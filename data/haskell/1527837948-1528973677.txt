Re `version 1`: `runState` actually has different type. This is how record fields work in Haskell. They always have data type as first argument. You can expect this in `ghci`: ``` Prelude&gt; newtype State s a = State { runState :: s -&gt; (a, s) } Prelude&gt; :t runState runState :: State s a -&gt; s -&gt; (a, s) ``` Re `version 2`: `sb` is a field of `State` constructor. It's just a name. And it has type `s -&gt; (b, s)`.
Version 1: runState is a function that accesses the “runState” field. So (check this with GHCI) it’s type is actually (State s a) -&gt; s -&gt; (a, s). If you come from an OO background you’re not used to thinking of the first parameter as a parameter (you think of it as “the object”). Version 2: State here isn’t the “State type”, it’s the “State Data constructor”. You can check in GHCI that its type is (s -&gt; (a, s)) -&gt; State s a. It takes the parameter and returns a State value with the parameter in runState. Hope this helps.
In addition to the other answers, I recommend messing around with records in ghci a bunch - it seems like you don't quite have a good intuition for how they work yet.
It's not so much the use of QuickCheck that is principled, but rather that we get a principled way of deciding _what_ to check and _how_ to check it -- that is, the what: the invariants and lemmas, the how: compare the results of the real implementation against the model.
Nice work! Have you thought about how you could abstract out the code that you've added on top of QuickCheck into a reusable library, so that it can be used to test other code? Also, correct if I'm wrong, it seems like you are following the approach in "Testing monadic code with QuickCheck" (2002). This approach was superseded by the state machine approach in "Finding race conditions in Erlang with QuickCheck and PULSE" (2009), which is the basis for Quiviq's Erlang QuickCheck, and at least three Haskell libraries. Is there a reason for why you chose to go with the former rather than the latter approach? Are concurrent interactions with the wallet possible? If so, have you thought about how to test those? Your formal specification seems Z inspired, did you consider using other tools than Coq for the formal proofs?
Would have loved to see some examples storing the data out of memory - seemed the blog post was excitedly leading up to it but I'm not really sure what to do with apart now. 
I used to use Keter. It works nicely. I would use it again, especially if I'm not deploying to AWS. Since I am deploying to AWS though, I do everything with NixOps. I wrote [an article](https://jezenthomas.com/deploying-a-haskell-web-service-with-nix/) a couple of years ago outlining how to deploy Yesod to AWS with NixOps. Maybe that will help.
Well, `apart` handle it in general. In README, there is an example with file: https://github.com/iokasimov/apart
&gt; What I'd like clarification on is, where is this behavior defined in GHC's source code that defines whether the monad is open or closed. I've been told that it's just a feature of the module system, like whether the type class's constructor is exported or not (https://en.wikibooks.org/wiki/Haskell/Modules), and that this is how the type checker knows to reject the program or not (???). &gt; and is the type checker less important (as in, not used, or used less) when the type class / monad is open? The typechecker is always used, and there is no such thing as using the typechecker "more" or "less" in some cases. The typechecker runs or it doesn't. If I define a module with some monad: module Foo where import Control.Monad (ap) data Foo a = Foo (a, Int) instance Functor Foo where fmap f (Foo (x, i)) = Foo (f x, i) instance Applicative Foo where pure x = Foo (x, 0) (&lt;*&gt;) = ap instance Monad Foo where (Foo (x, i)) &gt;&gt;= f = let (Foo (y, j)) = f x in Foo (y, i + j) That monad is "open", because you can write code like this: module UsesFoo where import Foo getFoo :: Foo a -&gt; a getFoo (Foo (x, _)) = x But let's say I change the first line of my Foo header: module Foo (Foo) where ... rest of the module is unchanged ... Then I can no longer use the `Foo` data constructor in my `UsesFoo` module, which means `Foo` is now a "closed" monad. I can still use `return` or `pure` to construct values of type `Foo a`, and I can use `(&gt;&gt;=)` to chain together functions that return `Foo a` values, but I can't ever get the value back out. By the way, this isn't really a monad thing, exclusively. I can make a type that isn't a monad, and make it "open" or "closed" depending on whether I export the data constructors. So putting information about this in the Monad typeclass would be kind of arbitrary.
Here's mine https://gist.github.com/LukaHorvat/58855a75ae74b81cd794c2fecf45c2b0 It turned out to be really slow though. The search space is too big so it's probably a better idea to only remember the last n states instead of all of them. I'm guessing this would also speed it up since the GC would do less work.
Which type\-safe SQL library\(Beam, Opaleye, Selda, etc\) do you prefer? And why?
I agree with pretty much everything said already, but I’ll give you a slightly different perspective: it’s better to think of monads as being a roach motel (closed in the terminology of the link). Things go in, they don’t come out. It turns out some of these things never existed in the first place (so how you would extract them is kind of meaningless). You _can_ get a value out of specific types that happen to be monads, but with the exception of identity, there’s alway going to be a qualification. In the case of Maybe, it could fail. In the case of List, either it could fail OR the value is a Monoid. And so on and so forth. It’s better to think that the only way to get a value “out” of a Monad is by binding it.
I'll have a follow-up blog post "I am not /u/snoyman" Followed later by "I am not Michael Snoyberg"
That course of action has never been a problem in my experience :D
I'd argue that without linear types we can only think of IO as being pure if we consider it a black box. IO being implemented as a State monad is simply a trick to have ordered evaluation, but you can't treat it as such, because you're not allowed to share the state. For example, this is evil: ``` extrict :: IO (IO a -&gt; a) extrict = IO $ \s -&gt; (# s, \(IO m) -&gt; case m s of { (# _, a #) -&gt; a } #) ``` Despite the fact that its State equivalent would be perfectly fine.
&gt; Excitingly, IOHK have recently hired someone to start work on the Coq formalization of the wallet specification, which will put the whole specification on an even stronger footing. 
Last time I've used wxHaskell was 7 years ago and if it's still not `complete` by now, then I don't really have to be more specific than that. `wx` is not a very well supported framework by itself, and wxHaskell adds on top by not binding to all the APIs. I'm sorry for giving an overly harsh critique for an OSS project, but anyone serious about developing Haskell GUI's should first look at jsaddle/electron – Yes, it's bloated, but at least it will work.
For the purpose of this comment, let's pretend that IO was defined as follows: module Prelude (IO, (&lt;&gt;), putStrLn) where data IO = MkIO [IOAction] data IOAction = PutStrLn String | ... (&lt;&gt;) :: IO -&gt; IO -&gt; IO MkIO actions1 &lt;&gt; MkIO actions2 = MkIO (actions1 ++ actions2) putStrLn :: String -&gt; IO putStrLn s = MkIO [PutStrLn s] This version of IO is a lot less expressive than the real IO, but the important point is that while this definition is much simpler, it isn't over-simplifying any of the important parts: GHC could totally use that as its definition of IO, and IO would still be "closed", we could still write programs producing some side-effects without compromising purity and referential transparency, etc. This version of IO also doesn't have a Monad instance. The point I am trying to make is that there is nothing magical about the Monad type class nor about the IO type. &gt; I would like to request some clarification regarding the Monad property of being open or closed I'd focus on the last paragraph of that Open monads section, the part which explains what a "closed" aka "no-exit" monad is: &gt; `return` and `(&gt;&gt;=)` alone do not allow us to extract the underlying value from a monadic computation, and so it is perfectly possible to make a "no-exit" monad, from which it is never possible to extract values. The most obvious example of that is the IO monad. It's the first time I hear the words "closed" and "no-exit" used to describe this property, but it is an important property and I don't have a better name to suggest, so let's roll with it. &gt; I've been told that it's just a feature of the module system, like whether the type class's constructor is exported or not That's correct! In my definition of IO, notice that I am exporting the IO type and a way to construct and combine values of type IO, but I am not exporting any function which allow you to extract values from IO. Once I call `putStrLn` on a String, there is no way to get that String back. I am also not exporting `MkIO`, so you can't pattern-match on it in order to extract values from IO that way. &gt; Shouldn't the property of whether the monad is closed or not be important enough to be included in the definition of the Monad type class, along with `bind` and `return`? Notice that my version of IO does not even have a Monad instance! IO is a "no-exit" type, because you can put values in but you can't get values out. It wouldn't make sense to add a method to the Monad type class indicating whether this particular type is open or closed, because whether a given type is open or closed varies from module to module! From inside my version of the Prelude module above, the IO type is open, because the MkIO constructor is in scope, and so the `(&lt;&gt;)` function can pattern-match on the contents of an IO value. From outside the Prelude, however, IO is an opaque type on which you cannot pattern-match, and it is closed because the module does not expose any function for extracting a value from it. &gt; and its importance to the understanding of the general concept of monadic types and type classes Not important at all. My version IO is closed, but it doesn't have a Monad instance nor an instance of any other type class. By the way, understanding type classes is a prerequisite to understanding monads, because, well, Monad is a type class. &gt; as well as their importance to a person's understanding of functional purity and referential transparity. Not important at all. Worse, I think this no-exit idea is misleading, because it might lead you to develop an incorrect intuition about purity. The _incorrect_ intuition is that if a pure function was allowed to contain an IO computation, the function would perform some IO side-effects when the program's execution reaches the IO code, and so the pure function wouldn't be pure after all. But as my definition of IO demonstrates, that's not what would happen at all! Values of type IO are merely _describing_ side-effects, they are not causing them to happen. If my version of IO was not closed, that is, if I was exporting the MkIO constructor, we certainly could write a pure function which pattern-matches on an IO value and extracts the Strings given to `putStrLn`, and running that pure function on an IO value would not cause any text to be written to the screen: -- | -- &gt;&gt;&gt; runIO (putStrLn "hello" &lt;&gt; putStrLn "world") -- "hello\nworld\n" runIO :: IO -&gt; String runIO (MkIO []) = "" runIO (MkIO (PutStrLn s : actions)) = s ++ "\n"++ runIO (MkIO actions) Haskell's purity and referential transparency is not a consequence of IO being closed. Haskell is a purely functional language because its functions behave like purely-mathematical functions, that is, their output only depends on their inputs, not on the state of a bunch of objects and global variables. This, in turn, allows you to substitute an identifier for its definition and vice-versa without changing the meaning of the program; this is referential transparency. Separately, once Haskell made the decision of being a purely functional language, there is the question of how to write programs which perform IO. Being able to write such programs is very desirable, but allowing functions to perform side-effects would ruin purity and referential transparency, so at first that looks like an unsurmountable obstacle. Haskell's solution is to separate the programmer's pure code which constructs the IO value describing the side-effects from the runtime system's impure implementation which performs those side-effects. So if you write: main :: IO main = putStrLn "hello" &lt;&gt; putStrLn "world" This, in itself, doesn't print anything to the screen, it merely constructs the value `MkIO [PutStrLn "hello", PutStrLn "world"]`. But then the runtime system examines this value and prints "hello" and "world". It can be helpful to imagine that there is a function `realMain` which calls your `main`, receives this piece of data describing a bunch of side-effects, and then performs those side-effects. The real version of IO is more efficient than that, and needs IO to be closed in order for its optimizations to work, but that's an irrelevant implementation detail.
And here is mine with animation: [http://jeffreyrosenbluth.github.io/2014/06/24/solving\-the\-15\-puzzle\-with\-haskell\-and\-diagrams\-10.html](http://jeffreyrosenbluth.github.io/2014/06/24/solving-the-15-puzzle-with-haskell-and-diagrams-10.html)
There is concurrency here, but the way we're choosing to specify this helps with simplifying the concurrency. The specification says there's a single wallet state and describes a small number of update operations. So a concurrent implementation has to do these updates atomically (and in practice we can simply serialise them). In the new implementation this turns into making the spec's update operations the atomic DB transactions. This is a big improvement over the previous implementation which was also concurrent but didn't have such a simple story about the state and updates.
wxHaskell is a community effort. Why should they do a big effort to make it complete, when there is little interest in it? It's good enough to build basic apps, and it could grow to be a viable toolkit for haskell desktop applications with enough feedback and contributions. The few electron apps I tried don't give a real native look and feel, and going via javascript seems like a real roundabout way. 
wxWidgets is a thin wrapper around platform widgets, so on Mac it's Cocoa (NSButton and friends), on Windows it's Win32 API controls (HWND "Button" and friends) and on Linux it's usually Gtk. So e.g. if NSButton, NSLabel, etc.. are hdpi-friendly, so is wx.
I have a tool for moving modules that mostly works available \[here\]\([https://github.com/vmchale/hask\-replace](https://github.com/vmchale/hask-replace)\). \&gt; So my suggestions are: None of these are ever going to be part of GHC, since Haskell\-the\-language is driven by a standard.
&gt; I recommend messing around with records in ghci a bunch Yes. I need practice more and to get the intuition. In fact I have read book like &lt;Programming in Haskell&gt; when I am reading I think I got it. But there is no real project for practice. These day I try to understand deeply question here I asked ( https://www.reddit.com/r/haskell/comments/8mjdul/cartesian_products_derivation_in_monad_form_for/) then I find more misunderstanding.
Has anyone done any work on a G-code backend for diagrams? I'd like to generate legend plates in a format that I can render to PDF and image formats, but also can render to a CAM program for an engraving machine.
Thanks all your replay. One more thing I can figure out **State s a ** in **&gt;&gt;=** 's type signature is just type kind. And it is different when *State* was using in function body. I think if the type name and constructor have different name may be good for me to understand. such like newtype State s a = MkState { runState :: s -&gt; (a, s) } 
Wow, beautiful code to read for a beginner like myself. Thanks so much for sharing!!!
Or I suppose to put it differently: we're no longer deeply concerned about concurrency bugs, since we've eliminated all the non-trivial concurrency. So the biggest return on dev time here is to have tests that check that we compute the right states and balances in the real impl. Yes in principle we could spend time writing other tests like tests that our implementation of the serialising of the state changes is right, but that bit is now trivial so it's not the most important test to implement. Remember this isn't about achieving maximum assurance, this is about a sensible balance between quality and time to deployment. We're basically claiming we're pretty close to the sweet spot for this problem in this commercial context, not that one could not achieve higher assurance still.
Is there a reason you used such tone in this comment?
Hello! This is the first announce of Kowainik's project. Previously `summoner` was called `hs-init`. Probably some of you heard of it or used it once or even more than once :fingers_crossed: * https://www.reddit.com/r/haskell/comments/76iti2/ann_hsinit_tool_for_creating_batteriesincluded/ Since then we gained some feedback and refined the project. Now `summoner` is a part of young functional programming oriented organization Kowainik. Our goal is to help Haskell community as much as we can. And we're trying to put a lot of effort into it! Also Kowainik is open to Haskell enthusiasts who wants to improve Haskell skills. Though we're still very small organization we offer mentorship to everyone who wants to contribute to our Haskell projects and who really enjoys writing in Haskell ^_^ 
Thanks for the kind words! Concur has a set of examples right now \- [https://github.com/ajnsit/concur#examples](https://github.com/ajnsit/concur#examples). There are also examples that come with the Purescript port of Concur [https://github.com/ajnsit/purescript\-concur#examples](https://github.com/ajnsit/purescript-concur#examples) which has very similar API. I do need to write better docs. It is one of the biggest hindrances to Concur adoption right now, even though it's an extremely simple framework. Do you have any examples from Reflex or some other lib that you would like to see translated to Concur? I would be happy to implement them and compare ease of implementation, code quality, performance etc.
Implementing the Elm architecture requires some kind of dom diffing and patching \(i.e. Virtual\-dom\). Does reflex have that now?
Oh boy... you’re right!
&gt; Programming in Haskell I second the suggestion on Stephen Diehl's writings. I also recommend going through [Typeclassopedia](https://wiki.haskell.org/Typeclassopedia)
As a frequent user of hs-init for stack projects I have to say the new name overreaches its features. Given the diverse and at times divergent project management ecosystem in Haskell, I would haves hoped to see some indication of stack in the choice of name. I do appreciate the tool though!
Whether the constructor of some datatype `MyData a` is exposed (so that the user can pattern-match and get to whatever is wrapped inside) has nothing to do with the question if there is `instance Monad MyData`. The monad interface _never_ provides this extraction functionality. That is why I don't think there is any reason to annotate the "openness" in the monad (class/instance) definition. It often makes sense to expose only a "closed interface" around some datatype, and hide the constructor(s) (very similar to having private members in OOP). And the exposed interface may consist of any combination of plain functions or type class instances (Monad or any other). So Monad is by no means special. I'd phrase things like "MyData is a monad" and "MyData has exposed constructor(s)". The term "open monad" seems misleading, plus the "open" term already is used to describe "open worlds/sets", i.e. how/if new instances can be defined by the user. 
What does ANN stand for?
Announcement
The reason I'm asking about concurrency, is because with the state machine approach you get concurrency testing for free from the sequential specification via "Linearizability: a correctness condition for concurrent objects" (1990).
This looks great, definitely going to try it out next project! I'm just wondering though, why did you choose toml as your configuration file language as opposed to e.g. yaml?
At Google, which has a large scale python deployment, relative inputs are forbidden. I don't recall the exact rationale, but speaking for myself, the readability benefit where everything is absolute far outweighs the modules being a bit easier to move. I've also done numerous large scale moves \(say 300\-400 modules\) and rewriting the imports is easy to automate. Also, `__init__.py` is forbidden, which I also appreciated, mostly through being annoyed by the rare times it was broken, usually in third\-party code. It's even addressed by my favorite "python zen" rule, which is something to the effect of "special cases are not special enough to break the rules." I'm not bothered by module name / filename duplication, because I automated that away a very long time ago, and I expect anyone who is bothered by it can easily add their own. What I am occasionally annoyed by is how ghc doesn't do any kind of warning when they don't match, it just emits an unexpected .o file. However, I know that there are build systems that depend on moduleName /= fileName, so any warning would presumably have to be behind a flag.
Thanks for your feedback! Previously `hs-init` used `stack new` command with generated template to create a project. But due to some limitation of `stack new` command, we don't use `stack` directly anymore. And `summoner` doesn't have goal to create only `stack`-oriented projects. It can be used with `cabal` as well. You can create project with `summoner` and run `cabal new-build` command to build project with `cabal` and without any problems. So, `summoner` supports both `cabal` and `stack` at the same time. Btw, it's so pleasant to see people who use `hs-init`!
I'm curious how a language closer to Haskell handle these things. Anyone know how Rust does it, for example?
Don't hesitate to ask any questions and create issues if you have any troubles! We're happy to help anyone who uses our tools and libraries ^_^ Regarding toml — excellent question! Short answer: because TOML is better than YAML. Long answer: * TOML configuration format is much more cleaner and simpler, doesn't contain unexpected and weird things, its specification much smaller thus simpler, but yet still as powerful as YAML. * Rust programming language uses TOML format as a format for their main build tool `cargo`, those guys can't be wrong. * YAML currently available for haskellers only with `yaml` package. And this package contains a lot of dependencies... Personally I like to care about size of dependencies and make packages smaller. We love TOML so much that we even created our own package `tomland` for bidirectional TOML conversion: * [`tomland`](http://hackage.haskell.org/package/tomland) It's not completely finished, but it is already good enough to implement simple configs for projects like `summoner`. And it also has less dependencies than `yaml`. And yes, there're already exist packages for parsing TOML in Haskell, but `tomland` was implemented with different design decisions in mind. 
Why do you need `Cofree`? Would `Fix` not do the job?
&gt; `__init__.py` is forbidden What do you mean? You have to have `__init__.py` to have any nesting of modules!
It's not clear to me that there's any difference between what we're both advocating here. The specification is as a state machine. The tests do indeed work by generating sequences of API calls for the state transitions. We do check post conditions (invariants from the spec). And we compare the states of different versions of the spec and of the impl with each other for equality (or equivalence under the abstraction relation). We're not doing concurrency testing here because the concurrency is trivial and we're not aware of any Haskell library that does give us that for free. QuiviQ's Erlang QuickCheck framework is very nice, but I'm not aware of any equivalent (mature or otherwise). For other projects where there is non-trivial concurrency, and a similar state machine style specification, then it may well be worth it to take the time to develop the framework to capture the concurrency in a free monad and implement the user level scheduler and explore the state space of possible interleavings.
Historically, blaze generated empty `__init__.py` for you. I think later on that was rendered obsolete due to custom import hooks, not sure though. I should say you could add them if you wanted, they just couldn't have anything inside. In practice, almost no one added them.
So was every importable module a leaf module?
Are these functions equivalent? fib0 :: Int -&gt; Int fib0 = go 1 1 where go a b n | n &lt;= 0 = a | otherwise = go b (a + b) (n - 1) fib1 :: Int -&gt; Int fib1 n | n &lt;= 1 = 1 | otherwise = fib1 (n-1) + fib1 (n-2) They calculate the same return value, but have vastly different complexities and run times: λ fib0 35 14930352 (0.00 secs, 75,280 bytes) λ fib1 35 14930352 (14.66 secs, 4,300,008,952 bytes) 
I don't really understand the question, but it's basically just like haskell. `from a.b.c import d` is isomorphic to `//a/b/c/d.py` (did I get that jargon right?). In addition, BUILD files allow relative paths, but forbid `..`, so that's sort of a compromise.
In a pure language like Haskell... yes You are right they have different run-times, but the run-time cannot be purely observed, so the two functions are equal, for all intents and purposes. You can define a different notion of equality, but then you'd move away from `Eq`-equality to some other kind of equality. In reality, these equivalence relations give rise to equivalence classes. For most domains, the `Eq`-equality gives rise to equivalence classes inhabited by only one element. However, in the case of functions, some equivalence classes have multiple members. Nevertheless, anything that falls in the same class can be said to be equivalent with respect to `Eq`, which is what you are asking for when you use the `(==)` function.
The scheme you are describing sounds too painful to use in practice so something's off. Suppose I have this module layout % for py in `find . -iname \*.py | sort -r`; do echo $py:; cat $py; echo; done ./a/__init__.py: print("a/__init__.py") ./a/b.py: print("a/b.py") ./a/b/__init__.py: print("a/b/__init__.py") ./a/b/c.py: print("a/b/c.py") ./a/b/c/__init__.py: print("a/b/c/__init__.py") ./a/b/c/d.py: print("a/b/c/d.py") The files `a.py`, `b.py`, `c.py` are completely ignored by `python` due to the `__init__.py`s in the directories of the same names. By hypothesis the `__init__.py`s are empty, so it's useless importing `a`, `a.b` and `a.b.c`. % PYTHONPATH=. python -c 'import a' a/__init__.py % PYTHONPATH=. python -c 'import a.b' a/__init__.py a/b/__init__.py % PYTHONPATH=. python -c 'import a.b.c' a/__init__.py a/b/__init__.py a/b/c/__init__.py The only module worth importing is the leaf module `d` which doesn't have a subdirectory of the same name, and therefore no associated `__init__.py`. % PYTHONPATH=. python -c 'import a.b.c.d' a/__init__.py a/b/__init__.py a/b/c/__init__.py a/b/c/d.py 
I still don't see how such a definition is useful, given that computing equality is not necessarily practical (for cases like `fib0`/`fib1`) or theoretically possible (given the undecidability of the halting problem).
It’s useless for most things... that’s why it’s not provided, but it is a law abiding instance for `Eq`
Oh yeah, it might be the case that blaze would error on you if you tried to have both `a.py` and `a/`. I could have honestly gone for 10 years and never noticed, because I don't have much reason to do that. Maybe it's because python doesn't really have the re-export habit like haskell does. I also noticed that various external python APIs didn't follow internal rules and shouldn't have passed review. Maybe rules are altered or relaxed for those, or the API bindings were produced by teams that don't otherwise write python. In any case, it's a bit off-topic for a haskell group :)
Is there a reason for some of the Prelude monads (IO and State are the ones I am aware of) to have classes like `MonadIO` and `MonadState`? Also, what does the `MonadState` class declaration, which looks like `class Monad m =&gt; MonadState s m | m -&gt; s where` actually mean? I remember reading somewhere that they're present to make it easier to use the monad transformers for these monads in a bigger stack of transformers, but I don't fully comprehend the magic yet.
You'd have to add an extra field to each constructor of the base functor (or, equivalently, wrap it in `Compose ((,) a)`), but yes. The main advantages of Cofree are that you don't need to do that, you get a `Comonad` instance for free, and you *know* that the resulting type is a tree with a value at each node, no matter what you pass to Cofree.
The key sentence in that section of the Wikibook is: &gt; `return` and `(&gt;&gt;=)` alone do not allow us to extract the underlying value from a monadic computation, and so it is perfectly possible to make a "no-exit" monad, from which it is never possible to extract values. As /u/ElvishJerricco , /u/gelisam , /u/hexagoel and others are pointing out, using "open monad" and "closed monad" to express that idea is non-standard terminology, and somewhat clumsy. It is a holdover from earlier versions of the monad chapters, and it had escaped me that it might be problematic. I will reword that section. Thanks for the feedback! 
Often you wouldn't want your type to be a comonadic tree with a value at each node though, right? Only certain classes of data structure fit that framework.
 class Monad m =&gt; MonadState s m | m -&gt; s `MonadState` is the class of types that store a state of type `s` and have an underlying `Monad` of type `m`. Furthermore, the *functional dependency* says that the `s` parameter is “fully determined” by the `m` parameter, so it can be inferred if only the `m` parameter is unambiguous—for example, if `m` is `StateT MyState AnotherMonad`, then `s` is constrained to be `MyState`, and if `s` would otherwise be an ambiguous type, you don’t have to add a type annotation because the compiler can figure it out. These classes basically let you use generic operations for state, I/O, reading, writing, and so on without explicitly adding `lift (lift (lift someAction)))` to wrap an action in the correct number of transformers. That in turn makes it easier to change your monad transformer stack without having to update any business logic which uses that stack.
Sorry, I can’t agree with you on the second paragraph. The Haskell Language Standard is old and getting older, there’s been any amount of innovation since then. Moreover, all the other Haskell implementations are no longer maintained. Haskell is GHC in a way that’s unprecedented in Haskell’s history. If there ever is another version of the standard (and I think that would be a good idea), it will be driven by GHC, not the other way around.
Ah, ok. It's `Writer Any`
Will help certainly, thank you!
Nice write up! You could expand the Binary tree example to have a function that traverses it to help people understand recursive types and their uses better.
The mouthful defining `testmap` could be written more concisely as a nested association list and relying on the `OverloadedLists` extension to convert it into nested maps.
Oh, right. Thanks for the hint! 
&gt; Trolling and sockpuppet accounts are just a normal part of internet discussions Maybe this attitude made some sense 30 years ago, when the Internet was still a tiny part of the world. At this point, "the Internet" isn't some other world where if you don't like being treated that way, you can just leave. It's an integral part of our lives. Deciding that rude and obnoxious behavior is just part of the Internet is the same as tolerating mistreatment of others in general. We should definitely consider the consequences of just saying it's okay. This isn't directed specifically at this account, which is unappealing to be sure, but at least a mild form of trolling. I'm mostly just pointing out that before long, this idea of writing off rudeness just because it's the Internet leads to a kind of dark place.
I wouldn't mind some of these changes - implicit module names and relative imports make sense to me. But...why does renaming the strings in the files take a long time? I've never heard of a programmers editor that doesn't have a feature or plugin to find and replace in all project files.
This might be a bit obvious, but an update to type Foo is a function of type Foo -&gt; Foo. That doesn't help with inspecting them or storing them to disk, but if you just want to keep updates in memory and apply them to objects, that should be ok.
Currently using Beam and am quite happy. Your data types are simple records and Haskell values, which is a breath of fresh air when comparing it to how the other libraries tend to work. It has a few conventions, but they don't get in the way and can be overriden. The author has written some great documentation, and is very active. Have submitted a few PRs and they were merged within 24 hours.
One thing is I like to have my imports in alphabetical order.
It's easier than you think. data User f = User { name :: f Text, birthdate :: f UTCTime } type ConcreteUser = User Identity type UserUpdate = User Maybe updateUser :: User Identity -&gt; User Maybe -&gt; User Identity updateUser (User (Identity nm) (Identity birthdate)) (User nmU birthdateU) = Update (Identity (fromMaybe nmU nm)) (Identity (fromMaybe birthdateU birthdate)) updateName :: Text -&gt; User Maybe updateName nm = User (Just nm) Nothing updateBirthdate :: UTCTime -&gt; User Maybe updateBirthdate tm = User Nothing (Just tm) Note that you can easily define a type class for this class Updatable u where update :: u Identity -&gt; u Maybe -&gt; u Identity instance Updatable User where update = updateUser You can also define a `Monoid` or `Semigroup` instance for `User Maybe`, or actually, any `User f` where `f` is an `Alternative`. instance Alternative f =&gt; Monoid (User f) where mempty = User empty empty mappend (User aName aBirthdate) (User bName bBirthdate) = User (aName &lt;|&gt; bName) (aBirthdate &lt;|&gt; bBirthdate) Now, you can represent an update of both name and birthdate. updateBoth :: Text -&gt; UTCTime -&gt; User Maybe updateBoth nm bd = updateName nm `mappend` updateBirthdate nm You can write serializers, etc, for `User` with some constraints on `f`. For example, `ToJSON`: instance ToJSON1 f =&gt; ToJSON (User f) where toJSON (User nm bd) = object [ "name" .= liftToJSON toJSON toJSONList nm , "birthdate" .= liftToJSON toJSON toJSONList bd ] Now you can send updates, concrete representations, etc over the network. No problem. I'm actually working on a package for expressing incremental changes to large expression trees using this approach. There's a few subtleties, especially when it comes to nesting, but this is the basic idea.
Yeah, I usually just fix it the next time I edit the imports in that file, but you can run `stylish-haskell` over your tree after doing the replace.
I'm trying to implement 2D coordinates \(I know...\) as a module using the algebra library. Unfortunately, I'm getting a conflict between an instance of LeftModule I've declared and one declared in the base library. GHC reports this as instance Semiring a =\&gt; LeftModule a \(Square a\) \-\- Defined at C:\\Users\\me\\grids\\src\\Lib.hs:50:10 instance \[safe\] Additive m =\&gt; LeftModule \(\) m \-\- Defined in \`Numeric.Algebra.Class' Due to another declaration, \(Square a\) is already an Additive, so I can see why these are conflicting, but how do I get out of it \(needless to say, I don't want to turn on a "bad" extension\).
I don't see a compelling enough reason though. The things that you mention as slow, fixing module names inside a file are super easy to automate with a good editor or just on the command line. 
So I guess there are two approaches here, one is that Haskell should need a very minimal set of external tools to build and scale a project in, such as just a text editor, and a way of installing dependencies / compiling. Another approach is to accept the idea that external tools are needed for a nice development experience, I think the former is a nice goal to achieve, but I understand if many take the latter approach. What tool would you recommend for automating all this stuff? Do you just use a simple project wide regex or something safer and smarter? In particular I am using nix / reflex\-platform as my package management / build tool, so something that works well with that would be ideal.
Partly I just like having my imports in sorted order, which then means you need to start using some kind of Haskell\-aware clever external tool.
You can apply a mass stylish-haskell on all files after the rename. 
Have a look at the Learn You a Haskell book (free version online). The Binary Tree example is near the bottom of the page. http://learnyouahaskell.com/making-our-own-types-and-typeclasses
Nicely. I really like it, though it is not yet something I fully understand. Rust allows individual files to contain multiple modules. Whole files can also be modules. Nesting is as expected, though I found working out which modules are in scope to be quite surprising. I managed to get code using modules working without much trouble (in my only rust project — https://github.com/dbaynard/booklet) though I'm not familiar enough to explain the scoping rules, especially when considering `public` interfaces. That project is a decent example of the module structure. See &lt;https://doc.rust-lang.org/book/second-edition/ch07-00-modules.html&gt;. So, &gt; Add support for relative imports: This is the bit that I haven't quite grokked. From the link above (one of the sub-pages): &gt; Overall, these are the rules for item visibility: &gt; &gt; If an item is public, it can be accessed through any of its parent modules. &gt; If an item is private, it can be accessed only by its immediate parent module and any of the parent’s child modules. Modules, data types and functions are declared as public using the `pub` keyword, otherwise they are private. The definitions of public and private are in the above quote. I _think_ 'parent module' means foo::bar can import anything private in foo::bar::baz but foo cannot (please correct me if I'm wrong — though the compiler will throw errors if you try to do the wrong thing anyway). Likewise, I think it means foo::bar::baz can import anything private in foo::bar. &gt; Make module names optional, since the file location already unambiguously specifies them: Module names are take from directory structure first, and module declarations separately within that. The duplication we have in Haskell would lead to duplicate modules in rust. &gt; Add an equivalent to `__init__.py`: If there is a directory `foo/` then the file `foo/mod.rs` will be the module `foo` and any `foo/bar.rs` will be `foo::bar` (equivalent to `Foo.Bar`). If there is only `foo.rs` that is module `foo`. &gt; Make it possible to specify what modules are a part of the project via some mechanism outside the cabal file In rust exported modules must be marked as public, and may (I'd need to check) need to be reachable from the top level `lib.rs` file. The equivalent of a cabal file (`cargo.toml`) does not need module information, and I don't think it's possible to add the modules there. In practice (snippets from my `booklet` project), this means the following: src/main.rs ```rust /// The booklet library contains most of the code extern crate booklet; use booklet::*; ``` This is the entry point for the executable. The rest of the code is library code. My (library) crate is called `booklet` and my `use booklet::*` imports the top level public modules. This code calls the `reorder` function, defined in `src/rearrange.rs`. src/lib.rs ```rust /// Actually rearrange the pages. pub mod rearrange; pub use rearrange::*; /// The extra modules supply functionality that is not specific to pdf processing. mod extra { /// Generate error values. pub mod error; /// Add missing functionality to `lopdf`. pub mod lopdf; } ``` This is the top level module. The `pub mod` lines indicate which modules are exported at top level. The `pub use` line is a re-export of the contents of the module. This combines an export list and the exported modules list from the cabal file. The module `extra` is not marked `pub` so is not available when importing the `booklet` library, but it is available in all modules within the library (as the parent is the top level `lib.rs` and all other modules are children). Within that module, the modules `error` and `lopdf` must be marked `pub` as otherwise they would only be available within the `extra` module (parent) or each other's modules (I'm uncertain about restrictions on cyclic dependencies here). src/rearrange.rs ```rust use extra::error::*; use calculate::*; /// Rearrange the pages /// /// - infile: If a path, use the file, otherwise use stdin /// - outfile: If a path, use the file, otherwise use stdout pub fn reorder&lt;P&gt;( infile: Option&lt;P&gt;, outfile: Option&lt;P&gt; ) -&gt; io::Result&lt;()&gt; where P: AsRef&lt;Path&gt; { … } ``` The function is declared `pub` so that any module which imports the `booklet::rearrange` module may import `reorder`. In practice, reorder is re-exported from `lib.rs`, and then imported directly in to `main.rs`.
This is really interesting! Thanks! But is there a way to represent those updates as serializable values? I want to store the updates themselves instead of applying them to a given object.
That's what the \`ToJSON\` instance is for. You can give it a \`User Maybe\` and it'll return a json object. For example, if you do \`Data.Aeson.encode \(updateName "John"\)\` you'll get { "name": "John", "birthdate": null } You can get rid of the \`null\` with a new type class to replace \`ToJSON1\`.
Oh, I updated my answer before seeing this. It was so obvious I'm embarrassed for not seeing it. Thanks a lot, this is really neat! 
My personal project is only around 700 modules, which is too small for it to be an issue. I just move by hand. I use `fix-imports` for managing imports, which I guess does handle the fixing imports part of the move, maybe that's why I don't mind doing it by hand. For a large move I guess I'd do a script to replace the module line, and then mass apply `fix-imports` so maybe that really is the automation you're talking about. I suppose it would need to be clever enough to run in dependency order. Also I assume a large code base will certainly not be using cabal, so updating all those cabal file won't apply, but you'd likely have to update some other kind of file. I just don't move stuff that often, so I feel like there are much bigger fish to fry in haskell tools land.
Maybe also take a look at the gdiff package. http://hackage.haskell.org/package/gdiff-1.1/docs/Data-Generic-Diff.html
No, you can import any of these. Traditionally (Python &lt;= 3.3, I think?), you needed an `__init__.py` to be able to import a Python module in a particular directory (and module is 1:1 with a file ending in ".py"). Thus, if you had this: dir1/ a.py You mostly couldn't import a.py in another module without having a (empty or with declarations) `__int__.py` in the same directory. The `__init__.py` file in practice is used to run code so you can *import the directory as if it were a module*. For instance, here's an [example from`flask`](https://github.com/pallets/flask/blob/master/flask/json/__init__.py), a popular web framework. This `__init__.py` file is in the directory `json` inside the package `flask`. Thus, you can do the following: from flask import json And every top-level declaration in this `__init__.py` will be evaluated and available under the namespace `json`. By contrast, if you do this: from flask.json import tag Then all top-level declarations in the `__init__.py` will be evaluated *and then* all top-level declarations in `flask.json.tag` will be evaluated and the latter will be available under the namespace `tag`. This behavior can lead to some surprising stuff, because you can bury a bunch of logic inside an `__init__.py` next to a variety of modules and all the top-level declarations inside the `__init__.py` will be evaluated the first time anything from that directory gets imported. I've had to teach this so many times over the years, so hope I did an okay job explaining it and hope I actually understood your question. 
Why would a large project not be using cabal?
Nice. I'd try your lib if you share, once it's done.
FYI, MonadState and MonadIO are both not in the Prelude.
Do you know how well \`Beam\` handles sum types?
I think you may be misunderstanding my example. My example shows that you *can* import `a.b.c`, for example, but that the file that is read is `a/b/c/__init__.py` and not `a/b/c.py`.
&gt; In any case, it's a bit off-topic for a haskell group :) It's on topic if you're using this as a counterpoint to /u/Tysonzero's proposal!
I have a library that does just that: [aeson\-diff\-generic](https://hackage.haskell.org/package/aeson-diff-generic) It represents updates as a json\-patch \([rfc6902](https://tools.ietf.org/html/rfc6902)\), which is an official json format representing changes to a json value. With my library you can apply the patch directly on any haskell datastructure, by auto deriving instances with template haskell. Typically you use it with the http PATCH method. You receive a patch via a REST api, then apply it directly to the corresponding haskell ADT, which will also validate the patch. I also have support for generating a patch from haskell, using modified lenses. Using those you can do updates the way you do with lens, but also get a patch out of it. For example: λ&gt; overPath _1P (+1) (1, "one") (Patch {patchOperations = [Rep {changePointer = Pointer {pointerPath = [AKey 0]}, changeValue = Number 2.0}]},(2,"one")) You can then store the patch to apply it later, or send it over the network to another service. That functionality isn't yet complete, let me know if you are interested in it.
Nice video you got here \^\^ I always had problem to understand what exactly is servant, and reading the docs didn't really help. Your video helped me quite a lot :\) However you're a bit hesitant, and maybe you should talk a little slower
Author here... Can you expand on what you mean when you say 'sum' types? In general, most currently available RDBMS systems do not support general sum types. Some backends support enumeration types. For example, I recently added support for Postgres `enum` types in the [latest branch](https://github.com/tathougies/beam/blob/travis/beam-0.8.0.0/beam-postgres/Database/Beam/Postgres/CustomTypes.hs) (sorry... not documented yet, this is a new change). This allows 'native' postgres enumeration types, stored in postgres's optimized way. Of course, you can also store enumeration types as ints, strings, or whatever in a RDBMS. You can do this in a backend agnostic way by providing two instances for each data type: a `HasSqlValueSyntax` and a `FromBackendRow`. For example, if you want to use the `Enum` instance for a data type (bad idea, for many reasons), you can do something like instance HasSqlValueSyntax s Int =&gt; HasSqlValueSyntax s MyEnum where sqlValueSyntax = sqlValueSyntax . fromEnum instance FromBackendRow be Int =&gt; FromBackendRow be MyEnum where fromBackendRow = toEnum &lt;$&gt; fromBackendRow You'll need these for the postgres enumeration support as well, but bleeding-edge `beam-postgres` provides convenience functions for this. Finally, if you really want to store arbitrary sum types, both the postgres and mysql backends support arbitrary JSON.
I guess I shouldn't say "certainly" with such confidence, actually I have no idea what people use. I don't, and wouldn't for anything other than tiny. Even for medium projects it's awkward and slow, and it gets worse as the size goes up. And it's not even an option if you need to build more things than haskell. I should say I think it works fine for lots of loosely coupled distributed small projects, namely hackage. You get the dependency resolution, which is the main draw, and the bare-bones build doesn't hurt much when there isn't much to build.
Thanks for your reply! I'll take a look.
But like what do you use instead? I use nix but I still have a cabal file, and I use cabal new-build inside a nix shell for incremental building. 
Thank you so much for the feedback! So glad the video does make some sort of impact😊 i was a bit nervous. hope with time and practice i will find a better rythem. thanks again.
Only took a quick look, but some tricks that I've come across when implementing tries in Haskell: * All of the operations (`insert`, `member`, `delete`, etc) can be implemented as a fold, making the structure a little more general: member :: (Ord c, Foldable f) =&gt; f c -&gt; TSet c -&gt; Bool member = foldr f (\(TSet (Node e _)) -&gt; e) where f y ys (TSet (Node _ m)) = maybe False ys (Map.lookup y m) insert :: (Ord a, Foldable f) =&gt; f a -&gt; TSet a -&gt; TSet a insert = foldr f b where f x xs (TSet (Node e m)) = TSet (Node e (Map.alter (Just . xs . fromMaybe empty) x m)) b (TSet (Node _ m)) = TSet (Node True m) * Using GADTs, you can make the type conform to things like `Foldable`: data Trie a where Trie :: Bool -&gt; Map a (Trie [a]) -&gt; Trie [a] This puts the type parameter the right way around. * Lensy operators work really well here. Insert, for instance, can be: insert = foldr (\x xs -&gt; children . at x %~ Just . xs . fold) (endsHere .~ True) * It's worth taking a look at compressing paths; it's not actually that much more difficult than the normal trie itself. * The normal trie definition is the same as `Cofree (Map a) Bool`: this type actually comes with a bunch of useful instances (traversablewithindex, for instance) for free. You could wrap a newtype around it, or just use the instances as a template. I'll look more if I get a chance!
ghc-exactprint uses the GHC lexer and parser, so matches what GHC produces
Thank you! There are many things to learn from your comment. * Making `member`, `insert`, etc. more general sounds good! * My implementation for `member`, `insert`, ... consumes a list lazily, so `genericMember xs = member (toList xs)` should not be much bad... is it? * GADTs trick seems interesting. My implementation uses auxiliary "Node" type: data Node c r = Node !Bool !(Map c r) newtype TSet c = TSet (Node c (TSet c)) Simply making TSet a GADT introduces an overhead since GADTs can' be `newtype`, so I think it needs some work to introduce it. * I don't know lenses well, only managed to understand your example. * I hear `TraversableWithIndex` first time. Is it `lens` package thing? I only searched at Hackage. * I considered `Cofree` once, but gave up that idea for fears to take possible performance penalties from the more generic data structure and `Bool` part being lazy. It seems you have an experience of implementing trie. Is there a information about it publicly available? Is that one of trie implementations found at Hackage?
&gt; I don't, and wouldn't for anything other than tiny Well don't leave us hanging here. What *do* you use!
`haskell-src-exts` will work correctly in almost all cases. Lots of tooling uses it. However, it cannot handle Template Haskell. In fact, the only way to analyse code that uses Template Haskell is to use the GHC API to actually run it and see what comes out.
&gt; It's not clear to me that there's any difference between what we're both advocating here. The specification is as a state machine. The tests do indeed work by generating sequences of API calls for the state transitions. We do check post conditions (invariants from the spec). And we compare the states of different versions of the spec and of the impl with each other for equality (or equivalence under the abstraction relation). I'm merely trying to find out what approach you're taking, and trying to spread awareness about that the "Testing monadic code with QuickCheck" approach is dated. If you guys are already thinking in terms of state machines, then that's cool. &gt; We're not doing concurrency testing here because the concurrency is trivial and we're not aware of any Haskell library that does give us that for free. QuiviQ's Erlang QuickCheck framework is very nice, but I'm not aware of any Haskell equivalent (mature or otherwise). Not mature at all, but there's: * https://github.com/advancedtelematic/quickcheck-state-machine * https://teh.id.au/posts/2017/07/15/state-machine-testing/index.html &gt; For other projects where there is non-trivial concurrency, and a similar state machine style specification, then it may well be worth it to take the time to develop the framework to capture the concurrency in a free monad and implement the user level scheduler and explore the state space of possible interleavings. This has been done before for things like testing Raft implementations. We may well do the same for a future Ouroboros implementation. I've also experimented with separating business logic from networking, so that simulations of different networking conditions can be run using a deterministic user land scheduler in: * https://github.com/advancedtelematic/quickcheck-state-machine-distributed It's still early days for those libraries though. I think we know how to do most of the cool stuff that Quiviq's QuickCheck does by now, but the user interface and ergonomics is still lacking. This is also why I was asking if you guys have thought about making a reusable library, with the hope of encouraging more action in this space -- which I think has the potential to improve software quality at large in our community!
Rhythm Don't worry, it's a bitch of a spelling and definitely missing a few vowels. 
If you have any feedback on the tutorial, let us know :)
I built out a generalised idea of your `Updatable` idea in a blog post from a few months ago: https://www.benjamin.pizza/posts/2017-12-15-functor-functors.html
Is the following function linear in its second argument? f b v = if b then g v else h v It appears to consume `v` twice, but we know that it will always consume it only once, since `b` can’t be true and false at the same time.
Never used toml for anything advanced, does toml support aliases? Like in yaml you have &amp; for alias and * to reference it.
You probably don't need anything advanced most of the time. But TOML doesn't support aliases. As to me, YAML is more complicated than advanced. It's not advanced enough to cover all your needs at the end. If you're looking for some advanced configuration format, take a look at `dhall`: * https://github.com/dhall-lang/dhall-haskell
I really don’t buy the argument that YAML is complicated. Maybe for the person writing the parser, but not for the user. Only in trivial configuration formats, do you not win from references. I of course haven’t looked at what is needed in the toml configs one has to write, but hope it doesn’t have a lot of duplication.
How should you write the ToJSON1 instances for the HKD types you wrote about in your blog post? Do you have an example?
Nice introduction
That sounds right to me.
Damn I wish I could have contributed to that.
I have a question about the overall philosophy of Liquid Haskell and its relation with other approach. In this [SO question](https://stackoverflow.com/questions/49477427/why-havent-newer-dependently-typed-languages-adopted-ssreflects-approach) there's a mention of a style of proof in Coq in which the invariants of a datatype are kept separate from the definition of the datatype itself. Isn't that Liquid Haskell's approach, as well? Are these styles related in some way? Liquid Haskell does seem to have more emphasis on automation by using SAT solvers.
Oh, my apologies! You are right on both accounts: I misunderstood your example and that's correct. In this as in other things in the language, convention dictates that people never name directories and sibling modules with the same names. Come to think of it, I had trouble remembering this practice in Haskell for a long time as a result of my Python training.
If it's complicated for parser it's also complicated for user. Because parsing program is just faster human parsing. YAML is easy only when you're using small subset of it. Did you know there're nine ways to write multiline strings in YAML? Like, what the hell. * https://stackoverflow.com/a/21699210/2900502 We've used `hpack` for big multipackage project. Basically, `hpack` allows to write configs for Haskell projects in YAML with some extra features. YAML really helped to remove configuration duplication! And we used references and aliases. But syntax is ugly... Doesn't really human-readable (and human readability is what you want from configuration usually). YAML just feels like partial solution. More power to complicate things. But doesn't solve all problems. For example, you can't remove config duplication in YAML lists: * https://stackoverflow.com/questions/9254178/is-there-yaml-syntax-for-sharing-part-of-a-list-or-map So, again, if you want to have full control over configurations and remove duplication, why not just use the tool which is a *total* solution to all problems like `dhall`? Several more arguments against YAML: * https://www.reddit.com/r/rust/comments/7izxrg/toml_or_yaml_for_config/dr2o73t * https://github.com/cblp/yaml-sucks
What’s the linearity of the first two arguments to [`bool`](https://www.stackage.org/haddock/lts-11.11/base-4.10.1.0/Data-Bool.html#v:bool)? Seems to me like this isn’t possible to infer at compile-time, since only one of the arguments will be consumed exactly once, depending on the value of the third argument. Or do we say these two arguments are linear since they are referenced exactly once in the definition of `bool`, albeit each in a separate pattern match? Ie.: bool a _ True = a bool _ b False = b 
Did you respond in the wrong place?
Oh, for my personal project, shake. At work, nix. Then there's bazel plus tweag's haskell scripts, which I haven't tried, but probably would if I were starting something new. Well, I'd realistically start with cabal and then migrate once cabal started getting unwieldy.
There's the upcoming `DerivingVia` extension for that. newtype M a = M a deriving (Functor, Applicative) via (WrappedMonad M) instance Monad M where ... There is another example here https://github.com/Icelandjack/deriving-via/blob/1b77212b6cb200e0e06aa08dd32d99c35c332d0c/examples/MTL.hs#L62-L64 and [in their paper](https://www.kosmikus.org/DerivingVia/deriving-via-paper.pdf) (search for `FromMonad`).
i "practice" to actually write code with challenges on sites like [codingame](http://www.codingame.com) ,[codewars](http://www.codewars.com) or [hackerrank](http://www.hackerrank.com) they also have very easy ones to get started with a new language
Oh yeah I've used a couple of those before, forgot about them, thanks for the reminder!
`bool` is not linear in its first two arguments. To encode its particular resource usage pattern, we need either to extend the type system to be dependent, or come up with a different combinator (and possibly more primitives).
The main reason for using foldr instead of pattern matching is that it can fuse—so often, the intermediate list is never created in memory. Yeah, to have the same overhead as your approach with GADTs you’d need to forgoe the Node constructor. The TraversableWithIndex class is in Lens: you probably won’t write and instance for it, but it can be used to make your Foldable instance for you TSet. There are a few trie implementations on hackage, but I haven’t really looked at them in detail. I have my own kind of playground for tries [here](https://github.com/oisdk/hstrie), but it’s not a proper package or anything.
sure theres also this chrome [extension](https://www.codingame.com/blog/new-feature-codingame-sync-use-your-own-code-editor-on-codingame/) for codingame which allows you to use your own editor of choice by syncing a local file with the online IDE, in case you're interested
Should I use `traverse` or `mapM` in new code? More precisely, it feels like `traverse` and `traverse_` are "better", partly because of the generality/type precision, and partly reflecting a mental model of foldable/traversable being first class abstractions for modelling problems. But I very often see new code written by expert old hands use `mapM` and `mapM_` still, so it also feels like this must (almost by definition) be more idiomatic Haskell. So which should I internalise into muscle memory?
Oh my God awesome
It’s not linear, but it is affine. `a` and `b` are each used *at most once* (affine, no contraction/copying) but not *exactly once* (linear, no contraction or weakening/dropping). Although I’m stoked about linear functions in Haskell, I’d rather `bool` have a type like `Drop a =&gt; a -&gt; a -&gt; Bool -&gt; a` so we could express types like this.
I recently did Advent of Code 2017. Learned a lot.
I usually go for making web programs in any language I come into. You could also make your own little toy language. Or an IRC bot—basically just anything that interests you. That said, I’d recommend checking out some of the following resources. Sorry me of them build various programs up, in their tutorials: - Yesod and the Yesod book https://www.yesodweb.com/book - Servant (a bit more type advanced) with it’s intro http://haskell-servant.readthedocs.io/en/stable/ - Checking out Stephen Diehl’s excellent Write you a Haskell http://dev.stephendiehl.com/fun/ - Learning to use Aeson for JSON (and more) handling https://artyom.me/aeson - Learning about lenses http://hackage.haskell.org/package/lens-tutorial-1.0.3/docs/Control-Lens-Tutorial.html 
http://exercism.io/exercises/haskell/ has a good set of problems and it lets you set up your environment locally.
I don't see anything about breaking the type system in the link you provided.
Awesome thanks 
Cool ideas, will probably do an irc bot, I've done one before in Ruby 
I saw that before, I'll check it out 
perhaps I mis defined "breaking". what I meant was you can get to a runtime error using a GADT, i.e. from the link: &gt;parse "K" **=** K &gt; &gt;parse "S" **=** S &gt; &gt;you'll get a nasty error like so: &gt; &gt; Occurs check: cannot construct the infinite type: c = b \-\&gt; c &gt; &gt;Expected type: Term \(\(a \-\&gt; b \-\&gt; c\) \-\&gt; \(a \-\&gt; b\) \-\&gt; a \-\&gt; b \-\&gt; c\) &gt; &gt; Inferred type: Term \(\(a \-\&gt; b \-\&gt; c\) \-\&gt; \(a \-\&gt; b\) \-\&gt; a \-\&gt; c\) &gt; &gt;In the definition of \`foo': foo "S" = S
That's a compile-time error, not a runtime one.
An elegant use of parameterization, thanks for posting this
Just to expand on this a little more: The GADT thing is more of a novelty, because actually using the GADT version can get a little cumbersome with type inference especially. In particular, instances will usually look like this: instance (Eq a, b ~ [a]) =&gt; Eq (Trie b) rather than this: instance Eq a =&gt; Eq (Trie [a]) Even though the first one looks more complex, it actually gives you better type errors. There's a blog post somewhere expanding on why, but I can't find it at the moment.
Oh. (Facepalm) Thank you
As soon as I saw the first line of code, I had to check the username. "Is that the Beam guy?"
No problem. Feel free to ask any other questions about the type system if you come upon them.
Just for future reference, haskell does not have *any* runtime type checks to my knowledge. You get garbage or segmentation faults.
In Haskell (along with all the GHC extensions), is it at all possible to define something with *kind* `A -&gt; B`, where `B` isn't `*`? I should clarify that I'm not talking about something that sort of has kind `A -&gt; B`, like type families. We're talking about first-class type-level functions that you can pass around.
I've been using Haskell for some twelve years and have internalized mapM and even still catch myself typing `liftM` sometimes. This doesn't make it the right choice. Internalize `traverse`, `fmap`, `&lt;$&gt;` etc. 
I often find myself using a coerced version on [`on`](http://hackage.haskell.org/package/base-4.11.1.0/docs/Data-Function.html#v:on): infixl 0 `upon` upon :: Coercible a b =&gt; (b -&gt; b -&gt; b) -&gt; (a -&gt; b) -&gt; (a -&gt; a -&gt; a) upon f _ = coerce f It's especially useful for writing instances for newtypes: newtype Max a = Max { getMax :: a } instance Ord a =&gt; Semigroup (Max a) where (&lt;&gt;) = max `upon` getMax It makes code using coercions a little bit more readable, like the operators from [Data.Profunctor.Unsafe](http://hackage.haskell.org/package/profunctors-5.2.2/docs/Data-Profunctor-Unsafe.html). My question is: does this exist already somewhere? I couldn't find it in lens (although maybe I just couldn't figure out the signatures), but it seems it would fit right in with `ala`, etc.
Is there any site that is an intersection of Goodreads and arxiv.org? I'd like to start tracking the white papers I read. I'm aware of arxiv-sanity.com, but that is missing the ratings and tracking of goodreads.
\(except if you have a \`Typeable\` constraint in your context\)
By the way I think you can get a nicer notation for this: (Morph $ \x -&gt; Morph $ \y -&gt; Morph $ \z -&gt; f x y z) Writing something like this: morph (\x y z -&gt; f x y z) (Or maybe just `morph f`) if you have a class with instances for function arrows and some base type…can’t quite figure out the specifics right now, but I’ve done something like this in the past when I wanted a convenient way to make fresh type variables in a typechecker, like: -- Class of types 'a' that can be converted to a 'Type' of kind 'k'. class ForAll a k where forAll :: a -&gt; TcM (Type k) -- A 'Type' of kind 'k' can be trivially converted to itself. instance ForAll (Type k) k where forAll = pure -- A function from a 'Type' of kind 'k1' -- to some type which can be converted to kind 'k2' -- can be converted to a 'Type' of kind 'k2' -- by supplying the input type with a fresh type variable of kind 'k1' -- given that 'k1' can be instantiated with a 'Fresh' type variable instance (ForAll a k2, Fresh k1) =&gt; ForAll (Type k1 -&gt; a) k2 where forAll f = do var &lt;- freshTyVar forAll (f var) So you could write this: -- (a × b) → a fstTy = forAll $ \ a b -&gt; FunTy (PairTy a b) a Instead of this: fstTy = do -- (a × b) → a a &lt;- freshTyVar b &lt;- freshTyVar pure $ FunTy (PairTy a b) c 
[removed]
Well, you can *add* those checks ofc.
More than 3 consonants in sequence is just too much. Specially for romance speaking people like me. 
That’s just because `K` and `S` have different types, because they’re tagged that way by the GADT. If you want to parse a string into a GADT for more type safety, the standard way to do it is to break down the problem into two steps: first parse it into a normal ADT, and then add a “typechecking” function that tries to convert the ADT to the GADT (if it’s type-correct). Lennart Augustsson did [a blog post in 2009](http://augustss.blogspot.com/2009/06/more-llvm-recently-someone-asked-me-on.html) about the general idea—the core of it is the function `typeCheckExp :: UExp -&gt; Maybe ATExp` in that article. In other words, you’d have: data UntypedTerm = UK | US | UInt Int | UApp UntypedTerm UntypedTerm data TypedTerm a where TK :: Term (a -&gt; b -&gt; a) TS :: Term ((a -&gt; b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c) TInt :: Int -&gt; Term Int TApp :: Term (a -&gt; b) -&gt; Term a -&gt; Term b data TermType a where TyInt :: TermType Int TyFun :: TermType a -&gt; TermType b -&gt; TermType (a -&gt; b) -- … -- With GADT syntax: data SomeTypedTerm where SomeTypedTerm :: TypedTerm a -&gt; TermType a -&gt; SomeTypedTerm -- Or with ExistentialTypes syntax: data SomeTypedTerm = forall a. SomeTypedTerm (TypedTerm a) (TermType a) And then define these functions separately, in the way described in that blog post: parse :: String -&gt; UntypedTerm typecheck :: UntypedTerm -&gt; Maybe SomeTypedTerm 
I liked the video very much. It's short, to the point, and there's a working exampled. That's perfect. To get a better rhythm you could try to write a detailed script of you video instead of making it up as you go. Even if you don't straight up read from the script nor memorize it. It will help you always have something to say ready in your mind.
Can't recommend exercism enough. When you get to the rotational-cipher exercise just know I made that exercise xD. It helps you learn modulo of a discreet set in your given language.
But nix still requires a cabal file doesn't it? So you are still using cabal at least somewhat. 
Yep, thanks!
Really appreciate your comments and suggestions about preparing a script. Thank you
Thank you for creating the contents. I learned about servant from you guys and I plan to create more based on what you have laid as foundation. From a learners point of view I think video tutorials can sometimes help by pinpointing the exact pain point during learning. Text and video together can make.the learning process more efficient and hopefully more enjoyable.
Thank you!
I used that with c++ or c I think before, I'll give it another go with haskell, thanks
My guess would be [IHaskell](https://github.com/gibiansky/IHaskell) + [EIN](https://github.com/millejoh/emacs-ipython-notebook). It's pretty awesome.
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://github.com/millejoh/emacs-ipython-notebook) - Previous text "EIN" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
Haskell doesn't have much in the way of game frameworks (although I did find a set of Godot engine bindings on github) but if you like making games, you might try making something with a textual interface, like hunt the wumpus, or hangman, or mastermind. Also, the OpenGL bindings are pretty solid, if you want to play around with making pretty pictures. If you want something higher-level, you may want to check out diagrams or gloss. Both are fun to just mess around with and see what you can make. Other than that, I'd recommend project Euler. Lots of little bite-sized programs to write (some bigger than others) with no danger of running out any time soon.
The post is [The constraint trick for instances](https://chrisdone.com/posts/haskell-constraint-trick) ([reddit discussion](https://www.reddit.com/r/haskell/comments/3afi3t/the_constraint_trick_for_instances/))
This probably doesn’t help you to know, but I think it’s so cool and I had to mention it: we’ve been using a version of this idea at work for the past couple months, discovered seemingly independently! I don’t mean to say that in a competitive way at all, by the way 🙂. This is the interesting part: I work as an iOS developer and we have this same exact idea implemented, as a monad, in Swift, to make our UI updates faster (if a change goes through our model layer and comes out `Clean`, we don’t bother touching the UI). I always wondered who else was using a `Writer` this way — I’d sort of puzzled it through myself a bit but figured it wasn’t so complex that others wouldn’t have discovered the same technique. That’s awesome that it’s also useful in the realm of compilers, though! 😊
Is there any sort of mapping of old concepts to new concepts like this anywhere? 
That's if you use the thing that parses cabal files and creates a derivation. You can write your own derivations directly though, and come up with a system based around that. The assumption of course is that with a larger project you're willing create more infrastructure. I think there's an unfilled niche for an "off the shelf" builder that you could use even with small projects. I'd give `pier` a go, it's new but seems interesting. And Neil has been talking about caching support in shake, so maybe it could evolve into a haskelly competitor to bazel.
&gt; This probably doesn’t help you to know I will add "UI updates" as a possible application when I make the next change, so it is definitely helpful 😄. &gt; discovered seemingly independently I think that's the thing great about Haskell (or more generally, a good type system). Often when you're writing code for your application, you think of it in specific terms (UI in your case, compilers in mine). However, if the type system is sufficiently powerful, then you will chance upon the right level of abstraction and recognize the generality of the solution.
The readme should probably be updated then, as the first paragraph says that it does use stack for creating projects.
Wait if you use nix and create a default.nix the cabal file is completely optional? But what about the modules list that tells GHC all the available modules, and the main\-is field, and the ghc\-options and so on? Also I'm not sure how you can do incremental building \(seems crucial for a large project\) without something like cabal new\-build, but I could definitely be wrong on that one.
I felt the same way about the last one, which is why I submitted to this time :).The next one is in November!
Yeah I was thinking the same on game engines. Thanks for recommending euler
Thanks; that makes sense. Would love to see a real example for this though. I mean, `StateT` is already, in effect, combining two monads, and `MonadState` allows us to combine them even further. At some point it'd get pretty complicated I imagine.
Cabal files aren't hardcoded into nix, it's just a library function which you can choose to not use. You put modules and flags and whatnot your nix expression. You get incremental builds at the package level. You could theoretically do derivations at the file level, but I haven't seen that working so I don't know if nix can handle many small derivations well. I'm used to being file-level parallel with shake, but cabal isn't file-level parallel either, so being distributed and globally cached with nix is already a big step up from cabal. I'm a complete nix beginner so I'm not the right person to answer authoritatively on these things, but that's how we do it at work.
Well, GHG is going to turn type errors into warnings with ` -fdefer-type-errors`. Evaluating such expressions will cause an exception at runtime then.
Here’s a good (albeit long) article which goes into the advantages of the “mtl style” using `MonadState`, `MonadReader`, &amp;c.: [example of why to use monads - what they can do](https://www.schoolofhaskell.com/school/to-infinity-and-beyond/pick-of-the-week/example-of-why-to-use-monads-what-they-can-do). TL;DR: you can enable new effects without changing any of your code except for the parts that actually *use* the new effects.
If I don't get module level incremental building it's going to be a huge step down in productivity, so that's kind of a hard requirement for me for big projects. 
A good way to start would be to look for a tool or a library you use yourself, and improve documentation. Sounds boring, but's incredibly important since the existence of up-to-date soft documentation and tutorials is necessary for any project to be considered alive and relevant. There is no excuse for this: if you know a tool or a library to some degree, you can contribute a documentation fix, a tutorial, or at least a cookbook entry. Writing good documentation is hard, and it forces the author to reflect deeply about the topic at hand, but because of this good documentation writers are appreciated deeply. Once you got an in-depth overview of the tool, you could ask on the issue tracker for easy tasks. Maybe there's already a filter or a tag for that. Also, most developers have always several ideas floating around through their heads, but reality forces them to prioritize and thus never follow up on most of them. It's really important you start with small tasks and well-defined goals, else you will get frustrated pretty quickly. Completing small tickets makes you familiar with source code management, using the project management tool and comunicating with your fellow developers. Also, you get insight into parts of the codebase. Another way to get started would be to start developing libs or small tools you can put to use by yourself. One never knows how useful those could be to somebody else. Also, at some point you will get around to use a library or a tool that is lacking or is not supported anymore. If you can spare the resources, this would be an opportunity to contribute. 
[under2](https://hackage.haskell.org/package/newtype-generics-0.5.3/docs/Control-Newtype-Generics.html#v:under2) from `newtype-generics`?
Excellent - thanks a ton for this! Highly unlikely I'll understand everything in there, but I'll keep coming back until I do.
Yes, `DefaultSignatures` plays that role. class Functor f where fmap :: (a -&gt; b) -&gt; f a -&gt; f b default fmap :: Monad f =&gt; (a -&gt; b) -&gt; f a -&gt; f b fmap f x = x &gt;&gt;= return . f class Applicative f where pure :: a -&gt; f a (&lt;*&gt;) :: f (a -&gt; b) -&gt; f a -&gt; f b default pure :: Monad f =&gt; a -&gt; f a pure = return default (&lt;*&gt;) :: Monad f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b (&lt;*&gt;) = ap I honestly don't know why this wasn't done at the same time we modified the `Functor`/`Applicative`/`Monad` hierarchy.
Purity can be understood completely without monads. Purity just means that the result of a computation only depends on its inputs, and that the only effect it has is returning a result. Monads are just an algebraic structure: a little more complex than monoids, but ultimately just a signature (a set of operations) and some laws. Many things can be made to look like monads; using them to define a DSL for I/O (conceptually, `IO` is nothing more than that) is just a very common use case. There are many monads, but apart from the monad laws, only their implementation actually tells what they represent. The open/closedness for Monads you describe is just an esoteric name for Abstract Data Types: you restrict entry points and hide implementation details. The only way to get around that is to commit type errors, and the type checker will stop you from doing so. This is also not specific to monads at all btw.
I'm always looking for contributors for taffybar: https://github.com/taffybar/taffybar I have a list of help wanted issues here: https://github.com/taffybar/taffybar/labels/help%20wanted And a gitter channel where I'm almost always responsive here: https://github.com/taffybar/taffybar/labels/help%20wanted Obviously probably only of interest if you are using linux with a tiling wm. It's a relatively easy project to work on, with lots of low hanging fruit as far as issues are concerned. 
Does anyone still use ghc-7.6 or older? I know that at least one person refuses to use newer ghcs that have `length ((),()) == 1`, but I thought 7.8 didn't have that problem.
Yay code duplication... The difficulty of sharing related constructors across data types is one of my least favorite parts of Haskell.
 instance Additive m =&gt; LeftModule () m doesn't exactly say that "anything that's `Additive` is a LeftModule with unit"; it says "everything is a `LeftModule` with unit, but type error if the thing isn't an `Additive`". It's a really broad constraint. If you want both instances, I think you're stuck with `IncoherentInstances`, or _maybe_ only `OverlappingInstances` if you never use `LeftModule () (Square ())`. IIRC, the only way out of this is to use a newtype wrapper, e.g. newtype SemiringModule x = SemiringModule x instance Semiring a =&gt; LeftModule (SemiringModule a) (Square (SemiringModule a))
Promoted data constructors have kinds of that form.
Yeah, I guess? I used to run into that problem a lot, but now I don’t really, and I dunno what changed—either I found workarounds that became internalised so I don’t notice them (“When I do it this way, it’s easier than whatever I was trying to do before.”) or I just don’t care because more safety is worth more effort to me in the long run, even if it involves effort that *feels* like duplication (I’m not sure that it always is). If you have an example at hand I’d like to think on it.
It happens to me more when I want something like a series of ast-to-ast transformations where each ast has slightly different invariants, but large parts of the structure are preserved. I _could_ reach for open recursion and functor coproducts with automated injections (a la Datatypes a la Carte)... or I could simplify but lose type safety. The latter is unfortunately the way I tend to go. Maybe I just don't understand Trees that Grow well enough that it's cheap enough in terms of complexity to be worth it.
Took a benchmark for making `insert` and `delete` a `foldr`. |current|foldr --|--|-- insert "wwwwwwwwwwwwwwww" |444.3 ns (410.1 ns .. 477.7 ns)|788.4 ns (745.1 ns .. 826.3 ns) insert "cheese" |321.7 ns (311.3 ns .. 335.1 ns)|360.1 ns (348.8 ns .. 375.9 ns) insert (replicate 200 'e')|3.600 μs (3.349 μs .. 3.894 μs)|5.384 μs (5.035 μs .. 5.781 μs) delete "wwwwwwwwwwwwwwww" |195.9 ns (186.1 ns .. 205.2 ns)|174.3 ns (171.8 ns .. 176.9 ns) delete "cheese" |290.5 ns (286.2 ns .. 294.7 ns)|310.0 ns (301.7 ns .. 320.6 ns) delete (replicate 200 'e')|153.9 ns (150.9 ns .. 157.3 ns)|169.9 ns (163.1 ns .. 178.4 ns) (Target TSet is built from `/usr/share/dict/american-english` file which contains about 100k words. so "wwwww..." do not exist in the set, "cheese" exists. Compiled with -O2.) In each `insert` case, `foldr` version is slower. This is understandable: in the current implementation, inserting `xs` to an empty subtree is shortcut to inserting `singleton xs`. `foldr` version didn't it. Winner for `delete` cases varied among several runs (I used my laptop), so I couldn't determine which is better. That's same for `delete (replicate 200 'e')` case which list fusions should help for `foldr` version.
Performance-wise, unfortunately fusion—especially in this case—can be fragile. It's worth looking at the actual core to see if it happens (with `-ddump-simpl`). Also, since you're building up a continuation, it's important to use [`oneShot`](https://ghc.haskell.org/trac/ghc/wiki/OneShot) where you can. That said, it's not hugely surprising that the list versions are quicker: the intermediate list itself probably isn't a major factor in the performance of the function overall.
[removed]
It would be better to have default `fmap = (&lt;*&gt;) . pure` with only an `Applicative` constraint.
Well, I just mentioned the version for completeness' sake.
I see. I’m not at a compiler right now so I can’t check this code, but a good (albeit heavyweight) solution I’ve seen—I dunno if it’s Trees that Grow or what—is to index an AST by its phase, and not only add annotations based on that phase (using a type family), but also enable and disable constructors based on the phase as well—something like this: data Phase = Parsed | Typed | Desugared data Expr (p :: Phase) = (HasInfix p ~ 'True) =&gt; Infix (Anno p) !InfixOp (Expr p) (Expr p) | Call (Anno p) !(Name p) [Expr p] | … type family HasInfix (p :: Phase) :: Bool where HasInfix 'Parsed = 'True HasInfix 'Typed = 'True HasInfix 'Desugared = 'False type family Anno (p :: Phase) :: * where Anno 'Parsed = () Anno 'Typed = Type Anno 'Desugared = Type -- And so on for different properties of the AST. While this enforces the right properties, unfortunately (last I checked) this results in spurious error messages where you get “non-exhausive patterns” if you don’t add a case, but a type error if you do. :/ So in practice I prefer to have multiple plain-ADT AST types, with fewer phases with differing invariants and more explicit parameters, and convert amongst them explicitly. If you have the privilege of designing your own language, and take some care, it’s a relatively small amount of boilerplate; for existing real-world languages this tends to be a bit “loose” though—lots of code that’s not necessarily hard to test but doesn’t actually *do* much. 
You can contribute to the `summoner` project: * https://github.com/kowainik/summoner It's easy to start implement anything in there, we don't have complicated monad transformers, and issues don't depend on each other so you can choose any straightaway and ask maintainers for details if something is unclear. Also we have couple more projects you can check. Besides, our organization is offering help for Haskell enthusiasts who would like to contribute to our projects, so if you're interested you can reach us out on xrom.xkov@gmail.com and we could give you more information.
If you are interested in making a Game, you might benefit from looking at the group game project I posted earlier. Even with the lack of established game engines, Haskell is very pleasurable to make games with. \[link\]\([https://www.reddit.com/r/haskell/comments/8jygjn/we\_made\_a\_game\_in\_haskell\_for\_our\_class\_project/?ref=share&amp;ref\_source=link](https://www.reddit.com/r/haskell/comments/8jygjn/we_made_a_game_in_haskell_for_our_class_project/?ref=share&amp;ref_source=link)\)
+1 for `ghc-exactprint`. I've used `haskell-src-exts` to write `importify` — tool to remove redundant imports. * https://github.com/serokell/importify I had a lot of troubles because `haskell-src-exts` actually can't parse everything... A lot of hacks and workarounds were required. It's not possible to finish `importify` with `haskell-src-exts`. Basically, GHC as a library is a way to go because you can't be better in parsing Haskell source code than GHC.
Good point, thank you! Fixed now :)
There’s probably still a couple of cases where the old functions are correct, in particular where the performance of bind is better than that of &gt;&gt;=, but unless you know that to be the case... stick with Applicative.
Well, strictly speaking I don’t care about the () instance, bit it’s in the library so I can’t do much about it. In any event, /u/kmett ‘s instance and my instance would do the exact same thing, so it doesn’t really matter which gets picked. Thanks for the new type approach. I don’t think it’s particularly attractive to me (who wants to newtype their coordinate system?) unfortunately. The new type thing is a 
/u/alphonse23 : A heads up: [the rewording has been done](https://en.wikibooks.org/wiki/Haskell/Understanding_monads/Maybe#Extracting_values); hopefully it is less confusing now. Once more, thanks!
Thanks.
That's kinda hard to read. Can it be split to two versions: english and mandarin?
Removed the mandarin part and will post it in another link.
Thanks!
By the way, can anyone tell me if there is there a more correct subreddit to post this?
/r/dependent_types
This essay seems too elementary for it lul
&gt; Nice write up! Thanks. &gt;You could expand the Binary tree example to have a function that traverses it to help people understand recursive types and their uses better. I wanted to just focus on ADTs in this post so as to not have the reader deal with the mechanics of tree traversal. There's however a post that I've been wanting to write for a while on trees ... someday :)
If you can do the *thing* with less, then prefer less requirements. Thus: * Prefer `traverse` to `mapM`. * Prefer `pure` to `return`. * Prefer `Applicative` to `Monad` whenever possible.
Usually it's better to write some command-line application in Haskell. Like directory bookmarks, CLI todo manager, terminal time-tracker. See tutorial regarding one of such applications here: * https://bollu.github.io/teleport/ Such applications are usually relatively easy to write. You don't need to know complicated things like monad transformers. Just some basic knowledge. And you also will learn how to separate pure code and code with side-effects (especially if somebody can guide you through code review how you can write code better). Haskell is much different from any other language (even some functional languages). It might be more difficult for beginner to write difficult and complicated application. But once you understand basics, you just need to learn more libraries and their API and you're good. If you want to work on some Haskell projects, our organization can offer mentorship to you :) For free. Just drop us line on xrom.xkov@gmail.com! 
Wow thanks for this, once I get better at Haskell I'll email you guys
Awesome thanks for the link
I've started keeping a bookmark folder of github pages with "Help Wanted" tags in their issue tracker. Then I choose how much time I have for open source contributions each week and spend it on one of those projects. I prefer smaller libraries where it's easier to understand the entire codebase.
&gt; [the library]‘s instance and my instance would do the exact same thing, so it doesn’t really matter which gets picked. This is exactly the use case for `IncoherentInstances`.
/r/logic
Here's a sneak peek of /r/logic using the [top posts](https://np.reddit.com/r/logic/top/?sort=top&amp;t=year) of the year! \#1: [just want to say](https://np.reddit.com/r/logic/comments/7iwxp4/just_want_to_say/) \#2: [Twelve things I love about philosophical logic](http://consequently.org/news/2017/twelve-things-i-love/) | [9 comments](https://np.reddit.com/r/logic/comments/6y5kch/twelve_things_i_love_about_philosophical_logic/) \#3: [Symbolic Logic – An Accessible Introduction to Serious Mathematical Logic](http://rocket.csusb.edu/~troy/SLmain.pdf) | [7 comments](https://np.reddit.com/r/logic/comments/8c1bar/symbolic_logic_an_accessible_introduction_to/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/7o7jnj/blacklist/)
Installing ghc\-mod and other tools globally is a bad idea, given that at least ghc\-mod is tied to GHC version. Proper way is to use \`\-\-copy\-compiler\-tool\` key and specify resolver. For example \`stack \-\-copy\-compiler\-tool \-\-resolver lts\-11.11 build ghc\-mod\` will install ghc\-mod on per\-ghc\-basis location \(in case of resolver\-11.11 this is ghc\-8.2.2\) so any projects that use same ghc version will be able to launch ghc\-mod via \`stack exec ghc\-mod\` There is a great article about tooling and some other things in modern haskell: [https://lexi\-lambda.github.io/blog/2018/02/10/an\-opinionated\-guide\-to\-haskell\-in\-2018/](https://lexi-lambda.github.io/blog/2018/02/10/an-opinionated-guide-to-haskell-in-2018/)
&gt; (last I checked) this results in spurious error messages where you get “non-exhausive patterns” if you don’t add a case, but a type error if you do Do you know about when you last checked? I vaguely remember that this was supposed to be improved. &gt; So in practice I prefer to have multiple plain-ADT AST types Yeah... And I understand, but I find it to be a sad fact about my favorite language. Between that and records, I really want row types.
Yep /u/rampion figured out a nice syntax for `Morph` which he built on top of an HList-like type: https://www.reddit.com/r/haskell/comments/78xxql/structures_of_arrays_functors_and_continuations/doy80ft/
&gt; The most simple data type we can construct in Haskell is a type with a single constructor [...] Actually, that's not quite right. You can build data types with no data constructors, e.g.: data Void 
Wrong sub? Try /r/purescript
Interesting read, especially the reflections on the adoption of functional programming in the software industry! I believe that there is a deeper meaning behind constructivism which ultimately leads to category theory (the Lambek part of Curry-Howard-Lambek). In the words from Goguen’s Categorical Manifesto: &gt; Indeed, many category theorists feel that the morphisms are more important than the objects, since they reveal what the structure really is. Moreover, the category concept can be defined using only morphisms. It is the bias of modern Western language and culture towards objects, rather than towards relationships, that assign precedence to objects over morphisms (see Maturana &amp; Varela, Tree of knowledge 1987 for some related discussion). 
If you end up enjoying writing command-line or terminal applications, you might also consider this library: https://github.com/jtdaugherty/brick
makes sense .. recursive datstypes are still very cool 
Sweet, are there some example programs from Brick?
Yes: https://github.com/jtdaugherty/brick#getting-started
The universal move-stuff-around idiom that works cross-language in any git environment if what I use. It's somewhat tedious, but not that annoying: ``` $ perl -pie 's/foo/bar/g' $(git grep -l foo) ```
&gt; I get a bunch of errors about mismatched packages Is it really a mismatched version, like this: hlint-2.1.5 from stack configuration does not match &lt;2.1 &amp;&amp; &gt;=2.0.8 (latest matching version is 2.0.15) Or is there _no_ specified version, like this? hlint must match &lt;2.1 &amp;&amp; &gt;=2.0.8, but the stack configuration has no specified version (latest matching version is 2.0.15) &gt; with the solution being to add extra-deps to my global stack This is definitely not what you want. Unlike with cabal-install, the intended workflow isn't to type `stack install &lt;package-name&gt;` and to let stack figure it out which versions of which dependencies you need to install. Instead, you need to tell stack exactly which version of all the dependencies you want. To make this easier, stackage provides a number of "resolvers", each of which pins a version number for a large number of packages. I always call `stack` from inside a folder containing a `stack.yaml` file, so I didn't even realize there was a global `stack.yaml` config. Mine specifies the resolver "ghc-7.8.4", which only specifies a version for ghc and a few core packages. If yours is similar, it is not surprising that stack cannot find a pinned version for any of the packages you try to install nor for any of its dependencies. You could do the work and manually specify the version you want for all those dependencies, but I wouldn't put those version numbers in your global `stack.yaml` file. Instead, for each binary you want to build, I would create a separate `stack.yaml` file which only pins the versions of the dependencies for this particular binary. This way, you will only have to solve the relatively small problem of finding compatible versions of all the dependencies of a single binary, you won't have to solve the harder problem of finding compatible versions of all the dependencies of all your binaries. Now that you have a separate `stack.yaml` per binary, you can make your life a lot simpler by picking a resolver which covers more dependencies than just the core packages. In particular, I see that [ghc-mod is included in lts-8.24](https://www.stackage.org/package/ghc-mod) and that [hindent is included in lts-11.11](https://www.stackage.org/package/hindent), so those are the resolvers I would use.
I usually just select the lines in question and send them through `sort` with `v10j:!sort` in vim or whatever. The 'qualified' keyword mucks that uo a bit, but one can clean up the rest.
Wrote this post because figuring out a nice breadth-first traversal has been a problem that’s stuck in my head for a while now. I’d be interested to see if anyone has a better algorithm, especially a queue-based one that avoids multiple passes.
Unrelated: appreciate that your website loads instantly, no wasting time with loading bs.
There's a lot to be said for dumb html! Now, if I could just figure out how to get it to display properly on mobile...
CSS with media queries is probably the easiest way. Just change to a different layout when screen width is less than X pixels. Then you don't need to worry about writing your theme to be responsive. Modifying the margins and making sure the code tags inherit your paragraph font size should get you most of the way there :)
Thanks, this fixed it for me as well.
Check [my `tree-traversals` package](https://hackage.haskell.org/package/tree-traversals)
Indeed, we could define everything in terms of `Category`. class Category (cat :: k -&gt; k -&gt; Type) where id :: cat a a (.) :: cat b c -&gt; cat a b -&gt; cat a c --- Every monoid is a one-object category, where every element of the monoid corresponds to a morphism. newtype MonoidCat (m :: Type) (a :: ()) (b :: ()) = MonoidCat { unMonoidCat :: m } -- Monoid is now a "class synonym" for (Category . MonoidCat) class Category (MonoidCat m) =&gt; Monoid m instance Category (MonoidCat m) =&gt; Monoid m -- Its methods become regular functions mempty :: Monoid m =&gt; m mempty = unMonoidCat id mappend :: Monoid m =&gt; m -&gt; m -&gt; m mappend x1 x2 = unMonoidCat (MonoidCat x1 . MonoidCat x2) Defining a `Monoid` instance now amounts to a `Category (MonoidCat _)` instance (with `FlexibleInstances`). It is syntactically heavier; there could be sugar to address that, but then the result might not be that different from a separate `Monoid` type class. Perhaps a more lightweight idea is to only witness the isomorphism between monoids and one-object categories with a pair of newtypes. newtype MonoidCat m (a :: ()) (b :: ()) = MonoidCat { unMonoidCat :: m } newtype CatMonoid cat = CatMonoid { unCatMonoid :: cat () () } instance Monoid m =&gt; Category (MonoidCat m) where ... instance Category cat =&gt; Monoid (CatMonoid cat) where ... -- such that Monoid m is equivalent to Monoid (CatMonoid (MonoidCat m)) -- and Category cat is equivalent to Category (MonoidCat (CatMonoid cat)) --- And `Alternative` defines a family of monoids, and that can be expressed as follows using the upcoming QuantifiedConstraints extension: class (forall a. Monoid (f a)) =&gt; Alternative f instance (forall a. Monoid (f a)) =&gt; Alternative f empty :: Alternative f =&gt; f a empty = mempty (&lt;|&gt;) :: Alternative f =&gt; f a -&gt; f a -&gt; f a (&lt;|&gt;) = mappend Why even bother having another class at this point? One difference that was omitted is that `Applicative` is currently a superclass of `Alternative`, and we could thus also require additional laws on top of the definition of a monoid that would make `Alternative` more meaningful than a higher-kinded `Monoid` (but it may be difficult to retroactively add any such requirement).
Not reflected in the Haskell code, they all have different (but related) laws. Also note that the signature of `(.)` does not just differ in kind from `(&lt;|&gt;)` and `mappend`, because the two arguments and the result are not all the same type. If you could restrict the type arguments of `id` and `(.)`, then you could express monoids as exactly those categories with a single object (`a`). 
or just `fmap = liftA`
The odd one out in this case is Category. Whereas Monoid and Alternative work with a fixed type, for categories this is parametrised: {-# LANGUAGE GADTs, DataKinds, PolyKinds #-} class Category (cat :: k -&gt; k -&gt; *) where id :: cat a a (.) :: cat b c -&gt; cat a b -&gt; cat a c Here we are parametrising over the kind `k`: we require the type variables `a`, `b` and `c` to be of kind `k`. This is a more general version of your definition (where we are parametrising over all Haskell types). You can then recover the other structures by specialising this parameter to the singleton kind `()`, which amounts to removing the parameter entirely. Unfortunately we have to do a bit of faffing to pass between the equivalent types `() -&gt; () -&gt; t` and `t`. newtype M m a b = M m instance (Monoid m =&gt; Category (M m :: () -&gt; () -&gt; *)) where id = M mempty (M a) . (M b) = M (a `mappend` b) newtype F f x a b = F (f x) instance (Alternative f =&gt; Category (F f x :: () -&gt; () -&gt; *)) where id = F empty (F a) . (F b) = F (a &lt;|&gt; b) You can also go back: newtype Cat (cat :: () -&gt; () -&gt; *) where Cat :: cat '() '() -&gt; Cat cat instance Category (cat :: () -&gt; () -&gt; *) =&gt; Monoid (Cat cat) where mempty = Cat id Cat a `mappend` Cat b = Cat (a . b) In mathematics, you usually think of a category as given by a set of dots (the objects, here parametrised by the kind `k`), and arrows between those dots that you can compose. A monoid can be thought of as a category with a single object: you don't need to worry about whether domain/codomain of arrows are compatible in order to compose, as there's only one domain/codomain.
The [xml-conduit](http://hackage.haskell.org/package/xml-conduit) package is probably a good bet.
You can technically do it in one pass but you will get terrible error messages because parsing order and type checking order usually don't get along. Parsing into GADTs to enforce type correctness forces you to typecheck the parsed data but if you do this for type correctness you would need to do so anyway.
It would be nice to have examples of arbitrary backward compatibility, via version numbers or whatever else. Default values for added fields is nice, but of course many changes won't be so convenient! Also some kind of size and speed comparison with binary/cereal and serialise would be nice. I also wouldn't call `binary` compact. It's probably because it uses fixed-sized integral types, so the files wind up being mostly 0s. However, a trip through gzip easily solves that problem. Does winery use variable length integers?
I was unable to get tagsoup to compile using stack. I have started with xml-conduit. What is best tutorial?
Oh, I'm happy to see that people are aware of `newtype-generics`! :) In this case we want `over2` though: newtype Max a = Max a deriving (Show, Generic, Newtype) instance Ord a =&gt; Semigroup (Max a) where (&lt;&gt;) = over2 Max max
Wonderful, I spent a bit of time aiming for graph traversal lambda calc, this is very welcomed
This one from the [Yesod book](https://www.yesodweb.com/book/xml) seems good.
I am now using it. Thnx
That's really cool! It makes the breadth-first code very short: breadthFirst c = runPhasesForwards . go where go (x:&lt;xs) = liftA2 (:&lt;) (now (c x)) (delay (traverse go xs)) Unfortunately, I can't figure out how to get it to run quickly. Maybe there's some transformation like the one in [Control.Applicative.Free.Fast](http://hackage.haskell.org/package/free-5.0.2/docs/Control-Applicative-Free-Fast.html)?
fyi that’s also in the package as `levelorder`
I discovered the {\-# INCOHERENT #\-} pragma, which solved the problem. But boy, is it ugly. I don't think I'd mind as much if I could have a pragma that literally said "Don't consider this instance in these particular cases". Then if the open world changes, your code would fail to compile, rather than just do weird things at runtime.
For first-class type-level functions, you might find [this post on defunctionalization](https://typesandkinds.wordpress.com/2013/04/01/defunctionalization-for-the-win/) by Richard Eisenberg interesting.
Thanks very much for the pointers! I'll take a proper look. From a brief look, I can see you've put a lot of effort into `quickcheck-state-machine` and have some nice looking documentation. As for making something reusable from what we're doing, I think we'll wait 'til we have at least two examples of this pattern before we either look for an existing library that might suite it, or abstract the pattern ourselves to make a reusable library. Given the projects underway we should have several examples in the next few months. And in fact we will have someone from QuiviQ reviewing the tests, so we may be able to get some input there.
http://hledger.org loves new contributors. And it is a practical end-user application where your changes might help you get rich! :-) 
Would you be willing to provide pointers for how to get started writing a beam/postgis integration?
You could try adding an "`a` is distinct from unit" constraint to the instance; it wouldn't help instance resolution, but it would error if your instance would get chosen. There are various ways to do something like that, and the way that I'm thinking of off the top of my head relies on closed type families: type family NotUnit a where NotUnit () = 'False NotUnit a = 'True instance (NotUnit a ~ 'True, Semiring a) =&gt; LeftModule a (Square a) where ... I don't know how well it would work in practice. You might be able to find out more by looking [here](https://kseo.github.io/posts/2017-02-05-avoid-overlapping-instances-with-closed-type-families.html) and following links. Good luck.
I don't know if this is any good, but this enumerates a binary tree of integers in one pass: data Bin = Bin Bin Bin | Leaf Int deriving Show bfe :: Bin -&gt; [[Int]] bfe t = bfe' t [] where bfe' :: Bin -&gt; [[Int]] -&gt; [[Int]] bfe' b [] = bfe' b [[]] bfe' (Bin l r) (xs:xss) = let xss' = bfe' r xss xss'' = bfe' l xss' in xs:xss'' bfe' (Leaf x) (xs:xss) = (x:xs):xss
FWIW, [hlint](http://hackage.haskell.org/package/hlint) hints about those, among other things.
Alternative has extra laws on how it interoperates with Applicative. (Unfortunately, nobody agrees on what those laws are, so there are 2-3 competing sets.) As for Monoid being expressed through Category. In category theory a monoid is just a category with only one object.
Hmm... I've seen some warnings like that from hlint but it doesn't seem to complain about `mapM` for example, since I just created a file with this function and it had no hints: foo :: IO () foo = void . mapM print $ [1..5] 
I have reimplemented the `newtype-generics` API in terms of `Coercible` at https://github.com/sjakobi/coercible-utils/blob/master/src/CoercibleUtils.hs. I've never much liked the `under*` and `over*` names, so I wouldn't mind adding `upon` and maybe other variants. I could publish it on Hackage if you're interested in using it…
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [sjakobi/coercible-utils/.../**CoercibleUtils.hs** (master → 460ba12)](https://github.com/sjakobi/coercible-utils/blob/460ba128edb22806daf9e9331e3f54db77afe3b5/src/CoercibleUtils.hs) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply e02csjy.)
How are you measuring performance?
these are small enough and sufficiently overlapping communities / interests. im ok with xposting.
I have the benchmarks [here](https://github.com/oisdk/bfs).
Very neat! 
I dunno but [I just tried an example](https://gist.github.com/evincarofautumn/20882678953c53d7b370773623dfd9dc) with GHC 8.2.2 (Stack: lts-11.11) and it appears to work just fine—no spurious error messages, and still correctly rejects invalid cases. Maybe I’ll actually take advantage of this technique now. You still have to explicitly convert the types of “irrelevant” cases (e.g. `Lit type_ n -&gt; Lit type_ n`)—I dunno how well these constrained constructors would play with lenses or generic traversal libraries like `syb` to avoid that.
I would use a wrapping`data` so that the type variables aren't ambiguous. type family HKD :: (* -&gt; *) -&gt; * newtype HKD' f a = HKD' (HKD f a) class toJSONHKD f where toJSONHKD :: (a -&gt; Value) -&gt; HKD' f a -&gt; HKD' f a instance ToJSONHKD f =&gt; ToJSON (User f) where toJSON (User nm bd) = let HKD' nmV = toJSONHKD toJSON (HKD' nm) HKD' bdV = toJSONHKD toJSON (HKD' bd) in object [ "name" .= nmV, "birthdate" .= bdV ] Or something like that. You may need to do some type golf to get GHC to be happy to accept that. You could wrap all this up using the various typeclasses /u/benjaminhodgson mentioned in his post.
I hate to be a one-trick pony, but it's a useful technique :)
Yes, I'd be happy to help! There's a mailing list and IRC channel that I'm usually on during the week. I started a bit on an OGC SQL integration, but it's not complete yet. You could start there, or from scratch. I'll admit I'm not super knowledgeable on GIS systems, so I don't have much domain knowledge, but I can help with the beam type classes, and such.
Question: Is it possible to have a type inhabited with proofs a statement is true, and also posses a proof of contradiction?
Nice! &gt; I dunno how well these constrained constructors would play with lenses or generic traversal libraries I have not found a generic programming implementation that works with non-trivial GADTs. I'd be ecstatic if you happened to know of one.
You can fix this with `:sort /import\( qualified\)\?` (easiest to assign that to a binding!)
Good trick
Might want to learn Aeson before Servant.
Ah, of course, that certainly qualifies!
No. If for any proposition you had P /\ ~P, all propositions immediately become trivially provable and your logic is broken. It's called the principle of explosion or ex falso quodlibet.
This is the definition of inconsistency.
Here is a parsec wrapper over hexpat : [here](https://gist.github.com/bartavelle/4593a47a3f93db9d2d7d32093a6097e1). No comments and ugly code, but I found using it much easier and faster than the other alternatives. It should also be lazy enough.
Hum, now that I look at it, it might be hard to use without any documentation :)
out of topic, but if I may ask, how is the CS master at NTHU university, any idea about the acceptance rate?
How come it did not compile with stack? Are you using any of the stackage snapshots listed [here](https://www.stackage.org/package/tagsoup/snapshots)?
On the other hand, the code blocks are not displayed in a mono-spaced font on my machine.
The problem doesn't show up with a single linear hierarchy, but it gets to be a bit more painful when all of, say, Applicative, Monad, Comonad, and Traversable... want to fill in the superclass definitions for Functor via liftA, liftM, liftW, fmapDefault... In that case, the instance is uniquely determined, so they can't get it wrong, but for other classes, there are all sorts of consistency checks to make to ensure that you can fill in the right superclass bits. `DefaultSignatures` lets you handle the linear class chain case today, so long as you're willing to define all of them in one place and anticipate the need. `DerivingVia` lets you cut the boilerplate down a bit, and there have been several superclass defaulting proposals, but they all have different problems.
/u/snoyjerk
No idea, and I don't think it's a good idea to come to Taiwan to learn this kind of stuff ...
poor snoyman :\(
Is it uncompressed plain XML? You could try memory mapping it and reading it with xeno: https://github.com/ocramz/xeno/issues/18#issuecomment-388039389 unhammer said xeno takes 4 seconds to walk through his 1GB file and mawk takes 1.2s. It depends on the contents of course, lots of tags is slower than lots of text. 
Nice example of using GitHub API library in Haskell! Maybe useful after announcement that Microsoft bought GitHub. But for me looks like too much code for googlable bash one\-liner: $ GHUSER=MyUserName; curl "[https://api.github.com/users/$GHUSER/repos?per\_page=100](https://api.github.com/users/$GHUSER/repos?per_page=100)" | grep \-o 'git@\[\^"\]\*' | xargs \-n1 git clone
Is there any advantages in such approach? For example I assume some functions like `fold` could word for any Category and no just Monoids.
Typing would be the main issue. The fact that a morphism's end points can have different types means we need more elaborate data structures to hold them so we can fold them. It seems `Monoid` is at a sweet spot in that respect. Another issue is to get through the `MonoidCat` newtype, which makes me think Haskell's flavor of overloading is not very well suited to this kind of generalization.
cc: /u/fumieval 
I wrote a blog post about this a few years ago, except that I mentioned MonadPlus instead of Alternative. No meaningful conclusions, just basically posing the same question with a little more elaboration. https://unknownparallel.wordpress.com/2014/08/11/similarities-monoid-monadplus-category/
Is there a reason not to turn on `StrictData` for a new project as a default? I haven't ever seen it used when browsing other people's code, but do see recommendations to insert `!` for all fields in `data` types. Is the lack of extension use simply because it's such a recent addition?
There are one or two open issues in `containers` about breadth-first traversals. The performance of the monadic ones seems particularly tricky to reason about. Perhaps you could have a look? Even if we can't improve performance, I'd very much like to remove the dependence of `Data.Tree` on `Data.Sequence`. The former is used by GHC, and the latter takes a long time to compile.
RemindeMe! 3 months HCAR notification (like I did in [the other thread](https://pay.reddit.com/r/haskell/comments/8jrlyx/haskell_comunnities_and_activities_report_34_has/) too)
RemindMe! 3 months HCAR notification (like I did in [the other thread](https://pay.reddit.com/r/haskell/comments/8jrlyx/haskell_comunnities_and_activities_report_34_has/) too)
I will be messaging you on [**2018-09-04 13:33:55 UTC**](http://www.wolframalpha.com/input/?i=2018-09-04 13:33:55 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/haskell/comments/8nnkba/haskell_communities_and_activities_report_may_2018/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/haskell/comments/8nnkba/haskell_communities_and_activities_report_may_2018/]%0A%0ARemindMe! 3 months HCAR notification) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
Would it make sense to have typeclass like Alternative but without Applicative restriction? &gt;There is a deep way in category theory which Monoid, Applicative and Monad are all the same thing for a sufficiently general notion of a "monoid object". Is there any language or package that had been expressed it?
http://hackage.haskell.org/package/semigroupoids-5.2.2/docs/Data-Functor-Plus.html 
Do you think there's a fundamental limitation keeping us from having a good superclass defaulting strategy? Is it more a matter of "we just haven't found the right trade-offs yet"?
From a conceptual stand-point, the big idea as I understand it is that the amount of `lift`ing that you have to do in order to embed computation in the inner monad to the monad transformer is completely determined by your monadic stack. The problem, then, is that if you change your monadic stack, you have to change how much you `lift` everywhere. So `mtl` solves this problem by using typeclass to infer the amount of lifting that needs to get done. That way, if you change your monadic stack, you don't have to change the amount of lifting that you do. In fact, mtls use of functional dependencies means that you don't do any lifting at all - it is inferred for you by the compiler. The downside to this is that mtl will always use the first instance that matches. So if your monadic stack is made up of two state monads, and you use `get`, it will always "choose" the first instance. Sorry, I can't explain this part any better than that.
I'm not sure about this specific tool, but I have another that also uses your username and a github token. This way I can fork, mirror pull requests, etc repositories from the command line. This includes private repositories.
To add to this, I have only read Real World Haskell sporadically because I worry that, as a beginner, I won't recognize what is still best practice and what is outdated. Thankfully, [there is an answer on StackOverflow](https://www.reddit.com/r/haskell/comments/8ksmq5/real_world_haskell/dza77a3/) that seems to do a good job of enumerating what parts of Real World Haskell. (That link is to a similar discussion on Reddit). Real World Haskell is really good, and now that I know theres a list of "here is what is outdated", I want to read it cover to cover. 
A lot of my current attention is devoted to the question of "how do you actually build a language that is good at this." Haskell is rather bad at dealing with deep accurate class hierarchies. It feels rather fundamental, in that I don't know how to reach a perfectly painless solution within the confines of the Haskell we have. If it's going to take 5 years to put in each superclass as we discover we need it, it behooves me to give equal time to trying to evolving a language where I never have to fight those battles.
Looks like what \`hub\` does \(though, not sure it can everything, I only used it for creating repositories, but should be capable of more\): * [https://hub.github.com/](https://hub.github.com/)
It looks like it is capable of a larger but not entirely overlapping set of operations. I'm not sure I like that it basically steals the `git` command though.
I folks. I want to get a better idea of how competent Haskellers read a type signature and a (new)type declaration. To make things concrete, let's use the [AForm](https://www.stackage.org/haddock/lts-11.11/yesod-form-1.6.1/Yesod-Form-Types.html#t:AForm) from Yesod. Let's pretend you haven't seen the declaration of `AForm`. What conclusion do you draw when you a value whose type signature `AForm IO Person`? (Note that I just picked those type constructors at random). The only conclusion that I can read from that is that `AForm` is a type constructor that must be applied to two type constructors / constants to yield a type constant. Now, the declaration of `AForm`: ```haskell newtype AForm (m :: * -&gt; *) a = AForm {unAForm :: (HandlerSite m, [Text]) -&gt; Maybe (Env, FileEnv) -&gt; Ints -&gt; m (FormResult a, [FieldView (HandlerSite m)] -&gt; [FieldView (HandlerSite m)], Ints, Enctype)} ``` What conclusions do you draw from this? I can conclude that `AForm` is a type constructor that must be applied to a type constructor of kind `* -&gt; *` and a type constant in order to yield another type. I can conclude that `m` has the kind `* -&gt; *` both because of the GHCI output, but also because `-&gt;` has the kind `* -&gt; *`, which means that `m (FormResult a, [FieldView (HandlerSite m)] -&gt; [FieldView (HandlerSite m)], Ints, Enctype) :: *`, which means that `m :: * -&gt; *`. Furthermore, `HandlerSite m :: *`, `FormResult :: * -&gt; *`, and `a :: *`. The reason why I enumerated what I can conclude from this is that, as I understand it, to be a competent Haskeller I need to be able to understand a type signature. However, aside from the kinds of different type constructors, I can't really conclude much. Granted, this is an unrealistic example - in real code, we'd pair this with other information / context. Still, am I gleaning what I need to be gleaning from this type signature, or am I missing something? 
Hi everyone. I am building a web app that will log into a website, scrap some metadata, and then save a PDF of the webpage using the print dialog. I am using [webdriver](https://www.stackage.org/lts-11.11/package/webdriver-0.8.5) to do this. `webdriver` is a Haskell client for selenium, which (correctly, I think) considers the [print dialog](https://github.com/seleniumhq/selenium-google-code-issue-archive/issues/1815) to be out of scope for the project. What are my options here? I want to save a PDF as faithfully as possible to what the browser is displaying. 
Don't avoid reading RWH if you're new to the language. It's age is not some silly brain poison that will fill your head with bad ideas. There will be sections with examples that don't compile under modern GHC, and that can be more trouble to fix than it's worth. Other than that it works just fine for what it is: An introductory text to teach you how to navigate Haskell as a language and get things done. The only part I think is possibly harmful to future understanding is the stuff about monad transformers, but comparing any more modern code to those examples makes it fairly clear things are different now, so I don't see this as a real problem.
Thanks - that's exactly what I could infer from the explanation by /u/evincarofautumn, as well as [this](https://stackoverflow.com/questions/43438875/confusion-about-statet-state-and-monadstate) SO post. What I could not understand is how exactly it works. The example that /u/evincarofautumn pointed to is great but slightly complicated, and actually never explains what is it about the State monad, for example, that let's you nest it however you like but still be able to use the get/set functions without unnecessary lifting. I found [this](http://web.cecs.pdx.edu/~mpj/pubs/springschool95.pdf) paper on the page for `Control.Monad.State.Lazy`, but as with all academic papers, it's a heavy read.
It augments it, and it is entirely up to you.
Nope. Because data structures in Haskell are "persistent", due to purity. Remember that `String`s are lists. Now, consider the following program (in a `do`-block): let j = "abcd" let k = j ++ "efg" Now, you would expect the value of `j` to not change when `k` is created, right? In order to make sure `j` remains constant, the compiler has to copy all the elements in `j`, before appending "efg" to give `k`. Ergo, list concatenation is linear in the left of the left list, as all the left's elements have to be duplicated, to overcome pointer aliasing. Prepending an element is obviously a trivial case of this, where the left-hand list is only one element long, and so will be done in constant time (without any copying, actually, just the creation of a single cons cell). 
`AForm (m :: * -&gt; *) (a :: *)` strongly suggests it is a monad transformer, thanks to both the names and kinds of the variables, and of course the instance list confirms that. So familiarity with monad transformers helps to understand that type. Most transformers are usually isomorphic to some combination of the standard ones in `transformers`. In particular, this `newtype` wraps a function of three parameters, they indicate either "state" or "reader" effects. The "result type" `a` (i.e., the last parameter of `AForm`) is wrapped in `FormResult`, which is probably some error-handling monad like `Either` or `Maybe`, which itself is part of a tuple, which indicate either "state" or "writer" effects. If a type is both a function parameter and a component of the tuple, that is likely to be a state effect, in this case there's `Ints`. And we can confirm that with a look at the `Applicative` instance (or `Monad` if it exists): In the definition of `(&lt;*&gt;)`, `mr` and `env` are being passed to both arguments of `(&lt;*&gt;)` (`f` and `g`), like `ReaderT`. `ints` is being threaded through (as `ints'` then `ints''`), like `StateT`. The second and fourth components of the returned tuple are constructed with monoidal operations (`(.)` and `mappend`).
Wonderful suggestion. Thank you!
I've looked at the `unfoldM_BF` functions a little before, and I can't really figure out a better way than the ones already suggested. That said, I'm almost certain that `Data.Sequence` is unnecessary. I'll take a longer look today or tomorrow!
I test tagsoup with Stack, and it's in Stackage, so it should just work. Reports to the contrary are most appreciated. 
Do you want to test the path of your users saving the page as a PDF, or would saving a screenshot of the page be sufficient?
The types `Either` and `(,)` have kind `* -&gt; (* -&gt; *)`, so `A` is `*` and `B` is `* -&gt; *`.
it's easier to see its linearity when you write it as f b v = (if b then g else h) v or f b = if b then g else h
This clearly belongs to commandlinefu.com . 
Hello /u/rampion - I am not sure what you mean when you say if I want to test the path of the users saving the page as a PDF. To answer your second question - I don't think a screenshot would suffice because there might be important information that you have to scroll in order to get to. (I wonder, though, if such a case would actually come up often).
Formatting, my dude. But try compiling with `-O2`.
Reddit uses markdown syntax, which differs from slack's. In particular, the syntax for displaying a block of code is to indent the block by four spaces, like this: here is my amazing code: int main() { printf("hello world\n"); } Not to wrap them with three backticks like this: here is my amazing code: ``` int main() { printf("hello world\n"); } ```
 #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;math.h&gt; #include &lt;assert.h&gt; long leftAppend(long k, long n) { if (n &lt; 10) return n + k * 10; if (n &lt; 100) return n + k * 100; if (n &lt; 1000) return n + k * 1000; if (n &lt; 10000) return n + k * 10000; if (n &lt; 100000) return n + k * 100000; if (n &lt; 1000000) return n + k * 1000000; if (n &lt; 10000000) return n + k * 10000000; if (n &lt; 100000000) return n + k * 100000000; if (n &lt; 1000000000) return n + k * 1000000000; } long isOuroboros(long k, long n) { long rest = n / 10; long tens = n % 10; return leftAppend(tens, rest) == n * k; } long firstOuroboros(long k, long start, long end) { for (long n = start; n &lt; end; ++n) { if (isOuroboros(k, n)) { return n; } } return -1; } int main() { printf("%li\n", firstOuroboros(4, 1, 100000000)); printf("%li\n", firstOuroboros(5, 1, 100000000)); printf("%li\n", firstOuroboros(6, 1, 1000000000)); return 0; } --- module Main (main) where import Data.Maybe (listToMaybe) leftAppend :: Int -&gt; Int -&gt; Int leftAppend k n | n &lt; 10 = n + k * 10 | n &lt; 100 = n + k * 100 | n &lt; 1000 = n + k * 1000 | n &lt; 10000 = n + k * 10000 | n &lt; 100000 = n + k * 100000 | n &lt; 1000000 = n + k * 1000000 | n &lt; 10000000 = n + k * 10000000 | n &lt; 100000000 = n + k * 100000000 | n &lt; 1000000000 = n + k * 1000000000 {-# INLINE leftAppend #-} isOuroboros :: Int -&gt; Int -&gt; Bool isOuroboros k n = let (rest, tens) = n `quotRem` 10 rotated = leftAppend tens rest in n * k == rotated {-# INLINE isOuroboros #-} firstOuroboros :: Int -&gt; Int -&gt; Int -&gt; Maybe Int firstOuroboros k start end = listToMaybe os where os = filter (isOuroboros k) [start..end] main :: IO () main = do print $ firstOuroboros 4 1 100000000 print $ firstOuroboros 5 1 100000000 print $ firstOuroboros 6 1 1000000000
How does this handle private repos? Does it depend on your login state?
I had an old version of stack. Upgrading fixed it. Thank you ndmitchell for prompt response to my email to him.
You could use [saveScreenshot](https://hackage.haskell.org/package/webdriver-0.8.5/docs/Test-WebDriver-Commands.html) function to save a screenshot of what the browser sees. The problem is that the print dialog is operating system dependent and is not Incorporated into the browser so it can't be controlled by selenium.
By "test the path..." I meant "Is this test intended to verify that users can convert the page to a PDF?" If you just want to test how the page looks, a screenshot is easy, even if it just captures the viewport. You can tell selenium to scroll and capture multiple screenshots, and I think there's plugins that can automate that for you.
If I don't see a ! in a data type I am 100% going to assume its lazy and not go look for a StrictData program since it's so unused. In general in Haskell I assume maximum laziness unless given evidence or reason otherwise, for that reason I think StrictData should not be used and ! should be used when desired. It's also worth noting that there are definitely plenty of situations where ! is not what you want. 
Infinite structures seem like the less common use case to me. So I think on the contrary that strict-by-default would have made it easier to signal when something subtle is going on. But it seem this ship has sailed already.
At the very least, we could use a different (simpler) queue.
Total tangent, but I'd go with GitHub as the markdown flavor reference for triple-backtick behavior. Slack's formatting is... markdown-adjacent, but broken in very basic ways; incorrect emphasis behavior, no escaping, etc.
That's only one example. There are also just cases where it has better performance. Also any knot tying can easily break in the presence of strict fields. Plus it just breaks expectations, the default expectation in Haskell is that things are lazy, particularly if you don't see a prime or a !
TIL! I'm always indenting my code blocks with four spaces in github, I didn't realize it supported both formats.
Thanks. I guess the fancy editor doesn't work as advertised. 
I'm currently trying to improve at working with the StateT monad transformer \(and really monads in general\), so I made a simple Hangman game. If anyone would comment on my code and what can be improved for more clarity and conciseness, it would be greatly appreciated. Thanks! \(Sorry if the code is a little long for this thread\) import System.Random import System.IO import Control.Monad.State.Lazy import Data.HashSet import Control.Lens import Data.Char data Game = Game { _phrase :: String , _lives :: Integer , _guessed :: HashSet Char } instance Show Game where show g = "LIVES: " ++ (show $ _lives g) ++ "\n" ++ fmap (\c -&gt; if member c $ _guessed g then c else '_') (_phrase g) makeLenses ''Game preGuessed :: HashSet Char preGuessed = fromList [' ', '-'] data Status = Won | Lost | InProgress statusGame :: Game -&gt; Status statusGame g | all (flip member $ _guessed g) (_phrase g) = Won | _lives g == 0 = Lost | otherwise = InProgress guessAttempts :: StateT Game IO () guessAttempts = do game &lt;- get lift $ print game &gt;&gt; putStr "GUESS: " &gt;&gt; hFlush stdout guess_ln &lt;- lift getLine let guess = toLower $ guess_ln !! 0 if member guess $ _guessed game then do lift $ putStrLn $ "You already guessed '" ++ [guess] ++ "'. Try again!\n" guessAttempts else do modify $ over guessed (insert guess) if elem guess $ _phrase game then do lift $ putStrLn $ "'" ++ [guess] ++ "' is in the phrase!\n" else do lift $ putStrLn $ "Sorry, '" ++ [guess] ++ "' isn't in the phrase.\n" modify $ over lives (\n -&gt; n-1) game &lt;- get case statusGame game of Won -&gt; lift $ putStrLn $ "You win!\n" ++ (_phrase game) Lost -&gt; lift $ putStrLn $ "You lose!\n" ++ (_phrase game) InProgress -&gt; guessAttempts main :: IO () main = do all_phrases &lt;- lines &lt;$&gt; readFile "src/words.txt" one_phrase &lt;- (all_phrases !!) &lt;$&gt; randomRIO (0, length all_phrases) evalStateT guessAttempts (Game one_phrase 7 preGuessed)
Yep. I'm used to GitHub. My bad. The fancy editor on Reddit web seems to handle the backticks by rewriting it with indents, but somehow it didn't work here.
I believe this is what Edward's `hask` library on Github does where everything is done in a kind-polymorphic way: https://github.com/ekmett/hask For example, it defines a kind-polymorphic variation on `Functor` such that you can have multiple instances for the same type constructor depending on how saturated it is: https://github.com/ekmett/hask/blob/master/src/Hask/Category/Polynomial.hs#L103-L113 data Unit a b = Unit instance Functor Unit where ... instance Functor (Unit a) where I believe the main downside of doing things this way is that type inference suffers and some things might require an explicit type annotation to work
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [ekmett/hask/.../**Polynomial.hs#L103-L113** (master → cd4d30e)](https://github.com/ekmett/hask/blob/cd4d30e7911dd7cc2da78383fd833272b1ff9303/src/Hask/Category/Polynomial.hs#L103-L113) ---- 
Meanwhile, I want less symmetrical pattern synonyms. =) pattern JSON :: (FromJSON a, ToJSON a, AsJSON t) =&gt; () =&gt; a -&gt; t pattern JSON a &lt;- (preview _JSON -&gt; Just a) where JSON a = _JSON # a is less useful than the equivalent `fromJSON` and `toJSON` functions as you need to supply instances of classes you aren't using to match or inject with the pattern synonym. This means that when I supply pattern synonyms I usually have to supply the normal versions of things _anyways_ drastically increasing my namespace utilization for no reason.
What would be some things less symmetric pattern synonyms would really come in handy for?
What everyone said is true, but in regards to Haskell this sort of thing is totally possible since Haskell's logic is inconsistent. Bottom (`undefined`, or `error`, etc,) is an example of that. They are all ways of writing a type that doesn't actually contain the value it claims to.
And `QuantifiedConstraints` too!
I'm not a bash guru. I just saw this post and thought that there should be easier way to do it with `bash`. So I googled and saw description of commands and now I at least partially understand how it works. Though, I was familiar with commands `curl` and `grep` and some `bash` basics before.
Thanks for the cool write up. My wife does similar research, and I would like to persuade her to switch to your approach, so great to have it explained. To address your comments: * Does not having ReaderT really complicate things? Generally I just pass a single extra arg to the rule functions and that's enough. I also find the contents of that arg change in different places. Can you point at code you think shows it is valuable? * For FilePath, do you have a benchmark showing its slow? The internals of Shake don't use FilePath but a wrapped ByteString (to make the FFI fast), and I've never seen a system where it's slow. Why switch to Path Abs when Shake recommends using relative paths as per https://shakebuild.com/faq#should-file-names-be-relative-or-absolute? I imagine the Path wrapper is nice and self contained - fancy releasing it? Shake is deliberately low dependency so FilePath ends up as the default. * The resource limitation is based on the fact that dependencies require you to stop executing, and resources are a bit like locks - so if they are held you might deadlock and if they are released you might be surprised. Preventing need was the safest way forward, but interested in what you think the right way is. 
Reading core revealed above version was wrong. The extra arity of the definition prevented inlining. delete_foldr :: (Ord c, Foldable f) =&gt; f c -&gt; TSet c -&gt; TSet c delete_foldr cs t = fromMaybe empty $ delete_foldr_ cs t -- this should be: -- delete_foldr cs = fromMaybe empty . delete_foldr_ cs {-# INLINE delete_foldr #-} delete_foldr_ :: (Ord c, Foldable f) =&gt; f c -&gt; TSet c -&gt; Maybe (TSet c) delete_foldr_ = F.foldr f b where f = ... b = ... {-# INLINE delete_foldr_ #-} Fusion did occur for "fixed" version. `delete (replicate ...)` was compiled to a tail-recursive function with no list construction involved. It seems slightly (~5%) faster, but I can't be sure of the impact of the fusion, due to high variance. Thank you for advice.
After playing with your code for a litlle bit, i think it may worth to create a GHC issue. The core is fine\(though too much inlining is blowing the code size\), the problem is in the codegen, I'm not sure where the problem\(tagToEnum#? register allocation?\), but the generated code is definitely not optimal here. 
Your Haskell code and C code have similar performance when compiled with `ghc -fllvm -O2` and `clang -O2` respectively. Looks like your `gcc` is doing a bunch of optimizations that the Haskell code is missing out on. --- Here's a version which is about 25% faster than the C code (`ghc -fllvm` vs `clang` again): {-# language MagicHash #-} {-# language UnboxedTuples #-} module Main (main) where import Data.Maybe (listToMaybe) import GHC.Base (Int(..)) import GHC.Prim ((&lt;=#), (&lt;#), (+#), (*#), (==#), Int#, quotRemInt#) leftAppend :: Int# -&gt; Int# -&gt; Int# leftAppend k n = case n &lt;# 10# of 0# -&gt; case n &lt;# 100# of 0# -&gt; case n &lt;# 1000# of 0# -&gt; case n &lt;# 10000# of 0# -&gt; case n &lt;# 100000# of 0# -&gt; case n &lt;# 1000000# of 0# -&gt; case n &lt;# 10000000# of 0# -&gt; case n &lt;# 100000000# of 0# -&gt; case n &lt;# 1000000000# of 1# -&gt; n +# k *# 1000000000# _ -&gt; n +# k *# 100000000# _ -&gt; n +# k *# 10000000# _ -&gt; n +# k *# 1000000# _ -&gt; n +# k *# 100000# _ -&gt; n +# k *# 10000# _ -&gt; n +# k *# 1000# _ -&gt; n +# k *# 100# _ -&gt; n +# k *# 10# isOuroboros :: Int# -&gt; Int# -&gt; Int# isOuroboros k n = let (# rest, tens #) = n `quotRemInt#` 10# in n *# k ==# leftAppend tens rest firstOuroboros :: Int# -&gt; Int# -&gt; Int# -&gt; Maybe Int firstOuroboros k start end = os start where os :: Int# -&gt; Maybe Int os cur = case cur &lt;=# end of 0# -&gt; Nothing _ -&gt; case isOuroboros k cur of 0# -&gt; os (cur +# 1#) _ -&gt; Just (I# cur) main :: IO () main = do print $ firstOuroboros 4# 1# 100000000# print $ firstOuroboros 5# 1# 100000000# print $ firstOuroboros 6# 1# 1000000000# 
Is this also possible for GitLab?
Not using 3 names when 1 would do. For example: https://github.com/ekmett/coda/blob/11af3261c3198d4fc4d20f04ffd78b8b3ab04f14/lib/bdd/Data/BDD.hs#L178 has to provide both [BDD](https://github.com/ekmett/coda/blob/11af3261c3198d4fc4d20f04ffd78b8b3ab04f14/lib/bdd/Data/BDD.hs#L178) and [BDD_](https://github.com/ekmett/coda/blob/11af3261c3198d4fc4d20f04ffd78b8b3ab04f14/lib/bdd/Data/BDD.hs#L184) so that you can "read" without the constraints needed to construct such a thing. BDD_ only exists because of this enforced symmetry in our pattern synonyms. If reading also required more than the writing, (as with the JSON example above) then the equivalent to the [`bdd`](https://github.com/ekmett/coda/blob/11af3261c3198d4fc4d20f04ffd78b8b3ab04f14/lib/bdd/Data/BDD.hs#L158) function supplied above would also need to be exported. In a world with less symmetric pattern synonyms that JSON pattern would suffice to be almost my entire API for working with JSON. I make use of it in things like https://github.com/ekmett/coda/blob/master/lib/coda-lsp/Language/Server/Protocol.hs#L982 where I define both the construction and pattern matching using a single pattern. But, while convenient here, if it took any type parameters, I'd demand too much of them and would have to write two other functions and further clutter the namespace to get the original utility.
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://github.com/ekmett/coda/blob/11af3261c3198d4fc4d20f04ffd78b8b3ab04f14/lib/bdd/Data/BDD.hs#L178) - Previous text "BDD" [Here is link number 2](https://github.com/ekmett/coda/blob/11af3261c3198d4fc4d20f04ffd78b8b3ab04f14/lib/bdd/Data/BDD.hs#L158) - Previous text "bdd" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
Nah, honestly your tutorial is pretty good actually. The only thing is that it is hard for a pure newbie in webdev to understand what this is about, but you can't really do anything about it ^^ otherwise it is pretty clear and comprehensive I think
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [ekmett/coda/.../**Protocol.hs#L982** (master → 11af326)](https://github.com/ekmett/coda/blob/11af3261c3198d4fc4d20f04ffd78b8b3ab04f14/lib/coda-lsp/Language/Server/Protocol.hs#L982) ---- 
It even supports specifying a language, like ```haskell code = colorized $ hooray ```
Replace `listToMaybe` and `filter` by `find`?
I was reading the changelogs a while ago and their `do`-notation is really cool. Basically, pattern binding in `do`-notation has to account for other possible patterns, but it can branch into other monadic computations: do Just hello &lt;- getName where Nothing &lt;- ohNoItsGoneWrong! putStrLn ( "Hello" &lt;&gt; name &lt;&gt; "!" ) Afaiu, this calls `getName`, and if it's `Just` we continue with the "happy" path, and if it's `Nothing`, we switch over to `ohNoItsGoneWrong`. I really like this, and kinda wish we had it! Also, kudos for the Idris team who I believe originally came up with this syntax.
&gt; 38 files changed, 1608 insertions(+), 381 deletions(-) Given that a 500 line test file was added, this actually isn't too bad! Really looking forward to using this feature, it's going to drastically improve things.
Nice!
Well, it feels to me like we could do a whole lot better without too much work. Some specific feedback about what kind of information is missing would really help us make the tutorial more "newbie-proof". A more gentle description on the frontpage? Instructions to follow along (the tutorial is buildable as a cabal project) on the landing page, with commands to execute to run the code for each page (server, client, etc) at the top of the said page? More "hand-holding" in specific sections that are too brief to be useful to beginners? I don't think such problems are unfixable, but I do need to hear about them, ideally from the people having them.
On windows, using the following code \(in ghci, if it makes a difference\) `import System.Process` `p = proc "start" []` `createProcess p` I get the following error: `*** Exception: start: createProcess: does not exist (No such file or directory)` I expected to see an empty cmd window. Why is this happening?
Ok so first take my words carefully because I may be too much of a newbie for it \^\^ Basically the presentation \([https://haskell\-servant.readthedocs.io/en/stable/](https://haskell-servant.readthedocs.io/en/stable/)\) is a bit harsh, but maybe with enough background all the words make sense by themselves. About the tutorial, it is pretty instructive but we don't really know what we're doing. The intro said that servant could be used both for server and client, and which one are we creating here ? And we could maybe start with a simpler API example I will tell you more as I progress \^\^
I tried uboxed version too\(even a manually loop unrolled version\), but ghc's NGC is not doing great on optimize this loop. I suspect there're some problems with either tagToEnum# hack or register allocation.
Open an issue, looks like there aren't rules mapM \-\&gt; traverse. Maybe Neil have a reasoning for that. btw, that would be \`traverse\_ for \[1..5\]\`, \(or \`mapM\_\`\). There is a rule warn: {lhs: void \(mapM f x\), rhs: mapM\_ f x} But it doesn't warn if you use composition. I think Neil would value this input too.
I don't think your approach that classical and intuitionist logic are in competition with each other is the right way to look at it. Classical logic is very successful and it will not be going away. The Curry-Howard isomorphism is proof that intuitionist logic is also very successful and will not go away. This is like many other similar kinds of "arguments" in the history of Mathematics - whether the square root of -1 exists, whether two parallel lines have an intersection point, etc. It starts as a philosophical argument, but in the end, we understand the underlying mathematics more deeply, and everyone profits from both approaches.
Please do feel free to open a new issue [here](https://github.com/haskell-servant/servant/issues/new) to give some feedback about the tutorial and point to things that could be improved.
Woohoo! I've been wanting a mechanism like this for a long time. Good stuff!
Thank you /u/alicelambda - I think the save screenshot might be worth a shot as an MVP. :-)
How is Agda compared to Idris now?
/u/rampion thank you for the reply. I think that I failed to make clear that I am using `webdriver` not because I am testing the web-app, but as a core functionality of the web-app itself. What I would like the web-app to do is to log in to a website, go to a particular page, then save that page as a pdf. That last part is what I am having troubles with.
Indeed, a mutable vector seems preferable to re-generating vectors from scratch here. There are other things that make this program slow: - boxed vectors (`Data.Vector`) instead of unboxed (`Data.Vector.Unboxed`); - retraversing the vector to compute extrema (all the `maximum` and `filter`); you can probably spare some work by keeping some auxiliary structures around. Since the vector contains small values, you might also benefit from a denser representation with multiple elements in one word (e.g., one by byte), but the bit tricks to make this pay off can be quite involved. The algorithm seems to do a fair bit of copying. A tree structure might actually be efficient, while providing a good place to manage auxiliary information. But it's likely the extra GC overhead does not compare to a mutable-vector implementation with no short-lived allocations. --- The mutable vector interface to use here is [`Data.Vector.Unboxed.Mutable`](https://hackage.haskell.org/package/vector-0.12.0.1/docs/Data-Vector-Unboxed-Mutable.html) and if the types look confusing, you can mentally replace all the `MVector s` and `MVector (PrimState m)` with `IOVector`, the type of mutable vectors in the `IO` monad, and replace all the `m` with `IO`. The primary functions to use are new :: Int -&gt; IO (IOVector Int) read :: IOVector Int -&gt; Int -&gt; IO Int write :: IOVector Int -&gt; Int -&gt; Int -&gt; IO () -- index first, value second You'll need to loop manually, as there are no higher-order combinators for mutable vectors. You can use `for_` loops though. The list gets fused away, but make sure the loop indices don't default to `Integer` (enable `-Wall` if you haven't already, that would catch this and many other mistakes): for_ [0 .. 30] $ \i -&gt; write v i (f i) To copy chunks, `slice` and `copy` may be faster, but you'll have to benchmark to check whether that's worth it on such small arrays. slice :: Int -&gt; Int -&gt; IOVector Int -&gt; IOVector Int -- begin index, length copy :: IOVector Int -&gt; IOVector Int -&gt; IO () There are unsafe versions of all those functions that don't do bounds check. To make it easier to switch back and forth for debugging vs benchmarking, you can wrap these functions in two modules with the same interface, a safe one and an unsafe one. --- Looking at the optimizer output helps to make good guesses about what to optimize. [I wrote a small example of this process](http://blog.poisson.chat/posts/2017-10-08-aeson-perf.html) but I don't have a comprehensive resource to point to sadly. The main objectives are to have functions inlined and data unboxed, so one starting point may be to search for threads about how data is represented in GHC and experiment with boxed vs unboxed data to better understand the performance implications. 
Well, but with intuionistic logic you can just add LEM/AC as a premise and get classical logic. I guess I should have mentioned it in the essay.
I wrote a parser for some relatively big XML files (generated by the Qt documentation generator) in Haskell a little while ago, that code may be of use to you: [`qdoc2psn`](https://github.com/taktoa/qdoc2psn). If I had to redo it, I would probably use [`xml-conduit`](https://hackage.haskell.org/package/xml-conduit) though. If you want to use XPATH, then the only Haskell package I know of that supports it is [`hxt-xpath`](https://hackage.haskell.org/package/hxt-xpath). I'm not really a fan of [`hxt`](https://hackage.haskell.org/package/hxt), though, so I would just modify `hxt-xpath` so that it uses `xml-conduit` (this is easier than it may seem, since you can reuse its tests and expression parser; I suspect the only part that needs reimplementing is [this file](https://hackage.haskell.org/package/hxt-xpath-9.1.2.2/src/src/Text/XML/HXT/XPath/XPathEval.hs)). I'd say your best bet for making the XML browser UI would be to use [`brick`](https://hackage.haskell.org/package/brick), along with [`prettyprinter`](https://hackage.haskell.org/package/prettyprinter) (to pretty-print the XML) and [`prettyprinter-vty`](https://hackage.haskell.org/package/prettyprinter-vty) (to convert the `Doc` into an `Image` usable with `brick`). For efficiency, you may want to fully parse the XML file, and then serialize the AST to disk in a binary format. I recommend [`serialise`](https://hackage.haskell.org/package/serialise) for this purpose, though there are many other options available. If your focus is on efficiency in the context of large files, here are a few tips that will help you avoid performance issues: - Avoid using linked lists (the `[]` type constructor); they take up a lot of space and fragment the heap - Use streaming frameworks like `streaming`, `pipes`, `machines`, or `conduit` (I recommend `streaming`) - Use Haskell's [heap and cost profiling tools](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/profiling.html). - When necessary, write code in C and use the FFI to call into it (though keep in mind that there is overhead associated with each FFI call) 
I must be being thick, because I don't understand your explanation. Even so, I want to ask: * What would a solution look like? * Could it be compatible with the "more symmetric" pattern synonyms?
I basically want to be able to give different signatures to the &lt;- and where parts of the pattern synonym. So, e.g. in the JSON example above. to match you need the FromJSON and AsJSON constraints, and to construct you need the ToJSON and AsJSON constraints. Making up a syntax on the spot: pattern JSON :: (FromJSON a, AsJSON t) =&gt; () =&gt; a -&gt; t pattern JSON a &lt;- (preview _JSON -&gt; Just a) where JSON :: (ToJSON a, AsJSON t) =&gt; a -&gt; t JSON a = _JSON # a 
Compatibility would be no problem. My proposal is more symmetric in terms of syntax. /u/edwardkmett's is less symmetric in terms of type. Indeed, there are "more symmetric" synonyms that can be given "less symmetric" types. Contrived example: pattern With5 (x, 5) = x -- pattern form: match anything and produce a pair -- expression: match pair, expose fst, and require snd == 5 Currently we'd get pattern With5 :: forall a n. (Num n, Eq n) =&gt; (a, n) -&gt; a Such that a use of `With5` in a pattern would cause an `Eq` constraint, even though we never actually check equality. With less symmetric synonyms we'd have pattern With5 :: forall a n. Num n =&gt; (a, n) -&gt; a With5 :: (Num n, Eq n) =&gt; (a, n) -&gt; a
Here's a comparison of serialised [data generated by mockaroo] (https://github.com/fumieval/winery/blob/master/benchmarks/data.csv): ``` -rw-r--r-- 1 fumieval staff 125709 6 5 23:23 data.binary -rw-r--r-- 1 fumieval staff 65437 6 5 23:23 data.cbor -rw-r--r-- 1 fumieval staff 73619 6 5 23:23 data.csv -rw-r--r-- 1 fumieval staff 65196 6 5 23:23 data.winery ``` I'm surprised that binary is so bad! and yes, winery uses VLQ for Int. I benchmarked winery, binary and serialise. Not very good I guess... ``` serialise/winery mean 2.812 ms ( +- 145.5 μs ) serialise/binary mean 1.279 ms ( +- 70.63 μs ) serialise/serialise mean 322.7 μs ( +- 15.41 μs ) deserialise/winery mean 1.542 ms ( +- 28.71 μs ) deserialise/binary mean 1.668 ms ( +- 51.11 μs ) deserialise/serialise mean 922.9 μs ( +- 32.50 μs ) ```
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [fumieval/winery/.../**data.csv** (master → a588eed)](https://github.com/fumieval/winery/blob/a588eedc57678959341935c910e62e0a14b895c9/benchmarks/data.csv) ---- 
And a preview of the `ghci` `:doc` command!
I seem to remember Edwin Brady mention that he took the idea for that syntax from Perl (I think)?
&gt; data types are simple records and Haskell values, which is a breath of fresh air when comparing it to how the other libraries tend to work As a point of information, Opaleye has represented SQL rows as Haskell records from its inception (and it's older than Beam). Whether you consider it "simple" or not depends on whether you define "simple" to imply the "Higher Kinded Data" style. Rel8 (a frontend to Opaleye) has always supported HKD style and the latest version of Opaleye also supports HKD style (though I recommend that new users wait until version 0.7 before using it). 
Perl 6, maybe, but Perl (meaning Perl 5) would very much surprise me - as it has no concept of pattern matching!
Maybe it's just the example - but what does this buy you over using bind/lambda-case directly other than possibly reducing nesting? Feels somewhat like I'm having to parse two separate bits of code to check what cases have been handled, instead of - ``` do getName &gt;&gt;= \case Nothing -&gt; ohNoItsGoneWrong! Just hello -&gt; putStrLn ("Hello" &lt;&gt; name &lt;&gt; "!") ```
There are loads of idiosyncratic features in both, so I mention only a couple of general things which are salient to me: Agda: much stronger and more robust inference &amp; unification, HoTT compatibility, modules, universe polymorphism. Idris: far more usable program compilation &amp; code backends.
I guess it's just a more compact way of saying the same thing.
For testing, I'm not sure what you mean by "clean", but if you want to actually be pulling from a test DB, the easiest way I've done this is create some helpers for creating test data (see e.g., this type class https://github.com/positiondev/hspec-fn/blob/master/src/Test/Hspec/Fn.hs#L178), and wipe the database after each full test. Since you don't want to have to have every test run through the DB, it's helpful to abstract out "get record by id" functions, so you can pass ones that just return an in-memory record. By the user account data in snap you mean in Snap.Snaplet.Auth? I've had multiple applications use that and honestly it's felt like a mistake each time. It doesn't make things easy enough and it causes a lot of friction (as you end up with an AuthUser &amp; whatever other datatype you need; ideally they are the same table, but you still have to do double queries, etc). Maybe someone else knows how to make this work better, but my advice would be to just create you own user account type, recreate logging in and such (but don't try to recreate session / cookie handling; that all works great!). I've never used Esqueleto, but I've been really happy with the typed DSLs that essentially represent SQL in haskell. Partly because it was the best (or maybe only) thing at the time (~4yrs ago), my applications used Opaleye, but there are a bunch of choices now. These let you write queries essentially in whatever structure you want, so you _should_ be able to get whatever performance you need. The underlying libraries (postgresql-simple) handle streaming pretty well, I think. 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [positiondev/hspec-fn/.../**Fn.hs#L178** (master → cf0607b)](https://github.com/positiondev/hspec-fn/blob/cf0607b5406ddf884dadf533c546377958cc35e8/src/Test/Hspec/Fn.hs#L178) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply e05q2k7.)
Thanks! I think I have the same issue with users: I want to store additional data \(e.g. user preferences\), so upon registering a user the app automatically creates the main user to store the password and then I add an \`AppUser\`, which is the type I create to store all that other data. I'll have a look at the typed DSLs and Hspec\-Fn, these do look useful.
Once you have different contexts, you have different concrete argument types already through `~` constraints, so that part doesn't matter. Once you have that you can fiddle with that to get construction to have higher arity than match, by ~'ing your way to the result being a function space on construction, but the other way would require something more.
8.6 is aiming to be the best release ever!!!
Is it the case statement or the unboxing that helps here? I'd expect ghc to be able to unbox everything about this problem pretty trivially. It doesn't even need to eliminate intermediate types.
I tried it with and without inlining And it was faster this way. I wasn't optimizing for cod binary size.
That is great. 
Completely tangential to the question, so feel free to ignore. I wondered how an SMT solver would do for this problem. I've coded the Haskell version almost verbatim (modulo the modifications to make it symbolic), and was surprised to see the total run-time for all the queries were a mere 0.12s. Quite fast, I was surprised myself. Here's the code: https://gist.github.com/LeventErkok/2cd04332f7404572e67e62218d55f7de
If the AppUser is in a separate table, I think you are asking for trouble... because you now have to always ensure that there is exactly one AppUser for each AuthUser, and that's a pain to do! You can actually hack this into the same table (Snap's code will explicitly list the columns it wants, so you can have other ones, provided they have defaults so the creation won't fail; this is another problem, but... like I said, it sucks). `hspec-fn` problably won't be useful aside from ideas: it's a bunch of testing helpers for a (minimal) web framework that I helped write called `fn` (http://fnhaskell.com/) -- for Snap you probably will do better with http://hackage.haskell.org/package/hspec-snap (which I also helped write, back when I was still using Snap).
Reducing nesting is a big thing. That marches to the right in the happy case unless you use explicit brackets.
What happens if you use `shell` instead of `proc`?
It's always like that. Just add the parallel postulate to projective geometry and you get classical geometry. That doesn't mean one is "better" or "stronger" or "more correct" than the other. We now understand that they are simply two kinds of geometric space. So too here, there are different logics that lead to different kinds of theories and applications, each interesting in its own way.
\&gt; Once users are up to speed they seriously love Haskell. But they say they don't have time to show all their colleagues why they love it; they believe it's the community's role to do this. Too bad those users don't see themselves as part of the community...
oxymoron?
Thanks for the comparisons! It looks like reddit mangled your text blocks, here they are: ``` -rw-r--r-- 1 fumieval staff 125709 6 5 23:23 data.binary -rw-r--r-- 1 fumieval staff 65437 6 5 23:23 data.cbor -rw-r--r-- 1 fumieval staff 73619 6 5 23:23 data.csv -rw-r--r-- 1 fumieval staff 65196 6 5 23:23 data.winery ``` I think for a comparison, it's would be fair to do gzip first. `binary` and `cereal` output compresses very well. It's interesting that the cbor size is about the same as winery. I thought cbor should be repeating field names, while winery should be able to omit those? ``` serialise/winery mean 1.985 ms ( +- 98.52 μs ) serialise/binary mean 1.282 ms ( +- 65.78 μs ) serialise/serialise mean 324.5 μs ( +- 3.221 μs ) deserialise/winery mean 1.551 ms ( +- 67.03 μs ) deserialise/binary mean 1.728 ms ( +- 57.18 μs ) deserialise/serialise mean 951.6 μs ( +- 36.41 μs ) ``` If you haven't done any profiling, there may be some easy fixes that can speed things up a lot. I gather the `serialise` authors paid careful attention to performance, and got numbers so much better than `binary` and `cereal` it made me think everyone should learn from that.
Three days later: [*`DerivingVia` landed in GHC master*](https://www.reddit.com/r/haskell/comments/8ooagf/derivingvia_landed_in_ghc_master/)
It's a combination of both- matching on `#1` gets back to the performance of the boxed version, but matching on False in the boxed version changed nothing.
Teaching in\-the\-small is a bit different than teaching in\-the\-large. By that I mean this: At a Haskell shop, pretty much every developer can answer a coworker's questions at will given they have experience with subject matter. And not only \*can\* they answer, they're typically happy to. But most Haskell developers aren't really as interested in going out and writing teaching\-oriented blogs or giving teaching\-oriented talks or otherwise engaging in public. And I don't think it's really reasonable to expect even a plurality of Haskell developers to do that. It's just not interesting to many people and they have much better (for them) uses of that time. But the power of this sort of teaching is that it only takes a small amount of willing teachers to have a huge impact.
I recommend having a plan for migrations from the start and using it in your tests. So if you’re using `persistent` but are managing your schema with some other tool (liquibase, numbered SQL scripts, whatever), be sure to **not** use `persistent`’s auto-migrate feature!
1) What does OVERLAPPABLE actually do? I've got an instance that can conflict with another instance. If I mark it as INCOHERENT, the code compiles. If I mark it as OVERLAPPABLE, I just get: \* Overlapping instances for LeftModule f (Square f) arising from a use of \`.\*' Matching instances: instance \[overlappable\] Semiring a =\&gt; LeftModule a (Square a) \-\- Defined at src\\Lib.hs:72:31 instance \[safe\] Additive m =\&gt; LeftModule () m \-\- Defined in \`Numeric.Algebra.Class' (The choice depends on the instantiation of \`f') OVERLAPS produces a similar error message. 2) The calling function that generates the above error looks like this: gridCorner :: forall d f . (*Direction* d, *Floating* f, *Semiring* f) =\&gt; *Square* f \-\&gt; f \-\&gt; d \-\&gt;* Squar*e f is there any way to convince this function to not bother for void and void alone? 3) Could QuantifiedConstraints help? (I understand very little about them and I'm stabbing in the dark, so a simple no will be a sufficient response.)
It's not quite that simple (for reasons already given) but there structures that have the big\-O performance you want. In particular, sequence does: [http://hackage.haskell.org/package/containers\-0.5.11.0/docs/Data\-Sequence.html](http://hackage.haskell.org/package/containers-0.5.11.0/docs/Data-Sequence.html) The performance of "List" is exactly the performance of "Singly linked list keeping only a pointer to the head". It is a deliberately dumb data structure. The advantage of using it is that Haskell is very good at optimising things using it. However, there are plenty of other data structures out there. The text and containers libraries are good places to start.
Nice animated diagrams! I like it and maybe would contribute to it but you need to structure your library as modules so it can be packaged up and reused, now it’s in the form of an IHaskell notebook which is really great documentation but maybe it should be one of the imports at the beginning of the file instead.
Being "part of the community" can be exhausting.
yeah I know you're right. I'll put the core into a haskell module and import that in the notebook soon
Agda is pretty strong, can do pretty complex inferences and I think it's pretty straight-forward. Toolchain is a bit weird though, but nothing too complicated. It compilea to Haskell so it's logistically messier.
No this is comment in Perl the mechanism is just different. Many function return True on success and False on Failure. So you often have syntax like: system ("mkdir -p Purged") or die "Failed to mkdir." ; That syntax was definitely in Perl4 and wouldn't shock me if it goes back to Perl1 it was so ubiquitous. 
Oh, yes, this is certainly a Perl idiom
What will it do?
This! I never understood auto migration, and honestly just find it to be a dangerous misfeature. Production migrations should be carefully designed to minimize downtime by staging them so that the application can work unchanged before and after each migration (this obviously isn't always possible, but it often is). The pattern is that the database initially expands to a superset of what the application needs, then the application changes (within the superset), and then the database contracts back to match the changed application. This multi-stage approach explicitly relies upon adding vestigial stuff to the database, and only later having it not be vestigial! Which is not possible with a strategy that says "make the database match my application". (Maybe auto migrate makes things faster early in development, pre-production, but given that the strategy should to be abandoned as soon as the application is useful, it doesn't seem much of an argument for it...).
As an alternative to Planet Haskell, I've cobbled together a little project called [Reveille](https://github.com/haskellweekly/reveille) for keeping up with blogs featured in [Haskell Weekly](https://haskellweekly.news). The service itself isn't super reliable because parsing Atom/RSS feeds on a tiny machine with limited memory is difficult. I mostly run the site locally, but if there's interest I could make the service more robust. 
In this preview version it's going to show documentation on declarations: λ :doc head Extract the first element of a list, which must be non-empty. In GHC-8.8 it might get more similar to the `:info` command and include type signatures, constructors and their documentation, documentation on function arguments, etc. It's the first feature merged from [my current Google Summer of Code project](https://summer.haskell.org/news/2018-04-23-accepted-projects.html#hi-haddock).
If you have a type with constructors that all have the same number of arguments (potentially of different types) is it possible to write a function that does the same thing to each constructor without writing out each line? To be concrete what inspired this was I had a type: data Stuff = StuffA Arg1 Arg2 | StuffB Arg3 Arg4 and had a function that looked like, f (StuffA x y) = g x \+ g y f (StuffB x y) = g x \+ g y The two right sides are identical, so I'd guess there's a simpler way to write this.
\&gt; the easiest way I've done this is create some helpers for creating test data I am currently building up towards having a collection of functions for building test data for unit tests, white box integration tests close to the db layer, black box integration tests at the API layer and above, and setting up manual test sites. Inside of my application's model layer, there are functions for creating new blank instances for types. Inside of my test suite, there are Hedgehog generators that start with the blank instances and fill in the remaining fields. For white box integration tests close to the db layer, I take a sample from the Hedgehog generator and override any fields desired. I want to build up an executable that can be used when building a test site for API tests and above, which will also sample from the Hedgehog generators with selective overrides. I'll probably build a second similar executable to populate a manual test site. I have been considering the "fake" library, but I will stay with Hedgehog for these for now.
Yeah, it works with shell, so presumably it's a shell command. Thanks! Is there a reason `shell ::` [`String`](https://hackage.haskell.org/package/base-4.10.1.0/docs/Data-String.html#t:String) `-&gt;` [`CreateProcess`](https://hackage.haskell.org/package/process-1.6.3.0/docs/System-Process.html#t:CreateProcess) instead of [`String`](https://hackage.haskell.org/package/base-4.10.1.0/docs/Data-String.html#t:String) `-&gt; [String] -&gt;` [`CreateProcess`](https://hackage.haskell.org/package/process-1.6.3.0/docs/System-Process.html#t:CreateProcess) similar to `proc`? Passing the args in in the same string is frustrating and annoying due to the amount of escaping required.
There are many materials out there to bust the myth that Haskell is slow. There are even some experiments showing that you can match the speed of C (FFI) with just pure Haskell. 
I'm happy you highlighted that bit. That feeling of &gt; seriously love [..] don't have the time [..] seems un-understandable to me. If I love something, I'm happy to (at the very least) talk someone's ear off if they're willing to listen 😃.
Relatively few career developers do this in any community. It takes serious dedication to the craft, and ALSO a life and a schedule that allows you the flexibility to spend that time 'giving back' to the community. Those stars don't align for everyone, and that's not a mark against them.
However, we are talking about the foundation. If the parallel postulate is always an axiom, we will never find out non-Riemann geometry. In the case of the standard way of classical logic, you can't say like remove AC and LEM to make C-H iso work. I totally agree classical reasoning has its use. However, as the foundation of all math, we would want something that suffice, but no more.
But no cumulative universes D:
Wow, looks cool, I'm learning a bit of Haskell at the moment, If I could do something useful to help then I'd definitely do it!
One way is to refactor Stuff to share the constructor. data Stuff = Stuff Tag Arg1 Arg2 data Tag = Tag1 | Tag2
Glad you like it! Currently I'm trying to make the repo a proper "stack" project directory before I go ahead and start adding more functionality. Right now I'm actually just Peggy-backing on the IHaskell repo to actually run the code in .ipynb because I haven't figured out how to setup a project with IHaskell and custom libraries yet (a fellow noob here too!) 
if you want you could do that (i.e structure the repo using "stack"), or just add more cool functions (like squiggly and squarify), or you could just play with it and share any cool results you make
Also another cool thing to have is projecting the points to 3d space and adding some 3d rotations and such... 
very nice results :)
Nice!
Again!
Showing people most languages typically involves showing the syntax for branching, iteration and function declaration, and then introducing the one thing that’s actually different. In my experience, co-workers start to glaze over by the time you’ve explained what Functor is precisely. I will do things where I’ll point out a feature of Haskell that would render a trash fire in our codebase five lines long.
pretty
You'll grow up and understand that there's more to life than proselytism
Always exciting to read about your progress :) Keep up the good work!
Arh, I think i have nailed down the slowdown, there's a dark magic to optimize division which is not performed by GHC's NGC: [convert division into multiply](https://android.googlesource.com/platform/art/+/fcc36ba2a2b8fd10e6eebd21ecb6329606443ded/compiler/dex/quick/arm64/int_arm64.cc#381) , which at first didn't catch my eye. But after getting rid of heap check inside the loop, it's basically the only difference between GHC and C version. Here's what GCC do for ``` long isOuroboros(long k, long n) { long rest = n / 10; long tens = n % 10; return leftAppend(tens, rest) == n * k; } ``` ``` isOuroboros: push rbp mov rbp, rsp sub rsp, 32 mov QWORD PTR [rbp-24], rdi mov QWORD PTR [rbp-32], rsi mov rcx, QWORD PTR [rbp-32] movabs rdx, 7378697629483820647 // 7378697629483820647 == 0x6666666666666667 // see the android's jit code linked above mov rax, rcx imul rdx sar rdx, 2 mov rax, rcx sar rax, 63 sub rdx, rax mov rax, rdx mov QWORD PTR [rbp-8], rax mov rcx, QWORD PTR [rbp-32] movabs rdx, 7378697629483820647 mov rax, rcx imul rdx sar rdx, 2 mov rax, rcx sar rax, 63 sub rdx, rax mov rax, rdx sal rax, 2 add rax, rdx add rax, rax sub rcx, rax mov rax, rcx mov QWORD PTR [rbp-16], rax mov rdx, QWORD PTR [rbp-8] mov rax, QWORD PTR [rbp-16] mov rsi, rdx mov rdi, rax call leftAppend mov rdx, rax mov rax, QWORD PTR [rbp-32] imul rax, QWORD PTR [rbp-24] cmp rdx, rax sete al movzx eax, al leave ret ```
We use persistent auto-migrations for a large and complex commercial web app, over 60K LOC in Haskell. Auto-migration is a simple, very well designed, and hugely valuable feature that has probably saved us months if not years of man-hours. We basically almost never have to think about migration - it just works. Auto-migration is very conservative by design - it won't migrate anything that isn't certainly correct, as proven by the types. When there's any question - auto-migration stops, and the app fails to load with a clear error message. The one drawback I have seen is that because auto-migration works so well, developers on our team will sometimes make new fields optional even though they really should be required, in order to avoid the need to worry about manual migration scripts when upgrading customers later on. This creates some code paths that deal with `Nothing` cases that will never happen.
Regarding esqueleto, we have been digging into the stuff somewhat lately. I'm not sure I understand your concerns. &gt; Esqueleto missing functionality for performance-intensive queries Esqueleto translates directly into SQL. It doesn't affect performance in any way, only the SQL you write matters. Is there something you want to write in SQL to improve performance that you couldn't figure out how to write in esqueleto? &gt; Esqueleto being slow when trying to parse a large data pull (&gt;50K items) into Haskell objects But esqueleto doesn't do any "data pull". It generates SQL code, that's all. The SQL does the data pull. Do you mean you are embedding &gt; 50K records literally into an esqueleto query to insert them? Don't do that - just use persistent, or even raw SQL.
I mostly lurk around here, but I've made an attempt at writing a blog post about a pretty simple subject that I did not find much (freely available) material on online. If you have any comments regarding the prose, the code or the presentation, I'd love to get some feedback.
There are many ways to view the foundation of mathematics. For most mathematical work, it doesn't matter that much. Historically, the intuitionists claimed that all the work done in classical mathematics on theories which cannot be constructed was a waste of time and should be thrown out. Mainstream mathematics will never accept that view. Nor do I think that anyone today would claim that Zorn's Lemma is the One Truth that everyone must accept, and reject any mathematics that does not assume it.
I could see myself in some form or shape contributing to the Javascript community. In Haskell, the amount of reaearch papers being floated around and the copious amounts of category theory in tutorials is just super intimidating. Granted I just started learning Haskell a few months ago but I don't see myself in the capacity of furthering the popularity of this language in the short or medium term future. It's just over my head.
Your code already looks pretty good to me. It's actually too small to suggest some big improvements. I can add only minor comments. ``` game &lt;- get case statusGame game of ``` Can be rewritten using `gets` function: ``` status &lt;- gets statusGame case status of ``` But now you can use `-XLambdaCase` extension to actually make code shorter: ``` gets statusGame &gt;&gt;= \case Won -&gt; ... -&gt; ``` Notice that you also don't need variable name for this which is good. I like this post about LambdaCase: * https://www.reddit.com/r/haskell/comments/7s0ski/lambdacase_in_the_wild/ This line: ``` modify $ over guessed (insert guess) ``` Can be written shorter with lens operators: ``` guessed %~ insert guess ``` But it's really okay to not use fancy operators before you feel comfortable with using `lens`. You have a lot of lifts like this: `lift $ putStrLn ..`. Default `Prelude` have all IO functions work inside raw `IO` monad. But you can use another custom preludes (for example `universum`) where all such functions are lifted to `MonadIO` so you don't need to write `lift` when you're working with some IO: * https://github.com/serokell/universum * http://hackage.haskell.org/package/universum-1.2.0/docs/Universum-Print.html For good and small example it's okay to use `String` type. But for big and serious programs it's better to use `Text` type from `text` library. You can try to use it on your small project to get feeling of it. For this you should use `-XOverloadedStrings` extension. There was very good blog post with refactoring code from `String` to `Text` recently but I can't find it...
It says, haskell even gets better adoption in ecommerce. Anyone knows production deployed ecommerce projects using haskell?
`{-# OVERLAPPABLE #-}` on `LeftModule a (Square a)` means other *more specific* instances are allowed to overlap with `LeftModule a (Square a)`, i.e., those obtained by substituting `a` with some other type, like `LeftModule () (Square ())`. `LeftModule () m` is not more specific that `LeftModule a (Square a)`, hence the error. `{-# INCOHERENT #-}` tells the compiler that it can pick this instance without worrying about overlap. It is almost never a good thing. The general solution is to avoid overlap in the first place, possibly with some `newtype`-wrapping or by reworking the type class and instance hierarchy.
In any language and community there is always space for learning materials for all stages of education. Even silly "Here is how \+\+ differs from :" can be helpful to some. (I wish I've read such tutorial before I spent 3h debugging the "issue" :D)
Thanks for working on this by the way. It's going to be a nice feature for me.
I enjoy your blog style
Thank you very much!
Does it require Haddock? Will I need to build the docs of all the packages I use?
Well, I guess nowadays pure intuitionists like you mentioned don't exist. It seems that all dependently-typed language designers care about being compatible with classical logic. The HoTT book even has a chapter devoted to it. Maybe they should now be called intuionistic type theorists, but obviously its too long for an ideology.
And when `Arg1` and `Arg3` are of different types, like in: data Stuff = StuffA Int Char | StuffB Float String You can still use this refactoring by using GADTs data Stuff' where Stuff' :: Tag a b -&gt; a -&gt; b -&gt; Stuff' data Tag a b where Tag1 :: Tag Int Char Tag2 :: Tag Float String Though you'll want to put any common constraints in the Stuff' constructor so you don't have to match on tags to perform those ops: λ f (Stuff' t a b) = Stuff' t (2*a) b &lt;interactive&gt;:19:30: error: • No instance for (Num a) arising from a use of ‘*’ Possible fix: add (Num a) to the context of the data constructor ‘Stuff'’ • In the second argument of ‘Stuff'’, namely ‘(2 * a)’ In the expression: Stuff' t (2 * a) b In an equation for ‘f’: f (Stuff' t a b) = Stuff' t (2 * a) b λ data Stuff'' where Stuff'' :: Num a =&gt; Tag a b -&gt; a -&gt; b -&gt; Stuff'' λ f (Stuff'' t a b) = Stuff'' t (2*a) b λ 
Does `show` escape enough? shell' :: String -&gt; [String] -&gt; CreateProcess shell' cmd args = shell . unwords $ cmd : fmap show args
It's true that you can prefer either ZF or ZFC. The main point is that with set theory you lose C-H iso and that can not be recovered, and programmers need that, well, hopefully in several decades ...
Did you consider looking at the implementations of languages which do exhaustive checking e.g. ocaml or do they also not account for the redundant pattern check you were looking for?
I mean, yeah, obviously there are ways of working around it, I'm just confused by the apparent inconsistency.
I'm very sure that they do, but it can often be hard to glean the core idea from highly optimized code that works with an actual language. For example, I conjecture that ocamls object oriented features might make matters more complicated. 
Docs can only be shown for modules compiled or loaded with `-haddock`. The overhead of compiling with `-haddock` should be negligible though. If it isn't, please file a bug report! :) In the future I hope we will include docs in `.hi`-files by default. Generating the documentation with haddock should be pretty fast then.
Nice stuff, very easy to read and understand!
Thank you, I'm happy you think so! 
We used a "pattern matrix" approach that Dan Doel found in a paper in Ermine: [Ermine.Pattern](https://github.com/ermine-language/ermine/tree/02b456e3cc32db4bb2374496263d5a8f683ffd22/src/Ermine/Pattern) I believe the paper was [A Term Pattern-Match Compiler Inspired by Finite Automata Theory†](https://pdfs.semanticscholar.org/c0d6/f0225c5140d1528f35d187f070d415f33ed6.pdf) by Mikael Pettersson but I may be mistaken, it has been a few years.
Very nice blog post! I recently implemented a [pattern match compiler](https://github.com/jdreaver/amy/blob/40214a1bb896ddfb9bf3f6cc46723ef67035602c/library/Amy/Core/PatternCompiler.hs) for a [Haskell-like language I'm working on](https://github.com/jdreaver/amy). * I first used [an algorithm by Setsoft](https://github.com/jdreaver/amy/blob/40214a1bb896ddfb9bf3f6cc46723ef67035602c/misc/SetsoftMatchCompiler.hs) in his paper _ML pattern match compilation and partial evaluation_. The resulting decision tree was very compact, and finding non-exhaustive patterns was easy, but unfortunately I was trying to use this to desugar nested patterns in case expressions, and translating the output to a case expression seemed really nontrivial. * The current algorithm I use is taken from Chapter 5 of [The Implementation of Functional Programming Languages ](https://www.microsoft.com/en-us/research/publication/the-implementation-of-functional-programming-languages/). It is much simpler, very well explained, and includes a method to find non-exhaustive as well as redundant patterns. It is quite naive and definitely duplicates branches if the patterns are crazy, but I'm fine with that for now. Here's a list of resources I gathered about pattern matching while I was researching this for my compiler, in case anyone finds this helpful: --- ML pattern match compilation and partial evaluation https://www.itu.dk/~sestoft/papers/match.ps.gz - Alternate pdf link http://dotat.at/tmp/match.pdf - Outstanding algorithm and presentation. Can reduce a list of arbitrary patterns to a compact decision tree of Switch statements. - Builtin exhaustiveness and redundancy checking falls out naturally. Very cool. Chapters 4 and 5 of Implementation of Functional Programming Languages (chapter 4 is called Structured Types and the Semantics of Pattern-matching) When Do Match-Compilation Heuristics Matter? https://www.cs.tufts.edu/~nr/pubs/match.pdf - Contains an algorithm for compiling pattern matching and a general explanation of the problem. Compiling Pattern Matching to Good Decision Trees http://pauillac.inria.fr/~maranget/papers/ml05e-maranget.pdf Blog post called "How to Compile a Case Expression" https://typeunsafe.wordpress.com/2011/07/14/how-to-compile-a-case-expression/ Warnings for pattern matching https://pdfs.semanticscholar.org/997d/371f1e063ff11e00fc6c0aef259558b92303.pdf
The definition of UnitList in your second test seems to specify the Cons constructor as `Cons Unit Unit`. Typo?
It's not just automigration but *diff*\-based migration that's nasty. `persistent` also gives you the option to spit out needed migration* step*s on a partially\-migrated database, so it's pretty easy to use that to automatically get migration steps for a tool like liquibase that you check into version control.
Oops, good catch! Thanks 
That's a very interesting idea. Thanks for sharing it. 
Thanks for reading it! And thanks for sharing your resources for further studies. I'll put a link in the post to this thread so people can find them. 
I'm poking around in the code now, I've been using stack so I'm trying to get it to work with that... But I've never heard of IHasekll so it is a little bit mysterious. If I get something working I can let you know. 
As someone who develops on OS X and also wants to target ARM, I have twice the reason to be excited about this.
Your patch for the load command bug was wonderfully. The code size to utility ratio was very high :p
I like this approach but it does seem like a lot of boilerplate writing all those instances. Could be nicely derived with Generics?
**fist bump**
IHaskell is super awesome... especially helpful if you're tryning to learn haskell
Keep in mind that `-haddock` can create parse errors on code that parses fine without it, because it changes the token stream. That said, I'd also like it enabled by default. But then it should ideally generate warnings instead of errors and that might be a bit tricky (or a nice challenge) to implement.
Usually the point of asymptotic analysis is to gaurentee certain bounds in either the worst or average case. You can't really get this from sampling. But nothing prevents you from plotting the results of your benchmarks. I guess what you are really looking for is a plotting library?
How suitable would this library be for connecting to MS Access through ODBC? (The library name is an unqualified 'odbc', but your focus seemed to be on SQLServer) I'm looking for a relatively painless way to migrate from Access to SQLite, and am wondering if your library can be part of that puzzle...
I had the same thing when I started with it a few years back. Don't worry, you can safely skip the CT in the beginning and just read blogs, code, notes of all sorts to satisfaction until you are able to give back some sort of intuitive explanation; you will understand the subject better as soon as you try to formulate it for the benefit of others.
Could be. At least I'm hoping it'll be like that. My most recent experiences are trying to grasp free monads. It's probably an advanced topic but the sheer depth of theory in Haskell seems like quite the mountain to eventually overcome. So far no other language seemed to offer such challenges. Even while I was learning Javascript nothing seemed so alien and out of reach as a lot of what one deals with when learning Haskell. Then again, a year or two from now I'll hopefully be more knowledgeable and can then maybe share some entry level stuff. Obviously not every contribution has to be Turing award worthy.
Yeah, I was thinking that maybe it could be included in interface files. That's great to hear! One step closer to a nice auto complete experience.
It's going to be practically impossible to test big O with random test cases as often the worst case is a very unique test case. You could get a good idea of the average case though which is often just as useful. 
A great example is the common use of TimSort over QuickSort (for example in stdlibs of Python and Java.) [https://en.wikipedia.org/wiki/Timsort](https://en.wikipedia.org/wiki/Timsort) TimSort will be slower than QuickSort on random data, but will perform better on data commonly encountered in the wild.
This is actually a reasonably well-studied area (see [the work of Catherine McGeoch ](http://www.cambridge.org/gb/academic/subjects/computer-science/algorithmics-complexity-computer-algebra-and-computational-g/guide-experimental-algorithmics?format=PB&amp;isbn=9780521173018#fsq30XJ4O9SWGAYK.97) especially), but there isn’t a library in Haskell for it. I was actually trying to build on previously, with quickcheck-style generators for input data, but my statistics education wasn’t up to scratch so it fell to the wayside.
You could hack something together with the [Criterion](https://hackage.haskell.org/package/criterion) library. 
GHC still uses the "naive" approach you mentioned. So that can take you pretty far for sure :)
also * [`Foldable1`](https://hackage.haskell.org/package/semigroupoids-5.1/docs/Data-Semigroup-Foldable.html) * If anyone wants to revive ticket [`#13573`: Add `Foldable1` to *base*](https://ghc.haskell.org/trac/ghc/ticket/13573)
Ah that's good to know, thanks! Now that I think about it, I wonder if GHC can afford some inefficient output from the pattern compiler since later optimizations like case of case (and now maybe with join points?) can tidy things up.
Somewhat surprised that I couldn't find these functions anywhere. They're trivial once you want them, but arriving at that want seems oddly difficult. Because of the triviality, I'm guessing they usually wind up sitting in a local utility module. Which was almost the case here, but that doesn't help anyone else realize they exist!
To some degree yes. But more than that laziness limits evaluation order. So one has to be pretty careful to avoid making code stricter. I'm actually looking into extending the good decision trees paper to lazy languages/GHC but I'm currently stuck (or rather run out of steam) on commoning up equal subtrees.
`Fix f` is defined to be equal to `f (Fix f)`. Substitute `Toy b` for `f`, and you get `(Toy b) (Fix (Toy b))` = `Fix (Toy b)`. But that's not a very useful explanation. A better one is "`Fix f` can be understood as an infinite number of "layers" of `f`. Or, at least, a potentially infinite number of layers." Let's take a look at an example, `Fix []`, which can be seen as a list of lists of lists of lists of... ad infinitum. One example of this is `[]`, the empty list. Or `[[],[],[]]`. Or `[[],[[],[]],[]]`. However, writing each term like this makes its type more complicated. The first one has type `[a]`, the second `[[a]]`, and the third `[[[a]]]`. If we tried to do something like `let x = [x]`, this wouldn't resolve; `x :: a` for some `a`, but `[x] :: [a]`, and `a` /= `[a]`. But`let x = Fix [x]` works, because `x :: Fix []`, `[x] :: [Fix []]`, and `Fix [x] :: Fix []`, so the type signatures *do* work out. Using `Fix` basically wraps the value so that the interpreter can understand that it can go infinitely deep, but without using an infinite type signature. Does this clarify things a bit?
You’re on the right track. It’s easy to get confused between `Fix`-the-type and `Fix`-the-value, so let’s rename the latter. newtype Fix f = In (f (Fix f)) So In :: f (Fix f) -&gt; Fix f Done :: Toy b r When type checking the application `In Done`, the task is to unify `f (Fix f)` with `Toy b r`. f (Fix f) Toy b r This generates constraints `f ~ Toy b` and `r ~ Fix f`. The latter can be discharged but the former has to be substituted in the return type. In the end you get In Done :: Fix (Toy b) An intuitive way to think about `Fix`(-the-type) is that it represents a nested lasagne of layered up `f`s. If I give you a `Fix f` you can unapply the constructor to get at the topmost `f`. Inside that `f` you find a further layer of `Fix f`s. `Fix` is a kind of generalised tree structure, where the shape of the nodes inside the tree is described by `f`.
/u/Vaglame I am no Haskell expert by any means, but I had a good experience with `webdriver`, which as others have mentioned is a driver for `selenium`. Let me know if you still have questions. The only problem that I have had with `webdriver` (and and the root is a problem with `selenium`) is that some items, such as the Print Dialogue is considered out of scope (correctly, In my opinion) and therefore you can't programmatically interact with it. This Google Pupetteer lib seems interesting, but all examples are in node / JS land.
My favourites along those lines: * If we had a static type system, huge swathes of our test suite would go away. * If we had `newtype`, that bug that mixed up IDs of different types and took ages to unwind would have been impossible. * If we had phantom types, that bug where we applied an exchange rate backwards and had to spend ages rebuilding tables would have been impossible. * If we had monads, we make it impossible to do non-DB stuff from inside a transaction. Only the last requires a fair amount of explanation, and even then you can handwave that away and say your `Transaction` restricts what you can put in its `do`-blocks. (Another great example is how STM code often reads `atomically $ do { ... }`.
&gt; It's just over my head. I think you're wrong, and are actually going to be in an ideal position for writing stuff very soon, if you're not already there. I claim that it is very hard to capture the "beginner's mind" once you really get something (see: the ecosystem of monad tutorials). You might find yourself building something, spending a little while getting the pieces to fit and then saying to yourself "someone else might not want to go through what I just did". These posts, written with the understanding and problem-solving process fresh in the author's mind, are often extremely useful.
&gt; So far no other language seemed to offer such challenges. Yeah, this is an interesting one. Maybe it's FP-Stockholm-Syndrome, but I have come to see this as a feature, not a bug. In a lot of other languages I felt like I topped out pretty quickly, or was learning weird esoteric rules (like dark corners of how C++ template metaprogramming works). With Haskell, it seems more like the relatively simple tools we have compose in more and more interesting ways that give us much more room to explore. That said, I still believe that when it comes to getting things done you don't need to understand much beyond monad transformers. Everything else is gravy. Delicious, type-safe gravy, but you can add new techniques piecemeal.
I actually used this paper: [Compiling Pattern Matching to Good Decision Trees](http://moscova.inria.fr/~maranget/papers/ml05e-maranget.pdf) possibly with some tweaks because that paper is for ML, but ermine is lazy. I think the result falls prey to some problems in one of the recent papers on GHC's pattern matching, though. It doesn't have exactly the same semantics as trying each clause in order, because it prunes some parts of the matrix that are irrelevant for well-defined values, but relevant for ⊥. Like: f _ False True = 1 f True True True = 2 f _ _ _ = 3 If you call `f undefined False False`, Haskell's semantics say you get ⊥, because the second case blows up. But the splitting tree algorithm first branches on the second argument, then decides the second clause is irrelevant when it's `False`. I don't remember the paper super well, but this issue (assuming you want to have Haskell's value and pattern matching semantics) might fundamentally invalidate the approach. To fix it, you can't even prune from the matrix when the rows are disjoint from the constructors you've matched already.
Tran Ma did a quick and dirty version of this here [https://github.com/tranma/shitty\-complexity](https://github.com/tranma/shitty-complexity)
It seems like a practical guideline to use monad transformer in the real world. What do you think of it? Is there other similar real world guidelines out there?
I wrote [a blog post](http://www.parsonsmatt.org/2017/09/22/what_does_free_buy_us.html) on free monads that approaches it from the other direction. You may find it useful.
[Similar here](https://jtobin.io/tour-of-some-recursive-types).
I really like that you're contributing to Haskell ecosystem! But I want to share my feedback with you. I don't think it worth it to create package only for those two one-line functions. As a library maintainer, I probably won't use your package as a dependency. If I need such functions I will just copy-paste them from your package with copyright notice saying that I took these functions from your package. It's not worth to depend on package only for those two functions. Cost of adding new dependency is much higher than adding two functions to some local `Data.Foldable.Extended` module. * https://jaspervdj.be/posts/2015-01-20-haskell-design-patterns-extended-modules.html We don't really want to be in JavaScript state where you have packages like this one: * https://github.com/jonschlinkert/is-even I understand that writing build systems and package-management system is really a very difficult problem. It would be great if we could share code in smaller pieces than `package` (like functions for example). Though checkout `fragnix`: * https://github.com/phischu/fragnix Also, I would recommend to avoid adding `safe-` prefix to packages. This is not right. Everything should be `safe` by default (especially in Haskell ecosystem). It only makes sense to add `unsafe` prefix if you want to draw attention to the fact that you should use this function (or package) carefully. But the existence of your package really helps people! At least when they hoogle type of your functions they can find such functions on Hackage! Though, I guess the reason why such functions doesn't exist is performance. Consider your implementation: ``` defaulting :: Foldable f =&gt; b -&gt; (f a -&gt; b) -&gt; f a -&gt; b defaulting d f xs | null xs = d | otherwise = f xs mayhap :: Foldable f =&gt; (f a -&gt; b) -&gt; f a -&gt; Maybe b mayhap f = defaulting Nothing (Just . f) ``` I think it's better for GHC optimizations like fusion and inlining to avoid evaluating list elements twice. So this version of `maybeHead` functions should work better with the rest ecosystem around Foldable type class (rewrite rules, GHC optimizations): ``` maybeHead :: Foldable f =&gt; f a -&gt; Maybe a maybeHead = foldr (\x _ -&gt; Just x) Nothing ``` 
Great writeup, thanks.
Compare this method of `Foldable` fold :: (Foldable f, Monoid m) =&gt; f m -&gt; m to this method of `Foldable1` fold1 :: (Foldable1 f, Semigroup s) =&gt; f s -&gt; s and wonder why `Foldable1` captures non-empty structures
I'm not sure what part of this is "dependent types" vs just type level programming. I was under the impression that dependent types were types that depend on values, but this involves no such thing. I'm still not 100&amp;#37; sold on dependent types to be honest (for day to day programming that is), what I want is a really clean type level programming interface that works a lot like how value level programming does. Things like automatically lifting value level functions into equivalent type level functions that work on the \`DataKinds\` variant of the types involved. While dependent types may give me the above, I am not yet particularly invested in the "dependent" part, so it seems unnecessary to require that part just to get the above benefits. I would love to see examples of things that are much harder without \*truly\* dependent types.
I would say at this point that reflex-platform exists to make building multiplatform apps in general easier, although yes it does have some reflex-specific stuff bundled in. There is some discussion of renaming the project to better demonstrate this.
Looks like you forgot to indent too. :)
I don't know why, but these code just indent fine on PC, on mobile it's messed up.
Wow! 
For code that has IO among other effects, `ReaderT r IO` is a sensible choice of transformer stack: https://www.fpcomplete.com/blog/2017/06/readert-design-pattern You can then put configuration variables, transaction variables (`TVar`s, `MVar`s etc.) and all sorts of method dictionaries in the `r` type.
Okay so there is only one step involved when unifying the types `f (Fix f)` with `Toy b r`? Because you immediately arrive at the conclusion that `f ~ Toy b` (which I understand), so I can now use that constraint to fill in the `f` in the *type constructor* `Fix f` on the left side of the equals sign and call it a day. Meaning I was (once more) confusing type level and data level information. If the above is correct, then I am now left wondering about the right side of the equals sign. Going with your `newtype` from above, in the end I have Fix (Toy b) = In (Toy b r) if I try to unify the types, right? And `r ~ Fix f`, so that I can e.g., pattern match on the `In` data constructor, interpret my `Toy b r`, and because `r` (which is often called `next` in tutorials on free monads) is another `Fix f`, I can now lazily continue intrepreting my program? Is that the correct conclusion to draw from this? It certainly feels like I'm now understanding what's going on here, but I want to make sure.
It's a very nice blog post, strange that none of my google searches brought it up (I did get a ton of scala content on free monads even though I am not a scala developer). It does not however dive too deeply into the type signature of `Free` which is precisely the point where I'm stuck. But for everything else, it's really the best from start to finish write\-up.
The part about infinite types and lazy interpretation up to the next data constructor I get. The type signature unification and substitutions I didn't \- although I think I do now. Apparently it was a lot easier than I thought but my brain kept insisting on confusing type and data level stuff (think left and right of equals sign \+ type parameters). Because in your very first phrase you've already solved it (and it seems what I did was indeed not wrong). As soon as you fill in `Toy b` fo`r` f you know what th`e` f is i`n Fix` f on the left side of the equals sign, for the type constructor. And so... that's why the examples I gave all turn out to be \`Fix (Toy something)\` and it appears not to be the complicated black magic I thought it would be. Since I simple, once more (I thought I was done with this), mixed up type and data level stuff. So in that sense, your very first phrase is in fact helpful ;) if I interpret it correctly.
A little trick for the future, since it seems like you already figured out your problem: When you're having trouble understanding the type, and the type constructor has the same name as the data constructor, change one of the names: data Fix f = Foo (f (Fix f)) unFix :: Fix f -&gt; f (Fix f) unFix (Foo f) = f Makes it harder to get them mixed up. :)
I need to play some error-like sound in an Haskell based application whenever a specific event occurs. From what I found online, people suggested to use either SDL or OpenAL. Both of these seem like overkill. What would be the easiest way to do this? I should specify that the application is being developed for Windows.
I guess I should write up the journey to this result, as there was a lot more code involved what the final diff shows.
Using finite (usually small) datasets for model selection sounds like a perfect use case for Bayesian statistics. Tran's `big-oh` (a.k.a `shitty-complexity` linked by /u/kamatsu ) explores this via the probabilistic programming language Hakaru. Very interesting connections!
The `singletons` library is essentially one big list of the things dependent types would simplify away. GADT witnesses and existentials let you effectively transport values into their promoted type-level counterparts, and typeclasses can be used to conjure the value-level version when all you have is the type. Right now type level programming is noisy enough that this machinery might be comparatively not so big a deal. But given that this level-crossing stuff is *possible* now, it makes sense that it'd be a target for making *pleasant* once function promotion simplifies other aspects of type-level programming.
I found this really confusing when first coming across this as well. The `Fix` constructor basically encapsulates recursion, we can do the same thing at the value level fix f = f (fix f) -- look ma no recursion: sumF f ls = case ls of x : xs -&gt; x + f xs [] -&gt; 0 sum = fix sumF So we can do the same thing with type constructors; data List a = Cons a (List a) | Done Becomes data ListF f a = Cons a f | Done type Fix f = f (Fix f) type List = Fix Listf Except recursive type synonyms aren't allowed so we actually get data Fix f = In (Fix f)
&gt; this seems like an almost trivial issue _Everybody_ struggles with `Fix` the first time they see it. You’re in good company. Don’t be discouraged. It’s all part of the learning process! It does sound like you’re beginning to grasp it now. I often find when learning a new idea that it helps to forget about it, let the subconscious digest it for a couple of days, and then come back to the original article.
I believe MS Access should be OK. It uses a different Jet/ACE-based SQL engine, however the ODBC interface is uniformal. So provided there are no differences in SQL you should be good to go. Actually, if you test it out and it works fine with minor modifications, then maybe we can add a dedicated module for it and add a test suite entry for it and advertise as "SQL Server OR MS Access" library. 
I knew if I tagged you you'd name the right paper. I just remembered the "pattern matrix" bits.
There are some TH helpers in the `rank2classes` package
Given you can solve this closed form, near enough, that's not too surprising.
FYI there's an easier way to calc this: for width in range(1, 100): for m in range(2, 10): for d in range(10): D = d * 10**(width - 1) j, r = divmod(D - d * m, 10 * m - 1) if r == 0 and j &gt;= 10**(width - 2): print("{} · {}{} == {}".format(m, j, d, D + j)) 
[removed]
People should be aware that the linked document is not what people currently working on the team consider best practices. I have raised a PR to delete it from the repository : https://github.com/input-output-hk/cardano-sl/pull/3063
As erikd says, please don't take this as recommended guidelines. It is a stale document.
I would generally advise not doing that. Having a top level application `Env` type is sound advice, but if the only reason you're using `ReaderT` is to pass that environment then don't bother. Haskell is rather good at passing arguments functions to functions, so don't introduce a ReaderT just for that. If on the other hand, you've already got some non-trivial application specific monad then adding a ReaderT into the mix isn't a big deal. Why avoid it? It dosn't make anything easier. It doesn't make types or code significantly shorter (especially if you use `RecordWildcards` or `NamedFieldPuns`). It makes it harder to pass parts of the environment to different parts of the application (which is often good to keep the app modular by separating concerns).
I've been looking for functions like that often, I'm not sure why I need a package for it. - First, it only works to call partial functions and therefore is only useful for people using partial function. For example, `minimum` (as in your example) as some alternatives using either `NonNull` ([Data.NonNull package](http://hackage.haskell.org/package/mono-traversable-1.0.8.1/docs/Data-NonNull.html)) or `NonEmpty` (via the [reducer](https://hackage.haskell.org/package/reducers) package). - Second, why stop to foldable ? I would prefer a more general function which either create a Maybe (so I can use maybe on it) to have something like maybe 0 minimum (justIf null xs) but probably something even more general with signature `(a -&gt; Bool) -&gt; b -&gt; (a -&gt; b) -&gt; b`. However, there is already a package with a `bool :: a -&gt; a -&gt; Bool -&gt; a`, which is pretty much already do what we want. In fact `boolM :: (a -&gt; b) -&gt; (a -&gt; b) -&gt; (a -&gt; Bool) -&gt; a -&gt; b` is really similar to a first attempt and can be rewritten `f b -&gt; f b -&gt; f Bool -&gt; f b` (with `f` being `(-&gt;) a`). So `boolM` is in fact just `liftA3 bool`. We can then write things like &gt;&gt; liftA3 bool (+1) (*5) (&lt;10) 0 1 &gt;&gt; liftA3 bool (+1) (*5) (&lt;10) 10 50 It can also be rewritten using applicative operator instead of liftA3 like this bool &lt;$&gt; (+1) &lt;*&gt; (*5) &lt;*&gt; (&lt;10) $ 10 which in the case of your minimum example, gives bool &lt;$&gt; pure 0 &lt;*&gt; minimum &lt;*&gt; null $ xs Having said, that I don't use `bool` and will either avoid to be in this situation , pattern match or just an good old `if ... then ... else ...`. 
Also libraries like \`QuickCheck\`, and \`Hedgehog\` for generating the test data. If one wants to go further, then they have to get into fuzzing, esp. evolving/genetic algorithms. Conceptually one can be inspired by exotic fields of analysis, FuzzyLOP, and the so\-called fox\-morphism that Conal or Deihl accidentally discovered while generalising their answer to a stack overflow question.
Forgot their handle, by the guy that co\-authored haskellbook. I think he made a small series about making an ecommerce site.
Thanks for the kind words and I definitely agree with the part about giving it (my brain) time to internalize the concepts.
OK. I'll try it out and then report back. Thanks.
Is there anything that is specific to SQL Server in the ODBC.SQLServer module? (i.e. should I be building on top of ODBC.Internal, instead?)
Would you mind expounding a little on the overall direction of change in these best practices?
To make type-level programming easier, we will (re)discover plenty of dependently-typed idioms. One way to summarize this blog post is "variations on pattern-matching on the type-level boolean `a == b`", and it concludes with what is basically a dependent eliminator of `Bool`. The "values" that the types depend on have to live at the type-level. This imposes restrictions on what we can do, but even if these values are erased at run time, it is quite useful to think of that system in terms of dependent types. I agree that it is not necessary to subscribe to the full "dependent types" package, but I would say that the "clean type level programming interface" you are looking for may already be seen as Haskell's own flavor of dependent types, with type classes and type equality at its core.
Christ Allen @bitemyapp?
&gt; What pain points do you typically encounter for which there aren't good community solutions? I have to choose between fancy Servant, where the API spec is available on the type level and all its available nifties. Or just do a quick few endpoints in what ever FW I'm already using (Yesod, Spock, etc.). No community effort can help me with this choice, I'm afraid. &gt; Are there any libraries that you [wish] existed? No specifically. For REST APIs Haskell's ecosystem is pretty complete. &gt; Compared to setting up a REST API in a framework like Rails, Django, or another "productivity-oriented" framework, do you feel that there's anything missing in the Haskell ecosystem? No. Though it takes me a little longer to whip up something quick in Haskell as it forces me to describe in much more detail how I actually want the software to behave. Though more and more of this "boilerplate" work is relieves by clever `deriving` tricks and libraries like `lens` (in combi with `aeson`). 
I'm not erikd, but I can possibly provide some input: - The intrinsic effects vs capabilities thing is definitely still in use. We use the method dictionary approach for the wallet client, for the data storage layer, and a few other places. - re Pure Code: the insistence on concrete monad transformer stacks in pure code is lessened somewhat. I see mtl-style constraints more frequently in newer code. - The document's `ReaderT ctx Base` pattern is not used frequently in the codebase that I've seen. Where the doc says: `m :: (Has A ctx, HasLens B ctx) =&gt; ReaderT ctx Base a`, you're more likely to see `m :: A -&gt; B -&gt; IO a` in the newer code. Passing parameters to functions works really, really well, and you should only use a `Reader` if it really improves clarity *and* you need the flexibility for some other part of the codebase. - The `Base` monad ended up being a lot of pain and boilerplate for very little benefit. If you're in `IO`, just own that fact and run with it. - `Has` constraints end up being useful for capabilities, but for "regular values", it's basically always simpler to write and test `m :: A -&gt; IO x` than `m :: (Has A ctx) =&gt; ReaderT ctx IO x`. - Capabilities are used, but we tend to pass them explicitly as parameters rather than putting them in a `Reader`. - re Context extension: Since we're preferring `A -&gt; IO a` over `(Has A ctx) =&gt; ReaderT ctx IO a`, instead of needing an `ExtC` type, we just have `A -&gt; C -&gt; IO a`. ezpz.
When I left Seller Labs, they had a ~30k line Haskell codebase that dealt with a wide range of business concerns. Importing data from Amazon, the email rules engine for Feedback Genius, integration testing using WebDriver, high performance APIs, high performance data processing, one of the customer service backend websites, etc. The improved performance of the Haskell code vs PHP code resulted in increased usage and sales (yes, PHP's slow performance was a bottleneck for our sales; both in terms of how many customers we could reliably serve and their size) along with dramatically lower AWS costs, and the improved reliability/maintainability of the code base allowed us to iterate quickly on new features (what would take 1-2 weeks in the PHP would take 1-2 days in Haskell).
Zalando seem to use Haskell quite a bit. There was a job listing here a few weeks ago: https://www.reddit.com/r/haskell/comments/7qn2zd/haskell_jobs_at_zalando_in_berlin/
This is a milestone issue. The rule for this issue is Turing complete.
You could print `\a`, [the bell character](https://en.wikipedia.org/wiki/Bell_character)
Nothing ecommerce specific. You could describe some military app component with the same text ;)
You might find this of interest. http://www.cis.upenn.edu/~jpaykin/papers/prz_qwire_2017.pdf
Change text to List a, and Just "" to Just []
That works for `String`, and for lists in general, but not for my actual use case of `Text`.
It happened to me to use this kind of function in web forms. In this xase, I would like to have some kind of validation of the text input, giving: ``` ensure :: (a -&gt; Maybe b) -&gt; Maybe a -&gt; Maybe b ``` Which is basically `mapMaybe` in the end: ``` mapMaybe :: Filterable f =&gt; (a -&gt; Maybe b) -&gt; f a -&gt; f b ``` This class is in the `witherable` package.
It happened to me to use this kind of function in web forms. In this xase, I would like to have some kind of validation of the text input, giving: ``` ensure :: (a -&gt; Maybe b) -&gt; Maybe a -&gt; Maybe b ``` Which is basically `mapMaybe` in the end: ``` mapMaybe :: Filterable f =&gt; (a -&gt; Maybe b) -&gt; f a -&gt; f b ``` This class is in the `witherable` package. That gives: ``` ensureNotNull = mapMaybe (\a -&gt; if null a then Nothing else Just a ```
 memptyToNothing :: (Monoid a, Eq a) =&gt; Maybe a -&gt; Maybe a memptyToNothing ma = ma &gt;&gt;= \a -&gt; if a == mempty then Nothing else Just a memptyToMzero :: (Monoid a, Eq a, MonadPlus m) =&gt; m a -&gt; m a memptyToMzero ma = ma &gt;&gt;= \a -&gt; if a == mempty then mzero else pure a
I've seen cardano-sl used ``Given`` from reflection package to replace some ``Reader`` usage, which is intreesting.
The printing of data types are SQL Server-specific. E.g. `N'foo'` for unicode strings. That's the same in MS Access, but I don't know about other things.
I think the only thing “missing” is lots of examples and tutorials so it’s brain dead easy, but other then that not really 
Thanks! Y'all are clearly having a discussion that's informed by much more experience than I have, but it's good to be aware of the possibilities here and my goal is to simply work with different approaches and find out what works best for my app.
&gt; but if the only reason you're using ReaderT is to pass that environment then don't bother. Haskell is rather good at passing arguments functions to functions I would avoid passing arguments explicitly if they rarely change. You end up with code that constantly passes an `env` argument (which is additional effort for no gain: you never change the argument, so why name it?). From a glance of code, it's not immediately obvious that the `env` is _never manipulated_. That's the value of `ReaderT`, you have to have some explicit call to `ReaderT` or `local` to alter the value. Also, if you want a set of functions to not read this value anymore, just change it to `Monad m` in the type-signatures and use-sites - which are explicit. With function arguments, _all call sites_ have to be updated, and use-sites aren't explicit so you can't really make a cost estimate of refactoring work, either. &gt; It makes it harder to pass parts of the environment to different parts of the application If you want to have some parts of the application use a different reader type then that's what `withReaderT` is for.
Thanks, you are right \- my question was poorly worded and might have nothing to do with Esqueleto. Let me try to explain better: It looks like (and it's very possible I'm still doing something wrong here) it's slow to pull many items. I've profiled a function that reads 50K rows from the \`(X,Y)\` tables into a list \`\[(X,Y)\]\`, which does take more than a second. The profiler tells me that a huge share of the time is spent parsing the raw sql data into the \`X\` and \`Y\` object and the raw SQL pull (e.g. output to Stdout) runs in a fraction of the time.
This does not work because `Text` is not a list. However, if you are ready to add the `mono-traversable` dependency, then you could generalize the function to `MonoFoldable`, which has a `onull` method. `MonoFoldable` uses a type family to get the element type of its instances. This makes it possible to define instances for basically everything that is also an instance of `Foldable`, and for a lot of things more, such as `ByteString`s and `Text`s.
Thanks! I'm not even sure it's different than what you've been doing but just wanted to share how I've approached it. I'm using `hspec-snap` and I needed to drill down a bit into Snap's initiatiators so that can initiate my app with the name of the database, and then I can run ``` testApi = Test.snap (route S.routes) (S.serviceInit dbName) $ beforeAll\_ setupDB $ do describe "In the database functions," $ do ... various tests ... setupDB :: IO () setupDB = do deleteDBContent addDBFixtures ```
Oh that's nice. Clearly much better to keep all the user data in one table.
Please don't do this. It's a mess and we're in the process of removing the use of `reflection` entirely.
* The record problem. How do you easily define record structures to deal with create, read, and update API calls to the same underlying model/DB-table? We have our own hacky solution for this.https://github.com/vacationlabs/record-splicer * A strange problem/bug introduced by immutability, that doesn't exist in the mutable Rails world: ``` r1 &lt;- readRowFromDb r2 &lt;- updateRowAndSaveToDb -- whoops! You just passed a stale record! _ &lt;- doSomethingWithRow r1 ```
Using `mfilter :: MonadPlus m =&gt; (a -&gt; Bool) -&gt; m a -&gt; m a` you can write squish :: (MonadPlus m, Monoid a) =&gt; m a -&gt; m a squish = mfilter (/= mempty)
Although the advantage of Sequence is in log(n) indexing from both sides. For just appending on both sides Sequence occurs more overhead than neccessary since it does a bit more bookkeeping to enable fast indexing.
You can also make use of `Control.Monad`'s `mfilter :: MonadPlus m =&gt; (a -&gt; Bool) -&gt; m a -&gt; m a` here to get memptyToMzero = mfilter (/= mempty)
&gt; I would avoid passing arguments explicitly if they rarely change. You end up with code that constantly passes an env argument (which is additional effort for no gain: you never change the argument, so why name it?). Not doing something is certainly easier than doing something but you have to compare with the actual alternative. One choice is `ReaderT Env IO a`, the other is `Env -&gt; IO a`. At the type level it's about the same effort. At the value level using `ReaderT` means one fewer argument but means more uses of `ask` and a lot more uses of `liftIO` (and sometimes `local` and `withReaderT`). There's also the concept complexity issue. Code bases maintained by multiple people typically means multiple people with different degrees of experience. Passing arguments to functions is simple, everyone understands it. Using transformer types (directly in function types, not just within newtype defs) and parametrising utils over effect constraints is several steps beyond. I'm not saying Reader is never a good idea, but the gain is very limited.
Indeed. The current use of `reflection` in this codebase was purely an expediency to replace something worse, not an example of best practice. 
The one thing I miss the most about Servant-based APIs (which are pretty great, in my opinion) is a good way of defining the structure of failure responses. Servant makes it really easy to handle requests by parsing all parameters (including the body) into abstract types, so that you can concentrate on handling the logic, and let Servant respond with e.g. 400-errors if parsing fails. It would be even greater if there were a simple way of defining the format (of the response body) of failed requests, so that we can have a type safe way of handling bad requests. Right now Servant’s “client” function just returns either a successful (well-defined) response, or an error with a status code (and some unparsed request body). It would be great if the API could be used to define the structure of failure responses as well, and the “client” function then delivered these errors in an easily digestible format for the API consumer.
Your last example, I’m not entirely sure what you are getting at there. 🤔 Would you mind elaborating a bit? 
There are multiple slightly differening versions of the data structure in scope and you can end up using the wrong one.
Maybe try using let statements with shadowing warnings turned off locally? Of course you still need to avoid accidentally recursively defining something.
For the record problem, I'm a strong proponent of parameterization. data Ignore a = Ignored data Tag' contents meta = Tag { _tagClientId :: contents Integer , _tagName :: contents Text , _tagColourCode :: contents Text , _tagId :: meta TagId , _tagCreatedAt :: meta UTCTime , _tagUpdatedAt :: meta UTCTime } type TagNew = Tag' Identity Ignore type TagNewDelta = Tag' Ignore Identity type Tag = Tag' Identity Identity The main issue with the approach is a lack of ability for GHC to derive classes without writing the constraints yourself. In an ideal world, GHC would use `Eq1`, `Show1`, etc. for all the parameters of kind `(* -&gt; *)`, but I'm not sure how feasible this is. Nevertheless, instances are easy to write deriving instance ( Show (contents Integer), Show (contents Text) , Show (meta TagId), Show (meta UTCTime) ) =&gt; Show (Tag' contents meta) If you're feeling lazy (which I always am), you can have GHC write the instance heads for you, by trying to compile `deriving instance Show (Tag' contents meta)` and then copying over the constraints GHC says are missing. 
Looking forward to your up-to-date best practices of real world Haskell project.
This is the last major problem still standing, and should be addressed by a suitable rewrite of the core combinators ([issue](https://github.com/haskell-servant/servant/issues/841), [pull request](https://github.com/haskell-servant/servant/pulls/969)).
I just didn’t see how mutability brought anything to the table, I guess name shadowing would suffice?
I've committed a differential for this to [​https://phabricator.haskell.org/D4812](https://phabricator.haskell.org/D4812)
 &gt; In an ideal world, GHC would use Eq1, Show1, etc. for all the parameters of kind (* -&gt; *), Is this something that would be fixed by `QuantifiedConstraints` since we wouldn't need `Eq1` anymore? 
&gt; First, it only works to call partial functions and therefore is only useful for people using partial function. Which is theoretically undesirable but still a practical concern when making use of some libraries. My actual motivator was [`statistics`](http://hackage.haskell.org/package/statistics). &gt; Second, why stop to foldable ? Because that's where `null` lives. :) &gt; `bool &lt;$&gt; pure 0 &lt;*&gt; minimum &lt;*&gt; null $ xs` This is definitely a cool implementation! But I'm going to use it often, and in code that may one day need to be maintained by people who know very little Haskell, so I'd rather make it more accessible by binding it to a function with a nice descriptive name. How about `defaulting`...
Is there an 'official' implementation of this somewhere? I end up re-implementing this independently in almost every project I make.
[One suggestion I endorse](https://stackoverflow.com/a/49282010/2751851) and consider worthy of widespread adoption is using `ensure` as the name of the following, closely related, function: ensure :: Alternative f =&gt; (a -&gt; Bool) -&gt; a -&gt; f a ensure p a = a &lt;$ guard (p a) With it, you might e.g. express `filter` as `filter p = mapMaybe (ensure p)`. It is also worth noting that your function (`mapMaybe` specialised to `Maybe`) is `(=&lt;&lt;)` for `Maybe`. 
If nothing else, `QuantifiedConstraints` will allow you to simplify the instance head to `forall a. Show a =&gt; Show (contents a)`.
If you keep `r` in something like the state monad and only access it via combinators then you won’t generally have stale copies hanging around. This can be inconvenient in other ways. 
I like this better, but I'm not convinced it's a good use of the `Monoid` class, as we don't actually care about any monoidal structure. I'd be more tempted to say that any time you need OP's function, you should just explicitly write `mfilter (/= "")`
Thanks /u/chessai for making it happen!
https://cdn-images-1.medium.com/max/800/1*gh9POXppzNAgtncJj17K9w.jpeg
I agree. But there's a warning for shadowing if you enable Wall so it might make you less inclined to use shadowing.
Step-based migrations are the sort of thing you can get away with not using until you’re using a long-lived, business critical database at scale in production. Once you’re in that situation, you definitely want to be more disciplined about migrations. Step-based migrations allow you to specify how the schema changes commit-over-commit which is very nice. 
You are right to write a function and for this and share it (and don't use the applicative version ;-)). My point was more about your question regarding why does it not exist already ?
Maybe a bit bitrotted, but did you look at http://hackage.haskell.org/package/complexity
Use FFI and call [PlaySound](https://msdn.microsoft.com/en-us/library/windows/desktop/dd743680(v=vs.85).aspx)
Can you document how this would be practically used with GitHub/GitLab/GMail in place of the mobile app? That's what this is, right?
Is there any example of the performance of `&gt;&gt;=` being better than `&lt;*&gt;`? If that's the case, can define `&lt;*&gt;` in terms of `&gt;&gt;=`? I guess you could have particular circumstances where bind is somehow better - but I'm curious what those are. 
&gt; Pain points - Better swagger integration. The servant / swagger integration doesn't work for "real" projects. - API versioning. How do I test that an API is stable in a microservice setup? I want: - Quickcheck-style API mocking at runtime so I know that [(x, y) | x &lt;- versions_of_x_running, y &lt;- versions_of_y_running] are interoperable at runtime. - Introspection of types at runtime (like swagger but haskell-specific so we can depend on it). Also makes it possible to flag when a microservice update might fail. - Tooling around specifying which additions to a type are safe/compatible and which are not. Similar to protobuf where optional ones are OK. - Being able to handle updates to types where they require a transform in a unified manner. A framework for this. The dynamically typed languages have an edge on Haskell in this area because they rely much more on runtime detection of incompatibilities, simply because their type systems are less capable. But runtime checking is exactly what is needed in this case because in a distributed system you have to be able to update one component at a time, safely, and with the ability to roll back. &gt; Are there any libraries that you which existed? More ready-made authentication setups, for web and mobile development. This will mostly be targeted to GHCJS but a toolbox that handles native phone#-based auth, auth0, firebase, and the social login systems like facebook, google, twitter, ~github~ etc. A standardized refresh of the aeson serialization format would be good. There are various bugs in the default serialization which are kept for backwards compatibility, but a "v2" that removes those bugs but can still be "standard, v2" would be good. Standardized health checks and stats that plugs into common tooling like docker, datadog, prometheus etc. Opentracing should be standard (http://hackage.haskell.org/package/servant-tracing maybe, but I haven't used it). I've had problems finding a good setup for API accounting. If you sell an API commercially, you'd want to be able to have reliable stats. A replacement for HAProxy / nginx as load balancer. I think most of the load balancer stuff such as being flexible around group membership definitions, accounting, authorization, traffic prioritization, SSL certificate handling (let's encrypt) and similar would be excellent to do using a wai-based setup instead of haproxy/nginx. Full GHCJS compatibility so aws lambda, azure functions, google cloud functions and similar can be used out-of-the-box and thus the deployment models are as flexible as with node.
Unfortunately I think i need step based migrations - I have only 50k rows, but each row is a computer evaluation of a chess position and takes about a second to compute, so I need to make sure I don’t delete them. But it’s a good challenge!
I'm not surprised by this. Does your profiling involve anything other than deserialization? Otherwise it makes complete sense the deserializing data will be your bottleneck. You "raw SQL pull" is likely doing far less work, it isn't allocating data structures on the heap and running gc cycles the same way that your Haskell will be. You are comparing apples to oranges. 
If you are not primarily interested in what's hot and what's not right now, find a copy of *Graded Problems in Computer Science (1981).*
Hey I'll take what I can get, thanks for the link
Ah! Yes, that makes sense, and is basically what I had guessed. The reason it was surprising is that we have the popular `safe` package, with specialized variants of most partial functions in `base`, but not these generic combinators.
To be fair though, compared to other frameworks this problem exists in most popular ORMs. In most cases this is considered an application-level problem, or a problem for you schema and query design.
(Tangential note: to format a code block here, add four spaces before the beginning of each line. It looks better than enclosing each individual line with backticks.)
I have added detailed instructions in the readme file.
Can you elaborate on the Aeson bugs and standardisation point? 
What about `mfilter (/= mempty)`, even more general. 
`mfilter (/= memory)`
Due to immutability you, naturally, keep creating multiple, slightly varying, copies of the same DB row in memory. It doesn't take much to end up with a bug where you use a stale version of the record. This doesn't usually happen when your data structures are mutable, because each function modifies the same in-memory record. 
I don't think turning off name-shadowing to get around this problem is recommended. I'm sure there's a better way to deal with the problem I'm describing. I just haven't found it yet. 
Point-free is what we attempt to do, but it is tougher for newbies to understand and write. Basically it depends on the experience of the developer to not end up introduce this subtle bug, which is something that goes against my reason for adopting Haskell. 
Not saying that this is the most important thing to solve, just something that we have to be very careful while writing everyday code. Which ORM (from an mutable language) has this problem? I'm pretty sure that rails/active-record doesn't have this particular problem. (it might have other problems, but that's a different story) 
In no particular order, I would like the following SDKs existed to assist web development and is well maintained and well documented with examples: * Braintree Payments * Stripe Payments * Twilio * Sendgrid * Mailchimp I am sure most of these exist as somebody's GitHub repository who stopped maintaining it 2 years ago.
Unfortunately I think those are still in flux. One of the problems with the document we are deleting there is that it was very, very specific about certain partiuclar issues, in the absence of documentation of broader subjects. 
At Vacation Labs we are using it for our core travel commerce product. 
Would strategies involving linear types help to prevent some bugs like this?
There's https://scirate.com/ does that help?
That's one thing linear types could help with, yes. They ensure that a value is used exactly once, which means you can't create an updated value from `r1` and also pass it to another function. *Linear* types also force you to use a value at least once, which prevents e.g. unnecessary fetches, or ignoring a return value that signifies success/failure. If this isn't desired, affine types could be used; they're similar to linear types, but allow a value to be used 0 or 1 times.
Is a generic "tell the type checker I'm using this linear value but don't *really* use it" function legal? A la ignore :: a ⊸ () ignore = const () So we could go record &lt;- fetch foo ignore $ update record bar IMHO it's beneficial to force the developer to *explicitly* ignore return values, especially ones like success/failure return values that really ought to be handled if you want defect-free software.
Disclaimer: I'm no expert on linear types, I've just picked up some bits from other posts on this subreddit. I don't think writing `ignore` like you did is legal, but I would assume any implementation of linear types that makes its way into GHC would include an equivalent one.
**Abstraction** When building a custom monad stack you should (usually) think of it as a DSL. You are providing an abstraction and hopefully all the tools needed to solve a problem in a manner specific to the domain. Don't make your users dig into the guts of the transformer stack to perform operations. Even if the user is you. Especially if the user is you. Any time you type `lift` think "should I make an abstraction?". For example, provide an alias (or a newtype) for your monad and some helpers: -------------------------------------------------------------------------------- -- Base monad and helpers type GameM a = StateT Game IO a output :: String -&gt; GameM () output x = lift (putStr x &gt;&gt; hFlush stdout) input :: GameM String input = lift getLine getGuess :: GameM Char getGuess = input &gt;&gt;= \case [x] -&gt; pure x _ -&gt; output "\n----\n" &gt;&gt; getGuess loseLife :: Integer -&gt; GameM () loseLife n = modify (over lives (\x -&gt; x - n)) renderGame :: GameM String renderGame = render &lt;$&gt; get where render g = "LIVES: " ++ (show $ _lives g) ++ "\n" ++ fmap (\c -&gt; if member c $ _guessed g then c else '_') (_phrase g) data Status = Won | Lost | InProgress statusGame :: GameM Status statusGame = do g &lt;- get pure $ if | all (flip member $ _guessed g) (_phrase g) -&gt; Won | _lives g == 0 -&gt; Lost | otherwise -&gt; InProgress isGuessed :: Char -&gt; GameM Bool isGuessed guess = member guess . _guessed &lt;$&gt; get makeGuess :: Char -&gt; GameM () makeGuess x = modify $ over guessed (insert x) Now use these helpers. Don't `lift $ putStrLn` but `output`. Don't `modify` but `makeGuess`. There are some more minor thoughts, but with respect to monad stacks its all about abstraction - don't break your abstraction to read the environment from your reader monad underneath an ExceptT, fix the abstraction. **Safety** Even in reddit comments, `!!` bothers me. Pattern match and recover or fail explicitly a la `getGuess`. Same goes for `main`. Also, you have an off-by-one error on your `length all_phrases`. **Ease Of Execution** Use Language pragma such as `{-# LANGUAGE LambdaCase #-}` or in your case, TemplateHaskell. **Class Contracts** Type classes typically have some informal contract. There is no need to break this contract just so you can use `show` (via `print`) to render your game state, this is exactly the purpose of a function like `renderGame`. **Good Randomness** StdGen from System.Random is horrible. If you like the interface and something light then consider tf-random. 
You would implement the dropping function for each type that is allowed to be dropped (some apis need the dropping function to reamin internal) probably as a type class.
Specifically it would only include an equivalent one if it is safe to do so. Often it would instead include a proper destructor that cleans it up nicely, so for example with mutable structures it frees it, and with file handles it closes it, and so on. This might perhaps be useful to have a typeclass around, with an overloaded `delete` function that does the appropriate cleanup, if any.
IMO the name `memptyToMzero` is kind of confusing, because `mempty` and `mzero` are usually the same value (for any given type), you really mean "map mempty to mzero and x /= mempty to pure x then join" IMO `filterOutMempty` or similar would work, hell it barely needs a name since the implementation is so short.
`mfilter (/= mempty)` is so concise that IMO its close enough to any meaningful name you might give it.
I would try https://hackage.haskell.org/package/proteaaudio-0.7.0.1#readme
`witherable` also exports `filter :: Filterable f =&gt; (a -&gt; Bool) -&gt; f a -&gt; f a`. So you can shorten that to just: filter (not . null)
Thanks!
It seems like the right generalisation is toSemigroupOf :: Monoid m =&gt; m -&gt; Maybe (SemigroupOf m) ensureNotNull = (&gt;&gt;= toSemigroupOf) (where `SemigroupOf m` is `m` without `mempty`).
&gt; How do you easily define record structures to deal with create, read, and update API calls to the same underlying model/DB-table? I'm using Opaleye and vinyl records. The ad hoc nature of records lets me easily add fields or modify type of fields in a generic fashion. The types sometimes get unwieldy, and I have to use TypeApplications a lot due to almost nothing being injective, but it works.
&gt; Quickcheck-style API mocking at runtime so I know that [(x, y) | x &lt;- versions_of_x_running, y &lt;- versions_of_y_running] are interoperable at runtime. Can you elaborate? How would you get the running versions of a server? [`servant-mock`](https://hackage.haskell.org/package/servant-mock) and [`servant-quickcheck`](https://hackage.haskell.org/package/servant-quickcheck) share crucial keywords with your pain point, so might be relevant, but I don't I entirely understand it to say for sure. &gt; &gt; Introspection of types at runtime (like swagger but haskell-specific so we can depend on it). Also makes it possible to flag when a microservice update might fail. Yeah, this would be nice. You could in theory have every server provide a wrapped version of its API type as one of it's endpoints, and whatever deployment tool you use keep the mapping between services and APIs, and on an attempt to deploy every service checks that it has everything it needs or fail otherwise. But in most contexts the services are very heterogeneous - not written in the same language, much less the same framework and client libs. So to a large extent I think some Haskell library alone taking this on wouldn't do all that much good. &gt; &gt; Tooling around specifying which additions to a type are safe/compatible and which are not. Similar to protobuf where optional ones are OK. The way I'd do this is to have `servant-quickcheck`s `serversEqual` run against the two versions, but using *the old one's* API definition. This should ensure that old clients function as before. 
One issue I remember is serialization of `Just Nothing` vs `Nothing`. 
I think servant-mock / servant-quickcheck are part of the solution, I haven't looked at them to be honest. I guess I just want a more "standard" setup that includes all of this out-of-the-box. Like yesod, but to me yesod doesn't really solve the hard problems like the servant-ecosystem does. OTOH, there could be some sort of standard servant-* setup that includes everything that a normal production setup needs - like lifecycle management, load-balancing, canary testing, health checks, metrics, (open)tracing, cloud functions (ghcjs compatibility), swagger/openapi etc.
Thank you. If I got this right, GitHub/GMail 2FA works like your regular , classic key generator fob you might have used for VPN, right? Why is it that those 2FA implementations send you message in the app or even an SMS?
If only there was a way to copy the TOTP and your password. I mean, when you have a secure, very long password that you usually copy via your key store tool, wouldn't it be nice if one could combine the steps? Not everyone keep a logged in session for days but rather logs in and out on demand. It's a reason why I avoided 2FA so far. The inconvenience just wasn't worth the security improvement. Maybe a wrapper around gamgee and key store tool that runs both in the right order to have required secret in clipboard at the right time. What do you think?
Thanks a lot for sharing this, I highly appreciate it!
I would love to see examples of best practices when running Servant in Production on Docker. I've been doing this now for the past 3 months and it worked but I kind of had no idea what I was doing and was just hoping for the best. Which worked for the most part. I had weird random timeouts two times and I couldn't figure out why it was happening. But restarting the service fixed the issue in both cases so maybe it was the communication between nginx and docker rather than Servant. At one point I did benchmark my API and it seems that handling thousands of concurrent requests was no problem for Servant. So I don't think the timeouts were caused by heavy load. 
I'd generalize the type to a \-\&gt; m a (since m a \-\&gt; m a is implied). This gives you \`\`\` memptyToMZero :: (Monoid a, Eq a, MonadPlus m) =\&gt; a \-\&gt; m a memptyToMZero = Control.Bool.guard' =\&lt;\&lt; (== mempty) \`\`\` (at this point you might just choose to give up and use guard' directly)
I'm curious why you chose json for the config file. Do you think users might want to edit it by hand, or it is a common structure that can be used by similar tools?
I haven't read all of the TOTP RFC yet, but maybe you can answer this: the code is generated by using the shared secret plus time of generation, right? Is there leeway or do github/gmail time and your local device's time have to be in sync, and if so, to what degree of error (2 minutes, 15 seconds)? I know this is an RFC questions, but it's one of the things I wondered about the protocol.
Pointfree version for giggles: ``` ensure = (((&lt;$) &lt;*&gt; guard) .) ```
Hi everyone! I asked the same question on #haskell but I'm asking them here so I can reference the answers one by one. I'm looking at Haskell for writing an HTTP proxy server that does the following: - proxies all HTTP requests to some backend services, on several domains (eg. several hostnames point to this server) - requests and installs SSL certificate(s) for each domain using LetsEncrypt (lazily, on first request) - keeps an eye on the SSL certificate expiry date on each request, and if necessary (certificate about to expire or has expired), performs the SSL certificate renewal again (using LetsEncrypt, or the likes) I've been looking at something like Warp to serve as the underlying HTTP engine and then building the business logic on top of this. There are other solution that exist (based on nginx) that do this, but I'm still thinking of writing a service myself. How much _estimated_ work am I looking at? Or is this totally unrealistic? ([here's a related post about this.](https://www.reddit.com/r/haskell/comments/41jzpw/spock_web_framework_and_ssl/))
I'm a bit confused. What do you want to express that `comb` does not already express?
On my phone right now, I will reformulate the answer later. I mean a static type-checking of the intervals 
Why not just a plain helper: stuff g (StuffA x y) = g x + g y stuff g (StuffB x y) = g x + g y f = stuff g And if this is a recurring pattern you can make it a type class.
You're doing pretty well. Here are my thoughts, written down before reading your own conclusion on each snippet: AForm IO Person Assuming that `Person :: *`, then `AForm :: (* -&gt; *) -&gt; * -&gt; *` newtype AForm (m :: * -&gt; *) a = AForm {unAForm :: (HandlerSite m, [Text]) -&gt; Maybe (Env, FileEnv) -&gt; Ints -&gt; m (FormResult a, [FieldView (HandlerSite m)] -&gt; [FieldView (HandlerSite m)], Ints, Enctype)} (m :: * -&gt; *): the m could mean monad - that is, that most functions operating on AForms require m to be a monad. What is a HandlerSite? The return type is weird - a big tuple with a function as the second element. This leads me to believe that I'm not supposed to work directly with that type, instead using combinators to chain AForms together.
Would it make sense to optionally delegate secret management to a local key store? There might even be a Haskell based password manager.
Isn't it possible to express affine arguments using a special arrow? It seems to me that the regular Haskell arrow `-&gt;` means that the argument is consumed `&gt;= 0` times, and that we could extend this to also be able to express `&lt;= 1` times (affine).
It `protolude` this is called `guarded`: * https://hackage.haskell.org/package/protolude-0.2.2/docs/Protolude.html#v:guarded
Perharps Liquid Haskell can solve this issue https://ucsd-progsys.github.io/liquidhaskell-blog/
/u/Tayacan thank you for the reply. That last bit - that the return type is weird, leading you to believe that you're not supposed to work with the type directly - is incredibly useful. Something I'll certainly watch up for in other libs.
I think its just that there are different ways to do multi-factor auth and each implementation chose what's suitable for them. There are pros and cons to each approaches.
`(&gt;&gt;= view (non mempty))`
Usually the server will accept OTPs corresponding to multiple clock steps to allow for clock drifts. For e.g, a server could be configured to accept any valid OTP in the range +/-2 minutes from current time.
Yay! It was a pretty fun question to answer, btw. I haven't worked with Yesod at all, so the last bit is pure guessing (but a *confident* guess). 
This is amazing! I've been using https://github.com/poolpog/bash-otp for over a year now, I'm glad to have a dependency free alternative written in Haskell. Thanks a lot for your work :)
Will this make building Windows apps easier, at some point? :)
For completeness, there's also a `pass` extension: https://github.com/tadfisher/pass-otp
Just that it is human readable, easy to debug if it gets corrupt, easy to parse in Haskell etc. I don't think there is any common format between 2FA tools.
May be. I haven't really thought about it. If you (or anyone else) want to give it a shot and send a PR, that's definitely welcome. You'll still need some sort of master password to unlock the key store though. So it's not necessarily more secure.
I'm still looking for a way to more easily login with password decrypted from store and code generated locally, ideally with comfort. There's an OTP extension for the pass project at https://github.com/tadfisher/pass-otp. I don't really like that pass stores the name of a password in its filename. Some of the passwords are for sites/services you don't want visible that easily via `ls .store`. Currently evaluating https://github.com/conradkdotcom/rooster for password storage and how to combine it all with gamgee. Maybe I should just get a usb key fob instead of mucking around. My idea is that I would get the password to gamgee's tokens from my common key store and then first copy the password to github.com to clipboard and then the otp. This would require a protocol, maybe via a browser extension like https://github.com/browserpass/browserpass so that I don't have to switch back and forth but enter only one password and then automate it. I suppose this would require auto-filling the user/password and then merely clipboard the otp. Man, I hope this is more reliable, coherent, and simpler with usb key fobs. I imagine you insert those in a usb port and then have to press a hardware button on the usb device which will then trigger actions on the smart chip and its tools listening on your machine.
Maybe linear types (if that ever lands) would be able to solve such an issue, by guaranteeing that r1 is consumed exactly once, and no more. 
&gt; It `protolude` this is called `guarded` Good find; thanks. &gt; And I don't see actual use case for this function. For instance, specialised to `Maybe` (`(a -&gt; Bool) -&gt; a -&gt; Maybe a`) it upgrades a predicate so that, if the test succeeds, the result carries the value that was tested. It occasionally can be a nifty little thing to have.
You can either use Liquid Haskell or the \`refined\` library: [https://hackage.haskell.org/package/refined](https://hackage.haskell.org/package/refined) with refined: \&lt;code\&gt; import Refined log :: Floating a =\&gt; Refined NonNegative a \-\&gt; a absP1 :: Num a =\&gt; a \-\&gt; Either RefineException (Refined (GreaterThan 1) a) absP1 = refine . (1 \+) . abs \&lt;/code\&gt; You can also have some compile\-time checking with 'refineTH' and \-XTemplateHaskell
Hi there, Today i've released the AutoBench system, which does something similar to what you are describing. It does not give asymptotic complexity bounds using big\-oh notation, but it does use runtime measurements to approximate what I believe is called "empirical time complexity". It uses QuickCheck to generate random inputs of different sizes (for example, lists of increasing length as you described) and then benchmarks the runtimes of one or more test programs on the inputs using Criterion. The runtime measurements are then analysed using ridge regression in order to approximate the time complexity of test programs. All of the results are plotted on a PNG graph. You can find the system on [GitHub](https://github.com/mathandley/AutoBench), and my PhD supervisor and I have just submitted a [paper](http://www.cs.nott.ac.uk/~psxmah/autobench.pdf) introducing the system to Haskell Symposium. I hope you find it useful. Feedback/comments/bug reports are welcome on GitHub! Cheers, Martin 
Indeed. However, if you work with only pure function, it's easier to save everything at the end. Another way is to separate totally the DB types and the useful ones. The useful ones are the actual models, where the DB ones are just here to model the database itself (if that makes senses). 
It's possible to do at least some static checking of intervals in Haskell directly using the [Refined](https://hackage.haskell.org/package/refined-0.2.3.0/docs/Refined.html) library; I've put this together for your small example here: ([github](https://github.com/adituv/refined-test/blob/42d63c1eb7d23e3ce0af9450e5bf3958703f9348/src/Main.hs)). This is going to be somewhat limited though, and you'll probably need something like LiquidHaskell (as already mentioned) for some intervals that go beyond the power of Haskell's type system.
I just want to point out that while I agree with this, I hope everyone understands that making it brain dead easy is a very, very valuable thing. Especially for a language like Haskell which would be able to pull a lot more users in with resources like that available.
Better now?
In response to the instance being missing from 'refined'; There are some things I haven't added due to just not having thought about them. The instance you provide there, on first glance, should be totally safe.
Here's how this might look in Liquid Haskell: ``` module Logs where import Prelude hiding (log, abs) import qualified Prelude type R = Double {-@ log :: {r : R | r &gt; 0.0} -&gt; R @-} log :: R -&gt; R log = Prelude.log {-@ assume abs :: r : R -&gt; {v : R | v &gt; 0} @-} abs :: R -&gt; R abs = Prelude.abs {-@ absP1 :: R -&gt; {v : R | v &gt; 1} @-} absP1 :: R -&gt; R absP1 = (1+) . abs comb :: R -&gt; R comb = log . absP1 -- This will fail since the argument is not always greater than 0. badLog :: R -&gt; R badLog = log ``` You should be able to paste this on their [demo page](http://goto.ucsd.edu:8090/index.html) and it should work. LH automatically figures out comb is safe and that badLog isn't safe. I assumed the result of abs is positive. 
Yes, that would work. I 
Hutton posted a paper on `autobench` on Twitter today, you might find it interesting: http://www.cs.nott.ac.uk/~pszgmh/autobench.pdf
You could turn these into records and give names to the left and right hand sides. This would be one of the few cases where record accessors are safe with multiple constructors. Another possibility would be to use `Data.Generic` functionality, though that's probably way overkill for this specific use case.
Try to include "start" into the argument list. Maybe that helps.
These duplications are all warts hat arose from the history of the Haskell standard library. It is best to ask yourself what you really want to say when you use these functions. This is important since technically you could use `traverse` and `foldr` with `Maybe` instead of `fmap` and `maybe`.
I'm not sure it's possible to give a meaningful answer to this question. If you're an expert in all of the things you mentioned and Haskell then it should be trivial. If you're inexperienced with all of it including Haskell then it will be a ton of work.
Or even the (uselessly?) more general `fmap ((&lt;$) &lt;*&gt; guard) :: (Functor f1, Alternative f2) =&gt; f1 Bool -&gt; f1 (f2 Bool)` ;)
I'm finishing* up The Haskell Book and was wondering where to go next. I have Real World Haskell on my radar, but I've read it's a bit dated. I'd love to get some advice on how I might proceed. I'd like to tackle real problems in a real way that real people use Haskell. I do have an idea for a project, a fairly straightforward web app for taking notes is the core of it. I'm looking to use Haskell on the backend and Purescript or Elm on the frontend. I'm a very experienced webdev so this is probably a good place to start. I've done a few Hackerrank problems but those kinds of things have never made me feel like I've particularly improved at *programming*. Also, graphs in Haskell are way more complicated than I thought they'd be! But they brought up comonads which are really interesting! Writing a small graph library might be a good way to improve, but I think it's a little out of my reach right now (I've been looking at the inductive graphs paper and the zipper comonad. My idea was for a regular grid with a 2d zipper for relative up-down-left-right, but it looks to be not so simple.) *I skipped the chapter on parser combinators (I plan to come back to it later), but I'll be finishing the two chapters on monad transformers. The rest of the book I'll pass on (I already skimmed the rest and it looks like things I'll be better served just gaining an intuition about through use) and I already have mentioned an idea I have for a project.
You should have single `where` after all guards. Like this: ``` foo x y z | ... = ... | ... = ... where localFun = ... ```
oh, so i cant have a `where` in the midst of the guards? it has to be after?
I think the where-clause needs to come after all guards. (Btw, it is common to use ‘otherwise’, which is equal to true, for the catch-all case of a guard.)
&gt; (Btw, it is common to use ‘otherwise’, which is equal to true, for the catch-all case of a guard.) Is that personal preference or common haskell practice?
Common haskell practice. It's what the value `otherwise` is designed for. 
Correct. The where is not tied to the guard, but to the function definition.
Yes, but it's worth pointing out that due to laziness the values in the where clause will only be evaluated when they are needed, so you don't have to worry about "extra work being done" for the where statements that are for other branches of the guard.
The Stripe client I'm using at work is pinned to the 2014 version of the API, which is missing some crucial features. Just bit me last week.
Hi! Thanks for replying. I'm experienced with the underlying HTTP based stuff (shameless plug: I'm the backend and infrastructure lead at [CentralApp](https://centralapp.com)) and I have about 6 years with Scala under my belt now. But I'd like to author new services at CentralApp in Haskell instead, in which I have about 8 months of experience. While I _will not_ call myself experienced with CT yet, I do have a strong willingness to learn and I'm aiming at Haskell because it enables me to learn. Moreover, its just a more beautiful language (readability, similar performance to Scala etc.), so I'm also looking at developer ergonomics here.
[`Data.Bool.otherwise`](http://hackage.haskell.org/package/base-4.11.1.0/docs/Data-Bool.html#v:otherwise) is defined otherwise = Bool
I wasn't aware of the refined library, that looks terrific. Is it production ready ?
Maybe this would be better asked on the Purescript subreddit? I mean, you might get lucky here, but your chances oughta be better there :)
Noob followup question: this makes sense for code that has to run in `IO` in the end anyway, but what about pure code? eg suppose one has a simplified web app: Web IO &lt;--&gt; App logic &lt;--&gt; Database IO | | | +----- Logging IO -----+ where we want to keep the app logic pure, quickcheckable in isolation etc. I understand how to achieve this if all its dependent effects are wrapped in monads (via tagless final, free, whatever). But if the IO components are simply `Env -&gt; IO a`, how does one structure the logic component so it avoids being hardcoded into the `IO` unification gravitational well?
u/chessai maintains refined and uses it in production!
Great organization, great speakers, great venue, lots of chatting with many new and old friends, a few weather glitches (though the low clouds hanging over Zurich lake after the rain against the hilly backdrop are very pretty). Personally, I'm getting zero coding done but having a really good time. I'll definitely return next year ! 
You might prefer `let` bindings, since those are a part of the RHS of your definition; i.e. it can be per-guard. foo x | bar x = let barLocal = ... in ... foo x | baz x = let bazLocal = ... in ...
One of the things I love about Zurihac is the community. Every year when I come out here it is an opportunity to connect with old friends and make new ones. I'd like to thank the Zurihac committee for making this possible. You folks are doing a bang-up job, and somehow make it look effortless, which is all part of the magic.
I think you should find it pretty approachable. You definitely don't need category theory to do this kind of thing in Haskell, but there may be some things you run into that require learning more of Haskell's advanced concepts than others. For example if you decided to go with Servant instead of just working with Warp directly then you might have to slow down and figure out all of the type-level stuff that Servant does. (I'm not recommending Servant for your scenario btw, I think you're on the right track with just using Warp directly, but it's a good example). One type of risk you might run into is that you might implement a solution that would work in some other language (manually doing IO to shuffle bits around or something) that will work in Haskell but will end up having bad space/time complexities or other problems due to laziness or something similar. My suggestion on this is to just power through and get stuff working as much as you can and then seek feedback here or on IRC/slack and people will help you upgrade the rough parts. The reason I suggest trying to power through as much as possible at first is that, at least for myself, I find it much easier to grok alternative solutions if they are replacing something I had to puzzle out the hard way the first time. That being said the other caveat is that if you find yourself spending way too much time on something upfront (especially something that feels like it should be easy) there's probably some alternative approach that you may not be likely to think of on your own but will be at hand for more experienced Haskellers, so in those cases ask for help as soon as you recognize the situation.
I'm a beginner in Haskell and when I got introduced to it via a university class, I was presented `let` and `where` and told I could use both. And honestly, I feel like `where` matches my thought process better. It's how I feel akin to `else if` and switch statements...I invariably become dependent on one and sorta ignore the other...
u/maxigit yes, i use it in production, it is very useful, lightweight, and i can stay within the confines of GHC Haskell (i.e. don't have to use Liquid Haskell), ask me if you have any questions
This is exactly the reason that both `let` and `where` were originally included in Haskell. `where` scopes over all the guards of an equation at once, and `let` applies to one guard at a time.
Lists in Haskell are just normal (inductively-defined) data types defined like data List a = Cons a (List a) | Empty The time complexity of append/prepend is because the nth element of the list is _nested_ n levels deep: Cons 1 (Cons 2 (cons 3 Empty)) The simplest way to make this clear would be to make a go at defining `append`. People like to describe `[a]` as a "singly linked list" but I don't think this is the most productive since there are proper mutable linked lists (e.g. `Chan`) which have a very different flavor
```getLine &gt;&gt;= print . sum . map read . words``` Monads ftw!
Only C programmers. C++ programmers can just use input streams and use a while loop.
Funny to see this list, I was just about to write something to send mail through Sendgrid this upcoming week (it's a service I've never used before). My needs are extremely simple: send plain-text transactional emails, no attachments. For this use case it looks pretty easy, though. Have you built a client already?
I'd like to know too :)
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/clojure] [Motivation for Monads](https://www.reddit.com/r/Clojure/comments/8pyxk8/motivation_for_monads/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I also wrote some of what I see as the motivation for monads a few years back. It may also be of interest for those of you reading this. http://imh.github.io/2016/05/26/why-monads.html
I implemented something like this in Intero for GHC 8.2 https://github.com/commercialhaskell/intero/issues/524 The UI is that you type _ and that triggers a completion call and pops up typed completions. Looks like I can throw that Haskell code away and switch Intero for Emacs to use the compiler messages for hole suggestions for GHC 8.4 onwards! Nice work Matthías!
Oh wow! I wasn't aware of this in Intero. I definitely should have included it in related work! IDE integration would be awesome. I made sure to make the output very configurable via flags, to facilitate parsing. I hope it works well in practice!
What a shitty discussion :)
Really nice work! Looking forward to using this A LOT. One minor correction: The PureScript version of this also considers local identifiers contrary to what it says in the paper: ``` listMap :: forall a b. (a -&gt; b) -&gt; List a -&gt; List b listMap f = case _ of Nil -&gt; Nil x : xs -&gt; f ?foo : map ?bar xs ``` produces suggestions for both `x` and `f` (Proof try.purescript.org/?gist=65bf5a6367233ad6f0cdd9d0031d224a) I'm super excited to (in good old PureScript fashion) steal the ranking algorithm for suggestions from GHC and put it into the PS compiler :D 
Oh no! I tried it out and it didn't work for me then, and looked at the PR to see what it did there and also asked on #purescript, but apparently I screwed it up. Sorry! I'll make sure to correct it when I get the chance.
Agreed.
Indeed.
I found [this diff](https://github.com/ghc-proposals/ghc-proposals/pull/143/commits/6e7a9cc758f22d87ebb820f9796a76c8d0af281d) also somewhat amusing. Also &gt; a language wildly different from modern Haskell with `-KitchenSink.` 
Fixed :)
I wasn't really confused by `*` but datatype promotion threw me for a serious loop at first. I only really got an intuition for it after seeing `Type`.
Bringing back the golden age of every Haskeller writing their own monad tutorial I see ;) 
My perhaps overly simplistic way of explaining them is, equations can be commutative &amp; associative, and sometime monadic, where the sequence of evaluation is important... In an imperative world everything is monadic. In a concurrent, lazy world, you really have sequencing has to be specified explicitly...
[removed]
Needless breaking changes leads to great pain and sadness. 
Generally, I agree with this position. However, I have two counter-arguments: * I explain in the proposal why this breaking change isn't needles. If you disagree, please share your position under the proposal so I can address your concerns. * The "pain and sadness" shall be avoided thanks to a careful migration plan. First, a warning is introduced into -Wcompat. Then it makes its way into -Wall. Then it gets enabled by default. Then the extension is marked deprecated. And only after all these steps, spaced by 2 release waiting periods, we may start considering removing the functionality. I take this concern very seriously. * Lastly, even if we consider truly needless breaking changes (and I don't consider this one to be such a change), they might still be a good thing if they reduce the surface area of the language, making the spec smaller, the implementation simpler, and the language easier to learn. There are always trade-offs to consider.
I agree but I rather have a shitty discussion then COC style censorship: https://github.com/anp/rfcbot-rs/pull/210
There is currently some work being done on trying to add this to Agda. I don't know the status of it though.
For what it's worth, Richard has some students looking at [#8809](https://ghc.haskell.org/trac/ghc/ticket/8809) this summer. We chatted at length about what this would look like when I was visiting last week. Hopefully by the end of the summer we will have a nice story for including rich, structured data in error message documents. This will make IDE integration significantly easier to achieve since we can avoid parsing error messages entirely.
Another great episode, thanks! Keep them coming! :D
[removed]
Heh. I will be extremely impressed if someone can actually learn to use monads from this post.
True, it's a bit short on elaborate metaphors for that.
I have some code that I wrote, but I don't know why it works. Sorry about the formatting; I wrote this for a code golf competition. type family a+b where Zero+b=b;s a+b=a+s b type family a*b where Zero*b=Zero;s a*b=a*b+b class(a#b)c|a b-&gt;c instance a*b~c=&gt;(a#b)c [Try it online!][TIO-ji95tujj] I understand how the type families work, but I don't understand how going from the world the multiplication type family `(*)` to the multiplication type class `(#)` works. Especially how the functional dependency is not violated. Is the equality constraint involved in making this work? [TIO-ji95tujj]: https://tio.run/##nVPRasIwFH3vV1zwQavLYNUnZwviVMbmHEwZjL3cpNEG2lSayCZz@3WXtKXT6UBWaHty7uGce9uEoop2DDUEIPAyUtDr1YfTUd35IDW47z@M5/3xECbrWItHzDCZbVZ8EKNSXF3AaC2ZFqnE@IavuAy5ZCLnY/4uaMxvpdIomaXmpspEiIesdZuueIY6zcxykJpShkLqOyHDsj7CRMTGFmrk0wlRI7zwLC3Q05oxwJ02MlhY3QawReEt4hnPZS3q02tlSR9bCqhzIG3uS5vUty@rNtDcLeowO2kDa9RlWwRKAuaIsnur@mJ@UFSLFiZgRMDAh0bNLbBTeMCMK30FuAUSYBmqLdXt4o9lYwKNfKTjp23NNdffJUDXD8qY/VTvONX7nWotTnhWlt6hZfvYsv3PQfJlldM@zOkc53TOzTmVedbn69gezBFwHM6iFAiHelcXP@tVlsirULtCnTpsYRkxAeRZpkSJZBWLhbA7nuQjEVZtb1VoEqGUkEuScB2loSpO4O4b "Bash – Try It Online"
/u/angerman is what you mention possibly related to what I found 10 days ago, `COLLECT_GCC_OPTIONS` being used between `gcc` and `cc1` to pass command line arguments, and the length limit of environment variables being exceeded, also on Windows (I found it on Linux)? * https://github.com/NixOS/nixpkgs/issues/41340 * https://github.com/haskell/cabal/pull/5356
Nice! I suggest using a lambda for the legs.
The benefits of this proposal are so inconsequential that I don’t think it’s worth doing..even if it is more “technically correct” or aesthetically pleasing. Hard for beginners is a pretty weak argument. LYAH (IMO still the most simplistic and approachable teaching resource) addresses `*` fine. It’s short explanation made it so I immediately understood `*` for all time. And that was when I was an FP beginner.
Hi /r/Haskell i'm new to PLT(Programming Language Theory) and i've been reading through old discussions and posts about the theory-related things that go under the hood with Haskell such as [this](https://www.reddit.com/r/haskell/comments/8m060w/mathematical_introduction_and_foundations_for/) and I was wondering if there was an active Haskell project that works on extensively focus on Formal Verification or anything theory related that's actively maintained and has a good community surrounding the project around it.
Shouldn't this proposal also suggest removing the `#` kind syntax for consistency?
I don't remember the name but the is a subreddit for Haskell videogames
This kind is already gone.
eggcellent suggestion sir
&gt; are so inconsequential Depends on who you ask. If you're already used to `*` meaning `Type` and you stick to Haskell98, then yeah. Maybe a sizeaable portion of Haskell users falls into this category and I can see why the proposal doesn't appeal to them. If you venture beyond Haskell98 and start using type-level features, you quickly discover the problems described in the proposal. And you can see people right in the thread telling you that `*` confused them. So there are people who would greatly benefit from the proposal. So, yeah, maybe you don't have much use for the change and it's inconsequential for you, I understand that. But for me and some other people it has palatable positive consequences. And I'm saying this despite the fact that I love the `*` notation, especially when it's a Unicode ★. It looks pretty nice, but I'm willing to give up aesthetics in favor of simplicity and consistency.
*smiles as Jaron Lanier*
Dunno what the Calculus of Constructions has to do with censorship...
Yes. This looks pretty. Much identical. I didn’t expect this to break on Linux that quickly as argument limit is usually much larger than ok windows and macOS.
&gt; Personally, I'm founding a startup, and I'm building our app in Clojure. Overall, the language is great, and I honestly don't think that haskell would have been better for us (for a variety of reasons that aren't relevant here). Perhaps your reasons could be worthy of a separate post though? I am curious what your reasoning is, and how Haskell can improve to get rid of those reasons.
I don't really get what you're after here.
In no particular order: 1. Learning curve. I have more experience in clojure than in haskell, and my co-founder had some scheme experience in college. Even then, going from that starting point to actually working in clojure professionally was a pain. I have a feeling that haskell would have made that process even harder. This is something that can probably be worked on, but some of the difficulty is inherent to the language -- haskell simply has more concepts that you have to pay attention to. 1. GHCJS has/had a lot of rough edges. I had trouble getting stack, ghcjs, and reflex to play nicely together, the library situation didn't seem optimal, and builds were taking longer than I'd like. I wouldn't be surprised if some of these issues have already been fixed, but it's a bit late to switch languages now. 1. Server-side haskell seemed to have a decent number of libraries, but there isn't necessarily a haskell api for random service X. If there isn't a haskell api, I have to write the code myself. However, everyone always has a well-tested java api for their service, and calling a java library from clojure is a lot easier than rewriting the library in haskell. For example, plivo wrote a java api for their service. It's sort of a pain to use from clojure, but it works well enough. Technically, someone wrote a haskell api for plivo as well, but it had 2 contributors and hasn't been touched in 3 years. I'm a lot more comfortable depending on the java version. As a side note, I also really like purescript overall. However, its library situation (and in particular, its server side library situation) is far worse than ghcjs's, which makes it a bit of a non-starter for me at the moment. And the learning curve is just as bad (if not worse). Overall, I don't think that haskell is a bad option in general. However, I do think that it was a bad option for us when we had to make a decision, and clojure has (mostly) worked out pretty well.
That said, on the topic of learning curve, I think part of the issue is that when you are writing code, runtime errors can be easier to figure out than type errors. You simply have access to more information at run time. "Function X expected an int and got '5'" is easier to parse than "Can't find a num instance for type [Char]", since you can see the actual values involved. Sure, once you are maintaining code, this advantage flips around, since the type checker can point out type errors in code that isn't tested, and it can do so faster than you can run a large test suite. However, new haskellers have to get through the painful side of the typechecker before they can experience the benefits.
See [SAW](https://saw.galois.com/) and [Cryptol](https://cryptol.net/) for the verification angle with some roots in PLT but those projects are more of a beneficiary and not a motivation for such language research.
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://saw.galois.com/) - Previous text "SAW" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
Well, I do prefer the grumps to the censorship.
I like to use `where` when you can write your function in really concise way and understand separate parts of it in parallel. Like this: ``` foo = foldr myAccum startingValue . map toSomething where startingValue = ... -- don't need this if it's something like 0 or Nothing myAccum = ... -- could be really huge function, like, 5 lines or even 6 toSomething = ... -- some mapping function ``` Now you see from `foo` definition that this functions maps something with some function and then folds result with another function. Now you can read definition of those functions in parallel. Don't need to keep them both your head or your context to understand them both. And such code looks cleaner than the same with `let` (at least to me).
The slowness of package installation is really difficult for my driving adoption -- I come from a Node.js background where `npm install` might take 5-10 minutes and people find that unbearably slow, but `stack build yesod` when you're starting fresh could take, like, an hour. Is there some better way to not totally drive away my colleagues who are interested in trying Haskell?
Heh, it's almost like we want some sort of cacheing build system like those used for large Java, C++, or C projects. Bazel or Buck would be neat. However, your situation also calls for a shared compilation cache which would be cool.
Perhaps if [Dynamic Witnesses for Static Type Errors](https://ranjitjhala.github.io/static/dynamic_witnesses_for_static_type_errors.pdf) were implemented...
I think [nix](https://github.com/Gabriel439/haskell-nix) is probably your best bet. Binary caches will avoid compilation most of the time.
Can you give some examples of what is missing? For example, https://haskell-servant.readthedocs.io/en/stable/ has a tutorial which introduces the basics of what Servant is. What are you missing from a tutorial like this? In my opinion, the challenge to Haskell newcomers wrt. Servant is understanding how types are used to *describe* an API, using types ( without actually implementing it) and then subsequently 1) providing an implementation for the API you've described -- where the compiler can catch a lot of errors in the implementation because the types of the implementation has to match the API (type) description -- and 2) querying that API, which only uses the API (type) description in order to know what type to take in as parameters and return as result.
What is the point of submitting this link? Do you want to share your solutions? Or you want to gather feedback on your solutions? Or you want to ask others to join your repository and submit solutions to you?
&gt; I think I would prefer attaching substructure to the type rather than the function arrow, at least in some circumstances (e.g., all uses of this type must be linear, &amp;c.) In which cases would you prefer this? As I see it, the notion of consuming an argument is a property of a function/transformation, which is described using an arrow.
Yes, I'd thought about that :)
My immediate pain point from using Servant is it's ever changing API. When I use it in a lib I have to have like CPP with like #if/#else for 3 slightly different versions of the API. I am very close to give up on Servant and to rewrite my code with something else, like wreq or similar which has more stable API
&gt; 1. Learning curve Having more prior experience in clojure (or similar) than Haskell (or similar) is definitely a valid reason, not much to do about that except try and make Haskell more popular and teach it earlier so that more people understand it. I do think that given zero prior experience in any sort of programming, that getting productive in Haskell isn't really any harder than most other languages (might be easier than Java/similar tbh), it's just that so many people do have prior OOP / Imperative / non-pure-FP experience. Also more high quality teaching materials wouldn't hurt. &gt; 2. GHCJS As of now GHCJS seems to work quite nicely in my experience developing/deploying it. I use reflex-platform which works very well, my only complaints are that it could use a rebranding (it's not reflex only, I use it for miso) and perhaps not having to use git-submodules. It has incremental builds and all that good stuff. Library wise I haven't really felt any pain points with GHCJS so far. &gt; 3. Api libraries Another issue related to popularity, it would be really nice if Haskell was more popular so that more of these random API libraries showed up, particularly considering how easy things like servant / servant-client make it to build them. Being able to actually compile Haskell to JVM (I know about frege, I want real Haskell) would also be pretty cool, might help boost Haskell's popularity to the point where such cross-compilation stops being necessary. &gt; 4. purescript Yeah reasonable, I personally am not a huge fan of purescript, it's a cool and well designed language but it's probably going to become obsolete once Haskell has full WASM support, to me it seems as though it just fractures Haskell front end development into two communities.
I dunno... There's *a lot* of code on Hackage using `*`. Has there been any attempt the quantify the breakage? I'd expect this to be just as breaking a change as AMP, and personally see it as significantly less beneficial.
They look like a spam account forking random crap and posting it to different subreddits for easy karma
The use of \`ask\` can definitely have downsides if you wanted to access the reader in all your \`where\` clauses, yeah. \`liftIO\` is a pain, but it seems all projects end up on a monad stack anyway. I take your point that it's a trade\-off. \&gt; There's also the concept complexity issue. Code bases maintained by multiple people typically means multiple people with different degrees of experience. Passing arguments to functions is simple, everyone understands it. Using transformer types (directly in function types, not just within newtype defs) and parametrising utils over effect constraints is several steps beyond. I'd agree that it's easier for newbies. One the one hand, it's not the best to be constrained to things only a newbie would immediately recognize, on the other hand: in a new codebase, we're all newbies and feeling a bit stupid. \`foo :: Env \-\&gt; IO (Either Error a)\` can be easier to grok than a combination of reader and ExceptT. \&gt; I'm not saying Reader is never a good idea, but the gain is very limited, and it doesn't come for free. It doesn't come for free, I agree. I do think the gain accumulates, but we covered that.
https://www.reddit.com/r/haskellgamedev/
It’s true that linearity &amp;c. are usually considered properties of functions, not types themselves. But for resources like stream handles and unique (owned) references, I prefer something like C++ or Rust, where you can say “This type can’t be copied”—in C++, by deleting the copy constructor and only implementing the move constructor—because if you’re modelling a resource with a type, then it’s useful for the *type itself* to enforce the resource semantics. Linear arrows are easier to add to an existing language like Haskell that wasn’t originally designed with a concept of substructural rules, but AFAIK that requires you to use the module system to encapsulate resource patterns, rather than the type itself.
Thanks !
Slightly different, but related: there are a bunch of algorithms that give worst-case execution time bounds (tight rather than asymptotic) for functional and imperative languages. The state of the art for functional languages is (as far as I know) [Resource Aware ML](http://www.raml.co/index.html), and the state of the art for imperative languages is [Compositional Certified Resource Bounds](http://flint.cs.yale.edu/shao/papers/ccrb.html) ([source code mirror](https://github.com/taktoa/c4b)). The latter has the benefit of being a _compositional_ static analysis, so it can infer a resource bound for a single function and then use that resource bound at callsites without having to do any inlining (many static analyses require all functions to be inlined, preventing them from being used in large codebases).
To take the opposite side of most here, I'm quite happy whenever someone tries to clean up a language and make it more consistent, especially when it seems to also be motivated by improvements in future features. I don't agree with the argument of not doing it because of code breakage: - It's an incredibly simple fix - There's a very long migration window - I believe fewer and fewer people need to support older versions of GHC, heck on macOS you can't even run pre 8.0 anymore...
Stack has support for building code in a Docker container. By default, it uses the `fpco/stack` images, but you can specify your own. This way you could set up a Docker container with prebuilt dependencies for Yesod development. And if your colleagues end up not liking Haskell, they can wipe any trace with two or three commands. PS: The Poor Man's version of the above would be to copy the `~/.stack-work` directory to your colleagues' computers.
I'm not a spam account. I just shared my github repo.
I agree. Let's at least *start* the transition.
Not sure if this is a good enough suggestion, but `-Wall -Werror` would've caught this (an unused `r2` variable), definitely helped me in a similar situation few times.
Do you know about [Eta](https://eta-lang.org)?
Oops that was the one I meant to say. Yeah I do. I really do not like the decision to not make it real Haskell. I love projects like GHCJS that encourage more people to come into the Haskell ecosystem and do more things with it and create more completely compatible libraries. Things like purescript and Eta might bring more people in, but it brings them into a fractured and disconnected part of the community.
It was never really there, actually. \`#\` was printed in error messages, but it could never be written in programs. It doesn't appear in GHC 8.x messages.
&gt;is /u/bitemyapp @bitemyapp Yes, I'm Chris Allen. I've been uploading streams of myself working on stuff. The aforementioned ecommerce app is Lorepub. The streams are here: http://youtube.com/c/bitemyapp There's other stuff on there but if you're curious about ecommerce then Lorepub's what you want to look at. This is very early stage, but I'm also working on https://github.com/fpco/badgers with a client.
I've animated the legs now.
I've been looking into writing some API bindings for infrastructure at work using `servant-client`, but I haven't been able to find many worked examples of dealing with various auth schemes. I'm currently trying to read through the `amazonka` and `gogol` family of bindings to pull some tricks out of them, but it's so far not obvious what the correct way is to implement that piece of API interaction.
The four-legged creature is definitely cuter.
I think there could be. But if the only way to talk to Java is via a non-Haskell Haskell-like language I think it severely impacts how much the actual Haskell ecosystem is improved by doing so. 
I looked at blunders in the 3rd World Championships and the first one output was this: Game: Steinitz, William - Gunsberg, Isidor Best move: 24. ... Nc5+ (-7.07) Move played: 24. ... Nc5+ (-2.66) I'm confused, the best move and the move played appear to be the same?
Aah, that's a funny bug that happens because of how I'm using the engine. The computer can say that X is the best move, with evaluation (+2), but after the move is made, the evaluation drops to (-2) because the computer now can see more deeply. Thanks for spotting! It's relatively easy to fix, I just need to drop all cases where the same move leads to such different evaluations based on the depth.
Thanks for this excellent explanation and perspective. That lenses are so closely tied\-in with basic language features like data constructors and accessors, as well as the fundamental category\-theoretic concepts of sum and product, makes me wonder whether lenses might be baked\-in to GHC (or perhaps another language, like purescript) at the language\-level. Are there any existing ideas or proposals around this?
&gt; You can program in Haskell without even changing your mindset. Just program as you would program in C++, it’s that simple. Ehhh, I’ve come around to this attitude now as an experienced Haskeller, but mostly because learning Haskell changed the way I write C++, haha—it would’ve been entirely unhelpful when I was a beginner. (“Am I really supposed to use these clunky `IORef` things every time I want a variable?!” and so on.)
Seems like bike-shedding. Backwards compatibility with code and literature trumps minor aesthetic tweaks.
The mapping function for profunctors doesn't require an isomorphism, only two general morphisms. A profunctor is just a functor C^op x C -&gt; Set, not a functor from the category of isomorphisms in C.
Ah yes I can see how that would be misleading :) I'll see if I can rewrite it to disassociate the fundamental idea of profunctors from the concept of isomorphisms.
Cool project! Out of curiosity, is there a more idiomatic way to express [this](https://github.com/cgoldammer/chess-database-backend/blob/master/src/AppTypes.hs)?
I see sum types and pattern matching. This already looks pretty idiomatic to me. I can recommend using `-XDataKinds` to be sure that in this line you can't accidentally be wrong in `AppType`: ``` getSettings Prod = Settings Prod False (getDBName Prod) (getPortForApp Prod) ``` But, personally, I don't think it worth it to complicate things for simple write-only-once things. Though, some code duplication can be removed in this way: ``` data AppType = Dev | Prod | Test data AppSettings = AppSettings { appType :: AppType , appSettings :: Settings } data Settings = Settings { showLogin :: Bool , appDBName :: String , appPort :: Int } mkAppSettings :: AppType -&gt; AppSettings mkAppSettings t = AppSettings t (mkSettings t) mkSettings :: AppType -&gt; Settings mkSettings t = Settings { showLogin = mkLogin t , appDBName = mkDBName t , appPort = mkPort t } ```
I really enjoyed this. Also the layout and the asides etc. are beautiful and a joy to read.
I loved reading this article, I learnt a lot of things. Thanks a lot for taking the time to write and share!
I think the idea is that `shell` just passes a command line verbatim to the system shell, so that the shell can handle all parsing. Trying to escape arguments separately seems counter to this goal.
We shouldn't make such a breaking change for something as small as this, _but_ it would be completely worth it if we bundle other things along with it that we want that would also cause breaking changes. This should be an opportunity to do so.
Awesome! Can you elaborate on what is a "safe" `head` function, and why the one in Prelude is not good?
Hey there. I've been using Spacemacs with the Haskell layer and loving it. I'm working on a project that depends on a library that only works with an old Stackage snapshot. It turns out that this snapshot doesn't work well with my global newer global install of Stylish-Haskell, so I can't use that to style my code, yet if I build the version of stylish-haskell specific to that snapshot in the project with stack and run that manually, that works fine. The problem is that Spacemacs' Haskell Layer's built in stylish-haskell support doesn't seem to try using the version inside the project folder, it just tries to use the global install and fails. Is there a way to fix this?
`head` from the Prelude is what's called a [partial function](https://wiki.haskell.org/Partial_functions). The short of it is: &gt; head [] *** Exception: Prelude.head: empty list Running `head` on an empty list results in undefined, and crashes your program. The package `safe` has implementations for partial functions that use Maybe, or default values instead, so: &gt; import Safe &gt; headMay [] Nothing 
Perfect, thank you!
Nice puzzle with that `match` function. Here is a lazier version than yours: match :: [a] -&gt; Either () ([a], a) match [] = Left () match (x:xs) = go x xs where go y [] = Right ([], y) go y (x:xs) = fmap (first (y :)) $ go x xs or in terms of `foldr`: match :: [a] -&gt; Either () ([a], a) match [] = Left () match (x:xs) = foldr (\x r y -&gt; fmap (first (y :)) $ r x) (\y -&gt; Right ([], y)) xs x
Nice puzzle with that `match` function. Here is a lazier version than yours: match :: [a] -&gt; Either () ([a], a) match [] = Left () match (x:xs) = Right $ go x xs where go y [] = ([], y) go y (x:xs) = first (y :) $ go x xs or in terms of `foldr`: match :: [a] -&gt; Either () ([a], a) match [] = Left () match (x:xs) = Right $ foldr (\x r y -&gt; first (y :) $ r x) (\y -&gt; ([], y)) xs x
Hi, there. When I was first learning haskell a couple of years ago I stumbled across a website that would generate functions that used function application to get rid of arguments. I was trying to find it again and had no luck. I was wondering if anyone here knew of it? Thanks in advance.
I actually like the * syntax. It matches the literature on kind systems, and stands as a reminder that * is indeed a kind, and not a universe. 
Can you clarify the distinction you're making here? According to http://wiki.portal.chalmers.se/agda/pmwiki.php?n=ReferenceManual.UniversePolymorphism &gt; A type whose elements are types is called a universe; Agda provides an infinite number of universes Set, Set₁, Set₂, Set₃, ..., each of which is an element of the next one. By this definition, `Type` in Haskell is definitely a universe, it's a type whose elements are all inhabited types (including itself!)
With the caveat that I'm not necessarily that familiar with Haskell-specific best practices [but am familiar with functional-first webservers] - the general style here is good. It's basically code-as-configuration-file, and high-level is almost like Prolog: [relation between facts expressed as new types] [establishment of basic facts in terms of well-understood types] For instance, let's say this app really takes off with the worldwide chess community - I mean, it could! The DB port might need to be sent to a load balancer function that takes an app connection request, does some work, and returns a port. By having it expressed as a static value of a function evaluation, it's easier to drop in that load balancer later if you need to. It also has the advantage of being easy for humans to parse - I would have been strongly tempted to do this: getSettings Dev = Settings Dev True "dev" 8000 which would have made it harder to track down the error when my local SQL Server inevitably went on the fritz and closed port 8000. It's common in production environments to have a config yaml/xml/json/etc that gets read at startup - that way you don't have to recompile if you change SQL servers - but from a functional perspective there are big advantages to having "facts" either in code or directly managed by code. Especially if you're not doing much redeployments yet - and even if you will later, better to have at least the scaffolding of the function from the get-go. I only see one minor non-idiomatic thing about this: 19 getAppType _ = Dev This should be getAppType "dev" = Dev and getAppType _ = [raise some sort of exception or log a warning or something]. If people are trying to access Prod and a regression bug is sending them to Dev because a JavaScript typo somewhere else was trying to send them to "prid", you want to know about it. You don't want people being silently sent to Dev without knowing how to log in. Maybe use some AppConfigString type deriving from string that only has three valid constructors ["dev","prod","test"] and one exception handler ("invalid argument, must be one of dev, prod, or test"), so you don't have to write exception handlers throughout.
Thanks /u/lgastako for that very detailed reply. I'll take a look into those packages and let you know. All in all, I'll also share my findings and experiences doing this project here. My knowledge of Haskell is limited but maybe it can still be of use to other people approaching this problem.
Have you tried `Ctrl-Shift-R` in your browser to properly reload and flush the cache?
In dependent type theories, universes are types. In lambda calculi with kind systems, most notably Pure Type Systems, kinds are not types. In particular, even though `*` does classify types like a universe, it is not a type, i.e. `* : *` does not hold. Something like `a -&gt; *` is not a well-formed type in any higher kinded system that I know of. I was under the impression that `* :: *` did not hold in Haskell also, at least without `-XTypeInType`. If it does, then I guess I'm ok with the `Type` syntax.
I'm an idiot. I mixed that with deleting cookies. Thanks!
1. See your browser network information — is the index.html comes from cache? 2. Do you happen to be on Docker and on Mac? Years ago I had an issue where files in docker volume not getting updated. I gave up using docker for development since.
Thanks - yes, as I was writing this code, I was pretty sure that there's a cleaner way.
Good points and thanks for the kind words! For context, this abstraction came about because I realized I do need a pretty functional web server, e.g. to run tests I need to be able to say "spin up this exact server, but with the test database" or I need to be able to say "create database fixtures, but do this with the right fixtures for either the prod or test database, and you should also be able to do this from the commandline". I don't think I use exceptions at all, because I've been scared of the exception monad transformer stack, but it's indeed important to have some exception or logging handler so I keep track of bad inputs and unsuspected behavior. Will work on it! 
You're looking for a site that takes a code snippet and returns the same code but in point free style? See [pointfree.io](http://pointfree.io/) and try `f x = x * x + x`
There's also a safe version in base, but with a different name: listToMaybe :: [a] -&gt; Maybe a -- AKA headMay http://hackage.haskell.org/package/base-4.11.1.0/docs/Data-Maybe.html#v:listToMaybe
Happens to me all the time :) What you can do is install a different version of a browser and completely disable caching in it. Or just get in the habit of force refreshing constantly
(small note: Reddit doesn't like the three tick notation for multi line code. You might need to turn the fancy editor off? 4 spaces indent every line will definitely work though) It tickles me a bit that what you essentially did was database normalization on a schema :)
This axiom always holds in GHC, which is why the name of the extension is a bit misleading and its functionality is soon to be merged into -XPolyKinds
Hah. I'd never noticed that it actually wasn't legal syntax. I'd just assumed the whole time that it'd work if I ever needed to write it.
It's something like 10-20% of hackage.
Could you elaborate more on the normalization I'm doing, I might be missing some context? Happy to improve the architecture! Thanks!
It's almost as if Scotty doesn't know...
This is excellent. I think I finally understand what a prism is now.
Use Chrome incognito mode for that, it doesn't share any cache with the normal profile. So you can be pretty sure that it's not an issue due to stale cache.
Someone (can’t remember who) said programming with lenses was like using a more sophisticated language that was just about supported by Haskell. Not sure what would really be involved, other than improving the baroque type errors and removing the need for TH, though.
[Monadic.Party](https://Monadic.Party) videos will be added to this playlist a day after a lecture happens. Check the schedule at [https://monadic.party](https://monadic.party) to see if there's something you're particularly interested in :)
^((This made me think about use cases for .io domain in Haskell context... and there's actually) [^(website named monad.io! :D)](https://monad.io/)^())
Apparently the three tick thing works if you've enabled the redesign. I haven't tried it, yet, but that's what I was told when I had the same issue.
You can, they just look different (no `where` keyword): foo :: Int -&gt; Int foo = \case 0 -&gt; 9 n | x &lt;- 2, y &lt;- 7, n &gt; x -&gt; x + y + n | otherwise, z &lt;- n * 100 -&gt; z Example: &gt; map foo [-2,-1,0,1,2,3,4] [-200,-100,9,100,200,12,13] 
Another trick is to open the Chrome Developer tools and disable the browser cache when dev tools are open. Then always run with developer tools when developing the web app. (You most likely want dev tools open anyway, so I find this really handy.)
I mean, nothing fancy, but I’m planning on adding support for deriving optics to a language I’m working on, and letting the compiler know about them so it can produce better error messages. (Either built in to the compiler, or through some more general mechanism like macros/generics &amp; custom type errors.) It’s a concatenative language—`over (atoms.traverse.point.x) (+ 1)` from [this lens tutorial](http://hackage.haskell.org/package/lens-tutorial-1.0.3/docs/Control-Lens-Tutorial.html) could be written `{x point traverse atoms} \(+ 1) over` for instance, since left-to-right composition is the default.
I believe there have been some proposals to make record syntax provide lenses instead of what they already are now (or in addition to), but I'm not sure if it ever went anywhere :'(
Thanks that's pretty cool. Would it be possible to get the slides ? some presentations are kinda hard to read ...
&gt; Are there any existing ideas or proposals around this? In PureScript, you can write a single lens for any record property, or a single prism for any constructor of a polymorphic variant, which is sort of along these lines. 
A long time ago I bought hackage.io and redirected it to \`hackage.haskell.org\`. It no longer does so because of some fastly security (probably a smart move) \-\- who should I talk to about either giving this domain over to the haskell committee, or adding it as a fastly security exception (so that I can continue to pay for it)?
Thank you! I just wanted to dive deeper into Source-Plugins! 😀
Nit: "insights gleamed" should be "insights gleaned".
tl;dr: You can use the same rank-2 types trick used in the `ST` monad and in `justified-containers` to get the compiler to check a surprisingly wide range of API invariants and preconditions, including: * Ensuring that lists have been properly sorted before using `mergeBy` * Generalizing the `ST` monad to allow state threads with sharing. * Ensuring that keys are present in maps * Ensuring that adjacency representations of graphs are well-formed * Writing APIs with enforced preconditions, that give the user plenty of flexibility in constructing arguments to prove that the preconditions are met. These are just the applications that I could fit into 12 pages; I'd love to see what other ideas people can come up with!
wow thank you I have been using this incorrectly my entire life
Here was mine: match :: [a] -&gt; Either () ([a], a) match xs = foldr step (Left ()) xs where step a acc = either (\_ -&gt; Right ([],a)) (\(lst, a') -&gt; Right (a':lst, a)) acc 
mine was: match :: [a] -&gt; Either () ([a], a) match xs = foldr step (Left ()) xs where step a acc = either (\_ -&gt; Right ([],a)) (\(lst, a') -&gt; Right (a:lst, a')) acc 
I don't know if there is a principled way to do it, but it seems like you can (ab)use QuasiQuotes to do any kind of calculation (e.g. see [runIO](https://www.stackage.org/haddock/lts-11.13/template-haskell-2.12.0.0/Language-Haskell-TH.html#v:runIO)).
yeah, I know that this is possible. But I was wondering whether there are some ideas to get a proper compile-time evaluation.
when i correct some syntax issues, it compiles just fine: {-# LANGUAGE FlexibleInstances #-} {-# LANGUAGE DataKinds #-} {-# LANGUAGE DeriveFoldable #-} {-# LANGUAGE DeriveFunctor #-} {-# LANGUAGE DeriveTraversable #-} {-# LANGUAGE LambdaCase #-} {-# LANGUAGE PatternSynonyms #-} {-# LANGUAGE PolyKinds #-} {-# LANGUAGE RankNTypes #-} {-# LANGUAGE StandaloneDeriving #-} {-# LANGUAGE TemplateHaskell #-} {-# LANGUAGE TypeFamilies #-} {-# LANGUAGE TypeOperators #-} {-# LANGUAGE PartialTypeSignatures #-} {-# LANGUAGE GADTs #-} {-# LANGUAGE UndecidableInstances #-} import GHC.TypeLits (Symbol, KnownSymbol) data FooType e -- index = Bar Symbol | Baz Symbol e type family GetSym (a :: FooType e) :: Symbol where GetSym (Bar c) = c GetSym (Baz c e) = c type family GetE x where GetE (Baz c e) = e data FooF (k :: FooType e -&gt; *) (i :: FooType e) where FooAF :: FooF k ('Bar c) FooBF :: k ('Baz c e) -&gt; FooF k ('Baz c e) deriving instance ( c ~ GetSym i , e ~ GetE i , Show (k ('Baz c e)) , Show (k ('Bar c)) ) =&gt; Show (FooF k i) main :: IO () main = pure () 
Where do you want your compile-time evaluation to occur? In the optimiser? Using template haskell?
In the optimizer 
GHC does do compile time optimization in many cases. Is there a specific optimization you had in mind?
If you have an expression that is all constant terms, 9 times of out 10, GHC will inline everything and optimize it away. The trick is to make it all constant terms at compile-time. GHC's version of Haskell has a very well-defined turing complete language that is guaranteed to run at compile-time -- instance heads, a restricted version of a prolog-like language. If you do all your compile time stuff in this language, and then use instance resolution to convert it to Haskell terms, and mark all your class methods `{-# INLINE -#}`, GHC will almost certainly optimize it away. &gt; Wouldn't it benefit from a system, which could tell GHC which expression can be compile-time evaluated and which not? The situation is straightforwards. If you have a bunch of calls on methods that are inlinable, fully-applied, and the arguments are all constants, GHC will almost certainly optimize them away. The few times where I've seen this not take place are almost always because I forgot to turn on `-O`.
Really? Maybe I am completely wrong and this question is resolved, but I am pretty sure that this is not true for recursive definitions and other, more complicated stuff, because the inliner doesn't kick in.
There's a couple of typos in the title of "Julie Moronuki - A Gentle Intorduction to Profunctions (Part 1 &amp; 2 / 6)" Introduction, profunctors.
I am not sure this question has been resolved. I am working on adding vectorization support to the native code generator of GHC and certain x86 vector shuffle instructions strictly require a compile time literal as an argument or what is known as "constexpr" in C++. An example is this: https://gist.github.com/Abhiroop/ab2d71f3b14e28c91b6acd2f395d605d I don't think GHC currently supports the concept of "constexpr" in C++, which would be a compile time literal. Most answers here are talking about "constant folding" or "constant propagation" among the various optimization passes in GHC and yeah that is a form of compile time evaluation, and if you are asking about that, I believe there exists some form of compile time evaluation already. But I dont think GHC still allows the user to declare a true compile time literal which can be used for shuffle operations.
well, maybe I've phrased the post wrong, but your answer is more or less my question (what's the status and are there any ideas for the future?) since I imagine it to be a difficult, but interesting problem.
This will definitely end up getting used in some really cool tooling. Thank you for your awesome work.
Well there was some important discussion points in this proposal, which you might have seen already: https://github.com/ghc-proposals/ghc-proposals/pull/124 And also you mentioned you are aware of the quasiquoter approach. Nothing else that I am currently aware of.
Ahh, sorry, I don't know how it looks now. For me everything is great. I'm using new Reddit design where I can switch between markdown and fancy editor. And I see message rendered correctly.
yeah seriously, only BEAM languages offer trivial concurrency
Interesting! I'm on the old design and I see \`\`\`data AppType as a single line of plain text... ¯\\\_(ツ)_/¯
Oooh, now that's one I'll have to write down and remember.
What /u/chshersh did is commonly known in database design as normalization. You essentially factor out a single set of relationships into the most fractured and modular setup you can so that there's the least amount of repetition anywhere. It also allows for you to update things in one place and have things work 'correctly' elsewhere easier. (Splitting AppSettings into AppSettings and Settings is what I was pointing out)
I would've been so about this before learning some Idris. Now Type just makes a hell of a lot more sense and * seems odd.
I'll make sure to upload mine somewhere this week, and make the exercises available as well
Hello! There already exist implementation of lenses with excellent error messages: * https://github.com/mrkgnao/silica
Your version is unnecessary strict, it loops in this case for example: `fmap (take 10 . fst) $ match [1..]`. 
[Deriving via](https://www.kosmikus.org/DerivingVia/deriving-via-paper.pdf) is a nice approach for resolving the instance boilerplate problem, and I hear that the extension has been merged recently!
This is great—I’ll definitely be playing around with these ideas and trying to come up with new applications. I was already planning on writing an implementation of `ST` to add local mutation to a language, and stuff like this might make its way into the standard library.
 {-# LANGUAGE TemplateHaskell #-} import Language.Haskell.TH import Language.Haskell.TH.Syntax foo = $(lift (1+1)) will perform the computation at compile time yielding `foo = 2` as the code to compile. You can do this for any type that has a `Lift` instance.
Fixed, thanks
Maybe you meant to say "real GHC," the haskell language standard can be implemented by more than one compiler. Afaik eta is compatible with GHC 7.x modulo FFI and some extensions. &gt; As GHC 8 is state-of-the-art and undoubtedly has some bugs, we will wait until the new extensions stabilize and start getting used in Hackage packages. If there are compelling, practical use cases for a given extension, we will definitely backport it. &gt; Eta is strategically designed so that Hackage packages can be compiled with little modification, allowing reuse of existing infrastructure. This is done by supporting many of the GHC-specific extensions that are used heavily in popular libraries. Only thing going against eta imo is it's company backed and there's quite a bit of politics and manipulation that comes with companies.
That's true. It is not the boilerplate that I'm concerned with -- I was more surprised to notice that, implicit modules plus ML functors give rise to typeclasses + deriving strategies in a totally natural way, in contrast to the fact that we need to somewhat regularly add extensions to GHC's deriving mechanism.
Somewhat remind me of lightweight static capability - same phantom type, same 'library author provide trusted kernel'. No doubt this paper propose more, but IMO this paper really need to cite static cap.
I dont get or_elim. Can anyone explain it to me?
Have you look at threepenny and reflex? I recommend threepenny, if you have not touch nix/frp yet, it has a simpler interface, and is simpler to install/use. Also it is a game, so having the whole game in ghcjs is a large performance issue (especially for game). Also with reflex the API need svg to draw stuff, which is a bit harder. But I recommend reflex once you get the hang - (I have no reason to back it up, please inform me if you do) I heard the core design is more efficient (dont leak memory), is more developed, and doesnt require a server running (so long latency or have user build it). 
I don't understand it either. That doesn't look anything like https://en.wikipedia.org/wiki/Disjunction_elimination
Thanks for catching this! I originally had a different set of rules there and it seems I did not complete the edit :( That line should be `and_elimL :: (p &amp;&amp; q) -&gt; Proof p`. The correct rule for `or_elim` is this: or_elim :: (p -&gt; Proof r) -&gt; (q -&gt; Proof r) -&gt; (p || q) -&gt; Proof r 
make sense to me. It seems like you are the author, and I want to hear your opinion on lightweight static capability (is it relevant or did you guys cite similar work? what do you think is the greatest difference? etc)
I am not at all surprised that Oleg has something related to this, but I actually had not seen that paper before. Thank you for the pointer. I'm reading through it now and will reply once I understand the similarities and differences better.
Cool :) I used to write Coq, would love to discuss with you.
Got it, yes, a big fan of reducing this type of repetition.
They've added quite a few languages since I last looked. I'm gonna try it out again if I can find some time. \^\^\^Sadly, \^\^\^no \^\^\^Kotlin \^\^\^though.
Keera studios is creating cross platform native games and build on top of SDL.
Thanks, very useful! I wonder if source plugins are what Liquid Haskell would need to become a proper plugin instead of a separate compiler.
Is there are choice for a desktop manager at the login screen? It depends on the linux distribution. 
No, it straight away logs in to xmonad.
You should probably ask on your distribution's subreddit. 
Or xmonad subreddit...
Maybe, but XMonad is not responsible for launching itself or a DE or anything, and the gory details of Xorg startup tend to be *very* specific to each distro.
I think it depends on your display manager if you are using one. 
It's mdm
I actually just implemented the same workflow last week. A tip: beam-migrate exposes a function that will create the db schema given the DB instance (and manage migrations though the latter isn’t fully documented yet).
Thanks for this reference, I hadn't seen it and it definitely is relevant! From an initial read, here are my impressions about the similarities and differences: * Both use phantom types + existentials as the main mechanism. * The lightweight static capability approach seems most similar to case studies 1 through 3, where a library-specific newtype wrapper is used to represent a predicate. * The full GDP case study (#4) generalizes this further, by splitting out orthogonal concerns: naming (and the corresponding existential introduction rule), and proof construction. * The awkwardness of `inserting` and `deleting` in `justified-containers` and case study #3 partially explains why the more general GDP approach is desirable. * GDP is benefitting from the safe coercion work in Haskell, which post-dates the lightweight static capability paper. This is particularly important in cases like the recursive maps: say you have a key set inclusion `incl :: Key ks k -&gt; Key ks' k`, and you want to upgrade a `JMap ks k [Key ks k]` to a `JMap ks' k [Key ks' k]`. To do this efficiently, you'll need to `fmap (map incl)`over the map to upgrade the adjacency lists. But without paying careful attention to type roles, you can end up accidentally allocating an entire identical copy of the map. This was a bug in the first version of `justified-containers`: https://github.com/matt-noonan/justified-containers/issues/1 * Hopefully, the format of GDP as a pearl will make it easier for other people to try these ideas out :) 
&gt; implicit modules plus ML functors give rise to typeclasses If they're not coherent, they're not type classes (pardon the hard line).
It looks like my example code wasn't complex enough to cause the issue. I've edited it by adding another constructor to the index and AST. Now I get: • Could not deduce (Show (k ('Bin c1))) arising from a use of ‘showsPrec’ from the context: (c \~ GetSym i, e1 \~ GetE i, Show (k ('Baz c e1)), Show (k ('Bar c)))
Figured it out: I was skipping the obvious problem (and proceeding to a more obtuse, speculative problem) of hiding parameters in some of the constructors without providing the needed constraints. This compiles: [...] FooEF :: (Show (k ('Baz c e))) =&gt; k ('Bin c) -&gt; k ('Baz c e) -&gt; k ('Baz c e) -&gt; FooF k ('Bin c) deriving instance ( c ~ GetSym i , e ~ GetE i , Show (k ('Baz c e)) , Show (k ('Bar c)) , Show (k ('Bin c)) ) =&gt; Show (FooF k i)
[removed]
[gloss](https://hackage.haskell.org/package/gloss) ?
gloss may be what you're looking for. Here is a semi-famous example of pong implemented in gloss using the lens package: https://github.com/ekmett/lens/blob/master/examples/Pong.hs 
This `abstract` function appears to be substituting the given variable with the number of lambdas "to its right", instead of those "above it". &gt; abstract "X" (App (Abs (F "X")) (Abs (F "X"))) Abs (App (Abs (B 2)) (Abs (B 1))) shouldn't that be Abs (App (Abs (B 1)) (Abs (B 1))) ?
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [ekmett/lens/.../**Pong.hs** (master → 2037a2d)](https://github.com/ekmett/lens/blob/2037a2db9a4be01f7647479f33676751ed7fa9a4/examples/Pong.hs) ---- 
I'm not sure what your visibility is into the Haskell community, but you probably would be interested in [Liquid Haskell](https://ucsd-progsys.github.io/liquidhaskell-blog/) if you haven't already seen it. 
You are probably launching xmonad from .xsession or .xinitrc files ... check them.
Thanks that's awesome ! 
How is it different to using just stack?
Initial look is promising, already excited about this application of `coerce`
I'm not sure what term I should use then. Do you mean I should qualify it as "modular typeclasses"? If you impose a strict canonicity requirement for coherence, you lose modularity.
Hmm. Ok that's fair, and a little better than I recall. As long as it implements Haskell98 and preferably Haskell2010 then it being a little behind in extensions isn't a big deal. Although I still don't like the choice to name it as a new language rather than a new compiler. Would Eta packages be uploaded on hackage, is Eta going to continue to follow Haskell language reports?
Ya I think the author meant to use `Reader` and walk under abstractions in a `local` context. `State` updates a global state, not a local one. IDK if this can easily be made to work with `transformM`
&gt;I just want to come out of it. Just kill Xmonad and start a different WM.
Coderwars is really nice: much slicker than Hackerrank for Haskell, which is the other similar site I've tried. For one thing, the boilerplate is way cleaner; and the methods of grading the solutions on two independent axes of "Cleverness" and "Best practices" are particularly relevant in Haskell. I would like to know the clearest way of solving a problem; I would also be interested (for curiosity) in any cunning tricks that can be used, even if I wouldn't put them into production code.
If your entire workflow is stack-centric then there's not really any benefit or harm to the platform -- you can think of it as just installing `stack` and some other stuff you won't likely use that often. However, if your workflow is not _entirely_ stack-centric (or even involves no stack at all) then the core platform is a joint installer for `ghc`, `cabal`, `stack` and a few other tools that, particularly on mac and windows, is idiomatic with regards to how installers for those platforms typically work. Further, on mac and linux it also gives some scripts and layout to manage switching between different versions of ghc and related tooling.
Gloss is made for this - a beginner friendly way to make games and other graphical apps that focuses the user on a declarative method of transitioning and rendering the game state.
Wow, great work! Will be curious where that leads to! Are you continue to work on this? Is this something that IOHK is using? Do you need help with it ;-) I could imagine some tooling that extracts and synchronizes tricky proofs with a companion Coq or Isabelle development...
modular implicits
It certainly played that role for me, and very well. :-)
We aren't using this at IOHK right now, but there are enough scenarios where we *could* use it that I'm hoping to get the chance to try it out at scale. For example, there are lots of places where a `NewestFirst` or `OldestFirst` newtype wrapper is used to assert a lists is chronologically ordered in a certain way, but all the constructors are exposed so at best it is a reminder to double-check what you are doing. Thinking about how to make this more than just a suggestion led to the `sortBy` / `mergeBy` case study. I'm really interested in ways to combine the benefits of GDP with other tools like Liquid Haskell, Coq, and so on. Would love to collaborate :)
[u/lolisakirisame](https://www.reddit.com/user/lolisakirisame/) I just wanted to thank you for creating some nice Codewars challenges – I remember having fun with the \[Isomorphism\]([https://www.codewars.com/kata/isomorphism](https://www.codewars.com/kata/isomorphism)) one some time ago :\-) Also the list that you provide looks comprehensive.
I'd suggested on a ghc-proposals thread (but didn't yet make it its own proposal) that we might want to add some syntactic sugar for that idiom, so we could write e.g. `[$| 1+1 |]` instead.
Don't install tools globally (so, don't use `stack install`). Instead, install them with `stack build --copy-compiler-tool tool-name`. Then simply configure your editor plugins to run tools via `stack exec`. Failing that, put a script in your path which does the same thing.
Ah damn, of course. Good catch, I need to test more thoroughly.
I think on codewars, the template/boilerplate is written by the person who also wrote the problem, so the style of it can vary a lot. Sometimes, there's an entire step\-by\-step guide consisting of comments and undefined functions, sometimes you're left with just the type of the function you're supposed to end up with. The hackerrank boilerplate for Haskell looks like it's been translated directly from C or something.
This is great! Would be nice to have it index any paper, but it's a start! Thanks!!
Great videos. Shame the slices are impossible to read.
I'd like a `-XTypeAbstractions` (or type-level lambda, like in 6.2) to write the code I want to [here](https://stackoverflow.com/questions/50159349/type-abstraction-in-ghc-haskell) without proxies. Although you can get pretty far by wrapping your existentials in a GADT and match on that (re-using type application syntax), it's still not first-class Big Lambda. My choice for Syntax would be `\@a -&gt;`, but that probably conflicts with as-Patterns `\a @b c -&gt;`...
Was this an early submission? Dont jinx them! 
Actually, I was just re-reading the modular implicits paper and it is noted in section 1.3 that: &gt; Further, modular implicits support a number of features not available with type classes. For example, giving up canonicity – __without losing the motivating benefit of coherence__ (Section 4) – makes it possible to support local instances (Section 3.8) In Section 3.3.2 &gt; In order to maintain coherence we must require that all implicit functors be pure. If Show_list performed side-effects then two separate applications of it would not necessarily be equal. We ensure this using the standard OCaml value restriction. This is a very conservative approximation of purity, but we do not expect it to be too restrictive in practice. Other sections also talk about this, so I believe that they maintain coherence (not canonicity though) assuming that the proofs are correct (I haven't looked at the reasoning in details).
Minor nit, Haskell has not always supported polymorphic recursion using a type signature. In fact, I lobbied for the change that added this. (It has, however, always been been possible to encode polymorphic recursion via type classes.)
&gt; they maintain coherence (not canonicity though) That's really cool!
Yes, we always joke that codewars is powered by potato server.
Thx. I also has fun making the kata. I has a few unfinished one, and probably will finish some in the summer :)
I’ve frequently wanted this. Mostly for recursive functions, which don’t inline very well. 
Any time, I'd love to! Feel free to email, my address is on the github page.
I think we need such table but for Haskell SQL libraries: * https://www.reddit.com/r/haskell/comments/8g8ojm/lets_create_a_comparison_table_of_all_the_haskell/
The paper is amazing! I just have one question about definition of inspection testing. There's a library called `type-spec` for writing type level unit tests: * https://github.com/sheyll/type-spec#readme We've used it in [`o-clock`](https://github.com/serokell/o-clock/blob/03bed1c7b7ea7b2c20c803e9aaca1e1c8d26a5ee/test/Test/Time/TypeSpec.hs) package to test functions over type level rational numbers. I wonder is this sort of testing can be called inspection testing? And if not then why? Sorry in advance for stupid question. 
Thank you! Will definitely try it out. It looks quite sufficient for my needs!
Thank you for the recommendation! Gloss seems to be what most people are suggesting. Will definitely try it out!
Thank you! I'll check them out. Threepenny certainly came up in my searches. However, you mention ghcjs and svg rendering - are these web-based? I am looking for native libs for now, but depending on how it goes, developing web-based games would be rather nice as well!
yes
Don't know if this has been asked before - which one of Edward Kmett's repositories is most accessible for a beginner to read through and learn how to structure Haskell programs?
However the `brew cask install haskell-platfrom` are no longer available when try to install haskell\-platfrom from my Mac while the [haskell.org](https://haskell.org) instruct users to do so to install haskell platfrom on Mac.
Yeah, they got burned out in the advanced track room. We'll put a link to the slides in the comments once we get them.
&gt; Was this an early submission I think so but I'm not sure. The link was recently shared in the [or-patterns proposal thread](https://github.com/ghc-proposals/ghc-proposals/pull/43#issuecomment-396851582).
Awesome! Finally, the GHC 8.4.3 release lifecycle is complete.
Did you look at appendix B?
The platform doesn't instruct users to do that -- it says they _can_, which they used to be up until seven days ago, apparently (https://github.com/Homebrew/homebrew-cask/pull/47908). The main instructions are for running the installer directly. Apparently the brew approach was eliminated In a deduplication effort. Thanks for letting us know though -- I'll go fixup the webpage.
In my experience, the very rare tildas '~' in types are much more readable than tons of bangs. https://github.com/LambdaHack/LambdaHack/blob/v0.8.1.2/LambdaHack.cabal#L261
But how do we represent the table
Glad you like it :-) I would say that `type-spec` are type-level unit tests but not inspection testing, as you are not testing properties that are not visible already at the source level.
No, it's a submission to the main track.
If *that's* how you judge, you will never ever succeed in achieving "accessibility and inclusion."
&gt;Judging from the demographic mix This isn't a good way to judge. Related: http://slatestarcodex.com/2017/08/01/gender-imbalances-are-mostly-not-due-to-offensive-attitudes/
Poor wording; I didn't judge anything, it was merely an observation. And mind me, I didn't say "we need more girls at these events"; I was also referring to the ethnicity mix.
I also agree with the [other comment](https://www.reddit.com/r/haskell/comments/8r01da/accessibility_and_inclusion_at_haskell_events/e0ne8b9/) that you shouldn't aim for equality of outcome because it might just be that more young white males are into haskell in the first place
&gt; I was also referring to the ethnicity mix Same principle
You should upgrade to hamster wheels.
As an event organiser, this is something we're unfortunately keenly aware of - but it still doesn't excuse the state of things. I'd welcome advice as to things we can do to help improve the status quo. Rather than enumerate what we do, I'd love to open the floor to other's thoughts. Rather than just feel bad about this, let's try and improve it!
On that note, a couple of friends and I are starting to do work towards a HaskellBridge (à la ClojureBridge). If you want to help organize, help write the curriculum, support financially, or otherwise contribute, send me a message!
I know full well that I just opened a can of worms, but can I get some sort of coherent reply rather than soundbites and downvotes?
You inferred something about "accessibility and inclusion," but that inference is based on a faulty assumption. (Please see the linked article for an in-depth explanation.)
You were provided with a pretty comprehensive source, would you like more?
[Another source if you'd like](https://edeq.stanford.edu/sections/equality-outcome)
Is it possible to implement \`fold : (b \-\&gt; c \-\&gt; a \-\&gt; b) \-\&gt; b \-\&gt; c \-\&gt; \[a\] \-\&gt; b\` with only \`foldl\` and function application / definition? (You cannot use any other Prelude function than \`foldl\` or any datatype (tuple, ADT, lambda encoded ADT)
I will read carefull it as it seems pretty well argumented. On the other hand, a low-effort "RTFM" comes across as pretty hostile as well. I would still like to stress that the "demographic mix" is IMO just one observable quantity; the actual causes of this are more interesting and are what should be understood in the first place. I don't attempt any sort of neuro-bio-sociological explanation, because such things are fraught with ideological biases and pseudoscience.
I find it amusing how rather than arguing you hand out "sources". I wasn't aware of there being a mandatory curriculum for these things, but I'll surely read this article as well, thank you. 
There was a moment at last year's HaskellX in London when someone asked "What are we doing for diversity?" while the parkbench discussion board was 4 white guys. You could hear a pin drop :)
It would be really great, if we could collaborate on some sort of list that contains ideas how to tackle this issue. :) In particular I, myself, am interested in making FP-events more accessible for all sort of interested beginners, not only those, who want to learn Haskell and/or FP “hard way”. ;) I strongly believe, that being able to have open-minded discussions about these sort of topics, will make our community even more awesome! 
I have edited [my comment](https://www.reddit.com/r/haskell/comments/8r01da/accessibility_and_inclusion_at_haskell_events/e0ne8b9/) to include a quotation from the article that more or less sums it up in a few paragraphs. Anyway, you should understand that you are the one making an assumption here that is without any grounding that you have provided. The article I linked is good for putting forward some counter-examples to your way of thinking. TL;DR is that nerdy stuff like haskell is never going to have as high a proportion of women as explicitly patriarchal organizations like the Catholic Church that tell women their proper gender roles and exclude them from positions of authority.
&gt; nerdy stuff like haskell is never going to have as high a proportion of women as explicitly patriarchal organizations I disagree, since I see Hs as a tool that empowers developers rather than an ideology. If this community is still perceived as some sort of monastery that forces years of study and isolation on its participants, this means there are plenty of opportunities for improving the quality, quantity and viewpoints on how the material is presented, explained and shared.
I agree with the article (not that that's any secret by my post history), but there's an interesting data point to consider: the [gender disparity in math is far less than the gender disparity in programming](http://www.randalolson.com/2014/06/14/percentage-of-bachelors-degrees-conferred-to-women-by-major-1970-2012/). So to me the solution is obvious: Haskell should focus less on the mechanics of day-to-day engineering and practical concerns, and focus more on the abstract, mathematical shapes. That is how we close the gender gap!
An ideology? A monastery? What I said was that it is nerdy.
Just to be clear - they, not 'me' or 'you'.
No, I didn't! In fact, the issue described in B.1.RankNTypes is exactly the situation in the SO thread I mentioned. Neat!
Strange, you'd normally get slated for arguing and *not* providing sources, rather than the other way round. Respectfully I made a pretty clear point, equal opportunity: great. Measuring it with equal outcome: not so great. Then I gave an additional source "if you'd like", nothing is "mandatory". Not sure what else you're looking for. Also I'd just like to add that I'm from an ethnic minority, in case anyone reading thinks I'm just a non caring white dude dismissing these issues.
There are plenty of successful women and non-white ethnicities in all fields of knowledge, both theoretical and applied, therefore I reject the easy association "nerdy = white dudes only"
This is exactly what we *shouldn't* do: change the content of existing events to achieve equality of outcome. That way lies madness. (Unless of course you are targeting a new event for the female audience) Everyone should be given opportunity to attend, and those that have an interest in the content of the event turn up. It might be that only 20% of females are interested, but as long as there's no barriers to that 20% attending (like charging a higher price for women) then great.
I broadly agree with you, my only objection is on the fact that the article you link wasn't written by you and comes across more as link tossing rather than an actual argument.
I can understand the logic that lack of childcare makes it more difficult for people with children to attend. Is there some hypothesis about what is making it more difficult for women, people of different skin tones and older people to attend?
Same thoughts exactly on my part, advice on how to be more inclusive would be amazing. We've ran a needs\-blind full scholarship programme that allowed us to get a couple of people to the summer school that couldn't attend otherwise, but it's just a drop.
Yes, they're completely different. `module` specifies the name of the module that the file contains. `import` imports another module into the namespace.
Yes but is module I guess similar to import like in the case that it brings the module into the namespace? 
I would be very interested in knowing why the whole thread is being downvoted as a whole; I was made aware of its poor wording and of the dangers of optimizing for the wrong aspect at tech conferences, but words are easier to understand than downvotes. Is the topic taboo? Or should it disappear in oblivion? Should I feel ashamed for having asked these things? So many questions
It doesn't bring the module into the namespace. It specifies the name of the module that the current file contains.
No. When you're creating a module `Example`, in Example.hs you would write module Example where import whatever thing = do... It's simply for declaring the module contained in the current file.
And what exactly is the problem? &gt; There are multiple issues to be solved here, but it's better to raise awareness among conference/hackathon/event organizers sooner than later. Should that be understood as 'try to appease those leftist-liberal-mumbo-jumbo types before they start making you problems'? But yeah, you are right, it would be much more fun with girls aroound, wouldn't it? We tried to do that in one slightly-extreme-flying-sport and somehow there are less girls than 60+ guys. Gave up. Those who want to, find a way. There is not much value in trying to tease in those who aren't interested. Given the numbers, it seems to me quite improbable that the reason would be a missing kindergarten.
Ok thanks :) 
 But would we need to declare there is that in there it’s just like saying hello neighbor not much use 
You don't need to declare the module unless you're importing it from somewhere else. If the program is a single file, you don't need to declare modules.
I did enjoy [this talk by Laura Gaetano at ReasonConf](https://www.youtube.com/watch?v=dUCErIbL_r4) - it's more general than about event organising, but it certainly helped get me thinking. It might be interesting to see how where less represented people are coming from when the are making their way into programming. Lots of them are career changers, coming from other fields like design, science, HR, etc. and I wonder if targeting our marketing and explanations to help those people understand why Haskell could help them might be a good strategy. Also we probably need to understand that many of them don't have a lot of time to spend on programming outside of getting skills to directly get a job, and figuring out how to make our events and conferences still worthwhile to them might be useful to. If we're honest, Haskell and other languages like Rust and Reason are far down the funnel when it comes to getting people interested, as opposed to languages like Javascript, PHP, and Ruby, which are far easier to search for online and already have a very establish, reliable job market. But the good news is that the work that we do to help target these kinds of programmers will also make our communities more enticing to existing programmers as well. It's good practice! I realise this is all very general, without much actionable feedback. It's definitely something that has been on my mind however, and something I've been trying to think of ways around. One thing that I have been starting to do is instead of talking about 'correctness' and 'documentation' with regards to types, I talk about '[affordances](https://en.wikipedia.org/wiki/Affordance)' and '[degrees of freedom](https://en.wikipedia.org/wiki/Degrees_of_freedom_(mechanics))'. This allows me to build a bridge to the field of design, and allows those with that background an opportunity to contribute to the discussion, and potentially give their own perspectives. It's not a game changer, but hopefully it helps a little!
Meaning module where by declaring 
Yes.
Ok I got it 
Have you deleted the thread or was this moderated? :)
&gt; This is exactly what we shouldn't do: change the content of existing events to achieve equality of outcome. That way lies madness. I think it's important to assess why the disparity exists - maybe it turns out to be a reason we're ok with (e.g., the disparity in shipping - men are just stronger and better at moving boxes) and maybe it turns out to be something we're actually not ok with. Frankly, I don't know why our disparity is so large. Yes, I know about "things vs people" *a la* Damore, I know about the larger male standard deviation resulting in distorted tails, but... I also went to university and got a math degree, and my math classes were practically never 20-1 M-F ratios. There were usually more guys, but it wasn't that bad at all - it was, as my link says, more like 6-4, maybe 7-3 sometimes. So what is our explanation for having a M-F disparity so much larger than mathematics? Are we really sampling that much further off the right tail? I doubt it. Are we really that much more "things"-oriented? Possibly - a lot of maths grads go into teaching! If this is the cause, then maybe focusing more on Haskell education would actually soften the disparity, and that sounds like something I'd be totally ok with - not at all like diversity quotas or test-hacking.
Do you realize that at ZuriHac, we had: - ...an entire track reserved for beginners? - ...Julie Moronuki (author of The Haskell Book) giving a three-day beginner course in Haskell? - ...special "Mentor" t-shirts that attendees could wear, signalling that they were willing to help beginners with all sorts of questions? - ...an explicit remark about welcoming beginners in the invitations and announcements? - ...a "difficulty rating" field for featured projects, so that beginners could easily find things they might be capable of contributing to? - ...no entrance or sign-up fee, which kept things maximally low-threshold? - ...an open hacking space strategically located in the middle of the location, right behind the entrance, which would simply suck everyone in and stimulate hallway conversations (up to Edward Kmett ending up doing a full-blown lecture right across the coffee machine)? On a more personal observation, I ended up spending almost half the time helping others with issues they were having, including an hour-long session where I explained some really basic Haskell concepts (typeclasses, kinds, functors, etc.). I really, honestly, don't know how you could possibly make it more accessible for beginners than that - you'd have to practically drag them in and force them to attend. But that's not at all necessary, because we actually did have a rather large crowd at the beginner sessions. So if your question is "how can FP conferences in general be beginner friendly", then I would suggest taking a look at ZuriHac, because they did a pretty damn good job.
"Judging from the demographic mix at ZuriHac, there isn't much of it;" Here you are using Bayes's rule to conclude a lack of inclusion P(lack of inclusion | population) = alpha. P(population | lack of inclusion) Then you attribute the responsibility to the organisation/organizers. If you are to judge other people, you might want to take a good metric. Indeed, you are explicitly not using the Bayes's rule to explain why you might be seeing a "large majority of attendees of young white males". Specifically, you are disregarding the fact that Zurihac is an event targeted at Haskell, a programming language, organized in Zurich, in Europe, for hacking. If you were to apply the Bayes's rules to those simple facts, you would explain away a lot of what you wrongly attribute to lack of inclusivity : - Programming might be less popular among women than marketing or medicine. - Europe might be the place that what you call "white" are found in large numbers - Older people might have other interests than coming to hack far away. You mentioned family, here's a reason, some older prefer to spend time with their wife and kids... Each of those reason would explain away the discrepancy between the attendee population's characteristic compared to the population of reference you have in mind, for reason others than the organisation.
https://github.com/agentm/project-m36
\&gt; Can you point at code you think shows it is valuable? Not really, since I avoided it on purpose. \&gt; For FilePath, do you have a benchmark showing its slow? Also no. It turns out that what I wrote was probably slow because I set up around 60k rules and not so much because of FilePath. I never dug into it any deeper because I quit academia before I got time to fix the problem. \&gt; I imagine the Path wrapper is nice and self contained \- fancy releasing it? [https://hackage.haskell.org/package/path](https://hackage.haskell.org/package/path) \&gt; Preventing need was the safest way forward, but interested in what you think the right way is. That makes sense! What you did looks like the better tradeoff so I have no suggestion. To be clear: all these 'pain' points are rather minor. Thanks fro the great work! 
Well the way you wrote it came across as pretty social-justice-y, like you were marching in from Berkeley to tell everyone how misogynist and racist they were, and nobody likes that. Maybe it’s impossible to discuss right now without those overtones polluting the discussion to an intolerable degree, and if so, that’s sad, because I do think there’s actual discussion to be had. One of the most fascinating unintended selectors I’ve ever seen is from the SSC reader survey: participants are massively skewed towards firstborns, which is... probably not something anyone even imagined was being selected for!
Honestly, I think ZuriHac is about as inclusive, welcoming, and nondiscriminatory as you can reasonably make a conference. Yes, there are problems, but IMO ZuriHac has already done their bit and then some. I don't know what else they could possibly do without making the experience worse overall.
Not just that. There are more males in the industry; this isn't something a conference can fix. There are vastly more white people than any other ethnicity within a 2-hour flying radius from Zurich. Young CS students benefit more from a conference than a 50-year-old industry veteran, and they tend to have fewer responsibilities to consider. This isn't the conference's fault, it's just how career paths and life choices work. You'll see old people overrepresented at Bingo events. You'll see females overrepresented at fashion shows. You'll see children and families overrepresented at the circus. This isn't discrimination, it's normal, and no reason to worry.
Look at how lawyers or marketing folks dress, shave, smell. Spot any difference ?
This needs to be higher
Absolutely agree, thank you. I'd like to reply here to /u/dnkndnts as well : &gt; social-justice-y, like you were marching in from Berkeley to tell everyone how misogynist and racist they were, and nobody likes that. If that's really the case, I apologize. However the degree of misinterpretation it's entirely up to the reader. I certainly didn't mean to criticize the ZuriHac organizers for anything; they did an amazing job at creating an inclusive environment as /u/tdammers explained so effectively. I guess my main concern is with the "pipeline" then; there are factors that select this sort of demographic mix, be it geographic proximity, the ability/luxury to just take a weekend off for nerding out, etc. Still, I think there's a remaining margin of improvement for attracting underrepresented groups. There's a lot of potential for us for creating more intuitively appealing tutorial material, for example, that would cater to less theoretical computer-science oriented crowds. 