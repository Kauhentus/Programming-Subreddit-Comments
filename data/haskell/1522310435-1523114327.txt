Pretty much everything having to do with Stack resides in `~/.stack`, except for the `stack` executable itself. Cleaning up after it is relatively painless.
What's the advantage to this over just using the system package manager to install GHC / cabal-install? Does brew not support installing multiple versions of GHC?
While that does apply to most CC licenses, CC0 is fine for software: https://wiki.creativecommons.org/wiki/CC0_FAQ#May_I_apply_CC0_to_computer_software.3F_If_so.2C_is_there_a_recommended_implementation.3F
Hi! Be sure I know how to search over the internet. It was more a 'How do you do" than a "What is the recomanded way of doing" question as theory and practice aren't always the same thing.
Not sure! It looks like something is trying to call `openFile` on something that is not a file (but instead a directory). If you have the code in a repo somewhere, I'll clone it later and see if I can reproduce it.
The main motivation for that script is, that it offers the same disk layout as HVR PPA, including *multiple GHC* versions. Also creates symbolic links `ghc-8.4.1`, `ghc-8.2.2` etc. It's maybe not important for 99% of users, but is important for me. (I guess you can `brew install ghc ghc@8.0 ghc@8.2` too, and arrange links yourself, not sure if you can have 8.2.1 and 8.2.2 simultaneously, can you?).
Ah. Didn't realize a normal GHC install didn't come with a `ghc-x.y.z` symlink by default.
What's your location? That would help us. I'm a student, also, btw, but I've been recruited for Haskell internships (and FP in general).
Slightly off topic, but I was interested to see mention of the Terraform NixOps provider linked through the post. I'm unconvinced that re-configuring deployed systems 'on the fly' is a good idea, ala NixOS, and prefer personally to use ignition to initialise a host before throwing it away and deploying a new one, immutable in a perhaps more literal sense. There's obviously poor support to follow this through the entire stack particuarly where persistent services like database are concerned. That said, separating out the orchestration and configuration from NixOps strikes me as a sane move. With that said, if the `website/*` markdown code follows the conventions of the other official Terraform providers I can generate a Haskell DSL for the provider's types. See the generated [Terraform AWS provider](https://github.com/brendanhay/terrafomo/tree/master/provider/terrafomo-aws) as an example. I'm currently using the DSL to emit raw Terraform in a preproduction environment, circumventing alot of the annoyances (like `count`, naming, and lack of type/interpolation errors.) It remains unannounced though due to a lack of documentation and a desire to continue to explore the surface DSL.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [brendanhay/terrafomo/.../**terrafomo-aws** (master → 2f24dc4)](https://github.com/brendanhay/terrafomo/tree/2f24dc4ce763627ab9b06ee770a542e2945db451/provider/terrafomo-aws) ---- 
So long as you're using Stack, almost everything, including the compilers, will be installed under `~/.stack`. The one exception is the Stack binary which will be placed at `/usr/local/bin/stack` (assuming you use the install script at https://get.haskellstack.org). There's no need to worry about making a mess like there used to be—no digging around in `/Library` or anything like that to clean things up. If you want everything off your system, just `rm ~/.stack /usr/local/bin/stack` and you're done. I do not see any benefit to automatically using Docker for Haskell development. Stack alone should be just fine. I recommend installing Stack via the previously mentioned install script. I have known people who have installed Stack via Homebrew and run into issues (although I couldn't tell you what they were) and other package managers may have similar issues. YMMV, of course.
For me, stack itself is in `~/.local/bin/stack`, which I like. I don't like tools that require root access. 
I gave a [talk on using freer effects](https://www.youtube.com/watch?v=gUPuWHAt6SA) using a bank as my example. The nice thing about this approach is it makes it significantly easier to test (a plus in my books when you're dealing with crypto stuff!) than the traditional MTL approaches.
The type of MyAdd' is when expanded (Int -&gt; Int -&gt; Int) -&gt; Int. The type you want it to have is Int -&gt; Int -&gt; Int -&gt; Int. The difference arises from (-&gt;) being right associative. The type of MyAdd' is not a function that takes three ints and produces one, but a function that takes a binary function on ints and returns an int. One way of getting what you want is doing instead myAdd' :: Int -&gt; MyType because that expands appropriately to Int -&gt; Int -&gt; Int -&gt; Int.
That's where stack installs executables. Perhaps you used stack to install a newer version of stack, and now you have two executables, one in `/usr/local/bin/stack` and one in `~/.local/bin/stack`?
ahhh oke. I thought that was derived from the ```writeTemplate "templates/pages.html" pages``` But your suggestion seems smart! I'll give it a try. I already looked at your example but I missed this part before. Thx
Having to configure an entire host as part of a deploy/application reconfiguration rather than deploying containers/pods will naturally going to have an unacceptable turn around. Sticking nix closures (for example) inside containers and deploying those gives you the benefit of existing ecosystems like k8s/mesos and spinnaker/flux/whatever without having to reinvent these same concepts for NixO{,p}s. 
I used `stack upgrade`. Maybe that's why.
[`TreeLike`](http://hackage.haskell.org/package/tree-traversals-0.1.0.0/docs/Data-Traversable-TreeLike.html#t:TreeLike) is interesting because it appears in its own method class Functor tree =&gt; TreeLike tree where treeTraverse :: Applicative f =&gt; (a -&gt; f b) -&gt; (forall subtree. TreeLike subtree =&gt; subtree a -&gt; f (subtree b)) -&gt; tree a -&gt; f (tree b) What other examples are there? Another example I got on Twitter is [](https://github.com/kwf/StrictCheck/blob/master/StrictCheck/src/Test/StrictCheck/Shaped.hs#L20) -- Shaped :: Type -&gt; Constraint class Typeable a =&gt; Shaped a where type Shape a :: (Type -&gt; Type) -&gt; Type project :: (forall x. Shaped x =&gt; x -&gt; f x) -&gt; a -&gt; Shape a f embed :: (forall x. Shaped x =&gt; f x -&gt; x) -&gt; Shape a f -&gt; a
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [kwf/StrictCheck/.../**Shaped.hs#L20** (master → bc36549)](https://github.com/kwf/StrictCheck/blob/bc36549d16bc919d06b1800b97b18c390df18597/StrictCheck/src/Test/StrictCheck/Shaped.hs#L20) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dwh1vmh.)
Yes, I understand the difference. I was talking about typeclasses
Yes, I am using 8.2.2. I have just forgotten in my original version `d` parameter in `forall`signature. Thank you for pointed out. Regarding repeating constraint is what i was looking for. I am going to explore that in deep. Thank you for the tip /u/gelisam
The unusual bit about class Exchange where getBalance :: IO Balance placeOrder :: Order -&gt; IO () is that it's a _nullary_ type class, which doesn't constrain any type. That is, unlike `Ord a =&gt; ...` or `Eq a =&gt; ...`, it's just `Exchange =&gt; ...`, not `Exchange a =&gt; ...`. This is unusual, but supported: -- or NullaryTypeClases on older GHCs {-# LANGUAGE MultiParamTypeClasses #-} class Exchange where getBalance :: IO Balance placeOrder :: Order -&gt; IO () getBalAndPlaceOrder :: Exchange =&gt; Order -&gt; IO Balance getBalAndPlaceOrder order = do placeOrder order getBalance Then each of your modules can define an instance of `Exchange`. One problem with that solution is that you can never directly or indirectly import more than one of those modules, because there would then be two overlapping instances in scope. So you can't, e.g. write a test suite which tests each of your exchanges. One solution is to [scrap the typeclass](http://www.haskellforall.com/2012/05/scrap-your-type-classes.html), that is, to use a record instead of a typeclass: data Exchange = Exchange { getBalance :: IO Balance , placeOrder :: Order -&gt; IO () } getBalAndPlaceOrder :: Exchange -&gt; Order -&gt; IO Balance getBalAndPlaceOrder exchange order = do placeOrder exchange order getBalance exchange There are other ways (which the other commenters have already covered), but this one is probably the simplest.
I'm relatively new to Haskell but have a decent grasp on MTL. I was planning on creating an ExchangeM monad with ReaderT and ExceptT for executing the functions. Do you think Freer would be a better approach to this? 
Thanks for the reply, I like the second option more. As I mentioned in another reply I was planning on incorporating an MTL monad stack for instead of using IO for the exchange functions. Would the second way fit in with that?
Oh sorry yeah of course. That is a pretty simple way. Is it just me or does that kind of feel like we are creating an object with this approach?
The problem is that the most of the haskell ecosystem is made of then ton hammers. At least the most publicised ones. Haskell has an ecosystem made by star programmers, not made by practical people want to get things done. 
Oh yeah makes sense. This is quite a simple approach. Would you recommend it over the others for any reason?
Pardon me for the misreading. I'm not sure there's a recommended way but there's an easy way. One possible easy way is the following: * brew install stack And then use stack to install all your dependencies including ghc and cabal. To remove: * brew uninstall stack * rm -rf ~/.stack * rm -rf ~/.local
I think this certainly applies to what gets the most attention, most definitely on this sub. I am not convinced this really applies to the community as a whole. In my opinion, most of the gaps that do exist are due to a lack of widely communicated best practices for library design, the relative lack of commerical interest in the language, and the smaller size of the community, not necessarily due to preening rockstars.
In that case, I think that what you have already is the best way to write it. The suggestion by /u/gelisam is cool, but I agree that the complexity is not worth what you get in return.
I think this is just what I am looking, it mostly type checks apart from one point. instance MonadIO m =&gt; MonadExchange Kraken (Exchange Kraken m a) where So Im guessing Exchange should be ExchangeT? this won't type check for me instance MonadIO m =&gt; MonadExchange Kraken (ExchangeT Kraken m a) where Here is my ExchangeT newtype ExchangeT e m a = ExchangeT { unExchangeT :: ReaderT Config (ExceptT Error m) a } deriving ( Functor , Applicative , Monad , MonadIO , MonadError Error , MonadReader Config ) Where am I going wrong?
3 job posts from 3 great Haskell companies in less than 2 days.. what's happening to "avoid success at all costs"? :)
What's the error?
Best people to ask are the authors but I’m pretty sure they get tired of answering the same questions all over again. u/bitemyapp u/Mob_Of_One u/Artyom 
I'm in the northern virginia area
Got it in the end. So I've got everything type-checking here. But is this the general way MTL classes are defined and used? https://pastebin.com/Wh3UDCHM For example, should I be returning the Either or using ExceptT to throw an error? Thanks for your help btw. 
Well, since all of your functions seem to return the same error type, it's probably better to use the ExceptT layer for it. Then the only place where you need to handle them is when you finally run your exchange computation. It is a bit of a tradeoff because you can't catch the exceptions on individual function calls (without introducing an additional method into your `MonadExchange` class). What you also want to do is provide default implementations for your methods so that the class can be easily derived for other transformers. Slightly more controversially, you can define an overlappable instance that will automatically work for all transformers.
Very interesting. I was wondering if you see any benefit on wrapping your maintype with a newtype wrapper. Something like that: newtype AppM a = AppM { unAppM::ReaderT AppEnv (ExceptT AppError (LoggingT (IO a))) deriving (MonadReader AppEnv, MonadError AppError, ..... Seems like to get better typesafety, you would need to create your contraints anyway.
So many choices :)
Instead of a typeclass-based approach perhaps the shared API for exchanges could be defined in a [module signature](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/separate_compilation.html#module-signatures), and exchange-general functions could depend on that signature instead of on concrete exchanges. An even more basic solution would be to use a good old record-of-functions.
I use Nix on OS X and don't use stack at all. I do not have much of anything install in my nix global package database. Instead I just run `nix-shell` on a per project basis. on `nix-shell -p haskellEnv` where `haskellEnv` is a package group I created with a few tools I commonly use. 
My reasoning is that Haskell is so painless to refactor compared to other languages that going with the simplest approach (not the overly simplified one) is usually the best idea. If it starts obscuring your ability to describe the problem domain or starts getting in the way, then you can upgrade to more bells and whistles (which, to me, will now no longer be bells and whistles but will be the new simplest way to think about things)
I'm trying to wrap up http://haskellbook.com first, but after that, I'll be working on https://lorepub.com/product/cookbook I'm also looking for authors who are interested in working with me (as Lorepub). I think the process we used for Haskell Programming from First Principles is repeatable and I'd like to see if it can be used to help other authors make better books.
🔥🔥🔥🔥🔥
The other approaches have some benefits over this one, but they also bring some extra complexity which may or may not be worth it. So until you get annoyed at having to pass this `exchange` value everywhere, or until you get into a situation in which you wish you could test your API without running in IO, I recommend starting with this one. 
It depends what you want to do. The host could be deployed NixOS running Kubernetes and then use containers to deploy the app on top.
this may of some help. https://github.com/erkmos/haskell-companies. I'm on the West Coast. :D
&gt; Interested in learning more about AI and blockchain technology Sounds like the person who wrote that job advert was writing lots of funding applications right before, and was in let's-use-all-the-buzzwords-mode.
There is! https://en.wikipedia.org/wiki/Haskell_Glacier. ;)
Oh man, you got me, a tiny buzzword management blunder!
I guess they are referring to their work on linear logic : https://www.tweag.io/posts/2018-03-08-linear-sort.html 
I duno. I'm fairly indifferent to that, because I can't believe the demand for Haskell programmers would ever be strong enough for someone like me (or really: any "ordinary" Haskell programmer) to be hired to use Haskell.
"lack of widely communicated best practices for library design" That is the main issue. This makes the language with a fragmented code-base. But a deeper problem is that there are no best practices or worse still: the best pratices change from year to year. I think that Haskell is not yet mature. It has an space of options so huge that has not been exhausted.
Oh shit. This *is* a great idea.
You'd be surprised!
https://gist.github.com/af5837b5aeb222e861fbf80e48c6c947
Thanks
You might want to read this: https://ghc.haskell.org/trac/ghc/wiki/LinearTypes
This is nice, succinct code! Well done. One thing to note though is that my original code supported functions with parameters of different types. For example, it could tabulate `f :: Int -&gt; Bool -&gt; Int`. I don't think this code can, because you can't stick `Bool` and `Int` into the same list without an `Either` or other sum type. It's a fun problem. Thanks for posting
My setup: * macOS High Sierra * stack * VS Code * ghcid * fast-tags * `stack haddock` Works great for me with fast type-checking and jump-to-symbol. There's some features that I don't have like seeing the type of an expression, which HIE, intero, ghc-mod etc are supposed to provide but none of them worked for me when I gave them a try.
I originally got the idea from /u/tathougies. There's nothing on hackage for it yet AFAIK, but as /u/ephrion points out on slack, generalizing the constraint to `Generic1` would allow us to abstract over `Maybe` into an arbitrary applicative, and get `gtraverse` for free. This would be the more valuable package to exist :)
Sandy gave me a shout out in his post, but my database library [beam](http://tathougies.github.io/beam/) has used this technique for the past two years to represent table types in Haskell. I've personally found it to be very useful, and easy to work with!
Congrats!!
Galois has an office in NOVA.
That's actually really neat. I didn't know that, and it wasn't apparent at the time I wanted it :) Thanks for the tip
`HKD` can be seen as an example of [*defunctionalization*](https://typesandkinds.wordpress.com/2013/04/01/defunctionalization-for-the-win/), a way to encode higher-order features (that would otherwise not be available in the type level of Haskell) with first-order constructs. In `HKD`, `Identity` is not directly applied, but is used as a "defunctionalized symbol" for the actual identity function (that doesn't wrap its argument). There is a more general `Apply` type family in the [*singletons*](https://hackage.haskell.org/package/singletons-2.4.1/docs/Data-Singletons.html#t:Apply) library but it's pretty heavyweight. It might be worth putting it into a separate package. `gvalidate` is an example of a "generic traversal", and some further generalizations can be found in [*generics-sop*](https://hackage.haskell.org/package/generics-sop-0.3.2.0/docs/Generics-SOP.html#t:HSequence), [*product-profunctors*](https://hackage.haskell.org/package/product-profunctors-0.9.0.0/docs/Data-Profunctor-Product-Adaptor.html#v:genericAdaptor) and [*one-liner*](https://hackage.haskell.org/package/one-liner-1.0/docs/Generics-OneLiner-Binary.html#v:gtraverse). It takes just a few lines (not counting all the extensions) to massage their very general interfaces into something close to `gvalidate`. [Gist using *one-liner* to implement `gvalidate`](https://gist.github.com/Lysxia/70bfeb67071fdd23f5d68eef7d3664f8)
This is also called the "functor-functor" pattern by this post https://www.benjamin.pizza/posts/2017-12-15-functor-functors.html (without the `HKD` family). Discussion on reddit: https://www.reddit.com/r/haskell/comments/7jzwvi/functor_functors/
This is very insightful! The linked blog post points to this cool paper by Mauro Jaskelioff and Russel O'Connor: "A Representation Theorem for Second-Order Functionals" (https://arxiv.org/pdf/1402.1699.pdf), which provides free constructions for types of this form: forall f. c f =&gt; (k -&gt; f v) -&gt; f a With several different constraints `c`: `Functor`, `Pointed` and `Applicative`, which match those that /u/ndmitchell and I rediscovered. Then, on page 23, they define the free construction for `c = Monad`, which is the same as yours, i.e. `Free (PStore k v) a` -- this one is different from the one we (re)discovered. The paper has lots and lots of other mind-bending stuff, so it will take me a while to fully understand it. What's most surprising to me is that `PStore` seems to appear in free constructions twice: in `Free (PStore k v) a` (for `c = Monad`), but also it is by itself a free construction for `c = Functor`, i.e. forall f. Functor f =&gt; (k -&gt; f v) -&gt; f a ~ PStore k v a I don't understand what this means and my brain starts to hurt, so I'll pause here for a while :-)
Curious, is https://github.com/tweag/asterius related to https://www.reddit.com/r/haskell/comments/7ax2ji/haskell_on_the_front_end/ ?
Since firstFor ignores its first argument, you basically have tsko &lt;- ts, but ts isn't a monadic action, so that's why you get the error about expecting m KAutomat. Try let tsko = firstFor ... instead, or replace ts with pure ts or return ts.
holy shit this is awesome
Earlier, rather than use a rank-2 type, [I tried having exactly one subtree type per tree](https://github.com/rampion/tree-traversals/blob/cd23abed144cfc8aabd4c44d178f080eff3eb019/src/Data/Traversable/TreeLike.hs#L15): class (Functor tree, TreeLike (Sub tree)) =&gt; TreeLike tree where type Sub tree :: * -&gt; * treeTraverse :: Applicative f =&gt; (a -&gt; f b) -&gt; (Sub tree a -&gt; f (Sub tree b)) -&gt; tree a -&gt; f (tree b) I feel like the rank-2 version is better, but the reason I switched was that that version required `-XUndecidableSuperClasses`, which made my errors much less legible. The version prior to that assumed that subtrees were of the same type as the tree: class Functor tree =&gt; TreeLike tree where treeTraverse :: Applicative f =&gt; (a -&gt; f b) -&gt; (tree a -&gt; f (tree b)) -&gt; tree a -&gt; f (tree b) which I ditched when it proved that making an instance for forests of rose trees was kludgey.
You would make your user type a 'higher-kinded type.' data User f = User { name :: f Text, age :: f Int } Now, your `ParsedUser` type is the exact same as `User (Either Text)`. You may want to have a user type where the fields are just values. newtype Value x = Value x Now, you can just construct simple user values: `User (Value "John Smith") (Value 30)`. Of course, it's better to use the pre-built `Identity` type for this! There's a [great post](https://np.reddit.com/r/haskell/comments/884pe0/higherkinded_data_reasonably_polymorphic/?st=jfd7ojyf&amp;sh=1183c6c0) on this pattern (include how to get rid of the `Value`/`Identity` unwrapping) today.
My [beam](http://tathougies.github.io/beam/) is not as 'type-safe' as it sounds. In particular, tables and all are just values. Although we provide a lot of generic machinery to build them easily at compile-time, it is straightforward to build them at run-time. I am happy to assist. Feel free to PM me, or join our IRC channel on freenode #haskell-beam and ping me.
Nope. Different projects; different strengths. Frankly, WebGHC seems much easier to implement; it's pretty close already, I just haven't had time for it :/ The main advantage to their compiler is that it will have a custom codegen and runtime, which will likely offer a 2-3x performance improvement (until wasm supports LLVM's tail calls, in which case I expect WebGHC to switch to the LLVM backend and close any performance gap). Personally, I consider a custom runtime and codegen a massive maintenance problem. The lesson we should learn from GHCJS is that having to duplicate all C level code and maintain a separate compiler is just too large a maintenance cost, which necessarily leads to inconsistent / bad experiences and slow update times (despite great efforts). As for the listed drawbacks to WebGHC: - Windows support: Actually there's no inherent reason WebGHC's work won't work on Windows. I haven't tested it, but I think you could build the toolchain on Windows pretty easily. We use Nix to make it *really* easy on Linux, and to aid developer experience, but it's not necessary. This complaint needs testing. - LLVM dependency: I don't really see this as a problem. Certainly not as great a problem as depending on a third party compiler with third party runtime shims... *Note: I fully expect 100% of the GHC work in WebGHC to be upstreamed. So it's perhaps inappropriate for me to be using WebGHC as the brand name; I'm just holding off on saying "GHC" until I actually have something upstream.*
fortunately, this kind of DSL also works *really* well for Servant! [`rowdy`](https://github.com/parsonsmatt/rowdy) has a Servant interpretation already. I need to make it extensible somehow (probably tagless final?), but it mostly works.
I can't help you with using an ancient cabal and Haskell platform. have you tried using `stack`? 
I'm aware of stack but haven't used it. ATM I'd prefer to stick with the HP if I can, though the ancient version has been bugging me for a while. 
Hm. That's nice. I'm maintaining both a servant project and a yesod one. But the README implies that the Servant implementation is not there: &gt;# Future plans &gt;Currently, `rowdy` intends to support Yesod-style routes concretely and completley. It will be made extensible so that Servant-style routes may be generated as well
There are lots of different lens types. Even for (conceptual) lenses there are multiple types, but you know, traversals, prisms, isos, getters, and so on.
So, is `moeb` a [build system](https://www.reddit.com/r/haskell/comments/85qdvf/build_systems_%C3%A0_la_carte_pdf/)? :-) P.S.: Some operators seem to have been eaten by Wordpress, e.g. `&lt;&gt;` and `&lt;$&gt;`.
Honestly I don't see it as much different than JS, except that new fancy crap has a better chance of not being incredibly stupid, fragile, and overengineered, comparatively. And as stated, there is less prior art and community wisdom to draw on. I'd much rather pick from a wide set of basically decent, well engineered solutions that may be broader than the problem at hand then a large collection of bullshit over opinionated frameworks that don't address my needs in a language that's harder to work with, which is what most other languages seem to have on offer.
In a strictly typed lang like Haskell is an IDE could do so much good things (show type, insert type, squiggly-red-line indicate error, type safe refactors, type-aware autocomplete, ...). Now I agree the IDE tooling for Haskell is not top-notch; it takes some effort to set it up, once set up is rather brittle, has rough edges and lack certain features. But saying "just ignore" raises my interest in some additional explanation: why ignore said IDE tooling?
Nice. But something always bothers me with such tricks: You can only use them if you can trust the input to not send your nice lazy program into a ~~loep~~ loop. And, of course, checking whether the list of nodes in this example are cyclic requires essentially calculating the heights… Maybe if we could have a RTS that guarantees that a certain exception is thrown upon a loop, then one could run risk running such code on untrusted input.
Yes, but that would be a slow Set. A fast set would require Hashable =&gt; ...
&gt; It'd be really cool to have a single route definition that you could then interpret into a Yesod server and a Servant client. I guess that would indicate some kind of elegance or correctness in the design, but it's also actually completely useless practically speaking.
Gah, I read that incorrectly. I was thinking yesod server + servant server. 
&gt; Maybe if we could have a RTS that guarantees that a certain exception is thrown upon a loop, then one could run risk running such code on untrusted input. If we had an RTS that could throw an exception upon arbitrary loops, then we should all quit programming and praise our new extra-dimensional overlords. As it is the RTS already throws an exception on trivial loops, detected via garbage collection.
Sandy: Your turn of phrase tickles my toes!
No: https://www.reddit.com/r/haskell/comments/85qdvf/build_systems_%C3%A0_la_carte_pdf/dvzvmoh/?context=1 &gt; [Lazy evaluation strategies] don't do incremental recompilation after mutation.
I don't know too much about Trees That Grow, but this appears related.
Where I went to university (Darmstadt), people didn't go to the user groups just for fun, the university has enough tutoring. Furthermore, the user group will have content at a completely level than the freshmen.
Dont you think $50/hr is too high for an experimental project?
And the nonreflectivity of floating point comparison is arguably a misfeature.
As best I can tell, there are absolutely no drawbacks to this approach other than possibly the portability issue (but whom are we kidding -- none of modern-day Haskell is portable anyway :) )
I have had that. Have you updated your packages recently? I think I've not gotten that since upgrading to the new intero version, but I might just be getting lucky. I don't think it has anything to do with flyspell, I don't have a spelling plugin installed - too high false positive rate for me.
The main drawbacks would be: - Worse error messages (not a terrible problem) - Inability to unpack single-constructor-data-types (this is a bummer depending on what you are doing)
This. Package. Documentation. Is. Outstanding!
I'd guess some deriving mechanisms won't work through the type family.
I essentially agree, but I expect more from the haskell language and his community. It is not fair to blame the external world for the relative failure of Haskell these 20 years. It is is the best language for most real world cases (I think so) then something must be wrong in the community 
To know what an Ethereum Virtual Machine is read here: https://themerkle.com/what-is-the-ethereum-virtual-machine/
interesting
Here's an entirely different way to skin that cat: using [K Frameworks](https://github.com/kframework), it is possible to define the semantics of every language with the lofty goal of creating a sort of programming babelfish. [EVM Semantics](https://github.com/kframework/evm-semantics) [Haskell Semantics](https://github.com/kframework/haskell-core-semantics) [Plutus Semantics](https://github.com/kframework/plutus-core-semantics) [IELE](https://github.com/runtimeverification/iele-semantics) semantics I'd also recommend [Plutus](https://github.com/input-output-hk/plutus-prototype) because it is a Haskell-like language developed from the ground up to work with the blockchain. There are some key differences but the syntax is VERY similar and it isn't as lazy as Haskell, which, from my understanding, is better suited to a cryptocurrency virtual machine.
Hi there, we've open sourced the library here: http://hackage.haskell.org/package/odbc
Congrats! This issue led me through Oleg's gist to [another great one](http://oleg.fi/gists/posts/2017-04-18-glassery.html) that I hadn't seen before.
If there is anyone interested in Haskell internship in Asia, please email me: allenleein at gmail
What makes 'tying the knot' different from other forms of recursion (where termination checking is impossible). The RTS guarantees that if a thunk attempts to evaluate *itself'* to normal form, then an exception is thrown. However, it is rather rare for a thunk to evaluate itself, except in pathological, specifically crafted cases. The RTS also throws an exception when it detects mvar or stm deadlock. It's quite robust, but a general solution is of course impossible.
The libsodium bindings, saltine, have[ easy key generation, sign, and verify routines](http://hackage.haskell.org/package/saltine-0.1.0.0/docs/Crypto-Saltine-Core-Sign.html). This has the advantage of calling out to a well reviewed and maintained library. If you don't like have the external library dependency then there are a large number of ed25519 implementations for signatures and verification. Austin's package named ed25519 is [well documented](http://hackage.haskell.org/package/ed25519-0.0.5.0/docs/Crypto-Sign-Ed25519.html) and uses the ref10 C code.
If the number of applicants doesn't pick up soon, I'll have to conclude that $50/hr is too low!
I guess just pressing Control-G probably fixes it without enabling any debug mode? I've had spacemacs hang like that lots of times but never had anything C-g didn't fix.
To be clear, I'm open to considering people with less experience as well. I'm actually wondering if the offered pay rate has intimidated people into not applying.
I've suggested cryptonite in the past but there is a lot of library bloat there these days. This combined with the complexity of how byte arrays are handled has made me more hesitant, particularly in cases like this where the need can be filled by one of many other smaller libraries or bindings.
updates on Joy of haskell https://typeclasses.com/news/2018-03-typeclasses-born
It depends on where you live. Remote jobs are hard to get because there's a big pool of amazing programmers who want to use haskell. And there aren't many local haskell jobs outside of tech hubs. The good news is that within tech hubs the situation completely different. Once the local enthusiast pool is used up companies struggle to find competent haskell programmers. For instance, there were at least three haskell companies in boston having trouble finding people this winter. I'm sure that will happen again.
What's your motivation for this? This seems more like a research project. Are you an academic? How is this different than Coq, Liquid Haskell, etc? Do you have formal semantics? 
I really doubt it. Anyone can "have trouble finding people" because they're not being realistic. I just don't believe this thing has ever happened: &gt; the local enthusiast pool is used up
Second this, I've found saltine easy to work with
Irrelevant linguistic side note: I believe the antonym of "fast" in "hard and fast" is "loose", not "slow". I'm pretty sure that idiom uses "fast" in the same way as things like "steadfast", "hold fast", and "fasten" - meaning "tight". 
My motivation, ultimately, is to generate a general purpose language that people actually use. At this stage, it is more of a research project. I am not an academic, which is why I'm inclined to look for help from those who could fill in gaps in my own knowledge. This project is not based on the calculus of constructions, or any dependent typing. The entire language is total, unlike Liquid Haskell. I am trying to keep the semantics as concise as possible. I don't have the core grammar specified in formal semantics, but a Haskell runtime for evaluating it is only 22 lines long. My immediate focus is on finishing an LLVM backend and then writing code to evaluate the runtime characteristics (at least memory use, maybe some vague estimate for CPU time) of any expression in the language.
They should probably offer IEEE equality as a special operator like Data.Float.(===) or so, and leave (==) sane. Haskell is flexible enough that we don't have to restrict to only one kind of equality. But, of course, that would be too much of a breaking change these days. (Though an alternative Prelude would probably be enough to get it?)
Keep in mind this would unravel a lot of the class hierarchy all the way down to `Real`. Mind you, "Real" is a pretty terrible idea, as it basically says you'll never do arbitrary precision reals. Also, users would be quite shocked if they can't compare for inequality (keep in mind Eq is a superclass of Ord, so you'd need a much more fundamental reordering to put a partial order above Ord in the class hierarchy and tie &lt;=, etc. to that instead.) It'd probably be easier to build up the class hierarchy more directly with a notion of a partial equivalence relation, partial order, then Eq and Ord can be total equivalence relations and total orders, and Real would then require a partial order. class PER a class PER a =&gt; PartialOrd a class PER a =&gt; Eq a class (PartialOrd a, Eq a) =&gt; Ord a class Eq a =&gt; StructuralEq a class (Ord a, StructuralEq a) =&gt; StructuralOrd a instance (Ord a, StructuralEq a) =&gt; StructuralOrd a -- pushout PER / \ PartialOrder Eq \ / \ Ord StructuralEq \ / StructuralOrd An Alternative Prelude isn't enough as all of these alternative preludes have to share the classes involved. This is what has complicated attempts to offer a `haskell2010` package sans AMP, etc.
The last command may also remove other programs' stuff, I'd recommend `rm ~/.local/bin/stack` instead.
Simplest: https://hackage.haskell.org/package/ed25519
I went with that, seems to work fine so far. thanks
Not strictly true; using `StandaloneDeriving` you can derive everything for every monomorphic f you want, although it's a little more work: deriving instance Eq (Person' Identity) deriving instance Eq (Person' Maybe) this works no problem :) I'm pretty certain it's possible to do this for an arbitrary `f` as well, but it might take some time to convince GHC too. Let me get back to you!
It's pretty extensive, that's true. What do you mean re. byte arrays?
The arguably-strange behaviour is not the fault of FunDeps but of UndecidableInstances. When GHC verifies the uniqueness of `b` given `a` in your instance, it assumes that the `b` is fixed by the fundep in the `Meow` superclass. (Think of it this way: if you had `class Foo a b | a -&gt; b; instance Foo a b =&gt; Meow a b` there would be no problem.) But that dangerous instance is only permitted when you allown undecidable instances.
Yes, but shouldnt there be some warning/error about this, because at the end of the day, FunDeps got broken (by UndecidableIn)? Maybe just detecting the parallel use of both extension, or do all type class instance resolution, and check to see if any fundeps are violate sounds viable to me.
&gt; hard and fast Yeah, it's nautical. Hard as in 'definite', fast as in 'secured'. So, 'definitely static', or 'totally not going anywhere'. It used to mean 'beached,' but also could be used to mean 'absolutely secured.' Sort of a weird definition of 'fast', where it's almost the exact inverse of the typical meaning. Used to bug the crap out of me when I was a greenhorn.
Well that makes them non-minimal, but I think they still satisfy the definition of correctness assuming there are no dependency cycles.
Can you articular what's 'broken' about the behavior? Did it segfault?
We have Int -&gt; Int, and Int -&gt; Bool at the same time, but according to funcdep, it should not happen - if a is the same (Int), b cannot be different value (Int and Bool).
There is *no* system that can be built that can detect the unboundedness of your first example in the general case. My claim was: &gt; The RTS guarantees that if a thunk attempts to evaluate itself' to normal form, then an exception is thrown In your example, there is *no thunk* attempting to evaluate itself. The RTS *will* throw an exception here, if `x` is evaluated, because the thunk of `x` *directly* invokes `x`. let { x = x } in x In my example, due to the sharing of `x`s thunk, the RTS throws the exception. In your example, there is no sharing, so the RTS cannot detect it. In my opinion, implementing any smarter strategy is simply a waste of time and can only decrease performance. You could extend this to a slightly more general case, but you would end up doing full on tree traversals from each object for a very weak 'guarantee'. 
&gt; There is no system that can be built that can detect the unboundedness of your first example in the general case. I never claimed that there is! (Although there are systems that detect diverge, and catch easy cases like this. They are just not ever both sound and complete.) &gt; In your example, there is no thunk attempting to evaluate itself. Rather there is an infinite chain of thunks trying to evaluate ever more thunks. Sure the is: The thunk `foo`! &gt; The RTS will throw an exception below, if x is evaluated, because the thunk of x directly invokes x. &gt; &gt; let { x = x } in x Unfortunately it will not always detect that: Prelude&gt; let x = x in x ^CInterrupted. I’ll repeat myself (for the last time): I know about the undecidablity of the halting problem. I also know how the RTS tries to detects loops. All I am saying is this detection is currently not guaranteed by GHC’s RTS (as shown by both my and your example), and that it would be good if it were a guarantee.
Ah, you have to compile it to get the loop detection to work. It doesn't do it in GHCi. &gt; Sure the is: The thunk foo! `foo` doesn't evaluate itself...
&gt; `UndecidableInstances` is a risky extension It sounds scarier than it is. While GHC doesn't have a termination checker detecting whether code terminates at runtime, it does have a termination checker detecting whether instance resolution terminates at compile-time. That termination-checker is extremely conservative, which gets in the way of fancier compile-time computations, so it's quite common to turn the termination checker off by turning on `UndecidableInstances`. The worst which could happen is an infinite loop at compile-time, which won't even cause compilation to go on forever because ghc increments a counter and gives up if instance resolution takes too many hops. So I really wouldn't say that `UndecidableInstances` is "risky".
It's usually abbreviated "FunDep", not "FuncDep".
What u/bitemyapp said: use syntax highlighting and use GHCi alongside Sublime. The more complex plugins are a pain in the ass to install especially on Windows and at least I feel I'm just better off using the time learning to code than trying to configure GHC-mod etc
Dependency management mostly hasn't been a problem for me. It's just my system, so having a global installation I control isn't a problem. I'm familiar with the tools in the Haskell Platform. The point was to spend time learning how to use gtk in Haskell, which I can now do without needing another change of toolset. Also, I don't react positively to sales people turning up uninvited and trying to sell me something I didn't ask about. 
Of course not! More jobs brings in more Haskellers from outside, etc. However, this isn't really significant compared to the two colossal forces that make it hard to search for Haskell jobs in other environments -- the incredible supply of remote haskell talent and the nonexistent demand for local haskell talent in most places that aren't tech hubs.
This has nothing to do with infinite loop. I had edit the post to demonstrate that.
This has nothing to do with infinite loop. I had edit the post to demonstrate that. 
Nay, importing a module shouldn't change the language.
Alternative to absence3, ``` firstFor x ts = return ts ```
The alternatively is dealing with what is for all intents and purposes a buggy type inference algorithm.
I ran into something similar with nix recently -- check if you have a separate mount for `/tmp` that has constrained space -- nix often does its builds there...
I do not have the directory /etc/nix/
No. Thank you!
What OS are you on? Did the installer ask you if you wanted to add the reflex binary caches to your system? I ran try-reflex on my Mac last night and it asked me if I wanted to set up the binary caches, I wonder if that is OS specific somehow. 
I have some notes on setting up the binary caches [here](https://blog.qfpl.io/posts/reflex/basics/exercises/introduction/), under the Binary Cache Setup section, which might help. 
The platform installers put things in multiple directories too, with symlinks, so you can switch between them. You can switch between them with `activate-hs` and remove them if you really want with `uninstall-hs`. Everything goes in `/Library/Haskell` except for your local stuff which goes in `~/.cabal/`.
Best-ish way to do random access on files without filling my code with hSeek? I'm parsing Android's DEX files and they have all sorts of tables with offsets to strings and stuff. For the header I'm just using `cereal`, but the Get monad doesn't look appropriate for jumping around... right? Ofc, I'm a newbie :)
&gt; but without the Meow a b constraint, the instance is rejected Because it would mean that `b` is not uniquely determined by `a` (in the context of the instance). In the questioneer’s code the type checker can assume that `b` is uniquely given `a`, because the uniqueness propagates from the fundep in the instance context (namely `Meow a b`), never mind that it makes the instance undecidable. As I suggested in my comment, imagine we had `class Foo a b | a -&gt; b; instance Foo a b =&gt;
I haven't done this, but usually it's some PATH issue. Check if your PATH is properly configured for this.
`rank2classes` offers a `Traversable` class with traverse :: Applicative h =&gt; (forall x. p x -&gt; h (q x)) -&gt; t p -&gt; h (t q) We can write instance R2.Traversable Person' where traverse f (Person x y) = liftA2 Person (f x) (f y) Then validate :: R2.Traversable t =&gt; t Maybe -&gt; Maybe (t Identity) validate = R2.traverse (fmap Identity) Note: the `HTraversable` class in `compdata` is basically the same.
Thank you for various information. For EVM, there is also the following collection of diagrams: &amp;nbsp; * [Ethereum EVM illustrated](http://takenobu-hs.github.io/downloads/ethereum_evm_illustrated.pdf#page=48) * https://github.com/takenobu-hs/ethereum-evm-illustrated 
Ugh. Reflex-platform's automated binary cache configuration is consistently its most inconsistent piece. It breaks all the time and someone has to be taught all about how to setup the config themselves. Nix really needs an option for Nix expressions to register their own cache, asking the user for trust at eval time.
I think you barely missed the deadline for a lot of them. For a high schooler, your best bet is probably to apply for the Summer of Haskell next year. Other than that, internship postings have been appearing here and on haskell-cafe every few months, so keep your eyes out. Also look at VacationLabs and /u/saurabhnanda, they are based in India but I heard they take remote interns.
You have demonstrated that there is not an infinite loop at the term level, but that is not the point. The point is that there is an infinite loop at the type level (`Meow a b =&gt; Meow a b`).
But it is assumed that `UndecidableInstances` are only a compile time risk, so a runtime infinite loop with no recursion or clever omega combinator stuff seems a little strange.
Yeah you can what?
It's nestled away on the sidebar. http://reasonablypolymorphic.com/blog/archives/ Any suggestions for how to make it more visible would be helpful :)
Well, I think the runtime infinite loop isn’t really UndecidableInstances’ fault. That’s a wrong program. UndecidableInstances very indirectly allowed it to compile. The weird part is the FunDep stuff (you can’t write a forall a b instance normally but you can by constraining it with itself) So I think UndecidableInstances is still fine outside of this FunDep weirdness.
Your second program does not loop for me.
Actually it looks like the second example didn't infinitely loop on my machine anyway. And the first one should infinitely loop. In that case I would say the main sketchy part is that it did allow the FunDep to be violated.
Worked at Tweag for about 3 years, I'd recommend it.
Cool! I [previously wrote](https://www.benjamin.pizza/posts/2017-12-15-functor-functors.html) about this trick of storing lenses in a value of a template type, though I didn’t go so far as writing `Generic` instances. I used a slightly more general type, though: `newtype FLens t a = FLens (forall f. Lens' (t f) (f a)); type Lenses t = t (FLens t)`, which allows you to use the lens for any instantiation of the template, not just `Identity`.
How big of a concern is this in everyday life? As far as I know, I've never explicitly coerced anything in ~4 years of writing Haskell full time.
Gentoo
`‘` is the literal representation of a character (`Char`). `“` ist the literal representation of a string (`String`) which in Haskell ist just a list of chars (`[Char]`). 
I did not add nix applications to PATH. Do you think that it needs to be done? 
Please give this information/question as feedback to the code jam team. I think they could provide a list of all available libraries for each language in the docs.
Gas costs and lazy evaluation are at odds of each other. It is probably a good idea for a language designed to work on a blockchain to not be lazily evaluated, should make it easier to reason about gas costs.
You can derive instances for an arbitrary `f` like this: data Test f = Test { a :: HKD f Int , b :: HKD f Bool } deriving instance (Eq (HKD f Int), Eq (HKD f Bool)) =&gt; Eq (Test f) 
That makes a ton of sense. Thanks!
No this is definitely not a PATH issue. The error would have come much earlier.
I like that with the record-of-lenses we don't have separate top-level names for the lenses and the accessors. We can get to the lens using the accessor.
When I first glanced at the post, I initially got confused. Restating it: "xyzzy" ia a string, "x" is a string, 'a' is a character "xyzzy" is a way of saying ['x','y','z','z','y'] The language has no entity for string; a string is just a list of characters. 
That 'fast' sounds a lot like german 'fest' as in 'tight'.
&gt; Person (LensFor lName) (LensFor lAge) = getLenses Needs some TH.
There should be a "disable auto-op" type of plugin somewhere for WordPress that should help. WordPress also does some sanitizing to all of the posts iirc so there should be a few plugins somewhere to make it behave nicer for odd symbols without having to wrap everything in &lt;pre&gt; HTML tags.
In the nautical sense, iirc fast is really just a shortened form of fasten(ed)
Where are you seeing 1980? Wikipedia says 1990: https://en.wikipedia.org/wiki/Haskell_%28programming_language%29
Lots of times when you `fmap` a newtype constructor or accessor over a structure, someone's rewrite rule will turn that into a coercion. This happens for lists, `containers` types, and probably a number of others.
I agree with you. What's is funny, is the first time I read the doc about TupleSections I didn't understand anything. Then (months later) I needed it and realized that I needed an extension for something which I though was obvioulsly part of the language.
Cool, thanks! I bet we can improve that still by proving some sort of `Eq1` thing for `HKD`. 
I don't think you can, and that's the problem. There's no way to partially apply the `HKD` family. `HKD f` should have the kind `* -&gt; *` but you can't do that unfortunately. To be honest, I'm not really sure why GHC doesn't just infer those constraints like it wold if the fields were just `f a` instead of `HKD f a`. 
we should call combined lenses glasses haha
&gt; is there any reasoning behind deriving a Num instance for a function (with any number of arguments)? Can you clarify this question? These are reasons to define a Num instance for a function but that doesn't seem to be what you're asking. &gt; When should you derive from Num and implement fromInteger, and when is fromInteger used? Any time you use a numeric literal (`0`, `1`, etc) you are implicitly using `fromInteger`. Similarly, any time you use `fromIntegral` you are implicitly using `fromInteger`. You should derive or define a `Num` instance if/when your type is a numeric type and the operations such as addition, subtraction, and multiplication makes sense. 
&gt; Notice that we *did not* write an instance for (`:+:`) (coproducts), because lenses are not defined for coproduct types. Maybe a good place to use a custom type error?
The same can be asked of a lot of extensions. The answer is usually that they weren't part of the official Haskell spec. Why weren't they part of the spec? It was probably kept small so that it was easier to implement a Haskell compiler without dealing with too many unnecessary surface-level features.
Is there a good resource for an explanation of the Of/On/etc endings of traversal and lens functions? Also on the topic of the lens library, are there accepted guidelines on when to use map vs fmap vs mapM vs traverse vs mapped, etc? (I realize that these all have different type signatures, but they all overlap in at least some functionality.)
i get an error on your example on mybinder.
`lens` offers a whole module full of `newtype` wrappers for optics.
Definitely opportunistic though I’m Not finding where I read it on mobile. There’s not a whole lot of info out about it Plutus yet but there is a working prototype that you can play with at previous link. Phil Waddler is one of two people writing the language. 
If you keep going with these great articles on generics, you're going to have to rename your blog to unreasonably polymorphic :)
servant-client is pretty nice if you're talking to predefined endpoints.
They are the same, yes.
It was always at least somewhat cross-platform, as far as I can remember, though the list of supported machine architectures has changed. The very early versions of the language had quite limited I/O to tackle anyway, so at least in terms of different operating systems on the same underlying hardware, it wasn't too much work to attain cross-platform support. For the case of the GHC implementation (which is now the most important, but in the early history of the language was one of several competing/collaborating options), you can go back through historical releases [here](https://www.haskell.org/ghc/download.html) and see what support for different platforms they had. Even the earliest versions had support for a few different flavours of unix, and different CPU architectures. Windows support was a bit spotty back then, but 2.10 had it, and pretty much every version since 4.06 has supported Windows in addition to various flavours of unix. Mac OS X support was also added early on, I think around version 5. The nhc compiler also supported many platforms from very early on. There are some links to its release history from [here](https://www.haskell.org/nhc98/status.html). I also recall the hugs interpreter running on a lot of different things (especially so because it was written in C, so didn't have the challenge of bootstrapping). HBC also had Windows support from fairly early on, though perhaps just for batch compilation, I'm not certain whether the HBI interpreter worked. More recently, work has been ongoing to bring Haskell to yet more platforms, with GHCJS providing the ability to compile Haskell to Javascript for the web, and there are a couple of projects to get WebAssembly support there. There's also been a lot of work done in cross compilation for mobile devices at various points, most recently, a bunch of effort was put into adding support for compiling [reflex-platform](https://github.com/reflex-frp/reflex-platform) projects for Android and iOS devices, which included a bunch of upstreamed changes to GHC, as well as a pretty involved encoding in nix (lots of changes to nixpkgs which are being upstreamed) of what to do regarding all the dependency issues that crop up in doing such cross-compiled builds.
Me too: &gt; Could not resolve ref for gh:gibiansky/IHaskell/4cd40d186c800b3360761e312d8e9ddacc83c994. Double check your URL. It looks like the corresponding commit is [no longer on github](https://github.com/gibiansky/IHaskell/commit/4cd40d186c800b3360761e312d8e9ddacc83c994). I'm guessing /u/vaibhavsagar rewrote the history of his branch. I'm currently trying https://mybinder.org/v2/gh/gibiansky/IHaskell/example-notebook-fixes instead, but it's currently stuck at the first line of the build log, `Waiting for build to start...`.
Read about minmax, and stochastic minmax algorithms as well as alpha-beta pruning.
There is no real reason to use `map` or `mapM`, since `fmap` and `traverse` respectively are better 99.9% of the time. For `fmap` vs `traverse`, if you can use `fmap` then you should, but if you are trying to do something that you fundamentally cannot with `fmap`, like say a stateful iteration through a list, then you must use `traverse`.
Besides your list I also have `atom-beautify`. It can format haskell code with `stylish-haskell`. 
https://artyom.me/lens-over-tea-1 This is a wonderful resource, its likely to become a book on lenses!
Ahh. That time of year again.
Control.Lens.Tutorial by Tekmo https://hackage.haskell.org/package/lens-tutorial-1.0.3/docs/Control-Lens-Tutorial.html
I've updated the blog post with [a link that works](https://mybinder.org/v2/gh/gibiansky/IHaskell/3cd40d186c800b3360761e312d8e9ddacc83c994). You should be able to use https://mybinder.org/v2/gh/gibiansky/IHaskell/master but might take forever to compile the first time after I make any changes, which is something I'm hoping to address with the combination of Nix + a binary cache.
Lol. Whew
I had my first exposure to Haskell in 1990. I recall that it was initially developed and conceived of in 1988. I was not particularly impressed at the time and it took quite a few years before I fully appreciated it (and also the subsequent introduction of the IO monad). 
I find it a bit humorous that one of the best sources for Haskell's history is... a paper :)
My personal guideline is "use the most general function possible". That means `fmap` instead of `map`, `traverse` instead of `mapM`, and `mapped` if I am only using the Functor instance.
Everyone knows an elephant is an integer.
march 32?
Wait, this is from 2012? So, before `stack`? ROFL 
&lt;sigh&gt; Every year the internet is pretty much useless on April 1. :( When I was 17 it was funny. A couple decades later...not so much.
 asProfit (Sale m) = pure m
In the spineless tagless g-machine (what GHC's runtime system is based on), the sort of recursion in `foo` is converted into a kind of tail call, and so `foo` is never entered from `foo`. You claim that only `let x = x in x` has `x` enter itself, and it certainly seems that way, but if you have thunks that end up resolving to one another in the right way, it can occur at run-time as well. I recommend the book 'the implementation of functional programming languages' by simon peyton-jones for a good overview of the ideas that went into the RTS.
I hate April fools.
I mean, there is some truth here. If library writers are constantly making backwards incompatible changes, you will run into situations where you rely on three libraries, and those three libraries each rely on a different version of some 4th library, and all 3 versions of that 4th library are incompatible with each other. Getting into that sort of situation sucks, and the solution of "fork and fix two of the libraries, and hope that the maintainer accepts your pr eventually" only goes so far. For that matter, even in simpler cases, stuff like "oh, I want feature X from the new version of a library, I guess I have to rewrite every single use of that api that I use constantly in order to work with the new version" can be a massive pain in a larger codebase. Yes, static typing can often catch those issues, but you still have to go through and fix them.
Web design is not my strong suit :) Hiding it seemed preferable to trying to scrunch everything. Better suggestions? I don't use mobile :)
Brilliant!
Also, everyone that has to read and understand this function will lose half a day.
Oh my, I almost got a heart attack when I got to the "obscure startup" phrase. Not one of my best days. Throughly trolled I must admit myself :-) ... 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [reflex-frp/reflex-platform/.../**project-development.md** (develop → f003577)](https://github.com/reflex-frp/reflex-platform/blob/f003577699ad5a47f8275dad4f05cdb15c4bcdf5/docs/project-development.md) ---- 
In my experience with one-liner if you add inline pragmas everywhere all the Generic stuff will be optimized away. (F. e. https://github.com/sjoerdvisscher/one-liner/issues/12) But this is not true in general, see this paper: http://dreixel.net/research/pdf/ogie.pdf
TIL Stack was originally an April Fools' invention Too bad they renamed it... `cabal install cabala` has a nice ring to it... lol
Such a valuable answer! I love the mtl example! Thank you!
I try to maintain backwards compat if it's minimal effort. E.g. Intero can be built with passing test suite from GHC 8.4 back to GHC 7.8. For that very reason; so that you don't have to upgrade all your stuff just to get new features. A new feature in GHCi isn't as exciting if I have to wait 6 months to get to use it because my company is locked on the previous GHC version.
Rich Hickey makes an argument on similar lines but sincerely: https://m.youtube.com/watch?v=oyLBGkS5ICk I think he expressed these ideas: 1. A breaking change is distinguished from a non breaking change. 2. A breaking change to a function (change of behavior or type) means you should create a new function within a different name: foo2 3. A breaking change to a module (removing or renaming) means you should copy the module with a different name e.g. Foo2 4. A breaking change to the package (removing or renaming a module) means you should rename the package. I believe this would necessitate a versioning scheme which would probably be e.g. a datetime, which would track non-breaking changes such as performance improvements, bug fixes, and new functions. So you would specify that you want the version published yesterday of bytestring7 which has the set of modules `Data.ByteString2.*` with `elemIndex3`, because you want the new function `foldPack` and the bug fix in `split`. And you can happily upgrade to that dated version to get the non breaking changes. Tooling would be able to automate the process of creating new changes and would be able automate how you consume changes coming from upstream. Sort of like SemVer or the PVP but actually meaningful.
What's the current best way to start a new yesod-1.6 based project?
It the single day where you have to use your head and don't consume stuff mindlessly.
This is my understanding as well, but it's a good question and I'll look into it :)
People are saying this is due to UndecidableInstances but that doesn't really make sense to me. AFAIK UndecidableInstances just turn off one heuristic that's used to determine that instance resolution will terminate. While this heuristic does prevent the code in the OP from compiling, it's _wrong_. The fact that it compiles with -XUndecidableInstances _and typechecking terminates_ proves it. The reason it compiles is because GHC ties the knot when doing instance resolution. Maybe we should talk about that instead. For example, you can't write the same code using associated types (you really do get a typechecker loop).
But it's not a consequence of `UndecidableInstances`. Not really. The overly strict heuristic just happens to stop this code from compiling because it thinks the instance resolution won't terminate yet it obviously does when you turn it off. Sure, a "bad" program doesn't compile unless you enable the extension, but to me this more or less an accident. 
For a moment, I thought that "burndown chart" was an April Fool's neologism. Turns out it's not…
Almost got me!
"A poor excuse for picking a man's pocket every twenty-fifth of December!" said Scrooge, buttoning his great-coat to the chin. "But I suppose you must have the whole day. Be here all the earlier next morning!" And Cratchit, put down that extra lump of coal!
At first seeing the post, I thought it was about Template Haskell...
Aprils fools aside, there was recently a very [succinct writeup in the Go blog](https://blog.golang.org/versioning-proposal) how things become better if you adopt "semantic versioning" along with "semantic import", i.e. follow this principle: &gt; _ import compatibility rule: “If an old package and a new package have the same import path, the new package must be backwards compatible with the old package.”_ Many haskellers seem to scoff on the idea, though this is basically how the rest of the programming landscape worked for the past few decades (perhaps without explicitly formulating it).
I cringed at the amount of conceptual consistency in the TeamServices section. Someone knows their VSTS. *Shudders*
The only problem I have with VSTS is that it still doesn’t support TPS reports.
Same with a whole host of syntactic extensions, but it adds up.
And the reverse side last year https://www.snoyman.com/blog/2017/04/enough-with-backwards-compatibility :) 
To be fair: * Microsoft [recommends Git](https://docs.microsoft.com/en-us/vsts/tfvc/comparison-git-tfvc?view=vsts), but still supports Team Foundation Version Control. * Support for XAML builds has been **removed** in TFS 2018.
I don't use stack but did you try to unpack package and run `stack install ./wxcore-0.92.3.0`?
This principle isn't absent in Haskell either. It's just not an absolute law.
Lovely work as always. Shame that the evm has such terrible design though :( 
A show/hide button (e.g. the "hamburger" style) would be a good fix, I think. Being able to see the nav is worth the temporary scrunch. I'll see if I have some time to make a more concrete suggested solution.
&gt; Use prefixes and suffixes I prefer PHP's approach: anything fundamentally broken just gets fixed and a "_real" slapped on the end.
Ahh, I've been waiting for this! I'll grab the popcorn and will even consider resubmitting this tomorrow...
This issue is the most serious Haskell ergonomics issue I've encountered since discovering that head is a partial function and is still in the prelude
I think everything you learn around programming can make you better—Haskell is no exception. I think Haskell has really improved my skill set. Many languages can drop in functional concepts but are riddled with cheats, Haskell teaches you how to write clear functional code without cheating. Also, mastery of functors/applicatives/monads gives you an insight into something that’s always been there, but few people truly understand—it’s quite cool.
Do it, John!
Go to the folder in which the `package-name.cabal` file is and run `stack init` to create a `stack.yaml` file. If that succeeds, you should then be able to build it via `stack build`. To use it as a dependency for another project, add the folder which contains the `package-name.cabal` file to your project's `stack. yaml`, in the `packages` section. Note that this will attempt to build using your project's resolver, not the one from the dependency's `stack.yaml` you created above, so you're not guaranteed that a build plan can be found.
Oh, please yes.
I almost commented, did you realize it was April Fool's? Then I realized it was April Fool's.
Good question! So I spent the day learning about core and fighting with stack to be able to see it, and making random tweaks, but here's what I think I've determined: The core generated for generic lens *definitions* is significantly worse than for those written "by hand" (requiring ~300 coercions, vs ~10). However, when you actually go to *use* the lenses, they turn out to get optimized away and result in exactly the same core. That being said, we do pay a small coercion cost (O(10)) for using lenses on our data when represented as HKD, rather than just plain-ol'-data. What does any of this mean? I have no idea, but I *think* it means the performance of this approach is pretty OK.
The response is even better
I am radically ambivalent about this.
Hello I work on compilers and recently, total languages (mostly theorem proving in coq) this seems interesting as a project, do you have more details by any chance?
Nice one ✌
April's fool joke and inside joke in one package ;) *looking at you conduit*
But but but how will I align `-&gt;` with `::` now?
This comment is too true for the occasion
Sure, `:` is a **tiny** bit nicer, but `::` is such an integral part of Haskell syntax that at this point this will cause **SO** much confusion and breakage that there is no way such a minor syntactic change is worth it.
Opinionated answer: * You become aware of distinction between pure and effectful code * You acquire habit to minimize state in your programs
Sounds like your problem is docker, not Haskell!
I often approach people from the opposite angle. Take the language you are familiar with. Write tests for your code. Think about how you could structure your code so that it is easier to write tests, with less ceremony and mocks. Think about what types or preconditions could make some some classes of errors impossible, eliminating the need for a test. Now look at Haskell. Try to express a similar program. Look at how it helps you think about testability (purity). Look at how you can use richer types to eliminate classes of tests needed.
1. Drilling down recursion 2. Understanding the power of functions 3. Doing a bunch of pattern matching leads to considering more corner cases and failure cases in general
I'm sure releasing software on April 1st is frowned upon, but I promise this release is no more likely to harm you, your data, or your loved ones than any other.
Can you share more about your process? I use Yesod with GHCI for development and it’s super fast then I stack build to create a executable and have a docker file to bundle the executable with css/js then send it out. Overall it seems to be the best for what I’m doing.
This takes equally long on my computer where I'm not using docker. Also docker does not have a huge overhead. If anything it takes less on docker because of the caching mechanism. The build time is slow with or without docker 
Dedicate a local machine or get a dedicated ec2 to serve as your build machine. Build there using stack docker integration, producing a docker image, publish somewhere. Download image as needed.
Coercions are free as far as I know.
I am fully in support of this proposal. I was skeptical initially, bu what swayed me was the reference to analogous decisions made in C, and the quote from Kernighan and Ritchie. I am am looking forward to more proposals inspired by C. I am aware that some people will have trouble adjusting to the new visual appearance. The proposal should recommend using a “legacy mode” font in their editor, that displays the unicode character “'U+003A COLON” as `::`, making the transition easier. While we are at it: `forall a.` is strange, we should use `forall a,` to avoid confusion with the function composition operator.
Weird. I mean I might be doing something wrong. So for example with docker these are the steps I'm using # Cached by docker unless .cabal file changes stack install --only-dependencies -j4 # Install app binaries etc stack install Whenever .cabal changes it takes about 25-30 minutes to build on my MacBook Pro 16 GB 1600 MHz DDR3, 2,2 GHz Intel Core i7. Maybe I need to have a dedicated build server that is much faster like the person below is suggesting. Is your machine very fast?
&gt; docker does not have a huge overhead I am not worried about the overhead of running code in a virtual machine, but about the part where adding a dependency to your .cabal file causes docker to start building from _scratch_. My understanding of docker is that it takes a snapshot of the machine after each command in your Dockerfile, so it can skip executing those commands the next time if the input state is the same. By changing your .cabal file, you are changing the input state, so docker starts from its previous snapshot, namely one in which you haven't built anything at all. If you build locally, add a dependency, then rebuild, you won't have to rebuild the packages you have already built. Building from scratch is going to be slow no matter what. So pick a workflow which reuses previous build artifacts instead of rebuilding from scratch. Such as, for example, the default workflow you'd get from `stack` and `cabal` if you weren't using docker to clear their cache of artifacts every time you modify your .cabal file.
you're right that's a very good point. Yeah I don't know why it does that. But I think it's because docker only knows how to cache the entire command or nothing. So I guess it does have this overhead of having to build from scratch everytime. Maybe deploying without docker is a better idea. I have to look into that
My first question was a bit poorly stated, yes I was asking what would a hypothetical scenario be in which a Num instance would be useful. Thanks!
What browser are you using? I know that Firefox has some issues with jsaddle-warp. 
I think the intermediate haskell book ran aground on lack of author time, though /u/int_index may want to elaborate. Two of the authors are also answering questions and running a consultancy at https://dirtcheaphaskell.io/
Doesn't this kind of issue occur all the time for you in existing Haskell then? What about: sufficientlyLongName = firstChoice &lt;|&gt; secondChoice What do you do instead?
Great article. Looking at this: &gt; Setting up redis for dev/test sounded annoying, so I implemented a testing mock that held an IORef (Map ByteString ByteString). I'm wondering how would you go about using an IORef for dev and Redis for staging/prod, for example using `#ifdef`s or is there a better approach?
You can add a backslash before the \# to escape it
Cool! So what's the metric I should be measuring? Terms?
I haven't used `Alternative` very often so far, but I can give you an example for function composition: fooBar = id . omega . beta . alpha fooBar a = id $ omega $ beta $ alpha a Actually, I often prefer to use (.&gt;) = flip (.) ($&gt;) = flip ($) -- which gives: fooBar = id .&gt; alpha .&gt; beta .&gt; omega fooBar a = a $&gt; id $&gt; alpha $&gt; beta $&gt; omega Some longer operator names: fooBar a = pure a &gt;&gt;= alpha &gt;&gt;= beta &gt;&gt;= omega fooBar = pure &gt;=&gt; alpha &gt;=&gt; beta &gt;=&gt; omega I guess I would write your example as follows: sufficientlyLongName = empty &lt;|&gt; firstChoice &lt;|&gt; secondChoice 
Correct me if I'm wrong, but your build times seem to be caused by constantly rebuilding dependencies, you'll have to setup a local hackage or nix binary store that your CI will then publish to, to avoid that.
I’m still learning Haskell so I’m not very good I’m still a beginner 
It will make you an unhappier developer in other languages because you'll always miss it.
The biggest problem with backwards compatibility isn't that you have to maintain deprecated cruft, it's that the deprecated cruft takes up all the good names. This means as the library user you have to be constantly on your toes keeping track of all `fooSafe` versions of things that your application's security and correctness depend on. For example until yesterday I used `decodeUtf8` all the time without knowing that it throws exceptions on invalid input (an absolutely insane default that would hopefully be fixed if backwards compatibility wasn't a concern). This can be somewhat mitigated with tooling supported deprecation markers (and requiring non-use of deprecated functions to compile), but the problem still stands. Hopefully in computing we'll eventually move beyond text and internally references to code will be via immutable and hidden pointers (like UUIDs) so that the user visible name can be changed to make way for an improved version as necessary.
Ah well then consider: {-# LANGUAGE FlexibleInstances #-} {-# LANGUAGE GeneralizedNewtypeDeriving #-} newtype Measure = MeterDist Double -- Or Integer, etc deriving (Num, Show, Eq, Ord, Read) data Unit = Meter | Kilometer | Mile | Foot m,km,mi,ft :: Unit m = Meter km = Kilometer mi = Mile ft = Foot instance Num (Unit -&gt; Measure) where fromInteger i = \u -&gt; case u of Meter -&gt; MeterDist (fromIntegral i) Kilometer -&gt; MeterDist (fromIntegral i * 1000) Mile -&gt; MeterDist (fromIntegral i * 1609.34) Foot -&gt; MeterDist (fromIntegral i * 0.3048) foo :: Measure foo = 40 mi :: Measure main :: IO () main = print foo -- 64373.6
&gt; Won't that slow things down in some situations? I believe that's not a problem since GHC will notice these spots and optimize the identity values away. But could be nice to look at some core-comparisons maybe. &gt; Also what if you are dealing with anything semigroup-like that doesn't have an identity value. Maybe I also haven't dealt often with `Semigroup` yet, and you are right that my approach works best if there is an identity value to speak of. Could you give an example perhaps? And I'll see how I'd write it.
Some complete and compilable example with this library use case would definitely help! For now it's hardly possible to understand from small description how to use this library. And where it can be useful. Personally, I found `markdown-unlit` package quite useful for writing Literate Haskell tutorials on GitHub repositories: * http://hackage.haskell.org/package/markdown-unlit You can see example on how to write such tutorials in `o-clock`'s `README.md`: * https://github.com/serokell/o-clock#oclock I understand, that writing good tutorial (especially literate haskell one) might be a difficult and big job. But this really helps your package and Haskell ecosystem as well.
(: ... Then people start making lists - https://github.com/erkmos/haskell-companies
The author of that tutorial is a coauthor of the upcoming book: https://intermediatehaskell.com/
I have actually considered that multiple times. Too bad it clashes with Ord comparison. But maybe I could do import qualified Prelude as P import Prelude hiding ((&lt;), (&gt;), (&gt;=), (&lt;=)) and use the operators qualified. Since I tend to compose functions much more often anyway than comparing. Though `a P.&gt; b` does look odd. Or maybe I could do something like: (&gt;#) = (P.&gt;) (&lt;#) = (P.&lt;) (&gt;=#) = (P.&gt;=) (&lt;=#) = (P.&lt;=) foo = a &gt;# b -- looks a bit cleaner 
Are you already doing this perhaps?
It can be nice to write s = long-expression &lt;&gt; and-another &lt;&gt; and-another
The `MonadLock` interface looked something like `acquire :: ByteString -&gt; NominalDiffTime -&gt; m (Maybe Lock)` and `release :: Lock -&gt; m ()`. So the `IORef` implementation was just a `ReaderT (IORef (Map ByteString Lock)) IO` and `redis` was `Redis`. A small interface is easy to mock.
`(&gt;&gt;)` → `(*&gt;)` `(&gt;)` → `(&gt;&gt;) `(&gt;&gt;&gt;)` → `(&gt;)`
I reported you to my mom.
Oh, what a confusing torrent of arrows, but I think I got it!
&gt; It's crucial to be able to deploy fast Really? I can understand the need to do a bugfix deploy very quickly, but those rarely include adding an additional dependency, and you should be able to do a rollback immediately if that does become necessary. For a typical `stack` or `cabal new-build` workflow, adding a dependency doesn't usually require much in the way of build time -- you have to build it once, but it's reused after that. If you're just developing and must use Docker, then you might consider building the entire snapshot, or using a pre-built Docker container. These containers are massive, but you spend 0 time building dependencies. Another option is to use these containers to *build* the executable, and then you copy it into a minimal docker container that only has the system libraries you need. This separates your `buiild` docker image from your `deploy` docker image.
This is the equivalent of the [Tau Manifesto](https://tauday.com/tau-manifesto): undisputably correct, yet doomed to fail.
&gt;The proposal should recommend using a “legacy mode” font in their editor, that displays the unicode character “'U+003A COLON” as ::, making the transition easier. Also, a ligature that makes `::` be displayed as `:`.
&gt; I believe that's not a problem since GHC will notice these spots and optimize the identity values away at compile time. But could be nice to look at some core-comparisons maybe. I'd be extremely surprised if this is true in the general case, in fact I'm just going to go ahead and assert that it definitely isn't. Only for a very restricted subset of all possible monoids. &gt; Maybe I also haven't dealt often with Semigroup yet, and you are right that my approach works best if there is an identity value to speak of. Could you give an example perhaps? And I'll see how I'd write it. By `semigroup-like`, I meant any binary operator without an identity value, so not just `Semigroup`. For example `NonEmpty` concatenation, `max`/`min`, `meet`/`join`. So I guess how would you do the following: maxOfSomeNumbers x y z = foo x \/ bar y \/ baz z Where `(\/) = max`
I personally don't love wasting vertical space, so I wouldn't do it myself.
What about: sufficientlyLongName = firstThing &lt;&gt; secondThing
 maxOfSomeNumbers x y z = maximum [foo x, bar y, baz z] but jokes aside; just like with the 'colonectomy' situation above, if all other hope is lost, I guess I can still fall back on maxOfSomeNumbers x y z = foo x \/ bar y \/ baz z 
I indeed cannot cause a segfault, but why dont haskell disallow tying the knot by searching for lhs of instance declaration without the rhs available? In that case if the dictionary is find at compile time it is also find at runtime.
https://en.m.wikibooks.org/wiki/Haskell/Lenses_and_functional_references
[Strict Text](http://hackage.haskell.org/package/text-1.2.3.0/docs/src/Data.Text.Internal.html#Text) is an array of Word16 elements storing text in UTF16. This means if you have a strict `Text` value then the memory requirement is linear with the size of the text. [Lazy Text](http://hackage.haskell.org/package/text-1.2.3.0/docs/src/Data.Text.Internal.Lazy.html#Text) is (morally) a linked list of arrays of bytes. This lazy list of chunks of text allows you to operate on large streams of text without holding the entire value in memory at once. For example, you can open an infinite stream like `/dev/zero` and mutate/write it out. All this said, I don't know why dhall prefers one over the other.
Like so : fib :: Integer -&gt; Integer fib 0 = 0 fib 1 = 1 fib x = fib (x-1) + fib (x-2) I found what I was looking for, you can see in edit. 
What is the best way to deal with cabal version conflict? For example, I use both `servant` and `jsaddle`. The later requires an older version of `http-types` however the most recent version of servant has a lower bound on the latest version of http-types. 
That's amazing, thanks for sharing!
[removed]
Your data will be safe, sure, but you do have to listen to a Rick Astley song everytime you cause a type error.
* (breaking change) The definitions for `reallyReallyUnsafePerformIO` and `unutterableAccursedUnsafePerformIO` have been swapped.
In the example, where is my MyApi defined?
I've tried exercism. The introductory exercises were pretty basic(At least first five) and then got interesting pretty fast. The platform is an eye opener though. After solving an exercise you're allowed to see the solutions of other participants and discuss if you want. There's no stressing on strictness of the code and once your solution passes a test, you're good to go. I encountered so many hacks and hundreds of ways to answer a single question. I'd recommend it especially if you're studying alternative material (like Haskellbook) and need to keep interested while you're working through the book
This would make a fine Pull Request at least for the Readme, perhaps?
That is why we have `mconcat`. ;) I mean, like literally, that is the only reason I ever want to see it used. =)
`toServant "Foo" routes` creates a type alias `Foo` and sets it equal to the routes. So toServant "MyApi" $ "hello" // get [json] @User becomes type MyApi = "hello" :&gt; Get '[JSON] User or, it will, when I finish out the implementation -- right now it only supports a tiny fraction of Servant's combinators and is not extensible.
It isn't that it "has" a right hand side, the whole situation is reversed. I can, at runtime construct arbitrarily complicated chains of instances, by playing games like how the original reflection paper reified arbitrary natural numbers as typeclass dictionaries. The compiler doesn't get to know how those will be strung together later on. It has no magic 8-ball. Using the same tricks i can readily encode an arbitrary SKI term and set it spinning using instance resolution to perform reduction. No evaluation strategy can work for this, termination is beyond the local insight of the compiler. At any use-site it's trying to resolve a demand for the right hand side, and once it does so it proceeds to "simplify" it by converting a demand for the right hand side into one for the stuff on the left hand side of the `instance` declaration. There are two tools for resolving instance demands. Walking up `class` hierarchies to superclasses, and walking backwards through `instance`s to simpler contexts. `UndecidableInstances` removes the _way_ over-simplistic sanity check that says you are somehow guaranteed to make progress when doing the latter. Shrinking an inductively defined argument definitely makes progress, and was the original condition, but it rules out way too many programs. The fact that we can build so many powerful things with the instance resolution system has allowed us to achieve some pretty impressive feats. Lots of the work on HLists, etc. would have been impossible without it. This is a feature, even if it is a fairly well disguised one! In the spirit of what you are suggesting, `UndecidableSuperclasses` was added fairly recently, which relaxed the `class` walk in a manner similar to what you describe, it iterates at compile time for a bounded number of iterations looking to achieve a fixed point, but it literally has to, because dictionary construction has to be strict lest you be able to use bottoms in it to produce segfaults. There a bounded search for a fixed point was a viable solution.
Codewars is ok.
Thanks for doing this for the community &lt;3 
I must be missing something. Is the mapping from routes to handler definitions accomplished entirely through a naming convention via Template Haskell? If so, then documenting that convention precisely is probably priority #1. Even with adequate documentation, though, it's still very unfortunate for tool support. Couldn't you refer to the handlers by identifier in the routes, instead of by string literals? For example, instead of `get "PanelR"`, it would be very nice if you could write `get getPanelR`. (I haven't tried the implementation, though; I suppose this might conflict with the way you're handling the argument in the TH implementation?)
It works exactly like Yesod's quasiquoter. So the quasiquoter like: /users/ UserIndexR GET POST /users/#UserId UserR GET PUT will correspond to the `rowdy` definition: do "users" // resource "UserIndexR" [get, post] "users" // capture @UserId // resource "UserR" [get, put] and the yesod dispatcher will expect functions `getUserIndexR`, `postUserIndexR`, etc. Adding a documentation note on how the QuasiQuoter syntax translates to the `rowdy` DSL is a good idea, though :)
I appreciate the author including an implementation. I can steal it for CodeWorld, which already locally patches GHC in at least one place. Compatibility is a problem, since I don't want CodeWorld students to worry about pragmas. I intend to be even more evil, then: in a wrapper around GHC: 1. Try to compile with `-XColonectomy`. If this succeeds, stop. 2. Try to compile with `-XNoColonectomy`. If this succeeds, stop, but add a warning telling the user to update to the new convention. 3. If both fail, prefer the failure with fewer colons in error messages??? I'll have to ponder this one a bit.
Thanks -- that makes me more confident that this is a good idea :) The plan for `rowdy-servant` is to just generate a Servant type signature, so the only difference will be actually defining the routes. You'd have the option to define a value-level combinator instead of a type-level combinator, which would be an improvement, but it'd all come down to the classes in the end.
No. `Sum` happens to be an `Applicative`, though. Sometimes people just prefer to use `pure` where it works, rather than remembering the specific constructor for a data type.
&gt; Is every monoid an applicative? `Monoid` uses kind `*` and `Applicative` uses kind `* -&gt; *`. Although you can provide `Monoid` instances with kind `* -&gt; *` by providing a parameter of kind `*` (See `Monoid` instance for `Sum`: `Num a =&gt; Monoid (Sum a)`). To answer your question: No. Although you can use `Const` to wrap any `Monoid` as `Applicative`. &gt; What's is reasoning to use `pure m` instead of `Sum m`. There is no compelling reason in particular other than being able to be polymorphic. You could use `getProduct` instead of `getSum` and you would not have to change `asProfit`.
Monoids and applicatives are quite different since monoids works on types with kind `*` while applicatives works on `* -&gt; *`. `Maybe` has an applicative instance but it cannot itself have a monoid instance without adding a type variable, `Maybe a` can be a monoid. I do not think that is what you are confused about though. Since `Sum` have a applicative instance `pure` can be used instead of `Sum`. They are equivalent since `pure` is implemented as `Sum`. The difference matters when you want to write a function that works on multiple types. Since the `getProfit` function works on any applicative you could get the product by just switching out `getSum` for `getProduct`. If `Sum` was used instead of `pure` you would have to switch out `Sum` for `Product` too.
Ok, will do!
&gt; Sometimes people just prefer to use `pure` where it works, rather than remembering the specific constructor for a data type. That's because they'd rather use [`pointed`](http://hackage.haskell.org/package/pointed-5.0.1/docs/Data-Pointed.html).
In Connor Mcbride, Ross Paterson paper every monoid induces an idiom, albeit a phantom one
And also needs `-XMagicHash` everywhere.
You get monoids which don’t take a type parameter: so those ones aren’t. If you narrow that down to monoids with a type parameter: I’m not sure but I can’t think of a counter example.
You should also ponder about whether every `Monoid` is also [`Pointed`](http://hackage.haskell.org/package/pointed-5.0.1/docs/Data-Pointed.html).
I’d rather leave : for cons and choose some Unicode symbol as an alternative for type signatures 
What real world problems are you solving with the chat bot?
Uhh I mean what is a chatbot supposed to do like it’s supposed to chat and do that type of stuff 
Some chatbots are specific to a domain. For example, hubot by github. Alright. So what I learned from your response is you want to build a general one that may response to your chat.
What is the best production ready option for a simple CRUD server running on AWS for a client?
HackerRank is good, since they have a dedicated Functional Programming Section. They also have a Project Euler section in case you want to try out Project Euler's problems. I would also recommend [Project Euler](https://projecteuler.net/) as a standalone, since sometimes these online judges place too much importance on running times whereas Project Euler imposes no such restriction.
Permission to use this for the readme? I could have named it aeson-diff-th, but since this library does more I stuck on generic. I originally intended to use generics as well, but creating lenses with generic doesn't seem to be trivial. Perhaps something for the feature, if there are requests for it. The default implementation of `JsonPatch` uses `FieldLens`, the default implementation of `FieldLens` just gives an error. That doesn't seem very useful, however you can make default instances for terminal (scalar?) types, like `Pet` in your example. I'll add documentation to make this more clear.
Unfortunately, my workplace burnt out when they put fire to a flipchart. I still don't understand why they did this. 🤔
Well the names could be much longer than `foo`, that was just an example, pretend that the chain of functions is like 40 characters or so. Also `maximum` is partial, so that's not a great solution, in general putting it in a list implies that list could be empty and thus doesn't help you with calling things that don't have an identity. On top of that you are also still in trouble if not all the arguments have the same type (and you are using a binary operator that supports such a thing), as you won't be able to put them in the same list.
Haha fair enough, although that style of function doesn't really help you with semigroups where an `mconcat` like function would be partial, it also doesn't help you with heterogenous binary operators like `.`.
that makes sense. T 
&gt; fooBar = id &gt; . omega &gt; . beta &gt; . alpha As long as we're bikeshedding this hard, for one-character operators its hard to beat: fooBar = id . omega . beta . alpha
You could use Stack I guess which handles that for you. Otherwise you have to manually find a version that is compatible. If it's only incompatible because of a version in a cabal-file maybe the bounds could be relaxed, you could submit an issue or get in contact with the author (or there's the quick-fix of just cloning the repo, relaxing the bounds and then depending on your own repo).
I know that [Reflex](https://github.com/reflex-frp/reflex-dom) can compile to Android. I've never dabbled in that though, but it is possible.
My original goal was more like something that filled the same role as Servant, but which used the fact that it was based on a value-level EDSL to provide all the examples without limiting itself to things that could be easily expressed in types. I can see the merit of just building atop what is there, and it still provides a heck of a proof of concept. It just means that when/if I ever find myself forced into writing a web routing DSL there is still room for me to do something else. ;)
It was Firefox that struggled! It's too bad it doesn't work, but I'm really happy the solution was so easy. Thank you!
How to do this with odd length operators and sconcat? https://hackage.haskell.org/package/base-4.11.0.0/docs/Data-Semigroup.html#v:sconcat Clearly the solution is sufficientlyLongName = sconcat $ pure firstThing &lt;|&gt; pure secondThing but it's bad enough I'd give up on my pretty indentation first. =)
I'm far too late obviously. Anyway, for completeness, here's also the variant using generics-sop: https://gist.github.com/kosmikus/3db332604190637bc93cede5031ea0e3
I use a default mode (not sure how it's called). There were many fixes and improvements merged into it some time ago and it's fine now. It has some issues with .lhs files and blocks of code that contain CPP, but otherwise it does its job.
So i have been assigned a task in my company to automate testing of web and mobile applications. I was wondering if could do that in Haskell through hUnit considering i have no experience of coding in Haskell. Also where can i find more resources of unit testing in Haskell? Thanks in advance!!
haskell-mode isn't too bad. But I always follow up eventually with `brittany`; it's an insanely good formatter.
Thank you, Carter :)
There is no need to use hi2-mode, since all changes in that mode where merged with the main haskell-indentation-mode.
From memory, everything added is under /nix - delete it with a sudo rm -rf /nix and you should be good to start again
I basically just write spaghetti of braces, parens and semi colons and then let hindent tidy it up. [Demonstration gif](https://i.imgur.com/yJ3j76e.gif), a contrived example but this is pretty representative of how I work. Structured-haskell-mode takes care of copy/pasting at the same indentation level, and a few backspaces/spaces fixes mistakes once in a while.
haskell-mode works out of the box
Will there be Linux binaries with DWARF support? [#14779](https://ghc.haskell.org/trac/ghc/ticket/14779) most visibly manifested when GHC 8.4.1 with DWARF support tried to compile Cabal Setup.hs files, so it would be nice to test that again.
There's also some stuff in `/etc/nix`. And I think there may be some files in `reflex-platform` itself, so probably best to do a `git clean -f`.
That's very neat. Does it format *all* the code in a file? I'm wary about reformatting code written by other people.
It just formats the current declaration. Formatting is hard, so I limit it to the smallest unit. And I don't want to bother other people either.
What is the scope of the problem sets in exercism? Just simple data structures, or do they cover intermediate concepts like transformers ?
Still better than the but that deleted the source on error.. :)
That's good to know! hi2-mode used to have little underline characters indicating which indentation points TAB would cycle though. Do you know how I get that behaviour back in haskell-indentation-mode?
Great. I will have to check it out! Thanks. 
Can you give a brief comparison between brittany and hindent?
Filed as https://github.com/haskell/haskell-mode/issues/1584
For our Haskell-course we stubbed a game with quickckeck-tests for player movement. Maybe that gives more insight. https://gist.github.com/Drezil/0b83bab718c12f28dc1cea1de474da52 (Only types &amp; test, no logic)
JFTR, now that it's April 2nd, I no longer support this, as it clearly does not pull it's weight.
“thanks for sharing” – yes, precisely that!
[@UserId's latest tweet](https://i.imgur.com/jDtJRr2.jpg) [@UserId on Twitter](https://twitter.com/UserId) - ^I ^am ^a ^bot ^| ^[feedback](https://www.reddit.com/message/compose/?to=twinkiac)
It seems to work out pretty well for us. I would love to hear your thoughts! :-)
&gt; And I cannot use vector, linear, lens, etc. which makes the code there very different from what I would write elsewhere.. This is why I want to want to create [this when I find the time](https://www.reddit.com/r/haskell/comments/847qwj/does_this_exist_already_condense_a_project_into_a/).
1 to 2 times a year updating to a newer stackage
What about ∈?
Nice. Obviously I can't say for sure since this is only part 1, but this looks a lot like what I tend to like. MVC is a great architecture when you remove all the excessively mutable object oriented crap. My one minor gripe would be that I don't usually like the `Has*` patterns. I've yet to find a scenario where being overly polymorphic on record access actually bought me anything. IMO it just obfuscates the type signature and serves as another vector for specialization failure.
The Has* pattern actually enables the architecture to work in the first place. I will try to get part 2 out as soon as possible, it should make it more clear. Many thanks for reading and the feedback!
bad bot, ignore pre-blocks
Oh wait a second. Is this going to be the mono-model architecture that Elm uses? I quite dislike that. I *strongly* prefer local states. Having one big state indexed by types means that widgets are inherently non-reusable, since reuse may cause states to collide. It's a major anti-pattern IMO. Requiring the top level of the application to know about all state is a one way ticket to spaghetti logic, since there will be nothing to prevent you from peeking at other things' state when you really shouldn't be. It's just the global variable problem all over again.
Looking forward to learning this idea in part 2 :)
Just coming back here after some time. The new layout is MUCH MUCH better than before. I can navigate in half the time now by having both dependencies and the module list easily available with less scolling. Great work!
As soon as I notice a new lts on stackage. I try to upgrade everything as often as possible, I've been in too many situations where upgrades are a nightmare because they've been left for so long.
People probably want one of those fancy functions like [`ala`](https://hackage.haskell.org/package/lens-4.16.1/docs/Control-Lens-Wrapped.html#v:ala) but don't want to bother or don't know about them.
Small upgrades are easy. Large ones are hard. I try to keep things up-to-date as much as possible.
I use intero. I don't have any complaints, except for its preference of aligning everything instead of just indenting. Not a big one, so I'm not even looking for a replacement.
Last time I checked intero only worked for stack projects. I don't know if that's changed.
bad bot
Thank you, isovector, for voting on WhoaItsAFactorial. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://goodbot-badbot.herokuapp.com/). *** ^^Even ^^if ^^I ^^don't ^^reply ^^to ^^your ^^comment, ^^I'm ^^still ^^listening ^^for ^^votes. ^^Check ^^the ^^webpage ^^to ^^see ^^if ^^your ^^vote ^^registered!
I don't think "Is of type" has the same meaning as "Belongs to set"
I don't use it for building. So, I don't know.
What version of nix has been installed on your system?
You only need `MagicHash` to put `#` at the end of an alphabetic name. It's a normal operator character so `&gt;#` would be fine.
What is a "route attribute"? I don't quite get what the purpose of the `(!)` operator is.
How do you integrate `brittany` with emacs?
It's a [Yesod feature](https://www.yesodweb.com/book/route-attributes). I'd never heard of it before digging around the source code.
I essentially took the hindent emacs code and tweaked it to use brittany. It's not very elegant and it's kinda buggy :P HIE comes with brittany integrated; so whenever I get around to setting that up with emacs, I'll get better brittany integration for free. Vscode already works great for this
This was a good idea 25 years ago, but it's too late now. In my humble opinion, the only viable option is to make `:` and `::` equally valid in the type/kind signature. Spending just a single minute changing `::` to `:` because of a compiler error outweighs whatever preference I have for `:` over `::`.
The problem is probably in the `shell` function. What you probably want is the [`createProcess`](https://hackage.haskell.org/package/process-1.6.3.0/docs/System-Process.html#v:createProcess) for this.
RIP humanity
Ah, thanks for clarifying.
what a calm idea
I'm pretty sure it still requires stack, but Dante is an emacs mode that's similar and configurable: https://github.com/jyp/dante
You can try the haskeline package: https://hackage.haskell.org/package/haskeline-0.7.4.2/docs/System-Console-Haskeline.html#v:getPassword 
Intero the Haskell program does not require Stack. Intero the Emacs plugin does require Stack.
From my C++ experience i learned from Haskell: - template pattern matching - types and meta-programming in general - C++ functors (in Haskell called functions) and there usefulness - what Design Patterns are about (or should be) Additionally, Haskell shows how to apply typed lambda calculus and category theory in computer programs and who knows what more. It gives me new perspective on how to design software on different way. 
That's good to know. I will try Dante.
Depends on the project. If it's just local and for you, or binary then you can pretty much leave it. If it's a library others might use, just throw some CI at it that periodically builds it against the newest stack snapshot (Travis now has periodic builds) and if it's a **genuinely important** library it should be on stackage anyways and then it will automatically be built against updating libraries and they'll open an issue if that fails. 
Not enough Free
You are welcome to contribute. ;)
&gt; Of/On/etc endings I think that: - No ending: the operation uses a traversal that "standard" in some sense, possibly given by some typeclass. - _Of: a trasformation that uses a traversal given by you, possibly more selective that the "standard" one. - _On: You have some enclosing type, that contains members of the actual data type that you want to traverse or alter in some standard way. You supply the traversal that locates those members in the enclosing type. - _OnOf. You supply both the traversal that locates the inner members in the enclosing type, and the traversal that you want to use (instead of the "standard" one) for each inner member.
1. Thinking about types. When you ask yourself what type your function would have in Haskell, you can document it in the comments, especially for "cases" (a.k.a. sum types), and might refactor it to match that fake type, which can simplify the definition. 2. In particular, knowing that "pure versus impure" exists. If you think about whether some program would be in IO or not in Haskell, you might notice something effectful that should be isolated. For example, I've been writing a lot of Nix recently, which is a dynamically typed language, and the (1) helps a lot. (But not the (2), interestingly, because Nix is already immutable, and most effects are "deterministic" (like you can fetch a tarball during evaluation, but you must provide its hash beforehand).)
All the answers here are pretty good and on point. What I learned from haskell was _simplification_. Programs have an innate structure, and if we have a lot of escape hatches possible, we build things in an ad-hoc way. It works, but misses the larger picture. Using haskell was the first time I looked at my problem itself at a data-structure manipulation problem. To take a concrete example, I had written high performance, streaming, concurrent code earlier (in java) and it's not a bad experience because there is already so much wisdom about how to structure it and go about it. But learning about the streaming libraries in haskell was the first time I was able to see the program itself as a `fold` over the Natural numbers and more generally connect how any program is a transformation of the natural structures of the input data (in this case, the natural number). Once you internalize this, you can spot it in any other language. After all, the problems are similar everywhere. And this experience helps shape the solution to be 'obviously correct' because it applies a standard operation over input (like map, fold, etc) whose behavior is well known, rather than being ad-hoc complicated to only have 'no obvios deficiencies'.
That's just beautiful
Would you agree that a mono-model architecture is simple and is well-suited for smaller or narrowly focused UIs? I agree with your objections, just wondering if there is a tipping point for you?
I use default one as well, it produces good results. The only problem I have is bison code which default formatter does absurd stuff even in bison-mode.
I'll tell you when it's installed. This time it's been running non stop. here's a part of what it's spewing out in terminal https://pastebin.com/9DjCHgvZ
At that point, Nix is already installed. try-reflex is now trying to build a bunch of stuff. It's *definitely* not supposed to be building that much, which means the binary cache did not get properly configured. At this point you should already be able to do `nix-env --version`. There should also be a file at `/etc/nix/nix.conf` whose contents would help me see what went wrong.
At that point, Nix is already installed. try-reflex is now trying to build a bunch of stuff. It's *definitely* not supposed to be building that much, which means the binary cache did not get properly configured. At this point you should already be able to do `nix-env --version`. There should also be a file at `/etc/nix/nix.conf` whose contents would help me see what went wrong.
It's just hard to come up with enough laws for `point` to make it easy to reason about.
It's definitely not possible to get that far without Nix at least being installed. Maybe it's not being added to your PATH correctly? IIRC, Nix installation modifies your... `~/.profile`, I think? One of those startup bash scripts... Anyway this does mean that you probably have to open a new terminal to see Nix on your PATH. If it's still not there after that, then the script it's added to isn't being sourced by god shell
Ok I know that is obviously a joke. But when it comes to simple functions and values (i.e not data types / instances / classes), there really isn't a reason why you ever need to make a true breaking change. Now of course naming them foo1 foo2 etc is silly, but having a package management system that automatically adds in the old function that a different library needs while still having you use the new API in your library would be pretty dope. 
nix-env: command not found and there is no /etc/nix/ folder here. 
edit: /s
Just trolling, looks good haha.
&gt; I checked the nix folder properties and it says this -&gt; 553,574 items, totalling 11.1 GB Is that normal? Yes. Nix pins *everything*, down to the libc and GCC. This means that using any given checkout nixpkgs likely means downloading a small operating system's worth of tools.
I've opened up a new terminal. Same thing. It's night time here and I won't be able to respond until tomorrow evening. Thank you for your efforts and I hope we'll continue tomorrow.
A few times a year. I usually only update if I really need a new feature (in a package or in GHC) and I give up if it doesn't work. For example, a quick look at the git log of my current big project Mar 2016 - Initial - lts-5.13 May 2017 -: upgrade to lts-8.13 July 2017 : upgrade to lts-8.24 Today, I tried to update to lts-9.21, but given up (stashed it) for the moment because I have more urgent stuff to do . There is no new extension I really need at the moment so I'm not in a rush to upgrade GHC.
Whoa! How big is it supposed to be? I'll run ./try-reflex once more and leave it over night. Hope the folder doesn't get bigger than 40GB because I don't have any more space.
&gt; I don't have any complaint That's interesting. I use intero (and SPACEMACS) and I have LOTS of complains but maybe it comes from SPACEMACS or my configuration. For example, when I insert a new import, emacs indent it, so I have to manually to deindent it. Do you have the same behavior ? 
Last I checked it was about 20G total, but I've been working on reducing it. For instance it provides you with the mobile toolchains, which I don't think is a good idea; so I've got a PR up which takes them out of try-reflex and saves a ton of space. I think it was like 8G after that
Join us on #reflex-frp on freenode tomorrow. Will probably be a lot easier to help on a more rapid communication channel like IRC.
That's a good question, as I'm really struggling with this. I switched from vim to spacemacs+intero and the indentation is driving me mad. In vim, I just get the indentation similar to the previous line and it works fine. With emacs, I don't know why but I can't get this behavior, I just get random indents which I have to fix manually.
Your point being?
I'm a bit suprised that you need to deploy every 20mn ;-) However, for development you can use `ghcid` and set it up to run your service instead of the test. ghcid recompiles and run you app in seconds. Ok, it's only interpreted, but it can fast enough anyway. That's what I do now on development and unless I do something requiring heavy computation the server is snappy enough for a single user.
It's unfortunate that the data type declaration is generated by persistent. Maybe it's possible to post-process the output of `mkPersist`, I don't know. If it were possible, we could refactor `User` and `UpdateUserReq` as a single higher-kinded type, or "functor-functor". There was a blog post on this pattern posted here recently: - http://reasonablypolymorphic.com//blog/higher-kinded-data - https://www.reddit.com/r/haskell/comments/884pe0/higherkinded_data_reasonably_polymorphic/ The hypothetical code for `User` would look like this: data UserF f = User { firstName :: f Text , lastName :: f Text , grade :: f Text -- ... } -- the type family trick that the blogpost talks about might be useful here deriving Generic type User = UserF Identity type UserUpdate = UserF Maybe -- just missing the idUser field To create `Update` values, we could first wrap `EntityField` in yet another record. type UserEntity = UserF (EntityField User) userEntity = UserF { firstName = UserFirstName , lastName = UserLastName , ... } This allows us to refactor the repetitiveness of applying `(=.)` and `(&lt;$&gt;)` using generics, it's basically a zip and a fold, so the code might look like this: updateToUpdate :: UserUpdate -&gt; [Update User] updateToUpdate = catMaybes . gtoList . gzip (\fieldEntity fieldUpd -&gt; (fieldEntity =.) &lt;$&gt; fieldUpd) userEntity 
When you have a significant amount of projects to maintain you'll value the wisdom of "if it ain't broke, don't fix it" as each major update update poses the risk of introducing bugs. Like others have commented I also only update when there's a feature or bugfix I need. 
I upgraded pretty often, usually about 1 version behind the latest lts. Large upgrades are hard and the Haskell projects I depend on are usually good at incremental change. Making those small changes every once and a while is far more manageable than big change sets infrequently.
Best-ish way to do random access on files without filling my code with hSeek? I'm parsing Android's DEX files and they have all sorts of tables with offsets to strings and stuff. For the header I'm just using `cereal`, but the Get monad doesn't look appropriate for jumping around... right? Ofc, I'm a newbie :)
I periodically go behind the two projects my team is working on and push things forward. Finally got us on GHC 8.2.2 last month - the required changes were minor, and the new error messages more helpful. I feel it's worth it to keep things moving. A few hours of maintenance here and there beats larger technical debt challenges down the road.
This is great, thank you! I want to use reflex during the next semester, so the timing is great. May I ask how you do built it as an android compilate? Do you just follow the instruction on the reflex repository or did you have to tweak it?
I use Turtle which creates a pty, but ive been thinking about a remote/ssh friendly version of Turtle that works kind of like sshpass.
Turtle looks like a really nice library. But when you use it with SSH do you just disable password authentication or use SSH keys? The below still prompts for a password. Are you reading and writing to "/dev/tty" with the library? stdout (inshell "ssh root@127.0.0.2 -tt" empty)
This and your post history is cringe as fuck dude
vim
Anyone upgraded yet to yesod 1.6? 
Are you using some variant of `Eff`?
Not sure whether this is a delayed April 1st celebration, but if it is not then definitely Haskell is going places.
Well, you don't implement throwM, as I see it. For maintaining the context state only a reader is required, yes. 
I would just need for `throwError` to rely on a `MonadThrow` constraint. For the time being, using `error` was fine for my use case.
Clojure has the `lein ancient` command to help with keeping on top of this. Quite liked using it. Not sure if there's anything similar for Haskell. https://github.com/xsc/lein-ancient
&gt; We love types at Co-Star, and we try to use them as much as possible to catch bugs and make sure our code is correct. It’d be interesting to see what kinds of invariants astrologers are looking to prove with Haskell’s type system.
If you decide to go the Frege route, then this may be useful: https://www.youtube.com/watch?v=_Hwcjreq_XU
Well, if these two are the most serious ergonomics issues, we're in a pretty good shape I'd say
As an introduction for non-mathematicians, this is very good: Seven Sketches in Compositionality: An Invitation to Applied Category Theory - Brendan Fong, David I Spivak (https://arxiv.org/abs/1803.05316)
for an introduction/beginner level abstract algebra book? :O
I really liked "Algebra" from Michael Artin as a student (it's useful for both linear algebra and the first courses on (abstract) algebra) other texts I quite like are - Abstract Algebra: An Introduction by Hungerford - Contemporary Abstract Algebra by Gallian the first one takes the number theory / ring theory route while the second starts with groups if you want a bit more of a challenge and get into category theory from the start (similar to the text ocramz recommended bellow) you could have a look at Algebra: Chapter 0 by Allufi - but I think that's to much for a beginner although it would fit you wanting the learn the abstractions somewhat more (CT is "abstract nonsense")
I applied last year. 
Apply again. 🤷🏽‍♂️
I just use rectangular editing commands and manual labor.
&gt; updateFirstName ?; I think that should be `?:`. Nice idea, thanks.
‘Twas a (poor) joke... 
Too local can be quite of a pain too and can make it pretty hard to evolve the architecture: Wait, I need this data - where is it - oh yeah in this component three levels down the tree ..... darn. I believe a proper MVC architecture, where you easily have the data available when needed, in a principled way is the way to go.
What a *darn* shame.. *** ^^Darn ^^Counter: ^^498706 ^^| ^^DM ^^me ^^with: ^^'*blacklist-me*' ^^to ^^be ^^*ignored*
Glad it is useful! Well I had a couple of pull requests that are merged already. So there should be more stuff that works out of the box, but if your application is non trivial and has to interface with Android in some way, you will have to get your hands dirty a bit. Gonimo Android itself can be built with `nix-build -A android.gonimo-front-android` provided you have followed the build instructions in the readme.
I'd recommend Pinter's "A book of abstract algebra"
One would hope that Haskellers would reject this kind of [pseudo-scientific nonsense](http://www.badastronomy.com/bad/misc/astrology.html). Relevant points: * There is no force, known or unknown, that could possibly affect us here on Earth the way astrologers claim. Known forces weaken too fast, letting one source utterly dominate (the Moon for gravity, the Sun for electromagnetism). An unknown force would allow asteroids and extrasolar planets to totally overwhelm the nearby planets. * Astrologers tend to rely on our ability to remember hits and forget misses. Even an accurate prediction may be simple chance. * Study after study has shown that claims and predictions made by astrologers have no merit. They are indistinguishable from chance, which means astrologers cannot claim to have some ability to predict your life's path. * There is harm, real harm, in astrology. It weakens further people's ability to rationally look at the world, an ability we need now more than ever. 
Fixed, thanks!
Do you believe that the movements and relative positions of celestial objects can influence human affairs and terrestrial events? If so, why, and how did this come to be?
Still no Poland :(
Jokes aside - this looks very clean and minimalistic, but are you actually trying to achieve a specific goal with a specific philosophy, or was it just some kind of experiment? I'm asking because I'm currently studying neural networks and might be interested to contribute in some way... if I manage to find time
This answer assumes that by "abstract algebra" you mean the mathematical subject of groups, rings, fields, etc., rather than something more immediately applicable to programming (even Haskell programming). Pinter is the gentlest good intro that I know of, and it's cheap. Artin is good if you are willing to plough through a pretty rigorous undergraduate textbook on your own. There is an outstanding series of lecture videos by Benedict Gross that mostly follow the book (currently available [here](https://www.youtube.com/playlist?list=PLA7B08F1D8252DE29).
Yeah thank you for the feedback. I will check for using repa, looks pretty neat. :)
Thanks! :)
I see your point now.
I always stay on the newest version of GHC that is at least at an `X.Y.2` release. I feel like the first release of a new major version always tends to have something broken enough that I'm scared to try relying on them in production.
http://www.clash-lang.org/
What are the main differences between Clash and Kansas Lava?
Me too! I haven't finished it but it's cheap, it's fun and conversational, and it's great for self-learning. 
Mostly replying to your last bullet point here. I wish people like you would realize that you yourself are not being rational about rationality. If you think the only way your brain would be irrational is in very explicit ways that you yourself realize and control, like following astrology, you need to think about your own decisions and what influence them. There are so many ways your brain is being irrational behind your back that it's futile to attempt to look at the world in a "rational and objective" way as you would put it. There are too many biases present in any human being to attempt something like that.
no I think it might be a bit much for a beginner abstract algebra books are often graduate level (not those I listed though) and that is for a reason - the prerequisites might be low but the rigor and abstractions can be hard to grok if you are not used to this literature btw: Galois theory is not to unusual to include in a abstract algebra book - it's a fascinating theory that solves some of the fundamental questions of algebra and ties much of learned topics together
I don't think anyone had yet the time to really work through it (it's rather recent) I guess it would take me 1-2 years of my weekends to work through it all at a level to say I understood &gt; 50%
Must use a Tardis Monad to allow future state to be sent backwards in time. Presumably you could run the app on itself for an introspective prognosis.
My school used Fraleigh's "A First Course in Abstract Algebra". It was a good book. I think that "Algebra: Chapter 0" is equally accessible but goes into more depth and connects the dots better than Freleigh though. If you don't have experience with writing proofs I think it would be most beneficial to first familiarize yourself with proof techniques and structure. "How to Prove It" by Velleman does a good job with that. Also I would like to caution you that abstract algebra may not be what you expect it to be. It is not so much a tour of abstractions as it is a very detailed study of a few abstractions. I think it is very valuable in training one to think in terms of structural properties, but I doubt you will find a lot of direct applications of groups, rings, modules, or fields in Haskell.
Checkout the [Reduceron](https://www.cs.york.ac.uk/fp/reduceron/) some cool work out of York by Matt Naylor, Colin Runciman, and Jason Reich. Here's a [paper](https://www.cs.york.ac.uk/fp/reduceron/reduceron.pdf) that describes it.
There's also Bluespec, which basically provides a modified Haskell compiler that spews out Verilog. It is a bit of a different model than Clash, though.
yeah sorry - english is not my first language and I think it shows
Don't worry, the fault was all mine. Your original message is clear looking back at it, I don't know why I read it the other way originally.
Astrology is fun! Of course it’s fake..but it’s a really interesting vehicle for introspection, even knowing that.
What's the current best openGL library?
I had to set an indenting option to fix stuff like that. It was a long time ago, I didn't even remember it. I think it's this option: `(add-hook 'haskell-mode-hook 'turn-on-haskell-indentation)`.
For what it's worth I *don't* like Gallian at all. The proofs are often excessively convoluted. I don't have any text I'd really swear by though.
Honestly, online type checking and documentation do not work at all. The only things that work are indenting and syntax highlighting. I just checked, and it depends on haskell-mode. So I may be using only that one without noticing.
I like the creativity but most of the appeal for me in terms of : is that it's the mathematical symbol and what every other type centric language uses. Unfortunately using the in symbol would be just as weird (if not more so) than ::. At least :: had precedence in Miranda (and a few other languages iirc?) :)
Definitely! Encoding astrology as code seems like a fascinating, interdisciplinary task. I love mapping topics of all kinds to Haskell.
yeah I think the book has to fit you somewhat I did not mind the proofs but the book has such a nice mixture of historical/persona backgrounds, exercises, etc. and I know it's stupid but I really love the layout and print of the book - I really enjoyed reading it
Probably. I already get that with haskell-mode :)
One thing I did not mention in the posts is how easy Haskell made some of this. E.g. Having immutability makes speculatively running different possible outcomes trivial. Also I suspect the web GUI may not be for everyone but building a different GUI client should not be hard with the existing backend. Perhaps I'll do that at some point...
Another major difference is that Kansas Lava doesn't build with GHC &gt; 7.10.3 :(
Fyi, there's more recent stuff, not quite as haskell specific, from edwards' research group: http://www.cs.columbia.edu/~sedwards/publications.html
I have no clue, but the jump in version number is big which means there might be breaking changes. So I'm reluctant to do it at least for now.
Awodey, too, is aimed at "everyone else", though it's so "fast and loose" that you need to be a more or less competent mathematician to appreciate it anyway.
Hi! The Haskell wiki has a list of links you may be interested: https://wiki.haskell.org/Research_papers/Domain_specific_languages In particular, IMO this paper gives a good first introduction: http://cs448h.stanford.edu/DSEL-Little.pdf 
For what is worth, I have a largely unorganized bunch of links about EDSLs [here](https://gist.github.com/danidiaz/36f5647c0968361eedd677ad3870715f#file-dsl-reading-list-md). And [this list](https://gist.github.com/danidiaz/36f5647c0968361eedd677ad3870715f#file-binders-reading-list-md) about representing binders.
What have you tried? Where are you stuck? What aren't you understanding?
Haskell and astrology are two of my favorite things in the whole world! This is too good to be true. Pisces sun, scorpio moon, sag rising
Very cool! It looks like you know what you're doing and put a lot of effort into this. Saving the link for later..
Top tips: - Set up CI process (https://travis-ci.org, https://circleci.com/) as soon as possible to build your code and Haddocks, and run tests and benchmarks. - Automate upper bounds management by putting `pvp-bounds: upper` in your `stack.yaml`. Bump the resolver in `stack.yaml` every once in a while. I've seen projects keep around `stack-previous.yaml` for building with a previous GHC version (you can go more than 1 release backwards by running CI tests against more `stack-X.yaml` configurations). - Add a hackage-deps badge from https://shields.io/ in your README so that you could know if you're lagging behind the ecosystem with a quick glance; it's powered by http://packdeps.haskellers.com/
Last night I ran ./try-reflex in a fresh docker container based on Linux mint. It took about an hour and a half and when it finished I was able to build and run the "hello world" example that ./try-reflex displays. As far as I could tell there are 5 new nix related files/directories/links . I searched for .nix* and nix* these using the gnu find command and deleting false positives. Searching like this, it's possible I missed something. There didn't seem to be any change in the reflex-platform directory itself (according to "git status"). here's where the new files/directories/links are ( /workarea is the home directory ): [nix-shell:/tmp]$ cat nixes /etc/nix /nix /workarea/.nix-defexpr /workarea/.nix-channels /workarea/.nix-profile Here's what they are: [nix-shell:/tmp]$ ls -lad `!!` ls -lad `cat nixes` drwxr-xr-x 2 root root 4096 Apr 3 03:56 /etc/nix drwxr-xr-x 4 dave root 4096 Apr 3 03:48 /nix -rw-rw-r-- 1 dave dave 52 Apr 3 03:48 /workarea/.nix-channels drwxrwxr-x 2 dave dave 4096 Apr 3 03:48 /workarea/.nix-defexpr lrwxrwxrwx 1 dave dave 29 Apr 3 03:48 /workarea/.nix-profile -&gt; /nix/var/nix/profiles/default And here's how big they are: [nix-shell:/tmp]$ du -sk `cat nixes` 8 /etc/nix 18331628 /nix 4 /workarea/.nix-defexpr 4 /workarea/.nix-channels 0 /workarea/.nix-profile As you can see, the nix install took about 18.3 GB and almost all of that was in "/nix" . This matched what I saw with before and after "df -k" commands. 
&gt;Great as it is to see Haskell being used commercially, one would hope that intelligent people would reject this kind of pseudo-scientific nonsense. I personally did reject it in a sort of teasing way, but being serious for a second, yes, I absolutely found it strange that this would be in the Haskell subreddit. &gt;&gt;We love types at Co-Star, and we try to use them as much as possible to catch bugs and make sure our code is correct. &gt; &gt;It’d be interesting to see what kinds of invariants astrologers are looking to prove with Haskell’s type system. In other words, does correctness (of the business logic) _really_ matter for this domain?
How can I profile a cabal build? Not build with profiling enabled, but find out which modules takes the longest to build.
As /u/terrorjack mentions, Clash is a compiler for a subset of Haskell; concretely this means that you can translate this "normal" lensy state-monadic code to a (combinational) circuit: https://github.com/clash-lang/clash-compiler/blob/4bfeb5a63e8c0dddc34d2d973c2200d01f71acee/examples/i2c/I2C/BitMaster.hs#L72-L119
Thanks, I was able to install it! However, I have another issue now. I need to install reactive-banana-wx that has wxcore as one of its dependencies. How do I do that?
This is a "throw the baby with the bath water" argument. &gt; it's futile to attempt to look at the world in a "rational and objective" Science, a human construct, looks at the world in a "rational and objective" way. I think it's futile not to look at the world in a rational and objective way. 
To expand on this -- Clash is extremely close to the "bog standard" semantics of Verilog, or any piece of structural RTL. It's quite possible to just literally translate Verilog into Clash with little effort, in fact. So if you know structural Verilog, Clash is very close to that, just with a much better language. :) BlueSpec (BSV) is much higher level; you aren't really thinking at the level of structural RTL, so much as you're writing a high level description of a design, and the compiler "schedules" the design appropriately to match the RTL semantics. So a single BSV program really is more like a *specification* of a design with many possible concrete realizations, and the compiler picks them for you. (As an aside, there is also the minor detail that Clash is open source and BSV is not... BlueSpec seems to be pivoting to RISC-V IP and BSV seems to be a smaller part of their portfolio now, which is a bit of a shame. It's a good HDL.)
It was a wild day today and I'm exhausted. I'll join you there tomorrow.
ssh will run SSH_ASKPASS to do the password prompting for it, so one way is to point that at your program so that your program runs ssh, which runs your program. An example of haskell code doing that is in git-annex in the file Assistant/WebApp/Configurators/Ssh.hs (There are various gotchas like DISPLAY needing to be set and ssh needs to be run without a controlling terminal.)
It looks like [reactive-banana-wx is not in any LTS snapshot](https://www.stackage.org/package/reactive-banana-wx). So you have to add a `reactive-banana-wx-1.1.1.0` entry to your `stack.yaml`'s `extra-deps` section. Since it is not part of the LTS, you again don't have a guarantee that a build plan can be found.
It seems to me that the biggest breaking change is that `HandlerT` is gone, replaced by `HandlerFor` which is not a transformer. That's going to be a painful one for us. We have someone studying how to reduce the pain.
As a Yesod shop, we find it worthwhile to keep up. We tag a version each month, and at that time we update to the latest LTS. Usually this is pretty seamless. But when a compiler change or breaking Yesod change is afoot, we need to be aware of it in advance and get ready for it.
I would definitely be interested in this sort of thing. If Clojurists Together and Ruby Together have figured out a model that works, let's steal it!
Intuitively I feel like it's unlikely, but OTOH something different from what we use today is also likely more efficient. For example, for hardware we'd like to take into account the frequency an expression is evaluated. So I'd imagine that seldom executed code could be executed in any possible manner, and it doesn't really matter for energy use or speed. For the "inner loops", I imagine that the ability to freely copy data and avoid cache-coherence issues should be a great advantage. FPGAs should make it "easy" to precisely express data dependence, but it also seems way to low-level. If you look at innovative architectures like graphcore, they do stuff like serializing compute and communication across the chip, and bringing SRAM onto the chip. Also being able to trade re-computing values against memory traffic is part of what they do. Imagine how many *thousand* operations a chip can do while waiting for a L3 cache miss! This fits the functional paradigm, except that the processing graphs that graphcore depend on (machine learning) are mostly static - similar to how GPUs work. .. just some random thoughts.
This sounds like it could combine really well with the idea of putting reward bounties on GitHub issues or specific code improvements. I like it!
It's been two months, but I've just encountered another error, namely the STATUS_INVALID_IMAGE_FORMAT error. I was trying to build the HIE executable following the official instructions as others, but I was constantly running into an error similar to that described [here](https://github.com/alanz/haskell-lsp/issues/41). I created the three symlinks, pointed Stack to the ICU DLLs with the `--extra-lib-dirs` and `--extra-include-dirs` options and the compilation finished successfully, but the VS Code plugin still doesn't work. VS Code itself doesn't betray any sign of anything wrong going on (no crashing and no messages), but all I have is few new entries in the Settings menu and few Haskell-related commands in the Command Palette, none of which works. Trying to ensure that the HIE binary was really installed successfully I typed in "hie" in my console and this is when I got a message box saying "The application was unable to start correctly” and an error code of 0xC000007B (STATUS_INVALID_IMAGE_FORMAT). I've been searching the web for the solution for a few days now but to almost no avail. According to [this](https://blogs.msdn.microsoft.com/dsvc/2017/09/20/diagnosing-status_invalid_image_format-c000007b-errors/) blog post, it has something to do with the target architecture, but I have virtually no idea what might be the culprit. All I've tried is placing the ICU DLLs alongside my faulty HIE executable. Has anyone ever seen this error?
I’ve used servant quite a bit lately and my impression was that the type level programming is fairly straightforward. It actually feels like nirvana and I’d love for a very lightweight framework that’s as quick as nginx to be designed around it for static assets. That would be spot-on. Maybe even something like webpack that reads your source files to figure out what static assets you need and bundles/optimises them automagically.
You can get pretty far using ADTs. I would start simple and extend your DSL as need be. There are a bunch of great examples here: http://dev.stephendiehl.com/hask/#gadts-1 http://dev.stephendiehl.com/hask/#free-monads http://dev.stephendiehl.com/hask/#final-interpreters http://dev.stephendiehl.com/hask/#typelevel-strings If you have time to descend the rabbit hole, this talk is awesome: Anthony Cowley - Framing the Discussion with EDSLs (https://m.youtube.com/watch?v=_KioQRICpmo) 
The New York Haskell Users Group (of which I am one of several co-organizers) has a not for profit corporation that could be used for something like this. We are already handling money for things like the Compose Conference, BayHac, and people doing paid work related to [CodeWorld](https://code.world/). We could certainly leverage the same infrastructure for something like this. In our experience the main difficulties lie in things like governance, finding qualified people to do the work, and oversight. It's easy to underestimate the amount of work involved in getting everything set up in a way that will be effective.
Definitely the biggest challenge in running Clojurists Together is dealing with all of the minutia that comes with handling money, especially if you are wanting to accept it as a non-profit. We are fortunate to be a member project of the [SFC](https://sfconservancy.org/) who handle the lions share of the work for us, but there is still a bit of work handling payments.
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://sfconservancy.org/) - Previous text "SFC" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
&gt; Uncritical thinking is tearing this world to pieces, and while astrology may not be at the heart of that, it has its role. I'd call this nonsense. If I had to name in a word one thing that's (almost literally) tearing the world apart I would say "technology" (i.e. the basic fruits of scientific, rational thought). Somewhere high up there I'd also put "capitalism" (aside: which is more absurd, astrology or whatever it is that Jane Street does?)
It is ripe for entryism from various political factions, who then get to decide how Haskell is developed.
Thanks! I do have a question. Do the maintainers you fund typically have a day job in addition to the funding they receive from your organization? Is it usually a full-time job or a part-time job? The reason I ask is because as an open source contributor, the resource I am missing the most is time, not money. My full-time day job is the reason for both. Receiving money for open source work wouldn't translate to extra time, unless I only worked part-time and had the luxury to choose how much time to allocate to that part-time job. Also, the fact that the Clojurists Together funding is re-evaluated every quarter makes that source of funding seem precarious, so I wouldn't be comfortable relying on it without such a flexible part-time job to fall back on.
OP /u/MitchellSalad has posted in /r/SandersForPresident And you /u/dantiberian have posted in /r/EnoughTrumpSpam I wouldn't be surprised if "*-ists Together" is yet another attempt to infuse politics into everything. We should like the freemasons and other societies keep politics and religion out of our professional communities. They are divisive and exclusionary and will eventually be detrimental to our growth as a species.
&gt; yet another attempt to infuse politics into everything.
At least it's not banking — unlike most of the Haskell jobs I see posted. I would much rather work for a company that promotes the fanciful fictions of astrology than for one that uses evidence based strategies that increase wealth inequality.
!ReMind me 18 hours
RemindMe! 3 days
I will be messaging you on [**2018-04-07 02:37:04 UTC**](http://www.wolframalpha.com/input/?i=2018-04-07 02:37:04 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/haskell/comments/89et9d/building_a_haskell_roguelike_game/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/haskell/comments/89et9d/building_a_haskell_roguelike_game/]%0A%0ARemindMe! 3 days) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
tl:dw; Functional Programming is the next paradigm shift and is viewed in a similar way to the OOP and structured programming shifts before it \(too academic, unnecessary, etc.\), but main problems are not in value but in pedagogy because if haskell is nicely abstracted for math, it should not be something for which math is taught to be able learn, but rather something that can be taught to learn math by intuition \(e.g. [www.bootstrapworld.org](https://www.bootstrapworld.org)\). The ways to teach it properly are as follows: # # Examples first Generalize &amp; abstract only after demonstrating a need \(e.g. to teach recursion—or even higher\-order functions, parametric polymorphism, categorical structures, type classes, etc!—don't start with what it is, but start with showing examples of the types of problems that it solves\) # Teach design patterns FP abstractions are used in various idiomatic ways \(e.g. provide a starting point that shows a skeleton of commonalities across—and thereby isolating the variation/problem in—a computational idiom such as how to implement map\-like recursion\) # Tight feedback loop Examples, stepwise evaluation, playgrounds \(e.g. Haskell for Mac, Swift Playground\) # Use visualization Pure computations lend themselves to visualization \(e.g. Drawing pythagorean trees to visualize binary recursion\)
I am the creator of qmdj.biz — a calculator for very special chinese astrology method. It is a web app. User registration and other light stuff is in ruby on rails. While real math is in haskell. Yes. It is fun. I am sending you an email. Not really looking for a job. But who knows. We might do smth together. Maybe.
I am a haskell beginner. But I would really love to and am very enthusiastic about contributing to haskell land.
Have you considered alternative funding models? For example, https://snowdrift.coop/ (not yet launched) has a crowdfunding mechanism. The gist of it is that the more patrons that pledge to a project, the greater each patron's donation is. The idea is to combat the tragedy of the commons, or the "snowdrift dilemma" (I'm not sure if they're the same thing). I'm much more likely to pitch in $5/month to a project if I know the community will match me with $25 (while knowing that, if the community grows yet larger, my $5/month donation might become $10/month, a good problem to have, because I want the project to succeed!). Obviously, this is a lot more work to set up than simply accepting and routing donations.
This is a very important problem to solve. Because if I am skilled developer who doesn't have a job at the moment, I would like to be paid something for my full-time efforts on an open source project. Because Haskell is being used in a few places in industry, and that too mainly in startups, I am sure this is a scenario for a number of people, either because they dont have interest in the *cool* startup idea or dont want to relocate to US. 
Good idea, but who allocates it how to which projects? If it's decided by voting, then the Haskell foundation or industrial group could do this and have take applications by library maintainer. None of that is ideal. How does Clojurists do this? Also, some of us live in places where we cannot accept donations for development work if we want to avoid costly and stressful discussions with the local IRS equivalent. Thus, any such project has to consider that projects and their maintainers are given the choice to redirect donations to haskell infrastructure or picking an individual who is able to accept donations. So the easiest solution is if we could redirect the money to get more servers, different servers (POWER9, Aarch64, RISC-V, very high core count box for RTS tuning) and things like that, when the donation is for someone who is unable to accept it.
&gt; In other words, does correctness (of the business logic) really matter for this domain? That is like asking if we are allowed to make a calculation error in a statistical calculation.
&gt; In other words, does correctness (of the business logic) really matter for this domain? That is like asking if the correctness in calculations really matter if you are doing..say..linear regression?
&gt;There is no force, known or unknown, How can you say about unknown stuff? Do you think humans have figured out all there is? Do you think electricity would have been discovered if it was not present in naturally occurring phenomena? 
Can’t believe this is downvoted. Very disappointing. 
For the web you can use [webdriver](https://hackage.haskell.org/package/webdriver) package. In our case we even use it to run tests with phantomjs. Although I would rather use chrome or firefox in their headless modes.
&gt; The idea is to combat the tragedy of the commons, or the "snowdrift dilemma" (I'm not sure if they're the same thing). From a Math / Game Theory point of view, they're the same (the ideal solution for the individual player prevents the ideal overall situation from happening due to the conflict between relative individual and absolute collective gains). Conceptually however, Tragedy Of The Commons takes a more materialistic / mechanical angle (the gains and losses are quantifyable and tangible: more sheep vs. fewer sheep), while the Snowdrift Dilemma focuses on the social and psychological side of things. Likewise, the proposed solutions are traditionally different: for the Tragedy Of The Commons (or the equivalent Prisoners' Dilemma), the textbook solution is "hyperrationality", as described by Douglas Hofstadter: if you assume that the other parties will act hyperrationally, then from a purely mathematical point of view, it becomes more beneficial to also act hyperrationally, and because of this, you can assume that if the other parties can assume that you will act hyperrationally, then they will, too. The Snowdrift Dilemma proposes are more practical approach, based on human psychology: if one person goes ahead and accepts a small risk, then they can use this risk to trigger empathetic group behavior. By simply investing a small amount to prove that you are being serious, and then stating or implying that you expect others to join in the effort, a single player can get a group to act in the collective interest. So the player in the Tragedy will ask themselves: "Suppose I limit myself to the number of sheep that represent my share of what the Commons can support, what are the odds that everyone else will follow my example?"; and if the odds are good enough, they will act hyperrationally. Whereas the Snowdrift player will ask themselves: "Suppose I demonstrate my willingness to do my share; will that make others feel obliged to join my effort?" Same thing, different angle.
Yeah since much of open source work is pretty much a service to society, one would hope that you could forego all that paperwork. That is, if I didn't know there would be fraudulent orgs being created to exploit it. What you're proposing sounds great, even though without a local company you are legally employed by, one would still have to do consulting/freelancing with all the mentioned "IRS chaos/risk". It's not about avoiding taxes, it's that many places want you to be on regular work force where your employer and you feed into funds (aka taxes) which you're not forced to when doing a solo dev ship. Which is why many consultants can sing a song about audits and battles with IRS to keep their tax status. I understand both sides, but it's a mess, really. On top of all that, in places like Germany, there's always this fairy tale of shortage of engineers, when it's just a thinly veiled propaganda campaign to keep wages down (compared to rest of Europe and Globe). It's pretty fucked up for engineers in Germany and probably other places in Europe. Similar stories I have heard from doctor friends who preferred to move to neighbor countries. I'm starting to think in "Made in Germany" as a quality mark is pointless by now, if the industry does its best to alienate experienced talent in favor of hordes of low pay junior engineers. I know first hand how I'm told to be overqualified and should try for a management role. It's a different way to say "we don't value engineers and can't pay for 3 good people but want 10 bad people instead". Sorry for the rant, it hit a nerve, after reading another "engineer shortage" propaganda blurb this week.
I don’t know anything about linear regression, so I cannot really comment on that.
Thank you for elaborating. &gt; Assume you have a linear `x :: MArray a` (the 'multiplicity' of `x` is 1). &gt; Assuming `read :: MArray a ⊸ Int → (MArray a, a)`, then `read x n` has also multiplicity 1. And, because pairs are linear, so is its second component. Thus, in the end, you have access to the elements with multiplicity 1. This is what I don't understand: in the paper, it's made clear that linearity (and multiplicity) applies to functions/transformations/arrows: &gt; [...] where “multiplicity” refers to how many times a function consumes its input). Given that `read x n :: (MArray a, a)` (ie. it's a value, not a function/transformation), how can it have a multiplicity of 1? Multiplicity of function arguments (within the scope of the function) makes perfect sense to me: the multiplicity of the first argument of `f :: Int ⊸ Int` is 1. That is, when given a fresh copy of the input value (such that no other thunk has a reference to this copy), we can safely have `f` mutate this argument (do in-place update), since the type of `f` guarantees that the `Int` is only used once within `f`. More importantly, though, we can safely turn `f . f . f . f . f . f . f . f` into an operation comprising a series of in-place updates, mutating a value at a given location (as opposed to an operation that creates a new copy of the `Int` for every application of `f`). &gt; Consider now `freeze :: MArray a ⊸ Array a`. As before `freeze x` has multiplicity 1. So you get a single `Array a`. This does not make sense: the whole point of `freeze` is to allow the new array to be shared. Aren't all values shareable by default in Haskell? `freeze x` is an ordinary value, just like any other. I don't see how linearity (of the first argument to `freeze`) can restrict sharing of the value produced by applying `freeze`. As far as I can see, the goal of Linear Haskell is to enable the `write` function to be constant time -- as it is in any other language -- instead of it being `O(n)` due to the memory manager needing to copy the `Array a` argument for every `write` (which takes time proportional to the size of `Array a`, ie. `n`). I've become interested in linearity after implementing a [union find](https://github.com/runeksvendsen/ufw/blob/master/src/Data/UFW.hs) algorithm in Haskell, and realizing that it takes time proportional to n^2 -- as opposed to just n, as it does in languages with in-place update notation (as in Java's `a[i] = n`). As far as I can see, the linear `write` function can be optimized in the same way as Java's array-notation, by interpreting the linear arrow to mean *mutation* or *in-place update* in a language like Haskell that has only immutable values. 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [runeksvendsen/ufw/.../**UFW.hs** (master → abf417a)](https://github.com/runeksvendsen/ufw/blob/abf417adfb4ce56a83a125e68bcb960fb8914f18/src/Data/UFW.hs) ---- 
It's been 5/18 of 18 hours!
I've personally used GHCJS instead of PureScript, which might be worth looking into.
I think it's probably back-end developers trying to prove things like whether you call a certain API correctly.
Say you are trying to interpolate or extrapolate an unknown value, like when you blow up an image of size say 50x50 to 100x100, and you have to calculate the color of all the extra pixels, right? So you try to do that by looking at the surrounding pixels and and applying a method X to them. The result is just an approximation.. So you are asking if it is ok to have an error in the implementation of X since the result is an approximation anyway...
Replying to you as a notification; my actual reply is to the bot.
1. I *think* you will notice a minor performance loss compared to mtl-style, since there's an extra indirection added by the continuations in your functors. But this is easily solved by using GADTs instead. 2. I fail to see how this solves the major disadvantage of mtl-style: the n^2 instances problem. Your examples are all instantiated directly on `IO`, as they would be in traditional mtl-style. In reality, most effects require a specific monad transformer as implementation. This will be no different with your method; try creating a `MonadState` equivalent with your method. You'll end up writing `instance Monad m =&gt; Monad_ (State_ s) (StateT s m)`. So all you've done is squashed the n^2 instances problem into a single type class. One class instead of n classes, but still n^2 instances.
This would still leave OP with their original problem: How do they compile the frontend as a part of site generation?
1. Thanks for the info. 2. Indeed this has nothing to say about n^2 instances. &gt; The n2 instances problem is the only disadvantage mtl-style has compared to extensible effects in my opinion. If we're not solving this, I don't really see the point. The point is that you can get free interoperation between MTL style and `Free`. If that's not interesting to you then fair enough.
This is what I was trying to get at with https://ocharles.org.uk/blog/posts/2016-01-26-transformers-free-monads-mtl-laws.html, though I suggest actually putting Free in the type class itself - if you do that, the type class method becomes a monad homomorphism. I'm not sure what interpret is (certainly as there are now constraints as to what f and m are in the class context).
&gt; I suggest actually putting Free in the type class itself - if you do that, the type class method becomes a monad homomorphism. I'm not sure what interpret is `interpret` is a functor morphism, a.k.a natural transformation. ("The very definition of a free monad is that given a natural transformation you get a monad homomorphism")[https://hackage.haskell.org/package/free-5.0.1/docs/Control-Monad-Free.html#v:foldFree] so `interpret` is indeed a rather natural thing. 
Did you get an answer?
Ok, so then maybe you want class (Functor f, Functor m) =&gt; Monad_ f m.
Though this is probably more natural, it does incur a necessary performance overhead with the continuations required in the functors. Without the `Functor f` constraint, you can use GADTs and avoid that cost entirely. It stops being a natural transformation but at the end of the day they'll encode the exact same thing.
Even `Monad m` might be better. But what would that achieve besides getting rid of the same constraints on utility functions?
What about class Functor g =&gt; Monad_ f g where interpret :: Coyoneda f a -&gt; g a Does that have the same problem? I guess so, as the old interpret would only take one layer of the functor anyway. Still, easier to have people write an f like that, rather than having to bundle up a bunch of continuations.
&gt; with no functional dependencies on Monad_, I think in practice you're gonna have a really bad time with inference Perhaps, but 1. I'm not presenting this as a packaged solution, just as an interesting observation. 2. If you define concrete operations like getCurrentTime :: Monad_ Time_ m =&gt; m UTCTime (which as observed in the article is annoying boilerplate) then I don't think you have any inference problems. 
Documentation, and allowing you to state the homomorphism property you want a little more directly. You do seem to assume these constraints anyway, so you might as well be upfront about it!
For Time_ that *might* be OK (I can only ever check this stuff by writing code out), but I think it might fall apart with something like Reader_ r.
Right, if the functor is parametrized it might get tricky. I can't see off the top of my head how it could get *more* tricky than MTL though. That requires further investigation ...
Yea that's going to have the same performance problem. Probably even worse actually, as `()`-returning effects are forced to be CPS'd when the other style would just do: data MyFunc a = Foo Arg1 Arg2 a -- instead of data MyFunc a = Foo Arg1 Arg2 (() -&gt; a)
I'm converting an important code-flow in a larger application to use freer monads. I've decided to use the `freer-simple` library because it's actively maintained and, well, simple(r). The code will include various effects which I'd like to mix and match independently. For example, here's the model for `ekg` integration: data Instrumentation r where IncGauge :: Text -&gt; Instrumentation () DecGauge :: Text -&gt; Instrumentation () AddGauge :: Text -&gt; Int64 -&gt; Instrumentation () SubtractGauge :: Text -&gt; Int64 -&gt; Instrumentation () SetGauge :: Text -&gt; Int64 -&gt; Instrumentation () SetLabel :: Text -&gt; Text -&gt; Instrumentation () ModifyLabel :: Text -&gt; (Text -&gt; Text) -&gt; Instrumentation () IncCounter :: Text -&gt; Instrumentation () AddCounter :: Text -&gt; Int64 -&gt; Instrumentation () AddDistribution :: Text -&gt; Double -&gt; Instrumentation () AddNDistribution :: Text -&gt; Double -&gt; Int64 -&gt; Instrumentation () incGauge :: Member Instrumentation effs =&gt; Text -&gt; Eff effs () incGauge = send . IncGauge decGauge :: Member Instrumentation effs =&gt; Text -&gt; Eff effs () decGauge = send . DecGauge addGauge :: Member Instrumentation effs =&gt; Text -&gt; Int64 -&gt; Eff effs () addGauge = (send .) . AddGauge subtractGauge :: Member Instrumentation effs =&gt; Text -&gt; Int64 -&gt; Eff effs () subtractGauge = (send .) . SubtractGauge setGauge :: Member Instrumentation effs =&gt; Text -&gt; Int64 -&gt; Eff effs () setGauge = (send .) . SetGauge .... The ctor names come from the `System.Metrics.*` modules of the `ekg-core` package. Now, here's the IO-based interpreter: runInstrumentation :: ProvidesInstrumentationContext =&gt; Eff '[Instrumentation, IO] a -&gt; IO a runInstrumentation = runM . interpretM (\case IncGauge t -&gt; Instr.incGauge t DecGauge t -&gt; Instr.decGauge t AddGauge t i -&gt; Instr.addGauge t i SubtractGauge t i -&gt; Instr.subtractGauge t i .... ) The specifics are not that important, but suffice it to say `ProvidesInstrumentationContext` is, essentially, a nullary type-class providing the necessary environment for maintaining the `ekg` store, and each of the `Instr.*` functions read this environment and perform the necessary actions. This is possible thanks to the `reflection` module, btw. ---- Now, here's my actual question: How do I write an interpreter which merely ignores this effect, regardless of whether the rest of the stack/interpreters are pure or impure? That is, an interpreter which throws this effect away? Due to the nature of `ekg`, the effect needs to be interpreted impurely to be useful, so I would like pure combinations of interpreters to ignore this layer fully. In other words, how does one "interpret" an effect by merely ignoring it, using `freer-simple` (or at least `freer-effects`)? Should I use the `Identity` monad (something like `runInstrumentationDummy :: Eff '[Instrumentation, Identity] a -&gt; Identity a`), or is there a more straightforward mechanism provided by the `freer-simple` library? I hope this makes sense... 
Hello! I'm the author of this small document snippet. I'm not a professional researcher in this area. I've studied Formal Language Theory at university, I've used parser generators `ANTLR` and `Happy` for writing programming language parsers and I've used parser combinators library `parsec`, `attoparsec`, `megaparsec` for different purposes. I wrote small tutorial on the idea of small and simple parser combinators library and I've explained them to students many times. I even tried to implement and use parser combinators in Kotlin programming language... But I still feel like I know nothing, might miss something or might be too opinionated in some topics (since I love parser combinators more than parser generators). I know that Haskell community has a lot of great people! So I'm hoping to gather feedback, to see where I'm wrong and what I need to correct. Thanks for reading this! 
🤔
Interpret each constructor as `pure ()`. interpretInstrDummy :: Eff (Instrumentation ': es) a -&gt; Eff es a interpretInstrDummy = interpret $ \case IncGauge{} -&gt; pure () DecGauge{} -&gt; pure () ...
Super cool, but I would propose a few minor things: Rename `Monad_` to `Uses` and `interpret` to `use`. Use the `freer` trick of not storing the continuation in the data type i.e.: data Time a where GetCurrentTime :: Time UTCTime Now you have: getCurrentTime :: Uses Time m =&gt; m UTCTime getCurrentTime = use GetCurrentTime To get access to the continuation you can handle effects in the continuation monad: instance Uses StateInt (Cont (Int -&gt; a) a) where use Get = cont (\k s -&gt; k s s) use (Put s) = cont (\k _ -&gt; k () s) If you need to reify the computation tree you can interpret into `Freer`: instance (Member StateInt fs) =&gt; Uses StateInt (Eff fs) where use = send Or you can use the plain old state monad: instance Uses StateInt (State Int) where use Get = get use (Put s) = put s
&gt; Extensible effects avoids the problem by using type level magic that's roughly equivalent to this mtl-style trick Oh right, I see. It seems to me that both the type level magic and the mtl-style trick would be accessible to the "MTL style for free" approach.
I stand by my original comment.
I see. Then how about parameterizing on `f :: * -&gt; * -&gt; *` class Monad_ f p m | m f -&gt; p where and have `f p` be the functor applied to some parameters `p`? For example data Reader_ r a = Read (r -&gt; a) data Writer_ w a = Writer w a data State_ s a = State (s -&gt; (s, a)) etc.?
Am I right in thinking that the correspondence between the functor (`F`) version and the GADT version `G` is that F a ~ exists r. (G r, r -&gt; a) (In some sense `G` is literally `F`-without-the-continuation). For example the functor version of state is data F a = GetF (S -&gt; a) | PutF S a and the GADT version of state is data G a where GetG :: G S PutG :: S -&gt; G () Then it seems that the isomorphism above indeed holds.
Regarding the GADT style (i.e. without continuation), you may be able to answer this question: https://www.reddit.com/r/haskell/comments/89njsr/mtl_style_for_free/dwsgl9w/
Parser combinators are comparatively young? Wirth was using that approach for Pascal in 1969. That makes them only about 2 years younger than that "50+ years" line on the other side of the table. Also note your classification system is a bit wonky. ANTLR for instance uses `ALL(*)` which is in the LL parsing school, even though it's a generator, while you can use "recursive ascent" to write for the LR side of the line using combinators. Using `Applicative` or `Arrow` can let you build a statically analyzable fragment in the recursive descent form. e.g. Swierstra and Duponcheel's original work on LL(1) parsing. Error recovery is something that the LALR side actually has hands down better than the LL side of the line. error productions make it easy to handle globally correct reporting of multiple error messages by starting to feed it more tokens and just shift/reduce as it can after an error. All such attempts at recovery on the combinator side are actually hacks, and rely on you knowing global properties of your grammar, though. Re: GHC and parsing layout it is effectively managed by having the lexer produce a set of "indent, dedent and virtual semicolon" tokens before the parser generator sees the token stream.
Wow, that's really a great feedback! Didn't expect such elaborate response. Well, that's really cool. Ensures I didn't save any nonsense. I will fix the table in order to apply your suggestions!
Thank you for this post. I've deleted everything you mentioned and that I have on my laptop. Now I've started a fresh try-reflex.
&gt; Performance: I didn't see benchmarks. But nobody complained so far. I would expect PGs to be faster, since the generator has the opportunity to generate optimized code and then the compiler can optimize that output further. PCs can't afford to spend much time on optimization, since those optimizations would have to be performed at runtime and so their cost would offset their benefits. &gt; Indentation: Usually it's much more difficult to parse layout-sensitive languages with PG. I don't known how GHC managed to do this... A common trick is to post-process the whitespace tokens to generate "increase indentation" and "decrease indentation" tokens. GHC seems to be using [a similar approach](https://github.com/ghc/ghc/blob/master/compiler/parser/Parser.y#L522-L523).
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [ghc/ghc/.../**Parser.y#L522-L523** (master → 72b5f64)](https://github.com/ghc/ghc/blob/72b5f649ede82ab3bb429aa72ee1c572f415b0eb/compiler/parser/Parser.y#L522-L523) ---- 
Yes, absolutely. I have first seen it in [`operational`](https://hackage.haskell.org/package/operational-0.2.3.5/docs/Control-Monad-Operational.html). You observe that all your functor data types share the same pattern and your factor it our into its own data type [`Coyoneda`](https://hackage.haskell.org/package/kan-extensions-5.1/docs/Data-Functor-Coyoneda.html#t:Coyoneda) or inline it into the [free monad definition](https://hackage.haskell.org/package/operational-0.2.3.5/docs/Control-Monad-Operational.html#t:ProgramViewT). F a ~ Coyoneda G a
Thanks! That's a really great information to know.
Why isn't this done? In the [`layers` "manifesto"](https://hackage.haskell.org/package/layers-0.1/docs/Documentation-Layers-Overview.html) it says &gt; The other reason why this is not done is because these instances require the OverlappingInstances extension. layers doesn't solve this problem, but we just say "fuck it" and use OverlappingInstances anyway. and the explanation that follows this quote convinces me.
Oh nice! It's been a long time since I looked at either Coyoneda or extensible-effects and I didn't make the connection.
You are clear about what I said right?
&gt; Well, but this is not implemented yet. It means that users don't have such feature if they use parser combinators in April 4th, 2018. Well, you get nice error correction with [uu-parsinglib](https://hackage.haskell.org/package/uu-parsinglib) and have been able to get that for the last decade.
&gt; (aside: which is more absurd, astrology or whatever it is that Jane Street does?) Give this man a cookie.
http://okmij.org/ftp/tagless-final/course/lecture.pdf
And it turns out it all makes sense via `Coyoneda`! https://www.reddit.com/r/haskell/comments/89njsr/mtl_style_for_free/dwsibqr/
This. High-frequency trading is a form of economic activity which produces nothing of value (as it undermines the ostensible purpose of finance) and does nothing but harm (since nothing of value is produced, to win at this zero-sum game, others have to lose), and we end up having our best minds working on ways to make the rich richer and the poor hurt. At least with an astrology app, the cost of the nonsense is up-front to the consumer, instead of abstracted away in a financial instrument, and bleeding human lives and human potential dry at at the edges.
It's a great idea, and I'd love for the Haskell.org nonprofit to broker a "Haskell Together" thing -- we actually recently started kicking the idea around after seeing "Clojurists Together". The main obstacle, as far as I'm concerned, is just that we need someone (or some people) to step up to volunteer to coordinate donations, a website, communications, assembling a trustworthy body to judge proposals, etc. We've been rather busy coordinating GSoC at the moment, so I don't think there's anyone on the committee chafing at the bit to take responsibility for another large-scope project. But organizing doesn't have to be (and shouldn't be) limited to the committee -- its only _necessary_ role is oversight. If someone stepped up and said "here's how I want to organize Haskellers Together, and I would like to use the haskell.org nonprofit status and apparatus to coordinate handling of the donations and payments" I think people would be thrilled!
This is the post that made ML type checking click for me: http://okmij.org/ftp/ML/generalization.html OCaml will be slightly easier in certain ways because it has polymorphic sums, but harder in others because it has no type classes. Both are terrific tools for the job, though, so don't sweat it too much. :-)
Stephen Diehl has a guide on writing a compiler in Haskell for a functional language - it also has a [chapter](http://dev.stephendiehl.com/fun/006_hindley_milner.html) on Hindley Milner type inference.
Quick question, do you really need a typeclass for this ? I mean, the standard translation of OO-classes into haskell are usually (depending on the situation) are either Algebric Data Types or plain record (with functions).
Just summon /u/terrorjack, who will tell that {-# language QuantifiedConstraints #-} is a worthy contender.
For what it's worth, I'd be willing to build an open source landing page for this. It would be in all haskell of course :) If anyone wanted to join me, or if others think this is a good idea, then let me know
If you're looking for something more in depth, Pierce's [Types And Programming Languages](https://www.google.ca/url?q=https://www.asc.ohio-state.edu/pollard.4/type/books/pierce-tpl.pdf&amp;sa=U&amp;ved=0ahUKEwiT-vnohKHaAhUQMt8KHZkkBOkQFghBMAk&amp;usg=AOvVaw3O9GRlCvb3JL2PmViDLpMi) covers pretty much everything you'd need. Difficultly wise, it depends. Writing a checker for a small expression language isn't so bad, but adding in more features (ADTs, Polymorphism, etc) becomes difficult. Additionally, unless you plan in hooking into Elixir itself, you'll end up writing a parser and resolver too. Don't let me stop you, but do set aside more than a weekend for it. 
Releasing important/legitimate things on April 1st is a Haskell tradition!
I'm a huge fan of Matt Parson's article that you linked (http://reddit.com/r/haskell/comments/8693m0/three_layer_haskell_cake/). The ReaderT pattern has its place somewhere deep in most apps, but I think the bulk of your business logic should avoid it. mtl-style has too many important benefits, and using `ReaderT _ IO` everywhere loses most of them.
I don't know with the 1.6 version, but normally the easiest way is to chose a scafold template depending on your need (this can be done with stack) &gt;&gt; stack templates Template Description chrisdone foundation - Project based on an alternative prelude with batteries and no dependencies. franklinchen ghcjs - Haskell to JavaScript compiler, based on GHC ghcjs-old-base hakyll-template - a static website compiler library haskeleton - a project skeleton for Haskell packages hspec - a testing framework for Haskell inspired by the Ruby library RSpec new-template protolude - Project using a custom Prelude based on the Protolude library quickcheck-test-framework - a library for random testing of program properties readme-lhs - small scale, quick start, literate haskell projects rubik scotty-hello-world scotty-hspec-wai servant - a set of packages for declaring web APIs at the type-level servant-docker simple simple-hpack simple-library spock - a lightweight web framework tasty-discover - a project with tasty-discover with setup tasty-travis unicode-syntax-exe unicode-syntax-lib yesod-minimal yesod-mongo yesod-mysql yesod-postgres yesod-simple yesod-sqlite You have a few version for yesod. If you want to use yesod-mysql, for example, just type `stack new yesod-mysql`. 
What semantics are you trying to encode here? What is the meaning of `n` and `d`? I think what you're trying to encode is a state machine with invisible state? If so, existentializing the internal state is likely a better approach: data Machine i o where Machine { mState :: s , mUpdate :: i -&gt; s -&gt; (s, o) } :: Machine i o pump :: i -&gt; Machine i o -&gt; (o, Machine i o) pump i (Machine s update) = let (s', o) = update i s in (o, Machine s' update) Now, if you want randomness, you can stick it into the `s` when you initialize a `Machine`, and nobody is any the wiser.
Wouldn't that defeat the whole purpose of ST? If refs / arrays can escape the monad, then you lose the guarantee of purity. If you want mutable arrays that persist long enough for you to do IO things and still read and write them, you'll need IO refs and arrays instead of ST ones.
If its just overriding bounds, you can also put an `--allow-newer` directly in your cabal.project like so: http://cabal.readthedocs.io/en/latest/nix-local-build.html?highlight=allow-newer#cfg-field-allow-newer (but yeah, in general, you should try to upstream the dep changes necessary to get everything to interoperate)
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [andrejbauer/plzoo/.../**miniml** (master → 07f2449)](https://github.com/andrejbauer/plzoo/tree/07f244967c415e37420277e5665796c1e0832c16/src/miniml) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dwsw225.)
You can use the super-cool inspection-testing plugin to verify that the code _really is_ the same too: https://github.com/nomeata/inspection-testing
At the top level of my program, I tend to use implicit parameters (including `IORef` for global state). It's very convenient, especially as one can combine functions that use different sets of parameters very easily.
I can't comment on the general case, but I can answer why I chose web (its covered a bit in the blog too) :) Firstly using a desktop GUI is non-trivial and takes a good time investment. That seems like an unnecessary cognitive overhead for what I'm trying to convey here. I.e. The GUI is not really the point, +90% of the haskell in the samples can be used with whatever GUI framework the reader likes. So... even if I really liked a particular desktop GUI, I may not have chosen to use it. Secondly, in all fairness, a web GUI does have quite a lot to offer as a first choice. - Many (most?) of us are exposed to JS &amp; HTML &amp; CSS already, so it makes sense to use existing skills. - Web GUIs are cross-platform by design, desktop GUIs always seem to struggle with this to different extents. - Colossal amounts of dev time and effort are being poured into web browsers. None of the desktop GUIs come even close in terms of dev focus. This is a real pity, I wish more time was spent making desktop GUI frameworks better, but that is simply not the case. (I know popularity is perhaps not a compelling argument, but I think its worth considering). So I'd say that it is somewhere between choosing something familiar and simply liking web GUIs depending on the individual. I doubt I've said anything new here, but I hope it answers in some way?
It would be wonderful for all of the organizers of these efforts to help others understand what works and what doesn't work so well. For example, what would make a successful long-term project, one that invites others to join and keep the code from rotting away as the original participants drift off to other activities? How can different skills (e.g., documentation and tutorials) be incorporated by those who can be encouraged to join the architects and developers?
On the web GUI aspect: My library [Threepenny GUI][1] gives you a web GUI while feeling like an ordinary Haskell UI library. You don't have to worry about setting up a web server and handling requests. [1]: https://wiki.haskell.org/Threepenny-gui
On the web GUI aspect: My library [Threepenny GUI][1] gives you a web GUI while feeling like an ordinary Haskell UI library. You don't have to worry about setting up a web server and handling requests. [1]: https://wiki.haskell.org/Threepenny-gui
You can use `runST`: myFunc :: (Int,Int) myFunc = runST $ do x &lt;- newSTVar 5 y &lt;- newSTVar 6 a &lt;- readSTVar x b &lt;- readSTVar y return (x,y) This works fine. If this doesn't help, you may want to post a minimal example that illustrates the problem you are having.
pretty sure i did that!
Funny you should ask, since this weekend I'm going to start writing an HN type checker for hnix, so I've been doing quite a bit of reading. I found these resources helpful so far: - Great for introduction to concepts, but the implementation was hard to follow: http://steshaw.org/hm/hindley-milner.pdf - A good follow up to that paper, clearer algorithm (because of the phase separation): https://pdfs.semanticscholar.org/8983/233b3dff2c5b94efb31235f62bddc22dc899.pdf - That second paper has a reference implementation in Haskell: https://github.com/kseo/poly_constraints
That might work well. I need to look at my Haskell code again.
A bit? I am looking more for 'what does HTML/JS/CSS give me that existing frameworks don't' Your answer seems to be: * An ecosystem I already know * Cross platform distribution But it doesn't seem like you're leveraging much of that ecosystem in this project, it seems like you've built a pretty thin client here. Likewise I'm not sure the second point really applies to your project, as you're not really implementing a full on webapp - To distribute, you're still requiring users to build the project from source locally, which is a bit of a headache. To be clear, I'm not criticizing your choice here at all - I see why you've made the choice and I agree with it in practice. I'm just trying to think through more exactly what it is about this development experience that is smoother than the alternatives.
In this particular case, a quantified constraint is a stronger requirement, and not actually needed. We need the `f a` instances only for the `a` values that actually occur in the type in question.
&gt; I am seriously considering redesigning the library to have fewer parameters but lets pretend this is the right design for now. Four parameters is certainly not unheard of (cf. [lens](http://hackage.haskell.org/package/lens-4.16.1/docs/Control-Lens-Lens.html), [pipes](http://hackage.haskell.org/package/pipes-4.3.9/docs/Pipes.html)). If you need 'em, use 'em. &gt; Another concern here is that most users will only need to customize "p" and "s" leaving "m" as () and never touch "g". Make a type synonym with `m` specialised to `()` and tell your users to use that unless they have a reason not to. The users can then make further type synonyms for themselves to customise `p` and `s`. Unsolicited advice: Reconsider the names of your type variables. Except for `g`, they don't obviously convey their meaning, and `m` is generally reserved for monads. Also, multi-letter names may be better for readability (but this depends).
Why not [freer-simple](https://hackage.haskell.org/package/freer-simple)? :)
Oh, yes, the `a` seem to be ground in all the examples. But what if some `a` would be a parameter to a HKD? One would need to assert that `forall a . c a =&gt; c (f a)` (i.e. `c`-ness lifts through `f`), right?
Resources which were helpful to me while I was writing a correct-by-construction Algorithm M (which is the more efficient dual of Algorithm W that is usually used): 1. Martin Grabmüller. [Algorithm W Step by Step](https://github.com/wh5a/Algorithm-W-Step-By-Step) 2. Oukseh Lee, Kwangkeun Yi. [A Generalized Let-Polymorphic Type Inference Algorithm](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.6832) 3. Dr. Gergő Érdi. [Compositional Type Checking](http://gergo.erdi.hu/projects/tandoori/Tandoori-Compositional-Typeclass.pdf) (in no particular order)
It didn't exist when we started working on this! Can I ask though, why did you chose to fork instead of make a PR?
We have business logic (that just happens to be astrologically based) which can be typed just like any other domain. And then of course there is the non business logic. We use persistent and esqueleto to help with making sure db queries are correct. Free monads lets us time all of our IO actions automatically with a nice hierarchy of effects (think flame graph) for analyzing performance (we're working on open sourcing this part!). 
This isn't quite Hindley Milner, but it's a system for writing a typrcheck byer that can handle many powerful constructs, with the trade-off that a few annotations are necessary. I know Purescript is based partially on this system. http://research.cs.queensu.ca/~joshuad/papers/bidir/ 
Actually, you may be more interested [in `createT`](https://hackage.haskell.org/package/vector-0.12.0.1/docs/Data-Vector.html#v:createT), which won't waste time on the extra copy. Bear in mind that tuples have a traversable instance. createT :: Traversable f =&gt; (forall s. ST s (f (MVector s a))) -&gt; f (Vector a) instance Traversable ((,) a) where traverse f (a, b) = (,) a &lt;$&gt; f b let (otherData, vector) = createT $ do arr &lt;- ... return (otherData, arr)
I don't think we use that (or really any other profunctors ... yet), but we do use [semi-direct products](https://hackage.haskell.org/package/monoid-extras-0.4.2/docs/Data-Monoid-SemiDirectProduct-Strict.html) and recursion-schemes if you're looking for algebras! 
I'm not sure there is a significant difference between parser generators and parser combinators. They are both domain specific languages for specifying parsers. I think the distinction which is being made here is that "parser generators" are not usually embedded in the host language. 
Cool, good to know. We're definitely excited to see the free monad ecosystem develop, so making sure that we're using the most up to date and widely supported/used library is important to us! I just started working on getting a small library we're using ready to open source, here's a preview of it (it uses freer-effects though 😁) [freer-catching](https://gitlab.com/costar-astrology/freer-catching). And many more to follow!
Wait for a couple of point releases after a major GHC upgrade -- all perf regressions get sorted out by then, or at least known.
I really like the idea of existentializing the internal state. Thanks! A behavior tree is like a state machine with no state. So the "s" being returned here is an action to mutate the state which is then used to produce "p" the input state for the next time the tree is ticked. Nodes can only communicate info to each other through the internal state "m". I think my code is unclear because "update" also modifies the input state "p" which is maybe a bad design decision. The user needs to create instances of BtNode to produce meaningful output from the input state hence the exposed type variables. The library only provides control flow nodes which don't actually care so much about these type vars.
&gt;To be clear, I'm not criticizing your choice here at all - I see why you've made the choice and I agree with it in practice. No offence taken at all. Having my assumptions challenged and hearing different opinions is a huge benefit of writing blog posts. &gt; To distribute, you're still requiring users to build the project from source locally Absolutely. When I said cross-platform I was talking about the dev experience. I.e. the same code base will build and work on any platform. If I was trying to distribute the app there would be a different set of decisions. &gt; ... it doesn't seem like you're leveraging much of that ecosystem in this project, it seems like you've built a pretty thin client here. I think that depends on how you look at it. Yes it is true that my client is very thin (~200 lines JS), **but** in those very few lines I get alpha transparency/layering, reasonably fast drawing, full keyboard support (with shortcut key support) etc. Adding animations / sound and more in is not that much more complicated. That is a lot of very well tested and documented cross-platform functionality for remarcably little effort. I seriously doubt many desktop GUIs could complete on this metric (they could on others though) If you want to consider distribution then there are options like electron or lighter weight alternatives that work similarly. But worst case distributing a binary per platform type is still pretty easy. Desktop GUIs would need that too. I think there is a place for desktop GUIs, and again I hope they get better too. What I'm saying is that I definitely see why web GUIs appeal to so many other people.
I guess the (C++) OO equivalent I'd be trying to create here would look something like: template&lt;class M, class P, class G, class S&gt; class BNode{ S update(const P inState, M&amp; inoutInternalState, G&amp; inoutRNG); } 
Any reasons why you want HM specifically? By all means go for it if that's what you want, but you may also want to take a look at bidirectional typing, which I found easier to understand and extend. Here are two papers that I like: - [Complete and Easy Bidirectional Typechecking for Higher-Rank Polymorphism](https://arxiv.org/pdf/1306.6032.pdf) - [Frank](https://arxiv.org/pdf/1611.09259.pdf) for a complete language with bidirectional typing. See also the [implementation](https://github.com/frank-lang/frank). I'm also a beginner in this area but to answer your questions: - I highly recommend Types and Programming Languages. It's a lot of fun and easy to read even without a solid background in logic and related math. It comes with OCaml implementations of all of the type systems in the book IIRC. - Perhaps check out [Typing Haskell in Haskell](https://web.cecs.pdx.edu/~mpj/thih/thih.pdf) for a starter. Note that it only covers a very simple version of Haskell's type system (I don't know if it covers type classes). - I think it's a great idea for learning. - No.
That looks very interesting, thanks. I'll take a look
I'm not sure whether difference is significant or not. But the fact that _parser combinators_ are embedded inside host language unlike _parser generators_ which are specified through separate custom DSL actually means a lot when you need to choose between approaches. Mostly the matter of convenience and maintenance. 
Yes, that type synonym is what I thought of. However, you probably want your functions to remain fully general, so update :: ... -&gt; BState m p g -&gt; ... Otherwise, `update` could only be used for `m = ()`. For the pattern, you can use a [pattern synonym](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#pattern-synonyms) (untested, but should be more or less correct): pattern BSimpleState :: p -&gt; g -&gt; BState () p g pattern BSimpleState p g = BState () p g
Personally I think both `lens` and `pipes` are extremely unreadable. I don't comprehend why they can be thought of as reasonable APIs. The only way `lens` and `pipes` were reasonable APIs were if you as a professional programmer is focused on these sublanguages only. It's very similar to old x86 assembly language where `AX`, `BX`, `CX` and `DX` had special significance. For example the `loop` instruction would implicitly modify certain registers, and the `mul` instruction would both read and write to certain registers. Of course, the x86 instruction set was pretty regular and easy to understand. I use `lens` everyday, but I find the naming convensions offensive, and IMO it's a disgrace that Haskell can't be more readable.
Wow! first time I've seen pattern synonyms. This is really awesome. Thank you!
Hope it helps. Happy cake day! 🎉
Timestamp the module-by-module output, for example piping into `awk '{ print strftime(\"%H:%M:%S\"), \$0; fflush(); }'` or some similar utility.
I have a chunk of work done for this in a pretty dishevelled state, but perhaps we should chat... 
[Tutorial on Hindley-Milner Inference in Haskell](http://dev.stephendiehl.com/fun/006_hindley_milner.html)
You might be interested in [this](https://www.google.co.uk/amp/s/lukepalmer.wordpress.com/2010/01/24/haskell-antipattern-existential-typeclass/amp/). In your case a polymorphic function should be enough.
Do you have thoughts on how to make them more readable?
My pleasure. You'll likely find that pattern synonyms are somewhat less awesome than it seems, because they don't interact well with the exhaustiveness checker. But maybe this has improved with recent GHCs.
&gt; Perhaps check out Typing Haskell in Haskell for a starter. Note that it only covers a very simple version of Haskell's type system (I don't know if it covers type classes). It covers Haskell 98 including type classes, I've used it to implement [Duet](https://chrisdone.com/toys/duet-delta/) (see e.g. the Monad example, click also "Show dictionaries" to see type-class dictionaries). 
Just wrote some code this morning and remembered your comment. If you have your lens TH at the bottom of the file, you *can* use those lenses earlier in the file.
Yes, let's chat after I get further into the work. I'm still at the reading stage right now. I was thinking of doing it the way `poly_constraints`, with an initial phase of evaluation that produces a set of typing constraints, and then a second phase of resolution to discover if the set can be properly reduced.
With the caveat that type-classes complicate matters. [Duet](https://chrisdone.com/toys/duet-delta/) has type-classes and that was hard. Whereas [jl](https://github.com/chrisdone/jl) is simply typed lambda calculus with HM inference, and [that type checker is trivial](https://github.com/chrisdone/jl/blob/master/src/JL/Inferer.hs). I wrote another based off that for a client that has row polymorphism with unions and it was still way easier than type-classes. It's worth shopping around for the simplest resources on basic type checking. The more simple sources in this page will make for a smoother ride.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [chrisdone/jl/.../**Inferer.hs** (master → 39eb96b)](https://github.com/chrisdone/jl/blob/39eb96b48b6c883025ae8d79bb2c8e4b9fef0a0d/src/JL/Inferer.hs) ---- 
Have you got a plan for typing sets with antiquoted fields, and `__functor`?
I feel like morally this should be generated with TH in the `MonadTime` =&gt; `Time_` direction.
(Snowcloning /u/crazyviz 's comment.) &gt; In other words, does correctness (of the business logic) *really* matter for this domain? That is like asking if the correctness in calculations really matters if you are coding the physics of a Mario game.
Galois does all sorts of Haskell work. See our [tech reports](https://galois.com/reports/) and our [github organization](https://github.com/galoisinc). Galois has been using Haskell for almost 20 years. Facebook uses Haskell for a few things, including powering its spam-fighting. You can read about their [Haxl project](https://code.facebook.com/posts/302060973291128/open-sourcing-haxl-a-library-for-haskell/) and the [github repo](https://github.com/facebook/Haxl). [Groq](https://groq.com/) writes their TensorFlow compiler in Haskell. [Fugue](https://fugue.co/) uses a lot of Haskell for their devops products. GitHub uses Haskell for their semantic code team. These are just the ones off the top of my head. There are many more.
This was the very first approach I considered using, but I kind of shyed away from it because it felt too much like uncontrolled global state? To take a cue from other languages, just about every single How do you run your tests on the individual functions/actions? -- do all the functions that try to use the implicit parameters take them as input? It would probably be better to take some abstract type and restrict the type with typeclasses necessary to the functionality you needed? Honestly I haven't used IORef much, just because I actually haven't had any mutable state in that way -- I've just recently started actually using the STM (TVar) when I had to introduce templating (since I wanted to load a template at runtime and keep it around).
Can you explain to me the difference between monad transformer stacks and "mtl"? I have a reasonably clear understanding of using multiple monads serially, monad transformer stacks, the ReaderT pattern (pending my re-read of the fp complete article today), and even a light grasp on Free monads, but I can't tell what exactly "mtl" is referring to/how it's different from these other approaches. Maybe once I'm done re-reading Matt Parson's article I'll get it
That does sound fun! Not sure if I can find the time but otherwise I’d love to
Sure, let's. :) Are you open to trying this even now or do you want to negotiate a later time, e.g. in private messages? I can also share contact details for Skype, Google Hangouts, Facebook Messenger or maybe even WhatsApp where we can communicate in real time chat or a voice call for increased bandwidth.
I haven't read it but here is another old discussion about this http://lambda-the-ultimate.org/node/5286
If you decide to implement HM type inference in Haskell, note that we have nice unification libraries so you don't have to reinvent that wheel. I like [unification-fd](https://hackage.haskell.org/package/unification-fd). Theres [a tutorial](https://winterkoninkje.dreamwidth.org/100478.html) As I mentioned in another comment, after implementing basic HM type inference, a more useful thing to implement is HM _typed elaboration_, for which, see [Hindley-Milner Elaboration in Applicative Style](http://gallium.inria.fr/~fpottier/publis/fpottier-elaboration.pdf) for a nice way to structure the code.
This is great! I'd love to see a CMS use Darcs as a backend for page revision history I remember that \[Camp\]\([https://archives.haskell.org/projects.haskell.org/camp/index.shtml](https://archives.haskell.org/projects.haskell.org/camp/index.shtml)\) \(\[video\]\([https://www.youtube.com/watch?v=iOGmwA5yBn0](https://www.youtube.com/watch?v=iOGmwA5yBn0)\)\) was being worked on to form the basis of Darcs 3. What ever happened to that work? 
Then `generic-lens` guys have that even the lenses are equal (according to `inspection-testing), but only after they used some Yoneda-something to fuse the chains of `fmap`s. Maybe you can do the same? And thanks for the nice rep for `inspection-testing`!
One interesting point about "The Essence of ML Type Inference". Classical presentations of Hindley-Milner usually present "Algorithm W" which performs type inference by traversing a program expression and immediately spitting out unification equalities to solve and generalizing as it goes. In "The Essence of ML Type Inference" (and other Pottier papers), the argument is made that it is much more scalable (in the sense of managing the complexity of the implementation) and extensible (in the sense of adding new features to your language) to perform two separate phases: 1. Traverse a program and generate constraints. 2. Solve the constraints to discover the typing. To that framework "Hindley-Milner Elaboration in the Applicative Style" adds a third step: 3. Write down a new program with all the type annotations written in. This two (or three) pass approach is what GHC does now. It used to be much more like Algorithm W, but ever since [OutsideIn(X): Modular type inference with local assumptions](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/jfp-outsidein.pdf) GHC follows the two-phase approach - generate constraints; solve constraints.
@jwiegley, I'd love to see a Haskell implementation of [Hindley-Milner Elaboration in Applicative Style](http://gallium.inria.fr/~fpottier/publis/fpottier-elaboration.pdf) - it's absurd that the paper is basically all about using `Applicative` to do typed elaboration (in the generate constraints; solve constraints style as you describe) but it's in OCaml.
I've looked over some of the same studies myself. My overall conclusion is that pretty much all the studies were really weak. I agree wholeheartedly with the summary in the article: &gt; ...the studies probably don't cover contexts you're actually interested in. They really don't! More philosophically, I've started to believe that "static vs dynamic" is the wrong question to look at because it's a really weak way to group languages. In practice static vs dynamic languages differ *far more* than just by when errors are caught. More importantly, languages in the same category differ from each other to a degree that overshadows aggregate differences between the groups. The distance between Haskell and Java is *massively* larger than the distance between Python and Java.
Apologies in advance about me being uninformed. Do people still use Darcs?
I'm interested. ;) I've also updated my main post with some general questions regarding time, experience, and topic/project interests. Please answer them if you are willing. I don't know much about hledger, but I can imagine liking working on it from the navigator/back seat in half of our time.
Here's a fairly up-to-date list of Haskell companies: https://github.com/erkmos/haskell-companies I worked at Awake Security last summer (and will be coming back after I graduate in May). We use Haskell for packet analysis and in our devops (along with Nix), as well as PureScript for some of the frontend stuff. Unless things have changed a lot since I was last there, there are about 7 Haskell/PureScript-proficient developers, including /u/Tekmo. [IOHK](https://iohk.io), [Formation](http://formation.ai) (formerly Takt), and [Galois](https://galois.com) are the biggest "pure" Haskell shops I know of. Standard Chartered also uses Haskell pretty heavily (and probably has the largest production Haskell codebase AFAIK) and Facebook's spam filtering system is based on a DSL embedded in Haskell. You may also be interested in the [Commercial Users of Functional Programming](http://cufp.org) workshop, which is a part of ICFP focused on commercial applications of functional programming. Here is the [2015 talk playlist](https://www.youtube.com/playlist?list=PLnqUlCo055hXArE00SkORNiK9fk54de2a) and the [2016 talk playlist](https://www.youtube.com/playlist?list=PLnqUlCo055hUaidgipB5HjDpUnskXgGJ1) (2017 has not been uploaded yet).
I am, and I think this is a great idea for an app.
I still get a rather high volume stream of darcs dev-chatter in my email inbox.
.... Did you mean 'astronomy' rather than 'astrology'?
Or you could always go with what [Silver](https://github.com/melt-umn/silver) does and use the `::` operator for both cons and type! 
Great, would you like to try a short session now/soon?
I'm interested. I enjoy pair programming. &gt; What's your time availability? Flexible but say 4pm Mondays Pacific time to choose something specific. &gt; What's your Haskell level of experience, roughly? 4.5 years, intermediate to advanced &gt; What topics or codebases are you interested in? Definitely interested in learning Reflex. Interested to learn GHC's codebase. Or we can hack on Squeal.
Hmm, great! I don't remember trying Squeal yet, but I remember considering to try it, so that topic could be interesting for me. And I think I'd definitely enjoy sharing what I've learned of reflex so far. I also like that you have 4.5 years of experience; I imagine there could be some things I could learn from you, e.g. regarding type level programming. 4pm Monday Pacific sounds good for me, and I'm available now too until someone takes me up on my offer for 'soon'.
[no](https://www.reddit.com/r/haskell/comments/8953h8/costar_astrology_is_hiring_a_haskell_developer_in/)
Potentially, if there is explosive interest here on Reddit, it could make sense to encapsulate the process in the form of an app, but so far I like this platform too. Have you seen the questions that I edited into my main post? If not, would you like to answer them here? Or in a PM to me?
Interesting - thanks!
Edited my comment to answer the questions.
Yeah, in this case since I don't know the way to proceed for either solution, I'd prefer sticking with PureScript
I get the impression that there are more people hacking on it than using it.
seems like for arrays can be done relatively easy runSTUArrayT st = runST (st &gt;&gt;= traverse unsafeFreezeSTUArray)
If you want something that does FRP, the `reflex` library has support for [debouncing and throttling things](https://github.com/reflex-frp/reflex/blob/develop/src/Reflex/Time.hs) and there's nothing requiring that it is used just for GUIs. I don't actually know what you're trying to do, but the book [Parallel and Concurrent Programming in Haskell](https://simonmar.github.io/pages/pcph.html) might be handy, and is free online. It covers quite a bit of asynchronous programming.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [reflex-frp/reflex/.../**Time.hs** (develop → 9f3356f)](https://github.com/reflex-frp/reflex/blob/9f3356fecb1620f74b45291b38aaaafbe92458fa/src/Reflex/Time.hs) ---- 
Sounds super fun. Is this remote or a specific location?
Does that mean Darcs 3 no longer aims to be based on patch-based version control? Why can't the theory behind pijul be used for darcs since camp never quite achieved the goal?
Huh, I wonder if it's a Peter Thiel company?
We're located in Orange County, California. Given the nature of the work, we're hoping to get as many developers on-site(and near our test sites) as possible, but we're open to other possibilities.
Is this something that [snowdrift.coop](https://snowdrift.coop) could be used for? The also happen to use a lot of Haskell IIRC.
We use it for [bioinformatics](http://ngless.embl.de) [github](https://github.com/luispedro/ngless). In academia, but not PLT.
[removed]
Research aside, what are companies/orgs investing in? Maybe it's the bubble I'm in, but it seems to me that there is quite a shift towards static (and even strong) typed language investment. Go, ReasonML/BuckleScript, Kotlin, Swift, TypeScript, Rust, PHP/Hack ... On top of that we see a lot more commercial action in Haskell. I've been on the dynamic side, specifically Ruby, and saw the uptake there (and with Python/Groovy). People and companies were moving to these languages from Java! I know that truth is not measured in mass appeal. But there must be a "commercial" (more features/quality for less $) reason for this type of movement?
That's a nice idea.
I see the ReaderT pattern as a supplement to the mtl-style. I use mtl-style for all the business logic I care about. But the ReaderT pattern is used as the base monad for my implementation of my mtl-style classes. I basically try to abstract the ReaderT stuff away completely. And whenever reasonable, it's preferable to e.g. implement a stateful effect by stacking another StateT on top rather than adding an IORef to the ReaderT environment. It's often *not* reasonable to do this; sometimes state needs to be handled more durably, in which case StateT is not the right choice. But avoiding the use of the lower level IO-based solutions that ReaderT pattern encourages is typically good whenever it's reasonable.
* /u/Pijul_org hasn't made a post in a year * /r/pijul/ hasn't had a post in that long * https://nest.pijul.com/pijul_org/pijul is empty and `pijul clone https://nest.pijul.com/pijul_org/pijul` creates an empty directory &gt; I think Pijul is now considered to be the way of the future for patch-based version control by most people. Are you sure about that? Because right now it looks like abandon-ware.
Please report back how this goes! It would be really interesting to find out.
woah, it does look like a limited, specialized to `m ()`, `wrap` of `MonadFree`.
FYI, I think `wrap` and `interpret` are equivalent. wrap = join . interpret interpret = wrap . fmap return or something like that.
hgeometry looks easy enough to fix up. I suggest you `cabal fetch` it and just fix the errors (which look related to the introduction of some new stuff to a few base modules -- see https://ghc.haskell.org/trac/ghc/wiki/Migration for tips). Ditto with cglib. e.g. for the first, change `import Data.Semigroup.Foldable` to import Data.Semigroup.Foldable hiding (nonempty)` and for cglib add `import Prelude hiding ((&lt;*&gt;))`
Neat! you should consider porting it over to https://wiki.haskell.org/Haskell_in_industry as well
updated. @Wizek - what do you do for a living ? Just curious as to how one can work with haskell for long time as i find it hard to find commercial haskell works.
Oh crap, I was not aware. Can you shoot me an email with what's failing? I'll fix it as soon as I have time.
https://stackoverflow.blog/2017/09/06/incredible-growth-python/
I've heard echoed many times over that Arch's custom Haskell management should be avoided, as it has a variety of problems that the maintainers refuse to acknowledge. I'd recommend downloading either Stack or GHC+cabal-install manually.
Give me two tickets, please :) I will be happy to collaborate with any person but It will be better if you have some pairing experience (because I don't have such experience). 1. What's your time availability? UTC+10 VLAT 9am - 12pm I have a very flexible schedule and generally, I am available at any time during my day. From time to time I have activities which can't be rescheduled but most of the time it's easy for me to be available. But due to my time zone, it can be hard to connect with people from Europe or America. Australia, Japan, China, and India are much easier. 2. What's your Haskell level of experience, roughly? I am a beginner haskeller who is trying to pass "mythical middle level" which every Haskell programmer somehow passes without speaking much about it :) Before that, I've been programming with different popular languages including C++ and Java. I am quite comfortable with basic everyday constructs (i.e. Monoid .. Monad, typeclasses, ADT, basic lenses, basics of streaming libraries and I had several chances to apply profiling tools). I didn't touch type-level programming (including GADT). 3. What topics or codebases are you interested in? Anything goes. As long as it's Haskell, I'm in :) But I don't have experience with pair programming. I mean at my previous job we did short "uni-directional" sessions when you come to help a newbie, or you are a newbie and someone helps you. But we were never meant to actually develop stuff together. Also, I have thoughts about tasks planning and knowledge organizing using plain text files (emacs ord-mode, etc...). So if someone wants to start a small silly project, or want to work with existing tools, that will be interesting for me. 
If you just want the ndth fib, you can do the matrix trick for O(log n) goodness. You can think of fib being the iteration of ```step (a, b) = (a+b, a)``` with a = 1 and b = 1 for the start state. (Eg. the fourth fib is ```snd . step . step . step . step (1, 1)```) Now the function step can also be written as: ```0 1 times b 1 1 a``` Where a+b lands in the lower component of the output vector and a lands in the upper one. And because matrix multiplication is associative, we can say: (m * (m * v)) = (m * m) * v = m² * v And so the ndth fib becomes: m^n * v where m is our matrix and v is the 1, 1 -column vector. And we can build m ^ n quickly (log n) for any powers of two up to and including n as m^2k = m^k * m^k. Then, if we want a fib for an index that is not a power of two, we can multiply up matrices according to the binary representation of the power. Eg m^45 (where 45 is 101101, most significant first) becomes m^32 * m^8 * m^4 * m^1.
Hi! I've tried by bumping the LTS version to one based on GHC 8.0 and GHC 8.2, but the relevant version of `template-haskell` must have changed the API so things break at that stage and I'm not experienced with TH enough to fix it. I'll file a proper issue ticket asap. Thanks!
SO if you add the StateT on top (which is actually what I have now with the `StateT ApplicationGlobals a`), would you suggest then implementing the typeclasses targetting that class instead (rather than ReaderT)? 
Huh? I'm not suggesting replacing the ReaderT pattern. Again, I see it as a supplement. Every application is going to run concretely on some monad transformer stack. My point is that I would write business logic in terms of mtl-style classes that then get implemented via instances on this transformer stack. Some of these mtl-style classes may be implemented in terms of adding a StateT over the ReaderT pattern, some may be implemented in terms of the ReaderT pattern directly.
I dunno. I don't think I'd be encouraging beginners to use IO to solve all their problems. If they're trying to write pure code, I think it's better for them to learn ST than it is for them to learn to throw out purity at the first sign of danger.
Could you please summarize some info for us? I mean contacting each other is great but it is O(n^2)! Yes, it is small for the current number of participants but still requires some repetition :) 
I know at least the library `transformers` uses Darcs.
[removed]
My assumptions regarding contiguousness were based on observations from a very simple experiment wherein I simply separated the last row in it's own function and added a threadDelay, experimenting with different buffer sizes and delays. For a one second buffer, a value was printed every second as long as the delay was smaller than that, which I interpret as there being no underflow, nor any skipped samples. For a longer delay, intermittently making some noise in front of the microphone, the noise was still detected, but it was delayed in proportion to the time since the program started, which I interpret as a growing backlog and no skipping. I could be wrong in my assumptions, however. Real time and low level stuff is not my strong suit (I come from a signal processing background). As for TBQueue and forkIO, that is indeed what I went for after a brief foray exploring the problem in Rust.
I have the exact same problem but haven't figured out a nice solution. I found this post from years ago though that implements a Hakyll Agda compiler so you might be able to adapt their code: https://mazzo.li/posts/agda-hakyll.html
So you eventually *do* launch missiles in Haskell.
Yeah, that's not what I was suggesting either -- you were saying to use a `StateT` on top rather than adding an `IORef` (or `TVar`) to the ReaderT -- in keeping with the mtl-style, that means that instance classes representing functionality should be created around that stack, no? So for me since I already have `StateT` wrapped around a thing the next thing would be writing something like: class EntityManager m s where createEntity :: DBEntity -&gt; m s instance EntityManager (StateT ApplicationGlobals m) where createEntity = ...
Godamn monads.
Which infos would you like summerized? I like your group chat idea, gitter, discourse or something similar could be nice there! A small and sensible potential next step. Feel free to set something up, if you wish. (I have limited internet access for a few hours likely.)
Sounds good; I hope to get back to you soon.
Well, as with all things, it just depends. There will be some state that you want in IORefs, and there will be some state that you don't. However, I would not typically do mtl-style with a `StateT ApplicationGlobals` type. mtl-style says that each class gets one transformer. So I'd do something like: class EntityManager m s | m -&gt; s where createEntity :: DBEntity -&gt; m s newtype EntityManagerT s m a = EntityManagerT { unEntityManagerT :: StateT s m a } deriving (Functor, Applicative, Monad) instance EntityManager (EntityManagerT s m) s where createEntity e = EntityManagerT $ do .... Though DB state is something I'd typically put in an IORef, since you probably want that state to be durable. But basically, you don't choose your stack then write instances over it: You choose the classes you need and construct a stack around them, preferably with one transformer per class. That's what is meant by "mtl-style."
How much experience are you guys expecting ? Senior devs or?
I had considered vectors (of vectors) to make the sudoku grid. I would need to unfreeze the inner vectors and the outer vector to manipulate them.
Yea. If you want to perform IO between mutations, your options are 1) Use an array type like Vector that has freezing/thawing and thawing it out every time you want to run a mutable algorithm on it, 2) Just use IO arrays and ditch ST for IO, and 3) Use the pure API of `vector` to modify vectors without a monad, which may not be suitable for your algorithm.
Can you add the newsletter and chat links here?
On Arch Linux, use Stack.
I use it. :)
I'm interested! 1- I'm available at any time this week. We can even schedule a session right now. 2- I started learning Haskell since about 2012. But it's been more of a on/off kinda thing. 3- I'm open to pairing on any project/codebase.
https://wiki.archlinux.org/index.php/Haskell#Problems_with_linking Don't rely on Arch for Haskell.
Can we schedule a session in about an hour?
If I'm unsure about typing, I usually load my file into ghci. That way I can quickly see if anything I've written doesn't typecheck, and I can use :t to check the type of something I'm unsure about. 
The code is in pijul-0.10 for an embarrassing reason. Also they rewrote it in rust from ocaml and deleted their benchmarks page. But the math is sound and the benchmarks of the ocaml version were faster than git.
LotR reference - Anduril is the name of the sword the elves made for Aragorn from the shards of Narsil
Very nice! thank you
Great, thanks!
I would suggest that improvements in C++ probably invalidate anything referring to requires LoCs etc. for that language. That language is also quite a bit less error prone than it once was if you use the new stuff.
I added contacts for instant messangers to my Reddit profile. It is more robust way to reach me.
Baby killers in MY /r/haskell?
Note that with `-fno-code` you don't see pattern inexhaustiveness warnings. I don't use it much for that reason.
I have (probably relevant) experience from the language exchange website. Finding partner and organizing meeting takes a lot of time. Two things help a lot: filled profiles, because one can know information about a person before contacting them (it seems that you already defined the standard for profiles). And people with many friends (aka super-connectors), they can recommend you to a friend. I made my comment because I assumed that you obtained a lot of requests and you can help with recommendations or you can somehow organize the community. I think gitter should work, but I can't create the channel until tomorrow. I saw people on twitter talking that they are ready to become someone's mentors and to help others. I am wondering if it possible to somehow connect your idea with their abilities. I am also wondering about collaboration software. Will simple desktop sharing via skype work well?
&gt; Consequently any expression mentioning `x` can be said to have also multiplicity 1. Even though multiplicity for exepressions is not defined in the paper, I find it's useful to think like this. That makes sense. Inside the scope of `f`, any expression containing `x` must appear exactly once since `f` is linear. &gt; By using this property, the types of the `MArray` API ensure that `MArray`s will never be shared. This is not in general the case, even for linear functions. Indeed, even assuming `f :: Int ⊸ Int`, if `y` has multiplicity &gt; 1, then `f y` cannot mutate its argument, because `y` can be shared. This is true, but if we want to optimize e.g. `f . f . f . f . f . f` we can simply wait mutating `y` until after having applied `f` a single time, after which a copy of `y` should exist (the result of applying `f` to `y`), which we can safely do in-place updates on for the remaining applications of `f`, since we've made a copy for `f` and `f` is linear. For example, if we use an API that's compatible with standard, immutable Haskell arrays (e.g. `Data.Vector`): type Array a newArray :: Int → Array a write :: Array a ⊸ (Int, a) → Array a read' :: Array a ⊸ Int → a and use it like so: main :: IO () main = do n &lt;- readLn intPairs &lt;- strLinePairs &lt;$&gt; getContents let initArray = newArray n finalArray = foldl write initArray intPairs forM_ [0..n-1] (print . read' finalArray) -- | Convert a string of the form "n m" (where n and m are integers) -- into a pair of integers strIntPair :: String -&gt; (Int,Int) strIntPair lineStr = let (p,q) = span (/= ' ') lineStr in (read p, read $ drop 1 q) -- | Convert a multiple-line string into multiple pairs of integers strLinePairs :: String -&gt; [(Int,Int)] strLinePairs = map strIntPair . lines then GHC would need to, for the first iteration of `write` in `foldl`, create a copy of the array since -- as you mention -- it might be shared by other expressions in `main`. But after this copy has been made, the remaining iterations of the `foldl`-loop can do in-place updates to this copy, since **a)** GHC will know that this copy isn't present in any other thunks (since it made the copy itself) and **b)** that `write` is linear with respect to `Array a`. If `n=1000000` then GHC's memory manager avoids making 999999 copies of the array (where each copy takes time proportional to `n`), by instead doing in-place updates of the array copy inside the `foldl write`-loop. This optimization is highly useful because **a)** it can be applied to most existing code, without the code in question needing to adopt a new array API, and **b)** it reduces time complexity from O(n^(2)) to O(n) (due to the GHC memory manager avoiding a copy operation that takes time proportional to `n` for each `write`).
The following trac tickets suggest this may be fixed in 8.4: https://ghc.haskell.org/trac/ghc/ticket/14954 https://ghc.haskell.org/trac/ghc/ticket/10600 
There's nothing wrong with using `-fno-code` first to flush out most type errors followed by a full build to do the rest :)
Not sure what your use case is but you might be interested in this: https://github.com/ndmitchell/ghcid It is basically a daemon that watches your code and runs just the ghc typechecker when it changes. 
Besides, back when it was announced they mentioned Pijul's IP is owned by the university they created it at. Not sure if that has changed in the meantime, but that can be a problem for an open source project. I can't find it right now but hope that has been fixed.
Reducing transaction overheads undermines the purpose of finance?
Template haskell doesn't work either.
As a sidenote: Does anyone have recommendations for alternative distros with a similar flavor to Arch? I'm really sick of this Haskell shit, but I really love Arch aside from how they deal with Haskell. :( 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [yesodweb/yesod-scaffold/.../**7eb34cccb97af04e76094c7a910d48de60e7ed87** (master → 7eb34cc)](https://github.com/yesodweb/yesod-scaffold/tree/7eb34cccb97af04e76094c7a910d48de60e7ed87) ---- 
I use with [Fames](https://github.com/maxigit/Fames) to enhance [Front Accounting](http://frontaccounting.com/)...
That’s a somewhat misleading statement. Most common usages of TH would be calling a library such as ‘lens’’s ‘makeLenses’, which would usually be installed normally where just the user code is checked with ‘-fno-code’. These common cases work perfectly fine.
What exactly is your problem with how you're currently structuring it? It seems fine to me.
Yes, ghci is even more life-improving than `-fno-code` :)
I've had good success with using pair programming as a sort of "forcing function" to drive me to complete a bunch of tasks that would otherwise sit in my back burner for a long time. I'm opening to trying the experiment on the internet at broad. I've been debating about that or doing live streams or something to serve the same purpose, as it'd force me to set aside a fixed time window to work on these things. 1.) I have pretty good availability on the weekends. 2.) I know Haskell, uh.. reasonably well. =) 3.) There's a pretty broad cross-section of projects I have in the air, so he's what I have that seems to make sense to pair on off the top of my head, ranked in terms of immediacy: In the short term I'm interested in releasing a bunch of packages for unpacked containers abusing backpack. That stuff I could probably pair with anybody who is interested in backpack and knows the general cut of `containers`, `unordered-containers`, etc. It is mostly syntactic work and packaging. This would be of fairly general applicability because most of the time when somebody imports `Set` or `HashSet` or `Map` in a module they go to use it at one type anyways. Getting an across-the-board improvement in memory locality and footprint seems like a no-brainer. I'm also interested in chewing down the backlog of issues in my current package set. If you have an issue you'd like to get fixed in something I maintain, feel free to reach out. I'm also interested in sitting down and playing with QuantifiedConstraints, but for that I'd probably want to pair with someone already well acquainted with the previous hask projects, etc. This has a bit of a higher level of activation because it means I'd have to actually build the appropriate ghc branch, myself, so it'd have a fairly slow start. I also have a bunch of more formative work I'm doing on a toy compiler project. This may involve a lot more flailing. If you're familiar with bidirectional typechecking, dependent types and what not this may be a place where pairing makes sense.
interesting article. i was (except for the haskell remark) talking about the investment in new languages though. 
&gt; Well, but this is not implemented yet. It means that users don't have such feature if they use parser combinators in April 4th, 2018. It isn't so much that it isn't implemented yet. It was implemented in 1996. It is more that nobody has bothered to reimplement it since in a consumable fashion. =)
You can use [my library for modeling Redis-backed data](https://github.com/identicalsnowflake/hlrdb), but I should be clear - the type safety is for modeling the algebraic structure of your data model and ensuring you talk to Redis in sane ways (e.g., that you don't conflate which kinds of values are stored for a key); it does *not* provide any data consistency guarantees on top of what Redis itself provides - for example, Redis is known to go into split brain and have problems with inconsistent histories if you start flipping off lots of nodes in your cluster. Anyway, I made it for myself and I like it, so... yeah. I recommend it ;)
The last question is easy to answer: &gt; Will simple desktop sharing via skype work well? If you are just sharing the screen with Skype that's less then ideal, since then the remote partner can only say things and cannot type when they want to. However, I've had quite good experience using TeamViewer where the host can choose to allow remote mouse+keyboard access. &gt; I have (probably relevant) experience from the language exchange website. Which site is that, could you share a link? Sounds relevant indeed. &gt; Finding partner and organizing meeting takes a lot of time. Yup, I think I'm also experiencing this now, have been getting a bit overwhelmed with the amount of notifications to deal with. But I'd much rather have this problem than no messages. So I'm also taking a bit of respite, and taking my time to send responses in a cadence that feels comfortable and not stressful. I think eventually I'll get back to everyone. &gt; I made my comment because I assumed that you obtained a lot of requests and you can help with recommendations or you can somehow organize the community. I'm definitely interested in helping/organizing the community to some extent. And at the same time a main focus for me is finding a few people with whom we like each other enough that we'll want regular sessions at least between ourselves. However, most of the requests that I've gotten were actually in the comments so far, available for all to read. In that sense your wish is already reality, anyone can contact based on that public ('profile') info. &gt; I think gitter should work, but I can't create the channel until tomorrow. I'm okay with that. &gt; I saw people on twitter talking that they are ready to become someone's mentors and to help others. I am wondering if it possible to somehow connect your idea with their abilities. Feel free to direct them here if you wish. Sounds like there could be quite fruitful connection between them and the people who've commented here. &gt; Two things help a lot: filled profiles, because one can know information about a person before contacting them (it seems that you already defined the standard for profiles). Yes, I'm quite satisfied with the questions and the answer so far. I urge everyone who is interested to submit a comment with those answers and we can consider that to be the profile that you mention. &gt; And people with many friends (aka super-connectors), they can recommend you to a friend. I don't think I can consider myself being in this category yet, especially since as I mentioned most of the info is public. But with time these people might come forward or emerge from these initiatives, and that could be nice indeed.
We're looking for engineers at all levels; we have a few new college grads, and we have a few engineers with 20+ years of experience.
Can confirm. My life is improved markedly when I never have to run my code.
[removed]
I never ran it anyway, but at least I don't have to compile it anymore.
Hey. Your comment won't be seen since this post was automatically removed, and has a lot of problems. It might be best for you to ask this question in the "Hask Anything" pinned post, actually, since the post is ideal for simple beginner questions. 😊 
Ben's Instagram where you can get regular updates on his work. https://www.instagram.com/bendotk/
Are you familiar with the spineless, tagless G machine (STG machine)? That's the VM that Core gets compiled to, and then compiled into efficient assembly/machine code. There's no reason you couldn't interpret STG directly, but it'd be much slower.
I don't think another distro is the solution. I think it makes sense to treat the compiler as a dependency of your project, and having a tool around that is able to switch between such environments(`stack`). This means that installing it directly via the package manager doesn't really make much sense anyway. If you're having issues with Arch and Haskell, see [my earlier comment about it](https://www.reddit.com/r/haskell/comments/7octd9/setup_haskell_environment_on_arch/ds8lptj/). If you do the thing with the `$PATH`, then you'll always have a `ghc` and `ghci` available in your terminal without going through `stack ghc/i`. If a new version comes out, you just need to update the global stack project file with a new snapshot and run `stack setup` again. I think those guidelines are still good, but if they aren't, just let me know and we can probably get you sorted.
There are decent [cassandra bindings](https://hackage.haskell.org/package/cql-io) I was pleased with last time I needed something of the nosql flavor.
What happens when you try to run what you have? [ putStr (replicate x '*') | x &lt;- (read str :: [Int]) ] I don't think that `read` is needed, `str` is already a `[Int]` isn't it?
str is an IO[Int] right? ill take out the read part and just put str and tell you the output
 * Couldn't match expected type `()' with actual type `IO ()' * In the expression: putStr (replicate x '*') In a stmt of a 'do' block: [putStr (replicate x '*') | x &lt;- str] In the expression: do str &lt;- createList [putStr (replicate x '*') | x &lt;- str] | 5 | [ putStr (replicate x '*') | x &lt;- str ] 
My original way this is the output: * Couldn't match type `Int' with `Char' Expected type: String Actual type: [Int]
This is a great little demonstration. The higher-kinded data techniques developed in this blog post have also been extensively elaborated in the [vinyl](https://hackage.haskell.org/package/vinyl) package, which provides performant lenses. A few years back, before `inspection-testing` was around, I proved the same property discussed in this blog post for `vinyl`'s lenses. The [vinyl tutorial](https://hackage.haskell.org/package/vinyl-0.8.1.1/docs/Data-Vinyl-Tutorial-Overview.html) gives a bit of coverage of the use of interpretation functors.
Gentoo has a very good Haskell ecosystem - see https://github.com/gentoo-haskell But of course since it's a source based distribution it comes with its own set of drawbacks ;)
Such a nice looking library. Really simple to follow. Great job. Will try it out now :)
Will this be available via stack any time soon?
No better way to guarantee the absence of side effects!
Darcs and git both have a kind of graph, but they are of different things, and this has a big impact on how you approach version control. In git, the nodes are snapshots of the tree, and the edges are diffs. At any point, your pristine working copy is derived from one of these nodes. In Darcs, the nodes are diffs, and the edges are dependencies. At any point, your pristine working copy is derived from a set of these nodes, respecting dependencies. The dependencies are usually just textual, but can also be added explicitly to represent semantic dependencies. This model allows you to cherry pick patches from other repos independently of their chronological ordering as long as you also bring along their dependencies. Reordering patches does not in general change their identities. This is great because it means I can cherry pick somebody's bug fix even if they had written it on top of some other changes I don't want yet, unless the bug fix depends on their other changes. This will not introduce incompatibilities or duplicate patches when I pull the rest later. I can even "unpull" stuff I had applied earlier if I decide I didn't want it, even if I had applied other changes since then, unless I did something dependent on the thing I don't want anymore. 
That's brilliant, thanks for sharing!
The fun part is that it generalizes: for any f a b c d ... n = k1a + k2b + ... + knn, you can write a matrix with a diagonal "transport layer" of ones that routes your older layers around and some set of weights. (And you can of course express many other things as matrices)
I did not receive a reply, and the FAQ has not been updated. For the Qualification Round this weekend, I believe penalties don't matter, as you are trying to achieve a minimum score, so it is another opportunity to experiment with what is available. But my go-to guess for libraries is what I posed above.
Yeah, basically. Virtual machines are 10-100x slower and to get closer to the left side of that range they usually use techniques that hinder maintainance like rolling the routines in assembler so that the machine registers can be mapped manually (ie rcx = instruction pointer and such).
On the idea of alternative VMs, I had this idea years ago to run VMs at near-native speed without using a JIT. Some assembly knowledge required and comparison to luajit generated code included. https://gist.github.com/donkeybonks/3c3421d9a804851150fa
This blog post [A Game in Haskell - Dino Rush](http://jxv.io/blog/2018-02-28-A-Game-in-Haskell.html) might be able to help you. He goes through the whole architecture in quite detail, and all the [source is up on github](https://github.com/jxv/dino-rush).
We put this list together years ago that was supposed to include all companies applying Haskell commercially: https://github.com/commercialhaskell/commercialhaskell We use Haskell for K-12 education technology at Front Row - http://tech.frontrowed.com/
you're using lenses, but you're barely tapping into their full power! Here's `updatePositions` as you currently have it: updatePosition :: GameState -&gt; Int -&gt; (Float, Float) -&gt; GameState updatePosition game playerIndex position' = game' where game' = Game{ players = (element playerIndex .~ Player {graphicalComponents = graphicalComponents (players game !! playerIndex) ,position = position' ,velocity = velocity (players game !! playerIndex) ,acceleration = acceleration (players game !! playerIndex) }) (players game)} And here it is, with a bit more lens magic: updatePositionLensy :: Int -&gt; (Float, Float) -&gt; GameState -&gt; GameState updatePositionLensy i newPosition = players . ix i . position .~ newPosition (when the lenses are defined, anyway)
I would personally try to debug those issues, the LMDB API is quite low-level, you can ask for help on its IRC channel or mailing list. But I have not experience using the Haskell bindings. Just to give you a bit of context, on my day job at an internet company, we run a system of several thousands or servers running a distributed storage system on top of LMDB writing a lot. We need an ACID, corruption-free and fast data store, LMDB is one of the best if not the best (I know its code base is ugly...).
[Weever Apps](https://weeverapps.com/) is starting to get its feet wet with Haskell in information management that helps manufacturing companies reach their World Class Manufacturing compliance goals. Our newest product is being developed in Haskell that will help companies in certain regulated industries meet their compliance goals while being able to take action on the data flowing through the manufacturing process in near-real time.
I just made an unsafecompiler that runs bower and pulp and doesn't handle errors at all. It's terrible when the purescript code is broken but most of the time I'm not changing that stuff. Code is here: https://github.com/maxsnew/maxsnew.github.io/blob/src/src/Lib.hs
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [maxsnew/maxsnew.github.io/.../**Lib.hs** (src → 2fbd3eb)](https://github.com/maxsnew/maxsnew.github.io/blob/2fbd3ebd765025b1e2215c3a76715fa542810966/2fbd3ebd765025b1e2215c3a76715fa542810966/Lib.hs) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dww0e6h.)
From what I've read SSH doesn't prompt using stdin/stdout, but rather /dev/tty which perfectly explains the behaviour I was seeing. I did not know about the posix-pty module. I'll look into it. thanks.
Thanks for the suggestion. I'll see if I can track down the example when I get some time.
glorious
Is there any way to get that same performance improvement without the need for backpack? This seems like a rather heavyweight interface for maps and sets relative to the standard way. Very cool to see some real life usage of backpack though.
Template Haskell that spews out exactly the same code? The downside there is you don't get the type checking guarantees that backpack provides. Otherwise, no.
Why is that? That seems like something that could be improved on the GHC side. I don't see a fundamental reason why you should need backpack for that performance, what special thing is going on that regular typeclasses / data families / inline pragmas etc. cant handle?
Backpack here is building completely separate code at each (distinct) instantiation. The entire package is built a-new. This is morally like instantiating a C++ template, not much at all like writing usual Haskell. This duplication of code includes all of the source code, which gets to know the entire `Ord` instance for the `Key` type, and the concrete `Key` type being used. The normal `Data.Set` code is littered with `INLINEABLE` to try to do as much as they can because if the code doesn't get specialized against the particular `Ord` instance, it is horrifically slow. Here you get code and new datatypes built for each template instantiation. You're not relying on `INLINEABLE` to hope that GHC inlines for your call-site, it is definitely being compiled anew. This is different than the usual Haskell polymorphic type story where the same code is being used at different types. SPECIALIZE pragmas can duplicate the functions, but it still doesn't duplicate the types. The old pattern I used to try to use was to build something like a custom data family and view patterns to convert in/out of that form, but then you thrash twice as much memory and lose almost all advantage (usually it is slower.) Note: this isn't a transformation we can expect haskell to do in general, because you can't tie knots through it and the like.
It's heavyweight but not *too* heavyweight. afaict, you create a module/package instead of writing an instance. If the names/types the symbols in your implementation coincide with the symbols in the signature, you can just import it ("mix it in"?) in a single line of a cabal file. 
Does knot-tying require recursive packages (or am I thinking about it at the wrong level)?
Yeah.
This still seems like a failure of GHC to me. I think it's a damn shame we can't expect perfect specialization on certain types / functions / classes. For instance, i *really* hope I'm never passing a runtime Monad dictionary around, as then every line in a `do` block comes with a massive performance overhead. But it's really hard to make sure GHC handles this reliably. Honestly, to me it seems like Backpack is a subpar solution to this glaring issue. I'm sure it's insanely hard to solve correctly for a variety of reasons, but it's one that's always bothered me about Haskell.
How does this compare to "just" using pattern synonyms and a typeclass/data family? Like class IsMap k a where data Map k a _Bin :: Prism' (Map k a) (Size, Key, a, Map k a, Map k a) _Tip :: Prism' (Map k a) () pattern Bin :: IsMap k a =&gt; Size -&gt; Key -&gt; a -&gt; Map k a -&gt; Map k a -&gt; Map k a pattern Tip :: IsMap k a =&gt; Map k a 
Are there some typos in the set.txt benchmarks? I see a Data.IntSet, Unpacked.Set, and Int.Set. Are those all the same thing or is there a difference? (I'm guessing Int.Set is from this package since the string benchmarks use String.Set consistently?) Also, if Data.IntSet isn't from this package, is there any reason why it vastly outperforms even the backpack code? Last question: do you have any guesses as to why the string.set performance improvement isn't as pronounced as the performance difference between Data.IntSet and the others?
I have 4+ year old networking library that used to work fine on cabal and stack (from 7.4 up to at least 8.0). However, I find as the 8.4 series arrives, cabal-based builds no longer pass unit tests, but stack build pass unit tests reliably. Where should I start to debug this?
I love it! If I might bikeshed for just a moment, while $30 a month is absolutely a fair price for access to all content, it's still a good chunk of money. However, might I suggest adding a smaller tier, say $5-10 a month? That could be access to a subset of content, or perhaps only old enough or so on. I know that, for myself, $30 is a lot to commit to for an extended period of time but $10 is much more palatable, even if I'm getting a little less for my money :) I wish you success in this either way! Haskell will definitely benefit from having more high quality resources out there
\&gt;but we're open to other possibilities. I'm pretty sure SpaceX legally can only hire citizens because of their work on defense related infrastructure. Is this not the case for Anduril as well? 
Have you thought about how to make these containers "mappable"? Or is that an acceptable compromise for their use cases?
Back in the stone age (ok, 2009) I wrote a version that did this: http://hackage.haskell.org/package/unboxed-containers But it never really paid out all that well. It seems the GC overhead of smashing things in and out of the views wipes out almost all of the steady state storage benefits of having the Set stored more efficiently. There are some papers that have also noted this same effect, using modules and view functions in ML the overhead of going through the views wipes out most if not all of the benefits of having more efficient internals.
This is awesome. I'm also pretty happy to see that we can put Backpack signatures / modules on Hackage now. Very much looking forward to being able to make use of whatever new techniques folks come with using this stuff.
For right now it is the core compromise. You _can_ make another module that provides the 'map' function that is parameterized on two of the base module type. This is the approach I've been exploring to try to make something like `linear` work, where I need several `V3`-like types, and `V3`s of `V3`s of `Quaternions` of `Floats` and the like.
I'm not sure exactly what sort of constraints SpaceX is operating under. As for Anduril, there should be no problems for anyone eligible to work in the United States. For any other situation, if you shoot me an email (travis@anduril.io) I can connect you with someone who actually knows about whatever processes are relevant.
&gt; IntSet is faster for Int, which is why we provide it from `containers`. =) Is it possible for backpack to allow for an IntSet like implementation to be written for an int type? I guess I'm just still a little fuzzy on the limits of what's possible with something like backpack &gt; String.Set gets no benefit because String doesn't {-# UNPACK #-} Ooh, doh, makes sense :)
It's sad that in Arch, a distro that comes with official support for so many packages, I have to avoid pacman and such when it comes to Haskell. Thanks for the info.
I don't know much about Arch, but the Arch wiki is a place I often go to figure stuff out for NixOS. I think they come with similar out-of-the-box behavior, and the main difference is just the package management and NixOS's declarative, modular configuration system.
This is cool. Having some trouble trying it out: https://github.com/lambdageek/shared-int (Full log at link above, but here's the short end of it). I don't think I'm doing anything stupid, but, well: ``` Configuring unpacked-containers-0 (lib)... Failed to build unpacked-containers-0. The failure occurred during the configure step. Build log ( /home/aleksey/.cabal/logs/ghc-8.2.2/unpacked-containers-0-aa56a1a32420cfa1ce501fbe46ba3238af8caa0462581dffc7aab8105a793ff1+B8WAiKVLOIOIniFj9VOY1u.log ): Configuring library instantiated with Key = shared-int-0.0.0.1-inplace-fin10-key:Fin10Key for unpacked-containers-0.. Error: The following packages are broken because other packages they depend on are missing. These broken packages must be rebuilt before they can be used. planned package unpacked-containers-0 is broken due to missing package shared-int-0.0.0.1-inplace-fin10-key cabal: Failed to build unpacked-containers-0 (which is required by shared-int-0.0.0.1). See the build log above for details. ```
Are cabal and stack pulling in different versions of dependencies?
 You have two separate `Fin10Key`s. The one you want, which is a part of `fin10-key`, and the one you don't which is being compiled because the `Fin10Key.hs` file is in a directory that external `shared-int` library is looking through for source. The fix is easy enough. Make a `keys` sub-dir, or some other name, throw your `Fin10Key.hs` file in there and add library fin10-key hs-source-dirs: keys so that the internal library `fin10-key` can find it, but the code for the unnamed `shared-int` external library doesn't find the source file, and so has to take it out of the dependency rather than trying to compile it itself.
Here it is: https://hackage.haskell.org/package/nn
Full abstract: &gt; The λ-calculus is popular as an intermediate language for practical compilers. But in the world of logic it has a lesser-known twin, born at the same time, called the sequent calculus. Perhaps that would make for a good intermediate language, too? To explore this question we designed Sequent Core, a practically-oriented core calculus based on the sequent calculus, and used it to re-implement a substantial chunk of the Glasgow Haskell Compiler.
For those who want to know more about the sequent calculus: https://en.m.wikipedia.org/wiki/Sequent_calculus
Non-Mobile link: https://en.wikipedia.org/wiki/Sequent_calculus *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^168355
**Sequent calculus** Sequent calculus is, in essence, a style of formal logical argumentation where every line of a proof is a conditional tautology (called a sequent by Gerhard Gentzen) instead of an unconditional tautology. Each conditional tautology is inferred from other conditional tautologies on earlier lines in a formal argument according to rules and procedures of inference, giving a better approximation to the style of natural deduction used by mathematicians than David Hilbert's earlier style of formal logic where every line was an unconditional tautology. There may be more subtle distinctions to be made; for example, there may be non-logical axioms upon which all propositions are implicitly dependent. Then sequents signify conditional theorems in a first-order language rather than conditional tautologies. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/haskell/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Fantastic -- I'll check it out. Thanks!
Thanks! The readme looks interesting, the API seems simple, I'll take a look
My issue with LMDB has been documentation so far, so the IRC channel is something that could help and I didn't consider yet, thank you :) LMDB seems to be the industry standard for building what I am building right now (a cryptocurrency node implementation), it just didn't seem to be so well established in the haskell ecosystem yet, but maybe I got frustrated too quickly.
Thank you, isovector, for voting on HelperBot\_. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://goodbot-badbot.herokuapp.com/). *** ^^Even ^^if ^^I ^^don't ^^reply ^^to ^^your ^^comment, ^^I'm ^^still ^^listening ^^for ^^votes. ^^Check ^^the ^^webpage ^^to ^^see ^^if ^^your ^^vote ^^registered!
Cassandra looks interesting as a load-balancing database engine, but is not quite what I'm looking for.
Ok the difference is that even though in theory I can I convert snapshot to diff and vice versa, if i apply an existing diff to a new snapshot, I get a new snapshot and therefore a new commit in vitro whereas darcs will see both commit as the same patch. Am I right ? I can see indeed some advantages but nothing which will change my day to day life and is worth losing access to the guy eco-system (editor plugins, GitHub, resources etc)
&gt; Which site is that, could you share a link? Sounds relevant indeed. I've been using italki.com for 2 years. Here is [my page](https://www.italki.com/user/3668827). &gt; I'm definitely interested in helping/organizing the community to some extent I checked gitter, slack, discord and only slack has some very limited notion of user profiles. One geeky solution is to create a GitHub repo and to maintain a page [like this](https://gist.github.com/kevroletin/99103f3de1f9c3b89bc1666fe62595e2) (It can be markdown, I choice org-mode out of habit).
good bot
good bot
I've created a repo based on your gist here and also invited you to have collaborative permissions: https://github.com/Wizek/haskell-pair-programming
**Good human**. \\ (•◡•) / I shouldn’t spoil this…but, remember how I am going to live forever, but you’re going to be dead in 60 years? Well, I’ve been working on a present for you. Well, I guess it’s more of a medical procedure. Well, technically it’s more of a medical experiment. You know how excruciating it is when someone removes all of your bone marrow? Well, what if AFTER I did that, I put something back in… that added 4 years to your life? *** ^^^I'm&amp;#32;a&amp;#32;Bot&amp;#32;*bleep*&amp;#32;*bloop*&amp;#32;|&amp;#32;[&amp;#32;**Block**&amp;#32;**me**](https://np.reddit.com/message/compose?to=friendly-bot&amp;subject=stop&amp;message=If%20you%20would%20like%20to%20stop%20seeing%20this%20bot%27s%20comments%2C%20send%20this%20private%20message%20with%20the%20subject%20%27stop%27.%20)&amp;#32;|&amp;#32;[**T҉he̛&amp;#32;L̨is̕t**](https://np.reddit.com/r/friendlybot/wiki/index)&amp;#32;|&amp;#32;[❤️](https://np.reddit.com/r/friendlybot/comments/7hrupo/suggestions)
All right. I can summarize contact from that thread and create a GitHub repo. Which IM messenger should we choose? I don't use IRC, Discord, Slack or Gitter on a daily basis. 
bad bot
I take that as a yes. Prepare to be collected tomorrow at 3:52 p.m. Don't forget to bring your bones. *** ^^^I'm&amp;#32;a&amp;#32;Bot&amp;#32;*bleep*&amp;#32;*bloop*&amp;#32;|&amp;#32;[&amp;#32;**Block**&amp;#32;**me**](https://np.reddit.com/message/compose?to=friendly-bot&amp;subject=stop&amp;message=If%20you%20would%20like%20to%20stop%20seeing%20this%20bot%27s%20comments%2C%20send%20this%20private%20message%20with%20the%20subject%20%27stop%27.%20)&amp;#32;|&amp;#32;[**T҉he̛&amp;#32;L̨is̕t**](https://np.reddit.com/r/friendlybot/wiki/index)&amp;#32;|&amp;#32;[❤️](https://np.reddit.com/r/friendlybot/comments/7hrupo/suggestions)
A few minutes ago I've created a repo based on your gist and also invited you to have collaborative permissions: https://github.com/Wizek/haskell-pair-programming Have you seen the invite? If not you may find it here: https://github.com/Wizek/haskell-pair-programming/invitations I've also created a Gitter chatroom as that seemed like the simplest choice to begin with, and we can change it later if we want to: https://gitter.im/haskell-pair-programming/Lobby#
I've used [rocksdb-haskell](https://hackage.haskell.org/package/rocksdb-haskell) in few toy programs, worked great. Their issue tracker reports some problems with memory leaks, but the bindings are relatively simple so maybe you could try that out and fix the issues there.
Oh couldn't find it. My project isn't picking it up though: In the dependencies for nn-test-0.1.0.0: nn must match -any, but the stack configuration has no specified version (latest matching version is 0.2.0) needed since nn-test is a build target. Some potential ways to resolve this: * Recommended action: try adding the following to your extra-deps in D:\src\nn-test\stack.yaml: - nn-0.2.0 * Set 'allow-newer: true' to ignore all version constraints and build anyway. * You may also want to try using the 'stack solver' command. 
Groq ?! Their website has barely any content apart from a couple graphs and diagrams. I'd be super interested in knowing more.
In case anyone else needs a reminder what's unpackable: https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#unpack-pragma
You got an answer about how to use lenses already, but even without lens you don't need to refer to all keys in a record: data MyRec = MyRec { field1 :: Int , field2 :: String } myRec1 = MyRec { field1=42 , field2="foo" } fld2Val = field2 myRec1 myRec2 = myRec1 { field2="bar" } As you can see, you only need to refer to the fields you're accessing. Other exising ones are just taken for the ride anonymously. 
Use more than one git remote, could you expand on this please? 
[LevelDB](https://hackage.haskell.org/package/leveldb-haskell) is quite amazing. I recently gave a [talk](https://youtu.be/gR8LdlrEFnM?t=54m26s) for which I needed a very simple cache and leveldb worked out of the box. I've used LMDB a lot and I feel your pain!
Nice! The documentation looks good, I'll definitely give this a try :)
&gt; PC can't handle left-recursive grammars (though, there's some article¹...). There is [another article](http://hackage.haskell.org/package/grammatical-parsers-0.3/grammatical-parsers-0.3/src../Grampa.lhs.pdf) of mine from the last Haskell Symposium, together with [a library](http://hackage.haskell.org/package/grammatical-parsers) that supports left recursion. The paper provides some more comparisons between the parser combinators and generators, as well as more bibliography. 
Yeah, I think it's clear that the world agrees with you that the tradeoff isn't worth it. I do think it's a bigger deal than it sounds like you think, though. 
Previous submission: https://www.reddit.com/r/haskell/comments/8336bq/generating_artwork_with_haskell/
Value to whom? Certainly not valuable to society. You also claim without evidence that this makes prices more "optimal" which might work if people had perfect information, but this is usually far from the case. Big data operates on a completely different scale than human decision making, and this information asymmetry introduces an entire class of market failures. 
Really great stuff! I wasn't aware of your library. Will read the paper and update my table. Though, I have several questions. 1. Do you think your library is production ready? 2. Can it output good error messages? 3. Are you interested in maintaining it?
Yes, no, yes. The error messages are close to the top of my to-do list, right now all you get is the character position and the list of tokens that were expected there. 
As good as the content maybe, 30 USD/month seems way overpriced. It would feel like buying the same book over and over...
You would be interested in [ticket #14197](https://ghc.haskell.org/trac/ghc/ticket/14917), which as an knock-on consequence, would give you the supercharged version of `INLINEABLE` that you want. However, even with something like this, you're still not going to be able to get around GHC's inability to unpack polymorphic fields into data constructors. You'll need backpack for this.
I think $30 is too much. That's $360/year...and if I just wait a year, I can pay $30 once and just get everything then. It should definitely be a one-time payment or cheaper.
"value to whom?" it does not really matter; because it is good for the economy, hence generally for the society; but if you insist : probably the value of price precision is realized by those people who pay for it, that is by those who are seemingly negative in this "zero sum game" optimization does not have to be perfect in order to have effect i do not see any kind of market failure in "information asymmetry"; the major market failures are lack of competition and externalities; neither of these are induced by "information asymmetry" 
Has anyone got experience with [`haskey`](https://hackage.haskell.org/package/haskey) though? It was last year's Summer of Haskell project and is implemented in pure Haskell instead of bindings to existing KV stores. Looks promising to me.
Alternatively, you can find `stack-bin` in the AUR repos, at leas then stack can be updated with something like aura. But yes, avoid all haskell packages in the arch repos.
I said this elsewhere as a comment, but the best way I've found to use haskell with arch is to install `stack-bin` from the AUR with something like aura / pacaur, etc. At least then the pkg can be updated easily and you don't get all tangled up with dynamic linking.
I am not sure I understand. Is it all about things being not in-lined, when they should? What is some example of code that does not inline, even though it should? ----- It would be lovely, if GHC had a page with known issues (description + multiple examples) and tickets could link to those issues...
Awesome! Its modeled after LMDB, has an in-memory Backend, thats perfect, hopefully will try it out and report my findings :D
I totally forgot about `layers`. Looks like there's still plenty of activity on the git repo, but no releases since 2013. Odd.
I'm interested in hearing more about how you used Haskell for packet analysis if there's anything published or open source. :)
Possible, even likely. Good call. I’ve been afraid there are different options being passed to GHC that are causing this, but this makes sense too.
As I understand it they relaxed it around the cabal 2.2 release, and its just now possible to produce haddocks, etc. so I figured this was a good package to use and a decent time to get things started.
It's not quite that simple, because you'd literally have to compile every module that was making any comparison separately for every type you wanted to make comparisons on if you tried to do that. This does seem to pay out well for performance-centric code that gets used a lot at the same type, though. Here we can know the `Ord` dictionary is always known at all use sites, so the compiler can worker-wrapper around it very easily.
I have a fork of https://github.com/SimplyNaOH/voronoi at https://github.com/bch29/voronoi which completes the missing edges. The reason they are missing in the original is that the core algorithm distinguishes between partial edges (which have one endpoint specified) and full edges (which have both endpoints specified). The original `voronoi` function just omits partial edges. My fork updates that function to calculate the intersection of partial edges with a bounding box, and adds the missing endpoint at that intersection point.
&gt; Hopefully the ergonomics improve a bit so you can release your compiler project thing without having to also upload like 20+ other supporting packages (if I'm remembering the issues behind that project correctly?) [:)](https://github.com/fgaz/gsoc/blob/master/2018/proposal-cabal-multiple-libraries.md)
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [fgaz/gsoc/.../**proposal-cabal-multiple-libraries.md** (master → 40507b3)](https://github.com/fgaz/gsoc/blob/40507b3d5d6f0b6c2702f8518daa6c96e495b9f0/2018/proposal-cabal-multiple-libraries.md) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dwwy273.)
&gt; i do not see any kind of market failure in "information asymmetry" You can't see much when you close your eyes. How do you expect agents in an economy to be perfect decision makers if they aren't aware what information is relevant to the decision? But if you insist, I've got a used car I'd like to sell you. Are you aware of how collateralized debt obligations packaged bad debt with good debt, ignored probability theory, and created a bubble? All of this creating lots of money in the short run (because Black Scholes approximations work up to the 2nd moment, but no further, no skew or kurtosis) but collapsed spectacularly in the long run. Are you saying that this is optimal and efficient? All of this creating overconsumption and then leading to recession? People buying houses they can't afford, then winding up having these houses repossessed, and ending up in a world where there's simultaneously too many homes and too many homeless. You say this is all works out? Price "precision" sounds good in a highly idealistic theory, but price accuracy is what we actually need, and Wall Street certainly isn't helping.
Fair enough—makes sense. I'm also curious if this technique has any use with regards to Data.Sequence? I've attempted a couple times to pull out the finger tree (to see if you could implement your rope idea based on some Data.Sequence.Internal.FingerTree or something), but the specialisations are so fragile it's always ended in failure.
I thought the contravariant article was probably the best one I've read on the topic (small sample size: I probably read three or four back when I was trying to understand and then gain intuition for the topic).
It seems like an overpriced service to me given the wealth of content that’s freely available or at a one-time fixed price. Obviously, the market will make that determination—caveat emptor.
Why `Map` is specialized only for the key and not for the value ? I imagine that unpacked values may also lead to more performances? (At the cost of the `Functor` instance I guess ?)
&gt; What is some example of code that does not inline, even though it should? `vector-algorithms` is another candidate for backpackification like this. Somewhere around GHC 7.4 it dropped an order of magnitude in performance because GHC started failing to fully inline all of the `Ord` dictionaries it was using when GHC internally switched to using some notion of "fuel" to drive inlinings. _All_ of the public API of `Data.Set` and `Data.Map` is set `INLINEABLE` to make it so that the outer wrapper at least can inline at the call site to make as much of the polymorphic use of `Ord` go away as it can. This isn't perfect. Every time there is a `go` inside of a combinator in `Data.Set` that still has an `Ord` constraint, the Ord constraint may well survive optimization, hitting performance badly. e.g. https://github.com/haskell/containers/blob/6dc1087993b9c5ef75ce2909272715edef6e13bb/Data/Set/Internal.hs#L522 See the Note here about this happening: https://github.com/haskell/containers/blob/6dc1087993b9c5ef75ce2909272715edef6e13bb/Data/Set/Internal.hs#L100 
Exhaustion from scraping through 5000 lines of code, and the fact that that needs to be a separate package. This version had the benefit that it didn't require me to be nearly as invasive, so I pushed it out first. I still need to do another package that provides a fully unpacked `Map`. Due to the inability to export more than one public library from a package that will have to be a separate package, though. Then all the functor-like mappings between map types would have to be yet another package that sits atop pairs of instances of that one. I had already written `Set`, so I added `Map` to finish out the first round of this, because it could fit into the same package as it has the same dependency set. `unordered-containers` is also a strong candidate for having this same transformation performed, first keys, then keys and values.
I mean, Treehouse and similar platforms are $25/mo. If the content's good and fairly frequent, it's not really that bad considering how small the team is.
What's 'streaming' like for FRP?
I spent a while trying to fix the errors but I eventually got to "X is not an instance of Y" and some other errors I wasn't able to easily fix.
It just took a few minutes until the haddocks were built.
Truth. I was scratching my head, thinking `cabal sdist` was failing to package the docs into the tarball upload. Turns out Hackage generates the docs directly from the Haskell source, and yeah the delay is annoying (esp when trying to actually use the preview candidate for anything useful), but it's manageable.
Thanks for sharing! When does this land? :)
If you need, you can always upload the haddocks yourself, as written in the last paragraph [here](https://hackage.haskell.org/upload).
I guess this counts as [part 2](https://www.reddit.com/r/haskell/comments/6ksr76/rfc_part_1_deriving_instances_of/) Last ICFP (sponsored by SCB) I was lucky enough to discuss this idea with several people and was encouraged to make a paper out of it. I was excited to do so but not confident that I could complete one on my own. I was told to contact /u/RyanGlScott and long story short: me, Ryan and /u/kosmikus have had weekly(-ish) meetings and now have a [implementation](https://github.com/RyanGlScott/ghc/tree/26b019112d5eba0b4f4c7cba68b218fcd7774f6a) and this paper. Thanks Ryan and Andres. The idea is very simple, generalizes `-XGeneralizedNewtypeDeriving` and only relies on `coerce`. You can derive an instance of a any type `X` if you can find a *via type* with the same instance. The only condition being that the *via type* must have same representation in memory as `X` ([`Coercible ViaType X`](https://hackage.haskell.org/package/base-4.9.0.0/docs/Data-Coerce.html#t:Coercible)) data X = ... deriving Eq via ViaType generates this (`X` need not be a newtype) instance Eq X where (==) = coerce ((==) @ViaType) (/=) = coerce ((/=) @ViaType) To emulate *GND* newtype Age = Age Int deriving (Show, Num) via Int There are a lot of weird and interesting applications, boilerplate begone!
[removed]
In any case, if more people start using LMDB from Haskell, the bindings will get improved and I think that will improve the Haskell ecosystem as having a solid DB library is always a must :)
Where I work, I've made a tool for analyzing and transforming large data sets, which has been in use for several years now. I also prefer to use Haskell for small command line tools, where others would use Python instead.
You might be interested in https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-908.pdf. Or, in an implementation of it, rather.
Patterns are tried in order (that's the semantics), but the complexity doesn't need to be `O(n)` (in all cases). I'm not sure what GHC does, but here are some links to get you started https://stackoverflow.com/questions/9027384/haskell-ghc-what-is-the-time-complexity-of-a-pattern-match-with-n-constructors https://mail.haskell.org/pipermail/beginners/2016-July/017010.html https://www.reddit.com/r/haskell/comments/3fyfmj/constant_time_pattern_matching_and_jump_tables/
I'm surprised that you think you'd never want it. Specialization is a bonus for me, just an implementation detail -- the programming model is much more important. Or do you mean specifically "I'd never want it for the purpose of specializing types", re: this thread's context?
Most browsers don't clear session cookies on close anymore, especially not if they were closed while the site the cookie belonged to is still open. Have you checked your browser to see if it still has the cookie after restarting it? (Note that Chrome's built-in cookie inspector lies and shouldn't be trusted. Either use Firefox or install an extension that doesn't lie.) 
We're currently preparing an accompanying GHC proposal, which we'll submit soon. Barring any unforeseen problems with the proposal, we could have it landed into GHC itself by the next major release (8.6).
Which one of the two are you more interested in fixing up? I could probably take a quick wack at a migration... (edit: of course if you're happy with the voronoi fork which i see below now, it would be even easier for me if i migrated neither :-))
Still, you have to keep order in some way, otherwise some function like: f (Just n) = n f _ = 1 would not work properly depending on the hash function. There must be some way of tracking dependencies between definitions.
try compiling with core output enabled. can give you some insight!
Are we talking mutually recursive packages? 
The voronoi fork is working for now! Thanks for the offer though!
This technique could be used to generalize [streaming-bytestring](http://hackage.haskell.org/package/streaming-bytestring), which provides a monomorphic version of the `Stream` type from [streaming](http://hackage.haskell.org/package/streaming) in which the `ByteString` is unpacked into the constructor. 
I wish there were a stack shortcut for uploading docs rather than having do do it via bash. Something along the lines of `stack upload haddock .` or something
Yeah. Say you wanted a data type like data Trie = Char.Map Trie you could define this using this package by building a mixin that picks `Key` = `Char`, etc. But say we have a more aggressive package that had both `Key` and `Value` unboxed. Then we'd have to define 'Trie' in a package that we then parameterize the the map package on, but the `Trie` itself is defined in terms of the map type from the map package, and we're back in mutually recursive package territory.
You've discovered supercompilation. However, supercompilation is a nightmare to build, and often takes a ridiculous amount of time to compile. You could build a language that did that, but accidental uses of polymorphic recursion would likely cause your compiler to spin forever, or you'd have to give up far too easily when you do anything that hints of polymorphic recursion, or just abort after things get too hard, like happens with c++ templates. You almost always wind up with some sort of awkward defunctionalization step at the end of a supercompiler to deal with crap it couldn't handle, and have to figure out when to stop. The approach GHC takes is far more robust, but not so aggressive.
This. Anyone hired to a Haskell junior/intermediate, even expert position should definitely get their employer to cover this. $30 may seem a little steep for hobbyists, but it's definitely cheap for professionals.
`fromList . map f . toList` seems to me a reasonable idiom for accomplishing this. I'm handwaving this but kind of hoping the intermediate lists can be optimized away. Unless you want [`mapMonotonic`](https://www.stackage.org/haddock/lts-11.3/containers-0.5.10.2/Data-Set.html#v:mapMonotonic) for very special cases which can be extra optimized.
There is a GSoC project to do it. My current `coda` project weighs in at 20+ packages, and needs probably 40 more before its usable, so I feel this pain rather sharply!
You're right. Browsers don't clear session cookies.
I've never used 'treehouse' but these don't look similar at all. Still, I'm happy they are at least trying. But I won't go for it unless the pricing model changes. I loved the original Haskellbook though. btw, what happened to the other Chris that wrote haskellbook.com? Is he not working on this? (not asking you specifically)
I have nothing to do with this, I'm trying to wrap up http://haskellbook.com and then my future stuff will be on http://lorepub.com
Not really. The core is just going to use a case statement, which will raise the same question
&gt; type level programming (`servant`, `opaleye`) Popping into this conversation a bit late to point out that I don't consider Opaleye to involve type-level programming. In fact I'm rather bearish on the promise of type-level programming generally.
Was it just me or did it seem to end rather abruptly?
This is so interesting.
Wait, are ordinary folk allowed to write papers and submit them to conferences? I have a bachelors degree, but I'm not affiliated with a university in any way at the moment, but if I wanted to write a paper on a cool idea one day, could I do that?
We submitted it to the Haskell Symposium. Nobody's stopped me yet
Let me know if protesters show up. But on a more serious note, awesome job! This will be a helpful extension for me.
Why not? 
It will use a jump table if `n` is big enough; the decisions are made in this module https://github.com/ghc/ghc/blob/master/compiler/cmm/CmmSwitch.hs
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [ghc/ghc/.../**CmmSwitch.hs** (master → 875e59d)](https://github.com/ghc/ghc/blob/875e59d37186a997df2cc7d0fdb49ef41d0e31ce/compiler/cmm/CmmSwitch.hs) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dwxmd1g.)
Should be fine now: I've updated [`netlist-to-vhdl`](https://hackage.haskell.org/package/netlist-to-vhdl-0.3.3), [`sized-types`](https://hackage.haskell.org/package/sized-types-0.3.5.2) and [`kansas-lava`](https://hackage.haskell.org/package/kansas-lava-0.2.4.5) itself. 
What happens is that case statements get compiled into a form that is _equivalent_ to having gone through those cases in order. However, in general a much more efficient form is used. Effectively in the back end of the compiler, what is done is that the patterns are compiled into a "pattern matrix" and them optimizations are done on that, to get rid of duplication, check coverage, etc. You might find [this paper](https://pdfs.semanticscholar.org/c0d6/f0225c5140d1528f35d187f070d415f33ed6.pdf) a good introduction to the topic. There are several variations on the theme, but having a _DEFAULT_ branch is a pretty common recurring pattern. As for integers? You probably aren't going to enumerate all of them, so throwing the few fixed cases into a hash table and _DEFAULT_ing the rest is the usual approach. This usually compiles in the same manner a a C++ switch statement at that point.
oy, no ciphertext option yet?
Do you have some references on how that might work/be implemented? My thought would be that --password-command is the general purpose thing here that could fit on most existing secure schemes?
The programming model is pretty much the same as type classes.
For large and dense equations like your example a jump table is used. For functions with few or sparse arguments a binary search is used instead. More complex patterns with eg nesting are first desugared into (possible multiple) simple case expressions which then again end up using binary search or jump tables. The desugaring algorithm for "regular" patterns is described well in SPJ's book "The Implementation of Functional Programming Languages" which is freely available as PDF.
They updated the FAQ, adding the libraries available for each language. For Haskell, it is `package: ghc`.
Shouldn't this in theory be no slower to compile than a backpack system? It's fairly easy to imagine various ways of controlling this like all functions outside some set of modules gets `NOSPECIALIZE` by default, that it applies to types with in their representation contain types X, Y or Z (i.e. only types which unpack X Y or Z) etc. 
I asked a [similar question](https://stackoverflow.com/questions/23748365/what-is-the-most-efficient-way-to-hardcode-a-map-in-haskell) on SO a few years ago and got some interesting answers.
Do you not have to pay to read the full article ?
I'm very excited about the 'deriving via isomorphisms' part! I think it wouldn't be very difficult to extend it a bit further so that the order of the fields doesn't matter: deriving Ord via (Track `SameRepAs` (String, Duration)) or deriving Ord via (Track `SameRepAs` (Duration, String)) (instead of requiring `Coercible`, just do a bit of reordering)
Sadly, I'm on Wordpress.com, which restricts my options. Thinking of mucking around with BlogLiterately to see if that'll solve my problem.
Oh, the haddocks have a separate (from Modules) Signatures section, sweet!
Is there a standard, or better way of writing the following? Turns out the moment you can't use `many` things get a bit trickier. ``` sequenceAlt :: (Alternative f) =&gt; [f a] -&gt; f [a] sequenceAlt [] = pure [] sequenceAlt (x:xs) = (liftA (:) x) &lt;*&gt; (foldAlt xs) &lt;|&gt; (pure []) ```
The space of types you _do_ want to specialize is a lot smaller than the space you don't. If you have to compile a completely custom version of (&gt;&gt;=) for list for every value type that passes through it, you're going to have a bad day in terms of code size. Here I'm just explicitly asking for recompilation at a few types where it has high power-to-weight ratio, and I'm abusing a type system that is designed and works for much grander things for a fairly pedestrian goal, because it is a tool available for me in the compiler I have access to today. Because backpack is recompiling the whole module for that type it can UNPACK, it can write out a custom info table ptr, etc. All that stuff comes for free and the attendant engineering problems effectively solve themselves. It is a concrete system available today for use. Yes, it is one with a bunch of limitations. Yes it doesn't feel like the rest of the system. One can imagine a system that does anything you want, but it is a lot of engineering effort. I don't have to just imagine a world in which Simon goes off and does a bunch of work for me for the next several years, when this is here today. You could build a compiler around this sort of supercompilation, but I've simply never seen anyone pull off one that is easy to use and isn't subject to horrible edge cases where the compile spins. It basically impossible for me to answer in the affirmative that the approach you want scales and works well, when every data point I've seen says the opposite.
I was shocked when that worked!
Yes, absolutely! Everything is generally blinded anyway, so the reviewers won’t know what hit ‘em.
There's always GitHub pages if you can switch to a static site generator :)
Great work!
"They do similar things" is practically never a good reason to choose one thing over the other though. It is also not really the way Haskell has ever been designed. Otherwise you wouldn't have about a million features you probably enjoy, since many features accomplish "similar goals" to others. Regarding Backpack though, I suggest this comparison is simply untrue. It undeniably adds conceptual features we did not have before. The major advancement is being able to abstract at the package/module level. I don't care if Haskell has `N` different String-ish types (every programming language does, no matter how they deny it). But why does every package providing a Parser that works on String types have to *depend* on `N` packages providing these string-like types? This alone is a game-changing feature in my opinion. Used properly it has huge potential to dramatically shape the landscape of Haskell's interconnected dependency graphs and would likely have a lot of nice benefits for users (including some extra specialization). For example, it could *hugely* decrease the amount of time you spend on compiling dependencies when you can break so many superfluous 'chains' to satisfy instances or whatever. No package providing parser combinators should ever require concrete dependencies on a type the *user* will choose later anyway! If you want to parse `ByteString` values, why on earth should your parsing library require compiling `text` as well? And just about every work to this is error prone, anti-modular, or a cop out, IMO. The reality is that type classes are not analogous to 'interfaces' in most programming languages, because they couple *implementation of an interface* with *the scope of a type implementing it*. This is by design to ensure coherence, but most languages do not do this. In this sense, Backpack offers a major feature that we did not have before and cannot easily be approximated by a typeclass. Are type classes bad? Spoiler alert: no, I don't think so. They're definitely lightweight. I like a lot of ours (many in `Prelude` have strongly proven their worth and I think Backpack would be burdensome for them.) But I have continuously found cases publicly (and at `$WORK`) where I think Backpack could offer huge improvements to modularity, performance (*not* related to specialization) and clarity.
Nope, the full article is online as far as I can tell :)
I just ran into this wonderful gem of a problem. I have a type class: class (TreeState p) =&gt; SmNode n p o where update :: n -&gt; p -&gt; (TreeStatus, p, [o]) utility :: n -&gt; p -&gt; (Utility, p) and I wrap it: data SmNodeWrapper n p o where SmNodeWrapper :: (SmNode n p o) =&gt; n -&gt; SmNodeWrapper n p o and I try and make an instance out of it instance (SmNode n p o, TreeState p) =&gt; SmNode (SmNodeWrapper n p o) p o where update (SmNodeWrapper n) p = update n p utility :: (SmNode n p o) =&gt; SmNodeWrapper n p o -&gt; p -&gt; (Utility, p) utility (SmNodeWrapper n) p = utility n p and I get an error: &gt;Could not deduce (SmNode n p o0) arising from a use of ‘utility’ from the context: (SmNode n p o, TreeState p) which I believe is because "n" which has the constraint "SmNode n p o" may also satisfy another constraint "SmNode n p o0". I'd very much like to call "utility" belonging to the "SmNode n p o" instance. Is there a way to disambiguate here? If not, what are my other options? 
Of course you can write and submit a paper. No affiliation needed. 
Can we work in teams? It'll be me and my fiancee.
I just wanted to say I'm disappointed you didn't go with &gt; -XGeneralizedGeneralizedNewtypeDeriving
I thought that comment about "some people do magical things with profunctors" was tantalizing. "What are these magical things?!" I wondered. I would like to see some examples. It honestly occurred to me that I should come here and ask you for some examples of the magic.
Do you mean jump tables? I doubt there is any hashing involved. 
 instance ( Generic a, Generic b, Arbitrary b , Coercible (Rep a ()) (Rep b ()), Arbitrary b ) =&gt; Arbitrary (a ‘SameRepAs‘ b) where arbitrary = SameRepAs . coerceViaRep &lt;$&gt; arbitrary where coerceViaRep :: b -&gt; a coerceViaRep = to . (coerce :: Rep b () -&gt; Rep a ()) . from Arbitrary b is in the constraint twice. Is that supposed to be there?
I think Google intends for individuals to compete. But unless you perform very well in the contest (I would say "very well" means qualifying for at least round 3) then Google will likely have no way of checking whether you and your fiance are working together.
Why are some libraries like `gi-gtk` impossible to search? Try looking for `mainQuit`, which is a basic and essential function of the library using the search on Hoogle, Stackage, or Hackage and none of them can find it (I'd be happy if someone could prove me wrong here :) ).
No, it's a mistake. The duplication is harmless but unnecessary. 
Yes, that should work. We have a number of examples using different transformations, and I think there is a lot of potential here.
That's true only for some conferences. Haskell Symposium is not double-blind.
I'm having trouble getting the python script to work with my C# application. Anyone having any luck with it?
&gt; The reality is that type classes are not analogous to 'interfaces' in most programming languages, and shouldn't be suggested as such -- because they couple implementation of an interface with the scope of a type implementing it. Namely, the type must be in scope, and there can only be one. This is by design to ensure coherence, but most languages do not do this. In this sense, Backpack offers a major feature that we did not have before and cannot easily be approximated by a typeclass, because "scope" is not relevant. Perhaps I'm missing something, but in most other statically typed languages, interfaces are EVEN MORE tightly coupled to the types, as at least with typeclasses you can define them either with the class OR with the type, with interfaces you must define them directly on the type.
What exactly do you mean by "search"? If you know you're looking for something in that package this is what you do: 1. Go to https://hackage.haskell.org/package/gi-gtk 2. Follow the link under Documentation to https://hackage.haskell.org/package/gi-gtk-3.0.22/docs/GI-Gtk.html 3. Click on [Index](https://hackage.haskell.org/package/gi-gtk-3.0.22/docs/doc-index.html) (in the top right) 4. Click on [M](https://hackage.haskell.org/package/gi-gtk-3.0.22/docs/doc-index-M.html) 5. Click on [mainQuit](https://hackage.haskell.org/package/gi-gtk-3.0.22/docs/GI-Gtk-Functions.html#v:mainQuit) On the other hand, if you don't already know you're supposed to be in `gi-gtk` then I don't know what to suggest. 
Here's my thinking 1. I'm suspicious of existentially quantifying over typeclasses, so I'd propagate the `n` out of `SmNodeWrapper` data SmNodeWrapper n p o where SmNodeWrapper :: n -&gt; SmNodeWrapper p o 2. `utility` doesn't mention `o` so I'd make a new class for it class SmNodeUtility n p =&gt; SmNode n p o where update :: n -&gt; p -&gt; (TreeStatus, p, [o]) class TreeState p =&gt; SmNodeUtility n p where utility :: n -&gt; p -&gt; (Utility, p) 3. Then we don't need `p` and `o` in `SmNodeWrapper` and we can just write our instances as data SmNodeWrapper p o where SmNodeWrapper :: (SmNode n p o) =&gt; n -&gt; SmNodeWrapper p o instance (SmNode n p o, TreeState p) =&gt; SmNode (SmNodeWrapper p o) p o where update (SmNodeWrapper n) p = update n p utility :: SmNodeWrapper p o -&gt; p -&gt; (Utility, p) utility (SmNodeWrapper n) p = utility n p I've no idea if this is useful to you but I do strongly advise you to avoid existentially quantifying over typeclasses if you can. {-# LANGUAGE ExistentialQuantification #-} {-# LANGUAGE MultiParamTypeClasses #-} {-# LANGUAGE GADTs #-} {-# LANGUAGE AllowAmbiguousTypes #-} {-# LANGUAGE FlexibleContexts #-} {-# LANGUAGE FlexibleInstances #-} {-# LANGUAGE UndecidableInstances #-} {-# LANGUAGE InstanceSigs #-} class TreeState p data TreeStatus data Utility class SmNodeUtility n p =&gt; SmNode n p o where update :: n -&gt; p -&gt; (TreeStatus, p, [o]) class TreeState p =&gt; SmNodeUtility n p where utility :: n -&gt; p -&gt; (Utility, p) data SmNodeWrapper n where SmNodeWrapper :: n -&gt; SmNodeWrapper n instance (SmNodeUtility n p, TreeState p) =&gt; SmNodeUtility (SmNodeWrapper n) p where utility :: SmNodeWrapper n -&gt; p -&gt; (Utility, p) utility (SmNodeWrapper n) p = utility n p instance (SmNode n p o, TreeState p) =&gt; SmNode (SmNodeWrapper n) p o where update (SmNodeWrapper n) p = update n p 
&gt; data WrapMyClass o = forall c. MyClass c o =&gt; WrapMyClass c This is a great example of why trying to program at the typeclass level is going to cause you a lot of pain. `WrapMyClass c o` contains a way of turning a `c` into a `String` but I think it only works if you can conjure up the `o` in question. I don't really know why. The way that typeclasses are resolved are still sometimes confusing to me. But also I don't really *care* why. It's much more convenient to program at the value level than the typeclass level. {-# LANGUAGE ExistentialQuantification #-} {-# LANGUAGE MultiParamTypeClasses #-} {-# LANGUAGE AllowAmbiguousTypes #-} {-# LANGUAGE FlexibleContexts #-} {-# LANGUAGE FlexibleInstances #-} {-# LANGUAGE GADTs #-} data MyData c o = Foo { foo :: c -&gt; String } data A = A data B = B data C = C myDataA = Foo (\A -&gt; "A") myDataB = Foo (\B -&gt; "B") myDataC = Foo (\C -&gt; "C") data WrapMyData o where WrapMyData :: MyData c o -&gt; c -&gt; WrapMyData o myDataWrapMyClass = Foo (\(WrapMyData (Foo myDatacf) c) -&gt; myDatacf c) _A = WrapMyData myDataA A :: WrapMyData () _B = WrapMyData myDataB B :: WrapMyData () _C = WrapMyData myDataC C :: WrapMyData () main = do putStrLn $ foo myDataWrapMyClass _A putStrLn $ foo myDataWrapMyClass _B putStrLn $ foo myDataWrapMyClass _C 
I'm not concerned about ,`mainQuit` specifically, it's just an example. It sounds like we both arrived at the same question when you said "I don't know why". I've been using a bunch of `gi-*` packages, so it seems like almost every package I'm using cannot be searched, but that is just this specific case. Just wondering why, and if I might be able to help contribute to a solution.
Hmm, I tried to understand the advantage of this. But it just didn’t click. In the repo I just see a _lot_ of files.. could anyone explain what the advantage here is?
[removed]
If you have a ProductProfunctor `p` then `p a a'` represents a way of converting `a` to `a'` in a way that can be put "side by side" with other such converters. For example if `DatabaseConverter` is a `ProductProfunctor` and I have a :: DatabaseConverter SqlInt4 Int b :: DatabaseConverter SqlText String c :: DatabaseConverter SqlFloat8 Double then I can form p3 (a, b, c) :: DatabaseConverter (SqlInt4, SqlText, SqlFloat8) (Int, Text, Double) Does that explain it? You inspired me to write some brief commentary about this in the Haddocks. They will appear in Data.Profunctor.Product and Data.Profunctor.Product.Default when they are generated.
I'll have a quick look and see if I can work out why. Before I look I'm going to bet it's because they're generated with TH or something like that. 
For qual you can work with others :) check the faq.
Excellent, thank you! Will try it out soon
It terminates the list at the first empty value. In the case I'm dealing with I've got an infinite list of parsers and want to turn it into a parser.
No, there really isn't. But your complaint is coming a bit too late, the `let` in GHCi has been optional for a pretty long time (a couple of years at least) now. Unless you're stuck on an old version of GHC (in which case, why complain?) you don't need it.
In the meantime, anyone who wants to try a patched GHC with `DerivingVia` implemented can build the implementation at https://github.com/RyanGlScott/ghc/tree/deriving-via-8.5 or the Nix expression at https://github.com/Icelandjack/deriving-via/tree/master/nix
I wish definitions like `x = 42` actually were differ. Sometimes I want to do something like that: a = [1,2,3] f = (+1) c = map f a And now if I change value of `f` or `a` value of `c` changes automatically.
Put them in a file and reload when you made a change? If you need something like this where you frequently change things, doing it all interactively is unnecessarily complicating things.
This proposal follows the usual Haskell approach of wrapping types in `newtype` wrappers to get different class instances. The interaction with MPTC is a bit awkward. I would be very interested in seeing what might come of an attempt to bring a `newtype`-like facility to the constraint system. Imagine something like newclass C x y = MkC (D x y) (syntax subject to extreme modification, including perhaps dropping the data constructor). The idea would be that `C x y` would be a class with the same methods as `D`, but potentially different instances. So one could potentially coerce between instances of `C` and instances of `D`. The most obvious challenge: what about superclasses? I don't yet see an obviously nice way to deal with them.
I agree (not with the warning bit since this is definitely an error), but the error message could definitely be improved. There could perhaps be some message stating "while trying to display `Foo`. Are you missing an implementation of Show for Foo?" or something along those lines. 
As explained by HKei, "Since GHC 8.0.1, you can bind values and functions to names without let statement" :) https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/ghci.html#introduction-to-ghci 
I don’t understand the comment about this technique not working for Data.Sequence. Backpack should work fine with polymorphic recursion. What is it that you are saying wouldn’t work?
Perhaps, but then you get random WTF moments in cases where `Show` can't be derived.
How is it an error though? It's `GHCI` that is calling `show`, not the user. So it's a bug in GHCI not the user's code.
`Show` can always be derived. You can do something like `show = const "##Foo##"`
Quality writing, and a great idea with that sublime quality of all great ideas: perfectly obvious, but only in retrospect. I greatly look forward to the next paper that makes it obvious in retrospect what the treatment of MPTCs should be. I have a certain... je ne sais... "qu"s. One question and one quibble. You consistently write in this style: data Foo a = . . . deriving (Baz a b c) via (Bar a b) ...whenever there are type-level applications. Will those parentheses be needed in the implemented thing? What do they disambiguate? My quibble is about calling the transformation from `Foo a` to `Foo` "eta reduction". It's not. Those are just two unrelated type-level terms. They don't even have the same kind, let alone being in any sense "equal"! Eta reduction would be the transformation from `/\a. Foo a` to `Foo` (assuming we had type-level lambdas spelled `/\`). Or for a value-level comparison: going from `\x -&gt; f x` to `f` is eta reduction, but going from `f x` to `f` is not -- the latter two are just two unrelated, inequal terms.
We shouldn't do that for `Show` itself for sure. But for `ghci` we *should*. Other languages' REPLs do not have this silly behavior, they display something for any value, even if it's something useless like a pointer (at least it's not 5 lines of error message). I *think* it would actually be easy enough to have some kind of class `GhciShow`, with an instance for `Show a =&gt; GhciShow a` and overlapping that `GhciShow a`. No breaking change.
I think MPTC is mostly an issue of syntax, we extend the functionality of `via` to multiple parameters and `coerce` does the rest -- assuming we can coerce Prisms instance Cons (ZipList a) (ZipList b) a b via Cons [a] [b] a b for `-XGeneralizedGeneralizedGeneralizedNewtypeDeriving` instance Num Age via Num Int
I've done things like this before - using classy prisms but without the cps trick - to do slices of languages. By a slice I mean the rules for parsing, pretty printing, evaluation, type checking and quickcheck generation. Once you have that you can create something that will turn a set of slices into a REPL which also does typechecking, plus a test suite that checks the usual PLT properties hold (progress, preservation, determinism of evaluation etc...) My first attempt did that with simple slices (bools, ints, if-then-else, STLC), my second attempt only did the evaluator and type checker but covered pattern matching and more complex slices (up to System Fw) and could do all of the plumbing and instance creation for you from a type level list of tags corresponding to the slices. Now I have the CPS trick and another trick to make some of the internals easier to manage, it's probably time to combine the stuff from the previous approaches and consider what would be required to add compilation to LLVM or Core :) 
That sounds reasonable enough actually. Though I think if we're doing that, we might as well change it so ghci always prints the types of the things too.
The sketch I initially gave /u/dalaing was showing how you could do it in a language where backpack might be able to mash together partial function definitions as well as just their signatures. To do that it'd need something like [Overlapping and Order-Independent Patterns](https://pdfs.semanticscholar.org/9cde/3b72487718f810abb0cc468f0166643d5119.pdf) to allow bodies to be glued together multiple times and in an order independent fashion to make signature merges commute. There, you'd be able to do the same examples in about 1/10th of the amount of code. e.g. consider an overly simplistic signature data Expr a eval :: Expr a -&gt; a then one coule defint data Eval a where Lam :: (Eval a -&gt; Eval b) -&gt; Eval (a -&gt; b) App :: Eval (a -&gt; b) -&gt; Eval a -&gt; Eval a eval :: Eval a -&gt; a ... Then later on define another module that defines data Eval a where Int :: Int -&gt; Eval Int Add :: Eval Int -&gt; Eval Int -&gt; Eval Int eval (Int i) = i eval (Add a b) = eval a + eval b Now merging those modules would give you an expression type and evaluator for a "language" with both sums and functions. This starts to get interesting to me when I think about the needs of something like a nanopass compiler, which is typically just removing a single constructor at a time. Building it out of current technology in Haskell makes everything a rats nest of "data types a la carte" or prisms. Mind you, this is a bit different than backpack we have in Haskell where saying part of a data declaration is specifying what would have to be there in a module, but one could envision a language that had these semantics.
Hmm. If you're going to print the type then I guess you don't need to print anything for an un`show`able value.
I was thinking of always showing both, like &gt; 2+3 5 :: Int &gt; id &lt;unprintable&gt; :: a -&gt; a &gt; data F = A (a -&gt; a) &gt; A id A (&lt;unprintable&gt;) :: F Maybe a prettier representation than "unprintable", but something along those lines.
You could literally just print `:: F` though. There's no need for any representation other than the type there.
I see. That last example is good. You do want to print that `A` there. Maybe you could do something like `A (_ :: a -&gt; a) :: F`
You can expire them, which is probably less overhead for the user than forcing a password change on them.