\`lens\` won't help you writing different data structures reflecting different subsets of fields. \`lens\` let you to \*\*get\*\* and \*\*set\*\* smaller parts of bigger structure, so you could have e.g. \`Lens' AdminView NonAdminView\`, as \`NonAdminView\` is (probably) a subset of \`AdminView\`. To make writing a variety of similar data structures, you could explore \*extensible record\*. For example, \[\`vinyl\`\]([http://hackage.haskell.org/package/vinyl](http://hackage.haskell.org/package/vinyl)) is one library, which in fact has support for \`lens\` in \[\`Data.Vinyl.Lens\`\]([http://hackage.haskell.org/package/vinyl-0.11.0/docs/Data-Vinyl-Lens.html](http://hackage.haskell.org/package/vinyl-0.11.0/docs/Data-Vinyl-Lens.html)) .So \`rsubset\` will let you view (or set) part of larger structure. But it's better to start with a tutorial: [http://hackage.haskell.org/package/vinyl-0.11.0/docs/Data-Vinyl-Tutorial-Overview.html](http://hackage.haskell.org/package/vinyl-0.11.0/docs/Data-Vinyl-Tutorial-Overview.html)
So, switching from time to chronos doesn't improve things for my project. I'm using only getSystemTime which is \*very\* fast. Using stopwatch\_ or getTime is about 40% slower for my usecase.
Ah ok. Unfortunate. No problem 
Why are you using those over Chronos.now?
`Either err` is still applicative / monadic. It's basically the pure version of checked exception handling.
ghci
I'd recommend that you don't actually use `Either err`, but rather something isomorphic to it (even just a `newtype` wrapper around it), so that you can do things like use `MonadFail` without needing to create an orphan instance.
... most forums, including (IME) this one prefer that you don't ask homework questions. Your current attempt only works for single-element lists, because of the pattern you've specified. Simply remove the point/argument and you'll be better off. Also, the syntax for an anoymous function is `\args -&gt; expression` not `args = expression`, and you'll need to fix that for the anonymous function you are trying to pass as the first argument for `hsMergeSort`. Basically you are pretty close, if you'd fix you syntax errors and do some basic testing.
Eh, I don't think `fail` / `MonadFail` a really a good ad-hoc interface, so I don't care if I don't have it. I *might* provide a `Text -&gt; MyMonad a`, function but probably not. I generally prefer enumerations or structured data as "exceptions" instead of just a string. --- Definitely recommend a `newtype` over an orphan instance for a library, but orphan instances are fine for an executable.
For what it's worth, I think the difficulties you are thinking of might be imagined. I don't personally know of any Haskell developer who would reject something like this based on overloaded naming alone.
Just write the separate data structures. One trick to reduce boilerplate conversion code is to have identical field names and enable DuplicateRecordFields. This way, converting from a data type with more fields to one with fewer is just one line of code convert ThingWithMoreFields{..} = ThingWithFewerFields{..} I quite like this approach because it's very explicit which fields are present in which variants of the data type. This is especially important since you mention admins can see more fields: it is very important to me to lay out exactly which fields are available publicly and which are available only to admins. Making things explicit is the way to go. 
That sounds extraordinarily error prone over time, honestly. Not sure if I would use that approach myself.
OP's Stack Overflow questions on this topic, to avoid duplicating effort: - https://stackoverflow.com/q/55083024/625403 - https://stackoverflow.com/q/55082377/625403
Nice work! What about imports/exports? Do you allow importing Haskell routines to wasm and vice versa?
I enjoyed the presentation, and I appreciate the effort that went into it. I'm sure many of us came to Haskell wanting to avoid the pitfalls present in so many other language choices, and a library that further reduces pitfalls — like the ones present in `base` — can only serve to help us even further. I am disappointed and embarrassed that so many comments in this thread are criticisms of FPComplete, or criticisms of a private company investing in the community (I do not believe there is any conflict of interest here; FPComplete driving Haskell adoption — which includes evangelising safer tools — is a win for everyone), or pedantry over the word "the" vs "a". This has been addressed by Snoyman, and the speaker in the presentation is clearly not a native English language speaker. We can do better.
Yes, you can create a “host function”, either pure or over the monad of evaluation `m` (which is left to you to pick), and then import this function into your Wasm module. Items exported from one module may be imported into others, though wiring this up must be done explicitly (see the Wast runner for an example).
This is great news!
`--file-watch` might be a useful thing to include.
Interspersing the benchmarks so you start seeing results from each right at the start is awesome.
Another useful thing to include could be `stack run`, a new command in the latest release which builds and then runs the specified command.
This is very exciting! Does anyone know what exactly is new for uninterpreted functions? I'm not sure what was supported before versus now.
I don't believe uninterpreted functions were ever part of SBV before, so their existence at all is new. This is huge and great new, even if it is limited to two of the backends.
Here is one approach: ``` newtype Hash = Hash String data Context = Create | Public | Full type family CtxCase ctx c p f where CtxCase Create c _ _ = c CtxCase Public _ p _ = p CtxCase Full _ _ f = f data User ctx = User { pk :: CtxCase ctx () Int Int , username :: String , password :: CtxCase ctx String () Hash } createUser :: User Create -&gt; User Full createUser u = u { pk = 42 , password = Hash $ password u } viewUser :: User Full -&gt; User Public viewUser u = u { pk = pk u -- ghc unfortunately seems to require this line , password = () } ```
Do not ask how to open Haskell. Ask instead how to open your mind.
&gt; I kinda prefer the more syntactic flavor Could you give more details on this? What are the differences between this design?
haha ok except my mind is literally haskell
Has anyone had success with using haskell-ide-engine with obelisk/reflex-platform? 
Would you mind adding it? (I don't use --file-watch and I'm wary of writing about things I don't know) 
This is neat! Can somebody do one for Cabal?
uste tuples
The site is completely user-editable (no registration needed), and if you start the one for Cabal, it will probably get filled in by others at some point. I don't know Cabal as well as Stack, but I can contribute too. It would probably make sense to only describe the "new-" part of Cabal, though. Unless the old commands are still used?.. I actually don't know. 
Using cabal new commands is, in my experience, more convenient than stack. The nix style builds work very well. With stack from time to time one needs to delete the local stack directory, it never happens with cabal. There is no --file-watch but ghcid works flawlessly. 
&gt;ghcid Stack is the best, --file-watch is a must have. I don't have any issues with stack.
Just benched it. Indeed [Chronos.now](https://Chronos.now) is for some reason faster and uses less mem. You convinced me, just pushed a new version with your suggested module hierarchy. Thanks!
I'm aware of the problems with \`RecordWildcards\`, but why would this particular usage be error-prone?
&gt; While we anticipate that expert programmers may want to write code that uses (`↝`) directly, our main focus is on using it internally, in the intermediate language of a compiler. If it makes it way to the surface this would be a cute notation f :: Int -# Int f = \a -# a
Haskell is a mess. For an actually good language, that 'turned out alright', look at Scala. No design by committee there.
This looks like a great resource! As the editor of u/HaskellWeekly, I've been compiling information about featured authors for almost a year now. It's not formatted as nicely as the Aelve Guide, but it contains nearly 300 authors. Check it out: https://airtable.com/shrp0GHpXNPXt7DnX
Awesome! Thanks for the good library! I hope to use it soon.
We've been using stack in my team for the past year and never needed to delete local stack directory. I've also never seen this problem for anyone. I'm not sure it's a common problem (or even a problem).
Dan Piponi's blog is how I fell in love with Haskell about 10 years ago. If I was a billionaire I would propose to hire him with a big salary to think and write about math and Haskell full time.
It's probably not a common problem, but it definitely was a problem around a year ago. Not sure if it's still a problem now.
*A note to whoever is trying to edit this page to make it look like Stack is "the" build tool for Haskell: I'm going to keep reverting your edits until the heat death of the universe*
This made me laugh - I mean who can be bothered spending their time on such pointless propaganda. Since this is a touchy subject I'll highlight that j like and use both Cabal and Stack.
A bit of topic, but maybe someone knows. Is there a wasm implementation somewhere which already integrates a wasm gc and tailcalls? I know the proposals are in flux, but maybe there is some implementation which already took some steps towards implementing them? This would be very helpful for functional programming impementations. I assume both asterius and webghc need tailcalls and use some trampolining instead? While the gc won't be used by neither of them, it is useful for toy interpreters and experiments and if a runtime decides not to carry its own gc.
Version bounds are a touchy subject as well: And the "one and only" edits come fairly often by now:
I haven't used it for about that time, so good to hear it has been fixed. Still with cabal you get reproducible builds (given the state of Hackege index); there's still advantage of using nix on ci, but (loacaly) it works really well. 
Uninterpreted functions were always part of SBV, but their values weren't queriable before. This version allows users to extract them in existential contexts: import Data.SBV f :: SInteger -&gt; SInteger f = uninterpret "f" t :: Goal t = do x &lt;- exists "x" constrain $ f x .== 2*x constrain $ f 21 .== 12 You get: *Main&gt; sat t Satisfiable. Model: x = 0 :: Integer f :: Integer -&gt; Integer f 21 = 12 f _ = 0 Previously, only the value of `x` in the model. If you use the programmatic API, you get function models as association lists of argument value pairs to do further programming with them.
[https://github.com/obsidiansystems/vessel/blob/develop/src/Data/Vessel.hs](https://github.com/obsidiansystems/vessel/blob/develop/src/Data/Vessel.hs)
Btw, I've forgot to comment, this would be ideally for a position in Kiev, though other options could be worked out given a good candidate.
There is `stack build`s `--copy-compiler-tool` CLI key that would install `intero` to compiler-specific location. It usually does it.
Locally from Kiev strongly preffered, but other options are possible, including remote or semi remote. &amp;#x200B; Anyway, feel free to send your CV or even just a short introduction of your experience and goals so we can schedule a video-call to talk about specific cases.
I also started writing a few tutorials in Haskell, but mostly for myself. I'm curious if anyone here has thoughts on what's missing in the current blog space. Do we need more basic/intermediate/advanced tutorials or discussions? 
Yeah `fail` isn't great, but it lets you use refutable patterns to the left of the `&lt;-`.
The [Except monad](https://hackage.haskell.org/package/mtl-2.2.2/docs/Control-Monad-Except.html).
I've been doing Haskell for nine years by now. I'm going to be cynical and say that all the low-hanging fruit has been already reaped. For example, it doesn't matter how good your tutorial on library X is, if it's not discoverable – and nothing is as discoverable as the docs on Hackage. Therefore the biggest contributions you can make are either a) pestering the maintainer to improve the documentation, or b) making it so that good documentation can make it on Hackage despite the maintainer's wishes. I.e. you're no longer writing tutorials, but playing social/political/power games (or forking Hackage, or whatever). Similarly, it doesn't matter how good your tutorial about Stack/Cabal/etc is, if the defaults are poor. Because the defaults are *infinitely* more discoverable than your tutorial. When I started writing this comment, I wanted to say that posts on large-scale program architecture would be really nice to have – I want to build X, what's a tried-and-true way to do it? But then I remembered that [The Architecture of Open Source Applications](http://aosabook.org/en/index.html) already exists and I was never tempted to use it for reference (and neither I have seen anyone else discuss it, except for "oh look, they have a chapter on GHC"). And of course, we need improvements on the state of the art – like when several people started writing about lenses and then we got lenses. But this isn't writing, this is research. I guess there could be something in the middle – can you think of something cool/useful that you don't see used much? Blog about it. Try to make it more popular. That's probably the biggest ROI you can get "just" by writing.
A while ago I posted a preregistration form – well, now it's official! TL;DR: * /u/Peaker will be talking about [Lamdu](http://www.lamdu.org/) and static typing. * /u/peargreen (me) will try to distill lessons from several years of using Haskell at [Wire](https://wire.com). * Ben Kramek (I haven't managed to find his Reddit nick) will give an introduction to [Shake](https://shakebuild.com/) and reportedly build something Webpack-like with it – very curious to see how that will go. * /u/int_index is going to close the meetup by telling about his work on GHC and making Dependent Haskell closer to reality.
It’s kind of unfortunate that our current social system doesn’t have good mechanisms for allocating resources towards this kind of work.
What would be neat is a TH syntax so you could write: ``` dbRecord = DBRecord oid $(curryRecord (record::Record)) created ``` And it would split out the fields of `record`. This of course requires that the same fields appear in the same order in both DBRecord and Record.
I've been wanting something like https://hackage.haskell.org/package/chronos-bench-0.2.0.2/docs/Chronos-Bench.html#v:isFasterThan for some time now. Finally!
Yes. It should be a valid career choice, not something that requires you to have a "day time job" and loads of sacrifice. Though Dan Piponi's daytime job is pretty cool also.
\&gt; it feels a bit unstructured to wrap my head around It's very unstructured and was never edited. Don't read it. (Source: I'm the author.) I would recommend watching Simon Peyton Jones's [talk on lenses](https://skillsmatter.com/skillscasts/4251-lenses-compositional-data-access-and-manipulation) instead if you want to get an intuition for them. \&gt; I am somehow not able to understand how was *Identity* and *Const* bought into the picture for the below two. We want all optics to have the `(a -&gt; f a) -&gt; s -&gt; f s` form because it composes well and because it's general enough to express many things we care about (getting, setting – though you have to generalize the arrow to get prisms and isomorphisms). Given this shape, how do we get setting/modifying? The most obvious way to express a modify function is `(a -&gt; a) -&gt; s -&gt; s`, from which you can mechanically deduce that `f = Identity`. Getting is trickier than setting. You want to get something like `s -&gt; a`, which has a very different shape. But if you know that you need an `a` in the end, and what you're getting `f s`, then you have no choice: `f s ~ a`. And so `f = Const a`. This was a mechanical derivation. My intuition for \`Const\` is likely going to be useless, but here it is anyway: "Okay, whatever function I pass to the lens is allowed to take a sneak peak at the `a`, so if I want to carry the `a` out I have to somehow hide it in the functor. Oh right, that's `Const`."
Yeah, I don't like using *that*, either. It's not *quite* a misfeature, but best used only when totality is known.
Because they will be interspersed as well, isolation isn't actually that important. I'm getting pretty consistent correct answers, while browsing, compiling other stuff or cleaning my nix-store. It'll be especially robust if both functions are fast (subsecond mean) and tax the same resource (e.g. CPU or IO or network).
Another point: If your benchmark begins to wibble, the standard deviation and therefor the standard error will increase as well. The termination criterion depends on the standard error (via confidence intervals). So wibbling will in most cases just increase runtime until a conclusion is met but not change the conclusion.
Glad to see [Call by Push Value](https://ncatlab.org/nlab/show/call-by-push-value) is the related work section. I read the first 3 pages and it reminded me strongly of that approach.
This is looking for `libcurl`, not the `curl` binary.
Yeah I tried finding resources on how to install this on Windows but everything I found pointed towards curl, not libcurl. Any idea how to go about this?
Windows version of stack also installs msys which comes with pacman package manager. I don't know if it already was in your Google results, but try to install libcurl via shipped msys. 
Not really answering your question, but I've always thought that [lens over tea](https://artyom.me/#lens-over-tea) by /u/peargreen is the **best** lens tutorial around. It actually explains why lenses are structured as they are. It's not as good, but the [Wikibooks tutorial](https://en.wikibooks.org/wiki/Haskell/Lenses_and_functional_references) is also good.
A `Lens' s a` takes an effectful transformation of type `a -&gt; f a`, which can change the value of the focused `a` and also perform a side-effect of your choice. It then returns an effectful transformation of type `s -&gt; f s`, that is, it constructs an `s` in which the focus has the new value, and also performs that same side-effect along the way. We can pick which transformation we want, and also which effect we want. So, if we just want to change the value of the focus, then that's easy, since that's what a lens does. It also performs a side-effect, which we don't need, so we can pick `Identity`, that is, no side-effects. If we want to get the value of the focus, one way to do that is to pick an effect which aborts the computation with the value of the focus. `Either a` sounds like a good choice, except when you get an `Either a s` at the end, so there is still the possibility that the result would be a `Right s`. `Const` is like an `Either` with only the `Left` constructor, so that's a better choice.
Hi. I'm trying to concatenate two Strings with ++ to build a RoutePattern using scotty. The following works `addHelloRoute :: RoutePattern -&gt; ActionM () -&gt; ScottyM()` `addHelloRoute path action = get path action` What I want to achieve though is `addHelloRoute :: String -&gt; ActionM () -&gt; ScottM()` `addHelloRoute path action = get (("/hello" ++ path) :: RoutePattern) action` No matter how or where I try to append the two strings I always get `* Couldn't match expected type \`RoutePattern'` `with actual type \`[Char]'` `* In the first argument of \`get', namely` `\`(("/hello" ++ path) :: RoutePattern)'` `In the expression: get (("/hello" ++ path) :: RoutePattern) action` `In an equation for \`addHelloRoute':` `addHelloRoute path action` `= get (("/hello" ++ path) :: RoutePattern) action` `|` `30 | addHelloRoute path action = get (("/hello" ++ path) :: RoutePattern) action` I'm new to haskell, not to programming in general and just do not understand this. It seems to be the actual concatenation that's failing &amp;#x200B;
Maybe I'm just confused - and please correct me if I'm wrong - but wasn't Stack originally designed to give reproducible builds as well?
Doesn't `-XMonadFailDesugaring` guarantee totality of it?
I would rather opt for a solution like the one u/gagandeepb proposed. You "open" the record by converting it to a more flexible data type, you modify it and then you "close" it again by converting it to the target record.
They are putting effort into reproducible builds: [https://www.fpcomplete.com/blog/2018/01/hash-based-package-downloads-part-1-of-2](https://www.fpcomplete.com/blog/2018/01/hash-based-package-downloads-part-1-of-2), as well as `stack --nix` and `stack docker`.
Can you share a direct link top the Talks, please?
They are on that page, just a little bit down (or click the 'Talks' section in the header). There's currently no way to link to a specific section in the url.
That is all new to me, could you point me in the direction of how to use it?
There's an id attribute hidden in there haha; you can link direct to [https://monadic.party#talk-titles](https://monadic.party#talk-titles) and it'll get you there, though the header cuts it off just a smidge :P Cheers!
Aargh, people finding unauthorized ids :P
&gt; wasn't Stack originally designed to give reproducible builds as well? You seem surprised that Stack was designed to do something that was already possible with Cabal via its sandboxes and freeze files?
Does anyone know how to get vulkan-api to work with MoltenVK on macOS? Ticket describing things I already tried is here: [https://github.com/achirkin/vulkan/issues/24](https://github.com/achirkin/vulkan/issues/24)
I don't know, I'm working from the desugaring given in the Haskell 2010 report. Did this change? In particular, did this change without an extension I'm not going to remember to use unless I need it to make things type-check? Based on https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html?highlight=inline#extension-MonadFailDesugaring it doesn't change the semantics, just which type class `fail` is pulled from. So, you can still do stuff like: `[only] &lt;- ioMyList` or `Just good &lt;- iotSecurity`.
Hi everyone, I’m happy to announce that the ticket and issue import processes are now complete and https://gitlab.haskell.org is back online. There are still a few final steps remaining which I will be carrying out over the next few days: * Put in place redirect logic for Trac ticket and Wiki URLs * Add issue comments showing commit messages, replicating the previous Trac behavior * Migrate the GHC Blog entries * Make the old Trac instance again accessible in read-only mode However, while I do this you should feel free to use &lt;https://gitlab.haskell.org&gt; freely. If you notice any issues with the import feel free to open a ticket [here](https://gitlab.haskell.org/bgamari/gitlab-migration/issues).
Scala being an "actually good language" relative to Haskell is not the impression I got from reading the [What does Haskell better than Scala](https://old.reddit.com/r/hascalator/comments/ahv098/ok_ill_bite_what_does_haskell_do_better_than_scala/eeocdhl/) thread.
Ah sorry, it didn't work on my phone.
&gt; they were so concerned with whether they could, they never asked whether they should... 😜
Try ``` # update package database (and do upgrades if available) stack exec pacman -- -Syu # Install libcurl stack exec pacman -- -S libcurl-devel ```
`"str" ++ x` is a `String`, not a `RoutePattern`. `x :: Type` is not a cast / conversion it an assertion; it's doesn't do anything at runtime, and the compiler is rightly rejecting it as not type correct the way you are using it. You need to call one of the [smart consturctors for RoutePattern](http://hackage.haskell.org/package/scotty-0.11.3/docs/Web-Scotty.html#g:3) in order to create one. You can also use the `IsString` instance of `RoutePatten` to create one, by calling `fromString` on the `String` you have, which is basically the same as the `capture` smart constructor. You might also look at the `OverloadedStrings` extension, which will automatically turn string literals into `RoutePattern`s or anything else with as `IsString` instance. That wouldn't directly apply to the code you posted, since `"str" ++ x` is not a string literal and `(++)` is `[a] -&gt; [a] -&gt; [a]`, not (e.g.) `RoutePattern -&gt; RoutePattern -&gt; RoutePattern`.
Ok I did this successfully but I'm still getting the same error when trying to build with Scalpel as a dependency
Thank you. I'm not sure where I got it in my head that :: Type was a conversion. I tried literal and that's working. I'm going to experiment with the others and add query parameters. `addHelloRoute :: String -&gt; ActionM () -&gt; ScottyM ()` `addHelloRoute path action = get (literal ("/hello" ++ path)) action` &amp;#x200B;
My bad, actually needs to be `stack exec pacman -- -S **mingw-w64-x86_64-curl**`
The extension is on by default in modern versions of GHC, and the idea is that refutable patterns will now give you an error at compile time unless the monad has proper support for handling failure in a total way.
I'll try this, how do you diagnose this kind of thing? I'm assuming I'll run into similar challenges in the future and I don't know where to look
This sounds really interesting, will the talks be recorded?
Most likely, yes.
You can pass `--verbose` to see what exactly stack is trying to do. In cases like this though, it's looking for a C library and it's sometimes not super hard to see why you can't see certain libraries, sometimes you have them in the wrong format, you have a 32 bit library where a 64 bit one was expected, dynamic vs static etc. In this case I just happened to know (although I forgot for a bit) that the development libraries in msys are the `compiler_name-architecture-library_name` ones, where `mingw-w64` is the compiler (suite), `x86_64` is the platform I (and most other people) are on right now, and `curl` is just the curl library. You can search for packages with `stack exec pacman -- -Ss search terms` if you're not sure what _exactly_ a certain package is called.
Ah - I didn't know about freeze files. Thanks for telling me!
Done.
Of course, lens over tea is what I would recommend to anyone as well even though the Artyom says I should not read it :). It covers a lot of stuff which no one has really written anywhere. I will take a look at Wikibooks entry.
The intuition for Const does help. And thank you for writing the lens over tea series of articles. They definitely help.
The added analogy with Either is interesting.
Oh wow I used to read someone's blog ages ago and loved it, but after a while stopped reading and forgot the name - it was Dan Piponi! Thank you, going to have some good reading to catch up on.
&gt;import Text.Regex &gt; &gt;main = do &gt; &gt;let r = mkRegex "\\\\&lt;dog\\\\&gt;" &gt; &gt;print $ subRegex r "mydog dog" "(\\\\0)" &gt; &gt;=&gt; output: "mydog dog" Thanks for the recommendation, do you know how to use "search and replace"? like subRegex..?, I can not find any sugRegex in TDFA lib... or I'm missing sth? &amp;#x200B;
Could you say more about how it reminded you? I never really understood CBPV.
I think you're right, stack does reproducible builds. There's a fair (and fairly recent) comparison here: https://medium.com/@fommil/why-not-both-8adadb71a5ed
As an outsider, it's very nice to see a batteries included style stdlib that definitely helps people. Ocaml stdlib is also similarly barebones and alternate stdlibs like containers, core etc. are widely being used by people. Sidenote: Interesting that a commercial company couldn't manage to have better audio in their webinar.
Any summer 2019 internship positions involving Haskell/FP/type systems? Research internships definitely preferred, but not necessary; I'd be very happy writing any Haskell code. I'm a MS student in a transition period, planning to start a PhD in Sept/Oct.
[Control.Dsl.State](https://hackage.haskell.org/package/control-dsl/docs/Control-Dsl-State.html) supports multiple states, but the data type to hold states is simply a type alias to `-&gt;`, which is simpler than `StateT`, which is a `newtype` of `s -&gt; m (a, s)`. At least, this `Dsl` approach simplifies the both the usage and implementation of states. 
The boilerplate of `toCont` also lead to more complex implementation than `RebindableSyntax`. Each statement of `toCont` in a `do` block creates two closures. In contrast, each `toCont`-free statement in a rebindable `do` block creates zero closure. 
Why doesn't Artyom recommend lens over tea? I don't remember him saying that anywhere.
See the top reply from u/peargreen. By the way I went through the Wikibooks entry and it is good. It provides additional intuition and takes a different angle. Thanks for it.
Very helpful, thanks!
I thought for some reason he was talking about lets-lens there. (And you're more than welcome for the Wikipedia article! There's plenty of other advanced Haskell in that book too.)
Partly it was that expressions in CBPV were of two kinds (in a more informal usage) and the bi-language construction. (I this paper they are call L and LX, but I think one of the CBPV paper I read did something similar with different names.) I'm not sure I really understand CBPV either, but I also don't understand STG as much as I'd like to.
&gt; I'm not sure where I got it in my head that :: Type was a conversion. I suppose it feel a little like one when you use it to monomorphize a polymorphic value.
For something like `[]` or `Maybe`, I suppose that's okay. But, those monads don't really do good error reporting, we you want to do that you generally need more (or less!) than a string to construct your failure value. I think OP is trying to "add descriptive error messages" and `"Incomplete pattern match at __FILE__:__LINE__"` is probably not what they meant by descriptive.
&gt; Const is like an Either with only the Left constructor exploding_brain.gif 
Intero is not global. Is per GHC tool.
That's pretty funny :)
This is our current target, indeed. We've had major setbacks before, so it's not a guarantee. But I rather hope it's a reasonable estimate!
&gt; I've been trying to install the Snap framework but keep getting an error after running the command &gt; &gt; `cabal install snap snap-templates` Well, there's your problem right there I recommend following the steps from https://haskell-lang.org/get-started/linux and and there's also a Gitter channel at https://gitter.im/commercialhaskell/stack if you need more help getting started with Haskell. 
Indeed, the regex libs in haskell don't typically offer a "replace" function. The haskelly way is to parse and operate on strings directly, rather than use regexes. That said, you can build a replace function by extracting the match locations from `matchAll` and gluing together the answer you want directly. This is actually how the `regex-compat` package does it itself (but based on posix regex bindings, rather than an in-haskell matcher): http://hackage.haskell.org/package/regex-compat-0.95.1/docs/src/Text-Regex.html#subRegex
Compare the completely desugared (no type class involved) code for `PolyCont` and `toCont`. getLine :: IO String putStrLn :: String -&gt; IO () returnIO :: a -&gt; IO a -- not to confuse `Control.Dsl.return` and `Prelude.return` PolyCont: runPolyCont :: Monadic IO any a -&gt; (a -&gt; IO r) -&gt; IO r runPolyCont (Monadic ma) = (ma &gt;&gt;=) pcBlock :: IO () pcBlock = runPolyCont (Monadic getLine) $ \line -&gt; runPolyCont (putStrLn line) $ \_ -&gt; returnIO () toCont: newtype Cont r a = Cont { runCont :: (a -&gt; r) -&gt; r } (&gt;&gt;=) :: Cont r a -&gt; (a -&gt; Cont r b) -&gt; Cont r b ma &gt;&gt;= f = Cont $ \k -&gt; runCont ma $ \a -&gt; runCont (f a) k toCont :: Monadic IO any a -&gt; Cont (IO r) a toCont (Monadic ma) = Cont (ma &gt;&gt;=) tocBlock :: IO () tocBlock = runCont ( toCont (Monadic getLine) &gt;&gt;= toCont (Monadic (putStrLn line)) ) (\_ -&gt; returnIO ()) While `tocBlock` is desugared to more complex expression as you said, I'm pretty sure both `pcBlock` and `tocBlock` can be easily optimized to the simplest version `getLine &gt;&gt;= \line -&gt; putStrLn line &gt;&gt;= \_ -&gt; returnIO ()` by any serious optimizing Haskell compiler. &gt; The fact of the simplicity of `Dsl` implies it is a more general and more basic construct than `Monad`. I don't think so. I still think `toCont` is the everything you're selling, so it's *a* Monad, not something replaces Monad as a whole. That doesn't mean I have no interest in `Dsl`. I'm expecting more focus on how it competes with Free/Freer/mtl/Transformers. It's not well investigated, isn't it? P.S. Happy cake day
&gt; I am disappointed and embarrassed that so many comments in this thread are criticisms of FPComplete It is truly disappointing and embarrassing. We have a big problem as a community if Haskell keeps up this anti-capitalist stance. Something very similar happened when Michael said that something "was a mistake" a couple weeks ago and Aaron had to call out the misconduct with [an empathic comment](https://www.reddit.com/r/haskell/comments/as18h4/shutting_down_haskelllangorg/egsefyg/?context=1) and got privately insulted for it &gt; Since Michael literally said in this post that the old way "was a mistake," it sounds like you are in agreement. &gt; &gt; May I make a suggestion, in the interest of community spirit? When someone makes a change to correct a past mistake, could you perhaps find a supportive tone for your comment? If we Haskellers can't be nice to someone who realizes a mistake, admits it publicly, and corrects it, well, what kind of community do we want to be? &gt; &gt; Edit: You replied to this with a PM laced with swearing and personal accusations, and then deleted your account, so I guess that answers the question. I hope most of the community does not agree with your perspective. And I hope you change your mind. I look forward to seeing you under another username. 
I think the utility of blogs comes from incubating and exploring ideas that aren't yet well-understood and may or may not prove to be useful. Successful examples include ["functional references" (now called lenses)](https://www.twanvl.nl/blog/haskell/overloading-functional-references) and [differentiation](http://conal.net/blog/tag/derivative).
If I got it right, (`↝`) is simply a way to statically ensure a function begins with a lambda.. thus `f :: a ↝ b` is always eta equivalent to `\x -&gt; for x`
First time I hear about https://getsol.us/home/, how did you install GHC and `cabal`?
One type of posts I'd like to see more is "Haskell type system success stories", i.e. good examples of how various GHC features are used in beneficial ways. For example, one question I see often is "What are good applications of GADTs? All the examples I see describe a calculator." There're plenty of examples from real code bases, e.g. in [darcs](http://hackage.haskell.org/package/darcs): -- | Forward lists data FL p wX wZ where (:&gt;:) :: p wX wY -&gt; FL p wY wZ -&gt; FL p wX wZ NilFL :: FL p wX wX (defined in `Darcs.Patch.Witnesses.Ordered`) or in [freer](http://hackage.haskell.org/package/freer) -- | A data type for representing nondeterminstic choice data NonDetEff a where MZero :: NonDetEff a MPlus :: NonDetEff Bool It'd be nice to have a curated list of good examples of how exactly a powerful type system (phantom types, `GADTs`, `TypeFamilies`, etc.) is useful in practice.
Oooh, that's a nifty way of looking at it! Thanks!
Come on, this isn't helpful.
Since these all have the "same representation in memory and can be used interchangeably" type TrRep = TupleRep [IntRep, IntRep, FloatRep] (# Int, (# List L Integer, Float #) #) :: Type TrRep (# (# Int, List L Integer #), Float #) :: Type TrRep (# Int, List L Integer, Float #) :: Type TrRep should they be [`Coercible`](https://hackage.haskell.org/package/base-4.9.0.0/docs/Data-Coerce.html)? The kind of Coercible :: forall (k :: Type). k -&gt; k -&gt; Constraint must be levity-polymorphic then Coercible :: forall (rep :: RuntimeRep) (k :: TYPE rep). k -&gt; k -&gt; Constraint
[`-XDerivingVia`](https://gist.github.com/Icelandjack/d258b88a0e0b3be2c0b3711fdd833045) started as a blog
Right, so if I install per compiler as some people mentioned, I should be ok?
Please avoid criticising without basis. So far your comment contains no arguments and is completely opinion-based.
Just so you know, I am finding Lens Over Tea to be a valuable resource as I document my own lens library. Since you did not try to restructure it for a cleaner presentation, it has given me insight into how you came to understand various concepts, which is helping me figure out how I want to structure my own documentation. You may think it's garbage, but I promise it is not. Thanks for sharing it! 
Dammit i thought this was the video of the talk.
Yes, a `Cont` could be a `Monad`, but not necessarily be. When using `Cont` in a rebindable `do` notation, you can define `(&gt;&gt;=) = ($)` in order to avoid temporary closure creation due to `Control.Monad.Trans.Cont.&gt;&gt;=`. `PolyCont` and `toCont` can be considered as tagless-final style for continuations, which perform effects. Therefore this approach solves expression problems on effects.
Very cool looking gig! (awful pun)
You can use add a type parameter to your record type and use type families for the field types to distinguish different variants: {-# Language DataKinds, TypeFamilies #-} import Data.Void data Context = AdminRequest | Storage | NonAdmin type family InContext (ctx :: Context) field newtype UserName = UserName String newtype Identifier = Identifier String newtype Password = Password String data MyRecord ctx = MyRecord{ uniqueId :: InContext ctx Identifier, name :: InContext ctx UserName, password :: InContext ctx Password} type instance InContext AdminRequest field = field type instance InContext ctx UserName = UserName type instance InContext Storage Identifier = Void type instance InContext Storage Password = Password type instance InContext NonAdmin Identifier = Identifier type instance InContext NonAdmin Password = Void 
That's a really cool idea. I've seen this kind of analysis done on orchestras but I always wondered if it would work for more popular music and instruments. Good luck, and great tech choice!
Thanks! Yes, harmony analysis is very common among musicologists to better understand (mostly classical) music. However, in our case we use the analysis of the chords to help musicians to learn to play the music of their choice. 
I feel like there could be more AWS/Azure/GCloud focused material, especially after AWS Lambda gained support (via custom runtimes) for Haskell. Sorta focused on commercial usage of the language, which you'd often encounter in both startup and bigger company scale. There are a few lying around, but could definitely be more. Some examples (some already covered): - Using Haskell in AWS Lambda via e.g. serverless - Setting up EKS/K8s with a Haskell service (quite general scope, but specific purpose) - Using AWS services like S3, DynamoDB - Using Haskell in SageMaker for Machine Learning Replace AWS with your favourite cloud above (I mainly use AWS, so I'm more familiar with their terminology). NOTE: These are obviously fuelled by my own interests and needs.
Function names cannot begin with a capital letter. 
Function and value names must begin with lower case letters in Haskell.
Also, you forgot an if
Galois hires interns every year. [https://galois.com/careers/software-engineer-intern/](https://galois.com/careers/software-engineer-intern/) &amp;#x200B; I've given my two cents in the past: [https://www.reddit.com/r/crypto/comments/9tlvnc/who\_is\_hiring/e8z7a7e/](https://www.reddit.com/r/crypto/comments/9tlvnc/who_is_hiring/e8z7a7e/) More than once: [https://www.reddit.com/r/haskell/comments/972io6/whos\_hiring/e45h2fr](https://www.reddit.com/r/haskell/comments/972io6/whos_hiring/e45h2fr) And so have my coworkers: [https://www.reddit.com/r/haskell/comments/awyb50/galois\_inc/](https://www.reddit.com/r/haskell/comments/awyb50/galois_inc/) &amp;#x200B; But I'm happy to answer questions... or at least try.
It's really more like the `Failure` of [`Validation`](http://hackage.haskell.org/package/Validation-0.2.0/docs/Data-Validation.html), but in this case we're only using the `Functor` instance so the fact that errors get combined wasn't relevant :)
&gt;as I document my own lens library What library is that, by the way?
Internal to my employer, but we can probably publicly release it eventually. 
Right, this looks suspiciously like the arch problems, even though its a different distro entirely. I wonder if they also have a static/dynamic packaging divide?
Motivated and inspired by this, I implemented a very small but straight-forward patch for `cabal-plan` https://github.com/haskell-hvr/cabal-plan/pull/37/files When the Boolean comes from cli argument, there aren't much we can do to prevent *Boolean blindness*; but phantom type at least makes it harder to mix them up; and makes type signatures more readable. ```haskell -- | Because 'TaggedBool' constructor isn't exposed, -- we have to explicitly 'tagBool' and 'untagBool'. -- That way it's less likely we mix up bare Booleans. module TaggedBool (TaggedBool, tagBool, untagBool) where newtype TaggedBool t = TaggedBool Bool tagBool :: t -&gt; Bool -&gt; TaggedBool t tagBool _ = TaggedBool untagBool :: t -&gt; TaggedBool t -&gt; Bool untagBool _ (TaggedBool b) = b ```
Haskell is way less of a mess than Scala tbh
You might consider sharing to /r/WeAreTheMusicMakers and /r/musictheory. I'm not sure how many programmers are there, but it never hurts to expand your audience.
Are there resources, blog posts, or books (doubtful) on best practices for Haskell project management... so not so much about the language itself, but about how Haskell might color how you go about herding multiple applications, multiple libraries, multiple contributors, cabal project structures, library layout, etc... an open-ended question but maybe there is something good that it will catch!
Better is to rename post to something like "Why TypeScript is successful but PureScript is not"
Hi Tom! Thanks for the note, but unfortunately I've applied this year and wasn't selected. It also seems that the intern recruiting season is already over, so no luck with Galois this year. I'll apply again in the future though.
The term is: engineering. Google what alan kay says on the topic
After seeing the `WithDefault` implementation, I thought "this looks useful, but this would never work in Haskell". It's only when the post started to talk about hasochism and singletons that I realized that the `WithDefault` implementation I had seen was written in Haskell, not in Agda! Haskell is already supports more dependently-typed tricks than I thought :)
What’s wrong with hiring people to do this kind of work? 
Is CloudHaskell mature like that? It seems very sparsely documented.
&gt; I thought "this looks useful, but this would never work in Haskell" Same, ha! And I admit I may have felt some relief in that moment.
I can confirm CloudHaskell is definitely mature enough. It has helped us to calculate the chords for millions of songs in a distributed matter for almost two years without any problems. 
This is a really important pattern to be aware of ime (i.e., to think critically about what we actually mean by "default"). Particularly important for persistent data (e.g. a user profile in the database): what should happen when the default value changes? Without care at the start you lost the ability to distinguish "whatever is the default", from "value incidentally matching the current default value", and you no longer have a choice.
I already had all those packages installed except for primitive-devel, but that one didn't help, and kernal-libc-devel, but it isn't in the repositories. I tried using ghcup, but I got this error when I tried to install it. Installing library in /home/blue/.ghcup/ghc/8.6.3/lib/ghc-8.6.3/ghc-8.6.3 "/home/blue/.ghcup/ghc/8.6.3/lib/ghc-8.6.3/bin/ghc-pkg" --force --global-package-db "/home/blue/.ghcup/ghc/8.6.3/lib/ghc-8.6.3/package.conf.d" update rts/dist/package.conf.install /home/blue/.ghcup/ghc/8.6.3/lib/ghc-8.6.3/bin/ghc-pkg: error while loading shared libraries: libtinfo.so.6: cannot open shared object file: No such file or directory gmake[1]: *** [ghc.mk:991: install_packages] Error 127 gmake: *** [Makefile:51: install] Error 2
IMO, you have got to get some Kiselyov on that bad boy.
I think many people would love to hear about your usage, I know I would.
Actually, we’ve given a few talks about our application of CloudHaskell in our backend at some meetups in the Netherlands. I can see if I can dig up some slides tomorrow, if you like? 
Yep! Perhaps this tip will fix it: https://dev.getsol.us/T3308
I remember seeing somewhere that with `-XKitchenSink` and Singleton's, Haskell actually can express essentially anything with dependent types. It's only the verbosity, compiler errors, general performance, and boilerplate (not to mention complexity) that keep it from being as easy as a "real" dependently typed language. Would make sense to me, at least
That would be awesome, thanks!
You're right, my apologies. I wrote this right after having read like 3 threads about how terrible RWC was and didn't realize how poorly it came across.
Thank you.
Having thought more about it, I confess that I can't really see a lot of reasons why this particular usage would be error-prone. I was thinking that there could be potential issues where if you change the shape of ThingWithMoreFields and ThingWithFewerFields you could end up with a situation where things silently change and the compiler wouldn't warn you. It's very common when spreading records blindly in JavaScript, but of course Haskell is a bit more safe than that :)
I don't get it. Where are the talks released? I can only see talk titles on linked pages. Clicking on title gives a little more info, but that's it.
The school will happen in June, so talks+abstracts are the only things there yet.
Oh, i see. So these are only announcements. Thank you for clarification.
https://github.com/obsidiansystems/vessel/blob/3196abd3/src/Data/Vessel.hs No README, but the comments are extensive.
I used sudo ln -n libncurses.so.5.9 libtinfo.so.6 and I was able to get ghcup installed, but it doesn't seem to be helping.
thanks!
On the subject of "evaluator consumes far too much memory", are there specific edge cases or samples for which high memory usage was observed ?
this is the link? https://www.youtube.com/channel/UCCeiYYR2fCXarkfSqqFBwuA
[wrong hoogle](https://hoogle.haskell.org/?hoogle=%28b%20-%3E%20c%29%20-%3E%20%28a%20-%3E%20m%20b%29%20-%3E%20a%20-%3E%20m%20c&amp;scope=set%3Astackage)
Ah indeed, thank you very much.
This function is the result of applying fmap to the result of a function application, so it's function composition composed with fmap: bindMap = (.) . fmap This however isn't immediately scrutable, so I'd avoid writing it pointfree, but I'd certainly replace bindMap f g with fmap f . g Note in particular that the Monad constraint can (and should!) be relaxed to Functor.
Haskell?
Yeah
Check out generic lens and look at the section titled "By structure". It will derive lenses for you that operate over structural subtypes of your records. http://hackage.haskell.org/package/generic-lens
You're certainly right, the \`Monad\` constraint is unnecessary. \`fmap f . g\` is pretty much exactly what I was looking for, so thank you.
Yes, when the `call.wast` test is executed, you’ll note that while stack and heap sizes remain usable, the profiling report indicates that &gt;30GB is allocated and freed during the course of evaluation. So we’re constructing and discarding a host of temporaries that aren’t being fused away.
A friend works there and seems to really like it, FWIW.
I'm really interested in your web/api stack: &gt;Servant, Persistent and Esqueleto and we distribute computation using Cloud Haskell Is this working well for you? You'd recommend it? How do you host the web apps? &amp;#x200B;
Do you mean that the `cabal` and `ghc` installed by `ghcup` have the same issue as the ones from your native packaging system? Are you sure you're using the correct ones in your path?
Is there a natural monad instance for this or am I tripping? Like `return x = Default x` and perhaps: `(Default x) &gt;&gt;= _ = Default some_default_value` `(Value x) &gt;&gt;= f = Value $ f x` Actually, it's almost like you'd like to have a withDefault in y slots... Like an applicative? Sorry if the formatting is off, I haven't tried multi-line code from the phone. 
If you have a Mac, feel free to download the [release](https://github.com/quasi-coherent/pixelsort/releases) and try it out for yourself. Or, explore the [source](https://github.com/quasi-coherent/pixelsort) and create your own sorting functions.
Those are last year's talks ;)
Better still any videos?
Here are some slides about Cloud Haskell from 2 years ago: [https://jeroen.bransen.nl/AMS-FP-2017.pdf](https://jeroen.bransen.nl/AMS-FP-2017.pdf) . Obviously some details have changed over time, and the code in the slides is simplified, but the setup is still pretty similar and works like a charm. The "memory leak" that we mention in the slides was related to some Set delete operations being evaluated too lazily, so nowadays we have turned on the Strict GHC extension for most modules.
Sorry, the CloudHaskell talks we did were not recorded.
Yes, in general this is working well for us. &amp;#x200B; Servant is a great piece of software and has everything that we need, and the Warp webserver that it runs on has never let us down in any way. The same goes for CloudHaskell, which we use in a single place to distribute the work over many workers (living on different servers), see the slides above. In the 3 years that the Servant+Cloud Haskell code now runs on production together I think we have never had a single issue with either of them. &amp;#x200B; Esqueleto+Persistent do provide a good layer of typing for our database queries, but we're not always entirely happy with it and have written a custom layer on top of it to make the types somewhat more precise. This is related to the fact that we are using MariaDB (partially for historic reasons, partially for the good replication), of which we use specific features, while Esqueleto+Persistent are intended to be more back-end agnostic.
A neat little thing: since `(-&gt;) s` is a functor, another way to get `bindMap` is `(fmap . fmap)`, which is part of a general pattern; to map into arbitrarily nested functors, you can write `(fmap . fmap . ...)` etc. for each layer. You can apply the same pattern to `traverse` and `liftA2` too. No Monad equivalent, unfortunately, since Monads don't (trivially) compose.
Taking it to the extreme, it’s also `fmap fmap fmap`.
Here at Functional Works we've recently started working with a content publishing platform in Tel Aviv, Israel. They are looking for an experienced Haskeller to continue driving the team forward. The role will be onsite, but they do have flexible working alongside some other great benefits. 
Paying up to $110k!
What is the relationship between Cloud Haskell and Kubernetes and how are they used together in production if at all?
Am I to understand that this means the final encoding does not work for things like ResourceT IO in its effect stack or is it more that you can’t embed a general Bracket effect?
Neither---just that I can't figure out how to do them fast :)
Is the slowdown just on &gt;&gt;=?
For reasons unbeknownst to me, the profiling machinery wouldn't give me anything useful to look at. So instead I looked at the core, and the issue seems to be that GHC can't inline through the `Yo` constructors. The monad instance for `Freer` is identical to the `too-fast-too-free` variant, so I'd be very surprised if that were the slowdown.
We don't use Kubernetes. 
MemoTrie
Thanks for sharing this, I expect to put up a repo that uses your examples to learn about CloudHaskell. 
&gt; ...and building a new library for futures in Haskell. Can anyone from Tweag comment on the result of this? Seems interesting.
Maybe I also came up with the idea similar to yours. I noticed GADTs can take place of type families in the Trees That Grow idiom, and was googling to check if another person already came up with the idea. I found your comment in this 5 months old thread, and your link was already dead. This is [my take on it](https://github.com/viercc/kitchen-sink-hs/blob/86167a6a53897555d93099636f0247cd94bdb7ad/src/TreesThatGrow.hs). I'll be glad if you could tell me how was yours. If it's same to yours, I also happy to hear how it compares to the original TTG approach.
Do interns really need to be skilled enough to implement a linear type system for Haskell? Other than that, sounds like a great opportunity.
Thanks. Your suggestion sparked a wonderful discussion on /r/musictheory!
No :-)
`Tagged` is like an `Either` with only the Right constructor
Not at all! That's why he have tutors. Projects will be adapted to the chosen interns. Feel free to apply!
I think it's comonad-ish, too. duplicate = Value extract = collapseDefault
My mind already went there. After my brain stopped exploding, I asked myself what was something with two type parameters that was like `Either` but with only `Right` and realized `Tagged` fit really well. It even has the `Bifunctor` instance you'd want.
This is why we can't have nice things -- someone out there is doing good work (it _is_ nice to have RIO instead of base for what I imagine is the majority of people) and instead of appreciating or critiquing the work, or better improving it, here we are attacking it for getting a figure of speech wrong. By a non native speaker too, geez. Besides, the posted video on the thumbnail and first slide says "a" not the.
Any other small positions open ?
What I'm trying to ask is, *what the hell is Cloud Haskell*? :D I'm trying to figure out where it fits into the rest of the web ecosystems. The short summary doesn't help me because I have no clue about Erlang.
a facc ro cazz
No problem. About the 20 pages, I mean there are lot of programmers with a good grasp on Haskell, but never trying it in a larger scale / production setting. From personal experience, there's a lot of figuring going on when you get there. Recently there are good tutorials, but you still have to catch the best practices with a small net in a big ocean. In 20 pages, you don't have to share all your knowledge - write down the top suggestions and practices, and people might be happy to get guidance. Obviously if it gets 30 pages fine, but you need a limit somewhere. Once your top ideas get a good traction (in terms of popularity / sales of the book), you can extend and start selling for more, or release a sequel. At least this is what I would do, but personally I feel I need to experience some more dark corners before enbarking on such on adventure. YMMV.
&gt; We haven't found a way yet to create a type called `RightInteger` that holds the right `Integer` for each situation, and we suspect it's impossible. Now I'm assuming the author is already quite aware of this, but using newtypes can get you most of the way there.
I dabbed with Haskell a little and love the language. I don't have any real world experience with it (or nix), though, but I'd love to apply for the internship next year—this time, better prepared. Do you have any tips regarding that? Should I focus on some area, or would it be sufficient to just make a project or two to have something to show you? 
&gt; it is nice to have RIO instead of base for what I imagine is the majority of people I imagine the majority of people will disagree with your hypothesis.
too bad that i am a haskell noob :(
It's an asynchronous IO library design which tries to ideas from very eclectic sources (I can't really comment on the specifics for the moment). &amp;#x200B; I'm rather happy with the general idea. But there is still a rather large amount of work in order to make it into a really usable library. Which is what the internship would be focused on.
Basically a way to run Haskell programs across a homogeneous cluster.
Definitely had to do this a few times myself.
Sounds promising, I hope it gets finished!
Above code block reformatted for old reddit: -- | Because 'TaggedBool' constructor isn't exposed, -- we have to explicitly 'tagBool' and 'untagBool'. -- That way it's less likely we mix up bare Booleans. module TaggedBool (TaggedBool, tagBool, untagBool) where newtype TaggedBool t = TaggedBool Bool tagBool :: t -&gt; Bool -&gt; TaggedBool t tagBool _ = TaggedBool untagBool :: t -&gt; TaggedBool t -&gt; Bool untagBool _ (TaggedBool b) = b
Depends on the exact situation. Types are great for restricting erroneous behaviour in broad strokes, and you can do a _lot_ more with them obviously than what many people used to weak or dynamic typing might expect, but for example if I'm writing a function `encodeAsIEEEFloat32` then the maximum amount of reasonable typing I'd expect is something like `:: Rational -&gt; Vector 32 Bit` - which is great, but of course doesn't actually guarantee that the relationship between in- and output is the one we'd expect from the name of the function. You really can't get around testing here. That being said, obviously testing vs types isn't a dichotomy, I'd expect any reasonable project to employ both.
Common Lisp people were aware of the problem long time ago &gt;Occasionally, it's useful to know whether the value of an optional argument was supplied by the caller or is the default value. Rather than writing code to check whether the value of the parameter is the default (which doesn't work anyway, if the caller happens to explicitly pass the default value), you can add another variable name to the parameter specifier after the default-value expression. This variable will be bound to true if the caller actually supplied an argument for this parameter and NIL otherwise. [http://www.gigamonkeys.com/book/functions.html](http://www.gigamonkeys.com/book/functions.html) (defun foo (a b &amp;optional (c 3 c-supplied-p)) (list a b c c-supplied-p))
what is your heuristic to omit the strict annotation? I'm using servant in my personal projects but I haven't put much thought into lazy vs. strict. That would bei nice to know!
You could make a separate post with the PDF link and your description as not everyone might see this comment.
There's always http://hackage.haskell.org/package/ghc-justdoit
Remote an option?
Very interesting. It itched to apply since I am simultaneously very interested in haskell, music and machine learning. Unfortunately Utrecht is a bit far from where I am. :D Good luck though. The better your app gets, the more I benefit as a musician :). &amp;#x200B;
I think that is determined on a case-by-case basis.
It's also not all that clear from the listings that there are offices in Portland, OR, as well as the bay area.
It generates positions based on what people are willing to sacrifice instead of what they desire.
Scalpel just dropped the curl dependency in the 0.6.0 release because of just these sorts of issues. You can pull in the new version by adding the following to your stack config: ``` extra-deps: - scalpel-0.6.0 ```
I would hate to see this in source code since it's so hard to read. Is there any way to write helper functions or structure your code to avoid having to resort to this pattern?
`fmap . fmap` is actually pretty useful function. We call it `&lt;&lt;$&gt;&gt;` (and have in our own alternative prelude). It has the following signature: (&lt;&lt;$&gt;&gt;) :: (Functor f, Functor g) =&gt; (a -&gt; b) -&gt; f (g a) -&gt; f (g b) It becomes very useful when you want to work with nested structures. Two nested functors is a very common case: 1. `IO (Maybe a)`: if you get environment variable or trying to get possibly non-existing file path. 2. `[Either Err a]`: list of results for evaluating some function that can fail.
It reminds me of [Edward Kmett's talk on Lenses](https://m.youtube.com/watch?v=cefnmjtAolY). It begins with `(.)` `(.).(.)` `(.).(.).(.)` and `fmap` `fmap . fmap` `fmap . fmap . fmap`, which is pretty intimidating at first glance.
It seems the type signature of \`(&lt;\*&gt;)\` is wrong? The listed signature is: (&lt;*&gt;) :: (Applicative f1) =&gt; f1 (a -&gt; b) -&gt; f1 c -&gt; f1 d When ghci gives us: (&lt;*&gt;) :: Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b In fact it would seem the only way to get the former type signature requires impure functions (e.g. `undefined` or `unsafeCoerce`).
It works as a type family. \`type family F a; type instance F () = Int\` and then \`class Foo a where foo :: a -&gt; F a -&gt; IO ()\` I wouldn't be surprised if the functional dependency version works on an older GHC.
Sorry, I messed my the path. `ghcup` should work just fine, but `snap-templates` is rejecting `template-haskell-2.14.0.0`, and some other packages need it.
I tested from GHC 7.8.4 to 8.6.4 and it does not work for any of them. Weirdly, changing the definition of `foo` to `foo :: a -&gt; (forall b. C a b =&gt; b) -&gt; IO ()` does!
I use `&lt;$$&gt;` for the same thing :) Sometimes even `&lt;$$$&gt;` :)
Does the internship programme offer re-location for interns from another country?
I personally don't like the name `&lt;$$&gt;` :) And on my previous job we had periodically occurring discussion about this operator name. Some people think that the `&lt;&lt;$&gt;&gt;` name is better, some think that `&lt;$$&gt;`. For me the `&lt;&lt;$&gt;&gt;` operator name always was more intuitive. Double angles show how deep is nesting. 1. `$` for plain function application. 2. `&lt;$&gt;` for one-level deep Functor application. 3. `&lt;&lt;$&gt;&gt;` for two-level deep Functor application. Since operator `&lt;$$&gt;` has two dollars inside, it kinda suggests that there are two function applications. Also, `&lt;$$&gt;` is taken for many other different things according to Hoogle: * https://hoogle.haskell.org/?hoogle=%3C%24%24%3E
I use `(fmap . fmap)` all the time as well, along with relatives; in fact, I can even find [an instance of `(fmap . fmap . fmap . fmap)`](https://github.com/bradrn/cellular-automata/blob/17aee4db7ae8f79c9b0907c4e1b234d89ba65902/cellular-automata-alpaca/src/CA/ALPACA/Parse.hs#L117) in my code! I've never thought of giving it a name though; that'll definitely be useful if I need it a lot.
Hello there! I am a bot raising awareness of Alpacas Here is an Alpaca Fact: The scientific name for alpacas is Vicugna pacos. There are only two breeds of alpacas: Suri alpacas and Huacaya alpacas. ______ | [Info](https://github.com/soham96/AlpacaBot/blob/master/README.md)| [Code](https://github.com/soham96/AlpacaBot)| [Feedback](http://np.reddit.com/message/compose/?to=JustAnAlpacaBot&amp;subject=Feedback)| [Contribute Fact](http://np.reddit.com/message/compose/?to=JustAnAlpacaBot&amp;subject=Fact) ____ If you liked this fact, consider donating [here](https://github.com/soham96/AlpacaBot/blob/master/README.md)
You're free to. But easy availability and consistent usage of containers, text, hashmaps, and other libraries fundamental to the ecosystem _in_ prelude is controversial to majority? I doubt it. RIO might be more controversial (people who actually used RIO praise it in this subreddit itself) but MTL is still available. Also, the comeback isn't as impactful as you seem to think it is. A more considered position would have convinced me better. 
It's probably an intended behavior. GHC can't guarantee global consistence of instances, so the following situation can be set up. (It uses `ExistentialQuantification` but `RankNTypes` also enables this shenanigans) module A where class F a b | a -&gt; b data Some a = forall b. F a b =&gt; MkSome b module B where import A instance F () Bool -- There is no reason GHC should reject it b :: Bool -&gt; Some () b x = MkSome x module C where import A instance F () Int -- If `c` is okay... c :: forall b. F () b =&gt; b -&gt; Int c x = x -- .. then `woops` is possible. woops :: Some () -&gt; Int woops (MkSome x) = c x module D where -- Importing both B and C doesn't cause compile error -- (IDK it's good or bad, but creepy for sure) import B import C -- unsafeCoerce! d :: Bool -&gt; Int d = woops . b BTW, `TypeFamilies` rejects similar settings at different point. module A where type family F (a :: *) :: * module B where import A type instance F () = Bool module C where import A type instance F () = Int module D where -- Just importing both B and C causes compile error! import B import C
I was working on some Reflex code and ended up defining `fmap2 = fmap . fmap` and also `fmap3` just because there were so many contexts to map through in some cases. I don't think `&lt;&lt;&lt;$&gt;&gt;&gt;` looks very pretty, and I'm kinda loathe to introduce new operators, though I do accept your reasoning for `&lt;&lt;$&gt;&gt;` - it does seem natural, just not scalable.
I also don't like introducing new operators. But, according to my practice, cases with more than two nested functors appear quite rare. But two nested functors are quite common. If I need to work with deep nested functors, I probably would define separate helper function with explicit type annotation rather than using something like `fmap4 transformUser`. It seems like the code that abuses generic deep functor applications might be harder to refactor because of huge and confusing type errors. That's why I'm okay with the fact that the approach is not scalable. I guess packages like this one shows why it's a bad idea to try to achieve generalisation via syntactic name: * https://hackage.haskell.org/package/composition-extra-2.0.0/docs/Data-Functor-Syntax.html
I like to us `Compose` from `Data.Functor.Compose` instead: ``` Prelude Data.Functor.Compose&gt; fmap (fmap (+1)) (Just (Just 1)) Just (Just 2) Prelude Data.Functor.Compose&gt; fmap (+1) (Compose (Just (Just 1))) Compose (Just (Just 2)) ```
Yes, we use `Compose` in production as well! We have tests that depend on time. And we need to create test data at runtime. So we have functions like this: mkTestUser1 :: UTCTime -&gt; User But when I want to test insertion into DB, I can't test insertion of functions, I need to work with values of type `[(Id User, User)]`. So having the following nice idiomatic operator: (??) :: Functor f =&gt; f (a -&gt; b) -&gt; a -&gt; f b I can write: insertReadingSpec = describe "insert reading" $ do cur &lt;- runIO getCurrentSeconds it "successfully inserts user readings" $ readingCheck $ getCompose $ Compose [ (userId1, user1Reading1), (userId1, user1Reading2) , (userId2, user2Reading) ] ?? cur
Ok, so it sounds like the major issue with ghc on your os was sorted out. The other stuff you're running into is sort of typical development woes. In this case, the problem is that `template-haskell` is tied to the ghc compiler version, and `snap-templates` doesn't yet work with the ghc 8.6 series. The three typical paths would be to either 1) see if you can compile with a newer version just by calling cabal with the `--allow-newer` flag https://www.haskell.org/cabal/users-guide/installing-packages.html#cmdoption-setup-configure-allow-newer 2) failing that, clone the package and fix it up yourself to compile with 8.6, 3) file an issue and wait, or 4) just use ghcup to install ghc 8.4.4.
I suppose this was because the name of the linked file includes APLACA... (deliberately misspelled so I don't trigger the bot again)
Thank you, we greatly value user feedback. I agree that the chord recognition is not perfect. In our defense, it is quite a hard problem. Especially when harmonies are implied. Another problem that we are facing is that musical harmony is subjective up to a considerable extend: what might be the right chords for a beginning guitar player, might not be the right chords for an experienced piano player. 
Small meaning more junior?
Yes , even business department job will do
I wonder how your this relates to [operational-alacarte](https://hackage.haskell.org/package/operational-alacarte). It supports higher-order effects with a rather simple interface (basically the same as [operational](https://hackage.haskell.org/package/operational), but with an `HFunctor` constraint on instructions). But AFAIR, the point of `Freer` is efficient reflection, which I don't think you get from operational/-alacarte. So that's probably a show-stopper. (I haven't been following the work on `Freer` more than just browsing through articles, so sorry if I'm missing something obvious.)
There _is_ a point in encoding the same thing at the type level, and in fact it's the one thing that never seems to get mentioned in these types vs tests discussions. Tests might check if my current function does what's expected, but types will propagate that information to other functions that call the original one. Encoding your example at the type level will matter a lot if I pass the result of that function to some other one that expects different things from it's inputs. You're forced to prove that the requirements are met. That's something tests can't do.
Orphans :(
Website doesn't load for me. Get a cert mismatch error https://i.imgur.com/2oVaw2L.png
I also hope the author is taking about Haskell (or Haskell-like) languages, because you *can* write `RightInteger` with dependent types (assuming you can express what "right" means in higher order constructive logic).
Thanks for the pointer to `operational-alacarte`. I hadn't run into this in my research, but it looks pretty similar. A brief skim over it looks like it falls apart in all the same ways as mine current approach---slow and lacking tools for interpreting things statefully. I'm not sure if that's reassuring or not :) but it's nice to have some other data points in the space. Cheers!
Working URL: [http://www.radicle.xyz.storage.googleapis.com/index.html](http://www.radicle.xyz.storage.googleapis.com/index.html)
Looking into it - meanwhile, I changed the link to http
NP, It's a pleasure! I know that this is a very hard problem and to be honest the precision you already have looks almost like a miracle for me. :)
I can recommend. Worked there for a couple of years. Friendly and knowledgeable people. Felt very comfortable working for them.
Would be really nice to have NixOS install instructions.
I started nix packaging [here](https://github.com/radicle-dev/radicle/pull/385), but never finished it. I just use the [shell.nix](https://github.com/radicle-dev/radicle/tree/master/nix) file and then do a stack build, but I agree proper Nix packaging would be better.
Why don't you link it directly to the blog? i.e. [https://chrisdone.com/posts/data-typeable](https://chrisdone.com/posts/data-typeable)
I don't know type theories behind fundeps, so don't precisely know the lack of global consistency is *the reason* of the rejection. It's possible that accepting something like this is inherently broken. Above code is my 'flex response to your question, so it may not wrong but missing more important point. This may be related? https://ghc.haskell.org/trac/ghc/ticket/4894
Great read! Thanks for the share!
Thanks for the post. On the one hand it's great that it's possible to write fast code in Haskell but on the other it's a pity that it takes so much effort to get there. Do you benchmark most of your code at Channable? What are your heuristics to write reasonably efficient code by default?
Oops, sorry, wrong link! 
For the interested linking also the [discussion on hn](https://news.ycombinator.com/item?id=19367916).
Wow, this is really old blog post. But it is surprising to me, how relevant it is nowadays. `Typeable` had some changes in recent GHC versions, so now it's more type-safe. But one really cool use-case of `Typeable` (that I personally really like) is how you can build fast dependent map on top of it: * https://kowainik.github.io/posts/2018-07-11-typerep-map-step-by-step
We don't benchmark all of the Haskell code we have, but for the service that makes use of the string searching library here, we did a lot of benchmarking and performance optimizations. Making things fast was a primary goal for this system: we do a lot of benchmarking and performance optimization here. Our [job scheduling system](https://tech.channable.com/posts/2017-02-24-how-we-secretly-introduced-haskell-and-got-away-with-it.html) (which is how we got started with production Haskell) was also more performant than the system it replaced. Looking at that repository; it appears we didn't need to do a lot of benchmarking there. We have a few scripts which run a synthetic workload which is a bit higher than what we usually handle. The most important lesson that we learnt there was "choose the right data structures" IIRC. /u/ruuda can probably tell you a lot more about this and verify some of the things I said
Didn't Rob Rix recently release fused-effects that was a huge performance boost in freer-like programming by making the underlying structure look like a recursion scheme?
Nor can you generate code based on tests (e.g generating purescript code based on servant types)
The version using specialized go- functions honestly looks the cleanest to me because the three states don't warrant an interpreter pattern (go + Step). The Step type was probably just a result of coming from the automaton view on things, though. I'm trying to figure out what ghc is struggling with here. product types passed between recursive calls?
If your goal is to guard read and write operations with a mutex there are a couple issues here &amp;#x200B; readMVar dbLock &gt;&gt; readDb' &amp;#x200B; This says: take the talking stick, put it back, then do \`readDb'\`. This doesn't do anything for you. Instead you probably want \`withMVar v (const readDb')\` or something similar. &amp;#x200B; The next thing you need to worry about is that you don't break invariants if an exception is raised (maybe asynchronously) in the middle of your code: &amp;#x200B; takeMVar dbLock &gt;&gt; writeDb' updFn &gt;&gt; putMVar dbLock () &amp;#x200B; This pattern is correct, except that if an exception is raised in \`writeDb'\` the \`putMVar\` will never happen and your program can never recover. Again you probably want \`withMVar\` and should check out the implementation there to see how they make things safe. &amp;#x200B;
Both articles are incredibly interesting, thank you for sharing. In regards to the scheduler, you mention that you opted to ditch MTL-style in because of concurrency. Could you have used the primitives in `lifted-async`?
 RightInteger : (isCorrect : Integer -&gt; Bool) -&gt; Type RightInteger isCorrect = Simga Integer (\i -&gt; isCorrect i = true) :) 
He absolutely did, and `fused-effects` is a huge inspiration of mine! Unfortunately using it requires a bunch of boilerplate, and the goal of this project is to combine the ease-of-use of `freer-simple` with the speed and higher-orderness of `fused-effects`.
This was an interesting read! Thanks :)
&gt; We considered binding the Rust library, but due to the way that Haskell’s foreign function interface interacts with the garbage collector, passing a string to a foreign function requires copying it. That copy alone puts any foreign library at a significant disadvantage, so we decided to see how close we could get in Haskell alone. This is true of `Text` but not true of `ByteString` - with `ByteString` you can [use it with the FFI without a copy](http://hackage.haskell.org/package/bytestring-0.10.8.2/docs/Data-ByteString-Unsafe.html#v:unsafeUseAsCString), provided the FFI call does not keep hold of or modify what it's given.
&gt; This says: take the talking stick, put it back, then do `readDb'`. This doesn't do anything for you. My intention was to let concurrent reads when no writes are in progress. But as you said, it does not seem correct anyway since it won't prevent concurrent writes. I remember the `Lock` class in Java, back in days when I was writing in it. It had methods for acquiring read and write locks explicitly, so thread asking for write lock would have to wait when read lock were issued. Maybe it's as simple as having an `MVar Int` with active read locks and let write lock only when it equals zero? The `takeMVar … &gt;&gt; writeDb' … &gt;&gt; putMVar …` – you are right, I did not think about what happens on write error. Maybe plain `bracket` would be good enough? Or the `withMVar` is just a wrapper around `bracket`… Will check that when I am back at the PC.
could a non-moderator please reply to this? I think they may have shadow banned me for suggesting an inconvenient truth, thanks.
I believe the problem is the sum result of `lookup`. There are two optimizations which can eliminate allocation of results: * constructed product result optimization: the allows us to return something like `(Int, Int)` in two word registers (essentially worker-wrapper but on the result instead of the arguments). However, this obviously doesn't fire in the case of `lookup` since the result is a sum. * inlining: if we were able to inline `lookup.go` then the simplifier could possibly push the allocation site to the case that it is eventually scrutinized by. However, this also doesn't work since `go` is recursive. One way (I believe, but have not checked) around this would be to write `lookup` in CPS'd form: ```haskell lookup :: (State -&gt; r) -&gt; (State -&gt; r) -&gt; CodeUnit -&gt; UVector.Vector Transition -&gt; r lookup left right !input ts = go left right 0 where go :: (State -&gt; r) -&gt; (State -&gt; r) -&gt; Int -&gt; r go left right !i = case ts UVector.! i of t | transitionIsFailure t -&gt; left (transitionState t) t | transitionCodeUnit t == input -&gt; right (transitionState t) _ -&gt; go left right (i + 1) ``` and modify the call-site appropriately (pass continuations to `lookup` instead of scrutinizing its result). This way we allow GHC to avoid allocation without the need for inlining.
Also, I believe /u/osa1 probably has something interesting to contribute here. He was once working on CPR for sums (here is even the beginnings of a [patch](https://phabricator.haskell.org/D2436)).
That worked, thanks. I still don't know what the issue with the ghc package from my os was, but ghcup worked perfectly fine.
The whole 'FFI with Text requires copying' thing surprised me. Turns out Text eventually calls [newByteArray#](http://hackage.haskell.org/package/text-1.2.3.1/docs/src/Data.Text.Array.html#new). Bytestring calls [mallocPlainForeignPtrBytes](http://hackage.haskell.org/package/base-4.12.0.0/docs/src/GHC.ForeignPtr.html) which in turn calls newPinnedByteArray#. mallocPlainForeignPtrBytes allocates pinned memory (e.g. in the haskell heap but without compacting so we might get some external fragmentation). The Plain in the name signifies that we don't use the whole weakref-finalizer. So that sounds like Text could use newPinnedByteArray# without changing much and you could use it in FFI if you take care to touch# the byte array after ffi calls so the gc doesn't free it during ffi? Why doesn't text do this and what are the tradeoffs?
I do see this comment of yours.
Nice to see Haskell being competitive with low level languages. Good work and thanks for writing the blog! I have used similar mutually recursive implementation quite a few times providing the best performance that I could get. This seems to be a good performance pattern.
thank you.
In GHC 8.10, the levity-polymorphic you suggest will be the kind of `Coercible`. This happened as a part of `UnliftedNewtypes`, which is still pending merge but is basically finished.
Try breaking down your example into a smaller example. Cut out everything not related to arrays. Resist the temptation to come up with rationalisations for why your code ought to work. The fact is that it doesn't, and this means you've done something wrong more often than not.
&gt; low level languages Rust doesn't have HKT or a GC, but I wouldn't really consider it low-level, since it does have interface polymorphism (e.g.).
Yeah, some sort of semaphore that readers increment at the start and decrement at the end but don't hold the entire time, where writers hold a linked resource through their critical section. There are fairness / starvation concerns -- who gets the lock if, when it is released, 1 writer and multiple readers are waiting on it? For some workloads you always want a writer to win, for some you always was a reader to win, for some you want to just go fifo.
Are there some ready-to-use solutions for this? Or should I write that little thing myself? What would you use to solve the problem?
I generally view any language which embraces the notion of "zero-cost abstractions" to be low level.
Completely forgot I wrote a ticket [`#13595`](https://gitlab.haskell.org/ghc/ghc/issues/13595) 2 years ago. [`UnliftedNewtypes`](https://github.com/andrewthad/ghc-proposals/blob/unboxed_newtypes/proposals/0000-unlifted-newtypes.rst) is great news
Great, glad I could help you sort this all out! 
I'm using WSL with HVR's GHC and cabal-install without any problems so far. You have to specify exact version that you want to install. Try using this: ``` sudo apt install cabal-install-2.4 ```
Last time I checked (a few years ago) it was like this: * The garbage collector is subdivided into blocks of 4k. * Small objects (&lt;2k I think) get allocated in blocks. Larger objects get allocated separately and never get copied during GC. * Pinning works per block by setting a tag in the GC block header. * Small objects are allocated via bump allocation, and may be copied by the GC. GHC only supports pinned byte arrays which don't have pointers to other objects. So the problem is that allocating a pinned objects is relatively expensive, so you want to avoid it if you can. Also pinning needs to be decided at allocation time. The `text` library chose to use the unpinned primitive because it's faster for the expected common case of smaller strings. ByteString explicitly wants to target FFI use cases, so they take the performance hit when allocating small objects. [code for allocatePinned](https://github.com/ghc/ghc/blob/a54c94f08b938c02cbaf003e23a7ef3352eee19a/rts/sm/Storage.c#L965) 
i believe i had success using ghcup
I had a post weeks ago get removed without comment and then (days later) approved without comment. I suspect there's an over-aggressive automated filter.
So, my solution (so far) is like this: ```haskell -- Lib.hs type Lock = MVar () newLock :: IO Lock newLock = newMVar () withLock :: IO a -&gt; Lock -&gt; IO a withLock io lock = (withMVar lock . const) io ``` and now: ```haskell readDb :: Lock -&gt; IO AppDb readDb = withLock readDb' writeDb :: (AppDb -&gt; AppDb) -&gt; Lock -&gt; IO () writeDb updFn = withLock (writeDb' updFn) ``` So, I have decided it's easier to have just one lock (no read/write) and using `withMVar`. It's SIMPLE (and good enough for my use case).
very good, thank you, it worked
I usually let postgreSQL handle any required locking. :) I like using STM / TVars for any in-memory mutable data, and then STM figures out where to do any locking, if needed. If I did use a MVar, I'd actually store the data in it instead of using it as a lock, using withMVar for writers and readMVar for readers. Readers might be working with an "old version" of data while a "new version" is being created, but it's possible even with ACID databases, and certainly true in the eventually-consistent NoSQL world. If I had to persist something I'd probably skip using UNIX advisory file locking, and just go back to storing data in postgreSQL. :P
That's really great!!! No push to central repo! I suppose that it needs the IPFS daemon or the software has it included?
Okay, just different definitions then. But, under your definition, Rust is low level. (When I learned C++ in '98, they told be it was a high-level language.)
Some people say only assembly is low level. Totally a matter of context and personal definitions tbh.
If I don't have to implement VTables (or some other form of single-dispatch polymorphism) myself, I consider it high-level. If I don't have to implement exception handling via the equivalent of setjmp/longjump (i.e. unstructured non-local control flow), I consider it high-level.
Salary range? You have a splatter of languages on the job posting -- C/C++, Haskell, Rust, Python, node.js -- is this actually Haskell work? 
DOE ranging from $70k to $100k. These positions will specifically be Haskell. 
Well, you are right with storing data within MVar, but I wanted to be able to modify the db.json file while the app is running.
Great post, but one tip: "94% reduction" isn't as clear or as impressive-sounding as "16x faster"
Very interesting read :) &amp;#x200B; btw, why does [https://tech.channable.com/images/automaton.svg](https://tech.channable.com/images/automaton.svg) have failure transitions 4→9 and 5→10? If the 'r' doesn't match the first time, it's not going to match the other time either, right?
Just create a jobs thread. This at least keeps it in one place, and is handy for people looking for a position too.
Let us drown in job postings. They're some of the best and most practical content on the subreddit.
The installation instructions say it does indeed need the IPFS daemon.
My gut feeling is that I prefer the name `&lt;$$&gt;` over `&lt;&lt;$&gt;&gt;` (and `&lt;$$$&gt;` over `&lt;&lt;&lt;$&gt;&gt;&gt;`, and so on) for `fmap . fmap`. *However*, that goes against the naming conventions in `base`. (Well, in my opinion.) Specifically, we have the functions `&lt;*&gt;` and `&lt;**&gt;` in `Control.Applicative`, and the relation (&lt;**&gt;) = flip (&lt;*&gt;) So, I feel it would only make sense (and maybe this would be useful to have in `base`?) that (&lt;$$&gt;) = flip (&lt;$&gt;) (Especially in light of the fact that we often use the `Functor` &amp; `Applicative` operators together, &amp; they have similar naming conventions.) If you accept this much, then of course the name `&lt;$$&gt;` is already taken and so you have no choice but to use `&lt;&lt;$&gt;&gt;` to denote `fmap . fmap` instead.
Rust brands itself a systems language, because it makes you care about low-level details such as memory layout, allocation and lifetime. In turn, this required level of detail prevents abstraction to some degree. So in that sense I think it's justified to call it a low level language. Consider that because of its memory ownership restrictions, Rust doesn't let you easily tap into the power of lambda calculus: variable capture is very much restricted, unless you go out of your way to manage the memory more automatically, but then you risk ending up with reference counting cycles and memory leaks! 
Rust brands itself a systems language, because it makes you care about low-level details such as memory layout, allocation and lifetime. In turn, this required level of detail prevents abstraction to some degree. So in that sense I think it's justified to call it a low level language. Consider that because of its memory ownership restrictions, Rust doesn't let you easily tap into the power of lambda calculus: variable capture is very much restricted, unless you go out of your way to manage the memory more automatically, but then you risk ending up with reference counting cycles and memory leaks! 
OK, I'll need to read more carefully to figure out what the problem is wrt. state interpretation. Just a note: The motivation behind `operational-alacarte` was code-generating EDSLs, so neither state handling nor performance was a concern. Higher-order effects are required in order to support code generation of control statements.
Yes definitely. I played around with it and there is probably still a branch floating around that uses `lifted-async`. Though I don't think we ever merged it. Maybe they do something else now.
Personally I think they are interesting even if not looking for work. It would be great to have guidelines. Don't have strong opinions there, but I think all the examples you gave are good ones.
lol not all are (but i do like the ones that are actually "you'll spend the majority of your workday on writing Haskell").
I guess that definition is much closer to the concept of… *levelness*? :D But people use "low-level" to mean "closer to metal", "no runtime", "no overhead" because that's convenient
I think this is a pretty good heuristic, which would place Rust somewhere in the middle for its lack of non-local control flow. IMO there are multiple dimensions of the high/low-level qualification. Performance is one axis, complexity or sophistication another. It seems like historically these categories were mostly inverse, but with improvements in language design and compiler tech (advances in static analyses), we could start to see these approach orthogonality. I always considered Haskell to be “higher” level than JS, and not necessarily for the fancy, threaded, generational GC. The type system and machine model in Haskell are conceptually further divorced from the machine language than JS. But this also enables some fancy optimization. I believe (hope?) we are quickly approaching a point where it becomes easier and more terse to express programs in static langs than dynamic ones. For this reason, and the design lineage of Haskell, I can’t decide if Rust is higher or lower level than JS. I think the answer is it’s lower along one dimension, and higher on another; I wouldn’t be surprised to see people start to consider strongly, statically typed languages like Rust as higher level, on balance, than its “dumber” weak/dynamic counterparts.
Continuous benchmarking and performance tracking is something that we are actively working towards. We have this string search benchmark and a few other microbenchmarks, and we do have tooling to profile a given workload, but so far most of our performance work has been reactive rather than proactive. Our workloads vary a lot, so it is difficult to see in advance whether something will be a bottleneck or not; some things only become problematic for 1% of users with an unusual feed. We track processing times in production and investigate slowness, and often there is a clear bottleneck that is not hard to resolve, but just something we did not look into before. String search was a major bottleneck before we started optimizing it, that turned out to be a bit more challenging to resolve.
Oh, for some reason I thought that Rust did have an exception system, but it makes sense that lifetimes would be more complicated with them. C = low-level, Rust = mid-level, C++ = high-level. Haskell/Python/JS = cloud-level, Assembly = ground-level. ;)
That is an interesting observation. The failure edges point to the state after the longest suffix of the inputs up to that state — this is how Aho–Corasick constructs the automaton — and for `tshi` that is `shi`. You are right that in this case the arrows could be pushed back, but in general, there might have been an additional transition away from state 9.
I don't think that's a good plan. That sort of like hex-editing your database storage while the DB is running; a good way to get data corruption and races.
I think it's coincidental that several job postings have shown up recently. There are still very, very few Haskell companies that are actively hiring (at least that I'm aware of). While I'd prefer maximal interaction, I think even the laziest of job postings are still worth having front and center. For now. Guidelines and a template do seem like a good idea though. If we have weekly job posting threads most will be empty, unless the same companies repost listings (which may be good a thing).
At the same time I kind of cringe at the notion C++ is higher-level than Rust. I started with a huge response, which I decided to just post on r/Rust 
I'll see it there, then. I'm not as active on that subreddit, but I am subscribed. I have only done very little Rust, but I did spend a weekend learning it.
This looks like what we [ended up with](https://github.com/channable/alfred-margaret/blob/72295ccb5a889cd7641ba3f600055baaddbd9721/src/Data/Text/AhoCorasick/Automaton.hs#L508-L527), only we hard-coded `left` and `right`. So we might be able to factor the big function again into CPS-pieces. That is interesting to know, thanks!
The database is a JSON file. When using "real" databases – one can access (read/write) it while the app is running, there is no much difference here.
&gt; To build Radicle from source you will need stack. It would be nice to have build instructions for those of us who don't want or can't use Stack. We still exist. 
What do you mean? Can you write a couple of examples for how you want to use `date2Str`, i.e. what would you put into the function, and what would yo uget out?
I suggest linking the white paper directly.
A couple other subs I'm in require some level of details, especially salary. I think that's healthy. I find the job postings interesting, even though I'm not actively programming Haskell or looking for a Haskell job right now.
Not, you can't let arbitrary programs fiddle with your DB storage and expect your data to survive. You *can* have multiple clients connecting to the same database service, but that database service will ensure accesses to the files are consistent, through a combination of scheduling, locks, and write-ahead logs. There's one service (could be multiple processes) that ensures correct access to the storage. You could write that service as one or more Haskell processes and you might use MVars as part of that. But, you'd need to ensure that service is always used as a gateway to the data. If you are on a POSIX-ish system, you can use advisory file locking to synchronize between two different processes, but it is only advisory (at least on even POSIX-ish system I've been on), so processes that choose not to check the lock can also access the file and potentially incorrectly access it.
The only rule should be that the job is actually a Haskell job, and not just a Scala/non-Haskell recruiter trying to trick Haskellers.
Thanks for the information! `&lt;&lt;*&gt;&gt;` is a nice and intuitive replacement for `fmap . fmap` :-) That's right, and using something like a MaybeT, EitherT, etc. (i.e., monad transformers which are nested structures by definition) give this (fmap . fmap) for free when used with &lt;$&gt; or &lt;\*&gt; too - for example, `(MaybeT IO a)` is `IO (Maybe a)`. 
I don't think there's enough of them yet to be a problem. I think that a stickied, monthly, job thread would be a simple solution if it does turn into a problem. I really like the stickied, monthly, AUA thread, probably even a better solution than /r/haskellquestions 
Super! And thanks for catching this typo :-) I corrected this in the article. 
Once half the /r/Haskell front page is job posts we can ban them and create a job-post-specific channel. Until then, I'll keep bookmarking each job post for future reference :)
Good idea. Weekly/monthly rolling jobs thread - stickied. Haskell is at a point where the tech and ecosystem can solve most industry problems well. What we need now is opportune for people to get professional production reps. That's literally the only knock I hear against Haskell by senior management lately.
We already have `flip fmap`, and it is `&lt;&amp;&gt;` from Data.Functor. Similarly to `&amp;` from Data.Function. myVal &amp; toList &lt;&amp;&gt; filter good Awesome :)
Is it possible to define a datatype `Var` such that `Var` comprises "non-empty strings of letters or such strings followed by digits"? I want to define functions from `Var` such as "assigning function" `assign :: Var -&gt; Int`. Moreover, is `Var` a dependent type? I'm new to type theory...
It's actually more impressive-*sounding*.
Which perfectly reflects reality: Dan Piponi needs food on his table (and also a place to live, new clothes etc.). If Dan Piponi spends his time writing about math and Haskell, someone else needs to provide these things. That’s where the sacrifice comes in.
My advice would be to immerse yourself in the community, read and write lots of code and keep in touch with other haskellers - both online, worldwide, and locally, IRL. Haskell is a fast-moving ecosystem, new stuff appears almost daily, it's hard to pinpoint any handful of specific things as "essential", beyond learning the basics, and people don't necessarily agree on any particular set of recommended "design patterns" and "best practices", to the point that using those phrases might produce a few sighs and rolling eyes. You may also enjoy Stephen Diehl's "What I Wish I Knew...": http://dev.stephendiehl.com/hask/ - you don't need to be deeply familiar with every single thing in there as it's quite comprehensive, but it is a great resource to come back to regularly, and at least skimming it once in its entirety will give a decent idea of what's out there. One thing about "industrial Haskell" that may not be immediately obvious is that you will often have to interface with things "not-Haskell"; so having some experience in a few mainstream languages and key technologies definitely pays off - if you know your C and your JavaScript, and maybe some Java or C# or some such, it will be a lot easier to translate between paradigms and mindsets. But in the end, the most important thing is experience, i.e., get your hands dirty and build things.
This is not a direct answer to your question but maybe my two cents about how I learned Haskell on the job might be of use. I read some intro books and posts on how to understand the basics of the language and basically got started on a project as quickly as I could, even though trying to read code from more advanced Haskell developers was intimidating (lots of abstractions, use of unfamiliar or custom operators, etc...). The code I wrote was ugly but it allowed me to slowly pick up concepts over time. I would write some code, maybe read some more Haskell material at night and realize that there were better ways to compose functions or use types to my advantage. I still wouldn't describe myself as an advanced Haskell developer, but I have over 10,000 lines of Haskell in production that's battle tested and probably the most reliable backend code at our company. I guess that makes me an industry level haskell programmer? 🙂
I'm not a professional Haskell programmer (or indeed any sort of professional programmer), but I would strongly recommend "What I Wish I Knew..." as well - it's how I found out about most of the Haskell ecosystem.
I‘m not a professional but from my thorough research and own use of Haskell, I can say that the following libraries are used often in industry: Web - Servant - Yesod DB - Persistent/Esqueleto - postgresql-simple Common stuff - base - mtl - transformers - text - bytestring - containers - vector Parsers - megaparsec - parsec - attoparsec Patterns - ReaderT design pattern This is ofcourse subjective but knowing these will make you very productive in a lot of contexts. Also it‘s not necessary to be pro at advanced type level programming.
From my experience the top five things if you're serious about industry level programming are 1. [Stack](https://docs.haskellstack.org/en/stable/README/) 2. [Stackage (stable vetted industry grade packages)](http://www.stackage.org) 3. GHC (Stack installs it for you) 4. [RIO Haskell Standard Library](https://www.reddit.com/r/haskell/comments/ayoluu/rio_the_standard_library_for_haskell/) 5. ["Commercial Haskell Accelerator" (a collection of best practices and best in class libraries)](https://haskell.fpcomplete.com/)
I don't think it would be a good use of the developers time to spend on maintaining support for less common redundant tooling they don't use themselves. Why can't you use Stack? 
&gt; pinning needs to be decided at allocation time That’s a bummer. I wonder how involved it would be to update the RTS to support per-object dynamic pinning. In Mono (SGen) we implemented this by tagging object pointers with a “pinned” bit during collections—we had spare bits since all objects are aligned. This is to support the C#/F# `fixed` statement, which lets you pin an object explicitly for the duration of a block, as well as objects that can’t be moved because they may be referenced by the stack/registers—which are scanned conservatively, absent precise stack maps. It does make some things more complicated—you can get fragmentation in the nursery and can’t free blocks that contain pinned objects—but it is very useful for avoiding copying when interacting with foreign code. 
I personally don't mind as long as the company itself is posting and some recruiting agency. 
Do you plan on putting your package on Hackage?
- mtl / monad transformers - lenses - go read "What I wish I knew when leaning Haskell".
According to my experience using Haskell in production, technical skills can be picked up by everyone: `mtl`, `servant`, `lens`, `aeson`, generics, type-level programming, etc. You can learn all that stuff, there always will be something in Haskell that you don't know but need to use in your particular problem. So, for me, top five essential things are: 1. Don't be afraid when you don't know something or don't understanding some discussions in the community. If some people like to dive into complicated stuff you don't understand, this doesn't mean you are a bad developer. A lot of people discuss lenses, but at the same time a huge amount of great software was written without lenses. 2. Be kind to other developers. Haskellers really like their programming language, and it hurts a lot that this language is not that popular, or when somebody says that the language only for academia. But this is not an excuse to throw poop into other languages or tools. 3. Communication – first, programming – second. If some library has bugs or doesn't support your case, it's not a reason to be an asshole in the issue description saying that this library or tool is unusable. There is always something that can be improved. Or probably there are reasons to doing things in that particular way. Or probably authors have their own opinion about the library usage. You can always discuss such problems and, if you want to contribute, discuss possible implementation plan before change whole code. 4. Be open to other ideas. If you like some way of structuring your application, don't say that other people who are writing in different way are wrong. Today you may like to write SQL queries in your Haskell application, but tomorrow you might want to experiment with some ORM library. If you like ORM more, don't run around saying that people who write raw SQL are crazy, and that we all should squeeze as much compile-time guarantees as possible. 5. Be tolerant to beginners. Believe me, there will be a lot of questions like "What IDE to use with Haskell?". The fact that this particular question has been asked many times doesn't mean that the answer is easy to find for beginners. You might think that this is not relevant to industrial Haskell usage, but usually software is written in teams. And to my experience, most software failures happens not because you don't have enough geniuses, but because of poor communication.
&gt; What are your heuristics to write reasonably efficient code by default? I’m not at Channable, but off the top of my head, here are some rules of thumb that I tend to follow: * Make data structure fields strict unless they need to be lazy, especially if you know you’re going to examine the whole structure anyway * Use lists as control structures, not data structures—you probably want `Vector`, `Text`, `ByteString`, `IntMap`, &amp;c. for data, and to avoid roundtripping between these and lists * Avoid needless indirections, redundant traversals, &amp;c.—asymptotic complexity is your first line of defense * Use zero-cost abstractions like `coerce` where applicable * When possible, write functions in terms of building blocks like `foldr` which the compiler knows how to aggressively optimise * Write lazy functions that can “stream” results, or tail-recursive functions with strict accumulators, to avoid needlessly retaining a lot of allocations (of data or thunks) * Use `ST` for local mutation unless you need the persistence/backtracking offered by pure `State` * If you’re already in `IO`, use exceptions instead of `Maybe` for early exit (saving a test on every bind) * CPSify things judiciously, or more generally, avoid reifying data that can reasonably be encoded into the structure of the program * Pay attention to memoisation and whether you’re missing an opportunity to make something a CAF 
It's possible to do even without dependent types. data Digit = One | Two | ... data Character = A | B | C ... data Var = Var Character [Either Digit Character] But most likely it won't be convenient at all to work with such type! It's more convenient to have: newtype Var = Var { unVar :: Text } mkVar :: Text -&gt; Maybe Var So you will perform validation of text data at runtime. Dependent types probably will allow to have more convenient runtime type representation while having all your checks at compile-time.
I think these points are very important and are often not stressed on enough. And I do believe the core 5 points should be applicable when using/learning any language or platform :) 
I'm a fan of stack and I am grateful/admire the contributions that FPCo makes to the community, but don't you think your answer was a bit too biased ? Then again, you said it's from \*your\* experience, so ¯\\\_(ツ)\_/¯ 
Great writeup, and provides some good intuition for optimisation and writing performant code generally. &amp;#x200B; Also, at first I misread the title as “séarch strings” (noun phrase) instead of “search stríngs” (verb + noun) and got excited to learn about a new data structure, the “search string”.
Guidelines are probably necessary, but don't stop them, please. It's one of the main reasons I open this sub-reddit every morning. 
I second a couple of remarks made by others: - only by companies hiring directly, no middlemen/recruiters - require at least some details on compensatio (like, salary, benefits, etc.) - perhaps dedicated stickied thread for job postings if they become too frequent
There should be a policy for the comments too. The other day I saw a job posting and half the comments were about how the company was unethical (I think it was Facebook). I think it's okay to criticize a company if they are known to be a bad employer, but getting political about about the company itself is only hurting Haskell adoption
Potentially. This will depend on the circumstances and how easy it is to arrange travel/visas from your country.
Or better: RightInteger : (isCorrect : Integer -&gt; Prop) -&gt; Type RightInteger = Sigma Integer Cuz curry-howard &gt; boolean blindness :P
I'll go from more basic stuff that it seems was missed by others. I'll also not focus on libraries but rather topics that are important (some of them are related to some libraries / design patterns). 1. lazy evaluation; there aren't many good resources on this. Well-Type has a very good training on performance and optimizations that covers this in detail. Duncan Coutts had an excellent talk at Monadic Warsaw https://www.youtube.com/watch?v=ofchfWw16eM, though the recording is not the best 2. Chris Okasaki book "Purely Functional Data Structures" - that's a very important book. Lot's of the time your application will need the right data structure with the right computational complexity for the given use case. When to use arrays (or rather not to use them), binary trees or fingertrees, ... 3. Good understanding of exceptions and asynchronous exceptions, masking. 4. Related to 1: strictness: how and when to use it to avoid space leaks. 5. I'll put various things here: recursive data structures to describe program evolution; a way of describing programs using data types (related to previous); Understanding memory consumption of simple (and not only) functions.
You are right. If I create wrap db access with locks within my app and, while it runs, edit the file, I am going around that locks and I can overwrite changes. I should not do it. I will leave it "as is" until I make some actual progress with the application logic (it's a Discord bot for Semux blockchain) and IF the bot proves itself actually to be useful, I will replace the db layer with regular database (thinking about MongoDB Atlas service, all I need is to store few objects).
i want job ads to be here; if someone feels the quality of a particular ad is low then can down vote it
Thank you very much!
Thanks for your reply! But I want something like `assign "x1" = 2`. I happened to hear about [liquidhaskell](https://github.com/ucsd-progsys/liquidhaskell) just now. Maybe it is a solution.
I'll be the party pooper: 1. Don't create preliminary abstraction just because you can and want to. It'll come back to you. Half of your abstraction will be useless in the end and hard to remove. 2. Don't write elegant code. Ever. Write simple code, strive for clarity. Elegant code usually ends up being an unnecessary intellectual burden that wastes everyones time whenever someone has to touch that part of the code. And it barely has any real benefit, except being elegant. 3. Don't follow the latest hypes. Solve problems with the simplest possible tools. Like functions. If you need to enable 10 GHC extensions, create huge monad stacks and use lenses for everything possible, then something is wrong. Use expressivity wisely. It comes with a price. 4. Don't try to express everything in the type system. Sometimes a little more information in your types can cause huge burden for your API. Weigh the benefits. Do you really need typed printf with dependent types? 5. Don't use haskell-tls, directory, filepath,... Seriously examine the correctness of the libraries you use. Strong types don't make everything automagically correct, especially when it's about low level behaviour. And remember: deleting code is better than writing code ;) (thanks Igor) 
&gt; I wonder if this is actually still something we want? Yes, absolutely! It makes me happy to see so many Haskell jobs given so much visibility in this community. &gt; should there be guidelines? I would prefer no guidelines. All the things you mention would be nice to have, but if someone wants to post a job that doesn't meet all the criteria, I would still encourage them to do so. (I say this as a moderator here, the editor of Haskell Weekly, and someone who has posted jobs here before.) The only rule I'm interested in enforcing is that the job is actually a Haskell job. Several other people have mentioned that already, and that's how the moderators generally respond to job postings as well. 
excuse me, who is giant? FP Complete? &lt;here is the face of Pepe the frog&gt;
reader monad is just function. So how function and its argument is related to "industry level programming" and is it really a "pattern"? 
let me google it for you: &amp;#x200B; [http://lmgtfy.com/?q=haskell+readert+design+pattern](http://lmgtfy.com/?q=haskell+readert+design+pattern)
1. What does JavaScript have? What does Python have? What does C++ have? What does PHP have? Having a single "giant" as a driving force behind a programming language is one way to do it, but it's not the only one. 2. In the sense that C# "has" Microsoft, and Swift "has" Apple, Haskell doesn't "have" FP Complete, or Tweag - both are highly visible users who contribute a lot to the ecosystem; but in terms of overall funding and donated labor, Microsoft Research and Facebook are probably the biggest forces supporting GHC. After that, support comes from a diverse group of organizations and individuals: industry users, consultancy firms (like FP Complete etc.), but there are also significant (and crucial) contributions coming from academic institutions, and many individual contributors. There are/were also government subsidies flowing into the ecosystem; IIRC the whole thing was bootstrapped on a UK government grant. 3. And let's not forget that Haskell has been a committee effort from day 1, and that has made it what it is - I don't think a language like Haskell could realistically come about if there were only one company behind it with one relatively specific agenda. 4. Strong feelings against FP Complete in the community aren't so much based on the code they produce; from a technical point of view, there is nothing wrong with the libraries etc., and the quality standard they deliver ranges from perfectly fine to pretty damn good. What people oppose isn't so much the code, but the way FP Complete as an organization, and its key people as individuals, behave or have behaved. I won't pick sides here, but there have been allegations of attempting a "hostile takeover", of trying to destroy existing library ecosystems and tooling (especially Hackage and Cabal), and of using their libraries and tools to gain power over the community, the ecosystem, and the language itself. There are also allegations of manipulative language use, false or misleading advertising, and disruptive / polarizing behavior. Of course there are also those who actually dislike FPComplete's vision of what programming in Haskell should look like, and there's plenty of civilized discussion about those things - but that's not usually the source of raging hatred, it's just something where everyone has their preferences, and that's that. 5. As someone who participates in the development of GHC and its ecosystem, you can rest assured that Haskell isn't going anywhere any time soon. Several people are committed full-time to the GHC project, and we have funding and donated labor and infrastructure coming in from many different sources. More is always welcome, but it is very unlikely for all that to dry out on a whim, and there isn't a single organization that could take the project in a radically different direction and leave you standing in the rain.
This. So much this. I have a couple small comments. In #2, I would s/elegant/clever/. And then in #5 not sure what is being referred to by "haskell-tls, directory, filepath, ...".
What’s wrong with directory and filepath?
I was onboard until #4. I looked at RIO yesterday and it is self marketed as pre-release. That hardly constitutes advice for someone just getting started. Not that it isn’t good (I haven’t tried yet). Just seems like this comment is more in the best interests of FPCo and not a genuine answer for the top 5 things to pay attention to as a new Haskell dev.
I was trying to have the inputs all be of types common to noot-DT languages. Even non-DT folk can understand the idea of carrying around a "property" / Boolean test. But, yeah, I try and avoid Boolean blindness in non-DT languages, so I always try and carry proofs around in DT languages.
Oh no not lenses, lenses are another language, and the question was about Haskell ;)
You can give the `Var` type in the `GP` an `IsString` instance (though you'll probably have to use `error`) and turn on `OverloadedStrings` so that you can use string literals for values of your type. You example uses a string literal as a pattern; I'm not sure if `OverloadedStrings` handles that.
Well, Java have Oracle and that hasn't been exactly productive for a long while.
Interestingly, some of the tests I added to the test suite for this feature are just copied from [examples you gave](https://github.com/ghc-proposals/ghc-proposals/pull/98#issuecomment-349519774) of things you would try to write if the `UnliftedNewtypes` extension were available.
Aaaah... yeah, you're absolutely right. I didn't realize that was in \`base\`. Not sure what to think about this now!
On closer look, it looks like it could probably handle state by directly taking the `Syntax` class out of "Effect Handlers in Scope". The interpretation in `operational-alacarte` is fundamentally tied to the `Interp` class, yeah?
1. Taste. Haskell is very expressive and has a high abstraction ceiling. Don't be tempted to shoot off to the Moon. Every bit of code must pay its own way and advanced code must be justified. Spend most of your time in Haskell 98 and tastefully use other features when the cost of complexity gives you a large ROI. 2. Tests. Some Haskellers malign tests. In industry this is a foolish thing to do. Expressive types, pure functions, immutability and tests work in concert to create huge levels of assurance. 3. Tooling. Haskell has great tooling. Get your team using it. `hlint`, `weeder`, `hoogle`, `fast-tags`, `brittany`, and more. These tools allow you to keep your codebase clean and discoverable. 4. Training. Even Haskellers with experience will require training. There are very few opportunities for production Haskell work, so sharing experience is paramount. Found something good? Stubbed your toe? Share that information with your team in a sustainable way. Even better write a blog post and maintain a company blog. 5. Teamwork. For teams to work well they need to when together. This usually means establishing norms (Tuckman's norming, storming, performing). Haskell is a large language, figure out what Haskell means to your team. Document it. Code review it. Discuss it. Work with your team to decide what industrial Haskell looks like for you (this is different at every company).
I think the first five have been well covered elsewhere here. But I want to add my #6: &amp;#x200B; 6. When (not if) you encounter the painful mini-civil-war over stack vs cabal (Stackage/Hackage) (possibly vs nix as well)...don't get discouraged. If you're in a team, use what they use. Easy. If you're starting a team, do your research, pick what you want. Move on. There will always be people who want to fight about things. Just ignore that as much as you can and get stuff done. I've used all three extensively and none of them is as bad or as good as people say. :P &amp;#x200B;
Any good book/ressources to learn this material?
Oh, of course - I'd recommend it for any Haskell programmer, whether professional or not.
1. [https://goalkicker.com/HaskellBook/](https://goalkicker.com/HaskellBook/) 2. [https://www.manning.com/books/get-programming-with-haskell](https://www.manning.com/books/get-programming-with-haskell) 3. [https://www.manning.com/books/haskell-in-depth](https://www.manning.com/books/haskell-in-depth) &amp;#x200B;
Of the lists so far, this is the most accurate for working at my company. As far as resources go, the Yesod book can help you learn Yesod/Persistent basics. If you can make a small site with what you learn and put it on Github, that’s even better. On that note, I always search applicants on github to see how they present issues, do their PRs look good, etc. So contributing to open source Haskell is good too
&gt; What does Haskell have? The giants: FP Complete, Tweag, etc. I personally think it's great and relieved that a corporation isn't behind Haskell. &gt; I'm glad to know that when I use Haskell, there are giants out there who have my back. I think it's a fallacy to believe that. It's probably what any "giant" wants you to believe--and if you do, you're obviously free to do so. "Giants," as in large corporations, are there to make money and nothing more. 
Yes please! I posted about [SimSpace's remote positions](https://www.reddit.com/r/haskell/comments/8u35gj/job_simspace_is_hiring_remote_and_local_haskellers/) a while back, and we are continuing to grow and so we continue to have remote positions available; but I no longer feel like it's adequate to write another top-level post on the topic, since nothing is new since last time. I would be much more comfortable posting in a monthly jobs thread.
This is solid advice almost regardless of what languages your codebase contains.
The #1 most important thing is to not go full fancy. If you go full fancy, you'll code yourself into a corner and waste time wrangling abstractions rather than getting shit done. This will torpedo the project and further harm Haskell's reputation. The second most important thing is to actually deliver working code. Haskell makes this really easy provided you do #1 right. It's one of the few places where doing the easy and obvious thing is the right choice. The third thing is to take the smart people with a grain of salt. There are a ton of *really, really, really* smart people in the Haskell community. They don't know how smart they are, and they're going to recommend you ignore rule #1. They'll tell you how they went full-fancy and it was awesome. They'll tell you how the dumb/simple/easy thing is not good enough for (reasons), even though the dumb/simple/easy thing in Haskell is light years ahead of Java or Go or Ruby. The Haskell community has a wide variety of viewpoints and perspectives. Only a portion of them will be relevant to you. Haskellers working in academia have a dramatically different set of priorities and goals than industrial Haskell. When you examine a library, blog post, etc. try to identify how the person has used Haskell, and in what contexts their advice *is* relevant. 
Scala postings should be replied to with this link: https://www.reddit.com/r/haskell/comments/1pjjy5/odersky_the_trouble_with_types_strange_loop_2013/cd3bgcu/ And then deleted after an hour :)
I don't like the negativity towards job postings either, but I don't think guidelines are the right solution.
&gt;Don't [...] use lenses for everything possible Well, that is what `lens` is for!
There's also Well-Typed who are pushing ghc forward. Check the work on ghc's GC by Ben Gamari https://youtu.be/7_ig6r2C-d4 And let's not forget that SPJ works for Microsoft Research. There are also lots of CS university departments advancing the studies of lambda calculus (broadly speaking) - that's even better than any large corpo. 
\+1 for Taste. I came to Haskell as a very young software engineer. I had not yet been hardened by various lessons you learn by just being an industrial programmer for a while. For me Haskell started as an intellectual pursuit, that incidentally happened to have a lot of benefits for industry. This did not stop me from selling these benefits (they are real of course), But I have lately had to start learning some of these hard lessons that type safety, point-freeing, and abstraction, are not monotonically good. &amp;#x200B; All that said, some people in the community may tell me "I told you so", but I also want to offer a different perspective. The advice above is good, and should be listened to if possible. But if you are genuinely attracted to Haskell at all, you will get this wrong sometimes, and that's OK, we all make mistakes and learn from them. What is important is that as an industrial programmer, while it may be OK to make mistakes, it is unlikely to be successful to operate under an academic value system. So never forget the point of what you're doing and strive to balance the amazing expressivity you get from Haskell, with the ugly world that is industrial programming. The better you get this balance, the more prosperous you will be in your work.
Is there a way to remove the boilerplate from `fused-effects` without rewriting it? Say, introduce type-level functions that let one write ``` action :: m &lt;=&gt; [State String, Writer Int] =&gt; m () ``` And the `&lt;=&gt;` is a type-level operator that would expand it into the verbose ``` action :: (Member (State String) sig , Member (Reader Int) sig, , Carrier sig m) =&gt; m () ```
where I can read about financial results of the "FP Complete" giant? I heard that their employees work in University and are not on full time in this hobby-company or I am wrong?
Congrats on the 150th issue
The analogy doesn't hold at all. Microsoft _created_ C#. Apple _created_ Swift. Both own the language, and both keep elements of it proprietary. Haskell was not created by a company. It was created by a committee of researchers explicitly as a free specification and the leading compiler is released under a free software license. Core development on it, while MSR-paid-researchers play a leading role, is a group effort with contributors from a _ton_ of different places, industrial, hobbyist, and research alike. And the feature addition process is governed by a committee that is drawn from a wide range of people and again is not under the control of any single company. This means that if any company that supports haskell development were to disappear, or to stop supporting haskell development, things would be able to _keep going_, perhaps with some hiccups, but nonetheless. This situation is preferable and more sustainable in my opinion.
Cloud haskell has nothing to do with the web per se. It is about distributed computation and communication between multiple Haskell processes.
My mistake! This doesn't require an optin. https://CDelta.io
It seems to me that the peanut gallery and the voting system are pretty good at rewarding reasonable job postings and downvoting poor ones to oblivion. As long as that general pattern continues, I think we're ok as is?
This is a pretty sweet idea! I've also been coming around to this point of view, that boilerplate reduction is probably the better strategy than rewriting everything. I'm more concerned with the boilerplate around defining effects and interpretations. There are a number of instances you need to give for all of the necessary types, most of which are homomorphisms but can't be `Generic`-d away. TH might be a good solution here, but I'm always loathe to reach for TH :)
Very well said. Mistakes must be made. My distinction between a junior and senior is that a senior has made more mistakes and learned from them.
Types?
We don't need those, we already have them.
To save a click-through. No: the monad instance is not compatible with the zippy applicative, same as for ZipList.
I really enjoyed reading this, thank you 
I don't know anything about (anti-)FPCo, but I am grateful for your opinion. Thank you
Way to go :) 
Thank you, a few other people have recommended Stephen Diehl's blog too. I'll definitely check it out!
Having used all three, which do you prefer?
By not going full fancy, do you mean stick to ~Haskell 98?
I goT iT :) 
That's not what the question is asking about.
&gt; a way of describing programs using data types Could you expand on this point, please?
I've made a note of these libraries, and the blog list is awesome. Thanks a lot!
That's a broad topic including free monads/applicative/functors/categories, type level programming using GADTs and type families. An example might be this https://coot.me/posts/categories-with-monadic-effects.html but also the `Proxy` type in `pipes` is a nice example.
I mean, if you're going by that you might as well say that the list is redundant because all of these things apply to all software anyway, Haskell or not.
This is really good advice.
TDD w/ Idris, Session Types, etc. (I think)
If you input the character in GHCi it will output it using an escape sequence: &gt;&gt;&gt; '➕' '\10133' I typically write my escapes in hexadecimal, so I would write it out as `\x2795`. As far as I know, there's no way to use the Unicode character name ("HEAVY PLUS SIGN") as an escape. The *Real World Haskell* book has a thorough appendix on characters and strings: http://book.realworldhaskell.org/read/characters-strings-and-escaping-rules.html
I thought this was a medium article for a moment. What's the point of this blog post?
And if you ever stumble upon the strange escape sequence `\&amp;`, it's used as a separator when a unicode escape sequence is followed by a number: λ&gt; "➕9" "\10133\&amp;9" 
There's no point in interpreting the question in this way since it uniquely determines the `Applicative` instance from the `Monad` instance. The actual question being asked is much more interesting than that.
 &gt;&gt;&gt; '➕' '\10133' Well, so it does. That works well enough for me, thanks!
Just finished the readme for a GHC plugin, which I started a little Christmas project :) &amp;#x200B; What do you think about the idea?
They apply to software in general to varying degrees. For example training is not an area of great need for JavaScript companies. There is a vast amount of resources. Haskell companies however have less resources in this area, so you need a higher level of teamwork to supplant it.
He means sometimes a web site can just be a web site rather than a free monad, and a parser can just be a parser rather than a type family to model state transitions, and you don’t have to wrangle your pipeline into a conduit or Arrow, you don’t always have to have a class for every possible operation your monad can do. Sometimes those are great, but if you don’t have the experience to judge whether it will be worth it and that you will actually reap rewards, don’t use your professional project to do that research.
There are a bunch of problems... I remember three off the top of my head - 1. Paths should be ByteStrings not String. 2. Traversal/Listing functions don't document behavior with symlinks. 3. Throwing exceptions is an questionable default for errors, making it easy to forget handling potential problems.
Cool! Some questions: * Can you `DeriveAll` minus some? Eg maybe you want to provide a custom `Semigroup` instance, but otherwise lift everything else? * How does it play with orphan instances? * Does it derive instances for classes that are not in scope in the defined module, but are in scope elsewhere? Ie. does it solve the MTL O(n^2 ) problem?
Thanks for sharing
Thanks! 1. Not yet, but I planned to add some kind of a black list, e.g. \`DeriveAllExcept \[String\]\` with the names of type classes. 2. I get orphan instances from a `ModGuts` , which tracks transitive closure of orphan modules, so they should be derived with no issues. 3. It's quite easy to get all instances for all modules from all dependencies, but the result is a bit too much for basic types like `[]` or `Maybe` :) Instead, I load all modules which declare types or classes visible in the scope of the current module; so a class must be in scope to be derived.
Plenty of resources out there.... try this [http://learnyouahaskell.com/chapters](http://learnyouahaskell.com/chapters),
When I'm learning a new language, I generally like to pick a simple problem to solve and then try to implement a solution in the language. For me, following a tutorial is too passive and I find coming up with my own problem helps to make the concepts gel a bit more. You could also try doing the Euler puzzles in Haskell, and then comparing your solutions to others that have been submitted. If you're struggling with just understanding basic syntax then the Learn You a Haskell book is a good start if you haven't read it already.
Ask lots of questions. Find mentors and helpers. Learn how to turn your problems into a series of small, simple questions. Learn how to understand what the compiler errors mean. They are often quite helpful, if you know how to extract the useful information. Trial and error. Learn to use the repl for testing things out. Write small functions that do simple things. When you are lost in something big and complicated, take a step back. Break it down. Make sure you are understanding each small component that goes into the big thing. If you're looking specifically for beginner exercises, try H-99: https://wiki.haskell.org/H-99:_Ninety-Nine_Haskell_Problems 
Thanks for the link, I'll check it out
I think I understand the basic syntax, it's just that when i'm supposed to write a function for something, for example, if I've got to use the functions ```drop```, ```length``` and ```munch``` to create a single function, I dont know what order to put them in, how to put them etc, if you know what I mean.
If you are fixing typos you might want to change `(&lt;*&gt;` to `(&lt;*&gt;)` in the sentence: &gt;Applying `(&lt;*&gt;` to `fmap`, by substituting:
Related question, what's the recommended way of getting a repl in the "current project" with no namespaces imported, but the modules in the local project (or modules in any declared dependencies) can be imported with a normal `import` statement?
The only guideline that I agree with from the job posting point of view is the haskell job content. Obviously if a recruiter post his java job on /r/haskell to get good candidates, that job posting have no place on this subreddit
If you are referring to how to design your functions then I just think about what data I’m starting with (like a String) and what data I need to end up with and how it gets converted along the way. Then possible make each step a “sub function” or function and combine them to get what I want. Much more about what does the data look like then what does my object tree look like. If you are talking about how to actually write good syntax then there’re a bunch of free resources like Learn You A Haskell (LYAH) which can help and by al means ask specific questions and well do our best to help!
that's indeed the current behavior. there's a ticket explaining the reason and some possible ways to improve things here: https://github.com/haskell/cabal/issues/5374
I think so, it all depends on what you're trying accomplish of course. The REPL is an excellent place to start with experimenting with the code. That makes it easy to try different things and see if you get the expected output. If you're struggling with function composition, then try looking at the function types to see what they input and output. You can only hook a function to another one if it returns a compatible type another ones input. Again the REPL comes in handy because you can do something like `t: munch` to display the types for each function.
Blank sheet is you enemy. Copy-paste and modify. Have fun! :)
I just want to add that Ben Gamari isn’t the only one working on the incremental garbage collector for GHC: there’s also Ömer Sinan Ağacan.
**Why do some people hate the giants, especially FP Complete?** The quote below may sounds familiar: It's a quote from Linus Torvalds with FPComplete substituted for Microsoft &gt; I may make jokes about FPComplete at times, but at the same time, I think the FPComplete hatred is a disease. I believe in open development, and that very much involves not just making the source open, but also not shutting other people and companies out. &gt; &gt; There are 'extremists' in the free software world, but that's one major reason why I don't call what I do 'free software' any more. I don't want to be associated with the people for whom it's about exclusion and hatred. &gt; &gt; I agree that FPComplete's contributions are driven by selfish reasons, but that's how all open source code gets written! We all 'scratch our own itches'. It's why somebody wrote GHC, it's why somebody cobbled together Cabal, and it's why FPComplete wrote Stack. It's the reason for everybody to end up in open source, to some degree. &gt; &gt; So complaining about the fact that FPComplete picked a selfish area to work on is just silly. Of course they picked an area that helps them. That's the point of open source -- the ability to make the code better for your particular needs, whoever the 'your' in question happens to be. 
Do more of it, that's all there is to it. There is a difference between understanding code that's being shown and explained to you, and translating an abstract concept to code. You need to be able to do both, and you can't learn either without actually doing it. Yes, this can be a frustrating process at first when you don't quite know what you're doing, but this passes.
Why would FPComplete be attempting a "hostile takeover"? Of what, the Haskell empire with its 0.1% marketshare in the industry? That makes no sense whatsoever. And destroying Hackage and Cabal? They managed to self-destruct on their own. But you know what's actually harming the Haskell community? People propagating fake news of FPComplete being the bad guys when it was haskell.org who have tried everything to sabotage FPComplete's efforts at improving the ecosystem. This is "avoid success at all costs" gone too far when it's taken to mean prevent FPComplete's success at all costs. 
It turns out that this is in fact a good Applicative: [https://stackoverflow.com/a/55152385/1523776](https://stackoverflow.com/a/55152385/1523776) Has anyone here encountered this instance before? Perhaps /u/edwardkmett?
Thanks for the answer. I went to all three that you mentioned today (discord, freenode, SO) and while I did get useful answers, I just didn't know what to do with them, for example, someone pretty much told me how to solve my problem, and while I did then have that information, I just didn't know how to structure it or actually convert it into Haskell, which I feel like is my main issue at the moment.
Thanks, I didn't remember who else works on in.
You're welcome. See also https://www.reddit.com/r/haskell/comments/b0yaq2/shoutout_to_the_giants/
I made an account on REPL and it seems pretty cool. As stupid as it sounds, it feels less frustrating to code in it rather than just in Notepad++. Do you know if there's any more examples apart from the 5-6 that they provide at the start? 
For what it's worth on my box is straight out crashes &amp;#x200B; bellman-ford-test.exe: internal error: evacuate: stack frame at 00000000058ffdc0 (GHC version 8.4.3 for x86_64_unknown_mingw32) Please report this as a GHC bug: http://www.haskell.org/ghc/reportabug bellman-ford-0.1.0.0: Test suite bellman-ford-test failed Completed 20 action(s). Test suite failure for package bellman-ford-0.1.0.0 bellman-ford-test: exited with: ExitFailure 3 Logs printed to console So likely you either found a serious GHC bug, or some part of your code writes/reads outside of bounds. (Usually it's the later).
It is worth noting that the downvotes on the comment above are presumably not due to any "commie anti-FPCo downvoting mob", but rather because all the author of said comment does here is obstinately posting about FPCo, often picking fights and harassing people along the way in the process.
Your point being? I hope this community can tolerate individuals having their own experience of what works well for them, their own truth. On the other hand It's a lot more concerning if Haskell committee members who take decisions on behalf of the community [exhibit anti-Stack bias](https://github.com/tonymorris/do-not-use-stack/issues/1#issuecomment-435691293).
Yes. That's because right now you don't yet have a mental model of how Haskell actually works. Until Matrix style brain uploading becomes a thing the best way to get one of those is still going to remain practising until you have one.
I'm not actually familiar with that service, when I was talking about the REPL I meant the local Haskell REPL, ghci
If you have a sense of how you'd write your function in a language you know, start with that. Slam it out and get it working. This frees you up from trying to solve a problem in Haskell to just expressing a solution that you've already found. Since Haskell is pure, you will need to do some legwork to map things over, but here are some ideas to get started: If you need a loop, look at fold and map. If they can't do what you need, you might have to slam out a tail-recursive loop. In particular, if you have a loop where you need to update a variable each iteration, you probably either want a fold or a tail-recursive loop. When you just don't know the name of a function for doing something basic, check out hoogle and hayoo. You can type the type signature you want and search for functions that satisfy it. Lastly, err on the side of getting some code written down over getting it 'right.' Awful-looking code that does the job is much better than no code at all. :) Once you have something that works, you can look for ways to make it cleaner. Good luck!
hlint,weeder, hoogle, fast-tags, brittany... cant believe ive never heard of weeder amd fast-tags
The top five, to me, must be the most general and basic: * Write simple code. Stick to the basic abstractions -- ADTs, functor, applicative, monad (+ transformers) -- unless there's a particularly good reason not to. * Keep as much of your code pure as you can. And related: pull important invariants into the type system, where and if you're able. Newtypes, phantom types, etc. are handy here. * *Never* use partial functions. You can very occasionally make the excuse for truly impossible code paths (e.g. "reached the end of an infinite list"), but even then, do so sparingly. * Use the appropriate abstractions and data structures. `ByteString` when dealing with bytes, `Text` for utf-8, `pipes` or similar for streaming IO. That kind of thing. * Write clean code. It's easy, in Haskell, to pack too much action into one line -- don't do that.
"I know that it's a matter of practice, but I cannot really find anything that will help me practice" C O D E W A R S will help you greatly. You can attempt challenges then after solving or giving up see many solutions for it. https://www.codewars.com/
This is not even wrong. 
Great talk! I reproduced the examples at [https://github.com/jmitchell/developers-intuition.hs](https://github.com/jmitchell/developers-intuition.hs)
Hi everyone, I think this would be an improvement over the current rating system, and ultimately improve discoverability of packages. &amp;#x200B; I'd love if the community could leave thoughts/opinions on the issue linked.
Ethical considerations are paramount to many people's decisions to apply to or work at a company. Just like I would want someone to call out "hey this company doesn't use source control", I want someone to call out, "hey this company is actively making the world a terrible place in X specific way".
Hey thanks! I fixed this too. Thanks for helping me learn to be more careful next time!
Before that, what's the point of ranking packages to begin with?
Lenses are so abstract and generic that they feel like dynamic typing. Your code might typecheck, but not do what you think it does at all. And that happens in practice. They are useful, but they also come with a price. And they can introduce subtle bugs.
You can also skip problems and view others' solutions.
Yeah, and abstracting over different platforms was a mistake imo. It's really hard to reason about what your program does on another platform. It's more like it does the same-ish, unless... (beware of symlinks). See all those "On Windows &lt;this function does something else&gt;" comments in the directory package. Or check 'canonicalizePath'... why not simply have POSIX realpath? Instead this is a huge reimplementation of a well-tested function to make it a little more portable. And behavior varies greatly across versions.
I totally agree that we should allow for job-postings. I think more than the companies getting advantaged, the community is also advantaged in two dimensions (1) Possibility for applying (2) Knowing the variety of jobs / opportunities available for the community, even if not actively looking out for jobs. Haskell is still niche in the industry, and this does give an opportunity for the community to see the situation is improving. One thing that could be done to help those of us not wanting to see job-postings to have that option is to make a flair such as "job" as a mandatory for such postings, so that those of us not interested in jobs to fill our feeds can just filter them off using the flair.
Package discoverability is a big one. If I look for a package on hackage right now, in order to find the higher quality and popular ones that are recommended by others, I have to evaluate: * Last updated date * Stars on GitHub * Activity level of the developer * Downloads per month on hackage * Google for articles and Reddit threads mentioning it * Documentation? Maybe? This barely has any correlation to quality unfortunately. And even that is all just to get a vague estimate of "quality" Page rank helps a ton and it's a surprisingly good metric for this sort of thing.
Help inexperienced / inexpert users decide what package to use among search results.
The online REPL service you've signed up for is probably fine, but as /u/SteeZ568 said below your local Haskell REPL (also called GHCi, for 'GHC interactive') is probably better. You can get to it by going into the command line and running `ghci`.
[Playlist for Lambda Days 2019](https://www.youtube.com/playlist?list=PLvL2NEhYV4ZvCRCVlXTfB6-d09K3r0Sxa)
No you are not. It is very easy to make every data in haskell a string, integer or boolean, basically falling back to primitive type system of algol based languages. &amp;#x200B;
I am learning Haskell right now and I know exactly what you are talking about. I was stuck for a while on trying to add a string to the end of a list of strings. After I finally figured it out for myself things got easier but it's been like trying to ride a wild beast, one that bites, kicks you, throws you off, stomps on you, and sprays a foul smelling burning liquid from a gland located near its anus. With each small victory I'm becoming more and more aware of the raw primal power of this terrible beast.
In a previous talk i saw him do integration tests with quickcheck, where it shows a mix of, say, a queue. It would push pull with random data and see if it breaks. I never found any more documentation or examples of this. It was in erlang though. Anyone know if that is/was possible?
What does “based on pagerank” mean exactly ?
Huh! The joke is on you. I consider simplicity the first and main property of elegance.
Shout out to the unpaid labor of the GHC and Cabal developers.
Yes. I fixed the `uninitialised` bug, which turned out to be me naively converting an exponentially resizing array to a list (including its uninitialized elements). After fixing this, I get a GHC error (but not the one you mention): internal error: evacuate: strange closure type 3989448 &gt; So likely you either found a serious GHC bug, or some part of your code writes/reads outside of bounds. (Usually it's the later). How would I test whether it's one or the other? &gt; Edit: I tried building it with a newer GHC but there are a few bounds issues so I didn't dig any deeper. You mean version bounds issues? If so, I'll look into that.
I'm not set up to compile against taskell, so maybe my refactoring is not perfect. However, I started with what you had, and started removing boilerplate. I also made the variable names shorter: yours were so long that it was hard to fit them on the page, or in my head. What I came up with was this: getDir = do home &lt;- getHomeDirectory let taskell = "taskell" oldConfig = home ++ "/." ++ taskell defaultConfig = home &lt;/&gt; ".config" &lt;/&gt; taskell envConfig &lt;- lookupEnv "XDG_CONFIG_HOME" xdgDirectory &lt;- maybe defaultConfig (pure . (&lt;/&gt; taskell)) envConfig bool xdgDirectory oldConfig &lt;$&gt; (doesDirectoryExist =&lt;&lt; oldConfig) You might not like the use of `maybe` or `bool`, and I wouldn't quibble with you. But I think you were caught up in doing "cute" things like using `&lt;$&gt;` into actions instead of just doing some plain old boring do-notation stuff.
You don't have enough IQ, go program in Python or something /s
I think you're describing an 'oracle' which is a state machine which you compare internal system state with. If the state doesn't match your Oracle's predictions, then you have found an issue
Do you perhaps mean the circular buffer example written in C from "Testing the Hard Stuff and Staying Sane" paper and talk? If so, we've reproduced that example in quickcheck-state-machine (QuickCheck + state machine modelling a la Erlang QuickCheck): https://github.com/advancedtelematic/quickcheck-state-machine/blob/master/test/CircularBuffer.hs
Thanks a bunch. Do you have any recommended blog posts/material for learning about pipes? 
I don't mean this in a snarky way but I get the impression that what you want is to work through a Haskell book. I've never tried to learn a programming language from lectures; that sounds terrible to me.
I have a very hard time imagining this sort of post on any other programming language sub that I read.
Why is this in the Haskell sub?
I totally feel your pain; I've been learning Haskell for about a year now, and I still get that same feeling (actually ended up here because of some frustrations with a simple game I'm trying to write as an exercise, and it is not at all doing what I want it to do xP). Anyway! I've been learning Haskell for a large part by using this book Haskell from First Principles ([http://haskellbook.com/](http://haskellbook.com/)), and it's pretty great, with a bunch of exercises at the end of each chapter, and I highly recommend having a look at it :) Other than that, when I'm stuck it really helps for me when one of my colleagues gives me a hint about the solution I'm looking for, rather than giving me the answer. If you don't have anyone around who could do that, you could maybe put it up here, but specifically tell people you don't want the answer and are only looking for a hint \^\^ 
Kardano and Kadena’s system are written in Haskell. I have played around with the open source parts of Kadena - cool stuff.
Please work on your reading comprehension before launching a full scale attack. I am not suggesting any of these allegations are true, and I refuse to pick a side in this. I am merely summarizing what those who hate (or dislike, or oppose) FPComplete said (or rather, what some of them have said in public). Don't shoot the messenger.
&gt; constructed product result optimization: the allows us to return something like (Int, Int) in two word registers (essentially worker-wrapper but on the result instead of the arguments). However, this obviously doesn't fire in the case of lookup since the result is a sum. Well, but `Either a a` is isomorphic to `(Bool, a)`. While reading that section I was wondering if something with unboxed tuples would work. Or an unboxed int with positive for Right and negative for Left, but that's pretty awful.
Go take a walk, and rest. Most of the time, a good night is the best advice. I also agree with the others, find good mentors, change of ressources to learn, change of project also, and start small.
8.10 will be the release of dependent types on haskell!
Actually I've tried it and it doesn't work :/
Is there any way 
``` /usr/bin/ld.gold: error: cannot find -lgmp collect2: error: ld returned 1 exit status `gcc' failed in phase `Linker'. (Exit code: 1) Warning: Some package(s) failed to build. Try rerunning with -j1 if you can't see the error. cabal: Failed to build Cabal-2.4.1.0 (which is required by cabal-install-2.4.1.0).
&gt; As an aside, I like how seamless this is in Haskell with polymorphic recursion—each recursive call is at a different type. Can anyone explain this? This seems incorrect to me, but maybe I'm misunderstanding what's being said.
Yes, CPR for sums would take advantage of the fact that sums can be rewritten as unboxed sums. However, we don't implement this optimization at the moment.
`badsort` works on `[a]`. Suppose we pass a `[Int]`. Have a look at the recursive call with `badsort . permutations`. `permutations` returns a `[[a]]` from a `[a]` so in this case `badsort` will be called on a `[[Int]]`, then later on a `[[[Int]]` and so on.
The definition of `badsort` is: badsort Integer -&gt; [a] -&gt; [a] badsort 0 = foldr insert [] badsort k = head . badsort (k-1) . permutations `permutatations` is of type `[a] -&gt; [[a]]` so the recursive call in badsort is being called on a list of type `[[a]]`, not the original type of `[a]`. Each level of recursion adds another `[]` to the type.
Consider badsort 1 [1, 2] = (head . badsort 0 . permutations) [1, 2] = head $ badsort 0 (permutations [1, 2]) `badsort 1` is called on an `[Integer]` argument, but `badsort 0` is called on an `[[Integer]]`. So if you call `badsort 5 [1, 2]`, it'll call `badsort 4` on an `[[Integer]]`, which will call `badsort 3` on an `[[[Integer]]]`, which will...
you sure you've added the ppa properly?
I gave up and installed on Ubuntu :) (will try once I boot into windows, thanks again)
Oh derp, yeah I totally missed that.
I wonder, what would be a minimal change to `badsort` to work lazily in O(n\^2) of the insertion sort?.. Since it always get `head` there seem to be no need to evaluate any permutations beyond the first one.
That'd make a useful quasiquoter for someone who's looking for a toy TemplateHaskell project: ``` ghci&gt; [u|a \N{HEAVY PLUS SIGN} b = c] "a \10133 b = c" ```
do you know what you don't know? 
&gt; In some sense I can’t quite define formally but still believe in my heart, it “doesn’t cheat” in the sense that it is always “making real progress” towards sorting the input list. Since we don't have a formal definition we can both be right, but I think it does cheat, spending far more times generating permutations than sorting any lists. &gt; diabolicalsort = worstsort (\n -&gt; ack n n) I think you meant: diabolicalsort = worstsort . (\n -&gt; ack n n)
If the base case was a sufficiently lazy sort, so that `head . badsort 0` was O(lg n) (or better), then you could reduce the run time quite a bit, I think.
Deviations from the report without an extension make me sad. I want a standards-based language, not an implementation-defined one.
Is the issue that you are having trouble writing functional code? or that you don't understand what the correct syntax is to define the functions. I often find it helps to write the type signature first. In the case of your strings thing you might start with something like this &amp;#x200B; doThingWithStrings :: String -&gt; ??? doThingWithStrings \[\] = undefined doThingWithStrings (firstChar:restOfString) = undefined your only job is to replace undefined with something of type ???. This is how I started when I was learning. Haskell has a very convenient style of "fill in the blank programming" so if you're ever stuck on what to put somewhere, put undefined! (WARNING: don't do this in any production code, but for self teaching it can be very helpful, at first). &amp;#x200B; It may be worth noting also that if you come from imperative programming, you will need to remember that the value that something "equals" in FP is equivalent to what it "returns" in an in IP. Without more information on exactly what you are struggling with I can't really help any further, but DM's on here or on \[FP Slack\](functionalprogramming.slack.com) are welcome
&gt; What does JavaScript have? Mozilla and descendants. &gt; What does PHP have? Zend and descendants.
It would be helpful if you could share what exactly 'failed'. As I'm not sure I understand which part went wrong from your description
&gt; I want a standards-based language, not an implementation-defined one. Why?
If someone has some time to kill I'd be pleased to hear some constructive criticism about this toy project. :)
`worstsort` takes a function of type `Integer -&gt; Integer` as its first argument. So what was in the post should be correct.
Sorry for the bad description! I actually thought that what exactly went wrong was not really relevant for the question, since I'm not exactly psyched to get the dependency (it's [tensorflow](https://github.com/tensorflow/haskell) btw) working in a fork with `cabal new-build`. I was hoping for a more general solution, however hacky, to try and get this to work on my end. But nevertheless, I'm trying. `cabal new-build` fails in a couple of ways, some of which I fixed and can't remember. But the one "big" thing where I'm basically out is the subdir `tensorflow-core-ops`, where the `Setup.hs` contains lots of code that hooks into the build process (from what I understand). This produces errors with `sdist`. I can get more specific on Monday when I'm back at work if you wish. Let me know if you need more info.
From the mention of the "munch" function below, I'm guessing you are probably a student on my Haskell course. There's two pieces of advice I'd offer. The first one is to ask for help in the weekly lab sessions. I'm there myself every week, and we have around eight lab assistants too, all of whom are Haskell experts. Any of us will be more than happy to spend some one-to-one time answering any questions you might have, or giving some help and advice for how to define each of the coursework functions. The second piece of advice is that I'm teaching directly from the course textbook (Programming in Haskell, Cambridge University Press, 2016), so I'd suggest also borrowing a copy from the library and reading each of the chapters that we cover. The core of what we cover in the course is chapters 1-6, which is only 70 pages. Each chapter also has a number of carefully constructed exercises, and the solutions to many of these is given at the back of the book. Doing these exercises is a good way to build experience and confidence with Haskell. I'd also remark that many people find Haskell difficult at first. When I first studied Haskell as a student some 30 years ago, I didn't really 'get it'. It was only when I took a second course that the ideas started to sink in. That's one of the reasons why we also have an Advanced FP course in second year. Hope this helps! &amp;#x200B;
No implementation lock-in. Clang made GCC innovate, and that wouldn't have happened if we didn't have the C and C++ standards and everyone wrote to the GCC language. (Some people did / do write to the GCC language, and Clang has some support for it, but it wouldn't have been able to thrive long enough to start that effort is the C and C++ standards weren't around.) I've had to run alternative JVMs because Sun/Oracle didn't make a JVM for the platform we were deploying on. Just writing the standard provides a level of detail and structure that I find valuable. I learned Haskell mainly by reading the Haskell '98 Report; I learned Java mainly by reading the JLS and spending a lot of time in the API javadocs. I still use the C and C++ standards as references, albeit less an less frequently as we move to doing more development in Java and JS. Heck, even with Haskell I've not always developed for GHC. GHC didn't support OS 4690, so I used JHC to generate C code that I could "cross-"compile with the IBM VisualAge C/C++ compiler that would work on OS 4690. Honestly, I don't think there's a single type of technology I've ever used when I didn't get more value out of the ISO / IEEE standards-compliant version than whatever non-standard implementations a vendor (no matter how trusted a vendor) put forward.
I think the problem that the article raises is a good one - allow `forall` as an identifier and get unhelpful error messages, disallow `forall` as an identifier and deviate from the report. Perhaps this isn't the dichotomy the article describes it to be, but it seems like a good example to me. I like the default being "helpful error messages" but I think there's also value in a standards-based mode. Maybe it's time to start thinking about a `HASKELL_REPORT_2010` extension to allow users to put it in strict report compatibility mode?
Not sure about other projects, but I usually much prefer to define recursive datatypes in the standard, IMO clearer way, and then relate it to the fixedpoint of its base functor to access all the good stuff in recursion-schemes. I think this should be the standard way to do it, because base functors can be generated mechanically from the normal datatype definition most of the times. I wrote a (very basic, and WIP) bunch of functions that do exactly that, i.e. generate a FooF base functor from a Foo datatype definition, together with instances for Recursive/Corecursive typeclasses to have recursion-schemes working out of the box. https://github.com/fsestini/recursion-base-th/blob/65f92480fbec7953eea6323e6b55d4cb7c7c2ca1/src/Test.hs#L36
Oh, sorry, I was thinking of `badsort`, not `worstsort`.
&gt; No implementation lock-in. Why is implementation lock-in a bad thing? &gt; Clang made GCC innovate The only reason GHC violates from the standard is to innovate. Making `forall` a keyword is a sidenote to the actually important changes.
Coming from someone who isn't quite well versed in dependent types, while the idea looks interesting, I would like to see some actual use cases (and show how they are better than their counterpart without using VDQ). For example, how is the last `type` defined in the post (the 'dependent composition') better than its non dependent counterpart? Where is it better, and what are the downsides to using it? 
**Perhaps** it's time for a new Haskell Report, one where we could reserve some words for future usage, even if we aren't 100% sure what semantics they will have in a future report, if any. I honestly think standards-mode should be the default, but C, C++, and HTML have all specified in their standard how to request standards mode. I think `{-# LANGUAGE Haskell2010 #-}` looks good, and if a new report ever gets written we can change the name of the request-standard-compilance-extension to whatever the name of that report is. I'm not 100% sure we need to steal `forall` and `foreach` to get dependent types -- Idris seems to get by without them -- but I'm also not too concerned about whatever implementation of DT hits Haskell. GHC hasn't had a standard-conformant mode for a long time (incompatiblities in `base`, among other things), so I think the author made the right decision given the current situation, but I really wish we'd get haskell back to being a standard-based, multi-implementation language.
&gt; Why is implementation lock-in a bad thing? With implementation lock in, all of the activities I mentioned in my previous post are impossible, or at least much harder. No alternate JVM, no JHC, no Clang, etc. My data happens to be source code, but I think this may still apply: https://queue.acm.org/detail.cfm?id=1868432 &gt; only reason GHC violates from the standard is to innovate You can innovate and still have a standards-compliant mode.
I don't think those are comparable.
Thank you for the input! It totally makes sense.
&gt; With implementation lock in, all of the activities I mentioned in my previous post are impossible, or at least much harder. No alternate JVM, no JHC, no Clang, etc. It's unclear to me why it's better to have a standard and competing implementations rather than contribute directly to GHC. The first activity you list, reading the standard, is easily replaced by reading the implementation's manual. I've learned a lot by reading GHC's manual, it's really well-written. The second activity, running on alternative platforms, is already a reality. We have GHCJS to run Haskell code in the browser, for example. &gt; My data happens to be source code, but I think this may still apply Even if you hide functionality behind a flag, it's still non-standard functionality. All of my code makes use of non-trivial amounts of GHC extensions. &gt; You can innovate and still have a standards-compliant mode. What's the point of maintaining a standards-compliant mode if the actual implementation-defined language is years ahead of it?
&gt; It's unclear to me why it's better to have a standard and competing implementations rather than contribute directly to GHC. Maybe I don't like their license, their architecture, or I have a personal problem with one of the other developers. Perhaps I have a copy of the report, but no Internet access. I shouldn't have to start from GHC to produce a Haskell. --- Reading a manual is very different from reading a standard, and while I often read the GHC documentation, I prefer the C standard or the JLS. --- &gt; Even if you hide functionality behind a flag, it's still non-standard functionality. All of my code makes use of non-trivial amounts of GHC extensions. If you use a flag, it doesn't have to affect code written to the standard. I have absolutely no complaints about whatever behavior you want to but behind any extension. You can implement `{-# LANGUAGE ActuallyPHP53 #-}` and I won't be bothered as long as every Haskell 2010 program still works. --- &gt; What's the point of maintaining a standards-compliant mode if the actual implementation-defined language is years ahead of it? So that code written against the standard still works? I want to update the code in response to my client's needs, not because my vendor has decided to tweak the language.
Oh, that's neat! :-) &amp;#x200B; Does it just end up throwing the explicit \`Expr\` alltogether in favor of the functorial one? &amp;#x200B; I guess one concern would be documentation, this could be very confusing.
&gt; If you use a flag, it doesn't have to affect code written to the standard. I don't share the assumption that code written to the standard is a realistic or a desirable goal. Real Haskell code is bound to use dozens of extensions, even if not directly but via its dependencies. Packages like `lens` or `servant` bind you to GHC's dialect of Haskell, end of story. &gt; Maybe I don't like their license, their architecture, or I have a personal problem with one of the other developers. Okay. So what if you go ahead and implement the Haskell dialect that you want, with the license that you want, with the architecture that you want, collaborating with developers that share your views? For libraries, supporting your dialect of Haskell will not differ much from supporting older versions of GHC. I still don't see what a standard brings to the table. Any real library will be written against an implementation or a set of implementations. The standard could serve as a documented common denominator between them, but then it's role is descriptive, not prescriptive. 
&gt; No implementation lock-in. With the current state of the Haskell ecosystem that ship hasn't only sailed, it's been over the horizon for years and the sailors aren't returning our calls anymore. There are a couple of nonessential GHC extensions you could safely ignore in a new Haskell report, like `MultiWayIf`, but GHC deviates from Haskell2010 in many nontrivial ways even without language extensions (for example, GHC Prelude is barely recognisable if you compare it with the one specified in Haskell2010).
i do agree with gershom: it does seem like in this case, you'd just be ranking packages in the sense of "whats the frequency/probability of visiting this package if i walk along the dependency tree of a randomly chosen package". I do think that *might* be an interesting additional metric, though i feel like theres lots of higher impact ways we could improve hackage server ... but its worth noting that "wide usage" isn't a measure of package user happiness! :) 
That certainly doesn't have to be true. C and C++ have been standards-based (including prescriptions not just descriptions) for decades, even if they are implementation-lead. I can write meaningful, useful C or C++ code, today, that works on a wide variety of implementations. I can also write new C or C++ implemenations from scratch that compile many C programs and most prortable C programs. I want Haskell to be as stable, diverse, and vibrant as C++. I want it to be standards-based AND implementation-lead.
i desperately want to say, “never”, but i will refrain.
I know two stories of migration from Haskell. One from Pusher and another from Cap'n'proto. https://making.pusher.com/golangs-real-time-gc-in-theory-and-practice/ https://capnproto.org/news/2013-08-12-capnproto-0.2-no-more-haskell.html
Might be useful to assume that high- vs low- level indicates the expected amount of non-functional extra-work a programmer reasonably expects to add to her program
Very interesting 
When I have memory constraints or gc pause restrictions I switch modes. I think more about using Haskell to produce the code that I'm going to run in those limited environments. e.g. How do I build an EDSL for a code generator that covers this domain. Then I can use Haskell again. This is a sort of mangling of an idea I first heard from Dan Friedman, where he said to me something to the effect that "he doesn't care what language he has to produce in the output, he'll still write his code in scheme" just with a few more types bolted on for sanity's sake.
I built some stuff with Haskell on raspberry pi and it was ok - doing sound synthesis stuff with supercollider. But then I wanted to add a web server to that, ugh. Cross compiling wasn't really a thing then (is it now?) and definitely not with template haskell, which was in play in my web libs. Starting with zero dependencies built, build times for the PI went into the tens of hours. Bummer because I'd already built a lot of stuff. Up to that point built times hadn't mattered too much because I could test on my laptop and just deploy on the pi at feature completion. Its too bad because it actually ran ok if it could actually finish compiling, unlike clojure. Ultimately I went to rust which was a pleasure to deal with in comparison - going from zero dependencies built took about 20 minutes with all cores working and constant memory use of maybe 150m. 
&gt; I still don't see what a standard brings to the table. Same thing any standard does, a common target for not only the consumer and producers around today, but consumers and producers that do not yet exist.
Thanks ! You earned a star ;)
How hard would it be implementing the Monkey language using Haskell by following the instructions in the book *Writing An Interpreter In Go* by Thorsten Ball[0]? The book seems to be exactly on my level and using a learning method that I very much appreciate, but I don't want to split my focus between languages I use. [0] https://interpreterbook.com/
This would assume that best practices in Haskell differ from those in industry. Industry introduces additional constraints that academia and hobby use don't have, it does not obviate best practice from the greater community.
Hard real-time. Our GC in the GHC RTS can't deal with that. You can use a DSL implemented in Haskell (e.g. Atom) to do hard real-time, but that's not *exactly* using Haskell.
We're currently using F# as our functional language of choice for 1 simple reason. We already have a huge codebase of C# that we depend on and it would be quite tedious to use a non .Net language. I'd imagine that it's the same reason for Scala, when you have a big Java codebase.
I suggest you read the responses to a similar dependent-types style question [here](https://stackoverflow.com/questions/11910143/positive-integer-type/11912348#11912348). The gist is you can: &amp;#x200B; * Use a type with an exact representation. /u/chshersh 's first suggestion was this. * Use a type capable of representing more than what is desired but guard construction with what are called "smart constructors". This was the second suggestion from /u/chshersh * Use the second type, but guard construction via Liquid Haskell instead of smart constructors. This is more experimental since Liquid Haskell, while fairly mature, isn't widely used by the community or richly supported by the tools as of yet. &amp;#x200B;
It's good to have names for *type-variable* (`data Either a b`) vs *return-kind* style (`data Either :: Type -&gt; Type -&gt; Type`). I have called the first one (lower-case) applicative or applied style, second one full-(kind) signature style. I completely agree with his reasons for using GADTs &gt; As this suggests, the `Either` type constructor takes two `Type`s as arguments and returns a `Type` as the result. The thing is, you have to squint a bit at the definition of `Either` to realize this. The fact that `Either` takes two `Type`s as arguments is implied by the two type variables in `data Either a b`. The fact that `Either` returns a `Type` is not spelled out at all; it’s an implied consequence of `Either` being a data type. &gt; &gt;While it is not impossible to reverse-engineer that `Either :: Type -&gt; Type -&gt; Type` from the declaration `data Either a b` alone, I prefer to be explicit about the kind of a data declaration whenever possible. For this reason, I try to use the following, alternative syntax for GADT declarations: &gt; &gt; data Either :: Type -&gt; Type -&gt; Type where &gt; Left :: a -&gt; Either a b &gt; Right :: b -&gt; Either a b
this might be a crash that was in 8.6.3 (and earlier) that was fixed in 8.6.4! see the release announcement https://ghc.haskell.org/trac/ghc/blog/ghc-8.6.4-released
This is an interesting one. If you use non-Haskell 2010 extensions in your Haskell code and packages, non-conditionally, you’re part of the problem. I’m not pointing fingers, I use GHC-specific features on almost every project or package I write. The more Haskell packages that are useful and don’t work on non-GHC implementations the more difficult it is for competing implementations like UHC or YHC to stand a chance at being used. The Lisp community has a strong culture of conditional, so-called “portable” code so that packages work on multiple implementations. I think that’s the only way standards can mean anything and compilers can compete. I believe you’ll need to start a strong initiative to get Haskellers to pay mind to that. Maybe by e.g. starting with UHC or YHC and opening PRs that make your favourite packages work on those compilers via conditional compilation. You might see resistance though.
A single function can be imported without using `hiding` by wrapping the desired function in parens within the module import; `import Data.List (sort)` will import only `sort` from the module Data.List. Check here for more examples: https://wiki.haskell.org/Import Haskell keeps module imports at the top of the file for code comprehension and understandability.* It's important to know what functions are available within a module, and that would be a lot more difficult to achieve if module imports were hidden within the definition of functions. *If memory serves correctly, having them at the top is also useful/necessary during compilation for preprocessing and concepts such as mutual definition.
I would advise you not to use haskell in projects you do not want to be tied up with. For example is front end web development something you want to do every day for next 20 years? If not, then maybe it is not a good idea to create a web frontend using reflex, because at some point you probably would like to transfer this project onto someone else. And that is much easier to do if you use a more established technologies like reactjs? Basically everything you create with haskell will be like an anchor on your neck. Make sure you do not carry too many anchors that are hard to pass on to someone else. &amp;#x200B;
Technically you can import specific function such as Data.List.sort which is a simple way to do, but many packages have long names.. which is make sense to do something like that. DL.sort \[1..10\] where DL = Data.List ... &amp;#x200B; Personally, I did not know much about how Haskell compile the code and how Haskell use the module to compile the code. &amp;#x200B; &amp;#x200B;
You can use `import qualified Data.List as DL (sort)` This is not exactly what you want because the function `DL.sort` will be available everywhere in the module not just in your definition of `fun` but it is fine I guess. 
That's an excellent point! And very realistic as well. I can say that it's exactly what we resorted to when faced with delegating frontend to another team.
"We have a fork of GHC that implements a new language extension, UnsaturatedFamilies, which supports all the features described in this paper, ... is backward-compatible"
Queinnec also did that in his classes. Root code was scheme, target would be xml, java5 or whatever fed to students. I guess once you see things in trees .. anything goes.
His talks are always interesting and well presented.
Irrelevant nitpick: Nooo, don't take `~&gt;` away from us :(
You might be interested in the [Stitch](https://cs.brynmawr.edu/~rae/papers/2018/stitch/stitch.pdf) paper, which has a similar aim but use more sophisticated Haskell techniques.
I'm not sure what you're saying? Backwards compatible in this context means that existing code that doesn't use this feature shouldn't be broken by introducing this extension.
The pipes documentation is top-notch. You can find a tutorial module in the library itself, and there is very clear commentary throughout the codebase. https://hackage.haskell.org/package/pipes
you are right, i extend the quote
Actually, you can do something like that, it seems to me it is only for function, not for Data constructor.. where mysort = Data.List.sort
[removed]
The original type, say Foo, is still there, it just adds a new datatype FooF which has basically all the constructors of Foo suffixed by 'F', and a parameter in the recursive positions. No code reffering to Foo needs to be changed, and you can continue to use it as before. 
What's the best set of tools for doing code generation from Haskell EDSLs? The only straightforward thing I can think of is traversing over trees and outputting LLVM IR.
Mainly, you shouldn't be using Haskell when you're collectively working on a shared code base with the people who don't understand it, and have no desire to learn it. Also, anything which requires very predictable time and memory performance may not be a good idea, though you might work around that with code generation. Cryptography, safety-critical systems, etc.
&gt; The "recursion-schemes" package allows another way of attaching the recursion schemes machinery to a type through the `Base` type family. It would make the original data type more trivial and easy to use, but I thought using `Fix` explicitly is the most "fare" approach :) I don't know what "fare" means, but I recommend using `Base`. In fact, [I would like to remove `Fix` from the library](https://github.com/ekmett/recursion-schemes/issues/78), specifically because I want to guide users away from the `Fix` style and towards the `Base` style. (You will still be able to use `Fix` by importing it from whichever package `Fix` will be moved, hopefully `base`)
&gt; Mainly, you shouldn't be using Haskell when you're collectively working on a shared code base with the people who don't understand it, and have no desire to learn it. Can you share any experience from a situation like this?
I can share a similar situation. I work at Google. Now, Google does use Haskell for some things. But there's a standard Google production environment that's based on a bunch of shared infrastructure with dedicated language teams to ensure that it works well with major programming languages. If you want to build something to run in that production environment, Haskell probably isn't a reasonable choice. It could be, but no one has done the work. That no one has done the work is related to the lack of coworkers sufficiently dedicated to using Haskell.
Every day I go to work has been a situation like this, for more than a decade. You're typically hired on a certain project. That project is already using a set of languages - typically C#, Java, SQL, Javascript, something of that sort. You need to fix some bug, or implement some feature - and there's a deadline, so you don't have the time to rewrite anything. Which is a good thing, too - since even if you do implement your bits in Haskell, nobody around you would be able to do a meaningful code review. And code reviews are a must, you're always going to have bugs in whatever language you're using. And then you have to explain your code to another person. And then you're needed on a different super critical project, so another less experienced person has to be hired to maintain your old project, to free up your time. But if your old project is in Haskell, you won't be able to free up any of your time, you would have to be distracted by that new hire until he's able to learn the basic syntax of Haskell, the type classes, the monads, the functors, and whatnot - in addition to the problem domain.
Emitting LLVM has the benefit that you can then compile and jump into it in-process without any sort of phase distinction. I've also done more brutish things like produce C/C++ with raw text either for external projects or for `inline-c-cpp` usage, which can aid with generating FFI. Somewhere in the middle lie things like jmacro, which can be used to produce javascript from a pleasant to use template haskell quasi-quoter with richer syntax and antiquotation support. This is used heavily by GHCJS for instance. Then there are other libraries that folks have for producing web-assembly, shaders, etc. It really comes down to a function of how much time you want to put into generating better intermediate representations vs. time won in the use of the representation.
Oh hell yes
Rust is quite good this days, and even on C, you can go very far with a small thread on the critical path that you control by FFI calls. But yes, when everything fails, one still has code generation.
One strong motivation behind VDQ is getting rid of checking for CUSKs in the compiler. Ryan discusses this a little bit in the article without mentioning the term "CUSK" explicitly: &gt; The proposal [for top-level kind signatures] also suggests that, after a certain window of time, all polymorphically recursive type-level declarations in GHC must have a top-level kind signature in order to kind-check. This would replace GHC’s current, ad hoc metric that it uses to determine when polymorphic recursion in a type-level entity is permitted. But how does it help all the folks who aren't hacking on the compiler? Consider this function: foo x y = bar x (baz y) What is the type of `foo`? We have no idea! It depends on the types of `bar` and `baz`. If the user had instead provided a type signature, we wouldn't even need to look at the implementation. This same problem shows up with data type declarations: data Foo k x y = ... What is the kind of `Foo`. Same answer. We just don't know. The stuff that shows up on the right-hand side dictates the kinds of `x` and `y`. There may even be an invisible kind variable. That is, it could be the case that `Foo :: forall (k :: Type) -&gt; k -&gt; Bool -&gt; Type`. But again, we just don't know. One can argue that we do not actually need VDQ for this. After all, today we can already write (with `GADTSyntax`): data Foo (k :: Type) (x :: k) (y :: Bool) where ... But this is a little cumbersome. It requires naming all the arguments and it omits the final `Type` that is part of the kind signature. What's more clear to comprehend? data Foo (k :: Type) (x :: k) (y :: Bool) where ... vs type Foo :: (k :: Type) -&gt; k -&gt; Bool -&gt; Type One further wrinkle is `UnliftedNewtypes`, which will also likely land in GHC 8.10. With this extension, it will be possible to have data declarations where the result kind is something other than type. And in this particular situation, it's not just a question of preference. Newtype declarations with kind signatures will have strictly more information that newtype declarations that use kind-annotated type variables. Consider the two options: newtype Key (k :: Type) (x :: k) where KeyC :: forall (k :: Type) (x :: k). Int# -&gt; Key k x vs type Key :: forall (k :: Type) -&gt; k -&gt; TYPE 'IntRep Notice that in the variant with kind-annotated type variables, I had to provide the body of the data type for it to even be possible to know what its kind was. The variant with a kind signature does not have this problem. Ending with a more personal reflection, I'll mention that at some point when I was learning Haskell, I began to experience bewilderment when someone would write a tutorial on something and wrote a bunch of top-level bindings without type signatures. It was so hard to figure out what the types of things were because I had to run my brain's crummy version of solver on the code. Years later as I started playing more with dependent types (to the extent that GHC allows), I started to feel the same distaste in the arena of data type declarations. If seeing things like `data Proxy a` instead of `data Proxy :: forall (k :: Type). k -&gt; Type` doesn't bother you now, be glad. But just know that one day it may.
Haskell is my favorite language and I still find it annoying to use it as a fill-in for a scripting language. I'm referring to the following situation: My task is a one time need (or close to it)... And my task needs a lot of IO. Moving folders around, getting dirty with regex searching files, or even webscraping sometimes falls into this space. If I need it done once and probably never again, I use Python. Haskell could work in any of these areas, but it's either a little too laborious and I give up, or it starts ending up too elegant and I start abstracting and beautifying a dirty one-off script that I never meant to fall in love with.
Oh yeah, I forgot that \`cata\` does the job of moving between \`Expr\` and \`ExprF\`.
Hi! OP here. I wrote up my thoughts on diving into hakyll's \`Hakyll.Core.Routes\` module and leveraging it to try and figure out how to instead use my posts' / pages' metadata to generate outputted routes in a "slugified" format. Hope it helps someone!
But Data Constructors are functions?
Wow that's cool...I work on Embedded but have never thought of using the Haskell + nix to target anything there...
I was asked to give a talk at the [Singapore Institute of Technology](https://www.singaporetech.edu.sg/) for CS students learning FP. I haven't googled these terms, but I'm pretty sure "CS" means "cooking school" and "FP" means "food preparation". This is all based on [this old blog post](https://unsafePerform.IO/blog/2012-12-01-static_analysis_with_applicatives/) of course, but is updated to use a representation more direct than the ([not really correct](https://arxiv.org/abs/1403.0749)) free applicative over a co-Yoneda functor.
I agree with this point but maybe not so much the example. It seems like every new frontend framework has a very short lifespan. Like does anyone remember how to write angular v1 anymore? (Is angular still even a thing...). 
FYI Agda uses the `Either a b : Type` syntax for type *parameters* and the `Either :: Type -&gt; Type -&gt; Type` syntax for type *indices*: https://people.inf.elte.hu/divip/AgdaTutorial/Sets.Parameters_vs_Indices.html 
Also relevant: a very simple (just a couple dozen lines of code) typechecker + typed embedding of STLC into Haskell: https://unsafePerform.IO/blog/2015-02-05-typed_embedding_of_stlc_into_haskell/
I didn't think an Raspberry Pi running some GNU/Linux distribution really counted as embedded! I certainly don't feel like I've done something embedded, but it feels super cool compared to my PHP/Typescript fullstack "what's an architecture?" dayjob.
Could you explain what automatic differentiation means in this context?
I'm reminded of [this](https://www.mipmip.org/tidbits/pasa.pdf). Fun stuff.
Well, it is really does not matter whether it is function or Data constructor. What I want is to simplify "the long name" on my code. 
My point is since they are functions the exact same thing should work, eg: import qualified Data.Maybe as M foo = bar 5 where bar = M.Just 
\`OverloadedStrings\` does (these days) allow for use as a pattern but you must be sure to have an \`Eq\` instance.
In a nutshell: 1. GC problems 2. Calling into haskell code isn't very pleasant 
Thanks for the tip! To be clear, though, the crash also happens with profiling off. I just upgraded to GHC 8.6.4 and it still crashes: bellman-ford-test: internal error: evacuate: stack frame at 0x4200ad8e88 (GHC version 8.6.4 for x86_64_apple_darwin) Please report this as a GHC bug: http://www.haskell.org/ghc/reportabug 
Very greedy!
This is so we'll timed for me. I was wondering yesterday how to do exactly this in Hakyll. 
I wonder if it will interact with the type-level \`\~&gt;\`, since this one is at the kind level.
How big is the step from here to lifting term-level functions to the type level? Note that I'm not talking about full dependent types, I'm just asking about if I have ```f :: Bool -&gt; Bool -&gt; Bool```, can I get ```F :: Bool ~&gt; Bool ~&gt; Bool``` (the equivalent of C++ `constexpr` if you will) for free? Or does this mean full dependent types in the context of Haskell given all the other extension?
There are no separate kind/type levels.
This is gold. A great contribution. This allows to apply the intuitions of higher order programming to the type level. Most of the things that makes type level programming difficult is the "monomorphic" boilerplate.
The link seems broken
What is this ~ operator?
Oddly enough, I can see it just fine.
As far as I can tell, the easiest way to do this would indeed be to use a lot of nested if statements. I don't think you can do much beyond that, other than putting some of the larger subtrees under a `where` clause. I do notice that some sections are repeated (e.g. quite a few bits under `yes play again?`); potentially these could be separated into functions like `playAgain ifTwoDiceAction = if {- stuff -} else ifTwoDiceAction`. So you'd end up with something like: game = if canTwoDice then case playOneOrTwo of playOne -&gt; ... playTwo -&gt; ... else ... where subtree1 = ... subtree2 = ... If you need to query everything via IO, it could get boilerplate-ey fast; a nice way to do it might be to define an auxilliary function `ifIO :: IO Bool -&gt; IO a -&gt; IO a -&gt; IO a`, defined as `ifIO cond true false = do { c &lt;- cond; if c then true else false }`. That would give you something like this: game = ifIO canTwoDice ( do playOneOrTwo' &lt;- playOneOrTwo case playOneOrTwo' of playOne -&gt; ... playTwo -&gt; ... )( ... ) where subtree1 = ... subtree2 = ... On the other hand, a more experienced Haskeller might be able to find a clever way to express this sort of big tree nicely; I can't rule that out.
The identity monad costs nothing because `(&gt;&gt;=)` and `return` expand to simple function applications. This `do`-block reduces simply to `38 + 4`.
Thanks for the reply. I will implement it the brute force way first. btw: Another topic, how to QuickCheck the validity of such control flow/logic flow? Doesn't seem to have any particular properties.
`Identity` is a `newtype` wrapper, so it should have no runtime cost, ever since https://www.microsoft.com/en-us/research/wp-content/uploads/2016/07/coercible.pdf — which was around 8.0 I believe?
 &gt; :kind (~) (~) :: k -&gt; k -&gt; Constraint It's type equality, id1 :: a ~ b =&gt; (a -&gt; b) id1 a = a that can be reified into a datatype [`(:~:)`](https://hackage.haskell.org/package/base-4.12.0.0/docs/Data-Type-Equality.html#t::-126-:) data (:~:) :: k -&gt; k -&gt; Type where Refl :: a :~: a id2 :: a :~: b -&gt; (a -&gt; b) id2 Refl a = a where you should think of `Refl :: a :~: a` as sugar for `Refl :: (a ~ b) =&gt; a :~: b`
This is very cool and useful
Try (Proxy @n)
I've upvoted your comment because it's a good point to consider, but you can still hire Haskellers, especially if you're willing to accept remote.
Do you have the option to refine your ast type, or is it dictated by the assignment? Having an ast of strings isn't very idiomatic haskell, as it doesn't give you very much information and it's obviously impossible to do exhaustive pattern matching on strings. An ast in haskell usually looks like `data Expr = Var String | Let String Expr Expr | Num Int... `. These constructors capture the structure of whatever program you're manipulating, whereas using raw strings incurs a lot more overhead. 
It's clearer with [`-XTypeApplications`](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#visible-type-application) {-# Language RankNTypes, ScopedTypeVariables, TypeApplications #-} import Data.List (permutations, insert) badsort :: forall a. Ord a =&gt; Integer -&gt; [a] -&gt; [a] badsort 0 = foldr insert [] badsort n = head . badsort @[a] (n-1) . permutations We are defining `badsort @a` but we recursively call it at `badsort @[a]`.
GHC is written in Haskell, so yes, GHC can (and does) compile GHC. I don't know if that's what you mean by "metacompiler" though.
I am positive they dictated it this way, because the internet has way too many solutions with "data Expr" :D I should let you know that, I sent this post to TA and he said that I don't need to use string and parse, that would just make it much harder than it is supposed to be. I suppose I'm expected to solve it as I solved writeExpression part (where I take AST and Mapping and create the string.) Except creating a string, I am supposed to do actual operations, maybe this time casting strings into proper types (no floats, so it's either String or Int, guaranteed by TA) then I need to add a "where" section to add values of each given variables in Mapping. Only thing I'm not comfortable implementing is, using recursion for both AST AND Mapping, because both of them have multiple operations or expressions. AST being nested and Mapping being an array. Could I make a function that returns an array of functions/expressions? Like [ x=5, y="cat"] etc. Maybe I am overthinking.
Could you encode the logic into a (game)-tree-like data structure? Tbh I don't quite understand your diagram but you could have like GTree = Leaf (IO ()) | GNode (IO Bool) GTree GTree then runGTree (GNode b l r) = ifIO b then (runGTree l) else (runGTree r) 
With regards to you wanting to transform a `[(String, String, String)]` into a series of bindings within a `where` block, I don't think there is any way to do this without using template haskell to do metaprogramming. This is an advanced feature of Haskell and considering you're doing an "introductory functional programming assignment" it probably indicates there is an alternative and simpler solution to what you're proposing. Your `solveAST` function is defined recursively and needs to evaluate its expressions based on your variable mapping. It would therefore seem natural for it to have the type `solveAST :: Mapping -&gt; AST -&gt; String` however, as u/jmorag has explained, it is generally bad practice to be using `String`s when you really want a more specific datatype for most of your expressions. You could acomplish this by defining a new datatype which can encapsulate all the values of types that you care about. E.g. `data Value = I Int | B Bool | S String | etc...` then you could have something like: `solveAST :: Context -&gt; AST -&gt; Value` where `Context = [(String, Value)]` and you can use pattern matching to define the behavior of your program based on the specific type of each value. This is only a rough idea though, I don't understand what you're trying to do well enough to be certain that this approach would work.
Thanks a lot for a well-written explanation. I do agree that all those "metaprogramming" shenanigans would probably be an overkill for this task and I think you have a valid point about data Value part. There is not restriction about defining new custom types whatsoever, I will consider it. I will be still thinking about how can I place the Mapping "rules" in where block or maybe I don't even need to. I might be tunnel-visioning. We have had a question regarding unused variables in Mapping and it was mentioned that they are being placed in "let ... in" blocks even if they are not used. This indicates that I just need to figure out handing that part then I am done. I will be posting what I come up with, in case anyone may find it remotely interesting for a beginner's perspective.
&amp;#x200B;
What exactly is the nature of the mapping list? Is it (variable, operation, number) or something else?
What an exceptionality well written thing!
Is there a reason why a module in `recursion-schemes` isn't good enough? http://hackage.haskell.org/package/recursion-schemes-5.1.2/docs/Data-Functor-Foldable-TH.html 
There does exist a reasonable solution roughly along the lines of what you posted for solveAST that doesn't change the data types etc. Pass the mapping array as an additional argument to solveAST, change the otherwise clause to be a lookup of operation into the mapping array (disregarding the middle field), and remember that all the return types are strings so eg. an "add" node will have to read both the recursively obtained strings into ints, add them, then show the result. This doesn't give you type safety but should work just fine. If you want type safety too you'd have to tag the return type at each step then remove the tag at the top level entry point to solveAST.
I was actually doing exactly what you are saying here, well the first part. I created solveAST and it solves perfectly. I just use read and show trick to cast to int and string back and forth. Using some $ to not get too many parenthesis. This was solving when Mapping is []. Your idea is particularly nice with "otherwise oper" trick part. I was currently implementing a helper function that modifies given AST according to map, but actually I can just do it exactly on otherwise part on current solveAST function! I will consider your tip, thanks a lot :)
Some examples: ` [( ” a ” , ” s t r ” , ” h e l l o” ) , ( ”b” , ” s t r ” , ” w o r l d ! ” ) ] ` `[("x", "num", "9"), ("y", "num", "19")]`
Indeed there is: I wasn't aware of that module. Thanks for pointing at it.
I see. u/Vampyrez is right that there's a reasonable solution without doing any intermediate conversion. It's probably the one that also involves the least amount of typing as well. Does your assignment specify what you're supposed to do if given an ast that tries to add an int to a string?
Or `symbolVal @n Proxy`
I use `~&gt;` at the kind level all the time so
According to the assignment text, we don't have to worry about erroneous input, which is also confirmed again in discussion board. So there will be no case where you will be tested with an input consisting of str-int. As a side note, I have solved it, tested all sample inputs an it works as intended!!! The tip with "otherwise = oper" part really saved me some trouble because I was going to re-create AST from scratch with respect to Mapping to get rid of variables on AST, instead I have implemented a helper function that changes oper on solveAST function. I will talk to TA and if he wants me to implement it the way I thought before without "otherwise = oper" tip, I will do it anyways because I learned what I am supposed to learn in the scope of this assignment I think. I will be posting my full solution on github or something, once the assignment is evaluated. Just for further reference for myself and for those who are mildly interested in AST evaluation implementation in Haskell. 55 lines. I really like Haskell because of the way it is with more thinking and less coding. Anyways, thanks everybody who has shown any interest in this post. Cheers!
Glad it helps. I think it's worth clarifying that one of the big reasons to use Haskell (imo) is that you can easily define algebraic datatypes (like mentioned in another comment, data Value = I Int | S String | ..) then operate over them w/ pattern matching to have clean, legible, &amp; type-safe code, in particular with some useful correctness properties enforced by construction. Operating with Strings and casting them back and forth does work, but then you may as well be using eg. Python, which is you are being encouraged to add more (type-level) structure. But I appreciate this is just a homework assignment so do as necessary to fulfil the requirements :)
You can teach a computer the algorithm for computing a derivative through the chain rule, product rule, etc. by simply extending your concept of a number formally, much like was done when imaginary numbers were invented. There they added i such that i^2 = -1. Here we add d such that d^2 = 0, but d /= 0. Then you can work through all the rules of arithmetic with that consequence and use the coefficient of d as if it were the derivative of a function. If you represent numbers as `a + a'd`, much like complex numbers use a + bi, then multiplication derives the product rule. (a+a'd)*(b+b'd) = ab + (ab'+b'a)d + (a'b')d^2 = ab + (ab+b'a)d The rest of the rules for derivatives follow automatically. There are reasons to prefer this encoding over, say, symbolically differentiating, because done right you can get better asymptotic performance of the result compared to a symbolic differentiation technique. This describes "forward" mode AD. Reverse mode AD is a bit more complicated and is useful when you are computing all the partial derivatives of a function with many inputs and few outputs. (Forward AD pays per input you need to differentiate w.r.t., Reverse mode pays per output, but turns your time usage into space usage.) Reverse mode is useful for computing things like gradients. There you have many inputs, but one output. Reverse mode is commonly used for backpropagation in neural networks, risk analysis, etc. Forward mode can be used in graphics to compute surface normals for implicit functions. http://hackage.haskell.org/package/ad implements the idea at a rather high level of abstraction in a form that is suitable for working with arbitrary number types, not just doubles.
Is there a tutorial on using `Megaparsec` with `alex`? The README states "Megaparsec works well with streams of tokens produced by tools like Alex" but writing instance for token stream is not quite straightforward. The process (for me) were riddled with gotchas, scrambling for documentation/examples and the end result was brittle.
I had an impression that brittany is more aggressive than hindent (but hindent's presense in stackage is more stable). Anyway, just install any hindent support plugin and use the standard vscode format / format on save facilities.
It should be possible to add a plugin for hindent, maybe open a ticket? 
&gt; * Build requires unattainable version of base. Since base is a part of GHC, you most likely need to use a different GHC version with the matching base. This means you need to drop to a resolver that uses the previous version of GHC. If you look at the errors, you'll see that they're all stack trying to use libraries that are too new. You probably want 11.22. Or you could specify a newer commit.
That's the commit that is on his user guide (for beam). You're saying I could possibly use a newer one? Also, how does one (in general) pick which resolver to use in a case like this? Which package do I use as the lowest common denominator?
`base` is usually the lowest common denominator since it's tied to the compiler version. If base isn't in conflict, you'd usually use the `stack solver` command. Also, I think you're misreading the tutorial. &gt; Some projects may want to follow the latest master, for the newest features. If so, put the following in your stack.yaml to build and use beam in your project! &gt; Note &gt; the commit will need to be changed to whatever the latest commit of master is, or whichever commit you want to build from even. 
Thanks for the warning actually - I was just considering trying that package.
**Web scraping:** I used [scrapy](https://scrapy.org) as my preference for web scraping to just get that data into a JSON file. Not long ago I experienced [Scalpel](https://github.com/fimad/scalpel) to result in simpler scraping definitions than Python's scrapy. &amp;#x200B; **Regex:** I failed to implement a basic substitution in Haskell. The many regex libraries and their interdependencies, add to that the state of documentation still confuse me. I invested more than half a day into it. This was at least the second attempt. — Finally I implemented the substitution part in some existing Python script.
I ended up with this resolver: lts-12.6 packages: - . extra-deps: - beam-sqlite-0.3.2.3 The backend can be `postgres` as well.
Don't get me wrong: it's working fine with `stack`, I just want/need to use the v2 of cabal-install :)
The image is gone, but I suggest you look at the [MultiWayIf](https://downloads.haskell.org/~ghc/8.4.2/docs/html/users_guide/glasgow_exts.html#multi-way-if-expressions) language extension.
I think there are a lot of reasons to not use any specific language. A big one is library access. I love Haskell (it is also my favorite), but sometimes a library I need just doesn't exist. Another is performance. This isnt about Haskell per say, but any garbage collected language. If your priority is performance and you are willing to spend more time to get it, you should be looking at c, c++, or rust. Ultimately, if the project is just you, go for it. Haskell your heart out. But if there are outside considerations it's best to recognize that no one language will always be best and you should find the best tool for the job. 
If I was in your position, I would implemented it as a tree, similar to /u/Vampyrez. I'd create a data type like... data GameTree a = Accept a | GameBranch String (GameTree a) (GameTree a) derving (Eq,Show,Functor) and create a function to ask a yes/no question. askYesNo :: IO Bool You could then run your game tree. runGameTree :: GameTree a -&gt; IO a runGameTree (Accept a) = pure a runGameTree (GameBranch questionString trueResult falseResult) = do putStrLn questionString questionAnswer &lt;- askYesNo if questionAnswer then runGameTree trueResult else runGameTree falseResult You problem is to express a tree, so it feels a bit more natural to express it as a tree rather than a collection of branching IO actions. I was unsure from your diagram what it meant when you reach an accept node. This presumes you return some value, but if not you can ignore all the as or use () for a. 
I wouldn't use QuickCheck for something like this, which doesn't have any obvious patterns; I would use HSpec. There might be a way to do it though.
How is this any better than if-else?
Well, Haskell is very well suited to writing interpreters &amp; compilers, so you might certainly use the book as a guide to implementing Monkey in Haskell. The broad structure of the Haskell implementation is going to be largely similar to one written in Go, but a lot of the specifics are going to differ, whether in small ways (how you represent your data structures when you have sum types available) or in larger ways (using parsing tools like Megaparsec instead of manually writing a recursive descent parser). So I think it would be a great learning exercise, in terms of exposing you to how to translate the meaning of a program in an imperative language into idiomatic functional code—that’s something I needed to do fairly often as a beginner–intermediate Haskeller, since for example a lot of algorithms are presented in tutorials or on Wikipedia in an imperative form. Of course, you can always fall back on imperative style in Haskell using IO or ST for local mutation, but it’s not where the language really shines. As for splitting your focus, whether that’ll be a problem depends on your learning style—I like having my fingers in many pies, so to speak, and getting exposure to a wide array of different things so I can compare &amp; contrast them, but if you want to learn a *single* topic more deeply (Go, Haskell, PL implementation) then this is perhaps not the best approach. Perhaps just try it and see? I’d be interested to read a writeup of your experience! 
You've separated the evaluation of the code from the structure of the code, so you can manipulate it in more ways. You can have multiple different ways of running the tree if you want different ways to interact with the game. You can map over the question string if you want. You could extend the result of the tree with something like extendTree :: (a -&gt; GameTree b) -&gt; GameTree a -&gt; GameTree b extendTree f (Accept a) = f a extendTree f (GameBranch q yes no) = GameBranch q (extendTree f yes) (extendTree f no) You could even read it in from an external file at run time if you wanted. If you just use if-else statements, you limit yourself to one way of running this tree, and it must expressible at compile time. It also saves a bit on line noise. Trying to do imperative style programming in Haskell in do blocks is possible, but is always a bit of a hassle. I find working with a data type like this far more idiomatic in Haskell.
Glad it can help! Do you think this sort of thing would work as a plugin/library? Have you seen anything do that already?
&gt; A parameter instead of an index is always a better choice I move heaven and Earth to give a full kind signature, so you can say we disagree
But that quote is not about syntax. It is about how the unifier will be able to do more if your parameters are marked as parameters.
You should name types more. When I see signatures like subst :: Parser ((String, String), String) that don't impart to me any information about why those three strings should be together, it's a clear case of a missing documentation or type name. Especially when the type is repeated like here. I can't tell you if you should introduce a type synonym or a data type here, but a new type name is definitely warranted. 
You can also consider using a quasiquoter so you get \`assign \[v|x1|\] = 2\`, and you can trigger a compiler error if the literal fails to satisfy the requirements of \`Var\`. If you don't care about type-safety in your literals (i.e. I'm writing them once and I can be careful while doing so), just go with \`IsString\` and enjoy the \`error\` at runtime when you occasionally misspell.
Alan Kay is probably not a very popular figure in this community.
Check out the [`monad-loops`](http://hackage.haskell.org/package/monad-loops-0.4.3/docs/Control-Monad-Loops.html) package as well.
My mistake - I thought the term was being used to describe a compilation technique! I do have a question about this though - is there any intuition as yo why this number system recreates the rules of calculus? And how are higher order derivatives expressed?
I hope this helps: https://markkarpov.com/megaparsec/megaparsec.html#working-with-custom-input-streams
So in one hand the token can't be used to prove who you voted for, but on the other hand the list of tokens allows people to verify the tally? How does that work?
Uhh... Cryptography^TM Actually though, that really does sound like a blockchain (woo buzzwords!). Each receipt verifies that the one before it is correct, and therefore every receipt must be correct? Or something like that? I guess we'll find out how exactly they implemented it some day
Maybe I missed something, but what does this have to do with Haskell?
There are such things called Zero Knowledge Proofs, of which the [Feige–Fiat–Shamir identification scheme](https://en.wikipedia.org/wiki/Feige%E2%80%93Fiat%E2%80%93Shamir_identification_scheme?wprov=sfti1) is but one example where one actor can prove their knowledge of one part the system I.e. who they voted for, to check and verify either to another party or to themselves without leaking that information. I don’t know the exactly scheme used in this instance but it’s likely to be one such Zero Knowledge Proof
Author here. It looks like you've used the commit in the docs. As others have said, you should move it up. In terms of stackage... I've just bumped the minor version and am doing a whole round of releases, but first have to get CI working to build the documentation. Look for an announcement here on reddit!
Galois is a software consulting company with a focus on correctness. They use a \*lot\* of Haskell in their work, and are active contributors to the community.
That's pretty cool then, thanks
The million dollar question that doesn't by itself answer is how to convince participants that an election is valid without provoliding them any way to associate themselves with their selection in any way that can be used to show other people who they voted for. That part of it totally went by me until someone pointed it out, but if people get any kind of receipt of how their vote was cast as proof, all elections become open season for anyone who wants to buy votes (even moreso than they already are).
One of the features of the paper system is that I am not able as a voter to prove how I voted, yet be reasonably sure by orgaziational means that the vote is counted properly. It seems to me that my ability to trust the system by allowing me to check that my vote counts properly means that I will be able to prove how I voted to a 3rd person.
&gt;Glad it can help! Do you think this sort of thing would work as a plugin/library? My requirements are a little different. I am using the a "published" date field to determine if a post is finished, or if it's still a draft. The date (if published) goes in the filename as well as the title, and posts move from "drafts/" to "posts/" when published. Eg: "drafts/my-blog-title.html" -&gt; "posts/2018-03-17-my-blog-title.html". Maybe with some thought an API could be designed that let you customise on this level, but on the other hand, maybe my requirements are so specific that it's not worth it. Either way your example code got me on the right track. &gt;Have you seen other plugins or the like? I had actually got as far as looking. I'm not a front-end dev so I had not come across the term "slug" before so I hadn't really even be sure what to search for.
This is kind of a tangent, but one thing I’m super enamored with lately is the method described in [Ghosts of Departed Proofs](http://kataskeue.com/gdp.pdf), which is akin to the smart constructor technique, but separates the validation from the construction. It’s massive overkill for this use case, but for example: -- Tying a value to a name newtype name ~~ a = Named a -- Locally binding a type-level name to a value -- (Not used here) name :: a -&gt; (forall name. (name ~~ a) -&gt; r) -&gt; r name x k = k (coerce x) -- Annotating a value with a proof newtype a ::: p = SuchThat a -- Tags for proofs of properties of characters data IsLetter c data IsDigit c -- Zero-cost wrappers for characters along with proofs about them data Letter where Letter :: (c ~~ Char) ::: IsLetter c -&gt; Letter data Digit where Digit :: (d ~~ Char) ::: IsDigit d -&gt; Digit -- Construct values proven to have a certain property proveIsLetter :: Char -&gt; Maybe ((c ~~ Char) ::: IsLetter c) proveIsLetter c | isLetter c = Just (SuchThat (Named c)) | otherwise = Nothing proveIsDigit :: Char -&gt; Maybe ((d ~~ Char) ::: IsDigit d) proveIsDigit d | isDigit d = Just (SuchThat (Named d)) | otherwise = Nothing -- The type of variable names: one or more letters, zero or more digits -- (Same representation as a pair of lists) data Var = Var (NonEmpty Letter) [Digit] -- Constructing letter and digit strings letterString :: String -&gt; Maybe (NonEmpty Letter) letterString = (nonEmpty =&lt;&lt;) . sequence . fmap (fmap Letter . proveIsLetter) digitString :: String -&gt; Maybe [Digit] digitString = sequence . fmap (fmap Digit . proveIsDigit) -- Now it’s only possible to construct a Var with the appropriate invariants (Var &lt;$&gt; letterString "abc" &lt;*&gt; digitString "123") == Just (Var ('a' :| ['b', 'c']) "123") (Var &lt;$&gt; letterString "" &lt;*&gt; digitString "123") == Nothing (Var &lt;$&gt; letterString "123" &lt;*&gt; digitString "123") == Nothing (Var &lt;$&gt; letterString "abc" &lt;*&gt; digitString "abc") == Nothing (Parts of this need to be encapsulated to prevent misuse by client code, just like with smart constructors.) The advantage of doing it this way is that you can build much more complex &amp; interesting proofs, carry them around at compile time, and avoid redundant checks. For instance, if we extract a character from the `Var`, it retains its proof of what properties it has, and we can reuse those elsewhere for functions that operate on individual characters. And this generalises to much more interesting data structures and use cases. 
It's possible to give the voter confidence that what they voted for is correct without giving them the ability to probe it to anyone else, see [5:15 in this video](https://youtu.be/BYRTvoZ3Rho#t=315). It's pretty high level so you might want to watch a full talk on end to end verifiable voting systems if you're genuinely interested. The system I've seen requires that the machine that is used to verify the vote is a different one (e.g. verified by some volunteers of a political party that you trust, but they have no way of knowing that you're actually voting that way since you can print off as many test votes as you want). The process is pretty complicated so I'm not convinced it will ever catch on, but it's always great for these boundaries to be pushed.
PureScript?
PureScript looks fantastic too - they appear to have a great community and loads of interest in category theory, and of course it's strict so that fits more closely to JS. My particular use-case is that I have some domain logic in Haskell that I also execute on the server, so Haste fits a bit better for that - sharing validation is a big win for rich apps.
I’m not saying your usecase isn’t valid, but there are so many “do Haskell or Haskell-like thing in the web” solutions out there that it simply isn’t surprising that not all of them excite people.
That's a fair point :)
It seems much cheaper to buy newspapers, social media companies, politicians, and union leaders than individual votes. It’s also possible to outlaw the provable selling of votes.
Template Haskell and GHC 8 are actually a very big deal for production work, especially on the web. One of the biggest issues with Haskell on large scale web applications is keeping the boilerplate of your typical "domain entity" record types to an absolute minimum. You don't want to write out all the SQL, Aeson instances, to-and-from URL logic, and all that stuff, by hand, for every single one of your domain types, and you also want to be able to change the way all that boilerplate works in one place, rather than duplicating the patterns across the codebase. In other words, you want explicit abstractions for all this, and many of these abstractions will have to live at the meta level. And this generally means you need either TH, or Generics, or advanced type-level programming features, or resort to code generators (ugh). GHC 8 has many many new features on the generics and type-level-programming fronts, but given GHC 7 minus TH, you're going to be in a rough spot. Another huge issue is the library ecosystem. You want to have all, or at least the interesting majority, of hackage available to you, but with the "GHC 7, and no TH, and also no C FFI" constraints, this too puts you in a rough spot. As a result, many of the benefits of "same language for client and server" melt away: you are not actually using the exact same language (GHC 8 on the server, GHC 7 without TH and C FFI on the client), and you need to do most of the things you would also do on a polyglot stack.
Hey thanks for answering! I've come to this solution: **stack.yaml** resolver: lts-12.6 packages: - . extra-deps: - beam-sqlite-0.3.2.3 **packages.yaml** dependencies: - base &gt;= 4.7 &amp;&amp; &lt; 5 - uuid - text - time - hspec - containers - beam-core - beam-sqlite - aeson - containers - free - sqlite-simple
I don't know what their implementation does, but it's possible to do this with just blind signatures, which are fairly well understood cryptography. You get a blind signed ballot after proving you're a property registered voter (which can be done traditionally or with public key crypto}. You fill out out, and add some number you made up, and turn it in. Because it was blind signed, the election workers don't know who they originally gave it to, they only know they signed it. They publish all the votes online so everyone can count them. You know your vote was counted by searching for the number you made up. No one else knows how you voted.
Idea of composable proofs sounds really interesting! I need to explore Ghosts of Departed Proofs more.
That's a really insightful reply - thanks a lot for taking the time to work through it all.
This is still very prone for literally purchasing votes. The one buying asks you to show him (live) the verification with your made-up number.
I would really like a unification or some other more aggressive approach towards language extensions. Maybe an opinionated basic/advanced/type-level heavy pragma would be great. &amp;#x200B; I feel like the usage of a lot of pragmas correlate and I am quite annoyed by the plethora of language extensions. Something like: *I want to enable all the usual type-level extensions and two non-standard ones* would really help me understand what I am dealing with in the code. It would help me recognise less common extensions. Maybe some empirical analysis of the correlation between language-extensions would help me to make a convincing argument? I am normally a machine-learning/data-science/statistics dude. I think I could do that without that much hassle. Maybe the compound-pragmas should also be data-driven by popularity and correlation.
I worked on a web app with complex frontend interactivity for something like two and a half years. It was basically a web-based collaborative [Tableau](https://www.tableau.com/#hero-video) clone...so quite a lot happening in the frontend. It started out with an EmberJS frontend and a Haskell backend. The frontend quickly became very difficult to work with. After implementing only a small subset of the functionality the app eventually got to, it got very hard to update without causing regressions. See [this blog post](http://softwaresimply.blogspot.com/2014/01/emberjs-is-driving-me-crazy.html) for a small taste of this. Pretty quickly we decided that this situation was untenable and a coworker rewrote the frontend in Haskell with Haste. This was a definite improvement and we continued to implement more frontend functionality. But we discovered that even though the differences between Haste and GHC looked small on paper, it was different enough that code reuse between the frontend and the backend was quite low. There are a huge number of Hackage libraries that you can't use and we had to duplicate a lot of code for even really foundational infrastructure like `aeson`. After awhile we completely rewrote the frontend from the ground up using GHCJS and Reflex. We were able to achieve feature parity with three people in a week and a half and had a 40% reduction in lines of code! Now, not all of this difference in code size is due to the Haste/GHCJS switch. A significant component of it was because Reflex made building frontends much easier and more concise. But Haste was also a significant factor as well. GHCJS allowed us to simply depend on things like `aeson` out of the box instead of having to roll our own or jump through hoops to get code reuse like we had been doing with Haste. Now to be clear, GHCJS isn't perfect either. For example, [TemplateHaskell is quite slow](https://github.com/mightybyte/ghcjs-perf). This resulted in us avoiding TemplateHaskell in our frontend code. But this problem is not really an issue for libraries which are rebuilt very infrequently and with Nix will probably be cached and not built at all. Also, from what I understand Haste improved significantly since we stopped using it on that project. I didn't keep up with the details, but from what I understand it got a good bit better. I would say it would be worth looking into it again, but if the Cons you mention above are still accurate, I think I would say the scale tips in favor of GHCJS. Even if Haste did support TemplateHaskell now, there are other seemingly minor features that are important. For instance Reflex makes significant use of weak references to achieve its level of performance. So if Haste added TemplateHaskell support but still didn't have weak references, you wouldn't be able to leverage the benefits of Reflex.
Vote buying is not an attack on a straight popular vote. IMO making resistance to it a requirement is a mistake. If the people choose to sell out for $50 apiece, that is their own choice. You can't have it both ways - either the people are responsible enough to make their own choices, or they're not. If they are, vote selling is acceptable. If not, democracy cannot work.
This notion of an "infinitesimal" `d` directly lines up with the way that Newton and Leibniz used think about derivatives until later folks figured out the more modern and more rigorous epsilon-delta formulation. So I suppose its more interesting to me to question how the epsilon-delta stuff matches up with this rather than vice versa. ;) That said, this sort of form pops up in a ton of contexts. You can compute similar derivatives using the same formal set of rules for algebraic data types (getting zippers) for regular expressions (giving the regex that matches a prefix or suffix of a string once part of it has been matched), or heck you can do both of those things at the same time by getting creative and [looking at matrices of types](http://ozark.hendrix.edu/~yorgey/pub/type-matrices-mpc-15.pdf), the [calculus of finite differences](https://en.wikipedia.org/wiki/Finite_difference#Calculus_of_finite_differences) fits this mold, etc. Almost all of these usecases have the same sort of "[differential ring](https://en.wikipedia.org/wiki/Differential_algebra)" structure. (You can go further and handle more interesting grammars if you relax that a bit.) If you want to see another use-case, these old WordNumbers posts by Chung-Chieh Shan are also pretty good. [http://conway.rutgers.edu/~ccshan/wiki/blog/posts/WordNumbers1/](1) [http://conway.rutgers.edu/~ccshan/wiki/blog/posts/WordNumbers2/](2) [http://conway.rutgers.edu/~ccshan/wiki/blog/posts/WordNumbers3/](3) [http://conway.rutgers.edu/~ccshan/wiki/blog/posts/WordNumbers4/](4) He talks a bit more about what you need from concept of a number to be able to perform this trick. &gt; And how are higher order derivatives expressed? One way is to iterate the construction. (a + δ_1b) + (c + δ_1d)δ_2 I use this sort of approach to [compute Hessian matrices](http://hackage.haskell.org/package/ad-4.3.6/docs/Numeric-AD.html#v:hessian). (Though I use the aforementioned reverse mode for computing the gradient, then I compute the derivative using forward techniques for each part of the gradient to get the Hessian. Another way is to modify the recursion so the coefficient of delta is already in this form, then you just get a tower of derivatives as a lazy list. I have this mode in the `ad` package as [`Tower`](http://hackage.haskell.org/package/ad-4.3.6/docs/Numeric-AD-Internal-Tower.html) This is used to implement `diffs`, which gives a lazy list of all the derivatives of a unary function. I have other techniques in the library for handling kth derivatives of n'ary functions, giving them back in a cofree comonad you can peel Cofree f a = a * f (a * f (a * ...))) The first `a` is the result, The `f a`s you can get by projecting out are the first derivatives, `f (f a)` provides the second derivatives, etc. This process of projecting layer by layer is supported through a funny data type I offer up called a [http://hackage.haskell.org/package/ad-4.3.6/docs/Numeric-AD-Jet.html](Jet), which models the infinite product data type: a * f a * f (f a) * ... ghci&gt; headJet $ tailJet $ tailJet $ jet $ grads (\[x,y] -&gt; exp (x * y)) [1,2] [[29.5562243957226,22.16716829679195],[22.16716829679195,7.38905609893065]] and in the computation of that I carefully account for all the symmetries to reduce work.
I have tried Reflex, I spent a year of evenings trying to get my head around FRP and how best to model my app, but honestly that level of sheer complexity in between me writing something, waiting for a compile, and the pile of JS that comes out the other end has really put me off. It's put me off even looking at my project. I should say that my project mostly works, but I'd prefer to delete the whole thing than fix the bugs and add features, just to save on sanity points! Afaik the performance Reflex gives in the browser isn't great either (after downloading all that JS) - the response for which appears to be to compile to native and use an Android/iOS app version, which doesn't fit my use case - not that I got any real performance issues anyway, I'm merely replying to what you said. That is to say: I don't consider Reflex' benefits to be worth the (imho) large cost - but I guess I'm just too dumb to get it all to fit together nicely :) tbh I spent most of the time wishing I knew someone to mentor me because hitting problems like lockups with 100% CPU usage are pretty crushing when you have nobody to turn to (and nobody awake in the channel since I'm on UK time). It's just not viable for me as a lone Haskell student with a Java day job. Whereas Haste seems (so far - I've not had time yet to find other dark corners I didn't mention) to give me a simple way to build, say, a React JS app without the headache of untyped JS. I've managed to get a prototype Elm-like program running with very problems despite being completely new to Haste.
What if your boss says, "vote for my candidate or lose your job." Many people can not afford to lose their jobs. So it just gives more power to the ruling class. &amp;#x200B; Being enticed into selling your vote is one thing, being coerced is another. A system which makes it impossible to be coerced is desirable, IMO.
100% agreed. Our code at works relies on ghcjs being able to compile TH and hundreds of dependencies from hackage. Haste is a non-starter. It would be a better use of money to make ghcjs faster and produce smaller output than to try to get everything built with haste.
There is no such system. If the system can prove to you your vote was counted, you can cooperate to pass that proof to someone else. So you can be coerced. The current system cannot prove your vote was counted, which IMO is way worse than being open to coercion.
Exciting news! &gt; it will be built on secure open source hardware Like risc v, or something less general purpose?
why not just put the usual ones to project level, into the cabal or hpack file ?
This isn't true, there could easily be a system that has multiple "keys" --- one to correctly verify your result, one to "verify" it to whatever candidate you want. The presence of such a scheme would make vote buying (theoretically) impossible. Of course, such a system sounds difficult from a UI perspective.
&gt;it will be built on secure open source hardware What, RISC-v isn't unpopular enough for you?
Are you saying that because you have not thought of a way and therefore assume it is not possible? Or do you have knowledge of systems like punchscan and understand their weaknesses? [https://en.wikipedia.org/wiki/Punchscan](https://en.wikipedia.org/wiki/Punchscan) &amp;#x200B;
Rumour has it that some money is about to be sunk into making ghcjs better, so...
It's not possible, the system you linked to has no such property. In every case, whoever is coercing you just demands you bring them whatever proof you'd get yourself that you vote was counted. 
Whoever is coercing you would just demand your key.
Note that my above comment (like the similar one from /u/tdammers) is not about Reflex. It's about things inherent in GHCJS and Haste no matter which framework / libraries you're using. &amp;#x200B; &gt;writing something, waiting for a compile This is a function of GHCJS, and it was definitely an obstacle with the project I mentioned above. But the situation is dramatically better today thanks to \[obelisk\]([https://github.com/obsidiansystems/obelisk](https://github.com/obsidiansystems/obelisk)). You can see the rapid development loop enabled by obelisk in action in \[this demo\]([https://www.youtube.com/watch?v=riJuXDIUMA0&amp;feature=youtu.be&amp;t=1858](https://www.youtube.com/watch?v=riJuXDIUMA0&amp;feature=youtu.be&amp;t=1858)). For most apps it's change code, compile, and test in your browser as fast as you can switch tabs. All the complexity of setting up the rapid feedback development cycle, closure compiling your generated javascript for deployment, etc is handled by obelisk and you con focus on building your app. It's a way better experience than what one probably would have experienced as recently as just a year ago. If you haven't tried it, I'd say it's worth a second look.
The point is that there could be multiple keys, all of which "validly" certify you voted for any particular candidate, but only one of which (which only you know) is the "correct" key. A third party couldn't demand your key here, because you could just give a key which certifies you did what they want without this being true.
[http://punchscan.org/](http://punchscan.org/) absolutely claims to have that property: &amp;#x200B; &gt;**End-to-end cryptographic independent verification, or E2E,** is a mechanism built into an election that allows voters to take a piece of the ballot home with them as a receipt. This receipt **does not allow voters to prove to others how they voted**, but it does permit them to: &gt; &gt;Verify that they have properly indicated their votes to election officials (cast-as-intended). &gt; &gt;Verify with extremely high assurance that all votes were counted properly (counted-as-cast). &gt; &gt;Voters can check that their vote actually made it to the tally, and that the election was conducted fairly. The FAQ also addresses it: [http://punchscan.org/faq-general.php.html#1](http://punchscan.org/faq-general.php.html#1) [http://punchscan.org/faq-protections.php.html](http://punchscan.org/faq-protections.php.html) The entire point of the system is that you can verify your vote using the receipt, but the receipt itself can not be used to figure out your vote. If someone demands the receipt, the only thing they can do with it is verify the integrity of the election. &amp;#x200B; &amp;#x200B; &amp;#x200B;
Try `ghc -package xmonad ~/.xmonad/monad.hs`
you should shrink the bug and report it to ghc. Or are you doing unsafe coerce somewhere?
If you know that a new reminder will not be added until the next soonest reminder, you can just sleep until that time. Otherwise, you could poll with an increased period, e.g. once a minute, and `threadDelay (min untilNextReminder pollPeriod)`. That way you can be late at most a single period (if a reminder is added and is due just after last poll). Then there are long polling and other, more involved, methods that will likely require to intercept the addition of a new request to the table and notify the client. --- You probably don't want to [`threadDelay`](https://hackage.haskell.org/package/base-4.12.0.0/docs/Control-Concurrent.html#v:threadDelay) for 3 ms too.
That does not compute. Purescript is much more difficult to integrate with Haskell and yet it has much more traction. Haste is much more easy to integrate and share code with the haskell server and it works pretty nicely. The amount of JS generated is not much more than the one generated by purescript. The answer why very good libraries often way better than the average are not disregarded is sociológical if not tribal. It is a matter of who own the loudspeaker of what is and what's not cool, the influencers, and the cheering and support that the author of each library has around it.
Wow! This is cool. In section 6 we are presented with the type-level equivalent of `foldl`: type family Foldl (f :: b ↠ a ↠ b) (z :: b) (xs :: [a]) :: b where Foldl f z ’[ ] = z Foldl f z (x ’ : xs) = Foldl f (f z x) xs So we basically have the exact same implementation, duplicated at the term and type level. Seems to me like DependentHaskell is the natural next step, as it lets us avoid this term/type level duplication. 
Indeed! Well done. I vaguely understand type families, and section 6 (*TYPE FAMILIES IN PRACTICE*) was very easy to understand for me.
`data Jet f a = a :* Jet f (f a)` How does this not lead to a divergence at compile time when `f` is anything other than `id` or a `const` function?
This is a data type. You pay for what you look at in it. Just like an infinite list. data Stream a = a :- Stream a deriving (Show) ones = a :- ones works just like ones = 1 : ones with a normal list. You can 'take 10 ones' and work with any prefix you want, traverse it and produce the results by printing them to the screen. etc. Just like any other infinite structure in Haskell.
It got a fair bit of use when it first came out, including a [bit of trolling](http://cokmett.github.io/cokmett/) directed at me =), but since then the buzz has been muted, largely because of the Cons you mention. Without TH, lenses are harder to use and a lot of boilerplate needs to be written, its different enough from normal Haskell that a lot of stuff just doesn't work, its lagged far enough behind mainline GHC that you don't get much code compatibility if you are trying to do an "isomorphic" web app sharing code between client and server, and there are large chunks of what we do today in GHC that aren't supported, like finalizers. The lack of those mean APIs like Reactand other FRP-like solutions, which lean on them heavily generally don't work there. In the face of those restrictions and a bunch of early usage failures, GHCJS managed to sweep in and steal its audience.
I haven't used `unsafeCoerce`. But it's possible that some library I'm using is doing that. I'm able to crash GHCi consistently when trying to debug this issue. It should be reproducible with the following commands: git clone https://github.com/runeksvendsen/bellman-ford.git -b ghc-bug-report cd bellman-ford/ stack setup stack repl bellman-ford:lib bellman-ford:exe:bellman-ford-exe and in GHCi: :break Data.Graph.BellmanFord 111 main :steplocal :steplocal :force vertexCount :steplocal :print vertexCount resulting in: [/Users/runesvendsen/tmp/bellman-ford/src/Data/Graph/BellmanFord.hs:112:30-37] λ&gt; :print vertexCount &lt;interactive&gt;: panic! (the 'impossible' happened) (GHC version 8.6.4 for x86_64-apple-darwin): isUnliftedType t1_agDZ[rt] :: TYPE t_agDY[rt] Call stack: CallStack (from HasCallStack): callStackDoc, called at compiler/utils/Outputable.hs:1160:37 in ghc:Outputable pprPanic, called at compiler/types/Type.hs:2021:10 in ghc:Type Please report this as a GHC bug: http://www.haskell.org/ghc/reportabug I'm not sure if it's the same issue. Something seemingly goes wrong with printing the value of `vertexCount` after evaluating `Arr.newArray` at this location: https://github.com/runeksvendsen/bellman-ford/blob/6f5262586fe0cb30405a28dbd5c84aab1dd3c38f/src/Data/Graph/BellmanFord.hs#L112. 
Fascinating. Maybe this kind of definition works because of Haskell's lazy semantics? In dependently typed languages like Idris could a type definition still be written like that or would it need to be wrapped in a lambda... data Jet f a = a :* (\x -&gt; Jet f (f a)) That is something like this pseudo-code for the sake of delaying evaluation at the type level?
The thing is that the reminders are dynamic. So, I can't know for sure if another one hasn't been added in the meantime. \--- Also, I meant to `threadDelay` for 3 secs. Thanks for cathing this.
In Idris you'd need to use an explicit Lazy annotation on the tail there.
Nah, we don't make mistakes. ;)
Idris is strict, so you'll have problems writing a value of type `Jet f a` if `f` is a "strictly positive" functor like `Identity` or `NonEmpty`. You will probably want to wrap the second element of the product in `Inf` (`Delay`) to make it like a lazy stream. Even after that, I had problems making a proper empty tail (something of type `Jet List (List a)`), Idris had issues unifying the type function application with its result. Type mismatch between (List a, Inf (Jet List (List (List a)))) (Type of (the (List a) [], Delay empty)) and Jet List (List a) (Expected type) --- Jet : (f : Type -&gt; Type) -&gt; (a : Type) -&gt; Type Jet f a = Pair a (Jet f (f a)) Will work until/unless the totality checker gets ahold of it, in which case it will see recursion that isn't based on a sub-structure relationship and flag it as partial. `Inf` won't help you satisfy the totality checker; you'd either need to put in an assertion or rewrite it in a less straightforward way using the [`WellFounded`](https://github.com/idris-lang/Idris-dev/blob/master/libs/prelude/Prelude/WellFounded.idr) part of the standard library. --- Agda might be a better PL for something like this, but the totality and positivity checkers are "always" on there, so it may be even harder to satisfy despite laziness being the default.
For what it's worth, this: (flip mapM) reminders (\rem -&gt; do sendEmail rem) doesn't need the `do`: (flip mapM) reminders (\rem -&gt; sendEmail rem) and then you can eta reduce the last part: (flip mapM) reminders sendEmail and then you could import `forM` (and `forM_`) from `Data.Traversable` which give you `flip forM`: forM reminders sendEmail But since you are ignoring the results you probably want `forM_`: forM_ reminders sendEmail Of course at that point it's probably more idiomatic to just use `mapM_`: mapM_ sendEmail reminders and then you don't need the extra import.
I'm just responding to the "It's GHC 7 without TH, but that shouldn't be a big deal" part - it *is* a big deal. That's all I'm saying. Whether that makes Haste a no-go, I can't tell; but I can tell that this restriction may be a bigger turn-off than OP seems to realize.
Try moving to 8.6.4. The libraries in 8.6.3 were not correctly synced with hackage and this can cause a lot of installation problems. 
hrmmm, so you're writing +infinite as 1/0, thats OK hrmm, have you tried a profiled build with -xc (or whichever command causes ghc to print out stack traces for every exception?) also: if you run this on linux, you can get a real DWARF stack trace with the exception? does this crash only happen in GHCI? i dont think ghci supports unlifted stuff last i looked (but I may be out of date) also i can't debug stack based examples, against my code of conduct/i dont use stack ever! :) i'm not super familiar with the Array package internals. hrmm 
That does sound enticing - I used the Reflex skeleton and it was pretty good but the compile times went up a lot. I'll check out Obelisk!
That trolling is pretty high quality! I'll have another look into GHCJS - it's mostly the size of the output that put me off it. Thanks for explaining a bit more about the context.
What about data SomeRegression where SomeRegression :: (KnownNat i, KnownNat o) =&gt; Linear i o -&gt; SomeRegression
I'm unfamiliar with hasktorch, but to answer your question about nat types dependent on runtime values, there are two methods I'm familiar with- either using the function someNatVal in GHC.TypeLits, or using the [reflection](http://hackage.haskell.org/package/reflection) library: foo :: KnownNat n =&gt; Proxy n -&gt; Bool foo n = natVal n &gt; 3 bar1 :: Integer -&gt; Bool bar1 i = case someNatVal i of Nothing -&gt; error "'i' wasn't a natural!" Just (SomeNat s) -&gt; foo s bar2 :: Integer -&gt; Bool bar2 i = reifyNat i foo baz = do print $ bar1 4 print $ bar2 4 print $ bar1 1 print $ bar2 1 bar1 requires importing GHC.TypeLits in base. bar2 requires importing Data.Reflection from the reflection library.
Not familiar with the library specifically, but this is roughly how you'd turn a runtime integer into a type-level Nat (you need to enable the `ScopedTypeVariables` extension): ``` case someNatVal n of Just (SomeNat (_ :: Proxy n)) -&gt; -- Now n is available as a type variable with a KnownNat instance let r :: Regression n = ... in ... Nothing -&gt; -- This case only happens if n is negative ```
The uninitialized vector error means you didn’t initialize a vector. You should maybe do that? :)
It worked! However, is there a way to make this work with the "regular" `xmonad` command?
I tried this, uninstalling GHC and Cabal and reinstalling with v8.6.4, however the problem persists. Is there any additional setup required?
That's a very interesting use case! I hope metadataRoute and maybe even gsubRoute have helped you. Thanks for taking the time to respond.
That I don't know. I just knew how to parse &amp; solve the error you got :)
I'm having some confusion related to existential types. It is easy to write a function check :: forall a. Eq a =&gt; (Bool -&gt; a) -&gt; Bool check k = k True == k False but I think it shouldn't be possible to write a function equivalent to check' :: (exists a. Eq a =&gt; Bool -&gt; a) -&gt; Bool check' k = k True == k False -- ERROR as you could supply an argument which returns values of different types depending on whether the argument is True or False. Here is a CPS-ed version of a problematic argument you could supply: -- het :: exists a. Eq a =&gt; Bool -&gt; a -- het :: Bool -&gt; (exists a. Eq a =&gt; a) het :: Bool -&gt; forall r. (forall a. Eq a =&gt; a -&gt; r) -&gt; r het b k = if b then k 1 else k ":(" -- OK However, it seems that the types for `check` and `check'` should be isomorphic. What step in my reasoning is flawed?
The token tells you that you voted for C. You know that because when you voted it told you on the screen that your candidate is X and the code for it is C. But you cannot prove to anyone that C stanbds for candidate X. Only you know it. &amp;#x200B;
Buying votes cannot be countered by paper ballot. All you have to do is to make a photo of your ballot and show it to the buyer as a proof. The point of anonymity in voting is not in preventing buying the vote. It is in preventing forcing people to vote as the buyer wants.
The publicly available ballot does not say who you voted for. It only says that the code you voted for is X. You know it is true because you have a print out with the same code. But you cannot prove to anyone that the vote was for specific candidate.
You are mistaken. You can easily prove how you voted. Just take a photo of your ballot.
A higher order function is a function that takes another function as an argument. The canonical examples are map, fold and filter. So rewrite the list comprehension or recursive version of this function using fold.
You might want to look at scanl.
On second thoughts. Filter is a higher order function - that is obviously well matched to this problem.
that was actually my first instinct and what I had been trying before I made this post. however I can't get the syntax right I understand that filter works as follows: "show me only items that meet this criteria from this data structure" so I tried filter (==0) n `mod` [2..n-1] but that fails because it wants a list to filter through. tried a few other things I have since overwritten that I may pull up and type in soon. The error message I keep getting usually has to do with trying to restrict results to n-1
Ignoring the niceties of currying, filter takes 2 arguments - a function and a list - and returns a list. In your example, you have the list OK, but the function, well, isn't? Go simple first and pass a full fledged lambda function. For this example it will have the signature: `f :: Integer -&gt; Bool` and the form: `(\i -&gt; put code here)` So the whole thing will look like: `filter (\i -&gt; put code here) [2..n-1]` On a separate point - do you need to go as far as `n-1`?
You might want to look at the type of filter `filter :: (a -&gt; Bool) -&gt; [a] -&gt; [a]`. Now you already have the list of a. What you need to do is to figure out how to fuse `n \`mod\` ` and `(==0)` into one function that has the type signature of `a -&gt; Bool`. You are pretty close to the right answer.
&gt; do you need to go as far as n-1? the assignment says: &gt;In this assignment, you are going to write a Haskell function factors to find all **proper** factors of a positive Integer. Given a positive Integer value n, a proper factor of n is defined to be an Integer value i between 1 to n (exclusively) such that n is divisible by i; that is, the remainder of dividing n by i is zero (0). **Note that although n is divisible by both 1 and n, they are not proper factors of n.**
Try isfactor :: Int -&gt; Int -&gt; Bool isfactor n f = (mod n f) == 0 factors :: Int -&gt; [Int] factors n = if n &lt; 3 then [1, n] else filter (isfactor n) [2..n-1] Or something more like that. The problem with that approach is that to the compiler, it looks like you're passing 4 arguments to filter rather than the two it expects. 
This does not prove that you have actually submitted the ballot.
Well if you are this committed you can video yourself putting the ballot into the box. Again, quite easy.
thank you. I saw the answer but didn't want to just copy paste it. 
(I think what they're saying is that the largest proper factor of n has a tighter bound than just n-1. What is the biggest factor of 20? 30? 200? How about 25? What more can we say about the largest factor, other than "it's less than n"?)
Academic honesty is a good thing. This way is better for learning, too.
OK, but are there ever any proper factors of n between (n \`div\` 2) and n?
you're right, I just used the list comprehension version to test it and there are not proper factors of n between n `div` 2 and n. so what effect would this have on the list? I ended up modifying my list comprehension version a bit to "qualify" as a higher order function for now. (list comprehension creates a list of factors, filter then filters out items in the list that are greater than 0 ¯\\_(ツ)_\/¯ ) the assignment is due Tuesday so ill keep working on it until then but for now I need to get some sleep. its hacky and cheap but it passes all tests. side note: i tested 8675309 and its apparently a prime number lol
Oh, of course, thanks! I should stop playing with this stuff after midnight :)
Sometime I used to leverage the view pattern and pattern matching to encoding a tree to a function like: ``` gameTree (canTwoDice -&gt; True) _ _ _ _ _ _ = ... gameTree (canTwoDice -&gt; False) (canPlayTwice -&gt; True) _ _ _ _ _ _ _ = ... gameTree (canTwoDice -&gt; False) (canPlayTwice -&gt; False) _ _ _ _ _ _ _ = ... ``` Also you can decouple the large function above to multiple similar function.
I fixed this error. Now I'm getting a segmentation fault. The `uninitialised` error was caused by me naively copying all the items of an exponentially resizing array inside a `Deque` (http://hackage.haskell.org/package/mutable-containers-0.3.4/docs/Data-Mutable.html).
&gt; hrmm, have you tried a profiled build with -xc (or whichever command causes ghc to print out stack traces for every exception?) Running with `-xc` makes no difference. I still just get a segmentation fault. &gt; also: if you run this on linux, you can get a real DWARF stack trace with the exception? I will try running it on Linux through gdb, but as far as I can see I need to recompile GHC to gain DWARF support, which I'm not comfortable with. &gt; does this crash only happen in GHCI? i dont think ghci supports unlifted stuff last i looked (but I may be out of date) I'm not sure if it's the same crash that manifests as a segmentation fault when running the executable. Also, `Vertex g` isn't unlifted, unless I'm missing something. &gt; also i can't debug stack based examples, against my code of conduct/i dont use stack ever! :) Fair enough. But I find it's a pretty good way of managing dependencies for my projects. Particularly when they grow in size.
Buying votes was effectively prevented for ~200 years after the application of secret paper ballot the first application for democracy. While today, with the advent of ubiquitous smartphones and 1$-at-Aliexpress buttonhole cameras it has lost its feature, that doesn't mean that we shouldn't strive for restoring vote-buying-prevention-properties for a newly-to-be-envisaged system to take its place. Quite the contrary!
So the guy buying the votes can ask you to hand over or disclose the code.
If you willngly submit to vote buying, you do not have democracy, you get oligarchy: the vote is not popular any more, but a battle between the top 1%, decided who has means and willingness to buy more votes. There is a reason secret paper ballot was introduced with yhe French Revolution 200-some years ago: it mitigated vote-buying quite effectively until the advent of ubiquitous smartphones and microcams. 
The current system does ensure it, because each running party nominates observers who together count the votes. It gives you assurance that there was no systematic false counting candidate X for Y.
Which will tell him nothing. All the code says is that on ballot 12345 you chose C (not name of the candidate). And each ballot will have different random codes for different candidates. You can only verify online that the ballot 12345 does indeed recorded with choice C. Nothing else. Not who voted, and not for whom the vote was.
Punchscan is not used in most developed democraties for a reason. Paper ballot and counting together by trusted nominees of the running parties is the standard. 
If you cannot prove to an third party the you cannot be convinced of cast-and-counted as intended.
But then you couldn't be sure that the voting machines are not rigged and code that claims to be the "right one" indeed is. If you get handed a code for alp candidates and the machine tells you "that one that is associated with the party you voted for is the one that's gonna be counted" you can kever know whether this assertion is true. With paper voting systems you have counters present from all four, five, or however many running parties ensuring that overall no false counting happens.
Yeah, but the system stood up 200 years after it was designed for general use in a democracy. When introducing a new standard we should strive for the same assurance and not submit to the fact that it was rendered insecure by now-ubiquitous technology twohundred years later.
Open source hw and full open source sw stack and interpreted rather than compiled with full read-access at the terminals is the only way that can give somewhat trust tjat the system was not rigged.
This will need the GADT pragma
You can prove it by taking a picture of the screen.
The flaw in the reasoning is the handling of qualified types. `(exists a. Eq a =&gt; Bool -&gt; a) -&gt; Bool /~ forall a. Eq a =&gt; (Bool -&gt; a) -&gt; Bool`. I believe you are at least somewhat aware of the connection between forall &amp; functions and the analogous one between exists $ tuples. This has to be extended to the constraints as well. `Eq a =&gt; ...` means we require the typeclass dictionary as an argument and pairs well with forall. To get something that pairs well with exists we need some tuple like thing that has the typeclass dictionary as the first component and a value of some type as the second component. Using some hypothetical syntax we need `(exists a. Eq a *&gt; Bool -&gt; a) -&gt; Bool`. So when we use this as the type of `check` the pattern for `k` brings both the type `a` from the `exists` and the `Eq a` dictionary "into scope" along with the `Bool -&gt; a` function. We can actually simulate this using the `Dict` type (modulo support for exists, but you can do that as a datatype as well) data Dict :: Constraint -&gt; Type where Dict :: c =&gt; Dict c check :: forall a. Dict (Eq a) -&gt; (Bool -&gt; a) -&gt; Bool check Dict k = k True == k False check' :: (exists a. (Dict (Eq a), Bool -&gt; a)) -&gt; Bool check (DIct, k) = k True == k False
Yeah, so you have to trust the system, that when it says "hey, you casted for candidate X, your code is alpha, and **alpha will be counted towards X**", it actually does. With this system you can *centrally* rig the system to whatever outcome without means for the voter to be sure about his vote. Nay, mate. This is not a viable solution.
The Justin Le post ["Existential Neural Networks and Types at Runtime"](https://blog.jle.im/entry/practical-dependent-types-in-haskell-2.html) might be useful. It doesn't use Hasktorch but the principles might still be applicable.
&gt; [..] because the internet has way too many solutions with "data Expr" :D So, you're saying you can't use _proper techniques_ in your exercise because you fear your students will copy it? That's terrible. You want to teach your students how to write clean and idiomatic code. It's like washing your hands: If your parents never did it right, you won't do it right later in life. What you can do instead is either make your task harder or introduce uncommon concepts. Then you can quickly find out whether they did it on their own.
The default way to do this is using a script named build, that would call stack or cabal with all the right packages available. If `ghc-pkg list` shows both `xmonad` and `xmonad-contrib` (I doubt it will!), create a file called `build` in `~/.xmonad` with the following content #build command ghc -package xmonad -package xmonad-contrib --make xmonad.hs -i -ilib -main-is main -fforce-recomp -o xmonad Since the advent of new-build style commands, my preferred way to do this is using a .ghc.environment file. I usually copy the .ghc.environment file from some other cabal project on my system and use it with just xmonad and xmonad-contrib. In my `~/.xmonad` directory I have a file `.ghc.environment.x86_64-darwin-8.6.3` like this. clear-package-db global-package-db package-db /Users/pranaysashank/.cabal/store/ghc-8.6.3/package.db package-id base-4.12.0.0 package-id xmnd-0.15-5553680b package-id xmnd-cntrb-0.15-c99f6454 However, there doesn't seem to be an easy way to generate a .ghc.environment file using cabal. I usually have a fake cabal project, in which I put the list of packages I want in build-depends, and do cabal new-build to get an environment file with a set of packages that are guaranteed to work together. Pinging u/hvr_ for insights into using environment files.
I don't think there were any limitations about using another custom data type, also we were mostly dealing with strings. This means only one typecasting during +/* and negate operations. I know what you imply, but in this specific case I don't believe our assistants being lazy or anything simply because we're allowed and actually encouraged to use different tools language provides. But hey, what do I know what's going on during creation of the problem? :D Btw I'll post both assignment text and my solution once it's evaluated, so maybe we could further talk about context and solution. I'm really interested in Haskell although it's a bit intimidating on more advanced topics.
Maybe the suggestions from [this blogpost](https://opensource.com/article/18/10/best-practices-giving-open-source-code-feedback) can help: - Avoid ad hominem comments. Remember to review only the contribution and not the person who contributed it. That is to say, point out, "the contribution could be more efficient here in this way…" rather than, "you did this inefficiently." ... - Include positive comments. Not all of your feedback has to (or should) be critical. As you review the contribution and you see something that you like, provide feedback on that as well. ... - Questions are feedback, too. Praise is one less common but valuable type of review feedback. Questions are another. If you're looking at a contribution and can't tell why the submitter did things the way they did, or if the contribution just doesn't make a lot of sense to you, asking for more information acts as feedback. ...
Yes, definitely. It's a really cool and simple tool which I use all the time as do many other people.
You may interesting in the way of [Haskell for Reader](https://github.com/nomeata/haskell-for-readers)
I'll check it out :) Have you used it before?
It's e-mail, you don't need to be accurate to the second or to anything that resembles real-time. You only need to send after a somewhat acceptable delay in human time-scale, and you need to be sure you send everything you have. Just be sure you're able to finish sending a batch inside of 3 minutes, and then poll once every 90 seconds or so. If you want to get more complicated and scaleable to arbitrary batch sizes you will need something more robust than just tuning a polling interval.
As much as I trust these organisations, [https://www.youtube.com/watch?v=w3\_0x6oaDmI](https://www.youtube.com/watch?v=w3_0x6oaDmI) has still left me fairly convinced that electronic voting is a bad idea. Be curious to know what the arguments are.
I wrote a bunch of machinery to do this while writing [Thinking with Types](https://thinkingwithtypes.com). The gist of it was a big latex document that was smart enough to cross-reference Haskell source files (for definitions) and run repl sessions. Compiled slow as fuck, and played really terribly when I wanted to generate _non-pdfs_, but besides that it was great. https://github.com/isovector/latex-live-snippets
Thanks! I am interested in being able to scale. How would you go about doing that?
Wow this book looks great. Definitely consider buying it. I'll give live-snippets a shot. Thanks! &amp;#x200B;
Old Reddit formatting for the confused: case someNatVal n of Just (SomeNat (_ :: Proxy n)) -&gt; -- Now n is available as a type variable with a KnownNat instance let r :: Regression n = ... in ... Nothing -&gt; -- This case only happens if n is negative 
What if you distrust the voting machine itself? Is that addressed? The voting machine contains hardware components from dozens of countries, and "fixing" those machines is not too expensive for those.
Irrelevant. The question is whether it is possible to design a system that allows you to verify the election *and* retain ballot secrecy. What people use in practice does not affect what is possible. If you can show that the math is wrong, then that is relevant. 
&gt; as you could supply an argument which returns values of different types depending on whether the argument is True or False Not with that syntax in any DT I've used. The `a` is bound before the `Bool`, so it would have to work for both `True` and `False`. You'd have to move the exists qualifier around to bind the `a` after the `Bool` (e.g. `Bool -&gt; Sigma Type (\a =&gt; Eq a -&gt; a)`) to get a type that was different for `True` vs. `False`.
But, of course it will, since you have to be parametric in them, whereas indexes can change shape / form which will affect behavior / function.
You can do it now too, by taking a picture of your ballot.
Our military and government organizations are using a lot of hardware. Are you saying you do not trust any of it? &amp;#x200B;
Thanks for you advice! My main concern of splitting my focus is mainly about time management and going off the road so to speak. But if there isn't any big problems translating Go code into Haskell (with some knowledge) I'll happily do that.
I don't understand why people think this is possible. This is like requiring that you be able to set up a secure communication channel with an adversary that can observe not only the wire, but all your local state. Can't be done. The adversary then knows everything you know, so from the perspective of the math, he's you. Same goes for voting coercion - if the adversary can demand access to observe what you observed, then he's you. If your vote is proven to you, it's proven to him. Coercers will just demand a backdoor on your machine, or that you record your actions with your smartphone, or whatever. This can be made more difficult or inconvenient, but there's no magic solution.
I prefer nix whenever possible. But there are situations where it wouldn't work (current Windows support is very weak, on a team where people don't *already* know nix, etc.). On Windows I think *stack* is the best choice because it handles GHC for you. I really like cabal new-\* and use it often in conjunction with nix. I actually have used Stack with nix as well to great effect.
Huh, interesting. I wasn't thinking about dependently typed languages (I don't have experience with them) but something closer to Haskell. I gave the example for `het`. Unfortunately, we don't have a separate `exists` quantifier, but let's pretend that we had one. So according to you, which of these would be false? 1. `Bool -&gt; forall r. (forall a. Eq a =&gt; a -&gt; r) -&gt; r` is isomorphic to `Bool -&gt; (exists a. Eq a =&gt; a)` 2. `exists a. Eq a =&gt; Bool -&gt; a` is isomorphic to `Bool -&gt; (exists a. Eq a =&gt; a)`.
Looks like there are a few other options to play with in `impure-containers`? Like turning on bounds checking, turning on debugging, or using the portable flag?
Sorry, no scoped importts or first-class modules in Haskell or GHC. It's one Scala feature (scoped imports) that I wish would make the jump into Haskell. (I think Agda has something similar already.)
I think I understand the point to some extent. The use of `=&gt;` with `exists` wasn't right. It makes sense as an argument with `forall` but it needs to be returned (say, as a tuple) with `exists`. I've made the dictionary explicit now. -- Earlier, this was -- Bool -&gt; forall r. (forall a. Eq a =&gt; a -&gt; r) -&gt; r het :: Bool -&gt; forall r. (forall a. Dict (Eq a) -&gt; a -&gt; r) -&gt; r het b k = if b then k Dict 1 else k Dict ":(" Now I want to show that it is impossible to write a function which takes `het` as an argument and compares the result obtained when you apply True and False, by writing a (the only?) reasonable implementation and showing that it returns a type error. But I'm kinda' stuck writing an implementation because of the CPS :(.
You may want to give a reference to your source repo (github) if it's possible or simplify your code to expose this seg. fault.
Ok i think I have a guess. You forked and depend on a bunch of patches to a bunch of other libraries, and I think they don't do what you want. In particular the `toList` you added here seems dodgy: https://github.com/snoyberg/mono-traversable/compare/master...runeksvendsen:master#diff-75ce93fe8ba6fd33b9d1493b2cfbbb44R159
&gt; exists a. Eq a =&gt; Bool -&gt; a is isomorphic to Bool -&gt; (exists a. Eq a =&gt; a). This is false. The first is `Sigma Type (\t =&gt; Eq t -&gt; Bool -&gt; t)`; the second is `Bool -&gt; Sigma Type (\t =&gt; Eq t -&gt; t)` (in Idris). The first has values like `MkSigma String (\_ b =&gt; case b of { True -&gt; "true"; False -&gt; "false" })` (may not actually be valid Idris syntax; I'm not sure what one-line `case` looks like). The second has values like `\b =&gt; case b of {True -&gt; MkSigma String (const "true"); False -&gt; MkSigma Nat (const Z) }`. I think the second even has values where the type chosen uses the provided `Bool` as an index, though that might require using a dependent binder like `(b : Bool) -&gt; Sigma Type (\t =&gt; Eq t -&gt; t)` Basically, in the first form I have to give you a `Bool -&gt; a` for a single `a` of my choice, without being able to see the specific `Bool` you will provide. But, in the second form, I can see the specific `Bool` before I make my choice of `a` and give you back a different one for `True` vs. `False`.
&gt; fn het(b : bool) -&gt; Box&lt;dyn std::fmt::Display&gt; I would expect this to have the Rank-2 (non-Haskell 2010) type `het :: Bool -&gt; (forall a. Show a =&gt; a)`. Since `Show` is effectively a one-method typeclass, you can "inline" it to erase the `forall a.` and lower the rank of the type to: `het :: Bool -&gt; (Int -&gt; String -&gt; String)` het :: Bool -&gt; Int -&gt; ShowS het True = flip showsPrec 1 het False = flip showsPrec ":(" -- or const (++ ":(") 
&gt; het :: Bool -&gt; (forall a. Show a =&gt; a) That... doesn't work the way I want. https://wiki.haskell.org/Heterogenous_collections#Existential_types shows how you might do it though, or you can CPS it.
I'm afraid I don't know where to start when it comes to producing a minimal example. I'm hoping I can get some help with that. Here's the source repo: https://github.com/runeksvendsen/bellman-ford/tree/ghc-bug-report 
Good point. In `mutable-containers`, I should probably try to replace the `unsafeRead` in `toList` with the safe variant and see if I get an out-of-bounds exception instead of a segfault. I only used the unsafe variant since this seems to be the coding style of the library. The only other repository I've forked and changed is `impure-containers`, to which I've added very simple, one-line lookup and delete functions, that basically just map to the same function for an internal HashMap.
You are exactly right! Thank you for letting me borrow your fresh pair of eyes. Replacing `unsafeRead` with `read` makes the program crash with an index out of bound error: bellman-ford-exe: ./Data/Vector/Generic/Mutable.hs:691 (read): index out of bounds (64,64) CallStack (from HasCallStack): error, called at ./Data/Vector/Internal/Check.hs:87:5 in vector-0.12.0.2-AoZ9EwUsgIW1yrOc105QXH:Data.Vector.Internal.Check CallStack (from -prof): Data.Vector.Internal.Check.error (Data/Vector/Internal/Check.hs:(86,1)-(87,41)) Data.Vector.Internal.Check.checkError (Data/Vector/Internal/Check.hs:(100,1)-(103,34)) Data.Mutable.Deque.toList (src/Data/Mutable/Deque.hs:(159,1)-(161,43)) Data.Queue.toList (src/Data/Queue.hs:55:1-30) Data.Graph.Digraph.outgoingEdges (src/Data/Graph/Digraph.hs:(114,1)-(116,41)) Data.Graph.BellmanFord.relax (src/Data/Graph/BellmanFord.hs:(68,1)-(89,39)) Data.Graph.BellmanFord.bellmanFord.go (src/Data/Graph/BellmanFord.hs:(53,5)-(60,59)) Data.Graph.BellmanFord.bellmanFord (src/Data/Graph/BellmanFord.hs:(48,1)-(60,59)) Main.bellmanFord.\ (app/Main.hs:(27,45)-(30,36)) Main.bellmanFord (app/Main.hs:(25,1)-(30,36)) Main.main (app/Main.hs:(18,1)-(20,21)) 
As /u/Slugamoon said, there's a better bound, and it's better than n/2. I'd put some thought into that. This part of the problem has nothing to do with FP and everything to do with pure math. As an example: 12 = 2^2 * 3. so 12 has 3 possible deconstructions (4 of which use proper factors): 1 * 12 2 * 6 3 * 4 So when making a list of factors do you actually have to check all 6 factors?
foo::Maybe Int foo = bar 5 where bar = Data.Maybe.Just this failed 
For the most part, it does. If you have a function like this: mySum :: Int -&gt; Int -&gt; Int mySum !a !b = a + b and it's used strictly sumAll :: [Int] -&gt; Int -&gt; Int sumAll [] !a = a sumAll (x:xs) a = sumAll xs (mySum a) Then, there's an excellent chance (with GHC -O), that `mySum` will be inlined and you'll get a tight loop with a hardware addition. The same is true for large numeric expressions (for example, if you made `mySum` calculate the squared sums, or something more taxing). GHC does this kind of unboxing automatically even for product types. So a function call that applies a function to an application of a type constructor will avoid allocating that constructor completely. This is is a generalization of the above, because `Int` and other 'primitive' boxed types are really wrappers over the unboxed type. When GHC applies its unwrapping rules, then it ends up with functions applied to unboxed types.
The main point is I want import some functions or Data Constructors in my function without import on my header, I think Haskell does't support that so far.. it might be in the future.. 
A simple approach is data Expr = Lit Integer | Plus !Expr !Expr | Sub !Expr !Expr | Mul !Expr !Expr which doesn't prevent you from writing `bad`, but blows up immediately if you try to force it.
yep, scoped imports are nice since you can look at your functions, and you know the function is from which package. One of big issue in Haskell is name collision, e.g. in GHCi, it is hard to use "sort" function if you import too many packages.. .. Obviously you need to use "import qualified package\_name as Sth" to distinct your function names. I wish some extension to do some "scoped imports" in Haskell
Nice. I suppose I can just have TH code force this then. 
Are you just concerned about cycles, or are you also concerned with infinite structures that aren't cyclical? For instance: bad n = Plus (Lit n) (bad (n+1)) I'll assume you want to avoid both. If so, looking for loops is the wrong strategy. The existence of a loop is not necessary to have an infinite data structure. This might be obvious to you, but if you want to avoid this at compile-time, you're going to have to sacrifice ability to express some valid computations on the type. Your solution with type-level naturals is one example of this. There will always be something more complex that you could do to make more computations possible, but it will never be enough to get all of them. The other option is to avoid them at runtime. NFData is the right option here. You can build a term that might be infinite, but use rnf to walk it. From that point on, you can be sure it's really finite. There's no need to do the dynamic stuff: if it's cyclic, then rnf will never terminate. Really, then, you're moving the nontermination from later computation into the construction. You can't avoid nontermination entirely (see: halting problem).
are we? the conflict between some cabal and stack developers has been long and sore. are there other incidents that made you uncomfortable? (i took a break from haskell (and r/haskell) for a year until recently, so maybe i'm missing something.)
A quick look at your post history on Reddit shows a ton of inflammatory comments that are "just barely" polite enough to not be outright trolling. Why do *you* contribute so much negativity to the Haskell community?
Hmm, I wonder if tagless final style might be helpful here?
I don't *need* to trust any of it. The voting machine I must trust, and trust is all I have. The military must trust its machines - and they vet their suppliers. If some machines maliciously fail - they have many other machines and fail-over plans. Financial organizations must trust their machines - *not the bank's customers*. If the machine defrauds the customer, they will sue, and the bank will pay, not the customer. The bank can vet their machines, and they regularly incur losses to pay off failures (hacks, machine errors). The commonality here - is that buyers of this equipment are the ones that maintain it, and the ones that pay if it breaks. They are also in a position to do something about it, from vetting to actively monitoring, to various other possible actions. With voting - those buying and maintaining the machines are not the ones who lose significantly if the machines become rigged. The incentives do not align correctly to prevent rigging. Unlike banks and military machines (at least in times of peace), rigging voting machines (especially silently) is *enormously* profitable. So profitable that it can justify *huge* expenditures in hacking, changing hardware designs, planting chips, or what not. There is absolutely no practical way to validate the hardware, or even the software that's running is what they think is running. Voting machines will be hacked and rigged. It's so profitable that it's practically inevitable. I believe they guarantee certain death of free elections, eventually.
That's why I always use the safe variants until performance matters. But glad you tracked down the issue further. 
You can also use [StrictData](https://downloads.haskell.org/~ghc/8.4.2/docs/html/users_guide/glasgow_exts.html#extension-StrictData) to make it the default.
In France, we vote by choosing 1 of n ballots (each just containing 1 name) to put in the envelope. So taking a picture of your ballot in the envelope isn't proof, since you can then switch it out. The only way to provably record your vote would be to film yourself putting the ballot in the envelope and walking out of the booth to the ballot box with it, but then people will see you filming. You'd have to provide someone with a hidden camera to buy their vote.
Thank you very much for your reply. That's very helpful. I don't think I was very clear about what I mean by cycles. What I originally meant was that, syntactically, the definition of a particular term involves recursion. For your `bad` example, if we are looking up all the names involved in the right hand side, we would see `Plus`, `Lit`, `bad`, `fromInteger` (due to the literal 1). Here the RHS involves recursion, and I wanted to prevent this. (Of course, this rules out valid computations that use recursion and do terminate.) Now that I've given it some more thought, I see that my idea of cycles wasn't very precise either. Your `bad` example could be detected, but `bad = foldr1 Plus (map Lit [1..])` will not be detected. Seems like a purely syntactic approach cannot work. This can be solved with the type-level naturals, but then there are other things the type-level naturals approach won't be able to detect. What I really want isn't really avoiding nontermination while preserving valid computations; as you have said, that can't be done, but I would think a suitable compromise in this scenario is to rule out some valid computations and be certain that the rest will definitely terminate and result in a finite structure.
Actually I just tried. I thought this particular example would throw a [NonTermination exception](https://hackage.haskell.org/package/base-4.12.0.0/docs/Control-Exception.html#t:NonTermination) but apparently it does not.
There are enough disadvantages (or inertia) that most Scala style guidelines recommend that scoped imports not be used. I think they can clarify things, but I haven't tried to do Scala "at scale".
All you're missing is that the OP is a troll looking to cause strife, and assuming they're the same troll we've had here for a long time, but under a different name (which seems extremely likely), they're indeed the number one cause of "negativity" on this subreddit.
Can anyone recommend a graphics library for Haskell? I looked on the Haskell wiki and there are a whole lot; what I want to be able to open a window, plot some points and draw some lines. To give you an idea what I'm looking for [https://www.ruby2d.com/](https://www.ruby2d.com/) is Ruby's version of what I want 
You might want to take a look at his `cabal-env` script :-) https://github.com/hvr/cabal-env
Yep. The deq structure there is a ring buffer, so the `toList` will need to wrap around at the edges instead of running right off :-)
Single issue trolls could realize they're hurting the community more than helping.
Yes, was that ever in question?
It is true that if you are able to continuously observe someone for as long as you desire it is then it is possible to know how they voted. &amp;#x200B; End-to-end recording of the person casting their vote is one of the more difficult attacks to counter. Solutions tend to involve allowing the voter to use fake credentials or recast their vote. This allows them to create a video of a fake vote which is identical looking to a real vote. &amp;#x200B; That can be countered by requiring the person to provide a continuous video of their presence for the entire time that polls are open so that the attacker can be sure they only voted once. With the availability of early voting, that time period might be fairly long - but with AI and fast-forward still observable. &amp;#x200B; Another solution requires users to enter a password before their vote is recorded. In this system there is a 'real' password and 'panic' password. If the user enters their panic password, then they appear to vote successfully, but the vote is not actually counted. This system would require the attacker to have uninterrupted footage from the time the voter originally created their passwords all the way until the voting period ended. &amp;#x200B; If the attacker tried to get them to \*change\* those passwords, the person being coerced would only need to use their panic password. When doing that the two new passwords they set will both be treated as panic passwords. &amp;#x200B; All encryption can be broken -- the aim is to make the resources required to do it impractical. By making the required continuous observation time long enough, you can make vote selling or vote coercion too costly to be effective. If you only need to observe them in the voting booth, that is one thing. If you need a continuous observation of the last 6 months -- that is much more difficult to exploit. Of course, a voting system that is too difficult to use is as bad or worse than a system where voter coercion is possible. So the aim of research is to design a system which is: &amp;#x200B; 1. easy to use 2. can be verified to a reasonably level of assurance by third parties 3. makes it difficult to coerce voters or sell votes &amp;#x200B; Also, in the modern age, we want to be able to do this all with remote E-voting. &amp;#x200B; There are many interesting papers on this subject which cover all sorts of attacks and counter attacks. While no 'perfect' solution exists, there is a ton of room to dramatically increase the integrity of elections -- especially compared to places like Georgia, where the e-voting evidence was easily and purposely destroyed. &amp;#x200B; &amp;#x200B;
I've written my own safe variants of lots of operations that use `assert` so they excercise bounds checking in tests but disappear otherwise. There might be a library on package for that
Please stop. Your posts make you look like a FP Complete sockpuppet, which obviously doesn't reflect well on them whether it's true or not. It's creepy and toxic and frankly bizarre.
the lambda function did the trick (the right way!). thank you very much! I saw this comment last night but didn't really process because I hadn't read as much about lambda as I should have. it was late, I was sleepy, but now I have. thanks again for the push in the right direction!
I use https://github.com/owickstrom/pandoc-include-code as a pandoc plugin for pulling in code snipptes; you can mark arbitrary blocks of code using special comments. As far as processing the pandoc and outputting a pdf you can likely write some adapters for http://hackage.haskell.org/package/slick which would allow you to cache partial build-steps in a reasonable way.
I find the Haskell community to be really positive. Where there are people there are problems but it’s the exception. Haskellers typically have a very deep and genuine interest in the work. If you are looking for toxic, try language X. I won’t name any. Positive, right? 
Haskell doesn’t feature a _termination checker_ - a system which analyses your code to ensure there aren’t any infinite loops. This means that you can’t rule out terms like `worse :: Expr _ = worse`. (Indeed, you can even write `worst :: a = worst`, which is a value with _any_ type!) Languages which are intended for proving mathematical theorems, like Agda or Coq, typically do feature a termination checker. Being able to write `worst :: a` is very bad in a theorem prover because it means you can prove any theorem, including false ones. Non-termination makes the whole system untrustworthy. Haskell is a programming language, not a theorem prover. Allowing arbitrary recursion turns out to be quite useful for practical programming; working with a termination checker turns out to be much more difficult than working without one.
Yeah, you can't do that. Imports can only be defined in between the module declaration and the beginning of regular declarations. 
Diagrams? Gloss?
But I'm not even asking for a sophisticated termination checker! All I'm asking for is a simple termination checker. I'm willing to have something so simple that rejects all programs with recursion! Is that something Haskell is able to provide? After all my goal is to produce a data structure in-memory that is finite. I'm not dealing with general conputation. 
If all you want to do is rule out literals with loops, you could index the expression type with a Nat that tells how deep the tree is. 
Is that in the London Bridge area? I _think_ it’s the uSwitch offices. They often generously host the Papers We Love meet-up
Maybe export only `Var` `App` and `Fun`? Because type holes pass type-check but don't actually compile so you can't write a `worse` of type `Expr *`.
Galois is already working on verifiable election technologies since last 3 years as I found in this post from 2016 - [https://galois.com/news/galois-launches-election-technology-spinoff-free-fair-enable-verifiable-transparent-secure-elections/](https://galois.com/news/galois-launches-election-technology-spinoff-free-fair-enable-verifiable-transparent-secure-elections/) . So my guess is that the technologies from [Free and Fair](https://freeandfair.us/) would be used in the 2 voting-machine that Galois would be creating and demoing in this year's Def Con as per the Motherboard article. Now the interesting &amp; relevant stuff here is that some of the important projects of *Free and Fair* is done using **Haskell** as explained in [this blog post](https://freeandfair.us/blog/open-free-election-technology/) 
I thought that was my approach described in the original post? Still that doesn't rule out `bad = bad` because the compiler deduces a type `a` which unifies with any Nat. Perhaps we want to say, the type-inferred Nat must not be a type variable; is there a way to have `(forall n. Expr n) -&gt; r` not typecheck?
&gt; One of the biggest issues with Haskell on large scale web applications is keeping the boilerplate of your typical "domain entity" record types to an absolute minimum. Can't wait for extensible rows, records and variants.
Thanks will check these out! 
[Liquid Haskell](https://github.com/ucsd-progsys/liquidhaskell/) can check this for you automatically: http://goto.ucsd.edu:8090/index.html#?demo=permalink%2F1552975333_18039.hs If all you want to do is check for non-recursion, you likely won't need to add any additional annotations; running `liquid` on the file should just work.
You're not supposed to optimise expressions entered via GHCi REPL. Optimising GHCi expressions caused bugs before. Basically the problem is optimisations introduce expressions (unboxed tuples) that GHCi can't interpret.
What are you trying exactly? Are you using \`forkIO\`?
Any day now, shouldn't take much longer than production-ready nuclear fusion.
Vector also has a flag for it.
I don't understand. They don't seem to mention FP Complete?
Fwiw the sockpuppet linked to a Tweet by FP Complete's CTO lamenting &gt; If your first response to someone talking about an amazing technical achievement is "allow me to publicly chastise you for not following my coding standards, and let me pull rank to enforce that," rethink your life. 
Hey /u/logical_space, thanks for the interest! You (and others that might be similarly interested) should DM us with contact info and we can invite you to the slack channel for the project where we're pretty active. Haskell is definitely the road less traveled with machine learning today, but we're doing our best to carve out some new paths with it with others that are interested. You can also email [hasktorch@gmail.com](mailto:hasktorch@gmail.com) which forwards to us. You can definitely do what's described, as /u/faucelme noted, Justin's posts are a good reference. Our current approach to autodiff uses Justin's Backprop library as a frontend with hasktorch as a backend for functions and gradients. There are also a few pointers to related learning materials in the developers file that you may find useful [https://github.com/hasktorch/hasktorch/blob/master/DEVELOPERS.md](https://github.com/hasktorch/hasktorch/blob/master/DEVELOPERS.md) The hasktorch examples just tend to veer on the side of making types specific to be beginner friendly. Regarding ffi-experimental, you're right we're in the middle of a substantial iteration. A good summary of the medium (\~ 6 month) roadmap is in our GSoC abstract - [https://summer.haskell.org/ideas.html#hasktorch](https://summer.haskell.org/ideas.html#hasktorch) Can give more details in the slack, but the upshot is PyTorch backend is a bit like an onion. The base backend is the C TH libraries, which is what hasktorch 0.0.1 targets. On top of that they've extended that base functionality with a ATen (C++ Tensor library) which subsumes TH and more recently with the PyTorch 1.0 release even more higher level functionality has been pushed to the backend which subsumes ATen and is called libtorch (see [https://pytorch.org/cppdocs/](https://pytorch.org/cppdocs/)). At the same time, with 1.0 they seem to have hardened the declarative specifications a bit, so we're also transitioning our code generation from using hand-rolled header file parsing to generating code off their spec. Juni Hashimoto, one of our recent collaborators, has been doing a lot of heavy lifting on this and has been great to have as a contributor. We want to piggyback on all this development going into libtorch which is what's happening in ffi-experimental. Eventually ffi-experimental will be the ffi layer for Hasktorch 0.0.2. That will be a big step for the library, and like PyTorch, some aspects of library usage will evolve. At the same time though, high level ML code should be pretty transferable as new functionality aims to be a superset of what's there today.
The `Proof` type &amp; associated combinators presented in the paper (and somewhat expanded upon in the repo) basically let you do tactics-style proofs, if you’re familiar with them from proof assistants. An example from the paper (plus `BlockArguments`): contrapositive :: Proof ((p --&gt; q) --&gt; (Not q --&gt; Not p)) contrapositive = implIntro \p2q -&gt; implIntro \notq -&gt; notIntro \p -&gt; implElim p2q p `contradicts` notq This is essentially a sequent proof like this, where `*Intro` combinators add stuff to the context (omitted here for brevity): p -&gt; q p ----------- implElim -- q ~q -------------------------- contradicts 0 -------------------------- p -&gt; 0 -------------------------- notIntro ~p -------------------------- implIntro ~q -&gt; ~p -------------------------- implIntro (p -&gt; q) -&gt; ~q -&gt; ~p They’re fairly straightforward to write, but unfortunately not terribly readable after the fact—although I guess that doesn’t matter too much, because it’s largely just “set and forget” machinery for plumbing your logic through the typechecker. 
&gt; There are reasons to prefer this encoding over, say, symbolically differentiating, because done right you can get better asymptotic performance of the result compared to a symbolic differentiation technique. I'm encountering differentiation these days and I'm leaning towards symbolic approaches just because I don't know how to answer the kinds of questions my project leads me to ask with the automatic approach. For example, I'm interested in finding the zeros of the first derivative (local optima of the original function), but I don't think the automatic differentiation techniques give me any nice way to access this algebraically. As far as I understand, the only way to get that info would be to do something hacky like the log-search-guess-and-check method, which I find unsatisfying (even though tbh it would probably work fine for my case). That said, even if I do choose the symbolic approach, as far as I know zeros in general aren't findable algebraically anyway except in nice cases. But my idea here is that even if I'm interested in finding the local optima of some wild higher-degree polynomial, I can at least guarantee in my case that the wild polynomial is *composed* of nice cases (i.e., I may have a 25 degree polynomial, but it constructed by throwing together simple polynomials like `(x - 3) * (x + 4) * ...`), which I think should give me the zeros I want algebraically. But I haven't actually written this yet, so it may turn out to be a wild goose chase. Who knows. I've always had a special place in my heart for `Free`, too, and somehow that always seems to get superseded by other approaches even in my own code 🤷‍♂️
I've been noticing the negativity too but I suspect it's not coming from the people you're trying to pin it onto... - https://old.reddit.com/r/haskell/comments/4fm6iv/new_lecture_series_on_intermediate_haskell_from/d2aicn2/ - https://old.reddit.com/r/haskell/comments/4l3y9f/store_a_new_and_efficient_binary_serialization/d3leo7f/ - https://old.reddit.com/r/haskell/comments/as18h4/shutting_down_haskelllangorg/egsefyg/ - https://old.reddit.com/r/haskell/comments/7yfdei/haskell_ecosystem_requests/duii6p7/ 
As obnoxious as the OP's behaviour can be, it isn't helpful either for you to also start digging threads from years ago.
That's beside the point. The authors of stack (as far as I remember) concluded that it was impossible for them to make significant progress toward the goal they set for themselves in the context of cabal. Maybe they were right, maybe they were wrong in doing so, but that's another debate, which they settled for themselves by concluding it was better to start a separate project. You can't force them to conclude it's unsubstantiated, 4 years later. It might be unfortunate, but that's another debate.
I tried using parMap and got no speedup when running it in the terminal. &amp;#x200B; Here's my source if you want it. [https://gist.github.com/xpika/c12214cb9b04a9f7cf8af5006d5d56e3](https://gist.github.com/xpika/c12214cb9b04a9f7cf8af5006d5d56e3) &amp;#x200B; &amp;#x200B;
In a strict pure language you wouldn't be able to create infinite values (at least without using explicit laziness/iterators).
After I started using Haskell around 4 years ago, I actually was impressed by the level of civility and the quality of discussions happening here. There is always room for improvement, but this is one of the best language communities I've participated in so far.
There are dozens of us!
A more regular (better ?) notation would be =&gt; for 2-morphisms (natural transformations in cat) and , and "three lines&gt;" for 3-morphisms (modifications). Of course that would conflict with type classes. At some point, arrows will become a big battle field :)) Ideally one would have visual clues for what category/context the code pertains to, as more logic is extracted out into the context.
great answer
That's the pragmatic way. but it might make sense (?) to have some opinionated aliases for grouping a bunch of others, maybe
Sometimes, enabling advanced extensions change the inference you'd expect from the code. of course you get a warning but it might puzzle at first. There is a good guide here : https://lexi-lambda.github.io/blog/2018/02/10/an-opinionated-guide-to-haskell-in-2018/
Color me jealous here in the US!
Finding zeroes is generally a hard problem. If you have a "nice enough" function, you can use http://hackage.haskell.org/package/ad-4.3.6/docs/Numeric-AD-Newton.html#v:findZero to try to find one. If you have polynomials, by all means keep them as polynomials. You can say way more about them. If on the other hand you have some hairy non-continuous function with a ton of cases (say, a ray-tracer or a sampler) and just need to locally determine the slope where you are for some technique like Hamiltonian Monte Carlo then AD is amazing.
Incredible! Congratulations SPJ :)
Suddenly, Haskell everywhere!
https://joeyh.name/blog/entry/verifiable_democracy/ shows it's been practically applied before, and links to a decent Google Tech Talk about Zero-Knowledge Proofs.
I think you could create a `FinNat` constraint?
You can use the system and still have votes hand-counted. It would still be slow, but it could be done. Scantegrity used a similar system for the Tahamo Park, Maryland elections, but the only "voting machine" involved was a fairly standard optical scan machine just like you would use for a standardized test. More complex software systems are definitely harder to trust, though with this system you could actually give the voter *more* access to the hardware and software they are using to cast their vote. In any case, the final results can be independently audited, and every voter that cares to check can know their individual vote was recorded accurately, by writing down the code/key on voting day, and checking that it matches later.
You definitely cannot exclude the possibility of having non-terminating expressions of your type. For example, `undefined` and `error ":("` and `let x = x in x` will always be nonterminating expressions with any type you like. You can exclude the possibility of nonterminating values hiding inside your type, by using only strict fields or by forcing the value with NFData after construction. But this will merely turn those terms into terms that are non-terminating at the top level. At least once you have a non-bottom value, though, you can trust that its fields also terminate. So I think the answer is simple: Haskell cannot do what you want. You could accomplish it with Template Haskell (if your values are in brackets so you can analyze them as data at build time) or with a GHC plugin.
&gt; alpha will be counted towards X No, that's wrong. The ballot looks something like this: [ ] Freedom -- D7 [ ] Liberty -- X2 [ ] Justice -- B9 [ ] Truth -- F1 But, the "codes" are different on each ballot (SHA-256(rand() ++ ballot_id ++ candidate ++ rand()) % 36^2) . You check the box you want, and when we are counting ballots we count the candidate. We we are disclosing ballots we disclose the code. You write down the code and your ballot_id before you leave. You don't have to trust that "alpha will be counted towards X", it's literally printed on your ballot, and the code are useless (and ignored) for counting purposes.
Your approach works right. The problem is just that there's no way to rule out bottom in Haskell in general. You can always just at best set things up such that a single force of a value will either render it `bottom` or something well-defined (i.e. get a "flat" domain). `let x = x in x` has the type `forall a. a`. There's no way around that :-)
I'm not exactly sure how that's even possible. It seems if I have the necessary hardware access, and I can bring is a small, strong magnet and spoil many, many ballots. But, I agree that full read-access seems like a good goal to provide every voter, even if most don't use it.
You have already with your second approach guaranteed that you have a finite data structure. You can't get an "infinite chain" of constructors -- just either bottom (i.e. non-termination) or a finite data structure. There is no haskell syntax or extension that allows you to prevent recursive use of names, full stop. However, you _can_ embed a quasiquoter for your syntax, and ensure that the values produced by the quasiquoter are not recursive, at compile time.
Holes in types do compile -- it is holes in _values_ that don't.
OK, now I've read the Effect Handlers article. I played around and came up with the following: type Handler t m n = forall x. m x -&gt; t n x handle :: (HTraversable is, MonadTrans t, Monad (t (Program is fs))) =&gt; Handler t (i '( Program (i :+: is) fs, fs)) (Program is fs) -&gt; Program (i :+: is) fs a -&gt; t (Program is fs) a handle _ (Lift m) = lift $ Lift m handle hdl (Bind p k) = handle hdl p &gt;&gt;= handle hdl . k handle hdl (Instr (Inl i)) = hdl i handle hdl (Instr (Inr i)) = join $ fmap (lift . Instr) $ htraverse (fmap return . handle hdl) i This uses a monad transformer `t` instead of threading an `s` functor as in the paper. It also uses `htraverse` to handle effects in sub-programs. AFAIU, `htraverse` corresponds roughly to `weave` in the paper. I'm not sure if this is an improvement, but at least `HTraversable` is a somewhat standard class that can be derived using TemplateHaskell (see e.g. `makeHTraversable` in [compdata](https://hackage.haskell.org/package/compdata-0.12/docs/Data-Comp-Multi-Derive.html#v:makeHTraversable)). I haven't tested it on any real examples, but here's an implementation of state: data StateInstr s m a where Get :: StateInstr s m s Put :: s -&gt; StateInstr s m () instance HFunctor (StateInstr s) where hfmap _ Get = Get hfmap _ (Put s) = Put s instance HTraversable (StateInstr s) where htraverse _ Get = pure Get htraverse _ (Put s) = pure (Put s) stateHandler :: Monad n =&gt; Handler (StateT s) (StateInstr s '(m, fs)) n stateHandler Get = State.get stateHandler (Put s) = State.put s runState' :: HTraversable is =&gt; Program (StateInstr s :+: is) fs a -&gt; StateT s (Program is fs) a runState' = handle stateHandler And for reference, the definition of `HTraversable` using kinds that match `operational-alacarte`: class HFunctor h =&gt; HTraversable h where htraverse :: Applicative m =&gt; (forall b. f b -&gt; m (g b)) -&gt; h '( f, fs) a -&gt; m (h '( g, fs) a) instance (HTraversable h1, HTraversable h2) =&gt; HTraversable (h1 :+: h2) where htraverse f (Inl i) = Inl &lt;$&gt; htraverse f i htraverse f (Inr i) = Inr &lt;$&gt; htraverse f i
Zero-Knowledge Proofs allow us to independently audit elections, verify our individual vote was counted, and *do not require* an electronic system. You can implement them with pen and paper. They solve issues completely separable from securing a voting machine, which I admit seems... quite difficult. Most of the arguments in the Computerphile video (didn't watch it today, but have seen it previously) are about that security. Galois and DARPA are probably working on all parts, but if you have enough people doing the independent audit and verifying their vote, you'll find any tampering at the machine level. I'm very comfortable with scannable paper ballots. I'm more comfortable with them that the touch-screen systems that I'm required to use now. In both those cases, and in some sort of "ideal" vote-from-your-PC/cellphone world, ZKP increases security through audit-ability without sacrificing anonymity.
Hidden cameras are fairly inexpensive these days, especially if you buy in bulk. ;)
Damn it's a shame that I left school almost a year ago, this would have been a very welcome change 
What's the benefit over paper ballots and 0 machines? 
Your type signature says you will return a value of type `a` but you are returning a value of type `MyMaybe`. There's no way to write a total function with this type signature as there's no way to produce a value of an arbitrary type. I'm not really sure what your goal here is, but one possible fix is to change your signature to one of: f :: MyMaybe (MyMaybe a) -&gt; Maybe a or f :: MyMaybe (MyMaybe a) -&gt; MyMaybe a 
Independent audit-ability. Also, ability to verify your vote is in the final tally, not just that you dropped in it a box labeled "ballot box". [Punchscan](https://en.wikipedia.org/wiki/Punchscan) is E2E secure voting and based on ink, paper, and math. [Scantegrity](https://en.wikipedia.org/wiki/Scantegrity) is E2E secure voting and based on special ink, paper, optical scanners, and (the same) math. It seems like Galois wants an E2E secure system, that allows you to vote from your PC / phone. [Paper systems do NOT automatically have the criteria we want](https://joeyh.name/blog/entry/I_voted/), while E2E systems guarantee at least some of them.
https://gitlab.haskell.org/ghc/ghc/issues/16463 has been raised to address some of the stage0/stage1 differences. Seems no one wants to bite on \`configure\` yet :)
He has promoted computer science unplugged and other computer science education in the UK. He promotes theory as much or more than the details like programing. I used to volunteer to teach short little segments of computer science to elementary school students and basically just took stuff from computer science unplugged. In his TED talk on these subjects he points out the sorting network activity. That one is *really* good. Parents are sometimes more amazed than their children however.
Strict fields are underappreciated. They are often a more nuanced substitute for `deepseq` when you are defining a type that needs to have a certain mix of strictness and laziness, as here.
&gt; If you have polynomials, by all means keep them as polynomials. You can say way more about them. I actually have a lot of flexibility in choosing the model - so much so that it's causing me to basically just sit around and do nothing because I don't have enough constraints to motivate me to move in a particular direction. I basically need to optimise resource allocation in a low-dimensional space. A similar problem to what I have would be like given a particular map layout in a game like Age of Empires, how can I place 5 lumber mills such that they will maximize the efficiency of harvesting the forest? In some sense it's a nice problem space in that it's quite simple to see if there are or are not valid solutions (can you fit the lumber mills on the map or not). But as for optimizing that space, I'm not sure the best way to go about it: I could try just plopping down 5 lumber mills in random locations a thousand times, evaluate them according to a rough objective function, and choose the best one among those, and if I can't find anything smarter, that's probably what I'll end up doing. My (terrible) understanding of Monte Carlo is I would basically plop down the lumber mills in random locations, then use the gradients so I can slide them in a better direction to get higher quality solutions than blind random placement would give. The fun part that to my intuition probably kills any hope of an algebraic approach is that lumber mills "interfere" with each other in the sense that having two lumber mills close to each other is silly, so placing two lumber mills in optimum positions is a harder problem than simply finding two local maxima of the cost function and blindly placing two lumber mills there. Hmm. On the plus side, the solution currently in use is terrible, so I don't have to do anything too amazing to beat it!
I wouldn't be mad.
I feel like a lot of lip service is paid to "teaching the youth coding" Putting somebody like SPJ in charge of it (and more importantly, convincing him that the whole endeavor isn't a huge waste of his time) demonstrates actual commitment to it. Good on them! Hopefully they stay out of his way and great things happen.
(DM sent) While I won't be able to commit much towards direct development, I'd certainly like to help with testing/implementing models. In particular, I'm working with models for graph/tree-structured data, and some simpler CNN models. One significant problem I'm having right now, compared to Grenade, is in using Hasktorch in developing a separate code base: as it stands, I've got around this by making another example *within* hasktorch. Ideally, I'd be able to pull it into a simple Stack-based project.
If the ballot box is transparently handled under lots of supervision, how does a vote not end up in the tally? As for machines, we must assume they're all harbouring hidden espionage remote controlled hardware and ask ourselves if they still are capable of serving that purpose
Suppose I have defined a type satisfying Num but not Ord, but another library introduces instance Num a =&gt; Ord a Is there a way to specify that this cannot apply to my type without just not using that library?
You have some advantages here, you can branch and bound if you have some cost function like this, as adding lumber mills only increases the value, and you have a discrete set of placement points. This can be used to manage pruning large exhaustive searches for exact answers. Another way is to look at somehing like Markov Chain Monte Carlo, rather than naive Monte Carlo. There you'd view the space as some distribution, defining a mutation procedure (e.g. moving 1-n lumber mills locally and/or globally) such that all lumber mill states are reachable from a series of mutations, define the score as something you are trying to sample with respect to, keeping the highest score you've seen during your random walk and then mutate repeatedly, accepting all "uphill moves" that improve your score and some that decrease your score with probability = the ratio of the scores. Assuming that you do this right, its a good way to spend time in high scoring regions while still paying attention to 'on average low-scoring but still worth exploring' regions. The superoptimizer STOKE uses this approach. The former is a path to provably optimal results, the latter is a path to computationally tractable but good results. Pick your poison.
The type signature of f states that it returns a type a, yet in the MyNothing-case, you try to return MyNothing, which has type MyMaybe a, not type `a`. You could either change the type signature to f :: MyMaybe (MyMaybe a) -&gt; MyMaybe a f (MyJust (MyJust a)) = MyJust a f _ = MyNothing --you don't need to go through all other combinations, _ matches everything or you could throw an error if f is handed MyNothing: f :: MyMaybe (MyMaybe a) -&gt; a f (MyJust (MyJust a)) = a f _ = error "no value" Using error makes f a partial function, meaning that, for some inputs, it'll throw an error that you can't catch (easily) and which will cause the program to come crashing down if it occurs. As /u/lgastako said, there's no way to write a function of type f :: MyMaybe (MyMaybe a) -&gt; a in such a way that it'll work for all inputs, because MyMaybe has the MyNothing-constructor, indicating no value - and if f returns a value `a`, then how will you conjure that value out of thin air? What would it be? A third option you could take is to declare a class of types which have a default-value, and constrain f to only work with them: class Default a where default :: a -- example-instance instance Default Integer where default = 0 f :: Default a =&gt; MyMaybe (MyMaybe a) -&gt; a f (MyJust (MyJust a)) = a f _ = default &amp;#x200B;
Outstanding choice. 
&gt; and you have a discrete set of placement points. Well this is one of the tricky parts of even defining my problem space—I actually am free to do continuous placement if I want! I know in some spaces like linear vs integer programming, the continuity tends to make things much faster to solve, hence my preoccupation with polynomials at the start. In any case, the Monte Carlo approach you describe doesn’t sound bad at all. It’s probably the best approach, as I’m reasonably confident it will give decent answers and that I can get it up and running without too much effort. And I just noticed you’re streaming again—welcome back! I really enjoy watching guanxi evolve over time!
How does Cabal know whether to link statically or dynamically with "extra-libs:" and "frameworks:"? Can it be influenced?
[https://imgflip.com/i/2wg6ow](https://imgflip.com/i/2wg6ow)
Dozens!
&gt; If the ballot box is transparently handled under lots of supervision, how does a vote not end up in the tally? Trust, but verify. An E2E system allows individual voters to confirm their vote was part of the final tally (cast-as-intended), and independent parties to verify the final totals (counted-as-cast). It does all this without sacrificing the anonymous vote (at least no more than our current system). Ballot boxes have gone missing in the past. --- While machines might be helpful in scaling E2E, and many voters would appreciate the ability to vote from their PC/phone, using a ZKP-powered E2E system doesn't require machines, paper, ink, and a source of randomness, and some math are sufficient. The math is also mostly simple arithmetic, not something where a computer (or even calculator!) is necessary; though they can speed some parts of the process up significantly. In an E2E system, if one of the voting machine changed or failed to record your vote, you'd notice because the cast-as-intended validation would fail.[1] In an E2E system, if the tallying machine didn't count every vote accurately, independent auditors would notice because the count-as-cast validation would fail. That said, we don't use an E2E system, and until we can get one in place that I audit, I would prefer fewer machines than I already have to use. We no longer get the choice of paper ballots with day-of voting in my neighborhood. [1] If the machine can predict that you will not do the cast-as-intended validation, it can change your vote. And, with computers already doing a passable job predicting what I want to watch and buy, I fear they might be able to accurately predict which voters are unlikely to validate their vote.
No.
No, but blanket instances of that sort are widely considered bad practice (in part for this reason!). In general, it's not something I would worry about.
To attempt a hint at this without giving away the answer. Lets look at 36, a number with a good amount of factors. 36 1 * 36 -- not proper 2 * 18 3 * 12 4 * 9 6 * 6 9 * 4 12 * 3 18 * 2 Now think about these questions. * What patterns do you see in these factors? * What is the smallest number in each pair? * Is it a coincidence that 6 is the only pair with the same number, how are 6 and 36 related, does this generalize to other examples? * These factors mirror each other, at what point do they start to do that? 
I've actually got some exciting news on this front; found a nice representation of everything that performs as well as MTL, requires zero boilerplate in most cases, and allows for `freer-simple`-style interpretation. Just polishing everything up now, hope to have something to show by the end of the week.
$10 million, Open source, secure voting. Choose *one*. 
When, where, how ?
That instance has no reasonable implementation: ``` instance Num a =&gt; Ord a where compare a b = ... -- hmm, cant implement this except by returning a constant value ``` In situations where you actually can implement such an instance in a lawful way: ``` instance Applicative f =&gt; Functor f where fmap f x = pure f &lt;*&gt; x ``` Then you would be wrong to claim that your type satisfies `X` but not `Y`. With that said in the above case the class on the left should have the class on the right as a superclass (in the above case it already does), and maybe some default implementations / convenience functions for writing the above. It's almost always a mistake to have an instance like the one you gave.
``` check :: forall a. Eq a =&gt; (Bool -&gt; a) -&gt; Bool check k = k True == k False data Exists c a where Exists :: forall a b c. c b =&gt; a b -&gt; Exists c a check' :: Exists Eq ((-&gt;) Bool) -&gt; Bool check' (Exists k) = k True == k False ```
Here's a more parallel version of your code: ``` import Data.Digest.Pure.MD5 import Data.ByteString.Lazy.Char8 hiding (iterate) import Control.Parallel.Strategies import System.Random applyNTimes f n x = iterate f x !! n f x = pack $ show (hash $ x :: MD5Digest) main = do s &lt;- fmap show newStdGen print $ parMap rseq (applyNTimes f 100000) [pack s,pack (s++s),pack (s++s++s),pack (s++s++s++s)] ``` The main difference is: in your code you build the list sequentially, and then evaluate the elements in parallel, whereas I'm doing this in one step (so the list is built in parallel while the elements are also evaluated). Also, make sure to add `+RTS -N` to GHCi, otherwise you use only one thread to evaluate Haskell code (so no actual parallelism).
Cool, looking forward to reading about that! 
To be fair, configure is mostly a problem on Windows because it forks so much. the configure step on my Linux machine is done in 20s max. Plus, I don't know enough of the build system/configure to be of any help.
But when you lokk up that "D7" was indeed counted, you cannot know that it was indeed counted towards "Freedom" you have to "trust us" -- anything can be printed on your printout. If you can, on the other hand, you can equally prove it to a vote buyer, which was the whole point of the conversation.
great. All I needed was to use the +RTS option in the way you specified. Previously I was using: \-threaded -rtsopts -with-rtsopts=-N2 which worked with when compiling the executable, but not with the REPL. &amp;#x200B;
It is in non-machinebased counting: if all l, say, five parties have representatives at the physical counting, as it is common here in Euroo, you can be reasonably sure about counted-as-intended. (This doesn't work with representatives and machines, as they have neither time nor expertise to audit machones in every voting location).
The keyword is "these days". Paper voting systems have been secure wrt. Vote buying for ~200 years after being wodely rolled out in republics and democracies. We should strive for similat standards for every newly-to-be-introduced system.
&gt; Also, in the modern age, we want to be able to do this all with remote E-voting. But why? I understand the convenience aspect but wouldn't trade it for the possibility to undermine the system. Even envelope voting gives you results within a couple of days in Western countries.
Noone could demonstrate me here so far -- "with the math" -- that you can have both reasonable immunity to vote-buying and reasonable assurance that your cast vote is indeed counted as intended.
In such a system you have to trust the system that the code that is handed you as "true", rather than "fake" is the one that got coynted indeed.
You actually never know if your vote is counted or not, it just get mixed with all the other votes. Unless you are officially designated (or you volunteered) to check that everything happened without any cheating / error, you have to trust those designated people. Many times, cheating happened - at several levels.
"What if the child consents?"
Can you show us your code? Without the code, we can't help you.
Thank you anyway but I think I fixed it now just a different error. Thank you though (sorry for the inconvenience)
Glad to see you solved your problem!
In our country no, you can't. You must go behind a screen where all recording equipment is prohibited. There you place a ballot into an envelope, which is cast afterwards (in clear view) into the box. You can always secretly scratch INVALID with a pencil onto the ballot.
&gt;*Tagless Final*: Deal only with *Typeclasses* and Monad, but it is a technique not based on any paper or Math Theory. [Typed Tagless Final Interpreters](http://okmij.org/ftp/tagless-final/index.html#course-oxford) mentioned in [Introduction to Tagless Final](https://www.reddit.com/r/haskell/comments/a40z4t/blog_introduction_to_tagless_final/)
Great to know it. I would update the post. Thank you for enlightening me 😀
You can have confidence in the system, because it works in regional layers. Each region is counted separately, and the tally is sent to a larger organizational unit. Cheating at a low regional level (like, a single neighbourhood) is relatively easy, but low-impact. Cheating at a higher level is hard, because somebody from the lower level is going to complain that his tally was miscounted (sub-tallies are public). The bigger the fraud impact is, the more people have to be in on it. &amp;#x200B; Compare that with e-voting, which is in practice AFAIK always centralised, and the machines/operators can fake regional tallies just as easily as the grand result.
Nice write up. Can I suggest follow on articles where you implement the same problem using free and mtl? 
Yes of course!!! I would be please to read them. BTW, My main attempt here was to write something easy for beginners. But I like also MTL style and Free too. Thanks again sharing.
So.. where is this?
That's false, and the point of the project being "open source".
It's a shame there's no nod to Haskell in that announcement. But really good news nevertheless!
He did say that functional programming is like mushrooms. You wake up one day and it's everywhere. Playing the long con.
I can only assume that Simon will be doing plenty of Haskell-nodding in the years to come!
The article makes it seem like you need to use type application in unNoCache $ requestData @NotInCache "john" but you don't. `unNoCache` requires the `NotInCache` type, so the type application here and in all subsequent places is unnecessary. (Unless I'm missing something).
Good catch. I am gonna modify article and code. Thanks!
No, you don't. "D7" can't be counted; "Freedom" has a different code on every ballot. I think you need to learn more about ZKP.
I am open to any improvement on the current system, whether or not it restores us to some ideal from before video capture was ubiquitous.
Thanks for the groovy article. I am a beginner at Haskell so I have a question around the newtype you introduce. `newtype InCache a = InCache { unInCache :: IO a } deriving (Monad, Applicative, Functor)` Where does the definition for the function `unInCache` come from? I get why it's used, just now how it's defined
False parallel. Children (now) have a special protected status that recognizes the rights we give to adults have to be curtailed in order to provide that protection. If the "child" can give informed consent, they aren't really a child anymore. I agree with your goals; it should actually be impossible for you to be coerced into voting a certain way. That may limit your ability to sell votes, but not if you are trustworthy or the buyer trusting.
[removed]
Hidden cameras aren't super expensive these days.
There is a hoogle for that, you know. You can even setup a hoogle db locally so it works offline
This line defines the data type InCache, it's constructor InCache and it's destructor unInCache, as well as some typeclass instances. If you define this with a normal Data definition you'd get unInCache as well.
There is a nice TUI front end as well: https://github.com/andrevdm/bhoogle
I see I see, thanks
No worries, glad to be of help
I'm aware of hoogle, but i find it doesn't replace browser based docs. It would be really neat if there was a colorized `:browse`, but the advantage of html based docs is searching and links.
&gt; I would be please to read them. I think the hope was that you were to *write* them ;)
Sorry for the delay. As u/merlin_thp pointed out, you can see `newtype` as `data` type with a single Data Constructor, and of course `unInCache` is the Data Destructor. Some of the advantages of using/defining `newtype`: - It has no runtime overhead - Unlike **Type** alias for the compiler it is a complete new data type definition. In that sense i use `newtype` which allows me to implement instances of **Cache and DataSource Typeclasses**. If i had used a Type alias I wouldn't be able to do it. - A `newtype` cannot be a neither a Product nor Sum type. So you can only define a `newtype` which contains one Type. Hope this could clarify a little more. Best,
Dude it's a joke about libertarians justifying pedophilia
You can just use a Merkle-Patricia Tree or a Sparse Merkle-Patricia tree - [https://github.com/ethereum/wiki/wiki/Patricia-Tree](https://github.com/ethereum/wiki/wiki/Patricia-Tree)
Why use `O(log N)` when you can get [`O(1)`](https://codaprotocol.com/)? (This is a serious question -- I have very little knowledge about blockchains).
Google offices behind Kings Cross in London.
I feel very nice when developers do these neat little things with bash scripts. I'll try this out. Thanks for sharing.
I misunderstood the first comment. I have understood you were about to purpose me some articles about mtl and Free. Now you pointed out my big grammar mistake I realized what you have asked. Of course I will try to do some follow up articles implementing the same program with mtl and free. Thanks again 
A lot more than lip service is paid to it. There are a lot of people who believe in it very deeply. But it's an extremely challenging problem. 1. No one agrees on the goal. Is it to prepare kids for software engineering? To help them learn logic? To learn "computational thinking"? (And what does that mean anyway? No one agrees...) 2. How do you get teachers who are qualified? Teaching is a low-paying high-stress profession in most places, and people with computer science skills have plenty of high-pay low-stress opportunities available. 3. How do you find the time? Sure, learning computer science is great, but so is learning mathematics, reading, science, history, civics, physical education, art, music, etc.? Schools are not suffering from a lack of things to teach. This is tricky for a lot of reasons, and people not taking it seriously enough isn't really one of them.
I guess that some projects want to have the complete transaction history available, and not just a checksum.
Isn't mtl exactly the Tagless Final Encoding (with reexports and instances for transformer types)?
IMHO it is not exactly the same, although both techniques are useful for describing DSL on Monadic computations. But certainly there is a correlation between both in that sense, also with Free Monad. From my point of view are different techniques to solve the same problem. 
If you look at what's actually defined within mtl you get classes like class Monad m =&gt; MonadState s m | m -&gt; s where get :: m s put :: s -&gt; m () Which (if I didn't misunderstand the definitions) is the tagless final encoding of data StateF s a = Get (s -&gt; a) | Put s a in the Free Monad representation? This is usually used in combination with StateT from the transformers package but that isn't really required.
Very well written. An enjoyment to read. I love these little elegant applications of Haskell.
It seems almost equal but with a subtle different I would argue: a Monad transformer it is a monad with another underlying monad inside. In my description of Tagless Final all capabilities, `Chache` for example are also Monads but it doesn’t contain another monad inside. All the capabilities are expanded constraining the program and because of that you gain horizontal extensibility. In mtl you Stack is vertical and you cannot only extends vertically. On the other hand Tagless Final is not only for Monadic computations, but Monad Transformer does. [See here ](http://okmij.org/ftp/tagless-final/nondet-effect.html) 
Thank you for the code example, that's precisely what I was hoping to get!