/u/chrisdoner, nice, will try this out. 
Sorry I could help on another language but I only subscribe here because I wish I knew Haskell.
https://wiki.haskell.org/Dealing_with_binary_data This is an excellent wiki article explaining many use cases. If you want to pull bit for bit, use the [BitGet](http://hackage.haskell.org/package/binary-strict-0.4.8.3/docs/Data-Binary-Strict-BitGet.html) monad.
Thank you, I will give getbits a try. 
It's possible to combine pipes-bytestring with bitwise's toList to get a Pipe or Producer for bits (i.e. Bools), but it's terribly slow to process single bits. :D Lets you do fun stuff like this non-return-to-zero encoder though: nrzi = Pipes.drop 1 &lt;-&lt; Pipes.scan (/=) False id
&gt; Can you imagine carrying on a conversation with someone who took 6 seconds to respond? I can. When I converse via IRC I often get responses in that sort of time; when I converse by email I get responses in minutes or hours, and, though I don't do this anything like as much as I used to, when I converse via written letter I get responses in days. In all cases it is possible to hold fulfilling conversations, so it's hardly surprising that many people can manage when their compiler takes seconds, or even minutes, without going insane.
(https://xkcd.com/303/)
[Image](http://imgs.xkcd.com/comics/compiling.png) [Mobile](http://m.xkcd.com/303/) **Title:** Compiling **Title-text:** 'Are you stealing those LCDs?' 'Yeah, but I'm doing it while my code compiles.' [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/303#Explanation) **Stats:** This comic has been referenced 619 times, representing 0.6378% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_czagr2m)
I have written both C and ocaml professionally. I assure you, most reasonably sized projects end up with much longer build times than this.
So all your projects become unreasonable a day after they start?
This is just one specific example. You are making broad claims that C and ocaml have "acceptable compile times" (for a pretty tight definition of acceptable) on all realistic projects. Doesn't that strike you as ridiculous?
Java. Usually less than a second even with over 7 million SLOC
That's very nice. I would combine `-fobject-code` with something like `-outputdir _ghci-builds` to avoid having the `.hi` and `.o` files scattered around in your source tree.
That wasn't really my question. *Where* do you work?
That might be a cool idea, PM me! :)
Cool post! I wonder how well a templating library like this performs in practice. BTW, you can import the IsString stuff from Data.String.
Continuations are generally very efficient, with continuation like types being used in many high performance libraries. (Continuations, for example, have `O(1)` fmap. Bind is similarly efficient.) There a lot more combinators you can add. In particular, you could import a template, manipulate, and then export it again (you could make a function to export `ContH String` as a template). Of course, the other main determinant of performance is your html parsing, rendering, and html type. (One issue is the lack of memoization (every-time you use something of type `ContH a`, it has to go back through its entire history), which is why occasionally converting it to a template (or some other format) might be necessary (although this wouldn't need to be exposed).) In general, I think its power would lie in its ability to create static content flexibly (although it might also be performant with respect to on-the-fly on a server).
:)
That looks like it's due to what's called the [Monomorphism Restriction](https://wiki.haskell.org/Monomorphism_restriction).
it's a default type from a list of default types which are tried in such cases. This behavior is switched on in GHCi (and is switchable everywhere in GHC).
Thought so too and set -XNoMonomorphismRestriction but that didn't change anything.
binary-bits is great! Here's some example protocol parsing where we used it recently: https://github.com/swift-nav/librtcm/blob/master/haskell/src/Data/RTCM3/Observations.hs
If you specify an explicit type for "f" (e.g. "IO (Int -&gt; String)") when you assign pf, then you'll get that type for pf. The issue is that pf must have _some_ concrete type when it's declared - ghci can't infer a type backward, for example. Also, pf _can't_ have the type "(Show a) =&gt; a -&gt; String" as written - f's type would have to be "IO (forall a. (Show a) =&gt; a -&gt; String)", as the value of pf (i.e. the result of f) could otherwise depend on the choice of a. 
There might be something obvious I'm missing, but could this be a `MonadPlus` instance? mzero = ContH (const "") mplus (ContH ca) (ContH cb) = ContH $ \k -&gt; ca k ++ cb k It might be personal taste but I think this would be a little easier to follow than the `i` syntax. Although it also does non-obvious things with guard; maybe it would be better as a `Monoid` instance.
I don't really see how that is relevant. I work at a big company with many different projects - even our biggest, most legacy one has low iteration times thanks to javac being incredibly fast. 
I'm guessing you meant Stack (the Cabal wrapper), not Slack (the trendy IRC replacement). The `flycheck-ghc` Emacs package has a checker called `haskell-stack-ghc` which will run `stack ghc` to compile your project repeatedly as you code, and underline any error-generating code (if you put your keyboard cursor over the error it will show up in the minibuffer area). Other than that, you can wait for the [haskell-ide-engine](https://github.com/haskell/haskell-ide-engine) project to come to fruition; it should solve many/all of the current problems with Haskell tooling in Emacs.
The issue isn't that the instance exists, it is that `m` unifies with `(a -&gt; r)` at all. You could bury the result of your variadic function in a newtype of course, but it'd be pretty awkward to use then.
It's called S**T**ack! ಠ_ಠ
Ryan's talk on Reflex from April at Boston Haskell might also be somewhat relevant. =) https://www.youtube.com/watch?v=dOy7zIk3IUI
Try `-XNoExtendedDefaultRules`. See [here](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/interactive-evaluation.html#extended-default-rules) for details. The next part is relevant: &gt; The unit type () is added to the start of the standard list of types which are tried when doing type defaulting. 
Blessed be the developers of `haskell-ide-engine`.
The "why don't you" part doesn't make any sense at all. Otherwise, why do some programming languages use different names for functions? Why don't you overload everything? Like: c = that that that that that
I would argue that yes, `+` should have supported strings and monoids in general. In the case of the latter, if you gave a "stringy" interpretation of `5` (by overloading some `fromInteger` factored out of the `Num` class along with `+`), it'd clearly have been `"H55"` and not `"H10"`. 
If you are in Linux, you can do it through xdotool.
I would expect that for any sensible numbers `fromInteger a + fromInteger b = fromInteger (a+b)`. This would not be true for your string instance, you would have `5+5 == "55"`, which is very unexpected imo. Additionally, it often makes more sense to think of concatenation as a product instead of a sum. For example in terms of parser combinators/regular expressions you have that `(+)` corresponds to choice and `(*)` to concatenation. In parsec I might write parser = ((++) &lt;$&gt; (string "a" &lt;|&gt; string "b") &lt;*&gt; string "c" You can imagine replacing `(&lt;|&gt;)` by `(+)` and `&lt;*&gt;` by `(*)` to get parser = ("a" + "b") * "c" As a bonus, you get that the `(^)` operator repeats a string a number of times.
I like how it even distributes.
I'm not aware of a Haskell-specific solution. When I need to automate keyboard and mouse events I like to use [Sikuki](http://www.sikuli.org/), which uses a mix of Java and Python. If I were you, I'd take a look at its source code to figure out of there's something I could port to Haskell.
Thanks! Will the repl by default work well with stack?
You should take a look at [Heist](https://hackage.haskell.org/package/heist): it's addressing the same problem space you are, albeit in a different way.
[removed]
I use a local `hoogle server`. You might be interested in [`hoogle-index`](http://hackage.haskell.org/package/hoogle-index), which makes it easy to generate a hoogle index for all packages in your package database.
I developed something like this for a while as an internal project for work. It's been put on ice and I doubt I'd get permission to open-source it, but it was a really interesting project and I'd love to work on something similar in the FOSS domain.
This is a really nice presentation of templating using a solution I had never thought of (continuations). Nice work!
Yes, documentation is built one package at a time, both locally and on hackage. So I still don't see the difference. How do you search for things on hackage? I always use hoogle.
I'm about 85% sure that that's _not_ how it ends up working in the language we're designing (not that I can really test it, given that we lack a standard library which contains Set). I _think_ that a mutable Set would be inferred to be invariant in its parameter (which would be inferred to be a union type of all possible insertions), and when it comes to an immutable set, anything you inserted into it would widen the output Set's type to just big enough to accommodate. On the other hand, "Trying to look up an Int in a Set[Double]" is an example that I need to keep in mind. Thanks.
Right, but you could refine the type to accept only `NonEmpty ()` (or some other encoding of the positive naturals) on the right. If you make this the default, then you can use it with things that aren't monoids, but code that takes monoids as inputs would have to implement this check themselves, and it doesn't work well with the numeric hierarchy either. I think `Monoid` is better, though.
Interview with Adam Wick [here](http://www.infoq.com/interviews/wick-security-unikernels) . Towards the end, he mentions HaLVM.
No, I am just getting started and have nothing to share right now. I am seriously considering writing a Haskell book, sort of in the spirit of my first Springer-Verlag Common Lisp book: a collection of (hopefully) interesting short programs with enough background material to make the book self contained. This side project would make a good book example. Lately I have been self publishing my books on leanpub for $4, so hopefully any Haskell book I write will be worth the money :-) I have the open source code to all of my books and side projects on https://github.com/mark-watson?tab=repositories so that is where the code will likely end up.
Nice - thanks! It sounds like their main motivation for developing a unikernel is to reduce the security vulnerability attack surface for the application. I wonder if there are approaches which focus on performance or scale.
If you're using `haskell-mode`, it should automatically detect that you're using stack in a project and should Just Work. I'd recommend checking out that project and familiarize yourself with what it provides.
You need to execute js snippet like this `window.scrollBy(0,250)` with `executeJS` function ( https://hackage.haskell.org/package/webdriver-0.6.0.4/docs/Test-WebDriver-Commands.html#v:executeJS ), if your question is about haskell webdriver.
Also worth considering (,,) &lt;$&gt; [1,2,3] &lt;*&gt; [4,5,6] &lt;*&gt; [7,8,9]
I'm really confused about what you're asking and why you're getting upset when I try to clarify? I do not want to tell you where I work on reddit as that's personally identifying - all you need to know is that I work at a big java based shop that manages to have low iteration times, even with large projects. 
Indeed, that's why `lucid` came into existance.
Good luck and have fun :)
The cool thing is that, because of `ContH Void`, it supports regular HTML just as well.
I'd really like to see this with some sort of encoding regime running, so that templates are safe in the face of XSS, to see what that does to complexity of usage. If you use an existing HTML type instead of string, you'd get that "automatically". It would be helpful to see how useful this is in a more realistic case. (This is not an implicit claim that this will render it useless. I don't believe it will. It would just be more useful/realistic to look at.)
Well, the [HaLVM](https://github.com/GaloisInc/HaLVM) is still up and around. We're using it as the basis for a network defense product at Galois, [CyberChaff](https://galois.com/project/cyberchaff/), for example, and use it now and again as a basis for other work we do for our clients. I've also been using the HaLVM as one of the target platforms for my [haskell-tor](https://github.com/GaloisInc/haskell-tor) implementation. Right at the moment, there are two major efforts going on that I know about in the HaLVM world: 1. Trevor Elliott's been rebuilding our network stack, [HaNS](https://hackage.haskell.org/package/hans), to much improve the memory performance. The initial stuff he's been showing me is pretty awesome. 1. I've been looking into HaLVM v3. The critical updates on that front will be an upgrade to 7.10.3, and then (probably) porting the base runtime to use the rumpkernel instead of our old system. The reason for the latter is to see if we can ride the rumpkernels stability (it's based on NetBSD, which I trust pretty solidly) as well as its portability (it supports Xen, but also bare metal, KVM, etc.). I suspect this will cause a shake-up in the libraries, but I'm hoping it's worth it in the end. If you want to see evidence of work, see the `halvm3` branch in the HaLVM tree. If you're interested in playing with the HaLVM, [here](https://github.com/GaloisInc/HaLVM/wiki/Building-a-Development-Virtual-Machine) are some step-by-step instructions for setting up a development machine, or you could pull the [Vagrant setup](https://github.com/GaloisInc/HaLVM-Vagrant/tree/fedora22) I've been using. (Note the branch.) Once there, play around with it! And if anything doesn't work, file a GitHub issue. It may surprise people, but filing bug reports may be one of the most effective ways to help the HaLVM, as it provides public evidence that there are a wide variety of people interested in it. I've been told by some folks that they're using it privately, but "I'm getting supportive emails!" is not quite as compelling to my management and funders as tangible things like bug reports. And, obviously, if you end up using it in a project, please tell us!
It's been stable enough for us in one of our products ... although I'll be the first to admit that said product is in alpha, so "stable" is an interesting term. But this is the reason you're not seeing much change in the `master` branch: we have something that seems to work well enough for a product we're pushing, so we want to be very careful about rocking the boat. If you want recent changes, I've been noodling around in the `halvm3` branch.
I like its idea for naming using underscores.
Yes, there are. One nice thing, though, is that minimizing attack surface should get us performance scale as side effects. So while they're not things we're relentlessly pursuing, like the [ClickOS folks at NEC](http://cnp.neclab.eu/clickos/), we do get some wins: 1. Reducing the attack surface is highly related to reducing the amount of code, which helps us scale out widely. 1. Fewer schedulers (for example, no process scheduler) helps reduce our latency numbers quite nicely. 1. Smaller code size means more cache hits and less pressure on the branch predictor. 1. No processes means no TLB / cache flushes on process switch; All Our Threads Are Green. Etc., etc. All that being said, of course, Galois's interest and my own interest is mostly about making cloud and other applications more secure by making them much smaller and much more variable.
&gt; I do not want to tell you where I work on reddit That's my answer then. I don't have that same personal policy; my real name appears in my username. &gt; all you need to know is... That's incorrect. My theory is that low iteration times have more to do with organization and culture than technology, so a data point without that information is useless to me.
&gt; Also, what did you have in mind for a more realistic case? Just that concatenating strings is an unrealistic case for HTML template, and I'd like to see it with real HTML to analyze it. I realize this is partially just me, but my _XSS! XSS!_ sirens are blaring so loudly I can't hardly concentrate on what you're proposing. But it would be nice to see it with not-strings anyhow, to compare cleanly to the other alternatives.
Continuations would probably be helpful: http://www.haskellforall.com/2012/12/the-continuation-monad.html (even if you've seen continuations before, I think this posts "complete-me-later" explanation is best for this situation.)
https://esolangs.org/wiki/Unary
What's wrong with `++`? Addition doesn't even make sense for strings, and not all monoids are addative (wouldn't it be weird to use `+` for the `Product a` monoid?)
A mutable set is perforce invariant. Just like a mutable Square isn't a subtype of a mutable Rectangle, but an immutable Square can be a subtype of an immutable Rectangle. Mutability mostly destroys proper subtyping relationships. A functional, immutable set can (and likely should) have the subtyping relationship just described, however, and this becomes actually necessary if, like Scala, you have poor (or no) inference for higher-rank / polymorphic types.
Are you looking forward to backpack? Are there things it would help you tremendously with? I am asking because of the great flexibility provided by Ocaml's module system that is exploited in Mirage. One nice thing is the workflow: develop on linux, then swap the layers and run on Xen. Do you think that having backpack would enable the same thing for Haskell and HaLVM?
They look similar but aren't exactly the same. Which would you rather use to get the last element of an array? @array[*-1] @array[ { $^number-of-elements - 1 } ] @array[ -&gt; $number-of-elements { $number-of-elements - 1 } ] @array[ @array.elems - 1 ] I would like to point out that `*-1` looks like special syntax, but it is not. Note that the first three examples are functionally identical, and the last one could have problems when using a Positional that takes care of race conditions for you for example. The first one is different because it is useful to have a way to write a very short very basic Code object, but sometimes you need to use something that can't be written so simply. So the two axioms are not absolute directives, but are guidelines. There are infix Set operators which look similar to each other, but different than Bag operators. There is also a bit of similarities between the operators. Both have `()` surrounding them, but Sets have `(elem)` and Bags have `(+)`. So they look sort of similar because they are for similar types, but they also look different because they really are for different types. Also note that the Bag `(+)` operator looks similar to the Numeric `+` operator, again because they do similar things with their operands.
I think it is a benefit that they can write it the way they are used to. At least then a more experienced Perl 6 programmer can figure out exactly what the other is trying to accomplish, and can provide helpful advice.
The type of the constructor ensures that the request arguments are well-typed, and the index of the GADT ensures that the response is well-typed. We have no need to get the request argument type in any other context.
Unless the grammar is infinite (/ recursive), like `many`. For example, in `parsec`: p_undistributed = "a" * ("b" + "bb" + "bbb" + ...) -- (:) &lt;$&gt; string "a" &lt;*&gt; some (string "b") can't to be left-distributed into: p_distributed = ("a" * "b") + ("a" * "bb") + ("a" * "bbb") + ... `p_distributed` doesn't terminate on `"c"`, but `p_undistributed` does, by short-circuiting. 
It's use of functional dependencies to optionally require arguments is nice, too.
It is useful to have a kitchen sink when you are building a kitchen. In such an analogy Perl 6 provides several different kitchen and bathroom sinks, as well as laundry room sinks, and drain pans to go under clothes washers. Why would you go to four different stores to buy each of those when building a new house? In other languages you "can have it in any color you want, as long as it's black". In Perl 6 you can have any color, here is a few common colors in stock, or you can custom order a color if that is what you want, even if it is a color we didn't know existed. Here is something you may not know, it is common to use Perl 5 code as a sort of preprocessor for Verilog. That is because of shortcomings in that language that have to be worked around. If it had a way to patch itself like Perl 6 can, there would be no need for that.
Okay, here is the XSS resistant version: http://lpaste.net/150853 (it's a lot more complicated, but that's because I added a ton of extra stuff besides XSS restitance. The XSS part was easy.)
I realize many static type systems are worlds worse than Haskell's, but I'm interested in legitimate (data-based) responses to this study, perhaps that I could use to dissuade. ;)
My paste shows how you can add attributes monadically (I edited the paste url into the post). Its pretty nifty (even niftier if your export `&lt;&lt;`). The only thing that sort of bums me out is you can't add the attributes after the thing (as far as I know).
Most important comment: http://games.greggman.com/game/dynamic-typing-static-typing/#comment-2471410945 It begins, &gt;&gt;People believe static typing catches bugs. People believe static typing helps document code. People believe static typing makes IDEs work better and therefore save time, etc. BUT … those are all just beliefs not backed up by any data. &gt; In the meantime, there is a number of studies out there that actually give evidence for these claims.
That is inlining C code in Haskell, what I showed had exactly zero C code. none nada zip That `...` is literally in the source code. It is ignored by NativeCall, so I could have put anything that could be parsed as Perl 6 there. Maybe I should have made it empty so no one would have gotten confused. Inlining is possible in Perl 6 as well, I don't really know C so here is the test from the Inline module: use Inline; sub a_plus_b( int32, int32 ) is inline('C') returns int32 {' DLLEXPORT int a_plus_b (int a, int b) { return a + b; } '} Most people would write something like this: use NativeCall; sub parse-vector ( UInt $length ) { # scope the declaration to inside of this subroutine # so that I don't have to deal with all of the types # that scanf can work with sub scanf ( str, num64 is rw --&gt; int32 ) is native('libc:6') {} eager ( 0 ..^ $length ).map: { last unless scanf( '%lf ', my num64 $n ); $n; } } 
But the point is, you'd then run the code in a REPL or unit test, find the error, and make it work correctly. I do agree with you that the class of errors that can be found in a language with a type system like Haskell's is much broader than `TypeError` and `NameError` (nobody seemed to account for the fact that static types can encode invariants, not just catch typos), but please don't succumb to the fallacy that just because the compiler can't catch errors in a dynamic language, they won't be caught.
Many programming languages only have the one reference implementation. F#, Rust, OCaml come to mind. Many more don't - Ruby, JavaScript, Python, C, C++, Java. I'm not sure what it really buys them though.
&gt; I mean, if GHC adds a feature, it basically becomes Haskell. That is my issue with GHC. The Haskell Committee is being reformed, which is *supposed* to help standardise things more, but really, if the new Haskell Committee refused to standardise (say) the Foldable-Traversable Proposal despite GHC pushing it on everyone they'd be laughed off the stage and lose all credibility. Extensions you need to explicitly turn on are fine, I have no problem with that. I *do* have a problem with changing the language or standard libraries in incompatible ways by default.
It's not the only implementation though.
There are elements of the current C++ language that can't really be disambiguated with classic lexer hacks. In Elsa, they'll typically leave the syntactic ambiguities in place, and then during typechecking go back through and ensure that only one passes the typechecker. See the description of how they implement `merge()` several minutes into https://www.youtube.com/watch?v=uncfFsbUF68 (At 12:58 or so it talks about how the lexer hack requires you dump everything into unparsed token streams.)
In the case of a small language, dispersion of focus is even more dangerous. But I feel that the open-source community behaves a lot like the left in politics: as soon as something is big and there is a divergence, it splits.
Yes, but if CPython adds a feature, it basically becomes Python, which is the "danger" OP is talking about with GHC.
Has this ever caused problems?
One could argue that if the "Haskell community" valued having multiple implementations over a single one that has more interesting features, we'd see more effort in maintenance of other implementations, or at least more objections voiced on the part of maintainers of other implementations that would be burdened by things become de-facto standard when GHC implements them. I've heard voices *other* than people maintaining non-GHC Haskell compilers note that some of GHC's recent type system features would be burdensome to replicate, but maybe I'm not listening in the right spots to hear maintainers of other Haskell systems. I know there are non-GHC Haskell implementations used and maintained commercially, but as far as I'm aware they're not available to the public and don't particularly care about GHC-compatibility, having developed incompatible features of their own. There are probably still some educational uses of the house-brand Haskell systems at various universities, but I don't really hear much about them aside from an occasional paper. JHC was briefly revived a year or two ago, but doesn't seem to have a lot of effort being put into it. I think Hugs was the last aggressively-maintained implementation besides GHC, and it's been explicitly out to pasture for a while now. Compilers don't just come into existence to protect some notion of language implementation independence; someone has to have a need for one and enough resources to make it happen and to maintain it. Right now, GHC development is open enough that people find it better to just focus their efforts on GHC. You can only do so much with a committee; they can provide some steering, but ultimately development effort is going to follow the needs of people holding the purse strings for funding development, or the interests of those who are donating their time.
I think it's good that the talented hackers who are capable of working on a Haskell compiler agree on enough things (features, licenses, etc.) to work on one compiler, and that users agree enough to use it. I don't see how the advantages of having multiple compilers outweigh the disadvantages of splitting the talent pool. 
It is absolutely dangerous, but the existing alternative of sticking to a published standard is worse. That we have no alternative to GHC and its accumulated culture is an enormous hindrance to many improvements, but the next Haskell will be based on the GHC breed of Haskell that enterprising users appreciate. It is a mistake to address this weakness by regressing to an inferior state of affairs. Instead, we should strive to make it easy to tailor GHC to be the compiler we wish we had, as that will be the launching point for a fork, not Haskell98.
Competition for competitions sake is stupid. Competition is useful to narrow down the design space in the presence of unclear metrics. And that does happen all the time, but usually not under the name Haskell. Committing to some form of Haskell compatibility is a losing proposition for competition, because essentially it leaves only rather well defined metrics like performance to pull ahead, which I boldly claim requires not only major innovation but also years of laborious work, at which point you would find yourself looking for some kind of synergy opportunity with GHC. Political considerations of checks and balances are something different and the limited form they are relevant to software development especially in presence of open-source licenses, amounts to making sure all stake holders a considered, which if sometimes not optimal is nothing the GHC community is particular bad at, I would say. So if GHC were a bad piece of software or some stake holders wouldn't have a say in the direction it was going, those where things competition could grow on. And I think an open-source license is important in that regard. But a preventive fork, let alone a reimplementation, in absence of a technical motivations, would be a non-starter, waste of resources and could only result from a badly mixed-up view of politics and resource-management, although maintaining the possibility for it in form of standards, documentation and liberal licenses is important, IMHO.
I'll give some concrete examples of this phenomenon: * Dynamic programmers love to directly render output using templates (using `mustache`, `jinja`, etc.) whereas static programmers will tend to first go through a strongly typed abstract syntax tree and then render that. Doing everything through a typed abstract syntax tree transforms runtime templating errors into compile-time type errors * Incorrectly escaped strings: type error * Out of bounds indexes can be made into a type error using more advanced type systems (like [Liquid Haskell](http://www.haskellforall.com/2015/12/compile-time-memory-safety-using-liquid.html)) * Dynamic programmers will often use a variabe-size array to represent a fixed-size data structure (i.e. a 3-tuple, for example), so what should have been a type error becomes an out-of-bounds index error * Reflection: type error in Haskell (using GHC generics) * Uninitialized values (i.e. `nil`/`None`) - runtime error in a dynamic language, type error in a static language values are non-empty by default * Incorrect handlers for routes or dead links - type errors in many Haskell web frameworks * Malformed database queries - type errors in many Haskell ORM libraries * Client/server API mismatch - type error using the `servant` library * Multiplying or adding matrices of incorrect sizes - type error when using phantom types to keep track of matrix sizes
IIRC, C++ can't be parsed by a CFG, though.
Do not forget about Category Theory
The category theory only really enters through the lambda calculus door. Monads are a big part of Haskell, but no where near as fundamental as lambda calculus.
Hey! You haven't upstreamed this. Care to make a PR?
Yup, from physics: https://en.wikipedia.org/wiki/Spherical_cow
~~There are counterexamples for any Monoid in `Const`, but these are essentially all the same as this one.~~ Nevermind. :)
Good idea. You can get the location of the element to scroll to with this: http://stackoverflow.com/questions/442404/retrieve-the-position-x-y-of-an-html-element
Most cows are trivial. Some speak of a nontrivial cow, but only in hushed whispers.
What do all those types mean? It's a bit hard to read like that. Maybe: data That a = That a | THat type family THAT a where THAT THat = () THAT (That (That a)) = IO (THAT a) THAT (That a) = a -- closed type family so that everybody knows exactly what a THAT means data family THAT_ a newtype instance THAT_ THat = MyThat {unMyThat :: THAT (That (That THat))} 
I understand what he said as this: "Dynamic languages don't have as many type errors, because the errors they have are no longer type errors". I would like to see a comparison of runtime errors, let us see where Dynamic languages stand then.
I agree with this. People think that competition is the key to everything. What about collaboration? I'm quite grateful that Haskell has a community where people first try to collaborate, and the fact we have a strong compiler is the result of this communal effort. GHC is not what it is because it has an evil mastermind behind it, trying to pervert the language, but because it is what the community wanted.
I wish I lived in the Bay Area :(. 
The point of using `Void` is increased type safety. Although HTML can be seen as accepting any type of hole, I prefer to think of it as accepting no holes. This way, you don't accidentally confuse `HTML` with other stuff. I guess it's a matter of taste. (You could probably define a generic summing operator of the form `(a -&gt; c) -&gt; (b -&gt; c) -&gt; ContH a -&gt; ContH b -&gt; ContH c`.) Also, report back any findings. Also, see my paste at the end of the post, which extends this a great deal.
Cool, I signed up for this, thanks!
Typing tremendously clarifies the intended and actual behavior of a program. Without clear types, we can make few guarantees, if any, of a program's robustness.
I don't have experience with OCaml. I do know it's impure. conflating IO String with String is a lot worse than just not distinguishing [] from NonEmpty. Java's typechecker is fast because it doesn't do much. 
It depends on the type of `return a`. If it's `m t` for some particular monad `m`, then there are counterexaples. If it's `forall m. m t`, then we can use the identity monad to show that `a = b`. (Or maybe the second one isn't possible and I'm accidentally pretending that `return` is more polymorphic than it is?)
I'm not sure what that grape thing is, or what you're asking, but aeson is the most popular library for JSON parsing and serialization, and that's where the `Value` type is coming from in the function you linked: http://hackage.haskell.org/package/aeson-0.10.0.0
I'd say UHC is aggressively maintained: https://github.com/UU-ComputerScience/uhc/tree/master/EHC 1834 commits, last commit: 11 hours ago. * Homepage: http://foswiki.cs.uu.nl/foswiki/UHC/WebHome * Changelog: https://github.com/UU-ComputerScience/uhc/blob/master/EHC/changelog.md
I think it's a stretch to say that type systems - even quite complex and robust type systems like Haskell's - help with correctness in the presence of varying application state. Only dependent typing systems have a strong claim there, IMO. I also contend that all code should have been executed at least once by the person developing it, and very often run at least once under a debugger. (Submitting code that has never been run at all is just inexcusably lazy and reckless.) That is even the case if there are no automated tests at all. Type errors are, in the vast majority of cases, found on the very first run of code, in dynamic languages, and then quickly fixed. The argument for refactoring is a good one. I personally prefer statically typed languages with strong type inference, and this is probably the best reason I know of. It is the one scenario where it is highly unlikely that all of the code has been tested after a type change. But to play devil's advocate, are you actually saving time in the long run? Duck typing in particular can save a ton of time on the front end of development, and even help with many kinds of refactoring, where in a statically typed language significant code changes would have been required but in a dynamically typed languages the type "shape" is still similar enough that no changes are required.
Python's language standard is at https://docs.python.org/3/reference/. Unless you meant something different?
"It is terse, but attempts to be exact and complete." This seems to imply that the reference is just that, a reference. If, on the other hand, when you downloaded the python interpreter it said "This attempts to conform to the reference", then it would be a standard. Namely, if differences between the interpreter and reference are found, I bet they would update the reference, not the interpreter.
&gt; Are there any good resources for learning the fundamental nature of SQL that a Haskeller would like? Prolog. Nah, I'm joking. Kind of. After somebody recommends a good resource (I don't know of any good introductions) and you grok SQL, definitely look at Prolog. If you squint enough, you can sort of see similarities.
[This](https://en.wikipedia.org/wiki/Relational_algebra) is a good start. Relational algebra is the theory behind relational databases, and SQL makes _way_ more sense after you've learned a bit of it. 
I found this very helpful http://www.postgresql.org/docs/manuals/
Sure. It'd probably help to have another couple of Simons with 20+ years worth of knowledge about the ins and outs of the codebase to help develop it though.
To an extent. A lot of the alternative Python implementations haven't been upgraded to work with Python 3-only features, so if you want to use Python 3 features, you basically have to use CPython. Not necessarily a *big* problem, but it has caused some issues.
Not unambiguously, but it's certainly possible to do it ambiguously.
I enjoyed "Database in Depth: Relational Theory for Practitioners" by C.J. Date. It's a nice thin overview of relational theory and normalization, then go to the postgres docs for SQL specifics.
&gt; 'infinite resources' assumption is what made lazy IO look like a good idea ;) Best joke I've seen today. Thank you for that :)
Looks like everyone above has great answers, so I'll leave the technical discussion aside and just comment that LYAH's discussion of Reader is I think pretty misleading in that it focuses solely on functions as an instance. Reader is essentially "read-only" state, much like Writer is "write-only" state (with the state being a Monoid) and State being read-write state. Reader is useful for things like environment bindings for type-checking or interpreters, where you're recursing down some structure (an AST, say) and want to provide context that depends on what part of the structure you're processing. For example, if you're evaluating a function application / beta reduction, the value of the parameter being passed should be added (with the name of the formal parameter) to the context in which the body is being evaluated. Using a Reader monad would be useful here since you probably don't want to let the binding be changed. (Although if the value is a reference to some object in the heap or something like that, the object being referenced should probably be mutable, in which case passing it along the State monad would be a better solution.)
Definitely agree here. It's not just a matter of cost, it's a matter of opportunity cost.
Haskell isn't popular enough for this to be a problem worth solving.
Sooo... We need a cloning device?
Frege aims for 100% interop with GHC, and outputs JVM bytecode
This is quite cool, Travis! If I were to use Beam for one of my projects, how would you recommend dealing with migrations (schema changes)? Does Beam have any support for that, or does it need to be done via ad-hoc SQL scripts for now?
For now, it would have to be ad-hoc SQL scripts for anything more complex than adding whole tables. Beam supports very simple CREATE TABLE statements based off the schema, and will create tables it sees are missing, but it won't issue any ALTER TABLEs (although it has all the information to be able to). In the current version, I've only implemented migrations inasmuch as I wanted to make the tutorials easy to run and understand. I could definitely see building this feature out in a separate package (beam-migrations, anyone?). 
[removed]
Honestly, it looks like a nice small library and all, but I don't buy this type safety claim. From what I can tell, it is still possible to generate code that does not compile, for example by causing name clashes: function identifiers being represented as runtime strings, there is no way the compiler can check their unicity within a given module. Granted, it is not exactly a matter of type safety, but it still defeats the original purpose: having static guarantees that the generated code compiles. Similarly, when using imported functions, you can specify any type you like and the compiler will take your word for this. It is totally possible to mess things up here. They do provide Template Haskell helpers to address this issue, though. As for the type checking that /does/ happen, it is based on the injectivity of type constructors: ExpG a ~ ExpG b -&gt; a ~ b. Not exactly rocket science. 
Which works in some use cases, but this thing is really useful to me. I'm trying to produce compiling code randomly, genetic programming related. To me, it's really useful knowing whether some code compiles without me having to call ghc. In fact, I suspect this library will make my work easier. I think it's a really good library for the use case of "does this expression type check?" - it's not perfect, but if you're generating code automatically and want to weed out the worst of mistakes before continuing, this'll help.
Does the same hold for `Applicative` only? If `pure a = pure b` then `a = b` but you do not get to use the `Monad` laws?
This is great - thank you for the information. I have a bit of exposure to the rumpkernel world and I'd love to see how HaLVM might fit into/onto it. I'll definitely check out the halvm3 work and see how far I can get with setting up a dev instance. If anything interesting comes of it I'll let you know!
#UNLIMITED ~~POWER~~ PACKAGES!
I'd take a dynamic language (python, ruby, scheme) over C/C++/Java anytime, except for performance. Totally agree about 1, advanced type systems shine when making changes. I change the datatype, and I just need to follow the typeerrors, instead of manually having to chase each use. And I have a guarantee I haven't missed one.
&gt; parser plugins to simplify implementing alternative syntaxes? https://github.com/gibiansky/ghc-reskin - "A preprocessor for GHC for alternate Haskell syntaxes"
Now you can start with the fun part: documentation! * Litter your code with Haddocks text! * Update your `README.md` file to include instructions on how to get your application up and running on both Windows and Linux! * Generate the Haddocks HTML documentation and host it on Github Pages!
Can't you just call GHC's type checker through the GHC API?
The idea seems a bit similar to the [recent paper](http://compilers.cs.ucla.edu/popl16/popl16-full.pdf) on typed self-representation by Brown and Palsberg.
It wouldn't give you anything: you'd only be warned that your code does not compile when it is too late, that is, when it has already been generated. You might just as well try to compile it directly. 
Your tone seems a bit aggressive but I would like to hear some deeper comparisons here as well. Is there some problem with Opaleye's approach [1] besides being Postgresql specific? The best version of an ORM (FRM?) for Haskell so far seemed to be Groundhog, which also supports different back ends. Are there problems with Groundhog's approach beyond that it has TH (which isn't required but just makes defining the database schema easier, afaict)? I personally don't like TH used unnecassarily but so long as it's never required and is mostly used for automating useful boilerplate [2] then I don't see a big issue with it. [1] The author of Opaleye seemed to imply in the past that one needed to use Arrows to get a good projection API but Beam seems to support project and not use arrows for it (afaict)? What are the consequences here? [2] Useful boilerplate as opposed to design problems, which TH becomes a crutch to avoid fixing.
1) Your pattern matches are incomplete. Pity if someone entered something other than "CA" or "DA" :p 2) The most generic advice ever: Whenever you find any repeating patterns in your code, write proper abstractions around those patterns. Example 1: putStr foo hFlush stdout bar &lt;- getLine put it in a separate function! add the "is valid input" check to that function! Example 2: Every branch in your Main:main:runloop ends with `runLoop newAccounts`. While `newAccounts` might be different, you sure can factor out the `runLoop`. This leads to: 3) Many of your functions seem to be `:: AccountStore -&gt; m AccountStore`. (`m==IO` or `m==Identity`). So this AccountStore basically is your "State" *hint hint*. (if you want to abstract over both monads, you could e.g. use `depositToAccountInStore :: MonadState AccountStore m =&gt; Integer -&gt; String -&gt; String -&gt; m ()`) (and while you're creating a monad stack, add some EitherT to avoid those "if" nestings in `doWithDrawlAccounts`. But maybe i am taking this too far too quickly) Hope it helps. [Sorry for the edits; i really need preview functionality..]
What kinds of features/semantics are you imagining?
Sorry about the tone. This was absolutely not meant to be any sort of challenge. I simply want to know - because we use these kinds of things and want to know about all the options. This is a very interesting effort, thanks for it! I'm not asking here about the pluses and minuses of various design decisions (TH or not, which DB backends and interface libraries supported, which Haskell type system features used, etc.). Those are also very interesting questions, of course, but I am explicitly *not* discussing those. I just want to know the basics - what does the library do? Does one of the choices I gave describe it? If not, then what? Note that when I said things like "like Opaleye", I did not mean "like the fact that Opaleye only supports PostgreSQL" or whatever. I meant: "like Opaleye, which generates Haskell types and a DB from a DB schema specified using a type-level EDSL". And so on for the other choices I offered. If that's confusing, then please ignore the phrases "like foo" in my choices. 
&gt; All of the documentation that claims to answer that question focuses on "doesn't use TH" and "makes good use of advanced type system features". I'm only speculating, but it seems as though the author wanted to make this point clear despite which page a reader landed on. I'd personally prefer that it was only stated once on the main page. It's been distracting for me as a reader because I have to think twice about whether I just accidentally re-read the last line, or if in fact the last sentence was repeated in the text itself. 
He hasn't done Monads yet. (Or, for that matter, Semigroup, Monoid, Functor, Applicative, or even Typeclasses fully).
That's right and actually the main reason for this new major release so soon after LTS 4. See [this earlier post](https://www.reddit.com/r/haskell/comments/41gpdk/lts4_with_aeson010_is_being_discontinued_lts5/) for more details.
IIRC, aeson is the main reason for LTS 5.0 release. There has been a post about the issue in /r/haskell, you could look it up.
Good summary. And the summary of the answer is: The studies and evidence quoted generally refer to the kind of weak and less principled static typing commonly found in traditional languages like C and OO languages, not modern strongly typed languages with type inference. And even then, much of the evidence can easily be seen to be invalid. In short, it appears that the author of this post falls victim to his own criticism. He is merely trying to validate a belief that he doesn't want to consider changing. Which is fine - a lot of good software has been written in languages with dynamic typing. If you enjoy that - go ahead, have fun.
See the [post](https://www.reddit.com/r/haskell/comments/42nq68/response_to_dynamic_typing_static_typing/czbrdzc) of /u/cotravariant elsewhere in this thread which gives a few references.
Hey all, Firstly - please downvote/delete if not appropriate for this sub, I spend my time between Haskell, F# and OCaml these days :) We’re a London-based startup working on a microservices-based “CloudOS” using a mixture of OCaml, Linux containers, and Erlang/Elixir - with some DSLs, systems code, and distributed systems thrown in. We want developers to spend more time writing core business-logic and less time thinking about infrastructure. We’re looking for our first technical hires, who will be working with us to design and implement the core platform that will make this a reality. We have a MVP in Python (https://github.com/StackHut/stackhut); it gives a feel for what we’re trying to build, although is only a start. We’re implementing this in OCaml, and are looking for talented functional programmers (OCaml, Haskell, F#, Scala, etc.) preferably with some knowledge of Linux/Unix systems programming. It’s a challenging role, working on hard problems, but the chance to build and manage a technical team and shape a company and product from the get-go. We’re funded by top-tier infrastructure investors from the West Coast and the founders are highly-technical and ex-YC / PhD. Salaries are competitive and include stock options. Any questions please comment, DM, or reach out on email (mandeep at our domain name). Cheers!
All of the libraries I mentioned generate SQL in a type-safe manner, in some sense. But to do that, you need to give meaning to "type-safe" - that is, you need to declare some relationship between Haskell data types in your application and a DB schema, and provide functions that marshall between them. So the library needs to have knowledge about both the types and the schema in some way. I listed the ways I know about that libraries do that. I'm interested to know which of those methods this library is using, or perhaps something new.
Yes, it is a horrible practice, as `bsmntbombdood` explained. There are many ways to map functions from dynamic languages to their typed correspondents, and that requires getting used to. If a Python function receives an int and always returns an int, then the Haskell correspondent is `f :: Int -&gt; Int`. If sometimes it can return `null`, then `f :: Int -&gt; Maybe Int`. Anywhere you'd use `null`, use `Maybe` instead, it is the exact logical counterpart. 
Unless I'm misunderstanding what a virtual function is, no. map :: (a -&gt; b) -&gt; [a] -&gt; [b] map _ [] = [] map f (x:xs) = f x : map f xs That is a higher order function (it takes a function as a parameter), but it is not overridden in any sense.
Haha thanks :) I've always found this sub-reddit super-welcoming so not too worried but wasn't sure - plus like to think that OCaml and Haskell have a friendly sibling rivalry more than anything else!
I'd seen Church encoded lists and other types referenced several times in other projects and articles, but never quite wrapped my head around them. I learned a lot more writing this post. Feedback welcome.
yes, the issue raised by OP is a nonstarter.
Isn't that what rasterific does? 
&gt; Frege aims for 100% interop with GHC, and outputs JVM bytecode This would be impossible, unless SPJ himself helps out :) We're striving for Haskell 2010 compliancy, though.
Is this a Haskell question?
Great thanks. Very interesting. So in terms of the most basic "what it does", /u/onmach is correct that beam is closest to opaleye. But how the two libraries accomplish that and the resulting usage experiences are different. It's more than just that beam is not specific to PostgreSQL.
Stackage is an opt-in operation on the part of package maintainers. If you know of good libraries on Hackage, then encourage them to join Stackage!
Haven't all the aeson issues been fixed already? There just hasn't been an aeson-0.10.0.1 bugfix release yet.
I didn't look it too deeply, but from the types, it seems there are a few functions that could be collapsed into one, to avoid code repetition. You also defined many repetitive aliases in the where clauses, like `l` and `r`, which could be refactored into another helper function. I quite enjoyed your commit comment: "Everything works now". I believe that when you are learning, this is the goal. Now you can improve the code using the functionality you obtained as a sanity-check.
Viera describes compositional CFGs (as well as compositional attribute grammars for semantics) for Haskell in his Phd thesis (chapter 3), it uses some clever types to achieve this, http://foswiki.cs.uu.nl/foswiki/pub/Center/PhDs/thesisMarcosViera.pdf. Chapter 7 contains a case-study of a compiler for the Oberon language.
Many thanks Stackage team! Among the user-oriented things added in LTS-5 are [darcs](https://www.stackage.org/lts-5.0/package/darcs-2.10.2), [Frames](https://www.stackage.org/lts-5.0/package/Frames-0.1.2.1), and [shelltestrunner](https://www.stackage.org/lts-5.0/package/shelltestrunner-1.3.5).
You can take it a step further: module Test (module Test) where import Prelude as Test import A as Test f x = x
&gt; I also observed that most c++/java developers see genericity as "how to solve as many problem as possible with less types as possibles". The name for this is "primitive obsession"
You might also enjoy [this paper](http://arxiv.org/abs/1009.1166) about relational data based on functors. It's not quite SQL (they build it on top of sql) but it does shed a lot of light on what SQL operations "really" are.
I believe the TXL language / system has support for extensible grammars, but I can't remember the formalism it uses (might be basically LL extended with special resolution for backtracking). One of the papers on TXL mentions it but I can't find it at the moment. http://www.txl.ca/ 
Unless they meant to refer to [this beautiful esoteric language](http://esolangs.org/wiki/Funciton).
&gt;EU cookie law compliance. (Is this even necessary? It uses cookies only to store the state of collapsible sections, the current style and things like that.) From https://www.cookielaw.org/the-cookie-law/ &gt;The Directive gave individuals rights to refuse the use of cookies that reduce their online privacy. Don't think so. Should be fine. IANAL Very nice looking design, I have a functional concern: It doesn't use space effectively. Huge grey space to the right. Vertical density not great either. I do a _lot_ of scanning in Haddocks. 
&gt; It doesn't use space effectively. Huge grey space to the right. The problem is that if I use the full width of the screen the text would become way too wide and therefore harder to read (see [this comment](https://www.reddit.com/r/haskell/comments/4141ge/attempt_at_a_modern_haddock_theme/cyzgmk8)). I tried to create a compromise layout where the documentation sections had limited width while the layout was allowed to grow horizontally - it looked extremely ugly. I am going to fix up the Ocean theme after I'm done with this one, with minimal changes. &gt; Vertical density not great either. I do a lot of scanning in Haddocks. Probably due to font size and line spacing. It's pretty good for tutorials though: http://lamefun.github.io/Pipes-Tutorial.html 
Is the plan to try to get this merged? I really like the style of the exported functions (with the grayish background, and bold text). http://lamefun.github.io/Pipes-Prelude.html take with a grain of salt: The different gray and purplish gray colors seemed a little visually confusing. I changed the code.inline background to `#ededed` and like it better. I also prefer a plain lighter gray for pre.block background; something like `#F3F3F3` http://i.imgur.com/UJm1DWk.png The more I look at it the more I think it's really nice! Good work.
&gt; Is the plan to try to get this merged? If I don't lose interest, yes, otherwise why would I do this? 
Is there any way to upload these docs to hackage for our libraries yet? Any tutorial for us let haddock familiar folks?
&gt; For the narrow version, without the side bar, are you planning in making the index/search a dropdown from the topbar? Yes. &gt; One observation, the code blocks seem to break at the right side when the screen width is reduced. They can be scrolled horizontally.
Aim for the moon; if you miss, you'll still be among the stars. :)
Good stuff! It'd be nifty if, given enough space, source code got opened up in the right column. That said, I realize how tricky it could be to get that right, so should probably be a rather low priority enhancement :)
GLPipe? Diagrams? What are you looking to do?
An interesting case study is the Lua language, which has an [official imlementation](http://www.lua.org/) and "benevolent dictatorship" by PUC-Rio, but also has a widely used and very-high-performance implementation in the form of [LuaJIT](http://luajit.org/). In the last couple of years, the maintainer of LuaJIT began to disagree with the direction the Lua language was being taken, as it would cause serious performance regressions in LuaJIT to implement the new features, so it simply hasn't been updated to the last couple of language releases. It also has a different FFI and a couple of other differences. There are now a few programs that target *only* LuaJIT, and a number that won't run on LuaJIT due to using language features it doesn't support. There's a bit of consternation in the Lua community over this (especially in the part that uses it as a standalone language rather than an extension language to some particular application) and some worry about a serious split if the languages drift farther apart. I'm not sure this is *actually* a problem, though. If one implementation or the other is appealing enough for some particular use, accomodations can be made to get things working on it with some extra effort. It's the sort of thing people grumble about sometimes, but at the same time the differences provided by the different implementations probably make a *lot* more people smile than grumble.
It's not just a "story", there is a dictionary at runtime. My understanding is that sometimes/often it can be optimized away, but it does need to exist and be passed around with values at runtime. When you have a function `f :: Foo a =&gt; a -&gt; Int`, the compiler can ensure that any given call to `f` is passing something with `Foo`, but at runtime it still needs to figure out *which* instance to use, and it does that by passing a dictionary around; very similar to virtual method tables in C++.
Because Stack Overflow marks everything as off-topic and contentious. Reddit &gt; SO
C compilers usually compile to an intermediate code where the execution model assumes you have an infinite number of registers and every register is only assigned a value once and is never assigned anything ever again. Under this assumption it is easier to compute how many registers are live at any given time during a procedure, and allocate your actual limited number of registers accordingly. But in Haskell, the language is **defined** such that you can only assign a value to a variable once, and then never assigned anything to it ever again (a property known as ~~referential transparency~~ immutability), just like intermediate code for a typical C compiler. So you could say Haskell is like a very high level, feature-rich intermediate code with static type checking. GHC Haskell compiles in stages. The first stage is to compile to an intermediate code called "core" which uses an execution model known as the Spineless Tagless G-Machine or "STG." During this first stage, the compiler can very, **very** aggressively rewrite the code, which is possible because of ~~referential transparency~~ immutability. Lazyiness and pureness also has a hand in efficiency. The optimizer may be able to prove that re-ordering lazy computations can save time and memory, and since these functions are pure (no side effects), re-ordering their evaluation will cause no unintended side-effects -- the code will operate the same no matter what order it is evaluated. This also allows for some aggressive optimizations. If the Haskell were to be interpreted, you may have to call through hundreds of layers of `newtype`s and anonymous functions, especially when using monad transformers. But after optimizing the STG core code, all of these layers are stripped away entirely, and all you are left with is the simplest, smallest possible program that obeys the logic defined in the Haskell code. Then, core is translated to a re-targetable assembler language like LLVM or C-- ("C-minus-minus"), and I believe it is at this stage that registers are allocated. But by the the time the STG core code has reached this point, the code is already quite well optimized, so the assembler has not much more work to do -- mostly inlining, loop unrolling, reducing, and dead code elimination -- things which don't need as much knowledge of the higher-level logic in order to perform well. If you were to use too many strictness annotations, or rely to much on the IO monad, these aggressive optimizations would not be possible, so keep your code as pure and lazy as possible. Also, don't use strictness annotations unless you are sure the optimizer is making a mistake. (**EDIT:** as /u/winterkoninkje pointed out, I confused immutability with referential transparency.)
Higher order functions are often optimized away during compilation, so in that sense you could consider them virtual. But otherwise no, higher order functions are just ordinary functions, except more polymorphic.
Honestly, I think there's too much vertical spacing in that tutorial. Within a paragraph is OK, but paragraph breaks and *especially* bullet point separation seem wide. The "Information" block at the top is probably twice as tall as it needs to be. I'd also favor a slightly smaller main font. The size in the info block actually feels better to me. Totally okay with the horizontal limitation over here, by the way. FAR better than the common alternative of designing for full widescreen. :P
The difference with C++ is that if the type has any virtual methods it must carry a vtable for dynamic dispatch --- you must pay that penalty. The class dictionaries are only used at run-time when the overloading isn't resolved statically.
I use LaTeX a lot and have more than dabbled in typography and graphic design. I love your design; much improved. If anything, I'd add about 10% more width to the pure white part of the page (to make for a more page feel on the light blue background) and leave the line spacing as it is. Your bullet points and paragraph breaks are not too large at all. You want them that large especially if you use `inline code` anywhere in the paragraphs or bullet points. I might suggest making the headers larger, though, for even more distinct separation. More whitespace is a good thing for reading and understanding material. The only reason high density becomes desired is on repeated viewings when your brain can create virtual whitespace and filter out everything you don't need for you. Quite frankly, this is *never* desirable with tutorials, documentation, or anything presenting important information to someone who isn't already highly familiar with it. If people insist on a high density layout, I'd make an entirely separate one and stick it as far away from the defaults as possible. However, I do really wish the programming world was just a touch more design conscious and I applaud you for taking a step in the right direction.
Great! Would be nice to include a standard '?' keyboard shortcut overlay. For example using mousetrap. https://github.com/Sveder/mousetrap.help
That sidebar is the best thing ever!
Weird I never heard of Capstone. When I was looking for a disassembler, I found https://github.com/vmt/udis86 and the associated Haskell bindings. I wonder how a Haskell binding would turn out for Capstone.
What I think would really be helpful, in general, would be a high-ish level comparison of what Arrows bring to the table for this kind of API verses what a Functor/Applicative approach does (perhaps Monad could also be covered). I think something like that would make a great blog post or article that could really aid in understanding at least Arrows because, in my experience, the hardest part about learning more abstract parts of Haskell (e.g. Arrows, Profunctor, Bifunctor, etc.) is no realistic (or not enough different) motivating example(s).
It looks really nice. A quick improvement I could think of is, hightlighting the subtitle in the sidebar depending on where one is, scrolling wise. Otherwise I always have to scan through the list to find where I am right now.
Yes, that's definitely correct. You can't have something as strong as a monad. Applicative would be fine, but Arrow allows slightly more convenience.
Thanks! Wow, roughly 100 times slower for most Free monad implementations, as compared to the Monad Transformer Library. I guess I will avoid Free monads then. In my case it wasn't a requirement, but I thought it may be nice if I could add scripting support to my library without requiring GHCi. But it is too much of detriment to justify adding such a feature.
Technically the examples are the Boehm-Berarducci encoding, not Church encoding which is untyped.
I just looked up, it is written in C, which makes the task fairly easier.
"Final encoding" is a slightly overloaded word. Oleg has his "finally tagless" style which I'm not sure is exactly a final encoding, but sort of looks like one. Then there's data Final f where -- a.k.a. "Nu" Final :: (s -&gt; f s) -&gt; s -&gt; Final f which is, in Haskell, due to laziness, equivalent to data Fix f = Fix (f (Fix f)) which, if you haven't seen this sort of thing before, equivalates data ListF a x = ConsF a x | NilF deriving Functor to :: Fix (ListF a) -&gt; [a] from :: [a] -&gt; Fix (ListF a) This `Final` notes that data types are "final coalgebras" earning its name and is probably as close to a "final encoding" as you can get. A Church Encoding of a data type looks a bit similar. Let me show you what it is for `[a]` type ChurchList a = forall r . r -&gt; (a -&gt; r -&gt; r) -&gt; r which, if we squint a bit is type ChurchList a = forall r . ListF a r -&gt; r So we can see that Church encodings aren't really the same as Final encodings. It turns out they're more like—well, exactly like—"initial encodings" -- doesn't actually need a GADT since we replace the existential with a universal, -- but for parallelism's sake data Initial f where -- a.k.a. "Mu" Initial :: forall r . f r -&gt; r It might not be totally clear, but you should try to convince yourself that `Initial` and `Final` things are somehow the opposite of one another. There are lots of strong ways to show this, but you can already get the idea by looking at the definitions. Universals (`forall`) replace existentials (use of GADTs, that `s` thing). The function looks like `f x -&gt; x` or `x -&gt; f x`. Then the final thing to say is that this article sort of suggests that `[a]` and `Initial (ListF a)` are "the same". I also sort of suggested that `[a]` and `Final (ListF a)` are "the same". In Haskell both of these things are true (-ish) due to laziness, so you might instead think of `Initial f` and `Final f` as just "perspectives" on a data type described by the pattern functor `f`. Each has it's own emphasis and use.
I wonder if having the language lazy but user-defined data types default to strict fields with opt-in laziness would have been a better choice. I guess the difficulty would then be where to stop: lists should be spine lazy, but should they be head lazy too? What about pairs? The accumulator example above would still leak if you choose (lazy) pairs instead of the `Count` data type.
There won't be, the fixes require a major version bump.
Some notes on navigation: * Add list of submodules to each module page. So you could, e.g, go from `Haddock.Backends` to `Haddock.Backends.Hyperlinker`. * Turn page header into clickable navigation. So you could go from `Haddock.Backends.Hyperlinker` to `Haddock.Backends`. * Add list of neighbour modules to sidebar. So you could go from `Haddock.Backends.Hyperlinker` to `Haddock.Backends.LaTeX`. Look at documentation generated by rustdoc: http://doc.rust-lang.org/stable/std/os/unix/ 
In Haskell: You can override entries implied by a superclass? Can you give an example of what you mean, please?
Does FreeMonad have space for optimization or will it remain slow in regards to MTL ?
So true! small tasks being completed is such a motivating force when one is a beginner. In fact, even one isn't ! ;-)
There is Thrift as well, the 1.0.0 version has a much better Haskell code generator than before. And since Thrift is used at Facebook and they have some Haskell development, I assume that Haskell is going to stay well supported. I am currently looking at GRPC as well, I think technologically it is a step forwards (i.e. on top of HTTP/2, multiple messages in both the request and response are possible), but the Haskell integration looks like writing wrappers on top of the C++ code, so that's not ideal. A native Haskell code generator plugin would be a great project ;-)
Current implementations are slow. However, according to this [Freer Monads](http://okmij.org/ftp/Computation/free-monad.html) article, the performance is something that is investigated and up for optimizations. Particularly, [this](http://people.cs.kuleuven.be/~tom.schrijvers/Research/papers/mpc2015.pdf) paper shows a significant improvement.
It's open again. Post quickly before it is closed again.
Wow, that is exactly the answer I had hoped for. Thanks! 
&gt;mconcat . fmap step foldMap step
I quite prefer your color scheme, /u/jberryman . Care to submit a PR?
If there's demand we may be able to churn out a few more LTS 4.x releases once in a while, like we have done for LTS 3 recently. Hopefully aeson-0.11 can land in Nightly too before too long.
That is a **really** good idea, thanks! I don't think I would have thought of that on my own.
This is pretty neat. I like how the typeclass dictionary passing is clearly visible in the decompilation output.
Nice work. I think there's a few things you could do to make it better: - Remove the grey background on the right, and centre the content, such that there is more padding on the left and right, giving it more breathing room. - I think the sidebar might work better with the same background as the main content area and dark text. This is because it draws a lot of attention right now. Good stuff.
I think it sounds interesting. Do you consider telecommuting or part-timing?
Obviously if we knew a better place to post, we would have done that.
Much of the stuff in Simon's 1987 book is simply a description on the LML compiler. A reason Simon wrote the book was that he was studying the LML source code and found it very poorly documented, so he thought that when he had understood it, he should make it easier for others as well. Thank you Simon! 
This isn't a criticism of your specific approach, but I've never seen an attempt make extremely type safe dom builder that ended up being useful. I would encourage you to keep trying anyway because you'll probably learn something from it. Now, some specific criticisms: (1) Try to put a single quote before promoted data constructors. It makes it easier to read for others. (2) The combinators you've given (`circle'`, etc.) can only take a single child element. This is a significant regression from what lucid normally offers. To be clear, your API offers no way to produce this: &lt;circle&gt; &lt;thing1&gt;&lt;/thing1&gt; &lt;thing2&gt;&lt;/thing2&gt; &lt;/circle&gt; What if `thing1` is of type `Elem 'Animation` and `thing2` is of type `Elem 'Descriptive`? You could provide a way to combine elements. Then you would end up with something of type `Elem '[ 'Animation, 'Descriptive]`. But now `Elem`'s type variable is no longer kinded `Category`. It has become `[Category]`. So you would need to change things to accomodate that. A better approach would be to make `circle'` and friends take a heterogenous list (like `Rec` from `vinyl`) as an argument and then put a constraint on everything in the list of child categories (see `RecAll` from `vinyl` in `Data.Vinyl.TypeLevel` or `LAll` from `frames`).
The linked "cookielaw.org" site is a private company's page pushing their audit services. The EU is generally very good about providing official information about their laws, and they have [a more detailed site about the cookie law(s) with the actual rules set out](http://ec.europa.eu/ipg/basics/legal/cookies/index_en.htm). According to a (semi?) official EU interpretation of the law, "UI customization cookies" are exempt from the consent requirement *if* they are session cookies (or last "no more than a few additional hours" after the browser session ends). See section 3.6 of [00879/12/EN WP 194](http://ec.europa.eu/justice/data-protection/article-29/documentation/opinion-recommendation/files/2012/wp194_en.pdf) (pdf). Normal disclaimer: This isn't a legal opinion; I'm not licensed to practice in the EU; I'm not your lawyer; I'm not an expert on this; please don't sue me because that would increase my malpractice insurance premium.
The work on ghc might well have started in 1989. The work on hbc, the Haskell compiler based on the LML compiler, started in July 1990. The ghc crowd fairly quickly decided to use hbc for the bootstrapping of ghc, since it was a pretty complete implementation of Haskell. Hbc had a big performance lead over ghc for a number of years (some 1995 numbers http://doc.utwente.nl/55712/1/benchmarkII.pdf). In 2007 hbc had been unmaintained for a number of years but it was still competitive with ghc. https://web.archive.org/web/20070225070308/http://www.cse.unsw.edu.au/~dons/nobench/results.html The reason ghc broke off was that most of the other implementations were interpreters, and lmlc/hbc was written in LML so I didn't feel like maintaining it anymore.
... is your code running long enough that 100x is a drawback?
This looks fantastic. However, I find that the layout might feel less claustrophobic if the content were a tad wider. I think a bit more whitespace between the sidebar and the content might not hurt either. Would it be possible to center the entire layout in the view window?
Great to hear from someone with experience in both - a very balanced set of pros and cons regarding OCaml and Haskell. * I certainly agree that the async and multi-core story in Haskell is stronger - apparently multi-core is on the way in OCaml so am excited to try out the alpha soon. * Tooling is pretty mixed, both have their strengths and weaknesses. I'm haven't had to use the FPComplete tools yet, surprisingly cabal worked well for my use-case at the time - but OPAM is very good and ocamlbuild is better than it used to be. Conversely I've yet to use Merlin properly, using tuareg sucessfully in the past, yet had a great experience with Leksah on the Haskell side. * Documentation I find far better on the Haskell side, espcially for 3rd-party libraries - just the ability to brwose the types and documentation for all my installed libraries locally was incredibly useful. * Community is an issue - I feel it's getting better than before in OCaml, with Jane Street, Facebook and Bloomberg getting involved along with the Mirage folk. However there is no doubting the Haskell community is bigger and I'm slightly concerned of the impact it may have on hiring also. Cheers!
Unfortunately not for LiquidHaskell yet but this could be the future. EDIT: I tried many times and the link works. Only once I got some server error. Please try again.
Yay for more free Haskell books.
On CT: http://www.math.mcgill.ca/triples/Barr-Wells-ctcs.pdf
&gt; a property known as referential transparency No, that property is known as immutability. RT is a completely different beast. Yes, there are some connections between them (in particular that they both are notions of "purity"), but they really shouldn't be confused.
I understand how purity allows more optimizations, but I don't understand how laziness allows more optimizations. Can you explain?
Have you taken a look at [penny](https://hackage.haskell.org/package/penny)? It's a pretty robust package, and even if you don't want to adapt it to your needs, perhaps you could glean some insights on module organization from looking through the source.
For where the two intersect, see https://en.wikipedia.org/wiki/Cartesian_closed_category (and look at the first reference).
I'd suggest forgetting about modules for now, and think in terms of writing a library that can server your application. So when you find you write some bit of code that seems general and useful, move it out of your Main and into the library. How you structure the modules of the library is up to you, but I prefer not to break things up into different modules unnecessarily; it just makes things more complicated for you and your users. Good reasons I can think of to break up a lib into several modules: - you want to export things with the same name (e.g. Data.ByteString.Strict/Lazy) - for convenient importing, where users can be expect to want only one or two modules - to export a superset of a module, with some internals ( e.g. Foo, Foo.Internal)
link broken?
It's broken for me too. EDIT: It works now!
Yes, each type gets its own dictionary, but it's not always possible to build all dictionaries at compile time, because a single Haskell program can contain unboundedly many types! Here's an example: data Tree a = Bare a | Wrap (Tree (a,a)) deriving Show makeTree :: Integer -&gt; a -&gt; Tree a makeTree 0 a = Bare a makeTree n a = Wrap (makeTree (n-1) (a,a)) main = print (makeTree 5 ()) A value of type `Tree a` can optionally contain a value of type `Tree (a, a)`, which in turn can contain a value of type `Tree ((a, a), (a, a))`, and so on to arbitrary levels of nested pairs. You can pass in any integer (or even read it from standard input) and construct a tree with that number of levels. Each of the infinitely many types involved has its own implementation of the typeclass Show, which is responsible for converting to a human-readable string. The dictionaries are created and passed around at runtime, because things couldn't work otherwise. This idea kind of blew my mind when I first learned about it, but now it feels quite natural to me. The technical name for it is "polymorphic recursion". Note that `Tree a` is a type of complete binary trees, whose number of leaves is always a power of 2.
The link is broken.
Online demo: https://twitter.com/polikarn/status/690277732475768832
Is anyone else very excited for the future of mainstream programming? Everyday it seems like good type safe and functional practices make it into mainstream languages. And now with liquid types we can have a subset of dependent types in most languages!
...You've linked to the Github front page.
It just makes me want to laugh so hard remembering the discussion about the [supremacy of dynamic typing the other day](http://games.greggman.com/game/dynamic-typing-static-typing/)...
&lt;3 Thank you! The more the merrier :)
Link worked once, abstract sounded fascinating. Video did not play. Refreshed only to get error page. Still have not gotten original page.
I purchased. It looks interesting. I'll try and get through it. Lean pub said 95% complete, but no indication of what is still not finished, unless I missed it. Please finish it though. Last Haskell book I bought from someone on Leanpub (or similar service, I can't remember) said they were going to constantly update, but never did.
Page can use localStorage as an alternative. There's no real need to spam servers with our section preferences.
There are actually multiple kinds of "search" to consider. First is "go to module" that opens module index and fuzzyfilters by module name. On a module page I would really like "go to definition" to navigate its synopsis. And then there's global "go to anything" that filter global package index. As for shortcut scheme, simple 1-letter commands are nice. Just don't bind to arrows w/o modifiers, it is annoying as %^&amp;$!
Thanks for the replies! My question was more about actual rpc, and not just messaging frameworks. I finally settled for [msgpack-rpc](http://hackage.haskell.org/package/msgpack-rpc), since it seems to be adequately active and [msgpack-aeson](http://hackage.haskell.org/package/msgpack-aeson). [This](https://github.com/pkamenarsky/users-remote/blob/master/src/Web/Users/Remote/Server.hs#L105) is how it looks in actual code.
An Introduction to Functional Programming Through Lambda Calculus a beginner level book; helped me when i started looking into FP &amp; Lambda calculus. http://www.amazon.com/Introduction-Functional-Programming-Calculus-Mathematics/dp/0486478831
Aw thanks! Yeah, it's actually finished. The only issue is we want to make sure to get at least 50 people reading it to give us adjustment / correction / feedback on it before we put it to 100%. Yesterday, for example, we adjusted one of the chapters by fleshing it out with another few pages of content to make things clearer upon another re-reading. As we publish the free sections of the book we're looking at it afresh to make sure there are no problems. We should probably write that on the page, I guess :) Or maybe we should put that it's finished? Not too sure here. Thanks very much for both reading and supporting. Our preference would be to put someone on these kinds of books full time if possible. Time will tell, I guess! Hopefully you'll recommend it too if you love it.
Do post results when you've got progress!
Laziness allows us to say things like: take 5 ( map (+5) [1..] ) ... and only have the `(+5)` be applied to the first five elements of the infinite list when those elements are required (a.k.a "forced"). Here is a great discussion on the value of laziness: https://www.reddit.com/r/haskell/comments/36s0ii/how_do_we_all_feel_about_laziness/ I personally concur most with this comment: https://www.reddit.com/r/haskell/comments/36s0ii/how_do_we_all_feel_about_laziness/crgs866 In the end, I believe that the ability to tag data structures as data or codata will make the differentiation between laziness and strictness a moot point in most cases, as the compiler will be able to write the conversion code for us. See https://www.reddit.com/r/haskell/comments/36s0ii/how_do_we_all_feel_about_laziness/crgo37v and its comments.
[Tyxml](http://ocsigen.org/tyxml/manual/) is considered useful by a non negligible bunch of people. It uses features of OCaml that are hard to emulate in Haskell, though. Basically, it encodes a state machine in polymorphic variants to ensure that nesting of html constructor is properly done (no &lt;a&gt; in &lt;a&gt;, for example). (It also very heavy on functors, but you can probably use typeclasses for a similar effect) I would be curious how you would do this thing in haskell. What you said about having heterogeneous list with a type constraint is just the beginning of the solution.
That's very cool looking. Thanks for pointing out a working example (even though I can barely read ocaml).
I'm looking for a more theoretical foundation. I went and picked up Hindleys book from a friend today, so I'm glad I made a reasonable choice. 
Exactly. You give a spec by providing refined types (just like in LiquidHaskell) and the automatic synthesizer finds a program (function), which satisfies the spec. The generation of the program is guided by types and because the type checking of a candidate can pin point the problem locally, the generator knows which subexpressions to fix. 
As an example of what you are proposing, you can look at the `default` package and the orphan instance packages that accompany it (`data-default-instances-containers` is one of them). There are mixed feelings about orphan instances. People try to avoid them in general-purpose libraries (the `default` ecosystem is an exception to this trend). And people are usually more accepting of an orphan instance in an application (this happens to me when using `persistent` sometimes). The most obvious way to avoid the need for orphan instances is to explicitly [pass a dictionary around](http://www.haskellforall.com/2012/05/scrap-your-type-classes.html) instead of defining a typeclass. This is often sufficient, but there are some niceties you lose with this approach. If you provided the typeclass in question, you could get some good feedback on whether or not it's a good typeclass.
The instance *can* be in the module - that's where it is right now, and that's why the smelly imports are there right now. Having a newtype wrapper would just mean I was putting the newtype wrapper into the framework rather than the type I want. Sure, that means there's a type constructor and data constructor name to export from the other module as well as the instance. But it also means I have to do lots of wrapping and unwrapping for interop. between the framework and other code that doesn't know about that framework. To put it one way, imagine you couldn't have `Show Int` but instead had to have `Show (Wrapped Int)` because a fluke of alternative-universe history meant the `Show` "framework" wasn't part of the standard library. 
Newtype wrappers are not always possible (in a reasonable way). 
Oh, I thought you meant that the framework had a typeclass and you didn't want to add an instance for it. So where is the typeclass? Can't that be made to have the instance of the base type?
they should be ultimately done in GHC, but it is good to have one or two other implementations when the design space is open.
IME Haskell performance is greatly overstated. Getting good performance in Haskell is far far more difficult than in c. Haskell does have decent performance, but it won't come near 5% of well written c without a huge amount of effort and very ugly code.
Isn't avoiding having to walk the entire structure to wrap something a large part of `coerce`'s purpose? Or are there other unmentioned considerations that render it impractical?
The whole course looks great. I don't see a license anywhere. Is there any chance you could release under CC BY-SA so that this content can be adapted (such as combined with content from the Wikibook) etc?
I actually didn't know about `coerce`. Thanks!
Yes, I was trying to get constant memory usage without using Data.Text, but I could not. However, I did achieve constant memory usage with the Data.Text modules, and I was able to keep my `Monoid` instance: import Control.Applicative import Data.Char import Data.Monoid import Data.Foldable import qualified Data.Text as Strict import qualified Data.Text.Lazy.IO as Lazy import qualified Data.Text.Lazy as Lazy data Count = Count{ letterCount :: !Int, numberCount :: !Int } deriving (Eq, Ord, Show) instance Monoid Count where mempty = Count 0 0 mappend (Count a0 a1) (Count b0 b1) = Count (a0+b0) (a1+b1) step :: Char -&gt; Count step c = if isLetter c then Count 1 0 else if isNumber c then Count 0 1 else Count 0 0 main :: IO () main = foldMap (foldMap step . Strict.unpack) . Lazy.toChunks &lt;$&gt; Lazy.getContents &gt;&gt;= print Compiled with just `-O2`, I did not even need to use `-funbox-strict-fields`. My test program was: tar cf - ~/Videos | base64 | ./CountLettersNumbers 
There has been talk of exactly what you are suggesting: https://ghc.haskell.org/trac/ghc/wiki/StrictPragma
Lazyness allows the optimizer to re-arrange the ordering of how various parts of the program are evaluated. You may have a function evaluation that executes code in procedures A and B and folds the results. Suppose you program evaluates the A and B functions in this order: A B A A B B A B. If your program is lazy, then it doesn't matter if the evaluation order is rearranged to A A A A B B B B. Perhaps if all the As are evaluated first, then all the Bs, doing so may allow for some kind of loop unrolling and inlining to make the program more efficient -- lazyness gives the optimizer the freedom to do this. But if evaluation is strict, then the code must always be evaluated in the order it arrives, which may prevent other optimizations from taking place.
&gt; except for the fact getting complex C code written in the first place is obviously much more work Yes, that is exactly what I mean when I say getting good performance from complex C code is difficult. I'm factoring in both the cost to implement even a first draft of the algorithm and the cost of deviating from the first approach to try improved algorithms.
Indeed, I would love to watch video recording of the lectures.
Can someone explain why I wouldn't just use a function of type f :: a -&gt; b -&gt; c -&gt; State -&gt; State ?
Well, pure terminating computations are safe to reorder in both strict and lazy languages. Are you saying that laziness gives more freedom to reorder potentially non-terminating computations? Doesn't that sometimes change the meaning of the code?
you mean like you manually thread the state value in and manually return it? you could do that if you want. the state monad is just a convenient way to manage that plumbing so you don't have to think about it much
I don't see any call to writeSave in your code, so I'm guessing you mean writeFile? It would be good to see the actual error message. And it would be good to see all the code - is it on github perhaps? Your code uses Haskell's ' lazy IO', which is notoriously tricky to get right. I don't actually see a problem with it but I'm often wrong about Haskell IO, and I'm not the only one. Have you considered using one of the streaming IO libraries? Or the functions that operate on strict Text?
Because themes are a matter of taste and the entire design of the theme system is precisely so we can add new ones without removing the ability to use older ones.
done
Oh I see. The `Type` you're mentioning in the family definition is an actual kind. Cool!
Any code which is described by a thesis but never actually written is perfect. (/s?)
I wonder why this page is not listed in lecture list https://cseweb.ucsd.edu/classes/wi13/cse230-a/lectures.html
The competition was [sCTF](http://compete.sctf.io/2015q2/) and specifically a problem that involved decompiling [this file](http://compete.sctf.io/2015q2/problemfiles/48/%CE%BB3). It turns out that decompiling a large file by hand can get boring fast, so I decided to make a computer do it for me.
It could be that readFile leaves the file open so that a later writeFile fails. Try the functions in System.IO that use handles, and explicitly close it yourself (or better yet, use withFile). Streaming libraries like pipes or conduit offer higher level solutions, but can be daunting if you're a beginner.
with [Boolean Blindness](https://existentialtype.wordpress.com/2011/03/15/boolean-blindness/) as its special form :)
If you sketch the project itself you could get more detailed advice...
Do you really need to link (almost?) _every_ question or answer you write on StackOverflow? Don't get me wrong, some of them are interesting, but it feels like you just want another [gold badge](http://stackoverflow.com/help/badges/262/publicist?userid=1172541), especially since this answer of yours does not contain any code at all.
Well...
Glad you like it! The material is all here: https://github.com/ucsd-pl/230-web/ The lectures are in `lectures/*.lhs` Its under an MIT license, am happy to change it if and as needed. 
Well as far as I know, even non-terminating code can be safely re-ordered if it is pure and non-strict. Suppose you were to have two very long running functions, one that terminates, and one that potentially does not terminate, for example factoring a large integer and hashing an integer repeatedly until it's lower 32-bits are all zero: main = do myRSAprivateKey &lt;- readFile "~/.ssh/id_rsa" &gt;&gt;= readIO :: Int4096 let hashLoop n = if n .&amp;. 0xFFFFFFFF == 0 then n else hashLoop (cryptoHash n) let facts = factor myRSAprivateKey x &lt;- randomIO :: IO Int4096 print (halfZero x - sum facts) The `hashLoop` function is not guaranteed to terminate and could loop forever, since the terminating condition depends on a cryptographically secure hash function which is not guaranteed ever to satisfy the condition that the lower 32 bits of the result all be zero. The `factor` function will terminate but it would take a very long time because it is operating on a very large number. Theoretically (not that any optimizer would ever actually do this), the fact that both of these functions are pure and non-strict, you could interleave computations of the `hashLoop` function with computations of `factor` by simulating multi-threading within a single thread. The low-level code may end up looking something like this in C: int main() { Int4096 n = random(); Int4096 private_key = read_private_key_from_file("~/.ssh/id_rsa"); struct Factor_StackFrame *st = malloc(sizeof(struct Factor_StackFrame)); struct Factor_Result *result = malloc(sizeof(struct Factor_Result)); init_Factor_StackFrame(stack, private_key); init_Factor_Result(result); while (n&amp;0xFFFFFFFF != 0 &amp;&amp; ! result-&gt;is_ready) { // This loop interleaves computations of the "hashLoop" and "factor" functions. n = crypto_hash(n); // &lt;-- Each of these functions single_iteration_of_factor(stack, result); // &lt;-- could be inlined here as well. } while (n&amp;0xFFFFFFFF != 0) { // if "factor" terminated first, continue with "hashLoop" until it is done n = crypto_hash(n); } while (! result-&gt;is_ready) { // if "hashLoop" terminated first, continue with "factor" until it is done single_iteration_of_factor(stack, result); } free_Factor_StackFrame(stack); Int4096_printf(Int4096_subtract(n, Int4096_sum(result-&gt;factors))); free_Factor_result(result); return 0; } This is a contrived example, but it shows how iterations of potentially non-terminating computations can have their evaluation order interleaved with other function evaluations as long as they are pure and non-strict. 
 print $ flip execState (0, 0) $ do let a = modify $ first (+ 1) let b = modify $ second (+ 1) a &gt;&gt; b &gt;&gt; a &gt;&gt; a &gt;&gt; b &gt;&gt; b &gt;&gt; a &gt;&gt; b The above state function reduces to a pure function: let a = (\ (x, y) -&gt; (x+1, y)) let b = (\ (x, y) -&gt; (x, y+1)) in b . a . b . b . a . a . b . a $ (0, 0) Since the functions `a` and `b` are both provably associative, it is safe to re-order their evaluation. b . b . b . b . a . a . a . a $ (0, 0) Of course, in this example, reordering evaluation may not provide any benefit at all, but the optimizer would have the freedom to do so.
I don't have GHC 8.0 yet, but from my understanding, even though `*` now has kind `*`, the kind of a type-level string is still `String`, not `*`. And those non-`*` kinds are only used for type indices, for example to say that in `Vect (S (S Z)) Int`, the index `S (S Z)` has kind `Nat`, while the index `Int` has kind `*`. And values must have types of kind `*`: you can say that `undefined` has type `Vect (S (S Z)) Int`, because `Vect (S (S Z)) Int` has kind `*`, but I don't think you can say that `undefined` has type `S (S Z)`, because `S (S Z)` does not have kind `*`. So I don't think it makes sense to have a value (`undefined` or otherwise) whose type is a type-level string. How about a value whose type is `Proxy s`, where `s` is a type-level string coinciding with the program's source code?
Okay, noted.
Am I missing something, or is this example of the pairs function incorrect? From the article: pairs xs ys = do x &lt;- xs y &lt;- ys return (x, y) &gt; pairs (Just 42) (Nothing) Just 42 Shouldn't that actually return `Nothing`? 
Using **Network.Socket** directly is defnitely the hard way because you have no control over the life time of resources like file descriptors. I have used the **Data.Conduit.Network**` stuff from the [conduit-extra](https://hackage.haskell.org/package/conduit-extra) package for TCP servers but that package also does [UDP](https://hackage.haskell.org/package/conduit-extra-1.1.9.2/docs/Data-Conduit-Network-UDP.html). Concurrency with Conduit is automatic. All you need to do is compile with `-threaded` to get the threaded RTS. The Warp web server is build on top of Conduit. 
http://hackage.haskell.org/package/webdriver
Sadly, the author of Adaptive, Magnus Carlsson, has passed away. 
Does this count? () its type is `()`
We lack infrastructure in Cabal to handle orphan instances, especially when those instances are being relocated. There's some ideas being discussed at [cabal#3061](https://github.com/haskell/cabal/issues/3061) trying to help the Cabal solver be aware of which package versions would provide conflicting instances.
Recently I found a PDF version of Categories and Computer Science online somewhere. It was reccommended to me by [this blog](http://graphicallinearalgebra.net). I haven't read it yet, so I don't know if it's any good.
http://blog.jenkster.com/2015/07/extending-esqueleto-for-type-safe-postgresql-queries.html talks about extending esqueleto to cover new things - I guess you could use this approach for what you require
Please be aware that `thyme` seems to have become moribund---I do not believe it builds against 7.10, for instance.
Just out of curiosity - why are people downvoting this as not constructive? It sounds like a cute exercise.
Thanks. This is another valuable option, especially given its relationship to Yesod's persistence (if my understanding is correct)
If I get it right, we only have to define a single defunctionalization symbol for each type family. That's nice (previously we needed one symbol for each partial application).
Hi, I'm the author of this post. This is essentially a brief overview of how GHC's heap profiling and ThreadScope can be used to track down memory leaks, or help identify performance bottlenecks. I'm hoping it might be useful for people in a similar situation as me who are trying to figure out where to start. It's all stuff I've been learning about in the last couple of months, and I'm still actively learning, so if anyone has any suggestions or feedback then please let me know :)
Awesome!
Nice! If I understand this correctly, this doesn't expose lazy IO from System.IO? What do you use instead? Also, I see you export Data.Time from the time package but hear that the Thyme package is preferred.
Yes, that is exactly right.
sure, that would be neat, but I think reasonably-documented packages can make it as clear to the human as non-orphans
This might get difficult since there are AFAIK no operations defined on type level strings (the `Symbol` type) other than comparison. In particular there is no concatenation. To make a quine you would either need a compiler plugin or perhaps template haskell. Another alternative is to give a Gödel number representing the source program, since we do have type level `(+)` and `(*)`.
Just one more question: is there a trick to getting Xen running inside VMWare/VirtualBox as described in the instructions? I've used "Other/Unknown (64-bit)" as the OS type and there are no guest additions installed; but booting a Xen kernel results in the disk devices not being found. This is true on Fedora 22 and 23, on VMWare and VirtualBox running on Fedora and Ubuntu. I've tried the Vagrant images and a manual setup. Any advice would be appreciated - thank you!
There's no `String` kind, and the closest we've got (`Symbol`) doesn't support any computation besides equality checking.
We're happy to hire from within the EU - although we're not sure if relocation or remote work is the right approach at such an early stage of the company. If you'd like to discuss more please drop me an email on mandeep at stackhut dot com.
I see `Rebase.Prelude` exposes a lot of strict types. What do you think about exporting lazy types (`ByteString`, `Text`, probably `Map`, etc) from `Rebase.Prelude.Lazy`? That way one can import the module qualified to bring everything into scope: import qualified Rebase.Prelude.Lazy as Lazy test :: Lazy.ByteString -&gt; Lazy.Text test = ... 
/u/ekmett gave a talk at Boston Haskell a few months ago (https://www.youtube.com/watch?v=DyPzPeOPgUE) about a library he is/was working on in this space (https://github.com/ekmett/propagators). I'm not sure if it's applicable though, because as I understand it it doesn't support values that change, only values that become more defined.
Those are two big advantages. Additionally there's the safety: you can't accidentally pass an old state to a later computation, which is very probably if you're manually threading a lot of state (coming up with names is hard, and `s`, `s'`, `s''` are easy to confuse). But there's nothing magical going on, if that's what you mean.
Yes, the rule of thumb there is to give preference to strict data-structures in case of conflicts. On the one hand your suggestion sounds interesting. On the other, it would add yet another purpose to the package and it already has several others. You see, I want the package to have a clear focus, so that the users can easily understand what's going on and so that the maintenance tasks are clear as well. Maybe, let's add it to the issue tracker as a "backlog" entry with intent of further discussion and possibly reviewing this later, when the package gets a user-base?
I believe there is a consensus in the community that lazy IO is an antipattern. Instead of it you can use the plentiful streaming libraries. However there was no original intent of being opinionated about it in this package. I simply didn't export plenty of modules because I intended for them to be added later, while the project evolves. Concerning the "time" library, it might be a controversial case, I agree. The library definitely suffers from the low quality, however I don't see "thyme" as an ultimate replacement to it either. Actually I don't think a decent replacement exists yet. So the strategy I've chosen is to orient on "time" until a decent replacement gets picked up by the community, because there's no doubt that "time" is the majority choice so far. Maybe let's add this to the issue tracker for the user-base to later catch up and express opinions?
"more progressive alternative" doesn't mean much to me in this context. I'd suggest "based on the [emerging] modern [community] consensus" or something like that. (I observe you have a Russian email address, so I'm offering this feedback about the words. Up to you what you do with it, of course.)
&gt; Do you see `streaming` as the leading candidate currently? I believe this is exactly a controversial case. There is a very high competition in that area. Hence choosing any particular library would leave a major part of the potential audience dissatisfied, which is why it's best to just not include any. The general policy I intend with this package works like this: there's virtually no competition for "containers" and everyone uses it, same applies to "contravariant", "semigroups" and etc., hence they make perfect candidates. There's actually a load of such packages, and, certainly, they have not yet been included in "rebase" so far, but are expected to be later on. I just don't have the time to do everything at once.
Makes perfect sense.
As someone who hasn't worked with dates &amp; times much in Haskell, has anyone written about the issues with time anywhere. Is it just a problem with the code's quality, or fundamental issues with the API?
[removed]
[removed]
Are people importing profunctor, bifunctor, and contravariant that often? I've never used any of those.
cool. I've been learning opaleye.
So amazonka-rds does not help with querying? The RDS is a MySQL DB. Is there any library for querying RDS MySQL databases? And am I right in assuming that the way it would work is I would give the RDS URL and authentication details to the library and will be able to run queries that way?
As far as I know, no. You query RDS databases just as if they were the same underlying database not hosted by RDS. The RDS API just controls starting, stopping, and provisioning the instances. Yes, you would give the hostname/IP address and authentication details to the library as if it were any MySQL database. I've never used MySQL from Haskell but if I had to I would look at mysql-simple or HDBC-mysql. It may be that there's another one that's better, I just did a minute of looking.
I would throw in comonad, free and kan-extensions for good measure! comonad is already a dependency of profunctors.
I use bifunctor a lot, it's great for mapping difficult-to-reach corners of tuples and sum types. I also implement instances for my own types.
"by /u/nikita-volkov" should trump anything in the title text. ;)
I use contravariant and sometimes bifunctor. I almost never use profunctor.
I have done exactly this and confirm that "should be" can be replaced by "is".
isn't that injective? 
RDS is running the same exact RDBMS server you could be running yourself, only exposing it through its DNS name. Anything you would use to interact with a regular RDBMS server can be used to interact with RDS. I'd recommend using Persistent, it's quite easy to start with.
[removed]
[removed]
Thanks for explaining the second thing, I thought GHC might convert between types somehow. When it comes to the `m` instance, I don't see where I've defined such a general instance and how to make this code work :)
You need to increase your daily dose of Opaleye then :)
Why are comonad and kan-extensions useful to add? I have never seen them used in any projects.
I might be able to give you some informed advice, as I have been using Opaleye since it's very early days and Postgres for a very long time. What do you mean when you say, "using many of its features to its limits"?
&gt; haskell is backwards and not modern because it isn't object oriented No, but I think Haskell's throwing away the baby with the bathwater. It's not a coincidence why people reject Haskell and like OOP languages, people like them because they have features that totally rock and solve problems, and these features are at the surface level, while Haskell's advantages are at a deeper level and the surface level is a total mess. Eg. in many OOP languages you can improve code clarity with named arguments: writeArchive(name: "hello.zip", format: "zip", contents: ["foo.txt", "bar.txt"], compression: HIGH); There are early returns and loops with breaks, so you don't have to [add indentation every time there's a decision to be made](https://www.reddit.com/r/haskell/comments/3xfoet/haskell_basics_how_to_loop/cy4hqmz). --- &gt; Yes you can, it is called a type class. class MapContainer m k v where insert :: k -&gt; v -&gt; m k v -&gt; m k v class SetContainer s a where insert :: a -&gt; s a -&gt; s a Can't use them both together in the same namespace. In OOP languages you don't have to import anything to use an object's methods, you just have to have a reference to an object itself. For example, Haskell's record problem wouldn't have existed if it had proper support for methods. --- &gt; Postfix function application is completely irrelevant to that though. Indeed it isn't, it could be eg. like this: `#upper (#strip (#stripSuffix "foo" name)`, no problem with that. `OverloadedRecordFields` will make it possible by defining `HasField` instances.
&gt; No it is not. It is not what you want. In most popular modern languages you don't have to enable an extension and add a line of import just to use non-linked-list strings comfortably. Also you aren't presented with a choice: either make a separate module per record or add prefixes to fields so that they don't clash. 
Consider it done :] 
there's a jupyter notebook for haskell on os x: http://www.kronosnotebook.com/haskell the standard package manager for haskell is cabal (some people now use stack to manage environments instead), and there is a repl that comes with haskell installs named "ghci". there are links to many guides on haskell tooling on the language homepage: https://www.haskell.org/documentation
Can you give me an example? 
Yes, exactly! And while I can't guarantee it always will, I verified that in the cases I checked it does in fact boil off to exactly the same machine code as the primitively typed version, and there's no *good* reason it wouldn't.
I'm gonna piggy back off this and ask about 3D openGL tools as well. I have found [HGamer3D](http://hackage.haskell.org/package/HGamer3D), which seems to be a toolset to join all the required libraries for a full 3D engine into one place. Then, I know of [GPipe](https://wiki.haskell.org/GPipe), which seems to be a neat way to make 3D apps in a pure functional way. But it seems to be very low level. It does handle input though. There also seem to be [ogre3d](https://hackage.haskell.org/package/hogre-0.1.5) bindings, and they're not overly complicated. Are they sufficient for making a game though? It's inactive too. The last lib I've looked at is [lambdacube](http://hackage.haskell.org/package/lambdacube-core), which now uses OpenGL rather than ogre3D under the hood. It's rather new. Does it have sufficient features though? How stable is the API? There's also OpenGL bindings mentioned above, but I think that's a bit too low-level. Those are the graphics libs I looked at. I'm not sure what most of them really do, and I would appreciate any help in comparing them, or finding more competing libraries.
Please make a PR
A large part of why `gl` has so few users is because `OpenGL` had a 10 year head-start. I wrote `gl` because at the time, `OpenGL` and `OpenGLRaw` only supported OpenGL 3.2, didn't lift anything into `MonadIO`, making it harder to use, and there wasn't a story for how to get a shared `StateVar` abstraction across the `sdl2` package and `OpenGL`. The `OpenGL` package frustrated me enough that I just decided to build something that I could build on top of rather than try to hack around it. `gl` instead generated code from the XML specification by Khronos, and made heavy use of pattern synonyms, enabling more idiomatic OpenGL support for all versions of OpenGL, in exchange for dumping support for old versions of GHC. It actually attempted to supply documentation, as opposed to the completely undocumented `OpenGLRaw` or randomly re-capitalized names in `OpenGL`. It had to change the namespace because of limitations in the compiler on Windows at the time. I shipped a `foreignvar` package, which since replaced the API for `StateVar` to get a common imperative state variable abstraction for use in `sdl2`. The net result of this was that we went from supporting fairly ancient versions of OpenGL to having support for every version and every extension supplied by every vendor overnight. At the time it didn't seem like we were going to get any appreciable changes into the `OpenGL` or `OpenGLRaw` packages, and something had to change. Since then, I've worked with Sven to enable `OpenGLRaw` to incorporated most if not all of the changes from `gl` back into the "mainstream" `OpenGLRaw` package. They adopted the `StateVar` code from my `foreign-var` / `quine` projects, and adopted the generator approach. The 'minimal' differences you see between the head versions of each of the packages are the result of that convergence since `OpenGLRaw` switched to the same style of generator as `gl`! Mind you, there are still some places where we differ in opinion, but at this point, the differences are fairly minor for most users, and mostly involve needing to use a bunch of extra `fromIntegral`s in `OpenGLRaw` code, and the fact that `gl` supplies OpenGL ES support, and that `gl` uses shorter module names to allow building documentation with older versions of GHC/cabal on windows. Arguably `OpenGLRaw` has a better installation story at the moment, since with `gl` we run the generator on each build, while `OpenGLRaw` does so before uploading to hackage, which means that users of `OpenGLRaw` don't need `hxt` and a bunch of obscure dependencies like users of `gl` have to today.
I think it never was ogre3d bindings per se, more like a library compatible with ogre3d's material formats and stuff. Then they changed it to be a GPipe-style EDSL to describe graphical pipelines but with the intention to encode more invariants in the type system. Finally they realized that Haskell's type system was not very adequate for this, so they wrote their own language instead. LamdaCube has [an online WebGL editor](http://lambdacube3d.com/editor.html) with a few samples.
I really like [graphics-drawingcombinators](https://hackage.haskell.org/package/graphics-drawingcombinators). It is very high-level and principled and uses opengl under the hood. It does not open any windows or handle any input. It just renders.
The gloss library expects a Picture value for rendering, which makes it really easy to use for simple games. You just define a function :: GameState -&gt; (optional IO) Picture and pass that to the loop which is handled by gloss. Now, outside of probably having to write my own main loop, what would be the workflow for simple 3D rendering in gl, OpenGLRaw or OpenGL? I'm assuming I'd have to have a function render :: GLState -&gt; GameState -&gt; IO GLState, where GLState is a supporting data structure for OpenGL (loaded resources or so?). I haven't worked with OpenGL directly before, but I have worked with Ogre3D in c++ and with Gloss, so I'm probably rather new to the workflow: How do I get things on the screen easily? I've also looked at [this tutorial](https://wiki.haskell.org/OpenGLTutorial1) just now, and it seems to be straightforward enough, but also quite far away from what Ogre3D could offer. Any suggestions for game devs from you?
typical haskell project doc section: "DOC SECTION NUFF' SAID" 
For the last point, lately I've been using hasktags. It works great and doesn't require anything.
[hpqtypes](https://hackage.haskell.org/package/hpqtypes) provides high-level interface and has e.g. full support for composite types.
Perhaps it uses the axiom of choice. ;)
(Since I couldn't manage to use a proper plotting library, I just write to `$PROJECTROOT/plot.png`, which is kept open in an image viewer that refreshes the display when the image file is updated. Hacky, but it works.) I believe I have unwittingly reimplemented a lot of "standard" code here (the functions that essentially pass the `StdGen` around and collect the intermediate values, especially), and also haven't used things like `&gt;&gt;=` (because the only monad I understand is `Maybe` :/). I think cleaning up this code will be a nice way to understand how the State monad works. Can anyone point out a few mistakes / stupid things in the code?
The issue lamefun is having doesn't seem to be with haskell not being OOP imo. Outside of syntactic concerns (which were never really brought up by him), the only things OOP brings to the equation really are Subtyping (which I haven't missed, and lamefun hasn't mentioned) and a lot of issues stemming from mutability. While mutability is nice in simple cases, it's exactly one of the reasons I'm using haskell. parallelizing couldn't be simpler.
What I have settled on at this point is to use the Haskell Platform, and Stack. That way I can have both developer tools and stack. The downside is that you still have to setup sandboxes to allow things like Leksah to build your project for you, but in the context of emacs/vim, this shouldn't really matter too much.
Thus is pretty cool. I can write Haskell and trick my coworkers into using it this way, probably, yes?
State is: newtype State s a = State { runState :: s -&gt; (a, s) } -- in a pretend GHCi session: Prelude&gt; :t State State :: (s -&gt; (a, s)) -&gt; State s a Prelude&gt; :t runState runState :: State s a -&gt; s -&gt; (a, s) State is defined by two basic functions: `get` and `put`. `get` returns the current state value, and `put` replaces the current state. Here they are: get :: State s s get = State (\currentState -&gt; (currentState, currentState)) put :: s -&gt; State s () put newState = State (\_ -&gt; ((), newState)) So when we're making `State` functions, we can start with the basic primitives: the `State` constructor, and a lambda with a single variable that is the current state. Then we directly return the tuple of new state and result. This is generally less pleasant than using the `get` and `put` functions (and `modify :: (s -&gt; s) -&gt; State s ()`) There's a _lot_ of `f :: StdGen -&gt; (a, StdGen)` in your code. So let's rewrite a function to be `State StdGen`. `mutate` is the simplest one I saw, so we'll change it. First, we transform the type signature: mutate :: Tour -&gt; StdGen -&gt; (Tour, StdGen) We want `StdGen` to be the last parameter. That makes it easier to wrap the function in `State`. So now we want to change the type signature to: mutate :: Tour -&gt; State StdGen Tour mutate (Tour tour) = ... So we're passing a `Tour` directly. Now we need the `State` constructor to return a type of `State`. Then we'll use a lambda to introduce the `StdGen`. mutate (Tour tour) = State $ \gen -&gt; let l = length tour (ix1, gen') = randomR (0,l-1) gen (ix2, gen'') = randomR (0,l-1) gen' in (Tour $ swap ix1 ix2 tour, gen'') And the transformation is complete! This is all you _need_ to do to make this function use the `State` monad. Let's wrap `randomR` in the `State` monad so we can take advantage of some `do` notation instead of manually passing the business around. randomState :: Int -&gt; Int -&gt; State StdGen Int randomState lower upper = State (\gen -&gt; randomR (lower, upper) gen) Now we can use that in `mutate` instead of manually passing the `gen` around. This ensures that we don't misplace it. First, we'll use `runState` to change it as little as possible: mutate :: Tour -&gt; State StdGen Tour mutate (Tour tour) = State $ \gen -&gt; let l = length tour (ix1, gen') = runState (randomState 0 (l-1)) gen (ix2, gen'') = runState (randomState 0 (l-1)) gen' in (Tour $ swap ix1 ix2 tour, gen'') So when we want to run a function in the `State` monad, we can do so by using the `runState` function and providing an initial state. Now, let's use `do` notation: mutate (Tour tour) = do let l = length tour ix1 &lt;- randomState 0 (l - 1) ix2 &lt;- randomState 0 (l - 1) return (Tour (swap ix1 ix2 tour)) I found it a lot easier to work with `State` and `Reader` after implementing them in the NICTA course. What would `randomState` look like if we used `do` notation instead of the manual building blocks? randomState lower upper = do gen &lt;- get let (res, gen') = randomR (lower, upper) gen put gen' return res
Unless there's a computational element to your LA course, it may be optimal to learn LA on it's own instead of trying to do both simultaneously.
This is the first I've heard of [`streaming`](https://hackage.haskell.org/package/streaming) and it looks really cool! EDIT: This library is wonderful. &gt; If you want to tempt fate and replicate the irrationality of Control.Monad.replicateM, then sure, you can define the hermaphroditic chimera accumulate . Streaming.Prelude.replicateM :: Int -&gt; m a -&gt; m (Stream (Of a) Identity ()) &gt; which is what we find in our diseased base libraries. It just gets better and better &gt; we might define getContents thus getContents = sequence $ repeat getChar &gt; There it is again! The very devil! My god this is more entertaining than Saturday night television &gt; That is, if I make the type synonym type String m r = Stream (Of Char) m r &gt; I get, for example: "getLine" :: String m () getLine :: String IO () "getLine" &gt;&gt; getLine :: String IO () splitAt 20 $ "getLine" &gt;&gt; getLine :: String IO (String IO ()) length $ "getLine" &gt;&gt; getLine :: IO Int &gt; and can dispense with half the advice they will give you on #haskell. I think this is the first Haskell package that is a work of both comedic and technical genius.
Somewhat related, but does anyone know if it is possible to use relative monads to address this problem? I was thinking like a relative monad on the functor that forgets whatever extra structure you have imposed, or something along those lines.
Interesting data NM :: (∗ → Constraint) → (∗ → ∗) → ∗ → ∗ where Return :: a → NM c t a Bind :: c x ⇒ t x → (x → NM c t a) → NM c t a This is just the same as the `Freer` monad, except with constraints. Still though, I don't think that data type can implement `Monad` in its current form, because of the constraint.
If you can get it into the build...
Based on [this](https://hackage.haskell.org/package/base-4.8.2.0/docs/Control-Monad.html), I don't see a Functor law that this violates.
Makes me wonder why we need to tell ghc to use LambdaCase... cause if hlint can recognize, so can ghc
Ah I see. I knew there was something wrong with Set as a Functor =P Regardless, I think the point about constrainable monads is still valid
The last point doesn't hold up much to grep-fu: $ cat &gt; x.txt x :: A y :: A yar :: A xor :: A x :: a -&gt; b $ egrep '^x( |$)' x.txt x :: A x 
The point about making Set a monad is also probably valid. If you have a 'broken' Eq, you have a 'broken' monad law.
sclv—thanks! I needed a restricted monad in SML yesterday, but since we don't have type classes, I had a feeling that it would be cleaner to implement it as a relative monad.
 x -- Here is my defintion of x :: a -&gt; a
&gt; If you have a set containing {1, 2, 3} and call fmap (const 2) on it you will get the set {2} which does not have the same shape as the original, thus breaking the functor laws. This isn't a counterexample to the functor laws: -- Second functor law, f = const 2 fmap (const 2) (fmap g {1, 2, 3}) = fmap (const 2) {g 1, g 2, g 3} = {2} fmap (const 2 . g) {1, 2, 3}) = fmap (const 2) {const 2 (g 1), (const 2 (g 2), const 2 (g 3)} = {2} You can check other examples with the other laws, everything will check out. But more generally, [your informal "shape preservation" argument doesn't work](http://stackoverflow.com/a/19192745/1094403). /u/Darwin226 has the right answer. The problem is that the `Eq` class allows for situations where `a == b` but `f a` and `f b` are not the same value. One example would be to have a `CaseInsensitive` newtype with custom `Eq` and `Ord` instances that treat upper and lower case versions of a character equivalently: newtype CaseInsensitive = CaseInsensitive { caseSensitive :: String } instance Eq CaseInsensitive where ... instance Ord CaseInsensitive where ... Then we can break the functor laws this way: fmap (caseSensitive . CaseInsensitive) (Set.fromList ["hello", "HELLO"]) /= fmap caseSensitive (fmap CaseInsensitive (Set.fromList ["hello", "HELLO"])) 
good point. RecordWildCards can reduce the boilerplate: module Script where data Script { x :: String, y :: String } script = do x &lt;- readFile "x" y &lt;- readFile "y" return Script{..} in ghci: &gt;&gt;&gt; :set -XRecordWildCards &gt;&gt;&gt; import Script &gt;&gt;&gt; Script{..} &lt;- script &gt;&gt;&gt; print x "..." but you still have to add the annotated accessor (in addition to the binding), so still a pain. 
For your case, I'm guessing you maybe would be interested in "Example 2" in the "Monads need not be endofunctors" paper or section 2 of this: http://arxiv.org/abs/1107.5252
You can give a nullary constraint
Well yes and no, the fact you are tied to Hask is _why_ your fmap would fail for a Hask endofunctor on Set. If instead you take your category to be of something like ordered objects with order-preserving maps between them, then you get a proper monad. And you can take, as discussed elsewhere on this thread, a related _relative monad_ in Hask, by using a kan extension along the embedding of that category in full Hask.
Haskell is very mathematical. Reading the source of [vector-space](https://hackage.haskell.org/package/vector-space) (found [here](https://hackage.haskell.org/package/vector-space-0.10.3/src/)) gives a set of linear algebra equations.
I think that's what https://hub.docker.com/r/fpco/stack-ghcjs-build/ is for, although the latest tag appears to be `lts-3.0`.
This is tricky. It is not about building it with `stack`. It is more about using stack, to get package versions and build `ghcjs-boot` and then build it with `stack`. The tradition here is to relay ghcjs team and hope the current git repositories point ti the same versions you need. And it is like hoping that `nightly` or `lts` follow `git` repos. My goal is to be able to do some `isomorphic`* SPA but have exactly the same versions of everything for both server and the client. *sorry for the term; but this one is used by quite few people.
Yea but it kinda defeats the purpose if you're just not using the constraint in order to make it a monad
You see, we have /r/haskelltil
&gt; One way to think about this is: the I think part of your comment got cut off.
Yikes. I guess I wrote the paragraphs in parallel and didn't force a thunk. Thanks!
It's not worth the extra complexity and there is a standard way to transform something that requires constraints into something that does not. See the [set-monad](https://hackage.haskell.org/package/set-monad) package for an example of how to do this.
Given that the interest for this is bigger than I expected, I've just implemented the last remaining change I always wanted to make to this library: You now no longer need to wrap functions into the identity monad to export them, closed type families for the win. More details at https://mail.haskell.org/pipermail/haskell-cafe/2016-January/122848.html
That's easy, just write and compile the functions at home, send yourself the object file via email, rename it to `test-specs.txt` and check it into your repository. (To my knowledge `dlopen()` doens't insist on an `.so` extension).
I am sorry, I didn't really elaborate on the conversion from SNat to Int. So let me do it here: If you look in the code you find following: instance Show (SNat a) where show n = show $ doShow n where doShow :: SNat a -&gt; Int doShow SZ = 0 doShow (SS n) = 1 + (doShow n) When using the Haskell REPL (read evaluate print loop) it uses that show function to make a string to print. If I should have stayed true to the article, I should have printed somethinh similar to: (SS (... (SS (SZ)))), but the decimal number are easier to read. Did this answer the question?
Compare with the [99 bottles of beer](http://www.99-bottles-of-beer.net) site. There are [four entries for Haskell](http://www.99-bottles-of-beer.net/language-haskell-1070.html), but none at the type level. Perhaps it's time to add one.
Mystery solved ! Thank you for the answer
But that subreddit has only 607 readers. There's no way that OP can get another gold badge there. ;)
Could you please give an example? I know very well what those things are, and I have never felt a need for them in practical programming use. I thought they they existed only to show how cool it is that the Haskell type system is expressive enough to be able to represent them.. What am I missing? Same for contravariant, for people who actually use that. Profunctor we already know - you need them if you use Opaleye. :)
For the last point: why not just run a local hoogle instance instead of grepping for types?
What about it?
Is there any loss by doing that? I was doing a lot of contrained classes for a a side project, this seems a cleaner option. 
Why isn't it called `haskell-msgpack`? I know that it is more general than that (not limited only to MsgPack) but having a name consistent across all languages would help discoverability a lot. EDIT: I found two packages [messagepack](http://hackage.haskell.org/package/messagepack) and [messagepack-rpc](http://hackage.haskell.org/package/messagepack-rpc), based on Cereal.
Very nice update to his original post on Haskell and Vim. I would recommend using vim-plug[0] as the bundle manager instead of Pathogen. With vim-plug you can do stuff like `Plug 'tpope/vim-fireplace', { 'for': 'clojure' }` to only load that plugin when opening a clojure file. Also, for the step installing vimproc you can add post-update hooks (since it needs to run make) as such `Plug 'Shougo/vimproc.vim', { 'do': 'make' }`. This means that everything can be handled by the plugin manager, instead of having to manually update via the command line. Finally, for the super lazy, there's also the nice one-line-install haskell vim setup via https://github.com/begriffs/haskell-vim-now. [0] https://github.com/junegunn/vim-plug
I would probably just blame it on a bad merge or rebase.
&gt; Finally, for the super lazy, there's also the nice one-line-install haskell vim setup via https://github.com/begriffs/haskell-vim-now. &gt; It looks nice, but overriding my current Vim configuration is a deal-breaker for any plugin.
I think that example is technically corecursion. One thing you have to get used to in Haskell is the prefix "co" being thrown on lots of words. The difference here is that recursion always has a base case in which it stops. Corecursion doesn't necessarily have a base case. It just needs to productively generate codata. I did say to watch out for that prefix. The rabbit hole here is deep. I won't try to overload you with everything. I'm just making a note that this really is different from what you're used to. It doesn't just feel that way. The underlying theory is different too. 
Would absolutely recommend UltiSnips over vim-snipmate. It is more stable, has more features, and is maintained more frequently.
The goal of GHC is to be a compiler for *exactly* Haskell: it should compile valid Haskell programs, and reject invalid ones. For this reason, we do not enable "innocent" extensions by default, although they don't break compatibility. It's true that GHC has ventured away from strictly being a Haskell compiler, e.g. by altering the Prelude (`Foldable`/`Traversable`), introducing `Applicative =&gt; Monad`, and removing the `Eq`/`Show` constraints on `Num`. But those changes are foreshadowing future language revisions and cannot be "innocently", so we made exceptions there. That said, I'm strongly for including the extensions I mentioned - `LambdaCase`, `TupleSections`, `BangPatterns`, `MultiWayIf` - into the next standard.
&gt; It [...] doesn't require anything. It requires Hasktags. :-)
Yeah, I mean. It also probably requires a computer and a screen, but those requirements are kind of orthogonal to the code.
Not sure it that's already covered by the other plugins, but some kind of indentation-defined text object is useful in Haskell: https://github.com/michaeljsmith/vim-indent-object
I'd suggest to replace vim with [neovim](https://neovim.io), syntastic with [neomake](https://github.com/benekastah/neomake) and pathogen with [vim-plug](https://github.com/junegunn/vim-plug). Neomake within neovim allows all these nice linters to be run asynchronously in the background without blocking the ui. That makes a huge difference especially in larger projects where it takes some moments to run ghcmod etc. Vim-plug also makes use of neovims async capabilities and installs/updates your plugins concurrently. The cool thing is that all three suggested changes are almost drop-in replacements.
This isn't tested, but I was advocating something like trying these: executeJS [] "window.scrollBy(0,250)" :: SessionId executeJS [] "window.scrollBy(0,250)" :: ProfilePref If those don't work, in ghci you can type: :info executeJS and it should show you the "7 others" instances referred to. 
&gt; Recursion means a function calling itself Somewhat more generally, a recursive value, which may or may not be a function, is self referential.
it would be useful to write down what are the different stages for installing and building with ghcjs, and what dependencies are picked up when and where. AFAIU the library picked up during boot time are then hardwired later on, but not really sure..
Thanks for sharing! I read your solution to day 6. Do you have the full code posted anywhere? You chose to use the array library, but most suggestions I've seen steer programmers away from array and toward vector or repa. Did you choose array out of convenience, or some other reason? Have you tested the performance of your solution? Thanks for any answers you have!
Interesting. But I don't see how working around it like this is better than just having a proper constrained monad class
This post has almost nothing Haskell-specific. Nerdtree and Ctrlp for example have nothing to do with Haskell development. For me, this is pretty much all I have: au FileType haskell setlocal makeprg=ghc\ -e\ :q\ % au FileType haskell setlocal errorformat= \%-G, \%-Z\ %#, \%W%f:%l:%c:\ Warning:\ %m, \%E%f:%l:%c:\ %m, \%E%&gt;%f:%l:%c:, \%+C\ \ %#%m, \%W%&gt;%f:%l:%c:, \%+C\ \ %#%tarning:\ %m, This allows running `:make` to check the syntax without any dependencies.
The primary benefit is you can uses existing support for the Monad class, including combinators like sequence, and syntactical sugar, like do-notation. The key idea is that the constraints are on the monadic primitives, not the monad itself.
&gt; Do you have the full code posted anywhere? I haven't kept a copy of the code, but I could easily recreate it from the snippets in my post if that would be useful to you. &gt; You chose to use the array library, but most suggestions I've seen steer programmers away from array and toward vector or repa. Did you choose array out of convenience, or some other reason? I simply happen to be more familiar with the array API. I did not know that vector and repa were favoured over arrays, do you know what is the reason? &gt; Have you tested the performance of your solution? In my original implementation, I used pure arrays and I updated them using the `(//)` operator. That turned out to be way too slow, which is why I'm using `STArray` in my post instead.
The classic and still most common approach is the excellent [postgresql-simple](https://hackage.haskell.org) library. It advertises itself as a "mid-level" library. It offers direct type-safe access to PostgreSQL features, and direct marshaling between Haskell types and PostgreSQL fields. Its use under the hood of libpq is exposed just enough that you can easily integrate lower-level uses of libpq and postgresql-simple use in the same application. Since esqueleto was mentioned, [persistent](https://hackage.haskell.org) should also. Esqueleto is designed to work together with persistent and add general join queries to persistent's limited but fully type-safe query EDSL. Persistent occupies the following spot in the high-level design space: You specify schema using a persistent's simple schema DSL (*not* EDSL). Persistent uses your schema specification to generate database tables at one end, Haskell types at the other end, and marshaling code in the middle, that implement the schema. This operation is performed at compile time using TH so the entire system is verified as completely type-safe by GHC. There is also an auto-migration facility that automatically handles many (but not all) cases where you change the schema. Persistent also provides a mid-upper level interface where you write type-safe SQL queries instead of using the query EDSL. Persistent is built on top of postgresql-simple, and again exposes its use of it. So you can integrate code at all four levels - libpq, postgresql-simple, persistent "raw SQL", and persistent+esqueleto - in the same application.
How do you use the Elevence.Prelude? Import it in every source file at the top with "import Prelude()"? I just converted my source file into this, ended up with something like 'base-noprelude' which seems to kind of work.
The reasoning is similar to the warning triggered when you discard results of an operation in a `do` block without explicitly saying that you want to do that. This was fairly recently made more strict in GHC, not less strict, because it was found that subtle hard-to-find bugs would often be introduced through this hole in the type system.
I think that the comment by /u/yitz is pretty spot on. If you dislike having to add `return ()` to the end of a `do` block, you can try using `void` (from `Control.Monad`) instead: -- option 1 (with returning unit) foo = do thing x otherThing y return () -- option 2 (with void) foo = void $ do thing x otherThing y I prefer the second construction in my own code.
Thanks for the awesome info! Need to learn more about this :)
True! Thanks! I did not think there are recursive data types as well. Need to jump on other types of stuff that's recursive. 
Or enable the `NoImplicitPrelude` extension and then import your custom prelude in all files. 
OP is not wrong. In mathematics, any definition that refers to the term being defined is called "recursive". The idea of "corecursion", and a corresponding narrowed definition of "recursion" to contrast it, are concepts that were only introduced within the past few decades, and are little known outside of the FP community. That said - sure, it's fine to introduce the idea of corecursion in this context. And the "co" prefix in general. :) As an aside: there is someone who used to be a well-known member of the Perl community under the name "pumpkin". That was a reference to an inside joke in that community having to do with a "pumpkin patch". When he crossed over to the Haskell community, he changed his nickname to "copumpkin".
Interesting, and regarding the URLs, probably cleaner than the approach I used awhile back - patching Hakyll itself. I used it in [my blog](http://www.aloni.org) after cherry-picking from [pbrisbin](https://github.com/pbrisbin). [Available here](https://github.com/da-x/hakyll/commits/master)
Sure thing! Will post it on github. Trying to keep online ids compartmentalized, so if anyone else is interested feel free to PM me. Eventually maybe I should contact haskell-mode maintainers to see if they would put something in. I think the reason it's not in haskell mode is just a cultural thing. Traditionally most Haskell devs are not coming from a repl driven development background (like python or R) where they see the value in that quick/interactive feedback loop style of workflow. That's changing as the language gains in popularity though.
Only Haskell source code is *actual* equations. In python or C++, you have a series of imperative steps involving assignments to come to the answer. In Haskell, you have equations where the two sides of that equation are equivalent. Both Haskell and other languages have `=` signs, but only in one are you declaring equations. See http://www.haskellforall.com/2013/12/equational-reasoning.html, it is very enlightening. In particular, in the LA package, you will actually find equations *defining* what functions most exist in relation to a Vector Space, Additive Group, etc... Most linear algebra packages simply crunch a bunch of numbers instead of dealing in abstractions.
Technically, you could use Shake to implement this, since a build system is simply a way of incrementally computing build products (which could be values!): http://shakebuild.com/ esp with some of the new persistent cache changes coming down the pike. https://github.com/ndmitchell/shake/pull/389
So I'm in a similar boat to you, and have so far discovered the following: 0. Haskell does not have good tools for anything GUI related. 1. The SDL2 bindings for Haskell are probably your best bet for making anything not-text-based. 1. a. [Abandon hope](https://github.com/haskell-game/sdl2/issues/41) [all ye Windows users](https://ghc.haskell.org/trac/ghc/ticket/3242#comment:47) [who enter here.](http://imgur.com/VHWnR4b) 2. You should probably just program in OpenGL, or go full text based. Edit: if you do decide to try SDL2, and you're on windows, see this: https://www.reddit.com/r/haskellgamedev/comments/3kvm7z/building_and_installing_sdl2_200_sdl2image/
Why not `gloss`? Chess or Connect 4 should both be fairly easily made in it. I've also had minimal trouble with it on Windows.
Looks a lot better than the alternatives. I think my reasons for not trying it earlier were concerns about gloss's user input handling.
I'll give this a shot, just have to make sure I read into it because at a glance it looks slightly intimidating to me. I only know what LYAH taught me, so nothing about cabal builds and importing modules, etc.
Sure. I don't see why it wouldn't be.
Personally I'd rather have a function `withAttrs :: Html -&gt; [Attribute] -&gt; Html`. do div_ a_ `withAttrs` [ href_ "http://foo.bar.com" , id_ "foo-bar-link" ] I'm not sure if this is possible or sensible in that representation of Html, but it's the sort of interface I'd like.
Yes, that would be possible. It would basically be using `sequenceA` with the monad approach.
This is only tangentially related, but I really don't like having to compile code when I edit HTML. For this layer of the app, I just prefer convenience over safety. I haven't ever really been bitten by failing to correctly provide data to the html templates.
Indeed, I have already cabal installed.
I picked up `gloss` a few months ago and have really loved using it. Its super simple, and I love how it allows you to keep your functions pure. Its really easy to start learning it. I'm not sure how advanced you want to get, but I think it was a great starting point for me, as I had just gone though LYAH too
Well sure, you want a linear algebra package whose job is to crunch numbers to do so efficiently. That isn't the one I referred the OP to though. The one I referred the OP to is rather abstract, in the same way a linear algebra course would be. Also, yes, not only Haskell is equations. I should have been more specific.
https://github.com/ekmett/quine/blob/master/Main.hs might give some semblance of what a main loop might look like for you. I put the project down before it got past the 'spike solution' stage though, so it could stand to be better factored, and it is missing most of what I'd consider a real 'game loop', but it does loop over frames, etc.
Yes, it could. However, the world seems roughly equally split between folks who prefer the more restrictive type signature we have today and folks who would like a generalized version. (I personally fall into the latter camp, as in general, I find even things like unused do bind warnings more of a hindrance than a help, but I accept that such is a minority view.) Given such an active split, it isn't likely to change.
It's interesting to see that this article recommends both `ghc-mod` and `syntastic`. I was under the impression that the latter was [dropping support](https://github.com/scrooloose/syntastic/issues/1576) for the former, meaning that you'd either want to use something like `hdevtools` instead of `ghc-mod` or use `ghcmod-vim` instead of `syntastic`. I'd love to find out I'm wrong about this though--`ghc-mod` has a lot of nice features, but so does `syntastic` so it's hard to have to choose between them!
Take a look at blaze-html, which takes a fourth approach: do div ! class_ "shiny" $ do -- child nodes go here I copied that approach with my `tamper` library.
I'm afraid it's not that simple. For one, if my configuration is under version control too, I'll get conflicts / nightmares. I have to check if there are conflicts using my recursive mappings, too. The keybindings aren't declared local so there will be more conflicts / nightmares. Who knows what else I've forgotten in my already huge config - why should I have to review all of it just to install a few plugins? It's much more sensible to package it as a collection of plugins, and follow common guidelines for plugins, rather than taking over the whole configuration.
[Hamlet](https://hackage.haskell.org/package/shakespeare) is built on top of blaze, and it uses a monad. 
&gt; Would you consider adding a TemplateHaskell wrapper around this to support normal HTML syntax inside Haskell code? (ala JSX). You mean ala [hamlet](https://hackage.haskell.org/package/shakespeare)?
Well, you very much aren't the intended audience then, I'm afraid. The goal of the HVN project is to provide a somewhat opinionated complete setup, that is ready to use immediately (the install script also installs ghc-mod etc), and it does this in a way that the user can still config it after. It's for people that ask for an editor for haskell, but have no intentions of spending several hours getting their vim config *just* right - they can do that later on, instead of having to learn vim and haskell in parallel. Disclaimer: I'm not responsible for HVN, I just use it as the basis for my own quite custom vim setup. EDIT: Regarding version control, you could simple use gitignore to ignore all files in the HVN folder, except for the configs I mentioned (they are ignored in HVN's gitignore), so that is a non-problem. Recursive bindings could potentially conflict, but the amount HVN brings in is not that many.
That's a little sad, because I really would like to try the setup too _without_ having to spend an hour tweaking configs. ;-)
Yes, the main reason for what I did is to be able to hard-wire my own packages' versions. eg. aeson or base; currently the scripts only take the clean resolver's versions without getting any local packages. As for booting, there is: https://github.com/ghcjs/ghcjs/blob/master/lib/etc/boot.yaml which say when and which package is used. 
It seems that you can gain a bit by filtering for empty lines *before* going into `anagrams`. Also I found that the code has complexities that don't seem to improve performance (in particular, this is my anagrams function that performs essentially the same): anagrams :: [ByteString] -&gt; [[ByteString]] anagrams = filter ( (&gt;1) . length ) . map dedupe . Map.elems . Map.fromListWith (++) . map mappify' where mappify' orig = (key, [(wkey, orig)]) where !toks = tokenise orig !wkey = List.sort toks !key = ByteString.sort $ ByteString.concat toks 
Me too. My URLs are all dateless e.g. http://chrisdone.com/posts/haskell-repl There's the date at the bottom of the page near the copyright, but I felt like having the date in the URL made pages seem, well, dated. And transient. Some are, but many aren't. And I just made an nginx rule to interpret the files under `/posts/` as HTML.
Look for parts that can be parallelized. Can't you parellelize ‘anagrams‘ ?
 filter (not . null) might be faster still
Just looking at `neomake` the first time, it just seems to be an asynchronous variant of the vim internal `:make`. `ghcmod-vim` is the Haskell specific backend called by `:make`. So you would still be using `ghcmod-vim` independent of `make` or `neomake`. 
Thank you very much for notising :-) I will fix that!
This is how it's done [in Haste](http://haste-lang.org/docs/haddock/0.5.4/Haste-DOM.html#v:with). It's worked pretty well so far.
Nope, because singleton entries must be discarded too!
Thanks, that provides some perspective, though I haven't had time yet to go through it in full detail. I'm still curious about a kind of minimal example. I haven't worked with OpenGL directly yet, only through the proxy of, say Gloss or OGRE. And I liked that quite a bit, since it abstracted over things like resource loading and rendering quite a bit. What I'm looking for is a library that does at least some of that for me. I don't think if I have to call render() for every triangle that that's gonna end well, you know? Assuming I want to have my laziness catered to like OGRE did, how much work would be involved in things like resource loading (assuming a export from blender to any supported format), rendering, lighting, moving objects and the like? Or would you recommend another library over gl if I'm so lazy? ^Maybe ^I ^should ^just ^read ^an ^OpenGL ^tutorial ^first...
Simon Peyton Jones has great [advice on how to give a talk](http://research.microsoft.com/en-us/um/people/simonpj/papers/giving-a-talk/giving-a-talk.htm), and his talks are really good. Personally, I often give presentations at our local [Haskell meetup](http://haskellers-montreal.com/), and as I prepare the slides I often realize that I need to explain this and that prerequisite before I can talk about my main subject, which either causes my presentation to become much longer than I originally planned, or if the duration is fixed, it means I have much less time to cover the main subject and so I have to cover it in a very shallow fashion. So my advice is: pick a very small subject, cover it in depth if you can, but think of your audience. Finally, if you need a really concrete suggestion, my go-to intro talk for an audience of imperative programmers is my [Combinator Libraries presentation](https://www.youtube.com/watch?v=85NwzB156Rg).
I think lens and FRP are bad choices if your audience has little FP experience. QuickCheck is a nice library with a high wow factor even for people without much FP experience.
`zipWith :: (*) [1, 2, 3] [2..] -- &gt; [2, 4, 6]` is wrong. It's `zipWith (*) [1, 2, 3] [2..] --&gt; [2,6,12]` 
I agree with /u/gelisam that you probably want to go deeper into one subject, rather than barely dip into several. ---- Since I'm currently writing a piece on parser combinators for beginners, that's probably what I'd be likely to give a presentation about if asked right now. I'd structure it like this: 1. Take a few minutes to go over the Haskell syntax, 2. Show various ways of parsing something simple (splitting/indexing strings, regexes and then parser combinators), to establish why we want them, 3. Teach parser combinators from the simplest parser ("this parses a vowel") to something slightly more complicated, like the output of a command-line tool. Even if they don't know Haskell, by choosing which syntax and coding style you use wisely they should be able to feel like they can actually follow along\*, and it should hopefully get them interested in parser combinators, which is a good thing! ---- * If your audience is of the low-level programmer kind, they might be more interested in **[the inline-c library](http://two-wrongs.com/using-withptr-from-inline-c-in-haskell)**, or, even better, **[how laziness works](http://two-wrongs.com/how-laziness-works)**. * If they are web people, you *can* dip into **[web scraping with lenses](http://two-wrongs.com/web-scraping-with-lenses)**. The important thing here, I think, is to keep the lens stuff cursory. Use it, and highlight which parts of it are cool (traversals are majestic!) but don't get bogged down with implementation details. * If they are interested in the craft of programming more than actually making stuff, you may want to speak about **[why controlled side effects are useful](http://two-wrongs.com/the-case-for-controlled-side-effects)**. What's important here, I think, is getting in several real-world examples of where rampant side effects have either created bugs (ideally) or made it hard to refactor code. This can be made very interactive, with asking the audience whether a refactoring is safe, or if there's a bug in the code. ---- \* That's one of the great things about parser combinators with `do` notation. I've had several friends who are diametrically opposed to Haskell read Parsec parser, and nod in agreement before being able to tell me exactly what it does.
I wanted to post something clever about showing P = NP is your first step but I am not sure if that applies here or not. Edit: [this video is very good if you want a refresher on P vs NP.](https://www.youtube.com/watch?v=YX40hbAHx3s)
Well, it's either that, the traveling salesman problem or the halting problem. It's always one of those three.
Try msys2. It comes with a package manager so you can just install what you need and point cabal at it.
Can't post any code, right now, as I'm on the road. Try this: For each of 26 letters (alphabet, or a better ordering) (Within each group, initially the whole file) Group lines by frequency of that letter Disqualify groups with less than 2 members Each time you refine, you can remove the occurrences of the letter from the lines. That would require you to keep track of line-number references to the original file, in order to print the result.
How can I get the command-line hoogle client to query only packages from a specific Stackage LTS version? I currently use a custom search engine in Chrome which works well, but I would still like to be able to run queries from `ghci`.
&gt; I am about to give a presentation which topic is functional programming in Haskell. Its length shall be 1 hour, and targets programmers with imperative programming experience. Which would you rather do: * convince them that FP ideas are useful and something they can (and should) start using at work, even if they're not using Haskell. or * convince them that Haskell is an interesting and powerful language that they should consider learning. If you'd rather do the second, then, as /u/gelisam suggested, combinator parsing libraries are great. If you'd rather do the first, then quickcheck is great. In particular, [Testing the Hard Stuff and Staying Sane](http://www.infoq.com/presentations/automated-testing) has some great material on using quickcheck to test imperative APIs and discover minimal failing examples for hard-to-find bugs. Additionally, quickcheck has spawned many clones in other languages.
Are refinement types the same as liquid types? And just how much inference is possible with them? If I have an annotated program, and remove an annotation, can that ever cause it to fail? 
http://lpaste.net/151455 Speed untested.
`l - 1` is evil.
Cool! :-)
Nice! Do you think it would make sense to publish your alternative WriterT implementation as a package? Edit: grammar
# Nailing down what we expect IO to do and not do - and why I'm writing a book, I'd like to get this nailed down and to get it right. If anyone on here that's familiar with the various ways in which IO/State#/realWorld# work in GHC and you have time to reply, anything at all would be welcome. Any pointers, links, references, details, anecdotes, or faint memories of GHC bugs will be greatly appreciated! Getting this written up (possibly for addition to Michael Snoyman's wiki article?) would make me, and I imagine others, a lot happier with trying to understand how the different bits and bobs fit together. I will be dumping my notes as I don't want to get linked to stuff that can be googled because I've already lost 10-15 hours to just that in the past 3-4 days. Digging it up in the compiler is hard because compiler behavior that influences how IO actions are treated don't necessarily have "IO" or "realWorld" mentioned in the relevant parts of the compiler, optimizations, etc. What I'm hoping for is answers on what specifically preserves the listed properties we want from IO in the compiler, prims, or structure of how we write IO actions. What we expect IO to do: - Disable sharing of results, even when it's not eta-abstracted and is evaluated multiple times by the same name. ie, getCurrentTime :: IO UTCTime should get evaluated more than once. - Not reorder sequential IO actions, such as in a do-block. Called "linearity" below - Not duplicate the effects of IO actions. Effects shouldn't be spuriously duplicated during optimization passes. - Effects should not be discarded separately of the value returned by an IO action, merged, or elided. # Sharing A friend suggested that perhaps one-shot semantics via the state hack for State# in the IO type is responsible for disabling sharing, I don't believe so, but here are my notes. &gt;-fno-state-hack &gt;Turn off the "state hack" whereby any lambda with a State# token as argument is considered to be single-entry, hence it is considered OK to inline things inside it. This can improve performance of IO and ST monad code, but it runs the risk of reducing sharing. &gt;A one shot lambda &gt;State hack, makes the lambda over State# assume it's one-shot universally by default. &gt;one-shot/state hack is an anti-inlining heuristic, suggesting that inlining is costly. Also I found this on Trac, does anyone know the answer to this? Is the summary above accurate? &gt;Can the IO state hack be avoided if oneShot is used in the right places in library code, e.g. in IO’s definition of &gt;&gt;=? This seems related how the state token works, for differentiating which IO action is which and how many times an IO action should run, when it should run, etc. From the prims: &gt;data State# s &gt;State# is the primitive, unlifted type of states. It has one type parameter, thus State# RealWorld, or State# s, where s is a type variable. The only purpose of the type parameter is to keep different state threads separate. It is represented by nothing at all. &gt;data RealWorld &gt;RealWorld is deeply magical. It is primitive, but it is not unlifted (hence ptrArg). We never manipulate values of type RealWorld; it's only used in the type system, to parameterise State#. # Linearity Is this from the nesting of lambdas? It doesn't seem like that's enough based on the various examples using State/State# in GHC Trac bug tickets. The RealWorld token seems to be what's driving this but precisely how that works hasn't been easy to find. # Discarding, not inlining effects I believe these are addressed by has_side_effects in the prim ops. I could very well be wrong. can_fail has_side_effects Discard NO NO Float in YES YES Float out NO NO Duplicate YES NO * Duplication. You cannot duplicate a has_side_effect primop. You might wonder how this can occur given the state token threading, but just look at Control.Monad.ST.Lazy.Imp.strictToLazy! We get something like this p = case readMutVar# s v of (# s', r #) -&gt; (S# s', r) s' = case p of (s', r) -&gt; s' r = case p of (s', r) -&gt; r I believe duplication addresses inlining IO actions more generally but I could be wrong. Here's a note I found regarding elision/merging: * Use the compiler flag @-fno-cse@ to prevent common sub-expression elimination being performed on the module, which might combine two side effects that were meant to be separate. A good example is using multiple global variables (like @test@ in the example below). Any help or pointers for nailing down and documenting this would be greatly appreciated. Also if there's a more detailed explanation of what behavior is expected out of each unsafe function, that would help as well. There are bits and pieces I've been able to aggregate from the GHC trac tickets. References used (not exhaustive): - Referential Transparency; Haskell Wiki https://wiki.haskell.org/Referential_transparency - IO Inside; Haskell Wiki https://wiki.haskell.org/IO_inside - Unraveling the mystery of the IO Monad; Edward Z. Yang http://blog.ezyang.com/2011/05/unraveling-the-mystery-of-the-io-monad/ - Evaluation order and state tokens; Michael Snoyman https://wiki.haskell.org/Evaluation_order_and_state_tokens - Haskell GHC Illustrated; Takenobu Tani - Tackling the Awkward Squad; Simon Peyton Jones http://research.microsoft.com/en-us/um/people/simonpj/papers/marktoberdorf/mark.pdf - Note [IO hack in the demand analyser]; GHC source code - Monadic I/O in Haskell 1.3; Andrew D. Gordon and Kevin Hammond - Haskell Report 1.2 http://haskell.cs.yale.edu/wp-content/uploads/2011/01/haskell-report-1.2.pdf Any pointers on how State# (or magic?!) preserves these properties would be greatly appreciated. Please don't tell me not to worry about it, I'm _curious_ and I'd like to better understand how the compiler works anyway.
Would it work with stack? Can't imagine going back to cabal-install...
Shortest haskell program, that exhibits its fp elegance over other languages.
If "compare a b" evaluates to GT, then which is greater, a or b?
Can someone explain *listen* from the Writer monad?
I like this one: fibs = 0 : 1 : zipWith (+) fibs (tail fibs) Recursion, higher order functions, infinite list, concise
I guess the mnemonic is "what symbol do I replace `compare` by so that a `compare` b is true"? If the symbol is `&gt;` then the compare results in `GT`, etc..
[removed]
Where do I go for learning resources after understanding the basics and things like Monads. Stuff just seems to go off the rails whenever I look at code posted on this subreddit. 
Every time I want to use a data structure in Haskell, I find several and it usually requires a lot of time + trial and error to identify the recommended/reasonable/commonly supported ones. So what are the standard haskell datastructure libraries for Set, Dictionaries, Trees, Queues, Stacks and Graphs. And are there any plans for a standard haskell library at least for the simpler/common data structures?
Is there anything you can do with the information that the function you're calling might not terminate?
For Sets and Maps the containers package is the de facto standard. For Graphs I'm thinking fgl, but I'm not sure. Queues probably depend on what you're looking for, but a Sequence from the containers package might just be good enough. I don't know about trees. As for stacks. Well. A list is a stack. That's as standard as you get.
I've been learning some about modeling effects in Haskell with typeclasses. is there a standard nomenclature for this? Right now I'm naming them things like `MonadEnv` for things that modify the environment and `MonadInterpreter` for god-functions, but is there a more idiomatic naming convention? I've seen things like `HasEnv` in kmett's code, that's why I'm asking.
There are many good YouTube-Talks about Haskell-related things out there. That's where i learned a lot. Look out for people like "Simon Peyton Jones" or "Edward Kmett". Even if you don't get the things they are talking about - something always sticks and you can re-watch them later to find more things you missed the first time :)
Question regarding profiling Haskell code. Imagine you have long running process (which might run forever) with about 300 modules (so you don't really know where the issue is) and you notice that after some time the amount of allocated memory is way too high. Compiling with profiling flags and running it with -prof results in a way slowed down version of your running process (as it times and logs everything) and it would take ages to reach that point where the problem is. How would you approach such a problem? I know I can enable profiling only for selected modules but having that many of them I first need to identify which module it is. And the problem might be spread among multiple modules. Also, would such an idea be of any interest: (if it is possible) to add an option to GHC to start gathering profiling info after some command (imagine somewhere in your code you put 'enableProf') so that before this command is reached we do not collect the data (therefore speeding up the process of reaching the problematic spot).
I'd just like to say that it's not really a pain to work on windows. The problems only arise when you use packages that bind to C libraries that are not included with GHC. It's far from impossible to work with in those cases, but it isn't as trivial as "apt-get install".
I often use the Hackage [reverse dependencies](http://packdeps.haskellers.com/reverse) list to get a feeling here. For instance, search for `containers` there.
&gt; -Strengths and weaknesses library wise? For example I heard that haskell has bad GUI support. [State of the Haskell Ecosystem](https://github.com/Gabriel439/post-rfc/blob/master/sotu.md) edit: oh no I responded to the wrong comment :(
There are actually pre-cached binaries for each library on the nix build servers. You run a command called `cabal2nix` to create a `.nix` file containing the project dependencies. Then, you can create a build/shell environment using just those exact dependencies. Check out the following link to see how to use Haskell with nix: http://nixos.org/nixpkgs/manual/#users-guide-to-the-haskell-infrastructure There is even a section on how to use stack with nix.
&gt; Disable sharing of results, even when it's not eta-abstracted and is evaluated multiple times by the same name. ie, getCurrentTime :: IO UTCTime should get evaluated more than once. Is that actually the case? getCurrentTime is internally a state transformer, which is a function, but the function itself wouldn't be evaluated more than once, right? &gt; Not reorder sequential IO actions, such as in a do-block. Called "linearity" below This is communicated just by the data dependency IO actions appear to have on the RealWorld token. There's no special magic here, AFAIK, except for the RealWorld token itself.
This is very neat! Thanks for sharing
The Writer monad allows you to record stuff as you go along. The `listen` function lets you peek at what has been recorded so far. More specifically, it lets you do one more action - which may or may not record something - and then gives you both the value of your action plus what has been recorded by that action, in a tuple. EDIT: Sorry, I was wrong, and /u/rampion is correct. `listen` does *not* give you everything recorded so far; it only gives you what is recorded by the specific action that you run inside `listen`. Here is a test that demostrates that: Prelude Control.Monad.Trans.Writer&gt; runWriter $ do {tell [1]; (_, x) &lt;- listen $ tell [2]; tell [3]; return x} ([2],[1,2,3]) 
A Partial constraint means that the function is definitely partial, but the absence of one doesn't mean anything. You can still define, eg, oops :: forall a b. a -&gt; b oops x = oops x
Thanks, that's really helpful!
Microsoft has been one of the strongest Haskell supporters, so it makes sense that there's decent Windows support. Honestly, I find it a bit easier to install Haskell on Windows, I can just download an installer for each version, instead of having to use the special PPA on Ubuntu.
The Writer monad aggregates a log alongside a return value: (a,w) &gt;&gt;= (\a -&gt; let {-...-} in (b, w')) = (b, w &lt;&gt; w') `listen` lets you peek at the log produced by a computation: listen (a,w) = ((a,w), w)
I think the idea is for it to be similar to Rust's `unsafe` mechanism. It stops you from calling (some) partial functions by accident, and forces you to explicitly opt in to partiality (again, only for some partial functions), so that it's easier to find the source of the error when you use partial functions and it does go wrong. If you're writing a function that uses some other function which has a Partial constraint, it allows you to communicate who has responsibility for not passing arguments which could cause crashes, too. If you expect the caller to take care about what arguments they pass, then you propagate the Partial constraint. If you are satisfied that the way you're using it is always safe, regardless of what the caller does, then you can use `unsafePartial` to avoid propagating the constraint.
This is great, clearer, shorter and actually when I benchmarked it it came out at about 60ms faster too. I hope you dont mind me adding it to the selection :)
Can someone help me with installing the Haskell-Platform in Ubuntu 14.04? Doing a simple sudo-apt-get doesnt work as there are many seemingly unmet dependencies. I was able to install cabal and ghc by building from source the problem with building haskell-platform from source seems to be the $PATH_TO_GHC_BINDIST Any suggestions/workaround or just `support' is well appreciated. Thanks, 
&gt; What would be a prime example of a haskell program? You can write any program in Haskell that you can write in other languages. Any non-trivial program will exhibit the flavor of Haskell. It is quite different than the languages of your "holy triad". &gt; Strengths and weaknesses library wise? For example I heard that haskell has bad GUI support. Haskell does not have great support for old-style desktop GUI frameworks like WxWidgets, Gtk, WinForms, etc. Haskell does have excellent support for new-style browser-based GUIs, and for web UIs. Another point where Haskell is much weaker than your "holy triad" is for massively heavy enterprise standards, such as SOAP, DICOM, etc. But you'll probably only need those if you are working with large corporations. (Actually, my company is in that space. We get along just fine despite this limitation, and we find it still worth it to be using Haskell.) In most other areas, I think you'll find Haskell libraries not only satisfactory for use, but also enlightening. &gt; Is it really a pain to work on windows (or outright impossible)? Nope, it's fine. Most of the Haskell users at my company use Windows with no issues. There are a few unusual cases involving Unix-style non-Haskell libraries that sometimes require an extra step or two, but it is completely doable - ask our friendly community for help if you run into that. Also, to avoid network issues when downloading packages to install, make sure your computer doesn't have any trace of either of these two Windows apps: * The K9 Internet filter * The iDrive backup client &gt; Would a novice programmer like me benefit from learning haskell and FP Yes! A growing number of universities are using Haskell as the first language they teach beginning programmers. Some people feel that "Haskell first" gives them a big advantage when learning other languages, too. Keep in mind, though, that you don't want to waste time as a beginning programmer fiddling with tools and other side details instead of programming. So make sure to keep in close contact with our community, and we'll make sure you don't get stuck.
You've got the right idea. I don't know that a tagless encoding necessarily solves the expression problem, but a common way of looking at it is that you don't pay an interpreter overhead because the relevant parts of what would be your interpretation function are scattered across type class instances that GHC can inline at use sites. The downside there is that your interpretation function is scattered across type class instances :P (And, as you said, that you don't immediately have an AST you can poke and prod.)
[removed]
Good spot - this is because I have rearranged those functions since writing them :) Doesn't alas make much difference but every little helps!
Trying to wrap my mind around [Free](https://hackage.haskell.org/package/computational-algebra-0.3.0.0/docs/Control-Monad-Free.html)/[Free.Church](https://hackage.haskell.org/package/free-3.2/docs/Control-Monad-Free-Church.html)/[Prompt](https://hackage.haskell.org/package/MonadPrompt-1.0.0.5/docs/Control-Monad-Prompt.html)/[Operational](https://hackage.haskell.org/package/operational-0.2.3.2/docs/Control-Monad-Operational.html)/(Free ([Coyoneda](https://hackage.haskell.org/package/kan-extensions-5.0.1/docs/Data-Functor-Coyoneda.html) f))... and now [streaming](https://hackage.haskell.org/package/streaming): &gt; Stream can be used wherever FreeT is used. Would really love some guidance for how to think about these libs and when each is the best choice.
One nice thing to show is how we can make the type system in Haskell force the correctness of the business model and outlaw a whole class of bugs. This if often overlooked in conversations with programmers from weaker type systems like Java or C++. When they hear that Haskell is strongly typed, they think it is the same. There was a nice talk about this, but for F#, it could serve as inspiration. Here is [the link](https://skillsmatter.com/skillscasts/4971-domain-driven-design-with-scott-wlaschin), but it requires registration
But then why is `subtract` the other way around? ```1 `subtract` 2``` isn't 1-2, it's 2-1. With subtract, currying (not infix application) makes sense: `subtract 2 :: Num a =&gt; a -&gt; a` does what it says on the tin: take two from the next parameter. So `(subtract 2) 3 == 1`. 
No worries, I saw you! 
`subtract` is something else entirely :) It is defined so that `subtract 3` subtracts `3` from its argument. This reads nicely but is inconsistent with standard usage. Although Haskell's infix operations are very cool, what their creators didn't realise is that `frobnicate 3` sounds like an operator which frobnicates 3 at its argument. However, the standard infix usage 3 `frobnicate` arg looks like it frobnicates `arg` at `3`. This is inconsistent. Someone clever once proposed on /r/haskell that a `operator` b actually be sugar for operator b a I think this makes a lot of sense. Infix operations (or the outfix versions of usually-infix operations) would read better. But unfortunately we can never do it to Haskell :( It'll have to wait until Schoenfinkel. 
It seems Try Purescript does not check for exhaustivity yet.
I might have painted a pettier picture than it actually is. It's not realy a simple issue.
Try PureScript doesn't show any warnings at all right now.
Ack, thanks! I was too sloppy in my rush to get from pretty `do` to a bunch of banged lambdas.
You said it yourself: * Always add deriving Show to your types to begin with. You're going to need to do debugging later. * Use GHCi. It is a powerful debugging tool. With practice, you can improve your skills. * Logging and tracing, although sometimes a pain, is other times the simplest and easiest way to debug. Other things: * Write unit tests / quickcheck properties. * Use profiling for cases where that is appropriate.
&gt; getCurrentTime is internally a state transformer, which is a function, but the function itself wouldn't be evaluated more than once The *function* wouldn't, but the closure (which is the function applied to the `RealWorld` argument) would :)
While you're learning I'd suggest just sticking with `Free`. When you're familiar enough with using it then you can move on to other versions if you need some performance tradeoffs.
This is extremely helpful, thank you! &gt;Suffice it to say I have discovered a marvellous proof that GHC's transformations on STG preserve externally observable effects, but this Reddit comment is to small to contain it. Could you link it? Is this a joke?
The 2010 Haskell report is surprisingly vague on IO's semantics.
&gt;I don't think anything special happens here for IO. Can you give an example where sharing occurs outside of IO and a similar example inside of IO where sharing doesn't happen? I had an example in the original post with getCurrentTime. &gt;Nothing special about IO here. The same ordering can be seen inside of the state monad. That's less true than you'd think. If you look at the GHC trac tickets, ordinary, lifted, lazy State monad is used a contrary example of what `IO` should _not_ do. From the conversations I am having it seems like a lot of the semantics arise from IO having the strict state transformer under the hood.
Well, since two other people chimed in and pretty much pointed out the same thing as you - as well as some problematic apps - I don't think you stated anything wrong. I understand that it isn't linux tier easiness of use - But its still a far shot of the "totally unusable garbage" that I heard.
Effectful operations produce their effect when the resulting *tuple* is forced (and because it's an unlifted tuple this happens automatically). The state token need not be touched.
To be honest, the first little push towards Haskell stems from me being sick of OOP being shoved down my throat day in day out at every lecture and course. I mean, I'm still a beginner but the way Professors tout OOP as the remedy to all programming woes just reeks of snake oil. 
&gt; I had an example in the original post with getCurrentTime. Yes but what is the context that would introduce sharing? I know you're asking about getCurrentTime but what is the surrounding code that you think would introduce sharing? &gt; That's less true than you'd think. If you look at the GHC trac tickets, ordinary, lifted, lazy State monad is used a contrary example of what IO should not do. From the conversations I am having it seems like a lot of the semantics arise from IO having the strict state transformer under the hood. Yes, that's true. I almost wrote `strict` in my reply but thought it was implied. I should have clarified. 
Just download `stack` and everything should go smoothly from there. It's the easieast way to get started nowadays.
Look for posts and videos of similar languages. They often cater for more traditionally oriented programmers. F#'s talks are usually less dense than Haskell's because of the .NET stack, and so on. Same for Elm and Javascript people.
Here's what I find works best: First, make sure you have already installed a recent cabal binary and the right version of GHC as required by the HP version you want to install. One way is using the apt repository of /u/hvr_, as described on the [Haskell downloads page](https://www.haskell.org/downloads/linux). If you already have a cabal binary or you can copy one from somewhere (feel free to ask me), then you can just use the GHC binary tarball directly from the [GHC web site](https://www.haskell.org/ghc/download). **Note:** You do need the right version of GHC, but you do **not** need to use the version of cabal-install listed in your HP version. Use the most recent version you can get. Also, make sure you have the right versions of happy and alex on your PATH, as listed in your HP version. If you don't, you can already compile those using cabal and GHC without the rest of HP installed yet. I suggest doing it in a fresh sandbox. Once compiled, my favorite way to install the exes (and also the cabal exe) is using [GNU stow](https://www.gnu.org/software/stow/). Then, once you have cabal and GHC and happy and alex, get the HP source distribution, but do not install it. Instead, just get the list of packages and versions from it, delete the ones having to do with OpenGL and GLUT, and install them all with a single cabal command: sudo cabal install --global package-9.9.9 package-9.9.9 ... where "package-9.9.9 ..." is the list of packages and versions you got from the HP source distribution. Then go to your home dir and do this sudo chown -R you:you .ghc .cabal where "you" is your user name. EDIT: My suggestion to omit the packages related to OpenGL and GLUT is under the assumption that you are installing on a headless Ubuntu 14.04 server. There the OpenGL and GLUT libraries are nearly useless, and they require a boatload of X-Windows-related dependencies which you don't need or want. But if you are installing on an Ubuntu 14.04 desktop, then you probably do want OpenGL and GLUT.
Good question! Without knowing your setup, I will guess you have a Haskell value-level representation of your target language's types. Perhaps you have something like data Type = TyBool | TyInt | ... data Expr = Add Expr Expr | LessThan Expr Expr | ... You can then write something like arbitraryOfType :: Type -&gt; Gen AST arbitraryOfType TyBool -&gt; oneOf [ do x &lt;- arbitraryOfType TyInt y &lt;- arbitraryOfType TyInt return (LessThan x y) , ...] arbitraryOfType TyInt -&gt; oneOf [ do x &lt;- arbitraryOfType TyInt y &lt;- arbitraryOfType TyInt return (Plus x y) , ...] It seems like that would generate you random well-typed `Expr`s. 
There are works where people get an ordinary program in Haskell or ML as input and then infer the most refined types. They use some kind of symbolic interpretation of a program (a kind of static analysis) to collect constraints on the value. For example, if you have -- say here x :: Int if x &gt; 10 then ... -- here you know that x &gt; 10 else ... -- here x &lt;= 10 In each branch of the `if` you can assume a more refined type of x then just integer.
&gt;I should have clarified. It's alright, it's just that we're trying to nail this down so I'm trying to be precise.
~~I think you are mistakenly taking IO to be more special than it actually is. In particular, I don't see why strictness of the state monad would be necessary here; anything that can't be reordered does indeed use the real world.~~ Never mind, this is wrong.
I'll have a look at that, thanks!
&gt; in practice, how do people deal with such scenarios? HaXmL typed schema generation is pretty cool when it works. My first port of call would be to try to debug why it doesn't work in your case.
How is \x -&gt; (f x, g x) The same as f &amp;&amp;&amp; g Hlint keeps bugging me about making this change.
Yeah, it's basically like "you use IO to do stuff". If you tried to include something of the form "you use this to do stuff" in any other languages semantics, they would laugh at you.
If you implement it let me know how it works out :)
Have you actually run into issues with cabal, or is this just noise you've heard from others? Just sandbox your projects, set version bounds, respect them, and for production pin down the versions of things with a freeze file. Alternately, you can pin to a particular stackage release and then that effectively "freezes everything." There are a number of guides to package and dep management on the haskell homepage: https://www.haskell.org/documentation
Dev work in general can be a pain on windows, particularly with c/c++. package managers are really cool. I remember having to build boost manually because the visual studios compiler version was incompatible. I think MinGW solves a lot of these problems though, no?
FFI newbie here. I know the FFI can allow us to call faster C functions, but is it an overall win in performance in multicore environments? If an OS thread needs to be taken over, it seems like it hinders green threading. For example most database drivers seem to wrap a C livrary through the FFI. Would we see better overall throughput on multicore machines if we replaced the FFI calls with native Haskell? Or are the gains in C efficiency more than the losses of spawning OS threads.
Is this a counter example? I'm not sure what this is 
&gt; I'd suggest to replace vim with neovim[1], syntastic with neomake[2] and pathogen with vim-plug[3]. 1) Not gonna use neovim till it's more "complete". 2) How would I configure neomake to get similar behavior to syntastic as described in the blog post? 3) Way ahead of you. 4) Your use of endnote links when reddit supports them inline confuses me.
Well I Installed stack it doesn't seem to work after that - nor the straight sudo apt-get install haskell-platform. 
Write code! That'll bump you into many interesting problems. Ask people how to solve said problems... and there you go! Soon you're using conduit, lens, persistent, blaze, quickcheck, readp and stuff like any old Haskeller.
A huge reason to call out to C code is that it means you don't have to write the full library yourself, including bugs and all. If you can just call out to functions that already exist you save a lot of time. Especially considering [how easy it is these days...](http://two-wrongs.com/using-withptr-from-inline-c-in-haskell)
OK, sure, then you also have X installed, so OpenGL and GLUT are fine. What cabal version do you have? (`cabal --version`) It needs to be at least 1.18 to get started. Yes, you need happy and alex executables on your path. You can compile them as follows: 1. Create a new directory and cd into it (in an xterm or console window). 2. If you have not run `cabal update` recently, do it now. 3. Run these commands: cabal sandbox init cabal install alex-9.9.9 happy-9.9.9 where "9.9.9" is the version of alex and happy recommend by the HP you are installing. 4. When the compile completes, copy the newly compiled exes from `.cabal/sandbox` to /usr/local/bin. 5. Make sure they are working by running `alex --version` and `happy --version`.
&gt; Set, Dictionaries Ordered: Data.Set and Data.Map from containers Fast: Data.HashSet and Data.HashMap from unordered-containers (relies on Data.Hashable instances for your data types, from the hashable package) &gt; Trees Data.Tree from containers. &gt; Queues Not sure. &gt; Stacks A standard Haskell list? Cons to push and pattern match to pop things off. &gt; Graphs Data.Graph from containers if you want something simple. The fgl package for more complex needs. GHC also has its own internal graph implementation, as well as implementations of fast strings, pretty printing, and other bits. But depending on GHC internals outside of GHC or code working with the GHC API is not advised. &gt; And are there any plans for a standard haskell library at least for the simpler/common data structures? That's what the containers package is for. It covers a range of common structures, and if you need more complex or performant implementations you can look to other more specific packages.
Xmonad is a window manager written in Haskell.
I've been working on a client-server type application, where we want to send files from the client to the server (and back). We are using the Network library to connect to the server and any communication is done by using handles and the Data.ByteString library. So a client reads a file, which is then represented in memory as a ByteString, which is then encoded and finally it's send to the server using the handle. However, for some reason the file would not be received on the server-side, until the client shutsdown or another message is send to the server. In which case the last message would again not be received. Here's a simple implementation of the Client and Server: http://pastebin.com/F2BvJx2m http://pastebin.com/sM7Mn8uR For the Client you have to pass a filepath as an argument. Also you have to start the Server before the Client. After some long time debugging we were able to fix it by replacing Data.ByteString with Data.ByteString.Lazy: http://pastebin.com/5xqY2rNG http://pastebin.com/7A149zEC Now my question is why would using lazy bytestrings work and not strict bytestrings?
Haskell-mode will helpfully tell me `could not find module Foo; It is a member of the hidden package foo`. * *Question:* What can I do to automate adding `Foo` to my build? If I add `foo` to my `.cabal` file dependencies and run `stack build`I have to close and re-open emacs or turn off and turn on `haskell-mode` again, before Emacs sees the dependency. Most IDEs don't require this manual multi-step process to add imports. Is this automated already, and I just haven't found it yet? (If not, maybe this will motivate me to finally write some Emacs Lisp :) )
Here's an hypothesis: With the strict bytestring server, the call to **B.hGetContents h** won't return until the client closes the socket on the other side. But the strict bytestring client doesn't seem to close the socket: after writing the file to the socket, it waits by reading a line from stdin. With the lazy bytestring server, the call to **L.hGetContents h** behaves differently: it returns immediately, and the contents of the handle will be read lazily, as the bytestring is consumed by **putStrLn $ L.unpack $ decode fdata**. Therefore the printing on the lazy bytestring server can commence before the client closes the socket (thanks to lazy I/O). Anyway, I would shy away from lazy I/O and use a streaming library like conduit, pipes or iostreams instead.
Thanks for the answer. That does make a lot of sense to me. Also, I'll definitely look into the streaming library. I didn't realize there were libraries we could use for that.
By coincidence I thought I'd check out purescript today, having played with it a year ago. I had no idea I was trying something that was just released today. There's a lot of cool functionality. `pulp` made it easy to get a project started. There seems to be some good possibilities to integrate with nodejs modules in the browser with `pulp browserify`. A couple of minor criticisms to take with a grain of salt: * It seems like last year you could run psci and type `2+2` and get the expected answer; Now you get `Unknown value (+)` because you forgot to import the Prelude. This seems a little extreme. * I also feel like you used to be able to define `let add a b = a + b` but even after importing the Prelude so you have `+` functionality, this definition is thwarted by `No type class instance was found for Prelude.Semiring _0`. Now, strictly from an uncultured user's perspective, this is discouraging. I even know what's a semiring, but what's a `_0`? The message includes a link to a wiki which explains that type inference is on the back-burner for now. I see, so I'll just uh ... wut? Anyway, if I want to do arithmetic, there's plenty of ways. I want to build simple, functional web apps. Hopefully after a few initial hurdles I'll find that purescript helps with that.
&gt; Use GHCi. It is a powerful debugging tool. With practice, you can improve your skills. What are some useful GHCi commands? Are there any workflows you find yourself using a lot?
Weird. Subsingleton sounds like it would mean null. Or negatively sized, haha.
comment history 
This only works if the target language is total right?
The only thing I don't like about this is that it is too verbose. Why do you need the `withAttrs`, why not just pass a list?
&gt; Since the keys of the map are bytestrings I'd replace the use of Data.Map with unordered-containers:Data.HashMap. I was also surprised by what was happening here, but I modified the original file where `Map` was an alias for `Data.HashMap.Strict`. And yes, it is much faster than the ordered container in that case. &gt; Also note that rather than using map on lists, you can apply it to the map itself (i.e., we have the natural transformation map f . elems = elems . fmap f). Prolly wouldn't speed things up unless you use a parallel implementation of fmap on the data structure, but still worth mentioning. It was faster to do it the way I write, probably because there is some sort of fusion with the subsequent filter.
In that particular case, lists are either 1 or 2 elements long, so this didn't affect the performance and shortened the code. With longer lists I would probably have gone with (not . null . drop 1).
It is an example of where sharing occurs outside of IO.
No, why?
I wouldn't say it's noise. I'm a Haskell beginner but I've already experienced cabal hell multiple times. Switching over to stack eliminated that. 
&gt; You could also host capstone and the Haskell code in separate processes I think Capstone's more like a C library(framework) and I've a similar vision for the Haskell binding too: something which can be used by others to build more tools upon. I guess that negates the possibility of using processes. Also, the IPC method sounds like a roundabout approach to me. Thanks a lot for the advice and the resources on FFI! I'll check them out once I've learnt more Haskell.
Due to all the times that you don't need attrs but you then have to pass the empty list. And making the tags polymorphic so that they can either accept a list or not is... messy. Leads to fun type errors and just doesn't feel Haskelly.
&gt; Rather than handling errors, exceptions, and logic in the same piece of code, Haskell separates error from logic by placing them in contexts (more technically referred to as monads). Contexts completely describe how to process invalid input, freeing the logic to only worry about valid input. Newb here. This switched on a light bulb in some dark corner of my mind. Thanks!
It means the latter, almost. For example, a function that constructs a singleton BST doesn't require that constraint. But a function that inserts into one does. Similarly a function that searches one does, but a function that enumerates all the elements of one doesn't, etc.
I did a longer summary of this on StackOverflow: http://stackoverflow.com/a/19650352
What is the difference between boxed and unboxed types, lifted and unlifted types ?
Gloss is great. It is the easiest graphics framework I have ever used. Unfortunately it lacks some features. You can't just display an image with a specific size, but have to determine the size yourself and then scale down. There also is just very basic input handling, so instead of adding a button with specific effect, you have to write the logical structure, that transforms a mouse click on a certain coordinate into an action yourself. And font rendering looks very ugly.
&gt; Operators as Aliases &gt; In PureScript, it is possible to define custom operators. For example: &gt; (+*) :: Int -&gt; Int -&gt; Int &gt; (+*) x y = x * y + y &gt; However, in version 0.8, this code will generate a warning: &gt; The operator (+*) was declared as a value rather than an alias for a named function. &gt; Operator aliases are declared by using a fixity declaration, for example: &gt; infixl 9 someFunction as +* &gt; Support for value-declared operators will be removed in PureScript 0.9. &gt; This warning indicates that we should instead define our operator as an alias for a regular (named) function: &gt; myAdd :: Int -&gt; Int -&gt; Int &gt; myAdd x y = x * y + y &gt; infixl 9 myAdd as +* Oh, awesome! I've always thought this is the right way to do custom operators - completely apart from concerns about readability of generated code. Just so that the operator has *a name*.
&gt; and I need to go and add deriving Show to twenty different types, just to observe the behavior of my function. To address this same problem I have a work-in-progress branch for present here: https://github.com/chrisdone/present/commit/a9cc1f08430be06ec01259feb0787a8248a8bb17 Because TH lets you break module encapsulation boundaries and inspect any data type, I can use that to generate a presentation for any data type and all the data types that it depends on. This allows: (1) a lazy GUI printer (inspect infinite or large data types without having to evaluate the whole thing until you need to) for something like Emacs or the web browser, (2) a regular text-based printer for a console-like environment (e.g. just inside GHCi), (3) an interactive command-line printer based on curses for example.
But if we are for example writing a game. Before you enter a level the resources are loaded, some rendering happens and so on, and the leak actually happens when you run and do stuff. But to profile the running/doing actions stuff you need to wait until all the resource loading/animation/rendering and other stuff is done. Also due to enabled profiler your game won't run at let's say 60fps but most likely will run at 1fps, reaching that place where the leak happens is quite hard and annoying to reproduce.
Does stack have this problem too?
It's a marginal joke at best ;-)
That's why I like Go: for all its flaws, at least it's a language with no inheritance support that I've actually got a decent chance of using at work. If there's one thing worse than using a language with no parametric polymorphism, it's having to deal with horrible inheritance hierarchies. Fun fact: it's actually possible to do a lot of OO in Haskell, via existential types and Typeable, but fortunately the community has the good sense not to.
PureScript is in a sweet spot of distancing itself far enough from Haskell for interop practicality while still being close enough in that you're almost just dealing with Haskell. It's going to be interesting to watch this language evolve over time too though.
Thank you.
I get that sometimes too when writing a file I got from the internet. Try keeping the file as a ByteString if you have the option and then using the writeFile function for ByteStrings instead of Strings.
1) I haven't had any major issues after switching from vim to neovim yet. 2) I just have autocmd! BufWritePost * Neomake in my (n)vimrc. That way neomake automatically runs hlint, ghcmod and hdevtools on every save of a haskell file (if the executables are found in your $PATH). I don't have a mapping to toggle Neomake and also there aren't any flags in my status line as described in the blog post. I'm note sure how easy it is to set this up. 3) Yeah, sure I wasn't the first mentioning this. But still, that's part of what I'd suggest to change. 4) Right, sorry. Editted my original comment such that the links are inlined.
Is there any realistic example out there showing how this library can make one's life easier ? I might see why having first-class constraints can be useful for generic programming, and I usually don't mind raising my level of abstraction to harvest more safety / genericity, nor do I fear delving into even poorly-documented APIs. Nonetheless, I don't think of it as my job to figure out what a library does.
The second issue is on the roadmap for 0.9 (so, soon). The problem is that the compiler is not yet able to infer constraints. When I try this with 0.8, I do get the following text in that error too: The instance head contains unknown type variables. Consider adding a type annotation. in value declaration add where _0 is an unknown type So it does explain what `_0` is. Did it not include that for you?
It can - for building stuff that requires external bindings. But that's only one step to deployment.
Fibonacci numbers quickly get so big that computing them using only additions is an exercise in futility. You gotta use some multiplications! Here's a much much much faster program that doesn't rely on laziness, higher order functions, or infinite lists: fib n = fst (fibs n) where fibs 0 = (0,1) fibs n | even n = (a*(2*b-a),a*a+b*b) where (a,b) = fibs (div n 2) fibs n | odd n = (b,a+b) where (a,b) = fibs (n-1) Math tricks &gt; programming tricks :-)
Here's a [question on SO](http://stackoverflow.com/questions/29905159/weakening-vinyls-recall-constraint-through-entailment) that I asked that demonstrates where `constraints` is useful. I'll warn you that it might be tough to understand. The main issue with understanding why `constraints` is useful is that you need to be in a situation where GHC isn't smart enough to figure out one set of class constraints from another, but where it can be guided to figure it out. These situations do not come up much unless you're working with sufficiently complicated types (often GADTs).
GHC might be a bit too hard while I'm still not "fluent" in haskell, but it might be fun so I'm starting from there :) Thanks!
Yes. I recall bumping into such a message with a Snap web application that was running in a VM with wrong locale settings.
Many times applicatives are too weak and moments are too strong. Traditionally this is where one uses arrows. Nevertheless the ecosystem around arrows seems less developed and does not provide the ease of use and infrastructure available to the functor, applicative and monad classes. What improvements - either syntax for supporting libraries would help bolster the use of arrows? Is there a fundamental reason that arrows are undesirable to use often?
(not parent, but...) Personally, I found Matt Might's line of work to be particularly accessible, though rather narrowly focused. * Abstracting Abstract Machines [[PDF](http://matt.might.net/papers/vanhorn2010abstract.pdf), [DOI](http://dx.doi.org/10.1145/1863543.1863553)] * Optimizing Abstract Abstract Machines [[PDF](http://matt.might.net/papers/johnson2013oaam.pdf), [DOI](http://dx.doi.org/10.1145/2500365.2500604)] * _A Posteriori_ Soundness for Non-deterministic Abstract Interpretations [[PDF](http://matt.might.net/papers/might2009aposteriori.pdf), [DOI](http://dx.doi.org/10.1007/978-3-540-93900-9_22)]
Worth to note that uses of Sequence (where only append from both sides is needed) could benefit from using [DList](https://hackage.haskell.org/package/dlist) instead for reaching better performance.
For info, here's my HTML rendering library: https://github.com/ndmitchell/bake/blob/master/src/General/HTML.hs I quite like this spot in the design space, and have been using it in Bake quite successfully.
Okay, thanks. I had a look at your SO question, and it does make things clearer. From a bird's eye view, it is very reminiscent of the kind of type hackery one has to do when playing with singleton types (encoding lots of stuff in type families / type classes, find ways to bring this information into context and rely on GHC to derive proofs automatically).
Thanks! This is great.
It tends to come up in constructive mathematics, when _you_ know that a set is either empty or not, but your logic can't tell you which one.
You can also look at the elm or purescript compilers :)
Got a blog?
Working on it. There's also quite a lot of code we'll open source when the firestorm settles a bit.
Leksah: Is this project still doing ok? I checked Github and since August of last year there have been 43 commits from 6 users (35 of those from 2 users). I know it's a slow part of the year but an IDE is an extremely large project for basically 2 people. Also, in case anyone knows, how well factored is the code? Does it follow a functional equivalent of MVP/MVC? That is, if I decided I like the idea but I'd rather have something other than GTK does that basically mean a complete rewrite or would it be possible to leave the majority of the code intact and only change the "VP"/"VC" part? This could be a bad question because maybe an IDE is, say, 90% GUI work no matter how you do it. If that's the case, I'd be interested to know.
Yeah, I would say it's pretty similar to the other things you've described.
Nix itself acts as a replacement for cabal-install/stack. nix and nixops are like stack except for the whole OS and deployment process. This means you get stack-like behavior not just for the Haskell libraries, but for C dependencies, system configuration, etc. Nix also has native support for using the stackage LTS package sets. That said, you can still use cabal sandboxes and/or stack with Nix as well. You don't have to do anything special -- they just work. 
looks useful too. Will check it out for sure. :D
Thanks for pointing that out!
I think I've fixed it. 
The [MSYS2](https://msys2.github.io/) environment solves a lot of those problems, in that it includes an actual package manager. (It's built on top of MinGW.)
/u/dagit mentioned Pandoc, which is a great example of a Haskell program that really dominates its niche, and does in part because of its Haskell foundation. Haskell makes writing and using intermediate representations easy, and that's what Pandoc does, allowing it to convert between numerous document formats (mostly) interchangeably.
what toolkit did you use? what frontend?
The stack: jquery, yesod, warp, esqueleto, postgres on EC2 instances. Locally we use docker. The frontend is almost entirely hand-coded and purpose built in javascript.
Also, for type signatures, you can do: let add = (\a b -&gt; a + b) :: forall a. (Semiring a) =&gt; a -&gt; a -&gt; a
Most Haskell types are "lifted" in that they also contain *bottom*, or undefined. I believe that in GHC Haskell this is synonymous with the idea that they may contain a thunk, i.e. a pointer to unevaluated code. In other words, a value of a lifted type may be lazily evaluated. Unlifted types do not contain bottom, and values of unlifted types may not be lazily evaluated. This is separate from the boxed/unboxed distinction, i.e. whether the value is a pointer. There can be boxed, unlifted types, e.g. `Array#`, which is represented as a pointer to the beginning of a memory array, just as in C; but it may *not* be a pointer to a thunk/unevaluated code. (I'm going off months-old recollection and what I could find in a few minutes Googling; I hope someone will correct any errors. See [the Wiki page on arrays](https://wiki.haskell.org/Arrays) and the [GHC trac page on UnliftedDataTypes proposals](https://ghc.haskell.org/trac/ghc/wiki/UnliftedDataTypes). The difference between lifted and unlifted types used to be captured in the distinction between kinds `*` and `#`; I don't know what the post-DependentHaskell story is.)
This is a simplified example. In the real thing, I reduced from about 40 typeclasses to about 6 before I noticed the problem. In the 40ish typeclasses case, a lot of the relationships weren't simple linear progressions - some quite complex inheritance digraphs, and there's some non-trivial conditions for some features. The project is basically how far I can model C++-like management of mutable data and owned resources in Haskell, and where I can possibly improve that model without fundamentally changing it. In C++, access to features in templates is basically by "compile-time duck typing" - in Haskell that's not really an option. Eventually in C++ we might actually get concepts to help declaratively manage that complexity - in Haskell, the issue is not forcing a hypothetical end user to implement his C++-style resource managing class by instancing 100 different typeclasses when a sanely small number will do. Null pointers are not unrelated to pointers, they're just a particular kind of pointer. That's one aspect for a high-level pointer scheme that includes member pointers, various kinds of iterators, standard interfaces for allocation, construction, moving, copying, destruction and deallocation of objects, etc etc etc. 
Your privacy policy is extremely non-commital. Actually, you don't commit to anything at all. &gt; Our *goal is* to not release your information for the public to see. That being said, any information you, the user, creates with WillChill is the property of WillChill. If we do end up using the information for our marketing purposes, or giving it to third parties for their marketing or analytics purposes, etc., *we'll try and anonymize it* There is no try.
The font is very "meh"... but congrats on the haskell success!
&gt; ~~with the default it means the compiler silently generates code that errors at run-time.~~ Oops - sorry for that brainfart. I'll give this a try in a bit. 
What font would you suggest? We aren't good designers.
Well if the book's anything like the talk, then I don't think it's a good resource. She appears to be very new to game programming herself. Further at least in the talk the examples she showed didn't make use of the ability to split IO and logic (see: her talking about games not being testable). And judging from the chapter list of the book it's a mix of "very basics of game dev" and "very basics of haskell dev", so it's probably better to just read game dev resources by professional game devs and haskell resources by the usual sources. Can't comment on the actual contents of the book since it's behind a paywall. also there's the #haskell-game channel on freenode
I want to use fixed-sized vectors and looked at the implementation [here](http://blog.jle.im/entry/fixed-length-vector-types-in-haskell-2015). There is the `Vector.Fixed` package which implements them, but without TypeLits, and `linear` has a kind of these too. What is the recommended way to go? I like the TypeLits approach, but found no libraries that implement them this way, besides this blog post. 
[removed]
Possibly, but I'd rather fix [this issue](https://github.com/fpco/monad-unlift/issues/3) instead.
Ah, shame, I was interested in maybe using this, but I don't use Facebook.
# Haskell on Windows: I've learned very basic Haskell in a university course using Hugs. I loved the concepts and wanted to see how far I could go with Haskell so I decided to give solving the Advent of Code puzzles a go in Haskell a while ago but then got stuck at fiddling with setting up a environment (under Windows) that I am happy with. Trucking along in a basic text editor was fine for the course but when using it to actually create bigger stuff I want more then support for text input and error messages from my tooling. Between work and studying I didn't have much time to sink into setting up a environment so I gave up after I couldn't get something satisfying up and running in a few Hours. (Between researching tools, installing them and trying if/what works time passes by fast.) Most Guides I found were either assuming one uses Linux with Vim/Emacs or I couldn't get them to work properly. (IntelliJ Plugins + Stack, Leksah) *** The time I tried this was also shortly after stack was becoming popular which made things for me as beginner even more confusing since many tools didn't work with it also I found a few good looking guides referring to tools that had just recently declared themselves dead. ## Some of the things I tried were: * Leksah: It sometimes crashed at random times and always crashed at exit. It also didn't seem to support code completion from imported libraries. * With stack there was a problem building a base component under windows which caused stack to fall into a unusable state. It boiled down to a file being placed in the wrong path, so all builds depending on that dependency just failed. I hit that roadblock before getting to hello world. Took far too long to find a solution and cost me most of my motivation at that point. * I somehow got stack to work though and then tried to use a Haskell IntelliJ Plugin. However it didn't seem to support syntax checking/code completion when using stack, at the time at least. * I thought about creating a Debian Image and just using that but I don't really want to go there. I still did back then but everything seems to be mostly vim or emacs centric though. I tried haskell-vim-now but as far as I could tell it only offers in-file tab completion. # So my questions is for the Windows users here is what do you use for Haskell? What does it support? (Syntax checking, Code completion, other goodies?) *** Is is reasonable to complete something small. (Think parse input json file, do computation, print output) without having to spending more then 2 Hours on installing tools/setting up a project and so on? For an novice. *** Should I just use Cabal and try to make that work with the IntelliJ Plugin for now because as a beginner I won't really benefit from stack? *** I love what I've seen from Haskell so far, however personally I don't want to lose what I gain from the Language to worse tooling so thankful for any tipps you have.
Is there a way to get out of file autocompletion to work with vim?
Almost certainly. I don't use autocompletion (except in `ghci`), though.
Hello! Another of WillChill's "parents" here. You raise a pretty good point about the privacy policy. We wrote it pretty early on, when it didn't matter as much, and kind of forgot about it. There was meant to be an amount of humor in it. Looking at it now, I'd be a little sketched out too! 0_0 I'll be drafting something more concrete and committal to go on that page. Our goal is to be good stewards of the information you leave with us in the course of using our app, and the privacy policy should be able to assure you that it'll be [more than just "our goal".](http://cdn.meme.am/instances/58942374.jpg)
Just a small critique. Your definitions have shadowed variables. You don't want that at all, since it looks like it might be a recursive call and is a bit of a PITA to parse. And before you go naming things "free", you should have a reason to call it such. All "free" things (monoids, groups, monads, modules, categories, sheaves) are named so because they take some object of one category (sets, sets, functors, sets, graphs, presheaves resp.) and add the "minimal" amount of structure needed to make it into an object of another category. (And minimal isn't an arbitrary word here. It has a precise meaning, but it carries a strong intuitive sense to it). It might also help not to have a random code snippet devoid of context. Why did you write this code? 
I swear (my hand on your choice of thick book within my arm's reach) we wouldn't intentionally be so underhanded! We've been working on this for something like six months, and we're eager to show off. So eager that there was a great flash of light and we momentarily forgot how to reddit properly! We'll get a substantial post together as soon as we can, and hopefully provide useful information. We, the WillChill team, are thankful for your patience. 🙇
It's not for me but for someone which has no experience in programming. I would help him of course, so I'm just wondering if Elm could be a good choice for that.
Very nice, and it puts the main responsibility where it belongs. For users to provide a differently-named function in their instances than what they expect to call when using them is really no different to things like `operator++(int)` in C++, or all those double-underscore-wrapped names in Python etc. I'm not sure I understand what it's doing, though - I just found the [Data.Type.Equality](http://hackage.haskell.org/package/base-4.8.2.0/docs/Data-Type-Equality.html) documentation so I thought I'd leave the link before figuring it out. 
Hmm, I guess there isn't something quite as nice say as TAPL, but here are some links. + Hankin et al. "Principles of Program analysis" http://www.amazon.com/dp/3540654100/ref=rdr_ext_sb_ti_hist_1 + Anders Moller's recent monograph, with a focus on recent developments https://cs.au.dk/~amoeller/spa/ + Antoine Mine's lecture notes. (Patrick Cousot also has a set somewhere...) https://www-apr.lip6.fr/~mine/enseignement/mpri/2015-2016/ + http://www.concrete-semantics.org , which develops abstract interpretation inside Isabelle. I personally also learnt a lot from Clarke, Grumberg and Long's "Model Checking and Abstraction" ... HTH! 
&gt; Locally we use docker. Only locally?
It was unnecessarily slow, and unnecessarily complicated for production where we can use literally different machines rather than putting all of our programs on one machine. Locally, it is great for simulating our production environment. 
I guess it's sharing caused by common sub expression elimination.
For sure, it's just mostly that Elm is Haskell related, but distinct, and you're likely to get a lot more answers on the mailing list. I don't think there are many packages for music out there, but it should be fairly easy to get set up in JS using ports and tasks 
caveat: the above only applies strictly. lists are not the free monoid in haskell.
After reading this I understand the tagless final approach at last! I'm not quite convinced by the aggregation section. If I was familiar with OCaml I'd play around with it, but I guess I'll have to wait until someone produces more examples.
That's a pretty thoughtful summary. I've (anecdotally) heard Haskell programmers are difficult to find, so it's nice to (anecdotally) hear this isn't necessarily the case.
I don't think `cabal-install` does this out of the box, but I wish it did! I've done it in the past with `awk`, `sed`, etc., but it's often sed how awkward that is.
I believe such an algebraic structure like `MonoidAST` is sometimes called *magma* in algebra. -- &lt;https://en.wikipedia.org/wiki/Magma_(algebra)&gt; Only, it's not clear whether the property of having a unit (`MEmpty`) is thought to have some interesting status and has a special name... Perhaps, it's a [unital magma](https://en.wikipedia.org/wiki/Magma_%28algebra%29#Classification_by_properties)... I'm not sure as to the common usage and understanding.
I'm not sure what the picture is here. At first, I thought you were trying to encode the neutral element and the binary function in `FreeishMonoid`, but shouldn't its type then be -- for clarity type Neutral a = a type BinaryOp a = a -&gt; a -&gt; a type Term a = a newtype FreeishMonoid a = FreeishMonoid (Neutral a -&gt; BinaryOp a -&gt; Term a -&gt; a) ? What can run possibly return if you can supply the neutral element and the operation, but not the term? Then again, I could well have gotten the intent of it all wrong. Can someone enlighten me?
Thank you very much for the suggestion. I am having a problem with unmet dependencies installing libgmp-dev. I suppose I can force it by dpkg -i.... My guess is the root problem somehow is the libgmp-dev package. 
 data a :~: b where Refl :: a :~: a means that Refl :: a ~ b =&gt; a :~: b is the data constructor. So `a :~: b` is a value that when you pattern match on the Refl constructor brings into scope a proof that a ~ b. What I did there was carefully not look at the contents of that box in the default `cNull'` case, just accept it and give an error. On the other hand, when the constraint on the default signature isn't satisfied, you have to supply the manual definition, which is precisely what you wanted. Then the constraint simplifier doesn't get two constraints of the form `PtrHasNull p ~ False` and `PtrHasNull p ~ True` in a situation where it would be tempted to do reduction and prove `False ~ True`. I'd argue that there is something wrong with GHC's logic here and we should be allowed to provide a body or proof directly, but it is hard to state precisely what the "right" way to avoid this song and dance would be.
&gt; sudo apt-get -y -q install --no-install-recommends stack Reading package lists... Building dependency tree... Reading state information... E: Unable to locate package stack 
Ah, sorry, never mind then.
Is it because of the possibility of an infinite list?
(Anecdotally) it's absolutely not the case. Post a job ad on r/haskell, get ~30-50 outstandingly qualified applicants in a matter of days. The signal to noise ratio couldn't be higher.
I like the gray fox
I'd consider contributing your pretty printer, which looks (from the blog post) to be a better implementation of `cabal format` to cabal.
If anyone is following along but confused by the Church encoding, an intermediate step to make it clearer is to express the ADT as a GADT with explicit type signatures for the constructors: data MonoidAST' a where MEmbed' :: a -&gt; MonoidAST' a MEmpty' :: MonoidAST' a MAppend' :: MonoidAST' a -&gt; MonoidAST' a -&gt; MonoidAST' a This is equivalent to the `MonoidAST` above (disregarding the double `MEmpty` constructor): the `MEmbed'` constructor takes a value and returns a `MonoidAST'`, the `MEmpty'` constructor returns a constant `MonoidAST'`, and the `MAppend'` constructor takes two `MonoidAST'` values and produces a new one. The Church encoding now universally quantifies the `MonoidAST'` type as some variable `r`, and takes each constructor as an argument to the Church function: newtype CEMonoid a = CEMonoid { mrun :: forall r. -- ≡ MonoidAST (a -&gt; r) -- ≡ MEmbed -&gt; r -- ≡ MEmpty -&gt; (r -&gt; r -&gt; r) -- ≡ MAppend -&gt; r } This form essentially encodes a fold-like operation as the data structure, where functions take the place of values, and the constructors become lower-cased: membed' :: a -&gt; CEMonoid a membed' a = CEMonoid $ \ d _ _ -&gt; d a mempty' :: CEMonoid a mempty' = CEMonoid $ \ _ e _ -&gt; e mappend' :: CEMonoid a -&gt; CEMonoid a -&gt; CEMonoid a mappend' a b = CEMonoid $ \ d e f -&gt; f (mrun a d e f) (mrun b d e f) Note that `mappend'` must work for all possible interpretations of the monoid, and so must evaluate its two arguments to be able to append them together. Each new operation chains functions together, and to evaluate a result you need to `mrun` it with some suitable operations: λ&gt; mrun (membed' "foo" `mappend'` membed' "bar") id "" (++) "foobar" To "run" a `MonoidAST` you would need to write an interpreter which takes the data type and functions for each of the operations: λ&gt; runm MEmpty d e f = e λ&gt; runm (MEmbed a) d e f = d a λ&gt; runm (MAppend a b) d e f = f (runm a d e f) (runm b d e f) λ&gt; :t runm runm :: forall t t1. MonoidAST t -&gt; (t -&gt; t1) -&gt; t1 -&gt; (t1 -&gt; t1 -&gt; t1) -&gt; t1 λ&gt; runm (MEmbed "foo" `MAppend` MEmbed "bar") id "" (++) "foobar" And unsurprisingly, the three interpreted cases in `runm` look very much like the three "constructor" cases for the Church-encoded monoid.
&gt; Integer, for example, is both monoidal under addition and under multiplication. So expressions of type FreeishMonoid Integer can be combined with mempty and mappend, and we can delay until later the decision of whether we wanted mempty and mappend to mean 0 and (+) or to mean 1 and (*). That's useful, but it's also completely different from the free monoid [Integer], which allows you to do much more than just squashing it with sum or product. That was the intent for this abstraction. Also it allows to conform to polymorphic monoidal interfaces, such as foldMap :: (Monoid m, Foldable t) =&gt; (a -&gt; m) -&gt; t a -&gt; m and have you specify what `mempty` and `mappend` actually mean later, when you `run` the final composed `FreeishMonoid`. It can also be used to conform to the Monoid interface with operations, which even violate the Monoid laws. This of course implies that such `FreeMonoid` is enclosed by your algorithm, which expects such a behaviour, and doesn't leak into the API. Thanks for all your points!
&gt; All "free" things .. add the "minimal" amount of structure needed to make it into an object of another category. Well, in a sense it does do that. However as I now know this thing doesn't conform to the definition of Free Monoid. &gt; Why did you write this code? See this comment: https://www.reddit.com/r/haskell/comments/43vqno/what_is_this_monoid_which_i_have_a_strong_itch_to/czm0twx
I think I 60-70% understand, though I'll need to play with it. I looked through all my code again, though, and in a couple of places I actually *had* turned an option off without getting a warning or an error, but I hadn't removed the functions from the instances and there was a difference in how I specified the option. Basically... {-# LANGUAGE KindSignatures #-} {-# LANGUAGE ConstrainedClassMethods #-} module Test (Foo, Bar, QuxClass (foo, bar)) where class IsFoo (x :: * -&gt; *) where {} class IsBar (x :: * -&gt; *) where {} class QuxClass f where foo :: IsFoo f =&gt; f x -&gt; x bar :: IsBar f =&gt; f x -&gt; x newtype Foo x = Foo x newtype Bar x = Bar x instance IsFoo Foo where {} instance IsBar Bar where {} -- GHC still warns if functions are missing from the instance, even when those -- functions can never be called due to the constraint. However, -- implementations can be provided. -- -- In this case, I believe GHC has to assume the functions may still be -- callable. There are no instances for IsFoo Bar or IsBar Foo *here*, but the -- user may provide them in another module. Though this is a bit suspect given -- that the class names IsFoo and IsBar are private to this module. instance QuxClass Foo where foo (Foo x) = x bar = error "Never happens" instance QuxClass Bar where bar = error "Never happens" foo (Bar x) = x Using classes as Prolog-ish predicates gets around the error issue, and to me seems like the simplest option. It creates the classic Prolog hassle that you can't really take the `not` of a predicate,but there are easy workarounds. I also have a case with metadata in data-kinded type constructor arguments, but that's done for type-level computations of derive metadata in result types. There's still a lot of classes in that part of the code I'd forgotten about - no "optional methods". 
And behind those, a couple of thousand programmers so eager to work with Haskell in production that they will put in tons of effort.
Yeah for sure! My feeling was to see how Judy Arrays would perform using your approach but I haven't tried it yet (I tried IntMap but it was worse).
JSON at least is certainly the wrong format for your config files aimed at non-programmers. Even YAML syntax can be quite tricky for people not familiar with it to get right. Have you considered a simpler format?
 You might be interested in the library [cabal-lenses](https://hackage.haskell.org/package/cabal-lenses-0.4.5) which provides lenses for operating on the `GenericPackageDescription` data structure of the `Cabal` library. I've written it for my own cabal file handling tools and it makes it quite easy to operate generically on cabal files. For example if you want to get the `hs-source-dirs` of the executable `foo` from the GenericPackageDescription `pkgDecrp`, then you could write: pkgDecrp ^.. buildInfo (Executable "foo") . hsSourceDirsL Or if the default flags and conditionals in the cabal file should be considered: pkgDecrp ^.. buildInfoIf (fromDefaults pkgDecrp) (Executable "foo") . hsSourceDirsL The really nice thing about lenses is how easy they're extensible, like adding an additional filter, e.g. like only taking directories starting with the prefix `boo`: pkgDecrp ^.. buildInfo (Executable "foo") . hsSourceDirsL . filtered (\dir -&gt; "boo" `isPrefixOf` dir) 
Your freeish monoid does not satisfy the monoid laws: count :: FreeishMonoid Integer -&gt; Integer count (FreeishMonoid f) = f 1 (+) and then observe that count (mappend mempty mempty) is not equal to count mempty however, your type is very similar to newtype M a = M (Monoid a =&gt; a) (which is legal given the right extensions) and which, IMO, at least morally obeys the monoid laws. 
This was exactly my experience.
Take x2 = x1 `mappend` x1 x3 = x2 `mappend` x2 ... x30 = x29 `mappend` x29 With `x1 = Sum 1` using the out of the box `Sum` monoid, you can look at x30 almost instantaneously. But consider x1 = FreeishMonoid $ \ _ _ -&gt; 1 Executing that with something like `runFreeishMonoid x30 0 (+)` will take a long time. Why? Because, while there are only 30 distinct "values" we want to build, but there are a billion function calls to be executed to compute the final answer. Reflection lets us dynamically pick the instance, but share the values. Let's look at what the API is for reflection: class Reifies s a | s -&gt; a where reflect :: proxy s -&gt; a reify :: a -&gt; (forall s. Reifies s a =&gt; Proxy s -&gt; r) -&gt; r Implementing those combinators requires some magic, but effectively `reify` takes a value 'a' and turns it into a fresh type `s`, such that reflect using that type gets back `a`. Since the `s` is a fresh type, this doesn't conflict with any other instance of `Reifies s a'`. Now we can define a monoid: newtype M a s = M { runM :: a } deriving (Eq,Ord) data Monoid_ a = Monoid_ { mappend_ :: a -&gt; a -&gt; a, mempty_ :: a } instance Reifies s (Monoid_ a) =&gt; Monoid (M a s) where mappend a b = M $ mappend_ (reflect a) (runM a) (runM b) mempty = a where a = M $ mempty_ (reflect a) withMonoid :: (a -&gt; a -&gt; a) -&gt; a -&gt; (forall s. Reifies s (Monoid_ a) =&gt; M a s) -&gt; a withMonoid f z v = reify (Monoid_ f z) (runM . asProxyOf v) asProxyOf :: f s -&gt; Proxy s -&gt; f s asProxyOf a _ = a and invoke it ghci&gt; withMonoid (+) 0 $ mempty &lt;&gt; M 2 &gt; 2 But if we do the x1 ... x30 example above inside of the call to withMonoid, it'll make 30 "M a s" values, but each of them will actually be an integer, not a function, and we'll share the result integers, running in 30 steps, not 2^30 steps.
&gt; Your freeish monoid does not satisfy the monoid laws Not exactly. It simply relays the responsibility for the implementation and the law abinding on the executor. &gt; however, your type is very similar to &gt; &gt; newtype M a = M (Monoid a =&gt; a) &gt; &gt; (which is legal given the right extensions) and which, IMO, at least morally obeys the monoid laws. And defeats [the purpose](https://www.reddit.com/r/haskell/comments/43vqno/what_is_this_monoid_which_i_have_a_strong_itch_to/czm0twx).
It may be worth it to see this idea exploited "in the wild" for using `foldMap` with an arbitrary unit/associative binary operator here: http://hackage.haskell.org/package/folds-0.7/docs/src/Data-Fold-M.html#M
I made a [pull request](https://github.com/haskell/haskell-platform/pull/232) adding a warning to the instruction.
Don't wait for cabal-install... just use Stack, which will have this feature long before cabal-install does!
&gt; in the past This is not the way of the future. The way of the future are GUIs and language processing. The sooner people realize this the better.
&gt; (disregarding the double MEmpty constructor) All my comments contain mistakes on this thread :(
&gt; This of course implies that such FreeMonoid is enclosed by your algorithm, which expects such a behaviour, and doesn't leak into the API. I don't understand what that sentence means.
Are you saying each user (or small group of users) would have their own chunk? And you could write your data structure in a way where each chunk is separate data yet one chunk can access the other (read only?) if it wants to? Sounds like STM could work depending on the frequency of the cross-section reads. That is if you can write such a data structure.
If you're going open source, BrowserStack and Sauce Labs provide free accounts. These are cloud services for cross-browser and cross-device testing. You can also use Selenium tests to do automated testing.
This takes 0.106s roughly on my system, faster than the other results so far! very nice approach; I'll add it to the repo and put up the benchmark when I get home!
Sounds like 90s rhetoric to me. Since then most GUI advocates have become less militant and started to admit that it is more of a 'best tool for the job' issue than a general rule that applies everywhere.
That's the only definition of free monoid that I know :-( Is there a more general definition somewhere, which allows infinities?
Cool! Has anything further been done with this in the last 9 years?
What would you think about tweaking pulp so it adds an `import Prelude` in the generated .psci file?
What do you mean by that hastor ? Could you elaborate on what benefits would that bring? I am not familiar with template projects.
I'm the author of the parser and I can tell you I'm still not using it in production. Unless you are willing to invest some time improving the codebase, I wouldn't rely on it too much for now.
It looks like plot.ty has a json schema linked to from http://help.plot.ly/json-chart-schema/. I have used aeson-schema (https://hackage.haskell.org/package/aeson-schema) in the past to generate types from a schema (the CodeGen module in aeson-schema). My only worry is that the plotly schema is in a different format than the one accepted by aeson-schema.
What is "RR"?
It is defined in the article as the reflection reification pattern with the following link : http://okmij.org/ftp/tagless-final/course/rr.ml 
It's hard for me to truly determine when a reflection approach makes sense. For example, I'm currently playing around with newtype Eff f m a = Eff (forall g r. (forall x. Sum f m x -&gt; Cont (g r) x) -&gt; Cont (g r) a) Basically a reader monad... thing. The first argument is supplied when you want to `runEff`, which makes it a candidate for reflection too. If I switch over to newtype Go f m g r = Go (forall x. Sum f m x -&gt; Cont (g r) x) newtype Eff s f m a = Eff (forall g r. Reifies s (Go f m g r) =&gt; Cont (g r) a) I have 4x slower results in my benchmark due to, presumably, the overhead in `reflection`. So maybe it's a win when you have the sort of "non-linear" flow you later demonstrate, but with monadic sequencing you don't get that. I suppose as you say, it's about solving the problem of sharing, and here there is none.
[removed]
I don't see why passing a vector to a function would copy it. I think it will copy a pointer to it instead. Is your problem that you want to modify the array/vector and they're immutable? It's true that modifying an immutable array creates a copy of it. To get around that, you need something like [mutable vectors](http://hackage.haskell.org/package/vector-0.11.0.0/docs/Data-Vector-Mutable.html). Or sometimes you can use Vector's loop optimisation framework or Repa.
Well? Did you get it work? Just posting an error message is a bit terse.
There's two kinds of callstacks, which is explained in [GHC.Stack](http://hackage.haskell.org/package/base-4.8.2.0/docs/GHC-Stack.html). One is provided by the profiling RTS, and one is generated lexically and requires manually annotating the functions whose call-sites shall be appended to the callstack. The support for explicit call-stack appending was actually already added in GHC 7.10.2, the visible change that occurs in GHC 8, however, is `error` and `undefined` getting this "partial callstacks" support, and the `ErrorCall` exception type changing its definition to pattern ErrorCall :: String -&gt; ErrorCall data ErrorCall = ErrorCallWithLocation String String to carry the additional call-stack information in the 2nd `String` field 
I don't understand the "bug" that the post talks about. If my prior distribution is 50/50 (equal probability of spam vs not spam), and I have a single example of an email with property x which happens to be spam, what could possibly justify assigning 100/0 (or 99/1) to P(spam | x)? That seems totally unreasonable to me.
I can't say about recruiters in general but I know that I'm trying to push Haskell on a Java company. Some of them might just be looking for someone to spend a bit of time with Haskell but the core of their time in Java on the main project. 
This post responds to a claim in the recent paper ([link](http://okmij.org/ftp/meta-programming/index.html#QUEL), [PDF](http://okmij.org/ftp/meta-programming/quel.pdf), [DOI](http://doi.acm.org/10.1145/2847538.2847542), [code](http://logic.cs.tsukuba.ac.jp/~ken/quel/), [reddit](https://www.reddit.com/r/haskell/comments/43p72l/finally_safelyextensible_and_efficient/)) &gt; Haskell typeclasses made the encoding lightweight compared to OCaml modules. On the other hand, in OCaml we relied on the include mechanism to program optimizations by reusing the code for the identity transformation and overriding a couple of definitions. Haskell does not support that sort of code reuse among type classes. Therefore, programming tagless-final transformation in Haskell has quite a bit of boilerplate. by showing how to use Haskell type classes with default method signatures and associated types with defaults to reduce the boilerplate while retaining the benefit of type classes.
Very slick! I didn't follow your build instruction though. I downloaded the zip and did $ stack init $ ... appeasing stack gods ... $ stack install No errors, it just worked. I'm having a little trouble believing the ecosystem has evolved to this point. Nice job on the game.
The explicit callstacks were added in 7.10.2 but they were not used by `error`. That has changed in 8.0, *but* the partial functions in `base` still won't provide a callstack unless you build with profiling. The reason is that we would have to add callstack annotations to each partial function and that 1. has a runtime cost 2. clutters the API so we're taking a conservative approach to using the feature inside `base`. That being said, I posted a [package] a while ago that provides callstack-aware variants of many partial functions from `base`. You can use it today with GHC 7.10.2, and I'll update it for 8.0 when the time comes. [package]: https://hackage.haskell.org/package/located-base
Thanks :) I didn't know about stack. It looks nice and simple, I'll check it out. I see you've made a pull request (I'm guessing that's you), thank you for your contribution!
How are typeclasses lightweight compared to OCaml modules? (I don't know much about the latter.)
Nope, not me. some other haskeller is on the case.
I love how the whole program is in one file. It makes me feel like I could put together something like this... thanks for sharing!
I just did the tests, this is the result: `202 passed, 411 failed, 0 errored, 0 skipped` There's a lot of tests that use raw HTML, something I have not implemented yet, so I need to work on that. I suppose this result makes sense since the library is only 1 week old. P.S. Thanks for showing how to run the tests! **Edit**: Checking my results more closely it seems that some tests should be passed, it is just that my produced HTML doesn't match the expected HTML *exactly*. 
It was me!! I couldn't resist the urge to stackify it. 
You can do a lot in one file! :) But I think this is about the limit before it gets confusing. It would probably be more readable if I separate it in modules. You should definitely put together something like this. I think Haskell feels very rewarding even on tiny projects like this!
That would not work, because that would require lists to be heterogenous. You could use fundeps or type families to enforce a relationship between the types, though. 
Awesome! Yeah, I chose clarity+boilerplate too: https://github.com/sboosali/commands-core/blob/master/tests/Test/DocTest/Discover.hs#L15 
I've crossed the line where even though not everything is best done in Haskell, I want to do everything in Haskell. I've been looking for a good UI library to play around with, and Curses looks good from the way you've used it. Multi file projects are great when the goal is a nice, modular library, but for self projects structured similar to yours, one file is completely fine, in my opinion. It's all a matter of taste when it comes to personal projects. You're right though, over 2 or 3 hundred lines it might be better viewed in separate modules, so you can have two files open at the same time and don't have to jump around within the same one all the time.
&gt; So what would you do? I would say the probability of spam given X is still 50-50, because the prior distribution would have predicted either sample result with equal probability. It's not until the second (and beyond) samples that you have meaningful evidence for or against that hypothesis. If I have 10 emails with property X and 9 of them are spam, now I have evidence that p(spam|x) = .5 is a bad theory, and I can reject it. If I only have one sample, how could I possibly reject that theory? It's perfectly consistent with what the theory predicts. In some sense, my interpretation of Bayes here is not an assessment of how much I believe a hypothesis, but rather that Bayes produced a *new hypothesis* (p(spam|x) = 1.0) using my observation, but there is as of yet no evidence supporting it. It's not until another sample that I have any "belief" in this new hypothesis.
As I said elsewhere, I think the correct distribution would be from the dirichlet family, such as the beta distribution when we have a binary classification. The fun part about the beta distribution is that you can pick your parameters in a pretty intuitive way: you basically say "let's pretend that I've already seen x examples, and that some fraction f were spam and the rest were not". This assumption then gives you a very natural decision for how much you change your priors when you see new examples.
This makes sense, and I think that what I suggested is pretty similar to what you're saying.
&gt; the class names IsFoo and IsBar are private to this module. Yes, but Template Haskell can magic them up anyway in a lot of cases, using something like [this](https://hackage.haskell.org/package/true-name-0.1.0.0/docs/Unsafe-TrueName.html).
I think the best answer would be DO NOT IMPLEMENT THEM, use existing libraries (except if you are really know what you are doing). The `vector` library has efficient arrays with O(1) access. The `containers` and `unordered-containers` libraries have lots of options of structures with different properties that may be useful for you.
Hope you will find this refactoring useful, its using `LambdaCase` and `NamedFieldPuns`. inputUpdate :: Window -&gt; [ColorID] -&gt; GameState -&gt; Curses (Score, Bool) inputUpdate w palette state@GameState{_highscore} = getEvent w (Just 100) &gt;&gt;= maybe (doUpdate w palette state) (\case EventCharacter 'q' -&gt; return (_highscore, False) EventCharacter 'Q' -&gt; return (_highscore, False) EventCharacter 'r' -&gt; return (_highscore, True) EventCharacter 'R' -&gt; return (_highscore, True) key -&gt; doUpdate w palette (stepGameWorld key state)) You have one `gamestate@GameState` and the rest is bound to `g@Game...`. aside: http://www.blaenkdenum.com/notes/haskell/#ghc-extensions Disclaimer not tested.
This looks great! I'll test it out tomorrow (it's getting late here in the UK). There's definitely plenty of refactoring possible with this code, and I didn't know about LambdaCase and NameFieldPuns. Thanks for your advice! :-)
Ah yes well spotted. That's what maybe is for :-)
I wrote up some sample code almost identical to what you commented, [here](https://gist.github.com/Solonarv/44618a66d54562346b3a). It seems that GHC will generate Core that takes each class' dictionary as a separate parameter, so the end result would look a bit like this: myFunction = \ (fooDict :: Foo a) (barDict :: Bar a) -&gt; (A.foo fooDict) . (B.foo barDict) Depending on how the syntax works, that's basically what the implementation in my head would want you to write.
any reason you didn't use gpipe for opengl? BTW really neat project, and in 24 hours no less. makes me wonder why nobody has pulled any substantial game dev off since that frag game from like 10 years ago.
That's true, but part of what I was saying is that you can't syntactically distinguish a class from two classes anymore, because we have `type Baz a = (Foo a, Bar a) -- constraint conjunction`. So with hiding and so forth the programmer can't even always access the names to "split it" into the "atomic" classes.
Check out [Ścibior et al](http://mlg.eng.cam.ac.uk/pub/pdf/SciGhaGor15.pdf) from ICFP 2015. The associated talk is also available [here](https://www.youtube.com/watch?v=hI0ajVy2xEk).
I think mainly because it's a small hell to target Windows, and a large one to target mobile. Real progress is being made on both fronts, tho.
&gt; Node ([Attr], String) `String`?
&gt; it seems that some tests should be passed, it is just that my produced HTML doesn't match the expected HTML exactly. The test runner does some HTML normalization so that insignificant differences will not cause test failures. We may need to do more of this, so feel free to bring up particular cases on the bug tracker. 
&gt; With Haskell’s data types, unpacking such chains manually at every use site will quickly become unwieldy. Can anyone give an example of that? I'm not seeing it.
&gt; However, there are other free objects besides free Monoids. For example, there are [..] "free Categorys" As I'm currently reading Awodey and he gives specific coverage of this, I tried to look at it in Haskell. I think free monoids work so well because you're moving between the categories **Mon** and **Set**, and for our purposes here I think we're basically working between **Mon** and **Hask**. With free categories though, you're working with **Cat** and **Graph** (at least, in Awodey's presentation), so I found it a little harder to come up with anything meaningful. The notion of a free category in Haskell usually comes out of some data type like data Path :: * -&gt; * -&gt; * where Id :: Path a a Edge :: Path a b -&gt; Path b c -&gt; Path a c I can at least see here that it forms the two necessary sets to represent a graph, namely a set of vertices and edges. I do agree that there's a lot of power in free structures that the programming community in general would do well to learn from. I'm trying to advocate a "library based" approach to using these mathematical concepts - understanding the functionality that some basic structure might afford (like the `(r -&gt; a)` or `Const [l] a` functors), and then learning the appropriate ways to combine this data, just as you would do in a library. In this case, that means learning about the `Sum`, `Product` and `Compose` of functors. I think there is space in there to talk about free structures, too.
nicely done!
Yes I downloaded 32bit file. Ran `chmod +x stack` in the downloaded stack folder, then `./stack setup`. When I type `ghci` it still loads the old one (from haskell-platform) in version 7.6.3. To run new one, I need to everytime go into the downloaded stack folder and run `./stack ghci`. What I did was I typed in terminal `alias ghci='/home/rain228/Downloads/stack-1.0.2-linux-i386/./stack ghci'` and now It's working ok. Thanks 
So what's the foldMap of Monads?
We wanted to learn to OpenGL and didn't know that GPipe existed. Looks like a really interesting approach that we'll definitely check out before the next hackathon though!
I'd love to see that! :-)
In that case, it sounds reasonable. But in the current hiring market, they keywords war it's a reality. As any developer, I'm very biased towards my personal preferences and favourite technologies, but sometimes I'd like to enjoy a bit of sanity and good practices no matter what is your stack. When we think about Haskell or any other nice piece of technology, we tend to think it would solve a lot of our problems. But sometimes I wonder how would it be having to use Haskell in a horrible code base. I guess the glamorous type system we all love would be a great win, but I wonder how effective would it be when you have to deal with sick code base that doesn't make any sense. 
&gt; so you can have two files open at the same time Don't most editors let you split the same file into two or more tabs?
Assuming there is some category **Monad**, whose objects are monads and arrows are monad homomorphisms, we would need to find another category for the forgetful functor to map to. I didn't know what this is, but [this StackOverflow answer by /u/edwardkmett](http://stackoverflow.com/a/13352580/74497) suggests it is a category **Endo** (my name, I don't know if there is an agreed upon name) whose objects are endofunctors and arrows are natural transformations. With that, I thought it would be something like foldMapOfMonads :: Functor f =&gt; (forall a m. Monad m =&gt; (f a -&gt; m a) -&gt; m a) But apparently it's class Algebra f x where phi :: f x -&gt; x foldMapForMonads :: Algebra f x =&gt; (a -&gt; x) -&gt; x I don't quite understand why `x` here isn't a `Monad` (as `foldMap` produces some `Monoid`). If you're interested in this from a category theory perspective, the first chapter of Awodey's book goes into the detail of free monoids and free categories. I spent a few hours on the two pages on free monoids (yay, mathematics) and have come away with an understanding there, but I don't think my intuition is quite up to being able to talk about other free structures yet :)
"In other words, the theory indicates that we can implement all other functions over lists in terms of this very general map-reduce function." This is I think potentially confusing wording, as it can be read to mean that all functions on lists can be written in the given form -- but this only holds true for list homomorphisms. There are functions on lists that are not list homomorphisms, and which can't be done efficiently in parallel, and so which aren't captured in the given framework. In general, even when something _can_ be given the form of a list homomorphism, it is not always very obvious how to do so. The more precise claim is I think one that reads slightly weaker -- all functions on lists can _factor through_ such a function -- but the way the can do so may include "trivially" in which this function is effectively identity on lists. In other words, functions on lists can be written in the form `foldr f z` and we set ourselves the problem of when that can be rewritten as `foldr f1 z1 . mconcat . map u`, and discover the answer is "always" but the problem of when it may be _efficiently_ done is somewhat more tricky...
Yes, the original is `{-# INLINE #-}d` to the extreme, which gets me performance equivalent to `transformers` (because it literally compiles down to the same code). It seems that GHC is probably smart enough to lift the lambda in `Eff` all the way up to the top, or something.
OTOH the original abstraction was sufficient. Here's how one could lift the value into it: newtype FreeishMonoid a = FreeishMonoid (a -&gt; (a -&gt; a -&gt; a) -&gt; a) singleton :: a -&gt; FreeishMonoid a singleton a = FreeishMonoid $ \_ _ -&gt; a However, the latter abstraction seems more flexible.
Yeah, the `reflection` version enables GHC to do a somewhat similar lifting to lift the reified parameter out of any other lambda, but it seems that it isn't finding any decent opportunities to do so in the `reflection` case.
It seems very natural with the usual type indexing, or maybe I'm not following {-#LANGUAGE KindSignatures, GADTs, PolyKinds, DataKinds #-} import qualified Control.Category as C data Free (g :: k -&gt; k -&gt; *) a b where Nil :: Free g a a Cons :: g a b -&gt; Free g b c -&gt; Free g a c after g Nil = g after g (Cons edge rest) = Cons edge (g C.. rest) instance C.Category (Free g) where id = Nil (.) = after Then one just declares an underlying vertex type, and a selection of edges: data City = Paris | Rome | Moscow data Flight a b where -- maybe this should be `FlightE` on the model of `ListF` etc. ParisRome :: Flight Paris Rome RomeMoscow :: Flight Rome Moscow type Journey = Free Flight arr a = Cons a Nil paris_rome :: Free Flight Paris Rome paris_rome = arr ParisRome rome_moscow :: Free Flight Rome Moscow rome_moscow = arr RomeMoscow -- &gt;&gt;&gt; :t rome_moscow `after` paris_rome -- rome_moscow `after` paris_rome :: Free Flight 'Paris 'Moscow -- &gt;&gt;&gt; :t paris_rome `after` rome_moscow -- &lt;interactive&gt;:1:20: -- Couldn't match type ‘'Moscow’ with ‘'Paris’ `type-aligned` has various optimized variants of `Free`
Most useful - for me at least - is being able to run functions individually at the shell prompt. To maximize usefulness, make sure to use many smaller functions at the top level rather than huge monolithic ones. Avoid putting too many functions inside let/where clauses where you can't access them in GHCi. The GHCi debugger is also sometimes very useful. Type `:help` at the GHCi prompt for a list of all commands, and see the [GHC User Guide](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/ghci.html) for more information.
I tried this stack package yesterday (I didn't know about it before) and it's very nice. With cabal you're left solving dependencies of dependencies of dependencies... \^\^ So I think using stack with `--flag` as you do is probably much better than simple cabal. 
Right, in that example I think it works because `f` is mentioned in `newtype Free f`
Nice. Reminds me of [Frets on Fire](http://fretsonfire.sourceforge.net/).
I looked at the [mutable vectors](http://hackage.haskell.org/package/vector-0.11.0.0/docs/Data-Vector-Mutable.html), but they said nothing about the performance of their operations. I have no idea how to use them for the best performance.
Maybe I misunderstood. If I do not implement the vectors, how would I use the vector libraries?
I mentioned `type-aligned` there, but forgot that it doesn't turn on `PolyKinds` for the different sequencing types. GHC does already know that &gt;&gt;&gt; :k TASequence TASequence :: ((k -&gt; k -&gt; *) -&gt; k -&gt; k -&gt; *) -&gt; GHC.Prim.Constraint `TASequence s` expresses a bit more than "`s c` constructs a free category from `c` as underlying graph", I suppose, but that's in fact what all the implementing types do. It does make the claim: TASequence s =&gt; Category (s c) -- no constraint on c :: k -&gt; k -&gt; * I submitted a patch https://github.com/atzeus/type-aligned/pull/10 fwiw that would let me use any of the `TASequence` types for e.g. the `Flight` example above. See the discussion of graph / path in https://personal.cis.strath.ac.uk/conor.mcbride/Kleisli.pdf pp 4 -5 -- and also footnote 3 there.
Eh? What of two calls to the same array producing two different arrays?
I can sketch one, I think... Imagine you have a (first order) language split into 3 fragments: addition, multiplication, and conditional; with type classes, to use these three fragments as a coherent language, all you need to do is say that `repr` instantiates all three type classes (or leave it to inference); with dictionaries, you need to construct an explicit new dictionary type to hold the methods of the fragments; this is made worse if there is a dependency (e.g. the conditional fragment depends on a fourth fragment, e.g. booleans, or integer literals are their own fragment).
As described on haskell.org, stack is a widely used tool to manage Haskell projects, just like people use npm for nodejs, pip for python and leiningen for Clojure. The path of least resistance is going to be to just learn and use stack and get used to using stack to work with GHC . Also occurs to me the easier way to deal with a downloaded executable is put it in a path referenced by your PATH environment variable?
As for purity: graphics is fundamentally impure, so all the GL stuff takes place in the IO monad. The main difficulty was figuring out how the openGL bindings work in Haskell - but that's mainly because the bindings we used are not the raw 1:1 ones, but slightly more abstract . Laziness: There was one time where the music's notes had to be synchronised from all channels to a single 'stream', and the relative timings of the notes turned into absolute times. This, if you do it with a naive foldl, accumulates up a huge thunk at the end (in the Gbs in size), so here we had to use the strict foldl' along with bang patterns to ensure strictness. Laziness was handy though when we needed to pass a game state object as a parameter to a function _before_ the object itself was created. The solution we came up with was exploiting the MonadFix instance of IO and use value recursion for this, which relies on laziness. (take a look at the RecursiveDo GHC extension for more info) General advantage: the hackathon's venue had problems with the wifi, so for the most part we couldn't merge our code at all, so essentially we worked separately from each other for ~22 hours. (We were sitting next to each other obviously, but the sources were air gapped). 10 Am in the morning, it took about 15 minutes to merge the two completely separate branches (graphics and the music backend) into a working version. I attribute that to the modular functional design Haskell enforces.
&gt; Exposing these dictionaries would make it possible to have multiple instances for the same typeclass application, and to specify one when you use the class. This is not a desirable feature (or at least not nearly as nice as it seems at first). Edward Kmett is one of the most vocal opponents of this feature, with an explanation of its downsides [here](https://www.reddit.com/r/haskell/comments/2w4ctt/boston_haskell_edward_kmett_type_classes_vs_the/). The problem in short is that global instance uniqueness guarantees the coherence of composition; to see what can go wrong in its absence consider `Applicative f =&gt; Monad f` and think of everything that can go wrong in writing and using a `Monad` instance if there are two different `Applicative`s for a type (e.g. `[]` and `ZipList`) and you can never be sure which one you'll get in a particular scope.
Thanks a lot for sharing :)
Essentially since Haskell lacks anonymous records it's not easy to mix those dictionaries together. Otherwise we could write a function which did the mixing and this would be pretty similar to an OCaml functor.
I understand how one can use Lists to represent the Free Monoid, but to me Trees seem a more natural representation of this: data Tree a = Empty | Single a | Node (Tree a) (Tree a) data Free a = Mempty | Value a | Mappend (Free a) (Free a) (This also has the benefit of not being Left/Right biased). And yet every time I see people talk about the Free Monoid, they talk in terms of lists. Am I missing something?
Super cool. Been wondering how to do beat detection for a while, I'll definitely take a look. Might consider building a different style game after it too. Always wanted to make a procedural music game. Even more impressive you did in a day! 
&gt; a category Endo (my name, I don't know if there is an agreed upon name) Endo is indeed the agreed upon name. Though some folks choose to call it [End](https://ncatlab.org/nlab/show/endofunctor) instead. (Though I'd avoid that name since there's another thing called "end(s)" so why flirt with causing confusion)
A tree would not satisfy the associativity property for monoids: (a &lt;&gt; b) &lt;&gt; c = Mappend (Mappend (Value a) (Value b)) (Value c) a &lt;&gt; (b &lt;&gt; c) = Mappend (Value a) (Mappend (Value b) (Value c)) But the monoid laws state that these must be equal.
What does Haskell `do` have to do with Ruby `do`. As far as I can tell, comparing it to ruby is irrelevant.
Thanks!
Thanks, just what I was looking for! Couldn't quite intuit that from just a type signature :)
They are often used in syntactically similar ways, especially in DSLs. Compare, for example, hspec and rspec.
Thanks for raising lambdas. I agree and think the same applies to if and case. If the grammar can be made to work for let, I'd like that too!
I thought you could write all functions as list homomorphisms (even strict left folds). Isn't that (basically) how `Data.Foldable.foldl'` works? It's implemented in terms of `foldr` and `foldr` in turn is (conceptually) implemented in terms of the `Endo` `Monoid`. It's sometimes more efficient, too, because if you factor `foldl'` through `foldr` it can trigger build/foldr fusion. However, I will still go ahead and reword it because even though you can trivially factor everything through the `Endo` monoid, it's not useful from a map-reduce perspective since you can't parallelize, serialize or precompute function composition. The only reason the `foldl'`-as-`foldr` trick works at all Haskell is because it's all on one machine, but the moment you distribute the computation the trick doesn't work any longer. By the way, anybody else who is interested in this topic should read the excellent post by Brent Yorgey: [`foldr` is made of monoids](https://byorgey.wordpress.com/2012/11/05/foldr-is-made-of-monoids/)
When I started reading I assumed that this was going to be about MapReduce, but it seems not. In fact MapReduce is not map followed by reduce at all (apparently, according to http://userpages.uni-koblenz.de/~laemmel/MapReduce/paper.pdf). `mconcat (map k xs)` is nice but I'm not sure what the category theory was for. 
[removed]
You choose the case where `m` is the `Endo b` monoid, so the type specializes to: foldMap :: (a -&gt; b -&gt; b) -&gt; [a] -&gt; b -&gt; b ... which is just `foldr` with the arguments in a different order, and `foldr` is just how you church-encoded lists, so it's the most general function possible on lists (at least, within System F)
I'm a bit confused. I thought /u/sclv was claiming that every function on lists can be rewritten as `foldr f1 z1 . mconcat . map u` but maybe he's not.
Yes, I think I've got that part slightly wrong. I need to think a little bit more closely about this
Yes, but I *especially* don't believe that every function on lists can be written as `foldr`! A proof of that would be even more interesting.
It's because sometimes we get extensions that require near unanimous approval, and sometimes we get extensions that the public doesn't get a say on. I suspect that sticking this behind a pragma would garner more than 50% approval, but we have some extremely squeaky wheels rolling around in here.
Thanks for the pointer.
I didn't realise it wasn't behind a pragma. I'd like it without but can understand that others wouldn't.
It was. I'm saying that if there was a popular vote, this would get something around 75-85% approval. That's not enough for a proposal to clear the trial by mailing list.
I was able to get ghc 7.6 working on the standard light weight os for pis. I think it's called rasberian. I'm not sure if I tried archlinux 
The lack of test suites is a little frightening... but overall looks cool
Right, I get you. I recall that there even *was* a vote for the FTP change and some people couldn't live with it. (Funnily enough, I voted for FTP but this evening I happened to show someone the types of join and concat in ghci. It did make the type of concat awkward to explain.)
Yeah, the nay sayers are not without valid arguments. It's just where different people want to find a balance. I think FTP would be massively easier to deal with in a teaching setting if we didn't have a default Prelude (so we could do something like Racket language levels as seen in HtDP), but others say that using different Preludes would make reading code too difficult.
To complete this exercise, we can resolve `foldFree` into the familiar two phases like so mapped :: (forall x y . graph x y -&gt; graph' x y) -&gt; (forall x y . Free graph a b -&gt; Free graph' a b) mapped phi s = case s of Nil -&gt; Nil Cons g rest -&gt; Cons (phi g) (mapped phi rest) reduced :: C.Category c =&gt; forall x y. Free c x y -&gt; c x y reduced Nil = C.id reduced (Cons now later) = reduced later C.. now foldFree' :: C.Category c =&gt; (forall x y . graph x y -&gt; c x y) -&gt; (forall x y . Free graph x y -&gt; c x y) foldFree' phi = reduced . mapped phi 
Totally 
Given that it's a toy application, why is it frightening?
ref: [Routing](http://snapforbeginners.com/chapters/routing.html)
Just because it's the same word, doesn't mean it's the same syntax. You wouldn't compare the capitalization of C++ `void` with Haskell `Void`, would you?
One way around the lifting is to use something like [Church Free monads](https://hackage.haskell.org/package/free/docs/Control-Monad-Free-Church.html). For example, something like: type EnvIO = forall r. (a -&gt; r) -&gt; ((env -&gt; r) -&gt; r) -&gt; (String -&gt; r) -&gt; ((String -&gt; r) -&gt; r) -&gt; r and then you do act = \return read putStr getStr -&gt; --code goes here I haven't figured out a way to use do notation in the lambda, but I'm pretty sure there's a way to do it with a `join` variant or something. I should go get some sleep though, so uhm \* *waves hands* \* exercise for the reader.
&gt;('x':) $ do { return 'y' } &gt;('x':) $ if True then "hello" else "goodbye" I don't consider `$` here a noise, on the contrary, it notably helps to read and parse this code, espicially with the right color scheme. &gt;show Rec { a='a' } And this line is a lot harder to read in absence of `$`, because if I didn't know that `show` takes only one argument, my first thought would be that function `show` here is applied to two arguments: `Rec` and some bizzare `{ a='a' }` thing. I think show $ Rec { a='a' } is much clearer. 
Sorry, yes, after complaining about a certain imprecision, I was guilty of one of essentially the exact same form. "functions on lists can be written in the form `foldr f z`" should have been "we consider functions on lists that can be written in the form `foldr f z`". There are functions on lists that are of course not folds :-)
I very strongly agree and like this syntax much better. Having used it in PureScript extensively, it is uniformly better and clearer.
I know I'm late to the party, but thank you /u/mightybyte! A very well-designed tutorial. Given that I think I'm in the cohort you're targeting (been programming in haskell for a little while but not grokking monads yet), I thought I'd mention that exercise 4-4 was basically a brick wall for me. I beat my head on it for several days before giving up and had to read some existing code to see what I was missing. Not sure what the best way to resolve it is, but implementing the instance for `Gen` was something I just couldn't do after the exercise build-up.
i found the explanation of raichoo more helpful: https://vimeo.com/146374255
I'd just follow the instruction at http://haskellstack.org :)
Eager? They don't seem to understand Haskell ;)
I think the condition that `liftAsk` be a monad homomorphism is equivalent to `lift :: Reader r a -&gt; ReaderT r m a` being a monad homomorphism.
OK, so you might end up with expr :: Addition repr -&gt; Multiplication repr -&gt; Conditional repr -&gt; repr expr add{..} mult{..} cond{..} = ... and then you have to plumb around those dictionaries by hand.
I actually agree about the record syntax. It really looks like function application, which it is not. I also agree that do example doesn't illustrate a big problem. But DSLs that use do suffer in my opinion: it "returns the first element of a list" $ do head [23 ..] `shouldBe` (23 :: Int) 
It's ARMv7 but the The raspberry pi 1 is ARMv6.
I agree with you. There is probably some obscure parsing reason. AFAIU you need something after the do, so the `$` before seems irrellevant. Moreover, do people actually know how do do print "foo" ; print "bar" is actually parsed ? and why `do (do print "foo")` is valid whereas `do $ do print "foo" doesn't compile ? 
I'm not sure I am understanding the impact of your statement. Are you saying that `ReaderT` will be the only possible implementation of `MonadReader`? If that's the case, `e -&gt; s -&gt; (a,s)` should also do just fine as a `MonadReader`, though we can see it as `ReaderT (State s) a`, which is maybe what you mean.
Ta!
Has anyone actually got good mileage out of extensible effects? From my quick glimpse of the article it didn't seem to mention it.
The existence of the straightforward patch rather proves that the language can be parsed without $. I don't know about your do do question though!
Thanks for the reply. By overheard do you mean runtime, compile time or syntactic?
The layers here to handle the situation, and how much conceptual overhead you need to grok before we get to the "business logic" as they say in the wild, is just absurd. This is why I only lurk Haskell these days and don't really code in it anymore. This is the quintessential jam where you end up serving the type system rather than it serving you, or it becomes a rude and clumsy servant at the least. I'm not just trying to take potshots, but actually I like Haskell and I hope the language doesn't settle for these, IMO, unsatisfactory solutions, but keeps fighting and makes all this a bad memory at some point.
Runtime, see https://github.com/feuerbach/freemonad-benchmark, though I think `extensible-effects` as it stands has a syntactic overhead too - the last time I tried to play with it it failed miserably in the face of inference, requiring me to important a load of symbols like `:&gt;` just to get the thing to type check.
Personally, I disagree - I find that most other languages that just "fire and forget" when it comes to business logic actually end up biting you in the ass pretty fast. The reason we care so much about effects in Haskell is because they are darn tricky to get a handle on. I *want* the type system be loud and make me think, because which effects I use and how I use them has significant implications for what the programs I write *do*.
It looks like there is an error in the code example using `Free`. I think this is the function that you want: getLine :: Free TeletypeF String getLine = liftF (GetLine id) But your post uses `liftF (GetLine return)` instead. While testing this I discovered that `iterM` was only added to `Control.Monad.Free` in version 3.4.2. And instead of `readLine` I used `Prelude.getLine`.
Can you help me fix this code: main :: IO () main = quickHttpServe handler handler :: Snap () handler = do param &lt;- getQueryParam "greeting" maybe (writeBS "must specify param in URL") writeBS param 
Where is the syntax czar when you need them!
Keep in mind that this exercise is for writing very library code, not application code (though of course a lot of application code should be library code, so maybe my argument is not so strong). Also, there aren't really a lot of types involved here, so I'm not sure I even see the problem. This is just a design technique. I think this is like me reading some blog post on writing games and saying there's too much C++ bullshit for me to take it seriously. 
The raspberry pi 2 does work though, and the larger memory makes it a much better experience running GHC.
I think you're just missing imports and pragmas in the beginning of the module: {-# LANGUAGE OverloadedStrings #-} import Snap.Core import Snap.Http.Server 
I've always heard that Freer is as fast as MTL or faster, based on the papers I read. Surprised how much slower it actually is
There may be some fixes/ minor improvements to the existing optimization passes, but no new passes are added.
I think that we need more objective evidence. Something like in [my other comment](https://www.reddit.com/r/haskell/comments/447bnw/does_argument_do_have_a_future/czoteou). Of course, it will introduce the negative effects as pointed out by [Taladar](https://www.reddit.com/r/haskell/comments/447bnw/does_argument_do_have_a_future/czor6s8) but I feel that having a choice in this case is better than not having a choice. 
This package works on the assumption that every function has a type signature. Initially I find out the ADT declarations within the file, by checking for the data keyword. Then I go through all the functions, and if a function has an ADT as an input, I generate the stubs for that function.
While that is significantly better, it's still 3-4 times slower than MTL. Regardless, I've really enjoyed learning about Freer. It seems really effective, but I can only imagine the absurd learning curve there'd be if it were the norm. Haskell is already hard enough to get into just with the concept of Monads. Transformers are a natural logical step to take. Freer is a whole other level of abstraction.
I guess I didn't explain myself clearly. I have no doubt that it's backwards compatible. I'm worried about writing new code which under the old regime would have a syntax errior, but which under the new regime will be a type error (or no error at all). For example `1 if c then t else e` is a syntax error today, but without needing the $ it would be a type error (maybe). So just because something is 100% backwards compatible doesn't mean that it comes without a cost. Haskell is already so terse that there is very minimal syntactic redundancy, and I'm worried that allowing even more syntax will make this even worse.
I was hoping there would be something related to Free monad optimisation. I want to give them a shot, but hearing phrases like "100x performance loss" gives second thoughts even when performance wasn't a major concern to begin with.
It depends on what you consider an optimization. Completely new optimization passes are rare. The last one was added in the 7.10 release cycle by Joachim Breitner: [CallArity](https://ghc.haskell.org/trac/ghc/wiki/CallArity). For 8.0, Adam Sandberg Eriksson added [-XStrictData and -XStrict](https://downloads.haskell.org/~ghc/8.0.1-rc1/docs/html/users_guide/glasgow_exts.html#strict-haskell). They are language extensions, not compiler optimizations, but they might make your code run faster nonetheless. Joachim Breiner created https://perf.haskell.org/ghc, which should help spot accidental performance regressions and monitor long-term performance evolution. See for example the nofib benchmark results for [7.10.1 vs 8.0.1](https://perf.haskell.org/ghc/#compare/ca00def1d7093d6b5b2a937ddfc8a01c152038eb/53dfaf723548001fc4ff0d40793ec1abe5d23dce). There is a [wiki page](https://ghc.haskell.org/trac/ghc/wiki/Performance/Runtime) to keep track of some of these results. There are currently 245 open [tickets]( https://ghc.haskell.org/trac/ghc/query?status=!closed&amp;failure=Runtime+performance+bug) concerning runtime performance. Throughout the year some 20 runtime performance bugs were [fixed](https://ghc.haskell.org/trac/ghc/query?status=closed&amp;failure=Runtime+performance+bug&amp;resolution=fixed&amp;milestone=8.0.1&amp;milestone=7.10.3&amp;milestone=7.10.2), by such fine people as: * Ben Gamari (#8832, #5916, #9105, #10457, #10678) * Simon Brenner (#11486) * Flaviu Andrei Csernik (#8435) * Jonas Scholl (#8793, #10372) * Michal Terepeta (#9430) * Takano Akio (#9848) * Marios Titas (#10067) * Joachim Breitner (#10129, #10137, #10260, #10744, #10750, #10788, #10677) * Simon Peyton Jones (#10148, #10359) If you want to help improve GHC, and get your name on a similar list for the 8.2 release, start with the [Newcomers](https://ghc.haskell.org/trac/ghc/wiki/Newcomers) page and the [reading list](https://ghc.haskell.org/trac/ghc/wiki/ReadingList#Optimisations).
Yes, it's always the case with new syntax. Consider the just added explicit type application. It's great that we have it but it'll be very hard to use it and still make your code compile with old GHCs without having to resort to the ugly CPP. Which is why for the next 3 releases people will probably stick to `Proxy` trick and only after that it'll be safe to use explicit type application and be backwards compatible 3 releases back. Same here. It would be good to have it and use it in executables or tests, for example. But most likely library authors would shy away from it for at least 3 releases and just keep adding the `$`. &gt; allowing even more syntax Yes, which is why my second part of the test was supposed to prove that no ambiguities will be introduced. Until we do such a test there will always be this lingering doubt that you raise (which is fair to raise, of course). 
Your server doesn't return control back to stack loop. I run server in a bash loop instead and `--exec killall servername`.
I suspect that Church Encodings are generally a bad idea (too complex), and hope that the Haskell community will get over it. (That might require better optimisations for cases where functional encodings currently perform better than ground data.)
This is really interesting. Are you interested primarily in learning the language, or applying it? It seems that they are quite different tasks.
Use `-fprof-auto` or even `-fprof-auto-calls`?
Thanks :)
What would a more satisfactory solution look like to you? (I'm not asking for a fleshed-out haskell design, but a pointer to some code different language with a sentence or two of explanation, or a small outline of an idea would suffice) I ask because I really enjoy using mtl, because as ocharles said actually handling effects is really difficult. I also find that often my business logic is not in the mtl creation per-se. For instance, I use the mtl library to give build a WebServiceClient monad, and the actual business logic a small chunk of code in a do block.
Hmm, this does seem suspicious, I've filed https://ghc.haskell.org/trac/ghc/ticket/11544#ticket to investigate. Thanks!
I'm not that knowledgeable about this side of the theory, but isn't MonadReader more like a crutch so we can have coeffects/comonads in a monadic context? Coeffects seems to be an underappreciated topic although we use them every day, so we may have just accepted the crutch. (Streams, the required existence of a GPS sensor on a device, function constraints, even the existence of a 'map'-function and package dependencies can be seen as (indexed) coeffects, as far as I understand.) So should MonadReader not be evaluated against Comonad laws instead? And as a follow-up thought: Do we even have a decent theory to define an action as monadic in x and comonadic in y? A constrained kind of Arrow, perhaps? I'm sorry to barge in on the discussions with my general ignorance, please take it as such instead of criticism.
I'm beginning to hit the point sherdogger has hit. Doing simple things with transformer stacks is possible, but when I try to build up larger abstractions, you have to deal with stacks of monads, maybe some you've made yourself, then deal with resource cleanup, then deal with libraries that are locked to IO and won't fit into what you've written, and it just keeps going on and on. I spent the last four hours trying to write some reusable database code that doesn't require I specify tons of type information at call sites and I just can't do it. I'm simply not smart enough to make the types work out. It is making me wonder if I shouldn't move on to scala or rust or something. I just need some practicality to get anything done.
&gt; I believe if transformers would just INLINE a few more definitions, the cost [of using monad transformers] can be entirely erased. I haven't heard this before. Is this the case? If so, why hasn't it been done?
I tried using cabal to install stackage and got esolving dependencies... Configuring stackage-0.1.0.0... Warning: The 'license-file' field refers to the file 'LICENSE' which does not exist. Building stackage-0.1.0.0... Preprocessing library stackage-0.1.0.0... In-place registering stackage-0.1.0.0... cabal: LICENSE: does not exist Failed to install stackage-0.1.0.0 cabal: Error: some packages failed to install: stackage-0.1.0.0 failed during the final install step. The exception was: ExitFailure 1 :( From stackage.org: &gt; NOTE: Requires GHC 7.10. For GHC 7.8, please change the URL to Adding a LICENSE file allows `cabal install` to complete. Some awesome error reporting there, cabal. Update: So, long story short: I'm building GHC. 
It's just a [bug](https://mail.haskell.org/pipermail/ghc-devs/2016-February/011286.html).
TIL about levity polymorphism. Cool. These threads are always interesting to read. 
I think the fundamental problem of this post is that you can't invent algebraic reasoning without checking that your symbols have the right semantics. For the presented "forgetful functor", I've looked for the source category, the arrows of that category, and its action on those arrows, and came out empty-handed (see last paragraph). I've done this in so much detail because I was trying to actually get the details -- if McBride likes the post, I should initially assume I'm probably missing something. I'm afraid this explanation requires actual category theory, but I've tried to express it in Haskell terminology. # Actual forgetful functors The real forgetful functor `U` for monoids maps a monoid `(m, mempty :: m, mappend :: m -&gt; m -&gt; m)` to the underlying ~~set~~ type `m`, forgetting its operations. If you want, `U (Monoid m, m) = m`. But even that is confusing. What matters to have a functor `U` is the action on arrows (or "functions"); `U` must map arrows in the category of monoids to arrows in the category of ~~sets~~ types. An arrow of monoids `f` between monoids `m` and `n` is a monoid homomorphism, that is a function with a proof of some properties. Most definitely, it is not an arbitrary function from `(m, mempty :: m, mappend :: m -&gt; m -&gt; m)` to `(n, mempty :: n, mappend :: n -&gt; n -&gt; n)`; its type is still `(m -&gt; n, &lt;type of the right proof&gt;)`. The forgetful functor maps it to the underlying function, just forgetting the proof that it is a homomorphism. If you think that proofs are values (as in Agda/Coq/...), you can actually visualize this as a projection. # Resolution The reason why the equation almost work is that, even though `Monoid m =&gt; m` is not the object we want, the type `[a] -&gt; (Monoid m =&gt; m)`, for **fixed** `a` and `m`, still *kind of* represent the right type of functions. What we want are monoid homomorphism between the free monoids of lists and the monoid `m`. Because of the real adjunctions, all monoid homomorphisms are simply produced by appyling the isomorphism `foldMap` to a function `f :: a -&gt; m`, so they are of form `foldMap f`. This seems to have type `Monoid m =&gt; [a] -&gt; m` for a fixed `a` and `m`, so this all seems to work out. Unfortunately, while this explains why the manipulations work out in the end, it's still incorrect reasoning. First, an actual monoid homomorphism in fact has just type `[a] -&gt; m`, because we can't pick which `Monoid m` instance to pass any more. But this type includes much more than monoid homomorphism, because we already absolutely had to pick `a` and `m`. For instance, if `m` is the monoid of natural numbers and addition, for any `a` we can write `const 2 :: [a] -&gt; m` which is *not* a homomorphism. So the isomorphism will not be from `[a] -&gt; m`, but from a subset. (The described isomorphism, indeed, will probably map `const 2` to `foldMap (const 2)`). # What could the object `Monoid m =&gt; m` be? What's actually `Monoid m =&gt; m`? It must be an object in some category, so let's say it's an object in the category of Haskell types. It should in fact be an object in the category of monoids, but I don't see how that's possible. So let's try for a second to follow through with Haskell types, and see if this leads anywhere. We actually want a monoid object, so that arrows into `Monoid m =&gt; m` are arrows into the monoid and produce a monoid element. I first thought of `∀ m. Monoid m =&gt; m`, then of `Monoid m =&gt; m` for a fixed `m`, but they are both wrong (since they are types of functions). The only actual value of the first type `∀ m. Monoid m =&gt; m`, by parametricity, are composed of `mappend` and `mempty`, so they are all equal to `mempty`. I think you shouldn't consider the open terms of that type, because in a semantics open terms map to functions. The second type `Monoid m =&gt; m`, with fixed `m`, is more confusing, since it seems a function from a monoid instance. That's not been, until now, one of the characters of our adjunction story. Or is the point that once we fix `m` we actually also know `Monoid m` because of coherence? Maybe that makes a bit more sense after all (though I don't like coherence), but then, why aren't we just writing `m`? To have a functor, you even need to give it an action on arrows, but here it's not even clear what are the arrows between `Monoid m =&gt; m` and `Monoid n =&gt; n`. 
In fact, given the above discussion, we want `Free f :~&gt; m ≅ f :~&gt; m`, where the function space on the left in fact includes only monad homomorphisms (whatever they exactly are).
I pushed other syntax issues a bit further; the next step is that SPJ requires a wiki page to describe what you want. I did this as requested, and never heard back. It's very frustrating that you need to recapitulate things so repeatedly, but that's the process. Potential vetoes are thomie, Richard, and Simon. If they object, I don't think there's a way forward.
Do you consider using `(do ...)` (as some people do) a syntax variant ? Or mine (which I don't use) which I *introduce* a new keyword `$do` ;-)
Thanks! The first and third are, as you may guess, the result of slightly changing examples. Second is a good observation! I allowed myself custom utility functions in those examples but that one should probably be explained. Edit: All three attended to!
The presence of those methods do offer up a story about `Reader` that is a fair bit stronger than you let on in the article though. They may be confusing, but they are enough to supply guarantees about behavior.
Probably, but it's also a dead end. $ cabal install stack Resolving dependencies... cabal: Could not resolve dependencies: trying: stack-1.0.2 rejecting: base-4.6.0.1/installed-7d8... (conflict: stack =&gt; base&gt;=4.7 &amp;&amp; &lt;5) rejecting: base-4.8.2.0, 4.8.1.0, 4.8.0.0, 4.7.0.2, 4.7.0.1, 4.7.0.0, 4.6.0.1, 4.6.0.0, 4.5.1.0, 4.5.0.0, 4.4.1.0, 4.4.0.0, 4.3.1.0, 4.3.0.0, 4.2.0.2, 4.2.0.1, 4.2.0.0, 4.1.0.0, 4.0.0.0, 3.0.3.2, 3.0.3.1 (global constraint requires installed instance)
1) yesod 2) servant
But that is fixable! I know because I've modified stack to build on GHC-7.6.3. Also, check for a pre compiled stack binary on their download page. However, the most direct route is to compile a newer GHC, which will take several hours.
Doesn't seem like it's considered a bug at all: https://mail.haskell.org/pipermail/haskell-cafe/2016-February/122921.html
From the linked response: &gt; Yes, absolutely, ($)'s type is quite ugly. In other areas, I've tried to hide the newfound complexity in the type system behind flags, but I missed this one. I consider the current output to be a bug.
No one seems to be building arm64 targets. Not stack, not haskell.org. This looked promising: http://downloads.haskell.org/~ghc/7.10.3/ghc-7.10.3-armv7-deb8-linux.tar.xz But when you untar it, it's just a source distribution. I guess I'm waiting the several hours (at best; these little phone processors are not quick) and then I'll attempt to donate my build product to haskell.org and stackage.org.
It is probably a direct result of the fact that record updates are not a first class value with its own type, associativity,... in Haskell.
A bit simplified, we have 5 general precedence levels in expressions: x :: T -- annotated expression a + b -- infix expression (with finer grained precedences among ops) if, case, \-lambda, do, let f x -- function application v, c, (x) -- aexpr (variables, constants, etc.) Now you see that, because `do { expr }` has a lower precedence than function application, it cannot appear as a function argument, but it can appear in (the right argument) of an infix expression. All that is needed is to simply say in the parser that do { .... } is an aexpr, aka term, and that is it then. This is particularly easy because the construct starts with a keyword (at which point the parser can already commit itself that it is parsing a term) and is clearly delineated with the braces (which are there, even if you don't see them). Note that the same would not be possible (or at least practical) with the conditional `if` and `let { .... } in ...` and `\ -&gt; ...` because they're not delineated, so in f if b then c else g h the `h` could be an argument for `g` or another argument for `f` (which would require at least another disambiguation rule). Nothing of that sort is needed with the `do`. By the way, not only purescript, but also Frege treat `do` this way. The charme of the proposal lies in the fact that all existing source code will continue to compile, since an aexpr (or term) can of course appear as the right operand of an infix operator, that is `$`.
Hard to believe this is 20 years old now :-) http://www.cs.nott.ac.uk/~pszgmh/monparsing.pdf
Codensity! Coroutine monads like the ones in **pipes**. Also some cofree comonads can be monads as well, there was an interesting [SO question](http://stackoverflow.com/questions/16551734/can-a-monad-be-a-comonad/16552594#16552594) about it. &gt; Concurrent This is more of an applicative, isn't it? One of my own harvest: while fiddling with the [monadic folds](http://hackage.haskell.org/package/foldl-1.1.5/docs/Control-Foldl.html#t:FoldM) of the **foldl** library, I derived a [monad instance for monadic folds over ExceptT](http://hackage.haskell.org/package/foldl-transduce-0.4.7.0/docs/Control-Foldl-Transduce.html#t:Fallible). It is a monad over the error type: return constructs a fold that starts in a failed state, and bind says "if the current fold fails, construct a new fold from the error value and continue folding with it". It is not a very useful monad... 
The base syntax of `do` is do { Q } where *Q* is a list of qualifiers, separated by semicolons, and a degenerate case of *Q* is simply an expression. Therefore do { (do { print "foo" }) } is correct, the most work here is doing the part of the compiler that implements the layout rule. If and when this is done, the parsing is straighforward. OTOH, do { $ x } must be a syntax error, since `$ x` is not an expression (and also not one of the other two possible forms of a qualifier).
You're not the only one with that line of thought. /u/funfunctional has expressed similar views to yours, and while some people might think their tone warrants a ban, I think the points they raised are very valid and very true. I'm a solid haskell beginner: have been for years. I've read countless blogs, haskellwiki pages, attempted diving into papers, subscribed to the mailing list. All the while thinking that I had to be "more prepared" to write "more idiomatic" code. Just like you, I saw posts coming in the planethaskell aggregator and thought that's the way it's supposed to be done, and whenever I tried to sit and code something, it always ended up being an awful chunk of imperative code running in IO. It just looked wrong. So I've always been hesitant to just try and write stuff in haskell, because I can't get that voice out of my head screaming "there's probably a better/more abstract/more idiomatic way of doing this!" And so while /u/funfunctional's comments were received with a load of downvotes, they help me realize I've been looking at it the wrong way all along. When learning python you don't try and get a good grasp of all patterns, of all that you can do with metaclasses or whatever, before sitting down and typing some code. You don't try to build a tower of abstractions through inheritance. Why should haskell be any different? EDIT: /u/lamefun has expressed similar views with a similar result.
Really, how so? `local _ = id` works for any monad, and there's nothing in the documentation about how `local` and `ask` need to interact. That's kind of what I'm getting with the lack of laws in `mtl`.
Except for the `runST $ do` typing hack, which incidentally would be unnecessary if [argument do](https://www.reddit.com/r/haskell/comments/447bnw/does_argument_do_have_a_future/) were available.
Yes, this bothers me so much, and I still explicitly parenthesize record syntax in silent protest
Really interesting, thanks!
On a related note, I wonder if argument do would help in the "teaching newbies requires explaining $" argument? Not that I have given it much thought...
Can you link me to an explanation of this `$` hackery? I know I've read about it before, but I don't know where, and Google is failing me.
Servant can serve "articles, categories, comments", I think the "user interaction" you're looking for would be implemented with a front-end framework like angular, react, reflex-dom. But yea, no reason you couldn't implement authentication and/or an admin panel.
Well, one thing to keep an eye for is that a lot of "exotic" monads will turn out to be variants or combinations of common ones. For example, you bring up Bayesian/Probablity monads, but [as this article shows](http://www.randomhacks.net/2007/02/21/refactoring-probability-distributions/), those can be modeled as a monad transformer stack: -- A pair of a value and a probability. The article presents this type as -- a probabilistic analogue to `Maybe`, but to my eye it's a `Writer` -- with some additional structure (probabilities are a monoid, but also -- have extra structure that the operations will want to expose): data Perhaps a = Perhaps a Prob deriving (Show) instance Functor Perhaps where ... instance Applicative Perhaps where ... instance Monad Perhaps where ... -- The monad transformer that corresponds to `Perhaps` newtype PerhapsT m a = PerhapsT { runPerhapsT :: m (Perhaps a) } instance Functor f =&gt; Functor (PerhapsT f) where ... instance Applicative f =&gt; Applicative (PerhapsT f) where ... instance Monad m =&gt; Monad (PerhapsT m) where ... instance MonadTrans PerhapsT where ... -- The "probability monad" `Dist` is a transformer stack: type Dist = PerhapsT [] 
Ended up taking about 4 hours.
This sounds useful! Do you have some example code?
Woah! @MitchellSalad - I'm the author of steeloverseer. I'd really appreciate it if you made a pull request! I can get your changes up on hackage.
I just went and did it for you.
Well, any tool that needs to parse Haskell should use the GHC API anyway. For robustness and completeness. 
I would second `snap` if you are looking to build a blog, as snaplets deliver great features to kick start your project. If you want to build something front end heavy (i.e. SPA) then definitely `servant` for the service layer.
I am not quite that strict about it but the original question was after all why 50% should mean that the ones in favour of the change should lose instead of win. As for optional syntax, I am more thinking of things made optional for no reason like the change proposed here or e.g. optional parentheses on function calls without parameters or optional braces in C++ around single statement blocks,... I am not limiting my statements to Haskell in particular. I have just seen how annoying languages with lots of these are to read.
I really like the idea of these monthly updates, but I hope it's okay if I make a tiny request: can we get maybe a paragraph of additional editorial about what's happened? The list of closed issues can be disappointing because sometimes I see something that sounds interesting, but the issue was only closed because, say, the discussion moved elsewhere. Just a few words about the overall project to say, "TL;DR: Design still being fleshed out." or "You should try haskell-ide-engine today if you're interested in X!" would be greatly appreciated.
Any time something is "freely" generated, you probably have a monad on your hands. Haskell's (fake) category "Hask" is pretty anemic in its structure, so there aren't quite as many interesting monads. But there are plenty of interesting examples if you stop thinking about programming for a minute. A free commutative monoid on a set X gives you a multiset monad. Free vectorspaces are formal linear combinations of a set X. This is a useful thing to think about when doing machine learning, where X takes the role of your set of features. If you're doing algebra, the free algebra of a set X are the polynomials whose variables are drawn from X. (For instance, for X={s, t}, the free algebra is the polynomials in s and t). Given a digraph, you can generate the free partially ordering on the set of vertices. For a package manager, this would mean that while each package only tells you its immediate dependencies, you can tell (given all of the packages involved) when one package has a dependency on another. There are many purely theoretical places monads can appear. Any kind of closure in mathematics (algebraic closure, topological closure, compactification) is generally hiding a monad. One example you can see in Haskell is the double-negation embedding, which sends a type A to (A -&gt; Void) -&gt; Void. While it is undecidable if A is isomorphic to its double-negation, the double-negation of a type will be (constructively) isomorphic to its 4-fold-negation: @djinn ((a -&gt; Void) -&gt; Void) -&gt; (((a -&gt; Void) -&gt; Void) -&gt; Void) -&gt; Void &lt;lambdabot&gt; f a b = void (b (\ c -&gt; void (a c))) 
And 30 years we (Kent Pettersson, I think) used parser combinators in a course at Chalmers. And 40 years ago Burge wrote about them in his FP book. :)
As if I needed yet another reason not to use `($)`
Wow, super simple solution that works pretty well. Thanks!
Ahh, that makes sense. So, bind the `a` to the specific `rep`, from the point of view of `cons`.
“Good-natured” or no, this is quite childish.
1) servant 2) servant It is pure awesome. Honestly though, for just a blog, I would use an off-the-shelf solution like Ghost, Hakyll/Jekyll, Wordpress, etc. In all the Haskell frameworks you'll be doing quite a lot of plumbing to build one of the most common types of website on the net.
Well, the magic is now part of the language. 
doesn't servant have a new project generator-skeleton? like in rails "rails new my_project".
GHC on AArch64/Arm64 seems to mostly work for me. I haven't done very much more than build GHC itsefl though. The bit that doesn't work is GHCi. The problem is the run time linker. Edit: And then I realised that I have a patch I should get commited.
I am actually just about to start on a personal project and this looks perfect for it! I will definitely give this a try. 
I also don't like `($)` because it makes Haskell code look like operator soup to people who don't use Haskell. I wrote more about this [here](http://www.haskellforall.com/2015/09/how-to-make-your-haskell-code-more.html).
I use yesod in production, and I ended up using only a small part of its features. IMO, it's a bit too opinionated. 
Some people just want to watch lisp everywhere. 
I'm pretty sure its an APM X-Gene: https://www.apm.com/products/data-center/x-gene-family/x-gene/ 
Just started reading this. I'm in a compilers class in my university right now, so I have parsers on the brain. Don't have much experience with Haskell, but this looks like fun. Thanks for writing it! edit: Wow this stuff is really cool. It took me a bit to make my own `string` (with Data.Traversable, hoo boy a large chunk of that was just reading what Applicatives were...) but it was worth it. This might be what gets me into finally seriously learning Haskell...
Just started learning about parsing with Haskell recently, although using Parsec. Seems like it's much more popular. I think I'll still give this a read, though. It looks pretty solid.
Great stuff!
Yesod is alright, but it just feels like a more complicated Snap to me. I don't think I really use Yesod (CircuitHub is built on Yesod) in the way it was intended, hence that feeling.
http://stackoverflow.com/questions/1012573/getting-started-with-haskell#answer-1016986
If lens can not do it alone, for sure servant will do it. It would be a whole lot of work, much more than with other libraries, but it is pretty and type level and it is servant (and lens)
Yep, http://blog.chaps.io/2015/10/13/torrent-client-in-haskell-2.html
It's a good idea. Here's a paper about it: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.34.4704&amp;rep=rep1&amp;type=pdf (BTW, the solver that cabal-install uses today employs this strategy.)
See also http://www.well-typed.com/blog/2015/03/qualified-goals/ for this particular example.
&gt; Yesod and ... Snap and happstack, I'd say. Both are relatively straightforward web servers (so not frameworks) without many frills.
Why is `Reader` exotic?
I guess that's not an option on a Raspberry Pi 2 B. ;)
I've never heard anyone refer to the monoid operation as "the law of composition". Also, I find it really strange that after all this talk about monoids, your function instead works on Integers. The rules for integer exponentiation are well known to most people and giving them a new name hardly achieves anything. You should have implemented the function for any Monoid and the shown a few specializations. 
So do I. It also makes it explicit that you are applying a value (given by do) to a function. runST $ do ... seems clear and natural to me -- we're applying the result of the do to runST. However: runST do ... looks more like magic (which Ruby is very fond of), and can be confusing to readers, especially beginners. It looks like a special form like Ruby's "while ... do" instead of just function application.
The only case when I use `($)` is running some `do` block or when using 'trailing lambdas'. Ex.: command1 = runStuff $ do r &lt;- this that command2 = forM_ [1, 2, 3] $ \x -&gt; print x I really don't want to obscure this with parenthesis. What is your stance on that? And, if you know PureScript, what do you think about changing the grammar in the same way such that no `$` is needed in those cases anymore?
&gt;In my experience, most monads in "real world" projects are a combination of IO, State, Reader, Writer, Either and Maybe. Just a consideration from the stratosphere: I´m preaching in the wild desert, but monads are not only an abstraction suitable for computer science problems but of computer engineering, which is a different field. Engineering need more complex and high level effects that are not usually considered by computer scientists. But engineers consider them as the "akward squad" that have no elegant mathematically-sound solution. For example, threading, concurrency, cloud computing, web navigation, web page interaction, IO transactions, GUI rendering, asynchronous inputs etc. You are assuming typical computer science monads, for typical computer science problems and some akward engineering solutions for the higher level effects. That is not ambitious enough. If there are no well know monadic abstractions for these problems (they are, I have done monads/applicatives for them) is not because they are impossible, but because they are not researched, since the computer scientists and the software engineers are two disjoint groups with rare exceptions and because each group dismiss the other and each one stick to his tradition of doing things the way they know. Sometimes the two mentalities are in the same person.
I agree, but you didn't generalize it at all! It feels like all this monoid talk it just an aside to a fast integer exponentiation algorithm. It's fine starting with a concrete implementation.
Ok, your comments are very much welcomed, i'll rewrite a little the post to come naturally from generalization to the special exponential example. Thanks again
I would use a function that receives an initial node, a neighbor function with costs and a "is target" function. `findCheapestPath :: Hashable a, Ord c =&gt; a -&gt; (a -&gt; [(a, c)]) -&gt; (a -&gt; Bool) -&gt; Maybe [a]` The `Hashable a` is to store it in intermediate data structures in the algorithm, could also be `Ord` instead, or getting a comparator function. `c` is a cost value so it needs to be ordered. You could easily write a generic path finding algorithm based on this signature, for example Dijkstra. You can also add a heuristic function for optimization. The return value is Just the list of nodes in the path or Nothing. For out specific problem: * Nodes are (Place, Time), allowing for "waiting" as a legal move. * Neighbors are flights available from one (Place, Time) to another (Place, Time). Waiting would be just moving in Time rather than Place. * Cost could be "price", "time", "hops" or any other combination. * For the "use only a single/given airlines", the neighbors could be filtered to the specific airlines and/or having an infinite price for switching airlines. * Shortest path would put cost as "time" or "count". * Cheapest path would put cost as "price".
How is lens relevant in this context?
Why would it help with that? $ is used in plenty of contexts where do isn't even involved.
Isn't any sort of argument along the lines "the pretty printer should print something simpler" basically just a beginner's version of the language forced on everyone if that simpler type is really a lie?
Why does the kind of the codomain have to be in this particular form? Is there a "simple" explanation for this new notation?
Regarding `extensible-effects`, there is also a tradeoff between extensibility (1st criterion) and inferability (5th criterion) that is explained [here](https://github.com/suhailshergill/extensible-effects/issues/31#issuecomment-100666123) by the maintainer of the library. I'm not sure whether it is intrinsic to Free monads or specific to this particular implementation, but you might be interested in mentioning it in your article.
I didn't. Found them on the internet.
I only have 7.10.2, so I don't know if there is a specific 7.10.3 issue. I followed the steps in this gist, although it's possible I missed something minor or made a typo: https://gist.github.com/dmcclean/bc0c5a858ef188989b06
It's not. As a Haskell beginner it was initially confusing, but once `$` was explained (not far into the guide I was reading), I had no trouble at all reading it. I could then read any instance of `$`, like the above. If I had saw the example above without `$` before them explaining that `do` is passed as an argument (like many guides do: explanation of IO is usually avoided), I would have thought it was weird nonuniform magic syntax.
I'm working on package for bundling swagger-ui into server apps: https://github.com/phadej/servant-swagger-ui I'd like to battle test it before I'll upload it on Hackage. But please add into your `stack.yaml`s even before that, if you feel so :)
Talking about "monoids" and "efficiency" is a bit of a strange thing; A monoid is just structure consisting of a set and an operator fulfilling some laws. The operation can be fantastically inefficient by nature or by implementation, but that doesn't mean it's not a monoid (when treating it in math of course you don't usually talk about efficiency at all; You don't even particularly care if the operation is computable most of the time). I honestly kind of got the impression you were grasping at straws there trying to make concepts that are unrelated align _somehow_.
Well... just don't mention it in a beginners book then. Just introduce the type as `(a-&gt;b) -&gt; a -&gt; b`. It's not like a beginner is likely to run into a situation where it actually makes a difference. Of course you should also be encouraging beginners to look up types, so I guess you should put up a warning that you simplified some standard library types and that they can safely ignore the difference until further down the line.
Just to be clear, the `runST` case will *still* be baked in to the type checker. The levity polymorphism stuff doesn't address that.
If you can't write a new operator with the same simplified type and a different name that behaves exactly like $ the simplified type is a lie.
Sounds like the ParIO monad. Simon Marlow has a chapter about Par in Parallel and Concurrent Haskell that's available online: http://chimera.labs.oreilly.com/books/1230000000929/ch04.html
Thanks for the response. Are there any Haskell-specific things that will make it enjoyable, other than a learning experience? Thanks
Is this on hackage as a library?
Haskell excels at building ASTs, compilers, interpreters, parsers, and such, but it's sufficiently different from the mainstream languages, so you can't just look at Haskell code and try to figure out how it works, you will have to actually learn the language.
Haskell has wonderful support for "algebraic data types" and has a tool for inspecting them which it terms pattern matching. It turns out that most compilers/interpreters are just a bunch of little passes which rewrite trees representing programs and algebraic datatypes + pattern matching are a fantastic sweet spot for doing this. Basically it's very easy to express something like "If I see a + b then do this, if I see a - b do this, if I see ..." which is 99% of what you'll be doing. A large part of the reason I've been using various FP languages for as long as I have is because it's so fantastic to write these little compilers-y projects in them so I may be biased, but I'd definitely say it's a fun choice. Good luck!
The `runST` type checker hack is actually orthogonal to the current debate over the type of `$`. I agree with you: I'd much rather see a separate operator with the fancier type so dear old `$` still looks pretty.
An organization would be overkill for the purpose, you can just give him write access by going to your repository's settings and adding him as a collaborator. Organizations are more appropriate when you have a bunch of related repositories and you want to allow contributors to create more repositories in that family.
Perhaps I misunderstood you. My point was that in GHC 8 where ($) :: forall (w :: GHC.Types.Levity) a (b :: TYPE w). (a -&gt; b) -&gt; a -&gt; b the type ($) :: (a -&gt; b) -&gt; a -&gt; b is not a lie. 
Less ($) tends to encourage more (.), as well.
Would you be willing to include a section on testing (unit, integration, etc.) beyond manual testing with curl? I've been having some trouble creating test suites that'd be no problem in a language like Java. 
They do behave exactly the same. The extra information just allows more inference. The "lie" has always been a part of GHC internally, but now it's expressible in Haskell types as well. 
Haskell was put together by academics, and academics *love* writing compilers. This means there are very mature libraries for creating everything you need for a compiler / interpreter. The design space that has been explored is also amazing. For instance, check out UUAGC for attribute grammars.
&gt; I think the biggest cognitive leap I had to make for several cases was leveraging lambdas effectively. Yes! A little while after I started Haskell I distinctly remember having a huge aha moment with that as well, so I definitely want to help people with that somehow. But I'd like to do it without giving away the actual challenges.
Haskell has a very steep learning curve. Most people here wouldn't say that they have mastered the language. If you find learning something entirely new enjoyable, go for it. But it's not "easier" unless you already know Haskell very well.
Happstack actually has pretty much all the same frills as Yesod. The difference is largely in presentation. Happstack starts with a pretty lightweight core (`happstack-server`) and then allows you to pick and choose what frills you want: type-safe forms (`reform`), type-safe urls (`web-routes`), database abstraction (`acid-state`), embedding HTML syntax in Haskell (`hsx`), etc. There is even support for Happstack+`servant`. And a book documenting how to use everything. 
Haskell won't be easier if you don't know Haskell. But it's well worth learning, and an interpreter is exactly the problem domain that Haskell is great at.
If your goal is to get something done, then you really need to not deviate too much from what you know, and if you've never done pure functional programming before, Haskell is just going to frustrate you. In this case, just stick with Node for now. However, if you're willing to take some time to learn the basics of functional programming in Haskell, then I have no doubt that you'll find it superior in every way to Node, and even more importantly, the concepts that you are forced to learn will be applicable for the rest of your programming career, no matter what language you use.
Monadic / Applicative parser combinators are freaking brilliant. This was posted yesterday: https://www.reddit.com/r/haskell/comments/44bd7c/parser_combinators_parsing_for_haskell_beginners/ And this is the classic paper about it: http://www.cs.nott.ac.uk/%7Epszgmh/monparsing.pdf
Thanks for the link! I've already verified that he defines the same forgetful functor and the same adjunction as I had in mind. He also defines it using projections, as I sketched. So at least my text talks about the same mathematics, in case it's useful.
Mhm. Do you have any resources for learning Haskell that aren't too math-based? 
Thanks
Here is how I would rank a few ways to write the same expression, in increasing order of quality (some of them were difficult for me to rank, but some of the finer details don't matter much): foo . bar $ baz $ someArg foo $ bar $ baz someArg foo . bar $ baz someArg foo $ bar $ baz $ someArg foo (bar (baz someArg)) foo . bar . baz $ someArg (foo . bar . baz) someArg In defense of my earlier claim, note that for the most part the number of `($)` and and the number of `(.)` are inversely correlated. Honestly, the last two are almost equally good to me. A significant reason I dislike `($)` is because it is so easy (and common in the wild!) to write some of the other variations, which are less consistent and group subexpressions in more arbitrary ways. The only version with `($)` that I actually like is the second to last one, and it doesn't seem to have any clear advantage over the last one. The last one slightly wins because the parens make it easier to manipulate in a text editor. I do use `($)` in cases demonstrated by /u/sgraf812 [here](https://www.reddit.com/r/haskell/comments/44bsxn/ghcdevs_new_type_of_operator_in_ghc_80_is/czpx11v), but would prefer that the language just parse a little differently so that `($)` or parens are not needed in those cases.
My understanding was that runST $ do and the like require $ to be taught so it is, ideally the operator would be avoided.
Recursion and linked lists! The shape of a parser is, at it's most basic level, this: type Parser = String -&gt; (Tree,String) *(Source: [Monadic Parser Combinators](http://www.cs.nott.ac.uk/%7Epszgmh/monparsing.pdf))* The basic principle is that a parser is a function which takes an input string, and returns the parsed AST alongside what's left of the string after parsing. If you generalize `Parser` to this: type Parser a = String -&gt; (a, String) you can use this parser inside of other parsers. So for the grammar rule `A ::= B C`, `A` would look like this parseB :: Parser B parseC :: Parser C parseA :: Parser (B, C) parseA = \s -&gt; ((b, c), finalString) where (b, cs) = parseB s (c, finalString) = parseC cs You can see that `parseA` will use `parseB` with the input string, then take the remaining string and use `parseC` on that. This string mutilation is efficient because we're only ever chopping off the front, and Haskell strings are linked lists. If you have a solid grasp on Monads, the [Monadic Parser Combinators](http://www.cs.nott.ac.uk/%7Epszgmh/monparsing.pdf) paper is really brilliant and explains in detail how parsing in Haskell works.
So I followed all the steps in the article, however, when I open atom with in a Stack project directory, I get the following error: Haskell-ghc-mod: ghc-mod failed to launch. It is probably missing or misconfigured. ENOENT Error: spawn ghc-mod ENOENT PATH: /usr/bin:/bin:/usr/sbin:/sbin path: undefined Path: undefined edit: I've solved this problem by using: stack exec -- atom
This is great! Thanks for posting.
There's a very good chance that I'm completely missing the boat here, but here's what I think you're saying: -because a parser in Haskell is the same as an ast, you just sort of select a value from the parser and that's how you get stuff. Is that correct? Also, what's going on with that finalstring part? Sorry for the questions
Thanks, I will add this to the guide as a possible issue. What system are you running on that you got this issue? I just tried a clean install on windows and linux and couldn't get that error.
I'm running it on OSX. Also, are you able to build projects within atom using Stack? I only see options for building with cabal however even that doesn't seem to work for me.
Unfortunately I have not been able to find a way to do this quite yet. However, you can just rely on ghc-mod feedback in atom. If it doesn't complain about anything then your project will build no problem.
Not sure why you were down voted but yes it does! Except it's done through Stack. stack new MyProject servant
You can always avoid that by naming your do block.
A parser in haskell is a *function* from `String` to `(AST, String)`. Big difference. Such a parser takes an input string as a parameter, and consumes some of the front of that string to produce an AST. It'll then return both that AST and what remains of the string. In the `parseA` example above, here's what's happening. * Use `parseB` (remember it's a function) on the input string. This returns `(b, cs)`, which are the AST of the `B` parser, and what remains of the input string after parsing the `B` AST. * Using `parseC` and `cs` to parse a `C` AST out of the front of `cs`. This returns `(c, finalString)`, where `c` is the `C` AST, and `finalString` is what remains of `cs` after parsing a `C` AST. * Finally, have `parseA` return the tuple `(b, c)`, and what remains of the input string after parsing both `B` and `C` ASTs; this is `finalString`. Does that make sense?
Possible to implement with `ghc-exactprint` but will probably be too slow for live display.
The normal way to do this would be to use a Reader monad to carry some config information (like which arrow char to use), and initialize the config at the start of the program.
Does adding the path to ghc-mod in the package settings for `haskell-ghc-mod` solve this?
Adding `stack`'s location for installing global binaries to your path, and then putting `stack` itself in that location, is a good idea in general: it allows `stack upgrade` to work!
Thanks, I've just updated cabal, and that worked.
For `ghc-mod`, yes. For `stylish-haskell`, not sure. The path in question is where `stack` puts anything installed "globally." As I commented above, I like to put it on the path and move the stack binary itself to that location: this enables hassle-free `stack upgrade`.
It's certainly OK in the sense that it won't crash your program. If you're a total purist then it's not ok, if you're pragmatic, then it is ok. 
So I got it working and was really excited to finally have a stable ghc-mod setup, but it doesn't look like it's reading the local .cabal file stack builds. (Could not find module ‘Data.Text’ It is a member of the hidden package ‘text-1.2.2.0@text_5c7VCmRXJenGcMPs3kwpkI’.) Not too familiar with atom, is there something dumb I should be doing to make it read the right .cabal?
Try opening the whole project folder in atom, instead of an individual file.
But why execute it more than once?
In summary, discoverability in Haskell is hard? Perhaps we need a single page website called http://haskell-is-easy.com which lists exactly which library you should use for each use case.
The problem there is that nobody submits a package to Hackage which they think is inferior in every way to the current offering. A curated list is a great way to phase out things which get superseded, but how do you handle adding new packages to it without either listing *everything* or getting accused of bias?
[removed]
A good package list would be awesome. Asked of course you'd accept pull requests.
Haskell would probably do that anyway. You only need the pragma if you need it for correct behavior or tests show it improves efficiency. The compiler is smarter than you about efficiency most of the time (maybe there is a good reason to recompute it, performance wise.)
Try pointing your stack.yaml file to LTS 5.1. It built for me on 5.1 but was failing on 3.15.
I doubt the compiler is smarter than /u/augustss.
I agree. I doubt the compiler would inline the definition of arrow even without the pragma. But I like to avoid taking chances. :)
That did it! Not really sure why, but it works now. Thank you.
&gt;That sounds fantastic. [haskelliseasy.com](http://haskelliseasy.com) &gt;We could also use a list of packages the ecosystem needs, but doesn't have yet. https://github.com/reinh/haskell-wishlist
You mean [like this](https://github.com/Gabriel439/post-rfc/blob/master/sotu.md)?
Ooh... That price...
`unsafePerformIO` is never ok. But you're still going to do it.
I am planning to give a talk on Haskell to some of my mathematician friends, some time in the next couple of weeks. They are all well-versed in category theory to the point that the classic "monads are monoids in the category of endofunctors" will be totally uncontroversial, but explaining how they are useful in programming could be a challenge... I'll report back afterwards, to see how their experience compares.
That's how it works in Agda. It's indeed a bit annoying, but on the other hand it gives you an incentive to compile early and often. :)
We have this exact stuff and more with other suggestions all documented in the docs for our project (Snowdrift.coop): https://git.gnu.io/snowdrift/snowdrift/blob/master/TEXTEDITORS.md It also includes instructions for setting up tags for quick jumping around in the code (and includes notes for Vim and Emacs users as well as Atom). In our docs, we also include language-shakespeare as we use that as part of Yesod etc, and our doc files are all CC BY-SA 4.0, so anyone can adapt/share/copy whatever under those terms… Cheers
Sorry if this is the wrong place to ask but can you ELI5 the use case for lenses? I.e. is it any time I want to get and set values? Or is it when there's a certain complexity of data?
I kind of had the opposite idea for a programming language where your source files were RTF, and the colour of a variable's name determined its type. You'd naturally have to colour type definitions as well. Union types would be elegant, since you could just colour each letter of a variable's name differently based on the possible types the variable could be. Not sure how polymorphism would work, but.
http://learnyouahaskell.com/
The parentheses are a [tuple](http://learnyouahaskell.com/starting-out#tuples)!
I had originally written a slightly longer post where I said that we identify sets with subsets other other sets. For instance, the reals in the complex numbers, or an integral domain in its field of fractions. Or in this case, `Int` is identified with the non-`Nothing` subset of `Maybe Int`.
Half-assed 0022 explanation Primary components are: lens, prism, fold, traversal - lens: ignore other parts of a product to zoom in one particular (possibly nested) path into the data structure and set/modify/read the value. Composably. - prism: ignore other possibilities of a sum to zoom in on one particular (possibly nested) path into the data structure and (maybe) set/modify/read the value. Composably. - fold: Retrieve multiple values. Composably. (Think normal folds, but composable in the presence of more structure than usual. Clojure transducers.) - traversal: Read/write multiple values. Composably. Somewhat weaker and less specific than the others, can bite you in some uncommon cases. I'm just summarizing what http://hackage.haskell.org/package/lens says though. I don't use pure profunctor lenses because of things like Traversal/Fold/Getter/Setter. Lets me stay in "lens mode" when I want to without breaking out into something else. lens in anger: https://www.schoolofhaskell.com/user/tel/lens-aeson-traversals-prisms
It seems that flickering is part of the hardware design. There are methods to reduce it but I didn't really dwell on it too much. [More information about that here](http://chip8.wikia.com/wiki/Flicker).
I applied this approach to coroutines, went in a slightly different direction, and came up with an interesting result. If I had skipped straight to an mtl-style type class for coroutines, it might have looked something like this unsatisfying thing: class Monad m =&gt; MonadCoro m i o | m -&gt; i, m -&gt; o where yield :: o -&gt; m i Really? A function that take some input and gives some output? Looks pretty silly. But with this approach, I started by lifting the free monad representation: data Coro i o a = Return a | Yield o (i -&gt; Coro i o a) But I don't think there are any normal forms for the semantics I want other than just that, and I found the `liftCoro` version this led to unsatisfying, so I decided to try reducing the laws by substituting the definitions of `return` and `(&gt;&gt;=)` for `Coro`. I ended up with only the following law which seemed to state anything interesting: liftCoro (Yield o (k &gt;=&gt; f)) == liftCoro (Yield o k) &gt;&gt;= liftCoro . f From here I made some sort of intellectual leap that I can't explain, but I ended up with the following type class and law: -- yield o k &gt;&gt;= f == yield o (k &gt;=&gt; f) class Monad m =&gt; MonadCoro m i o | m -&gt; i, m -&gt; o where yield :: o -&gt; (i -&gt; m a) -&gt; m a This law seems to require that the result can't ignore the supplied function, which means that if I'm using `yield` and I want access to that value of type `i`, I am guaranteed to actually be able to use it. For example, the following instance is rejected: -- illegal instance MonadCoro Maybe i o where yield _ _ = Nothing This law doesn't even seem to be expressible for my original mtl-like type class (for which the sad implementation `yield _ = Nothing` is expressible even though the law rejecting it is not).
Type checking is nearly instantaneous for smaller amounts of code, and your editor could cache the types for anything you've given a signature, so it shouldn't take a perceptible amount of time.
I like the idea of colouring types. Something else I like is if you have colour coded types, colouring **blank space** with some representation of the types of things that can go there, to help you keep in mind the structure of what you're writing.
`local` should have a documented interaction with `ask`, I do consider that missing to be an oversight on the part of the `mtl`, as all of the instances we admit today pass laws that `local = const id` violates. 
Now do so many levels deep into a monad transformer stack. I've done this inside `lens` via `zoom` -- it isn't trivial to encode and needs roughly one or two supporting data types and a pile of instances per monad transformer.
As an atheist haskeller that don't get impressed by the functional ideology, I think that Haskell has a lot of accidental complexity introduced just for the pleasure of authors to display his own mountain of concepts and software constructions crushing a problem instead of just solving it. And is a duty of honesty to recognize it and make things as easy as possible. “It is one of man's curious idiosyncrasies to create difficulties for the pleasure of resolving them.” ― Joseph de Maistre 
Guess you just gave me an incentive to improve Opaleye :)
On the contrary. Very good packages regularly are overshadowed by mediocre ones coming from enthusiast over-confident newcomers that reinvent squared wheels and are noisily cheered by other newcomers. It is like if the "avoid success at all costs" that had a good intention has turned out to his malign side: "avoid the success of others and look after my own success at all cost, of course smiling everyone" If the Haskell community is so nice and Haskell so revolutionary, Name a single popular package or application that would revolutionize software programming or change the way people program. Something that would make programmers of other languages say "wow" this is done in haskell I want to learn Haskell!. There is none popular except perhaps the work of Simon Marlow. But indeed there are such ideas and packages. Only that they are carefully silenced.
That doesn't make it ok.
https://medium.com/@jkff/mapreduce-is-not-functional-programming-39109a4ba7b2#.8fg4t8xdv 