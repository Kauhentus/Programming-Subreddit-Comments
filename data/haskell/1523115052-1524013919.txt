I don't think so. I mean why did you type `Foo` into the prompt? To see it, right? So you *wanted* ghci to call `show`.
Is this sort of thing valid? ``` data X f = … deriving Eq via f ``` Edit: I guess subject to f being isomorphic or representationally equal to X f… so maybe ```newtype X```?
My stand is that it is an error in the sense that ghci cannot display it, not that it is the user's error entering `Foo` (of course, the onus of at least deriving `Show` would be on the user). 
Maybe for that specific example, but not in general. I could type `launchMissiles` where `launchMissiles :: IO Foo`.
We just updated the cabal-install version on hackage, so it should work now. As a bonus, we're doing the fancier hyperlinked/colorized docs pervasively now (e.g. http://hackage.haskell.org/package/scotty-0.11.1/docs/src/Web.Scotty.html) :-)
They're generated code based on GObject Introspection, hence the "gi". 
Thanks for the information and the paper link. I will definitely read through it and it may end up being a useful reference for my dissertation. The integer example given was just to illustrate my problem. What I'm doing in reality is much more complicated. Appreciate the help!
Interesting that you say this because this is the exact problem I'm facing. I've got a function which takes two parameters (it's the transition function for a Turing machine to be specific) and, while I can see that a map implementation is faster, I need to understand why
Interesting. The exact problem I'm looking into is maps vs pattern matching so this is extremely useful. Thank you!
Well alright. Anyway REPLs in other languages have more useful behaviors.
Just to reaffirm my stance: going from `forall a. Foo a` to `Foo` is *also* not eta reduction, bugs in the GHC commentary notwithstanding. Reductions move from one term to another term that we intend to consider as "behaving the same", for some sense of "behaving". (Sometimes we relax "the same" to "having a subset of the same behaviors".) But we absolutely don't have that intention -- either the strong "behave the same" or the weak "subset of behaviors" expectation -- about these two types.
Great!
&gt; but Show is usually intended to be a representation of the value in Haskell syntax This is certainly the "traditional" intention of `Show`. On the other hand, is it not a rather artificial requirement? What would break if we break with this tradition?
The assumption that you can `read` a value produced by `show`, which is often done in tutorials, which are read by beginners, which would be the main demographic benefiting from this change.
The other defaults also lead to WTF moments. Not deriving Show where it can't be derived seems reasonable to me. 
I asked a question about Netwire on SO. If there are any Netwire people lurking here and not there, I'd appreciate an answer. [What invariants am I supposed to maintain when using Control.Wire.Unsafe.Event?](https://stackoverflow.com/questions/49701058/what-invariants-am-i-supposed-to-maintain-when-using-control-wire-unsafe-event) I also ask about running an event driven network service with Netwire.
Strictly speaking that assumption is already untrue, because we have plenty of `Show` instances without a corresponding `Read` instance.
As a dyed in the wool Haskeller I can tell you I have no interest in contributing to StackOverflow. I'm sure there are thousands of other Haskellers in the same boat.
Could it be a lot of people have moved from IRC to Slack (which you may not agree with, but that's besides the point): Clojurians Slack has 12,789 members of which 800 are active daily. Functional Programming Slack (which active channels #haskell, #haskell-beginners, etc) has more than 8000 members of which 900 members are active daily. To me, that's pretty active. I have been subscribed to the Haskell question tag on StackOverflow and turned it off after a couple of weeks because I got too many e-mails.
First of all, take a look at [this](https://www.reddit.com/r/haskell/comments/85lghz/developers_who_work_with_languages_like_matlab/). Additionally: * this subreddit is super active. * #haskell on freenode * Haskell [mailing lists](https://wiki.haskell.org/Mailing_lists) And I'm sure there's more I'm missing. And that's just Haskell--plenty of other languages have robust and active communities--Clojure, OCaml, etc. Functional programming is alive and well. So, just because it's not where you're looking, doesn't mean it's not happening--it's just not happening where you expect it should.
I'd hardly say Agda and Idris capture the state of Functional language communities, being niche languages under heavy research and experimentation.
reminds me that F#'s repl can print data structures, but there is no way to reuse it in a program
Stackoverflow is dead because a lot of questions get deleted and in a lot of parts Stackoverflow people know little and down vote the ones with more knowledge.
&gt; Show in modern Haskell is pretty much only meant to be used for REPL not only, in logging it would also be useful. I just commented in other thread that situation in F# where has REPL has exclusive privelege to stringify data is no less depressing.
Yes thanks! I see I hadn't thought of moving the constraint out of SmNodeWrapper. I'm still a little confused by data types with constraints but it seems to me I can get away with just keeping those constraints on the functions that use those types. Splitting out the u makes sense :). Yeah, after running into all these issues, it's clear to me about the advantages of moving things into data level. I'm also not leveraging type level safety to cause compile time errors on invalid trees (I'd like to do this some day) so I don't think I'm gaining anything by using typeclasses. A funny meditation on the matter: storing a function in a data type is a very function approach where as doing the programming at the type class level is more akin to OO programming where "update" uses the vtable to resolve which function to call. 
Sounds like this could make for a pretty solid GSOC Haskell project if most of the work is somewhat mechanical... I wonder if there's a list somewhere of really large pain points in the Haskell community that could potentially be solved with backpack. I'm guessing string types, streaming interfaces, and parser combinators would be a good start?
Yeah and they do... except when there is no instance for Show.
Well I guess then we have the wrong argument. The actual question here whether it would be desirable to do it like other languages and automatically derive a `Show` instance. 
I have entirely switched all development to Rust which I have found far better on the “getting things done” point of view. It has all the features of Haskell I love (pattern matching, type inference, no class-based inheritance), and much better/more modern for a lot of software development. Better package manager, better modules, better unit test story, better name spacing semantics, better macros. It emulates monad for my most common use case (Maybe, Either) with the ? operator. The one thing I consistently miss most is partially applied functions and being able to define infix function, most notably function composition. 
Thanks - I wasn't clear whether that meant the 'via' statements were first class, so to speak. So it's possible to parameterize a type by its typeclass instances.
You couldn't derive an instance for `Show` because it would break compatibility with expectations/documentation. But as I said elsewhere in this thread the repl does not have to be relying on `Show` itself. You could have a class `Show a =&gt; GhciShow a` and automatically derive an overlapping instance when there is no `Show a` (or something equivalent to that).
That would be possible. 
The `forall n.` in the second one has the wrong scope. The equivalent of the first in GADT syntax is. data SmNodeWrapper p o where SmNodeWrapper :: forall n. SmNode n p o =&gt; n -&gt; SmNodeWrapper p o As you have it written currently the `n` inside the brackets is unrelated to the `n` outside the brackets. I think it is interpreted as data SmNodeWrapper p o where SmNodeWrapper :: forall n1. (forall n2. SmNode n2 p o) =&gt; n1 -&gt; SmNodeWrapper p o which as tomejaguar mentions has a currently illegal quantified constraint.
Perhaps I was just missing most of the momentum, then. I'm glad to hear that. Maybe it is time to get used to Slack too (I like it, just wasn't aware it was actually more active.)
^(*I may sneak it into the proposal*)
Note that the reflex on Hackage / Stackage are quite old. They had version 0.5 ready to go over a year ago, but still haven't put it on Hackage, so maybe check out their GitHub and see if they have some shell scripts you can use instead of Hackage.
This feels more like an advertisement for Rust than an answer to OP.
Thanks for explaining that. I now see that polymorphic recursion doesn't work with backpack. I think it should be possible to write `FingerTree` to [avoid polymorphic recursion](https://gist.github.com/andrewthad/637326ffd95b29a08e9bd2dffa0d1cf6) in the element type of the various data structures: data Nat = Z | S Nat data Digit n a = One (Tree n a) | Two (Tree n a) (Tree n a) | Three (Tree n a) (Tree n a) (Tree n a) | Four (Tree n a) (Tree n a) (Tree n a) (Tree n a) data Node n a = Node2 (Tree n a) (Tree n a) | Node3 (Tree n a) (Tree n a) (Tree n a) -- Two-three tree with values at leaves. data Tree :: Nat -&gt; Type -&gt; Type where TreeZero :: a -&gt; Tree 'Z a TreeSucc :: Node n a -&gt; Tree ('S n) a data FingerTreeN :: Nat -&gt; Type -&gt; Type where Empty :: FingerTreeN n a Single :: Tree n a -&gt; FingerTreeN n a Deep :: Digit n a -&gt; FingerTreeN ('S n) a -&gt; Digit n a -&gt; FingerTreeN n a newtype FingerTree a = FingerTree (FingerTreeN 'Z a) If this translation is correct, you could use backpack, but your point about `Node` not unpacking still holds. You get nearly no unpacking from this. One easy improvement would be to inline the definition of Node into Tree, giving it three data constructors. Still not good though.
This is a great idea, and if this happens I think we should add pretty-printing as well.
PA GHCi &lt;interactive&gt;:2:1: error: * Dafuq? No Show on that one, human. * Do you even type class, noob? * In the stmt of RTFM 
As for the OCaml/ReasonML communities, they have largely begun moving over to other platforms. For OCaml, we see a lot of activity on https://discuss.ocaml.org/ and the ReasonML community has both a Discord channel https://reasonml.chat/ and https://reasonml.chat/
What does a random generator of terms in System Fw look like?
I mean, when I type `Foo` in the REPL *I want to see a readable representation of `Foo`*. The fact that it calls `show` is an implementation detail. An *unfortunate* implementation detail because `show` was not really meant for human-readable input and errors out on certain types. It would be more consistent with my expectations if GHCi had some way of displaying values that didn't have `Show` instances instead of giving me an error. The simplest option would be to just show the type signature, but I would also be fine if it had a default display mechanism that could introspect on the type and only used type signatures for certain things (like functions). That is, if I define: ``` data Foo = Foo (Int -&gt; Int) ``` I would prefer something like: ``` λ&gt; Foo (+ 1) Foo &lt;func: Int -&gt; Int&gt; ``` I think that's significantly more convenient and in-line with reasonable user expectations than the current behavior.
IMO GHCi should be able to do a few different things with a value: Execute it and print the result Execute it and show the AST of the result Print the value Show the AST of the value You should be able to choose one of the four options with `:somesingleletter`, or it should try them from top to bottom. Every value has an associated AST, even functions technically do, although for them it might be worth printing something else like `&lt;function :: Type&gt;`
I was envisioning something similar, and I don't think it is too *magical*. ;)
Thanks for chiming in, and thank you for writing such a great book! I didn't know it was still unfinished, I thought I read the whole thing almost 6 months ago.
The idea of using the full sequent calculus as an intermediate language in GHC has been abandoned. However, they took some lessons from the development and added *join-points*. This is explained in a more recent paper: https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/join-points-pldi17.pdf
I don't think your observation is true at all. Haskell seems to be on the rise and is a lot more active compared to a few years ago. People are actually doing stuff with it, there are multiple job posting here every week, a lot of discussions happen here, on twitter, on IRC and discord, a lot of blog posts and news are published every week and many offline events are happening (as you can see in haskellweekly.news), [there are quite a few questions asked on SO everyday](https://twitter.com/SO_Haskell) (not that i find that a good metric tbh), there are quite a few quality books and learning resources available for beginners and there are 3 (!) intermediate/advanced books are in the works, GHC release cycle became a lot faster and more and more.
Why is F# low volume? I was a fan of it for a while, but it never took off here in The Netherlands. I wonder why.
What I think is not mentioned in any of the answer that I thought afterward when using a map is : even though in theory the access to a map is log(n) you must build the map first which is (I believe) n. As the map is not built when you declare it but when you actually use depending how the final map is memoized it might actually be a much worth than we think.
&gt; A funny meditation on the matter: storing a function in a data type is a very function approach where as doing the programming at the type class level is more akin to OO programming where "update" uses the vtable to resolve which function to call. Yeah that's a good observation.
You should ask the Agda questions on the Agda mailing list, especially the UX and technical ones. Most Agda devs aren't on SO, but they reliably answer on the list.
I'm not sure I understand what you're saying, because it doesn't align with what I understood your question to be. In `data X f = ... deriving Eq via f`, the `f` would not be a typeclass (but rather a *type*, and in particular one which is an instance of `Eq`), so `X` would not be parameterized by its instances.
When I found my first Haskell job there were a handful of job posts per year. Now there are a handful per month. Including astrology.
You will get upvoted once you have a golden star, I promise!
Maybe because of aggressive, and in my opinion overzealous, moderation? I asked something very specific about vim on Stackoverflow years ago, waited months and concluded it's a weird place with its own culture not worth bothering with. At least I didn't get yelled at for answering something incorrectly or commenting in the wrong context. It just seems like a violent place just as Hacker News.
That's very, very embarrassing, but... how exactly do I use a mailing list? I've sent an email to `agda@lists.chalmers.se` but I'm not sure it worked (perhaps nobody replied?). Did you get it?
I haven't done that yet - the version with random generation only go as far as STLC, and the version with System Fw only dealt with evaluation / type inference / pattern matching. I think I can use most of the tricks from generating STLC terms in the generation of System Fw terms, although I won't be sure about that until I get there. 
Had to check twice because at first I thought Austin's whole programing optimizing compiler got revived (it had the same name back in 2010). Important question, this is a reimplementation of a Haskell compiler meant to be a replacement for GHC, right? Could this become the basis of an improved GHC that is easier to maintain?
Beats me. I've been a huge F# advocate (read: fanboy) for maybe five years. It's not the perfect language, but it comes closer than anything else I've ever tried.
Stack Overflow, as a whole. is a fairly toxic community. April Wensel on Twitter has posted a lot about this, though I don't know of a good way to present that information.
Doesn't initChip8Memory = Chip8Memory byteMem' wordMem' (writeMem' initChip8Memory) undefined where work?
I think the hype of the day(tm) is machine learning, and the focus has shifted away from programming to training and modelling, using programming languages like python.
Small mistake in line 1101: "the desired Monoid instance" should be "the desired Semigroup instance". Also, how could I derive an Arbitrary instance for `data Pair a b = Pair !a !b` from `(a, b)`? These types are not coercible so AFAIU `SameRepAs` wouldn't work.
There's a healthy amount of active discussion in the various matrix rooms as well!
How usable is `haskell-scope` and `haskell-tc` as of early 2018? iirc they were far less used and maintained than `haskell-src-exts`.
It would be a noble idea. There isn’t much of a good reason to maintain an NCG nowadays (except for the performance ... which most people could probably tolerate and it could get fixed up with the proper investigation).
Did you [subscribe](https://lists.chalmers.se/mailman/listinfo/agda)? Can you find your emal in [the archives](https://lists.chalmers.se/pipermail/agda/)?
IRC is a really frustrating and unpleasant medium. It's been declining because it should decline. From my perspective, I feel like a lot more people actually use FP (even if it is not Haskell) around me, and I've never had access to talk to more FP folks. This subreddit is vibrant. But I straight up refuse to interact with Stack Overflow. I refuse to participate in the monetization of work that ultimately strangles good documentation with uncurated and stale questions. It's a cultural facet of languages with an unhealthy obsession with what they call "humanist" documentation; which is to say actively avoiding technical writers.
Why should anyone contribute to Stack Overflow, a for profit business, without compensation? It's weird that we even need to justify not using it.
This is a nice blog post! We (Capital Match) still haven't upgraded to the new Shake yet unfortunately (because of priorities, and also because rewriting is quite a bit of work since we have lots of custom rules to deal with non-file artefacts like docker containers and images). Was a bit disappointed that the ["official" release announcement](https://neilmitchell.blogspot.com/2017/09/shake-016-revised-rule-definitions.html) didn't quite outline a smooth upgrade process but I'm glad to see this fill the void. 
I'd love to use a free and open source chat system, but no one has made one that's nearly as good as Slack. Of course I'm aware that Slack has a bunch of problems, but until there's an open, viable alternative, I have nothing to protest for. Gitter is garbage, and I have to use IRCCloud (another for-profit company) in order to make IRC tolerable. Someone has to make something open that I can use before I can start complaining like this.
You end up locking other people in because of network effects. It shouldn't be done, even if the software is somehow better in your opinion. There are a bunch of slack clones you didn't mention by the way, e.g., "mattermost." 
There is no 'this'. You have a record that happens to carry a function around. It isn't an "object" where every function in it takes a copy of the record as an extra argument. If I give you `(Int, Double -&gt; Bool)` the function on the right hand side of the pair has no access to the Int on the left. Its just a function. If I give you a list of functions, those elements get no access to each other. Records are the same way.
In the specific case of [the \[haskell\] tag](https://stackoverflow.com/questions/tagged/haskell) and the community around it, I sincerely don't believe that is the case. The regulars are polite and helpful, and moderation isn't unforgiving in the way it tends to be in the high-traffic tags. The environment does feel different than elsewhere in Stack Overflow.
# Question 1 That is incredibly confusing how it is written. However, the idea should be that the identity natural transformation on a functor F : C -&gt; D is exactly the identity morphism at every F(a) for objects a in C. That notion of identity is the vertical identity, but it is only the horizontal identity if F is itself an identity functor. So, every horizontal identity is a vertical identity. But not vice versa. # Question 2 That is the **definition** of the product of two categories, and so the *definition* of what qualifies as a morphism in the product category. We might ask if this definition (or we might say construction) is actually a product in the categorical sense, and indeed it is, which is maybe what you need to prove to yourself. 
This may help. You can encode a product category `(-&gt;) × (-&gt;)` as type Cat ob = ob -&gt; ob -&gt; Type data ProdCat :: Cat (Type, Type) where ProdCat :: (c -&gt; c') -&gt; (d -&gt; d') -&gt; ProdCat '(c, d) '(c', d') Objects are pairs of kind `(Type, Type)`, this can be generalized to products of any categories with objects of kind `(ob, ob')` type ProdCat = (-&gt;) × (-&gt;) data (×) :: Cat ob -&gt; Cat ob' -&gt; Cat (ob, ob') where ProdCat :: cat c c' -&gt; cat d d' -&gt; (cat × cat') '(c, d) (c', d') ---- Side note, we can almost give a `Category` instance for the product category `(cat × cat')` instance (Category cat, Category cat') =&gt; Category (cat × cat') where id :: (cat × cat') a a id = ??? (.) :: (cat×cat') b c -&gt; (cat×cat') a b -&gt; (cat×cat') a c ProdCat f g . ProdCat f' g' = ProdCat (f . f') (g . g') Due to annoying reasons we cannot simply write id = ProdCat id id since GHC doesn't know that `a` has the shape of a type-level pair required to construct `ProdCat{}`. A stopgap solution is writing ProdCat :: cat (Fst cd) (Fst c'd') -&gt; cat (Snd cd) (Snd c'd') -&gt; (cat × cat') cd c'd'
Thanks for the pointer. I'm glad you enjoyed it and found it an easy read. We can derive `Arbitrary (Pair a b)`, look closer at **4.3** data Pair a b = Pair !a !b -- Needed to convert (Pair a b) to its generic representation and back deriving stock Generic deriving Arbitrary via (Pair a b `SameRepAs` (a, b)) You are right that `(a, b)` and `Pair a b` are not coercible. But their [generic representations](https://hackage.haskell.org/package/base-4.10.0.0/docs/GHC-Generics.html#t:Rep) are: try type checking coerce :: Rep (a, b) () -&gt; Rep (Pair a b) () Deriving via arbitrary isomorphisms was my original motivation but I underestimated the humble `coerce`. In a shocking twist it turns out coercing (which has no operational behavior!) is enough to do exactly that ([related](https://www.reddit.com/r/haskell/comments/7j90mr/blog_trick_encoding_overlapping_extensible/)). How? In this case we [generically](https://hackage.haskell.org/package/base-4.11.0.0/docs/GHC-Generics.html) witness the isomorphism between the two pairs with wit = to . coerce . from -- coerce ignores junk / metadata which can be instantiated at both of these types wit :: (a, b) -&gt; Pair a b wit :: Pair a b -&gt; (a, b) then deriving via `SameRepAs (Pair a b) (a, b)` is like writing instance (Arbitrary a, Arbitrary b) =&gt; Arbitrary (Pair a b) where arbitrary :: Gen (Pair a b) arbitrary = fmap change arbPair where arbPair :: Gen (a, b) arbPair = arbitrary
This sub alone has doubled in size since I first started reading it a couple years ago.
How far does this philosophy extend? Where do you draw the line that divides what proprietary software is and isn't acceptable? Windows / MacOS? Office? Certainly it seems absurd to me to suggest that Windows or MacOS should never be used, but they're relied on far more than Slack is.
I think functional languages are actually on the uptick. Not only are hardcore functional languages like haskell either growing (haskell, elixir, erlang are ones I've particularly noticed) or remaining stable, but mainstream languages are taking more and more features from them (rust, swift, javascript). It's pretty vindicating. I even got to take part in a haskell user group for the first time a few months ago that stopped meeting because half the people got hired and moved away. That was a pipe dream when I first got into haskell.
&gt; it seems absurd to me to suggest that Windows or MacOS should never be used Well, you need to keep in mind the very important difference between using some piece of software in your own individual way and relying on (i.e. requiring) others to use that software. For example, it's one thing to write a document in Microsoft Office and then print it out. It's quite another to demand that other people (for example, if you are a university professor, your students) provide you with documents in formats that can only be created in Microsoft Office. That is never acceptable. 
I'd just use an `if` statement. `bool` is the worst option IMO, since most people have to look up what the order of arguments is, or might just not even know what it is. chooseChar c l = if l `elem` [1,n] || c `elem` [1,n,l,n-l+1] then '#' else ' ' I tend to prefer the mulit-equation syntax only when the values are being instantly pattern matched and dropped (i.e. there must be a constructor match and no `@`). If you need to reuse the value your dispatching on, I usually prefer to just use one equation and case on it. The potential for variable names to go out of sync between equations bothers me too much. Your second variation is also good, but I don't prefer it simply because I always found guard syntax a little awkward to read.
There is a lot of value in ensuring that everyone you work with uses the same toolset. Universities often have requirements on what laptops and software students use, because trying to operate in a wild west leads to far too many practical problems and incompatibilities. Enterprise environments are extremely strict about this. Taken to the absurd, if we can't have requirements on what OS people are using, why should we have requirements on what networking infrastructure they use? What if I invented my own TCP alternative that I prefer, or even my own IP and DNS system? At some level, there *must* be consensus. And in that case, unfortunately there will be times that the consensus must be on unfree software. I think that's a bad thing, but it's an unavoidable a practicality of the world we live in (yay capitalism...). For instance, it would be virtually impossible to convert the media production industry to non-proprietary formats. As far as Slack goes, yea it'd be great if the consensus was on an open alternative. But I've not seen any free and open alternative that's as good as Slack. We can complain about it all we want, but until this exists we don't have a leg to stand on. Additionally, I'm guessing you don't have the same problem with Reddit simply because you're here voluntarily. But isn't that the case with the Haskell Slack channels too? No one forces them to go there; there are plenty of other places to go.
Honestly, the biggest barrier would be some people would assume you're a crank but if you avoid being cranky you should be fine. 
None of TCP, DNS, or IP are controlled by autocratic for-profit corporations. They are controlled by non-profit standards bodies (IETF). The IETF has a legitimacy that a self-interested corporation cannot attain. (I can't believe I have to explain this.) It has exactly the same kind of legitimacy that open communication protocols like IRC or Jabber have, and that Slack lacks. &gt; What if I invented my own TCP alternative that I prefer, or even my own IP and DNS system? Submit it to the IETF through the RFC process, implement it under a free software license, see what happens. &gt; unfortunately there will be times that the consensus must be on unfree software. I think that's a bad thing There will never be, and has never been, such a consensus. You cannot ever get anything past the IETF if there is no possibility of a free implementation. And even if we are not talking about something that has to go past that standards body or any other, you will never obtain consensus because there are so many people who will not agree. &gt; it would be virtually impossible to convert the media production industry to non-proprietary formats. What? Why? &gt; As far as Slack goes, yea it'd be great if the consensus was on an open alternative. But I've not seen any free and open alternative that's as good as Slack. We can complain about it all we want, but until this exists we don't have a leg to stand on. I'm not "complaining." I'm telling you why you shouldn't use it.
I've been around the community for awhile now and I definitely do not have this perception. The biggest place I've noticed this is in Haskell job openings. I try to stay fairly aware of what companies are hiring haskellers and I've seen a significant increase in the last few years. In just the last few weeks alone I can think of at least 5 companies that have posted Haskell job openings that I didn't know about previously. I used to be worried that if I left my job it would be hard to find another Haskell job. That is not the case any more. It's a great time to be a Haskell developer!
&gt; None of TCP, DNS, or IP are controlled by autocratic for-profit corporations I know. I was merely proving that consensus is necessary. &gt; And even if we are not talking about something that has to go past that standards body or any other, you will never obtain consensus because there are so many people who will not agree. Yes, I was definitely not suggesting that IETF will accept unfree standards. But there have been and will be unfree standards on which our industry depends. MP3, for instance. &gt; What? Why? Money. Yes, it's a bad reason. But the reason that we have so many unfree standards that we depend on is because some powerful companies put a lot of money into keeping it that way. Anyway, long and short, I think we're roughly agreeing here. The world is better when things are open instead of proprietary. I think you sufficiently answered my original question about where to draw the line: When it starts imposing unfree requirements on other people. I think that's fair, but I wouldn't agree that this means we should shut down the Haskell Slack channels. People are there voluntarily; no one is imposing requirements on them.
As you have it written there you've put a level of indirection between your Digit and the element type, undoing the benefit of doing the transformation in the first place. =)
Sorry to hear the release announcement was a bit lacking - I'm still not happy with the story of custom rules but will try and up the quality of the docs. (Generally I want the release announcement to just point at docs that are sufficient)
Austin Seipp? He and I (as well as Samuel Bronson) worked on LHC in the past.
`bool` is completely analogous to `either` and `maybe`, where the "less happy path" is the first argument.
[removed]
This page has the diagram for the interchange law: http://www.stephendiehl.com/posts/adjunctions.html
Yes but it goes the opposite way as `if ... then ... else` so even though there is a logic behind you still need to remember to which kind of logic it belongs. Also, a major difference between `bool` and `either` and `maybe`, is that for the laters, the documentation is in the type signature and if you doing it wrong the code won't type check. So I second /u/ElvishJerricco on this. Even though `bool` can be used, you take a risk of making a mistake. Why you should you (one) take such a risk when there is a safe alternative ? In some companies, that's good enough to ban the usage of `bool`.
(I am a Stack Overflow employee, and contributor to the [haskell] tag.) I think it probably helps that the Haskell community out there is still relatively small and self-selecting. We get our share of beginner questions, but not so many of the _really_ low-quality questions that plague more popular tags. So the questions tend to be good and they provoke good answers, but there’s also the second-order effect contributors are less jaded by the deluge of poor questions and so are in a better mood and less inclined to be rude to newbies. [Jon Skeet, who now has over a million reputation, has written about the causes and effects of jadedness in SO contributors.](https://codeblog.jonskeet.uk/2018/03/17/stack-overflow-culture/) “Avoid success at all costs.”
I think the "more expressive" version should be property tests.
Is that a genuine question? People like to help each other. More selfishly I’ve also found that contributing to Stack Overflow has helped me become a better writer and a better programmer. PS Stack Overflow doesn’t and will never take ownership of community contributions; everything you write is CC-licensed and we upload regular data dumps. (I am a Stack Overflow employee, but I was a Stack Overflow contributor long before that.)
### Question 1 As /u/philipjf already explained, a vertical identity is the identity natural transformation of any functor, so it does not act as an identity for horizontal composition unless the functor happens to also be the identity. ### Question 2 There is a nice way to see that morphisms in the product category 𝓒 × 𝓓 *have* to be defined as pairs of morphisms, if we want the product to have its universal property. In fact, if I denotes the "walking arrow", i.e. the category with only two objects 0 and 1, and one non-identity arrow 0 → 1, then it is a general fact that the set of functors I → 𝓐 is naturally isomorphic to the set of arrows of 𝓐 (we say that I *represents* the functor Arr : Cat → Set that gives the set of arrows of a category). Now, let's assume we don't know anything about product categories, except that they are indeed products in the category Cat. The fact above then tells us that Arr(𝓒 × 𝓓) ≅ Cat(I, 𝓒 × 𝓓) ≅ Cat(I, 𝓒) × Cat(I, 𝓓) ≅ Arr(𝓒) × Arr(𝓓) (a representable functor preserves binary products), so we see that an arrow in the product is forced to be a pair of arrows in the two components. The same of course holds for the objects, simply by using the trivial category 1 (with one object and no non-identity morphisms). By looking at naturality squares of the two inclusions 1 → I you can also deduce that sources and targets work out in the way you expect. You can also find out how composition in the product works, by looking at functors from the category [2] that looks like this · → · → · (the ordinal 3, regarded as a category). This tells you that there is at most one way you can define a product category, and it exactly corresponds to the definition in the book. Now you can take that definition, and prove that it indeed satisfies the universal property of the product (if you know a bit more category theory, this is automatic, since the three basic categories we used above, 1, I, and [2], form a [dense](https://ncatlab.org/nlab/show/dense+subcategory) subcategory). Note that the same argument can be used to show that arbitrary limits exist in Cat, and are computed "pointwise", much like products. The underlying reason why this works is that the [nerve-realisation](https://ncatlab.org/nlab/show/nerve+and+realization) adjunction for the aforementioned dense subcategory gives a reflection of Cat into the corresponding presheaf topos. Incidentally, there is another way to define a "product" of categories. It is not a categorical product, of course, but it still gives a symmetric closed monoidal structure on Cat. Its right adjoint gives the category of functors and (not necessarily natural) transformations between them. Categories enriched over that monoidal structure are called [sesquicategories](https://ncatlab.org/nlab/show/sesquicategory). ### Question 3 I would maybe draw a different diagram: a 3x3 square of functors and natural transformations whose vertices are functors and edges are natural transformations. It has GF in the top left corner, and G''F'' in the bottom right, with all possible combinations of compositions of the 6 functors involved in your original diagram, and all possible whiskerings. Now the interchange law is very easy to prove by chasing this diagram: the "principal" diagonal maps are the two horizontal compositions, so the outer diagonal is the right side of the equation. On the other hand, if you just look at the outer square, you can see that its diagonal is exactly the left side of the equation. 
How does IHaskell compare to just org-mode (Apart from the fact that it doesn't really work ;-) ?
Well, one requires an interactive computing environment mostly written in a dynamically-typed language, and the other requires Jupyter :).
ghci doesn't error when it encounters an `IO Unshowable` value. It simply executes the IO action quietly without displaying the result. Only when it encounters a pure unshowable value it complains, because nothing can be done there.
Oh, thanks for clearing up my misunderstanding! :) I'm quite impressed of the type of coerce in this case: λ :t coerce :: Rep (Pair a b) () -&gt; Rep (a, b) () coerce :: Rep (Pair a b) () -&gt; Rep (a, b) () :: D1 ('MetaData "Pair" "Ghci2" "interactive" 'False) (C1 ('MetaCons "Pair" 'PrefixI 'False) (S1 ('MetaSel 'Nothing 'NoSourceUnpackedness 'SourceStrict 'DecidedStrict) (Rec0 a) :*: S1 ('MetaSel 'Nothing 'NoSourceUnpackedness 'SourceStrict 'DecidedStrict) (Rec0 b))) () -&gt; D1 ('MetaData "(,)" "GHC.Tuple" "ghc-prim" 'False) (C1 ('MetaCons "(,)" 'PrefixI 'False) (S1 ('MetaSel 'Nothing 'NoSourceUnpackedness 'NoSourceStrictness 'DecidedLazy) (Rec0 a) :*: S1 ('MetaSel 'Nothing 'NoSourceUnpackedness 'NoSourceStrictness 'DecidedLazy) (Rec0 b))) ()
We should have non-toxic, respectable responses explaining our position. If people refuse to heed them, then we can't do much more.
I'm genuinely interested in what Jupyter offers over.org-mode (other than the fact , which i agree is a big point, that org-mode doesn't really work). Im just surprised that nobody's seems interesting to implement ESS for Haskell.
So is this a continuation of https://hackage.haskell.org/package/lhc?
I'm a bit sceptical about compiling to Java as an intermediary step before JVM bytecode, unlike [Eta](https://eta-lang.org/) which appears to target bytecode directly - skimming the github page didn't reveal much and neither "Eta" nor "byte" are mentioned. Conversely the [Eta FAQ](https://eta-lang.org/docs/faq#eta-vs-frege) does compare against Frege. Does anyone have experience or some insights to address my scepticism? I should say I've not used either solution but am monitoring Eta as a possible avenue to build Android apps.
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://eta-lang.org/) - Previous text "Eta" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
You can use Jupyter in Emacs with the [emacs-ipython-notebook](https://github.com/millejoh/emacs-ipython-notebook) package.
If the current political climate has anything to teach us, it is that we can dismiss these statements as "Fake Monad Insights" and immediately move about our business.
My hope with this is that better Haskell integration on a good front end combined with better backend Haskell for big data leads to a situation where Haskell really can show the advantages of purity for big data. If nothing else though Haskell is a lot like Mathematica and with a good notebook feature... 
&gt; perfectly obvious, but only in retrospect Best compliment I could ask for :) I discuss how we can extend it to [MPTCs](https://www.reddit.com/r/haskell/comments/8aa81q/deriving_via_or_how_to_turn_handwritten_instances/dwyvgru/)
Consider comparing to https://github.com/typed-wire/typed-wire. (See [samples](https://github.com/typed-wire/typed-wire/tree/cce9f8fa14b5033084d941d7be630b495967543a/samples)) Seems to be solving the exact same problem! Perhaps collab is possible.
Good idea. Has anyone compiled a compendium of questions?
Ah, I thought you were saying that IHaskell doesn't work (which was a bit frustrating to read since that's clearly not the case :) ). Jupyter notebooks have support for rich text and display output and better integration with other ecosystems such as GitHub, which renders them natively by default. There's also mybinder.org that will host them for you for free if you can write a Dockerfile with your dependencies.
Also, as a diehard Vim user, org-mode is pretty inaccessible to me and it's nice to have something that doesn't require Emacs. I used IHaskell almost exclusively when I was newer to Haskell and I don't think I would have been able to use something Emacs-based as easily.
Yes, this is lhc-0.11. The version on hackage is lhc-0.10. It's close to a complete rewrite, though.
&gt; Since `Show` in modern Haskell is pretty much only meant to be used for REPL This is totally untrue. `Show` is a fundamental debugging and logging tool. Also, `Show/Read` give you quick and dirty serialization/deserialization, very useful in many situations. Those were the original purposes of `Show`, and they're still completely relevant.
Have bee a dieahard about vim user for 15 years and switch to SPACEMACS which is for me the best of both world. Going from vim to spacemacs was pretty much seamless and org-mode is great ;-) I've tried IHaskel (through Kronos ?) l a few years ago (when I was still using Vim) and I really didn't like the edition experience. Maybe things have changed.
What is the relationship between this new kind of generalized newtype deriving and roles?
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://hackage.haskell.org/package/gl) - Previous text "gl" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
I don't use IHaskell with Vim, I use the browser which is an inferior editing experience but good enough for me otherwise.
I read an interesting article lately that I think oversells the case, but nonetheless makes a key point: there are some fields in which the Jupyter notebook has become effectively the standard way of communicating information. I got sold on them as important when I attended a PyData conference and saw _every speaker_ forego static slides in favor of notebooks. I'm a big fan of literate/livecoded presentation material in general, and this was the first community I'd seen it taken up in not just enthusiastically, but pervasively. I hope with projects like this, we'll reach a stage in which talks start to all come with notebooks rather than slides, etc. I.e. the fact that you can share these things on the web, and people can view and interact with them freely is what makes it exciting to me, and also the possibility of integration with various tools for improved visual display.
Sometimes, when you divide a complex task into smaller, simpler pieces, the result is both readable and compact: topBorder xs@(x:_) = map (const '#') x : xs leftBorder = map ('#' :) reflect xs = xs ++ reverse xs diag xs = [ys ++ '#' : zs | (ys, zs) &lt;- zip (inits xs) (tails xs)] crossed n = unlines . reflect . map reflect . topBorder . leftBorder . diag $ replicate m ' ' where m = n `div` 2 - 2
What is this even talking about? What famous person (people)?
&gt;good ol' Uncle Bob Who?
I only started using irc few days ago and people have been very helpful.
Maybe it was [this article](https://www.theatlantic.com/science/archive/2018/04/the-scientific-paper-is-obsolete/556676/?single_page=true)?
Frege has been around for much, much longer than Eta. The first version was in 2007. In those days, it was considered a "Haskell-like" language but not actually Haskell, because it differed from Haskell in [several important ways](https://github.com/Frege/frege/wiki/Differences-between-Frege-and-Haskell). Since then, most of those differences have been adopted in Haskell itself as extensions. So now perhaps it's more accurate to say that Frege is "Haskell 98 with a few extensions, that compiles to Java". Interaction with the JVM has a different philosophy in Frege than in Eta. In Eta you access external Java classes via the Haskell FFI, whereas in Frege you import them directly as Frege data types and functions.
Cool!
See /u/Lemmih's comment elsewhere in this thread - this is a continuation of the LHC project, but it's a complete rewrite.
https://github.com/jwiegley/hnix is essentially a catamorphic lambda calculus interpreter. Using a functor fixed point to encode expression trees yields some very useful flexibility. 
I'm with you but cannot ignore the freeing of developer resources for other work if native code generation could be offloaded to LLVM. That is, without any loss in developer productivity or performance drops due to LLVM's model. Finally I can't help but wonder in what ways LLVM would hinder experimentation that would be simpler with NCG.
[This garbage](https://twitter.com/unclebobmartin/status/982229999276060672).
So i was watching this video on [computerphile](https://www.youtube.com/watch?v=9T8A89jgeTI&amp;t=3s) about the y combinator and the guy poses a question, using a function rec f = f(rec(f)) define the factorial function like so rec (\f.\n. &lt;your code&gt;) and (more by luck than judgement) i've got an answer that works, but I'm not sure its what the actual answer is. Its fac = rec(\f n -&gt; if (n == 1) then 1 else n * f(n-1)) But I'm unsure of exactly what is going on. I get that the lambda is the the argument provided to rec, but what exactly is the argument for \f? Is it rec itself, or maybe the lambda? Is rec behaving like a higher order function that abstracts recursion in an arbitrary way? If so how? 
Good article! Two nits: the `Clos` constructor doesn't seem to need the `Monad` constraint, and the `MonadReader` instance can be derived using `GeneralizedNewtypeDeriving`.
Oh yep. I meant to post the link but somehow forgot in the midst of writing the rest of my comment :-)
omg I love drama
From a theoretically satisfying point of view, the best paper i know of on this topic is "Bananas in Space": http://www.cs.nott.ac.uk/~pszgmh/bananas.pdf Other representations may be better for actually working with, but this approach has been, to me, the best one for trying to understand how things actually work.
Hm. I duno about that. Maybe we should hold would-be gurus accountable by instilling a fear of public shame.
Here's a different way to restructure the types if you want to use a generic `Reader [Value m]`. To avoid the infinite type, we shall make the index `m` a newtype, so we still define `EnvM`, but we won't need its monad instance. Its only purpose is to keep types finite, and otherwise at runtime it's equivalent to a `Reader`, a fact that can be expressed by a `Coercible` constraint (or a pair of inverse functions `forall a. (m a -&gt; n a, n a -&gt; m a)` as an explicit parameter). newtype EnvM t = EnvM { unEnv :: Reader [Value EnvM] t } -- m = Reader [Value EnvM], n = EnvM evalAlgebra :: forall m n. (MonadReader [Value n] m, Coercible m n) =&gt; Algebra LambdaF (m (Value n)) ... pure $ Close e (coerce t) -- wrap ... local (\_ -&gt; c : ctx) (coerce t) -- unwrap eval :: Lambda -&gt; [Value EnvM] -&gt; Value EnvM eval t initial = runReader (cata evalAlgebra t) initial
Yes, or find a way to rewrite the function so that the value is already unwrapped at that point.
Regarding [the tweet](https://twitter.com/unclebobmartin/status/982229999276060672) and its responses, I believe a better way to approach this would've been to explore the results of the claims by the author asking some questions in a socratic way. That way, you begin by accepting their premise and treating them as an equal. Replies like "you're wrong" and "let me know when you're ready to be taught" is aggressive language. Ideas for programming come up over the decades and make people who have worked in the field for a long time feel uncomfortable and threatened by new things, especially if they have merit or are regarded well. People tend to be desperate to see something new as "just some concept I'm already familiar with but with different clothes on". They don't want to be in the dark, especially people like Bob Martin who are used to teaching other people what the cutting edge of programming is about (and getting paid for it). I empathize with that. He, along with other people like Douglas Crockford, find themselves in the same boat as the rest us mortals trying to understand FP. Looking at it charitably, I can see that Bob is struggling with the concept and isn't really settled on what the concept is. Clearly some of the Oleg article stuck. It just needs more work. The only thing achieved in that Twitter thread is to establish to outsiders observing, and to Martin himself, is that Haskellers are attacky and to him something like "social justice warriors". It's the opposite of for example the reputation of the #haskell IRC channel. Perhaps it's the medium of 140 characters that makes Twitterers mean and uncharitable. 
There are no plans for an interpreter.
A preferred solution is to keep it out of a Maybe in the first place—sometimes this takes some additional cleverness, and other times it is impossible, Impossible scenarios will arise, because the type system cannot express all invariants (and this why people are interested in dependent typing, it can express more). These are places where it may be reasonable to throw an error—the program just did something previously believed impossible and how do you handle what could only be a bug in the program? This, however, is a _last_ resort, and I’ve only done this about a half a dozen times total in Haskell.
Ahh, the nuclear option!
Nice! For the interested there are also a couple of other projects that showcase the an isomorphic setup :) - [miso-isomorhpic-stack](https://github.com/Tehnix/miso-isomorphic-stack) focuses on stack - [miso-isomorphic-example](https://github.com/FPtje/miso-isomorphic-example) uses nix
If you “know,” then prove it! Either with Maybe combinators or with better non-Maybe types. For instance, if you have a product two Maybes and at least one is always Just, use These.
Can't answer this without more context. Sometimes it's possible to get rid of the `fromJust` by using TemplateHaskell. But **always** use `fromJustNote` and in the note try putting some helpful text (along with values of relevant bindings) for the helpless soul who is tasked with fixing a crash in production.
`rec` is a function that computes a fixed point, i.e., a solution to the equation x = f x -- for some given f Indeed, by definition, rec f = f (rec f) The recursive function `fac` can be seen as the solution to this equation (with unknown `fac`): fac = \n -&gt; if (n == 0) then 1 else n * fac (n-1) that is, fac = (\f n -&gt; if (n == 0) then 1 else n * f (n-1)) fac or fac = g fac where g = \f n -&gt; if (n == 0) then 1 else n * f (n-1) i.e., `fac` is a fixed point of `g`, which is precisely what `rec` computes. fac = rec g 
No. either handle all the cases of the Maybe or find a way to express this invariant in the type system by not having the Maybe to begin with. uses of partial functions are doomed to fail.
The whole twitter exchange reminded me of this - https://www.youtube.com/watch?v=TXeTkQYvP6A
No, that's not a great idea. Later your code will change, either here or elsewhere, and then you'll get a mysterious run-time exception that's hard to debug. (Among other reasons why this is a bad idea.) As others have pointed out, this could be a sign that there's some problem with your algorithm that got you here. Theoretically, if it could never be `Nothing`, it shouldn't have been a `Maybe` in the first place. But in real life this does come up sometimes. Other ideas of things you can do: * If there is something reasonable to do if it is `Nothing`, do it, even though right now you know it won't happen. (Anyway, are you really sure that you'll never get a `Nothing`? *Really?*) * Rearrange your code so that the `Nothing` and non-`Nothing` cases are handled at the same place, and then use the `maybe` or `fromMaybe` combinator. * Use `maybeToList`to switch over to a list instead of `Maybe`, if it's easier to deal with a list that you know is non-empty than with a `Maybe` that you know is not `Nothing`. * Keep your calculation inside `Maybe` for now by using `&gt;&gt;=`, and then do one of the other things somewhere else where it is more convenient. Or perhaps further down in the calculation this value will anyway combine with a `Maybe`, so just leave it there.
It looks like webpack is mostly being used to wrap everything in a familiar react style architecture (a mostly blank vanilla index.js and a blob of code loaded in using the "real" language) It also has support for a pretty badass hot reloader for developing :)
&gt;The only thing achieved in that Twitter thread is to establish to outsiders observing, and to Martin himself, is that Haskellers are attacky and to him something like "social justice warriors" Is it really a "Haskellers" thing? Isn't it more of a "this is what happens when you say dumb stuff on the internet" thing? &gt; Replies like "you're wrong" and "let me know when you're ready to be taught" is aggressive language. The opportunity has been lost. As OP's essay implies, the goal here isn't necessarily to somehow enlighten and educate one Uncle Bob, but to prevent his audience from being misled. So demolishing his credibility is more than just fun, but also an effective tactic. That's somewhat tongue in cheek, but look at this: https://twitter.com/unclebobmartin/status/982969778741669889 Arguably, *more* aggression and humiliation might have prevented the continuance of this nonsense.
I'll just add that MP3 isn't an example of consensus. Entire codecs were created exactly for the reason that there was no consensus to use patented MP3, exactly because of the patents.
Thanks for posting this. Just recently I've been looking for a text covering similar topics.
FWIW, I agree. I wrote the post in frustration with the entire cycle, but most especially being asked by people I'm teaching Haskell to if I'm *sure* monads aren't *just X* because so-and-so (who is more famous than I am and therefore surely smarter?) said so. I'm not sure it's a problem specific to Twitter's character length; I think the issue with Twitter is that it's less segregated. The only place I ever see what Uncle Bob or Dan Kaminsky said is on Twitter, because they tend not to frequent FP-specific channels such as here or #haskell on IRC or the FP Slack. It's similar to what happened with the contravariance post I mentioned -- everything was fine until it made its way out of the community of people who already can read Haskell type signatures. Once it did, the article's assumption that the reader could read Haskell type signatures and knew basically what functors are was very upsetting to some of the readers it reached. I was both sympathetic to why it upset them and also defensive because, had I known the audience it might reach, I could have written it differently. But I agree entirely that the immediate "you're wrong" responses are a lost opportunity.
I didn’t know monad was feminine. Cool.
Java is not too far from Java bytecode, so compiling via Java doesn't impose too many restrictions. In a toy compiler project of mine I wrote a backend compiling via Java first, but ultimately I went to generate bytecode using the ow2 asm library. Eta uses its own codec-jvm Haskell library for generation. Advantages of going via Java: * Simpler to implement * The java typechecker helps a bit Advantages of going directly to bytecode: * Faster compilation * No "unnecessary" typechecking (assuming the frontend is doing that itself) * No bothering about checked exceptions for FFI calls * Access to goto instruction (Otherwise you might need a relooper like for wasm/binaryen, if the frontend produces a cfg) - Access to the invokedynamic instruction, you could use your own LambdaMetafactory 
Thank you for your answer, actually yes it does feel there is a problem with the algorithm or maybe the way am solving the problem to elaborate more about the design choice, I have the below : `Item` an item a data type with `itemid`, `category` and `price` `[itemSpecificPrice]` a list of items with a specified price, this list may not hold a items, if the item is not available in this list then its price is defined by the category list `[categoryPrice]` list of prices by category itemSpecificPrice :: [Items] -&gt; [itemSpecificPrice] itemSpecificPrice items = ... -- the above function will look at the specific price (using lookup)and get it, if not it will get the item price price for the category after this normalization, I can be sure that the lookup function will always find the price for a given item, maybe I should validate that all items have either category price or specific price? 
No. Letting someone firmly know that they are wrong doesn't need aggression and humiliation. Aggression prevents most people from even considering that you might be right, instead they immediately become defensive and emotional.
Thank you, do you mean to use `isJust` to be sure that it has a value?
&gt; I should say I've not used either solution but am monitoring Eta as a possible avenue to build Android apps. For what it's worth GHC is capable of producing Android apps via cross compilation to ARM these days. [reflex-platform](https://github.com/reflex-frp/reflex-platform) makes it easy to target web, desktop, iOS and Android with the same codebase even. However interop with Java APIs is pretty painful at the moment so if you need that Frege/Eta might be a better choice.
Here's something to ponder: What happens if the item's price can't be found in either the specific or category price lists?
How does this compare with Category Theory for Programmers?
Sometimes you *know* that something will be a `Just`, but it's difficult to convince the compiler that it is so. For example, putting a value into a map and then getting it out. There's a nice library called [justified-containers](http://hackage.haskell.org/package/justified-containers) that helps with that particular case.
I really like this talk that tries to show the motivation behind using Haskell: https://www.infoq.com/presentations/functional-techniques-complexity
thats right, I have already handled this case while constructing the data type, since I am parsing it from a JSON file, then the parser will fail if this case happens. Thanks
These guys' story comes up quite often. So [this good rebuttal](https://blog.plan99.net/modern-garbage-collection-911ef4f8bd8e) should come up just as often. TL;DR: It's not just latency vs. throughput, and Go makes a lot of other sacrifices.
thanks for the answer appreciate it thanks, it made everything make a lot more sense. So in essence x = f(x) means where in the domain of f does the input equal the output, and fac is that point...? One last thing, I find this sort of comp sci really interesting and would like to learn more about it without just using wikipedia and youtube- do you know any good books on lambda calculus and functional programming? 
Hey, please don't be sorry for anything. If anything, I am grateful that you put your brilliant mind into building a tool and opening it for the greater good. I realized that you really didn't want custom rules to take off. From the (lack of) good descriptions on howto build custom rules, as well as the lack of good naming, one could infer, that the last word has not been spoken, on what these concepts actually mean, how they align and how they are to be exposed. It is only now, after working with shake more intensely than ever and actually having read most of the conference paper, that the dust settles and that I begin to understand things more clearly. I think that custom rules could become an elegant choice for user extension, after the underpinnings have been understood/discovered. A step towards that end is to assign different names to existing entities in a thought experiment. For example "Builtin Rules": These determine how to deal with the technology that stores generated content (e.g. Files on a file system) and these rules map to two things at once: 1. code to find out the current "value" - i.e. a file modifaction time 2. code to generate the contents AND also stores it in that file. So maybe builtin rules could be called one of * ArtifactResolver * OutputStorage * ArtifactLocationProvider Also, users of GNU make may have the wrong intuition for the terms "rule" and "builtin rule"; a builtin rules in make say how common file patterns are built, e.g.: `n.o` is made automatically from `n.c` with a recipe of the form `‘$(CC) $(CPPFLAGS) $(CFLAGS) -c’`. See, [gnu make documentation](https://www.gnu.org/software/make/manual/make.html#Catalogue-of-Rules) 
agreed, actually I am using a data type to match the input data, I just put here a pair of list for mentioning a simple example.
Use type applications instead of proxies, and don't use unicode :)
&gt; So in essence x = f(x) means where in the domain of f does the input equal the output, and fac is that point...? That's right. There are some complications that a good theory will address: we need to restrict the set of functions under consideration to only functions that have fixed points, and we also need to be careful which fixed point we get. The usual approach is to study notions of *continuous functions* ([in the domain-theoretic sense](https://en.wikipedia.org/wiki/Scott_continuity)) and *least fixed points*. [Formal Semantics of Programming Languages, by Glynn Winskel](https://mitpress.mit.edu/books/formal-semantics-programming-languages) may be a good starting point.
Another point is that there is (almost) no runtime system. No glue code with a fixed number of "primitive operations", like "add" for every numeric data type. Instead, we just say in the frege Prelude (a module that is imported by default in every program): pure native + :: Int -&gt; Int -&gt; Int and that's it. Voila, there we have integer addition. And so on.
Is there anything ghcjs specific? Does it work with e.g. haste as well?
Haste is an entirely different beast.
Ok, in what way do you mean? 
Wow, gophers really gone wild here. This chart comparison at 24:30 really sucked. They're not even using proper benchmarking tools for Java like JMH, and the presenter basically goes like: _"We've also added Java here. But we have no idea what we are doing, so probably the result is impacted by JVM warmup, but we still added the Java to show how it sucks. Ya know, ya can turn some knobs and make it better, but we don't care and Java sucks so we didn't bother"_. 
Plus only looking at worst case pause time is really really stupid. If Java had the best pause time in the world, you'd never know from that graph because they only showed that one really bad pause during warmup. They claimed they represented the data this way because it was easier to compare results, but a box and whisker plot would have been far more accurate and would have been about as easy to compare.
But you actually can implement monads (or at least, continuations, which are deeply entwined) with pipes, though...
It's a very rare psyche that is emboldened to persist by a massive chorus of voices saying such things as: &gt; Uncle Bob polluting impressionable minds with piles of wrongness once again. May the world learn not only how wrong you have been, but also your complete lack of concern about leading masses of people astray with mental crapware. 
After watching the video and reading the article I think the video does a decent job at admitting it was a trade off and that if their requirements were different Haskell would of been a good fit
I think `bool` is only preferable when curried to get a function `Bool -&gt; a`.
What do you do when it doesn't have a value? `isJust` doesn't prove there is a value, it checks if there's a value. "Prove" in Haskell terms can be as straightforward as meaning that you write a function signature with the result you want (the "proposition") and then implement it (the "proof"). In your case, you'd be looking for a proof like: itemHasPrice :: Item -&gt; Price If you can implement that (with total, safe code) you've proved that every Item always has a Price. Your parser might only produce structures in which a Price is achievable, but because your parser's type (essentially, from a string to either your data structure or a parse failure) doesn't capture that, the type system doesn't recognise the proof and carry it forward into other expressions. Change the type of your parser, that is, change the type of the structure that it produces, to express _in the type_ that every item must have a computable price. Tools in your kit for this include `Data.List.NonEmpty` for a list that must have at least one item, `These` as parent poster said for having one or both of some data, and `Either` for having one or the other of some data.
I'm not debating that. Certainly if latency is your only goal, Go may be a good fit. However, the presentation and original blog posts spread misleading information about what those tradeoffs are. Their thesis centered around the idea that garbage collection is largely about throughput vs latency, but in reality this is only one very small piece of the puzzle, and there are *many* other tradeoffs you need to worry about.
I tend to use it in this situation but I must admit it makes me feel anxious. Is there a way to avoid this pattern? function xs | any (is Condition) xs = Left $ Error $ fromJust $ find (isCondition) xs | otherwise Right xs
AFAIK the only remaining friction is the alias annotations being NQR and the register allocator not being as good. The latter AFAIK can be solved with plugins and the former is (I think) just a lack of manpower in GHC. In terms of rest, LLVM consistently produces quicker assembly on all platforms in nearly every test case .. which is as you’d expect because just look at all the developer effort they expend on it and also it is the backbone of clang.
Every time I've used `fromJust` because I knew there was a value, I wrote a comment explaining why. Turns out they were all bugs anyway, and crashed my program at runtime.
I was about to type the same point in myself! Compiling to Java also takes care of getting the decades of optimizations of javac for free (of course the base compiler has to produce decent Java code too).
I would best that javac is much better at producing optimized byte code than Eta, so unless the code generated by Frege is terrible Java code, you get all those optimizations for free. 
Ahh I had misread your comment, either way thank you for the link it was informative.
Normal psychology suggests that someone seeing an aggressive counterpoint will actually shut down and lock down on their beliefs (regardless of their accuracy) and will believe them even more extremely and be even more resistant to further exposure to that differing viewpoint. If you want someone to see something the same way you do, the worst thing you could possibly do is be hostile and aggressive towards their viewpoints or character or ideas. However, if you just want to feel better about telling someone off on the internet, potential consequences be damned....
I don't agree with that idea of "normal psychology" at all. &gt; If you want someone to see something the same way you do [...] However, if you just want to feel better about telling someone off Well, what you want is to shake someone's confidence enough that they stop talking. Right? 
Thankyou for sharing that you found programming difficult to learn. "Intellectual entitlement" is a problem among programmers. People forget how much effort they put in to achieve their current skill level and assume that they have "done all the learning". If an unfamiliar technology appears and is difficult to learn then it is a problem with the technology, because "I already know programming, and if I don't understand it then it's not programming". Learning new things is hard, and that's okay.
Social pressure, conformity and shame can still influence people; that doesn't change the fact that aggressively putting down someone's ideas and worldview will almost always push them towards extremist views and will have a backlash effect--achieving the opposite of convincing them that they're wrong. &gt; Well, what you want is to shake someone's confidence enough that they stop talking. Right? What would that accomplish in the grand scheme of things? Especially considering that everyone else who reads that aggressive viewpoint will also have a similar reaction. To my mind there's no point in addressing a wrong viewpoint if the way you go about it is almost guaranteed to make the problem exponentially worse.
Let's figure it out! I've never used that library before, but let's see if the types tell us what's going on. Let's see, we begin with a `[Either Char Int]`, which [`S.each`](http://hackage.haskell.org/package/streaming-0.2.1.0/docs/Streaming-Prelude.html#v:each) turns into a `Stream (Of (Either Char Int)) m ()`, which [`S.partitionEithers`](http://hackage.haskell.org/package/streaming-0.2.1.0/docs/Streaming-Prelude.html#v:partitionEithers) turns into a `Stream (Of Char) (Stream (Of Int) m) ()`. Hmm, I would have expected a pair of streams, why do we receive two nested streams instead? Do we have to consume all the Chars before we can obtain the inner stream and start consuming the Ints? Nah, that would be `Stream (Of Char) m (Stream (Of Int) m ())`. The inner stream is not in the result position, but in the base monad position. Ah, I get it! `Stream (Of Char) m r` is a computation which produces a bunch of Chars, and in between those Chars, it performs some `m`-actions; and so `Stream (Of Char) (Stream (Of Int) m) r` is a computation which produces a bunch of Chars, and in-between those Chars, it can also produce some Ints. And some `m`-actions. I think the reason we don't get a pair of streams is because we need to perform those `m`-actions in order to get to the actions which produce values, so both stream would have to perform the same `m`-actions. Anyway, we now have a `Stream (Of Char) (Stream (Of Int) m) ()`, which [`S.chunksOf 2`](http://hackage.haskell.org/package/streaming-0.2.1.0/docs/Streaming.html#v:chunksOf) turns into a `Stream (Stream (Of Char) (Stream (Of Int) m)) (Stream (Of Int) m) ()`. That's quite a mouthful. Let's see, it's a outer stream which produces a bunch of inner streams, and in between those inner streams, it produces a bunch of Ints. Those inner streams are producing Chars, and some Ints between those Chars. I think it's already clear from the type that this is where your bug is: there are two places in which the Ints can be produced. They can be produced by the outer stream, in between producing the inner streams, and they can be produced by the inner streams, in between producing the Chars. I am guessing that the first inner stream consist of the first and second Chars from the original list, plus any Ints found in between those Chars, then the outer stream produces the Ints found in between the second and the third Char, then it produces an inner stream consisting of the third and the fourth Char plus the Ints found between them, and so on. Anyway, so we have this `Stream (Stream (Of Char) (Stream (Of Int) m)) (Stream (Of Int) m) ()`, which `S.mapped (lift . chunkContents)` turns into a `Stream (Of ([Int], [Char])) (Stream (Of Int) m) ()`, that is, a stream which produces `([Int], [Char])` pairs and Ints in between those. So it's no surprise that you sometimes end up with an Int such as `3` outside of those pairs. To avoid producing standalone Ints, you should strive to construct a `Stream (Of ([Int], [Char])) ()` instead of a `Stream (Of ([Int], [Char])) (Stream (Of Int) m) ()`. So, `partitionEithers` gives us a nested stream structure, and this nesting brings us trouble. Chunking exacerbates the problem, because it uses its `m` both in the inner streams and in the outer stream; so when that `m` produces values, we end up with Ints in two different places. So the first thing we need is a version of `chunksOf` which doesn't do that: chunksOf' :: Monad m =&gt; Int -&gt; Stream (Of a) m r -&gt; Stream (Of [a]) m r chunksOf' n = S.mapped S.toList . S.chunksOf n Using it, it is easy to independently chunk both the `Left`s and the `Right`s of a stream of `Either`s: chunksOfEither :: Monad m =&gt; Int -&gt; Stream (Of (Either a b)) m r -&gt; Stream (Of [a]) (Stream (Of [b]) m) r chunksOfEither n = hoist (chunksOf' n) . chunksOf' n . S.partitionEithers But grouping the first Char chunk with the first Int chunk, and the second Char chunk with the second Int chunk, etc., is a more difficult task. This part has nothing to do with chunking though; if you can write the following function, you should be good to go. pairLeftWithRight :: Monad m =&gt; Stream (Either a b) r -&gt; Stream (a, b) r But what should such a function do if there are more `Left`s than `Right`s or vice versa? Drop them, like `zip`?
I think it does change that. Or rather, I don't think it was ever true, so it didn't have to be changed. Aggressively putting down someone's worldview is something that works against their holding that worldview. Of course, it won't always cause them to abandon it. But it will be a push in the direction of them abandoning it, *not* in the direction of them holding it. What you're proposing is what would be called in medicine a "paradoxical effect," i.e. the medicine has the opposite of the effect you would normally expect (e.g. a stimulant makes someone sleepy). It might happen sometimes, I wouldn't claim otherwise. But normally the stimulate wakes you up. That's why it's a stimulant. Normally, the social shaming causes you to stop doing the thing you're being humiliated for doing. Discouraging a thing discourages the thing. The paradoxical effect, to the extent that it exists, is the exception, not the rule. &gt; considering that everyone else who reads that aggressive viewpoint will also have a similar reaction As explained, I don't accept this premise. &gt; What would that accomplish in the grand scheme of things? Nothing really. Like I said before I'm being a bit tongue in cheek. But only a bit. Nothing is accomplished "in the grand scheme of things" by gently persuading old Bobby MonadPipes that he was wrong, either. I just don't have a problem with seeing the smack laid down under appropriate circumstances. (In fact, I rather enjoy it. More ego, more smack, makes me more happy.)
&gt;The only thing achieved in that Twitter thread is to establish to outsiders observing, and to Martin himself, is that Haskellers are attacky and to him something like "social justice warriors". Yup. The thread is a mess, but that is no excuse to write "leading masses of people astray with mental crapware" or "lol dude stick to tdd you're clearly out of your depth here" -- that is aggressive, and also shows terrible taste.
&gt; Aggressively putting down someone's worldview is something that works against their holding that worldview. ... But it will be a push in the direction of them abandoning it, not in the direction of them holding it. It's been known and studied extensively for a while now that this is not the case. [The New Yorker has a great article on it](https://www.newyorker.com/magazine/2017/02/27/why-facts-dont-change-our-minds). Confronting people's worldviews almost *always* causes them to double down on it, *especially* when done so in a hostile way. I'm not "proposing" this as some sort of hypothetical on my end, but rather as an established and well known theory in modern psychology (theory here being the scientific sense, much like evolution is a theory even though it's basically discussed as if it were fact). &gt; Normally, the social shaming causes you to stop doing the thing you're being humiliated for doing. I think what might be tripping you up here is the separation between "things" and "ideas"; the distinction is very important psychologically. People behave very differently with their ideas than they do with their actions; shaming someone publicly for their *action* will indeed make it less likely for them to continue doing it, however the same doesn't hold for attacking someone's worldview (the 2016 US election should be ample proof of this). Just out of curiosity, why don't you accept the idea that confronting people about their ideas makes them more resistant to changing their mind?
That’s correct. `f` is equal to the inner lambda, `\n -&gt; …`. (Recall that `\f n -&gt; …` is sugar for `\f -&gt; \n -&gt; …`.) In the standard library (in `Data.Function`), `rec` is called `fix` and is defined as: fix f = let x = f x in x Which means `x` is a reference to the result of the function (`\n -&gt; …`), and is *also* passed as the first argument to the function (`f`). This cycle in the definition of `x` is what provides the “loop” needed to perform recursion. Note that you don’t have to define only functions with `fix`: you can also define recursive data structures, like `fix (1 :)` which is equal to `let x = 1 : x in x`, an infinite stream of 1s—or, if you prefer, a circular linked list where the tail points back to the head.
I actually read that article and it has nothing to do with what we're talking about here. Pretty disappointing. I mean that's bordering on offensive. That's a long article. The article is more representative of its title which says "Why Facts Don’t Change Our Minds." (Facts are different from "aggression," "humiliation," etc. which is what we're talking about.) But even what it says about facts is not that they have the *opposite* effect to what would be expected. Just that they're weaker than one might expect. There's nothing in that whole article about a paradoxical effect. So... wtf? &gt; Confronting people's worldviews almost always causes them to double down on it, especially when done so in a hostile way. I want to point out a certain relevant selection effect. If you have someone who has gone their whole life (or let's say years) believing in some crazy cult idea or whatever, then they have probably been confronted lots of times and (by premise) have not responded to such confrontation. This is just something important to keep in mind. &gt; shaming someone publicly for their action will indeed make it less likely for them to continue doing it, however the same doesn't hold for attacking someone's worldview (the 2016 US election should be ample proof of this). What? How? &gt; Just out of curiosity, why don't you accept the idea that confronting people about their ideas makes them more resistant to changing their mind? Well, for one thing, it doesn't make any sense. Opposition is at worst weak evidence against your position. More opposition is more evidence. More and more evidence against your view doesn't make you more and more confident in it. If I believe it's not going to rain today, I don't become *more* confident when the lightning and thunder start. For another, if this were actually true we would see a lot more non-conformity and idiosyncracy, because any initial seed of non-conformity would just expand and strengthen in the face of social opposition. Every idiotic idea or random mistake that all the other kids laughed at would just get stronger and stronger so that adults would be *especially* likely to have idiosyncratic mistaken beliefs that were *especially* prone to bringing forth the most hostility and fiercest mocking. I believe that we see the exact opposite in the real world: as people are socialized, they become more conforming, they shed their idiosyncracies. This is essential to the whole reason that there is such a thing as culture (or at least culture that includes views/beliefs), religion, etc.. So when we do see people with long-held mistaken beliefs it's usually because of an entire social environment that socially supports those beliefs (and very often aggressively ridicules opposing beliefs), and almost never idiosyncratic individual beliefs except in the case of literal schizophrenics. I suppose you might argue that what enables this is the fact that people naturally respond with opposition that is non-confrontational, that people are naturally very patient with others who are wrong, that it's very rare that someone gets called a moron or laughed at for making a mistake and *because of that rarity*, social correction is usually effective. But I don't think that all of that is factual. &gt; I'm not "proposing" this as some sort of hypothetical on my end, but rather as an established and well known theory in modern psychology OK, what's the theory then?
Ok, what I meant was if ghcjs could be replaced with haste in this project? (Haste is also GHC with a js outputting back end, but it generates much smaller and faster code.)
What does this buy you over using ghci?
Hi, no specific question, just new to haskell and some feedback would be appreciated To learn the language I built a little gui for xinput with gtk2hs. https://github.com/Attox/xinput-hs
I'm guessing one advantage is that it doesn't require the user to install anything and is available anywhere a web browser is.
Doesn't that require leaking memory? Or at least doesn't reclaiming the leaked memory require the total time across pauses to be proportional to heap size? If so, it's a little disingenuous to say this isn't a proportional pause time just because it's spread over multiple pauses.
I use the precompiled binaries for HLint, GHC, Stack and Cabal - all of which are available online released by the projects. The issue I have is the libraries I depend on, and these change over time, and also are quite large to cache. Any ideas there?
Especially not after the "yay, we offer xmpp/irc bridges!" became "haha, you're locked in now, those bridges are going away".
&gt; social pressure, conformity, shame, etc., influence people. I'd be pretty sad to be part of a language community where it was considered appropriate and acceptible to use social pressure and shame to influence people, even people who are wrong about monads. 
Thank you for your answer, I liked this approach, however, it is a bit ambiguous for me how to express that in the above. to exemplify, let me share some data type if that is possible: data Item = Item {itemid :: Id ,itemPrice :: Int ,itemCategory :: Category }deriving(Eq,Show) -- not all items are in the list data ItemSpecificPrice = ItemSpecificPrice { ItemSpecificPriceItem :: Id ,ItemSpecificPriceAmount :: Int } data CategoryDefault = CategoryDefault { categoryDefault :: Category ,categoryPrice :: Int } data Company= Company { companyName :: String ,itemSpecificPrice ::[ItemSpecificPrice ] ,itemCategoryPrice :: [CategoryDefault ] } Data Input = Input {companyData :: [Company] , items :: [Item] } The data type `Input` is the structure parsed, `items` are shared across all companies, `[ItemSpecificPrice]` may not list all the items, when this is the case the price should be deduced from the category, any suggestion of how to change the type of the structure ! 
I think we are talking about slightly different things. You seem to be referring to _total_ pause time, while the Go guy was referring to _per-pause_ time. I added that some algorithms (as a latency vs. space trade off) are able to just skip collecting some garbage, which is desirable in some cases, besides the mere fact that doing less work (when possible) is usually a win.
&gt; [CircleCI] allows me to specify my docker images as builders You can build inside the docker container in travis - in this manner you don't waste time for building your toolchain. &gt; I know most of the time spent in TravisCI is compiling and installing tools and a minimal amount of time was testing my code. Firsty, as mentioned above, you can use docker and images with tools already baked in. Secondly, you can also use caching to avoid recompiling of dependences each time: https://docs.travis-ci.com/user/caching/ So what's new here? What CircleCI brings to the table? Isn't this post sponsored by CircleCI?
Good to know. Thanks! :)
In the model as it stands, there is no guarantee that a company as a default category for all items and even if you can guarantee it at "parsing" time, nothing can stops it to change. You could have instead for each item a price with it source (specific to the idem or from a category) data Company = Company { companyName :: String , itemPrices :: Map Item (Either ItemSpecificPRice CategoryDefault) } or equivalent. 
Glad to hear it :)
Well said 👏Thank you for the response :)
I thought that in Haskell, least fixed point and greatest fixed point coincide? Or is that only at type level?
This isn't fair, other people have also talked about how CircleCI makes their builds faster: http://bitemyapp.com/posts/2016-03-28-speeding-up-builds.html
Using Appveyor for caching the cache always ends up being in the 200Mb-1Gb region, which exceeds the amount of space they have for the cache. Part of the issue is that most of the cache is GHC, but there's really no point in caching that, since fetching it afresh isn't any slower.
Do you mean streaming in general or streaming in Haskell?
Thinking about that it could go further. GHCi could use quickcheck and show a small array of values and results: λ&gt; Foo (+ 1) Foo &lt;func: Int -&gt; Int&gt; sample: map Foo [0, 3, 56, -9] = [1, 4, 57, -8] 
Javac does hardly any optimization, starting with 1.3, optimization is deferred to runtime with the HotSpot JIT. Which is one reason Kotlin has essentially identical performance to Java, despite javac having existed decades longer. 
As someone in my final year in Trinity this sounds awfully similar to my experiences! Great article 
Yes, I can confirm the disclaimer is stale, as of today! I've updated the API, to make it consistent with the likes of `Data.Map` (encouraging qualified imports) and released version 0.3.0.0 on Hackage!
Glad you like it :) Hope to see you at the Dublin meetup if you're not too busy on the FYP ;)
Good to see more miso examples! Also checkout: https://nixtodo.com/
I do not think so. They have for one very different ways of FFI'ing into JS.
When is it? My FYP is in Haskell so I would have a good excuse at least... 
Here's the link: https://www.meetup.com/haskell-dublin-meetup/events/249428074/ There's also a survey because we're trying to figure out the future of the group :) 
&gt; social pressure, conformity, shame, etc., influence people. Except in this case the roles are reversed. Uncle Bob is a well-known reference in the programming world and those who oppose his view are just unknown people on the internet. Who do you think benefits from social pressure here? Moreover, as other people said, it would be sad to be part of a community that encourages social pressure and shaming, for whatever purpose.
Thanks for the very thorough explanation! Yes, that makes sense when I think about what I've read about the difference between data and codata - it always stood out to me that none of them mention how you can't actually specify in Haskell, "this recursively defined type *must* be finite". That makes sense if Haskell only has codata, but data can be represented as codata. 
The Haskell package.
Yes type signatures everywhere, even for simple things like data Endianness = Little | Big deriving (Eq, Show) reverseEndianness :: Endianness -&gt; Endianness reverseEndianness Little = Big reverseEndianness Big = Little
[removed]
This is such a great approach to analysing a complicated problem.
I think I did, but I never received the confirmation email. It isn't.
Also https://groups.google.com/forum/m/#!msg/mechanical-sympathy/JJTUs_jXw5A/I2O-QLHNCgAJ
It's definitely in the same problem space of generating web API code for clients and servers. `typed-wired` appears very similar to `nirum`. Contrasting to Fluid, `type-wired` is bounded on HTTP, doesn't have automated versioning, and doesn't have a programmatic/smart interface. That isn't bad, but they don't line up with the same goals and tradeoffs. I'm open to hearing counter arguments.
Interesting. What do you consider intermediate? Also, I'm in the PST time zone but prefer to start early (6-7am), would that suffice?
yes because others will be reading your code.
It is not necessary (unless there is an ambiguous type), but it helps with readability a lot.
&gt; Is it really necessary since today's tool can infer the types on the fly? That makes a lot of assumptions about how people view your code though. More often than not I end up reading other peoples code via github/hackage/diffs/cmd line so even when I can mouse over for signatures for me it's helpful if they are written down.
I second your recommendation of "Haskell Programming from first principles" by Chris Allen (http://haskellbook.com). I am going through it now, and it is among the very best introductions to Haskell, let alone any language.
If repl.it had an ability to use Haskell packages from Hackage it would be a really great thing!
&gt; I second your recommendation of "Haskell Programming from first principles" by Chris Allen and Julie Moronuki
Also, compilation is faster when you add type signatures. At least for top-level functions. But readability if much more important.
I'd appreciate any feedback to overcome the performance issues. Once I add type signatures, would it be worth it to upload this *minimalist* project to hackage?
Super noob questions: how does using Docker help in speeding up builds? If the key thing is caching the container, why doesn't caching the directories have the same effect? Also travis has docker support: https://docs.travis-ci.com/user/docker/ although I don't know what the difference is between Travis's support vs CircleCI's support.
WRT code quality, something simple you can do is add this to your `primality.cabal` file: ``` ghc-options: { -Wall -Werror } ``` This turns on all warnings and stops compilation on a warning. This will require you to add type signatures, as others have suggested, along with some other things. You could also consider adding a test to run `hlint`
Thank you. :)
Whenever the m-word comes up (as has been the case several times over the past few days), I feel tempted to dig up some blog post I read a while ago. Can't find it anymore. It was called something like "Purely Algebraic Abstractions". I think the gist of it was that there are something like three aspects you have to take into account when trying to grok some unfamiliar abstraction, like `Monoid`, `Functor`, or `Monad` of course. * Specifics of the programming language, that is, how is the abstraction *represented*. Think ADTs, type classes, pattern matching, do-notation, all of which are initially unfamiliar. These are minor issues I think, given some patience and practice. A pitfall is *higher-kinded types* and the fact that in `m a`, the `m :: * -&gt; *` is the `Monad`, not the `(m a)`. * Intuition. People keep asking "What is a monad", and other people keep replying to the question "Can you give me an example of an instance of the `Monad` typeclass?". Because that is how they built intuition themselves, they had to look at several *concrete* examples to get a feeling for what problems can be solved, what kinds of patterns are captured et cetera. * What do all these examples have in common? Turns out, not much. The commonalities are captured by some type class or algebraic structure. We can still talk about some `(M, +, 0, ..)`, that is some carrier set (some "things") `M`, some operations/distinguished elements, and some laws. This is the bare-bones definition that allows us to determine if X is an instance of Y, but by necessity, everything that was related to the *concrete* we got started with, is now gone. Kind of. At least it isn't part of the definition. But that is deeply unsatisfying, if you're used to dealing with definitions referring to the concrete. That is what we learn in school, after all. Vectors are some arrows you can draw on paper, or a physical observable that comes with a magnitude and a direction. Then you might learn about eigenvalues and eigenvectors, again by looking at concrete examples. Everything is fine until suddenly you are not dealing with rotations anymore and you ask yourself "Okay, but then, what *is* an eigenvector really?". And you find yourself in the same mess, until you are ready to "just make piece with the definition". Same with groups, which are not inherently related to symmetry operations, or Monads not really being about failure or launching missiles. Maybe Bob should have a look at the `Tardis` Monad? Regarding Monad tutorials, I think a viable approach would be something like: * Okay, instead of `a -&gt; b -&gt; c` we want to model effectful computations as `a -&gt; b -&gt; m c`. * We might also want something akin to `let` bindings, just for this kind of "smart function", if you will. * What if somebody took `let` bindings away from you? You could YOLO things with `(&amp;)`. * Introduce `(&gt;&gt;=)`, maybe `Identity` to show the correspondence, bam! Monads. Big whoop. The problem is that there is no way for me to tell if that would have helped me as a beginner, of course.
Thanks Ryan, that answer is enlightening.
I don't know about that. Category theory builds off of Algebra and even group theory. I started down that route trying to go through Category Theory first, but it was too advanced for me. I decided it made more sense to learn Algebra/Group Theory first. But to each is own. Either way, good luck on your journey!
I don't know enough about opengl to have an opinion. Sorry! I just used `gl` a few times when following guides like https://learnopengl.com/ and it worked well because `gl` is just bindings over OpenGL api, so everything translates fairly straightforwardly. Also, [this guide](https://lokathor.gitbooks.io/using-haskell/content/opengl/) uses `gl` as well.
With the lack of example documentation in the Haskell ecosystem, Rosetta Code was the single biggest tool I used to keep me productive when learning several years ago.
After hearing all that, I think that probably your best strategy here is to believe the types. You are sure that the item will always be found, but the reasons are *ad hoc* - the way you set up the data, various loosely related parts of the code that you tried to be consistent about, etc. The types are telling you: don't rely only on that. You're probably right, but in real life thing sometimes go wrong. Write a case that says what to do if the "impossible" happens and the item isn't found - display an error message, or whatever.
`case` is the only way to *prove* it has a value. More specifically, the right hand side of the arrow of a `Just` pattern match. Every other total combinator (like `maybe`) has that under the hood.
Besides -O2, Are there any compiler's flags that would optimize resource usage? For relatively not so big numbers, I find it consuming a lot of memory, without understanding the need of that much memory (by examining the algorithm).
Regarding the time zone that would be fine. I consider that an intermediate developer would have **at least** the following properties: 1. This is not your first professional experience with software development. 2. You have solid understanding on the basic CS concepts (e.g. basic data structures, what is OOP, FP, Static vs Dynamic typing, regular expressions) 3. You are fluent in at least one programming language and dabble in a couple more. 4. You understand why the IO type is necessary and know how to use it (this also means you know how to use *bind*, *return* and the *do* notation). 5. You are familiar with FP/Haskell vocabulary (words like monad, applicative and lenses are not scary)
The roles are reversed... from what? Remember, I'm talking about the nature of human psychology in this phrase. I am making a factual claim. &gt; it would be sad to be part of a community that encourages social pressure A community by its nature constitutes social pressure. For example, by speaking in English we are exerting social pressure on others to use that same language. You are never not exerting social pressure (in any social situation). It is different to "use social pressure" though (as in consciously decide to employ some strategy). But I wasn't saying "let's all decide to exert social pressure," I was saying that social pressure exists as a phenomenon that influences human minds. ping /u/tomejaguar
Great to see more number-theoretical projects in Haskell! 1. Consider using `Math.NumberTheory` namespace instead of `Math.Number`. The former convention is shared by most existing libraries, dealing with number theory: [arithmoi](http://hackage.haskell.org/package/arithmoi), [integer-logarithms](http://hackage.haskell.org/package/integer-logarithms), [pell](http://hackage.haskell.org/package/pell), [HaskellForMaths](http://hackage.haskell.org/package/HaskellForMaths), [canon](http://hackage.haskell.org/package/canon). 2. Use `Math.NumberTheory.Powers.General.isPerfectPower` (http://hackage.haskell.org/package/arithmoi-0.7.0.0/docs/Math-NumberTheory-Powers-General.html#v:isPerfectPower) instead of `isPerfectPower`. It should be both faster and more robust, when numbers become really large. 3. Use `Math.NumberTheory.ArithmeticFunctions.totient` (http://hackage.haskell.org/package/arithmoi-0.7.0.0/docs/Math-NumberTheory-ArithmeticFunctions.html#v:totient) instead of `eulerTotient`. Your implementation has linear complexity and is much slower than it could be. Disclaimer: I am a maintainer of [arithmoi](http://hackage.haskell.org/package/arithmoi), so my views may be biased. What kind of performance issues did you encounter?
Posting jobs without any details about salary / benefits is not a great practice. I'm not actively looking for work, but if I were, it would be a major turnoff, and a good reason for me to ignore this posting: it communicates you don't value your workers. Especially when paired with "very young startup", makes it seem like you aren't going to may much or anything, and I'd just be wasting my time researching the company, writing a cover letter, etc.
Generational collectors scale with live data, right? For minor collections with card marking the amount of written data, I guess,
Does anyone know why haskells GC is so much stop the world? I've been under the impression that haskell has very good conditions for having a more or less completely concurrent GC.
I like [this](http://blog.sigfpe.com/2006/08/you-could-have-invented-monads-and.html) blog post that demonstrates monads by re-inventing them together with the reader.
Let's not get wound up about this.
I would be very excited to hear from you when you upload that! I wanted to use the package, and was sad that I couldn't.
I recommend [ghc-devs](https://mail.haskell.org/mailman/listinfo/ghc-devs) mailing list instead of reddit for this kind of question. A small subset of GHC developers hang out here but most of them respond to ghc-devs emails.
Just speculating, but as Mark-Sweep/Generational stop the world is often the simplest and cheapest way to build a GC runtime, this is probably what Haskell started with at least. The community might be much more focussed on other issues to be bothered by trivia such as latency.
You don't know how happy that makes me 😄
The project is nice, but it's rather awkward that we now have two rather identical versions of the containers code floating around. Is it possible/how hard would it be to recover the existing `un-unpacked` interface from the `unpacked-containers` code?
I tried to build your code from github. Cabal-file lists module `Math.Arithmetic.Modular`, but there is no such file in source tree. Could you please add it?
Is the approach of "bananas in space" related to HOAS in some way?
Done! Thanks for notifying me about this.
I forgot to continue this since I don't use Reddit much anymore, but in Java at least, you're right, you need `implements`. In C++ this isn't the case (template instantiation at a type in some context where you use class methods of that type merely has to have the right structure). In OCaml, it's obviously not true since you have structural types and modules. Go also has structural typing to provide interfaces, IIRC. Rust is nominative, I believe (except tuples; it had structural records in the past, as well). If we expand this slightly outside statically typed languages though, pretty much every dynamic language works on some form of protocols or "shape matching" against a particular interface at some level, and those interfaces do not need to have dependencies on downstream consumers, or vice-versa. Personally, I think this is a fine comparison when talking about the nature of interfaces, in this context. But not everyone would agree (certainly coherence makes no sense in these languages anyway.) My complaint in a real sense has little to do with static vs dynamic types -- it's more about who is responsible for the choice of what interface implementations are available. In Backpack, the user is responsible for available interface implementations, and implementation choice, at the use-site. With typeclasses (barring orphans), essentially the author (of the type *or* the class) is responsible for the implementations available, but users can choose the use-site. Both of these have major tradeoffs, static vs dynamic aside.
In my understanding, it really depends on where you draw the line of what's "standard Haskell". For the classes in `base` (which is arguably a standard), this is a pretty easy exercise (just load it up in GHCi, start querying with `:i Monad` and chase the pointers). For common stuff such as `mtl`, the graph has depth 1 to `base` (all classes have a Monad constraint). 
Thanks. I run your library with profiler and it shows that most of the time and memory is spent in `Math.Polynomial.Univariate`. List representation is extremely slow for arithmetic on polynomials. I have not worked with polynomials much, but I suggest you to try [polynomial](https://hackage.haskell.org/package/polynomial-0.7.3/docs/Math-Polynomial.html) package. Or alternatively one can implement polynomial arithmetic, using vectors instead of lists, from scratch.
I'm not sure what the implication is :P. That the documentation should be improved or that these coding problems should be solved in Haskell?
&gt; Is there any sort of manifesto (or blog post, etc.) formulating this concept of "humanist documentation" that you mention? I might enjoy reading such a thing critically. (The top Google hit for "humanist documentation" is this thing, which feels like a reductio ad absurdum of the aforementioned SO Documentation project.) A classic example is the documentation for Python's Flask, which is so focused on forming a narrative it fails to cover lots of common cases. 
Hm, well the course in which this textbook is used is 15-210 so you can look for any course notes/recordings related to this. While Bob has been involved in this course a few time it's usually taught by others, but all the lecturers are quite good in my opinion. Here's the [official course page for 210](https://www.cs.cmu.edu/~15210/). In particular the Schedule tab has lecture notes, but I have no idea how closely the fit the textbook since I'm not involved in the course this semester. The language based cost model is quite nice but sadly I don't think it's fleshed out in an introductory way beyond that book/the above notes.. If you look at the publications of Guy Blelloch and perhaps Umut Acar (I'm sure I'm missing someone else here..) as well as Bob Harper's you'll find other examples of the methodology I'm sure.
This may help sketch some connections https://www.schoolofhaskell.com/user/edwardk/phoas
I agree the Haskell IRC channel is actually full of helpful and polite people. It stands out for this. IRC itself is a pretty awful contraption.
&gt; It is by a wide margin the best category theory book ever written to this day, and one of the best textbooks ever written on any subject. Bold claim :)
It still seems somewhat disingenuous to talk about per-pause time. I could write a GC that runs 10ms of puase, then 1ms of program. This is obviously low time *per-pause*, but is still going to have high latency. You have to also beat a certain threshold of pause frequency in order for low per-pause time to be meaningful.
There are a lot of tradeoffs w.r.t. concurrent GCs. They sacrifice more than just throughput. IIRC, pause frequency and memory overhead also go up. Concurrent collectors aren't just usually better. It depends entirely on the use case. It'd be nice if GHC had an option for a concurrent GC.
&gt; but each actor ("process") has its own heap Isn't this standard in generational GCs? GHC's has a different G0 nursery for each capability, for instance.
Terribly sorry, the second part was irrelevant to your question (package dependencies rather than typeclass dependencies), so I removed it.
As a fairly newbie haskeller please both!
The issue is that Go's collector is concurrent. There is an initial stop-the-word phase that sets up some data structures and marks global variables. Then the program restarts and the actual marking phase is done concurrently with the user program executing. Finally there's another small STW pause to do some more cleanup to prepare for the sweep phase which the proceeds concurrently again with the user program running. Go has optimized for reducing these STW pauses. The pause frequency is estimated such that the concurrent sweep phase will begin just as the program allocation reaches the target heap size for the next collection. The proposal to eliminate stack-rescanning to reduce STW pauses (as these were previously done while the world was stopped) https://github.com/golang/proposal/blob/master/design/17503-eliminate-rescan.md The pacing algorithm: https://docs.google.com/document/d/1wmjrocXIWTr1JxU-3EQBI6BK6KgtiFArkG47XK73xIQ/edit The source code for the collector contains a detailed comment at the top explaining the different phases: https://golang.org/src/runtime/mgc.go
I was implying the second. If others are looking to a simple way to help, Rosetta Code was a big help to me so I think it would help others as well. This is a more actionable list of tasks than just yelling from the roof "Hey everybody, you need more example code"
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [golang/proposal/.../**17503-eliminate-rescan.md** (master → 9830606)](https://github.com/golang/proposal/blob/9830606d88efaa072ad54d61cb0d87ac0710f1d1/design/17503-eliminate-rescan.md) ---- 
Just implemented "Active Directory/Search for a user" (https://rosettacode.org/wiki/Active_Directory/Search_for_a_user).
I assume this also satisfies "Active Directory/Connect" https://rosettacode.org/wiki/Active_Directory/Connect
Yes.
You can get publicly shamed for saying *anything* on the net. Fear of public shame means people don't join the conversation.
#ghc on freenode is good for help too
Well, O(log n ^ 5) can easily be pretty big in terms of absolute value. I doubt that strict evaluation of lists will make a significant difference here. But if you'd like to stick to the lists, there is still a plenty room for improvements. Do you actually need such generic representation of polynomials? Is `Big` endianness used anywhere? Can `shiftFactor` be just `Int`? For instance, `degPoly` alone is responsible for 20% of time and space, and much of it due to `genericLength`. If `shiftFactor` will be changed from any `Num` to `Int`, you'll be able to use `length` and save some ticks. It would be even more beneficial to keep evaluated `degPoly`as a field of `Polynomial`. Also please add type signatures. It greatly simplifies code review.
`genericLength` because the degree of the polynomial (length of list) is the size of the value returned by `smallestR` which can get pretty big for big primes. But in any case, current end-users machines will not be able to manipulate lists with size bigger than upper limits of `Int`. Which makes it a possibility to improve performance. While I wrote the library with most general types possible, now I see how it can get in the way. I was counting on compiler's optimizations to speed things up, but I think my expectations about the compiler's strategies went a bit too high.
With respect to b, `cabal new-build` with multiple packages (and a `cabal.project`) does the right thing if just one part of a dependency changes - it won't rebuild an entire other package just because one module changed (unless, of course, everything depends on that one module).
Yeah, that's the same link as mine. All public lecture notes appear to be (perhaps slightly updated) chapters from the book draft. Google searching, too, doesn't appear to come up with anything and certainly no video. Like I said, from the text itself there really doesn't seem to be much hand holding through the learning process for something at this level. I know that since undergrad prospectives now apply directly to Computer Science, they're likely to have had some prior experience; but given Bob's comprehensive "learn it right from square one and don't waste time learning it the wrong way" philosophy, and the curricula of the other intro courses, it seems this is supposed to be a genuine intro course--albeit a challenging one. I feel like he wouldn't expect his students to have spent a bunch of time learning other approaches to prep for his language-based intro! And I was hoping the same could be true of me. You've TAed for this course in the past? What was your impression of the preparation of the students and the steps the lecturers took to supplement the reading and guide them through the material? Do you have any tips for me to make life easier?
Yes, the vast majority should be, unless your code consistently builds large structures that exceed the GC's capability to evict them when the nurseries are GC'd. In any case, some objects would be tenured into the older generations, and eventually a full mark-and-sweep has to be done - this is usually the cause of the longer pauses (for which Java for example has been historically notorious for).
I'll admit that I'm ignorant of Toronto software wages, but that range seems quite low -- even for a junior developer and especially for one with Haskell experience. In addition, equity wasn't mentioned to offset the (current) lack of benefits or low salary. I'm assuming remote and Haskell is the perk. Is this correct?
No problem! I just wanted to get as much information as I could about current practices. Thanks for the link to that guide too! Very good to know about. 
&lt;3
Thanks, just coded the [FASTA](https://rosettacode.org/wiki/FASTA_format) in. I'm sure the parsing function can be a one liner, but I'm just a beginner so I rather made it long and clear. if there is a way to make it better, please let me know here on Reddit, so I learn something new!
Here is how I run Haskell code blocks in org-mode: 0. The usual Nix + cabal steps to make the libraries I want to use in org-mode available. 1. `M-x shell` in that directory 2. `cabal repl` 3. (optionally) `M-x rename-buffer` to `*haskell*`, use the `:session` code block attribute otherwise. 4. `:set +m` 5. In addition, if there are any declarations involving types in the code block, enclose the content of the block in `:{``:}`. Ideally all those steps should be done in `ob-haskell.el`...
Isn't there a tool for making graphs of typeclass hierarchy? Or am I mixing up with the tool for module/package dependencies?
What about using haskell-src-exts and forking haskell-type-exts to support all the extra plugins?
Firstly, for Monads I've been handing out this link. Thomas is a great writer, the paper is very very easy to skim, and it has some amazing pull quotes for people talking about Monads. What's more, he's part of another language community that is not Haskell, so his insights are sometimes a bit less laden with community jargon: http://tomasp.net/academic/papers/monads/monads-programming.pdf For folks like Dan Kaminsky, this might work. For folks who are not engaging in good faith, any reference or stock argument will just be fuel for the fire, in my opinion.
Reflex-platform. 
I went and implemented "object serialization" (https://rosettacode.org/wiki/Object_serialization) using the binary package and then realized that the rubric specifically mentioned *inheritance*, so I gave up for the time being. I posted my code at https://gist.github.com/rcook/5bee57a3b7e485b3735fe9fed9536cae but haven't incorporated it into Rosetta Code because it doesn't use inheritance. Thoughts?
&gt; I use the precompiled binaries for HLint, GHC, Stack and Cabal - all of which are available online released by the projects I know only of GHC and Stack, can you point me to the links where I can download a built binary for HLint and Cabal. On a note, I had a lot of challenges with HLint, it seems it depends in the data-folder Cabal option, and when I was building the binary myself and putting in it in an environment where it was not built, the binary simply wouldn't work.
Keep writing Haskell. (btw I'm not experienced) On your github, go to confs involving Haskell (Compose, Haskell X, etc). I'm in a school that doesn't even teach Haskell and I've been recruited at least twice for Haskell, and wrote some code for a technical interview in Haskell today. People will find you if you keep writing Haskell. Give talks on Haskell, blog about Haskell, etc. The Haskell community is great! Keep writing code and reach out to others in Haskell-Cafe, Stack Overflow and in the community in general. And seek out places that do hire and ask them directly (most likely they're also the same persons you'll be interacting with on here, too). Good luck!
Make a bunch of projects! The more visible and tangible, the better. Implement a Twitter clone in Yesod. Write a Servant API. Do some database programming. Or implement some tooling or useful stuff. Write blog posts about what you're learning and doing. Even if it's not ground-breaking, simple stuff with a new perspective can be really helpful and useful. In short: provide a large, public body of evidence that you are a competent and capable Haskell developer, and that you are improving over time. These are the factors that contributed to my own Haskell job history.
No, I'm just a very happy user... You see, is not very obvious on TravisCI documentation how to configure your own docker image, it was quite a no-brainer from CircleCI documentation, if there is something new, is that TravisCI docs are not as great ¯\_(ツ)_/¯ After looking at it a bit more, if you are talking about this: https://docs.travis-ci.com/user/docker/ An essential difference is that I'm not doing a bash algorithm in YAML to download my docker images, so yeah... that is an improvement
True, you can cache all the things in the CircleCI or Travis cache, I'm guessing there is going to be a limit to it though, also, you don't have a level of granularity around the cache. You would expect to expire your library cache way more often than your tooling cache.
Nice! In all honesty, I didn't look at Gitlab before, can you integrate the Gitlab CI with Github? 
Yes, this experience report is for OS libraries, which don't tend to be big, and when the cache doesn't kick in, it is slower than my machine as well. This is more of a comparison with what I had before with TravisCI.
Where do you live? Are you interested in interning anywhere over the summer?
Parsing by hand is a pain. I prefer using parser combinators. Much nicer and will do things like throw errors on syntax errors. module Main where import Data.Foldable import Control.Applicative import System.Environment (getArgs) import Text.ParserCombinators.Parsec hiding (many, optional, (&lt;|&gt;)) fasta :: Parser [(String, String)] fasta = many block block = (,) &lt;$&gt; description &lt;*&gt; contents description = char '&gt;' *&gt; many (alphaNum &lt;|&gt; char '_') &lt;* newline contents = concat &lt;$&gt; many (many letter &lt;* newline) main :: IO () main = do [filename] &lt;- getArgs result &lt;- parseFromFile fasta filename case result of Left err -&gt; print err Right xs -&gt; for_ xs $ \(h, b) -&gt; putStrLn (concat [h, ": ", b]) 
&gt; Implement a Twitter clone in Yesod. Write a Servant API. Do some database programming. Or implement some tooling or useful stuff. One more bit of advice: While you're doing application work, keep an eye out for little libraries that you can extract. They don't have to be super general or groundbreaking, but Haskell isn't super widely used so there's a lot of low-hanging fruit. For instance, if you come up with a domain-specific Servant combinator (like a different MIME type), you should consider making it available for others to use.
&gt; I know that it will involve some form of writing some Haskell and working on some projects Yes, and some good advice on that here: http://www.haskellforall.com/2017/10/advice-for-haskell-beginners.html
It's been a while since I checked but I remember Toronto software wages being way lower than I'd expected. They do mention equity, it's the last line in the edited post.
It's surprising given a quick look at rent prices. And I must have missed the equity bit. Thanks for pointing it out.
Go to haskell meetups.
The next obvious step would be to use a streaming library to process the file :)
I wrote this post awhile back with my thoughts on the matter: http://softwaresimply.blogspot.com/2016/08/how-to-get-haskell-job.html
It's about 100 lines of Java
Webkit has their own called riptide
I suspect that the definition of said read barrier will vary from runtime to runtime. Thanks for the link!
Another one is: https://www.codewars.com/
How would you inject the output of running a code block back into the buffer?
Have you looked at [`acid-state`](https://github.com/acid-state/acid-state)?
That sounds like a lot of work :)
Or accept 20 min turnaround, which is a lot simpler :)
Maybe your are thinking of [graphmod](https://hackage.haskell.org/package/graphmod)? Which is for module dependencies.
Cabal: https://www.haskell.org/cabal/download.html HLint: https://github.com/ndmitchell/hlint/blob/master/README.md see Running with Continuous Integration. That provides both binaries and scripts to download, extract and run. Cabal has ways to compile with a movable data-dir, but it's a pain, so the binaries are easier.
Hijacking this. Berlin, yes
Good idea, added. Although I used `ReadP`, because it is in the "standard library".
At least as important: participate in *existing* projects that interest you. Contribute useful things, and get some PRs accepted. That's the first thing you should concentrate on, before you focus completely on your own projects.
Wow Rosalind looks coooooool, thanks for sharing 
By the time you get an answer you could have figured it out yourself.
The claim you want to make is quite broad: that, for every possible item, every possible company has a price available. That claim is codified in types as: hasAllPrices :: ItemId -&gt; CompanyId -&gt; Price But this isn't really the case - it's more that for every _available_ item, every _available_ company has either an item specific price, or a category price. What we really want is some way to say: hasKnownPrices :: Known ItemId -&gt; Known CompanyId -&gt; Price To accomplish something like this, we can use a phantom type and a continuation, where we'll take the structure from the parser without static analysis performed, then write a static analysis function along the lines of: withKnownEntities :: Input -&gt; (forall ph. [KnownItem ph Item] -&gt; [KnownCompany ph Company] -&gt; (KnownItem ph Item -&gt; KnownCompany ph Company -&gt; Price) -&gt; t) -&gt; Either BadInput t The general principle is that the Input given will be checked for consistency, and if it's correct, then some code you supply will be given a list of known items, a list of known companies, and a promise that an item and company can be combined to obtain a price, and whatever you do with that code produces the ultimate result of the function. The `forall` expression is preventing the escape of the phantom types of known items and companies from the continuation. Regrettably, the implementation of this sort of type constraint will ultimately use an expression along the lines of `error "impossible"`. This problem can be directly expressed using dependent types, but I'm not sure if the current state of dependent typing for GHC is far enough along or not. 
Check with Zalando :) 
Some really great advice here! I'd reiterate the need to have as many visible projects as possible. Speaking as a Talent Manager with Functional Works, most of our Haskell clients look at engineers without commercial experience, as long as there is some open source code for them to check out. You can also check out the learn section on our site, and we've had quite a few people trying out Ben Kovach's generative art using Haskell - https://functional.works-hub.com/learn/generating-artwork-with-haskell-09371. If you'd like to chat some more about it, feel free to reach out - peter@functionalworks.com
[removed]
[removed]
To derive instances from a single representation via Triple () () () instance Triple () () A instance Triple () () B instance Triple () () C .. instance Triple C C C
Anyone can intern anytime in their life. Most people don't after they graduate because they would usually prefer a job with a salary, paid vacation, and health benefits, but you're always allowed to pursue what you want to work on over what pays best. Anecdotally, I've seen a college student turn down a $35/hr job for a $15/hr, and I've seen a seasoned engineer turn down a $150,000/yr job for a $75,000/yr job. I'm not recommending doing this. I'm just saying that it does happen.
Without knowing what error you got, it'll be hard to help you with it. Here are some more general tips: `if x then y else return ()` can be written with [`when`](http://hackage.haskell.org/package/base-4.11.0.0/docs/Control-Monad.html#v:when). So: when (not isEmpty current) $ do left &lt;- readIORef (getLeft current) ... That being said, `(not isEmpty current)` is a type error - it should be `(not $ isEmpty current)`, or `(not (isEmpty current))`. Also, all those parts where you have multiple lines within a `then` or `else`, you need to put a `do`-block. 
You need other `do`s: morris :: IORef Tree -&gt; IO () morris t = do current &lt;- readIORef t if (not isEmpty current) then do left &lt;- readIORef (getLeft current) if (isEmpty left) then do print (getVal current) morris getRight current else do p &lt;- predecessor current pr &lt;- readIORef (getRight p) if (isEmpty pr) then do writeIORef (getRight p) current morris getLeft current else do setRightToNull p print (getVal current) morris getLeft current else return () Hope this helps :-) I haven't checked if it compiles...
I get an error on the line `left &lt;- ...`, and that is because you need to start a new block: if (not isEmpty current) then do -- New block left &lt;- ... A `do` block is a sequence of statements, here the last statement is an `if` *expression*, with the following syntax: if &lt;expr&gt; then &lt;expr&gt; else &lt;expr&gt; the branches should be expressions as well, and `do`-blocks are expressions, but naked statements are not: if &lt;expr&gt; then do { &lt;stmt&gt;; ... } else do { &lt;stmt&gt;; ... }
There are few classes named like that in `base` though. In particular there are `MonadPlus`, `MonadIO`, `MonadZip`, `MonadFix` and `MonadFail`.
Thanks everyone! 3 great answers in just a couple of minutes :D Have it all sorted and it's working fine. 
Why?
Might be best to edit the question and say that it's solved. This comment currently appears at the bottom ...
Thanks!
Thank you, and welcome to /r/haskell
At university, I had a course on Big Data and Data Analysis and we also talked about the alpha algorithm for process discovery. Since the algorithm is defined using sets, I decided that this would be a perfect fit to try out implementing with Haskell. The repository also contains some rudimentary code to plot petri nets.
Use your physics background - I was in a similar situation before I got into research, but my experiences apply mostly to F# since I was already working on the .NET framework. Haskell is in dire need of good numerical libraries. If you were to work on symbolic math packages or algebraic solvers or statistics packages (not t-tests so much as CDF and PDF etc) you would be making a non-trivial contribution to the Haskell ecosystem. Even if it’s incomplete it will show a mastery of the language and pave the way for others to build off of it. If you really had the time and know-how, a robust physics engine would be an impressive undertaking. That’s the kind of thing some people make their career on, and a Haskell physics engine would probably be performant enough to find real-world use.
Seriously just rewrite it yourself. It’s surprisingly easy.
I can't see anything wrong with this code. Try limiting the used memory by enabling RTS options, and running the program with `+RTS -M100M` (only use 100MB of heap space, [see GHC manual](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/runtime_control.html#rts-flag--M%20⟨size⟩)).
I don't think this is a problem, but you can replace `joinImages` with `B.pack $ zipWith (.|.) b1 b2`. 
I don't think this is a problem, but you can replace `joinImages` with `B.pack $ zipWith (.|.) b1 b2`. 
"Give a man a fish, and you feed him for a day. Teach a man to fish, and you feed him for a lifetime." So I won't give you the final image, but I'll show you how to make one. First, grab the source for the latest version of base. $ cabal update $ cabal get base-4.11.0.0 $ cd base-4.11.0.0/ Look at all the `.hs` files and list all their class declarations: $ find . -name '*.hs' | xargs grep '^class' &gt; classes $ head -n 3 classes ./GHC/GHCi.hs:class (Monad m) =&gt; GHCiSandboxIO m where ./GHC/StaticPtr.hs:class IsStatic p where ./GHC/Read.hs:class Read a where Does any of those class declarations span more than one line? $ grep -v where classes ./Data/Type/Equality.hs:class a ~~ b =&gt; (a :: k) ~ (b :: k) Looking at the source, it's not that the `where` is on a later line, it's that this type class has no `where` clause because it has no methods. Next, I painstakingly transform that Haskell syntax into graphviz's directed graph notation, so I can turn it into a visual representation of the graph: $ cat classes.dot digraph { "Monad" [shape=box]; "GHCiSandboxIO" [shape=box]; "Read" [shape=box]; "Monad" -&gt; "GHCiSandboxIO"; } $ dot -Tpng classes.dot &gt; classes.png If I was doing this very often, I'd probably use haskell-src-exts to parse the type class declarations and then programmatically produce the graphviz code, but for now it was simpler for me to do it by hand: digraph { "GHCiSandboxIO" [shape=box]; "IsStatic" [shape=box]; "Read" [shape=box]; "IsList" [shape=box]; "Semigroup" [shape=box]; "Monoid" [shape=box]; "Functor" [shape=box]; "Applicative" [shape=box]; "Monad" [shape=box]; "Alternative" [shape=box]; "MonadPlus" [shape=box]; "Datatype" [shape=box]; "Constructor" [shape=box]; "Selector" [shape=box]; "Generic" [shape=box]; "Generic1" [shape=box]; "SingI" [shape=box]; "SingKind" [shape=box]; "BufferedIO" [shape=box]; "RawIO" [shape=box]; "IODevice" [shape=box]; "KnownNat" [shape=box]; "Bounded" [shape=box]; "Enum" [shape=box]; "Exception" [shape=box]; "Show" [shape=box]; "Ix" [shape=box]; "Real" [shape=box]; "Integral" [shape=box]; "Fractional" [shape=box]; "RealFrac" [shape=box]; "KnownSymbol" [shape=box]; "HasField" [shape=box]; "Num" [shape=box]; "IsLabel" [shape=box]; "Floating" [shape=box]; "RealFloat" [shape=box]; "PrintfType" [shape=box]; "HPrintfType" [shape=box]; "PrintfArg" [shape=box]; "IsChar" [shape=box]; "Eq1" [shape=box]; "Ord1" [shape=box]; "Read1" [shape=box]; "Show1" [shape=box]; "Eq2" [shape=box]; "Ord2" [shape=box]; "Read2" [shape=box]; "Show2" [shape=box]; "Traversable" [shape=box]; "Data" [shape=box]; "Bifunctor" [shape=box]; "IsString" [shape=box]; "Typeable" [shape=box]; "Bifoldable" [shape=box]; "TestCoercion" [shape=box]; "~" [shape=box]; "TestEquality" [shape=box]; "Bits" [shape=box]; "FiniteBits" [shape=box]; "Bitraversable" [shape=box]; "HasResolution" [shape=box]; "Foldable" [shape=box]; "Storable" [shape=box]; "Category" [shape=box]; "MonadFix" [shape=box]; "MonadZip" [shape=box]; "MonadFail" [shape=box]; "MonadIO" [shape=box]; "Arrow" [shape=box]; "ArrowZero" [shape=box]; "ArrowPlus" [shape=box]; "ArrowChoice" [shape=box]; "ArrowApply" [shape=box]; "ArrowLoop" [shape=box]; "Monad" -&gt; "GHCiSandboxIO"; "Semigroup" -&gt; "Monoid"; "Functor" -&gt; "Applicative"; "Applicative" -&gt; "Monad"; "Applicative" -&gt; "Alternative"; "Alternative" -&gt; "MonadPlus"; "Monad" -&gt; "MonadPlus"; "Typeable" -&gt; "Exception"; "Show" -&gt; "Exception"; "Ord" -&gt; "Ix"; "Num" -&gt; "Real"; "Ord" -&gt; "Real"; "Real" -&gt; "Integral"; "Enum" -&gt; "Integral"; "Num" -&gt; "Fractional"; "Real" -&gt; "RealFrac"; "Fractional" -&gt; "RealFrac"; "Fractional" -&gt; "Floating"; "RealFrac" -&gt; "RealFloat"; "Floating" -&gt; "RealFloat"; "Eq1" -&gt; "Ord1"; "Eq2" -&gt; "Ord2"; "Functor" -&gt; "Traversable"; "Foldable" -&gt; "Traversable"; "Typeable" -&gt; "Data"; "~~" -&gt; "~"; "Eq" -&gt; "Bits"; "Bits" -&gt; "FiniteBits"; "Bifunctor" -&gt; "Bitraversable"; "Bifoldable" -&gt; "Bitraversable"; "Monad" -&gt; "MonadFix"; "Monad" -&gt; "MonadZip"; "Monad" -&gt; "MonadFail"; "Monad" -&gt; "MonadIO"; "Category" -&gt; "Arrow"; "Arrow" -&gt; "ArrowZero"; "ArrowZero" -&gt; "ArrowPlus"; "Arrow" -&gt; "ArrowChoice"; "Arrow" -&gt; "ArrowApply"; "Arrow" -&gt; "ArrowLoop"; } The resulting image is... not that interesting. Most type classes have no arrows going into or out of them. The Category fragment is the same as in the Typeclassopedia. The Monad fragment looks the same as well, except that Monad points to MonadZip, MonadFail, MonadIO and GhciSandboxIO in addition to MonadFix and MonadPlus. The Num fragment is the same as in [this](http://dev.stephendiehl.com/hask/#numeric-tower) graph, plus `Ord a =&gt; Ix a`. The rest consists of a few isolated subgraphs, which aren't super exciting either: class Semigroup a =&gt; Monoid a class Eq a =&gt; Bits a class Bits a =&gt; FiniteBits a class a ~~ b =&gt; a ~ b; class (Bifunctor f, Bifoldable f) =&gt; Bitraversable f class Eq1 f =&gt; Ord1 f class Eq2 f =&gt; Ord2 f 
I don't think this is a problem, but you can replace `joinImages` with `B.pack $ zipWith (.|.) b1 b2`. 
HRL is hiring for a haskell position on aerospace simulations. They will be interested in your physics background.
Thanks! I'll give it a try.
(Reddit says there are already 5 comments here but it doesn't show any, so perhaps this has already been answered?) The problem seems to be that the possible_files list is infinite which leads to that the "mapM doesFileExist possible_files" action keeps going forever. You probably want to stop doing doesFileExist after it has become false the first time, or some thing like that.
Thank you! 🙇
Thanks! I'll try removing the infinite list. But I thought using filter with the infinite list would make sure that doesFileExist only runs as much as is needed? I guess not.
Collaboration is usually a huge part of working at a company. I can tell whether or not you can code during an interview much more easily than I can tell that you are capable of a collaborative workflow.
How many of these images are there? It looks like you're loading them all into memory at once.
You forgot the redirect / line in your episode notes
One thing you're doing (if I'm reading the code right) is you're opening every single file at once in memory, and then you're loading the entire contents of each file into memory throughout the course of the program, so your ram usage end up at around `~25M * numberOfPictures` (not including the memory for the image processing) before the handles are closed. You might consider an alternative structuring of the program where you open each file one at a time, extract what you need, and keep that bytestring somewhere. Then, once every single image has been processed, perform the final bitwise OR. Using strict bytestrings for that seems like a good idea :) What you're doing here is lazy IO, which can be done well and is appropriate in a few particular instances but generally... very easy to shoot yourself in the foot with. If you want to keep this particular control flow, a great option to look into would be a streaming library. Then the code control flow would look something vaaaaaguely like "get every file name. Concurrently stream the images one bit at a time to extract the image section; then take that stream of images and do a streaming bitwise OR on them"
You are searching for an infinite list of files, the compiler has no way to know that one day it will not find a file with the given name. A better approach would be to get the list of files in the folder and filter those which match the pattern.
Finally got the comments to show. Weird. If I understand correctly, mapM will do the action for all items in the list before continuing, but I might be wrong. I found that your code got stuck there by putting putStrLn "A" at some different points in your code and see what got printed to the console. You could fix this in different ways, but if you want to keep the infinite list you could use takeWhileM from the [monad-loops package](https://hackage.haskell.org/package/monad-loops-0.4.3/docs/Control-Monad-Loops.html), "let files = takeWhileM doesFileExist possible_files".
No need to thank me, friend!
Oh, that's exactly what I need. Thanks, I'm going to fix it now.
Then why do that first before working on your own projects? After doing a bit of your own work you are more likely to know what interests you and how it can be improved. I don't understand why one should do it the other way around.
Oh, nice catch! Thanks.
Well, I work in a small shop as a sysadmin. When the place I work at has a project, I stood up and take the responsibility for backend part. Now, I am a sysadmin-cum-haskell programmer. And considering how barren fp landscape in my country is, it's better than nothing.
Well, at least I got that right :P. By the way, I got rid of the infinite loop and now the program is working properly!
My docker container has about 18G of tooling required to do the CI build. On top of that there is around 5G of cache. There are at least 3 advantages docker has: 1. You can run the docker container locally 2. It's a pre-cooked file system, so vastly faster than unpacking a cache. 3. Figuring out all the paths to cache is a PITA when it's not build artifacts you're caching, but all sorts of packages and tools that sometimes come with the operating system, but sometimes not.
Glad to hear it! Can you update your gist to the working code? I enjoy seeing how people fix their code :)
Personally I’m a big fan of https://mightybyte.github.io/monad-challenges/ It gave me a pretty solid working intuition for monads, and this was after I was exposed to monads and used them uncomfortably for a while.
Ins't that how all code blocks work in org-mode? Just set the `:results` parameter to what you want it to insert.
Sure, no problem. There, I updated it.
Wow, I didn't realize the file sizes would be so big! Your answer does make sense though. If the container itself gets so big, do you have a separate server that caches the container? Otherwise, building the container itself would take quite some time, right?
let me know if you want twitter advertisement on that :)
I have found that coding in Haskell on Arch Linux isn't that painful, given the current mess (the choice of using dynamic linking with GHC): - First, compile your own cabal-install, don't use the one in the repos: https://wiki.archlinux.org/index.php/Haskell#Building_statically_linked_packages_with_Cabal_.28without_using_shared_libraries.29 - Second, use cabal new-build always, it makes the cabal-hell problem gone and it's easy to do profiling (Nix-style builds): https://cabal.readthedocs.io/en/latest/nix-local-build-overview.html
Well.. I think that the book/lecture notes do match the lectures pretty closely.. There's less focus on the cost model approach though than you might expect. It's a tool talked about for the first lectures as a way of avoiding the hand-waving that you often run into with complexity when your model is too low-level to actually program in. After that first little bit the class is just a discussion of particular algorithms and data structures (with more of a focus on parallelism than is typical). The students in this have already taken (or know the equivalent) of - 15-112 the introductory course which starts with no assumption of programming knowledge and ends with a small project (like a game) written in Python. - 15-122 the course on "imperative programming" taught in C0 (C but without some broken bits) and focuses on specification and proof as well as actually doing a fair amount of programming. I think the final project is writing a VM for C0. - 15-150 the course on "functional programming" taught in SML. Lots of focus on proofs. The assignments are generally of the form write an algorithm &amp; prove it correct on paper. A significant chunk of time is also spent discussing the efficiency of such programs using the work/span/language-cost-model ideas. They are not as fleshed out as they are in 210 but they are there and we do expect students to prove certain things to be O(whatever). A representative project, though not the final one, is to implement a regex matcher using CPS and prove it correct. All told, most people in this class have been exposed to a fair amount of data structures, a fair amount of programming, and a lot of reasoning and proving things about code. This probably explains why some of the notes seem oddly fast moving: a lot of the details are front-loaded (especially to 15-150). My usual impression of the students is that everyone is pretty solid (though I am perpetually sad that people have forgotten all of their SML over the summer) and even with that 210 is hard. If you're struggling to get a foot-hold a reasonable action at this point might be to just email one of these instructors. It's possible that you won't get a response since people are busy and forgetful but it can't hurt.
Sorry I can't be of more help :(
Instead of `-XDerivingVia`, perhaps `-XDefaultSignatures` would be enough in this case? Something like class Monad m =&gt; MonadAccounts m where createAccount :: Email -&gt; Password -&gt; m Account default createAccount :: (MonadReader r m,HasAccountConfig r) =&gt; Email -&gt; Password -&gt; m Account createAccount = undefined 
The container image isn't built by the CI, it's just given as a base image. If it can't be pulled, it will fail. 
I had the same "5 comments, but none visible" problem, and it's not the first time. I wonder what's going on!
Needs documentation.
Yea you don't have to lose the infinite list if you just short circuit the loop yourself rather than using mapM_. Or even you could use MaybeT with mapM_ to short circuit on Nothing
I just wanted to say the Hask-curious folks at my workplace have been watching these, and this one is by far the most popular so far.
DM me any job posting details or similar!
Yes, generating java code is much easier and I would at first recommend that approach. I didn't stress enough that it is much more work to go to bytecode, in particular if you are writing your frontend in haskell. Either you use a nice hs library like codec-jvm or you go via ow2-asm. While codec-jvm looks good in principle it hasn't been released to hackage for quite a while and doesn't support invokedynamic, which a functional programming language implementor might want to leverage. I think eta is also considering to use invokedynamic lambdas and scala is doing that already. Instead using ow2-asm requires hs-java bindings or another intermediate step. I used a sexp-based assembler and a java service transforming that representation into the asm ast. Concerning checked exceptions - they exist only on the java language level, not in the bytecode. Therefore you can generate bytecode which doesn't catch exceptions, while in java you would have to write all those try-catchs wrapping the exceptions in runtime exceptions, rethrowing them via a helper function or tainting all your functions with thows Exception.
the spock website says that one of the projects built with it are unionizeme.org but it seems to be offline and wayback machine doesn't have an archive. what did it used to be ?
I have the same concerns as you did: I don't think anything I've done is worthwhile (after all, I'm still just learning). But I'm going to start (albeit, apprehensively) making things public.
In a current project I use `-XConstraintKinds` to do the something like type MonadAccount r m :: Constraint = (MonadReader r m, HasSomeAccountConfiguration r)
Thank you.
Thank you.
On the roadmap :)
I have no idea how org-mode works, but that sounds pretty good!
Yes.
That's nice to hear! :)
Yes, I was somewhat confused about it also. I suppose that using the environment to hold mutable state references is a common pattern, and might be the reason it's called `state`. But I'm just guessing.
That sounds a lot like just having instances on [`RIO`](https://hackage.haskell.org/package/rio-0.1.0.0/docs/RIO.html#t:RIO) instead of an actual transformer stack.
Its a long time ago that I looked at acid-state, but from the top of my head I remember that it doesn't have transactional updates and its more a general store for arbitrary values than a key-value store, right? (Offtopic: update on what I'm doing: I'm currently trying out haskey and it seems to be a good choice)
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://hackage.haskell.org/package/rio-0.1.0.0/docs/RIO.html#t:RIO) - Previous text "RIO" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
Not OP but I wrote a redmine CLI client in Haskell: https://github.com/prikhi/hkredmine/ https://github.com/prikhi/hkredmine/#workflow
Thanks, I'll give it try !
That's the point of org-mode (and org-babel). It just inject the result of codes block into a delimited new block (which can be reused as an input of the next code blocks). 
Eeeee. Don’t put me on fire. But I need to ask. Do you know about google calendars?
Otherwise `servant` for making http api with json. `Persistent` to talk to a database. That seems to be enough.
Yes, but I'd like to do this to build experience with a language I love
And then an HTML Front-end on top?
You can keep the infinite list but you must use unsafeInterleaveIO to decouple the laziness of the IO for the list from the laziness of the rest of IO. Otherwise the list is forced to execute strictly.
Purescript is another alternative that is very Haskell like.
Well. There is haskell-miso, but I agree, that Elm is very nice. And it can exchange data with other js-elements on your page, that may be written in jquery or anything. 
&gt; our own Emmett Who?
Sorry, autocorrect 
How do you compare `servant` to `scotty`?
Ah, this makes more sense. I'm still curious about the actual idea though.
Since you are overwhelmed by libraries, I'll just share the stack that works for me: 1. web: scotty 2. persistence: postgresql-simple (I don't like ORM :) ) 3. templating: blaze-html 4. json: aeson 5. form validation: digestive-functors 6. hosting: Heroku, with [this buildpack](https://github.com/mfine/heroku-buildpack-stack). I guess you can host on free plan forever.
In my practice I used only servant. The power feature is that api is a haskell type. And route parts are types. And input/output json is a type. So while coding the compiler makes you sure, that for example 2nd route part is Integer and output json is a representation of MyFancyOutput type. Scotty in its routes actually seems to receive Text and output Text. So in scotty function, giving output for request is basically `[Text] -&gt; Text`, while in my project’s servant I am writing functions like `ZonedTime -&gt; Double -&gt; TimeZone -&gt; Settings -&gt; NatalChart` and they themselves are handled by servant, because it’s api is formulated with the same types. 
If you are making just a backend for your angular/elm/whatever frontend, then servant is cool. If you look for full web framework similar to rails, then yesod. Scotty is like sinarta. And servant can also generate Html with blaze or lucid and have its typelevel coherence.
Hi, your CCI config seems to have lots of repeating code: all the "lts-*" and "nightly" builds are pretty much the same. It is possible in CCI to simplify your matrix by removing these repetitive code, here is an example: https://github.com/haskell/haskell-ide-engine/blob/master/.circleci/config.yml
More complete code now up at https://gist.github.com/lunaris/86440b552c7cc282a5cc37fb89845f70. Echoing /u/Faucelme's point, I don't think `-XDefaultSignatures` let you solve this problem without the API having knowledge of implementation details (e.g. `HasAccountConfig` or the `AccountConfig` type itself).
This works and may serve very well for quite some time (ala "You aint gonna need it") but I think you may want the type class (or some similar, "firmer", interface) at the point where e.g. you have two implementations -- one in-memory, do-the-stuff and one make-HTTP-call-to-microservice-hosting-the-do-the-stuff. I've not explored this too far though.
Thanks for the tip!
Start with `scotty` as the most basic. Maybe with bare `wai` if you're feeling bold.
Don't use Elm. You'll regret it, especially after having spent a good amount of time writing Haskell. Reasons to not: * it's missing typeclasses (and all of the wonderful things we get with them -- typesafe comparisons, functors, monads, etc) * the elm architecture makes it literally impossible to make reusable components, since all dataflow needs to be wired by-hand from the top of your app to the component that uses them * relatedly: this makes event-handling a nightmare, since you need to write a top-level pattern match for literally every event you want to handle, and without monads this means you'll need to fold any resulting state yourself. * hearsay: there is a whitelist of packages that are allowed to do JS interop, and if you're not on that list, you have absolutely no way to work around it I've got some other ones too, but they're a little more ad hominem :)
I can attest that 1-4 works very well, as I use the same. :o) I've no experience with 5 and 6. 
Our stack at work is Yesod and Elm and we love it!
Watch this from a couple days ago: https://haskell-at-work.com/episodes/2018-04-09-your-first-web-application-with-spock.html It won't be the only source you need, but it's worth a watch.
Yesod can to 1, 2, 3 and 5.
This goes out as a general call to action for this subreddit, and isn't necessarily just directed to you as an individual commenter: _Please_ stop recommending Servant to beginners, _especially_ in a situation like this where it's not clear that the author would be best served by a full-on JS frontend. Servant carries with it a _lot_ of incidental complexity, especially around understanding and using the advanced language features that are required to do anything with the framework. The compiler messages can very quickly become completely unhelpful, and navigating off the beaten path requires familiarity with nontrivial type level programming. I'm going to echo what /u/ephrion has said a few times: Servant can be useful if you have a JSON API, probably one that uses JWT-based authentication as that's the "happy path" at the moment, and you require automatic derivation of Haskell clients as well as a semi-automatic derivation of Swagger specifications. Servant is really, really awesome in these situations, but it is also _extremely_ rough if you need to wrangle it to do something else. (n.b. This isn't meant as a criticism of the Servant team or the Servant maintainers, I just really don't like seeing people advocate that beginners use what i see as extremely advanced libraries all the dang time.)
Hm. Of course. Any recommendation can ruin someone. But I need to say, that I started with servant on 2nd week after getting to haskell. Maybe I am a genius.
Use Yesod, it's a lot more mature and you won't get stuck on stuff nearly as much as Servant.
Or you managed to stay on the happy path and haven't actually done much with it. I've used Haskell for my work for 3-4 years and myself and coworkers have a lost a lot of hours to blockers and limitations with Servant. It's really not a good recommendation as a general framework and that is _especially_ true for new people who won't know how to solve their own problems.
`digestive-functors` is a Perl library masquerading in Haskell. Very stringly typed. I'm surprised people think that's normal/acceptable for HTML forms.
Why purescript if I may ask ? He's already had Angular thrown into the mix 
Might be just me, but by the time he's done with all the excess TH overload, he'll probably just give up on the app. I think Yesod is probably the best framework in the Haskell ecosystem but i don't know if i'll recommend it to a beginner
Do you mean that you get stuck on any Haskell framework (Yesod included) and the thing you got stuck on would be trivial on another framework? Or is it that you get stuck when you use Haskell frameworks that aren't Yesod? I'd be curious to hear about some of the stuff you get stuck on as I'm debating using Servant or Jooby/Kotlin 
Even if you don't use it, check out miso's README https://github.com/dmjio/miso/blob/master/README.md
I'd suggest miso/reflex over purescript. Reflex will even make it so that putting it on mobile is easy (and very performant too)
You do not have to put your team in jeopardy just because you are trying to learn something. Use Google Calendar for now. And build a web app anyway. 
Bare `wai` is in many ways more pleasant than Go's `net/http` and people seem to love that!
Hey, can you PM me your GitHub handle and your email address? I'll have to check I know who you are (via GitHub and e.g. Haskell Cafe) first.
Hey, can you PM me your GitHub handle and your email address? I'll have to check I know who you are (via GitHub and e.g. Haskell Cafe) first.
If I were you I would try to find example projects on GitHub of the libraries people mention in this thread, glance through the code, and see what looks most enjoyable. At this point, personally, I'm not sure if I'd recommend reflex-platform for a complex, large-scale production application, but for something like this, it could be a perfect match, particularly if you'd like users to have access to native mobile apps, you are interested in FRP, and you'd like your entire codebase to be Haskell. Warning: this is not complete, but I've been putting together an [example websocket-driven reflex app](https://github.com/samtay/reflex-todo) that might give you an idea of what developing in reflex would look like.
This is very cool, thank you!
Reflex docs are also getting better: http://docs.reflex-frp.org/en/latest/
The TH in Yesod are pretty simple to grasp and you can ignore the complexity behind it if needs to be, so I'm not sure if it's actually a reason good enough to ditch Yesod. I think Yesod is great, especially for new starter.
I tried scotty a few years ago and I wouldn't recommend it to a beginner (but maybe things have changed since). Yes it was easy to start with, but as your app grows, you need to add more and more things (session, permissions, migrations, logger etc ) and you wish that every things was alredy set up and choice made for you. If scotty offers already all of that, then it's probably not simpler than Yesod anymore, and therefore I'll go for Yesod ;-)
You can't go wrong with Yesod and I unless you know what you are doing and have a good reason not to use it : use it. Especially if you are a beginner. It comes with a great documentation (the Yesod book), scaffolding (you start with running app), come with all batteries included (yes you might not need them all, but just ignore what you don't need, until you actually need it) and last but nost the least comes with a great ecosystem which you are pretty sure will be maintained. Some pepole will say it is opinionated and yes it is but when you start it's a big advantage. It means that (good) choices like libraries and design pattern have already been made for you, and that really solve the "where to start" problem.
Actually I took a closer look on `polynomial` package and unfortunately it appeared to resort to lists. Even if both polynomials were created from vectors, they will be converted to lists and zipped up. P.S. If you are interested in hacking number theory in Haskell, I encourage you to pick up one of `arithmoi` [issues](https://github.com/cartazio/arithmoi/issues). Some of them may appear pretty accessible for newcomers.
(can I say the same thing about nix as well?)
Some people are scared of Yesod complexity and require building an ad-hoc version of it for themselves before they can start enjoying the features. But yeah, you should leave the raft after traversing the river.
Or you can use [unless](http://hackage.haskell.org/package/base-4.11.0.0/docs/Control-Monad.html#v:unless) instead of `when`: unless (isEmpty current) $ do left &lt;- readIORef (getLeft current) ...
Can you elaborate on "complexity of factorisation over an elliptic curve" for the totient function? It is really simple once one has the factorization argument, but that's the bottleneck. It's integer factoring, which is not sublinear. In practice for AKS, typically the argument is prime so the totient consists of a single integer decrement.
I can't comment on Haskell and its libraries, but AKS should be quite reasonable with memory use even with significantly larger inputs. Performance in terms of time is problematic however. It is very slow \(as you mentioned in the original comment\). Still a nice project to implement.
done
Out of curiousity, I believe elm can be used to generate the html. Do you use elm just to add some dynamic to html generated on the server using for example hamlet or do you generate the page with elm ?
That's the bit of a bold statement. As good as bucklescript might be , there is definitively no reason to dismiss Haskell for web development especially for the back end. On my side, I moved on from "isomorphic" application (as it's seemed to be called) so bucklescript is probably not better than anything else ...
We don’t have much that is public facing ... most is a SPA behind a login. So Elm really controls most of the page.
Isomorphic web app is kind of a buzzword for a stylistic choice in code design, yes, but that doesn't mean that you want to write your form validation logic twice, or your HTML (once client-side dom operations, once static server-side html, because yes it's a very good idea for various reasons to not rely on client-side scripting). On the server side both are over long stretches basically equivalent -- you can run both on bare Xen, for example. Ocaml's runtime is leaner and meaner, though. GC is less problematic, not to mention that the binary sizes tend to be small enough to spin up a whole VM for a single request. A large part of my choice might be that bucklescript needed way less fighting to get things done during evaluation, though, and it's not like Ocaml would be worse when it comes to abstraction powers... different ones, but definitely in the same ballpark. Syntax is definitely worse, though. Compilation times are ridiculously fast. I've also looked at things like elm and purescript. Elm isn't a very powerful language and lacks on the server side, purescript has huge huge performance issues. In any case I'd definitely recommend a look at bucklescript, "I want to do things in Haskell" is often just code for "I want to do things in a sensible functional language". Which, bickering aside, Ocaml is.
`lines` (String -&gt; [String]) turns your input into a sequence of lines. `words`(String -&gt; [String]) turns your lines into a sequence of words `read` can be used to turn individual Strings into Floats, like so `read "2.5" :: Float`
Thank you, yeah I'm having difficulty adjusting to it from a language like java or C. The reason I'm having difficulty with it for my particular task is that I can't just operate on every line the same way, but rather on groups of lines. In a grouping of 4 lines, the first will be the number of items (2), the next two will be the item and a probability (3 0.5) and the final line will be the number of attempts, and I need to calculate the probability that each item will be obtained in the attempts.
&gt; read We have [`readMaybe`](https://hackage.haskell.org/package/base-4.11.0.0/docs/Text-Read.html#v:readMaybe) (and `readEither`) which returns `Nothing` on a failed parse case readMaybe "False" of Just b -&gt; not b Nothing -&gt; .. -- something failed here
How exactly does the function concatenation work? I tried next &lt;- words . hGetLine input And it threw an error
&gt; I have never used a more frustrating and soul crushing tool. Even in comparison to AppVeyor?
Much like my comment below, this is not meant to call you out _specifically_, but rather to call upon the subreddit to rein in some of the overzealous recommendations: GHCJS is an absolute fucking mess of additional complexity on top of learning the language and ecosystem. It requires Nix to use in any realistic capacity, which is _incredibly_ complex relative to `stack` or vanilla `cabal new-install`. On top of that, the build artifacts that it produces are absolutely _enormous_ unless you're doing something like running it through the Closure Compiler afterwards (and even _then_ it's going to be much larger than minified, gzipped PureScript). And on top of _that_, Reflex in particular is an innately complex paradigm to anyone unfamiliar with reactive programming (e.g. you can create **causality loops**). I would even hesitate to recommend PureScript to someone without a decent amount of Haskell experience, but to recommend anything GHCJS related is doing them a complete disservice.
I've only used AppVeyor coincidentally (for Cabal) and didn't have any issues with it although I hear bad things about it.
How would I go about diagnosing and fixing a segmentation fault? I'm pretty sure it's being caused by the GLUT library, but I don't know where to go from here. If someone could put me in the right direction, that'd be great. The code is here: https://github.com/sam-barr/haskell-gui-snake I believe the seg-fault causing code is in Display.hs
Awesome, I was thinking of going through Tiger blog. What's the blog 's URL?
are you by chance on windows? I think windows delineates newlines with "\r\n". You could write a smalll function yourself or use `Data.String.Utils` `rstrip` to remove additional newline characters. 
The most basic way to do this is: getsFloats :: FilePath -&gt; IO [Float] getsFloats path = do contents &lt;- readFile path let someFloats = map read . lines $ contents return someFloats Here is what we are doing, line by line. `getsFloats :: FilePath -&gt; IO [Float]` We're declaring the type of a function, `getsFloats`, to be `FilePath -&gt; IO [Float]`. That means this function will take type "FilePath", and it will return type "IO [Float]", or, an IO list of floats . `getsFloats path = do` We're now declaring our function. We've declared a single argument 'path', which as per our type signature above, must be of type `FilePath.` We're also using `do` to indicate that we're going to use "do notation", which is a special syntax that lets us work with monads. There is a lot to unpack there, but for now the relevant bit is that the IO type is an instance of Monad, and that our function is using 'do notation' to interact with the 'IO monad.' `contents &lt;- readFile path` This line is executing the function `readFile` on our argument, `path`, and it is binding the result of that execution to `contents`. `readFile` is a function that takes a `FilePath` and returns an `IO String`. It's type signature is similar to ours - `FilePath -&gt; IO String`. The `IO String` that `readFile` returns is a `String` representing the contents of the file. When we 'bind' the result of that function call with the `&lt;-` operator, we're taking special advantage of the 'do notation' syntax to allow us to treat the result `IO String` as a regular `String`. That's important, because most functions don't operate on `IO String`, they operate on `String`. That probably seems pedantic to you right now, but the difference is super important, and the reasons for why Haskell does stuff this way will become clear to you later on. `let someFloats = map read . lines $ contents` This line has a bit going on. First, we're declaring a local binding, `someFloats` with the `let` keyword. In functions that aren't in a `do` block, we'd need a corresponding `in` keyword, but, the do block relaxes that requirement. We are declaring `someFloats` to be equal to the result of `map read . lines $ content`. What we're doing there is taking `content`, the string representing the contents of the file, and we're using `$` to pass it to the function `map read . lines`. This is a key idea behind functional programming - When we compose functions, we're building a big function out of multiple little functions. The `.` function is combining `map read` with `lines`. `lines` is a function that breaks up a multiline string into a list of strings, where each string is the line until the line ending character/sequence (it handles multiplatform inputs transparently, so don't worry if you're on windows or something). It has type `String -&gt; [String]` `read ` is a cool function. The type of `read` without an annotation is `Read a =&gt; String -&gt; a`, which is a fancy way of saying that `read` can take in a string and return literally anything that implements the `Read` class (sort of like an interface if you're used to OOP). Haskell is strongly typed, so when we call `read`, it needs to 'know' specifically what it's return type should be. Haskell has very strong type inferrence, so it was able to figure out based on context that the return type of read in this context should be `Float`, but if we wanted to help it out we could've used a type annotation like this: `map (read :: String -&gt; Float)`. Our last function here is `map`. `map` has type : `(a -&gt; b) -&gt; [a] -&gt; [b]`. That means it can take a function that consumes some type `a`, and returns some type `b`, and a list of `a`, and then give us a list of `b`. Note, significantly, that `a` and `b` can be each be any type at all, including the same type. In our use, `map` is taking the function `read` as it's first argument. This is making use of partial application to turn `map read` into a function with type: `Read b =&gt; [String] -&gt; [b]` Lets play that back really quick: read :: Read b =&gt; String -&gt; b map :: (a -&gt; b) -&gt; [a] -&gt; [b] map (read :: Read b =&gt; String -&gt; b) :: [String] -&gt; [b] So, `map read` takes a list of `String`, and gives us a result list of... Some `read`able type. So, we're combining `lines`, which takes a string and returns a list of strings, with `map read` which applies `read` to a list of strings to produce a list of readable values, and we're using the function that creates to process value `contents`, which is a String. Woo! Lot going on there. `return someFloats` Oh, that's simple, now we just return `someFloats`... Oh, but wait! `return` isn't a keyword... It's a function! What is the type of `return`? `return :: Monad m =&gt; a -&gt; m a` Oh, there's those monads again... So, we just got ourselves a list of `Read`able values, which, by context, we know are a `[Float]`. But we can't just send out a `[Float]` - We already told the compiler we were going to return `IO [Float]`! From our lesson earlier, we learned that `IO` implements `Monad` - So, that means that just as `read` can have type `read :: String -&gt; Float`, `return` can have type `return :: a -&gt; IO a` So `return` lets us 'wrap' our `[Float]` in `IO` and become an `IO [Float]` Alternatively, we could've skipped all of this and done this: `ggetsFloats p = map (read :: String -&gt; Float) . lines &lt;$&gt; (readFile p)` And did all of the above in one line. But then we would've learned NOTHING.
Well first of all, you would need parentheses around that, because function application binds more tightly than `.`. But it's also wrong because `words` wants a `String` not an `IO String` so you have to use `fmap` (whose infix form is `&lt;$&gt;`) to lift `words` into the `IO` functor. So basically you wanted this: next &lt;- words &lt;$&gt; hGetLine input
Yes, please. `nix` is a fantastic idea and it's time hasn't quite come yet. The True Believers are doing great work, and it feels like Nix right-now is where Haskell was ten years ago -- you *could* use it, but you were in the weeds.
I'm pretty confident that he meant Servant specifically. eg, a task that would be trivial in any other framework is difficult in Servant. I've had the same experience, fwiw.
Web is the world which's full of strings bad and bad design language (javascript), and there is a great place to show how Haskell and other strong type-inferred type language save the world.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [parsonsmatt/yesod-minimal/.../**Minimal.hs** (master → 3dc0b1e)](https://github.com/parsonsmatt/yesod-minimal/blob/3dc0b1ea3c81c17f86acfa91e37d866d17744b29/src/Minimal.hs) ---- 
How's GHCJS's JavaScript FFI? It's been a few years, but I simply could not figure it out back then, while PureScript's is fantastic.
And then we can map readMaybe over a list of words and further catMaybes the result.
I disagree. Miso for example has a pretty forgiving learning curve. And install directions you can copy verbatim + a bunch of examples. It's just following instructions.
Relatively straightforward I'd say: https://github.com/dmjio/miso/blob/master/ghcjs-src/Miso/FFI.hs
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [dmjio/miso/.../**FFI.hs** (master → 142a10d)](https://github.com/dmjio/miso/blob/142a10df3de3fb568d77c2c2c5e0f5890ad1792f/ghcjs-src/Miso/FFI.hs) ---- 
What would you use? I don’t see many libraries in this space and digestive-functors is the best one I discovered so far 
[removed]
How about main = readFile "/tmp/foo" &gt;&gt;= return . parseNumbers &gt;&gt;= doGroups doGroups ([Just items] : [Just item1, Just prob1] : [Just item2, Just prob2] : [Just attempts] : more) = doGroup items item1 prob1 item2 prob2 attempts &gt;&gt; doGroups more doGroups [] = return () doGroups (_ : more) = putStrLn "error" &gt;&gt; doGroups more 
`yesod-forms` doesn't 100% satisfy me (my standard is Django forms) but it's been serviceable and offers a measure of type-safety that I was content with. I found making my own form and field input widgets to be pretty flexible too.
These are bad, sure, but they are the default and unless you're doing something complicated or demanding, which OP clearly isn't, they are easy to use and reasonably fast.
Yeah I would recommend doing it this way to start with, that's why I did!
I would use [Parsec](http://unbui.lt/#!/post/haskell-parsec-basics) for this. Though I don't know if you want to use an external library for this.
Since other people have already suggested how to actually do it -- if you're asking a question like this, it might be the case that you haven't read far enough in an introductory text to the language. Maybe [give Learn You A Haskell For Great Good](http://learnyouahaskell.com/) a try -- it goes over the `Read` and `Show` typeclasses, along with opening/closing files and reading content from them, in a prinicpled fashion. Happy haskelling! :)
Come to think of it, I think that was with textual keys; numbers - particularly sequential numbers - might very well go better.
You can use [this](http://hackage.haskell.org/package/split-0.2.3.3/docs/Data-List-Split.html#v:chunksOf). But you might as well write the function yourself as an exercise (`chunksOf :: Int -&gt; [e] -&gt; [[e]]`).
That's terrible code advice for a beginner: * No type signatures * A lack of abstraction * Mixing pure and non-pure code for no reason
A one-line answer: map (map read . words) . lines &lt;$&gt; readFile filename This is actually using lists rather than arrays. If you actually wanted arrays, ask again. and someone can probably help. Now let's understand what that junk all means. This is actually not hard code to read once you're a bit familiar with Haskell, but it some seem daunting at first. Give it time. * First of all, `.` means function composition. Remember in high school algebra when you learned about the function composition operator, written "∘"? For example, if you defined a function h by writing "h = g ∘ f", that means h(x) = g(f(x)). In other words, work from right to left, and send the argument through each function in turn, sending the output from the right function as input into the left function. In Haskell, since Unicode is a pain, function composition isn't "∘"; it's ".", the period. So there are two function compositions in the example above. Once you've got that down, the next bit to look at is `map`. `map f` just says: apply this function `f` to everything in a list, and give a list of the results. For example: `abs` is a function in Haskell that takes the absolute value of a number. So `map abs` is a function that takes a *list* of numbers, and gives back a *list* of their absolute values. With those in mind, let's put together the first part of this expression. `words` is a function that takes a `String`, splits it up around spaces, and returns a *list* of the words in it (each of which is a `String` in its own right). So `words` maps from a `String` to a list of `String`s. And `read` parses a `String` and gives you the underlying value instead. Through the magic of type inference, Haskell will usually be able to figure out what type you want to parse it into -- in this case, probably `Double`. So remembering the above, if `read` converts a `String` to a `Double`, then `map read` converts a *list* of `String` into a *list* of `Double`. And using function composition, `map read . words` converts 
Well that's true. I'll still be trying a web-app, but a Google Calendar might be an intermediate fix
This is a nice short introduction video! Looks like a lot of other great content is there too
Probably `sequence`ing the result (or just using `mapM` in the first place) is more reasonable. I think it would be weird to see something that didn't parse and just go on your merry way as if it didn't exist.
&gt; "I want to do things in Haskell" is often just code for "I want to do things in a sensible functional language". You are right, however Haskell purity or lack of escape hatch makes it the best to make sure you are doing it in a functional style. Also some people want to do things in Haskell because Haskell is pure, lazy and has typeclass etc, and don't care of functional style. For example,I found myself trying many functional languages to realize that what I wanted to do was Haskell, period.
Yes, under certain circumstances mapM would make more sense.
My fault, I meant "subexponential" instead of "sublinear".
Every single bug in a site I've developed is due to the part that concerns digestive functors. I've looked at [forma](https://hackage.haskell.org/package/forma) as an alternative (and there's [reform](https://hackage.haskell.org/package/reform) and [a suggestion by dirt cheap haskell](https://dirtcheaphaskell.io/#2017-12-06-digestive-functors) too), but as the form was a retrofit I'm loath to touch it until after I've implemented the js replacement.
Expect up to a day of disrupted service while we get things back in order. Really sorry about the inconvenience.
I never used it, but I mostly hear "bad" things about ghcjs
Defined "bad"? It's working great for me in prod.
&gt; "I AM TRYING TO FIX CONTINENTAL DRIFT.... I THINK IT BROKE WHEN I RELOADED NEW ZEALAND FROM A BACKUP COPY, BUT I DO NOT KNOW WHY. MY SYNCHRONIZATION WAS IMPECCABLE AND THE CHANGE PROPAGATED SIMULTANEOUSLY ACROSS ALL SEPHIROT. I THINK SOMEBODY BOILED A GOAT IN ITS MOTHER’S MILK. IT IS ALWAYS THAT. I KEEP TELLING PEOPLE NOT TO DO IT, BUT NOBODY LISTENS." -The Archangel Uriel, Unsong ([source](http://unsongbook.com/chapter-3-on-a-cloud-i-saw-a-child/))
Mainly with the output js files: big file size and hard to read/debug code. I also never used nix.
Closure compiler helps a lot with the big output js files, and library / dependency issues can be harder to debug, but issues in your own code aren't really any different to debug than usual.
I'm looking into Yesod now. Going web is a big leap from building small programs always. [It's gonna be fun](https://i.imgur.com/KymIVNE.jpg)
&gt;it's missing typeclasses (and all of the wonderful things we get with them -- typesafe comparisons, functors, monads, etc) It is a bit annoying without typeclasses. But from a design pov, I can see why it was not included. With type classes people might end up creating too many needless when a simpler code would have sufficed. I am not sure, but wouldn't it also make the compilation process a whole lot slower.. &gt;the elm architecture makes it literally impossible to make reusable components, since all dataflow needs to be wired by-hand from the top of your app to the component that uses them.. But it only needs to be done in a number of well defined places, right? 1. Adding one more branch in the parent components message type (to wrap the message type for child component) 2. fmap the new constructor over the view of the child 3. Add branch in update function to match on the new constructor and pass the sub message to child's update function, and update the corresponding part of the model from the result.
You can always roll your own typeclasses: just define a record whose contents are functions, and pass around a tuple `(actions, value)` to your functions which can then call `value |&gt; actions.head` 
Lots of people like to say "you can just use records", but I'll bet you a nickel that those people haven't actually tried to just use records. I did. [I wrote about it.](http://reasonablypolymorphic.com/blog/elm-is-wrong) It wasn't a fun experience.
Is there a mirror for the documentation wiki?
Reading your blog post I feel you went a bit too deep with the idea of structural typing and missed the solution: https://github.com/eeue56/elm-all-dict It's a pain, and the language needs to fix it ultimately, but I would still suggest Elm is a pretty good place to start for SPAs
 &gt; purescript has huge huge performance issues Are you referring to that benchmark that covers completely unrealistic cases?
The compiler has quite literally no optimisation passes at all. If the performance target is "at least not slower than plain javascript", its output just doesn't cut it. Bucklescript actually tends to be faster than idiomatic javascript as the code uses arrays and integer constants over objects, sprinkles asm.js style type hints (but not the pragma, it's not asm.js) all over, and doesn't create closures for no particular reason: Javascript VMs eat that code style for breakfast. Yet it's perfectly readable (but no really editable). I don't deny that purescript *could* be fast, the current implementation just isn't. 
Thanks for keeping us informed, it's highly appreciated.
Quantified Constraints. There's a paper and a GHC proposal for it. It's probably going to be in GHC 8.6.
`DerivingVia` is a buzzword. There is a paper and an impl.
Do you know what is it for exactly ?
It allows you to write constraints like `forall a. Class (f a) =&gt; SomeClass f where...`.
Thanks for all of your hard work looking after this infrastructure, /u/gbaz1!
Have you installed `directory` with `stack`? `stack install directory`
Maybe a little more detail - size of project, range of compensation ? To save everyone's time.
I also found [QuickForm](https://github.com/tomsmalley/quickform), which looks super interesting and is pretty much exactly the design I was thinking would be ideal for a super type safe form validation library.
https://zfnmxt.github.io/ but it's still empty as of now. I'll be updating it soon. :) 
If it works with runhaskell but not stack ghci my bet is that you have those libraries installed globally whereas stack installs things locally. Add those libraries to your project's cabal file (or it's hpack config file thing) and you should be good to go with a simple `stack build` to get the dependencies and then `stack ghci` to run them. (Obligatory mention that "stack install" is an unintuitive alias and never does what people expect it to. You almost assuredly do not want to use it. Stack has no way to manage a project's dependencies from the command line, which is very unfortunate)
I've done worse, it happens :) But hey, look on the bright side! Free stress testing for the mirrors!
You still can't get around having to load all of Haskell's runtime as a giant blob of JavaScript, unfortunately. Which means anything that's not a SPA is going to load unacceptably slowly; especially a one off small project like this.
I felt like the point with the blog post was "can I achieve X while not compromising on type safety" which is the entire point of Haskell's typeclass design (ad-hoc polymorphism in a type safe way). The answer was a no because Elm in general has an incredibly low abstraction ceiling and seems to actively prevent you from building your own abstractions up by hand.
Woops! Can you share roughly what happened? Will there be a more complete postmortem afterwards? These things always turn into good stories, even if they aren't much fun at the time.
Yes. This could be a very major project
where are the mirrors?
Thank you very much I was looking for this as well
Done :\)
True
I feel absolutely stupid and like I shouldn't be let near computers again at the moment. We're in the middle of trying to fix things carefully, which is making me anxious. After that, when I have my wits about me, I certainly owe everyone a postmortem.
[removed]
There's a hackage mirror in the main post
Is this lacking a link maybe?
None of those links work for me.
Slightly more interesting if you run it through this to exclude the isolated classes: egrep -v "\\b($(&lt; classes.dot egrep -o '\b[A-Z]\w+\b' | sort | uniq -c | awk '/ 1 / { print $2 }' | xargs | tr ' ' '|'))\\b" classes.dot | dot -Tpng -o classes-better.png
Bad choice of link, the link added this video to my watch later list on Youtube.
I apologize. Should I re-post?
sounds like you don't need javascript at all!
I couldn't find any evidence that Haskell is a thing at Zalando. Can you share more details?
Your choice, but I say probably. Just make sure you delete this copy.
Well Miso is an isomorphic framework. So the website is first rendered server side extremely quickly. So in practice it feels zippy as hell.
I don't think it is. If the user cannot distinguish between the program returning a correct result and an incorrect result, it doesn't matter which result you return. If I'm a Cancer, but I get a Sagittarius answer, how would _I_ know? Yeah, yeah, types would still be useful, but I can't imagine any actually useful domain-specific types for astrology. ``` data Horoscope = -- …what? ```
`map (flip addDays startDay) [0..]` could be written `map succ [startDay..]` 
Nice! Quite interestingly, it turns out you were not the only one trying to solve day24 using an hylo :) https://bartoszmilewski.com/2017/12/29/stalking-a-hylomorphism-in-the-wild/
Since `Day` is an instance of `Enum`, `map (flip addDays startDay) [0..]` could be written `map succ [startDay..]` which I think is a little clearer.
Thanks! I didn't know I could do that.
This is great
[Proposal (rendered)](https://github.com/Icelandjack/ghc-proposals/blob/1263ff1fd7f40db1a13fbccf47734f31f6e7d4aa/proposals/0000-deriving-via.rst). This proposes a new extension, `-XDerivingVia` adding a new strategy (`via`) to derive with. `via` strictly generalizes the `newtype` deriving strategy. * [paper](https://www.kosmikus.org/DerivingVia/deriving-via-paper.pdf) * Previous [reddit discussion](https://www.reddit.com/r/haskell/comments/8aa81q/deriving_via_or_how_to_turn_handwritten_instances/)
I mostly enjoy Elm. &gt; it's missing typeclasses (and all of the wonderful things we get with them -- &gt; typesafe comparisons, functors, monads, etc) Instead of `potentialTarget &gt;&gt;= someFunction`, you have to write `potentialTarget |&gt; Maybe.andThen someFunction` (where `|&gt;` == `&amp;`). Instead of `fmap someFunc values`, you do `List.map someFunc values`. It's kind of annoying at first but it's nice to know(and helpful to tell the compiler) which instance you're trying to use. &gt; the elm architecture makes it literally impossible to make reusable &gt; components, since all dataflow needs to be wired by-hand from the top of your &gt; app to the component that uses them I don't follow - you do have to wire the component's data somewhere in your app state, but you can still abstract &amp; re-use them... I like the nested wiring &amp; state. If I see that some message update is buggy, I can look at the model before a message &amp; trace the changes to it by following the layers of nesting. &gt; relatedly: this makes event-handling a nightmare, since you need to write a &gt; top-level pattern match for literally every event you want to handle, and &gt; without monads this means you'll need to fold any resulting state yourself. It's like four lines &amp; you can totally nest pattern matches: type Msg = InternalMsg String | ComponentMsg Component.Msg update : Msg -&gt; Model -&gt; (Model, Cmd Msg) update msg model = case msg of InternalMsg someData -&gt; myFunction model someData ComponentMsg subMsg -&gt; Component.update subMsg model.componentState |&gt; Tuple.mapFirst (\cState -&gt; model { componentState = cState }) |&gt; Tuple.mapSecond ComponentMsg Sure, it's not 0 lines but if `Component` is from a package then it's not like I have to handle every value in the `Component.Msg` type. If `Component` is our code &amp; it's buggy, we get a trace of the code that handles the message. `ComponentMsg (SubcomponentArrayMsg 2 (Move Left 3))` tells us to look at the `ComponentMsg` branch of `update`, the `SubcomponentMsg` branch of `Component.update`, &amp; the `Move` branch of `Subcomponent.update`. It also lets us modify the component state at any layer of the update call. &gt; hearsay: there is a whitelist of packages that are allowed to do JS interop, &gt; and if you're not on that list, you have absolutely no way to work around it The whitelist is for packages pushed to https://package.elm-lang.org. You can still do whatever JS interop you want in your application via Ports, Subscriptions, &amp; Flags: https://guide.elm-lang.org/interop/javascript.html And you can still use packages that are not on the whitelist using something like elm-github-install or elm-grove. 
Any reason you didn't use [timezone-series](https://hackage.haskell.org/package/timezone-series) and [timezone-olson](https://hackage.haskell.org/package/timezone-olson)?
Right. I was looking for the website `hackage.org`
Downgrading from Haskell to OCaml for web dev sounds very unpleasant, speaking as someone who has used both.
`tz` was the search result in Google and Hackage. I'll look at these other packages once Hackage is back up.
Stupid question. Why don't you just `coerce` the (value of the) instance dictionary (as opposed to coercing all methods inside it)?
I think I have a *solution* for you! It's a bit more of a hack than a *solution* though, and it's definitely not very clean. In `~/project/app/.ghci`: :{ myGHCI :: IO String myGHCI = pure $ unlines [ ":set prompt \"myApp&gt; \"" , "import Control.Arrow" -- Add whatever setup you want here ] :} In `~/.ghci`: :set prompt "home&gt; " -- More setup here if needed :cmd myGHCI What's happening in this *solution* is that instead of setting up an environment in the app `.ghci`, you instead create a variable that will hold the environment that will eventually be evaluated in the next `.ghci` (the one in `~`). Here's what it looks like when I run `ghci` from `~/project/app`: ➜ ghci GHCi, version 8.2.2: http://www.haskell.org/ghc/ :? for help Loaded GHCi configuration from /home/Boom_Rang/project/app/.ghci Loaded GHCi configuration from /home/Boom_Rang/.ghci myApp&gt; However (and here is why I'm calling this a hack), when running `ghci` from anywhere else you will get a (small) error message: ➜ ghci GHCi, version 8.2.2: http://www.haskell.org/ghc/ :? for help &lt;interactive&gt;:1:1: error: Variable not in scope: myGHCI :: IO String Loaded GHCi configuration from /home/Boom_Rang/.ghci home&gt; If that get's annoying in other projects you can add an empty `myGHCI` in your local `.ghci`: myGHCI = pure "" As far as I can see the `ghci` commands don't have any conditionals, which is a shame. I have also tried to get CPP working to solve this, but `ghci` won't take it. I hope this helps! If you find a better way, I would love to know about it! :D 
You definitely run into issues when you start talking about associated types and type families. See https://typesandkinds.wordpress.com/2013/08/15/roles-a-new-feature-of-ghc/
The simplest answer to your question is that `DerivingVia` (or any deriving strategy, for that matter) works by generating source Haskell, and since there's no surface syntax for explicit dictionary values, there's no way to `coerce` them as a result. Perhaps you don't find this to be a satisfying answer, so let's suppose that `deriving` directly produced GHC Core, which *does* have explicit dictionary values. Then in principle, you could use a coercion to go from a dictionary value of one type to a dictionary of another type. But there's a big drawback to this approach: the code that `deriving` would generate would bypass the typechecker entirely (normally, the typechecker is what desugars the generated surface syntax into Core). This is particularly bad in the context of `DerivingVia`, since it relies heavily on the typechecker to rule out improper `via` types. If you're wondering we GHC doesn't just add explicit dictionary passing to the surface syntax, I'd encourage you to read the paper [*Making Implicit Parameters Explicit*](http://www.cs.uu.nl/research/techreps/repo/CS-2005/2005-032.pdf) (which we briefly discuss in the [`DerivingVia` paper](https://www.kosmikus.org/DerivingVia/deriving-via-paper.pdf).) This shows how to formalize and implement a variant of Haskell with explicit dictionary passing, but at the cost of significantly complicating the metatheory.
I don't sympathise with explicit dictionary passing. The type-checking argument seems convincing, thanks. In Core, though, an optimisation pass surely could recover that a cast of the dictionary is possible.
Why is it &gt;deriving via (Sum Int) instance Monoid T and not &gt;deriving instance Monoid T via (Sum Int) ? Seems more consistent with non-standalone syntax. 
It seems the dictionary also contains superclass instances, which are not guaranteed to be representationally equal as well. 
Update: Things are _very close_ to being fully restored. However, due to varying time zones and sleep schedules we're not in a position to flip the switch just yet, lest I make another dumb error on my own and send us back to square one. Also: the hackage server datamodel can feel a bit overengineered, but at times like these it really shines, in terms of the the ability to restore things. And the haskell language is great, in terms of letting me bang out a complicated restore script over the course of a day that worked essentially the first time when we set it loose on real data. More on this when the restore is actually done, and I sleep and recover, and then write a postmortem up.
Thanks for sharing Chris. I've watched some of the Lore videos before you stopped posting and i enjoyed them. Wishing you the best of luck on it
This is covered pretty well in [this recent thread](https://www.reddit.com/r/haskell/comments/8blpy6/how_to_read_line_by_line_in_haskell/).
Thanks /u/gbaz1
Lazy IO isn't done in the IO monad??
That's right. I mean, `readFile` has type `FilePath -&gt; IO String` but if you use bind to get that `String`, the actual IO is not performed in the call to `readFile`. That's exactly why it's called lazy IO. The IO is performed in the pure code, lazily, as needed.
Ah yeah, makes sense, thanks.
[slides](https://www.snoyman.com/reveal/async-exception-handling)
Sounds like a Notepad++ question, not a Haskell question? Are you asking whether Notepad++ can be configured to launch a command containing the path to the current file (no idea), or are you asking what that command should be (erh, isn't it just `ghci &lt;filename&gt;`? presumably, you have already tried that?)?
Have you tried `cmd.exe /c ghci &lt;filename&gt;`?
Probably because you could have `via` as a type parameter.
I think this is a great idea, the proposal is very as written is very convincing.
I do like the somewhat hyperbolic claims that some haskell proponents make. Think "you can't have a null pointer error" or "a function with type signature `Int -&gt; Int` is guaranteed to be pure". Those are both false. `fromJust None` is basically a null pointer error, and `unsafePerformIO` breaks all purity guarantees. Instead, haskell gives something that is honestly more valuable. It makes things safe by default. You have to consciously choose to use unsafe functions, and if you avoid them, a large number of errors simply cannot happen. You still have access to stuff like `unsafePerformIO` when you actually need it, but 99% of the time, it's easier to write things safely. That's huge, but that isn't the same as "haskell makes it impossible to do X, Y, and Z".
Thanks for all your hard work!
There's a few libraries that are pretty much "standard libraries", but aren't included in base. You can find a list of standard libraries here: https://www.haskell.org/platform/contents.html
stack support please!
I mean ultimately this is getting at the same basic feature either way: Making good design easy by making failure states easier to identify and harder to achieve.
We will survive; thank you for keeping everyone up to date on the status!
[Abstract out binary expressions.](https://github.com/Average-user/LEC/blob/2ebcd84b1ce64eb7687d4124931feaa08b641093/src/Types.hs#L5) Infix syntax is nice but hinders abstraction and you might as well define pattern synonyms for it. data BinOp = Or | And | Implies | Equiv | Xor data Expr = Var String | Not Expr | BinOp Expr BinOp Expr [Abstract out whether a sub-expression needs parentheses.](https://github.com/Average-user/LEC/blob/2ebcd84b1ce64eb7687d4124931feaa08b641093/src/Types.hs#L22) Here you can make use of the specific operator ADT (`BinOp`). Use either `either` or pattern match on `parsed` instead: https://github.com/Average-user/LEC/blob/2ebcd84b1ce64eb7687d4124931feaa08b641093/src/Parser.hs#L14 Why do you need to check whether your expression is valid? Your parser does that already. Removing tautologies doesn't seem too hard to me (e.g., a | !a, a &amp; a).
&gt; I do like the somewhat hyperbolic claims that some haskell proponents make. Certainly you mean you *don't* like them? To be fair, the OP asked for it. &gt; That's huge, but that isn't the same as "haskell makes it impossible to do X, Y, and Z. From a pragmatic perspective, it really *shouldn't* make X, Y, and Z impossible. The sane default is necessary, as well as the escape hatch, which is there for a reason. I personally find it great when some library tries to protect me from stupid mistakes. Or subtle ones, for that matter, which means that by studying the API, I might learn something new about the problem domain as well. On the other hand, not exposing unsafe functions or internal modules may bite you at some point, if the abstraction does not fit your bill one hundred percent. And we *do* have "implicitly nullable" values in the form of impure exceptions, or the fact that Haskell isn't total and bottom (_|_) is part of every set of values some inhabited type can take. Every Haskeller learns this early on, if they use some educational resource worth its salt. And I think it's a good thing, too. I personally would find vector indexing a la (!) :: Vector a -&gt; Int -&gt; Maybe a really annoying, but also misleading. It's not like we want to say "Even if the Int is within bounds, the value might not be there". Since an indexing error is not "an exceptional situation" I might want to setup some handler for, either, failing fast and hard with an error message (which isn't terribly descriptive most of the time, unfortunately) is preferrable to hoping that our off-by-one error actually triggers a segmentation fault by going off-page. Queue `Fin/Vec`, yada yada... Point being, Haskell *could* make X, and Y impossible (don't know about Z) by exposing a different API, but the actual (in this case, pragmatic) choice may not tell you much about the type system. But the way it is, I get my type safe STM (for which the purity guarantees that we *do* have are essential), but I am still able to interact with my pointer-fiddly C code as well. Seems like a fair trade-off.
&gt; From a pragmatic perspective, it really shouldn't make X, Y, and Z impossible. The sane default is necessary, as well as the escape hatch, which is there for a reason. 100% agreed. That's why I said that what haskell gives is "honestly more valuable". I'm not complaining about Haskell's design. I just think that some of the ad copy that people use is a bit inaccurate.
What's the catch?
I thought about adding a line saying "I know you didn't intend to say such and such", but deemed it unnecessary. For what it's worth, I don't like the fanboy talk either. Nor do I condone things like "Haskell can be as fast as C!!!1" and stuff like that. We really should try to keep emotions out of this. There is always some safety/performance/productivity tradeoffs to be made, and the principle of diminishing returns applies.
Yes, its available. You can apply @ https://www.xoken.org/careers/blockchain-research-engineer/apply/ It says full time but you can apply here for part time as well(kindly mention that you want to work part-time in the last answer field)
1) The thing is that `fromJust` is highly discouraged. You won't find it in a lot of projects and if I find out that a library I'm using has such a thing (e.g. I get an error due to that) I'm going to throw it in the trash. It also does not mean the same thing as `null` (You can evaluate null). 2) `unsafePerformIO` is meant to be used not as an escape hatch but as a way to be able to mark pure foreign functions as pure. If I find a library that uses that in a way that breaks purity I'm probably going to throw that in the trash as well. Since these things aren't prevalent as null in Java land, I can safely reason about my code with purity guarantees. And if I find that I have problem doing that (e.g. I used a partial function) I fix it rather than work around it and try to sweep it under the rug. Life's too short to worry about nulls!
Yup yup yup. You can use stuff like fromJust/unsafePerformIO to do unsafe operations, in the sense that the compiler won't actively prevent you from doing so. However, you have to go out of your way to do stuff like that, and it isn't recommended. It's generally easier to just do things safely from the start. However, "you have to go out of your way to see runtime errors" and "runtime errors are literally impossible" are different statements.
That's great, thank !
One thing I don't understand about the first example in the proposal; isn't monoid a strictly more general concept than an applicative functor? As in, could we derive Applicative instances via Monoid instances instead?
That is outdated, though. General recursion is not too general actually. It is for EAL ("stratified") terms, but what I failed to realize is that many non-EAL terms work fine with the algorithm. Recursion seems to be, in fact, absolutely fine. Notice I started using the Y combinator a lot [here](https://github.com/MaiaVictor/abstract-algorithm/blob/master/lib/main.lam), and I even implement the λ-calculus itself [here](https://github.com/MaiaVictor/abstract-algorithm/blob/master/examples/lambda-calculus.js) (outdated syntax). I'd say the catch is 1. we don't have a GHC for this; 2. since EAL is too restrict, we don't really have a precise criteria that determines what terms work; we'd need to figure that out before proposing a profissional language, obviously. My experience, though, is, though, is, if you take absolutely any Haskell algorithm and tweak the call orders a little bit (often by replacing non-linear variables by function calls), it will work. Example: ``` and = λa . λb. λ False. λ True. (a (b False False) (b False True)) ``` This is bad, because `b`, `True`, `False` are duplicated. ``` and = λa. (a λb. λ True. False. (b False False) λb. λ True. False. (b False True)) ``` This is the exact same program, except no duplicate variable was used; I just delegated the pattern-matching of `b` to be inside `a`. This kind of tweak is almost always what you need. Note the first example works too, but is a good example of an unfriendly program. I suspect the criteria will end up being a simple structural criteria, and wouldn't be surprised if there is a simple/automated way to "fix" a bad program so that it works with the algorithm.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [MaiaVictor/abstract-algorithm/.../**lambda-calculus.js** (master → b85ba0d)](https://github.com/MaiaVictor/abstract-algorithm/blob/b85ba0d1f7a00074ec95b0799b4b5a4e3c601a45/examples/lambda-calculus.js) * [MaiaVictor/abstract-algorithm/.../**main.lam** (master → b85ba0d)](https://github.com/MaiaVictor/abstract-algorithm/blob/b85ba0d1f7a00074ec95b0799b4b5a4e3c601a45/lib/main.lam) ---- 
&gt; That's huge, but that isn't the same as "haskell makes it impossible to do X, Y, and Z". One thing that is nice is that you can make those impossible if you want to in certain contexts, and it doesn't change the language much. 
By the way, stratified just means that you use the following language: ``` data Term = Lam Term Term | App Term Term | Let Term Term | Box Term | Var Int ``` Which is like the λ-calculus, except 1. Lams can't have non-linear variables; 2. Terms can wrapped in a box (`!term") if they have no free lambda variables; 3. To duplicate a variable, you use `let x = !y in z`; this will replace all occurrences of the boxed term `y` inside `z`. 4. Between a `let` variable (such as `x` above) and its use (inside `z`), there must be exactly one box. That's it. It is a structural criteria that forbidden certain shapes of λ-terms, but is still pretty powerful. 
By the way, stratified just means that you use the following language: data Term = Lam Term Term | App Term Term | Let Term Term | Box Term | Var Int Which is like the λ-calculus, except 1. Lams can't have non-linear variables (you can only use variables once); 2. Terms can wrapped in a box (`!term") if they have no free lambda variables; 3. To duplicate a variable, you use `let x = !y in z`; with `y` being a boxed term. This unboxes `y` and replaces all occurrences of `x` by it inside `z`. 4. Between a `let` variable (such as `x` above) and its use (inside `z`), there must be exactly one box. That's it. It is a structural criteria that forbidden certain shapes of λ-terms, but is still pretty powerful. 
I was annoyed our CI was broken due to the recent Hackage outage to I finally sat down and wrote a script that just mirrors only the packages our project needs. Since we're pinning dependencies with `index-state:` in `cabal.project` anyways this works nicely.
It's true that you can't ever convert them away from IO. What you can do is write your pure functions: parseIntAndFloat :: String -&gt; (Int, Float) doSomethingCool :: (Int, Float) -&gt; ? And then call those form within an IO context: main :: IO () main = do ... string &lt;- hGetLine input print $ doSomethingCool $ parseIntAndFloat string
Great work. Is your `open` just eta expansion or is there more?
That is outdated, though. General recursion is not too general actually. It is for stratified terms, but what I failed to realize is that many non-stratified terms work fine with the algorithm. Recursion seems to be, in fact, absolutely fine. Notice I started using the Y combinator a lot [here](https://github.com/MaiaVictor/abstract-algorithm/blob/master/lib/main.lam), and I even implement the λ-calculus itself [here](https://github.com/MaiaVictor/abstract-algorithm/blob/master/examples/lambda-calculus.js) (outdated syntax). I'd say the catch are 1. we don't have a GHC for this; 2. since stratification is too restrict ([here is what it means](https://gist.github.com/MaiaVictor/fac8a59ee98e9e33c3d8f42a8e7a29f8)), we don't have a precise criteria that determines what terms work; we'd need to figure that out before proposing a profissional language. My experience, though, is, if you take absolutely any Haskell algorithm and tweak the call orders a little bit, it will work. Example: and = λa . λb. λ False. λ True. (a (b False False) (b False True)) This is algorithm-unfriendly, because `b`, `True`, `False` are duplicated. and = λa. (a λb. λ True. False. (b False False) λb. λ True. False. (b False True)) This is the exact same program, except no duplicate variable was used; I just delegated the pattern-matching of `b` to be inside `a`. This kind of tweak is almost always what is needed. (Note the first example works on this case, but is still a good example of an unfriendly program.) I suspect the criteria will end up being a simple structural criteria, and wouldn't be surprised if there is a simple/automated way to "fix" a bad program so that it works with the algorithm.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [MaiaVictor/abstract-algorithm/.../**lambda-calculus.js** (master → 8e96c64)](https://github.com/MaiaVictor/abstract-algorithm/blob/8e96c640bf51de14003ad61f0dec385a047f2a08/examples/lambda-calculus.js) * [MaiaVictor/abstract-algorithm/.../**main.lam** (master → 8e96c64)](https://github.com/MaiaVictor/abstract-algorithm/blob/8e96c640bf51de14003ad61f0dec385a047f2a08/lib/main.lam) ---- 
It is just eta-expansion! (If you consider converting `foo : (a,a) -&gt; (a,a); foo a = a` to `foo (x,y) = (x,y)` to be eta-expansion; I'm not sure if the term applies to data). I've updated the article to clarify.
I'm not familiar with the topic in detail, but I thought that Lamping's algorithm had been shown to require exponential bookkeeping, so isn't genuinely optimal: http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.46.3157
This was addressed [here](https://pdfs.semanticscholar.org/8a35/42d70fc1d4531bc77c7bda130b0350245763.pdf). &gt; Technically, this implies that (on a sequential machine) the cost of sharing a single redex cannot be bound by any elementary function, but this is merely due to the enormous amount of sharing that is inherent in lambda terms. The result in [Asperti and Mairson 2001] tells you nothing about the efficiency of optimal reduction. The surprising result is that in lambda terms, due to higher order, we have much more sharing (in Levy’s sense) than expectable. &gt; Rephrasing [Asperti and Mairson 2001] in this context, [Asperti et al. 2004] showed that the non elementary cost of optimal reduction is not due to bookkeeping (which one may suspect to add superfluous work), but to the (apparently unavoidable) duplication work. If you accept the fact that optimal reduction performs the minimal amount of duplication, you will have at least the same operations, and hence the same computational cost in any reduction technique. &gt; In conclusion, while there are several examples of classes of lambda terms where optimal reduction outperforms standard techniques, there is so far no known counterexample to its computational efficiency.
Unless you are going to write everything in the IO monad there is no such thing as "translating" an imperative language into Haskell. The whole point of Haskell is to be a higher level language than those. Hence to write idiomatic Haskell you first have to reverse-engineer the high level design of the original, and then figure out how to implement that in Haskell. Of course it might be that the original is well designed and coded, and so the high level design is clear and transparent. But for a large body of code with significant history I wouldn't expect that.
Thanks. That also refers to this old reddit thread of yours which has some useful discussion: https://www.reddit.com/r/haskell/comments/2zqtfk/why_isnt_anyone_talking_about_optimal_lambda/
Not to mention, you can use unsafe functions to do things you couldn't do otherwise, and make them safe again by putting them behind a safe interface. That's better than making it impossible to be unsafe. 
Section 4.2 of https://pdfs.semanticscholar.org/8a35/42d70fc1d4531bc77c7bda130b0350245763.pdf is enlightening: &gt; On more numerical computations Caml Light was sensibly faster (up to one order of magnitude), that was not sur- prising due to the underlying overhead of graph rewriting &gt; The main problem we faced when implementing sharing graphs was not related to performance but to memory consumption. [...] Twenty years ago, this looked like a serious problem; since then, memory has become much cheaper and maybe, in the Big Data era we are entering, this is not a real issue any more. Well, let's have a Core to `abstract-machine` compiler first to see how it performs in benchmarks.
&gt; General recursion is not too general actually. Well, surely something has to be too general, right? Not all untyped lambda terms even have normal forms.
[removed]
Yes, what I mean is that recursion is not that bad. You can define an infinite list like: ``` ones = (Y λ self . (Cons 1 self)) ``` And it works fine. You can apply a recursive function like: ``` twos = map (add 1) ones ``` And it works fine. You can get head, tail, zip over infinite lists, and it works fine. On the other hands, the following term does not work: ``` (λ x . (x x)) (λ f . λ x . f (f x)) ``` It has a normal form (`λ f . λ x . f (f (f (f x)))`) and most evaluators have no trouble with it, but it breaks the optimal algorithm! So, point is, problem seems not to be recursion, turing-completeness, totality, but just the abuse of variable duplication. I unfortunately can't be more precise than that.
Allow me to do some thinking out loud. Let me try to assign a type to `(λ f . λ x . f (f x))`. twice : !(A -&gt; A) -&gt; (A -&gt; A) twice = λ f . λ x . f (f x) Where the bang means that we are using the argument more than once. But now `twice twice` won't typecheck since `twice`'s type does not have the form `A -&gt; A` for any `A`. Let's assume we had a builtin function `extend : (!A -&gt; B) -&gt; (!A -&gt; !B)`. Now `twice (extend twice)` would typecheck. The builtin function `extend` would at runtime increment the index of all duplication nodes or in other words introduce a new level. If we had a builtin function `lift : A -&gt; !A` we could define `extend f x = lift (f x)`.
https://hackage.haskell.org/
How so? `\x -&gt; x x` works fine in Haskell: ``` {-# LANGUAGE RankNTypes #-} type Nat = forall a . (a -&gt; a) -&gt; a -&gt; a two :: Nat two = \f x -&gt; f (f x) selfExp :: Nat -&gt; Nat selfExp x = x x main :: IO () main = print $ selfExp two (+ 1) 0 ``` But I had to use rank-N types, so I may have been wrong about having a simple type. In any case, this simple, clearly total function breaks the abstract algorithm, whereas a [complete implementation of the λ-calculus](https://github.com/MaiaVictor/abstract-algorithm/blob/master/src/lambda-calculus.js) (thus, general recursion) doesn't.
The instance you are thinking of is instance Monoid a =&gt; Applicative (Const a) and we use that to derive newtype Accum a = Accum { accum :: Int } deriving (Functor, Applicative) via (Const (Sum Int)) sum :: Traversable t =&gt; t Int -&gt; Int sum = accum . traverse Accum
Hackage is back! Hallelujah!!
That’s really cool. 
&gt; Abstract out whether a sub-expression needs parentheses. One further suggestion to the OP: use `showsPrec` and `showParen` instead of show you use the precedence to wrap parenthesis. Check the SO thread [here](https://stackoverflow.com/questions/27471937/showsprec-and-operator-precedences)
Thank you! :)
does hylo make for maintainable &amp; flexible code? My goto reference for a hylo example is https://www.reddit.com/r/haskell/comments/cs54i/how_would_you_write_du_in_haskell/c0uvqqo/
Have you looked into [Matrix](https://matrix.org/blog/home/) / [Riot](https://riot.im/app/)? I find them quite awesome and they're completely free. We even use it at work, now …
Thank you
Actually, I managed to run several primitive vulkan examples on Mac OS using MoltenVK today. Though, GLFW supports MoltenVK since version 3.3 only, but currrent haskell bindings are for GLFW 3.2. Windows and linux builds are fully supported now.
I'd add another thread: https://www.reddit.com/r/haskell/comments/568gtk/why_the_overall_lack_of_interest_in_interaction/ In particular, I don't think the problem of readback lambda term from interaction net has been solved when general recursion is present. So, yeah, nothing is really free.
This feels like you're being intentionally obtuse. If you were a regular Haskell user a few years ago and you "have entirely switched all development to Rust," then it's an answer to OP's question of where is everyone.
The catch is, optimal evaluation is not super-compilation. I suggest anyone who thought so read [what super-compilation really is](http://repository.readscheme.org/ftp/papers/pe98-school/D-364.pdf). In particular, being able to evaluate lambda terms to normal form while maintaining sharing (in the sense of levy's optimality) does not mean optimal evaluation can be used as a practical partial evaluator. To be more precise, I'm not aware that anyone has shown that applying optimal evaluation technique to non-closed lambda terms can preserve all sharing. After any attempt to reduce sub-expression `e` in lambda term `f e` when `f` is free is likely performing redundant reduction and hence not optimal. Besides, there is an unsolved readback problem when general recursion is present, as previously discussed: https://www.reddit.com/r/haskell/comments/568gtk/why_the_overall_lack_of_interest_in_interaction/d8h9c1r/ 
Could you point to the exact post/problem you mention? I don't remember/can't find it. I'm using recursive functions every time with on my implementation.
&gt; Huh? No. I mean, you have to lift every function in haskell into the IO monad (ultimately) or it doesn't run, but other than that, no. Maybe I misunderstood your question. Nah, that's not what I mean. I meant that your signature would have to be: `a -&gt; IO (String)` to encode the fact that your lazy work is side effecting. With the streaming packages, is the lazy IO machinery being handled within the streaming library (as i'd imagine, you'd still have to handle the same situations that you'd encounter with lazy IO)?
I've read this paper previously, but chances are I was mistaken about the definition of supercompilation. In any case, I worded it as "supercompilation-like behavior" because it optimizes a class of programs that, previously, could only be optimized by supercompilation. Is that right? If there is any incorrectness in the post please let me know!
Can you show an example with duplication that works with the algorithm? 
Hello! I'm not sure what you mean with that. Are you asking for a function that has duplicated variables, yet works on the algorithm? There are many on [main.lam](https://github.com/MaiaVictor/abstract-algorithm/blob/master/lib/main.lam). `List.fold`, for example, duplicates `nil`. `Bin.toCNat` duplicates `add`, any church-encoded structure duplicates something (so, `List.fold` duplicates `con` many times), and I use the `Y` combinator a lot, which obviously needs duplications. You can just look at the code, all those functions work with the algorithm, and there are many uses of duplicated variables. I avoid them as much as possible, though, as they're the main cause of inefficiencies. There isn't much on this file, though, since I've only recently started to look at that stuff again.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [MaiaVictor/abstract-algorithm/.../**main.lam** (master → 59e174f)](https://github.com/MaiaVictor/abstract-algorithm/blob/59e174fa516ea96b3a74b703bb71eb840d74d674/lib/main.lam) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dxb5ut0.)
Cooool . . . do you have the code somewhere?
What web frameworks do you guys use at work? 
idk, purity is extremely important to functional programming. Idris and PureScript exist, but Haskell is the only pure language that's "ready", imo. 
Purity is the default in OCaml, too. It's just that in the presence of strictness, the equivalent of `unsafePerformIO` is easier to not get wrong, so you get more impure code that exposes a pure interface. It's kind of like Rust in that way, where everything relies on carefully encapsulated unsafe code. In Haskell, it's compiler magic, instead. Potato, Potato.
Sorry, my post was wrong and cryptic. Let me try a better explanation. First, I'll need some syntax to make duplication nodes explicit: `letcopy_n x1, x2 = x in M`. It means make two copies of `x`, call them `x1` and `x2` and evaluate `M`. There is a family of duplication nodes indexed by a "level" `n`. Duplication nodes with the same level annihilate, duplication nodes with different levels duplicate each other. In your conversion from lambda term to interaction net you give each duplication node a fresh level. Now the problematic term is (λx.letcopy_0 x1,x2 = x in x1 x2) (λf x. letcopy_1 f1, f2 = f in f1 (f2 x)) After a few reductions with the optimal algorithm you arrive at (λf x. letcopy_1 f1, f2 = f in f1 (f2 x)) (λf x. letcopy_1 f1, f2 = f in f1 (f2 x)) If you continue reduction the duplication nodes at level `1` will annihilate but they should duplicate each other. The following term would work fine: (λf x. letcopy_1 f1, f2 = f in f1 (f2 x)) (λf x. letcopy_2 f1, f2 = f in f1 (f2 x)) I was thinking about a new kind of node, call it `box`, that gives all duplication nodes a fresh level. The problematic term would be legal if it was written as: (λx.x (box x)) (λf x.f (f x)) And then my question is if we could enforce this use of `box` and whether we could infer it.
Thanks very much, I find that using `Map` is better than using `List` since it turns out writing lot of `lookup` function and lot of boiler plate, so I though about transforming `ItemSpecificPrice ` and `CategoryDefault` to `Map` data Company= Company { companyName :: String ,itemSpecificPrice :: Map Item Price ,itemCategoryPrice :: Map Category Price } this reduce the code which is kind of good but at the same time, the way suggested above won't work anymore or it might be more complicated to model it in the type 
For me, Purity means "pure versus impure" is distinguished by types, and thus type checking can tell you when an expression isn't pure. afaik, Rust and OCaml require manual checking, but haven't coded much in them, so maybe they help the programmer with effects in their own way.
New videos are up.
What is a probability table, and what do you want to do with it?
Thank you... It can be parsed unambiguously either way and the proposal already reserves keyword `via` in this context of deriving clause. IMHO one should optimize for 99.99% of use cases which do not include the type variable `via`. Also the purpose of parentheses around Sum Int evades me. 
It is all there, in the examples folder https://github.com/achirkin/vulkan/tree/master/vulkan-examples These are not real programs, but they do show that the vulkan symbols are linked properly and graphics devices can execute vulkan commands
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [achirkin/vulkan/.../**vulkan-examples** (master → d511487)](https://github.com/achirkin/vulkan/tree/d511487451cdd31acb46863422d833bb00623c92/vulkan-examples) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dxbkebd.)
I was going to use a 2d array to have each row reflect probability values and each row edits itself and the one below it as it is filled out, so probably not a way to do something in Haskell. If you know a functional way to solve this problem, please let me know: Ok so the probability of an event with a probability 'p' occurring exactly 'n' times in 'x' attempts is: x!/((x-n)!*(n!)) * pn * (1-p)x-n And the probability of an event occurring at least 'n' times is: P(n) + P(n+1) +......+ P(x) So what if I have two events (inclusive) with different probabilities? How do I calculate the probability of each event happening a certain amount of times within x attempts, where I have to account for the fact that they can both occur at each attempt? I have answers for a set of test data but I need to figure out the process, I can provide them if needed.
To sum up the old thread: &gt; how do you perform optimal reduction over `map f . map g`? Where `map` is defined using generally as `map h xs = h (head x) : map h (tail xs)` rather than church encoded.
Looks interesting and useful as a reference. Still, the issues found weren't very haskell-specific.
Being [`universum`](http://hackage.haskell.org/package/universum) maintainer, I'm very pleased to hear such nice feedback about custom prelude from FPComplete! Especially when they have their own [`rio`](https://hackage.haskell.org/package/rio) custom prelude. My respect here. Always nice to see when other people appreciate your work instead of trying to push their own solutions :+1:
Perhaps I'm misunderstanding what you're saying, but I'm not sure why that would be a problem. In [this file](https://gist.github.com/MaiaVictor/2548bcd65e11c7b47908e44c89982d67) I've computed `(map double . map double) list`, where `map` and `double` are implemented recursively (with the Y-combinator) for Scott-encoded lists and nats, and `list = [0,1,2,3]`. It reduces fine with the abstract-algorithm. You can test it by saving the code as `maps.lam`, installing absal (`npm i -g abstract-algorithm`) and running `absal --bruijn --stats mapslam`. Here is the output: ``` ##//b ##a ##//b ##/b ##/b ##/b ##/b ##a ##//b ##/b ##/b ##/b ##/b ##/b ##/b ##/b ##/b ##a ##//b ##/b ##/b ##/b ##/b ##/b ##/b ##/b ##/b ##/b ##/b ##/b ##/b ##a ##a - time : 0.07s - loops : 2675 - rewrites : 1192 - dupls : 701 - annis : 491 - betas : 177 ``` I formatted the list for clarity, but that's the bruijn-encoded list `[0,4,8,12]`, which is indeed the normal form of `map (* 2) . map (* 2) $ [0,1,2,3]`. 
Actually the term is a dynamic programming table, not sure how to simulate that in haskell
I think that `package: ghc` in the FAQ means that `ghc` is the Debian package they install to provide GHC.
There's no need to do bottom-up dynamic programming in haskell; everything you need is already there due to laziness. The key is to make sure that the computation you want to cache is itself represented as a data structure. If you want to just get this 'for free' without really having to bother, you can use something like the [`MemoTrie`](https://hackage.haskell.org/package/MemoTrie) package. I might write an article on this later this month.
I must admit that I never understood what `invokedynamic` was good for or what problem it is supposed to solve. I think it's something to do with obejct oriented dynamic languages? Hence, the opposite of Frege. &gt; Therefore you can generate bytecode which doesn't catch exceptions, while in java you would have to write all those try-catchs wrapping the exceptions in runtime exceptions, rethrowing them via a helper function or tainting all your functions with thows Exception. I see. From Frege, you can throw only unchecked exceptions. Checked ones appear only in native (i.e. imported from Java) functions, and surely you don't want to ignore those. Hence, any Java method that throws checked exceptions must have a wrapper anyway. But of course the compiler does that automatically and transparently.
Could you restructure your problem as a set of recurrence relations? I'm having a hard time figuring out what value you want in the end. You keep talking about 'updating' the next row, and I can see why you may want to do that, but I'm having a hard time figuring out what you want to arrive at in the end. Are you trying to calculate the probability of an event occurring 'n' times? 
Lamping's 'optimal reduction' consists of 2 parts. Very simple and uncontroversial 'abstract algorith' and 'the oracle'. The graph in the abstract part has nodes of N types. [Figure 2 in this paper](https://pdfs.semanticscholar.org/6cfe/09aa6e5da6ce98077b7a048cb1badd78cc76.pdf) shows all the rules for N=2 (for N&gt;2 rules are the same, i.e. annihilate when nodes are the same type, duplicate otherwise). The oracle is controversial but necessary to implement all the untyped lambda calculus. One may ask what about typed lambda calculus. With N=1 (and a certain technical property: all-switchings-are-acyclic) , you get linear logic. I.e. a calculus that which each step the term (or graph) get smaller. With N=2 (and the same property): you get some copying. I.e. you are able to copy the terms that are linear (N=1 case). But you have no way of copying the terms containing both types of nodes. With N=3 (and the same property) you can copy terms containing N=1 and N=2 nodes with your N=3 node, but not the terms containing N=3 nodes, etc... One can prove (I'm not sure completely that its true) that for a given N, the abstract algorithm is complete for complexity O(2^(2^... k)....) i.e. it can express any algorithm that has its complexity being a tower of exponential of height N. Without a bound on N, the abstract algorithm can express all the algorithms of complexity of tower of any finite height. This class is called [ELEMENTARY](https://en.wikipedia.org/wiki/ELEMENTARY). For instance it does not include Ackermann's function computational complexity. I'm also not sure about how to implement ```\n -&gt; n^^n``` (exponentiation) in abstract algorithm. Help? Oracle allows you to change the level of a node *dynamically*. I.e. it has 2 additional families nodes that I'll call "+1" and "-1" (they are usually called bananas and brackets). The problem of the oracle is that one might have a "+1" node followed by "-1" node that have no effect on the graph. Yet such a pair will not disappear. Moreover, in the Lamping's encoding of the untyped lambda calculus, such pairs accumulate and can make significant overheads. A part of the problem is that Lamping's algorithm is putting them in every lambda term even if they are not needed. [Here's a paper](https://www.semanticscholar.org/paper/Optimizing-optimal-reduction%3A-A-type-inference-for-Coppola-Martini/56bc8efa7857ba50f11c75045b64a59bcafa4b6f) that tries to identify where "+1" and "-1" are needed. There is a folklore that the 'abstract' part of the algorithm is non-controversial. Yet reading of a recent [Andrea Asperti paper](https://pdfs.semanticscholar.org/8a35/42d70fc1d4531bc77c7bda130b0350245763.pdf) made me realize that there is a problem with it. I recommend section 4.2, but I'll try to shortly describe the gist of the main problem here. Lamping's algorithm implements *maximal sharing*. This means that a beta-reduction or copy-reduction will never be evaluate twice, i.e. (an appropriate part of) reduction will be evaluated before it is copied. Both copies will be stored until they are consumed. It might take a lot of time until the second copy is needed. Memory usage will be high. Moreover, after long time it might turn out that the other copy (or copies) will be erased. This effect is also present in Haskell and it is called *space-leaks*. When it comes to CPU-Memory trade-off, Lamping's algorithm is opinionated. I'm afraid that *maximal sharing = maximal space-leaks*. But I'm not sure, that's one of my main research topics recently. I'd love to learn more if anybody is knowledgeable. This situation applies in both the cases of lazy and strict evaluation (try not to copy if it's going to be deleted anyway). Lazy evaluation requires separate Garbage Collection. In the case of strict evaluation the situation is worse because one might have huge terms that are already disconnected from the main graph but will get evaluated for a long time just to be deleted. This implementation of identity illustrates a mild example of this effect: ```(\x -&gt; ((\a -&gt; \b -&gt; b) x x)) hugeTerm```. 
Hum, you mean as in, printing the normal form of `(map double . map double)`, optimized? That is not possible in the same way you can't print the normal form of `map` itself. If that was what you mean I guess I get it, but why would that matter? Perhaps I just don't get exactly what you're arguing for - are you arguing against the abstract algorithm being feasible, or that it isn't supercompilation? (I agree with the later!)
Optimal reduction certainly can reduce a class of lambda terms to their normal forms in exponentially less steps required by every one of call-by-name, call-by-need, and call-by-value. There is no question about this. Your example linked to in the subject demonstrates this too. However, claiming it can have "supercompiler" like behavior is misleading. You example only demonstrated *evaluation* or *reduction of closed terms*, but not *compilation*, which is a transformation from program to program.
By the way, the definition of `map` is already in normal form, which by definition is only required to have no beta redex. Similarly, you can reduce `(map double . map double)` to normal form too.
You mean the map I linked you? It has no normal form... (?)
This worked great! Thanks :)
First, thanks SrPeixinho for the experiments, they are awesome. Lamping's 'optimal reduction' consists of 2 parts. Very simple and uncontroversial 'abstract algorith' and 'the oracle'. The graph in the abstract part has nodes of N types. [Figure 2 in this paper](https://pdfs.semanticscholar.org/6cfe/09aa6e5da6ce98077b7a048cb1badd78cc76.pdf) shows all the rules for N=2 (for N&gt;2 rules are the same, i.e. annihilate when nodes are the same type, duplicate otherwise). The oracle is controversial but necessary to implement all the untyped lambda calculus. One may ask what about typed lambda calculus. With N=1 (and a certain technical property: all-switchings-are-acyclic) , you get linear logic. I.e. a calculus that which each step the term (or graph) get smaller. With N=2 (and the same property): you get some copying. I.e. you are able to copy the terms that are linear (N=1 case). But you have no way of copying the terms containing both types of nodes. With N=3 (and the same property) you can copy terms containing N=1 and N=2 nodes with your N=3 node, but not the terms containing N=3 nodes, etc... One can prove (I'm not sure completely that its true) that for a given N, the abstract algorithm is complete for complexity O(2^(2^... k)....) i.e. it can express any algorithm that has its complexity being a tower of exponential of height N. Without a bound on N, the abstract algorithm can express all the algorithms of complexity of tower of any finite height. This class is called [ELEMENTARY](https://en.wikipedia.org/wiki/ELEMENTARY). For instance it does not include Ackermann's function computational complexity. I'm also not sure about how to implement ```\n -&gt; n^^n``` (exponentiation) in abstract algorithm. Help? Oracle allows you to change the level of a node *dynamically*. I.e. it has 2 additional families nodes that I'll call "+1" and "-1" (they are usually called bananas and brackets). The problem of the oracle is that one might have a "+1" node followed by "-1" node that have no effect on the graph. Yet such a pair will not disappear. Moreover, in the Lamping's encoding of the untyped lambda calculus, such pairs accumulate and can make significant overheads. A part of the problem is that Lamping's algorithm is putting them in every lambda term even if they are not needed. [Here's a paper](http://www.cs.unibo.it/~martini/papers-to-ftp/EA-typing.pdf) that tries to identify where "+1" and "-1" are needed. There is a folklore that the 'abstract' part of the algorithm is non-controversial. Yet reading of a recent [Andrea Asperti paper](https://pdfs.semanticscholar.org/8a35/42d70fc1d4531bc77c7bda130b0350245763.pdf) made me realize that there is a problem with it. I recommend section 4.2, but I'll try to shortly describe the gist of the main problem here. Lamping's algorithm implements *maximal sharing*. This means that a beta-reduction or copy-reduction will never be evaluate twice, i.e. (an appropriate part of) reduction will be evaluated before it is copied. Both copies will be stored until they are consumed. It might take a lot of time until the second copy is needed. Memory usage will be high. Moreover, after long time it might turn out that the other copy (or copies) will be erased. This effect is also present in Haskell and it is called *space-leaks*. When it comes to CPU-Memory trade-off, Lamping's algorithm is opinionated. I'm afraid that *maximal sharing = maximal space-leaks*. But I'm not sure, that's one of my main research topics recently. I'd love to learn more if anybody is knowledgeable. This situation applies in both the cases of lazy and strict evaluation (try not to copy if it's going to be deleted anyway). Lazy evaluation requires separate Garbage Collection. In the case of strict evaluation the situation is worse because one might have huge terms that are already disconnected from the main graph but will get evaluated for a long time just to be deleted. This implementation of identity illustrates a mild example of this effect: ```(\x -&gt; ((\a -&gt; \b -&gt; b) x x)) hugeTerm```. Lukasz Lew
The probability of _any of several things happening_ is the inverse of the product of their inverse probabilities. p1 = 0.24 -- chance of first event happening p2 = 0.42 -- chance of 2nd inverse p = 1.0 - p p1' = inverse p1 -- chance of first event NOT happening p2' = inverse p2 p1_or_2' = p1' * p2' -- chance of NEITHER event happening p1_or_2 = inverse p1_or_2' -- chance of EITHER event happening -- Also: p1_and_2 = p1 * p2 -- chance of BOTH events happening p1_and_2' = inverse p1_and_2 -- chance of EITHER OR BOTH events NOT happening 
Cool, thanks for the notice!
Genuine question here, how is algebraic data type different from, say objects in JavaScript or value objects in Java? It seems to me they all contain different data packed into a single aggregate. Except for immutability, they kinda do the same thing..
Is [Data.Map.Strict.mergeWithKey!](https://hackage.haskell.org/package/containers-0.5.11.0/docs/Data-Map-Strict.html#v:mergeWithKey) safe? I previously assumed that it'd be unsafe, based on [Data.Map.Lazy.mergeWithKey!](http://hackage.haskell.org/package/containers-0.5.11.0/docs/Data-Map-Lazy.html#v:mergeWithKey). But upon closer inspection I don't actually see any warnings on it. (Given that the safety is nontrivial to verify for end-users, it might be really helpful if we add a note to Data.Map.Lazy.mergeWithKey telling the user that Data.Map.Strict.mergeWithKey could be a viable option, if they're willing to swap to strict maps?)
Ohhh, wait, I got mixed up -- [Data.IntMap.Strict](https://hackage.haskell.org/package/containers-0.5.11.0/docs/Data-IntMap-Strict.html#v:mergeWithKey) seems to be the safe one. I'm getting mixed up between the extremely-similar-looking docs, though I'm not really seeing that there's any simple solution to that!
I wonder what they mean by "monad transformers (...) instances are not free and difficult to test".
&gt;Any chance that codebase will opened up for viewing some day? Very little chance of that. I don't stream myself working on certain parts of it. I've touched a large portion of it at one time or another while streaming so the missing parts shouldn't matter to anyone not trying to compete with me.
That's still fine. Thanks for this once again
I actually tend to agree. I mean, the syntax is opt-in, so it should only break existing code that someone plops a DerivingVia pragma on.
It breaks the abstract part if the optimal algorithm, not the full optimal algorithm. Abstract algorithm breaks when we have a term that has to duplicate itself (impredicativity). 
Compare the difficulty of testing code which is pure (only relies on input parameters) withe code that needs to operate within a transformer stack. The first is relatively easy to test, the second requires setup of the stack. Consider in particular when the stack is complex, and then compare `MonadReader` vs explicitly passing the value as a parameter. 
This is a nice approach, but it seems to me some of the "zero cases" are missing - and I don't think this is necessarily a trivial matter (i.e., not just "use nonempty lists"). In optimization, you often don't know whether a solution will even exist. For example, I give you a list of generic products to buy (fertilizer, dog food, etc) and a bag to carry them and say "buy these while spending as little money as possible." Well, it may turn out that there is not even any combination of these items available at the store that fits in the bag I gave you. I think the article is sort of predicated on the fact that trivial (if poor) solutions exist, no?
Yeah -- I had the docs open for Data.Map.Lazy, Data.Map.Strict, and Data.IntMap.Strict open at the same time, and got them mixed up. My mistake
This looks really interesting but that site has all sorts of rendering issues in Firefox mobile, such that it wasn't possible to read it. I'll look it up on another device maybe, but thought you might like to know. 
This query is too complex for `persistent`, you'll need to use the `esqueleto` library or a raw SQL query. Do you know how to write this in SQL?
I try to do a exercise I once did in c# and there they give a very complex sql query. The query they give was this one : SELECT {Room}.* FROM {Room} WHERE @NumberOfAdults &gt; 0 AND {Room}.[AdultsCapacity] &gt;= @NumberOfAdults AND {Room}.[AdultsCapacity]+{Room}.[ChildrenCapacity]&gt;=@NumberOfAdults+@NumberOfChildren AND NOT EXISTS (SELECT 1 FROM {Booking} WHERE {Booking}.[RoomId] = {Room}.[Id] AND (@CheckInDate BETWEEN {Booking}.[CheckInDate] AND {Booking}.[CheckOutDate] - 1 OR @CheckOutDate BETWEEN {Booking}.[CheckInDate] + 1 AND {Booking}.[CheckOutDate]) AND {Booking}.[StatusId] &lt;&gt; @Canceled) ORDER BY {Room}.[Price] ASC but I hoped there was a easier way then using raw sql. IM not so good in raw sql . 
You can translate the logic into an `esqueleto`. You can also do it in multiple queries (and a single transaction), though this will perform worse.
oke, Then I have to think well how to translate this in esqueleto. Never worked with it. Any hints 
Their response to the use is partial functions is worrying especially given their emphasis on formal methods. If something can fail you need to handle it’s failure.
It will work if you change the type signature to `nmap :: (forall s m. Node s m -&gt; Node s m) -&gt; NodeADT -&gt; NodeADT` Be aware that in that case your function can't do anything specific with the `s` and `m` types.
Thanks, that compiles now. I'll have to see whether it works for this use case.
Specifically, `fn' = traverse fn`.
Can I get an ELI5 for it?
/r/haskell/comments/8bt1o2/ghc_proposal_deriving_via/
In short in allows to do automatic derivation of a typeclass by automaticcally wrapping it and unwrapping it in a newtype and reuse the newtype instance. This mean you don't have to write the code yourself and can also chose the underlying implementation by specifying which intermediate newtype to use. 
Using on Map with Either as in my example enforces the fact that an item are either a price or belong to a category. In your model you still have no guarantie that the category belong to item is in the Map ...
Just to add that Hoogle can be very useful for finding library functions when you know the type. If you generalise the type a bit, [it shows both mapM and traverse](https://www.haskell.org/hoogle/?hoogle=%28a+-%3E+m+a%29+-%3E+%5Ba%5D+-%3E+m+%5Ba%5D).
You can list c sources in a cabal file with `c-sources: foo.c`
This seems to also work in `package.yaml`: ``` library: source-dirs: - lib c-sources: lib/a.c ``` Is that the intended way for stack?
In Haskell it's definitely sometimes better to recalculate rather than store. As I recall, `permutations` is a good example.
Maybe I'm just not experienced enough but it isn't immediately obvious why that would be useful.
Labels disambiguate fields of the same type, and also decouple the meaning of the field from its representation. You can use newtypes with this purely type-directed approach to the same effect. But if you wrap/unwrap them often, the code can become more noisy than indexing into records by field name/symbol.
That's a good point. I didn't think of the maintenance burden of changing the type. So
You register in advance. I seem to recall the registration for the ICFP that I attended opening a lot later than I expected, too.
Thanks for the feedback &gt; I plan to make the utility calculations more per-squad than &gt; per-actor and then intelligently distribute the goals with the &gt; highest utility among the squad members. Interesting. I think it would be interesting to decide on the balance between centralised control of a squad vs emergent squad like behaviour from per-actor rules. I saw an idea on roguebasin when the author had the idea of "remote actions" i.e. actions that one actor can "send" to another. Another idea perhaps is to have a squad "memory" with rules for interaction. That might lead to more emergent behaviour rather than having to try coordinate actors. It all depends on what you are after :) Let us know what worked for you, when you have tried? 
I can't give a well thought reply right now, but reducing: ``` (λx. ((λa. λb. b) x x)) ((5 5) (5 5)) (λx. x) (λx. x) ``` Takes `570841` rewrites, where reducing just ``` ((5 5) (5 5)) (λx. x) (λx. x) ``` Takes `352084` rewrites, so almost half. Is that what you meant?
Let's say you are creating your own type which happen to be a `Num` so you have something like data MyNum = MyNum &lt;your code&gt; instance Num MyNum where &lt;your code&gt; And now you would like `MyNum` to be a Moniod (so that you can collapse many `MyNum` to one). If someone has defined a `Monoid` instance for all `Num` by doing instance Num a =&gt; Monoid a where a `mappend` b = a + b mempty = 0 `MyNum` type would have been a `Monoid` without having to do anything. However, this is not the case (for many reasons) but instead we have two wrapper `Sum` and `Prod` which uses either `+` or `*`. Given two `MyNum` I can write `getSum (Sum myNum1 &lt;&gt; Sum myNum2)` and get a new `MyNum` which uses the `+` defines for `MyNum`. I can also do `getProd (Prod myNum1 &lt;&gt; Prod myNum2)` and get the product of the two `MyNum`. If you wanted to use `+` to defined a Monoid instance for MyNum you could write instance Monoid MyNum where mempty = getSum mempty a `mappend` b ` getsum (Sum a `mappend` Sum b) Or using the `DerivingVia`, just write something along data MyNum = MyNum &lt;...&gt; deriving Monoid via Sum 
They probably don't bother opening registration until they've notified authors of acceptance, since many will only attend if their paper gets accepted.
Continuing on the idea of using newtypes to represent fields, instead of data User = User { firstName :: String , lastName :: String , age :: Int } we could write newtype FirstName = FirstName String newtype LastName = LastName String newtype Age = Age Int type User = (FirstName, LastName, Age) And construct or pattern-match on users as ( FirstName fn, LastName ln, Age a ) Since fields are standalone types, they can trivially be reused. type FullName = (FirstName, MiddleName, LastName) The ergonomic differences from a single `Label` type (like in `labels`) are quite subtle, but it's not clear to me whether one is definitely superior to the other. newtype Label label a = Label a
You're making the classic mistake of trying to enforce database constraints in the application. Preventing "double bookings" is the easiest to solve at the database level, at least in PostgreSQL, with the use of exclusion constraints. An exclusion constraint is just an abstracted unique constraint that lets you specify the operator. In your case, you want something like this: CONSTRAINT bookings_no_double_booking EXCLUDE USING gist ( room_id WITH = , daterange(checkin_date, checkout_date) WITH &amp;&amp; ) If you want to find a room that is free on a given date, that's easy too: SELECT room_number FROM rooms WHERE NOT EXISTS (SELECT 1 FROM bookings WHERE bookings.room_id = rooms.room_id AND daterange(checking_date, checkout_date) @&gt; '2018-04-14'); * http://thoughts.davisjeff.com/2010/09/25/exclusion-constraints-are-generalized-sql-unique/ * https://www.postgresql.org/docs/current/static/functions-range.html As for enforcing maximum room occupancy, that should be done using a constraint trigger. This is completely irrelevant when searching for a free room. Don't select more information than you actually need at any given time. P.S. you might want to switch to a timestamptz (tstzrange) rather than a date, since occupants are not guaranteed to leave at the specified checkout time. P.S.S. you might also want to add a check constraint to prevent checkin_date from being greater than the checkout_date.
I want to write a C linter in Haskell, more for practicing my Haskell than for the need of the utility. How would I go about doing that?
oke, this is complete new to me. Can I do this with esqueleto or persitence or where do I put these constrains. I will also read the links 
There's no way to make a complicated query any simpler by trying to use another language that compiles to SQL.
Oke, I have to do the contrains on the database itself. Can I do the select with persintence then ? 
Yep. both contrains can I also make on the database itself ? 
Woah. Thanks u/Maxigit that is awesome. I have actually been doing stuff like this and your explanation makes it much clearer. Thanks
What I have know is definitely a lot of (silly) emergent behaviour. It's fun to watch (e.g., in screensaver mode when AI controls both heroes and monsters and I can watch one or the other party), but strength of AI suffers and then the player is more "how do I exploit AI quirks" than "how do I deny information to AI and predict its moves based on what I led it to believe". I have the impression the "autonomous actors" is not really any deep concept, but just one of many equally reasonable ways of iterating over data --- in this case iterating over friendly actors, as opposed to iterating over enemies, loot, strategic points on the board, etc. It's simple to code, doable in one pass and so cheap computationally and it's relatively stateless, but these are all just convenience factors. Well, I will know better when I experiment. :)
Look at hlint for inspiration!?
That's pretty untrue. We compile higher level languages down to something else all the time because they make it easier to express what we want. It might be the case that SQL is already high enough that we have no good alternatives, though.
Yes, you should register in advance. I saw on a relevant and reputable twitter feed that they are working on a combined ticket this year for Elm + ICFP + RacketCon + PW&lt;3 + SL. That might be part of the additional time delay.
Nice! I'm looking forward to your presentation at SeaHUG.
Yes, you're absolutely right. This was meant as a sketch of a basic technique. There is still a long way to go before this can be made into some kind of generalized package. I think what you're getting at is that some combinations are simply undefined, right? Typically, with `[]`, you could use `guard`, which requires an `Alternative` instance. This would have the effect of 'pruning' particular branches from the search space. I'm certain we could write such an instance for `Combinatorial`, I just haven't gotten around to it yet. Of course, having such an instance would mean that the final optimization would return `Maybe`. As it is `minimum` is a partial function as well, so -- for lists -- this detail is being hidden by the fact that `minimum []` is `error`.
Actually we recently did just that for Mono: https://github.com/lambdageek/Centrinel The key design decisions I made were: 1. Don't be the C compiler - look for domain-specific bugs for my application of interest, don't try to solve all C problems. 2. Use [language-c](https://github.com/visq/language-c) for parsing and semantic analysis. The nice thing about `language-c` is that it's pure Haskell and it understands enough of C99 (and some C11) for my needs. The semantic analysis is a little bit frustrating to work with (it tries to be extensible, but right now you only get to hook into it at toplevel definitions and declarations, so if you want to thread your own analysis through function definitions you end up duplicating a lot of the typechecker control flow).
&gt; I think what you're getting at is that some combinations are simply undefined, right? I don't think so. Take the shopping bag example again -- if my bag holds a maximum of 30 cm^3, it might be that the smallest pack of dog food the store has is 15 cm^3 and the smallest bag of fertilizer is 20 cm^3. Here, each item would fit into the bag individually, and the objective function (price) is obviously defined no matter how I combine these items, but yet the constraint is still unsatisfiable and the problem has no solutions.
@cinnamon and can you give examples how I can make these constains. It's it not a danger when deploying to another database that the constrains are forgotten. 
[removed]
I guess with "type-directed" extensible records, you get the option of mixing usage of newtype wrappers with "plain" types. For example, say there is a data type where you most likely will only only have one of this type in a record, or that you do not necessarily want the newtype wrapping/wrapping noise for it. data Hobby = Haskell | Gardening | Cooking type User2 = (FirstName, LastName, Age, Hobby) If the concept of a label is built into the extensible record system, then you would be forced to provide labels for that field, whereas a type only record system will allow you both options (and use newtype wrappers instead of labels to provide unique types). My motivating use case is that I've been experimenting with a widget library that can create larger widgets by somehow combining smaller widgets. In this case, if I have a widget A (that knows how to manipulate the state "A") and I want to combine it with widget B and C (that manipulate different types), then the combined state of the widget will effectively (A, B, C). widgetA :: Widget A widgetA = ... widgetB :: Widget B widgetB = ... widgetC :: Widget (A, B, C) widgetC = widgetA `magic_plus` widgetB `magic_plus` widgetC In this case, I don't want to force the user to declare new types just to combine the widgets: -- This would have to be declared at the type level just -- for the 'widgetC' function. newtype wrapper FieldA = FieldA A newtype wrapper FieldB = FieldB B newtype wrapper FieldC = FieldC C Then, only in the case you want to combine widgets with the same type, would you have to use the newtype wrappers (or the single `Label` type or `Data.Tagged`) to make them distinct from each other. 
Works fine for me on Windows. You can try putting [debug](https://hackage.haskell.org/package/base-4.11.0.0/docs/Debug-Trace.html) statements around suspicious calls to help you pinpoint where exactly its failing.
huh. I'm on ubuntu and it runs fine but gives me a segfault once the snake dies.
Nice project. I guess this is complementary to https://hackage.haskell.org/package/file-embed?
There are literally several fully fledged SQL DSLs in Haskell alone. 
Try using stack (haskellstack.org). It has LTS snapshots which pins all packages to versions that play nice together
From a cursory glance at the docs it think it is. It's a nice approach for your executable but it doesn't seem to solve the problem of a dependency referencing some external resource; asset-bundle does.
ICPF is in September. Registration will not open until July or August.
There are a number of C lexers/parsers for Haskell. Search for `language-c` on https://hackage.haskell.org/packages/ .
That's right, `gdb` is the tool of choice to debug segfaults. Or Visual Studio (e.g. VS 2015) in case you are on Windows. They will show you in which C function the segfault happened and the stack trace to there (with `bt`), as it's relatively unlikely that the segfault is in Haskell code.
Record without labels are just tuples, if you really enjoy this `Has` style, please checkout [data-has](http://hackage.haskell.org/package/data-has).
Write a scheme or python linter or something first. C is pretty hard to parse since it has context-dependent grammar, you have to make bunch of passes and "lexer trick" to parse it right.
Kinds are the types of types. Typeclasses are more like predicates or relations between types.
A typeclass isn't quite the type of a type and thinking about it this way does not give you the correct intuition (hence why some people will think of writing Num -&gt; Num, rather than Num a =&gt; a -&gt; a) A typeclass is a set of implicit functions/values associated with a given type. In particular, it is a structure, not a property, and the existance is associated with an implementation, not a data structure (for instance, numbers can be made into Monoids in numerous ways, that doesn't mean that they are a Monoidal type, you need to describe what the implementation is)
If a type has an `Eq` instance, says that the type in question has a property: namely, for any three values `a`, `b`, `c` of that type you can compare them in a way that `a == a`, `a == b` implies `b == a`, and `a == b` + `b == c` imply `a == c`. If a type has an `Integral` instance, that's a statement saying the type has another property (namely that it implements the `Integral` methods, obeys their laws, and so on for each superclass).
Typeclasses are type constructors, of kinds like `* -&gt; Constraint` (`Num`, `Eq`, `Ord`) or `(* -&gt; *) -&gt; Constraint` (`Functor`, `Applicative`, `Monad`), &amp;c.; however, since they behave like predicates on types, you could think of them as subsets of kinds—`Eq` is the class of types of kind `*` that can be compared for equality. But there’s the rub: the most literal definition of a typeclass is “a class of types”.
The app consumes 4ms out of each 16ms frame when idle. That's a lot for doing nothing.
I like it. [data-has](http://hackage.haskell.org/package/data-has) is a really simple way of adding the ability to get/set types for tuples. Does the compiler enforce that each field has a unique type (with maybe overlapping instance errors)? What happens if there are fields with the same type?
I just tried it, yes, data-has correctly complains with "Overlapping instances" errors. I'll update my gist to use Data.Has as well.
A typeclass is a property of a type, like /u/Thimoteus said. `Eq`-types are types that can be compared, `Num`-types are types that behave like numbers, `Functor`-types are types that behave like containers. When you write something like `myFunction :: Num a =&gt; a -&gt; a`, then you're using the typeclass to *constrain* what values `myFunction` can work with - you're saying "only types that behave like numbers, please". By the way, it's not very hard to get the same functionality without typeclasses, although it becomes a bit cumbersome to actually work with: -- Eq "typeclass", which is just a dictionary of functions data Eq a = EqInstance { (==) :: a -&gt; a -&gt; Bool , (/=) :: a -&gt; a -&gt; Bool } -- shorthand for defining instances based on the (==) function mkEq :: (a -&gt; a -&gt; Bool) -&gt; Eq a mkEq cmp = EqInstance cmp (\x y -&gt; not (cmp x y)) -- Eq "instance" for Bool boolEq :: Eq Bool boolEq = mkEq cmp where cmp True True = True cmp False False = True cmp _ _ = False -- Eq "instance" for maybe, with a constraint that a must also have an instance maybeEq :: Eq a -&gt; Eq (Maybe a) maybeEq eqA = mkEq cmp where cmp Nothing Nothing = True cmp (Just x) (Just y) = (==) eqA x y -- infix operators don't work so well with this :( cmp _ _ = False -- Function with Eq constraint lookup :: Eq a -&gt; a -&gt; [(a, b)] -&gt; Maybe b lookup _ _ [] = Nothing lookup eqA a ((k,v):xs) = if (==) eqA a k then v else lookup eqA a xs
That’s right they do do the same thing at run time. There isn’t anything too special about the underlying representation of algebraic types. They are extremely different at compile time though. You can express way more interesting types in way less time with `data` than any way in Java. 
&gt; To support multiple variables, we’ll just have our objective function return another optimization problem I think this only works if the objective function is "separable" in functions of the single variables (e.g. is a linear combination of the single costs). 
Okay, I'm beginning to comprehend it! I'm intrigued by the first part of your comment. Is Num -&gt; Num the exact same thing as Num a =&gt; a -&gt; a? Correct me if I'm wrong, but the =&gt; is a class constraint so that 'a' adheres to the rules in the Num type, right? Does this make Num a typeclass? What about Int a =&gt; a -&gt; a is Int a typeclass?
There are multi parameter type classes as well. Those make no sense if you think of then as kinds.
I doubt that link is active anymore, as it just redirects to https://www.haskell.org/ghc/ , but I could be wrong. In such cases is best to use the provided WHOIS admin e-mail address. In this case it's hostmaster@galois.com . Domain Name: HASKELL.ORG Registry Domain ID: D495475-LROR Registrar WHOIS Server: whois.enom.com Registrar URL: http://www.enom.com Updated Date: 2016-07-07T00:20:21Z Creation Date: 1996-12-12T05:00:00Z Registry Expiry Date: 2019-12-11T05:00:00Z Registrar Registration Expiration Date: Registrar: eNom, Inc. Registrar IANA ID: 48 Registrar Abuse Contact Email: abuse@enom.com Registrar Abuse Contact Phone: +1.4252982646 Reseller: Domain Status: clientTransferProhibited https://icann.org/epp#clientTransferProhibited Registry Registrant ID: C2861138-LROR Registrant Name: Yale University Computer Science Department Haskell Group Registrant Organization: Yale University Computer Science Department Haskell Group Registrant Street: 51 PROSPECT ST Registrant City: New Haven Registrant State/Province: CT Registrant Postal Code: 06511-8937 Registrant Country: US Registrant Phone: +1.9999999999 Registrant Phone Ext: Registrant Fax: +1.9999999999 Registrant Fax Ext: Registrant Email: hostmaster@galois.com Registry Admin ID: C57836113-LROR Admin Name: Galois Hostmaster Admin Organization: Galois, Inc Admin Street: 421 SW 6th Ave Admin Street: Suite 300 Admin City: Portland Admin State/Province: OR Admin Postal Code: 97204 Admin Country: US Admin Phone: +1.5036266616 Admin Phone Ext: Admin Fax: Admin Fax Ext: Admin Email: hostmaster@galois.com Registry Tech ID: C57836113-LROR Tech Name: Galois Hostmaster Tech Organization: Galois, Inc Tech Street: 421 SW 6th Ave Tech Street: Suite 300 Tech City: Portland Tech State/Province: OR Tech Postal Code: 97204 Tech Country: US Tech Phone: +1.5036266616 Tech Phone Ext: Tech Fax: Tech Fax Ext: Tech Email: hostmaster@galois.com Name Server: LEX.NS.CLOUDFLARE.COM Name Server: POLA.NS.CLOUDFLARE.COM DNSSEC: unsigned URL of the ICANN Whois Inaccuracy Complaint Form: https://www.icann.org/wicf/ &gt;&gt;&gt; Last update of WHOIS database: 2018-04-15T10:00:55Z &lt;&lt;&lt; For more information on Whois status codes, please visit https://icann.org/epp Access to Public Interest Registry WHOIS information is provided to assist persons in determining the contents of a domain name registration record in the Public Interest Registry registry database. The data in this record is provided by Public Interest Registry for informational purposes only, and Public Interest Registry does not guarantee its accuracy. This service is intended only for query-based access. You agree that you will use this data only for lawful purposes and that, under no circumstances will you use this data to: (a) allow, enable, or otherwise support the transmission by e-mail, telephone, or facsimile of mass unsolicited, commercial advertising or solicitations to entities other than the data recipient's own existing customers; or (b) enable high volume, automated, electronic processes that send queries or data to the systems of Registry Operator, a Registrar, or Afilias except as reasonably necessary to register domain names or modify existing registrations. All rights reserved. Public Interest Registry reserves the right to modify these terms at any time. By submitting this query, you agree to abide by this policy.
Diagrams of the first kind (where in each crossing one strand goes below the other) are called [braids](https://en.wikipedia.org/wiki/Braid_group). They are surprisingly complicated. There is a Haskell implementation [here](https://hackage.haskell.org/package/combinat-0.2.8.2/docs/Math-Combinat-Groups-Braid.html). It turns out that equality of braids (in the standard Artin representation) is decidable using normal forms. One version of this is implemented [here](https://hackage.haskell.org/package/combinat-0.2.8.2/docs/Math-Combinat-Groups-Braid-NF.html).
Another point of view: the type of a value tells you what operations are valid on it. In the same vein, the type of a type should tell you what operations are valid on *that type itself*. If I know that `'a' :: Char`, I know I can pass it to `toUpper :: Char -&gt; Char`. Similarly if I know that there's an `instance Num Int` then I know I can pass *values* of type `Int` to `negate :: Num a =&gt; a -&gt; a`. This is still about operations on values, not types. Here's how the actual "types of types" work (they're called kinds). `Int` has kind `*`, written `Int :: *`. Meanwhile `Maybe :: * -&gt; *`, so I'm allowed to pass `Int` to `Maybe` in order to form the new type `Maybe Int`. This is an operation on the types themselves. If I tried to pass `IO :: * -&gt; *` to `Maybe` to form `Maybe IO`, the kinds wouldn't match and the compiler would reject my code. And indeed it makes no sense. `Maybe`is supposed to hold concrete values of some type. There are no values of type `IO`, only of type `IO a` for some `a`.
I can't comment on _Reason_. The last time I looked into the state of client side functional languages GHCJS was a no-go for me. It compiles the entire GHC runtime into Javascript which you will need to load and it is recommended that you have 8-16 GB RAM to compile. Not to mention, at it's current state it reimplements a lot of GHC Haskell. Just to get GHCJS working for your project is a project in and of itself. I really wanted to like GHCJS, the idea is brilliant, but it just does not seem like a good idea to use in production in its current state. Purescript seems to be the way forward if you just want to improve the usability for the already existing UI with a Haskell-like language in place of Javascript. The code it generates isn't fast and I wouldn't use it for heavy client side calculations (then again, neither would I use Javascript), but it's a good strongly-typed replacement for general Javascript tasks like AJAX and DOM manipulation which are handled by the browser anyhow. There also exists https://hackage.haskell.org/package/purescript-bridge , which allows you to export your Haskell types to Purescript so you don't have to duplicate your code between frontend and backend.
I have no idea what you're asking. I already gave you examples. There's no point in having a database at all if you don't have the constraints necessary to prevent irregular data from creeping in.
Bonus reading: if you enable the ConstraintKinds GHC extension, you get to talk about the "kind of a type class" too. Normal types have kind `*`, while the things you write on the left side of `=&gt;` have kind `Constraint`. So `Num a :: Constraint`, which means `Num :: * -&gt; Constraint`. `Functor`, meanwhile, takes arguments of kind `* -&gt; *`, which means `Functor :: (* -&gt; *) -&gt; Constraint`. When doing heavy type system hackery, you sometimes encounter things that go the opposite way, turning `Constraint` into `*`. The take away from this is that the world of `*` and the world of `Constraint` are both part of the same type level language. They don't have a hierarchical relationship. In the language of partial orders, you can think of "types" and "constraints" as incomparables.
"What I personally would like to see is more client side use of Webassembly and get rid of Javascript entirely, but we aren't there yet." Yeah thats the dream of every front-end developer. But controlling the chaos of the client side development using the existing frameworks like React, angular, ember etc is still bad. Hope this changes soon! Does Ghcjs have concepts like Redux for immutability or so, Dom diffing like React etc ?
&gt;Does Ghcjs have concepts like Redux for immutability or so, Dom diffing like React etc ? GHCJS only compiles Haskell to Javascript, so there aren't any real concepts in that sense. You can use any pure Haskell library from Hackage together with GHCJS. There is also react-haskell and reflex (FRP framework) for GHCJS, but I never used them and cant comment on them: https://github.com/joelburget/react-haskell , https://github.com/reflex-frp/reflex
The output of ghcjs is quite big. That's a downside. That downside can be minimised with things like the closure compiler, but it's a downside nonetheless. Nevertheless that's something that can be lived with for the benefits it gives you: - Code generation with Generics and TemplateHaskell - Lens love - Elm like architecture and easy programming with [Miso](http://haskell-miso.org/), without Elm's language restrictions. You can do FFI without going through ports and subscriptions. - Code sharing with Haskell, more than something like the `purescript-bridge` you mention can offer, as you can also share application logic. - Advanced type safety, with type families and the like, because Haskell. Starting a ghcjs project is easy enough, especially if you use nix. Try cloning [this Miso components example](https://github.com/FPtje/miso-component-example). Compile it by running `nix-build` in the cloned directory. You can build your application using that as a starting point if you like!
And which one would allow you to express this (or any) query more simply? You are suggesting a major breakthrough in computer science, and providing no evidence to support it. If someone had discovered a higher level abstraction than the relational algebra it would be major news, not something some random guy casually mentions out of nowhere on reddit. Every single "SQL DSL", in haskell or any other language, uses the exact same operations as SQL, and is thus precisely the same level of abstraction. You might as well suggest using an arithmetic DSL because addition and subtraction are too complicated and a DSL can abstract them away.
Ghcjs produces much too large binaries, purescript barely has any optimisation passes at all, reason is mature. Reason is based on bucklescript, an ocaml-&gt;javascript compiler that produces fast and quite readable code (but not really editable), it's really just plain ocaml with a syntax more friendly towards curly-braced people. An accent, not dialect, dialects need semantics changes :) Facebook uses [reason-react](https://reasonml.github.io/reason-react/), using the ordinary js react implementation. [bucklescript-tea](https://github.com/OvermindDL1/bucklescript-tea) comes with its own vdom implementation in plain OCaml.
Well, I have to admit that I actually prefer stack behavior to cabal which didn't have a simple way to run the executable without checking if it needed to be built and it's simple enough to do `stack build &amp; stack exe` if I really need to. However, I guess a `stack run` command wouldn't hurt as it has been implemented, unless we fear that people will get confused between `exec` and `run` (In that cas maybe `exec --build` would have been better).
Check constraints: https://www.postgresql.org/docs/current/static/ddl-constraints.html#DDL-CONSTRAINTS-CHECK-CONSTRAINTS Yes, if your constraints are not in the database, there's nothing preventing you from getting invalid data.
There's a Haskell binding to the OCaml CIL library on Hackage. CIL is used by a number of existing static analysis tools like FramaC and at one point was also used by CompCert as the first unverified translation pass.
&gt; didn't have a simple way to run the executable without checking if it needed to be built `cabal new-run` does so.
Glad to hear it made sense. :)
`Num -&gt; Num` doesn't make any sense, and the compiler will reject it. It's just a thing beginners often try to do before they understand how typeclasses work.
I've been using this simple script which gives me `stack run`: $ cat /usr/local/bin/stack-run #!/bin/bash stack build --exec "$(cat $(basename $PWD).cabal | grep executable | head -n 1 | cut -d' ' -f2) $@" 
Any hint of a criticism of stack, and the first comment needs to be "well stack is better than cabal"? Come on. This kind of shill is really old and transparent by now.
The following on show the advantage of Haskell's lazy evaluation over strict abstract algorithm: ``` Prelude&gt; :set +s Prelude&gt; v4 = \s z -&gt; s (s (s (s z))) (0.00 secs, 0 bytes) Prelude&gt; snd = (\_ x -&gt; x) (0.00 secs, 0 bytes) Prelude&gt; :set +s Prelude&gt; snd v4 0 0 (0.00 secs, 63,888 bytes) Prelude&gt; snd (v4 v4) 0 0 (0.00 secs, 63,912 bytes) Prelude&gt; snd (v4 v4 v4) 0 0 (0.00 secs, 63,944 bytes) ``` I'm expecting the abstract algorithm to have exponentially bigger run-times. This *can* be solve by using lazy abstract algorithm. But then I'm worried about space-leaks.
SQL is *a* language to express relational algebra. It's not relational algebra itself. It's not like SQL is a fundamental aspect of the universe that we just discovered. SQL is a man made language with man made syntax that attempts to express concepts from relational algebra. There's no reason to claim it is the best one possible, and in fact it is updated and extended pretty regularly. The dead giveaway is that there is more than one flavor. PG and MySQL and MSSQL dialects are all attempts to express the relational algebra you're talking about. It's like you're arguing that Scala and x86 assembly are basically at the same level because it would be a major breakthrough in computer science if someone built a decent machine that didn't follow the von Neumann model. You don't have to revolutionize CS to make a dsl for SQL.
&gt;SQL is a language to express relational algebra Exactly. And any other language expressing it will be the same level of abstraction. &gt;SQL is a man made language with man made syntax that attempts to express concepts from relational algebra And if you want to claim there is another language that is a higher level of abstraction, then SHOW IT TO US. This is absurdity beyond belief. You may as well be claiming you know P=NP and we should just take your word for it. &gt;There's no reason to claim it is the best one possible, and in fact it is updated and extended pretty regularly. The dead giveaway is that there is more than one flavor. PG and MySQL and MSSQL dialects are all attempts to express the relational algebra you're talking about. That contradicts your claim, it does not support it. You clearly don't know anything about SQL. None of those dialects change the level of abstraction, they simply change syntax (and in the case of mysql leave out basic functionality). &gt;It's like you're arguing that Scala and x86 assembly are basically at the same level No, it is nothing like that at all. It is like pointing out the objective reality that identical abstractions are the same level of abstraction. Stop talking hypothetical bullocks and provide an example to support your claim. &gt;You don't have to revolutionize CS to make a dsl for SQL. You do to make a language that does everything SQL does but is more abstract. Why do you think you are smarter than every single CS research in the last 70 years combined? And why do you think you can casually mention this on reddit and not expect people to demand proof?
&gt;You don't have to beat relational algebra to beat SQL in ease of use as a language Ease of use is not the question. Simpler is. &gt;but it's not like SQL is the one true way to express relational algebra anymore than Matlab is the one true way to express linear algebra. Nobody suggested it was. You falsely claimed that the factually correct statement: "There's no way to make a complicated query any simpler by trying to use another language that compiles to SQL." is wrong. If you want to claim that is false, you need to prove it. Bad analogies to assembly are not proof, a language that compiles to SQL but is a higher level abstraction is proof. So cough it up. &gt;That doesn't mean that some dsl can't be written to make this less cumbersome to do, even if the computational complexity is no different. The complexity is precisely the issue at dispute. &gt;This is literally the entire idea behind programming languages in the first place. Again, trying to use bad analogies is simply dishonest. We're not discussing programming, we're talking about a non-turing complete language that exists purely to express and clearly defined algebra. &gt;I don't understand why you two are treating SQL like algebra itself rather than the language that it is. I am not. You are treating it like it is just some random ad-hoc programming language. You've made a lot of posts now, and keep ignoring the simple request to PROVIDE EVIDENCE. Repeating a lie is not productive. Prove it.
I wonder Backpack could be be useful when sharing code betwen server and client. My half-baked idea is that shared code would depend on a new abstract prelude that would be instantiated with Haskell datatypes on the server side and with Javascript datatypes on the client side. It would be impossible to share code that didn't use the abstract prelude, though.
Jesus Christ, guys. OP is asking how to express a query in an actual program that they are actually writing. Not for a formal proof that relational algebra is or is not the optimal way. The question is *absolutely* about ease of use. Why would someone ask about Yesod as a pretext for arguing about the fundamental mathematics powering SQL?
Let's see if I can give an example. So if you have `Alternative`, bag :: Weight -&gt; [(Item, Weight)] -&gt; Combinatorial [Item] bag maxWeight [] = pure [] bag maxWeight itemsLeft = do (item, wt) &lt;- itemsLeft guard (wt &lt; maxWeight) let items' = filter ((/= item) . fst) itemsLeft (item:) &lt;$&gt; bag (maxWeight - wt) items' Then, because of the presence of `empty`, we'd have to use a safer version of `minimum` that returned a `Maybe` value for lists, or modify our annealing functions to toss out branches that ending in no solution.
Stop with the red herrings. Nobody is talking about fundamental mathematics. You made a clearly false claim. You need to prove it. Put up or shut up.
I would like to continue to explain what I mean, but I clearly will never care about this as much as you care about protecting SQL as if it were math itself rather than a programming language.
This is a big downside of constraint-based solving: inaccurate bounds. However, constraint-based solving has upsides, too, so whenever I find myself in a situation like this, I try to resolve the build manually and then file patches to fix any inaccuracies. It's not too bad: - `cabal new-build -O0 --max-backjumps=-1 --reorder-goals` - Investigate build failure by reading changelogs of relevant packages - `cabal new-build -O0 --max-backjumps=-1 --reorder-goals --constraint="whatever &lt;= 4"` - Loop until success
I also said that it's pretty obvious that we're talking about different axes of "simpler.". But go ahead. I'm 100% certain this discussion is worth the effort.
According to [this paper](http://web.mit.edu/15.053/www/AMP-Chapter-13.pdf). A separable problem is one where the objective function and constraints can be expressed as a sum of univariate functions over the individual variables. The approach I presented here is not limited to separable problems, although the implementation of `Combinatorial` may be. For example, here are some non-separable problems nonsep1 :: Combinatorial Double nonsep1 = do x &lt;- domain [ 0 .. 100 ] y &lt;- domain [ 0 .. 20 ] pure (x * y) nonsep2 :: Combinatorial Double nonsep2 = do x &lt;- domain [0 .. 1000] y &lt;- domain [0 .. (x^x `mod` 10) ] pure (x `mod` y) There are some problems that'd be easiest to encode if we had an `Alternative` instance for `Combinatorial` representing an unsatisfiable branch. Perhaps this is something I'll get around to in the future. Nevertheless, if we restrict ourselves to using lists (which is a very reasonable Monad for our purposes), we can exploit it's `Alternative` interface to encode these problems. For example, to solve for the minimum of `sin(x) * cos(y)`, subject to x &gt;= 20, x &lt;= 100, y &gt;= 1, y &lt;= 20, and an arbitrary predicate `p` on `x` and `y` . reallyNonSep :: [ Double ] reallyNonSep = do x &lt;- [20..100] y &lt;- [1..20] guard (p x y) pure (sin x * cos y) You may object and say that this greatly complicates the simulated annealing search because neighboring solutions aren't necessarily going to be similar. This is true. However, annealing is a heuristic, only useful for certain problems. Other search methods are likely more appropriate for these tougher problems.
Where is this DSL? Show me. Just like OP, I want a simpler language to use. So stop saying it exists and show us. Don't claim you are trying to help and then keep refusing to help. 
If there are no DSLs that make it easier to work with SQL, why do people keep using them instead of just writing raw SQL?
I did not make the claim that you're arguing against. I have said this at least twice now.
Hope Ghcjs gets something similar to Bucklescript to produce optimized code.
&gt; like vtables, with the crucial difference that they are resolved at compile time Not always. Sometimes instance dictionaries are passed at runtime; you can see this in core output, they're usually named something like `$dShow`.
Yes you did. https://www.reddit.com/r/haskell/comments/8c61ac/how_can_i_make_this_the_best_work_with_yesod/dxctv1k/ Stop lying and support your claim. You said the statement is untrue. You then said there are lots of DSLs. So show me. Where is this DSL that demonstrates the "untrue" nature of the statement you said is "untrue"?
Welcome to Haskell! In the Haskell world, there currently are two ways of building packages: stack and cabal. They both try to fix this problem you've encountered, that of finding compatible versions of those hundreds of dependencies... and they both fail to build Twidge. It's a more difficult problem than you might think! The cabal way is to have each version of each package specify the range of versions of their dependencies with which they are compatible. Cabal then checks all the combinations in order to find a "dependency tree that actually works", which we call a "build plan". It does this by default, so: &gt; Is there a way I don't know about to tell cabal to build a dependency tree that actually works? There are two ways to build with cabal: `cabal build` and `cabal new-build`. They both automatically search for a build plan, but `new-build` searches harder. &gt; do I have to manually check and cross reference 100+ different dependencies and make sure the version I'm installing is friendly with everything else I have to install You don't need to manually search for a build plan, because cabal has already searched for a build plan. If the computer's search couldn't find one, your manual search is doomed to fail as well. --- Let's move on to stack then. The stack way is to simplify the problem by limiting our attention to a fixed set of packages. The authors of those packages agree to work together to make sure there exists a version of each of those packages which is compatible with all the other packages. Such a set of versions is called a "snapshot". There are many snapshots, each of which supports a different subset of packages, at different versions. Unfortunately, [twidge is not part of any snapshot](https://www.stackage.org/package/twidge). `stack init` asks stack to try a few snapshots, to see if it can find one which contains all the dependencies of twidge, but unfortunately [HSH is not part of any snapshot](https://www.stackage.org/package/HSH), and [neither is hoauth](https://www.stackage.org/package/hoauth). --- Okay, so neither cabal nor stack succeeds at finding a build plan. That's unfortunate, but it's not the end of the world: it just means we'll have to spend a bit more time to figure out _why_ they can't find a build plan. Let's look at `cabal new-build`'s error message: $ cabal new-build Resolving dependencies... cabal: Could not resolve dependencies: [__0] trying: twidge-1.2.0 (user goal) [__1] trying: hoauth-0.3.5 (dependency of twidge) [__2] trying: dataenc-0.14.0.7 (dependency of hoauth) [__3] next goal: base (dependency of twidge) [__3] rejecting: base-4.11.0.0/installed-4.1... (conflict: dataenc =&gt; base&gt;=3.0.0 &amp;&amp; &lt;4.8) [__3] rejecting: base-4.11.0.0, base-4.10.1.0, base-4.10.0.0, base-4.9.1.0, base-4.9.0.0, base-4.8.2.0, base-4.8.1.0, base-4.8.0.0, base-4.7.0.2, base-4.7.0.1, base-4.7.0.0, base-4.6.0.1, base-4.6.0.0, base-4.5.1.0, base-4.5.0.0, base-4.4.1.0, base-4.4.0.0, base-4.3.1.0, base-4.3.0.0, base-4.2.0.2, base-4.2.0.1, base-4.2.0.0, base-4.1.0.0, base-4.0.0.0, base-3.0.3.2, base-3.0.3.1 (constraint from non-upgradeable package requires installed instance) After searching the rest of the dependency tree exhaustively, these were the goals I've had most trouble fulfilling: hoauth, dataenc, twidge, base Since you're new to Haskell, those dependency names probably don't mean anything to you, but to me they are familiar enough that I can see the problem at a glance: twidge and its dependencies were written with an older version of ghc, for which a build plan exists, but you have installed a more recent version of ghc, and cabal cannot find a build plan which is compatible with it. Let's look at the [correspondence between versions of ghc and versions of base](https://wiki.haskell.org/Base_package#Versions): GHC version base version 7.8.4 (Dec 2014) 4.7.0.2 7.10.3 (Dec 2015) 4.8.2.0 8.0.2 (Jan 2017) 4.9.1.0 8.2.2 (Nov 2017) 4.10.1.0 8.4.1 (Mar 2018) 4.11.0.0 The `conflict: dataenc =&gt; base&gt;=3.0.0 &amp;&amp; &lt;4.8` bit says that the `dataenc` dependency expects a version of base older than 4.8, which means you need ghc 7.8.4 or earlier. It's a pretty old version, so instead of installing it globally, let's switch back to stack, which is capable of installing multiple versions of ghc without messing up with your global ghc installation. We need to jump through a few hoops in order to use both stack and cabal together: $ cat ./run-cabal.sh #!/bin/bash set -e # let cabal use its own package database, not stack's unser GHC_PACKAGE_PATH cabal new-build --dry-run $ stack --resolver=ghc-7.8.4 exec ./run-cabal.sh Build profile: -w ghc-7.8.4 -O1 In order, the following would be built (use -v for more details): - entropy-0.3.8 (lib:entropy) (requires build) - crypto-api-0.13.2 (lib:crypto-api) (requires build) - RSA-2.3.0 (lib) (requires build) - hoauth-0.3.5 (lib:hoauth) (requires build) - twidge-1.2.0 (exe:twidge) (first run) Cabal found a build plan which is compatible with ghc 7.8.4! Alternatively, now that we know what the problem is, we could try to use stack. According to [stackage](https://www.stackage.org/), the most recent snapshot for ghc 7.8.4 is "LTS 2.22", so let's use that and add the latest versions of HSH and hoauth: $ cat stack.yaml resolver: lts-2.22 packages: - . extra-deps: - HSH-2.1.3 - hoauth-0.3.5 Since those two dependencies aren't part of the snapshot, we aren't guaranteed that this will work. Typing `stack build --dry-run` fails with the suggestion of adding two more dependencies in `extra-deps`: - ConfigFile-1.1.4 - dataenc-0.14.0.7 And with that change, `stack build --dry-run` now finds a build plan as well!
How about development experience? Say I chose Miso for a Backend-Frontend Haskell app. How long does it take to compile my code incrementally? Do the Haskell IDE tools work for GHCJS?
I've had success with ghcjs and https://hackage.haskell.org/package/react-flux on some small projects. I haven't pushed it terribly, and certainly haven't benchmarked, but it seems to load and run fine on my (modern) phone.
My claim is that it can be *easier* to express what you want. Simple things like composibility of expressions and syntax absolutely matter in that case. Read OPs post. He is clearly not a SQL expert. A safer, easier to use language can make things that were previously too confusing to build correctly possible. For example, some people probably find it *easier* to express relational queries using e.g. opaleye than PGSQL. That doesn't mean opaleye is somehow not expressing relational algebra. Opaleye gives you a different language for expressing the same concept. Are we done?
Are you arguing that there are no relational algebra query DSLs in Haskell? Here's one, for example: https://khibino.github.io/haskell-relational-record/quickstart.html
If you wanna keep using stack, then check out https://github.com/Tehnix/miso-isomorphic-stack, which I've made tried to make so that one can use it as their first Haskell project even, with stack, hpack, hie wrapper and lots of VSCode goodies :)
Besides what Tayacan says, No Int is not a typeclass, it is a type. There is actually a constraint ~ which equates two types, so a ~ Int =&gt; a -&gt; a is a valid type. 
I am not arguing anything, I am asking you a simple question. You can tell from the "?" at the end. It is called a "question mark". So to answer your question, people don't keep using it. Almost nobody uses that, and the few people who do are doing it for type safety, which is the entire point of the library. That library does not allow you to express this query simpler than SQL. Now would you please stop trying to deflect and support your claim. Where is the DSL that allows you to express SQL queries simpler than SQL?
Yes please! 
I would suggest `traverse` / `for` over `mapM`. `mapM` has an unnecessary `Monad` constraint, and should probably be eventually deprecated.
This is pretty neat, I was wondering how to do this. Thanks!
The certificate was issued by Let's Encrypt, should be no effort to get a new one.
It seems like this should only work if a particular executable has been specified in the `stack.yaml`, rather than just picking the first one.
Sure. But that's mostly an implementation detail, and pretty much irrelevant for forming a useful intuition.
[removed]
I think it belongs here! (So do 18 upvotes and counting ...)
It seems to me that [optparse-applicative](http://hackage.haskell.org/package/optparse-applicative-0.14.2.0) is able to do what you want. (That is also what `optparse-generic` is using.) Is there some feature missing?
I want to present a DSL for a language that's far simpler than what optparse-applicative can parse. I hope that's clear from my description! On the other hand I'd be happy to use it as the back end. I couldn't see how to get it to do what I want though. That's one consequence of it being an extremely powerful languge.
I don't quite follow. It picks the first available executable in the `packages.yaml` file.
Just curious, is there a reason why the provided admin address from WHOIS differs from the actual admin address?
You're seriously trying to tell me that you think this horrible mess: import Data.Functor.ProductIsomorphic import Database.Relational hello :: Relation () (Int, String) hello = relation $ return (value 0 &gt;&lt; value "Hello") world :: Relation () (Int, String) world = relation $ return (value 0 &gt;&lt; value "World!") helloWorld :: Relation () (Int, String, String) helloWorld = relation $ do h &lt;- query hello w &lt;- query world on $ h ! fst' .=. w ! fst' return $ (,,) |$| h ! fst' |*| h ! snd' |*| w ! snd' main :: IO () main = putStrLn $ show helloWorld ++ ";" Is as easy to read, understand, debug, and maintain than the SQL it compiles to? SELECT ALL T0.f0 AS f0, T0.f1 AS f1, T1.f1 AS f2 FROM (SELECT ALL 0 AS f0, 'Hello' AS f1) T0 INNER JOIN (SELECT ALL 0 AS f0, 'World!' AS f1) T1 ON (T0.f0 = T1.f0); You're mistaking terseness with simplicity. Map is simpler than writing a for loop, but not because you write less code. This is not. On top of that, like all great SQL DSLs, I'm sure it only handles the database features the author knows about or worse, only the features that are common among all databases it claims to support. Does this thing support window functions, CTEs, lateral or full outer joins, or functions that return tables or sets (eg. [regexp_split_to_table](https://www.postgresql.org/docs/current/static/functions-string.html))? No? Don't worry, there's usually a "raw SQL" option, which usually ends up completely defeating the purpose of using such a library in the first place.
Could you please clarify this? My stack project consists of seven packages, two of which have executables. Typically I want to run the first executable of the last package. What would `stack run` do?
It runs the first executable it finds. You may need to specify the executable in your case with `stack exec`. `stack run` isn't meant to replace `stack exec`, it's merely a convenience command. Here's the part that finds the executable which it should run: https://github.com/commercialhaskell/stack/pull/3952/files#diff-f6aef6f8551ef69c947357fb3387ad22R842
I wrote this a while ago: https://github.com/blitzcode/ghc-stack It's a bit dated, but should hopefully give you the understanding required to work through these types of errors. Since then there has been support for generating DWARF debug symbols added to GHC, making debugging with standard tools easier.
If you run `stack init` it creates a bare stack project with a `stack.yaml` and a `package.yaml`. In the `stack.yaml` you generally define the resolver and extra deps and in the `package.yaml` you generally define your package attributes, dependencies, executables, tests etc. As long as stack is able to build your project, `stack run` will work as it uses the internal build mechanism to load the local packages and find the first executable: https://github.com/commercialhaskell/stack/pull/3952/files#diff-f6aef6f8551ef69c947357fb3387ad22R842
So... the first executable of the first package, is that correct? That's not very useful, since I list the packages in my `stack.yaml` more or less in the order they tend to get build. It's the last package that builds the final executable that I run.
`packages.yaml` or `package.yaml`? I've never heard of the first. The second is an optional per-package way of autogenerating `.cabal` files, so not all stack projects have them.
OK, that's not very useful. I think the executable to be run should be specifiable in `stack.yaml`.
One point I'd like to add. The article writes that: "It produced an different permutation than the rotation diagram, but one that shared the same property: iterate the process exactly n times on a set of n points, and you got back to your original order... Later, I started calling this type of permutation a plait." However, (I'm rusty, but I'm pretty sure this is true) it should follow from https://en.wikipedia.org/wiki/Cyclic_permutation#Basic_properties that all permutations on finite sets should have some periodicity after which they return back to their original ordering. (This is in fact the "order" of a permutation: http://mathonline.wikidot.com/the-order-of-a-permutation) 
And it seems they compile the submitted code without optimization. From the [FAQ](https://code.google.com/codejam/resources/faq#language-details), the compilation command line is: ghc +RTS -V0 -RTS -rtsopts -o Solution Solution.hs I emailed them suggesting they add `-O2`, but have not heard back.
The domain was originally bought by the Yale Haskell group back in the day. The administration of it was passed to Galois, which continues to hold it. However, the day-to-day administration of things on the domain, including subdomains, and the installation of certs on particular machines, etc. is handled by the haskell.org admin group. The administrative address provided by the whois information is contact-of-last-authority for the actual administration of the _domain name_ itself, and nothing else (which is what whois information reflects generally).
Nice detailed walk through of solving OPs problem :) 
One issue I've run into that idk if Backpack will solve: I'll have a shared type, but it has some instances that are backend-only or frontend-only. Right now, I just use CPP which feels less than ideal.
Gotcha! What is your precise definition of a plait, btw?
Nice - I've previously been using dmenu with a bunch of little shell scripts (created by arandr). This will be much nicer. Thanks
Why not newypes for each ...End?
And here we have the heart of the problem. You personally don't see why anyone would use anything other than whichever dialect of SQL you happen to think is best because you understand it and it does everything you think you want. Next.
I also [posted this](https://www.reddit.com/r/ProgrammingLanguages/comments/8cetkg/reimplementing_hacketts_type_language_expanding/) on /r/ProgrammingLanguages - hope that's ok!
Thanks for asking. I should go back and be more precise in my introduction. The initial idea I had in my head for a plait was as an extension of that diagram: _ X X X X ⋮ X X X X_ (`X` swaps the value at the position of the line above with the value of the line it's on, `_` is a no-op on the current line) So for an odd length finite sequence: a_0, a_1, a_2, ..., a_2n The plait would be a_1, a_3, a_0, a_5, a_2, a_7, ..., a_2i, a_{2i+5}, ..., a_{2n-6}, a_{2n-1}, a_{2n-4}, a_2n, a_{2n-2} And for an even length finite sequence: b_0, b_1, b_2, ..., b_{2n+1} The plait would be b_1, b_3, b_0, b_5, b_2, b_7, ... , b_2i, b_{2i+5}, ..., b_{2n-4}, b_{2n+1}, b_{2n-2}, b_2n --- At its essence, it's about partitioning the adjacent pairs of positions into two sets s.t. each position is in at most one pair per set. In the first phase, the swap the values of the positions paired in one set, in the next phase swap the values of the positions paired in the second set. Perhaps my inability to plait codata with an inifinite middle means I got my implementation wrong, as the above suggests that for any position: * in one phase, swap values with the prior position; if no prior position, no-op * in the other phase, swap values with the next position; if no next position, no-op Consider the following value, which makes `plait` explode: Pair (repeat 1) (Identity 0) :: Product [] Identity Int There is no position whose next position holds the `0`, so does that mean the position holding the `0` has no prior position? And so plaiting it should be a no-op? I need some better definitions. --- A looser definition for plait I'd be cool with would be any permutation that scales to arbitrarily long sequences that only moves individual values at most a constant amount, yet results in a hamiltonian cycle.
&gt; I never made any of those claims. Pay closer attention to what you're replying to next time. This is the last time I respond to you. You don't know how to discuss something in good faith and without belittling your counterpart. It's just not necessary. I disagree with the second paragraph. One might know how to express something in Sass or LESS but not how to create it from scratch in CSS. In such a scenario, yes LESS or Sass or whichever language you're familiar with is indeed going to help you. Is that great? That depends. If you ever run into a situation where Sass or LESS *can't* express what you need then you're boned. Otherwise it likely doesn't matter at all. The same is true of SQL. SQL is not feature complete. Things are added to it all the time. If you knew how to write query plans natively then you might be able to work around difficulties in the language itself, but for the rest of us, we must wait for our higher level language (SQL) to adopt it. &gt; Also, SQL is a DSL, it just happens to be a very verbose one. I have been saying this the entire time. It is (one of many) languages that attempt to express relational queries. Additionally, some people obviously find it preferable to use a *different* DSL sometimes, even when SQL might be better at it in the hands of an expert.
Fun toy project that I hacked on Friday afternoon. Once again butting up against how fiddly System.Process is, so I'm starting to get motivated to create a streaming variant of this use-case. Any interest?
I asked this on #haskell, but nobody knew of any options, so this I'll ask again here too! I've been building a little program for running a bunch of processes and showing their output nicely interleaved similar to how docker-compose does things: https://github.com/sordina/logody#logody (posted to /r/haskell today!) Everything is working okay, but once again I'm butting up against just how gnarly System.Process is. Is there a better library for creating processes and aggregating their outputs, including stdout/stderr/exit-codes etc? I'd love to do something like: ``` let ps = map createSource processDefinitions pipeline = multipleSources &gt;&gt;&gt; formatter &gt;&gt;&gt; printer results &lt;- run pipeline output results ``` I know there's turtle, but is this still a good choice? I had a look at Conduit's support, but it seems to be more about allocating conduits for each handle, not aggregating. I might be missing something. Happy to go with any of the streaming libraries if they make this nice, but it's not obvious and I've dealt with System.Process directly way too many times now: https://github.com/sordina/logody/blob/master/src/Main.hs#L193 Thanks! 
That is a tiny little package and who does not like 2 function packages. Was wondering if there is a smaller package which does something non-trivial.
Works!
Thanks!
Haha! I was just about the write this and then I saw your edit. ./Stargazer --x86 --stack --tool --target Install {tool_ = Stack X86, packages = []}
Haha! I was just about the write this and then I saw your edit. ./Stargazer --x86 --stack --tool --target Install {tool_ = Stack X86, packages = []}
Haha! I was just about the write this and then I saw your edit. ./Stargazer --x86 --stack --tool --target Install {tool_ = Stack X86, packages = []}
I'm honestly curious: What's the advantage of using this over regular bash script?
I'd be interested to know what you found fiddle about System.Process. I recently revisited it and found `readCreateProcess` and family quite convenient. I did think about a streaming version though (presumably with stdout and stderror interleaved).
This is of course possible in a regular bash script. But it would be a fairly large and brittle one once you had a large list of programs, especially when you wanted to update their restart behaviour etc. I'm not sure if it really has much utility for anyone, but when I first used Docker-Compose I thought that it was quite nice how it managed all of the containers and presented their events and output and wondered if there was anything similar for regular programs. Not that I could see!
I used `gdb` to debug a segfault and it helped me.
There is https://hackage.haskell.org/package/typed-process library which is a very thin layer on top of `process` library to make it a bit safer &amp; more convenient to use.
Doesn't need to be higher rank: data Weird a = Nest (Weird (Weird a)) (Weird (Weird a)) | Dona a If you construct one in a recursive function then the type changes for each iteration and a type class dictionary would have to be build as you go along.
Even if typeclasses were always resolved fully at compile time, the motivation for the monomorphism restriction would be the same.
https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/join-points.pdf does not work for me.
This looks a fair bit nicer!
https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/join-points-pldi17.pdf
thx 
I never said any of that. Strawman less. You've been trying to argue "ease of use" this entire time because you don't understand that "simplify" means something entirely different and you bring me this horrible monstrosity that is not easier to use by any stretch of the imagination. There is no "best" dialect of SQL. You can't separate SQL dialect from the RDBMS that supports it because a lot of the differences in dialect are due to features that are unique to the RDBMS. There's no way to patch the SQL engine to add support for window functions on MySQL because the database fundamentally does not have the underlying code to support it. No one chooses a database because they really really like the dialect of SQL that comes with it. Seriously, stop trolling and provide an example that supports your claims.
On-topic-ness (on-topicality?) notwithstanding, I really enjoyed reading this! You did a great job of defining the problem and bringing non-Lispers like me along with you. Great work!
Could you elaborate on how those fake leaks would happen? My evaluator is lazy so obviously it has no problem with that program: ``` @v4 #f #x /f /f /f /f x @snd #t /t #a #b b /snd #t //t //v4 v4 v4 0 #a #b #b - time : 0.052s - loops : 15 - rewrites : 4 - dupls : 0 - annis : 4 - betas : 4 ``` And as soon as it completes, it garbage collects every unreachable memory, so there is obviously no leak in this case. I'm just not sure how it could have leaks after a garbage collection.
Your demo uses "logdog" instead of "logody". I like the name "logdog" much better!
Linking back to the original would be nice: https://typelevel.org/blog/2018/04/13/rethinking-monaderror.html
I think the advantages would be much clearer if you added a list of feature to your README. Docker-compose does a lot of things, and logody only supports a small subset of what docker-compose does, so it's easy to look at the demo and assume logody supports an even smaller subset than it really does. The first time I say the demo, I saw two features: 1. logody runs a shell command, and prints some extra metadata in addition to the shell command's output 2. you can save a bunch of shell commands to a yaml file and execute a subset of them Neither feature seemed very enticing TBH. It is only now that you're talking about restart behaviours that I took a closer look at the demo and at the example at the bottom of the README, and I now think that logody's feature list is as follows: 1. runs several programs in parallel, annotating each output line with the program which produced it and with whether the output is from stdout or stderr. Each program's exit code is also printed. 2. optionally, each program can be configured to be automatically restarted after they complete, or only when they complete successfully, or only when they fail. 
While Artin groups are cool, it seems like what you really are thinking of is something much simpler. The cycles of length n in S_n are exactly the conjugates of the cycle (1 .. n). If n is prime, then these are all the elements of order n in S_n. If n is composite, then there are non-cycles that have order n - they are products of disjoint cycles such that the least common multiple of the lengths of the cycles is n.
`UIO` can still crash with async exceptions so I'd say that saying it's somehow "safe" or "exception-free" is a lie. Also, here's some code that seems to do what you propose without changing the MonadError class: f :: MonadError Int m =&gt; m () f = throwError 5 g :: MonadError Int m =&gt; m () g = catchError f (\i -&gt; throwError (i + 1)) -- catch via catchError and re-throw h :: Monad m =&gt; m Int h = do -- catch by running the computation as ExceptT, explicitly handing that -- transformer layer and discarding the `MonadError` constraint of the -- original function e &lt;- runExceptT f case e of Left i -&gt; return i Right () -&gt; return 0 I'd say the function you're looking for is `runExceptT :: ExceptT e m a -&gt; m (Either e a)` and as you can see it does explicitly change the type of the monad. Of course that doesn't work with `IOException` since you have no guarantee the exception will be thrown with `throwError` instead of `throwIO`, but that's fine because you can't guarantee that you caught all the `IOException`s anyways. With this interface you have the ability to statically prove no "pure" exceptions can be thrown and you still get the `catchError` function to handle the IO ones. 
I'm the author of both, so I figured it was fine :)
How does GHC know what to inline? For example, why doesn't it inline the y combinator `Y f = (x. f (x. x) (x. f (x. x))` ?
This capability was recently added to persistent. It was discussed in [this issue](https://github.com/yesodweb/persistent/issues/778) and a [linked discussion](https://github.com/naushadh/persistent-examples/tree/master/model-organization), including benchmarks, and added as a feature in [this PR](https://github.com/yesodweb/persistent/pull/791). It was released in what is currently the latest version of [persistent-template](https://hackage.haskell.org/package/persistent-template), version 2.5.4. To see how to use it, look at the haddock documentation for the function `persistManyFileWith`. Make sure to expand the "Examples" section.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [naushadh/persistent-examples/.../**model-organization** (master → 0dc7449)](https://github.com/naushadh/persistent-examples/tree/0dc74499cb2752973d1e8739894371889a0b1d84/model-organization) ---- 
I've had almost exactly the same issues. The documentation for `System.Process` is also not very helpful in pointing out how, if possible, `System.Posix.Process` can be used to get more features.
Is there a way to get GHC to output stuff like discharging: Eq (Int, c) try: Eq Int --&gt; does not match try: Eq (a, b) --&gt; matches remove `Eq (Int, c)` pred match types: a ~ c b ~ Int discharge: Eq Int discharge: Eq c discharging: Eq Int try: Eq Int --&gt; matches remove `Eq Int` pred discharging: Eq c try: Eq Int --&gt; does not match try: Eq (a, b) --&gt; does not match keep `Eq c` pred This would be useful when debugging "can't do X arising from Y" when X isn't even mentioned anywhere in the expression Y.
&lt;rant&gt; Am I the only one in thinking that a well-designed library shouldn't need explanation blogposts written by expert third parties? `diagrams` contains a beautiful tower of abstractions (and is indeed very powerful) but it's absolutely exhausting to use for a beginner.
Things would be a lot better if we could provide custom type errors in ambiguous situations. 
Not sure! Maybe [one of the flags on this page?](https://downloads.haskell.org/~ghc/7.6.2/docs/html/users_guide/options-debugging.html) I tried `ddump-tc` and `ddump-ds` to no avail, though.
Yep, that was my first choice, taken :(
You did read that this was a Friday afternoon toy didn't you? Your criticism seems quite harsh. But, the docker-compose comparison is without a doubt aspirational. I'd love to add more of the features here. Obviously any of the ones relating to containerisation are out, networking is questionable, but there could be a good usage of the volumes, environment variables, etc potentially.
I think it's fine to have both easy-to-understand but restricted libraries and powerful but harder-to-understand libraries. If we can make a library which is both powerful and easy to understand, than that's even better; but if we can't, whatever, that's fine too.
My apologies, I did not mean this comment as a criticism! And I'm certainly not saying that logody should be more like docker-compose. Rather, I'm saying that I think logody in its current state has features which weren't immediately apparent to /u/eckyo and I, and so I am suggesting to add a list of features to your README. I even wrote down such a list in a way which I think would help newcomers to the project such as myself to better understand the value which logody brings. I'm not complaining about logody, I'm trying to contribute to it by improving the documentation!
You can fake it a *little* bit with `Symbol`s: λ data Tagged (a :: k) b = Tagged b λ type Input = Tagged "OMG What did you do?" λ f :: Input Int -&gt; Int ; f = undefined λ f (Tagged 'a') &lt;interactive&gt;:9:4: error: • Couldn't match type ‘Char’ with ‘Int’ Expected type: Input Int Actual type: Tagged "OMG What did you do?" Char • In the first argument of ‘f’, namely ‘(Tagged 'a')’ In the expression: f (Tagged 'a') In an equation for ‘it’: it = f (Tagged 'a') 
Has this example project been posted somewhere? It would be very helpful. Thanks!
There's also "process-streaming" by yours truly.
Or perhaps `(exists a. Num a =&gt; Dict (Num a))`
I also wish for such a feature!
I'm sure more would be welcome on there too! :)
Thanks! One of the features is "Kill all processes easily with Ctrl-C", but I don't see that in the code; you're not using `terminateProcess ` nor `withCreateProcess`. Are you sure you're not just killing the threads which print the output of the processes, but not the processes themselves?
Looks nice!
Thanks for this! As a fellow xmonad user, who moves around during the day, this is perfect!
No, but I also think we're seeing type families become so popular (and simplify so many typeclasses without the intimidating functional dependency syntax) that we need to get pretty serious about documenting those correctly and improving the way they're automatically documented. This challenge will only get bigger over time as type level hacking and backpack-level module hacking become more common. We need to get better at explaining it. I certainly only understood this pattern because I slogged through understanding it with `recursion-scheme`'s `Base` functor and immediately recognized the pattern. 
It looks like the functional dependencies mean `Identity` is now forbidden to other instances of MonadBlunder as the error-free type. That feels not great, but maybe it's not actually a problem in practice? Or am I misunderstanding?
Sorry, no :( My backlog on personal-projects has become kinda huge
&gt; In general, it must be either a problem with C code or with unsafe/primitive functions. One possibility that's arguably not quite either of those is if some C code provided by a library is not thread-safe. In that case you'll probably want to be sure it's only interacted with from a single, bound thread (http://hackage.haskell.org/package/base-4.11.0.0/docs/Control-Concurrent.html#g:8).
You're right, probably need to get rid of that constraint and just have f -&gt; g, f -&gt; e. Thanks for pointing that out :)
That looks like it should do the trick, thanks! Although I will say it's a somewhat surprising approach that it's via external non-Haskell files. How are imports dealt with when I use non-Prelude data types? Also it seems like this prevents me from taking advantage of Haskell's module system, as I assume I will now have to import everything from the same module, and I also assume there is no way to drop the prefixes and use modules for name disambiguation.
It wouldn’t be *entirely* the same motivation, it’d be [about half the same](https://www.haskell.org/onlinereport/haskell2010/haskellch4.html#x10-930004.5.5).
Right, it should have a big disclaimer. It's important to stress that they are are different in practice. OO interfaces come along with inheritance, so they're used mainly for dynamic dispatch on a hierarchy. In Haskell, you use data with multiple constructors for that. Typeclasses let you have functions that work on intersections of types that share properties. It's more like the narrower case of what you'd use multiple inheritance for, except Haskell can constrain on multiple interfaces at once. Actually the closest practice in a popular language I can think of is C++ templates calling overloaded free functions, but those constraints are all implicit.
How can I use that for models/tables defined in dependencies of my project, since their location (`FilePath`) will be pretty non-trivial to figure out?
ReadP was developed in the dark ages of 2002. It looks like ReadP.optional = () &lt;$ Applicative.optional and therefore I would be in favour of retiring `ReadP.optional`.
Frankly dependent types scare me, so they can take as long as they want. 
I'm afraid I cannot condone the message of this comment, even though it did make me [chuckle](https://i.imgur.com/vVkoPPU.gif).
How is it different from [interpolate](https://hackage.haskell.org/package/interpolate)?
Or a phantom parameter. Orphan instances in -end specific code is another possibility, though not sure it's better than CPP.
Can't be as scary as the singletons code I'm writing!
`PyF` is a super set of interpolate. The example: [fString|Hello {name}, you know that pi rounded to two digits is {pi:.2}? But did you know that 120 times 2 == {120 * 2:#b} == {120 * 2:#o} == {120 * 2:#x}?|] Will be written (roughly, not tested) like that in interpolate: [i|Hello {name}, you know that pi rounded to two digits is #{Numeric.showFFloat (Just 2) pi}? But did you know that 120 times 2 == 0b#{Numeric.showIntAtBase 2 (\x -&gt; if x == 1 then '1' else '0') (120 * 2) ""} == 0o{Numeric.showOct (120 * 2) ""} == 0x{showHex (120 * 2) ""}?|] So, if the available formatting options are OK for you, then `PyF` is great, else, interpolate will do the same, but you need to write all formatters by yourself. Most of the time, I need binary/hexa representation, padding and float representation with a fixed number of digits. All of this can be easily done in PyF. For example, the following, rather contrived example: *PyF Numeric Data.Foldable&gt; for_ [0..16] $ \i -&gt; [fIO|{i:&gt;2}: Binary: {i:_=#7b} Octal: {i:_=#4o} Hexa: {i:_=#4x}\n|] 0: Binary: 0b____0 Octal: 0o_0 Hexa: 0x_0 1: Binary: 0b____1 Octal: 0o_1 Hexa: 0x_1 2: Binary: 0b___10 Octal: 0o_2 Hexa: 0x_2 3: Binary: 0b___11 Octal: 0o_3 Hexa: 0x_3 4: Binary: 0b__100 Octal: 0o_4 Hexa: 0x_4 5: Binary: 0b__101 Octal: 0o_5 Hexa: 0x_5 6: Binary: 0b__110 Octal: 0o_6 Hexa: 0x_6 7: Binary: 0b__111 Octal: 0o_7 Hexa: 0x_7 8: Binary: 0b_1000 Octal: 0o10 Hexa: 0x_8 9: Binary: 0b_1001 Octal: 0o11 Hexa: 0x_9 10: Binary: 0b_1010 Octal: 0o12 Hexa: 0x_a 11: Binary: 0b_1011 Octal: 0o13 Hexa: 0x_b 12: Binary: 0b_1100 Octal: 0o14 Hexa: 0x_c 13: Binary: 0b_1101 Octal: 0o15 Hexa: 0x_d 14: Binary: 0b_1110 Octal: 0o16 Hexa: 0x_e 15: Binary: 0b_1111 Octal: 0o17 Hexa: 0x_f 16: Binary: 0b10000 Octal: 0o20 Hexa: 0x10
I'm hoping dependent types end up relatively unobtrusive in Haskell. I'm glad that I'll have the option to use dependent types where I personally want to, but I really wouldn't want it becoming a ubiquitous requirement in Haskell. Regardless, it'll certainly be simpler than a lot of the crap we do today to work around the lack of it.
We already have them in many ways. They're much scarier without proper support IMO.
I have seen activity on various issues related to dependent types in the [ghc-proposals repo](https://github.com/ghc-proposals/ghc-proposals/), over the last few weeks and as recently as today. I guess there's just a lot of details to discuss, and that none of it is interesting enough to make it onto this sub.
[removed]
I would support a change to either rename it as you have suggested or to remove it outright. Duplicate identifiers are a source of confusion for users. As a sidenote, you could probably skip the reddit query and just go straight to the GHC issue trac, which is where suggestions for base are presented. Often, you will get punted over to the mailing list, but this ends up creating a better history of the proposals discussion. There are discussions on GHC Trac issues that span months (in some cases, years or even a decade). By contrast, anything discussed on Reddit is nearly undiscoverable after a month or two, Plus threads get locked after a certain period of time, so the discussion can’t continue anyway. I say this as someone who has made a few small contributions to base and core libraries. It took me a while to realize that I was pouring a lot of my best arguments into a place that would obscure them over time. Sometimes, suggestions just take a while to get hashed out, and Reddit’s not great at handling a while.
One option is to have a beautiful tower of abstractions, but then export an `Easy`/`Simple` module that monomorphizes things more, perhaps with a single concrete ADT that you build up and then "run". You could even have a separate package for an easy and beginner friendly interface that uses the more complicated tower under the covers without exposing them to the user. Then beginners can be recommended to use `blah-simple` instead of `blah`, or something on those lines.
Hopefully we can start to think about much better tooling for mechanically generated documentation. For example, module-level interfaces have such a massive impact on how someone can use them (you need to resolve them before you can even build them), it probably makes sense to have a section at the top level of the docs, above the modules list ,that calls them out. That'll also gently encourage people to keep that number small, as it'll render their documentation unreadable. :)
What I meant by "intrusive" was that I hope that dependent types permeate all our important libraries to the point that using Haskell for any nontrivial project requires extensive use of dependent types. Good documentation doesn't make that ok, because dependent types are still sort of a Next Level thing compared to the Haskell 2010 type system, which is already kind of a Next Level thing compared to what most programmers are used to. I don't think you should have to understand this many levels to do anything nontrivial with Haskell as a beginner / intermediate, so I hope dependent types don't intrude on those people's paths too aggressively.
Ah, well I agree. But as someone who is certainly not your equal in the world of haskell, I found myself immediately productive in Idris. After a short period of time I started to feel more *confident* there too. So my contribution to the pile of samples is that DT makes life easier, not harder. Dependent types give you a lot of ways to just bail out of any given architectural hole you might have made for yourself in a way Haskell, with its more principled requirements, do not. Of course, you pay for it with crazy compile times. 
http://video.s-inf.de/#FP.2005-SS-Giesl.(COt).HD_Videoaufzeichnung 2005-SS-FP.V01.2005-04-12.HDV 2005-SS-FP.V02.2005-04-13.HDV
Maybe this is helpful? {-# LANGUAGE NoImplicitPrelude #-} import Rebase.Prelude import Codec.Picture (DynamicImage (..)) import Diagrams (mkWidth, renderDia) import Diagrams.Backend.Rasterific (Options (RasterificOptions), Rasterific (Rasterific)) import Graphics.Rendering.Chart.Backend.Diagrams (defaultEnv, runBackendR) import Graphics.Rendering.Chart.Easy (Renderable, bitmapAlignmentFns) renderToDynamicImage :: MonadIO m =&gt; Double -&gt; Double -&gt; Renderable a -&gt; m DynamicImage renderToDynamicImage width height renderable = do env &lt;- liftIO $ defaultEnv bitmapAlignmentFns width height return $ ImageRGBA8 . renderDia Rasterific (RasterificOptions (mkWidth width)) . fst . runBackendR env $ renderable 
Oh my god! Thank you for the helpiest help anyone on a tech reddit has ever helped! I think I'm ALMOST done but. . . when it's building hoauth, I now get src/main/haskell/Network/OAuth/Consumer.hs:188:78: Not in scope: `R.ha_SHA1' Perhaps you meant `R.hashSHA1' (imported from Codec.Crypto.RSA) I gather that GHC thinks a variable in hoath is not properly registered. I googled for this error and found a report in twidge. I'm looking over the hoauth code and I'm curious why something like this would successfully build for some and not others.
Also on a side note, do you know why foreign key constraints are not created when you do things the way I originally did it? It would be very convenient for that to work out of the box, and it looks like I'm going to have to add a bunch more code and files to have the foreign key constraints work.
That makes sense to me. Code switching over to the more powerful one from `Applicative` should work out of the box in most situations, and would at worst need an extra call to `void` in a few places to suppress the remaining warnings.
Thank you for the example! A little bit of tinkering and I got my code working.
I never thought that I would need both backends to perform such a conversion. Thanks!
I think that the question "when are dependent types coming to Haskell" raises more priority questions like "do we even want dependent types in Haskell?" and "would Haskell still be Haskell with (full-on) dependent types?"
Updated to use withCreateProcess
I think you might have (re)invented datasort refinements: Some references: https://www.cs.cmu.edu/~fp/papers/pldi91.pdf https://arxiv.org/abs/1701.02842
There is the so calle Carmacks law, which states that over time and given sufficiently large project, all features of language get used in all ways. This means that, no, you can't opt out, because eventually, you will depend on some library that will use dependent types and which will force you to use them as well. Proof writing for everyone!
You might enjoy this 1999 [paper by the Simons on GHC's inliner](https://www.microsoft.com/en-us/research/wp-content/uploads/2002/07/inline.pdf).
It's not quite Haskell, but Elm has given me more enjoyment out of pushing pixels than any other environment.
Here's a good summary of how the inliner works in general: http://mpickering.github.io/posts/2017-03-20-inlining-and-specialisation.html ---- Back to your example, that's a tricky one, and indeed GHC does _not_ know that it shouldn't be inlined. This is documented in the user guide: http://downloads.haskell.org/~ghc/latest/docs/html/users_guide/bugs.html#bugs-in-ghc In order to try it for ourselves, we need to tweak it a little bit. The `(x x)` application is problematic, because it would produce an infinite type, and Haskell's type system doesn't like that. Instead, we can encode this via isorecursive types newtype Mu a = Roll { unroll :: Mu a -&gt; a } with `Roll` and `unroll` witnessing the isomorphism between a type and its expansion. Now we can write y :: (a -&gt; a) -&gt; a y f = (\x -&gt; f ((unroll x) x)) (Roll (\x -&gt; f ((unroll x) x))) And this indeed typechecks, however, when we compile, we get an error: "Simplifier ticks exhausted". According to the user guide (linked above), this problem occurs only in a rare class of contrived examples. 
Looks awesome. Can't afford it this year, unfortunately, but I do hope I can be there next time.
This is some perfect timing. I've been fighting a similar issue, fight down to the 2.6 era kernel. Thank you for sharing.
We have some amount of scholarships available, you can always mail us with your situation and see what we can do :)
Thank you, I'll send an email asap then!
Dependent types will not *require* anything existing to change. It will allow some things to become simpler and easier to understand - I think those kinds of changes will gradually spread through existing libraries. And it will allow some new things that are powerful but complex - I expect to see those in new libraries, or as new separate features in existing libraries.
/u/tomejaguar, since you've [asked](https://www.reddit.com/r/haskell/comments/89uk5u/are_there_people_here_who_are_interested_in/dwubfjt/) &gt; Please report back how this goes! It would be really interesting to find out. I'm pinging you here to make sure you see the post. 
If we want to give this function a name, `optional_` seems obvious to me.
&gt; Proof writing for everyone! Could you perhaps elaborate to us the specifics of this much-quoted "problem" with implementing full dependent types in Haskell? Not only will the features designed by /u/goldfirere be opt-in (just like type-families, GADTs, type-applications, and other approximations of dependent types we currently have available), writing code in a strongly-typed language is already a form of "proof writing", depending on how you would like to defined that (Curry-Howard isomorphism, and all that jazz). What do you mean by this statement?
Haskell apps I've used take very little time to respond to requests (&lt;10ms), and I wanted something dead simple for the UI side (I also do not need any UI fanciness). So I went with good 'ol server side rendering using Yesod. No matter what JS rendered UI approach one uses, there will be overhead: * You have to manage state and routing both on the client and on the server (part of it is shifted from server to client, and part is extra/double) * The conveniences of using a browser are thrown out, and you have to implement that yourself, like back/fwd buttons w/ scroll position remembering and w/ refilling form fields When I really need some in-page updates I use *cough* jQuery, but it's only in very few places, and works like a charm for these very local use cases.
And, as someone who spent two days trying to work it out recently, is phenomenally beginner hostile.
Wow this is exactly what I was looking for a few days ago. We're running scientific linux 2.6 and I need to build some haskell projects. THANKS!
From the description in YouTube (link to video downloads): http://video.s-inf.de/#FP.2005-SS-Giesl.(COt).HD_Videoaufzeichnung Other options: (2012) https://video.fsmpi.rwth-aachen.de/12ss-funkprog (2005) https://video.fsmpi.rwth-aachen.de/05ss-fp 
&gt; Dependent types will not require anything existing to change. No, but my point was that libraries adopting DTs aggressively will require things to change. I'd rather not see DTs become an integral part of our library ecosystem, because that would likely be a step too far out of the league of newcomers coming from other languages.
The Python ecosystem provides great examples of this approach. Complex modules often contain a function or several that handle the most common use-cases with one call, and a lower level object-oriented API. For example, [`subprocess`](https://docs.python.org/3/library/subprocess.html) has a `run` function for running a command and the `Popen` class for more customizability. The `requests` module has a [main interface](http://docs.python-requests.org/en/master/api/#main-interface), [lower-level classes](http://docs.python-requests.org/en/master/api/#lower-level-classes) and [lower-lower-level classes](http://docs.python-requests.org/en/master/api/#lower-lower-level-classes).
Thanks!
I think I know what's happening. Remember when I said that "the cabal way is to have each version of each package specify the range of versions of their dependencies with which they are compatible"? Well, if cabal found a build plan but executing that plan results in a compilation error, that must mean that some package A is incorrectly specifying a range of version for a dependency B which incorrectly includes a version of B with which A is not compatible. This is what /u/MitchellSalad's comment is about: what to do when one of the packages you are compiling has inaccurate version bounds. In this case, `R.ha_SHA1` is qualified by an `R`, which means it has to come from one of the two modules which are imported "qualified as R" at the top of the file: import qualified Codec.Crypto.RSA as R import qualified Crypto.Types.PubKey.RSA as R Googling for both "Codec.Crypto.RSA ha_SHA1" and "Crypto.Types.PubKey.RSA ha_SHA1" reveals that it comes from the first module and that this module is part of the RSA package: https://hackage.haskell.org/package/RSA-1.0.6.2/docs/Codec-Crypto-RSA.html#v:ha_SHA1 The version google found is RSA-1.0.6.2, but as you can see in the output of `cabal new-build --dry-run` in my previous comment, cabal picked RSA-2.3.0 instead. And if we look at the Codec.Crypto.RSA page of that version of the package: https://hackage.haskell.org/package/RSA-2.3.0/docs/Codec-Crypto-RSA.html We find... that it re-exports the contents of the Codec.Crypto.RSA.Exceptions module, okay, so let's look at the page for that module: https://hackage.haskell.org/package/RSA-2.3.0/docs/Codec-Crypto-RSA-Exceptions.html And we find that this page does not export a symbol named ha_SHA1, but that it does export a symbol named s a symbol named [hashSHA1](https://hackage.haskell.org/package/RSA-2.3.0/docs/Codec-Crypto-RSA-Exceptions.html#v:hashSHA1); hence ghc's suggestion that `Perhaps you meant `R.hashSHA1'`. Clearly, RSA's API changed in a backwards-incompatible way at some point (at version 2.0.0, I'm guessing), and hoauth is still using the 1.x API. So cabal should have picked a build plan involving RSA-1.x, but it didn't, so hoauth must incorrectly [specify a version range which includes RSA-2.3.0](https://github.com/dgvncsz0f/hoauth/blob/master/hoauth.cabal#L32): ... , RSA&gt;=1.2.0.1 ... That is, hoauth claims that it is compatible with RSA-1.2.0.1 or above, but we know that's not true. It should instead say that it is compatible with RSA-1.2.0.1 up to but not including RSA-2: ... , RSA&gt;=1.2.0.1 &amp;&amp; &lt; 2 ... You can ask cabal not to pick RSA-2 or above: cabal new-build --constraint="RSA &lt; 2" Or you can download the source for hoauth, make the change above to its `hoauth.cabal` file, and then create a `project.cabal` file pointing to the folders containing the twidge and hoauth sources: $ cat project.cabal packages: ., ../hoauth and then ask cabal to build both with `cabal new-build all`. Or, using stack, you can try to build using the same snapshot as before, except with RSA-1.2.2.0 and your local copy of hoauth instead of the versions from the snapshot, by modifying your `stack.yaml` file: $ cat stack.yaml resolver: lts-2.22 packages: - . - ../hoauth extra-deps: - HSH-2.1.3 - ConfigFile-1.1.4 - dataenc-0.14.0.7 - RSA-1.2.2.0 If your build succeeds with those changes, I encourage you to send a pull request to the hoauth project, so that future users don't have to repeat the work we did today and can simply rely on cabal to find the correct version of RSA.
&gt; Suppose for a moment that type constructors were considered nominal subtypes of the type they constructed Try Scala, that's exactly how they implement algebraic data types!
I'm trying to build something like that. A haskell like language that compiles to OpenCL.
interesting. any specific use case in mind?
You could compose it like this: map ((`mod` 12) . (root +)) node. However, I would just write a lambda function like this: map (\x -&gt; (x+root) `mod` 12) node
Awesome work. Can you explain a bit more about the shortcomings of this approach (i.e. "nowhere near as smooth and interactive ..")? I mainly thought about the semantics I would want from such a language, and figured that with enough type information and carefully chosen set of primitives, the optimization could produce efficient enough code (of course, I may be completely wrong about this)
Here's a pretty simple version: scale root mode = map f mode where f x = (x + root) `mod` 12
You're missing a starting parentheses in your first example ;)
&gt; Awesome work. Can you explain a bit more about the shortcomings of this approach (i.e. "nowhere near as smooth and interactive ..")? Well, it's pure for one, and the data scientists I know seem to like using various impure hacks, especially for interactive use. It is also a distinct programming language, so everything has to be built from scratch (for example, there is no debugger yet). &gt; I mainly thought about the semantics I would want from such a language, and figured that with enough type information and carefully chosen set of primitives, the optimization could produce efficient enough code (of course, I may be completely wrong about this) If you want efficient code, the key is what you *don't* support. Many of the things we take for granted in functional programming (lazyness, higher-order functions, even sum types) provide obstacles to efficient execution. Of course, it depends on what you consider "efficient". Languages like Haskell and OCaml show that you can support these features and still get decent (sequential) performance on CPUs. Optimizers are *difficult* to write, especially if the language they are trying to optimize is not built to help the optimizer.
Thanks for your help. I will experiment with both ways.
Could you produce a minimally-breaking example ?
This actually makes sense to me and it works, thanks!
1. One thing I was annoyed with using IPython, is that the lack of purity makes the order of evaluation of cells important. I was finding myself thinking my program works only to find it broken after restarting the kernal. 2. I was thinking laziness would be beneficial to performance until we reach the primitive array operations (which of course would be strict). I would restrict data types to not contain functions. I think such algebraic data types could be efficiently paralelized by squashing them into a flattened representation of fixed length (if that's too big you can maybe chop it up into parts). I guess there's plenty of research in that area, no?
I fully agree with your rationale and had similar thoughts in the past, however it's a lot of work that requires a concerted effort at the very least. Do you know about datahaskell.org ? 
It's definitely not a simple undertaking. Though my idea was to just synthesize already existing ideas into one language rather than to reinvent the wheel. Have not heard of data Haskell, looks cool, I'll definitely look into it.
If I'm using the Aeson library, I can use generics to make my types instances of ToJSON and FromJSON : {-# LANGUAGE DeriveGeneric #-} import GHC.Generics data Person = Person { name :: Text , age :: Int } deriving (Generic, Show) instance ToJSON Person instance FromJSON Person This works great as long as I am defining the types myself in my own library. However, sometimes I may want to use a type defined in another library that doesn't support Generics. I don't believe Haskell allows me to define instances for the types in a different library (or at least I get errors when I attempt it). I end up writing new types which basically mirror the types in the other library, which is crude, but effective. Is there a better way to handle this situation? 
I honestly thought this was some advanced threading technique that was going way over my head until I saw the pictures and realised it was about actual weaving
Awesome! The more we automate the building and testing of our open source ecosystem, the better.
A big tip which has helped me a lot: if you are stumped by error messages, comment the whole thing out and write simpler things. In this case, you could have written f as a top-level function and built up the answer from there. There’s no rule that says you have to use the fancy type deduction or point-free syntax, and there’s no points for doing so. (These things are useful, but start using them when you have confidence.) Seriously, the smartest thing I ever did was comment out all my code, write a function in GHCi, paste it into my code file and repeat.
Thanks!
Good tip, thanks! I think I'm just still struggling to understand how to do basic things. Something about this language is so alien to me.
Nice, tell me if that works for you too, or if you had do modify something!
Nice, tell me if that works for you too, or if you had do modify something!
Space-leaks are different from memory leaks. Haskell suffers from them: [link1](http://neilmitchell.blogspot.nl/2013/02/chasing-space-leak-in-shake.html) [link 2](https://wiki.haskell.org/Memory_leak) [link 3](http://blog.ezyang.com/2011/05/space-leak-zoo/). It's not that memory never gets reclaimed, it's that it's get reclaimed too late. This often leads to enormous *peak* memory usage. In order to recreate this in abstract algorithm, imagine you have a compact (unnormalized) representation of a huge data structure like [0..1000000]. Now you want to copy and consume one of the copies. Abstract algorithm, will normalize, copy and consume the copy. It will keep the other copy in expanded (normalized) form until it is needed (either for consumption or erasure). That might be a long time, leading to big memory usage. Hope that is interesting to you. 
&gt; If you're allergic to gitter and like IRC, you can connect via http://irc.gitter.im. Oh yeah, good mention. I do the same as well and access it through IRCCloud.
People always say this and it's often untrue. Programs do not live in a vacuum, they live alongside other programs and code. Other programs and code are absolutely going to use dependent types, and you will have to work with them, whether you like it or not, if it comes down to it. You only have to look at how popular libraries like Servant -- which ramp up the type level programming to a high degree, far beyond what most people are comfortable with, I'd say -- have become, to see that "you don't have to use them" is flatly untrue. I will have to use them, because someone else will choose to introduce them in some way I have to manage! Now, I think DTs could help make some things we currently do a lot simpler. But don't kid yourself: you will, in all but the easiest cases, not be able to avoid using them in practice at a certain point, once they're established and begin to proliferate. You don't have to rewrite a million libraries to use DTs to force them on people. Someone else just only has to choose a single library using them once.
`ptrace`-based emulation of chroot functionality can have significant performance implications from what I understand (minimally), which is a major reason to prefer actual namespacing features if possible. If you're running on Scientific Linux clusters, I assume you're dealing with work where 99% of it is totally compute bound, throughput oriented and where problems like system call usage are minimized (HPC, basically). So maybe this isn't an issue, but it would be interesting if you could see a difference! Alternatively you could always create your own Nix closure with a custom store path, although this variously depends on things like `/home` still matching up or whatever, and you need Hydra to do the builds in practice at that point...
A boring but important detail that I don't see mentioned in that blog post is that the compiler only inlines functions that are fully applied w/r/t the syntactic left-hand side of the function definition, so for the purposes of inlining, these two definitions are different: foo x y = ... foo x = \y -&gt; ...
Hylo sh*t, dude, I don’t understand any of that...
Were any of these sessions recorded?
Not that I am aware of. How about you, /u/edwardkmett? Maybe you could also ask in Gitter, others might have recorded one. If all parties involved are okay with that I can imagine recordings could be very nice.
I generally don't like to record unless what I'm presenting is fairly organized. I've debated about doing some live-coding sessions, if there is enough interest. As a bridge in that direction, I generally have no objection to multiple people tuning in while it's happening though.
Maybe [Luna](www.luna-lang.org) would be of your interest.
Nice, been waiting for this. Very well written series of posts, and surprisingly engrossing and digestible. Props.
I'm aware of `IHaskell`, and it's defiantly a step in the right direction. I think that nothing I described is particularly novel or new, what I want is a language that combines all of the things I mentioned. This language can be embedded in haskell for all I care, if we could only make distributed computing work (cloud haskell?)
You probably meant ***DEFINITELY*** -not *'defiantly'* --------------------------------------- ^^^Beep *^^boop. ^^^I ^^^am ^^a* ^^bot ^^whose ^^^mission ^^is ^^to ^^^correct ^^your ^^^spelling. ^^This ^^^action ^^was ^^^performed ^^automatically. ^^Contact ^^^me ^^^if ^^I ^^^made ^^^A ^^mistake ^^or ^^^just ^^downvote ^^^^^^please ^^^^^don't
Two options: you can use standalone deriving to derive an instance for a type that was declared in another module. Or you can manually define the instance. The standalone deriving method seems to be what you want. For example: module X where data Foobar = FB { foo :: Int, bar :: String } deriving (Show) And {-# LANGUAGE StandaloneDeriving #-} {-# LANGUAGE DeriveGeneric #-} module Y where import X import Data.Aeson import GHC.Generics deriving instance Generic Foobar instance ToJSON Foobar foobar = encode (FB 42 "test") notice: ghci Y.hs ... *Y&gt; putStrLn $ Data.ByteString.Lazy.Char8.unpack foobar {"foo":42,"bar":"test"}
Thanks Defiantly_Not_A_Bot! That was really helpfal.
That seems like a bad idea unless performance is really crucial. To me Rust seems like a significantly less ergonomic version of Haskell (e.g borrow checker) that performs better.
A lot of good tips here. Also, I think [these are the slides](https://github.com/jaspervdj/talks/blob/master/2017-haskell-exchange-getting-things-done/slides.md)?
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [jaspervdj/talks/.../**slides.md** (master → dbcaed1)](https://github.com/jaspervdj/talks/blob/dbcaed1cac46477840512c46fbbf1b1c93299815/2017-haskell-exchange-getting-things-done/slides.md) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dxj5cvx.)
**Luna** is a programming language on its own. **Luna studio** is text + visual IDE for the language. Luna definitely shares many similarities with Haskell. After all *it is* written in Haskell and currently compiles to GHC core.
How did you copy over the .apk? You need to get it on your phone in a way that your phone recognizes the mimetype `application/vnd.android.package-archive`; sometimes during file transfer it will instead look like a zip archive. Does the .apk get opened by android package installer? Also, post a link to the code if possible. If it's a simple hello world, it might be easy to find the problem if it exists in the code / configuration.
It's Android 4.2.2
I connected the computer to the phone and copy the .apk to the phone storage. Then I opened the File Manager on the phone and run the .apk. The code is the original code from the link above. I just followed the instruction to build it. I did not change any configuration.
Ah yeah it looks like reflex-platform only support 5.0 and higher (API level 21). ☹️ This bound might be entirely artificial though, you can try lowering `minSdkVersion` in `android/build.gradle.nix` and see if it builds and runs successfully.
Haskell is the System F + (sort of) dependent types solution. There's nothing about the language that would keep you from achieving your goals.
Hi kmicklas, I just changed the minSdkVersion to 1, and the .apk could be installed on the phone. After the installation, I chose to open the application, and I got the message "Unfortunately, Example Android App has stopped". Also, there was no application icon installed on the phone. Can you help me out?
Try setting `minSdkVersion` to 17 (version 4.2). I suspect though that we're relying on a number of features only introduced in version 5.0. If you can find out what those features are and there's an easy way to make it fall back gracefully without them, pull requests are welcome.
Right now, I'd kill for a good Haskell wrapping of the TF Estimator/Dataset API. Don't really have time to do it myself but oh my god Python is so painful.
 /r/haskell/8cwnhw:1:312: error: • No instance for StateOfBeing (RelentlessErrorMessages) arising from a use of Apostrophe • In the second argument of 'with', namely it's relentless error messages In the sentence: In every other language, I can just throw parenthesis somewhere and put the 'mod' 12 but Haskell is making me want to put my head through a window with it's relentless error messages. Perhaps you meant 'its'
Frankly, I'm hoping that over time your ideas will percolate into GHC. This is as relevant as it gets IMO!
[removed]
Great metaphor potential here. I mean, dung is actually part of natural ecosystems.
[removed]
Hmm, that is very interesting indeed. Thanks for the insight.
Update: they just replied to say they've now added `-O2` to their GHC compilation command :)
What makes this an incredible paper?
Getting a solid feel for how the language treats whitespace and fixity was really hard for me at first, despite coming to Haskell with a fairly decent understanding of function composition. I found it super helpful to just use parens, lambdas, and where/let bindings until `(.)` and `($)` felt more natural. Refactoring to remove local bindings and lambdas in favor of composition operators is sometimes called 'pointfree' programming - I am not of the opinion that the pointfree style is always preferable, but I think that refactoring to pointfree style is quite possibly the best way to get used to the less intuitive bits of Haskell syntax, and I cannot recommend it highly enough.
Should’ve said “seems incredible” because of the implications if it checks out. I don’t understand a large portion but the general idea seems reasonably sound (and incredible) to me. The paper starts by describing class calculus as “expressive enough to describe itself” which reminded me of Haskell and a critical component of a general AI. What made me feel like this is truly a groundbreaking idea was this description: “Rather than learning only from data, class calculus learns from hierarchical descriptions that are created from the data.” 
You mean this ADT? data GenericValue = Unit () | Void Void | Product (GenericValue, GenericValue) | Sum (Either GenericValue GenericValue) Since GenericValue is such a generic representation, there exists a function of type `A -&gt; GenericValue` for many `A`s. But there isn't a (total) function of type `GenericValue -&gt; A` for many `A`s, only a function of type `GenericValue -&gt; Maybe A`, because `GenericValue` has too many inhabitants. In this sense, `GenericValue` is a lot like `Aeson.Value`, it's a generic format into which many values can be encoded, but it's not a very precise type. `Rep A`, on the other hand, is a very precise type, something like `Rep Bool = Either () ()`. There is both a function of type `A -&gt; Rep A` and a function of type `Rep A -&gt; A`. This is important, since many generic algorithms work by converting from `A` to `Rep A`, manipulating the `Rep A`, and then converting back to `A`. Another important difference between `GenericValue` and `Rep A` is that `Rep A` can hold sub-terms which aren't themselves `Rep`s. For example, in `Rep [a] ≈ Either () (a, [a])`, notice that the `a` and the `[a]` are ordinary types, not `Rep`s. This makes it possible to write a generic algorithm which delegates to existing non-generic implementations for those types. A generic implementation of `ToJSON` applied to `[Text]`, for example, can reuse the `ToJSON` instance for `Text`, it doesn't have to convert the `Text` into a `GenericValue` and then encode it as a tree structure. Yet another reason is to detect misuse at compile time. If you have a generic operation which makes sense for products but not for sums, you can write an instance for `(:*:)` but not for `(:+:)`. This way, when you try to call your generic operation on a type `A` which is a sum, you'll get a type error telling you that there is no instance for `Rep A`. By contrast, with `GenericValue`, you would instead write an implementation for `Product` and fail for `Sum`, and this failure would only show up at runtime. One final reason is for extensibility. Currently, deriving Generics only works for algebraic datatypes, not for more exotic types like functions and GADTs. This is quite unfortunate, but if you have an exotic type A, there is a way out: you can write your own `Generic A` instance instead of deriving it, and you can use whatever you want as your `Rep A`. Of course, the existing generic algorithms only have instances for products and sums, but you can write your own algorithm which work e.g. with products, sums and functions, or you can add an instance for functions to an existing generic algorithm.