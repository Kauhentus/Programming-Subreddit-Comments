It's a screenshot of Edward's [hask package](https://github.com/ekmett/hask/blob/master/src/Hask/Tensor/Compose.hs#L137) he's been working on. He tweeted about it, so I [shot back](https://twitter.com/stdlib/status/652961671493738496) with this picture. The reason is because it reminded me of a very similar demotivational poster I saw for Agda a long time ago ("AGDA - Don't even bother trying to learn it"). In spirit it was the same, but of course had significantly more unicode.
&gt; &gt; This is what I find really exhausting about Haskell... every question leads to ten more things that I don't understand. Doesn't pair programming solve this problem and many of the problems discussed in this thread?
It is the constant churn here: Having to do this every year for all one's old code is quite a burden. Further, I didn't think the scheme accommodated "Tibell's Three": No warnings, No CPP, No unqualified, unrestricted imports. 
&gt; In this case they weren't referring to Foldable, but the problem is that Foldable just added at least three more things to that list for many cases which should be simple. The cost/benefit tradeoff for Foldable just seems to be very badly wrong. In my very limited experience with Haskell beginners, this one is not a problem. The concept of collections that have common "methods" is not exotic to people coming from most other languages. The problem is more about surprising instances ...
It seems I might be able to use: ghc -package haskell2010 -hide-package base
And [tree-view](http://hackage.haskell.org/package/tree-view) does it even better, using Unicode to make the rendering more compact. It can also produce an HTML file with foldable nodes.
Why not make Haskell popular? It would, in my opinion, do a service both to the entire world (better code for everyone!) and myself (better code for me).
&gt;Now they will need to introduce typeclasses We already need to introduce typeclasses just for basic arithmetic. Has anyone ever had a student stumble over the basic typeclass introduction? It is one of the things I've never had anyone have trouble with, it barely requires any explanation at all. "Num a =&gt; a means that a has to be a number. You don't need to care how to make something a number right now, just to understand what that stuff on the left hand side of the =&gt; means". &gt;some really quite abstract ideas Like what? 
&gt; I understand that some of the concerns are pedagogical, So basically he refuses to ride a bycile once the training wheels are removed? Why not have a separate bycicle with training wheels for learners? like in real world? 
Perhaps we should introduce monomorphic `mmap` and `mfilter` for this teaching role.
There's a ton of context missing in the picture, but when you break up the `where` clauses and assume that a lot of the strange function calls are from imported libraries, it's a bit easier to see some intent. I suppose it's like any obfuscated code in any other language, but I'm just happy that I was able to recognize the different clauses. You're definitely ahead of me if you're able to take any stab at what the context could possibly be, even if it's just a guess. ;)
The difference for me is that the a rule in Haskell allows you to predicate behavior in other areas as well as the case at hand. While memorizing a rule in javascript only helps with the particular case at hand.
Ok, so you're only dealing with a very specific set of functions. You can't for instance distinguish f = + and g 0 0 = 5 g x y = x + y without first knowing about both of them.
Yeah. 'Foldable' is too concrete apparently: Wat?
`Either` only makes sense because `Either` was bastardized to be `ErrorWithValue`. As a simple "one or the other", I don't think it should have even been an applicative, let alone a monad.
&gt; but that's not what we usually refer to by "impredicative types" there Well, only because in Haskell predicativity is enforced in an ad-hoc way rather than by universe levels, right? The end result is the same kind of restriction? &gt; In contrast, in Agda or Coq one can have const : forall a. a -&gt; forall b. b -&gt; a, and map over a list like map (const id) xs, and get back a result with List (forall a. a -&gt; a) type. You can? Wouldn't your `List (forall a. a -&gt; a)` end up in a higher universe then? I mean it's clear that with universe polymorphism or cumulativity or what have you, you can do some things that you can also do with impredicative types, but it's quite different. As far as I can tell the real issue is whether types like `(forall a:Type_n. a -&gt; a)` have type `Type_n` or type `Type_(n+1)`. So if your List constructor has type `Type_0 -&gt; Type_0` then it won't accept `List (forall a. a -&gt; a)` in a predicative language, whereas this would work in an impredicative language. With universe polymorphisms you could have `List : forall n:Level. Type n -&gt; Type n`, but now `List (forall a. a -&gt; a)` ends up at level 1 instead of level 0. For instance in Coq if you did something like: Definition foo:Set := list (forall t:Set, t -&gt; t) You'd either end up with a type error that `(forall t:Set, t -&gt; t)` has type `Type` and not `Set`, or that `list (forall t:Set, t -&gt; t)` has type `Type` and not `Set`, depending on whether `list` is universe polymorphic or not. p.s. After the edit this discussion looks quite confusing, so I'm not sure if that actually helps ;-)
[**@headinthebox**](https://twitter.com/headinthebox/) &gt; [2015-10-10 19:49 UTC](https://twitter.com/headinthebox/status/652934071551660032) &gt; @JoinReturn That is rather imperative, it leaks the implementation. ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
That's true, but if you go back and read the original post, you'll see that I never stated that one had to implement Show correctly for *all* binary functions. This, and worse, lawyering characterized all of the exercises.
You managed to convince me that this is an even worse idea than I thought it was. :) Namely, you're apparently seriously suggesting using a *Church encoding* for *efficiency*. Higher-order representations should *never* beat a first-order one. If they actually do, that means there either there is a tremendous deficiency in the language's type system (ie, it can't express critical data representations), or the compiler is really falling down on the job somewhere. 
I've worked in Ocaml and F# before I looked at Haskell. It's such a different beast, we might as well start calling it a different paradigm. 
Nope, still no haskell2010 package for GHC 7.10.
I think the idea is more that we should not make it worse but popular than about the idea that popularity itself is bad if all else is equal.
I still don't understand it. (And I really like most of FTP, so I don't think I'm biased here)
GHC won't stop supporting `{-# LANGUAGE Haskell2010 #-}` (or the equivalent `-XHaskell2010` flag) for the foreseeable future. But that only controls the language part. The main problem is the library part which inevitably broke due to implementing (F)AMP. The short story is, that modifying the `Monad` typeclass hierarchy combined with the lack of features in GHC to either define a distinct proper Haskell2010 `Monad` class, or to implicitly instantiate a hidden `Applicative` typeclass is the limiting factor here. See also https://mail.haskell.org/pipermail/libraries/2015-October/026309.html Otoh, AMP will almost certainly be part of the next Haskell Report. So at some point in the future you will be able to write standard-conforming Haskell code with the newest GHCs again.
Interesting. Do you use MLton or SML/NJ? I've used SML before, as a learning language it wasn't that great but I liked it nonetheless.
&gt; (I'm sure it is not exactly like a Java/C# interface, for reasons I can not understand...) For example, type classes don't operate under a closed world assumption. In Java, a class implements whatever the author wrote after `implements`. In Haskell, you can add instances for type classes separately from the type definition. There's no need for the instance to live in the same module, or even the same package, as the type definition.
I use SML/NJ for development, since builds are near instant. We'd like to be using MLton for "production" builds to take advantage of its optimizations, but there's a few incompatibilities in our code we have to address first. I'm curious what the weaknesses in using SML as a learning language were for you. One example I could think of would be type sharing and structure sharing, which are very complicated and (honestly) frustrating.
The main remaining issue, as I see it, is having a standard-issue binary distribution system for libraries that works on Windows. I realize this is a problematic undertaking. But the requirement to spend twenty minutes compiling libraries before building any project of any size seems like a major deterrent to uptake. Yes, it gets better, and yes, with things like `stack`'s cache sharing you don't have to do that multiple times, but it still seems like it'd leave a sour taste in a newcomer's mouth---"oh, Haskell takes forever to compile."
Then I don't think the function should be called `length`. `howMany` could be more appropriate, or we may find that `length` as generalised isn't actually that useful and can be done away with. As /u/simonmar points out &gt; The root of the problem is really that the Foldable operations were given the same names as the Prelude and Data.List ones, leading to the name clashes which were "fixed" by replacing the simple list operations with unnecessarily general and completely inscrutable ones.
You might, but [mostly](http://www.googlefight.com/%22a+hero%22-vs-%22an+hero%22.php) we use "a hero".
Say I'm interested in learning about how errors are generated, making changes to the error language, etc. Where do those things live in the source tree? Are there existing pages on the developer's wiki? I tried looking around, but I didn't find much, and I don't know the source tree well enough to even know where to start.
 Prelude&gt; :t length length :: Foldable t =&gt; t a -&gt; Int Prelude&gt; :t ("hi",False) ("hi",False) :: ([Char], Bool) So length works on the `a`s in some `t`. Now if our `t` is ([Char],-) then in this case it must work only on the second component -- in this case `Bool`. So how many Bools are in ("hi",False) ? One! (I'm not trying to argue this is the most intuitive thing or anything -- but just showing how the types can help you see why this is the case.) Parametricity is important here too, since obviously `length (True,False)` gives the same thing -- so it is important to understand why for uniformity's sake this must work the same regardless of the type of the first component of the pair.
I think the idea of a modular Prelude would play nicely with this. The base (call it `GentlePrelude`) gets basic stuff like arithmetic, some of the list operations, and so on. Then higher-level things are introduced in stages. `GentlePrelude.List` gets the monomorphic list functions, `GentlePrelude.Maybe` for optionals, and so on. Things get a little stickier as you get to the highest levels: Does `GentlePrelude.Foldable` re-export types from `GentlePrelude.Maybe`? I still think it'd be a nice idea.
I think as a start a -strict package requiring `RebindableSyntax` on each file is a good start, to be honest. Having that half done makes adding the option to GHC more straightforward, since we have the proper testcase for it to begin with.
Here, the old style length function would still get tripped by nested lists. It would be better to define an auxiliary function like lengthNonNull :: [a] -&gt; Int -&gt; Int 
As a sidenote: Please don't concatenate lists with foldl. Use foldr to avoid traversing the accumulator more than once. 
Well, there's this page: http://okmij.org/ftp/Haskell/impredicativity-bites.html There's a section of the [Coq book](http://adam.chlipala.net/cpdt/html/Universes.html): &gt; In old versions of Coq, Set was impredicative by default. Later versions make Set predicative to avoid inconsistency with some classical axioms. In particular, one should watch out when using impredicative Set with axioms of choice. In combination with excluded middle or predicate extensionality, inconsistency can result. But I don't have a good reference, unfortunately.
I'm quite skeptical that's really the case. Instead, I think it's a more like: the more senior they are, the more expectation they have of being productive quickly. New programmers have a higher tolerance for the learning process. When I learned Haskell in 2006, I used it immediately for substantial projects. Now, Haskell is moving rapidly away from being a language where it's possible to be productive quickly.
&gt;One example I could think of would be type sharing and structure sharing, which are very complicated and (honestly) frustrating. I'd love to agree with you, but I have no idea what those are :) My issues were much more fundamental: * The parser/lexer error messages of SML/NJ were pretty wat-inducing. * We didn't get a proper introduction to identity types, so the entire time we were wondering what the hell that was about. * No online walkthroughs/tutorials. * At the time, no `smlnj` package was available in the Ubuntu repositories. Small time stuff, but it counted. Having a pre-built environment and someone to pair program with would have solved all of those problems, but that's a rare luxury outside of industry.
No we do not. http://www.grammar.com/a-vs-an-when-to-use/ It's a hero if you pronounce the "h", and an "hour" because you do not pronounce the h.
Even as an experienced Haskeller, the most important piece of information in a ghc error is the line number. Only if I can't figure it out from starting at the line do I bother with the message itself (especially now that the useful info is moved all the way down due to the scope dump). As a beginner this was even more true.
It took me a long time to understand Foldable. I assumed it was obscure and difficult. I think it will actually help beginners to have it in Prelude. As the article says, it's just like other languages.
Definitely! Simon is awesome. I literally don't think Haskell would be on anyone's radar today if it weren't for his community leadership (as well as his technical work!). In this case, though, I think he's missed the mark. Simon is talking about the difficulty of migrating. But the point wasn't about the difficulty of making changes. It was, rather, about these specific changes putting Haskell in a much worse position than it was before. Obviously, there's a good bit of disagreement about this, but to many, this feels like the point where we've taken a step off the deep end, and started throwing in arbitrary abstraction whenever possible, without an eye to the cost.
Sounds very promising! I think I'll have a go at this. Thanks for making Shake!
&gt; I think he's missed the mark. pun intended? 
i don't think I understand this comment. care to elaborate?
That's what I meant by: &gt; Well, only because in Haskell predicativity is enforced in an ad-hoc way rather than by universe levels, right? By the way, what do you mean by you can instantiate `(-&gt;)` with polymorphic types? (without turning on impredicative types) 
I thought the ability to deduce what a function did by parametricity was meant to be a good thing? smh
What kind of style do you have in mind? Maintaining two styles feels like even more work than replacing one style with a better one.
&gt; Like what? The idea of things with different structure being generally foldable. That may seem totally obvious to you but you don't know much about teaching if you expect everyone to pick that up straight away, bearing in mind that we're talking about Day 1. One solution will be to handwave it and explain later, but this is a big step backward from the beautiful simplicity of the previous types. I agree, Typeclasses are easy to explain if you start with Eq etc. Your Num example is indeed hard to misunderstand but there is a big difference between "being a number" and "being foldable", and "don't worry about it now, I'll tell you later" isn't a good approach. 
&gt; When I learned Haskell in 2006, I used it immediately for substantial projects. Now, Haskell is moving rapidly away from being a language where it's possible to be productive quickly. I'm not convinced this is actually the case (or at least not significantly so). I think the burden is on you here to provide substantial supporting evidence. And secondly, even if you do succeed in supporting that position, I think it can very reasonably be argued that this is just the inevitable price of progress. As any field becomes more advanced it will take more and more time to get to the point where you can productively contribute.
since no one else has any suggestions: I can't answer your specific question, but I've heard scratchbox helps: http://www.scratchbox.org/
Seeing the httpLbs early on got me wondering about memory usage. A tracker probably won't spam horribly big http responses.. unless it's malicious. As you note, dupChan avoids new clients seeing stale buffered messages. But, what happen if a client loop is blocked for some time (ie on a network send), and broadcast messages are accumulating in the meantime? Seems this could lead to unexpected memory use, perhaps in a way that swarm peers could exploit. 
Ah I see, I think that's where the confusion came from. In a dependently typed context that would already be called impredicative, but in Haskell that's called -XRankNTypes whereas the whole shebang is called -XImpredicativeTypes.
Thanks for the clarification, but not really what I wanted to hear :(
I was all for it, until someone pointed out that length (1,2) == 1, and length (Left 2) == 0. That alone doesn't dissuade me but I could find myself a little peeved if I get a wrong answer in compiling code where I expected the length of a "[Int]" but was instead getting the length of an "Either e [Int]". I wonder if the ability to specify type arguments to functions as detailed at the end of [this blog](http://www.haskellforall.com/2015/10/polymorphism-for-dummies.html) will allow us to specify something like "(length @[]) arg" as in code, which seems like it would at least help track down errors.
Indeed there was. 82% of respondents were in favor of the change. That doesn't mean we can't think they are wrong. :)
I cannot prove the claim, and didn't think I was entering a debate. I only have my own observations about the language, and my own experiences. (I suppose I have quite a few students' experiences, too. But I'm not sure it would be fair to count the experiences of 11-year-olds... and I provide a customized Prelude with no type classes for them, anyway.) And I recognize that many people disagree with me. Still, I supposed that it would be possible to have a conversation, and I'm a bit puzzled by the tone of your response. I also agree that there are some advantages to generalizing. Indeed, I'd agree that Haskell pre-FTP can encourage the use of linked lists when they are often not the best choice. One could call solving that problem "progress". But only if it's really better than the alternative. I think there's a strong argument that it's not... and that as a community, we often miss the cost of too much abstraction.
Did you export your PATH? If not, run: export PATH export in sh and related shells (such as bash), marks an environment variable to be exported to child-processes, so that the child inherits them.
An hero is a joke from 4chan about someone committing suicide. It's meant to be incorrect.
As I have said elsewhere, Linux is an example of what we'd like to model. Linux has a strong open-source community and also gets significant funding from a multitude of Linux companies, such that it is not dependent on a single entity for its survival. I'm suggesting it would be nice to ensure we move in that direction, rather than centralizing around a single commercial entity. Ultimately, it seems that FP Complete is getting out of the tools market and into the consulting market. As a result they are no longer supporting FP Center. Fortunately, for most people, that is not a tool they care about. But it is a prime example of my concern. FP Complete will only continue to support tools, services, etc, as long as it seems economically interesting to them. Perhaps they will find Haskell consulting too hard to sell and switch to Scala or Clojure and abandon stack next. It seems to me that the Haskell community is in a pretty weak position. We have tons of libraries from many authors on hackage -- which is great. And friendly, active communities on reddit, irc, etc. Yet, at the same time, it seems that much of the core infrastructure is supported by only a handful of people. And a number of those folks have made it clear that they would really like it if someone took over their duties. It is not a conspiracy to suggest that SPJ will one day retire. dcoutts has already made it clear that he is not interested in being the main hacakage-server maintainer any longer. One reason people are excited about stack is because cabal-install development appears to be moving at a glacial pace. What is the plan for bringing fresh money and energy to these critical projects? Money is a good tool for getting things done. Much of the work on cabal-install and hackage-server came from GSoC funding. And this is great -- work gets done, no strings attached. But that is a drop in the bucket compared to what needs to be done. Having a company like FP Complete take over development of core technology can be attractive because a few paid developers can get a lot done. But, when fp complete decides to change business strategies and stop supporting the tools -- what then? When I made my original post, it was 'conspiratorial' to suggest that FP Complete might make a radical shift in their business and stop supporting tools. And yet that does seem to be what has happened. It seems they are exiting the tools marketing and getting into the consulting market. Fortunately, they did it before getting more deeply entrenched, so the only lose so far is the FP Center IDE.
`Foldable` is merely another case where it can happen, or did you never have students try out Prelude&gt; "hello" + "world" No instance for (Num a0) arising from a use of ‘it’ The type variable ‘a0’ is ambiguous Note: there are several potential instances: instance Num Integer -- Defined in ‘GHC.Num’ instance Num Double -- Defined in ‘GHC.Float’ instance Num Float -- Defined in ‘GHC.Float’ ...plus two others In the first argument of ‘print’, namely ‘it’ In a stmt of an interactive GHCi command: print it and not run into the very same problem already much earlier?
I'm helping move over an introductory functional programming class from SML to F#, and this was a major concern for us as well. I think what really sold us on F# is that the fancier bits don't show unless you're actively looking for them, much like Python and SML - and much unlike Haskell and Java.
If I ever do a [WAT talk](https://www.destroyallsoftware.com/talks/wat) for Haskell I will include this. :)
It seems like the best solution there would be to change the error message to be "type Foo is not a Foldable" when possible.
`Foldable` is a superclass of `Traversable` and the Traversable instance is certainly useful -- so arguably the _need_ for Foldable is a knock-on effect of the other. But I can't promise there's not another need for Foldable, perhaps with lens machinery or something, that I too can't think of :-)
But the need for those funny imports would in itself add another thing to the list to be explained.
Correct me if I'm wrong, but when we do A ++ B, A is copied to A' with just the last list cell which *points* to B instead of an empty list. But if A is directly garbage collected after that, is ghc able to avoid the copy by just "reusing" the data from A ? (Edit: replaced B by A in last sentence)
what about an IDE API like http://docs.idris-lang.org/en/latest/reference/ide-protocol.html? Haskell IDEs have to parse ghci's human-(but not machine-)readable messages, which is fragile. good error messages are a long-term goal. structured error messages seem more of an engineering problem than a design problem. by which I mean, I feel like someone without any experience in programming language design could refactor GHC away from ad hoc pretty printer combinators. 
The trouble is, few people are lucky enough to have an expert Haskell developer available to be their partner/mentor/teacher. There simply aren’t that many people around who are expert Haskell developers. Similarly, there is still a rather wide gap between the handful of introductory books now around (some of which are now quite out of date, possibly to the point of being actively unhelpful) and the kind of academic papers and bleeding edge research going on at the top levels of the Haskell community. Probably somewhere in the middle lies a level of competence where someone can make productive use of Haskell for substantial software projects, but there are still few resources generally available to help someone new to the language develop to that stage. If the community and ecosystem around Haskell are to grow then we need to close that gap, and the danger here seems to be that the changes will instead widen it.
Fyi, newer Haddock versions do this replacement for you: http://i.imgur.com/zRPCKNR.png (taken from [`Data.Foldable`](http://hackage.haskell.org/package/base-4.8.1.0/docs/Data-Foldable.html) documentation)
I think the reference was to a problem I've seen more in Scheme than Haskell wherein you can quite easily lose track of list nesting depth. So you pop the head off a list and take its length, but did you mean to take its length or the length of the tail? When everything's a list, a polymorphic length type doesn't help you catch some common bugs.
&gt; You download the installer * Download stack &gt; Install it * run `stack setup` &gt; run IDLE * run `stack ghci` &gt; type `print("hello world") * type `putStrLn "Hello world!"` If this doesn't work then file a bug against stack. It should be just that easy.
I'm in favor if it means: "a quick way to download most of the packages you'll need as a beginner, but equivalent to starting with just stack" There's a use case for "download it in advance so you can do the work offline", especially for travelling students
I agree that the mentor problem won't resolve itself until there are more Haskell jobs. However, I believe haskellbook.com has a lot of promise as a beginner-to-intermediate level textbook that can help round out the Haskell bookshelf. However, the changes don't really affect new learning materials that much, in my opinion. The big historic cause of breakage in tutorials was due to the lack of reproducible builds before `stack`. If all tutorials use `stack` and fix to specific resolvers then these changes should not be an issue for the reproducibility of tutorial examples. For example, if Real World Haskell were adapted so that all the examples built with `stack` then it would age much more gracefully.
Wait ghci&gt; toList (1,2) [2] Why does this make sense?
&gt;the fact that you get access to all the .NET libraries is pretty useful for making fancier and more interesting labs and assignments :) I'd agree, except that the .NET libraries are extremely imperative, so not a great fit for the class. We moved away from SML and towards F# for a few reasons: * Better error messages * Better tooling * More documentation available online * Better reputation as a "real world language", to placate criticisms of the class material as unusable and irrelevant
If A' is live it contains a pointer to B, which would therefore not be eligible for GC.
I've used Python, and I *really* don't like it. I could use it if I had to for a job, but I would not enjoy it. However, I'm sure there are a lot of people who have trouble or qualms with Haskell who would be more happy with Python. But for me, it is in many ways nearly the antithesis of Haskell. It's type system is unreservedly *abysmal*. Even beyond types, Python compilers will not even check basic things, like that you're trying to call a function that has been defined *anywhere at all*, let alone for the object you have actually called it on. It embraces mutable state, and by that I mean *it has no means of preventing any object from changing the internal state of any other object it can see*. A library does not *have* an internal implementation, every attribute and method it uses can be accessed *and overwritten* by anyone who can see it. These last two points are even worse than they seem, because the qualifier "can see it" isn't a qualifier at all, because anyone can import gc and get *all the objects* and then fiddle with them arbitrarily.
Seems like a good idea to me...
Actually I am okay with the Foldable instance for Either, for the same reason that I am okay with the Foldable instance for Maybe. The main instance I object to is the one for 2-tuples.
Everything you said is foreign to haskell. 1. Haskell does not need anything, never promised anything you demand and was always developed and driven by those who want haskell, not another scala or clojure. 2. Those who want to jump to haskell the same way they jump from c# to java already have such options: scala, clojure, c# with haskell goodies (linq), reactjs, elm, purescript and many many more functional and reactive things that been simplified for the sake of adoption. What good would it serve the world if we get rid of one and only haskell and instead turn it into yet another scala or clojure? It would simply push out all the talent that is right now making progress in programming theory to create another haskell. And the circle will repeat after the horders will come and again demand to make it more approachable. 3. I do not think secret to adoption in industry is in limiting haskell. Rather it is in building infrastructure, like stack, stackage, IDEs, servant, postgrest, developing database libraries for Oracle and Ms Sql, making haskell first class citizen in browser, making very simplified and user friendly frameworks akin reactjs (react-flux is very good port to haskell) instead of overly confusing and undocumented FRP UIs like reflex-dom and francium. There are a lot of things that are hurting haskell in becoming more popular. But principled approach to types is not one of them. 
I'm sorry if my tone was too harsh. That was not my intent. I have great respect for your experiences teaching Haskell. They are certainly far greater than my own and have done a lot for the community. I refer people to your learning materials pretty much any time I encounter someone interested who's not already an experienced programmer. But I don't see how those experiences have much to do with the statement I quoted, as no 11-year olds can be expected to be productive with substantial projects quickly in any language. In short, I just don't see a convincing argument for the statement "Haskell is moving rapidly away from being a language where it's possible to be productive quickly." While I recognize that things like AMP, FTP, MRP, etc can be a small temporary obstacle to overcome, I think it's several orders of magnitude less significant than the overall amount of work it takes to learn Haskell. And if we take this as true (or even close to true), a statement like "Haskell is moving rapidly away", stated as fact and with no supporting evidence starts to sound a lot like FUD. You certainly aren't obligated to enter the debate, but then I would say the statement should not be made so strongly and with the appropriate qualifications. I should also say that while I don't have a strong opinion on AMP/FTP/MRP/etc themselves, I think I'm generally a little more on the side of supporting them. However, I fined the point made in [this comment about the unexpected behavior of `length`](https://www.reddit.com/r/haskell/comments/3ojekh/excuse_me_i_think_this_is_my_stop_haskell_platform/cvy1a48) to be a significant concern (although not so significant as to justify "moving rapidly away". I don't think it's an argument against the core of AMP/FTP/MRP though, but rather an argument that perhaps things like `(,)` and Either should not have Foldable instances.
I agree that it's not easy for newbies, but stack is still young so there's hope :)
So you're saying that `fmap = bimap id`? Why? Also, where does this `bimap` come from? Hoogle reveals nothing. Edit: And yeah, I know that that's not the actual implementation of fmap in the functor instance for pairs, but it seems to be the point you're trying to make. Edit 2: I found Bifunctor. So `fmap = second`. Still, why?
In general, I'll just say that I was talking about prerequisites to Haskell gaining traction as a mainstream language with substantial use in the software development industry. That's not everyone's goal, and I appreciate that. That said, when you say: &gt; What good would it serve the world if we get rid of one and only haskell and instead turn it into yet another scala or clojure? Keep in mind that I'm actually arguing for more caution with future changes to Haskell. You've characterized Haskell as it existed until GHC 7.10 as "training wheels." It seems that you have in your head an ideal vision of what Haskell ought to be. You're not alone. There's a large subcommunity that wishes Haskell were, among other things, dependently typed or close to it, or had a numeric class hierarchy based on abstract algebra, or moved some more of the old category-extras into base, and made more pervasive use of type classes a la the FTP changes, etc. But that isn't the same thing that Haskell has been -- at least until very recently, or in general even at all. It remains to be seen how such a language will be received, or whether it will survive as reality sets in and people need to get things done. Historically, Haskell has set a very admirable balance between being a playground or type theory, while also being very conservative with core language changes. I am of the opinion that this *balance* is responsible for Haskell remaining relevant rather than dying the conventional death of research languages. That balance feels threatened at the moment.
I have learned Python after C++. It was a dream come true, I loved programming in it. After all the complexity of C++ it was a breeze - programming was fun again. Then I learned Haskell. I loved it even better. It was logical. It was concise. And the programs just worked. A few months ago, I've tried to do a basic project in Python. The initial charm was not there anymore. It was like walking through a minefield. I missed those strong guarantees that Haskell had. I missed the "it just works" experience. Eventually I've ditched that project and rewrote in Haskell. No regrets. Python is fine, but it doesn't quite cut it for me. Haskell does.
Names were given by most respondents and were considered in weighing the replies, it wasn't just a raw numerical superiority. 82% was the percentage in favor overall, but it was a pretty good mix of old and new hands in favor.
(Sorry, typo, I was meaning that if A is directly garbage collected, it may be reused instead of copied to A'. I edited my post for clarification, but let this message to keep your post in context, thank you.)
Sure, that's why said "some classes of changes". I just thought the idea deserved some support, since many people don't seem to know about it, and it's a great way to avoid CPP, use new features and keep backwards compatibility. It seems it's mostly class changes that seem to be hard to do. Perhaps we need to think about language features that would make evolution of classes easier? I can remember threads about this in the past, but I don't think anything came of it.
Good luck! Do email the Shake Mailing List or ask on Stack Overflow if you get stuck. Both are linked to from http://shakebuild.com/
`Foldable` tells me hey I can put all the `a` elements here into a sequence. `Functor` tells me I can change them, even if there are uncountably many (e.g. results of a functor). `Traversable` tells me I can change them the elements inside with `Applicative` affects and that these changes compose. This implies both of the other relationships by picking the `Applicative` appropriately. Using `traverse` with `Const m` yields the power of `foldMap`, `Identity` yields the power of `fmap`. Given `Foldable` a ton of things that had previously been written on an ad hoc basis "just work". But _removing_ a `Foldable` instance because you don't happen to need it now means that anything that has that as a superclass can just never work with your type. `Traversable` for `Either x` tells you that there is a distributive law that lets you `sequenceA :: Either x (m y) -&gt; m (Either x y)` to distribute `Either x` over _any_ `Applicative`. This is an incredibly general property with a ton of knock-on consequences. This is why you can do so many things with it. Some of these enable new idioms: for_ someEither $ \x -&gt; ... will run the right hand side when someEither is `Right` something, and not when it is `Left`. length (Just x) = 1 length Nothing = 0 makes perfect sense to folks. Either is just this where the `Nothing` (`Left`) carries 'other stuff'. Importantly, each of these classes does "the only thing it can do" given the types involved. You can reason through the behavior of `Foldable` and `Traversable` for `Either` just by looking at the definiton of ``` data Either a b = Left a | Right b ``` and the type and the 'left-to-right' convention of `Traversable`. Now, is `Foldable` the most general thing that can support the operations it does? No. It is however about the most general thing it can be and still live within Haskell without type families or functional dependencies, and sits at the point it needs to to supply the parts of Traversable needed for for_ and sequence_, and that brings with it enough stuff to implement about half the combinators in Prelude. That `foldMap` is a powerful enough abstraction to subsume about half of our API is a very powerful observation, so it seems worth making an investment in teaching that abstraction, and in making sure that the design of the standard library doesn't go out of its way to make it harder to use.
That's actually awesome.
(In case it wasn't clear, the reference to my students was not intended seriously. As I mentioned, there aren't any type classes at all in the Prelude that I use in that class.) I suppose I should be clearer that I'm commenting on what I perceive to be a larger community direction, rather than the FTP changes specifically. And I actually am strongly in favor of AMP and MRP. But on top of the FTP changes, we have: * A plethora of changes pushing Haskell toward dependent types. * Widespread use of `lens`, which is a remarkably complex library. * An increasingly widespread meme that good Haskell programmers must be comfortable with the Yoneda lemma and related ideas. * etc. Taken together, I think it's fair to summarize a lot of the current movement of the Haskell programming language as being the addition of more cognitive overhead, without bounds. As I just wrote in another subthread, each of these things taken alone may not be prohibitive. But the aggregation of all of them seems to be prohibitive, to me. At least, I no longer feel comfortable in describing myself as an effective Haskell programmer. And, not to try to sound too arrogant here, but I'm coming into this now with nearly 10 years of history with the Haskell language, a research-level mathematics background, a 30 year history of programming for both fun and profit, and a pretty good aptitude for picking up new things. Now, if you scale that back to (a) needing to bring new programmers up to speed relatively quickly, (b) needing to be productive on occasional Haskell projects while primarily working in a different tool set, or (c) not having the freedom to assume a strong background in mathematics or an incredibly high innate aptitude of your entire team... I struggle to make myself believe that, particularly if things continue in this direction, it's reasonable or practical for me, personally, to advocate for more uses of Haskell. The other alternative, I suppose, is that I'm just getting older and dumber. I have no doubt that's true! But I do hope it's not happening quite so quickly...
&gt; Haskell needs to be usable by developers without years of experience. A 3 month ramp-up time to being productive is on the long side. Anything longer is untenable. I don't think this is a reasonable expectation of a language as dramatically different from the mainstream as Haskell is (at least not until the mainstream moves closer to Haskell). It's a bit like saying that students just out of their first programming class should be able to ramp up to production-grade professional software development in three months. Well, maybe that analogy is a bit of a stretch, but frankly, in my experience it takes longer than 3 months for an already competent developer to ramp up to being productive when they start a job at a new company! &gt; And it's not ONLY remembering the scheme for deciphering the hundred-ish operators in Lens, or recalling the meanings of a dozen more type classes there. This is not a requirement at all. I just used lens today to save me quite a bit of time writing tedious code. I didn't need to use or understand any of the operators. I did have to use some stuff that came from some of the type classes, but I didn't already know which one I had to use. I just went to the haddock page for Data.Map.Lens and Data.Sequence.Lens and found everything I needed. You don't have to hold this stuff in your head. You just look it up lazily as you need it. &gt; And it's not ONLY working through the type-level stuff going on with automatic promotion of ADTs to the type level. In five and a half years of professional Haskell development I've never needed to worry about this in production code. &gt; There is an aggregate cost here, which is definitely starting to feel overwhelming. I think it's actually much smaller than you're making out. And there are actually very real benefits such as the significant amount of time I saved today by using lens. In short, I don't think the things you mention actually have much of an impact on real world code. I also think that Haskell is very good at allowing us to wrap these complicated things up in abstractions that allow users to completely ignore most of the complexity inside them. This is why I'm still in favor of continuing to move the language forward.
I discovered LW recently, and to me it feels like cotton candy. I enjoyed reading the articles and talking to some of the people, but compared to formal mathematics, there's little real nutritional value. I allow myself to indulge in small doses.
How did you use the Haskell of 2006 that barely had any libraries for anything compared to today for substantial projects but have trouble doing so today? That makes very little sense when looking at the overall ecosystem, not just the language.
I don't really understand this post, what do you mean by "invite all of you to join and learn/use Python"? are you opening a class or teaching? or are you just telling me to learn python because..? Honestly, I was expecting a short tutorial that will help me use my haskell knowledge to learn python easily and quickly, which I would probably read, But I'm not going to take the time to learn a language that is probably not going to teach me something radically new without a really good reason. I have enough languages I want to learn as is (PureScript, Idris, Forth, Rust, Clojure, Erlang, Prolog, J) and a lot more programming related domains, and simply not enough time. 
any ideas?
All of those are examples of what is totally wrong with Haskell now. It doesn't matter if the follow logically from something or other. They are counter-intuitive to most people.
Nitpick: `Map` is fine being a `Functor` and the instance is indeed defined in `containers`, the `Ord` constraint is only needed for the keys. That might only make it impossible to define a `Profunctor` instance.
Agreed. I think given the state things had hit by the time of the poll I'm not sure what a better approach would have been, but we shouldn't view it as setting a precedent for the future :-)
I think everyone wants progress. But we differ in what we think is progress. 
We need to try to make Haskell more popular by making it better. FTP made it worse.
Some of the Algol68 ideas survived. 
Good catch: the law needs to be made more precise and refer to the values whose position is typed by the Foldable's type parameter (i.e just/all the values which would have a different type if the Foldable instance was parameterized differently).
That doesn't follow at all from this discussion, which is a complaint about a lack of restraint in exchanging clarity for abstractions.
Reading GHC error messages is certainly a skill that can be taught/trained. There are very few parts of the message that I actually read – I assume beginners feel kind of lost as to which parts are relevant. I'm not sure if other people read the other parts or if they're just there to make it look more complete.
`Foldable` in both cases literally does the only thing it can do. Folks come into Haskell and wonder why `fmap` works over the second half of a pair. Then they learn to think about the pair as (,) c a. This is an "a ha!" moment. fmap :: (a -&gt; b) -&gt; (c, a) -&gt; (c, b) They have the same revelation about `fmap` when they realize it is also (.). fmap :: (a -&gt; b) -&gt; (c -&gt; a) -&gt; (c -&gt; b) This is exactly the same revelation. Virtually everyone goes through this revelation at some point fairly early on in their Haskell learning process. It previously usually struck someone as a cute one off trick. Now it applies _uniformly_. That same insight can now be applied to half the combinators in the Prelude. They do the only thing they can do. When you are looking at a data type, and a `Foldable` instance, if you stop and considered what is the last argument what it does becomes immediately obvious, just as with `Functor` today. This is why`Map` gives you an `fmap` that maps over the values not key-value pairs unlike say Scala's collections. There is a consistency to this that runs bone deep through our culture. The moment the user has this experience it is a teachable moment that leads to an insight that stretches from `base` across most libraries they consume. And unlike before it isn't likely to be quickly forgotten as a curiosity. `Foldable` gives you a canonical way to fold over occurrences the last argument, which is precisely why it must "privilege" `Right`. `Traversable` gives you a canonical way to traverse occurrences of the last argument replacing it parametrically with anything you want, but with Applicative side-effects. If you are looking for a way to get rid of that uniformity, you can appeal to traversals and folds and lenses. Then you can work with the `both` traversal and map easily over both sides of a pair or `Either`, but those step beyond the scope of the Prelude or even base -- and yet they can be built out of building blocks we find there.
&gt; Python compilers will not even check basic things, like that you're trying to call a function that has been defined anywhere at all, let alone for the object you have actually called it on. Survival tip: static analyzers like pylint/pyflakes/pep8 can help detecting the more egregious "undefined" errors. The sight of a complex integration script failing after &gt; 30 minutes of execution due to a syntax error is not a pretty one. 
Any chance you could share some code? I actually have a pretty pressing need for exactly Accelerate + AD, to the point that I'm probably going to do it myself. My main problem at the moment is manipulating DAGs in a type-safe way.
yeah, I know. I simply exaggerated it.
Have you actually programmed in Haskell? Your post seems overly generic and completely misses what's good on Haskell. I mean, your points might be true to someone that has mainly programmed in C++ or some similar language, but I don't think that's the case anymore after you have had programmed in Haskell for a while.
Yeah, the `Foldable` instance for tuples is really sketchy. That seems only useful for writing clever one-liners and it's more likely to cause a runtime failure than actually improve code clarity. Actually, the `Either` instance one makes sense to because it is consistent with the behavior of the `Maybe` instance (which is very handy). For example `Data.Foldable.forM_` is very useful when specialized to `Maybe` and it would be weird for it to break when you switch to more informative error messages using `Either`. We want to encourage people to use `Either` more over `Maybe` and making it API-consistent in terms of `Foldable` is part of that. I could see an argument for removing the `Foldable` instance for both `Maybe` and `Either`, but I think they should both be consistent in terms of either both implementing `Foldable` or neither one implementing `Foldable`. I think it's fine to bias the `Foldable` instance for `Either` for the same reason that we bias the `Monad` instance: it's very handy to use `Either` as a right-based type for modeling failures in the left value.
&gt;If you are looking for a way to get rid of that uniformity Nah, I just think that while it makes sense all in all, that's still a lot of possible WTF moments for someone who just wants to return two values from a function. The whole existence of `Foldable`, `Traversable`, `Functor`, etc, instances for tuples is weird IMHO, and I wouldn't mind having a separate data two-element data type with these instances, if that shed wasn't painted already.
&gt; though of course it’s not finished yet Given that the current release is 797 pages and covers up to Monad, you could make the argument it's more complete than many pre-existing resources. It's not done because we say it's not done. We could've planned to stop at Monad all along and people still would've been pleased, but we're more ambitious than that. &gt;the counter-intuitive (IMHO) results of combining that with some of the instances you now get out of the box that I’m worried about. /u/idontgetoutmuch helpfully posted a few examples of what I mean earlier in this discussion. They're counter-intuitive because people don't understand constructor classes and higher kinded types. But, there's good news - by the time one reaches the Foldable chapter in our book, you will have had this _hammered_ into you. My coauthor, who'd never programmed before and thus has no experience with "Iterable" interfaces understood why those expressions do what they do without a word from me. The mistake is believing we can elide or ignore details we forgot we even learned in the course of teaching other people a programming language. Ed's comment here alludes to what I'm talking about here that must be learned by users of the language: https://www.reddit.com/r/haskell/comments/3okick/foldable_for_nonhaskellers_haskells_controversial/cvyj8d0
&gt;I could see an argument for removing the Foldable instance for both Maybe and Either, but I think they should both be consistent in terms of either both implementing Foldable or neither one implementing Foldable. Please no. I use those Traversable instances. Not infrequently.
I mean if we want to talk about rolling Foldable back up into Traversable, fine, but if people kill my Traversable I'll fork the damn language.
Given the constraints of how Haskell's functor class instances work there is only one law-abiding implementation of `Functor`, `Foldable`, `Traversable` available for each of `((,) a)` and `(Either a)` (possibly upto moral equivalence) and the instances provided are them. In Haskell, the only alternative is to not provide them at all, which would be a shame since they are fairly useful.
If I could vote this up 1000 times, I would do it. 
I think you are extrapolating a little bit much from your one anecdote. I've taught lots of people Haskell (mostly Java/Python programmers) without encountering any of these issues. They see `Foldable` and they just go "oh, okay, it's a collection of some sort, got it".
C is a very fine language. Maybe you're thinking of C++?
I agree that C is a fine language. But that doesn't mean Haskell should be like C. :)
Why not try JavaScript? Seriously, no one needs dynamically typed languages for real programming.
&gt; I know not a lot of people are checking out the Python language. Haskell is still a fringe language compared to Python, so I suspect that many of us on this sub did try Python and many other languages, way before trying Haskell. I did anyway. &gt; Because 2 programmer is better than 1. I will do whatever it takes to bring even one extra programmer. Python is not a fringe language which needs more love, it's a hugely successful language whose user base is many times the size of Haskell's. If anything, it's Python users who should give Haskell a chance, not the other way around! Have you?
&gt; We found the trickiest kind of IO to mock was concurrency (specifically forkIO) and STM. It was possible, but it did mean we had to write a mock thread scheduler — a non-trivial amount of code. This interests me, as I've been working on [testing concurrency in Haskell](http://www.barrucadu.co.uk/publications/dejafu-hs15.pdf) ([the code has advanced a fair bit](https://github.com/barrucadu/dejafu)). Do you just test one schedule and hope that's good enough, or do you test many? if many, how do you choose? The approach I talk about in the linked paper is using typeclasses to abstract over the concurrency primitives and using schedule bounding (specifically, pre-emption bounding) to determine which schedules try. My current approach is a combination of schedule bounding and partial-order reduction with some support for relaxed memory. I actually had a nice little success today with reducing the number of schedules to try, but I'm not sure when exactly it's a sound optimisation, so I need to do some more thinking on that matter... and then write up my algorithm! Because currently the code *is* the algorithm, alas.
I've thought about this further generalization in the past, and asked around here, but it basically boils down to a way to create/preserve structure. For that the easiest way was to create a [Container typeclass](http://lpaste.net/142967) (`csingleton` is not really necessary but it was there for a way to write simpler code) My initial paste on that topic was [this one](http://lpaste.net/123069). As a random insight it seems every time I reference that typeclass I remove more methods from it. I think at this point it could be reduced to a simple typeclass `(Monoid (m a), Foldable m) =&gt; Container m a` with the `empty :: m a` function :)
The best way to get answers about this is to ask erikd on #ghc.
&gt; It's not done because we say it's not done. We could've planned to stop at Monad all along and people still would've been pleased, but we're more ambitious than that. And I’m happy that you are. It wasn’t a criticism, just an observation. &gt; They're counter-intuitive because people don't understand constructor classes and higher kinded types. I think they’re counter-intuitive because having `length (Left 1)` and `length (Right 1)` giving different values is absurd. Having a function called `length` return a value rather than causing a type error here seems questionable in the first place. How often will someone writing that code really have intended to treat a single `Either` value as a `Foldable`, and how often will it just be a mistake when they actually meant `[Left 1]` somewhere several screens away, which unfortunately now type checks? This kind of stretched interpretation causes C++ programs to have multimillion dollar security flaws and makes people write presentations called “WAT?!” about JavaScript. To me, Haskell is attractive partly because it helps to get away from that sort of madness. In any case, it’s clearly arbitrary to have `Left` and `Right` give different answers in this context. The only reason I can see for that inconsistency is pandering to an informal convention about error handling that isn’t acknowledged in any of the actual code that will get written and is barely mentioned in any official documentation that I’ve ever seen. You just have to know it, and that sort of unwritten magic is the nemesis of readable, maintainable code. The convention was itself born of the regrettable failure to establish a distinct and descriptively named result-or-error-value type long ago. Again, one of the things that normally makes Haskell attractive is that it’s so easy to name types for what they really are and to distinguish structurally equivalent but semantically different types. There might be sensible historical reasons for how we wound up where we are, but it’s still not a good place to be. I really don’t see how understanding of either constructor classes or higher kinded types has anything to do with any of this. The result is arbitrary and IMHO the sort of thing we would do well to move away from, not promote.
All true, but fundamentally `Maybe` and `Either` are different. In the former case, `Nothing` and `Just` are asymmetric: one has an associated value and the other does not. Personally I still think having a function called `length` apply to a `Maybe` is awful on general programming principles, but at least there is *some* objective justification for returning 0 or 1 in the two cases. In the case of `Either`, you have one value associated with it whether it’s a `Left` or a `Right`. Having `length` not only accept an `Either` as its parameter but also return 0 in one case and 1 in the other is just completely arbitrary magic. I like your other suggestion far better: neither of these types should be `Foldable` by default in the first place. The perfectionist in me wonders whether, if we’re going to admit changes on this scale, if it might have been worth considering an explicit success-or-error-value type at the same time. In reality, both compatibility and convenience mean that ship probably sailed long ago and the use of `Either` in that specific, conventional way has become a wart that will probably be around forever. But it’s still a wart.
Thanks! I'm not sure I understand the double powersets. The type `μa. (a → 2) → 2` defines the *set of* sets that are isomorphic to their double powerset, or not? Presumably that type isn't inhabited, so there's no contradiction with set theory, or is there? It's also a bit suspect since `F a = (a → 2) → 2` isn't strictly positive, and fixpoints only work for strictly positive functors right? The Church encoding works for all `F`, but the type you get out of that isn't necessarily a fixpoint of `F` unless `F` is strictly positive? &gt; you can never work with standard sets What do you work with instead? Is is true that proving termination of impredicative types is hard, because induction on types doesn't work as nicely any more? How *do* you prove termination? &gt; I like it, though I like it too. It makes you have to fiddle with universe levels less, but the greatest attraction IMO is the ability to define inductive types via Church encodings. Interalized parametricity promises to derive induction principles. You even get some bonus types. For instance when you define HOAS with inductive types you run into issues because of strict positivity. This can be kind of worked around with parametric HOAS, but the Church encoding magically gives you exactly the right thing despite that the functor isn't strictly positive!
So... if impredicativity in Haskell and Coq is the same thing, is it still a different thing from `Type: Type`? If so, what's the difference?
Yes, it's different. With predicative types you have: (forall a:Type(n). a -&gt; a) : Type(n+1) and you have: Type(n) : Type(n+1) Whereas with impredicative types you have: (forall a:Type(n). a -&gt; a) : Type(n) but you still have: Type(n) : Type(n+1) In other words, with predicative types you have to increment the universe level for *both* quantification over `Type(n)`, *and* for `Type(n)` itself. With impredicative types you only need to increment it for `Type(n)` itself, so that polymorphic functions stay inside the same universe level. For instance the identity function on base level types is itself a base level type. In a predicative system the identity function on base level types would be pushes one level up the universe hierarchy. This means that you cannot use that identity function in places where a base level type is required. With `Type : Type` the whole hierarchy `Type 0 : Type 1 : Type 2 : ...` collapses to a single `Type`, so then everything just has type `Type` and there is no difference between impredicative and predicative. This `Type : Type` makes the type system inconsistent: you can now write a non-terminating program without recursion. That's a disaster for proof assistants since they rely on termination for soundness. For Haskell it doesn't really matter, since it's just one more way to write a non-terminating program.
The last paragraph is the key part for me. The state of the world in 7.8 requires learning more if you are using a code base of significant size. If you accept you will have to learn Foldable no matter what, which does seem to be the case if you are programming Haskell for a living, then 7.10 is an improvement.
They shouldn't have generalised "length". The version in foldable should be called "count". As in "count the `a`s in this `t a`".
Very insightful. The names are not as suggestive as one would hope in Foldable. The 'length' arguments below show that. If Foldable.length was Foldable.extent I don't think anyone would care ...
Best description of my experience.
Oh no, not again! It's very simple. Some people like a more monomorphic prelude. Some people (apparently most) don't. Some people want something in between, maybe both monomorphic and polymorphic versions of all these functions. No proposal will satisfy everyone since each has different tradeoffs and people have differing values, but of course we all like to imagine that our opinions and preferences are more weighty and objective than saying "chocolate is my favorite ice cream flavor". In any case, a totally reasonable decision has been made after the issue was discussed to death. I'm still amazed at how much time has gone into this decision. Now I see no new information being discussed on this thread, just the same stuff getting rehashed again with slight variations. Do any of the people still talking about these issues think that the problem is that you just didn't phrase your position in the right way? I think everyone understands each other quite well, there's just some fundamental disagreement that isn't ever going to be resolved due to differing values or preferences. Which is totally fine. At a certain point, there has to be some level of acceptance on the part of people who disagree with the decision---no decision can satisfy everyone, and some people are going to be in a position of disagreeing with the decision.
Yay! I actually have some questions for you, first: * What languages are they most familiar with? The reason I ask this is that this affects what will be the most effective project examples * Are they familiar with functional programming or do they prefer procedural or object-oriented programming? * What sort of projects are they interested in applying Haskell for?
I think better error messages and perhaps better tooling, and definitely better documentation are all very valid complaints about SML. As for "real world language", I think honestly that students who complain about this have got to ask themselves what they're trying to do. If you want to learn how to code up some app, the language you choose to learn is pretty much arbitrary, since if you learn one language, you should be able to learn them all. So, it seems to me that the reason to pick one language for teaching over another is not that it would better or worse prepare students for a job (since it won't), but rather that it will elucidate crucial aspects of PL design (or not). SML is the ideal language for the latter purpose.
&gt; Even beyond types, Python compilers will not even check basic things, like that you're trying to call a function that has been defined anywhere at all, let alone for the object you have actually called it on. Well, sure: In [1]: def watify(name): ...: globals()[name] = lambda x: x + 1 ...: In [2]: watify('wat') In [3]: wat(3) Out[3]: 4 Since modules are also mutable objects, you can do this on a per-module level, too.
You've taken an expression of sympathy and understanding for an objection (not agreement) and contorted it into a weird proposal, set it in my lap as if I made it, and are challenging me to justify your weird projection.
&gt;If you want to learn how to code up some app, the language you choose to learn is pretty much arbitrary, since if you learn one language, you should be able to learn them all. Unfortunately, this is a lesson most students learn some time after their second year of university. We humor them in order to sneak in a few learnings, to lure them into picking up insights they would have rejected at face value.
He consider himself cool??:)
&gt; A 3 month ramp-up time to being productive is on the long side. Anything longer is untenable. The only reason Haskell has a ramp-up time longer than 3 months is because people are learning Haskell in their free time on the side. If you have somebody learning Haskell full-time or professionally the ramp up time is typical of other functional programming languages.
Okay, I'm confused. I don't think that I proposed anything, actually. I tried to answer your question about the objection to `Traversable`, by pointing out that it is essentially just `Foldable` plus a few extra methods, so all the same objections would apply.
How about the [School of Haskell](https://www.fpcomplete.com/school/advanced-haskell) which has lessons at every level?
* C is the most familiar language for most people here, some Java and Ruby, a few people know Scala. * Some people have some familiarity with functional programming, but primarily people are familiar with C-style imperative programming. * I actually don't know that they're particularly interested in specific applications, most of them seem to have become interested after using xmonad. I think it's more of a general interest at this point.
&gt; I think they’re counter-intuitive because having length (Left 1) and length (Right 1) giving different values is absurd. Are you equally convinced that the following is absurd? Prelude&gt; fmap (+1) (Right 1) Right 2 Prelude&gt; fmap (+1) (Left 1) Left 1 &gt;Having a function called length return a value rather than causing a type error here seems questionable in the first place. Tony mentioned earlier today that Scalaz has had Foldable and Traversable instances for Tuple2 and Either for going on 8 years. Seems to have been fine for them. &gt;In any case, it’s clearly arbitrary to have Left and Right give different answers in this context. Can you justify this assertion as somehow being uniquely applicable to the Foldable instance and not also the Functor? You haven't explained why it doesn't make sense. &gt;The convention was itself born of the regrettable failure to establish a distinct and descriptively named result-or-error-value type long ago. The way Haskell type constructors work made the creation of a distinct type for this completely pointless, so rather than introduce a pointless redundancy, people used Either. &gt;Again, one of the things that normally makes Haskell attractive is that it’s so easy to name types for what they really are and to distinguish structurally equivalent but semantically different types. The thing you just asked for a moment ago would be structurally *and* semantically identical to Either. I suspect there's some name fetishism here too. &gt;There might be sensible historical reasons for how we wound up where we are, but it’s still not a good place to be. It's a more considered design than you're implying is the case. &gt;I really don’t see how understanding of either constructor classes or higher kinded types has anything to do with any of this. I mean no offense, but if this is true then I'm not sure you understand Haskell. The ordering of type constructor application combined with parametricity is partly why given a type, I can tell you the _only_ thing a typeclass instance for it could do. You lose that predictability if you start letting the principle-of-doesnt-know-haskell's least surprise dictate your APIs. You couldn't write a different Functor or Foldable for the Either datatype *even if you wanted to*. Consider how the uniqueness of Functor and Foldable instances to a given datatype representation is why they can be derived. You can try it for yourself and understand what I mean. Here's the same datatype (I'm pulling this from an exercise in the book), with different names. Write a Functor and a Foldable that does something other than what Either's does. data Errorable a b = Error a | Success b deriving (Eq, Show) Practically speaking, the current practitioners of a language should have more say in it's direction than past practitioners or hypothetical future practitioners. If for no other reason than that they are more aware of where the pain points are.
There are also those (most?) who desire "an even more polymorphic library", but are happy to settle with at least what is proposed.
You're right, but to be fair, "one or the other" is usually better coded by defining your own datatype.
Do you know if any companies use formal methods? The only time I've heard of them was in a class setting.
To pick on this example, if one hoogles for `[a] -&gt; Int` and gets length :: Foldable t =&gt; t a -&gt; Int I would hope that the name `length` gives away the game. Also, they would get as another result `length :: [a] -&gt; Int` from `GHC.OldList` -- not sure if this is good or bad, but such are the ways of hoogle.
This works great, and I'm intending to introduce it to my older son who enjoys logic puzzles and has been learning some Haskell. I will say that in level 3, it was not always immediately apparent to me what the functions did. I did a lot of trial and error to see what the results of different function applications would be. If there was some more clever way to go about it, I wasn't able to see it. Afterwards, I did have a good time reading the source code and trying to figure out how you put it all together. Thank you. :) 
&gt; rather that it will elucidate crucial aspects of PL design (or not). I know we sometimes forget this, but there _are_ students whose primary interest in programming classes is not the nuances of PL design. Weird, I know :-P
I grew up using Algol 60 ("superior to most of it's successors") in it's Burroughs/Unisys incarnation. I still love Burroughs Algol (though I last used it 30 years ago) . But the Algol68 syntax was incomprehensible to non-PhDs; the grammar phrase "ROWSty ROWS ..." is something that sticks in my mind. The whole report was extraordinarily abstract. Some ideas like "if ... fi", "case ... esac" were absorbed in later languages.
While you're at it, in that same example, the output example is wrong: values = [[1,2,3],[4,5,6]] concat value -- results in Not in scope: `value' ...or you could fix it the other way too. ;)
Yes, to an extent. With ghc-mod (which I use in Emacs), if you refer to an unknown identifier, say, `join`, you get a red squiggle underneath it. If you hit `M-t` on that error, it will offer to import `Control.Monad`. If you refer to an unknown name with a qualifier (eg `M.join`), it will offer to `import qualified Control.Monad as M`. If you have a bunch of messy imports, highlight them and hit `M-s` to sort and organize them. I said "to an extent" because it can't always guess where to import something from. I rely on it pretty heavily, though; it's a very nice feature.
Given that I can have containers for which `sum` is executed in parallel, gets to reuse intermediate results, may work asymptotically more efficiently in O(log n), or even be cached in O(1) whereas the latter is O(n) no matter what? Yes.
Hrm, I thought I had already written a response to this? The wikibook has come a long way since I first started learning Haskell, and I think the people who are working on it are doing a commendable job. Due to the nature of the project, it's not very even, in pacing or quality. Some parts are very good; some parts less so. Honestly I haven't looked back at the earlier chapters in some time, so I couldn't comment on their most recent state, but I found them rough last year when I was starting Haskell. More recently, I've read the Monoid, Foldable, and Traversable chapters of the wikibook and found Monoid quite good, Foldable good, and Traversable a bit confusing. Still, considering how few Haskell books really give Monoid its due, it was refreshing to see such a nice chapter on it. 
&gt; | This is what I find really exhausting about Haskell... every question leads to ten more things that I don't understand. Funny, this is exactly my favourite thing about Haskell!
The traversable instance for Maybe tells you why MaybeT exists. It gives you the distributive law that makes the monad transformer "go" in the first place. for_ maybesomething $ \x -&gt; ... is also a fairly common idiom today. length Nothing = 0 length (Just x) = 1 is even perfectly sensible. The instances are biased because `Foldable`, `Traversable`, `Applicative` and `Monad` all have to work on the last argument.
I figured there was a reason that hadn't been proposed, thank you.
What was a bad idea? Having `Functor` at all? Scala has "unbiased" `Functor`, since you can use a type lambda to define how it works. It is a complete abomination. You can't abstract over it, you wind up passing them all over your code, you have no guarantee that the instance you have is the right one.
Well then shouldn't Hoogle be upgraded to account for instances? The tooling should support the language, not the other way around.
I wrote one long ago: http://hackage.haskell.org/package/fix-imports Not as fancy as some of the newer ones, but I couldn't live without it.
Build data Pair a = Pair a a deriving (Functor,Foldable,Traversable) and it will map over both, because both use the last _type_ argument. instance Functor ((,) x) gets what it says on the tin: fmap :: (a -&gt; b) -&gt; (x, a) -&gt; (x, b) Let's look at the Traversable. sequenceA :: Applicative f =&gt; (a, f b) -&gt; f (a, b) This distributive law lets us push (,) a's inside of any Applicative. (,) is fairly special though. We can even write strength :: Functor f =&gt; (a, f b) -&gt; f (a, b) strength (a, fb) = (,) a &lt;$&gt; fb because every "Functor" is strong in Haskell. I make pretty regular use of these sorts of "surprising" instances that do the only possible thing that they can do.
&gt; When there's multiple possible instances then making a type an instance of a type class shouldn't be taken lightly. Absolutely. However in this situation there is precisely one instance available for each of the situations folks are complaining about here.
&gt; I strongly dislike the bit where useful warnings about future change would be delayed just to satisfy people who want a clean -Wall. With the current plan you'll be able to opt _into_, say, `MonadFail` warnings as soon as 8.0. As for whether 3 years sans warnings is too much, that is also a perfectly valid opinion. If enough people hold forth with that view it may be that we might want to weaken the guarantee to have 2 years without warnings with no CPP and have that third year allow warnings of pending change.
Look at the type of anything imported from Data.List. It's unexpected. 
I've been wondering if there's a good way to hook TLA+ into Haskell. I'd love assistance making sure my implementation matches the assumptions I've made when modeling things.
Testing concurrency by picking uniformly is unlikely to catch anything that's not pretty egregious. I'm not sure that there's no way of biasing your distribution toward more interesting regions of the state space to the point where it becomes useful. I agree that formal methods should be even better, where applicable.
Sure, but there's no need for them to spend 100K going to school to learn this shit if they don't want to learn the science. If they just want to learn how to write the app, they should get an internship at some company or something and spend the money on a house down payment. Teaching students python (or haskell, tbh) at an expensive university is basically a robbery.
&gt; Are you equally convinced that the following is absurd? Prelude&gt; fmap (+1) (Right 1) Right 2 Prelude&gt; fmap (+1) (Left 1) Left 1 Of course it is. The code reads as if the situation is symmetric, but the actual behaviour isn’t. That kind of misleading presentation is undesirable in any programming language and any context, unless you are deliberately trying to obfuscate the meaning of your code. The only defence is experience with the language in question so you recognise the implied convention, but even the most experienced programmers of a language can forget a detail or make a mistake in this sort of situation from time to time. I wonder whether we’re talking at cross purposes here. Just to be clear, it’s not the asymmetry itself that I’m objecting to. My concern in this `Functor` case is the presentation and use of names that *appear* symmetric when in fact they aren’t (and indeed can’t be, given Haskell’s framework where `Either a` is going to be the instance of single parameter typeclasses). You can call this name fetishism if you like, but to me it’s about writing readable, maintainable code. If the type and its constructors are going to read as if either constructor is as significant as the other, I would personally rather be explicit about whether I’m working with the first or second of them or both at once. For example, one could use `first`, `second` or `bimap` from `Data.Bifunctor`, of which `Either` is also an instance, instead of `fmap`. Alternatively, if one of the cases is going to be active and the other passive in order to act as a regular `Functor`, I would rather have names for them that imply this, e.g., data Outcome a b = Aborted a | Completed b or data IntermediateOutcome a b = FinalResult a | PartialResult b As I see it, this is then similar to idiomatic use of `Maybe`, where there is an obvious asymmetry between using `Nothing` and using `Just`, and so it’s clear that any compound operations on such a value must be working with the `Just` case because that’s all you’ve got. As an aside, this has drifted away from the earlier discussion about `Foldable`. There is a second point about whether an instance of a typeclass should be specified by default just because it is possible to do so in a way that mathematically obeys the relevant laws. I’m not convinced this is a good idea with something like `Either`, because it makes it much easier to write incorrect code that type checks as demonstrated earlier. However, if we did decide that allowing folding over `Either` values was appropriate, an analogous argument to the above would apply, and I think it would be better to be explicit about which case(s) were being folded over if the naming and presentation appears symmetric. &gt; The way Haskell type constructors work made the creation of a distinct type for this completely pointless By that argument, isn’t any use of new types with the same structure as existing types for exposition purposes completely pointless? If that’s your view then I strongly disagree. &gt; It's a more considered design than you're implying is the case. How so? Given that in Haskell the implementation details for `Either a` as an instance are forced by the way these typeclasses are specified, isn’t the only real decision to make whether `Left` or `Right` should use the second parameter and therefore be the active case when used as something like a `Functor` or `Foldable`? And then with this naming, it’s just an arbitrary convention again. &gt; Practically speaking, the current practitioners of a language should have more say in it's direction than past practitioners or hypothetical future practitioners. If for no other reason than that they are more aware of where the pain points are. Perhaps, but if it’s a useful goal to expand the appeal of the language and thus grow the pool of practitioners and ecosystem for everyone’s benefit, laying traps is never going to help. Every programming language is different and realistically you usually want to cater to people who have some familiarity with the language, but if you’re going to ignore basic general programming principles and risk misleading readers then I think you need a very compelling argument, and I don’t see one here.
edwardkmett's point is the key one here: the reason Foldable is important isn't because it lets us avoid typing `toList` all over the place; the reason it's important is because it allows us to have better asymptotics than the version with `toList` everywhere. Though, yes, allowing `length` to work on `Maybe` may not be the brightest idea.
Stumbled upon the existence of Haskell very recently from a fellow redditor. In my coding practice I am often accused of being too functional with my programming, don't ask, I still don't get there explanations. My questions are very newb, I believe they may require some kind of background about me, if so, my nickel bio is at the bottom. Anyways my questions: what is the one [or two] things you wish you knew or someone taught you when starting to learn Haskell? what is a good high-level-beginner to low-level-intermediate program to bang my head through? I think it might help to figure out the syntax. nickel bio I am not new to programming, I would describe myself as a die-hard hobbiest. I started with Qbasic over 2 decades ago, moved on to turbo C. Played with them quite a bit. These were already on the first laptop I bought while in Jr high. In high school I covered Visual Studios, VB and C. Since then I have studied various programming paradigms and methodologies. My preferred style/method is to separate functions and states, it just makes it easier for me to understand what I am creating. I am reading through the material at "www.haskell.org/documentation". I am definitely having probs wrapping my head around the syntax, as well as a lack of any states. I can kind of visualize a machine in my head, but can't put it to keyboard.
I think it's just because 20+ years of building Haskell linearly has resulted in a *lot* of cruft. I think if Haskell's intent is to be a "serious" programming language, then it needs a 2.0 to dump cruft, the way that Python 3 dumps a bunch of Python 2 cruft. I don't know that that's a goal of Haskell. Honestly, I think the fact that something like Rust exists and can take all the big wins that Haskell figured out is probably a good thing. That's Haskell winning, that's PL research winning. The good ideas get coalesced into a clean language design that more or less only sacrifices some of the bleeding edge concepts.
Oh certainly, many model checkers more or less do this.
And then tons of code using "count" as an identifier name would suddenly have warnings.
Agreed, it's just so different than other FP
&gt; All of those are examples of what is totally wrong with Haskell now. It doesn't matter if the follow logically from something or other. They are counter-intuitive to most people. Thinking that way, the only way to be right is to be intuitive to most people. There is already Go for that ...
Well, sure. So there must be some idea of how we will avoid those kinds of things in order to use DT effectively in Haskell.
Don't misinform, `cabal freeze` did allow reproducible builds way before `stack` (`stack` is just built around different defaults and with a different UI philosophy) ;-( We rather need tutorials that show how to exploit `cabal`'s features, and optionally also show how `stack` can be used for those who care. Even better, a canonical side-by-side comparision of of how to perform the same tasks with `stack` and `cabal`. I'd bet many would be surprised how little difference there is.
I'm not proposing it actually be changed. But the original Foldable.length shouldn't have been called that.
RWH was a victim of the exceptions transition -- that's a rough one to just paper over with version pinning.
Functor are Foldable are both superclasses of Traversable. There are Functor instances that are not Foldable. e.g. (-&gt;) x There are Foldable instances that are not Functors. e.g. Set There are even (slightly bizarre but interesting) things that are both `Functor` and `Foldable` but not `Traversable`. data Repeated a = Repeated a !Int deriving Functor instance Foldable (Repeated a) where foldMap _ (Repeated _ 0) = mempty foldMap f (Repeated x y) = f x y where f x y | even y = f (x &lt;&gt; x) (y `quot` 2) | y == 1 = x | otherwise = g (x &lt;&gt; x) ((y - 1) `quot` 2) x g x y z | even y = g (x &lt;&gt; x) (y `quot` 2) z | y == 1 = x &lt;&gt; z | otherwise = g (x &lt;&gt; x) ((y - 1) `quot` 2) (x &lt;&gt; z) `Repeated`here gets away with using a logarithmic number of `mappend` calls in `foldMap`, and is trivially a `Functor`, but can't pass the `Traversable` laws. 
For Haskell there's a much more fundamental concept at work (related to the Curry-Howard correspondence) which lets the types determine a large amount of things, including some (at first) surprising consequences. But those latter ones are just an effect of being used to other languages with less principled constructions (although admittedly, `Foldable` is probably one of the weaker ones *when* taken out of context). And as Haskell is without doubt a types-driven language, you can't expect to program in Haskell without assimilating the underlying type-system foundations, which includes getting familiar with Functors, and why `(,) a` is a functor, including everything that follows from that. So comparing the strong type formalism of Haskell to the rather adhoc type conversion rules of JavaScript is unfair.
It's only weird because you seem to see `(a,b)` to be something like a fixed-length `[a]`, even though the types say it's a product-type of two independent variables. You need a different type to model that, like edkwardkmett's `data Pair a` example.
Maybe [Haskell Tutorial for C Programmers](https://wiki.haskell.org/Haskell_Tutorial_for_C_Programmers) could be a place to start?
I can think of an instance for `(a,b)` that maps over the `a` component and one that maps over the `b` component. One of those isn't definable in Haskell: that's what I meant by peculiarities of partial type application, it's an arbitrary choice.
Seconded, they teach Haskell first semester of first year on my CS Uni course and the experienced programmers always struggle with the initial tutorials more than the people that haven't ever programmed. I'm still really happy they go with Haskell first and not python or whatever
A commit "Improve error messages for ambiguous type variables" just landed in GHC HEAD. Maybe it solves your issue: https://phabricator.haskell.org/rGHC7b443bb1df8f7f0a6b3124537590aa655a9300cd
I see, I was thinking about the type wrong :) What do you mean by loss of strong dependent sums? Do you mean that you lose the induction principle when you encode it with a dependent product? But that is the case for all Church encodings, right? The problem is that the type theory isn't aware of the parametricity, so internalizing parametricity might solve this (for all Church encodings).
I think that says more about those concurrent systems than about testing concurrency.
Maybe, but it was systems that had been in production for years. 
While playing around with [reflection](https://hackage.haskell.org/package/reflection) I started to wonder if it would be possible to make some sort of "impredicativity monad" that could de-invert `reify`, as `cont` can't: GHCi, version 7.10.2: http://www.haskell.org/ghc/ :? for help Prelude&gt; import Data.Reflection Prelude Data.Reflection&gt; import Control.Monad.Cont Prelude Data.Reflection Control.Monad.Cont&gt; :t reify reify :: a -&gt; (forall s. Reifies s a =&gt; Data.Proxy.Proxy s -&gt; r) -&gt; r Prelude Data.Reflection Control.Monad.Cont&gt; :t cont cont :: ((a -&gt; r) -&gt; r) -&gt; Cont r a Prelude Data.Reflection Control.Monad.Cont&gt; :t \a -&gt; cont $ reify a &lt;interactive&gt;:1:14: Couldn't match type "a" with "Data.Proxy.Proxy s" because type variable "s" would escape its scope This (rigid, skolem) type variable is bound by a type expected by the context: Reifies s a1 =&gt; Data.Proxy.Proxy s -&gt; r at &lt;interactive&gt;:1:14-20 Expected type: (a -&gt; r) -&gt; r Actual type: (forall s. Reifies s a1 =&gt; Data.Proxy.Proxy s -&gt; r) -&gt; r In the second argument of "($)", namely "reify a" In the expression: cont $ reify a With `ImpredicativeTypes` that becomes: Prelude Data.Reflection Control.Monad.Cont Data.Proxy&gt; let foo = (\a -&gt; cont $ reify a) :: a -&gt; Cont r (forall s. Reifies s a =&gt; Proxy s) &lt;interactive&gt;:16:25: Couldn't match type "forall s1. Reifies s1 a1 =&gt; Proxy s1" with "Proxy s" Expected type: ((forall s. Reifies s a1 =&gt; Proxy s) -&gt; r1) -&gt; r1 Actual type: (forall s. Reifies s a1 =&gt; Proxy s -&gt; r1) -&gt; r1 Relevant bindings include a :: a1 (bound at &lt;interactive&gt;:16:13) In the second argument of "($)", namely "reify a" In the expression: cont $ reify a But even if that worked, I guess that in `Cont r (forall s. whatever)` the `s` couldn't be used anything following it, unlike the `s` in a callback passed to `reify`. I don't know enough about type theory to tell if it makes any sense, but it does feel like it should be possible; all in all, the `Proxy` is going to be used inside callbacks in nested applications of `&gt;&gt;=`, doesn't seem to be that different to passing callbacks to `reify` directly.
I started by skimming through LYAH. It's not great, sure, but it has the basics down, which I wanted first and foremost. Then I started going through the [99 questions](https://wiki.haskell.org/99_questions), exploring Hoogle at every step to 1) get a familiarity with types and 2) see what's available. If there was some sort of tutorial/material which combined these 3, it'd be ideal for me. YMMV. PS. I had the same imperative/oo background, but I also had experience with Erlang.
is it really a *choice* though if only one way is supported by the language?
Technically both of them are definable in Haskell, but you need a VERY general notion of a Functor that goes far outside of what any Haskell language standard is likely to allow in the next decade. https://github.com/ekmett/hask/blob/master/src/Hask/Category.hs#L303
By this token you are advocating for a world without Monad, because that 'arbitrarily' chooses the last argument. Scala works precisely the way you advocate here. You can write various functors for products. You just have to tell it which one you want when you go to invoke them by picking a type lambda. Having used it extensively I'm much happier here with inference that works.
For unqualified import, does it put the symbol into the import list? E.g., import Control.Monad (join) That's very important. It's much harder to maintain modules where you can't immediately see where each non-Prelude symbol is coming from. But that adds some busy work to maintaining the import list - so a perfect opportunity for tool support.
Only affects qualified imports - but for that, it looks nice. Thanks for sharing.
Back when we implemented the Foldable/Traversable Proposal we generalized the combinators in Data.List because upon scanning the bulk of hackage it was vastly more common to import `Data.List` to get at `sort` than it was to try to call its version of `foldr`. Of course there was no reason to call its version of `foldr` before, so that i almost vacuous, but there was a _lot_ of code out there that just blindly import Data.List unqualified to do things like that and then would get the `foldr` from Data.List in scope as well. When it was the same as the one in Prelude, then this didn't hurt anybody. Once the one in Prelude generalized a lot of code would have broken had we not done that very uncomfortable generalization during the initial FTP release. FTP as released caused almost zero measurable breakage. Unfixed AMP instances seem to have accounted for more than an order of magnitude more work -- by way of comparison -- but had we not done this then the FTP breakage would be the larger of the two by an almost equally large margin. Now, when we did that release we put forth that it was a transient state, and that we could either a.) remove them entirely after a suitable deprecation period or b.) someone who wanted to keep them could come up with a plan that would mitigate the damage of ungeneralizing them. e.g. a language pragma for weak imports that they could try to win the community over on through the usual process or even c.) we could just say 'screw it' and ungeneralize the ones in Data.List and anybody who used the module unqualified (most users) would just start getting conflicts on the import of those combinators. None of these options are particularly good, but a.) has the benefit of being simple and getting rid of the uncomfortable status quo. b.) could be made to work but would require someone to do some serious lobbying and some minor engineering work. c.) would make those who are upset about the loss of a canonical home for those combinators happier, but comes at a pretty steep tax in terms of breakage and gives up the "nothing in `Prelude` conflicts with anything else in `base`" rule. -- That said, we already break that for `Category((.),id)`.
Can you elaborate on why I'm advocating a world without Monad?
I have had success building a 7.10.2 cross compiler according to this description: https://github.com/ku-fpg/raspberry-pi/wiki/GHC-Cross-Compiler-for-Raspberry-Pi. 
We were very concerned about taking new names in `Prelude` that we didn't have to take. It impacts everyone if we take a new name and we can't see all of the code out there. AMP came into base with warnings, but even those warnings missed a few names and the new names there caused a fair bit of breakage. We've also had about 10 different suggestions for names for this combinator from `cardinality` to `extent` to `size` to `count` -- just in the last 24 hours. ;) No choice here makes everyone happy.
Agreed, my post (sibling to your, sorry) tries to argue why I mind not having that separate datatype, and why that'll come bite us in refactoring.
Have you seen Michael Walker's [dejafu library](http://hackage.haskell.org/package/dejafu)? It aims to systematically test all potentially problematic schedules. I think he gave a talk on it at Haskell Symposium this year
&gt; When there's multiple possible instances then making a type an instance of a type class shouldn't be taken lightly, especially when the type and the type class are common. Yet the objection you use to back that up is that you don't like the positional nature of `Foldable`, but `Monad` is just a "positional" in that it uses the last argument. We have an `instance Monad (Either a)` that makes "arbitrarily" over the second half of a sum, because it is the only thing it can do. It turns out to have all sorts of theoretical justifications, but the choice of biasing over the second argument is just as arbitrary as the other things you are complaining about above and yet just as forced by the types to do the only thing it can do. You could write all the combinators to make a fake monad over the first argument of a pair, but you can't abstract over it with the existing class. In scala you can `flatMap` over either projection of an Either, but because of the nature of how it is done you can't abstract over it and treat `Either` like any other monad, because there is the constant source of ambiguity. In the name of flexibility they gave up consistency and usability.
Looks much nicer, yeah!
https://ghc.haskell.org/trac/ghc/wiki/Prelude710/FTP#list covers that issue as part of the FTP. Data.List is included in the Haskell Report (as PreludeList but then the hierarchical modules stuff moved it). It is the place people go to get combinators like `sort`. It imports unqualified cleanly and people have expected it to do so for a very very long time. A naked import Data.List is a common sight in Haskell code across all of hackage. The major cause for concern was that the amount of breakage that would have been caused by leaving those monomorphized and incurring conflicts with the newly generalized Prelude combinators _vastly_ outweighed the damage from everything else in 7.10. Importing Data.List to get `sort` would now spontaneously break 2 dozen other combinators. I'm very very open to concrete proposals for how to fix the status quo. Removing the redundant combinators entirely, trying to build a language pragma to fix them, even figuring out a migration plan where we slowly tell everyone they must absolutely import Data.List qualified and treat it like they do Data.Map which similarly dumps all over the namespace are all viable options to a greater or lesser degree. Right now GHC.OldList exports the monomorphized versions of the combinators as a stopgap.
Ah, I thought you meant that I was arguing for a world without Monad at all. Indeed, I don't think Either should be an instance of Monad. The type system is there to prevent mistakes, and all these instances allow things to type check that might be mistakes. A better solution imo is to not make these instances for products and coproducts, but instead introduce newtypes like `Error e a` to be explicit about it. The `length (x,y) = 1` smells like Javascript: when given the choice between doing *something* and raising an error, just do the something. This is also why -rectypes is not on by default in OCaml: it makes things that might be mistakes type check. If Haskell used a generalization of Functor that treated both arguments of `Either a b` and `(a,b)` symmetrically then that would be neat because at least that's not arbitrary, but it doesn't...
I had to learn python while writing a two week project at uni, it was easy and not very exciting. I haven't had a reason to use it since. I often rate programming languages by the new things it'll teach you. Haskell obviously rates high on that list. Python is probably at the bottom. I can't think of anything it includes that I haven't already learned from other languages. If you know ruby, javascript, or perl you are likely to find python cleaner but less expressive. If you are stuck with picking a dynamically typed language and you aren't writing browser client-side code (and don't want server/client code sharing), maybe it's a good choice.
If they're experienced programmers I think they could start straight on the NICTA course after some syntax explanation
I'm not sure if I understand any more what was I thinking when I started to complain about unintuitive folds and fmaps, but thanks for taking time to explain it anyway.
 type String = [Char]
It's too late. In my opinion FTP went in prematurely, but I'm not sure backing it out is feasible. With some more time I think we could have come up with something a lot nicer. For instance, I'm highly sceptical about Foldable and even more so the kitchen sink of methods in it. IMO, all those methods should have been in a subclass of Foldable, which would not have been part of the Prelude.
Modelling the system in a way: &gt; We find this rigorous "what needs to go right" approach to be significantly less error prone than the ad hoc "what might go wrong" approach. That was a good read. It was not too detailed about the language but still showing pros of choosing TLA. In my opinion this is a good reference on how to sell the haskellish language to managers (but I might be wrong; I am not a manager nor a Haskell expert). EDIT: typo
and yet beginners are told early on to avoid String for any serious work except homework exercises...
I've updated the article based on all of your remarks, and added some more explanations about type definitions etc, for people new to Haskell. Thanks everyone!
A current discussion I've been having with Herbert around a Report-friendly form is to consider standardizing possibly something just as minimal as: class Foldable f where foldMap :: Monoid m =&gt; (a -&gt; m) -&gt; f a -&gt; m class (Functor f, Foldable f) =&gt; Traversable f where traverse :: Applicative m =&gt; (a -&gt; m b) -&gt; f a -&gt; m (f b) and stating in the language of the report that implementations are free to move additional members into classes as an explicit permission to allow for efficiency concerns, or backwards compatibility concerns. (This caveat would cover the fact that importing Traversable(..) may bring in other stuff you aren't expecting.) Then those other methods could be considered effectively a GHC extension. This would give Haskell implementations a good deal of flexibility in how much they allow you to overload the derived operations. On the other hand, every time one of them lets me run a generic operation in O(1) or O(log n) compared to the naive implementation I'd be forced to maintain in parallel with the super-fancy subclass version you'd prefer, I find I don't feel so bad about the status quo.
The problem is that had that gone into 7.10 we would have had rampant performance regressions across the board. GHC isn't smart enough to optimize code written with that small set of base combinators well, and there are issues about the fundamental choice of default folding order for certain combinators that will need to be tackled in time for a Haskell Report. e.g. left folds vs. right folds in certain places, standardizing a form of foldl', trying to fix `sum` so it isn't so godawful stupid, etc. 
Ah, I got the solution myself. It seems that I needed to do a export DYLD_LIBRARY_PATH=/usr/local/lib/mariadb/ to add it to the search paths for dylds and it seems *stack* isn't forwarding env variables like *DYLD_LIBRARY_PATH*. I noticed because I tried to run the *hsc2hs* generated executable manually and it worked as expected. Is this intended behaviour for stack? 
fixed both!
fixed
That's why I suggested putting all those extra operations in a subclass, which would have been in a non-prelude module. Yes, it would have made it a little more cumbersome to use the efficient operations, since you'd have to avoid the name clash. (But exactly what should have been done should have been discussed for longer in a larger forum.)
I love the idea of more alternate preludes, and this one in particular looks like it hits a great "sweet spot" in adding lots of convenience without any dependency bloat. I wonder if anyone would be interested in a similar package, but exporting monomorphic (list-specific) versions of functions instead.
And the function-specific version of `.` and `id`. But yeah, I like alternative preludes as well. While we're on this topic, I've thought about one that exports everything from transformers as well.
I'd prefer using mtl, but I like the idea. The great thing about an alternate prelude is that if we disagree about which version to use, we can just have two different packages
PRs welcome I'm sure :)
I also contacted Michael and use the ide in a similar manner. I have other projects I want to work on but this seems useful to the community. My first goal would be to support the latest LTS and GHC. Upgrading to GHCJS seems more involved.
Or someone could just make a `prelude-builder` program, which allows you to choose from different predefined groups through some sort of graphical interface, allowing a combinatorially explosive possibly of alternate preludes. But more seriously, yes I totally agree with your statement about different having preludes for people for different preferences.
This is almost what I created [`base-noprelude`](http://hackage.haskell.org/package/base-noprelude) for... if the `BasePrelude` module was named `Prelude` instead, you could simply depend on `base-noprelude` and `base-prelude`, and have it working rightaway :-)
Building on insanity, we should just have one package with a separate module for each possible choice. I look forward to import PreludeFoldableNoTraversableArrowApplicativeSystemIONoEnvironmentPreferLists
We have a custom prelude that tries to hit this "sweet spot" without exporting *everything*. I could share the import list if people are interested.
You can't use point-free style in this case because you need the input character twice. A correct example would be: takeWhile (\c -&gt; isDigit c || c == '.') Technically it is possible to rewrite in point-free style but that's not something one would come up with easily: takeWhile (liftM2 (||) isDigit (('.') ==)) (Generated through [pointfree.io](http://pointfree.io/))
Man. This is what I need! 
I think that Alex's solution is definitely the right way to go, but just to give an example of the applicative instance for `-&gt;`: takeWhile ((||) &lt;$&gt; isDigit &lt;*&gt; (=='.')) But this is less readable and tends to be harder to maintain.
Yes, it does.
If you mean because of e.g. `Foldable`, they'll be disappointed: one of the reasons we created it was to have that available more easily, so it's similar to base-4.8+some stuff. It even has generalized `id` and `(.)`. I was affraid that would cause problems initially (and we had two options, one monomorphic and one polymorphic) but we never had problems. Here's the import list: import Prelude.Compat hiding (id, (.)) import Control.Applicative import Control.Arrow (first, second, (&amp;&amp;&amp;), (***), (+++), (|||)) import Control.Category (Category (..)) import Control.Monad hiding (forM, forM_, mapM, mapM_, msum, sequence, sequence_) import Control.Monad.IO.Class import Control.Monad.Trans.Class import Data.Char hiding (GeneralCategory (..)) import Data.Data (Data (..), Typeable) import Data.Either.Compat import Data.Foldable.Compat import Data.Function.Compat (on) import Data.List.Compat hiding (all, and, any, concat, concatMap, delete, elem, find, foldl, foldl', foldl1, foldr, foldr1, mapAccumL, mapAccumR, maximum, maximumBy, minimum, minimumBy, notElem, or, product, sum) import Data.Maybe import Data.Monoid.Compat (Monoid (..), (&lt;&gt;)) import Data.Ord import Data.Traversable import Data.Tuple import Data.Time (FormatTime, NominalDiffTime, ParseTime, UTCTime, addUTCTime, diffUTCTime, formatTime, getCurrentTime, parseTime) import Data.Time.Clock () import Data.Time.Locale.Compat (TimeLocale, defaultTimeLocale) import Safe hiding (abort) Giving credit where it's due, this started from a custom prelude from Better (now sadly gone).
But the monad instance is very useful!
But then it wouldn't be obvious to the readers of your code what was in scope
Yes: &gt; takeWhile ((liftM2 :: _) (||) isDigit (('.') ==)) Found hole `_' with type: (Bool -&gt; Bool -&gt; Bool) -&gt; (Char -&gt; Bool) -&gt; (Char -&gt; Bool) -&gt; Char -&gt; Bool &gt; :t liftM2 liftM2 :: Monad m =&gt; (a1 -&gt; a2 -&gt; r) -&gt; m a1 -&gt; m a2 -&gt; m r a1 ~ Bool a2 ~ Bool r ~ Bool m ~ (-&gt;) Char
I don't agree and I can't imagine many will. While your point about the confusing nature of the Monad-instance is perfectly valid criticism, simply removing the instance won't solve the problem. There's two cases: 1. people don't use fmap, &gt;&gt;=, return, etc. for tuples. In this case, the confusing implementation is no problem. 2. people do use them, but they want more intuitive implementations. The problem is that straightforward implementations don't exist. Tuples are heterogeneous, therefore you can't have, say, a generic fmap for them. What would it look like? `fmap2 :: (a1 -&gt; b1) -&gt; (a2 -&gt; b2) -&gt; (a1,a2) -&gt; (b1,b2)` for two-tuples? `fmap3 :: (a1 -&gt; b1) -&gt; (a2 -&gt; b2) -&gt; (a3 -&gt; b3) -&gt; (a1,a2,a3) -&gt; (b1,b2,b3)` for three-tuples, and so on? It's the same for `foldr`, where you'd have to pass a folding function with a type like `Either a1 a2 -&gt; b -&gt; b` to actually fold over all elements. The only function that has a reasonable implementation for tuples `length`. The more modest idea of removing it from `Foldable` might be interesting, because it really does return results that can reasonably be considered wrong. Perhaps one could introduce a `Size` typeclass specifically for it? Or maybe one could just rename `length` to something like `foldLength` to make it clear that it only returns the number of folding operations that will be performed, not the number of elements in the data structure, which is different concept.
The changes that FTP is making are a good start, whether people are happy about them in the short term or not. It's a bandaid rip moment. I *think* everyone acknowledges that if it had been this way from the start, it'd be the right way to do it. But the below mentioned String is another one. I'd also personally say that the overwhelming number of compiler extensions is seriously intimidating and you really cannot just go and read code out in the community without understanding a decent chunk of them. There's also cruft not in the language itself, but in the ecosystem. For one, documentation is spread *everywhere* for the language. You have to go to blogs, two separate wikis, module documentation pages and reference manuals to get a complete view of many common subjects. Haskell's libraries are also a confusing miasma to try and understand. People just don't seem to like picking winners and that is a serious detriment because it means repetition of work and a hard time understanding when something has fallen out of favor. But like I was saying, I don't know if this is avoidable and I don't know if it needs to be fixed or anyone wants to fix it. I'm personally 100% happy with the arc of programming right now. Things are finally getting better after hovering around the C++ local minima for damn near 3 decades. If Haskell keeps forging on ahead and new languages creep along behind it coalescing and cleaning up, things are going to be really great.
What's wrong with LYAH if you're an experienced programmer? Seems a perfectly good introduction, after which you can move onto creating things looking up new concepts as needed.
I can see *some* value in having it being a Functor (because I've used that instance some times). But I do not see the reason for pair being Foldable. Would like to know the reasoning behind that. EDIT: As for being a Functor, you can see the pair (`a`,`b`) as being a value `b` with a context `a`, so that's reasonable, I think.
I know they are used in some safety-critical systems. For example Airbus use them to verify their flight control software. [This paper](http://vsr.sourceforge.net/fmsurvey.pdf) surveys examples from a number of industries.
You're right. I'll fix it.
Awesome. Thanks. Still quite the newb in Haskell and programming in general. Since Im working with doubles I will only keep going after a first '.' Im thinking some sort of helper funktion that recursively goes thru a list, taking numbers as long as they are numbers and when it hits a '.' It will use isDigits on the rest. Any thoughts or tips on this?
Sounds nice. I'll take a look.
Not just yet, but I might in the future once my thoughts here are more organized.
&gt; No choice here makes everyone happy. We need absolute value special syntax ;P | [] | = 0 | x : xs | = 1 + | xs |
I'm pretty sure that they're tricky enough to run into that you won't in practice. Russell's paradox is hard enough to trip over by accident; Girard's paradox is a supposedly _clever_ port of Russell's paradox to the type layer, so I assume it's even harder to stumble upon.
We also use typeclasses to abstract over the concurrency primitives. We have an Arbitrary instance for possible schedules, so we can use QuickCheck to test many. I did not write the code, but looking at it, it looks like threads are scheduled randomly. I haven't looked into schedule bounding or partial-order reduction, but they look like interesting topics that I will have to look into more. Thanks for sharing!
what are "formal methods" here? like you read the code very hard? use STM? theorem provers?
There's the writer newtype..
Just use _2 which is clearer and works with other tuple types and can be replaced with _1, etc.
I can't use that with sequence? And I don't want to depend on lens?
Thanks, that makes perfect sense!
I like the Bifunctor instance for `(,)` a bit better than `fmap`ing over `(,)`s
I wish people had talked about this before the vote. I voted in favor of FTP because it seemed perfectly reasonable and the only reason I saw put forth by the "no" camp was "it will be hard for beginners to learn because of the type signatures and error messages". That was entirely unconvincing since I have experience telling me otherwise. But these instances that allow bugs to type check are a much more compelling argument, and I would have voted no if I had been aware of them at the time. Things like this and: Prelude&gt; length $ lookup 3 [(3, "hello"), (5, "world")] 1 Are a pretty serious problem.
Also ubiquitous function composition + ubiquitous concurrency + better performance.
I think this example has helped me understand how the crazy reader-based point free code works,and why it comes up so much. 
That only makes me skeptical about the Traversable instance as well :)
I think `Traversable` is far more widely understood in the Haskell community than `lens`.
I wrote a little bit about the predicative hierarchy in axiomatic set theory and type theory in [this blog post](http://liamoc.net/posts/2015-09-10-girards-paradox.html). I'd appreciate a more knowledgeable person going over that if they get time.
You can't have impredicative polymorphism because it ends up requiring something like Type : Type, which violates Girard's Paradox. With inductive types, you can even encode russell's paradox, which I wrote up in [this blog post](http://liamoc.net/posts/2015-09-10-girards-paradox.html). Edit: I realised that you already know this. You were asking about the more fine grained example where quantifiers don't bump up the universe level but you still have the hierarchy. I still think you end up needing Type : Type, but I can't think of an example at the moment.
I would make a custom generator for a newtype wrapper around Char. You can google for how to do it.
Rather than this rather drastic cut, simply do a little renaming: foldLength :: Foldable t =&gt; t a -&gt; Int length = foldLength :: [a] -&gt; Int This replaces "`length (3,4) = 1`, `length (Left 'c') = 0`. Wat?! Haskell is _insane_." with "`foldLength (3,4) = 1`, `foldLength (Left 'c') = 0`. What on earth is happening when you fold tuples and Eithers?", which is actually a sensible question.
I agree. There are some very interesting/subtle examples in LYAH, and lots of exposition about the mindset of Haskell. 
I have the same problem with LYAH... (I don't dislike it, I just found it hard to make progress in learning Haskell with that style of delivery) and I find the [Haskell wikibook](https://en.wikibooks.org/wiki/Haskell) to be pretty great. Underappreciated, even.
&gt; As for being a Functor, you can see the pair (a,b) as being a value b with a context a, so that's reasonable, I think. Having come that far, it already makes sense that the length of that value is 1.
Pattern-matching and tupling up again is even more widely understood :) What are you optimizing for?
But this is beautiful, and what I wanted to write. I'll concur if you mean the lamba is more straightforward, but not if you prefer liftM2 to this.
This is awesome, thank you!
...or prop_convert c = isAscii c ==&gt; convertToCapital c == toUpper c
Ah. At some point after I made this comment, it looks like Alex amended his answer to include a point-free version with `liftM2`. I agree with you that the applicative operators are much more beautiful than `liftM2`, `liftM3`, etc.
This is a really good choice - it helps with the cultural change and makes a bridge from existing understanding to new ideas.
&gt;If they're experienced programmers I think they could start straight on the NICTA course after some syntax explanation cis194 -&gt; NICTA course is still the recommendation even if you're an experienced programmer because you're not going to have an instructor on hand for NICTA. Going straight into NICTA by yourself is *hard*. I've only known a handful to succeed in completing it that way without relying on other resources.
This is a good list, I also had a couple people ask about concurrency, which I don't know much about, but I have an order in for Simon Marlow's book which I hope will help. It seems I've agreed to give a series of lectures to the office now, so any material you've used to do something similar would be great.
I've only skimmed the paper so far, but I wanted to chime in and say that I really appreciate that *somebody* is saying *something* about the overloaded term "type". Starting off in software engineering, I really wanted to understand what was up with types. Figuring that out took a lot longer than in retrospect I think it needed to because it turns out whenever anyone talks about "types" they have something very specific and very unique in mind. Dynamic types in Lua are different than dynamic types in Ruby and what dynamic types are doing is very different from what C#/Java is doing which is very different from what Haskell/ML are doing. Additionally, if you look at Haskell/ML or Idris/Agda what their types are doing is different not from a definitional[1] point of view but from an implementational[1] point of view. Long story short: If there was more effort to differentiate between different usages of the word "type", I think at least 90% of internet arguments about them disappear (assuming people would otherwise be intellectually honest) and I probably get to cut 6months to a year off of my journey about learning about programming languages. [1] - Imagine a lot of hand waving from me about what those terms actually mean in this context ... The theme between haskell and ml is very similar but you get weird differences between the two once you start annotating types ("blah :: a -&gt; b -&gt; a" type checks differently in haskell than ocaml, but only if you annotate).
I hope that some day I can feel the same.
Thanks for the suggestion! I've looked into them, but haven't fully tried it. I will give it a spin again. Debugging this kind of bugs is very difficult. I tell the story more if it may be helpful to anyone who are interested. ;-) Previously, when directly calling haskell from java and calling java from haskell using JNI in threaded runtime, the app crashes after a few or tens of seconds. Crash happens earlier if I manually call performGC, so I suspected that this was related to GC thread. When this problem happened, the android log system left only very blunt messages from ghc_worker, like SIGSEGV or SIGABRT.. Since android does not allow app to shout using stderr, I had to modify ghc rts code to use __android_log_write (by calling it using dlsym from dynamic log library. This has another long story). It's a little progress in error reporting, so that now I see that the error happens when doing some STM operation or some storage management in garbage collection, it is still unclear what's going on. Now as a workaround, I just separate the thread for hs_init from java thread using manual pthread creation, and it looks okay. Somehow android runtime deals with threads created from java runtime with rather special rules on thread local storage or some thread interruption, but I cannot figure it out. In fact, having guaranteed separate threads for haskell and UI runtime is not a bad idea at all, for stability and for portability. So now I am formalizing this approach with appropriate UI monad abstraction which can be described as a free monad with allowed operations, and C backend posts syntax trees accumulated on haskell side to UI thread. (every UI library has a method pushing a function call to UI thread. android has runOnUiThread ) 
Nice to see Haskell in production here in London. Do you follow any methodology to track space leaks? Are you planning to present some of this stuff in a meetup here in London? :)
(Should probably be "blah :: a -&gt; a -&gt; a" instead of "blah :: a -&gt; b -&gt; a" which I would expect to type check identically in both ocaml and haskell)
&gt; Do you follow any methodology to track space leaks? I think that'll come in their next post they mentioned which'll be about space. In the meantime, another UK Haskeller has written a fair bit about this: - http://neilmitchell.blogspot.com/2015/09/three-space-leaks.html - http://neilmitchell.blogspot.com/2015/09/detecting-space-leaks.html - http://neilmitchell.blogspot.com/2013/02/chasing-space-leak-in-shake.html 
The complaint doesn't seem to be about explaining things to beginners, rather about having to be more careful while refactoring because common data transformations will not yield a type error -- rather compile with corrupted data as a result. That is pretty bad.
A non-monadic solution would be something with `all` and `foldl (||)`, I guess?
Well that's good to hear. The whole setup seemed a bit insane to me at the time, I guess I must have missed that part.
List is an abstract data type that's not particularly well defined. It can be implemented with arrays, linked lists, binary trees or any other concrete data structure. Python lists are backed by arrays, like Javas ArrayLists, that is correct. Clojures lists are backed by trees of arrays. Haskell built-in lists are backed by linked lists; though there are libraries providing alternatives.
But a 2-tuple doesn't have a length of 2. It has a size of 2 which is a different kind of thing. It's length is 1 because it "contains" 1 thing (the right value). If we somehow made `length (1, 2) == 2` we would just be punting the problem. Next the person will want `fmap (+1) (1, 2) == (2, 3)` which should never happen. I would say could never happen but in theory in some alternative universe a special instance of `Functor (,)` for `(a,a)` could exist but it would be a terrible thing to have.
I think there's merit in this. I can see myself making careless mistakes akin to this: maximum (1,2) 2 maximum (2,1) 1 
From my work monorepo: [callen@boura ~/work/CENSORED feature/CENSORED] $ ag -G .hs "String" | wc -l 4401 TIL my work isn't serious :( For fairness' sake: [callen@boura ~/work/nope feature/nope-nope] $ ag -G .hs "Text" | wc -l 1343 [callen@boura ~/work/nope feature/nope-nope] $ ag -G .hs "ByteString" | wc -l 2961 
&gt; People are using lens because it's good, not just because they can. I do some pretty typical, boring software work for a living and `lens` is indispensable to me for killing off redundancy.
if i'm not mistaken :-) the adjunction is between C x - : C -&gt; C and (-)c : C -&gt; C , means between ProdB : A -&gt; A x B and ExpB : A -&gt; (B -&gt; A) and the functor instance for this product maps over the first param instead of the one defined in Haskell (,)e :-)
But I agree totally with your argument related to Foldable
I would say that most often, in my experience, the word "list" is a contraction of "linked list", though certainly in Python, the reason the word "list" refers to an array is because "list" is the ADT and "array" is the data structure. Also, when "list" refers to an ADT, it's often (though e.g. obviously not in Python) considered a slightly different ADT than "array" as an ADT - as with that "Hashed Array Tree" data structure I already mentioned. We could argue all week about word definitions, but of course they're are some slightly varied definitions based on context - different language standards, different academic papers, sometimes even different textbooks have different definitions. In particular, the difference between the "list ADT" and the "array ADT" is IIRC mainly about performance guarantees, which by at least some definitions aren't an aspect of an ADT. TL;DR = linguistic determinism - [down with this sort of thing](https://www.youtube.com/watch?v=gT9xuXQjxMM) My real point is that, like most languages, Haskell has both arrays and lists, so it's misleading to claim we use the term "list" for arrays - easily misinterpreted as meaning we don't have "real" arrays - and the usual blanket term is "sequence". 
Indeed that is the usual formulation. Fortunately we're in a symmetric category, being Cartesian, so we can work the other way. We wind up forced into a few fairly backwards conventions from a categorical point of view. e.g. our profunctors have the distributor style ordering, rather than what you'll find for profunctors in ncatlab. I do define the usual adjunction: https://github.com/ekmett/hask/blob/master/src/Hask/Adjunction.hs#L16 but because we're bad at abstracting over things like this non-positional stuff" I define the currying adjunction separately: https://github.com/ekmett/hask/blob/master/src/Hask/Adjunction.hs#L29
If you don't annotate in haskell the type of "blah a b = a" (recognizable as "const") is "blah :: a -&gt; b -&gt; a". However, if you annotate with "blah :: a -&gt; a -&gt; a" then the type of your first parameter and second parameter must be the same ("blah 1 'input'" works in the first case and fails in the second case). However, ocaml seems to use type inference only (any annotations you use are only used as naming hints). So "let blah (a : 'a) (b : 'b) = a" actually has the type "blah : a -&gt; b -&gt; a" [1]. And "blah 1 'input'" works regardless. Okay, if you read my footnote you'll see that as of latest ocaml (4.01.0) what I'm saying isn't true of ocaml. However, it's not hard to imagine a language such that this is true and it's an okay decision to make if you don't want GADTs or some other interesting language features. The point is there's a lot of decisions like this you can make in the implementation of your type theoretic based type checker (for example agda has homogeneous equality and idris has heterogeneous equality I think) and it changes how people are able to use your language. So you can't just say "we use static types" or "we use a real type theoretic type system" and have a clear picture of what reality looks like for your specific instance. [1] - Interestingly enough I just tried this with ocaml 4.01.0 and it actually works the same as haskell. (I might try to dig up the version of ocaml where this works the way I'm saying here later if I get the opportunity).
Yes we are going to be looking at memory profiling in part two. We plan to cover space leaks, as well as looking into GC profiling/tuning. I was asked to give a London Haskell talk about the work we are doing at Pusher during the Haskell Exchange last week. I would be keen to do this, although I haven't decided on the exact topic yet. I do find this optimisation stuff very interesting, so that's definitely a likely option!
Tweeted it for you, good luck in the search! :)
very interesting !!! Is there any good resource / tutorial for learning / developing intuition for that ? 
The `adjunctions` package provides a boring * -&gt; * only version but _all_ possible instances in there look like the (,) e -| (-&gt;) e adjunction in disguise since every other adjunction from Hask to Hask is isomorphic to that one for a suitable `e`.
https://twitter.com/bitemyapp/status/654397656429629445 RT if ya want :)
Just for reference, fmap2 has a name: `:t bimap` `Bifunctor p =&gt; (a -&gt; b) -&gt; (c -&gt; d) -&gt; p a c -&gt; p b d` 
I'm 100% in favor of increasing the political consciousness of programmers *in general*. But I think if we want to increase that political consciousness, associating political factions with programming and programming-language factions seems like a terrible idea, counterproductive for everyone involved. If a certain paradigm or technological methodology became associated with a certain political ideology, people would probably allow their opinions about one to influence opinions about the other. Since in fact they have no meaningful relationship, this will decrease the accuracy of people's decisions on both sides. EDIT: It occurs to me, a bit later, that I should specify that *some* technological ideas, like how to manage teams or whether code should be open source, absolutely do have a relationship to politics. This just isn't one of them.
Not sure which language I was thinking of that behaved the way I described ocaml behaving with respect to the type annotations, but it doesn't appear that ocaml ever behaved that way. I think my point is still vaild, but please note that I was not correct about the specifics of ocaml type checking.
Hmmm. If `P(x) = 1` then the pair `(x:A,1)` is essentially just `x`. That elimination would let you show that `Σ Type P = Type` pretty much, so then you'd have `Type : Type`. Is that the idea? You wouldn't literally get `Type : Type` but rather `Σ Type P : Type` but maybe it's still good enough to make Russell's paradox fly? I'm not entirely sure what precisely is going wrong here.
While remote work is possible, where are you located?
I'd also like to know
I am confused by this thread. base defines no Monad instance for ((,) a), but everyone seems to pretend it does.
Very happy to see a shout out to `profiteur` which is amazing.
This is now at https://github.com/syl20bnr/spacemacs/tree/master/layers/%2Blang/haskell
Unclear whether remote work is existentially or universally quantified: "there exists remote work" or "all work is remote".
Has it? I'm not at all involved in that community.
Ooops, that should be paging /u/snoyberg.
It runs on windows server. But our backend applications run on linux.
And most people would think that `[[1,2],[3,4]]` contains four things. I can even count them. That doesn't mean that the length is four. Similarly for `[(1,2),(3,4)]`. Both have a length of 2 and I doubt there is any argument there. The reality is that `Foldable.length (1,2) == 1` cannot be anything else without making it incredibly confusing. Sure the fact that `length (1, 2) == 1` is a little confusing but it is a small price to pay. Also it might cause someone to stumble on the `Functor` instance of `(,)` which is actually really useful.
Well, just to be clear the last gap was 18 years, so 3 is downright timely. ;)
It is a little exhausting for me to verify how the advice of people with the greater experience in Haskell, implementing , teaching, in academia and in industry all of them questioning the the changes is contested by relatively newcomers who apparently know it better. I think that a big change in the composition of the haskell community has happened a few years ago simultaneously with the gain in popularity, and this change is not the one that I would expect: it is not towards a openness and popularization of haskell, on the contrary, is a drift towards relatively marginal and aesthetic things that have little impact, like folding ( EDIT: or lensing by the way), instead of solving real computing problems that happens out there in the impure world of IO. It is surprising how much effort is devoted to bike shedding. I would have much more to say, but I will leave it at this point. whoever want to know, drop me a private message.
I think you can understand the thread as referring to the Functor and Applicative instances, which are defined in base. There's nothing specific to Monad here.
You've forgotten case 3: people accidentally use these functions with tuples. Especially with tuples being the generic way to carry around extra information, this is actually extremely likely. Who hasn't used a function that evaluates to a tuple, when you expected it to evaluate to just one of the values, and then fixed the type error when it came up? What if the type error never happened?
I can assure if we find a good haskell dev, he will have work as long as he wants. Btw i've been working with them for more than 15 years.
one perspective which could be mistaken for I not Scottish who wins top coder and top languages? 1.)Russia (OCAML plus C) 2.)China (haskell? plus C++) and Singapore 3.)USA mixed languages 4.)Korea - who knows? 5.)note sure if India counts for Java plus javascript.... Is this an irony? GHC is GLASGOW, SCOTLAND yet the country is sinking in poverty; lacks needed computer language teachers; IS UNDER THE UK AUSTERITY PROGRAM -- well what did you expect after the Irish Potato Famine??? and Haskell marches on. With most of the contributions from Microsoft Research - a TOP LEADER IN OPEN SOURCE plus 'opportunity for all' commercial venture, or so some say. PPS. IMHO this is similar patterns used by environment organizations like Greenpeace against Nuclear Energy, despite the global warming - climate change goals. Of course, poorly design power plants, based on closed source software are common ALL OVER THE WORLD. However, thorium and other 'smaller' plus higher quallity safe designs could be a solution to the global warming crisis. and yet another controversial opinion of a futurist. What's yours? 
Yeah well, I hear something strange is afoot at the Circle K.
&gt; What I don't buy is the idea that, obviously, a pair contains one thing. (An interpretation, incidentally, that I find hard to reconcile with construing a pair as a product type.) Here is a different take: a pair contains two things, but when using the `Functor`, `Applicative`, `Foldable` and `Traversable` instances you focus on only one of them. I think the interpretation being discussed here is neither obvious nor forced; it all depends on what you want to do with the pair.
There are plenty of "people with the greater experience in Haskell, implementing, teaching, in academia and in industry" who support those changes. 
Sure, that seems fine with me.
As long as we force typed computations to be fully evaluated, then "loopy" things that could hide a paradox just make the typechecker spin until it gets cut off. So this prevents writing `unsafeCoerce` which is what we would want to be worried about. This year's HIW talk from Richard Eisenberg had some good details: https://www.youtube.com/watch?v=gn_ho6amc7U
&gt; However, because matrix multiplication is non-commutative, there is no (singular) notion of "inverse". This is true for arbitrary vector spaces, but thankfully, whenever a finite-dimensional and square matrix has a left inverse, then the left inverse is also the right inverse. The simplest proof I've seen is this: suppose AB = 1, so that B is a right-inverse for A. Since det(AB) = det(A)det(B) = 1, then both A and B have nonzero determinants, and thus inverses as well. Right-multiply both sides by B^-1 and then left-multiply both sides by A^-1 to get 1 = A^(-1) B^(-1). Finally, invert both sides to get 1 = BA, so that B is also a left-inverse of A.
Stack does in general forward environment variables on to every tool it calls. I don't have a Mac to test on to confirm this case, though.
That's what it does inside the virtual machine. Unfortunately apt-get doesn't work on Windows or Mac. And even on Linux, hugs has surprisingly many dependencies (although Vagrant is also not light weighed with regards to dependencies).
so, hugs is back from the software graveyard now ..
For large projects, I also recommend `-split-objs` for making the static files a bit smaller. &gt; When set to YES, static library object files are split into smaller pieces. &gt; This means that less of the library code needs to be linked into the final application, which makes smaller binaries. It takes longer to build libraries this way, though. If you use GCC, I also recommend `-optc "-pipe"` because that speeds up compilation, by using pipes instead of temporary files.
It's just I don't see the point to virtualise every `apt-get install` for packages that are part of the standard Debian/Ubuntu distribution. Why have a Linux distribution packaging up a huge amount of packages at all otherwise? Also space on SSD still isn't that cheap, and `apt-get install hugs` is far more lightweight than setting up a vagrant env, and you don't have to cross the container boundary to interact with `hugs`.
Thanks! That worked like a charm. Do you know how to update the yesod examples for the uninitiated?
For me it's "ease of mind". When I want to use something, I just setup a Vagrant file, save it on a repository (locally or on github) and then I am done. If I have to work on a different machine, reinstall my laptop or run it on a server, I just use the Vagrant files. I try to limit myself to a few base images, in the hope that the OS or the virtualisation software is smart enough to do some kind of deduplication (block de-duplication or copy-on-write on the file system or use delta images for virtual storage). But even if I have to clean up my disk from time to time, it's still worth it for me.
I'm curious, can you enlighten why you choose SQL Server instead of something like Postgres? Is it legacy from a time the services ran on Windows?
You can have something akin to "named instances of monads" with [Ether](https://int-index.github.io/ether/).
&gt; However, ocaml seems to use type inference only (any annotations you use are only used as naming hints) That's not the case - annotations can and often are used to restrict the generality of definitions. What you are probably thinking of is that user provided type variables aren't any different from those introduced by inference, and they will happily unify with other types - that is, you can type `'a` and get `int`, like this: let fake_id : 'a -&gt; 'a = fun x -&gt; 0 This will type check, giving `fake_id` the type `int -&gt; int`. (Note that the annotation's constraint that the argument and result types are the same has been honored: without any annotation we would have `'a -&gt; int`.) It's a wart on the language. You can use an explicit forall (`let fake_id : 'a . 'a -&gt; 'a = ...`) to prevent such unwanted unification.
There are differences in how OCaml and Haskell (and SML) interpret type variables in type annotations. In OCaml variables are inference variables by default, so they can be unified with anything, and in particular using `'a` as a variable name does not enforce polymorphism. So you can write: let choose b (x : 'a) (y : 'b) = if b then x else y;; (* val choose : bool -&gt; 'a -&gt; 'a -&gt; 'a = &lt;fun&gt; *) and also let succ (x : 'a) = x + 1 (* val succ : int -&gt; int *) If you want to enforce polymorphism (have variables that *cannot* be instantiated), you can use `(type a)` or `type a .` (which technically introduce 0-ary type constructors, not (inference) variables). `(type a)` was actually introduced for helping definition of local modules in OCaml 3.12, and re-used for GADTs later (in the next version, OCaml 4.0). OCaml's behavior, beside being a historical choice, is interesting when you want to be able to leave some parts of a signature unspecified, but still talk about sharing. You can write for example `_ -&gt; _` to say that something is a function type, but it is sometimes convenient to say `'a -&gt; 'a` to say "I don't care what, but the same on both sides please". This can even be refined with for example `(int * bool) as 'a -&gt; 'a`, which allows to express sharing of type expressions. This may seem to be anecdotal features, but they are actually very convenient for some use-cases (they played an important role in OCaml object-oriented layer, which is fully structurally typed, so where you may manipulate large types with non-trivial sharing). The *one* thing that I think *all* ML-family languages (Haskell included) *should* agree on, and actually do not, is: all variables should be explicitly scoped with an explicit binder. We have found out again and again that giving (type) variables an implicit scope is a *design mistake*, yet this mistake keeps popping out whenever new language features introduce new ways to introduce type variables (for example existential parameters of a GADT). It is very hard to take a clear stance on the matter because people will be beguiled by the convenience of implicit variable scoping -- to find later that it was a cumbersome mistake. (And I suspect that Haskell is just as guilty of this as OCaml, although I have been following the matter less closely.) Language designers of the world, unite against implicitly-introduced variables!
See ["mtl-prelude"](http://hackage.haskell.org/package/mtl-prelude) :) (pinging /u/andrewthad)
That's good to know! It looks like you're covering everything we rely on except the `yield` function. dejafu looks like a really great library, and seems like it could be a great tool for the problems we are tackling. Thanks for sharing/writing it!
&gt;You've forgotten case 3: people accidentally use these functions with tuples. Especially with tuples being the generic way to carry around extra information, this is actually extremely likely. A fair point, yes. That's why I agreed that it might do to factor out length from Foldable. In most other cases, though (Functor, Monad, Foldable, Traversable), the types themselves are telling you why you can't look at all the elements of a tuple.
Nice, you chose the strict variants instead of lazy! To confirm: the intended usage is: {-# LANGUAGE NoImplicitPrelude #-} import BasePrelude import MTLPrelude Correct?
It removes confusion, adds a bit of complexity instead that you really want to eventually learn.
I could hardly write any Haskell at all after finishing LYAH. Sure, it might be a good introduction to Haskell and FP mindset, but I'm sure we can do better.
I would choose a strict Haskell over the current one in a heartbeat altogether if only that was an option :) Yes, you're correct.
If I recall correctly.In the US it's required for administrative purposes. At least in Europe it's usually illegal for a company to ask for this data as it breaks the european privacy directive and will usually also be classified as discrimination. There are only a few exceptions. For example when casting for "Martin Luther King" you may discriminate an actor on skin color during an interview. We've learnt from WWII that storing race in databases is a really really bad idea here in The Netherlands. So I think it's sad that companies in the States ask for this. I at least feel very uncomfortable with it.
There’s two ways of looking at this: one is that `Foldable t` is no more leaking the implementation than `[t]` is: a version of `and` that uses `Foldable t` is free to play any stupid games it likes with the foldable set of values it iterates over, up to and including hopscotching all over set of foldable values and back before returning an answer. The other says that in reality `and` over `[]` is going to be implemented as a fold, whether explicitly or not, because how else are you going to write it? Abstracting away from `[]` to all `Foldable` things is not leaking the implementation: everyone already knows the implementation is a fold, because what kind of mad idiot would write `and` any other way? Only an object-oriented obscuratist would insist that hiding whether `and` uses a fold or not is important. Feel free to guess which of these two interpretations I prefer.
&gt; In the US it's required for administrative purposes. Wait. What? The land of endless possibilities.
Does [this "crazy-moon language" talk](https://www.youtube.com/watch?v=b9FagOVqxmI) count as a Haskell WAT talk?
&gt; The one thing that I think all ML-family languages (Haskell included) should agree on, and actually do not, is: all variables should be explicitly scoped with an explicit binder. ... giving (type) variables an implicit scope is a design mistake ... I think this is a really good idea. I tried writing an ML style type checker and was immediately assaulted with all the design decisions that go into that, but which I hadn't really thought about before. The big one that got me to rethink a lot of my approaches was realizing that depending on where type variables are bound a lot of semantics change. I came to the same conclusion that you did (a lot of problems go away if you explicitly bind them). However, I wasn't able to settle on a syntactic form that I liked for it. I'm probably going to ignore the syntax for now, but I am interested if you've got any clean looking syntaxes for doing such a thing.
Then there's always uncurry (||) . (isDigit &amp;&amp;&amp; (== '.')) But yes, I'll go with Alex first, you second, and this third.
Is this Haskell web app built on a framework, and if so, which one?
In my personal experiment with ML type-checkers, I used the two forms `for &lt;type variables&gt; in` and `some &lt;type variables&gt; in` to bind rigid and flexible variables respectively. This works in both type expressions and term expressions, although one may prefer `.` to `in` in type expressions: (fun x -&gt; x) : some a b . a -&gt; b (* accepted *) (fun x -&gt; x) : for a b . a -&gt; b (* type error *) (fun x -&gt; x) : some a . for b . a -&gt; b (* type (scoping) error *) (fun x -&gt; x) : for a . some b . a -&gt; b (* accepted *) for a b in (fun (x:a) -&gt; (x:b)) (* type error *) some a b in (fun (x:a) -&gt; (x:b)) (* accepted *) One thing that one must be careful about is the fact that, *even* when they are explicitly bound, ML type variables are naturally unordered. `for a b .` and `for b a .` are equivalent. If you want to mix ML variables with explicit type applications, you get into muddier waters because then you have to think about the ordering (or refer to the variable by name rather than position). One possible point in this design space is presented in the draft [Visible type application](http://www.cis.upenn.edu/~eir/papers/2016/type-app/visible-type-app.pdf) by Richard A. Eisenberg, Stephanie Weirich, and Hamidhasan Ahmed.
We are? That's a third party site we post a job position to. It must have their own submission form. We do not ask any such questions. And i think you can ignore it since it is optional. 
The whole company closed down; it wasn't person specific
Just use a lambda and give your collaborators a break.
my guess is that they mean (.//.) isn't a binary operator anymore, because it must be given proofs. but maybe vanilla smart constructors work here? newtype FullRankMatrix ... = FullRankMatrix (Matrix ...) with a validating constructor isFullRank :: Matrix ... -&gt; Maybe FullRankMatrix 
what has happened? 
I know right?
Totally.
Everyone got laid off at AlephCloud / PivotCloud
That I totally agree with. It sucks to have to pretend.
Good answer....good answer. =)
Erik really has lost all my respect the past few months. &gt; we will either answer with another question, or we will give you a http://lmgtfy.com/[2] link :(
Apart from this (which is bizarre), what has he done in the past few months? 
The stuff he has said on twitter and his lack of good answers to back it up. [Example 1](https://twitter.com/headinthebox/status/621443337049010176), [Example 2](https://twitter.com/headinthebox/status/652934071551660032). There are more.
To be fair, I believe he clarified that for the first one he was talking about adding option types to a language which already has pervasive nulls, i.e. where `Just a` can be `Just null`.
Eric is a douche.
I like to focus on the positive, so let's say it's good that he's making it clear students should not expect to learn Haskell from his class. Responding with a question is sometimes a good way to help a student clarify intent and understanding, if the teacher is doing it for those purposes. The inclusion of lmgtfy here makes me doubtful of the teachers' intent in that regard, though.
Miranda.
Edward Kmett. There were numerous public discussions about them, so you can find others there.
We should talk more about this. I abandoned automatic differentiation in favour of symbolic differentiation, and then spent weeks trying to implement it. Shortly before I had to shelve it, because it was too interesting and taking up too much time, I found out how to assert type equality and how type dictionaries work. The result is, I have a repo that can differentiate the most interesting Exp surface level ASTs, and maybe some knowledge to share. Here's my repo: https://github.com/johncant/accelerate-symdiff
Dead software that is no longer developed is never a great choice for anything you rely on.
I think the point was that nothing in the mathematical notion (ignoring the `Ord` implementation detail) of `Set` prevents its elements from having an `Ord` instance too so you can actually implement `Foldable` for `Set` of any type with an `Ord` instance, which happen to be all of them in practice because the implementation detail forces the element type to be an instance of `Ord`.
Yes. 
I haven't tried recently, but ime Hugs has always been easy to install. Certainly much easier than ghc; though these days ghc is pretty easy in most places fwiw, I learned Haskell on Hugs back in the day, so I've always had a soft spot for it. It's an excellent pedagogical tool, and back in the day had a much nicer repl than ghci. Though, again, these days ghci has had a chance to catch up
&gt; ... Previously we would map the entire object file using MAP_32BIT, but the object file can consist of 75% or more symbols... &gt; ### but the object file can consist of 75% or more symbols &gt; # **75% or more symbols** https://i.imgur.com/vbYqEHg.gif
I just used it and can say that hugs is much faster to load on my laptop than ghci. It seems that execution is a little faster in hugs than ghci's interpreted mode as well. Now that I think about it ghci has always started kind of slowly for me, anyone have any idea why? If I wanted to help optimize ghci startup time where would I look?
I don't know very much about how compilers or binaries work... does this mean they have 1.5 Gb of variable names?
Because you can't say "Well obviously a beginner like you should have imported these functions qualified so you realise that they aren't simply finding length or maxima, they're folding first" in reply to _"Let's talk about Haskell:_ ghci&gt; length [1,2,3,4,5,6,7] 7 ghci&gt; length ([1,2,3],[4,5,6,7]) 1 ghci&gt; minimum (4,8) 8 ghci&gt; product (0,5) 5 ghci&gt; sum (Right 2) 2 ghci&gt; sum (Left 2) 0 _...Wat?! Seriously, they discussed this and the answer is that this is all correct because of functors and Cartesian closed categories. Truly it is possible to be so clever you're stupid. This is about as far removed from a practical language for solving problems as you can get."_ We shouldn't put fuel in the "it's just for ivory tower folks' fire". By contrast, ghci&gt; foldLength [1,2,3,4,5,6,7] 7 ghci&gt; foldLength ([1,2,3],[4,5,6,7]) 1 ghci&gt; foldMinimum (4,8) 8 ghci&gt; foldProduct (0,5) 5 ghci&gt; foldSum (Right 2) 2 ghci&gt; foldSum (Left 2) 0 only results in "Haskell fold functions are weird. I don't get it." Can you see the difference? Everyone is 100% sure they understand `minimum` and can see when it's wrong. Anyone seeing a counterintuitive result for `foldMinimum` assumes it's the fold they don't understand, because of course they understand minimum. The conclusion changes from "that's clearly a very broken language" to "I clearly don't understand this". _Allowing_ people to prefix the name doesn't do anything whatsoever to reduce people's utter misunderstanding about what this new function, `length` does, so your suggestion doesn't help at all, I'm afraid. It's simply a misnomer, and I genuinely think giving these secretly sophisticated functions oversimplified names is a huge teaching and marketing mistake.
Ah, I was not aware of that. Still, you can enforce that your option type does not contain nulls (in a language like Java) by checking in your constructor/static factory method and throwing an exception.
I don't think there is a better place to put it `Transversable` is even weirder, since it doesn't `transverse` and a new type class just to hold it isn't worth the pain. So the only alternative is to leave it monomorphic. I don't think `length (1, 2) == 1` is worse than requiring `foldr (\_ c -&gt; c + 1) 0` (or `getSum $ foldMap (const $ Sum 1)`) to get the length of a `Set`. If the community hadn't decided that fewer type classes is generally better then I would agree that moving it makes sense, but given this it is the only place it could be. Also I am still curious whether a new user won't be sent down a very helpful rabbit hole by having this bug in place.
Who cares when you're doing this in a language like Java?
As part of making [Snowdrift.coop](https://snowdrift.coop/) as welcoming to newcomers as possible, we've worked to have the best possible docs (although still lots of room for improvement, ADDENDUM: merge-requests/pull-requests/suggestions are all welcome). Our code at https://git.gnu.io/snowdrift/snowdrift — and mirrored on GitHub https://github.com/snowdriftcoop/snowdrift — has really clear docs now from the [BUILD.md](https://git.gnu.io/snowdrift/snowdrift/blob/master/BUILD.md) guide to the [CONTRIBUTING.md](https://git.gnu.io/snowdrift/snowdrift/blob/master/CONTRIBUTING.md) that even includes minimal intro to Git basics and lots of links to resources. We also have this document linked here about Text Editor setup. I know there's *tons* of opinions out there, but the goal is to just get people started as best as possible with what's currently workable. **Our goals are: strictly free/libre/open everything (even for the educational reading links), and this is not truly general, it's focused on what's needed for Snowdrift.coop which is strictly Yesod and Stack.** The goals for text editor setup is to balance functionality with ease of setup. We want the absolute minimum needed to get started but to make it as easy as possible also for people to have a good experience as they make their way around the code. There's some learning process no matter what and none of the tools are completely as easy, working, approachable, as we'd like, but this is what we've come up with so far. *note*: more of the Vim folks worked on this vs those who use Emacs, probably some improvements could be made to the Emacs section. There's also a lot of quirky reasons for particular details such as focusing tags on hasktags for now because Atom doesn't currently support the line-number style of fast-tags and similar sorts of issues which we hope to update as things improve.
Thanks for this. I'll check it out. I got kind of frustrated with recent versions of Vagrant -- I had trouble building my own boxes, ssh stopped working for some reason.
Haskell 98 was a well designed standard, and isn't bitrotten. Superseded, yes, but bitrotten, no. For it to be bitrotten it has to be malfunctioning in some way. It isn't. You can redefine bitrotten as much as you like, but Hugs works.
haven't read the paper yet, but it seems that [Against the definition of types by Tomas Petricek](https://www.reddit.com/r/haskell/comments/35zzvu/against_the_definition_of_types_by_tomas_petricek/) is relevant I also like [this](https://existentialtype.wordpress.com/2012/02/01/words-matter/), but that is about variables
Have you tried the memo monad package on hackage? It's pretty straight-forward.
&gt; I don't think `length (1, 2) == 1` is worse than requiring `foldr (\_ c -&gt; c + 1) 0` (or `getSum $ foldMap (const $ Sum 1)`) to get the length of a `Set`. And it's not only more wordy, but also `O(n)` rather than `O(1)` in the case of `Set`... I'm surprised that those who complain about `length` seem to be ok with `null :: Foldable t =&gt; t a -&gt; Bool`...
What if you take the replicateM case (which seems to be very fast) and fmap it into a strict list? Would that not make it not need the stack space through optimization?
You can get much faster by never materializing the list (ala `pipes`/`conduit` for example). Then the cost per entry starts dropping to the 10s of nanoseconds range.
I wonder what the user proposes to do with this list once she 'extracts it from IO'? If you use a genuine (monad-independent) streaming type, `sequence` tends to be `id`. I.e., instead of doing something like sequence :: List (IO a) -&gt; IO (List a) sequence = undefined -- see blog posts you do sequence :: List IO a -&gt; List IO a sequence = id and forget about this kind of pointless crisis. But we can get some comparison by actually doing something, e.g. finding a sum. Choosing the best of the optimized list operations, which seemed to be `sequenceH`, I tried this: import Criterion import Criterion.Main import UnsafeSequence import Control.Monad import qualified Streaming.Prelude as S import Streaming -- cabal install streaming import qualified Pipes.Prelude as P main = defaultMain [ bgroup ("10^" ++ show n) [ bench "stream" $ nfIO $ S.sum $ S.replicateM nn act , bench "pipes" $ nfIO $ P.sum $ P.replicateM nn act , bench "sequenceH" $ nfIO $ fmap sum $ sequenceH $ replicate nn act ] | n &lt;- [7] , let nn = 4 * 10^n ] where act :: IO Int act = return 1 For this choice of length, the results were like so: $ ./Benchmark -o benchmark-results.html benchmarking 10^7/stream -- really 4*10^7 time 1.275 s (1.227 s .. 1.337 s) 1.000 R² (0.999 R² .. 1.000 R²) mean 1.315 s (1.297 s .. 1.330 s) std dev 24.41 ms (271.9 as .. 26.12 ms) variance introduced by outliers: 19% (moderately inflated) benchmarking 10^7/pipes -- really 4*10^7 time 7.457 s (7.218 s .. 7.873 s) 1.000 R² (0.999 R² .. 1.000 R²) mean 7.367 s (7.248 s .. 7.437 s) std dev 107.2 ms (0.0 s .. 120.2 ms) variance introduced by outliers: 19% (moderately inflated) benchmarking 10^7/sequenceH -- really 4*10^7 time 21.84 s (13.99 s .. 26.09 s) 0.983 R² (0.964 R² .. 1.000 R²) mean 14.88 s (10.98 s .. 17.27 s) std dev 3.627 s (0.0 s .. 4.141 s) variance introduced by outliers: 48% (moderately inflated) I picked `4*10^7` because for any higher figure the list programs exhaust memory and start to freeze my laptop ... as would you expect they would at some point. The length of time the `pipes` and `streaming` program take for the smaller lengths is relentlessly linear in the length of the list/stream/producer. And they barely read for memory consumption in Activity Monitor, for any length of "list" . They are slower at small numbers because the give the ghc more constructors to grind through ... but, as we see, for good reason! (By the way, the pipes program is slower than the other, I think, because the implementations of `sum` and `replicateM` in Pipes.Prelude are hyper-elegant, I think basically for tutorial purposes. The `streaming` type is equivalent to `pipes` producer; it is just missing constructors that are unused here; the functions are implemented by naive recursion with the constructors.) A conduit program would be even faster in this particular case, because its fusion system would kick in with such a simple program; but in parallel cases where the fusion isn't possible, it should come to about the same as the other correct, i . e . streaming, programs. ---- Edit: As I predicted, conduit crushes everyone in this particular benchmark. If I add the lines import Conduit ... , bench "conduit" $ nfIO $ replicateMC nn act $$ sumC I get results like: benchmarking 10^7/stream time 1.299 s benchmarking 10^7/pipes time 7.790 s benchmarking 10^7/conduit time 51.17 ms benchmarking 10^7/sequenceH time 16.09 s This is admittedly the best imaginable case for the rewrite system conduit is using. But it goes to show that if you want to think about clever optimizations, you do better to optimize the correct program, and the one that actually expresses what you mean.
I can hypothesize that the reason why `streaming` has better constant factors than `pipes` is that there are no functions in the syntax tree for `streaming` whereas `pipes` has the equivalent of `() -&gt; ...` in its tree which probably hinders the optimizer. The other possible reason might be different strictness behavior (the `streaming` syntax tree is slightly more strict and the implementation of strictness in each library's respective `fold` function slightly differs, too).
elem &amp; co are different from length in that the types preclude mistakes (generally). While you might genuinely expect `length (1,2) = 2`, `maximum :: Foldable f =&gt; f a -&gt; a` won't work because tuples are generally heterogeneous. If you call `maximum (True, 1)`, it will be clear that True won't come out.
You can't just make a claim like that and not cite an example.
&gt; making HTTP and HTTPS requests `wreq` is pretty fantastic, and its tutorial wound up giving me the final shove I needed to start actually using `lens`. Previously I've used `http-conduit` and it's fine too, just a lower-level interface. &gt; parsing responses (tagsoup?) This is the next thing I need to nail down myself. Preliminary research suggests `tagsoup` has a strong competitor in `html-conduit`, but I haven't looked into either enough to form opinions yet.
If you're the author: you might want to go into the history of the notation, specifically why functions are applied prefix (because of Euler) and why Haskell applies operators via whitespace (because of the lambda calculus). One could also compare prefix (f x y), infix (x f y), and postfix (x y f) application, and curried vs. uncurried functions, and their respective consequences further down the line. For instance, partial application is quite cumbersome if you use brackets, but invisible if you use spaces. On the other hand, separating operands can be tedious if you can't use commata... things like this, to make an interesting read.
Bitrot has nothing to do with the viability of the standard. It is a property of implementations, installers, dependencies and similar parts of the system, not of specifications.
There is a difference between a programming language where the only implementation can not be fixed when it inevitably stops working due to some change of the environment it needs to run in and a TV or similar appliance where you can get a different model that fulfils exactly the same function when it breaks. In economic terms one has substitute goods, the other does not.
&gt; -- I don't know a good name for it &gt; qq :: (a -&gt; a -&gt; b) -&gt; a -&gt; b Ironically, the name for `Join` came from: Prelude&gt; :t Control.Monad.join which has exactly the type of `qq` when specialized to the `(-&gt;) a` Monad. Anyways `Join` is a data type, not a combinator. Most of the data types in `Data.Bifunctor.*` exist to permit the the gyrations you are doing here at the value level, just one level up at the type level. The data type serves as a "type adapter" you can pass into contexts expecting something else, e.g. if you have code parameterized over the Functor but you have a Bifunctor and need it to work over both arguments.
Wow your technology stacks are awesome, I played all of them for a while, they're so great and enjoyable. Wish you find the right person 
Thanks! That's very helpful with respect to the concrete difference, though I don't have a good feel for the ramifications yet. I'm fairly well familiar with "wannabe dependently-typed" programming in Haskell, but have only *looked* at code written in honest-to-God dependently typed languages, not written it myself -- so I know what impredicativity is good for, but (now that I know the difference) have less of an idea about where the `Type(n): Type(n+1)` restriction is even relevant. Would it be accurate to say that in current GHC, `*` is `Type(1)`, `BOX` is `Type(2)`, and there are no higher levels? If GHC 8 is going to have `Type :: Type`, then does that mean impredicativity will also "just fall out" (as per your last paragraph)? Or not, because Haskell isn't (as) dependent? In that case, then, will GHC end up with better support for impredicative *kinds* than for impredicative *types*? (Or is this all just a question of how well type inference works?) From a different direction, considering a system like 1ML which doesn't have *syntactic* stratification, I don't have a good intuition for what kind of restrictions you'd put into place if you wanted to avoid *dependency*, versus if you wanted to avoid *impredicativity*. (I still need to read that paper a few more times, I suspect.)
That's hillarious. The reason I didn't have a name for `qq` was because I wanted to name it `join`, but couldn't due to the name-clash. I should have thought to check whether the clashing `join` was exactly the same :) Also, this is what comes of me understanding/using `Applicative` more than `Monad`. Thank you. Now, we can just let this post gracefully sink into the abyss.
Thanks. On further study, I noticed that `(&gt;&gt;= id)` and `(=&lt;&lt; id)` get specialized to the same thing for the `Monad` instance of `(-&gt;) a`: (&gt;&gt;= id) (_ :: a -&gt; b) == (=&lt;&lt; id) (_ :: a -&gt; b) Which is why `(&lt;*&gt; id)` matches with `join = (&gt;&gt;= id)`, despite the different definitions of `(&lt;*&gt;)` and `(&gt;&gt;=)` in the `(-&gt;) a` instances: f &lt;*&gt; g $ x = f x (g x) f &gt;&gt;= g $ r = k (g r) r A subtle thing...
Except for `length`, I feel those are harmless curios. Your hypothetical flame warrior would have to go way out of their way to write `product (0,5)` rather than `0 * 5`. Perhaps a bona fide newbie might try `minimum (4,8)` before `min 4 8`, but even in this case elementary knowledge about what is the syntax for passing multiple arguments in Haskell should be enough to suggest something is wrong. 
I just like watching him talk. He could be presenting PHP best practices for all I care. He's fun!
I was wondering, would it matter if I used the latest version of GHCi instead of Hugs, is it really _that_ different (for what Eric will be teaching)?
Do you think spacemacs would be a good addition to this page? It has the easiest setup by far IMO, though I suppose cloning the .emacs.d directory could disqualify it as easy for many.
Thank you, that is good to know. Since this isn't an actual uni course, I shall free to make my own choice (and bear the responsibility for any problems that causes).
Seriously. Those are all things that I would consider in a greenfield scenario.
Minor typo: stack new hello-haskellcd hello-haskell I think you missed a newline. Also, I think it needs to be `stack exec exe-hello-haskell`, though admittedly I haven't tested that. I'm looking forward to finishing the rest of the post later :)
Good question
It's a device for turning programmers into category theorists.
Thanks mate 
is there some relationship between `tagsoup` and `handsomesoup`?
Haskell is an advanced purely-functional programming language. See http://haskell.org Feel free to ask any further questions and we'll do our best to answer.
R.U. Nijmegen?
This is a great resource - thanks! I recently tried emacs but found that complicated to set up. I'm pleased with Atom though. It feels pretty solid. Stack support could be better, goto definition is missing and it lags behind emacs in advanced features such as Hare. But it's getting so I could recommend it to regular developers.
There most certainly are. We're using loads of Haskell at my current job ([Ambiata](https://github.com/ambiata)) for anything from manipulating Amazon AWS, web dev, general tooling, writing our own query language and all things machine learning. 
Well, Hugs works, hence not bitrotten. Not sure where you feel there's debate here. 
Let me paraphrase what my professor said 2 days ago: &gt; Any question is a good question. Either it's a tricky question and deserves to be answered, or it's a question about something I failed to explain. Whenever you ask a good question or answer one, I'll reward it with candy. Some sugar for your brain while studying. In my opinion exactly the way to handle questions. The reward of course is optional. Then again, this professor is also very concerned with feedback.He'll stand outside the lecture hall until all questions are answered, will take any kind of constructive criticism seriously.
Hugs is not the only implementation of haskell! If at some point in the future, Hugs stops working because of 256-bit processors being finally unable to run 32-bit code or something, (don't get your hopes up: my 64-bit laptop still runs some 25-year-old 16-bit music notation software I have) then it can at _that_ point be replaced with some more recent haskell implementation. (I'm sure you have one in mind.) There's just no need _now_ to do so. (Note: I only use hugs for teaching beginners and if I'm at someone else's house borrowing their computer and need to do a calculation or something that excel isn't suitable for. A quick hugs installation and you're going. I wouldn't install ghc on family members' computers.) 
that still leaves `toList` out there... would we need to rename that too?
The debate is about using it for something where you rely on it for an extended period of time, say, a course like the one this post is about. What if the major Linux distributions stop shipping a library you rely on half way through your semester? What if there is a new OS X which suddenly disallows you to install binaries to the usual locations (as just happened with their latest release). What if your students upgrade to Windows 10 and MS is no longer updating some DLL you rely on? What is your plan for those kinds of scenarios?
wat? how are you measuring community adoption? and what's the criteria at which it becomes a failure?
I measure it in terms of libraries using lens-like interfaces, tutorials (apart from those for lens libraries themselves0 written using lens-like mechanisms,... and as far as I can see lens use is a very small minority of the community, no more than 20% I would say, less for popular libraries. Lens is just too complex to see easy, broad adoption without being a solution to a problem people really struggle with. Right now it is not a solution to a practical problem as most programs don't require you to reach many levels deep into data structures. The common case is one or two levels at most and for that lens is not worth its cognitive cost.
Which linker just silently corrupts on overflow?
Help us to help you: share the first few lines of your .stylish-haskell.yaml, as you suggest that is where the problem lies.
If people don't like the course (and they shouldn't, because Erik isn't acting like a teacher in good faith), then they shouldn't enrol in it. He can use whatever tool he likes.
Looks cool - thanks for reply!
Perhaps I'm completely missing the point, but if you want to generate a fixed-length collection of `Int`s in a monad, why don't use an unboxed vector?
I can totally understand that there are different opinions on how to bring functional programming to the masses, but bluntly stating that "Erik isn't acting like a teacher in good faith" really makes me wonder if the Haskell community is secretly afraid of widespread adoption of functional programming principles. But then I realize that every time you are using Haskell, I have actually effectively infiltrated inside your brain and hence achieved success. So just keep that in mind when you write your next snippet of code; the evil Erik Meijer is always there watching you in the background. You are coding in a beautiful language that he had his dirty fingers in. Darn! But don't let that spoil your fun of hacking Haskell ;-)
&gt; Although I'm not sure it would be profitable for you given the relatively small French audience that doesn't already learn programming languages mainly in English. Then again we're notoriously pretty crappy at foreign languages so there's that.
Are you by any chance referring to yourself in the 3rd person? 
I'm guessing whoever doesn't like the course doesn't need to enroll in it. If you think Erik isn't acting like a teacher is good faith then don't you agree many students will think badly of functional programming and Haskell as a result? don't you think he is doing a disservice to his students and to the Haskell community in this case?
Thanks for taking the time and writing this guide. Where can I find more information about what I can do with spacemacs for Haskell development? for example, how do I run type checking for a module?
Often it is more important the perception of something rather than what this something really is. If a language is hostile to newcomers in very subtle ways, for example, telling them that they need to know advanced idioms for doing simple things, then that people will get off and will not discover the many good things that lie ahead once they surpass the entry barrier. But you think that there is no problem at all, even if almost nobody in industry uses our language, the best one by far. Many people out there, haskellers and more importantly, non-haskellers say that yes, there must be some big problem. And the symptom is in front of your eyes. It is a disheartening for me to verify that you do not see it.
In many respects wannabe dependently typed programming in Haskell is far more complicated than the real thing :) Type(n):Type(n+1) is there to prevent Girard's paradox. If you have Type:Type then you can write a non-terminating program. This is fatal for dependently typed languages because it lets you "prove" anything. In practice you don't run into it that often. It's like Russell's paradox in set theory: to prevent it you have sets, classes, and higher classes. There is no set of all sets, but there is a class of all sets, and there is a class(n+1) of all class(n). This is like Type(0), Type(1), Type(n). In practice in mathematics you don't really care about that. In dependently typed languages you do have to keep track of the universe index, but usually inference is supported so that you can just write Type and the compiler infers the level. In Haskell the situation with impredicativity is a bit complicated. It's not enforced by the type system but by ad-hoc syntactic restrictions. Therefore even Type:Type wouldn't get you impredicativity. Type:Type in Haskell also doesn't have the same problem as in dependently typed languages, since Haskell isn't a total language anyway. It's just one more way you can write a non-terminating program. You can avoid dependency by not having any type constructors that work on values. So you have, say, value level numbers and type level numbers. They have a different type so that type constructors would only be able to depend on type level numbers and not on value level numbers.
I recommend Haskell layer documentation: [link](https://github.com/syl20bnr/spacemacs/tree/074f425dc5d233f24195ecc3021eb96ac9d55d4d/layers/%2Blang/haskell) About type checking - I use spacemacs haskell repl `SPC m s s` and then I load current module/file with `SPC m s b` keystroke - it should try to compile your file and highlight all type errors and so on.
thanks, it worked now. I think I misunderstood the readme 
Mr. Meijer, I can see that there are valid objections agains Foldable, but may I ask what are your thougths about Applicative/Traversable? In my opinion (that of an amateur) they are exceedingly useful abstractions.
HandsomSoup is listed in the latest Haskell LTS, it should work with GHC 7.10.2 and probably with the GHC versions in between.
I have absolutely no opinion about the practical value of any these abstractions for Haskell as a language. But I cannot stress enough that the MOOC is not about Haskell. Haskell is just one possible medium to express the general ideas of functional programming. Once people have seen x concrete instances of a pattern and are sick to their stomach writing the same boilerplate again and again they may appreciate the fact that in Haskell they can abstract over it. But that fact is not super useful if for their day job they are using Java or even F#. My favorite FP books (such as http://usi-pl.github.io/lc/sp-2015/doc/Bird_Wadler.%20Introduction%20to%20Functional%20Programming.1ed.pdf and https://books.google.nl/books/about/Recursive_programming_techniques.html?id=81kZAQAAIAAJ&amp;redir_esc=y) do not use any type classes, yet they really convey the supreme beauty of FP better than any of their successors.
so you dont like bird's later editions, do you?
&gt; Type(n):Type(n+1) is there to prevent Girard's paradox. Yeah, I got that -- what I don't is the other half. :) What kind of things do people do in dependently typed languages where this (as distinct from predicativity) is a PITA and you really wish you could just have `Type: Type`? I don't have a good sense of that from Haskell because it's evidently not advanced enough to even contemplate the sort of thing. (Also, the question of whether quantification pushes you into a higher universe is called "(im)predicativity", and the question of whether types can depend on terms is called "dependency"... is there also a separate name for the question of whether `Type: Type` holds?) &gt; So you have, say, value level numbers and type level numbers. They have a different type so that type constructors would only be able to depend on type level numbers and not on value level numbers. And if you add `Type: Type` to this kind of system, that means you'd have "dependent kinds" like GHC 8 will? How does this interact with something like [reflection](http://hackage.haskell.org/package/reflection)? The Haskell type is: reify :: forall a r. a -&gt; (forall s. Reifies s a =&gt; Proxy s -&gt; r) -&gt; r Specializing to `Nat`: reify :: forall r. Nat -&gt; (forall s. Reifies s Nat =&gt; Proxy s -&gt; r) -&gt; r Instead of the `Reifies` and `Proxy` business, suppose our number type is parameterized over whether it is type-level or value-level -- `Nat Static` and `Nat Dynamic`. Then we could write something like: reify: (R: Type) -&gt; Nat Dynamic -&gt; (Nat Static -&gt; R) -&gt; R Does this give rise to dependency? What does it (ahem) depend on? It seems like the devil is in what you can instantiate `R` with -- if you can instantiate it with `Type`, then the returned `Type` may depend on a `Nat Dynamic` argument. So seemingly `Type: Type` is implicated. (Or maybe we should also be writing, say, `R Dynamic`?)
&gt; What kind of things do people do in dependently typed languages where this (as distinct from predicativity) is a PITA and you really wish you could just have Type: Type? You usually run into this when you want to pass around types as values. Suppose you want to define finite products of types. You could define a function `product : List Type -&gt; Type`, `product ts = fold (×) 1 ts` where `1` is the unit type (the () in Haskell) and `A×B` is the pair type. Without `Type : Type` this won't work, since then `Type 0 : Type 1` and the list constructor `List : Type 0 -&gt; Type 0`, so we can't do `List (Type 0)`. That's where universe polymorphism comes in: you can give List the type `List : Type n -&gt; Type n`, then you can do `List (Type 0)`, which gives you `List (Type 0) : Type 1` because `Type 0 : Type 1`. Note that impredicativity doesn't help you here, you really need universe polymorphism. &gt; is there also a separate name for the question of whether Type: Type holds I don't think so, I've only heard it being called "type in type". &gt; And if you add Type: Type to this kind of system, that means you'd have "dependent kinds" like GHC 8 will? How does this interact with something like reflection? I don't know anything about Haskell's road to dependent types. I would expect that such a reflection-like thing does not give rise to dependent types in the usual sense, because as far as I can tell there isn't really anything connecting the type level nat you get out of it to the value level nat as far as the type checker is concerned. To be honest I also don't think these issues are terribly interesting, because it's like those "smart TVs": technology of the past that's trying to catch up with technology of the future with lots of peculiarities coming from historical baggage. Forget about TVs, think about computers :)
Great suggestions, thanks! That was just a small 'trivia' post :)
Erik, I was saying that you weren't acting like a teacher in good faith because of your patronising LMGTFY reference, not because of your Hugs decision. This is just deeply discouraging to students who are eager to learn. I hope you will be more considerate in future.
Aix-en-Provence, just this week: asked what an unknown menu item was, waiter answers "fish", i got squid. Not great english confirmed :)
I've had luck with `xml-html-conduit-lens` with xml, which parses xml with ease. It has great examples on its haddock for using the lenses. I found it difficult to use for scraping html due to difficulty formulating a lens to find the right path through html because it usually isn't as well structured. Here's an [example](https://github.com/mindreader/clalert/blob/master/src/Main.hs) of parsing craigslist's rss. 
Help, my brain is pulsating with images of tie dye patterns, how do I make it stop Mr Meijer? P.S. I enjoyed your Channel 9 FP/Haskell lectures very much. And while some of the choices you have for this course seem strange, that doesn't detract from the work you have already done or my opinion that you are a rather clever, quite accomplished chap. _edit_: I didn't (or at least, don't think I did) say that you were acting in bad faith.
Is this the one you like to read at Christmas time?
I changed it to this : prop_convert c = not (isAscii c) ==&gt; convertToCapital c == toUpper c but then I see a failing test : test_convert : *** Failed! Falsifiable (after 2 tests): '\251' How to deal with that one ? Roelof 
We don't really put a lot of debugging information anywhere at the moment, so I wouldn't doubt if it's actually symbol entries (I mean, you can turn on the DWARF work now, but it's not very useful still).
Nice! What will be the distinguishing features?
`sequence` is of interest because it is used in the definition of the functions that mix lists with IO, in particular `mapM` \ `traverse`; or anyway they all come to the same, `sequence = traverse id` If I understand, you could indeed say that they are trying to define a list `mapM` that behaves more or less as the vector `mapM` does; the vector "unstream" functions do something like initializing a new vector and writing to it -- writing to undefined positions in the allocated vector, if its size is known in advance, or growing the vector and adding elements to its tail. The use case that traps us in this problem is not very clearly specified of course. Neil Mitchell does seem to have practical uses in mind, but in the advice at the end he treats a use of pipes and conduit as if they were emergency moves to be made in a crisis, rather than the first thing that should come into your mind when you type `mapM` `sequence` `replicateM`; it is an illusion that they are any more difficult than Data.List. For example the "frequently used" `concatMapM` he defines for us is pipes `for`. 
That's a good point generally, although we use that term all over the place and don't want to always mention it, but any document that might be viewed out of context, that does make sense. Thanks for the suggestion.
This is subjective, but `f(x, y)` feels noisier. (just like `f$b` feels noisier than `f.b` despite not being actually larger)
I'm also looking for internships!
That's probably it, my laptop has a slower hard drive.
But what if you option type is null? The issue is that null is still lurking.
Your professor is lucky then. There are also genuinely stupid questions from people who haven't stopped to think before they open their mouth, who have no intention of trying to find the answer themselves, and so on. Probably not on this course, I dunno.
It's fully functional. What's so primitive about the REPL? (By the way, it seems more than one person criticising hugs seem to be unaware that it's an interpreter and speak as if there's something else to it. It suggests unfamiliarity to me.) 
Even before it moved into `base` the instance was a very common orphan. As for giving multiple names being allowed or not allowed, it is often very useful to be able to talk about "the" product, in which case it behooves us to let it have the properties it can reasonably have without mutual contradiction. Some of those may give some users pause. But my experience is that what happens when you start getting needlessly prescriptive about "how" something is to be used that it becomes a pain point. In math defining things up to isomorphism is good enough. When you have a type family picking one out you can't do that any more. I note you aren't proposing a concrete alternative instance here. So it is a balance of surprise (which can turn to insight) vs. getting trapped in an orphan instance ghetto from which code compatibility never recovers and the instance is rarely tracked down and insight is never gained. "Oh users will only put on these newtype wrappers in Data.Monoid for a little while, they don't need any instances other than the Monoid" is a scenario that is directly at odds with the call people put forth for a Map that has a monoid that unions using the semigroup associated with its elements. Being prescriptive here isn't without cost. Is it surprising? Perhaps. But once the user learns what it does and why it work they are enlightened. For instance that instance in particular was the start of my road to understanding adjunctions at all. Notably, this instance passed libraries proposals on separate occasions multiple times over the years. It wasn't included prior to now solely for the technical grounds that `Monoid` wasn't available in an appropriate scope, and so it would have had to be an orphan no matter where it lived. That is no longer the case.
Now i get what FLO means :) Thanks. I only knew FLOSS and FOSS.
&gt;Hey help out our for profit company by working for free. Get more opinions as I doubt the qualifications of anyone who sees that site and says there's nothing wrong with it. There's a **damn good reason** this keeps getting brought up. That shit is fucking hideous. 
In the last two days I've [retweeted](https://twitter.com/purelyagile) Haskell job ads from four companies with seeminly nine roles available between them. This was unthinkable even merely one year ago!
Thanks, I'll take a look at tags.
Too bad remote isn't a possibility, I have several years of professional Python experience doing data processing and a good amount of Haskell experience (just not professionally), but sadly I live in a state in the US where last I checked I was one of two registered Haskellers. There aren't many Haskell jobs posted for Arkansas...
Damn... I thought that you mean some exotic islands :|
That repo is so helpful to look at. People kept saying I could use Yesod modularly, but I had no idea about what that would look like. I really like the look of the Lucid DSL too.
A lot of people do this same thing dicker and I've heard it's more hard drive space efficient.
[fragnix](https://github.com/phischu/fragnix) [slices](https://github.com/rwilhelm/slices)
For people wondering how `morte` differs from `fragnix`: `fragnix` expressions are Haskell expressions (just packaged into smaller units of distribution). `morte` expressions are expressions in the Calculus of Constructions. That means `fragnix` gets the benefit of the Haskell ecosystem and `morte` does not. The smallest unit of distribution of `morte` is smaller than in `fragnix`. For example, let's assume that you define a data type like this: data Bool = True | False In `fragnix`, you have to package the type `Bool` and the constructors `True` and `False` as a single unit. In `morte` you can distribute them separately (without any internal references between each other). In fact, you can go a step further and do this even for mutually recursive types like this one: data Even = Zero | SuccE Odd data Odd = SuccO Even In `morte`, you can distribute `Even`/`Odd`/`Zero`/`SuccE`/`SuccO` as separate, non-recursive, closed, and independent expressions, even though they were originally defined in a mutually recursive fashion. The third difference is how side effects are implemented. `fragnix` uses Haskell where side effects are embedded within the Haskell language semantics, whereas `morte` uses the Calculus of Constructions to build a side effect tree which is interpreted by a separate backend. This means that `morte` is as safe as the backend interpreter: if the interpreter only understands two side effects (such as `getLine` or `putStrLn`) then you automatically trust any remote program that you execute using that interpreter. If the distributed language has any sort of backdoor (like `unsafePerformIO` in Haskell, or pretty much any other language for that matter) then you cannot automatically trust any remote code that you execute. Since `morte` separates the intermediate language from the set of permitted side effects you can customize the backend to change the set of allowed side effects. The last difference is that `morte`'s syntax tree is absolutely tiny (it's very principled, almost to a fault) so that it's highly portable. `morte` is designed to be used as an intermediate language that is easy to manipulate, transmit, and statically analyze. All high-level abstractions are defined within the higher-level `annah` front-end language and then desugared to the low-level `morte` language. However, other than those differences the implementations are conceptually very similar: every expression explicitly declares all dependencies at a very fine level of granularity so that you only pull in the exact amount of code that you need and no more.
I'm guessing it's just `&gt;=`, not `==`.
I mean, it's not that subjective. whitespace has fewer black pixels than commas/parens. same for dot and dollar. this lets the eye focus on the arguments. it's actually ridiculous to expect whatever the mainstream function application syntax is to be most easy on the eyes. 
This is a great framework y'all
&gt; What about **fab**? I think it's tersest possible if you allow for a necessary separator between separate identifiers. If you restrict all identifiers to 1 character so there need be no separator, then you could indeed get rid of the whitespace.
How do you do pattern matching (not folding) on recursive types?
How does this compare to some competitors? * [PureScript](http://www.purescript.org/) with a React binding lib, like [thermite](https://github.com/paf31/purescript-thermite) * PureScript with [optic-ui](https://github.com/zrho/purescript-optic-ui) * [GHCJS](https://github.com/ghcjs/ghcjs) with a React binding lib, like: [ghcjs-react](https://github.com/fpco/ghcjs-react), [blaze-react](https://github.com/meiersi/blaze-react), [react-haskell](https://github.com/joelburget/react-haskell) and [react-flux](https://hackage.haskell.org/package/react-flux) * GHCJS with [reflex-dom](https://github.com/ryantrinkle/reflex-dom) * [Elm](http://elm-lang.org/) * [Haste](http://haste-lang.org/) I think we need a "Haskell('ish) browser-side UI framework zoo", that could simply refer to the TODO apps that all seems to provide as a baseline example. *Edit:* Added reflex-dom thanks /u/gimli. Added more links. *Edit2:* Added optic-ui thanks to /u/paf31, and react-fux thanks to /u/vagif.
I didn't find it convincing. There are [many clear arguments against](https://www.reddit.com/r/haskell/comments/3oq0kd/proposal_eliminate_the_monad_implementation_on/cw0yyqp), but I have yet to see one good use case for folding a tuple. Just because you can make a function work on a data type doesn't mean that you should. Down that path lies Javascript.
If I understand correctly there's no native pattern matching support, for any type.
Unless I'm missing something, the section about GHC 7.8.5 does not specify what "this breakage", "such a popular OS" (I guess OS X?) and the only included fix actually are.
I wrote [this series](http://www.parsonsmatt.org/programming/2015/10/03/elm_vs_purescript.html) which compares Halogen to Elm. I'm in the process of updating it for the 0.5 release -- but it is mostly similar.
I found it to be way too complex for my taste. I prefer a much simpler approach: [react-flux](https://hackage.haskell.org/package/react-flux-1.0.1/docs/React-Flux.html) Unlike halogen, the state is not spread out through your components and instead is concentrated in one place (store). This makes view rendering a simple pure function with a much simpler type signature. It also makes reading / changing any data in the store much easier and does not require building a complex mechanism for "peeking" into components to get their state. There are no special "parent" components and "child" components with different type signatures, no "installing" compomnents. None of that overengineered cruft. 
It's in the `nordom` branch of the `annah` repository, which you can find [here](https://github.com/Gabriel439/Haskell-Annah-Library/tree/nordom). The key two new pieces of code are the `exec/Nordom.hs` file and the `src/Annah/Haskell.hs`. Eventually `nordom` will go in its own repository.
That means that certain operations are asymptotically inefficient right? For instance taking the tail of a list is O(n) because you have to re-encode the entire list. Do you see any way around that? More generally I think there are two issues that need to be solved before Church encodings are a practical replacement for data type definitions: 1. Translating (mutually) recursive pattern matching algorithms without asymptotic overhead, and then without any constant factor overhead. 2. Getting the induction principles by internalized parametricity. I really hope these issues can be solved, because Church encodings are very beautiful and feel Right^(tm). There's people working on (2) but I'm not aware of any work on (1). Do you know of any?
&gt; have yet to see one good use case for folding a tuple. Traversing a tuple might be useful. I have something like this in my testing code: /* module Foo */ prop_foo = ... some QuickCheck code ... run :: IO Bool run = $quickCheckAll /* module Main */ import qualified Foo as Foo main :: IO () main = do let tests = [ ("Foo", Foo.run) , ... some more tests ... ] failed &lt;- map fst . filter (not . snd) &lt;$&gt; traverse sequence tests if null failed then exitSuccess else do traverse_ putStrLn failed putStrLn "failed." exitFailure ... and `Foldable` is a superclass of `Traversable`. 
 Yup https://mobile.twitter.com/kmett/status/654185755288444928 
[**@kmett**](https://twitter.com/kmett/) &gt; [2015-10-14 06:43 UTC](https://twitter.com/kmett/status/654185755288444928) &gt; @noam\_lewis Agreed. https://ghc.haskell.org/trac/ghc/wiki/Prelude710/FTP#list offers two roadmaps for how to proceed there. I'm pretty ambivalent about which way to go. ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
Since `Foldable` is essentially the `toList` class, it makes sense to me for these functions to be in `Data.List`.
Sometimes the polymorphism is overdone; just for readability, you don't always mean for something to be used with arbitrary types. When I write `Map.map` I explicitly say that this shouldn't compile if I don't give it a Map. When embedded in some bigger expression or behind a non-annotated `where` it helps read the code. Even if used only sparingly it's important to have this safety hatch, so for example Data.List.length should work only on lists.
It was a sort of crazy decision to prevent some kinds of breakage. Though, of course, it creates others :)
For those interested, I implemented support for this GADT style in this project: https://github.com/derive4j/derive4j
Do you think it would be feasible to build an interpreter that runs embedded systems like the arduino which has only 2k of ram? Or the teensy which has 64k?
kd-trees are hard to mutate generally--they are really best suited to precalculated data sets. If you want a better data structure for dynamic addition/removal that supports similar operations to kd-trees, I suggest a sphere-tree.
It was [discussed](https://www.reddit.com/r/haskell/comments/2vfczx/ghc_710_prelude_we_need_your_opinion/cohiril) at some length in the pre-FTP times. It's a really bad state of affairs, in my opinion, but no agreement was found on who to annoy.
Fascinating. I hope one day to be capable of producing this sort of project on my own. This world is mesmerizing (if not rather difficult.) holding onto the belief that i can be capable of participating if I keep at it.
Oh my, this language is getting more and more complicated, and this is not a good thing. I read the [wiki entry](https://ghc.haskell.org/trac/ghc/wiki/ExplicitTypeApplication) and still don't know what is going on and how it relates to the polymorphism problem.
I could definitely provide such functionality in `annah` (and desugar to an F-coalgebra encoding under the hood), but I wouldn't want to provide it in the core `morte` language. Actually, now that I think about it, this could be provided as an ordinary library, let me see if I can write something up.
The issue is that Data.List is the defacto successor to PreludeList from the Haskell Report, and is the place where combinators like `sort` live. There is a very long tradition of importing that module unqualified just to get at `sort` or one of a half-dozen other combinators in there. However, doing so would then break `foldr` and the like if the versions in there were ungeneralized. https://ghc.haskell.org/trac/ghc/wiki/Prelude710/FTP#list We generalized them because the alternative was about 2 orders of magnitude worse code breakage. The original intention was to remove them entirely after a grace period. However, a rather vocal portion of the crowd wanted them to continue on or something else to happen, so we never started stage 2 of this plan. This leaves us in the current state. From here we could just remove them (the monomorphic versions currently live in GHC.OldList), concoct some sort of weak or qualified-only export pragma and convince folks it was a good idea to complicate our import semantics or accept a ridiculous amount of breakage and ungeneralize them in place without a bandaid. Given that the relative amount of breakage of the first plan is by far the least, I'm rather heavily inclined to go in that direction. I am inclined to start the removal phase, however, to just get this out of the way. Nobody has offered up a convincing plan for the alternatives in the last year.
Colists don't let you fold, unfortunately. With Boehm-Berarducci encodings you can express recursive functions on the type via folds, but you can't do inductive proofs. For instance for Nat you want induction on natural numbers forall P:(Nat -&gt; Type). P zero -&gt; (forall k:Nat. P k -&gt; P (succ k)) -&gt; forall n:Nat. P n Turns out this is a free theorem^* of the type Nat = forall t. (t -&gt; (t -&gt; t) -&gt; t) -&gt; t Neat eh? So what you want is an automatic mechanism that lets you obtain the free theorem for any type *within the language*. That's internalized parametricity.
That clears it up, thanks. 
Data.Trees.KdTree's K nearest neighbors implementation is really inefficient because of this tree rebuilding - I found that out the hard way. Maybe you should be using an R-tree, since they are supposed to be better at adding and removing elements efficiently than KD trees. Apologies for the boring answer, but you could FFI out to a mutable KD tree implemented in C++? 
currently switched to c++ because of that ;)
Just a heads up about a name collision: https://air.mozilla.org/flowbox-io-luna/ Flowbox has been developing a language named Luna in Haskell for a couple of years now. They use it for movie effects and distributed data processing.
What forces the _'s in your pattern syntax? You seem to unambiguously use uppercase names for functions and lowercase names for local variable names.
Course size maybe? The courses I've visited have usually been 60-100 students, courses on rather hard subjects. I guess that's the size where people stop and think before asking totally trivial questions, so as to not embarass themselves. Truth be told, he's an excellent teacher. Combine that with hard subjects and maybe you get disciplined, willing students. Another explanation to consider.
The reason that colists don't let you fold is because they can be potentially infinite, so folding an infinite list is not valid in a total language. I consider that limitation a feature Note that the type you gave is how `Nat` is encoded in `morte`, except with different variable names: forall (Nat : *) -&gt; forall (Zero : Nat) -&gt; forall (Succ : Nat -&gt; Nat) -&gt; Nat So I'm guessing the point is that you want induction on natural numbers but you don't want to give up O(1) pattern matching on the head of `Nat`. For that I don't have an answer
It's type-application — which I know about from Pierce's Types and Programming Languages. Working through that book will give you a good understanding of what types do, and how types work in strongly typed languages. It's the first time I've heard of this proposal, but I must say that I immediately understood what the syntax intended to do here. It's actually a very intuitive way of specifying a type, and it's already done in GHC's core (as you have seen from /u/Tekmo's post below.) I can wholeheartedly recommend reading TAPL. It's not a difficult read, and very well explained.
I'm more confused by `and (False, True) ` than I ever was by lens. Lens is more deep than confusing. Just much to learn, nothing that's very confusing though.
[Visible type application](https://phabricator.haskell.org/D1138), in flight towards [GHC 8.0.1](https://ghc.haskell.org/trac/ghc/wiki/Status/GHC-8.0.1).
Leaning this way myself. I get that the latter form matches Core, but I'd really rather match Haskell.
haskell-ghc-mod supports `ghc-mod` 4.1.0 to 5.2.1.2. The page for it says it might work with 5.4 but it isnt guaranteed
Just tried to install using cabal install ghc-mod-5.2.1.2 ... and it failed miserably. Something about ExposePackageId not in scope in Ghc.Mod.Gap. Build failure. Is this what sandboxes are for? Have I just entered cabal hell?
"looks sleek [...]" no screenshots why
React-flux is great, and if it meets your needs, it's an awesome choice for UI development. That said, if you take a closer look at Halogen, you'll find that some of your characterizations are not correct. For example, there is only one type for Component, not two, although you'll see type synonyms used to clean up signatures. Also, the parent state always includes the state of children, and peeking lets you observe child responses to queries or commands (not state!). In Halogen, both rendering and query processing are pure functions. And unlike react-flux, you don't have to use effects anywhere in your UI (which revolutionizes testing and improves code comprehension). Your entire UI can be purely declarative composition of views and query DSLs. Now, Halogen never lies or hides information behind effects. This means as you compose components, the full state and query algebras are exposed in the type signatures (AKA 'no lies'). This means type signatures can get complex, which is why in many examples you'll see type synonyms and polymorphism. It's not very 'beginner-friendly', but as the types don't lie, they tell you exactly what's possible. For maintaining large, complex applications, this compile-time precision buys you a lot (YMMV). Is Halogen the only way to build UIs using FP? Nope, and it may not be the best, either, depending on your tastes and needs. But it brings purity and precision to levels just not seen in any other UI library. I'd like to think that's the opposite of 'cruft'. :-)
I have my eye on [optic-ui](https://github.com/zrho/purescript-optic-ui) as well, which uses lenses and traversals in a very elegant way to compose components. It's quite young, and the ideas are still being developed.
Just did this today (https://git.gnu.io/snowdrift/snowdrift/blob/master/TEXTEDITORS.md) worked wonders. Just remember to make sure atom sees the $PATH with the stack compiled ghc-mod (launch it from command line on Mac for example).
Thanks! I haven't used stack so far. Do I need to expect problems using cabal and stack independently, or can I safely use both asynchronously? Edit: Well, turns out all I had to do was start atom from the CLI. Gnome-Do won't do.
What's subjective is choosing the measure of black pixels instead of something else. I had a professor of optimization that used to say that *an [objective function](https://en.wikipedia.org/wiki/Loss_function) is anything but objective*, because choosing what you optimize for is inherently subjective.
I've been using both cabal and stack asynchronously. I don't think you should have any problems since stack puts all it's stuff in a differently directory than cabal.
Gah! Time to start brainstorming more names "/
Actually, I think there might be at least one law, which is that if `f` is both `Foldable` and a `Monad` then `toList` is a monad morphism, or in other words: toList (return x) = return x toList (m &gt;&gt;= f) = toList m &gt;&gt;= \x -&gt; toList (f x) ... and I'm not aware of an instance of `Foldable` that doesn't implement `Monad`, so it's a pretty useful law. However, I generally agree with the dislike for `Foldable`. The main reason I put up with it is because it is a super-class of `Traversable` which is a pretty lawful class. Also, `Foldable` has the handy property that you can derive it for data types using `DeriveFoldable`.
We went through this forever. The law is the free theorem. The statement that now appears in the documentation does at least admits this, if I remember, but points out the interest of the free theorem. Obviously Traversable could have a foldr method. As far as one can tell, it was just the desire to get things like Set on board that gave rise to the separate class. 
Thanks to vertical composition, you only ever need to compose 2 levels into 1 -- so the above example is actually as complex as you need. If you actually *wanted* a single component that has knowledge of 300 subcomponents, I'd say that's a problem with information flow in your application. Components should be as polymorphic as possible and should know as little as possible, which means that a big application can be reasoned about locally, one level at a time, and with code no more complex than toy examples. Now, that doesn't mean you should use Halogen. You probably shouldn't. Halogen is designed for the subset of functional programmers who *really* want to avoid effectful code and who like types to reflect semantics, and who are willing to pay the cost of that in a non-dependently-typed programming language (which sometimes means writing routing code, like the above, that is impossible to get wrong, because the compiler will balk, but which is basically a runtime proof of something you'd really like to prove at the type-level). While you have to write a bit more type mangling in some places, in other places, you have to write less. For example, did you know that components in Halogen are automatically installed and uninstalled in response to changes in the view? Or that views are automatically rendered only a single time unless their state changes? Or that you can test a well-written Halogen app completely on the server-side, without simulating browser motions? Or that you can weave effects into a Halogen app by interpreting the application component's output DSL? These are not possible in any other UI libraries. That's pretty cool in my book, even if it's not a reason for most developers to look at it (by all means, use react-flux, it's definitely cool too in different ways!).
&gt; I'm not aware of an instance of Foldable that doesn't implement Monad `Data.Set`
Thanks for these updates. It is really nice to get a condensed view on what is going on in GHC!
Wasn't there a survey during the FTP decision process that concluded the Haskell community (in majority) supports breaking changes in the interest of moving the language forward? In 5 years no one will care about broken code from today, but inconsistent or confusing design decisions will handicap adoption of the language for as long as they exist. Just rip the bandaid off :)
No, `foldMap` makes sense for all monoids. Even though it is named `Data.Set` it is clearly a set equipped with an ordering. Anyway I don't see what this has to do with the discussion at hand. 
But we can take it... because it's the `Data.List` we need right now, not the one Haskell deserves... =)
Skipping the annoying programmer thing where I note the weirdness of the request: none of the above. Find a low-power efficient x86 server platform and use that. ARM works, but it's more trouble than it's worth for what you're doing. If I can't convince you on that point, then benchmark the workload on one of each and incorporate that into your final decision.
While I definitely disagree with Erik's tweet, it is not true that /u/really_qmark posting it here was "not constructive". Upvoting.
`toUpper` uses the Unicode definition of lower-to-upper conversion. `'\246'` is Unicode "LATIN SMALL LETTER O WITH DIAERESIS", i.e., a lower-case 'o' with two dots above it. Why is it surprising to you that the result of `toUpper` on that is "LATIN CAPITAL LETTER O WITH DIAERESIS"?
Why not just this? prop_convert c = convertToCapital c == if isAscii c then toUpper c else c In particular: is there anything magical about `==&gt;`, or is it just syntax for `if ... then ... else True`?
&gt; control-bool What a nice library. Thanks for pointing this out!
Yep. I have a haskell platform installation that regularly gave me problems, and stack running happily alongside. I can confirm that they don't mess each other up, unless you count the fact that winghci pleasingly switched to 7.10 when stack did as messing up.
Before you buy anything, I recommend trying out your soft on cheap [dedicated ARM servers](https://www.scaleway.com/) It worked almost fine for me. Boot latest Ubuntu (not LTS, but latest release). Use GHC [from here](https://packages.debian.org/experimental/armhf/ghc/download). Put `library-stripping: False` into your cabal config to omit ton of warnings as per [issue](https://ghc.haskell.org/trac/ghc/ticket/10376). As for "what to buy" – I'd go with Raspberry Pi, but only "Raspberry Pi 2" version, since it's ARMv7, which is supported by Ubuntu and can also have these GHC binaries. I never tried other boards, but probably any ARMv7 would do.
Yeah ok, not many things are monads and comonads. There's [Moore](https://hackage.haskell.org/package/machines-0.4/docs/Data-Machine-Moore.html) but the Monad instance is unusuable. The [foldl] (https://hackage.haskell.org/package/foldl-1.1.2/docs/Control-Foldl.html) library is also an interesting analogy and is very close to the signature. Fold has a comonad instance but not FoldM, which is the monadic version of a Fold. (A lot of ifs but) if there was a comonadic transformer FoldMT m w a b (seperating the m monad and the w comonad) and a comonadic transformer EarlyT w a b, then you might end up with a neat comonadic transformer solution. But your final sig is much better than these ifs and maybes! 
Multi-paradigm is always a lie.
Yes, I was adverting to that interpretation in what I said, if you look. `Set` admits two interpretations, one is `Set`, the other, if you like, `SetEquippedWithAnOrdering`. On the interpretation you mean, the Ord constraint is a part of the meaning of the type; on the Set interpretation, the Ord constraint is a condition of sensible implementation -- it is like the Hashable constraint on HashSet, which despite its use in the name of the type does not enter into the meaning of the type. (Note that HashSet implements Foldable, despite basically asserting that it doesn't guarantee order.) There are presumably still other ways of looking at such types. 
Interesting. But other than the video of the talk itself, the only link is to the home page of /u/Tekmo's blog. Could we have more info please? * Where/when was this talk? * Links to the original posts about morte and Annah * Links to other stuff written/spoken about using morte for the Internet of Code, by /u/Tekmo or others * Links to related ideas. /u/joehillen posted links to [fragnix](https://github.com/phischu/fragnix) and [slices](https://github.com/rwilhelm/slices), and /u/Tekmo [commented](https://www.reddit.com/r/haskell/comments/3p2bfo/the_internet_of_code/cw2lr6e) on them - nice! Those are both also Haskell - how about other languages?
We use cursors from `xml-conduit` extensively for parsing, and I think it is still the best option out there for simplicity vs. power. However, there are some caveats: * Valid XML is required. There is a lot of junk out there on the net. Browsers deal with it, but `xml-conduit` won't even get started. I believe this is also a problem with HandsomeSoup mentioned elsewhere in this thread. (This is what the tagsoup library is designed for, but the trade-off is that then you lose structure. Take your pick.) * Cursors are a bit tricky to understand. The documentation doesn't do much more than quote the XPath documentation for similar or analogous XPath combinators. That's not always very helpful, and completely unhelpful if you're not already familiar with XPath. But if you're willing to give it a day or two, you'll get it. * Cursors are hard-wired into the bare list monad. So, for example, if you need any non-trivial error handling, you have to thread it through your parsers manually.
I thought this attempt by Gershom Bazerman of giving a "law" of sorts to Foldable was interesting: https://groups.google.com/forum/#!msg/haskell-cafe/-zd0Kyhjqs4/99QdS3J86OgJ I find this "all the as that can be extracted from an f a" interpretation quite intuitive (although, apparently, it doesn't work well for GADTs).
I agree with you about the twitter post. But upvoting or downvoting is about the reddit post, not about the twitter post. Downvoting means "No one here wants to see this; please make it disappear". It is useful for off-topic posts, spam, trolls, etc. People in the Haskell community do want to know that Erik is saying this and discuss it. Erik is well-known and influential in the world of software in general, plus he has roots in Haskell. It is not helpful for us to put our heads in the sand and make believe that Erik never said this. So the reddit post is indeed constructive, even though the twitter post may not be.
readme got updated: https://github.com/monky-hs/monky/blob/master/README.md
&gt; People in the Haskell community do want to know that Erik is saying this and discuss it. What is there to discuss, trying to guess his argument for him? Making an offhand controversial remark, without any argumentation, for the sole purpose of stirring up a discussion, is "trolling" in my book, no matter who does it. I don't see how ignoring this kind of posts is "putting head in sand".
dnib
This appears to be a reference to the FTP controversy. That is the sensible definition of `foldr` only according to those who like FTP. According to those who don't like FTP, the sensible definition is the traditional one: foldr :: (a -&gt; b -&gt; b) -&gt; b -&gt; [a] -&gt; b Enough of that flame war. Let's not go there.
The Adapteva Parallella has a dual core A9 and a 16-core SoC thingie, 1GB DDR3, an FPGA on board and GbE networking: http://www.parallella.org/docs/parallella_manual.pdf . It can run Ubuntu, so I suspect you can build GHC on it etc.; however I think one should be keeping both eyes open on space leaks ..
:)
It occurs to me that there are other things that are "extractable" in some sense. Random is extractable if you're in IO, for instance. MarkupM in Blaze seems to behave similarly (I may be wrong about this one). Const a a as well, which is useful for processing one element and... not much else.
Tbh, I only really mentioned it because the old definition still shows up on Hoogle. https://www.haskell.org/hoogle/?hoogle=foldr (I'm not entirely clear on why.)
No worries
The `haskell-ghc-mod` package has an additional path directories setting, add the appropriate entries there to ensure that `ghc-mod` and `ghc` are both visible to the package, and you don't need to worry about CLI vs GUI launch. 
Do ghc and cabal-install have Debian packages for ARM architecture? If so, Raspberry Pi is an easy way to get into cluster computing.
ARM is not a bad platform at all. Using Ubuntu ARM I was able to get ghc and cabal (no ghci at the time, not sure if it's available now), as well as a bunch of other libraries through apt-get. So, no need to build ghc from source, nor to cross-compile, at least for playing around, in the setup that I had. One caveat for cloud haskell is that I believe two nodes can only talk if they were compiled on the same architecture, so the master node would have to be running on the ARM board, too. I didn't do any clustering - just a single BeagleBone black. Hooked up to a projector and some Staples "Easy Button"s. But my application was running an little game with gloss and JuicyPixels - I was very impressed that so much works out-of-the-box. Compiling on those ARM boards is a lot slower though. So I did all my development and debugging on my (x86) laptop, then just moved the files over to the BeagleBoard and recompiled there when they were ready. Very curious to hear how your project goes.
Oops! I fixed it. Thanks!
Ah I missed that. The discussion seems to be looking for some law, any law, which is more than a little strange ... Foldable seemed absurd to me from the beginning since its purpose is to cover Set and Map, but on the set interpretation of `Set` (more transparently `HashSet`, but also any use of `Map` that doesn't give a semantic meaning to the order of the keys, which would seem to be the usual case), `foldMap` is *transparently* meaningless ... unless the monoid is commutative. A restriction will only be good if it rules this instance out as applicable to monoids generally. The point isn't really theoretical, it arises immediately in programming, since typical folds are iterations and an unordered iteration is ... difficult. What does `foldMap` *mean* in say `HashSet`, where it is explicitly affirmed - in exact reflection of the meaning of the type - that the order of `toList` is indeterminate? This is a practical problem; it seems clear it should be excluded, for the simple reason that the implementer has to be saying something about monoids in general, and the only thing that can be said about them in general is a word salad. Yet the whole purpose of the `Foldable` class is to allow such instances. It seems that the laws of traversable, read at the monad instance for `(,) a` are exactly what are needed to exclude intuitively specious `foldMaps` like the one in HashSet.
This was talk was given this last Thursday at a Haskell meetup in San Francisco. You can find the original posts on `morte` here: * [Morte - An intermediate language for super-optimizing functional programs](http://www.haskellforall.com/2014/09/morte-intermediate-language-for-super.html) * [The internet of code](http://www.haskellforall.com/2015/05/the-internet-of-code.html) There's been no post on `annah` yet because I haven't release the library just yet. There's still more work to be done. I've given one other talk on this which is pretty similar to this talk (except slide-based instead of a live demo): * [Secure execution of untrusted scripts](http://forwardjs.com/university/secure-execution-of-untrusted-scripts) I haven't really followed the prior art for this in other languages, so I can't comment on that.
Odroid XU4 8 cores, 2GB RAM, USB3, and an okay GPU with OpenCL drivers.
The order of arguments to elem makes more sense with backtick notation: 3 `elem` [1..10] 
Could you say something about the differences compared to `xmobar`?
I know plenty of Foldable instances that aren't Monads. Set makes a pretty glaring example.
Its rather humorous that you have listed Arduino there. Do you have any application you're using this for? How can we even start to recommend a product before you give us a concrete use case? Again, the fact that you listed Arduino showed you have done very little effort to even understand the devices and what they are capable of. A Home cluster hints at compute for me, and ARM and compute don't go together very well, Grab a cheap GPU and write some OpenCL/CUDA (forget cloud haskell). Otherwise buy a Haswell ITX board for the price of how many "units" you were planning on buying, and forget the hassle of syncing them all up over a slow ethernet thats sharing a bus with the USB.
For Raspberry Pi you can only get GHC7.6.3, without dynamic linking, template haskell or GHCi
A fine example of practical lens use. Thanks Gabriel and keep up the excellent writing.
My pleasure! :)
Just wondering, because I suspect that the list on the wiki isn't comprehensive, but are you going to be at Hac φ?
On the other hand in the last few weeks the "Don't ever change my Haskell at all, not even the tiniest bit" faction has been very vocal.
Not this year, but perhaps another year
Excellent post! Now I'll have to try again to get a grip on lenses...
Just last night, I was talking with a coworker about how I'm not sure you fully realize what a tremendous pillar of the Haskell community you really are. This is me making sure you do. :)
Thank you. I really appreciate that :)
I have a [lens-tutorial](http://hackage.haskell.org/package/lens-tutorial-1.0.0/docs/Control-Lens-Tutorial.html) on Hackage that you might find useful
That is one part of it, but the other part of it is that certain programs are most likely a mistake (such as `length (Left 3)`), and it's better to make this a type error.
And it's an excellent tutorial, too. You've consistently done a great job of getting to the simple, key lessons that make the entire infrastructure approachable and understandable.
Meant to give /u/Tekmo Reddit gold for the article, but accidentally gave it to /u/sibip too. Oh well, /u/sibip enjoy the Reddit gold for being an all round great Haskeller!
Hi /u/Tekmo, there is a typo, with a missing " &gt;&gt;&gt; over _Right (+ 1) (Left "Foo") Left "Foo 
I recently realized that some type have instances which results in incoherent behaviors. Like Foldable on a tuple, or Ord on Maybe. For now I had never found an interesting use case for those instances when in many cases it was, as you said, a code mistake.
Yep, did this specifically with kd trees once: http://tavianator.com/k-d-forests/
 I'm just saying that "readability" is both subjective in that it depends on he person, but also quasi-objective in that I would expect large groups of people to have consistent preferences. 
I've read through (some of) the blog posts and the [tutorial ](http://hackage.haskell.org/package/luminance-0.5.1/docs/Graphics-Luminance.html), but I still am not sure about the goals of this library. Why and how is it different from pure opengl? 
The use case is not `Maybe` directly inside set but deriving `Ord` on something with at least one `Maybe` field. You also get the same arbitrary choice for e.g. `Ord Bool` and many other `Ord` instances of sum types. It is definitely portable.
&gt;On the other hand, Ord on Maybe makes an arbitrary choice on the fact than Nothing &lt; Just t. It is no ~~less~~ more arbitrary than `[]` being the smallest list.
I agree.
So you would say that newcomers do find it confusing? https://twitter.com/a_cowley/status/654046363945160704
[**@a\_cowley**](https://twitter.com/a_cowley/) &gt; [2015-10-13 21:29 UTC](https://twitter.com/a_cowley/status/654046363945160704) &gt; The current Haskell brouhaha is a bunch of newcomers saying, "It's not confusing," and a small group of experienced users saying it is. ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
Do folds from [Control.Foldl](http://hackage.haskell.org/package/foldl-1.0.7/docs/Control-Foldl.html) work with folds from [Control.Lens.Fold](https://hackage.haskell.org/package/lens-4.13/docs/Control-Lens-Fold.html) somehow? I've tried to use an "applicative Fold" over a lens fold, but the only thing I figured out was `Foldl.fold foo . Lens.toListOf`.
You can lift folds over a prism a a sort of escape hatch. See `beneath` in the `folds` package: http://hackage.haskell.org/package/folds-0.6.3/docs/Data-Fold-Class.html#v:beneath
MRP is a thing that if we decide to do it will take place on a fairly glacial timescale. Effectifely, nothing can happen at all until 8.4 at the earliest. I do think that doing something gross in terms of a compiler hack around return would be well included in such a package, however.
If I had it to do over again, I probably would have fought harder against the crowd that wanted to generalize it and `null` in the first place. It was fairly marginal. That isn't to say that I support thrashing backwards on that decision now that it has been made and that some newer libraries have started to adapt and drop their local definitions of each of those combinators in favor of the shared ones. It _is_ very nice to be able to use this on many different foldable containers: Sequences, Maps, Sets, heaps, vectors, etc and to have those be able to be optimized implementations rather than the dumb thing they'd have to be without being in the class and recoloring the bikeshed on this at this point would cause all sorts of pain to the very folks who trusted us enough to adopt them.
I think it's more or less an efficiency hack (like most of `Foldable` outside of `foldr` and `foldMap`). For example vectors can read out their size in O(1), while `foldr (+1) 0` would have to traverse the whole vector.
A good reason to have `map`, `fmap`, and `liftM` is that sometimes you want specific types. If you have multiple listy things in scope and only one is a genuine list, using `map` will ensure that you are mapping over that one. More concrete types can also help with type inference. In terms of naming things, `liftM` makes sense because of `liftM2`, for which there is no `Functor` analogy... `Functor`s literally cannot support the operation you need to make `liftM2`. That is precisely the difference between a `Functor` and an `Applicative`. The question then is why `liftM2` when you have `liftA2`, and the answer for that is that until literally the latest major GHC revision earlier this year, `Monad`s did not have to be instances of `Applicative`even though they all are. Also, `&lt;$&gt;` is not a higher precedence apply than `$`, it is infix `fmap`.
You need to learn three things to get proficient at Haskell: functions, data-structures and type classes. You need all three to understand foldr in FTP. You only need functions and data-structures to understand foldr in List. The students know type classes by the time I introduce foldr, but 7.10 requires them to hold three new concepts (functions are first class, walking over a specific data structure can be generalized; how you walk over a container can also be generalized) at the same time. From experience, its just too much at one time for *new* users.
I'm not sure if I understand what you mean. Gabriel's `Foldl` is definitely a `Profunctor`, even though it lacks an instance, so it could be used with `beneath`, but I don't see how does that help. Thanks anyway, I'll have to think about it.
Sorry for calling attention to this here - CST.SO hasn't a lot of traffic and, since I know some folks here are directly interested/affected by this issue, I thought it would both be useful and maybe help me figuring the answer.
This take a full two seconds to run anything on my computer. Is there any way to make this faster?
Compile the script. `ghc` will ignore the header, including the `#!` line
I've got some code showing that data ListZipper a = ListZipper [a] a [a] has instances for Functor/Applicative/Monad/Comonad/CoApplicative. There's some QuickCheck to check that they're law abiding, I should probably write up the equational reasoning that shows why the laws hold and post something at some point. I'm using it to play around with an interesting implementation of Conway's Game of Life, so I'll probably do the write-up after that's all finished.
The `L'` type in that package is the same as the `Foldl` Gabriel uses, with a few more instances, notably `Choice`.
It was picked that way mostly to avoid having HLint complain. ;)
https://hackage.haskell.org/package/mono-traversable-0.10.0/docs/Data-MonoTraversable.html However, that isn't a suitable replacement for Prelude / superclass for Traversable. 
Even `foldr` can be classified that way.
`liftM` now exists as a valid default definition of `fmap` for any `Monad`. if it was called `fmapDefault`, its purpose would be more obvious. It is there to save you work when you write your instances because we can't plug in part of a superclass when we define a subclass. 
One can think of `mapMOf_` as the underscore version of `mapMOf`—which is itself the lens version of `mapM`—but not as the lens version of `mapM_`.
yes, but in this case, complicating the language with type application can simplify dozens of libraries. like it avoids some instances of the proxy/undefined hack, like sizeOf.
but the first is hacky, you use the composition operator on a type proxy. and what if you want to specialize two type arguments (which I assume visible type application can do).
oh, that's a great point. there should be a warning in the documentation ( if there isn't already). a foldMap_commutative would be cool, but probably too fragmented.
Haskell's not perfect. only least imperfect. 
I wrote a bit about making use of some advanced features of the GHC type system to achieve additional safety guarantees when trying to generate SQL using Opaleye. This is more of a walk-through that explains in detail how to use the type system to reason about different problems; the lessons here should be applicable beyond this single Opaleye example. 
I'll double down - you're probably the single most important public face in the community right now. There are obviously other important contributors, and they fulfill equally important roles. But you're a lighthouse for newbies and established Haskellers alike.
I should be thanking you all. I wouldn't be where I am today if it weren't for the Haskell community.
good to know :)
oh yeah, i've done that before for fun, when trying to understand Foldable :) thanks!
&gt; but thankfully, whenever a finite-dimensional and square Alas, I don't live in a world where all matrices are square ;)
Is that not what I said above?
Do you use it? Could you point to some written account about setting it up in a cluster configuration?
Wouldn't it make much more sense to the following situation, where `Prelude` exports the `Functor` `map`, and if you need a specialised one you `import Data.List as List` and write `List.map`? Prelude.map :: Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b Data.Functor.map :: Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b Data.List.map :: (a -&gt; b) -&gt; [a] -&gt; [b] Data.Vector.map :: (a -&gt; b) -&gt; Vector a -&gt; Vector b Data.DList.map :: (a -&gt; b) -&gt; DList a -&gt; DList b ... What's stopping us from setting `Prelude.map = fmap`? PS: we do have liftA :: Applicative f =&gt; (a -&gt; b) -&gt; f a -&gt; f b liftM :: Monad m =&gt; (a -&gt; b) -&gt; m a -&gt; m b wouldn't it be consistent for naming to also have a synonym liftF :: Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b defined?
Unless `stack` gets abandoned once `cabal` catches up and adds native support for package sets. Anyway, you should also mention how to use `cabal`, otherwise inexperienced users (which also are your target audience I assume?) will wonder what this `stack` thing is, if they only know about `cabal` (and nobody should be forced to install `stack`)
Wtf... how is that simpler than $ cabal install lens-simple $ ghci &gt;&gt;&gt; import Lens.Simple ?! ಠ_ಠ
Safety, basically, and it’s more Haskell-idiomatic than imperative expression. You can find more information on the [github page](https://github.com/phaazon/luminance). It gives you information about what luminance is. The main motivation was to provide people with a simpler, safer and easier-to-learn API. And trying to prevent the case when you just have a black screen because you’ve mismatched OpenGL format or enums.
I'd really like to see a comparison between Opaleye and Esquelto. I've used Esqueleto in anger, but wondering if Opaleye has enough improvements to make me want to switch (at least for my next project).
Well, what's the definition of "optimal"?
I'm rather fond of the ASUS Chromebox: http://www.newegg.com/Product/Product.aspx?Item=N82E16883220572 It's definitely more expensive than a Pi2 or BBB, but it comes with case and power supply and will be both faster and easier to maintain. I got a bunch of them at work for prototyping embedded stuff after dealing with insane headaches with broken Linux kernels for the Pandaboards we were previously using. Unlocked them and installed minimal Arch Linux builds, and they just work like any other PC, except they're tiny and nearly silent. They've also got built-in WiFi/Bluetooth, which is handy if you want to place them throughout your space rather than hide them all in a closet or something. It's really hard to find a better price/performance/convenience deal than these. They've got fast storage, enough RAM for local builds, and assuming you want to use them headless, there's no 'starter kit' needed to get them running. If you get bored with your cluster, they make excellent HTPCs or classic video game emulation boxes, too. 
&gt; Eventually they cabal install yesod, which breaks everything and end up in cabal hell. Right, Yesod... that's the one single package I avoid installing outside a sandbox. The Yesod package seems to be doing something significantly different compared to other packages that it triggers cabal hell more often than not :-( &gt; Finally, having stack install GHC means that you'll be using the same version of GHC that /u/Tekmo did, even way in the future, meaning the tutorial will still work, just as I mentioned before with the updated packages. cabal install lens-simple=0.1.* Then I get the same major API version of `lens-simple` as the tutorial was describing (or we could pin the minor version to be even safer). In contrast `resolver=lts-3.9` doesn't tell me much about which version of `lens-simple` was used, unless I go look it up somewhere in the package-set describing `lts-3.9` (where is the most convenient place to find that information btw?)
Maybe cabal should be deprecated instead, and nobody should be forced to install cabal?
If you use length on a Set, is it O(1) like it should be?
That's really nice. I agree with the naming convention - it makes things clearer. There's not a lot of enthusiasm for renaming established prelude functions though, which is why I like your Prelude.Unicode suggestion so much. 
The aim of Opaleye is type safety and composability. If those are amongst your highest priorities then it's probably worth switching. If not, probably not.
I don't know. Maybe: foo . (:: Double -&gt; Double) . bar 
Thanks. Nice stuff!
Could someone please expand on Gabriel's statement that recursion rarely gets below 20 ns. So what about numerical code in Vector and similar libraries? These are definitely fast libs and they don't use any encoding tricks. 
Hmm... I was thinking that because of laziness, foldr is short-circuiting "for free": Prelude&gt; let myAnd = foldr (&amp;&amp;) True Prelude&gt; :set +s Prelude&gt; myAnd (replicate 100000000 True) True (5.07 secs, 8794803832 bytes) Prelude&gt; myAnd (replicate 100000000 False) False (0.00 secs, 8624656 bytes)
&gt; (where is the most convenient place to find that information btw?) https://www.stackage.org/lts-3.9
Rails seems to do well on this spreadsheet. Can I ask why you're switching? There are definitely some advantages to Haskell (and other languages) that wouldn't be captured by it. My frustrations with Rails include: 1. Rails is super slow. Running a fleet of servers is expensive and carries hidden costs like longer deploy times and thousands of connections to databases. 2. Dynamic typing makes code very unreliable. While making a small site with Yesod I had no 404s or 500 errors in development—it's unthinkable that when making even the smallest Rails site I wouldn't make any typos, make bad assumptions about parameters always being present, etc. Dynamic typing also makes validations much harder. 3. Rails' multi-process model makes pulling data into local caches impractical. Running entirely off local, cached data is core to my company's Java services: it decouples their uptime from the database and gives more consistent and dramatically improved performance. But maybe these aren't important to you, or don't apply to the type of site you're making (e.g. 1 and 3 are more specialized to a high traffic site).
Minor nitpick about the german. Tisch just refers to the table with legs, not the table with data, that would be Tabelle.
Not really related to Haskell, but if you are making a web framework comparison matrix you may also want to check out Elixir's [Phoenix](http://www.phoenixframework.org/).
if you have enough reputation on one subsite you automatically get 100 rep on every other one you join (and so can upvote and stuff)
you mean in the class declaration of functor or in general - for all non list datatypes 
By what reasoning should it be 1?
From a semantics point of view, `map` can be used to express the intent that you want to map over a list. The compiler would prevent you from accidentally mapping over a different functor. From a syntactic point of view, I would prefer `map` for the general operation, and e.g. `mapList` as a specialization of `map` to `[]`. Ideally, I'd like a way to partially apply type class instances. Then I could write something like `map @[]` to specialize `map` to lists, which I find clearer than `map :: (a -&gt; b) -&gt; [a] -&gt; [b]` and requires less boilerplate than defining a dedicated `mapF` for each functor `F`. But afaik partial type class instance application seems to be problematic for general expressions, which do not neccessarily have an explicit type annotation. In those cases the ordering of multiple type class constraints is up to the compiler so it's not clear which constraint to specialize. I had [a discussion](https://www.reddit.com/r/haskell/comments/2vmzaw/ftp_dangers/cojimsh) with /u/edwardkmett some time ago, where he explained some of the approach's problems in more detail.
No, they have different types for a start. map is the same as fmap, only when specialised to lists.
For teaching purposes you can give the specialized signature, and explain the more general signature later. The only thing that may be harder are the error messages.
I'm assuming you mean, why does `map` operate on lists and not on functors in general. Or to put it another way, why is `fmap` not called `map`? The reason is that `map` is simpler than `fmap`. It is easier to understand because you don't need to understand type classes or functors. It gives easier error messages, for the same reasons. When operating on lists, it is also more explicit, since it explicitly only operates on lists. The reason is not that nobody thought of making them the same, or that functors hadn't been discovered when Haskell was invented. Whether this is a good enough reason is a matter of opinion. It is, perhaps, less obviously good than before the FTP changes ( [https://ghc.haskell.org/trac/ghc/wiki/Prelude710/FTP] ). It's still reasonable though. 
I know, I asked that question. But I understood that (as soujak put it), it just meant that optimal evaluators aren't miraculous. It didn't mean there are terms that can be evaluated quickly in non-optimal evaluators yet slow on optimal, which is what seems to be.
BOHM (and Anton's evaluators) takes fewer beta reductions but a ton more of combined total interactions.
Actually, they do use some encoding tricks: according to http://bartoszmilewski.com/2013/06/10/understanding-f-algebras/ , Vector library uses F-algebras to extract recursion into something more easily optimizable.
That's related to the "higher cost" thing. Why spend lots of time to add tests manually when you can have your compiler check conclusive proofs for the same thing?
I explored that idea a bit but did not pursue it thoroughly as I am not particularly convinced about `Nullable (Column a, Column b, ...)` for multiple columns. For a single column I think it can work quite well, I can't think why not off the top of my head, but maybe for multiple columns it deserves some further exploration. It would be nice if it did, though.
I suppose the problem is that not all "non-nullable operations" really make sense when lifted into this proposed `Nullable`. Only the operations which return null when any of their arguments is null really make sense, I think.
OT: I like the naming scheme: &gt; Koln, short for “Column, nullable” &gt; “HsR” stands for “Haskell, Read”. Since naming is always troublesome I guess it's nice to learn new scheme for it:)
While I agree that lenses work really nicely in practice, I find it amusing they're being promoted as an alternative to type classes, when the Van Laarhoven approach depends so fundamentally on type classes.
True, but you will still need tests for logical things, rather then syntax/semantics.
Yes, but fewer of them, since the type system rules out a lot of logic errors. (Such as the mentioned 404 errors.)
I think /u/gasche is saying that you should verify whether your term is elementary-affine typable because your algorithm is not necessarily optimal otherwise
A more accurate statement of that theorem is "if you don't know anything about your objective function, you can't perform better than blind search", but in this case we do know some things about our objective function (i.e. fewer reductions is usually better, avoiding recomputation is usually better, being cache friendly is usually better, etc.).
Thanks for the feedback. I didn't want to give a particular example to give at the beginning as this is more about using the GHC type system in general and not so much about individual examples, but I'll try to adjust the first few paragraphs so that they mention the various topics that will be discussed later in the article.
If anyone is newer to haskell and has concerns about using lenses (because they can be confusing sometimes), you can consider using [Data.Either.Combinators](http://hackage.haskell.org/package/either-4.4.1/docs/Data-Either-Combinators.html) from the `either` package to get non-biased maps over an `Either` (`mapLeft` and `mapRight`). Just thought I'd mention it as an alternative.
if Set has efficiently overriden the method, yes
you haven't made any claims. what exactly is the issue? if people from object oriented backgrounds (like myself) stop trying to define ad hoc typeclasses for things like HasLength, that's a good thing. both for the person who's learning haskell and the people importing that code.
I'm not sure I follow - the algorithm isn't supposed to be optimal. I believed optimal evaluators were supposed to evaluate any term with same or better asymptotics than non-optimal evaluators. That's what I thought optimal meant.
read my response to duploide
Yes but optlam implements a simplified algorithm that is only optimal on a subset of the lambda-terms (those that are elementary-affine typeable, EAL-typable for short -- see optlam's [README](https://github.com/MaiaVictor/optlam#how-does-it-work)). I don't know much details about optimal evaluation, but it may be that the evaluator does not fail when you pass it a term outside this subset, it justs behave in a non-optimal way. Implementing the full algorithm (for all terms, not just elementary-affine ones) is known to be rather complex and difficult. Could it be that all evaluators you tried assume this simplified case, and that your input falls out of it? 
I think it does fail actually, but that makes some sense. But definitely not for the last thing you said, I tried many evaluators including the best one (BOHM) and evaluators with and without the oracle with many different strategies. While it is, indeed, the case that some evaluators have a number of beta reductions that increase linearly, the number of total reductions is always exponential. In practice, that means that simply no interaction-net based evaluator is able to compute something like `(badTerm 20)`, whereas even JavaScript with its naive call-by-value strategy can easily compute `(badTerm 200)`. So, that begs the question, in what sense are those optimal? 
I've not used it in a cluster configuration, so I can't offer anything specific there.
One of those is not like the others :) Ember.js is a client side framework, while the rest are server-side. 
This installation `stack install` doesn't polute the cabal user package database in any way, right? And `stack ghci` uses the package database of the specified resolver and the default ghc package database.
I'm glad it helps :)
It's very promising. relational-record has the ability to pull your schema out of the database using TH and drop it into a source file so you don't need to deal with specifying your schema manually. It works with postgresql, sqlite, and mysql (although some operations like intersect don't exist on mysql). Also it is monadic.
Speaking as someone coming from Drupal &amp; PHP, I'm not learning Snap &amp; Haskell because I expect it to have the same strengths as Drupal &amp; PHP. I don't think Snap (I haven't used Yesod much) has many of the features in the spreadsheet. The 'Environment' stuff doesn't seem to be baked in (though I don't think it would be hard to replicate and maybe abstract into a lib for sharing?) Haskell has support for tests (QuickCheck in particular is interesting), probably not as full featured as RoR tests and it would be nice if Haskell caught up, but then you won't need tests as much when using a strongly typed language like Haskell. The items under 'Deployment' are a bit of an apples-to-oranges comparison. Haskell applications are generally compiled not interpreted, so as long as your build and deployment environments are sufficiently similar, it's just copy/paste a single file, restart the application, finished. It's ridiculously easy. On the 'Relational database' section, Haskell &amp; Snap allow mixing and matching libraries, so if Haskell supports the RDBMS, Snap and Yesod probably work with it too. I don't know what the difference between a one star and three star review is in this context though. I believe ORMs are available, but they're not something I use, so I'll defer to others on that question. I'm not sure what's meant by most of the items in the 'Features' section, sorry. [This document](http://www.haskellforall.com/2015/08/state-of-haskell-ecosystem-august-2015.html) seems like it might answer some of your questions. Haskell does have mature support for the file formats listed (YAML and JSON) and it does have support for Unicode, though again I'm not sure what's meant by that feature. Overall, I think this spreadsheet concentrates far too much on things you like about RoR and ignores [all the benefits](http://www.haskellforall.com/2015/08/state-of-haskell-ecosystem-august-2015.html#server-side-programming) Web development using Haskell can bring. Coming from PHP &amp; Drupal, I nearly cried when I saw how fast the Snap framework generated pages, no churning or thrashing the disk for 30+ seconds, it just served the effing page, I couldn't believe it. You won't get many runtime errors either, if it compiles there's a good chance a Haskell application will do what you expect. Try Haskell, you'll find your priorities will change. :)
I think you've misunderstood most of the people complaining about FTP. We don't resist change in general, just some change. I think AMP was the right thing to do, and I think that return should probably be removed from Monad as a consequence of AMP. I do think the FTP change was premature.
It's rather common on the conference circuit to take one's standard presentation and rebrand it in whatever way necessary to match the topic of the conference. Since the conference was CUFP the title had to relate to "commerce" somehow, even if the organizers and attendees gave their forgiveness that the content didn't.
Oh, I misread that as length being 1, not O(1), my mistake.
IMO, you totally deserve the gold for pointing this out. With the release of stack, packaging and distributing has done a complete 180 degree turn having one of the build systems I trusted least for compiling old code to one of the best. The rolling release system of "curation" has turned all those frustrations of being a compiled language into benefits. I'm talking about also how packages are actually shared over the net. Attaching a stack.yaml file to a tutorial is all that is needed. I never seen a single person cabal freeze their sandbox attach those constraints to a tutorial.
I'll keep it in mind, thanks. I'll probably do some renaming before putting this in Hackage.
Rumors of our demise have been greatly exaggerated.
Does opaleye support parameterization of queries?
How can that Scaleway service be profitable? Their pricing is surprisingly low. (I know I sound like a shill. I'm just surprised. I had never heard of them before.)
Welcome back!
I was trying to figure out how to get to more material about using prisms in practice, but I couldn't figure out how to get there without actually introducing the concept first. Even with the extended timeslot that Katie Miller gave me that required a rather large ramp up.
No, not lazy.
Correct 1 &amp; 2. For 3: it uses the stackage package list and automatically sandboxes those packages. AFAIK It doesn't use anything outside base from the ghc installation if one preexists. 
Despite the lack of ordering can store them in a `HashSet`. If you don't care about the ordering of the contents that is typically 3-4x faster anyways.
Interesting! Thanks, I'll check it out. You can see, I'm pretty focused on these deployment &amp; environment features. But if Servant would save me time in other areas, that'd be good.
Rails does well on my chart because it's a tautology: I began using it because it has those features. :-) I'm looking to switch because I'm fatigued by the severely untyped nature of Ruby plus the culture of monkey patching and multiple DSL's. Interesting comments. Speed efficiency is definitely an area of Rails I've needed to spend time on to master. Currently, I get the local/cached type of speed with a combination of enough RAM for my dataset to be cached by the OS, and then memcached with Russian Doll style key generation. And yes, there's definitely a test-writing overhead with Ruby and Rails that'd be lower with other systems. 
Good reminder. I've been reading about it lately on Hacker News.
I don't know :) On the other hand, Raspberry Pi 2 costs $35. Even if we add that to $50 for one machine, that'd be just 11,6 months to pay for one machine, so maybe that's not that much.
Not to mention the `liftF` in `Control.Monad.Free`.
I think it could be possible to have our cake and eat it, it's just the tools aren't there yet. In particular, we'd want to have some sort of notation for non-locally providing implicit arguments, with a simple solver to plug the provided proofs into the right place. The goal being to separate the proof/logical portion of the code from the executable/mathematical portion of the code, since tangling them up together is what causes the syntax to get ugly. That is, the user would write something like the following: x / y / z where proof1; proof2 which would desugar into the explicit version: (/) ((/) x y {proof1}) z {proof2} In this particular example we provided the two proofs in order, but the syntax shouldn't require that. Also, in this particular example we gave complete proofs, but in general we should only have to provide the "hard" lemmas and let whatever standard automation build up the complete proof from those parts.
Yes, [here you go](https://packages.debian.org/experimental/armhf/ghc/download).
Semantically evaluation order does not matter for a total language. Operationally it matters a lot. 
I'd still say it needs more than it has. 
Hmm let me be clearer. What kind of sql does opaleye generate when I pass a user supplied string as a parameter to a where clause? e.g. where FirstName = 'Bob' does it generate select * from Users where FirstName = 'Bob' or does it generate select * from Users where FirstName = ? with the parameter passed in at a later time? If it's the first then I'd be worried about sql injection vulnerabilities and also performance penalties since the query plan wouldn't be re-used with different parameters.
Thanks for going to the effort of putting this episode together. It truly made my day.
I am not sure this is as necessary today as it might have been ten years ago though. People coming to Haskell from other languages are likely already familiar with map and other basic higher order functions today. They are also more likely to have encountered some language mechanism to abstract over different types.
Happen to know how much is "enough?"
No it doesn't require explicit signatures. They're supplied in the order they appear in the (implicit) forall. Source : https://ghc.haskell.org/trac/ghc/wiki/TypeApplication
There is a benefit outside performance, and that is tools like pg_stats - it's hard to do automated analysis when every query is different.
And also `Monad` to `Burrito`! 
i don't see how that makes sense. OP wasn't proposing some enterprisey or anti-mathematical name like "decontainerizeable" or something. fmap abbreviates "Functor Map". I don't really care either way, but map is a bit more clear. 
In Agda, type classes are simulated using [instance arguments](http://wiki.portal.chalmers.se/agda/pmwiki.php?n=ReferenceManual.InstanceArguments). Those arguments are implicit: when you call a function without passing their value, Agda infers their value based on candidate expressions that are in scope. But you can pass their value explicitly as well. I think Idris has a similar mechanism of passing arguments implicitly (but it also has type classes as a language concept).
Finally! I checked everyday in false hope that one came out, finally one has!
&gt; Ubilinux is ... except for the fact that it doesn't appear to be maintained anymore. &gt;... Its Linux ecosystem is fantastic; the community is large, well-informed/well-supported, and experienced; and obviously it's not in any danger of getting the rug pulled out from underneath Among others, those are excellent points. Thanks! 
That's not an argument for why the Functor/Foldable instances for Either/(,) do not make sense. More briefly, that's not an argument.
relational-record is currently missing a lot of basic stuff (like `LIMIT`), and is built on top of `HDBC`, which is very flakey. I used it on a project for a good chunk of time and strongly regretted it.
Good job. But I don't think it goes into WHY the `Functor` instance looks the way it does. Maybe because you were avoiding explaining kinds? We have `data Either a b` This implies that `Either :: * -&gt; * -&gt; *`. The `Functor` typeclass is of kind `Functor :: * -&gt; *` (takes a single type parameter). This implies that `Either a` can be a `Functor` only when it get the `b` (`Right`) parameter. So it is indexed by the type on the `Right`. Ergo, purely **syntactically**, the only way to make `Either a` a `Functor` is by using the `Right` type (the second and last parameter) as a parameter for the `Functor` instance. Thus the `Functor` `fmap` method can only work on the `Right` side (implying in this case that it can only work on `Right` values; for tuple pairs this means that it can only act on the right side of a pair). Admittedly, this isn't very deep. It goes some way to explaining why some people think that these instances are "obvious", although it explains it using syntax and not deep category theory.
Didn't swift get open sourced? 
Am taking the course now. Any questions that were asked in the forums were answered quickly and succinctly. The vibe i got was that he wanted to encourage the students to make an effort on their own first. I quite liked it. First and foremost the student is responsible for their learning. Especially in a MOOC where it would be feasibly impossible for any instructor to do all the answering himself. 
I tried that too, but getting some glibc errors. I'm guessing it's because I'm using a distro with a newer version (Archlinux). What distribution are you using for creating the binary?
I don't understand what you're saying here. The types you point out are, of course, precisely what everyone is already talking about. Prior to GHC 7.10, `(,) a` being a `Foldable` instance wasn't really such a problem because Data.Foldable was imported qualified and used rarely, and `length`, `elem`, etc. were monomorphic. Now that's changed, and there is a substantial down side to the change. &gt; That's fair enough, but this goes into what MLers have been saying about typeclasses generally as well. The important thing here is to treat this as an engineering decision. Type classes aren't evil just because they can have bad effects when over-used. But abstractions like this have costs. What are the benefits that outweigh that cost? I have trouble seeing them.
Here's a strawman migration plan idea: * generalise `Prelude.map` to `Functor` (i.e. set `map = fmap`) * move `map` into `Functor` class with a default implementation `map = fmap`. Also, give `fmap` a default implementation `fmap = map` and set `{-# MINIMAL map | fmap #-}` (better yet if this was possible: `{-# MINIMAL map 'xor' fmap #-}`) While this doesn't remove `fmap` yet, new code can be written against a generalised `map` now, and `Functor` instances can be instanciated as if `Functor` had a `map`-named method. At this point, one can start to *very* slowly phase out `fmap` out of `Functor` to a top-level binding. In the mean-time, shim packages can decide whether to expose `Functor` with a `map` or `fmap` method, or both methods.
One question that is bugging me: the foremost example of a Foldable type that is not Traversable is Set. And yet *Set a* is isomorphic to *Map a ()*, which is Traversable... I wonder, do all "foldables but not traversables" have an "easy" isomorphism into a Traversable type, like Set does?
The problem is that this plan is predicated on every single user who has ever used `fmap` eventually changing their code in a non-backwards compatible way across the board. There is a phase transition there. There is code that lived before this change completes and code that works after, and no amount of CPP will paper over the fact that it is an entirely different name _everywhere_. The other generalizations we did in `Prelude` avoided an actual problem, where the combinator was actively getting in the way of using the more general concept. This is "house keeping" at the expense of major breakage.
She knows that, but the point is that they become considerably more useful with their typeclass instances.
I can say this. I've personally gotten a lot of mileage out of that `Functor` instance. The line of code l %%= f = State.state (l f) in `lens` works with both lenses and traversals out of the box due to the instances instance Functor ((,) e) and instance Monoid e =&gt; Applicative ((,) e) respectively. When you call it with a `Lens` it works and gives you back an auxillary answer as you update your state. When you call it with a `Traversal` you wind up asking yourself for a monoid to aggregate all those auxillary results, as you are going to visit multiple targets. The functional version of this combinator, which doesn't need the state monad is even easier: l %%~ f = l f We've had the instances which I rely on there for 10 years, they were around in `base` 3.0. I have whole a package for talking about adjunctions that relies on `(,) e` being a Functor to even have a canonical instance to talk about. The monad arises in code I have for everything from discussing recursion schemes to typecheckers. The Comonad (which needs the Functor) demonstrates further the adjunction lying there and makes it clear the duality between monads and comonads when compared with the (-&gt;) e monad. You don't use any of these things. I get that. But I'd hardly classify having the ability to think these thoughts as "always wrong".
How in the world have they never used any other language besides Haskell? O_o
I think it's simpler than that. The usual convention is that `Right` represents the case that is "right" - i.e., correct - and `Left` is the other case, whatever is "left" after covering the "right" case. Of course, it's only a convention, and you can just as easily do it the other way around. But since we need to pick one way or the other, might as well do it the usual way.
I did not see this comment from Gabriel before. I though that it was from some newbie. I can not believe it. Really Gabriel propose the substitution of type classes by lenses. WTF????????? Are you kidding Gabriel? Your article is just some consideration for using some lens instead of fmap and little more. How do you plan to substitute type classes in general? do you mean to use registers and lens for field access? That is a level down in abstraction, not a level up. That is how type classes work under the hood! I repeat, are you kidding?
Yes. We are all in agreement on that. My point of disagreement is that what you think is intuitive is not at all to me. The Functor instance for a (semantically exclusive) disjunctive type is quite intuitive to me. But intuitive is at any rate so ill-defined that this is pointless. *wanders off to stare into Void*
This is not theoretical interest. Parameters are one of the fundamental features of any SQL interface library. They are considered obligatory to avoid injection vulnerabilities and other classes of bugs. For at least some of those classes of bugs Opaleye provides a different mitigation, using type-safety, but that doesn't help; the whole ecosystem around RDMS has a built-in assumption that people are working using parameters. So it affects performance optimizations, monitoring tools, etc. Most people wouldn't consider a library to be production-ready if that feature is missing.
But `fmap` preserves the structure of the function, so if you expected it to be something else you'll get a type error somewhere down the line, at least. `length` doesn't preserve the structure of anything, so you won't get any type error at all – the program just chugs along with invalid data. (I'm not saying it's wrong the way it is, I just wanted to point out why you can't compare to `fmap`.)
&gt; but rather a runtime bug What's worse is that it won't crash or throw exception, you'll have to debug it. And your intuition is your enemy in this case (if you don't expect `(,)` to even be a `Foldable`), so you might spend many, many hours. I'd be strongly against these instances if only edwardkmett didn't mention their usage in lens. Because of those I'd just deal with it.
&gt; Of course, it's only a convention, and you can just as easily do it the other way around. Case in point, in F# when we use the type `Choice&lt;'a, 'b&gt;`, which is equivalent to `Either a b`, to designate success/failure, we generally use the first case `Choice1Of2` for success and the second case `Choice2Of2` for failure. But that's mainly because F# doesn't have Haskell's kinds and typeclasses system; in Haskell, using the second case for success is more logical for the reasons given by /u/BoteboTsebo: so that you can map/bind/etc over successful values.
Wow, thank you for the quick response. Especially the **lawless typeclass** one, I didn't know you could have a default implementation, that's really nice ! Yeah, I know there was at least one other project that could do the same but I like things on my own to have a better grasp ;-) Thank you again Ephrion
Awesome work with Haxl and very didactic talk Simon. I'm very grateful to experienced people like you, working in commercial companies that spend time sharing and teaching about real solutions for real problems in real programming. That is something that we really need. Awesome. 
The issue with the mike is distracting.
You've defined valid a = (not . valid) a
ooops my bad, thanks for the catch.
Right, I was echoing the documentation and noticed that ambiguity. It's all pure; it's just that the ordering depends on the hashing function for the type and the library's tricks for using it. You can detect features of the implementation by using `(toList.fromList)` &gt; fromList [0..15::Int] fromList [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15] &gt; fromList [0..16::Int] fromList [0,16,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15] But surprises like this are just what you expect if the library is implementing a genuine set concept. 
But the Functor instances for Either and (,) are arbitrary. It's only because of a quirk in the Haskell type system that they operate on the second type variable. If Haskell had had type level lambdas it could have been the other way around (yes, I know Haskell can't easily have type level lambda). Or what if we had this definition `data Either a b = Left b | Right a`?
Not sure the best place to put this observation, but in reply to your comment here will do... Here's how I think about it to make it seem reasonable: A "container" in Haskell must hold elements of the same type. It can be zero or more; sometimes the number is fixed by the type, sometimes it isn't; sometimes the elements' type is a parameter to the container's type, sometimes not; but such details are orthogonal to that principle. As such, when considering `(a,b)`, that means `(,)` can't be the type of the container you're measuring the length of - its elements can be different types! The only meaningful way to interpret pairs as containers is to say that `(,) a` is the container, and `b` is the contained element - so there's always exactly one of them. A comparison to `data Const a b = Const a` might be illuminating: `Const a b` is a container, `Const a`, that always contains zero `b`s - so the `Foldable` instance would say `length _ = 0`.
First World Problems.
Awesome to see this picked up! Any lessons learned you want to share? Unexpected downtimes or issues?
Here's my assessment of Yesod: **Core Web Features** * Declarative routing - 3 - And they are typesafe * Reverse routing - 3 * Fully Unicode from view to db - 3 - Also first-class i18n support **Relational Database Support** * PostgreSQL - 3 * MySQL - 3 * Migrations 3 - More declarative and automatic than Rails. You just edit the equivalent of schema.rb directly * ORM - 2 - Persistent has a good API but doesn't do SQL joins. Esqueleto provides typesafe SQL-like DSL for writing arbitrary queries. * App/db console - 3 - Haskell is a REPL driven language, you can run your entire web app from the REPL. **Environments: dev, test, production** * Separate configurations - 3 * Separate databases - 3 * Separate logging - 3 **Testing** * Testing support - 3 - Yesod.Test provides lots of helpers for testing your web app * BDD / Spec-style tests - 2 - HSpec is Haskell equivalent of RSpec. RSpec is not baked into Rails either so Rails is a 2 here as well * Acceptance tests - 1 - There are a few ports of Cucumber to Haskell but they are not particularly popular **Deployment** * Heroku - 3 * System for deploying to a server - 3 - see Keter * Asset compilation - 3 - Yesod.Static **Other Features** * Authentication - 3 - Although the default is outsourcing it to BrowserID or OAuth, they give examples for how to set up email/password auth. * Authorization - 3 * Easy JSON parsing &amp; creating - 3 * Less or Sass - 3 - Lucius is equivalent to Less plus Haskell templating * Outgoing email - 2 - Network.Mail.Mime * Easy YAML parsing &amp; creating - 3 * Task Scripts - 1 - But I have not missed rake at all * Admin UI - 1
I wonder if it would be feasible to allow only orphans created with standalone deriving, without complaining about overlap when two packages derive the same instance.
I was only saying that lenses solve some of the issues with type classes, not all of them
That looks to be outdated documentation :-( The `Graphics.Rendering.Chart.Gtk.Simple` module doesn't appear in the `chart-gtk` library after version 1.1 (in 2013). My advice is to use the more up-to-date instructions on the chart library proper to create a `Renderable` and then use the functions in `Graphics.Rendering.Chart.Gtk` to send that renderable to a Gtk window...
Thanks for your helpful answer. But im relatively new to haskell and especially very net to `Chart` so where can i find examples or tutorials with more updated content?
It seems to me like most of the other examples on that wiki will be more up-to-date, but this is just from looking at it (I haven't used the chart library in a long time myself). Those other examples use the Cairo backend, which hopefully works for you. If not, you can try to modify them to make them work on the gtk backend -- but as someone just learning Haskell I'm not sure how easy it will be to work that out...
Regarding project duration: we won the contract in November last year and delivered it in the beginning of June. Before that we had a small prototype that we used to prove to ourselves that the technology could work but besides that everything else had to be developed in that time frame. Our team consists of 2 software engineers (my brother and me), 1 industrial designer, 1 electrical engineer and 1 project manager. Also see my [previous post on /r/haskell](https://www.reddit.com/r/haskell/comments/3959r0/haskellbased_bicycle_parking_guidance_system_in/) where I write a bit about the internals of the system. 
They are middle school math teachers. I think one of the two has some minor experience with Scratch.
FTR, based on @bitemyapp's feedback I've updated the original article: http://tojans.me/blog/2015/10/13/foldable-for-non-haskellers-haskells-controversial-ftp-proposal/#update:916dcbca10117e99a7571170d02b3db4 . Thanks for the feedback.
True. That is a limitation of class/instance syntax. Seems like we ought to have some way to fix those kinds of problems now that type-level programming is becoming more common.
Why is it a problem? You can still do that, if you prefer. Why should we not have any `Functor`/`Applicative`/`Monad` instance of `Either` at all, instead of picking one?
&gt; classes aren't classes No, no, you've got it backwards. Classes aren't classes in OO languages. :)
/me dons flame-proof jacket The `Functor` and `Foldable` instances are useful. But `length` applied to a tuple should not compile, as was always the case. This is yet another problem that was caused by FTP.
There are some classes that can't be derived that I nonetheless use orphan instances for (e.g *JSON instances, Safecopy instances, or Arbitrary instances)
I assume from /u/cdsmith's answer that they're *teachers* who are in a *Haskell course*, not teachers *of* a Haskell course.
&gt; length for (,) is never going to do anything but return 1 because there’s always one value of the type you’re folding over with (,) Perhaps length should be ungeneralized? I'm hugely in the lengthFold, maximumFold camp -- I think it would make our library authors who want to keep tuples Foldable happy, and at the same time would encourage people not to use functions that will make refactoring less safe.
I'm guessing spam of some kind?
Really well put! It's only non-arbitrary because of a non-intuitive technical limitation of Haskell's type system.
&gt; (It's possible I haven't looked in the right places, but the usual keywords "path" and "walk" didn't seem to return anything.) I have been looking for years and also never found one I liked (the one I have used took like 15 mins to figure out every time, even though I used it like for 10 times now). Looking forward to trying pathwalk!
Should we be stating this as a law? Or should we mention that custom implementations should be congruent with default implementations?
Yes, this is right. Sorry for the confusion. These are math teachers, who are co-teaching my CodeWorld curriculum with me. I try to teach jointly with existing teachers at the school. In general, they don't have previous programming experience, so Haskell is their first significant programming language. It's just the closest thing I could find to Haskell programmers without significant non-Haskell experience. In general, though, this experience has taught me that whenever functional programmers claim that certain things are only unintuitive because programmers have had their minds polluted by non-Haskell programming languages... they are usually wrong.
Great work! I think reproducing some of pythons excellent scripting-style libraries (like this) is key to Haskell becoming a full replacement as a scripting language. 
In general we should port nice libraries from every language (or call into them)
Indeed. 'length' seems like a poor choice of name. Consider the definition of length: the longest extent of anything as measured from end to end: For things like 'Map' and 'Tree' which look a bit like a river with branches coming off -- shouldn't 'length' be the depth/height of the longest branch? I think the the intuitive definition of 'length' in Haskell is, "If I converted this value to a list, how many elements would that list have?" For '(a, b)', you really only have a few possible choices: [b] [a] [(a ,b)] In all cases that will be a length of 1. I guess if you were sneaky you could do: [Left a, Right b] And then you'd get length 2. Of course, the type for 'toList' is: toList :: Foldable t =&gt; t a -&gt; [a] Which rules out '[(a,b)]' and '[Left a, Right b]'. I think that intuitively, when you think about converting a type to a list, you don't imagine also incorporating additional new types aside from '[]'. So I think the property that holds is: length x == length (toList x) Perhaps the obnoxious name, 'lengthAsList' or 'toListLength' would give people a better idea of what to expect? Of course, a friendlier name would be nice. On the other hand, I am in favor of having fewer symbols in Haskell not more. Having both 'length' for a list and 'lengthFold' for every thing else just increases the number of things I have to remember. Ultimately, a name can only convey so much meaning. Which is why we have types and documentation. If you just want to guess what functions do while ignoring their types and documentation, then you'll likely have a poor time. tl;dr - The implementation of 'length' is certainly, fine, perhaps the name is the issue? 
`Left` started out as error by convention. The `Either` type predates monads in Haskell. The traditional mathematical notation for the sum injection is `inl` and `inr`, but this was considered too obscure. If memory serves, it was Mikael Rittri who coined the names `Either`, `Left`, and `Right` for the data type. And since this type could also be used for errors it would have been very weird to use `Right` for the erroneous alternative. In fact, early Haskell version allowed renaming on import to avoid name clashes, and one suggested renaming was to rename `Left` to `Wrong`. That the ordering of type variables in the `Either` type was the right one for the monad instance is just a coincidence.
You've missed the point I was making in the article. It doesn't matter if the definition of Either was: `data Either a b = Left b | Right a` It matters that _a_ default exists and is chosen for the Functor because that's the only reason to make something Left or Right. Contrary to developer intuitions, Right doesn't mean "success", rather, it's defined by what the Functor/Applicative/etc. do. I've used Left to indicate Success in situations where I want to stop fmap'ing a computation that might fail. It is the picking-of-a-winner that Haskell's semantics induce that is valuable and not arbitrary. What _is_ arbitrary is what we call left and right and the syntactic position of their type arguments in the type constructor. There's much less utility in an `Either` that doesn't have a Functor with a default target. Further, they _aren't_ arbitrary. Following from the definition of arbitrary that Google provided: &gt; based on random choice or personal whim, rather than any reason or system. We can break it down as follows: 1. Is there a reason the Either Functor works the way it does? *Yes*, it makes the datatype more useful in that it gives us a biased-choice Functor which is frequently useful regardless of whether the biased-target represents success or not. The way Functor behaves is _useful_ insofar as its only reason for existing is to pick one of the two exclusive choices. There is _no reason_ for programmers to favor the target being Left or Right. Those words mean nothing and word/name-fetishism kills software reuse and modularity. 2. Is there a systematic cause for why the Either Functor works the way it does? *Yes*, cf. Jones' work on Gofer dating to 1993/1994. The way the Functor behaves is _necessary_ and follows from how the language works in a natural way. You can make a learner predict what the Either Functor does if you teach them how HKTs and constructor classes work. (I've done this with learners before). So, this isn't surprising if you know Haskell. Summary: It _doesn't matter_ whether one of your types is going to be in the Left or Right data constructor, all that matters is what you want your Functor-target to be. Not having a universal winner for Left or Right being the Functor target is bizarre and counter-productive. You _cannot_ and _will not_ ever have a Functor that lets you pick either/or of Left or Right. If that's what you want, what you want is Bifunctor or a prism. So, we've covered _both_ ways in which the Functor instance is not arbitrary, due to being both _necessary_ and _useful_. We can also see that the way the Either Functor works is neither random nor based on whim. I'm disappointed this hasn't gotten across but I guess I didn't just come out and say it in the article. I'll write a follow-up.
It's a sensible design choice, not a technical limitation, and I'm glad we don't have type lambdas like Scala or the absence of HKTs as with SML or OCaml. Have you used Scala? If not, you should take a survey of what that's been like for them.
I once did a survey of these, a few years ago. There were several, but I agree that none were very satisfactory. What I really want is a function that gives me a `Data.Tree`. The problem is that the most obvious way to do that would result in lazy `IO`, which can sometimes lead to problems. This solution is a kind of roll-your-own CPS approach - which is the underlying approach of Oleg's enumerator, and its modern successors such as [conduit](http://hackage.haskell.org/package/conduit) and [pipes](http://hackage.haskell.org/package/pipes). So in conclusion - this library is fine for generic use. If you're already using conduit or pipes, it would be simpler just to get a stream of `(dir, subdirs, files)`. Some existing more complex alternatives using pipes are: * [pipes-files](http://hackage.haskell.org/package/pipes-files) provides an interface similar to the Unix `find` command, and allows rolling your own `find` predicates using the [CondT](http://hackage.haskell.org/package/hierarchy) monad. (This used to exist for conduits also, but the author has unfortunately deprecated that version.) * [data-dirstream](http://hackage.haskell.org/package/dirstream), written by the author of pipes itself, provides a few simple combinators to build directory traversals.
I don't know if you found my old package: http://hackage.haskell.org/package/directory-tree or if it fits your criteria, but it at least can use lazy IO (like `readFile`) to return a directory tree immediately. It may not be terribly well-designed; it was the first library I wrote, and I haven't touched it in ages.
The trouble with this in Scala has little to nothing to do with the cumbersome notation. Particularly you scan through the history of the Scalaz library and interactions with other parts of the Scala ecosystem to see how it's been counter-productive.
Thanks for the pointer! I've never used pipes or conduit myself but it would be great if there was a layer on top of pathWalk that made it easy to integrate with pipes/conduit consumers. 
Yes, I agree with this. It's definitely a very specialized sample. Unfortunately, I don't know how to find more full-featured Haskell programmers who have also never used any other languages.
&gt; no fancy abstractions Would using `MonadIO` instead of raw `IO` in callbacks count as "fancy abstractions"? Because this would, for example, allow the user to keep state or accumulate a summary between callbacks without using `IORef`s. (though I'm not sure what would happen if someone tried to use `ContT IO`)
I agree with you, but it is also a *feature* that you can swap types and have things continue working in other scenarios. The problem with `length` is that the type in question doesn't appear in the result, so any subsequent calculation is now operating in a regime defined by an unchecked assumption regarding the provenance of the result of the `length` call. The Haskell charicature way to solve this would be to have `length` return a `Tagged f Int`. An easier way would be to rename `Foldable.length` to something like `size`, `count`, or `foldLength`. 
Have you seen https://hackage.haskell.org/package/filemanip? It works for me.
Naming it `foldLength` is a sure way to discourage to use that function at all (as it's longer than e.g. `V.length`, noisy to read, and cumbersome to type). `size` or `count`, however, seem much more preferable alternatives. `size` has the benefit to match what `containers` and `unordered-containers` already use. The "length of a set" does sound weird after all. "size of a container" however makes much more sense to me. So my vote would be to rename `length` to `size` here. 
He [gave one at CUFP](https://www.youtube.com/watch?v=IOEGfnjh92o) last month as well.
What's wrong with itertree over filesystem monad after transformation lens?
I agree that we probably should have pushed back harder on the "generalize `null` and `length`" crowd at the time. However, that signal got lost in the noise of the "please do anything else but FTP" group and everything got lumped into one all-or-nothing vote. That said, going forward, it seems hard to find a plan that ungeneralizes them that complies with the other constraints on the process (3 release policy, sufficient notification of changes, etc.) that doesn't just leave things in a worse state and create precisely the kind of CPP-heavy maintenance headaches that just burned out Johan. So even if we decided we wanted to ungeneralize those combinators, it wouldn't have a concrete effect for at least a couple of years.
To be clear, I'm talking about the distinction between those whose interest in seeing this feature in Opaleye is practical and those whose interest is theoretical. The former would put the new feature into production in a matter of days or weeks and give me useful integration testing and bug reports which is why I'm interested in helping them. The latter may be correct about the utility of the feature in the abstract but if they're not going to use it themselves then it's not really worth me spending the time on it (yet). Regarding the specifics, I doubt parameters can help Opaleye avoid bugs since it already encourages users to lift all sorts of Haskell-side values into the query. Regarding performance optimizations, monitoring tools, etc, I'll take your word for it. However, I should reinforce that Opaleye *has* been production-ready for two years (as evidenced by the variety of commercial firms that are using it in production) and no one has yet (to memory) asked me to support parametric queries. If anyone can make the case for them (show me profiling logs, tools that don't work without parameters ...) and actually, demonstrably need them now then I'm happy to collaborate to work on them.
Good talk by /u/edwardkmett as to why it's good Haskell doesn't do implicit dicts: [Type Classes vs. the World](http://www.youtube.com/watch?v=hIZxTQP1ifo)
That is my personal opinion , but I find python's walk.tree just to imperative. For example it supports modifying dir that one gets trough list of arguments. from https://docs.python.org/2/library/os.html#os.walk &gt; When topdown is True, the caller can modify the dirnames list in-place (perhaps using del or slice assignment), and walk() will only recurse into the subdirectories whose names remain in dirnames; What would be cool to have in Haskell is something like getTree :: FilePath -&gt; IO (Tree FilePath) But lazy, so one can write. import Data.Tree ... main = do tree &lt;- getTree "/home/raluralu/" let tree2 = fmap (last.splitPath ) tree putStrLn $ unlines $ take 30 $ lines $ drawTree tree2 -- print only 30 lines of pretty tree and it traverses just few directories Using `unsafeInterleaveIO` can be used to implement ordinary and strict tree traversal into LazyIO for example getTree :: FilePath -&gt; IO (Tree FilePath) getTree fp = do isDir &lt;- doesDirectoryExist fp case isDir of False -&gt; do return $ Node fp [] True -&gt; do cont &lt;- unsafeInterleaveIO $ getDirectoryContents fp let contf = map (fp &lt;/&gt;) $ filter (`notElem` [".", ".."]) cont sub &lt;- unsafeInterleaveIO $ sequence $ map getTree contf return $ Node fp sub 
Made a pull request to make pathWalk accumulate a value by default. That way collecting files is easy: pathWalk "src" (pureForeverCallback (\_ _ files list -&gt; list ++ filter (isSuffixOf ".hs") files)) [] Added `pathWalk_` for callbacks that don't accumulate.
Lazy IO can lead to problems, but it can also be really handy. My personal rule is that it's fine for scripts (as opposed to dedicated programs). Since walking through a directory is something useful for one-off scripts, I think a Lazy IO version would be fine.
/u/jonsterling has something similar in [hs-abt](https://github.com/jonsterling/hs-abt).
I like your idea about specialization syntax. More generally, we could have an option to do it the way most other languages do, like: map{f=[]} , which would just be shorthand for the full type declaration, not a new language feature tied specifically to typeclasses. 
https://github.com/fpco/stackage/issues/918#issuecomment-149652658
I don't know about `conduit`, but I think that this library should be easy enough to use with `pipes` should anyone want this, through `pipes-concurrency`, and something like this: pathpipe :: FilePath -&gt; Producer (FilePath, [FilePath], [FilePath]) IO () pathpipe path = do (output, input) &lt;- liftIO . spawn $ bounded 1 liftIO . forkIO . pathwalk path $ \dir subdir files -&gt; atomically $ send output (dir, subdirs, files) fromInput input edit: there are `find`, `ls`, and `lstree` commands in [Turtle.Prelude](https://hackage.haskell.org/package/turtle-1.2.2/docs/Turtle-Prelude.html) that can be used for this when writing a script in Haskell, so that might not be necessary.
I disagree, as it happens, but _shrug_ (I am bitemyapp)
&gt; The ability to travel between versions in a single working tree seamlessly &gt; seamlessly ... &gt; git stash Yeah... Though darcs is even worse in this regard.
What should I use in a new product?
In the section that gets the directories and files the code is like this: names &lt;- getDirectoryContents root let properNames = filter (`notElem` [".", ".."]) names dirs &lt;- filterM (\n -&gt; doesDirectoryExist $ root &lt;/&gt; n) properNames files &lt;- filterM (\n -&gt; doesFileExist $ root &lt;/&gt; n) properNames It seems that this might be doing 3 times as many filesystem calls than necessary. It would be preferable to have something like: (files, dirs) &lt;- getFilesAndDirectories root But that would mean rolling your own function ...
I think the post is actually the blog version of that talk.
SHA-2 or SHA-3 https://konklone.com/post/why-google-is-hurrying-the-web-to-kill-sha-1 http://arstechnica.com/security/2012/10/sha1-crypto-algorithm-could-fall-by-2018/
We've been using it at Silk for a while now. No problems except when loading packages using different Preludes. That bug report doesn't seem like a bug to me. It needs NoImplicitPrelude.
Personally I just wish that the type class instances for `(,) a` would go away. They're sensible instances but using the Writer newtype is just so much more preferable for clarity.
The Chart-simple package is deprecated, and hasn't been part of a chart release for some time. I will remove the example that uses it from the wiki, and put up a corresponding example that plots directly to a window. 
If you're doing this for fun, I would consider there two data points: [point 1](http://stackoverflow.com/research/developer-survey-2015#techSuper-loved) and [point 2](http://stackoverflow.com/research/developer-survey-2015#techSuper-dreaded). If you're doing it for money, then they may not be that informative or helpful.
That's hilarious. Thank you for that. At this stage, it's not like a SalesForce job is being waved in front of my face, so I may as well take the plunge with http://haskellbook.com/ 
The directory-tree package provides something similar to that API (I believe anyway, at first glance). However, you're right that sometimes lazy IO is pretty convenient. To that end, I added a pathWalkLazy function in 0.3.0.0 https://www.reddit.com/r/haskell/comments/3pi3nw/announcing_pathwalk_an_implementation_of_pythons/cw723y6 
Sorry, worked piled up and this slipped through. I just created a quick pull request with what I would recommend. Not sure where else this would be useful, but as I go through the examples I will post any other changes that might help. Also, where is the best place for me to get help on these "simple" things? The Yesod IRC? The examples in the book tend to be single files while the default template gives you quite a bit more. Is there something that gives an overview of how the framework files are intended to be used?
Host here. Me too.
Nice! Any easy way to pull the dependencies out of the shebang line? Running `ghc` on it won't work, since it doesn't know how about the dependencies. *EDIT:* This works, but it sorta sucks: $ head -n2 build.hs #!/usr/bin/env stack -- stack --resolver lts-3.9 --install-ghc ghc --package ... $ cat script #!/usr/bin/env bash set -e if [ ! -e ./build ] || [ ./build.hs -nt ./build ] then ./build.hs fi ./build
&gt; GPUs are optimal for small computation on streaming data (they were conceived originally for processing mesh data); Small? have you looked at a GPU in the last ten years? I've written a niave NBody sim in Repa, it slows down around 700 bodies on my 6 core machine, The code I based it off [can do 16k bodies on a 2006 GPU](http://http.developer.nvidia.com/GPUGems3/gpugems3_ch31.html), GPUs don't do just do "mesh data" these days, the GCN designs from AMD is full featured OoO RISC 2000-4000 core processor. that LLVM has a [backend for](http://llvm.org/docs/AMDGPUUsage.html). [The list of applications even includes MPI](https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units#Applications). &gt; the OT was asking about Cloud Haskell Yes but he also suggested Ardiuno, a embedded processor with no support for Linux, or "out of the box" stuff that would make it anywhere useful for networky stuff, it seems OP just wanted us to do the work for him. It would have taken him all of 30s to figure out Arduino was not going to work with Cloud Haskell. So in the end I gave him an idea of what other tools might be better for the job, since he seemed mostly clueless what he wanted to do.
Not being familiar with the term "second order algebraic theory" I googled and found the following nice paper: http://arxiv.org/abs/1308.5409 It leaves me with more questions that before (not that I expect I'll necessarily get answers here, though one can hope :-P). In particular, the relationship of the definition there to the "traditional" account of substitution as a functor, if the sort of definition given there can be extended to systems with dependency (and the relationship to essentially algebraic theories in general). One thing that strikes me is that they have a category M which is initial among cartesian categories with an exponentiable object. So it seems to me that we can (possibly) view many other sorts of constructions such as categories with attributes as structures which functors from M somehow "factor through". I am also curious what relationship (if any) has been developed to the theory of nominal sets.
Also, parameterized queries are not always a performance win. parse time can be several times longer than execution time for short, frequently executed queries. OTOH, parameters hide the actual value which can be very useful to the optimizer when data is skewed. So, parameterization should be a choice if you do decide to implement it.
I meant more transparent dictionary passing, where you can override locally the dictionary (and thus typeclass instance being used). Haskell, due to having only one way to do a typeclass on a type (ignoring OverlappingInstances), has guarantees useful for reasoning. As for summaries about those guarantees, you'd have to ask /u/edwardkmett, since it's been a while since I've watched the talk and I'm bad at explanations. :)
Google does not, to the best of my knowledge (which isn't great - I don't work at Google), use Haskell. If that's changed, that is great news and you should let us know what you heard :) I think a few SREs have snuck in some utility'ish stuff here and there. But I don't think it's a generally sanctioned language for building out products or infrastructure, the odd open source project notwithstanding.
Simplest example: Consider the fact that Set and Map don't carry around the dictionary. This enables us to move them to insert :: Ord k =&gt; k -&gt; v -&gt; Map k v -&gt; Map k v lookup :: Ord k =&gt; k -&gt; Map k v -&gt; Maybe v and know that we don't have to risk somebody passing us a different dictionary each time and e.g. inserting with one order but looking up with a different one, or inserting with several different orders. Here we could keep it in the Map somehow, but if we stored it in the Map we'd have a different problem. When you `union` two maps, which `Ord` wins? You can try to insert the smaller into the larger (hedge union is out without the ability to compare dictionaries for equality which opens a can of worms all its own.), but then you have a problem the very ordering you get on the result map would depend on the relative sizes of the sets you merged. Alternately you can merge left into the right or vice versa consistently, now you get the wrong asymptotics. The video goes into further detail about what goes wrong in other situations. Basically, the status quo gives library authors a lot of flexibility in how code is organized. Refactorings are almost all universally sound. On the other hand, a world with explicit passing gives folks a lot of power to pass anything anywhere, and it means that libraries are able to assume a lot less about what can happen behind their backs, and at best you wind up in situations where you have to rely on convention rather than laws to reason about the state of the world.
There's not a ton there, but these guidelines are good. I might steal them for work :)
The ruby folks should have fun with this ;) https://twitter.com/rubyconf_au/status/656614693616951296
[**@rubyconf\_au**](https://twitter.com/rubyconf_au/) &gt; [2015-10-20 23:35 UTC](https://twitter.com/rubyconf_au/status/656614693616951296) &gt; We're excited to announce that Katie Miller will be speaking about Haxl at RubyConf 2016! http://www.rubyconf.org.au/2016 &gt;[[Attached pic]](http://pbs.twimg.com/media/CRzDlZ1UcAAInr1.jpg) [[Imgur rehost]](http://i.imgur.com/a5seOsY.jpg) ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
I used indent level of 2 for a long while, until I realized that it makes the nesting structure of the code just not stand out. The code kinda looks like unstructured soup. With indent level of 4 (and never aligning, always indenting!) the code structure becomes much clearer. I now strongly recommend avoiding indent level of 2.
&gt; and at best you wind up in situations where you have to rely on convention rather than laws. In Agda the most common method is that you could bake the instance selection in as a type parameter and reason about it with dependent types. The talk addresses to a greater or lesser extent why that doesn't work for all situations, e.g. when you have many classes to deal with, not all of which are known when you make up the data type.
They don't have such a guide but I [wrote one for my students](http://www.cse.unsw.edu.au/~cs3161/15s2/StyleGuide.html), that might be useful.
Oh, I understood this as the type system not being powerful enough to check the error. If the type system can statically enforce that the maps use the same `Ord` instance, then you're not relying on convention anymore.
Thanks for the tip, I'll give it a shot.
Looking at this: class Valid a where valid :: a -&gt; Bool valid a = (not . invalid) a invalid :: a -&gt; Bool invalid a = (not . valid) a Is there any situation where you would want `invalid` to do anything other than `not . valid`? If not, it may be worth moving one of the functions out of the type class declaration. Like this, for example: class Valid a where valid :: a -&gt; Bool invalid :: Valid a =&gt; a -&gt; Bool invalid = not . valid Now, you know that `invalid` and `valid` will always give the opposite answer for any `Valid` instance. Also, it may be worth considering whether you really need a type class here. See [this post](http://www.haskellforall.com/2012/05/scrap-your-type-classes.html), for example; while I wouldn't go as far as it does (and as it happens, the author has written that his opinion has mellowed as well), I do think it has a lot of important points. For these reasons, I am generally very hesitant to introduce new type classes in my own code. Normal functions go a long way!
I thought this was going to be a stab at Yesod's pronunciation.
Actually more than that. The difference between directory and file is already present in the structure that getDirectoryContents reads from. So when this implementation does 2n calls to stat, a smarter implementation will not do any call. Python solved this by with os.scandir. I was working on porting getDirectoryContents to a similar fashion, but my commits are blocked on my computer because of time and lazyness... (Mainly because the task of patching unix / win32 packages + directory + files + base is a bit too much.)
It would be nicer to just have: import Prelude.* trigger `NoImplicitPrelude`. A single import line per file is nice, explicit information for the reader. Making it self-contained, and not changing the semantics of files from outside those files. Basically same reasons that language pragmas are nicer in-file than as command-line options.
As a data point: [pandoc](https://github.com/jgm/pandoc/commit/82b3e0ab97a67188f0886dd6b758aa8d0ccd1064) uses the same trick. I don't know whether thay ran into the issue with ghci though.
Thank you for the advice. Indeed it's more clever this way. Regarding your last point, I guess I'm not experienced enough to get the whole picture of the typeclass issue but I think I see your point. Thank you hdgarrood !
The HTTP stuff is basically the most boring part anyway.
This is the walk call using the package transient. It has controllable multi-treading; It executes with as much threads as you like, so the number of files simultaneously processed can be fixed. Also is probably the most readable one, since has no callbacks/forks. It is also recursive (and it is composable): import Transient.Base import Transient.Indeterminism type File= String walk :: String -&gt; TransIO File walk dir = do fs' &lt;- liftIO $ getDirectoryContents dir let fs = sort $ filter (`notElem` [".",".."]) fs' file &lt;- choose fs -- multithreaded nondeterminism let dir' = dir &lt;/&gt; file isdir &lt;- liftIO $ doesDirectoryExist dir' if isdir then walk dir' else return dir' main= keep . threads 5 $ do file &lt;- walk "mydir" guard $ condition file -- guard can be used myProc file EDITED for more composability [how it works](https://www.fpcomplete.com/user/agocorona/beautiful-parallel-non-determinism-transient-effects-iii#using-the-parallel-non-determinist-effects-in-transient-to-perform-parallel-search) 
I don't think it's in widespread use there, but it's certainly used: http://k1024.org/~iustin/papers/icfp10-haskell-reagent.pdf
The problem is the bifunctor that you must asimptotically maintain withing O(n) limits. Only with an indexed multifunctor over the range of possible categories you can have a good getter and setter for your 2-tuple.
Once you develop a coordinate system a hex grid is just a 2-d array and the coordinates are just pairs of integers. I would probably just use a single Vector and write functions to convert between a hex coordinate (i,j) and an offset within the vector. Whatever you decide on you can always abstract away the implementation so you are always dealing with hex coordinates. You might look at the [__grid__](http://hackage.haskell.org/package/grid-7.8.4/docs/Math-Geometry-Grid.html) package for help dealing with hex coordinates. The docs [(link)](https://github.com/mhwombat/grid/wiki/Hexagonal-tiles) might also be helpful.
Concerning hex grids, I can't recommend [this website](http://www.redblobgames.com/grids/hexagons/) enough.
Unless it's a massive board, just use lists, once you run in to performance issues, then move on to the structure that suits your issues better, which you should understand better by then as well. A more advanced technique for handling this kind of "localised" (checking connections) access pattern is the comonad package. Though I haven't used it personally, it's often compared with Conway's Game of Life. A hex board is just a square structure, with each row pushed half a row sideways (either alternating, or repeating) Assuming upper right corner is 0,0 a tile at point (2, 2) would have neighbours of (1,1) (1,2) (2,1) (2, 3) (3,2) (3,3) in the repeating case.
A very nice resource!
Thanks for the pointer to comonads. Can't tell if it's useful though. List of lists seems inelegant. 
I like this idea, it should be interesting to try out on some projects. Can I suggest a README which explains the meaning of the output somewhat? The screenshot also seems newer or older than the README example as they have differing output (one has alphabetical ratings, seemingly). 
I see that it's based on HSE so it's purely syntactically defined complexity. It would also be fun to compare it to the results of looking at Core output. Or otherwise have some way to include precomputed complexities for referenced names. `map` is fairly straight forward, `foldr` is a bit more complex, `sort` is more, etc. Using `sort` twice in a function is probably likely to make that function more complex than using `map` twice, etc. It'd be neat to show a code golf one liner and this tool (or similar) to say "this is simply written but does a lot of complicated action underneath", i.e. superficial vs deep complexity.
Of course, I'll edit the README with an explanation. Basically every line represents a function binding (the first two numbers are line number and column number), along with its complexity. Normally, the output is colored and each function has a rank associated with it (A -&gt; complexity between 0 and 5, B -&gt; 6..10, C above 10). If one disables colors with the `--no-color` options then ranks are not present. This explains the difference between the screenshot and the example (without colors and ranks). Results are sorted indipendently for every file. Sorting is done with respect to (in this order): * complexity (descending) * line number (ascending) * alphabetically
Storing a hex-board is actually no different than storing a 2D array. You just have to tinker a bit with the indices. I'll just go out on a limb and assume that you want to uniquely identify each field with a pair of coordinates (x,y). With tessellated squares, this is easy; with hexagons, it is possible, but you have to accept that the x- and y-axed won't be orthogonal. See [this image](http://imgur.com/CZXJ16O). The x-axis is in green and goes diagonally upward. The y-axis is blue and goes vertically up. With this mapping in hand, you can use any 2D data structure you like. For instance, you can just use a regular `Array (Int,Int) SomeData`. You only have to remember during rendering the thing graphically that the "rows" actually go diagonally instead of horizontally.
I can vouch for the docs of grid too, having used the package in projects myself. They're first class!
At Soostone we do most of our development work in Haskell. Here is our [style guide](https://github.com/Soostone/style-guides/blob/master/haskell-style-guide.md).
I don't mean to diminish your effort, but I am never going to use any tool based on Haskell-src-exts. It's fundamentally the wrong idea to use a parser that is not the same as the one your compiler uses. 
Thanks for your feedback! I was under the impression that haskell-src-exts was the de facto standard library one would use in these cases. When I first set out to write the program I checked and Hlint uses it. Are there alternatives?
If you want to actually get a job working on massive enterprise OOP systems like SalesForce, then you should learn Java or C# because that's where the jobs are. If you want to build your own system or work for a smaller company doing something a little more cutting-edge, or work in financial tech, then Haskell is a fine choice.
You can reuse many algorithms (like for pathfinding) when you just use a graph. A hex field is a node, which is connected to the 6 neighbors. Very simple. 
Take a look: http://www.redblobgames.com/grids/hexagons/ It is a very comprehensive article about hex grids: storage, rotation, pathfinding etc.
So wait, you already know the questions you're being tested in? You should probably start by going to google.com, typing in each of those points and append/prepend "haskell", and you'd get a long way... Honestly, this seems quite suspiciously like homework, and the fact that it's for tomorrow even more so. Also, if your uni requires this off you, then you should probably have a serious talk with them.
These tasks are simple enough that you can do them after 1 week of learning haskell(probably not after 1 day though...). Also (hopefully) no one will write these for you (I definitely won't) but if you can get started you can ask questions about obstacles you run into at stackoverflow or /r/haskellquestions There are a lot of helpful people out there but you have to show that you put the effort into it.
How does the hash function that a VCS uses for commit identity relate to security?
Yeah i have in c++. Im looking through it as Im writing this comment.. I hope I can make it. Thank you..
No, I understand you clearly. And I wasnt offended at all. Thanks for your concern.. Im looking through LYAH right now I just hope I learn enough for tomorrow.
Also pinging /u/Tekmo to ask if you think Morte can be compiled to maintainable code like that? That would be a project I'd like to embrace if my total lack of understanding on dependent types wasn't a barrier.
I don't understand why https://github.com/ghcjs/ghcjs does not qualify. GHC itself also compiles to C AFAIK, though I don't know if it's readable.
rosetta code man...
Because 1. no iOS/Android. 2. a company specifically asking for maintainable JavaScript code is unlikely to accept the GHCJS blob since their JS devs wouldn't be able to maintain it. Just imagine you are working for a company that has no Haskell programmers (common situation), and you write your code in GHCJS. What happens if you leave? Your company will be forced to hire Haskell developers just to maintain with your code - whereas this approach would enable their existing JS devs to do it without issues. The point is that the core of functional programming is simple yet rich and informational enough that this kind of compilation-to-maintainable-code could be possible - at least so I think.
I already know Java / C#. It's totally true that it's where the jobs are. It just bores me. And similar to what I said before, there isn't really a dot net or java job being waved in my face. And I feel like most java/dot net jobs are hiring abroad anyway, right?
Specific advice?
Already mentioned previously. Does not answer the question.
Do you mean [this game](http://mathworld.wolfram.com/GameofHex.html)? There is another interesting representation strategy for boards that is useful for games that depend on symmetries of the board. You use tie-the-knot in two ways: for each location you create a circular list of the outgoing links, and you point each outgoing link at its peer in the adjoining location. You assign each location a fixed unique ID (usually an `Int`) and store state in an `IntMap`, or, if you must, a vector or array. This representation is independent of symmetries, so you can easily rotate and flip the board for zero cost. Local operations are also very fast due to the use of tie-the-knot - moving from a location to a neighbor is essentially just dereferencing a pointer. However, if the game is the one linked above, this representation may not be too helpful. It seems that the board valuation must be quite global with local patterns not playing much of a role.
It does have some security impact when you use signed commits since you only sign the commit object, not every object it points to (parent commits, trees, file blobs,...). With a hash collision it would be possible to switch out one of the files without invalidating the signature.
Yes, I mean the game that you linked to. I'll add this link to the question. [edit] I may have misunderstood your particular version of tying the knot. I'll read your post more closely.
You should use [this](https://hackage.haskell.org/package/grid/docs/Math-Geometry-Grid-Hexagonal.html#t:ParaHexGrid), from the vastly under-popular [grid](https://hackage.haskell.org/package/grid) package.
I'm not sure I understand your first paragraph. But about your point, I don't know. Such a tool would make infiltrating Haskell in existing environments much less drastic and the choice of using Haskell in production much less risky. Which would cause Haskell to be more used. Why wouldn't someone convinced Haskell is a better language want that? It is not admitting that other tools are better, it is just providing a proper bridge for the migration.
It seems like you could have to two hashing methods. The resulting pair of hashes would both point to the same content. So the hypothetical git that moved away from sha-1 would by default use some other hash but could still be accessible by sha-1 to interoperate with legacy systems.
The Rapsberri Pi 2 is the cheap part. The expensive part is paying labor to hook it into the rack and configuring it on the network and managing and paying for the 50GB of SSD-backed storage and paying for the 200 Mbit/s unmetered bandwidth. 3 Euro is currently about $4 US, so by my guess they probably need a three year contract to recoup their initial investment - and at that point some of their profits are going to be eaten by replacing failed switches, firewalls, SSDs, and Raspberri Pi 2s. I love the pricing, but don't understand the business model.
i like chris done's https://github.com/chrisdone/haskell-style-guide also there are some interesting tidbits here that are unique http://www.cse.unsw.edu.au/~cs3161/15s2/StyleGuide.html "Functions should in general be named based on what they return rather than what computation they do." "The reason for short local variable names is to make them easily distinguishable from top-level function definitions."
Right now the type system is strong enough to ensure that you always get the same `Ord` instance. What we have is a sufficient but not necessary approach. Uniqueness of instances is sufficient to provide that guarantee. On the other hand, i've yet to see another system that can actually provide that guarantee in the presence of the same instance being constructed in multiple situations, possibly coinductively. Value equality of instances isn't good enough because we synthesize them out of parts and deal with an open set of them in the presence of polymorphic recursion. data Jet f a = a :- Jet f (f a) deriving Ord
&gt; write functions to convert between a hex coordinate (i,j) and an offset within the vector It is also very easy to write a lens for this, and it is incredibly convenient.
The best you can hope for is code that can use (and can be used from) other code of the target language. Haskell is particularly complicated, because of laziness. This alone makes the target code most likely intractable for humans. Apart from that, it is always a bad idea to "maintain" generated code. Even readable one. Because you used the tool that generated it in the first place for a reason. You used yacc because it is a DSL for writing parsers, you used UML because drawing boxes is supposedly easier than to code, and you use Haskell because it has sum types, higher order functions, towers of abstractions and, last but not least because the type system gives you some strong guarantees concerning the generated code. Do I need to pint out that those guaranees are void for maintained target code?
yeah, I do prefer writing language pragmas over and over again for each file, rather than once for all. but the point of the prelude is that it's implicit. like Haskell2010 is different from Haskell98, I'd be okay with a consistent company wide (or even person-wide) prelude.
The tricky bit would be the readability since the only way to achieve that would be to track naming of variables,... through the transformation process. You would not be able to have any significant optimizers or other code transformations because of that, you would not be able to generate a significant amount of new variable names in the output (except those derived from Haskell names in the input),...
Yes! Every time you think isomorphism (or bijection), think lens!
why the downvotes? hse is fragile. I like to use lots of language extensions and hse-based tools always fail on my code. for the author of the project, I'd recommend they try to traverse the output of parseModule and/or typecheckModule, in the GHC API. it's a huge pain, as there are lots of flags you have to set. but if cabal build works than those will "just work" for the user, given the right flags. since cabal build ends up calling the ghc executable which itself calls parseModule/typecheckModule. what we really need is function like getFlagsAndTargetsFromCabal :: Ghc DynFlags (I thought I saw a package that did this). and some higher-level api (like lenses) and wrappers with no implicit dependencies (like "this field is undefined until stage", I thought I saw stuff like that) for the types returned by parseModule/typecheckModule. edit: having said that, I like this project a lot. haskell is perhaps the mainstream language most amenable to static analysis (given its rich types like NonEmpty lists), yet has the worst tooling. 
You do not understand, that is exactly the point. It wound't do any kind of transformation. It would merely be a syntactical, 1-to-1 compilation. It would delegate optimizations to the target language. 
But once it *can* be inconsistent, it is an extra thing to worry about and keep in mind all the time. Where does the `min` function come from? Now you can at least consult the imports to know. With command-line options affecting that -- you depend on external configuration. I think it would be nice if each file also had a small header saying it was `Haskell2010` (which would imply `Prelude` too).
Aren't scott encoded datatypes uniquely identified by their types? Sorry if this makes no sense, but I guess you're right.
That is astonishing. If just Haskell was taught like that.
Right, but wouldn't it be nicer if the compiler enforces the requirements? That's why I like the approach that I mentioned in my update better.
In what way would that then be Haskell? It wouldn't be lazy, it would not have sum types (since most target languages don't), it would not have type classes, there would be no pattern matching. It would be a syntax for another language that looks a little bit like Haskell. That is certainly much simpler to implement. I don't see how it would help you much compared to just programming in the regular version of the target language.
**Alice:** Hey Bob, I wouldn't normally say this, but I've been at this company for a month and our code is kind of shit. **Bob:** ...I know. The first version was written in Haskell by a guy named Clarence five years ago and auto-converted to Java. He's since left the company. We've been adding new features in Java ever since, the system is much bigger now but we're still stuck with a mix of new and old styles. **Alice:** Holy crap, that explains why it looks so weird. But why did Clarence use that approach? How did he justify it? **Bob:** He wanted to "get his foot in the door".
&gt; This doesn't require maintainable target code, and is already in progress with some (limited) success. By limited you mean no success at all, or something I've not aware? I've asked not long ago how to write even simple graphical applications such as Gloss animations for iOS/Android and the answer was "you can't yet". &gt; In fact, I think this requirement is non-existent in the real world. We might be living in different worlds because that's exactly the concern several different contractors raised when I asked to use Haskell - "how I will maintain the code with existing programmers if you leave". Have you never heard that phrase? &gt; Because it's incredibly difficult and provides very little value. You could say it provides very little value to you.
Your language semantics will radically differ between a language with and without laziness even with the exact same syntax. I am not sure which example you mean. I didn't say that they are impossible to represent in a target language but they are impossible to compile to a target language with a mere syntactical transformation.
&gt; By limited you mean no success at all, or something I've not aware? I've asked not long ago how to write even simple graphical applications such as Gloss animations for iOS/Android and the answer was "you can't yet". No, by limited I mean limited. If it can do some things but not other things, that's "limited". &gt; We might be living in different worlds because that's exactly the concern several different contractors raised when I asked to use Haskell - "how I will maintain the code with existing programmers if you leave". Have you never heard that phrase? That doesn't imply that they want you to use a Haskell transpiler. It just means that they don't want you to write Haskell. It's ridiculous to claim that they are asking you to build or use a Haskell transpiler. &gt; You could say it provides very little value to you. I have evidence for my claim, which is the complete lack of existing solutions or progress towards creating them in Haskell or any other language.
make it recognize .gitignore
I'm also not sure about heroku getting a three. Build times causing time outs have proven problematic for a lot of people.
Maybe it'd be nice to have a generics instance to provide something like data KeySet = KeySet { key1 :: Key Int , key2 :: Key String , ... } deriving (Generic) instance Keyed KeySet class Keyed a where instantiateKeyed :: IO a default instantiateKeyed :: Generic a =&gt; IO a instantiateKeyed = ... instance Keyed (V.Key a) where instantiateKeyed = V.newKey Then you slide your `KeySet` into your `Reader Config` layer in a stack.
Thank you so much for making these, they're a real treat :)
The content addressable storage would save the same blob in two namespaces to stay compatible. Not such a huge deal. At least not if it could be combined with a storage layer that would actually fix the scalability issues.
What about the coziness of Github? ;)
Saving every object twice is not a huge deal? You could get rid of that by using an index from secondary to primary hash of course. The bigger problem would be that there is no way to convert a repository with one hash to one using both without changing all the hashes in the original hash algorithm used due to the new data in the commit and tree objects themselves.
I was there for an interview last week and asked. It's not one of the sanctioned languages and they're working to use even less of it than they do now.
Of course one wouldn't store every object twice. Also of course one couldn't change an existing repo, similarly to how it is impossible to retrofit signed commits. Signed commits and non-signed commits can interoperate just fine. There is no conflict here.
hooray, the shadow banned passwordissame must be back!
I'm not sure what difficulty level do you have in mind, but Bartosz Milewski wrote / is writing a series of blog posts about category theory: http://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/
`product-profunctors` and `Default` instance will give you this :)
Thank you, that looks very interesting. Maybe let's disregard the difficulty, I can always come back to the more difficult ones later ;). If only it existed in nice pdf :)
Hey, I've been working on this for the past few days. The library is very minimal so I've made sure to document everything in the API. There's also example usage in the documentation of the [Slides.Presentation](https://hackage.haskell.org/package/Slides-0.1.0.5/docs/Slides-Presentation.html) module.
Well yes, but the OP is also talking about compiling a *subset* of Haskell. So we only need to get rid of many, not all.
I really don't agree with this. The stateT exposes an eDSL if you will and allows you to create and compose programs with it. This vanilla function lacks those capabilities.
That was my thought process too. My lecturer has given us this exercise: Ex. 24 1. The definitions of both map and filter can be improved by using “don’t care” matching. Make this change. (You will need to give the functions new names.) 2. Any even better solution is to use a where clause to introduce an auxiliary function. Do so. I just don't see how these are better.
The only difference I can see is that in the ' versions `f` is passed into the recursion while in the '' versions, `f` is passed from the created closure, possibly (?) having less parameters to pass. Someone more knowledgeable than me would likely show that they are both optimized to the same most efficient code which sidesteps this difference completely.
If whole-program compilation is available, you can use lambda-lift and defunctionalization to derive a program that only uses first-order functions.
That's a matter of style then. They have no performance impacts here. Also your professor doesn't seem to be aware that the map' is how the Prelude map is actually defined.
OP said the subset of data types and terminating functions. 
I think this is a silly assignment.
The way you turn the first two into the second two is by applying something called the 'static argument transformation' (go Google it).
Vault is a lovely library.
I'm going to bikeshed a bit. The link in the OP says: -- better f $ g $ h x -- best f . g . h $ x But I prefer the all `$` option for these reasons: 1. It's one less character. 2x `$` versus 2x `.`. and 1x `$` 1. If I remove or add a function on the right end, I don't have to change a `.` to a `$` or visa versa. 1. Uniformity. Just sprinkle `$` throughout. I don't need to think: "sprinkle some `.` and then put a `$` at the end". It's minor, but one less trivial detail to think about means space for one more nontrivial detail in my head. What are your thoughts?
cool! does it then parametrize the data types of different stages with different records? or did those fields become Maybe's where Nothing replaced undefined, which is better but not ideal. 
Screenshots would be great. You can even include images in Haddock documentation, but I'm not entirely sure how off-hand.
Next time your professor uses words like "better" or "improved", ask for specifics. How is it better? In what way is it improved? This is sloppy thinking and sloppy teaching.
Wow, surprised at all the downvotes. I wasn't being facetious at all (honestly not sure whether that's how it came across) and agree with the spirit of the OP. Let me be more detailed. - "Mappable" is not in any way anti-mathematical. The best names aren't enterprise-y or mathematical, but concrete (and specific). - If a typeclass requires only one function to be implemented, it makes sense to either name the typeclass after the function or to name the function after the typeclass, e.g. `Foldable`. - If there's an easy, concrete metaphor or image that captures the essence of the typeclass -- again, see `Foldable` and `Traversable`; also e.g. `Ord` -- it makes sense to use that to name the typeclass. Easy check of this: virtually every tutorial will say "Functors are things that can be mapped over". As far as I can tell, the main arguments against this (in Edward's talk) is that "[Functor] gives me access to 70 years worth of documentation". Access to 70 years of mathematical literature is not what your typical practical programmer needs, cf. a PL academic. E.g. in practical programming, "anonymous function" is a better _name_ than "lambda", which apart from its roots is just a notational convention.
Is `Foldable` "enterprisey or anti-mathematical"? I think it's a great name.
Total Haskell newbie here, but I think the key word you're overlooking in the question is **"definitions"**, i.e. how can you improve the **readability of the definitions** by using matching and where clauses. The question actually doesn't ask how you can improve the performance of the functions.
I've seen a talk on ghcjs which had interactive slides running in the browser, compiled using ghcjs. It used diagrams and a FRP library. Wish I knew where the source to that is..
Default cabal settings which should be -O1. -O0: stack overflow, -O2: no difference cabal configure -ON; touch Main.hs; cabal build; cabal run -- --output tN.html where N is optimization level [0..2]
The second version have used the [worker-wrapper](https://wiki.haskell.org/Worker_wrapper) transformation.
foldable's great, as is fmap.
Perhaps you're thinking about the [Reflex talk](https://www.youtube.com/watch?v=dOy7zIk3IUI)? It has interactive slides running in the browser, compiled using ghcjs, and Reflex is of course an FRP library. I don't remember any diagrams though.
Thanks! Seems it is available on his [github page](https://github.com/tibbe/haskell-style-guide).
At my university, asking people for answers to a test (aka, cheating) is a serious violation of the academic integrity policy. The punishment ranges from failing the test to expulsion.
Any name I give you is going to carry some baggage. If instead of "Monoid" I start calling things "Appendable" now you get some baggage with that assumption. If you _knew_ what a monoid was now you have to keep track of the extra alias for an existing concept. If you didn't now you think it is about appending, so Endo doesn't make sense, Dual doesn't fit the intuition, why is Any and All in there? etc. you focus in on one part of the whole. On the other hand learning about functors opens a door to a whole lot of things that you don't have to make up and name yourself. If you make up a name then use it then people can only learn about it what you tell them, or what they can map in from their own understanding. If you give something an accurate name with a history behind it, people can tell you things about it you didn't already know. They can do this even if you call it a WarmFuzzyThing, but now you are relying on them figuring out a WarmFuzzyThing is actually some other concept with deep roots on their own. Their efforts to find out about a WarmFuzzyThing will be hampered by the fact that the only things they'll find on google are your own references. I found a connection to something called Codensity about 7 years ago a couple of years after I found Haskell and started blogging. I started using the "right name" for talking about it. This found ways to improve the asymptotic performance of free monads. At the same time I was realizing the connection and how it right associated (&gt;&gt;=)'s, I found that Janis Voigtländer [wrote a paper](http://www.janis-voigtlaender.eu/papers/AsymptoticImprovementOfComputationsOverFreeMonads.pdf) on how this was useful for building up free monads. Using that I started teaching people how to use this to write efficient EDSLs. Along the way someone spotted a connection to a CPS'd state monad, and I wound up showing all monad transformers can be expressed this way. This also showed me that for a monad `m`, that Codensity `m` is "bigger" than `m`. Then other folks showed me a bunch of topology connections, whence the term "density" actually arose. Then other folks showed me how this relates to Kan extensions in more detail. I found a way to rephrase that to find a way to transform any comonad into a monad transformer. Some of those approaches led to a number of the more complicated combinators that we have in `lens` that "just work" in all sensible situations. Then other folks showed me how this relates to "monads are monoids in the category of endofunctors" and how we can view it as a 'curried monad'. Then other folks showed me how you can build efficient effect systems with it. Other folks realized that if they reified the 'deque' of computations it represents explicitly they could get structures that permitted efficient binds and compositions. This means that another library I had written for working with streaming computations could be made more efficient. I'm still exploring knock-on consequences of this years later. Along the way I've learned a lot! That entire chain of reasoning started with "using the right name" and accepting that the idea was far more general than my limited initial understanding of it. Names have power. A name you make up only has the power of the imagination you bring with you.
`Functor` and `Monad` are well-known in programming language theory and in many parts of pure mathematics. I wouldn't say they're well-known in mathematics generally.
There are SYB instances for the GHC AST I think, that works similarly to uniplate. 
I would also recommend just watching Bob Harper's OPLSS lectures.
I think traditional FRP is nice for modelling "combinational" programs, where the output depends on the input but not on the previous state of the program. For writing "sequential" programs, I'd suggest [transient](https://hackage.haskell.org/package/transient).
The potential benefit to pulling `f` out into the environment rather than passing it repeatedly and recursing without it is that strictness analysis can then use `f` as a fixed thing. This is needed for things like foldl (+) to have a chance of doing the right thing in concrete cases. The potential cost to pulling `f` out, however, is now that we have an environment to allocate on the heap. This means you'll likely generate more garbage in terms of profiling. Recursing with the same argument on the other hand is going to burn through more stack, but the stack is more likely in cache.
I did that here: https://github.com/boothead/ohm-talk I went a bit crazy: Used Xmonad for layout, reveal.js for presentation (trying to overlay a nice functional library over reveal's javascript was a real pain). I also used oHm for interaction, including a second app that lets you control the presentation slides from another device over websockets. I spent so long writing the slides that I didn't leave myself enough time to write the slides :-) *edit* This code is a mess!
You can simplify your foldMap's a fair bit by using nested foldMap calls. Alternately, you can make a bit more use of the `bifunctors` package to add `Bifoldable` and `Bitraversable` instances. These make it easier to pingpong back and forth by just swapping function arguments: import Control.Comonad import Data.Bifunctor import Data.Bifoldable import Data.Bitraversable data Node b a = Node { me :: a, kids :: [Node a b] } deriving Show instance Bifunctor Node where bimap f g (Node a bs) = Node (g a) (bimap g f &lt;$&gt; bs) instance Bifoldable Node where bifoldMap f g (Node a bs) = g a `mappend` foldMap (bifoldMap g f) bs instance Bitraversable Node where bitraverse f g (Node a bs) = Node &lt;$&gt; g a &lt;*&gt; traverse (bitraverse g f) bs instance Functor (Node b) where fmap = second instance Foldable (Node b) where foldMap = bifoldMap (const mempty) instance Traversable (Node b) where traverse = bitraverse pure instance Comonad (Node b) where extract (Node a _) = a duplicate t@(Node _ bs) = Node t [Node b (duplicate &lt;$&gt; as) | Node b as &lt;- bs] ana :: (Show b , Show a) =&gt; (b -&gt; [a]) -&gt; (a -&gt; [b]) -&gt; b -&gt; Node a b ana vs ks k = Node k [Node v $ ana vs ks &lt;$&gt; ks v | v &lt;- vs k] Personally I'd probably still implement a lot of this stuff directly rather than use the `second`, `bitraverse pure`, etc. definitions, just to avoid accreting unnecessary `pure` computations in some unknown Applicative and the like when invoked parametrically, but YMMV. All of this code then works with only minor modifications in case you decide to make this a form of alternating cofree comonad: data Node f b a = Node { me :: a, kids :: f (Node f a b) } deriving Show
That is true, but let me say you something: I forgot to insert two or three "covariant" words in my response. if I would have done it, I would have won the argument. When I say "covariant" my beard grows and a ton of global warming gases dissapear from the atmosphere of the planet. 
In the sense that your computer has some fixed ports which have inputs flowing through them and a screen which has pixels, yes, FRP can cleanly model those semantics. But that's not what anybody means when they're talking about GUI apps. In the GUI world, we talk about things like buttons and text boxes, and it makes no sense to have a text box which "produces" a `Signal Text` which somehow magically stops existing when it's not on the screen. FRP (where Signal T is defined as Time -&gt; T) does not model those semantics at all. When you add bind, either you have to handle cases which you know are ridiculous ("What happens when they type in the box when the box... isn't even on the screen?") or you have to break referential transparency. And yes, you can hack stuff together in Elm by maybe having some global `buttonCode : Signal Int` and then map everything through there, but that is *not modelling the semantics of your program*. It's just... hacking. You have no type guarantees whatsoever.
It unrolls the construction until it doesn't have to alternate. Fix (G a b) = (a, [(b, [(a, [(b, ... 
Interactive presentations are cool. I've seen a couple of talks that had something like that. This project was born out of "need" since I'll be using it to make presentations for my classes. I don't have the advantage of running them on my own machine so a PDF is as close to reliable as you can get.
Ah of course! Thanks for that explanation!
My main focus when writing the reactive-banana library are GUIs. In fact, all the [examples][1] are GUI examples. [1]: https://wiki.haskell.org/Reactive-banana/Examples
I think I see what you mean. Monadic signals are just unnecessary. Its really just complicating matters that need not be complicated as evidenced by the Elm Architecture. The model of the semantics of the program should explicitly rely on the history when it needs it, rather than having the framework have to implicitly decide when history is important.
I'm really not sure about a lot of this :) - I don't think `coordinates :: ![!Coordinate]` is doing what you think it does - I think you might want to use `UNPACK` inside Coordinate - I think your foldl' might not be as strict as you would like, because I think you're building up thunks in your tuples - one of the various libraries specializing in folds might help here Edit: nevermind the UNPACK, just spotted -funbox-strict-fields in your .cabal files If I get a change I'll play with this later on and see what happens.
I started using reactive-banana for my latest project, and while i like frp so far, this question is still open to me as well. Does it scale? (my `networkDescription` currently is 300 lines, with ~30 events. In a single large chunk.) More concrete questions: 1) How much overhead will it create if i split up the network description monad function (of type `Moment t ()`)? I will only be able to use Events/Behaviours that are either defined locally or that are passed around. I could of course define all Events/Behaviours in one place and place their logic in separate functions. How to avoid overhead? 2) But is there a design that is not centralized? 3) Is it even a good idea to not have one big network function? To have network logic and pure functions for one part of the program in the same module? Or should i have multiple MyProject.Network.* modules if my network grows too big? 4) This feels similar to the IO/pure code split up, where i already have some intuition of how to handle things. How different is Moment/pure? (hm you basically have all three: IO/Moment/pure. There are interactions between all of them i guess..) [edit: i need a preview-button to see the formatting.]
Well, that's not necessarily *better*, but it's certainly easier ;). If you're curious, you can take a look at how [lens] does it with their enterprisey UML diagram. A screenshot inline would be the easiest way to show people who stumble upon the package exactly what it does and how a presentation looks, which is exactly what they'd care about. A link is great, but I suspect a fair number of people just won't follow it. [lens]: https://hackage.haskell.org/package/lens
Well, here's the more knowledgeable person! I think it might also depend on context, as the function might be inlined and allow the call to stream, removing the whole need for a deep stack. I have a feeling these questions should not even matter in our time and age, given amazing optimizers. In general I believe that code should be written beautifully and succinctly without having to even care about these internals most of the time.
Why would you split your code on the level of `Moment`? You can easily write functions of types like `Behavior t a -&gt; Behavior t b -&gt; Event t c -&gt; (Event t d, Behavior t e, Behavior t f)` to make your code more modular. No need for monadic operations.
I had a build failure why trying to install this: stack install argon Run from outside a project, using implicit global config Using resolver: lts-3.10 from global config file: /home/gareth2/.stack/global/stack.yaml While constructing the BuildPlan the following exceptions were encountered: -- Failure when adding dependencies: docopt: needed (==0.7.*), not present in build plan (latest is 0.7.0.4) needed for package: argon-0.2.0.0 -- While attempting to add dependency, Could not find package docopt in known packages Recommended action: try adding the following to your extra-deps in /home/gareth2/.stack/global/stack.yaml - docopt-0.7.0.4 You may also want to try the 'stack solver' command Interestingly I see the missing dependencies in the `stack.yaml` file and it builds fine if I clone the source. Is this a bad upload to hackage or a problem with stack? Stack --version is `Version 0.1.4.1, Git revision 5f3ffe5ea8b4d8d1f4d1e4d15bee8b481ec6a8d4 (1752 commits) X86_64`
Interesting read, from someone (read: me) who completely missed the FTP debacle. I think they have definitely done this the right way. IMHO, he is right that the suggestion of having the Haskell Prime Committee decide on this is just in the hopes that it would get rejected, and would not have been a complaint otherwise (except maybe from the opposing side). I'm glad to see that Haskell/GHC is not afraid of making some breaking (although very mild) changes in order to further the language. Stagnation helps no one.
what would you consider to be a "right" approach to GUI programming in functional languages?
This looks nice! Too bad that there is no working version of hplayground for ghcjs.
&gt; various libraries specializing in folds Could you point me to some of them please?
&gt; FRP FTP
Also consider an operator such as: -- execute an action asynchronously whenever an event is fired. Trigger the -- result event after each finished computation. executeAsync :: Frameworks t =&gt; Event t (IO a) -&gt; Moment t (Event t a) executeAsync e = do (addHandler, handler) &lt;- liftIO $ newAddHandler reactimate $ e &lt;&amp;&gt; \x -&gt; void $ forkIO $ x &gt;&gt;= handler fromAddHandler addHandler It requires Moment as well, yet i would want to use it everywhere. (that operator is my own invention - perhaps there is a different way to implement it better (?))
Thanks for trying it! That is actually a feature of Stack :/ To prevent bad things happening behind the scenes, Stack finds packages through its *resolver* (in this case lts-3.10), which contains all Argon's dependencies except for docopt. So one has to manually specify s/he wants something which is not in the resolver. As /u/alt_account10 suggested, I'll have to find a way to have docopt included in Stackage. It's weird because stack.yaml is included in the tarball, so Stack should read that and figure everything on its own. I don't know if in this sense it could be considered a bug.
&gt; Just so you know I do not care for this module at all.. They forced me to take it to be able to graduate Everyone has to take classes that they don't like or want to take. That doesn't make cheating OK. &gt; The lecturer took a risk helping me so you better respect his decision to help me out. I think it is you who should respect your lecturer by *doing the work yourself*. I seriously doubt your lecturer gave you the questions with the expectation that you would just have people on the internet give you the answers. However, if that is the case, then I absolutely do not respect that decision.
Hahh, was also reading an article on FRP, must have been on my mind :) Thanks, fixed!
In response to your edit, I'm glad to hear that the test went well.
This website has some good answers: http://purelytheoretical.com/sywtltt.html What I personally ended up doing is watching the first lecture series that the link I mentioned gives you, and then I started learning a little bit of agda. The difficulty I had with type theory is that I realized that I had little motivation because I couldn't see where I was going to do anything with it. So, if you hit a similar roadblock, definitely consider looking at agda because there are a lot of good tutorials. I was not able to understand the idea of using GADTs as proofs until going through some agda tutorials (this might just be because people into agda are way more interested in doing that, but it's a useful skill that translates back into haskell).
Oh, I forgot to go back to the ruby generated file ... man that ruby is slow ... but here are the results $ time ./json1 -- original 0.5003196200378981 0.49983027578216976 0.499740922863519 real 0m34.750s user 0m25.175s sys 0m7.324s $ time ./json2 -- json-stream + streaming-bytestring 0.5003196200378981 0.49983027578216976 0.499740922863519 1000000.0 real 0m12.059s user 0m11.666s sys 0m0.281s $ time ./json3 -- json-stream + lazy-bytestring 0.5003196200378981 0.49983027578216976 0.499740922863519 1000000.0 real 0m11.563s user 0m11.251s sys 0m0.243s So that would seem to beat pypy. It's clear the file is too big for the ultra-correct aeson: it ends up with too much in memory, because (I think) it validating the top level json, not just streaming results as long as things look good. That would explain the results above. For further comparisons one should also look to see if the other programs are doing legitimate arithmetic as augustss points out. 
I think the problem is in decoding, before using your types at all. I also tried Vector, also tried structure-less code (just match J.Value/J.Array etc.) – didn't help.
I remember in one of Ryan Trinkle's talks (reflex), he mentioned some sizes of production apps, hundreds of thousands of events, etc. I wish there was a blog post or something giving these kinds of data. Afaik, he put a lot of effort into avoiding linear cost for event processing (with respect to # of events), and added cashing so that you sample only once but can use the result many times. He explains these design choices in reflex talks.
How did you manage to build this? `fold_` seems to be since version `0.1.2.0`, while `streaming-utils` don't allow that one.
I have been working on a reflex application of significant size for the better part of this year. The code is proprietary, so if you're looking for actual code examples this won't help you. But I can tell you that building the front end compiles 70+ modules and well over 10k lines of code. So this should provide at least a little evidence that one can indeed build large applications using FRP. Some of the pieces we've built along the way are public, however. You can see that code in the [reflex-dom-contrib library](https://github.com/reflex-frp/reflex-dom-contrib). As far as organization goes, with reflex the idea is that fully self-contained widgets are just pure functions of inputs and outputs. For instance, here is a simple [edit-in-place widget](https://github.com/reflex-frp/reflex-dom-contrib/blob/master/src/Reflex/Dom/Contrib/Widgets/EditInPlace.hs) that I think is a nice small self-contained example that is also very realistic and useful in the real world. Here's the type signature: editInPlace :: MonadWidget t m =&gt; Behavior t Bool -- ^ Whether or not click-to-edit is enabled -&gt; Dynamic t String -- ^ The definitive value of the thing being edited -&gt; m (Event t String) -- ^ Event that fires when the text is edited This defines the entire interface to this widget. What makes this example particularly interesting is that the widget has to maintain some internal state in order to implement its functionality. Namely, it has to keep track of the Viewing/Editing state. Reflex allows widgets to handle this kind of state internally without needing to add it to some top-level application-wide state object. This hugely improves composability and ultimately allows you to build GUI apps just like you would any other Haskell app--main is your overarching top-level function and then you split out whatever widgets it makes sense to split out. Your guide for splitting things will probably be that you want to find pieces that are loosely connected to everything else in terms of inputs and ouputs and make them their own function.
Damn, sorry about that. To try it you can just inline [this function](https://github.com/michaelt/streaming-utils/blob/master/Data/ByteString/Streaming/Aeson.hs#L132) with the imports at the top. It's an experimental library so the the lazy bytestring version http://lpaste.net/143611 is more to the point anyway and just needs json-stream There are defects in my last remarks by the way. I will look into it again later, but I have to run. The python does amass the whole parsed json before acting further, as aeson does, so there is some more interesting question about aeson and very large jsons. Also it was wrong to speak of validation as the main point. The strict accumulating fold will of course fail with the json-stream library too, though one can also stream intermediate results.
Not all FRP libraries use a continuous time semantics and perhaps should not be branded as FRP libraries because of that. For example, Elm uses purely event-based semantics and it works just fine. In general, I feel that event-based reactive programming is a more appropriate fit for GUI programming.
Ah, thank you! I tried to inline `fold_` previously but it depends on some internals. By the way, these streaming libraries do look interesting! And last point, just in case you've missed it, here's the discussion and results for other programming languages to compare https://www.reddit.com/r/programming/comments/3pojrz/the_fastest_json_parser_in_the_world/
Ok, I confirm on my machine, json-stream one is in-line with PyPy. Still would be nice to be in line with Rust/C++/D :)
[ghc-core](http://pastebin.com/kacu4BUa) output of ./.cabal-sandbox/bin/ghc-core --no-syntax -- --make Main.hs -O2
I saw that talk too, and I believe him when he talks about efficiency. From his larger examples, though, everything is tied into one monad. Namely, the `MonadWidget t m` class. In all of the examples I have seen, people freely mix UI creation and UI business logic into one large function. Yeah, it looks cool for small examples, but I can't see a clean way to scale to large examples. I'm sure there is a way, but I can't get around forcing everything to be in the same FRP monad.
I use Boehm Berarducci encoding and it's not clear to me if you can reverse the encoding when you start adding higher-kinded type constructors.
I think that in Elm the monad instance is hidden because it is actually *everywhere*. That's cool if you've committed to Elm, but in Haskell I would love to separate the logic of my application and the models from the FRP monad instance. It would be awesome to be able to have (in reactive-banana terminology) multiple EventNetworks that can be combined, or at least allow the sharing of Behaviors and Events between networks.
No, but perhaps `appEvents : Signal AppEvent` might be? Then you get to pick which events get injected based on the app state. 
A presentation is literally what this package does. Why wouldn't they follow a link to see a sample? I mean, don't get me wrong. It's not hard to make a screenshot, but I feel like that really doesn't capture the result. I've spent some time on the sequencing which you can't see in a picture. Everything is vector graphics which is again lost in a picture. Basically, the only thing you can see is my amateur CSS work.
FRP makes sense to me, especially if you abandon thinking in "widgets", which are really visual expressions of object-oriented programming. Instead, think of the events your domain has, and then how you will react to those events, and how those events can mutate state (if at all). This works better than widgets because usually buttons and labels do not act as little islands of functionality. Instead, when some part of the application state mutates, many things happen. Maybe a button goes to disabled state, a counter of active items at the top left goes to 2, and a new row is added. State is a function of time, and ui state is a function of app state. This makes more sense to me than a bunch of island widgets strung together with callbacks, global messages, and lifetimes. 
&gt; I'm not sure precisely what you mean by this, but I don't think you have to. I meant you should be able to create a widget in one spot, and then hook it up to a model later on. That's a good point about main. I agree that pulling out pure parts can be done (and my statement was imprecise and hyperbolic). I am just worried that as the FRP parts of your application grow, they become necessarily intertwined because of the monad. For example, imagine you have two windows that communicate only through one behavior. This could be a color picker, and the behavior could be the string representing the color. I thought you would be able to construct a color picker independent of any other windows, including the Behavior representing the color, and an Event saying the user has picked a color. I feel like attaching the color picker Behavior/Event to the main window logic should be a single operation in a small function. It seems that with the monadic approach, you must intertwine this color picker Behavior/Event logic with everything else that happens in the window's event network at once. In fact, that window's event network may be connected to other event networks (say, the whole application), which means you eventually have to thread this Behavior/Event all the way to some monolithic monadic function that ties everything together. I do think there is a solution, and I agree with your point about `main` and the IO monad (we can deal with that nicely, so this shouldn't be much different). I created this post to explore how everyone else does it. I have very little FRP experience and I thought there would be some design patterns I could learn. Thanks for your thoughts, and thanks for that link to Ryan's presentation! I'll give it a look right now.
&gt; You have to handle every mailbox, all the time, and that's semantically wrong. Do you really? (I don't know Elm.) If so, there's nothing intrinsically FRP about that behavior. I'm not arguing that FRP is a good fit for GUIs, but that point seems odd.
This game is very creative and imaginitive, as is another game from /u/gelisam, [Push and Fork](http://gelisam.com/octocarina/). I'd recommend anyone to try them out! The former is particularly quick to complete.
I agree, and what's worse, there isn't even a *theoretical* semantics for these sorts of things let alone a practical one (as far as I am aware).
I really like how Alberto is marching to the beat of his own drum while working through these things. What I most want to see, though, is for someone else to pick up what he's done and try to build something with it. I think everything I've read about `MFlow` and friends has been by Alberto; I want to hear from someone who isn't yet entirely on the same page as him.
 join m t = m t t The semantics is Behavior a ~ Time -&gt; a
&gt; I am claiming that FRP semantics do not fit GUI semantics. And the semantics of GUI are? I think that FRP fits GUI problems quite well. On the most fundamental level, a GUI is something that maps mouse clicks and keyboard presses to a picture that varies in time. Everything else (windows, widgets, etc.) are just abstractions to compose bigger moving pictures from smaller ones. Due to unfortunate historical reasons, traditional GUI toolkits provide these abstractions only with IO. It happens. Note that the example you describe (different screens with buttons transitioning in between) is straightforward to model with `accumB`.