By the way , Wadler https://cs.au.dk/~hosc/local/LaSC-7-1-pp39-56.pdf mentions two possible extensions of monads that can be used to accomodate composable continuations inside monads: Danvy and Filinski: bind :: M o a → (a → M o b) → M o b Murthi: bind :: : M o p a → (a → M p q b) → M o q b 
Blah. They've gone from "Sorry: this video does not exist" to "Sorry: because of its privacy settings, this video cannot be played here."
At least https://skillsmatter.com/skillscasts/9098-haskell-in-the-large-the-day-to-day-practice-of-using-haskell-to-write-large-systems works for me. I think I also got the privacy settings error sometime in the past, try turning off antitracking or adblocking stuff.
It's probably simpler to change the playback speed of the video via the console: document.getElementsByTagName("video")[0].playbackRate = 1.5; 
FLTKHS fully supports [resizing](http://www.fltk.org/doc-1.3/classFl__Group.html#afd220e45e1ac817bde7d6a25fdf74e37). While you do use absolute coordinates to place widgets they grow proportionally as you would expect as the window size increases. You should be able to see this behavior on all the [demos](https://github.com/deech/fltkhs-demos). But it's also quite flexible since FLTK allows you to [resize proportionally](http://fltk.org/articles.php?L415+I0+T+M1000+P1) to a widget of your choice rather than the window as a whole.j UPDATE: FLTK doesn't have a lot of layout widgets like GridBagLayout but it does have one [Fl_Pack](http://www.fltk.org/doc-1.3/classFl__Pack.html) which has been ported to FLTKHS. The [pack](https://github.com/deech/fltkhs-demos/blob/master/src/Examples/pack.hs) demo shows usage. 
I think you CAN, it's just more awkward. I think /u/edwardkmett did a thing where he combined the precondition/postcondition indexes into a single AtKey index. Maybe that's not always the case, but it should handle all the same lax 2-Functors. So, you could have: class Bind m i j where (&gt;&gt;=) :: CtB m i j a b =&gt; m i a -&gt; (a -&gt; m j b) -&gt; m (K i j) b class Bind m i j =&gt; SuperMonad m i h where return :: CtR m i a =&gt; a -&gt; m i a
Hello, we've organized an open source team a month ago for improving the state of the data science environment. There are a few things missing and other few that are awesome and much better than in other languages, like HLearn. If you want to chat about this, come to our Gitter: gitter.im/datahaskell/lobby :D
This is a great talk. And the lesson about keeping it simple at scale is _so_ important.
I'm hiring. In two countries. Different kinds of roles. Please apply :)
See https://github.com/Gabriel439/post-rfc/blob/master/sotu.md for a decently up to date rundown :) 
This is a pretty handy hack, thanks!
Interesting! This Danvy/Filinski encoding[1] looks suspiciously close to [my very old implementation of delimited continuations with indexed monads](https://github.com/thoughtpolice/hs-asai/blob/master/src/Control/Indexed/Monad.hs#L54), based on some work from Oleg a few years ago. And sure enough, the whole paper is about shift/reset :) [1] I believe you got the two of those flipped around - section 3.6 defines Danvy/Filinski as the second of your examples, not the first!
&gt; I wouldn't call this monograph "philosophical;" It's published in a journal called "Philosophy of science." It is indeed succinct but it definitely does not address technical aspects of homotopy, for instance. &gt;Now this might not seem very important, but it is basically the entire justification of Category Theory: there are often more than one notion of equivalence I am well aware. But it is not immediately obvious why a mathematician would desire syntheticity over analyticity, much less a programmer.
Lean is another good one, and it even has a nice online evaluator+tutorial to get you hooked! :)
[removed]
I used stable names to avoid repeated serialization of shared expressions. package refSerialize So the serialization of `let x= "hello" in (x,x)` is the string `"(x,x) where x= \"hello\""` It is necessary to keep the stable name references "alive" in a table or else will be reused
I have an implementation of multi-core distributed map-reduce fully in Haskell. https://hackage.haskell.org/package/transient-universe-0.3.5/docs/Transient-MapReduce.html It may use boxed and unboxed vectors. Basically it implements the spark layer of Resilient Data Sets (called here distributed data sets (DDS) Over it it could be implemented algorithms for machine learning. There are some machine learning algoritms scattered in haskell libraries that may become very scalable if re-implemented over map-reduce. Even in a single machine, instead of a monolitic process using parallelism, to run distributed processes in a node per core can speed up dramatically the computation since each core run independently and the garbage collector does not stop all the cores when running. If anyone wish, I would be very happy to help him
There's a difference between being philosophical and having to do with philosophy. Type theory resides as much within philosophy as it does within mathematics or computer science, yet most manuscripts that deal with type theory resort to inductive semantics than pure philosophizing. While this isn't a comprehensive introduction to abstract homotopy theory nor MLT, it gives several technical examples of the usefulness of HoTT nevertheless. The take-away is a general motivation of HoTT. &gt; But it is not immediately obvious why a mathematician would desire syntheticity over analyticity, much less a programmer. A synthetic theory just means a theory that does not depend on a separate theory to define its basic objects. For mathematicians who work closely to the foundation, the appeal will be natural. For programmers like you or me, it doesn't really matter all that much. A report that is technical does not mean that it has to appeal to programmers. Like I argued before, HoTT influences a lot of different fields. It will benefit PLT by motivating the development of new and interesting rewrite systems that can cope with the demand of the different flavors of HoTT. However, there's no reason to believe that the resulting language will be vastly different from your everyday run of the mill dependently typed language. If you want to program in it, you will still be able to write your Haskell or ML code; if you want more, you can work in a bit more dependent types; and if you want even more, you construct an instance of isomorphism between two types (which ends up being a pair of mapping) and automagically transport a general algorithm on type A to type B, or any other types that is somehow isomorphic (or "identical") to your ground type. That is all that has changed, and while it is interesting, the programmer doesn't have to take classes in algebraic topology to use the new features.
It's not so much that I'm not interested, as that I have a backlog of things I am interested in but haven't followed up on.
Can't speak on other's behalf, but I believe the no. 1 reason Interaction Net (IN) has not taken over the world is that there exists no efficient implementation. Pointer chasing (in traversing a graph) is never efficient given existing computer architecture. Maybe FPGA can help? I don't know. But if you are only interested in it for research purpose, I'd suggest you dive deeper into a particular problem and try to publish your discoveries, rather than seeking opinions here. You'll have much better chance seeking out collaborators by directly contacting authors of relevant work. If you are really motivated, take an internship with one of those people or doing a PhD is the way to go. EDIT: By the way, graphs in Interaction Net do not have 1:1 correspondence to lambda terms. As soon as you have recursion, things get complicated. Say if you start with a lambda term with letrec, convert it to IN to reduce, get the final result and convert it back to lambda term. Try it, and you'll find that some intermediate IN graph CANNOT be expressed in a finite lambda term even with the help from letrec. Grabmayer and Rochel had a paper on [Expressibility in the Lambda Calculus with letrec](https://arxiv.org/pdf/1208.2383v5.pdf). 
Thinking of writing some word2vec bindings. Has anyone done this already?
Good question. I was fretting about `yield` which is structurally different of course. I found a reliably lame pipes program and added the equivalent rule: "await &gt;&gt;= f" forall f . await &gt;&gt;= f = Request () (oneShot f) in [this gist](https://gist.github.com/michaelt/611d4a28768d088b10982e2a99accdb1) It works as well if I just include it in a [patched pipes](https://github.com/michaelt/Haskell-Pipes-Library/blob/master/src/Pipes.hs#L203) using [this program](https://gist.github.com/michaelt/3c8e7a0590691ab1c34e5c088c490bae) It takes 500MB with hackage pipes, but is like hello world with the patch. I suppose it isn't very robust but it was interesting to see it work. It's fairly hard to cook up a reliably pathological cases, so maybe this is just kicking the machine and works in this case. If it were robust it would solve most problems with pipes and sinks, I would think, since even if they yield, they also await. Or maybe I'm wrong to think that would stop the pathology. The corresponding yield rule doesn't work, as could be expected. Maybe if there were a few more options in `GHC.Magic` this could be handled deep inside the libraries. 
The AtKey construction was originally due to /u/pigworker in his not-quite-published Kleisli Arrows of Outrageous Fortune paper. It shows that the 2 argument form is a special case of the 1 argument form. (That said, operationally, encoding things this way is slightly annoying in GHC as it results in paying for an extra box due to the need to carry an equality constraint around. The only thing I contributed to the story was dualizing the atkey construction so I could use it for comonads. (Instead of needing a construction data Atkey i j a where AtKey :: a -&gt; Atkey i i a you need newtype Coatkey i j a = Coatkey ((i ~ j) =&gt; a) for handling comonads this way. Regardless, this unifies these two forms, but that leaves off Dominic Orchard's encoding. Personally, I find this whole supermonad thing a mess with terrible inference and I hope to hell that it doesn't catch on.
Appears so: https://github.com/abailly/hs-word2vec
If it's okay for employers to post job offers here, I would hope it's okay for a third-party to post a donations page for a project that's already provided free content.
If they already use Haskell it is extremely unlikely they'd be happy with Elm longer than a week or two. You could probably suss this out by having 2 (elm) x2 (purs) get 20% time to investigate and then discuss. If you need to make a decision _right now_, use PureScript. Your app is less likely to become legacy out of nowhere that way. Elm's audience is more along the lines of "JS dev leveling up" rather than the other way around, generally. Disclosure: we use GHCJS and GHC Haskell at my company.
Purescript is way more like Haskell. Elm lacks the type level features to mock even the most basic of Haskell abstractions. Purescript is like mini-Haskell. To me the debate is between Purescript and GHCJS
I much prefer purescript, except that the the interpreter/compiler is annoyingly slow.
Right! Because I got used to do template by adding jinja2 syntax on the html page (I am coming from Python and Node) So I wonder whether you guys would have any idea for it
&gt; That is quite out of the reach of an undergrad attending to a quite unrelated subject, don't you think? I have no formal education to "publish my discovers", I don't even know how those things work. Don't worry too much about the formal academic system. It's nice if you can get into it, but it's not essential. Publishing there is *sufficient*, but it is not *necessary*. It's #2016, if you don't have an inroad to the bureaucracy, just publish on Github and post your ideas around here, like you're doing now.
Just so we are clear, It's not only about advanced types and generallity though, even expressing `Map CustomDataType OtherType` is impossible in Elm.
There's no primitive heterogeneous equality in MLTT and book Hott, instead it is represented as an equality lying over another equality: coe : {A B : Set} → A ≡ B → A → B coe refl a = a PathOverPath : {A B : Set}(p : A ≡ B)(a : A)(b : B) → Set PathOverPath p a b = coe p a ≡ b In book HoTT it's usually notated as `a ≡ₚ b`. If we hide the `p` path inside a sigma, we get "John Mayor" heterogeneous equality: JMEq : {A B : Set}(a : A)(b : B) → Set₁ JMEq {A}{B} a b = Σ (A ≡ B) λ p → coe p a ≡ b However, `JMEq` is unusable in HoTT, becase we can't convert `JMeq {A}{A} a b` to `a ≡ b`, since if `p : A ≡ A`, `coe p` isn't necessarily the identity function. With Axiom K, however, all reflexive paths are just `refl`, therefore all coercion along reflexive paths is just `id`, so we can get back to `a ≡ b`. Back to the question. In a HIT definition for `A` both sides of the return equality for the higher constructors must have type`A a⃗`, where `a⃗` is a telescope of `A`-s indices (equality is homogeneous). We can use `PathOverPath` and coerce any of the indices. For example, if `A : Nat -&gt; Set`, `n m : Nat`, `p : n ≡ m`, `a : A n`, `a' : A m`, then `coe (cong A p) a ≡ a'` is a valid return type for a higher `A` constructor. 
That's great to hear!! We've now got most of the other talks of the Haskell eXchange up as SkillsCasts as well... You can find them here, hope they are useful too: https://skillsmatter.com/conferences/7276-haskell-exchange-2016?tc=60a9d8#skillscasts
How about dual GPL/Commercial? Anyone who makes free, open source software is free to use your project; anyone who is from a megacorp and wants to use your project must contact you and obtain a paid commercial license via contract with you. This is not without precedent by the way. There are [major software developers](https://www.qt.io/licensing/) who operate this way.
Besides the wonderful insight of seeing FRP trough temporal logic lenses, beginning in the minute 33 gives the key why FRP is hard to be adopted for GUI's
it really depends what you're trying to do with them.
Unless I'm misunderstanding you, you're not right. The standard library doesn't do this, but you could write a Map module where the function to create an empty Map takes a compare function. This is what Ocaml programmers seem to prefer even though Ocaml functors are neat. No typeclasses or HKT needed.
You have got me very excited about the topic, thank you for that. I am working on an implementation as a side project. It will be based on [this paper](https://arxiv.org/abs/1505.07164). You can [take a look at the code](https://github.com/phischu/llol/blob/master/src/InteractionNet.hs) but beware it is side-project-early-prototype-quality. If you squint a little you'll recognize a stack, a heap and static single assignment form. I am trying to understand the connection to proof nets. I think interaction combinators correspond to proof nets for the multiplicative fragment of linear sequent calculus with explicit weakening and contraction. That would give us a type system and a curry-howard-correspondence. EDIT: If you want to know more about the latter you can read [`A dissection of L`](http://assert-false.net/arnaud/papers/A%20dissection%20of%20L.pdf).
Nothing fancy: symmetric and asymmetric versions of sign/verify, encrypt/decrypt, with a hashing routine. Bonus points for PBKDF2 or similar. In theory I'm comfortable trusting someone who has been *very* careful making nice choices so that these things are easy to use. But I default towards choosing and assembling primitives myself, because then I know exactly how careful I've been. I'm not so familiar with the available Haskell libraries (which is why I asked). So far, I'm not loving any of the ["easy to use" options][1]. And the "grab bag" libraries seem to have lots of unfinished and/or severely [outdated][2]/[never-dated][3] implementations, so it's hard to know what is science project and what is industrial strength (not that I'm going to use DES or TEA, but were those constructs implemented with the same level of care -- and side channel awareness -- that I'm expecting of the AES, ECC, or RSA routines? Is that boundary specified?). [1]: https://github.com/tel/saltine/issues/28 [2]: http://hackage.haskell.org/package/cryptonite-0.20/docs/Crypto-Cipher-DES.html [3]: http://hackage.haskell.org/package/Crypto-4.2.5.1/docs/Codec-Encryption-TEA.html
You are right. My mistake. Any idea why the standard library doesn't do that?
Sigh! "Please log in to watch this conference skillscast." Really?
People say this but outside video it seems like a lot of people wanting to do distributed machine learning really have datasets on the order of a few terabytes, hundreds of gb or even less. In that case does distributed computing outweigh overhead costs?
I'm hiring 1 or 2 PureScript developers to develop GUI frameworks to front Haskell systems in London. Send me cvs if you're interested.
Albeit a year old, still related: [On the state of cryptography in Haskell](https://www.reddit.com/r/haskell/comments/2zsbth/on_the_state_of_cryptography_in_haskell/)
Have you looked at cryptonite? http://hackage.haskell.org/package/cryptonite It's relatively recent (if you consider 2015 recent). Looks like it aims to be kitchen-sink crypto package and seems to be maintained. I can't vouch one way or the other for its security though unfortunately, as I've only used it for hashing stuff. Hopefully someone else can chime in here. 
Tried noredink's JSON pipeline?
It's deceptively young. Vincent basically took a bunch of packages that have been used for years and combined them into one package. In other words, it's more mature than it looks.
But then this doesn't degenerate to regular `Monad`s without forcing some dummy `()` type parameter on them.
AFAIK, at least a feedback loop using psc-ide or pscid is pretty much instant
Is this similar [alphasheets](http://www.alphasheets.com/)?
I find the idea very interesting (I've been of the opinion that something like this would be a good environment for years), and wish you the best of luck. Unfortunately, I'm not going to even look at it, since my employer has a spreadsheet-on-the-web product and I'm trying to avoid any conflict of interest (and I doubt I'd be able to stop myself from coming with suggestions if I looked at your system.) I look forward to trying it if I change jobs! :-)
This is the answer I almost always turn to, unless I'm willing to put up with building my own combinators for functions, calls, let bindings rather than observe sharing directly in the host language.
"Big data" is really a moving target.
What is the business reason for requiring registration? p.s. the parsing video is broken.
It is only hard to express **In Haskell**, because functional programming languages have very strong notion purity on pattern matching that disregards resource usage (there is some magical copying going on under the hoods to make it true). Suppose that pattern matching was slightly modified to have a linear/graphical flavor, i.e., it actually replaces the left occurrence by the right occurrence, and reconnects unvalidated pointers (if X points to location A in Y, but Y was matched and now location A internally became location B, then X points to location B now). Under that language, implementing Interaction Combinators wouldn't require dealing with pointers manually anymore. Here is the code: data Port = A | B | C data Type = Yin | Yang data Wire = Wire Port Node data Node = Node Type Wire Wire Wire wire :: Wire -&gt; Wire -&gt; Wire wire a@(Wire A (Node at au al ar)) b = Node at b al ar wire a@(Wire B (Node at au al ar)) b = Node at au b ar wire a@(Wire C (Node at au al ar)) b = Node at au al b link :: Wire -&gt; Wire -&gt; Wire link a b = wire a b &lt;&gt; wire b a reduce :: Wire -&gt; Wire reduce (Wire A (Node at (Wire A (Node bt (Wire A _) bl br)) al ar)) | at == bt = wire bl al &lt;&gt; wire br ar | otherwise = wire al (Wire A aa) &lt;&gt; wire ar (Wire A ab) &lt;&gt; wire bl (Wire B ba) &lt;&gt; wire br (Wire B bb) where aa = Node at bl (Wire B bb) (Wire B ba) ab = Node at br (Wire C bb) (Wire C ba) ba = Node bt al (Wire C aa) (Wire C ab) bb = Node bt ar (Wire B aa) (Wire B ab) (&lt;&gt;) :: ∀ a . a -&gt; a -&gt; a a &lt;&gt; b = b 
Respectfully, I don't need _another_ throw away account on this Internet littered with arbitrarily "sign-up blocked" content. Why not upload the content on YouTube or Vimeo where anyone can view the content with no barrier to entry?
As a couple of data points, both Strange Loop and Yow Lambda Jam both seem to have videos available directly on Youtube. I bet they're also a lot more popular too, for this reason. https://www.youtube.com/channel/UC_QIfHvN9auy2CoOdSfMWDw https://www.youtube.com/user/YOWAustralia
No, Maybe is an unary constructor. "Maybe Int". 
Thanks for the parsing video feedback, looking into it right now.
&gt; Hmm, order of magnitude+ level big? Yes, likely. Previously, psci would invoke a full psc compile on every input. With large projects this is non-trivial, even with incremental compilation. It uses a different architecture now which avoids this overhead.
I'd recommend auditing especially the cbits before using `cryptonite`. Last time I checked, there were a few minor issues/bugs lurking in there which may or may not be a problem to your specific use case.
Well spotted - there had been an upload error, we're re-uploading now.
&gt; wire :: Wire -&gt; Wire -&gt; Wire &gt; wire a@(Wire A (Node at au al ar)) b = Node at b al ar this looks like a type error, since this equation has type `Wire -&gt; _ -&gt; Node`. &gt; Suppose that pattern matching was slightly modified to have a linear/graphical flavor, i.e., it actually replaces the left occurrence by the right occurrence, and reconnects unvalidated pointers (if X points to location A in Y, but Y was matched and now location A internally became location B, then X points to location B now). I don't understand what you mean by this. What would be the semantics of the program you wrote down for instance? With Haskell I can give semantics where each function corresponds to a mathematical function (with a bit of handwaving around bottom). But it seems your functions have side effects. Should I consider the whole mess of Ports, Wires and Nodes as a mutable data structure? In that case you lose a lot of the benefits of functional programming like referential transparency and equational reasoning and persistent data structures.
Yeah thanks, not sure what I was thinking there!
"non-nullary" seems redundant: to me, `Int` is a type, not a nullary type constructor, and `Maybe` is a (unary) type constructor, in the same way that `3` is an `Int`, not a nullary function returning an `Int`.
&gt; this looks like a type error Yes, that type is wrong. &gt; I don't understand what you mean by this. I just want to point out that expressing the algorithm isn't really complex, it is just complex in Haskell in particular because Haskell doesn't fit the model well. Don't think too much about the language I defined, it doesn't really make sense and is just a haskellish analogy to show how the algorithm works. Interaction-net based languages are somewhat like that but not really, you can't "apply functions", you can only define global reduction patterns and create graphs. Referential transparency isn't broken because you don't have two copies of the same object in different places.
The parsing video should work now
&gt; Referential transparency isn't broken because you don't have two copies of the same object in different places. So it's like a linear logic. But for many useful programs you need a way to duplicate values and/or functions. For instance if you want to do recursion.
Not in a position to make this decision right now, but if I were, I would most likely end up with, in that order: 1. GHCJS. 2. PureScript. 3. ClojureScript. 4. Biting the bullet that is plain JS with a minimalist virtual-dom framework and a "take away the worst pain" library like Ramda.js. 5. Elm, maybe. Let me elaborate. GHCJS comes first, for one simple reason: because it is not similar to GHC Haskell, it *is* GHC Haskell. You get to use anything on Hackage that doesn't rely on the C FFI, which is a whopping bunch; you can reuse code between client and server (e.g. data structures, validation logic, etc.); you get the full power of Haskell's concurrency abstractions, which essentially makes callback hell go away entirely, and allows you to pretend that you can have multi-threaded programs in the browser; and for the cases where you do have to interface with JavaScript, the FFI, while underdocumented, is pretty straightforward and works well. Another advantage is that, with GHCJS being tied to GHC proper, regressions between compiler versions are rare, and breaking changes are managed well. Biggest sore spot is the learning curve to get set up and make your first productive steps, so if your plan is to convince a non-Haskeller, GHCJS is going to be a very tough ride. Next up is PureScript; it is closer to the JavaScript ecosystem, which will make the transition easier for JS developers; the FFI is straightforward and works well, which makes up for a less rich library ecosystem than Haskell's, and some of its language features are actually better than what you'd have to use in Haskell (I'm looking at you, record syntax!). One downside I can think of is that the toolchain seems less robust than the alternatives, and that the language is similar to Haskell, but subtly different in a few crucial regards. ClojureScript is an odd one to list here, its big downside being that it's a unityped language, thus not addressing one of the biggest problems that plain JavaScript has. However, Clojure itself is a pretty mature language with a sound design, and ClojureScript can at least partially feast on its goodness. Particularly, it offers similar threading and state abstractions as GHCJS (green threads, MVars/atoms, channels, etc.), so you can at least avoid callback hell. The language's value semantics are also a lot saner than JavaScript's, and having a metalanguage in the form of macros is pretty damn useful. ClojureScript also has a few really neat tools for an interactive workflow where you can interact with a running application in the browser from a REPL in a terminal. Elm, for me, comes last; the biggest buzz killers are its lack of crucial abstraction features, particularly typeclasses or a comparable tool, the brittle toolchain, bad forward-compatibility (at one point, an unchanged codebase from mere months ago would no longer compile), and error messages that try to be helpful but occasionally fail epically, or become full-on condescendant. The language is also too opinionated as far as application architecture goes, and the primitives it offers to deal with effects don't make an awful lot of sense to me. Plain JS, while comparatively awful, is still a viable option; some of its problems can be mitigated with tooling, others can be avoided, yet others can be softened with suitable libraries. The big upside is that all of the existing library ecosystem can be used, and you won't have to teach anyone a new language (OTOH, you *will* have to teach people proper development practices, which is arguably a much bigger problem...)
it's working on my machine... https://skillsmatter.com/skillscasts/8722-meet-hadrian-a-new-build-system-for-ghc Do you mean this one? 
Raaz is promising. It uses types like `AES 128 CBC` and `KEY256` and `Key (HMAC SHA256)`, rather than other libraries use of often undifferentiated ByteStrings. Using it has felt much less foot-shooty to me. It has some good groundwork for avoiding timing attacks &lt;http://www.cse.iitk.ac.in/users/ppk/posts/2016-07-30-Why-another-cryptolibrary.html&gt; and a nice secure memory monad &lt;http://www.cse.iitk.ac.in/users/ppk/posts/2016-08-02-Handling-Secure-Memory-in-Raaz.html&gt;. Still needs time to mature and be reviewed..
Looks like it’s been fixed. It’s now working for me as well.
If that's what you want to do, use PureScript. But, 99% of the time *in web-dev*, you're using functor operations on pre-existing things: IO (Cmd/Task in Elm), List, Maybe, Either (Result in Elm). All the functions are provided, you just have to do `Html.map` or `List.map` or `Result.map`. And if you have your own data structure, you just write your own `map` function. Sure, you can't write a function that is generic over functors, but that situation doesn't come up often in Webdev, and when it does, you use PureScript. (And it's worth mentioning, Elm got it right by using map instead of fmap in the name!) As it is now, Elm wouldn't be my first choice of language for, say, writing another language, but it's well suited for its niche.
Also, PureScript is strict, no?
For me, advanced = Beyond Hindley Milner. You can fake typeclasses pretty well with dictionaries, but nobody has gotten around to writing a custom generic Dict in Elm yet.
Because 99% of the time in Webdev, you're using Int or String as your key in a Map. Nobody's gotten around to writing the generic one, but it would be a bit cumbersome to use all the time, so it's better suited to being a library than the standard implementation.
Thanks for writing it! 
In my opinion these are the main differences: * In Herculus, you can't define a formula for a single cell, only for whole columns. This keeps your table more structured. * Instead of allowing to write R and Python expressions, we design our own language for formulas, which is purely functional and strictly typed. * We have a column type called `Row` which allows referencing rows of other tables, like in a relational database. Also, the build-in language works very naturally with these references.
I'd like to know too. I know no more than you do. I found the system interesting and made a few observations over time, and that is all I know. I commented on some possible downsides on the efficiency of the system below, but emulating FP languages isn't really my motivation to keep studying ICs anymore.
It's indeed pretty cool to have a speadsheet tool which supports fancier types than just numbers, strings and dates!
Sorry, what do you mean? `map f . map g` of what? Something like `map (* 2) . map (+ 2) $ take 4 numbers`?
I play around with Haskell on Windows, and always hated GTK's *so called* native experience (font rendering and input are both broken), FLTK and Wx are both ugly, so it's good to see Qt having some love.
Life is much more exciting when you might get cut though!
Your `map` definition is not recursive, which is why it works. You pretty much have your mind set on church encoded list, which encodes recursion strategy in the number itself, not in the `map` function. 
How have you found GHCJS's performance and general production readiness?
I'll suggest you extend your language with data constructor/destructor and letrec (which translates to simple looping structure in IN). Then you can define list and map the "usual" way, and you'll see what I mean. Basically, most lambda evaluation strategies stop evaluating once it encounters a lambda, and treat it as a **value**. However, optimal evaluation (with sharing) will not stop evaluating under lambda, so evaluating `map f . map g` should lead to evaluating the body of `map`. This will again work out fine if you stop the evaluation as soon as the outer most lambda appears. So it's actually tricky to come up with something that has its lambda body partially evaluated. So how about this: let map = ... f = ... g = ... mapFG = map f . map g in (mapFG [1], mapFG) EDIT: You may encode recursion with self application `\x.xx` too, which becomes a looping structure in IN once evaluated.
I don't think this is really a problem in practice. Most shallow wrappers I've seen are from people getting acquainted with the language, where it's useful to see how the libraries you are used to using in the JS world map to PS types and idioms. The PS ecosystem is pretty diverse for its age, and I don't think these sorts of libraries make up a large set of libraries in real-world use. Keep in mind, Elm's most used library (elm-virtual-dom) is implemented completely in FFI with a shallow Elm wrapper :)
Glad you like it. I think having a library that is not much more than a thin veneer over the FFI, with just primitives offered, is a good point in the design space to have -- and I think this roughly hits the right level of 'necessary complexity' (basic type safety, but of course foot guns are still possible if you're not careful). It also has all the primitives I like ;) In the past I had a few other tricks I tried around to make the API nicer, but this one seems pretty solid and not overly complex. I didn't want someone to have to *know* many Haskell features at all just to like, hash a blob of bytes. The reason I haven't ever finished it is because I've actually spent more time in recent memory on the *implementation* of the primitives in a fast secure manner, rather than wrapping them up in a Haskell library... Turns out that's more fun than the FFI :) Either way I should really get around to releasing this... EDIT: BTW, if you do use that, I would appreciate any bugs or anything you can report! I think some of the only real hacking I've done is some minimal deduplication of some code; e.g. sharing curve25519 among some of the other APIs [like right here](https://github.com/thoughtpolice/hs-nacl/blob/master/src/cbits/curve25519xsalsa20poly1305/curve25519xsalsa20poly1305.c#L4). But if you look over the code, I think you'll all find it's pretty "obvious". Reports welcome though, of either it failing horribly, or being useful. EDIT: I realized I started this library nearly 5 years ago in my spare time. please send help.
That makes total sense now, and is very interesting; so if part of you graph isn't expressible as a finite term, then the whole graph can't be read back despite corresponding to a finite λ-term. Is that it? Nether less, that is the kind of thing that I usually sweep under the carpet as if it is a manifestation of some defective computational property on the λ-calculus's side. After all, those terms simply won't happen under certain programming disciplines - so, why would they be so important? Am I wrong in having that interpretation of the situation? 
Actually it is, I thought it wasn't but I misunderstood the paper. What isn't turing-complete is the class of EAL-typeable λ-terms, but there are interaction combinator nets that don't correspond to λ-terms capable of simulating a turing machine. And EAL-typeable terms are "complete" for any turing machine that takes elementary time to reduce. (Someone please correct me if I said something wrong.)
Oh okay, I don't actually know anything about interaction combinators. I was just going by your post :P. I guess another reason for lack of interest on the theoretical side might be that everything they can do can be done with lambda calculus with an optimal reduction strategy and everyone already understands lambda calculus (even if they don't understand the full details of optimal reduction). Though I could believe that they make things conceptually simpler. Do you have a link to a nice introduction to interaction combinators?
Eh. If you want to write purescript, write purescript. It's not like the language is stopping you, and the ability to step down to the JS doesn't get in the way unless you let it.
&gt; For me, advanced = Beyond Hindley Milner. That's very very bare bones for me. I need at least some way to abstract my code. I can get away with only having higher kinded polymorphism. &gt; You can fake typeclasses pretty well with dictionaries Not sure I understand, can you explain?
What is the license going to be?
yep. AFAIK the core idea was to make something that translates to JS in a very straightforward matter. you can take a look at generated code at [try.purescript.org](http://try.purescript.org) for examples.
Sadly, yes. I believe that when it comes to types, there are two sweet spots: 1) A type system and type checker that are powerful enough to pull their weight. Haskell does this well, C++ kind of does if you use it right, Java fails across the board. 2) A unityped language that makes up for the lack of types through things like rapid iteration, powerful metaprogramming, etc., combined with a programming style that embraces dumb generic data structures, dealing with failure instead of avoiding it, and builds abstractions through metaprogramming. Erlang seems to be doing this rather well, and obviously the Lisps are textbook examples; Python, JavaScript, PHP, and other popular dynamic languages try to take things into this direction, but they are both too complex and too limited in their expressivity to cash in. Personally, I much prefer option 1), but IMO Elm falls short in terms of expressivity and tooling, and I found the experience rather disappointing. I would not say that Elm's type system pulls its weight.
&gt; talks by Haskell and other experts 'Haskell' is not a person in the context of this talk, but the topic. 
Sure, but this won't work for the most useful things such as a Functor abstraction because of the lack of HKP. :(
The compiler can't type check Javascript or enforce semantic versioning on it which hurts reliability, and my gut tells me any module complicated to warrant wrapping will come with a big ugly sin bin API, and probably won't play well with whatever declarative UI library you're using so it might as well be used through a port in the short term and replaced with pure Elm eventually. Elm allows the programmer to not write code that feels like Javascript-in-Elm, and I think it's because wrapping JS is sort of frowned upon. To me, it seems uncommon for successful language communities to cling to libraries written in the language they're trying to get away from. But you see it all the time in front end web development, like nobody wants to leave npm behind. C++ can pull it off with C and Typescript can pull it off with Javascript, but can PureScript when it isn't really similar to Javascript at all? And as I said, some day Elm will start compiling to WebAssembly and it won't be a big deal if the FFI code is kept to a minimum. Elm could compile to machine code for server side and not depend on node. Your code doesn't care what, if anything, is on the other side of the port (ports are the escape hatch back to Javascript, but it could be Haskell or even PureScript). I don't actually want to bash PureScript. I know there are a bunch of great libraries that use minimal or no Javascript underneath. I just saw a lot of bashing Elm's (limited) type system as if that's the only thing that matters. Elm is quite productive and wanted to point out some advantages Elm has, and I really hope it brings more people to functional programming. I'd be extremely happy if those people eventually migrate to PureScript for its richer type system as long as they're not doing it so they can wrap a poorly conceived JS module.
Grrr... I also realize I *somewhere* had a secure random library I also wanted to publish that was literally just a pure Haskell port of `arc4random` based on `/dev/urandom`/`WinCrypt`, but now I can't find it! I remember wanting to release that separately from this. Sigh. So much to do and so little time...
That doesn't bother me the same way, because the Javascript code is within the project and is written to the needs of the Elm module. A React wrapper, on the other hand, would need to be kept in sync with an external library and probably will not feel idiomatic. I'm aware that in many cases, FFI is necessary, but yes, I think it's a good thing that it's not documented or encouraged in Elm.
&gt; Sure, you can't write a function that is generic over functors, but that situation doesn't come up often in Webdev One of the first pieces of elm code I wrote needed me to reimplement `sequence`. That's a fairly trivial function I use everywhere when programming (also `traverse`/`mapM` and other friends). I just don't want to reimplement it for `Map`, `List`, `Either`, `Maybe` and more when I know a very simple solution for that exists. &gt; (And it's worth mentioning, Elm got it right by using map instead of fmap in the name!) Yes :) So did purs btw :)
I dislike the patronizing stance there - I'm a grown man, I can bloody well decide for myself whether I want to use an FFI or not, and the absence of an FFI is, plain and simple, the absence of a feature. I can understand why, as a language designer, one would choose to not have an FFI, especially when you're designing a general-purpose language: not providing an escape hatch means you can substitute a different backend without having to worry about FFI code people may have written that will inevitably break when the backend it targets doesn't exist. But Elm is not a general purpose language, and my gut feeling says it never will be: it is too opinionated, too much tailored for a very specific subset of front-end web development, and the general-purpose language that it could become if it were to take that route would be some sort of crippled Haskell dialect, nowhere near powerful enough to not just use Haskell. As far as Elm's limited type system goes: it's not the only thing that matters, but it's so limited that at least for me, it becomes a major productivity bottleneck. And when that happens, it might as well be the only thing that matters, because the best build toolchain, best libraries, best syntax, best performance, can't really make up for such a bottleneck - they are all relevant, but their relevance is only relevant in the absence of a show stopper.
Do you mean I was patronizing or Elm's attitude about FFI is patronizing? I didn't mean to say anything patronizing, just trying to explain why I think it's smart to keep JS code at arm's length.
I meant Elm's attitude. Could be me overreacting to genuine attempts at being helpful, but there are several things about Elm that somehow trip me up that way.
`#19` lets you write [ x, y | x &lt;- xs, y &lt;- ys ] It is similar to how products can be defined in Agda, as `_,_` which lets you construct it without parentheses test : Bool → Bool → Bool × Bool × Bool test x y = x ∧ y , x ∨ y , not x f : ℕ -&gt; ∃ (Vec ℕ) f m = 3 , replicate m
I want to remind everyone that we should keep discussion on the proposal page. That's what it's there for, and anything posted here does not stay with the discussion.
Nice paper! I haven't read it in much detail, but was kind of wondering what is the difference between your approach and S. Pinto's VM. The paper was mostly comparing to amineLight, but I more familiar with S. Pinto's work, and hence the question.
I don't Twit!
[removed]
This is a very stripped down msys (next release we're going to have a slightly bigger one -- including most importantly pacman). That said, the shell shipped with msys is in \msys\usr\bin\sh
Agreed. The conference cost over 600 pounds, so an email address to watch all the videos doesn't seems like a lot.
Would be nice to actually get some comments on Neil's talk on this thread.
The SkillsMatters person was say it was free. I was pointing out that its not. Also, they ran HaskellX as a for-profit exercise and sold tickets etc. Its kind of hard to imagine them making money out of the email addresses they collect unless they are selling them to marketing firms. However, making the videos freely available is good advertising for next year's HaskellX. 
&gt; The SkillsMatters person was say it was free. I was pointing out that its not. Yes, you also have to pay for the electricity to power your computer. Come on, we could, as a community, at least show a little bit of gratitude that recordings of these talks were professionally edited and made available for the low, low, price of one email address.
Nice to hear you like our framework :p ([link for those who don't know it](http://ocsigen.org/)) As far as the haskell side goes, The closest is http://haste-lang.org/. It's not as featureful as ocsigen/eliom, and in particular it doesn't have static code slicing and the execution model is less efficient. However, it embeds quite nicely into Haskell idioms (by re-using monads for client/server separation). Unfortunatly, afaik, it's not actively worked on. /u/valderman can probably tell you more.
&gt; (&amp;&amp;) :: Bool → Bool → Bool; infixr 3 &amp;&amp; &gt; (&amp;&amp;) = \case &gt; True True → True &gt; _ _ → False Problem is that the parser wouldn't be able to know whether the second True is a parameter to the first True constructor or whether both are constructors without arguments
What libraries do you use on the front and backend?
A dummy argument seems to help in some cases. See this [little streaming library](https://gist.github.com/michaelt/2757b484c8a316c4c9f436091fce3b09) for the type data Stream a m r = Yield a (Stream a m r) | Done r | Delay (() -&gt; m (Stream a m r)) if I add a rule for `liftIO` "liftio hack" forall m f . liftio m &gt;&gt;= f = Delay (oneShot (\() -&gt; fmap f (liftIO m))) then evil sharing goes away in my example. The corresponding general rule for `lift` doesn't work though, as you can see by replacing `liftIO` by `lift` on line 58.
On the backend, the web "framework" is Spock. And it's fantastic. (I've messed with *servant*; it's fun, but (for my use case) the mechanism for auth is chock-full of incidental complexity.) In terms of supporting libs, I use *persistent*, *aeson*, *conduit*, *validation*, *async*, *bcrypt*, *stripe-core*, *attoparsec*, *jose-jwt*, *lucid* and more . . . For the front-end, I primarily use *purescript-react* and *purescript-rx-state*. But things like *purescript-validation*, *purescript-argonaut*, *purescript-affjax*, and *purescript-routing* feature prominently. This is the first (deployed) app I've ever built. But I haven't had any problems finding a library that does what I need. It's amazing to write in languages where you compile and it works. I'm only half-kidding when I say that I pray daily that Simon Peyton Jones doesn't retire any time soon - - because *stm* . . . And given that Elastic Beanstalk allows docker now, it's trivial to deploy Haskell apps. The CPU utilization is stupidly small. :) edit: I forgot to mention that with GHC 8.0.1, there is StrictData now. Saves on the exclamation points.
It can help simplify implementation if you treat types as a special case of type constructors. At least this is how I learned to impliment a basic language. 
Thanks for the info. How do you do auth with Spock? Did you build your own or use spock-auth? Or something else?
I built my own; but *users* is a reasonable option. In my opinion, as long as you're not rolling your own cryptographic functions (i.e., use *bcrypt*) or, god forbid, storing plaintext passwords in your database, there's no reason not to set it up yourself. Once you have an auth abstraction, then Spock gives you 'context' -- which employs type-level lists to ensure that you don't leave end points unprotected.
 I've thought about this for dictating into text fields without context. Unfortunately, editing text via keyboard events isn't a group: * The relevant actions are only inserting characters and deleting them (and arrow keys, for navigating text). Deletion is right-inverse to insertion (i.e. if you press delete after pressing any character, it's like having pressed nothing), but not left-inverse. And, the inverse isn't unique for insertion (every character is deleted by the same key), and deletion has no inverse (you don't know the character you deleted to reinserted). * Keypresses and character insertion/deletion aren't even one-to-one. Take Emacs: with TEX as the input-mode, pressing 6 keys (e.g. "\alpha") inserts a single character ("α"); with abbreviation mode, pressing 2 keys (e.g. "r ") can insert 7 characters ("return "). Even associativity is violated, depending on how you interpret grouping. * Text has a boundary. At the start of the buffer, deleting does nothing, and up-arrow isn't as inverse to the down-arrow. That is, editing text is *context-sensitive*, not algebraic (at least, if the group is a keyboard). You have to model the buffer, not just actions on that buffer. 
monoid-subclasses is awesome 
This looks awesome! I'll need some time to read and digest most of it, but thank you very much for your work.
It is indeed actively worked on. There's a *lot* of new stuff coming up in the next version, but I can't really tell you when it's going to be officially released. Development has been decoupled from the Haste compiler, to make work on it be a bit more flexible.
Huh, glad this is a haskell forum.... Anyway, what was your experience with purescript? Did you use some purescript-bridge to transfer data types to purescript or did you write the argonaut instances yourself? 
That is actually quite a perfect time frame - thank you! ;-)
Yes, you're right. See the replies to your sibling comment.
How would you create anonymous function without argument binding? 
Do you think it would make sense to create some central place where resources for debugging spaceleaks this way can be collected? Specifically I’m thinking of a list of false positives (at least mapM and sequence but I guess there are others) and possible replacements, examples of hard to find spaceleaks to give people an idea what to look for and other tricks like your `wrapper` function. Maybe a list of functions in base leaking space also makes sense (e.g. `maximum`, `sum`, …) Would it make sense to just add this to your `spaceleak` repo? EDIT: I forgot to thank you for this great talk. This is extremely useful!
I think that'd be backwards-incompatible to existing code though :/
ouch, nice scaremongering hvr_. If you know of genuine issues or suspect issues, why didn't you open a bug to let everyone know (and possibly create bug fixes, etc) instead of spreading vague FUD like this ?
This sounds uncannily like the stack we use at work!
this is awesome
Ok had a chance to go over the contents of the page. Since I've been using this for over a year now, I've a few opinions on how one should be producing static executables. I could write this up into a more expansive blog post but for now a quick TLDR: don't do this, update your cabal files like so (or add a flag so you can do so), I contributed this to the stack project itself so I could produce static stack executables this year, note the -pthread isn't needed I've since learnt: https://github.com/commercialhaskell/stack/commit/cda4c091a95b9753818bebb0530cfa460b5f039b Basically do this: /tmp/pid1 # diff -u pid1.cabal.original pid1.cabal --- pid1.cabal.original +++ pid1.cabal @@ -23,6 +23,7 @@ ghc-options: -Wall executable pid1 + ld-options: -static hs-source-dirs: app main-is: Main.hs ghc-options: -Wall -threaded Then you'll get just the executable statically linked, what the post here is describing is amounting to forcing shared libraries, .so really, to be built as static archives or .a's and then linked into a static executable. This will work, but you'll get a bigger binary. Example: /tmp/pid1 # stack --local-bin-path /sbin install --test pid1-0.1.0.0: configure Configuring pid1-0.1.0.0... pid1-0.1.0.0: build Preprocessing library pid1-0.1.0.0... [1 of 1] Compiling System.Process.PID1 ( src/System/Process/PID1.hs, .stack-work/dist/x86_64-linux/Cabal-1.24.0.0/build/System/Process/PID1.o ) Preprocessing executable 'pid1' for pid1-0.1.0.0... [1 of 1] Compiling Main ( app/Main.hs, .stack-work/dist/x86_64-linux/Cabal-1.24.0.0/build/pid1/pid1-tmp/Main.o ) Linking .stack-work/dist/x86_64-linux/Cabal-1.24.0.0/build/pid1/pid1 ... pid1-0.1.0.0: copy/register Installing library in /tmp/pid1/.stack-work/install/x86_64-linux/lts-7.1/8.0.1/lib/x86_64-linux-ghc-8.0.1/pid1-0.1.0.0-1E8Wn5CST6h62vVcVjDfim Installing executable(s) in /tmp/pid1/.stack-work/install/x86_64-linux/lts-7.1/8.0.1/bin Registering pid1-0.1.0.0... Copying from /tmp/pid1/.stack-work/install/x86_64-linux/lts-7.1/8.0.1/bin/pid1 to /sbin/pid1 Copied executables to /sbin/: - pid1 /tmp/pid1 # ldd /sbin/pid1 ldd: /sbin/pid1: Not a valid dynamic program /tmp/pid1 # file /sbin/pid1 /sbin/pid1: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, stripped /tmp/pid1 # du -hs /sbin/pid1 656.5K /sbin/pid1 The way given here isn't wrong, but its conflating two things and the gcc trick being used is a bit dangerous to use outside of lets say docker or a vm. You're modifying how gcc will behave when it links libraries. The conflation arises due to the fact that to gcc, -static will apply to both shared libraries and executables. The linker error being seen is due to -static being sent to things trying to build a shared library. But those libraries are built with TEXT segments which the linker rejects for various reasons that I don't want to get into before I go for a run. Would anyone want me to write up a blog post somewhere with a bit of a longer explanation behind things like elf binaries, linking, the GOT, segment types etc...? 
Just in case that there might be a misunderstanding: the paper is not by me. My approach is a spcialization of the paper to interaction combinators and some simplifications. I am not aware of Pinto's work, are you referring to "Parallel Implementation Models for the lambda-Calculus Using the Geometry of Interaction"?
For some time, I've been interested in tech entrepreneurship -- social and otherwise. So in June 2014, I started with Harvard's online CS50 course (uses C), moving next to Berkeley's intro course (python). Learned a lot from both, but I was shocked at just how error prone it was. As a litigator, I look to minimize risk. And building with these tools -- C and python -- felt risky for me. (Note: I'm really not interested in starting a "best language" discussion. Horses for courses; people are doing great things with Perl and php.) Looking for something "better," I stumbled upon an old cached version of Phillip Wadler's introductory CS course (in, obviously, Haskell). It was baller. From there I did a bunch of free online courses, including for example: algorithms (learning discrete math and probability in tandem), the Coursera scala courses, distributed programming, etc. I read and worked through the classics (e.g., SICP; Purely Functional Data Structures; Concepts, Techniques, and Models of Computer Programming) I love struggling to understand the next genius thing that comes out of Gabriel Gonzalez' or Edward Kmett's mouth. It's fun. Yet the reason that I use Haskell is that I find it to be the most productive and practical language out there.
Are you suggesting it's no harder to find a security vulnerability in code you don't have the source for than code you do?
That's unfair. Haskell is perfectly happy to create anonymous functions of one argument without binding (i.e. point-free style). You just want this to work with more than one argument, which (as you know) is where concatenative programming shines. How would you design the ability to case simultaneously on two (or more) arguments?
Yes, the spaceleak repo is an effort to collect that. The plan was to put all the links to the blog posts to start with, then tie it into a single coherent whole later, with extra information. I assume there are other false positives beyond sequence, but I'm yet to find any...
Do you have any resources or advice for detecting/debugging/avoiding excessive _non-stack_ memory usage (e.g. memory being retained beyond when it should be, at least AFAICT)?
Me too, and I've wanted multi-arg lambda case many many times.
You could write unit tests for Timeclock to verify that you get outputs from the methods that you expect, right now it is simple but considering how much of a problem datetime stuff can be it might be worth covering to make sure nothing breaks. You could probably also build some integration style tests that mock out the notifications and timing system and verify that you can run commands and everything works as you would expect (e.g. have the test run your command, set the timer to 25 minutes later, verify the notification mock is fired)
Nice to hear! I will be interested to see what you're cooking. Btw, we published [a paper](http://poulpe.yt/bazar/eliomsem/aplas.pdf) presenting the semantics of eliom, which might be of interest to you.
I think there is an undiscovered fundamental force in this universe that pulls lawyers and Haskell together. I've seen another lawyer in the IRC and [Obsidian Systems](https://obsidian.systems/), the company behind reflex, was "founded by two Harvard Law School graduates". Dammit, God, you should have used a typechecker. There is a glitch in the matrix somewhere.
Justice Holmes coined the phrase "free trade in ideas . . . [within] the competition of the market." This quality is one of my favorite things about living in a free and democratic society. I'm saddened to read the post about your friend, and I welcome the opportunity to convince him that the current situation -- working families living in poverty -- is unjust.
You're asking too much of GHC here: Realising that `repeat reverse n === id` for even `n` requires somewhat advanced reasoning; certainly too advanced to be applied automatically. Rewrite rules are extremely simple: If the pattern on the left-hand side is found verbatim (modulo instantiation of variables) in the source after inlining, it is replaced by the right-hand side. Nothing more, though it turns out that this suffices for a bunch of important optimisations. In particular, rules are entirely compile-time, so even if GHC could prove the required theorems, it would not be able to apply your optimisation because it is not known in advance whether `n` will be even at runtime. Wrt the warnings, they tell you pretty much what you need to know: `(.)` will usually be inlined, turning `(f . g) x` into `f (g x)`. In this case, the left-hand side can of course never occur and the rule won't fire.
Yeah, it sucks. 
Is Haskell all that suited to the exploratory programming that crops up in data science, and well, science in general? Don't get me wrong, I'm a huge fan of Haskell, but I think something more dynamic and more focused on interactive development fits this niche better. Julia, Python, or R for example.
Really until Haskell has its version of Pandas and scikit-learn, it won't even begin to be widely adopted by the data science community. Would also help to have a Haskell API for Spark (like Flambo for Clojure), but ideally, there would be a native Haskell framework for running massive parallel jobs on Hadoop/YARN/Mesos. I say this as a data scientist working in Python (before that R) and trying to pick up some Haskell. I'd love to be able to bring in some Haskell to my work, but I just don't see how I can do that with the tools being what they are currently.
Ah, yes, I have experimented with that setup, but having client-server in a single module is what we're looking for.
That's great! I didn't know about dataHaskell, but I will closely follow the project and hopefully manage to contribute in the future (currently really busy on various fronts).
I don't read in the document any occurrence of the world "continuation". Doesn't it uses continuations anymore? 
Awesome!!! See ya on Gitter! :D
Thanks. I'd be happy to be proven wrong, so I'll check it out next time I have the chance!
Thank you for your feedback! You're right, the sign up process could be better and needs some work. Regarding your question, there won't be a possibility to "drop straight into Haskell", since we're essentially defining our own language. But we're going to provide a prelude which will contain many of the functions Haskellers are familiar with. You'll also be able to define your own modules that you can then import into your formulas.
What's a function you're having trouble encoding? Maybe I can help. Sorry I don't have anything off the top of my head to link you to.
Great looking website, but I think the tagline is weak-- qualifiers aren't necessary there. How about just: "DATA SCIENCE SHOULD BE DATA DRIVEN WITH A STRONG FOCUS ON TYPES. OUR AIM IS TO BRING POWERFUL TOOLS TO THE BEST LANGUAGE FOR THIS TASK: HASKELL." There are a few more parts I think could be rewritten better, but the tagline is what's the most important.
If you want to write your application for both client and server as a single module (with automatic RPC), you might want to look at [Ur/Web](http://www.impredicative.com/ur/). It's not Haskell though, but a custom language that was very much inspired by both Haskell and OCaml. No idea if it fits into what you're looking for, just throwing it in there as it sounds similar to your goals.
True. I didn’t really mean to come off negatively, it’s just unfortunate that this feature seems hard to design well. I’d probably design something based on the fact that a pattern is the (partial) inverse of a constructor function.
Haskell: data types for data science
haha, too little too late. Amerika is pretty much finished, and the people are fuked for generations to come. Even if they raised the minimum wage to $15, it wouldn't be enough. Technically, the minimum wage should be over $20 by now. And then there is technological unemployment, which means millions are going to become unemployed in the coming years, so no amount of unionization is going to mean anything.
Laws are in test/test.lhs right now, with a few bugs showing up.
Ooh, that's good. I think that (or some other solid and succinct tagline) definitely needs to be on the front page of the site somewhere. "dataHaskell - Data Types for Data Science"
My friend is literally the target audience for OP's website (a far narrower audience than "anyone who wants a bank account"), so I thought OP and those involved in this discussion would be interested in his reaction.
I actually would like to include some equational reasoning to go along with the laws. Or at least some stronger proof than quickcheck. Float is passing the existing tests!
I take no offense; this is almost certainly the case. I don't particularly agree with him, but then again, he's the one that works there, not me.
Yes! Years ago I did a little screencast showing how I used ghci to do some really simple log analysis. https://vimeo.com/12354750 The stuff that I do in that video is VERY basic and probably not super interesting today. But it gives you an idea of how Haskell definitely can be used in the interactive way you're talking about. It also gives a little hint at how Haskell's abstractive power and composability can be a huge win for this kind of thing. There have been so many more tools and libraries created in the 6 years since I made that video that today Haskell is way more powerful for these tasks than what you see in the video. And going forward it will make even bigger leaps in power as this dataHaskell initiative creates more and more sophisticated tools.
I have implied using Ur/Web multiple times, but my boss isn't convinced by it. Mostly because Haskell has a huge community and a great amount of libraries, while Ur seems like an island in the middle of nowhere. I find it a great suggestion, though, thanks for bringing it up.
This needs to happen the num class is second only too partial fictions as the biggest embarrassment in the Haskell prelude. 
Wow. Thank you for introducing me to this.
I'm actually in almost the same situation, which is why I asked this question. Unfortunately, it appears you're right - there's no real haskell-learn or handas right now. 
On the menu panel on the right-hand side of the board, click on `... more` &gt; `Settings`. Then I think you aught to be able to set `Commenting Permissions...` over there.
I'm not attached to the naming at all, and would like suggestions. To get a rigorous semigroup float, you have to use non-classical logic in there, and this feels too far away from the mainline. My floats are passing but.
I have cloned your repository.
For anyone interested in further details, a paper that develops the technique using a series of worked examples is available here: http://www.cs.nott.ac.uk/~pszgmh/ccc.pdf
Thanks for pointing out the advantages of discussing on the proposal page. That said, it's perfectly legitimate to chat informally with people we know, in a transient forum, and explicitly NOT want these passing conversations to be forever enshrined with the proposal!
Interesting. I felt with the original proposal that the problem being solved wasn't worth the complexity (specifically, adding "and sometimes `case`" to layout rules) in the syntax, and this seems to suffer from many times that problem. Adding a countably infinite number of keywords? Isn't that a rather large cost for an occasional syntactic convenience. (Other variants are at least a little better than that extreme!) I'm aware of the likelihood of accusations of bikeshedding here. But in this case, it seems the aesthetic concerns outweigh the usefulness of the proposal, which was already just a syntactic tweak to begin with.
&gt; do I write: Maybe you should? Some people might be a bit naïve as to the (mal)practices of their potential employer but would be extremely grateful to be warned.
Your book, "Programming in Haskell" was what really made me *get* Haskell. It really is a beautiful piece of art. Nice to see that the second edition is out!
Thanks! :-)
&gt; Create a program which repeatedly applies reverse to a list, and then prints the length &gt; Of course, if I do this correctly the reverse' function should never fire; I should be able to create a rule that says reverse' . reverse' = id and another that says length' . reverse' = id. This is somewhat tangential to your point but it seems to me that it's a *really* bad idea to have rewrite rules that change the asymptotic run time of a program.
You should also consider that the real purpose of exploratory programming is probably building something reliable at the end, and being easy to explore doesn't necessarily translate to being easy to make reliable. You easily explore how to get openCV python bindings to find a face in the image, but you learn the hard way that the function arbitrarily returns None or a vector of length 0 when it can't find anything in the image.
The point isn't what I want to do, but the lack of benefit in sign-up blocked content.
Great. Nitpick: Some of the text would look a lot better on mobile if it was hyphenated.
So Ints are a semigroup because we learned plus before times, but Bool isn't because we learned ands and ors at the same time?
For reference, here's subhask: https://hackage.haskell.org/package/subhask I don't particulary care for making `(+)` the monoid operator, plus implies commutativity to me.
&gt; To get a rigorous semigroup float, you have to use non-classical logic in there This sounds very interesting, could you expand a bit (provide pointers) here so that I can read further?
Yeah, I suppose so. In the future it will be improved
/u/tonyday567 one test seems duplicated https://github.com/tonyday567/tower/blob/master/test/test.lhs#L110
Cool, especially the String-&gt;Text conversion. I will have a look.
This is nice. Please make sure you retain the ability to have `instance Module (Map k v)`. This was the use case that make me write my own package https://github.com/jyp/gasp/blob/master/Algebra/Classes.hs My two cents: please retain `(&lt;&gt;)` for Monoid and call the `(+)` class Additive, for the sake of making the migration Num -&gt; Tower less painful.
What's an example where foldl is better than foldl'?
`ghci` has debugging capabilities and, unlike the experimental DWARF support, doesn't suffer from not being aware of Haskell's idiosyncrasies.
First off, you've redefined Haskell's Maybe using ML naming. The function exists for Maybe, as 'fromJust'. Secondly, such a function is always unsafe, since there's nothing to map Empty/Nothing to. If you give it Empty it will crash. Try using the `case` keyword to pattern match in your function body instead. 
The function you describe must fail in the `foo Empty = ...` case, it's what is called a **partial function** just like [`head :: [a] -&gt; a`](https://hackage.haskell.org/package/base-4.9.0.0/docs/Data-List.html#v:head) which fails on the empty list (we want functions to be total, meaning that they are defined for every input): &gt;&gt;&gt; head [] *** Exception: Prelude.head: empty list `Example` is `Maybe` with the names changed (we can use them interchangeably) data Example a = Empty | Some a data Maybe a = Nothing | Just a and there is a (partial) function [`fromJust :: Maybe a -&gt; a`](https://hackage.haskell.org/package/base-4.9.0.0/docs/Data-Maybe.html#v:fromJust) which is implemented as: fromJust :: Maybe a -&gt; a fromJust Nothing = error "Maybe.fromJust: Nothing" fromJust (Just x) = x &gt;&gt;&gt; fromJust Nothing *** Exception: Maybe.fromJust: Nothing This makes Haskellers sad ---- You don't *need* a function, you can pattern match on it when you *know* what you want to do in the `Empty` case: ... case example of Empty -&gt; "ERROR" Some a -&gt; process a But you can implement the (partial!) function `foo` as foo :: Example a -&gt; a foo Empty = error "..." foo (Some a) = a but a better way is to provide a function that takes a default value (like [`fromMaybe :: a -&gt; Maybe a -&gt; a`](https://hackage.haskell.org/package/base-4.9.0.0/docs/Data-Maybe.html#v:fromMaybe)) fromExample :: a -&gt; Example a -&gt; a fromExample default Empty = default fromExample _ (Some a) = a or [`maybe :: b -&gt; (a -&gt; b) -&gt; Maybe a -&gt; b`](https://hackage.haskell.org/package/base-4.9.0.0/docs/Data-Maybe.html#v:maybe) example :: b -&gt; (a -&gt; b) -&gt; Example a -&gt; b example default _ Empty = default example _ f (Some a) = f a
Laziness does make debugging hard, but that difficulty is even more pronounced if you're using tools that weren't built with Haskell in mind. Though I should note that I haven't had cause to use any debugger yet, so I'm mostly regurgitating what I've read on this sub and elsewhere.
Thanks. I'll take a look.
For me it's hard to separate intrinsic difficulties with laziness from the fact that the GHCi debugger itself is hard to use. I remember the graphical version that came with Leksah being much much nicer but it's hard to install and doesn't keep up with GHC development. Ultimately I think we'll need something like that, but perhaps a stand-alone version.
If you want to impress the Haskell community, I suppose porting Threadscope to FLKTHS would be a good idea, since getting FLTKHS seems like an easier challenge, all platforms considered.
I.e. you want detect whether the type is recursive or not. My wild guess it's difficult to express, so isn't possible. Please prove me wrong! E.g. situations like data X = X0 | X1 Y data Y = Y0 | Y1 X data Z = Z (Tagged Z Int) both `X` and `Y` are potentially infinite structures, but they don't have self recursion. yet `Z` looks like infinite type, but actually isn't.
`Data.Text` seems "good enough" for now. It seems to install easily on all platforms and doesn't drag a truckload of dependencies with it. Once Foundation is further along maybe someone can help me with a port but for now I don't want to keep changing the API.
That sounds like a great idea! Unfortunately I don't use ThreadScope enough to want to put in the time to fork and re-skin it just to impress people. That said if ThreadScope devs want to take this on I'm more than happy to support and assist the effort.
(I haven't used numpy in years; as soon as I wrote my post, I thought "but is it falsy?", which illustrates the usefulness of falsiness)
What I would like to see are examples of how one would implement instances for existing types, to see how onerous the tall hierarchy is. The examples would ideally include at least one thing all the way through the hierarchy and a bunch of things taken from hackage that implement `Num` for comparison.
I'm in
Laziness does not make debugging intrinsically hard. But it makes debugging different. So it is hard in the sense that if you are already experienced at debugging in a strict language, many of your intuitions have to be forgotten and re-learned. The debugger is indeed useful, but I find myself using it a lot less in Haskell than in other languages. Usually I use it mostly as a way to stop and examine values that is sometimes more convenient than `Debug.Trace` or `monad-logger`.
most agree re the text type mess I think. And partial function in the base are unfortunate default, agreed - though that seems easy enough to explain and avoid. Some of this list seems like a documentation problem though: Like, surely whatever resource you used to learn the langugae will explain to you the Left/Right convention and qualified imports syntax? There's surely greater challenges when learninig haskell than this; like the type system, class hierarhy, the common infix operators etc. And those seem like good challenges to me, given what the payoff fot the learning curve there is in safety and expressivity, creating custom eDSL-like syntaxes etc.
**Auto import** Agreed. In our shop we try hard to make all imports either explicit or qualified. That goes a long way towards making code more readable, and is well worth the few extra characters you type. GHC warnings help make this easier to maintain, but better tool support would indeed be welcome. EDIT: Note that Backpack will soon be changing all that. **Infix operators** Dunno, I don't run into this too much. It just takes a little getting used to. Once you learn the basic common ones - for `List`, `Functor`, `Applicative`, `Alternative`, `Monad`, and `Monoid` - you can do fine. Well, as long as you don't try lenses, but lens fans do seem to like the lens infix operators. **Too many string types** Most languages have at least two, for binary and text. So, we have 50% more, and each has its own good reason, so I don't think that's so bad. Counting the lazy/strict varieties as separate isn't fair; all languages have various streaming techniques, and in Haskell this is just one of ours. **Type over-complexity** I agree with this one. But it will take a while for us to fix that. Until dependent types are fully implemented, together with various yet-unforseen libraries and language extensions that will eventually make them easy as cake, things will get harder before they get easier I'm afraid. **Unsafe functions** Yeah! **Right and Left** That is just homesickness for Elm. Right and Left in Haskell make perfect sense as both the general sum type and as the basic error type, with the easy-to-remember "Right is right and Left is wrong" convention. I actually love the Either type. **Out-of-date banner for documentation** This is a great idea. We need it because Google always sends you to out-of-date pages. (If the Google employees among us can do something about that, it would be even better. :)) **More code examples in documentation** Yep. **Compare a c q v d** I agree. It's like getting stabbed by the lens library. (sorry couldn't resist, the lens library is actually great)
So... did you like *something* ?
Qualified imports make operators a bit of a mess, but I agree qualification is better than implicit import. As a side note, I'm also in favor of record accessors being qualified with the record name, for the same reason. The Either type makes sense as a sum type, just as (,) makes sense as a product type. What does not make sense to me is that there are functor, applicative and monad instances for them which are biased. I understand that it's the only valid instance for "Either a" and for "(,) a", but it doesn't mean we *need* to have them as instances. Just as it doesn't make sense to have instances for any random type on its last type. "Success/Failure" makes a lot more sense to me for successes and failures than bastardizing the standard sum type.
I am excited about DWARF related stuff, but to me it's mostly about profiling with perf.
&gt; This is about GDB debugging. Oh really? Sorry, I didn't get that. When you said "set breakpoints and step through the program", I thought you meant source code, not object code. Anyway, if you had meant source code, you would have been far from alone. :) Indeed GHC object code is much more complex than the object code for a typical strict language. 
I'm not in a position to judge the value of the work presented here, but given some recent work using indexed monads combined with Free, MonadState and its lenses and some other things, I wish there'd be some generally-accepted generalization of 'somewhat funky' monad types (like indexed ones) so all libraries, utilities,... would 'just work' (once generalized).
&gt; Infix operators [...] Well, as long as you don't try lenses, but lens fans do seem to like the lens infix operators. On this issue, I would side with the camp that claims the operators should not be an obstacle to learning *lens*, and that newcomers should be made aware of that -- after all, the operators can be easily avoided when using pretty much all of *lens*' basic functionality (the only exception being `State` stuff like `+=`). Granted, that doesn't help a lot with reading code bases that you didn't write, which was the primary complaint of the OP, but not being scared of *lens* as a whole because of the operators should count for something.
Nitpick: &gt; Unsafe lists [...] There are a number of other standard functions (foldr/foldl?) that seem to suffer from similar issues. `foldr` and `foldl` are safe. If you want examples of that sort, you can use `foldr1` and `foldl1` instead, or `maximum` and `minimum`. 
I'm hoping there's a generics solution for the tallness. You have an operator list (+,-,*,/,0,1), and generically derive a ring, say, and all the right instances are created. Or a poor hackers version is a Ring' class, and wire the necessary operators directly there.
This guide might help with the operators: https://haskell-lang.org/tutorial/operators
You could name the properties, which are overloaded on numeric types. for example, each specialized property: , SC.testProperty "abelian commutative: a + b == b + a" $ ((\a b -&gt; a + b == b + a) :: Float -&gt; Float -&gt; Bool) merges into an overloaded: ring_laws :: (Plus a, Testable IO a) =&gt; proxy a -&gt; [TestTree] ring_laws proxy = [ ... , SC.testPropertyOf proxy abelian_commutative -- see below ] -- must resolve (Testable IO (a -&gt; a -&gt; Bool)) from (Testable IO a) and each group: scheckFloat :: TestTree scheckFloat = testGroup "smallchecks - float" [ -- (30 lines) ] becomes a specialization (one-liner): scheckFloat :: TestTree scheckFloat = testGroup "smallchecks - float" $ ring_laws (Proxy :: Proxy Float) given: -- (inferred) -- :: (Plus a) =&gt; Property (a -&gt; a -&gt; Bool) abelian_commutative = ("abelian commutative: a + b == b + a", (\a b -&gt; a + b == b + a)) type Property a =(TestName,a) -- testProperty :: Testable IO a =&gt; TestName -&gt; a -&gt; TestTree testPropertyOf :: Testable IO a =&gt; proxy a -&gt; Property a -&gt; TestTree testPropertyOf _ = uncurry testProperty (I haven't typechecked it or used Tasty, the instance resolution might be ambiguous) 
You just need to learn different tools. Imagine if your whole life you'd been programming in languages based on Haskell, and suddenly you need to tweak performance of a Java program and most of the documentation you can find about critical parts like the GC is written by academics. 
I see it as intentional ambiguity, in that Left/Right gently suggests the error interpretation but not to the exclusion of alternatives, as Err/Ok would -- and I think it is a good solution.
A left-handed person might disagree!
When it comes to code, exploratory programming in Haskell, in my opinion, is one of the best, if not the best. And I used IPython in the past and I'm a big fan of Mathematica. Don't get me wrong, I definitely see a lot of room for improvement. But it's already better than other options in important areas and, arguably, other options can't have certain kinds of improvements at all, unless they will rewrite their ecosystem to have good type system and type inference. ## Haskell has * Strong types, so you can easily see what an interface is for each function. Type signatures is like a free (hopefully extra) documentation. * Type inference and type holes, so you can see what transformation is needed to glue two interfaces together. Typing `let result :: [Int] = map _ [5.5, 5.5]` will infer that "_" needs to be `Double -&gt; Int` * Hayoo, hoogle, so you can discover functions which would do that you want based on their type signature And usual stuff: * GHCI, so you can interactively load your code in a REPL environment * GHCI helpers like `:t`, TAB completion (like `import qualified Data.Map as M; "M.&lt;TAB&gt;`). FTR, I don't think this is the ideal way. * IHaskell if you need output rather than text ## There are few tricks that I constantly use in Haskell: * "_" creates a type hole * undefined variable shorthand `u = undefined` (undefined is useful for many things during prototyping, I don't want to type it each time) * hayoo, hoogle for discovering functions * `Debug.trace` and tricks like `a + b` to `let !a' = trace' a in a + b`, conditional traces, global unsafe variables that count how many times a function was executed. Global unsafe variables allow to only trace n amount of input (useful if you want to inject trace in some function that gets executed a million times and you want to print first 5 executions and throw an error to terminate). * nix package manager + default.nix (sometimes default-with-profiling.nix that is exactly the same environment, but with with all libraries compiled with profiling) + github clone. Instead of loading third party module as a "remote" dependency, I can find the github repo for that library, `git clone` and swap a dependency for my package with my local github clone. Then, you can modify their code to learn about it. This is not Haskell specific, because in Nix you can just as easily swap dependencies in any language. But it's easier in Haskell due to type safety. For example, modifying their C or Python code will likely result in some completely unexpected runtime disaster. Haskell will usually give a compile error (which you still can ignore using undefined, if you want it to just compile). So the feedback cycle is minimized in Haskell when modifying unfamiliar codebases. You don't need to run code to get feedback. Not to mention that being able to see type of every variable in their function is very useful. You can annotate variables inside their code with signatures , which reminds me of assembly reverse engineering, where you add comments to pieces of code you're trying to figure out, except that "comments" can be typesafe (if they are type signatures), like `(a :: Int) + b ` (but hopefully they write code that is clear enough so you don't have to annotate / refactor it in place like this). * I try to never type anything into `GHCI` unless it's like `:info`. I have a hotkey in the editor for reloading "env.hs" and executing code in that environment with GHCI. For VIM I use "mu" hotkey (its' just random available shorthand; both keys are easily pressed by index fingers on the Programmer's Dvorak layout, so I can hit them fast and often without making my fingers tired). So each time I press "mu" it saves the current file + reloads and executes current environment in GHCI, outputting values I want. You can obviously have autoreloading on save (as many other ecosystems do), but I sometimes want to save a file without executing GHCI (I'm a compulsive saver). I don't care about images that much for things I use it for, but perhaps for data visualization it could execute it in IHaskell to load images. I still type `SomeModule.&lt;Tab&gt;` in GHCI. But I consider it a bad habit and I'll probably try to later write better inspection through Template Haskell that will spill info based on query. Ideally I want to type small line in current environment file I'm working in like `$i "Data.List *"` or `$i "Data.List Bool, a -&gt; Bool"`and have it print everything in that module that matches those signatures and then just dd (delete hotkey) that line. ## Example You can explore things pretty fast this way. Here is an simple example of how you can use type holes, undefined and trace. Forgive the stupid example, I started writing whatever came to my mind. Versions of the file were concatenated into 4-th dimensional output separated by dashes: http://lpaste.net/250830 Each time I press "mu" the `c` gets executed in ghci in another window. ## Addendum The main reason for interactive development and exploratory programming is to minimize the feedback loop. This is the first principle in "Inventing On Principle" and this is one of the pillars of productivity in any domain. You want to go as fast from a hypothesis / idea in your mind to empirical feedback from the outside world. Then, depending on the feedback you either leave it as it is, adjust your idea / product, or conclude that it's currently impossible or not worth pursuing. I think that key principle behind using interactive tools is what the focus should be on. Because sometimes faster feedback can be achieved without pretty pop-ups in a GUI or IDE. For example, I used regex101.com in the past without realizing that I could do the same thing faster if I were using a simple file, hotkey and REPL automation... but it had beautiful blue highlight, menus and it was pretty. Similarly, I don't use IPython anymore. With visualization I imagine it just swapping windows / images by running some code in GHCI. I wouldn't even go IHaskell / IPython route. It's just less productive. I think a simpler setup is going to be more productive for most things. If I wanted it I would have it this way: a hotkey when you press types "reload env.hs; c'" into ghci window (without unfocusing your editor window). That `c'` sends images or JSON (if the server has interactive plots) to a server. Meanwhile a server waits for calls, when it receives some data, it swaps current image or plot with a new updated visualization. You could even have the result displayed on another device if you wanted. What it lacks however when it comes to data exploration is better visualization and data. This is what Wolfram Alpha and Mathematica excel at. But again, you can force `c` to be supplied to some fancy prettier function that is going to give you Wolfram Alpha like page with several widgets displaying that data differently. This is where Haskell has potential as well, because for each data you can have a typeclass similar to `Show`, but which is designed to specifically visualize that data. You can probably even have `trace`-like function, except that it pauses, feeds your data to a visualizer, then you can edit, filter or debug chunk of that data and then it continues execution with that new data when you're finished. Or imagine a `Conduit` that logs each data transformation step in signal processing and visualizes that pipeline, even in real time. Perhaps, for production you can use an optimized `Conduit`s and during development you can use a `Conduit` that secretly spits data somewhere where it's going to be visualized on each step. There is just so much room for exploration here. I guess the moral of this long story is that KISS approach sometimes can be faster and more flexible than writing your own complex IDE-like environment. For data it would just need better visualization tools, data generation and, of course, data libraries themselves. There is one area when it can screw up and it's complex compile error messages if some type level magic is going to be present, which might slow down exploration. But that would be more of a fault of a library author rather than anything else. Also, ironically, learning functional programming might be hard for scientists who already use other paradigms. Other than this, I can't imagine a better language for data, science and exploration. As a documentation, I imagine a website like Hayoo on steroids that indexes all tutorials (rather than libraries) and then when you search it gives you each "notebook" where that type was used in. If that tutorial has dependencies besides the data library, then it can give you a magnet link, so with one click you're dropped into an environment with all those dependencies and that notebook open and ready (would be trivial to do with nix). And if the community agrees to write tutorials in a format that can be indexed and that is 100% reproducible (every tutorial default.nix), then this thing can dominate the world. Looking at numpy, scipy, matplotlib documentation or tutorials would be considered a form of masochism.
What would help is data constructor aliases. Imaginary syntax: type Result a b = Either a b where Err a = Left a Ok b = Right b
`Storable` makes a bunch of hard assumptions that the structure is always exactly the same size. You could make a `Generic` storable for products where the leaves are all `Storable` pretty easily, though. I've done the same for a very closely related format. https://github.com/ekmett/quine/blob/master/src/Quine/GL/Block.hs#L83
&gt;Types get too complex Really? You can create synonyms, and there are monad transformers. Anyways learning to read more complex type signatures is a good thing, but not trivial. &gt;Unsafe lists The `foldl` thing is really irritating, partly because they should have fixed that eons ago. Ugh. 
&gt; There's a good reason for each of these types to exist. But why does prelude use a linked list of characters? It's a bad way to store text. &gt;It's easy to write code that is too abstract and hard to understand. Isn't that kind of the point? Monads aren't too bad, and learning to think functionally involves abstractions sort of by its nature. (And these abstractions will be new if you come from a programming background)
`foldr` and `foldl` are type safe, but OP might be thinking of the fact that they have a tendency to blow the stack if used on large lists.
The OP appears to be thinking about partiality (e.g. `head`), though the stack blowing troubles of `foldl` would indeed make it relevant for this discussion. 
You can already do that: {-# LANGUAGE PatternSynonyms, NoImplicitPrelude #-} module Data.Result (Result, Err, Ok) where import Data.Either (Either(..)) type Result err a = Either err a pattern Err e = Left e pattern Ok a = Right a This is called [pattern synonyms](https://ghc.haskell.org/trac/ghc/wiki/PatternSynonyms).
`Compare` may not be real, but `LensLike f s t a b` and friends aren't much more approachable.
&gt; But why does prelude use a linked list of characters? It's a bad way to store text. Because it's a simple straightforward representation. &gt; Isn't that kind of the point? Monads aren't too bad, and learning to think functionally involves abstractions sort of by its nature. (And these abstractions will be new if you come from a programming background) I'm not talking about well understood and commonly used abstractions. I'm talking about situations where you get carried away with domain specific abstractions that are overly complex and hard to understand. I know I've done this before and I've seen code that suffers from the same problem. I would venture that we've all done this at some point or another. But I think this is just the price we pay for having such a great amount of abstractive power. I don't think it's hard to combat. You just need to have another person review code keeping an eye out for excessively complex and hard to understand abstractions.
I personally think the real issue with haskell is the lazy/eager uncertainty. For instance if i get passed a `List`, there is no type safety warning me that calling `length` on it can crash my system. Type hidden lazy basically reintroduces a much worse version of null
About the infix operators: I suspect that with time and practice one learns them, just as one learns C's &gt;&gt;, &lt;&lt; and assignment versions. Others have already mentioned Hayoo and Hoogle; I will point out this: ghci's :t is my and your friend, precisely because those types you consider too complex are your friend. If you forget what the heck (&lt;*&gt;) does (like I did recently), a simple :t (&lt;*&gt;) gives (&lt;*&gt;) :: Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b a serious hint of what it does and that it only makes sense for instances of Applicative, so you know which type class to investigate if the type itself doesn't suffice.
https://hackage.haskell.org/package/generic-storable exists, but doesn't check for cycles. 
&gt; The ultimate reason not to use Err and Ok is that Either, at its core, represents a generic sum (i.e., disjoint union) type, which is a symmetrical concept that's certainly not tied to the idea that either side is the error case. This is exactly the reason not to use `Either` for error handling, but instead to use an isomorphic type with different constructor names.
A big plus one for this idea xD. I think existing lattices can be grafted on at the base of the tower. I haven't put too much thought in how Bools fit with the tree. 
&gt; What does not make sense to me is that there are functor, applicative and monad instances for them which are biased. I understand that it's the only valid instance for "Either a" and for "(,) a", but it doesn't mean we need to have them as instances I agree. This has caused me some headaches.
Hear, hear! `Either` may capture the essence of a computation that may produce two different results, but that doesn't help when reading code. Of course, once you get used to it, you can read it fine, but the question remains - why create that initial friction at all?
No other language uses a 'simple straightforward' string representation, do they? I'm skeptical that the learning benefits of being able to write list functions that operate on strings outweighs the string type's poor qualities when it's the de facto default representation. When teaching lists to newcomers, we could use `[Char]`, or just avoid teaching lists using strings as an example, and use `[Int]` instead.
That proposal is exactly what I'd like in Haskell. It may not seem like that big of a deal, but I've noticed that I end up spending too much time worrying about imports with Haskell, when I should be spending that time worrying about the logic of the code.
Monad transformers are an intermediate topic, so I guess you're kinda right there. I don't find it overly complex though. The type system is one of my favorite things about Haskell, and one of the really good things that has been there since day one. For everything you learn, you get tremendous power in terms of catching runtime errors and debugging so it seem fair to me. 
&gt;Lets imagine some hypothetical haskell tooling would exist where you could set breakpoints and step through the program. Why would you want to set breakpoints? I feel like the point of a declarative language is that you can write you code out of order and it will work. I could see doing traces being quite valuable but you'd be letting the compiler guide you.
I will create a follow up blog post
It's useful for exotic types, but that's not a reason to include it as the default. `base` should encourage good practices.
&gt; Too many infix operators. Where an operator is defined is mostly easy to find out via hoogle and hayoo. I heard the general point often but this is one of the things I don't really feel (except for lens maybe, but even there it makes sense). Can you point at some operators that annoyed you? Out of interest. &gt; This assumes 2 things * You know about Hoogle and Hayoo * The infix operator is not local to your project Plus when reading code I don't want to to keep jumping to Hoogle to have to understand what code is doing. In order for me to reason about code I need to know what everything does. If I have to keep 30 operators in mind I am going to get it wrong. A side note, when I was in college I recall a prof telling us that putting parethis around expressions in C indicated that we did not understand the order of evaluation. Well C has like 15 levels and no I don't recall them all. When in doubt make the code easy to read.
I think the reason `qualified` exists is so you can do `import qualified Foo.Bar` and then write `Foo.Bar.baz`. If you want to keep that you get the surprising: import Foo.Bar -- not qualified import qualified Foo.Bar -- qualified import Foo.Bar as Bar -- surprisingly qualified 
as someone who has to deal with python and R (and even julia sometimes) on a daily basis, Haskell would be a much better foundation for interactive development. It's the ecosystem that has to catch up.
Obvious? Really? Might be obvious once you're familiar with it but if you're coming to it for the first time, there's nothing there to suggest thst that's there's even a relationship between "left/right and fail/ok". In fact, it wouldn't even occur to someone to use those terms. 
&gt; I understand that it's the only valid instance for "Either a" and for "(,) a", but it doesn't mean we need to have them as instances. You might not use them, but someone that does will either have to use a newtype wrapper (which is hard to justify since there really is only one instance) or have an orphaned instance (which is painful for modularity and in rare cirsumstance and break expectations that are guaranteed when there are no orphan instances.) You can always provide your own `newtype Pair a = Pair (a, a)` and `data Choice a = One a | TheOther a` for the "other" Functor (etc.) instances.
&gt; why the qualified keyword exists at all. Isn't as enough? Because they are orthogonal concepts. * `import M (y)` brings `M.y` into the current scope as `y` and `M.y`. * `import M as X (y)` brings `M.y` into the current scope as `y` and `X.y` * `import qualified M (y)` brings `M.y` into the current scope as `M.y` * `import qualified M (y) as X` brings `M.y` into the current scope as `X.y` One renames the qualifier; one doesn't import the unqualified name. 
See the [`safeint`](https://hackage.haskell.org/package/safeint) package.
I agree that qualified should be the default, at least for whole-package imports.
Example of semigroup law violation in `Float`: Prelude&gt; (50000000 + negate 50000000) + 1 == 50000000 + (negate 50000000 + 1 :: Float) False Prelude&gt; (5000000 + negate 5000000) + 1 == 5000000 + (negate 5000000 + 1 :: Float) True 
&gt; (Proxy :: Proxy Float) `[] :: [Float]` is shorter to type and you don't have to import `Proxy` for it.
Who can tell me what it would take tot get such a solution into base? It seems like a nice backwards compatible addition. What are the requirements wrt recent ghc's extensions?
&gt;I can see this from a beginner standpoint. I remember trying to do some simple stuff with parsec and hitting walls with the type errors. Doing simple stuff with complicated libraries isn't guaranteed to be "nice." Like I said, I think the added complexity is pretty linear with added capability so I don't see an issue. &gt; There is a lot to learn from elm on making errors more readable and even aesthetically pleasing. &gt;Granted, the expressivity of haskell makes it hard. I think you hit the nail on the head. I can't imagine monadic parser combinators being any easier in elm.
I think this is largely what `Control.Monad.Except` is for.
Not really *that* contrived. This of it as `list ++ listFunctionFunctionThatMayCallThrow args`. `throw` is in too much Haskell code. :/
[removed]
Why shouldn't you use foldl?
Check out this page on the wiki: https://wiki.haskell.org/Foldr_Foldl_Foldl%27 Basically you should always use `foldr` and if not use a package: https://hackage.haskell.org/package/foldl
I'd also be interested in a link to a paper, as I'm not sure what you mean by 'staging' in this context?
1. Hoogle and hayoo are standard tools which are linked everywhere. It's like saying you don't know of cabal or stack. 2. You can use stack to generate your own local hoogle for your project and query it from the command line/editor/repl 3. I haven't run into projects that define so many operators, but one option is just to define an equivalent named function and use that.
Nice talk. Neil mentions this at some point, but it's worth emphasizing that not all space leaks are stack space leaks; ni_mapM_ :: (a -&gt; IO b) -&gt; [a] -&gt; IO () {-# NOINLINE ni_mapM_ #-} ni_mapM_ = mapM_ main :: IO () main = replicateM_ 2 $ ni_mapM_ print [1..1000000] This runs perfectly fine with a 1 kB stack but has a huge space leak. (EDIT: pasted the wrong example. sorry. fixed now.) Personally I often have some integration tests that limit _both_ the stack _and_ the heap to make sure the program runs in the amount of memory I expect it to take. -- Though I've never been brave enough to insist the code runs in 1 kB stack :)
Usually you want `foldr` or `foldl'` but not `foldl`, which is prone to leak space. `ghc` has gotten much better at optimizing away space leaks due to strictness analysis but I consider it unwise to rely on that
'Group' is fine, because it does not clash with with any pervasive existing class (except Num, which everyone agrees to scrap).
Notwithstanding &lt;&gt; vs +, I agree with all your points. I think your package is the one I like the best among 'Num replacements', so if you stabilise it near its current form I'll start using it. Thanks :)
The pretty-print example is rather interesting and subtle. The problem is in this line (https://github.com/haskell/pretty/pull/35) beside (TextBeside t p) g q = TextBeside t $! rest where rest = .. recursive call to beside .. Neil's explanation in the talk is that this evaluates too much of the AST for the document, and while that is true, it doesn't explain why that would result in a _stack_ space leak (after all, the AST is constructed on the heap). But I guess what's going on here is that `besides` now is both too strict _and_ non-tail-recursive, hence causing the _stack_ overflow?
We can have a conversion function that's actually unsafe coerce. Though we could also use a newtype, coerce, and pattern synonyms. Finally, just pattern synonyms for Left/Right could be nice too.
You could check out a little experimental library I built a while ago: https://github.com/boothead/oHm
It's easy to see "static types" in Java, C++, Typescript, etc. and equate them with Haskell's idea of types but please don't make that mistake. Haskell's type system is a different universe all together. I think the best way for you to understand is simply to start reading and writing Haskell. The benefit outweighs the cost.
Here is a list of papers about staging in Scala: https://scala-lms.github.io//publications.html There is also a tutorial: https://scala-lms.github.io/tutorials/index.html Pinging /u/fear-of-flying
Yeah I've been thinking a whole lot about this recently, I haven't been able to nicely incorporate things like partial orders well without having to redo even more of the Prelude
&gt; Are the benefits of Haskell's purity so high that it justifies the inconvenience it forces upon programmers? For me, yes, and indeed now I consider purity a *convenience* not an inconvenience. I'm not sure anyone else can convince you of this. I think it's something you have to have lived experience of. 
&gt; Are the benefits of Haskell's purity so high that it justifies the inconvenience it forces upon programmers? Inconvenience? Functions being pure is good practice in *any* language: how else do you test things? To test an impure function you need to set up the environment in the way it expects, and then clean up after it. To test a pure function, you just call it.
I agree. Purity feels like the natural order of things. Mutability is nothing but an inconvenient and manually laborious performance optimisation that is sometimes necessary. It is crazy to make such performance optimisations the default in a language! Imagine a language without loops because manual loop unrolling is a good performance optimisations enabled by default...
Yes, but it comes at a cost. in terms of what you said let me take 2 examples Raw JS Vs Elm, and Haskell vs Erlang/Elixir and Dialyzer In terms of Elm vs JS (I haven't used PureScript) I would say very much yes, purity is amazing bust most importantly in Elm code you can be sure that 100% of the pathways threw your code are valid and that you have not left out any corner cases. Elm's type system is not the same as Haskells but does take ideas from it. In terms of Haskell vs Elixir or Erlang, It provides some benifits and some costs. This one is I think a bit less of a sure win. Learning Haskell has costs, it is a very powerful language but not an easy one. You can write very solid code in Elixir using dialyzer (assuming you actually put in your CI Chain) and with Testing. I have built some major systems in Erlang and would not hesitate to use it again. Dialyzer is an amazing tool and it can find a lot of strange corner cases. In addition Kostis Sagonis' group at Upsala and NTUA is making Erlang testing an area of active research See this talk from EUC https://www.youtube.com/watch?v=XVOV0KQAf-8 So would I recommend Elm over Raw JS, 100% no contest. Would I recommend Haskell over Erlang or Elixir, well that is a bit more nuanced. Both offer major benefits and some downsides. I would say choosing to do a project in Elixir would be a good choice for many teams as would doing it in Haskell. I would also Point out that this year's keynote at the Erlang User Conference was given by Simon Payton Jones, there is a lot of cross talk between the Haskell and Erlang communities. People such as Keven Hammond, Simon Thompson and John Hugues work in both areas
&gt; I did a proof of concept Vim script for auto-importing modules and symbols using ghc-mod; it's pretty tractable as a problem, I think. I've not had the time to make it function effectively. The hardest problem is actually parsing the source code to determine where to put the import statement, because vim is text, not AST. You might be interested in [hsimport](https://github.com/dan-t/hsimport) and [vim-hsimport](https://github.com/dan-t/vim-hsimport).
&gt; You may be interested in this proposal for import syntax. I think that's a great proposal, thanks for mentioning it! 
I think using `Either` to encode problems is covered by a generalization of boolean blindness (using True/False instead of AccessGranted/AccessDenied). You have implicit "in the programmer's head" or "in the docs" information that the type system is perfectly capable of describing.
&gt; It might surprise me to write a program that fails in PureScript due to strictness, but I don't complain that the language has "type hidden strictness" that caused the failure. The difference is in PureScript, an expression `f b` (function application) can fail (e.g. `True | False | _|_`), but evaluating `f` (`Boolean -&gt; Boolean`) or `b` (`Boolean`) cannot fail. When you have a value `a :: Boolean`, you _really have one_ `True | False`, not what you have in Haskell which is `True | False | _|_`. The only way to get that in Haskell is via `Bool#`, but unboxed types can't be defined by the programmer in standard Haskell. There isn't a substantial difference between this and e.g. C# having implicit null in every object value. Arguably you can say that "people shouldn't use `error` or `null`", but it's better to remove it from the language. PureScript doesn't come with `error` in the `Prelude`, you have to download a package to get something like it.
I left out the type signatures for brevity's sake, you're right that they should be included though.
This is not the type of thing that gets added into base, AFAIK. It adds no new functionality and is just a transparent wrapper around an existing type.
Agreed, and if it really bothers you so much, bind it to a key in your editor for goodness sake. But I really want a shorter alias for `qualified` for a different reason. Now that common IDE/editor tools line up import indentation, the length of the word "qualified" causes those indented imports to line-wrap, making unreadable spaghetti out of my imports. And no, I am not planning on wasting my screen real estate by widening my window greater than 80 characters. I have been spoiled by the power of xmonad.
Make sure also to read the [Trac ticket](https://ghc.haskell.org/trac/ghc/ticket/10478) for the proposal. That's where the bikeshedding is happening.
my understanding was this was deliberate because Right is *not* always the OK value, if you want to stop on first success but continue looking on failure Left/Right are arguably better than Fail/Ok
In my experience, you will want to prefer clock speed. All the cores will come in handy when you compile the dependencies, but you'll spend more time compiling your own project. Given that the 6 cores variant probably runs a faster clock than the 8 cores one, I would go for it.
&gt; Existential Question: How practically useful is Haskell's type-system and Purity? "Useful" is a judgment, and only one person can make a judgment, in this case, _you_. What are your _needs_ and what are the observable things that static types (a la Haskell, Elm, F#, PureScript) and purity offer that satisfy your needs? Do you need good refactoring, code-completion, correct-by-construction, enforcing invariants statically, do you need impure effects and dynamic treatment of values? What are your own personal priorities?
I'll add that many "generic" programming are not possible with dynamic types, or rather difficult. Think about deriving `Show`, `Eq`, `Ord`, `Hasable` for the more common, or `Serialize`, `Functor`, `Foldable`. That's a massive amount of boilerplate which can be removed.
I can't open your link, [this one](https://www.packtpub.com/application-development/haskell-high-performance-programming) works. I didn't read the book but Packt has a reputation for low quality books.
was planning at least 16gb ram (maybe 32) and a M.2 SSD
Well, in dynamic languages, runtime introspection and monkey patching serve the role of instance derivation pretty well. The drawbacks are of course awful performance, complete type unsafety and horrible debugging, but Rails shows that such things are possible.
I live in Bangalore, India. 
I really like Stephen Diehls [similar list](http://dev.stephendiehl.com/hask/) and the [various](https://ocharles.org.uk/blog/) '24 days of' [blog series](http://conscientiousprogrammer.com/blog/2015/11/30/haskell-tidbits-24-days-of-hackage-2015-day-1-introduction-and-stack/) 
I use both Elm and Haskell at work (used to work using Python) and something stands out about strong statically typed pure languages. 1. Programs are easier to read and follow 2. Easier to debug 3. Forces you to account for errors eg. Results from attempting to turn a string into an int. (On a side note, Elm not having type classes makes It an explicit pain in the ass.) I really believe that strong statically typed functional programming is easier to learn than imperative if you were to start there. Alot programmers ( myself included ) tend to over think things making it hard to grasp simple concepts, trust me, functors are easy, monads are easy etc. Also keep in mind if you want to learn how to program functionally you dont need a working knowledge of category theory, though it does make things easier by allowing you to further abstract transformations.
Was planning SSD and 16gb of ram, if I have more budget may invest in a 4k monitor
&gt; No other language uses a 'simple straightforward' string representation, do they? Yeah they do. In imperative languages an array is the most simple straightforward thing. In functional languages a list is the most simple straightforward thing. Also, text and bytestring didn't exist when the prelude was written.
I unfortunately tend to have a lot of display issues with Edward's blog on Chromium/OpenBSD||Linux: http://imgur.com/a/lM9fz 
Whoops, I completely forgot about that angle. I think my confusion stems from `import M as X (y)` being functionally useless - why import something both qualified and unqualified? (Same question with the default explicit-import syntax in your first example.) Anyway, it's simple enough to have a bunch of qualified imports and then some unqualified ones for type names, just a bit warty.
This looks good! Apologies for kicking off the discussion with shameful bikeshedding but, /u/ezyang, any chance we could rename the flag before we head for a release? To my knowledge, "backpack" is just the working name introduced by an old paper to refer to their theory of modules, and will mean very little to new users in a few years time. Couldn't we have a more descriptive and generic naming throughout, say `--make-units` etc?
Fair point. Numeric classes bring out the mathematician in me, but string addition does seem entirely natural.
I had the exact same thought when I read what you quoted. I thoroughly enjoy looking at a function definition and *knowing* -- rather than having to deduce it from the implementation -- that it is a standalone "tool", and that it can never possibly affect any of my other "tools". It occurred to me recently that the `=` operator in traditional programming languages acts like a "store" operation, of sorts, storing the data following the `=` operator at a location with the label preceding the `=` operator. So x = 4 stores the number *4* at the location with the handle **x**. In other words: I cannot reference information directly in eg. Python; I can only store it in a specific location, and then hope that location contains the same information when I want to process it. It's very useful to store stuff at a particular location sometimes, but making this the only way to reference information in a programming language -- by first storing it and then having a handle to the location -- really isn't what I want to be doing when I program. I want to define behaviour, which the compiler then transforms into store/load operations.
Unfortunately, the publisher, Packt publishing, is known for not paying much attention to the quality of their books. Instead, they focus on a high volume of titles, recruiting authors by sending mass emails and hoping that one of them will bite. Apart from that, I can't say anything about the quality of this particular book, I haven't read it or skimmed it.
&gt; calling length on it can crash my system. Calling length on a singly linked list can crash your system in any language! You can easily create a circular singly linked list in C, or JavaScript. Even without any cycles, you will still probably severely degrade your program's performance by carelessly calling `length` on data structures that you receive. You'll probably only do that if you know that `length` is O(1), and that'll be written in the documentation. We don't have any industrial strength languages whose type systems are powerful enough to express complexities yet.
I think regardless of the storage mechanism, imperative languages that aren't C present an API that is clearly different in some ways to that of an array. For example, JS strings have no `map` or `forEach` methods.
&gt; Even learning Java has a cost if you don't know it already. I love how this sentence assumes that it's probably been forced down each one of our throats at some point :)
`base` is massively constrained by backwards compatibility considerations. It's really not that hard to use text or bytestring as appropriate. And with the string-conv library I mentioned above conversions between them are simple.
Looks like the browser is running the text rendering code in parallel ;)
Yeah, thats why `proxy ` is type variable. 
Could you elaborate more on the FRP capabilities of Haskell vs Purescript? What is PS lacking compared to Haskell that got it such a low score?
Left and Right are useful wherever you may want to shortcircuit the computation. In this sense, Left is success and right means nothing worked. Once you learn the general thing, is really annoying to deal with specific things that aren't compatible.
https://www.vacationlabs.com/haskell-internship/
How are they different? 
What does bikeshedding mean? Google didn't help. 
This isn't a very useful list and just reads like blogspam. I would recommend Stephen Diehl's comprehensive explanations and list: http://dev.stephendiehl.com/hask/
For offline usage you can also get the pointfree (and pointful) tool. I've got it integrated into vim too, so I can check on the fly if there's a nice pointfree version of something I'm writing that might be a better solution.
I have dealt with these problems a lot. I now have some wrappers for all inbound data that use [text-icu](https://hackage.haskell.org/package/text-icu). Also there is [charsetdetect-ae](https://github.com/aelve/charsetdetect-ae) for detecting the character set. I have found that people on the web often lie (don't know?) about the character set of their content. Ultimately no matter what language you use it pays to be very defensive when decoding any exterior input. 
Not quite the same, since pattern matching can give alternatives, whereas `head`/`tail` throw exceptions if given empty lists.
&gt; We can have a conversion function that's actually unsafe coerce. That's not enough. If you have a [Either a b] and need an [IsoEither a b], you still have to walk the whole list calling coerce. Throw ContT or polymorphic recursion in there and the problem gets really difficult. I think the new roles system sort of solves things, but it also breaks other things. &gt; Finally, just pattern synonyms for Left/Right could be nice too. I'm fine with that, even if you want them in base. Plus, you can do this today in your own code without having to wait for a change to base.
Just a quick counterquestion: With dependent types it should generally be impossible to determine if a type is finite since figuring that out would basically be the same as checking wether any computation would ever stop(decision Problem)... Right?
That looks like a bad font substitution to me. If you "inspect" a piece of text in Chromium, you can find out which font is actually being used under "Elements" -&gt; "Computed" -&gt; "Rendered Fonts".
I haven't read this book but Packt aren't very well thought of. If you want to learn high performance programming in Haskell, I would highly recommend Parallel &amp; Concurrent Programming in Haskell. It's extremely well written.
Here's a similar question in a different field: Are the benefits of Python so high against plain Fortran that it justifies re-tooling and re-training? At one time, the answer to that question was "clearly not". But a few people did it anyway, and managed to build up a very compelling environment for scientific computing. There was a point at which that answer changed from "no" to "yes", as Python grew an ecosystem that matched Fortran's while Fortran continued to be a fundamentally inferior programming language to Python. To a degree, this was the wrong thing to do. Yes, Python is a much more pleasant and expressive language than Fortran, and has lots of other advantages as well. But if you just wanted to get stuff done, Fortran was the way to go, because of the ecosystem that had been built up there. By being stubborn and persistent, the Python folks essentially created the world they wanted, and are now enjoying the benefits. I see Haskell vs. Ruby, Elm vs. Flow, etc. as a bit of the same thing, only not as far along. The advantages of Ruby/Flow/Java/C# lie in their ecosystem; the advantages of Haskell/Elm/OCaml lie in their fundamental structure. The question is whether the new functional camp can build up an ecosystem like Python did. Of course, maybe you don't believe that Haskell is better than Ruby in its design and structure, in which case we have a different debate. But your question just assumes the structural superiority of the functional approach, so it sounds like that's not the debate you're having. It might sound a little condescending to ask whether you want to be a leader or a follower, but there's something to be said for just getting practical things done. In that case, sticking to Ruby and Flow might be the right choice. But if you want to be a leader, you have to take a risk, be less efficient, perhaps suffer a little bit, in order to create the world as you think it should be. 
I'll do you one better. You should have tests in Haskell! Haskell's testing ecosystem is powerful, quick check is absurdly great and value semantics make testing assertions a joy.
&gt; There isn't a substantial difference between this and e.g. C# having implicit null in every object value. I actually believe it is substantially different. Bottom isn't a value, so you can't reasonably use it's presence to drive program flow. Null is a value and often a very useful one, especially in an imperative context. But, for once I would like to find a Pacman-complete language that prides itself on safety that doesn't also expose the unsafe primitives (Haskell: undefined, Idris: believe_me, Lean: sorry, etc.) in the base packages. I honestly want a language that says: "No programmer's escape hatches here or in the compiler. You are either going to follow the logic of the language or you are going to write in a different one, but we are going to be a consistent logic!"
Do you have Gentium Basic installed locally? If so, it _seems_ to have fixed itself for me when I removed it (but kept Gentium Plus, which is the same font with better character coverage and, more relevantly for this problem, a different name). ^(Sorry for the disappointing workaround)
on the other hand "Type safe but don't use it " has problems all its own
&gt; length on a singly linked list can crash your system in any language! You can easily create a circular singly linked list in C, or JavaScript Yes it is true you can mess with anything if you try, Except in those languages it's very rare that it will happen to you where as it's very easy to have happen in haskell. And here I am not referring to just length of lists.... Have an element in a list that's undefined?? crash.. foldl on a list?? woops space leak. My point is just that whether or not something is lazy/eager is almost two differnet types, for instance calling length on a strict list is totally fine.
Three people independently thought of firing on the publisher without having even opened the book. I have at least read the few freely-available sections and enjoyed the hands-on (GHCi) discussion on lazy evaluation.
The first type systems I worked with were in Pascal and C, and they felt really like me helping the compiler know how to store the bits. Considering the compilers of the time that was needed. Todays better ML Family languages (Including Haskell, OCaml, F# and others) the types are really about proving the program is correct. So you have the ability to enforce all sorts of invariants on your code at a type level that might require testing. The key point is that when Java says "types" and when Haskell says types they are talking about two very different things. When talking about different type systems you have to be very careful as they often mean very different things, and check for very different properties Of course you can also go look at Idris or Agda to see how far it can be pushed. 
Haskell (and most other ML derived languages) have Algebraic Data Types and pattern matching. This alone is a huge win over the "static types" on Java and C++. They help make "Illegal types unrepresentable in the type system" (to quote Yaron Minsky of Jane Street Capital).
This is great, thanks for the pointer. But it doesn't solve the problem of similar bugs in other libraries, does it? I'm less worried about my code, but more about the numerous libraries that I use. I don't think it is possible to enforce SafeInt on all the packages that are being build (by cabal or nix). That is why I'm looking for a compiler flag (or any other generic solution), so that I can enforce it on the whole environment.
One simple difference is how easy it is to create new types and do operations on them. A common example is encoding either 1 or 0 instances of a value and then pattern match to make sure you handle all cases. Units of measurement is another. Haskell makes it very easy to create and use these types so you will use them. You can read more abou those [here](https://en.m.wikibooks.org/wiki/Haskell/Type_declarations).
Besides the language, what in the world of programming interests you?
&gt; Have an element in a list that's undefined?? crash.. If an element of your list is bottom, lazy evaluation at worst delays the crash. With strict evaluation, you'd have crashed earlier. Then you can say crashing earlier is better for debugging, but I'd argue that "earliness" isn't that meaningful when your program is defined by immutable data. &gt; My point is just that whether or not something is lazy/eager is almost two differnet types, I see that the topic of expressing strictness in the type comes up often, but then someone much more knowledgeable than me comes around and points that the strictness of a data structure is much more complicated than it first appears. So, if you have a strict list, how strict is it? Is it strict in the spine? Or is it deeply strict? Maybe it's strict in the prime number of elements, as in if you evaluate the 3rd element, all the elements until the next prime number will be evaluated as well. 
[removed]
Well, the ghc --backpack mode doesn't really matter for anything real: it's just an easy way to write examples but not the way you will ever actually interact with GHC for real development. But the term backpack does show up in the Cabal syntax `backpack-includes` so I suppose the bikeshed point is valid. Unfortunately my stubbornness is showing through a little here: I've been asked to come up with a new name for my design since it has diverged from the POPL'14 paper, but I happen to like the Backpack name, we're not really *that* different, and we never really came up with a good other name. The term "unit" too has a torturous history: in fact in our (rejected) ICFP submission we expunged every mention of the term unit in preference for the more descriptive (but longer) "linked component"; but kept the naming in the implementation because having a short name for a Backpack-y thing was nice. If we were to rename `ghc --backpack` it would also make sense to rename the file extension. But I have little clue what a better extension would be. I *am* pretty unhappy with *backpack-includes* so suggestions solicited.
In your function or functions that actually do something with the current time, you can take the current time as a parameter of type `UTCTime`. Or you can take a parameter of type `IO UTCTime` that *provides* the "current" time.
Can someone tell me how this is different to having a typeclass for the types you want to parametrize over? When would someone use this?
&gt; There is currently no text in this page. You can search for this page title in other pages, or search the related logs, but you do not have permission to create this page.
I’m still waiting for the HIW videos. I hope their recording worked.
https://github.com/ezyang/ghc-proposals/blob/backpack/proposals/0000-backpack.rst#motivation lays out the situations where type classes don't work well.
I have wondered about the same. I have even expressed my concerns [here in /r/haskell](https://www.reddit.com/r/haskell/comments/4v6nff/a_founders_perspective_on_4_years_with_haskell/d5vym01). Similar to your experience, some people seemed offended a bit, and my comment was immediately downvoted. I think a lot of people like you and me come from a dynamically type/loose typed programming background to Haskell, and gets impressed by it. But in my case, after a while, I recognized, that what I was mostly attracted was three things. 1. static typing. That I can refactor with confidence with the help from typechecker. 2. concise syntax. 3. ability to use functional constructs (like map, fold, zip etc) After a while, I started learning Rust. And I felt the same amount of confidence writing programs as I felt when building with Haskell. So in the end, what I felt is that there is a certain, solid advantage, an advantage worthy of the trade off in most cases, when you come from a dynamic language to a statically typed language. But when you move from something with modern static type system (like Rust) or a dynamic one with a great static checker (like Elixir) to something like Haskell, the advantages are, let us say, a bit hazy, and might not be worth the trade offs *for most cases*. I would be extremely happy if someone/something can change my mind.... 
Now this is the premium content I signed up for!
Please contribute to [snowdrift.coop](https://snowdrift.coop/how-it-works).
&gt; Is IsoEither a newtype of Either? Probably not, since the normal reasons for doing this is to rename the constructors. So, it would be something like `data IsoEither a b = Error a | Ok b`. Producing a witness for the isomorphism is left as an exercise for the reader.
&gt; Hendly Milner inference [Hindley–Milner](https://en.wikipedia.org/wiki/Hindley%E2%80%93Milner_type_system) IIRC, the Haskell report doesn't require Algorithm W but it does require bidirectional inference. GHC uses [OutsideIn(System F_c)](https://www.microsoft.com/en-us/research/publication/outsideinx-modular-type-inference-with-local-assumptions/) since Algorithm W doesn't cover type classes or GADTs.
I'm afraid I still don't really see it. As far as I can tell it's maybe a bit better type inference and some import convenience. What's the major problem here that justifies, what seems to be, a whole new way of writing Haskell code?
Indeed, it does not. And I think people are turned off by the thought that there might be a performance impact over using the native `Int` operations, so I don't think `safeint` is very popular. A compiler flag (a la Rust?) would be nice.
`.bkp` is NOT the recommended way of using Backpack at all, just to be clear. It's really just a convenient method to test it all in one place, and for showing "complete demonstrations" IIRC (e.g. we want to have 10, 20, 30+ tests in GHC itself; having multiple packages for each would be huge amounts of work). Fundamentally, *real* usage of Backpack needs support of the build tool and Cabal, and real world usage of it will require that. It'll all be in `.hs` and `.cabal` files, in 100% of cases.
tl;dr: The big sell of Haskell is that you get a language that has a nice set of qualities: 1. Expressiveness between Ruby and Lisp 2. Performance between Java and C 3. Safer code than Java/C# 4. Easier to refactor/maintain than, well, anything Does Java/C# have better tooling? Yes. Is Ruby more convenient? Yes. Is Lisp more expressive? Yes. Is C++ faster? Yes. But nothing is easier to maintain, and Haskell does better than it's competitors in most aspects. &gt; Last night I chanced upon a Medium post titled The Shocking Secret About Static Types. Then, I went on to skim the "research" that it linked to. Then more stuff on Quora. Then Stackoverflow. I'd be *very* wary of any "research" on programmer productivity. Most of it is garbage with tiny sample sizes and untrained populations. I don't care how someone does after 1 week of TDD training; I care how a professional that uses TDD for years does. Same with Haskell (or more!) style static types. &gt; But, would I be feeling the same way if we were using "static analysis" tools on our code anyway. I spent a year doing Rails development, and now have a bit over a year doing professional Haskell development. The best static analysis tools for Ruby/PHP pale in comparison to GHC, and when you flip `-Wall` on, there's no contest. Given that there are even more (and better) static analysis tools available and possible for Haskell, it's kinda silly to even compare. &gt; Are the benefits of Elm (or Purescript) so high against plain JS+Flow that it justifies re-tooling and re-training? If you've already [made JS work for you](http://blog.jenkster.com/2015/06/javascript-the-collection-of-parts.html), then it might not seem like a good sell. But if you're looking at Elm/PureScript or JS+Flow+Babel+Immutable.js+etc. then the purpose-built solutions start to look a lot nicer. If I were given a front end project, I'd use PureScript since the FFI is great and the ps-react ecosystem is pretty good. &gt; Are the benefits of Haskell (or OCaml) so high, compared to Elixir+Dialyzer that it justifies switching to a language that is wildly different from Ruby? (Given that our team is comfortable with Ruby). Elixir is syntactically similar to Ruby, but that's about where the similarities end. Learning syntax is easy; it's the semantics that hurt, and I've found similar syntax to fool me into a false sense of complacency where I **should** be feeling confusion and ignorance (and then remedying that by learning). &gt; Are the benefits of Haskell's refactoring so high, compared to Java or C#, that is justifies switching to an ecosystem with poor tooling/IDE support? Isn't the refactoring story same in all statically typed languages, with Haskell probably being poorer because of immature tooling? Haskell's expressivity and productivity is *much* better than Java or C#, such that the lack of tooling isn't a significant obstacle for development. &gt; Are the benefits of Haskell's purity so high that it justifies the inconvenience it forces upon programmers? (Really, who fires nukes in a function called computeInvoiceTotal anyway?) So we were debugging a performance problem in our PHP app at work, and it turns out that a pretty innocuous method ended up calling another innocuous method, which .... well, you get the story, until eventually we had a call to a seemingly innocently named function which queried the database. Which do you think is easier to debug: "Huh, why is `def computeInvoiceTotal` slow?" vs "Huh, why is `computeInvoiceTotal :: MonadDatabse m =&gt; Invoice -&gt; m Money` slow?" &gt; I'm not trying to criticise or trivialise Haskell in any way. Just late night wonderings. These are definitely valid concerns, and to some extent, you just need experience to see how they pan out.
any special video recommendations?
Hi, if you want you can try your hand here: https://github.com/blender/Rome/issues . I believe the project to be fairly suitable for beginners.
This is actually a really interesting topic! thanks!
Thanks for the background. Ok so let's start here: what does `backpack-includes` *mean*? Is *a* backpack some entity that can be defined to the user? Or is `backpack-includes` really talking about units? Is that field always of the form `pkg (Mod1 as Mod2)`? In that case, would calling it `module-aliases` make sense? If not, `unit-includes` sounds better to me than `backpack-includes` provide that a "unit" is a defined entity for the user. I think it's fair enough to call the theory Backpack, Backpack', Backpack 2.0 or whatever. But that's not to users ought to see that. In principle, users will never have to even know about the theory as published in the papers.
Honestly, it should really have been `import Data.Map as Map`. I have never used or *seen* anyone use `as` without `qualified` except that one time when I was too lazy to refactor some code, and that was clearly an abuse... There are edge cases where it's useful, to be sure, but I think the default 99% of the time is that `as` goes together with `qualified` and that's what should be the easiest thing to do.
Since these unit description files are pretty rare anyways, and that the syntax seems to be some superset of Haskell syntax, how about a verbose but evocative file extension like .hs-unit?
Yes, sometimes people use byte arrays for ascii data. That's true in any language, and is the point. String vs Text is a unique haskell problem. Unicode strings (String/Text) and byte arrays (ByteString) both existing is the normal situation, most languages have this. Those that don't are merely lacking unicode support.
I set it up like this: * `common/` contains my common package with API components, data types, etc that are shared between frontend and backend. This is just a normal Haskell package with a `.cabal` file and everything. There is *no* `stack.yaml` in this folder. * `backend/` contains the backend code that will be compiled with GHC. In `stack.yaml`, I include the packages I have in `backend/` but I also include `../common` as a package and use that as a dependency in the backend packages' `.cabal` files. Then, whenever the backend is built with GHC, the common package will be built too. * The `frontend/` directory contains everything built with GHCJS. This setup is exactly the same as the backend: just include `../common` in the `stack.yaml` file. In summary: make a package called `common` with no `stack.yaml`. Have a `stack.yaml` file in each of the backend and frontend. Just include `../common` in both `stack.yaml` files. Then, a simple build script is just two lines: stack --stack-yaml=frontend/stack.yaml build stack --stack-yaml=backend/stack.yaml build If you need the JS bundle from the frontend before building the backend, use this (replace `dist/bundle.js` with whatever you need): cp "$(stack path --local-install-root)/bin/main.jsexe/all.js" dist/bundle.js
&gt; Are the benefits of Elm (or Purescript) so high against plain JS+Flow that it justifies re-tooling and re-training? Yes. Not only does Haskell's restrictiveness improve your code, but it also improves *everybody else's code* that you depend on. I trust Haskell dependencies much more than I do Javascript/Ruby/Python dependencies for exactly this reason.
unionization is definitely not the way to go, might as well just give everyone a basic wage at that point. I work in a software union shop, people can't wait to jump to the union side so their days become full of vacation and relaxation. There's actually a rule where you can't wake someone from slumber abruptly.
Waking up to someone having implemented your design/desire, without any communication, must feel sweet and pretty surreal. 
I had about the same experience myself. Being quite a newbie in Haskell (but already got to the point where I **use** rather than am afraid of monadic computatons), I tried to write a simple chat bot. This required sending a few http requests, parsing json, doing some work based on it, etc. And when after about an hour of incremental and interesting conversation with a compiler I got it immediately working as I intended - that was a wow moment indeed :)
Maybe `hs-includes`? (Like `hs-source-dirs`). We're "including" haskell source files.
Ah good. This is actually very reassuring - I look forward to the issue being resolved, even if it takes a few years. Great work on Backpack BTW.
- `rosetta`: common types, JSON de/ser stuff. We don't put ToJSON instances on datatypes which contain anything the frontend shouldn't see. We _try_ to keep database and API (JSON) types separate. Often the types intended for sharing are denormalizing the database representation. - `hestia`: backend (Yesod) app - `hestia-fe`: frontend app (Servant + GHCJS + React) Separate `stack.yaml`s for frontend and backend. We build the frontend app and symlink the `jsexe` assets into `hestia`'s static directory. The `stack.yaml` for the frontend app won't be of any use to you, we use a patched version of GHCJS because PRs aren't getting merged. (PR's still sitting there)
Beautiful, absolutely stunning.
Asking this is like asking "how does salt taste differently from sugar". Here's an indicator of how large the difference is: in languages with rich type systems, programmers tend to use debuggers only exceptionally. Even when they are available (such as in F#).
You have been given plenty of productive responses. And this kind of question gets tiresome after the 1000th time. Pretty much all of us have concluded that it absolutely is worth it else we would not be using Haskell. Which is not to say that such questions should be banned, but understand that not everyone has the time or desire to answer it or even see it cluttering up the front page. You don't see these questions very often on other programming language subs, and they probably would be received substantially worse there than yours was here.
I use GHCi for 'debugging purposes' sort of. I write tiny functions (I dislike anything that uses more than 5 lines per pattern matched, and even 5 is pushing it) and check that each works exactly as expected in GHCi before using them in any other functions. I also try to avoid changing existing functions after a day or two (and thus all of the considerations that went into making them are fading from memory), instead writing new ones, and renaming when they work reliably. I rarely have anything to actually debug later on, and it's almost always where I've taken a shortcut that I know might bite me later on. I'm working on taking those less.
Yeah, I guess that's why my title was probably a little over-enthusiastic. :P
Is this really such a huge problem for you? I find it to be just a minor annoyance. Certainly records are higher on my list.
&gt;You have been given plenty of productive responses... I have noticed that these kinds of questions trigger an initial barrage of quick down votes, but often level up eventually, as cooler heads come across the post. &gt;And this kind of question gets tiresome after the 1000th time. &gt;but understand that not everyone has the time or desire to answer it or even see it cluttering up the front page. Haven't noticed these kinds of posts that often. What are you taking about? And should the front page of a sub be only filled with posts that sing praises? I have seen posts that just sing praises, and nothing else, cluttering the front page with no one even batting an eye....And no one is obliged to answer these posts. just let someone else with time and desire to do it. &gt;You don't see these questions very often on other programming language subs, and they probably would be received substantially worse there than yours was here. The only programming sub I have seen this kind of knee jerk behavior is, sadly, /r/php. I would imagine that anywhere there is a large subset of users who hold blind beliefs about anything, gets triggered when those are questioned by posts such as these. And the initial responses are often kind of passive aggressive. I am not saying that everyone here is like that.
Are the Haskell Symposium lightning talks going to be uploaded? How will I know when to check for `null` pointers otherwise?
It would even help if `qualified` came _after_ the module name, so we didn't have people contorting their import lists to align non-qualified and qualified imports.
The way he solved those lemmas by just jamming `%runElab mush` on each line was amazing.
Agreed, and while I can definitely appreciate clean abstractions for their own sake, is there also a practical path here? An eventual reworking of the numeric tower in base?
It would be useful to know what platform you are running your code on. Is your code x86-64? Are you running on Windows? Which XMM registers are getting clobbered that you did *not* expect? My understanding is *some* of the XMM registers are used for passing arguments, hence those XMM registers are not preserved by the callee. For Microsoft's calling convention however, XMM6 and XMM7 do need to be preserved by the callee. Are those getting clobbered by Haskell? You might find these links useful: - https://en.wikipedia.org/wiki/X86_calling_conventions#x86-64_calling_conventions - https://msdn.microsoft.com/en-us/library/ms235286.aspx - http://wiki.osdev.org/System_V_ABI
you could `flip f` to make it put the biggest one first.
I guess the "1000th time" was more aimed at the programming community as a whole, less so /r/Haskell specifically. Although if these posts do come up decently frequently. There are tons of posts all over the Internet doubting Haskell and asking if it is actually worth it. No Haskell's front page should not be posts singing praises. They should be posts about interesting advancements and questions about the language that generally shouldn't be overzealous with praise unless it is perhaps at a very specific cool feature they discovered and want to share. They also shouldn't be "is Haskell even worth it".
Plenty of rules already do that. In fact there are rules that change the termination behavior of programs: main = print . V.take 4 $ V.fromList [1 ..] Compile that with `GHC` and compare it to what you get if you paste it into `GHCi`.
The best bit is with a little care about imports and a few "#ifdef __GHCJS__" lines, you can have intero work nicely with all of your code.
&gt; should the front page of a sub be only filled with posts that sing praises? There was a month or two a while ago where every second post was "why Haskell sucks". At some point it just became annoying.
Following on from this, has anyone done anything similar with shake (maybe using stack underneath for building)? You quickly end up with non trivial build process and it would be nice to be able to manage this better.
It looks like it's a bug in the most recent nightly. Paging /u/hvr_ WORKAROUND: install ghc-head-dyn
Thanks, full credit to Mike (the subhask author) for that - I just cut and pasted it out. I'm exploring the design space mostly, and base is something you like have to plan 5 years out - happy to help out if others want to try for that. An interesting proof of concept in this is that subhask has a much broader range of what a category is, compared to our Hask, but the same interface worked with both - so a numeric tower is independent of category choice it seems. It's a nice property to sit back and really think about - plug-n-play categories. In practice, the library has to use the Data.Semigroup and Data.Monoid in base to have a chance at usage. And then find a way to supply highly-performant and probably mutable instances. I would expect that heavy-duty numerics in haskell will pretty much evolve towards spitting out code not numbers (accelerate and plover are examples already). In summary, I see a practical path being finding and locking onto the right interface between base and the tower, ironing out the kinks in the heirarchy, writing instances for Vector and Matrix, and creation of a new Num for legacy code replacement. However practical, it may not be possible, however, from the point of view of using the current base Semigroup and Monoid. If it is possible, I'm interested in exposing the laws to the agda crew to prove (or similar). 
Yes, my assumption was its the non-tail-recursive bit that blows the stack. I didn't really seek to understand it though, just fix it. 
Sure I have signed up. Waiting for someone to comeback on the projects I can work. 
Please report this on the bug tracker (https://ghc.haskell.org/trac/ghc/newticket) with a simple reproducing example if possible. 
What type classes can do but backpack cannot? For example, is it possible to replace Function, Applicative, Monad classes with backpack?
Root directory has `stack.yaml`, which describes regular build (native), while subdirectory has a `stack.yaml` and a project which is GHCJS-based, which uses others as a libraries from `../lib-foo` and `../lib-bar`.
I did something like that with nix here: https://github.com/boothead/ohm-examples In the server package I have the snap exe and the library exports its types to ghcjs: https://github.com/boothead/ohm-examples/blob/master/ohm-chat-server/ohm-chat-server.cabal Library exposed-modules: ChatTypes build-depends: aeson, base, containers, text if impl(ghcjs) build-depends: ghcjs-base ghc-options: -Wall -O2 -threaded default-language: Haskell2010 
The wording of the names don't have much to do with it. It's the types and the degree to which they permit doing case analysis (aka introducing complexity) within the function: whether to be polymorphic (no casing: `reverse :: [a] -&gt; [a]`), type-class polymorphic (indirect casing: `sort :: Ord a =&gt; [a] -&gt; [a]`) or monomorphic (direct casing: `lowercase :: [Char] -&gt; [Char]`). I think the article doesn't work very well as a whole because of the initial premise.
tl;dr: Using descriptive variable names is a clue that your types are much less general than they could be. This lack of polymorphism means that your functions can do just about anything with their input, and looking at the types does not give much information about what they're actually supposed to do. Writing polymorphic code is thus considered good practice, not only because of reusability but also for correctness and documentation purposes. It is similar to the OOP mantra of writing code "against the least powerful interface".
Good article, bad title maybe?
I'd recommend you to buy a mainboard that can plug at least 64 GB of RAM. Then you can start with one 16 GB plugged in, and upgrade over time for very cheap. RAM is the first thing you will run out of, especially if you'll load multiple instances of big projects into ghci.
I think the causations are "overly specific code" =&gt; "descriptive variable names" "overly specific code" =&gt; "increased chance of bugs" To conclude that "descriptive variable names" are associated with "increased chance of bugs is somewhat tenuous"
We ([beautifuldestinations](https://www.instagram.com/beautifuldestinations/)) are doing this in a couple of our apps. It's a bit icky, but roughly: We have three sets of modules: * `frontend/` * `lib/` * `server/` ghcjs stuff is frontend+lib; server side stuff is server+lib. We have a different `stack.yaml` file for each of the above two platforms, ghcjs and ghc. In one project, (for historical reasons) they live in separate directories; and in another project, we have `stack-ghc.yaml` and `stack-ghcjs.yaml` in the same directory and use stack's `--stack-yaml=` parameter. I prefer the latter style. The output of ghcjs needs some non-trivial postprocessing (js optimisation, for example) and we use a Makefile and shake to drive this. The reasons for preferring shake over Make are orthogonal to using ghcjs. Within `lib/` we have a multitude of sins wrapped in `#ifdef` statements. A bunch are accidents of history, due to these being separate repositories for frontend and backend that were merged and haven't been tidied up. The most fundamental, though, is the good old "how do we represent text strings?" where on the browser side we use `JSString` and on the server side we use `Text`. We swap this per-platform using `#ifdef` (although I suspect with re-factoring, a `type` alias would be fine, and the need for `#ifdef` is again an accident of history). So I suspect we can get away without `#ifdefs` with some effort. For communication between the two, we have tried a couple of different (HTTP based) approaches - one is an "explicitly named HTTP endpoints" approach, and another that looks like a "passing Haskell structures between the two halves" approach (that happens to use Generics/Aeson as a transfer format). The second approach appeared when we took the view that we were running the same program distributed between two runtimes, rather than talking about a "frontend" progam and a "backend" program. Amusingly to me, `Setup.hs` runs inside node.js and so to call out to unix to run other setup shell commands, you need to write javascript FFI.
This does clear it up a bit but I'm still wondering if this isn't the same thing as saying "Ok guys. Orphan instances are ok now." What's the practical difference between the user choosing the interface implementations and the user adding an extra package to his dependencies that provides some orphan instances?
Well, if you move from `f :: String -&gt; String` to `f :: a -&gt; b`, I'd say you're less likely to name your function's argument `str` (of course, this is a stupid example, but I guess the point is clear). So we also have the following, equivalent causations: "suitably specific code" =&gt; "nondescriptive variable names" "descriptive variable names" =&gt; "overly specific code". In other words, your first causation goes both ways, and descriptive variable names probably mean you have an increased change of bugs. 
Oh, that's of course true. Feel free to replace "overly specific" by "monomorphic", if you like. Note that I am not a big fan of the "code smell" concept. I believe each coding practice should be judged in context, and I actually think variable names were a poor starting point for this article. I get the idea, but I fear the only thing beginners will take out of it is "use letters instead of descriptive names". When your code cannot be made any more polymorphic, descriptive names are /definetely/ better !
Now, we can have a mirage os in Haskell thanks to this work. Using functors in OCAML is critical there.
TL;DR: The functional languages and C++ did better than the OOP languages. But all languages have moved on since 2005.
&gt;that it is a standalone "tool", and that it can never possibly affect any of my other "tools"... But, really, do you need the help from a compiler for that. What are the chances that in a 'normal' imperative language (anything with static typing) that one function may mess with the local scope of another function, or one function may accidentally access a global variable, when it meant to refer to a local one, with out having to go explicitly out of your way to make that happen? I think very little.
How about an alternative prelude that made safer/more correct functions available by default and had a bunch of these less-academic aliases? I can see why you wouldn't want to put this kind of thing in base, but having a curated set of aliases available with a single line would be a lot more beginner-friendly than expecting everyone to define this in their own project.
Modules can be renamed, instances can't. Another difference is that orphan instances still need to be linked with the typeclass declaration in the package it's declared in, while modules don't; the determination on whether modules satisfy a signature is determined by the client, so the implementation is further decoupled from other packages.
But it has some sort of function overloading. From the article `null :: Str -&gt; Bool` works for `String` and `ByteString`.
What do you mean?
I do the same, but named the server and client `stack.yaml` files `server-stack.yaml` and `client-stack.yaml`, because I think Intero would sometimes be confused if they were named stack.yaml. I might be wrong about that and/or it might no longer be the case.
The example in the article showed implementations using different types, which resolves fine for typeclasses, but modules can have different implementations using the same type. You can't have two instances of, for example `Regex String` if we were using typeclasses, but you can have two modules that define `Str` as `String` because modules can be renamed and you can specify which module whose implementation you want using the appropriate name.
This conclusion in this article is complete rubbish. Yes, it is true that functions should be as general as possible. No, no example in the article is "real world" in any meaningful sense. In real world code, there is a lot of code that interacts with the real world. That code is monomorphic. That code needs descriptive variable names. Interacting with the real world is not a code smell. Interacting with the real world using `a`, `b`, and `c` as variable names is a code smell.
Yes, if you need specific implementation. But if you don't I think you can do import Regex foo :: Reg -&gt; Str -&gt; Bool foo x y = accept x y 
WRT Haste.App, the "spaghetti code" feeling is somewhat justified, in that the `App` monad is really not nice to work with. There's some work in the pipeline to fix that (or rather, rework the whole thing) though, so while perhaps not mature, soon it will at least be new and shiny again. :)
What role does Servant play in the frontend (since you already seem to be using Yesod for the backend) ?
[removed]
Can you really make an argument that string addition makes any more sense than string multiplication though? Doesn't this just seem like it makes sense cause we're used to it?
[this](https://www.youtube.com/watch?v=gQmDeq9eyF8&amp;list=PLnqUlCo055hX8RkgLEjBYnETx6NuiL756&amp;index=7) seems to be the right link for the title.
More specifically, type-based dispatch. You have to set up all of the instantiation yourself, whereas typeclasses will *generate code for you* based on the types in question. You could Backpackify Functor/Applicative/Monad. But I don't think you'd want to. Use a type class.
Now I see, thanks. So, for Functor It would be something like Maybe.map, List.map if they are in same module. Not great.
Great to hear ! I'm eager to see your next release and won't pass the occasion to give it a try :)
A large part of what you're describing is the [`Show`](http://hackage.haskell.org/package/base-4.9.0.0/docs/Prelude.html#t:Show) and [`Read`](http://hackage.haskell.org/package/base-4.9.0.0/docs/Prelude.html#t:Read) typeclasses, which already exist in the Prelude. show "abcd" &gt; "abcd" x = Just 5 show x &gt; Just 5 You can effectively "run" a `String` by typing: read "Just 5" :: Maybe Int &gt; Just 5
Yeah, that's how it is. The upside is that you can have more than one implementation for the same type, assuming that makes sense e.g. Monoid for Ints using `mappend = (+); mempty = 0` for one implementation and `mappend = (*); mempty = 1` for the another. 
Serializing a closure in the way that you describe breaks referential transparency. From your example: serialize $ map (+1) &gt; map (+1) But what should I get if I do this: let foo = map (+1) serialize foo Would you expect to see `map (+1)` or `foo`?
` map (+1)` or let foo = map (+1) serialize foo but definitely not ` foo` Is that a problem?
But now you can distinguish between two values that denote the same thing; meaning that you can actively choose to execute one path based on if the input is `foo` and another if the input is `map (+1)`. But then, if you substitute `foo` for `map (+1)` in your program, or vice versa -- your program semantics have changed. More generally, being able to distinguish `f(x)` from `y` for any case of `f(x) = y` destroys this property[1]. Doing this also requires some notion of function equality, which is its own can of worms aside from breaking all this. FWIW, doing this is absolutely possible, just not theoretically nice at all (and that does have some practical impact). Mu Haskell can do this for example, and can serialize any value, including function types, and deserialize them later. But Mu also doesn't care a great deal about the semantics for that feature, or anything. So if it behaves weirdly or doesn't abide by the properties you expect (like "functions that are equal" have sensible equality rules), that's just "the way it is" and you can't do much about it. [1] OK, so `seq` also is problematic here, but we typically just don't consider it very much in the semantics. I'd say function equality, etc is a much bigger can of worms than `seq`, but I suppose it's a matter of degree.
Not yet. There is no big implementation but it is being evaluated. So technically it is not production ready. But this is not fair. First, to achieve the level of programming and flexibility that transient bring out of the box you would need a lot of in-house developments and integrations that definitively would need a lot of effort and testing. On the other side, most of what transient offer is beyond web programming. Some companies are evaluating it for needs in which the Web is only an element in the equation. Creating an haskell infrastructure from scratch need much more effort and knowledge that in other languages. I'm helping enthusiast companies that enter in the Haskell language to reduce the gap by bringing them a coherent base for remote communications, streaming, distributed computing AND web programming among others, and at the same time I evolve and mature the platform to match the requirements of real usage cases. I think that this assures a long term success rather than a short fame. Because transient Is here to stay. It runs the algebra for which the business applications were crying for. No kidding. 
[removed]
Haskell's purity and its type system are easily my favourite features about it. Laziness is excellent for creating abstractions (it has myriad downsides, although I think it's worth them) but frankly I can take it or leave it. I don't like them for their ability to rule out entire classes of bugs, although that is extremely nice, I like them because they force people to create abstractions which turn out to be vastly superior (in terms of developer ergonomics and code reuse, the main two things I look for in a language) to the more straightforward alternatives. Purity means that to manage side-effectful calculations you need to use monads, but they turn out to be a brilliant abstraction for imperative programming in general and allow you to structure your program as a series of DSLs. Plus, purity leads to referential transparency (although I suspect it is possible to have purity without referential transparency), which makes it completely trivial to extract portions of a function into a seperate helper function. The type system means you essentially never need to code defensively - your code Just Works. It takes a while to get used to, but when you are it's intoxicating and programming in other languages feels inherently messier.
&gt; It must be possible to serialize any object, thus it can't be a type-class That doesn't sound very Haskelly at all. Most languages allow you to check whether any two values are equal, and to convert any value to a string, but Haskell chose to have `Eq` and `Show` type classes even for those very basic operations. So no, you can't have universal serialization in Haskell, pretty or not. You do have [`Serializable`](https://hackage.haskell.org/package/distributed-process-0.6.1/docs/Control-Distributed-Process-Serializable.html) though, and it even supports [(static) functions](http://haskell-distributed.github.io/tutorials/1ch.html#spawning-remote-processes)!
At runtime, values are always monomorphic. So if you specify that it must implement `Show`, then you can always call `show` on a value, even if you the programmer don't know what type the value will be.
After little bit of thinking, I have to agree with you. It should be typeclass like any other. ( But definitely other but `Show` )
Is `evaluate` the only thing you can do to a serialized value? Or can you, for example, save it to a file and display the serialized value to the user? I assume so, otherwise you wouldn't ask to make it pretty. But then if you can do that, it means you can examine the resulting string and do something different depending on whether the serialized value begins with `'f'` or not. Note that being able to do something different depending on that was only a problem when you wanted universal serialization. Now that you have come to accept that a type class will be required, the fact that we can examine the first character of the serialized value is totally fine, because the type class constraint says that you're allowed to do so.
Thought the point of asm.js was to be way faster than hand rolled js.
But you're not *only* evaluating those functions anymore. You can now also necessarily do things like compare them for equality. Function evaluation is only "one of" the things you care about now. You could absolutely deserialize the two serialized functions terms, and *not* evaluate the resulting, deserialized function -- but instead take two program paths, based on whether the function you deserialized had the name "foo" or not. If you have the function `foo = map (+1)`, then it works. If you instead serialize `map (+1)` and then try to read it back, it would fail, because it doesn't have the name "foo". But `map (+1)` and `foo` *are* the same thing. And if they're the same thing, but I pass them both to a function, and get two different results based on the argument -- then it's not referentially transparent. Once you bring general function equality into the question, you can no longer "just" evaluate functions. You can necessarily *change* evaluation by inspecting them, even if they are denotationally equivalent. This is the same reason `seq` is problematic, because it allows you to tell the difference between `undefined :: a -&gt; a` and `(\x -&gt; undefined) :: a -&gt; a`, even though you should not be able to (they have the same type and are otherwise equivalent, and this is not possible to detect). Traditionally, when we talk about Haskell semantics, we ignore `seq` for this reason (we sort of "quotient out" the relevant terms that are not `bottom`, and only care about those), because it ruins your ability to say "These two things are equal", when you can in fact distinguish them.
I wonder if (for some cases) backpack could be an alternative to the mtl-style approach of abstracting monad stacks.
i thought it was more for convenience of porting stuff already built to browser; re-use sort of
I really should comment more. Type aliasing would definitely help readability. Thank you for the feedback! 
I don't think they are talking about hand written asm.js code.
It's the software that goes inside the microcontroller of a keyboard, currently an ATmega32U4. Its job is to read the switch state matrix from the GPIO pins populated on the MCU, transform it into a sequence of keys and sending them via the USB HID protocol.
Statically, we can probably define a QuasiQuoter that pairs an arbitrary expression with its quotation (I think you can splice back any code). Dynamically, you have to thread a constraint (like Show) through your data and functions. And you probably need compiler support for: class Debug a where debug :: a -&gt; IO String since even if you can traverse the memory representation of an expression, chasing pointers from closures/constructor/fields, you need the "leaves" to have been tagged with some simple. Like once you reach a thunk that will call `(+)`, there must be a `"+"` stored somewhere. (but, I'm not familiar with the compiler internals). I think I heard the Mu compiler provides arbitrary serialization, but I don't know how and it's closed source anyway. 
Lens-family has iso if you wanted a smaller dependency. I do iso's as a matter of course when I find them.
Indeed. If your run time is dominated by network latency, then this definitely isn't for you; the idea is allow you to write most of your application in normal Haskell and use a (much) faster DSL for the performance-critical parts. If the increase in (uncompressed) JS size is a deal breaker for you, you shouldn't even be using Haskell in the browser in the first place.
Thanks for the link. `oHm` seems to be very similar to `Elm` as well. `oHm` model corresponds to `Elm` model, `oHm` model events/actions correspond to `Elm` actions. `oHm` renderers correspond to `Elm` view functions. Off the top of my head I can't think of what `oHm` processors correspond to. I can't read closurescript, so I don't know how much of that is based on `Om`. Was `Elm` based on `Om` as well? Or is it just a coincidence that they are similar? I'm interested to understand how you use mvc as well... I've got a lot of reading to do!
I can't find the code for `todomvc` using `oHm` that is mentioned in `oHm`'s [readme](https://github.com/boothead/oHm#todo-mvc). Is it still available?
I think you can rewrite any type as records with their fields being their canonical projections, which would allow you to achieve entirely point-free functions.
Sorry, I screwed up the title. It should be saying, "Never slower than hand-rolled Javascript." The author (not me) at 15:00 says that often 10X speed can be achieved over hand-rolled Javascript and 100X speedup over Haste, and that it's never slower than hand rolled javascript.
I'm not the author, but, the way I understand it, it compiles on the client. So, you send 150K (which can be minified further) compiler. Then compiler generates ASM.js on the client. He answers this question at 18:20. It seems that main use-cases for this are gaming, signal processing and other high performance applications. In those use-cases sending game assets, or streaming data would already require plenty of network traffic and space.
I wrote a brief summary of Aplite over at the Haste dev blog: http://haste-lang.org/blog/aplite/. It also links to the full paper, if anyone feels like reading a bit more about it.
The speaker brings up a good question about reducing the size of type level expressions. Are there any proposals that would help with this? Would injective type families be enough? Is there a need for something else? If we want to push dependent features more in Haskell, I feel it will become crucial to fight against compile time bloat. If it takes 30minutes (exaggeration) to type-check a program that will dramatically reduce the productivity of devs and therefore the usefulness of those checks. 
If you are willing to drop the human readable aspect then this can be made more agreeable to the community, and easier to build in general, by making a quasi-quoter for Haskell and compile to a bytecode. Then we just need an interpreter, type witness, and perhaps a method of inputting the environment depending on the desired interface. 
Thank you for the clarification, I'm at work so I can't go through the whole thing. Client-side asmjs generation sounds like next-level hackery (in a good and bad way imo). It'd be interesting to do measurements on the effect this has on total request and load time as opposed to server-side generation (caching is pretty useless in these use-cases, where requests generally aren't repeated per client), although I'd imagine that could probably be somewhere in the video.
I'm not sure that secrecy will help much with security. With software, more eyes can spot more bugs and more hands can fix issues. I would suggest that the best way to protect workers (just like any other people) and gain their trust is to make them able see the code (and even change it). Is there something that we can do to help this get published? In sensitive matters like these, the best license would be [AGPLv3](https://en.wikipedia.org/wiki/GNU_Affero_General_Public_License), which grants the workers (your users) the best protection. Let me know if you would have any question regarding licensing (but hey, *you* are the lawyer here :D ) 
Is there a way to configure stack to use a docker image like this to perform builds using the docker integration [1]? [1] https://docs.haskellstack.org/en/stable/docker_integration/
It's certainly possible! For example, it might be a lot more convenient for doing alternate IO stacks, where there are a lot of operations you want to support.
The problem is the explosion. If isomorphisms between two types were unique then given n types there'd be potentially n^2 instances you must write. There isn't a way to state instance (Isomorphism x y, Isomorphism y z) =&gt; Isomorphism x z where to reduce that overhead. But isomorphisms between two types aren't unique, so this tends not to be built as a class. For a type of n inhabitants there are n! isomorphisms from that type to itself. When I work with long chains of isos in the lens library I typically need things like the iso for `not`, so this isn't strictly an academic concern!
&gt; you may want to use `confusing (some.big.traversal.stack)` Please tell me that's not a typo (for `fusing`)!
I don't believe injective type families is enough. And I don't know of any suggestions on how to alleviate the problem with large type expressions. It would have to be something like newtype for non-* kinds, but I don't know what that would look like. 
I'll just leave this here: https://github.com/GaloisInc/HaLVM
If serialize was in the IO monad, things would still be nicely behaved. Also, serializing to an opaque blob seems feasible. 
They do client-side compilation for performance reasons, not just to minimize the source size: &gt; The Aplite compiler runs in the browser, at run time. This lets the Haskell host program consider the browser environment, user input and other factors, and then modify any Aplite functions before compiling them. This idea is known as multi-stage programming, and is generally used to specialize programs to a bunch of factors that are not known at compile time, allowing programs to run faster than without this specialization. [...] &gt; Since the specializer can be triggered by the host program at till, an application might start off not using any specialization, realize that it is running too slowly, and attempt to speed up one or more Aplite functions using the specializer depending on the needs of the application. Put simply, Aplite gives developers more tools to speed up their code at run time. Source: http://haste-lang.org/blog/aplite/
Yes, I am aware of HaLVM; however, in Mirage, they leverage OCAML functors to swap implementations of the different parts allowing for smooth transition from developing on the host to running on the VM. I cannot find the video now but I saw aa very nice explanation of that. Now, backpack will allow us to do the same in Haskell.
If all you need is converting between newtypes and their representation, you might be able to use `coerce` from Data.Coerce.
If you have any questions feel free to ask. I'm in the Arlington office, so I can field questions about that specifically as well. 
Is it true that the Arlington office just plays games and drinks beer all day?
also times distributes over plus but not vice versa, so that seems to put an ordering on which is "prior" that doesn't exist in the bool case where the operations are symmetric 
Interesting! I really like the _notion_ of action, but i'm not sure if the instances capture it in a way i'm happy with...
hi panashe
I believe that Mu compiles to bytecode and allows shipping bytecode around. GHC also has bytecode support but it isn't used much outside of GHCi, probably because it's terribly slow. If GHC had a faster interpreter (or JIT) this would be less of a problem. In the land of compiled apps there is some utility in serializing arbitrary functions... mostly of interest for grid computing scenarios ala DpH (and Eden) which have fixed address space layouts, but useful nonetheless. The Eden RTS has C functions that implement what is essentially `a -&gt; ByteString` and `ByteString -&gt; a` (see https://ghc.haskell.org/trac/ghc/wiki/GpHEden/Packing) and I have spent some time trying to do this in pure Haskell and Cmm, which also seems quite possible... though not fully functional (see: https://github.com/alphaHeavy/vacuum-tube/blob/dewonking/GHC/VacuumTube.hs).
What about interns this time? :)
Processors are how I map events from one type to another. For example: onChange $ contramap (const $ SetCompleted idx (if complete then False else True)) chan Is converting the onChange dom event to something suitable to put on the DOMEvent Action channel. There's a slightly more involved example here with two processors, one converting UI events to chat model events and the other converting the larger combined model events to the larger model messages. They are then combined together using the magic of lenses. https://github.com/boothead/ohm-examples/blob/master/ohm-chat-client/src/Main.hs The message and event types are here: https://github.com/boothead/ohm-examples/blob/master/ohm-chat-client/src/Messages.hs
Better inference would perhaps alleviate the problem. I would like to see native support of either row types or type-level sets in Haskell, which would surely help us to improve inference.
So, you're never working with data structures in "real world" code, nor defining trait-like typeclasses for different types ? Of course, you can't make every function fully polymorphic. No one is saying that.
As Edward says, there is a ton of aggressive inlining going on in `lens`, but also the way some of the internals work is done by literally coercing (sometimes "unsafely", though it's safe here!) values into appropriate types. When GHC can see concrete types everywhere (which - to invent a number - is probably 90% of the time, think `myFoo ^. bar.baz.waffles`), it can both inline all the lens code *and then* inline the resulting `Applicative`/`Functor` code using `Identity` or `Const` (as that too is `INLINABLE`). Note you'll only get these benefits if you compile with `-O` (at least). If you want to check if things really are being inlined `ghc --make -ddump-simpl` is your friend.
It certainly wasn't the reply I expected when I first saw the email notification about a "new reply from StackSucks".
Why "the community cannot handover such basic things to a private company"? What are you worrying about? It's not unheard of to have a commercial entity provide the basic infrastructure for open source projects: I don't see anyone objecting that Google is keeping the infrastructure running for Go... And as for "fixing them seems achievable in reasonable time", what do you consider a "reasonable time"? One week? One Month? One Year? [Three Years](https://github.com/haskell/hackage-server/issues/145)? 
No, I believe inlining kicks in at -O0.
Even Stack makes heavy use of Hackage. Hackage is the core package center for Haskell, and will remain so as long as Stackage is a curated package set, even if no one actually directly uses Hackage much. It makes much more sense to *fix* Hackage than to abandon something so important.
Most languages allow functions to modify their arguments in-place. Even standard library functions do that. Doesn't this count as messing with the local scope of another function?
I absolutely agree on recruiting help for tooling, but isn't `haskell-mode` written in elisp?
This can be generalized to just `op = fmap . fmap`.
For those that want to fix hackage, just google "stackage foo"
A more elegant version I'd say is (&gt;&gt;=) = flip (&lt;=&lt; id) or in your terms kmap = (&lt;=&lt; id) (&gt;&gt;=) = flip kmap
Thanks to both of you ! :)
Well spoken.
It's worth making explicit for the unfamiliar that as `Functor` is the typeclass for endofunctors in `Hask` with functions as morphisms, so `Traversable` is the typeclass for endofunctors with Kleisli arrows as morphisms: class (Functor t, Foldable t) =&gt; Traversable (t :: * -&gt; *) where traverse :: Applicative f =&gt; (a -&gt; f b) -&gt; t a -&gt; f (t b)
Traversable is quite a bit different than endofunctors on Kleisli categories. Such endofunctors would fix `f` to a particular *monad*, instead of being polymorphic on an *applicative*. The lack of monad constraint means those aren't Kleisli arrows at all. Plus the `Foldable` superclass throws everything off =P
So... cokmap :: (Monad m, Functor f) =&gt; (a -&gt; b) =&gt; f a -&gt; m (f b) cokmap f = return . fmap f Which leads me to believe that there may be another more useful dual. What about cokmap :: (f a -&gt; f b) -&gt; a -&gt; m b or cokmap :: (f a -&gt; f b) -&gt; w a -&gt; b
Also, you'll notice that I didn't put a `Functor` superclass constraint on `CoKleisliFunctor`. This is because unlike `KleisliFunctor`, there's no guarantee that `f` implies an endofunctor on Hask.
Just to be clear. The Hackage docbuilders are maintained by volunteers. The docbuilder has long been unreliable in a variety of ways, at times reporting builds poorly, at other times grinding to a halt, and at others just dropping things intermittently. Some issues are fixed, others arise. Some get looked at in a timely fashion, many others haven't been. If anyone at all wants to roll up their sleeves and help fix these bugs, or volunteer to admin the docbuilder servers, or to improve the entire docbuilder architecture, that would be wonderful! For a weird task like "building _all_ the stuff" we're never going to be perfect, but we can at least be a lot more robust than the current setup. And patches and admins and investigators are always welcome.
Right, as opposed to the stripped down msys we've been shipping thus far.
Yes, it is. Sits in the "haskell stuff" part of my brain, whoops :)
Depends on the role. For the engineering role we look for generalists mostly, i.e. someone that is comfortable using a variety of technologies and techniques. Ideally the candidate will be an expert in _a_ language but it doesn't have to be Haskell (a common misconception). Because we work a lot with formal methods, comfort in that area, or the ability to demonstrate that you'd be able to take that on, is important, but we don't expect every engineer to be a researcher in formal methods. I hope that helps, feel free to ask more, or if you were interested in another role, let me know.
But didn't use a variable name for the container *at all*, and that's what you are polymorphic over!
The implementation relies on Haste's FFI for run-time code loading. Since the FFI doesn't need any particular compiler support (it's [just another library](http://haste-lang.org/pubs/ifl15.pdf)) it should be easily portable to GHCJS, and once you have that ported then Aplite itself should build without modification. tl;dr it should, but you'll need to get your hands dirty.
I don't believe so. I can't see anything about disallowing `undefined` or `throw` in Safe Haskell.
Ah, damn. If there's ever an opening, I'd be super interested :) Thanks!
It's important to keep in mind that Stackage doesn't have all the packages. In fact, it routinely removes packages that it can't build, which actually gives it a similar level of stability in this regard. You just don't see the packages that it has removed. The devil, in this case, lies in the details of expanding your scope from "all packages I can build" to "all packages".
You can disallow verbatim use of `undefined`, but you can't prevent he programmer from tossing around denotationally equivalent values without making the language not Turing-complete. `throw` is, I believe, denotationally equivalent to `undefined` and the difference is only observable if you're inside the appropriate monad.
EDIT: There is an internship position as tomejaguar pointed out below. [here](https://galois.com/careers/software-engineer-intern/)
Aplite seems to be Haste-only. Is there a mechanism to do this with GHCJS?
I'm a bit puzzled by this whole subthread, since there's an open position advertised for interns https://galois.com/careers/software-engineer-intern/
From a software engineering point of view - can someone elucidate what this means, and what it can be used for?
I'm not sure what such a DSL would really achieve. There aren't so many times that I run into things that would be elegantly caught as type errors in Haskell. Making q look like Haskell might be a decent way of breaking its weirdness barrier a bit faster, but they have fairly different semantics... Things like a lack of lexical scoping or strict evaluation might catch people out. q also hasn't got tail call optimisation.
Ha, good catch! I was not aware of that. I'll edit my response.
Honestly, the more I use Haskell, the less of my code there is actually interacts with the real world, instead delegating to other operations/DSLs/etc. In the limit I suspect that interaction with the real world could be reduced to being proportional to the "logarithm" as it were, of the code size (that is, you must interact with the world directly to create a new *kind* of capability, but using a capability can be done purely)
https://galois.com/careers/software-engineer-intern/
Thank you!
We should not have a Hackage, at all. There is no good reason to have one central repo that is blessed, along with tooling that makes it practically impossible to use any other repo or to set up your own. Most Linux distros can have multiple repos. For instance Ubuntu has the PPAs. Other software tools, like the Emacs package manager, can have multiple repos. Emacs is an excellent example, as the official GNU repo is far smaller than MELPA. I'm tired of seeing people bicker over Hackage and I wish we had tools that let people go their own way with their own repo.
Ok, but we can at least catch the most obvious cases
["newcomer" issues for Opaleye](https://github.com/tomjaguarpaw/haskell-opaleye/issues?utf8=%E2%9C%93&amp;q=is%3Aopen%20is%3Aissue%20label%3Anewcomer)
Do you answer every job application? I applied earlier but haven't heard from your guys in over a month so I'm hesitant to apply again.
Could the paper [APLicative Programming with Naperian Functors](http://www.cs.ox.ac.uk/people/jeremy.gibbons/publications/apl-extabs.pdf) serve as inspiration?
The syntax for remote and local repository configuration is described e.g. [here](http://cabal.readthedocs.io/en/latest/installing-packages.html) You can mix in custom repos even locally per-project by adding a `repository` specification to your `cabal.project` file. A typical use case is to enable your company's private package repository (which is then automatically merged with the official hackage.haskell.org repository index, unless you disable that one) for some project. The documentation is a bit scarce though on how to create a new-style secure repository (01-index), but it's trivial to create an old-style legacy format (00-index) repository.
I see three ways: - get a job, start using Haskell there - start using Haskell, make it a business (thus, a job) - find a Haskell job proposal (e.g., a Haskell Job), get hired
Actually, now that I look at it, `confusing` isn't actually that confusing. The main type involved is [Curried](https://hackage.haskell.org/package/kan-extensions-5.0.1/docs/Data-Functor-Day-Curried.html#t:Curried) ([Yoneda](https://hackage.haskell.org/package/kan-extensions-5.0.1/docs/Data-Functor-Yoneda.html#t:Yoneda) f) (Yoneda f), which is basically `forall r. Yoneda f (a -&gt; r) -&gt; Yoneda f r`. This is basically a kind of difference list for `Applicatives`. And if you flatten the `newtype` noise, you get: -- Isomorphic to Curried (Yoneda f) (Yoneda f) a newtype CurrYo f a = CurrYo { runCurrYo :: forall r s. (forall t. ((a -&gt; r) -&gt; t) -&gt; f t) -&gt; (r -&gt; s) -&gt; f s } instance Functor (CurrYo f) where -- fmap f cu returns a CurrYo that fmaps (. f) onto the Yoneda-encoded -- argument before passing it to cu. fmap f (CurrYo cu) = CurrYo $ \y -&gt; cu $ \c -&gt; y $ \x -&gt; c $ x . f {-# INLINE fmap #-} instance Applicative (CurrYo f) where -- pure a fmaps ($ a) onto its Yoneda argument. pure a = CurrYo $ \y c -&gt; y $ \x -&gt; c $ x a {-# INLINE pure #-} -- cf &lt;*&gt; ca fmaps (.) onto its Yoneda argument before passing -- it to cf, then passing the whole thing to ca. This ensures -- left-association. CurrYo cf &lt;*&gt; CurrYo ca = CurrYo $ \y -&gt; ca $ cf $ \c -&gt; y $ \x -&gt; c $ \f -&gt; x . f {-# INLINE (&lt;*&gt;) #-} -- liftCurrYo fa produces a CurrYo that &lt;*&gt;s fa onto the end of the -- Yoneda-encoded Applicative. liftCurrYo :: Applicative f =&gt; f a -&gt; CurrYo f a liftCurrYo fa = CurrYo $ \y c -&gt; y (c .) &lt;*&gt; fa {-# INLINE liftCurrYo #-} -- lowerCurrYo cu first lowers cu to a Yoneda f by passing it pure id, -- then lowers the Yoneda f to an f by passing it id. lowerCurrYo :: Applicative f =&gt; CurrYo f a -&gt; f a lowerCurrYo (CurrYo cu) = cu (\c -&gt; pure (c id)) id {-# INLINE lowerCurrYo #-} -- And with all this, confusing is simple. Lift the function from a -&gt; f b to -- a -&gt; CurrYo f b, traverse (using the CurrYo Applicative instance, -- which left-associates), and then lower it to an f t. confusing :: Applicative f =&gt; LensLike (CurrYo f) s t a b -&gt; LensLike f s t a b confusing t = \f -&gt; lowerCurrYo . t (liftCurrYo . f) {-# INLINE confusing #-} -- This also suggests an alternate strategy for traverseByOf - since the -- CurrYo Applicative instance doesn't refer to the Applicative instance of the -- base f, using different lift and lower functions allows you to traverse using -- custom pure and (&lt;*&gt;) functions without using ReifiedApplicative. traverseByOf :: Traversal s t a b -&gt; (forall x. x -&gt; f x) -&gt; (forall x y. f (x -&gt; y) -&gt; f x -&gt; f y) -&gt; (a -&gt; f b) -&gt; s -&gt; f t traverseByOf t pur app = \f s -&gt; runCurrYo (t (\a -&gt; CurrYo $ \y c -&gt; y (c .) `app` f a) s) (\c -&gt; pur $ c id) id {-# INLINE traverseByOf #-} -- And similarly for sequenceByOf. sequenceByOf :: Traversal s t (f b) b -&gt; (forall x. x -&gt; f x) -&gt; (forall x y. f (x -&gt; y) -&gt; f x -&gt; f y) -&gt; s -&gt; f t sequenceByOf t pur app = \s -&gt; runCurrYo (t (\a -&gt; CurrYo $ \y c -&gt; y (c .) `app` a) s) (\c -&gt; pur $ c id) id {-# INLINE sequenceByOf #-}
Which brings us to semantic editor combinators and thus to `Lens`. Whatever you thought of there is a good chance [Ed](https://hackage.haskell.org/user/EdwardKmett) has already written the library. `:¬/`
I feel you already know the answer to that one.
The reference compiler does catch common cases. head :: [a] -&gt; a head (x:_) = x The compiler will emit a warning because your pattern match isn't exhaustive. You can suppress that warning by adding head [] = error "head: empty list" But then you used `error`, so it's your own fault if you run into trouble. The compiler doesn't catch cases like these: loop :: a -&gt; a loop x = loop x That's a design choice, not a technical limitation. If you want to catch `loop`, shouldn't you also catch this? foo :: a -&gt; a foo x = bar x bar :: a -&gt; a bar x = foo x But still need to allow this sort of thing: fix :: (a -&gt; a) -&gt; a fix f = f (fix f) Because if you don't you lose general recursion, and then you can't do anything interesting anymore. You can write an ever more complex totality checker that handles ever more edge cases, but you can't write a perfect one. You need to stop somewhere, and the authors of GHC decided to stop rather early. I'm not in a position to explain the reasons behind that decision. 
I actually linked to the tutorial in my post https://www.schoolofhaskell.com/user/tel/lens-aeson-traversals-prisms
The link actually contains a ghci session.
At risk of being cute ... Haskell is an imperative language with Haskell syntax.
Let me know if you find anything better. I'm fascinated by why the interface for .+ (Action) needs to different to .* (Module). I think I can cut quite a few dependencies for Scalar as well, and hope to understand better if there's any relationship/analogy between these concepts.
Indeed. By the way, it is worth mentioning there is a not entirely inconvenient way of finding out whether some package has vanished from the latest set: this diff page... https://www.stackage.org/diff/lts-6.21/lts-7.3 ... shows all changes from the last 6.x LTS snapshot to the current 7.3 one, including additions and removals.
*What* makes it a better syntax? This statement lacks arguments. "Nothing is unnecessary" -- you can make that claim about assembler, too. I'm far from a haskell expert, however that probably puts me in a good position to lose a few words on this. Haskell has a good syntax for functional programming (it's good for applying arguments to pure functions and you can make your own infix operators). Less so for e.g. array or pointer style programming. Try writing `a[b[foo]] = c[foo]` in a nice way in Haskell. Look at the various bits of low-level Haskell code. I dare say C is much more readable and writable in this space, simply because the syntax is specialized. I think the lenses library enables "syntax" like `x += y` in the ST monad. However the same in C (where this is just syntax for `x = x + y`) has much less conceptual overhead.
It is just a monoid in the category of endofunctors. Take Maybe as an example. You should already know that Maybe is a functor, and for every a -&gt; b there exists a corresponding function given by fmap f: Maybe a -&gt; Maybe b (try to write down the definition of fmap). The motivation here is, if we have f: a -&gt; Maybe b, g: b -&gt; Maybe c, how could we compose them together? A possibility is to use fmap g . f, whose type signature would be :a -&gt; Maybe (Maybe c). We run into a problem! What is a Maybe (Maybe _)? Is it another functor? How is it related to Maybe? Let's recall the definition of Monoid in Haskell, which has two functions: mappend: m -&gt; m -&gt; m mzero: m In Monad, which is also a monoid as said above, we have a function called join: m (m a) -&gt; m a. Back to the Maybe case, it is specialized as Maybe (Maybe a) -&gt; Maybe a. This solves the problem of composition, namely we can write join . fmap g . f At last, given a value x: a, how to get a Maybe a? You can use Just, but you can also use pure/return: a -&gt; m a (they are equivalent since GHC 7.10). It serves a purpose similar to mzero. Monad is a monoid in categorical sense but cannot be defined as a Monoid in Haskell, AFAIK. If you can comprehend what I have said, start to do some exercise. You should probably start with the type signature of the Monad class, which uses a different but equivalent primitives (try to define one from the other!). Then, you should start to write your own Identity and Const monad, then List, then Reader/Writer. IO would be simple. Continuation…personally I haven't actually understood it. Sent from my iPhone so sorry about the formatting. Happy hacking.
See my edit to the OP.
Start with a value of type `f a`. Let's say that this is a context `f` with a result of `a`. Next is the Functor class, which has the operation `fmap :: Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b`. This means that we can change a result of `a` to a result of `b` inside a context `f`. Next is the Applicative class. Every instance of Applicative must have a Functor instance. Applicative gives us two more operations: `pure :: Applicative f =&gt; a -&gt; f a` and `(&lt;*&gt;) :: Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b`. `pure` means that given an `a` you can create a context `f` with a result of `a`. `(&lt;*&gt;)` means that if you have a context `f` with a result of `a -&gt; b`, you can apply that result function to another result of type `a` in the same context, and get back a context with result `b`. Notice how we can't get the results out of the context (it almost seems like we're deliberately avoiding it!) Applicative is expressive enough for us to "sequence" contexts- apply them one after the other in a predetermined order. Example: anInt :: Applicative f =&gt; f Int aChar :: Applicative f =&gt; f Char replicateA :: Applicative f =&gt; f String replicateA = pure replicate &lt;*&gt; anInt &lt;*&gt; aChar But what if the result of `anInt` is negative? This would break. I want to write a function that only runs `replicate` if the result of `anInt` is &gt;= 0. If the result &lt; 0, try it all again. Something like this: result_of :: Applicative f =&gt; f a -&gt; a tryReplicateA :: Applicative f =&gt; f String tryReplicateA = let res = result_of anInt in if res &lt; 0 then tryReplicateA else fmap (replicate res) aChar However `result_of` breaks our unspoken rule of not extracting results from contexts. Can you implement `tryReplicateA` using only `fmap`, `pure` and `(&lt;*&gt;)`? It turns out that you can't. We need new technology. This leads us to Monad. Every Monad is an Applicative, and therefore a Functor. The Monad class has one operation: `(&gt;&gt;=) :: Monad f =&gt; f a -&gt; (a -&gt; f b) -&gt; f b`. This means that given a context `f` with a result `a`, and a function that from `a` to a context with result of `b`, you can have the result from the first context fed into the function and produce a context with result `b`. Simply put, `(&gt;&gt;=)` provides some mechanism to examine the result of a context and change to a different context based on that, *without* allowing the user to extract the result from the context. Now we can write `tryReplicateA`: `tryReplicateA = anInt &gt;&gt;= (\n -&gt; if n &lt; 0 then tryReplicateA else fmap (replicate n) aChar)` 
we were all thinking it tho
How I understand it, could be way wrong. A monad is a construct that allows programs to have side effects but remain functional.
It might be handy for interoperation between Haskell and q?
Well, it is never too late to begin! For maximum clarity about the results, I suggest you try the following snippets from a source file, as opposed to directly from GHCi. main = putStrLn "First!" (An I/O action, which prints a line of text to the console) main = putStrLn "First!" &gt;&gt; putStrLn "Second!" (Two I/O actions. One is executed after the other.) main = getLine &gt;&gt; putStrLn "Whatever." (Two I/O actions. The first one reads a line from the console, but we do not do anything with it.) main = getLine &gt;&gt;= \s -&gt; putStrLn s (Two I/O actions. This time, we pick the result of the first action -- that is, the line read from the console -- and echo it back. We could also ditch the lambda and write simply `getLine &gt;&gt;= putStrLn`, but I wanted to emphasise the similiarity to the other examples.) And that's it -- you have just used the `IO` monad! ---- The key method of the `Monad` class is `(&gt;&gt;=)`, which is just a Haskell function like any other: Prelude&gt; :t (&gt;&gt;=) (&gt;&gt;=) :: Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b That type becomes `IO a -&gt; (a -&gt; IO b) -&gt; IO b` if you specialise it to `IO`. In our example, `(&gt;&gt;=)` runs two I/O actions in sequence, the second one being generated from the result of the first one (that is, we take the line read with `getLine` and give it to `putStrLn`). As for `(&gt;&gt;)`, it is just shorthand for the special case in which you want to discard the result of the first action and run a second action unconditionally (so `getLine &gt;&gt; putStrLn "Whatever."` is the same than `getLine &gt;&gt;= \_ -&gt; putStrLn "Whatever."`). What about do-blocks? They are just syntax sugar for `(&gt;&gt;=)`! This... main = putStrLn "First!" &gt;&gt; putStrLn "Second!" ... is the same as: main = do putStrLn "First!" putStrLn "Second!" And this... main = getLine &gt;&gt;= \s -&gt; putStrLn s ... is the same as... main = do s &lt;- getLine putStrLn s ---- Now that you know that there is nothing deeply complicated about code involving monads, a few extra words on why all of this matters. (Don't worry if some of the things I will say now feel a bit confusing -- it is the sort of thing that gets clearer over time with practice and more examples.) Why does Haskell use monads for I/O? Consider which type something like `getLine` should have. `getLine` gives back a `String`, but I can't say that it is a `String`. If I said that, you might reply with "Then which `String` is it?", and I would be in trouble -- the `String` changes every time you run the program! I/O actions have unpredictable results, and treating these results as if they were regular values would wreck the whole plan about making a functionally pure language (i.e. one in which all functions give back the same results when given the same inputs). For that reason, the type of `getLine` is not `String`, but... Prelude&gt; :t getLine getLine :: IO String `IO` is a *functor*. Since this is a bit long already I won't try to explain what a functor exactly is here -- suffice it to say that the list type is also a functor, and just like you have `[String]`, `[Int]`, etc. you also have `IO String`, `IO Int`, etc. A functor allows us to do two things relevant for I/O: * You can refer to, and modify, values in a functor without touching them directly. That is nice in the case of I/O, as it allows us to sidestep the whole issue about the unpredictability of, say, the value brought back by `getLine`: instead of referring to that value directly, we just say what we *will* do with it once it is produced at runtime. * A functor places values into a *context*. In the case of a list, this context is the skeleton of the list. In the case of `IO`, it is the specification of whatever I/O operations need to be executed for the value to be produced. Functors make it possible to handle the values within them independently from the context. That is significant for I/O, for while the values produced by an I/O action are unpredictable, the operations used to produce these values aren't. That means even something like `putStrLn :: String -&gt; IO ()` is a pure function -- it takes a `String` and returns the instructions needed to print it to the console. The type class for functors is `Functor`. It has one method, `fmap`, which allows changing values in the functor (so `fmap` for lists is just `map`). Now, some `Functor`s are also instances of a second type class, `Applicative`, which makes it possible to not only change values in the functor but also combine the context of two functorial values (in `IO`, that amounts to sequencing the I/O actions). Finally, some `Applicative`s are also `Monad`s, with `Monad` adding the ability to generate extra context from the values within the functor (for I/O, that means deciding which I/O action will be done according to the result of a previous action -- or, in other words, the sort of thing we did with `(&gt;&gt;=)` and `putStrLn` in the echo example above). ---- The great thing about monads (and functors, and applicative functors), and what makes them a bit intimidating at first, is that they are very general -- lists and I/O are just two examples among many many others. Rather than trying to grasp it all at once, you should just try to use them in practice, for little things at first if need be. You will build intuition as you go along. If you want extra reading, there are a few good options around, some of which have been pointed out by the other replies. I will, in addition, suggest the relevant Wikibook chapters -- you can perhaps begin from the [Simple Input and Output](https://en.wikibooks.org/wiki/Haskell/Simple_input_and_output) chapter, then skip to [the one about functors](https://en.wikibooks.org/wiki/Haskell/The_Functor_class) and then move on to the [unit about monads](https://en.wikibooks.org/wiki/Haskell/Prologue:_IO,_an_applicative_functor) and keep going, at a leisurely pace, until at least the (other) chapter about IO in that unit.
Thanks! I've been architecting things the last couple months, which has been hard on volunteers, BUT: we're gonna (re)launch the site at the end of the month! It's just an early version and the only project we'll support is Snowdrift itself, but once it is out the door, we should be able to fan out the work a little bit.
n.b. I'm a relatively young engineer, and I'd rate myself as fairly inexperienced with Haskel to boot. The only place I've successfully managed to apply (1) at was a relatively low-tech environment in which I was the sole software engineer for my group. Everywhere else I've met with moderate to heavy resistance from many people with prior software experience. So far at my current job, I've been leaning on Haskell for tasks that typically don't leave my workstation (e.g. Mocking APIs, writing a little script that's expected to run longer than the typical bash, etc.). Anything larger than that and I'm fairly sure there would be significant push back. Are there any types of applications or projects that Haskell is particularly well suited for *and* people without prior FP experience are receptive to?
Is there a transcript?
Not every function can be made point-free in Haskell, though. Functions with RankNTypes can cause difficulties when combining them with operators such as `.`.
Python...
Coming from Standard ML, OCaml, F#... I *hate* Haskell syntax.
This paper from SPJ has a bit of historical perspective on monads for Haskell: http://research.microsoft.com/en-us/um/people/simonpj/papers/marktoberdorf/mark.pdf. It focuses on the IO monad, which I think is the most frequent source of confusion.
Thanks. Now I can understand my xmonad config a bit better.
SML syntax is really pretty darn nice. Not only the core expressions, but all the way up to the syntax for signatures, structures and functors. It looks like it was holistically all thought out or it just fell together nicely. OCaml is just this side of a syntactical train wreck. It looks like it came together willy-nilly or was designed while tripping at Woodstock. 
This is a friendly and generous reply to what I think can be a tough question. There's a lot to learn from and be inspired by in the style and substance of what you have written. Kudos.
Does the ghc manual say they are the same? I do not think they are but will have to look it up myself.
Quite honestly, I have thought about the same and had even started to work on one...But couldn't continue. Might pick it up again....
In case you were unaware (and occasionally this is useful) Haskell is not *necessarily* whitespace dependent. When a layout keyword (`do`, `let`, `where`, or `of`) is *not* followed by a `{`, then a layout context is introduced, and indentation becomes significant. (This includes the implied `module Main of` that's assumed when you leave out a module declaration.) But if you use braces everywhere with semicolons as separators, you may use any formatting (or lack thereof) that you like. It's often more convenient to do it this way when you are generating Haskell programmatically. You never need to line up guards. The only thing you need to do with this is *not* mess up other containing layout contexts. So, for instance, if you didn't put braces around your module, you would need to indent any new lines at least a little so that the line isn't interpreted as a new module-level definition. But you need not line them up any more than you need to line up statements in C. It's just convention.
Not that I can think of, though a PR to stackage-server to add such a lookup would certainly be welcome. Probably the easiest way to get something like that today would be to add a `foo == 1.2.3` in your .cabal file and try out a `stack init`, though it won't do a truly deep dive of all available snapshots.
As far as style goes, [Johan Tibell's guide](https://github.com/tibbe/haskell-style-guide/blob/master/haskell-style.md) is probably a good starting point -- and it is applied by [hindent](https://github.com/chrisdone/hindent).
What I've never understood about uploading your own documentation to Hackage is: how does it determine how to generate links to types/functions from other packages? I know that in the Stackage doc build scripts, we configure it to match all of the package versions in the current snapshot. But I can't even guess how you'd even know if a specific package/version combo has generated documentation when generating before uploading to Hackage (unless the scripts are really complex and check for 404s before calling `cabal configure`, which certainly seems to not be the case).
Generating docs at the library maintainer level instead of the infrastructure level is definitely the pragmatic choice right now! That said, it's not a super principled one and I would be disappointed to see us use it long term. People make mistakes. Perhaps I upload a version of my package and then start on the next version locally. Then I come back a day later, see the docs failed on Hackage, and upload the docs for what's currently in the project forgetting I had made changes since release. The specific scenario doesn't matter -- what does is that having library maintainers do this opens us up to human fallibility (and is drudge work, and we'll forget to do it sometimes, etc).
i have found in Elm at least I end up writing far fewer tests, as the type checker tests many things for me that I would have written a test for in say Javascript. If you setup your types well you will find that many of the things you might have written a test for happen for free with a type. But if you combine types, and example tests and quickcheck and whatever else you can think of you will get great code 
I don't work for Ambiata, but I've bumped into quite a few of them via the Australian FP scene. The folks I know there are good people / very smart /working on interesting problems. They've given a lot of talks over the last few years (random sample [here](https://yow.eventer.com/yow-2014-1222/programming-in-the-large-architecture-and-experimentation-by-mark-hibberd-1695) and [here](https://www.youtube.com/watch?v=ZuCRgghVR1Q)), which might provide some idea of the kinds of things they get up to. If Sydney was an option for me at the moment, I'd be tidying my resume - and not writing this whole comment, so that I wasn't increasing the amount of competition :)
&gt; though a PR to stackage-server to add such a lookup would certainly be welcome I somehow misread this as "an issue against stackage-server would be welcome" and then actually [filed the issue](https://github.com/fpco/stackage-server/issues/205), which is somewhat embarrassing...
There's a well-known URL scheme for packages and identifiers in the packages. As long as you're building against packages you installed from hackage then the URLs will be sensible.
Yeah, the links will point to the correct location so that when the dependency's documentation is ready the links will be ready to go.
The solving step is essential for packages uploaded to Hackage. If your version bounds are not accurate (which is one of the very few things we expect from package uploaders) and consequently the cabal solver comes up with a bad install plan, then everyone downloading your package risks running into the very same compile failure. So including and relying on a `cabal.config` to find a working install-plan is the wrong approach here.
Here's how I view monads (I've been writing Haskell for a couple of years). A Monad -- for example `IO a` -- is an environment in which you have access to certain functionality. For example: print to console, read from a file, send data to a web server. You can easily see which functions "live" inside IO, but looking at their return type: getLine :: IO String means that `getLine` is a function that, inside IO, can "pull" a String out of nowhere (this particular string will be read from the console input). putStrLn :: String -&gt; IO () means that `putStrLn` also lives in IO, but unlike `getLine`, it only has *an effect* inside IO, because it doesn't return a result (in this case it prints the supplied string to the console). If you have a function that converts a `String` to upper case, for example: toUpperCase :: String -&gt; String you can only take this function and "bring it inside IO", in order to modify the String in there, and then return the uppercase string as an `IO String`. Inside IO, you have access to the pure values, by "binding" the return result from an IO action, like so: getLineUpperCase :: IO String getLineUpperCase = do line &lt;- getLine let upperCaseLine = toUpperCase line return upperCaseLine Here `line` and `upperCaseLine` are just `String`s, but become `IO String` when we use the `return` function on them. So you can always bring a pure function (eg. `toUpperCase`) into IO, and use it to act on values returned inside IO, but you can never pull a string out of IO. You bring your logic (your pure functions) into IO, and use it to modify values that are only available there, rather than pulling values into the domain of your pure functions. You can convert a pure function into a function that operates inside IO by "lifting" it into IO using `fmap`: toUpperCaseIO :: String -&gt; IO String toUpperCaseIO = fmap toUpperCase Now we can use this function without having to `return` the value it produces: getLineUpperCaseNew :: IO String getLineUpperCaseNew = do line &lt;- getLine toUpperCaseIO line which is exactly the same as: getLineUpperCaseNew = getLine &gt;&gt;= toUpperCaseIO 
Can something similar be done with stack?
Well, Stack's primary use-case is to *not* be mussing about with versions of dependencies: just use Stackage. But it does support calling out to a solver so I imagine that this mechanism should be enough to get you where you need to be.
What you mean by "domain reasons" when you mention FunctorMaybe class in Reflex? As far I see in code comments, it's just there because /u/ryantrinkle hadn't found the existing library for it, and if there's gonna be one, it might be switched. Or is there more to it?
&gt; use custom prelude P Are they on Hackage? I tried to look them up, but it's kind of hard to search for a one letter name.
Well we are not convinced that what we have so far is great, and since haskell devs are rather thin on the ground in Tel Aviv we are assuming that we will have to do some (or a lot ) of training 
I just meant that the class is in a domain specific library for domain specific reasons. It isn't there so that the world can have a FunctorMaybe class; it's there because reflex needed it
Of course it is better than unrestrained mutability. But it doesn't guarantee the absence of side-effects and referential transparency. That means you cannot freely compose or refactor functions unless you have read the code and know that it is safe to do so, whereas referential transparency in Haskell allows you to do a lot of refactorings in a completely mechanical fashion without any risk. What is the most practical solution is a matter of personal preference, but personally I trust the compiler more than my memory or attention. That's why I like Haskell.
&gt; I don't know what is being done when a plus is inside the angle braces, and I'm not able to find out on Google. You can use Hoogle: https://www.stackage.org/lts-6.2/hoogle?q=%3C%2B%3E&amp;page=4 although unfortunately your operator only appears on page 4.
Is relocation an option or you are looking for people already living in Australia?
&gt;no partial functions Can you elaborate on this? * what are partial functions? * why is it beneficial to avoid them? Do you mean something like this? number 1 = "one" number 2 = "two" number 3 = "three" Will the compiler catch it?
A partial function is a function that is not defined for all possible arguments of the specified type. So in that example `number` would be defined as `number :: Int -&gt; String` and passing in anything other that 1,2 or 3 would yield an exception like `*** Exception: &lt;interactive&gt;:3:15-33: Non-exhaustive patterns in case` Unfortunately in Haskell there are a bunch of these functions in the Prelude which don't generate a warning and the compiler treats non-exhaustive matches like `number` as a warning rather than as an error. Which is most unfortunate.
&gt; RecordWildCards What's your reasoning for this? We use them a lot and I'm not sure they ever caused a bug :) 
Did you set "OverloadedStrings" as mentioned in the example? You have to either type :set -XOverloadedStrings in your ghci session, or add {-# LANGUAGE OverloadedStrings #-} at the very top of your .hs file
I guess the reasoning is to avoid accidental name capture.
[removed]
Assembly language is extremely redundant. And indeed I'd love an assembly language designed around less syntactic redundancy. movq $123, %rax lea 123(%rsi,%rdi,2), %rdx vs.: rax &lt;- 123 rdx &lt;- rsi + rdi&lt;&lt;2 + 123
No problem, and good luck!
Indeed. All these tools are good.
got it working! (y)
You can use any text editor. I think the majority of us use emacs or vim. As an alternative to notepad++ you might want to consider SublimeText 3. It has a bunch of Haskell related plugins. For practice, if you are new to functional programming, you might want to try solving a few [Project Euler](https://projecteuler.net/) problems with Haskell. (Or at least that is how I got my start) For installing GHC, an alternative to stack is to install a system wide GHC with the Minimal [Haskell Platform](https://www.haskell.org/platform/#windows) install, but you'd probably end up using stack anyway though. 
i think i have somewhere a copy of sublime text3. i tried vim before and also emacs, but i didnt like it. i already did some problems on project euler in terms of python :D was pretty cool there, so i will play with it. i have stack now and just tried a few basics out, its working.
As a related note: In PureScript you either `import Prelude (foo,bar)` explicitly or `import Prelude as P` qualified, there is no `qualified` keyword. `as P` _means_ `import qualified Prelude as P`. Personally, I like it. It's a bit of a departure from Haskell, though.
I like it too. Unfortunately importing modules qualified but not aliased it clunky: `import Prelude as Prelude`. In my opinion, [Elm's import syntax](http://elm-lang.org/docs/syntax#modules) is the best. `import List` is qualified, `import List as L` is aliased, and `import List exposing (..)` is an open import. 
Since this is a Windows question, for the editor, I'd recommend Atom with the Haskell plugins for it. Also the beta REPL plugin comes in separately from the main package, but I'd recommend getting it as well as it will save you quite some time on the smaller projects.
To understand Monads, it's first helpful to understand Functors. Every Monad is a Functor (that also has a few additional things). If you've used functional programming before, you've probably come across the `map` function, where e.g. `map (+ 5) [1,2,3,4,5]` evaluates to `[6,7,8,9,10]`. It was later realized that map is really just a particular case of a generally useful function: fmap :: (a -&gt; b) -&gt; [a] -&gt; [b] fmap :: (a -&gt; b) -&gt; (r -&gt; a) -&gt; (r -&gt; b) fmap :: (a -&gt; b) -&gt; (s, a) -&gt; (s, b) fmap :: (a -&gt; b) -&gt; Tree a -&gt; Tree b fmap :: (a -&gt; b) -&gt; Maybe a -&gt; Maybe b fmap :: (a -&gt; b) -&gt; Either c a -&gt; Either c b fmap :: (a -&gt; b) -&gt; Identity a -&gt; Identity b fmap :: Ix i =&gt; (a -&gt; b) -&gt; Array i a -&gt; Array i b fmap :: (a -&gt; b) -&gt; IO a -&gt; IO b Because of that realization, the Functor typeclass was defined: class Functor f where fmap :: (a -&gt; b) -&gt; f a -&gt; f b They decided to call this abstraction "Functor" because if you squint at Haskell from the right perspective it lines up with a mathematical concept of the same name. Basically, a Functor is something you can map over. You could define a Monad typeclass as class Monad m where fmap :: (a -&gt; b) -&gt; m a -&gt; m b join :: m (m a) -&gt; m a pure :: a -&gt; m a However, that's not how it's defined in Haskell (join and fmap are equivalent to &gt;&gt;=, and it's defined in terms of &gt;&gt;= and pure) and it's also not terribly apparent why we might care about monads from that definition. One useful function that might help you understand why we care about monads is &lt;=&lt;, the [Kliesli](https://en.wikipedia.org/wiki/Heinrich_Kleisli) composition operator, often pronounced "left fish". Note the similarity to `(.) :: (b -&gt; c) -&gt; (a -&gt; b) -&gt; (a -&gt; c)` &lt;=&lt; :: (b -&gt; [c]) -&gt; (a -&gt; [b]) -&gt; (a -&gt; [c]) &lt;=&lt; :: (b -&gt; r -&gt; c) -&gt; (a -&gt; r -&gt; b) -&gt; (a -&gt; r -&gt; c) &lt;=&lt; :: (b -&gt; (s,c)) -&gt; (a -&gt; (s, b)) -&gt; (a -&gt; (s, c)) &lt;=&lt; :: (b -&gt; Maybe c) -&gt; (a -&gt; Maybe b) -&gt; (a -&gt; Maybe c) &lt;=&lt; :: (b -&gt; Either d c) -&gt; (a -&gt; Either d b) -&gt; (a -&gt; Either d c) &lt;=&lt; :: (b -&gt; IO c) -&gt; (a -&gt; IO b) -&gt; (a -&gt; IO c) As you can see, Monads and Functors aren't really all that closely related to performing imperative things. It's just that one way of capturing imperative things happens to fall into this generally applicable pattern. If you're wondering what exactly a value of type `IO a` is, you can think of it as "a program that, when run, will eventually yield a value of type a". In Haskell, only one IO action is ever really run: the one that's bound to `main`. Main is typically built up via "combinators" like &lt;=&lt; and &gt;&gt;= from smaller actions, and there's a bunch of primitive actions like readLn in the standard library.
Had a better proposal ;) https://ghc.haskell.org/trac/ghc/ticket/9977
Sry for the bad joke, I really thought this was about {-# LANGUAGE MonadComprehensions #-} Apart from that, you can perfectly make use of monads without understanding the theory behind it... I see there are enough good examples here already.
In HIndent we explicitly avoid dependency on the length of any symbol to avoid editing overhead and messy diffs. E.g. if you rename `foo` in your example above then every line below it has to be moved.
*Tackling the Awkward Squad* is an excellent paper and it's what made monads click for me. Doesn't try to dumb it down, doesn't take you through eleventeen leagues of deep categorical bog to get to the point. *And* it's straight from the horse's mouth, as it were!
I miss [Agda's modules](http://wiki.portal.chalmers.se/agda/pmwiki.php?n=ReferenceManual.Modules): * Modules can be nested, decoupled from files, and even parametrized. * `import` is always qualified * `open` provides a way to add things to the local namespace * `open` supports `using`, `hiding`, and `renaming` * `open` can be used in any scope * `open` supports a `public` keyword, making the result available for re-export
Yeah. But, that happens with other tools as well. E.g. I require a clean FindBugs run for one code base. But, you can satisfy that either by writing the code FindBugs understands as correct, or by adding the appropriate exclusions to FindBugs for correct code that it doesn't recognize. New FindBugs exclusions get plenty of human code review attention. I think you can do the same with hlint.
Yea. But type families tend to have much worse type inference and error messages. Can't say how much practically worse it would be for this case
The functional dependency works unless they want to cast Word8s into Word32s directly. 
gVim has a windows installer, and is a significantly better editor. ;)
It's possible you were in the batch that we are currently going over. We get a ton of applications and we're a pretty small company, so it takes us a while to comb through them all. If you don't hear back in the next month or so, let me know.
Well, then either: 1. newline before `::` (which, yeah, breaks some tools), or 1. line up `-&gt;`, `=&gt;`, ` .`, ` (`, ` ,`, and ` )`, but not necessarily with the `::` (that does mean your `forall`, single constraint, or first argument doesn't quite line up with the others).
This seems to work pretty well: {-# LANGUAGE TypeFamilies #-} {-# LANGUAGE FlexibleContexts #-} module Temp where import Data.Word import Data.Bits import Control.Arrow ((&amp;&amp;&amp;)) class (Integral a, FiniteBits a, Num (DoubleWidth a), Bits (DoubleWidth a), HalfWidth (DoubleWidth a) ~ a) =&gt; BitAppend a where type DoubleWidth a (|++|) :: a -&gt; a -&gt; DoubleWidth a a |++| b = higher a .|. lower a higher :: a -&gt; DoubleWidth a higher a = fromIntegral a `shiftL` finiteBitSize a lower :: a -&gt; DoubleWidth a lower = fromIntegral class (Integral a, Bits a, Num (HalfWidth a), FiniteBits (HalfWidth a), DoubleWidth (HalfWidth a) ~ a) =&gt; BitBisect a where type HalfWidth a bisect :: a -&gt; (HalfWidth a, HalfWidth a) bisect = high &amp;&amp;&amp; low high :: a -&gt; HalfWidth a high a = a' where a' = fromIntegral (a `shiftR` finiteBitSize a') low :: a -&gt; HalfWidth a low = fromIntegral infix 9 |++| instance BitAppend Word8 where type DoubleWidth Word8 = Word16 instance BitBisect Word16 where type HalfWidth Word16 = Word8 instance BitAppend Word16 where type DoubleWidth Word16 = Word32 instance BitBisect Word32 where type HalfWidth Word32 = Word16 instance BitAppend Word32 where type DoubleWidth Word32 = Word64 instance BitBisect Word64 where type HalfWidth Word64 = Word32 
Here is the commit for GHC: https://phabricator.haskell.org/rGHC00b530d5402aaa37e4085ecdcae0ae54454736c1
It's a pretty minor change, with pretty minor benefits.
Type families are also a little harder to understand for newer users =P
`import` can be used in any scope, for that matter. But GHC intentionally doesn't support that (to be able to do dependency analysis without having to parse the whole file).
you aren't sharing code, please put your project on github or whatever and email haskell beginners or equivalent subreddit and someone can help. 
How would you import `List` (the type) unqualified, but the rest of the module qualified? Would it have to be split across two lines like in Haskell? import List exposing (List) import List
It is unnecessary, but I like having it there. A little bit of redundancy can be nice :) Heck, you could drop `as` if you wanted to: `import List L`. I'd argue that's not any better. 
+1 for Atom. It's working well for me. The REPL plugin also works for me though it's currently a bit basic. I think it's easiest to install ghc-mod through Stack and go Stack only for projects.
Thanks! This comment was helpful in clearing up my confusion.
try working in it and you learn the (practical) difference.
I've worked in both to some extent, though the most complicated x86 program I've ever written was a Sudoku solver... If you add symbolic registers and a register allocator that assigns them to machine registers then you are one step closer. If you then add some syntactic sugar for loops and functions you are closer again. The last major difference is structs. 
`haskell-mode` has imports formatting already, so I am using that with combination of `hindent`, no need for `stylish-haskell`
&gt; In Haskell, I typically don't mind using redundant name likes Text.Text or Map.Map. Those two are okay, but when you start typing `HashMap.HashMap`, `NonEmpty.NonEmpty`... _shudder_
&gt; I think the lenses library enables "syntax" like x += y in the ST monad. Is that true? Or are you confusing the `State` monad with `ST`?
[removed]
Old projects will still use the old way, new projects might use either, styles will get mixed in the same project (and probably even in the same file). Tools will have to support all of those cases and either use a heuristic to decide which one to use or burden the user with changing the configuration (see inadvertent mixed styles). Effectively it becomes _harder_ to read import statements because each line might now have a "qualifying" keyword in either of two places. So I don't see how this is an improvement.
How about using pattern synonyms? This way you can both compose larger words out of smaller words and decompose larger words into smaller words. {-# LANGUAGE PatternSynonyms #-} {-# LANGUAGE ViewPatterns #-} import Data.Bits import Data.Word -- just a few helper functions, the real meat are the patterns below split16 :: Word16 -&gt; (Word8, Word8) split16 n = ( fromIntegral (n `shiftR` 8 .&amp;. 0x00FF) , fromIntegral (n .&amp;. 0x00FF) ) split32 :: Word32 -&gt; (Word16, Word16) split32 n = ( fromIntegral (n `shiftR` 16 .&amp;. 0x0000FFFF) , fromIntegral (n .&amp;. 0x0000FFFF) ) split64 :: Word64 -&gt; (Word32, Word32) split64 n = ( fromIntegral (n `shiftR` 32 .&amp;. 0x00000000FFFFFFFF) , fromIntegral (n .&amp;. 0x00000000FFFFFFFF) ) -- | -- &gt;&gt;&gt; Split16 2 0 -- 512 -- &gt;&gt;&gt; let Split16 x y = 260 in (x, y) -- (1,4) pattern Split16 :: Word8 -&gt; Word8 -&gt; Word16 pattern Split16 hi lo &lt;- (split16 -&gt; (hi, lo)) where Split16 hi lo = fromIntegral hi `shiftL` 8 .|. fromIntegral lo -- | -- &gt;&gt;&gt; let Split32 x y = 65540 in (x, y) -- (1,4) -- &gt;&gt;&gt; let Split32 (Split16 x1 x2) (Split16 x3 x4) = 65540 in (x1, x2, x3, x4) -- (0,1,0,4) pattern Split32 :: Word16 -&gt; Word16 -&gt; Word32 pattern Split32 hi lo &lt;- (split32 -&gt; (hi, lo)) where Split32 hi lo = fromIntegral hi `shiftL` 16 .|. fromIntegral lo -- | -- &gt;&gt;&gt; maxBound :: Word64 -- 18446744073709551615 -- &gt;&gt;&gt; :{ -- Split64 -- (Split32 (Split16 255 255) (Split16 255 255)) -- (Split32 (Split16 255 255) (Split16 255 255)) -- :} -- 18446744073709551615 pattern Split64 :: Word32 -&gt; Word32 -&gt; Word64 pattern Split64 hi lo &lt;- (split64 -&gt; (hi, lo)) where Split64 hi lo = fromIntegral hi `shiftL` 32 .|. fromIntegral lo 
I don't think that's an option for us, we're not looking for freelancers/contractors necessarily. Many of us spend days working from somewhere other than the office but not in a full time capacity.
I found `import Data.Map as M (Map)` confusing (or maybe just not english). Also, how do you import some symbols qualified (i.e. `import Data.Map(Map) as M`), not sure anybody use it? 
OK, worth asking. Would love such an opportunity if one arose. Good luck!
RecordWildCards can leads to runtime error when used to contruct values with missing fields, example: data Point = Point { x :: Double, y :: Double } pointX x = Point{..} This compile but throw an runtime error because `y` is undefined. It's a feature apparently. 
The https://typesandkinds.wordpress.com/2015/09/09/what-are-type-families/ link mentioned there is worth reading in full (by Richard Eisenberg)
That sentiment can only hold true if you are never going to contribute to (or even read, for that matter) other people's code. Also, trying to convince people to use a code checker to adhere to you favourite style is a sisyphean task.
Not really. Case in point - gofmt. After hindent finishes next major update (the "one true style") it will be faux pas to publish code unformatted. And even more so in the future. Or so I hope (= 
Thank you for the pointers, I will take time to digest everything ;)
I've never used, but one use case could be to reexport some of a module, example module MyModule ( module M ) import qualified Data.Map(toList, Map) as M 
People are downvoting you, I assume because you truly do think of your solution as superior, perhaps coupled with a big of smug thanks to the `;)` Which is not necessarily bad, to think that your solution is better. But that doesn't mean it's the truth, either. Your proposed change, as noted by Edward, changes the layout rule for Haskell which is triggered in well defined ways. It also adds a significant change on-top of that to the import system and its syntax. That's a significant change to the lexical syntax of the language and would likely complicate GHC's frontend even more than it already is. It would also mean a real, formal proposal would likely need to be quite detailed and carefully constructed. Haskell is not a simple language to parse. Furthermore, your proposal does not come with a detailed specification or, for example, an actual proposed change to the grammar. The OP does, while being drastically smaller in scope and change. And frankly I find the proposed "solution" to the problem Reid presented in the ticket, with `@` syntax, just unbelievably ugly (yes, some amount of aesthetics matter). Most of these are simply significant negatives to your proposal, I'm afraid, some more than others. It's not inherently "better" by many definitions other than "it's more featureful" or "bigger is better", or something like that. That's not all that matters, though. The import system could definitely become more powerful through various extensions. That does not categorically mean those extensions are always "better" than other, simpler ones -- for a variety of reasons.
I've seen that mentioned a few times in the PR, but: which tools are broken by moving `::` to a new line? That's something I have never run across.
I personally disagree, I think `TypeFamilies` are very intuitive. They are just functions, but on types instead of values. MultiParamTypeClasses plus FunctionalDependencies IMO are less intuitive and kind of Prolog / logic programming ish. They don't feel very "functional" like the rest of Haskell.
Another option is [Spacemacs](http://spacemacs.org), a distribution of Emacs bundled with Vim controls and a much more streamlined customization method.
I'm firmly in the camp of style 2, with the dot of the forall, the fat arrow of constraints, and the double colon, all lining up with the function arrows, all at 4-spaces indentation.
The big thing I dislike about this style is that, because the `::` occurs immediately after the name, that means the indentation is highly dependent on what names you use. This looks inconsistent and ugly to me, as well as making diffs a lot noisier whenever you rename things. Similarly, when it comes to aligning the bodies, if it's long enough to wrap then I always break it around the equals sign so that the indentation isn't dependent on the name.
I align the dot with the start of the arrow, but also give two spaces so that the RHSs line up; best of both worlds.
Sorry for taking some time to answer you, I've been really busy and that reply puzzled me through the whole week. I've read the first few pages of that paper, but I'm a little confused because it seems that the combination of bindings and commands is the same thing as a λ application on the λ-calculus - I don't get why it is less powerful. I quite understand what you said, though, and if, indeed "interaction combinators are proof nets of this particular flavor of sequent calculus", that would be truly enlightening in many senses. I need some time to understand proof nets and the sequent calculus better before I can fully appreciate that statement. Meanwhile, can I ask a more practical question? I'm looking for a dependently typed functional programming language with terms that can be reduced with interaction combinators. That is mostly for an unrelated project which involves a distributed database of λ-terms, and I need to pick a language to it. The computational properties of interaction nets make this project much simpler in many senses, so I'd like to use a functional language that compiles to them; but I still need the language. Most functional languages don't work for all terms without some type level trickery I don't fully understand yet (EAL, yet). Could that "multiplicative fragment of the sequent calculus" be that language? After all, the paper mentions something about dependent types. I'm not sure exactly what it is, but, in short, is that thing dependently typed programming language which can be used to build functional programs normally (with ADTs and the like) and can be reduced on interaction nets?
Did you see my edit to the question? 
Within single files it should not be too much of a problem. If you need to modify the imports, update them all as a drive-by fix. (In a separate commit, to make it easier to review and blame.) Sure, there will be inconsistencies in the project then, during the transition period. That will always be the case in a large project anyway. And if that really bothers you, contribute a batch update. It shouldn’t be hard to automate even.
Semi-offtopic, but I just wanted to say that I absolutely love the documentation of various libraries on https://haskell-lang.org/libraries ! Recently took advantage of a couple of them, because they provided better documentation than anything else I could find :) EDIT: Fixed URL
Personally I don’t find messy diffs all that objectionable any more nowadays. Git has `--word-diff` and `--ignore-all-space`, and modern code review tools highlight the word diff with a faded line diff in the background, so it is very easy to spot and skip over whitespace-only changes.
How do you handle multiple constraints?
Do you mean https://haskell-lang.org/libraries
I work on the operations team at IMVU, not the infrastructure team, but I can personally say that I've really loved working here. Here are a few links to blog posts about Haskell at IMVU. * [The store of Haskell at IMVU](https://chadaustin.me/2016/06/the-story-of-haskell-at-imvu/) * [Testable IO in Haskell](https://engineering.imvu.com/2015/06/20/testable-io-in-haskell-2/) * [What it's like to use Haskell](https://engineering.imvu.com/2014/03/24/what-its-like-to-use-haskell/) I know there's also a video recording out there somewhere of Andy Friesen's presentation about Haskell at IMVU, but I failed to find it quickly on Google. 
Yeah, I don't really consider some locally wrong colors for a type signature 'broken editor support'.
That is true. There are whitespace-related options for the merge strategies in Git too, but I’ve never looked into them.
How's the job mobility for people on your operations team wanting to move into Haskell dev?
I like the last 'ugly' solution. foo :: X -&gt; Y
Cool, I didn’t know repeating the fat arrow was allowed. It completely sidesteps the alignment issues of parentheses and it looks more even, great!
Whoa
Just to offer another angle, the equivalent in `do` notation would be: three = do a &lt;- item b &lt;- item c &lt;- item return (g a b c) where g x y z = (x, z) The applicative notation just avoids naming the intermediate results `a`, `b`, and `c`. Also, `pure g &lt;*&gt; …` could be replaced with `g &lt;$&gt; …`. 
Actually, there would be no inconsistency (at least in that regard) if we just stuck with the old style, which is kind of my point. Keeping the styles consistent in all the projects I contribute to is what I called sisyphean. Sure, I could just hack a function into emacs that updates it whenever I write a file (or better yet: open it, so I never have to see the style I don't like); I did exactly that for trailing whitespaces, but even there I ended up disabling it occasionally because pairing a one-line fix with 300 whitespace changes seemed odd (Also, I couldn't be bothered to untangle the changes for the commit :P ). Making stylistic changes to code the owner of the project might not even want changed isn't more appealing. So what I worry is that in the end we'll end up with more work, while for many projects we'll have less stylistic consistency , more mental overhead handling imports and little to show for it.
It allows SPJ to talk about how awesome GHC is without causing too much success, which we try to avoid. :)
Sure, but not at *all* costs. ;-)
Not exactly for the _whole_ presentation, since he used a different font for the second slide in this video :D But joking aside, people have brought it up a bunch of times, and there's even a previous [_thread_](https://www.reddit.com/r/haskell/comments/1bd1ia/spj_and_comic_sans/) with a transcript quoting SPJ: &gt; This is a very funny question, why I use Comic Sans. So. All my talks use Comic Sans, and I frequently see little remarks, “Simon Peyton Jones, great talk about Haskell, but why did he use Comic Sans?” But nobody’s ever been able to tell me what’s wrong with it. I think it’s a nice, legible font, I like it. So until someone explains to me — I understand that it’s meant to be naff, but I don't care about naff stuff, it’s meant to be able to read it. So if you’ve got some rational reasons why I should not, then I’ll listen to them. But just being unfashionable, I don’t care.
Want to return the pair of the first and the third elements from the input stream? For me it's better to express as: ``` three = (,) &lt;$&gt; item &lt;* item &lt;*&gt; item ``` After becoming acquainted with [`regex-applicative`](https://github.com/feuerbach/regex-applicative/wiki/Examples) library such constructions look familiar for me.
This is useful, thanks. The next example in the book actually makes Parser an instance of Monad and its usage is very similar to what you've shared.
Neat. I'll have to check out that library.
Do you want a two-way fundep there? A Word16 can only decompose into two Word8s.
[On the other hand...](http://thenextweb.com/dd/2011/06/02/comic-sans-may-improve-your-reading-retention-says-study/)
agree with all his points!
Depends on what you want. I can imagine a world where someone wants to have different things that build Word16.
Accepting SPJ's pervasive use of Comic Sans is the second most difficult step on the path to Haskell enlightenment, after understanding monads.
[removed]
How was that breaking change not considered to be a showstopper bug in aeson? Edit: Looking through aeson's changelog, the only mention of such a change was for the bug fixed in https://github.com/bos/aeson/issues/53
This can be confusing though, because the 'eval' monad (for one) chains together parallel computations. And it doesn't touch on monad transformers/free monads! Which are a big part of why this can be made reasonable.
Plenty of packages change the way they do things. Even GHC itself has changed Applicative and Monad from being not related to Applicative being a requirement of the Monad type class. I believe Template Haskell has changed a lot between versions as well. However, in these cases you get warnings from the compiler. When you are using Aeson you are generally producing something to be used outside of GHC. This is be problematic if the serialization changes because JavaScript doesn't have nice type safety. Generics for Aeson are naturally quite complicated. Now we have a lot of tests and checks to notify us if serialization changes. I think its a good practice to exercise more control over the way you serialize things in order to mitigate unexpected changes.
Nothing, just me being dumb. Updated (on Github, it'll update on haskell-lang.org at our next redeploy).
I agree. Since operators don't have fixed size (and I include `::` and `.` here), I think they should always come in the end, as much as the `&lt;$&gt;` and `&lt;&gt;` walls are nice to see... It's a pity that Haddock doesn't support it.
I hoped that your style was possible to apply with the arrow-after approach, but unhappily Haddock does not supports the following: function :: Eq a =&gt; a -&gt; -- ^ argument b -- ^ output I really like this as everything that finishes by `-&gt;` is an argument, while starting by `-&gt;` in the other style does not implies the same...
If you generalize to Profunctors, so that your class maps `p a b` to `q a b`, then I believe this is an encoding for extranatural transformations? If so, it should be asked whether such transformations are unique to each pair of f and m; if not, perhaps a newtype is more appropriate than a type class. 
`;)` was the hint. In the 9977 proposal, there was a need for a right `epsilon`. It was more a call on how the layout should look like if we want to `factor` common bits out, and I thought - *let's do it better then go* You are right: for the real proposal, one needs to show how the grammar will look like, not the shape you would like to have. 
Thanks, this looks like everything I need.
IMHO your use case is so irregular that trying to express it with primitive combinators will probably just obfuscate it more, but you can still improve your code's readability by simply making stylistic changes: applyCommRel' :: [Expr] -&gt; Context -&gt; [Expr] applyCommRel' (a1:b1:rest) cr@(CommRel a b c) | a1==a &amp;&amp; b1==b = Plus [Mult [b1, a1], c] : applyCommRel' rest cr applyCommRel' (x:rest) cr = x : applyCommRel' rest cr applyCommRel' [] _ = [] ~~You can further simplify the first line as:~~ (EDIT: Turns out I'm an idiot, so you can't do that) applyCommRel' (a:b:rest) cr@(CommRel a b c) = Plus [Mult [b, a], c] : applyCommRel' rest cr -- Doesn't work ~~But maybe others would think the condition is too subtle?~~ Edit 2: Now that you've fixed the code's formatting, I can see what you're actually asking, you could try: applyCommRel (Plus x) cr = Plus (map (flip applyCommRel cr) x) `flip applyCommRel` flips the argument order of `applyCommRel` so that when you give it `cr`, it'll return a single function that expect s the elements of x
This is very hard to understand. Do you want to uncurry the function so it takes a tuple instead of two arguments?
 Couldn't match expected type `[Expr]' with actual type `[Context] -&gt; [Expr]' In the return type of a call of `map'
&gt; uncurry the function "Currying is the process of transforming a function that takes multiple arguments into a function that takes just a single argument and returns another function" This sounds like what I want to do yes.
I like the look of this style. I wish Haddock parsed it. How would you handle multiple constraints? 
Who cares?
With this style, both of these approaches work for multiple constraints: Foo a =&gt; Bar a =&gt; (Foo a, Bar a) =&gt; 
I did not know about these stylistic effects. Thanks.
 applyCommRel (Plus xs) (CommRel (a) (b) (c))= Plus (map(uncurry(applyCommRel)) xs ) I believe this is along the right lines.
Ooops, I wonder where I got the idea that you could do this. This is obviously impossible since it would logically require `Eq`, and this would give `Eq` a language-level special status.
In theory, yeah, but the Go team wrote gofmt before people had fallen in love with an endless number of different styles. If you wish issue such proclamations now, you are 18 years too late. Trying to retrofit "One True Style" guidelines onto Haskell [isn't going to help anything](https://xkcd.com/927/).
[Image](http://imgs.xkcd.com/comics/standards.png) [Mobile](https://m.xkcd.com/927/) **Title:** Standards **Title-text:** Fortunately, the charging one has been solved now that we've all standardized on mini\-USB\. Or is it micro\-USB? Shit\. [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/927#Explanation) **Stats:** This comic has been referenced 3656 times, representing 2.7927% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_d8rqs5m)
Eq (and Num) do have a language-level special status, but for a different kind of pattern: -- inferred type: -- isZero :: forall a. (Eq a, Num a) =&gt; a -&gt; Bool isZero 0 = True isZero _ = False 
Apache-rewriting /library$ to /libraries would be a nice touch. 
Ah, weird. I would have to dig into `haskeline` a bit and see how they set up that, since adding the whole library as a dependency feels a bit like bloat. I don't have a windows machine to test this stuff unfortunately -- would you be interested helping out there?
Given your requirements, you clearly need to work inside IO (or an instance of MonadIO). unsafePerformIO won't help you here.
Don't do it! Because you'll start trying to reason about *when* it gets called when you get strange bugs; and monads are a structure for reasoning about when actions happen. Plus you'll be able to do things like pluggable versions: one which talks to the system clock once, and one which talks to the system clock every time; and a test harness which can simulate various rates of time flow (from 0 to very fast) and let you test around edge cases like leap seconds. 
You'll want to separate your code into two fragments 1. Code that is atomic with time. 2. Code that changes behavior with time. That is, any code that simply needs one value for the current time can have that passed down as a parameter (or in a Reader monad). In fact, you may find this useful for a number of other reasons; you may have some context about the computation that you want to share (such as current time), which can be stuffed in a `Context` type and given to the hierarchy of computation with the Reader monad. Then you'll want to separate functions which will call those functions with varying context. These functions probably want to use `IO` in order to acquire the needed context in order to pass it down the line.
Maybe you need [coeffects](http://tomasp.net/blog/2014/why-coeffects-matter/). :-P
Just to confirm: so the type constructor `Plus` has type `[(Expr, Context)] -&gt; Expr`? If that is the case, then you are obtaining a list of pairs when pattern-matching, and you need to construct a list of pairs when calling `Plus` on the right-hand side of the equal sign. Since `applyCommRel` returns an `Expr`, not an `(Expr, Context)`, which context do you want to give to `Plus` on the right-hand side?
data Expr = SymT String | Plus [ Expr ] | Mult [ Expr ]
so we are trying to get a plus([expr])
&gt; I've written a library which is pure, [..] that I also verify the data in question against the current time Then it is not pure! Yes it sucks, I know, when you have your lovely pure code base and need to mess it up. But that's why Haskell is great, it forces you to be correct. There are several ways too, for instance: get the current time in `main` and pass it along to your functions as a parameter, or in a Reader monad.
Alright, guys. You've convinced me it's not the right thing to do. I think I actually feel better passing the current time as a parameter to the function that verifies the payment, after all. 
Amazing, exciting, congratulations!
&gt; the paper goes one step further and adds a primitive that gives you a proof of type equality. The former is actually enough for many purpose, including the embedded arrow notation presented in paper. Right. To me the primitive with the proof of equality is the _whole point_. The fact you can do ST with it is just a happy accident.
&gt; most hated font ever challenge accepted. off to redo all my slides in papyrus.
I was actually talking about Elm.
Largely because it's a lot mechanically easier to use functions that take actual functions of Kleisli form than it is to have to wrap and unwrap arrows all the time. Also, the generality doesn't buy us much. And the type inference and instance resolution become a lot harder for GHC. Ultimately, it's just hard to write code that way, and it gives very little benefit
Instead of giving you a solution for your problem (many other comments already give good advices), I'll give you an example where `unsafePerformIO` is acceptable, desirable and safe. Suppose you want to cache the results of a function which can be really long to call, say `f :: a -&gt; b`. You can write it with a `memoize :: (a -&gt; b) -&gt; (a -&gt; b)` function which returns a special version of `f`: `f'`. `f'` returns exactly the same result as f, but first it looks inside a container, like `Data.Map` if the result is available. If not, it compute it and stores it inside the container for following calls. This container modification cannot occur in a pure function. However it does not change the purity of the `f'` function in the sense that its result stays the same, only the time to compute it change. In this case, we can "trick" the type checker to force the type of `f'` to something which does not involves `IO`. This is the same with the `ST` monad. You can do non-pure computation, such as inplace modification of a `Vector`, as long as the external world cannot see theses modifications.
I think you should be very careful while doing something like this, as you can easily introduce multi threading bugs this way! So, purity isn't just about returning the same value every time. Besides, why not use a pure data structure for memoization? Laziness makes this very easy in Haskell. You just define a data structure to contain the results of the function with all possible arguments, but laziness makes sure that they're calculated once first time they're needed.
Bike shed is looking pretty darn good from here.
+1
Using a container makes it possible to delete entries from the cache, to implement a least-recently-used policy for example, while the laziness-based approach doesn't.
This will make it to /r/programmingcirclejerk in record time...
So a Monad is much like the midichlorians...
I really like the idea of terminal-based presentations. Just think of how many stupid presentation clichés it makes impossible!
So you're saying there is power to be had in the dark side. ;) What I want to know is if I can get a purple light saber.
I suppose that if you store the data cache inside an `MVar` you'll get safe multithreading in this context, but I agree that this kind of thing should be done with a lot of care.
&gt; `applyCommRel (Plus xs) (CommRel (a) (b) (c))= Plus (map( applyCommRel xs ) )` You really don't need all those parens, it makes things kinda hard to read ala Lisp. Try `applyCommRel (Plus xs) cr = Plus (map (flip applyCommRel cr) xs)` or maybe `applyCommRel (Plus xs) cr = Plus (applyCommRel' xs cr)` (like your `Mult` case). 
My bad.
&gt; So you're saying there is power to be had in the dark side. Power? No. The pure side is Turing-complete. Explicit state saves us from uncertainly and confusion when refactoring. Immutabilty makes it easier for the mind to master the code. Statics instead of dynamics lets us choose speed or flexibility[1] rather than being a slave to the later, and always risking a bad cast. [1] You can always go with a finally tagless, extensible record encoding for maximum flexibility.
[clckwrks](http://hackage.haskell.org/package/clckwrks)
I appreciated his description of monads as being fundamentally just a type of composition for "complicated functions". I thought the conversation on the whole was interesting and approachable.
Does remind me of J and APL. You know how some people complain that Haskell turns into readable operator soup? J, APL, and Q *start* as unreadable operator soup.
I don't have any links or libraries for you on hand, but I know Facebook does something like this. They load new Haskell code on the fly into a running server whenever a developer pushes to git. I'm not sure if they've open sourced how they did this, but you might be able to figure it out.
&gt; His monad transformer stack is off the charts. Over 20,000!
When you can snatch the pebbles from Ed Kmett's hand, then you are able to leave the monastery.
[I beg to differ](https://www.haskell.org/hoogle/?hoogle=try)
Does not compile. You mean `(&amp;&amp;&amp;)` instead of `(***)`.
My only gripe, and maybe it was just me, was that some of those questions were super long/convoluted/hard to follow. Still, I've been enjoying the videos that Bartosz has on YouTube, as well as his blog posts on Category Theory, and this was another nice explanation of the topic. Pretty cool.
Urxvt and friends support images as well. For nearly 15 years already. Just putting it out there. Just nobody uses it
Are you speaking of hs-plugins or equivalent ? I've been told they don't really work ...
Use spacemacs. Every month spacemacs gets better and getter. One of the biggest complaints I hear about emacs is the long load times. The load times have been cut down to 1.4 seconds using only base and the Haskell layer. My load time with over 40 layers is only 4.3 seconds. Spacemacs' Haskell layer has first class support for intero. You want to be using intero trust me. So much of the Haskell IDE tools are developed for emacs first. When I switched from vim to spacemacs I never looked back. 
I recommend Emacs, not spacemacs (and I say this as a vim user who prefers vim keybindings) but you will have to do more customizing to become productive. I think it's worth it. `use-package` can help get the startup times down, but I have never bothered with this because I always just have emacs running.
I really just wish an intereo plugin would come to atom :( Are there any resources on what specifically the emacs plugin does (e.g. spawn a process, build if x etc)? Except for reading the source code.
I definitely agree with that and had the thought myself. I don't want to give that interviewer a hard time because it's obviously a hobby, but a good interviewer should ask short, to-the-point questions and should also sieze opportunities to explore interesting aveneus of thought. Each question he asked should have been about a third of its length instead of repeating ideas in four different ways in some vain pursuit of clarity.
bad memories: HashMap&lt;Integer&gt; hashMap = new HashMap&lt;Integer&gt;(); 
Spacemacs is fully customizable so you can make it anyway you want. This being said I highly recommend you learn vim key bindings so many people use them for a reason they are very efficient and also quite easy on the hands. 
Yeah... No. Everyone thinks their bindings are efficient, but I've been efficient with a keyboard for way too long in normal editors to switch to vims funky bindings. I need my CUA and I refuse to use an editor where I have to switch modes before typing. 
I think your view is very short sighted and will make you less productive in the long run. Switching modes is literally adding one character to your sentence. But to each their own. 
Modal is definitely much faster. And much better for long term hand health. Also read my comment again then yours. Who is really more calm?
I never said I was "calm," I'm truly sick of vim trolls. My experience with Haskell unexpectedly confirmed also how many smart people use and love emacs like I do, and we never, ever, criticize vim. We certainly don't hop onto a "should I use emacs" and pollute it with "use vim" smartassery. Why would we? Ed K makes vim look amazing in videos, it obviously works for him. Meanwhile I've coded circles around every vim user I've worked with, plus I'm privately convinced Ed would be *even faster* with C-c C-l into an interactive Haskell buffer instead of shelling into ghci, but who cares? 
&gt;Is there a straightforward way to understand when point-free is ok, performance-wise, and when it isn't? I might be wrong, but I'm fairly certain point-free is syntactic sugar and it compiles to the same code.
I really doubt that point-free somehow affects performance. I'm almost sure your examples would compile in the same code. But sometimes overuse of point-free style leads to very bad readability, excessive use of functions like flip and ap and ASCII nightmare of dots and parenthesis. For example, readable function foo f a b = (f $ snd b) ++ (f $ snd a) can be replaced by ugly foo = ap ((.) . flip . ((++) .) . (. snd)) (. snd) I use point-free when I see I can use it AND it doesn't affect readability. 
Well the calm down and quit acting like a baby just because someone hurt your feelings. And I'm pretty sure you do criticize vim, so that is probably just a lie. Hahaha yeah I am "sure" you coded circles around competent vim users, sure thing buddy. Ed would definitely not be faster with Emacs, because it is not a faster editor.
See [this](https://github.com/ekmett/succinct/blob/master/HLint.hs#L3). I used to follow that HLint suggestion whenever I could.
Disclaimer: This is just my understanding of GHC, I’m not an expert here. GHC inlines functions only when they are “fully applied”. What number of arguments need to be passed to a function for GHC to consider it fully applied is based on the syntactic definition. So if you define `foldr f x = …` it will inline when at least two arguments are passed while if you define `foldr f x xs = …` it will only inline when all three arguments are passed. Eta reduction/expansion change the number of arguments that are applied to a function and thereby change whether GHC will inline a function. Since inlining often enables a bunch of other optimizations this can have a dramatic effect. Going back to your question: When does point-free syntax affect the performance? When the functions that you are calling are no longer fully applied after eta reduction! In your specific case `.` is fully applied so it will inline to `\x -&gt; f (bar x)` at which point you have your manually eta expanded version so there should be no performance difference.
these days HLint would have you write `foo f a b = f (snd b) ++ f (snd a)`. There's a notion that `$` harms readability, which I don't totally agree with (thus my secondary q in the post). Yes flippity flip and curry/uncurry is silly, basically somebody's been harrassing poor lambdabot when you see that. Effective point-free (eta reduction mainly) can enhance readability. 
I just did a quick test ouputting GHC Core, and your example appears to compile to the exact same Core whether or not you use point free style. data Foo = Foo { bar :: Bar, baz :: Baz } invoke :: MVar Foo -&gt; (Bar -&gt; IO a) -&gt; IO a invoke m f = withMVar m (f . bar) However, this is a single test, and I don't know the limitations. I believe the `(.)` operator is inlinable. So any time that you can just trivially plug that in, GHC should inline it to get the exact same expanded lambda. However, I imagine there are less trivial cases where this isn't true. But I can't really think of any such that that would come up on a regular basis. EDIT: The concern may be about [eta-reduction](https://www.reddit.com/r/haskell/comments/57napf/pointfree_fear_and_loathing/d8tbxp0) (which this example is not). I don't know how GHC optimizes that, but I have no idea why it would be a problem. Would really love to hear some thoughts on how eta-reduction could be a bad thing.
I don't think Intero works without Stack, by design.
I don't think /u/basil-slap is advocating for additional administrative overhead. "Just" switch your application architecture to be multi-process with each plugin isolated to its own process(es).
[Try `applyCommRel (Plus xs) cr = Plus (map (flip applyCommRel cr) xs)`](https://www.reddit.com/r/haskell/comments/57fovt/applying_map_to_a_function_with_two_arguments/d8s96ir) 
Thanks. Fixed.
&gt; Effective point-free (eta reduction mainly) can enhance readability Yes, I agree. But overuse of it can lead to unreadable code. 
&gt; So you're saying a company may not get permission by their lawyers to use my software, because of this (absence of a) license? Yes. It need not be a company. Any legal entity might *justifiably* ignore your public domain dedication, because of the dubious lack of precedent backing such dedications. If they did so, and you provide no other license, they would have to operate under the full restrictions on copyright law. The FSF [recommends the use of CC0](https://www.gnu.org/licenses/license-list.html#CC0) instead of *just* a public domain dedication. CC0 includes a public domain dedication and, if that fails to hold legal weight, also provides an extremely permissive license.
You are probably right. Still seems overly complicated compared to standards "plugins".
I mean random elpa packages. So for example, if you want to use haskell-mode, you would to need to write a bunch of evil-leader bindings. I use emacs with at least a half-dozen different language each of which has several elpa packages, almost none of which come with evil bindings.
Oh, I see. That does sound like a palaver. 
What happens when you "relax" the constraint on `id` to `id :: (c |^ x , c |^ y , x ~ y) =&gt; c x y`?
"Could not deduce: y ~ 'CTy c0 a0" I'm really concerned that there is essentially no unification taking place here. The clear strategy is to instantiate x as CTy c0 a0 and unify, but maybe I'm misunderstanding something about Haskell's model of doing this.
I think something else is going on (i.e. misleading error message). For composition you match on constructor so there's no problem unifying an `x` with a `CTy c a`, but with `id` there isn't. So, the way you're defining `id :: c |^ x =&gt; c x x`, GHC can't figure out that `x ~ CTy c a` for some a, there's not enough injectivity thrown in for it to figure that out I guess.
I believe it uses the global package in ~/.stack off the top of my head.
Spacemacs also has a minimal base meant for customization. Sure the load times will be better with vanilla Emacs but I'm sure once you start adding evil and other extensions it'll slow down compared to Spacemacs. 
I parse it as the comment means is that HLints advice to manually eta reduce is never useful.
By not eta-reducing, you can match a rule. id . f . id -- apply identity twice f Don't know how/whether these optimizations are staged though. edit: nevermind, it's "by not eta-expanding".
everyone talks about spacemacs=vim. this is nice, but what turned me off of spacemacs was the layers config abstractions. It breaks the normal configuration of emacs. Just install evil mode and a few contrib packages.. that's spacemacs lite. The overengineered/complicated Layers system is why I abandoned spacemacs after trying it. Just installing Evil mode served my needs better. (require 'evil) (evil-mode 1) (require 'undo-tree) (require 'evil-matchit) (global-evil-matchit-mode 1) (require 'evil-surround) (global-evil-surround-mode 1) gets you basically 99% of what spacemacs has. (evil-surround, evil-leader, evil-matchit)
I can test it if you send me a commit. Haskeline has very lightweight dependencies.
Here's sort of a stream of consciousness about the issues involved with eta expansion in Haskell: INLINEing only ever happens when a function is applied to all of the arguments it has on the left hand side of the = sign. The difference comes when expanding 'f'. Say the definition of f gets inlined into g, but g doesn't get inlined into its caller. (You'd need something a little more complicated than this for that to happen. Let's say g = whatever . f vs. g = \x -&gt; whatever (f x) In both cases you might inline a large `f`, but if `f` takes arguments, that can only happen after we inline (.), and of course well-written RULES will only fire if it also inlines `(.)` in the former case. (.) here is still too simple for this to really be a problem, but I offer it up as an example. (And, putting a RULE on `f . g` is kinda silly as nothing stops `.` from inlining immediately, and you'll get warnings up the wazoo.) This can backfire, though, as eta-expansion isn't free. `\x -&gt; f x` and `f` have different costs. In fact back in the day, this actually caused derived `Functor` instances to be quadratic in performance until Twan fixed them. (We found this out by exploring the core generated by lens.) (If you incur n eta expansions each operation takes n steps longer to compute!) One observable semantic difference between `\x -&gt; f x` and `f` is that the former is always safe to `seq`. While the latter can be \_|\_. In theory you could write all of your code eta reduced, and with lambdas on the right hand side of the = sign, but it doesn't make for idiomatic haskell; it destroys backtracking on pattern matching and it destroys `where` clauses. In the case where you eta reduce one argument out of 2-3 argument list if the compiler doesn't get to shuffle things around you'll be making some kind of closure on the heap to hold some of the arguments, and the rest will come from the stack, so you can get some differences in how much stack is being used vs. how much heap allocation your code yells at you about. The eta expanded code will give you better metrics in terms of garbage produced. If the compiler doesn't see both halves of the application and somehow move them together, which I've just not seen it do, it'll typically turn into one call to build the partial application and another call to invoke it.
This is because `id` is polymorphic in `x`, no? Same reason you cannot write: data Foo a where Foo :: Foo Int foo :: Foo a foo = Foo -- type error
I understand why it is true, but the reason that it's okay in this case is that there should be an injectivity constraint at the kind level which forces x to understand that it is equally general for him to unify with ('CFun c0 a0). This is how I would like data to be generalized anywho, maybe its not how its implemented like this in GHC. How can you program over data at the kind level if you can't pattern match on it?
I don't think you have to use vim keybindings; in [.spacemacs](https://github.com/syl20bnr/spacemacs/blob/master/core/templates/.spacemacs.template#L98-L104) you can also choose "emacs" or "hybrid" modes. 
I believe all our C++ is Backend. If you are interested in C++ and 3d rendering, you could consider [this one](http://www.imvu.com/jobs/index/senior-full-stack-engineer-3d-tools/)
My philosophy has always been that point free doesn't affect performance (and if it does, that's a bug in GHC).
To your aside: a chain of `(.)` optionally followed by a single `($)` is a nice clean style that a lot of people recommend, not least because it provides an intuitive syntactic link between pointfree style and function composition. Being generally used to that, I think having `(.)` _after_ `($)` is what's producing the sense of wrongness there.
GHC doesn't currrently support this, but it could, given some FC extensions: https://ghc.haskell.org/trac/ghc/ticket/7259
Nice. Any tips on how to get to know FC?
Looks like you're missing the 'else' part of your 'if' expression. Btw, ghc will give you much more sensible error messages than hugs.
&gt; Btw, ghc will give you much more sensible error messages than hugs. They're a student learning the basics of Haskell, on Windows; they might not be up to installing the GHC toolchain on their box (and/or might not have the administrative privileges to do so). Or were you simply trying to say "Please don't think that all Haskell compilers/interpreters provide such less-than-helpful error messages!"?
Please indent each line of your code with four leading spaces (without a '&gt;' at the start of any line), so that reddit doesn't alter its formatting.
Thank you :)
&gt; Would you agree that &gt; &gt;&gt; forall x :: ConstrainedType. x ~ CFun c a GHC does not agree, no. Let's look at a simpler example. {-# LANGUAGE DataKinds, GADTs #-} data Unit = MkUnit data Bar unit where MkBar :: Bar 'MkUnit bar :: Bar unit bar = MkBar -- type error It's the same example as /u/MitchellSalad's, but while `foo` should be rejected because `Foo` is not a valid value of type `Foo Bool` for example, no such counter-example exists for `bar`, because the only valid type of kind `Unit` is `MkUnit`. This is the core of your issue: you have a data type `ConstrainedType` whose values all have the form `CTy c a` for some `c` and `a`, but you can't convince GHC that an arbitrary `x` of kind `ConstrainedType` has that form. This simpler example has the same issue: we have the data type `Unit` whose values all have the form `MkUnit`, but we can't convince GHC that an arbitrary `unit` of kind `Unit` has that form. You are clearly used to working with dependent types, so let's see how Agda deals with this issue. data Unit : Set where MkUnit : Unit data Bar : Unit → Set where MkBar : Bar MkUnit barAgda : {unit : Unit} → Bar unit barAgda = MkBar -- type error: MkUnit != unit Surprisingly, Agda complains about the same thing as GHC! Even in a full-fledged dependently-typed language, the compiler doesn't immediately see that an arbitrary value `unit` of kind `Unit` must have the form `MkUnit`. In Agda, however, there is an easy fix: pattern-match on `unit`. barAgda' : {unit : Unit} → Bar a barAgda' {MkUnit} = MkBar -- type checks &amp;nbsp; &gt; How can you program over data at the kind level if you can't pattern match on it? So the reason we could pattern-match on `MkUnit` in Agda is that `{unit : Unit}` is a real argument, which `bar` receives at runtime and can inspect. In Haskell, types are erased at runtime, so it's not possible to write a value-level function which pattern-matches on a type variable in order to choose what to return. In order to pattern-match on a type, you must either stay in the realm of types by using a type-level function, that is, a type family: {-# LANGUAGE GADTs, TypeFamilies, TypeInType #-} type family BarFamily (unit :: Unit) :: Bar unit where BarFamily 'MkUnit = 'MkBar Or you can define a singleton type, thereby creating a runtime representation for your type on which you can pattern-match: data SingUnit unit where SingMkUnit :: SingUnit 'MkUnit barSingleton :: SingUnit unit -&gt; Bar unit barSingleton SingMkUnit = MkBar 
I don't see why any C code is needed. It is shown that ccalls can me made direct from rust, so why not call hs_init directly instead of wrapping it trivially and then calling that?
Agreed!
 foo f = (++) `on` f . snd
I know. Probably an orthogonal route with approaches like autodiff is the practical way to go. Still, there's a lot of useful territory between nothing at all and full-blown mathematica replica (look at sympy for example).
Or even Maxima, which would be nicer to work with if it was more typed.
&gt; I use stack cuz I have to for apps, but as soon as new-build is standard I'm going back to cabal, and still only cabal for my O/S libs. Why would you ever want to go back to cabal? Once you go Stack you'll never go back!
Luckily there's an easy workaround for that. Somewhere in your Emacs init file, you probably have a line that adds intero-mode to the Haskell-mode hook. You can just get rid of that and bind intero-mode to a convenient shortcut (I do "C-.").
If you write the same function twice, except that one of them is eta reduced, then the reduced one will be fully applied in every case that the expanded one is fully applied, and more. So the only way it affects inlining behavior is by inlining more easily.
That's what "I use stack" means: I've "gone" stack and I want to go back. I have gone back for my O/S libs. The curated thing is nice for getting started but it becomes a problem as soon as you get serious about releasing a lib to the world. As most things I do will eventually get released, stack becomes a form of tech debt. 
I'm not as familiar with rust but isn't there some kind of extern declaration? EDIT: Wrote too soon. You declared the init and fin as extern why not just use the hs_init directly?
Can you link a file that didn't work?
Yeah, I opened [an issue](https://github.com/commercialhaskell/intero/issues/289) with some questions regarding some of the behaviour and to see if I had the understanding of how it works down. Flycheck would probably be replaced with [linter](https://atom.io/packages/linter) and company-mode with [autocomplete-plus](https://atom.io/packages/autocomplete-plus) in Atom. Unfortunately the elisp doesn't give me that much, the spec is a bit more helpful, but some plain ol' english would be even better :) 
One thing that may help you think about `if` in Haskell is that `if` is an expression, it returns a value, so that both branches of the `if` / `then` / `else` must be present. This is in contrast to imperative languages like C, C++, Java, JS, Python etc where `if` is a statement that does *not* return a value.
Thats not 99% of spacemacs. You layers and all vim keybindings for packages. 
The types are strong in this one.
You might look at gitit's plugins system, which uses the GHC API. https://github.com/jgm/gitit#plugins https://hackage.haskell.org/package/gitit-0.12.1.1/docs/Network-Gitit-Interface.html 
In a package with a library and an executable, can I have a parameterized library and a non-parameterized executable?
I think you may be a little over-conscious of the problem. It seems quite rare for Ed's concerns to materialize in most code. If you're very concerned about performance, then his points are important to keep in mind; but I'd say the vast majority of code will be unaffected. So it seems to be a premature optimization, and I'd say you should fix issues as they appear instead of wasting time trying to deliberately avoid point free.
You should look up [Data.Traversable](https://hackage.haskell.org/package/base-4.9.0.0/docs/Data-Traversable.html) and its `List` instance. You should then be able to write something like this : files &lt;- traverse readFileNumber [1, 2, 3, 4] or files &lt;- sequence [readFileNumber 1, readFileNumber 2] 
You want `traverse` (https://www.haskell.org/hoogle/?hoogle=%28a+-%3E+IO+b%29+-%3E+%5Ba%5D+-%3E+IO+%5Bb%5D). E.g. `traverse readFileNumber [2, 3, 4] :: IO [[String]]`
Interesting question. That's kind of in line with my question: Can I instantiate a parameterized package twice? Like, can I use a parser library with both `Text` and `ByteString` in the same project?
Thank you so much for the detailed explanation of why this is currently disallowed. I could imagine that it might be useful to be able to extend the language to allow this, however, no? Is there any particular reason why this is an undesirable feature? What I would really like to do is to be able to write a proof externally and convince GHC all is well.
Personally, I follow the "when in Rome..." strategy. I may strongly prefer purely functional programming, but I'm gonna stick to the conventions of whatever project I'm working on. If I start on some highly OOP Java codebase, I'm going to keep it OOP. I may start using some optionals and streams to make life a little easier, but I'm not going to start making architectural decisions based on Haskell conventions. Clean code fits snugly in its ecosystem. In Haskell, that ecosystem is pure, and it's nicer to me. But trying to port that style of code to Java is not going to fit snugly in the OOP world.
It's fairly well understood that a transpiler is a compiler that produces code, not assembly or machine code. 
Ultimately, the universe is just one giant quantum mechanics equation, and quantum mechanics operations are not only functionally pure, but unitary - IE not only does the input fully determine the output, the output fully determines the input!
I've been writing a lot of C++ lately. The thing that really makes me want to do more in Haskell though is that when I build a sufficiently complicated template, I don't really get to know until I instantiate it at concrete types if I've completely screwed up and the thing I have will never work. Often that can be days later, and then I have to go back and page in all that work I did on my template. Playing static-assert games and modeling concepts and the like can help but SFINAE means it can be very hard to know if you've got it all right without exercising every single one of the parts. =(
I agree with your management. You didn't get any direction or instruction to do this, right? You should be working on the priorities your bosses set for you, not trying to fit a square peg into a round hole because round pegs frustrate you now that you've "seen the Light of the Square." If you're on a dev team, this is especially egregious because you can't just change the way the entire codebase works unilaterally. Your team has an understanding of how things are and conventions that are in play. You also touched huge amounts of the code, which, depending on your industry, might require a code review of *every single change.* I think the right way to approach this would have been to open a dialog with your management and team about the benefits of functional paradigms, get some buy-in and excitement going, then get the codebase updated. Why would the counseling sessions be "of course, unsuccessful"? It sounds like their diagnosis of your situation was spot-on. I'm glad you were able to move on eventually, but I would recommend giving it another shot. There are a lot of red flags in your story that all point to long-term professional unhappiness. If functional programming is really so important to you, you won't be happy unless you find a position that allows you to revel in it. I hope this doesn't come off as overly-critical. Thanks for sharing your story. Best of luck to you.
At least you still get the error at compile time :)
Well the point wasn't really about Java. More about following project conventions. If the conventions aren't pure and functional, I'm just gonna live with it.
It's purely a connotation thing. If I tell you I've built a Lisp compiler, most people assume it compiles to machine code, or LLVM or something. Transpiler makes it clear. It's not necessary, but it helps. 
Today's Dilbert cartoon is apropos as usual. Hopefully you can find other employment more to your liking. In the meantime it will be to your benefit to do the work they are paying you for, even if you don't like it.
[source](https://twitter.com/expersso/status/787694694851547136)
I agree. Every time I have to do some specific programming task, I usually tell myself: "Well, it'd be so easy in Haskell if I do this and this, but since this is JS/Java/PHP, I'll have to do it this other way around". Although I like Haskell very much, keeping code idiomatic is better.
Also yes! This blog post http://blog.ezyang.com/2016/10/try-backpack-ghc-backpack/ has some runnable code where a regex engine is parametrized over String and ByteString. In Cabal, the way you do it is you mixin the package twice.
C++ is indeed very amenable to FP, if you can do with the ugly template syntax, horrendous error messages and long compilation time. I had to work on one project where a colleague of mine went a bit overboard with this, so much that we were the only two to still understand the code. Needless to say, management was not pleased.
Wave function collapse is not functionally pure.
It's gotten a lot better with the new constexpr functions which replace a lot of the ugly template code
It does under the Everett interpretation, that appears to be the only one that gives account of all the facts, since there is no collapse (two cents) 
Unrelated question, does traverse suffers from the same memory leaks as mapM? I wonder if the Applicative contraint instead of the Monad one allows the results to be treated independently.
In my humble opinion, Haskell is more than functional. It is category theoretical. And CT encompasses both functional and imperative programming under a single principle. In the other side, sequencing is necessary. There are problems that are inherently sequential. For example, the graph reduction algorithm that executes lazy haskell programs. Working with finite resources makes mutability unavoidable. mutability is an optimization whose side effects can be hidden in order to keep purity. The garbage collector is the engine that carries out such task of letting the program to believe that it is pure and works with almost infinite memory. So think that in C++, mutability exposes to you an optimization that may be dangerous and you should care about
I used the term wave function collapse because there's no interpretation agnostic term for the observable phenomenon it describes. There are several consistent interpretations of quantum mechanics in which wave function collapse doesn't objectively occur, but none in which calling observables the outputs of pure functions is accurate.
That's like calling all functions in Haskell impure because an internal observer (the runtime system, or the thunks themselves) can 'tell the difference' between a thunk and the value it evaluates to. Indeed, if there was such a thing as the experience of being a thunk, they would declare the same thing to be true of the supposedly 'pure' Haskell operations - that an evaluation 'collapse' occurs, and that it would be inaccurate to label the "Haskell universe" as one of pure operations.
`mapM` does not leak memory. It might take up more heap than the programmer intended if you want to ignore its result, but that's not the case here: the result is required.
When I discovered Haskell, I also discovered the concept of `Maybe` and immediatly applied to our C++ code base, but because C++ does not have pattern matching, it leads to code like that : Maybe&lt;float&gt; res = f(); if (res.isJust()) { doSomething(res.fromJust()); } Then I'll understood the concept of `Functor`, `Applicative` and `Monad`, and our code base evolves to: f().map([] (float res) { doSomething(res); }); Finally, I was bored with all the lambdas and the parenthesis, so I overloaded some C++ operators, mostly `&lt;&lt;` and `&gt;&gt;`. My colleague hates me, but finally they like it. Then, I was so in love with sum types, that I used sum types everywhere in our C++ codebase : struct Something { enum class Flag { SUB_TYPE1, SUB_TYPE2, SUB_TYPE3 } _flag; union { t0 sub0; t1 sub1; t2 sub2; }; }; foo(Something &amp;s) { case(s._flag) { // I let you imagine. } } And I mostly got fired.
Your company allowed an employee to suspend their work for a whole week to perform a pervasive change against the current conventions of the team, without any instructions or prior agreement. I think they have a bigger problem than imperative code. How could you even allocate this time without asking your manager?
Surely that's just the first place it fails. What about the IO manager, for example?
A **transpiler** is a compiler that transforms from one programming language to another at the same level of abstraction. That is from high-level to high-level or from low-level to low-level. It is usually implied to be from high-level to high-level. A **decompiler** is, funnily enough, also a compiler. It works from a lower level of abstraction to a higher level. A **compiler** can both mean the general term — that is any `a -&gt; b` code transformation — but it is usually implied to go from a higher to lower abstraction level. An example is from a high level _(Java)_ to low level _(bytecode)_ or from low level _(assembly)_ to machine _(binary instructions targeting a given machine architecture)_. All of the above are compilers, but they imply different things. You can call them all compilers, and you would not be wrong, just like you can call both an airplane and a car for a vehicle. It is just more useful to say you've built a car if that is what you've done.
Very cool! One minor critique: Not totally convinced that a test suite testing that responses all occur within 100ms is very helpful. Production deployments tend to occur in fairly different environments / hardware setups than development, so it's pretty likely to induce a false sense of confidence. Factor in production-level middleware, higher database load, etc., and it's a totally different picture than locally. To anyone who uses this, please benchmark endpoints responsibly by ensuring that your benchmark environment is as representative of your prod environment as possible.
You could use the built in prometheus metrics to report the response times and analyse them later instead of course.
Great stuff, Heinrich! I prefer native guis for many reasons, but given that it's split into a server backend, can I access it with my normal browser as well, or does it require local file access not available to a normal browser's javascript?
Thanks. :-) &gt; can I access it with my normal browser as well, or does it require local file access not available to a normal browser's javascript? In principle, yes. Note that file access is also split between front-end and back-end: The front-end contains all the logic dealing with worksheets, whereas the back-end is really just a very thin REST API for evaluating Haskell expressions and setting imports, it doesn't know anything about worksheets. Have a look at the [`jsonAPI`][code] function. Of course, the back-end needs access to a Haskell package database, and also to any files that you want to load with it (the equivalent of GHCi's `:load` command). Other than that, talking to the server is just like talking to any other REST API. (If you are thinking about hooking the server up to the internet: I can't recommend it for hyper-haskell-server-0.1.0.0 because it -- obviously -- allows arbitrary code execution on your server. But do have a look at [Péter Diviánszky's `ActiveHs`][divipp] project, he did something like that. I'm happy to accept patches as well, e.g. about `SafeHaskell` etc, but it's not a priority right now.) [code]: https://github.com/HeinrichApfelmus/hyper-haskell/blob/master/haskell/hyper-haskell-server/Main.hs#L62 [divipp]: https://github.com/divipp/ActiveHs
I'm mainly interested in avoiding reliance on a separate, embedded browser engine, when I already have more than one at my disposal. 
Say I wanted to write a native gui ala gnuplot for this, would I have to go through REST or is the Haskell API deemed stable? I mean, the README sounds like you would at some point add a native gui, but I may be interpreting things.
The advantage of bash on windows is that one can use apt to install packages. Currently, we're using MSYS2 and MinGW on Windows. MSYS comes with pacman, so one can install many packages from MinGW. So, the question is: would there be many more packages available on bash for windows as compared to MSYS/MinGW? If yes, then certainly it makes sense to invest in replacing MSYS/MinGW with bash for windows. Of course, the caveat is that bash for windows is only available for Win 10, so users of older versions would have to stick with MSYS/MinGW.. And now we need to maintain support for two instead of one.... 
Would this work better as an [awesome list](https://github.com/sindresorhus/awesome) since all non-official templates have to be specified fully anyway? Benefits seem to be less maintenance effort and people don't have to go through the effort of PRing more than a link to their templates repo. Also, I use [this repo](https://github.com/ChristopherBiscardi/stackify) for a tool that pulls a project folder into a `.hsfiles`. It includes a [servant template](https://github.com/ChristopherBiscardi/stackify/blob/master/dist/servant-pg-simple.hsfiles) (and [raw project](https://github.com/ChristopherBiscardi/stackify/tree/master/raw/servant-pg-simple)) example. It may be useful to other people too.
&gt; the README sounds like you would at some point add a native gui, but I may be interpreting things. I'm not sure what you mean. I guess I meant something else. Note that the separation into front-end and back-end is not just because of the JavaScript stuff, but also because of the following fact: *The interpreter has to be compiled with the exact same version of the `Hyper` module as all other packages that you want to interpret with it.* That's why it makes sense to split front-end and back-end, regardless of what GUI framework the former is implemented with. It's similar to the problem of GHC fixing your version of the `base` package. My remarks in the README refer to the possiblity of, if not outright *linking into*, then at least *bundling* the back-end with the front-end, i.e. provide a precompiled package databse and a `hyper-haskell-server` executable in the download. &gt; Say I wanted to write a native gui ala gnuplot for this, would I have to go through REST or is the Haskell API deemed stable? If you link with the Haskell API, then you run into the problem above. The REST API seemed like the simplest solution, and I guess I will stick to that for now. I'm not sure if it will stay stable, but hey, it's only four functions at the moment. :-)
The next step up if these things get to be really important is to reify times in your application. The usual approach is to think about time-ordered sequences and time-varying values; probably you want to think of: type Time = Int newtype Event x = Event (Time, x) newtype TOSeq x = TOSeq (IntMap x) newtype TVVal x = TVVal (Time -&gt; x) and things that convert between them. It's overkill for the whole "check if the transaction time is within epsilon of the current time" logic that you seem to be describing now, but being able to insert events into a `TOSeq evtType` and then describe functions `TOSeq x -&gt; TOSeq y` which, say, compute the current balances in a set of accounts, can get really powerful. 
I did not know that project, and it looks promising on many aspects, especially the part about the list Items being awesome. 
Looks like it's `kqueue` and friends on Linux: * https://ghc.haskell.org/trac/ghc/wiki/Commentary/Rts/IOManager * http://haskell.cs.yale.edu/wp-content/uploads/2013/08/hask035-voellmy.pdf 
Thanks for this; I thought the article was well written and easy to follow! I'll no doubt draw inspiration from it, as a project I have in mind (but may never get around to) partly involves writing an interpreter and my own (fairly basic) language.
I have been looking forward to this for a while! Will this aim to address the String/Text issue by parameterising base over the representation used - so we can take a base-indef and apply it to Text instead perhaps - or is that something that will happen further down the road (or is it just plain impossible given how things are wired up)?
This is a valid concern if you want to make Windows binaries (without cross-compiling). The Linux subsystem is similar to WINE, in that it runs native Linux elf binaries.
Well, we *do* have a significant amount of C++ in the old client; I just don't know if we're particularly looking for more client engineers right now, which might have been what you meant. Also, although our new C++ rendering engine is primarily compiled for android, iOS, and javascript through emscripten, we have been starting to do some research projects building it as a windows DLL, although those aren't fully-funded enough to hire for at the moment. While I believe I'm slightly more technically correct, I agree with you that the tools team position is the C++ position we're primarily hiring for.
Thanks for providing the documentation! I did read a bit trough the PDF and it looks like it is using `epoll` on Linux while `kqueue` is used as an alternative on BSD: &gt; On BSD systems such as FreeBSD, NetBSD and OpenBSD, Mio uses the kqueue subsystem, as epoll is unavailable on these platforms. WSL is listing support for the following syscalls: EPOLL_CREATE EPOLL_CREATE1 EPOLL_CTL EPOLL_WAIT EPOLL_PWAIT ;; Added more recently, only for insiders at the moment It looks like that it is also capable to fall back to using `POLL` on systems where `EPOLL` is not supported, so we should be good!
👍 both of these features are wonderful
You could. You can also do that in C or Python or whatever. I did it in Haskell.
I'm curious; when I read about Backpack before, I remember there was something about type-class anti-modularity being a problem. How was this solved, how does Backpack interact with type classes?
 Prelude&gt; import System.Random (randomRIO) Prelude System.Random&gt; let pick xs = fmap (xs !!) $ randomRIO (0, length xs - 1) Prelude System.Random&gt; data RPS = Rock | Paper | Scissors deriving (Enum, Show) Prelude System.Random&gt; print =&lt;&lt; pick [Rock .. Scissors] Rock Prelude System.Random&gt; print =&lt;&lt; pick [Rock .. Scissors] Paper Prelude System.Random&gt; print =&lt;&lt; pick [Rock .. Scissors] Paper Prelude System.Random&gt; print =&lt;&lt; pick [Rock .. Scissors] Paper Prelude System.Random&gt; print =&lt;&lt; pick [Rock .. Scissors] Scissors 
Can I recommend that you generalize the type signatures to avoid hard-coding `Void` as the output for `udpSink` and `()` as the input for `udpSource`? This will make it easier to reuse these functions in more generalized contexts. And yes, I noticed that you're [avoiding the type synonyms](https://github.com/snoyberg/conduit/issues/283) :)
Well thanks for reading it! Good work. I'm afraid I only skimmed it before posting the links. I think the mechanism ghc uses is could in, isn't it? That would mean it would not fall back at run time.
&gt; It seems very confusing that two functions with the same type could be treated very differently. Tell that to the guy that invented the monomorphism restriction, another time when the specific syntax used triggers behavior in the compiler. In this case, sometimes changing the type.
Coding fonts with ligatures are my new favorite thing!
&gt; If I start on some highly OOP Java codebase, I'm going to keep it OOP. Most "highly OOP Java codebases" use design patterns that basically implement functional paradigms and architectures in OOP Java code. And this is considered a good practice.
I created an account and tried to vote but when I click the vote button nothing seems to happen :( While I do want this improvement I would also love to see GHC work with the "native" windows tool chain (aka msvc). Taking inspiration from Rust, they have two toolchains on windows and they are good at different things. They have the gnu toolchain which works like GHC currently does. The really nice thing about it is that you can install dependencies with msys2's pacman. They also have the msvc toolchain which builds programs and libraries that more naturally interop with other windows libraries and programs, but is incompatible with mingw libraries (as far as I can tell).
I showed that you can do this with yesod and hint. Reloading the code on page refresh. I'll find an example tomorrow. At least reloading the view, i.e. The hamlet template or the lucid.
 defRandIO :: (Enum a, Bounded a) =&gt; IO a defRandIO = randBound minBound maxBound where randBound :: Enum a =&gt; a -&gt; a -&gt; IO a randBound l h = fmap toEnum (randomRIO (fromEnum l, fromEnum h)) You can even make an instance of the typeclass (I'm sure there are some pitfalls to doing this) import System.Random import Control.Arrow defRandomR :: (Enum a, RandomGen g) =&gt; (a, a) -&gt; g -&gt; (a, g) defRandomR (l,h) = first toEnum . randomR (fromEnum l, fromEnum h) defRandom :: (Enum a, Bounded a, RandomGen g) =&gt; g -&gt; (a, g) defRandom = defRandomR (minBound, maxBound) data RPS = Rock | Paper | Scissors deriving (Enum, Bounded, Show) instance Random RPS where random = defRandom randomR = defRandomR
Didn't you rather mean to call this [ow-my-stack-templates](https://www.youtube.com/watch?v=r_4jrMwvZ2A)?
It's like saying you drive corvette instead of saying you drive a car. It's still a car, but more specific.
You can't just run code after it has been transpiled. You need to either interpret it in something or compile it again.
FWIW, you can use IHaskell with regular Haskell files using things like `org-mode` in emacs. I don't know how many people other than me actually do this, but it does work and means you don't need to use any special kind of file format.
*Every* other framework is faster, in my experience, because they are much smaller. I've actually taken to just using Warp and gluing in stuff by myself, testing it in GHCi. My ability to see the changes quickly in a browser is limited by the rate at which I can hit the relevant hotkeys.
GHCi works great for web dev. you definitely should not be recompiling yesod on every edit. For _real_ hot code reloading, I've heard good things about rapid and halive although I haven't used either myself. https://hackage.haskell.org/package/rapid https://hackage.haskell.org/package/halive
Yeah I think this similar to what I described in "Future Work" near the bottom, right? The whole plug qdisc is unfortunate and not something I anticipated having to use. nginx has seen performance improvements from SO_REUSEPORT so I think it could be valuable even if the zero downtime aspect comes from fd passing.
Essentially what /u/schmook said. There is a `Display` typeclass for things that can be converted into `Graphic`. At the moment, the `Graphic` type has two smart constructors, `string` for embedding a `String` and `html` for embedding arbitrary HTML. See the [documentation of the `Hyper` module][hyper]. For now, I suggest embedding the image data (PNG or something?) in HTML in some way. Suggestions on how to improve the `Graphic` type are most welcome as well, I'm happy to add new smart constructors. [hyper]: http://hackage.haskell.org/package/hyper-0.1.0.0/docs/Hyper.html
Yea, we're doing orderly shutdown on a `SIGTERM` by closing the accepting socket &amp; then waiting a bit ("lame duck mode"). That introduces more latency than the solution in the blog post but doesn't drop any connections. So this is definitely the poor-mans solution. We only deploy 5-10x per day so it's not been an issue so far.
Definitely be that guy, I discuss the advantages of this approach versus using a load balancer in the post
if you use warp you can wrap thread forking and keep track of open conmections to make sure you don't shutdown while there are outstanding requests. This is how it worked at IMVU.
Hasklig?
This is interesting to me. I started a job at the beginning of the year where they wanted to use docker for stuff and I quickly started learning how to build Dockerfiles that take advantage of caching and also that we had to delete old, dead images and remove processes. Our setup is very limited so probably not at all relevant to what you're doing, but we've got cleanup scripts that do stuff like this: docker stop $(docker ps -aq) docker rm -f $(docker ps -aq) docker build -f dockerfile -t tagname . docker rmi -f $(docker images -q --filter "dangling=true") We also always start processes with `docker run --rm`, and I actually froze a few EC2 instances from exceeding disk space before I learned all of this stuff and I had to go in and manually delete `/var/lib/docker/devicemapper`, but since then I haven't had any issues, and it seemed like my problems were all related to not understanding Docker well enough. I did see some bugs that existed and something about the default filesystem stuff, which I don't remember well enough, but your comment has me concerned that there are other looming things I don't know about. It's all going fine now (for about four months) and Docker seems to be used in production at huge companies, so I'm curious what's going on. For instance, when you say this: &gt; It tends to have trouble cleaning up images on restarts or incomplete starts. Does that mean that you can't forcefully delete those images?
 docker rmi -f $(docker images | grep "&lt;none&gt;" | awk "print {3}") ... can also be achieved with: docker rmi -f $(docker images -f dangling=true -q) But beware, both of these approaches introduce race conditions with any other builds in progress.
There is a way around: take a look at `app/DevelMain.hs` and [this little video clip](https://www.youtube.com/watch?v=1akOBGihKNs).
Hm, no actually not. Although I find this funny, I also find it a bit insulting. If you have maybe another way to tell me why you find the project or name idiotic or stupid, please go ahead and tell me.
Well you could also have a pure language that mixes HoFs, parametric polymorphism, and subtype polymorphism. But I guess I just don't see why subtype polymorphism is fundamentally reliant on mutation.
A compiler is a compiler that takes code in one programming language and converts it to another. It's a real term.
This is awesome. We absolutely do need a crossplatform version of Haskell-for-mac. Not everyone can afford a 1000 dollar computer, especially state schools.
There's a little bug in the template if you change the service name. Sent you a pull request.
In my experience it really depends on how much TH you are using. By default yesod uses quite a lot, which explains why it's so long to compile applications. But I have a servant application that is now very slow to compile too ...
Some notes about my experience with Munihac and 3 hours at the haskell exchange hackathon Beginners are important. Set up some form of volunteer mentoring for a beginner workshop. They lead to fun insights. We had a beginner find a bug in stack and cabal while helping me with fixing a simple bug in Servant! Get some keynote speakers to open each day. Someone who can motivate you to write cool stuff. Don't pull all nighters. Close the venue after 7 and invite people to join you for dinner. I really liked this as normal hackathons just don't attract me. That brings me to the next point. No competition. Make it a place for smart people to meet and collaborate! However do give people the opportunity to present their work. Everybody likes bragging :) Announce on haskell-cafe. Here. In the IRC channels. There is plenty of promotion opportunities 
It depends… I'm an Atom user for a long time, who switched to Emacs two months ago. Even using [Prelude](https://github.com/bbatsov/prelude), [Intero](https://commercialhaskell.github.io/intero/), days of setting up everything and studying [Mastering Emacs](https://www.masteringemacs.org/) it took me few weeks to get something like productive. However, I could not get the speed of coding as with Atom. Not at least because it took some time to handle all the keyboard shortcuts. Although I tried `god-mode` and / or `evil-mode`. So I switched back to Atom these days and I'm happy now. Atom's support of Haskell is not bad as it seems. [haskell-ide](https://github.com/atom-haskell/ide-haskell) gives you a lot of powerful stuff to speed up coding with Haskell. It works with [Stack](http://haskellstack.org) and it gets better from day to day. Anyway, a performance issue with Atom seems to be running [ghc-mod and ghc 8](https://github.com/DanielG/ghc-mod/issues/834). The most thing [I have missed with Emacs](https://github.com/tolysz/spock-ghcjs-sample/issues/1) is the support of [GHCJS](https://github.com/ghcjs/ghcjs). This is also an issue by using Atom. It seems that [Leksah is working with GHCJS](https://github.com/commercialhaskell/intero/issues/64#issuecomment-252736115) but I have not tried it so far.
&gt; Notebooks are saved as single files in the normal filesystem. Granted, you can only open files which are below the directory the server is started (for security reasons), but it's the normal filesystem. Ok. I have to admit that it has been a couple of years since I've had a look at it.
That sounds cool. Is there a guide somewhere on how to set that up?
By making this easy to use on as many platforms as possible, I also hope to establish some kind of community standard. I mean, I don't want to force anyone into using HyperHaskell, but I think it would be very beneficial to have a common ground for graphical output (e.g. the `Display` class), just like the `Show` class of today. I think that the community will discover some unexpected and exciting use cases, and I would hate to miss those.
Aside from the other answers here, there's a demonstration branch on haskell-lang for runtime reloading of code via hint: https://github.com/haskell-lang/haskell-lang/commit/490034bcd7c9b205787df58e896231f952fca878 You have to be explicit about which modules you're going to load. I can imagine this being added to Yesod as an option or a framework template, to reload all templates on page refresh. Here is an example video of it in action: https://www.youtube.com/watch?v=oHYASkrdNq0 It yields pretty good subsecond page refreshes. It surprises me that doing it like this isn't a "thing" because it was pretty easy.
This is surprising to me. I was under the impression that a bunch of companies were using docker in production? I was planning on doing it soon myself. Do you have any articles I could read about these issues? 
I'd still encourage you to try out a PR, it's also a good way to get feedback.
Thanks for clearifiying! The name is inspired by `oh-my-zsh` - which I actually assumed would be familiar to many. I think there are other `oh-my-...` projects out there. The reasoning for choosing a not too serious name is to indicate that the list of templates is only a temporary solution.
Ok, so your use case would involve exploring code (type signatures, type instances, etc) more than it would involve exploring the results of this code (pretty pictures, etc). Of course it's not an either-or situation, there is a continuum between these two. &gt; And as I said, being able to view notebooks directly in GitHub is handy. Noted. Conversion should be fairly simple right now, but it may get more complicated once results are interactive, i.e. can call other Haskell code (planned for Level γ).
There are essentially four storage drivers. AUFS triggers kernel panics and the kernel developers see it as something to keep out of the mainline kernel at all costs due to low code quality. btrfs triggers soft lockups, often pauses the system (not lockups but another issue) so it becomes unusable for any sort of interactive work, plus it is slow. It also corrupts data if the disk fills up (and doesn't show correct data in df) so Docker won't start and there is no way to revert to a state where it will other than deleting the whole partition and starting over. Due to Docker's heavy use of subvolumes normal backups also become impossible on this backend (since every layer is visible seperately to a normal tool reading the filesystem). Devicemapper in loopback mode is horribly slow. Devicemapper in LVM mode is still horribly slow. OverlayFS seems to work and perform fine for now (other than the inherent limitations in overlayfs itself like being unable to rename directories from one layer to another,... and the fact that it requires a kernel a lot newer than stable distros feature) but after going through the others with issues that made it basically unusable and forced me to switch backends, can you blame me for feeling uncomfortable at having no alternatives left? There is also the issue that Docker itself does not reap zombie processes if the PID 1 process inside the container is a regular process, leaving nothing but a reboot to fix this (unless you use something like [dumb-init](https://github.com/Yelp/dumb-init) as PID 1 in all your containers). I don't have articles for the issues since I had to experience most of them themselves. There are long-standing Github issues for most of the kernel issues we had (other than the btrfs soft lockups but apparently [the author of this](http://sirupsen.com/production-docker/) had similar issues).
I'm supposed to write one 😬 I've been stalling on it because there are several very finicky aspects to it that will need help from upstream. For instance, the `org` -&gt; `jupyter` part is provided by `ob-ipython` whose name hints at the problems. This [PR](https://github.com/gregsexton/ob-ipython/pull/74) is a promising way forward, but the `ob-ipython` maintainer doesn't have much time for the project. What you can do is follow along with this [merged PR](https://github.com/gregsexton/ob-ipython/pull/38) to get going, but it's not easy to work with multiple jupyter kernels in one document. Then there is at least one IHaskell [issue](https://github.com/gibiansky/IHaskell/issues/685) that makes life a bit challenging if you want to have a file that can serve as both an interactive playground *and* a regular Haskell source file. The upshot is that I have worked out conventions for working around these limitations. For instance, I edit the playground parts of my file with `outorg` but ensure that they are commented out when I go back to non-interactive, library-ish parts of the file by indenting the `#+BEGIN_SRC` lines that start interactive blocks by an extra space. This lets me view the file via `outorg` exposing all the code that I want to send to IHaskell, and/or view the file via normal Haskell editing with Intero without getting messed up by the naked top-level expressions one uses with IHaskell for displaying figures and such. And to package it all up, my emacs has a little helper function for re-evaluating a file via IHaskell up to the current point that also filters out the `module` declaration. Gnarly, right? I can show someone how to do this, but it's hard to make the written-out steps seem reasonable. I keep waiting for a big IHaskell update (maybe with the impending GHC8 support Andrew will incidentally address my `module` problem, too), and for Greg to get some more time to put into `ob-ipython` (or someone to helpfully fork it into `ob-jupyter`) before writing up a detailed guide because I don't think many people will want to work with as delicate a process as I have for myself.
In the benchmark for 'constant reloading', do you know how many times the server is restarted during the benchmark?
This is unrelated to the question, but why is the first argument generalized to `PrintfArg` instances instead of just using `Int` or `Integer`?
It is restarted every 100 ms. 
Typo Thread. * Fold Univerality * Figure 9: "mempty x &lt;&gt; = x"
What error are you getting?
I have tried putting do parts in the if, I have tried taking out part of the code by putting it as extra text in the file, I have added and removed returns to see if it would give different errors. It seems to be going wrong from the first if part. But the hint given to add then gives a new error message, unexpected '&lt;-'. The classes and books in my oppinion are not of the level of the assignment making it really hard for me to get through it. I understand that people look down on it, but nevertheless changing things with no clue why it's going wrong doesn't help either cause I want to understand WHAT is wrong, and not just try stuff until I get a lucky shot and still not understand it afterwards.
&gt; The classes and books in my oppinion are not of the level of the assignment making it really hard for me to get through it. It's easy for experts to forget which parts are not obvious for beginners. I probably wouldn't have thought to explain that you need a `do` after a `then` if your `then` block has several lines either. If you tell your teacher about the things which are not obvious to you, it will allow them to improve the contents of their course and to make it more helpful. &gt; It seems to be going wrong from the first if part. But the hint given to add then gives a new error message, unexpected '&lt;-'. That's good! It means you have fixed your first error, and now you need to fix your next error. &gt; changing things with no clue why it's going wrong doesn't help either cause I want to understand WHAT is wrong, and not just try stuff until I get a lucky shot and still not understand it afterwards. Indeed! Changing things randomly until it works really is not a good way to learn, I'm glad you agree. But what do you do instead? Before giving up and asking us for help, I recommend you try those same experiments in a much smaller program. As you have seen, in a larger program it is easy to make multiple errors, and so when you make a change which happens to fix a mistake, you get a different error message and you don't know whether that's because you've introduced a new problem or if you now need to tackle this second problem. If you start from a tiny hello world which you know works, and you make very small incremental changes to it, compiling every time, it will be very obvious what is the cause of the problem because it was introduced by such a small change. This way, you can figure out what is wrong on your own. If you do such an experiment and you still don't understand what is wrong, or you don't understand why a particular change fixed the problem, now is the time to ask for help. You'll have a tiny example to show us (indent it by four spaces so reddit formats it properly), and since it's so short you can also give us a few variants to show us what you've tried. These variants, plus some text explaining what you think is going on, help us to understand how you are thinking about the problem, which in turn helps us write a more illuminating answer.
can you post your edits 
[https://ghc.haskell.org/trac/ghc/ticket/12736#ticket](https://ghc.haskell.org/trac/ghc/ticket/12736#ticket) Still working on a smaller test case, which is taking some time as simple changes can seem to cause vastly different assembly/register allocations.
then and else need to be indented past the I in "if", I think if foo then do blah blah else do blah blah
Okay ... I found three obious `awesome-haskell` lists * [awesome-haskell](https://github.com/uhub/awesome-haskell) * [awesome-haskell](https://github.com/gavinwhyte/awesome-haskell) * [awesome-haskell](https://github.com/krispo/awesome-haskell) Two are related and pretty nicely organized, one is a flat list. None of them actually meets the criteria for an awesome list. All of them are missing a contribution guideline. One of them is missing a license. Also none of them contains haskell templates. Then, pure lists don't cut it, if we want instructions on how to use the templates as well as common patterns for describing/presenting the properties that are important when comparing Haskell project templates - Would you have some ideas on howto describe a Haskell-project template in a single sentence, as a single bullet point in a flat list? So I think awesome lists are great on a more abstract level, i.e. to link to Haskell project templating solutions instead of actual templates. Also, just know I realized, that there are Haskell project templating _solutions_: * [haskeleton](http://taylor.fausak.me/2014/03/04/haskeleton-a-haskell-project-skeleton) * [hi](https://github.com/fujimura/hi) * [stack-templates](https://github.com/commercialhaskell/stack-templates) I guess I should think about on improving one of them instead of diverting the effort to a redundant project? I don't know. @biscarch @peggying ... opinion please (even as animated gif or meme image ;) ) 
Hm, OpenGL is a tough one. The Electron framework, with which the front-end is currently built, supports everything HTML, but nothing else. I don't think its possible to embed a native OpenGL view, much less several of them. WebGL should work, but then this is not Haskell. Building a new front-end, entirely in OpenGL, is probably not worth the effort. That said, it should be possible to run Haskell code that uses OpenGL from HyperHaskell, just like it is possible to do that from GHCi. The OpenGL content will be shown in a new window, I guess. But it would still be fun to have 3D scenes embedded in the worksheet. Hrm.
I think this should work: type Zipper a = Cofree Maybe a delete (_ :&lt; xs) = xs toZipper = fold alg where alg Nil = Nothing alg (Cons a b) = Just $ a :&lt; b Using `fold` from [`recursion-schemes`](https://hackage.haskell.org/package/recursion-schemes). Edit `delete` is also available as [`unwrap`](https://hackage.haskell.org/package/free-4.12.4/docs/Control-Comonad-Cofree.html#v:unwrap)
BTW "dice" is already plural. The singular is "die". "Dices" is a verb: He dices and gambles a lot.
 do partTurn (8 - length pickedlist) pickedlist return () vs. partTurn :: Int -&gt; [Dice] -&gt; Int -&gt; IO () You don't seem to be providing enough arguments here. (This error occurs twice.) --- putStr str return () The second line is unnecessary. --- do {- ... -} if (score &gt; 20 &amp;&amp; elem W pickedlist) then Layout rules will insert a ';' before `then`, since it starts on the same column as the first token following `do`. If you want the line starting the `then` to continue the same "statement" as the line starting with `if`, it needs to be more indented than `if`. Alternatively, you could avoiding using the layout rules entirely (i.e. use braces and semi-colons explicitly) until you get comfortable with them. Significant white space can often be a barrier for new programmers. --- I'm assuming getCharDice, takeDiceScore, and takeDiceNow do not have "IO" in their type, correct?
Every time I've tried emacs I always run back to vim in horror, but I've never been completely satisfied with my Haskell setup on vim. Recently I've tried spacemacs with intero, and dear god, this is amazing. It's the little things like the fact that it always automatically shows the type of whatever is under the cursor or selected. Thanks to spacemacs+intero, I'm now an emacs convert.
Isn't `Cofree Maybe a` the same as `NonEmpty a`? But thanks! I should be able to use `recursion-schemes`. `Cofree (Compose Pair []) a` (where `Pair` is homogeneous 2-tuples) is more along the lines of what I was thinking for a [list zipper](https://en.wikipedia.org/wiki/Zipper_%28data_structure%29#Example:_Bidirectional_list_traversal) (though I should've spelled that out...)
&gt; Isn't `Cofree Maybe a` the same as `NonEmpty a`? They are isomorphic, yes. I initially thought I was going to do things are an unfold of `Cofree Maybe a` and at the same time plug my [proposed additions to `recursion-schemes`](https://github.com/ekmett/recursion-schemes/pull/26), but it ended up just being simpler to fold over the list. It might be a little more awkward with a bidirectional Zipper.
&gt; It seems that some of the developers of Haskell tried to give Erlang the former’s beautiful type system but turns out this broke the Erlang implementation. Hot loading works only because of the dynamic type system. If Erlang were statically typed then hot loading would not work. There is hot loading in Haskell. They do it at Facebook.
I agree that there is a need for more templates / project scaffolding for Haskell in general. Perhaps stack should have the ability to add extra template repos?
[removed]
I might be missing something. The paper presents example `ps_fib2'` which shows that it is enough to _mention_ the relevant reflections. How far does this extend? For example, could I define `fibUp` as fibUp :: n:Nat -&gt; {fib n &lt;= fib n+1} fibUp 0 = [fib 0, fib 1] ** QED fibUp 1 = [fib 0, fib 1, fib 2] ** QED fibUp n = [fib (n-2), fib (n-1), fib n, fib (n+1)] ** QED
Unfortunately I'm not aware of any better options than reading [the papers](http://research.microsoft.com/en-us/um/people/simonpj/papers/ext-f/).
well, reading an arbitrary large number of arbitrary large files at the same time, i don't think that would work in other languages either. I'm not completely sure what you mean by the second sentence. But it seems to me now, since monads are about sequencing, that if you look at the first item resulting from a `sequence`, it will actually execute all the monadic actions for the whole list first.
what a distasteful name
I seem to be hawking this a lot lately, but you should have a look at [FTL](https://github.com/beark/ftl).
The error messages are getting better over time (compare GCC 4.x series with the 6.x series, although this is probably thanks to Clang giving them a kick up the arse). Emulating multiple returns by passing pointers in is a code smell though, and I'd (figuratively) poke anyone who did it - `std::tuple` exists (or probably even better, use a named `struct`).
Sorry I can't help you but that's interesting. What have you tried and where did it fail?
Correct, they are pure functions. That's why I used them that way. 
There are unsafe methods such as `head` and `unsafePerformIO`. Not using these functions would limit Haskell severely. It's up to the community to build a trusted set of libraries. Otherwise there would have to be a "save" part of Haskell which is maintained by a committee (which I suspect is the case with Elm).
&gt; Or can any library just throw an Exception and burn my otherwise perfect application down without even a warning from the compiler beforehand? Yes, though then the library is likely broken. The situation is very similar to rust where you of course *can* panic in a library, however, you bloody shouldn't. You also shouldn't call `abort` in a C library. We have guns in Haskell land, however, you first need to aim them at your foot. Pure library code really should be exception-free, that means no calls to `fromJust` and such, and report failure by returning `Either` or such. The situation is different with IO libraries, where throwing IO exceptions might be part of the contract, though also with IO there's a certain drift towards functions advertising that they can throw in their types. [Like for example this](https://hackage.haskell.org/package/control-monad-exception-0.11.2/docs/Control-Monad-Exception-IO.html). The distinction makes sense: Catching IO exceptions is actually sensible, catching pure ones is not. ---- That all said, the infrastructure to write code as you want it in Haskell is *gigantic*. Starting from [replacing failing Prelude functions with safe ones](https://hackage.haskell.org/package/safe) going to [a static analyser](https://github.com/ndmitchell/catch). Neither, of course, is stopping you from *explicitely* throwing exceptions. Just, well, don't, same as you shouldn't just call `unsafeCoerce` unless you actually *are* smarter than the compiler. If you insist, grep for those buggers. Going further than that wouldn't actually make sense in Haskell as Haskell is turing-complete. It makes no semantic difference whether your program throws or enters an infinite loop, and those can't be reliably detected.
Couldn't the compiler tell me "Warning: Uncaught exception here." or "Warning: Impure function failure case not handled."? Since the Haskell compiler should have a lot of information about the code anyway. Especially since the tooling compiles libraries as well when installing them. Or is this just something that is "nice to have" for Haskell because it doesn't happen in practice?
&gt;Not using these functions would limit Haskell severely. It's possible to use versions of these functions that return e.g. `Either error a` or `Maybe a` (which is what `head` returns in Elm and Purescript) to avoid exceptions. I haven't found that safe definition of `head` to limit me at all, in fact I've found the opposite: it gives me more confidence in my code, as it's one less chance to accidentally use a partial function that fails at runtime. IO too; I found for instance that the Rust IO functions, which return `Error` types instead of throwing exceptions, make me much more confident about my IO code than Haskell, and the code is less likely to fail at runtime. Fortunately there are libraries to achieve better compile-time handling of IO errors in Haskell, like [unexceptionalio](http://hackage.haskell.org/package/unexceptionalio-0.3.0/docs/UnexceptionalIO.html), but this doesn't help if you depend on libraries that use functions from the default prelude.
I've looked at the [android-haskell-activity](https://github.com/neurocyte/android-haskell-activity) project, but haven't been able to build the [foreign-jni](https://github.com/neurocyte/foreign-jni) dependency. I've looked into [foreign-jni](https://github.com/neurocyte/foreign-jni) by itself without really understanding how to use it (or still being able to build it. Both of these seems to be abandonware by now. I've seen some projects using docker, but having had no experience what so ever with docker I've skipped them for now. I've also tried to simply compile a library on my own, exporting C functions and to a middle layer NDK library which calls my library, but that's a lot of extra work when building my library that I hope I won't have to do. Also, cabal doesn't really seem fit to export library files, but that may be me missing something obvious...
This. I also preferred this approach in Elm. Put the result in a case statement and the compiler will force you to actually write a case for the error. Sure you can crash in the error case, but it is glaringly obvious that you are doing so, and there is no "ups" moment. It is no more complicated that a if else. I'm just unsure if it is as obvious in Haskell with the higher level of abstraction? Maybe it is.
&gt; Elm has it made, you just CAN'T get Runtime Exceptions What happens in Elm if I divide by zero?
I consider FFI a different beast entirely. Ofcourse crashing Elm from using JS through ports is trivial as well. I'm considering Elm and Haskell alone for now.
Having partial functions such as `head` in the Prelude is widely considered a misfeature. However, it's decades old now and removing then would be a breaking change. They are even useful sometimes. Elm benefits in this regard from being newer and able to start with a clean slate.
I guess I have to place my hopes in the community, that the more well established libraries solve errors correctly and consistently. Wish Idris was production ready. Hope learning and using Haskell will get me ready for the future - Idris or it's like.
1 / 0 Infinity : Float Parameters to (/) are treated as Floats it seems: [docs](http://package.elm-lang.org/packages/elm-lang/core/latest/Basics) Even if I write them as Integers.
It does make my mouth water. Any remote opportunities? Also what kind of Haskell experience are you looking for?
Edited my initial statement in the post, to be less "all encompassing". 
Recently found this, but have not tried yet. Looks like good source of multiplatform Haskell. https://github.com/sseefried/open-epidemic-game
Haskell (and the core libraries), have gone through such big changes recently (and it's still going on): Foldable-traversable, removing fail from Monad, Functor-Applicative-Monad, now Backpack and all of them were hard due to the fact there's gonna be some breaking changes involved or that maintaining backward compatibility is problematic. Yet it didn't stop from implementing those things. I wonder if painpoints OP mentioned can be tackled similarily, somehow...
There's a cottage industry of more modern Prelude replacements. You use them on a project by project basis. There's no generally-agreed radically better Prelude. The libraries committee does make progress but slowly, taking backward compatibility very seriously.
I'm still having a hard time taking this concept seriously. If I "squint" really hard and there's a lot of noise outside my window, *maybe* some of this sounds like actual music. For the most part, this just reminds me of the time I was learning to use linux and I tried piping `/dev/urandom` to my soundcard.
That certainly works. Here's the use case: permutation :: Alternative f =&gt; [f a] -&gt; f [a] permutation = go . toZipper where go :: Alternative f =&gt; Maybe (Zipper (f a)) -&gt; f [a] go = maybe (pure []) $ getAlt . foldMap Alt . extend use use :: Alternative f =&gt; Zipper (f a) -&gt; f [a] use z = (:) &lt;$&gt; extract z &lt;*&gt; go (delete z) 
&gt; In the same way you validate untrusted input in any other language: then what makes dependent types cool?
Heh that's weird + interesting because this sounds *super* accessible and exciting to me - very detailed but not at all noisy. Out of (genuine) interest, what kind of music do you listen to normally, any electronic music?
It's the same kind of coolness as when generics were added to Java 1.5. You don't have just `ArrayList` with some element, but you can have `ArrayList&lt;Int&gt;`. Dependent types is the next step in that direction.
Someone make this a wallpaper please. 
Not even that. The problem with yesod that it will recompile every module that uses haml/js/css templates regardless if that module was changed. The reason is yesod cannot figure out whether the templates themselves were changed so it just recompiles everything to be on the safe side. We had to stop using all haml templates and basically moved all client side code to purescript just to avoid recompilation times. 
I'd be concerned about that implementation of `callProcess`: the `forkProcess` function itself is notoriously flakey, and by making the call to `fork()` from Haskell code instead of FFI code, there's the potential for another thread to grab control in the interim and cause trouble. You'd be better off either doing all of that work in the FFI, or (if you're willing to lose performance) make this code a wrapper around the process package.
Correct me if I'm wrong, but I think the insanity of catching exceptions in pure code is related to non-strict semantics. If we could do that, the runtime would need the ability to backtrack to the catch-site when the exception is uncovered, which can happen a very long time after the function call. It is not absolutely infeasible, but the runtime would have to do a lot of bookkeeping and consume a lot of memory. Is it the gist of it?
&gt; There is hot loading in Haskell. They do it at Facebook. Is it possible to hot load code of different type signature (in Haskell)?
As your post hints at, you can make sure you don't do "risky" things in your own code and that takes you a huge part of the way there. Like you observe, exceptions could possibly be thrown by libraries you use, and that is conceivably harder to protect against. It's easy to protect against in the sense that you can just not use those libraries. That's still a little bit unsatisfying because you don't want to do a careful inspection of every library you depend on and all their transitive dependencies. This is where [SafeHaskell](https://ghc.haskell.org/trac/ghc/wiki/SafeHaskell) comes in, which provides infrastructure for percolating the safety and trust level of modules down to your application in a useful way.
Ah, yr right :-)
Yesod and classy-prelude are both by Michael Snoyman. Just an instance of [dogfooding](https://en.wikipedia.org/wiki/Dogfooding).
That is really quite awesome.
With dependent types, you can do something similar to the validation described above (`age &lt; 0 or age &gt; 150`) but you end up with a value that proofs this. So you have you the one entry point that creates something of type `Maybe (Value&lt;GTE:0,LTE:150&gt;)` and then your other functions consume the `Value&lt;GTE:0,LTE:150&gt;` with certainty that it is bounded appropriately. In practice, proofs can be cumbersome. People are trying to figure out how to make this better. Refinement types are one approach.
The people trying to place you at the bank have an interest in having you there. Follow their cues and you will make the tech interview. Ask them a few days before what you should know, and read that. You will talk to someone less technical from the bank itself. You will pass that conversation with a combination of expensive tie and suit, cuff links, stay-the-course, and talking about non-geeky hobbies. For a banking job you also want to ask as few questions as possible. The banking industry in London and many other traditional tech industries located there want people who can fit in without showing up on the radar and don't express any specific preferences. The dress code in London is always tie, white shirt, suit and cuff links. Even when they tell you it isn't. This is not SF or Berlin. Even when applying to a laid back media company where the owner wrote a book about his crack addiction and harem of paid-for maidens, and the manager runs around with vomit on his shirt that he acquired while lying on the street drunk the night before* guess what you wear? You guessed it, tie, white shirt, suit, and cuff links. Go to Oxford circus and do all your shopping in one hour: Suit: above 500 quid, grayish black, eg armani sport. Not Zara. Those look cheap. Tie: dark, silk, have em tie it for you if you can't Shirt: thick, eg Zara. Shoes: good dark brown leather shoes. Spend a lot. They'll pay off after 1 day of work. Source: years of freelancing as a programmer in London, dozens of job interviews. (*) 100% accurate, first-hand experience
Awesome!
I don't think I'd ever go to an interview in jeans and a hoodie. Typically slacks and a button up are the starting point, and then you dress up further to meet the dress code of the company (advice I've been given is to dress "one step above" the dress code, i.e. if they require slacks and button up, add a tie. If they require a tie, go for a suit, etc.) It's not a set in stone thing, but you typically don't want to under dress, and it's easy to take a jacket off or a tie off in the waiting room if you feel overdressed.
You should ask /u/ndmitchell, since he is most likely the one that will be doing the interview.
The video presentation about this is also great: https://skillsmatter.com/skillscasts/8725-haskell-meets-java Anybody tried this on Android, yet? Also, there seems to be inline objective C library[1]. So, does this mean that one can now potentially natively target both Android and iOS without too much hassle, and the only thing that is missing is an abstract view layer / framework to make UI development simple? If so, then we could either go react-native route and have virtual-dom with abstract components that work across both platforms or have similar thing to ghcjs-dom (which compiles differently depending on whether you're using GHCJS and DOM or GHC and Webkit). [1] : https://github.com/mchakravarty/language-c-inline Another piece of the puzzle with cross platform app development is hotloading. Facebook does it for HAXL and there are some modern instructions like this [2]. For UI ideally we would want to compile as fast as possible with no optimizations only the module that is being worked on, and then hotload it to see changes in the UI as you develop. [2] : https://purelyfunctional.org/posts/2016-05-20-dynamic-loading-haskell-module.html If all pieces of the puzzle are there, namely hotloading for faster feedback cycles, easy interoperability with native platforms and an abstract UI layer, then one could rapidly prototype and develop cross platform apps with little technical debt and potentially high code reuse.
It starts at 1.0, goes up in increments of 2.0 and stops once it's hit 4.0 or greater. The smallest number that's 4.0 or greater, going up in increments of 2.0 from 1.0 is... 5.0.
That's not it. Prelude&gt; [1.0, 4 .. 5] [1.0,4.0] The answer is that for some reason, the spec requires a nonsense `Enum` instance for `Float` and `Double`. It should never be used by anyone, ever, under any circumstances.
Yes! (to my surprise, TBH) which just goes to show why SMT solvers are very useful. In fact, you can further simplify the proof to just: fibUp :: n:Nat -&gt; {fib n &lt;= fib n+1} fibUp 0 = [fib 0, fib 1] ** QED fibUp n = [fib (n-1), fib n, fib (n+1)] ** QED (see: http://goto.ucsd.edu:8090/index.html#?demo=permalink%2F1476903873_17422.hs) It turns out you *do not* need the induction hypothesis, but instead, just need the fact that `fib` returns a nat. That is, in the last case, "mentioning" the calls yields the following facts: fib (n+1) = fib(n) + fib(n-1) fib (n) = fib(n-1) + fib(n-2) fib (n+1) - fib(n) = fib(n) - fib(n-2) = fib(n-1) &gt;= 0 which yield the result.
&gt; The situation is very similar to rust where you of course can panic in a library, however, you bloody shouldn't. You say that, but I get bitten by people using unwrap in Rust libraries a lot more often than I get an unexpected exception in Haskell.
/u/ezyang What hardware/software do you use to do that wonderful graphics you have in the presentation?
I really appreciate this comment. I think I actually have experienced that "flakey behavior" at least once. I'll look into it. Thanks for a great insight.
Thanks, I should have known that :-(
wrong subreddit? 
Spacemacs is amazing. I used to use Sublime and Atom, and then moved to vim. But now that we have Intero, Spacemacs is absolutely amazing.
Yes, but remember that SO_REUSEPORT does load-balancing. So if you have a modern server, you'll have up to 44 threads, and that's just going to increase. It's pretty nice to be able to use a single IP:PORT and actually utilize the whole server.
[Use Powershell instead of cmd.exe apparently](https://github.com/commercialhaskell/stack/issues/1798). Though I think there's a bigger underlying issue somewhere. At work vim calls command prompt instead of Powershell and I never have any problems....
I like what I see, although... &gt; Referential transparency. Functions in the Safe dialect must be deterministic. Moreover, evaluating them should have no side effects, and should not halt the program (except by throwing uncaught exceptions or looping forever). Looping forever I can understand, but why exceptions? I would demand the code be sufficiently annotates with a "this throws an exception" and the compiler to warn me that I didn't handle the failure case.
&gt; I don't think I'd ever go to an interview in jeans and a hoodie. This is a _very_ tricky topic. If you were to _not_ wear tshirt and jeans at SF tech companies (or even outside of bay area) that can reflect badly (even if only subconsciously). I've always tried to emulate the style of people at the company, to make it seem like I'm not out of place there. For a bank I'd probably go with suit and tie, or at the very least, slacks, collared shirt + blazer. I guess that would depend on the bank and who I'm interviewing with though. 
Already answered: https://www.reddit.com/r/haskellquestions/comments/574mkh/what_does_haskell_when_calculating_01031/
In theory, `undefined`, `error`, and `throw` exist and even if you purge them from source you control, linking to a library containing one could certainly terminate your program with an uncaught exception. In practice, both library authors and library users in the Haskell ecosystem have decided they'd rather have `Either` (`Left` instead of `error`), `Maybe` (`Nothing` instead of `undefined`), or `IO` (using `throwIO` instead of `throw`) decorating their types and let the type system guide them to completely covering error scenarios. I haven't deployed any medium-sized or larger Haskell apps. (I only get to use it as my fun language.) But, industry reports indicate that it's not hard to achieve that 95%. It helps to know or shape what packages are good on hackage though; there's not actually any "quality" requirements to upload to hackage.
...and what's worse is `Rational` uses the same nonsense `Enum` instance, which makes even *less* sense for `Rational`.
I think the storage situation is pretty well known. Some believe btrfs can work, but most (everyone?) uses OverlayFS. I didn't know about the PID 1 issue. Thanks for pointing that out.
I do listen to lots of different electronic subgenres, and had no better label for it. "Minimal" might be too generic, insert whatever adjective here. Feeding /dev/urandom to the speakers as IceDane was suggesting would sound like filtered white noise.
Indeed. But this situation seems silly (and doesn't give you `x == x/y * y + x%y`): - `1 / 0` results in Infinity (type `Float`) - `1 // 0` results in `0` (type `Int`) - `1 % 0` throws a runtime error (type `Int`) - ``1 `rem` 0`` results in `NaN` (type `Int`) 
I'd call it a mix of drill 'n bass, braindance, breakcore, idm and straight techno. To me 'minimal' suggests something quite specific, depending on the context either stripped down techno, lowercase sound or 20th century american experimental composition. To my ears, this has a lot of detail. I don't think I'm going to understand what you're hearing, which is interesting in itself..
Short version, care more about the types and functions you use and write rather than formatting of code. It doesn't matter if it's beautifully formatted if you've used a partial function or have your Monad Transformers assembled in the wrong way. Correctness over bikeshed colour.
Another unfortunate such function is Codec.Compression.{GZip,Zlib}.decompress from the zlib package. Which doesn't have an Either/Maybe based alternative :(. PS: is there a way of catching pure exceptions without doing it in IO ? I use Control.Exceptions' (try . evaluate) :: Exception e =&gt; a -&gt; IO (Either e a) to catch pure exceptions
That said, there is some value to choosing and adhering to a coding style. For one, you no longer have to waste time thinking about how to format a piece of code; you can spend that time thinking about the best way to write it instead. For another, standards shared by teams make it easier for everyone to work with the code. For Haskell, there is a tool called [hindent](https://github.com/chrisdone/hindent) that will enforce a particular coding style by reformatting files and declarations. You can use it from most editors. There are also a number of style guides in the wild, such as [Johan Tibell's](https://github.com/tibbe/haskell-style-guide), on which the current hindent style is based. 
&gt; I've seen and been in too many teams where formatting was endlessly bikeshedded, for no benefit. Fair point, and that's an explicit goal of tools like hindent, rustfmt: let a computer make this boring decision for you so you can stop wasting time on it. &gt; Now days I really don't care and do my best to fit in with the style of the code that's already there. Another good point! OTOH, I do think it's reasonable to ask "what does good Haskell code look like?" if you're trying to *choose* a coding style, rather than adapt to an existing one.
Could be dons though.
In that case I'd point to our open source code from Ambiata https://github.com/ambiata/ Getting the conventions right around Preludes, partial functions, error handling and the like would be my first priority. Then formatting :-)
`unsafePerformIO . try . evaluate` Don't do this though. You can't *safely* catch unchecked exceptions purely, that violates referential transparency.
I think this is a non-answer. I'm sure OP and co know quite well the things that make Haskell great. OP asked about code formatting. I don't know how monad transformers or total functions solve that problem.
hindent provides a standard indentation, it's a lot more agressive than stylish-Haskell. And hlint is decent as linters go. 
Certainly it can, if you've got things splattered all over the place then you've got problems. I'm more talking about the difference between data Date = Date { dateYear :: Int , dateMonth :: Int , dateDay :: Int } -- versus data Date = Date { dateYear :: Int , dateMonth :: Int , dateDay :: Int } -- versus data Date = Date { dateYear :: Int, dateMonth :: Int, dateDay :: Int } or where to put the `=` for a function definition or where the `do` should appear, and whether to use `;` or explicit binds, or any other bikeshed formatting issue These are all in the category of "I don't really care", choose one and move on, or don't choose one and keep to the style of the existing code. They're really not worth spending that much time on. The things I worry about in Haskell code is correctness and robustness. Like are you using partial functions, that'll blow up at runtime causing things to fail, or does your data type encode particular states that shouldn't be possible. Perhaps this isn't the place, but after seeing a few of these sort of *formatting* questions, I'm concerned that people are looking at this all wrong. Especially for someone introducing Haskell somewhere. 
Thank you writing and sharing your work. Regarding the pub/sub example, can it also be made to work over a network?
This is jawdroppingly cool!
Cool! Unfortunately, it does not appear to be possible for `fMono`. Defining {-@ fMono' :: f:(Nat -&gt; Int) -&gt; fUp:(z:Nat -&gt; {f z &lt;= f (z+1)}) -&gt; x:Nat -&gt; y:{Nat|x &lt; y} -&gt; {f x &lt;= f y} / [y] @-} fMono' f thm x y | x + 1 == y = [f y, f x, f (x + 1)] *** QED | x + 1 &lt; y = [f x, f (y - 1), f y] *** QED but forgetting the accompanying Haskell type signature gives me this as a log: LiquidHaskell Copyright 2009-15 Regents of the University of California. All Rights Reserved. [1;94m **** DONE: A-Normalization **************************************************** [0m[1;90m [0mliquid: &lt;no location info&gt;: Error: Uh oh. This should never happen! If you are seeing this message, please submit a bug report at https://github.com/ucsd-progsys/liquidhaskell/issues with this message and the source file that caused this error. RefType.toType cannot handle: {VV : _ | f z &lt;= f (z + 1)} Adding the missing type signature gives Unsafe! /home/rjhala/research/stack/liquid/liquid-server/resources/custom/liquidhaskell/sandbox/1476936313_17434.hs:138:5-33: Error: Liquid Type Mismatch Inferred type VV : () not a subtype of Required type VV : {VV : () | f x &lt;= f y} In Context x : {v : Int | v &gt;= 0} y : {y : Int | y &gt;= 0 &amp;&amp; x &lt; y} Unsafe! /home/rjhala/research/stack/liquid/liquid-server/resources/custom/liquidhaskell/sandbox/1476936313_17434.hs:136:1-6: Error: Liquid Type Mismatch Inferred type VV : () not a subtype of Required type VV : {VV : () | f x &lt;= f y} In Context x : {v : Int | v &gt;= 0} y : {y : Int | y &gt;= 0 &amp;&amp; x &lt; y}
Haskell didn't originally have impure exceptions. So, `undefined` and `error` got the same denotational semantics as an infinite loop. When impure exceptions were introduced, we wanted to implement `undefined` and `error` in terms of them but without changing the semantics. So, impure exceptions received the same denotational semantics. I think impure exceptions, partial functions, `undefined`, `error`, AND asynchronous exceptions should be purged from Haskell, or *at least* suitably isolated behind a(n) (monadic?) interface. But, (a) that wouldn't save us from \_|\_ (b) changing things would be a HUGE project and (c) I'm not very good rallying people to my cause.