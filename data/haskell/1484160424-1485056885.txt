At [Obsidian Systems](https://obsidian.systems/), and at my previous companies, I've had great experiences with hiring. Haskell developers are some of the most enthusiastic and interesting people I've met. I've never met a Haskeller who's in it just for the paycheck. I've also had good luck hiring people whose experience is in other functional languages - SML, Erlang, etc. You'll have to find the right person - someone who's really into FP itself, rather than just working in a language that happens to be functional. However, if they've absorbed the principles of functional programming, it transfers pretty easily and I don't think you'll have too much more ramp-up time than with someone who already knows Haskell. For people coming from non-FP languages, you're taking more risk. In my experience, some people see FP as a breath of fresh air - it's the thing they didn't realize they were looking for - and they'll come up to speed quickly. Others don't take to it as naturally, and will require more mentoring to get productive. Obsidian Systems does custom web development, and generally we've been able to find great infrastructure for what we do. Snap, Servant, Postgresql-Simple, Aeson, etc. Although languages like JavaScript have more libraries that *exist*, in my experience, Haskell projects are able to *make use* of far more libraries, because the quality is so much higher. Plus, the type system means that libraries almost never step on each others' toes. We did encounter one large gap in the ecosystem: the frontend programming framework. We built [Reflex](https://github.com/reflex-frp/reflex-platform#tutorial) to fix this problem, using GHCJS and FRP. Since then, we've had a lot of success building applications for our clients and ourselves with Reflex. One thing we've found is that it's very important to be an active contributor in the open source Haskell community. We frequently contribute fixes and improvements to the libraries we use. Not only is it really enjoyable to help others out and help the language succeed, it's also cheaper over the long (or even medium) run than maintaining workarounds or forks. Overall, I think you'll find that Haskell can be a great advantage in many areas, especially hiring. There are definitely challenges associated with not being in the mainstream, but in my experience the benefits have greatly outweighed the costs.
&gt; But, I think it relies on folding starting with the monoid's identity In the **foldl** package, you can specify the starting state for the [Fold](http://hackage.haskell.org/package/foldl-1.2.3/docs/Control-Foldl.html#t:Fold) datatype: &gt; Fold (x -&gt; a -&gt; x) x (x -&gt; b) -- Fold step initial extract The type also has an "extraction function" for the final result; this allows us to define the `Functor` instance.
 s -&gt; i -&gt; s is equivalent to i -&gt; s -&gt; (s, ()) and thus to ReaderT i (State s) () -- also StateT s (Reader i) () Then there are many ways to combine actions monadically/applicatively. (*.*) (&gt;&gt;) liftState zoom (from lens) liftInput ask + traverse when when postProcess (&gt;&gt;) + modify Maybe I'm missing your point.
Happy new year everyone! This was obviously more than a bit later than we would have liked, but hopefully the result is worth the wait. 8.0.2 fixes a number of rather serious correctness issues, as well as a range of critical portability issues. The latter include, * Compatibility with macOS Sierra's linker * Compatibility with distributions which enable position-independent executables by default (which Debian `testing` recently enabled) * Runtime linker issues on Windows These issues were in large part the reason for the delay. Obviously this has pushed the schedule for 8.2.1 a bit; at this point we are planning to fork for 8.2 in early February, with the intent of making a release candidate in mid-February. This means we should hopefully be on track for a release by late March or April. As always please file tickets if you encounter issues. Thanks to everyone who has contributed to this release!
That's great to hear. 1 Does that mean that the simplifications/divergences someone proposed [here](https://github.com/typelead/eta/issues/119) are not official? 2. Also, while this will take a long time, and support from several library maintainers, I have some hope that backpack can modularize ffi (and IO) calls in the most popular packages. e.g. "text-core" could be an indefinite package, and "text-c" mixes "text-core-c" into "text-core". Then, ghcjs could work with "text-js", and eta with "text-java". Then "text" can be a compiler-specific alias (?), and people can use it when compatibility with existing datatypes/classes is more important then [performance](http://stackoverflow.com/questions/40923946/ghcjs-text-data-constructor). Otherwise, (I think) the "indefiniteness" would trickle up to any package that depends on a package named "text"... /u/ezyang mind if I ask if this makes sense? 
My current impression is that their notion is `Eta : Haskell :: Racket : Scheme`. As long as the compatibility is there, I don't think the name matters much.
Cool! If you're looking for suggestions, some use of pattern matching and guards can make short Haskell functions much more readable. For example, I might rewrite the first few functions like: clamp :: (Ord a) =&gt; a -&gt; a -&gt; a -&gt; a clamp value minimum maximum | value &lt; minimum = minimum | value &gt; maximum = maximum | otherwise = value and addCouples :: (Num a) =&gt; (Num b) =&gt; (a, b) -&gt; (a, b) -&gt; (a, b) addCouples (x1, y1) (x2, y2) = (x1 + x2, y1 + y2) 
Wow. This is awesome. Heh, I'd be proud if this were my 1000th program, let alone my first functional one.
Would linear types help with the recent [streaming headaches](https://pay.reddit.com/r/haskell/comments/5n7sfw/nested_monadic_loops_may_cause_space_leaks/) caused by laziness?
Thanks, I'm a bit new to all this so I wouldn't be surprised if I missed something so obvious. I'll look down this path.
Do you have any thoughts on the issue posed by: https://groups.google.com/forum/#!searchin/tlaplus/haskell%7Csort:relevance/tlaplus/7vxzRBAR6TQ/tmZ8syRxFQAJ That is, does the fact that TLA+ assume mutable state make it less useful for purely functional programs?
"Unit tests shouldn't touch the database" is significantly less controversial than the "you shouldn't have integration tests" implicit in your "no tests should touch the database" (and explicit elsewhere).
Yes, those are not official. Once I get the eta-proposals repo setup, I'll close all those issues. The package ecosystem with backpack sounds great.
This is simply an outstanding accompaniment to the linearity proposal. Thank you!
Haskell definitely has some legacy which could be removed, and I think those methods are part of that. But there are many other cases of cruft lingering around. You can replace Prelude in your own projects if you want. Unfortunately, most of the replacement Prelude projects still have 'head' and 'tail'.
Thank you, this is much more readable, I'll fix my code :)
&gt; The LLVM backend works with 3.8 and beginning with 8.2 it's 3.9, right? In GHC 8.0.\*, it works with LLVM 3.7. In 8.2.\*, it'll be LLVM 3.9. See https://ghc.haskell.org/trac/ghc/wiki/Commentary/Compiler/Backends/LLVM/Installing. &gt; Speaking of, is it possible to choose `llc` and `opt` after ghc is built and installed upon invocation? Correct. GHC will simply look for executables named `llc` and `opt` on your `PATH`. There's no guarantee that LLVM 4.0 will work with GHC 8.0 (or GHC 8.2, as of now), so caveat emptor.
/u/edsko, could you provide an RSS feed to your blog if it's not too much trouble? I couldn't find one at: - edsko.net/rss - edsko.net/rss.xml - edsko.net/feed - edsko.net/feed.xml Thanks!
&gt; In GHC 8.0.*, it works with LLVM 3.7. Oops, better cancel and reconfigure the build then :).
And support for [inline-java](https://github.com/tweag/inline-java). Awesome!
I’ve been thinking about adding something like this to my language, Kitten. For tracking side effects of functions, I use a set (row) of “permissions”, e.g. `prompt` :: `Text -&gt; Text +IO`. I was thinking that it should be possible to encode assumptions about values in this way too, e.g., `List&lt;T&gt; /Unique /Sorted` is a sorted, unshared list, and the subtyping relationship is pretty natural: you can pass a `List&lt;T&gt; /Unique` to a function expecting a `List&lt;T&gt;`, but not vice versa. You could imbue a value with assumptions using a static check or dynamic check and cast.
Okay, would JavaScript (ES5) be a good example to one? 
It sounds like what you want is a headless browser, I recommend phantomjs. You could spawn it as a sub-process in haskell and parse the result. In regards to hspec integration, you could spawn a phantomjs sub-process for each snippet / test, or have multiple tests inside the snippet. Hope that helps.
&gt; Compatibility with distributions which enable position-independent executables by default I wonder if that fixes the text relocations issue on Android 7.0
Note that there is an ARMv7 binary distribution which I believe should run well on most reasonably modern distributions.
I believe this should be considered as a bug in GHC, instead of some heap behavior that is justified only after one deep dives into STG machinery to understand how it works. Throwing some specific pragma just to remedy this particular issue to me is a non-solution. The real solution is to fix STG semantics, in regard to how it handles currying/arity and thunks.
Racket or Clojure would be my go-tos.
I messed around with it a bit with some admittedly pretty simple cases just with large numbers, and I cannot replicate the issue. Can you perhaps give an example initial state and lex function?
Functional vs OOP is orthogonal to Dynamic / typed. Typed languages are really nice for really big software in my experience. Dynamic typing otoh is a bit more fun but more error prone and makes refactoring much more painful too
I don't know, if they want library writers to care about making their code haskell 2010, or to accept patches from Eta users it would help to call it Eta Haskell or EHC or something. Though a surprising number of folks *do* still care about this. **EDIT** also people are (perhaps justifiably) extremely sensitive to issues of attribution and hijacking in OSS, and this becomes more important when the culture is BSD-licensed software. What does it smell like when http://eta-lang.org/ doesn't contain the word "haskell"? Even if their implementation is from-scratch, how many peoples' work are they implicitly laying claim to by that branding choice? There was a certain flavor of this when FPComplete moved onto the scene; they received a lot of pushback due to their posture and branding choices, even while releasing a lot of demonstrably awesome open source code. I remember the emergence of Ubuntu being the same: no mention of "linux" or "debian" for miles. I don't mean to sound negative as this seems like a very exciting project (which I might try out myself), but I think names, branding and attitudes end up being rather important.
The hash itself is just a naming convention for unboxed types (i.e. not heap allocated). `(# Int#, Double# #)` is for example an unboxed pair an unboxed int and double. There's a `UnboxTuples` language pragma needed to use unboxed tuples and `Int#` et al need to be imported from `GHC.Prim`.
So tiny. I like. I'll have to give rofi another try. I downloaded it a while ago and after 10 minutes gave up. That was with a different window manager, though, so maybe it'll be easier the second time around.
Oh, yes please. That’s one of my biggest gripes when writing Haskell, having to jump to the top so often to write boilerplate imports.
"Functional programming" doesn't have a single, clear and concise definition everyone agrees on, so this sort of question is very hard to answer. I don't want to get into a discussion on what is and isn't functional programming. I will say one thing about functions: when we think about functions, we think of them as mappings between a domain and a codomain. That is, the domain and codomain *are part of the function*. This is what types in Haskell give us: an easy, automatically inferred language to talk about functions *including their domains and codomains*. That is, types give us a natural and convenient answer to the question of what a function maps *from* and what it maps *to*. This is nice theoretically—it makes functions in our language more akin to functions in math—but it's also incredibly nice *practically*. I actually find it easier to write and think about functions using types, because I don't have to spend nearly as much time thinking about what a function takes in and what it needs to produce. This makes *calling* functions incredibly easier and it even makes functions easier to define in the first place: I can declare the domain and codomain ahead of time and then fit the body to the "shape" of the type. In essence, types give me a nice blueprint for what the whole function has to look like.
It might make sense to have three kinds of substructural weights instead of two. This third one could refer to something that provably does not have a cyclic reference with itself. This would enable reference counting to be used instead of garbage collection, which, in turn, would enable deterministic freeing of resources without manual management. Also, if there was a way, to attach a destructor to such a value then lazy IO could actually work. Something like: readLines :: Path Absolute File -&gt; IO (refCounted: [String]) Then when all references to the list and any of the contained thunks are gone, the file could be freed. Perhaps this third weight does not have to be visible in the type system because it does not seem affect the usage of the values. A function of this form would be satisfactory. unsafeRefCounted :: 1:a -&gt; IO() -&gt; IO a
Just ignore it and install stack.
AFAICT that's just a description of CQRS+ES. Which is *good*, don't get me wrong, but it's not original... as noted by Greg Young (paraphrasing): "Accountants having been doing this since accounting was invented." 
press Ctrl-+
I am running an older version of Chrome and the content does not load. I get "Uncaught ReferenceError: Promise is not defined" `3.post.52afbd2ddad221275bff.js:452`. It works fine in Firefox.
You can install `cabal` using `stack`, but why would you? You can use `stack install` to install things. Stack can install all the tool stack including `ghc` and the required libraries pretty easily. Just download the stack binary. Run `stack setup` and you will have a running ghc. You need to have `gcc` and a few tools installed, but if you use `wget -qO- https://get.haskellstack.org/ | sh`, it installs those prerequisites for you as well. See https://docs.haskellstack.org/en/stable/README/
Heh
The author didn't know what they were talking about, and one would be better just reading the [README](https://github.com/LuxLang/lux). Lux itself seems fairly decent, though I haven't read all that much about it.
I see what you did there.
To clarify, I guess I was looking to leverage functor/applicative/etc machinery to modify the state itself, whereas with the state monad the state takes a backseat to the value that's produced. But maybe my question doesn't really make sense, and nothing 'magical' is going to emerge if I'm looking for an applicative instance where there isn't one.
Ah I see, so the functor modifies the output type but not the input type. That's a reason why I can't use it, unfortunately.
Oh thank god. Please have some gold to speed the release gnomes.
I agree with this point. If we are saying all tests should be unit tests that seems like moving the goalposts somewhat, or at least a different kind of controversial thing to say, but I have to admit that I find the parent argument compelling, that is: you don't need to test the things out of your responsibility, such as those contracts provided by third-party libraries. I guess it has come up for me because I've been using `postgresql-simple`, which means I'm sort of running SQL inside my handlers.
A strict linear type is guaranteed to only have one reference to it and not be a thunk. The compiler is then freed from allocating a pointer to it if it had not already and instead storing it on the stack. The comonoid instance here provides essentially a copy constructor and destructor. As long as this hypothetical compiler allows the calls to `destroy` and `split` to be implicit (like C++ and rust hehe), denotatively, this behaves in the same fashion as an unboxed value. Therefore, the compiler is free to represent this at run time as unboxed.
Well the problem is that `State` is in both covariant and contravariant positions in your type, so you can't make a functor out of it. You can, however, allow those positions to differ in type, and create a `Profunctor` instance.
Ok fair enough :) I don't think I can do that because I need to fold over a list of Inputs. But, just using the state monad should be fine. Thanks again.
A smart import tool is really handy. Specially one that can remove the extra imports, and possibly can convert non-qualified imports to qualified ones.
"Windows 10" &lt;-- from the OP Of course, one could install stack on WSL that way... The README link is good, though; it has a link to the stack installer for Windows. 
that's a fantastic post thanks!
We will recommend library writers to keep things Haskell2010 for generic libraries and it benefits them to have widespread use of the library in both Eta and Haskell anyways. We will most likely be maintaining a separate package server for the Java FFI-heavy libraries like JDBC-bindings etc. and tell people to upload the Haskell2010-compatible libraries to Hackage directly since that makes more sense. I think it would annoy people to download a package from Hackage just to have it fail the build because it was meant only for Eta. Thanks for the concern! I've explained in the [FAQ](http://eta-lang.org/docs/html/faq.html) why we don't use Haskell directly. tl;dr I had an instance where a person give me a look of horror when I mentioned Haskell and it was quite disconcerting. A name change is almost mandatory if you want widespread adoption. And the number of misconceptions people have about Haskell is ridiculous (like it can't do side effects or I/O). It's easier just starting with a fresh name and create the right perceptions from day one that it's a language that can do really powerful stuff, just in a controlled manner that doesn't get in your way. At the end of the day, this is going set those misconceptions of Haskell straight as well. While I do not mention Haskell on the landing page, I go out of my way to list anyone who has contributed to Eta directly or indirectly on the typelead/eta Github page under the "Gratitude" section including the GHC Team and I mention Haskell several times in the docs.
I currently use haskell-mode + hlint in emacs for Eta development and it works pretty well due to the similarities. Unfortunately, intero fails because it's unable to import the new base modules we've added for Java FFI support. We'll probably migrate that off to a separate `stdjava` package in the future and keep `base` consistent with GHC. We'll eventually get eta-mode ready. We could use some help on that front. I'd imagine the changes would be minor.
As /u/RyanGlScott pointed out, it should fix a large number of packages. But not everything. I am aware of a bunch of other issues. Some will be fixed in 8.2, but most in 8.4 as the linker has to be rewritten slightly. What currently for sure will not work is linking against static C++ libraries created by Microsoft VC++. If you find an issue. Particularly linker issues please report them. There's no such thing as too much test data. 
These are the just Foldable methods modulo packing/unpacking Const, right?
Helpful post that shows an iterative approach to writing fast code. Several of the optimizations you made seemed like they were "instinctual" to you. I'm curious if in reality it simply took some guesswork on your part (particularly the "unrolling" of `isPrefixOf`)? Also of interest to me was that no runtime cost is paid for using `Maybe`. I've never benchmarked it or anything, but have always just assumed (not a smart thing to do!) that there was some penalty for using it (Although perhaps this varies based on specific usage?). In some cases, my false belief caused me to avoid `Maybe` altogether. I think next time I had best just benchmark the damn thing!
I use an Odroid XU4. I am frankly not terribly excited about recommending it to others: upstream kernel support is poor (e.g. the only reason it has `cpufreq` support is that I contributed it), it barely has enough memory to finish a build, and the Ethernet adapter is quite flaky (although not quite as bad as you describe). That being said, it does work well enough to get a build out.
Could be missing something, but after implementing `foldMap` via `traverse`, all the examples only used `foldMap`. Could this article also be called "Foldable is the Real Deal"?
Can someone explain to me why the `S.index` version is faster than the one with `S.isPrefixOf`?
Eh? Supplying multiple `stack.yaml`? Wouldn't they overlap?
I'm glad you found it helpful!
&gt; Typo: "we cannot apply a non-linear function... to an argument which is constructed using non-linear assumptions..." should be "... using linear assumptions...", i.e. we can't apply an unrestricted function to an argument that is linear. Nice catch. Fixed. &gt; Also, for linear types, there is no ambiguity about whether (f . g) is a linear &gt; function, the type of (.) will make that clear. However, there are many possible ways to define (.) each of which has slightly different properties, e.g. (.) :: (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c (.) :: (b -&gt; c) -o (a -&gt; b) -o a -&gt; c (.) :: (b -o c) -&gt; (a -o b) -&gt; a -o c &gt; and so on... But note that not all combinations of unrestricted and linear arrows work; e.g., there is no (closed) term with type: (b -&gt; c) -o (a -&gt; b) -o a -o c Well, we _can_ capture the more general term: ``` (.) :: (b -&gt;:u c) ⊸ (a -&gt;:v b) -&gt;:u a -&gt;:uv c ``` as I mention a little later in the blog post. But I'm not sure if you're just expanding on something I mentioned or correcting a mistake?
Note that these mean entirely different things: linearity versus uniqueness, tracking-in-types versus tracking-in-bindings. Comparing type signatures like this is likely to be misleading.
To answer your specific query, the `Category` instance cannot be defined; at least, not with the current definition of `Category`, because the type of composition for linear functions would be ``` (b -o c) -o (a -o b) -o (a -o c) ``` instead. We could get away with `(b -o c) -&gt; (a -o b) -o (a -o c)`, but not with `(b -o c) -&gt; (a -o b) -&gt; (a -o c)`. In Idris it's actually kind of converse; although we can define ``` (.) : {a, b, c : Type*} -&gt; (b -&gt; c) -&gt; (a -&gt; b) -&gt; (a -&gt; c) ``` as you indicate, the _kind_ of that resulting `a -&gt; c` function would be `UniqueType`, not `Type`. So here too the analogue of the `Category` class would need to be generalized somehow.
As an aside, Check out Conals functional reactive programming model. It's a different take on solving similar problems with an (imo) simpler semantics then the one used by redux. There are less usable implementations outside of haskell, but it's instructive to think about. 
I didn't realize `foo :: (Class a) =&gt; (Class b) =&gt; a -&gt; b` was a valid way to write type signatures
2G is barely enough, sometimes you get regressions where a compile starts using 4+GiB of memory. I use the scaleway arm boxes to test arm builds for alpine linux. It still takes about 12 hours to build ghc though. https://www.scaleway.com/pricing/ I also preordered one of these boxes last month, waiting for it to arrive: https://www.solid-run.com/product/armada-8040-networking-community-board/ https://www.solid-run.com/marvell-armada-family/armada-8040-community-board/ A cortex a72 64bit arm should really help out reducing compile time. And it fits in an itx case. Should still run 32bit armv7 stuff fine.
Not at all. Even C++ can do this (the newer versions of C++ support some type inference).
I do :-) But at work C++ is the only choice. So ....
Just expanding. Your post is a nice explanation and comparison of the uniqueness and linearity. Thanks for writing it up.
for the same reason that printf("%d",1); printf("%d",2); printf("%d",3); is faster than for(i=1;i&lt;=3;i++){ printf("%d",3); } in the second example there is the extra traversal i++ as it checks whats left to do in case i happens to be determined at runtime.
Not really. You can implement `foldMap` with `traverse` but not the other way around. Besides, I just picked simple functions to show a point.
For example [stack itself](https://github.com/commercialhaskell/stack?files=1) supplies a `stack-x.yaml` for several LTSs and for nightly.
These are just example to show a point. One particular point is, you can derive all `Foldable` functions with `traverse` and more. 
so for instance, if you build a project with a `--resolver x` flag, then it'd default to the project local `stack-x.yaml`?
That's a much more interesting argument. I imagine the intention here is that the `fold...` functions should be defined globally in terms of `Traversable` rather than being a class? I could see that. However, I see two issues here. 1. Folding is a pretty fundamental idea. It's a way of representing arbitrary data structures in a meaningful way. And not all foldable data structures are traversable. `Set`, for instance (though I could see the argument that `Set` *should* be traversable, but can't because of the `Ord` constraint). 2. For lists, `foldr` is an essential component of its stream fusion. I imagine this would work much worse if `foldr` didn't have a specialized implementation for lists.
Thanks. I also post it on Reddit for blunt critics too :-)
Are there sensible Foldable instances that are *not* Traversable?
Yea I just feel that folding is a fundamental enough concept that it deserves its own class. (Though the class does probably deserve some laws...). See my other comment nearby.
`Data.Set`, for instance. Or this type: data StringList a where Nil :: StringList String Cons :: String -&gt; StringList String -&gt; StringList String instance Foldable StringList where foldMap f Nil = mempty foldMap f (Cons s ss) = f s &lt;&gt; foldMap f ss
Hmm, I didn't mean to be so absolute about that. *If* you are testing some custom database wrapper you *are* going to test it on a real DB. No objections on that. I'm talking about the part where you *use* this wrapper. You should *not* be testing the wrapper at the *use* site.
To specify a bit further: It's not path entries that do that, as such. Its the presence of a system ghc in the path that does that. In older stack versions (anything before the latest), stack assumed that presence of a system ghc in the path meant the presence (in the path) of an msys distro, which led to it not installing one when necessary. This assumption can be violated a number of ways, including just the presence of a ghc installed directly from upstream. The standard workaround was to use a stack config with system-ghc set to false. The current stack not only no longer makes this assumption, but also defaults that value to false anyway.
You can map contravariantly over the input using `lmap` from `Profunctor`. And if you use a newtype to shuffle the order of the type parameters and put the input type last, you can also define a `Contravariant` instance. 
This is awesome. But it definitely highlights some pain points in writing performant Haskell. It's just hard to write code that manages memory efficiently. It'd be wonderful if we had a Haskell-like language that prioritized memory management for performance.
In a very approximate way could that language be rust?
Please fix this problem 😍
Or having it convert to `import Blah (justThese, functions, prettyPlease)`-- that makes it easier to see what's coming from where when looking at new code.
They wanted the command you have to type into your shell to be at least as concise and easy to type as `cabal` so `haystack` would have been at a disadvantage.
I don't think `Set` should be either `Foldable` or `Traversable` because those classes let you observe the order of elements. We need to restrict `foldMap` for `Set` to *commutative* monoids.
This is directly [addressed in the FAQ](http://eta-lang.org/docs/html/faq.html#why-eta-and-not-haskell), it's an attempt to avoid "26 years of psychology and perception that was built around the language" (meaning Haskell).
Dependent types can't directly express linearity. Embeddings are possible, but that's true for Haskell too. 
How are newbies supposed to learn Eta? There is no documentation (except for the FFI) and the fact that Eta is Haskell is hidden in the FAQ.
Xeno.DOM.parse is returning a Left XenoExpectRootNode on all the xml files used in the benchmark for me.
&gt; Some of my docs didn't print out as expected, but I guess I'll figure that out later. For reference, [here](https://github.com/haskell/haddock/blob/8d826904a8a37ada9c74f1821cc8a4a1a5abcd05/doc/markup.rst) are the markup docs for the latest version of haddock. For the misformatted code blocks, I think you'll only need to add an empty line after the preceding paragraph.
Interesting. Actually it may be a good idea generally, since Haskell's tuples are not exactly products, they are lifted products. But if every tuple pattern matching is lazy and `seq` doesn't exist then it seems like tuples and unlifted products are indistinguishable and we get `⊥ = (⊥, ⊥)` observationally.
Foldable's types enforce some laws for free. (Same 'free' as in Theorems for Free.) Those laws aren't terribly interesting, that's why we often neglect them. You could also bring the charge of lawlessness against the definitely useful Default typeclass. In any case, Traversable is great and glossing over Foldable in an explanation of it aimed at beginners seems perfectly cromulent to me. There are also some laws for other typeclasses that use methods from Foldable in their formulation. Of course, if you have a law involving multiple typeclasses, it's somewhat arbitrary which class you assign it to.
Very instructive post on how to approach performance debugging. Thanks Chris!
Hmm, why inlining `elemIndexFrom` made it run in constant memory is a bit obscure to me. I wonder if adding a bang pattern or `seq` as in `case elemIndexFrom ... of Just x -&gt; seq x ...; Nothing -&gt; ...` would also fix it. Alternatively calling `parseTags $! fromGt + 1`.
It is quite easy to use (basic) OpenGL in GHC Haskell, and then you can have "real" graphics
Thanks, I corrected it!
Ah, that's just because as a last minute I added the API and [this validation](https://github.com/chrisdone/xeno/blob/master/src/Xeno/DOM.hs#L124..L127) to check the first node parsed was a root. In the files it's some whitespace content, could probably skip over that. In the end it makes no diff. to the performance. 
In fact combining dependent and linear types is a research problem on it's own. Even Idris is mentioned in the post, AFAIK they don't play well together, e.g. having dependent lollipop function: `f : (x : a) -o g x where g : a -o Type`
I have been dogfooding GHC 8.0.2 myself and I haven't noticed any issues with `turtle` nor `alex`; there is [an issue filed early on back in october blocking `shelly` w/ GHC 8.0.2](https://github.com/yesodweb/Shelly.hs/issues/130) but apart from that GHC 8.0.2 works fine for me. I just tried building `idris-0.99` and it appears to compile w/o any build breakage. Can you provide more specifics about the build breakages you noticed? Which cabal version are you using?
&gt; Embeddings are possible, but that's true for Haskell too. Well ya, that was kinda my point (Haskell has dependent-ish types now, right?). Why do we need builtin linear types if we can already encode this stuff? I haven't actually tried it in Haskell, but what immediately comes to mind from the OP is that file close thing, which we can see [from this paper's indexed monad](https://personal.cis.strath.ac.uk/conor.mcbride/Kleisli.pdf) or even Idris's Effects library can be done quite nicely (afaik those Idris effects don't make use of the builtin linear support, just the regular type system).
Thank you for the clarification, I'm not good at using stack.
According to the website, they're working on an ebook aimed at people familiar with Java.
This is great. I might apply some of the improvements back to hexml (or might not - it's already fast enough for my purposes). I will also benchmark it on the XML I care about, which is very tag heavy. 
I would be interested to see what happens when we run American Fuzzy Lop on the parser written in Haskell. Has anyone ever tried this?
&gt; my results are reversed compared to yours Your `Endo`'s `(&lt;&gt;)` is flipped compared to `Data.Monoid`'s.
Because knowing you can rely on the return type of something is super helpful when tons of your code is plugging output of one function in as args to another. IMHO having a complete lack of a null value is just as important, but most language designers don't agree, apparently.
If you look at the code, you'll see that calls to `elemIndexFrom` are immediately cased on to dispatch between `Just` and `Nothing`. My intuition is that adding the `INLINE` pragma to `elemIndexFrom` gives Haskell the opportunity to fire some optimizations. [This HIW talk](https://www.youtube.com/watch?v=HzBXuvh4Mas) goes into more details on related matters.
Adding a bang on the `!x` doesn't change the speed here.
Yes, I think that is the [case-of-case optimization](http://stackoverflow.com/a/35815694/477476) firing.
That is true, but why have a more general `traverse` function, when all tasks can be done with the simpler and more specific `foldMap` function? It would be nice to have an example which would need the full power of `traverse` and could not be implemented with `foldMap`.
I run Debian on both the workstation and the servers, so for most things I can afford to just build on metal and copy the binaries over; however, I have a few 32-bit servers still that won't run my 64-bit binaries, so in order to compile for those, I build on a VM. For [sprinkles](https://sprinkles.tobiasdammers.nl/), I abuse TravisCI as a build service, however this only works for 64-bit; the 32-bits still have to be done on a VM. If I were you, I'd look into a build VM - I'm sure your dev machine has at least 8 GB of RAM and a reasonably beefy CPU with all sorts of virtualization support (if it doesn't, demand one that does), so it should be able to handle those builds without too much of a performance hit. Alternatively, arrange for a proper build server; either a physical machine on your office network (or home, as the case may be), or a VPS on sth like AWS or DigitalOcean or whatever.
FWIW, I've filed an issue to the `hackage-trustees` repo with packages that error when building (i.e., not failures due to bad install plans, which have been thoroughly spotted [here](https://github.com/fpco/stackage/issues/2203)) in https://github.com/haskell-infra/hackage-trustees/issues/93.
Unfortunately you were unable to receive a single blunt criticism
Yeah I wish to build on my dev station. It's for a side project. Having to setup a dedicated build machine seems to be overkill for my case. Thanks for the input, though :)
The downside to using Codensity Set (or Coyoneda Set, or this more ad hoc construction, etc.) as your monad is that that after several &gt;&gt;='s in the monad you can very quickly get to the point where no computation is going to terminate in your lifetime, as nothing gets reduced until the very end. Take a simple (Bool -&gt; Set Bool) computation as your step function that just always returns both true and false, then &gt;&gt;= to that function 32 times in sequence. a true set monad (in a language that admits it) can terminate nearly immediately, doing like 64 items of work, as it is able to collapse the possibilites after each &gt;&gt;=. Where as something like Codensity Set pays for the entire 'tree' of possibilities at each step and needs to do 2^32 things before it can tell you the result is the set of {True, False}. This construction comes for free, but you get what you pay for!
Sadly, 'Free(r) Set' is bigger than 'Set'.
I have used NixOS on a Raspberry Pi 3 and a bit on the [C.H.I.P.](https://getchip.com). Things have been working fine for me on the RPi3. Everything I have tried seems to work including the GPIO pins, bluetooth, wifi, and the camera port. I use the HDMI output, but have not tried the display port. I did it 'the hard way', and actually compiled NixOS from the ground up. And I definitely had to apply some patches here and there to get everything to build. I am hoping to start pushing those patches upstream next week. I think the biggest task left to do is to get openjdk built so I can build bazel so I can build tensorflow. 
Set is the canonical example. data Repeated a = Repeated !Int a deriving Functor instance Foldable Repeated a where foldMap k (Repeated n a) = f (k a) n were f x y | even y = f (x &lt;&gt; x) (y `quot` 2) | y == 1 = x | otherwise = g (x &lt;&gt; x) (pred y `quot` 2) x g x y z | even y = g (x &lt;&gt; x) (y `quot` 2) z | y == 1 = x &lt;&gt; z | otherwise = g (x &lt;&gt; x) (pred y `quot` 2) (x &lt;&gt; z) is an example of something both Foldable and Functor, but not compatibly Traversable.
Neat. The armada 8040 looks like a nice build machine. Though it is also in the price range where I start to wonder if it would be practical to use a OnePlus 3T as a build machine: - Quad Core, Kryo™: 2x 2.35 GHz, 2x 1.6 GHz - 6GB LPDDR4 - 64GB onboard storage - $439 I think the big limitation is that it is only USB 2.0. If it had a USB 3.0 port, then you'd be able to hook up a fast external disk. The advantage is that you get 6GB of RAM. Though, I am not sure how useful that is for building ARMv7. I'd also be concerned about heat dissipation for long running builds. A used OnePlus One has 3GB of ram and a quadcore 2.5GHz processor. I think the sell used for under $200 now. Obviously there are tons of used cell phones out there -- I mention the OnePlus series because they are cheap and you don't have to jump through any special hoops to root them. And, since I have a rooted OPO, it is something I can actually try easily :) 
Save the length of `grayscaleMap`, so you don't walk the list twice every time you call `intensityToChar`. You could also memoize that function or use an IntMap for your `grayscaleMap` (would perform better than many list traversals) 
But further down the thread you say that you fixed the issue by increasing laziness...?
If you use stack you can build your application inside a docker container and deploy the resulting executable. See the [stack - docker integration documentation](https://docs.haskellstack.org/en/stable/docker_integration/)
That's very interesting to me what could you represent with Free Set that you couldn't with Set
&gt; stack - docker integration documentation wow I didn't know this before. I think I missed it somehow. Thanks!
My bad, for a side project all of this is obviously overkill!
You could try compiling Haskell stuff to C using JHC, and instrumenting the C intermediates.
What are your performance requirements? If you're not really taxing the executable, try just interpreting it. Much less memory overhead.
This is our pipeline, but you could do something similar to deploy to not-beanstalk. Basically using the free tier of CircleCI as the build machine. https://medium.com/@folsen/deploying-a-haskell-application-to-aws-elastic-beanstalk-24c7c29d3a8f
I found that [this](http://learnyouahaskell.com/recursion#quick-sort) explained it rather well.
So first, you take 'x' as your pivot, so in this case the first element of the list. Then you take all elements other than 'x', in this case 'xs' (the rest of the list)and you split it in two lists. Where 'yx' is the list of of all elements lower or equal to 'x' and 'xz' the same for higher. The expression 'ys = [a | a &lt;- xs, a &lt;= x]' is a list comprehension. It takes all a's out of the list 'xs' where 'a' is smaller or equal to 'x', i.e. all elements of 'xs' smaller or equal to 'x'. And before putting the 'ys' and 'zs' around 'x', you sort those two list recursively first. Note that however this implements the idea of the quicksort algorithm, it's time complexity and performance is alot worse than normal because of the list opperations.
How has your experience with using stack for dependency management with docker been? I did that strategy but build times were way too long as they had to download and build all of the dependencies there (AWS). 
[removed]
I have zero experience with the docker integration; I only know about it because I've seen it mentioned in a changelog (or maybe /r/haskell). Either way, it fits OPs requirement so I thought I'd mention it. 
LinearTypes will help with this example. 
It is now :)
&gt; The functor instance is hard to get I think. If a function has type (s -&gt; s), if I change the outgoing type I have to change the incoming type as well, which seems impossible. &gt; I think I could make a contravariant functor over the input, but I'm not sure how useful that is. Any function `a -&gt; b` is an instance of `Profunctor`: Contravariant in the first type argument and covariant (Functor) in the second. This is pretty useful at times.
Three fewer key strokes is more highly valued than improved searchability? If this is the case, the decision was more fickle than I imagined. - Time to type `stack`: 200ms - Time to type `haystack`: 320ms - Time to type `stack` and have your project compile: several minutes + 200ms - Time to type `haystack` and have your project compile: several minutes + 320ms Not seeing the real usability advantage there...
Yea, I often read about FRP but it doesn't seem like a big win to me so it's hard to get motivated to make use of it, especially for game programming. Here's my current understanding of its advantages/disadvantages: Advantages: - Allows expressing behavior in terms of continuous time - No need to create/manage data structures for tracking some state. Just fold over time instead. Disadvantages: - Potential memory leaks in FRP implementations - Harder to 'see' state of entire program Is that all fair/accurate? I guess the advantages don't seem so great for game building-- maybe they pay off more in web programming. For games, it's not really that hard to update state based on a time delta, and there's not really much extra UI state to track outside of your game world. But dealing with a memory leak would be super frustrating I think. Or am I just making the same argument as 'programming without static types isn't that hard so why bother with haskell'. ;)
we use ansible, with some cloudformation to do provisioning, all hooked up to autodeploy on accepted code review+CI passing. It's a bit clunky in parts, but it does have the advantage of avoiding docker.
You asked for code review, and I noticed a resource leak in [createSocketPassive](https://hackage.haskell.org/package/ftp-client-0.1.0.1/docs/src/Network-FTP-Client.html#createSocketPassive): if `S.connect` of `print` fail, then `sock` will never be closed. The same issue exists in `createSocketActive`, `createSIOHandle`, `createDataSocketActive`, `createSendDataCommand`, etc.
Ok thanks. Some other folks have pointed me towards profunctor as well.
What do you mean?
My initial test didn't go so well, but I'm not sure if it is eta's fault or my fault because I haven't used straight cabal in a long time. Created a project via `epm init`. Added basic-prelude (or any other library) as a requirement. `epm configure` or `epm build` gives me: epm: At least the following dependencies are missing: basic-prelude -any `epm install` just echos Resolving dependencies... epm: buildTypeAction Custom `epm update` followed by `epm install basic-prelude` installs basic-prelude somewhere succesfully, but doesn't change the output of the other commands.
I haven't looked at the stack docker integration, however I have used stack on OS x, and then manually launched a docker container for a specific version of linux, mounted the directory from osx in there and used stack to build the executable to deploy, works perfectly for me.
Thanks I think I have tried it and failed also, but now I'm going to wait for the 8.02. I hope that will fix a few issues on os x. 
recursion happens in the 2nd line
Yeah, that is a pretty convincing argument for the armada. I'd love to hear how well it works in practice since I will eventually need something with that type of power.
A typeclass is like an interface in OO language. You define a set of functions that an "instance" of the typeclass matchs. An "instance" is explicitly declared, you define all the function of the typeclass for that type in an `instance` block. Usually a typeclass comes with rules that instances must follow in their implementation of the functions. Theses rules are here to give some guarantee to the developer. For example, you know that if `a &lt; b`, then `a` cannot be equal to `b`. Implementing an instance which does not follow that rule may lead to surprising behaviors. Usually an instance of a typeclass for a type is defined in the module where is defined the typeclass or the type. `Eq` and `Ord` are typeclass which define the equality (and inequality) and the ordering relation (less than, greater than, ...) typeclass can be seen as a way of implementing operator overloading (as in C++), but that's usually considered bad practice if there is no rule associated.
(what do you mean by "in place"?)
While you're absolutely right, the reality is that writing *highly* performant code is always painful in some way, shape, or form. Using C is painful too. Using Rust is painful in other ways. My point is: no pain, no gain. You can't get amazing speed without working hard.
An observation I had is that your final result `isAnagramMaybe3` is the same as `liftA2 isAnagram` using the `liftA2` function from `Control.Applicative`. `liftA2` takes a function `f` of two parameters, and two arguments with matching types "embedded within" an applicative context, and provides the result of the supplied function `f` within the applicative context. There are many more "lifting" functions for functions of different artity. 
You can do a lot of neat things with stack and docker. I've been [playing around with it](https://github.com/jkachmar/pauvre/blob/master/README.md), and I think it wouldn't be unreasonable to set up a CI/CD pipeline that spits out a 30 MB image at the end to deploy to an AWS container registry, Kubernetes, etc. Building the binary in an intermediate Alpine Linux container and then copying it to a clean container with the minimum number of dependencies works surprisingly well. I'm mostly using that repo as a dumping ground for random nonsense lately, but all the stack - docker stuff _should_ be okay.
That's all fair, but there's a difference between optimized performance and baseline performance. Haskell's baseline performance is severely bottlenecked by the GC in many cases such as the OP. Painless Haskell code will have *much* worse memory performance than painless Rust code.
Interesting. Thanks! I've updated the post.
We have a CI server (Jenkins) build our code for both Linux and Mac, and use the Jenkins API to deploy directly from there to the servers through a custom app.
This isn't really a good example since the loop bounds are known at compile time.
Ok thanks, that's very helpful actually. I'm probably held back by the fact that I haven't actually tried to build something with it. Anything you want to write on the subject would definitely be interesting to me!
Awesome, I'll give it a go! EDIT: Just tried, the stack install process seems to freeze after its first command. Right now it reads colour-2.3.3: configure Progress: 0/35_ If I rerun stack install it will show something else, but never get past the first command. Any idea how to fix this issue?
I understand now that I don't need to worry about Haskell Platform folders remaining on the computer. To elaborate on what happened the second time I tried installing Haskell Platform: ghc.exe (or ghci?) simply didn't install. The paths were added to %PATH% as far as I could tell, but the exe wasn't there so cabal reported ghc as missing when I tried running it. Some further information on why cabal install tidal didn't work: I got some error message in cmd saying entropy-0.3.7 and network-2.x.x failed to install (don't remember exact names). Why might this be? Thank you for your elaborate post!! TO double check, where should I expect to find ghc if it has been properly installed?
I think the state monad is your friend here. Oh! You mentioned folding over a list of inputs. You can use `traverse` for that. class (Functor t, Foldable t) =&gt; Traversable t where traverse :: Applicative f =&gt; (a -&gt; f b) -&gt; t a -&gt; f (t b) instance Traversable t where traverse _ [] = pure [] traverse f (x:xs) = (:) &lt;$&gt; f x &lt;*&gt; traverse f xs foldInputsStatefully :: [Input] -&gt; State MyState [Output] foldInputsStatefully = traverse $ \input -&gt; do -- For each input, do a stateful operation. -- Returns from this body will be accumulated in an output list ... 
&gt; you don't need to test the things out of your responsibility, such as those contracts provided by third-party libraries My responsibility is delivering value. If my project fails, and it's someone else's fault, my project still failed. Tests also serve to validate my understanding of other people's code, and help me know whether it's safe to upgrade a dependency. That's not to say that there's not distinctions to be made in my treatment my code versus dependencies, but I do find a lot of value in having some integration and end-to-end tests.
I don't work in a Haskell shop or anything but I try to keep my side-project portable across platforms. My setup is Stack, some C++ libs, my primary Linux development machine, and for portability to other platforms, an older Windows 10 box that I inherited and a smaller Mac I bought specifically for this purpose. Works well enough for me but probably doesn't scale beyond a couple of people.
On the 8.0.1 platforrm, the ghc binary is in `C:\Program Files\Haskell Platform\8.0.1\bin` I would guess that those two packages failed to install because you didn't alter your cabal config (in step 3 of the platform install instructions) to point to the msys location by adding the extra lines: extra-prog-path: C:\Program Files\Haskell Platform\8.0.1\msys\usr\bin extra-lib-dirs: C:\Program Files\Haskell Platform\8.0.1\mingw\lib extra-include-dirs: C:\Program Files\Haskell Platform\8.0.1\mingw\include Its odd that cabal would report ghc as missing -- cabal itself is to be found (from the platform install) at: `C:\Program Files\Haskell Platform\8.0.1\lib\extralibs\bin`. So if would be very strange if that folder installed, but the other didn't. Good luck getting everything up and running! Tidal seems like a lot of fun to play with.
Is there a good way to make something both a library and an executable? My specific use case is for writing a compiler, the compiler backend might be handy to access via a library, but at the same time I don't want a whole separate package for the CLI as 99% of the time you are going to want both together.
Yeah, that's what I thought. Strange thing: after Haskell Platform install completed (the second time), C:\Program Files\Haskell Platform\8.0.1\bin was empty. I did follow that step 3, so I have no clue why the installation wouldn't work. Thank you for your assistance, I'm defintitely looking forward to getting it to work!
Most CI/CD systems have support for caching build dependencies. If you configure it to cache `~/.stack`, then a given build agent will only need to download &amp; compile the dependencies once (for a given version and resolver).
It is important to remember that one should cache the ~/.stack folder separately for each target platform (seems obvious in hindsight but easy to forget).
I have faced a similar situation and found the best solution was to either dual boot linux and use that for dev, or run a vm with lots of resources. I used vmware but virtualbox would be fine. I was able to generate binary compatible executables and copy them to the cloud server. This required movement of some dynamically linked libraries as well, which provided a "learning" opportunity. Faced with the same situation today I would look closely at the nix-based solutions others have mentioned. Another idea would be to build a compile server. You could build one much more powerful than a laptop with lots of cores, memory and SSD storage for about $2000 using some older cpus/memory. I would run nixos or nix on that too. 
Could you be more specific about what confuses you? Of course there is a definite technical answer, but you probably read that already somewhere and didn't find it helpful given that you are asking. The sentence of which you ask if it is right doesn't strike me as accurate. Saying that typeclasses group a couple of types together is in intuitively conceivable and the definition of the typeclass happens in one place. Membership of a type in a typeclass can be declared basically anywhere though and doesn't happen in one "place" neither in source code nor in some semantical or operational sense. You probably are aware that there are two syntactical keywords `class` and `instance` the first defines what the typeclass (`Eq` or `Ord` e.g.) means and the second declares that a specific type (or type constructor) is an instance of a declared typeclass (e.g. `instance Eq Bool ...` would mean that the type Bool is now a member of the typeclass Eq). There is no function in haskell like `equals :: a -&gt; a -&gt; Bool`. It could be built-in probably, but isn't for a number of reasons. The typeclass `Eq` steps in providing `eq :: Eq a =&gt; a -&gt; a -&gt; Bool`, that is a function like equals but only working on the subset of types that have a `Eq` instance. `Ord` does the same and more giving you `compare :: Ord a =&gt; a -&gt; a -&gt; Ordering` where `data Ordering = GT | EQ | LT`. My favorite somewhat childish way to think of typeclasses is that a typeclass is a function from a subset of all types (or type constructors) to a specific record type. You can add members to the subset (by adding an instance) but then you have to repair the function (by constructing a valid instance) to keep it total. Another more elegant way is that a typeclass defines a predicate on types and instances of the typeclass provide evidence that the predicate is true for a type and therefore make the type part of the typeclass. A few key observations about typeclasses are that: * .. there can only be one instance per typeclass and type, which is why you don't have to mention the instance when using a value or function from a typeclass * .. they are fundamentally open, meaning you can't reliably enumerate all types which have an instance and you can always add new instances * .. typeclasses can be mechanically translated into datatypes and instances into values of that datatype (at the cost of verbosity) like explained [here](http://www.haskellforall.com/2012/05/scrap-your-type-classes.html) I didn't talk about informal typeclass laws which can be seen as a social construct but are a big part of the more useful typeclasses, neither did I mention superclasses nor how instance resolution works. Also there are a few extensions beefing typeclasses up with more capabilities, but they don't change the fundamental concept. There are more useful remarks and intuitions and I'm not sure I picked (or thought of) the most important and useful ones (also depends on what you already know). If you can elaborate on what specifically is unclear, I'll expand on those aspects.
No quick and dirty way to print a value that doesn't implement Show when debugging
This is probably overkill for what you are doing, but https://github.com/uncannyworks/build-server may give a few good hints on how to achieve your goals.
Code and types can tell you what the code does, and perhaps even hint at why. But they have a has time telling you why that obvious alternative approach doesn't work.
Same reason why it’s `ls` and not `list` or even `listdir`. When you are power user each “superfluous” key starts to hurt after a while. That’s why shell completion is so valuable.
AFL's QEMU mode works for any binary. I used it to minimize a crash in hs-asn1 once. It's not as fast as instrumenting at a higher level, but it was good enough.
I think in monads and applicatives abstractly quite often. My intuition around them gives me a different view on many problems than I would otherwise have.
It's easier to read the more abstract version, because I know it doesn't do anything `Maybe`-specific (or `List`-specific, or `IO`-specific).
Hm, maybe. In my game there are definitely situations where I want to be able to write a one-liner. But I guess I could provide functions to flip between the monad and back to a simple function again. I guess my design decision is what should the 'default' be, and maybe the answer is monad...
Thanks, I'll check it out!
I went through the [NICTA course](https://github.com/NICTA/course/) recently and it helped me a lot. I think it just takes practice and then this abstraction is very natural, as long as you understand the underlying applicative.
I was wrong. That change has the effect of forcing the tuple constructor. The simplest solution is placing a bang pattern on b, which forces the tuple constructor, but not the values in it.
&gt; Note that however this implements the idea of the quicksort algorithm, it's time complexity and performance is alot worse than normal because of the list opperations. The problem is the `(++)` operator, right? I tried this to eliminate it, but it doesn't seem to perform any better. Any idea what's up? quicksort' :: Ord a =&gt; [a] -&gt; [a] quicksort' = go [] where go suffix [] = suffix go suffix (x:xs) = let f a (ys', zs') = if a &lt;= x then (a:ys', zs') else (ys', a:zs') (ys, zs) = foldr f ([], []) xs in go (x : go suffix zs) ys 
What? Stack has idempotent build commands already. 
Why? IIRC, the directory name used to scope the binaries includes the compiler version and arch.
Vagrant with OSX host and Linux host. Switching to a Jenkins build server soon.
&gt; If the only viable "IDE" for Haskell is Emacs/Vi you're massively limiting the amount of people who will ever give the language a serious look. Vim and Emacs aren't bad. 
I'll take a look at that when I have some spare time. Sadly my spare time is in short supply. But I've put it on my TODO list :)
Any reason you can't just deal in raw Bytestrings? 
Why do you think non-sum types don't need `_|_`? bottom :: () bottom = bottom
What about let loop () = loop () in loop () :: (a, b)
 λ&gt; let liftI2 f a b = runIdentity $ f (pure a) (pure b) λ&gt; :t liftI2 (liftA2 isAnagram) liftI2 (liftA2 isAnagram) :: String -&gt; String -&gt; Bool (except it's probably more like `dropA2` than `lift`anything :-) 
In such a system all pattern matches on constructors of non-sum types would automatically be irrefutable. So: bottom :: () bottom = bottom is completely indistinguishable from: bottom :: () bottom = () For example, `show` would not be able to distinguish them: show () = "()" which is automatically: show ~() = "()" which is the same as: show _ = "()" so: show undefined == "()" If you can come up with a counterexample function that can differentiate them I would genuinely be very interested, ignoring `seq` of course, as `seq` is a language primitive that would be adjusted in such a system. Ideally your `bottom` example would actually not have a runtime decision, and all uses of it would be statically replaced by `()`.
I mean sure, either `(_|_, _|_)` or `_|_` should not exist, as it is IMO pretty pointless to have both. But my suggestion is much easier to implement than using parallelism everywhere, and probably has more practical benefits.
Interesting idea! Look up codata and "negative polarity" types, they seem kind of related to it. Codata: in total languages, bottom is not allowed for either product-shaped data types nor sum-shaped data types, but in addition to data types there are also "codata types" which admit infinite computations. Those infinite computations aren't bottom either because they are "productive", but let's call them bottom-ish for our purposes. Here are the similarities with your idea: (1) Those codata types are always products, never sums; (2) Since the language doesn't have bottom, that product is not bottom either; (3) the components of that product may be bottom-ish. Negative polarity: I'm less familiar with this one, but my understanding is that some types, like functions, are intrinsically "negative", while some other types, like sums, are intrinsically "positive", and then other types, like products, come in both a positive and a negative variant. Normally a type only contains or returns values of the same polarity, except at special points at which the polarity reverses, and that's important for mumbo jumbo focusing bla bla bla evaluation thingie thing. That sounds related to your idea because the points at which your nested products switch to sums are important for evaluation, it's the point at which we stop constructing bigger thunks out of expressions which come from irrefutable patterns, and we start to evaluate all of our accumulated thunks, "focusing" on the part of those thunks which answer our question about which of the sum's constructor is used, if any.
[Unlifted data types](https://ghc.haskell.org/trac/ghc/wiki/UnliftedDataTypes) is what you are looking for. However the majority of Haskell types, functions, etc only work well with things in kind `*` (boxed, lifted types). Switching to `#` means losing the ability to use practically any handy combinator you've known so far.
It seems to me as though you could still implement what I am suggesting while keeping things in kind `*`, if you look for example at my edit that explains a possible implementation, however some of the optimizations might only work in situations where GHC is able to use kind `#` instead. The main benefit I see is that I am pretty sure lifted tuples can basically never be optimized into kind `#`, but I am pretty sure that with the change I am suggesting it should very frequently be possible. I also think that some of the possible optimizations might be unrelated to being able to use kind `#`.
Looks cool! Yeah I might implement my own on top of `Vector` assuming it isn't too crazy difficult, automatic in-place resizing when necessary might be hard for situations such as my immediate knot tying example.
No, but you'll have a hard time convincing many people to use them over a shiny IDE.
When you pattern match on a value it's first evaluated to WHNF, so `bottom` is inspectable in a sense. Pattern matching on `bottom` will force its evaluation to WHNF which will cause the program to not terminate, which is different from pattern matching on just `()`. If you want types that actually don't have bottom, then you can use unboxed types. Since these are unlifted, they cannot contain bottom. Thus, any value of an unboxed type is definitely known to terminate. However, these suffer some major disadvantages, although they give you unboxed products (via tuples) but no unboxed sums.
I have a similar situation as the OP: I develop my yesod app on a powerful Mac but the yesod binary has to be developed to an OpenBSD server with 512 MB RAM. My Solution is to build the app on the Mac in a VM running the same OpenBSD version as the deployment server. After the build finished I rsync it to the deployment server. 
Looks great! Perhaps a few simple example source code files and their core dumps would illustrate it nicely for people not acquainted to core.
Thanks a lot /u/josephwrock for the tutorial. It will be very helpful in translating. However, I'm a bit worried about &gt; I'm going to simplify the truth and lie to you for the sake of clarity; in the process, I absolve the following of being even remotely correct. 
haskell-ide-engine was originally conceived as implementing a common protocol to the frontends. There is now one under active development at [Microsoft Language Server Protocol](https://github.com/Microsoft/language-server-protocol/wiki/Protocol-Implementations). The work on this is taking place at * https://github.com/alanz/haskell-ide-engine/tree/lsp * https://github.com/alanz/haskell-lsp * https://github.com/vibhavp/emacs-lsp * https://github.com/alanz/vscode-hie-server It is a proof of concept, but already works with emacs and vscode, providing hlint hints, types on hover, and HaRe renaming. I am engaging with the protocol designers to extend it to support general [commands](https://github.com/Microsoft/language-server-protocol/issues/61)
For those interested, here is an [example output](http://yav.github.io/dump-core/example-output/Galua.OpcodeInterpreter.html) from the program.
I can, but I didn't know I had too until this surprising error. However, just adding `=$= encodeUtfC =$=` /u/snoyberg works.
`basic-prelude` has not been tried yet, so I went ahead an submitted a patch. Run `epm update` and try again and it should work now. You can request for us to make a patch for a given package in [eta-hackage](https://github.com/typelead/eta-hackage).
How often in your business logic does a `fullName` behave like a `password`? If the answer is "practically never", then maybe not putting them in the same record will naturally clear up a lot of difficulty. In the backend I manage, authentication is almost totally separate from the rest of the code base. It has all sorts of strange dependencies (facebook, SMTP, etc.) and requirements which are not needed anywhere else in the code.
Yes we'll use the pragmas for any divergent features. The architecture for any new feature would look just like normal GHC. And yes, we do depend on GHC's codebase. The current implementation can be faster than GHC **after JIT warmup** in some special cases **after JIT compilation** but it can also be very slow in some others. Warmup time can be as fast as some 100 milliseconds or as slow as 5-10s depending on the complexity of the application. For server apps, you don't even have to worry about performance with Eta. For client apps it's not that bad: eta-2048 was running pretty smoothly but it's not such an intensive app (like an IDE or build tool) to judge performance on the client side. The code generated by Eta is pretty good but it can be a lot better. I'll be filing issues in the coming months highlighting all the codegen optimisations we can try. The current priority is to finish up concurrency support which requires generating more bytecodes so there's a chance that it may prevent the same JIT optimisations that made Eta compete with GHC above. I'll run the benchmarks again after concurrency is done and share the results. Also, work is being done to setup a performance dashboard for Eta similar to gipedia for GHC and we'll share it here once it's hosted. We're going to be pretty disciplined about watching for performance regressions. Method-based JIT compilation applied to a lazy functional language is an unresearched topic to my knowledge (if anyone knows any papers, please forward). The JVM is evolving to give power to the language developer to add their own JIT optimisations so lots of avenues for Eta to become competitive with GHC (after JIT warmup of course!) with lots of hard work.
I'm more intersted in the general principle of having protected/private fields for various reasons in Haskell - not this particular example. Some more examples: * A `status` field that is used all over your code, but which, when changed, needs to have some side effects. * The `email` field in the example given in the question - it will definitely be used all over the place, but needs to be treated specially when changed. * A `createdAt` or `updatedAt` field, which, again, can be used all over the place. But only the DB layer should be changing it.
May I request to re-read the question keeping just one change in mind, i.e. `setEmail` and `setPassword` are NOT defined on the `User` model but, say some `UserService` model. Does this change the core concept of my question? Are you essentially saying this: updateUser1 :: UserId -&gt; FullName -&gt; Age -&gt; IO User updateUser2 :: UserUpdate -&gt; IO User initiateEmailChange :: UserId -&gt; Email -&gt; IO VerficationKey verifyEmailChange :: UserId -&gt; VerificationKey -&gt; IO User changePassword :: UserId -&gt; Encrypted -&gt; IO User While this mind sound good in theory, this leads to type-related boilerplate for "dumb" updates in the case of `updateUser`` and `updateUser2` above.
Wouldn't that make the API even harder to write, harder to use, and harder to reason about (and infact go against the *principle* of Haskell)? Which API would you prefer working with: * `updateUser :: User -&gt; IO (User, Maybe VerificationKey)` which will silently send out email notifications if the password is changed. And it may also result in a `VerificationKey` if the email is changed (and will also silently send an email notification). * Or, `updatedUser` `changePassword` &amp; `changeEmail`?
Here are two examples: Away from `Maybe` cases to `Applicative` to get more **succinct** code, taken from this blog post: -- this original isAnagramMaybe :: Maybe String -&gt; Maybe String -&gt; Maybe Bool isAnagramMaybe xs ys = case xs of Nothing -&gt; Nothing Just s1 -&gt; case ys of Nothing -&gt; Nothing Just s2 -&gt; return (isAnagram s1 s2) -- becomes isAnagramMaybe2 xs ys = isAnagram &lt;$&gt; xs &lt;*&gt; ys And away from `Monad` to `Applicative` to get more portable and (potentially, depending on the `Applicative` instance implementation) **parallel** code for free. From Simon Marlow's [Haskell 2016 paper](http://research.microsoft.com/en-us/um/people/simonpj/papers/list-comp/applicativedo.pdf): -- this original numCommonFriends :: Id -&gt; Id -&gt; Haxl Int numCommonFriends x y = do fx &lt;- friendsOf x fy &lt;- friendsOf y return (length (intersect fx fy)) -- becomes numCommonFriends x y = (\fx fy -&gt; length (intersect fx fy)) &lt;$&gt; friendsOf x &lt;*&gt; friendsOf y Would it be possible to develop `Applicative` refactorings such as these into hlint? CC /u/ndmitchell
Yes, but I never assumed you meant mutating. I just want to know how exactly you have the persistence/DB level updates envisioned.
Hmmm... which brings me to my other related question. What's the easiest way to build &amp; maintain these "related types"? This is what I mean by "type related boilerplate"
...and this is the question I can only subscribe to, but I don't have the clear answer for (but generally, not only in Haskell)...
Why do you consider it boilerplate? The thing you are sending to your API to perform updates are often different from what's stored in DB, and this is regardless of the language. Was it really that different in Ruby-land? I come from .NET land, and most projects I've been involved in had separate API types (even if it was sometimes just annoying).
Here's how Ruby/Rails solves this problem: class User &lt; ActiveRecord::Base attr_protected :email, :password def changeEmail(newEmail); end def changePassword(newPassword); end end user = User.find(10) user.update_attributes(incomingParams[:user]) # attr_protected will prevent email &amp; password from getting changed user.save!
Definitely. Also cool to see a proper [Lua implementation in Haskell](https://github.com/GaloisInc/galua). I wrote a partial one for a course which was also my first Haskell project and it's nice to see how much better it can look. 
I'm very interested in how [mysql-haskell](http://hackage.haskell.org/package/mysql-haskell) perform in DB bench, could you give it a try?
You can get the semantics you desire for individual types with pattern synonyms {-# LANGUAGE PatternSynonyms #-} data Pair a b = PAIR a b deriving (Show,Read) pattern Pair :: a -&gt; b -&gt; Pair a b pattern Pair a b &lt;- ~(PAIR a b) where Pair a b = PAIR a b Then just don't export `PAIR`. Now the `Pair` "constructor" always does a lazy match.
recursion happens where you see an application of self... your function`f` recurses by calling itself `f ys` and `f zs` but first it needs to prepare the new inputs `ys` and `zs`.
That seems to make sense with the existing strictness semantics for newtypes. newtype Unit = Unit newtype Pair a b = Pair a b This would only force evaluation when you pattern-matched on the fields, if any.
Consider the function `sum`: sum :: (Foldable t, Num a) =&gt; t a -&gt; a It works on any foldable container filled with any numeric type. This means you don't have to write the following functions: sumListInt :: [Int] -&gt; Int sumListFloat :: [Float] -&gt; Float sumVectorInt :: Vector Int -&gt; Int sumVectorFloat :: Vector Float -&gt; Float ... sumMapComplexDouble :: Map k (Complex Double) -&gt; Complex Double ... We reuse the same *implementation* across a big number of combinations of container types and numeric types. What's more, we can create our own container type and without touching any other code we can reuse the existing sum function over our container type containing any existing or future numeric element type. Similarly when we create a new numeric type.
Right, now I'm wondering how often one'll write functions polymorphic in that parameter in a typical CRUD scenario (which kind of differs from something like CSV processing), /u/saurabhnanda if this code is already somewhere in action, could you link to it?
I have a Windows desktop that runs an Ubuntu 64 bit VM that I do my dev' on (or I use my Linux laptop if I'm not at the desktop). The servers I deploy to are all linux, so I have Jenkins build the binaries and deploy to AWS or local docker containers.
Only because type unification is deliberately not done for `#` types IIRC. I’ve never been quite sure why this is - is it just for efficiency inside the compiler, or is there a deeper theoretical reason?
To go in HLint they need to make the code clearer - the first does that, but the second looks more complex. 
It's also a "documentation" things. If you have 3 types classes for users, nothing stops you (or your workmake) to use the unprotected one and save it, or you might not even be aware of the existence of the 2 others. With this, it might be more obvious that theyr are the same entities with different "facet". Also, it solves the overloaded record problem (not anybody uses the last version of GHC) and allows conversion function to be written quite easily using wildcard records. Ex toCreate :: User Read -&gt; User Create toCreate User{..} = User{..,userPassword=decrypt userPassword, createdAt=(), updatedAt=()} Of course, the more fields left unchanged, the better ...
This paper is based on real world scenarios using Liquid Haskell to verify popular Haskell libraries: http://goto.ucsd.edu/~rjhala/papers/real_world_liquid.pdf
Discussing (and *action*) the TechEmpower benchmarks What?
I wouldn't say that it is typically less efficient, sometimes sure. But remember that both of them involve fairly equal amounts of thunking. In both cases a and b will both be thunked. The only difference is whether or not the constructor is forced, and since a tuple is not strict in its elements forcing the constructor doesn't do much to effect the amount of thunks. A huge amount of libraries and functions lazily match on functors. Look at Control.Arrow, Data.Bifunctor and functions like partition. Lazy tuple matching is the main way you are able to do guarded recursion with multiple return values, partition being a great example. Losing that guarded recursion due to a strict match on the constructor can actually massively effect performance in a lot of situations, with potentially huge stack usage that should normally be O(1). And this is ignoring the optimizations that can now happen due to the fact that tuple constructors don't really exist anymore. So they can hopefully be largely eliminated at compile time. So that tuple constructor you are worried about leaving as a thunk may never exist at all, it will just essentially be two values.
You can have invariants without types. Personally I like that parts of my code are checked by the type checker since it catches many errors I would have to check for manually otherwise. Even better that it catches errors before hitting code paths at runtime. But claiming you need types for **any** sort of serious programming is certainly hyperbole. 
I'm not sure how seq would interact with them. It would probably just not do anything, you could also make it force all elements or perhaps do the old seq typeclass approach and disallow it. 
With single field newtypes, seq of the newtype forces the field, so forcing all elements would be consistent. However, that would go against the proposal.
That is not my point at all, I really thought I was making myself very clear. You would make it so that matching on these non-sum type constructors is always irrefutable, and thus does not evaluate the constructor. And thus bottom and () would not be possible to distinguish. Right now go ahead and try to distinguish them in an actual program with a "main" without using strict pattern matching or seq. I guarantee you that it is not possible. It is actually possible to get the exact semantics I want without any changes to GHC, we just don't get any of the optimizations. See Edward Kmett's comment [here](https://www.reddit.com/r/haskell/comments/5no3tj/comment/dcddjud?st=IXVTHJTI&amp;sh=ae29c104). So clearly such a thing is not unsound. 
In this case `User` would become sort of `UserWrite` and would contain only `userName` and `userAge` meaning you can just write `updateUser :: UserId -&gt; UserWrite -&gt; IO ()`
One way to approch this is to use Haskell modules as equivalent to OOP classes. Create a module `Application.User.Internal` which contains all private/protected/unsafe/internal things and a module for the public API `Application.User`. This way internal functions can also be tested and provided to those users of the module with more advanced requirements. Then have functions of the following types in the public module. -- Creates an email and a DB update for a user. changePassword :: UserId -&gt; Encrypted -&gt; SendPwcMail -- Sends the email and performs the DB update to the user. sendPwcMail :: SendPwcMail -&gt; IO User and also `initiateEmailChange` and `verifyEmailChange` from your post above. This should encode all of your invariants. You can't update a user password without also sending an email. Also emails can only be changed after receiving a response from the user. Of course that's type-related boilerplate. You are using the typesystem and modules to encode invariants, after all. These invairants have to be written down somewhere. And lenses should play no role in this as they have very little in common with OOP setters, which often include non-trivial computation, sometimes even with side-effects. Lens setters are meant to be accessors to public fields. There is very little you can do in a lens setter that doesn't violate the lens setter law set l y (set l x a) = set l y a or any other laws if the lens is also a getter or traversable. There is no place for anything stateful in this and you certainly shouldn't do any IO side-effects within a lens setter, like writing to a database.
&gt; Is this generalized implementation useful? Maybe. Is this fun? Definitely. It is not only Maybe useful, it is also List useful and a bunch of other applicatives. ;)
Oh, for a while I thought the `User{..,userPassword=decrypt userPassword}` means the .. will fill the rest of the fields, was I wrong or is this the case?
Is there any way to keep track along the optimization passes of the history of transformations that took place? If we could we could have something like source maps and with a viewer we could easily decorate the source code with notes about what got inlined, eliminated, etc.
Those packages are pure Haskell and would normally compile without problem. The problem here is with custom build types at the Cabal level that are not supported in `epm` yet. `system-filepath`, one of the transitive dependencies of `basic-prelude` uses a custom build-type. `epm` can support custom build types as soon as `Cabal` the library can be compiled with Eta, which is coming soon.
I wonder why Spock lags so behind its peers...
Just tried it and got syntax error on the `..,`. What extensions does it need?
It's missconception that `servant` is only for APIs. You can make website with UI and forms etc with servant as well. type API = "feedback" :&gt; Get '[HTML] FeedBackPage or more generally, I use https://github.com/futurice/haskell-mega-repo/blob/f05df8c24f600053b042d02f81b999f0c302ae19/futurice-foundation/src/Futurice/Lucid/Foundation.hs#L110-L119 so I can write type API = "page1" :&gt; Get '[HTML] (HtmlPage "page1") :&lt;|&gt; "page2" :&gt; Get '[HTML] (HtmlPage "page2") server :: Server API server = page1 :&lt;|&gt; page2 where page1 = HtmlPage $ do ... lucid code page2 = HtmlPage $ do ... more lucid code, actually in different files etc. You just don't get much out of servant generation automation, docs for html pages are not interested, you cannot consume them with `servant-client` etc, so it's quite shallow `servant` library application. I.e. there is not much benefit of having the API type separate from the endpoint implementation. OTOH, you can reuse all query/capture param parsing code etc. 
-XRecordWildCards It might needs the `..` at the end.
I mean traversing a vector does sort of create the new vector through a series of mutations on that vector right? Otherwise it would be `O(n^2)` if you needed a new data structure at each step. 
I'll probably look into making that change in relevant libraries next week. If you're interested in the details of why this happens, I described it in more detail in this post: http://www.snoyman.com/blog/2016/12/beware-of-readfile. I saw your answer about Docker in a different comment. Setting the `LANG` environment variable to something specifying UTF-8 is probably a very good idea, as there are lots of pieces of code lying around the ecosystem that rely on system locale.
Edward Kmett gives another example if you see his nearby comment. I am sure there are more, I can take a look later when I am back on my computer. 
For the record, the low-level `mysql` package has finally been fixed regarding the concurrency issues (see [here](https://github.com/paul-rouse/mysql/pull/15)). However I don't think libraries like `mysql-simple` actually take advantage of this fact yet. 
Right, needs to be at the end. Many thanks for it, TIL! :) And it can be used with separate types just as well: data UserApi = UserApi { name :: Text, password :: Text } deriving Show data UserDb = UserDb { userId :: Int, name :: Text, password :: Encrypted } deriving Show toUpdate :: Int -&gt; UserApi -&gt; UserDb toUpdate key UserApi{..} = UserDb{userId = key, password = encrypt password, ..} 
I *observed* a huge performance boost when I updated `mysql`, `mysql-simple`, and `persistent-mysql`. Hopefully they're not explicitly taking advantage of that fact, and will be even more performant :D
How do you propose writing the general `updateUser` function given the following: I know that it's not possible to mutate a record in Haskell, so while it's possible to write something like this: updateUser :: Connection -&gt; User -&gt; IO User It will have a very jarring usability, because it will allow you to send in a User object that has new values for email and password, but the User object that it gives back, will completely ignore those fields (essentially reverting them to their original value). Isn't this absolutely surprising? And the function's type signature is not capturing this behaviour at all!
I think the places where I’ve run into this issue have been ones where that wouldn’t actually have mattered - unboxed values would still have ended up being passed to functions expecting unboxed arguments after type unification over the #’d types in the program in question, but the fact that GHC refused to unify over # values at all was something of a stumbling block :)
will you expain how?
so what do you recommend for web forms and the rest of the website apart from rest api?
is that a wise approach? is that common to create web services like that?
&gt; E.g. Would it be possible to get rid of the bound checks in yesterday's XML parser? Yes, it should be possible to use LiquidHaskell to remove the bounds checks (in fact, eliminating bounds checks was one of the original motivations for refinement types). Section 5 of http://goto.ucsd.edu/~rjhala/papers/real_world_liquid.pdf gives a taste of this kind of reasoning in the `bytestring` and `text` libraries, which we have proved memory-safe with LiquidHaskell (we actually found a bug in `text`). /u/tekmo also has a brilliant writeup of removing such checks from a simplified parser, along with a performance comparison (https://github.com/Gabriel439/slides/blob/master/liquidhaskell/slides.md).
aaahh, I don't want to have client side on js only.
It's interesting that `bottom = ()` *is* a solution to `bottom = bottom :: ()` viewed as an equation.
It seems like all you're saying is "it changes the operational semantics!" Which is true, but also the intent. Can you establish that the change is harmful? By far the biggest damage to the existing ecosystem that I see is breaking all uses of `rnf :: a -&gt; ()` from `deepseq`, I may be missing other things too, although many of them may fall under "... but you shouldn't do that anyway".
I don't like the relationship between Constraint and tuples. The fact that `()` is ad-hoc overloaded to have the kinds `*` and `Constraint` and the fact that `(a, (b, c))` is the same as `((a, b), c)` without any fundamental machinery behind it.
This was a nice read. The Monad instance for Set at the end really helped things click - thanks!
As others have said, you're probably better off having the email address outside of the user object. Email addresses and passwords aren't very good fits for CRUD operations on the user (actually, as business applications get more complex, CRUD fits less and less well). For another thing, users tend to have multiple email addresses and passwords, so in relational terms they're in another table anyway. I think the equivalent in Haskell is as follows: -- Update a user do user &lt;- userFind (UserId 10) let user' = updateUserAttributes(incomingParams "user") userSave user' -- Change email do let userId = UserId 10 let email = 'mmouse@disney.com' user &lt;- changeEmail userId email The idea here is that changing an email is a separate action from updating a user. You're highly likely to have separate user details and password change forms, after all. And I'm not passing the whole user to the password change action either - it doesn't need it. And typically you'll only have the ID in the request anyway. Another thing people often do is define `UserId` with a phantom type. That is: type UserId = Id User The idea here is that it's an ID that identifies users, so it's a compile error to pass it to something that wants an order id, say. Then you define `Id` something like: newtype Id a = Id Int 
There has been talk about parameterising `TYPE` by it
Is the output json equivalent to the core ast? 
A problem with constraint synonyms like type Text a = (Show a, Read a) is that you cannot partially apply them. To get that effect use class (Show a, Read a) =&gt; Text a instance (Show a, Read a) =&gt; Text a More info on [constraint synonym encodings](https://gist.github.com/Icelandjack/5afdaa32f41adf3204ef9025d9da2a70#constraint-synonym-encoding).
For those who don't know where to find it: https://github.com/ghc-proposals/ghc-proposals/pull/32
yes
I'm not 100% sure. I mean honestly `Set` and friends alone make me want to keep `Foldable` for now. There are plenty of container types that limit their contained items that you may want to fold up. 
Very nice! It was always annoying to figure out where the matching braces were with plain `-ddump-simpl`. The collapsible expressions provides a view of the bigger picture which I can see myself making use of quite a bit! Totally tangential, but why does it use [`monadLib`](http://hackage.haskell.org/package/monadLib) rather than the usual [`transformers`](http://hackage.haskell.org/package/transformers) / [`mtl`](http://hackage.haskell.org/package/mtl)? I don't really see the point… at least not from a brief glance of the code.
Actually another good example is basically all infinite data structures. You cannot traverse an infinite data structure except in perhaps very degenerate cases. Maybe only with sufficiently lazy applicatives or something like that. 
Anyone know how long it will take for this to trickle down into the Stackage nightlies? 
&gt;I don't like the relationship between Constraint and tuples. The fact that () is ad-hoc overloaded to have the kinds * and Constraint Perhaps, we should make both (,) and (-&gt;) poly kinded such that it chooses the right notion of product and arrow based on the kinds involved. This would eliminate the ad-hocness and give us some other things for free. As /u/edwardkmett [demonstrated](https://www.youtube.com/watch?v=Klwkt9oJwg0&amp;t=3277s), this could potentially be used to make functors functorial in any argument and other interesting things. &gt;the fact that (a, (b, c)) is the same as ((a, b), c) without any fundamental machinery behind it. Given the nature of constraints, it makes sense this would be the case. See /u/doloto's comment.
Once we have [`class Semigroup m =&gt; Monoid m`](https://prime.haskell.org/wiki/Libraries/Proposals/SemigroupMonoid) both instances can be a flipped `runFree` {-# Language TypeApplications #-} instance Foldable (Free Monoid) where foldMap :: Monoid m =&gt; (a -&gt; m) -&gt; (Free Monoid a -&gt; m) foldMap = flip (runFree @Monoid) instance Foldable (Free Semigroup) where foldMap :: Monoid m =&gt; (a -&gt; m) -&gt; (Free Semigroup a -&gt; m) foldMap = flip (runFree @Semigroup) **If** we get implication constraints ([discussion](https://www.reddit.com/r/haskell/comments/52f77p/how_would_you_express_the_free_category_in_haskell/d7o8rmq/?context=10000)) we can write a single instance that works for any type class that `Monoid` entails: instance Monoid |- mon =&gt; Foldable (Free mon) where foldMap :: Monoid m =&gt; (a -&gt; m) -&gt; (Free mon a -&gt; m) foldMap = flip (runFree @mon) I think I've got that right
I'd been wondering how to do that (`Monoid |- mon`) for ages! That's an interesting discussion. I wonder if you could achieve it with the [`Class`](https://hackage.haskell.org/package/constraints-0.8/docs/Data-Constraint.html#t:Class) class from `Data.Constraint` (although you'd have to implement `Class` for every superclass, I suppose).
I have considered it, pragmas are a possible issue: does a `Constraint` synonym require undecidable instances (like the class encoding does)? Are there any cases where the user might not want to conflate the two.. You should [submit a ticket](https://ghc.haskell.org/trac/ghc/newticket) if you have the time
There are lots of responses, but I feel they're mostly missing the point. I've had the same problem, and I don't really know a clever solution. I just use the straightforward solution: export the record type, but not its constructors. All modifiable fields export a `modifyX :: (X -&gt; X) -&gt; Record -&gt; Record`. If modifying a certain field needs side effects or validation, then it returns `m Record` or `Either Error Record` or whatever. If you have a bunch of fields that don't need any of that, you can put them in a sub-record and export modifySubRecord to save some boilerplate. I'm sure TH could automate the boilerplate, but I don't mind writing it. Lenses might help, but I haven't figured out how to express that some fields are pure while some require a monad, and have both compose. Any lens experts out there know? Another approach I've used is to repackage a StateT, but when you export `put`, it has some checking or side-effects. Then you can freely write `modify $ \state -&gt; ... normal record updates or lens updates` and the `put` at the end of the `modify` will check every field, to either verify or say `when (field old /= field new) sideEffect`. Of course this only works if verification is cheap. To be honest, what I usually do is export both record fields (or pure lenses) and the specialized update functions, and just rely on the caller knowing when to use the update functions.
[Dependency.Internal](https://github.com/rampion/cabal-linking-bug/blob/master/Dependency/Dependency/Internal.hs) should be listed in `other-modules` in the [cabal file](https://github.com/rampion/cabal-linking-bug/blob/master/Dependency/Dependency.cabal). It is [known issue](https://github.com/haskell/cabal/issues/1746).
&gt; `rnf` is theoretically a no-op `rnf` is *semantically* a no-op. Theory can speak about operational behavior as well. I don't otherwise disagree much.
The package can be compiled, linked and installed, it is described in the issue. Linking a package doesn't require all dependencies. But I'm not sure what you mean by "it can be used". When linking the final executable, the missing dependency will be reported as an error (assuming it is actually used.) Template haskell involves linking to execute the compile time code, so the error occurs during compiling the executable instead of linking.
TIL about implicit params. Damn that's ugly, but awesome.
&gt; It takes much more effort to guess the loop invariants Owch owch owch. The invariants should be known by the programmer when they write the loop! 
Servant is *amazing* for JSON APIs. It is *much less* amazing for websites. Write a form handler in Yesod and Servant. Write a redirect handler in Servant. It's just not easy or fun. Fortunately, most Haskell web frameworks use WAI, and they expose a way to mount other WAI applications. At work, we have a Yesod application that has a Servant API mounted at `/api`. It is a fantastic best-of-both-worlds setup. I wrote a blog post on getting that setup: [Servant in Yesod](http://www.parsonsmatt.org/2016/12/18/servant_in_yesod_-_yo_dawg.html). 
The hackage git repo should probably used `https` instead of `git` in order for the link to work in the browser as well.
On the demo page (http://yav.github.io/dump-core/example-output/Galua.OpcodeInterpreter.html) it took me a while to figure out that you have to hover with the mouse.
My understanding is that the audience is JVM programmers/institutions (c.f. ghcjs), which means that breaking compatibility might be done for feature-reasons, not maintenance-reasons. So that must be traded off against supporting some powerful modern library. (though i think lens is Haskell98, which is one of the most powerful ones anyway). e.g. ghc itself might do most(/all?) of the work for some complex type system extension, which is mostly(/entirely?) erased before stg or even core, and eta could support it, but won't because it makes error messages worse when enabled, which might not be desireable for the users, even if optional. (i don't know if this is accurate, please correct me.) 
Syntax and error messages and performance, at the very very least. I mean, does Haskell need records? You can just encode them with vinyl. 
Please keep in mind this is not actually quick sort.
Although you're not supposed to share Project Euler solutions, the solutions posted on the Haskell Wiki helped me a lot. I would solve a Project Euler problem without looking at the solution, and once I have something that works, I would compare my solution to the solutions posted on the Haskell Wiki. There's many techniques embedded in those solutions which are often not mentioned in tutorials, like using mutual recursion in a call-by-need setting to efficiently generate the infinite list of prime numbers.
Great answer! Did not know that Gabriel used LH at one point. Maybe I should find some spare time and see if I can get LH to run and try to check the parser myself. 
IMO, tackle each problem one at a time as you get to it, then worry about breadth. Most learning comes from doing. Keep doing projects you are passionate about until things start to gel. Fight each barrier one at a time. Once you 'get' it, I think then it helps to explore other code (for the sake of exploring, not finding a specific answer) and watch conference talks to introduce you to new ideas and tell you what kind of things are out there. You can then go back to your old code and make it better, find abstractions, and share it to get feedback from others.
Is there a categorical equivalent of the applicative typeclass? How it would fit this hierarchy given in Diehl's post?
To learn how to structure a Haskell program, build one yourself! Maybe build a game or copy a popular command line tool or build a website. Accept that the code may be terrible at first, and improve it gradually. Use r/haskellquestions, https://codereview.stackexchange.com, or the Haskell Cafe mailing list to get code reviews. To learn tricks and design principles from experienced Haskell developers, contribute to existing projects, or simply watch them on GitHub and read the PRs. Cabal, stack, hledger, really most projects that have existed for a while are looking for contributors. [Here](https://github.com/haskell/cabal/issues?utf8=%E2%9C%93&amp;q=is%3Aissue%20is%3Aopen%20label%3A%22meta%3A%20easy%22%20label%3A%22attention%3A%20pr-welcome%22%20no%3Aassignee) are two issues in the Cabal project, that you could start with. But I think you can even learn from watching other people. For example, I've been watching the [vgrep project](https://github.com/fmthoma/vgrep), which is pretty low-traffic, but looks like I could learn some design from it, and has quite interesting discussions on its PRs. Don't be afraid to ask questions – most Haskellers are very willing to explain things, and package maintainers are ready to invest some time into newcomers in the hope of aquiring a new core dev.
If you're wondering what concept to learn next, maybe take a look at the ["Standardized Ladder of Functional Programming"](https://pbs.twimg.com/media/CydL5EYUsAAI-61.jpg:large). The name is a bit grandiose but as a basic guideline it seems to be pretty ok.
Are you familiar with `Applicative`s? In Haskell terms: ($) :: (a -&gt; b) -&gt; a -&gt; b Now let's put the extra argument in liftA2 ($) :: (r -&gt; (a -&gt; b)) -&gt; (r -&gt; a) -&gt; (r -&gt; b) Which is the stronger composition operator.
When GHC-7.10.3 was released, the nightlies switched after a week. This time, there's [a bit more breakage](https://github.com/fpco/stackage/issues/2203), so I'd speculate that it might take 2 or 3 weeks. 
If I know other programming lanugages (C, Lisp, Python) but not so much of Haskell, and I only have around CalcII in terms of math skill, what's the canonical way to learn monads for a beginner? I'm quite new to Haskell and I'm seeing people talking about them, but very little in the way of explanation. I couldn't understand this essay unfortunately.
Don't learn monads in the abstract. Use concrete monads: Reader, Writer, State, IO, List. Once you've gotten a hang of utilizing them you'll have a better time generalizing the concept. Breadth first, not depth first.
I haven't seen them used for anything but stack traces ([GHC.Stack](https://hackage.haskell.org/package/base-4.9.0.0/docs/GHC-Stack.html#t:HasCallStack))
&gt; The numbers 60 and 62 are &lt; and &gt;. In XML the only characters that matter are &lt; and &gt; (if you don’t care about entities). &lt; and &gt; can’t appear inside speech marks (attributes). They are the only important things to search for. Sadly this is false. The &gt; character is valid inside an XML attribute. No, I don't know what they were thinking either. https://www.w3.org/TR/REC-xml/#NT-AttValue 
&gt; I'd be especially curious how you manage your Nix environments across machines. Do you have any specific questions? We're not doing anything out of the ordinary. We kind of just do dependency management, then have Nix build a Haskell program. When we need to deploy, it's as simple as `nix-copy-closure`, since we have NixOS on the server. We have Nix get PostgreSQL as a dependency, but our Haskell code does 100% of the setup and configuration of the db (this is, admittedly, a shortsighted shortcoming, as it will eventually need to access a remote db).
Applicatives are ["strong lax monoidal functors"](https://en.wikipedia.org/wiki/Applicative_functor) and are significantly more involved. You'll find that monads only imply applicatives in some categories, and Hask happens to be one such category. To start, we need an understanding of monoidal categories. A monoidal category `C` is a category equipped with a bifunctor `⊗ : C×C -&gt; C` known as its tensor product, and a particular object `I : C` known as the identity of that tensor. With these tools comes a few laws: - There are isomorphisms between `A⊗I`, `I⊗A` and `A`, for all objects `A`. - There is an isomorphism between `(A⊗B)⊗C` and `A⊗(B⊗C)`. A monoidal functor is a functor between two monoidal categories that preserves their monoidal structure. Specifically, given two monoidal categories `(C, ⊗, I)` and `(D, ⊕, J)`, a monoidal functor `F : C -&gt; D` comes equipped with these morphisms: - `J -&gt; F(I)` - `F(A)⊕F(B) -&gt; F(A⊗B)` In a *strong* monoidal functor, these two morphisms are isomorphisms. In a *lax* monoidal functor, the need not be. So why do we call applicatives "strong lax monoidal functors?" Well, this is why I prefer the phrasing "lax monoidal functors with a strength." Turns out, the "strong" in this phrase refers to a completely different kind of strength. So an applicative is a *lax* monoidal functor as shown above, with one extra feature. For `F` to have a strength, it must have a morphism like this: - `A⊕F(B) -&gt; F(A⊗B)` In Hask, all endofunctors have such strength strength :: Functor f =&gt; a -&gt; f b -&gt; f (a, b) strength a b = fmap ((,) a) b Given this, we can say that an applicative endofunctor on Hask is just a lax monoidal endofunctor where both of the tensors we're concerned with are `(,)`. Meaning one possible definition of `Applicative` would be this: class Functor f =&gt; Applicative f where unit :: () -&gt; f () (&lt;**&gt;) :: (f a, f b) -&gt; f (a, b) Or, more conventionally: class Functor f =&gt; Applicative f where unit :: f () (&lt;**&gt;) :: f a -&gt; f b -&gt; f (a, b) Assuming the `Functor` instance is independently defined, I can show that this class is equivalent. -- This is why applicatives must have strength. -- Otherwise `pure` cannot be derived from `unit`. pure a = fst $ strength a unit f &lt;*&gt; a = fmap (\(f', a') -&gt; f' a') (f &lt;**&gt; a) unit = pure () a &lt;**&gt; b = (,) &lt;$&gt; a &lt;*&gt; b The reason that we define `Applicative` the way we do is similar to why we use `(&gt;&gt;=)` instead of `join` or `(&lt;=&lt;)`. It's just more convenient for programming with, and often more efficient. Plus, you can define `fmap` in terms of `pure` and `(&lt;*&gt;)`, which is handy (same thing goes for `(&gt;&gt;=)` and `return`, which can be used to implement `Applicative` or `Functor`).
That design has been proposed for Haskell 1.3, back in 1995. Despite reading through the exchange, I'm not clear on why it never saw the light of day. Another alternative considered was to make all tuples unlifted, and yet another to make all single-constructor ADTs unlifted. There is a brief overview in section 5.4 of [Being Lazy with Class](http://haskell.cs.yale.edu/wp-content/uploads/2011/02/history.pdf) 
This reminds me of the [Moore method](https://en.wikipedia.org/wiki/Moore_method) of teaching math-- but I don't think I've ever seen it applied to a CS course. A couple of questions: 1. How did the students rate it compared to the conventional PL courses? 2. How big was your class and what were their backgrounds?
Haskell already has light weight threads, so *semantic* parallelism everywhere is not necessarily a problem. `(⊥, ⊥)` is worse than ⊥ because it pretends to have more information content than it really does. Pattern matching on an information-less value should produce an information-less value. 
&gt; Can you design a type system where # and * kinds can be freely blended together? I very much doubt it. I have been thinking about this and have come to the conclusion than `#` can be denotatively modeled as linearly-typed values of `*` that are also `Comonoid`s in the category of linear functions.
That is one axis of generalization. What I meant was making `(-&gt;)` the same as your `(~&gt;)` type. `(,)` is already somewhat kind polymorphic. If Haskell were to make it properly so, it follows to give `(-&gt;)` a similar treatment. For example, `[] -&gt; Maybe` would be a natural transformation from lists to maybe (perhaps `head`). These would not be callable like regular functions because that would break type inference, so there would probably be a function of the form `naturally :: forall f g a. (f -&gt; g) -&gt; f a -&gt; g a`
&gt; but with type synonyms you'd have to check whether for any argument they expand to the same type: this is the same problem as comparing functions for equality, it's not possible in a Turing-complete language. Are constraint types Turing complete? Also, can't it just determine what constraints it places on its type parameters rather than seeing if it expands to the same constraint. 
&gt; Don't learn monads in the abstract. I'd agree very with that and add that its good to know the [monad laws](https://wiki.haskell.org/Monad_laws). 
It can be law abiding if the domain of the functor is the category of Haskell functions that produce the same result for arguments that are equal according to `Eq`. Not all of Hask meets this requirement because `Eq` is not required to be structural equality.
Seems you use Nix to acquire stack and intero within the build. I don't do that, and it still works for me with the setup in that GitHub repo I linked.
I'll add that to the gist, thanks a lot
A couple of things that I can think of that haven't been mentioned by others: * Get good at encoding invariants in the types you design or as Yaron Minsky says "make illegal states un-representable in the type system". * Get good at writing property tests (ie QuickCheck) for your types and functions. * Get to know which standard Prelude functions are not total and learn how to work around them. Maybe even write your own custom Prelude which imports the standard Prelude but hides unsafe, non-total functions. * Learn how to profile haskell code and fix performance issues. 
Interesting. Not actually related, but I know someone who, after teaching advanced stuff, would introduce errors in the material. The student needed to find and explain the error, and in this way he was made aware of the concepts involved and what means that something is correct. Your method is brilliant, i think you can use the error strategy in another course, complementary, when the student becomes more profficient. P.s. sorry for my english writing, I'm not a native :)
It's not actually that ad-hoc at all. Where a constraint isn't specialized immediately, it's passed as a dictionary, and I believe somewhere between Core and STG `Constraint`s turn into `*`s and `=&gt;`s turn into `-&gt;`s. In fact, a typeclass with a single value inside of type `x` is represented by the value of type `x`. That's how [reflection](http://hackage.haskell.org/package/reflection-2.1.2/docs/Data-Reflection.html) is currently implemented - that and a heaping helping of `unsafeCoerce`.
...and thus new `base`/`ghci`/`ghc-boot`/`ghc-boot-th`/`template-haskell` versions are on Hackage now! :-)
&gt; Have you already learned about Monoids, Functors and Applicatives? If not, I'd recommend you learn those first. I actually pretty strongly disagree with teaching `Applicative` before `Monad`. Though it sits higher in the hierarchy, it's a much more complicated class and comparatively obscure. Once you learn how functors work, it's easy to see how flattening after mapping is useful and makes sense. Applicative, however, has nothing to do with mapping. It's about pairing, and it's done in really obscure ways. Lists, for example, do cartesian product. I think it's much simpler to learn monads, and then be shown `ap`. ap :: Monad m =&gt; m (a -&gt; b) -&gt; m a -&gt; m b ap f a = do f' &lt;- f a' &lt;- a return (f' a') When you know monads, it's obvious how this works, and it directly translates back to an explanation of `Applicative`. From there you can start explaining the differences between the two classes and how you can have applicatives that aren't monads and why that's useful.
Did you base the CSS parser on https://www.w3.org/TR/css-syntax-3/ or something else?
Yes, mostly on the specifications (not only level 3, but also CSS2.1, and some level 4 such as 4 and 8 digit hexadecimal colors). The thing is, if you stick 100% to the specification, you can't deal with CSS hacks, so I had to deviate a bit. For example, the parser accepts "*margin" as a property name (which is invalid, but commonly used as a hack), as well as ending a declaration with "\9", another commonly used IE hack. Other than those things, I think it is for the most part compliant. The parser is filled with comments with the grammar verbatim from the specs.
Monad is just one of the many abstractions available in Haskell, and you don't need to know what it is to program in Haskell, just as you don't need to know what Semigroup or Alternative is. Here's an anecdote: The Scala language lacks the concept of a monad, but contains monadic operations for several types. My coworkers use them all the time without knowing that they are monadic operations, or what a monad is.
Thanks, I need `base` for `ghcjs` when I pack it for `stack`. Now I will need a real `stack` with `ghc-8.0.2` -- anyone :)
When you solve a PE problem, you get access to the forum with other people's solutions. Often, someone there will have posted a Haskell solution, so you don't really need them to be posted on the Haskell Wiki.
&gt; Scored on a scale of 1 (complete fail) to 11 (better than Python), with Python scoring a 10. That the scale goes to 11 tells you exactly how serious I am. &gt;Adding them up, we get that Haskell scores an 8.2. That actually feels about right to me. This must be one of the worst way of scoring I've ever seen.
Awesome might use this. Also its a good first project. Keep it up :)
You might check out my blog post [How to Get a Haskell Job](http://softwaresimply.blogspot.com/2016/08/how-to-get-haskell-job.html). I would say that the things I suggest there for getting a Haskell job are pretty much identical to the things you should do to improve your Haskell skills in general.
&gt; Haskell has fewer special cases than any other language I've run into. Maybe I just need to look harder? Let's see how many we can find :) Let me start: 1. `(- 1)` is a [special case](https://www.haskell.org/onlinereport/exps.html#sections), it means the number `-1`, not the partial function `(\x -&gt; x - 1)` like it does for every other operation section. 2. `($) :: (a -&gt; b) -&gt; a -&gt; b` is a special case, you can write `runST $ do ...` and it will type check, but if you define `($$) = ($)` and write `runST $$ do ...` you get a type error, "Couldn't match type `ST s0 a` with `forall s. ST s a`".
If you include syntax, we cannot forget lists and tuples!
I thought it set the tone of the article very well. It's a layman's fun comparative poke at two programming languages.
&gt; `(- 1)` is a special case, it means the number -1 Strictly speaking, that's not fully accurate though: `(- 1)` desugars to `(negate 1)` -- unless GHC's `{-# LANGUAGE NegativeLiterals #-}` is active.
It's a somewhat different issue. `build-depends` also causing to build executable components of a package and install them somewhere (possibly overwriting existing ones) where they may or may not end up in your `PATH` is more of a happy accident/side-effect than a deliberately designed feature. This was finally fixed in the next-gen nix-style cabal, which means that abusing `build-depends` for that is not going to work anymore in the future. In future you need to declare your build-time executable dependencies either via the legacy `build-tools` or the new more generic `tool-depends`, otherwise `cabal` won't know what that you need the executables to be pre-installed. See https://github.com/haskell/cabal/issues/3708 for more details.
Actually we specificy the corange and codomain instead of the domain and codomain. (see http://cs-syd.eu/posts/2015-11-30-codomains-reconsidered.html)
I actually have a problem with "explicit is better than implicit". Most of the time transparent is better than explicit. What you need is regularity of behavior, so that you can create an expectation and not be surprised. The behavior is transparent, even if parts of the code are not explicit. Typeclass polymorphism is not explicit, but it is transparent. Do notation also. 
*New* as in: I have not seen it yet. Don't know when it was changed.
The second is not a Haskell special case, it's just ghc. 
It appears to me that this question is about data hiding in its core. Your last two bullet points are on the right track. I don't fully understand what is considered boilerplate and what is not in relation to types. I'm not sure I would try to enforce the intended usage with data hiding instead of just documenting it, given that the to-be-exposed functions need to have effects all over the map, which should be understood by the programmer anyway before using the functions, but that might be a fallacy and the intention is certainly justified. So you written all the functions and data types in some module and now you want to expose an API that doesn't allow the direct modification of a record type. There are useful comments about separation of concerns in this thread but that does not seem to be what you asked. You are right that first key step is to not export all constructors especially the positional constructor (I made that term up, you call it tuple constructor if I read you right) to prevent writes and if you want to prevent reads also not the field accesor functions. Now you have different options for regulated access to the data type. Something smart-constructor-ish is probably what you want first, given your requirements probably something like: `(MonadDB, MonadWeb) =&gt; Text -&gt; Text -&gt; Int -&gt; Encrypted -&gt; m ()` alternatively `(...) =&gt; UserInput -&gt; m ()` where `UserInput` closely mirrors `User` but is constructed from maybe some post request and only used in this context. Now you export your functions `changePasswordAndNotify :: (...) =&gt; User -&gt; Encrypted -&gt; m ()` and `initiateEmailChange :: (...) =&gt; User -&gt; Text -&gt; m ()`. Or maybe with `UserId` instead of `User`, your call. Now you can export field accessors at will depending on what you want to have readable. I would also provide lenses. As you noted it is possible to have just Getter lenses you do not have to use them internally. Say all your code is in one module named `Foo.Internal` you want you nice API exported as `Foo` or `Foo.Safe` you exports the read-only Lenses under some long name from `Foo.Internal` an rename them in `Foo` to the name you use for the read and write one (or just keep the specific name, I don't know what is less confusing). If you want to pattern match the classical options are ViewPatterns along with an auxiliary data type or PatternSynonyms. Both options are described e.g. [on StackOverflow](https://stackoverflow.com/questions/8172548/is-it-possible-to-export-constructors-for-pattern-matching-but-not-for-construc). You could now have another function like `updateUser :: (...) =&gt; User -&gt; m ()` (maybe you need a UserId, too) where it would not be possible for a `User` to have those fields you wanted to have protected to be modified directly. A wrong `User` value say retrieved from another Id, could still be used. After writing this I have to say that I do not like the API I just sketched although it seems to be the closest to what you have asked for. Your API already tries to enforce high-level concerns persistence, validation, confirmation, ..., sending emails around and firing up additional routes to achieve this. What about `UserAge`? I suppose it is something that the user should be able to change without special precautions, but it should still be persisted and is therefore effectful, to be on the same level as the rest of the API, right? Trying to enforce correct usage here by restricting access to some data types seems to be the wrong tool. I would just go for an API like: changeName :: UserId -&gt; Text -&gt; m () changePasswordAndNotify :: UserId -&gt; Encrypted -&gt; m () ... I see you worried about bulking changes to the user profile, which might be premature, but can be done of course by having a function like `changeUser :: UserId -&gt; UserUpdate -&gt; m ()`. Where `UserUpdate` could for example be `data UserUpdate = UserUpdate { _name :: Maybe Text, _email :: Maybe Text, ... }`. I don't know if you consider any of this unacceptable type-related boilerplate. To me it isn't. The quantity of data types I employ in on average coding grew for quite a while when I started using Haskell, so maybe your perspective might change, too. Apologies for this rather lengthy reply and I guess you already now most of this, but I don't think your question had any deeper point. As I don't know what your web and db technology is I kept the type contexts symbolic.
&gt; It makes writing complex stuff easier than "simple languages" It may be, and this is potentially true for sure, but, in the practice, with the current way to do things in haskell, the promise is not fulfilled: it is hard to argue that programming the same application is easier in Yesod that in Ruby on Rails. It adds some advantages, but it is hardly easier. Really it is more complex. &gt; How would what you envision look in practice? I can't quite transpile this into a vision of how that "simplified language" you're imagining might appear from over here. Sounds well isn't? But it seems to be too much from too little. I know that this sound like utopic for some and enraging for others. Many people here know what [I'm talking about](https://github.com/transient-haskell/transient) It seem utopic because it seems like having the cake and eating it too. It sounds insulting, because it makes things easier and this reduces the epic of programming in haskell. So the typical reaction is incredulity and silence. But It is a matter of time that something like this will finally succeed.
Reread the post please. This suggestion is aimed at reducing the runtime information and removing one more source of bottom for non-sum types of whatever element types you want.
I think the animating the examples is brilliant.
Any more info about the bug in `text`? Do you happen to know the commit?
I would disagree. Applicative was quite easy for me to learn because from the start, someone (perhaps it was the haskell book, too lazy to check) explained it in terms of (to paraphrase) monoids on the structure, functors on the values. I was shown an example and it made sense and I never had an issue with it again because I already understood monoids and functors. The reason I had such a hard time with Monads was that for some reason, there is only 2 types of explanations for it: 1. Just use them and you will figure it out. After a few months of 'just use them' I was still no closer to figuring out WTF was going on. Looking back, this likely didn't work because I had no idea how or when to use `&gt;&gt;=` itself, I only knew how to use `do` syntax which completely obscures what is going on behind some nice syntax. I would look at 'desuggaring' do syntax examples, only to be left with the feeling that lambda's were (for some reason I didn't understand) required to use bind. 2. Super long winded explanations that while technically correct, take so long to get to the point that I would stop paying attention half way through and miss key parts of the explanation due to boredom. Here is an example of that: https://www.youtube.com/watch?v=ZhuHCtR3xq8 I couldn't find a short to the point explanation. Finally understanding Monads took two things for me. 1. Realizing that the default bind had flipped arguments compared to functor/applicative. Prior to this, I didn't understand why anyone thought they were related since they had such different looking type signatures. 2. Realizing that monads were two conceptual parts that had to be written all at once in a single function. There is the fmap part where you are applying the function to the inner value, and there is the join part, where you have to somehow eliminate the nested structure that you would make if you were to only do fmap. Those two concepts form a 'checklist' of features/functionality that my bind function needs to implement.
I think that's more a problem with the way monads are taught than with monad itself. The explanation you received for applicatives is not one I've heard, but you're lucky you had it. But I think even that was more complicated than what it *should* take to learn monads.
Sure, it's related to the UTF-16 encoding that `text` uses. Basically, a `Char` will either consume 2 or 4 bytes when stored in a `Text`, so the safety of a write operation to the array that underlies a `Text` value depends not only on the **index** of the write, but also the **value** being written. Now, suppose you're writing a `copy` function, it might look something like (heavily simplified) copy (Text array) = go 0 newArray newArrayLen (getChars array) where go i arr len [] = Text arr go i arr len (c:cs) | i + numWords c &gt;= len = go i (extend arr) len (c:cs) | otherwise = go (i + numWords c) (write i c arr) len cs The important bit is the `i + numWords c &gt;= len` guard, which tells us when we need to extend the new array to avoid an out-of-bounds write. This function is safe, but consider changing `copy` to `map`. map f (Text array) = go 0 newArray newArrayLen (getChars array) where go i arr len [] = Text arr go i arr len (c:cs) | i + numWords c &gt;= len = go i (extend arr) len (c:cs) | otherwise = go (i + numWords c') (write i c' arr) len cs where c' = f c The code is almost identical, but now there's a bug because we're determining whether we need to extend the array based on the `Char` from the input `Text` instead of the `Char` we're about to write into the new `Text`. This is exactly what happened in `Data.Text.Fusion.mapAccumL`, and the fix is just to change the `c` in the guard to `c'`. There's a bit more background, and of course an explanation of how to encode the necessary invariants in LiquidHaskell, in section 5.2 of http://eric.seidel.io/pub/realworldliquid-haskell14.pdf. https://github.com/bos/text/pull/50 is the patch. Pretty simple patch, but I think it would have been very difficult to discover the bug without the help of a tool like LiquidHaskell.
I bet it's emacs with haskell-mode and maybe http://commercialhaskell.github.io/intero/? I can't say for sure though.
https://wiki.haskell.org/ListT_done_right
Is there any reason *not* to use Liquid Haskell?
The whole `$` thing is kind of lame, and it's also annoying when it breaks in other similar situations. I understand that type inference with higher rank types isn't possible (or at least isn't practical for rank 2 types, and impossible for above that). But would it be possible to not "forget" higher rank types, and carry them around fine, even if you never infer them from scratch?
[removed]
There is no harm reporting anything you think might be a bug to the [issue tracker](https://ghc.haskell.org/trac/ghc/newticket?type=bug). Panics are always bad, the compiler should never panic.
I mean... no it doesn't. `R` and `a` are both not referenced at all in the negative position. Regardless we don't get non-termination, we get a compiler panic, which explicitly suggests reporting a bug.
`data False` is clearly not recursive. `data R a ...` is also clearly not recursive. `condFalse` only references it's argument and nothing else, and thus is clearly not recursive. `absurd` only references `MkR` and `condFalse` and nothing else, and thus is clearly not recursive. So where exactly do you see value level recursion in the above code?
Nope
Last I heard LH only runs on single files. Is any work being done to integrate it with cabal/stack projects? I'd love to just be able to run `stack build` and have all of my LH annotations checked automatically.
`ghc: panic!` is *always* proof of a GHC bug. In fact, it's one of the easier proofs to formulate.
Yea I would say open an issue! There isn't anything bad that can come from it.
Good to know, I submitted a [ticket](https://ghc.haskell.org/trac/ghc/ticket/13125#ticket).
Ok [done](https://ghc.haskell.org/trac/ghc/ticket/13125#ticket).
Ok good to know, [done](https://ghc.haskell.org/trac/ghc/ticket/13125#ticket).
What this implements, if you squint a bit, is the simple looping lambda combinator called `omega`: omega = (\x. x x) (\x. x x) Of course we can have divergence without explicit recursion; we do have all the looping lambda terms and the Y combinator as well, with which we can recover general recursion. So, the divergence is not a bug. `R` is in fact not strictly positive because of injectivity of type constructor application (which is a different and much stronger assumption than injectivity of *type constructors*. If type constructors are injective, then `c a ~ c b` implies `a ~ b`. If constructor application is injective, then `f a ~ g b` implies `f ~ g` and `a ~ b`. Injectivity of application is basically the assumption that type constructors form a first-order term language without computational behavior). Maybe it's more apparent if we desugar `R`: data R a where MkR :: forall a c. c () ~ a =&gt; (c (c ()) -&gt; False) -&gt; R a If we have `R (R ())`, then by pattern matching on `MkR` we get to know that there exists a `c` such that `c () ~ R ()`, but then by injectivity `c ~ R`, so this makes `R (R ())` isomorphic to the negative recursive type data R = MkR (R -&gt; False) What *is* a bug however, is GHC's panicking, because GHC is supposed to be type safe, so while we're able to loop, we shouldn't be able to cause undefined behavior without unsafe primitives. The following simple `omega` implementation loops properly, although we need the `noinline` pragma to prevent GHC from throwing inliner stack overflow on compilation (in GHCI it works either way): data False data R = MkR {proj :: R -&gt; False} f :: R -&gt; False f = \x -&gt; proj x x {-# noinline f #-} omega :: False omega = f (MkR f) main = do print (omega `seq` ()) The more convoluted `GADT` definition should loop as well. 
This can't be true? Otherwise it would be completely unusable.
That's the inliner issue, which can be avoided with `noinline` pragma. The panic is different.
Dependent types, probably
If you have a good use case go for it. Reasons not to use it, from my not really informed point of view: * It's basically shoehorned onto Haskell, which means you'll write all type signatures twice. Depending on context the extra visual noise would be frowned upon. * It's very much a work in progress. Expect rough corners. E.g. I don't think it builds with GHC 8 yet? * Depending on what you work on you won't find any use cases. But I have yet to get a good intuition what LH can do and what not. 
I agree it is a bug if it panics, but I think the constructor type is recursive... condFalse :: R (R ()) -&gt; False condFalse x@(MkR f) = f x So MkR is invoked with: R (R ()) -&gt; False and the type of MkR is (c (c ()) -&gt; False) -&gt; R (c ()) and here c = R. Therefore the concrete type is (R (R ()) -&gt; False) -&gt; R, which is a reference to R on the left-hand side of the concrete type of a constructor for R (making it recursive).
It would be really great if you documented the process you used when you push your changes upstream. I couldn't even get the prebuilt boot images to work.
The value level recursion can be seen if you expand absurd using the definition of condFalse: absurd = condFalse (MkR condFalse) condFalse (MkR condFalse) = condFalse (MkR condFalse) Haskell doesn't claim to guarantee that only programs that terminate will typecheck (it is Turing complete), so it isn't inherently a problem that you can write such an expression - the only real problem is the way it fails.
I agree with this article’s assessment, but I think Uncle Bob has a point about the “dark path” of mainstream statically typed languages. These arguments are related to something that’s been on my mind lately. In functional programming, you’re inclined to decompose a problem into an *algebra*, while object-oriented programming is more about *taxonomy*. Both are valid and useful program structuring techniques, but it’s a much simpler task to design an expressive-but-not-oppressive logic (read: type system) for one than for the other, and they don’t interact well. 
https://github.com/spinda/liquidhaskell-cabal#readme
One of the author said he uses spacemacs.
I found the simplest and most portable way is to build the deployable asset in Docker. The resulting Docker image can be run cross platform and easily distributed. Single instance deployments are easy, `docker run ...`, multiple instance deployments you can take advantage of Kubernetes, Docker Swarm etc. For local development on OSX I use Stack. When I want to build a deployable asset and push to a Docker repository I build the image in an Alpine Linux Docker container which produces a statically linked binary. I then package the binary up as a separate Docker image which results in a ultra small Docker image. A good example of this is a HTTPS redirection microservice I built which results in a 1.8MB Docker image. https://github.com/ajevans85/httpredirector . The README gives full details on the build, I have also since created a makefile where all you need to do is run `make clean dist docker-image` When building Docker artifacts I strongly recommend keeping all configuration as key/value environment variables. If you must use configuration files make the path of the configuration file an environment variable and keep the file out of the image, either then mount the file or make it accessible remotely. 
I didn't use the pre-build boot images. I pretty much followed this guide: https://nixos.org/wiki/Bootstrapping_NixOS_on_ARM I have one sdcard that has raspbian on it. Following those instructions I build the core nix tools so that I had a working nixpkgs on top of raspbian. And then I used that to build nixos-install and friends. And then used that to build a new nixos distribution on a second sdcard. As you might imagine, that was a couple days of waiting around for things to compile. Obviously, that is not going to win people over, so the end goal is to make sure there are images that really work ;)
Thank you for this. I think I've got it going.
Agreed completely, it's *incredibly* distracting as it is currently. EDIT: Some browsers have a "Don't loop" on the context menu, though, so it might be possible to stop the animation that way. However, it shouldn't be necessary.
I haven't heard of Liquid Haskell before today, but after taking a look I'm really impressed. Top job by the developers. New site looks good as well.
Normal typing and Liquid Haskell are independent, so you'll have to write both signatures in many cases if there are not inferred. For top level expressions it's good practice anyway [1], so I assume you'll end up with lots of doublicated signatures. [1] ... Especially because it can have impact on performance. 
I'm not at my computer, on my phone but I was wondering how does one generate a refined type from a runtime value (rather than one constructed syntactically)? In some languages you can have a case like `case lessthan 5 x of Just x' -&gt; ...` where the x' carries a proof that it's less than 5 in the type. Put another way, how do you call any liquid haskell function from the REPL with random user input? I would hope there's a mechanism to take a LH constraint and generate a runtime function that checks X is satisfied and gives you a proof that LH can use later. I think including that somewhere on the homepage would show where this ends up being useful in the real world. I think you could fake it with `assume` and a hand-written function. But that's not _too_ satisfying as it has a maintenance burden.
From what I gathered you don't... At least not in the sense of *existential types*. The Liquid Haskell way would be to state "this function needs an integer of value x" and then before calling the function you need a runtime check checking that precondition. 
Interesting. Could you give an example of the "taxonomy" of something in OOP? I think I get what you mean by algebraic expressions in Haskell, but I'm unsure of what you mean when you mention the taxonomy of something in OOP.
Yep ... that's how I assume it works too. Actually I am in the (slow) process to apply the LH treatment to [your xml parser](http://chrisdone.com/posts/fast-haskell-c-parsing-xml) ... learning by doing: https://github.com/fhaust/xeno/tree/liquidhaskell
Memoization can also been achieved using `unsafePerformIO` and a mutable data structure.
Having to go use BS might be a bit extreme. What I don't understand is which encoding is used if you say anything ? As far as I understand, Text is unicode and as such not linked to any particular encoding (ie the memory representation should be transparent shouldn't it ?). So I guess before writing some Text to a file, it need to be encoded somehow, is the default encoding not Utf8 ? FYI, using `encodeUtf8C` solved only half of the problem. `glabels` on its side, didn't understood the unicode until I set `LANG` to `C.UTF-8`. I did that by specifying the environment variable when creating the process `proc ... {env = Just [("LANG", "C.UTF-8")]`. Easier and much reliable than modifying docker container itself.
I really like the gloss-like functionality! Just one question: Would reimplementing the ncurses functionality in Haskell add any benefit ? I thought about implemeting a rougelike side project in either Haskell or Idris. The terminal stuff is very OS-specific, and coming up with a library that is cross-platform could be problematic. On the other hand avoiding a non-Haskell dependency is a good thing IMO.
I would love to try it! That being said, I think you don't miss much not hitting the windows crowd, as the windows terminal behaves really poorly in my experience with this sort of thing. Does curses work for Mac?
And if you don't think roguelike is a good name totally raise an issue and make a proposal for a better name
This is exactly how LH works. It is different from the dependent types style of proving, but I also find it to be more natural in most cases :)
That's simply not true: module Y where {-@ type Zero = {v:Int | v = 0} @-} And module X where import Y {-@ one :: Zero @-} one :: Int one = 1 Then in your editor or command line you can see: &gt; Liquid Type Mismatch 7 | `one = 1 ^^^ Inferred type VV : {VV : GHC.Types.Int | VV == (1 : int)}` not a subtype of Required type `VV : {VV : GHC.Types.Int | VV == 0}` In Context
Oh wow, there's a lot of replies here. I understand this now, thanks.
&gt; Does curses work for Mac? Yes, it does, but I'm not sure of the level of compatibility.
Good explanation. Since you have clearly thought about this, do you think that -- outside of the case of recursive pure functions as you described in your example -- one could practically use TLA+ to model pure functions using "variable mutation"? (Here by "variable mutation" I mean changes in state values across a behavior). That is, if one is modeling the essence of a pure Haskell function in a high-level specification language like TLA+, and that function involves no usage of recursion, then is it possible that TLA+ "variable mutation" could still be a useful concept in spec'ing such a function?
I don't see why not. Every algorithm could be naturally described as a state machine. When you write Haskell, you think of some simple things as declarative compositions (which you could model as I've shown in TLA+ using non-computational definitions), but you likely think of your more complex algorithms (like sorting) in terms of a machine that takes steps. It really depends on how you want to think of your algorithm. TLA+ gives you the option of describing a program definitionally or computationally, but usually as a combination of both. Simple things like applying `map` or `filter` are best described definitionally, whereas more complex things like transaction flow are best described algorithmically. If you really think of your *entire* program as some static definition (which I would find surprising for Haskell, but likely in, say, SQL), then maybe TLA+ is not the best choice, because it shines (compared to other tools) when you're describing computations. But you do have to learn to think of an algorithm in terms of how it works rather than how it's written using your programming language's construct. Moreover, if your program is distributed, concurrent, or even just interactive, then you *must* think of it as some state machine, unless you're a type-theoretician who enjoys thinking in terms of infinity groupoids on presheafs or something (I have no idea what this means).
&gt; So the only part of classic imperative "memoization" that usually interests us in Haskell is the algorithm itself - does it recalculate values multiple times, or re-use them? Precisely the thing I find difficult to "intuit" in this pure&amp;lazy new world. Which "thunks" are computed just-once and stay "cached" forever, and which aren't. "Surely if I do a million different multiplications from some real-time input stream of numbers these don't all end up as cached thunks / weak-heads / whatyacallit" --- or so I *think*. But am not too *sure*. Anyone recall where this sort of info is documented?
The [uglymemo](https://hackage.haskell.org/package/uglymemo) package is an implementation of that.
So this same website was posted over in /r/rust yesterday (see [here](https://www.reddit.com/comments/5nxhpp)) and it was found to be inaccurate as it didn't even include repos like Servo or Parity. I can't verify the same about Haskell but I wouldn't be surprised if it was the same here.
No one would blink if you incurred a dependency on a library called arbitrary, just like deepseq for an NFData instance. It needs its own library. I like an Arbitrary instance right there with the type definition. Makes it so much easier to learn a new data type. 
The fact you have to ask to get that added though seems weird, especially for such major projects like ghc and cabal.
I think if you use `unsafePerformIO`, may as well use an ephemeral hash table, that'll be much quicker than a persistent `Data.Map`.
It's exactly that. Structural typing (as in Go or O'Caml OOP) helps a **lot**, but it doesn't really solve the Circle-Ellipse problem. That, and "mainstream OOP"[1] is fundamentally a broken single-dispatch system... as opposed to type classes. [1] Yes, thank you, I'm aware of CLOS. It's not relevant to the mainstream.
Say you have a train system. In real life, conductors scan or punch the tickets of passengers to validate them, and passengers with missing or incorrect tickets are asked to leave. In object-oriented design, you can model this directly with objects such as `Train`, `Ticket`, `Conductor`, and `Passenger` (generally having mutable state and identity) and represent real-world “is-a” relationships with subtyping: a `Conductor` is a `Passenger` with additional privileges. Business logic is expressed through interactions (messages/methods) amongst these objects, and ideally the program reads like instructions for a process in the real world. Moreover, you can use exceptions to determine what to do in exceptional situations—say, an unticketed passenger refuses to leave. This can be a very natural way to model problems, but any algebraic properties or useful laws (which you could enforce with a type system) are obscured by the fact that you’re not composing functions on an algebra of pure representations, but instead conducting actions on a taxonomy of impure agents.
&gt; We can create a concrete value of any type (...) `Proxy` is not a value of any type. The point however is that any type can appear in a type of kind `*`. Many disagree with how `TypeApplications` was implemented, so I wouldn't say it has made `Proxy` obsolete yet.
It's more of an impredicative thing. It requires instantiating a type variable with a `forall` type, but that's not implemented.
Sorry yeah that is what I meant. And from what I understand inference for impredicative types isn't possible, but surely just carrying around impredicative / higher rank types isn't that hard? Although with that said I know a lot of very smart people are working on this kind of thing so it probably is much harder than I imagine.
While I would like a syntax for `forall`, I don't like `\/` at all, and I don't think it's a major problem for `TypeApplications`. As for requiring explicit `forall`, I think that's just too heavy handed. There's way too much code that you just wouldn't be able to use `TypeApplications` with.
IIRC it can lead to unintuitive behavior sometimes, especially around exceptions and concurrency.
That made me wonder -- how much of a rich type system could be added to, say, Java without drastically changing the way you write code in it? I understand that Java doesn't have first class functions, which are a basis for any functional programming. But is a rich type system synonymous with functional programming, or is it totally orthogonal? Of course it can't be necessary for functional programming, since we have dynamically typed languages like Lisp.
&gt; Proxy is not a value of any type. The point however is that any type can appear in a type of kind *. Thanks for the comment. I fixed the error. &gt; Many disagree with how TypeApplications was implemented, so I wouldn't say it has made Proxy obsolete yet. Yes, I agree. It seems it is an overkill to say that `Proxy` is made obsolete by `TypeApplications`. 
unlifted vs lifted is not quite the same as boxed and unboxed. You can actually implement the exact semantics I want without using unboxed values at all, see [here](https://www.reddit.com/r/haskell/comments/5no3tj/would_it_be_possible_to_make_nonsum_types_not/dcddjud/). Now it is true that some optimizations apply to unboxed types that do not apply to unlifted types, so whenever possible (and not a pessimization) GHC should internally replace these unlifted tuples with unboxed ones.
Do let me know if you get stuck would be happy to help!
[corrode](https://github.com/jameysharp/corrode) should be up there...
I think there's a version somewhere else that has more of the sudoku developed, but I can't seem to find the link. I thought it was on Vimeo but didn't find anything. Anyone else?
Hi I changed it so it only animates on hover. Does that work better? Thanks! 
I mostly use the API's from http-conduit to do HTTP request. Also haskell-lang has a nice documentation for it: https://haskell-lang.org/library/http-client
Perhaps this will help: https://haskell-lang.org/tutorial/string-types. Any time you write a `Text` value to a file, there is some character encoding conversion going on. I don't believe "a bit extreme" applies to using BS, it's simply the most natural way to make the character encoding explicit instead of implicit. This tutorial and the "beware of readFile" blog post both go into why the implicit stuff is a bad idea in general.
[**servant-client**](https://hackage.haskell.org/package/servant-client) -&gt; http://haskell-servant.readthedocs.io/en/stable/tutorial/Client.html, dead simple.
I don't understand. So many people seem to use memoization functions/libraries in Haskell. Can someone enlighten me on why we need a memoize function in a call-by-need setting?
Maybe you're referring to his Haskell Exchange talk in 2016?
Note that `typeRep :: proxy a -&gt; TypeRep` which is a more general type that given in the article, and it's what we have in `base` now. Emphasis on the lowercased `proxy`.
Safer Head and Tail or replace with pattern matching?
That's the one. It uses the vimeo player but isn't on vimeo :) Here's the link (requires login): ["Is a Type a Lifebuoy or a Lamp?"](https://skillsmatter.com/skillscasts/8893-is-a-type-a-lifebuoy-or-a-lamp) It's basically the same talk but later in the year, so it's a bit more fully developed (includes printing boards, not just parsing) and has fewer shoes. 
but it's not widely used, is it?
Well... I was planning to raise an issue on Github, but as you ask here... :-) I managed to compile `liquid-haskell-0.6.0.0` from Hackage. Later I compiled the current version from git. I set up `liquid-haskell-cabal` on the `xeno` project, downgrading to a pre GHC 8 resolver in the process. Building the project now runs LH and LH raises some Indexing issues on ByteStrings, nice! Moving forward I probably need to use the `bslen` measure from `Data.ByteString` but LH failes to resolve the name, complaining that it is unbound. The question is: how do I bring it into scope? `Data.Bytestring` is imported [qualified](https://github.com/fhaust/xeno/blob/master/src/Xeno/SAX.hs#L19). Don't know if that is a problem? [edit] I should note that I tried to use `bslen` unqualified, qualified and fully qualified. Also I tried to provide the specs by `LIQUIDHASKELL_OPTS="--idirs=/path/to/liquidhaskell/include`, but to no avail.
Reactions on browsing the haddock: this is a wonderful one-page cheatsheet and single import (!) for modern haskell's basic api, and how did we get this far without it. I think a huge pain point for ~~new~~ haskellers is simply finding their way around haskell's huge import space, endlessly hoogling and tweaking imports, etc. to discover and bring into scope the basic useful types and functions.
Isn't brick a gloss-like interface for the terminal ?
Haskell might be a calculator, but it's a *superb* calculator. Want a number? Calculate. What about a web server? Just calculate one. Wanna go meta and make a calculator app? You can even calculate that! You certainly need a few libraries to get started. You could [read through this](https://haskelliseasy.readthedocs.io/en/latest/) and see if anything interests you. There's also [another more comprehensive survey](https://github.com/Gabriel439/post-rfc/blob/master/sotu.md). The Haskell ecosystem is generally good enough for production use, but quite a few areas really need some love. So this is going to tell you about what's ready and what's not.
 ghci&gt; [1,3..4] :: [Double] [1.0,3.0,5.0] 
I didn't mean "extreme" but only "a bit" ;-). What I mean is, even though, I 99% agree without you about implicit, if we follow it through, ALL accesses to files should be done using BS, which totally makes sense, but is pretty heavy and doesn't really helps the programmer to know which encoding to use. The main problem I encounter dealing with BS, is too know which encoding to accept. In my `glabels` case, it's pretty straight forward, I generating the file and using it. So I have total control on the encoding. But when you deal with external files things are getting much trickier. The only clean way to deal with this is to ask the user to choose the encoding and propagate it to function dealing with BS. That's pretty heavy, considering that `LANG` works 99% of the case and some encodings could be detected automatically. What about, instead of removing all Text related IO function, add them an implicit parameter whith a (Maybe?) list of accepted encodings ? This makes explicit, that those functions are not magical and actually assume there is a default encoding, that you can change if needing. That also allows you to not have to deal with BS directly (it's really a pain to have to import both Text and Bytestring). I know you prefer typeclass over implicit parameters, but I think implicit parameter are under rated and typeclass (or monad reader) have the problem that is really difficult to override temporarily a value. 
Incredibly interesting, though I didn't quite get what the idiom brackets `(|` .. `|)` are for
So? It's relatively new and very popular considering. I've used Servant's server-side stuff for a while now and love it.
they are just sugar for applicatives. So instead of `f &lt;$&gt; x &lt;*&gt; y` you just write (| f x y |)
This really is a case-by-case basis, depending on the data you're writing. In my experience, almost all file formats you're going to be writing are going to tell you which character encoding should be used. There are certainly cases where we want the user or the user's system to specify the encoding... but that's rare IME. In fact, it's so rare that I've never once needed it. Here's what I'd say: * If you're specifying the format yourself, use UTF-8, unless you have an __extremely__ good reason to do otherwise. * If you're using a preexisting format, check that it specifies a character encoding. Formats like XML, JSON, and YAML, for instance, all give rules on how character encoding is handled. * If you're dealing with some preexisting file format, and you're absolutely certain that the character encoding to use is ambiguous, you're on your own, I have no advice.
Good question. I see three options right now: 1. `safeHead :: [a] -&gt; Maybe a` but this is rather silly / useless 2. `withHead :: b -&gt; (a -&gt; b) -&gt; [a] -&gt; b` like `maybe` / `fmap` but this is not enough 3. pattern matching as you described 4. preserve what we have now I'm a bit towards 3. Then you could have `unsafeHead` and `unsafeFromJust` (or `partialHead` &amp; `partialFromJust`).
[removed]
I think all you should have to do is this: ``` compiler: ghc-8.0.2 ``` The [stack-setup.yaml](https://github.com/fpco/stackage-content/blob/master/stack/stack-setup-2.yaml) has already been updated to include GHC 8.0.2 bindists, so `stack setup` should know about them aready. That said, I noticed your content length was different than I'd added to the metadata just after GHC 8.0.2 was released, and indeed it appears they updated the bindists since then, so I've likewise updated our copies and metadata. 
For xmonad there is a great youtube video called "code deconstructed". It also features an episode on [FRP in yampa](https://youtu.be/-IpE0CyHK7Q). 
There is `listToMaybe` there, which is exactly `safeHead`.
I've only gone a little ways into this, but I really like it. One silly comment for /u/byorgey - You could use the GADTSyntax extension instead of GADTs. The GHC manual claims it's been supported since 7.2, so I can't imagine it being a compatibility problem.
After some testing your change seems to increase laziness, it just might be more efficient about how it manages that laziness, but it is definitely not more strict. I cannot find any examples where your change will cause non-termination and the original will terminate. f (_, _) = Nothing -- unfoldLexer f undefined = undefined -- unfoldLexer' f undefined = [] f (_, _) = Just undefined -- unfoldLexer f (1, 1) = undefined -- unfoldLexer' f (1, 1) = [(1, undefined) : undefined : ...] So yeah I am pretty much 100% sure that your change is not more strict. In fact it may actually be evidence in favor of my suggestion, as lazily matching on a tuple then creating a new tuple without forcing the original tuple at all is exactly what my change is talking about.
My first "non-toy, still-a-toy" program was [this static site generator](https://github.com/metaleap/haxtatic/tree/master/src) .. definitely not "just a calculator"! Warning, probably not pro-level code (zero 3rd-party libs/deps used!) .. just to showcase you can really hit the "real world" ground running with Haskell nowadays. =)
It looks like you think the `class` keyword means class in the object oriented sense. It does not, at all. Unless you're doing some pretty advanced type stuff (and you're not, since you don't understand this error) this is wholly unnecessary machinery. You likely just want a `Terrain` type. You can then just have an `isWalkable` function with type `Terrain -&gt; Bool` and skip the `isTerrainWalkable` function entirely. Something like this: data Terrain = Farmland | Hills | Mountains | TheDeepColdVoidOfSpace data Walkable = Yes | Somewhat | NO isWalkable :: Terrain -&gt; Walkable isWalkable Farmland = Yes isWalkable Hills = Yes isWalkable Mountains = Somewhat isWalkable TheDeepColdVoidOfSpace = NO
Think of it this way. When you see a function with this signature `Num a =&gt; a -&gt; Int`, what does it mean? It means that you can give it any value whose type has the `Num` instance. You, as the caller of the function, determine which type that will be. Now if the functions signature was instead `Num a =&gt; Int -&gt; a`, why would the interpretation be any different? The function is expected to work for any `Num a =&gt; a` that YOU as the caller choose. How do you implement such a function? How can you implement a function that returns a value of ANY type? The answer is: you can't. Luckily, the Haskell's type system allows classes to have methods that _create_ the values in question. For example, the above function actually _can_ be implemented because the `Num` typeclass has the `fromInteger` function which let's it construct a polymorphic value out of a concrete `Integer`. To get your code working it would be best if you described the behavior you wanted and then we can see how it can be typed.
Does it actually work 'instantly' as the author states with using `(!!)` which has linear complexity?
Thanks, I got it to compile with the following code class WithTerrain m where isWalkable :: m -&gt; Bool class WithTerrain e =&gt; WithTerrainCollection m e | m -&gt; e where getTerrainById :: WithTerrain e =&gt; Int -&gt; m -&gt; e data Terrain = Grass | Water instance WithTerrain Terrain where isWalkable Grass = True isWalkable Water = False data World = World instance WithTerrainCollection World Terrain where getTerrainById _ _ = Grass isTerrainWalkable :: (WithTerrain e, WithTerrainCollection m e) =&gt; Int -&gt; m -&gt; Bool isTerrainWalkable id m = isWalkable $ getTerrainById id m I have another case which puzzles me: class WithTerrain m where isWalkable :: m -&gt; Bool class WithTerrainCollection m where getTerrainById :: WithTerrain e =&gt; Int -&gt; m -&gt; e instance WithTerrain Int where isWalkable 0 = True isWalkable _ = False instance WithTerrainCollection Int where getTerrainById _ _ = 1 :: Int compile error: • Couldn't match expected type ‘e’ with actual type ‘Int’ ‘e’ is a rigid type variable bound by the type signature for: getTerrainById :: forall e. WithTerrain e =&gt; Int -&gt; Int -&gt; e at Main.hs:20:3 • In the expression: 1 :: Int In an equation for ‘getTerrainById’: getTerrainById _ _ = 1 :: Int In the instance declaration for ‘WithTerrainCollection Int’ • Relevant bindings include getTerrainById :: Int -&gt; Int -&gt; e (bound at Main.hs:20:3) Why does `getTerrainById` returning `Int` fail to compile? My Intuition is that this should not be the case since `Int` is an instance of `WithTerrain`.
Haskell isn't widely used in general, but it doesn't stop facebook from processing 1M requests / sec. Adoption doesn't determine correctness. PHP is widely used, would you rather use that?
Ok ... `bslen` and co are just not available in `lh-0.6.0.0`. The current master has it's own problems. Can you recommend a "mostly stable" commit I could try out?
Good lord, Postgrest is awesome!
It must return a value of type `e`. It cannot return a *specific* type, since you said it could return *any* type `e`. Imagine a genie pops up and says "I shall grant you any form of transportation you request!" and you say "Great, I'll take a private Jet" and the genie says "Here is a pair of shoes, that's a type of transportation." You'd feel cheated. The type signature you have written in your class declaration is defined like the genie's original offer - whatever type you chose, on the use site of the function. You are then trying to supply an Int, reneging on that promise.
Thanks for sharing. What is the advantage of doing this as a DSL compared to a Python library? I guess one is static typing, are there others? Do you use NGLess at EMBL? What was the driver behind this project?
Ah, I think I got it now. Thanks.
looks like it's a bit more than that to me! I think if you wanted to make a real user friendly thing, you might want to use brick, but if you wanted to look at a real simple piece of code built off of the NCurses library that I'm having fun tweaking, you should check out gross
Static typing is one advantage. In general, we do a lot of error checking before even starting interpretation. The result is also very readable even for non-experts as there is little boilerplate. Another important advantage is that Haskell has a compiled implementation and performance matters. I use Python all the time and like the ecosystem a lot, but for some of the things that ngless does, it'd just be too slow (and if using PyPy, I'd miss out on numpy, so that's not very feasible either). By controlling the environment more than would be typical with a Python library (or any other language), we can also get some reproducibility guarantees. Note too that we declare the version of every script so that we can update the interpreter in the future without silently changing the behaviour of older ones. * We are starting to use it, yes, for some metagenomics profiling. It's in "beta testing" phase.
IIRC, that general type-level map only works because of a bug in ghci. Type families can't unify with type variables. http://stackoverflow.com/questions/40758738/why-doesnt-this-code-infringe-the-saturation-requirement-of-type-families 
The type of `getTerrainById` promises that *no matter which instance of `WithTerrain` the caller chooses*, it will produce a value of that instance. So producing an `Int` isn't good enough: you have to produce a value that is polymorphic over all `WithTerrain` instances.
I mean I guess. But I still think my suggestion would solve the issue, at least for this situation, you may be right that there are still some situations that aren't covered.
Hi, yes the 0.6.0.0 is super old -- we really need to put out a new release soon. Try `develop`: that has the `bslen` etc: https://github.com/ucsd-progsys/liquidhaskell/blob/develop/INSTALL.md#build-with-stack-recommended
are you an idiot?
Thanks :) It was also cool to learn how an expert such as McBride thinks while coding, and that he too gets yelled at by GHC.
Please be respectful. https://mail.haskell.org/pipermail/haskell/2016-September/024995.html
It may also help to know how the underlying ideas work. When you say, for example, class Terrain m where isWalkable :: m -&gt; Bool walkables :: Terrain m =&gt; [m] -&gt; [m] walkables = filter isWalkable you are equivalently saying implementation-wise something like, data TerrainDict m = TD (m -&gt; Bool) walkables' :: TerrainDict m -&gt; [m] -&gt; [m] walkables' (TD isWalkable) = filter isWalkable Notice that now the class is actually a dictionary of values (which might be functions) and it is passed as a first argument to the function. So `M a =&gt; b` really means "This is secretly an `MDict a -&gt; b` but I am going to specify a canonical `MDict a` for `a` elsewhere, e.g. for `a = Int` when I say `instance M Int where ...`, and therefore I want you to infer which one I mean by the eventual concrete type of `a`." So now you have `class TerrainCollection m` which says "given a dictionary holding an `isWalkable` function, and an `Int` and an `m`, I am going to cook up for you a value which you could feed to the `isWalkable` function." Surprising and weird! It's almost certainly not what you meant. You can get a step further by using a multi-param type class and functional dependency, so that `TerrainCollection m e | m -&gt; e` now says "I am also going to store a canonical terrain type `e` with my terrain collection type `m`, so that if you hand me the canonical dictionary of `e`, I will cook up such an `e`." It becomes clearer that then you want to drop the `Terrain e` from the multi-param typeclass, it doesn't do anything there. In fact you probably want to go one level more abstract, class Terrain m where isWalkable :: m -&gt; Bool class Collection m where getById :: Int -&gt; m x -&gt; x isTerrainWalkable :: (Collection m, Terrain t) =&gt; Int -&gt; m t -&gt; Bool isTerrainWalkable id coll = isWalkable $ getById id coll Then you have a clean separation between simply "we are storing things with integer IDs" (where you might start with a list type `instance Collection [] where getById = (!)` and then "graduate" to `Array` or `IntMap` accordingly), and "we are looking at terrains," with the appropriate "this is a collection of terrains" thing well-specified in terms of two typeclasses.
Thought to add, I have little experience with purely functional languages (I learned, and coded some Scala), I refer to 'functional programming' when: * Functions are first-class citizens (and types too?), mostly means it should be easy to pass functions as arguments. * Language encourage pure functions, recursive functions over loops, maps and lists over "arrays". * Small amount of assignment statements in code if at all (but is that really possible?). * Support both eager and lazy evaluation. I'm actually thinking to learn Haskell as I really like types and C++ :)
Well, you're right about the function as arguments, but what about the other functional programming concepts? And I'm with you, my whole argument actually is that ES5 = bad as functional language, ES2015, ES2016 = quite good for functional programming. and with TypeScript even better.
Thank you so much for your answer! I understand it much clearly now, though I do have one more question. Since q is defined as the head of qs (via the head function or pattern matching, depending on how it was coded), and qs is defined as `scanr f q0 xs` , doesn't this mean that scanr will be called twice in the expression `f x q : qs`? 
No, there is no restriction; it's a best effort system. All these checks are best effort, they attempt to catch user mistakes as early as possible, but there are no guarantees. In the case of path checks: 1. If the user hard codes a path, then it's easy. 2. Otherwise, as soon as we can, we perform the check. Worst case scenario is that the check is performed just before the write() which is not as helpful, but often we can move it almost to the top of the script and provide a very early check. These checks do not replace the "runtime" checking (also, the state of the filesystem may have changed), but they catch &gt;90% of typos instantaneously instead of after your script has run for a while.
[Spock](https://www.spock.li/) is my favorite.
It could very well be a waste of time for you, but for those who want to show how Haskell can be applied to real world problems that information is invaluable. If a tutorial is leaving you with the wrong idea about Haskell, there is possibly a lesson to be learned to improve our approach.
I'll try it out, thanks. I can't find anything about multipart file upload in the docs, though. edit: seems like wai-extra has something for that. edit2: as per usual, for Haskell, documentation is pretty much non-existant ^^
I don't know if it is as simple as the others but Servant is an excellent piece of server technology. 
See also http://www.lamdu.org/ I don't see the value in upside-down text.
Servant may require a little more upfront learning than, say, scotty, but it's worth the investment. I use it now for all the web services that I write.
`(:)` is kind-polymorphic when used as a type constructor. Its kind is `a -&gt; [a] -&gt; [a]` where `a` can be any kind. That's the reason why both [1,2] and [Char, Int, Bool] can be constructed. 
&gt; The use of the alias at the bottom confuses me. Not sure if you know this already but just in case or for other learners.. of note the @-pattern can be employed for both tuples and lists (maybe other stuff too I don't yet know about ;) When you see it or write it (whether in a let/where variable definition or written as function arg pattern) just always read it as `fulltuple@(fst_val,snd_val)` or `fulllist@(list_head:list_tail)` (although of course where pattern matching applies, *any* valid pattern syntax should work just the same right after the @ --- can do nifty things with this notation!) Consider, sometimes you branch to either do something with the `fulltuple`, or just with its `snd_val` --- with @ syntax you don't have to reconstruct `(fst_val,snd_val)` for the former case or get `(snd fulltuple)` for the latter, you can just name what you're gonna need. Same with lists and the head/tail. A "pythonic" thing you can do this way is single-line multi-"assignment": let (name , age, gender) = ("Bob", 42, Male) -- syntactically a tuple in putStrLn name -- but de-facto just 3 local variables All just syntactic sugar technically, but very productive stuff.
Thanks, I will add a note to my post. BTW, it seems it's a bit hard to explain the strict semantics of type-level functions because it isn't really strict but more like constraint solving. Jan Stolarek's post explains the difference. http://lambda.jstolarek.com/2014/09/promoting-functions-to-type-families-in-haskell/ 
Data.ByteString.Builder _is_ Blaze.ByteString.Builder.
 `xmonad` (the window manager), `shake` (a make-like build system), `turtle` (a library for writing shell scripts), are all great ways to learn Haskell while getting stuff done. http://xmonad.org/documentation.html https://hackage.haskell.org/package/shake-0.15.10/docs/Development-Shake.html https://hackage.haskell.org/package/turtle-1.3.1/docs/Turtle-Tutorial.html 
I think they mean that even simple type increase correctness (e.g. `Maybe` replacing `null`).
I disagree safe head is useless. It allows you to "view" the head of the list then use maybe functions to manipulate the head. 
Now I how It works, thanks!
Ah interesting! I think for every case I've come across where I "don't want to use the old value", I get saved by the fact that *not using the new value* generates a warning.
It seems quite useful, I'll take the @ in account for future endeavours! Now I'm learning the (.) and ($) operators. Haskell never ceases to impress me with different ways to solve problems, both old and new.
The more interesting question is how will you do server-side validation and which DB library will you use. Do write about that once you find satisfactory answers. 
I think Spock covers that capability. Check out "files" and "UploadedFile" here: https://hackage.haskell.org/package/Spock-0.10.0.1/docs/Web-Spock-Shared.html 
Idris has those idiom brackets, by the way, except they're written `[| ... |]`.
I've been following this [pure mssql](https://github.com/denisenkom/hsmssql) driver for some time. If I were you I'd post info about my use case as an issue and ask if the current state of the library can handle it. I tried using hs-ODBC first for my task but ran into issues.
I very much agree with /u/ninegua on there being too much variance in these tests. I'd also like to see something like `Data.Text.concat` added to the tests. 
The fact that bindings are sometimes *implictly* recursive and sometimes not makes it dangerous to shadow bindings anytime. It's a pretty reasonable (and pretty common) thing to do in Ocaml, because there recursive bindings are explicit, but in Haskell it's playing with fire. Now, if we're on the topic of name shadowing warnings, what would be great is if we could differentiate between locally bound names shadowing other locally bound names, vs shadowing globally bound ones. While the former is nearly always a bug, the latter very seldom is. I'm looking at you, Prelude's `log` function. I'd like to shadow you without the bureaucracy of importing Prelude explicitly just to hide you. See how they did it in GCC: http://stackoverflow.com/a/15554949.
That's neat, wasn't aware of that!
&gt; Right, this small example might give the impression of unnecessary machinery, however it is a small part of a bigger program in which I think having a typeclass is the way to go. It is very likely that this is not the way to go at all. While typeclasses look like interfaces in other languages, they are not used in the same way in Haskell. Here is an example on how to write a very general and reusable API [without typeclasses](http://hackage.haskell.org/package/astar-0.3.0.0/docs/Data-Graph-AStar.html). Given your example, I suppose there will be some sort of pathfinding. You might want to think at how a typeclass-heavy approach would be superior in any way to this ... One good rule is that if there are many possible implementations of a typeclass for a given type, then it is a bad idea to use one (some people even go as far as saying there should be only one, and that the typeclass must have rules that must be satisfied). `IsWalkable` is a good example, as different entities might be able to cross different types of terrain. As with this: class WithTerrainCollection m where getTerrainById :: WithTerrain e =&gt; Int -&gt; m -&gt; e What is such a typeclass supposed to do? You can either say your terrain type is an `Enum`, or just write a function `Int -&gt; e` that you will pass to the functions that need it.
The Circle vs Ellipse problem gets solves by immutability, doesn't it?
I got put off Haskel in uni by a fuckwit professor. I may check these out and give it another try.
I have been using https://hackage.haskell.org/package/servant-auth-cookie and it is going well so far.
I'm not making a judgement, simply stating a fact: justified or not, if your "IDE" of choice is vi/emacs a lot of people are not going to take the language serious.
&gt; Come one, a bunch of other languages have a foo[bar][baz] or foo.bar.baz-like syntax for nested structs access, and they're doing great. In your custom prelude or your project's shared-module-that-all-others-import-unqualified: import Data.Function ( (&amp;) ) infixl 9 -: (-:) = (&amp;) Now you can go: `person-:address-:city` and so on. Or use `-.` or `.:` or whatever. Just still-sucks-slightly if your records are from import-qualified modules as this then potentially becomes `person-:Users.address-:Address.city` etc But yeah built-in / canonical syntactic-sugar for this sort of notation wouldn't hurt.
Well if you decide against Haskell for this scenario, at least there is still F# to still go "natively functional" in the MS / .NET universe..
Are there better alternatives to Docker?
...and what many extract from this kind of teaching is what I said above. Also this teaching is the result of a over emphasis on purity, exemplified by the calculator metaphor
Other than history, is there a good reason for `MonadIO` over `MonadBase IO`? `MonadBase` seems strictly better to me and if there's no good reason then I would like to see a migration.
It's not as principled. The abstract syntax tree contains all variable names. There are some transformations applied to the tree before interpretation, but then, the interpreter just walks down the tree (the root is a sequence [ie, a list of statements]) and interprets them. Variables are kept in a in-memory `Map`.
I used to think that Ocaml's `rec` was inconvenient and ugly but now I think it's better to be explicit. I don't think Haskell can change now though.
We've used HDBC and hdbc-odbc. There have been issues with connecting in Linux vs windows environments. We've also faced terribly hard to debug performance problems with the library - for instance sending a SqlLocalDate as a queryparam vs a SqlString slowed us down 10x. 
That doesn't hold up entirely because you might use it more than once, but it's certainly saved me more than once.
I'm not sure. One argument for `MonadIO` is that it's more convenient and requires less extensions. It also may be easier to use in some cases because it matches the kind of other similar typeclasses (`(* -&gt; *) -&gt; Constraint`). But IMO, even if `MonadBase IO` was absolutely strictly better, I'm not seeing enough of a benefit to warrant the fairly significant pain in making the transition.
Servant is my favourite.
Did anyone here had success using Eta with Spark/Hadoop? That would be very interesting for me and I'd really like to hear about that. My experience trying to interoperate Haskell with Spark is not very successful, so having real Haskell in the JVM would be nice.
&gt; I'd also like to see something like Data.Text.concat added to the tests. Why? Text and ByteString aren't really comparable and don't solve the same problem.
I like that Darwin226's way demonstrates how to use pattern matching, just wanted to add that using `isJust` would be a good way to do it too. Edited: remove mention of `not`
I think this is a case where simple recursion would be prettier maybee :: [Maybe a] -&gt; [a] maybee (Nothing:xs) = maybee xs maybee (Just x:xs) = x : maybee xs maybee [] = []
Whoa...I'm trying to wrap my head around why I would want this, but still kinda neat.
To extend of what /u/Darwin226 said, to get the exact function you need, you have to do something smarter than just a `filter` or a `map`. Because `filter` cannot change the elements, and `map` cannot shrink the object: maybee :: [Maybe a] -&gt; [a] maybee = (maybeToList =&lt;&lt;) This works because: maybeToList :: Maybe a -&gt; [a] converts a `Just` into a one element list, and a `Nothing` into an empty list. So if we apply that to every element of `[Maybe a]` we get `[[a]]`, at which point we just concatenate, which for lists is what happens at the end of `=&lt;&lt;` once the elements have been mapped over. The following might make it more clear: maybee :: [Maybe a] -&gt; [a] maybee ms = join $ maybeToList &lt;$&gt; ms So `maybeToList` is the same as above and is applied to every element via `&lt;$&gt;`. And `join` is simply `concat` for lists, but works in other ways for other types. Or you can also just use `catMaybes`, which does exactly what you want for you!
Why would `not` be useful?
why not simply and concisely `(maybeToList =&lt;&lt;)`?
Definitely. The "unused variable" warning has failed to catch my mistakes in math-heavy code, like when doing a series of coordinate transformations producing variables like `x`, `x'`, and `x''`. The compiler can only fix human error so much I guess! :)
This example shows in principle how environments with dynamic backends can be managed without restarting nginx and (more importantly) how nginx instances can be made active clients (in this case of each other).
Ah, cool. Thanks, will do. 
I think OP is just learning, in which case writing the function by hand is useful. He/she could also use [`catMaybes`](http://hackage.haskell.org/package/base-4.9.1.0/docs/Data-Maybe.html#v:catMaybes) from base.
Maybe when funding increases. ;)
Because that's not that simple. OP does not know the relations between `Eq` and pattern matching, and also the fact that `Maybe` doesn't unpack magically, and you propose a partially applied function using the monad instance of list, point free using section syntax and the `maybeToList` function which is buried inside standard library and for which the immediate usage is not obvious ;) If you want a simple and concise solution, there is `catMaybes` (but don't look at its implementation inside base, it is even more confusing ;)
Oh yeah I forgot about that one. That would work well.
I mean they are already using partial application in the original post, and operator sections really aren't that magical. Although yeah `catMaybes` is better.
Ahhh...I see, I figured there had to be a way to filter just based on whether the value was Nothing...need to remember that pattern matching isn't necessarily the same as equality, I guess.
Yeah...I can see how that would work too. Part of what I'm doing is trying to experiment with writing functions as point-free to learn how to do that to. As I work through Haskell from First Principles, I'm trying to write most functions in at least a couple different ways, just for practice and getting used to both styles.
Yes, though I haven't found a good F# backend that supports foreign key constraints that is not a C# ORM. Dapper looked to be the best but I don't love writing inline sql statements in parameterized strings. 
Yeah...I'm just working through Haskell from first principles and haven't even encountered the (=&lt;&lt;) syntax yet.
Shoot...I just realized the function I wrote in my original post was written wrong...It should be, maybee :: [Maybe a] -&gt; [Maybe a] The problem in the book was to go from [Maybe a] -&gt; [a] but I reduced it to the simplest case I could get to fail for the post. I haven't gotten to the (=&lt;&lt;) syntax in the book yet, so I'm still writing things out by hand.
It is still going to have that linear complexity. You can do the same kind of thing with vectors for a lot better performance though. Although you will want to know in advance how deep into `fib` you want to go to set the correct vector size. Now if you don't want to worry about all that you can always just use [memoize](https://hackage.haskell.org/package/memoize-0.8.1/docs/Data-Function-Memoize.html) which seems to be quite fast.
Pattern matching isn't at all the same as equality. You can't really define equality for functions, for example, so any data structure containing a general function can't deal with equality, but you can still pattern match on the outer bits without touching the stuff that's not examinable. Also, once you've figured this out to your satisfaction, this function already exists as `catMaybes` in Data.Maybe, in case you need to use it in the future.
Nice. I just found isJust on Hoogle. I'm not familiar with most of the libraries yet.
Any idea who I could contact? That deal might be possible for me and some others.
Maybe common lisp, but that's likely too easy to write imperative style code in.
If you aren't allowed to just use `catMaybes` and aren't yet ready for `=&lt;&lt;` or `join` then I guess hand writing it with recursion isn't the worst idea.
That does technically work. But just for reference `\(Just x) -&gt; x` is highly frowned upon. As it will crash your program if ever given a `Nothing`. So while it is true that you know that the values are going to be `Just` because of the filter, it is usually better to encode things in a total and more type-based way. `fromJust` also exists which does the same thing, but has the downside of not giving you as good of an error, as it will tell you your code broke within `fromJust` instead of at the call point. You can also replace the entire thing within the filter with `isJust`.
`maybee xs = [x | Just x &lt;- xs]`
Don't really bother for now. Actually it is not a special syntax, only an infix function (similar as `(+)`, `(-)` or any infix operator, really. You will meet it when the book will talk about `Monad`. That one is the flipped version of `(&gt;&gt;=)` which is the function which caracterise a `Monad`. And in this context, it is applied to a list, which is a `Monad`, but not really the most intuitive one in my opinion. Although it is intellectual satisfying to understand this piece of code, that's not mandatory and as many well crafted abstraction, you may be able to use `Monad` long before understanding it enough to understand this example. Good luck. Edit: You need to learn what is syntax in Haskell and what are user defined function. There is not a lot of mandatory syntax in haskell compared to many language (case, if, guard pattern, type definition, function definition, lambda, do notation, type of function, let, where, typeclass declaration, perhaps a bit more, but not that mutch). The rest are just user defined functions with abuse of weird symbols ;), so don't fear them and think you can replace their name by any word.
There's only one infix operator in the expression, so I don't see how that could help. It certainly doesn't parse as `(runST $$ do) ...` instead of `runST $$ (do ...)`!
The difficulty of reasoning is a Haskell red flag, so I suppose the next step would be to design an abstraction that makes this delayed evaluation reasonable, like pipes/conduit do, but I expect it needs a new kind of bidirectional flow of data.
Sorry, I meant the `ByteString` version of `concat`.
This was posted 27 days ago, but I'm surprised it got no upvotes. This particular passage I found very interesting: &gt; I’ve been doing functional programming for over 20 years now. For decades there was a social chasm between functional programmers and people who had real problems to solve. Thankfully this problem is now starting to dissolve away with functional languages like Scala, Clojure and F# being used for real work but for many years the predominantly-smug-weenies dominated the functional scene, making it hard for people to get real solutions to their real problems. Part of the reason for this was that, having languished in obscurity for so many decades, some communities (most notably Lisp) had highly evolved (but wrong) arguments as to why Lisp was good. It took me many years to figure out what was wrong with these arguments.
+1 to this. These sorts of digestible blog posts are pretty common in the Scala community. I learned a lot about Scala's type system / type-level capabilities with them. These seem to be filling a similar niche, and with Haskell's proliferation of extensions, it's even more useful.
If one smugly calls the community a bunch of smug weenies, then they don't really want to hear what one has to say.
It got no upvotes because it's the same FUD Harrop has been peddling for years.
I find the other points that focus on actual technical issues much more interesting.
Isn't the blogger, Jon Harrop, a troll.
The technical points, I think, have merit. Even in Haskell we use mutable data when we have to.
Yes. The first item is the thing he's been fixated on for years: the hashmap. Will not read the rest.
wow, I had no idea this guy was a character in the community. But maybe you should listen to his technical arguments, he is arguing along technical lines, (maybe without going all the way to mathematical analysis), but it's true, haskell does have performance issues. Which -- is probably the main thing that's blocking it from commercial success.
This seems a repost of [an older blog post](https://flyingfrogblog.blogspot.dk/2016/05/disadvantages-of-purely-functional.html?m=0). I think Harrop's good points drown in his caustic style. In particular, I agree with him that the ease of (efficient) parallelism in functional programming is vastly overstated. However, I do not agree with him that one paper having a poor choice of performance baseline is a symptom of this problem.
I found I was reading that in the voice of General Ripper: &gt; ... some communities (most notably Lisp) had highly evolved (but wrong) arguments as to why Lisp was good. It took me many years to figure out what was wrong with these arguments. It's incredibly obvious, isn't it? A foreign substance is introduced into our precious bodily fluids without the knowledge of the individual, and certainly without any choice. That's the way your hard-core Commie works. 
&gt; haskell does have performance issues. Which -- is probably the main thing that's blocking it from commercial success. Python has commercial success, and is obviously a lot slower than Haskell. So I doubt this is the reason.
is it really? care to link this. First time hearing this.
Python is slower, but Haskell is harder to reason about. Edit: I was being unclear. I meant resource complexity is harder to reason about in Haskell.
^Hi! ^Here's ^a ^summary ^of ^the ^term ^"Strawman": ---- ^^A [^^straw ^^man](http://rationalwiki.org/wiki/Straw_man) ^^is ^^logical ^^fallacy ^^that ^^occurs ^^when ^^a ^^debater [^^intentionally ^^misrepresents](http://rationalwiki.org/wiki/Red_herring) ^^their ^^opponent's ^^argument ^^as ^^a ^^weaker ^^version ^^and ^^rebuts ^^that ^^weak ^^&amp; ^^fake ^^version ^^rather ^^than ^^their ^^opponent's ^^genuine ^^argument. ^^Intentional ^^strawmanning ^^usually ^^has ^^the ^^goal ^^of ^^[1] ^^avoiding ^^real ^^debate ^^against ^^their ^^opponent's ^^real ^^argument, ^^because ^^the ^^misrepresenter ^^risks ^^losing ^^in ^^a ^^fair ^^debate, ^^or ^^[2] ^^making ^^the ^^opponent's ^^position ^^appear ^^ridiculous ^^and ^^thus ^^win ^^over ^^bystanders. ^^Unintentional ^^misrepresentations ^^are ^^also ^^possible, ^^but ^^in ^^this ^^case, ^^the ^^misrepresenter ^^would ^^only ^^be ^^guilty ^^of ^^simple ^^ignorance. ^^While ^^their ^^argument ^^would ^^still ^^be ^^fallacious, ^^they ^^can ^^be ^^at ^^least [^^excused ^^of ^^malice.](http://rationalwiki.org/wiki/Hanlon%27s_Razor)
https://www.quora.com/Where-does-Haskell-fall-on-the-performance-scale-between-Ruby-Python-and-C Haskell is interesting because, written sloppy like and poorly, it can be slower than Python, but written very optimized, you can get C levels of performance out of quite a bit of it. Realistically, normal code seems to be anywhere from a bit faster than Python to quite a bit faster, especially when parallel stuff is concerned. 
Interesting, what do you find that's overrated?
Wait what? First time hearing that Python is slower than Haskell? Are you shitting me??? http://benchmarksgame.alioth.debian.org/u64q/measurements.php?lang=ghc http://benchmarksgame.alioth.debian.org/u64q/measurements.php?lang=python3 Because of the whole "statically typed with type erasure and actually compiled" thing, Haskell is usually an order of magnitude or so faster. Like they are barely even comparable. EDIT: Thanks /u/igouy for the better [link](https://benchmarksgame.alioth.debian.org/u64q/compare.php?lang=python3&amp;lang2=ghc)
Wut, have you ever actually used Haskell?
You can have multiple things pointing to the same object and actually mutating in place at any time in Python, so you definitely don't get rid of ANY issues. And then there are a trillion more introduced by python because you have absolutely no guarantees of anything, anything can be monkeypatched or mutated or do literally anything.
When I said easier to reason about, I meant the cost semantics are easier to reason about. Yes, Haskell's dynamic semantics are easier to reason about than Python's.
All Applicatives should implement `Num` anyway, so that isn't a good example. 
I still don't agree with that though. Generally I find the implementation and performance of Haskell functions are a ton more intuitive than Python's OOP mess of inheritance and effectful functions.
Why all these downvotes for this guy? Yes, once you pass the cognitive barrier of getting used to the Haskel way to do stuff, it get easier, but after knowing nothing but shell commands and TI BASIC, I picked up enough Python to be dangerous in about a week. I'm a few months into Haskell and I still can't write anything practical. This is not an uncommon story.
[An older thread about this post](https://www.reddit.com/r/haskell/comments/4ogle3/post_about_the_disadvantages_of_functional).
Try writing it with `foldr`, too! maybe = foldr combine empty where combine x acc = ??? empty = ???
thanks! nothing too suprising. I was just curious so I figured I'd share. Now I feel a lot less guilty about using `++` in my scripts.
My point is not that Haskell is harder conceptually than Python (that may be so, but it's not what I'm saying). My point is that it's difficult to analyze time and especially space complexity in Haskell.
Maybe but people writing in python usually don't implement algorithms in pure python. They use python as glue code for C/fortran bindings.
What happens to the promised "ease of use" of dynamic languages then?
thanks! that made a big difference
I don't think the reason is inherent to pure functional programming, [but we apparently do have hashmap problems] (https://github.com/tibbe/unordered-containers/issues/119).
We do have hashmap problems, or data structure problems in general. The particular linked problem is an issue of trade-offs mostly, but we have more core issues: We don't have guaranteed compile time-dispatched polymorphism (e.g. ala C++). This leads to two problems: * For functions to be efficient we use `INLINABLE` to try to compile-time specialize away dictionaries and inefficient calling conventions (i.e. pass values by pointer). However since `INLINABLE` is a pragma, not a guarantee it can fail as programs get large enough and sometimes spectacularly so. * For data types we use a very inefficient pointer-to-value representation for the elements contained in containers. This is bad for both cache locality and cache usage. If we fixed these two core problems we could have much better collection types.
After spending some hours, to getting LH set up, I found that I probably have to rewrite a lot of the Xeno code to replace the exception based code. That's not strictly necessary, but I guess the goal of this exercise is to write code that "cannot fail". I actually managed to check the very first version that is found in your blog post (with a little help from the liquid haskell guys). So a little success there. That said, if I run Liquid Haskell on your original code the `SAX.hs` file is actually considered `SAFE`. But I don't know how exceptions are handled by LH.
And somewhat outdated. Try the Haskell Book by Chris Allen, and Julie M.
&gt; He may be caustic/toxic, but instead of trying to downvotes him to oblivion, I believe the better response is to have a point-by-point rebuttal on the Haskell Wiki. I think you are totally free to create one if you like. &gt; And even I've had shades of similar experience where things that are straightforward in imperative languages, become unnecessarily complex in Haskell. It's funny you're saying that, because I feel the same way but the other way around (simple things in haskell become hard in imperative langs). There are tradeoffs when choosing a language and paradigms. I think haskell makes better tradeoffs. &gt; So, Don't try to bury him. Disenfect, if what he is saying is wrong. Again, you are free to do that if you wish. I think fighting trolls is a total waste of time and energy and is incredibly boring. I'd much rather see people create stuff in Haskell or for Haskell than see them trying to fight every troll that comes along :)
That's nice. Can I see the code?
Because Python has tons of libraries for everything?
Sure, it just looked like nobody had mentioned it then...
Yes, see http://stackoverflow.com/questions/12001350/useful-operations-on-free-arrows
tbh, `isJust` is yet another terrible case of "Boolean blindness" you're probably better of never using it and using either pattern matching (or, nowadays `null`). For a good explanation of boolean blindness, see: https://existentialtype.wordpress.com/2011/03/15/boolean-blindness/ and https://shreevatsa.wordpress.com/2015/01/31/boolean-blindness/
The problem is that he lies, misrepresents, and changes the goal posts as he's exposed. This is time wasting and discussion with a liar is usually a waste of time.
Correct me if I'm wrong, but I believe that you could write a pure functional language with linear types and ownership that had no garbage collection whatsoever. Rust proves this, it's not a purely functional language but one could be made that shamelessly steals its concepts. This would probably be inconvenient though, because you could not express some forms of recursive data (and, since functions are data, some forms of recursive functions). I think this bars the existence of curried recursive functions in the general case, but I'd love to be wrong. You could write a functional language with a different kind of GC, too. Reference-counting would be another solution, but probably not what you want because it's trivial to create cycles.
&gt; compile time-dispatched polymorphism What do you think about using associated data types for this, as `adaptive-containers` does?
Thank you, the example is indeed helpful!
Fixed! Thanks.
&gt; This would probably be inconvenient though, because you could not express some forms of recursive data I don't actually think so. I'm not sure what exactly you are talking about, but at least when it comes to easy things like singly linked lists, it's easy to do in Rust, you just have to fall back to heap allocations. You can't do enum List&lt;T&gt; { Nil, Cons { head: T, tail: List&lt;T&gt; } }; but you can do enum List&lt;T&gt; { Nil, Cons { head: T, tail: Box&lt;List&lt;T&gt;&gt; } };
I don't think so
I'll give you an example of how to fix the "show . read" example. The compiler has to know which parsing code it should execute for these functions. You can't just execute the read function. You have to execute it for a particular type. Somehow you have to tell the compiler which type to use between the show and the read. There are a number of ways to do this. Here are a few possibilities: (show :: Bool -&gt; String) . read show . (read :: String -&gt; Bool) forceBool :: Bool -&gt; Bool forceBool = id show . forceBool . read 
The majority of his complaints are unfounded when you consider `Vector` and `ST`
Yeah. I think that improvements like these are worth the effort rather than removing return from the Monad class. But they attract much less attention from the community. This is also cultural.
Take a deep breath. "5GL" was almost purely a marketing term, used by 1980s Japan to create the impression that they were leapfrogging the US in software (they weren't). A modern analogy would be "Web 3.0" or "7D cinema".
Thanks, I've just started writing the code without typeclasses and it feels easier to me (at least for now) :)
That's a recursive _type_, I mean recursive _data_. So, a list like bunchaOnes = 1 : bunchaOnes is representable in a language with ubiquitous garbage collection because `bunchaOnes` is just a pointer, but in a language without it would cause a memory leak, since it can't own this data and if you use `Rc`s then the structure will always have a single referent (itself). Maybe you could have the user specify which values are weak references and which are strong, who knows.
it's easy to write sloppy glue code (hard to maintain but easy to write) :P Also to be fair people prototype algorithms to re-implement in C++, or they write algorithms that can expressed as some composition of linear algebra operations, in which case you're leaning on numpy which is leaning on fortran. Could you do these things better in Haskell? In theory yes, but the numpy equivalent hasn't happened yet, people are working on it though.
Oh, you're talking about infinite lists? That working in Haskell has got much less to do with garbage collection and much more with Haskell being lazily evaluated. It is not a general problem in Rust either, though; you just have to represent the list tail as a function, which is kind of what unevaluated values are in Haskell. The easiest kind of (possibly) infinite "list"s in Rust would be [`RangeFrom`](https://doc.rust-lang.org/std/ops/struct.RangeFrom.html). EDIT: Kicked a word that made the whole thing sound unnecessarily unfriendly; sorry!
Alright, that particular problem was solved by `rm .stack-work -rf` -- have now managed to make `intero` boot, at least. But then, `intero` fails to load a source file via `C-c C-l` (aka `intero-repl-load`) like this: Starting: stack ghci --with-ghc intero "--docker-run-args=--interactive=true --tty=false" --no-build --no-load --ghci-options "-odir=/home/deepfire/src/mood/mood/building path(s) ‘/nix/store/h0n79g62y2xfsyz9pii61psi5x657xrv-cabal2nixResult’/building path(s) ‘/nix/store/7sfadwxkw5rh92sxwi8fv06hkhjb1x92-cabal2nixResult’/.stack-work/intero/intero11385MrM" --ghci-options "-hidir=/home/deepfire/src/mood/mood/building path(s) ‘/nix/store/h0n79g62y2xfsyz9pii61psi5x657xrv-cabal2nixResult’/building path(s) ‘/nix/store/7sfadwxkw5rh92sxwi8fv06hkhjb1x92-cabal2nixResult’/.stack-work/intero/intero11385MrM" mood building path(s) ‘/nix/store/6vx9bzzqj4n1rgjcddl801ynblswfaa1-cabal2nixResult’ Intero 0.1.20 (GHC 8.0.1) Type :intro and press enter for an introduction of the standard commands. Warning: ignoring unrecognised input `‘/nix/store/7sfadwxkw5rh92sxwi8fv06hkhjb1x92-cabal2nixResult’/.stack-work/intero/intero11385MrM' Warning: ignoring unrecognised input `‘/nix/store/7sfadwxkw5rh92sxwi8fv06hkhjb1x92-cabal2nixResult’/.stack-work/intero/intero11385MrM' Warning: ignoring unrecognised input `‘/nix/store/7sfadwxkw5rh92sxwi8fv06hkhjb1x92-cabal2nixResult’/.stack-work/intero/intero-script11385Z1S' target ‘path(s)’ is not a module name or a source file Prelude Text.Printf&gt; target ‘/home/deepfire/src/mood/mood/building’ is not a module name or a source file Prelude Text.Printf&gt; 
Personally, I can't wait for 7D cinema to be a thing.
No, it's unrelated to laziness. You can have a circular linked list in C or Python or JavaScript. `RangeFrom` is different, since it generates values on the fly. It might represent a collection to us squishy humans but it's unrelated to collections internally. You can represent cycles with iterators, but you can't represet an arbitrary graph, for example a list that looks like `A -&gt; B -&gt; C -&gt; D -&gt; B`, safely without garbage collection. It might be that that isn't a particularly useful topology but the point is that there are serious annoyances and issues with ownership/refcounting. They don't come up as often as you'd expect, but purity compounds these issues. Monadic abstractions are more costly without garbage collection, for example, because: someMonad input = do a &lt;- first input b &lt;- second when (a &lt; b) $ someMonad a -- Retry if we got wonky numbers return $ a - b Conforms to exactly the structure I mentioned above. The use of the parameter is to show that you can't just have a normal pointer either, it has to store data.
Yes, *as-fast-as-C* when it is C :-)
I wondered if you had additional information, I didn't interpret the post that way. 
Python's compiler is certainly faster ;) 
Perfect :) 
To be fair, countering John Harrop with reasoned argumentation was a major sport in the 2008-2010 era. Then we all got bored and moved on. You can probably find a dozen old blog posts from that era, but we just stopped giving him mindshare as it became clear that no matter what we said or whatever argumentation he tried to offer on the surface, he just wanted to sell books/consulting services. 
Ahh yeah, the Python example was the explanation I needed :D This does seem like it would be hairy to implement in Rust without leaking `c`. I suppose I just haven't come across a problem where this was the obvious solution yet.
https://ghc.haskell.org/trac/ghc/ticket/8767
To summarize: because the rule would break non-lawful instances. I'm not sure why that's a good reason though. If my code mysteriously breaks when I turn optimizations on and I discover that it's because my instance doesn't satisfy the Functor laws, I'll blame my instance, not the rewrite rule!
This would be an optimization that you'd have to specifically ask for, IMO. I often have non-lawful instances, and I don't want the compiler messing with what I'm doing.
Good question! There is no need to worry, as that is not really code. What the OP has written are just equations, in each case saying that both sides must be the same. We often write class laws (that is, the specification of how methods of a class should behave) in this way.
Fantastic wrap-up! Any good resources (or just sub-field key-words to research further) you'd recommend with regards to: &gt; It is possible to build little libraries that provide declarative specification of problems (..) You can write a simple little finite domain solver in Haskell, or (..) and then use it to solve 'declarative' specifications. In that sense you can build little "5GL" EDSLs in any language. ? With a strong focus on the search/reasoning/solving part (over the EDSL (or parsing) part)?
&gt; because the rule would break non-lawful instances. In that case, it seems like the kind of thing that would work great in Prelude alternatives.
Very tangential question: I've stumbled across SMT solvers a few times now, but never really jumped into the domain. Do you know of any resources which approach them from a Haskeller perspective? Or is SMT in general about as useful to us as, say, machine learning: cool, interesting, but (afaik) little if any relevance to the daily coding and modus operandi of a Haskell programmer?
So, the hospital will have internet access right, guys? We'll have to get him some ECC memory so his neck doesn't segfault GHC.
That is some very unfortunate news :( Wish you the best in your treatment.
[removed]
&gt; I'm interested to hear why you think it's magic. It uses the same language features as extensible records. Yes, I just mean that the `#` kind is fairly magical. In a dependently typed language, the equivalent would be definable within the language.
Good luck with the treatment. I hope everything goes as well as it can.
What a difficult situation. I wish you the best and a speedy recovery.
Ah ok, I see what you mean. I've thought a bit about this, since we recently added fundeps, meaning you _could_ implement something like rows in the type system now, if you wanted to. I do think it's worth keeping rows, along with their special behavior in the type checker though, both for performance reasons and the fact that they are much simpler to understand.
That really sucks man. I hope everything goes well and that you have a smooth recovery.
I wish you the best.
I agree. We've already seen the endless stream of issues that come with trying to define row types with a Haskell-like type system using typeclasses and fundeps. It just doesn't work very well. So for a language without dependent types, I think you made the right choice. But I do think dependent types are the best way to solve this problem.
You can have rewrite rules written pretty much like so as well https://downloads.haskell.org/~ghc/7.0.1/docs/html/users_guide/rewrite-rules.html
Although I dislike Elm for its tendency to become a huge bunch of boilerplate, I think it is a nice way of introducing people to FP: Let them try out Elm and reveal to them a couple of days later, that everything with an 'andThen' function is a monad. But the author is right in saying that this only works, if there is a Haskeller around as a lot of FP programming techniques are simply called 'good design' in the Elm community . 
Really happy to see you succeed with your plans Christiaan! I remember you hoping for the best not half a year ago, and it seems you got just that :-) 
Since "Elm" made the list, I think js_of_ocaml (a side-project of the client/server Eliom/Ocsigen project) should make it too. It compiles OCaml bytecode to JavaScript and has proven rather stable and efficient, even if it's a bit lacking in the marketing area.
Good luck with the treatment
isn't more a research problem and not a fundamental flaw in FP-languages? to quote from the 2015 paper: &gt; Comparing the GPU implementations, although we have doubled the performance of this program over our previous work [32], the hand-written CUDA version is still several times faster, as it uses on-chip shared memory to reduce the memory bandwidth requirements of the program. The shared memory is essentially a software managed cache, and making automatic use of it remains an open research problem [29].
Ha, a down voted article, but look at all the discussion!
Best of luck and get well soon Ed!
 unIdentity :: Identity a -&gt; a unIdentity (Identity a) = a
That definition removes the variables `fx` and `fy`. Sometimes those variables will be things like `peopleIHate` and `peopleILove`, and thus the meaning of the code is significantly impaired by removing them. It makes the refactoring more possible, but you still have to be careful.
Is PureScript the language necessarily strict? I know that the default JS compiler produces strict output. I think that's because lazy output either requires a runtime or more annoying JS. Since PureScript doesn't have a spec (that I know of), creating a lazy compiler might be fine. In fact, I started working on [a PureScript to Haskell compiler](https://github.com/tfausak/thran). It is lazy. 
In my mind, the only unlawful instances we should be using are ones that are only unlawful because of `bottom`. And I don't think these instances should be morally considered "unlawful." So I think a LAWFUL pragma would be misleading a kinda gross.
Tysonzero's is correct, but you can also use the label from the constructor: unIdentity :: Identity a -&gt; a unIdentity = runIdentity
I wish you all the best in getting through this.
Reflex is definitely not bound to GHCJS. I've used Reflex on the server, and I've used GHCJS without Reflex.
Also &gt; This is about purely functional programming, which means I’m not even going to consider a system valid without managing IO in some way.
Yeah, I agree, but given that people write unlawful ones and that is stopping these rules from being applied, that would be an advance. And that would be an incentive for writing lawful ones, optimization for free.
I think we lack a "really real world" haskell book/tutorial with all REPL stuff reduced to a minimum
I agree, but how that can be verified practically? The only law there is in Haskell is the type system and it's not enough for it. I know that `SubHask` [automatically generates]( https://github.com/mikeizbicki/subhask#automated-testing) tests based on the laws you give to a class, and I always found that awesome.
Ouch! Good luck!
All the best. I've looked up to you since I started programming in Haskell. What else could the symptoms have been indicative of?
Genuinely lawbreaking. For instance, I often make instances that build syntax trees for deeply embedded languages (not just Functor, but any class). And I don't want the compiler to make transformations that it cannot know are correct. 
Wouldn't it make sense to use something other than `Functor`, since what you have is not actually a `Functor`?
I prefer to use existing type classes. With some care the code can be used with different concrete types, some that obey the functor laws, some that don't. I don't mind using type class laws for optimization as long as it's opt-in. 
I liked [safe-prelude](http://www.snoyman.com/blog/2017/01/safe-prelude-a-thought-experiment)'s description. [SubHask](https://github.com/mikeizbicki/subhask) is extremely interesting.
I think you're missing the fact that dependent rows are very hard to infer. PureScripts row types basically always infer in my uses. This being said dependent types are the future, go dependent types!
I wish you all the best and that you quickly and completely recover from this. 
If like me you're a Haskeller and want to give PureScript a try on a project but can't justify installing node and derived tools, and need reproducible builds like with Stack in order to mitigate development risk, you can use https://github.com/chrisdone/purify It's similar to stack but lacks a stackage, and PureScript packages are still so in flux anyway I prefer specifying by commit hash mostly. Additionally, you can use stack to manage PureScript psc and psc-bundle, and purify, so that all your ps build tools are also reproducible. I used this at work and it's sufficient to run stack build; stack exec purify and everything is pulled and built automatically. No node nonsense or other strange dependencies necessary. No buggering about with require.js mess. Put your .purs sources in src. Example project: https://github.com/chrisdone/metrolink it doesn't actually do anything, just a file structure.
Thanks! You can see elsewhere on this thread that I realized my error (I had recently been reading a paper about singletons) and that LH handles this trivially without special ceremony. But it's nice to see it interact with the real world to make that click early. I'm getting super excited about LH.
Unfortunately it doesn't work. If you look at the [source](http://hackage.haskell.org/package/adaptive-containers-0.3/docs/src/Data-Adaptive-List.html) you see that this suffers from the problem of having to list all possible specializations up front. This doesn't work for your own types and doesn't even work for the standard types if there are two type parameters, as that would give rise to O(n^2) instances written by the programmer. For polymorphic compile-time specialization to work it really needs to be done by the compiler based on the uses it sees.
 mapMyType :: (a -&gt; b) -&gt; MyType a -&gt; MyType b instance Functor MyType where fmap = mapMyType {-# INLINE fmap #-} {-# RULES “mapMyType/mapMyType” forall f g. mapMyType f . mapMyType g = mapMyType (f.g) “mapMyType/mapMtType2 forall f g x. mapMyType f (mapMtyType g x) = mapMyType (f.g) x #-} --- In general, you /just/ cannot prohibit people from writing law-violating instances. For example, they could be lawful only if some condition on input is true. E.g. I can imagine there is a `Functor` which is lawful only if `f` in `fmap f x` is lazy (or maybe not with functor, but with some similar class. 
I've been messing around with achieving something like that with Nix. Step one was to get [a Nix system around](https://github.com/ElvishJerricco/nix-purescript-skeleton) it, where given some `purescript-packages.nix` file, it gives you a very simple build interface. Next step was to [auto generate that file](https://github.com/ElvishJerricco/purescript-packages2nix) from [purescript/package-sets](https://github.com/purescript/package-sets). This does a great job at getting all those benefits from Stack/Nix with very little effort. But it currently has two major problems: 1. `psc` is not yet designed for compiling against precompiled dependencies, so I had to do an ugly workaround to trick the incremental compiler into not recompiling other things. [I've opened an issue about this](https://github.com/purescript/purescript/issues/2477), but have unfortunately not yet had the time to fix it myself. 2. Getting an incremental dev environment for this also depends on that same issue. `psc` and `psci` need to be able to build against those precompiled dependencies automatically in order to use them in a `nix-shell` to do manual incremental builds for dev time.
Shameless Plug: I'll be giving a talk about more or less exactly this at BOBKonf this year in Berlin: http://bobkonf.de/2017/athiemann.html :-)
React-flux is great, but you have to be careful with callbacks between JavaScript and GHCJS Haskell...
The author /does/ consider JavaScript as an option, so that list is not really restricted to purely functional programming languages anyway.
For example this, is not strictly lawful: https://github.com/bos/aeson/blob/d470ac61874b4dc80b88a44a0c2d967430a8d5ce/Data/Aeson/Types/FromJSON.hs#L415 Unfortunately I don't remember from top of my head any example where the `fmap id -&gt; id` direction would cause problems&gt; Actually today during bike ride I was thinking of using `Applicative` to construct an AST of some language, which could be interpreted directly `AST a -&gt; a`, or used to generate some textual representation. I dismissed the idea by the end of the ride, as `Applicative` laws would allow transformations, so that textual representation won't be possible, i.e. something previously concrete will hide inside the function. (Maybe something like `Apply`without `Functor` instance would work, it was a short ride).
With lumps on the side of your neck, it could probably have been any form of orofacial cancer.
How?
Having the supraclavicular lymph nodes matted and enlarged that way tends to be a strong indicator of lymphoma which has much scarier survival rates.
The author considers JS with the caveat that you must use the cleanjs eslint config and the Rambda Fantasy library. 
Waitaminute, if the doctor cuts does that mean I can't backtrack?
Would there be a better way to encode that, that did not involve such unlawfulness? Why bother with `FromJSONKeyCoerce CoerceText`. Isn't `FromJSONKeyText coerce'` essentially the same?
Would there be a better way to encode that, that did not involve such unlawfulness? Why bother with `FromJSONKeyCoerce CoerceText`. Isn't `FromJSONKeyText coerce'` essentially the same?
mconcat [Reflex, GhcJS, Yesod, PostgreSQL, Heroku]
Would there be a better way to encode that, that did not involve such unlawfulness? Why bother with `FromJSONKeyCoerce CoerceText`. Isn't `FromJSONKeyText coerce'` essentially the same? Is it just so that you can check sometimes if all you are doing is coercing and nothing else, so a very limited function equality / introspection?
You'd think so, but nobody has done it. That's one of the issues with the haskell ecosystem, we needs more contributors willing to go beyond "solution exists" and proof-of-concept stages. I think the C code is written very much with Python bindings in mind, but I haven't looked myself to see how feasible it is.
Heh, I wish we'd have cut-free surgery as of now. That's why we need you with a heatlhy life and brain so you can help disrupt the medical field and unleash non invasive surgical nanorobots.
I had surgery almost two years ago, and my recovery took longer and was more difficult than I expected (or hoped). The best thing for me was when people told me to take all the time I need, and not worry or feel guilty about the situation. So I say this to you now, too. Take all the time you need and thank you for the enormous amount of work, dedication, and helpfulness you brought to the Haskell community. 
Best of luck with the surgery and treatment Ed, wishing you a speedy recovery. I've never failed to be inspired listening to your talks or talking to you in person. Thanks for all the hard work you've done in the Haskell community. Cheers
Get well soon
Best of luck! Fight it!
He used Erlang to demonstrate QuickCheck.
wow :( hope all goes well
Is there a reason this should be left out of base for the default definition?
Well for one thing, it's only an improvement for singleton foldables like `Maybe`. It won't actually tailcall anything but the last element. It also may have performance overhead due to converting to a list (something which could be avoided with a more clever fold). It's also a breaking change, since the function you give it must return `()`, which won't compile with a lot of current uses of `mapM_`. And although I don't think this matters, it's worth noting that the semantics are slightly different for unlawful instances of `Applicative`, since it removes the trailing `pure ()` in nonempty cases.
Thanks! The API breakage is quite bad. I wish there was some way to do this without the function needing to return unit.
There is work being done in bringing linear types to GHC for safe efficient mutation in pure code. Also, there was the recent support for levity polymorphism to make working with unlifted data much easier.
I should also add that, as per a comment in the OP, this breaks under `bottom` as well. `mapM_ putStrLn ("hello" : "world" : ⊥)` evaluates to `putStrLn "hello" *&gt; ⊥` instead of `putStrLn "hello" *&gt; putStrLn "world" *&gt; ⊥`. As for doing it without changing the return type, this is unfortunately just not possible for foldables that might be empty. We have to be able to do `pure ()` in the empty case, and the only way for tail calling to be compatible with this is to also return `()`. One of the few semantic differences between a `void` function in C and a `m ()` function in Haskell.
Sorry to hear, Best of luck.
You could also throw in `mapM1_` or something like that and either just unsafely ignore the possibility of an empty foldable, or use something like [this](https://hackage.haskell.org/package/semigroupoids-5.1/docs/Data-Semigroup-Foldable.html). If that helps for obtaining a useful return type sometimes.
How would you achieve that without inserting some `()` such that the tail recursion is broken?
Uhh. I mean maybe I am missing something but shouldn't this work: mapM_ f a = mapM_' ((() &lt;$) &lt;$&gt; f) a Where mapM_' f a = ... -- your original code that is tail recursive
Thanks for all you've done for the community, and for me personally. Wishing you a smooth recovery and (echoing Ancipital) all the time you need to take care of yourself.
You're an inspiration for me, I've come across your work very early on my learning process - the right combination of mathematician and programmer. I think you'll beat that thing, you're strong and, as I can see from here, a very kind man. Best of wishes, you can do it!
Wait what? But `f` is already an arbitrary function that you have absolutely no control over. So how in the world can a change to it affect your function in a way that wouldn't already cause your function to not work half the time? I am very very very confused.
Please don't die before I meet you in person and get a categorical monologue! 
 foo f a = f a I do not control `f` here. But Haskell will still do tail call optimization. Similarly, foo :: (Result -&gt; IO a) -&gt; IO a foo f = do result &lt;- calculateResult f result Haskell will do tail call optimization on `f` here, meaning the stack will not grow by 1 from calling `f`. Finally, foldr ((&gt;&gt;) . f) (return ()) [x1, x2, x3] == mapM_ f [x1, x2, x3] == do f x1 f x2 f x3 return () Clearly, in this case, `f x3` won't be tail called. The OP is about transforming this to: do f x1 f x2 f x3 So that `f x3` can still be tail called, even if `f x1` and `f x2` won't be (works out fine when the foldable is `Maybe`, since there will only be a tail callable element). Haskell will grow the stack by one for each of the first two elements, but the stack will not grow for the last one. Your suggestion transforms that to this: do () &lt;$ f x1 () &lt;$ f x2 () &lt;$ f x3 at best. Clearly, this cannot tailcall `f x3`.
This is great news, I just need to find a good excuse to use clash now. Conrad Parker did a great talk about how they're [using CLaSH at Optiver for HFT](http://yowconference.com.au/slides/yow2016/Parker-FPGAMicroservices.pdf) (though without any of super secret HFT sauce). The video isn't up yet sadly.
I agree! It is a good practice to have a central `Import` module based on one of the recommend prelude libraries and adjust it with respect to the requirements of the project. This really helps in practice. 
Servant needs an underlying HTTP server. It doesn't do that part on its own. By default it does this with Warp, but you can do it with Snap too. Basically just means that `Raw` endpoints will be Snap handlers instead of Wai applications.
I always thought it was bad practice to actually do the build on the server. I thought people built locally then pushed a resulting binary in a container or a Nix expression or something else of that sort.
I tried to use purify recently. It doesn't work on Windows because it tried to shell out to tar or something. I tried to file an issue but it seems the purify repo doesn't have an issue tracker.
It is possible if a little clunky: runghc --ghc-arg=-fobject-code --ghc-arg=-O2 ...... 
Interesting! What's the benefit of using Snap instead of Warp here? 
https://github.com/haskell-servant/servant-snap/blob/master/README.md
Awesome... that's exactly what I wanted, thanks!
I'm a big fan of `acid-state` to start with, switching to `persistent` later if I find it necessary. Acid state is a really simple persistence layer that lets you stick to straight Haskell. And persistent is a nice and simple SQL library that gives me total control and lets me build my own abstraction layers. Alternatively, it can also be quite nice to just use `aeson` and have a JSON schema if you can get away with something *really* barebones, since it's by far the easiest to inspect. For an HTTP server, I tend to prefer Servant, but it's often totally unimportant. In a reactive WebSocket app, I'm entertained by the idea of using Reflex on the server, but I've yet to actually try this.
IIRC, it is typed solely as an experiment / to make compiler development safer (make sure you don't have type errors in your lower level representations). Most languages live well without a typed back end
For mutable dictionaries, can anyone explain to me why nobody got around to making an IO version of that? Maybe it exists, but a Google search does not turn up anything. In general I haven't been able to find any structures based around the IO monad, but I am not too familiar with Haskell.
Spock + Spock-digestive + digestive-functors + digestive-bootstrap + hasql + something like Spock-worker but with a redis backend Seriously - try out hasql. At first glance I disliked the interface, but now I love it and it's really fast! Frontend depends from project to project - I've done TypeScript, Elm, PureScript and GHCJS. Each has advantages and disadvantages... I've also built a project on servant because I wanted to really try it out in the real world and compare to Spock. It works great for APIs, but for server-rendered frontend nothing beats the simplicity and power of Spock-digestive+digestive-functors+digestive-bootstrap. It's so easy to get decent forms with so little boilerplate! My future stack might include servant for APIs and Spock for everything else. Time will tell :-) Disclaimer: I'm the maker of Spock :-)
Are there benchmark comparisons?
Sorry to hear that. I don't know you personally, but the haskell community wouldn't be the same without you. I wish that your surgery and the recovery go well. 
IMHO, Snap is much easier for understanding than yesod/warp in case you need to contribute to codebase, teach developer from groundup and just use straightforward functionality 
I agree that Spock is very nice! But aren't you the developer of this project ?
Didn't you forgot to add sudo swapon swapfile after the mkswap line ?
Best of luck Ed.
Yeah, I've added a disclaimer.
Ah...yeah, this is what Harrop was comparing. Actually, I did not think too deeply about [the article](http://flyingfrogblog.blogspot.hr/2009/04/f-vs-ocaml-vs-haskell-hash-table.html) when I first saw it a year ago and just assumed that that he must have been comparing the immutable map to the mutable hash table as the performance difference was so dramatic. Personally, I have been bit by Haskell's optimizations breaking in the past and in general, whether it is Ocaml, F# or Scala, they all have trouble attaining optimal performance with map,fold,filter and the like. Scala for example has the [for loop](https://issues.scala-lang.org/browse/SI-1338) issue that has been open for years. I've thought that a solution based on macros would work better than relying on inbuilt compiler optimizations, and just recently [saw this](https://arxiv.org/abs/1612.06668) posted on /r/programming which I thought was interesting. Also, I did some research and based on [this SO post](http://stackoverflow.com/questions/3058529/curious-about-the-hashtable-performance-issues/), the performance problems with Hashtables have been fixed. I wonder what Harrop was using in this more recent [2013 post](http://flyingfrogblog.blogspot.hr/2013/09/hash-table-insertion-performance-f-vs.html)?
Does anyone have recommendations for an affordable FPGA that works with CLaSH for playing?
While I have optimized quite a few Haskell programs (memory usage or wall clock), I only once needed an immutable data structure to achieve the required performance. I worked in the ST monad, and a mutable vector of unboxed Int. The performance was horrible compared to the equivalent C code (perhaps 50x slower?), but I just couldn't write the C code confidently. So, in my limited experience, Haskell is not good with mutable data structure performance. I also think that while it can be a showstopper in some specific application, it is a very minor pain point. [edit] it is probably highly useful to people that want to write performant immutable data structures that do magic under the exposed API
I wanted to use hasql but the documentation was sorely lacking in comparison to postgresql-simple, so I went with that instead.
&gt; This also allowed us to scale beyond a single machine. We've described this effort in the past... It's not entirely clear how you implemented the multi-machine software stack, but from what I can see from your YouTube video, you've rolled your own node communication stack to transmit `(state,input)` using sockets. Did you look at the TCP implementation of the `network-transport` API, for lightweight logical connections on top of real TCP connections (which is what I did when building the HdpH-RS library (Fig. 2 of [JFP'15](http://www.macs.hw.ac.uk/~rs46/papers/jfp2015/JFP2015-Stewart.pdf))) ? The Cloud Haskell API is fairly quick to pick up. Was there a reason you chose not build your prototype on top of Cloud Haskell?
While the hospital will have internet access (this *is* Boston, after all), I will be restricting it somewhat so he can get some rest.
Use [stack](https://docs.haskellstack.org/en/stable/install_and_upgrade/#ubuntu) (second option on the haskell.org website) and it will do the work for you.
The use case I have in mind is writing a reinforcement learning demo in Haskell with tabular states. I did this in F# before, and having discriminated unions and a mutable dictionary to store the value for the states was an immense benefit, so I am curious about the hashmap's performance. I'll run a little test comparing the two and post it in this thread later. Also, the deep learning algorithms I am interested in benefit greatly from memory caching and inplace mutation. On the GPU in particular, the cost of allocation is linear in the size of the allocated chunk and without an object pool, allocations can take up most of running time. So I am interested in how to do mutable object pools in Haskell. Because of the whole purity and laziness deal, I haven't considered Haskell a suitable language for machine learning and was originally intending to finish my ML library in F#, but what recently changed my mind is doing a Cuda compiler in it. It is not the compiler that is the problem (I did 3 different versions of it,) but what I could not figure out what to do is how to make a well typed interface to it, meaning for every different kind of lambda I pass into a Cuda module, I'd have to write a bunch of boilerplate similar how in Java you would have to declare a new class and write 30 lines of boilerplate for each Runnable instance. Sigh, and I was working for a year on it too. There is also Ocaml which has GADTs that I want, but its Windows support strikes me as even worse as Haskell's. Maybe I'll help debug those `ghc-mod` crashes as I go along...
It really depends on what kind of project you would like to do with the FPGA. Like if you want to do something with audio, you should pick an FPGA board that has an audio peripheral and the proper connectors. The VHDL/Verilog that CLaSH produces is fairly vendor-agnostic (although you should use the `-clash-hdlsyn Xilinx` to work around some corner case if you're using Xilinx FPGAs). Some FPGAs that I have personally used for smallish projects: * DE1-SoC (http://www.terasic.com.tw/cgi-bin/page/archive.pl?Language=English&amp;CategoryNo=167&amp;No=836) * SoCKit (http://www.terasic.com.tw/cgi-bin/page/archive.pl?Language=English&amp;CategoryNo=167&amp;No=816) * DE0-nano (http://www.terasic.com.tw/cgi-bin/page/archive.pl?Language=English&amp;CategoryNo=139&amp;No=593) * DE1 (http://www.terasic.com.tw/cgi-bin/page/archive.pl?Language=English&amp;CategoryNo=53&amp;No=83) Some FPGAs that I know others have used for their projects: * Mojo V3 (https://embeddedmicro.com/mojo-v3.html) * iCEstick Evaluation Kit (http://www.latticesemi.com/en/Products/DevelopmentBoardsAndKits/iCEstick.aspx) &lt;-- this is a really small FPGA though * Nexys 2 (no longer made, Nexys 4 (http://store.digilentinc.com/nexys-4-ddr-artix-7-fpga-trainer-board-recommended-for-ece-curriculum/) seems to be its modern day replacement) * Arty Artix-7 (http://store.digilentinc.com/arty-artix-7-fpga-development-board-for-makers-and-hobbyists/) * The papillo boards (http://papilio.cc/)
Well, for starters, Nix and Haskell are both pure functional languages (although targeting vastly different domains), so people interested in Haskell have a certain probability to be interested in Nix as well, and vice versa. As for the advantages: * Nix provides the entirety of Hackage as packages, so you can directly use Nix as a build tool for Haskell. * Stack provides direct Nix integration (to build with a Nix-installed GHC in a pure environment). Note that these refer to Nix (the package manager) and only indirectly to NixOS (the Linux distribution built around Nix). Due to its purity, NixOS is a good choice as an environment for reproducible, independent build, but this property is not confined to Haskell builds. Disadvantages are, well, purity: For development (as opposed to build), you usually want to have certain tools in your environment (e.g. ghc-mod for your editor). Setting up a development environment on NixOS is usually a bit harder than on other systems.
Would using `microlens` instead use less memory at compile time?
A great project. I've got a lot of interest in how to get FP languages down to FPGAs. When you advocate CLaSH to folk who are wanting to use FPGAs, or FPGA industrialists, how do you pitch it? 1. **"CLaSH produces smaller hardware designs that can be clocked higher than equivalent C or C++ programs via Vivado HLS"**? .. which would be extraordinary. 2. **"If you've got lots of existing legacy software written Haskell, then you can accelerate it for free using CLaSH"?** .. possibly at the cost of performance, versus re-writing your programs in C++. 3. **"Haskell is strongly and statically typed, ruling out a whole class of bugs that can be difficult to find in C or C++"**? .. which is true for software, is it also true for hardware? E.g. what does a runtime segfault look like on an FPGA? And doesn't Vivado HLS catch type errors quite early on (albeit caught at the Verilog level)? 4. **"It is faster to write Haskell than it is to write equivalent programs in C or C++, therefore it is faster to design hardware using CLaSH versus Vivado HLS"**? .. how can this be quantified? 5. **Haskell hides all FPGA hardware detail from the programmer**? .. this is definitely true. The C and C++ support in Vivado HLS *does* work without hardware pragmas, but as soon as you want good performance, the Vivado documentation strongly encourages the programmer to use HLS pragmas to guide memory implementation and pipelining. It's great if CLaSH can afford *not* to expose hardware pragmas in this way, whilst remaining competitive with C and C++ programs for FPGAs that do use pragmas. The *accelerating legacy Haskell code support for free* is a strong argument for using CLaSH. If a domain expert, say, in image processing, has to implement code from scratch, what argument would you put forward to advocate Haskell with CLaSH, over C++ with Vivado HLS ?
Could try msys2, comes with tar, and find.
[removed]
Well, to be fair, Clash is not an arbitrary-haskell-program-to-fpga compiler. It views Haskell programs as structural descriptions of a circuit, which has its advantages, and certainly also its disadvantages: - Advantage: full control over resource sharing and register placement, meaning if you do it right, you get the smallest, fastest, and lowest-latency, circuit achievable on the FPGA fabric. - Disadvantage: full control over resource sharing and register placement, meaning if you do it wrong, you get really large circuits that don't fit on the FPGA, or circuits with very long combinational paths leading to low operating frequencies. So my thoughts on the pitch ideas: 1. __CLaSH produces smaller hardware designs that can be clocked higher than equivalent C or C++ programs via Vivado HLS__ This is probably true, when both languages are used by a skilled engineer. Precisely because we have exact control over register placement in CLaSH. 2. __If you've got lots of existing legacy software written Haskell, then you can accelerate it for free using CLaSH__ That's definately not true... there are many aspects of Haskell that Clash doesn't support: http://hackage.haskell.org/package/clash-prelude-0.11/docs/CLaSH-Tutorial.html#g:19 3. __Haskell is strongly and statically typed, ruling out a whole class of bugs that can be difficult to find in C or C++__ I think there are aspects of Clash's use of GHC's type system that help, for examples * Clash' Vector type, http://hackage.haskell.org/package/clash-prelude-0.11/docs/CLaSH-Sized-Vector.html, can rule out many classes of off-by-one errors when dealing with lists/arrays/vectors * Clash' Signal type, http://hackage.haskell.org/package/clash-prelude-0.11/docs/CLaSH-Signal-Explicit.html, is tagged with its clock domain, meaning you can never have any accidental clock domain crossings. 4. __It is faster to write Haskell than it is to write equivalent programs in C or C++, therefore it is faster to design hardware using CLaSH versus Vivado HLS__ Well, _I_ can certainly write faster circuits using Clash in a shorter amount of time then I could do using either traditional HDL languages, or C/C++ + HLS pragma's. Indeed, the only proper business way to quantify this is with money. Can you write a maintainable fast circuits for less money than others can using alternative methods, our company is indeed making that claim. 5. __Haskell hides all FPGA hardware detail from the programmer__ I guess it is clear by now that Clash certainly doesn't hide the hardware details. For image processing, the argument I would put forward to using Clash over C++ HLS, is that with Clash you get full control over your pipeline meaning you can achieve the lowest latency and highest throughput. The interactive interpreter, and testing frameworks (QuickCheck, etc.), allow you to incrementally work from an initial high-level description to the ultimate pipelined design in a correct-by-construction manner. C/C++ HLS tools mostly always force you to buffer full frames before processing begins, which for certain image processing algorithms your latency is much higher than it needs to be because you have to wait for the frame to be completely buffered. That being said, specifically for image processing, Myrtle Software's image processing compiler, https://www.myrtlesoftware.com/case-studies/fpga/, which takes a functional DSL as input is probably a better approach, as it does abstract away from a lot of the hardware details. On a final note, where C/C++ HLS tools are A LOT better than Clash is interfacing with DRAM, as they allow you to completely abstract away from it using global and local buffers. Given how intricate DRAM interfacing is, this is a really big win for people using C/C++ HLS tools. However, if you want "ultimate" DRAM performance, you might have to think about starting to control the DRAM refresh lines, I have no idea whether modern HLS tools analyse DRAM access patterns to find a proper refresh schedule.
https://github.com/chrisdone/purify/pull/1
For the list monad, return creates a singleton list of the element passed, and bind is concatMap (that is, given a function that produces a list from the elements of a list, concatenate each of the produced lists in order). Some people refer to it as the non-determinism monad, but it might be easier to think of it as a different syntax for list comprehension for now, that's more general, and may be easier to work with. Anything you can do with list comprehension, you can do with the list monad. There's also the `MonadComprehension` extension, which extends list comprehension to arbitrary monads, working in the other direction.
HTTP APIs: Servant and its ecosystem. Just love its brevity and type safety; kudos to all involved Libs: postgresql-simple, transformers, hspec, Pipes (a personal favourite) Queues: Pipes? I use this for a processing system talking to AWS SQS at the moment; it's worked very well Front-end: still deciding what to do. I'm intrigued by Purescript but my heart's with Haskell so am tempted to GHCjs but am unsure what I can achieve on the frontend with it...
Yes. The `f` *is* different. That's precisely the problem. We want to tailcall the `f` we were given, because if `f` is recursive, we want it to tail recursively loop. By changing `f`, we won't tailcall the originally desired `f`, and we won't get tail recursion. This is the problem stated in the OP. If you're still having trouble understanding, I suggest you take a harder look at the problem in the initial blog post
I had a hard time picturing this so I went `Prelude&gt; ["foo","bar"] &gt;&gt;= id` and sure enough! Funky. Poses a new challenge for me though, all my monadic operators have been in the IO context so far and my code-reading part-of-the-brain has by now inadvertently been thoroughly trained to immediately associate I/O wherever I see them. Will take a while to unlearn and drive home to the easily-conditioned-brain that `&gt;&gt;` / `&gt;&gt;=` can be/do *anything*..
I upgraded Win10 to 14986 (slow ring) and gave it a shot. And I couldn't run `stack setup`, encountering the same problem described [here](https://github.com/Microsoft/BashOnWindows/issues/1479). Switching to 15007 (fast ring) resolved the issue, however `stack setup` took about an hour or two. Seriously? Looks like anything Haskell-related is dreadfully slow for now. There's a long way to go.
Ok, the test was not that difficult to make. Haskell code: {-# LANGUAGE ScopedTypeVariables #-} import Control.Monad import qualified Data.HashTable.IO as H import System.TimeIt type HashTable k v = H.BasicHashTable k v main = timeIt $ do (m :: HashTable Int Int) &lt;- H.new forM_ [1..10000000] $ \n -&gt; H.insert m n n v &lt;- H.lookup m 100 print v Output: C:\Spiral-V5-Haskell&gt;ghc -O3 hashmap [1 of 1] Compiling Main ( hashmap.hs, hashmap.o ) Linking hashmap.exe ... C:\Spiral-V5-Haskell&gt;hashmap Just 100 CPU time: 2.98s Fsharp code: open System open System.Collections.Generic let s = Diagnostics.Stopwatch.StartNew() let m = Dictionary() for i = 1 to 10000000 do m.[i] &lt;- int64 i printf "%d\n" m.[100] printf "%A\n" s.Elapsed Output: 100 00:00:00.3014356 Not shown here (as I am running from the IDE) is that the F# program is compiled on Release and with optimizations on for 64-bit architectures. The results do not look good for Haskell here - on my computer there is a 10x gap between Haskell and F# in favor of F#. After nearly ten years - at the start of 2017, it seems his point still stands. Using the options in [this post](http://stackoverflow.com/questions/3058529/curious-about-the-hashtable-performance-issues/) I tried compiling with `-rtsopts`, but with `+RTS -s -A2G` my computer ran out of memory and could not finish. The hash table is from the [`hashtables`](https://hackage.haskell.org/package/hashtables) package. I guess it is a good thing I am interested in Haskell for its unique type system features rather than its hash tables.
My intuition is it's basically a cross product. Simple use case: imagine we're iterating through a user's tweets and we're only interested in some particular `searchTags : [HashTag]`: searchTweets : [HashTag] -&gt; [Tweet] -&gt; [Tweet] searchTweets [] xs = xs searchTweets searchTags tweets = filter pred tweets where pred t = any (==True) $ (==) &lt;$&gt; searchTags &lt;*&gt; tags t The predicate above will check to see if any of the search tags is equal to any of the tags in a given tweet. EDIT: fixed case where no search tags are given
You safely get a () back for any weird type I've tried it on so far (including coercing functions), and there's no reason it shouldn't tail call, since unsafeCoerce has no run-time representation.
Not anything, it still has to be monadic ;) You'll grok the pattern eventually.
We have now written a (somewhat lengthy) blog post to answer your question. It's here: https://blog.grakn.ai/knowledge-graph-representation-grakn-ai-or-owl-506065bd3f24#.62t36es86
I think Yesod team coined WAI and it's a natural connection. I think production ready web-frameworks in Haskell are only Snap and Yesod, everything else is working, but not sure if applicable for project scaling. I mean middle size web-apps that developed over years. I know people using plain wai/warp but don't have information about projects to judge.
I'd recommend thermite or pux. Basically the Elm architecture in PureScript.
Indeed, as the website for the platform says: "Note that distribution-packaged versions are typically behind the current platform release. If you prefer to use the latest version rather than the distribution-packaged version, then you may use the generic Linux installer." This is the case with most things when installing from a distro package manager. The advantage is that packages are vetted and worked on to make sure they work in a given system. Ubuntu is a very good example, actually. They changed some gcc configuration and out of the box generic installs of any ghc before 8.0.2 (which was just only released) won't work without additional configuration. See https://ghc.haskell.org/trac/ghc/ticket/12755 for example. Also, for ubuntu specifically, a very good way to get any ghc version etc. through standard ubuntu tooling is hvr's ppa: https://launchpad.net/~hvr/+ppa-packages (and a new platform with 8.0.2, where the generic installer will work on ubuntu, will be released soon as well) 
So you are saying that it therefore only works on a restricted subset of `f` values? So: f = ... mapM_ f ... -- Might work or might not g = (() &lt;$) &lt;$&gt; f mapM_ g -- Will not work Because I guess at that point it is logically consistent. If a little surprising. 
It is unfair to cast framework complexity on its underlying application server. And I would be glad if Snap (and happstack) shedded their server and pooled resources with wai world instead.
This deserves a bit more emphasis: &gt; Note that these refer to Nix (the package manager) and only indirectly to NixOS (the Linux distribution built around Nix). You can run the Nix package manager on top of OS X or a linux distro like Ubuntu and get a ton of benefits with out having to switch entirely to NixOS. On Darwin this is especially nice, because it means you don't have to use Brew to install system dependencies. I develop using Nix on Darwin, but seamlessly deploy to NixOS servers. The nix expressions are portable between both platforms. So I only have to describe what I need once, and it works the same everywhere. In fact, right now I develop on Nix+Darwin, but run nixops and our hydra server on a Ubuntu+Nix machine, and then deploy to NixOS on EC2. And while this sounds like it should be a huge headache, it is hardly any different than if it was all NixOS machines.
I address some of these questions in [Haskell &amp; Nix - episode 0 - Why Nix?](https://www.youtube.com/watch?v=UNcv5XlIfu0)
I recommend: - [iCE40 HX8K Breakout Board](http://www.latticesemi.com/Products/DevelopmentBoardsAndKits/iCE40HX8KBreakoutBoard.aspx) (with about 8k logic elements -- small, but very possible to create real designs for). You can get it for $50. - Installing [Project IceStorm](http://www.clifford.at/icestorm/) for your synthesis toolchain. IceStorm is a free RTL synthesis/place-and-route setup for iCE40 FPGAs (a fancy, hardware-way of saying "It compiles Verilog to binaries"). It's completely open source and reverse engineered, based on the physical chips. The reason I recommend IceStorm is because it takes about 5 minutes to install, is very easy to use, and is extremely high quality software. The iCE40 is very simple as a design so it won't "overwhelm" you with a billion adapters/do-dads (how do I use ethernet on an FPGA???!) I think it's a good starter for an FPGA, without breaking the bank, and the software makes it very tolerable. The cheaper chip (HX1K-IceStick) with only 1k logic elements is only $20, and works just as well! (1k is a *lot* more limited however) [I have some notes on using Clash with the iCE40 here](https://github.com/clash-lang/clash-compiler/issues/145#issuecomment-241797811) One of the very nice things about the iCE40 series is that the USB adapter includes an FTDI USB-to-Serial converter you can leverage in your designs. That means you don't need anything but a USB cable to power it, and with a a TX/RX UART module on the FPGA, that same USB cable is used to talk back and forth (no wiring, etc, the pins are already there for you). Afterwords, I'd suggest something like a small Xilinx 7-series FPGA when you want to upgrade to a more advanced toolkit. Then you'll get the wonders of playing with tools like Vivado. I have the [Arty Board](http://store.digilentinc.com/arty-artix-7-fpga-development-board-for-makers-and-hobbyists/) on the way for my first Xilinx device, on this note. Some people suggest going with systems like Vivado/Xilinx first, because Vivado includes advanced features like "IP Catalogs" and "IP designers", which let you do flowgraph-based design (it's like UML for FPGAs, only it actually works) that can make it easy to synthesize "big" designs. There are no equivalent things like this for iCE40, etc. IMO, I think it's best to just stick with Verilog and to learn a lot of the absolute fundamentals first, rather than relying on the magical IP-builder tools to do everything for you. Once you can read Verilog and feel good with Clash -- then I recommend that stuff.
I've only used `acid-state` for hobby projects. It works quite well though. I think it makes a wonderful way of getting persistence out of Haskell very easily, with good performance. But it is a memory store, so you have to keep all the data in memory, and your lookups / updates are only as performant as your Haskell data structures. So as soon as these things become problems, you'll have to look into more tailored solutions. So I tend to think of `acid-state` as a solution for smaller problems, or as a great prototyping tool.
`foldMap` is a much more interesting solution to this problem. I've often wondered about the performance implications of everything being implemented in terms of `foldMap`. It's a much more natural function and it seems like there are cases where it can be a lot better.
That's good for Ed, but bad for the planet...
I've only skimmed it, as I'm already using MegaParsec, but it looks like a nice little intro. For me, 6 to 9 months ago this might have been useful. Honestly though, most of the stuff you cover I managed to get to grips with quite quickly, especially as there's little difference with Parsec at this level. The stuff I've struggled with is after this. Things like how to test parsers (I've landed on [hspec-megaparsec](https://hackage.haskell.org/package/hspec-megaparsec), and quickcheck), or debugging them (Megaparsec recently added [`dbg`](https://hackage.haskell.org/package/megaparsec-5.1.2/docs/Text-Megaparsec-Prim.html#v:dbg) which helps, but not if you hit an infinite recursion). Then you get to the higher level issues of what data types should parsing generate (ASTs, etc), and whether it's better to tokenise and then parse, or just do it all together. You could quite easily get enough subject matter for a whole book I think. I don't write this to be critical, but more to say that if you wanted to continue writing about parsers in Haskell, there's lots to explore.
Servant, snap, reflex, and a couple libraries gluing them together. It's an all-Haskell workflow with the frontend and server sharing types and API endpoints. I love it and I try to contribute to the respective ecosystems. These brought me into contact with nix and frp, which are really fun topics of study in their own right.
Nice, thanks!
The good news is that there's been real progress on running Nix on Windows with WSL. Excerpt from a [GitHub issue][nix-wsl]: &gt; I've installed Nix, did a normal build of GNU Hello and executed it. I then did a cross-compile from WSL to an .exe file &gt; And the brilliant thing is that an .exe will work within WSL so it's possible to execute Windows binaries within Nix builds! It's still brand-new and probably not ready for broad consumption, but the fundamentals are there. It shows Nix itself is usable on Windows—the practical question is how much of Nixpkgs carries over, how much needs some updates but could work and how much won't work at all. [nix-wsl]: https://github.com/Microsoft/BashOnWindows/issues/743
Best wishes, in all circumstances!
I think your question probably needs a little bit of re-framing. A list being a monad wasn't an implementation choice that somebody made. A list is implemented using linked lists. The same linked lists that you know in every other language. A haskell list is a monad^* because lists in all languages are monads, it's just in haskell there's a standard way of exposing the "monadiness" of the type. Nullable types in Java are monads, but I don't believe they expose a monadic interface. In Haskell they're called `Maybe` and do expose a monadic interface. So, to answer your question the list monad doesn't have an advantage over non-monad lists, because lists are lists and all lists are monads. Does exposing the monadic nature of lists have an advantage? Yes, as it allows lists to be worked with in some interesting ways. ^* I'm being a little imprecise here, but hopefully that doesn't get in the way of the point. A type in isolation isn't strictly speaking a monad. It needs the monadic operators defined too. 
You can find it in the [`search`](https://hackage.haskell.org/package/search) package newtype Search a b = Search { optimum :: (b -&gt; a) -&gt; b }
Thanks for feedback! Yeah this was meant for someone who is beginning parsing. My reasoning for this post was based on my own experience. Not knowing how much megaparsec diverges from parsec, I tried to follow the docs of megaparsec alone. And the tutorial in their github repo talks about lexemes and parsing a small programming language from the get go. I felt that parsing and knowing how to parse a programming language are two different problems, with the latter belonging to a more advanced category of tutorials. Testing parsers and do a data-backed comparison of multiple parser libraries is something that's already very interesting to me. Hoping to get to that once I'm able to complete my markdown parser to a satisfactory level.
I wasn't able to see that text on the Haskell Platform download page because my window was too narrow: https://github.com/haskell-infra/hl/issues/195 That GHC bug is only a problem if you build from source, right? You should be able to use the generic Linux versions of GHC 8.0.2 binaries without trouble. That PPA is what the minimal install option recommends for Ubuntu, but the OP got the Haskell Platform instead. 
I'm not sure if there is enough demand but you can send an email to `libraries@haskell.org`
Feel free to PM me if you want to bounce ideas
I stand corrected.
The fact that `hasql` can't do migrations automatically is the main reason I won't use it. Otherwise it'd be my first choice.
Just announce it.
&gt; frontend and server sharing types and API endpoints &gt; gluing them together how/what libs help you achieve this? This sounds like the dream!
I would just announce it. I appreciate when people announce new libraries here. It sometimes leads to good discussions about topics I'm not familiar with.
FWIW, among those Altera FPGAs, after looking around recently -- the DE0-Nano-SoC seems, IMO, to be the best bang-for-buck setup, at $100 USD for a dual FPGA/ARM system, and a few peripherials, compared to the SocKit &amp; co: http://www.terasic.com.tw/cgi-bin/page/archive.pl?Language=English&amp;CategoryNo=205&amp;No=941&amp;PartNo=2 Combo ARM/FPGA devices tend to be a bit more complex to maintain and develop on though (interfacing between devices via Xillybus/memory mapping, uploading, be prepared to understand uboot etc if you want to deal with/upgrade Linux), so a "pure" FPGA that can just be programmed over USB is what I'd suggest if you're new, I think.
ah gotcha. i didn't realize i needed to _evaluate_ the comment ;)
When you use the list monad it's convenient to treat `x &lt;- someList` as choosing one `x` out of a list of values. But the choice isn't made at random. Instead, each value from the list is chosen at the same time and the rest of the code is ran for each of them.
You are welcome to use https://github.com/jwiegley/hnix in your efforts. In fact, if you'd like to take charge of the project, just drop me a line.
That's interesting. I tried to ressurect nixpkgs on cygwin and ran into problems with almost every package (openssl, gettext, etc).
Is there a simple way of loading a whole `stack` or `cabal` project into `hint`, in the same way as `stack repl` or `cabal repl` runs `ghci`? I've tried to run `stack repl --with-ghc echo` to get the list of command line arguments normally passed to `ghci`, and feed them into `hint`'s `unsafeRunInterpreterWithArgs`. After removing the `--interactive` argument, which `hint` doesn't know, it seemed to work for my examples. It doesn't seem very elegant and robust, though ;-) *Update:* Created feature request issue on [github](https://github.com/mvdan/hint/issues/25).
I managed to figure out my issue with `cabal test`. Was a silly mistake. But as for the `stack`+`intero` stuff, it gets incredibly messy, and is somewhat unreliable. If you have Stack provision dependencies, it's easy; just turn on Nix integration to get GHC and it works perfectly. But if you use Nix for dependencies, you have to tell stack to stop trying to get any packages (by using `resolver: ghc-xxx`), and have `shell.nix` give you a shell with a GHC with all your dependencies. It *functions*, and Intero works *mostly*, but it's unreliable and a little buggy. [Here's my attempt](https://github.com/ElvishJerricco/nix-cabal-stack-skeleton). But anyway, what do *you* do for editing? Do you just use GHCid or something?
Hey again, thanks for the help earlier. Apparently my failed installation processes created a lot of corrupted files in C:/sr, that stack didn't know what to do with so stack install just crashed. Hopefully it will work now that I've deleted this folder.
I'd announce it both here and on the Haskell Cafe mailing list.
This is a great tutorial! I can't emphasize enough that declarative approach to system configuration and deployment has all the same benefit as what FP is to programming, if not more. 
Try using `STACK_ROOT` to install stack to `/mnt/c/stack` or another directory. This method installs Stack to a filesystem that doesn't have the same constraints and should work much more quickly. Edit: I used: export STACK_ROOT=/mnt/x/c/stack-lxss/ stack setup --allow-different-user Edit #2: It looks like in 15007 this is still very slow for some reason. I'm now very curious why, because I've had success using `/mnt/` paths to speed up installs for other purposes. I don't have time to diagnose now. Explanation follows: There are some issues where certain filesystem operations in the "virtual filesystem" (located in `%localappdata%\lxss\`^1) can be very slow. I suspect the issue is related to how they accommodate Linux ownership/permissions on files with alternate data streams, and there is some insufficient caching of the records. My own research shows that the Linux Subsystem for Windows is approximately as fast as native compiled code. (Tested with some of my own Rust and Haskell programs.) My microbenchmarks showed comparable performance with a Linux VM as well. There are two types of filesystems present in the Windows Subsystem for Linux: VolFs, which simulates a Linux-compatible root for permissions and ownership (that's in the `lxss` folder) and DriveFs, which does not, and for which everything your user account has permission for will apear to have the appropriate read/write/execute permissions. DriveFs volumes are mounted in `/mnt`. For a little more detail see their [blog post](https://blogs.msdn.microsoft.com/wsl/2016/04/22/windows-subsystem-for-linux-overview/) and subsequent articles. ^1 - This is why you should never, ever modify any files under `%localappdata%\lxss\` manually. You could strip alternate data streams inadvertently or leave them in an invalid state, as most file manipulation tools don't support working with them. 
Hey This is what my cmd looks like when running cabal install. It just freezes at this point: Microsoft Windows [Version 10.0.10240] (c) 2015 Microsoft Corporation. All rights reserved. C:\Users\toivo&gt;cabal install tidal Resolving dependencies... Configuring entropy-0.3.7... Configuring mersenne-random-pure64-0.2.2.0... Configuring permutation-0.5.0.5... Configuring vector-0.12.0.0... Failed to install network-2.6.3.1 Build log ( C:\Users\toivo\AppData\Roaming\cabal\logs\network-2.6.3.1.log ): Configuring network-2.6.3.1... bash.exe: warning: could not find /tmp, please create! configure: WARNING: unrecognized options: --with-compiler checking build system type... bash.exe: warning: could not find /tmp, please create! bash.exe: warning: could not find /tmp, please create! x86_64-pc-msys checking host system type... x86_64-pc-msys checking for gcc... C:\PROGRA~1\HASKEL~1\802E01~1.1\mingw\bin\gcc.exe checking whether the C compiler works... yes checking for C compiler default output file name... a.exe checking for suffix of executables... .exe checking whether we are cross compiling... Building mersenne-random-pure64-0.2.2.0... Building vector-0.12.0.0... Any thoughts? 
If you lurk the forum, and/or the IRC channel, you can always suggest your lib when you hear people asking about a problem it solves. Also try writing a blog post on how to use the libthat you can referr people to, and fill in the readme with a lot of examples.
Hmm. I would like the Debian packages for binaries written in Haskell to (continue to?) include global manpages. Some of those involve cabal in the build.
Damn, I am sorry to hear that. I've never met you, but I know you from your work. I'm afraid I cant think of anything else other than stereotypes: prioritize caring for your health, stay strong, and get healthy. All the best!
Your concerns are warranted - I'd keep expectations on Haskell vs. C numeric benchmarks in check at the current time. The numerical/scientific computing ecosystem has a ways to go as much as I'd like to see that furthered along. My guess is you're probably best off using haskell to take care of higher-level dataflow aspects and for the innermost computations either 1) if it's all linear algebra, using some sort of blas/lapack binding (eg hmatrix) or 2) if there's a lot of imperative computation needed dropping down to the C FFI. Some resources: http://www.datahaskell.org/ https://idontgetoutmuch.wordpress.com/
You might also want to look at J for doing numerical mathematics.
For reference, this is 's in the log file: Configuring network-2.6.3.1... bash.exe: warning: could not find /tmp, please create! configure: WARNING: unrecognized options: --with-compiler checking build system type... bash.exe: warning: could not find /tmp, please create! bash.exe: warning: could not find /tmp, please create! x86_64-pc-msys I have now switched over to the stack install method for easier bug tracking - I will create a new thread as it appears the issue is about installing any packages - the process simply freezes when it comes to configure.
You could always try http://hackage.haskell.org/package/inline-c-cpp ;)
I am earnestly curious here: Why would someone want a strictly typed language for front end work? JS is my first language, and although native Dom APIs are horrifying, honestly the language itself is really quite forgiving and easy to work with. It seems like most forrays into making JS make things more restrictive without addressing what I see as the core problem space - the Dom. Is there some usecase here that I don't understand? Or is this simply a matter of providing options that are more similar to code the author is used to dealing with, ala Node.js in reverse?
My uninformed guess would be the Debian build script should manually handle the manpage :/
I think you need about as many drugs as you need for Haskell. I picked up J quickly, it's actually not that complicated.
Going to try this. I really only wanted stack for the sake of intero. Nothing against stack but I need the nix features that let me manage non-Haskell deps. Thanks! 
I just use plain `vi`. That's why I haven't written anything about editor integration because I don't have experience with any Haskell editor plugins
If you're familiar with list comprehensions, it works in the same way: [x + 5 | x &lt;- [0..9]] &gt; [5,6,7,8,9,10,11,12,13,14] do x &lt;- [0..9] return (x + 5) &gt; [5,6,7,8,9,10,11,12,13,14]
A key question is -- is the issue with installing packages like `network` that have custom "configure" types that involve c libraries, or is it also with packages like say `microlens` that are pure haskell code with no ffi. That narrows things down quite a bit... One other thought I have is I noticed that you have `checking for gcc... C:\PROGRA~1\HASKEL~1\802E01~1.1\mingw\bin\gcc.exe` in the log. Now that looks like there's a problem with the generated shortname for the platform directory path to gcc. So my thought is _either_ there's some hidden characters in the config file that sets it, _or_ you could be using a cabal version that had a regression in handling those shortnames and you might just be able to replace the binary with the latest (you can download from here: https://www.haskell.org/cabal/download.html) and perhaps then `cabal install Cabal` to ensure that the library that custom configures get linked against the latest version of the `Cabal` library. (or perhaps that's a real shortname and I'm confused somewhere else.) Sorry you're running into so much weirdness!
The idea behind the typeclass is that if eventually I need to mock the database part for testing other parts of the system it would be easy to write a "fake database" instance for this purpose only. I will grant that it can be a premature worry and I may never actually do it. I guess I maybe falling for a kind of mind trap of always going for the most general type I can think of first, even for a trivial thing like this. I don't know... EDIT: Also, if I eventually want to change what database I'm using it seems a lot easier to just roll another instance of the typeclass.
Looks promising! A lot of my code probably could be structured in a way where the low-level stuff that runs billions of time can be in C, and then haskell can mesh it all together.
This is sad news! I hope that everything goes well and that you recover quickly. You are a wonderful person and community builder. I'm so grateful for your contributions and willingness to share with so many people.
What does this do?
I can't help more sadly, but I did notice there are many errors like: 2017-01-20 00:13:25.724822: [debug] Exception ignored when attempting to load C:\Users\toivo\AppData\Local\Temp\stack904\base64-bytestring-1.0.0.1\.stack-work\dist\b7fec021\stack-cabal-mod: C:\Users\toivo\AppData\Local\Temp\stack904\base64-bytestring-1.0.0.1\.stack-work\dist\b7fec021\stack-cabal-mod: openBinaryFile: does not exist (No such file or directory)
How long does it freeze for? It looks like it's trying to compile a library, which can take a while. Also, what does your CPU &amp; memory usage look like?
&gt; built locally then pushed a resulting binary in a container That sounds like a much worse practice to me. The CI/CD server should be checking out the source, compiling it, and running your tests. Building locally means it can't be automated and risks introducing environment-specific quirks. In practice this only needs to be done once per build agent though, since you can configure it to cache the Stack folder. (Of course if you're using Nix then it'll download compiled versions of the libraries instead of source, but the same logic applies.)
C++ gives you a control that you don't have in haskell, about the way your datastructures are layouted in memory, the possibility to drop back to assembly (well, intrinsict) when needed, a fine control on how/where memory is allocated and possible high scalability with a huge number of core. This being said, Haskell can do a lot, in a more safe, fun, productive way, So if you are looking for the last bit of performance, I think that C++ can't be beaten at that time. If you accept something slower (I cannot say for sure by how much, it may be 10% in some bench, and 5x in some others...), Haskell can be a solution. However, take this answer with a grain of salt, I'm writing C++ since 15 years, 10 years in the "high performance industry", in comparison I'm doing haskell since 2 years, just for fun.
Having the CI/CD server do the build is very different from having the production server do it. Can't imagine having a CI/CD server with only 1GB of memory.
I'm quite fond of [basic-prelude](https://hackage.haskell.org/package/basic-prelude-0.6.1/docs/BasicPrelude.html) - it focuses on fixing the main issues with Prelude (String, partial functions) and not doing anything too crazy. However, if a good type-class hierarchy is important to you, then you may find classy-prelude more to your liking.
Does this actually generate executable code or is it actually running an interpreter? I'm wondering if it would work on restricted environments like iOS where the program can't generate new instructions 
Probably because understanding why it works requires you to know that pattern matching failure in a monad will invoke `fail`, instead of throwing an exception as it does in non-monadic code, and also what the behaviour for `fail` is in the list instance. I don't have a problem with list comprehensions or other useful syntax, but someone new to the language is better served by a solid grasp of the fundamentals than code golf.
Are you able to shed light on what specific projects you would be working on at the Brisbane office? Or is it more of a "generalist" software engineering role?
Let me know how this goes (github issue would be best in case of problem)
For so many roles I see in here, I think: I'd apply in a heartbeat if I didn't have commitments that keep me in Brisbane... :) 
&gt; once I'm able to complete my markdown parser to a satisfactory level. On Github yet? Wouldn't mind starring/following this project..
You can do this with classy lenses, which works fantastically in conjunction with MonadState. I'll try to dig up an example later on. 
Just Googled and [found this](https://hackage.haskell.org/package/lens-4.15.1/docs/Control-Lens-TH.html#v:makeClassy). At first glance, it looks like it's exactly what I need!
I worked for CSIRO IT at the ANU campus a looong time ago. Its probably the best work environment in Australia for things computing-related. We held seminars on [functional programming](https://en.wikipedia.org/wiki/Standard_ML) long before most people who are reading this were born. The academic and work expectations are high.
It gets even nicer when you start nesting things. In that example, you only need to define `foo` to make an instance of `HasFoo`. If you had data Bar = Bar { _bFoo :: Foo , _bBaz :: Int } makeClassy ''Bar you can write instance HasFoo Bar where foo = bFoo which can be pretty handy. It means you can be working with `StateT MassiveAppState m` and be writing functions with constraints like `(MonadState s m, HasFoo s)` that will work with all `MassiveAppState` and everything in between. You can also use this with `MonadReader`, and you can use classy prisms with `MonadError` - see [here](https://gist.github.com/nkpart/c3bcb48c97c5ded6e277) for the awesomeness that brings.
Libraries that deal with extensible records are suitable for that, like [vinyl](https://hackage.haskell.org/package/vinyl), [record](https://hackage.haskell.org/package/record) and others.
I dislike the magic that is happening behind the scenes in makeClassy. I tend to write those type classes my self if i need them. so i dont have to guess what they might look like... We shouldn't need to guess as in https://gist.github.com/nkpart/c3bcb48c97c5ded6e277#file-err-hs-L25 EDIT: removed grammetical hiccup
[removed]
I came to say exactly this. The name `UndecidableInstances` sounds terrible, because it sounds like it will *always* be undecidable. In reality, I don't think I've ever had anything that was actually undecidable. It also sounds like GHC will just randomly pick an instance because it can't decide. This is also not true, but if you're not familiar with the formal meaning of decidability, then it's understandable how people could get confused.
Heh, I'd mostly finished my application before you even posted the roles here - it looks amazing. I've seen other roles on /r/haskell that have looked amazing but that would require me to move, which isn't on the cards for me at the moment. 
I'm sympathetic to the idea behind Vinyl, but suspicious of how usable it is in practice (how nicely does it play with Aeson deriving, Binary, etc?) Is the [record documentation](https://hackage.haskell.org/package/record-0.4.2/docs/Record.html) displaying oddly? It doesn't look like normal hackage docs to me.
Performance shouldn't be a problem. After all, Python is slower as haskell, and is used often for numerical computing. Haskell can be made almost as fast or sometimes even faster than C. In my library for doing arithmetic on Bernstein Polynomials, I use rewrite rules to convert to and from the scaled Basis. Redundant conversions are optimized away, and most operations reduce to a convolution. The convolution is written in a low level way, with mutable vector updates, unrolled loops, etc... It looks more like C than haskell, but it's safely hidden in the abstractions. In C++ it would need to do the conversion for every operation (or require tedious manual conversion). Disclaimer, I haven't actually compaired it against C. There are papers demonstrating how using rewrite rules can outperform C. for example: https://www.microsoft.com/en-us/research/wp-content/uploads/2016/07/haskell-beats-C.pdf More of a problem is the lack of libraries and standards. There are many libraries out there, with incompatible representations. In Python or Julia, you can usually be sure that any third party will use the same representation for Matrices. They also have a fairly complete library of numerical algorithms, where haskell lacks many basic functions. tldr: haskell is a great language for numerical computing, but lacks libraries and standards.
I think [data-has](http://hackage.haskell.org/package/data-has-0.2.1.0/docs/Data-Has.html) is exactly what you asking for.
It seems that yes: [aeson](https://hackage.haskell.org/package/vinyl-json) and [binary](http://stackoverflow.com/questions/14020491/is-there-a-way-of-deriving-binary-instances-for-vinyl-record-types-using-derive).
The `project` function lets you reorder fields easily, at least: &gt; project (#bar := "hello", #foo := 3) :: ("foo" := Int, "bar" := String) (#foo := 3,#bar := "hello") But yeah, it's a disadvantage.
You can upload `haddock` documentation to Hackage using `cabal haddock --for-hackage` and `cabal upload --doc`.
I'm awared of lens based solution, but it's definitely too heavy for me. I just want `HasLabel` equivalent for tuples, so `data-has` works nicely for me. Overall if`makeClassy` suits you, you may also want to keep a eye on [OverloadedRecordFields](https://github.com/ghc-proposals/ghc-proposals/pull/6) proposal, since they belong to the same design space.
halogen is starting from zero, while thermite is just an addition to react, so you could use thermite where you're comfortable and shell out to react when you need to
This. Is. Not. The. Point. Of. Stack. Nix. Integration. This is written in the docs, which you clearly haven't bothered to read if you come up with "The only thing it does is use Nix to get GHC instead of letting Stack download GHC its normal way", the point is to have Nix handle your NON haskell dependencies, not to provide another backend to download/store haskell packages.
&gt; After all, Python is slower as haskell, and is used often for numerical computing. Although I agree with you on Haskell being "fast enough" for most applications, I think it's important to note that none of the numerical Python libraries I know of are actually written in python, but usually just wrappers for heavily optimized functions written in e.g. Fortran. The performance of pure Python would probably terrible to work with in numerical applications [edit] Quote fixed
I think `data-has` will work well with ORF. `data-has` for targeting nominal records, ORF for the record fields. 
&gt;I'm sympathetic to the idea behind Vinyl, but suspicious of how usable it is in practice (how nicely does it play with Aeson deriving, Binary, etc?) Not sure, but here's a library for using vinyl with JSON: https://github.com/tbelaire/vinyl-json/blob/master/src/Data/Vinyl/JSON.hs 
I've ran into loops plenty of times. My current gripe with anything that affects instance resolution is that there's no way to specify flags like this on a per-instance basis. Only on the whole module.
That's quite true. Haskell isn't worse in this respect, since writing wrappers is relatively easy. It may be a good strategy anyway, since those underlying libraries have proven their worth, and are usually optimized to the last bit. It would avoid duplication of effort.
normally yes, but as this is a package candidate and i'm using stack i dont really know how to do this.
&gt; papers demonstrating how using rewrite rules can outperform C That paper says - "[o]ur ideas are implemented in modified versions of the GHC compiler and vector library". Have those ideas made it into the current GHC compiler and libraries?
Haskell can run code like this: ones = 1 : ones take 5 ones you can't run this code on a strict language. It will infinitely repeat calculating `ones` before it gets to the `take 5` part. so that's the way that lazy code is incompatible with strict implementations. Now consider strict code on lazy implementations: println("foo"); println("bar") If `println` is an implicit (non-monadic) side-effect, and we don't use its result, how does the runtime know which order to execute these effects? In Haskell, it probably wouldn't execute either of them at all! That's the reason that strict code can't be used on lazy runtimes: lazy evaluation is free to just not evaluate something if you don't use its result, or evaluate it in a different order than it's defined. Now, if you are writing strict code that uses monadic effects, which is exactly what purescript does, then the order of execution of side-effects is encoded into the structures. So you can probably implement a lazy runtime for purescript that would execute a good amount of its code correctly. But there are still probably subtle cases where things will go wrong (especially if purescript has anything like an `unsafePerformIO`). I may not have explained it very well; perhaps someone else can take a crack at it :)
The trick is finding a good enough long series of comics that I haven't read.
FOUND IT! It's Avast stopping it for some reason!!!!!!!!!1 NOW IT'S RUNNING Would never have found this without the process monitor.... thank you!
You might be able to deduce it, or something similar, from this haskell cafe message https://mail.haskell.org/pipermail/haskell-cafe/2007-December/035800.html It seems the main point of the example was that we can supply different "interpreters" to run a single game. This is by now completely conventional in the literature on `Free` `FreeT` and earlier `operation` and so on. 
Is it different than having progName :: String progName = ... ? 
It's different. It adds a string *argument* to every definition contained in the block and names them progName without you having to write the pattern yourself. 
Oh, ok, got it. I guess it could be useful, but I think it's dangerous to have hidden arguments, or at least bad practice. 
The list monad is mostly useful when you allow `MonadPlus` methods, like `guard`. This allows you to specify conditions on continuation. For example, the following is a list of all natural numbers up to a given count: naturalsTo x= [1..x] I can express "give me all pairs of natural numbers up to x" like: naturalsPaired n = do x &lt;- naturalsTo n y &lt;- naturalsTo n pure (x, y) But that gives us a lot of `(1, 1)` and `(2, 2)` entries. So we want to omit entries where that is the case, and we do that by introducing a `guard`. `guard` only allows the process to continue when the condition is `True`. naturalsPaired' n = do x &lt;- naturalsTo n y &lt;- naturalsTo n guard (x /= y) pure (x, y) This pairs up without (1, 1) etc. Let's solve some project euler. [Problem 9](https://projecteuler.net/problem=9) is "special pythagorean triplet". The problem asserts "There exists exactly one Pythagorean triplet for which a + b + c = 1000. Find the product *abc*." Let's find it with list monad! First, we start with all the natural numbers up to 1000, since it can't be larger than that. `c` is the largest number, so we draw it first. Then we grab `b`, which must be less than `c`. specialTriplet = do c &lt;- naturalsTo 1000 b &lt;- naturalsTo (c - 1) a &lt;- naturalsTo (b - 1) Now, we have `c`, `b`, and `a` in scope, and we're satisfying the property that `a &lt; b &lt; c`. Now we want to ensure that `a^2 + b^2 = c^2`. specialTriplet = do c &lt;- naturalsTo 1000 b &lt;- naturalsTo (c - 1) a &lt;- naturalsTo (b - 1) guard (a^2 + b^2 == c^2) Finally, we want to ensure that `a + b + c = 1000`. specialTriplet = do c &lt;- naturalsTo 1000 b &lt;- naturalsTo (c - 1) a &lt;- naturalsTo (b - 1) guard (a^2 + b^2 == c^2) guard (a + b + c == 1000) And then we can return the product: specialTriplet = do c &lt;- naturalsTo 1000 b &lt;- naturalsTo (c - 1) a &lt;- naturalsTo (b - 1) guard (a^2 + b^2 == c^2) guard (a + b + c == 1000) pure (a * b * c) So this is a really natural expression of the problem. It's also kinda slow since it just enumerates all of the possibilities and selects them, so performance-wise it isn't great.
Cool! The query language reminds me of [jq](https://stedolan.github.io/jq/). 
`IsString` should *not* [fail at runtime](https://hackage.haskell.org/package/aeson-quick-0.1.1.1/docs/src/Data-Aeson-Quick.html#line-42). Instead, why not use a quasiquoter? That way you get compile time failure that a structure isn't right, rather than a runtime error. What advantage does this bring over lenses?
hah, wow, what an ordeal!
Well, from a theoretical point of view, the right hand expression has a free variable not bounded by the left one.
You can essentially emulate this with named parameters, no?
That changed with respect to `OverlappingInstances`, maybe it'll change here to?
The variable isn't free, it is bound by the enclosing module. The same thing happens whenever you have nested scopes, such as when you use `let` or `where`. foo x = bar 42 where bar y = x + y In the above example, the right-hand expression `x + y` has a variable which is not bound in the `bar y` left-hand side, and it's fine.
Not exactly true. Yes, in general you cannot make lawful "lens product". See http://stackoverflow.com/questions/36521208/how-to-make-the-product-of-two-lenses But if you are ok to do it (as what happens in `aeson-quick` if you write `val .? "{a,a}"`), `val ^. lensProd (key "a" . _JSON) ("key "b" . _JSON) :: (Int, [Int])` *EDIT* And above doesn't even work, because `key` is `Traversal`. Which makes you ask question, what is the result of `val2 .? "{a,b}" :: (Int, [Int])` when the `val2 = {"a" : 1 }`. IMHO that's the power of `lens`, it makes you ask yourself right questions. FWIW, making something like `magicLens :: AesonMagicLens a =&gt; String -&gt; Maybe (Lens' Value a)`, and `Traversal` would be cool exercise, if it can be done!
I'll be there!
I really like this. I think the correct way to put in a type sinature, is right at where it is declared. I.e : context fixes var :: var_type in Though making that work with multiple arguments is a bit awkward. Maybe the lambda form would be better: context fixes \ arg1 arg2 -&gt; _ :: arg1_type -&gt; arg2_type -&gt; _ in I also like changing the keywords to "fixed context [blaw] for" slightly different intuition, but I like it. Or we could do it the way Coq/LEAN does it section parameter arg1 :: arg1_type parameter arg2 :: arg2_type f :: f_type f x = ... g :: g_type g = ... We need the "parameter" keyword or something to distinqish types declarations with a missing body from section arguments. (Maybe we could do something like the above but just use the module namespace as the 'section'? so something like: module Blaw [export_list] where f z y = ... arg1 ... arg2 module local arg2 :: arg2_type g x = .... arg2 ... f ... arg1 module local arg1 :: arg1_type ) (Man my fingers really want to type "modual".)
That's a great explanation, one thing I will say is that you don't actually need `MonadPlus`. You only need `Alternative`, `guard` has type `Alternative f =&gt; Bool -&gt; f ()` for example. I think `MonadPlus` comes in handy for things like filtering already constructed objects, such as `mfilter :: MonadPlus m =&gt; (a -&gt; Bool) -&gt; m a -&gt; m a`.
Megaparsec's author here. Of course I'm biased, but I think there is no reason to stay with `parsec` except when you're working with legacy software and you don't have the time to migrate. There are things that Megaparsec does better, but is there anything Parsec does better than Megaparsec? If there is, report it to Megaparsec's issue tracker, we'll discuss, I do not ignore any issue. I know that the number of people choosing Megaparsec over Parsec is growing steadily, I can also see that more and more libraries start to depend on it. Some of reasons people choose Parsec over Megaparsec might be: * **People don't know about Megaparsec**. Still possible. * **General inertia**. Parsec is well known, it's even mentioned in books, surely it's better. * **Parsec is old and thus proven by time, it's much more mature and reliable**. Can't be more wrong. It doesn't even have a test suite. I invested a lot of time and effort getting Megaparsec 95% coverage using mostly generative testing with QuickCheck (and Hspec). Since beginning of the project, no regressions happened, and only one bug (after initial release, for functionality that didn't have tests at the time and was later deprecated) was reported. Etc. No technical reasons I know of. By porting your library to Megaparsec , you just instantly make it higher-quality, why not do it? Immediate gains are: better error messages and handy testing. See [Megaparsec's readme](https://github.com/mrkkrp/megaparsec) for more info. 
Agda modules and the proposal both support multiple arguments. What do you mean by "arguments of another type"? Do you mean that you want context fixes x in foo :: Double foo = x bar :: Int bar = x to expand to foo :: Double -&gt; Double foo x = x bar :: Int -&gt; Int bar x = x As opposed to having a fixed type for both occurrences of `x`?
That's not consistent, I mean for `a-&gt;b` or `F a`, does it get infered from the use of the variable?
Curious stuff! Thanks for the detailed outline. I'll put this in my way-overflowing bucket of "Haskell ecosystem's countless cute syntax plays that allow sub-performance approaches to solve problems *the neat-o way* I have never ever encountered in the last 19 years of lame-stream programming but sure keep hoping I finally will any day now" ;)
This is actually the whole reason that distros like Ubuntu/Debian/CentOS etc. exist. You only have potentially breaking changes when a major release is done. If those distros have too slow of a release cycle, I'd suggest Fedora as it sort of sits half way between arch and ubuntu on how new the packages are. I don't think nix will help you unless you are running nixOS as your system would not be using the libraries that nix downloaded for you. Be warned though that nixOS is not for the faint of heart, there is a steep learning curve.
If this was sugar for anything, I agree it would better be sugar for implicits. But I also agree with others that implicits alone seem to do the job fine here... is there some drawback detailed elsewhere that I missed?
Awesome, that's gonna be in the next commit :)
Sounds amazing. Good luck filling the role 👍 Would love to move down under and work in functional programming. 
Interesting trick, renaming the arrow. I will add it to the alternatives in the proposal.
This is actually why I moved to stack + ncurses5-compat-libs. Granted, It's only been two days since I've switched over to this setup, but updates are faster and less scary (no warnings about unregistering haskell modules, for instance).
yeah, backpack subsumes this, right? (but probably less conveniently)
@dailaing: Do you know if Nix is able to handle low-level dependencies like video card drivers/openGL libs and such?
&gt; what is the result of `val2 .? "{a,b}" :: (Int, [Int])` when the val2 = `{"a" : 1 }` It's `Nothing`, for this case you have `{a,b?}` which gives you Maybe (Int, Maybe [Int]). &gt; FWIW, making something like magicLens :: AesonMagicLens a =&gt; String -&gt; Maybe (Lens' Value a), and Traversal would be cool exercise, if it can be done! Well I am [somewhat on the case](https://github.com/libscott/aeson-quick/blob/master/test/Test.hs#L121), unfortunately my Lens knowledge fell a little short of making a `Traversal`! I also considered implementing aeson-quick in terms of lens products, it may be possible to go implement `(FromJSON a, ToJSON a) =&gt; Structure -&gt; Lens' Value a`, but I had my doubts that it would have been worthwhile. The lens products would likely not achieve the same performance or flexibility.
Yes (for both Nix the package manager and NixOS the operating system)
The big difference is that in python those wrappers are written and extremely battle-tested / mature. Also, with any new data/numerics/scicomp innovations that comes out, bindings are available very quickly. In haskell there's hmatrix, which is an okay starting point, but nowhere near as mature as the numpy/scipy ecosystem and doesn't really leverage the haskell's strengths either.
I'm not personally looking for a new job, but that seems like a good thing to mention on the job ad, especially if you explicitly remove the education requirement.
@dalaing: In what sense have you had trouble with opengl libraries and sdl2?
@Tekmo: Do you know if there are/should be any performance hits when using Nix to manage low level dependencies like graphics card drivers and openGL libs? And is there any reason Docker would be better here if this is my primary use case?
[removed]
I don't think you can do exactly this with the ML module systems, but with functors and first class modules you get close. 
&gt;We're after the best and brightest Dang.
My thoughts are with you and your family. I'm so glad the prognosis is so good. 
If I may make another suggestion, I would say start breaking your code into multiple files/modules. I personally like to have a Types.hs module where I simply define types. Functions on those types are put in other modules. You could separate render data like game_map and sprite_list into RenderData.hs and functions like intensityToChar in Render.hs. (That last sentence was an idea, not a suggestion. You know how your code works, you can come up with your own aesthetics of defining module boundaries.)
ADTs are amazing, I constantly find myself missing them when writing in other languages
Sorry, https://www.youtube.com/watch?v=kzXXcr8TyJY
This.. So much this...
Perhaps because it's a role you might expect to use to transition into doing a PhD, in which case the pay is pretty good. I'm not keen to take a large pay cut for it right now, but I've still got a few years left in my masters; in two or three years, this sort of role might be just right for me, despite the salary.
It's sad but pretty interesting, that a human often sees something he/she does not understand, and subsequently rejects it *by* assuming that it's bad, useless, whatever. I don't need to care about evaluation order, you say? What??? That's what I do for *life*, lazy evaluation sucks. I can use algebraic data types. How are they compiled into machine? Am I not supposed to care? How can I even *program* with that? And you see one programming problem geared towards imperative languages, *because* you're geared towards imperative languages. You see Haskell's solution of 'don't do that'. You're not convinced. You may think Haskell is useless here (it solves *none* of my problems), but that's *not* the correct way of seeing a programming language. I'm not saying that Haskell is good for everything. It can't be. It's all about having an extra set of tools in your pocket. You just simply can't say a wrench is useless because you can't use it to hammer nails. Somehow. I don't know for sure, but this misunderstanding of programming language features is everywhere, I think. &gt; “Look, I used a monad! And defined my own type class for custom folding of data! Isn’t that amazing?“. “What does it do?” “It’s a CRUD app”. I *think*, and with strong faith, believe, that many, many object-oriented programmers are doing the equivalent with 'classes', 'interfaces' and 'design patterns'. He/she could well be in production, who knows. Edit: equivalent ~~of the same thing~~
imho ⅋ (pronounced par) is where linear logic gets interesting.
If we're unsure which level to apply for, should we apply for multiple roles, or would that be a no-no? I can get stuff done in Haskell, and I'm not exactly at the beginning of my career, but I'm anticipating the standards are going to be quite high and I'd rather be a part of the team than not.
There is **absolutely nothing** curious about Go's popularity. I think this dismisses a strongly contributing factor. The network effect. _Google_ created Go, like _Apple_ created Swift. Both of which, calling a spade a spade, are both two "who cares?" languages technically speaking that you wouldn't look twice at if you saw was backed by a slowly growing community the size of Python's 15 years ago. _Sun_ (now Oracle) back Java (and the JVM). _Microsoft_ created and back C#. Ericsson created Erlang. The _web_ backs JavaScript. It's not about cool logos on web sites. It's about backing (and trust). (And the reason people try to make good web sites is to give the impression of backing.) When a big company backs a technology people are--reasonably--inclined to trust that the technology (1) addresses some kind of problem in a practical way, (2) scales, (3) is going to be supported and last a long time, to make it worth investing in. Why are Scala and Clojure popular? And transpilers to JavaScript so in vogue? Because even though developers know they dislike Java or JavaScript, the JVM and the browser are the "backing". Even a colleague once replied to me "but _Facebook_ use PHP, so it can't be that bad..." Meanwhile it took 20 years for Ruby or Python to taken seriously, and they're BASIC-with-classes! They don't even bring something novel! The choice filter for any kind of professional adoption of languages usually starts with "what's the backing like?" Remove all the languages below a certain threshold. That leaves us with the languages I've written about in my first paragraph. That's my choice. Languages like those of Ruby and Python have to make the slow climb used by heroic mavericks. (Though some say Ruby gained its popularity via the wildly popular Rails web framework. I think that's called a "killer app".) Echoing what's written in the article, do any of the first and second paragraph languages really improve on what came before it? Not really. That's kind of the point. What's the standard recipe for language adoption? Take an existing successful familiar language. Give it strong backing. Add a small incremental improvement to the old language. Give it a slight facelift. Better open the gates because a flood's coming your way! Haskell isn't in either of those two groups, because it _does_ bring many novel alien things (pattern matching, stronger types, purity, laziness -- downright shocking) all in one go, and it _doesn't_ have any kind of backing. I have never expected Haskell would ever reach some kind of substantial level of adoption, it doesn't satisfy even the basic criteria for a popular language. I'm okay with that. Like SPJ says, the industry slowly, slowly leans towards better approaches over time. 
Yeah definitely
Great job covering the hole in intermediate Haskell tutorials, I'm really enjoying the blog.
Disagree with Haskell being "bad at programs with a lot of IO".
Doesn't Microsoft back Haskell? Though mostly so they can poach its best features for C# and F#?
GHC has, deep within it, a bytecode of some kind. The documentation on it is somewhere between "extremely sparse" and "nonexistent". One of the operations involved is something called `newBCO#` in GHC.Prim, though, I'm pretty sure.
The only sensible interpretation of that is 'bad at imperative programs'
&gt; I think, and with strong faith, believe, that many, many object-oriented programmers are doing the equivalent of the same thing, with 'classes', 'interfaces' and 'design patterns'. He/she could well be in production, who knows. There's two rules of thumb I see in OOP 1. OOP is very nice and elegant in theory (as is anything which is taught to beginners through the lie of "it models the real world") 2. OOP is almost always really fucking ugly, unmaintainable, and horrific in reality.
[removed]
Robert Harper (who also complains that Haskell's laziness makes reasoning about space usage difficult) says "[Haskell is the world’s best imperative programming language; I’m only half (if that much) joking](https://existentialtype.wordpress.com/2011/03/16/what-is-a-functional-language/)". Funnily enough, I always thought it was Simn PJ who said that. By reflecting side-effects in the types, we are *encouraged* to separate pure from impure which is hugely beneficial from a testing and reasoning point of view. 
Ooh that `const` is nice. I didn't want to go for `&gt;&gt;` because that won't work for general `(a -&gt; m a)` functions. But I do believe that using `const` for a special type of function would seem a bit less general, but anyway that's cool.
correctly building all foreign dependencies with a `stack build` is very useful.
&gt; what it's currently designed for isn't very useful i'm excited for cabal's proposed full nix integration, as i use nixos, but i'm also reasonably satisfied with stuff like stack's weaker but *existing* nix integration. 
Ah. Yes, Stack's Nix integration is certainly sufficient. It's just not what I was hoping for.
Because we're keeping it a secret. I'm okay with that. I like having a secret weapon. Practically... it's not surprising that Haskell isn't popular because it's built, at the base level, on an unpopular model that's built on another unpopular model that's built on *another* unpopular model. It's entirely predictable that it would be unpopular. What's actually strange is that it's edging out of being weird and strange. Slowly. Sort of. I mean, I went to university at the nerdiest university in my country, ended up in the most esoteric niche of that university, and there were still only about 5 people who had heard of it including my professors, but... I've lost my train of thought.
&gt; There's two rules of thumb I see in OOP "OOP" is basically a pattern wherein you "tie the knot" around a record of closures so that the closures can all take a `self` argument that they will dispatch through. This in turn allows you to make "derived" versions of the data structure and make sure that mutual calls inbetween these closures will always go to the correct, 'derived' version of your code. It's a cute trick, but the real rule of thumb that nearly always applies to OOP is "YAGNI"!
&gt; If Haskell is so great, why hasn't it taken over the world? Quite simply, because some parts of Haskell - most notably the runtime, and even the compiler to some extent - are, shall we say, *not so great*. Of course, work is underway to address these concerns, at all sorts of levels. You're welcome to help!
Nice little conference. I attended last year and I really enjoyed it.
If it's a desktop app, you may want to consider [flatpak](http://flatpak.org).
The types are isomorphic, yes, but that does not mean you can use them the same way in your program.
When you want to repeat `m ()`, you can use the `replicateM_` function from `Control.Monad`: `replicateM_ :: Applicative m =&gt; Int -&gt; m a -&gt; m ()`
Thanks! So sort summary: all projects dep'ing on parsec should migrate over to megaparsec. :) I'll give it a go when i have the time.
It is interesting, but tbh, I don't understand it. It's always presented in the classical linear logic, where - there id and cut rules are different and/because - we also have linear negation, and ?-exponential. As wikipedia says: &gt; Multiplicative disjunction (A ⅋ B) is more difficult to gloss in terms of the resource interpretation, although we can encode back into linear implication, either as A⊥ ⊸ B or B⊥ ⊸ A. So my confusion is because I have no idea what kind of "programming languages" we get from CLL, via Curry-Howard. If there is some good paper / presentation on it, I'd like to see it. IIRC Philip Wadler does some research in that field. Also I remember [Ling](https://github.com/NP/LING) presentation from [haskellX 2016](https://skillsmatter.com/skillscasts/8734-ling-a-language-with-predictable-fusion), but I hadn't time to think about it properly.
I, personally, find static typing a great programming aid. Lisps tend not to have that.
What is it about the runtime and the compiler that you think is not so great?
Don't do this. And the fact that you can do this doesn't make Haskell bad. It gives you a choice. It's just a bad one here.
Hasn't Haskell taken over the academic PL world? Isn't that what it was designed precisely to do? Everything else is a bonus.
That's effect not side-effect. There's nothing 'side' or 'impure' in `IO`. It's important to note that the effect *is* the value, not a side product of evaluating the value. That makes a *huge* difference. And the lack of imperative structures makes imperative programming tiresome and assembler-ish in Haskell. But you *should* be assembling pure functions to get effects, right?
Not only that, but it also means it's possible to have "different kinds" of "side effects" – mutation (`State` and `ST`), loops (`[]`), read-only configs (`Reader`), logging (`Writer`) – and each of these can have its own unique control structures that may not work with some of the others. In a language where all these side effects are mushed into one you lose the ability to write control structures that don't work for *all* of them.
[Lumiguide](https://lumiguide.eu/) from Nijmegen, Netherlands, is one; they rely on Haskell rather heavily, they even use GHCJS for their web frontends.
Not quite. You have to trick Stack into not managing Haskell dependencies with `resolver: ghc-xxx`, and then you have to use a `shell.nix` specially designed to abuse that. I've done that before, and it works 90% of the time, but completely blows up the rest of the time.
[SQream Technologies](http://www.sqream.com) from Israel. GPU powered big data database, with a Haskell parser/compiler core
Ok then. I have just added the `resolver: ghc-xxx`. Though it seems to me that with a classic `lts-xxx` resolver stack will go and download a plan but then it will use haskell nixpkgs (and not stackage). 
I worked at a company that uses F# as their language of choice, but before they settle on using F#, they did evaluate other functional languages (erlang, haskell, clojure...). Why did they choose F# over Haskell ? Short answer: tooling Long answer: Haskell is a very sound and consistent language compared to the others. On the other hand, consistency on its own is hardly a selling point, no matter how advanced it is. The real factor in nowadays world is productivity, or as they like to call it, how fast can you put a product into the market. For that, tooling is of essence. The lack of native IDE for haskell, the lack of debugger support (being lazy doesn't help, but is feasible) will definitely put the language out of favor. That factor will make any big corporation choose the lesser evil (Scala, F#, Clojure...). In the case of this company, they wanted strong typing, and the only viable alternative was F#, back then scala wasn't as mature as it is today. So yes, their choice for using F# was the ability to debug, the interoperability with a vast choice of libraries and the support of a larger community. 
Systor Vest in Norway. Http://systorvest.no 
That page is chronically out of date and poorly curated. I personally do not recommend using it. It's not a good resource and it won't be unless somebody takes the lead to consistently keep it updated. (Not that I'm volunteering :P.)
Does the post really claim that, though? I understood it as saying that (paraphrasing) "the gains provided by Haskell are not as large in programs with a lot of I/O", which, though certainly debatable, is a far less outrageous claim.
&gt;I find that comment particularly funny based on your user name. Is this a reference to Novaya Zemlya? Is it a tectonic peculiarity?
I disagree. The title serves well to illustrate the ambiguity and arbitrary opinions of the article itself. 
&gt;Surely the future of programming looks different The joke is on you. There's no future for (human) programming. Precisely because the most efficient way for humans to program is so ... human centric. Once machines start writing programs we will be hopelessly outmatched with our primitive hairless apes abilities. And that day is not far away. 
I'm not sure why people are getting all defensive. The author strongly implies that Haskell is the best at building languages and runtimes that are then used to build killer applications. This is the ultimate compliment and has the incredibly practical advantage of letting one innovate behind the scenes while maintaining the illusion of stability.
Sounds like [type directed name resolution](https://wiki.haskell.org/TypeDirectedNameResolution). I doubt it will ever be implemented. Personally I don't mind qualified names; in fact, I prefer them! 
You should move your discussion to r/futurology And thinking about fusing human brains with AI helpers is the same mistake as early technology thinkers envisioned robots as having a body, two legs, two arms, and a head with 2 eyes etc. In terms of engineering it is a dead end. A pure technological solution will always be infinitely superior to any alternative that accepts limitations of human body and brain. 
Actually SPJ said something along those lines in his beautiful concurrency article though.
The big problem with this is that often, formally specifying what you want an AI to write for you is harder than just writing it yourself, especially for interactive or GUI based code. Not to mention the barriers of undecidability and complexity that come with program generation. The history of AI is littered with broken promises.
Yes, you are right about effect instead of side-effect, but what imperative structures are you talking about?
Digital Asset in Zurich, Switzerland
Programming is all about details, precision, and abstraction. In that department text is the best thing out there by a mile. There is simply no better way to express abstractions precisely in as small an amount of space. There are some visual systems that have been created that are useful...UML, for instance. But these systems typically only express projections of the system into a much smaller space. I'm pretty confident that a hypothetical visual system that captured everything would either be much too large to be able to manage efficiently...or it would make important details too small to be recognizable by the human eye. You know what's actually a fantastic visual summary? Haskell type signatures. A pure strong type system is a great way to project some details away while still being tremendously flexible in what it can tell you about the pieces of your system without necessitating a deeper dive into the implementation to verify assumptions.
Going to add to the type system love. Clojure, Scheme, and Common lisp have optional types. A popular lisp with rich static types wouldn't be that different from Haskell. That might be why one hasn't been successful, since haskell is already here. 
Those fields you describe use mathematical formulae. 
Nice, platform includes `stack`, now time for `stack` to actually include it :)
There's no history of AI, because there's no AI yet. There's history of attempts to make AI. &gt;The big problem with this is that often, formally specifying what you want an AI Why would you even bother communicating with AI on such low level? You do not give genie blueprints to the palace you want. You just command him "Build me a palace."
Do the Elevence guys still work there?
Under open positions, they say they almost exclusively use C# and Java. Are you sure your info is up to date?
Myrtle Software, Cambridge UK, https://myrtlesoftware.com/
Apparently there are people working on means to program by manipulating parse trees in a more visual way.
I'm just going to reuse a comment I made on Hacker News: One critical assumption behind discussions like that is that popularity is strongly correlated to quality. But that just doesn't seem true in practice—popularity is the result of complex social dynamics and isn't strongly correlated to any intrinsic qualities of whatever becomes popular. We come up with compelling narratives about whey one thing gets popular and another doesn't after the fact, but these are just rationalizations; we can't use them to make good predictions and they do a poor job of representing the social processes involved. We can see this in a microcosm when we consider music. What makes music popular? To a large extent, it's music that's listened to by the right people at the right time—perhaps seeded intelligently with exposure and marketing. There are some minimal bars the music itself has to pass, of course: it can't be terrible and it has to be accessible, but those aren't high bars to clear. There are thousands of bands as good or better than most of the ones you hear on the radio but they don't get anywhere. You just never hear them, or they never catch on among your friends and never make inroads into your social network. (Or, more importantly, into the social networks of the labels that push music in practice.) Unless they do, in which case you have some unknown band "going viral"—virality says a lot about how something spreads and little about the thing itself. It doesn't even matter what you mean by "better": some objective notion of quality, musical sophistication, aesthetics, "catchiness", pertinent lyrics... whatever. That's not the main driver of popularity. Nautilus had a great article[1] about this a while back, based on some experiments run with music. They created several large groups of participants listening to the same set of 40 musical tracks over time. People in the control group listened to music independently; the other groups all had social feedback mechanisms within the groups. The results were all over the place: the popularity of songs was completely inconsistent across groups, and could be traced to early chance decisions that snowballed over time. The article had a great analogy about how the whole process worked: &gt; …a single match is not the entire reason for a wildfire starting and spreading. But that’s exactly how we naturally think about social wildfires: that the match is the key. In fact, there are two requirements: a local requirement (a spark), and a global requirement (the ability of the fire to spread). And it’s the second component that is actually the bottleneck: If a forest is dangerously dry, any spark can start a fire. Sparks are easy to come by, and are not intrinsically special. The programming language in question? Its qualities? Pragmatism? Purity? Elegance? All just sparks. Which one starts the biggest fire depends far more on its context than the spark itself. [1]: http://nautil.us/issue/5/fame/homo-narrativus-and-the-trouble-with-fame (The article was written by a researcher in the field and cites a few papers on the topic, if you want to read more.)
My point is that 99% of all humans problems and needs arise from the overly complicated and huge social/economical/political system we've built for ourselves. It is a necessity of reality where humans have to work (together) and exploit each other to have things we either really need / want or are conditioned to think we need / want. AI is not just a slave that will do all your work for you, but leave our world untouched otherwise. It will destroy everything you know and expect to be. &gt;Right, and they build you Buckingham, but you wanted the Taj Mahal. You just described the current state of software development :) Only instead of Buckingham most users get an abomination where rooms have no doors and floors are not connected with stairs etc. Humans are the worst interpreters from requirements to a formal language. AI will surely understand and implement our fuzzy, incomplete and most of the time uninformed desires better than any human programmer or architect ever would. 
&gt; AI will surely understand and implement our fuzzy, incomplete and most of the time uninformed desires That's not possible. If the information of what we want isn't given, the AI can't infer it. Just because it's smart doesn't mean it can read minds or predict the future. The classic [No Silver Bullet](http://faculty.salisbury.edu/~xswang/Research/Papers/SERelated/no-silver-bullet.pdf) paper does a good job of arguing why AI is unlikely to revolutionize software development.
Dude, humans building software for other humans fails and breaks down constantly due to failed communication, and people simply not knowing what they want. If you think that problem will get LESS severe when attempting to interface with a non human intellect (or pseudo intellect, more likely) you're straight crazy.
[Ambiata](http://ambiata.com/) in Sydney, Australia. The public part of our github is [here](https://github.com/ambiata/).
which Lisp? :)
Do you interview a cow what it wants when you build a farm? 
I mean like 99% of other jobs will be automated away before that happens. Programming will be one of the last to go.
I'm surprised that on /r/haskell nobody has bought up manipulating ASTs directly and we're talking in circles about futurology stuff. There are some initial attempts towards this like: http://www.lamdu.org/
that sounds promising? would you know what groups or people or projects are doing this that you're referring to?
Yes, it will not happen soon enough to leave us without jobs. But it will also not happen far enough to allow any real change in the way we write software. Functional Revolution is probably the last big change we will witness.
It does not need to. Like car industry did not need to come up with a better way to feed horses (The problem just went away). AI will change the world we live in, making a lot of problems we are trying to solve today simply go away. You do not need to build palaces when no one wants to have a palace. 
Back in the '90's, there was an ACM/IEEE conference called Visual Languages conference, where such languages were demonstrated and discussed. Some that gained a user community: Prograph, AgentSheets, Self.... LabVIEW and HP Vee are box and line languages that are successful and ongoing. Current efforts: Bret Victor's [Inventing on Principle](http://worrydream.com), Scratch, TouchDevelop. UML, is, IMO, not nearly expressive enough, more like powerpoint. [https://en.wikipedia.org/wiki/Visual_programming_language] (https://en.wikipedia.org/wiki/Visual_programming_language)
&gt; constrain their thinking in terms of what can be typed into a text Anything can be typed as text, programmers are not constrained by it. The only question is what is more productive/effective/comfortable, which I think text writing wins at, because once you master fast typing with the use of hot keys, no visual programming with mouse will ever be faster. [Visual programming](https://en.wikipedia.org/wiki/Visual_programming_language) exists though, I've encountered it mostly as scripting, or in tools that generate code from UML diagrams - but for large amounts of code writing text is simply faster, easier to process automatically etc.
You're right it does say that, hm. But it seems they're a part of the Haskell Industry Group http://industry.haskell.org/partners they're also listed on https://github.com/commercialhaskell/commercialhaskell/blob/master/README.md I guess they could've stopped using it, but if that is his github nick he actually works there. I will leave it up for now
In Haskell, every name means exactly one thing. If a name can be usefully polymorphic, we use a typeclass (as you found Foldable for your one example) -- if not, then explicit import lists or qualified names make it much easier for a developer to be able to see at a glance what a given name refers to.
The easiest way to prove that popularity does not correlate with quality is to just point out `docker`
Writing lisp with emacs's paredit mode is pretty close to direct AST manipulation too.
This is great! I'm glad that Stack and Platform are together in one installer especially for Windows. Does Platform piggyback off the same MSYS that's bundled with Stack?
What would it mean for stack to include the Haskell platform? edit: rewrite "the Stack" as "stack"
In short, it sucks. I highly suggest pouring yourself a glass of wine and steeping in http://worrydream.com/. Bret Victor is the modern day Doug Engelbart. However I suspect you'll need something stronger than wine when you realize how much further we could be.
Writing code that is maintainable over the long term requires all imports from external libraries to be explicit or qualified. 
As an engineer, I have to comment, that's *a lot* of code is written before the wind test tunnel is committed. Writing code is cheap in comparison to building a physical prototype. Actually what kind of prototype we should build? we should calculate or compute first! Also some of the visual aids are meant to communicate problems and their solutions between humans, like graphs. When physist, mathematician or chemist talks with a machine, it's more or less writing code. The more specific problem the more likely you have to write the piece of software yourself.
&gt; I assume this is because `foldl'` is part of the Foldable type class and therefore has generic parameter types. No, that's not the reason. If GHC had difficulties figuring out which type to use, you would have had an "ambiguous *type*" error, not an "ambiguous occurrence" error: -- error: Ambiguous type variable ‘a’. Probable fix: use a type -- annotation to specify what ‘a’ should be. foo :: String foo = show (read "42") In the code above, we know that "42" should be parsed as an Int, but GHC doesn't, so it asks for a clarification. We need to write this instead: -- OK bar :: String bar = show (read "42" :: Int) The only way to get an "ambiguous occurrence" error is to define the same top-level name in two different modules, to import the modules in a way which brings both names in scope, and then using the name. In your example, both `foldl'` and `singleton` are defined in both `Data.HashMap.Strict` and in`Data.Vector`. Note that the error is only based on the conflicting names: the types don't enter the picture until we know which definition the name is referring to. To disambiguate, I usually import those modules like this: import Data.HashMap.Strict (HashMap) import Data.Vector (Vector) import qualified Data.HashMap.Strict as HashMap import qualified Data.Vector as Vector This way I can use `HashMap.singleton` and `Vector.singleton` to disambiguate which one I mean. I make an exception for the `HashMap` and `Vector` types, because `HashMap.HashMap` and `Vector.Vector` look too verbose to me. I sometimes make exceptions for infix operators as well, so I can type `xs ! 2` instead of `xs Vector.! 2`, but in this case both modules use the same operator name, `(!)`, so it doesn't help. Since you're specifically asking for ways to avoid using qualified names, here are a few alternatives. You could define non-conflicting names as aliases for the qualified names, this way you wouldn't have to use the qualified names anywhere else. singletonVector = Vector.singleton singletonHashMap = HashMap.singleton If the two definitions not only have the same name, but also the same semantics and mostly the same type signature, it might be a good idea to define a typeclass with one instance for each module. In fact, `foldl'` is already a [method](http://hackage.haskell.org/package/base-4.9.0.0/docs/Data-Foldable.html#v:foldl-39-) of the `Foldable` typeclass, and there is already a Foldable instance for both `HashMap` and `Vector`, so you can simply do this: import Data.HashMap.Strict hiding (foldl') import Data.Vector hiding (foldl') import Data.Foldable foo :: HashMap String Int -&gt; Int foo = foldl' (+) 0 bar :: Vector Int -&gt; Int bar = foldl' (+) 0 As you can see, you can now use `foldl'` unqualified, and type inference will be able to figure out which instance you want. This works because the name `foldl'` is no longer ambiguous: there is only one definition with that name in scope, namely the method from `Foldable`, and so we can move on to the next step, figuring out which instance to pick using the type inference. I think the only reason `HashMap` and `Vector` even expose their own `foldl'` definitions instead of encouraging you to use the one from `Foldable` is in order to be backwards-compatible. Similarly, `HashMap` and `Vector` both have an `IsList` instance, so you can do import Data.HashMap.Strict hiding (toList, singleton) import Data.Vector hiding (toList, singleton) import GHC.Exts singleton :: IsList a =&gt; Item a -&gt; a singleton x = [x] foo :: Vector Int foo = singleton 42 bar :: HashMap Int String bar = singleton (3, "foo") That is, the `IsString` typeclass does not expose a `singleton` method, but we can easily build a generic one. Or you can just use `[x]`, it's shorter :)
If you make the database connection the last parameter in those functions, then it's just `ask &gt;&gt;= run`. eg: foo :: DatabaseConnection -&gt; m a bar :: a -&gt; DatabaseConnection -&gt; m b baz :: a -&gt; b -&gt; DatabseConnection -&gt; m c withConnection run = ask &gt;&gt;= run foo' = withConnection foo bar' = withConnection . bar baz' a = withConnection . baz a Alternatively, you could just define them all with a `MonadReader DatabaseConnection m` constraint instead, like: foo :: MonadReader DatabaseConnection m =&gt; m a bar :: MonadReader DatabseConnection m =&gt; a -&gt; m b 
Hum, I don't have this control over their signatures because those functions belong to a library I'm using. I was hoping that maybe `Applicative` could help with that.
Well what you're asking reminds me a bit of Applicative. But this isn't that great: join $ run &lt;$&gt; ask &lt;*&gt; a &lt;*&gt; b &lt;*&gt; c I'd be tempted to define a special operator for doing Applicative style monadically (&lt;#&gt;) :: Monad m =&gt; m (a -&gt; m b) -&gt; m a -&gt; m b f &lt;#&gt; a = join $ f &lt;*&gt; a infixl 4 &lt;#&gt; Allowing you to write this stuff as run &lt;$&gt; ask &lt;*&gt; a &lt;*&gt; b &lt;#&gt; c But I'm uneasy about this because nobody likes operator soup.
I'm afraid I don't follow. Currently the `stack` installer for 64-bit Windows defaults to the following: &gt; which ghc C:/Users/user/AppData/Local/Programs/stack/x86_64-windows/ghc-8.0.1/bin/ghc ... and when linking it uses libraries in `ghc-8.0.1/mingw/lib`. Is this how Platform will behave as well?
Awesome! Question: What differences do you see between Frege and Eta? I have at least one in mind that really matters to me, but I'm curious what your opinion is.
That day is probably still a long way off we can't estimate it very well because we don't even know what we don't know a good indicator it's still a ways away. 
Look at the sponsors of the European FP conferences (BOB, ..). Glance through some snapshots of functionaljobs.com on the Wayback Machine. Search for keywords in this reddit. Factis research, liquid democracy e.V. Silk was bought out.
I think they are for 2 different demographics. Frege seems to be for people who program in Java and are curious about Haskell. Eta is for people who want to use GHC Haskell for JVM projects. I'll pick Eta up when it gets closer to V1. Some advantages of Eta - compiling any arbitrary hackage package + support of GHC extensions are obvious advantages to the Haskeller. For the Java programmer subclassing and OO in general will be easier in Eta since Frege compiles to static functions and makes any Frege defined subclass final whereas Eta is a little more flexible. Some advantages of Frege - Maturity: the compiler has few, if any, issues. Easy FFI. I picked it over Eta because it compiles to Java and that is easy to plug into Android. With the move to a Jack compiler I think that's a strong advantage. Frege is easier to plug into existing Java build systems. Which is why I'm inclined to think it is mostly for Java developers and I think Dierk and Ingo have said so in the past.
why do we need to accumulate logs in the memory, in the first place? won't most real life applications of logging simply be writing to a file without accumulating anything in memory (except, perhaps a small buffer for IO performance)?
The most serious attempts I know of are Meta-Programming System (https://www.jetbrains.com/mps/) and mbeddr.com Mbeddr is built on top of MPS but for embedded development. They implemented projectional editing and pushed the DSL approach very very far. In addition to text, they also support tabular and graphical ("lines and boxes") notations. Check out the videos, they are pretty cool.
Please indicate which versions are provided by each distro's package repos. It's confusing as hell because people expect to get the latest release but they get an old one. The text: "Good news! Haskell Platform is already available in your distribution's package repository. Simply run, .... " is very misleading. Add a warning that users won't get the latest release. 
Yes, we don't need keep the entire logs in memory if we will write them to a file eventually. Something like fast-logger is better in this case. https://hackage.haskell.org/package/fast-logger Here I used the term "log" in a very general sense including other types of outputs such as emitted code.
In much the same way that Facebook backs D. :P
I like the `join $ f &lt;$&gt; ... &lt;*&gt; ...` idiom because it generalizes to transformers: f :: ... -&gt; m a r :: T (T m) a r = joinTrans (lift . lift) $ f &lt;$&gt; ... &lt;*&gt; ... joinTrans = (=&lt;&lt;)
May I request you to please NOT give a use-case of logging for WriterT when used this way. it is misleading and downright dangerous in any real life scenario. what is a genuine real-life use-case for WriterT ?
Lots of imperative expressions are inherently impure so they don't really fit that nicely into Haskell. Have fun writing a while-loop condition that reads a mutable variable. I think you will agree that it's more painful than in imperative languages.
I think ETA is also for JVMers more than Haskellers, but currently supports greater compatibility. 
I sent in my application, but I don't think the computer is going to let it through due to my answering no on the degree question, and I can't figure out how to get back to it with my filed out information. Should I reapply, or just wait for a human to review it?