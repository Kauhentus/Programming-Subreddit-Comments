And even with the log scale he STILL manages to make it seem exponential.
Nice work. Now we just need R as a combinator library for Haskell...
libraries once again....i wanted to do some prototyping in haskell with an https webservice...where is the haskell https support? back to perl again, hopefully this support will materialize at some point
At the moment, [haskell-curl](http://hackage.haskell.org/package/curl). Open source: contributors wanted.
I don't consider it an elegant solution, but I use [http-wget](http://hackage.haskell.org/package/http-wget) for HTTPS downloads.
I came here to say that too. That's in the "why didn't I think of that?" class of ideas. Any template tool that isn't glorified code-embedded-in-HTML ought to have the same capability. Kudos.
Have you taken a look at Richard Bird's Intro to Functional Programming book? It asked for proofs for questions like: 1. Prove that "length" works correctly. (You use induction on the definition) 2. Prove that a certain function is strict or nonstrict.
Maybe by stating how Haskell is adopted in some places, Haskell will be even more adopted in those places. So listen, Haskell is being adopted everywhere!
Took that class not a year ago. Are we going to be doing spectral decompositions or something? :-)
Nope...I actually very little experience in functional programming. I've become more aware of it due to Java's poor support for it, as I've been working with Java a lot recently, which means many of the functional programming things I did in Python and MATLAB aren't available.
That book is pretty fantastic, especially if you like mathematical rigor. I highly recommend it if you're looking to get into haskell/functional programming. 
i generally agree that if i want this library, i should consider building it....but something like tls support is going to be difficult to get right, unfortunately its out of my league, i would do haskell a disservice by forwarding a weak solution
&gt; The gold standard does not cause recessions and it does not cause recoveries to take forever. The gold standard may not cause recessions, but it is a fact that recessions under the gold standard were deeper and longer (that's what she said) then they have been under fiat currency.
Cool! and looks like the game could be fun. Here is their blog, with some development details: http://joyridelabs.de/blog/
This is why I'm excited to take a CIS194: Haskell next semester.
I'm a research scientist heavily slanted towards computational work, and, though I don't use haskell, I do a lot of functional (style) programming. Maybe using Haskell as a benchmark is not entirely accurate? 
Do you use a functional language?
I had a good laugh at that too.
Not directly, but I am the dude who implemented the Emacs Lisp version of Monads. The point is that FP is a style, not a language, and its a pretty influential style for me. If Haskell had better support for plotting hot figures, and a numerical library the size of Matlab's, I'd be happy to switch. I'm the only numerical guy in my lab, so no one would even notice. [EDIT] : By "the dude" I don't mean "the special dude" just that I think there is only one implementation of monads in Elisp.
could some one do a play by play...?
Haskell's type system, when leveraged by an experienced user, makes applications less prone to error. In the case where thousands of dollars are being won or lost in a second, correctness matters. 
The world won't be free until the last banker is hung with the entails of the last haskell programmer.
Maybe all those cubicle drones will take note. Haskell is a good tool to mention in their CV and they can make $$ with it. 
These are serious business.
&gt; Lack of good community That's one of those things that is so untrue, you just have to believe it was sarcasm, lol.
This should give us better scaling on systems that support epoll or kqueue and let us get passed the 1024 open file descriptor limit on systems that support poll, epoll, or kqueue. 
I also wrote a short announcement with some of the implications: http://blog.johantibell.com/2010/08/new-io-manager-merged-into-main-ghc.html
That's great news! Speaking of epoll, have you come across [this post](http://sheddingbikes.com/posts/1280829388.html) by Zed Shaw? Have you considered some sort of a hybrid approach like the one he suggests?
I thought I'd submit this because it's a great post that succinctly and clearly explains why STM is far from being a dead end.
We've recovered 41 of them. Do you have others? Want to create a new one?
You don't know how ecstatically happy this has made me. I grepped the whole internet for these damn creatures more than a few times and only came up with one or two.
I think it would only be right to code something up for this. I suppose hsmagick would be the way to go?
I'm not sure the notion is that helpful, but being able to understand this sort of inductive definition is useful for programming in Haskell. As kurtel says, the definition is mostly trivial (I think it points out some regularity in definition syntax, but isn't so useful about operational behavior). There are two notions of function arity here. In most languages, including scheme, there are proper functions of multiple arguments (defun binary (lambda (a b) body)) Here the arity of a function is just the length of the parameter list, and (defun (foo) ...) is distinctly different from (define foo ...). You seem to be thinking in terms of functions like this. Remember, we are talking about Haskell. In Haskell all functions are curried and take one argument at a time, so we need a different notion of arity. So, we say a type with is a type of n-ary functions if it begins with n arrows nested to the right (and maybe require the result type of the last arrow is headed by something other than an arrow). I guess you have no problems when n &gt;= 1. The first question is, is it possible to let n go to 0 in the definition? Well, yes. By the definition, "0-ary function type" describes any type which is **not a function**. The next question is whether considering a 0 case of curried arity actually corresponds to any regularities in Haskell ("the language" to which I was referring in your third quote). Your fourth quote was some enumerations of ways plain value definitions behave like and unlike function definitions. For example, the function syntax has no parens or commas, so dropping the last argument just leaves a simple value definition. Also, unlike most languages mutual recursion between value definitions works. On the other hand, the body of a value definition is shared between all references, while the body of an explicit function definition is recomputed for each application. I think this does point out some regularity in the definition syntax, but doesn't say much useful about runtime, where we mostly care that we can pattern match, and it only matters a little that you can't apply plain values. I wonder if my long and confusing or short and cryptic answers are more useful.
I suppose [] isn't a list because you can't rewrite it with (:)
I don't see what you've added. You seem to be saying we have 0 and 1 arity functions in Haskell, which have different behavior. So you still haven't added anything by introducing the lie; now everything is a function, but you have two different types of functions. Why not call a spade a spade? I just don't understand why you won't accept the fact that there is no such thing as a zero arity function in Haskell. I see you're more than capable of inventing a mental framework for it (even a mental framework with syntax or semantics similar to Haskell's), but in every case you wind up introducing a new dichotomy to achieve it.
Lists have explicitly two cases: empty and cons. Functions do not.
I have read it (and a follow up post by someone else). If there's a real use case it'd be worth looking into. It's hard to find one though: you need a use case where you have a high number of active connections. This is hard to find as your server is unlikely to handle say 6000 active connections. If you have a few hundred active connections I doubt it makes a difference. I open to corrections of course.
These have really made my day. Although, now I've got to resist putting the catamorphism one up on my wall.
I just acquired a nice, high-resolution [test-case-eating guinea pig](http://spl.smugmug.com/Humor/Lambdacats/13227630_eKt46#960526344_JXN7j).
Very cool. What software was used?
Thanks for hosting that archive. :)
But it's not hard to achieve the same thing in an imperative language, is it? You just treat shared stuff as read-only, and prepare new data structures outside the transaction; then only exchange references in the transaction. Basically the same way you'd do it in Haskell. The difference I guess is that this way of working isn't _enforced_ (or _encouraged_ anyways) like it is by Haskell's default purity. Well, okay, I suppose my argument boils down to the fact that you _can_ do pure programming in an imperative language, but it's annoying and difficult. Nevermind, nothing to see here. Anyways for what it's worth, I do this kind of thing in C a lot lately when dealing with real-time audio code. I prepare a new block of data (instructions, audio samples, etc) outside the concurrent audio callback, and I use an atomic pointer swap to communicate it. I suppose I learned this trick from hearing about how STM works.
Upvoted for potentially awesome game (I'm raised by Nintendo platformers) and nice distribution/business model.
haha, KittehT cracked me up. Have to say though, humor value was lost for images with text that deviated from the gold standard Impact face.
I've looked at what he's been doing, but frankly I'll be surprised if there's a significant performance win, especially given the substantial increase in complexity that must necessarily be a part of his efforts.
Also, notable lack of burritos.
I loved "ceiling cat is watching you unsafePerformIO" :D
yeah, that was the point at which i laughed out loud too :)
Zed's post seems to be saying that the absolute number of connections, whether active or idle, is not the important thing, and that it's simply the ratio of active:total that matters. He ran his experiment with, as I understand it, many different numbers of total FDs and ended up seeing the same break-even ratio each time.
I didn't make that one, but it's a guinea pig, not a hamster :-)
Thanks. Corrected. 
That's pretty awesome. I appear for about two seconds before flying off the bottom of the chart. I guess I should have sent in more patches! (^_^)
What are hot figures?
Higher arity functions are just as much of an invention. An arrow takes one argument to one result, all else is convention. Do you think Haskell has two-argument functions? You seem to have one definition of arity which you do not explain, and refuse to consider any other definitions. If your notion of arity contains an idea of "zero arity functions", and Haskell doesn't have such things, then I think you are probably using a notion of arity suitable for a language like Python, which will not describe Haskell very well. I'm not particularly fond of the definition kurtel offered, but it isn't nonsensical, and it does point to some regularities in the language - and also points to the much more important idea that just about everything that works with functions of varying arity, like the return/`ap` lifting style, is built from a base case that works for any kind of value, and an inductive step that handles another arrow. It seems to me you are having trouble understanding what was proposed, which is why I'm still hoping to explain.
&gt; You seem to have one definition of arity which you do not explain, and refuse to consider any other definitions. I am using Haskell's definition, but for your sake, it is this: - A Haskell function has arity one. - Functions of higher arity are simulated by returning functions of lower arity. - There is special syntax which enables this. You continue to assert that the base case of functions is values. This continues to strike me as sloppy reasoning, but if I can't convince you that 1 is as good a base case for recursion as 0 when 0 is never seen or used, I don't know who can. &gt; the much more important idea that just about everything that works with functions of varying arity... is built from a base case that works for any kind of value, and an inductive step that handles another arrow. This proves that functions are values, not that values are functions. I'm through. If you must retain your mental inconsistencies, be my guest. I hope that you program well anyways.
I see. But at a low number of connections the absolute overhead of connection management goes down quite considerably compared to processing cost.
&gt; But it's not hard to achieve the same thing in an imperative language, is it? You just treat shared stuff as read-only, Except that the definition of "shared stuff" is complex. For example, often you have threads which contain some kind of internal data structure which persists across calls, but that internal structure cannot be accessed by other threads. However, those private structures are still "shared" in the sense that changes to them must be reverted when the transaction fails. Technically this is the same in functional languages as well. But since pure functional languages don't allow mutation in general, you always have to be explicit about when mutation is used. Thus, there's already a built-in distinction between TVars which have transactional assignment and other things like STRefs which have fast unchecked assignment. To make it work as cleanly in imperative languages we'd have to set up a similarly principled distinction between transactional and non-transactional references, and to enforce that distinction in the type system. Haskell uses monads for this, which works well because Haskell uses monads for a bunch of other things too. At MSR they considered it a requirement to violate the monadic structure (by allowing transactional references to be accessible outside of transactions), which was part of the performance downfall... &gt; prepare new data structures outside the transaction; then only exchange references in the transaction. Except that how you prepare that structure can depend on reading from transactional variables. Which means you want to be notified when those variables change, because that may invalidate the structure you're building and force you to restart. Thus, reads must be logged as well as writes.
So it works on Windows now?
We've left the Windows I/O support untouched for now, as unfortunately we're not Windows users and it doesn't scratch an itch for us.
Yeah, what was the visualiser?
This helps prove the point of all that recent discussion about how "there is got to be other haskell jobs besides financial companies". Ohh well, at least it will satisfy a chicago resident who doesn't consider hft as evil.
&gt; I am using Haskell's definition, but for your sake, it is this: The only mentions of arity in the Haskell report refer to constructor arity, I don't know of any standard formalization. I expect people will agree on simple cases (n &gt;= 1, takes n arguments and returns a concrete "data" type). one notion of arity goes like this (leaving out type synonym expansion) arity :: Language.Haskell.TH.Syntax.Type -&gt; Int arity (ForallT _ _ t) = arity t -- explicit polymorphism arity (SigT t _) = arity t -- kind signature arity (AppT ArrowT _ r@(AppT ArrowT _ _)) = 1 + arity r arity (AppT ArrowT _ _) = 1 a possible extension like arity' (ForallT _ _ t) = arity' t arity' (SigT t _) = arity' t arity' (TArr _ r) = 1 + arity r arity _ = 0 &gt; ... 0 when 0 is never seen or used, I don't know who can. If you still say things like that after *writing* code containing things like "let x = 12 in ..." or "case x of ...", not always things like "let f x = ..." or "case f x of ...", then I'm not sure what else to suggest. Oh well, I don't think you are missing out on much if you refuse to consider whether a definition of arity might be extended to include values / sometimes produce 0. Sorry, this wasn't actually a very useful example. For one that turned out to be more productive, check out [datatype derivatives](http://blog.sigfpe.com/2009/09/finite-differences-of-types.html).
Have you had a look at kazu yamamoto's ghc mode? http://github.com/kazu-yamamoto/ghc-mod
Survey's closed, thanks for all the responses everyone! The winners are Cassius, Julius and Mustard. You can see the results here: http://spreadsheets.google.com/pub?key=0Aj9dwvcPwQ9ldHVOU2p6OVRkcWVQVG10d01OWk8yU2c&amp;hl=en&amp;output=html
Don't know about that video, but [code_swarm](http://code.google.com/p/codeswarm/) does something like that.
Okay, I'm answering a bit late, but I am confused by your question: "Where does the null argument come from?" Of course, if the function has no arguments, then there is no argument to come from anywhere. Perhaps you're attempting to group this together with the notion of a value being equivalent to *unary* functions with () as a domain? That latter notion I agree has little merit in understanding Haskell programming. What I was arguing does make sense is the realization that the notion of curried functions of n parameters extends exactly to thinking of plain values as the n=0 case.
I'm surprised it was merged with the most used platform missing.
I don't think Windows is the most used platform for the high-performance server market, which seems to be the main thrust of this work.
First, I should make it clear that I know nothing about Allston Trading or how they do business. &gt; Qualifications &gt; &gt; * Understanding of high level programming paradigms including object oriented and functional programming (e.g. Haskell, Erlang, Scheme, Java, C++, Python, Ruby) &gt; &gt; * Enjoy programming as both a hobby and a career. It's pretty clear that these qualifications aren't necessarily skills you'd use on the job. My guess is that they've heard that smart people know Haskell, and they want to hire smart people to write C++. My guess is that a company actively using Haskell would say so in the ad, and would recruit in all the places active Haskellers would know about -- here, IRC, `haskell-cafe@`, etc. Though, it's possible they do use Haskell, and avoid saying so for reasons of competitive advantage. Haskell is not a good fit for core HFT work. There are some niches in the field where it'd be appropriate -- EDSLs to generate protocol converters, risk management, etc. But, in the absence of more specific information, I don't imagine this job will involve writing much if any Haskell. The areas of finance where Haskell has seen the most success -- like modeling complex derivatives -- are worlds apart from high-frequency market-making. &gt; The best candidates are those who live for clean programming &gt; abstraction and elegant solutions to complex problems. Again, I know nothing about Allston, but as an industry-wide statement I'm highly skeptical of what they're implying here. In HFT there is no fixed release date; every day you push back the release directly costs you thousands or hundreds of thousands of dollars. So there's an extremely strong bias towards finding the closest similar project, copy-pasting it, and hacking it up until it barely works, then fixing the bugs later, or probably never.
Install Silverlight? Just to watch a video? Haven't these guys heard of HTML5? ;-)
Great news! Congrats!
You can download: mp3 mp4 wma wmv wmv (high) and zune file type Besides, it's microsoft technology, and it works great, so why not to use it?
This is my first submission to Hackage. Any comments, suggestions or criticism is welcome!
I agree with snoyberg. I don't think Windows is widely used for high-performance servers. If someone would like to try patches are always welcome.
It also works fine if n=1 is the base case and values remain ordinary values and we have no nullary functions. Which is the truth.
Thanks for doing this. Thanks especially for providing a nice overview.
I like how cheap it is! Does anyone know what the separate Haskell and Erlang days are? 
Nice that you extended upon fclabels instead of making yet another variant!
&gt; every day you push back the release directly costs you thousands or hundreds of thousands of dollars. Doesn't getting the HFT program wrong cost you millions or hundreds of millions of dollars?
Awesome, finally, a proper, _descriptive_ package description on Hackage!
Speaking as the haskell-mode maintainer, I approve of this. I'd ask you to post them to the haskell-mode list, except it's.. down right now, apparently. Still, if you post something, do go ahead and pre-authorize me to adopt it.
Congratulations! One day I will hopefully join your ranks. Seriously though, great job. Have an upvote. P.S. Keep up the good work on the documentation.
i'm pretty satisfied with how hackage has worked out i would like to see a popularity score for libraries that don't exist yet, maybe potential coders can see where the most potential glory lies... 
I don't get what's all the fuss about (wrt choosing libraries). there are many toy libraries on hackage, but it takes a few minutes (usually less than 5) of looking at the api to decide if it's just a toy, proof-of-concept or if it's actually usable.
Add to that all those libraries you don't investigate because their descriptions aren't sufficient to tell you that they offer functionality you want, and the fact that stuff is going to get worse over time as more and more libraries add up on hackage. More structure and information to go by won't hurt, there.
you probably don't want to use a library that can't explain its purpose in its description
The expression problem is the software equivalent of having your cake and eating it too.
Well, when you're looking for a database-like backend, would you look for "happstack-state: Event-based distributed state."? There's just so much information which fits into a short description, and the author might choose one that doesn't make applicability immediately obvious, in _your_ case (and possibly your case only).
In case anyone is interested, I just realized I could generalize the type of the input from String to Eq a =&gt; [a] with just type changes, and I could make Kleene star greedy without breaking anything. (Weird. User error, I assume.)
No need to invoke GATDs: http://www.haskell.org/haskellwiki/IO_Semantics
Turns out the news is already a few days old. :-) Anyway, people seem to be busy checking the proof: http://rjlipton.wordpress.com/2010/08/09/issues-in-the-proof-that-p%E2%89%A0np/
There has been quite a bit of discussion in [/r/math](http://reddit.com/r/math), but most of it is over my head.
You have seen http://www.reddit.com/r/haskell_proposals/ right? It's not perfect, but it does have karma.
We're setting up a reading/lecture group at my uni for going over all the necessary background and then trying to dig into the proof itself.
The problem is that if you're looking for a high-quality library that does X you might not find any, for certain values of X.
It's not clear to me from reading the overview how or why a field is different from a subfield. Can you clarify?
&gt; http://control.monad.st THAT is a cool domain name.
A draft of the paper with the claimed proof is available on the [author's website](http://www.hpl.hp.com/personal/Vinay_Deolalikar/): &gt; Manuscript sent on 6th August to several leading researchers in various areas. You can find the current version [here](http://www.hpl.hp.com/personal/Vinay_Deolalikar/Papers/pnp_8_11.pdf). Please note that the final version of the paper is under preparation and will be submitted to journal review. Note that the current version has been updated on August 11th. [Richard Lipton](http://en.wikipedia.org/wiki/Richard_J._Lipton) has written a series of blog posts about the paper: * [A Proof That P Is Not Equal To NP?](http://rjlipton.wordpress.com/2010/08/08/a-proof-that-p-is-not-equal-to-np/) * [Issues In The Proof That P≠NP](http://rjlipton.wordpress.com/2010/08/09/issues-in-the-proof-that-p≠np/) * [Update on Deolalikar’s Proof that P≠NP](http://rjlipton.wordpress.com/2010/08/10/update-on-deolalikars-proof-that-p≠np/)
Good job for the proposed PVP checker -- prevent Hackage uploads in contravention of the policy, if the library is in the HP class (or otherwise registered as following the PVP)
This response (the "is the truth" part) is perplexing to me. Of course it's not the truth. The truth is that the only functions are unary. So instead, we are talking about mental abstractions we build on top of that. In what sense is the artificially limited mental model more "true" than the natural extension to n=0? I find it very helpful to point out, when someone is learning the idea of how Haskell does functions of multiple parameters, that the relationship between values and unary functions is *precisely* the same as the relationship between n-ary and (n+1)-ary functions... which is exactly the same thing as saying that *within* the n-ary function abstraction, a 0-ary function is the same thing as a plain value.
Is there a difference between Unpointed types and and Unboxed types? I guess Unpointed types are more general.
Masterminds of Programming isn't a haskell-related book. Perhaps you meant some other book? 
&gt; The book features interviews with the creators of many programming languages, including a chapter on Haskell with contributions from Paul Hudak, John Hughes, Simon Peyton Jones, and myself.
No, I think he meant "mentioning" instead of "related". Or, more generously replace "Haskell-related book" with "book containing at least one Haskell-related chapter".
How about Hackage actually compute the API and have packages depend on that?
We've thought about this and it's harder than it looks, it's also a major undertaking. I think the most realistic approach is to use a PVP checker tool to derive traditional version constraints. That's the first step in any case, when we've got that working then we can think about whether we want to do something more radical.
You mean the package system? And the module system?
Is that enough? I can change the semantics of a function, requiring a major version bump, without changing it's type signature or name. In other words, the name and type signature doesn't fully specify the API. 
no amount of social-web20 tags and comments is going to help with that.
hackage should try to compile with any version of the deps and use the min and max bounds for the sucessfully compiled packages.
"Subfield" just means a field of a nested record. I.e. when you have a record inside some other record, I chose to call the field of the inner record a "subfield" when it's accessed through the outer record.
That's true.
Yes, please everyone do this! Using Haskell at our company, this has been our most frequent reason of breakage. Haskell encourages modularity, so you end up depending on lots of packages. We depend on A.B.* if we've tested with some A.B.C.D, but we've had broken builds both if a package was released with API-breaking changes without incrementing the major version when needed, and when packages fail to set an upper bound on their dependencies (e.g depend on foo &gt;= 0.4). 
The policy implies that you ought to depend on A.B.C.* .
Hey, some good stuff on here. We should merge into haskell-mode. Not sure depending on the Haskell executable is entirely necessary. 
Yeah, the continuation style also works well as an encoding. It also appears to do a better job of hiding the difference between terms which we're not supposed to be able to tell apart according to the monad laws. I still rather like the GADT style for its directness in representing the language we want though.
Not quite. If you're adding to the API, you can increase only C, but if you change types, add instances or remove functions, you have to increase B. Since we control if we import everything or just named functions, depending on A.B.* is safe (or at least the safety depends on us, not on the library maintainers that follow the PVP).
I'm very grateful for the continued support that Galois is providing the Haskell community, but I cannot help wondering whether it is time to leave hosting to a professional hosting company. There are just too many people using these servers 24/7 — it's part of the price for success. Given today's size of the Haskell community, it must be possible to raise the funds required for professional hosting. (I know about the plan with sparky, but really that's the same deal with the failure point at a different institution.) I think it is time to move past DIY hosting.
&gt; Doesn't getting the HFT program wrong cost you millions or hundreds of millions of dollars? Sure, in the event of an unlikely catastrophe. In that situation the traders won't be liable for most of the losses anyway. Meanwhile there's money just lying there on the ground and we're not picking it up due to *your* stupid obsession with code quality. (Of course, heaven help you if a bug in your code does end up costing someone money.) If the traders are setting development priorities, do not expert a sober-minded, long-view assessment of risks and benefits. Depending on the organization there may or may not be other people to keep them in check. 
I don't really see a problem with applying the PVP across all of Hackage :-) See also the "[Poor Man's PVP checking tool](http://www.haskell.org/pipermail/haskell-cafe/2010-April/076863.html)" which can help out in spotting PVP violations -- perhaps I should rewrite it in Haskell and stick it on Hackage.
Ah, my mistake; I should have read the PVP again. Strictly speaking, however, if you've tested for some A.B.C.D, then you should depend on `A.B.C &lt;= x &amp;&amp; x &lt; A.(B+1)` since you need to increase version numbers.
Really nice video and a good speaker. I don't think it said anywhere but was that Mark Jones? He was the first name on the slide but that might have been coincidence...
Concerning raising funding, maybe a [flattr](http://flattr.com) button (microdonations) on the hackage website can contribute?
How about something much simpler: a mirror?
&gt; i'm pretty satisfied with how hackage has worked out I'm not. Everything on one page doesn't scale, and all you get is a title and a one-line description for each listing on the front page. I look forward to the new improved Hackage 2.0.
Headline is a bit misleading then.
For some functions this could be approximated in QuickCheck style by applying the old and new versions to the same arguments and asserting equality of the results. Unfortunately, I suspect many functions for which this technique isn't applicable are the ones we'd most want to test...
&gt; We are pleased to announce the availability of a new Galois tech talk video: “Developing Good Habits for Bare-Metal Programming”, presented by **Mark Jones**.
This book is available on Safari Online, so there is a good chance that people with university access can read it online through their library web page. (I was able to access it at Columbia.)
The new [lambda.galois.com](http://lambda.galois.com/mrtg/localhost_2.html) machine, hosted in germany, was purchased a fe weeks ago, and will start hosting services soon. Already it serves up the HP install.
http://www.galois.com/blog/2010/08/11/tech-talk-video-developing-good-habits-for-bare-metal-programming/
Yay, the video was made available. http://www.galois.com/blog/2010/08/11/tech-talk-video-developing-good-habits-for-bare-metal-programming/ Thanks everyone!
Ah, unfortunately since the Galois server's been down I only watched it on the [vimeo page](http://vimeo.com/channels/galois) which has no such description.
If you are not using qualified imports then adding to the API of a dependency can still potentially break your build (consider if the API starts exporting a function with the same name as one you have defined in your own code base).
&gt; In other words, the name and type signature doesn't fully specify the API. Obviously we need better types, then. :)
It really means something if it's [John Goerzen's lawn](http://www.flickr.com/photos/jgoerzen/4873370591/) you have to get off.
Yes, but at least dons posted the article, so the visual effect is minimized. ;)
You'll need overrides in both directions, but I've become fairly convinced that API versioning is best left to the tool, not the developer.
If I understand right, "unboxed" refers to the memory layout - an unboxed type is contained inside another object, whereas a boxed type is heap-allocated as a stand-alone object. (I'm not sure if stack variables count as boxed or unboxed.) An "unpointed" type, on the other hand, is one that has to have a value, i.e. it can't be bottom. I believe that all unboxed types are also unpointed, and it may also be that all boxed types are pointed.
including Bug and ThisIsUglyHack monads.
For those not following the Haskell Cafe thread, Simon Marlow has solved the puzzle with: process xs = blackhole where blackhole = tail blackhole Wei Hu submitted the following variation, which was close to what I had in mind: process _ = blackhole where blackhole = blackhole My original example was: process = let x = x in x Pierre-Etienne Meunier gets an honorable mention for being very much on the right track.
Sebastian Fischer's solution: process = process
Mark is an excellent speaker :)
"Unpointed" is a denotational term here, while "unboxed" is an operational one.
You can have unpointed boxed types. For example, a lazily computed value when we can prove that it is terminating (therefore, it's not bottom, but it's still a pointer).
You can have unpointed boxed types. For example, a lazily computed value when we can prove that it is terminating (therefore, it's not bottom, but it's still a pointer).
I have an extended vacation coming up (joblessness) and want to do some Haskell game programming. What is a Haskell library for handling screen buffers / active rendering stuff? Java for example has [BufferStrategy](http://download.oracle.com/javase/6/docs/api/java/awt/image/BufferStrategy.html). You ask it for a Graphics context and it handles all the screen buffer stuff like page flipping automatically. Any Haskell equivalent?
Instance chains sound both very cool (finally, some closed type functions!) and very scary (adding or removing an instance can change the behavior of code without affecting whether it compiles or not -- yow!).
How about [SDL](http://hackage.haskell.org/package/SDL)? (There are other SDL subpackages you can find on Hackage also.)
Server wasn't actually down. The cable running into our building was cut by construction work. :-)
Any advantage in SDL over using GLUT? (Assuming game programming will involve OpenGL..)
I'm sorry, I've never programmed a graphical application in Haskell. Hopefully someone more knowledgeable on that topic can reply to your question.
As far as I'm aware, GLUT is pretty bare bones compared to SDL. SDL will give you the cross-platform window management, events, keyboard/mouse/joystick input, sound, etc. Obviously with both you can use OpenGL. I've never written a full-scale game, and I haven't done much with GLUT, but I've heard it repeatedly stated that GLUT isn't good for anything other than simple demos. I've also heard that it encourages poor habits with OpenGL, but again, I have very little GLUT experience.
Changing existing instance chains can changes the behavior of code---but so can changing existing data type declarations, function definitions, etc. Adding new instance chains cannot change the behavior of existing code.
Thanks. That's a good start. Can't play around with it until this weekend.
Overlapping instances are scary, too. =)
I have used GLUT in C for OpenGL games and it offered me window management. don't know if the same is true for Haskell but I'll try soon.
This seems kind of on-topic: I came across an interesting Google tech talk about how to apply a reputation system to a web site the relies on user-generated content without alienating the users. Building Web Reputation Systems Presented by Randy Farmer http://www.youtube.com/user/GoogleTechTalks#p/u/18/Yn7e0J9m6rE
Well-typed robots don't go wrong?!
"With a warning label this big, you know they got to be fun."
Is the limitation here just interfacing with C? Otherwise it seems like this should be a bigger deal...
Yeah, I'm shitting myself over here.
And even interfacing with C won't be an issue for long because of Haskell's FFI.
NEED MORE INFO: * Benchmarks (time/space) * Compiled file size * How long has he been working on this? * Holy shit * What is his programming background?
That's because they're neeeeerds. Someone should tell /r/math that /r/haskell says they're nerds.
Might be harder than it looks though since basically you'd need to write the Python FFI on top (I think). 
True, but at least there's a visible path.
Yes, there are some very respected names weighing in, as reported by these blog entries. I was moved by Terence Tao's assessment, which I read as saying that this probably isn't the proof, but the ideas are of value in ways that will become clear with time.
Yo dawg?
According to the [wiki](http://wiki.github.com/bjpop/berp/developing-berp): These features are not implemented at all in the current version: * Module imports. * Keyword and default arguments. * Comprehensions. * The eval function. * Metaclasses. * Decorators. * Augmented assignment (+= etcetera). * File I/O. * Variable scope annotations (global and nonlocal ). 
So apparently VHDL stands for: Very-high-speed integrated circuit Hardware Description Language Which wikipedia says is: a hardware description language used in electronic design automation to describe digital and mixed-signal systems such as field-programmable gate arrays and integrated circuits.
Haskell to hardware.
GLUT is a pretty awful hack. On Linux platforms, it does not properly report key presses, for example ("Shift+Tab" is not reported, when non-English inputs are selected, no keys are reported, etc). GLUT+OpenGL makes (IME) proper font rendering (with anti-aliasing) a huge pain, compared with SDL+SDL-ttf.
Sure, it's not bullet-proof. But the majority of changes that break API's do change types and names. And you can reduce the "if you change an API, follow the PVP" policy, which is far from ideal even when followed, and not trivial to follow, to: * If you change the meaning of a name, change its type, or change the name.
Didn't he imply they don't "import everything" but "just named functions"?
My main problem with the PVP is that even if people followed it, the situation would still suck. I think the real thing cabal-install should attend to is import/export signatures. This radical change is necessary and probably sufficient. I don't think any other change will be sufficient in the long run.
I found the wording confusing at first, but now I understand that what I mentioned was explicitly addressed after all.
(I am the author...) Unfortunately Precis isn't very good in practice as it uses source code parsing and metrics to find differences. For version policy checking this results in too many false negatives - files that won't parse (acceptable to GHC but not haskell-src-exts) and some instances where the metrics are wrong, or don't cover things that should mean a version bump. At some point, I intend to change it just to do a textual diff instead.
Could you just process the .hi files?
Wouldn't that put a dependency on GHC-API though? I chose to use haskell-src-exts rather than GHC-API as I didn't want to have to update Precis with every GHC revision.
Font rendering is a good point. Dealing with text in GLUT is pretty painful. I haven't used SDL-ttf, but do I assume correctly that it renders text into the framebuffer after the OpenGL update, or does it use OpenGL textures to render text? (For that matter, are there any general purpose text handling libraries for generic OpenGL?)
Just searching for info on this since I hadn't heard of the library before (would it kill the author to put a link to the original library in the hackage description?), I found the [following](http://sourceforge.net/apps/trac/gtk-osx/wiki/Integrate): &gt; The integration library contains two implementations, the original one using Carbon (ige-mac-integration) and a new one using Cocoa (GtkOSXApplication). Since Apple has deprecated Carbon in OSX 10.6 (Snow Leopard), ige-mac-integration is also now deprecated and should not be used in new code. Furthermore, maintainers of existing Gtk-OSX ports which use ige-mac-integration are strongly encouraged to convert to GtkOSXApplication. In addition to being 64-bit compatible, it also fixes some glaring bugs in ige-mac-menu when using multiple windows.
Just released a new version with support for the signals. I will add a link next time. BTW this library only wraps the newer Cocoa GtkOSXApplication.
You could use ghc-api, or ghc -ddump-iface
[Maybe this would help?](http://www.haskell.org/arrows/)
Allowing immediate uploads has also worked well for PyPI -- I just create an account, upload my package, and it shows up. Also, allowing maintainers to set the "deprecated" status of their packages manually is great.
Good to know!
SDL-ttf just makes SDL surfaces. You can load those into OpenGL textures separately. The best drawing combinators I know for generic OpenGL are: http://hackage.haskell.org/package/graphics-drawingcombinators-1.4.1
I think GLUT is fine if you're just rendering and not looking to do much UI. It gets a window open and lets you deal with the keyboard and mouse. If that sounds like all the UI you want, then GLUT is an *extremely* portable way to do so. My point is not to say that SDL doesn't bring a lot of value to the table, but that GLUT should not be dismissed if you're looking to do some graphics programming.
Can I just say plus one for this clever tool even if it does not yet work 100%. I will try and use this as a nice tool. 
Once this works properly it would be a great thing to include in a new version of hackage.
You can use it to e.g. program FPGAs.
This is really coming along quite nicely. I hope it will continue to the point where it is a real alternative for commercial web development (it isn't really right now because the API changes too fast, otherwise it would already be worth considering).
This could also be useful for hot code swapping: Make each module a package and GHC does all the versioning for you.
this should be great for test|bench-suites, you can compile your library and install other libraries depending on it into custom cabal repo ( no more pulling two retarded versions of pandoc into sources!) edit: this is version 0.1 yet it has the best documentation I've seen for haskell packages!
This is awesome. Thanks! Would it make sense to have it integrated in ghc-pkg and cabal? As an alternative to --user and --global, --private would point to the local package repository
Looks like [gource](http://code.google.com/p/gource/) to me.
People may also be interested in the manual: http://community.haskell.org/~ndm/darcs/cmdargs/cmdargs.htm I hope to write a blog post on this in the next few days.
I have such a plan: port the HBI-style full program definitions to run on the GHC-API bytecode interface. 
I haven't ever found anything I couldn't do with GHCI (even though braces and semicolons can get a bit messy). Could you give examples of things that aren't possible but should be?
One of the reasons to *not* do this is that case analysis is done by the linear order of definition parts. It might seem sensible to break up a definition like that to organize the conceptually similar definition parts together, but then you have to worry about whether or not putting "blog post admin actions" before "blog frontend actions" is the same as doing the reverse. This is much easier if definition parts are all together.
I can't for all of google figure out what HBI stands for
Haskell B interactive, the interactive system that comes with hbc. I totally understand the sentiment; ghci feels very primitive when you have used a system that allows the full language. 
...it was not that hard I thought. First google result for "hbi haskell" gave "An introduction using the Chalmers Haskell B interpreter (hbi)."
It's not a feature most haskeller want. 
I would tend to agree though if somebody can think of improvements then I would tend to say go for it. Start a wiki page of suggestions or suggest more. I would be interested to hear about bettering something as useful as ghci; better and better is always good.
I wouldn't necessarily expect function swapping in a REPL for a static language. Given that though, it'd still be neat if were implemented.
I agree with that but if there are times when order is not important (and you know what you are doing) then I see this as being acceptable and helping readability.
Import modifiers (`qualified`, `hiding`, name list) are the most noticeable for me -- especially when working with modules which redefine Prelude names, like Data.ByteString.Lazy (try typing *that* 10 times in a statement).
I'd be fine with this as an extension. It seems really simple - stable-sort the definitions by name. That should work, right?
Sure, there are lots of times when the case analysis is so well fleshed out that it doesn't matter what order you put them in so long as the base case is last. But it's a lot harder to see this if the different cases are separated, and this is almost certainly why Haskell requires definition parts to be put together. EDIT: there's also the point that if you're going to break things up by functionality like that, at least for the translation version, you could just as easily, and probably more wisely, use dedicated names. Instead of *sayHello "spanish" = "hola"* you'd have *toSpanish "hello" = "hola"*, etc. or more ideally, *fromEnglishTo "spanish" "hello" = "hola"*. The blog functionality probably less so, but I suspect the design used there isn't ideal anyway, and a better design would end up not needing this sort of spreading of definition parts.
I usually start ghci with a file argument, and then type :set editor vim. Then I can type :e to edit in vim, and when I am done I type :r to reload the definitions. Works for me, but it is not perfect.
The lack of qualified and hidden imports are my #1 complaint about ghci. You can use them if you've loaded a file that does the qualified import for you, but you can't do it at the REPL itself.
You'll be glad to hear this has been done for 6.14.1 then :-) edit: [here's the ticket](http://hackage.haskell.org/trac/ghc/ticket/2362).
You can't define types and instances. In a perfect world, you would be able to, although in the current world it isn't likely, given the amount of work that would be required. I don't know of a way to print function definitions; I've wanted that once or twice.
Recently I created a patch for ghci, which suggests modules for completion in a smarter way when removing them from context. http://hackage.haskell.org/trac/ghc/ticket/4249 I was concerned that it would be difficult to understand and modify the code, but after 2 hours since I saw the code first time, the patch was ready. If you have some free time and ideas, try to implement them. It is easier, than it seems.
I think you can also get some modularity with multi-parameter type classes, like so: {-# LANGUAGE MultiParamTypeClasses #-} data English = English data Spanish = Spanish data German = German class Language l instance Language English instance Language Spanish instance Language German ---------------------------------- data Hello = Hello data Goodbye = Goodbye class Phrase p instance Phrase Hello instance Phrase Goodbye ---------------------------------- class (Phrase p, Language l) =&gt; Translate p l where translate :: p -&gt; l -&gt; String instance Translate Hello Spanish where translate _ _ = "ola" instance Translate Goodbye German where translate _ _ = "Auf Wiedersehen" This is of course going to be very cumbersome for natural language, but for the blog stuff, where there are a limited number of actions on a limited number of things, this could work pretty well.
could this be looked at as breaking purity?
I would only use this if it were enabled by a pragma on the specific function, not on the whole module. And even then only extremely rarely. It's so important to be able to see the cases all together to feel confident that the matching logic is correct and that there are no missing cases.
I'll give you types and instances (although they're not the kind of thing I'd usually want to test at the REPL). As for printing function definitions you can: 1. Press up arrow if you wrote it yourself 2. Construct your functions symbolically or parse them from strings 3. Make (a-&gt;b) an instance of show (this solves the halting problem or something and is effectively impossible) 4. Have a path for any source you might be using and write a function which greps that
some would argue that it's important to see all the functionality related to some object (e.g. a word) together. Wadler, we have a problem!
Which you can do by reorganizing your code, i.e., one function per word. But to have both organization by function and by object you'll need editor support that can show slices of the code.
GHC could easily verify that order is not important
There a bug in your example code: "ola" means wave, hello is "hola".
I week to early for me. :(
I think Miranda took the relaxed aproach you describe, but the Hskellers decided it was a bad idea. I must say that I think Haskell is right and I would not like to read any scripts that made use of such an extension.
But don't we wave... to say hello... :D
The idea of rewardind people that write good documentation by giving them karma or whatever is IMO a good idea. Look at how some people are attached to reddit karma even if it is of no use.
When I first saw this kind of grouping, it screamed "polymorphism" at me. I would probably write something like this as: class Sayable a where sayHello :: a -&gt; String sayGoodBye :: a -&gt; String data English = English instance Sayable English where sayHello English = "hi" sayGoodBye English = "laterz" data Spanish = Spanish instance Sayable Spanish where sayHello Spanish = "hola" sayGoodBye = "hasta la vista" Yes, it's more wordy, probably overkill for many use cases and might lure you into advanced extensions like GADTs, but I'm guessing that in the simpler use-cases you don't have a particular need for rearranging the functions either.
You can set the environment variable EDITOR, and ghci will use it. Put export EDITOR=vim in your shell configuration file (.bashrc?) and you should be done.
This sort of thing is a great reason to use literate programming, since chunks of code can be reordered mostly arbitrarily. For example, both [NoWeb](http://www.cs.tufts.edu/~nr/noweb/) and my [Anansi](http://hackage.haskell.org/package/anansi) can handle disassociated pattern-matching. Of course, I only ever use it when pattern-matching constructors -- pattern matching strings is bad enough already, and spreading out the matches over an entire module gives me the willies.
I wish some job descriptions in Belgium look even remotely the same.
That made me smile. :D (But I can't help pointing out that "ola" doesn't mean that kind of wave, just the kind made of water.)
brb, reviewing deolalikar.
I'm not sure that "static language" has a precise meaning. I think it just means a lack of features like this one. Thus one can add dynamic features to a "static language" piecewise, with varying degrees of difficulty. For example, GHC Haskell has [run-time type information](http://www.haskell.org/ghc/docs/6.12.2/html/libraries/base-4.2.0.1/Data-Typeable.html), [dynamic types](http://www.haskell.org/ghc/docs/6.12.2/html/libraries/base-4.2.0.1/Data-Dynamic.html), [eval](http://hackage.haskell.org/package/hint), and [runtime heap-graph inspection](http://hackage.haskell.org/package/vacuum). So I think it's reasonable to expect a powerful, flexible REPL. That said, I think GHCi is a great tool as is. There are some annoyances and it could always be better, but overall I am very happy.
Well, starting a wiki page might not be enough... for instance, I'm still waiting for someone with the required skills to actually implement http://www.haskell.org/haskellwiki/GHCi_in_colour ;-)
reminds me of python's virtualenv ...is there an easy way to start a ghci session inside that capri-generated environment?
This is a bit more explicit than [the last one](http://www.reddit.com/r/haskell/comments/czkik/github_jobs_just_started_one_job_with_a_tiny/). More of the shibboleth words. Still, there's no indication you'd actually write any Haskell on the job.
&gt; As an alternative to --user and --global, --private would point to the local package repository That's what cabal's --package-db flag does, though that just *enables* isloation, it does not *guarantee* it. You can use a local package db (via --package-db) on top of the global or user package db. Capri guarantees isolation by copying a few core packages into a local package db and then working only with that local package db. BTW, if someone would like to think about how cabal-install could better support isolated builds then [please file a ticket](http://hackage.haskell.org/trac/hackage/).
Some of our teams use Haskell. Some use other languages. We don't want people who code one language though - we want smart people who understand how to choose and use the right tool for the job. Sometimes that's Haskell. Sometimes it's Python. Sometimes it's awk.
I haven't tried this, but if ghci understands GHC_PACKAGE_PATH that addresses only the project's private packages database then you can. Not sure if capri really needs to be updated for that; can you just use this (being inside your project)? GHC_PACKAGE_PATH=`pwd`/.capri/packages ghci 
How much are you willing to say about which roles Haskell is used for? I'm extremely curious.
Not much in public, unfortunately. Send in an email and we'll chat on the phone about it before things get too serious, though.
Would you possibly have an internship available for a CS undergrad that does most of my leisure coding in Haskell?
Certainly, we're always looking for bright students. We just had a great summer intern leave my team last week. Send in an application!
Dang, I'll be in Boston from the 17th through the 19th.
So what's Chicago like? I'm not sure I could bring myself to live there.
Personally, I'm a fan (I'm biased, but I've lived in Chicago, Cambridge, NYC, and SF in the last few years, and chose to come back to Chicago). The people are nice and have some perspective, things are cheap, and there's a lot to do. Winter is tough if you're coming from Cali. It's not much worse than NY or MA though.
Suggestions for a topic for my talk are more than welcome!
Sorry, scheduling constraints pinned it to that Monday. =/ Runar did contact me about grabbing dinner with you or something while you are in town, though. That said, if you take the job, there will plenty of Boston Haskell sessions you can attend in the future! ;)
Yeah I've always thought other languages are better at this... In Python/Ruby people just kind of start typing into the REPL, but in Haskell you first create a file and load that up, then you switch back and forth. It would be cool if you could use the REPL like a text editor almost (and actually print out the file), where you could type in any Haskell and toplevel expressions would be evaluated directly (and not stored in the "buffer" that would be printed out if you save the file). Haven't really thought this through but I do find ghci to be a bit crippled. Anything other than a one liner or two and I have to open a file. I'd like it to be a bit more powerful than that...
&gt; Sometimes it's Python ಠ_ಠ
Your mentioning awk is a very positive sign to me.
That's not the point! &gt;|
Makes me wish I knew haskell better. I'm just beginning the learning process. My wife and I are looking to move back to Chicago from LA.
I think GHCI would benefit from some of the features that exist in the IPython shell. Some of the most notable (and forgive me if some of these already exist, I do not have enough GHCI experience to know any better) are: * Show help documentation by &lt;function&gt;? * Show source by &lt;function&gt;?? * Easy access to previous inputs and outputs (both accessible through separate lists) * Magic commands such as: run (with -p(rofile) and -d(ebug) flags) to run scripts, timeit (could interface with criterion?), and access to shell commands * Will also dump the history (or a subset) to a file. * And as mentioned by fixedarrow: having color would be nice :) 
Anyone have a video camera to record the talks that they could take along?
To add packages to the HP, please [propose the package](http://trac.haskell.org/haskell-platform/wiki/AddingPackages). Another alternative would be to add MaybeT to the mtl package, which is already part of the HP.
In the past, on the mailing list I read that mtl might be replaced with the transformers library in the future, is that still the case? 
[EitherT](http://hackage.haskell.org/packages/archive/category-extras/0.53.5/doc/html/Control-Monad-Either.html) too! Also in its own separate package: http://hackage.haskell.org/packages/archive/EitherT/0.0.1/doc/html/Control-Monad-Either.html
Note to self: do not mess with gwern, he is capable of destroying you with his ninja-like use of everyday tools such as Google Calendar.
maybe.
There are 3 hackage packages that I know of for command line parsing, cmdargs, cmdlib and console-program (not to mention GetOpt). Unfortunately, they aren't even in the same hackage category. Perhaps it's time for haskellwiki page outlining the pros/cons of each.
Don't forget it's the home of the married with children fountain.
too bad I'll have to miss yet another haskell meeting
Wow! I guess I was wrong. I don't know whether it's more sad that this hasn't been done or that sheep1e remembered [our conversation](http://www.reddit.com/r/haskell/comments/7ydun/share_your_haskell_experience/c07qruz) more readily than I did :)
This post was in response to [a comment I made](http://www.reddit.com/r/haskell/comments/7ydun/share_your_haskell_experience/c07qruz) 18 months ago. Back then #haskell was a chorus of "use MaybeT for that" and a few notable people there seemed confident that MaybeT was a given for inclusion with GHC.
&gt; Another alternative would be to add MaybeT to the mtl package, which is already part of the HP. Use [this process](http://www.haskell.org/haskellwiki/Library_submissions) to submit a proposal.
Very good plan. I'd love to see what people think. Perhaps as a start take one of the libraries, review it on a blog, and then allow the author of the library to post a response (if they choose). I think lots more Haskell libraries should be reviewed that way.
I'm tempted to see if I can at least set up a cheesy webcam or something.
This looks like a nice library! Reading the code for the various d[n] definitions made me think of this neat trick that somebody showed me a little while ago: you can use pattern-matching even at the top level. d4, d6, d8, d10, d12, d20, d100 :: DieRoll [d4, d6, d8, d10, d12, d20, d100] = map d [4, 6, 8, 10, 12, 20, 100] where d n = makeEvent [1..n]
I just clicked the headline, nothing more than short-term ADHD-style internet memory required.
There's also a follow-up article, covering how to use the MonadError type class to provide exception handling. It's located [here](http://mvanier.livejournal.com/5343.html).
This is really neat. I have some preliminary code for a EDSL for describing state spaces of board-games, I might use this.
Whoa.. didn't know about that. When is map evaluated exactly?
I appreciate these articles. I'm under the impression that a new error handling mechanism was added to GHC recently. Is that MonadError?
There's also parseargs, simpleargs and ui-command to add to that list.
Thanks! I'm not sure of the exact timeline, but I think you're referring to extensible exceptions, like you'd find in the Control.Exception module. Anybody know more about this?
That sounds about right. The sense I get from your article is that this isn't the currently preferred method. I have been so befuddled by the error handling situation in Haskell right now I have mostly tried to avoid all of the options, but as I do more I'd like to do it right.
If you use d10, it will evaluate the spine of the map up to the d10 entry, and the value of the map at the d10 entry (and nothing more) -- i.e. it's evaluated lazily. ;-)
I wouldn't go so far as to say that it isn't the currently preferred method. It all depends. If the only monad you're using is the IO monad, you might well want to use exceptions that live in that monad. OTOH if you already have a monad transformer stack and have a smallish number of well-defined exception cases it's not much work to add an error-handling monad to the stack.
Excellent. So basically equivalent to: foo = map ... d4 = foo !! 0 d6 = foo !! 1 ...etc What I was looking for was if this was optimized away by the compiler, i.e. equivalent to: d4 = (\x -&gt; makeEvent [1..n]) 4 d6 = (\x -&gt; makeEvent [1..n]) 6 ...etc
http://www.haskell.org/pipermail/haskell-cafe/2010-August/082149.html
He will remind you that he needs to kick your ass.
If someone proposes so. So far, no one has.
&gt; Due to the way in which Potential code is compiled, the language is particularly well suited to “infectious” licenses: since Potential mnemonics are really just Haskell combinators, there is an opportunity to license Potential in such a way that code written in Potential necessarily adopts the same license. A program is not a derivative work of the language it is written in. How parsing works is a technical detail that won't interest judges: Anyone could come along and write another implementation for it. Wine isn't property of Microsoft just because they wrote the original version of the API, and noone will be able to sue linux developers for implementing the POSIX API. What you can do, of course, is release all runtime and library code under [A]GPLv3 to make sure that anything using _your_ implementation will have to be distributed as source code, too. If in doubt, spread FUD and say everything has to be [A]GPLv3 no matter what.
Look at it like this - this way, you saved $10 &amp; learned a valuable lesson, while I got both satisfaction and karma. Everybody wins!
Speaking of reminders, I put off all my Xmonad reminders because you said you were supposed to be working on your thesis up to July/August... How's that going?
Looking at the patch, I'm surprised how involved a change to the RTS this was; I had sort of assumed this was a 1-5 liner.
&gt; A program is not a derivative work of the language it is written in. This very much depends on how the language is implemented. Remember that Potential is an embedded language. Though it has support tools that make it behave like a language, but it *really is* a combinator library. There's a very strong case that use of a library constitutes derivative work, which is why there's an LGPL. Of course, someone could write an implementation for which this is not true. But that has no bearing on the license of the original implementation.
&gt; This very much depends on how the language is implemented. The question is whether there's a trace of the implementation left in the compiled code. The licensing of a C program depends on the licensing of the libc it uses, but not on that of the C compiler. That's the reason virtually all compiled-in runtime systems have very, very liberal licenses even if the compiler itself has a more restrictive one. Put bluntly, closing up potential would require re-implementing all library code, but (IANAL) not the parts from parser to codegen. A trademark with a policy that everything that calls itself a potential library has to have a GPL-like license and everything that calls itself a potential compiler a FLOSS license could help there. I hate to say it, but a patent or two, too.
Great news for those of us who generate DLLs that have to play nice with other code.
If it was a 1-5 liner, it wouldn't have taken 5 years to fix.
&gt; I still don't believe that it is important for GHC to release memory back to the operating system during a process, and I'm unsubscribing from this ticket so hopefully I'll hear no more about it. wow. somebody never heard of long-running processes.
Consider: myFunction [] = [] myfunction [x] = [x] myFunction _ = [] It's an easy bug to make if you can ungroup functions, which I believe is why it's the way it is. Writing a preprocessor to allow disjoint functions should be an hours work - once you have learnt both haskell-src-exts and Uniplate :-)
That's not true. There are plenty of small easy problems in FLOSS that take many years to fix. (Adding Control.Monad.void comes to mind from my own personal experience.)
very cool man, thx for sharing! just starting to get into graph databases myself, been looking at neo4j.
As if this post does not have more upvotes, this is awesome news for everybody. 
Wow. I don't know much about Haskell (only used once or twice at uni) but that seems like it was a huge issue.
It's not very important to return memory to the OS if it's a Haskell program that is running, because then Haskell has the whole address space to itself (and unused memory will be paged). But when Haskell is used as part of a larger program it's vital that it doesn't hang on to address space (it's address space rather than memory that runs out) that other parts of the program might need at a later time.
&gt; wow. somebody never heard of long-running processes. Actually that would be the least significant case after short-running haskell-only process: if the system regularly spikes, the haskell runtime system will reuse the memory it kept for itself at one point or another, so that space is not "lost". And if that can conflict with some other tasks, then you're betting the farm on your haskell long-running process not running at the same time as those tasks or everything comes down anyway.
It became a significant issue with DLLs. It wasn't much of one before, hence having been a 5-years low-priority bug.
There aren't that many of us, but this is important for embedded systems, as they can't swap because of flash wear.
Any link?
I googled and found this: [Quora: What are the best languages for getting into functional programming?](http://www.quora.com/What-are-the-best-languages-for-getting-into-functional-programming)
It would be great if all the haskell document db libraries could adopt a similar interface. The latest MongoDB interface is pretty good. http://hackage.haskell.org/packages/archive/mongoDB/0.7.1/doc/html/Database-MongoDB.html
Just submitted a ticket for a variation on the same theme: [GHC never returns OS threads to the OS](http://hackage.haskell.org/trac/ghc/ticket/4262)
*Hurray!* Will this fix be in 6.14, or a 6.12 point release? Right now I've set up my long-running Haskell programs to periodically restart themselves so they won't monopolize swap after a space spike, but fixing the underlying RTS bug is much better.
&gt; closing up potential would require re-implementing all library code, but (IANAL) not the parts from parser to codegen. I agree. I'm struggling to find a license (for the runtime system) that I'm comfortable with. Things which are highly permissive are good for promoting adoption; things which are about "free as in speech" have their own appeal. Any suggestions?
In your second definition of `factorial`, the summary is wrong: &gt; if factorial is ever called with a negative input, there will be a pattern match error which will also abort the computation and not result in an Integer being returned. Actually, what will happen is `factorial` will loop infinitely. If you want a pattern match failure, you have to put a guard on the recursive body: factorial: Integer -&gt; Integer factorial 0 = 1 factorial n | n &gt; 0 = n * factorial (n - 1)
Why would forkIO make OS threads? It should make light-weight user-level threads. forkOS makes OS threads...
Show (a-&gt;b) doesn't solve the halting problem since (a -&gt; b) is only the space of representable (in Haskell) functions. Now, you might lose referential transparency, but I'd be happy with debugPrint :: a -&gt; IO String which gave me a compiler-dependent non-referentially transparent printout of the object passed in which might vary based on the evaluation state of the object. Something like this: ghci&gt; let f = 1:1:zipWith (+) f (tail f) ghci&gt; debugPrint f x0 where { x0 = 1:1:(zipWith (+) x0 (tail x0)) } ghci&gt; f !! 2 2 ghci&gt; debugPrint f 1:x0 where { x0 = 1:x1; x1=2:(zipWith (+) x0 x1) } 
You're entirely correct: It actually isn't forkIO but the **safe** FFI call that creates an OS thread. **safe** FFI calls are run in a separate OS thread to prevent them from blocking other Haskell threads. To see how it works, compile the following program (don't forget -threaded!) and see how many OS threads it uses: {-# LANGUAGE ForeignFunctionInterface #-} module Main where import Control.Concurrent import Control.Monad import Foreign.C.Types foreign import ccall safe sleep :: CUInt -&gt; IO () main = do getLine replicateM_ 10 $ forkIO $ do threadDelay (5*10^6) sleep 2 getLine You will see that for the first 5 seconds it only uses the 3 OS threads that are always used by the GHC runtime system, and then, when each thread calls sleep, the thread-count goes to 13.
Nice! These slides need a set of exercises. 
http://unlicense.org/ the only really license that is free, not merely someone's idea of free.
Hmmm. &gt; In keeping with the goal of providing a language for trustworthy systems, the following principles are relevant: &gt; &gt; - Users must be able to modify code written in Potential. &gt; - Users must be able to deploy modified code on any devices they own which run code written in Potential. &gt; - Potential should not be used as a foundation for denying users transparency into the devices and systems that they rely on. Someone showing up to preach the gospel of their own particular definition of "free" while blatantly ignoring what the author of the code has explicitly stated are their goals seems to be some sort of Godwin-esque law of open-source licensing discussions.
libgcc uses [GPL with linking exception](http://www.spinics.net/linux/lists/gcchelp/msg03788.html), ghc is BSD, anyway.
* In some legislations, certain author's rights are inviolable and thus not transferable, rendering "all" quite fuzzy. * That disclaimer of yours is null and void in the EU if the consumer isn't a professional.
Good catch! I'll fix it.
But doesn't Show superclass Eq? And I'm quite sure you can't be pure and allow functions to be an instance of Eq (though I'd like a computer scientist/category theorist weighed in on that). Also I'd love to see you write debugPrint. I think it's harder that it appears to be.
Nice read. I've been dabbling in Haskell for some time now, but when I see techniques like this laid out so plainly I realize that I could be doing so much more to take advantage of the type-system provided.
&gt; Your approach appears to work, but is made rather longer and less readable than the Ruby version I just want to say that to me the Haskell version is a lot more readable. I have basic Haskell knowledge and cursory Ruby knowledge. It could have something to do with the way Haskell encourages descriptive function names, the Ruby just looks like Perl-esque gibberish to me.
Show doesn't superclass Eq; you might be thinking of Show,Eq superclassing Num (which is kind of silly, although it's used for pattern matching on integer literals) You can sometimes make functions an instance of Eq: class Exhaustive a where everything :: [a] instance Exhaustive Bool where everything = [False,True] instance (Exhaustive a, Eq b) =&gt; Eq (a -&gt; b) where f == g = all $ map (\x -&gt; f x == g x) everything 
But two things should necessarily be equal if they have the same string representation no? instance Show a =&gt; Eq a where (==) :: a-&gt;a-&gt;Bool (==) = (. show) . (==) . show 
I'm thinking of putting a short course together using ideas from this. 
forkOS isn't just "spawn a new OS thread" -- it acts like forkIO, except it's only multiplexed onto one thread. It's intended for use with external libraries which rely on thread-local data.
Adding a function to do that has downsides though (namespace pollution), and the right name to use isn't obvious, which means that it's not a small and easy problem to fix.
Don't know why you got downvoted for saying that. I think it's a great idea to do a course. Related: Xavier Leroy and Didier Remy have written [Unix System Programming with Objective Caml](http://ocamlunix.forge.ocamlcore.org/)
The right name to use isn't obvious == hard problem? Wow. BTW, the hard part of Control.Monad.void was not picking the name. There were only 2 serious contenders, 'ignore' and 'void'. Nor was it hard to settle on the general Functor signature once someone pointed it out. The hard part was getting people to give feedback - any feedback! - and get the base devs to actually commit my patch. (This is a perennial problem with XMonad as well - it's not that some patches need tremendous cleanup or anything, it's just that no one comments or approves them. They just get ignored.) As Wikipedians sometimes say: 'editing is easy, consensus is hard.'
[HSH](http://hackage.haskell.org/package/HSH) is John Goerzen's much larger attempt at shell scripting in Haskell that has been around for a while. It shares many, but not all, of the design goals expressed in Don's slides. The main difference is that HSH is trying to provide an alternative to the shell command line, while Don is focusing more on scripting. I think there's a lot more that could be done in this space. It would be really nice to find something up on Hackage that you could just download and start using without thinking too much. Yes, just getting things done without thinking too much - that's what shell scripts are for, after all.
&gt; it's not that some patches need tremendous cleanup or anything, it's just that no one comments or approves them Well, that just shows that your creation, `Control.Monad.void`, is being well used.
Would it possible to get a copy of the final script?
Generally, I'd agree with that, but note that debugPrint returns IO String, not String. And you can get showable functions for some data types as well, too (Exhaustive a, Show a, Show b) =&gt; Show (a -&gt; b), and have show print case analysis.
It does become somewhat annoying in that the OS still has to waste time paging out that memory though, and even more annoyingly paging it back in when you go to write fresh data to it later. Moreover, if you're doing 'varnish'-like abuse of swap space as cache anywhere else on the machine it is annoying to have something knowingly waste that shared limited resource. While it isn't a huge concern, it can still cause annoying hiccups in which a pure computation gets stuck waiting on disk access if it has a bursty space usage profile, even if you aren't part of a larger process, and didn't need any data that is sitting on the disk, but instead just wanted some fresh pages.
I have to admit having cas and test-and-set primitives would be really convenient for a lot of reasons. Currently I FFI out to perform tasks along these lines when I want to work with lock-free data structures in Haskell, but have to do so with un-gc'd ptrs, which means I wind up having to face ABA issues that would be non-issues if they were in the garbage collected world with the rest of my code.
How are you safely exporting haskell data as Ptrs to C without using StablePtr?
I don't. I should have said StablePtr. =)
Ah sorry, I didn't realise it was in IO. In that case I'd love to see DebugShow implemented and operating as you'd said. Mightn't be quite trivial to write though.
Yeah, it's actually a tough problem (the GHCi debugger implementers had to work on it for a while; I remember a great article about the problems they ran into). It's actually not 100% solvable in Haskell since the rules for newtypes (no runtime representation) means you can't actually have 100% accurate type tags in your in-memory structures.
&gt; The right name to use isn't obvious == hard problem? The combination of it not being obviously worth adding, and not having an obvious name, meant that achieving some level of consensus was difficult. 
The paper link and the slides link work for me. The source link does not.
&gt;This project demonstrates the most recent "best practices" for laying out a large Yesod project Yes! We need more of those.
This is great stuff! Orange Roster wants an LDAP server now. :) Also, have you looked at SMTPClient for your mail? It's a bit more portable than using sendmail.
I'm getting the impression Wadler's Law doesn't apply to dependent languages, while they could definitely use some discussion, there. Stealing from Haskell is a definite option. Oh, and please don't expect me to write proofs without a theorem assistant, or to install emacs, for that matter (I'm looking at you, Agda). I think Idris is the only language I've seen that got most of the basic usability issues mostly right (ignoring {;}).
http://research.microsoft.com/en-us/um/people/simonpj/papers/assoc-types/fun-with-type-funs.zip
Hmm. Patrick Bateman reviews Haskell eh?
Hilarity ensues
Follow the thread for some benchmarks. Applications are already starting to appear: [attoparsec-enumerator](http://hackage.haskell.org/package/attoparsec-enumerator)
I'm working away slowly on a package called hexpat-iteratee which is a chunked XML parser intended for things like socket I/O. I really appreciate your work in this area, however... Having a lack of standardization on which package is the "real" iteratee can be quite a stunter of innovation. Another example of this phenomenon: I tried to persuade the author of WAI to use the List package (which everyone should know about - I also intend to write a List-iteratee bridge). The argument against using it was that it introduces a dependency on transformers and people might want to use mtl. What may now happen is that WAI will become stable before the transformer/mtl split is resolved, List will never be introduced to WAI, and an opportunity for increasing Haskell's expressive power will be lost. I don't know what to do about this problem, typified by transformer/mtl. I am guilty of it myself, being the author of yet another XML package (hexpat). hexpat-iteratee-mtl, hexpat-iteratee-monads-fd, hexpat-iteratee-monads-tf, hexpat-enumerator-mtl, hexpat-enumerator-monads-fd, hexpat-enumerator-monads-tf... It's an N^2 problem.
Type-safe client/server communication is a pretty powerful idea.
What is the List package? Is it distinct from Data.List?
Unfortunately, research.microsoft.com is a very broken site. If you are using IE on Windows, you can definitely access it. If you are using anything else, it may or may not work for you.
Don't skip this because it's ML - off the top of my head I can't think of any of his points that wouldn't apply equally as well to Haskell.
Link: http://hackage.haskell.org/package/List It provides a List class and a monadic list (which can be used as a monad transformer, but looks useful outside of do-notation).
This diverges if it encounters a word that is longer than the line length. Here's a simpler one (imo) which doesn't: wrapLine' :: Int -&gt; String -&gt; [String] wrapLine' maxLen line = map unwords $ gobble 0 [] $ words line where gobble :: Int -&gt; [String] -&gt; [String] -&gt; [[String]] gobble k acc [] = [reverse acc] gobble k acc ws@(w:rest) | l &gt;= maxLen = reverse acc : [w] : gobble 0 [] rest | k + l &gt;= maxLen = reverse acc : gobble 0 [] ws | otherwise = gobble (k + l + 1) (w : acc) rest where l = length w Tests: *Main GOA&gt; let test = "one two three four five six seven eight nine ten" *Main GOA&gt; putStrLn $ unlines $ wrapLine' 10 test one two three four five six seven eight nine ten *Main GOA&gt; let test2 = "one two three four supercalifragilisticexpialidocious five six seven eight nine ten" *Main GOA&gt; putStrLn $ unlines $ wrapLine' 10 test2 one two three four supercalifragilisticexpialidocious five six seven eight nine ten
Actually, there is a small bug in the above. See if you can find (and fix) it :)
It is an implementation of [ListT done right](http://www.haskell.org/haskellwiki/ListT_done_right). It replaces the `Control.Monad.ListT` module from [mtl](http://hackage.haskell.org/package/mtl). That module has been buggy right from the start, yet it *still* hasn't been fixed.
But that's not the function intended by the original poster. Your use of `words` and `unwords` changes the whitespace characters in the string; the original does not. The bug in the original function is very minor - nothing more than changing `any isSpace line` to `any isSpace beforeMax`. As for "simpler" - as you say, it is a matter of opinion. The original looks simpler to me. Yours is nice too, though.
A nice way to do error handling in a partial function is to use `Control.Monad.guard`: unsafeFactorial :: Integer -&gt; Integer unsafeFactorial 0 = 1 unsafeFactorial n = n * unsafeFactorial (n - 1) factorial :: MonadPlus m =&gt; Integer -&gt; m Integer factorial n = do guard (n &gt;= 0) return (unsafeFactorial n) Now, clients can use `Maybe Integer`, `[Integer]` or which ever `MonadPlus` instance they like.
Yeah, we're more interested in finding feature sets that reflect and support new programming patterns than in arguing about matters more lexical. When you're not sure of the structure of programs, there's not much return in fretting about their appearance. I don't know whether you intended to come across as outside the tent pissing in, but we're just not in that tent yet anyway. Would that we were. Stealing from Haskell has pros and cons. On the one hand, a lot of effort went into making Haskell's syntax as sparsely pretty as it is. On the other hand, too much unquestioning Haskell-think can impair creativity and create a comfort-zone which should rather be challenged. We should gratefully adopt Haskell solutions if they fit our problems, but we should guard against skewing our choice of problems to fit Haskell solutions. Asking people to step away from their favourite editor is one of those toMAYto toMAHto things which make you want to call the whole thing off, but please keep it in context. Tight editor integration has been a very useful shortcut to exploring incremental type-informed modes of programming which become more and more helpful the more you can express and compute in types. In time, and with community help rather than community whining, it might get easier to support multiple editors. My plan for Epigram is to implement a batch-mode transducer which acts like an annoying coauthor: you feed in your file with some new work and some requests for help, and you get it back updated with some details added and a bunch of unhelpful comments; when the thing finally stops moaning, you can ask for an executable. Hopefully that will reduce reliance on specific editor choices whilst retaining the benefits of working incrementally. But I could really use a parser library which makes it easy to recover the source text from the structured data: I want to retain the programmer's layout choices where possible, prettyprinting only what the system generates. I do agree that Idris makes a better fist than Agda of separating "programming" and "proving". The two may both be exercises in constructing lambda-terms, but they have a different look and feel. Programming should emphasize terms; proving should emphasize types. (By the way, I suspect that Idris's reliance on {;} is because life's too short for implementing layout. You want it, you do it.) Epigram will separate programming and proof: the program elaborator will search the context for whatever lemmas it needs, allowing a proofs-in-the-appendix style. Back to Adam's blog-post, what you're seeing there is not the source syntax of Epigram 2 (we don't know what that is yet) but a script for interacting with "Cochon", our cheap and nasty command-line interface to Epigram's interactive construction engine. We're getting to the stage where the commands correspond to higher-level programming steps, so it's probably time to start thinking about design choices there. We had a long chat about the lexical structure of comments (with escapes for scoped, typechecked, partially evaluated terms) the other day...
No, it doesn't diverge if you feed it a word longer than the line length: batkins@hudson Haskell (master) % runhaskell WordWrap.hs adfsjkdsafjkadkfjsahkfdshfdsahafdshfadshfhkfdsajhfdsajhkfkajdhfjdhsadfasjhfdhajsdfhjkfdjkhfdahsjkfdhakhfdaufhiewuiehrruieerwuiwerquihrewquiherwuhierwhuirewuhrewqhuerwqhuwerqhuewrqhuweruqhehrwquuihdvsgvsdagiewr8914590u3190541 adfsjkdsafjkadkfjsahkfdshfdsahafdshfadshfhkfdsajhfdsajhkfkajdhfjdhsadfas jhfdhajsdfhjkfdjkhfdahsjkfdhakhfdaufhiewuiehrruieerwuiwerquihrewquiherwu hierwhuirewuhrewqhuerwqhuwerqhuewrqhuweruqhehrwquuihdvsgvsdagiewr8914590 u3190541 Can you send me an example that breaks it?
I wonder why they chose to target CUDA instead of OpenCL. I'm not following this stuff too closely, but my understanding was that OpenCL is very similar, but is meant to be a standard that will also run on ATI cards eventually, and currently OpenCL algos can also run on the CPU without changing the code. Anyways, either way this sounds like a pretty nice way to get into GPU processing, I hope I get some time to take it for a spin..
One of the slides contains the following snippet: &gt; `let module F = Command.Flag in some_expression_here` Are there any Haskell proposals for this kind of syntax?
I think it was a student project, and it dates back to previous work using CUDA for parallel array work before OpenCL was available (according to wikipedia, the first publicly accessible version of OpenCL by nVidia was in a beta program in mid 2009.) I think I've heard chak express they'd be interested in someone porting it to work on OpenCL.
 wrapLine 10 "longwordhere test" But it is easy to fix as others have pointed out.
How about "Don't be puritanical about purity" :)
GHC ships with libraries for local impurity, which is one of the techniques advocated by Yaron. Imperitive programming in Haskell is a delight, really. And there's all kinds of work going into declarative impure programming with the itereatee work going on.
Ah, I see - if a word length is &gt;= maxLength. Thanks!
&gt; implement systems that a user can trust when there is a gun to his head. If there's a gun to my head, I can probably be made to trust anything :-)
That only caters to *your* idea of free... Personally I care less about whether software matches some dictionary's definition of "free" and more about whether it caters to a world with more or less software that people cannot modify, redistribute, etc. For me, GPLv3 helps rid the world of that kind of software which I do not want to exist.
what's the status of ddc? any new simple bugs? 
Nice, Tom Hawkins should feel quite happy!
I hope they get into a hiring spurt soon, while I'm on the job market. :)
Oleg in ML land is all about delimited continuations. Oleg in Haskell land is more about iteratees and hlist and zippers. Maybe we have a better post-Oleg processing phase? (Hackage).
Sample code? Benchmark?
There are some small examples in http://code.haskell.org/accelerate/examples/simple/src/ I discussed some old benchmarks in my talk at the Haskell Implementor's Workshop last year. Here are the slides http://www.cse.unsw.edu.au/~chak/papers/accelerate.pdf and a video of the talk http://justtesting.org/running-haskell-array-computations-on-a-gpu We need to run new benchmarks, though.
We started working on this before OpenCL was released. The approach that we are taking to code generation in the CUDA backend can be applied in the exactly same manner to OpenCL. It'd be great if somebody would consider porting the backend. We currently don't have the resources to push two backends.
Hopefully the number of bugs is decreasing, not the other way around :P. We're still in the development phase. The overall structure is there but there are holes that need filling in. Most of the bugs on the trac are some version of "this isn't done yet". 
Makes sense, thanks for the answer. From my understanding there are a lot of similarities between CUDA and OpenCL, so maybe a port wouldn't be too much work, but it certainly would be a project.
It shouldn't be too much work for somebody who knows OpenCL. The biggest chunk of work would probably be to figure out exactly what code to generate so that it executes *efficiently*.
How is it possible to use Haskell for a hard real-time system when Haskell has no real-time guarantees?
Copilot is an EDSL that generates C code with guarantees of real-time behavior
Copilot uses Atom. Atom itself is an EDSL that generates C. The generated C code has those guarantees; e.g. no dynamic allocation.
&gt; I want to retain the programmer's layout choices where possible, prettyprinting only what the system generates. &gt; Epigram will separate programming and proof: the program elaborator will search the context for whatever lemmas it needs, allowing a proofs-in-the-appendix style. Doesn't the latter solve the former? Just append the proof (or, better, the script needed to drive the assistant) and be done with it. I sense a major philosophical difference there: I don't think assuming any editor support during design is a good idea, things should be workable with copy+pasting from the assistant into the source, like I tend to do with Haskell type signatures. (this might be due to the fact that I love vim but loathe vimscript) And, yes, I'm outside of the tent, but peek inside on a regular basis to see whether it's cosy enough for a non-Ph.D like me, yet.
Haskell doesn't have first-class modules or ML-like functors. The only way to get something like that (that I know of) is packaging up all the exported functions in a record, but that gets painful pretty quickly. The idea is something like this: data ModuleSignature = ModuleSignature { function1 :: Int -&gt; String } moduleImplementation1 :: ModuleSignature moduleImplementation1 = ModuleSignature { function1 = show } moduleImplementation2 :: ModuleSignature moduleImplementation2 = ModuleSignature { function1 = reverse . show . (+2) } -- use it thusly: x1 = let m = moduleImplementation1 in function1 m 500 -- evaluates to "500" -- or so: x2 = let f1 = function1 moduleImplementation2 in f1 500 -- evaluates to "205" -- or like this: x3 = let (ModuleSignature {function1 = f1}) = moduleImplementation2 in f1 123 -- "521" Especially adding functions to a signature is pretty tedious!
If we had dependency resolution based on import/export signatures (in cabal-install), we could write an mtl interface provider based on transformer's implementation. Then, packages that depend on MTL's interface could be linked with transformers (and that bridge) and the split could finally be resolved?
The mtl shouldn't be used by anyone anymore, yet it is in the Haskell Platform instead of any one of the numerous properly implemented libraries.
 newtype Parser a = P (ParseState -&gt; (Maybe a, ParseState)) how did you come up with this type? this is not what Parsec looks like, it's not what RWH presented and it doesn't look like the thing from Hutton book (or slides, don't have access to the book). have you tried any other approaches? if this was your first idea, congratulations - you have better intuition than people with oh-so-many years of haskell programming.
&gt; ParseState -&gt; (Maybe a, ParseState) That's a straight-forward state monad. Isn't that the obvious way to change a recursive descent parser into a monadic one? parse :: String -&gt; (Maybe a, String) ... type Parse a = String -&gt; (Maybe a, String) parseM :: Parse a
&gt; Oleg in ML land is all about delimited continuations. http://okmij.org/ftp/ML/ has many posts that aren't about [delimited] continuations. maybe they are based on them, but that's like saying, that Haskell.Oleg is about typecast. &gt; Maybe we have a better post-Oleg processing phase? (Hackage). I think it's because we need it. iirc Oleg only packaged HList, but there are at least three ocaml libraries (pa_monad, ber-metaocaml and delimcc). I've only used pa_monad, but it was in a better shape than HList (despite the fact that I have much more experience with haskell than ocaml). Oleg is about four things: * awesome * "oh boy, I discovered something so cool, it'll make a great blog post! now only to google some related work and... god damn it, Oleg already did it..." * "man, this is hard, I have no idea how to solve it. maybe some googling will help? oh wow, Oleg already did it!" * you want to point someone to Oleg's previous work, that completely solves all of his problems, you can't remember the link, so you visit his site and despite reading the table of contents so many times, you find yet another interesting thing to read (this time I've found http://okmij.org/ftp/ML/#dynvar ). it's nice to know that in this ever changing world, while you keep on improving your programming skills and widening your interests, you can rely on the fact, that whatever you're interested in, Oleg already did something about it.
I'm well aware of Oleg's work: http://hackage.haskell.org/package/liboleg
I think the more obvious type would be something like `ParseState -&gt; Maybe (a, ParseState)`, which isn't quite the same. Putting the `Maybe` around just the parsed value differs in that it would seem to allow a parser to fail without forgetting how much input it took. This could probably be useful somehow, but not with only a Monad instance to work with, and as far as I could tell the article here doesn't make use of the distinction. I'm too lazy to go look it up, but I suspect it's roughly the difference between StateT Maybe and MaybeT State.
I too find this the obvious way, and noticing the similarity to the recursive descent parsers is practically screaming. what I don't understand, why Parsec was written the way it was (which is a very wrong implementation). Another surprising thing is the popularity of Parsec - it has been ported to every other language by using this very unnatural (especially in imperative languages) design.
this is exactly the difference between ErrorT State and StateT Either. but the whole world disagrees with you about what's more obvious.
The Stack Exchange FAQ explains the following about the Beta phase: "This is the actual, live site set up on a "probationary" basis to see if people will use it. It is very important to participate early. The earliest questions will set the tone and topic of the site for a long time. This is also the time to spread the word via Twitter, blogs, and email far and wide. If the site does not get used, it will be deleted." This can be a great resource, but if we don't get participation now, then the project fails. At the moment, the focus is very complexity-theory heavy. More algorithmic content, pl content, types content, logic content, etc. would be a very good thing. It seems like a natural home to discussions of dependent types, coq, agda, epigram, etc. and the like in particular.
I think it would be a good idea if you do this blog again using type families which give you a functional style for type computations. Yes you can define factorial in with C++ templates, template meta-programming in C++ is functional, support pattern matching on arguments via template specialization, with the aid of framework like [boost::mpl](http://live.boost.org/doc/libs/1_44_0/libs/mpl/doc/index.html) evaluation strategy can [become lazy](http://live.boost.org/doc/libs/1_44_0/libs/mpl/doc/tutorial/the-importance-of-being.html) which can dramatically improve compile-times (only instantiate at the point when it's absolutely necessary) and provides more expressivity such as support for infinite meta-data structures. Now I wonder are type functions in Haskell lazily evaluated?
I think type synonyms are expanded immediately, so I guess that the same applies for type families.
To get prettier output: class Nat n where toInt :: n -&gt; Int instance Nat Z where toInt _ = 0 instance Nat (S n) where toInt _ = 1 + toInt (undefined :: n) And then call it with: toInt (undefined :: Fact ...)
You don't have to expand them immediately. In fact, doing so will give you worse error messages. 
Try CmdArgs instead.
Holy crap, that's pretty amazingly awesome. I wish I could make code like this. I'm going to use this in my project for sure, and then I'm going to disect it.
I've always assumed that the reason it's popular is that so many libraries (network, parsec, etc) all use it. If patches were tendered to move all the platform libs to transformers and monads-tf, could mtl just go away and die in a corner?
As the author of the linked clog post, I agree. Like I noted in the comments, I kind of rushed into the standard library docs instead of doing the *right* thing and searching around for idiomatic approaches.
Fantastically well explained, thank you!
You get an upvote for using "clog" because my phone always prefers that spelling too :-)
I use the spelling out of choice. "Blog" is a shortening of "weblog" and likewise "clog" is a shortening of "coder's log". Also, it's a sly reference to all the other blogs out there that clog up the intertubes. Can you believe that some people don't subscribe to my sense of humour? Impossible, I say!
Ronuk's lemma: "All problems have already been solved on Hackage. Thrice!" Why, just look at this: data Complexity = P | NP deriving (Eq) main = print $ P == NP This prints out "False". Problem solved. I don't get all the hype surrounding that proof that came out a while back.
This blog post should be on hackage. If every package had such an easy to follow tutorial, life would be so much fun. It looks really simple to use, i am looking forward to using it.
Cool trick, thanks!
Thanks for the compliment!
This is a good suggestion. I'll get on it.
Be careful when you disect the code. It contains powerful black magic that must not be wielded frivolously. 
&gt; (\f r -&gt; f r) or you can just say `($)`.
Actually, I found a new bug-let today that would be perfect for someone looking to getting into ddc development. Here it is, [bug #186](http://trac.haskell.org/ddc/ticket/186). 
[This item](http://cstheory.stackexchange.com/questions/174/major-unsolved-problems-in-theoretical-computer-science) attempts to collect a list of all the "major" unsolved problems in computer science. It appears to have the highest number of votes of any item on the site. Currently, every unsolved problem proposed - **every single one** - involves computational complexity as an essential part of the problem. Are there no important unsolved problems in computer science that are not computational complexity problems?
and 'putStrLn $ show flags' is 'print flags'.
shouldn't that be a type error? it looks like it's trying to concatenate list to strings
 say "Hello" "spanish" = "hola" say "GoodBye" "spanish" = "hasta la vista" say "Hello" "english" = "hi" say "GoodBye" "english" = "laterz" 
TIL that some supercomputers use as much power as high speed trains.
History that persists across sessions would be nice, too. Edit: though I guess that's an obvious side-effect of dumping history to a file, as you mentioned.
I don't claim authorship, I read it somewhere else. Can't remember where, though.
Half the comments by edwardkmett have been fixed already, some others are nearly fixed and should be in the next version. Some others (bash completion particularly) I have no idea how to fix, but if someone sent me a pointer to a manual I'd have it done in no time at all.
Um, yeah I took a look and it pretty much is black magic. I'll figure out parts of it perhaps.
I'm intending to write a blog post on some bits of it, which should hopefully illuminate the scary bits (only 1 module is magic, the rest are fairly straight forward)
That would be awesome. :)
How is compiling a single .hs file into a .o file not a pure computation? I understand that it might not be implemented in a pure way in GHC, but fundamentally it is a referentially transparent operation is it not?
it's not implemented in a pure way and if it depends on gcc it's not referentially transparent, because gcc isn't pure - iirc it can produce varying binaries for the same sources because of timestamps or something like that
Nitpick: capitalizing "Monad" like it's the name of God. The type class is named by the identifier `Monad`. Instances are described by the English word "monad".
Interesting. I have heard the term "unification variable" used, to contrast with the variables used for polymorphism. Does this have anything to do with what GHC means when it says a variable is "rigid"? I think another way to think about it is a distinction between bound and free variables. Unification variables are free, but the variables in foo :: a → b are bound by an implicit quantifier: foo :: ∀a b. a → b
Cool. I am reminded of the classic paper "[Typing Haskell in Haskell](http://web.cecs.pdx.edu/~mpj/thih/)".
There's actually a brief discussion in TAPL, in section 22.2. Pierce refers to these type variables as *held abstract*. I'm not sure if calling them *Skolem constants* is accurate or helpful.
I totally agree -- very approachable. Thanks.
I tried to write a type level if, using lazy evaluation. It failed: {-# LANGUAGE EmptyDataDecls, TypeFamilies, ScopedTypeVariables, UndecidableInstances #-} module Main where data T data F type family IF c t e type instance IF T a b = a type instance IF F a b = b data X data Y type family Test a type instance Test X = Test X -- infinite type type instance Test Y = Y instance Show X where show _ = "X" instance Show Y where show _ = "Y" main = print $ (undefined :: IF F (Test X) (Test Y)) This compiles forever. That means both `Test X` and `Test Y` are expanded before the `IF` is expanded. 
so who are those guys?
let me know what y'all think and if you find any mistakes or if you have concerns regarding the tutorial or just if you like the pics :)
Will read this as soon as I can. By the way, LYAH is by far the best introduction to haskell. So keep them coming!
 _ _ _ _ | | | | | | | | | |_| |__ __ _ _ __ | | _____| | | __| '_ \ / _` | '_ \| |/ / __| | | |_| | | | (_| | | | | &lt;\__ \_| \__|_| |_|\__,_|_| |_|_|\_\___(_) 
This seems to be the idea of holding a variable abstract is there, but not the issue mentioned in the post. I went and got Pierce's code and tried a simple example: (lambda x:A. lambda y:B-&gt;C. y x) : B -&gt; (B-&gt;C) -&gt; C So Pierce's type checker for that chapter (it's the fullrecon one) is freely unifying explicit type variables. It would happily accept the motivating example given in the blog post, which should really be an error. As for the name Skolem constants, well, it's what everyone seems to be using for it. I would have gone for "existential type variable" myself, but meh.
&gt;Does this have anything to do with what GHC means when it says a variable is "rigid"? Yep. A "rigid" variable is something which can conceptually vary, but which we are holding constant during type inference, e.g. because the user has put an explicit type signature and therefore we don't want to allow the variable to be refined (because then it wouldn't be polymorphic). Whereas unification variables are like logic variables in logic programming, or like the variable names used in pattern matching. Pattern patching is a form of unification BTW. Bound and free don't quite capture it, since implicitly all type variables are bound. Rather, the distinction is between when things are bound and when they're allowed to vary. Bound and free also don't quite capture it because there are two different kinds of unification going on. When unifying during type inference and generalization, rigid variables are held rigid; but when unifying to specialize a polymorphic function for applying it to arguments, then the rigid variables are allowed to be specialized.
&gt; I have heard the term "unification variable" used, to contrast with the variables used for polymorphism. In Hindley--Milner inference, they're the same thing. Unification variables represent unknown substructure in the term structure representing the type. As we do type inference we learn about the structure and so unification variables become bound to things and new variables are introduced. Any unification variables which remain after inference then become prenex universally quantified type variables. Once you move beyond Hindley--Milner types, then things become more complicated.
I just want you to know that you are THE BEST. And I have already pre-ordered your book. If I could have your haskell babies I would.
I think answering that question with specifics would be a privacy violation. It is in general not good for your boss to find out you're hunting before you want them to.
FINALLY! Thank you!
Reading this makes me feel hopeless about finding a job that uses Haskell. The entry level is just too high. :(
I am looking forward to your kleisli fish pictures!
Every time this topic comes up and someone speaks from the employer's perspective, the dialogue always says that the hiring is insanely competitive. I get the impression that it's good to be in a position to hire Haskell people, but not good to be looking for a Haskell job.
Computational complexity is an easy source, at least. Pick a random calculational problem and ask how fast you could solve it, or ask about comparisons between two complexity classes (of which there are a lot). I could think of a similar problem-generating algorithm for type theory. Pick some random combination of features added on to a well-studied type theory (definitions and delta-reduction, universe polymorphism, induction-recursion, ...) and ask if it's strongly normalizing. Or ask for a proof-theoretic ordinal (you can ask the latter for impredicative theories, too, since theirs are unknown, I think). I don't know how "major" those would be considered, though.
Nice!
Indeed, I have found myself liking it much better than other popular sources.
Your misunderstanding of recursion speaks poorly of the book...
here's a typo: "Now here's the kicker: how do would we feed a Maybe value to this function?" The explanations have been very clear so far. Thanks for writing this. edit: another typo: "fail takes an error message int he form of a string and returns a failed value. "
You have a marvelous didactic style.
As editor of the HWN for a couple of years, I can attest that hand-compiled aggregators don't scale as well as reddit et al. 
Yes [there's a reddit](http://www.reddit.com/r/todayilearned/) for that. Share your new found knowledge with the world :)
I have applied for a few haskell jobs, including this one, and have to agree that it's very competitive. Of course I would like to work with haskell, but because I know how qualified the people who end up getting the jobs are, I can't really feel dissapointed.
[Apparently going to be back eventually...](http://www.reddit.com/r/haskell/comments/cdw38/hwn_it_will_be_back_promise/)
Well, there's more than a single problem with that line of code. Benl32 says its a problem with associativity / precedence handling and that is probably not too hard to fix. 
Don't despair! Keep in mind that we were specifically hiring Haskell experts, since we are after all a Haskell consultancy company. Other jobs where you can use Haskell will require a different mix of skills.
I will surely recommend this introduction (along with the previous chapters) to anybody willing to learn monads. It's just like the typeclassopedia but with more examples. Brilliant.
I'm in the process of hiring Haskell programmers too, and business-wise the right decision is to hire the best programmers that my budget (time and money) can afford. Having said that I'd definitely like to support the community by opening it up to those with fewer of the usual requisites (academic and/or years of commercial experience). This typically means that he or she will spend some time learning advanced Haskell on the job, sort of like an apprenticeship, from senior staff. I'm worried that if I do go down this path, once the new hires feel they have some skills they'll bail on me by jumping to another more lucrative position. The tech industry is notoriously bad when it comes to old-fashioned notions like employment loyalty. Whereas with hiring a "Haskell expert" I wouldn't feel I lost any investment in training. Does anyone have any ideas about this?
Needs more burritos. But seriously this is great, I learned Haskell from the beginning from your book, I love how simple and straightforward you make everything seem.
But then Skolem constants were invented (by Thoralf Skolem) exactly to replace existentially bound variables by constants, so in some sense the names are equivalent.
&gt; Having a lack of standardization on which package is the "real" iteratee can be quite a stunter of innovation. &lt;radical-mode-on&gt; In other languages one has to rely on libraries. In haskell one does and should own all the code. The "real" x-package is whatever you got from hackage and then extended on your own. Knuth: I also must confess to a strong bias against the fashion for reusable code. To me, "re-editable code" is much, much better than an untouchable black box or toolkit. &lt;/radical&gt; 
I think you ran into some trouble by treating `fail` as if it's a *bona fide* method in the Monad class. Really, it isn't, it has nothing to do with monads themselves. It's only there for a technical reason: to support pattern matching in `do` notation. Later on, you end up having to say things like: &gt; But because we have no way of encoding error messages into our Maybe values, we just ignore the error message and return a Nothing. Well, that's not true. Just use `error`, like in the default implementation. The real reason is that we want to be able to use pattern matching for selection, which is possible because `Maybe` is an instance of `MonadPlus`. Also, introducing `fail` in this way can perpetuate the misconception that `fail` can be used in general to indicate a failed calculation. Most experienced Haskellers feel that is a very serious mistake - that practice often leads to fragile programs which can crash at runtime. The name `fail` of this method is referring to pattern match failure, not failure in general. So to stay out of trouble, I would just tell the truth up front: `fail` is only there to support some special syntactic sugar for Monads that we'll see later, don't worry about it right now.
&gt; I could think of a similar problem-generating algorithm for type theory... &gt; I don't know how "major" those would be considered, though. The same is true for problems generated using the complexity algorithm. But there are some such problems which do indeed seem to be especially important, either because of their deep theoretical consequences, or their far-reaching practical consequences, or both. Aren't there any such problems in type theory, or any other area of computer science? 
Just hire the best people you can get and make sure they have a job they really like. If they're really good, you'll probably lose them anyway.
Here's an idea: Provide a complete denotational semantics for an imperative programming language. Or equivalently, define a purely functional IO system with complete and precise semantics.
Minor error: In the definition of `guard`, you have indented the lines below the type declaration, which results in a syntax error.
Great! Another typo: In the Functor redux section you've got two examples like this that are missing $ after putStrLn: main = do line &lt;- getLine let line' = reverse line putStrLn "You said " ++ line' ++ " backwards!" putStrLn "Yes, you really said" ++ line' ++ " backwards!" 
oh, would you look at that. fixed
fixed! :)
not anymore!!
very good points. i didn't want to introduce the monad type class and then confuse the reader by saying right away: but fail shouldn't be in here, but it is! but you're right, it's best to introduce it like that and then show how it works in do blocks. i'll go about incorporating this into the text today edit: i incorporated your suggestions into the text. it should be correct now regarding fail and its usage.
Lambdas like the one in this expression: Just 9 &gt;&gt;= \x -&gt; return (x*10) Could be written as a composition: Just 9 &gt;&gt;= return . (* 10) You could use this instead, for the sake of making the code look more idiomatic.
Is this available in PDF or some ebook format? I was hoping to read it on my iPad.
I worry when I see variables floating about without a context to bind them and give them scope. I recommend checking out Dale Miller's "mixed prefix" unification to get a clearer grasp of these issues. Here's the gist. We try to solve constraints over a context storing two kinds of variable, marked \ or ?, e.g. \a \b ?x |- a=x &amp; b=x This represents a game. Your challenge is to instantiate the ? variables with types which validate the constraints. Meanwhile, the devil will try to instantiate the \ variables with types which falsify the constraints. Play proceeds along the context from left to right (global to local). That's as much to say that more global variables are in scope when choosing instances for more local variables. To solve the constraints, you need a winning strategy. Moreover, you'd rather like to find the strategy which would leave you in the strongest position to solve further constraints: that's yer "most general unifier". In the above example, however, the devil's got you stitched up like a kipper. Order really matters. You have a winning strategy for \a ?x |- a=x, just picking x to be a. Meanwhile, for ?x \a |- a=x, the devil can wait for you to pick x, then choose a to be different. In Hindley-Milner type *inference*, the context consists solely of ? variables. When you *check* a function against a given Hindley-Milner type scheme, you'll have a bunch of global \'s for the free type variables in the scheme (yer Skolem constants), then a bunch of ?'s for the type variables which arise from the function. However, in higher-rank inference, you can get arbitrary interleavings: local \'s show up anytime you're supplying a polymorphic function; local ?'s show up anytime you're invoking a polymorphic function. So, you certainly need to know which variables are \ and which are ?, but to solve higher-rank problems, you also need to pay attention to their scopes.
Also, one can make an alias to liftM/fmap, for example: import Control.Monad ($&gt;) :: (Monad m) =&gt; m a -&gt; (a -&gt; b) -&gt; m b ($&gt;) = flip liftM So everything becomes as simple as: Just 9 $&gt; (* 10) which returns Just 90. In the same fashion as Applicative, you can bind more than two computations using that operator: Just 9 $&gt; (* 10) $&gt; (`div` 9) and this returns Just 10. Surely, this is very similar to how you made the abstractions later in the article.
I noticed monad transformers have gone from the coming soon section. Have these been dropped from the book? I was looking forward to an accessible intro to them.
After 5 hours... ... 2 hours... ... *...oh god it all makes sense* **I CAN SEE THE MATRIX**
A pretty simplistic analysis: given how competitive Haskell jobs are in general, even if they *want* to jump ship the odds are against them being able to. There are, after all, more Haskell experts than there are jobs for Haskell experts.
that is indeed more idiomatic, but i chose to use lambdas because i think they're easier to follow if you're a haskell beginner, at least until you've internalized function composition
yeah, let's just say Maybe for now :) i thought they might be kind of tedious to write about. although i'll definitely try. if not until the book release, then i'll put up a blog and write about them there. any other topics that y'all would like to see given the lyah treatment?
why? which part needed the most work and could it be automated with some help from blog authors (e.g. you can provide a recent link with a description conforming to some rules (like not trying to be funny, spell checked), perhaps choosing a theme (announcement, trick, new paper))?
What?
I guess his motherboard never came :)
Sweet! Just wanted to say thanks for writing LYAH. Two minor things: * In the section where you define `type Pole = (Birds,Birds)` you refer to `Pole` in the description as `(Bird,Bird)`, dropping the **s**. * When you write the `landLeft`/`landRight` functions, does it make sense to allow a negative number of birds on a pole?
CUFP starts on Oct 1st. Will those of us that only have CUFP tickets he allowed to attend this? 
I have contacted Joe regarding this issue. I find myself with a bit of time on my hands, and would love to pitch in to be part of this community. I have offered to step in as a temp editor, at least until Joe can pick things back up. My current question is: do we need HWN? Seems like the Haskell reddit ends up getting all the good stories anyway. So, I've been scratching my head, trying to find something else that could be useful to the community, and not just a compilation of links for which there are other, seemingly better tools. What would you guys think of a Kernel-trap type site for Haskell-cafe? I could track interesting conversations, and summarize them in a way that is more digestible than the back-and-forth of emails. Does this sound useful?
whoa, fixed that! i presume you mean having pole like (-3,-2). well, depends on how you look at it, you could view that as birds actually lifting the pole from his hands. but generally i'd say it doesn't. you could make it so that if there's a negative number of birds on the pole that Nothing is returned, but then you're using Nothing to represent a failure in the code (nonsensical data) as well as failure in the model (the guy losing balance), which seems sort of dodgy
"Just like functors have the `Functor` type class and applicative functors have the `Applicative Functor` type class" Was the last "Functor" intended to be there?
Hmm. I see your point that actually handling the problem would make the meaning of Nothing ambiguous. I don't really think it's much of a problem at all, just a small oddity.
You don't have to sign up to either CUFP or ICFP to attend this session. So please, consider yourself welcome!
Excellent, is it still in the convention center then?
I remember when part 1 of this post was posted to the Haskell Reddit back in December. The [original comment thread is here.](http://www.reddit.com/r/haskell/comments/ak9g1/fun_with_the_lazy_state_monad/) I had a heck of a time decoding that `pro` example.
HWN should provide interesting links to productive people, who don't want to read my stupid comments, old links and self.haskell posts, leaving this pleasure to us!
I don't know enough to disagree, but I do find it slightly ugly to have to go to redditland to get what I used to get from the HWW and the sensible judgment and goofy wit of a trusted editor. It is true that reddit permits commentary, and I learn a lot from it. And no doubt it 'scales' in the sense of attracting some of the immense readership of /r/programming to Haskelly themes. But the whole site has something evil about it. So for example, even in this chunk of the reddit archipelago, the discussion can take a special turn toward the ugly. And worst of all one is inevitably tempted to look at the 'other discussions' listed at the top of the page -- which is basically like looking at -- I don't know what -- pornography. Reading HWW I felt I was in an innocent world of enthusiasts. Reddit may 'scale' in the short term, but I wonder if it can last; surely the site as a whole is subject to a law of degeneration, it's palpable. In the long run r/programming will be %100 javascript pornographers like our troll `redditnoob`. By contrast, the Haskell presence on Stack Overflow, which has a focussed mission, seems excellent: uplifting, educational, Haskelly in all the best ways. It seems to me that HWW could mention the really interesting discussions on r/haskell, as it did those on Haskell-Cafe. Then some of us would be spared this place.... Likewise with the more expert controversies on Stack Overflow. I by no means want to suggest that everyone should feel the way I do. 
No, no it wasn't! nice catch
Here's a short (and basic) monad transformers tutorial I wrote. You'd probably want to go deeper and expand much more as you do.. But I think it shows it doesn't have to be that tedious to show a couple of transformer examples: http://www.haskell.org/haskellwiki/Monad_Transformers_Tutorial
HWN could include: 1. Links to the most important things on reddit (for those of us who are trying to wean ourselves from the reddit addiction). 2. Links to the most interesting Haskell-cafe discussions. 3. Attached pages by scholars describing their PhD thesis and the most important ideas, etc. I am thinking that this would be before the thesis was written - maybe the community could help with ideas. 4. Important trends/reports on ongoing activities like: the LLVM backends, what people think of DDC. Is anybody working on a better GRIN (whatever that would be).
You might be right but only time will tell. I think that it is the people and not the medium that make the society. Haskell has been going for a while and people will drift to whatever best suits us as a whole. I think that the community will move in the right direction if and when the time comes. For now, and because I am Australian, if it ain't broke, don't fix it. ;)
Well, I'd at least be interested in a strong normalization proof for a type system with all that stuff added in, because they're useful features for actual programming in type theory. But, the proof methods for that are fairly well known, and I don't think there's much reason to think that anything novel would be required for the proof. It's just a matter of someone working through it all, which is boring. And, for instance, I think induction-recursion is an interesting, useful and significant feature for a type theory to have (technically it goes back to Martin-Loef, but he only used one particular case of it to my knowledge). But, it's difficult to come up with some cut and dry problem or conjecture that it is an answer to. I suppose I could come up with some, though. For instance: 1) What is a good way to incorporate general recursion into a programming-and-proof language, such that it's both easy to use, and doesn't ruin the proof stuff? 2) We now have languages allow us to write (barring paradoxes we've missed) verifiably terminating programs. How can we use a language to help us write verifiably _efficient_ programs? That last one has something to do with computational complexity, I guess, but oh well.
I like it, I like it! (I hope others do too.)
&gt; This function can also be written without the use of lists as a monad... &gt; You can use a list comprehension.. OK, that's fine if you present it that way. But I still remember the moment I realized that list comprehensions really **are** do notation, just a slight variation on the syntax. That was the moment the light bulb when on for me for monads. 
I wondered if this reddit was supposed to be the replacement. If so, it wouldn't hurt to put a note on the sequence site. That way when someone does find it, it doesn't look abandoned. Maybe something like: "This site is great when we have a good editor but we keep using them up. For now, enjoy http://reddit.com/r/haskell for the latest news. In the future some enterprising soul may bring this site back, possibly in a more scalable form." 
&gt; And no doubt it 'scales' in the sense of attracting some of the immense readership of /r/programming to Haskelly themes It 'scales' in that the editor's work is *far* less, it is *easier to have multiple editors*, and *easier to determine top content*. For a while I tried the approach of editing the aggregator, too, you might recall: http://haskellwebnews.wordpress.com/ -- though quarterly was too much for me. I think that might replace the HCAR in some ways.
"In the first line, an empty list is fed into the lambda." ... Should say "...is fed into bind" or something like that because it never gets as far as the lambda.
I haven't had much time (just one lunch time) but I've been trying to get this work via: type family If c (t :: * -&gt; *) (e :: * -&gt; *) :: * -&gt; * Adding another layer of indirection with another type function might do the trick, it's similar to how lazy template instantiation works in C++ boost mpl.
That's a good idea. Unfortunately t and e would then have to be data families, because type synonyms have to be applied to all arguments (have kind *). Edit: But it works if you put the type family outside the IF: type family Case a -- this does the indirection data XTag -- you have to define a tag for every type you use data YTag -- in a conditional type instance Case XTag = Test X type instance Case YTag = Test Y and then define IF as: type family IF c t e type instance IF T t e = Case t type instance IF F t e = Case e 
I think some of these have been solved, but... http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.3962
Ah, i haven't seen that, that's a nice tutorial. I like the approach. I was thinking of doing something similar, introducing how failure can be introduced to the state monad by turning it into s -&gt; Maybe (a,s) and then when writing the instance, noticing that no Maybe specific stuff is used, only return and &gt;&gt;= and going forward from there
The more general approach is to move the type family outside of everything and abstract over type function application in general. Lo, it is written in the [Scrolls of Kiselyov](http://okmij.org/ftp/Haskell/types.html): *"Those who hurry to their destination surely shall never arrive, but to the one who measures each step [all roads lay open](http://okmij.org/ftp/Haskell/types.html#Haskell1). Learn ye first the way of beta reduction: From that, [all else follows](http://okmij.org/ftp/Computation/lambda-calc.html#haskell-type-level)."* {-# LANGUAGE EmptyDataDecls #-} {-# LANGUAGE TypeOperators #-} {-# LANGUAGE TypeFamilies #-} {-# LANGUAGE UndecidableInstances #-} data T x data f :$ x type family Eval t type instance Eval (T x) = x type instance Eval (f :$ x) = Eval (Apply f x) type family Apply f x data Yes data No data If type instance Apply If (Yes, t, e) = t type instance Apply If (No, t, e) = e data X data Y data Test type instance Apply Test X = Test :$ X type instance Apply Test Y = T Y instance Show X where show = const "X" instance Show Y where show = const "Y" main = print $ (undefined :: Eval (If :$ (No, Test :$ X, Test :$ Y))) 
nice catch, thanks! i removed this contrasting of list comprehensions and do notation (since like you say, they're the same) and it is already mentioned before that list comprehensions = do notation
Yes, that's a good reference. It's mostly a survey of ongoing work, but it does mention some open problems - some of which may even still be open. Anyone who can pick one or more open problems that can be considered **major**, state them simply yet accurately, and use this as a reference, is encouraged to do so.
*"The choice of problem is based on our belief that a good understanding of evaluation order is very important for writing practical Haskell programs. People learning Haskell often have the idea that evaluation order is not important because it does not affect the calculated result. It is no coincidence that beginners end up floundering around with space leaks that they do not understand."* As a Haskell beginner who has read some advanced Haskell literature but coded barely a Hello World, this paragraph really hit on my nerves. I mean, is practical Haskell this problematic in hiding runtime details while excelling at abstraction. This [too] encourages me to wait until Disciple is not anymore at prototype stage.
&gt; any other topics that y'all would like to see given the lyah treatment? Did you have any plans to cover arrows?
I like it but I am no category theorist. Is there an official name for a monadic value? Because otherwise I'm sticking with mote.
Hmmm, I don't think 3 or 4 are called "monads" very often. Am I mistaken? What's wrong with continuing to use "monadic type" and "monadic value"?
Values are anathema to category theorists. They (the theorists, that is, not the values) wouldn't be caught dead giving a name to such a concrete concept.
&gt; What's wrong with continuing to use "monadic type" and "monadic value"? From TFA: &gt; One thing I have discovered in my writing life is that the clarity of a confusing document can sometimes be improved merely by replacing a polysyllabic noun phrase with a monosyllable.
They're often called "computations". As in the "Computational Lambda-Calculus" of E. Moggi.
Thanks, missed that. I'm going to question it though, as with an ajdective-noun pair, one can often improve flow by breaking them up, and without sacrificing clarity. To use the article's example: "What's the type error here? Oh, its return value should be monadic." Disclaimer: I'm not a native English speaker.
Or you could say "It should return a mote" ... what could be more clear if you know what a mote is? I am actually very much liking the four letter term.
I don't like "computations", because a non-monadic value can also considered to be a computation. plus, it's really vague
haha, i support this movement, i hope this catches on
I agree that 3 or 4 shouldn't be called ‘monads’, and usually aren't in my limited experience. I generally call (4) ‘monadic actions’ instead, but I suppose that depends on whether you want to emphasise the side-effecting aspect or not. For example, I might refer to the IO monad (case 2), but I'd refer to ‘foo :: IO Int’ as an IO-action (or monadic action, in general) that returns an Int. The point I took away from that post is that ‘monadic type/value’ is too much of a mouthful, which is a fair enough complaint. Should ‘motes’ not gain enough traction, I'd humbly suggest the alternative ‘WAFTs’.
It's one more definition that you can misunderstand. Anyways, it's just my personal opinion, not necessarily the best one.
No, I think it's just a failure in the way we tech sometimes. Understanding evaluation order is really not that hard. You just look at a function, look at the result and see what demand that places on other things, working back towards the function arguments. The problem is thinking about the right thing at the right time: high level and low level. You don't want to think about evaluation order when working out how to solve the problem but then later you do want to think about it when thinking about how the program will behave.
yes but we use bind to feed it to the function
Awesome! I never bothered to read up on the mathematical foundations of Haskell, maybe I'll start now.
I like it, but I can't help but wonder if other category theoretic structurens would similarly benefit.
I'm not passing judgment. I'm just reporting a naming decision that has already been made. Haskell people often feel free to make up new names for stuff that already has names. The merits or punchability of this tendency I leave to others.
Let me think ... I usually think "monadic value" or "action". If we combine the two you get "motion", but that's two syllables. You can call it "mote" for short! 
Moval.
[Mobit](http://www.haskell.org/haskellwiki/What_a_Monad_is_not#Monads_are_not_values). Otoh, Mote seems to be intended to be more concrete than Mobit, so one could say `instance Mobit &lt;specific mote&gt;` And, no, Mobit was not intended to be a nonceword.
So, you would call `[1..10]` a monadic action? (Assuming, of course, a context where the Monadic qualities of a list were relevant)
Remember, lists are monads. Getting carried away with renaming computations on lists, doesn't seem like a good idea to me. So, yes, it is vague, but that is because monads are so general. (I do tend to use the term "actions" for computations in state transformers in lectures, though, if I want to contrast them with other code.)
I have been struggling to explain why I *don't* like the word "mote", and I think it has to do with giving a special name to that one specific instance of a general idea that comes up a lot: namely, a value of some type obtained by applying a type constructor to another base type. Monads are definitely not the only place this happens. Calling it a monadic type and a monadic value opens the door to talk about functorial types and values, or even more concretely, set types and values, or list types and values. These are connected concepts. I've said before that the more I get into Haskell programming, the less I tend to see monads as a core concept. They are important, sure, but important enough to tear them out of context and treat them as if they are some phenomenon on their own, rather than placing them in their natural location amongst related ideas? 
Another issue with looking in category theory for the answer is that Haskell differs from general category in that being the result of applying some functor to some object is what *defines* the object itself. That is, if there were no IO monad, then the type (IO Int) would simply not exist. In general category theory, an object in the image of a functor isn't necessarily anything special. You might choose to mention that it's the image of some other object in the functor, but that's one of many true statements about it, *not* part of its definition.
I don't think it matters all that much what we call things. Even if `Monad` becomes `WarmFuzzyThing`, it's still not something familiar from Java. The naming issues generate more heat than light. It's easy to have an opinion, and hard to definitively say that any opinion is wrong. See also: [Wadler's Law](http://www.haskell.org/haskellwiki/Wadlers_Law), [Parkinson's Law of Triviality](http://en.wikipedia.org/wiki/Parkinson's_Law_of_Triviality).
&gt; the less I tend to see monads as a core concept. I think you are absolutely right. Monad is nothing more than a design pattern, supported by some syntactic sugar.
In some contexts calling `[1..10]` an action is fine. In particular it is the non-deterministic action (or alternatively "computation") that evaluates to any and all of the numbers 1 through 10.
Oh, I think that's not really fair. The IO type constructor can stand perfectly well on its own without a Functor or Monad instance. The fact that the IO type constructor happens to induce a functor on the category Hask is just a bonus.
If it's not a nonce, can you point to another place it is used that makes it appropriate...?
Aren't arrows just a myth? :)
I see 3 and 4 being called "monads" all the time by newbies. Besides, in my native language (Russian) the translation of "monadic value" sounds so grotesque (monadicheskoye zhacheniye) that newbies get bored by just reading it, so a one-syllabic replacement will be very useful for me :)
You mean like this? instance (Monad m) =&gt; Mobit (m a) where ... What's the point of that? Would you ever have other instances? Why would you work with this class rather than `Monad` directly?
Was "A list is also a monad" really intended to mean a list *value*? It's not clear from context that that's the case. For example: "type constructor, `[]` (for building lists)"; clearly "lists" means "list *types*" in that instance.
*conceptually*.
I never claimed it isn't a nonce, but it also wasn't intended as such. I in fact tried to popularise it on #haskell.
What's the concept?
Each different kind of mote (list motes, maybe motes etc) all being mobits.
&gt; bail on me by jumping to another more lucrative position We actually had that happen (in Galois' favor) recently, with a couple of people with Haskell experience gained from one company, jumping to us. It's still fairly rare, but possible.
Great, I wanted this before and didn't know it is possible. &gt; This feature of cabal isn’t mentioned in the manual, at least I didn’t find it. Further, there seems to be no changelog for cabal. Maybe this feature is not officially released yet because of problems such as [#656](http://hackage.haskell.org/trac/hackage/ticket/656). Otherwise: Don't Conceal Useful Features!
Yes, this is very similar to Control.Monad.Prompt, which started out with almost the same data structure as Program. But there's a problem with Program; it exhibits O(n^2) behavior with binds nested on the left. Consider this program: ((singleton x &gt;&gt;= singleton . f) &gt;&gt;= singleton . g) &gt;&gt;= singleton . h It eventually gets translated to x `Then` (\a -&gt; f a `Then` (\b -&gt; g b `Then` (\c -&gt; h c))) But the parentheses moving from the left to the right takes n^2 time.
That reminds me of Asheron's Call.
I have opted to explain the simple version of `Program` in the tutorial, but the problem is of course fixed in the [`operational`](http://projects.haskell.org/operational/) package. :-)
&gt; One thing I have discovered in my writing life is that the clarity of a confusing document can sometimes be improved merely by replacing a polysyllabic noun phrase with a monosyllable. That's where I dislike the english language. I think the problem is not so much that the term has multiple syllables, but that it's a *noun phrase*. It's nigh impossible to write comprehensible sentences that contain noun phrases about technical topics. Compare that to German where it's perfectly fine to say Monadenaktionstransformationsfunktion ("monad action transformation function", I just made that up).
I usually use "monadic action" or just "action".
&gt; It's nigh impossible to write comprehensible sentences that contain noun phrases about technical topics. That sounds like an assertion you'd be hard pressed to back up with evidence.
&gt; monadicheskoye zhacheniye I'm calling them this from now on! Short names are for the weak.
probably not, the only thing i ever use arrows is for the functions: second, first, *** and &amp;&amp;&amp;
return takes a value and returns an "action"
Mote? Pfft. I vote for **mojito**.
It's correct, like you say, if "feed" means "&gt;&gt;=". But it could be interpreted to mean that the lambda actually receives something, i.e. "feed" means "value is applied to the lambda". In this example it never gets evaluated at all. I think it's potentially confusing for a learner. I found it confusing and I already know this stuff.
&gt; interpret :: State st retVal -&gt; st -&gt; (st, retVal) Where did the return type for interpret come from? We went through all this trouble to define our state monad operationally, but in the end it seemed to me like we already had to know what the state monad was (i.e. `st -&gt; (st, retVal)`) before we could complete our work. When you can derive the type `st -&gt; (st, retVal)` from `Get` and `Put` and the laws they are supposed to satisfy, then you will have reached your goal of defining a monad from its operations.
&gt; data Program m a where &gt; Then :: m a -&gt; (a -&gt; Program m b) -&gt; Program m b &gt; Return :: a -&gt; Program m a This is an (indexed) tree structure where `Return` forms leaves and the `Then` is a node that data of type `m a` and has a subtree for each value of type `a`. You can see the same structure in [IO Sematics](http://www.haskell.org/haskellwiki/IO_Semantics) where `Done` is a leaf like `Return` and each system call holds some kind of data and has one child per return result. I have an inkling that you should be able to define Program without GADTs, though you will still need it for StateOps. But it is just a small inkling.
This is my objection too. This privileges a particular concept too much; I wouldn't care to guarantee that in 5 years, the state-of-the-art Haskell won't have moved on to some other concept that will be the "primary" abstraction (which I suppose in this case is "the thing that `main` in implement in terms of", today the IO monad), like arrow or [parameterized monad](http://blog.sigfpe.com/2009/02/beyond-monads.html) or iteree-based IO or whoknows. And naming each of those things just doesn't scale.
Yeah, I'm going to call it a vrashch...that's one syllable, right? 
IIUC, translating the program to CPS form fixes this.
The GADT-ness for `Program` is only used for existential quantification. The `IO` semantics gets along without it because in fusing the `Then` with each operation, it can specialize to the concrete type yielded by each operation. So: GetChar :: IOop Char Then GetChar :: (Char -&gt; Program IOop b) -&gt; Program IOop b PutChar :: IOop () Then PutChar :: (() -&gt; P IOop b) -&gt; P IOop b ~ P IOop b -&gt; P IOop b However, if we had: Evaluate :: a -&gt; IOop a then: Then . Evaluate :: a -&gt; (a -&gt; P IOop b) -&gt; P IOop b even the fused version would still need existential quantification.
I'm not so concerned with whether main is implemented in terms of a monad; it looks like the right abstraction to me. I'm just less than convinced that it being the right abstraction for main makes it the right abstraction for any other particular use.
The post doesn't show this, but the type `st -&gt; (st,a)` is no longer mandatory. For instance, the following works as well: interpret :: State st a -&gt; (st -&gt; a) interpret (Return a) _ = a interpret (Get `Then` k) s = interpret (k s ) s interpret (Put s `Then` k) _ = interpret (k ()) s 
I would like to see the FFI covered, as this is something that can get really confusing for beginners (me) trying to integrate Haskell into their existing codebase. Thanks again Bonus!
I won't argue the point, but I have to admit it doesn't seem natural to me.
You'd be surprised how easy it is to pronounce :)
Apfelmus already answered this (and I bet he can answer much better then I could), but one of the points about the operational semantics is that you car write multiple interpreters. If you don't like `interpret`, you can write your own interpreter. Apfelmus' post have an example with the Random monad: one interpreter sample from the random variable and the other returns the probability distribution.
I prefer iota
&gt; It's nigh impossible to write comprehensible sentences that contain noun phrases about technical topics. This sentence appears quite comprehensible, despite containing such noun phrases as "comprehensible sentence", "noun phrase" or "technical topic".
"monadnoye zhacheniye" is a bit shorter and it will do :) I think "mon" sounds better as a monosyllabic version.
in this tutorial i aim to kind of show how &gt;&gt;= is just another function for application, much like ($), so i kind of went off from there. even though &gt;&gt;= is called bind, i don't like describing "m &gt;&gt;= f" as "m is bound to f", because binding is already used to describe binding something to a variable, like in let expressions or in where. what would you suggest instead?
It is impossible to *definitively* say whether he's got the perfect most optimal solution, but that doesn't mean that other choices are *clearly worse*. Many important things in life are like that. Furthemore, Mark-Jason Dominus did offer some solid criteria for evaluating whether a name was useful or not. He asserted that: * "Monad" was being used in several different senses, and * small words reduce cognitive load. Which to me are obviously true, but we could at least discuss it rather than dismissing the argument out of hand. Finally, if you want an authority on how to teach functional techniques to average programmers, Mark-Jason Dominus has demonstrated expertise. He is a published author of a book which explained Lispy techniques to the Perl mainstream (Higher-Order Perl), and given classes called on similar themes for years. In the mid-90s and early 2000s he was the highest rated tutorial presenter at O'Reilly conferences. The Haskell community would do well to consider his advice. Actually, if MJD were to write a Haskell book, it might definitively end the infinite stream of articles that try to explain Monads.
I prefer [jot](http://esoteric.voxelperfect.net/wiki/Jot)
Sure, but there would be no way to access them from Haskell. After all, how would we name them if we didn't name them `(IO a)`? Sure, we could make up other names which have the same functorial structure, but the point is that we *want* the functorial structure precisely because it expresses a relation between the preimage and postimage of the functor. But in category theory, that's not important. Both categories exist prima facie, and discussing the relation between them is just to note that there exists a functor between them. The use of `F X` to name the image of `X` under `F` is just a convenience, it doesn't *mean* anything in the way that it means things in Haskell.
[Oh no!](http://github.com/noteed/mojito)
lol
...for values of "as well" that doesn't include performance, although the reduceron's performance is very notable, indeed, as it can be more or less equated to the Pentium by educated guessing which isn't a trivial result, considering that Intel has a bit more manpower and experience.
There is also a follow-up article [here](http://mvanier.livejournal.com/5846.html) which gives a fully-worked example using state monads.
See, as far as I am I know they are. Which is why I wanted to know. :)
What other values of "as well" are there? Surely, OP is not talking about *interpreting* a 3 ghz Pentium.
Make that "absolute performance", and it makes sense, again. In fact, the Reduceron definitely interprets Haskell more elegantly, parallelising reductions and doing them in one clock cycle etc.
Well, it's already ambiguous (although that's not due to noun phrases). :-) Namely, is it the noun phrases that are about technical topics or is it the comprehensible sentences that are about technical topics? I could have written "comprehensible sentences about technical topics that contain noun phrases", but then it would sound like the technical topics and not the comprehensible sentence contain noun phrases. In other words, no matter how I order the adjectival phrases "about technical topics" and "that contain noun phrases", it's not clear that they both refer to the comprehensible sentences. Also... what do you think of the comprehensibility of this paragraph above? ;-)
I think it's best for people to suggest topics that they understand and know first-hand of their importance. Imagine being introduced to the vague philosophical texts of Zarakostrabrafuldor. You try to comprehend it but it really isn't working out. Then, a group of intelligent looking people (they have glasses) start discussing it and it seems as if they know what they are talking about. Either they are all just as confused as you are, but are very good at make believe, or in fact there is some profound truth in Zaratoskrabrafuldor's writings and it's only you failing to see it. It's hard to tell. Do you think it would be a good idea to pull BONUS_ to explain Zar's idea which as far as you know may even not be real? Imho something like that which [Peaker did above](http://www.reddit.com/r/haskell/comments/d51ao/lyah_intro_to_monads/c0xp88s) (to suggest a topic that he really understands and also offer a good explanation on the specific topic) is much more productive and useful. Inception
very thorough, very cool. i like
Thanks!
does compiled haskell still run faster than 3ghz pentium?
I guess, they mean something like "Haskell, written in the most straightforward way, compiled with the default options" - I guess you'd need a miracle to reach the (very good) Haskell results on the alioth shootout even (or especially) with a massively-multithreaded processor that can take advantage of Haskell's declarative nature.
I think some of the pdf slides mentioned ghc -O2 as a comparison, and test programs can be found in the papers.
What does “absolute performance” mean? Counting cycles rather than wall-clock time? (Sorry, non-native English speaker here.)
Is this a return to a CISC?
According to [this source](http://www.google.com/url?sa=t&amp;source=web&amp;cd=1&amp;ved=0CBUQFjAA&amp;url=http%3A%2F%2Falphamike.tamu.edu%2Fweb_courses%2Fcpsc321%2Ftransparencies%2Fmips_x86.pdf.gz&amp;rct=j&amp;q=mips%20vs%20x86&amp;ei=gCV5TJKPKpGmnQe5o5GdCw&amp;usg=AFQjCNEpWVT8ZouRJ_zbkd_mTlcFswY-9g&amp;cad=rja), x86 IS CISC.
According to the 2007 paper, the reduceron is faster than any bytecode interpreters (Hugs, NHC). ghc -O2 results are reported too, which are 3-10x faster on a P4 with 2.8GHz than the Reduceron. (Which is still impressive, because the Reduceron uses the same bytecode as Hugs/NHC, and doesn't do the fancy stuff that ghc does)
The implementation notes on these pages are *well* worth reading for anybody interested in functional language design and implementation, if you ask me.
Hmm, fair point :-). However, most of the instructions used in modern programs/generated by modern compilers are part of the rather 'restricted' subset. Also, most of the complex (legacy) instructions are microcoded in a RISC style iirc (then again that is quite similar to the proposed processor I guess).
X86 was always CISC. RISC type processors generally only have store/load for working on memory. Normal operations are register only. But that's only a guideline as such. SPARC has atomic fetch-and-add instruction, which is would be more of CISC type instruction.* Intel CPUs are effectively RISC processors with a hardware translator, since the pentium pro iirc, though I'm not sure about Atom. The 'micro-ops' as they are called allows for multiple instructions and/or parts of instructions to be processed in parallel. A specialized piece of hardware called the retirement station re-orders the results into the order the instructions entered the core. tl;dr desktop/server x86 hardware are CISC frontends to RISC cores. Edit: Atom chips also do CISC to RISC micro-op translation. * The fetch-and-add part, you can ignore the atomicity part there.
I wasn't suggesting that he *does* go into arrows - I was *asking* if he was.
So what is the app about? I don't see anything obvious in the link, and clicking the link to the app itself apparently requires installing a client-side application just to get information?
sorry, here's a link viewable in browser: &lt;http://itunes.apple.com/us/app/source-code/id384046187?mt=8&gt; it's just an app that displays source code for open source projects in various repository formats.
Looks really, really nice. Great work! (I hope to see this look on hackage.haskell.org soon :)
+1 That looks really really good; that would be a sweet new look for Hackage.
Looks nice! I suggest incorporating information about the last time it was updated. That would help people know whether the package has been abandoned -- like all of mine. :(
read "as well" like "as good as". The point the OP meant is that the clock rate is rather low but it can perform haskell operations in very few clock cycles. Regular cpus are rated in FLOPS (floating point operations per second) and various general benchmark software too. I presume some sort of haskell specific benchmark has shown this cpu to have similar performance as a 3ghz pentium.
Beautiful! Can you rework the Haddoc default doc template in the same style?
I was under the impression he meant a specialized instruction set.
&gt; I presume some sort of haskell specific benchmark has shown this cpu to have similar performance as a 3ghz pentium. Table 4 from the ICFP10 paper shows it to be a good bit slower (1.5x-10x).
That's really nice. I would love to see haddoc docs in that style as well.
You can't remove a source once it's added. This is especially bad if there is a typo in the url
Performance before arguing that a RISC on the FPGA the Reduceron runs on is about 40 times slower than the Intel.
I like it.
Wow, I just started actually looking into the papers. Apparently, they translate algebraic data types to continuation types that involve only lambda abstractions and primitive types (ints). A notable consequence: Haskell's “Bool” type is *compiled* to Church booleans!
Another suggestion is to add release notes/change log section.
I found a grammar error: "we're going to have to manually check the if the laws hold"
swipe horizontally on top of the project in project list view will trigger the delete button to appear :)
this reminds me of debian website for packages
I have a suggestion for the display of the dependencies. Namely, the version ranges introduce a lot of clutter. I propose to omit the parentheses and write them *below* each package name, in a slightly different front (italics, for instance). In other words, package name and version range are joined vertically instead of horizontally.
Mark Lentczner has done a great job improving the generated HTML and the stylesheet for Haddock: http://www.ozonehouse.com/mark/snap-xhtml/containers/index.html At some point we should pick a common palette and set of fonts and font size for all pages under haskell.org. Right now I'm happy things are moving forward.
Nice! +1
This looks awesome. Is there an example of how to do form submission? Thanks snoyberg! 
Something like this maybe: handleFormR :: Handler App RepHtml handleFormR = do (res, form, enctype) &lt;- runFormPost $ stringField (string "My Field") (string "") Nothing let mhtml = case res of FormSuccess x -&gt; Just x _ -&gt; Nothing applyLayoutW $ do wrapWidget (fieldsToPlain form) $ \h -&gt; [$hamlet| %form!method=post!enctype=$show.enctype$ ^h^ %br %input!type=submit %br %br $maybe mhtml html $html$ |] Based om the more extensive [widget example](http://docs.yesodweb.com/yesod/tutorial/widgets.html).
Nice work indeed :-) I would make dependencies more prominent (eg larger font): I spent quite a bit of time glaring at dependencies of packages... It is a pity that hackage2 won't support changelogs?
How would changelogs be supported? Old discussion.
This is great news. It makes you wonder what other performance improvements are lurking in other highly used libraries.
There's a [source repository](http://code.haskell.org/QuickSpec). But it ain't on Hackage is it?
Many I think, unless someone went over the code specifically looking at performance (e.g. by reading the code and writing benchmarks).
̶P̶i̶c̶s Hackage or it didn't happen!
so how about it? everybody grabs a library and tries to make it more efficient. see you in 15.
I just added a form example to the [code section of the doc site](http://docs.yesodweb.com/examples/). Tim_M is mostly correct, but the syntax has changed a bit in 0.5.
Yay, free speed!
There's a tension between having something fast for hundreds of thousands of people now, **today**, versus modifying GHC, and benefiting the same hundreds of thousands after the ICFP paper is published. I'd also like to write more ICFP papers.
I'd actually make the dependencies *less* prominent. That's a bunch of overwhelming noise to present, and they're pretty well unreadable.
The idea of this project is to really exploit knowledge of the process of reduction to improve program performance. The Reduceron utilises wide memory buses, low-level parallelism and other tricks to try and get as much of a reduction done in one go as possible. As such, it doesn't really use an instruction set as one would usually describe it.
Thanks to everyone that made these three patches happen; more speed is always win. Especially in something so commonly used as Data.Map
You really put alot of effort into your monad tutorial series. Thank you!
You're welcome! It's a fun topic to write about.
That means almost nothing, since they're written in very different languages. FTA: &gt; If you're just comparing C to Haskell it's a factor of about 4. That's probably close to the common factor between a Haskell program and a C program with similar features. Without any scientific backing, I'd even wager that the factor might be higher in many cases.
Git doesn't lock sometimes when committing either... ;)
Jeebus, why are there so many bash files in darcs?
They're not comparable on a feature-for-feature basis. For example, `git blame` in a Linux source tree finishes in a fraction of a second, while `darcs annotate` in a GHC tree spins for several minutes, then quits with a stack overflow. Darcs is an interesting program, but I don't think it's a great success story for Haskell. I should note that I haven't used darcs enough to say that it's good or bad, but I think there's enough issues to make it questionable as the Haskell poster child.
Meanwhile, a similar program written in APL would probably take about 400 lines, at most.
What I'd like to know is why each of these have so many different languages involved.
That is the most useless piece of information I have ever seen. So this person includes CSS and HTML as part of the code base and says that git has 200k more lines. And forget the fact...that they are two completely different programs. WTF.
I agree that they are not comparable; the darcs algorithm and the git algorithm are different. maybe that results in the code size difference. Then again, maybe not. :D Though I bet the algorithm difference causes the stack overflow and it's not an inherit feature of Haskell. IMO I think the git system is "better" but i still use darcs for small projects because darcs is easier to use. YMMV
It appears that this has been an [open ticket in GHC for four years now](http://hackage.haskell.org/trac/ghc/ticket/888), so I'm glad Don decided to actually go out and do something rather than keep waiting. 
&gt; Though I bet the algorithm difference causes the stack overflow and it's not an inherit feature of Haskell. "Stack overflow" means something different in GHC Haskell than in most languages/implementations. It's a matter of excessively nested pattern-matching / evaluation, not excessively nested function application. It is hard to untangle laziness from algorithm design. A lot of lazy algorithms won't work at all in a strict context. A lot of strict algorithms will perform terribly in a lazy context without extra care.
It would have been nice if the author would have just said, here are numbers for darcs and here are the numbers for git and be done with it. I don't understand how he could have seen any comparison.
I think it's about 10 to 1...
Well, the best solution would be to improve the compiler in such a way that tuning programs becomes very predictable and can be done solely with RULES pragmas. The worker/wrapper transformation seems to be a candidate for the latter. There a few rules of thumb (unboxed types, tight loops, stream fusion) for getting high performance Haskell code, but they require manual intervention and you have to break abstractions to apply them.
I took the quote out of context and linked to the source so you can see where it came from. I think the patch is great and well worth applying but my question aims in a more general direction. I am trying to form an opinion based on evidence whether there is a tension or symbiosis (or both) between hacking on libraries and hacking on the compiler. There is a tension if highly optimised libraries release compiler writers from the pressure to improve code generation. There is a symbiosis if library improvements lead to compiler improvements in the long run or if compiler improvements help to write more efficient code, for example, via RULE pragmas. Do you know examples where efficient coding techniques found their way into the GHC optimiser? Or examples where you think a smart library writer reduced the need for smarter code generation? Go out and hack on libraries. And if you find something more general is going on, hack on a compiler. I think this is independent of writing papers.
&gt; Go out and hack on libraries. And if you find something more general is going on, hack on a compiler. Well, that was the motivation for starting the new language [Dyna](http://www.cs.jhu.edu/~jason/papers/#acl04-dyna): a whole lot of the optimizations for making natural language processing fast all look the same after a while.
Oh, I didn't mean "go, write a new compiler" but "go improve an existing Haskell compiler"!
Holy crap, that is awesome! Things like this really highlight the value of pure interfaces.
I've been toying with this framework and eagerly watching progress. This is an excellent framework to work with. 
Obviously because it's more convenient to write parts of the system in other languages than figure it out in the "core" language :-)
is it something like wascally, as in wascally wabbit?
If you get into haskelly habits you'll write great code!
Look like most of that is our test suite. find tests -name '*.sh' | wc -l gives me 296
For what it's worth, annotate is due for some TLC after Darcs 2.5 is out. We have a patch index optimisation in the works which will reduce the effect of patch history size (it associates filenames with a subset of the patches, so darcs has less to comb through), and a promising proposed reimplementation which has already given us some [nice improvements](http://pastebin.dqd.cz/hSYd/) without the patch index. We'll get there!
Hmm.. I think I've found a bug in GHC, the RTS or STM library for Windows (HP 2010.2.0.0). After some random period (0-10 seconds), the ant activity suddenly drops by 90% or so. I guess it's a deadlock issue, as ram and cpu usage don't change much. Recompiling with -threaded seems to fix the problem, but makes profiling impossible. **edit:** added 'suddenly'
* Haskell (169 files) - Darcs is primarily written in Haskell * sh and bash (303 files) - Looks like our test suite * HTML and CSS (6 files) - home page * C and headers (19 files) - some low level code deal with locks, permissions, talking to libcurl. Perhaps some of these could be rewritten in low-level Haskell * Perl (2 files) - contrib scripts, one of which acts as a backend supporting darcs send over http, another providing integration between our Darcs repository and our bugtracker * make - leftover makefile to build documentation (we use Cabal nowadays) * Lisp - looks like an Elisp contrib file for hoogle/emacs integration on the Darcs API
It's not a compiler bug or any major issue. It was just that my code sucked! Performance was pretty terrible with that version after a bit of time. I spent some time on it (http://www.fatvat.co.uk/2010/08/speeding-up-ants-program.html) and its much faster now and hopefully more stable (though it still leaks a little memory according to the space profile). dons gave me some hints on how to fix that, so I'll do that once I get a chance.
So, TL;DR: it made sense to do it that way. Sounds reasonable to me.
I've pulled any changes and recompiled, still have the same issue. There's a slight increase in memory usage when things suddenly go slow, about 100k allocation over a second, then it turns into a slowly rising graph again. And considering it works fine with -threaded, I think we can clear your code of any blame. 
&gt; Python does not have a convenient lambda, which is why asynchronous frameworks like Twisted are so painful! Uh, Python does have lambda -- it's even called `lambda`. Sure, `(lambda x, y: x * y)` is a bit more verbose than `(\x y -&gt; x * y)`, but not significantly so.
Hence Edward saying "convenient"? Python's lambda is almost useless.
How so? The only difference between `lambda` and a procedure is that lambdas can only contain one expression. Haskell lambdas (indeed, all haskell functions) have the same restriction.
&gt; We associate programs that take advantage of these language features as “Haskelly” because Haskell makes it easy—both syntactically and conceptually—to use them! Of course, the reason that we (or at least I) use Haskell is because we believe that is is "better" to write programs in this style. I just wanted to make sure we are all clear that we don't use these features because Haskell makes it easy, rather we use Haskell because it makes using these features easy. I'm sure the original author is aware of this too.
Haskell functions are all one expression, so it's evolved ways to make this work when you need more than that. Python, because it has other ways to write complex functions, doesn't offer these affordances. Furthermore, the predominant style in Python (which you are then pretty much forced into using if you want to interface with existing libraries), demands such multi-line functions. This makes using lambda in Python less joyful. I make no value judgement on whether this is a good or bad thing, however.
Haskell expressions can be arbitrarily long and encompass the entire language. Because of the significant whitespace python expressions are much more limited. Before python 3 you couldn't even do something like: map(lambda x: print "Found an %s" % x, xs)
Never seen snoc, but from its name I guess it's sort of a reverse cons, appending an element to the end of a list. snoc :: [a] -&gt; a -&gt; [a] snoc xs x = reverse (x : reverse xs) Am I right?
Sure you could. `print` is broken in 2.x (for various reasons), but proper style like `sys.stdout.write()` work fine: from sys import stdout map(lambda x: stdout.write("Found an %s" % x), xs)
Yes, but that is not so interesting. What is interesting is that snoc sounds like some kind of exotic crocodilian. Maybe it's the one thing from Haskell that may prove to be revolutionary. Will we one day discover real life snocs? What are snocs? Where are there snocs?
You might not know this, but Git struggled with annotate/blame at one point too. They had memory exhaustion problems also. You can see from this thread on their public mailing list: http://thread.gmane.org/gmane.comp.version-control.git/67890/focus=67953 The difference is that Git devs already spent the time to fix their inefficient blame command but darcs has had other performance priorities. I think darcs 1.x also had a more efficient annotate than the current darcs. I think Git also has more contributors due to its use on the linux kernel, which if properly coordinated can make it faster to get things fixed. Fortunately, these days darcs developers take regular performance marks and are committed to closing the performance gap between darcs and git.
You don't *need* to use procedures in Python. It's the common style, but it's also possible (and relatively easy) to write LISP-style expressions. Every imperative-style statement can also be accessed as an expression, and it's even possible to use Haskell-style imperative constructs (Monads) if need be. In fact, when writing declarative Python, my biggest gripe is that the `if` statement is backwards. This is quite a minor complaint.
The reason I thought there would any comparison is because git and darcs solve a similar problem. Distributed version control. They take approaches that are dual to each other. One focuses on the transformations between states and the other focuses on the states themselves. In one you have to derive the states and in the other you have to derive the transformations. So both of them really have to do the same work in terms of implementing features. Therefore, the comparison comes down to that of developer culture, language choices, engineering practices, and so on. Perhaps I should have added more of my speculation. Claims I could have made: * Haskell is less verbose than C * Performance requires more lines of code * Source code size is proportional to project popularity * State based vcs requires more code than transformation based vcs * Git hackers like to write shell code, even more than darcs hackers I think most of those are untrue, but what I've read of the Git source makes me think that C is more verbose.
Why did you include the CSS and HTML in the results?
I didn't per se. That's just how cloc works, but... * Neither contributes significantly to the total line count, yet both are things included in the project. * Some human had to think about them and write them. * They require human attention and maintenance. I could have figured out how to make cloc not count them, but I still think they're interesting. Feel free to ignore their contribution when you look at the numbers.
OK, I agree now. I made some further changes and now on Ubuntu 10.04 x64 I produce exactly the symptoms you've described. Recompiling with -threaded fixes the problem. I guess now the battle is trying to narrow it down.
I agree. However, style is what really makes a language, since everything is always possible. It all comes down to a matter of syntax, taste and community. In Python, lambdas are simply not frequently used because it is not part of that style, and the broader community does not hold to it. One pays a cost to work in such a style when the common tools do not work to aid one. Sometimes the cost is worth it --- but it is an individual decision to be made.
heres how i imagine them http://dl.dropbox.com/u/665999/snoc.png
Maybe dons knows better, but I'd say that's pretty much what they would probably look like.
Well, google's "I'm feeling lucky" says that snoc is "The Canadian Manufacturer of Residential Outdoor Lighting Fixtures". Sometimes I believe there must be a very weird world on the other side of my front door ; )
Yes, but with System FC you don't need to go outside anymore to entertain yourself. It might even be dangerous. There might be snocs there.
&gt; It's the common style, but it's also possible (and relatively easy) to write LISP-style expressions. Not quite. Because Python's statements are all that, statements, not expressions. `if` is not an expression, `while` is not an expression, `for` is not an expression, ...
&gt;In Python, lambdas are simply not frequently used because it is not part of that style, and the broader community does not hold to it. I would say the real reason is that Guido doesn't like real lambdas so he thinks they are redundant for the community. I'm pretty sure there are many people in the python community really want decent lambdas.
Now you are just arguing over semantics. Python's lambda is annoyingly crippled unlike say javascript's or perl's because of Guido's dislike towards anonymous functions. Haskell's lambdas might be limited to one expression but that is not a real limitation. Let's compare python to an imperative language like perl for a more fair comparison. How would you do the following in python: my @with_p = grep { print "Checking $_ for 'p'"; /p/; } qw/perl python haskell/; @with_p =&gt; qw/perl python/; (Yes, I know this example is very contrived) To do this in python you would need to define a function and then do a filter( the_func, [...] ) but this is not the same thing. 
We would absolutely name them `IO a`. But if you read your own post, you'll find that you're conflating the _type constructor_ `IO` that maps types `a` to types `IO a` and the _functor_ IO that maps objects and arrows from category `Hask` to objects and arrows in category `Hask` (by prepending the `IO` type constructor to objects and embedding the arrows into the `IO` computation). cdsmith's original claim was that defining the `IO` type constructor happened by defining the `IO` functor; I claim that isn't fair, that the type constructor itself is perfectly useful even if there's no corresponding Functor and Monad instances (as are many other non-monadic type constructors).
I'm also eagerly watching this framework (sorry I'm not much of an early adopter). Keep up the excellent work snoyberg!
Honestly, I'm not surprised by these results. We all know full well that c is one of the most low level and verbose languages out there. In fact, I would be extremely surprised if git's codebase was comparabale in size to darcs'. How about a comparison with hg instead? hg is written in python and such a comparison would be far more interesting to me. 
I'll leave those questions to be answered by the Snocodile Hunter. We just have to find him...
`if` is an expression: `a = 1 if True else 2` `while` and `for` aren't expressions, but neither are they needed -- proper declarative Python should use `map`, or perhaps a user-defined `map_` (for procedures without side effects).
I'm absolutely baffled as to what that Perl is supposed to do. Could you rewrite it in Haskell, so it's more readable?
 ghci&gt; filter (elem 'p') ["perl", "python", "haskell"] ["perl","python"] To be entirely equivalent, it should use [`filterM`][1] from Control.Monad: ghci&gt; filterM (\s -&gt; putStrLn ("Checking " ++ s ++ " for 'p'") &gt;&gt; return (elem 'p' s)) ["perl", "python", "haskell"] Checking perl for 'p' Checking python for 'p' Checking haskell for 'p' ["perl","python"] Making the semicolon visible, we get ghci&gt; filterM (\s -&gt; do { putStrLn $ "Checking " ++ s ++ " for 'p'"; return $ elem 'p' s }) ["perl", "python", "haskell"] Checking perl for 'p' Checking python for 'p' Checking haskell for 'p' ["perl","python"] [1]: http://www.haskell.org/ghc/docs/6.12.2/html/libraries/base-4.2.0.1/Control-Monad.html#v%3AfilterM
The best example is stream fusion, which drove the inliner and rules engine massively, and lead to constructor specialization, and the LLVM backend.
Close, but you also have to print the string that you are checking. (That's the whole point because python lambdas cannot have 2 statements).
See edit!
Yep. jmillikin, look at gbacon's example. Have an upvote!
 &gt;&gt;&gt; from sys import stdout &gt;&gt;&gt; filter(lambda s: (stdout.write("Checking %r for 'p'\n" % s), 'p' in s)[-1], ["perl", "python", "haskell"]) Checking 'perl' for 'p' Checking 'python' for 'p' Checking 'haskell' for 'p' ['perl', 'python'] 
I've implemented his example in Python
Cool trick! But to me this looks like a hack because if you want to add more statements you need keep incrementing the index. Also, the syntax looks very unnatural.
Sorry, I made a small typo -- the index should be [-1], so it will always pick what's in the last position. The syntax doesn't look any more unnatural to me than LISP's, though it's not as elegant as Haskell's or imperative Python. And it demonstrates that Python's lambda is not "crippled", as so many ignorant bystanders love to claim. It's a fun exercise to implement simple things like tic-tac-toe or the game of life in declarative-style Python, though I suspect most Python users would rather hammer themselves unconscious than read it.
&gt;And it demonstrates that Python's lambda is not "crippled", as so many ignorant bystanders love to claim. Python's lambdas are still crippled. Can you add an if statement after the printing? Can you define a lambda inside the lambda? Most other languages have this limitation. I'm not a python hater but this is the one thing about the language that really irks me.
&gt; Can you add an if statement after the printing? Yep! &gt; Can you define a lambda inside the lambda? Also yep! You can go pretty far with just `lambda` -- for example, this is a simple duplicate-file detector I wrote a while back to prove this point to somebody (ignore the `and`/`or` ugliness -- this was before inline `if`): import sys import os import hashlib check_path = (lambda filepath, hashes, p = sys.stdout.write: (lambda hash = hashlib.sha1 (file (filepath).read ()).hexdigest (): ((hash in hashes) and (p ("DUPLICATE FILE\n" " %s\n" "of %s\n" % (filepath, hashes[hash]))) or hashes.setdefault (hash, filepath)))()) scan = (lambda dirpath, hashes = {}: map (lambda (root, dirs, files): map (lambda filename: check_path (os.path.join (root, filename), hashes), files), os.walk (dirpath))) ((len (sys.argv) &gt; 1) and scan (sys.argv[1])) 
I am willing to bet that you are the only one that would consider this syntax natural or convenient (even when compared to lisp). If only Guido would let us use optional braces to enclose the lambda block your code would be a lot more neat.
It's not natural, or neat, but it is *possible*. I'm fine if you want to say "multi-statement lambdas are ugly in Python", but please don't spread around nonsense by calling them "crippled".
Sure. But the fact that most people would just rather define a named subroutine than go through all the hoops you posted is evidence of the fact that lambdas are "effectively" crippled. E.g. OOP in C is possible, but you would still never want to do it (Although lambdas are a much more minor issue).
How does this compare to hmatrix-static on Hackage? 
Why the link to a four year old email?
It looks good, but requires side scrolling on my (admittedly narrow) screen.
You might also be interested in [this thread](http://www.reddit.com/r/haskell/comments/9mbnc/any_solution_to_the_accessing_nested_records/), and these posts by Edward Z. Yang: * [Inessential Guide To Data Accessor](http://blog.ezyang.com/2010/04/inessential-guide-to-data-accessor/) * [Inessential Guide To fclabels](http://blog.ezyang.com/2010/04/inessential-guide-to-fclabels/) Finally, there's also the [sec](http://hackage.haskell.org/package/sec) package.
I wrote [fields](http://hackage.haskell.org/package/fields) a while ago. It's based on fclabels, and offers infix syntax (similar to what you'd find in OO-languages) and additional combinators for fclabels lenses.
I'm one of the contributors to fclabels, and last time I checked our package differed in an important way: we have instances for both Applicative and Category. The Category instance allows you to compose labels "vertically": you can point deeper into datastructures. The Applicative instance however allows you to also compose labels horizontally, for example, to select two fields and combine them into a new datastructure.
Would you (the fclabels devs) have any interest in merging the fields library (or just a part of it, I guess the Indexable stuff could go), into fclabels, perhaps as a sub-module?
One of our goals is to keep the core of fclabels as small as possible, but I can see that a submodule would work. Just send us an e-mail with a proposal, or fork fclabels on github ;)
Stream fusion is a good example of how the development of a library raised the demand for better compiler optimisations. I didn't know that it lead to the LLVM backend! Can anyone elaborate on how stream fusion influenced it?
sec is actually not about "Functional references", but provides a very minimalistic interface for manipulating different kind of data... even Monads and functions. It even supports the implicit use of predicates to decide wether to modify a value or not
The LLVM backend was speculated as being good for tight loops, such as those produced via stream fusion of bytestrings or arrays. A student project was undertaken, and confirmed the suspicion.
Isn't considering 1 to be a prime the right thing? Z_1 is an integral domain and a field, I think. It often simplifies definitions to consider 1 a prime (as Dijkstra observed).
I think criterion graphs are useless - the only thing you care about is the mean time and the (boolean) information if there was something wrong during benchmarking. I prefer (the type of) graphs made by progression - after all you want to compare two "values" - do it on just one graph.
Z/1 isn't considered a field where I live due to it having only one element (1 /= 0 does not hold), but that's just a matter of definitions. Isn't the motivation for not considering 1 as a prime number that 1 is a unit in Z, and units aren't considered for prime elements or irreducible elements? (Such that, e.g., prime factorisation is unambiguous up to order and units.)
kudos to dons
I added a link to this to the [wiki page](http://www.haskell.org/haskellwiki/How_to_profile_a_Haskell_program).
Calling Z_1 a field is stretching it, I admit. But all non-0 elements do have an inverse. :)
Awesome. But all CPUs do major GC together, I presume?
still stop-the-world... :'(
That's right. 
There's also [DeepArrow](http://haskell.org/haskellwiki/DeepArrow), which has the general version of semantic editor combinators (SECs) for "deep arrows" (not just functions/values). DeepArrow forms the basis of [Tangible functional programming](http://conal.net/papers/Eros/) for manipulating not just simple values but also types, GUIs, and code as well. The latter three work by using deep arrows other than `(-&gt;)`.
Yes, there seem to be some philosophical discussion whether the zero ring is a field or not. I have no strong opinion in this matter, but it surely look nicer with having 1/=0 than 1=0. :) Btw, I could have skipped the Pos constraint since Z_0 = Z/(0) = Z. But this felt a bit silly and I didn't want to modify mod so that it performs somethings sensible in this case. :)
Most axioms for fields that I've seen explicitly have 1 /= 0. The [field with one element](http://en.wikipedia.org/wiki/Field_with_one_element) is an interesting beast, by the way :-)
Is it possible to split up major GC so there's no stop-the-world?
Semantic editor combinators are similar but still quite different from lenses/accessors.
I've used [data-accessor](http://hackage.haskell.org/package/data-accessor) in the past (not on your list) and it has worked really well for me. &gt; By the way, do you think it is something that should be included in the haskell platform ? Or maybe there's something going on in GHC to improve records in the future ? I think the HP should be ignored. Just use whatever package you think is best for your task. My complaints about HP really belong in a different thread.
More info about Snocadiles please. 
&gt; I'm not worrying much about these missing libraries. Someone will write them once they need them and publish them somewhere So you don't care whether real world functionality will be available next week or in 10 years? Is that related to you being busy writing your PhD thesis on zygohistomorphic prepromorphisms? ;)
You'd get lots of overheads for that. It's also very hard to implement. Most Java realtime-GCs are actually still only mostly-concurrent. They do marking in parallel and have a shorter stop-the-world phase.
and tibbe
And Utrecht, for being a nice place to hack.
That's not if but the ternary operator which was introduced in Python 2.5. Technically, it doesn't have anything to do with the if statement (except when you want to talk about the implementation, of course).
Minor GCs are very quick (a few ms at most), so although they stop the mutator thread the pause shoudl be short enough for most uses. Major GCs are a bigger problem for pauses of course - maybe we'll do something about pause times in the future, but right now the focus is on improving scaling. 
Yes!
I think my code is to blame. I changed the way evaporate worked again thanks to some feedback and it appears to work properly now in all cases. My understanding of the problem is that I was trying to do evaporate as one big transaction which ended up getting repeatedly retried. What I really wanted to do was just evaporate on a cell by cell basis and commit, rather than do the whole lot at once. That's just a guess at what was happening though!
I like this 'lets make everything faster' sprint.
The issue is still there on my windows pc. But it runs fine under linux, and after compiling with -threaded. Commit cfeec71ef93f1a632e82700d2c7a33f Not that I expect you to debug it or anything, just saying it's probably something other than what you've been seeing. 
As a new Haskeller (ite?), I use this as my window into the Haskell world (along with planet.haskell.org, but I don't have enough time to keep abreast on IRC). The reddit#haskell community seems nice, smart and interesting so keep it up! I really enjoy the tutorials/blog posts along with the internal GHC/library announcements and ticket links. So keep em' coming. I can't really think of anything else that needs doing that isn't already being done.
keep calm and carry on!
&gt; Reduceron uses the same bytecode as Hugs/NHC Nope. It uses the same *frontend*, but it translates the code into supercombinators (top-level functions with no free variables) and then uses a custom instruction set. YHC uses a stack-based bytecode format based on the Spineless G-machine. Reduceron is *not* an interpreter for or hardware implementation of this bytecode.
The concept of monads seems a bit obscure. A tutorial or two on the subject would be nice.
For a second I thought you were serious and then I nearly fell of my chair laughing.
...and also get that warm and fuzzy feeling that things are only getting increasingly more awesome...
By including a ChangeLog file in hackages? Or just have a changelog box on the upload page perhaps.
This is my favorite reddit.
It'd require a brand new gc to avoid Stw behaviour.
Git has much more features. Compare any of the following for git and darcs: * number of commands * number of configuration parameters * size of the documentation to feel the difference. Have darcs got in-repo branches support at least? OTOH, the part of the difference is of course due to high-levelness of Haskell.
Oleg is a strongly-typed version of Nabokov: &gt; The new libraries are faster (so the reader who may wish to play will have less time to think) This one is great too: &gt; It pays to use CCCxe in code with long stretches of determinism punctuated by fits and restarts. 
Less posts, more high quality libraries.
How about 3 posts per library, and one tutorial?
The complement of stop-the-world is not necessarily realtime or even incremental. See [on-the-fly collectors](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.8405) for instance.
I liked: &gt;In Python, 'yield' is a keyword and generators are built-in. In Haskell, yield is a regular, small, user-defined function, and generators are programmed-in. In your face Python.
The lectures are great, but am I the only one that thinks that Dr. Ralf Lämmel looks a little like the PC guy from the apple ads?
Nifty...
i one day hope to be as bad ass as Oleg.
Is Silverlight safe for my machine, or am I going to regret this?
/r/haskell is the only reason I'm registered on reddit. For me it is a very convenient source of Haskell news: well structured, not too much traffic, and rss is available. The IRC channel distracts me too much, I even don't manage to read all the haskell-cafe (and I prefer it via gmane). /r/haskell and the planet are just right for me. It would be nice to see links to some interesting discussions on haskell-cafe posted here. Always nice to see tutorials and similar content. 
yet another post without a content.
I have a Schemer friend who just *loves* to say about any language feature, "that's a macro in Scheme". For example: "Static typing? That's a macro."
I believe a blog post is a good way to simply share some thought and spark some discussion. Calling it 'without content' is a bit overstretched.
That would be [John Hodgman](http://en.wikipedia.org/wiki/John_Hodgman), by the way.
yet another comment without content.
He writes a post every 2-3 days (4 posts in 9 days). There's only so much "tech" stuff (that deserves to be published) in a month. You post more often and it starts to look like twitter, only longer (or live journal?). All I see in his posts (most of them, I did enjoy a few) are links and paraphrases of other people's posts. It's not enough for an interesting read. Here's this post: "There are 3 libraries for session types. One of them has unreadable types". I know saying this out loud makes me look like a bigger douche than I really am, but I had to. Downvote me all you want - I deserve it and I'm ready.
&gt; I know saying this out loud makes me look like a bigger douche than I really am, but I had to. You *had* to? Really? Even assuming, for the sake of argument, that your opinion on the matter happens to be completely and objectively correct, do you honestly think that pointing it out, in a rude way, in public, was the right course of action? Seriously.
There are basically three different hierarchies which can be connected through wrapper constructors. The edge from Monad to Category is missing because there was no space left. I probably missed a few others too.
wot no monoid?
Monoid has no superclass constraints and none of the mentioned classes has Monoid as a superclass. Is there some relation between one of the classes and Monoid?
If m is a Monoid then Const m is an Applicative Functor. This is connection is used in the definition of foldMapDefault.
I see. Apparently there are multiple possibilities defined in Control.Applicative. So, Monoid is not a real subclass of Applicative, but you can construct an Applicative from an Monoid in multiple ways. On the other hand, the wrapper types (like WrapMonad) represented by the dotted edges just exist in order to be able to define instances of superclasses that happen do have been forgotten in the standard (like Applicative m =&gt; Monad m). Thoses edges represent real subclass relations. 
`Monoid`, you say? Monoid is everywhere and nowhere. Many types with two parameters are `Functor`s in general, but become a `Monad` if the left parameter is a `Monoid`. An `Alternative`, `MonadPlus`, or `ArrowPlus` is a higher-order monoid for their respective "base" class, and could be a `Monoid` instance for any fixed type parameter. Fix the type parameter for an `Applicative`, `Monad`, or `Arrow` to a specific `Monoid`, and the whole thing can be a `Monoid` as well. `Applicative` can describe a *type-level* monoid on a Functor's type parameter. `Monad` and `Arrow` describe type-indexed monoids. There's no escape!
I'm pretty sure that every parametric type constructor is a functor, regardless of whether there's a Functor instance for it. The existence of the type constructor trivially gives us the mapping from objects to objects. If the parameter is used directly, then we just apply any function to the corresponding arguments of the data constructors. If the parameter is used indirectly, then it must be passed to another type constructor; apply inductive assumption. If the parameter is not used (i.e., it's a phantom type), then it's trivially a functor. The only way to make non-functorial type constructors is if they're non-parametric. This includes type class constraints on parameters (a la `Ord` on `Set`) and existential constraints a la GADTs. For type class constraints, we've only restricted the parametricity; therefore they're still functors, just functors in a subcategory. Though that does mean we can't write a Functor instance for them. For GADTs, well, GADTs are special. Type families can also avoid forming functors, for the same reason as GADTs.
:)
&gt; I'm pretty sure that every parametric type constructor is a functor. Doesn't sound right to me. This implies that multi-ary type constructors would have to have a `Functor` instance for each argument, and in particular, that the `(-&gt;)` type constructor would have to have a `Functor` instance for its first argument. This would imply the existence of a function fmap :: (a -&gt; b) -&gt; ((a -&gt; r) -&gt; (b -&gt; r)) which djinn tells me isn't realizable.
Yeah, good (well thought out with minimal noise) haskell discussion is actually harder to find than I would like. IRC is sometimes ok but extremely noisy, cafe is better but also high noise (most haskellers I know don't subscribe these days), and reddit is terrible for quality discussion.
High quality libraries require discussion, posting blogs (which always get turned into reddit posts) is a good way to get readers thus starting discussion.
Thanks for putting the slides up with the speaker notes! For anyone interested, here are some more slides comparing traditional Ruby testing you might see to a kind of proving in Agda: http://dtp10.heroku.com An interesting result here is a way to do universal quantification-like proof composition with tests parameterized by mocks! Raw version with speaker notes, &amp; associated files: https://github.com/larrytheliquid/dtp10/raw/master/slides.md https://github.com/larrytheliquid/dtp10
Wow, awesome, I remember you mentioning this briefly at the BAHUG! I was that dude who flew in moments before.
So maybe better to put the sidebar onto a separate tab in the page then?
I disagree about OOP in C. I think OOP in C is nicer than OOP in C++ in many aspects...
Pointer to more information, please. 
You don't need Silverlight. There are download links available in the right column.
Convince him while he sleeps that he's himself a macro. (reminds me of "Inception")
This reminds me I have to figure out how Arrows work in Haskell. Anyone know where a Haskell noob could find a good explanation of Arrows?
Funny, I was just looking at hoauth (client implementation of the OAuth protocol), and wondering why it didn't use bytestrings. Turns it needs base64 encoding, which was only implemented for the String type... Until today! Thank you!
&gt; * 200 MB/sec strict decoding (per RFC 4648) &gt; * 100 MB/sec lenient decoding From the documentation I got the impression that lenient would be faster than strict as it neglects error handling. Surprisingly, it's the other way round. Why?
[The Typeclassopedia](http://haskell.org/sitewiki/images/8/85/TMR-Issue13.pdf) is awesome! It really helped me to understand the stuff beyond Functors and Monads.
I think in this case lenient probably means that it also accepts and tries to decode non-compliant input (per RFC4648). Edit: and this seems to be the case according to the source code: -- | Decode a base64-encoded string. This function is lenient in -- following the specification from RFC 4648, -- &lt;http://www.apps.ietf.org/rfc/rfc4648.html&gt;, and will not generate -- parse errors no matter how poor its input.
The comment you quote lead me into thinking that lenient is faster because not testing for errors is easier than reporting them. But you are right and it may be the other way round: handling unspecified input in a reasonable way is more difficult than just throwing an exception. I somehow thought that the motivation for providing a lenient version was efficiency.
I see the use of unsafePerformIO in both encode and decode functions. Could someone elaborate on why perhaps the decision was made to take this approach instead a more purer approach? edit: I thought the rule of thumb was to avoid unsafePerformIO unless your name is Simon*. :-)
Implemented in "pure Haskell", huh? :)
[This](http://en.wikibooks.org/wiki/Haskell/Understanding_arrows) helped me.
I think that's a useful observation. Had you wrote this before stating your original summary, I wonder if people would not have appreciated it more. 
Is this by any chance correlated to what's happened at Digg?
It looks to me that the secret to the speed of this "pure Haskell" implementation is that he wrote C in Haskell syntax. ;)
`ByteString` is already full of `unsafePerformIO` under the hood. It's implemented roughly by data ByteString = ByteString (ForeignPtr Word8) Int Int That is, a pointer to an array of bytes, plus an offset and length. That array is not a GHC heap object; it's just a chunk of memory, allocated and manipulated using the FFI functions in `Foreign`. So it's naturally going to have an `IO` interface. The `ByteString` authors have taken much care to hide the imperative inner workings. This `base64-bytestring` library is so fast because it operates directly on these arrays, rather than through the `ByteString` API. So you could say that it's extending the `bytestring` package, rather than using it "normally". &gt; edit: I thought the rule of thumb was to avoid unsafePerformIO unless your name is Simon*. :-) Fair enough. But I think that anyone with their name on the cover of *Real World Haskell* gets to be an honorary Simon. ;) 
were ruby people actually interested in your talk (it's really hard for me to imagine that)? I think it would be more interesting if it didn't contain any agda code, only some pseudocode, preferably with ruby syntax (so instead of that wordy GADT data-type declaration for days, you could use a sentence like "a day is either a Monaday,..., or a Sunday", or maybe some ruby code for visitor pattern for that). Instead of using sigma types you could use comments and mention that there is a static program that checks those.
If you've had some experience reading academic papers, you might find [the arrow bibliography](http://www.haskell.org/arrows/biblio.html) helpful. Once you've got the hang of it, you should also definitely check out [Wadler's presentation of arrows](http://homepages.inf.ed.ac.uk/wadler/topics/links.html#arrows).
Submit a bug to the GHC bug tracker, if you think it is an issue with the runtime. If you suspect the user's code, report it to the user. * http://hackage.haskell.org/trac/ghc/newticket?type=bug
Thanks. I created [#4285](http://hackage.haskell.org/trac/ghc/ticket/4285), as #1 -- I don't see the same issue on Linux, and #2 -- It goes away when compiled with -threaded. I know there's really too much code for a bug report. Will try to reproduce the issue over the weekend. 
shiny new and XHTML What is this, 2004? Oh, the previous version used tables. Well, it's an improvement. But it does confirm that I have fallen back in time. 
Nowadays the array stored inside a ByteString is allocated and managed by GHC. I believe it's pinned though so it can be passed to C.
&gt; Another great new feature is markup support for examples, contributed by Simon Hengel. The idea is to be able to write examples that function both as documentation and unit tests. So, is this like Python's [doctest](http://docs.python.org/library/doctest.html)? How does one go about integrating this into projects?
Yes, it's more or less Python's doctest. The markup is the same. To actually run the tests you need to wait for a new version of Simon Hengel's DocTest program that will use the Haddock API to extract the examples and check them.
Ah, interesting. Would it be fair to say it's not a closure, though?
&gt; I thought the rule of thumb was to avoid unsafePerformIO unless your name is Simon*. :-) unsafePerformIO is extremely useful, and should be totally safe in the right contexts. I use it all the time (maybe that's a heresy, but hey :)
unsafePerformIO is a significant mechanism in using the FFI in general. Without it, the FFI would be much worse off.
The ForeignPtr in ByteString points to a ByteArray# which, if I remember correctly, consists of a length field and a pointer to the raw byte array.
The `(-&gt;)` is special, as always. Would you have preferred if I said parametric ADT type constructors? I.e., sum/prod/rec ADTs. Adding exponentials to ADTs makes things funny again. Indeed `Functor (-&gt; r)` is unrealizable in a total language.
Yep, it's pinned and GC-managed. A rather odd beast in the GHC memory hierarchy, but there you go.
This is pretty cool. I've got to say that I'm somewhat disappointed on one count though -- all the tricky parts like parsing, dealing with corecursion, etc, are farmed out to Haskell, so what's left is just a formalization of Request -&gt; Response. Pretty cool still, but less fun than I imagined -:)
It is a photoshop sketch so it can't flex. I don't plan on the layout being entirely fluid (very long line lengths tend to be very unreadable) but there will hopefully be some flex.
I've been fooling with different ways to display dependencies. Definitely consider what is there a WIP. 
Thanks. I should have been more specific: 1. What is `WrapMonad` and why is there a `WrapMonad` arrow going from Monad to Applicative? I guess it's to show that all Monads are also instances of Applicative, but only if you tweak the API with some sort of wrapper? 1. Similarly "Kleisli". 1. What's `Alternative`? I don't see it in [the index](http://users.skynet.be/jyp/html/doc-index-A.html). 
[Here's `Alternative`](http://www.haskell.org/ghc/docs/6.12.2/html/libraries/base-4.2.0.1/Control-Applicative.html#t%3AAlternative)
But then there's really no reason to expect that IO could be described as an ADT (and indeed, if it's implemented as something like State Realworld, the way people often think of it, it isn't an ADT), and so no reason to expect a priori that it be a Functor.
this is true of the master branch (which was an experiment in test composition that just straps onto haskell's hack). the rfc1945 branch is starting to build up an http parsing/validation core, which includes many type dependencies (http method, response status, inclusion and value of specific headers, etc...) coinduction for both client and server operation is on the radar too... one thing at a time :)
the people that came were interested, but probably due to selection bias as it was a multitrack conference i partly wanted to use Agda syntax to show some real code in a language few have seen... sticking to Ruby + analogies is definitely another good possible approach
http://hackage.haskell.org/package/Monatron-0.3.1
Schrijvers. Apologies!
why not use scion? iirc eclipse plugin for haskell uses that.
It seems Prelude isn't indexed? "read" for example seems unmentioned. This confused some of the newbies I'm teaching Haskell to :-)
Too bad it's not on hackage (yet?).
Doing a code review for it now. The authors are keen.
I'm asked that alot, i hope http://mistuke.wordpress.com/2010/09/03/why-didnt-you-use-scion/ clears this up
what about that immix stuff from gsoc? is this unrelated or an alternative (all I know about GCs is that they clean up stuff)
it's orthogonal. As in, you can do both, and I hope that one day we will.
The arrow indicates that monads actually are applicative functors, the Monad type class just lacks the Applicative super class constraint. Ideally the type classes would have been defined like this: class Functor a =&gt; Applicative a class Applicative m =&gt; Monad m But unfortunately the were not. So, as the next best thing, we would like to write: instance Monad m =&gt; Applicative m where pure = return (&lt;*&gt;) = ap but Haskell98 doesn't allow that. That's why there is a wrapper type `WrappedMonad` in `Control.Applicative` which lets us write instance Monad m =&gt; WrappedMonad m where ... Its value constructor is called `WrapMonad`. --- `Kleisli` is a little bit different, because `Arrow`s have a different kind then `Monad`s. So, `Arrow` is not a super class of `Monad`, but you can make a `Monad` into an `Arrow` by applying `Kleisli` to it. There are maybe other possible arrows based on a monad, I don't know.
this... won't work with mersenne-random. It natively generates doubles. Some people don't care so much about cryptographic properties, but performance, and gladly exchange security (which they don't need) for one or two magnitudes of runtime.
Thanks for the pointer. I'm impressed by how for the most part you've managed to keep everything quite clean and haskell-like :-)
Indeed, it seems that the Haddock docs for the base package are not generated on Hackage: http://hackage.haskell.org/package/base We will look into this... Thanks for the hint :)
Dare I say it: swell?
Is a twilight action capable of cancelling (note, not restarting) an otherwise healthy transaction?
There's no reason mersenne (-pure64) can't have a RandomGenerator instance. Serializing is perfectly legitimate and the existence of an instance doesn't prohibit higher-performance users from using mersenne's specific interface directly. Do you have an alternate proposal that would provide performance and the generalized interface? Your comment makes me think of something like: class RandomGen g v where newGen :: v -&gt; g genValue :: g -&gt; Int -&gt; (v,g) ... This is very similar to the [pure interface](http://hackage.haskell.org/packages/archive/mersenne-random-pure64/0.2.0.3/doc/html/System-Random-Mersenne-Pure64.html) - so much so I could make an instance without any lower primitives. Note I just talked about the mersenna-random-pure64 package. If you really mean mersenna-random (which I see you probably do) then you probably already know its covered with IO and doesn't even have an old RandomGen instance, so its already the odd-one-out.
This is too much for my little brain. Any case study showing how this can be used?
the analogy between the way Haskell strives for purity by separating side effects is a useful one to think about sometimes... in agda things that are not proven ("impure"), such as imported haskell functions, are treated as dirty postulates/axioms :)
It looks we cannot have a single class that is OK both for crypto purposes and also for general purpose code that needs pseudo random number sources. In the Crypto case we have to deal with the possibility of using up all our entropy. On the other hand, most other non-crypto algorithms will cope perfectly well with minimal entropy and the numbers cycling around and it would not be appropriate to force them to deal with possibly-failing PRNGs. Given this seems to be the case, perhaps we can distinguish two type classes for PRNGs and give them sensible names, e.g. RandomGen[erator] for the general purpose one, and perhaps something with "Crypto" in the name for the other one, like CryptoRandomGen. It would be nice to design both at the same time since some of the limitations and solutions are common between the crypto and non-crypto cases.
OTOH, It's low-hanging fruit that a clever guy like you could just write and contribute. (How else did the other systems evolve....?)
I was thinking of replacing strict bytestrings with ListLike, keeping the choice of underlying array and element type up to the random gen.
times out for me.
Sorry, my ISP tends to disconnect me after a bit. I'll mirror it on my remote host. Edit: Mirrored: http://benboeckel.net/osb-mirror/2010/09/04/so-i-started-to-package-hledger/
http://downforeveryoneorjustme.com/http://www.imn.htwk-leipzig.de/~abau/lhae/ ?
This is beautiful. I'll have to reread it a couple of times, but there are really cool ideas. I like the mixins a lot. 
Yeah, I also noticed that. Perhaps even more pertinent: it doesn't seem to be on hackage yet.
works for me. i browsed to http://www.imn.htwk-leipzig.de.nyud.net:8080/~abau/lhae/ to cache it just in case.
http://hackage.haskell.org/package/lhae - seems to have gone up on Friday.
Thanks. 
mbuf has submitted the package to Fedora a while ago :) and waiting for review
Thanks for getting Yesod onto Fedora ;)
Glad to see that lhae is [on hackage](http://hackage.haskell.org/package/lhae/), and that the [home page](http://www.imn.htwk-leipzig.de/~abau/lhae/) is up. This looks like a fun app!
&gt; It would be nice to design both at the same time since some of the limitations and solutions are common between the crypto and non-crypto cases. Please see the [latest e-mail](http://www.haskell.org//pipermail/libraries/2010-September/014167.html) on l@h.o
Sigh, the semantics for conditional non-buildable components is a mess. I tried fixing it in cabal-install-0.8.0 but discovered that it's more subtle than it looks and had to revert things for cabal-install-0.8.2.
Last month I installed Arch Linux under vmware running on my mac, just to hedge against such problems on mac. Took some time to set up but was not as tricky as I thought. Very impressed with Arch so far. What about virtual appliances: machine images with haskell, libraries and applications pre-installed. Have these gone out of style? Also, I once would have thought ubuntu would also be a good platform to support, but debian based distributions and bleeding edge don't seem to mix that well. It's too bad since many people are like the skydiving accountant--stable in some aspects of what they do and bleeding edge in others. Is there really anybody using haskell yet that doesn't want bleeding edge type updates?
Another problem on the Mac with the HP binary installer is that the readline package is uninstallable. I worked on it a while back with some help from the mailing lists, but we were unable to get it to work. The problem is that the Mac has pre-installed libraries with the same name as GNU readlines's libraries, but they are actually editline. And MacPort's readline seems to be incompatible with the HP binary, apparently due to 32 bit/64 bit issues.
I guess my main point is: +1 I am a Mac user. I'd be happy to help, though I am unable to take charge.
MacPorts is *incompatible* with the Haskell Platform binary installer, for now, as the HP installer uses the native C libraries, which have different, inconsistent (at the ABI level) C libraries. iconv, readline at least. For now, either you *only* use the (bitrotted?) MacPorts, or you use the HP binary + cabal install.
The [slides](http://people.cs.kuleuven.be/~tom.schrijvers/Research/talks/ifl2010.pdf) of the talk are available.
Gentoo's Prefix Portage is a great alternative to MacPorts. Setting it up might take a while but its definitely worth the effort.
Looks good! Unlike in the linked docs, the *Source* links in one of my packages do not appear at the right margin but inline with the rest of the documentation. See, for example, the source links in the [documentation of the weighted-regexp package](http://hackage.haskell.org/packages/archive/weighted-regexp/0.3.0.0/doc/html/Text-RegExp.html). Did I make any mistake in the Haddock markup which causes this?
[Teach Yourself Programming in Ten Years](http://norvig.com/21-days.html)
I would definitely appreciate some help in creating the HP binary installer!
It's available now at the publisher, [The Pragmatic Bookshelf](http://www.pragprog.com/titles/btlang/seven-languages-in-seven-weeks).
The goal of this book isn't to make you an expert but to gives you a taste of many types of langage.
Have you seen [HBC](http://hal3.name/HBC/)? It's a compiler for a DSL, but it does much of the sort of thing you want.
Thanks for raising this issue for discussion and recommending an effort. The broken state of Haskell+Mac is why I stopped working on functional GUIs &amp; graphics after switching to a Mac one year ago. I'd love to get back to it! The problems I ran into: * gtk2hs was too hard for me to get working more than once. That one time, I had to install in a ton of stuff in MacPorts. The resulting GUIs looked like Gtk rather than like Cocoa, and they required the X compatibility layer, which meant they didn't work like Mac apps. I couldn't use the native Gtk port, because that port doesn't include OpenGL, which I need. * wxHaskell, which looks lovely on Mac, kills its host process the second time a top-level window is opened. My GUI and graphics examples are usually tiny half-liners, so I want to play with them in a REPL or in a setting like [Eros](http://conal.net/papers/Eros/). * Under GHCi, GLUT windows don't come up with their borders &amp; buttons, so e.g., I couldn't move, resize or close them. I think wxHaskell probably has this issue also. I'm happy to help out as I'm able. 
I love how clear the function type signatures are. 
I would instead suggest homebrew (http://github.com/mxcl/homebrew). 
Homebrew packages build against the native C libraries. I don't know how popular it really is, and if people would be willing to use it instead of MacPorts, but I'm getting the definite impression that MacPorts just isn't working for us. I think I'm missing something. Are you hoping we can provide pre-built libraries? Otherwise, if a MacPorts or Homebrew package simply builds the library from source, what would be the point of doing that instead of cabal install? 
I've had no problems with [homebrew](http://github.com/mxcl/homebrew) - much better than macports imo, and much more up to date. Not sure who's maintaining it, but it's certainly not lagging behind: $ brew info haskell-platform haskell-platform 2010.2.0.0 http://hackage.haskell.org/platform/ Depends on: ghc Not installed [...]
As far as I know, the homebrew formula for GHC just goes off and installs the .pkg file. Would it be more useful if it built GHC from source? 
Homebrew is my pornography.
Python must be pissed
I bet this book sparks a lot of language discussions.
I'm surprised the author didn't choose to explore a stack-based language such as Factor or Forth.
Certainly, that seems long past due. I don't know if Mac OS X is going to make it past the decade, though. edit: **Obviously, this needs clarification.** Apple totally rewrote the kernel for their OS when it came time to make OS X, preserving the legacy codebase for OS 9 in what was called "Classic" mode (which, I believe, was later discontinued (?)), much like Windows did for Windows 7 (following their suit). This, however, is like trying to fix a dam with scotch tape. The fundamental problem that creates bloat in software is actually a social problem - organizations producing proprietary software themselves become bloated, as a result of too much departmentalization and confusion, leading to a product organized by those same hierarchies - the coding process becomes a huge game of "telephone." This was exactly what led to the demise, most famous, of Real Player, Nero, and other similar products which expanded into bundled suites of products. Microsoft did the same thing, roughly, in the past The DOS codebase was so undesirable to them that, by Windows XP, they had switched it in favor of the NT codebase, which was considerably less sloppy. Then, of course, Windows Vista happened, and the backlash for the bloat was so huge that they were forced to undergo the aforementioned kernel rewrite. If you make a big graph, time versus software bloat (however you determine what constitutes 'bloat'), you'll notice that the rate of change of bloat is roughly proportional to the size of the organization in question, in the absence of 'distributed' software models, like the ones you see in the free software world. A kernel rewrite will make the bloat basically drop down close to zero, but since the organization itself is so bloated, it will rapidly recover, unless great caution is maintained in the inclusion of new features (which it usually isn't, because of the tendency of sales reps for that company to try to get every conceivably profitable feature packaged into the product. This theory explains, actually very cleanly, the tendency in the free software world for a product to be boiled down to its discrete components. People only use what they want to use, and if the source is available, they may even go so far as to chop out the other parts of the program. Utilities like ls, cd, bash, strace, ffmpeg, whatever, they're all very strictly confined to one purpose. Whenever a program exceeds that specific purpose, its users react against it and choose an alternative, sometimes forking the code. Even in the case of something as basic as, say, X11, there are people who think it has too many unnecessary components, and instead elect to use strictly console-based applications, usually with "screen" or something similar. 2 upvotes, 5 downvotes at this point. I hope this is a sufficient explanation?
[Vagrant](http://vagrantup.com) may be best for this? It's written in Ruby, but environment agnostic. Basically it compiles together a bunch of open source projects (Virtualbox, Ubuntu, Chef) and lets you auto provision everything from a tiny set of descriptor files. Macs already have Ruby installed, so it's just getting Virtualbox and the Vagrant gem. From there, distribute a set of Chef cookbooks that install GHC, Libraries, Demo projects etc.
Mac OS X is not Linux, so please don't go off trying to improve MacPorts or Homebrew or compile from source or any of that. As far as software installation goes, what we need are .pkg and .mpkg installers. A .pkg for GHC, one for the rest of the HP, one for darcs, one for Alex &amp; Happy and so on. Then, on top of that a .mpkg bundling those together. Simple one click install, Mac style. Making these installers is not hard (I wrote the code building the GHC installer, so I know &amp; developer.apple.com has plenty of docs explaining how to build bundles.). All it takes is some people sitting down writing the code and maintaining it. Secondly, we need Xcode integration. You should be able to drag the GHC.framework into Xcode like any other framework and then write an Objective-C program that calls Haskell code. An Xcode plugin that supports Haskell development in Xcode would be nice, too. Thirdly, we need better integration with Objective-C/Cocoa (see http://hackage.haskell.org/trac/ghc/wiki/ObjectiveC for some ideas). That is somewhat tricky and needs a good design. You can of course do it all manually using the C FFI, but that gets tedious quickly: http://tscheff.blogspot.com/2010/02/currync-converter-using-haskell-with.html Then, on top of the former, we need bindings to Cocoa libraries.
And a pony :-)
Does anybody know whether the Haskell part is any good?
Unfortunately, the "Synopsis" lacks a bound on the width — see http://hackage.haskell.org/packages/archive/accelerate/0.8.0.0/doc/html/Data-Array-Accelerate.html
Nice. It's really pretty. Funny that the link to [http://darcs.haskell.org/binary/tools/derive/BinaryDerive.hs](http://darcs.haskell.org/binary/tools/derive/BinaryDerive.hs) in the documentation is still broken though.
It is required and I would vote for some of those that were suggested, probably all of them actually. It needs to happen eventually...thought something like this does fly a little in the face of "avoid success at all costs" but I like the change.
i'm happy to help where i can (minor patches/testing).
&gt;I don't know if Mac OS X is going to make it past the decade, though How do you figure that?
Can't keep up with Linux. Plus, they're going to keep putting out new revisions, and I don't think it's going to hold together real well. I feel bloat coming on, like animals feel the coming storm.
Now I wish hackage had a similar UI refresh. It's weird jumping between the two styles.
Does anybody know who wrote the Haskell part?
Yeah, this is what's been keeping me out of the Haskell community lately. I don't care whether Haskell is built with native installers or not, but I need to use MacPorts for work and don't feel like switching the entire company to Homebrew right now. Would love to have a working portfile again. 
Well, you can choose *either* the binary installer, or MacPorts GHC + tools. Once you've got a GHC installed, then cabal gets the rest of it. But this, as you obviously notice, is why there should be a serious team working on the Mac.
 "avoid success at all costs" isn't meant literally. 
Is Pragmatic Bookshelf part of O'Reilly?
Concerning integration with Objective-C/Cocoa, this is solved by [HOC](http://hoc.sourceforge.net/). Looks like it hasn't been updated for a while, though.
I love the look but don't like that synopsis frame or something. Is there an alternative look where the synopsis appears at the beginning of the page that I can enable? [edit] It just stroke me that the synopsis presented that way is accessible whatever the current vertical scrolling is, which is good. However, on my firefox 3, the expanded synopsis requires horizontal scrolling to browse some type signatures on the linked example. Is that supposed to be normal?
Actually, there are more differences in the docs to my package that I linked. I started to list some of them but then saw that the most notable difference is in the page footer which says &gt; Produced by Haddock version 2.6.1 rather than version 2.8.1. It seems the stylesheet has been updated but the html page has not. Only some of my packages show this behaviour. [level-monad](http://hackage.haskell.org/packages/archive/level-monad/0.4.1/doc/html/Control-Monad-Levels.html) and [stream-monad](http://hackage.haskell.org/packages/archive/stream-monad/0.2/doc/html/Control-Monad-Stream.html) are among them but others are not.
I've been using Gentoo for too long to leave Portage behind! Besides, it sits nicely in my home directory and if something goes wrong, all i need to do is rm -rf ~/Gentoo and restore the directory from backup. Neat!
I liked the previous style better. Also, that Binary documentation is way too verbose.
Hi dons, I use Haskell on OS X, and I would like to help with your strike force. I'll look over those mission statements later today. wiki : http://www.haskell.org/haskellwiki/OS_X already runs documentation : keep on wiki? discussion page : What are you picturing here? party list : Look at the CC: list on http://hackage.haskell.org/trac/ghc/ticket/2965 leadership : http://hackage.haskell.org/trac/ghc/ticket/4163
I know OSX people don't like Gtk, but it could be a lot better than it is currently. The [gtk-osx project](http://gtk-osx.sourceforge.net/) has finally got the native/quartz gtk engine and and some app bundle scripts together. Some non-trivial programs like Gimp and Inkscape now have OSX installers that use this and look more native than the older X11 Gtk backend on OSX. So some effort to get the packaging/installing working for this would be great. It would solve the worst of the problems of Gtk on OSX, like having to use macports and the theme looking really bad.
As I understand it, making .pkg packages is a bit harder than you suggest, but not impossible. The chap who's been making the HP installers for OSX says that there are lots of different .pkg/.mpkg formats and compatability across OSX versions is not ideal. Many of the formats are undocumented, have terrible command line tools and can only effectively be used from inside Xcode making them really hard to script into a build/release process. Nevertheless he's made some progress on a cabal-&gt;pkg tool and I agree that this is the way to go rather than working with macports.
Conal, see my comment about the gtk-osx project. Perhaps you can persuade one of your helpers to work with the gtk2hs project and automate the generation of OSX installers using the new native gtk stuff.
I'm sorry if I appear negative, but while I had hopes for gtk-osx, I'm not convinced it is going to be useful any time soon. For example, have a look at the build prerequisites: http://sourceforge.net/apps/trac/gtk-osx/wiki/Build#Prerequisites It says, "If you have MacPorts or Fink installed, you must remove all traces of them from your environment before you try to run jhbuild." As I said, many times, I'm no big friend of MacPorts, but even I still use it for some simple tools. The requirement, to completely purge it, seems quite onerous. At the bottom of the same page, they also have the disclaimer, "WARNING: The frameworks as built, including the intel binary at http://gtk-osx.org, are not suitable for end-user use at this time." Last time, I tried it (which admittedly was a while back), they supported neither gmodule nor libglade (at least in the binary distro I found), which meant that I couldn't build the application, I was interested in (Threadscope). Maybe it could be made to work, but it might require a substantial amount of work.
HOC isn't maintained, has it's problems, and is to a certain extent orthogonal to the lower-level FFI integration discussed at http://hackage.haskell.org/trac/ghc/wiki/ObjectiveC (I started this with André Pang who is one of the two authors of HOC).
There are different formats, but not that many. The main issue for us is that Snow Leopard (Mac OS X 10.6) introduced new functionality that is not supported on Leopard (Mac OS X 10.5). So, either we forgo the new features or have to drop support for 10.5. I'm not sure what issues he had with the command line tools — I had no problem integrating the building of the GHC .pkg into the GHC build system as a simple makefile target (and the code is there for everybody to copy — although, it could be improved). I also don't understand the part about Xcode. Xcode has (a) nothing to do with package building and (b) if you use it for building binaries, you can use it perfectly fine from the command line: http://www.unix.com/man-page/OSX/1/XCODEBUILD/ To make the actual package in a script, you use http://www.unix.com/man-page/OSX/1/packagemaker/ (How would Mac developers do nightly builds etc. if you couldn't drive all this from the command line?)
me too, I guess I'll have to figure out how to override it... hmm, the idea of generating info pages to browse within emacs has been lingering in the back of my mind for sometime though
&gt; As far as software installation goes, what we need are .pkg and .mpkg installers Please speak for yourself. I'd much rather see better cooperation with MacPorts. I also have zero interest in Xcode integration — and I develop Objective-C applications for a living. Considering how flaky Cabal is, MacPorts integration would be very useful.
I expect most people in this book's target audience have already met python.
I just created http://www.haskell.org/haskellwiki/Mac_OS_X_Strike_Force and lightly populated it with some of the ideas in this reddit thread.
OS X 10.6 added practically no feature and was all about removing wasted space and improving efficiency. Of course this lack of features was mainly driven by moving developers to iOS. If OS X dies it will be because the iOS dystopia displaces it.
Homebrew is not a good idea to recommend. All their installation instructions that I see include sudo chown -R \`whoami\` /usr/local which is not a same instruction.
Homebrew is not a good idea to recommend. All their installation instructions that I see include sudo chown -R \`whoami\` /usr/local which is not a same instruction. 
I have had good results with installing MacPorts and building ghc against it. Then I can "cabal install gtk" and it works.
Well, it's better than Seven Language Paradigms in One Programming Language (I'm looking at you, *Oz*)
Can .pkg .mpkg or a "Distribution Package" handle the version dependencies between haskell packages? Is there any sane way to upgrade or uninstall?
Python must be proud since it's not that much about introducing new, cool but hard to understand principles. Python aims at being usable, not exploring new language paradigms.
Perhaps you could work together with the guy who makes the HP installer? I'm sure he'd be grateful for any amount of help.
Now announced: http://www.well-typed.com/blog/45
We don't need it to be suitable for end-users. We need it for our own packaging. If it's good enough for GIMP and Inkscape to make installers then presumably it's good enough for us to bundle with a gtk2hs package (or with ghc+gtk2hs+threadscope).
Ferry looks awesome. Is there some library or the ferry program from the video talks available for download?
Well, that's another factor. Attempting to push that crap on consumers would also result in the death of Apple as an OS producer very quickly.
I like it. Good work guys. Any chance the favicon can be changed to match the new theme?
Is there any sign of gtk-osx supporting OpenGL or in any way giving access to GPU programming? That bit is a make or break for me and I expect a lot of other folks.
I'm not trying to be rude, how is this different from your typical parser combinator framework?
Sounds great to me. If anyone out there has the OSX know-how to tackle these issues and is interested in helping me get cross-platform denotative/functional graphics &amp; GUIs going in the Haskell world, please let me know. Helping Jeremy O'Donahue fix the die-on-restart problem in wxHaskell might be an easier alternative to gtk2hs for cross-platform. And yield a more elegant programming interface. Either way.
It does a few things differently: * A BNF *EDSL*, so you write happy-like grammars, but inside Haskell, like parsec. * The grammars are typed * LALR parsers are constructed at compile time (unlike parsec)
Glad to know! Have you been able to build the Haskell Platform against MacPorts as well?
The haddock docs should be generated by middle or end of today (depends on your timezone) but for now, for the curious, [here's a copy](http://web.cecs.pdx.edu/~dubuisst/secure-sockets-1.0/html/)
In fact, if someone with more time and OSX expertise could take the project over I'd be pleased as punch.
All I need now is a fake PhD...
I like the new style. Some others don't. Are there any plans to enable the old style via themes so people can choose?
[Here](http://www.haskell.org/pipermail/haskell-cafe/2010-September/083248.html) is some additional information on the library. Hopefully the library documentation will be up soon too.
Could indeed be what people mean. Even so, it's not the case that operationally in Haskell everything is a thunk. At most, everything *begins* as a thunk, but then *mutates* into non-thunks. And I doubt everything even starts out as a thunk, depending on its initial simplicity (e.g. `False`). Moreover, if people have such an operational perspective in mind when discussing what everything *is* in Haskell, then mutation (as a side-effect) is rampant &amp; pervasive, so next I wonder how they could also refer to Haskell as a "pure(ly) functional language"? 
More info in the release http://www.haskell.org/pipermail/haskell-cafe/2010-September/083248.html
what do you mean by "happy-like grammars"? do you refer to the fact, that they usually split the syntactic part from the semantic part: Exp1 '+' Term { Plus $1 $3 } compared to regular Parsec, that mixes both problems?: do e &lt;- exp1 char '+' t &lt;- term return $ Plus e t if so, it can be solved nicely with Applicative: (\e _ t -&gt; return $ Plus e t) &lt;$&gt; -- semantic part exp1 &lt;*&gt; char '+' &lt;*&gt; term -- syntax only It's also based on counting parsed tokens. &gt; The grammars are typed well, grammars in Parsec are regular Haskell code (and pretty good at that, no unsafe stuff, no Strings attached) so they're typed as well.
this is of outstanding quality for 0.1 release! I have a question: is all that dynamic typing really needed, or is it optional (for efficiency) ? 
I remember you sending me a link to that wiki page a while ago when we last discussed this, but the links to subpages on it seem to be dead, so I can't remember how you proposed doing it. In the mean time, I had an idea on how to deal with strongly typed messages using GADTs and data families, which I've pasted [here](http://hpaste.org/fastcgi/hpaste.fcgi/view?id=29766#a29766).
Also, haskocoa? :P kind of a gimmicky name though :(
I heard that GLFW works better than GLUT. I haven't tried it recently, though. Some time ago, it was true that GLFW required the application being an app bundle, but either they changed it or it is possible to patch it (in the latter case we should inform the maintainer of GLFW). wxHaskell (as of 1.5 years ago) was very nice until I tried anything nontrivial, then it broke completely (which I believe was the fault of the underlying wxWindows library, but still). gtk2hs is really hard to install, but somehow I managed to do it once. It must have been rather traumatic though, because I didn't remember it later :). I'm pretty sure it involved some binary gtk build, a native framework, probably the same stuff as gtk-osx.
Haddock does that already. If you select multiple themes then a switcher menu appears in the html.
Sorry, my question is whether there are any plans to use this feature on Hackage.
Thank you! I have been working on it for some time now. I'm assuming you're referring to the use of Data.Dynamic in the parser, and not the mkDynamicParser function (which I realise now could probably have a better name, as it's not more dynamic than the static version in terms of typing, but rather in terms of when it does the parser generation (runtime vs. compile-time)). Dynamic typing is only used internally, for example because the semantic action functions are put in an array indexing rule and production numbers (Ints) to functions, and they all have different types (and so can not be put in an ordinary array expecting the same type for each element). I know there are ways to do it using references into a typed environment, but from my experiments with it I felt it was too much work with little gain. It proved hard to keep the typed representation of the grammars when implementing the parser generator. I admit it feels like a hack, but since the grammars themselves are typed it means that (assuming there are no bugs in the parser generator) the semantic functions will always be used on data of the right types and it will thus be safe.
so it's safe as long as you haven't made any mistakes in those recursive arrows and other scary stuff... if you try to cast the wrong function from the table inside TH, do you get the type error at the compile time?
If the library works correctly it should be safe for any well-typed grammar that is LALR(1) (you will get conflict reports at compile time when using mkStaticParser if it isn't). If the library does not work correctly, please file a bug report! :) The function tables are created at runtime currently (even when making static parsers, but doing it is very fast judging from my profilings), as there is no way that I know of to lift arbitrary functions to TH expressions. If there was an error in the table, the error would be at runtime, when the dynamic functions are applied. I have not run into any bugs in the tables with any of the grammars I have thrown at the parser generator, and I have also used random input (and expected output) generation to test the parsers.
You can install it anywhere you want and as any user. So, just don't do it that way. 
The position only requires a Masters. A PhD is what you get out of it! 
The [paper](http://www.dreixel.net/research/pdf/gdmh_draft.pdf) (pdf).
All I need now is a fake Master's...
Cabal blows up far more often in my experience. Another option would be nice. Don't be such an ass. I said I do Objective-C for a living, not that I think it's good.
&gt; Mac OS X is not Linux, so please don't go off trying to improve MacPorts or Homebrew or compile from source or any of that. [...] I'm all for having a really great set of libraries for Mac/Cocoa programming from Haskell. I also want *cross-platform* graphics &amp; GUI libraries that install easily, work solidly, and look good on the major platforms: Windows, Linux &amp; Mac OS X. I don't know whether gtk2hs can play this role, because of the difficulties in MacPorts vs GHC and the incompleteness and fragility of gtk-osx. So, I'd like to see Cocoa discussed as an *additional* goal rather than an *alternative* goal. 
I just read my post again and I meant it jokingly but it really did not come across, at all...humour fail.
So is there going to be a 6.14, or has the decision been made to call it 7.0?
I don't think want handle library versioning using .pkg et al. The HP .pkg provides a baseline set of blessed Haskell packages together with "cabal install". If you want to pull extra libraries from Hackage, you use "cabal install" as usual. However, common *application*, such as darcs, Happy, and Alex, should be available as .pkgs, too. (It's not reasonable to assume that a developer who wants to use darcs wants to install the HP and cabal-install darcs.)
Go Ben! As you saw I've committed to biting the bullet and splitting the package; you gave me the final nudge. With luck my plan to access plugins from one front end will come together.
I've no issue with someone attacking Objective-C if the criticisms are valid... and there are many, many valid criticisms. It's extremely painful to work with compared to a modern language like Haskell. Not fun. Then again, Haskell has its pain points too. Thanks for clarifying the intent of your remark in either case.
I have become quite sceptical of cross-platform GUIs. OpenGL, and hence GLUT, is truly cross-platform, but widget libraries seem to have a hard time getting accepted on more than one platform. This is not a Haskell-specific problem, but seems to affect all languages for half-way sophisticated GUIs. In the Haskell space, Gtk2hs has always had problems on Mac OS X (and I don't see gtk-osx helping so far) and wxWidgets seems mostly unmaintained. On Twitter, njbartlett suggested that QtHaskell would be worth looking at. Anyway, if anybody can produce a well maintained, easy to install, well-working cross-platform GUI library, I'm going to be the first person to rejoice. Until then, I really like to see good Cocoa support for Haskell (and that is an area where I like to contribute if I only find the time to do so).
The formatting of the wiki links changed. I fixed the wiki page now at http://hackage.haskell.org/trac/ghc/wiki/ObjectiveC
IMHO, the easiest way to use Threadscope on OS X at the moment, is to install Linux in a VM (eg, VirtualBox) and run Threadscope in there. (Execution is a bit resource-intensive, though ;)
Let's say, some of us have put forth the argument that a heart-lung transplant of the type checker is sufficient reason to bump the major version number and that the minor version number is starting to get a bit too high.
Yes, we probably should have decided this earlier to avoid confusion (we refer to 6.14 all over the place), but is time for. a major bump.
In addition to which we have all kinds of other awesome sauce to look forward to: the new inliner, the llvm back end, the new I/O manager, and I'm sure more besides. 7.0 is going to be a big release!
That's right, there are quite a few major advances in this release. A worthy 7.0 :)