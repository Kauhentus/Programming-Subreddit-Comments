Our idea is to have the talks in a summer school format - most would be workshops, with talks being more intimate and hands on and taking multiple hourlong slots. We will publish exact talk titles and an agenda after CFP ends.
I’d recommend checking out /r/ProgrammingLanguages for questions about language design &amp; implementation that aren’t necessarily Haskell-specific. It’s a good community of people, some quite knowledgeable &amp; experienced with language development.
Could you show me the process step by step, if that's not too much to ask?
&gt; lexer or no lexer I think that a separate lexer can be nice in certain cases, while it is overkill in others. I found a separate lexer quite useful for parsing a language, which is mostly context-free, but has a few context-sensitive things, which can be offloaded to the lexer. An example would be parsing with off-side rules (aka "semantic whitespace", e.g. `do` blocks), where a handwritten lexer can replace indentation with explicit `{`, `;`, and `}` tokens. This has the benefit, that the context-sensitivity is now in the lexer, so a parser library like `Earley` can be used, which works for arbitrary context-free grammars. &gt; how to implement my own type system (later to include type inference) &gt; &gt; What are some good resources for language design? I can highly recommend Benjamin Pierce's [*Types and Programming Languages*](https://www.cis.upenn.edu/~bcpierce/tapl/). It covers both theory and implementation of type systems including type inference, and you also learn something about semantics, i.e. how to think formally about program evaluation. Specifically for Haskell, I like the *[Typing Haskell in Haskell](https://web.cecs.pdx.edu/~mpj/thih/)* paper by Mark Jones, which shows how to implement a type checker for Haskell (98, no extensions) in Haskell. The paper requires some familiarity with type systems, so I wouldn't start here.
Thanks for the PPA. It makes my Travis testing effortless!
Hey! I've been implementing a compiler for a Haskell98 style language for a while now. I've had to deal with these problems so maybe you'll be interested in the codebase. Eventually, I'd like to clean it up to make it an educational resource for people like you (and me) that are looking to go beyond 'toy languages'. Codebase: https://github.com/xldenis/ill
That paper was what convinced me that the technique was sound and gave rise to the current API. The implementation technique I use nowadays, on the other hand, is a much more magical affair, but has the benefit of being about 3 orders of magnitude faster.
Are you still relying on the fact that a single function dictionary gets represented as a function (so that one can `unsafeCoerce` away), or is it even _more_ magical than that these days?
I'm guessing [you mean this](https://github.com/ekmett/reflection/blob/master/fast/Data/Reflection.hs#L417)? I can take a wild guess at what that does, lol. Should I expect a type-level implementation of RISC-V soon?
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [ekmett/reflection/.../**Reflection.hs#L417** (master → 6508a04)](https://github.com/ekmett/reflection/blob/6508a04342256cab34bd6aee06ec61a166ce56fb/fast/Data/Reflection.hs#L417) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply drkvey7.)^.
I'm good with everything on here except: &gt; If you basically have to rewrite a lot of a library, then it probably doesn't count. In my eyes, as long as you don't change the public-facing API, it should count the same amount.
Fair counterpoint. As long as it still produces the same result for the same API, it counts. Let me reword: use your discretion. I feel like the larger a patch is the less likely it is to be accepted. It wouldn't be a wasted effort because there'd be something learned, but getting the changes merged in is nice too. :-)
That's a pretty nifty way of getting around large haskell builds without fiddling around with compiler settings. I'm guessing that performance is the same or with negligible differences so that's probably useful when releasing your image.
I think it was a given that everything originates from Oleg's mind
huh, that's pretty nifty. Would you mind sharing your setup's config? I'd love to play around with it.
Sounds great, but make sure it has media coverage here on r/haskell or everyone will just forget. It's not one package (or maybe it is?) per se, but one thing I think needs attention is to figure out why we do so poorly on those popular TechEmpower benchmarks. There has to be something wrong - [Servant achieved 1% the rate of the top speed and Yesod was the slowest entrant that managed to finish successfully with no errors](https://www.techempower.com/benchmarks/#section=data-r14&amp;hw=ph&amp;test=update). That's embarrassing, and it's probably the most public benchmark we have!
My understanding: * The formal model of execution is called an STG machine, and terms are evaluated to something called weak head normal form. You probably don't need to understand these to reason about your program unless you're doing weird stuff with strictness, but they at least provide a guide for how Haskell evaluates things. * I'm pretty sure everything gets passed by reference, except unboxed types. Since Haskell is immutable, this is safe, and it makes immutable data structures fast. * Operations are not mutable under the hood, although they may be made mutable during an optimization pass. The general approach is to not think about the execution model until your code is correct, then to use profiling to make it efficient. But prematurely optimizing is not likely effective, and will make your job harder than it needs to be.
Fun! I was not aware of the new implementation strategy. I wonder why it is so much faster.
I'm not an expert but I think you might've just described the refinement calculus. Some theorem provers and model checkers implement it.
That looks like it. https://github.com/ekmett/reflection/blob/master/fast/Data/Reflection.hs#L169 `Magic k` is basically of type `Reifies s a =&gt; ...` and gets coerced to `(proxy s -&gt; a) -&gt; ...` and applied to `(const a)`.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [ekmett/reflection/.../**Reflection.hs#L169** (master → 6508a04)](https://github.com/ekmett/reflection/blob/6508a04342256cab34bd6aee06ec61a166ce56fb/fast/Data/Reflection.hs#L169) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
One other fairly public benchmark is [the benchmarks game](http://benchmarksgame.alioth.debian.org), so I would say putting some effort into that would also be a great idea. There are some things about the way the benchmark is set up that I really don't like, but alas it is a very public benchmark site that is often referred to. 
Why is there such a big difference with this? https://turingjump.com/blog/tech-empower/ That's 20 times worse than python/flask...
It's a bunch of probably front end devs thinking they can do systems style programming with very little background in case to know what they are doing is massively wrong.
It's not completely trivial, because pandoc has a whole lot of options. Many of these are relevant only to certain output or input formats; some are incompatible with others, and so on. So a nice GUI might change change the controls that are displayed depending on your choices. For example, if you select HTML output, it might present you with several different options for displaying math. If you select Markdown input, you might get access to a list of syntax extensions to enable or disable. And so on. 
How do I model a classical OO interface/trait? For instance this [Go interface](https://github.com/fogleman/nes/blob/master/nes/mapper.go) defines a Mapper interface. There are several implementations [here](https://github.com/fogleman/nes/blob/master/nes/mapper1.go) and [here](https://github.com/fogleman/nes/blob/master/nes/mapper2.go) Do I use a typeclass?
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [fogleman/nes/.../**mapper2.go** (master → 3b568f8)](https://github.com/fogleman/nes/blob/3b568f8e5dcc0419934aad5997da851a133dd7d3/nes/mapper2.go) * [fogleman/nes/.../**mapper.go** (master → 3b568f8)](https://github.com/fogleman/nes/blob/3b568f8e5dcc0419934aad5997da851a133dd7d3/nes/mapper.go) * [fogleman/nes/.../**mapper1.go** (master → 3b568f8)](https://github.com/fogleman/nes/blob/3b568f8e5dcc0419934aad5997da851a133dd7d3/nes/mapper1.go) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
I did a Ctrl-F "changelog" and didn't find anything.
That's just a macro that helps write dummy instances without the help of Template Haskell, so certain Typeable things can be reflected back. But that's not the real trick. The real magic that makes it efficient is the fact it simply represents the constraint dictionary as a parameter in GHC Core -- which is exactly what it *is* in GHC core. It literally optimizes down to nothing but function application; there is no other indirection. The original implementation reflected things using a clever trick involving `Storable` and `StablePtr`, but it's not nearly as cheap.
It just does less work. The current implementation boils down to a very clever way to make GHC do function application, and "apply a function to an argument" is substantially faster than going through Storable/StablePtr values to reflect things.
Cool, does that mean when 8.4.1 is released, Hackage will carry compatible packages for everything that used to build with 8.2.2? It's been delay upgrading to a new release since there are no maintenance releases of past versions, while Hackage doesn't contain releases that build with the new GHC.
TIL, thanks!
Perhaps they build it with +RTS -N1 -O0 -fvia-c -fslow-math -with-blocking-io 
Have you tried using Nix? It has some really great features for building docker images. There is a good description of using it for building small docker images [here](https://github.com/Gabriel439/haskell-nix/tree/master/project3#minimizing-the-closure). One thing not discussed there is the `fromImage` argument that you can pass to `buildImage` to allow you to make layered images. More details can be found in the [docker tools section of the nixpkgs manual](https://nixos.org/nixpkgs/manual/#sec-pkgs-dockerTools).
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [Gabriel439/haskell-nix/.../**project3#minimizing-the-closure** (master → 5b34448)](https://github.com/Gabriel439/haskell-nix/tree/5b3444871db03179752f6f6135bd2fbe085a79da/project3#minimizing-the-closure) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
I'm fairly sure the blackboard font is actually handwriting.
Perhaps we could start with Int parsing, which may universally speed up benchmarks that read ints.
Nix has some really great features for building docker images. There is a good description how to build small docker images for Haskell applications [here](https://github.com/Gabriel439/haskell-nix/tree/master/project3#minimizing-the-closure). One thing not discussed there is the `fromImage` argument that you can pass to `buildImage` to allow you to make layered images. More details can be found in the [docker tools section of the nixpkgs manual](https://nixos.org/nixpkgs/manual/#sec-pkgs-dockerTools). Building the image will only work with Nix on Linux (not macOS), but the docker images will work anywhere of course.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [Gabriel439/haskell-nix/.../**project3#minimizing-the-closure** (master → 5b34448)](https://github.com/Gabriel439/haskell-nix/tree/5b3444871db03179752f6f6135bd2fbe085a79da/project3#minimizing-the-closure) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
Everything is immutable, so it doesn’t matter how it’s passed. Things sized a machine register or smaller typically in a register. Everything else by reference (with pointer tags). Some exceptions.
As working with amazonka-dynamodb is a little tedious, I tried to write some opnionated layer (slightly inspired by persistent) to make it easier: https://hackage.haskell.org/package/dynamodb-simple I started with using `Generics` and ended up with a lot TH. Nevertheless, it seems to work quite well.
Functions are first class, you can do much of the work of interfaces without classes and instead use a data declaration. My Go is rather rusty but consider: data Mapper = Mapper { read :: Address -&gt; Word16 -&gt; IO Word8 , write :: Address -&gt; Word16 -&gt; IO Word8 , step :: IO() , save :: Encoder -&gt; IO (Maybe Error) , load :: Decoder -&gt; IO (maybe Error) }
Right. So just bundle some functions into a data type.
Well I think you can get Storable without anything magical at all -- all you need is the type level nat (and in practice, maybe type list), which is clever, but still feels within the "bounds" of the language itself (as in, it doesn't depend on implementation details or FFI). It was the arbitrary function passing that required pushing into territory that made me throw up my hands and say "I'll leave that to the mages."
Right, so just bundle some functions into a data type 
I think it's funny how good Nix is at building Docker images, considering Nix can usually make Docker unnecessary.
Doesn't `foldl` work just as well as `foldr` on bidirectional structures such as `Seq`, `Vector`, etc?
I think the problem there was the absurd microbenchmarking it represents. Like, most of those implementations are barely wrappers around pure C servers that do damn near nothing. Servant+Wai is doing a lot more logic to handle robust real world applications, and its doing it all in pure Haskell. For instance, most of those implementations are implementing routing by hard coding and manually matching on the *five* routes the benchmark requires. That's just practically zero work compared to Servant's proper routing overhead and content negotiation.
What makes you think this is a problem? Plus, it's such a generic thing implemented by so many libraries it's hard to say it's universally bad.
It's just `let`.
TechEmpower benchmarks are completely useless micro benchmarks. I always get a bunch of negative points for telling the truth.
Because it gave incorrect perceptions here only about a week ago https://www.reddit.com/r/haskell/comments/7jr2yy/haskell_and_rust_on_advent_2017_maze_challenge/
The cases where it works fine just lull you into a false sense of security. Better to use foldl' most of the time. The case in the article is one of many.
The [author of that version said](http://reddit.com/r/haskell/comments/7k4wsx/my_take_on_haskell_on_advent_2017_maze_challenge/drboya8) that was just a direct copy of the version in the bytestring library, with the only difference being to drop the extra return to make it a bit faster. I haven't seen a benchmark comparing the two versions, but I'm guessing it's pretty negligible, especially considering how fast it already was. I don't think this is a problem. The original OP had a version that was using String, and I think something else naive, so that's why his was so slow
Thanks for clearing that up .
This is absolutely awesome idea. I believed I'd be honored if I had a widely used open source library and it was featured in a project like this.
My laptop appears to be too noisy (lots of processes) so the benchmarks seem unreliable. Have seen 3.9% improvement on one benchmark and repeating it gave 0.5% regression. So I have no good results yet.
Thank you very much! That was very encouraging! These feedbacks have helped me to look at the article from different perspectives, and have surely improved the quality of the article. So, yes, thanks for all those who commented, and you, because of the encouragement.
Fantastic idea. It would be nice as well if people could "nominate" certain libraries/features for an attack. Some people may know of far more slow spots than they'd ever have time to attack themselves.
Can we open this up to general lib improvements please? I know a lot of core libs that could really use some love in the documentation department
This will of course require cooperation from package maintainers but I do hope that head.hackage will help facilitate faster adoption of new GHC releases.
Are you familiar with Monad transformers? But the essence is that a Parser 'P a' does not just produce the pair (a, remainder) but also the source position. So while a [simple](http://dev.stephendiehl.com/fun/002_parsers.html#nanoparsec) parser is 'String -&gt; [(a,String)]' you want the result (a, asEndPos, remainder) in the results. In order to get the position you need the offset at which you started parsing as well so we also pass a position on top of the string we parse. '(String, Pos) -&gt; [(a, Pos, String)]' Using stateT allows you to move the Pos argument out of the argument/ result assuming you can move it out of the list first. However I'm at the moment not sure what the trick is to achieve that. Hopefully someone else can fill that gap. After that it's a "simple" monad transformer stack. If you are unfamiliar with them it might be easier to just embed the state in your parser monad type. You can always change it to use StateT later on. 
I love this idea! I think it'd also be fun to expand the focus to documentation, which I think is another of those things where there's always room for improvement. Documentation is also more accessible to newcomers, unlike performance which often requires some expertise.
Not exactly. That version is only used for `Typeable` reflection. Note [`reify`](https://github.com/ekmett/reflection/blob/master/fast/Data/Reflection.hs#L169) never uses it and desugars basically to `reify a f = f Proxy a` plus some type coercions in core! Unfortunately the parameter `s` that gets generated that way isn't `Typeable`. And there is one usecase in `lens` where we need a `Typeable` form of `reflection` to allow creation of custom fake `Exception` instances so we can create handlers from arbitrary folds.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [ekmett/reflection/.../**Reflection.hs#L169** (master → 6508a04)](https://github.com/ekmett/reflection/blob/6508a04342256cab34bd6aee06ec61a166ce56fb/fast/Data/Reflection.hs#L169) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply drlk4xd.)^.
I like the idea of targeting a specific measurable improvement, otherwise you lose the ability to "gamify" it like this. However, another target focused on docs is a good idea too!
Fixing bugs might be an acceptable change to semantics. ;)
I will meet them in January, what do you want me to ask them? They are not really front-end devs though. You can look them up.
Typeclasses are probably the most direct way to model a classical OO interface/trait. So yeah I would probably suggest that. class Mapper a where read :: a -&gt; Word16 -&gt; IO Word8 write :: a -&gt; Word16 -&gt; Word8 -&gt; IO a step :: a -&gt; IO a save :: a -&gt; Encoder -&gt; IO (Either Error a) load :: a -&gt; Decoder -&gt; IO (Either Error a) data Mapper1 = ... instance Mapper Mapper1 where read = ... write = ... step = ... save = ... load = ...
Solidity looks an awful lot like JavaScript.....
You can statistically compile and then run the binary through UPX to compress it. See https://github.com/ajevans85/httpredirector which generates a simple wai app in a 2mb docker container.
Thanks for keeping this weekly compilation of resources going. Stellar job. 
Finally i can play with the new awesome monad transformers in 'transformers' :)
From the look of it, `histo` seems to be bottom up traversal, so when you give it a recursive data structure as input, you'll never reach bottom.
Why not do that to security as well? Particularly cryptolibraries. 
&gt; Never hesitate to create a type alias or—even better—a type &gt; It doesn't matter if it doesn't get exported, or only gets used by one function, or has a wonky name: types are always good. &gt; One of my major pet peeves about Haskell-the-language is that I can't define new types within let bindings or where clauses, like one can in other ML languages, because sometimes I want a new type for just a few lines. This may be interesting to you or the author: https://ghc.haskell.org/trac/ghc/ticket/4020
Still, when they ran the tests themselves, [the results](https://turingjump.com/blog/tech-empower/) were vastly different.
&gt; There has to be something wrong There have been at least two serious attempts that I heard of to fix it. It actually requires a lot of work, and probably some horrible hacks. I understood that servant loses a lot of time by doing the right thing, parsing and acting on the request headers for example, whereas many of the other solutions just ignore them. There is also the problem that it is not really a *web* benchmark, the database library seems to be extremely important, and it is pretty slow. To achieve good speed, a smart, probably native, implementation would be needed (something that opens a pool of connections, and that supports batching).
About the database layer story, I know one person who works on the Vert.X benches, and he basically had to [write this](https://github.com/vietj/reactive-pg-client) to be competitive.
Wtf. Why are the results on the site so different from these?
But the Spock results aren't much better and [they're just hardcoding the five routes](https://github.com/TechEmpower/FrameworkBenchmarks/blob/master/frameworks/Haskell/spock/src/Main.hs#L117) and [setting the content type directly](https://github.com/TechEmpower/FrameworkBenchmarks/blob/master/frameworks/Haskell/spock/src/Main.hs#L81). I feel like we'd have a lot more ground to stand on if we did well, then claimed it was only because of hacks that shouldn't be necessary. When an A student criticizes a class, it might be worth listening to; when someone in the 1st percentile (as in, bottom 1%) criticizes a class as full of crap, well.. I think he's just salty.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [TechEmpower/FrameworkBenchmarks/.../**Main.hs#L81** (master → 10a7827)](https://github.com/TechEmpower/FrameworkBenchmarks/blob/10a7827794446cb8d82eaa08c04a8317627cedf2/frameworks/Haskell/spock/src/Main.hs#L81) * [TechEmpower/FrameworkBenchmarks/.../**Main.hs#L117** (master → 10a7827)](https://github.com/TechEmpower/FrameworkBenchmarks/blob/10a7827794446cb8d82eaa08c04a8317627cedf2/frameworks/Haskell/spock/src/Main.hs#L117) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
Were those run before or after? It sounds like they're from before the official benchmarks. Still, in any case, that's a huge difference. If the results in that blog post are accurate, it means everything's fine. If the official results are accurate, it means we have a problem somewhere.
Thanks!
Well see my response I just made above -- the Spock implementation doesn't score much better and they just hardcode the output header and routes, so I don't think that's the problem. &gt; There is also the problem that it is not really a web benchmark, the database library seems to be extremely important I agree it's probably the database libs, especially considering that the other benchmark results aren't as bad as this one.
&gt; I will modify my instance accordingly: in this case, I can using the QuickCheck-provided Positive newtype, whose Arbitrary instance will only ever create positive numbers, &gt; also pet names aren't going to be arbitrary unicode sequences; they're going to be validated so that people don't name their pets emoji or the empty string or something like that, so now I have two axes along which a pet might be invalid I think a very good solution to these sorts of "problems" is to change the declarations of types in your `Pet` type so that your `Pet` type more fully reflects which inhabitants are allowed and disallowed. In fact, I advertise this as a feature of QuickCheck like libraries: If your QuickCheck generators are complicated, it's an indication that your types are making illegal state representable and seeing this QuickCheck ugliness can be a mechanical way for people to build an intuition about "tight" types.
I forgot to mention that I corrected the article to be technically right, and mentioning that a "partially applied function is a monad". Thanks again for the hint!
&gt; building a monad alias over a monad stack that has a StateT SourcePosition You probably misintepreted that sentence. The idea here is that you create a `Parser` type by assembling a suitable monad stack, and then wrapping that in a newtype or in a type alias. We wouldn't actually use `StateT SourcePosition`, because we need to track not only the source position, but also the state of the input stream. So: data ParserState = ParserState { psInput :: [Char] , psSourcePos :: SourcePos } data ParserError = ParserError { errorMessage :: String , errorPos :: SourcePos } data SourcePos = SoucePos { sourceFile :: FilePath , sourceLine :: Int , sourceColumn :: Int } -- convenience functions for advancing the parser state: nextSourceColumn :: SourcePos -&gt; SourcePos nextSourceColumn sp = sp { sourceColumn = sourceColumn sp + 1 } nextSourceLine :: SourcePos -&gt; SourcePos nextSourceLine sp = sp { sourceLine = sourceLine sp + 1 , sourceColumn = 1 } type Parser m = StateT ParserState (ExceptT ParserError m) Now armed with this type, you can write a few primitives. The first thing we need is a convenient function to throw a parser error: throwParserError :: String -&gt; Parser m a throwParserError msg = do -- This is where we attach source position information to our parser -- errors pos &lt;- gets psSourcePos throwError $ ParserError msg pos Next, we need primitives to "peek" ahead, and to consume the next character from the input stream. peek :: Monad m =&gt; Parser m Char peek = do input &lt;- gets psInput -- this fetches us the remaining input stream case input of (x:_) -&gt; return x _ -&gt; throwParserError "Unexpected end of input" consume :: Monad m =&gt; Parser m () consume = do input &lt;- gets psInput pos &lt;- gets psSourcePos case input of (x:input') -&gt; do -- This is where we update the source position to keep it accurate let pos' = case x of '\n' -&gt; nextSourceLine pos _ -&gt; nextSourceColumn pos modify $ \ps -&gt; ps { psInput = input', psSourcePos = pos' } _ -&gt; throwParserError "Unexpected end of input" We can express all other parsers in terms of these two, e.g.: next :: Monad m =&gt; Parser m Char next = do c &lt;- peek consume return c satisfy :: Monad m =&gt; (Char -&gt; Bool) -&gt; Parser m Char satisfy p = do c &lt;- peek if p c then do consume return c else throwParserError $ "Unexpected " ++ show c This isn't exactly what you would see in a real, production-quality parser combinator library, but the essence is the same. If you want to see what it looks like in the wild, I recommend looking at the source code for Parsec, Megaparsec and Attoparsec. They all take slightly different approaches, but the core mechanisms are very similar. So that's the parser error part. Now on to errors in subsequent parts of the pipeline. Once we leave the realm of the parser, the concept of "current source position" becomes less meaningful, because our Abstract Syntax Tree is, well, abstract - it doesn't naturally have a source position anymore, its shape follows the shape of the programming language constructs we're modeling. Which means that if we want to retain source position information, we need to add it into our data model ourselves. Suppose our "naked" AST looks like this: data Expr = LitExpr Value -- a literal value | AppExpr Value -- apply a function to a value | VarExpr Name -- get a variable's value | LetExpr Name Expr Expr -- let-bind an expression This is almost enough to cover a basic untyped functional language, enough to demonstrate the ideas here anyway. Now, the naive approach, adding source position information to every constructor, would give us this: data Expr = LitExpr SourcePos Value -- a literal value | AppExpr SourcePos Value -- apply a function to a value | VarExpr SourcePos Name -- get a variable's value | LetExpr SourcePos Name Expr Expr -- let-bind an expression Simple, and it works - now every expression knows where in the source code it was originally defined, and we are forced to conjure up a `SourcePos` whenever we construct any expression. But we don't always have source positions at hand, so this can be inconvenient. So instead, we may want to make our AST polymorphic: data Expr s = LitExpr s Value -- a literal value | AppExpr s Value -- apply a function to a value | VarExpr s Name -- get a variable's value | LetExpr s Name Expr Expr -- let-bind an expression Our parser will then produce `Expr SourcePos` values, but we can use `Expr ()` for synthesized AST that isn't based on source code, or we can use `Expr (Maybe SourcePos)` when mixing synthesized and parsed AST. Deriving a Functor instance makes this trivial: for example, we can erase source information using `fmap (const ())`, or we can translate `Expr SourcePos` to `Expr (Maybe SourcePos)` using `fmap Just`, or `Expr ()` to `Expr (Maybe SourcePos)` using `fmap (const Nothing)`. Then in the intepreter (or code writer, as the case may be), whenever we evaluate an expression, we will take note of its source position, and if there is an error, we use that source position to construct our error message. Again, automating this mechanism is a matter of a few straightforward utility functions, no rocket science here. The pseudo-expression approach takes a different path: instead of adding the source info to each data constructor, we introduce an *additional* data constructor whose sole purpose is holding source position information: data Expr = LitExpr Value -- a literal value | AppExpr Value -- apply a function to a value | VarExpr Name -- get a variable's value | LetExpr Name Expr Expr -- let-bind an expression | SourcePosExpr SourcePos Expr `SourcePosExpr` wraps an expression to annotate it with source position information. Whether the fact that we can wrap a SourcePosExpr in another SourcePosExpr is desirable is open for debate, however I don't have any fundamental objections myself, and it may even be useful to annotate an expression with multiple source positions - e.g. if your language supports compile-time includes, it may be useful to track both the source of the include construct and the source position inside the included file, and since includes could nest, arbitrarily long chains of annotations would be a perfectly reasonable thing to allow. With this approach, we can also polymorphize `Expr`, although it is less useful here, because we can simply model the absence of source position information by not using any SourcePosExpr values anywhere. Then, our interpreter (or code writer) will need some sort of stack mechanism to keep track of the source position. We can do this in two ways. The first one is to use a StateT that contains a list of recent source positions, newest first (i.e., the list acts as a stack). Evaluating a `SourcePosExpr` pushes the new position onto the stack, then evaluates the child expression, and finally pops the position back off the stack so that the caller gets to continue in the original context. If an exception occurs, the current source position is read from the stack and added to the error message, and then during exception handling, the stack is unrolled because we have those "finally"s in place. The second way is to piggy-back on Haskell's call graph. This requires our exception type itself to contain a source position stack. When an exception occurs, we will first throw it without any source information attached to it; however, the evaluation function for `SourcePosExpr` will use `catchError`, and modify the error message by adding its own source position before rethrowing it. This way, the evaluation call graph will produce the same kind of unrolling behavior, and once the error reaches the original topmost caller, it will contain a neat stack of source positions, just like it would in the first approach. Does that make sense? 
Measuring "security" is much harder than measuring allocation or speed. Unless you mean e.g. entropy of random number generators?
Yes keeping an eye on the entropy source on different platforms can be daunting. I think there are other valuable reviews that a user can do 1. Documentation ofcourse 2. If any code looks funny and is not clearly documented, ask for clarification 3. Using a better type 4. May be some liquid haskell checks. 
The observations on typeclasses and readability are insightful. Typeclasses can make code easier to write, but harder to read. The thing is, writing code is easier than reading it. When I write code, I’m immersed in what it does. When I read it, I have forgotten everything about how it works. So it’s often better to write for readability, but this is more tedious and takes time. 
&gt; What are the advantages of a pure functional programming language? I see some advantages of functional programming but I don't see, why a language should not allow also imperative Programming. Yeah, that's why it does allow it. &gt; What are cool features I would miss at other programming languages? List comprehensions are somewhat cool but what else? To be honest, if you're naming something purely syntactical as a single "somewhat cool" feature then you haven't really seen anything yet. I'm sure you can find a ton of material that answers your question with a single search. &gt; Haskells function are often so undescriptive. Lets say I have some function like "foo :: String -&gt; Int". Since I have no variables I don't know what the String is supposed to be and what the integer that comes out should be. In Java I could write something like "int foo(String name)". In short: I have no variable-names to make code more easy to read. Witch brings me to my next point. This doesn't make any sense. The function definition doesn't stop at the type signature. We do like types much more than names, that's true. That's why we usually avoid ambiguous "catch-all" types like String and Int. In any case, you just need to look one line bellow that type signature to see the names of the functions parameters. &gt; When I want to write something in Haskell, I am so slow, slower than in any other language. It is so unproductive. And even if I try to read Haskell-code I am even slower. I'm gonna take a wild guess and say this is because you don't know the language. All in all, don't worry about productivity. You'll get there when you learn the language and get some experience. It's probably much less frustrating to forget everything else you know about programming and treat learning Haskell as a puzzle.
Short comment, because on mobile: we don't write`String -&gt; Int`, but rather `Name -&gt; Age`. &gt; I have a function which takes a *Name* and returns an *Age*. Note, you could say that even you write JavaScript, in Haskell we tend to write what we say :) &gt; A Parser for Things is a Function from Strings to List of Pairs of Things and Strings newtype Parser thing = P (String -&gt; [(thing, String)])
One trick to make code with type classes more readable: add `-XInstanceSigs` extension and add type signatures to methods in instances.
&gt; Lets say I have some function like "foo :: String -&gt; Int". Since I have no variables I don't know what the String is supposed to be and what the integer that comes out should be. foo :: String -&gt; Int, is a type declaration it tells you only that it takes a String to Int which you understood just fine. The function definition would contain the variable names. I have some serious question if you have ever written any Haskell at all if you thought what you gave for foo is a full definition that would execute but was non-descriptive. So I suspect trolling on your are literally first day or a few days into learning Haskell. In which case it is simple. Haskell is going to quickly show you very sophisticated things that apply generally that purity makes possible; show you things you simply could never or would never do in Java. For example that stuff you like about list comprehensions is going to apply in shockingly general contexts as varied as: almost all data structures, parsers, error messages, execution strategies, aspects of state. And as you see this work in example after example after example you begin to realize how short Haskell code is. It is short because you have at hand incredibly powerful abstractions that work in all contexts. They work in all contexts because of purity. Haskell won't just teach you how to write better programs it will teach you how to write perfect programs. But of course if ultimately you don't want to see it Haskell isn't going to make you. Nobody can force you to learn anything. 
&lt;troll&gt;GHC?&lt;/troll&gt;
so basically you are frustrated that you have to learn something you don't need? This is ok but please stay civil - as you mentioned yourself we tent to like Haskell here (a bit) As you asked for some nice stuff - I always liked SPJs "beautiful concurrency" (https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/beautiful.pdf) and it fits the season - of course you can have STM in other languages as well but Haskell makes it actually feasible and a joy to use "type signatures are undescriptive" - well have a look at the famous "theorems for free!" by Wadler (http://homepages.inf.ed.ac.uk/wadler/topics/parametricity.html) - you'll see that the opposite is true Cannot help you with the slow going - you have to help yourself (hint: there is a advent of code going on - why not have some fun and try the exercises in Haskell - you'll learn to love it quickly I think) As for our arrogance: sorry (don't know what else to say) So I'm afraid I cannot really help you love Haskell but I'd love to help you out getting to speed if you can calm just a bit down
I'm starting to agree :) Already spent some time with the struggle tho. Tools will hopefully only become better for all platforms, but i think setups with simple editor with highlighting + command line works fine. Haskelling is enjoyable nonetheless.
Nice, according to [this issue](https://github.com/duog/generic-lens-labels/issues/7) of `generic-lens-labels` it appears that some variant of this has been integrated into `generic-lens-0.5.1` ~4 days ago.
In my opinion the function name is crucial, however the name of the parameters are not. I get you called it "foo" as an example, but the real function name is "length". That provides good description. However the String "int length(String ...)" is hard to be named. Some libraries in Java and Typescript call them "v" or other meaningless names. Also a better type is "[a]" -&gt; Int" instead of String, because it tells you more than "String -&gt; Int", the former means it will return either a constant or the length, the latter means it can be a constant, length or a parsed Int or a lot of crazy stuff based on the argument. In languages like Java, types are useless, "int foo(String name)" can be a function that does the same as those in Haskell, or get a global or a property of an object or a value from the other side of the galaxy, who knows?
I see that you know multiple languages. But can you recall when you first learned programming? Was it, like, super smooth? As you may have noticed, Haskell is a pretty different language. You may have learned C after Java and had a very easy time -- perhaps you could learn enough in a day! But if we add Haskell into the picture, Java and C almost look identical. Therefore &gt; When I want to write something in Haskell, I am so slow, slower than in any other language. It is so unproductive. And even if I try to read Haskell-code I am even slower. Did read/write code super-fast when you first learned programming? I'm certain that you could quickly get up to speed because you have only learned similar languages, and the skills transfer easily. Would you please let Haskell sink in more before judging? Also, this means that by learning Haskell you learn whole new areas in computer programming. Since you are in university, I suppose you want to learn more? Then have a look at these new things Haskell has to offer please. &gt; What are cool features I would miss at other programming languages? I want to add this: You can work with higher order functions nicely. Various combinators allows you to use function applications where in other languages you might resort to metaprogramming. And static types will guide you through the way, by giving you hints about what you could do (see: typed holes). And it's much easier to keep these seemingly advanced stuffs in control, since as you refactor your code you could almost just change a little bit and let the compiler tell you what needs to changed accordingly. This way you aren't going to debug mysterious run-time type errors or template errors (*cough* C++). Please be patient. If you don't want to be patient then... sorry.
I see that you know multiple languages. But can you recall when you first learned programming? Was it, like, super smooth? As you may have noticed, Haskell is a pretty different language. You may have learned C after Java and had a very easy time -- perhaps you could learn enough in a day! But if we add Haskell into the picture, Java and C almost look identical. Therefore &gt; When I want to write something in Haskell, I am so slow, slower than in any other language. It is so unproductive. And even if I try to read Haskell-code I am even slower. Did read/write code super-fast when you first learned programming? I'm certain that you could quickly get up to speed because you have only learned similar languages, and the skills transfer easily. Would you please let Haskell sink in more before judging? Also, this means that by learning Haskell you learn whole new areas in computer programming. Since you are in university, I suppose you want to learn more? Then have a look at these new things Haskell has to offer please. &gt; What are cool features I would miss at other programming languages? I want to add this: You can work with higher order functions nicely. Various combinators allows you to use function applications where in other languages you might resort to metaprogramming. And static types will guide you through the way, by giving you hints about what you could do (see: typed holes). And it's much easier to keep these seemingly advanced stuffs in control, since as you refactor your code you could almost just change a little bit and let the compiler tell you what needs to changed accordingly. This way you aren't going to debug mysterious run-time type errors or template errors (*cough* C++). Please be patient. If you don't want to be patient then... sorry.
&gt; At University I have to learn Haskell and till now I really do not like it. Sorry about that.
In this proposal I'm specifically focusing just on taking a given Haskell package and making it perform better than it was. It's really easy to confirm the results. 
Indeed, performance is straight-forward to measure reliably, docs are hard to motivate.
Before I tried to do something similar by hand, in order to avoid other developers having to install Haskell dev tools because they were programming other parts of that system in other languages. I like this way of working because it is easier for integration of various parts of a single multi-language project.
OK. That's fair.
Taking a bit more time may be a fair point. Thank you.
This is very useful. Especially with type families
&gt; so basically you are frustrated that you have to learn something you don't need? It is a bit more than that but yes. I don't see where I ever want to use Haskell if I can choose myself. &gt; This is ok but please stay civil - as you mentioned yourself we tent to like Haskell here (a bit) Did I not? I really tried. &gt; As you asked for some nice stuff - I always liked SPJs "beautiful concurrency" (https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/beautiful.pdf) and it fits the season - of course you can have STM in other languages as well but Haskell makes it actually feasible and a joy to use Thank you for that. I will look into it. &gt; "type signatures are undescriptive" - well have a look at the famous "theorems for free!" by Wadler (http://homepages.inf.ed.ac.uk/wadler/topics/parametricity.html) - you'll see that the opposite is true Also thank you for that. :) &gt; Cannot help you with the slow going - you have to help yourself (hint: there is a advent of code going on - why not have some fun and try the exercises in Haskell - you'll learn to love it quickly I think) &gt; As for our arrogance: sorry (don't know what else to say) I don't expected an answer here. I wonder if this Haskell-elitarism is unique to my university? Oh well. &gt; So I'm afraid I cannot really help you love Haskell but I'd love to help you out getting to speed if you can calm just a bit down. Thanks again. Did I really sounded that upset? 
&gt;&gt; What are the advantages of a pure functional programming language? I see some advantages of functional programming but I don't see, why a language should not allow also imperative Programming. &gt; &gt; Yeah, that's why it does allow it. I don't understand. &gt;&gt; What are cool features I would miss at other programming languages? List comprehensions are somewhat cool but what else? &gt; &gt; To be honest, if you're naming something purely syntactical as a single "somewhat cool" feature then you haven't really seen anything yet. I'm sure you can find a ton of material that answers your question with a single search. I am sure I can't. &gt;&gt; Haskells function are often so undescriptive. Lets say I have some function like "foo :: String -&gt; Int". Since I have no variables I don't know what the String is supposed to be and what the integer that comes out should be. In Java I could write something like "int foo(String name)". In short: I have no variable-names to make code more easy to read. Witch brings me to my next point. &gt; &gt; This doesn't make any sense. The function definition doesn't stop at the type signature. We do like types much more than names, that's true. That's why we usually avoid ambiguous "catch-all" types like String and Int. In any case, you just need to look one line bellow that type signature to see the names of the functions parameters. Well, I think I wasn't clear at that paragraph. &gt;&gt; When I want to write something in Haskell, I am so slow, slower than in any other language. It is so unproductive. And even if I try to read Haskell-code I am even slower. &gt; &gt; I'm gonna take a wild guess and say this is because you don't know the language. &gt; &gt; All in all, don't worry about productivity. You'll get there when you learn the language and get some experience. It's probably much less frustrating to forget everything else you know about programming and treat learning Haskell as a puzzle. I don't know if that helps.
Well [it is a library](https://wiki.haskell.org/GHC/As_a_library). Kinda.
&gt; You may have noticed, in the definition of `sortBy`, that we map the `reflectOrd` and `unreflectOrd` in order to convert between `a` and `ReflectedOrd s a`. However, while, `reflectOrd` and `unreflectOrd`, have no computational cost, using them in combination with map will traverse the list. If you are dissatified with this situation, you will have to learn about the `Coercible` type class. GHC has rewrite rules set up that should, ideally, optimize `map reflectOrd` to `id`: http://git.haskell.org/ghc.git/blob/master:/libraries/base/GHC/Base.hs#l1136
Haskell does allow for imperative programming. It's a bit of an overloaded term but pretty much any aspect that you might consider imperative is doable in Haskell. The `do` notation that's pretty central in most Haskell code is very imperative. If you're thinking of mutating variables, this is also done via the various Ref types like `STRef` or `IORef`. Personally I find type level features very exciting and I miss them in other languages. Things like HKTs for example. I like that I can talk about the various side-effects my function is doing. I like that purity is forced and that global mutable state is extremely inconvenient to do, it makes understanding functions a million times easier. 
Denotational semantics is a different paradigm from procedural. Why don't C, C++ allow denotational semantics? While learning Haskell I used procedural languages less and less because I found a paradigm that fit the way I think about and plan programs closer, which is to program by writing a description of what something is or means, specifically a description of what it is to be what I intend it to be, rather than a description of what it's doing, how it's being, which is orchestrated in order to achieve the required state-transition conditions. I was able to derive the circumstance-of-being-dependence logic form of what I'm asking to exist on the machine, but now I don't have that consistent layer of indirection between what I'm trying to express and a working implementation. * Do you ever write a function for handling one situation, then you enter the same situation again but with different types, and you can't back out of it to where you can apply the original function? You could only apply the function in a way that destroys information about how to use the results. * Do you ever find yourself writing a sequence of functions that return either a value representing meaningful data or another signal indicating a default meaning, and knowing that if the first function defaults the whole pipeline defaults, but that you can't combine them without losing modularity? * Suppose you can still continue the computation after backing out to simpler types, but you've realized it's much easier to write code that shows how to extract a feature about the state than it is to extend that into code that updates the state, or it takes time to do so. Polymorphic higher-order functions (functions between functions) let you handle all of a class of situations with the same piece of code, which means it only has to be written once and learned once to be used in all those situations. There's things humans regularly try to do and ways they try to describe things, and the patterns go back millennia. That's why the solutions are mathematical concepts. And it suggests other things, like, do libraries really have to fit together this way? Do I really have to restrict the code I write with this library to the callbacks it needs and give up my program managing its own control flow and having the integrity of the control flow model included in the code? Why can't two libraries for doing the same thing ever interoperate? Why should I switch, actually? The latter's not necessarily a problem solved in Haskell, it's just the kind of thing worth questioning.
Useful for [`Generics`](https://hackage.haskell.org/package/base-4.10.1.0/docs/GHC-Generics.html) where we can cast problems of isomorphisms into a smaller universe of `Rep` / `Rep1` (confusingly named the same as [`Data.Functor.Rep.Rep`](https://hackage.haskell.org/package/adjunctions-4.3/docs/Data-Functor-Rep.html#t:Rep)).
nix can replace docker if you're willing to run nixos or install nix on the host. But if you use other docker images (such as prebuilt ones, eg. from hub.docker.com) then having everything packaged up as docker images makes more sense, run coreos or something similar on the host, and separate docker containers for each application.
I would say the real advantage of Haskell is that it's powerful enough to use in a practical-sized system without having to step "outside" the language. In most languages, for a practical-sized system you will inevitably end up using reflection, AOP, monkeypatching, metaclassing, or some other form of "magic" that destroys your ability to reason about the system. That's fine as long as your program is small enough to keep the whole thing in your head at once - say, less than 20k lines - but means that smaller parts of the program are impossible to understand in isolation. Once you get past that 20kloc limit, all bets are off: you have to add unit tests to everything to understand how anything works, you're scared to do things like delete unused variables or inline functions, in case the variable is exposed via a web handler and the function is used as an AOP pointcut. So you drift towards making the smallest possible changes you can, and your codebase gradually rots: you make changes by adding patches upon patches, each one slightly harder to apply than the last, because you don't dare do any big refactors. Whereas in Haskell you can refactor fearlessly. If you see `f (g a) (g a)` you really can replace that with `let b = g a in f b b`, *blindly*, no ifs, no buts. Very few other languages make that possible in practice, even though it works in theory and in basic examples. 
&gt; "There are two types of people, those who like Haskell and those who don't understand it." Yeah right. "Haskell is great because in every other language things don't work." WTF. I hope I speak for most of us when I say: that sort of divisive language has no place in the Haskell community, and I'm sorry that someone said that to you. Some people like to make themselves feel important and clever by putting people down - _"I know something you don't know"_ - but really it does no one any favours. It just puts people off! The Haskell community I know is all about sharing and teaching new ideas, and we love to help newcomers learn this beautiful language. We know that there's a steep learning curve (we all went through it!), but we know that it's worth it and we want to help you become a better programmer by getting to the other side.
Hello and welcome to r/haskell! You will be excited about Haskell, when experience have taught you that rampant state and lack of effect management kills your productivity and makes you and your users hate your software. It's never about "cool features". It's all about "how can I maintain this software for potentially decades". If the software you write is inconsequential, and not under constant pressure from users and lack of time, then the language hardly matters. Pick whatever. The language does though start to matter a lot, as you scale up and out in terms of size and complexity. This is where Haskell shine, IMHO. I've got a 130kloc Dart project running 24/7 in my company, and while I'm very happy with Dart as a language, I've started the process of moving to Haskell. Why? Primarily because I'm sick and tired of having state and effects all over the place. I fully admit, that despite my experience (programming since 1981), I lack the mental capability to keep my imperative systems nice and clean. In short: I really don't want a function named *Map xmlToJson(String xml) {..}* touching the database or doing random IO stuff, but it is **impossible** for me to guarantee that it doesn't. That little sucker should simply convert some XML to JSON, and yet here we are, having just launched a bunch of missiles. Haskell makes it clear in the signature, whether or not you have effects, and it makes it simple to reason about state. What kills you in the end, is managing state and effects. Everything else is easy - well, except of course cache invalidation and naming things. :) When I started my Haskell/Elm journey, I felt my brain was about to melt (I still get that to be honest), because I was so used to think about code as a recipe, a series of steps. Now I'm slowly starting to think in terms of types and how things compose and transform. Stick with it, and you will get there. Even if you never end up using Haskell in your future career, it will for sure make you a better programmer. I've personally never experienced the "arrogant Haskell programmers". I find the community to be very welcoming towards beginners, so I can't help you there. :o)
I'd like to expand on this because that would've been my reply too. In the definition of `foo` the name of the parameter would be right below the type instead of next to it: foo :: String -&gt; Int foo name = ... In Haskell it is super easy to introduce a type alias: type Name = String Just one line anywhere in your file. Haskellers will do this a lot. If you want to prevent confusion between a string that represents a name and a string that represents an email this is super easy too: newtype Name = Name String newtype Email = Email String Again a single line anywhere in your file. In Java for example this is cumbersome enough that people will usually not do it. The definition of `foo` would then be foo :: Name -&gt; Int foo (Name name) = ... In larger projects this can help to ensure that no name ends up in an email field of your database.
Why like Haskell? Because after 9 months experience with programming, I was brought on as an intern at a company using Haskell... and I was actually able to contribute. With that little experience, I couldn't have added any value in any other language I've used. The true strength of the language is in how it combats common bad ideas in code, and enables the least qualified programmer to write adequit code. The language features themselves are also a highpoint with Haskell, but everyone else seems to have them covered (monads, arithmetic types, tiny scope, etc) so I'll not talk about those. If you really want to complain about Haskell, complain about the build setup (it's not ergonomic), documentation culture (type signatures should not count as documentation), and the perils of analyzing runtime performance. No offense to the community, but the culture of Haskell neglects the human side of programming. I hope we continue to improve in that regard.
Does this mean DPH is back in development? I can't wait to access that awesome syntax.
The paper's from last year. Haven't seen anything that suggests that stream fusion is about to make a new leap.
Thankyou!
In other words, if I understand correctly, the goal here is to improve the lives of practicing Haskell by making widely-used libraries more performant. This has nothing to do with improving public advertisements for programmers that are not yet using Haskell.
&gt;Please change my view and make me exited to learn Haskell No. 
I can't build some basic things like Cabal and transformers against GHC 8.4alpha1 even with this overlay. Is that expected or am I doing something wrong?
I ll try, but I don't think I can get you to like Haskell more right now. I like the syntax of Haskell. There are no commas, semicolons or parenthesis. After you get a bit used to this you will hate writing any other syntax. The productiveness that you are facing will disappear as soon as you learn or understand that you can express the same stuff that you were writing with loops, if - else and switches much more safely/efficiently using/combining filter, folds and map functions. If loops, if else (statements) and switches are the words that make the vocabulary of the programming language you knew before, filter, folds and map make up the vocabulary of Haskell (and similar languages). Once you learn to use that and express stuff using this new vocabulary, you will be as productive or even more, than you were in those imperative languages. Then you will *love* writing Haskell. Then there is the type system, which has a rich (but different) vocabulary on its own, and once you enter there, you will hit another level of frustration in the form of various extensions. But that too, will pass. What a type system lets you to do is that it allows you to say things to the compiler, so that it will make sure that you are not making a mistake, at any point in the programs. Simple type systems lets you to say simple things. Rich type systems lets you to say much more, so that the compiler can check more things, helping you to write safer programs. You will also come to love this, but it will take much more time that the former. But at this point you are already very productive in Haskell. And there will still be a lot of stuff to learn. So it will still be interesting... How did i do? 
Did I miss something, or isn't this paper from 2013 even? (Also, doesn't anybody else find these "as fast as C!!!11" exclamations kind of childish? Just saying...)
Have added a small write up [here](https://github.com/sras/ghci-remote/tree/master). Please let me know if you need anything more..
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [sras/ghci-remote/.../**0842a9005a327396d5139e10b3ca554e60e1abcb** (master → 0842a90)](https://github.com/sras/ghci-remote/tree/0842a9005a327396d5139e10b3ca554e60e1abcb) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply drmn0ci.)^.
C++ template errors are literally the reason why I picked up Haskell, after reading a post by Bartosz Milewski which [relates template metaprogramming to functional programming](https://bartoszmilewski.com/2009/10/21/what-does-haskell-have-to-do-with-c/). It's a shame though that *Learn You A Haskell* almost caused me to give up on it again. Thank god I didn't.
Did this get implemented? I wasn't aware GHC handled SIMD.
a great list! maybe take a look into generics-sop and sum of products stuff in general!
Cool thanks, I'll add that to [my playground](https://github.com/fosskers/playground/tree/master/haskell).
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [fosskers/playground/.../**haskell** (master → 25adb4c)](https://github.com/fosskers/playground/tree/25adb4c4b53dd8896d748dfecf2253a3a7b422d5/haskell) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply drmnxqk.)^.
I believe GHC offers an API allowing you to invoke simd instructions manually, but it won't vectorize things automatically like c compilers do.
Umm, this might sound odd but why is rainfall defined like that? Just curious. Seems to me like your could come up with a numerical answer to countWetWeeks instead of creating a list for rainfall to act over. Then again, if this is an example function, feel free to ignore me. So what i'd use instead of list comprehension is use foldr, scanr, map, filter or a combination whenever I can. It makes code a little easier to read and I find it easier to refactor if necessary. List comprehensions are a bit harder to figure out if they get a little more complex. rainfall n = 3.9 * (fromIntegral (n `mod` 7)) countWetWeeks n = (length) . (filter (&gt;10)) . (take n) . (map rainfall) $ [1..] Try figuring out what that function does. If it's a bit too hard, here's an in-depth explanation countWetWeeksExplanation n = numberOfWetWeeks where rainyWeeksInfinite = (map rainfall) [1..] --- This maps rainfall over an infinitely long list of integers starting from 1. rainyWeeks = take n rainyWeeksInfinite --- Takes the first n elements of the infinitely long list. Haskell allows you to mess around like this because it's lazy. --- So it's not going to construct the entire infinite list, just what you require. wetWeeks = filter (&gt;10) rainyWeeks --- This filters only those elements that are greater than 10. numberOfWetWeeks = length wetWeeks --- This counts the length of wetWeeks --- One benefit of doing it this way is that you don't worry about edge cases like n = 0 (in your code, you made that = 0 explicitly.) In this case, you'd get the length of an empty list which is zero (which kinda makes sense if you think about it.) You can also mess around quite easily with the function to find the number of dry weeks. If you really wanted to, you could do this. countRainyWeeks n f = (length) . (filter f) . (take n) . (map rainfall) $ [1..] This would allow you to to set the function you want whenever it's applicable to your code. So something like countRainyWeeks 5 (&gt;10) would give you the same result as countWetWeeks 5 --- If you were a full-blown weather man who needs absolute efficiency, you could even make rainfall a function passed to the argument. This way, you could write simple functions for snowFall or hailStorm or whatever you want and plug it into: countConditionalWeeks n f weatherCalc = (length).(filter f).(take n).(map weatherCalc) $ [1..] One benefit is that you can use this pretty much anywhere AND if you were to write multiple functions to use this function, you know exactly what the type signature is for your weatherCalc function (Int -&gt; a) where a is likely a double or an integer. 
(Continuation because that comment was getting too long.) So it might take a while to read a function that's rather terse like the one I just wrote but it's much easier to deal with and it has the benefit and being much more readable in the long run. Reading the type signatures for foldr, foldl, scanr, scanl, map &amp; filter makes this much easier in my opinion. If you're stuck with something, let me know :)
But I thought the point of the paper was that it does happen automatically. I mean it says in the abstract "high-level Haskell code written using our compiler and libraries can produce code that is faster than both compiler- and hand-vectorized C." That doesn't sound like "we made a way to manually invoke SIMD." Did something go awry somewhere between the paper and actually getting implemented?
Nowadays you’re better off with the [Accelerate](https://hackage.haskell.org/package/accelerate) framework which can generate SIMD or GPGPU code for you. 
Nix is… fresh air. Once you try it you'll feel dirty with all other distros :P
Is `nix` + Haskell a good way to begin, before attempting NixOS? Not sure if I need full NixOS.
Get yourself a Haskell job! You're already there. Serokell, IOHK, FPComplete, and Confer Health are all hiring Haskellers right now.
This is very reassuring to hear, thank you.
Just completely anecdotally, I find NixOS a much better environment for working with nix than anything else. Otherwise I quickly start fighting against whatever other package management system I've got going. You do not need to be well versed in writing Nix expressions to get a usable system up and running and configured how you like it. I dual boot and am slowly spending more and more time on the NixOS side.
&gt; So, here is my working task list: &gt; My long-term goal is a Haskell job. Non of this is needed for getting Haskell job. Sure, such things are interesting and it's extremely exciting to learn them. But usually in practice almost nothing from your list is required. If you want to get a Haskell job then I recommend you to just write some production code. Like, come up with idea of some simple CLI tool which might ease your life and implement it. Maybe this tool become too big and you even will use monad transformers! Or contribute to some open-source project. Or, even better, create your own package and maintain. Try to make one package be great! You will not only improve your skills but also help community and language ecosystem. When I learned Haskell I found that only learning theory doesn't help me much, I need to have a lot of practice. This holds even after I learned Haskell. Mostly I gain skills and experience while I'm coding something, not just learning. A lot of my friends have Haskell job and some of them aren't even aware of things you mentioned. But they have their own packages and they have a lot of programming experience. Don't learn things just to learn things. Learn through creating. `Use miso and GHCjs for something` and `Rewrite this hunk of outdated crap` are good canditates! `Graphs are neat` probably won't help you much. For example, I'm writing tool which collects different statistics from data given in form of list of tuples. I found ideas from this recent Reddit post very useful! My data is small so I don't care about performance. But code is really neat and it's a pleasure to work with! * https://www.reddit.com/r/haskell/comments/7f50q9/functional_pearl_nested_datacubes_tim_philip/
I've been playing around with it recently! Took a bit of work to get it setup and running (it half-found half-didn't-find my CUDA installation), but eventually I got it working and was able to run the examples and start experimenting. But numerical Accelerate-style code really isn't the only use case for SIMD. You can see here [Intel is openly promoting SIMD for XML Parsing](https://software.intel.com/en-us/articles/xml-parsing-accelerator-with-intel-streaming-simd-extensions-4-intel-sse4/)! C actually [has trouble implementing some of these transparently because it doesn't have the memory safety guarantees necessary](https://stackoverflow.com/questions/26586060/why-is-strcmp-not-simd-optimized), but Haskell shouldn't have that issue.
&gt; But usually in practice almost nothing from your list is required. I had guessed as much, but I still want to understand advanced topics. &gt; I need to have a lot of practice. This I do have. The Aura tool that I linked to is my creation, but I wrote it years ago without a lot of the understanding I have now, and the project is really creaking at the seams. I want to look into `alga` for its potential in resolving software dependency relationships.
Haskell ecosystem is pretty decent already, so usually just nix + haskell amounts to… Stack. I'd advise you to dive in NixOS directly, because it won't really change your haskell habits (if you usually go with cabal and stack) too much, but you'll really feel the difference with other linux distro. If you were a C/Rust/Python/Ruby/… programmer, I'd say that replacing your toolchain with nix is a good way to start. NB: documentation is still lacking, but don't hesitate to join the nix-dev mailing list, subreddite, IRC, …
If your libraries have non-Haskell dependencies, Nix can cover that too for you.
I do use spacemacs + intero (which assumes stack), so my hope is that nix integration for stack is good. 
I mean sure that'd be nice. But I'm not upset about the ability to write simd code manually. I think that's a decent step one.
There are lots of talented people who don't like haskell. You can be one of those people if you want. But I think if you push through a bit of "weirdness" you will find it rewarding. 
Author here, thanks for taking the time to look at my post! I haven't tried Nix yet, it's on my list of things to check out. The main reason I approached the post this way was because my daily programming life is in the node community, where we use docker/docker-compose commands and files on a daily basis, so it is transferrable knowledge from one ecosystem to another (usually). In the node community we work with docker directly, and I would like to work like this for now before working with an abstraction.
I tend to get a lot more value out of Nix+Haskell than Stack. - Remote binary caches (built by CI) are insane. Can't imagine working on a large project without it anymore. - End to end testing can be done to some extent in Nix; no need for a wealth of extra tools. - Deploying an application to NixOS servers is a dream. - Total system determinism ensures that the only unexpected system breakage we get is when macOS does something stupid in an update. - Everything is extremely composable, unlike Stackage snapshots or Docker containers. - When a dependency is being mean, you can do some pretty nutty stuff without having to fork it. I've seen sed scripts applied to libraries to force them to export internals. Ugly? Sure. But really useful in a pinch.
It's not. It's basically worthless. Stack just uses Nix to download GHC; that's it. You can trick it by having Nix produce a GHC that has all the packages you need, and telling Stack to use a resolver with no packages, but this is an unsupported mode of operation and is really buggy. If you're using Nix, I strongly recommend dante over Intero. It's almost as good, and it works with pretty much any tooling setup, including Nix.
Neat, I've never heard of Dante. Thanks.
I remember working my way through the non-published version of this post a few months ago (the author provided me a link on `#haskell` and was kind enough to answer a lot of stupid questions of mine), and am really glad to see this is finally up officially. After all this means Part 2 is in the making. The `singletons` library really is a scary beast, since the programmer is required to *really* know their way around the various language extensions, and the papers assume you already have some familiarity with a real dependently-typed language - at least, that was my impression. TL;DR: This is really valuable!
Here are some libraries that I love and I thought they should get some attention if you're a newbie like me. * Benchmarking small code - [Criterion](https://github.com/bos/criterion) If you're trying to improve your code or you're starting to use a vector or a mutable type because Prelude's data structures are too slow, benchmarking your code is invaluable. Let's you know exactly what the difference is and it's presented in a simple easy to read way. Also, the documentation is wonderful for a library that's easy to understand. * JSON - [aeson](https://github.com/bos/aeson) I don't think I need to say more about aeson but it's the definitive JSON library for haskell. If you're wondering why it's called that, it's because Aeson is the father of THE Jason you're probably names after (the argonaut.) Both these libraries were written by [u/bos](https://github.com/bos/) and I love both libraries - they're easy to use and have great docs. Kinda wish more libraries were written this way.
Sorry :( Edit: To add something that could vaguely considered to be constructive, I usually try to find what I need on Stackage first, since packages are required to build successfully if they are to be part of an LTS release. Makes it more likely that they are maintained. Also, (actually) asking may help. More often than not, I was able to save time and don't get angry by asking on `#haskell`, or maybe this subreddit for things more complicated. StackOverflow not really, since these things tend to be opinionated. Using the search function helps. One time I *really* struggled with the various Uri parsing libraries that are available, none seemed to cut it for me. In the end, I implemented what I needed in maybe thirty lines of code. These things may happen as well, though I don't know if it's possible for your case, since I don't know what "an email library" is supposed to be. Regarding the quality of some of the API docs, I feel with you. On the other hand, sometimes the type signatures are actually enough, given that types are either [general enough or descriptive enough](https://www.schoolofhaskell.com/user/chowells79/types-not-tutorials). If it's actually just one or two functions you need, playing around in ghci may be more productive than spending hours looking for a tutorial. Purity pays off here, since you don't have to initialize global state and so on. But one thing remains, which is choice. In Haskell, there's always at least five ways to do it, which goes against the spirit of Python. I don't think that is a bad thing, but you do have to learn to not be scared of doing things "non-idiomatically".
Oh no, I hope I didn't insult you (or your libraries if you wrote some of the ones I mentioned.) That wasn't my intention.
To anyone learning how to use `singletons` — make sure you understand the idea of pi/sigma types from a proper dependently-typed language! This will really help you think on a higher level, `singletons` are just an awkward encoding. My personal recommendation is to learn the basics of Agda, as it is fairly similar to Haskell.
It's a hit or miss with Haskell packages some of them are solid, some not, and some aren't supported any longer. I believe that Haskell has yet to gain the advantages of network effects of other languages as it has yet to hit that critical mass of users. However, at the same time, this subreddit is great for recommending packages that you may want to use for your projects. 
Wow, looks like we had the same idea for a blog at the exact same time xD. Nice post!
;) This is IMHO a sign of the idiosyncrasy of Haskellism: The most voted response upto now, is the one that (kindly) gives references to a paper for each question. Even if the questioner is a beginner. And this is,supposedly, not arrogant. 
This is good advice. I'd just like to chime in and recommend Conor McBride's current [Agda course](https://github.com/pigworker/CS410-17). Reading through written tutorials and implementing `Nat` and `Vec` over and over again, I still didn't know how to "think like a dependently-typed programmer", that is, which questions you should ask yourself when you develop some algorithm or prove something. His course really helped me in that regard. Of course, "the Idris book" is also good.
You didn't, no worries. It just comes off as a "Haskell sucks!" a little. Though I *know* this is not your intention, since you cited positive examples as well.
There is also some useful material on [haskell-lang](https://haskell-lang.org/), specifically under the `Libraries` and `Documentation` sections. But *the* official "go-to libraries list" doesn't exist. Not even the Wiki (which is, by the way, a Wiki, so people can edit it).
It is beyond me why haskell-lang's tutorials exist when that information belongs on the wiki or in the package's docs / GitHub.
I'm rewriting the back end of a website of mine with Snap and Heist. I had to write my own authentication snaplet for it and I plan to make a separate library from that.
Thanks for the comment, that looks pretty cool! I'll have to try it with a more complex project. Also I like your alpine based haskell_build_env image :)
Your complaint that Haskell's ecosystem is impoverished compared to Python's is really just an effect of the fact that Haskell has at least one order of magnitude fewer users and developers than Python. If you see the wiki is outdated -- get an account and update it! If you see a library that could use better docs, submit a PR adding them! If we want to make things better, there's nobody else but us to do it.
&gt; When I want to write something in Haskell, I am so slow, slower than in any other language. It is so unproductive. And even if I try to read Haskell-code I am even slower. Yes, this is because you're learning new things. Learning new things is good. That's why you're in university -- to learn. If you could do everything assigned to you quickly, you wouldn't be learning. Trust your professors -- learning this stuff will teach you important concepts, even if you don't write Haskell in the future.
There are libraries that are poorly documented (I sometimes wish E.Kmett libraries were more beginner friendly...I always feel like a beginner when looking into them). However, looking at `smtp-mail`, it seems to me it is documented quite well. The first function in the module is `sendMail :: HostName -&gt; Mail -&gt; IO ()`, a few lines down there is `simpleMail` that generates the `Mail`. Both functions have one-line description that seems to make clear what it does (if the name and type signature is not enough). Clicking on `Mail` produces description of that ddata type. For me that would be enough information to start using the library - what are you missing in particular? I think this is more about attitude how to learn about libraries. In Python I usually try to find some tutorial, look at the code try to understand what it does. Because that's the fastest way to understand the library. In Haskell there exists one more way - looking at the type signatures. Try it. It works. &gt; Some really great examples I can think off the top of my head are requests, pandas, numpy, flask and unittest. We have `wreq` or `req`, a multitude of unit tests libraries (seems to me it mostly doesn't matter which you choose) with `quickcheck` and `servant`/`yesod` framework/others. I'm not familiar with data analysis libraries in haskell. It seems to me most newer libraries are well documented and work really well. The older ones (unit tests..) are somewhat lacking the documentation.. yeah, that could be better.
There’s no reason a Text object can’t be converted into an Accelerate vector of UTF8 uint8s 😉 
Windows users can try this out using my [chocolatey](https://chocolatey.org/packages/ghc) packages as well: choco install ghc -pre -version 8.4.1-alpha1 will install it along the latest `cabal-install`. use the `-m` option to install it side by side another install.
Maybe you should have a look at the first one - not all "papers" are hard to read - they are the blog posts of a more civilized time 😉 Btw: I choose it for the santa theme - the second one is just the goto reference for what types give away In oop you point to GoF as well in F# you point to ... hmm I guess you point to stuff most likely inspired by those papers or directly to them (I think)
&gt; I want to look into `alga` for its potential in resolving software dependency relationships. I'd love to help. Ping me if you reach this item in your task list!
nix's package management model is amazing and freeing, but holy hell the cli interface is terrible. I switched to NixOS for a few month, but I had to switch back to Arch, because I kept wanting to `pacman -Qo` or `-Ql` something and I had to keep chasing down file locations in the nix store (and even if it's starting to show its age, `aura` is wonderful, thank you!) check out the [liquidhaskell slack channel](https://liquidhaskell.slack.com/messages), btw; we're always willing to help!
This was a great introduction. Struggled through using `singletons` years ago, feel like I finally understand it. Can't wait for the next in the series!
I guess what i'm trying to say is that I shouldn't have to read the type signatures for a library as a rule - it doesn't work with larger and more complex libraries. In the case of smtp-email, i can read the library and figure it out rather easily but that's because smtp-email is rather small. There's also the context of the library that I understand. If i had no idea what smtp was or how it worked, the library would be rather confusing, especially if I was trying to send fancy images (which uses the mime protocol as opposed to smtp.) Having a description, even a brief one, about the capabilities of the library and its typical use, anyone could use the library with far less work. --- In short, I think the haskell community started off with the wrong idea when it came to the lack of documentation and rationalized it into "read the code, it's obviously clear from the code what you're supposed to do." The best code, imo, is clear and predictable (a perfect blackbox that I can ask questions to.) Haskell libraries, unlike popularly used libraries in C, Python and Java, break that rule and it's annoying. I might be a bit presumptuous when it comes to my ability to criticize an entire community that probably much better than me but i think this point would not be accepted by most communities centered around other programming languages.
That's a fair point and it's something I'll try to work on. I don't think the haskell ecosystem is impoverished - it's actually amazing how a (rapidly no longer) niche language has a pretty awesome set of libraries to work with. The really good libraries in Haskell are much better than libraries in other languages - it might be thanks to Haskell's syntax but the difference exists and it's noticeable (to me.) I think it's really that the hackage isn't good at letting people find the library they're looking for and if you do, it's rather annoying to get started. Once you do know how a library works, it's rather smooth sailing.
That's a great list and I wish I saw that as a newbie. Or perhaps I wish I saw that as a newbie and was able to use it for the stuff I was working on. I think the most I gained out of it was quickCheck and Criterion at the time. 
And [TVision Insights](http://www.tvisioninsights.com/)! Located in Boston, but we will consider remote candidates. PM me (anyone, not just OP) if you want to learn more.
&gt; I think it's really that the hackage isn't good at letting people find the library they're looking for and if you do, it's rather annoying to get started. While it's possible that Hackage could offer more here, I don't think this is mostly Hackage's fault. I think it's mostly due to the lack of good documentation in so many packages that make it difficult to evaluate whether those packages will meet your needs. That means: introductory material (very rare), tutorials (very rare), demo programs (rare), Haddock on all top-level declarations and in all modules (typical but sometimes poor). There are other issues, too, such as whether some libraries appear to be unmaintained, or whether there are variants of a library that use different techniques (such as conduit- or pipes-flavored versions of the same basic machinery). It takes a lot of work to provide this extra support but it pays off. It's a pain to not be able to just find what you want when you want it. I think the best way to deal with that is to ask people what they use, and to understand the trade-offs they needed/wanted to make when making those choices. In Haskell the trade-off space is big enough that proliferation is important, and that may make it hard to tell which library is the Right One for any given task.
Eh! The man himself. Awesome, thank you very much.
It's always good to hear from a happy user. Expect a fancy 2.0 release by March!
I love the edits and they bring up good points. I probably owe everything I know about Haskell to #haskell and a bunch of blogs online. While that works for me (because I like using IRC) I don't know if that's a good solution for everyone. Most people my age have no idea that IRC exists (even if they are involved with programming.) Like I mentioned in another comment, I don't think a lack of documentation works for a library that is to be used by more than a few people - especially if the library is big or complex. More importantly, good libraries should be treated as blackboxes that I shouldn't have to peek into - this would be a valid statement when it comes to most mainstream programming languages. As an example, if I had to read the code of numpy (in Python) before I could use it properly, I would probably never use it (it is far too big for a normal programmer to understand and if they did, they're probably contributing code to numpy.) As a black box, I'm able to use it rather efficiently in my code and never know that numpy is actually a bunch of C libraries masquerading as a Python library. Good libraries are predictable and easy to use - Haskell libraries have the first one but not always the second one.
Most of the better libraries are well-documented..but yeah, hackage search does suck. I've discovered interesting libraries by them being mentioned here, or by skimming through the githubs of authors of good libraries (like ekmett), or even ctrl-f'ing through hackage's browse. It's absurd.
Asking people is how I've learned most of everything I know about Haskell - most learning resources are almost exclusively catered to learning Haskell syntax (and monads :) ) I guess I don't want to depend on irc to solve issues for me if there's some reference I can look at. Asking people to solve something is the last step in my book - makes no sense (to me) to bother people unless absolutely required. I guess programming is also one of those things where you can't have people tell you how something works - you need to read and understand it on your own if you're to understand it. Having a reference handy is rather necessary in that regard.
Nix is definitely worth checking out. Node is not as well supported in nix as Haskell, but I still think it is better than using npm. The tool I have tried is [node2nix](https://github.com/svanderburg/node2nix#node2nix), it lets you snapshot a bunch of node packages (as they would be installed at that moment in time). It outputs a bunch of nix files you can put in source control (allowing others to reproduce your builds exactly). I helped set up some docker images for [Stencila](https://stenci.la/) using nix. We put the list of node packages in [packages.json](https://github.com/stencila/images/blob/develop/base/node/packages.json) and the output files are in the [node2nix subdirectory](https://github.com/stencila/images/tree/develop/base/node/node2nix). One super nice thing about the nix approach is that you can set it up so that `nix-build` makes a docker image, but `nix-shell` in the same directory puts you in a shell set up like you had done `docker run -it bash` on the image. Unlike the `docker run` though you still have access to everything on the machine as well. You might also be interested in [this tool](https://github.com/stencila/images/tree/master/.shrink) to shrink the size of a docker image for a specific given task. We assume you have some command you can run that will use all the dependencies you need in the image. Then we use `strace` to identify what files were accessed and remove everything else from the docker image and flatten it to a single layer.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [stencila/images/.../**node2nix** (develop → 45f7387)](https://github.com/stencila/images/tree/45f7387396d6339cf87959cdb5291378f9d8fa13/base/node/node2nix) * [stencila/images/.../**.shrink** (master → 698e953)](https://github.com/stencila/images/tree/698e9531dece17aa4b2ebdd26b363cccede46f47/.shrink) * [stencila/images/.../**packages.json** (develop → 45f7387)](https://github.com/stencila/images/blob/45f7387396d6339cf87959cdb5291378f9d8fa13/base/node/packages.json) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply drn27gm.)^.
&gt; I guess I don't want to depend on irc to solve issues for me if there's some reference I can look at. Asking people to solve something is the last step in my book - makes no sense (to me) to bother people unless absolutely required. Yeah, that makes sense. I am a huge advocate for better documentation and learning resources! When I write docs, my hope is that when people do have questions, then answering them can lead me to make the docs better, or lead me to point them to docs they missed. :) &gt; I guess programming is also one of those things where you can't have people tell you how something works - you need to read and understand it on your own if you're to understand it. This is debatable. I understand where you're coming from, and I agree that you can't depend on others as a crutch for your own understanding exclusively, but I think that human interaction is fundamental in what we're doing. (And I think it starts with documentation.)
&gt; In short, I think the haskell community started off with the wrong idea when it came to the lack of documentation and rationalized it into "read the code, it's obviously clear from the code what you're supposed to do." I don't think that's totally fair. There's a big difference between "I didn't write docs" and "just read the code, doofus." There was no pervasive "wrong idea," just people doing the wrong thing for any number of reasons
Huge +1 for the list comprehensions. As a note, my most common use of `XTransformListComp` is to make a map of lists by category, as in Map.fromList [(the c, x) | x &lt;- xs, let c = f x, then group by c using groupWith] An example might by countBy f xs = [(the c, length x) | x &lt;- xs, let c = f x, then group by c using groupWith]
Yeah, you're probably right about that. I guess I'm being too harsh - it definitely varies from case to case and the haskell community does have reason for less documentation (haskell code is much easier to read and comprehend.) I guess I'm just annoyed by the lack of any real documentation in some libraries being justified. 
&gt; I guess what i'm trying to say is that I shouldn't have to read the type signatures for a library as a rule - it doesn't work with larger and more complex libraries. I think this might be where your frustration is coming from. My viewpoint, and I think that of a good chunk of the Haskell community, is that type signatures provide some of the best documentation, because they are so much more reliable than prose, and they do tell you a hell of a lot if you know how to read them. I always read the type signatures carefully when I am trying to learn a new library, and I think it's even more important to do so for larger and more complex libraries.
&gt; I guess what i'm trying to say is that I shouldn't have to read the type signatures for a library as a rule - it doesn't work with larger and more complex libraries. You absolutely should have. That's the change of the attitude. And it works very well with larger and more complex libraries. In case of `smtp-email`, the `sendMail` function is literally the first function in the package. One easy search and you'll find the `simpleMail` function and one click away is a definition of the `Mail` type. And that's all you need. &gt; There's also the context of the library that I understand. If i had no idea what smtp was or how it worked, the library would be rather confusing, especially if I was trying to send fancy images I'm not sure the author of the library should be required to explain the domain. It sometimes makes things easier, but it seems to me that it is often reasonable to assume that the user should have at least some domain knowledge. And actually in the case of `smtp-mail`, looking at the type of `Mail` seems to me enough to send a particular email even without knowing much about emails. I think you are not used to reading the documentation. You just read the examples and then dig around. I used to do that as well. &gt; In short, I think the haskell community started off with the wrong idea when it came to the lack of documentation and rationalized it into "read the code, it's obviously clear from the code what you're supposed to do Your attitude is: read examples, it's obviously clear from the examples what you're supposed to do. Haskell attitude is: read the type signatures and documentation (hackage). In a well designed library (and I'd say that smtp-email is reasonably designed in terms of understanding) it should be clear what your are supposed to do.
I feel I should add a little to what I said before. I linked a post where some dude took a non-trivial library and figured things out (*slowly!*) by "following the types". Additionally I tried to imply that this requires type signature that are sufficiently expressive, by using descriptive types and/or by being highly polymorphic (in Haskell, this actually helps). However, I only intended to say that this kind of reasoning can take you a long way, but it is not an excuse for not documenting what can *not* be captured in a type signature. Indeed, there are library authors who provide "documentation" in the style of * "It's all written in the paper!" * reciting the function name * "Just look at the type, bro." This shit has to stop. Looking at the types will *never* reveal information about * Exceptions that can be thrown (especially so regarding impure exceptions for code that doesn't live in `IO` and similar) * Laws that should be upheld * Asymptotic complexity information to name but a few. Especially the last one is something you *really* care about if you do number-crunching, and I have seen a few issues in the `hmatrix` repo which would've been cleared up, had this information been available. For me, these kind of questions are sometimes answered by looking at the code, which is indeed more readable to me than some of the FORTRAN77 I've had to look at. The situation is what it is. Anyhow, you should also have a look at Gabriel Gonzalez' [State of the Haskell Ecosystem](https://github.com/Gabriel439/post-rfc/blob/master/sotu.md) document.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [Gabriel439/post-rfc/.../**sotu.md** (master → 9aec61c)](https://github.com/Gabriel439/post-rfc/blob/9aec61cb08bded38ea454b52b5b1a3bb7426db17/sotu.md) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply drn65an.)^.
I want to get a good grasp of practical Haskell tools and fast algorithms and data structures beyond the std Prelude. Does there exist a singular resource like [the ocaml tutorials ](https://ocaml.org/learn/tutorials/) for Haskell? I’m looking for things from fast algorithms all the way up to the latest and greatest with GHC in an accessible (blog?) manner without having to travel through stale documentation. I’ve read programming in Haskell, LYAH, and know of real world Haskell (but know it’s out of date). Thanks! 
It's a response to a university student discussing the language used in their studies, not a random stackoverflow question; I'd say a few references to the academic literature are more than justified.
Really? When I try and write Python, I find the documentation mostly appaling. There are rarely any concrete type signatures and it takes a very long time to look up each function. I used the Haskell pretty-show package yesterday. There was little or no docs, but it did _exactly_ what I wanted and I was able to figure it out in less than 5 minutes using the types (I needed to increase the terminal width to stop it wrapping, so I pressed “Doc” and got sent to another module which had functions that operated on those types — cool!)
This notion reminds me of the "[Type safety back and forth](http://www.parsonsmatt.org/2017/10/11/type_safety_back_and_forth.html)" post. Sometimes it makes sense to make things correct by construction, other times it makes sense to return `Maybe a`. 
Really, you should blame Python users for not getting their butts over here. There's the [Haskell Is Easy](https://haskelliseasy.readthedocs.io) list. It seems like a good direction, not sure what others think of it. But yeah, this is one thing I can appreciate about Elm's ecosystem philosophy: just decide on one good tool for a given use case. But this works mostly because it's a domain focused language. Whereas Haskell is used for all sort of stuff. So the utility of certain packages is not always clear. 
I don't know what you want when you look for an "email library". You want something to parse email messages? Something to help with writing an MTA? Or something to write an MUA? Maybe something to help read Maildirs? Something to communicate with Microsoft Exchange servers? So then you searched for "email", got a bunch of results that don't match this unspecified thing you want, and then you complain that Haskell library ecosystem sucks? Maybe it would help if you knew what you were looking for? But ok. Maybe there is a community out there that will respond to your attitude by giving you the free help you need. Most of us have to earn a living, and helping ungrateful people is something to do only when it pays bills. 
I would skip the nix reading in this pass. It's easy to pick that up incrementally, and you can keep using whatever you currently use in the mean time. Reflex-dom or reactive-banana I would look at the servant internals write-ups and try to apply using a type level DSL for a very simple problem. ---- Clarification: none of those of job related recommendations, just notes about how I would personally spend Haskell sabbatical time.
Love the list. It looks rather similar to the list of libraries I like to use but it's wonderful to have something written down that I can refer to or share with others. Definitely saved for future reference.
I hadn’t seen this blog post before, but it is absolutely fantastic.
What is completely missing is a set of benchmarks (only searched briefly). It's high performance – yet there there is no criterion benchmark? Criterion would be very helpful to benchmark the fastest possible haskell version with a version without CUDA versus a version using CUDA. The other – very big! – problem is that Nvida means it's a vendor lock-in to that company. And Nvida has said in the past that the are ANTI OPEN SOURCE. This got to so extremes that Linus had to publicly say FUCK YOU NVIDA to raise concerns to this anti open source behavior. This is simply a deal breaker.
Haskell has several different incompatible Prelude libraries, different from the standard one. In fact, there are good reasons to avoid the stock Prelude. This is pretty much all you need to know about Haskell's ecosystem of libraries. Email? Lol. People can't agree even on the basic set of functions.
 So at the time, I was looking for a library to connect to a smtp server and send email over that (preferably mime email.) It was for a little toy application to send emails about my shopping list - I would track what food I consumed and what I wanted and head to the local store on Fridays to buy it. Wasn't writing my own email server or something to parse through my email. Not exactly the most exciting use of email (or haskell for that matter) but it's simple which is exactly why i called it a toy application. Pure smtp wasn't what I wanted to use because smtp is limited to ascii and mime allows me to add html and pictures. The search terms I looked for where email, smtp and mime. I gave an example of me looking for a library using "email" as a search term because it's the first the thing I searched for and would search for if I was looking for a simple email library that piggybacked on an smtp server to send email - which is the simplest email function you'd expect from any email library. So let's look at how I do when I google packages in other programming languages for an email library. * Python I'm using Python 3.x but this works for Python 2.7 as well. First valid result I get is part of the standard library and it simply called [email](https://docs.python.org/3.4/library/email-examples.html). It has simple examples that's easy to understand for a variety of cases, most of which satisfy what I'm looking for. If I wanted to, I could stop write here, build what I have to build and move on. That's the benefit of a standard library that's well documented - it's easy to use and people use it regularly which makes it better over time. If I was thinking about running an email service for more than 1000 emails/day, I'd rather use some third party app that has a decent python api (mailgun was I used.) If I wanted something better, there's yagmail which works pretty well and is easier to use, although I'm not sure if it works well for something other than gmail. * C/C++ libcurl has everything I need and it's documented pretty well. It also has the benefit of working with almost all file transfer protocols I would ever use. There's a C++ wrapper as well and i don't need to worry too much about using it for pretty much the same reason as Python. * Java Oddly enough, I haven't really used Java for this particular purpose. There are a bunch of libraries but from what I see, I'd probably use JavaMail for simple stuff and Aspirin for anything major. And I can say that because both libraries have pretty decent descriptions of what they can do - I didn't need to look at their code to see how to use them, I just look at the documentation. --- My point is that it's hard to find Haskell libraries by using Hoogle. It shouldn't give me deprecated libraries as its first search result or someone's test library that shouldn't be on hoogle in the first place. I used email as an example because it's easy to follow and requires almost no explanation of how email works. I like to ask the irc channel for libraries to use because they're the best resource and have the most experience - they're honestly great people and I wouldn't know most of the stuff I do know without them. &gt; But ok. Maybe there is a community out there that will respond to your attitude by giving you the free help you need. Most of us have to earn a living, and helping ungrateful people is something to do only when it pays bills. Jeez. Look, I get I'm being a little brat about Hackage but that's the point of the post - to say that Hackage should be better. As the library repository for Haskell, it should be easier to find a good library to use for any application. Haskell is an awesome language and it's depressing that I can't find great libraries on my own.
Eh, the prelude thing is something I got over rather quickly. I use foundation for most things and honestly, Prelude works until you need to build an application that's complex and needs to run efficiently &amp; reliably. Probably sounds weird when I say that the most basic library is exempt from the criticism I had in my post but the difference between Prelude and any other prelude out there is vast and often for a reason - sometimes you just need/don't need stuff in Prelude.
I guess I usually stick to large Python libraries (standard libraries or libraries that should become standard because they're awesome) but I've definitely seen libraries with no documentation. If I had to choose between a Python library or a Haskell library where neither of them had docs, I would almost always choose the Haskell library because it's so much easier to figure out. 
smtp-email is a library that's well written and it's easy to understand. If I was trying to figure out a library with template haskell, I would be screwed. Same thing applies to libraries using the latest hotness that would require me to read an academic paper to understand why they use it. Docs go a long way to making my life easier. Like I've mentioned elsewhere, good libraries can be treated as black boxes and are simple to use. I shouldn't have to know what smtp is or how to works if I want to send email - the only thing I should know is that for this library, I plug in an email address and some ascii text and I'm good to go. I guess that domain knowledge is essential for some things but it's always good to minimize the amount of knowledge and work required to use a library. I think of requests (Python) as an example of a great library - it's extremely easy to use &amp; I don't need to know what sockets are or how they work. I just have a url and a payload and requests does almost everything for me. If I had to understand how to perform a handshake with a server before I wrote code, it would take much longer and would suck more.
It’s my understanding that the authors of those tutorials consider haskell-lang to be a much more easily consumable/discoverable resource than the Haddocks/wiki. In general, I’d say that unless you’re used to reading Haddocks, the discoverability can be a little less obvious versus a simple tutorial or blog post.
Does backpack let you dynamically instantiate modules at runtime? I'm in a situation where I read an integer, and then have a bunch of functions working on fixed length list the size of the int I read. I'd like to try to use a HList or similar to improve my type safety, having a whole module that's parameterized over the length of the list. Will this work with backpack? Or should I use typeclasses and instead, and put all my functions in a record with a polymorphic type?
Can anyone explain what is the type constructor Seq? Never seen it before, and why does it has 2 argument (instead of 1 from Data.Sequence)?
Well, I'm totally biased and so not able to know if this is *actually* the most beneficial for you, but what I'd recommend is diving into a *real-world* project where you can apply your Haskell skills and learn along the way… …such as the project I'm involved with: [Snowdrift.coop](https://snowdrift.coop/) (a non-profit which could really use help from someone who has dedicated time, and could eventually be hiring Haskellers if we have a successful launch…)
Sure, I read the types too when I'm learning a new library but that's not the first step. The first step is finding which library to use and I really prefer soft documentation for that, especially for finding out if it meets my needs. Once I know that, sure, types are great API documentation; they're still horrible discovery documentation and introductory documentation.
Backpack is static, the instantiation being done in cabal files too, not even Haskell. Can you provide an example, in Haskell or pseudo-hadkell-with-dynamic-modules? I'm not familiar with languages with such modules (is OCaml, or Idris, like that?), so I can't appreciate parameterizing something over the lengths of the list. iiuc, it sounds like you can use "vectors of known length" data Vector n a where VEmpty :: Vector 0 a VCons :: a -&gt; Vector n a -&gt; Vector (n+1) a and write the functions against some `Vector n a`. 
&gt; Prelude works until you need to build an application that's complex and needs to run efficiently &amp; reliably. Well *there's* an advertisement for a language whose chief pitch is being able to build reliable and efficient complex applications.
&gt; I sometimes wish E.Kmett libraries were more beginner friendly...I always feel like a beginner when looking into them `lens` is pretty great but he's maintainer on so many packages that I don't really blame him at all. 
&gt;I guess what i'm trying to say is that I shouldn't have to read the type signatures for a library as a rule - it doesn't work with larger and more complex libraries. I mean yeah there are supplementary materials that would make things better but it's contributed by volunteers working in their free time for the most part. &gt;but i think this point would not be accepted by most communities centered around other programming languages Haskell's type system is better than most. It's certainly a different community, but there's simply no way Python could get away with skimpy docs - it would be completely unusable. 
Haskell's community is smaller and everything else follows from the fact that there are fewer contributors. I've found that hackage packages tend to be higher quality than e.g. PyPI but it's been awhile since I did Python so this may not be accurate. &gt;if I have to read a library whose only documentation consists of type signatures in code and random blog posts somewhere on the net, I'm ending it all You probably should avoid Haskell in that case. I've had to read papers to understand libraries on occasion. I've used [htoml](https://hackage.haskell.org/package/htoml-1.0.0.3/docs/Text-Toml.html) before and it was completely fine (admittedly that was after a few years of writing Haskell - it was harder at first). &gt;An example of a really good library ecosystem that I love to use is Python's. Not exactly. The package management model is... questionable. &gt;pandas, numpy, flask and unittest You might like [hspec](https://hspec.github.io/) for testing. I've used it and it works well. 
&gt; smtp-email is a library that's well written and it's easy to understand. If I was trying to figure out a library with template haskell, I would be screwed. I got lost what are you criticizing then :) smtp-email is then *not* an example of a doc problem in haskell? TH is not self-documenting as normal Haskell, so there is a strong reason to write python-like documentation (and strong reason not to use TH). And the authors generally do that; `lens` TH is well documented, `persistent` TH too. &gt; Like I've mentioned elsewhere, good libraries can be treated as black boxes and are simple to use. I shouldn't have to know what smtp is or how to works if I want to send email - the only thing I should know is that for this library, I plug in an email address and some ascii text and I'm good to go. But... you can. By coincidence I did this about a month ago (I needed to write some monitoring and send emails in case of problems). I took the library, read the types and directly constructed production code. It worked. &gt; I think of requests (Python) as an example of a great library - it's extremely easy to use &amp; I don't need to know what sockets are or how they work. We have very easy to use and well-documented [wreq](https://hackage.haskell.org/package/wreq-0.5.1.0/docs/Network-Wreq.html) and slightly more complex (arguably with better types, but I wonder if it's worth it) but still very well documented [req](https://hackage.haskell.org/package/req-1.0.0/docs/Network-HTTP-Req.html). It seems to me that most high-use libraries are well-documented. What is not so-well documented are sometimes the haskellish category things; but then if you know the domain, it's probably quite easy to grasp them from the types.
Accelerate supports more than just CUDA these days. 
My computer science department doesn't offer Haskell course. Most students never heard about functional programming. I am graduating this month and I am dissapointed with my education. You should be happy for having a chance to learn more about Haskell
Sorry to disagree. This "lack of users" argument is a red-herring. Haskell library ecosystem sucks because the core language committee doesn't want to bless a set of libraries for common tasks (HTTP, Email, logging, etc). Nor does it want to publish guidelines for building a library. The Hackage UI and ecosystem doesn't help either. Enough time is being spent. It's just being frittered away. 
smtp-mail doesn't support TLS. A library with such a generic name is expected to support such common use cases. I spoke specifically about this in my talk. smtp-mail is a particularly bad example of a "foundational" library. 
Library ecosystem in Haskell is *effevtively* broken. I say this with first hand experience of building a mid sized production app for last 9 months. Don't let anyone convince you otherwise. Question is, would you pay 19$ per month if someone were to fix it for you? How much would you pay?
I think one way to reduce the pain is a way to have a simple way for users to filter out the really useless hackage libraries. That's a low-hanging fruit if people can generally agree on what it means for a library to be useless.
Can I sort an vector consisting of 8000 floats faster than by using the package vector-algorithms? My program (frame-rate with complex animation) spends 70% of the runtime sorting such vectors. My suspicion was that only the CUDA speed improvements are substantial. I also don't get why there are no criterion benchmarks but probably I have just overlooked them.
Is there an link on this??
&gt; Enough time is being spent. It's just being frittered away. That's quite ignorant and very disrespectful to the people working on the Haskell tooling and infrustructure.
I realise how it can sound. It's just that I'm just appalled at what *could* have been achieved by the high quality community that Haskell is, and what has actually been achieved. And again, this is not a scathing comment on the contributors and volunteers, but the leaders and committees.
I think that Haskell need a brave commercial company that would offer Haskell with the python philosophy: a reduced set of libraries for everything which would combine seamlessly (but with more elegantly and with more power than python) which do each task in one single way and would offer all that is necessary for basic tasks. No monad transformers, no zigohilo-petafunctors. The interface with the rest of Hackage should be considered as a kind of FFI
Can confirm. I've been using Haskell at work full-time for 2 years and the we use only the most basic of fancy type features. We use all the standard libraries and we don't really use lens. These things can be (somewhat) easily learned when you come across them or need them for a specific part of a project. You certainly don't need these under your tool belt to get a Haskell job. Hell, the company I work for have zero Haskell requirements to applicants!
Then just say Hackage should be better. Nobody here has to help you. Maybe saying "your thing sucks" works when you are paying someone for their services, though "your competitor sucks, so I'm trying you" will likely work better. But coming into a place full of volunteers who are giving you something and then saying "your thing sucks"? Ungrateful, immature, and not likely to get you the results you want. Unless the result you want is to feel superior and to blow off steam because this free stuff people are giving you isn't good enough for you. You accomplished that pretty well. 
I think he very clearly articulates that he likes Haskell, but raises a very valid point about the ecosystem surrounding the language. The only way a language can grow and get better is with good, valid, criticism like this post, so I think it's helpful.
&gt; It's just that I'm just appalled at what could have been achieved by the high quality community that Haskell is, and what has actually been achieved. Sorry, but this is just nonsense and not a very realistic view, because at the end there're complexities and a lot of work to do, and just very few people are willing to do this "unsexy" work. 
any reason dante is "almost as good" and not "better than" intero in your opinion?
It feels odd to make all these functions IO actions and now AWS actions - forcing IO feels like it would take control from their user. 
I'm so sorry you had a bad experience with Haskell. What issues did you run into and how did you fix them? I'm not sure if it's something that needs to be paid for in order for it to be fixed. (But if Could fix it by paying $19, I wouldn't say no. That's less than what I pay for my phone.) I genuinely think it's something we need to talk about - deciding which libraries are good, dismissing immature libraries and writing basic documentation for the libraries we make/use. Hackage shouldn't be used to store libraries made by and for companies - if you post it on hackage, you should expect for it to be used by other people. Otherwise, stop polluting namespace and get a personal library tracker.
Exactly!
No. People can take criticism (even if they're volunteers.) Heck, you make it sound like I'm attacking them personally. I'm criticizing one part of an otherwise great language. And the libraries I use are great - it's how I get to them and how I use them that's not so great. Hackage is the main site to go to for haskell packages. Stackage is a curated list in comparison and has a different goal in mind. A Haskell programmer (especially a new one) just won't survive without Hackage and it makes sense to improve Hackage. 
&gt;Not exactly. [Python's] package management model is... questionable. &gt;I've found that hackage packages tend to be higher quality Same here once I know how to use said Haskell packages. It's finding them and learning how to use them that's not so great. Python's package management system may not be great (we're effectively forced to used virtual environments if we want anything to work) but its libraries are easy to use and understand. &gt;You probably should avoid Haskell in that case. I've had to read papers to understand libraries on occasion. Eh, I was exaggerating a bit about ending it all. Probably shouldn't make jokes like that. 
Yeah, I'll concede that Haskell's Prelude could be better.
Why should kindly pointing papers be arrogant? There are lots of very nice written paper like the [functional pearls](https://wiki.haskell.org/Research_papers/Functional_pearls). Thinking someone you don't know can not understand any paper is, to me, what's really arrogant. In every language people give links to learning resources, either blogs, rfc, w3c specs, books, papers, etc. Resources on Java/C/C++/C#/Python/Ruby/Scheme/Lisp/etc are not easier to understand than the papers CKoenig points. Programming is learning, learning is mostly done by reading/watching such resources. That's the way our field works.
Hey bud, I'm terribly sorry I wrote the wrong package name. I used smtp-mail for something I've written and I guess the name stuck. I was referring to mime-mail in my original post and all the criticism applies. I hope I didn't waste too much of your time. I was going through some code and was wondering why it was easy to use when it was smtp-mail's methods before I realized my blunder. And you're right, smtp-mail is documented enough for anyone to use it. That's probably the main reason I used it. mime-mail's code is [here](https://github.com/snoyberg/mime-mail) if you want to take a peak.
Wait, what. That's odd. You'd expect that it would be able to support TLS.
Haskell is the only language I can think of that has two official websites. I'm still not quite sure why the two exist - they seem to do the same thing. (If I remember right, it's over stack or some other issue that should have been resolved already.)
&gt; Yeah, that makes sense. I am a huge advocate for better documentation and learning resources! When I write docs, my hope is that when people do have questions, then answering them can lead me to make the docs better, or lead me to point them to docs they missed. :) I love people like you :) Probably the reason why some packages are so widely used. As for the last point, I think we more or less agree. Sure documentation isn't a panacea for all my programming problems and I love haskell's community for helping me out every time i've asked. I guess I've always depended on docs before humans when it comes to other languages and that's why i think that way.
In your opinion, what criteria would you use to describe useless libraries?
Only one is official while the other is fpcomplete.com's Stack-opinionated take on how Haskell's official page should be like. Haskell's official homepage on the other hand promotes choice and tries to be impartial on Stack vs Cabal as well as literature choice.
I have and it's great! Saved for (near) future reference.
right, because stack is maintained by a private company. Honestly, it seems like stack is much more functional than cabal (or at least when it comes to actual development on different packages) - at some point, it's going to be a moot point of being impartial about stack vs cabal since everyone uses stack anyway. I mean stack is literally built on top of cabal. IMO, cabal should have incorporated whatever stack had - even if it broke a few dependencies. Having a functional (and easy to debug) package manager is important. 
You are right that they haven’t benchmarked their CPU performance against, eg, HMatrix. However it is pretty clear that Accelerate is better than just folding and zipping unboxed vectors of floats. As for NVidia, I can’t help but think you’re looking for an argument since you’re the only one to mention it in a conversation that’s been focussed on CPU SIMD so far. Nevertheless, I will say AMD/ATI has invested so little money in GPGPU hardware and software that even Apple, their preferred customer, just abandoned OpenCL in favour of their Metal library. Meanwhile 14 of the 16 deep learning frameworks listed on Wikipedia are CUDA only, and Amazon only rents out NVidia powered GPGPU clusters. Hence, as someone who works in Machine Learning, I agree that that CUDA is a deal breaker: but only because I couldn’t get my job done without it. You are right that NVidia is secretive when it comes to source code, but then again, AMD doesn’t open-source their GPU drivers either. Ultimately you have to decide how important open-source is to getting your work done. 
&gt; Sorry, but this is just nonsense and not a very realistic view, because at the end there're complexities and a lot of work to do, and just very few people are willing to do this "unsexy" work. My hypothesis (now, becoming an anecdotally verified belief): * A lot of high-quality developers are already doing a lot of work in Haskell, BUT because efforts are being duplicated while solving the same/similar problems, the velocity is not as high as it should be. The entire package ecosystem is an example of efforts being duplicated. * This forms a negative spiral where others are *unable* to contribute meaningfully because of the general lack of established practices and confusing library ecosystem. * This general mess makes learning difficult for newbies, thus slowing down general adoption of the language/ecosystem. What did you mean by "unsexy" work?
Found this in the Haskell Weekly newsletter, and thought it looked like a great opportunity. They're very honest about their actual requirements and seem to have actually realistic expectations. I would apply myself, but I'm already facing too much uncertainty in other areas of my life at this point. I thought I'd share it for others, though. I realise it might not be appreciated since it is a job ad, after all, so if people don't want it, I'll take it down.
Are you using this as a learning excuse, or are you looking to use it for real? This sounds more like something that could be done in shell, or using `socat` than any language... 
Or maybe even `inetd`
You said they haven't benchmarked their CPU performance against HMatrix. This implies that they have written benchmarks. Is there a link? Did they use *criterion*? Did the benchmark CUDA versus no CUDA for the same benchmark (e.g., the various benchmarks)? How do they check for performance regressions? Perhaps I didn't understand something regarding the benchmarks. Benchmarking versus HMatrix might be too obvious. I am just used to seeing a benchmark folder with criterion code. Yes I am biased. I was forced to use a labtop with nvida card at work and this meant suffering for years because of their stupidity. I lost 3 weeks of my life. And I hope that publicly shaming them might have this tiny bit of chance that they don't abuse their power in this regard in the future. It's hard to understand if you haven't been in this situation. I am working in a small group that tries to build their own CPUs and GPUs. It's just quite hard without the 500k to start wavering with expensive masks. So there is the option to do open source CPUs and GPUs. Vendor GPU chips aren't very good anyways what I have heard.
With "unsexy" work I mean all the work beside writing a library. Writing good documentation or good tutorials, curating a set of libraries is all quite a bit of work, which is mostly done by unpaid people. This is the kind of work where a bigger community helps. You can't solve these issues just by having a bunch of smart guys. I don't see the cabal/stack as that much duplication. There's no stack without cabal, and there's no Stackage without Hackage. 
[`ghc-prim` has a massive number of functions for this.](https://hackage.haskell.org/package/ghc-prim-0.4.0.0/docs/GHC-Prim.html#g:28)
I would also be interested in which machine learning library you are using, if you use Haskell. I guess for Haskell tensorflow seems easy to get started. But I would also be interested in a baysian network library. I have also been searching for a wavelet library in haskell (e.g., feature extraction from signals or images) but haven't found anything useable.
Intero is definitely less buggy. Dante's autocompletion [doesn't work with flycheck enabled](https://github.com/jyp/dante/issues/54). But otherwise I probably wouldn't notice the difference.
&gt; then group by c using groupWith Is this standard Haskell syntax? 
In case you would be looking for already existing solution, there is sshuttle and redsocks + IPTABLES.
My goal is to use Haskell in my career and not just during spare time. Serokell is particularly interesting and although I'm not there yet (currently writing my [first](https://github.com/srid/slownews/pull/13) Haskell backend project) I hope more such companies start using Haskell, because eventually I'll be there! After using Haskell I find writing code in Go or Python to be uncomfortably lax. I strongly believe that writing and maintaining Haskell projects is way more pleasant (and safe, and reliable) than other lesser typed languages.
Seems that [dirt cheap Haskell consultancy](https://www.reddit.com/r/haskell/comments/79n679/dirt_cheap_haskell_a_100mo_haskell_consultancy/) paid off!
1. One option is to define certain objective criteria, e.g i) ability to build under compiler version or stack resolver after a certain version, total number of revisions, the date of the last revision, whether there's a maintainer. The filtering of a library is a combination of how it fares under these criteria. The user sets the thresholds for the criteria to filter out disqualified libraries. For example, I care about GHC 8.2.2 and lts-10.0 and fix-parser-simple (from 2011) just doesn't build because its dependency mmtl-0.1 (from 2008) has a compilation error, so it's useless to me although it may be useful to someone else. Another example is hnop, which is listed as having no maintainer. The advantage of an objective approach is that it can be automated and it's transparent. 2. Another option, a social approach, is to allow users to vote that a library is 'useful', and prioritize showing libraries within a given category by the number of 'useful' votes. Of course, your 'useful' is different than my 'useful', and people could try to game the system or troll for whatever reason. There's also a question of where votes come from. Maybe stack and cabal can have a per-project opt-in feature where the user automatically votes for a package when it gets used in a successful build of a project. For convenience, the voting is automatic. For privacy, the automatic voting is opt-in. For meaningful voting results, the automatic voting is enabled on a per-project basis (e.g. to exclude projects used to learn how to use libraries). For meaningful statistics, the votes need to be deduped somehow.
Oh, no – Serokell isn't my company, I just work there.
I think the OP's attitude was absolutely fine. They provide an experience report of using the current ecosystem, some examples of ecosystems they think perform better, some suggestions for change, and are upfront that the whole thing is a *rant* rather than a complete request for help. It's meant to be starting a conversation, rather than asking a pointed arrogant question. *Your* attitude, however, and the attitude you espouse in other replies is absolutely toxic, and should be avoided. You mock their understanding of their own problem ("Maybe it would help if you knew what you were looking for?"), call them "ungrateful" and do everything you can to put them off interacting with the Haskell community again. In your reply, you suggest that the OP do something *that they did in their original post* ("Then just say Hackage should be better"), insult them some more, and do even more to try and make them feel unwelcome. When you next see someone complaining about something in the haskell community, take a minute to use some fucking empathy before becoming a toxic asshole, and maybe you'll make the whole community better.
No, it's a GHC extension. Specifically, it's the `TransformListComp` extension. Activate it by putting this as the first line of your file: {-# LANGUAGE TransformListComp #-} 
*[Plus ça change, plus c'est la même chose](https://en.wiktionary.org/wiki/plus_ça_change,_plus_c'est_la_même_chose)* You might want to refer to this [previous discussion](https://www.reddit.com/r/haskell/comments/3v4t9y/is_it_just_me_or_do_haskell_libraries_seldom_have/).
Working my way through "Learn You a Haskell". My apologies if I don't get all the terms correct. Why do I get an error in the custom sum' function if I use the class restriction of (Num b) instead of (Num a)? -- Spits out 'match' error? sum' :: (Num b) =&gt; [a] -&gt; b sum' [] = 0 sum' (x:xs) = x + sum' xs -- No errors... sum' :: (Num a) =&gt; [a] -&gt; a sum' [] = 0 sum' (x:xs) = x + sum' xs Where as, in the custom length' function I can use either class restriction, depending if I want to include all types or just numbers: length' :: (Num b) =&gt; [a] -&gt; b --(Num a) =&gt; [a] -&gt; a works too length' [] = 0 length' (_:xs) = 1 + length' xs My only guess is that there's no need to switch types. Because the sum' function is only working on Numbers. Edit: Formatting for Code...
Instead of Backpack, you could try using dependent-ish types. For example, the [fin](http://hackage.haskell.org/package/fin) and [vec](http://hackage.haskell.org/package/vec) libraries. [reify](http://hackage.haskell.org/package/fin-0/docs/Data-Type-Nat.html#v:reify) from fin lifts a natural number to the type level, letting you use fixed-length vectors from *vec* inside the callback argument. *fin* uses Peano naturals, if your *n* is very big perhaps a library based on GHC's typelits would be more appropriate.
&gt; It is a bit more than that but yes. I don't see where I ever want to use Haskell if I can choose myself. You're in university. Your only programming job there is broadening your perspective by learning different approaches to solving programming problems with their pros and cons including using different paradigms like functional programming, imperative, OOP etc. If you start with the view that you already understand imperative programming and it's sufficient, you've chosen your team and all other teams suck, then you're missing the point and would probably better appreciate some fast-track technical school designed to churn out cheap coders for quick employment. As someone who prefers functional programming to OOP, I would still advise any university student only familiar with functional programming to make an honest attempt at understanding OOP and its benefits because whichever language they ultimately work with, they will be in a better position to appreciate the trade-offs of that language and how to work within or around its limitations. To summarise the main advantages of haskell / functional programming, is that it enforces discipline, making large classes of programming bugs impossible, and provides powerful means of abstraction and composition that make it easy to express problems in a declarative style more closely customised to the domain of the problem being solved. That makes for better expressiveness and confidence in correctness. I suggest starting by really making an effort to understand the advantages of a strong type system and how Haskell's algebraic data types, type inference and type classes make Haskell's more powerful than a typical imperative type system. Also, get an appreciation for functional programming in general with higher order functions. Write some stuff in an imperative language's loops then again using haskell functions like map and filter and compare the two paying attention to modularity and composability as well as how well you can express the problem you're trying to solve in more direct, clear language rather than as a step-by-step imperative recipe. Consider how functions like map and filter themselves can be written using fold showing how you can build your own custom control structures and ponder how imperative loops provide you with no such composition mechanism. Get an appreciation for why side-effects can be scary and how helpful it is that Haskell goes further in protecting you from the pitfalls of side-effects than most functional languages by clearly flagging all side-effecting code in the type system. 
I'm toxic? OP says something sucks, you unleash obscenities, and I'm toxic? This attitude is exactly why I hesitate to release free software. Because this is the thanks you get. 
 &gt; VsCode + HIE Why HIE and not Haskero? I know that HIE is supposed to be the future of Haskell IDEs, at least as far as the backend goes, but is it actually better *now*?
Basically the only thing to improve things is working together and making sure others can profit from your work. But I am also complaining a lot recently because what you say is also true for me. Currently I am looking for: * *A library for haskell to talk to Ocaml code (without C FFI)* * A good message passing library * A Wavelet library that is comparable to the good ones in R * A baysian network library and generally machine learning libraries (e.g., gneralized and/or nongaramtric regression, mixed models, etc.) * A library for handwritten analysis (I might write that someday but if someone wants to help this is easy to write if not alone) * fast vectors and sorting functions (Accelerate apparently forgot to write criterion benchmarks?? Can't even test if that makes sense) * A library to do nice graph layouts without generating images from the result (ie GML ---&gt; A layout of each node) * A library to automatically improve the performance of libraries (brute force try different stuff such as compiler flags and the common tricks) 
The `sum` function adds elements of the list, so the result must be of the same type as elements of the list. In contrast, the length of a list is mostly unrelated to what is inside the list, and the result can be any type of number (that is to say, a type with an instance of `Num`).
That's a fun post!
Why not apply? You never know what you are capable of and it might just give you some perspective.
&gt; Eh, I was exaggerating a bit about ending it all Ah okay. Glad to hear; perhaps I will get better at detecting facetiousness on the internet :) &gt;It's finding them and learning how to use them that's not so great. I'd agree on finding them. In terms of learning how to use them... that's a bit of an acquired skill. Using `htoml` was easy for me - but using `htoml` when I was starting out wouldn't have been. Btw one thing I recently discovered was `cabal list` - it's a bit simple-minded, but I definitely think it can be of help
The Haskell ecosystem isn’t great for ML. I use Python and its Numpy, Scikit, and Tensorflow packages. At present it’s just the right tool for the job. There _is_ a Haskell Tensorflow library, and you could probably construct a Tensorflow graph to do inference in a (directed/undirected?) Bayes net. There are also a few Haskell plotting libraries, and there was a Jupyter kernel called ihaskell. I haven’t looked at them in a while though. The Haskell tensorflow lib is at: https://github.com/tensorflow/haskell For your own benefit, I should say that deep learning approaches outperform manual feature extraction for images, so I wouldn’t pursue that path. You can just download a pretrained network (Keras has links) take the “top” off (ie the prediction step) and run the rump to generate a feature vector per image. For audio, it depends on the problem. FFT has the issue that you need to pick a window. Recent work on speech to text has found convolutional recurrent networks with the ability to predict “gaps” work very well. However that presumes prediction is your use case: since you mentioned Bayes Nets, perhaps you’re interested in denoising, and I can’t much help with that. 
&gt; &gt; &gt; but I don't see, why a language should not allow also imperative Programming. &gt; &gt; Yeah, that's why it does allow it. &gt; I don't understand. You might find Gabriel Gonzalez' blog post [Program imperatively using Haskell lenses](http://www.haskellforall.com/2013/05/program-imperatively-using-haskell.html) enlightening. (I did) There's also some good discussion on [this stackoverflow post](https://stackoverflow.com/questions/6622524/why-is-haskell-sometimes-referred-to-as-best-imperative-language).
Ah, ok, I see. Thank you for the clear explanation.
There might be some ways to do this filtering, but I don't think those are *objective criteria* - they're *heuristics*, because there will always be cases when those criteria produce false negatives. Just the first question about whether something builds is complicated by numerous factors, so in my opinion it's a "best effort" kind of test. I'm more a fan of social approaches, or of teaching people how to draw their own conclusions, rather than building algorithms that try to stand in for human judgment. To me, voting sucks because it becomes an oversimplification of that judgment, and thus difficult to interpret (but people will try anyway). That's why I'm not a fan of the new-ish voting feature on Hackage right now.
&gt; it’s often better to write for readability Readability is more important than ease of writing, but there are other benefits to type classes. * Maintainability: When developing code, code changes; I have found that type classes often mean I have to make fewer code changes, and that they are easier to see correct. One example is that if I rename a type, and somewhere I was calling a `print` method on it, I'm faced with a choice between renaming the print method everywhere or leaving the name wrong; this is not a problem if the method has the same name for every type. * Domain modeling: sometimes, it's clearer to think of the same operation applying to different types. Addition is addition, whether it's on doubles, integers, or rationals; in fact, you (more or less) _need_ type classes if you want to be able to perform addition on complex doubles using the same name as on complex rationals, i.e. if you want to have a parametric `Complex` type. * Code generation: when it comes down to it, type classes are a way to have the compiler write code for you, given types. There are some powerful things you can do (that e.g. `lens` uses internally) that depend on being able to pick a data type with certain instances of certain type classes. Contra the article, I prefer to use the more generic version of a method because * a) it suggests that I have "nothing up my sleeve"; i.e. that I'm not using any particulars of a data structure * b) if I ever change the data structure, I don't have to change the code
Yeah, this is the kind of thing I was looking at. My interest in Backpack was in making the dependent typedness opaque, so I could parameterize the whole module over the list length, instead of having each function have a length parameter, but that's probably not possible. Thanks for the pointers to the libraries! Do you know if they use Peano numerals at runtime, or just at the type level for compile time?
Huh, I wonder what they use Idris for. Exciting!
It sounds like you're expecting a perfectly concerted effort to be driving the language forward. This does not exist in *any* language. Every language has a large percentage of people "frittering away" work (with the except of maybe Rust, somehow); you just don't notice it because larger communities *also* have more established tech. And although Haskell's percentage of this may be a bit higher, I think it's completely unreasonable to expect this to be close to zero as you wish. So yes, Haskell's small community *is* a major factor, because it's incredibly hard for *any* language to minimize this "frittering," and control the focus of volunteer hobbyists.
(Just FYI, I went ahead and tried this challenge. I've posted my code [here](https://ptpb.pw/PKfo)) When I compare my code to yours, the first things that jump out are the data structures and data types you've chosen to use. DuetVal is isomorphic to Either Char Int. This is not a big deal, but sometimes it is easier to stick with the default datatypes because certain convenience functions are trivially accessible (for instance, fmap, either etc.). In the datatype Duet, unless you otherwise have a good reason, you should go ahead and make certain fields strict. For e.g. dPtr and dSendCount should probably be strict Ints (just put an exclamation point to the left of Int). Otherwise, those fields, if not evaluated immediately, may just be large thunks being passed around for no good reason. I see that in your program function, you use a parser. Frankly, I am of the opinion that using a parser here is just overkill. You can take a look at my implementation for a simpler solution if you would like (look at the first line of the do block in the main function specifically mapMaybe parseInstruction. Also look at the parseInstruction function). In your execInst function, a simpler type signature you could use is, DuetInstruction -&gt; DuetState (Maybe Int). This may seem confusing, but if you think about, if you return Nothing, that means that there is nothing to recover and you can then recursively call execInst. Eventually, execInst will return "Just something", at which point, the program will halt. You can take a look at my implementation where I utilize this strategy (look at the function runProgram). Generally speaking, it is a good idea to avoid Bools when possible. Using built-in or custom datatypes to drive control flow makes it easier write to more comprehensible code. I am not entirely sure why you have the function runTwoPrograms. I also don't think you need to import Control.Monad.State.Strict. Control.Monad.State should be enough. I hope what I've written could be of value to you. (EDIT: If you take a look at my code, don't worry too much about all the details, just look at the places I've pointed you too in this post.) (EDIT2: I now know why you've written runTwoPrograms, I didn't realize day 18 has multiple parts.)
I see "dependent-types-waiting-for Haskeller", but where is Idris referenced? I'd be glad to see Idris starting to be used in production.
half way through - a quick note `data User...` is not a `typeclass` definition - it is a definition of a data type
The problem with python documentation is that there aren't types (not trolling). Haddock hyperlinks types, and GHC checks them, which is great; but even in a un typed language you can say "this should return one of these subclasses of C". Take `requests`, a well-written and well-documented library, with better functionality than any existing http client in Haskell, and an enormous community. it took me a while to find even what type of thing a response was. Until I just Rage Quit, opened the interpreter, and called `list` on the output. 
Unfortunately, it is not only stupid, but also largely wrong.
no Monad transformers?
As an alternative to dependent types that /u/Faucelme suggested, this is actually one of the use cases for [reflection](http://www.tweag.io/posts/2017-12-21-reflection-tutorial.html). You can also get halfway there, using rank-2 types (like with `ST`). It's not quite to the level of Agda's parametrized modules, but it's nice to have in your tool box.
Thus "search for an email package" example is very detailed and helpful, thanks
&gt; AMD doesn’t open-source their GPU drivers either For Linux, yes they do! IMO it's the major (and only, unfortunately) compelling reason to use them.
We do have votes on hackage packages now, and the ability to sort by them. We also have a longstanding project to calculate reverse-dependencies directly in hackage, which if I recall correctly, is stuck on needing to ensure it genuinely doesn't cause any bad space usage (since the full rev-deps structure is rather large if not stored carefully). The code for this, from a GSoC project (the rest of which has been merged already) lives here: https://github.com/haskell/hackage-server/pull/551 In general, adding filtering to the search interface seems like a good idea. It can be added purely in javascript at this point, due to the new search results setup with enhanced in-browser tables. PRs for this would be very welcome! (Although for better results, integrating build info from the matrix builder would be very important, and that work needs to be done).
Apparently you didn't read the initial paragraphs.
I'll change that, then. It is unnecessarily misleading.
Blessing a set of libraries for common tasks is not the job of the language committee -- core libraries are delegated to the core libraries committee, and the goal is to _shrink_ not grow the number of libraries tied directly to the language and GHC. An effort to designate a larger set of libraries as "blessed" did take place in the past. The libraries in this set constitute the Haskell Platform. However, the aim since then has been towards moving people towards the "core" platform (which is just ghc-shipped libs, cabal-install, stack, and other build-related binaries [e.g. alex, happy]. The broader platform libs still give a good basis for distros to target. Hopefully once broader ecosystem changes shake-out and stabilize there will be a good and meaningful way to "bless" libraries again that doesn't involve shipping them directly with a platform installer (since that puts them in the global db, which people do not tend to recommend).
The "leaders and committees" are volunteers and contributors too! This is an open-source ecosystem, nearly everyone does this because they choose to, not because they are employed to.
The hackage search normally sends deprecated libraries to the bottom iirc, but has an exception for exact string match, which always wins. Adding filtering (as suggested elsewhere) would be a good way to sidestep this.
\**blushes*\* No problem. I hope I can give back to the community - lord knows I've gained a lot from them.
Damn, I forgot how obscenely comprehensive the python standard library was (it's been years). We can try to curate an "extended standard library" for haskell ourselves, it's easy to get a set of 100 packages to build together if they're on stackage, and we can contact the maintainers for non-stackage ones. And we can right tutorials and documentation. But there still compatibility problems, like between different strings (lazy text v strict text, let's not even talk about the prelude string), between different containers (aeson uses HashMap, `json` being an important standard library, while others use Map), etc. Whereas in Python, my guess is that it's all `str`s and `dict`s. But most datatypes, like `Maybe`, and a thousand simple pure functions (like `zipWith`) are reused across the ecosystem, which does increase compatibility. So definitely possible, it just seems like it'll take a lot of time, and effort from multiple library authors. 
It's listed under "technologies used" on their website.
Any relation to IOHK?
Serokell and IOHK are working together on the Cardano cryptocurrency.
You're definitely right about taking a lot of time. A lot of the libraries you discussed are rather similar in function but have different internals. Python is much more uniform and a lot of what I have to import to replace Prelude is part of the language specification. Which libraries would you add to the extended standard library? Or I guess more appropriately, which functions do you want said libraries to fulfill. I'm certain data structures, strings and network-related stuff is important; I'm kinda curious what you would pick.
*sarcastically* *oh, how unfortunate that someone new to Haskell doesn't know Haskell*
[sbv](http://leventerkok.github.io/sbv/) maybe?
The effort that the Haskell community had to package a bunch of "blessed" packages was the Haskell Platform. Don Stewart led the charge to get us a "batteries included" Haskell distribution that all worked together. Nowadays, it's mostly /u/sclv shipping releases and getting shat upon from great height. The core libraries committee isn't the body that maintains the platform. Its job is to ensure that the packages _that ship with GHC_ work and evolve to the best of their abilities. These "core" libraries formed the heart of the Haskell Platform, not its entirety. GHC doesn't require anything that has to do with email, and therefore per our charter, we don't have anything to do with such a library. Is there room for growing the Haskell Platform? Sure. /u/sclv could probably use some help with this regard. Is there much will? Not much. Stackage has subsumed much of the original mission of the platform in that it provides the continual integration framework and a reasonable model for packaging, but the one thing that it has lost is this sense of having one carefully selected tool available to do each job.
There has been some effort towards getting us "social media" functionality like voting about package quality for several years now. This led to the "hackage 2" project that the current hackage we have is descended from and the "lambda star" ratings you can click on on the packages. This isn't the automatic voting system you mention, but it is a start to attempting to address quality filtering. Alas, it hasn't been terribly well received, so its a foundation that it is rather difficult to get folks excited about building upon.
I think they may have dusted off Hood a bit a few years ago? https://hackage.haskell.org/package/hood
I was referring to Potts' code for linear fractional transformations, not the stepper bit, but that's cool too. =) I updated Potts' code to Haskell 98 for reference a couple years back: https://github.com/ekmett/fractions/blob/eefee71a88b6e6c0cc9a20587118f801255e233e/Reference.hs Transcoding the original was a fairly adorable exercise in finding out / remembering what changed in Haskell 98.
Came here to say this. It integrates really well IMO
`sbv` is the one everybody I know seems to use these days.
Haven't read the whole thing, but the section on do notation is kind of backwards. If `func x y` returns an `IO String`, then `varname &lt;- func x y` puts a `String` into `varname`. In other words, it lets you sort of ignore the context the value came from (because the compiler figures out what you're ignoring and automatically rewrites the code for you). When you did the transformation with `fmap`, it worked because `func x y` is a `IO String`, so in order to operate on the `String`, we treat `IO` as a functor (keep reading LYAH) and `fmap` over it. The `&lt;-` is the special thing that extracts the value from its context, so until we get to that operator, it's still in the `IO` monad.
I contributed https://github.com/portnov/libssh2-hs/pull/40.
Keep going with your notes! Some of them are common or obvious learner things, others might help teachers later on.
As others have said, I suggest SBV. I've worked on a number of SMT driven projects and they are either: * SBV (mostly for a couple custom solvers, SAW, and Cryptol) * Custom high grade SMT connection such as Crucible SBV has some huge advantages over others I know about: * *Type-safe* While there are unsafe-like escape hatches, you really have to opt in to those. * *Expertly Maintained* Levant does a bang-up job responding to and resolving any issues as well as adding enhancements. He even answers properly-tagged questions on StackOverflow. * *Widely Used* If it breaks, chances are you won't be the first to notice. If one user stops the project will live on thanks to a larger base. * *Large Prover Selection* The possible solvers include Z3, CVC4, MathSAT, Boolector, Yices and perhaps others. * *Numerous Examples* There are many non-trivial examples included in SBV that can get you started. 
Fantastic, will definitely keep around as I won't remember it all after just the one read. Thank you (:
look at the difference between the recursive case of each: length' (x:xs) = 1 + length' xs -- 1 :: Num a =&gt; a -- length' xs :: Num b =&gt; b sum' (x:xs) = x + sum' xs -- x :: a (N.B. not Num a =&gt; a) -- sum' xs :: Num b =&gt; b Consider the type of `(+)`, which is `Num a =&gt; a -&gt; a -&gt; a`. In English this means to take two values of the same type iff that type is in typeclass Num, and return a value of the same type. In `length'` you're providing a `1` and a `length' xs`, the former being an untyped numerical constant (`Num a =&gt; a`) and the latter being defined as having type `Num b =&gt; b`. Alpha equivalence makes those types equivalent. In `length'` you're providing an `x` and a `sum' xs`. While the latter here has type `Num b =&gt; b`, the former has type `a` with no assurance that `instance Num a`. Haskell then complains that you're trying to add a number with a non-number. Length works anyway because `"Some string"` has a length, but asking for a sum of that string is probably crazy. You might be able to derive one, but I doubt it's what you want. class Summable a where unlikelySum :: [a] -&gt; a instance Summable Char where -- note Char, not String unlikelySum = chr . sum . map ord -- equivalent to chr . foldr (\x acc -&gt; acc + ord x) 0 -- or unlikelySum xs = chr $ go xs -- where -- go [] = 0 -- go (x:xs) = ord x + go xs main :: IO () main = print $ unlikelySum "Some string" -- gives back '\1099'
My experience with Python libraries has been terrible. Just like Haskell, you have to find the good ones, but there's very little in the package database itself telling you which those are. You just have to ask people. Same for Haskell TBH.
I'm effectively still learning Haskell. For example I'm yet to read up and understand Monad Transformers. They specifically list this stage as a bad sign: &gt; Solid knowledge of Haskell 98 features. If you haven't ever written your own typeclass, if you struggle with applicative functors, if you don't know how stuff like ReaderT works – those are bad signs. *** EDIT: They do have an internship position that I'll consider applying for.
`(\x y z -&gt; [x,y,z]) &lt;$&gt; (+3) &lt;*&gt; (*2) &lt;*&gt; (/2)` is a fancy way of writing `\v -&gt; [v + 3, v * 2, v / 2]`. The result of applying this function to 5 is `[5 + 3, 5 * 2, 5 / 2]`, which evaluates to `[8.0,10.0,2.5]`.
Hey, where did you see the internship position? I only saw the job offer.
I think it's even *more* than that. Python and many others like Ruby, Go, etc. are extremely *unambitious* languages. But Haskell is a very ambitious language and it not only allows but even forces you to explore things along more axes. How many Python libraries are there for doing inter-thread communication? Very few. Because Python has terrible support for threading at all. How many Python libraries are there for catching bugs at "compile time" (let's just say MyPy counts): almost none. That's because you basically can't even do this. What about using exceptions vs. various failure types? Python has only one option. So in many ways, the actual design space for Python, etc. is much smaller. Haskell often has 10 libraries that do almost the same thing at the end of the day. But what they do differently is use more or less advanced types, focus more or less on performance, etc. So it's the combination between Haskell's smaller community and it's *larger* design space.
Because of first hand experience. I tried all the plugins available in the VS code marketplace and the only on that worked for my project was HIE. Then I followed the project and understood that it was the future of Haskell&lt;&gt;IDE development, which is why i recommend it. 
See my other comment: Haskell as a language introduces several additional axes in the design space, which makes your package design space absolutely huge. This is a large factor. No one in Python spends time figuring out how to do things "type safe". It doesn't even cross their mind.
Applied! By what time frame can I expect a response? Will I hear back in case of a "reject" as well? :)
Does sbv have optimization (as opposed to just satisfiability) yet? When I checked about a year ago, it didn't.
&gt; it seems like stack is much more functional than cabal (or at least when it comes to actual development on different packages) Have you used cabal's new-build support?
That's a pretty bad example, btw. If you want to understand where application functors are really used in real-world code, take a look at any parsing or validation code.
How is this a constructive comment? Who does this benefit?
[Yes it does](http://hackage.haskell.org/package/sbv-7.4/docs/Data-SBV.html#g:34)
Oh a "dependent-types-waiting-for-haskeller-spotter Reditter"!
I guess most Haskell people don't use applicative functors that way? Can you show me any parsing or validation code that uses applicative functors?
If throughput is what you are looking for, you may want to try the bindings to the `z3` API from package `z3`. I don't think that `sbv` would be particularly fast as it also communicates with the solver by using strings over a pipe.
I applied to IOHK directly a few months ago. The work seems really interesting, and I liked the team, but salary was a sticking point. "Not quite entry-level Silicon Valley grade without benefits" would be accurate, though if you're in Europe or Asia where salaries are lower and health insurance is provided by your government, it might be competitive. I did buy some ADA though.
I can't speak to why you are slower in Haskell. I know I was at first, but after a while it became much faster. Why? Fearless refactoring. I can change my code, and because of strong typing, the compiler tells me of nearly every single place I need to fix to accomodate the change. I spend way less time writing and running tests, and way less time debugging. Secondly, there are some times when Haskell has just the right abstractions. Monads let you do backtracking, memorization, logging, etc. without having to implement any of these yourself. It makes these things clear from the types, and I can use them without having to implement them myself. The work of threading things through is entirely done for me. Finally, studies from places like Microsoft show that the hardest parts of code comprehension are reasoning about preconditions and side effects. Haskell makes these explicit.
Ok, so abstractions like Functor, Applicative, and Monad (spoiler alert) give you abilities, but they don't mean anything on their own. It's the implementations that mean something. So, first you have the `x, y, z` part. (I'm on mobile, so I'm going to try to use more English than code examples) The `&lt;$&gt;` operator is just `fmap` as an operator. So it says "this is a function, please lift it into a context for me." What context? Dunno yet. Depends on what comes after it. What comes after it is a function because of partial application. So the context we're in is the context of a function that operates on a future value. When we fmap our `xyz` function over that context it says "you give me a value, and I'll add this to that number to get a new value, then I'll pass that result as `x` to the lifted function." And because of partial application that gives us a new value, which is a function that takes two more values 'y, z`, still in the context of waiting for a future input value. (`fmap ` has preserved our context across function application, which is another way of looking at what it does) Functor alone doesn't allow us to do anything with this function in a context, so we need `&lt;*&gt;` from Applicative to continue. We continue to combine other elements of our context (that is functions that take a value and produce a new value) and slot them in as arguments to that very first `xyz` function. At the end we'll have applied each variable to a member of the context we're in and we'll be done. We'll have a context that contains a return value, which is a list of numbers. That context, remember, is a function that receives an input and does something with it. The definition of Applicative for this context is such that the same input is passed to both sides of `&lt;*&gt;`, so both functions get the same input when we eventually give it an input. So at the end we give it a `5`, which is then passed to each of the arithmetic functions because of the definition of Applicative, and then finally those results are passed to `xyz` to be assembled into the list and now we're done and we have a list of numbers like we wanted. This example is confusing because we have the `xyz` function and the three arithmetic functions, but they play different roles in this example. The first is a "pure" function that doesn't know anything about this context and is being lifted into it, and the other 3 are the context of "functions waiting for an input", they just all happen to be functions. In another context, like `Maybe ` where the values may or may not exist, `xyz` would still be a function, and it would still collect the results into a list, but now it'd be Maybe a list, and the other 3 inputs would be `Maybe Number ` rather than a function that takes a number in. In practice I don't know if anyone really uses this kind of coding, since it's a little golfy and hard to understand, but it is a good exercise and it does technically show off the Applicable instance for Functions. 
To be clear, people use Applicative often. Just not usually the Function instance of Applicative because it's a little weird. Later (more spoilers) you will learn about the Reader Monad and it will tie back to this, but on its own it's a little weird sometimes. Still an option, though. 
The library people use is Parsec (or others in its family like attoparsec or megaparsec) I don't have a link to anything handy, but it tends to look something like `buildPerson &lt;$&gt; parseName &lt;*&gt; parseAge` Where buildPerson is a function that doesn't know anything about parsing and just returns a Person given a name and age, and parseName and parseAge are each parsers that return a name and an age. Then we're using Functor and Applicative to plug the pure function and the Parsers together. This returns a parser for a Person. Later we can build up some other more complicated value using this new "People Parser" we've just constructed and in this way we can build larger things out of smaller pieces, and in the end isn't that the goal we aspire to. 
This is better than most of the posts that explain some advanced Haskell type system feature. But one small issue. Why do you have to use lambda case? I think it just makes making sense of the examples a little bit more difficult. Same thing with function composition. I think if you are writing for people who don't already know these advanced features, please make these examples as accessible as possible by not using things like lambda case and function composition (if possible). For example, this example closeDoor :: Door 'Opened -&gt; Door 'Closed lockDoor :: Door 'Closed -&gt; Door 'Locked lockAnyDoor :: SingDS s -&gt; (Door s -&gt; Door 'Locked) lockAnyDoor = \case SOpened -&gt; lockDoor . closeDoor -- in this branch, s is 'Opened SClosed -&gt; lockDoor -- in this branch, s is 'Closed SLocked -&gt; id This would be much more accessible if it was closeDoor :: Door 'Opened -&gt; Door 'Closed lockDoor :: Door 'Closed -&gt; Door 'Locked lockAnyDoor :: SingDS s -&gt; (Door s -&gt; Door 'Locked) lockAnyDoor door = case door of SOpened -&gt; lockDoor (closeDoor door) -- in this branch, s is 'Opened SClosed -&gt; lockDoor door -- in this branch, s is 'Closed SLocked -&gt; door I mean, stick to the essence of what you are trying to show. Keep everything else basic. (But kudos for mentioning that the syntax is lambda case, which is why is say this is better than other posts that deals with advanced stuff.)... 
Anyone able to say straight what the salary is? ie $X per hour
As others have mentioned, SBV is a good choice. If you're using Z3 specifically, the Z3 bindings are worth a look: https://hackage.haskell.org/package/z3 They're direct bindings against Z3's C API—much lower level than SBV. If you know you're working specifically with Z3 and need direct access to the solver, the API bindings are worth a look.
Thanks for posting it :)
Wow - I was not aware of haskell-lang.org! We actually have a website where Haskell is properly pitched! Where you can see on the first page, why you might be interested in this language, what your actual benefits will be when using the language. Awesome!
Thanks! It looks like a really well made library. How is it for throughput performance? Is it going to choke getting really big problems to the SMT solver?
Thanks, that's good feedback :) Initially I had it in for sake of imparting some sense of code-writing style, but I see that it might be a situation where it's better to introduce less new concepts all at once.
&gt; If you see f (g a) (g a) you really can replace that with let b = g a in f b b, blindly, no ifs, no buts. I wish this was the case universally. But I've run into type-system/polymorphism limitations regarding this multiple times. #### Example: {-# language NoMonomorphismRestriction #-} fooHandlerR = do uID &lt;- currentUserId let condition :: EntityField v (Key User) -&gt; Filter v condition = (==. uID) notifySelectUsers condition condition ... notifySelectUsers cond1 cond2 = do tokens &lt;- runDB $ selectList [cond1 NotificationTokenUser :: Filter NotificationToken] [] users &lt;- runDB $ selectList [cond2 UserId, UserEmail !=. Nothing] [] ... The above Yesod code I've written some time ago, and distinctly remember being quite angry with the type system for not letting me pass `condition` to `notifySelectUsers` and forcing me to pass it in duplicated as `cond1` and `cond2`. Maybe all I needed here was to enable `-XRankNTypes`but I hadn't heard of that at that time and I'm not sure. If you have ideas I'm all ears.
Hi, anyone with a good guide to setting up Haskell with Atom for Windows. Its honestly very frustrating to see no resources for this and only seeing comments that this is the easiest approach, yet being unable to get it to work properly. As of now, it crashes everytime I load a .hs file in Atom and I have no idea why.
do-syntax doesn't really let you write imperative code (but it does sort of pretend). What really happens is that your do-block gets transformed into a big expression made of anonymous functions, (&gt;&gt;=), and (&gt;&gt;). The rules are: do { E1; E2; } ~&gt; E1 &gt;&gt; E2 do { x &lt;- E1; E2 } ~&gt; E1 &gt;&gt;= (\x -&gt; E2) For example: do print 23 print (True, "Hello") Is transformed into: print 23 &gt;&gt; print (True, "Hello") And this: do s &lt;- getLine putStr "Hello, " putStrLn s Is transformed into: getLine &gt;&gt;= (\s -&gt; putStr "Hello, " &gt;&gt; putStrLn s) The operators (&gt;&gt;=) and (&gt;&gt;) both come from the monad typeclass, so what they do depends on which monad instance you're working with. For Maybe, they make sure that if any expression returns Nothing, then the entire thing also returns Nothing. For IO, well, that's probably out of scope for this post. Let me know if you want me to explain it at some point. A good exercise, at this point, would probably be to take some code you've written in do-notation, and transform it to use (&gt;&gt;=) and (&gt;&gt;), like I did with the examples above. Test that the two versions still do the same thing. Then try to write some code using the two operators, without writing it in do-notation first. 
That's a library you can use for [applicative validation](https://hackage.haskell.org/package/Validation-0.2.0/docs/Data-Validation.html#t:AccValidation), an example would be: Person &lt;$&gt; validatedName &lt;*&gt; validatedAge :: AccValidation [Error] Person Where `validatedName/Age` have type `AccValidation [Error] String/Int`. Imagine that they're coming from a network endpoint, and at this point they might have been validated or they might have failed with `Error`. If one or both of them have failed, the result of that applicative expression contains all errors in its `[Error]` constructor. As a more abstract note, in the long term you'll realize that **all** abstractions have a place in the grand scheme of things. Don't let the common discourse around `Functor`, `Applicative`s and `Monad`s fool you, there are infinitely many such useful abstractions, and they all have a place.
I guess what I'm trying to say is that posting incorrect "insights" isn't going to help anyone. We have too many Monad Tutorials already, and this thing further contributes to the confusion, and that's a bad thing.
The problem is not that someone new to Haskell doesn't know Haskell, the problem is that they're writing about it in a way that's going to make learning Haskell harder for people even newer to Haskell, by presenting "insights" that are in fact wrong and create more confusion than clarity.
Thank you for giving us a chance.
We have received an astonishingly high amount of applications and we are trying to process them as fast as possible. We will try to reply to everyone, ofc. :) 
Excellent! One very little detail: Before the GHCi command &gt; :k 'Opened the GHCI option &gt; :set -XDataKinds should be set. If not set, for beginners in Haskell type level programming the resulting error message may be confusing because they see the language pragma &gt; {-# LANGUAGE DataKinds #-} at the top of the file.
Please keep in mind that I am not expert. This is my interpretation. `\x y z -&gt; [x,y,z]` a.k.a `f x y z = [x,y,z]` is a function with 3 arguments that will build a list of arguments given ```` f 1 2 3 = [1,2,3] ``` `(+3)`,`(*2)` and `(/2)` all all function with one argument (after partially applied, or something `Curry`-thing) but the point is there is nothing special about them. Being functional language means they can be use as arguments to function above. The only problem is you can't visualize the function in ghci but you can ask for expression type. ``` λ&gt; :t (\x y z -&gt; [x,y,z]) (+3) (*2) (/2) (\x y z -&gt; [x,y,z]) (+3) (*2) (/2) :: Fractional a =&gt; [a -&gt; a] ``` Obiously, these function can be applied with one argument ``` (+3) 5 = 8 (*2) 5 = 10 (/2) 5 = 2.5 ``` With applicative syntax you can do the application of differenct context (I can't find more pricise word to describe, this might also means I don't really understand it :)) `(&lt;$&gt;)` a.k.a `fmap :: Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b` lifted the functions `(+3)`,`(*2)` and `(/2)` to a functor `[x,y,z]` `(&lt;*&gt;) :: Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b` is the tricky part, basically I treat this operator as `function application for fmap` as analog to ` `(space) is function application for simple function `($) :: (a -&gt; b) -&gt; a -&gt; b` is just a simple function application to apply `5` to those functions that wait for it. 
&gt; health insurance is provided by your government I'm not sure if you really meant to say it's free (zero, nada) for any resident, but if you don't mind, allow me to explain the situation in Germany. - the government isn't the health service provider in Germany, unlike the UK's NHS - there are many insurance companies, the choice is yours - fee is proportional to your income and also considers other factors - even without any kind of income you must find a way (social services if needed) to pay the minimum of ~170 - higher taxes and mandatory insurance plan, which are in some countries called government interference in one's life, are used to provide what might be perceived as a free service. If you live in a country where you pay &gt;=50% taxes, it's not unusual to get 1 to 3 years of unemployment support, which you could use to retrain for a different job. What I'm saying is that it's not free, but just a different resource scheduler (taxation, budgeting, spending) in use. Think of BeOS schedulers back in the day. Installing BeOS on your PC made it seem like you suddenly had an SGI workstation (of sorts) under your desk, whereas Windows struggled with any multimedia load. The resources (hardware) were still the same.
In my experience (the PureScript compiler) using the `Positioned` wrapper constructor leads to problems down the line. It causes pattern-matches to fail, because you tried to match two levels of structure at once. It's too easy to double-wrap certain expressions and at the same time when you encounter an error you don't have a source position at hand, because you'd need to climb the AST back up to find the narrowest position node. I think it's best to just insert a position into every constructor: data Expr = LitExpr SourcePosition Value | AppExpr SourcePosition Expr Expr It leads to a bit more boilerplate, and you might need to create some `&lt;internal sourcespans&gt;` along the way, but it's a lot easier to track down how these ended up in your error messages.
Well, I'm not really a Haskeller, but I'd be willing to take a look. Would need a more standalone example though - I'm not familiar enough to know what e.g. `selectList` is without a bit more context.
Yes, my experience agrees with this, at least for things resembling compilers or interpreters for general-purpose-ish programming languages
In the last paragraph of [the new link](https://gist.github.com/neongreen/98d40ea2b965166001bc20b15a26a6f9#how-to-apply).
Was just an example, but thanks!
If the smt problem is amazingly large then it can take lots of time. AES? Sha3? No problem. I did have a problem with native model that required n squared terms - running that (counting sat) took long enough that I didn't go over n=1000. I don't recall how much of that time was due to sbv vs z3.
I think using `LambdaCase` isn't bad here. If you work with singletons, you're going to want `LambdaCase`. `singletons` was actually the motivation for the first time I used `LambdaCase` Also, i don't think the function composition change makes it any easier to understand or read. If anything i end up doing more work by managing the currently bound variables in my head. When I see `door` I end up backtracking to see where it's bound 😞
&gt; making large classes of programming bugs impossible I think it's very unfortunate that when you say this, most non-FPers think you're talking about annotating your function arguments with types like `String` or `Int`. If you're lucky, they'll think you're talking about `Maybe` etc. And these are actually quite petty bugs, and they won't realize you're actually talking about parametricity, programming with laws, pairing of monads and comonads etc.
But you do seem to have a genuine typing issue here, your predicate is comparing its input to something of type `uID`, so the type-checker rightfully complains that `condition` is receiving something of the wrong type.
[removed]
What have you tried? Are there any logs so we can file issues with appropriate projects?
The shit that really has to stop is the indulging of this nonsense idea that just because something is written in an academic paper, i.e. it's typeset slightly differently and written with a slightly different register than what you might be used to, it's reasonable to not bother reading it, throw your hands up, and exclaim "Haskell library authors must just not care about documentation." On multiple occasions, reading papers linked in Hackage library docs has helped me not only understand a library significantly better, but also level up as a Haskell programmer more generally.
I get what you're saying, but I do think information like this is very valuable. Seeing wrong information can be just as useful as seeing right information. That's why live coding demos and troubleshooting are so useful for learning. Perhaps it'd be better if they were a bit more clear about being a beginner and how some of the information was likely wrong? I feel like they got that across pretty well though.
I had to extend `smtp-mail`'s functionality recently and am now a maintainer. Would you be willing to post an issue and perhaps what functionality you're expecting?
There's been rumblings for a "we use this commercially" list, where folks can "vote" on packages that are in use in real industry. I think that would be really helpful, but it's tricky to keep that stuff up-to-date.
Definitely. We ended-up using a mixture of haskellNet HaskellNet-SSL and mine-mail, when IMO, all three should be bundled into a unified library. 
Thanks for the detailed reply! Here are some thoughts I had while reading it: --- &gt; ... stuff about Rete and Datalog ... I had heard of Rete a long time ago but completely forgot about it since then. I am somewhat familiar with Datalog and propagators but totally missed that connection; it makes sense in hindsight so I'll definitely mine the literature there for insights. I guess the fact that the callbacks defined in equality analyses monotonically increase the number of nodes / edges / equivalence edges in the EPEG might be related to the connection between Datalog and monotonicity and termination explored in [this paper](http://www.rntz.net/files/datafun.pdf) and others? Certainly there's a connection between the monotonicity of equality analyses and the fact that if the saturation engine terminates, the resultant saturated EPEG is canonical. --- A complete tangent: The interesting thing about implementing equality saturation on term rewriting systems is that you really want to be able to trigger on more than one rule, and since a TRS is a set of rules that means you need to do associative-commutative unification. AC unification is technically NP complete (since it is equivalent to computing a basis of nonnegative solutions to a nonnegative linear Diophantine system), but in practice there are decently fast implementations of it. Speaking of which: someone should really write a C/Rust/C++ library for fast AC unification; it's kind of like SAT solving in that it really doesn't make sense for everyone to make their implementation of it that is highly specialized to their application. --- &gt; In any event, that is the only use of MCMC I've really thought about for Equality Saturation. Interesting; I had thought briefly on using machine learning to figure out which equality analyses are more likely to yield a node with higher utility, but did not connect it to MCMC. I had seen STOKE before, so stochastic superoptimization seemed pretty obvious as an option. --- With regard to the WYSINWYG problem: I think I might have a partial solution there. The [K Framework](https://github.com/kframework) people have put a lot of effort into making pretty-complete specifications of programming languages in rewriting logic, so if you could ensure that these specifications respect the cost model of the language and you augmented them with some notion of a network stack and networking primitives, you might be able to partially-evaluate these specifications on the (non-TRS) code you want to optimize so that you can run it through the TRS equality saturation engine I'm working on. I have no idea if the performance will allow for this (since it is whole program optimization taken to another level), but I suspect that equality saturation is at least somewhat parallelizable (certainly if your utility function is costly it can be evaluated in parallel), so I am optimistic that this kind of approach would be usable for very large organizations (like Google). --- Another completely weird question also just came to me: if selection during equality saturation is an integer linear programming problem, what properties should equality analyses have to allow a change of variables to a computationally easier problem for this algorithm in the style of the [heat method](https://arxiv.org/abs/1204.6216)? I suspect there's a lot of graph algorithms that might benefit from being studied from this point of view; the only reason that Dijkstra's algorithm was the first is that it has such an obvious geometric interpretation. 
This seems to not have anything to do with Haskell at all.
Would xform = (\(x,y) -&gt; (xz x, yz y)) work?
How do you think we could improve the search further? I think the table-based results from the gsoc project are a good first step...
Yeah, it's okayish.
Neat!
We don't know what that means because all of us are in different economic climates. "okayish" for some of us is $20ph, others $40ph and higher.
It was a joke :P a play on the job ad
have you seen grenade? https://github.com/HuwCampbell/grenade
IOHK needs as many good Haskell people as possible, /u/ethereumcharles any chance this person can negotiate with you? :)
Nice! I _think_ you can go back and forth from this to the (non-type-changing) profunctor version, using something like [this](https://pursuit.purescript.org/packages/purescript-profunctor/3.1.0/docs/Data.Profunctor.Split#t:Split) in one direction, and data Trace p a = Trace (p a a) in the other.
send me an email with the resume and github charles.hoskinson@iohk.io
`data User = User { name :: Text }` the first User is called a type constructor, the RHS User is called a data constructor that defines a record with a `name` field that is Text. Underneath, it's all functions, the record shorthand is just defining a User that has a function `name` that takes a User and returns a Text. `ActionM` isn't a subtype of IO. It's a so-called 'monad transformer' which is sort of a fancy way to say it's a composition of other monads. You can see here https://www.stackage.org/haddock/lts-9.18/scotty-0.11.0/Web-Scotty.html#t:ActionM that it's an alias for `ActionT Text IO`. The suffix T is a common naming convention for transformers. You can see its parametrized by Text and IO, so you're able to use both of those monads inside of ActionM/ActionT. In your func/IO example, func would have to return IO String for it to be used inside the do-notation like that. As a beginner, I found it helpful to think of &lt;- as an 'unwrapping' operation inside 'do'. i.e. a &lt;- func, if func :: IO String, a :: String.
/u/AshleyYakeley I hope you can work something out, IOHK is working on world changing stuff!
Oh, I hadn’t realised they’d changed their mind on that stuff, they used to be closed source. It seems to be that the older-gen drivers [are still closed](https://wiki.archlinux.org/index.php/AMDGPU) Still, from my (selfish) point of view, it would be more useful if they wrote a Tensorflow backend rather than open-source their drivers. 
Thanks for the link, I hadn’t seen that. It’s still a little raw in the sense that I see no mention of dropout or GRUs, and no choice in the gradient update (standard SGD is a bit slow), but maybe I need to read the docs. Unfortunately for very large datasets it wouldn’t work very well since it works on CPUs only: Tensorflow is the better choice if you want to train on hundreds of thousands of images. Still it’s a neat project with some solid ideas that exploits Haskell’s unique features. Thanks for bringing my attention to it. 
No problem! I hope the answer wasn't too long (or boring.)
It's almost certainly going to depend on your personal skillset, resume, negotiating skills, etc. If what /u/AshleyYakeley says is true: &gt; "Not quite entry-level Silicon Valley grade without benefits" would be accurate, though if you're in Europe or Asia where salaries are lower and health insurance is provided by your government, it might be competitive. In my experience, entry level (eg new boot camp/college grad) SV total compensation range around ~$90-120k depending on what kind of company it is. "Not quite" implies on the lower end of this.
That’s a good point. As examples of usage, I think IO is a reasonable trade off. Each function is kind of a pluggable main function. It wouldn’t be ideal to use these directly as a library, however. You can get AWST-typed actions by removing the runAWST from the examples. Amazonka itself has an AWST transformer. It has an algebra limited to AWS API actions allowing you to constrain away from “fire the missiles”-type arbitrary side effects being allowed, The Amazonka actions are composable as well making it possible to provide an action of composed AWS actions without admitting arbitrary IO.
This is genuinely interesting. There is some good explanation of trade offs and the frustration of reinvention of common functionality. A practical, useful post for solving a real-world app dev problem :)
Reading over my previous post, it might indeed come across as me trying to diminish people's accomplishments. I did not intend a personal attack against anyone, and could have phrased it differently. Yet I can share the OP's frustration and wrote my comment in spirit. I wholeheartedly agree with your second paragraph, it matches my own experience. Still, I think in your first paragraph you are jumping to conclusions. There might be some libraries out there where reading a paper will suffice to get started, and indeed if one is available, I *do* read it. However, I don't think it is a substitute for actual haddocks, and see the following problems: * If I want to just know what one function does, and can't figure it out from the type signature or from trying around, having to read or just browse a whole paper is terribly unproductive. * The function should not be assumed to be even mentioned in the paper. The paper will most often primarily deal with the actual scientific contributions, not an exhaustive API description. * An exhaustive API description isn't generally possible, since the API changes. * The paper might not just be "typeset differently", it might use totally different identifiers, including Unicode operators, making it difficult to search. * If the last point applies, I can't "just browse" the paper after all, I need more context and may have to read the whole thing. * I can browse haddocks locally, and can play around with type-signatures in ghci. I can't read the paper if I am not online. It might not even be open-access. All these things are *not* a deal breaker. They are just annoying. Especially if only after reading the whole paper it becomes clear to me that this library would not fit my needs. Let me stress that I know I have no right to demand library authors provide a different kind of documentation, after all, the library itself is something I didn't pay for either and I am grateful that the libraries I use were written in the first place. But, this doesn't mean this situation is ideal. First of all, from my experience the point I made about some characteristics not being captured in a type-signature still holds when extended to an accompanying paper - except maybe the point about laws, if (in the paper) emphasis was put on some algebraic structure, for instance. Furthermore, and this is of course opinionated, I strongly disagree with the idea that the documentation should not contain recommendations (if they can be given) on how to use the library. However, this information probably does not belong in a scientific paper. One more observation I made (biased, of course), was that in a library where some functions are documented, the less well documented ones are also less likely to be used or talked about. A specific example would be the `stm` package. What does [alwaysSucceeds](https://www.stackage.org/haddock/lts-9.11/stm-2.4.4.1/Control-Monad-STM.html#v:alwaysSucceeds) do? Now it could be different for you, but to me the description is not terribly enlightening. That's fine, just look in the paper. Not the one cited at the top though, I mean [this one](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/07/stm-invariants.pdf), which you can find by searching for "Haskell STM invariants" or similar. Did you know they exist? I read the whole paper, worked through the examples, decided this is actually pretty cool and tried it out on some pet project of mine. After a few hours I was able to come up with a minimal example of why my program would either live-lock or trigger an assertion, and filed a [bug report](https://ghc.haskell.org/trac/ghc/ticket/14310). Turns out the feature was [broken for ten years](https://github.com/bgamari/ghc-proposals/blob/deprecate-stm-invariants/proposals/0000-deprecate-stm-invariants.rst). I bet you, had these functions been documented more thoroughly, maybe in a dedicated section or an example, this would have been noticed sooner.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [bgamari/ghc-proposals/.../**0000-deprecate-stm-invariants.rst** (deprecate-stm-invariants → f4b3da9)](https://github.com/bgamari/ghc-proposals/blob/f4b3da90c48ea140f4457b35b2c78dfe3e80c3ba/proposals/0000-deprecate-stm-invariants.rst) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply drq1g3e.)^.
OK so that’s $40-50ph or more, which is very high even for a long time professional in my region.
I think you're running into let generalization or rather the lack thereof in functions. let f a = a in (f 1, f True) -- This is fine. (\f -&gt; (f 1, f True)) id -- This is not fine.
A rewrite of aura would be awesome, I use it all the time.
Hey Thanks so much! Honestly all the other posts that make it to /r/haskell are way more interesting, well-written, and in-depth. Thought I might vary it up with some more low-brow pieces from the trenches of application development.
Thanks for the small reproducible case! This indeed seems like the (or at least one) crux of the issue. And I managed to make it work! At least with this simplified case: Prelude&gt; :set -XRankNTypes -XScopedTypeVariables Prelude&gt; (\(f :: forall a. a -&gt; a) -&gt; (f 'c', f True)) id ('c',True) I wonder why `forall a. a -&gt; a` is not inferred in there. Any ideas?
Can we make a donation to a **specific cause**?
I think You are guilty of a bit of waesel talk, pal. It may be String -&gt; Int you have issue with but int foo(String name) is not equivalent. foo :: String -&gt; Int foo name So I fail to see the difference. Both are utterly disastrous function names. FOO, really? What about length? syllables? vovels? is_utf8? See you code example where name of parameter don't matter at all. Totally. It's name if function that will make all the difference. And as I showed you both languages have same information. So are you just a troll?
Right, their massive open sourcing of their drivers is a [recent phenomenon](https://www.phoronix.com/scan.php?page=article&amp;item=amdvlk-radeon-vulkan&amp;num=1). As for TF, I thought it had decent OpenCL support? In any case, I think NVidia's increasing efforts to lockdown their platform will eventually backfire. The only reason people tolerate that is because we have no choice - AMD currently simply does not have any hardware available that can compete efficiently (TDPs are wayy too high on current AMD GPUs). But as soon as they do, I will be jumping ship.
[removed]
I agree; however I used it as an example of reasonably-easy-to-understand library, which it seems to me it indeed is.
&gt; "Not quite" implies on the lower end of this. Not quite. AFAIK IOHK doesn't pay $90k (and neither do we). $20/h is more accurate than $40/h, although depending on your needs, skills, and experience it can vary in both directions. Oh, and yes, no benefits. I really should've mentioned that in the original post – I simply forgot because in Russia benefits-as-a-job-perk aren't as widely spread as in other places.
Oh, right :) I think this is more a problem between what a beginner expects and what an advanced user expects. Having a few years experience in Haskell it seems to me perfectly OK. I think this is exactly the case - if you are used to reading the function signatures, it works. If you are used to reading example code, it is very frustrating. I usually work like this: I need to create a `Mail`. So first look at the [Mail](https://hackage.haskell.org/package/mime-mail-0.4.14/docs/Network-Mail-Mime.html#t:Mail) declaration. That's pretty clear, I could make it by hand. I just need to look up [Address](https://hackage.haskell.org/package/mime-mail-0.4.14/docs/Network-Mail-Mime.html#t:Address), that's quite easy too. And [Part](https://hackage.haskell.org/package/mime-mail-0.4.14/docs/Network-Mail-Mime.html#t:Part) - that's harder; are there any functions to create a `Part`? (Ctrl-F, -&gt; Part) Yes, there are `htmlPart` and `plainPart`. There are also some functions that manipulate the `Mail` and add an attachment. If I were designing the library today (the first version is 7 years old!), I think I'd take different design decisions - so would Michael Snoyman, I guess. But that's it; should somebody make 'newGeneration' library that would do the same, just with a slightly more modern API? I don't know. I tend to add some short tutorials to my libraries precisely to help the beginners to use the library, but I quite understand the haskell community, as now I am perfectly happy without the examples and I usually just search for the proper function anyway. But it's not that hard, it's just a change of how to look at things. Don't let it discourage you :)
There’s no official OpenCL support for TensorFlow. There are third-party attempts to create such a backend, but Google hasn’t adopted them yet. Honestly I’d love it if there was, I own a lot of Apple gear, and I’d prefer not to have to rent an Amazon box every time i wanted to try something. 
/u/grokkingStuff if you ever find yourself in need of intel on numerical/data stuff, come over at datahaskell.org/docs . 
A crypto currency option would be nice as well.
Your tutorial should mention `th-abstraction` package: * https://hackage.haskell.org/package/th-abstraction I can't imagine writing TH code without this package because every new GHC version brakes something in TH. And if you don't to rewrite your TH nightmare code every year you need to use some abstractions for this.
&gt; we only get to see the most common, conventional, and benign uses of the feature One of the most important uses of TH is to create DSLs that are integrated into systems built in Haskell. That is the principal documented purpose of quasiquoters, and one of the major uses of TH throughout the ecosystem. As correctly discussed near the beginning of the tutorial, there are reasons why this use of TH, like others, may be more appropriate or less appropriate for particular use cases. Perhaps the author of the tutorial doesn't favor this usage of TH in general. But to avoid mentioning it completely seems like a huge gap in something claiming to be a TH tutorial. There are whole ecosystems, such as Yesod, which make extensive use of TH DSLs, and could never have existed without them. The Yesod platform is used widely in large commercial systems and has attracted hundreds of developers to Haskell.
I think I see where the problem is. You have to go back and forth in terms of thinking of the ((-&gt;) r) functor. First off if you have a function X -&gt; A, and another function A -&gt; B then from composition you can create a function X -&gt; B. So this is an fmap. (+3) :: A -&gt; A, that is you can think of it as F(A) using the (A-&gt;) functor. This is what the Functors, Applicative Functors and Monoids chapter is saying with: fmap :: (a -&gt; b) -&gt; (r -&gt; a) -&gt; (r -&gt; b) next let ma1 x y z = [x,y,z] ma2 x = (\y z -&gt; [x,y,z]) ma1 and ma2 are the same function. Fmap is going to add one more level ma2 :: A -&gt; (A -&gt; A -&gt; [A]) fmap ma2 :: F(A) -&gt; F(A -&gt; A -&gt; [A]) or fmap ma2 :: (A-&gt;A) -&gt; (A-&gt;( A -&gt; A -&gt; [A])) (+3) is an `A-&gt;A`. So that leaves the `F( A -&gt; A -&gt; [A])`. F of a function is what `&lt;*&gt;` wants. Which is why you can then use the (*2) and pull off the next term just leaving the `A -&gt; A -&gt; [A]`. But you can also think of this as `F(A-&gt;[A])` and apply `&lt;*&gt;` again. When you are done you have a `F([A])` which you now have to think of back as an `A -&gt; [A]`. Thought of this way you have something you can apply 5 to. 
See my answer why it doesn't work. 
&gt; Let me know if you want me to explain it at some point. Hey, I want to know that! I partially understand it for `Maybe` and `Either` from looking at the function signatures, but not yet for `IO`.
Why? Consider the transaction and conversion costs, and the high value volatility.
I will write a thing when I get to my computer later! :) 
Thank you. I still don't understand what `ActionM` is, but I've gotten closer. So `Text` is a monad too? Is (almost) everything a monad in Haskell? What is the advantage of making something a monad instead of just a simple value or data type?
&gt; Perhaps the author of the tutorial doesn't favor this usage of TH in general. But to avoid mentioning it completely seems like a huge gap in something claiming to be a TH tutorial. I just forgot, I'll add it. Your comment also sounds somewhat aggressive, and I don't know what is the cause of this tone. "In something claiming to be a TH tutorial" -- there are many tutorials that do not even try to enumerate uses of TH, they just throw some code at you and explain it. Nothing wrong with that, I still consider them "TH tutorials".
Thanks for the tip. Instead of `:make`, I often use `tmux` + `ghcid` to watch changes (it can also run tests). Does anyone know if there's a plugin that lets you import the error locations displayed in the `tmux` pane back into Vim?
&gt; the section on do notation is kind of backwards Yes, I understand that now. Thank you. It is really saying the opposite of what actually happens. But I won't change it, since it would defeat the purpose of the post. &gt; Saying "you don't" is throwing away the usefulness that monads/functors give you. Thank you for the detailed example. It was really clarifying. I already understood `Maybe`s weren't supposed to be just passed to `fromMaybe`, but that you could manipulate the value inside the `Maybe` without removing it (I tried to say that in the post) and just remove it on the end of the computation, but couldn't really figure out an example using the `do` notation. I remember, however, getting really annoyed and upset I couldn't grab the value from inside a `Maybe` in the beggining, and so I wanted to calm down the reader by talking about `fromMaybe` first. &gt; Lists ([]) are also a monad, so you can use do notation with them. What do you think the &lt;- does then? (Hint - how many ways are there to take a value out of the context of a list of, say, 3 elements?) Again, I can't imagine an example of this. I can't conceive of a situation in which you would apply the `do` notation to a list, nor what the `&lt;-` would do. Maybe the answer is `head`, `tail` and something else? (Probably not, I'm confused). Also, the analogy with the callback hell was very helpful. That should really be used in the next `Haskell for Javascript people` tutorial.
Pretty sure that violates parametricity.
I concede on the easy-to-understand part wrt smtp-mail. I have used it as well, and had not issues in understand how it works. However, I hold steadfastly on the overall comment about Haskell library ecosystem being *effectively* broken, and `smtp-mail` is "exhibit A" wrt that.
Means? 
What's with the downvotes? It's a genuine question.
Long time user, first time donating! Actually, I'm donating a lot more money to a lot more charities this year, and it's all thanks to Haskell. After using Haskell for my personal projects for a decade, this year I finally achieved my dream: working for a company whose _main_ language is Haskell. Having heard of the "[Haskell tax](https://www.reddit.com/r/haskell/comments/27onwq/why_programmers_cant_make_any_money/)", I was prepared for the possibility that achieving my dream might come at the cost of a lower salary. I am happy to say, the opposite happened! So I now have more money to spend on, among other things, charity, and Haskell-related charities are at the top of my list. Are there others? The [Lambdaman T-shirt](https://www.customink.com/fundraising/lambdaman) profits "support Bootstrap, teaching Functional Programming to Middle- and High-School students", for example.
&gt; The most wonderful thing about quoters is that we can actually use splicing inside them Unfortunately, as of GHC 8.2.2, splicing doesn't yet work inside declaration quoters: &gt;&gt;&gt; let x = [e|()|] in ppr &lt;$&gt; runQ [e|$x|] GHC.Tuple.() &gt;&gt;&gt; let x = [t|()|] in ppr &lt;$&gt; runQ [t|$x|] () &gt;&gt;&gt; let x = [p|()|] in ppr &lt;$&gt; runQ [p|$x|] GHC.Tuple.() &gt;&gt;&gt; let x = [d|type Unit = ()|] in ppr &lt;$&gt; runQ [d|$x|] ... ...error: ...Splices within declaration brackets not (yet) handled by Template Haskell
Both directions indeed work: http://oleg.fi/gists/posts/2017-12-23-functor-optics.html#s:8 I find quite surprising that`Split` is working for `Strong` too. Well guessed! 
If I'm understanding correctly, this isn't about "causes." This funding isn't for paid developer time to improve various projects. I believe these donations go toward the monthly bills of keeping haskell.org online and running, including the Hackage matrix builder, GHC issue tracker, wiki, and more.
Your type for `mkName :: String -&gt; Q Name` is incorrect. The correct type is `mkName :: String -&gt; Name` http://hackage.haskell.org/package/template-haskell-2.12.0.0/docs/Language-Haskell-TH.html#v:mkName
The general haskell.org fund isn't earmarked. The best way to make earmarked donation at the moment is via funding of specific SoC projects. 
It’s not either/or - nor is it about the merits of crypto - but simply that some people have a lot of crypto lying around.
Glad it was helpful - feel free to ask more questions or send a PM as you learn more. About lists: just as we can have our functions return `Maybe` or `Either` to model "functions that might fail", we could have our functions return a list to indicate that there's more than one possible right answer. (Some people might refer to this as "nondeterminism".) This is the interpretation we get from the monad instance for lists. So, with do notation, `&lt;-` just picks one right answer from a list of them, and lets us do something with it. The rest of the monad machinery makes sure that this happens with *all* possible choices, so we don't have to do that boilerplate ourselves. (The answer to my hint question earlier would be "there are 3 ways to take a value out of the context of a list with 3 items, so `&lt;-` must pick each of those options".) As an example, let's say we have a bunch of files that are named following a pattern: each filename is a prefix, followed by a number from 0 to 9. Given the list of prefixes, we want to generate all possible filenames. Here's what that could look like: genFilenames :: [String] -&gt; [String] genFilenames prefixes = do prefix &lt;- prefixes num &lt;- [0..9] return (prefix ++ show num) (I think that's right, but I'm on mobile so I can't check right now. The last line might be wrong.) In this example, we can use do notation to say "pick a prefix from the allowed ones (doesn't matter which, as long as all of them eventually get picked), then pick a number from the allowed ones (same deal), then use them together somehow. It turns out that doing this kind of thing is so common that Haskell provides another special syntax for it, called list comprehensions. (You've probably seen this in LYAH already.) But lost comprehensions are just syntax sugar over the list monad!
Iirc haskell.org donations cover Summer of Code and server maintenance costs. If you want to fund development effort, this isn't the route. 
You are right, and it was completely unintended. I sincerely apologize. I removed that part of my post. Perhaps it was fueled by frequently seeing unjustified "TH sux0rs" comments in the community. But that's clearly not you. Your tutorial is excellent, and I completely agree with your attitude about TH.
Thank you, fixed!
I updated the text to mention this, thanks!
I mentioned this in another thread a while ago but sponsoring a person or two to go through and just write pages of documentation, tutorials, etc, for Haskell libraries and concepts would be awesome. Would be a great chance to go through the wiki and really clean it up, too. Discoverability of packages on Hackage is another thing I'd love to see perhaps tackled. The design of the website is also a bit lacking, to me. It doesn't need to be all css and magic js, but a little less dated of a design and a little easier to find information would be fantastic. Perhaps the community could vote on, say, 10 libraries that Haskell really should have but doesn't, or some libraries that sorely need code and performance improvements (particularly lower level libraries where speed benefits affect everyone else?) I think it might also be a good idea to take a good long look at what Rust did and accomplished for their 2017 goal of being a more beginner friendly and ergonomic language and seeing what we could do to improve our ergonomics as well. There's also the Dev ops side of GHC that could be touched upon. What if we set aside an entire "developer" worth of money and set bounties on a bunch of small, easy little tasks to be fixed through simple PRs to GitHub? First come, first serve, and it'll encourage more people to get their feet wet :) It would be cool if we could somehow get GHC "adopted" by more companies that are sold on it's benefits and are willing to invest in the technology. Not quite sure how we could make this a HSOC thing, though.
No problem, and I have added a mention about TH DSLs in the motivation section: https://markkarpov.com/tutorial/th.html#motivation.
Is there an alternative to http://haskellbook.com that explains stuff like monad transformers, ReaderT, etc to existing programmers (not total beginners)?
on my phone, so I can't research the most elegant solution at the monent, but one way to do it would be to - change your `tmux + ghcid` setup to `tee` the compilation/test output into a file, `SOME_FILE` - in vim `:let &amp;makeprg="cat SOME_FILE"` - whenever you want to load error/broken test locations in vim, run `:make`
tl;dr: Check [this pull request](https://github.com/fpco/stackage/pull/3140/files) to see if your package was just removed from Stackage Nightly. Yes, this is just copying the tl;dr from the blog post itself. I'm guessing lots of people read the comments before the article itself. :)
There's a good section in Real World Haskell iirc
Thanks for all the help. To understand it, I did a step by step evaluation. Since Haskell is lazy, I am not sure that's how it evaluates it. (\x y z -&gt; [x,y,z]) &lt;$&gt; (+3) &lt;*&gt; (*2) &lt;*&gt; (/2) $ 5 -- f &lt;$&gt; g = \x -&gt; f (g x) (\r1 -&gt; (\x y z -&gt; [x,y,z]) ((+3) r1)) &lt;*&gt; (*2) &lt;*&gt; (/2) $ 5 -- f &lt;*&gt; g = \x -&gt; f x (g x) (\r2 -&gt; (\r1 -&gt; (\x y z -&gt; [x,y,z]) ((+3) r1)) r2 ((*2) r2)) &lt;*&gt; (/2) $ 5 -- f &lt;*&gt; g = \x -&gt; f x (g x) (\r3 -&gt; (\r2 -&gt; (\r1 -&gt; (\x y z -&gt; [x,y,z]) ((+3) r1)) r2 ((*2) r2)) r3 ((/2) r3)) $ 5 -- apply 5 to r3 (\r2 -&gt; (\r -&gt; (\x y z -&gt; [x,y,z]) ((+3) r)) r2 ((*2) r2)) 5 ((/2) 5) -- apply 5 to r2 (\r1 -&gt; (\x y z -&gt; [x,y,z]) ((+3) r1)) 5 ((*2) 5) ((/2) 5) -- apply 5 to r1 (\x y z -&gt; [x,y,z]) ((+3) 5) ((*2) 5) ((/2) 5) [8.0, 10, 2.5]
VSCode with haskell-ide-engine works well for me ([instructions here](http://www.vacationlabs.com/haskell/environment-setup.html#installing-an-editor)). Though spacemacs and haskell-ide-engine is my current preference (and I prefer stylish-haskell).
I started www.haskanything.com a few years ago to address the discoverability concerns. It's a statically generated Hakyll site that gets rebuilt every time new content (Markdown files with metadata) is pushed. You can add new content via merge requests and via the site itself (but I haven't tested that out since a long time). It's still on my to-do list to revive it by doing stuff like: - ask blog authors for permission to write a short , two-three line summary of their posts and link to the article on their own site. There's a lot of awesome tutorials and articles out there! - add a lot more papers and presentations (again, a summary / abstract and a link to the actual resource). - making more collections. Currently I have a few series of conference presentations. - use the data from Hackage / Stackage to automatically create pages for packages and libraries. - trawl Github for more Haskell stuff not on Hackage / Stackage I'm looking for people to help me out with this large endeavour. Hit me up here or at beerendlauwers@gmail.com if you're interested!
Okay, so I was gonna write a long post with examples and explanations and stuff, but while looking for some code examples to steal from the internet, I stumbled over [this post](https://wiki.haskell.org/IO_inside), which is honestly a better explanation than what I could write. So I'm gonna be lazy and leave you with that to read. :) Merry Christmas!
`Text` is not a monad, no - for a type to be a monad, it must have a type parameter (for example `Maybe a` or `IO a`). The advantage of making something a monad is that you get access to both do-notation, and a bunch of useful functions like `sequence`, `forM`, `filterM`, and many more.
Excellent, glad it worked :) `Split` came out of trying to find an adjoint to `Trace`, in order to construct a `Profunctor` from an existing `Invariant` (thereby showing that you don't really ever _need_ `Invariant`, you can just break things into covariant and contravariant type arguments)
What does matter to an organization is that the donations have a consistent value. I think it's the same reason why so few merchants accept cryptocoins.
e.g. `aeson` and `lens` use it, it's great!
It's different for merchants - they're selling a product. But for donations, you're getting it for free, so I don't see any downsides. The value is likely to change, but it's value regardless, vs. not accepting the donation.
As a student, I'm looking forward to finding a project related to Haskell if possible. Please feel free to send me a PM if anyone has any ideas and would like a possible applicants opinion on.
&gt; datahaskell.org/docs &gt; posted on Christmas This is the best gift I've received in a while. Thanks you! 
:) Thanks! I kinda get what you mean and I'm definitely improving on looking at libraries and figuring out how to use them. I'm actually thinking of making an email library that abstracts email protocols away for the library user - would make life easy for me and other people. Would be a great project as well. Also, Merry Christmas! Hope you have a great year ahead.
My pleasure! We also have a chatroom for questions and ramblings: https://gitter.im/dataHaskell/Lobby 
I did not know about this package when I was doing a bit of TH earlier this year. Thanks for mentioning it!
Yup my thoughts exactly. It’s simply yet another channel through which people could give. 
Plus, automatic scripts could be used to immediately cash the money to a more stable currency if wanted (I think?)
An alternative? Any alternative? Like almost every book on Haskell and numerous tutorials? I'm not sure what you are looking for if you are unaware of any alternatives and have looked around much at all.
I proposed to consider `exference` instead of Djinn in one of the idea: * https://github.com/commercialhaskell/intero/issues/8#issuecomment-353892306 As a supervisor in university I came with the diploma topic like _support bigger subset of Haskell in Djinn_ but then I discovered `exference` and canceled my diploma proposal because there wasn't much sense in improving Djinn when Djinn is already improved...
One thing that might expand Haskell use would be if someone packaged up the whole Safe Haskell, dynamic reloading,... stuff into something that could easily be used for embedded Haskell use, think applications that would otherwise be solved by a scripting language like user-supplied scripts they can upload to some sort of server software that doesn't fully trust the users.
I don't think you need permission to summarize content 
The fluctuating value might make bookkeeping quite hard anyway.
I don't think there's a way to do that specifically, but we're happy to hear your suggestions regardless of whether you donate. You can email committee@haskell.org if you want to contact the committee directly.
Your question was a riddle I would never guess. Anyway, this is amazing. I thought `genFilenames` would be implemented using some form of `map-over-values` (like JavaScript's `.map`), but the use of `do` notation is great here (probably the same thing can be done with something like a `map` function). Where can I find the type definitions for the list monad? Couldn't find them on `Data.List` or `Prelude` docs.
Thank you. I'll read it for sure. I think I'm able to understand these explanations at this point -- with all the help from people in this thread. The big problem is that they're too alien for total begginings.
The job I interviewed for was not exactly the same as this one. I suggest you just ask Serokell about it. (Also [this comment](https://www.reddit.com/r/haskell/comments/7lont3/serokell_is_hiring_haskellers_fully_remote_job/drqguv5/).)
Note that you would need to disallow IO, which would greatly limit the utility - http://blog.ezyang.com/2012/09/common-misconceptions-about-safe-haskell/ I wouldn't trust safe haskell as a security mechanism. I bet you could still craft out of range memory writes that could violate security properties. It requires that you trust the modules that are marked trustworthy. Not sure what the mechanism is to approve modules marked trustworthy. It is an interesting system, but TBH I haven't seen a real use for it (would be happy to be proven wrong!)
Sorry, I probably could have phrased it better - wasn't really a fair question. You're right - `genFilenames` could definitely be implemented with `map` instead. It would call it twice (once for the prefixes, then once for the numbers), but that would end up with a list of lists, so you would want to flatten it with `concat` too. Or to save a step, you can use `concatMap`, since that both flattens and maps. Now to blow your mind - we know do notation is just syntax sugar for something else. The compiler rewrites do notation into expressions that use `&gt;&gt;=`, a function defined for any monad. In Haskell, `&gt;&gt;=` is called "bind", but some other languages call it `flatMap`. Considering what we just said about `concatMap`, do you see why? The source for the list monad instance is here: http://hackage.haskell.org/package/base-4.10.1.0/docs/src/GHC.Base.html#line-819 Looks like I was wrong- the list monad is defined as a list comprehension. But either way, it's easy to express one in terms of the other.
To quote my other comment: &gt; &gt; "Not quite" implies on the lower end of this. &gt; &gt; Not quite. AFAIK IOHK doesn't pay $90k (and neither do we). $20/h is more accurate than $40/h, although depending on your needs, skills, and experience it can vary in both directions. &gt; &gt; Oh, and yes, no benefits. I really should've mentioned that in the original post – I simply forgot because in Russia benefits-as-a-job-perk aren't as widely spread as in other places. So, the fork is $20–70k junior-to-teamlead depending on various things (even all else being equal, it makes sense to increase the compensation based on cost of life, taxes and so forth). I should've included the fork right from the start, and if the reddit link went to the gist and not to the specific revision, I would've just edited the gist and be done with it :) Also, I should probably spell it out, even though it's already mentioned in someone's comment below: we're not IOHK. We are collaborating with them on [Cardano](https://iohk.io/projects/cardano/), and it's our biggest project, but we have other projects too. --- _[below is a bit of backstory for curious souls and people who want to learn from others' mistakes]_ The reason I went with vague descriptions like “okay-ish” instead of a fork is simply that I didn't know whether I was allowed to disclose the details about compensation – or whether the details I knew were even accurate. It happened roughly like that: — guys, I'm leaving Serokell in two months — :( can you at least help us find a replacement? Since I don't really know any unemployed Haskellers, I just went ahead and wrote a post in functionalprogramming Slack (without showing it to management or anyone else). It wasn't intended to be an “official” vacancy – I just wanted to find 3–10 interested people, ask them some questions and then refer them to our CEO. (And then Matt Parsons tweeted it, Gabriel Gonzalez retweeted it, /r/haskell blah blah, we got 80+ applicants and things went ~~completely~~ a bit out of hand and we started doing semi-proper HR with our CTO doing interviews and such. It's definitely been... an interesting experience for me, so far.) --- **tl;dr** * not warning people about the vacancy being unofficial * not having control over the text after the publication * somewhat outdated/wrong impressions about Silicon Valley salaries ;)
&gt; These Complete Haskell Tips &amp; Secrets for Professionals series are compiled from Stack Overflow Documentation via Archive.org Wat.jpg The ordering of the chapters looks completely arbitrary, the ToC looks like it was randomly generated from a Haskell buzzword salad, the sample category theory page looked terrible, and the title is ridiculous. I'm struggling to see why this is even a thing. Is there anything in there that you can't get from reading the Haskell tag of stack overflow? (The page layout of the pdf also terrible but that's not relevant to the content)
So much this. I wanted to start some projects in Haskell but documentation is really lacking. Just one book for learning but resources for common libraries, web libraries, GUI and such simply doesn't exist.
Sorry, I'm failing to see who this is useful for. Anyone using Haskell professionally isn't going to get much use out of it.
The downside: "These Complete Haskell Tips &amp; Secrets for Professionals series are compiled from Stack Overflow Documentation via Archive.org, the content is written by the beautiful people at Stack Overflow, text content is released under Creative Commons BY-SA, see credits at the end of this book whom contributed to the various chapters. Images may be copyright of their respective owners unless otherwise specified." The upside: at least its free?
The same user has made similar posts about CSS and C# books. It feels a bit like the libhunt posts, but across less languages.
I expected "a" but got &lt;interactive&gt;:2:1: warning: [-Wtype-defaults] • Defaulting the following constraints to type ‘[Char]’ (Show a0) arising from a use of ‘print’ at &lt;interactive&gt;:2:1-3 (Data.String.IsString a0) arising from a use of ‘it’ at &lt;interactive&gt;:2:1-3 • In a stmt of an interactive GHCi command: print it I was wrong :' (
&gt; datahaskell.org/docs This is interesting, thanks for sharing!
Sign me up /u/chrisdoner!
Hi, thanks for your feedback! &gt; These Complete Haskell Tips &amp; Secrets for Professionals series are compiled from Stack Overflow Documentation via Archive.org Will re-word that make that clearer. In summary there used to be a Stack Overflow documentation page, I used to use it regularly for other languages and it contained quick summary notes I found useful for my job. In August Stack Overflow removed the content from Documentation pages, and uploaded it to Archive.org in JSON files I just wrote a script that reads these JSON files and converts them to PDFs &gt; The ordering of the chapters looks completely arbitrary The ordering is probably wrong, I think I had a bug and sorted chapters alphabetically rather by numerical &gt; the title is ridiculous I will change the title, but to re-build all 50 PDFs takes 2 hours, so will update soon &gt; I'm struggling to see why this is even a thing. Is there anything in there that you can't get from reading the Haskell tag of stack overflow? For some languages I have found the content useful to learn new tricks not outlined in the language documentation, not sure the content would be useful specifically to you?
Yes correct, these PDF books are generated from Stack Overflow Documentation, for 50 languages including C, C#, C++, CSS, HTML5, JavaScript etc...
&gt; at least its free The book content is CC-BY-SA identical to Stack Overflow, however as some books include for example company logos, they can be protected by trademark and copyright; so that is why "Images may be copyright of their respective owners unless otherwise specified" and another similar trademark disclaimer is included
This sounds an awful lot like what ml modules are supposed to be great for. 
If the homepage of the book explained more clearly why it was made -- like what you have above -- then it might help your reception. The fact that people put a bunch of work into this documentation, and you're helping it live on, helps clear a lot up!
IIRC this is undecidable in general, but you could quickcheck it the same way you'd quickcheck anything else -- generate random values and show that both expressions evaluate to the same value. If you need a universe of values, you might be able to get by with SKI which you could check for syntactic equality.
Hear, hear! This is a great thing to address, or at least carefully consider for the benefit of Haskell-like languages. Throwing something else into the mix (as if this needed to have more things to fix, heh), is a mechanism like https://ghc.haskell.org/trac/ghc/wiki/InstanceTemplates or https://github.com/Icelandjack/deriving-via . The primary goal of these proposals, and some others that came before, is to have an abstraction that results in instance dictionaries. This is useful in diminishing boilerplate and easing backwards compatibility. It's quite relevant to the problems described here, because one way to look at it is being able to write a function that results in instance dictionaries. One thing I don't quite like about instance templates is that you can observe whether the template was used or not, from the interface, since it's just another typeclass. I think it should not be visible in the interface. 
hear, hear
Thanks for the clarification. Have set up a small monthly donation. Thank you for keeping the infra alive &amp; kicking. Moderators (/u/dons /u/jfredett /u/edwardkmett /u/taylorfausak /u/Iceland_jack /u/BoteboTsebo), please consider pinning this post to top of the subreddit.
As /u/Tayacan said, no, not (almost) everything is a monad in Haskell, since every monad must take a type parameter. But I just want to point out that that's not the only requirement - there are also other "laws" that must be satisfied for something to be a monad. In other words, something has to behave in the right, very predictable, ways. Additionally (as you may have guessed already), monads exist outside of Haskell :) It so happens that Haskell supports monads very well (because it's type system in expressive enough to be able to write code that works with arbitrary monads), while most other languages can't support the *concept* of a monad. But, that doesn't stop anyone from implementing a *particular* monad (e.g. `Maybe`) in another language. In fact, JavaScript promises are a monad*! (`.then` is the `&gt;&gt;=` or `&lt;-` operator.) That's why they're so much easier to use than callbacks. (And `async`/`await` is just do notation for that particular monad only.) *Ok, promises technically aren't a monad - they don't follow all the monad laws. But they're disobedient in a way that doesn't make them harder to use, so it doesn't really matter.
What is the _real_ reason that Haskell has been (repeatedly?) rejected by GSoC? I ask this because the stated reason -- "...we didn’t really have a great homepage for Summer of Code with ideas for students..." doesn't seem very genuine. IIRC wasn't this the original reason why Haskell was rejected the first time around (about one or two years ago)? Here are samples of some other organization's pages: * https://wiki.postgresql.org/wiki/GSoC_2017 * https://code.djangoproject.com/wiki/SummerOfCode2017 * https://github.com/discourse/discourse/wiki/Summer-of-Code-2017-Ideas-List * https://github.com/elm-lang/projects/ * http://clojure-gsoc.org//project-ideas/ One thing missing from the current HSoC ideas page is a clear definition of "expected outcome", which Posgres and Clojure seem to have. However, it is missing, or unclear, even in the other pages.
https://github.com/haskell-org/summer-of-haskell/pull/15 &gt; Most (all?) editor tooling uses GHCi-as-a-library and essentially keeps "reloading" your source-files in the GHCi session. This allows your editor tooling to type-check your files "on the fly" and report compile errors as you edit your source code. However, GHCi has a nasty space-leak, where it retains some bindings across reloads. So, for long-lived GHCi sessions, or for very large projects, the GHCi memory usage keeps increasing over time, eventually causing slow-down or sluggishness of the entire code-typecheck-debug cycle. 
https://github.com/tonyday567/numhask-range is my trip down this rabbit hole. My use case was charting and I went for union/mappend/plus as a convex hull union ie Range 0 2 + Range 4 10 = Range 0 10, but thought about your RangeSet a lot as an alternative. I think RangeSet as a Number can form some interesting algebras. 
Conor McBride has a [PDF](https://personal.cis.strath.ac.uk/conor.mcbride/so-pigworker.pdf) of all his Stack Overflow answers, quite an interesting read.
If you're on Windows there's a possibility that you're having the same issue that I had recently, which, as it turned out, had nothing to do with Stack. Whenever I would (often unintentionally) select text in the terminal, it would "hang" until enter was pressed. Disabling quick edit mode fixed it for me.
I'm on OSX, but just to be sure I pressed enter. As of now it's still stalled.
The first year we were rejected we didn't have a good explanation -- there had been a change in the people running it, a lot of orgs were rejected, and there wasn't a lot of responsiveness from the (very overburdened) folks at google hq. The second year it happened we contacted them directly and they were kind enough to give some feedback. They wrote us back and told us our ideas list was not a real ideas list, but just a link to a tracker instance, where many of the links didn't provide solid ideas. The current team running GSoC values the ideas page as the most important part of an application. So while we didn't have a great answer the first time around, we got a much clearer answer the second time -- and it was "collect a really good ideas page!"
And if I remember correctly it doesn't really hang. It just freezes the display so you can select stuff. I think the process still works in the background.
I understand that `&lt;*&gt;` could be parallel according to this [Haxl talk](https://youtu.be/sT6VJkkhy0o?t=16m51s)
If the intervals need to be ordered, it seems that you can't make the interval set a Functor, as the mapping function could screw the invariants.
Worth 10000000 times more than this rubbish. 
I already can have any type of literals in AST, and have the interpreter. It seems tricky to get out from the evaluation of nonterminating terms, but I'll try. Thank you!
I would be very supportive of the idea of having a slot writing documentation for `base`, `containers`, etc. Unfortunately, I don't think this is allowed by the GSoC guidelines. That being said, regardless of whether or not we get accepted, we might be able to find some more sponsors to fund additional slots.
https://intermediatehaskell.com/ perhaps? It's still WIP but it says 'the beginning of 2018'
Notionally, yes. Sure, a better story for constraints would be great to have. I think everybody can get behind that idea. Unfortunately, at this point it seems like that is all they can do. I just don't happen to see the makings of a concrete proposal here. Given a concrete proposal or a spike solution implementing it in a toy language, holes can be punched in it, lessons can be learned, consequences can be considered. That's a sort of thing that takes time. I say this mostly to level set expectations. By all means, sketch how it could work, get others to help shave off round edges, workshop it for a while! I'm just rather dubious think you're going to get all of those issues resolved to a sharp enough point in one thread that it'd make a compelling enough case for GHC to abandon everything else and completely change around the internals of all classes / data types in one go.
Hmm, I wonder if it would make sense to have a variant of Functor which requires the function to be monotonous? Maybe in a dependently-typed language in which they precondition can be verified.
This was rather straightforward, I got what I expected.
One thing you can do is generate non-recursive terms (e.g terms that could be typed by STLC); there's a paper discussing how to do it that I can't find right now. You can also generate applications between a fixed small set of combinators. The property you want is something like "operational equivalence" and the easiest way to test it is to apply the pair of terms to a bunch of different arguments and reduce the result; it should reduce to the same thing.
Try using high verbosity flags. Does cabal update work on your system? Iirc this does basically the same thing 
Hi total haskell beginner here: What does the pattern in a function for an array look like ? For example: I simply want to add +1 to the first element in my array a = array (1,10) ((1,1) : [(i,( i * 2)) | i &lt;- [2..10]]). My first thought was: arraytest :: Array (Int,Int) Int -&gt; Array (Int,Int) Int arraytest (array (mn,mx) (a,b):xs) = (array (mn,mx) (a,b+1):xs) I hope you understand my problem :)
[duplicate](https://www.reddit.com/r/haskell/comments/7ko31f/humble_book_bundle_be_a_coder_presented_by_no/)
For comparison, see the standard [ranged sets](https://hackage.haskell.org/package/Ranged-sets) library. At one time it was even a candidate for inclusion in base.
Thanks a lot! 
I am reading this (and upvoting) as a call for papers. It is something that will take time, and maybe even a new language. It certainly won't get solved here in Reddit, but it is always great to get some attention to the largest Haskell weaknesses.
Thanks! A few notes and requests about these points: (1) and (2) - Can you (or someone) please post to links where someone who has not been following these developments closely enough can find all these things defined and get up to speed? For me - just reference-style, not tutorial-style. But other readers might also appreciate tutorials. Thanks. (3) This sounds like something Richard is almost certainly already looking at as part of his DH work. Or even if not, he is almost certainly about to make changes to GHC that will pull the rug out from anything you propose if you don't consult with him first. Possibly also for (1) and (2). So it would be a great idea to make sure he is in the loop here. (4) The linked classic post of /u/Tekmo is not the only way that classes and ADTs are closely related. We can think of a class as an "extensible ADT" where each constructor of the ADT is unary, and where each class instance corresponds to a constructor of the ADT. In place of a class constraint, you provide a constructor as witness. Methods are functions that pattern-match the constructors. (5) A huge amount of work was already done on this over a period of years, and then it fizzled out. It would be worthwhile to see why, and to compare that with where we are now. Here is a [summary](https://wiki.haskell.org/Comparing_class_alias_proposals).
 iterate show "a" !! 15
https://www.youtube.com/watch?v=218iXiKhKlg ;)
 take 15 . map length $ iterate show "a" take 15 . map (maximum . map length . group) $ iterate show "a"
Not sure why you have to be hostile. Different content works for different people. If Haskell requires wide adoption, there needs to be contents that explain same thing in different ways. So that more people can find stuff that works for them. It does not help to discourage/attack people who are trying to add to documentation. It is funny how to communities response to poor documentation is "Please contribute". And is this the reaction that one should expect if their contribution turns out to be a little out of the comfort zone of a few? I think things like these are valuable (as long as it does not contain stuff that is completely wrong). /ubrogrammer2018 appreciate this work. I find this really valuable and helpful. 
I'm pretty sure higher-rank types are never inferred, but I may be mistaken.
I would definitely recommend using stack, specially if you are starting to learn Haskell. Unfortunately ghc-mod will not work for the time being, until it is updated to work with the newer compiler.
Every time a new version of the compiler comes out, it takes a bit of time for all the tools and libraries to adapt. If you are excited about the new GHC 8.2 features, one good way to help making it a viable choice is to roll up your sleeves and send a patch when you encounter a tools or library which doesn't support it yet. It's usually not too hard, just bumping up a few version bounds here and there, and perhaps fixing a few type errors.
`cabal`'s dependency hell is basically a thing of the past now it has sandboxes and more recently `cabal new-build`.
It appears not to be too simple in case of `ghc-mod` - at least that's the impression I got from the discussions in the GitHub pull requests and the comment I linked in my posting. I'd have to roll up my sleeves pretty high since I have no knowledge of the `ghc-mod` codebase (yet) ;)
It's hard to give concrete advice without knowing the details of your product and organization. My general advice is to give them glamorous work important to the business (even if means taking a hit to the delivery schedule to train them) instead of having them work on the leftover tasks that nobody else wants to do. That improves the attractiveness of their resume to future employers.
This is **the** main reason why I was ecstatic when I finally found out about `intero` -- `ghc-mod` breaks regularly whenever you change your global GHC compiler version, due to (IIRC) `haskell-src-exts` being incompatible with the latest GHC, and lagging behind for significant periods of time. It's not a `stack` or `cabal` issue. It's your IntelliJ plugin and the fact that it's built upon `ghc-mod`. It has nothing to do with your build system. I use `stack`, and edit using Spacemacs with the `intero` plugin. I recently updated my Stackage LTS version to `lts-10.0`, ran `stack install intero` to get the latest version, and my editor didn't break. 
It appears your problem is that you think the array is mutable. Values are immutable by default. There is a different type and set of operations for mutable arrays. See [MArray](http://hackage.haskell.org/package/array-0.5.2.0/docs/Data-Array-MArray.html) and certainly the [writeArray](http://hackage.haskell.org/package/array-0.5.2.0/docs/Data-Array-MArray.html#g:4) function.
Consider using something like `dante` or `ghcid`, which doesn't use ghc as a library and is less likely to fail with newer ghc releases.
&gt;alongside this issue the workflow for GHCJS and stack is far from optimal After moving to nix and reflex-platform I had a far easier time building ghcjs projects on both nixos and macos. 
I wanted to play around with VSCode and `intero` too, but when I tried `stack install intero`, I got this: ``` me@Sh4pe:~/devel/my-awesome-project % stack install intero intero-0.1.24: configure intero-0.1.24: build ... Could not find module ‘GHCi.ObjLink’ Use -v to see a list of the files searched for. | 47 | import GHCi.ObjLink as ObjLink | ^^^ ``` Didn't dig into it yet though. Now I'm trying at VSCode with [haskell-ide-engine](https://github.com/haskell/haskell-ide-engine).
Yea, perhaps, although I'm not sure if they will assume knowledge of the concepts already explained in haskellbook.com.
You could try the [wikibooks pages](https://en.wikibooks.org/wiki/Haskell) - back in the day I felt those were great.
As of 3 days ago you can actually build a `ghc-mod` from sources that supports GHC 8.2.x, due to the awesome work in the [#911](https://github.com/DanielG/ghc-mod/pull/911) and [#922](https://github.com/DanielG/ghc-mod/pull/922) PRs. You can either use `stack` to build it ([instructions](https://github.com/DanielG/ghc-mod/pull/922#issuecomment-353896120)), or you can do something along these longs to build using `cabal`: git clone https://github.com/DanielG/ghc-mod.git git clone https://github.com/DanielG/cabal-helper.git cd ghc-mod git fetch origin pull/911/head:pr911 git fetch origin pull/922/head:pr922 git checkout pr911 git merge pr922 touch cabal.project # see below for contents of cabal.project cabal new-build And the contents of `cabal.project` to tell `cabal` to use the local copy of `cabal-helper` you just cloned: packages: . ../cabal-helper The path to the executables will be something like `dist-newstyle/build/x86_64-linux/ghc-8.2.2/ghc-mod-5.8.0.0/build/ghc-mod/ghc-mod`. You need a pretty recent `cabal-install` (`&gt;= 2`). Also, as far as I know unfortunately `ghc-mod` doesn't use any of the `new-*` cabal commands, so you'd probably want to use sandboxes or even better, `nix`.
&gt; some people have a lot of crypto lying around. Case and point: [MAPS receives almost 60 Bitcoins from lone philanthropist](https://www.maps.org/pineapplefund). Transaction fees are less relevant since you only have to worry about them when spending what you have been given, as a single transaction -- if the givers don't mind the fees associated with donating coins to you, then it's not really your concern. 
More like an extensible GADT, with the additional constraint that the types of different constructors must fail to unify.
Right - but we are already in the unsafe territory, since there is no checking, that the supplied `Range` is valid, e.g. `(5, 2)` would not be valid, yet the type system does not help us here. Dependent types perhaps? But if we can live with this lack of safety, what would the `Functor` look like?
Well, this library does not define any of the typeclass instances that I am seeking :(
Hitting that url directly I seem to get an error at the moment? https://s3.amazonaws.com/hackage.fpcomplete.com/ &lt;Code&gt;AccessDenied&lt;/Code&gt; &lt;Message&gt;Access Denied&lt;/Message&gt; Perhaps that mirror is down?
So here is the `Num` typeclass: class Num a where (+) :: a -&gt; a -&gt; a (*) :: a -&gt; a -&gt; a (-) :: a -&gt; a -&gt; a negate :: a -&gt; a abs :: a -&gt; a signum :: a -&gt; a fromInteger :: Integer -&gt; a I can see what `+` and `-` could be, but what is a multiplication? The same goes for negation - my `RangeSet` operates requires `Eq`, `Ord` and `Enum` instance for the type it holds, but not necessarily a `Bounded` type, therefore it is not clear what would negation do. But perhaps a `Monoid` or a `Semigroup` instances could make sense (inspired by your mention of algebra).
IntelliJ-Haskell does not use `ghc-mod`. It uses `intero` but unfortunately LTS 10.0 does not contain the latest version of `intero` which is compatible with GHC 8.2.2
It’s refreshing to see similar experiences to my own show up in posts. I think regular practioners appreciate discussion of regular stuff. I find the type theory intriguing, but often over my head. Having some down to earth content in the mix reminds me and other visitors that Haskell can be and is being used to great effect for productive day to day work :)
HIE uses ghcmod.
The basic construction functions will need to be careful about checking the invariant but after that the type system will ensure that the invariant is kept. If the only way to implement fmap is to mess with the representation of an interval then that implementation also has to make sure it keeps the invariants. People seem too eager to suggest that our current type system is inadequate for something and that 'dependent types' would fix that. 
Let's suppose that we have a `Functor` instance, that operates on the `Range a` components and not on the `a` points themselves. Let `fn (Range (x,y) = Range (y, x)`, then type system would not stop me doing the following: `fmap fn rangeset`. Where am I making a mistake?
S3 can be slow sometimes. Try connect to the internet through a VPN if you can. Or go to an internet cafe. Or anything that changes your routing path towards S3.
Regardless, HIE still works with lts-10.0 for vscode. Personal experience. Maybe HIE uses a branch of ghc-mod, or uses it in a special way. So, if IDE is a problem for you under stack lts-10.0 and you don't want to be limited to vim or *macs, I recommend vscode will HIE.
&gt; People can't agree even on the basic set of functions. Should people have to? It seems quite likely that the appropriate "basic set of functions" differs substantially by domain.
`System.Random` from `random` package is okayish. It's fast _enough_ and _random_ enough. But I wouldn't use this package for something serious (like, implementing randomization algorithms in cryptocurrencies with reliable sources of randomness). Use `cryptonite` package. It's the best available option. And it's **really good**. * http://hackage.haskell.org/package/cryptonite Though, API is not very good.... This library doesn't even contain function to generate random number. For now you need to copy-paste implementation manually. I've created issue about this: * https://github.com/haskell-crypto/cryptonite/issues/209
I wrote up multiplication in the link readme, with Range -0.5 0.5 being the multiplicative unit. I was performing a projection operation - changing the size of a chart - a lot and it boiled down to something that obeyed the multiplicative laws. I think all the instances you list make sense. 
If you make `RangeSet` a functor, `fmap` has the type `(a -&gt; b) -&gt; RangeSet a -&gt; RangeSet b`. It takes an `a -&gt; b`, not a `Range a -&gt; Range b`; and you can't in general turn the former into the latter. You can't even merge two overlapping `Range a` values without an `Ord a` instance. That is actually fairly simple. Just don't export the `Range` constructor, and instead export an `mkRange :: a -&gt; a -&gt; Range a` function that ensures the range is correct.
I believe you misunderstood the question. It seems to me like they're asking for the equivalent of `f (x:xs) = (x + 1) : xs`. Unfortunately, there is no equivalent of this for `array`. You'll have to use a function from the `Data.Array` module instead.
In haskell, I think it's easier to throw out the constraints in order to make Functors etc instances, and then deal with the necessities such as ordering in specific functionality. As an example, allow `Range (5,2)` to be a valid Range (and I think of this as a negative range), and define `abs (Range (x,y)) = bool (Range (y,x)) (Range (x,y)) (x&lt;=y)` for when you need a positive Range.
Thanks for keeping the docs alive, but I think you should make it more clear that this is what you are doing. Without the smallprint clarification at the bottom on your page, I found the term "book" a bit misleading, allthough it is not technically wrong.
Hi, I believe this is quite a commonly asked question and in fact, I found many questions asked (and answered) about this already on Stack Overflow or Reddit. However, I just don't understand the explanations given online of why foldr can work with infinite lists but foldl cannot. This link here seems to explain it: https://stackoverflow.com/questions/3082324/foldl-versus-foldr-behavior-with-infinite-lists?rq=1 but I can't understand his explanation at all, in particular when he makes these statements: "Because foldl is backwards each application of f is added to the outside of the result ... This means that to compute any part of the result, Haskell first iterates through the entire list constructing an expression of nested function applications, then evaluates the outermost function" (Doesn't foldr have to iterate through the whole list to generate the result expression also?) and "foldr can transform one lazy recursive data structure into another." Anyone have a clearer and easier explanation?
Thanks for the great alternative and instructions!
I am personally using react-hs for my front end framework. I'm open to the idea of using nix, but would rather not deal with another learning curve or much more time investment. It's a simple project with a small number of dependencies that I just want to work already.
It doesn't matter. Are you on an embedded system that you need to aggressively conserve space? A mediocre standard is still better than no standard at all, since as soon as you have two competing basic libraries you have separated your library ecosystem in half randomly in one fell swoop. Each possible package can act as a dependency for other packages, so any time you have two incompatible packages doing roughly the same things, you have cleaved you dependencies in half for no reason at all. 
The StdGen typeclass is _fundamentally_ slower than it needs to be, and the Random typeclass attempts to lean towards uniform results but doesn't actually precisely ensure them (as far as i understand the math). Obviously you can't get uniform float results because of how floats work and all, but you could at least get uniform integral results. So if you want fast, you want something else. If you want high quality, you want something else. The only thing that `random` has going for it is that it's what quickcheck uses, and quickcheck is awesome.
&gt; To quote a type, add two single quotes in the front of it: `MyRecord` → `''Record`. (I guess this is because quoting of types with one single quote is already used in `DataKinds`.) I think this is a typo; it should be `''MyRecord`. I also think that TH existed before `DataKinds`, and that the real reason is to support the distinct namespaces between values and types. Consider: data Identity x = Identity x I may want to refer to `'Identity` (the name of the constructor) or `''Identity` (the name of the type).
If you need specific distributions, mwc-probability is the best option I know: https://hackage.haskell.org/package/mwc-probability .Also a very friendly API and good documentation.
&gt; The StdGen typeclass is fundamentally slower than it needs to be ELI5?
As I understand it, cryptonite gives crypto-suitable randomness, which is very random (it is believed) but not necessarily as fast as one can get if you're ok with non-crypto-quality randomness, e.g. for monte-carlo. A few good choices to investigate might be pcg-random, tf-random, and mwc-random
Sure, i wrote up the whole rant one time for a lib that i never ended up publishing. https://github.com/Lokathor/pseudorandom-hs/blob/master/Reasoning.md
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [Lokathor/pseudorandom-hs/.../**Reasoning.md** (master → 1b5d2bf)](https://github.com/Lokathor/pseudorandom-hs/blob/1b5d2bf52c880d3d6926ebf60fe3ef4be1f50977/Reasoning.md) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
DONT use it :) As curren maintainer I’ll be getting a random 1.3 out in the next few days (long over due , by a year or thee) There’s a lot of gotchas in current random, and in many of their current alternatives. But it also depends on what your goals are in terms of different measures of quality. What do you intend to do? The better we understand your problem the more we can help! (And randomness and it’s applications is a rich deep topic )
OK - submit a PR :)
Cryptographic randomness is kinda orthogonal to simulation / sampling randomness. We should better understand what the original poster wants first! 
There’s some issues with random 1.0/1.1, but what could be faster than a state passing generator? (At least if the prng fits in registers!)
There are at least - tf-random - mwc-random - splitmix I'd say, all are good enough. Benchmark speed (and randomess if you can) for your application
Thanks for such clarifications!
As an aside, folks saying "the salary is okay" would be better served by giving a currency dollar and a % size of the bracket and letting folks decide on their own.
See my reply to the other reply, where i linked to my github rant :P
Yes, you would need GADTs for when the type is the return type of a method, and GADTs with your constraint for when the type appears multiple types in the signature of a method. But apart from an exact match, it is interesting that classes do seem to be analogous to some kind of extensible ADT.
Reflex-platform's [project](https://github.com/reflex-frp/reflex-platform/blob/develop/docs/project-development.md) format makes it reasonably simple. I've got [a skeleton](https://github.com/ElvishJerricco/reflex-project-skeleton) showing basic usage of it.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [reflex-frp/reflex-platform/.../**project-development.md** (develop → feaf80e)](https://github.com/reflex-frp/reflex-platform/blob/feaf80e90c547a2c9d407e8e38d0e7309342b5f1/docs/project-development.md) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply drsnqmy.)^.
I'm interested in what you'll be doing for 1.3, and I'm also interested in if you think it might ever be good to move to a breaking 2.0 version.
&gt; *I have ran into an issue where it would appear that the latest intero surreptitiously enables deferred type errors and reports type errors as warnings to emacs. I'm still trying to investigate what, exactly, might have caused this. But otherwise my editor experience is overall not broken. This is a small infelicity that I'll fix when I get back to my computer. I think this should only show up on GHC &lt;8, because the Intero Emacs mode now depends on helpful metadata included in error messages in 8 onwards. It's not a showstopping bug and it should only apply to old GHCs but I'll fix it soon. Explanation here: https://github.com/commercialhaskell/intero/issues/476#issuecomment-348467874
&gt; I wanted to play around with VSCode and intero too, but when I tried stack install intero, I got a compilation error. It depends when you tried it, but latest uploaded Intero should work on GHC 8.2. If it doesn't then you should report that.
Honestly, I don't think the idea of generators having different ranges is the worst -- rather, I think the problem here is in an insufficiently powerful `Random` typeclass. A good modern V2 api would arguably use type-level reflection stuff to carry the range information statically... On the other hand, you're probably right that just doing everything as Word32 is the "standard standard" anyway, and anything else is overkill :-)
It's the best of both worlds! Word32 does carry static range information :P
Type equality constraints? structure F : FOO structure B : BAR where type F.foo = B.bar Coherence? Just bundle associated modules together. That's what hierarchical modules are for. Higher-kinded types? Okay, you got me. 
While your mileage may vary, I am a very happy `cabal new-build` user. I use Spacemac's `flycheck-ghc` support, which works wonderfully with `new-build`'s [GHC environment](https://downloads.haskell.org/~ghc/master/users-guide//packages.html#package-environments) support.
&gt; What do you intend to do? I mostly had in mind pseudo-random numbers of particular given probability distributions. (From what I understand, it's common practice with Monte Carlo simulations to generate such numbers beforehand and store them so they can be reused over and over again.) But then I'm also interested in knowing the state-of-the-art in cryptographically secure random number generators.
Lots of folks here have provided much better examples than I can give. I saw this post rather late and decided that for my own sake ([I keep telling myself to get better at this kind of code](http://extradimensional.space/posts/2017-11-27-fizzbuzz-followup.html)) I'd also like to throw in with the crowd and try and explain it to you. An alternative way of thinking about this is that you are "lifting" your 3-argument list-producing function into the world of "reader" functions. This means that reader functions are Functors, and if you think about them this way then the code in question becomes a lot more like common examples of Functors like Maybe and List. We can re-interpret the entire statement one step at a time and end up with a working type and code at each step, which I will now do. Let's start by trying to break down the middle of the line: (+3) &lt;*&gt; (*2) &lt;*&gt; (/2) Each one of these functions has a type, which we'll simplify from a class constraint to a single numeric type for the sake of the discussion: Float -&gt; Float Normally we say, "*This is a function that takes an Float and provides a float).*" But we could also say, "*This is a a computation of a float value that requires a float value to be provided before it can run.*" We often call these, "Readers" in the Haskell world. So let's just, you know, make a type alias: type Reader need provide = needs -&gt; provides We can then think that functions like (+3) are actually "`Reader Float Float`s. That's pretty easy to imagine, even if it seems pointless. But what about the first term that we're fmapping? There is another way to think about how that works, but to build up intuition about algebraic effects, I think it helps in this case to actually build up the result left to right. So let's start with the first two arguments. GHCi is always a lovely friend to appeal to (especially if we explain to it our Reader type). &gt; :t (\x y z -&gt; [x,y,z]) &lt;$&gt; ((+3) :: Reader Float Float) (\x y z -&gt; [x,y,z]) &lt;$&gt; ((+3) :: Reader Float Float) :: Float -&gt; Float -&gt; Float -&gt; [Float] -- And we could rewrite this in our type alias: :: Reader Float (Float -&gt; Float -&gt; [Float]) The intuition for what's happening here that I use is that fmap is actually "lifting" your array-making 3-arg function up into the functor world of Reader, then treating it like a function. We now have 2 arguments left to apply, but we're trapped in the world of Reader where everything is predicated on receiving an argument. Finally applying all of those readers, we end up with... well... a Reader from Float to Float We continue to apply your other two arguments until we've eliminated all the contravariant bits from the functor's type (which is to say; we fill all its arguments with promises to compute a Float, given that we'll receive a float later): &gt; :t (\x y z -&gt; [x,y,z]) &lt;$&gt; ((+3) :: Reader Float Float) &lt;*&gt; (*2) &lt;*&gt; (/2) (\x y z -&gt; [x,y,z]) &lt;$&gt; ((+3) :: Reader Float Float) &lt;*&gt; (*2) &lt;*&gt; (/2) :: Float -&gt; [Float] -- And we could rewrite this in our type alias: :: Reader Float [Float] Our applicative here is using the Applicative Laws and the Functor laws to "lift" up the idea of a function into the world of 3 argument functions. Now all we've got is this "reader" that is really just `Float -&gt; [Float]` We pass it an argument and bam, it works. Now, because you're using `&lt;$&gt;` on the left hand side, what actually happens at a process level is a bit different. You're actually making the (+3) and then using fmap on the `(-&gt; a)` instance. The best way to understand what that means is to play with what happens when you use fmap on functions a bit. Fmap is really a simple and fundamental operation for functions (you have seen it in many forms), but because of the way functors in haskell are often presented as containers it's often a bit of a leap for folks. If this is still confusing, it might be worth noting that [Control.Applicative has a `liftA3` function](https://hackage.haskell.org/package/base-4.10.1.0/docs/Control-Applicative.html) that does this lifting operation, so we could write this without using without using `&lt;*&gt;`: Prelude Control.Applicative&gt; :t liftA3 (\x y z -&gt; [x,y,z]) (+3) (*2) (/2) liftA3 (\x y z -&gt; [x,y,z]) (+3) (*2) (/2) :: Fractional t =&gt; t -&gt; [t] -- We were using float so it's also :: Float -&gt; [Float] 
&gt; I use `stack`, and edit using Spacemacs with the `intero` plugin. Do you mean the (abandoned) [intero-layer](https://github.com/cydparser/spacemacs-intero), or the [haskell-layer](https://github.com/syl20bnr/spacemacs/tree/master/layers/%2Blang/haskell)? I use the `haskell-layer` as well, since I found the `ghc-mod` plugin for Vim to be too slow for my purposes (auto-completion would be done synchronously, which would mean hang-ups of several seconds if a large number of identifiers had been imported). While I am quite happy with my current set-up (stack/Spacemacs/intero), two features I kind of miss are 1. Automatic case-split on data constructors, and 2. Hlint suggestions. The latter you can get via `M-e flycheck-select-checker haskell-stack-ghc`, which is not the default (nor do I know how to make it so...). Case-splitting however appears to be `ghc-mod` only. While this is not the end of the world, I would be interested to know if other people have found some workaround?
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [syl20bnr/spacemacs/.../**haskell** (master → 4bb4cb4)](https://github.com/syl20bnr/spacemacs/tree/4bb4cb46968e5bbb98fffd480c8c822269fced4f/layers/%2Blang/haskell) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply drspcab.)^.
I wish I knew what those instances would be - that is the original question after-all.
Yes, of course, I meant if in the end we come up with something. You have some nice ideas, and there has been some interesting discussion here.
Would like a spoiler about how to solve "creating a Door with a given state that we don’t know until runtime". Does it involve `forall` by any chance? 
1.3 will be somewhat breaking, but still resemble the current api somewhat. But will have some effort at providing a easy to migrate to new apis. Ok so it’s going to be very breaking: rng algs I provide should provide the same outputs on every architecture. Also more combinators for generating useful / handy samplers and monadic dsl goodness. The rngs I provide will be easy to seed from both the system csrng sources or user inputs. 1.3 will have splitmix but updated to use the mixing constants and tweeks in jdk10 Or whatever is current over there , and there’ll also be pcg32. Splittable rngs are a tricky topic... they make sense for combining large RNG subsystems or used for testing a la quick check , but for inner loops you want your monadic interface for taking a non sampling step to be free , like in a state monad. I am really happy with my rough cut of sampling combinators for different distributions. There’s a few more I wanna / need to do, such as tail sampling of a Gaussian, etc. one fun party trick I like to do lately is show how the Gaussian samplers in R and Scipy are both massively unthreadsafe and generating a sample with a value greater than 6 or 8 ish is literally unreachable. I should get back to holiday travel packing :)
I’ve not looked at the grand parents post but there’s def a huge number of problems in the current api. The sampler / random api for userland datatypes is definitely wrong. Measurably so even :)
Good reminder that there is quite some low-level stuff going on that you should know about when doing `Handle`-based I/O. Still, I feel that this article could have expanded on a lot of important concepts, especially so since you can not assume that every Haskell programmer also has a background in C. This includes what a file pointer is in the first place, mentioning the quirks of the underlying POSIX API, and if you're really fancy how to do concurrent file I/O using pre-calculated offsets :) By the way, I believe an alternative way would've been to save the previous position and later restore it using [hGetPosn and hSetPosn](https://www.stackage.org/haddock/lts-9.11/base-4.9.1.0/System-IO.html#v:hGetPosn). This could be easier if you don't know the absolute offset at compile-time.
Unlike lists, which can share the tails, the whole array would need copied (be it an array of unboxed elements or an array of the pointers - expensive either way). I likely don't understand the intent, but if the intent is to compute a similar array with one element modified then I'd encourage /u/GedankenRevolution to find another more suitable structure or at least acknowledge the costs and how they differ from either a mutable array or immutable list.
That all sounds great. Might I ask if you plan to cut the genRange method from `StdGen` and then have outputs be specified to always need to be uniform Word32 or Word64 values? I think that would be a big improvement, and in line with all your other (exciting) proposals.
Shoot me an email next week / have a gander at my cartazio/random GitHub repo in a few more days / both! I think I’m going to do something equivalent to what you’re asking, but slightly different in details. 
Yeah the basic samples not being in a fixed portable size does make a mess of things unless you do some cpp 
This might be a good place to mention that I'm looking for a summary of high-level, no expertise required cryptography libraries in Haskell. [cryptonite](https://github.com/haskell-crypto/cryptonite) gets mentioned a lot, but is pretty explicit about being lower level than I'm looking for: &gt; If you have no idea what you're doing, please do not use this directly. Instead, rely on higher level protocols or implementations. I'm looking for a list of common tasks, along with a library or function to use for each. Something like: + Generate random bytes: [entropy](https://hackage.haskell.org/package/entropy-0.3.8/docs/System-Entropy.html) + Hash user passwords: `foo` + Hash data (blake2b / sha-256): `bar` / `baz` + etc. I don't actually even know that `entropy` is good. It *looks* good, is used by `uuid`, and has such a small API that I don't think I can shoot myself in the foot with it, but those are pretty superficial things to go on. So I would love to hear what more proficient cryptography people recommend.
Absolutely will do
I typed out a lengthy and somewhat incorrect reply, entered `foldl (\_ _ -&gt; "works") "" [1..]` into GHCi, and had to restart. In the meantime, I figured out where I went wrong. There are two important things about evaluating expressions in haskell: 1. Nothing is evaluated unless its value is needed by something. This is why `length [undefined, undefined]` just returns `2`, instead of crashing: `length` doesn't look at the values of the list, only its structure. 2. It starts at the *outer*most function application: first, the function is evaluated (if necessary); then, control passes to the function. The function may or may not evaluate its arguments, depending on if their values are needed. This can be shown using `bool` (from `Data.Bool`): Prelude Data.Bool&gt; bool undefined "yay!" True "yay!" Prelude Data.Bool&gt; bool undefined "yay!" False "***Exception: Prelude.undefined We are now ready to explore why `foldr` can work on infinite lists. foldr f z [1..] turns into something like f 1 _thunk2 `_thunk2` is a special kind of value that will replace itself with `f 2 _thunk3` when `f` inspects it. I'm sure you can figure out what `_thunk3` is. If you were to expand all the thunks, you'd end up with something like f 1 (f 2 (f 3 (f 4 ... ))) So, `foldr` results in an infinite tower of `f` applications, which is built up from the bottom. This works fine as long as `f` decides to stop eventually. Analogy: `foldr` builds a staircase upwards that `f` can walk up. If `f` decides to stop climbing, `foldr` will stop building. Now let's look at `foldl`. foldl f z [1..] will attempt to build an infinite tower of `f` as well, like so: 1. first, build `f z 1` 2. then, wrap another layer of `f` around it: `f (f z 1) 2` 3. keep wrapping more layers of `f` around the expression, until you've exhausted all the elements of the input list 4. then, start evaluating (from the outside in, of course). Step 3 will never finish, since the list is infinite. It cannot be cut short either: evaluation starts on the outside, so we must reach the outermost layer before we can do anything. Going back to our staircase analogy: `foldl` builds a staircase upwards that `f` wants to walk down on. `f` can't start doing that until the staircase is completely built, so the construction process can't stop early.
One idea is to improve the [TensorFlow Haskell bindings](https://github.com/tensorflow/haskell); this could appeal to those interested in machine learning as well.
check out `toSing`, `SomeSing`, and `withSomeSing` :)
For statistical sampling, use MWC (mwc-random). Cryptography-grade PRNG are an overkill for Monte Carlo / too slow for no benefit.
BTW, instead of: &gt; data Expr = LitExpr SourcePos Value -- a literal value &gt; | AppExpr SourcePos Value -- apply a function to a value &gt; | VarExpr SourcePos Name -- get a variable's value &gt; | LetExpr SourcePos Name Expr Expr -- let-bind an expression why not: &gt; data Expr subexpr = LitExpr Value -- a literal value &gt; | AppExpr Value -- apply a function to a value &gt; | VarExpr Name -- get a variable's value &gt; | LetExpr Name subexpr subexpr -- let-bind an expression &gt; &gt; data ExprPos = ExprPos SourcePos (Expr ExprPos)
How is this different from using a custom base image for `stack [--docker] image container`? Note that it's different from `stack --docker build`, although the default image is the same fat fpco/stack-build. I usually create a Dockerfile for base image (lower half of your Dockerfile) and put it in Stack configuration to use when producing deployables.
The username checks out.
May be try out raaz. http://hackage.haskell.org/package/raaz For its randomness interface see (Warning not yet multi-thread safe without some added gymnastics) http://hackage.haskell.org/package/raaz-0.2.0/docs/Raaz-Random.html Password hashing a la argon is currently not present but is planned. But we have hashing. http://hackage.haskell.org/package/raaz-0.2.0/docs/Raaz-Hash.html 
Thanks, you're most certainly right. I have updated the text.
So continuing with some of the problems I was having last week, still on the same project I'm trying to show that a Cofree (Either b) a of length n (where length for Cofree would be written as length (x :&lt; Left y) = 1 length (x :&lt; Right y) = 1 + length y ) is equivalent to a list of length n of type a tupled with a value of type b, forall a, b, and finite n. To do this, I embedded the length in the type (using Nats), so for lists this is just Vec, for Cofree I needed something a little more bespoke, which is indexed functorially as well (so 3 :&lt;&lt; ILeft 'x' has to be Cofree ('S 'Z) (IEitherFlip Char) Int (IEitherFlip is an IEither that flips the b and the n, so that forall a. IEitherFlip a :: Nat -&gt; * -&gt; * (since the kind sig in ICofree should look like data ICofree (n :: Nat) (f :: Nat -&gt; * -&gt; *) (a :: *) where... ) data Nat = Z | S Nat type family Plus (m :: Nat) (n :: Nat) :: Nat type instance Plus m Z = m type instance Plus m (S n) = S (Plus m n) data Vec (n :: Nat) a where VNil :: Vec 'Z a VCons :: a -&gt; Vec n a -&gt; Vec ('S n) a data ICofree (n :: Nat) f a where (:&lt;&lt;) :: a -&gt; f n (ICofree n f a) -&gt; ICofree ('S n) f a data IEither (n :: Nat) a b where ILeft :: a -&gt; IEither Z a b IRight :: b -&gt; IEither (S n) a b newtype IEitherFlip b n a= IEitherFlip { getEither :: IEither n b a} newtype PairVec n b a = PairVec (Vec n a, b) data Iso a b = Iso (a -&gt; b) (b -&gt; a) eitherCofreeVec = Iso toPairVec toCofreeEither where toPairVec :: ICofree n (IEitherFlip b) a -&gt; PairVec n b a toPairVec (a :&lt;&lt; (IEitherFlip (ILeft b))) = PairVec (VCons a VNil, b) toPairVec (a :&lt;&lt; (IEitherFlip (IRight b))) = toPairVec' (VCons a VNil) b toPairVec' :: Vec m a -&gt; ICofree n (IEitherFlip b) a -&gt; PairVec (Plus m n) b a toPairVec' xs (x :&lt;&lt; (IEitherFlip (ILeft y))) = PairVec (VCons x xs, y) The full error: Could not deduce: Plus ('S 'Z) n3 ~ 'S n3 from the context: n1 ~ 'S n2 bound by a pattern with constructor: :&lt;&lt; :: forall (f :: Nat -&gt; * -&gt; *) a (n :: Nat). a -&gt; f n (ICofree n f a) -&gt; ICofree ('S n) f a, in an equation for `toPairVec' at C:\Users\Acer\Desktop\iso.hs:84:14-43 or from: n2 ~ 'S n3 bound by a pattern with constructor: IRight :: forall a b (n :: Nat). b -&gt; IEither ('S n) a b, in an equation for `toPairVec' at C:\Users\Acer\Desktop\iso.hs:84:34-41 Expected type: PairVec n1 b1 a1 Actual type: PairVec (Plus ('S 'Z) n2) b1 a1 * In the expression: toPairVec' (VCons a VNil) b In an equation for `toPairVec': toPairVec (a :&lt;&lt; (IEitherFlip (IRight b))) = toPairVec' (VCons a VNil) b In an equation for `eitherCofreeVec': eitherCofreeVec = Iso toPairVec toCofreeEither where toPairVec :: ICofree n (IEitherFlip b) a -&gt; PairVec n b a toPairVec (a :&lt;&lt; (IEitherFlip (ILeft b))) = PairVec (VCons a VNil, b) toPairVec (a :&lt;&lt; (IEitherFlip (IRight b))) = toPairVec' (VCons a VNil) b toPairVec' :: Vec m a -&gt; ICofree n (IEitherFlip b) a -&gt; PairVec (Plus m n) b a toPairVec' xs (x :&lt;&lt; (IEitherFlip (ILeft y))) = PairVec (VCons x xs, y) .... I'm not entirely sure what it all means, but it seems to be saying that it can't prove that forall n. Plus (S Z) n == S n, which seems ridiculous to me. It also seems that the sig should be :: ICofree n (IEitherFlip b) a -&gt; PairVec (S n) b a, but I tried that to no avail 
This is probably because you have `-Wall` or similar configured either for your project or for GHCi globally.
As far as I remember it's llvm only and instructions available are very limited
I read this title as "Anime News Network is switching to Haskell". I was genuinely shocked until I read the rest of the title :)))
Thanks for the feedback! I'll look into expanding the post (I'll probably have to relearn some concepts that are hidden in my brain somewhere)
I did not know about `th-abstration`. It looks good, I mentioned it in the conclusion.
No! There are a few things to consider: do you want `split`? Then you can use `tf-random` which is used by QuickCheck or you can use `splitmix`. `split` does *not* work in System.Random. If you want an R-like experience then you can use random-fu which allows you to sample from most distributions and also provides CDFs and PDFs (also in log space). The actual randomness is provided by Mersenne Twister (MT) or MWC. It's easy enough to add other generators if you want them. If you just want random numbers then there are the venerable MWC and MT packages. MWC gives some samplers. Monadic interfaces are available.
https://liberapay.com
That sounds good -- do you have anything specific in mind? Or should I ask on their mailing list?
yes
Ok. That's what confuse me. You want to do beginner "tier" too. So there should be minimal curriculum that you would want to cover, and it should be orthogonal to CFP, right?
I'm unsure why, the CFP is also for the beginner track. It's not a University course with a set curriculum we want to cover, but the things we have in line for beginners are also pretty unique and awesome.
Thanks for the clear explanation! Your tower analogy resonated well with me. So if I want to evaluate the first finite n elements of an infinite list, foldr will produce something like this: f 1 .. n thunk_n wherein the first finite n elements can be "functioned" due to outside-in evaluation but for foldl, due to the same outside-in evaluation, it necessarily generates more layers of f which can never end. I guess a large part of the confusion for me was not knowing that evaluation is done outside-in since it is a lot more intuitive to think of evaluation as being done from where the first element of the list is, followed by the second and so forth. 
As someone who's done a lot of MCMC in the past for Bayesian models, it's very unusual to store the basic uniformly distributed random numbers from your RNG, since you can just recreate that sequence by re-running with the original seed. I think what you're thinking of is not the random numbers from the RNG, but the _random samples_ drawn from your probability distribution _using_ those random number from the RNG. You can reduce those instantly if you're looking for an expected value (i.e. the mean of some function of X, where X has some distribution), or you can keep them if you want to re-use them for expected values, variances etc. So in general keep the random seed, discard the random numbers, and _maybe_ keep the random samples.
You can call me on 6859 once the GSM network is up. There is also https://events.ccc.de/congress/2017/wiki/index.php/Assembly:Curry_Club_Augsburg and https://events.ccc.de/congress/2017/wiki/index.php/Assembly:NixOS
(Disclaimer author of raaz here) For cryptographic randomness consider the raaz library The interface is http://hackage.haskell.org/package/raaz-0.2.0/docs/Raaz-Random.html 1. High level and the user does not need to worry about details like seeding/reseeding, entropy management etc 2. Uses the best entropy source for seeding available for the given platform 3. Follows the current best design (the same design used in OpenBSD system) 4. Blazingly fast (Can produce random bytes at about 6Gbps on a resonable machine)
What is new in `new-build` regarding the `GHC` support? Didn't `cabal` for quite a time support different `GHC` versions?
I'm glad I could help!
I'm unaffiliated with any party. Found on /r/functionalprogramming, and after a little bit of searching I haven't found it on /r/haskell, so I'm reposting url.
Maybe ghci could help you with types, if your editor have mode/plugin that allows to move code both ways (file to ghci back to file).
Wont this implementation run into expression problem? Longer living event sourcing will have to deal with different event versions. How could that be handled without growing significantly in size? (Also how one would serialize/deseriazlize versions of such events?)
You can install ghc-mod globally and then run Atom via stack like `stack exec atom -- .` This should set up the environment properly. It works like that for me, anyways.
We can't guarantee the topics just yet unfortunately, we will publish a full agenda after CFP ends though. Yes, there are time and quantity limits on the early bird tickets.
Well, what about quipper? https://www.mathstat.dal.ca/~selinger/quipper/
I use nix to manage my haskell environment. I have ghc-mod installed globally. It works fine on directories which have a cabal file, but fails on single haskell files which import modules from packages (in a directory without a cabal file). Example: &gt; ghc-mod check Main.hs Main.hs:5:1:Failed to load interface for ‘Turtle’Use -v to see a list of the files searched for. Main.hs:6:1:Failed to load interface for ‘Data.Text’Perhaps you meant Data.Set (from containers-0.5.7.1)Use -v to see a list of the files searched for. Main.hs:7:1:Failed to load interface for ‘Control.Foldl’Use -v to see a list of the files searched for. Main.hs:9:1:Failed to load interface for ‘Filesystem.Path’Use -v to see a list of the files searched for. &gt; ghc-pkg describe turtle name: turtle version: 1.3.2 ghc can compile Main.hs without issue. A more complicated issue, which is probably going to occur in any tool is that the shebang makes it an invalid haskell file: &gt; ghc-mod check weekday.1d.sh target ‘/home/miguel/.config/argos/weekday.1d.sh’ is not a module name or a source file at the start of that file I have #! /usr/bin/env nix-shell #! nix-shell -i runghc -p haskell.packages.ghc7103.ghc haskell.packages.ghc7103.time #! nix-shell -I nixpkgs=/home/miguel/.nixpkgs/nixpkgs-channels-4aab5c57987af2dbf8b93fe30d5859a4a56d1aca 
https://www.humblebundle.com/books/be-a-coder-books Referral free link
https://www.humblebundle.com/books/be-a-coder-books Referral free link
 take 15 . map (length . filter (=='"')) $ iterate show "" take 15 $ [0,2..] take 15 . map (length . filter (=='\\')) $ iterate show "" take 15 $ scanl (\t i -&gt; 2*t + i) 0 [0,2..]
what is cabal new-build i'm looking on the doc site and don't see any reference to it?
alternately, just abandon `ghcid` and create an autocommand to rerun `:make` every time you write the file: :au BufWritePost *.hs make build And use the quickfix buffer to display the errors instead of `tmux`
The `new-*` commands collectively provide Nix-style local builds, one of their side effects being eliminating the need for cabal sandboxes. In fact I've been using cabal `HEAD` (built from `master`) for my personal projects since the end of summer and have [mostly] migrated away from stack. Documentation is available on [Nix-style Local Builds](http://cabal.readthedocs.io/en/latest/nix-local-build-overview.html), and /u/ezyang had written a [few](http://blog.ezyang.com/2016/05/announcing-cabal-new-build-nix-style-local-builds/) blog [posts](http://blog.ezyang.com/2016/08/cabal-new-build-is-a-package-manager/) on it last year. If you decide to give it a shot, I recommend you use the most recent version of `cabal-install` released, or perhaps even better, compile from latest sources.
ok i see the problem here i was trying to search on the cabal doc site for new-build and new- and it didn't seem to find any of it..maybe the search is broke, thanks for the reference to the docs that i was looking for and thanks for the suggestions I'll check those resources out
Monads are things that implement the monad typeclass; you can look at a types documentation, and if it has a monad instance, then it is a monad. Not all things are. The answer for why things are monad's is a bit more complex. If you look at the typeclass, 2 functions that need to be implemented for it are 'return' and &gt;&gt;= (bind). do-notation desugars into nested bind's. I recommend looking at the implementation of monad for a given type to see what it's doing, that may give you some insight as to why it exists.
I tried to give the important details above. There is "important work" with respect to features that mostly involves knowing the data model well, making small changes to it, and then updating a set of http endpoints to modify/retrieve that data. It would involve touching a lot of Haskell files in simple ways and also digressing to learn template haskell and a few abstractions used well enough to be able to understand the code. It would show that someone can handle responsibility of working within a simple, larger codebase and help move a product forward. But it won't make someone a Haskell black belt for tough interviews. I could imagine such experience would be really valuable when interviewing for a traditional web application development job in Python or Ruby. This would give someone some exposure to Haskell basics, and probably enable someone to land an Elm, Purescript, Scala, F#, or Elixir entry level job. Then there is more involved Haskell work, that falls more into refactoring or green field experiments. I am leaning towards mostly tasks like this (if I can get approval for such a role), to get someone a little sharper for interviews. This would involve rewriting large portions of code, coming up with smooth incremental paths for converting from homegrown libraries to standard libraries, which might require reading the source of the homegrown libraries in depth, as well as architecting a bit. It could also involve diving into c FFI's for media files or building out parsers or streaming servers. This could possibly enable someone to land a local, entry level Haskell job, if someone already had a background in Scala or good engineering experience and they exhibited potential and passion for Haskell. The problem is that there might be between 0-2 entry level Haskell jobs around our group's city. I think someone would have to have a very strong background to leap from such an internship to a remote Haskell job, or they would have to turn into open source superstar during the internship.
I don't use nix so I'm far from any kind of authority on this, but isn't this kind of the point? Nix is supposed to provide a hermetic environment. If you don't tell it what the inputs are, how can it?
As of now, no. Both work fine.
Hi, hello. Still not happy about you appropriating my name from HN, causing people to mistake you for me.
nix can provide a hermetic environment (via nix-shell for instance) but it can also install haskell packages globally for a certain user (via nix-env). Nevertheless the issue I'm mentioning is independent of that, using either my global haskell set of packages (installed via nix-env) or a project specific set of packages (via nix-shell), ghc-mod seems to work fine on a directory with a cabal file, but fails if there is no cabal file. The nix provided ghc/runghc on the other hand can in both cases (global and hermetic) compile/run the single haskell file without issues.
If you are ok with an external (C library) dependency then consider saltine too. It has two out of three on your list: random bytes (recently exposed) and hashing (via blake2b). It does not have any sort of KDF but the scrypt package is reasonably light weight so paring the two together is not unreasonable. FYI, the things you ask for fit into the category of "explicitly lower level". When people talk about high level cryptography interfaces they typically mean something like `crypto_box`, not individual hash functions, KDFs and random values.
Thanks again! IIRC, tmux has commands to "print" the contens of a pane from another pane. Perhaps it would be easy to write a Vimscript function that invoked such command and parsed the results, putting them in the location list.
There is no sensible `Functor` instance. All of the other classes you listed have `Functor` as a superclass, so those instances are also unwriteable. Notice that even the [Set](http://hackage.haskell.org/package/containers-0.5.10.2/docs/Data-Set.html) type from `containers` does not have a `Functor` instance.
Cool! Also I’m an idiot, I mean the next release will be major version 1.2 :) 
Hello, I first want to say that I only have some experience playing with Tidal, Overtone and Euterpea. I believe that Tidal is more of a "algorithmic" sequencer as in time lined live performance, or however you want to call it. I am sure you could compose your structured passages and such and then from this compose them somehow in to a "score". On the other hand, I feel that Overtone has more tools and functions that while still being mainly a live coding tool might be slightly more easy to compose more structured music. Though it is in Clojure. Then, even though I checked it like 3 years ago, I remember [Euterpea](http://www.euterpea.com/) being more composition oriented while still being able to have some kind of live coding. There was a pdf/book available on their page that was quite well written but it seems they have taken it down at is pending publication, though it seems accessible albeit an old version (2.6). I don't know how up to date it is or anything, but it was really interesting and the authors I seem to remember had some work on Jazz generative music. Hope someone who knows more can help you.
What is 34C3?
https://en.wikipedia.org/wiki/Chaos_Communication_Congress
I didn't read your question in detail, but &gt; it seems to be saying that it can't prove that forall n. Plus (S Z) n == S n, which seems ridiculous to me. That's exactly what it's saying, and it's not exactly ridiculous. Basically, it's the problem with using type-level nats: the type system doesn't know that `Plus` is associative, commutative, or any of the other nice properties you want it to have. I don't know what the right (or common) solution is when doing it in Haskell, but you basically have 3 options in general: * Construct your data so that this isn't a problem * Case on your data so that the type checker sees all the base cases * Construct a manual proof of the relevant equational property and introduce it (said proof can use `unsafeCoerce`, but it shouldn't need to) 
Thanks all for the helpful comments. Still not a clear choice for me regarding editors and plugins, but i see a bright future. I do fine without IDE-features, auto completion etc., now i enjoy Haskelling in a simple editor with syntax highlighting + GHCi
Any Haskell developers in Haskell?
Probably not. I'm on the other side of Texas.
Ok, so how would I go about doing one of those 3? I'm a bit new to dependent types. 
There's the network package, which is pretty much a straight low-level import of the C Socket API, so you should be able to use that.
What has haskell-src-exts got to do with ghc-mod?
Certainly. See my comment above: https://www.reddit.com/r/haskell/comments/7lont3/serokell_is_hiring_haskellers_fully_remote_job/drr7v8v/
I am aware of `network`, but it does not contain functions such as `sendmsg(2)` and `recvmsg(2)`. https://hackage.haskell.org/package/network-2.6.3.2/docs/Network-Socket.html does not mention the word "multicast".
&gt; As of the 2010 census, the city population was 3,322. Sounds about right...
I wouldn't try to learn them in Haskell. I'd suggest going through some Agda learning materials for a better introduction. Haskell's treatment of dependent types is... let's call it quirky. I also think there's a type error in your code, because `VCons x xs` doesn't look like it should be associated with `(Plus m n)` in `toPairVec'`.
I’d be up for it. You could set up a [Self-organize session](https://events.ccc.de/congress/2017/wiki/index.php/Static:Self-organized_Sessions) if you want to give it more structure.
Following a c tutorial like [this](http://www.tldp.org/HOWTO/Multicast-HOWTO-6.html), You can use [setSocketOption]( https://hackage.haskell.org/package/network-2.6.3.2/docs/Network-Socket.html#v:setSocketOption) and [send](https://hackage.haskell.org/package/network-2.6.3.2/docs/Network-Socket-ByteString.html)
Cabal has always supported many GHC versions. In fact, `cabal new-build` supports a good number of GHC versions, going back to 7.8 or something, I believe. The particular feature Ben is referring to is a new feature in GHC 8.x that `cabal new-build` has support for. When you run `cabal new-build` using GHC 8.*, after it picks an install plan and builds everything, `cabal` writes out a `.ghc.environment.&lt;foo&gt;` file in the build directory. This file is something that is read by `ghci` when you invoke it, and it tells GHC how to find a set of libraries it should implicitly load in this project. GHC makes these libraries available. The net result is that if your `.cabal` file says `build-depends: aeson` and you run `cabal new-build`, after it's done you can run `ghci` and just write `import Data.Aeson` and it Just Works. This is project local and works immediately with no extra tools for GHC. So this feature works well with flycheck modes, etc. All you really have to do is run `new-build` once and then set your flycheck mode to just run `ghci` with nothing else; imports will automatically work (provided you set up other e.g. `-i` parameters)
Could you tell us where your `QLearner` type comes from? I have tried to reproduce your error but a few imports are missing (I think I found most of them) and if you have defined `QLearner` yourself its definition is missing. For the `KnownNat` constraints, the easiest thing to do to solve errors like `• Could not deduce (KnownNat ((l + 1) + 1))` which should be trivially solvable from the `KnownNat l` constraint is to use the ghc plugin [`ghc-typelits-knownnat`](https://hackage.haskell.org/package/ghc-typelits-knownnat) with the following pragma in your file: {-# OPTIONS_GHC -fplugin GHC.TypeLits.KnownNat.Solver #-} (By the way, other plugins such as [`ghc-typelits-extra`](https://hackage.haskell.org/package/ghc-typelits-extra) and [`ghc-typelits-natnormalise`](https://hackage.haskell.org/package/ghc-typelits-natnormalise) are also very helpful.) I rarely ever use a proper dependently typed fold when I can avoid it. I would usually reify between type level and value level back and forth and do the folding logic at the value level. This does however require to "prove" that the constraints of whatever you are calling hold after reifying back to the type level. To reify back and forth you can use [`snatToNum`] (https://hackage.haskell.org/package/clash-prelude-0.11.2/docs/CLaSH-Promoted-Nat.html#v:snatToNum) and for the other way something like: reifySNat :: Natural -&gt; (forall n. SNat n -&gt; a) -&gt; a reifySNat n f = reifyNat (fromIntegral n) (f . snatProxy) But if you actually need to use `dfold`, I hope the ghc plugins will solve all of your constraint issues. If you don't want to use the plugin you can manually provide the proof that if you know `l` then you also know `l + 1` using [`plusNat`](https://hackage.haskell.org/package/constraints-0.9.1/docs/Data-Constraint-Nat.html#v:plusNat) from the `constraints` package and pattern matching on the result to get the proof in scope. Good luck :-)
The /r/haskell sidebar currently says "30,209 Haskellers"...
&gt; secede `-XIndependentHaskell`
The Prelude is a question of what's in scope by default. There's nothing about that that should be inherently incompatible with packages that make different decisions. The different *"incompatible"* preludes (subhask?) are not merely disagreement on "the basic set of functions" but on large questions of how the ecosystem should be structured. And so far as I'm aware, you're still always able to get things working together with some boilerplate.
If you have two opinion on how your ecosystem should be structured, then you have two ecosystems --- in an environment where most purposes aren't covered even by a single ecosystem. And I don't really care about ecosystem structure, what I care most is getting the job done quickly and efficiently, without reinventing the wheel. A single big all-encompassing (but of course entirely modular) standard library provides that, a fracture of ecosystems and proof-of-concept packages doesn't.
I find this awesome, only that instead of competition, I'd prefer cooperation, say choose a library, and provide pull requests with improvements in general, it can be performance improvements, documentation, bug fixes, etc. Benefits of this over the competition way are: 1. Lower entry bar: non performance-gurus can still participate. 2. The library will potentially end with more improvements. 
The whole idea of a professional secret is repulsive. Sounds like something people would use to protect their ass and artificially inflate their value by hiding just how easy their job actually is. In other words, a conspiracy. “One weird trick” to keep your employers from firing your ass for goldbricking. Any so-called secrets in Haskell should be exposed and burned for all to see. Same with anyone who hoards and propitiates others with them.
Ah I see. Yeah the search on those readthedocs instances don't always work that great. Glad to help!
I wouldn't focus so much on how much it improves their Haskell skills. Anybody can sharpen their Haskell skills for interviews by just grinding HackerRank or some similar site. The unique thing they can get out of an internship is an accomplishment that they can put on the resume. For example, suppose that you were comparing resumes to determine which candidates to interview. Would you be more likely to interview the candidate that has "grew user engagement by 5%" or "smoothed incremental paths for converting from homegrown libraries to standard libraries"? Focus on giving them solid accomplishments to list on their resume that show they are capable of delivering value to any prospective employer.
I really like what you're doing, and i think ansi-terminal is a good lib. I wish that haskell had a better lib for roguelike IO.
Why you did't create .cabal or stack file? I compiled and tried to run it, but it fails with "Vauxhall: Prelude.head: empty list"
Ok. That error happens when run without argument )
I tried this, and I couldn't get it working. I suspect you're running into an impedance mismatch between Stack and Nix. The non-Nix Stack build uses system libraries and tools, and the non-Stack Nix build uses patched libraries to get around the lack of `ldconfig`. The Stack+Nix build uses system libraries but within a Nix `sandbox` without `ldconfig` and no way (AFAICT) to add it. I think either using the whole Nix toolchain or the regular Stack toolchain without Nix would allow you to get a project up and running.
My first programming course at uni (2004) taught Java and Haskell. I absolutely detested Haskell. It seemed impractical and unnecessary. I'm still a Haskell beginner, but I've been constantly called back to the language for years by some of the amazing characteristics of the language. One by one, mainstream languages have become tedious and noisy and I know I'll end up doing everything exclusively in Haskell or something like it. Needless to say Java, C++, and more recently Go have become loathsome to me for the boilerplate, mental padding, and ceremony required to avoid bad and lacking features.
What does it mean using the entire Nix toolchain?
I vote for composition.
You can try stack pure option. nix: pure: true
/u/Faucelme this is probably the *most* practical examples I've seen about `lens-aeson`, it would be a god send if you could write more examples like this :) Quick question, since `lens-aeson` is so much convenient and faster, is it the de facto approach people in haskell community handles json these days? Is there still need to use auto derived instanced etc.?
Thanks a lot for the info!
try: ``` $ cabal2nix --shell . &gt; default.nix $ nix-build ``` and hop on #nixos so we can help you :).
&gt; In fact, cabal new-build supports a good number of GHC versions, going back to 7.8 or something, I believe. We go a great lengths ensuring it keeps working for even older ones (not the least, because http://matrix.hackage.haskell.org/ needs this). Currently the [`new-build` docs](http://cabal.readthedocs.io/en/latest/nix-local-build-overview.html) say &gt; Nix-style local builds were first released as beta in cabal-install 1.24. They currently work with all versions of GHC supported by that release: GHC 7.0 and later.
In my context (ray tracing) it is common to store the uniformly distributed random numbers, because - Generating them takes time, one random sequence is used many times (i.e. the number of pixels), but the sequence is not long (proportional to the depth of the ray tracing times the number of samples, for example, depth == 3, number of samples == 1000, samples per depth = 6 -&gt; 18000 samples.). - Generating them uses memory fetch from some global lookup table, so if we need to pay the cost of a memory fetch, at least we can remove the generation time - We uses the numbers of the sequence in somewhat random order (well, we may skip some of them). It is costly to skip random numbers from the sequence. - Pre-generation can be done in an offline process, hence we can use smarters algorithms to ensure a good distribution of random numbers.
Thank you for this, it's going to be very useful for me, since I am also trying to get into haskell more by making a simple game :)
Hi, I have quite a lot of imports, so I tried to reduce them to the most important ones. But of course I can show you them: import qualified CLaSH.Sized.Vector as SV import qualified CLaSH.Promoted.Nat as SV import Control.Arrow import Control.DeepSeq import Control.Lens import Control.Monad.ST import Control.Monad.State hiding (zipWithM) import Data.Array.ST import Data.Foldable import Data.List import qualified Data.Map.Strict as M import Data.Maybe import Data.Monoid import Data.Singletons import Data.Singletons.Prelude.List as SL import qualified Data.Vector.Storable as DV import GHC.TypeLits import Grenade import Grenade.Core.Network import qualified Numeric.LinearAlgebra as SAD import qualified Numeric.LinearAlgebra.Static as SA import System.IO (Handle, hPutStrLn, stdout) import System.Random Missing here are some internal package imports (but they shouldn't be important here), the QLearner type looks like: -- Monad m, RandomGen g, State of Environment st, State Representation stRep, -- input shape of one period iShape to the network, number nr of last inputs to serve to the NN, -- Neural net type net data QLearner m g st stRep iShape nr net = QLearner { _randomGen :: !g -- ^ Random generator , _period :: !Integer -- ^ Number of previous actions to reward. , _currentState :: !st -- ^ Current state of environment. , _newEpisodeFun :: !(Maybe (g -&gt; st -&gt; stRep -&gt; Maybe (st, Reward))) -- ^ According to the given state -- representations traverse over to the state -- with given reward if wrapped in Just, -- symbolizing the end of an episode. Specify -- Nothing if this is a continuous task. , _episodeEnd :: !Bool -- ^ True means end of episode. Used internally. , _actionList :: !(V.Vec (Int, Action m st)) -- ^ List of all possible actions, the agent is -- capable of doing. , _actionFilter :: !(ActionFilter st) -- ^ Defines which states are reachable from -- the given state. Thus, it is a function st -- -&gt; [Bool]. The length of the list must -- correspond with the length of the -- actionList, otherwise an error is raised. , _actionNames :: ![String] -- ^ Names of the actions for output. , _stateRepresentation :: !(StateRep st stRep) -- ^ Function (st -&gt; stRep) to represent a -- state. stRep is used for separating between states. , _policy :: !(Maybe (Policy g st)) -- ^ [Action st] -&gt; st -&gt; [Action st]; Nothing means random , _alpha :: !(st -&gt; Double) -- ^ Learning rate (alpha): The learning rate -- determines to what extent the newly acquired -- information will override the old -- information. , _gamma :: !(st -&gt; Double) -- ^ Discount factor (gamma): The discount -- factor determines the importance of future -- rewards. , _replayMemory :: forall layers shapes' . Network layers shapes' ~ net =&gt; V.Vec (Bool, Double, stRep, Int, stRep, V.Vec Int, S (Head shapes'), Reward) -- ^ final, gamma, stRep, ActionNr, stRep of s', acts', inpRaw, reward r , _nnParams :: NNParams net -- ^ NN parameters. , _actionValueRepper :: stRep -&gt; Int -&gt; iShape , _actionValueTable :: net -- ^ Stored as a neural network. , _nrOfLastInputs :: Int -- ^ Nr of last inputs to give as input to the NN. (nr == nrOfLastInputs) , _lastInputs :: SV.Vec nr iShape -- ^ Used internally. , _statistics :: !Statistics -- ^ To keeps stats. , _ioSettings :: !(IOSettings st) -- ^ Actions to do for writing results, etc. } I know, I should probably refactor rather soonish :-) Well I think I try it with taking it out and reifying back. I'll let you know if it worked out :) 
If the `KnownNat` constraint is the only issue remaining I would give the ghc plugin a shot before changing it to a value level fold. It is fairly simple to setup :-)
IMO dependent typing isn't truly needed, we rely plenty on asserted behavior that isn't formally verified all the time, such as the laws for basically every typeclass. Now verification is nice and sometimes the way to go but just wanted to throw that out there. Some sort of `assertMonotonic :: (a -&gt; b) -&gt; Mon a b` would work, I am pretty certain SubHask already does something like this. But on a side note I'm not sure if monotonicity is sufficient. I guess it depends what exactly it means for something to be a `Range`. For example: ``floor10 = (`div` 10) . (* 10)`` is monotonic. But is: ``floor10 &lt;$&gt; RangeSet [Range (45, 52)] == RangeSet [Range (40, 50)]`` reasonable? I mean it might be if you are essentially using it to find all possible values that something can be in, but are ok with false positives. But there are definitely use cases where it is not reasonable.
Hey thanks, yes you're right. I already wanted to post it, but then figured it might be better to wait until I resolved all other issues and it compiles. Anyways, it seems to work when I add {-# OPTIONS_GHC -fplugin GHC.TypeLits.Normalise -fplugin GHC.TypeLits.KnownNat.Solver #-} {-# OPTIONS_GHC -fno-warn-incomplete-patterns -fno-warn-redundant-constraints #-} and change the function to toNetInp :: forall m g st stRep layers shapes net iShape iShapeK nr len x . (Network layers shapes ~ net, iShape ~ S iShapeK , len ~ Size iShapeK, HeadShape iShapeK nr ~ (Head shapes) , KnownNat (nr+1), KnownNat nr, (nr + 1) ~ (1 + nr) , S x ~ iShape) =&gt; QLearner m g st stRep iShape nr net -&gt; S x -&gt; S (Head shapes) toNetInp ql (S1D inpV) = S2D $ (SV.dfold (Proxy :: Proxy (Append len)) stepDim1 base (fmap fromS lasts)) where base :: Append len @@ 0 base = SA.col inpV fromS :: S ('D1 len) -&gt; SA.L len 1 fromS (S1D x) = SA.col x lasts = fmap (normInput ql) (ql ^. lastInputs) stepDim1 :: SV.SNat l -&gt; SA.L len 1 -&gt; Append len @@ l -&gt; Append len @@ (l+1) stepDim1 SV.SNat y x = x SA.||| y Note the signature of stepDim1. I removed the forall constraint completely. However, this only works with the ghc plugins enabled. Thanks so much :) 
Is there a way to do something like that without depending on reflex or reflex-platform at all, since I'm not using reflex at all?
I think it was down, ran the same command again some time later after doing a bunch of things that probably weren't overly related, and it worked.
Am I missing something, because I just tried `cabal new-build` with `GHC 8.2.2` and 'cabal-install 2.0.0.1`, but there's no `.ghc.environment.xxx` after its run inside of the build directory?
If you look at the Gist I linked, you'll notice there's a version check; you need at least `cabal-install` 2.1 and GHC 8.0.2
brick is fantastic https://hackage.haskell.org/package/brick
Glad this worked for you! What the plugin does is something along the lines of: stepDim1 l@SNat ... = case l `plusNat` d1 of Sub Dict -&gt; case (l `plusNat` d1) `plusNat` d1 of Sub Dict -&gt; ... rest of the code ... *Note*: `d1 :: SNat 1` in CLaSH Hope that helps your understanding! :-)
&gt; Should I use nix? I'd personally prefer not to as it's a simple project Nix is indeed an additional complexity to add, but I found it a worthwhile investment. So much so that I switched my desktop to NixOS after seeing how well it worked for ghcjs. &gt; I should note I am not using reflex, so the reflex-platform doesn't seem like the way to go. I should also note I am developing on OSX, but others on the project might not be. While I use reflex-platform for reflex, it doesn't restrict you to reflex explicitly. The repo is very active and there is even an IRC where people are very helpful. The new 'project' implementation by /u/ElvishJerricco is really nice in particular. I no longer have to rebuild ghcjs+boot libraries on what seemed like a weekly basis. With the project implementation packages are automatically resolved based on hackage, but you'd add react-hs (which isn't on hackage) like: overrides = self: super: { react-hs = self.callCabal2nix "react-hs" ../path/to/local/react-hs {}; }; or if you are pulling from github: overrides = self: super: { react-hs = self.callCabal2nix "react-hs" (pkgs.fetchFromGitHub { owner = "liqula"; repo = "react-hs"; rev = "48f437029cc58b7c707179688e619cd53134cce6"; sha256 = "1cbnir4ycjpfbypkqignicn5faz1815qknixsh7kdkx0vvvzhjkm"; }) {}; }; where you can get rev and sha256 easily by `nix-prefetch-git https://github.com/liqula/react-hs` on the command line. Then when `default.nix` is setup like the examples, just run `nix-shell --attr shells.ghcjs` (to get a ghcjs shell) and you can build with `cabal new-build` or `stack build` provided you have `system-ghc: true`. In general I use cabal except for if I need a repl with multiple targets, in which case I use stack. I can't speak for how nix works on windows.
&gt; Should I use nix? Yes. &gt; I'd personally prefer not to as it's a simple project that I just want to get working and don't really want to deal with learning nix or forcing other people who are new to Haskell altogether to also learn it. &gt; I should note I am not using reflex, so the reflex-platform doesn't seem like the way to go. Run `./try-reflex` to get a shell with `ghc` and `ghcjs`. Inside the shell you can pretend nix and reflex do not exist. The reflex packages will be in `ghc-pkg list` and `ghcjs-pkg list` (along with lots of other useful stuff), but you don't have to use them in your `.cabal` files. Use `cabal new-build` inside the shell to build your project (unlike `stack build` it will use the `ghc`, `ghcjs`, `ghc-pkg` and `ghcjs-pkg` installed by nix). If you want to use more nix stuff then check out [this](https://github.com/reflex-frp/reflex-platform/blob/develop/docs/project-development.md). 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [reflex-frp/reflex-platform/.../**project-development.md** (develop → feaf80e)](https://github.com/reflex-frp/reflex-platform/blob/feaf80e90c547a2c9d407e8e38d0e7309342b5f1/docs/project-development.md) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
&gt; build with cabal new-build or stack build provided you have system-ghc: true Am I right in thinking that `stack build` will not use patched versions of the packages that may have been installed by nix into `ghc-pkg list` (even if you set `system-ghc: true`)?
You do not have to use reflex to use reflex-platform. You can use it with miso, react-hs, or whatever else. The platform is basically just the Nix infrastructure for good cross platform Haskell web apps. Might as well be called ghcjs-platform.
If you turn on Stack's Nix integration and use `resolver: ghc-xxx`, Stack will just use Nix for GHC and assume it can't install packages. So you can then trick it by having the Nix shell provide a GHC with packages installed, and it will use them. This is not an officially supported node of operation, and I've found it to be a bit buggy, so I *definitely* recommend the new-build workflow.
To add to this, I think Nix is the only effective way to develop web apps in Haskell right now. Stack's support for GHCJS is fairly poor, and it doesn't support cross compiling *at all*. `reflex-platform` is the only reliable way to get an up to date and stable GHCJS, plus the cache means you won't spend forever building it and the whole Haskell dependency tree from source on practically a weekly basis. Also, I can't really recommend `./try-reflex` for anything but the most basic possible uses. The `project` workflow just accomplishes a lot more with a lot less effort.
I've heard a lot of good things about `reflex` and wanted to try it out, work through the tutorials et cetera. However, I steered clear of it (or rather, kept procrastinating), not because of `nix` and having to learn a whole new tool-chain, but because of the `GHCJS` buy-in. When I read up on `GHCJS`, I encountered claims that it is quite the memory hog. That is, people recommended your machine should have at least 8GB RAM, or better yet 16GB. Are these claims (still) accurate? Do I have any chance of using `GHCJS` with only 4GB (and 8GB swap space, which I would like to avoid using for obvious reasons)?
Yes that is also necessary and is something I forgot about. It is buggy, but it allows loading (for example) `common` and `server` into ghci for development (with `ghcid`) which I find necessary since changes are almost always cross package.
Thank you I'm so glad to hear that!
I'll be updating semi regularly so I'm glad to hear that!
It's not *exactly* a parser combinator library, but Duncan's work on binary deserialisation (see https://youtu.be/60gUaOuZZsE and https://hackage.haskell.org/package/cborg) uses a deep embedding (somewhat surprisingly) for performance reasons.
You have to include a name as an argument to the binary file when you run it
Note that the OP said: &gt; I should also note I am developing on OSX, but others on the project might not be. And nix is, AFAIK, not usable on windows natively. 
You can use Nix in the WSL, but that's not ideal obviously. But I took "others might not be" to mean Linux :P
An interesting article although I can't seem to get the `NonEmpty a` example to work. `headOr :: a -&gt; [a] -&gt; a` does and will do but I like the readability of `NonEmpty a`... any idea what I'm doing wrong? {-# LANGUAGE OverloadedStrings #-} data NonEmpty a = a :| [a] deriving (Show) safeHead :: NonEmpty a -&gt; a safeHead (x :| xs) = x main :: IO () main = do print (safeHead [1, 2, 3]) Has a type match error; 
In [Earley](http://hackage.haskell.org/package/Earley), you build a grammar whose value is a concrete datatype, whose productions can be listed and examined, I think that's what you're looking for? While searching for that library (I had forgotten its name), I also stumbled upon [pinchot](http://hackage.haskell.org/package/pinchot), with the promising "Write grammars, not parsers" tagline, and [peggy](http://hackage.haskell.org/package/peggy), whose [Expr](http://hackage.haskell.org/package/peggy-0.3.2/docs/Text-Peggy-Syntax.html#t:Expr) type is clearly representing a grammar.
You're getting a type error because `[1, 2, 3]` has type `[Integer]` but you need `NonEmpty Integer`. You can either rewrite it as `1 :| [2, 3]` or enable the [overloaded lists extension](https://ghc.haskell.org/trac/ghc/wiki/OverloadedLists) and provide `instance IsList NonEmpty`. 
and Frisby, for parsing expression grammars, which observe sharing monadically like Earley https://hackage.haskell.org/package/frisby-0.2.2/docs/Text-Parsers-Frisby.html 
The [open issue](https://github.com/tensorflow/haskell/issues/156) for using dependent types to ensure tensor dimensions are valid seemed interesting, but I haven't looked into it more than reading through the thread. 
For GHCJS, you can always just run your builds in nix via Docker or a VM since the output is JS which can run on any system.
&gt; If you have two opinion on how your ecosystem should be structured, then you have two ecosystems I mostly agree with this. But it's only applicable to things like subhask that actually restructure things, and which - to the best of my understanding - no one actually uses. And it's not "for no reason at all" - it's an experiment in what that alternative structure leads to. The more-used alternative preludes *don't* split the ecosystem. (And even so, the standard Prelude is overwhelmingly the most common in production.)
When talking with people who are open to learning a new language if it will improve their work, but are not that curious or have a low tolerance for learning theory, I often hesitate about what to teach them. Often, this might be someone who is programming for a living, without a CS background, or who got into programming because they were smart and it was an available job. They are willing to learn only if it provides gains in the short term. Currently, I tend towards either picking a library in their language of choice that either introduces ideas like functors/monads or immutable data structures, or steering them towards Elm. I don't recommend Haskell because they will not attempt to use it regularly and there is little possibility that they might experiment with it in their work. To that end, a less glamorous path to planting typed FP ideas in people, is to start from their preferred language (ruby, python, javascript, etc), and writing tutorials for the FP leaning libraries there. Then, a person might possibly cruise through Haskell from First Principles faster, as the topics would be familiar. I also like the idea of diving deep into Elm. This might prevent the problem where someone loses momentum because they become stuck with a complex compiler error or harder concept. One could explicitly call it "Haskell through Elm", similar to the approach of "FP in Scala," where the focus is on learning concepts rather than using Elm idiomatically. I have tried the alternative path that this book might approach with some people, where you teach me bare minimum Haskell and then focus heavy on practical, common web programming tasks like using mysql-simple, aeson, scotty, and lucid. People tend to just abandon the effort, as soon as they are left alone with the language and libraries.
Thank you for this effort and your prior efforts and writings so far. A minor note from skimming some topics listed - consider adding a nix section. I agree that I would emphasize stack, because of the wider user base, good docs, and low number of new concepts to learn. A brief aside about nix, where you avoid teaching much about nix, but provide a few very simple uses cases (fire up ghci with libs desired; hello world program) might be useful for some beginners.
[removed]
Unix only I'm afraid. If you're gonna make a game it has to work, and well, on win32
Thanks! Perhaps I'll write a post about it. &gt; Is there still need to use auto derived instanced etc.? You mean using lean-aeson instead of mapping to separate "model" types? I think it is a good idea to have them. But for cases in which you are only interested on a small part or the document, our you want to make a change but you don't want to model a complex schema, `lens-aeson` it a good solution.
It is not "random enough" for many uses, including quick check. Avoid it.
Checkout https://github.com/basvandijk/nixtodo which is a demonstration on how to use Nix to build, test and deploy a Haskell web application.
Thanks for taking the time to gather and present us with the most interesting bits of information about Haskell on a regular basis. Really appreciate the effort!
Thank you for your hard word on Haskell Weekly.
The source for https://haskell-miso.org is a good example of a client / server setup with nix that maximized type sharing. It doesn't require a fork of nixpkgs and allows for correct pre-rendering. code here: https://github.com/dmjio/miso/tree/master/examples/haskell-miso.org
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [dmjio/miso/.../**haskell-miso.org** (master → 7a8117e)](https://github.com/dmjio/miso/tree/7a8117ed33725692c0629f84a223e07db9db07da/examples/haskell-miso.org) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
If you don't mind using an UI library consider using Miso with Stack: https://github.com/dmjio/miso#stack I have been able to get it working fairly easily, along with Emacs integration.
&gt; It doesn't require a fork of nixpkgs and allows for correct pre-rendering. Forgive me if I'm being presumptuous, but I believe this is a remark about Reflex, so I will respond in kind ;) To be fair, the main reason `reflex-platform` needs a fork of nixpkgs is to support native mobile cross compilation, which I don't believe miso supports; otherwise I *think* most of it has been upstreamed, and the cross compilation stuff is being upstreamed slowly. And `reflex-dom` also [supports pre-rendering](https://github.com/reflex-frp/reflex-dom/blob/develop/reflex-dom-core/src/Reflex/Dom/Builder/Static.hs) without much fanfare.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [reflex-frp/reflex-dom/.../**Static.hs** (develop → 1cdea31)](https://github.com/reflex-frp/reflex-dom/blob/1cdea3187bfadda0ffb1ba680a1c0c4260bc4fc6/reflex-dom-core/src/Reflex/Dom/Builder/Static.hs) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply drvk3cj.)^.
&gt; to support native mobile cross compilation, which I don't believe miso supports Yes, miso does not currently support native cross-compilation, at least, not yet. The native strategy will be moreso inline with the react-native approach, not cross-compiling to a WebView. Correct me if I'm wrong here, but I believe a WebView is very limited in what APIs it can access on the phone, and I'd like to have full access to all the APIs (on android and iOS).
Automated-theorem proving via SMT solvers can be effectively used to prove such equivalences, programmatically: {-# LANGUAGE DeriveAnyClass #-} {-# LANGUAGE DeriveDataTypeable #-} {-# LANGUAGE StandaloneDeriving #-} {-# LANGUAGE TemplateHaskell #-} {-# LANGUAGE ScopedTypeVariables #-} .... import Data.SBV .... data BaseA mkSymbolicEnumeration ''BaseA .... type A = SBV BaseA .... a_equiv_b :: IO ThmResult a_equiv_b = prove $ do x :: (A -&gt; A) &lt;- return (uninterpret "x") y :: A &lt;- free "y" z :: A &lt;- free "z" .... let a = x ((\p -&gt; y) z) b = x y .... return $ a .== b .... bad_a_equiv_b :: IO ThmResult bad_a_equiv_b = prove $ do x :: (A -&gt; A) &lt;- return (uninterpret "x") y :: A &lt;- free "y" z :: A &lt;- free "z" .... let a = x ((\p -&gt; y) z) b = z .... return $ a .== b We get: *Main&gt; a_equiv_b Q.E.D. *Main&gt; bad_a_equiv_b Falsifiable. Counter-example: y = BaseA!val!1 :: BaseA z = BaseA!val!0 :: BaseA Since you have access to ASTs, you can generate these formulas on the fly and pass them to an SMT solver and prove equivalence. You can have uninterpreted types like the one I had above or use concrete types (such as Int/Char etc.) to make your life easier when looking at the counter-examples. In fact, SMT solvers have been used for establishing such program equivalences before. A few pointers: * Program refinements: Here's a nice slide deck: https://pdfs.semanticscholar.org/5989/872f149fdb90bfb806640eeb9f687afebea6.pdf Look towards the end where it talks about "Automatically verify(ing) instances of refactorings." * Liquid Haskell, while built on the idea of type-refinements, also use SMT solvers for establishing equivalences as it performs proofs of refinement judgments. https://ucsd-progsys.github.io/liquidhaskell-blog/ * Microsoft researchers have put in similar tools into many of their recent projects, such as PEX, Dafny, etc. Google will give you lots of pointers! * Here's a nice summary of such techniques with an introduction to SMT solving: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.367.9961&amp;rep=rep1&amp;type=pdf Having said all this, I should emphasize that using SMT solvers (and theorem proving in general) has its cost: You'll have to build the necessary infrastructure, and while the automation in Haskell for doing so have matured over the years, it's not as simple as using, say, something like QuickCheck. Looking into pure testing based approaches might bring more bang for your buck, though there's quite a bit of frustration and a fair amount of satisfaction (pun intended!) waiting for you if you do go down the path of exploring theorem proving.
I haven't done a comprehensive survey or anything, but it's had all the browser APIs that I've ever needed. If you're talking about native APIs, that's what's so great about native cross compilation. You can just use the C FFI to get access to native APIs. I've implemented e.g. push notifications this way. Would be nice if Haskell had a nice API for several native APIs, but at least it's possible :P
A mass market GUI game, sure, but I didn't think a rogue like game needs to be on Win 32. If anything Linux users will find it more interesting. 
Oh awesome, wasn't aware it was possible to take advantage of native APIs outside of the WebView in this way. Very cool. I'd definitely like to see source if you're able to show it, keep up the good work :) 
It should work on both. Haskell needs to work towards more cross-platform UI styles when developing UI. Particularly brick. I know personally that any time I mention a roguelike in haskell someone thinks its a good chance to plug brick (again). Get that Unix-only junk out of here.
I recently gave a talk on the topic and created a minimal repo that uses nix to that effect: https://github.com/nmattia/websters
&gt; reflex-platform is the only reliable way to get an up to date and stable GHCJS The problem with reflex-platform is that it's a swiss-army knife and makes GHCJS seem a lot more complicated than it actually is, especially if you don't know nix well enough to puzzle out what you actually need modulo reflex. What would it take to create a ghcjs-platform, that gives you the basic tools you need for any ghcjs project, and can be extended to support whatever framework you want to use? So you'd end up with reflex-platform and (a hypothetical) miso-platform as extensions of the base ghcjs-platform. This would benefit the reflex project as well, since it'd provide intermediary destinations between GHC + stack + &lt;JS framework&gt; and GHCJS + nix + reflex, so developers don't have to commit to all three to do anything with GHCJS at all.
Yea since the Haskell is being compiled to the native machine, it's got all the C level access you'd expect from, say, Rust or Swift. IIRC, [this](https://github.com/obsidiansystems/cross-android) is what Obsidian Systems uses for some of the basics. It's very ad-hoc, as I don't think anyone's really had time to figure out and create the proper abstractions. But it should be a good example.
Well what you're suggesting is not far from reflex-platform. Almost all of reflex-platform is just setting up a good GHCJS environment with the ability to use jsaddle's other backends (including native mobile apps and webkit2gtk). Only a fraction of it is specific to reflex. There's also a lot of benchmarking, testing, and ops-ish tools that the guys at Obsidian like to use which could maybe be put somewhere else.
Do you think it would make sense to migrate miso away from the JS FFI in favor of JSaddle? This would make it essentially free to port to WebAssembly when the time comes.
Have you seen [mezzo](https://hackage.haskell.org/package/mezzo)? I haven't used it but it might be relevant to your needs.
Honestly a name like that really would help with discoverability for non-reflex users. But thanks, I'll take a look. 
Sweet, thanks for link. Yea, as long as it's possible that's huge. Easily taking advantage of native phone APIs with Haskell in a user-friendly way would be the dream. The approach I'm planning would take a barebones Swift or Android application and use the available javascript interpreter (jsdom) to evaluate the GHCJS generated js to update the model and perform diffing of the native GUI (in a separate thread). It's possible to call JS from Swift and vice versa by registering native functions in the JSContext. This is, as far as I know, how react-native does it. Will be interesting to see how it performs. I know react-native has had some performance issues, we'll see what happens. But this approach /should/ allow an application to be extensible via both the C FFI (if new native apis are needed) and the JS FFI. 
As I mentioned in the post I am using react-hs as my UI library. Although I'll look into that to see if it will also work for react-hs + stack. 
That seems odd to me. Why run GHCJS code when you could compile it natively? Using GHCJS will not let you use the C FFI. Does react-native render stuff? Does the same code work on browsers and mobiles; i.e. is react-native just translating HTML / CSS to native GUI stuff?
Does it make sense to do HSTS preload now? It looks like everything on haskell.org is HTTPS by default.
&gt; Using GHCJS will not let you use the C FFI. Right yea, I misspoke here, if the user wants to extend the application to take advantage of native APIs, they would have to write that code in Swift / Java, then make it accessible to the JSContext that the GHCJS app is evaluated in, and then call that registered function from the GHCJS FFI. So calling JS functions calls Swift code indirectly, no C FFI necessary. &gt; How does react-native render stuff? AFAIK central to rendering in react and react-native is the virtual-dom. Normally you're just diffing the DOM tree structure, but I think they've created a generic tree representation that both UIView (iOS) and the Android equivalent use (believe both have an XML structure). So when your model changes, a new rose tree is created (in JS), it's diffed (using jsdom, the js interpreter available in the same process), and then a patch is returned from the diff function outside of the JSContext, and applied to the native UI in Swift / Java. &gt; Does the same code work on browsers and mobiles; A lot of it, yes. But code for handling events would have to be written for each platform specifically. &gt; i.e. is react-native just translating HTML / CSS to native GUI stuff? Sort of. In `miso` the view you're constructing is a rose tree in javascript (just like react). There is nothing DOM specific about it except the impure reference to the DOM. In a native context, this reference would need to be replaced by a number or some other identifier to the GUI tree in iOS or Android. As far as CSS is concerned, FB has a cross platform layout tool that implements the CSS box layout (https://facebook.github.io/yoga/). So during the diff, the js interpreter would have to call out to native functions that use yoga. &gt; Why run GHCJS code when you could compile it natively? If you can make the cross-compilation development experience as user-friendly as the react-native experience, then I think it would be a better option. I'd agree, the morally right approach is cross-compilation here, but convenience is king. 
do you have a link to an example try-reflex project that, say, takes the hello world reflex program, and adds some particular version of lens as a dependency, and that compiles both to js and native? I tried it last year, and it worked initially, but I got stuck on making a nontrivial project. ( I think I added things to the right places in the nix file, but it's been awhile ).
[I have `reflex-project-skeleton`](https://github.com/ElvishJerricco/reflex-project-skeleton). It compiles to JS, Android, desktop, and iOS would be trivial (I only didn't do it because I couldn't test it). Adding a custom lens dependency would be trivial too. Just depend on lens in your cabal file as normal, and add this to default.nix overrides = self: super: { lens = self.callHackage "lens" "x.y.z" {}; };
&gt; If not, what's the point, if you have to rewrite the frontend again anyway? User's want the iPhone version of their app to look like an iOS app, same with Android. If everything is in a WebView, then it all just ends up looking the same. The only way to mimic this is w/ iOS styled CSS, or android, but imo, it pales in comparison to using native UI components. 
Agreed, as long as the same presentation code works on all platforms.
Yea, I'd need to see that this approach does indeed make it easier for the end users to build applications. How are the WebGHC efforts coming along? Does WebAssembly support DOM modifications? Or does it still rely on JS for this. To start this I'd need to move miso's diff function back to Haskell (it was originally), and replace all DOM calls to use jsaddle. Would be a relatively straightforward time-consuming task. For now I'm hoping /u/luite2 can improve the GHCJSi experience for 8.2 or 8.4 when it lands, so the experience can be as good as jsaddle.
&gt; How are the WebGHC efforts coming along? Slow but steady... I've been stuck on a codegen bug because I haven't had time to fix it. But I think it might be the last thing in between us and a working code generator. Then it's just a matter of implementing syscalls in [webabi](https://github.com/WebGHC/webabi). &gt; Does WebAssembly support DOM modifications? I think JSaddle has proven that it doesn't need to. The FFI shimming JSaddle does on other platforms will be effectively identical to the FFI shimming we'll do on WebAssembly to JS. And JSaddle is plenty performant. That said, yes they are working on adding DOM support via the [host-bindings](https://github.com/WebAssembly/host-bindings) proposal, which may not work with Haskell for syscall related reasons... &gt; To start this I'd need to move miso's diff function back to Haskell (it was originally), and replace all DOM calls to use jsaddle. Would be a relatively straightforward time-consuming task. Nah. You can still use raw JS with JSaddle. As for your last point, you're going to have to get compile times way down, and runtime performance way up to really match jsaddle's developer experience, even with GHCJSi. I think WebAssembly is a much better bet for getting all of this stuff more reliably.
Gregory Stevensh?
Compiling ghcjs is painful, especially on low RAM systems; that's where the 8-16gb suggestions come from. However, the compiler itself is just a compiler and the compiler's memory usage isn't too bad. Using nix, especially the reflex project stuff, will download binaries of everything for you so you don't have to compile much of anything.
You have a bad case of confusing your opinions with facts.
Of course they're opinions. Did I ever say that they were facts?
 they say it's your third monad tutorial that makes any sense. 
Wrt coherence what is to stop you using one module to create a map with say ascending ordering, and then using a different module to insert into it that has a descending ordering, where both modules operate on the same underlying type. How do you statically prevent the above? Since it is trivial to do so in Haskell.
What?
Consider the following code: signature ORDERED = sig type key val &lt;= : key * key -&gt; bool end signature MAP = sig type key type 'a entry = key * 'a option type 'a map val empty : 'a map val lookup : key * 'a map -&gt; 'a option val update : 'a entry * 'a map -&gt; 'a map end functor TreeMap (K : ORDERED) :&gt; MAP where type key = K.key = struct (* ... consult a data structures book ... *) end structure IntAscMap = TreeMap (IntAsc) structure IntDescMap = TreeMap (TreeMap) Then the type constructors `IntAscMap.map` and `IntDescMap.map` are actually different (even if the underlying representation is of course the same), so there is no risk of conflating them - the type checker will prevent it.
you did https://phabricator.haskell.org/rGHC71a423562a555ef0805bba546a3a42d437803842
Thank you! A few quick questions if you don't mind, does this support the whole incremental building thing that reflex-project supports? Also what things can I remove for an absolutely completely minimal setup, I assume the `python` related stuff can all be deleted? One last thing is how do I deal with versioning with nix, as I definitely am going to be pinning my dependencies pretty tightly in my cabal file, but it seems like nix doesn't work that way with regards to versioning.
I'd like to talk to Carrie.
Interesting. What kind of things would it be useful for?
Maybe for chaos-monkey style resilience testing, but on a smaller scale? In particular, since functions like [`timeout`](https://hackage.haskell.org/package/base-4.10.1.0/docs/System-Timeout.html#v:timeout) assume that all the IO actions in the world correctly handle asynchronous exceptions, it might be a good idea to test that this is indeed the case in your codebase.
How about using Brick with Windows Subsystem for Linux?
I'm always excited to see a new issue in my inbox!
&gt; Nah. You can still use raw JS with JSaddle. Well if this is true, then I don't see why `miso` couldn't work with jsaddle as-is. What else would need to be changed? &gt; As for your last point, you're going to have to get compile times way down, and runtime performance way up to really match jsaddle's developer experience, even with GHCJSi. I think WebAssembly is a much better bet for getting all of this stuff more reliably. The big thing is having an interactive REPL for type inspection, regardless if changes are hot-reloaded in a browser. I know (many) others prefer having both. GHCJSi 7.10.3 is pretty good right now. Having TypeApplications or type-level append of Symbols (among other niceties) that 8.x brings aren't deal-breakers yet imo. I do hope /u/luite2 will gift us with an updated GHCJSi. &gt; I think WebAssembly is a much better bet for getting all of this stuff more reliably. Sure, but I still think this is quite a ways off, would you agree? /u/luite2 might have some surprises for us before WebAssembly can be completed *and* make its way into GHC. Lastly, and importantly, one of the goals of miso is minimal dependencies. jsaddle feels kind of kitchen sink with the lens dep. and for GHCJS, deps. matter.
Does that work? Honest question; I tried, after years of not touching Windows, some Win dev and it was still not very nice to my taste. At least it had the subsystem for Linux, but after trying to use it for real cases, I found it lacking. It is young so I am sure it will get there. 
Well i don't want to move the goalposts on you, but even if that did work (I can't test it i dont have win 10), brick still has a very baf design for use with a roguelike. It's based on VTY, so you need to build up this whole huge app type with all these features just to do anything. You want two or three things in a curses-like lib for a game: tell me the terminal size, let me poll for input, let me draw a character at a specific location. I know this because it actually tried to make a UI lib for a roguelike that did more abstraction stuff for you and it actually just got in the way and turned out to be hard to use. I'll do another version one of these days, and it'll stay simple, and it'll be good because of it.
A deep embedding might be less useful than you would think. Common grammar formalisms (LL, LALR) aren't compositional, so I would aticipate a lot of the benefit of building them with combinators vanishes (modularity, the ability to swap out pieces to extend the language). Ideally, you could need to target a formalism that is compositional (Earley, PEG, I think GLR...) but where parser generators exist for these formalisms they are potentially less "battle hardened" and so less attractive from a software engineering perspective.
For some reason when I run: nix-build -A server-exe I'm getting: ============================== 2 tests deselected ============================== ======= 1 failed, 868 passed, 18 skipped, 2 deselected in 112.69 seconds ======= builder for ‘/nix/store/wgw8spg61xrvr76rg1c7h6h3mz82p2zv-python2.7-Sphinx-1.5.2.drv’ failed with exit code 1 cannot build derivation ‘/nix/store/wh7pcccy666z92m823lg2cpjif62nkgd-ghc-8.0.2.drv’: 1 dependencies couldn't be built cannot build derivation ‘/nix/store/9q173lnwfd3gmn0crl69csp6259j9kwf-cabal2nix-2.2.1.drv’: 1 dependencies couldn't be built cannot build derivation ‘/nix/store/9zgqxbdxas3xl9li2cgqwg5ih95004fh-cabal2nix-hashable-1.2.5.0.drv’: 1 dependencies couldn't be built error: build of ‘/nix/store/9zgqxbdxas3xl9li2cgqwg5ih95004fh-cabal2nix-hashable-1.2.5.0.drv’ failed
Au fait, je viens de voir ça : https://github.com/erkmos/haskell-companies
Screenshots, or it never happened! :)
You don't need GHCJS to use reflex-dom. In the reflex-platform you can run a reflex-dom program just with *runghc foo.hs*. It will compile with GHC and run in webkitgtk and you can even use GHCi. So development is *much* faster than with GHCJS!
Is there any chance of a completely decoupled ghcjs-platform? I really appreciate all the hard work that has gone into reflex and reflex-platform, but it would be nice to have a viable way to play around with other front-end libraries without directly piggy backing off of reflex.
What should I do to convert that skeleton to one that does not compile to Android or depend directly on `reflex`? Thanks for all the help!
They whom? What do they say?
Just remove reflex from the cabal file and delete the lines about android.
I'd say the chances of that are low just because it's not a priority for anyone. You can already use reflex-platform without tying yourself to reflex, so I don't see a major issue. Plus, one of the main complaints about Haskell is that there are *too many* options for other things :P
Reminds me of [similar thing](http://blog.probablyfine.co.uk/2016/05/30/announcing-byte-monkey.html) I just saw for the JVM too.
Hopefully we'll have a repl and TH for WebAssembly. And hopefully it's all not too far away. Honestly if i just had time for it, I actually think we'd be pretty close. But I've only had a couple hours a week on it for a while now.
The idea is to test the robustness of programs at the IO level. For example: * Does code handle asynchronous exceptions well? /u/gelisam already pointed out that use-case. We observed some examples of this in the Cardano (cryptocurrency) codebase. By throwing async exceptions randomly to new threads at random times, that's one way to confirm. * Does code handle regular exceptions well? This can be achieved by making all the basic low-level I/O functions in `base` randomly return error codes instead of running. Additionally, it can be applied to a version of `network` to simulate connection failures. Ideally, your programs will never present the user with an actual exception, but perhaps a message that means something to them, or by taking the course of action to correct the situation. * Does code handle invalid data well? This is basically fuzz testing. You can have functions that read from file descriptors randomly return garbage data, or data that's too large, or empty. Have programs that write to file descriptors randomly fail with "file not found" or "out of disk space", etc. * You can also introduce random slow downs where it could happen, e.g. in `threadDelay` or simply a `read` call or `forkIO` -- anything that could cause a race condition because it took a bit longer than normal. This is slightly different to renice'ing because it would make only one thread slower than usual, putting them out of sync. Similar to QuickCheck, I've been thinking of a system based on starting seeds. When your program crashes, you can re-run with the same randomness seed to reproduce the same run of the program. Then run again but advance one step instead of being chaotic on the last thing. As for implementing such a system, the GitHub repo above is just a proof of concept (which just actually fails on every file-related call with a bad exception type) to confirm that I can alter base and easily recompile my project with chaos enabled: $ PATH=/Users/chris/Work/ghc/inplace/bin:$PATH stack build $ stack exec chaos-demo OK! $ CHAOTIC_GHC_ENABLED=1 stack exec chaos-demo chaos-demo: foo.txt: openFile: failed (Unknown error: -1) I'll probably play with the idea some more. Any code that makes an FFI call is kind of out of scope, one would have to manually support "chaotic" support for functions in their libraries. That sucks a bit.
In my experience, GHCJS does not scale well enough on mobile. Complex apps are just far too slow for mobiles. I think you're going to *have* to cross compile. And I think Nix can make it pretty painless; just needs some polishing for incremental dev.
Hi /u/lowaiko , I co-maintain `network-multicast`, feel free to try it and shoot me a message if something doesn't work out. 
Very cool.
Some of this could go straight into the Readme, as it currently does not hint much to the purpose of the codebase. Cool project :)
I don't wanna sound mean, but this is just a different syntax for a subset of Rust, since the only thing it does is parse some AST and translate it to Rust. This can't be called a programming language in my opinion.
Good idea, I just copied it in there.
&gt; brick still has a very baf design for use with a roguelike You are simply wrong here. I have used it and it works fantastically and directly covers many use cases that you always have in a roguelike: pop up inventory menus, progress bars, scrolling message boxes, etc.
Indeed, you did. Phrases like 'has to' and 'needs' are not for stating opinions. Furthermore you are being needlessly insulting and standoffish. Why don't you talk to the brick developer and see how difficult it would be to add Windows support?
yea, I feel your pain. Similar story here.
Well, this might be true, but react-native is used in many complex apps (including the FB app itself). It would be interesting research to try the react-native approach with GHCJS generated js. Maybe we'll all be surprised, or maybe the JS interpreter will be too slow to handle it.
Doner is always expanding the universe of interesting.
This is great. May be there should be a stack chaotic-lts which is the same as lts by installs the chaotic-ghc as its compiler. Will make testing convenient.
I'm happy that you had a good time, but those are easy to write myself, and none of those make up for the infuriating inability to just write a character to a location that I want.
Well, I believe the reason GHCJS doesn't scale on mobile is because the GHCJS generated JS is slow, not because JS interpreters are slow. So react-native doesn't have this problem because JS is pretty fast; it's just that GHCJS *makes* slow JS
I totally get where you're coming from and I plan on moving over to llvm soonish. 
You've got a wild view of the English language.
Yea, this was my worry as well. Miso's diffing algorithm is confined to its own file (only a few kb). So it can possibly be as fast (if not faster) as react in this way. We might also be able to have this run in a separate thread, maybe even use two js interpreters in different threads, who knows. When it comes to updating the application logic, this is where things could get slow. Depends on how fast jsdom is.
I am developing a next generation GUI lib. Perhaps this is a nice example of doing graphical demo (even if Roguelikes have been done in the terminal historically).
Not sure about best practices, but I had to solve the exact same problems building and packaging a C++, C and Haskell library. It unfortunately involves a [rather complicated](https://github.com/deech/fltkhs/blob/master/Setup.hs#L42) 'Setup.hs' and various other [nasty hacks](https://github.com/deech/fltkhs/blob/master/fltkhs.cabal#L179) but so far it does seem to work across platforms. There's a lot there so feel free to DM me if you have any questions.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [deech/fltkhs/.../**Setup.hs#L42** (master → 2d97fc4)](https://github.com/deech/fltkhs/blob/2d97fc4e3fec945f09a4748caf7b90f5e1e43297/Setup.hs#L42) * [deech/fltkhs/.../**fltkhs.cabal#L179** (master → 2d97fc4)](https://github.com/deech/fltkhs/blob/2d97fc4e3fec945f09a4748caf7b90f5e1e43297/fltkhs.cabal#L179) ----[^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply drwuvuu.).
That's just not one of the things gloss is built to handle. You have to break it up yourself. If want only the one asset file, you can slice it up with an image manipulation library - just build a function to take a pair of coordinates and slice out (in immutable terms this means generate a new image that matches a certain part of the old image) a smaller sprite, then map it over a list of sprite coordinates. JuicyPixels can generate an image from a function, and read pixels at coordinates, thats basically all you need.
I developed several packages with C++ bindings, which basically followed a similar pattern: * Include a snapshot of the foreign library in the tarball by including its source files in the `.cabal` file's `extra-source-files` field. Using `hpack` helps a lot since it supports using wildcards here. * Use a custom `Setup.hs` script to build and install the library, before building the Haskell sources. `Cabal` makes it simple by providing a hook mechanism, basically, you can know the target Haskell library path during `confHook`, so you can run whatever build process you need and set the appropriate installation path. Modify the resulting `LocalBuildInfo` to add whatever linker flags required. * Do not use a global installation prefix like `/usr/bin`. Either take the trouble of building and installing to the same Haskell installation target, or simply tell the user to build the foreign library themself in the `README`. I've extracted some util code useful for above process into a separate package: [`cabal-toolkit`](https://hackage.haskell.org/package/cabal-toolkit). You may take a look and see if it helps for your own use case.
This is saddening for Haskellers working on Windows (like me).
Indeed, you will need a Custom cabal build type and to specify the build process in Setup.hs .I'm not sure about the way to proceed with the golang compiler. Does this project build a single binary or dynamic libraries? 
Some time ago I wrote the *reedsolomon* library which uses some C code which needs to be built in a non-trivial way (hence using Autotools). It took me a while to get this all working correctly (Cabal invoking *./configure* and *make* correctly, the right files ending up to be linked into my Haskell library,...) but it works, see https://github.com/NicolasT/reedsolomon I think you can mostly take this setup and adjust the Automake stage to invoke Go to generate your C files. Note this repo also contains CI configurations, including AppVeyor, to make sure things build correctly on Windows as well (which is a can of worms on its own)..
I have not looked into the implementation details, but [this faq](https://github.com/haskell/haskell-ide-engine/blob/master/docs/Challenges.md) suggests that they are aware of ghc-mod's problems and actively try to avoid them.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [haskell/haskell-ide-engine/.../**Challenges.md** (master → 08c43af)](https://github.com/haskell/haskell-ide-engine/blob/08c43afc62ab9719688f239f378ad02b50a47a85/docs/Challenges.md) ----[^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply drwy2pv.).
I haven’t heard of this before, but it sounds good! &gt; `getHiddenChar` yields a single character from the standard input device with buffering and echoing to standard output disabled.
[removed]
FYI http://hackage.haskell.org/package/echo &gt; The base library exposes the hGetEcho and hSetEcho functions for querying and setting echo status, but unfortunately, neither function works with MinTTY consoles on Windows. This is a serious issue, since hGetEcho and hSetEcho are often used to disable input echoing when a program prompts for a password, so many programs will reveal your password as you type it on MinTTY! &gt; This library provides an alternative interface which works with both MinTTY and other consoles. An example is included which demonstrates how one might prompt for a password using this library. To build it, make sure to configure with the -fexample flag.
&gt; Get that Unix-only junk out of here. Steady on, old bean.
Neat, got an example repo you'd care to show off yet?
I think Chris Done has had the most creative ideas of 2017.
Right! Similar to how we have the GHCJS stack.yaml, it'd be great to just pass a different yaml file to run in this mode. With the custom snapshots this might already be possible, I'll have to look into it, after I've made this thing practical.
What are the other front end libraries that you want to try ? I know of miso and reflex. Are there others ?
On Windows, I used `ghcid`(it just watches your files and reloads them in an interpreter, while displaying any type errors, quick and very reliable). Then kept the output file open in vscode or emacs. like ghcid -o ghcid.txt --command "stack -j2 ghci --ghci-options -fobject-code --ghci-options -ferror-spans" but the default ghcid works too. https://github.com/ndmitchell/ghcid https://github.com/sboosali/examples-ghc-eight/blob/master/watch.bat 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [sboosali/examples-ghc-eight/.../**watch.bat** (master → fa269ee)](https://github.com/sboosali/examples-ghc-eight/blob/fa269eed063f3043334ed4b65a8d61a7463221a1/watch.bat) ----[^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply drxcejr.).
Looking forward to EC2!
I wouldn't use Custom setup here. Make a pre-packaging step to compile a Go to C, then you can make Cabal build C-stuff by using `c-sources` field (also `includes` and `include-dirs` are relevant). My rule of thumb: if the step can be done on the HOST (i.e. It's TARGET-system independent), do it already before `sdist`.
[removed]
It isn't just about trying out different frameworks, although that is the primary use case. It's also about creating a platform for people who want to learn GHCJS and create new things from it. And to not be locked into `reflex`, which certainly isn't congenial to all let alone most Haskell developers. And btw, you can a port of PureScript's `optic-ui` to your list. It's something I want to have within the next couple months, although it will probably be renamed since I'm going to extend it, and it clashes with Haskell's `lens` library already. 
&gt; I'd say the chances of that are low just because it's not a priority for anyone. Given that frontend development Haskell is still in its infancy, and that PureScript has already produced superior options, I think that supporting the meta-level of framework development should be a high priority for anyone who cares about its future. &gt; Plus, one of the main complaints about Haskell is that there are too many options for other things :P It's not about having too many options so much as the options not being sorted in any meaningful way. FRP isn't the only way to create visualization frameworks in a purely functional programming language, but given that the short list of options all fall roughly into that category, the unenlightened are inclined to think that they literally have no other option. And this is wrong. It's not about having a dozen different implementations of The Elm Architecture that differ only in the details. It's about the type of person who prefers any given general representation ideology being able to find the frameworks that support it. And for those (like myself) who see holes in the options currently available to have the necessary tool support to fill them in.
react-hs (fork of the unmaintained react-flux) is the one I use and develop. It's a pretty easy transition from react.js which is nice. 
/u/haskman's `concur` library also deserves a mention, especially as its meant to be a simplification of `reflex`'s overcomplication, and gives back a lot of the power that `miso` takes away. In other words, a improvement, although I haven't analyzed it enough yet to verify. :)
&gt; I think that supporting the meta-level of framework development should be a high priority for anyone who cares about its future. I guess I'm just not seeing how reflex-platform is deficient in this?
I believe GHC does generate a tiny bit of machine code when you export closures as function pointers for FFI: https://ghc.haskell.org/trac/ghc/wiki/Commentary/Rts/FFI I don't know about other cases though. I imagine it'd be avoided if possible as it's very platform dependent in nature.
Good example. Exporting closures outside the language seems to almost necessite code generation... I can't think of any other solution besides statically allocating a large number of closures and data pointers at load time and that's obviously rather crude (but then again we do similar for the stack in most imperative languages).
I'd actually be most worried about your orphan `Enum`, `Eq`, and `Ord` instances for `Float -&gt; Float`; they're definitely dodgy, and because they're defined on a type synonym and not a `newtype`, they could affect other parts of your program which use `Float -&gt; Float` in unpredictable ways, based on whether this module has been imported (even in parts of your code which don't involve any functions from this module). While the documentation for the `Eq` class is not completely clear on what counts as a valid instance, I'd say your `Eq FuncOrOp` instance is a bit insincere because it doesn't provide any information at all, since it always returns `True`. If you need to write that instance to make the library work, then I think either: - the library you're using is not suitable for what you're trying to use it for, and it probably is broken but just in a non-obvious way, or - the `Eq` constraint is unnecessary and the library shouldn't require it. The `Ord FuncOrOp` instance suffers from the above problems too, and I'd say it's more insincere than the `Eq` instance; the documentation says that `Ord` is for totally ordered datatypes, and your instance doesn't provide a total ordering. (In a total ordering, if `a &lt;= b` and `b &lt;= a`, then `a` and `b` should be indistinguishable.) Some examples of ways these instances could cause problems is if you try to use functions like `nub` on values of these types, or if you try to use them as elements of a `Set` or as keys in a `Map`. For example, with those instances, if you create a `Set`, and insert `FuncNotOp id` followed by `FuncNotOp (+1)`, then ask it for its size, you'll get `1` back, even though you might expect to get `2`. These might not be the most convincing examples, but you're at risk of this sort of thing happening with pretty much any code which uses `Eq` or `Ord` generically (which is quite a lot).
Tldr? 
I agree, Float -&gt; Float might be used elsewhere. What if I made Func a newtype, and only used it for parsing? My concern is that megaparsec might actually need those things to be Eq, Ord and Enum, for some function I'm unaware of but might end up using.
&gt; What if I made Func a newtype, and only used it for parsing? I think that would be a big improvement, definitely. &gt; My concern is that megaparsec might actually need those things to be Eq, Ord and Enum, for some function I'm unaware of but might end up using. Yeah; it's difficult to say but it seems quite plausible that you could end up being bitten this way.
FWIW, this is a fairly niche case, and it's not used in most Haskell applications. Also, most C libraries that ask for function pointers will also ask for context pointers to pass to the functions, so I believe you can satisfy these APIs without runtime codegen.
The more common term for those is "unlawful instances".
I'm not convinced you actually need the `Enum` instance. As far as I can tell the only reason you need it is because you copied `defaultAdvance1` from the Megaparsec code. But yours is exactly an example of a stream where the default `advance1` is not the right thing. `advance1 :: (Ord (Token s), Ord (Tokens s), Stream s) =&gt; Proxy s -&gt; Pos -&gt; SourcePos -&gt; Token s -&gt; SourcePos` is supposed to take a source position, a token and return a new source position that you get to by advancing past the token. That's great if you actually care about textual position if your stream actually represents text. But your stream doesn't. So you might as well just have your `advance1` implementation just always advance by 1. That will at least get rid of the `Enum` instance. (I'd sleep better at night if the `Ord` and `Eq` instances always returned `False` instead of `True` - but its harder to see where those instances are used in an essential way, so maybe `False` will actually break the parsing). Longer term, I wonder if you wouldn't be better off just borrowing the precedence parsing algorithm (ie the code for `makeExpressionParser`) from Megaparsec rather than all the rest of its machinery which I don't think you need.
I would be interested to know if GHC does in fact avoid generation of machine/native code for closures and partially evaluated functions that stay within Haskell.
&gt; So you might as well just have your advance1 implementation just always advance by 1. That will at least get rid of the Enum instance. Omg it's so much prettier now. &gt; I'd sleep better at night if the Ord and Eq instances always returned False instead of True -- I had the same thought about Eq. I didn't realize the same was true of Ord until you pointed it out -- if it's always false, then it will never deduce from x&lt;=y &amp; y&lt;=x that x==y. &gt; , I wonder if you wouldn't be better off just borrowing the precedence parsing algorithm (ie the code for makeExprParser) from Megaparsec Haha that's a cool idea. If I have problems with it I'll do that.
&gt; allocate a relatively large buffer and pray I thought they were auto-growing
IIUC it does not generate machine code to implement closures. You can get more information on how GHC works internally here: https://ghc.haskell.org/trac/ghc/wiki/Commentary/Compiler/GeneratedCode
If you're referring to the stack space of languages like C, then nope. Too many function calls (e.g. non-tail-call-eliminated recursion) or allocating large structures on the stack (less common and more obviously problematic) can cause a stack overflow.
Would that also disqualify PureScript, CoffeeScript, etc as programming languages? Indeed, Have and Nim compile to C. In other words, while I'm not really in a position to say what does qualify as a new programming language, I think your logic precludes a lot of languages that are recognized, which doesn't sound right either. 
I wouldn't like an `Eq` instance that always returns `False`, as it disobeys the rather fundamental `x == x` law. It's also part of why I hate basically all float implementations. 
It does. Ordinary Haskell language feature require no runtime codegen. It's just this one feature which you have to invoke with a library call (don't remember which one offhand, sorry)
I'd be happy to take PRs that modularize reflex-specific pieces of reflex-platform and make them modular. Originally, reflex-platform was called try-reflex, and it was just a way to avoid needing to use vagrant to install ghcjs; over time, it morphed into a whole lot more, so we changed the name. I'd be quite happy if it became useful to more people, and perhaps it would make sense to change the name again if that happened.
This is great! Do you have examples of how cabel-toolkit might be used?
IIUC there's a stack *limit* but it's not pre-allocated. The limit is set at runtime (`ulimit`) on Linux, and built into the executable on Windows.
Julia's performance: my guess is that the major sin in Julia's code is the use of global variables --- compiler cannot guarantee that their type will remain the same. Move them into the function and the performance should jump. Another issue with Julia's performance is the way how it compiles. Long story short, you need to run the code ones (say, on a short time interval) for compilation to be complete (and with all the optimisation it might be a long process) and then measure the time within the same Julia session --- at the moment there is no persistent compilation cache to last between the sessions. Finally, Julia being targeted at numerical computation already has more and better libraries. I would claim its ODE-solvers library is the state of the art, superseding that of MATLAB/NumPy etc.
This may help you: https://ghc.haskell.org/trac/ghc/wiki/Building/Preparation/Linux#NixNixOS 
There is a `shell.nix` file in the hadrian subdirectory which you can use to setup an environment. nix-shell hadrian/shell.nix configurePhase buildPhase
Am I missing something, or do those instructions tell you to clone nixpkgs despite never using the clone?
It would be great if the package description was "This package provides a getHiddenChar function which works reasonably consistently across the Windows, Linux and macOS platforms. getHiddenChar yields a single character from the standard input device with buffering and echoing to standard output disabled."
I have a small issue that I am trying to figure out last couple of days, and I was just gettting ready to ask for some help :) So, would like to have a data Result = Done | Fail type Handle a = a -&gt; IO Result class Action a where act :: Handle a what is bothering me is this. I would like to have a data structure that can hold different Handles eg. String -&gt; IO Result, Int -&gt; IO Result, in some data structure so on some other place I can get one of those Handles and run it. Question is namely I don't know how to write a type of that datastructure that will hold all those functions. As I type this question I have a sense that I am missing something, in the whole picture to complete the puzzle, but my Haskell skliz are not the shiniest! Thank you so much! :)
All these languages add some significant changes and enhancements. But this? https://github.com/HenningTonko/Carrie-Programming-Language/blob/master/Carrie/Compiler/CarrieCompiler.hs
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [HenningTonko/Carrie-Programming-Language/.../**CarrieCompiler.hs** (master → e1c958a)](https://github.com/HenningTonko/Carrie-Programming-Language/blob/e1c958aa7295eab74d506265810edd0219e175d0/Carrie/Compiler/CarrieCompiler.hs) ----
Unless I've misunderstood, don't you simply want a tagged union? data HandleUnion = HandleString (Handle String) HandleInt (Handle Int) You can then have a [HandleUnion], and then pattern match to figure out the kind of handle. There are more complicated ways to handle this, and if tagged unions aren't enough, say so, and I'll write up a longer response.
I wonder, which Haskell extensions do you use on a daily basis ? Are there "safe" extensions that you add in all of your projects ?
See for instance [Danielsson's Total Parser Combinators](http://www.cse.chalmers.se/~nad/publications/danielsson-parser-combinators.html)
Pretty sure OverloadedStrings and GeneralizedNewtypeDeriving are in every project I write. TemplateHaskell also crops up frequently but it can have a huge compile time cost so try to minimize modules that use it so you don't have to recompile them as often. There are a bunch of extensions that are more syntax sugar related and which I enable when it simplifies code. Think tuple sections, bang patterns or lambda case. Fancy type extensions like GADTs, MultiParamTypeClasses, FunctionalDependencies, TypeFamilies, RankNTypes, ScopedTypeVariables, TypeInType and so on have their place but I try to keep their scope to a minimum.
We can view the `Lens` type as either: type Lens1 s t a b = { get :: s -&gt; a, set :: s -&gt; b -&gt; t } or: type Lens2 s t a b = forall f. Functor f =&gt; (a -&gt; f b) -&gt; s -&gt; f t We can go from on representation to the other (I omitted the implementation): lensIso12 :: forall s t a b. Lens1 s t a b -&gt; Lens2 s t a b lensIso21 :: forall s t a b. Lens2 s t a b -&gt; Lens1 s t a b But why is the`Lens2` implementation seemingly preferred over `Lens1`? Is it because we can use `.` to compose them?
It's not hard to make a composition operator for Lens1 either. If you need to modify, Lens1 has to first get, then set. For a list, for example, that means traversing the structure twice. Lens2 only has to traverse the structure once. 
Mh that's strange. It shouldn't actually build much. Did you set up the binary caches as described in the [README](https://github.com/nmattia/websters/blob/b8518f004c150e159e49f5ba9af3c4c8fc5b562d/README.md)? Nevertheless I've pushed a commit that removes the python dependency: https://github.com/nmattia/websters/tree/b8518f004c150e159e49f5ba9af3c4c8fc5b562d. You can remove everything that's related to the slides, as I doubt you'll need to serve my talk's slides. Regarding the incremental building thing, no, it unfortunately doesn't. I'm working on a [hack](https://gist.github.com/nmattia/117f45a643f885f94420b1d2a8bd166b) that should allow any haskell package to be rebuilt incrementally with nix, but it needs some more love. I'm also trying to get a stack project working with nix (so all the package dependencies are handled by stack, but the stack executable, GHC and GHCJS are provided by Nix) but I've run into issues: https://github.com/NixOS/nixpkgs/issues/32847. I'll ping you if I get stuff to work. 
Ok, sure, but we could also have `type Lens3 s t a b = { get :: s -&gt; a, modify :: s -&gt; (a -&gt; b) -&gt; t }`. Is `Lens2` the preferred choice because it is generally has better performance? 
As there are other optics too (prisms, traversals, etc) using a type-class representation let us get right kind of subtyping. E.g. If we compose prism with lens, we get a traversal automatically. If we used concrete representation, we would need n^2 composition operators (which could use single name though) Another point to use Lens2 representation, is that you can write `lens` compatible lenses without depending on the package! E.g. we recently added some lenses to `Cabal` (which cannot depend on `lens` or even `microlens`), and hopefully they will be useful for the downstream users too.
Ok thanks ! On the other hand are there conter-productive extensions that I should avoid as much as possible ? 
I wouldn't call ScopedTypeVariables fancy! And it let's write type-signatures for things you cannot otherwise, which is useful to both beginners and experts alike!
those are some interesting points, thanks
What benefits does type constructor IO (i.e. monadic IO) in Haskell provide over function attribute IO? Both allow us to track effects, and the latter can make it a bit easier to make it clear which types of effects you're using: -- Anything that calls it has to add "using io". attributing io read : Path -&gt; String read path = compiler-level function for IO -- Anything that calls it has to add "using random". using io-&gt;random randomInt : Int randomInt = get an Int using IO for randomness using random f : Int -&gt; Int f x = x * randomInt Is the benefit the conceptual aspect of seeing `IO a` as `RealWorld -&gt; (a, RealWorld)`, and relatedly `IO a` as being a promise of an action, not an actual action? Perhaps the latter interacts with laziness in important ways, I don't know. If it's about sequencing effects, I'm sure some construct could be added like `{{ print "Hello"; launchMissiles; print ", world!" }}`, maybe just glued together with `seq`s. I realise it'd add a whole other layer to Haskell and at the moment IO, state*, and so on are all (relatively) neatly dealt with by types with help from monads, but to me it seems like it'd be simpler in general. (One could use attributes for other things too. This is a throw-away comment and I don't know if it would be feasible or efficient, but e.g. restrict all uses of general recursion to go through one function which provides it, allowing you to track which functions are definitely total) \* to be clear, I'm not suggesting doing away with `State` too, just mentioning it as part of Haskell's unified way of dealing with this stuff. 
&gt; Should I use nix? I'd personally prefer not to as it's a simple project Unfortunately, building GHCJS is not simple, so this is your best bet :)
I think you're right. Maybe whoever wrote this had their $HOME in NIX_PATH or they misunderstood how the angle bracket syntax works? The "assuming nixpkgs is in home" and "cd ~" bits seem to assume that nix-shell implicitly searches the current directory for channels?
ScopedTypeVariables, LambdaCase, ViewPatterns, InstanceSigs, NamedFieldPuns, TupleSections, are a few I use a lot and just turn on by default.
I don't quite get what "attributing" is or what its intended benefits are. In particular, it does not "make it clearer" which type of effects we're using in comparison to monads; you could have a finer-grained effect monad with separate IO and randomness, as it used to be in Purescript until recently, for instance. Having a coarse-grained IO in Haskell prelude is a library design decision, not a language feature.
Yes, that sounds a likely explanation for the confusion. I'll try to find out if I can remedy the instructions.
I am aware of the finer grained stuff you can do with types, like in [Idris](http://docs.idris-lang.org/en/latest/effects/simpleeff.html), so yeah you're right, that was an unnecessary and wrong aside. What I'm asking for is a better story for `IO` that isn't "to track effects", because you can do that by tagging functions with a keyword (and I know some languages do do this, I forget which).
Thanks for the feedback: https://github.com/rcook/hidden-char/issues/3
Thanks for the feedback: https://github.com/rcook/hidden-char/issues/3
What do tags on functions do, what do they restrict or inform? Are there tags for anonymous functions (and expressions) or are tags tied to name binding (which would be awful)? What benefit justifies having a separate tag system and type system instead of just a type system?
I think "insincere" is actually quite a good choice of word in cases such as `Eq` and `Enum`, where the description of what the class is for on Hackage is really rather vague and it can't really be argued that anything contained within could be considered a "law". - [`Eq` docs from latest `base`](http://hackage.haskell.org/package/base-4.10.1.0/docs/Prelude.html#t:Eq) - [`Ord` docs from latest `base`](http://hackage.haskell.org/package/base-4.10.1.0/docs/Prelude.html#t:Ord)
Tl;dr: If you skim over the generated code the article isn't that long. Just read it
OK, fixed it (I think!)
Short story: `nix-shell '&lt;nixpkgs&gt;' -A haskell.compiler.ghcHEAD` By changing the attribute specified by `-A`, you can get the build environment for any package in nixpkgs in the same manner.
ImpredicativeTypes, IncoherentInstances, Strict, NPlusKPatterns, OverlappingInstances (use the scoped versions), Rank2Types (use RankNTypes).
My friend works at Habito and he is a strong developer so I would recommend this offer just because of him. Too bad they are not remote though :(
Tangential to your question: You're buying into all these problems when you use data types that contain functions. They can't be printed (serialised), parsed (deserialised), compared, equated, and so on and so forth. Hence, you may want to consider other representations of these functions. In the simplest case, where you have a repertoire of builtin operations, the representation might look something like this: data Func = Sin | Cos data BinOp = Plus | Minus data FuncOrOp = Func Func | BinOp BinOp You would effectively define a miniature expression language for your problem domain. (Perhaps this is the usual distinction between shallow and deep embeddings. What you're doing looks more like a shallow embedding, whereas I'm suggesting a deeper one.)
This looks like a pretty nice library.
I had imagined doing that, but it would be restrictive. The application I'll be using this idea in, Sound.Tidal, sends sound-generation instructions to SuperCollider. I want a user to be able to mangle their Patterns* according to any function they can program, using any part of Haskell they might want. * a Pattern in Tidal is like a discrete Behavior in FRP: an almost-everywhere null map from time to the onsets of sampled sounds, plus effects like volume or panning.
So my __ultimate__ goal is to build a way to register some of those actions in with a key, and hold it in some data structure, say Map or something like that, which you can query by that same key. Say that data structure is: type X key handle = Map key handle -- THIS IS Actually the part that I am trying to figure out, so it is incorrect, I am puttiing it as a mental placeholder :) data Keys = KeyOne | KeyTwo type ConcreteX = X Key (???) --- This is the point of above questions! registerHandle :: Action a =&gt; Key -&gt; (???) -&gt; ConcreteX -&gt; ConcreteX -- this whould register to collection runHandle :: Action a =&gt; Key -&gt; a -&gt; ConcreteX -&gt; IO Result -- And this is where I want to get After I wrote this, I it seems to me that I don't need `class Action`but I am unsure how to put all of this together :) 
If you look at the history, it did used to tell you to point nix-shell to the right place but something got out of sync when it was edited.
A closure is just a combination of a function pointer and some arbitrary data (the variables being closed over). This is true in any language, Haskell or otherwise. The number of function pointers is always finite and can therefore be statically allocated.
I was looking at [dmjio's library][2] for querying the [Bittrex API][1] and was wondering if I could implement somthing similar using `servant-client`. The ‘public’ part of the API was fine, as there was no authentication and I’ve made a [gist of what I got][3], however the other parts of the API require signing the request (in this case the URI). From their [website][1]: ``` $nonce=time(); $uri='https://bittrex.com/api/v1.1/market/getopenorders?apikey='.$apikey.'&amp;nonce='.$nonce; $sign=hash_hmac('sha512',$uri,$apisecret); $ch = curl_init($uri); curl_setopt($ch, CURLOPT_HTTPHEADER, array('apisign:'.$sign)); ``` I haven’t found existing machinery for signing requests in Servant, so I thought about adding a combinator. (I’ve had a look at the servant-auth package, however this seem orthogonal to what I’m trying to achieve here.) The signature depends on the ‘final’ value of the request, which (I don’t think) we don’t have access to in `clientWithRoute` as we only get the partial request built up so far. We can modify the definition of `Request` in `Servant.Client.Core` (something I wanted to avoid) to add a function^1 `sign :: MonadIO m =&gt; Request -&gt; m Request` (which can be `return` be default), that can be set by the new combinator. I could then update `Servant.Client.Internal.HttpClient` to quite easily implement the signing in [`performRequest`][6]. This is a partial idea, as I’ve only looked at this from a servant-client point of view. It appears that [AWS also uses a similar form of authentication][5], so it isn’t as esoteric as I first thought (I hadn’t come accross it before) and might be useful for other APIs. My questions are: - Is there an easier/better way to do this (ideally without modifying Servant)? - Is this something Servant would consider adding? I'd really appreciate any feedback/advice! ^1 The reason for `MonadIO` is that the signing function may need to get the date (or a source of entropy), however I’m not sure if this would break compatability with other with other libraries as RunClient only has a `Monad` constraint - `class Monad m =&gt; RunClient m where...`. [1]: https://bittrex.com/home/api [2]: https://github.com/dmjio/bittrex [3]: https://gist.github.com/jonathanlking/265d3318f88e83a74b8c331746a8f10b [4]: https://hackage.haskell.org/package/servant-client-core-0.12/docs/Servant-Client-Core-Internal-HasClient.html [5]: http://s3.amazonaws.com/doc/s3-developer-guide/RESTAuthentication.html [6]: https://github.com/haskell-servant/servant/blob/cbd3862f2415f95fd07a06aa897e7ff1b2b40073/servant-client/src/Servant/Client/Internal/HttpClient.hs
I have really mixed feelings about scoped type variables. Iirc these are two main use cases : - Replace proxies with TypeApplications, great but not many libraries use it yet - Unify type variables when using explicit signatures on scoped functions that capture some variables from their context My problems is mostly with the second one. It's fine if the explicit type signature is necessary because of fancy types causing inference issues. But it can be really tempting to write an obnoxiously hard to follow function by closing over a bunch of variables by giving a scoped signature and following the type. I generally try to lambda lift the inner function to the top level while writing and then re-add scoped type variables and free variables when it actually helps readability. That's really subjective, though, and probably colored by me forgetting the explicit forall occasionally.
I see. That's indeed the usual motivation for a shallow embedding: being able to use all constructs of the source language for your DSL. However, how are you going to compile the user's Haskell code to instructions that SuperCollider understands (`sclang` code?)?
Sorry for the (ultra) late reply, have been using reddit less and less. You are correct for standard Haskell code, but it's a bit different for hardware. There's a direct correspondence between the unknown/'X' hardware state and bottom/error in lazy languages like Haskell. Sometimes this is what you want. In an actual production CPU, you would definitely want to use a soft-failing instruction decoder so you could trigger an "invalid instruction" interrupt or something.
Sorry for the super slow reply. I wouldn't want to use `Word` since that doesn't have a specified size. `Word64` would be OK, but it doesn't work with Clash's bit-slicing primitives. `Unsigned 64` has the same semantics as `Word64` but more features.
I mean, it's a very first version and rough draft by someone who's clearly learning as they go (which isn't a bad thing!); I'd call it a great first step, myself. I don't see a need to not compile to rust to make it a "real" language.
My *primary* use for ScopedTypeVariables is to write type-signatures I want to write, not the ones I need to write (latter may be needed more often with MonoLocalBinds enabled by GADTs). Even in map/filter pipeline it's helpful to name arguments to map/filter. And often they are so specific, I don't want to pollute the top level (e.g in app code where everything is exported)
We should create a (backpack) signature for base, then the normal base or chaotic base can just be different implementations, without requiring a patched GHC (unless there's something special about base or the Prelude w.r.t. dependencies). Each module imports the custom Prelude, and the cabal component mixes in one of the base-implementations. The problem is, iiuc, that all transitive dependencies must be built against the signature rather than, well, `base`, which no packages currently do. 
It's not compiling to SCLang. It just becomes instructions for triggering a sampler or a synthesizer in SC. I only need the DSL to allow users to generate Epics and apply unary and binary operators on them. Func in this sample code was standing in for the Epic type, which is like a discrete Behavior in FRP, or a MIDI sequence: It's a series of audio sample onsets, where each onset is paired with settings for effects like volume and panning. Except it's not really a series because many samples can overlap in a single Epic. (Epic is my extension to Tidal. Standard Tidal offers the Pattern type, which is similar but does not let you vary the duration of a cycle.) There is a library that compiles to SC from Haskell: Rohan Drape's hsc3. I tried it as a Haskell noob and couldn't get it to work, and now I'm kind of married to Tidal, but it looked wonderful. (SC offers the best realtime audio generation environment I know about, but the language is awkward.)
Other than the different surface API, how does your underlying approach to controlling echo state compare to the approach in this other library?
same
I don't understand why this instance for `Ord a, Eq a =&gt; [a]` is in the library.
One really boring thing to do would be to equip FuncOrOp with `String` components as well to name each thing, and to base the instances on the embedded `String` values, trusting users to pick unique ones for each thing.
The basic idea is the same except that `echo` works around shortcomings of `hGetEcho` and `hSetEcho`. I could, in fact, build `hidden-char` on top of `echo` I think.
I see, thank you for the explanation. In that case, the shallow embedding you're pursuing is probably indeed your best bet.
Possibly silly terminological question. In Liquid Haskell, `reflect` seems to lift implementations to the type level, whereas in other places I've seen `reflect` as a going in the other way: getting a term out of a type. Is is common to use `reflect` for both directions?
Zero bureaucracy works until you get more than 5 people. Then the disagreements are no longer so easy to solve.
In my experience so far, Slack keeps you more consistently connected, but brings out more arguments in an environment not well-suited for arguing.
Which instance? Which library?
Indeed, the Ord and the Eq instances are both lies, only there to allow me to parse a list of FuncOrOps using Megaparsec. But if, as hdgarrood suggests, I wrapped them in newtypes so that the instances only get used in the parsing context, do you foresee Megaparsec doing anything I wouldn't want?
Haha that's an interesting thought. I wouldn't ask them to do that. But even if I did, the instances still might not be completely right. Many distinct expressions can map to the same function, so the Eq might give false where it should give true, and the Ord might give a &lt; b &lt; c &lt; a' where a and a' represent the same function.
https://github.com/mrkkrp/megaparsec/issues/255
Sadly base and GHC have to be compiled together - you can't recompile base after the fact.
Full stack, extensive Haskell knowledge and deep learning experience in ideal candidates? Coupled with no management structure? Great.
This actually wouldn't be too hard to do yourself. Those lines are just unicode characters.
Onsite in Stockholm? Relocation support? How strict are you on fulfilling all listed requirement (not the nice to haves listed after)?
Thank you a lot. I guess I simply need to learn more about Nix.
Thank you for that.
You are confusing bureaucracy with power of decision.
What you're describing is known as an [effect system](https://en.wikipedia.org/wiki/Effect_system). They have been around as an idea at least since [1988](http://ropas.snu.ac.kr/lib/dock/LuGi1988.pdf). Monadic IO was introduced in [1998](https://www.haskell.org/definition/from12to13.html), 7 years after [monads](http://www.disi.unige.it/person/MoggiE/ftp/ic91.pdf) were introduced more abstactly. Haskell, at the time monadic IO was introduced, AFAICT, had all the language features required for monads and IO, and the only change was to actually _use_ monads for IO; by contrast, an effect system would have required major changes to the language and type system, and wouldn't have solved some of the problems that monadic IO solves (like guaranteeing sequencing).
Honestly I do think there is some substantial potential for unintuitive / incorrect behavior. I would do a lot of digging and figure out exactly why that constraint exists, because if it's there I'm fairly sure that it is used for something non-trivial. The last time I made an instance like that it was only after looking through the source of the library that needed it, and even going as far as to submit a PR to remove said constraint.
Good! I would like to study parsec beginning on this project.
Or it could be that bureaucracy was confused with red tape. You can have plenty of red tape in a 5 person team and equal power of decision amongst all 500 members in a team. English is confusing even before we bring politics into it :)
After research-fumbling through Megaparsec for a while, I asked on its [issue tracker](https://github.com/mrkkrp/megaparsec/issues/268).
Hmm. Don't think we thought about it quite that much TBH; the other contender was "lift" but I think that has several other uses already... :)
There's also "reify" although I completely forget what people use that one for...
Don't know, sorry. I'm not associated with the company in any way; just found the ad and thought it was interesting.
At the moment I am definitely far too unfamiliar with reflex-platform to help with that. Although once I get the hang of it I'm definitely interesting in helping out with that. At the moment I actually can't get `./try-reflex` to work at all. I'm getting (On OS X Yosemite 10.10.5) for the last few dozen lines of output: download-from-binary-cache.pl: could not download ‘https://cache.nixos.org/pm7sbzglayqci1x7asyv3jmar0hi8xdw.narinfo’ (Curl error 35) download-from-binary-cache.pl: could not download ‘https://cache.nixos.org/cqq8yfsf2wxjwyv5bnmnqrwf56yf71jx.narinfo’ (Curl error 35) download-from-binary-cache.pl: could not download ‘https://cache.nixos.org/jd0cnsdy3hnn6fis47pn52rifcndn9sq.narinfo’ (Curl error 35) download-from-binary-cache.pl: could not download ‘https://cache.nixos.org/d8hvvaqigj6az5rhrc4s1fvpbx3vnvk1.narinfo’ (Curl error 35) download-from-binary-cache.pl: could not download ‘https://cache.nixos.org/a59qx3r73cprq169p799r67zh3wvpcng.narinfo’ (Curl error 35) download-from-binary-cache.pl: could not download ‘https://cache.nixos.org/d4kwifvgjxw1w4cj8scnvw7js6av1wgq.narinfo’ (Curl error 35) trying http://tarballs.nixos.org/sha256/13s8wz9gk82cpwskc7ic3fvcpy572g87ny4icmj1apfzrrcpdp1v % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 845 100 845 0 0 845 0 0:00:01 --:--:-- 0:00:01 4567 unpacking source archive /private/tmp/nix-build-ghcjs-eb8670c4b03b4a0ff5dd7ac3f524b410b37051ea-src.drv-0/eb8670c4b03b4a0ff5dd7ac3f524b410b37051ea.tar.gz gzip: stdin: not in gzip format tar: Child returned status 1 tar: Error is not recoverable: exiting now do not know how to unpack source archive /private/tmp/nix-build-ghcjs-eb8670c4b03b4a0ff5dd7ac3f524b410b37051ea-src.drv-0/eb8670c4b03b4a0ff5dd7ac3f524b410b37051ea.tar.gz setupCompilerEnvironmentPhase Build with /nix/store/y1mcm3ilackdqnypv5ida6300adc68cv-ghc-8.0.2. unpacking sources unpacking source archive /nix/store/c2vl55kfqh7nczarh6hk4zic2sbwjj0k-hscolour-1.24.1.tar.gz source root is hscolour-1.24.1 /nix/store/j1ly0zzpnzb8y8ry6k4vi4prk8vwq233-set-source-date-epoch-to-latest.sh: line 7: warning: command substitution: ignored null byte in input setting SOURCE_DATE_EPOCH to timestamp 1466681385 of file hscolour-1.24.1/hscolour.css patching sources compileBuildDriverPhase setupCompileFlags: -package-db=/private/tmp/nix-build-hscolour-1.24.1.drv-0/package.conf.d -j1 -threaded [1 of 1] Compiling Main ( Setup.hs, /private/tmp/nix-build-hscolour-1.24.1.drv-0/Main.o ) Linking Setup ... setupCompilerEnvironmentPhase Build with /nix/store/y1mcm3ilackdqnypv5ida6300adc68cv-ghc-8.0.2. unpacking sources unpacking source archive /nix/store/qdzq366jxz6hh0srvm92q964x9w8frb6-jailbreak-cabal-1.3.2.tar.gz source root is jailbreak-cabal-1.3.2 /nix/store/j1ly0zzpnzb8y8ry6k4vi4prk8vwq233-set-source-date-epoch-to-latest.sh: line 7: warning: command substitution: ignored null byte in input setting SOURCE_DATE_EPOCH to timestamp 1483722960 of file jailbreak-cabal-1.3.2/jailbreak-cabal.cabal patching sources compileBuildDriverPhase setupCompileFlags: -package-db=/private/tmp/nix-build-jailbreak-cabal-1.3.2.drv-0/package.conf.d -j1 -threaded [1 of 1] Compiling Main ( Setup.hs, /private/tmp/nix-build-jailbreak-cabal-1.3.2.drv-0/Main.o ) Linking Setup ... builder for ‘/nix/store/hndkwp9qha3v5m0kpfd9ksm2p50l7501-ghcjs-eb8670c4b03b4a0ff5dd7ac3f524b410b37051ea-src.drv’ failed with exit code 1 cannot build derivation ‘/nix/store/i79k4mnfdvlgjjbmlv0y6b07acl86cy8-ghcjs-0.2.0.drv’: 1 dependencies couldn't be built cannot build derivation ‘/nix/store/698rszdr844d5qcivc6rlzz7hky505x3-stage1Packages.drv’: 1 dependencies couldn't be built error: build of ‘/nix/store/698rszdr844d5qcivc6rlzz7hky505x3-stage1Packages.drv’ failed (use ‘--show-trace’ to show detailed location information)
Yeah the binary caches were set up (well the second time I tried, I think I tried once without setting them up). Thanks for the commit, I'll try and build it soon and let you know what happens! And thanks for the info, that all sounds great!
I'm personally not a fan of `NamedFieldPuns`, it directly leads to a massive amount of name shadowing, which I'm not a fan of. I mean hell `-Wall` literally warns about name shadowing.
Why not use the discrimination library? https://hackage.haskell.org/package/discrimination
This was my first idea, actually! However, the discrimination library turned out quite slow in my benchmarks. Around 40% slower than the vector-algorithms package for my vector of float values. I guess while the sorting is O(n) the constant overhead is quite substantial. Also my vectors are have about 3500 elements on average. Also note that the discrimination library is based on lists. I haven't seen c code yet for sorting vectors. 
AI is dangerous
But not as dangerous as humans.
I've only used it for personal applications, but the ncurses library written by John Milliken was usable for me (a Haskell beginner)
Human make AI, double dangerous
One big issue with extra systems separate from the type system, is that they tend to break down in more complicated cases. For example if you start dealing with polymorphism or higher order functions. How would you model a function with a type like: mkBaz :: Monad m =&gt; (Foo -&gt; m Bar) -&gt; Foo -&gt; m Baz Because I had to make a function like this today, and `m` is sometimes going to be `IO` and sometimes `State`.
So as I currently understand, Cardano is centralised at the moment right? When is the plan to enable Proof of Stake and start Stake Pools?
Usually the inverse of whatever they use "reflect" to mean.
I think in about 5 days there should be an announcement about that, but it should happen somewhere in the first half of 2018.
This seems okay... I might try to design tests that focus on the external API only, ignoring that the calls are happening from inside a web server. You could write a few tests for someapicall (or a pure version of it) when the service is available and unavailable. You can abstract the essential part of the callback handler as a pure helper function, then write tests how the handler responds when it receives a successful response and a failure response. To have some tests that also exercise the full behavior (still ignoring that it is happening within a web server), I would start by adding some persistent state to track outstanding API calls and then write tests that exercise different combinations of the persistent API calls and notifications receiving, including a response receiving after a timeout period.
It looks like 35 is CURLE_SSL_CONNECT_ERROR, so I think you may be having an issue with certificates. Can you try running `curl https://cache.nixos.org/d4kwifvgjxw1w4cj8scnvw7js6av1wgq.narinfo` to test whether it works on its own? Also, it may be worthwhile to try reinstalling nix if you installed it some time ago. We don't test on Yosemite anymore, but I'll be happy to work with you to get this working, and hopefully there will be a fix I can apply either upstream in nix or in reflex-platform. Feel free to hit me up anytime in #reflex-frp.
Seems appropriate in this case, then :)
May I ask what you plan to implement with it? I am writing a new GUI framework at the moment (PhD work) and I am collecting My GUI framework is cross-platform (only dependency are Haskell packages). Generic code allows the same app to be viewed as a standalone GUI and as a Webpage/Webapp.
A terminal game. btw it sounds like your framework is in the spirit of threepenny-gui, is that correct?
Hi, I'm the author of Brick. For what it's worth, before I took over maintainership of Vty, Corey O'Connor (the previous Vty maintainer) started (but did not finish) a pull request for Windows support. It has been a while so I don't know what state it is in, but I'd certainly be happy to work with anyone who wanted to revive it, or even start over. In particular it'd be helpful to me if whoever wanted to do it had a good understanding of what Windows support would require, because I don't. :) https://github.com/jtdaugherty/vty/pull/1
But soon AI will make human batteries so triple dangerous.
Not at all. It's one GUI framwork and the main backends are: FLTKHS, Threpenny-GUI, and also a SDL2 backend. There is also a wxHaskell backend, but this might not be needed if the others work well. 
Could you send me a link to your paper?
The sprite sheet looks nice! Up vote! Do you have another link like this one? I might program what you need for myself. I would a nice demo for my [GUI library](https://www.reddit.com/r/haskell/comments/7l203h/what_haskell_programslibs_need_a_gui/).
What's preventing `brick` from working on windows? It's awesome enough that in your shoes I might spend some time trying to get it working before moving on.
Small nitpick that I found: in your proof by induction, you never explicitly mentioned that it was a proof by induction on the range `i..j`. The "on" part is very important in proof by induction because the phrase 'proof by induction' doesn't actually say anything about the proof and it's structure; kind of how saying "I'm turning on" doesn't tell you what electronic device you just powered up.
aH!
Do you suspect that has been what’s behind the recent surge, or is there something else going on?
Since you seem to have posted this question for the third time now, I feel compelled to share my thoughts and ramblings. * What exactly are you trying to achieve? Are you repeatedly sorting smallish vectors, with some other operations interleaved? Or are you sorting a lot of these vectors in one go? Could you provide some sample code / pseudo code / problem description? * Do you actually want to use a GPU now, just parallelize, or just make things faster using any means possible? * Would a solution of your algorithm already be available via FFI? Or do you think you would find it easier to recode this critical loop in another language? * Have you checked literature like *GPU Computing Gems*? From what I have seen, they tend to use similar terminology, like reductions, scans, and so on. * In what way are the examples you posted incomplete? The Radix sort algorithm appears to be implemented, though I didn't test it. The most important question is of course if the `Accelerate`/`Repa` models fit your bill. I personally find the APIs very clunky and had to [struggle a lot](https://www.reddit.com/r/haskell/comments/68pc7a/equational_reasoning_with_multidimensional_arrays/) when first using them. While nowadays I know a lot more about things like type families for instance, I still wouldn't make them my first choice. Unfortunately, there isn't exactly a lot of people who do number crunching in Haskell. There's the [Data Haskell](http://www.datahaskell.org/) folks of course, and if you haven't you should ask around in their Gitter channel. Other than that, don't expect a huge number of Haskellers to be able to help you in the Numerics department. This isn't meant to offend anybody, it just reflects my perceived reality that we don't have a critical mass in this area. My personal experience of doing numerics in pure Haskell: * `Accelerate` / `Repa` are nice to check if your problem is "embarrassingly parallel". I did not find them very performant, but could probably have squeezed out more, given more experience. If your problem is inherently serial and requires mutation for memory efficiency / cache reuse, you're going to have a bad time. From what I have seen, `Repa` is not actively developed anymore (I might be wrong of course). * The `array` library is vastly underrated. While it doesn't have a fancy stream fusion framework, it doesn't deserve to be *completely ignored* like many people seem to do. However, some optimizations only apply up to the three-dimensional case. I needed to use four-dimensional arrays once and couldn't get indices unboxed no matter how hard I tried. * Instead of reimplementing an unboxed four-dimensional index tuple, I decided to YOLO it and just manually index into vectors. This is of course very low-level, but using indexing functions is a workable solutions if you want to exploit symmetries for instance, or just want to be sure of what's going on under the hood.
No. I'd say it's because of interviews that Charles gave recently and overall concept of Cardano and ADA which earned recognition from the crypto community because it offers some pretty intelligent solutions to problems that have become apparent with other crypto currencies. Still, I'm a bit skeptical about practical viability but only time will show.
I didn’t even realize this was the Haskell subreddit. Assuming that means its written in Haskell?
Thanks again for the long post. I updated the question (see EDIT). The goal is to improve the performance of the rasterific library: https://github.com/Twinside/Rasterific For now I want to sort one vector in parallel (low hanging fruit as only 1 function needs to be updated. Then sort more vectors in parallel.) I was mainly thinking about using Accelerate AVX / SIMD speedup and only later run on the GPU (since the latter is less portable). So parallel and AVX/SIMD speedups and *not* the GPU in the near future. I have searched a bit for C implementations but still need to keep looking in this regard. There is also inline-rust. Of course, I would prefer to implement all in Haskell if this is not too difficult. But I am open to inline c. There are some quicksort algorithms implemented in C that I can check out. Thank you for all the advice!
Regarding reposts: I wanted to change the title of my first post. This is not possible in reddit, unfortunately. So I deleted the post and wrote a new post. This resulted in a mess.
Yes, your assumption is correct :)
Could you maybe narrow down which function you want to speed up? Would it be `sortEdgeSamples` per chance? The book "Structured Parallel Programming: Patterns for Efficient Computation" goes over parallel sorting in great detail, using `OpenMP`, `TBB` among others. I am not an expert in using vector instructions to speedup sorting implementations, but [ghc-prim](https://www.stackage.org/haddock/lts-10.2/ghc-prim-0.5.1.1/GHC-Prim.html#g:29) exposes some SIMD instructions as well. Of course, parallelizing the sorting vector itself might not be worth it if the vector only has a thousand elements or so. If you can produce a lazy list of vectors to be sorted, you might be able to map your sorting function over it in parallel. Just to make sure, you do know about [Simon Marlow's book](http://chimera.labs.oreilly.com/books/1230000000929), right?
The Windows console is very, very different from any equivalent in the *nix universe. There are some really long, in depth articles about the differences but it boils down to them being totally different architectures, created at different times to serve different needs, and backwards compatibility reasons.
Ah, that's a bummer.
My advice for OP is that if you need a cross platform **terminal** UI, then you may want to strongly consider just implementing your code for *nix systems and recommending Windows users use the Windows 10 "Windows Subsystem for Linux" (WSL). 
Hi, I'm the author of Brick. Since this is even more relevant here, I'll re-pos a comment I left elsewhere: &gt; Before I took over maintainership of Vty, Corey O'Connor (the previous Vty maintainer) started (but did not finish) a pull request for Windows support. It has been a while so I don't know what state it is in, but I'd certainly be happy to work with anyone who wanted to revive it, or even start over. In particular it'd be helpful to me if whoever wanted to do it had a good understanding of what Windows support would require, because I don't. :) https://github.com/jtdaugherty/vty/pull/1
How would a version without `INCOHERENT` look? Also, would using `Generic1` instead of `Generic` let you derive more instances?
nice
We got half the haskell space working on it. 
You could use K-Means clustering to derive the pixels that belong to one single sprite. This way you solve the problem in a generic way (because the sprites have different sized!). The algorithm is described here: http://simonmar.github.io/pages/pcph.html
For all intents and purposes, the answer is that code is never generated by the GHC runtime after the initial compilation if the application is a self-contained Haskell application.
Look up Selenium and PhantomJS. I do not know the state of haskell drivers for these technologies, but they solve a very complicated problem and are fairly painful to work with.
Thanks!
For node.js I'd use https://github.com/GoogleChrome/puppeteer. The underlying protocol is open (https://chromedevtools.github.io/devtools-protocol/). There appears to be a Haskell package which implements that API: https://github.com/ThomasCrevoisier/chrome-remote-interface-haskell. But I've never used it so I can't tell anything about the quality. Another option is to use the webdriver protocol, which is for example used by selenium. You can use it to drive all of the major web browsers, it's not limited to Chrome. The Haskell package (https://hackage.haskell.org/package/webdriver) is reasonably complete and you'll be able to find more examples than for the chrome-remote-interface-haskell package. I would stay away from PhantomJS because it's not maintained anymore. The maintainers stopped working on it once Chrome Headless was released. https://www.infoq.com/news/2017/04/Phantomjs-future-uncertain