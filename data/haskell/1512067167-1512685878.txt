&gt; with the additional effect of making that particular argument strict There are no arguments, please see [the other answer](https://www.reddit.com/r/haskell/comments/7fmjld/ghc_feature_proposal_warn_on_recursive_bindings/dqcvwah/).
I'd like to see return removed entirely (in a presummably distant future), instead of leaving return = pure. I understand it would break a lot of code, but it seems like the clean thing to do.
I think tomejaguar's comment probably answers your underlying question. There's nothing in particular wrong with `liftA` or `liftM`, except that `fmap` is more general, more idiomatic, and sometimes more efficient. They mostly only exist for historical reasons, or to define instance Functor SomeDataType where fmap = liftM where you already have a `Monad` instance defined (or similarly for `liftA`/`Applicative`). Although if you do this then obviously `fmap` will be no more efficient than the others.
The only other way I could think of doing it is if they made `Ord` [`Deferrable`](https://hackage.haskell.org/package/constraints-0.9.1/docs/Data-Constraint-Deferrable.html).
This is the a problem with a language not with the concept of those type classes. We should be able to extend type class hierarchies by making them more granular after the fact. `Semiapplicative`(`Apply`) is very useful and gives us consistency `Semigroup`.
There was once a proposal for adding superclasses after the fact by taking a subset of the members from a larger type class. 
This is actually pretty cool because it gives us stronger constraints and free theorems, but it runs into problems once we start working with say tensors in the category of functors. 
Return is a straight up bad and unintuitive name. I personally think `just` is a really good name but we are probably stuck with `pure`.
`liftA2 f x y` is identical to `f &lt;$&gt; x &lt;*&gt; y`, and works in just as many circumstances. It is true that `liftM` should generally be avoided though.
&gt; is there any reason that cause the server to stop? Uncaught exceptions would be the most obvious cause. Of course execution can also just reach the end of an action, but this is trivial to prevent by using e.g. `forever`. &gt; I did not figure out the way to combine several Wrap application into one so I though about making 2 web server. the thing is how to look at the request? Well, `Application` is just an alias for `Request -&gt; (Response -&gt; IO ResponseReceived) -&gt; IO ResponseReceived` (it used to be `Request -&gt; IO Response`, which is morally equivalent, but makes it hard to write efficient streaming code), so the whole dispatching is really just going to be something like: dispatch :: (Request -&gt; Bool) -&gt; Application -&gt; Application -&gt; Application dispatch isMatch appYes appNo request respond = if isMatch request then appYes request respond else appNo request respond 
You can combine server in the same way you combine API's. So type API = UserAPI :&lt;|&gt; PostAPI userServer :: Server UserAPI userServer = UserHandler1 :&lt;|&gt; UserHandler2 postServer :: Server PostAPI postServer :: PostHandler1 :&lt;|&gt; PostHandler2 server :: Server API server = userServer :&lt;|&gt; postServer 
The `f &lt;$&gt; mx &lt;*&gt; ... &lt;*&gt; mz` idiom is more general than `liftA2` because it works with functions with more than two arguments, while `fmap` and `f &lt;$&gt; mx` are more general than `liftM` because they work with type constructors which have a Functor instance but not a Monad instance.
Thanks all. Very helpful.
Essentially, lift is for taking a function that produces a monadic effect, like `ask` or `put`, and pointing it to the proper level of a 'stack' of monads in a monad transformer. The `mtl` library went and defined all of this for us given the usual monads you use on an everyday basis, so unless you are building your own monad and elevating it to the level of a monad transformer, you probably don't need to ever use `lift` in your code. Functions like `liftAx` or `liftM` are basically `fmap` - They are for applying a function to a scope enclosed by a type. They're different from the `lift` function discussed in that article. As a rule, don't use `liftA` or `liftM`, as you can instead use `fmap` and it will do the same thing. Don't use `liftMx`, all Monads are applicatives, so instead use `liftAx`. For extra points - `liftA2 (:) rollDie (rollNDice (n-1))` is the same as: `(:) &lt;$&gt; rollDie &lt;*&gt; rollNDice (n-1)` To more easily understand what is happening there, you can use the applicative instance of list: `(,) &lt;$&gt; [1] &lt;*&gt; [2]` `(,,) &lt;$&gt; [1] &lt;*&gt; [2] &lt;*&gt; [3]` Generally, we prefer using `&lt;$&gt;` and `&lt;*&gt;` because it's a fairly well established idiom and it reads a bit nicer, but I've found that sometimes it can be a little easier to use `liftAx` in some situations, depending on what you're doing.
And ‘+rts -N ...’ etc
IMO it's very misleading to call `f &lt;$&gt; x &lt;*&gt; y` more general than `liftA2 f x y` for that reason. I mean if you want 3 arguments you can always do `liftA2 id (liftA2 f x y) z` if you really wanted to, so technically there is no difference in generality, only perhaps in readability.
Title is funny !
There is also the reflection/reify/tagged packages which are my preferred method for setting up reader-like values if they are immutable because they allow you to access the reader from within your type class implementations (which is otherwise impossible).
`Reader` lets you have a "context" of stuff that doesn't change. But you can alter that context and run it in a sub-block. Consider a logging monad that supports adding a log prefix to make it easier to tag certain lines. do log "Hello" addContext "Foo" $ do log "Inside of foo!" addContext "Bar" $ do log "Inside of foo and bar." This would result in the output: Hello [Foo] Inside of foo! [Foo] [Bar] Inside of foo and bar. We can implement this easily using `ReaderT` and local: type Context = [String] log :: String -&gt; ReaderT Context IO () log str = do ctx &lt;- ask liftIO (putStrLn (format ctx ++ str)) addContext :: String -&gt; ReaderT Context IO a -&gt; ReaderT Context IO a addContext prefix = local (\ctx -&gt; prefix : ctx) We've also got a parser for XML that uses `ReaderT` for keeping track of context inside of the document, so we can describe exactly where the parse failed. When we `throwError` to report a problem with the document structure, we grab the context from the `ReaderT` at that point and bubble the path back up to the top. Because `Reader` ensures that the state changes are local, we don't have to worry about unsetting or modifying state, resetting things to "normal" is handled automatically.
You can represent the vectors as lists of ints. The scalar product of them then is `scalarProduct v w = sum ( zipWith (*) v w )` If you then choose a fitting representation for your Matrix you can then calculate x^T Hx.
&gt; when I start needing random numbers Also consider using [MonadRandom](https://hackage.haskell.org/package/MonadRandom-0.5.1/docs/Control-Monad-Random-Class.html): rollDie :: MonadRandom m =&gt; m Int rollDie = getRandomR (1, 6)
I don’t think you talked much about refactoring and maintainabilty, but the latter approach you used makes it much easier to extend your application with a new behaviour.
Per my tweet at the author, `Maybe` is of limited use for data validation because the failure mode doesn't carry any information. `Maybe -&gt; Either` when something can fail in more than one way `Either -&gt; Validation` when something can fail more than once hackage.haskell.org/package/validation http://hackage.haskell.org/package/either-5/docs/Data-Either-Validation.html 
I've used `friday` to crop images and found it to be ok, you have to do to much type coercion with inline signature s for my tastes. Admittedly I only dealt with PNGs. What are your issues with it?
It's built on the same machine it is running the binary, using this buildpack. https://github.com/mfine/heroku-buildpack-stack.git I use Hpack and local and Heroku versions both use same file which have specified only this: executables: zoobehavior: ghc-options: [-O2] Kinda noobish i know :) 
I will try these flags first thing in the morning, thanks! :)
If the randomness does not depend on the computed values it can just be passed as a list to the function. E.g simulateGame :: GameState -&gt; [Int] -&gt; [GameState] simulateGame initialState diceThrows = _ main :: IO () main = do g &lt;- getStdGen let ds = take 10 . (map mod 6) . randoms $ g simulateGame mkGameState ds 
[servant-generic](https://github.com/chpatrick/servant-generic) is interesting for specifying your endpoints as records instead of trees of `:&lt;|&gt;`, it helps you get better error messages too (which you'll soon find out can be obscure to debug)
You will have to do research on each thing and customize it to fit your needs, that flags above are just prompts.
You will have to do research on each thing and customize it to fit your needs, that flags above are just prompts. 
I think it was pretty clear that he was just exaggerating in a hyperbolic way. Just so you know. It's really weird seeing people who don't understand simple ideas like nuances in speech.
The general mathematical technique is to start with a description of your problem, a description of your goal or how you know you've solved the problem, &amp; a description of your initial information. Then figure out how to subdivide the path from the things you already have to the things you need into a path through something you need but don't have but might be able to get &amp; can use to reach your goal, starting by reducing the descriptions to formalism or things that have mathematical meaning. For anything vague or undefined, look up the definition, unless the real problem is figuring out what you mean and coming up with a definition. Keep track of how you're transforming definitions, making inferences. The first step in formalizing things to the point where you can start writing code is to figure out the types of everything involved. The problem right now is you don't know the type of thing you're being asked to do. Working out the types on paper means they don't have to exist in the Haskell type system, so you can write types like "A number k such that k &gt; 20 &amp; k &lt; 22" and "length-5 list", &amp; after the fact replace types you can't express with means of generating values that enforce their interpretation as things with the required properties (or, at least that give error messages when they don't). Hole-driven development helps codify how that organizes into an implementation: T is the transpose, &amp; its type here is effectively (n-dimensional column vector) -&gt; (n-dimensional row vector). You can use type definitions to organize the different roles of row &amp; column in the expression. `transpose :: ColVect a -&gt; RowVect a` Vector-matrix and matrix-vector multiplication have types as well. Row and column vectors are treated as matrices for the purpose of multiplying a column vector-row vector pair. `vecMatMult :: Num a =&gt; RowVect a -&gt; Matrix a -&gt; RowVect a vecMatMult v m = _vecMatProduct matVecMult :: Num a =&gt; Matrix a -&gt; ColVect a -&gt; ColVect a matVecMult m v = _matVecProduct exprOnRight :: Num a =&gt; RowVect -&gt; Matrix a -&gt; ColVect a -&gt; a exprOnRight rv m cv = _exprOnRightVal` Those holes can then be replaced with implementations using terms that have holes in their own definitions. This means that the problem has been subdivided into a new need (to fill the holes) and what you know about the problem (the typing of expressions plus the inputs x, H, &amp; N). 
You may be interested then in [Project:M36](https://github.com/agentm/project-m36/blob/master/examples/blog.hs) written in Haskell with strict algebraic data typing even at the database value level.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [agentm/project-m36/.../**blog.hs** (master → 7905d57)](https://github.com/agentm/project-m36/blob/7905d57afd412951298a30c3c3a18a44f753ba95/examples/blog.hs) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
Can you expand on the problems?
Haskero on VSCode is nice. I also liked the ghc-mod integration in Atom. There's an IntelliJ plugin but I have no idea how good it is.
I tried it once, there was a lag on every keystroke. I would put it in the 'literally unusable' category. Another vote for atom + plugins here.
So last time I dived into Haskell. I actually went with Haskero and VSCode. It was pretty good, but not good enough. My main gripe was: * No way to search for reference across the project (Not just the file) * No automatic imports and stuff * Many times errors would remain even after being fixed. (Had to close and reopen folder in VSCode to fix this) So I guess there hasn't been much progress in IDE-land for Haskell in the past year :(
You really should consider a vim or emacs based approach. I have tried various editors and prefer vim over any IDE, particularly in a language like Haskell.
&gt; So I guess there hasn't been much progress in IDE-land for Haskell in the past year :( There’s been a ton of progress with Haskell IDE Engine in the past year. I’m not sure if it solves those specific problems, but it’s by far the most fully featured IDE experience out there right now. It’s an LSP based system, so you can probably get it to work with any editor that has an LSP library pretty easily. But it works great in VSCode
Although vim and emacs's ability to search a project, grep things, etc is generic and not specialized for Haskell. Haskell also doesn't have any tooling to facilitate any of this, so I can see how this would get pretty frustrating. (I know I've been frustrated by tooling more than once)
I mean there are VIM plugins for various "fun" features. So Haskell does have tooling for facilitating things like that, from the IDE engine to hdevtools to ghcmod. 
&gt;Please no emacs or vim. I am spoiled by Jetbrains products Turn back then. There are no commercially viable IDEs for haskell. Anything you'll try would feel crude and inferior to Jetbrain products. That is...anything besides emacs and vim. I'm emacser myself. And despite having extensive experience working with IntelliJ IDEA and Visual Studio, I'll never trade my emacs. Those 2 are slow and awkward behemoths in comparison. 
Is this actually a good idea. It seems like it is to me but I pretty new to Haskell and don't have an informed view.
I already knew about Haskell-ide-engine. But last time I checked it only worked with GHC 8.0.2. Also I see project wide references are a planned feature and not yet implemented. (Has been like that for over a year) Anyways been rooting for haskell-ide-engine. Hopefully it pans out. In the mean-time I'll keep pestering Jetbrains to make a product for Haskell. The funny thing is, it's a chicken and egg problem. If my company was into Haskell big-time, then IDE would happen within months, but to get my company into Haskell, I need smooth IDE and tooling. What a mess.
Typical solutions for project-wide references are grep integration in your editor, hasktags, and sometimes hoogle. Not great, but it's something.
Honestly the main reason I won't trade emacs is because I can do everything in one editor. The need for a zillion different editors in the IDE world is really frustrating.
Using `ExceptT` can be tricky, because it *does not handle exceptions*. See [this post](https://www.fpcomplete.com/blog/2016/11/exceptions-best-practices-haskell), which takes the extreme other view. Making your `App` a `MonadIO` opens the door to doing a ton of unconstrained side-effects in a way that's extremely convenient right-now, but also inhibits refactoring and abstracting side effects in a way that makes testing easy. I'm starting to be in favor of defining more clear domain boundaries and interfaces, and having wanton IO is a good way to make that difficult. We're consolidating services at work, so there's a patch to get one of our services to use a database instead of calling an HTTP API. Since the HTTP API was abstracted into a client datatype, it was trivial to provide a database backed record instead, and the switchover was seamless.
It's not a bad idea, but like all ideas it's good only under the right circumstances. The problem with globally using `ExceptT AppError` is that it's not very different from using `SomeException` in the `IO` monad. After all, what are you going to do with `AppError` anyway? You're probably just going to `show` it. I don't think `ExceptT AppError` really adds any layer of type-safety either, since if each and every action in your application will have `ExceptT AppError` attached to it, regardless of whether it'll actually throw any exceptions, you'll end up using them in a way that doesn't take into account the fact that they may throw an exception. Then why not just use regular exceptions? BTW, I'm not really suggesting you should use exceptions, the point is, when you look for a one-size-fits-all monad you'll just end up with `IO`.
&gt; Many times errors would remain even after being fixed. (Had to close and reopen folder in VSCode to fix this) Hmm, I almost get the feeling this is on VSCode and not just Haskero specifically 🤔 The hie-vscode plugin has the same issue I feel, with rapid saves, and it has no code share with Haskero.
It works in Atom and Neovim also (and there is some work on the emacs LSP client, but don't know the status of that one) :)
&gt; But last time I checked it only worked with GHC 8.0.2 Yeah, unfortunately it is blocking on ghc-mod (which is blocking on cabal-helper) supporting 8.2.x, because of the major changes to cabal 2.0 with backpack et al. 
Meh, I wanna like emacs, but it's generally so damn slow I just don't have the patience for it. I prefer vim, but it lacks a lot of things UI-wise, which there are some attempts to bring support for with the GUIs for Neovim. Atom with atom-haskell-ide or using HIE works *very* well, and VSCode with either Haskero or the HIE LSP also works great, so there are those choices too.
I get this sort of thing frequently with intero on emacs. I think it has to do with how the tooling isn't super robust at behaving "sanely" in the face of non compiling code. Once things stop compiling, the tooling works decently, but some errors mask other errors, and errors tend to mask other things, etc.
A few shameless self-plugs: If you go Atom, you can quickly get set up with [atom-haskell](https://atom.io/packages/atom-haskell) for the ghc-mod based workflow or [ide-haskell-hie](https://atom.io/packages/ide-haskell-hie) if you want to use HIE. Unfortunately, for both, ghc-mod is waiting on 8.2 support :( If you go VSCode, I'd recommend [hie-server](https://marketplace.visualstudio.com/items?itemName=alanz.vscode-hie-server) for HIE or [haskero](https://marketplace.visualstudio.com/items?itemName=Vans.haskero) for Intero support (in case you work with 8.2 projects). It's also worth checking out [ghci debugger](https://marketplace.visualstudio.com/items?itemName=phoityne.phoityne-vscode) which I only discovered recently, so haven't spent much time with yet. For Neovim I personally try to polish [Spaceneovim](https://github.com/Tehnix/spaceneovim) from time to time. 
IntelliJ-Haskell is really nice. https://gist.github.com/androidfred/a2bef54310c847f263343c529d32acd8
Can you give an example of this. Surely both and HTTP API and a database API both require IO.
&gt; BTW, I'm not really suggesting you should use exceptions, the point is, when you look for a one-size-fits-all monad you'll just end up with IO My initial motivation for looking at this is I'm struggling to combine `logging-effect` and `pipes`, which I use quite a lot (or should I put it another I *intend* to use it quite a lot!) and this seemed like quite a nice approach. Both require IO so it seemed like a reasonable approach.
Do you even lift bro?
They do. The problem is if your `DB` is a `MonadIO`, you can unprincipled :: DB () unprincipled = liftIO $ const () &lt;$&gt; get "facebook.com" which violates the spirit of having a `DB` monad in the first place!
I just tried haskell-ide-engine with vscode on a nightly-2017-11-27 stack project (GHC 8.2.2). It seems to work as advertised except for missing hoogle documentation in the tooltip. The "Known Issues" on the plugin page is a little misleading. It means if you do a naive installation, you can only use hie with 8.0.2. In my case, I used a slightly-modified version of the `stack-8.2.2.yaml` to build hie.
The aim of this blog was to explain the rationale behind these design choices, why does the language impose certain restrictions, how to follow the chain of constraints until GHC is happy, and so on. Refactoring and maintainability become easier, once these things are understood.
&gt; The Haddocks already support collapsible examples, they're just not commonly used. Since when and what syntax? 
So is the argument then that we want to avoid exposing the IO interface to the API consumer, instead preferring to only expose the functions that we so choose?
A way to interface with OCaml code. I am writing a bridge to use lambda prolog in Haskell right now. Lambda prolog is available in the form ELPI interpreter that includes also constraint support. The problem is that the only way to call OCaml code is going via C FFI. This is not good in my eyes. 
I think the conversation tends to come down to one's editor philosophy, I have been using vim+terminal for all my coding for a while now and love it, but it's because I don't treat vim as an IDE. I don't use any of the numerous IDE-like plugins available for vim as they seem to be unnecessary to me. Ultimately, I think with some effort vim/emacs+terminal can give you everything you need to code with better editing paradigms than IDEs. However, IDEs have the benefit of taking people from not coding to coding with decent efficiency very, very quickly, which is why I think they see such heavy usage. They are the fastest way to get people up and running in a standardized way, which is a great thing, but I do think that the vim+terminal (yeah yeah, emacs too) model is more effective in the long run.
Kinda funny that you say emacs is slow and then say atom works great. :)
If you use a Mac you could try: http://haskellformac.com/
Well at least you have to opt-in to cheat via writing `liftIO`, so it's not that bad. I don't feel strongly about it being available (there's plenty of other ways to cheat in Haskell anyawy), but I do try to avoid using it.
Another approach would be newtype AppM c e m a = AppM (LoggingT (ReaderT c (ExceptT e m)) a) That has enough flexibility that you can guarantee a particular action does no IO, never returns `Left` and doesn't read from the context.
I just suggested it because it's the closest thing to a parser framework in `base`. Of course, `read . show` should always be equal to `id`.
"emacs is slow" - ehhhhh not really. Maybe your use of it is slow, but the software it self is snappy, especially compared to atom. Vim nay be a bit faster but probably not if using command-line emacs.
&gt; Functions like liftAx or liftM are basically fmap Minor clarification: `liftA` and `liftM` are exactly the same as `fmap` (unless you have non-law-abiding instances). `fmap` should always be preferred unless you're trying to provide compatibility with pre-AMP versions of GHC. All the `liftA2`, `liftA3`, etc. functions are not the same thing as `fmap` though.
Although `liftA2` is identical to `f &lt;$&gt; x &lt;*&gt; y`, it may perform better since in the newest version of `base`, it's been added as a typeclass method of `Applicative` and can be given a more efficient implementation depending on what the actual type is.
I am using https://github.com/emacs-lsp/lsp-haskell. It is starting to get pretty usable.
The million IDEs thing is exactly why I switched to vim. It's exacerbated by the fact that some IDEs are far worse than others, so your efficacy in a language becomes dependent on the quality of the IDEs built for it, which is crazy to me. Why should my editor have any bearing on my decision to use one language over another? Somehow we developers spend all of this time creating abstractions for building software in a modular, minimally dependent way, yet we keep creating incredibly tightly-coupled toolchains. I was on a project that had a dependency on a *visual studio-specific testing library* I mean, what the actual fuck. You have your editor choice infecting your goddamn code! It's like we took the entire body of knowledge of good software design and just said "lol, fuck that."
May I ask what vim lacks in UI? I have been using it exclusively for coding for quite a while now and I can't think of anything.
I think there is a way to get rid of most of the complexity involved in mocking the MonadToken typeclass, by reworking the design just a slightly bit. The detailed explanation got out of hand in terms of length, so I posted it here instead: https://deque.blog/2017/12/01/answering-r-haskell-how-to-unit-test-code-that-uses-polymorphic-interfaces/ This would be my take at the problem: I hope it answers the question correctly and might help you in your struggles.
&gt; does no IO How so?
Consider this: should one's editor choice really influence what language one uses? It seems quite strange to me to have one's choice of language to learn dependent on the IDEs that been built for it. How one manipulates the text and files that makes up a codebase should be completely irrelevant to the merits of the language itself. Further, the ergonomics of having to radically alter your editing environment when you want to program in a different language seems to be really poor. These considerations (and many others) are what cause so many people to prefer vim/emacs (or atom/vscode, I guess) over IDEs.
I wouldn't call it 'completely irrelevant'. The experience of programming should be a happy one. How you manipulate language text is a substantial part of the programming experience; if that sucks, then your experience is going to be diminished, and your happiness. 
Your argument is correct in theory but not practical. Try convincing 300 people to switch to language with poor tooling vs a language with first-class IDE and tooling. It's impossible in an corporate setting. Just see the rise of Kotlin and Rust. They have such rapid adoption in part due to first class commercial tooling. Companies are willing to drop $600/yr per dev license for 1k+ devs, but they won't invest $600,000 to develop one, cuz risk.
I agree that it is an extremely important part of the programming experience, but I think one's enjoyment of editing text should be abstracted away from any particular language, because otherwise the editing bears influence on technical decisions (like the OP trying to decide if they want to pick up Haskell again, or a company considering the presence of IDEs in their evaluation of the state of a language's toolchain). It introduces a tight coupling in our toolchain and (in my opinion) unnecessary dependencies.
Until someone smashes your window and steals the seat.
You know that a value of type `AppM Context Errors m ReturnVal` does no IO because `m` is polymorphic.
I found that stacking too much monads, while it looks like a good idea at first, is cumbersome on the long term. It doesn't add much security and is complex to understand after a while. Instead now I put everything in a single StateT (state, config and logs). My signatures looks cleaner. I express that view here: http://www.corentindupont.info/blog/posts/Programming/2016-08-06-Haskell-hard.html
Just throwing this out there but if you can tolerate mac only http://haskellformac.com/ is a pretty nice Haskell IDE. It is aimed at initial learning so it is most valuable during the transition period. Cost is low. Wouldn't shock me if for a site license it would go much lower, possibly free or near if the author wanted prestige clients. 
I think it's mostly just a matter of culture and experience. If all of those 300 people had started with my proposal from the get go, then the editor becomes immaterial to the language consideration, because they can simply use the same tools they have known all along. The fact of the matter is that the current model forces developers to create an entirely new workflow for every single language they use (well, most of them, anyway), which to me seems rather wasteful. For what its worth, there are indeed quite a few dev shops that almost exclusively use text editors over IDEs, which I think speaks to the idea that this is more of a matter of developer culture than anything else.
I think the large range is due to the different levels. My guess is that the lower range at around ~180k is for Senior Engineer while the higher range at ~350k is for Staff Engineer.
I don't see what prevents throwing a `liftIO` in there. Or `lift` it all the way up to base.
Could it be that that Heroku routing infrastructure is the bottleneck? That used to be the case with other projects I worked on at least.
You work for Jetbrains?
If you use `liftIO` or `lift` then the type will be `AppM Context Errors IO ReturnVal`. 
For those like me who don't get what automatic imports are, here's a [link](https://www.jetbrains.com/help/idea/auto-import.html). Don't automatic imports lead to dead code? Or is there some automatic burninate for that?
[removed]
Haskell is also less dependent on heavy IDEs by virtue of its design.
Every editor that has LSP (Language Server Protocol) integration (e.g Atom per plugin) can be a decent Haskell IDE. Just get the Haskell-IDE-Engine and you are done. (Personally I use Vim with the HIE, but it works on many Editors)
It would be great if there were a simple cheat sheet for emacs for IDEA users. I use spacemacs for Haskell development, and I still haven't figured out how to do everything i want. Stuff with tags (jump to tag definition, rename tag) doesn't seem to work consistently or at all.
Unfortunately, no. We are a customer with tons of licenses is all.
Jump to tag is just standard emacs M-. But in order to generate tags you need to install hasktags. I do not know whether spacemacs install the constellation of needed utils itself. I'm just using vanilla emacs and follow instructions for intero and emacs-haskell. 
Haskell have more programming tasks that can be perfectly automated. Why not use it?
Hmm, interesting. Thanks for the link!
Wouldn't "how you think" be a much more important part of whether you are happy as a programmer? There's a reason exodus of java programmers to ruby and python happened about a decade ago. Despite having bombastic IDE's people preferred to abandon the language and code in freaking sublime text editor, just to get away from it. 
&gt; Don't automatic imports lead to dead code? Or is there some automatic burninate for that? In Intellij IDEA, unnecessary imports are removed on auto-format.
&gt;No way to search for reference across the project There's `hasktags`. &gt;So I guess there hasn't been much progress in IDE-land for Haskell in the past year :( Don't think so. There aren't big corporate backers so no surprise really. 
&gt;Haskell also doesn't have any tooling to facilitate any of this, which means no automatic imports, or other fun features There's `hasktags` and `hoogle` to search a project. 
But yeah, boils down to dev culture, unfortunately it's the least easiest thing to change, especially quickly. The correct approach is not always the most profitable or the fastest. Investors only care about profit and so does management :( 
I agree that how you think is a factor too. I was arguing against one aspect of the developer experience being "completely irrelevant".
&gt;Can someone give a quick overview of the best way to setup Haskell dev environment, especially in terms of IDE and stuff? `cabal`, `hasktags`, `hoogle`, `ghc-mod`, `hlint`, `hask-replace`, and ``stylish-haskell`. are what I use. I've heard good things about `fasttags`. &gt;(Please no emacs or vim. I am spoiled by Jetbrains products) Don't use Haskell if you want an IDE. There is nothing like Jetbrains. You can use Atom to avoid Emacs or Vim. 
&gt;less dependent on heavy IDEs by virtue of its design. True, but having automatic imports would be welcome. 
[removed]
I feel you on the jetbrains thing. I use pycharm for most of my professional python development and it really gets the job done. But, there's just not anything out there for Haskell that comes close to pycharm. At least, not yet. The quickest way I've found to get up and running with a good development environment is spacemacs with stack. I know you said no emacs or vim. But, you didn't say no emacs AND vim ;)
I'm not sold that `MonadIO` is *bad*, necessarily -- I just think it's a lower level than most domain code needs to be in. There's a blog post [A Modern Architecture for FP](http://degoes.net/articles/modern-fp) that discusses "layering" the application in a way that I like -- `IO` is the lowest, base level of what stuff gets run in eventually. In `IO`, I can do anything I want. So instead, we want to restrict effects in a way that makes our application easier to understand and maintain. If you disallow `MonadIO`, then you can't just lift any arbitrary `IO` into your app. You need to be more careful. For example, we can "purify" a lot of the `IO` code in our work codebase by using a typeclass for getting the current time: `class MonadTime m where getCurrentTime :: m UTCTime`. This "becomes" `IO` eventually, but it's much more explicit about what the function needs and what environments it can operate in. The next step is "Well we need to run database queries, and that takes IO." And the first thing you'll want to do is have a ton of functions like (using Persistent's `SqlPersistT` type) `runDb :: MonadIO m =&gt; SqlPersistT m a -&gt; App a`. And this is fine, but it's quite low-level -- you can't test it without talking to a real database. You definitely don't want to test/mock an entire SQL implementation. So instead, you write a *domain specific* class for talking about exactly the models you need: class UserQuery m where getUser :: UserId -&gt; m (Maybe User) selectUsersWith ... `UserQuery`, by virtue of it's small/specific implementation to your domain, will be easy to test and work on. We could then write: getUsers90DaysOld :: (MonadTime m, UserQuery m) =&gt; m [User] getUsers90DaysOld = do time &lt;- getCurrentTime let 90DaysAgo = addUTCTime (-90 * 60 * 60 * 24) time selectUsersWith [UserCreated &lt;=. 90DaysAgo] Likewise, if you have `MonadIO`, then it's tempting to just issue HTTP requests directly from your app stack. But what's *really* likely is that you have some domain model that's accessible via HTTP, and HTTP is just an implementation detail of getting that. So instead of writing `Wreq.get "https://some-data-source.com/v1/foobar"` and `Wreq.post "https://some-data-source.com/v1/foobar/1234`, you should prefer to write class FoobarData m where foobarIndex :: m [Foobar] foobarUpdate :: FoobarId -&gt; Foobar -&gt; m () The big win is when you need to change any of the implementations of these things. Because all the "I can do whatever I want" stuff happens in very localized places, you only need to change a few things to enact widespread changes on the application. Because your types are now talking very concretely about your domain, they tell you a lot more about what your functions are doing, and document your codebase better. Consider exceptions: `MonadIO m =&gt; m a`. I can write a function that throws an exception. However, `(MonadTime m, UserQuery m, FoobarData m) =&gt; m a` can only get the time, query users, and talk about foobars. If I'm reviewing some code, I might ask "Why is our user query code talking about foobars??? that doesn't make sense." But if I'm reviewing `MonadIO m =&gt; m a`, I don't have that type-level information about what the function I am writing is really trying to do.
Discoverability. It's the key reason that GUIs won the UX war before it ever started. The discoverability and affordance of the user experience in Vim (or emacs, for that matter) is attrociously bad compared to even the worst GUI editor. I personally think that those are tradeoffs, and that once you get past the initial barrier of entry there is a lot to love about vim, but it shouldn't be that hard to understand why some people don't like making those tradeoffs.
On the plus side, if code doesn't compile for long enough, usually the whole thing just dies and emacs runs a lot faster.
Oh I perfectly understand that vim lacks in discoverability (though I do think this is somewhat mitigated once people learn the `:help` command), but it sounded like you were already past that, so I was wondering what it was about the UI that you didn't like for daily usage. I'd like to add that the GUI model of discoverability does have a cost in terms of efficacy (menu-driven interaction, for one), so while it certainly has its benefits for the initial learning curve, the power tapers off pretty quickly compared to vim or emacs.
How do you use HIE/LSP with Vim?
[vim-lsp](https://github.com/prabirshrestha/vim-lsp) or [LanguageClient-NeoVim](https://github.com/autozimu/LanguageClient-neovim) (Obviously only for nvim)
I think this brings in the concept of professional grade tools. If you are a software professional, you will invest the upfront time to learn a tool that saves you a lot of time down the line. Effectiveness of the tool once you have mastered it is the key driver. And this is where vim and emacs shine, because you can retain that investment while working on any number of language projects. So discoverability is a big deal if you are trying to get drive-by users interested, but not otherwise.
And cabal-helper is waiting for a merge: https://github.com/DanielG/cabal-helper/pull/38 And my branch https://github.com/alanz/haskell-ide-engine/tree/new-cabal-helper is using it.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [alanz/haskell-ide-engine/.../**6941e6908c3a1141909526030e8876e3fc905a42** (new-cabal-helper → 6941e69)](https://github.com/alanz/haskell-ide-engine/tree/6941e6908c3a1141909526030e8876e3fc905a42) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dqmbdd0.)^.
So, my editing tastes are not remotely normal. I use, daily : VSCode SublimeText3 spacemacs vim Notepad ++ Depending on precisely what I am attempting to accomplish at any given point. For freeform text editing, my goto is usually sublime text, basically because of the multiple cursors feature, and because the plugins and command pallette conspired to make a fairly fully featured experience. For columnar editing, which comes up with surprising frequency where I work, I use Notepad ++, because multiple cursors doesn't handle columnar selection quite as gracefully, and because I run windows (not by choice), it's just a little bit easier to pull up notepad ++ for this quick, single purpose task than it is to pull up vim. For Haskell projects specifically, in situations in which I feel I could benefit from tooling, I will use spacemacs with haskell-layer or VSCode with HIE, depending on which decides to encounter some weirdass bug and die/do the wrong thing that day. I am edging more and more towards VSCode, despite my furious hatred for electron editors, because it seems to 'just work' a bit more often than spacemacs. Theoretically HIE is supposed to work with SublimeText3 as well, via an LSP plugin, but I've yet to get this working properly on windows. The day that I do is the day that I light fire to VSCode and never look back. vim I use when I really need to roll up my sleeves and do some serious text-wizardy sh*t. It is my goto editor for doing large scale editing operations on structured text, because generally if I am doing serious text munging I've dropped into a gitbash shell anyway, and also because using vim is just drastically faster than using anything else, so if I need to jump around a lot of files or a really big file, vim's speed and ease of navigation save a ton of time.
So, given the above: I run out of mental space for vim's keyboard shortcuts. vim doesn't have multiple cursors (there is a plugin, I've tried it, it's not quite right and it's oddly slow), and getting tooling to work on vim in windows is an utter hellscape. Thus, discoverability is important, because I forget what arcane series of keystrokes does X in any one of my 5 editors, and need to re-learn it probably about once or twice a week. 
What vim users fail to remember is the amount of time, research, energy, and sweat they have spent and are consistently spending keeping their tools tuned to save them all that time. I like making that tradeoff, because I do this to solve interesting puzzles anyway, so I don't use IDEs. Others don't, so they do. Also, some people do not have the memory that others do. It takes a lot of mental space to hold all of the various arcane methods by which you invoke X action, especially when you add language tooling on top of regular editing tasks. So this is a matter of neurocognitive differences too - Some people find it easier to have the GUI there to browse through because otherwise they would constantly be forgetting how to 'goto def' or what have you. It's not because they're dumb, or because they haven't spent the time, it's because their mind works differently than yours does.
One remark on this bit from your article: &gt; Instead, it’s better to put everything in one State monad. The ReaderT settings and the WriterT String parts can both be integrated in the StateT data structure. It’s a little less secure (for example immutable parts can still be modified in the StateT). using the "HasSomeRecord" approach or simply using [zoom](http://hackage.haskell.org/package/microlens-mtl-0.1.11.0/docs/Lens-Micro-Mtl.html#v:zoom) and [magnify](http://hackage.haskell.org/package/microlens-mtl-0.1.11.0/docs/Lens-Micro-Mtl.html#v:magnify) can make this approach more "secure" by limiting parts of the computation to the subset of the state they really need.
I would not agree that Rust has better tooling than Haskell. They're pretty much on par.
I have to say this feels like an antipattern to me. Having a single global application-wide monad invites unwanted coupling. Let's just focus on the `ReaderT AppConfig` part: what this says is that even irrelevant parts of the app configuation is available to every module. Personally, I prefer for the types to tell me (as much as reasonable) what a particular module is doing. `comp :: AppM ()` is no better than `comp :: IO ()` - it tells me nothing.
Does lsp-haskell module renaming also take care of file and directory changes?
Heh, I suppose that's one way of finding a silver lining...
What are the semantics of `MonadToken`? Is crypto algorithm, initialization vector, etc fully specified? I would argue, if these are not all specified, the only appropriate test would be of round-trip, i.e. check `encryptToken &gt;=&gt; decryptToken = pure . pure`, and testing any other property of the cyphertext would be wrong.
lsp-haskell does not currently support module renaming.
This might not be for you OP, but if anyone else wants to try using Emacs to write Haskell I had a recent positive experience with [dante](https://github.com/jyp/dante). If anyone wants to try a minimal haskell emacs configuration, [I've made one to share](https://github.com/soupi/minimal-haskell-emacs/). 
&gt; The `f &lt;$&gt; mx &lt;*&gt; ... &lt;*&gt; mz` idiom is more general than `liftA2` because it works with functions with more than two arguments In that sense it is more general, but `liftA2` lets me write `liftA2 . liftA2` to lift a 2-argument function thru 2 `Applicative`s, which in my experience is often convenient.
I think my point (below) is that by choosing one of vim or emacs, you dont have to remember 5 different editors. Just one. Well.
And many are mathematicians ☺ 
What caught my attention is it's ability to download packages' source and connect them as external libraries so _all_ the code is around — the thing I did anyway, just manually.
Yeah, that's just a basic expectation of mine but it seems to be missing from most or all other setups.
IntelliJ-Haskell works the way you seem to want it to https://gist.github.com/androidfred/a2bef54310c847f263343c529d32acd8
IntelliJ-Haskell comes close https://gist.github.com/androidfred/a2bef54310c847f263343c529d32acd8
Nice, `(liftA2 . liftA2) f fgx fgy` does look a lot better than `(\gx gy -&gt; f &lt;$&gt; gx &lt;*&gt; gy) &lt;$&gt; fgx &lt;*&gt; fgy`!
Apparently with `==== __Examples__`. See for example the docs for `Maybe`: [rendered](http://hackage.haskell.org/package/base-4.10.0.0/docs/Data-Maybe.html), [source](http://hackage.haskell.org/package/base-4.10.0.0/docs/src/Data.Maybe.html). Here's the [documentation for the collapsable Haskell sections](http://haskell-haddock.readthedocs.io/en/latest/markup.html#headings): &gt; As of 2.15.1, there’s experimental (read: subject to change or get removed) support for collapsible headers: simply wrap your existing header title in underscores, as per bold syntax. The collapsible section will stretch until the end of the comment or until a header of equal or smaller number of `=`s.
You could always write your own and use it. data NotifyIORef a = NotifyIORef (IORef a) (a -&gt; IO b) newNotifyIORef :: a -&gt; (a -&gt; IO b) -&gt; IO (NotifyIORef a) newNotifyIORef a callback = do ref &lt;- newIORef a pure (NotifyIORef ref callback) setNotifyIORef :: NotifyIORef a -&gt; a -&gt; IO () setNotifyIORef (NotifyIORef ref cb) a = do writeIORef ref a cb a (Off the cuff)
Here's the backstory if you're curious: https://github.com/haskell/haddock/issues/335
`ghc-mod` regularly locked up when editing big files with many language extensions. After restarting it would lock up again after a few minutes. So I ditched it for Haskero.
I'd suggest looking into functional-reactive-programming (FRP) and event based programming models. Whatever you end up implementing will be in the spirit of FRP! /u/eacameron's solution seems ok, but it's quite ad-hoc (not really a criticism in this context) in the sense that if you find yourself wanting to use this idea (model) throughout a project that you're developing, you might have fun looking into or considering the use of an FRP library; however, that might be overkill for the time being. Though, I promise it would be fun to learn about ;)
I'd just pair an IORef with a Chan, and write each update to the ref to the chan as well. Or alternately, if you only really care about the stream of changes, and not the persistent value, just push changes to the chan, and forget the ref entirely, or just have a separate listener on the chan to keep track of the latest value, for caching purposes...
If they are completely unrelated, it's a shame then that they only have 1 character difference in names.
The author of this is none other than [Tim Sweeney](https://en.wikipedia.org/wiki/Tim_Sweeney_(game_developer)) of the Unreal fame. I'm curious what people think because this would be insanity. Like balls to the wall insanity. 
I was actually thinking the same thing but didn't mention it. Thanks for completing the thought!
I'm not sure I understand the problem. To my eyes unit testing a polymorphic function/type class can be done by simply instantiating the type parameter(s) to concrete types and going from there. Parametricity should take care of the rest?!? I mean, yes, the instances you instantiate for your tests may violate laws (and thus accidentally pass when they shouldn't), but then... so may instances that you use in production and we don't worry *that* much it. Or are we talking about some *very* specific definition of unit testing, or...?
Not sure why this was downvoted, but if there is something specific about why this doesn't work, I'd love to hear it.
It would be better if it was irrelevant, but the truth is that bad tooling not only diminish enjoyment, but it also **does** influence technical decisions. Imagine a conversation like this: - A. let's use Haskell for this project - B. it is difficult to find Haskell programmers - A. Haskell it is a good language, our system will have less bugs - B. but there is no good tooling, there is no good IDE nor stable plug-in - A. those are not needed, you can use emacs or vim, and search using grep - B. also, there are not libraries for our use case compared to X language - A. you can write the missing libraries, don't worry - B. let's use X language, ok? it has X IDE, good tooling, the libraries we need - A. hmmm, ok u.u What do you think about that?
&gt; Can you set up a callback that activates when an IORef changes? No, but as others have pointed out, there are other data structures that can do that.
Actually, the reason I asked was I was thinking about making a minimalist frp library.
The equalities there are looser than that. Still interesting, but I'm not jumping in excitement over this kind of thing.
Excuse me for being very bad at this language, but I have seen the following multiple times and can't seem to find an explanation: `greyImagePixelsAvg img@(Image width height _) = ` What I mean is the `@` Syntax. Can somebody point me to a name of this notation so I can do my research? Thanks!
https://wiki.haskell.org/Keywords#.40 is the place to go - it has a list of all keywords, and an explanation of this one - including importantly the name which you can Google for.
What makes emacs/vim more effective in the long run?
No, but it's really easy to cook up with `TVar`: watch :: TVar a -&gt; (a -&gt; IO ()) -&gt; IO () watch tvar callback = readTVarIO tvar &gt;&gt;= go where go old = do new &lt;- atomically $ do val &lt;- readTVar tvar guard (val /= old) return val callback new go new
Please try [Leksah](https://github.com/leksah/leksah/blob/master/Readme.md#getting-leksah). It might not meet expectations, but any feedback you have would be very valuable to us. What bugs or features do you think we should work on next? 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [leksah/leksah/.../**Readme.md#getting-leksah** (master → d4a36a6)](https://github.com/leksah/leksah/blob/d4a36a68d1cdfd8499a3ccdabd6facbc5d58b96d/Readme.md#getting-leksah) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
You used `Int` because you had to return *something*, but you only ever return the single integer 0. So the type `Int` is much too big - we really want a type that only has a single value. This type is `()`, and it's single value is `()`. Hence, your `putS` is putS :: t -&gt; StateM t () putS t = StateM $ \_ -&gt; ((), t) This is consistent with the standard type of `put`.
Thank you a lot. Sorry for being so clueless :)
Try implementing : lkp :: (Ord k) =&gt; T k d -&gt; k -&gt; d First. Then, look for a function that can take `d`, and *return* `Monad m =&gt; m d`
 sumpairs x = [(a, x - a) | a &lt;- [0..x]]
If you have threads that want to wait on an IORef for a particular condition, and you want to notify them when the IORef changes in case the condition is true, then that's a classic use case for `STM` and `retry`.
I'm nowhere near Boston but it's cool to see businesses using Haskell in the wild. Do you find it a good language for the task?
The problem with that is you could miss updates (if for example its updated twice in a row really fast).
This is just a way to provide a more distinct logical separation between the different effects that IO already provides you at program start - It no more forces you to infect all of your code with reader than needing to invoke your functions from `main` forces you to infect all of your code with IO. Yes, using this as a cop-out so that you can write an entire app in an effectful monad transformer stack leads to convoluted and dirty code - But that's sort of it's own problem that still exists independently from this practice, and I'd argue that large near-to-main stacks are at least less obnoxious than a bunch of quasi-global `IORefs`, so even in the worst possible use, it's still a step up from doing it all in IO. I think rather than calling this an antipattern, it's probably better for us to call it a component of the solution, instead of the entire solution.
Ah, yup, that's true.
Although, I guess in many applications if something updates twice in a row quickly, forgetting the first update is fine.
Not on the job hunt myself right now but really cool to know this kind of thing is happening in the city! Hopefully this presages even wider use of Haskell/FP locally. Good luck with the search!
I don't think there's an answer to your question, because there's a lot that falls under the category of "functional programming". Just like imperative programming, you can spend a lifetime getting better at it. Sometimes people make the mistake of thinking that their Haskell has to be different from their code in other languages, just because it can. The truth is that Haskell programmers - like programmers in other languages - do whatever they have to do, to get their code working. If there's a more elegant way, that's great! You can use it *after* you learn about it and understand it. But until then, you can still do things in other ways. Example #1: you can often define a function using parameters (like `foo x = bar (baz x)`, or using combinators on functions (`f = bar . baz`. The latter is called point-free style. People who want to be "proper" Haskell programmers often misuse point-free style. Mostly, it's easier and clearer to just name the parameter. Example #2: Haskell has a lot of people thinking about fancy coroutine-like streaming I/O abstractions. Often, there's an elegant solution to handling your I/O needs using these. But that doesn't mean you can't just write a `do` block and do the I/O you wanted to do! Use the abstraction if it helps, not if it hurts. Haskell even has mutable variables (`IORef` and `MVar`), loops (`forM_`), and such. There are even versions (the `ST` monad and `STVar`) specifically designed for writing pure functions where you just can't figure out how to implement the function clearly and efficiently in a functional style. Granted, using these all the time will make your code look like novice work -- but it will work! As you get more comfortable with the alternatives, you can start using them. How long does it last? Haskellers are still discovering and writing research papers about interesting functional ways of accomplishing many tasks. This is what many people find appealing about the language. Once you've accepted that it's okay to do things the obvious way first, it's no longer a problem that you're constantly learning new things.
Classical Logic == Topology == Types Linear Logic == Geometric Algebra == (??)
Not in Boston but would love to hear more about the tech stack.
This is from 2000. Has there been any discussion/papers/investigation into this?
Two things stick out: Linear logic is pretty normal for spaces with tensor products, it's more of a default than anything. This has bottom = top, which is to say it's not faithful in its rendition.
Linear types https://en.wikipedia.org/wiki/Substructural_type_system#Linear_type_systems
&gt; But without any input variable having a type a such an attempt is useless, a can't be concretely deduced. Not to say you should (you should use `()`), but this is perfectly fine! putS :: t -&gt; StateM t a putS t = StateM $ \_ -&gt; (undefined, t) What do you mean by 'without any input variable having a type `a`'? If you think about it, `undefined` *itself* doesn't have any input variables at all, let alone `a`.
I believe you are supposed to: - `return x` when the lookup is successful and result is x - `fail "Some message like not found"` when the lookup failed. It's not really how we tend to do things anymore... nowdays we just use `Maybe`
While they are quite different in their approaches, both offer incredible returns on your time investment, much more so than IDEs imo. This is because each feature or customization one learns/makes can compose extremely well with other features/customizations, and because they generally have a richer feature-set, allowing one to be making productivity gains even years after starting to use the editor (yes, really). The result is a non-linear progression of productivity, as learning one thing can cause a cascading boon to your productivity. Even though IDEs are called "integrated", they are really more like a collection of mostly unrelated subprograms stitched together. Vim and emacs aim to provide a truly unified interface, meaning your knowledge of how to accomplish one thing generally translates very well to another, and better yet, you can even know many keybindings *without explicitly learning them*, because such an interface allows one to make inferences about what a keybinding should be to accomplish a particular task. I have used vim for quite a while now, and I can tell you that I most certainly did not explicitly memorize every binding I use (which is in the hundreds if you count every combination). I learned a small handful (which are mnemonic, like `d` for delete or `c` for change), then got a boatload for free as a result. Keyboard-driven navigation is also much faster than mouse/menu-driven, and so it's very beneficial to be using an editor that is keyboard-driven by default, instead of something that is primarily mouse/menu-driven with fairly ad-hoc keyboard navigation support.
Of course, that certainly does happen. OP is effectively in that camp, considering Haskell based on the IDE situation (not hating on OP, btw, just providing an example. I am not saying that such things don't happen, but rather they shouldn't. I don't believe it is necessary at all to couple our editor choice with our technical decisions. I think it's a cultural issue more than anything else, one that can only be changed by breaking the status quo one developer (or dev shop) at a time.
Imports can be ["optimized"](https://www.jetbrains.com/help/idea/optimizing-imports.html), and it can be set so that "optimize imports" is run after every auto-import. 
I don't know if those situations shouldn't happen, but the reality is that they do, and sometimes the comparisons are right. I know I prefer work with Haskell using vscode or emacs instead of using just nano, because they provide some features that make time usage more efficient and enjoyable (even if they are not perfect). At the same time, I prefer using QtCreator for C++ programming instead of vscode or emacs, because they don't provide the kind of support I need to work efficiently. Maybe it would not be possible for me to finish my work each day at all with something more primitive like nano or even emacs (it doesn't matter how much I would configure it). In my case it is not a cultural issue... It is just that I could not finish my work without good tools, because instead of creating solutions, I would be spending time doing things by hand when they could be automated (eg. changing variable names one by one, or deploying an apk building it by hand, etc). Believe me I have tried to use my favourite editor for most of the things, but it was not always possible. Maybe my emacs knowledge is too low or sometimes it is not the right tool for the job. I think the right path is to accept the situation, then to develop the missing libraries, and finally to make editor-agnostic tools (eg. haskell-ide-engine and most lsp plug-ins). That way the ecosystem will flourish around a really good language. 
Repl helps. What you call a list of steps can be converted into a list of functions and each function can be tried separately in the repl. That's basically how I start. From smallest chunks of independent code that accept some input and produce some output. I try them in repl. Then I combine those functions by feeding the output of one function into the input of the other and naturally grow my program, testing it step by step in repl. 
Most of the IDEs that "we" create (ie. open source) are in fact modular and are, *not* "incredibly tightly-coupled". Those are commercial products, and there is a very real business idea behind it: vendor lock-in. Welcome to the myth that a capitalistic setup leads to a globally optimal result. Capitalism only optimises one thing: return for the capital holders. All other local optimisations are incidental byproducts. Neither guaramteed, nor global. 
How often do you run hasktags then, and when? 
I agree. I was using "we" very loosely to refer to developers as a whole, and definitely specifically referring to non-open source software, since that makes up most (all?) IDEs.
I do not run it. Emacs does. There's a hook for haskell mode that runs it on file save so tags are generated automatically for me. 
I'd hate depending on a single developer continuing my tooling. Really, that's why only open source of corporate solutions are an option. 
I'd recommend going to Boston Haskell to advertise the open position.
Yeah, I realise that. I think my main gripe is that a lot of features are synchronous, such as auto-complete and various others.
&gt; Maybe your use of it is slow Mine and a couple of thousands others using Spacemacs, I guess. There are a lot of core features that are synchronous, such as auto-complete and various others, which VIM has fixed for quite some time. Vim is generally feels a lot snappier than emacs.
Almost everything is thrown into the status line/command line area (the one in the bottom), where we could have benefitted from hover pop-ups etc. With more thought, you could probably do something similar as the completion pop-up, but just nothing does it. Also, just in general there are UI things you (to my knowledge) just can't change, like having variable line heights (like emacs when you edit markdown), e.g. something like Cmp+Shift+P in VSCode (the command launcher thing), markdown et al previews etc. You are kinda limited to the TUI. That said, there are some GUI projects using Neovim that are making some cool progress :)
[removed]
[removed]
Thanks! I'll pass on the feedback to our design team :) Backend is servant and postgres. Web is reflex-platform on ghcjs and we use swift for iOS. We are also doing some neat things with extensible records IMHO (https://github.com/ConferHealth/composite) and we are trying to open source as much as possible.
I live about 2 miles away (I used to live about 4 blocks away on Washington Street) and am interested, but I'm a first year MS student at Tufts. Are you doing any internships or something of the like? My background is mostly Elixir and Erlang, but I do know Haskell up to the Monad level and Standard ML.
But the crucial thing is that commercial IDEs are used by "us", but not *built* by "us". In a commercial setting, business goals always trump best engineering practice, if they are at odds. 
That's what I meant, so "on saves". 
[removed]
[removed]
It seems like I had the blatant misconception that any type variable I use should eventually be one of the basic types after type inferences. Like, a polymorphic `length :: [a] -&gt; Int` sets `a` to `Char` when `length "Hello"` is evaluated. But in this case, if I never use the result `putS` gives, `undefined` would forever have the type `a` and die in that form only, without ever being attached to a concrete type. But it seems like I was wrong. :) 
No problem at all. Searching for such things is tricky!
Thanks a lot for the clarification 
I will second spacemacs, I have used it with intero and had a good experience
sumPairs x = zip [0..x] [x..0] Seems simpler :)
So you only bought one car in your life?
You're welcome to pitch that you're looking for somebody at the meetup.
So the real (full) type is `forall m. Monad m =&gt; AppM Context Errors m ReturnVal`? Context matters.
Evidently yes, if they're using it :)
For me, it was around a year of on-again-off-again trying to learn it. To fix this, you need to write a bunch of code. Pick a very simple goal, then puzzle out how to achieve it. Then pick a slightly bigger goal, and so on. If you don't have any project ideas, try writing a to-do list. Here's a simple spec for you : https://gist.github.com/LightAndLight/e014ad039d9ff5aac0e23fe9f913da3a. If you sit down and have no clue regarding what to write, if you can't think of what functions or data structures to create to achieve your goals, then you need to solidify your fundamentals. CIS194, Learn You a Haskell, Haskell Programming from First Principles, or Real World Haskell are some potential resources for this.
I thought Leksah was dead? When I was getting into I did indeed read about Leksah and everywhere it said it's no longer in-active development.
Maybe. [Intellij Rust](https://intellij-rust.github.io/) looks way more polished that [Intellij Haskell](https://github.com/rikvdkleij/intellij-haskell)
What are you gonna do? These guys wanna make money not the products using best practices in engineering.
Yes
&gt; OP is effectively in that camp Lol, no . I am not in that camp. I can do vim and emacs, my colleagues won't and I know that, and that's why I want to test a solution and once satisfied pitch it to my colleagues. &gt; one that can only be changed by breaking the status quo one developer (or dev shop) at a time. Try introducing such changes, and when short-term productivity goes to hell, and projects get delayed, your ass will be first to get not only fired, but get a scathing recommendation, that will destroy your rep in the industry.
So true.
We have not done an official release in a while, but that is partly because it is much easier to build it from the github source than it used to be. It also has some strange quirks that it would be nice to sort out before we do an official release, but I use it for all my Haskell work and it has most of the features I want.
I really like this idea. I've been thinking along similar lines recently for my needs. The major thing I would change though would be to take `ExceptT` out of your stack. Short-circuiting monads don't tend to compose as well. I prefer dropping in and out of `ExceptT` as necessary. However I wouldn't go so far as to say that it should be done this way across the board. It probably depends on the failure patterns of the problem you're solving.
I'm not quite sure I understand what you're getting at. It doesn't sound like you're saying anything that disagrees with what I've said as best as I can tell. I think we are on the same page. 
&gt; `undefined` would forever have the type `a` and die in that form only. Yes it will! That's the correct understanding. In practice GHC infers a type `GHC.Exts.Any`, but since `a` just dies it's not supposed to matter.
Well I think the memory issue goes away once one learns the concepts of vim (operators, motions, etc.), but the investment may not be worth it to you if you prefer to use so many editors, I suppose. May I ask why multiple cursors are important to you? I've seen them in other editors but I never understood what it is they are supposed to do. Is it just the live feedback? Because if so, that is fairly easily done in vim's search/replace.
One of the key things about the vim philosophy in particular is that it gets committed to muscle memory, which is also why it is fast. I rarely am ever consciously thinking about keybindings, and if I had to keep it all in my head I would never get anything done. Instead, I'm looking at text, and I decide I want to delete a paragraph, and my fingers do it automatically. I've gone on vacation and been away from computers for months, and when I come back my fingers behave just he same. It's kind of like riding a bike.
Simple and straightforward solution! It's not difficult how one can elaborate upon this to allow registering multiple callbacks. 
Well I suppose it is a bit of a matter of taste. I vastly prefer information in my statusline or preview window over a bunch of distracting popups (to me) all over the place, and I think most vim users would probably say the same. So I mean there's gvim for GUI stuff, though I have never used it. What does variable line height mean? Is that different from dynamically increasing/decreasing the font size (which is handled by the terminal emulator)?
I'm a vim guy so maybe someone else can chime in about this, but I thought emacs had async, or it was coming? It seems like it should at least be possible with a plugin, because it's even possible in standard Vim 8 now.
Just install Spacemacs and Intero. "You" won't have to run Hasktags, or anything else, most of the time, since it just works. Of course, then you have to learn Emacs keyboard gymnastics, or Vim bindings if you decide to use Evil mode. Just choose one. 
Sorry, I didn't mean anything by it. I was just saying that you your choice about whether or not use the language (presumably at work?) was being influenced by the IDE situation, which I do think is reasonable given the current climate. &gt;Try introducing such changes, and when short-term productivity goes to hell, and projects get delayed, your ass will be first to get not only fired, but get a scathing recommendation, that will destroy your rep in the industry. I don't know about introducing the changes. When I said dev shop I was more referring to those that started that way from the get go, as they can influence the status quo as they hire new devs.
I suppose when I say "cultural issue", I mean to say that developers have sort of "grown up" on IDEs (I do not mean to patronizing in any way, this is just the best analogy I could think up), and so it's effort to move away from the associated inertia. I am of the opinion that if devs had instead "grown up" using editors and terminals, we would not really be missing out on anything. I don't think nano can really be placed in the same category as vim or emacs. It's kind of like a better version of Window's Notepad, not much more. Variable renaming across a file or even a project is generally pretty easily done in vim or emacs. (At least I can do it efficiently in vim, never tried it in emacs but I assume it is similar) I don't know much of anything about deploying an apk, but it sounds like the kind of thing a quick bash script could do, or perhaps a terminal build tool of some kind?
That actually makes sense. Is there any way to confirm that? Thanks!
Thanks, yet another nitty gritty of Haskell that I have to go into. :) Since I have started working on this Haskell project, literally everyday I learn something new about the language and ecosystem. And i have been prepping to work in Haskell for years! :D Thanks, I have many reading and testing to do obviously. :)
I learnt FP fairly easily but I came in via Lisp and F#. I too am in the situation of being able to read a menu written in Haskell but struggling to use it to start a conversation. 
&gt; [x..0] This doesn't work.
tl;dr related question -- this is time based cache invalidation, right? I've always wondered if a well-constructed DB monad can get caching and cache invalidation right.
I has, but I get the sense that it's quite cumbersome to use, so many don't :(
Something like this https://discuss.atom.io/t/setting-different-font-sizes-on-syntax-level-for-specific-elements/48872. Admittedly I don't think many editors support something like that currently.
Major props for adding this in the docs up-front: &gt; Motivation and Req vs other libraries 
In 2005, as part of my second semester CS courses, I learned Haskell. I could use it, but it did not click. The following year, I TAed that class. And although I still wrote Haskell code that looked like Python code back then (e.g. a GTK frontend for a MySQL data base to enter the student’s points), that is when it clicked. So maybe the conclusion is: In order to understand Functional Programming, you have to teach it? (But then, this conclusion holds for almost anything…)
nice to see the dots connected, it's useful. advanced category is not trivial at all.
Seeing a coend as a colimit in Twisted, this argument can be made about (co)limits.
[removed]
&gt; Nobody really makes an HTTP request to get 404 or 500. Especially when http-client implements following of redirects and req adds retrying, if you get a non-2xx status code, something certainly went wrong, it’s not what you expected, so it’s an exceptional situation that should be treated as such. This seems wildly incrorrect to me. I have written *tons* of code where a 404 is completely expected (checking if a user exists or not, etc). This is exactly why throwing an exception for stuff like this is wrong; it may be exceptional in one person's use case and ordinary in another person's use case.
http-client throwing exceptions on non-2xx's is one of the most unexpected things I've seen in Haskell libraries within 5 years that I've been using Haskell professionally.
In as much as functional programming is the process of breaking a program up into small discrete functions and then composing them to produce something complex (but understandable by its individual components), it took me a few months learning Lisp back in college for it to finally click. Of course there are plenty of other functional programming concepts that I learned later, but those were each learned individually in varying amounts of time.
I completely agree. I've written lots of APIs where callers may wish to find out if a resource exists and if it doesn't I return 404s. It always seemed perfectly reasonable to do so and not really an exception so much as the message, "this does not exist."
This is an incredibly hard question to answer clearly. A lot of editors and plugins have attempted to do multiple cursors, and try, and get it almost right, but miss some tiny piece. No thinking about regex. Live editing. Not just feedback, live editing. If you make a typo, etc, you fix it in place right there, it's fixed everywhere, you keep going. Navigation. You can still navigate using the same keycombos you're used to using, it moves all cursors at once. Why this is cool is hard to describe, but I inevitably miss it when I don't have it. Incrementally adding more cursors if you want to edit only some matches. The most important part of multiple cursors is that it does all of the above at once, seamlessly, as a single consistent feature experience. Vim can match the raw power of multiple cursors easily. But it offers each component separately, and ultimately using vim to do similar things feels less expressive and more rote - you have to context switch and think about each action individually.
&gt; Nobody really makes an HTTP request to get 404 or 500. Especially when http-client implements following of redirects and req adds retrying, if you get a non-2xx status code, something certainly went wrong, it’s not what you expected, so it’s an exceptional situation that should be treated as such. Throwing exceptions on non 2xx status codes is a bad idea, IMHO. Please just return the status code, and let me worry about whether it is to be considered exceptional or not. :) Other than that: Nice library and post. Thanks!
It took me until age 13 to learn to tie my shoes, and age 18 to ride a bike. I am still clumsy with both. Some people's 'muscle memory' and coordination is not the same as others.
I agree that that turn of phrase is too strong. What I meant that more often than not, especially when you're interacting with API of a web service, you expect your requests to end up successfully. Otherwise you'd have to check status code after every request. It's like writing lots of case statements vs using Either monad or similar. &gt; This is exactly why throwing an exception for stuff like this is wrong; it may be exceptional in one person's use case and ordinary in another person's use case. Completely agree, but we can only have one default behavior and I argue that expecting a status code that indicates success is simply more common. But in the end, it's easy to switch behaviors, so everyone can get what he/she wants.
Before my comment there were 6 others, 4 complaining about throwing exceptions on non-200 status codes! I'm afraid I'm going to have to make that 5 from 7 ... 
I would be careful with `undefined`. You don't really gain anything by using it here as opposed to `()`, and if you accidentally do something like `putS t &gt;&gt;= f`, where `f` does a case analysis on its argument, you will get a crash.
You're right, that was my bad. Small brain fart
The difference is that one default behavior is obvious in the type and the compiler forces you to handle it whereas the other is invisible and can be easily missed by the programmer. I'd rather throw the occasional `fromMaybe (error "not there!") foo` into my CLI scripts than have a production server that silently reports a confusing error to users.
It wouldn't even be so bad if the exceptions it threw were at all sane. Instead, it lumps all the exceptions which can be thrown by various parts of the library together into the single type [HttpException](https://hackage.haskell.org/package/http-client-0.5.7.1/docs/src/Network-HTTP-Client-Types.html#HttpException) that has two constructors, but one of them has a field of type [HttpExceptionContent](https://hackage.haskell.org/package/http-client-0.5.7.1/docs/src/Network-HTTP-Client-Types.html#HttpExceptionContent) which has 21 data constructors.
Perhaps there could be a function that took a proxy with a type-level list of status codes, returned Either-like errors for those codes, and threw exceptions for anything else.
FWIW this is something we've been looking into in servant land (e.g see [this ticket](https://github.com/haskell-servant/servant/issues/841)). An `ExceptT`-based solution that generalises to several "error types" (all the ones returned by some endpoint) is I think the best solution here and that's what we want to have eventually all over the place in servant. It's just hard to make that work and be convenient to use =)
This. This is what I was trying to say. When there is a tool that increases productivity, why do not use it? emacs and vim are really good when there is a language-aware plug-in for them, or when there is no support for the language in any editor at all. When there is some better tool, just use it!
That's probably true. But I wouldn't judge an entire language's tooling by its IntelliJ plugin :P I think the Rust community is trying to converge on an LSP implementation anyway, just like HIE.
Abelian categories have finite biproducts, so, yes, in particular bottom = top. This seems problematic if you want to give a categorical semantics to intuitionistic linear types. But I shall argue that this is actually the right thing, because it forces us to think about what is really going on in a linearly typed programming language: * In mathematics, function spaces are inhabited by (“pure”, if you will) functions only. In computer science, computation spaces are inhabited by effectful (in particular, nonterminating) computations too. Recall the reason why the untyped lambda calculus doesn't have a nontrivial semantics in the category of sets: function spaces can't faithfully model effectful computation spaces. * An value of type top is like a hot potato: You have to discharge it, but all you can do is pass it around. Thus, a computation of type top can't be followed by a terminating computation. If your linearly typed language shall only have terminating computations, so that you can give it a semantics in an Abelian category (whose arrow spaces are very much function spaces), then a value of type top is as good as a value of type bottom: neither can arise in a program. * If you want to give a categorical semantics to a language with effects, you actually need *two* categories: one with positive type constructors (direct sums, tensor products), the other one with negative ones (direct products, function types). And then there are no more biproducts, since coproducts and products don't even live in the same category! Read Paul Blain Levy's [call-by-push-value](http://www.cs.bham.ac.uk/~pbl/cbpv.html) papers for the details.
I think this is what `wreq` does.
Sometimes it could be cultural, but most of the time it is about the money and the hours it takes to implement a solution or fix the existing code. I learnt about computers using text mode, when I was a child, even if gui was already available. I learnt programming at first using paper and pencil, writing the code, because they taught us that way. That's why I know how is it to work without any tool or the most simple one (eg. nano). People use vim or emacs because those tools provide features which are useful for them, and make them more productive. nano doesn't have those features, but it doesn't mean you cannot do programming with nano, it is just not productive because the other ones save you lot of time. Variable renaming is **not** pretty easily done with any tool which is not language-aware. Sure, you could use eg. sed in the terminal with some regex, but sometimes renaming that way it is just wrong. It is possible that unrelated code, with similar name, it is renamed too. You cannot trust that naive way of renaming when working in a big project with various developers and few time. About apk deploying, maybe it is possible to write an script to do it. First you would have to learn how the build system handle that, and do the same in the script. Then you would have to maintain that script, and fix it when it differs from the original build system. I think it would be a nightmare, it would take lots of time, and the company would not pay me to do it anyways. Also, I'm not interested in how apk's are made, I just want to write the code and upload it to the phone to see it working in the less time possible, but I would do it if they would pay me for that.
Same post I replied to here: https://www.reddit.com/r/haskell/comments/7gq077/applicative_functors_and_data_validation/dqkwzqt/?context=3 Why is this getting posted a second time?
It's a wiki. You can edit it. The correct definitions are: (&lt;$) :: Functor f =&gt; a -&gt; f b -&gt; f a ($&gt;) :: Functor f =&gt; f a -&gt; b -&gt; f b - https://www.stackage.org/haddock/nightly-2017-12-01/base-4.10.1.0/Data-Functor.html#v:-60--36- - https://www.stackage.org/haddock/nightly-2017-12-01/base-4.10.1.0/Data-Functor.html#v:-36--62-
Looks like cabal-helper merged your PR, /r/allan_zimm: https://github.com/DanielG/cabal-helper/pull/38 
The hardest part for me was dealing with lack of state. Making a function that recurses and passes itself a new argument instead of simply assigning a new value to a variable. I worked with Haskell for several months in my free time but there are so few job opportunities that it was a big waste of time. Never did get comfortable with monads or understanding the library documentation. 
Since they're different URLs, they're arguably different. But the content is the same. There's no sense in having both links. Removed.
Fair enough.
Yep, but one more small thing I must fix up. Tomorrow, hopefully.
Ah I see, well increasing the font size in a terminal doesn't have any of the mentioned issues as far as I can tell, so doing that seems fine to me. In fact, whenever I see presentations using vim (Like Ed's videos, for example), they generally increase the font size so the audience can see the text on the projector and it seems to work nicely. I just tried it on mine and there was no weirdness going on.
Anyone who would like to contribute to the wiki or correct any part of it should feel free to request an account. We usually respond to new account requests within 24 hours -- often much sooner.
`fibs'` does not depend on what you pass in to `fib'` so it is most likely being floated out. Try out `-fno-full-laziness` and see what happens. 
would a TUI work as well? if so, take a look at [brick](https://github.com/jtdaugherty/brick).
Please tell me at least that those tabs aren't sneaking into any open source libraries. 
3 months to get comfortable with syntax, and a year before it became my primary language. I found it helpful to try solve Project Euler problems, fail miserably, look at the solution on the Haskell Wiki, and try again until I could do it myself without looking at the Wiki anymore.
Apps built with `ghcjs-dom` will work in a browser. You can also compile them to a native machine using `jsaddle-webkit2gtk`, which is kind of like electron except way faster since your Haskell actually runs natively. `ghcjs-dom` will give you a pretty cut-and-dry implementation of most (all?) browser APIs, but it's a bit verbose. `reflex-dom` provides a much higher level API and sets up `jsaddle-webkit2gtk` out of the box for you, but requires knowing how to use FRP, which can be a learning curve.
Great! I have to learn more about this library.
You need a native application if you want it to be performant. It boggles my mind that people use a glorified web browser for development. Learning around 10 - 15 keybindings is a very small price to pay to get a powerful, fast and convenient dev env. for haskell. Unfortunately there's no native IDE or text editor (on linux) that I know of that has comparable to emacs / vim haskell support. 
I help maintain the neovim plugin for Haskell and it's quite fast. I know that's not what you want, but taking the week or two to learn vim/emacs really opens up a world of possibilities.
I've fixed the type declarations and made the descriptions a little more clear. Thank you.
Here is a port of 2048 from Elm to Haskell. It uses GHCJS to target the browser. game: http://2048.haskell-miso.org/ source: https://github.com/ptigwe/hs2048/ &gt; I looked at elm and thought it might not be too hard for implementing the GUI, but I'm new to web dev, so how would I go about this? If my logic is in haskell, I'm assuming that I use elm to detect events (and print output), and then send function to receive serializable data (the tiles) / json? from the haskell code? Miso (https://github.com/dmjio/miso) is basically Elm for Haskell, and very easy to get started with.
Thanks! I actually wanted to use miso, but I had trouble installing it and ghcjs. 
I see, how did you go about installing it? did you use stack or nix?
Spent a month just reading stuff (not actually doing any programming with Haskell). Then I started building a webapp with yesod (a haskell library for web applications). After four months of that, I felt comfortable with the language. What this means is that I could do stuff, but I didn't necessarily come up with the most robust solution (or even a remotely robust solution). After two or three years of using haskell professionally, I felt like I could take a problem description and confidently pick the abstraction that modeled the problem accurately. For context, I'd done OOP for five years before using haskell, and I still never feel confident in modeling anything with objects.
I used stack setup, just as described in their readME. When it gets to the step of installing GHCJS it fails: stderr: solver must be one of: modular CallStack (from HasCallStack): error, called at ./Distribution/ReadE.hs:46:24 in Cabal-2.0.0.2-inplace:Distribution.ReadE Booting GHCJS (this will take a long time) ...Process exited with ExitFailure 1:/.stack/programs/x86_64-osx/ghcjs-0.2.0.9006020_ghc-7.10.3/src/.stack-work/install/x86_64-osx/lts-6.20/7.10.3/bin/ghcjs-boot --clean 
Sounds like a case for memoization to me.
I suppose maybe you're right about the refactoring. One can prompt for confirmation for each replacement and quickly jump through each one in vim, but I can appreciate that is more tedious than it needs to be. As mentioned, my knowledge of apks is very limited, so I may be way off, but [this](https://developer.android.com/studio/build/building-cmdline.html) article looks fairly straightforward for building and deploying apks? If this would work, then you wouldn't actually even have to write a script yourself at all.
When you say "one of the basic types", keep in mind that, among lifted types (which is basically everything that you'll use unless you start digging into `ghc-prim`), there really are no "basic types". `Int` is not special. Neither is `Char`. Here are several other non-special data types provided by `base` that are useful when you have a function that needs to communicate that absence of information: data () = () -- Uses special syntax so you cannot actually write this definition on your own data Void Note that `()` is typically pronounced "unit". It has one inhabitant, and `Void` has zero inhabitants.
That's odd. Attempting to reproduce on OSX and NixOS w/ `stack` using the following: ``` git clone https://github.com/dmjio/miso &amp;&amp; cd miso/sample-app &amp;&amp; stack setup ```
Thanks! I still get the same error :(. Think I'm gonna try going the elm route. 
If you want a native app, [`fltkhs`](https://hackage.haskell.org/package/fltkhs) provides bindings for GUI development and /u/deech has done a lot of work towards making it portable, and easy to install/use. There's a ton of documentation and examples as well.
That usually requires that the thing being memoized is part of special typeclass (such as [Memoizable](https://hackage.haskell.org/package/memoize-0.8.1/docs/Data-Function-Memoize.html#t:Memoizable)), which can't be used in a Functor instance.
thanks! I'll check that out
Thanks. I didn't realise that Functor couldn't be memoized. That seems like a problem.
Can you share which OS you're on? I did a wipe of `~/.stack` and then ran on OSX: ```git clone https://github.com/dmjio/miso &amp;&amp; cd miso/sample-app &amp;&amp; stack setup &amp;&amp; stack build``` Works for me.
I'm on macOS
The joy of emacs is that you can change all of the bindings.
That's strange, stackage should guarantee it's deterministic, so it should be fine.
Did you try removing `~/.stack` and running that command again?
I worked on a project at least 5x that size and Dante was never that slow. 10sec, max. But it’s emacs. Though Dante shouldn’t really be faster than intero...
This is the primary reason Reflex’s implementation is so complicated. You have to cache things in all the right places, which is very difficult.
Nope, guess I'll try that. So I call rm stack inside the folder? 
It depends on the implementation you use. Reactive-banana caches the results, it does not apply `f` twice.
Im not so sure. The definition that the `where` clause is attached to takes no arguments. If you eta expanded `fib’`, then full laziness might come into play. But without the function binding syntax, I’m pretty sure `x = ... where y = ...` will just naturally root `y` at the same level as `x`
&gt; You need a native application if you want it to be performant Not really. VSCode is pretty darn fast on its own. I’d wager it’s Haskero which is being slow here, which is ironically a native application.
On second thought I'm pretty sure you are right. `fibs'` is not behind a lambda so there is no reason for it to be recomputed regardless of optimizations.
My experience with regex is that it becomes pretty natural once you start regularly using it, but I appreciate that it is not for everyone. I had forgotten that my live editing was a neovim feature, not in base vim. I think it is still doable in vim with a plugin, though. For me, when doing any search, the matched pattern is highlighted in the editor, and when doing the replace, the replacement is shown live in the editor as I type, but not committed until I press enter (which gives me the added benefit of hitting Esc to cancel the search/replace entirely). Fair enough, vim probably can't do the described navigation very easily (though you can move your cursor between matched patterns, like emacs). I would not use such a feature even if vim had it by default, but to each their own. Do multiple cursors scale well? Are there any performance implications of editing, say, 20 functions at the same time? 
``` sudo rm -r ~/.stack ``` It will get recreated after you call `stack setup`
No, VSCode is single threaded (because js is). Vim has the same problem, that's why neovim is rising. Emacs with intero (same backed as haskero) works fine and is performant. 
&gt;On my current project of ~5k LoC, it typically takes ~2 minutes from when I save my file (which kicks off the typecheck etc.) to when it will show errors inline in the editor. I'm not sure that's VSCode being slow. I use `ghc-mod` with vim, which works quite nicely except for the fact that it requires ghc 8.0.2.
But you still have to install the text editor afterwards. ;)
Damn ... I got the same error after a really long time of installation: Booting GHCJS (this will take a long time) ...Process exited with ExitFailure 1. But thank you for the help!
Emacs is single threaded until version 27 (or maybe 26?) which adds very simple rudimentary threads to emacs. Threadiness of the editor is irrelevant to it's performance. Vim and neovim should be plenty fast, I use it for editing Haskell sometimes and use intero on neovim; intero is also plenty fast on emacs. The problem is either vscode or haskero and considering that vscode does just fine with JavaScript, php, and many other languages, I'm inclined to think the problem is haskero itself.
I follow existing coding standards when contributing to existing projects. But, we've got open source libraries on hackage that doesn't even use layout -- explicit `{;}` everywhere. Tabs certainly aren't worse.
To add to the above, Reflex is using push based computations for Events and pull based computations for Behaviors - you can read more about that [here](http://conal.net/papers/push-pull-frp/). That can help keep unnecessary recomputations down. 
VSCode uses external processes to get parallelism, and does a pretty good job of it. Also, the threading model doesn't say much about performance. It's perfectly possible for single threaded programs to be fast. VSCode is pretty fast. It's quite frequently faster than my Emacs setup. Though I admit that's largely because of the poorly written Emacs plugins I use, the point remains. There's no inherent reason that JS in VSCode would be slower than Emacs Lisp. The DOM is the only possible difference, and rendering is never the thing that makes either editor slow to me.
Would it be possible to provide a few default implementations of http exception that people could choose from? Currently your examples use throwIO to implement the instance. It would be nice to have an example on how to customize the behavior to, for example, never throw on any http status code, or one that would log all non 2xx codes, etc. The other thing that's annoying is that you make a request and customize the request to get what you want, so certain things you would expect a certain behavior and others you would expect a different behavior (for example, is there a nice way to setup the configuration so that if I write a function to get the status code, it always works, but if I write a getData function, it logs on non 2xx, and a postData would throw on failure?) Currently, as it is, the request is so general that everything goes through it, even things which seem so separate that they should be handled far differently.
I never liked VSCode, I always had to have 3 SO tabs, and a tutorial open to get anything done. I'd even go as far to say it's harder than vim.
I never liked VSCode, I always had to have 3 SO tabs, and a tutorial open to get anything done. I'd even go as far to say it's harder than vim.
I second fltkhs and if you consider Qt5 to be a better fit for your platform requirements, check out Qtah.
https://www.meetup.com/Boston-Haskell/ My fuzzy impression is we're skipping December. https://www.youtube.com/channel/UCUCpgCWjaniUkX88wZrK_Ig/videos Videos of some past meetings.
Emacs also has a single thread of execution and frankly js vm should be performing better than elisp interpreter because of more engineering effort. 
What version of stack are you using?
You might like [SICM - Structure and Interpretation of Classical Mechanics](https://mitpress.mit.edu/sites/default/files/titles/content/sicm/book.html). Programatic (scheme) variational mechanics. Fun [preface](https://mitpress.mit.edu/sites/default/files/titles/content/sicm/book-Z-H-5.html). [Chapter 3](https://mitpress.mit.edu/sites/default/files/titles/content/sicm/book-Z-H-36.html) is Hamiltonian mechanics.
I think I have the latest. How to do I check?
I'd recommend trying the nix instructions as well.
```stack --version```
Version 1.5.1
guess I'll try that. thanks!
Can you paste the entire terminal output, from the ```git clone``` command to the ```stack setup``` command, as a gist or using lpaste.net. Want to make sure you're on the same resolver, etc.
I dunno, I was able to pick it up pretty quick and still haven't fully gotten the hang of vim or Emacs. But the hotkeys I expect are there, and the command palate gives me basically everything else. It really depends on what you're familiar with. Atom is basically the same, just a bit slower.
Sure: here is my output: http://lpaste.net/4031492273823809536
It is not only about the apk's, that's not the point. The thing is that good tools save time and increase productivity, eg. at work I use QtCreator for C++ and Qt, which gives us: - Automated deploy to Android and iOS devices (build apk/ipa and upload). - Running natively on Linux, MacOS or Windows (eg. for testing purposes). - Possibility of adding more Kits to support extra compiler, architectures, etc. - Integrated refactoring, goto definition, info on hover, documentation, etc. Imagine if each developer should have to write scripts by hand to do all that and keep up with all the platforms, compilers and packaging updates; it would be a big mess impossible to be maintained. It is better to write tools to do those things, and let people contribute to improve them. Finally books and tutorials could be written around that ecosystem. I would like that kind of workflow for Haskell. It doesn't have to be a GUI if you don't like it, but it has to be simple enough to work without trouble. We should be writing code to solve real problems (eg. medical, social, etc). Spending time on things which could be automated is useless.
For speed, the Haskell IDE ones are much faster - https://github.com/haskell/haskell-ide-engine . You can use with Atom or VS Code, however this is new and currently lacks features compared to the older plugins on VS Code and Atom. Might be ok if speed is your primary concern? Otherwise I think spacemacs + vim bindings is the other alternative. Once you watch a vim/emacs master edit code you can appreciate that you CAN learn it really and it CAN be really effective, if you push through the pain ;) Emacs does have the most powerful Haskell integration IMO with almost no setup.
Strange how different my output is from yours. One thing that caught my eye. ``` The cabal-install found on PATH is a version stack doesn't know about, version 2.0.0.0. This may or may not work. See this issue: https://github.com/ghcjs/ghcjs/issues/470 ``` In your output, it seems like a new version of `cabal` is being used (`Cabal-2.0.0.2`). ``` error, called at ./Distribution/ReadE.hs:46:24 in Cabal-2.0.0.2-inplace:Distribution.ReadE ``` Since the version of ghc this ghcjs uses is 7.10.2, it can't use this newer version of Cabal (and GHCJS hasn't been released for `8.2` yet). I'd try to either downgrade you version of cabal (in `/usr/local/bin/cabal`), and/or try running `stack setup --no-system-ghc`) again. here is my output for reference, http://lpaste.net/360459
How would I downgrade my cabal? The no system ghc didn't work.
I would also recommend checking out HIE, but since that has already been suggested, you could maybe also check out ghcid, which also has a VSCode plugin.
You might be running into the same issue I had, you can try the fix I did in https://github.com/DanielG/ghc-mod/issues/905#issuecomment-327146373. It will probably work after doing that.
&gt; can be a learning curve Very much so. While I quite like FRP, I don't think I could recommend it with a 2-day deadline. So be careful with taking this route, /u/rsChron 
Oh I only brought up FRP because `reflex-dom` gives you `jsaddle-webkit2gtk` out of the box, no `JSM` configuration necessary. I am not suggesting it on a 2 day deadline. `ghcjs-dom`, however, is more reasonable; and I would still recommend `reflex-platform` as the means to setup GHCJS etc..
Yes, brick is very nice. I can also attest to it being easy to learn and use. I could get started using it in about half an hour IIRC, and learn much of it in a few hours, along the way as I was using it. If, as /u/gilmi says, a TUI suffices, this could be a workable avenue for you to explore even with your deadline.
Agreed. 
Thanks! In that same folder you described, I only have Cabal-1.24.2.0.conf. I guess my Cabal 2.0 file is somewhere else, and that I should delete it
yea, just use nix :)
Stackage is not the error here. This looks like it may be an incompatibility between Stack and Cabal-the-library 2.0.0.2? /u/rsChron, what version of Stack are you using?
Is purescript an option?
almost :) the plot thickens, the thick plottens.
I'm required to use Haskell. Unless there's some way for them to be interloped. 
but it would have gotten deleted already in the ```rm -f ~/.stack```
I was wondering how OCC (Optimistic Concurrency Control?) differs from MVCC? Is it related to the ability to have user-supplied resolutions?
&gt; Cabal-2.0.0.2 All my Cabal-2.0.0.2 files are in nix. and end with .drv. Should I delete them?
`default (Text, String)` can provide very nice inference still even with `-XOverloadedStrings`.
oh yea... ur right. Not sure what's happening :( 
Multiple cursors have never slowed down editing noticably in my experience, even numbering in the hundreds... But there is sometimes a bit of a 'hurk' when selecting all occurrences in a very large file. I'd imagine you could probably get slowdown at some point, but I haven't hit it yet.
I believe they were suggesting just using Purescript on the frontend. It's probably the easiest frontend option available right now for haskell-like languages.
Someone correct me but I think Functors are by "nature" not powerful enough to deal with any kind of "memory". Efficiency in this case requires memory of past events. I think you are saying functors are not efficient because they have to re-compute values, even though they have already been computed. The only way to avoid this is to remember the computation, something which can only happen with recursive data structures (functor is not an RDT). Monad on the other hand has the ability to compose recursive computations, which would allow the capacity to check if something has been computed and use the value in memory if so. 
At this point, I'd just go through the nix instructions on the README.md, should be straightforward. After installing nix, cd into sample-app and call `nix-build`.
So time based cache invalidation was actually thrown in as a bonus towards the end. There's only one API server that's going to be running -- the project uses SQLite as the backend and I want to see how far I can go using just SQLite. The cache invalidation for most lookups is actually manual (since there's only one API server putting stuff in the database), something new comes in I just wipe the appropriate caches. I think a well constructed DB monad could absolutely get the caching and cache invalidation right -- that wasn't the approach I took, however, though it could be better depending on the approach. I chose caching at the API layer (via an app component that's exposed to everything), so I could cache things that my not be stored in the database per say.
So finally got it installed and the speed is amazing, I backspace out a letter from a variable located at the very bottom of my biggest file (3500 lines) and it marks an error within a few seconds, and in another file that is at 300, it is nearly instant, no need to save the file for it to trigger as well. As a note for anyone else, perhaps some wayward googlers from the future... If you get an error about cabal not supporting `custom-setup`, make sure you have updated stack before you waste an hour pulling your hair out messing around with cabal. I was on v1.1.# and the latest version after `stack upgrade` is 1.5.1. Makes all the difference... &gt;_&gt;
When I call nix-build I get this error: app/app.nix:3 has an unfree license (‘unfree’), refusing to evaluate. a) For `nixos-rebuild` you can set { nixpkgs.config.allowUnfree = true; } in configuration.nix to override this. b) For `nix-env`, `nix-build`, `nix-shell` or any other Nix command you can add { allowUnfree = true; } to ~/.config/nixpkgs/config.nix. I'm not sure where I can edit these files 
It's unclear to me if this has to be a web application, or if you are simply using web GUI's because they are one option. You mentioned 'three-penny gui packaged as a desktop app'. If a desktop app is fine then I'd use: http://hackage.haskell.org/package/gloss Here is a tutorial, http://andrew.gibiansky.com/blog/haskell/haskell-gloss/ 
``` mkdir -p ~/.config/nixpkgs &amp;&amp; echo '{ allowUnfree = true; }' &gt;&gt; ~/.config/nixpkgs/config.nix ```
I wonder if it would be possible to cheat and make a Memoizable instance of Event and Behavior and then write law-breaking Functor instances that do some weird stuff under the surface to behave in a 'morally correct and efficient, though technically wrong, way'
I'm going to change the license just because everyone hits this.
Ok, you can go ahead and `git pull origin master` from `miso` and then `cd sample-app &amp;&amp; nix-build`, it won't worry about license issues anymore. Feel free to do a `nix-channel --update` as well.
Nice, glad you are happy with it :) 
Which one?
I have just managed to get neovim working with ghc-mod. It's pretty quick, asynch, and you can't beat the responsiveness of vim. My setup is complicated enormously by my decision to use NixOS. For folks using the spaceneovim haskell layer, intero works out of the box and it works really well. I also found that hdevtools in server was quick quick off the first invocation. Folks have also had a lot of success with the haskell intero plugins for IntelliJ.
`5 minutes` to understand what is functional programming. &gt; functional programming is language where function is the first-class citizen, There is no difference between `int` and `(int -&gt; int)` other than type. &gt; I know in `python` I can use a function in `map` before but in Haskell it a lot easier to understand. `Forever` to learn the rest (joyfully). I know some programming languages (BASIC, Pascal, C, Python, C++, C#) before learning Haskell. 
VSCode uses the Javascript I/O model and it's calling out over I/O to intero. It took me approximately 40 seconds to find a commit demonstrating this: https://gitlab.com/vannnns/haskero/commit/8c23b8a8c34257158bec66be3486c3865aed884d If there is one thing javascript's good at, it's async I/O. You sorta have to give it that. Even naive nodejs programs often outperform competitors in the space, even Golang.
if you are looking to go with the ELM approach, I suggest to use [servant-elm](https://www.google.com.sa/search?q=elm-servnt&amp;oq=elm-servnt&amp;aqs=chrome..69i57j69i60l4j69i65.2693j0j7&amp;sourceid=chrome&amp;ie=UTF-8) and [elm-export](https://github.com/krisajenkins/elm-export) the former will help you to generate the ELM api that call servant endpoint and the latter will generate ELM types from your haskell type. this [file](https://github.com/kwaleko/blog-post/blob/master/src/Adapter/FrontEnd/Generated/Types.elm) is an example for the above, I did not write any line of code rather it is generated from haskell which save time and help you to focus on the logic instead of writing JSON`decoder` and `encoder` and types again, and ofcourse, your frontend will stay in sync with the backend.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [kwaleko/blog-post/.../**Types.elm** (master → 99db95e)](https://github.com/kwaleko/blog-post/blob/99db95eec780b69f0610ac53835ce8195b2d9347/src/Adapter/FrontEnd/Generated/Types.elm) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
FWIW, the use of `{;}` is quite pervasive throughout GHC's code-base. There are lots of places where `do` blocks don't use indenting but rather `{;}` with the classic prefixed `;` style, e.g. cgBind :: StgBinding -&gt; FCode () cgBind (StgNonRec name rhs) = do { (info, fcode) &lt;- cgRhs name rhs ; addBindC info ; init &lt;- fcode ; emit init } -- init cannot be used in body, so slightly better to sink it eagerly cgBind (StgRec pairs) = do { r &lt;- sequence $ unzipWith cgRhs pairs ; let (id_infos, fcodes) = unzip r ; addBindsC id_infos ; (inits, body) &lt;- getCodeR $ sequence fcodes ; emit (catAGraphs inits &lt;*&gt; body) } 
thats amazing. Thanks! Seems pretty straightforward to me although I don't have much web dev experience.
Answer: use of mutable references `IORef`
I find it easier to think of applicatives in terms of `merge :: f a -&gt; f b -&gt; f (a, b)` (with `pure :: a -&gt; f a`), as these are computationally equivalent (given `Functor f`). Likewise, monads can be considered in terms of `join :: f (f a) -&gt; a` and `return :: a -&gt; f a` (again, assuming `Functor f`). These methods are generally easier (for me, at least) to think about, and reveal both classes' underlying monoidal structure. Anyway, I'm glad you found a solution. Just here with another perspective. The monad one is pretty well known, but the applicative one seems less so.
what I did in my project is expose some REST API to handle the communication between Haskell and ELM and I have used [servant](https://hackage.haskell.org/package/servant) for this purpose. for example in the backend I have a `parser` that take a `Text` and parse it to a specific format. What i did is to expose the parser behaviour using api endpoint so I get the `Text` from ELM( client) and process the parsing on the backend then return the parsed data to ELM. for example check [this](https://github.com/kwaleko/blog-post/blob/master/src/Adapter/API.hs#L42)
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [kwaleko/blog-post/.../**API.hs#L42** (master → 99db95e)](https://github.com/kwaleko/blog-post/blob/99db95eec780b69f0610ac53835ce8195b2d9347/src/Adapter/API.hs#L42) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
`stack script --ghc-options` is a good one, thanks!
Potentially stupid question, but you don't have those 5k LOC in a single file do you? VS Code doesn't perform terribly well on really large files and a lot of features get turned off. If this is the case you could probably find an editor that will handle this better, but you'll also find maintaining a file that large really painful.
&gt; Is there a way to get these to have Monad-like behaviour or get them to use do notation? Perhaps try `-XRebindableSyntax`?
For me it lagged a lot and rarely worked. However Ghcid in VSCode does give compiler feedback pretty quickly.
Last I checked it severely limited which Haskell libraries you can use in your projects.
&gt; but they won't invest $600,000 to develop one To attempt develop one with a 5% chance of success.
gtk2hs is pretty alive still (I think it's still being not bad) and it's not very complicated but for your task brick looks better (I think)
good job mr.runKleisli thank you solve :: [Double] -&gt; [Int] solve hs | isSquare (length hs) = let n = floor (sqrt (length hs)) xss = possibleInputs n ys = map (eval n hs) xss ymin = minimum ys answers = [xs | (xs,y) &lt;- zip xss ys, y == ymin] in head answers
Assuming this is the OP I'll reply here. I've been working with Haskell for a few years now, and a couple of those professionally, and I've been using Windows exclusively. So it definitely works, let's say, 90% of the time. That being said, it's true that Windows support is an after-thought for a lot of developers/maintainers and you can't really blame them. They want to make applications and libraries, not mess around with setting up Windows VMs and fixing obscure issues that arise (though it would be great if people were less trigger happy in using libraries that are OBVIOUSLY Windows-incompatible). The best advice I can give you is to set up msys and do everything through it. You will need a bit (ton) of patience but it can be managed. As for GUI, this is probably your best bet https://hackage.haskell.org/package/fltkhs. The developer actually cares about Windows support. Sometimes I wonder how much bigger Haskell would be if the answer to "How can I get a window with a button on it work in the most popular OS?" wasn't "Uhh......."
Conor has an [SO anwser](https://github.com/pigworker/so-pigworker/blob/b3acb4a402ccf726fe835f94101505869745899b/markdown/indexed-monad.md).
Yes, this is what I found out, too and is mentioned in my edit. :)
Which FRP library is mature for backend use? (as opposed to gui programming)?
I think you've written `join` wrong here (should be `join :: f (f a) -&gt; f a`), but otherwise, I agree.
Whoops, fixed. Thanks.
Yeah. For the browser, right now, Purescript is my favorite.
If your only problem with Emacs is its insane keybindings, try [Evil](https://github.com/emacs-evil/evil).
I think [elm](http://elm-lang.org/) is an excellent language for teaching functional programming. It's easy, practical, has a friendly compiler and a very helpful community.
Make sure to check out gloss (http://gloss.ouroborus.net/) for 2d and notgloss (https://hackage.haskell.org/package/not-gloss) for 3d. 
Functional languages are harder to approach and you want to interest the student in the practice. I think if you had to pick one as your first language, that would be scheme.
Something like Racket or Clojure. Functional, but dynamically typed. IMO they're not any harder to grasp than Python.
Plenty are included last I checked, maybe there's a way to install more now, I haven't checked in a while. I feel this would be perfect for OP to learn. Later when the language is less of a problem, he can switch to emacs or whatever.
When OP wants to make something as he learns, be it a computer game, website, economic simulation or whatever, and he finds on reddit/SO that there's a package that does something he needs in his project, but also finds the hard way that he can't use it on HaskellForMac, it's going to be a negative experience and a roadback.
Join is implemented as following: join :: (Monad m) =&gt; m (m a) -&gt; m a join x = x &gt;&gt;= id if x has type : m ( m a) then then shouldn't the right side of &gt;&gt;= have type: (m a -&gt; m (m b))? 
They are distinct because they operate on two different levels. `unit` is a "regular" function, meaning it maps values of the underlying type (e.g. `"hello"` or `42`) to values of the monad (e.g. `Just "hello"` or `[42]`). The type constructor, on the other hand, is a type-level "function": it maps types to other types, e.g. `String` to `Maybe String` or `Int` to `[Int]`. Notice how the type constructor of the `Maybe` monad is `Maybe` while its `unit` function is `Just`. It would be nonsensical to write `Maybe 5` or `Just Int`, because they do not operate on the same objects (types and values). Value-level functions are the expression evaluated by your program during its execution, hence why I described them as "regular". Type-level functions, on the other hand, are evaluated by the compiler when it type-checks your program for correctness.
Is there a simple and easy to understand tutorial on state monad and free monad? I have seen plenty of tutorial and I just still don't get it... Is state monad a automation for continuous passing style? Please give an easy example... Please...
As negative experience as spending more time trying to get IDEA/Emacs/Vim than actually programming in Haskell.
Scheme is good cause minimal syntax let you focus on concepts. But for high school maybe python is better cause you students want to see fast interactive results. Out of schemes maybe Racket is ok.
Let's do the unification by hand: x :: f (f t) (&gt;&gt;=) :: m a -&gt; (a -&gt; m b) -&gt; m b id :: c -&gt; c so in `x &gt;&gt;= id`, we have f (f t) = m a -- from plugging x into the first slot of &gt;&gt;= a -&gt; m b = c -&gt; c -- from plugging id into the second slot The first equation means `f = m` and `f t = a`. The second equation means `a = c` and also `m b = c`. We can combine these to also conclude `f t = m b`, and so `t = b` too. Substituting these back into the original types, we get x :: m (m t) (&gt;&gt;=) :: m (m t) -&gt; (m t -&gt; m t) -&gt; m t id :: m t -&gt; m t 
I would go with Racket, which is a dialect of Scheme. How To Design Programs is a great first book. Dr Racket environment can grow the language with your students as it follows this book to make error messages simpler because in the earlier stages there's less the language let's you do. http://htdp.org
methodless classes with extra laws are weird. if you call a method from either superclass, the pair of constraints is inferred, not the subclass. 
Check out this video from one of the creators of Racket, talking about how they use it to teach programming to middle and high school students: https://www.youtube.com/watch?v=ayoofXuKqMY Then there's the Code World project which aims to replicate Racket's success with Haskell, by teaching a simplified version of Haskell to students: https://www.youtube.com/watch?v=7CGuI9HcfqQ I recommend checking out both projects even if you choose to go with another language. 
&gt;I can't see any difference between the type constructor and the unit function - why are they broken out separately as requirements of a Monad? The difference between the two doesn't come from the nature of monads, but from the way monads are implemented in Haskell. I would recommend you check out Idris because there's no distinction between type-level functions and value-level functions, and concepts like monads become a lot clearer when you use it. 
Bash and Racket, in my case. Source: am a high school student learning programming.
fwiw, Dante and ghcid both work for me and have been fast. the latter is a fork of intero and thus more convenient, the former is just a ghci that watches your files, and thus is more robust (I just keep the ghcid output open in emacs with compilation-minor-mode). https://github.com/jyp/dante/blob/master/README.org https://github.com/ndmitchell/ghcid/blob/master/README.md
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [ndmitchell/ghcid/.../**README.md** (master → 6380d7d)](https://github.com/ndmitchell/ghcid/blob/6380d7d7ff8c01fd2b30f828720214529687cf4f/README.md) * [jyp/dante/.../**README.org** (master → ac0b97c)](https://github.com/jyp/dante/blob/ac0b97c7c7a9b4757daaf8af1f431f3e9b7844e4/README.org) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
&gt; Is state monad a automation for continuous passing style No. This is a partial explanation of `State`. Suppose you have three functions like foo :: a -&gt; b bar :: b -&gt; c baz :: c -&gt; d Applying and composing functions is what functional programmers like to do: baz . bar . foo Alas, now our requiremens change and we need to thread some kind of state through the computation. It might be some kind of counter which the functions might have to check and update. So now we have something like: foo :: a -&gt; s -&gt; (b,s) bar :: b -&gt; s -&gt; (c,s) baz :: c -&gt; s -&gt; (d,s) Darn, now we have lost the easiness of composition, and instead we have: bazDotBarDotFoo a s = let (b,s2) = foo a s (c,s3) = bar b s2 in baz c s3 Ugh. So to alleviate this we decide to put the troublesome state-threading bits behind a newtype, in a way to pretend "they arent there"; to partially regain the clarity of the original definitions: newtype State s x = State { runState :: s -&gt; (x,s) } foo :: a -&gt; State s b bar :: b -&gt; State s c baz :: c -&gt; State s d And furthermore, we define a `&lt;=&lt;` operator which tries to mimic how `.` worked for pure functions, but also takes care of the troublesome state threading stuff, so we don't have to repeat the logic each time: (&lt;=&lt;) :: (b -&gt; State s c) -&gt; (a -&gt; State s b) -&gt; a -&gt; State s c fbc &lt;=&lt; fab = \a -&gt; State $ \s -&gt; let (State sab) = fab a (b,s2) = sab s (State sbc) = fbc b in sbc s2 now it almost look as nice as with `(.)`: baz &lt;=&lt; bar &lt;=&lt; foo
I also agree that Racket is a great choice.
Another vote for BSL (with DrRacket as the environment). The first lecture or so in this course discusses why https://www.edx.org/course/how-code-simple-data-ubcx-htc1x
This is not a tutorial, but I'll try to explain the motivation behind `State`. Haskell is purely functional: a function, on the same input, always returns the same output. In other words, a pure function cannot store internal state. However, many algorithms are quite naturally expressed in a stateful way, e.g., quicksort; how can we implement them in Haskell? A simple way to represent a stateful computation is as a pure function that takes the initial state as an argument and returns the result together with the final state. The `State` type describes such functions: type State s a = s -&gt; (a, s) The fact that `State s` is a monad means that it implements a certain interface (which is the `Monad` type class in Haskell, but you can translate that in any language with higher-order functions). Without going into the details of it, the consequence is that we can write stateful functions in an imperative style even in a purely functional language. 
[CodeWorld](https://code.world) teaches Haskell to [young audiences](https://github.com/google/codeworld/blob/master/Users.md), with a custom Prelude equipped with graphical primitives to easily make animations and games.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [google/codeworld/.../**Users.md** (master → 94dfd29)](https://github.com/google/codeworld/blob/94dfd29664aa33e1d2db44aa21bcea499fbbded4/Users.md) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
Thanks for the link on Idris. I think it might be too much right now, but I see it supports some other concepts I've had on my bucket list also: theorem-proving (like Coq), tactics, and embedded DSL's.
That's a really good explanation, it makes perfect sense. Thanks!
&gt; Is state monad a automation for continuous passing style? No, it's an automation for _state_-passing style; the continuation monad is an automation for continuation-passing style. State-passing style is: you have a bunch of functions that, in addition to their inputs and outputs, take a "state" input and produce a "state" output, so if you have "stateful" functions `foo :: A -&gt; B` and `bar :: [B] -&gt; C` and a state type of `S`, you actually have `foo :: (A, S) -&gt; (B, S)` and `bar :: ([B], S) -&gt; (C, S)`. You can write code like that (I had to once), but it gets quite tedious, especially since you have to explicitly pass the state everywhere, and make sure to use the right state. The `State` monad automates the default case. For me, the way `State` really clicked (along with `Reader` and `Writer`) was to write a simple type inferencer, first without monads, then with them. I had to do it for [this](https://pl.cs.jhu.edu/pl/assignments/assignment5.shtml) assignment, though [this](https://goc.vivint.com/problems/hm) coding challenge explains it well too. I used the `Reader` for the type environment, the `Writer` for the constraints, and the `State` for a counter to generate unused variables.
Functional programming is a real skill and languages are moving in that direction so any functional language is going to be better than Python for new students. Racket is good for beginners. Clojure is good as well. I wouldn't shy away from Haskell if you are knowledgeable about it and can relate the concepts to the kids. The real key is how accessible you can make it for the students to get them thinking about programming and how computers work and that probably trumps the language you actually teach them. Back in 2010, I taught Math for a year in a public middle school on an impoverished island in the Pacific. I introduced my students to JavaScript. Why? They had access to a laptop, notepad, and a browser and teaching them how to do metric to standard conversions was part of the curriculum. But probably more than either of those two, my students needed to immediately be able to see the results of what they did. What I was doing was outside the curriculum a bit so I didn't want to waste a lot of time focusing on programming concepts. I don't know how successful it was but students still remember it and one of them is graduating this December with a degree in Computer Engineering. 
You could consider Pyret, which is a language created by some of the people behind Racket intended to serve as a better teaching language. https://www.pyret.org/ Another way of seeing it is a better (for teaching) version of Python. For Haskell folks, probably the most interesting part (compared to Racket, Python, etc) is that it has proper algebraic data types.
But I think codingame is much better thant codewar.
And at the very end of the course you can direct them to the wizard book.
You can do a lot of cool functional things in Python. Python is just too simple for me to not recommend you use it as a high schooler.
That isn't really true. The unit function and type constructor represent two different parts of what a monad is in category theory. It's true that both category theory and dependently typed languages derive a lot of power from the fact that concepts can be thought of on multiple levels at once. For example, in category theory you can interpret a functor as itself being an arrow in a category that has functors operating on it, and a dependently typed language perhaps makes it a bit easier to exploit that in programming. But I wouldn't say that makes monads easier to understand for a beginner.
I would choose any language that has a good graphing library, and focus on math exploration. Math is a ticket into many deep domains where programming has an intersection.
&gt; The unit function and type constructor represent two different parts of what a monad is in category theory. Can you elaborate on this? 
How about Swift? On the one hand it has the practical usefulness of being backed by Apple and thus being "hip" and having real-world use, but on the other hand it actually has a decent theoretical foundation - much better than any other mainstream language (though not as good as Haskell).
Not functional, but Processing is wonderful; graphics and animation from the very start. Leads directly into Java (if you consider that a good things); also has a Python mode.
no reverse dependencies on hackage, afaict https://packdeps.haskellers.com/reverse/auto
Justin Long, the author, posts about auto related things quite a bit: https://blog.jle.im/ It helped me understand reactive programming and streams. 
I mean codewar wasn't mentioned...
I'm not sure I agree that functional languages are harder to approach. If you have absolutely zero prior programming knowledge, just some basic mathematics, I feel like there isn't going to be much difference in approachability between FP and imperative, hell FP might even be a little more approachable.
I mean you can make various styles of app in Haskell, from webapp to native application.
Honestly I think Haskell is fine, perhaps with a custom prelude to simplify things at first.
I would agree with Elm as well. On top of it being a simpler functional language, the elm architecture gives them a framework to build up so you don't have to teach them how to layout their code. It also has that "immediate usefulness" factor in that they can build web pages and other things that they would be able to show off to their friends and family, instead of just building terrible command line applications. This will hopefully keep them engaged better. &gt; friendly compiler The compiler messages are really quite amazing and this feature on its own would be enough for me to recommend it as it should make the students a lot more self sufficient and stave off frustration. /u/m0d2 check out these two links for examples of elm compiler errors: http://elm-lang.org/blog/compiler-errors-for-humans http://elm-lang.org/blog/compilers-as-assistants
I think Reflex is doing some unsafe stuff underneath, for example, so yes, this seems to be solution.
[`intero-neovim`](https://github.com/parsonsmatt/intero-neovim). /u/owickstrom is working on getting plain GHCi support in there as well, so we might have to change the name to something more general :)
Different user, but I think they're thinking of the type constructor as representing the (endo-) functor `M` that is monadic, and the unit as the natural transformation `η : 1 -&gt; M` (where `1` denotes the identity functor on whatever category we're looking at). The missing bits are the natural transformation `μ : M² -&gt; M` (`join` in haskell) and a couple of coherence laws relating these things. 
Indexed Monads sound a bit similar to the dependently typed Finite State Machines I've been playing with in Idris (from TDDwI), are they related (and how?)?
oh! I'd read their series on neural networks, didn't know it was the same author.
https://blog.jle.im/entries/series/+all-about-auto.html
* Justin Le
Is it true Pyret was prototyped in Racket, but is now build on JavaScript ?
Yet another user, but I agree. The type constructor is present in Functor instances as well, `unit` is not.
I teach Haskell to my 7 year old and 11 year old kids and they have grasped it pretty well. This is their very first exposure to any programming. They have written simple but full programs as well using vim editor and stack to compile. They can navigate hackage to go through the documentation, mainly simple base modules like Data.Char and Data.List that they need for the problems that I give them. They can understand simple types, use :t and :info in ghci to understand functions and figure out some type errors as well. It was not very difficult for them to grasp things like map and filter. I think we underestimate kids, they can go much beyond what we think they can, we just need to try. I had to do some ground work to introduce concepts in the right way, in the right order and refreshed them from time to time.
&gt; I don't think Haskell itself is a good one for this purpose, but you may have another simpler functional language in mind. Why not? Is there a lack of resources for teaching? I think high-schoolers are perfectly capable of learning Haskell if the material is presented to them. 
Depends what for. I think it's fine for teaching a bit of frontend, but it lacks the abstraction necessary to do larger projects. 
Haha, I visited the blog, double checked his name. And I still typed the guy from Jeepers Creeper's. How embarrassing. 
Using gtk2hs is fine (especially if you know the paradigm), but deployment can be tricky. I wish someone would build a `.cabal`-to-Windows-installer tool that just completely takes care of that.
I would actually agree that Python probably the right choice, even though this surely depends on many factors like how much computing concepts these high school students know, and how mathematically inclined they are. If you do want to teach a functional style of programming, just stay away from that OOP stuff and make limited use of mutation. Even without knowing classes, there’s a lot that can be done in Python. 
I think the main difference with the FSM in Idris is that the postcondition can depend on the returned value.
Not Haskell. Not Python. Plain old C. Lisps are nice too, but then again - in most cases - GC. For a GC'd language I'd recommend Go anyway, since it's preposterously easy. In general I think it's a bad idea to teach languages without managing memory by hand (as the first language). A programmer **must** know that memory isn't just an abstract thing that exists somewhere. It is there, and we rely on its capacity on a daily basis. It is even more important when running on constrained resources. And this is ever more relevant in the context of distributed computing. In my experience people who start with languages with managed memory usually have literally no idea what's going on behind the scenes. Unfortunately Haskell is one hell of an example regarding memory problems. And so is Java (ever wondered why running out of memory is so common in Java apps?)
I don't think there's a one, at least without refining the question with regards to the goals of instructions and context further. 1. Something with a small core that doesn't have too many gotchas. PHP and JavaScript lose on the gotcha side, C++ is too huge. 2. A REPL of some sort is valuable. I think a quicker loop between writing and execution is motivating and besides using it as a better calculator comes handy. 3. Either dynamically typed or a good enough static type system, i.e. not C or Java. 4. Easy access to graphics stuff. Making a damn turtle move and stuff like that. Limiting yourself to terribly command line programs isn't that fun. 5. Easy access to arbitrary-precision arithmetic and why not rational numbers as well. The warts of the usual floating point arithmetic and ints/shorts/longs isn't that terribly interesting in the beginning. 6. Sane access to recursion - it should Just Work transparently enough. Understanding implementation details is premature understanding. 7. Compiler errors should be ideally good. Trying to guess what is "noob friendly" is perhaps a fruitless route, but something that pays off to pay attention to with some learning would be good. 8. Utf-8 friendly. I think that delaying learning about character encodings is good and kids like emojis so let them blast them around. They can be good in text output as well for projects of beginner level, like a poker game and so on. 9. I have a preference for pattern matching, it's pretty great. I think kids are going to agree. I don't know of any language that fills all of these criteria. In the end, some of them might not be that important or even beneficial.
Well, as I see from quick tutorial overview, this package uses arrows with `proc-do`-notation. Code generation for `proc-do` is extremely inefficient. Using arrows without `proc-do` is not very convenient and what you want to do... This might be one of the reasons explaining why nobody uses this package yet.
Haskell is good as part of a math class. I think Python is becoming a standard for good reason. If it were me I'd say goal is to create excitement by having them hit wins fast. Livecode. Get them to a result fast. 
Without 9, this is BSL.
Currently only supports stack; but I haven't found any other solutions like this around. Uses pieces adapted from stack's build process and some stuff from https://www.reddit.com/user/taylorfausak 's workflow. Hope this saves some other folks some time.
I ended up switching to https://github.com/haskell/haskell-ide-engine, still using VSCode, and now everything is super fast again. Inline errors show up in &lt;5 seconds on my biggest file (3500 lines) and virtually instantly in all other files. Doesn't require me to save either to kick off the error checker either which is a nice bonus, it just does it as I type.
Somewhat related: Anyone know how to build distributable binaries with Nix? I'm guessing you just turn on all the static linking imaginable, and somehow reverse or prevent the `patchelf` process?
&gt; Yes, brick is very nice. I can also attest to it being easy to learn and use. I could get started using it in about half an hour IIRC, and learn much of it in a few hours, along the way as I was using it. I'm glad to hear it!
Do you have any documentation about or experience with `proc` being inefficient? It just to sugars to munging tuples, right? afaik, Opaleye uses proc to build queries. And if the Arrow value doesn't get too big, maybe the inefficiency doesn't matter? 
Racket is pretty good. But I'd also argue that Coq is also a strong contender, thanks to resources like CoqIDE and *Software Foundations*.
Haskell-gi / GTK works fine with Windows. Building it can be a pain, but it's not impossible, just obnoxious.
The values built by Opaleye using arrow notation are not really executed directly. They're converted to SQL, so it's not hugely important whether arrow notation build efficient queries.
- lua (you can use with torch for math neural network ) - C# because will be used in the next steps for jobs is easy to start it and can be more complex . - no for the python don't work very with neural network and some python modules are not very good also some bugs - no for java will need more time to have a good development area of working 
Very nice read, thank you!
Alright, so. This is obviously a low effort post. But what you're building is a [REPL](https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop). Since we don't know the details of the commands/expressions that you need to execute/evaluate, we can't help with that part. The skeleton of a REPL in Haskell is pretty short though: main = repl repl = do line &lt;- getLine result &lt;- evaluate line -- up to you to implement `evaluate :: String -&gt; IO a` print result repl
**Read–eval–print loop** A Read–Eval–Print Loop (REPL), also known as an interactive toplevel or language shell, is a simple, interactive computer programming environment that takes single user inputs (i.e. single expressions), evaluates them, and returns the result to the user; a program written in a REPL environment is executed piecewise. The term is most usually used to refer to programming interfaces similar to the classic Lisp machine interactive environment. Common examples include command line shells and similar environments for programming languages, and is particularly characteristic of scripting languages. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/haskell/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
Looks great! I'm glad my workflow helped out. I've been meaning to write it up, but maybe I won't have to now :) 
I guess there is hypothetically a way to push these into a different branch so you can have a link in your README where you can download a binary blob of any build of any commit or tag straight from github.
yeah, that's what I meant; it just builds the syntax. It can't be slow, unless you're sql query as text is weirdly huge. 
While that's true, abstraction is often seen as the bane of understanding and learning. Plus, I'm pretty sure a high school class isn't going to build a huge 10k+ loc project in a semester starting from 0 programming experience, so they'll probably be fine.
What is BSL? Surely not British Sign Language?
I think it's referring to Racket's "Basic Student Language"
When should you and when should you not write a function with arguments curried/uncurried? My intuition is that arguments should be curried when they are semantically inseparable, but it also seems silly to unnecessarily complicate things by having some functions require a tuple and others not. What is the standard wisdom regarding this?
Your English is great (except for capitalization, and your use of commas where a period should be). 
This is cool, I will be checking this out
With this setup https://github.com/choener/MutationOrder/blob/master/.travis.yml I only build tagged releases. The tagged releases show up here: https://github.com/choener/MutationOrder/releases which I point to in my readme (see README.md of that project). Does that help?
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [choener/MutationOrder/.../**.travis.yml** (master → 081d804)](https://github.com/choener/MutationOrder/blob/081d804f4639f6feabdcfe0e66ab1b95b5ac31d5/.travis.yml) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dqqabht.)^.
I was thinking something like attaching a build for every commit so that you can i.e. direct people to test a version built after a patch commit in an issue thread, but GitHub doesn't provide a way to attach builds to commits like you showed with tags.
Actually, I'm pretty sure that works. During my tests here https://github.com/choener/DeploymentTests/releases I managed to actually build for untagged commits before I curtailed that. You'll need commit 7eb... which should build on every push to master, I think. You can then point to releases and search by commit. And the newest one is on top, given that it did build.
Vim's most recent version supports concurrency for plugins.
The problem with those tricks is that your morally correct optimization could stop firing due to completely unrelated changes somewhere in your codebase. If it's a minor optimization you need for saving a few bucks in EC2 costs, the fine, but if your operation depends on it, then you'll be in a nightmare. 
In Haskell the usage is to curry functions (`a -&gt; b -&gt; c`) by default. If some arguments are inseparable as you mention, it would be better to define a custom type (perhaps a record), than to use tuples. This also gives a good place to document the meaning of the combined values.
Perhaps you misread "CodeWorld" as "CodeWar"?
Wtf? This is just went from cool to dustbin material.
I already know a fair bit of Haskell. I just want to try out an IDE which I can then in turn recommend to my colleagues. And no, I cannot recommend emacs or vim. My attempt to introduce Haskell will we dead on arrival if I propose emacs or vim as an IDE. Lack of tooling (compared to Java/Kotlin) was the reason why I dropped Haskell last time, because there was zero hope of introducing it to work, and unfortunately the situation remains same :(
You can install whatever you want with cabal and stack, in Haskell For Mac. See my other comment with a link to their FAQ.
Comments are needed to communicate the intent of your design, on a small scale, to future readers. That takes many forms. Communication is not a universally solved/solvable problem, and so there are not universal rules about when to write comments. Code can be more or less clear about behavior, but no code, regardless of language, is any more or less clear about the distance between the intent of the design, and the actual behavior as implemented.
The way I see it, a programming language offers several ways of expressing yourself, and they are not equally suited for all communication tasks. You have: - Programming language constructs (expressions, types, typeclasses, ...) - Naming, coding style, indentation - Structured documentation (Haddock) - Automated tests - Assertions - Examples - Free-form inline documentation - Free-form external documentation (README, `./docs/...`, man pages) Each of these has certain advantages and disadvantages; generally speaking, it is better to use rigid, explicit and checked communication channels when possible, and sacrifice as much of those as needed to get the information across in an efficient manner. Haskell is very expressive by itself, embedding more information in language constructs than many other languages, so we can usually do fine with much fewer free-form comments. In Clojure, for example, you have to document what types of arguments a function takes, what return types you should expect, and what kind of side effects it has, while in Haskell, we can gather all that information from the type alone. Often, though not always, a Haskell type signature gives you almost all the information you need, and you don't need any further documentation at all: e.g., a function `isZero :: (Num a, Eq a) =&gt; a -&gt; Bool` can only do so many things, and the name clearly tells us which one of this it is going to be. Adding a comment to repeat this information is completely redundant, so we don't do it. However, if this function has edge cases (e.g., when used with floating-point numbers, the usual caveats about equality comparisons on floats apply), then those should be documented, and neither the type system nor the function name are suitable places. So we'd resort to a combination of unit tests, examples and free-form documentation to cover these edge cases. There might be an alternative function with epsilon comparisons that is more suitable for floating-point calculations, and we would link to that in the Haddock, as well as pepper that function with unit tests and examples to cover the differences and intended usage, and we would also write inline comments on the inside of that function to explain exactly what it is we're doing, and why we chose a particular epsilon. So, in a nutshell, pick the strongest possible communication channel for each concern.
Also on [Hacker News](https://news.ycombinator.com/item?id=15841259) with interesting comments.
Typo: Brent Yorgey drafted a new course for teaching introduction to Computer Science using Haksell 
You might want to read [Donald Knuth's](http://www-cs-faculty.stanford.edu/~knuth/) thoughts on [literate programming](http://literateprogramming.com/). He sees program writing as explaining the problem and solution to human readers more than instructing the computer what to do.
Comments should express: * Constraints on what input is allowed that aren't expressed via types (i.e. head only takes a nonempty list). * A description of the result of the function * Description of which argument is which (i.e. in pow, which is base, which is exponent) Also, treat comments like notes to an amnesiac. What will you need help to understand if you look at this code in a month?
No London in your plans for 2018, Stephen. Please come to HaskellExchange! If not you will be missed. 
Beginning Student Language is a language designed for teaching programming to students and is used in "How to Design Programs" (and the equivalent How to Code mooc). It is available in DrRacket and got everything you wanted except for pattern matching.
I think either of APL/J/K would be good for high school students. For those who are not familiar, these are array-oriented functional languages where functions are just 1-2 bytes long. As a result of this combo, these languages are more difficult to learn for those who are already familiar with traditional languages, but are easy to grasp for those who are new to programming. APL comes in several "flavours", but the good ones are proprietary. However, Dyalog APL hosts a student competition every year that might further encourage high schoolers. I am not much familiar with K, but as for J, it can be downloaded from a free license (hence it is open sourced). Unlike APL, J and K use only ASCII characters. Additionally, I am teaching a high schooler J as an introduction to machine learning, since J is powerful with arrays and matrices. The reason I chose J is because it offers a new way of thinking that would suit the young minds is high schoolers. Finally, if I were to select one of these languages to recommend to a high schooler, I'd suggest J for its great power that can be achieved in just a few keystrokes, its strength with matrices and multidimensional arrays and its idiosyncratic way of thinking and approaching a problem.
&gt; video https://www.youtube.com/watch?v=7NB8tMa8sUk
There is also SimpleServer (https://github.com/ajnsit/SimpleServer) which I wrote a while back, and which uses simple dynamically loaded haskell configuration files, and allows you to define simple cascaded handlers.
 getUser :: DBReader m =&gt; UserId -&gt; m User getUser DBReader UserID are semantically meaningful for you because you understand what user DB and `m` means (the latter usually is a monad in the haskell lingo). for the computer, that has no meaning. it is identical to: a :: B d =&gt; c -&gt; d e So these names are there for you, not for the computer. If that implicit documentation is enough, it is enough. The problem is that there are haskellers that write directly: a :: B d =&gt; c -&gt; d e and give no additional clue at all.
I think comments serve a multitude of purposes. It has become a sort of hammer in software development. One purpose is specification: a description of what the code does, without specifying how it is done. This is written as comments, but is often referred to as documentation. The specification delegates tasks and mediates between users and providers, by being a contract about what a piece of code is supposed to do. Specification also handles how the code is understood as a living document with several versions. Another is as an aid for understanding the code. How this is achieved is very situational, and takes some experience.
also: "Haksell-family"
There should be no observable difference between the two at least in terms of usage. But you'll need to provide a bit more detail. Particularly: what ghc version, what library, and what did you put in the extra lib dirs and extra-library or your -l line. If possible an output of ghc -v3 if you're not using a cabal file.
Well, following this conversation I downloaded it again now (already purchased it long ago) and gave it another try. Had to rename my existing project folder to end with `.hsproj` to open it. Why? But ok.. Then it's just amazingly slow. Scrolling on my text is just unbearably slow, and I get wrong compilation errors. My `stack.yaml` and `.cabal` files got rewritten, part of it was losing my `extra-dep`s so no way my project is going to build successfully. Bottom-line: I just can't recommend this tool. My current non-emacs recommendation is VSCode with Ghcid (which I personally use), with ctags/hasktags for jump-to-definition. So it doesn't provide any fancy refactorings or symbol type annotations but does successfully offer pretty quick compiler feedback and navigation.
I like this idea a lot. I'm not sure how I feel about the keyword `val` though. This would probably end up replacing `let` in most instances. Also, how would this work for top-level and where bindings? We could do something like: let x := y x := y where x := y I don't like the idea of writing `:=` everywhere though. We could use `&lt;-`, but it seems bad to overload that, especially for beginners. 
&lt;- is already overloaded in that way with pattern guards. Actually this feature isn't necessary because we already have pattern guards for this purpose. := is hideous. I avoid languages with that notation if at all possible. Regardless, that syntax is already taken.
&gt; Is there a FAQ about FFI on Windows? I don't think there is, but if there is one, it also ought to explain the `ccall` vs `stdcall` business on windows, and how you can avoid all that `ccall`/`stdcall` CPP boilerplate-jazz by simply using `capi` instead... :-)
What's the replacement though?
How do pattern guards make this feature unnecessary? I agree, I don't like `:=` either. There are many options like `≈`, `=~` `≐`, `=.` (maybe the last two could both work). We'd just have to be careful it's not an infix operator for existing popular libraries. Why not allow it at the top level?
I remember this SO question: * https://stackoverflow.com/questions/45260173/proc-syntax-in-haskell-arrows-leads-to-severe-performance-penalty
This would imply take home exercise correlate with how well a person can do the job they are hired for. Apparently (based on blog posts I read and a bit of experience interviewing people, so yeah, I am not really authoritative), interviews processes are really good at selecting people that are like the interviewers! Also this is barely related to haskell. 
This looks very similar to one of my old blog posts: http://tojans.me/blog/2014/02/26/cqrs-and-functional-programming/
the only real test IMO is pairing with the people and then you still don't get the full picture because they might be nervous etc. The personal bias is IMO not that bad as "team compatibility" might be a important factor as well - what's really bad is when the HR person does the interview alone. So yeah: if you can afford to pair at least half an hour with your candidates then ditch the home tests - if not I would prefer those above some stupid "how many tennis balls fit into a car" or "implement a b-tree on the whiteboard" kind of tests
There's a few different replacements, providing previous Haskell code that could already be available on GitHub, Pair Programming during the interview or as someone else mentioned whiteboard exercises. Some companies now just trust the judgement of previous companies they've worked for
[removed]
[removed]
I should have added that the Haskell houses seem to be taking this step of ditching the tests more than other FP shops. Maybe due to the competition for Haskell talent!
Agreed. To hire a good developer, there is no way around interacting with the candidate creating code. Best is face-to-face, but if you can't do that, then a take home at least gives you something. If you don't do any coding at all, then your hiring strategy effectively boils down to "let's hire more than we need, then fire the ones we don't want". I don't think that's a better strategy for anyone.
Sorry, I'm not going to do (any more of) your homework for you. 
Take home tests are nice because they make the inbound candidate workflow somewhat more scalable. They can be automatically graded to some extent and require little oversight. Taking them away is an investment in personal connections with candidates that comes at the cost of making your candidate funnel more expensive. Most likely, you will close down the rate of creating new inbound leads. You'll also do better at selling the job and will be able to identify more diverse good candidates. So that feels like a good trade-off for smallish Haskell teams. If you can create high-signal inbound leads (references, identifying public work, asking for Haskell which is already liable to be a high-performance indicator) then a narrow funnel works.
&gt; How do pattern guards make this feature unnecessary? Because you can already do non-recursive local bindings with strict pattern matching using them. &gt; There are many options like ≈, =~ ≐, =. (maybe the last two could both work). The last two would be acceptable to me. This Unicode symbol, ⩦, fits better with the ASCII symbol you provided. &gt; Why not allow it at the top level? Well the one I suggest didn't support functions, was monomorphic (to ensure sharing), and had strict pattern matching. It doesn't seem very useful to have it at the top level nor is it clear what it means to strictly pattern match at the top level.
Personally I'm completely comfortable hiring people on reputation (that I've worked with before or that folks have recommended) and skipping the tech interview. I think if someone has an inspectable body of work you can get away without a tech interview. I personally feel that attitude is the most important thing to consider when hiring, so I always prefer to have a conversation that gives me some insight into the candidate's mindset and curiosity. If we have a chat about a problem we're facing, or a direction we're thinking of going and I see the wheels turning and a spark of interest, then that's usually what I go on. That being said, I think a take home test is a good choice of filter, especially if it's an open ended question with lots of degrees of freedom. OTOH I have had the experience of spending many hours on a take home test, getting really great feedback on it, and then getting rejected on CS kinds of questions, which was frustrating. I think if you're going to get a candidate to spend multiple hours on something, make that something the pillar of the interview. From a personal point of view, I think the worst kind of testing is the whiteboard or coding interview. I don't have a CS background and I'm self taught. I suck at tech interviewing and I'm loath to spend valuable time building that skill set (I mean tech interviewing as the skill rather than actually being good at programing). As a signal I think it's poor, because it decreases diversity in teams due to making the barrier higher based on background.
Depends on the tests. The best indicator is to have a candidate solve a problem as similar as possible to what they'd be doing on-job. Ideally, chose a recently fixed problem (completed by an employee familiar with the code base in ~20 minutes or less, since the candidate will not have any familiarity), and then check their solutions against the in house one. If you're doing some kind of abstract problem solving junk, or first/second year university exam question 'implement this structure/algorithm' testing - ditch it, it's not telling you anything.
These are permanent positions based in London and are not open to remote applicants. There is the option to work 1 day per week from home. 
Haskell comments give you Haddock and DocTest. Use them for these things! I have not seen any other compelling reasons to comment Haskell code.
&gt; Haddock is creaking at the seams. Most large Haskell projects (GHC, Stack, Agda, Cabal, Idris, etc) no longer use it for documentation. I have no idea what he is talking about here. A look at the [Stack API documentation](https://www.stackage.org/package/stack) reveals Haddock annotations all over the place. Does he mean that Stack and GHC are not using Haddock for their [user guides](https://docs.haskellstack.org/en/stable/README/)? True, but I think Haddock was meant for API documentation, not writing a complete user guide. If anything, the fact that people (ab)use Haddock to write [packages that are nothing but documentation](https://hackage.haskell.org/package/lens-tutorial-1.0.3/docs/Control-Lens-Tutorial.html) shows that Haddock works quite well.
LeapYear impressed me the most. You want some way to see people coding, without artificial pressure, while also not wasting people's time. So some exercise which also helps people grow, learn while doing it seems like a good balance.
File an issue on here? https://github.com/sdiehl/stephendiehl.com/blob/master/posts/haskell_2018.md
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [sdiehl/stephendiehl.com/.../**haskell_2018.md** (master → ad9fb6a)](https://github.com/sdiehl/stephendiehl.com/blob/ad9fb6a2bf4bd72200938ecf8add8d730ea157ca/posts/haskell_2018.md) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
Questions about "quick and easy Haskell GUI" where the top answer isn't `Gloss` make me sad. You don't get quicker or easier than `Gloss`. In Haskell or elsewhere. There are cases where you don't want to use `Gloss`, but the considerations there have nothing to do with being quick or easy.
I think the idea would be affine types + prompt destructors. That would allow finer grained exception handling than the top level bracket since references would be cleaned up either way. Neat to see more practical use cases for linear types. This one is a neat crossing of resource management and type level api.
On 64-bit ghc supports only `ccall` if I were right. `capi` generates C stubs and requires header filename besides the function symbol.
Yeah. Gloss is not the best choice if you need a bunch of standard widgets and layout (checkboxes, text areas, etc). But for something like 2048, where you are doing all your own widgets and layout anyway, it is pretty darn perfect. 
Yes. From a technical documentation point of view, single sourcing with semantic context is critical. As a any professional in the field will tell you, it's really the only hope to maintain accurate, complete, usable technical documentation over time. For Haskell code API documentation, Haddock is still our only single-sourcing solution. So no matter what other documentation you write - and yes, there is definitely a need for more than Haddocks - good Haddocks are still the most important step. In my view, any code base missing good Haddocks is effectively undocumented, or will be soon.
&gt; Because you can already do non-recursive local bindings and strict pattern matching using them. Can you interleave them with monadic bindings? I don't usually use pattern guards, but as far as I can tell you can't. &gt; Well the one I suggested didn't support functions, was monomorphic (to ensure sharing), and had strict pattern matching. It doesn't seem very useful to have it at the top level nor is it clear what it means to strictly pattern match at the top level. I was thinking it would just be non-recursive. It might be useful to be able to name shadow imports at the module level. For example: id :: Either Key Int -&gt; Key id x ⩦ either id Key x This is a contrived example, but you could redefine `id` in your module while still using the `id` from Prelude without qualified imports. 
Exactly. [I use zoom and magnify for the lens library](http://www.corentindupont.info/blog/posts/Programming/2016-12-14-Haskell-structure.html#state-monad-with-lens). If you structure correctly your data records, you should be able to pass to your functions only the data they need. In the example given, a `Game` record contains a `Settings` record (instead of having one flat structure), so you can pass only the settings to your function.
Hmm, no mention of Dependent Haskell, other than participation in a multi-language project of specifications. According to previously published plans, the release of DH should be imminent by now. Has something happened?
&gt;Edit: &gt;Here is a video that displays the differences in programming paradigms. Morten Kromberg, CXO of Dyalog APL, explains APL's functional nature and why is it special, as opposed to other languages and their style of programming. You accidentally omitted the link.
I'm working through Software Foundations at the moment, but I'm curious what you're seeing as the strengths of Coq for this purpose.
Echoing /u/Syrak, I agree with "prefer record arguments to tuple arguments." My rule of thumb: curried by default, uncurried when it makes calling easier, but note that heavy use of tuples is a code smell. One situation in which I often find myself using uncurried functions is for functions of type `T -&gt; T` where `T` happens to be a tuple type.
Yeah -- more than just prototyped -- the whole first version (and maybe the first year of development) was done as a #lang in Racket, including building an in-browser editor that used the Racket bytecode-to-Javascript compiler on the backend (courses were taught with this, but it was....slow). Given that providing an in-browser editor was really important, eventually it just made more sense (and a lot more performant) to compile to it directly, and they've done a lot of really neat stuff to get good performance while still providing reasonable features (like interrupting execution). 
&gt; I read somewhere that kind of convinced me that comments in programming are needed in two cases : &gt; &gt; * describe or explain what a piece of code &gt; * avoid breaking changes that should not be done Could you explain what led you to this conclusion? Usually, my comments explain _why_ the code does what it does, not what it is that it does. "Avoid breaking changes that should not be done" seems even worse; for example our codebase has a comment which says "warning: do not change the order of these edit, doing so will result in weird behaviour", which is worse than useless: if you don't explain _why_ changing the order lead to a weird behaviour (and probably what the weird behaviour is), then we'll never dare to touch that piece of code, and we'll never have the opportunity to make that bit of code less brittle.
Fixed
[According to Richard](https://typesandkinds.wordpress.com/2016/07/24/dependent-types-in-haskell-progress-report/): &gt; The short answer: GHC 8.4 (2018) at the very earliest. More likely 8.6 or 8.8 (2019-20). We could be looking at three years.
[removed]
With just a tiny bit of setup, you can make a function that turns a lens into a checkbox in Gloss. Text areas though, are more complex functionally, and would definitely be a good case not to use Gloss.
Looks like the usual "not a practical language because" thread.
Thank you for your answer. &gt; my comments explain why the code does what it does, not what it is that it does. let say I have big function somehow and to be understood the reader will read it carefully to figure out what is going on, wouldn't it be better if there is a comment that describe in nutshell the behavior of the function is doing, could you explain why you write the why? am open to new thought. &gt; But if you don't explain why changing the order lead to a weird behaviour I completely agree with you with the why part in this point. 
The point is that they chose to write their user guides in reStructuredText rather than Haddock. Haddock is a garbage format that I hate writing in. You could point to my API documentation as an example of Haddock in the wild, but I only use it out of necessity. 
Basically: 1. It teaches programming as a puzzle-solving game, which is the essential thing that makes it attractive to newcomers; 2. It teaches you to really *think* about the code you're writing, and in particular its invariants; 3. It teaches you that compositionality is awesome, which is less obvious in dynamic languages where writing non-composable code may be easier or more natural. People who learn coding via JavaScript may never come to really appreciate how fun and productive it is to "build on the shoulders of giants". *Software Foundations* is essentially an esoteric video game that teaches you programming as a side-effect.
I agree with most of what @b00Take home tests are good, you are inviting the candidate to truly explore a problem within a reasonably large time window without significant pressure. Live coding tests, on the other hand, inherently push the candidate towards playing it fast and loose due to the short time window and the stress due to the interview process. The candidate, if hired, is more likely to have to work on “take home” assignments, not on “live coding”, so why pay so much attention to the latter? 
ghc version ``` $ stack ghc -- --version The Glorious Glasgow Haskell Compilation System, version 8.0.2 ``` It is a C wrapper for C++, not a system library. DLL wasn't compiled by me. My coworker says he can use it in C project. Maybe the problem is in implicit dll loading. I work mostly on linux, I'm not quite proficient in windows to determine the error. I wanted to ask question here to get directions to where to look for :) I putted absolute path for C library build folder in `--extra-lib-dirs`, and absolute path for C library source folder in `--extra-include-dirs`. I cannot provide `ghc -v3`, I use cabal file. I use `ccall`. I tried to use `stdcall` instead, but, still, I got the same error. Also, I use `FunPtr` to set callbacks in C. I'm not sure I can do it using `capi`.
I wish I could remeber why I decided to use `ccall`. I didn't make any notes :(
I agree with most of what /u/b00thead says here. Some things to add: I think take home tests are good because you are inviting the candidate to truly explore a problem within a reasonably large time window without significant pressure. I like to see whether the candidate managed to truly understand the problem and write a nice solution for it, which is what I expect the candidate to do on their day to day job. The “alternative” live coding tests, on the other hand, inherently push the candidate towards playing it fast and loose due to the short time window and the stress due to the interview process. The candidate, if hired, is more likely to have to work on take home assignments, not on live coding, so why pay so much attention to the latter? I don't really care how well the candidate performs on a live coding exercise. Having said that, if the candidate has published a good amount of work that you can see for yourself, then a take home test would be redundant, as you could just take a look at their published work instead. I definitely agree with the attitude part. An overly negative person is likely to deter you from wanting to work together with them, hindering commitment and collaboration in your team. Also, an overly positive attitude often means the person is unlikely to question decisions and complain even about bad things, which will can quickly send your project down the wrong path. I like working with smart and respectful people who commit and know how and when to complain, that's what I look for when interviewing.
&gt; let say I have big function somehow and to be understood the reader will read it carefully to figure out what is going on, wouldn't it be better if there is a comment that describe in nutshell the behavior of the function is doing A comment would be one way to make that function easier to understand, but refactoring the code so that it is itself easier to understand would be a bigger win, because it will then also be easier to modify. &gt; could you explain why you write the why? I think [well-written code](https://youtu.be/85NwzB156Rg?t=17m44s) can be self-explanatory. By reading well-written code, it should be quite clear what it does, but knowing that is not sufficient! If it's not clear _why_ the code does what it does, then when the circumstances change, we won't know whether we still want the code to do that or not. Another example from our codebase: we have a migration system which stores the number of rows modified by each migration step. I recently discovered that we're storing the wrong number. Obtaining the correct number is difficult, but possible. Is it worth the effort? No idea, because I don't know what that number is stored! It's not used by any other code, or at least I couldn't find any uses. Maybe it was stored because the now-known-to-be-incorrect number was easy to obtain, and so we decided to store it along with some other metadata in case it ends up being useful for debugging? Maybe we have a checksum of known-good modified row count somewhere for a known db state?
But what do you put in extra libraries vs hope the library is called? It's the important but of information ☺️ I assume you've put the name of the import library and not the dll there? 
What businesses? Take home tests might be acceptable if the company pays the premium hourly rate, regardless of outcome of course. I instantly reject those companies who reply with hackerrank or similar bullshit site links.
wxHaskell is native as well.
I tried this `--extra-lib-dirs=/path/to/build/folder`. DLL is in this folder. Do you mean there is a flag in `stack` like `-l&lt;lib-name-here&gt;` in `gcc`? I have a line in cabal file: `extra-libraries: my-lib-name`. Is it not enough?
If you define `fmap = liftM`, you might also want `x &lt;$ t = t &gt;&gt; return x`. If you define `fmap = liftA`, you may also want `x &lt;$ t = t *&gt; pure x` or `x &lt;$ t = pure x &lt;* t`. But only if there's a custom optimized `&gt;&gt;`, `*&gt;`, or `&lt;*`.
To follow up on this: Things change pretty fast in startup life so we can't commit to a summer internship position(s) now, but it is something we would like to do. So the answer is "Probably" 
The Wizard Book is fine for high school students, and it can be approached with basically any version of Scheme (including Racket).
&gt; everything is a function Um, [no](http://conal.net/blog/posts/everything-is-a-function-in-haskell).
If the function feels "concrete" or "domain-specific", I'll pack up the arguments to a function into a record when they're more than one or two. (i.e. it gets "uncurried" into a record, over a tuple). Otherwise, I keep them curried, obviously for partial application. 
Speaking of Advent, is anyone else doing AventOfCode this year?
lens-tutorial shows that Gabriel Gonzalez is good at and cares about documentation, not that haddock is a format that's good for documentation. I write Haddocks heavily because it's necessary, not because it's convenient. 
Repo here: https://github.com/matthewleon/advent-2017 A warning, though: If you check the subreddit for AOC, some of the solutions on there are more clever/elegant/performant than mine :) https://www.reddit.com/r/adventofcode/
Are you sure it wasn't some initial indexing? If you have the time and patience, I'm sure the author of HfM would like to help you resolve it. I had a problem with it once and he resolved it really quick. Seems like a nice fellow.
Don’t worry, my Day 3 code was pretty rough :)
Can confirm, mine too. The 4th day was 3 lines, though.
What are Haddock’s failings? What is better and how?
Couldn't stop chuckling that fizzbuzz showed up here too. Ofc, it's way cooler when you point out that that instance Monoid b =&gt; Monoid (a -&gt; b) exists. I was just starting to edit an article talking about how it's "old fashioned" to use comprehensions in this way. 
&gt; If anything, the fact that people (ab)use Haddock to write packages that are nothing but documentation shows that Haddock works quite well. People just want it on Hackage I think. &gt;Haddock is creaking at the seams. I disagree that it's unsuitable for most projects (it makes documenting libraries much easier), but at the same time I wish it was faster. Generating Haddocks for a project often takes longer than compilation. 
&gt; I want to see the list of applications written in haskell that are useful and not used for programming a computer. Looks like HN is the same as ever.
I am new to this nix builds, but it appears `try-reflex` sets up an environment with ~15gb disk space. I am not sure if it is necessary. It seems it has lots of irrelevant things like wayland, jdk and other stuff. Can i use reflex with webkit2gtk using stack? I am interested in native guis only. Thanks.
I think this is due to a bug in `try-reflex`. I'm pretty sure it tries to pull in the entire Android SDK as a dependency, even when you're not building the Android version of your app. If we fix that, it should use less disk space. It's still going to be a lot; at least the size of coreutils + gcc + GHC + your Haskell dependencies, as it needs to pin all of these to make builds truly reproducible. But it shouldn't be what it is right now. You can use Reflex with Stack, but it seems like more trouble than its worth. You're going to have to pin a lot of packages to the right versions and somehow ensure the right webkit lib is on your path. I recently learned the webkit library used is different on MacOS than it is on Linux (we use `jsaddle-wkwebview` for MacOS), which will make it painful to manage being able to build it on MacOS and Linux. All in all, I'd say a little bit of disk space is a small price to pay to solve all of these issues for free.
You might need to call LoadLibrary if he provided you with a dll rather than a static object file. It all works completely different.
Calling conventions are not your problem, the test that is failing in cabal is essentially doing a giant file exist check by calling out to ld to link a dummy program. Unfortunately cabal swallows all feedback given by the linker and doesn't provide any output on what test it tried to run, so it's virtually impossible to tell what may have gone wrong without the full link recipe which looks like you're unable to provide since it seems to be some proprietary software. So here's how ld resolves libraries on Windows https://sourceware.org/binutils/docs/ld/WIN32.html#WIN32, look at the section below `For instance, when ld is called with the argument ‘-lxxx’ it will attempt to find, in the first directory of its search path,`
Oops, replied to the wrong thing, see my response above.
There's no reason to use `stdcall` in your own programs. `stdcall` in the Windows ABI for x86 is for historical reasons and a slight code size one. OS/2 used the Pascal calling convention and Windows 3.1 was designed to be an OS/2 clone (much of the weirdness in Windows comes from this compatibility with OS/2 btw.). When the Windows APIs where being designed they used a calling convention based on the Pascal one, which ended up being `stdcall`. Because disk space was an issue back then using this convention had one other advantage: each function call was 1 instruction shorter, because the callee cleans up the stack, the cleanup stack is only in one place instead of at every call site. (this setup has disadvantages too, you can't do any functions with varags for instance.). This was all cleaned up with x86_64. The ABI there has but one calling convention. And it's neither ccall (cdecl) nor stdcall. It doesn't really have a name, but most compilers will accept `cdecl` but emit warnings/errors for `stdcall`. Anyway, the point I'm trying to make here is that unless you're calling Win32 APIs on 32 bit Windows, there is absolutely no reason to use `stdcall` on any of your own calls.
Thanks for your detailed reply. The problem with disk space for me was purely due to having a small filesystem mounted on /. I am planning to use overlayfs to amend it. I will stick to nix for now.
Yes, it's proprietarity software, I'm not sure what I can provide) Could it be the reason that library is built using Visual Studio? So the names are mangled, and mingw's ld doesn't accept it?
Unless your making Windows API calls, the choice of `ccall` vs `stdcall` is a moot one. I haven't actually seen many end user libraries that use `stdcall`. Besides, calling conventions aren't that hard... And `capi` has it's draw backs as well, you pay for it by at the very least doubling your stack space for each call for instance.
Thanks! It is not directly related to haskell, but it would be nice to have it on haskell wiki FFI page. All it has about `stdcall` is &gt; Other available conventions supported by GHC include "stdcall" (i.e. Pascal convention).
Maybe, but unlikely, `ld` does accept import libraries from msvc. that's the `xxx.lib` alternative in the link I provided above. if you do `-lxxx` it expects a file named `xxx.lib` which is the name of the import library for the dll, the name of the dll itself is irrelevant. (though if the dll is named xxx.dll or libxxx.dll, ld will try linking to it directly at some point). You should be able to recreate the test cabal does manually: main.c: ``` int main () { return 0; } ``` `gcc main.c -L... -lxxx` and see what comes out.
If you have a dynamic library and no import library, the easiest thing to do is just create one. `LoadLibrary` is much more work. All you need is to know which function you need and make a def file https://msdn.microsoft.com/en-us/library/28d6s79h.aspx and use `dlltool` or `lib.exe` to create the import library. then you can link against it as normal. `ld` and `ghci` also allow directly linking to a dll file.
That's nice; but I've got https://github.com/ChrisPenner/Firefly for simple webservers; what I wanted was something that was easily usable by even people who've never even heard of Haskell ;)
Correct! I've updated the post and mentioned the influence explicitly. Thanks to your original post I got into Haskell some time ago and I'm halfway through http://haskellbook.com 
&gt; stack oh btw, if you're using `stack` you should keep your paths in mixed case mode, e.g. use `/` instead of `\`. so `E:/foo/bar` instead of `E:\foo\bar`. this is because of escaping. By the time it gets to `ld` it may not be valid. also you probably just meant `/path/..` as an example, but avoid doing this. `/foo` has different meaning inside msys and Windows APIs!. It may be the test is failing because the paths are wrong. You said you used absolute paths :).
I do too. I wonder if some Haskellers could get on the global leaderboard. :)
Write a function as such data Command = Quit | Help | Store | Set String Float | Unset String data EvalStmt = (...) data Input = Command Command | Eval EvalStmt | Failure String parseInput :: String -&gt; Input Then use pattern matching to construct the `eval :: Input -&gt; IO ()` program for the EP in REPL
Stack is an abstraction for cabal. Its best to use both with your main interaction done through stack.
Generally, modulo name collision, putting bindings in where clauses should have no semantics difference on your program. Someone correct me if I'm off here. 
Also known as: - Golden master testing - Approval testing - Snapshot testing - Expect testing Seems a lot of people independently keep coming up with this idea! One of the best implementations I've seen, by the way, is Facebook's Jest: https://facebook.github.io/jest/docs/en/snapshot-testing.html
 type FatStack m r = (MonadError ErrorType m, MonadIO m, MonadState StateType m) =&gt; m r foo :: FatStack m () foo = ... Would be polymorphic in return as I understand /u/joehillen
&gt; type FatStacks m = (MonadError ErrorType m, MonadIO m, MonadState StateType m) I wonder. Do you think I could define such a stack, maybe with even more constraints, use it in many places, and at a few places be able to specify: "FatStack m, Except for constraint X"? 
I use comments for functions to express 1. what is not immediately clear from the function name and type, 2. how the function interacts with other functions / what relevant laws hold for the function, 3. code examples (but them being comments is rather a haddock detail). In my experience, giving good names to types and values can reduce the need for comments, but does not always eliminate it.
Oh hey, my project at Uber got a mention! Still need to get that tidied and up on hackage...
&gt;From a technical documentation point of view, single sourcing with semantic context is critical. As any professional in the field will tell you, it's really the only hope to maintain accurate, complete, usable technical documentation over time. That's certainly not true. Lots of good reference manuals exist for all sorts of software that isn't inline in the code. Putting documentation directly in the code is horrible.
I've been doing something like this for aeson with this package. It's not well documented. If anyone is interested in using it, I'll add more to the readme. https://github.com/plow-technologies/hspec-golden-aeson
Ha, the fizzbuzz example is of course contrived (I came up with it while looking for simple yet impressive example). I think it demonstrates the point well and cute enough compared to other ways, but yeah there are better (or just clever) ways to do fizzbuzz, I actually might try to use it for a couple more contrived examples, like [`flap`](https://pursuit.purescript.org/packages/purescript-prelude/3.1.0/docs/Data.Functor#v:flap) (aka `&lt;%&gt;`). I like Monoidal fizzbuzz too, and [that article](http://www.parsonsmatt.org/2016/02/27/an_elegant_fizzbuzz.html), it goes deep in it. If you wish to write it, we can add a note there, perhaps in a separate file with a link to it after a fizzbuzz sniplet.
&gt; This isn’t perfect since each cons call is a O(n) operation meaning the whole thing is O(n²) Can you explain a bit about why V.cons is O(n). Are these vectors unable to overlap in memory and so save making a full copy just to front append? We're never going to modify the vector (only create modified copies) so what limits us from doing this?
I think `proc-do` definitely needs an overhaul like the `ApplicativeDo` extension. Of course we should first start by reconstructing the `Arrow` hierarchy so that `Profunctor` and `Strong` are superclasses, and the `proc-do` desugaring doesn't require `Arrow` if its bases suffice (just like `ApplicativeDo`). Then I think `Arrow`s would be as big as `Monad`s.
I'm really passionate about functional programming and more specifically dependent types and verified software. I am working through Conor McBride's course on agda from YouTube. I've been studying idris for about a year now and I'm slowly progressing through a proof of concept for a verified large and effectful program in idris. To that end I've been studying papers like "kleisli arrows of outrageous fortune"(C. McBride), "state machines all the way down" (E. Brady) and "parametrized notions of computation" (R. Atkey). I would love to do more as a PhD student but I'm self taught and have no degree. I work a full time job in order to pay the bills but that slows down my studies considerably. What are my options?
I’m not sure how that’s comparable? SimpleServer is a binary which can be run from a directory, while firefly is yet another web framework? I agree about yaml config being easier for non haskellers, than a config file being written in Haskell. 
I don't have a screed locked and loaded, but Haddock has plenty of failings. These are the first few things I came up with scrolling through the documentation: - It's specific to Haskell. Nothing else uses it. - It uses common symbols, like `'` and `"`, as part of its syntax. And escaping is annoying. - The first character in a comment is sometimes important. For example, a comment like `-- *NOTE*: ...` is a syntax error. - Documentation for module re-exports is hilariously bad. (You can also lie about which modules you export: https://twitter.com/taylorfausak/status/816398031511842816) I could keep going, but I've got other stuff to do. I would prefer any one of Markdown, reStructuredText, or AsciiDoc. 
Agreed with everything /u/taylorfausak mentions. I imagine there are haddock issues for some of these things: * As reported [here](https://github.com/feuerbach/tasty/issues/59), code like [this](https://github.com/feuerbach/tasty/blob/hunit-0.8/hunit/Test/Tasty/HUnit.hs#L48), which uses an asterisk in the middle of a comment in the middle of a function will cause haddock build to fail. I'm still baffled by this. I understand that `-- *` is special, but even in the middle of consecutive comments, in the middle of a function? * AFAIK if a value name is ambiguous with a type name, there's no good way to prefer one or the other when linking * This might have been fixed, but for higher kinded types, the kinds were appearing as arguments in the haddocks. Very confusing * There's no display of orphan instances. I think they should be listed at the end of the module. I'd also like to see orphans listed directly with a datatype / typeclass if they are declared in the same package. * Gonna reiterate this one, haddock is an atypical markup. It takes a while to get familiar with it. I still don't know most of it. In my head, I only really know how to do code blocks, inline code, module references, and identifier references, and I've been writing haskell for 10 years. I don't know how to do any of the formatting stuff. I think I know how to do italics, just because I've seen it break the display of urls (use `/`). I don't fault Simon Marlow at all here, I think at the time it was designed there weren't any decent + common plaintext markup systems (e.g. markdown, reStructuredText). * It is intertwined with the compiler and requires recompilation. I discussed this a bit with rust folks here, who have a similar circumstance and are seeking to decouple it - https://github.com/steveklabnik/rustdoc/issues/176#issuecomment-332059363 There is nothing better for Haskell. Unfortunately, plans to use markdown as a new syntax was scrapped, for confusing reasons. IIRC, John MacFarlane, author of pandoc, had a very short patch that demonstrated rudimentary support, but nothing came of it.
Since it's related, I'll just put this here. https://github.com/TaktInc/armor I've been meaning to blog about it, but haven't found the time. TL;DR Golden testing to guarantee serialization backwards compatibility.
Defining a monoidal functor with `merge` actually works quite well for more than just `Functor`s: class Monoidal f where merge :: f a -&gt; f b -&gt; f (a, b) unit :: f () A `Monoidal` `Functor` is equivalent to an `Applicative` (with `pure a = a &lt;$ unit`), but it also works for contravariant functors! newtype Op r a = Op { getOp :: a -&gt; r } instance Monoid r =&gt; Monoidal (Op r) where merge (Op fa) (Op fb) = Op $ \(a, b) -&gt; mappend (fa a) (fb b) unit = Op $ const mempty A similar sort of monoidal functor can be made with coproducts: class Comonoidal f where comerge :: f a -&gt; f b -&gt; f (Either a b) counit :: f Void You can define them for things which are `Alternative`s: instance Comonoidal [] where comerge fa fb = fmap Left fa ++ fmap Right fb counit = [] But you can also define them for contravariants: instance Comonoidal (Op r) where comerge (Op fa) (Op fb) = Op $ either fa fb counit = Op absurd There's no contravariant equivalent of `join`, though, because Op r (Op r a) is covariant in `a`, and is equivalent to the continuation monad.
Getting a 404 on that link
Oops, try now.
Apparently that works, but you need `RankNTypes`. You'll still get unhelpful error messages, which are why you should prefer to use `ConstraintKinds`.
This is specified in the vector documentation. They are unable to share memory because they're not like lists, if you want to increase the size of a vector you have to allocate a new contiguous amount of memory which can fit all the elements. You can't just allocate memory for the new element and make it point to the rest of the vector thereby sharing the memory (this is exactly how the singly linked list works).
A ton of GHC's testsuite also uses golden tests. In fact, I think it's one of the main ways tests tend to be built as it's so incredibly flexible.
Same for Agda.
How would the following be represented in memory without any copying: a = V.fromList [3, 2, 1] b = V.cons 4 a c = V.cons 5 a I feel like this will answer your question pretty quickly.
[removed]
The BBC also did this with Wraith: https://github.com/BBC-News/wraith
&gt; And `capi` has it's draw backs as well, you pay for it by at the very least doubling your stack space for each call for instance. But only when `capi` bridges the `stdcall` impedance mismatch, doesn't it? Otherwise I'd expect the c compiler's TCO to kick in and reuse the callers stack frame for the `capi`-wrapper.
I would have thought that any vector operation that was just adding / removing items from the vector could be done once without having to make a new vector. Obviously if you add or remove different items to make new vectors (or if you add or remove from anywhere other than the front / back) you have to make a copy. After thinking about it a bit, the code for vector cons should be O(n), but the task of constructing a whole vector should be able to be optimised to O(n), not O(n^2)
Your bottom paragraph is exactly what happens for most vector implementations. (And sometimes cons becomes O(1) through optimizations). So in other words I agree with that assessment. 
&gt; It's specific to Haskell. Nothing else uses it. Yes, it's optimised to Haskell (which also happens to use a Syntax nobody else uses) -- same goes for `.cabal` vs. YAML, PVP vs SemVer --, and markup grammars are inevitably a tradeoff of stealing syntax and the need of escaping/markup verbosity. That being said, we're not deaf to the suggestions to add alternative markup support (see https://github.com/haskell/haddock/issues/570#issuecomment-310769037 for a recent discussion), but it does require careful design and consideration for something that's intended for long-term support.
&gt; The point is that they chose to write their user guides in reStructuredText Btw, Stack uses Markdown for its user guide, while *everyone else* mentioned uses reST... 
None of places I've worked at had home assignments during recruitment, but I probably just take shit jobs.
Sorry I don't understand what you mean by 'using both'. Could you please give me example of nix expression file and how the workflow would be like?
[removed]
This approach is very easy to go wrong, and you end up with a seemingly unrelated code change results in 30 cases each has page of diff and neither the test author nor the person who made the code change have no clue what does the diff mean. Then they have to come up with rules what to assert for anyway.
Oh neat. Thanks
Are you using Homebrew, Mac Ports or something like that? You've probably got a seperate haskell installation somewhere that's interfearing. You don't need any Haskell anything on your system before you start with Stack.
Could you show me an example of an unhelpful error message?
I'm pretty sure they send PMs to random people on the sub, too. I've been contacted by recruiters who I'm sure had zero knowledge of programming or Haskell.
It depends how you construct your lists but without a concrete example it's hard to say. In general if you construct your lists with any recursion then I wouldn't count on it optimising like you want. 
I've used this and it works well. The documentation was sufficient enough for me to figure out the correct usage without much effort.
Normally the hiring company pays the recruiter a percentage of the employee's starting salary but that's *on top* of the salary. It doesn't come out of the employee's pay! 
The ap operation that you described matches a graded applicaitve/monad. A popular implementation of graded monads (not applicatives) can be found here: http://hackage.haskell.org/package/effect-monad You could just implement you ap operation in terms of the monad. Another way to encode them in Haskell is through supermonads: http://hackage.haskell.org/package/supermonad
PS: I would be interested to here more information about your application. Is there a repository I can look at?
Of course it does, the employee's ability to negotiate a signing bonus is reduced by the recruiter's fee.
I would certainly love to live in Alaska, and I love Haskell aswell. Sadly I only grasp the surface of Haskell, I need to learn more
The point was that they didn't use Haddock. I mentioned Markdown (and AsciiDoc) in my other comment. 
fromList allows O(n) because it doesn't cons every element. The reason why I thought it was O(n^2) and not O(n) amortized was because I tried it since I wasn't sure, and according to my small benchmark the run time was increasing quadratically. 
I'm in a similar boat, and I know of one other person who is too. Would be curious to hear if there is a way to get into a PhD without having to do 3 years of undergrad. 
It's still very experimental and I'm exploring different possibilities. It's not yet ready, but I will remember to poke you if it ever ends up being presentable.
Shameless plug: That's why I created [`tree-diff`](https://hackage.haskell.org/package/tree-diff), to not only rely on text file diffing! To answer /u/max630 concern: `tree-diff` prevents formatting related issues in textual diffs, that's already a win. --- Also I have to mention, that none of QA methods is the silver bullet. You should pick what suits your thing the best, you may pick *many*: better types, (small)-unit tests (doctest!), golden tests, property-based tests, testing against reference implementation, `inspection-testing` / `ghc-proofs` etc. to cover a lot of issues, without introducing too much of the development drag (tests should help the development process by adding confidence, not slow it down).
Hello. Yes, perhaps we could use some prompt finalizers. But it is not very clear that we would reach a simpler solution both for GHC and inline-java.
I think in this case copying would happen. If it is O(n^2) then 2 new copies will be made
Does anyone know how one can distribute command line tools written in Haskell? My project is managed using Stack, and I am hoping to build `deb`, `rpm`, and OS X packages from my code base or provide something like Homebrew or Aptitude package scripts for easy consumption by the users.
I strongly suggest you split that up. It's not just the software that has a hard time dealing with files that large, you will too.
In EU, I see job offers for JS developers who are interested in F#/Scala/OCaml/Haskell/Erlang... "Functional programming interests" become synonym of "better" developer. Still think it funny to ask Haskell devs to come and work in Java shop :D
Unfortunately, an undergraduate degree is one of the prerequisites for a PhD position. It used to be the case that a first-class BSc degree was sufficient to gain entry to good programmes, but it has become more competitive in recent years, which effectively means that a first-class MSc is now a standard requirement. 
Thank you!
It's very unusual for someone to short-circuit the system that much - academia is fairly political, although compsci/math are better about that than most. You might be able to talk them into letting you do an accelerated program (combining undergrad/masters) or something, but unless you make some groundbreaking discovery, they're probably not going to just let you jump straight into a doctoral program from nothing. In any case, most research in this field is freely available, as are the tools you need to build stuff. It's not like medicine where the research is closed, experiments are regulated by a megabureaucracy, and the tools are locked away in expensive labs. A PhD program is great if the stars line up in your life so you can make it happen, but if not, it's definitely not the end of the world in this field.
&gt; That's certainly not true. I don't know why you say that, but I can tell you why I say that it certainly **is** true. For years, our Haskell-based company has been supplying technical documentation tools and technology to many of the worlds largest enterprise tech companies, as well as many medium-sized and small-sized companies. And we are no strangers to open-source projects as well. I promise you, if documentation is not single-sourced, it will quickly become inconsistent, inaccurate, and incomplete. &gt; Putting documentation directly in the code is horrible. Again - why would you say such a thing? There are many good reasons why this is the widely accepted approach. Not the least of which is that most people want code to be readable and understandable by humans. This is not to say that Haddock is the greatest, but it what's we have right now. I believe it can be built on and improved. But if someone comes up with a better and different single-source solution with semantic integration to the code, I'm all for it.
I think it’s very important to relate a snapshot with the test that produces it. In my experience the best way to do that is a naming convention: derive the snapshot file name from the test file name and the snapshot name (in the snapshot file) from the test name. Then when you get a failing test you can immediately trace the diff back to its test and work backwards from there.
haddock is a good format, not a perfect one. That's all I was saying. The existence of a few examples of good technical writing in some markup format won't prove or disprove much about that format. Something being possible it's different from something being convenient, or maintainable, etc. As someone who has written /u/Tekmo -style documentation, I'd like better syntax and more "primitives": * Slashes shouldn't need to be escaped. They're used more in prose then most other symbols like asterix, hence other markup languages not stealing it. Every time you see three words on hackage smushed together with one italicized, the author wasn't properly escaping them. * Relatedly, raw urls trigger that. * Directly inlining a definition. e.g. with the triple apostrophe being a hypothetical syntax: '''configureDefault''' becomes configureDefault = configureWith defaultConfig * Hyperlinking every symbol from from the current package in a code block. This also helps vertically aligning comments, and helps doctests with hyperlinked symbols. e.g. with the triple at symbol being the syntax: @@@ do -- configureDefault -- doSomewith withSomething -- @@@ becomes something like @ do -- 'configureDefault' -- 'doSomething' 'withSomething' - @ (but without breaking the vertical alignment, I'm on mobile, so don't know if I formatted correctly anyways, lol). * Exposing function argument names, and linking directly to them. Currently, you have to name them manually, which introduces inconsistency, and the `-- ^` style docs don't support longer explanations, because it's indented severely when rendered. * Linking directly to a source file, and to a location therein. For example, for linking into an example module, or even into test modules. when discussing internals, like some pragma or macro, highlighting the span. Most are less about convenience, and more about consistency. And consistency, consolidating your documentation into your source files and onto hackage, is the primary reason for haddocks itself, with haskell-specific features being secondary, imo. 
Note: The code is not 100% optimal. Some stuff could definitely be improved with better combinators.
&gt; plans to use markdown as a new syntax was scrapped, for confusing reasons The problem is that for decent API documentation, you need to support auto-linking of symbols and module names, and other kinds of semantic integration with the source code. Markdown is not well suited to that out of the box. It could be built, but it would be a lot of work, and no one has done that work yet. reST is designed for that sort of thing. It could be that would be much easier to integrate.
They *do* use Haddock. Click around the haddocks for stack, it's there. That's far from being the only documentation, of course. Stack is mostly used as stand-alone program. But Haddock API documentation is there, and extremely useful for in-the-trenches stack development or when using stack-as-API.
They *do* use Haddock. Click around the haddocks for stack, it's there. That's far from being the only documentation, of course. Stack is mostly used as stand-alone program. But Haddock API documentation is there, and extremely useful for in-the-trenches stack development or when using stack-as-API.
In light of the size of the change, 2018 is soon. 8.6 and 8.8 are not all that far off either. It would be encouraging to see some more recent progress reports, and if possible, some concrete code.
imo, the problem isn't syntax being stolen, it's that the wrong syntax is stolen. Apostrophes and slashes, instead of grave accents and asterix, for example. 
In any sufficiently rich ecosystem, parasites are a given. And parasites' net contribution to the system is negative. Whether you can measure that net negative or not doesn't make a difference.
They use Haskell?
&gt;I have to learn how to calculate Big O Notation for university but the meager resources I'm getting from the prof are extremely sparse, confusing and bad. Heh, welcome to German universities. I'm actually confused: are you trying to analyze the runtime of Haskell programs specifically? Or are you looking for resources that explain big-O using Haskell?
How about for cases where it is ambiguous, suffix with (type), (expr), (module), or (kind)? This would allow hyperlinking the identifiers full expressions and types! Even better than what we have now. In the event of this being unspecified it seems fine to me to have it try parsing as all 4 varieties. If multiple work, then It'd then default to one interpretation and warn about the ambiguity. Boom, problem solved. Something like reST is probably better, but markdown is so darn familiar to people. I think markdown would be a better choice, because i think it would be more pleasant / less error prone to write docs
&gt; Heh, welcome to German universities. Indeed! &gt;I'm actually confused: are you trying to analyze the runtime of Haskell programs specifically? Or are you looking for resources that explain big-O using Haskell? Both. Well, my first course at university is *Functional Programming*, which is taught in Haskell. And we're supposed to learn Big O Notation and calculate it on Haskell functions.
I would definitely separate learning big-O and calculating it for specific Haskell instances, i.e. first learn it without any Haskell-specific applications. The de facto reference for big-O is probably Cormen's Algorithms. It's in Chapter 3, you don't have to read any other chapter to understand it, and it's a relatively short chapter. I'd just read that. Here's a PDF: http://www.eecs.yorku.ca/~jeff/AIMS/introduction-to-algorithms-3rd-edition.pdf
Would it still be short-circuiting the system if you only have a Bachelor's? I'm in the U.S. so the politics might be different but most programs seem to prefer a master's degree first (especially if your B.S. had a low GPA). 
&gt; There's been a few job Haskell job posts recently without any actual details about the company or positions unless you contact some random person. &gt; Note that I am trying to find those of you that love the language and Alaska :D \&gt; Doesn't provide details about the company or position So... Alaska, you say?
I don't think anyone made a specific decision to abandon markdown. It just hasn't been done. If you want to pick up the mantle - great!
Haskell packages use Haddock for API documentation because they must. My point is that when given the choice, nobody chooses Haddock. Haddock *itself* uses both Markdown and reStructuredText instead of Haddock: https://github.com/haskell/haddock/tree/e9e2fd3/doc
Thanks a ton, that's super useful! &gt;You will see big-O throughout your CS studies, so it's worth it to properly learn it. That's what I figured, that's why I want to do it *right*.
My experience with German education is just find a textbook that covers the topic (if such a textbook exists, becomes problematic in grad classes) and read it there. Then everything is simple. You can get any textbook you want for free here: http://gen.lib.rus.ec/
Both of the recruiters you're talking about are in London where there are several legit companies with Haskell positions open right now. A lot of dev jobs (in fact most) in London go through recruiters. /u/DisregardForAwkward and I seem to be fortunate that if we wanted to hire Haskellers we could reach out through our personal connections to the community. I am pretty sure that I wouldn't need to use the services of a recruiter. Many other tech leaders are not so lucky, so in IMHO we should all be very glad that there are recruiters that see enough of a market in Haskell that they deem it worth making a specialization out of. Taylor from Oliver Bernard actually contacted me on linkedin about one of the jobs he posted here and I suggested to post to /r/haskell. This is one of the hubs of the Haskell community after all. I've met lots of recruiters from different companies in London over the years - I can count on one hand those that bother to learn about and understand the eco-system they operate in and actually add some value. For my money Taylor is on that hand and so are functional works, who have also posted job here (and also contribute to the community by hosting one of the largest FP meetups in the London). I also want to take issue with this statement: &gt; we have little to gain right now by working with them Wrong. If /r/haskell starts to be a place that's hostile to recruiters, and labels them parasites what do you think is going to happen when someone comes to them on the fence about the tech to use? Say there's a guy in a company talking up Haskell and saying they want to use it and the tech leadership goes and talks to a couple of recreuiters to assess the market. Do you want the response to be: 1. There aren't that many Haskellers around, and those who are around seem to not want to be contacted about jobs. Try scala instead. or 2. Haskell is a small community, but Haskell jobs are a rarity so I'm pretty sure I could help you source a team if you go down that route. TL;DR Connecting candidates to vacancie is recruiters main job - we should be glad Haskell's profile is such that they are starting to even take notice
Not outside that project and one other (a linter for Thrift specs).
A few years ago it was possible to be admitted to good PhD programmes with a BSc, but these days an MSc is more-or-less a requirement.
Thanks a ton, that's an amazing resource! :)
It's common to dismiss middlemen in all industries as economic parasites, but in general that's not accurate. Middlemen often perform useful services, either by aggregating the products and services of others, or by aggregating information about such things. I'm alright with recruiters here so long as they don't disrupt conversation and become (effectively) spam. Though I'd prefer it if they were recruiting for actual FP jobs; I wouldn't mind having one of those.
Do you have any advice on how to navigate a master's degree if a PhD program is the end goal? I ask in particular because programs might not translate terribly well across borders (the U.S. in this case).
Oh, and sometimes the library genesis links change/die. The wikipedia page always has up-to-date links: https://en.wikipedia.org/wiki/Library_Genesis
**Library Genesis** Library Genesis or LibGen is a search engine for articles and books on various topics, which allows free access to content that is otherwise paywalled or not digitized elsewhere. Among others it carries PDFs of content from Elsevier's ScienceDirect web-portal. In 2015, the website became involved in a legal case when Elsevier accused it of providing pirate access to articles and books. LibGen is reported to be registered in both Russia and Amsterdam, making it unclear which legislation applies, and whether defendants will show up in a United States court hearing. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/haskell/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
This is supported using danger for example. Also gitlab and circleci provides this out of the box. It's also a requirement for any CD setup. Apps should be pushed to the app store and Google play to get the extra checks they provide. 
In that case, I think the word "imminent" probably conjures up fairly different images in our minds :)
These don't paint a rosy picture about getting a different markup format into Haddock: - http://fuuzetsu.co.uk/blog/posts/2013-08-30-why-Markdown-in-Haddock-can't-happen.html - https://github.com/haskell/haddock/issues/570#issuecomment-310769037
How do you express that User cannot be changed because it changes the database schema which breaks the php front-end. How do you express forward and backwards compatibility requirements on external interfaces as a type?
A lot of places are willing to help you along on that journey, this is from OP's post for a position a few months back: &gt;[Always happy to take in enthusiastic developers with experience in other technology, knowing Haskell is by no means a requirement. Hard to be too picky and choosey due to the small population size of the state.](https://www.reddit.com/r/haskell/comments/6mzezk/software_engineer_1_position_at_alasconnect/dk6wm2q/) Not sure if it still applies, but never hurts to try :)
It's actually not too bad as the entire file is purely a parser for attoparsec. Couple hundred lines of data declarations that map 1:1 to the specification it is parsing, TH makelenses for them, and then the rest of the file is parsing functions ultimately all rolling up into a single function that I pass to attoparsec. The length is a side effect of the awful specification I am parsing. That said, thinking about it a bit, it would probably be best to move the data declarations/lenses to their own file so I can explicitly only export the single function, instead of the current situation where everything is exported because it would be too much hassle to list all of the lenses/data types explicitly.
They do. I was on it all of these days.
Then I shall wonder if one of the haskellers could snatch the first place. ;)
Similar packages are [`varying`](https://hackage.haskell.org/package/varying) and [`dunai`](https://hackage.haskell.org/package/dunai).
Thanks! 
This is like saying nobody uses a dump truck to go drag racing, or nobody uses a screwdriver to hammer nails. Haddock is a tool to document Haskell source code. It’s not intended to write user guides.
Well said!
I haven't done so for a while, but * [cabal-debian](https://hackage.haskell.org/package/cabal-debian) for creating debs. * [bamse](https://hackage.haskell.org/package/bamse) while now old, was at the time entirely reasonable for creating a windows installer. * Fedora has [a wiki page](https://fedoraproject.org/wiki/Packaging:Haskell#Haskell_Packaging_Guidelines) dedicated to packaging Haskell. * Debian also has [a page](https://wiki.debian.org/Haskell) which is pointed at by Ubuntu, so I'd guess they consider this process acceptable.
Looks nice! I showed it to a co-worker who is highly skeptical of Haskell to see what he thought. He liked it a lot and thought it was cool; the only thing that bugged him was the invalid json in the example, no live reloading on changing the yaml file, and the terribly ugly error messages. I found it hilarious that just pasting raw html into the yaml document (inlined css and all) actually worked :) Gonna see if I can use this for some mocking around at work; it's dead simple, which is just the way I like it.
Near the bottom of github issue in your second link, I outlined a way to decouple GHC's side of the processing from the documentation processor. Using this approach, I believe you could use any format you want to replace Haddock - your favorite markdown flavor, reST, your IDE's preferred format, or whatever else. There are two parts to this process: 1. Implement this more general and flexible protocol in GHC. 2. Implement a wrapper around your favorite API documentation processor that implements the protocol facing GHC, and marshals between GHC and your documentation processor. Your wrapper is called twice, in two different modes. The first time, you get a file containing a bunch of raw documentation source snippets. Your wrapper responds with a file containing a bunch of symbols that it wants GHC to provide links for. The second time, you get the same source snippets, plus the links you asked for. Now you render the actual API documentation. There are a lot of design details to fill in, and it would take some work to implement. But I think it's doable.
Everything is relative. For a task of this size and of this importance, it's imminent. You would expect that in addition to all the type wizardry that Richard is doing, there will be tons of other integration work needed. I'm a bit surprised that Richard hasn't appealed to the community to recruit armies of volunteers to help with all that. Or perhaps he has, but only among the GHC HQ regulars, and I just didn't hear about it.
I think the reason is that `mtl`-like type classes have laws associated with them. It's not clear for me, why laws are not written down explicitly in documentation. In case of `MonadError` I can think of the following laws: 1. throwError e &gt;&gt;= f ≡ throwError e 2. throwError e `catchError` f ≡ f e Maybe my laws are not correct. But I think there just won't be much sense in laws if you don't require your type be `Monad`.
You can improve the readability of the interpreter by using arrow notation: https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#arrow-notation
&gt; but markdown is so darn familiar to people Yes, I'd also like to be able to write haddocks in markdown.
I see, good point thanks 
Well in the `Validation` example, it deliberately does something different than law 1, that law forces short-circuit errors. It is possible to view that law in for example an `Applicative` setting. Something like: `f &lt;$&gt; throwError e &lt;*&gt; ... ≡ throwError e`. Also, those laws for `MonadError` are not on the page I linked [here](https://hackage.haskell.org/package/mtl-2.2.1/docs/Control-Monad-Except.html). Are they mentioned somewhere else?
I try to avoid using the arrow notation as it isn't supported in languages like Frege which I also try to target with other projects. About the Arrow type: I could have done that, yes, but I wanted an arrow that is similar to what Control.Arrow.Transformer.State (https://hackage.haskell.org/package/arrows-0.4.4.1/docs/Control-Arrow-Transformer-State.html) does.
Also: With the use of StateT, using Kleisli for that would be quite unnecessary. Besides that I noticed some parts in the interprete function that were quite suboptimal. These can definitely be improved with better Arrow combinators.
I opened an issue on github where I explained my suggestions.
Seems like the ordering of composite effects would start to get really hard to predict/control for without `&gt;&gt;=`
I'm happy to [give you](https://www.reddit.com/r/haskell/comments/6mzezk/software_engineer_1_position_at_alasconnect/) [some](https://twitter.com/mojobojo/status/937821244245794817) [information](https://news.ycombinator.com/item?id=15828277) and then contact you for an interview. There's a difference between that and sending you unsolicited information after our initial contact.
If Taylor had simply left it at sending me the first email about [this completely ambiguous post I inquired about](https://www.reddit.com/r/haskell/comments/7glmkx/remote_haskell_developers/), which I highly appreciated getting emailed about, I would have left it well alone. However, I received yet another email about another unrelated position. I did not sign up for recruitment spam, and do not condone it.
We're still looking, thanks!
If the other position was also Haskell that's as good as it gets from recruiters.... I don't start calling things spam until it's a PHP job in Scunthorpe paying £15k :-) I guess I'm pretty much hardened to approaches from recruiters and have learned to tune it out, as I said in my original comment, the vast majority of recruiters are a lost cause. That makes me value the ones that have a slight clue quite highly :-)
Signing bonus? 
I was mainly just pointing out something I found ironic :P Personally, I think Haskell is great, and far better than what most companies use, but for me to leave my current job that I'm quite happy with to go to Alaska, the job would probably have to be primarily Rust programming.
CodeWars. Different from CodeWorld. 
&gt;Middlemen often perform useful services, either by aggregating the products and services of others, or by aggregating information about such things Does that necessarily suffice to show non-parasitism? I think even plantation slavers could legitimately claim to "perform useful services," yet they still strike me as parasistic on the slaves.
Thank you for the follow up! Surprisingly, few people post follow ups. As a GUI and Haskell noob myself, I was following your original post and this is helpful.
The `MonadError` laws are just the `Monad` laws with `throwError` and `catchError` taking the place of `return` and `(&gt;&gt;=)`. left identity: throwError e `catchError` f ≡ f e right identity: m `catchError` throwError ≡ m associativity: (m `catchError` f) `catchError` g ≡ m `catchError` (\e -&gt; f e `catchError` g) 
This is, unfortunately, a bug introduced thanks to `integer-gmp` using a new syntactic feature of Cabal 2. You'll have to use a less-current build than `nightly-2017-12-05`; the latest LTS releases should work. You are not the only one being affected by this bug; it appears to be tracked in [this](https://github.com/commercialhaskell/stack/issues/3624) GitHub issues ticket.
See: https://github.com/commercialhaskell/stack/issues/3624 Quoting from there: "The problem is that integer-gmp is included with GHC itself. This has a long history, quick summary: Stack through version 1.5.1 was too eager to parse Cabal files The work for extensible snapshots accidentally fixed this, and then we added a test case in #3396 to ensure it stayed that way With GHC-8.2.1, the only problem was ghc.cabal, so we made a patch release Stack 1.5.1 to work around that limitation with PR #3304 In other words, this will be fixed permanently with the upcoming release." It seems like you can work around this by using nightlies prior to 8.2.1.
I read this article with some interest because later this week I am giving a similar presentation to some coworkers — an intro to `Applicative` error handling in Swift (we’re Swift developers, and Swift luckily has pretty good support for functional programming). I found it interesting that this article waited so long and played it so “low key” about introducing `Applicative` and the related operators — that was by far the hardest thing for me to understand when I learned about this stuff. Curious if anyone has any opinions about this. I am planning on introducing `Applicative` and the “`Applicative` style” as soon as possible — just as soon as everyone in the room is comfortable with `Either` (which is close to elementary for Swift developers, in case you are unfamiliar with the language). I feel like once one “sees” how `&lt;*&gt;` works to chain values together, it’s a quick jump to swapping out the `Applicative` in question from `Either` to `Validation`. And (this is really where I would like the input of more experienced Haskellers) even though — to my understanding — the `Applicative` instance of `Either` is not “necessary” (as in, it duplicates the functionality you get via `Monad`) it still strikes me as convenient and something I would use if I wrote Haskell more often. Does that seem reasonable, or would anyone discourage the use of `Either` in an “`Applicative` style” for some reason I’m not seeing?
I've been using Validation in my project and I found the best way to use it is to exclusively use `&lt;*`. Your function will end up looking like: buildDataStructure field1 field2 field3 = pure $ Data field1 field2 field3 &lt;* arbitraryTest1 field1 field3 &lt;* arbitraryTest2 field2 In this way, your tests can return any value you want on success because it is thrown away, but if any of the tests fail, it will stop the data structure from being built and return the errors. Letting successful tests return any value makes it much easier to nest them and otherwise combine them into a full coverage of the tests you want to perform. It also separates the concerns a little bit so that building and validating the structure are two separate things.
OK. I just upgraded my laptop to 8.2 from Debian experimental &amp; on my AdventOfCode code from today’s problem my Haskell is *faster* than the equivalent C++. What wizardry is this?
I tried, and get this: 2048Haskell: src/Main.hs:(47,17)-(53,63): Non-exhaustive patterns in case stack 1.1.2 ghci 8.0.1 
I see. It's quite unfortunate that QA didn't catch this. How long till the upcoming Stack release will be here? However, as I do need GHC 8.2 for my project can I somehow use Stackage nightlies prior to 8.2.1 with GHC 8.2.2 in the meantime? 
I don't mind to use nixos over Debian, recently I was watching a video of Richard Stallman and get to know the GNU, however, it seems that nixos is a GNU/Linux project and not only linux which kind draw my attention. for the practical standpoint, why should I use nixos, for example maybe deployment and generating static binary is easier, I have no idea am just assuming.
Since Vidme is [closing down](https://medium.com/vidme/goodbye-for-now-120b40becafa), I put it up on [YouTube](https://www.youtube.com/watch?v=j0XmixCsWjs).
Weirdly, while integer-gmp 1.0.1.0 was only released 12/4, it shows up in all the stackage nightlies going back through the 8.2.1 series. So I guess stackage will need to fix that issue :-/. On the plus side, that seems fixable prior to a new stack release (which, as I recall is already slated for next week anyway -- and until then you can use the release candidate: https://github.com/commercialhaskell/stack/releases)
I use Homebrew for OSX. I publish to Github releases then create a Homebrew recipe that points there
There is https://github.com/markhibberd/pirate if you want to write CLI parsers using Scalaz.
Thanks for your remarks! If this article is at all useful to you, I'd love to hear more about it. Funnily enough, I got into Haskell via Swift. I'm wondering how you would implement an applicative functor in Swift. I didn't think the language had higher kinded types? Or do you just specialize it at the outset? Regardless, I do think this is the best way to programmatically aggregate errors. My goal is to make this sort of pattern easier to pick up and adapt, so the low key approach you identify is no accident. You might think of applicatives as operating in an effectful world, that world being determined by the type of applicative in question. A Maybe does Maybe effects, an Either coproduct effects, and a Validation, well, validation effects. These effects are encoded into the type, and are collected by the semigroup or monoid instance contained within the applicative. Otherwise, the context notwithstanding, you're just performing function application, however that is defined for a given applicative. One advantage gained by using applicative is, heh, applicable to validation, and that's the fact that these are independent computations and can therefore be run in parallel. A monad gives you the ability to chain computations sequentially, such that the result of one could depend on the result of another. This is not possible with applicative. To answer your question, a typical Haskell programmer would probably use only what functionality is necessary. If applicative is enough, it should be preferred over monad. With the introduction of the ApplicativeDo language extension, of course, you can just use the same syntax for both and let the compiler sort it out.
Actually this is one of the things nix does well. You specify the c dependency and it gets built as well.
Well spotted. Taking any expression, a very general type will constraint the number of implementation possible, and their complexity. When we christen a new typeclass we likewise quantify over every possible implementation with this signature, so the same principle applies, only at static time. So it's best to keep those typeclasses as orthogonal and general as possible, which also insure they are focused on one sole bit of functionality
I'm hesitant to agree with such a suggestion, although I'm sure there are cases when it works well. if you don't change any of the types of the fields in the validation process then that basically guarantees that the compiler / type system won't help you at all with validation. Whereas if you have the following: newtype Username = Username String mkUsername :: String -&gt; Either Error Username mkUsername = ... hidden in a module with the constructor exposed, then you know that as long as `mkUsername` is correct (e.g doesn't allow symbols or overly many characters etc.) then you can't ever accidentally assign someone an invalid username. Even better than that is making the invalid states unrepresentable: data Color = Red | Blue | Green mkColor :: String -&gt; Either Error Color mkColor = ... I personally believe that you should get things as far into the type system as possible as early as possible. Either fully (bad states unrepresentable) or at least partially (bad states only possible using things that aren't exported). This leaves a lot less room for error and makes refactoring and reasoning about your code much easier.
Exactly, they are unable to overlap in memory. And the reason is because they are a contiguous piece of memory of a certain size. So you allocate an array in memory of size n*(size of element). The compact stream of bytes is what provides the benefits of vectors over lists. Anyways, you allocated these bytes in memory and now you want to add an element. Sadly the previous allocated space only fits exactly n elements, you now have to find a new location that fits (n+1) elements so now you allocate that much memory and you copy the previous elements and add the new one. In the end this is a limitation in the heap which doesn’t allow you to increase the size of previously allocated memory.
or read another way, some of the cabal team were so eager to introduce this new feature, that they made sure many core packages would get this new optional syntax ASAP without giving time for the alternative tools to catch up and thus render them broken. it's the new use cabal-2.0-or-die motto.
What? So cabal just can't add new features now? I *might* agree that core libraries should be compatible with one or two old cabal versions. But to claim it's a bad thing for cabal to add new syntax just because Stack has to catch up is ridiculous.
Sort of like the use-Stack-or-die motto a lot of people have adopted? It's the nightlies that are broken; I don't think anyone should be all that broken up over nightlies being unreliable. Stackage wouldn't have released an LTS with GHC 8.2 until Stack supported Cabal 2.0 either way, regardless of this issue.
I should make this more clear in the readme. I'll probably take out the menu soon, but first hit enter. THEN type h and hit enter. 
Please. I'm just trying to be helpful here, not have an argument.
Of all the flavors to choose from...
There's an open issue about documentation of laws for mtl, with a reference to boot. I'm sure a PR would be well appreciated. https://github.com/haskell/mtl/issues/5
Exactly -- a validation function *should* change the type of the thing you're validating! Otherwise, you are leaving easy type safety on the table. And not fancy types type safety, but plain ol' Haskell 98 type safety.
Good catch! I'll fix the json, live reloading should hopefully be pretty easy to add; I plan to add a `file` option to the `response` config, so that should help with pasting raw html haha. Glad it works!
Yeah, I think I tried that as well. I'll see if I can troubleshoot more later.
Yeah, the more I think about actually implementing O(1) V.cons the more of a headache it becomes. I think it's possible to allocate a bunch of extra memory and optimise the cases where a vector is used only once, in the process making another vector but anything else is going to need copying. It's a shame really. I hope the compiler can take out unnecessary vector creation.
Just making the point that overwhelming your tools is a potential code smell. At the very least it probably indicates you're doing something that's not common practice, but it's very likely that your brain has less stack space than your tools.
Please don't discourage anyone from posting job offers. We all need jobs, and it's not like we're drowning in offers. Different firms use different methods of sourcing talent for different reasons. You shouldn't pass judgement on the practice unilaterally. Also, bless you for trying to hire Haskell devs in Alaska - Ex-Alaskan here. Let me know if y'all move just a hair further south to Seattle.
Add 4 spaces in front of lines of code to format them as such. (See "formatting help" in the bottom right corner when you are editing a post.) 
Tbh I kept expecting them to find bugs and was disappointed when there weren't any.
I don't understand what you are disagreeing with in my comment, it sounds like you are suggesting the same thing, except to use Either instead of Validation. There also are plenty of constraints that cannot be encoded into Haskell's type system feasibly. How do you enforce a minimum password length, a requirement that the password has a capital letter or that it is not the same as the username? You can't. I would suspect that the majority of things people want to test for are not encodable into the type system. Either is strictly worse than Validation if there is the possibility of multiple errors because as soon as you hit a single error, Either stops checking for any other errors, while Validation will return all of the errors. What happens when a user is given a username, password and email field to fill in and they only fill in the username field? In the case of Either, they will get only a single error saying that the password field is empty, they fill in a password, submit the form again, and only then will it tell them that email needs to be filled out as well. In the case of validation, that first submit would be able to tell them that both the password and email fields need to be filled in. With Validation, you can easily make tests for that following the style in my original comment: mkAccount username password email = pure $ Account username password email &lt;* usernameNotEmpty username &lt;* passwordNotEmpty password &lt;* emailNotEmpty email You can also do your newtype wrappers if wanted as well: mkAccount username password email = let newUsername = Username username newPassword = Password password newEmail = Email email in pure $ Account newUsername newPassword newEmail &lt;* usernameNotEmpty username &lt;* passwordNotEmpty password &lt;* emailNotEmpty email In the above, if a user submits the form empty, they will get back 3 errors instead of 1. If then the project manager comes down and says they want you to check that the password is not set to the same as the username and email fields, that is easy as well, we just tack on a new test: &lt;* passwordNotUsernameOrEmail username password email Need to check that the password meets a minimum length? &lt;* passwordAtLeastLength 8 password Has the number of tests grown unwieldy? Just cut and paste them to their own function: checkPassword username password email = pure password -- This could be anything really, even pure () &lt;* passwordAtLeastLength 8 password &lt;* passwordNotUsernameOrEmail username password email &lt;* passwordNotEmpty password And now your original function looks like: mkAccount username password email = pure $ Account username password email &lt;* usernameNotEmpty username &lt;* checkPassword username password email &lt;* emailNotEmpty email Need to temporarily disable a test? Just comment it out. -- &lt;* emailNotEmpty email --- My original comment was mostly pointing out that using `&lt;*&gt;` is an antipattern and you should almost exclusively stick to `&lt;*`. It makes growing the function so much easier and keeps the concerns of building the data type and validating the data type separate. If you originally build it like: mkAccount username password email = Account &lt;$&gt; valUsername username &lt;*&gt; valPassword password &lt;*&gt; valEmail email Not only do you have to stub out three functions, but you will likely end up at this point somewhere down the road (once your tests start checking for more complex error conditions) which looks ugly and obscures what is going on: mkAccount username password email = Account &lt;$&gt; valUsername username password email &lt;*&gt; valPassword username password email &lt;*&gt; valEmail username password email In addition, you will likely still end up following the style I originally posted, just you'd be doing it one step removed, and in a less clear format such as: valPassword username password email = passwordAtLeastLength 8 password &lt;* passwordNotUserOrEmail username password email &lt;* passwordNotEmpty password By relying upon the "success" type of passwordAtLeastLength, it becomes less clear how the password is actually built because the builder relies upon the return value of a function 2 functions deep. For all we know, that one moron on your team did a `sort` down there after the password passed validation. passwordAtLeastLength len password = if (length password &gt; len) then Success $ sort password else Failure $ "Password not long enough" --- To use the example from the blog: validateForm :: Form -&gt; FormValidation ValidatedForm validateForm (Form email password) = ValidatedForm &lt;$&gt; validateEmail email &lt;*&gt; validatePassword password This function will almost certainly become ugly over time as requirements are changed. It will likely become: validateForm :: Form -&gt; FormValidation ValidatedForm validateForm (Form email password) = ValidatedForm &lt;$&gt; validateEmail email password &lt;*&gt; validatePassword email password due to needing to cross check things between them, such as that the password is not identical to the email. when instead, it is much clearer to write it like: validateForm :: Form -&gt; FormValidation ValidatedForm validateForm (Form email password) = pure $ ValidatedForm email password &lt;* validateEmail email &lt;* validatePassword password In this way, tests are easy to add and remove and it is immediately obvious how the data type is built and that the Validated Form is built from the original values without any modification. --- Sorry about the long post, I'm trying to procrastinate and I am so far succeeding at it.
Imagine wrapping a monad within a monad and using do syntax. How do you use the inner monads bind in do when the function is scoped to the outer wrapper? You could create a function scoped to the inner monad to perform said operation. Now why does that force us to constrain type monad without it just being a forall? Well that means in order to use do syntax we need a monad in there somewhere. Either way we need to write a new instance of class monad to use do. All MTL monad transformers have identity monad implementations afaik. Which saves you some typing.
You this is a strawman simply due to the fact that the slaves don't consent to the "services".
&gt; I did find and fix three bugs: But only at the very end of the blog post I reveal that…
Interesting! Yes, thank you, this is helpful. I hope to be able to talk to my colleagues about this concept of “effects” in the way that you describe, but I suspect that we will mostly be focused on the basics of the syntax and simply using the functions in a practical sense. It's still a lot to cover in 1 hour! And, yes, no HKT in Swift. We will just be implementing the typeclass “by convention” for each type. Specializing it immediately, as you say. Thank you for the reply! 🙂
This is fixed in latest stack, you can either use the latest prerelease [here](https://github.com/commercialhaskell/stack/releases/tag/v1.6.0.20171202), or use `stack upgrade --git` to update to the latest development version. It seems very strange to use such new features of Cabal in core libraries, for no apparent benefit. However, lets ignore the potential motivations there...
Ok so I wasn't referring to Either vs Validation, I was just using Either as a quick example. My main point is that `&lt;*&gt;` is not an antipattern, and if you CAN use it, do so. Now there are situations where you eventually end up using `&lt;*` or `&lt;$`, but they should not be the first thing you jump to. Since remember that if a `&lt;*` gets added or removed or changed in some way erroneously, the type system will NEVER catch it. My core idea is that things should be moved into the type system as early as possible. Where "type system" could either mean a newtype without an exported constructor or even better making it unrepresentable. For your specific example I might do something like: data Email = Email ... mkEmail :: String -&gt; Validation Error Email mkEmail = ... Here you probably want to use an actual parser You also probably don't want to represent Email as just a String https://hackage.haskell.org/package/email-validate-2.3.2 newtype Password = Password String mkPassword :: String -&gt; Validation Error Password mkPassword p = p &lt;$ validPasswordLength p Here is an example where you might just use `&lt;$`, as you probably just want to leave it as a string after first checking a thing or two. data EmailAndPass = EmailAndPass Username Password validateForm :: Form -&gt; Validation Error EmailAndPass validateForm (Form email pass) = EmailAndPass &lt;$&gt; mkEmail email &lt;*&gt; mkPassword pass &lt;* passNotInEmail email pass Another example of where you might just use `&lt;*` since you cant really check that any earlier / encode it fully in the type system. So whenever you see `&lt;*` what you should be thinking (IMO) is "can this be properly encoded in the type system" or "can this be done any earlier in a module that hides the constructor". Now the optimal scenario where you will see the biggest benefit is when you can make more states unrepresentable: data Model = ... parseModel :: String -&gt; Validation Error Model parseModel = ... data Color = ... parseColor :: String -&gt; Validation Error Color parseColor = ... data Car = Car Model Color parseCar :: Form -&gt; Validation Error Car parseCar (Form model color) = Car &lt;$&gt; parseModel &lt;*&gt; parseColor Which is clearly much better than: data Car = Car String String parseCar :: Form -&gt; Validation Error Car parseCar (Form model color) = Car model color &lt;* validModel model &lt;* validColor color
I also ran into this problem. Upgrading to the release candidate for Stack 1.6.1 fixed it for me. Downgrading to an older snapshot might work too. I am frustrated by packages at the "bottom" of the dependency hierarchy quickly adopting bleeding-edge features for basically no reason. This version of integer-gmp uses Cabal 2's new "caret" syntax for dependency constraints: build-depends: ghc-prim ^&gt;= 0.5.1.0 If that constraint had been expressed like this instead, it wouldn't be a problem: build-depends: ghc-prim &gt;= 0.5.1 &amp;&amp; &lt; 0.6 Unfortunately I can't figure out how to report bugs or open pull requests against integer-gmp. 
Huh? It's not "a strawman" because I'm not suggesting anyone else took any position with regard to slaves. I'm just pointing out that slavers "perfom[ed] useful services." Thus, if slavers are accepted as parasitic, then "perform[ing] useful services" cannot demonstrate non-parasitic status.
Mea culpa! I just somehow jumped over that paragraph. But as writing feedback you should have totally let us know that you did get find some bugs near the beginning. Proposal, argument, conclusion was Rod Serling's recipe for telling stories and blog posts very much deserve their own proper first acts as much as TV episodes and films do.
A one-off bonus you get for accepting an offer, usually prorated over 12–18 months. Offers for junior technical positions at the major tech firms (Google, Facebook... etc) often have a 20–70k signing bonus. This is one of four components you get in most offers: base salary, yearly bonus (%), equity grant and signing bonus.
Don't know how your interpreter works, but just wanted to show off my 234 bytes Brainfuck interpreter written in Ruby: a,*b=$&lt;.read,c=d=n=0 (t,m=a[d],-1 t[?&gt;]&amp;&amp;b[c-=m]||=n t[?&lt;]&amp;&amp;c+=m t[?+]&amp;&amp;b[c]-=m t[?-]&amp;&amp;b[c]+=m t[?.]&amp;&amp;$&gt;&lt;&lt;b[c].chr t[?,]&amp;&amp;b[c]=STDIN.getc.ord n==b[c]?t[?[]&amp;&amp;n=m=1:t[?]]&amp;&amp;n=1 (a[d+=m][?[]&amp;&amp;n+=m a[d][?]]&amp;&amp;n-=m)until n&lt;1 d+=1)while a[d]
They should also relate the regular monads use of `pure`/`(&gt;&gt;=)` to `throwError`/`catchError` I think, like in the `throwError e &gt;&gt;= f ≡ throwError e` law chshersh gave.
Oh for the day that we can actually say that about real code...
Why does this sound so much similar to Kubernetes? 
do you mean as static executable?
While I agree that middlemen can perform useful services, I don't see how they do in this case, unless the middle man actually knows Haskell and can meaningfully discuss what the job entails (which I highly doubt is what people are complaining about here). And this goes double for the recruiters that are just using "Haskell" as a keyword for "smart developer" and aren't even offering work in the language. That's definitely parasitic.
Well you're completely discarding that `q` in your final `otherwise` clause. Are you sure you didn't mean `p : applyNegatives (q : rest)`?
It certainly does look suspicious if it's always a certain person's actions which keep disrupting Stackage...
&gt; some of the cabal team There's no point being coy: It's always the same person's actions (spreading fud about Stack, mutate packages on hackage, PvP sniping, broken flag names, prematurely uploading new cabal syntax) that result in disrupting Stackage. And somehow they always manage to shift the blame onto Stack...
There's no more Tsuru in SG. At least no office with programmers.
yeah, that's what I do. most things worth validating are worth a few lines of boilerplate for the smart constructors. 
yes, those mottos are similar /s: * "please use stack on my 3rd party package, if you use cabal it will very likey just work, but I don't really support that" * "you don't have another choice than to use cabal, the core packages are now using an optional (SIC) syntax, that if you don't support, all your tools are broken. it doesn't matter that we could have in the meantime use the previous syntax for a little while longer" I'm not broken over the nightlies being unreliable, or lts ghc 8.2 not being available just yet. But clearly it matter to me (and to many others) that a core team maintainer made sure this happened on core packages AND was not willing to revert the optional behavior to help with making sure ghc 8.2 delivery is smoother.
I'm not having any argument. I'm just saying this could have all been prevented from happening in the first place (OR this could have been fixed really quick for a temporary amount of time)
It's a good idea for your dissertation to be in the general area you'd like to undertake a PhD in. It's also good to try and find a supervisor that is knowledgeable in this area, as they can give expert advice regarding what to read and how to proceed. Potential PhD supervisors will want to see your dissertation and will make judgements about your ability and suitability for research based on it, so it's important to do an excellent job with this. It will also be beneficial to have taken courses in related topics, or if these are not offered at your institution, do some reading on your own. General FP-related topics such as type theory, category theory, semantics, would be beneficial.
Maybe something like this? https://hackage.haskell.org/package/ghc-mod-5.8.0.0/docs/GhcMod-Exe-Info.html It's not exactly an annotated AST, but I'm not sure you're going to get that anywhere.
yes, we're in agreement here. The only reason that I alluded to a bigger group is that, some of this debacle (e.g. new syntax in core packages) could also have been prevented if a group stepped in to override this questionable *unilateral* decision (after the fact is fine here, we're not seer, things can break in unexpected/unplanned way). Clearly the flag story is just a personal low but at least it's a 3rd party package.
Using partial record fields is the problem here. It's a Bad Idea. Enable `-Wpartial-fields` in your project.
I agree. I was thinking about using lenses to mitigate the drawbacks, but I can think of cleaner solutions by completely avoiding partial records. Not sure why I didn't avoid them in the first place.
Having a "partial record" is not a bad thing as long as you don't use the selectors. 
Can we please not start witch hunts? This is only contributing to making our community unpleasant and sour. If you've got a problem with some behavior in the community, we should take the appropriate steps to fix or prevent that instead of trying to crucify anyone over it. This is an innocent mistake. No one is actively trying to break anyone's tools.
I'd argue that having something like &gt; data Channel = TextChannel TextChannel | VoiceChannel VoiceChannel &gt; data TextChannel = TextChannel' { ... } &gt; data VoiceChannel = VoiceChannel' { ... } is cleaner than partial records in conjunction with prisms over `Channel`.
If it needs to be fixed, [open an issue about it](https://ghc.haskell.org/trac/ghc/ticket/14558), don't complain on reddit. They're looking into it. The world is not ending
People make mistakes. [They're looking into it](https://ghc.haskell.org/trac/ghc/ticket/14558). Let's try to fix problems instead of starting culture wars on reddit.
Interesting, although might want to remove, and `.gitignore` `.stack-work`, and `dist` paths from the git repository.
The way arraylists do it in java for example is that they allocate double the memory. Meaning you have a vector of size 4 and you add a 5th element, a new vector of size 8 gets allocated (meaning there's space for 3 more to add before it doubles again) this minimizes copying and would make cons O(log(n))
As it's included with GHC trac seems right.
Running `stack upgrade --git` fails to fix the error on my machine :(
Hmm, did it warn about the install location not being on the path? Please check that "which stack" gives the install location (probably should be ~/.local/bin/stack)
`which stack` yields `~/.local/bin/stack`. Also: after running `stack upgrade --git`, `stack --version` still shows Version 1.5.1, so something must be wrong?
Author of Threepenny-GUI here. :-) Sorry that Threepenny didn't work out for you, but glad that you found a replacement!
Ok, what are those appropriate steps? We are talking about it now, and there have been many private discussions attempting to restore rationality and civility. Unfortunately, stuff like this keeps happening. I really have no idea what the solution is here except maybe switching to Rust... (half joking, i like haskell too much to do that fully) I see no reasonable explanation for changing a core package in this way. Maybe it isn't intentionally targeting stack users, but hvr has had a historical pattern of blatant disregard for breaking people's builds. As far as i follow, even the cabal developers aren't quite sure what ^&gt;= will actually mean for the solver. So, it seems bizarre to start using it in integer-gmp
The "as long as you don't ..." caveat is why partial functions are bad in general. They're fine until they're not.
Scala has an option to dump the code at various stages of the compiler, and I remember that this output is _very_ verbose, it had type annotations _everywhere_.
The GHC API has that in a trivial example. https://wiki.haskell.org/GHC/As_a_library#Another_example See specifically the `typecheckModule` function call, it returns an AST with types in it. Warning: the AST is probably a lot bigger than you'd expect. Haskell's syntax is wide in scope.
Huh, weird indeed! Well one approach is just to download the prerelease. Alternatively, clone the git repo and do "stack install" from within it
Intero also has this built-in via `:all-types`: https://gist.githubusercontent.com/chrisdone/36527f49a6b85a492db9b2622af3ea67/raw/c103096120fc8057374af2a468b4c0bbb78154db/demo.sh
No promises, but it seems likely that it will be released today or tomorrow. Moving up the schedule a bit because so far no critical bugs found in the prerelease, and to deal with this issue..
The appropriate steps are, obviously, to [file an issue with the appropriate party](https://ghc.haskell.org/trac/ghc/ticket/14558). I think it's reasonable enough to expect the maintainers to revert this minor syntactical change. There's no reason to blow up over this when we just fix the fucking issue.
Good luck with that. If https://github.com/hvr/cassava/pull/155 is any indication your expectation is not reasonable.
While recruiters often don't understand the technology they're recruting for, I think you're wrong that they add no value. A recruiter generally has a better connection to the company they're recruiting for than you will. So you can be one resume in a pile of resumes or you can be a person that is being talked about to a hiring manager from a person who knows the first name of said manager's kids. I realize there are sleezy agents out there, and plenty of "cold calling" ones that don't have any real relationship with the company but, at least, they are motivated (financially) to getting you hired for that company and will invest effort you probably don't have time to in making that happen. They will also have developed better strategies for this outcome based on having to do it vastly more often than you do. They're not leaches, they provide a service that has value. I know, I use this service quite often and it's how I've gotten nearly every job I've ever had. I've tried for a few Haskell jobs and don't even manage to get so much as a "lol, no" back. I wish I had an agent to raise my odds of getting hired for one of these roles.
Let's try to solve the current issue instead of laying blame on past ones. The toxicity is not helping.
Ahh, right. I'll fix that tonight thanks
Yeah, array list does pretty well. Thanks for checking that.
Assuming you're using [`splitOn`](https://hackage.haskell.org/package/split-0.2.3.2/docs/Data-List-Split.html#v:splitOn) from Data.List.Split, I get many type errors when I try your code, the first of which is: Couldn't match type ‘[Char]’ with ‘Char’ Expected type: [Char] Actual type: [[Char]] In the first argument of ‘applyNegatives’, namely ‘splitPolynomial’ This means that `splitPolynomial` has type `[[Char]]`, or equivalently `[String]`, while `applyNegatives` expects a `[Char]`. That's weird, since clearly you meant for `applyNegatives` to work on a list of strings, not a list of characters, didn't you? What's happening here is that Haskell uses type inference to figure out the types from your code, and then it tells you about any inconsistencies it finds. This has the advantage that you don't have to write as many type signatures, but the disadvantage that the type errors sometimes show up in unintuitive places. The problem is that if you meant to write a function of type `[String] -&gt; [String]` and gave it an argument of type `[String]`, but you implemented the function wrong so its inferred type is `[Char] -&gt; [Char]`, Haskell can't tell whether you wanted the function to have type `[String] -&gt; [String]` or if you wanted the argument to have type `[Char]`. For this reason, and because it makes it easier to see what's going on when reading the code, I recommend always using type signatures: import Data.List.Split polynomialString :: String polynomialString = "44x^2 - 2x - 15" splitPolynomial :: [String] splitPolynomial = splitOn " " polynomialString polynomial :: [String] polynomial = applyNegatives splitPolynomial -- Have ["44x^2", "-", "2x", "-", "15"] -- Want ["44x^2", "-2x", "-15"] applyNegatives :: [String] -&gt; [String] applyNegatives [] = [] applyNegatives (p:q:rest) | p == '-' = (p ++ q) : (applyNegatives rest) | otherwise = p : (applyNegatives rest) Now I get a much better error message: Couldn't match type ‘Char’ with ‘[Char]’ Expected type: String Actual type: Char In the second argument of ‘(==)’, namely ‘'-'’ Now the error message points to the right place: you have used `'-'` when you should have written `"-"`. In some languages, those two are equivalent, but in Haskell single quotes are for single characters while double-quotes are for strings. Your code now compiles, but it has two other small mistakes, which I'm sure you'll be able to find now that you can run the code and observe how it fails at runtime. Good luck, you're almost there!
Depending on his research just working on the Core level might be an option as well. It's still typed but a fair deal simpler.
I downloaded the latest beta and everything works now. I still don't fully understand what exactly happened and how this relates to cabal, but thank you for fixing this so quickly! 
And somehow some fanboys always manage to drag threads off-topic with non-backed accusations. 
My tools do such fine. If a tool causes as much damage as stack, is it still a tool?
what if we slightly change the `Fine` instance to the following: instance Semigroup e =&gt; Applicative (Validation e) where pure = Success Failure e1 &lt;*&gt; b = Failure $ case b of Failure e2 -&gt; e1 &lt;&gt; e2 Success _ -&gt; e1 Success _ &lt;*&gt; Failure e = Failure e Success f &lt;*&gt; Success x = Success (f x) When I run it with your tests it seems to have similar behaviour as `Fine`.
Have you considered using nix?
Oh, so maintaining a separate build-tool requires actually maintenance _work_? If only someone had considered this before deciding to create this new tool instead of contributing to the existing one (and splitting up the tool-space and the community in the process). You know why the blame looks shifted in one way? Because there would not be friction between different tools if there were no different tools. Shocking.
[removed]
This indeed works in this case, but this is because `multifail` returns an outermost `Failure` immediately, so everything streams properly. Imagine a situation where some function has failed and you need to stream the errors, but the function continues executing and is not going to return either `Failure` or `Success` for a long time. You won't see the errors until another `Failure` appears or functions finishes. On the other hand your version is strictly better than the existing one, so I indeed should have considered it.
This is not a culture wars, nor about people shoulnd't/couldn't make mistakes; However, this is not an isolated incident, many people have tried to argue to take a more tolerating position (albeit temporarily), with the same party, in at least &gt;= 3 different instances.
Thanks for your suggestion, I added it to the readme.
Probably for historical reasons. Applicatives compose nicely, as witnessed by the Applicative instance for [`Compose`](https://hackage.haskell.org/package/base-4.10.1.0/docs/Data-Functor-Compose.html#t:Compose). Monads don't compose so nicely, which is why we need Monad [transformers](https://hackage.haskell.org/package/transformers). And the API for Monad transformers requires a lot of calls to [`lift`](https://hackage.haskell.org/package/transformers-0.5.5.0/docs/Control-Monad-Trans-Class.html#v:lift), which some people find annoying. So, the Monad Transformer Library (mtl) was created, using type classes to determine how many calls to `lift` are needed and to add them automatically using type inference and instance resolution. Since the intent is to use an mtl-constrained type instead of a concrete Monad transformer stack containing the same pieces, it made sense for the mtl type to provide the same API as the concrete Monad transformer stack, including the Monad methods. Since then, we've realized that mtl-style constraints can be used to [readably express what a computation needs](https://www.youtube.com/watch?v=zLa9wQRhY-8), and that those constraints [combine](https://www.youtube.com/watch?v=JxC1ExlLjgw) much more elegantly than alternatives based on concrete datatypes. With this new understanding, it is true that it no longer makes sense for a constraint expressing the requirement that a computation needs the ability to throw errors to also express the requirement that the computation needs the ability to combine sub-computations monadically. So, ironically, the meaning of "mtl-style" has evolved in such a way that the mtl is no longer a very good example of an mtl-style library!
Thanks for the great example of this process! As a side issue, I'm still not sure why you rolled your own Intervals type and didn't use the usual [ranged-sets](https://hackage.haskell.org/package/Ranged-sets) library. Proving correctness using Coq would probably be harder because it is more general. But it does have a great collection of quickcheck properties that probably would also have found your bugs :).
I've just switched to using generic-lens, and my product business value increased by 27%.
But why? You're [using Kleisli IO](https://github.com/s4ke/brainfuck-arrows/blob/master/src/Control/Arrow/BrainFuck/BFArrow.hs#L30), which indeed has an Arrow instance, but it also has a Monad instance, which is more expressive. What is the benefit of using Arrow over Monad for this program? Are you just training your Haskell muscles by implement a program with one hand tied behind your back?
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [s4ke/brainfuck-arrows/.../**BFArrow.hs#L30** (master → 95b4ef7)](https://github.com/s4ke/brainfuck-arrows/blob/95b4ef782736f65e8ba1267c854c909cae7fb76a/src/Control/Arrow/BrainFuck/BFArrow.hs#L30) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dquq7mp.)^.
oooh, I'm sure no one tried this in the past few years. After all, we're clearly all have our day jobs clearly centered about witch hunting specific individual and posting negative comments on reddit; our long list of common grievances are just isolated incident after all.
head in the sand and pretending everything is fine is not helping either.
At the time of writing, I did not want to interrupt my programming by search and evaluating libraries, trying to understand their types and type classes etc. But I agree that it’s not the best example of software engineering practice :-)
I have seen this `Validation` type before, but I don't remember where. Where is the standard place to get it from?
Surprising hard to find out the date of that event from that email. June 8-10, JFTR.
Ah OK. This was once a candidate for inclusion in base, so I thought you had heard of it. We definitely still have a problem of library findability in our ecosystem.
Awesome find, and a neat trick! 
I fully agree! The toxicity is definitely not helping just like it didn't help in https://github.com/haskell/process/pull/102#issuecomment-322794371
Is it? It says it in the second paragraph. Granted, it would be even clearer to put it on its own line at the top.
You already know how to find it :) https://www.stackage.org/lts-9.17/hoogle?q=Validation
Improving cabal-install would require to throw most stuff out and start over building it up with the right UI. And this is what the people at FPCo did after having gained experience starting with a tool that was called FPBuild originally and after some serious evolution ending up with the Stack tool we all love today. 
It was definitely more than 3 times. I can think of at least 5 incidents off the top of my head. Maybe it's time we thought about something like three-strikes policies to prevent such toxicity in the future.
If you call one of the most important and influential advances in computer science in history a "design bug", we definitely disagree on the definition. But we agree that the current change is a good one, and that's what's important.
Other people have already pointed out how to get your code to work, but here are two more points since I'm at it: * `splitOn " "` works, but `Data.List.words` handles multiple spaces as well as other kinds of white space, and doesn't require pulling in an extra dependency. * You're missing a pattern for `applyNegatives` - a single element list matches neither `[]` nor `p:q:rest`. This doesn't crash your particular example because you're going straight from a two-element list to an empty one, but it's definitely going to explode on you eventually. (Hint: GHC/GHCi will point out missing pattern matches if you run it with `-Wall`.)
Nitpick: `splitOn " "` works, but `words` (from `Data.List`) handles repeated spaces as well as other kinds of white space, and doesn't require pulling in an extra dependency.
Ha, thanks. :) I wasn't so interested in the name, but rather in the idea of something like `Either` that accumulates multiple errors on the left. And in fact, in the library that Hoogle comes up with for that search, `Validation` is the type that does *not* accumulate errors; there is a different type in the library that does that. Is this the standard library for that kind of thing? On a lark, I tried a Hoogle search for "instance Semigroup l =&gt; Semigroup (T l r)". It gave me a list of many functions that return a type of kind `* -&gt; * -&gt; *`. Actually surprisingly good, but not what I was looking for.
What library does Hoogle come up with for you? I get https://www.stackage.org/haddock/lts-9.17/either-4.4.1.1/Data-Either-Validation.html#t:Validation which does accumulate errors.
Look, I'm not a recruiter, but it's fairly standard practice for recruiters to stay in touch with their recent contacts from what I've seen over the years. It doesn't mean they were untruthful about their original post and I wouldn't treat their trying to stay in touch as spam. As others have pointed out, we do want them here as long as they're not disrupting dialogue. If you want out, you can simply say "I'm not interested, please stop contacting me" and they usually oblige.
Oh interesting. Using regular [hoogle on haskell.org](https://www.haskell.org/hoogle/), not the stackage-specific one, I found [validation](https://github.com/qfpl/validation). This does look like a mainstream library, original author Tony Morris, now actively supported by the Queensland FP Lab. But Ed's `either` library is also popular. It's slightly annoying that the two libraries use the same type name in totally incompatible ways.
I don't understand. That one seems to accumulate errors too. https://github.com/qfpl/validation/blob/master/src/Data/Validation.hs#L87
I'm curious. That's something I'd like to do. Do you have an example?
Hey, I want one!
&gt; `($ x) &lt;$&gt; f` is better than `f &lt;*&gt; pure x` In which way? Aren't those supposed to be equivalent?
You have a [similar type](http://hackage.haskell.org/package/transformers-0.5.5.0/docs/Control-Applicative-Lift.html#t:Errors) in transformers. One small disadvantage is that it uses `Monoid` instead of `Semigroup` for the errors.
Awesome, that really helps. Thanks!
Denotationally, yes. But in general they can differ operationally. I once encountered a space leak which was fixed by replacing`a *&gt; return y` by `y &lt;$ a`.
That's `AccValidation`, which does accumulate, and which has `Semigroup` and `Monoid` instances. `Validation` does not accumulate, and has no such instances. Oh wait - a [recent commit](https://github.com/qfpl/validation/commit/1f2a79d79bfbd65068e298c796d6c02e427652ca) just erased the `Validation` type, as well as `ValidationT`. Now there is only `AccValidation`. OK, that solves the problem of inconsistent use of the same type name. I just found yet another mainstream-looking library [validationt](https://hackage.haskell.org/package/validationt), supported by [typeable.io](https://typeable.io). It's a crowded field.
Why do you think it's wrong to have a `.gitignore` file in a git repository? AFAIK it's quite standard practice.
I meant `.gitignore` as a verb.
I requested same feature from `haskell-ide-engine`: * https://github.com/haskell/haskell-ide-engine/issues/353 But still didn't receive feedback :( Though I think it's capable of doing this.
Can you add screenshot or even an asciicast (using http://asciinema.org/) to the README?
&gt; http://asciinema.org/ Yes, thanks for the suggestion!
Ah ok, I understand what you mean now. All the instances I have had to use Validation already had simplified checking applied by the nature of the service, such as an earlier field in the message dictating what is allowed to come later so those sorts of things are already in the type system if it made sense to do so, though that layer could potentially be based upon Validation instead of e.g. attoparsec. I could forsee this being used in checking e.g. JSON where each value is mostly independent and can potentially be converted to a sum type or otherwise individually checked, but you may still want to validate the message as a whole as well in a sort of 2 stage validation pipeline: You first convert the fields to sum types, then use those to check further properties of the whole system: data Color = Red | Blue data Model = Car | Truck data Order = Order Model Color data ValidatedOrder = ValidatedOrder Model Color mkOrder :: String -&gt; String -&gt; Validation Errors mkOrder model color = Order &lt;$&gt; mkModel model &lt;*&gt; mkColor color mkModel "Car" = Success Car mkModel "Truck" = Success Truck mkModel _ = Failure "Invalid Model" mkColor &lt;patternmatch&gt; = ... isCombinationValid Truck Red = Success () isCombinationValid Car Blue = Success () isCombinationValid Car Red = Success () isCombinationValid _ _ = Failure "Invalid Combo of Color and Model" validateOrder :: Order -&gt; Validation Errors ValidatedOrder validateOrder (Order model color) = pure $ ValidatedOrder model color &lt;* isCombinationValid model color buildAndValidateOrder :: String -&gt; String -&gt; Validation Errors ValidatedOrder buildAndValidateOrder modelStr colorStr = case (mkOrder modelStr colorStr) of Success order -&gt; validateOrder order Failure errors -&gt; Failure errors learn some new way to do things every day in haskell.
Snapshots added!
Haha, have you tried Scala?
and asciicast available here : https://asciinema.org/a/151404
Would your repeated attempts to cause "us vs them" arguments count as strikes?
This year, I promise to talk about Haskell. ;)
Great work! Especially the explosions. :)
Merged into `either` HEAD.
Merged into `either` HEAD.
A combinator that does your lazier applicative construction has been added to the `either` package in HEAD as 'mvap', and the existing applicative has been updated to match xalyama's trick above. I also found a few places where i could increase sharing in the monoid/semigroup, etc.
Nice concepts, very cute! I love the number explosions. Could be nice for kids learning arithmetic. I made a game with similar do-arithmetic ideas in http://chrisdone.com/numbergeddon I've been pondering how to make one for lambda calculus. I had some ideas like that a lambda is a castle and you use catapults to send arguments in and things like that. But you really need to capture the idea of copying and duplicating arguments and things. The crocodile lambda calculus doesn't make sense because eggs hatch into other eggs which is just shoehorning an idea into an inappropriate metaphor.
You can embed your asciicast directly to your README. Just see how it's done here: * https://github.com/bollu/teleport#readme
Agree. Explosions are really amazing (\*.\*)
thanks! Works perfectly now
&gt; http://chrisdone.com/numbergeddon Thanks for your comment, I spent some time on the explosions, I'm glad you like them ;) I tried playing your game, it's really really hard! 
thanks! It was a lot of fun to program, it's cool to see that I'm not the only one liking them :)
The ones I like best is when the ship hits a number, but in the video it doesn't look very good because it's near a wall... you have to play the game to see :)
You don't even try to refute my point. \*yawn\*
You talked about Haskell this year as well, in the bait part of the bait and switch. What I want is a promise you’ll be talking only about Haskell. In your talk. At ZuriHac. (I will write a formal request in Agda if necessary to be precise.)
We use travis to publish a release to github. Here is the .travis.yml and our Homebrew cli.rb: https://gist.github.com/dbousamra/107b67993c0050c3ec38c15c47d94818 
I just tried out the effect monad and it is indeed exactly what I needed. Thank you for this!!
Uh oh everybody, tony's back.. Better hope you use the same software as him or your gonna get an earfull.
I liked the fact that `ranged-sets` library exposes properties as well! I see this first time. And immediately understood that this is great! If you're writing application and you want to have tests, you don't need to reimplement tests for all libraries you use. What is even nicer is that properties are just functions to `Bool` so you won't force users to depend on `QuickCheck` or `hedgehog` testing libraries!
Glad I could help :)
Why should anyone but the library’s test suite have to run these tests? (I wonder if they are just there because of the problem that you cannot export properties in a way that they are only visible to the test suite.)
You're is the contraction for you are. No is the answer to your question.
Haha, better hope you use proper grammar when typing on you're phon too :)
[I'd like to have an argument, please](https://www.youtube.com/watch?v=kQFKtI6gn9Y)
I have a `Handle`. On the other side of that handle, a process is doing this: other :: Handle -&gt; IO () other h = forever $ mk &gt;&gt;= BS.hPut h . Data.Store.encode mk :: IO MyData I would like to write something like this: myproc :: Handle -&gt; IO () myproc h = forever $ myGet h &gt;&gt;= print . show myGet :: Handle -&gt; IO MyData How do you write `myGet`? Thanks!
Is this a suitable event for people who do some hobby Haskell dev on the side and just want to sit back with a bag of popcorn and chill while listening casually to and meeting other Haskellers? Or is it mostly/only meant for more serious Haskellers doing serious Haskell work?
I'm glad you've kept the commitment to discussing personal attributes of individuals. I have code to write now. Cheerio.
Hobbyists are definitely welcome!
... which is already in GHCi. You need to `:set +c` before loading, though.
Sure, continue to say and do ridiculous things, and I will continue to discuss your personal attributes. Cheers!
I think you've made a mistake with your link; I don't see how that comment can be interpreted as "toxic"
Do you know of any good example of an mtl-style library?
Because it diverges from Haskell. Eta has it's own roadmap and with time I fear it will become Haskell-like rather than Haskell on JVM.
Oh boy. The stack vs cabal is becoming such a soap opera that it is not even wrong any more.
Indeed. /u/haskd3v is banned. Obvious trolling, and probable sockpuppetery of another banned user. 
Its no secret that lists are inefficient for certain operations, which is why people have come up with other containers that are like lists, but better for other uses (like [Data.Sequence](https://hackage.haskell.org/package/containers-0.5.10.2/docs/Data-Sequence.html)). In this paper, the authors show that can be generalized to any Monad. For example, here is a [more efficient Free Monad](https://github.com/atzeus/reflectionwithoutremorse/blob/master/Fixed/FreeMonad.hs).
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [atzeus/reflectionwithoutremorse/.../**FreeMonad.hs** (master → 2ab000b)](https://github.com/atzeus/reflectionwithoutremorse/blob/2ab000be1ddc49a2ec36afaaa58485df56aef654/Fixed/FreeMonad.hs) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dqvx5zd.)^.
Obvious troll is obvious. This thread won't appear on the subreddit. 
One technical question though. As far as I understand, stack uses the same parser for parsing cabal packages. How is it that the parsing is failing?
I recently learned threepenny-gui and got hung up on hooking up the css files as well. I dug through other people's projects for an hour or two and ended up making it work by passing in a directory in the defaultConfig, like so: main = startGUI defaultConfig { jsStatic = Just "./app"} setup My css file was located in projectdirectory/app/css/style.css. Then I called addStyleSheet with "style.css". Not sure if this was what you were missing. I'm glad your project worked out nonetheless!
Can you add a pdf flair for this? (Saves people with data limitations on mobile) Cheers
"Freer effects, more extensible effects" is in the continuation of that work; that free monad construction with an optimized continuation representation can now be found in [extensible-effects](https://hackage.haskell.org/package/extensible-effects-2.1.0.0) and [freer-effects](https://hackage.haskell.org/package/freer-effects), and now that I look at them closer I wonder what the difference between these packages is.
How is this different than using LiquidHaskell? Does it allow to catch different kinds of bugs?
Have you tried using `BS.hGet`? How many bytes is a `MyData` encoded as?
I do not see an option to that. Maybe only the mods can do that?
Do you have a corresponding Decode function to `Data.Store.encode`? This seems to possibly be a usecase for [named pipes](https://en.wikipedia.org/wiki/Named_pipe). You can read from and write to them more or less like they are regular files.
**Named pipe** In computing, a named pipe (also known as a FIFO for its behavior) is an extension to the traditional pipe concept on Unix and Unix-like systems, and is one of the methods of inter-process communication (IPC). The concept is also found in OS/2 and Microsoft Windows, although the semantics differ substantially. A traditional pipe is "unnamed" and lasts only as long as the process. A named pipe, however, can last as long as the system is up, beyond the life of the process. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/haskell/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
Ah well. Thanks for trying
Does anyone know how this compares to slapping `Codensity` on top of the typical `Free`? AFAIU, the main difference is in the ability to tear apart, manipulate, and rebuild `Free` programs without really running them; but this is definitely not how `Eff` monads end up being used in the vast majority of cases. Considering that most uses of `Eff` are as an `mtl`-style alternative for ordinary effectful programming, how does the performance of RWR compare to `Codensity (Free f)`?
Cabal-2.0 added a syntactic feature. Stack's currently released version uses Cabal-1.24 as a library to do a lot of things, including parsing cabal files.
That [past discussion](https://www.reddit.com/r/haskell/comments/6qn4y0/when_to_use_cps_vs_codensity_vs_reflection/) seems to agree with you.
The thing here is that when I return a `Failure` with some errors, I want these errors to be stored in a `NonEmpty` which is not a `Monoid`. We need something like ``` class Append a where append :: Foldable f =&gt; a -&gt; f a -&gt; a instance Append e =&gt; Applicative (Validation e) where pure = Success Failure e1 &lt;*&gt; b = Failure $ e1 `append` case b of Failure e2 -&gt; Just e2 Success _ -&gt; Nothing Success _ &lt;*&gt; Failure e = Failure e Success f &lt;*&gt; Success x = Success (f x) ```
One of the professors managed to get it working for me, but unfortunately I have no idea have they managed to do it:/ 
Yes, that is the issue. The receiver does not know, a priori, how many bytes will be passed. Moreover, even if the receiver knows the number of bytes, `BS.hGet` makes no guarantees as to how many bytes are returned. It seems like a lot of work to separately encode the length of the bytestring (through some other means than Data.Store), and then loop reads, gradually building up the requisite bytestring. Moreover, it seems like everyone who wants to serialize data will have to do this. So my question is, is this already done somewhere? Is there a standard idiom?
Ok let's define a grammar and parser that we can run against his talk
It seems like `conduitDecode` from `Data.Store.Stream` handles this.
It's not a problem to rely on testing libraries if you put the tests in a separate module, and then only include them in a `test` stanza in the cabal file. That does not create a dependency for applications using the library.
What are the bug’s symptoms? I updated to the new stack nightly and all seemingly worked fine..
Tangentially, is the new `^&gt;=` operator supposed to be the idiomatic way to mark dependencies now?
I think it would be good if that can be avoided if you want to be backward compatible.
It's nice to have people who work on making sure our development tools keep on working. While previous discussions on this issue often get derailed by speculation into whether the problems are caused by malicious actions, I think that is an unnecessary debate (and is socially toxic). My take-away is that a fairly small change somewhere had an unfortunate effect elsewhere, but that the tool maintainers fairly quickly stepped up to diagnose and fix the issue. I'm really happy someone else is dealing with this stuff so I don't have to do it myself.
Maybe you're implementing wrapper around `ranged-sets`. Or you have complex data types with several ranges inside. So properties for your data types can be expressed using existing properties for library types.
Great to hear &amp; thanks for the reference!
[Info on `^&gt;=`](https://www.haskell.org/cabal/release/cabal-2.0.1.1/doc/users-guide/developing-packages.html#build-information)
&gt; This means that before any actual errors are returned, a whole computation must finish -- no lazy streaming of errors is possible. Which also implies that Validation can never be short-circuiting: even if you don't care about actual errors and just want to know whether a computation has finished successfully, you won't be able to stop early once an error has occured. I thought this was the whole point of doing validation with applicatives, because monadic validation short-circuits on the first error. That is, use applicatives to get all the errors, use monads to get just the first one. 
There seems to be a typo in the explanation. or am I missing something 
`Either` always short-circuits, but proper `Validation` allows you to not short-circuit (if you want all the errors) and to short-circuit (if you only care whether there are any errors or want just the first ten of them). With proper `Validation` you can also process errors as they appear in a lazy fashion rather than waiting for a whole computation to finish and only then being able to handle the errors.
Right, what I'm asking is are we encouraged to use the first now? Is it there so They (whoever that is) can resolve/loosen bounds in a more principled way? Or is it just syntax and not meant to imply anything like that?
Does it have an official, pronounceable name? I vote for "the woodpecker operator!" Who's with me?
Flair added. `[PDF]` flair can now be added by moderators to link posts.
You'll see the error message: &gt; Unable to parse cabal file for integer-gmp-1.0.1.0: NoParse "build-depends" 58 It's possible to bypass this by not updating your 01-index.tar.gz file to include the new changes. But next time you run `stack update` or try to use a newer snapshot, it will download the new file. Of course, upgrading to Stack 1.6.1 is a more surefire way to avoid the problem.
And other than displaying an error message would had stack still build my project successfully? Or would it fail?
The discussion on this issue may be helpful: https://github.com/commercialhaskell/stack/issues/3464. Following that discussion, I'm still not completely sure what the plans are for `^&gt;=`. For that reason, as well as the backwards compatibility concern already mentioned, I'd be cautious.
It would be a complete build failure. It's possible that you'll avoid the problem indefinitely with caching, but upgrading is much more reliable.
I see, so I guess that because of caching I didn't notice the bug. (caching was the bug in the bug)
Ok, that 23Skidoo comment (in particular the long-term plan paragraph) clears up the intention - "I need at least this version and maybe a future version if it works." This is indeed what I as a user usually want to say, even if the ecosystem infrastructure hasn't decided precisely how to implement stretching future upper bounds.
I call it "caret". 
Hmm, is that useful? It seems to me that this new operator should not be used already because people ask what it means. I've never seen anybody misunderstand or even ask what `foo &gt;= 1.2.3.4 &amp;&amp; &lt; 1.3` means, as it uses operators any programmer is familiar with. Saving a few characters here at the expense of understandability seems like an optimisation in the wrong direction.
Rumor has it ZuriHac made some hobbyists non-hobyists.
Note that `^&gt;=` implies soft lower bounds too. If your package has `foo ^&gt;= 1.2.3`, the Hackage trustees might decide to change that to `foo &gt;= 1.1 &amp;&amp; &lt; 1.3`. 
I'd argue that it should be avoided, and not just for the sake of compatibility: https://twitter.com/hdgarrood/status/892003648951259138
In lambda calculus (and programming languages) arguments are either bound or free. f x = x + 1 has a bound argument (x) and a number literal (1) f x = x + g has a bound argument (x) and a free argument (g)
I'd like to see a more detailed category theory programming language, where you could define monoids in more than just the base category, so you could just *say* that a monad was a monoid in the monoidal category of endofunctors with composition, and just write join :: Compose f f ~&gt; f return :: Id ~&gt; f It probably wouldn't be efficient at all, but it would be nice from a mathematical point of view. You could also write merge :: Day f f ~&gt; f pure :: Id ~&gt; f (&lt;|&gt;) :: Product f f ~&gt; f empty :: Const () ~&gt; f (of course, all this with:) data Id a = Id a data Compose f g a = Compose (f (g a)) data Day f g a = Day (f x) (g y) ((x, y) -&gt; a) data Product f g a = Product (f a) (g a) data Const x a = Const x type (f ~&gt; g) = forall a. f a -&gt; g a
Essentially, I hope it comes to mean "my code is guaranteed (by me) to work with this version, but you (stack) can supply any non breaking version if you want to"
So what's the bound argument of the `join` function then, which is projected into the outer level? I'm aware of the concept of free and bound variables, but I find it hard to make sense of this documentation of `join`.
Would you mind wrapping the documentation quote in markup? Took me a second to realize you were quoting it.
In some sense I agree - it's not at all obvious what this symbol means. But in another sense, it's *always* obvious what dependency versions mean: I just wrote whatever was necessary to get my project to build, [and as long as it builds, great](https://media.giphy.com/media/6yjZMdb5TQvcI/giphy.gif)! Ok maybe not *always*; but the point is I have no idea what the difference between `text-1.1` and `text-1.2` is, and the fact that I wrote `text-1.2` as my dependency is just because it happened to be what was available when I started writing my package. I think we often pretend like version bounds are something the developer specified rather than something the developer wrote because he was supposed to write something, and I think the latter is more common.
I'm inclined to agree with you. 
Maybe here the "bound argument" notion is : if `m` is the Monad, in `m a`, `a` is the "argument bound to the Monad". Looking at the implementation of the join function, I think the "bound argument that is projected into the outer level" is `a` here.
In my opinion this Haddock comment is confusing and doesn't add anything. It should just be: The join function is the conventional monad join operator. join x = x &gt;&gt;= id
Sorry for causing confusion ;) I did actually think about making the reference more explicit, but didn't want to use quotes as I was paraphrasing. Also I was hoping that the second paragraph would clarify that.
Sorry, the documentation is a bit confusing. I didn't realize what it was trying to get at until I read it the second time. A monadal context is something like `m a` where a is bound by the monadal context m. What the documentation is saying is that the a is projected into the outer layer (ie the outer m) In other words, join takes nested monadal contexts and "flattens" the upper two layers. This is probably one of the many examples of Haskell documentation that is a little more academic sounding than it needs to be to get the point across.
Agreed. I'd also add the other direction of the law m &gt;&gt;= f = join (fmap f m) and maybe a few examples of `join` with concrete monads.
Wow, what a confusing piece of documentation. I would have said something more like join :: Monad m =&gt; m (m a) -&gt; m a If `x` is an action which yields another action as its result then `join x` runs `x` and then runs its result. In `do` notation join x = do y &lt;- x y 
What methods have you tried?
If the list is empty, there is no way you can return a value of type a. Your only option is to abort the computation.
in retrospect I'm almost embarrassed to say.... maybe I didn't word it correctly. getLastElem [] = ??... but my return type seems to a mismatch with x, or [], or "list is empty". So I'm not sure what to do. 
It is going to be used in the future to lessen the contraints for the solver, AFAIR. It's there to differentiate a hard upper (tested/known) bound, the 'old' syntax. from a soft (untested/unknown) upper bound - the new syntax. This has been a subject of multiple blog posts AFAIR, and has been created to reduce the attrition between proponents and opponents of upper bounds / PVP.
OK, so as a solution to problem01 of 99haskell problems I just deleted the check and have a working solution. is this acceptable - as a solution. 
Learning Haskell will make you hate Elm.
There are two possible ways. The first is to do as you did, and write a partial function. The second is to write a function with the signature `[a] -&gt; Maybe a`. This is a good exercise!
Typically you would have a case `getLastElem [] = error "getLastElem: empty list"`, though the only difference is a slightly more informative error message.
I went and learned FP basics in an imperative language with higher order functions and kept translating toy problems from haskell into my language of choice. I used JS for this purpose, due to personal familiarity. I found that at some point I transitioned between being frustrated with Haskell to being frustrated with JS, and from there it was a short trip to finding it easier to think in Haskell.
I did try Maybe a.... resulted in compiler error. I'll try again - Maybe I didn't understand the error correctly. 
You have to wrap value in a Just constructor: getLastElem [x] = Just x 
hate - Elm. What word appropriate for Javascript then? :)
Several languages are starting to implement these operators for their package managers. I've seen tilde / caret version constraints in javascript, php, and rust. I've seen tilde only in elixir. It probably won't be long before these become standard in many languages, because they (seem to) largely fix the problem of package maintainers not specifying correct bounds. I know that has been a persistent problem in haskell over the years.
I feel potentially a monad tutorial coming on here (oh no!) but `join` actually made sense to me before I understood the monad concept (before `unit` and `bind`) because if I have, for example, a computation which may raise an exception and I want to pass its result to another computation which may raise an exception, I've got something like a nested potential-exception couple of computations. Thus, I need something that will run my computation inside the rest of the first and then flatten it. I don't think I'm helping the "bound" argument, though. That seems like a really obtuse way to phrase this. I wanted to respond, though, because the `do` notation here seems to get further away from this, in my view? Maybe no one else will agree. It obscures the simple thing that's happening, somehow, for me. 
&gt; I think we often pretend like version bounds are something the developer specified rather than something the developer wrote because he was supposed to write something, and I think the latter is more common. This is definitely a great point. Especially for a tool which tries so hard to abstract out nasty working details and make sure things "just work". What I'd love to see is that `^&gt;=` become, essentially, "I can guarantee that the code works on my computer using this version, but if stack/cabal wants to substitute any other version that they think will be compatible, they can" At that point, I think the best course of action for most people would be to switch over to using `^&gt;=` by default; it lessens maintenance burden on the developer's end and makes things much easier on the programmer's end. (As an aside: It would be cool if the build tool eventually got smart enough to say "well, the build file wants version `X-2.3.4`, but it only uses a few functions and those functions have existed since `X-1.0.0` and the last change to their code was in version` X-1.2.4` which I already have installed, so I'm just going to use `1.2.4` instead and swap it out if they start using any newer functions")
I think the pattern match for the recursive case is missing: getLastElem l@(_:_) = getLastElem $ tail l
&gt; I don't think I'm helping with the "bound" argument phrasing, though. That seems like a really obtuse way to phrase this. I agree. &gt; I feel potentially a monad tutorial coming on here What I actually feel coming on is a git fork of the documentation of base, trying to improve the docs for many existing functions ... 
But why does it operate on the first minor version number for ranging? Aren't backward-compatibility breaking changes indicated by bumping the major version? 
I do like that better, but to be honest, if I was trying to understand what join did as a beginner, `join x = x &gt;&gt;= id` wouldn't have helped me a whole lot unless it was also present with /u/tomejaguar's comment, /u/m0rphism's, and ideally a few examples of `join` with concrete monads. Which, of course, sort of brings me to my vague annoyance with documentation in general. Soft documentation doesn't really belong in the source code; it takes up way too much space and often requires non-ascii content to achieve maximum effect. Yet, if it's not inlined with the source, it'll eventually bitrot. It's a tough problem and I don't think anyone has a perfect solution yet.
Yes, i've written just a partial example on how to apply Maybe constructors with a little context.
Unfortunately, due to the level of abstraction, there aren't good terms for clearly describing what `join` does. "Action" isn't a good choice if you're considering that `join [[1, 2], [3, 4]] == [1, 2, 3, 4]` or that `join (Just Nothing) == Nothing`. Perhaps it would help to say that it "flattens the context". But I think in the end, it just needs a variety of examples.
If the version is `w.x.y.z` then changing `y` and `z` do not indicate breakage but changing `w` and `x` do. This is the PVP scheme, not the SemVer scheme.
I agree it's somewhat tenuous but I think it's at least an order of magnitude better than the current version. Besides, I consider list to be an action that can return multiple results and maybe to be an action which can possibly fail. With those readings the doc is precise as stated.
That seems like a very confusing way to write it. Particularly since it leads to you using partial functions (tail). Why not: getLastElem [] = Nothing getLastElem (x : xs) = getLastElem xs &lt;|&gt; Just x Or: getLastElem [] = Nothing getLastElem [x] = Just x getLastElem (_ : xs) = getLastElem xs
Aggressively despise?
Apologies if I have offended you in anyway, that was not my intention at all. The only reason I sent you the second Haskell job spec was because I thought you may not of been interested in the first, I was not aware you didn't reply because you didn't want to be contacted by a recruiter (which is completely fair enough). I have removed all of your details from our system so you will not receive anymore emails from Oliver Bernard. Apologies once again, all the best. 
How do you construct a Maybe value?
That seems like the common danger, though, when trying to find a metaphor that will unify our intuition surrounding all monad instances. In other words, it's the same problem anyone must face when trying to understand monads. Avoiding any of the unifying metaphors is the safest thing to do, I think.
Eh? Then how is it different from the wildcard? ie. `foo ==1.2.*` is the same as `foo &gt;= 1.2 &amp;&amp; &lt; 1.3` (per cabal documentation), which you say is equivalent to `foo ^&gt;= 1.2.3`. So why would I ever want to use the new operator? It's backwards incompatible but functionally equivalent to an existing operator.
Do you have some links I could follow? The [linked cabal documentation](https://www.haskell.org/cabal/release/cabal-2.0.1.1/doc/users-guide/developing-packages.html#build-information) says it's just `new syntactic sugar`. But what you says sounds like it will have different semantics in the future. If that is true, it seems people are scheduled for another surprising change in behaviour / breakage when that change happens.
fwiw, there's Neil Mitchell's NSIS dsl: https://hackage.haskell.org/package/nsis /u/chetanbhasin 
Are part time student positions available?
While I agree that point-free shouldn't be over-used, I think the point-free version in the first example is much clearer than the applied example. The point-free version makes me think in terms of the composed functions instead of the parameter. While there certainly can be clarity offered by an explicit parameter, it also can increase line noise and obfuscate what the code is really doing, because we are so frequently bad at naming things, and so the naming of a parameter can give us preconceptions about the code that don't match reality.
Awesome. Thanks
Thanks, yea I need to remove those. I'll be making my changes after my finals end in 2 weeks.
A quick google got me this: &gt; &gt; New caret-style version range operator ^&gt;= (#3705) that is equivalent to &gt;= intersected with an automatically inferred major upper bound. For example, foo ^&gt;= 1.3.1 is equivalent to foo &gt;= 1.3.1 &amp;&amp; &lt; 1.4. Besides being a convenient syntax sugar, **^&gt;= allows to distinguish “strong” and “weak” upper bounds**: foo &gt;= 1.3.1 &amp;&amp; &lt; 1.4 means “I know for sure that my package doesn’t work with foo-1.4”, while foo ^&gt;= 1.3.1 means “I don’t know whether foo-1.4, which is not out yet, will break my package, but I want to be cautious and follow PVP”. **In the future, this feature will allow to implement automatic version bounds relaxation in a formally sound way** (work on this front is progressing on matrix.hackage.haskell.org). See this section of the manual for more information. [From this releases notes of cabal 2.0](http://coldwa.st/e/blog/2017-09-09-Cabal-2-0.html) At least this part I wasn't very off :) &gt; If that is true, it seems people are scheduled for another surprising change in behaviour / breakage when that change happens. I don't see why it would be the case, as using the solver is already opt in AFAIR, and even if not, this behaviour can be guarded behind a flag (like 'allow-newer') 
I guess OP is talking about this https://wiki.haskell.org/99_questions/1_to_10 I have to say, that's a *very* bad beginner question.
That's what I forgot "Just a"... so now it compiles.
Neat! 
Yes it does, thank you! Thanks to your "stream" pointer I now see multiple solutions to this issue out there in Hackage-land: * [`Data.Store.Streaming`](https://hackage.haskell.org/package/store-0.4.3.2/docs/Data-Store-Streaming.html) * [`Pipes.Binary`](https://hackage.haskell.org/package/pipes-binary-0.4.1/docs/Pipes-Binary.html) * ... and I'm sure there are others.
I've been learning and using Haskell for about 3-5 years now, depending how we count, and I don't yet aggressively despise JS. Not even hating it. There are even a few things I wish I could have from the JS ecosystem that is hard with Haskell.
JS is just about the worst designed language in existence so I must say I am surprised. What exactly do you feel Haskell is missing from the JS ecosystem besides just pure popularity (which would be nice to have for sure).
100% agreed. This will waste a everyone's time googling for the meaning of it. Googling this isn't trivial either.
Either `Just :: a -&gt; Maybe a` or `Nothing :: Maybe a`.
I have used the 99 questions in LISP list twice to teach Haskell. 1-20 work quite well. They are short and they force people to deal with pattern matching and recursive thinking. More importantly they can be done inside the REPL so they don't have to deal with mistakes about edit -&gt; load -&gt; edit -&gt; load... 
1. Yes, popularity would indeed be nice to have. 1. The other day I've installed a CLI tool with `npm`, and it took 14 seconds to install, including about 300 packages as dependencies. Cabal and stack are orders of magnitude slower than that to compile from source. It can take hours to install a comparable CLI tool with cabal or stack. Nix has some binary caching, but that has a much steeper learning curve compared to npm, and a very unpolished user interface yet. 1. I'd love to be able to write GUIs that are unit-testable. With AngularJS I could do that rather easily. Reflex-frp and reflex-dom come the closest to allowing writing nice GUIs in my experience, but it's not testable whatsoever yet. Although me and some others are working to change that. 1. Haskell has a slower compile-time/load-into-ghci-time/feedback-loop than it takes to reload a browser window while developing. The former, even with GHCid can take up to 10-30 seconds, while the latter usually takes about 1-5 seconds. Even with mid-sized (5-20k sloc) projects. Maybe JS's JIT compilation helps with that. 1. There are some problems which would be easiest to solve, or only possible to solve with polymorphic dynamics. Yes I can do `toDyn 'c'` for monomorphic values, but not for polymorphic ones, like `toDyn id`. 1. E.g. I'd love to write very high level APIs that are able to take optional and named parameters. Yes, I can do something like that with defining ADTs and making `Default` instances for them, but it's more of a pain than in JS. 1. And in the meantime `Map Text Dynamic` could work if only that was polymorphic. Oh, and I had high hopes for Bookkeeper, rawr, and similar extensible/ad-hoc/anonym record libraries, but it seems most that I've tried have very uncomfortable limitations, like 8 fields max. Although I do concur that static type checking would be very nice here too, but what I'm trying to point out is that in JS it is trivial to have `Map Text PolyDynamic`, in Haskell such is not yet possible. Row type polymorphism might help here. If/when that gets added to GHC. `generic-lens` might help somewhat, but I've only heard about it recently and I haven't gotten around to try it yet. These come to mind at the moment. Although please keep in mind I am very aware of many limitations and disadvantages of using JS instead of HS, but since Tysonzero asked me I wrote about the other way around: What I miss from JS when I write HS.