TIL of visual block mode. It's something I will definitely use.
_TIL of visual_ _Block mode. It's something I will_ _Definitely use._ &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ^- ^quick_dudley ------------------------------ ^^I'm ^^a ^^bot ^^made ^^by ^^/u/Eight1911. ^^I ^^detect ^^haiku.
My emacs life works better if I use one emacs process for everything: - Emacs is kind of slow to start up, especially if you use a big crufty init.el, or spacemacs. - If you have two emacs (emacs-es?), you have file ownership conflicts. I use org-mode, and I often want to check my tasks list. With multiple processes I have to remember which emacs owns my task list, or deal with annoying dialogues, or be better about instantly saving than I am. - Context-switches should be as cheap as possible. Switching workspaces in XMonad is pretty cheap! Hitting Space b b and picking the buffer I want in Helm is cheaper. This sort of thing is why emacsclient was invented, so I'm not the only person who works this way. And of course the short version is that this is the way I work now, and I don't want to change --- at least not without a compelling reason. Which I'm open to hearing, but bear in mind that I'm just an end-user: what do I care about code quality? :-)
You missed a great opportunity to call this "Launch You A Haskell Group for Great Good"
Why is that difficult to understand? If you see the advantages of multiple tabs open in your favorite browser, then you should be able to see the advantages of having multiple GHCI sessions. 
I was just thinking in the context of an editor. I guess it just doesn't match up with my typical workflow. ¯\\\_(ツ)_/¯
 Hi! This is just a friendly reminder letting you know that you should type the shrug emote with three backslashes to format it correctly: Enter this - ¯\\\\\\\_(ツ)_/¯ And it appears like this - ¯\\\_(ツ)_/¯ --- *^If ^the ^formatting ^is ^broke, ^or ^you ^think ^OP ^got ^the ^shrug ^correct, ^please ^see [^this ^thread](https://www.reddit.com/r/john_yukis_bots/comments/6tr5vq/u_you_dropped_this_a_shrug_fixing_bot/)^.* ***^Commands:*** *^!ignoreme, ^!explain* 
Emacs is much more than an editor as you can use it for ghci sessions, bash sessions, cli sessions to your fave DB, etc. You can play chess and all sorts of things that go beyond an editor. It allows you work and play so that your hands never have to leave the keyboard.
Yes, thank you -- I'm an emacs user.
Righto, it makes your original question more surprising then.
Announcing Squeal, a new Haskell database library. Please check it out and let me know what you think. I'm interested in questions and critiques.
Examples of usage in any one of the page you linked, the repo, the README or in the docs would make it much easier to grok.
Please check out this [example](https://hackage.haskell.org/package/squeal-postgresql-0.1.1.2/docs/Squeal-PostgreSQL.html) in the docs.
I've started learning a bit of Haskell recently and I'm not really sure what exactly the benefits of having a study group are (not trying to be rude here, just curious): couple of guesses -- (0) you have friends studying together so you can bounce ideas off each other (kinda' like a course) and (1) you have a fixed pace so you don't slack off much unlike say self-study (again like a course) ... are those the main benefits?
I think it uses Flash, that might be why it might not have worked on mobile.
So does that mean I will not be able to work on more than one project at a time in emacs? 
data point: I had found those examples already, so they might not be as hard to find as the other data point might make it seem :)
I've added an example to the README. Good idea.
You could use the Nix style recursive modules. A module is a function `module -&gt; module` that you apply to `fix`. It uses its argument to refer to final versions of the functions. When you want to extend the module: type Module a = a -&gt; a type Extension a = a -&gt; a -&gt; a extend :: Module a -&gt; Extension a -&gt; Module a extend f g a = g a (f a) The idea here being that the extension `g` gets to see what `f` thought the module should be, and what the final extended version will be, so it can produce the new version (which may end up being the final version) http://elvishjerricco.github.io/2017/04/01/nix-style-configs-in-haskell.html
I've only read from your EDIT, but what you want is for your function to be _productive_ another good term is _guarded recursion_. http://blog.sigfpe.com/2007/07/data-and-codata.html?m=1
Any idea of the performance compared with raw sql? My instinct is that it should be nearly free since it looks like we're just building bytestrings underneath
Regardless, I can assure you they are easier to find now :) As a related data point: For better or worse, the place I typically look for examples on hackage is in the yellow box at the bottom of the primary page. That's why I didn't find the already existing examples at first glance.
That's my instinct as well. All the phantom bytestring types have `NFData` instances as well. If anything gums up performance a bit it will be the use of generics. I don't have any benchmarks yet. That'd make for an excellent contribution!
I'm not sure how to update that yellow box. It seems to have an old README in it.
Pretty much a Scotty clone, built it mostly for my own education/enjoyment, but the code is simple enough and short enough (~300 lines for the whole thing without docs/imports) that it should be a decent learning tool. It uses a ToResponse typeclass, so you can return whatever type you want from handlers (with an instance) and Firefly will figure out the response for you. Honestly you should probably just use Scotty, but it was fun to build; take a look if you're so inclined!
Terrific, I think this is what I was looking for! I'll give it another shot tomorrow. Thanks! EDIT: OK, playing around with a toy function, it seems that guarded recursion doesn't work in the IO monad. This terminates after grabbing 40 elements: apply i = (:) i (apply (i - 1)) x = take 40 (apply 10) this runs forever: apply i = (:) i &lt;$&gt; (apply (i - 1)) x &lt;- take 40 &lt;$&gt; (apply 10) Is this a fundamental limitation?
Awesome, thanks. This looks very cool and I will definitely check it out over the weekend.
`llvm-hs` was forked from `llvm-general` to un-stick some development issues. Administrative grease applied to a great project, and /u/cocreature has stepped up in a big way to keep things moving forward, not backward; upward, not forward; and always twirling, twirling, twirling! (It's just a more rapid development pace.)
This is awesome! Are you going to do the other chapters?
As someone who uses python daily and has (barely) dabbled in Haskell, I think a big part is along the lines of what /u/outlacedev says. Python has a ton of high-level libraries for science, data munging, machine learning, etc. As a scientist, I know dozens of colleagues who use routinely use python in their laboratories and not a single one who uses Haskell. A big part of this is due to a few glue libraries like numpy and pandas. On top of that, I think Haskell code has an issue with readability for newcomers. The gratuitous use of operators, single character variable names, point-free style, etc, combined with the overall high level of abstraction in Haskell often makes it really hard to understand what's going on, at least in my experience. It's both terse and elegant once you grok it, but can seem deliberately inscrutable to a new comer.
I don't know. I've never published a package before but I assumed that it updated when you pushed a new version.
Hi, I'm the author of data-diverse, and this is how you could do this with 'Many', which doesn't require Labels. https://github.com/louispan/data-diverse/blob/master/test/Data/Diverse/ManySpec.hs#L91
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [louispan/data-diverse/.../**ManySpec.hs#L91** (master → d2a3793)](https://github.com/louispan/data-diverse/blob/d2a3793d1b1a1a4fae32c344c7f99576cd01f317/test/Data/Diverse/ManySpec.hs#L91) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dmpojke.)^.
I believe this is the `README.md` file from the `.tar.gz` which gets created by the `cabal sdist` command when you upload your package to hackage, but it only gets included if your `.cabal` file lists your `README.md` file in its `extra-source-files` section.
If someone could explain what i'm doing wrong with my code I would really appreciate it. I keep getting a non-exhaustive pattern error in my code. I think I have every case covered except for an empty list which I do not know how to program in. The code is supposed to take in an int and a list and "drop" the first "n" items from the front of the list. (obviously I need to do this without using the built in "drop" function, which I have already hidden) i.e. drop 2 [1,2,3,4,5] =&gt; [3,4,5] drop :: Int -&gt; [x] -&gt; [x]; drop n [x] | n &gt; (length [x]) = [] | otherwise = drop (n-1) (tail [x]) 
I'm excited to see if reflex mobile will help much. People love app development and being able to build cross platform high performance apps in Haskell might be pretty killer.
Generally I'd agree with this but the book covers troubleshooting and debugging in not as much detail as I'd like. Learning the techniques of equational reasoning, type holes, and other methods aren't really covered at all. To compound on that, less than half of the exercises have test cases included so you have to either "know" how it behaves, know what prelude function you're reimplementing (if you are), or hope the implementation was obvious and trivial enough to just get it right. The only solutions out there are what other students have on their public git repos and are often incomplete, not always correct, etc... Plus that doesn't really help you learn the same way. It's by far the best beginner Haskell resource out there, but it's by no means perfect and even a partial checker would likely help a lot in the absence of a mentor to help you work through the material.
&gt; Ctrl isn't though... It used to be. Highly recommend mapping it back there. http://www.economyofeffort.com/media/images/sun-keyboard.png
Not a didactic device. A mistake, in my opinion, but actually there.
Well ... no, not really. `runRW#` isn't inlined until Core Prep, which happens shortly before code generation. So core-to-core optimizations don't get to take advantage of that inlining at all. Only the generally more limited STG, CMM, and backends do. The whole thing is rather sad, IMO; `IO` should never have been defined the way it is. A graph reduction machine is a terrible way to do `IO`. And describing `unsafeDupablePerformIO` as "safe" seems a bit of a stretch! It remains substantially less safe than `unsafePerformIO`.
The problem here is that when you write: drop n [x] You're pattern matching any number n, and then a list **containing exactly one element, x**. If you wanted to pattern match lists containing exactly two elements, you could use [x,y]. Simply replacing [x] with xs will fix that issue. xs isn't special, it's just a variable name. Some other issues you might want to think about: n and length decrease at the same rate, so the first guard branch will never trigger if it doesn't the first time. This means that either it will return [] immediately or never terminate. 
Good bot
Thank you fgaz\_ for voting on haikubot-1911. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://goodbot-badbot.herokuapp.com/). *** ^^Even ^^if ^^I ^^don't ^^reply ^^to ^^your ^^comment, ^^I'm ^^still ^^listening ^^for ^^votes. ^^Check ^^the ^^webpage ^^to ^^see ^^if ^^your ^^vote ^^registered!
Try Haskell first, and detour via Elm if you bounce off. I know a number of people who have bootstrapped into FP via Elm, despite bouncing off Haskell.
I'm not sure I understand the question. Could you clarify ?
I am also trying to create benchmarks for generics-sop, and to work on optimising it better. If you happen to do more work on this, please let me know. I'm sure your benchmarks would be interesting for me as well.
I actually thought about it. I opted out :-)
Those are, in my mind, certainly among the main benefits. But you can do it on your own, too. Given the number of people who ask questions about the exercises daily, I'd say the group approach is worth at least considering for most learners. But plenty of people have gone through the book on their own, some in a quite rapid amount of time, too. YMMV.
I like your project name! 
&gt; GitHub pull requests While I agree with your other points, I think this is also a terrible metric, that is culture and language dependent.
A matter of degrees; `accursedUnutterablePerformIO` was almost unusable, `runRW#`-d code can be hand optimized to desired speed (and I expect it to often be, in practice). The new thing is clearly safer and faster than the old, though less than optimal as language feature.
It might be wise to choose something else than C-b, since that is the main control character of tmux, the successor of screen.
&gt; A capitalist act between consenting adults is a beautiful thing. I propose a "wealth of consent" then. Due to differences in power, there are serious concerns about whether the underwealthy can truly give consent.
Very few db modules seem to take PSQL enums into consideration, is that something you're thinking about? The enum type that is... CREATE TYPE blah AS ENUM ('foo', 'bar', 'baz')
Shouldn't `l: myfunctions.hs` be `:l myfunctions.hs`? I also don't find it clear that this command should be executed in ghci (because ghci is not mentioned before it).
Right, I mapped `C-s` as a prefix in tmux, precisely because I wasn't happy with it interfering with cursor movement in shell. And `C-s` (freeze terminal) is something I only use by accident, so it actually was a double improvement.
For example, VS Code emulates not just Vim, but with multicursors and some popular plugins: https://github.com/VSCodeVim/Vim#emulated-plugins I don't know if Spacemacs or Atom or any other editor also does some customization in the same manner, so I'm asking.
I would be cautious because you can lose type safety. I recently changed a type like data MyRecord = MyRecord {quantity :: Int} deriving (Show) to newtype Quantity = Quantity Int deriving (Show) data MyRecord = MyRecord {quantity :: Quantity} deriving (Show) in the hopes of achieving more type safety by making it impossible to mix up Int values with different meaning. I forgot to define my own Show instance for Quantity. As a result, the dropdown fields in my web app had values like "Quantity 1", "Quantity 2", ... instead of 1,2,... Bug made it to production. Since then I'm careful with deriving Show.
Spacemacs makes an entire tree of useful commands, all beginning with `&lt;Space&gt;`, for example * Open magit-status: `&lt;Space&gt; g s` * Inline git-blame `&lt;Space&gt; g b` * Open a 2 window layout: `&lt;Space&gt; w 2` * Open something from a projectile project `&lt;Space&gt; p p` 
One thing that I like a lot about spacemacs is that it has a menu-like system when pressing `space`. So instead of `:w`, you could type `&lt;SPACE&gt; f s` (in this case it is not shorter, but for me it is easier to type because `:` requires pressing Shift on my keyboard). Also, you get an interactive help as soon as you press `&lt;SPACE&gt;` (it'll show you all possible sub-menus in the bottom bar). So you don't need to know all commands by heart, and you can access most useful commands through this system. (Want to toggle gold-ratio mode? `&lt;SPACE&gt; t g` and so on). I wish there was something similar for vim. 
This probably works a lot better with unfold/destroy fusion ala vector instead of the build/fold rule fusion that lists use in haskell. Alternatively we could extend build with append build :: (forall r. (a -&gt; r -&gt; r) -&gt; r -&gt; (r -&gt; r -&gt; r) -&gt; r) -&gt; [a] and parallelize steps independently. Java streams use this approach but it makes the non-parallel case more annoying. Unfold/destroy fusion essentially rewrites the pipeline into one huge loop so it should be enough to parallelize your final consumer. Data parallel haskell should be able to do this for free, don't know much about dph but I saw this mentioned [here](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/07/haskell-beats-C.pdf).
Good comment. I think failing to distinguish notes in different octaves is also a problem, because it stops you from talking about chord inversions. Might be better to use a pair of integers: signed number of scale steps from middle C and signed alteration.
You should checkout [Myrtle Software](https://www.myrtlesoftware.com), they are based in Cambridge UK. I've done two internships with them and really enjoyed it! They use Haskell to create hardware solutions to vision/AI problems. :-D
it seems to be a really cool project, but one thing that really bums me out is the amount of syntactic noise. Especially `:* Nil` is really distracting because the rest of the code is very dense. I would guess that i can accept it in other projects or languages because due to constant noise so my brain learns to ignore it. I know there is probably no way around it right now, but a solution for a more flexible List-Syntax would really benefit the community i think.
Where are you based, and how far abroad are you willing to go?
So I'm trying to use your method, but I'm not familiar with how to use Template Haskell. Do you have any advice on how I should use this? So I have a vector `myvector`. Do I just run `[| bake myvector|]` and then `myvector` has been precomputed?
&gt; Due to differences in power, there are serious concerns about whether the underwealthy can truly give consent. &lt;off-topic&gt; Wish this wasn't a haskell thread... there is a big big problem with a definition of consent that depends on wealth or difference between value of different courses of actions the actors are being subjected to. Ignoring that such definition is pretty much arbitrary (if you define it on absence-of-coercion, it's not easy either, but the arbitrariness is much lower), you'll ultimately end up with a conclusion that we should e.g. treat under-wealthy as unable to assume liability (the fact they are under-wealthy would effectively strip them of the right to sign any contract) or that e.g. the liability of thieves/corrupted politicians is inversely proportional to the assumed benefits they would obtain from the crime. To get back to Haskellish ideas, it seems to me that we try to keep our definitions clear in order to comunicate clearly the message. The very poor are often indeed in dire situations, however I think that there are multitudes of ways how to describe the sitution or possibly modify the legal arrangement without needing to redefine what 'consent' means; that would be rather *impure* solution to describing the problem and we love the *pure* functions, don't we? ;) &lt;/off-topic&gt;
Came here to say the exact same thing.
&lt;off-topic&gt; I have no idea how this discussion came about, but it is clearly a deficiency in most companies acts that companies have limited liability :-). A corporation cannot possibly consent to paying damages to cover the cost of environmental effects as it likely wouldn't be profitable. Still they sign contracts, and they go bankrupt (or live on through bribes/subsidies). For some reason the investors are not liable, but the company can give consent. The ultimate price to pay is typically defined as capital punishment, but in the bible God punishes for up to 4 generations. That is, God considers consent to be given on behalf of your future descendants. Given these two cases, I can't see how consent is binary. It's always relative to the punishment. This does not lead to "under-wealthy as unable to assume liability". But it does lead to rejecting limited liability corporations from being able to give consent in certain cases. &lt;/off-topic&gt;
Yeah, it'd be great if there was a list desugaring extension that let you replace standard nil and cons. Unfortunatley OverloadedLists uses a different mechanism.
You're converting in the wrong direction: `[|...|]` turns code into its AST, but `bake` returns a `Q Exp`, which is the type TemplateHaskell uses to construct ASTs. To splice an AST into your code, you need to use `$(...)` instead. So while I don't quite understand what `bake` does, based on the types it looks like you would use it like this: {-# LANGUAGE TemplateHaskell #-} import qualified Data.Vector.Storable as VS myVector :: VS.Vector Int myVector = $(bake ((VS.fromList [1,2,3]) :: VS.Vector Int)) *edit*: I was curious about how `bake` worked, so I googled [`StringPrimL`](https://hackage.haskell.org/package/template-haskell-2.12.0.0/docs/Language-Haskell-TH-Syntax.html#v:StringPrimL), and it almost looks like `StringPrimL` was added to TemplateHaskell just so that `bake` could be written! My example code above looked suspicious to me because the result of `bake` is some expression which is then assigned to `myVector`, and so whatever that expression is, it's going to be evaluated at runtime, not at compile time. It turns out the expression is basically a String literal, casted into a Vector. The AST representation of the Haskell literal `"hello"` is `litE (StringL "hello")`, so `$(litE (StringL "hello")) ++ " world"` gets compiled to `"hello" ++ " world"`. There are a few other constructors like IntegerL for numeric literals, etc. But instead of using any of the normal literals, `bake` uses `litE (StringPrimL "hello")`, which uses a secret kind of string literal which I didn't know was supported, and I don't know what the surface syntax for such a literal would even look like (`#"hello"#`?): it's a C-style string, so it's a single block of bytes, not a Haskell data structure, and it's probably stored as-is in the executable. Exactly what is needed!
Yes, I've been thinking about it. There's the ideal solution and a stopgap. Ideally, when you do a `CREATE TYPE` it would change your schema so that you could reference the type, but this would require a much more sophisticated schema kind. For now, there's an escape hatch called `UnsafePGType` that you can use for this, along with using `UnsafeDefinition` to create the type and the `enum` binary encoding/decoding from 'postgresql-binary'. createBlah :: Definition schema schema createBlah = UnsafeDefinition "CREATE TYPE blah AS ENUM ('Foo', 'Bar', 'Baz')" type PGblah = UnsafePGType "blah" data Blah = Foo | Bar | Baz deriving (Eq,Show,Read) instance FromValue PGBlah Blah where fromValue _ = enum (readMaybe . unpack) blah :: TypeExpression ('Required ('Null PGblah)) blah = UnsafeTypeExpression "blah" foo, bar, baz :: Expression tables groups params ('Required (nullity PGBlah)) foo = UnsafeExpression "Foo" bar = UnsafeExpression "Bar" baz = UnsafeExpression "Baz"
Also, there was a research group called galois that looked interesting. 
Why is it a mistake? How would you represent IO instead?
Funny, my code compiles with the `[| |]` brakets, though I guess it's just not doing anything? Thanks for the help. Edit: I just saw your edit. Seems like there's a lot going on under the hood. You say that you expected the code to be only be used at runtime, but it's actually doing something funny to get it to work at compile time? Edit2: My vector has a `Vector Word8` type. I assume this is not a problem with this `bake` function.
sure thing!
I've updated it a bit and added an example here: https://github.com/chpatrick/baked-vector/blob/master/test/Spec.hs
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [chpatrick/baked-vector/.../**Spec.hs** (master → 4a3efb2)](https://github.com/chpatrick/baked-vector/blob/4a3efb2645da2314a2164454716e838b3814eb93/test/Spec.hs) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dmqc1z3.)^.
Thank you for your help. In another comment the syntax was `$(bake vector)` and in your sample code it is `$$(bake vector)`. Is there a difference between the two?
I'll just repeat what's on repeat here: map caps lock to ctrl :). There is rarely a need for it [1], but it is placed on a very expensive place of keyboard real estate -- in very comfortable reach with left pinky. As an added bonus you'll find using bash like a boss in no time. [1] I do acknowledge that there are situations where it's used more often (SQL comes to mind), then either find another way (have a shortcut for "uppercase last word"), or pay the bill of selecting and uppercasing the text, or just hold down shift.
I find [kakoune](http://kakoune.org) pretty solid improvement of vim.
Maybe to transfer it to a separate repository so people can fix typos and add useful information? EDIT: Oh, I see "Created 5 years ago"
My employer is planning an internship cohort next summer. The work will likely focus on our internal tools and massive prelude, but depending on the scope we may have options to work directly with a client. Full details will be announced officially around newyears.
In the updated version I use the newer typed expressions feature, which must be spliced with `$$(...)`.
I think adding sql quasiquoters would go a long way here, so we can add `inline-sql` to our list along with r, c, and java. I'm not sure if there's a technical barrier to doing so without just trying it, but it's something I'd be happy to contribute if it seems like the best way. Although it's already quite readable considering the amount of power given.
&gt; Is this a fundamental limitation? ah, yes sort of. Consider the concrete: apply :: Int -&gt; Maybe [Int] apply i = (:) i &lt;$&gt; (apply (i - 1)) We can't determine whether the right hand side will be a `Just ...` or `Nothing` without evaluating the infinite recursion fully. This is just the mechanics of bind. Streaming libraries like pipes, streaming, conduit, io-streams, etc. all solve this problem (along with a couple others) of interleaving effects with producing and consuming.
Quasiquoters would be a great contribution! Then folks could write their SQL as (a subset of) SQL and use Squeal to type it.
&gt; Funny, my code compiles with the `[| |]` brakets, though I guess it's just not doing anything? That's weird, what's around the brackets? The output of `bake` is the AST of a Vector expression, which should neither work at the top-level nor as a value of type `Vector Word8`. Example using String instead of Vector for simplicity: {-# LANGUAGE TemplateHaskell #-} import Language.Haskell.TH -- Couldn't match type 'Exp' with '[Dec]' [|pure $ litE $ StringL "hello" |] -- Couldn't match type 'Q Exp' with '[Char]' myString :: String myString = [|pure $ litE $ StringL "hello" |] &gt; You say that you expected the code to be only be used at runtime, but it's actually doing something funny to get it to work at compile time? I'm saying that TemplateHaskell produces Haskell code, and this Haskell code is executed at runtime, so using TemplateHaskell might not in itself be sufficient to solve your problem. It can be used to compile an expression like `Vector.fromList [1,2,3] &lt;&gt; Vector.fromList [4,5,6]` at compile time, but the result can't be an already-allocated vector which will magically be available at runtime, it has to be a Haskell expression computing the same result in fewer steps, such as `Vector.fromList [1,2,3,4,5,6]`. This expression would still be evaluated at runtime, which may or may not be good enough for your purpose. `bake` is going further by taking advantage of the fact that a Vector is stored as a sequence of bytes. It stores those bytes in the executable via a C string, and then the runtime expression is simply a cast from that C string to a Vector. It would not have worked with something like a Tree or a List because of the internal pointers. &gt; My vector has a `Vector Word8` type. I assume this is not a problem with this bake function. Word8 is Storable and Typeable, so indeed, not a problem.
I don't recall implying that this was not the case. But it's valuable all the same. In the same sense that newtypes are valuable even if they are just a compile-time convention.
But do consider applying for an "off-season" internship. Our summer internship is extremely popular, and we get way more solid applicants than we can accept. I think our acceptance rate was under 1% this year. [Details on the website.](https://galois.com/careers/software-engineer-intern/)
I'm not quite at the level of some folks here, but I think that there is are alternative disciplines to monad transformers. Certainly we've seen a few people try. I'm aware the current names associated with phantom types in purescript are an accident of history, but I'm not sure why they couldn't become something more. 
Excuse my noob but what is "PL"? 
Programming Languages 
Programming languages. And PLT is programming languages theory.
&gt; Haskell is very strong in high-concurrency applications, but how much is that growing ? A lot, but it seems the growth is swallowed mostly by Go and perhaps node.js.
I so much wish Haskell had [Idris syntax rules](http://docs.idris-lang.org/en/latest/tutorial/syntax.html).
I go one step further. I map both control and escape to the caps key. When I tap the key, it's escape; when I chord the key, it's control. Very elegant and works perfectly for me
Outperforming existing antenna routing production code by 20-30%, thanks to fusion, is a great result (49m 54s)! Given that it wasn't enough to persuade Ericsson to migrate to Feldspar for other products, one wonders why. It's either that 1. 30% **speedup is not enough** (what would have been enough?), or 2. that they **trust** the correctness of their existing C code and their C compiler more than their Feldspar code, or the Feldspar implementation, or GHC. 3. **Support**, because funding for an academic project like Feldspar is never guaranteed. It'd be interesting to know the answer.
Exactly. I think people in Haskell forget after a while how many concepts they had to learn initially, and the number of things they had to unlearn. The worst thing that can happen is to have someone who is eager to learn Haskell, alone, struggling, and feeling like the compiler is the enemy. My hope is that a little time with Elm will give people a taste of what getting further down the road with Haskell will feel like, to provide motivation and focus on endurance through the Haskell Book.
I prefer C-[ myself since it works on any system and any program.
That won't kind-check though :)
Right, needs parens
You can, and it's easy, if non-obvious: a :: Num a =&gt; a a = 5 where _ = a :: Int _ = a :: Double Getting it into the docs is another matter, although shouldn't be difficult... Edited to add: Actually, the `where` is optional - they could also live at the top level. Not sure which I prefer, organizationally.
In other words, once it compiles, it works, you don't need to make a PR anymore :-D
You could name them `_`.
Well, pretty much every cool vim plugins have their equivalent in Emacs , so spacemacs just add them with their own key map. From the top of my head spacemacs gives you out of the box (from the top of my head) Vim-surround Gundo Vim-impeared Align Nerd-commenter Nerd-tree Magit (git front end , different from fugitive but i actually prefer it) Completion Snippets Multi edit : Via an evil plugin Helm-grep: do a a grep (across all project file) like and modify the result (in the equivalent of the quick fix window) Using yasnippet auto template Cltr-p (finding files, most recent , current project) Ack again etc integration Lock-face is like `match` but better Cool stuff which I don't know if the vim equivalent Eyebrow allow to undo window configuration Projectile : do things within current (git) project And much more (as you might guess , I think spacemacs is fantastic).
I agree with Tom W Bell's conception of consent in [The Scale of Consent](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1322180)
I could just never get used to that no matter how hard I tried ¯\\\_(ツ)\_/¯
Kind of annoyed that there are more options to consider now (:... but thanks!
The types remind me of a [Traversal](http://hackage.haskell.org/package/lens-4.15.4/docs/Control-Lens-Traversal.html): weaveEffect :: (Monad t, Traversable t) =&gt; Traversal (t a) (t b) a (t b) weaveEffect f tx = join &lt;$&gt; traverse f tx But since the implementation does not follow the laws (it does not leave the same number of elements as a candidate for subsequent Traversals), I doubt we'll find an existing optic within lens, so that's a dead end for finding its "proper" name.
Yikes, 1% is so low. Plus I would think that Galois would attract a certain kind of applicant, which makes it seem even more dreary ... By "off-season", do you mean in the middle of the semester? The linked page doesn't mention that term.
Is there an alternative way to define `IO` that you have in mind? Got any papers?
I don't think it has a name, it's just `fmap join . sequenceA . fmap f` Although looks related to `=&lt;&lt;&lt;` from the [`bound`](http://hackage.haskell.org/package/bound-2.0.1/docs/Bound.html#v:-62--62--62--61-) library. class Bound t where (&gt;&gt;&gt;=) :: Monad f =&gt; t f a -&gt; (a -&gt; f c) -&gt; t f c
You don't like overhyped evangelism?!
Ah, that makes sense, the Maybe example is very clear. Thanks!
I'm more interested in using this sort of thing in a mentor - student sort of approach because I'd like it if we had more FP in my city and my University; this seems like a good way to go about it.
This doesn't have a name, but if it did, I would call it an `concatMapA`, or rather, an overgeneralized version of such. Let me explain. It's weird how you use both the `Traversable` and `Monad` instances of `t`. Traversable operations are in some form "structure-preserving", but the monadic join destroys the structural guarantees because it smashes two layers together. Since you're not preserving the structure, it seems likely that you are just trying to iterate over things and run effects as you go, while also collecting a sequence of the results. Does the output really need to be `f (t b)`, or would `f [b]` be an acceptable output? If so, then you could loosen the constraint from Monad &amp; Traversable to just Foldable. The first arg's output type and the second arg's type don't even have to be the same Foldable. weaveEffect :: (Applicative f, Foldable t, Foldable t') =&gt; (a -&gt; f (t b)) -&gt; (t' a) -&gt; f [b] weaveEffect f as = concat &lt;$&gt; intermediate where intermediate = for (toList as) (fmap toList . f) concat :: Foldable t =&gt; t [a] -&gt; [a] toList :: Foldable t =&gt; t a -&gt; [a] for :: (Applicative f, Traversable t) =&gt; t a -&gt; (a -&gt; f b) -&gt; f (t b) Let's simplify the Foldables to just lists, and expect that the caller is capable of using `toList` appropriately. weaveEffect :: (Applicative f) =&gt; (a -&gt; f [b]) -&gt; [a] -&gt; f [b] weaveEffect f as = concat &lt;$&gt; intermediate where intermediate = for as f Another spelling of `for` is `flip mapM` (though mapM has tighter constraints, for legacy reasons). weaveEffect f as = concat &lt;$&gt; mapM f as Writing it this way makes it pretty obvious that all you are doing is a side-effecting concatMap. But going back to the `for` implementation, you only need an Applicative constraint, rather than a Monad constraint, hence why I'd call this `concatMapA`.
Looks like a general-traversable monadic concatMap to me, so concatMapM?
One place this might come up is if you have a type of expressions in some language. It's `Traversable` so you can replace variables effectfully, and it's monadic so you can substitute subexpressions for variables. This function does both at the same time, so in that context, I might call it something like `substituteA` (`A` for `Applicative`). Note: I don't think you need `f` to be `Traversable`.
&gt; There are just too many un-researched questions with records right now. If you mean this seriously and it's not just the usual "maintain the status quo at any cost" syndrome: If you really mean what you just said, I think you should be advocating for removing record syntax completely from Haskell. The current situation is actively harmful.
I know this is old, but I just watched part 1 and I somehow missed there's a part two. Thank you for posting this.
As long as we’re generalising, I think something like this (using `Monoid`) is a bit nicer: foldMapM :: (Applicative f, Traversable t, Monoid m) =&gt; (a -&gt; f m) -&gt; t a -&gt; f m foldMapM f = fmap fold . traverse f I’ve written various incarnations of this in the past, usually calling it something like `mconcatMapM`. 
I'm in Western Massachusetts in the US. I have some family stuff so I would prefer to stay in states but it's only going to be for the summer so I would be willing to go anywhere.
Hi everyone, I just finished my thesis, and I was told I should put a link to it here. I hope someone else finds this useful and/or enjoyable. Abstract: Property discovery is the process of discovering properties of code via automated testing. It has the potential to be a great tool for a practical approach to software correctness. Unfortunately current methods remain infeasible because of the immense search space. We contribute a new approach to taming the complexity of a state-of-the-art generate and test algorithm. Our approach runs this algorithm several times with carefully chosen inputs of smaller size: signature inference. We implement this approach in a new tool called EasySpec. The results suggest that this approach is several orders of magnitude faster, fast enough to be practical, and produces similar results. EDIT: Feedback is very welcome!
Any way I can board any of these trains early? What are you looking for in candidates? 
`fmap join . traverse f` is pretty common pattern, but doesn't appear to be special enough to have a name.
Well, if you fancy a trip to Australia, I know both Ambiata and Arbor Networks (just the Sydney office) use Haskell.
You can compose IO from a chain of smaller IO actions. These actions will be executed exactly once and in the correct order when the larger action is executed. The unsafe_ functions gradually remove these guarantees - unsafeInterleaveIO executes at most once, potentially at any time after the call - unsafePerformIO executes at most once and at any time but doesn't require an IO context - unsafeDupablePerformIO may start execution any number of times so it isn't resource safe (in the presence of threading) but doesn't require locking - unsafeInlinePerformIO inlines so you save a call and the standard assortment of optimizations can be applied. This basically means that the only safe thing to do is reading from memory. For instance malloc calls might be floated out by full laziness and shared which is ^really ^very ^bad™
This may be a good time to mention that I'm looking for contributors to my general purpose programming language, based on something roughly similar to simply-typed lambda calculus. I just hired a friend to work on it part-time while he looks for another job, but he's new to Haskell and I'm not sure how much he'll actually contribute. If I can find other people who are decent with Haskell and excited by the idea of trying to build a general purpose programming language where all expressions terminate, I may be willing to pay them as well. https://github.com/sfultong/stand-in-language
Whoa, those are great. Surely this could be a ghc feature request?
 -- join :: t (t b) -&gt; t b join ttb = ttb &gt;&gt;= (\tb -&gt; tb) That's just `join` from `Control.Monad`. You can import it instead. In slightly more idiomatic Haskell (and writing our function in a pointfree style): weaveEffect f = fmap join . traverse f
Oh cool. Previously unsafePerformIO was NOINLINE, right?
With super record, the various lensing libraries and default (not really) record syntax, what is the best way to use records at the moment (especially for people used to syntax like C++/java)?
Lenses have nothing to do with records problem though. They do not provide solution for creating multiple records with same field names in the same module. 
Australia is definitely on my bucket list so I will check those out. Thanks for the heads up!
For me, the record problem is only partly about name overlap. It's also about the awkwardness of updating fields inside nested records without having to write functions for every usecase. I consider lenses to be strongly related to the record problem as any solution will need to work well with lenses.
Awesome, thanks. I'll be digging into this next week!
Yes they do. `makeFields` does exactly that. 
But this doesn't help with that really, does it? Everyone's (roughly) at the same level of confusion/expertise due to self-selection for the study group, don't you think?
And when you do manage to formulate a good SO question it ends up being a duplicate of a poorly worded and confusing question.
Well ideally you'd have one expert putting on the studying group and guiding we beginners through the group, pushing them, answering questions, and making sure the Meetup doesn't die from lack of interest... All fun things.
[EasySpec](https://github.com/NorfairKing/easyspec) for the lazy
Oh, I didn't think about that. I was under the impression that it's supposed to be entirely a student run thing. But yeah, you're right -- that would definitely be more helpful.
When you write `[x]`, you probably mean `x`. There isn't any reason to surround it in brackets...you can match variables of all types with the same syntax. The fact that it isn't a syntax error is actually pretty crazy coincidence. For example, `foo x y z` will name the first argument `x`, the second argument `y`, and the second argument `z`. It doesn't matter if `x`, `y`, or `z` is a list or not. You don't need to surround a parameter in brackets just because it's a list.
On mobile, so I have yet to read it How does this relate to Liquid Types and similar code contracts?
I don't know if we're making a habit of it, but [LeapYear Technologies](https://leapyear.ai/) had an intern this past summer. We had a good experience, so I wouldn't be surprised if we repeated it next year.
How close can Haskell get to an interpreted language? Contrast these two scenarios in which I want to run the tests for my application (or play with them in the repl): * Python: I load the file in the repl; I run the tests. I might have had to manually download the dependencies, but that doesn't take too long. * Haskell: I tell `cabal` or `stack` to test; it fetches all the dependencies for them, spends forever compiling them, compiles my library (including modules that are not being tested), compiles every executable and test suite, then runs the tests; running `ghci` does a little better, but every package still needs to be compiled, and loading modules still takes on the order of seconds. To what extent are each of these possible or thought about or worked on? * Interpreting rather than compiling packages * Deferring type errors in all dependencies * Deferring module load until a symbol is actually necessary * Running a test suite through the interpreter rather than compiling and running the executable
Read Edward Kmett's blog post, "Free monads for less" for one approach. You may also want to look into "operational monads". The general idea is to have a Haskell (and Core) representation of IO based on something like a free monad. It's not particularly semantically beautiful compared to the world Conal wants, but it's *not wrong*. It separates the very different optimization needs of pure and impure code. It just never really made sense to do I/O (always!) as a side effect of graph reduction.
See my reply to /u/andrewthad.
I've always done all my testing in ghci. It takes a couple of seconds to load the modules the first time, but there are usually around 200 to 300 so it's understandable. It's important to load .o files, not .hs files, it gets slower when it has to bytecode compile all that stuff. :r is quick enough after that. I don't use cabal or stack, but I've used 'cabal test' for a project and I agree it seemed really slow and awkward.
No way. I never bothered to find out what PLT stands for. I only knew that it is for Scheme.
I think you can just delete the stack folder from your home directory. rm -rf $HOME/.stack Stack sometimes installs utilities and executables too (including the stack binary), typically in: `$HOME/.local/bin` So check there too. You should be aware that Arch changed the way their packages are compiled and distributed and now pretty much all haskell packages now include the full development ecosystem as dependencies. For example expand the [dependencies for stack](https://www.archlinux.org/packages/community/x86_64/stack/). I chose to install and maintain stack locally (apart from the Arch packages) into my home directory and just to install the compiled binaries through stack e.g. ghc, ghci etc. but you have to choose for yourself what to do. 
&gt; I consider lenses to be strongly related to the record problem as any solution will need to work well with lenses. Hear hear! In particular, we're not saying that /u/edwardkmett's entire `lens` library needs to be included in `base`, or whatever, but rather that at the bare minimum it should be easy to produce [van Laarhoven lenses](https://www.twanvl.nl/blog/haskell/cps-functional-references), which are [automatically compatible with the `lens` library](https://github.com/ekmett/lens/wiki/How-can-I-write-lenses-without-depending-on-lens%3F) and several other alternatives. The [Haskell Wiki page for `OverloadedLabels`](https://ghc.haskell.org/trac/ghc/wiki/Records/OverloadedRecordFields/OverloadedLabels) briefly mentions lenses, for example. They're are not a core feature of Haskell, but solutions certainly have to be compatible with them. 
I have read many of these threads and still don't "get `newtype`" because most of the discussion seems to be around *what* `newtype` is, not *why you'd use it over data/type*. Anyone care to elaborate? 
I don't think that it's necessary to have an expert run the group. When I did my group, we simply all went through the book together. I was in the same boat. What saves you from needing an expert is the diversity of experiences: some people caught on more rapidly to some things than others, and we all ended up just helping one another. The book serves pretty well as the only expert you need, in this sense. That doesn't mean you can't or shouldn't find a more experienced person to run your group, but it could be hard to find someone who wants to dedicate the time. And many people won't be able to find any such person, and so they will have no choice but to do it themselves and shouldn't feel discouraged from doing so. The book is designed for self-study anyway. This is just group self-study.
Author here: Liquid types are only vaguely related because we don't try to prove anything.
&gt; now include the full development ecosystem as dependencies. Except static libraries … so you have to fidget with compiler flags to get things to compile dynamically because GHC uses static linking by default.
you can check all places `stack` is using with `stack path` - on my system the relevant places only include stack-root: ~/.stack local-bin-path: ~/.local/bin so I would just `rm -rf ~/.stack` and then have a look in `~/.local/bin` and see if I had to remove some links/programs from there (probably just things like `hlint`, `stylish-haskell`, `cabal`, ...)
Very cool. Wonder if we could have a variant on this for graph databases (e. g. Neo4j) for type safe graph queries.. 
I agree with this. With Haskell I find myself spending less time wondering how others solve problems, and most of my time working on my own code to get it to where I want it to be. Also, because Haskell is so compact, with relatively short chunk of code achieving so much, I find it relatively easy to read the library code and work it out. There is less boilerplate I suppose is what I’m trying to say. Far greater capacity for expression. 
I hear you, but I think that once this unease passes, Haskell is the most direct intelligible language I’ve come across. I think the strong relationship to category theory yields this. The way I think about code naturally, which is a kind of flow of data through transformations, just seems so much more natural to me in Haskell than in any language I’ve used in anger over two decades or so.
[Tweag I/O](http://tweag.io) is always looking for interns. We've had interns both at the HQ in Paris and remote. Here are some of the projects interns have worked on: * [Typing Nix](http://www.tweag.io/posts/2017-05-23-typing-nix.html) * [Linear Types](https://m0ar.github.io/safe-streaming/) (through [HSoC](https://summer.haskell.org/)) Don't hesitate to get in touch at jobs@tweag.io ! We're looking forward to it :)
I’ve asked plenty of stupid questions. What is marvelous about the Haskell community is that the answers are invariably very deep. But that can be intimidating for beginners, who probably want a fix rather than week’s new material. 
+1 I’ve read most books in the context of providing recommended texts to students. For my money, this is the best of the lot for noobs. 
Cool, Van Larrhoven lenses seem great. I'd love to see them in base with some decent record operators etc. But I'm looking forward to a few breaking changes so I'm getting used to having to expect to wait.
Are you working on a `cabal` project, with a `.cabal` file? Perhaps you forgot to add `QuickCheck` as a dependency?
&gt;You should be aware that Arch changed the way their packages are compiled and distributed and now pretty much all haskell packages now include the full development ecosystem as dependencies. Could you point me to a discussion or announcement that outlines the reasons for this change? I noticed it, but I've been wondering why they did it, and what that means for the average user.
Since I'm really new to this it's a bit hard for me to answer, but all the files that are in use are .hs files. I can run the exact same code on the schools computer and it works flawlessly.
`-XNoTraditionalRecordSyntax`
Oh, what a coincidence, I see the line of sight model you've chosen is Permissive Field of View, one of the few algorithms originally implemented in LambdaHack as well (and not very popular among roguelike developers). Here are links to LambdaHack code: https://github.com/LambdaHack/LambdaHack/blob/v0.5.0.0/Game/LambdaHack/Server/Fov/Permissive.hs https://github.com/LambdaHack/LambdaHack/blob/v0.5.0.0/Game/LambdaHack/Server/Fov/Common.hs And here is a similar algorithm, Digital FOV, eventually chosen and heavily optimized for LambdaHack: https://github.com/LambdaHack/LambdaHack/blob/v0.6.1.0/Game/LambdaHack/Server/FovDigital.hs And the original design discussion: https://github.com/LambdaHack/LambdaHack/wiki/Fov-and-los Would you list your implementation on the roguebasin page? I think it's encouraging for potential Haskell game devs when they see multiple implementations in Haskell, especially with such a friendly and detailed tutorial as yours. http://www.roguebasin.com/index.php?title=Permissive_Field_of_View#Implementations
Can you be more specific about the commands you tried here? &gt; I've tried reinstalling the full version and the cabal command, but none have worked. How did you install QuickCheck? `cabal install QuickCheck`? How are you calling ghc?
I think the underlying cause was [a change to the compilation flags of gcc](https://www.reddit.com/r/archlinux/comments/6n5tkp/arch_now_enables_pie_and_ssp_by_default_in_gcc/) - contains a link to the arch-dev discussion about the flags. I think that meant that many haskell libraries can't be statically compiled into packages written with haskell. I don't think there was an announcement and it caught lots of people off-guard when, for example [pandoc suddenly required 700MB of haskell packages](https://www.reddit.com/r/archlinux/comments/6j20e9/pandoc_packaging_change/) when previously it was a binary only package. 
I don't understand all the details, I just heard people had problems with the change, for example with their xmonad configuration and projects that suddenly wouldn't compile any more. 
Would love to see more in-dept video series on this. [This ](https://www.youtube.com/watch?v=wjyiOXRuUdo) one is giving a good overview and I love it.
Interesting. I hadn't heard of Neo4j. Is it related at all to graphql?
STM and Web servers I see a lot of post saying like "STM is far and away the most underestimated feature of the Haskell runtime." On the other hand, If you have stateless servers deploying without downtime is "simple", the state is managed in the database. But if you wou use STM now you have statefull servers. So how this works with web servers and deploying? Is there something that I'm not seeing? 
Thats the command that I've tried. I installed it by downloading the full ghc(?) from the Haskell website
Did the command succeed, or are there error messages? If so, what do they say?
This is the message that I get: Warning: --root-cmd is no longer supported, see https://github.com/haskell/cabal/issues/3353 (if you didn't type --root-cmd, comment out root-cmd in your ~/.cabal/config file) Resolving dependencies... All the requested packages are already installed: QuickCheck-2.10.0.1 Use --reinstall if you want to reinstall anyway. 
&gt; Indexed monads Where are indexed monads used, exactly? (At first I thought [`Definition`](https://hackage.haskell.org/package/squeal-postgresql-0.1.1.2/docs/Squeal-PostgreSQL-Definition.html#t:Definition) was some sort of indexed category, but it is a regular category, which is nice!)
There is a type called `PQ` which is an Atkey indexed monad transformer. It is indexed by the schema, which may be changed when you run a `Definition`. Take a look at the [documentation here](http://hackage.haskell.org/package/squeal-postgresql-0.1.1.2/docs/Squeal-PostgreSQL-PQ.html#g:2).
Sorry I'm not sure how to continue troubleshooting this. Maybe someone else has an idea. It would be more efficient for someone to be there in person, ask your teacher or TAs for help.
Thanks for trying!
Let me try to unpack that. “Free monads for less” and operational are two different ways of encoding the Free Monad, and while the exact details matter for performance, they shouldn't matter for the semantics. So let’s see, instead of using a concrete Monad `State RealWorld`, you suggest using `Free Something`. Clearly, you’re not thinking of Get and Set as the constructors of Something. The type which would make the most sense here is an IO action, but `type IO = Free IO` would be circular. So you still need some way to represent atomic IO actions. Maybe a C call? -- @Args (a -&gt; b -&gt; c -&gt; IO r) r@ is isomorphic to @(a, b, c)@ data Args a b where Nil :: Args (IO r) r Cons :: a -&gt; Args b r -&gt; Args (a -&gt; b) r data IOAction a where CCall :: Args a r -&gt; FunPtr a -&gt; IOAction r data Freer f a where Pure :: a -&gt; Freer f a Bind :: f a -&gt; (a -&gt; Freer f b) -&gt; Freer f b type IO = Freer IOAction This might again look circular because of the IO in `Nil :: Args (IO r) r`, but that type is only used as a phantom type, both in Args and in FunPtr, so we’re fine. Now GHC is free to optimize and rearrange any of the arguments and even the FunPtrs themselves, but there’s no code which calls those FunPtrs, so no optimization will ever mess with the order in which they’re called. Instead, the program evaluates to a possibly infinite sequence of nested Bind constructors. We’re not done yet, because the program isn’t performing any of its IO side-effects. At this point with the `State RealWorld` representation, we would have a function from `RealWorld` to `((), RealWorld)`, but no value of type `RealWorld` to start the computation. So the compiler cheats, it knows that the value of type `RealWorld` will never be examined, so it can pass `undefined` or something and then force the `()` in order to cause all the IO to occur as a side-effect of that normalization. With the Bind constructors, normalizing doesn’t cause any IO, instead we need to write an interpreter which walks down the sequence of Binds and executes the C calls in order to perform the IO effects and to get the value required to evaluate the continuation. This interpreter would need to be built into the compiler, we can’t write it as a function of type `Freer IOAction a -&gt; IO a` because that would be circular. This would increase the complexity of the compiler, but now the compiler would know exactly when it is performing a side-effects and when it is evaluating pure code, so there might be less need for magic functions like `runRW#`. Is that more or less what you had in mind? If so, is there any way to implement `unsafePerformIO` and friends using that representation?
Do you have an automated test suite? You say you need to load the `.o` files, but this requires compiling first (and also interacts poorly with build tools, since they tend to put the outputs somewhere other than where `ghci` looks for them, IME); it seems like it would be slow if I change an underlying data structure and need to retest a high-level function, requiring basically a full recompile; even worse if the data definition is in another package. Thanks for sharing your experience!
Nice. Neovim is great for this sort of stuff. I wrote a ghcid plugin for it which I use daily: https://github.com/ndmitchell/ghcid/tree/master/plugins/nvim
Archlinux recently changed the default compiler flags which resulted in `stack setup` not finding an appropriate bindist of GHC. I have since submitted bindists for `8.2.1` and `8.0.2` so at least those should work. The archlinux packages shouldn’t really have any effect on the behavior of `stack setup` and installing Haskell packages globally comes with its own set of problems so I would highly recommend that you try to figure out why `stack setup` is failing. If you provide a bit more information, I might be able to help.
Very cool! It would be nice if the Intero features made it into ghci proper 
Thanks for this! I've been getting really sick of intero, it's slow and the repl is pretty out of date. This one's working great so far!
We do internships several (I think three?) times a year, but our summer ones are by far the most popular. At the moment the linked page has details on our winter/spring internships.
You say next release will be in December 2018. Did you mean 2017?
The way I understand it, graphql is a technology used to expose an API / data on a server (haven't used it myself yet)? Graph DBs on the other hand are a type of NoSQL database where you only have nodes that are connected with relations. Very handy when you work with highly interconnected data where the relations themselves are also very important. So they are different things, but I think you can have a graphql instance expose data from an underlying graph DB. In Haskell, there are already a few libraries for CRUD operations on graph DBs (e.g. https://hackage.haskell.org/package/haskell-neo4j-client); but they all work with raw strings. Would be cool if there was also a type safe library that could converted a query to a string, to be used together with those other libs. I'd do it myself, but I'm not skilled enough (yet) in haskell to do it. :)
Amazing work!
I *am* talking about things like `Get` and `Set`! Those are the (many) primops. Whereas an FFI call is a black box, a compiler knows *everything* about its primops, so it can apply specialized transformations to the `IO` values the program builds. The interpreter you speak of could be part of the RTS, or (as Kmett also describes) the compiler could eventually (late in the compilation process) switch to something more like what GHC does. None of this really gets away from the need for a magical `unsafeDupablePerformIO` function (a la `runRW#`), but it guarantees no one will perform unsafe `IO` *without* using that function. It's certainly always possible to offer such a thing.
There is some controversy over Van Laarhoven lenses vs. profunctor lenses. Each has its ups and downs. Profunctor lenses seem cleaner to me, but it's apparently rather trickier to make the indexed and non-indexed versions play well together. For now, I'm leaning toward the profunctor lens approach, but I don't think there's any kind of consensus on that.
Cool, glad you are enjoying it! :)
Oh, I thought about how ghcid could be integrated with neovim as well. There we go! Very neat!
Yeah, commands like **:type-at** and **:loc-at** would be very useful.
Is it really so much effort to understand `trifecta` to one that has some sort of understanding of `parsec`/`attoparsec`/`megaparsec`? 
The blog post says: &gt;We plan to make a new release of Cabal/cabal-install before the end of the year – that is, around December 2018. It was published today, so I think they meant dec 2017
&gt; PureScript has by-far the best record system in any language I've ever worked with. It is miles above Haskell, or any other language. OCaml's structural subtyping lets you do a lot of what you might want to do with records, too. In fact, OCaml objects support row polymorphism too (in addition to structural subtyping), the same mechanism used by PureScript. See Section 8.4 of [1]. I'd be very interested to know what makes PureScript records so nice – and what they had to recently bake into the language for it. I have not tried that language, and am interested in row polymorphism. [1] https://www.cl.cam.ac.uk/teaching/1415/L28/rows.pdf. 
This is much closer to something like QuickCheck than it is to Liquid Types. But where you give QuickCheck a property for it to test "automatically", you give this a function and it finds the properties automatically. So you can imagine it as sort of a step "prior" to QuickCheck. Ideally you could then pipe this sort of thing into a QuickCheck-like prover and then you get property based testing of your entire program essentially for free. (You can also imagine that certain properties that would be discovered would end up being properties that are well served by being enforced through refinement types, like for example the head function requiring a non empty list. You could theoretically discover the properties of a function with this, and then separate out the "laws" from "type constraints" and cover both with a combination of refinement types and QuickCheck)
Is it just me or is it an odd choice to release 2.0 basically when new-build is stabilized but to not rename it in this major release but to plan to do so in the next one?
Yes, I have a pretty extensive test setup. It's one of my own design though, since when I started there weren't really test libraries, and when they did start showing up they seemed more awkward (and lacked important features like line numbers, though I imagine now that HasCallStack exists they probably have that now). The way mine works, each test is a toplevel function, so I can run them from ghci. I use shake for building, and put the .o and .hi files in a build directory, but that just means ghci needs -outputdir. In fact ghci needs all the flags to be the same, so I have shake put the flags in a file, and replace ghci with a script: exec ghci -v0 +RTS -I0 -RTS $(cat build/debug/ghci-flags) "$@" GHC itself occasionally breaks this, for example I can't upgrade to 8.2 yet because it has too strict flag checking. It should be fixed in 8.2.2 but it gives me the impression that not many people use this workflow. I'm not sure why... the REPL is one of haskell's key strengths for me. How much needs to be recompiled depends on the change. If you change the interface of a low level module, then yes it tends to be worth it to recompile, then restart and reload in ghci, otherwise ghci gets more and more loaded as bytecode. But it can actually be quick if you are not modifying the low level module's external interface. For example, it's common that I run a test, get a confusing result, and go stick a debug trace on a low level function. I can usually reload and rerun the test instantly. Probably ghc's recompilation avoidance is helping out. Since I use shake, builds are parallel, so they go pretty fast in debug mode. Not sure if cabal has caught up here yet. I don't really edit multiple packages at once, but yes it would be annoying to edit one and test from another. Shouldn't a package have its own tests though?
That sounds like a cool setup. &gt; Shouldn't a package have its own tests though? Yes, but IME some things are most easily tested integration-style rather than unit-style. If, for example, I'm trying to extend the data structure (defined in package A) in a way that doesn't break package B, I need to run B's tests. We have a large project that we broke into related packages, but they're still pretty interdependent.
There's still quite a few new-* commands missing (or at least missing functionality), so I think that's the reasoning. (Aside: I don't think the version numbering for Cabal is necessarily "semantic", so there's also that.)
Thanks!
 Ideally you could then pipe this sort of thing into a QuickCheck-like prover Nit: I think you will want to check the properties manually because of 1. false positives and 2. silly properties like this: all p (drop (length ls) ls) == True 
PureScript's record system only recently supported extending records. So insert :: forall r. { | r } -&gt; { foo :: String | r } is a recent thing. There's a lot of neat stuff they're doing with record types now. I need to dig into OCaml at some point. Thanks for the tip!
Fixed, thanks! Yes, I meant to write December 2017.
It's still beta, and some significant pieces of the functionality are still missing, for example `new-install` (which, by the way, is being actively worked on at the moment).
I'm excited about the new caret version range operator (`^&gt;=`), but: - It's not the same as the operator it's based on from npm. With npm, `^1.2.3` means `&gt;=1.2.3 &amp;&amp; &lt;2.0.0`. With Cabal, `^&gt;=1.2.3` means `&gt;=1.2.3 &amp;&amp; &lt;1.3`. I realize that these are *semantically* equivalent since npm uses SemVer (major.minor.patch) and Cabal uses the PVP (major.major.minor.patch), but it's still weird. Cabal's caret operator behaves like npm's tilde operator; `~1.2.3` means `&gt;=1.2.3 &amp;&amp; &lt;1.3.0`. - It introduces "soft" upper bounds. `^&gt;=1.2.3` is "equivalent" to `&gt;=1.2.3 &amp;&amp; &lt;1.3`, except that the upper bound is soft. A soft upper bound means "that version isn't released yet, so I can't promise that my stuff will work with it." Upper bounds can be automatically relaxed by build tools using dependency solvers. That's fine, but there's no way to manually specify a soft upper bound! The caret operator is the only way. So if your bounds don't match the caret operator (like `&gt;=1.2.3 &amp;&amp; &lt;1.4`), you can't soften the upper bound.
What other info do you need?
Me too, I was just about to post the same :-)
I think this boils down to *compiled* versus *interpreted* (with the typical pros and cons). With incremental compilation I see almost no advantage for interpreted languages in the REPL. Also, GHCi is able to mix both in the REPL.
Oh for sure, there's definitely some filtering of the properties required; I just wanted to give more of a sense of what it *could* do (in the future, potentially)
But if you have an idea of the upper bound then it is no longer soft? This matches PVP, and the upper bound would be soft because there is no higher numbered package, so no reasonable knowledge about the future.
I'm pretty sure these were already imported into ghci a few versions back. 
How could Haskell become a proof assistant? Just put a termination / totality checker for functions and removing "undefined" and "error" is enough or is there some other complications?
Yeah, I don't break things into packages like that. Mostly because I'd have to generalize the whole test, build, and profiling system, but also because everything together is convenient for sharing code... all the usual mono-repo excuses. I would like the ability to enforce import rules within a package though, because separate packages are so heavyweight. Google's blaze has a fancy visibility system, maybe something like that. I feel like ghci loads a package faster than all the individual .o files though, so as long as you're not modifying them together they should be overall good for ghci.
If automatic upper bound relaxation will work well enough, explicit soft upper bounds won't be really needed. The semantics of `^&gt;=1.2.3` will then be "at least version `1.2.3`, and please figure out the correct upper bound for me automatically".
There's [type-level-sets](https://hackage.haskell.org/package/type-level-sets) which is used to good effect in the [bookkeeper](http://hackage.haskell.org/package/bookkeeper-0.2.4) record library.
I have one more question, this bake function uses `Vector.Storable`, is it possible to use with `Vector.Unboxed`? I'm not sure of the difference exactly except for compatibility with FFI.
 type family Choose (a :: Ordering) lt eq gt type instance Choose LT lt eq gt = lt type instance Choose EQ lt eq gt = eq type instance Choose GT lt eq gt = gt I am pretty sure this is going to blow up in complexity. Haskell's type system is unfortunately strict, so this kind of combinator must evaluate each of the three paths before it can select one.
I've done something like this before. If your using it for something like sorting, your compile times go through the roof once you have a list with more than a few elements. But, the OP is doing this: type instance GetType (ShapeSet n b t) (m :: Nat) = Choose (Compare n m) NotInHeap b (GetType t m) This only recurses in the third case, so I think the complexity stays linear instead of jumping up to exponential. Although, I'll add that I've pretty much given up on trying to do stuff with type-level orderings in haskell (until Dependent Haskell lands).
That's where I learned that :) I've gotten around that with mutual recursion with a helper that does the pattern matching, but it's *real* annoying to write the top level helpers every time. Can't wait for Dependent Haskell to eliminate all this business.
If I reading the GP correctly, it more a problem of - You write your code against version 1.2.3.1, specify it as `^&gt;=1.2.3` because that's what must work. - Library author writes version 1.3.1.0 of his library, with an incompatible change that does not impact your code. - You are out of luck, because there's no way to specify `^&gt;=1.2.3 || ^&gt;=1.3.1` in a way that keeps the spirit of the original declaration.
If you want Haskell to grow, support languages like Elm. The easy ramp up time, getting people familiar with the style of programming, the excellent documentation. The large user base it's pulling from (Javascript users). This data here is a stark reminder of the business/real-world side of programming languages. Yes it's nice to look down upon other languages for the minutia they lack compared to Haskell, but alternatives that are out there are JS and Python. Selling Haskell in a world where Elm is as popular as Python is now, is a whole lot easier than selling Haskell in the current ecosystem. Even more F# or OCaml users is a net positive. Sending more people to read Category Theory tutorials, or deep debates about TheRightWay are enjoyable, but are counter productive if you're goal is to grow the language base. (Which doesn't mean they shouldn't happen or be avoided. Everyone should take and give to the community as they see fit and how they enjoy). This is just a reminder that Haskell can easily become an evolutionary language dead-end. Getting people closer to this world, even if it's in a language that doesn't have feature X is a win. 
We're looking mainly for advanced hobbyist. Having some code to show is what we've found most effective for both parties, though we recognize that many hobbyists wouldn't have "impressive" work to show off at this stage. We'll be releasing some longer-term coding sample projects that we hope will bridge that gap, and that will be the best way to get on board early. Since it's an internship, ambition and good design sense are more important than experience to us. If you pm me some details on your experience and interest we can put together a toy project sample; mostly for edutainment at this point, but it will speed up the process when we actually start recruiting.
This is serendipitous! I was looking into Scotty recently, but as a newbie didn't find many complete examples to learn from. Someone should probably add it to the Scotty tutorials wiki as well.
I have absolutely no idea how any of that works. Because it's done clean-room style based on shadowcasting instead of being based on the C reference implementation, the PPFOV code is totally alien. I suspect somehow that, if I did know how digital FOV works in other languages, the lambdahack version would be alien looking to me as well. I'm totally interested in the fastest, no-artifact FOV style that can fit in the general fov format I'm using: ```haskell fov :: VisionBlocked -&gt; Int -&gt; (Int,Int) -&gt; Set (Int,Int) ``` But I'm not the best haskell programmer, and I have a lot of trouble with all those short-letter names that LambdaHack seems to love. actually the version in the tutorial is not even the fastest version of the "do what the C version does" style that I'm going with here. That would be this version using some additional concepts that I didn't want to go in to for the tutorial: https://github.com/Lokathor/ludolib/blob/master/src/Util/PPFOV.hs I'd love to see some benchmarks that compare that version with the shadowcasting based and digital based FOVs, if you or someone has a way to set that up. I have absolutely no idea how I would cut out the Lambdahack FOV code and get it into a benchmark rig.
Forgive me if this is the wrong place to ask this, but I read this announcement and I read Edward Yang's blog post about "new build" and I'm still confused about something. He mentions that new build caches packages so you don't have to build them every time you need them, but also uses specific ones for each sandboxed project. That blog post also seems to indicate that you make sandboxes first, but I didn't see how that would work. Maybe I'm the only one confused about this, but if I have cloned someproject with a someproject.cabal and I do a "new build" with it as my first step, will a sandbox be created for me somehow or do I need to do something first to create a sandboxed environment? I briefly used sandboxes awhile ago, but I've totally forgotten the details: are we talking about those old sandboxes?
Nice read (so far). Thanks for sharing. I really enjoyed the Frank "do be do be do" paper, good to see improvements are made! Questions :) 1. There is no comparison with PureScript's record type and how they use it to codify effects in the type system. 2. On p7 "let expressions". I think there is an "in" too much in "case t in [...]". 
You mean, like the Universe?
Let’s start with the full error message and the resolver of the project in which you’re using `stack setup`.
 No information found for ghc-7.10.3. Supported versions for OS key 'linux64-ncurses6-nopie': GhcVersion 8.0.2, GhcVersion 8.2.1
Looks great. Don't forget to change the GitHub repo description.
Either change the resolver to one corresponding to `GHC 8.0.2` or `GHC 8.2.1` or install `ncurses5-compat-libs` from the AUR which will make `stack` search for bindists for ncurses5 and those exist for more versions.
`new-build` has nothing to do with the existing sandboxes. It is somewhat similar in that different projects don’t interfere with each other but that all happens implicitly behind the scenes. You never have to manually create and manage sandboxes or something similar to that.
Thank you, [oink!](https://camo.githubusercontent.com/d4023131d3fb0190b93cfe6a5c29e3cfedb2f029/687474703a2f2f7777772e656d6f7469636f6e7377616c6c7061706572732e636f6d2f656d6f74696f6e2f637574652d6269672d7069672f637574652d7069672d736d696c65792d3034362e676966) 
I've actually decided to avoid this problem for the time being as it wasn't necessary for what I wanted to do in the first place, just something that would have been nice to have. Thanks for your help though.
You may also want to take a look at [the more recent documentation](http://cabal.readthedocs.io/en/latest/developing-packages.html#pkg-field-build-depends) which doesn't claim that `^&gt;=` is the same as `^` but its naming is inspired by it. Syntactically, `^&gt;=` is to PVP what `^` is to SemVer, just like what we call major versions in PVP is syntactically different from what is considered a major version in SemVer. There's a lot more to say about what I intended to express by using the term "soft" bounds (NB: it's actually also a soft lower bound), for now the important thing to note is that `foo ^&gt;= 1.2.3` expresses the fact that you *know* that foo-1.2.3 is semantically compatible with your package. This is also related to [this cryptic comment](https://www.reddit.com/r/haskell/comments/6jv15h/haskell_infrastructure_swift_navigation/djnpgwd/) and there's a formal system in the works (sorry, can't say more at this point; please stay tuned) for which this new operator is a key ingredient and which will significantly simplify/automate dependency management in a principled &amp; semantically sound way.
Done. Thanks for letting me know!
Oh, surprising! :) Couldn't find them when doing **:?** in GHCi 8.02, but they are indeed there. I can maybe use them in the Neovim plugin then, and fallback to regluar **:type** for older versions of GHCi. Thanks!
Will try my luck as well, may be they have interest to part-time haskell newbie as well.
Awesome, can't wait so try it. It says "does not rely on Stack". So can I still use it for stack based projects? Will it find the locally installed packages?
No, I don't think it's possible to bake in an Unboxed vector. You can use the convert function from vector to convert to one from Storable though.
Thanks. (checking if I'm still banned for writing in the list)
I haven't had time to try, but I think if you set `g:ghci_command` to `stack repl` it should work!
Sounds good. I'll report back once I tried.
Tried it, it works :)
Is there already a function like this in the `lens` library? setAndReturn :: s -&gt; (x -&gt; (t, x)) -&gt; Lens' s x -&gt; (t, s) setAndReturn a f l = (x, a &amp; l .~ y) where (x, y) = f (a ^. l) example use: &gt; setAndReturn ([1,2], [3,4]) ht _2 (Just 3,([1,2],[4])) where `ht` is: ht :: [a] -&gt; (Maybe a, [a]) ht [] = (Nothing, []) ht l = (Just $ head l, tail l) You can use it to fetch an element from something and remove it from the original value.
I like the spirit, thanks! How do you discover the Github page from the package name?
The new `DerivingStrategies` extension in GHC 8.2 allows you to derive `Show` in the way you originally wanted, by explicitly selecting the `newtype` deriving strategy.
Quickcheck is an external library and not part of the compiler. In order to use it you have to install/download it to your computer, and when you compile you have to tell the compiler that you want to use it. Can you share how the structure of your project looks like and which commands do you use to compile? There are multiple ways to compile a program and It'll be easier to explain how to make this work in your workflow.
&gt; if I have cloned someproject with a someproject.cabal and I do a "new build" with it as my first step, will a sandbox be created for me somehow or do I need to do something first to create a sandboxed environment? No, that's the beauty of it. Just run `cabal new-build` and it will take care of everything. Read [this section of the manual](https://www.haskell.org/cabal/users-guide/nix-local-build-overview.html) to learn more about `new-build`.
I recently started using the new-* commands and they work quite well. Multi-package projects are also nice.
Hackage has a source repository field.
There's even a https://www.stackage.org/package/errors package for that, hope you'll find it helpful
I find runtime exceptions absolutely unnecessary with a type system like Haskell's. In my eyes, you are doing yourself a favor.
Depends, if it's an IO related function, I wouldn't bother to wrap. If it's partial function (e.g. `head` that fails on empty list) than it makes sense. this blog post probably related to your question https://www.fpcomplete.com/blog/2016/11/exceptions-best-practices-haskell
What do these Stars mean exactly? I've clicked before, feeling that it's like subscribing to a subreddit, but now that I check my "feed" at github.com it seems like it doesn't do that, only "Follow" does?
What about asynchronous exceptions? What about simple programs for which you just want to terminate when any error happens? Catching failures in those cases is busywork. (Just an idea, but perhaps a library could be written which "decorated" IO actions with a type-level list of possible errors, and would let you choose with errors to handle "as values" using `TypeApplications`. The rest would behave like run-time exceptions. Does something like this exist?)
It's like a bookmark; everything you've starred is listed on &lt;https://github.com/stars&gt;. (Also, like a "Like".)
That is only an aesthetic change. Perhaps it forces the exception treatment to be done ever after the function invocation and does not handle asynchronous exceptions. if you are within these constraints or you want these constraints, it is good. Be aware also that you perform two, not one exception checking for each function: one internally in the function, to return `Left`, and another after the invocation, to check if `Left` is returned. I don't find any real advantage. An exception monad makes it closer to the semantic of native exceptions. It is a good exercise for learning, but the boilerplate makes this worthless in practice IMO.
Sure? Also in situations like: * Reading a large file that gets deleted. * Doing some network IO that gets interrupted. I think when it comes to IO that exceptions are a good construct for modelling what actually happens in the code. Here some text on best practices: https://www.fpcomplete.com/blog/2016/11/exceptions-best-practices-haskell
Yes, I am sure that this is my opinion. Elm handles the "no runtime exceptions" pretty well. It also handles async IO really well. Besides, it puts failure into your type signatures. I really like that.
Much of the time, I agree. But the important thing is that pretty much *all* `IO` is bound to throw in some circumstances. You probably don't want to have to catch every "Thread blocked indefinitely on empty MVar" every time you use `readMVar`. And *literally* all code can throw when you consider that other threads are allowed to kill your thread. So as much as I want to be dogmatic and say "I don't have any unchecked exceptions because I always use Either/Maybe," I have to admit that this is impractical in the large. So I think you have to take a more balanced approach to it. Generally, there are exceptions that are semantically relevant to your code, and there are exceptions that are asinine to try to expect ahead of time. The strategy is to catch the semantically relevant exceptions as early as possible, converting them to Maybe/Either. These exceptions are generally good to put in an `ExceptT` type. In practice, most of these are semantically relevant in 100% of applications, making me wish they just had the exception in the type signature instead (stuff like `head`). But there are ones like `HTTPException` where I can easily imagine writing code that does not want to care about that semantically. So it's an application-dependent thing. But with the exceptions that don't make sense to try to anticipate 100% of the time (the `MVar` one, for example) I just make sure to make the job exit gracefully. Use `bracket` to close your resources; maybe catch the exception completely so you can return to your event loop; whatever you have to do to account for the fact that this job can fail in unexpected ways. You will not anticipate all exceptions, so you must allow your top level code to save you when you throw. I think this approach is much more reasonable than the extremes of "always use Either/Maybe" and "IO always throw so there's no hope." I think the former is just impractical once you look under the covers, and the latter is throwing the baby out with the bath water. It's a big grey area; many exceptions can fall into either camp just depending on who you ask or what the application is. But there are also some completely unambiguous ones; there are far too many unchecked exceptions on Hackage that *really* ought to be in the type signature, and I consider that highly unfortunate..
you meant `join &lt;$&gt; intermediate -- :: f (t (t b))`. 
If that's the direction we're headed, why not make `&gt;=1.2.3` mean that? 
What's wrong with the or'ed constraints?
How do you want to model OOM exceptions in the Haskell type system?
That sounds great. I've been using stack for awhile but sometimes I want an easier way to mix and match packages that aren't in the resolver.
That sounds great.
At Vacation Labs we have a full-time internship, as well as a part-time bounty program: * http://www.vacationlabs.com/internship-program/ * http://www.vacationlabs.com/haskell-bounty-program/
Good question! I'll leave it to [/u/hvr_](https://www.reddit.com/user/hvr_) to answer.
Worth noting that the linked article is an opinionated piece. It's good content. But a lot of people disagree that this is the best way to handle this stuff.
Also worth noting that a lot of people agree. It's far from just the opinion of that author. EDIT: To be more clear: It's standard practice in quite a large swath of the Haskell ecosystem. It's well understood, well supported in libraries, and works well in practice. So if you use that approach, you're definitely not doing something which is dodgy or risky. That's not to say that there aren't any other interesting approaches out there, of course.
This is explained in the article. &gt; This blog post is the opinionated part: how I recommend you use exceptions in Haskell, and how to structure your code around them. There are dissenting opinions, which is why this is an opinion blog post instead of library documentation. However, in my experience, these approaches are the best way to make your code robust. But yea, it would be good to have the competing opinions presented so well.
Did not mean to imply it was *only* his opinion. Just that one should consider the alternatives as well.
Seems like they should work, but it could get tedious as the number of constraints goes up. Something like Aeson could end up having a constraint like `^&gt;=1.2.1 || ^&gt;=1.1.2 || ^&gt;=1.0.2 || ^&gt;=0.11.3 || ...`.
Because we still need syntax for *real* constraints, and it's a bad idea to retroactively give existing vocabulary a totally new meaning. Also, `^&gt;=` is more than just a "smarter lower bound"; there's more to this and it will become more evident soon why we needed a new operator for that.
This is absolutely great progress. I'm quite happy with the new family of commands based on `new-build`. I even stopped using `stack`, now I feel like **cabal** is a modern build tool quite comparable to other modern languages. Now there isn't any excuse for somebody complaining about *cabal hell* anymore.
The naive 10-year-old child answer is it depends if it makes sense continuing the program without the result of this function meaning if you know how to handle this result so that the program remains correct. As an example I've had was when I wrote a parser that at some point called fromJust (which throws an exception when the result is None) I didn't care about it because if that happened it meant the source was dead wrong and it wouldn't generate any useful AST capable of yielding a correct template so it's better failing sooner than later. Which I believe is the whole point of Haskell you want everything to fail as early as compile time instead of later in production. Unlike the spawn of the entropy called JavaScript.
And how about: * Computer runs out of memory, or some essential hardware failure * User hits Ctrl-C
I wish there were no programmer-defined exception in Haskell. Things like a file being deleted as you're processing it, or running out of memory, those are *truly* exceptional circumstances: the runtime *should* throw an exception. I'm even happy to allow `killThread`, a thread being killed is pretty exceptional. But is a test failing an exceptional situation? Or any of the many other things people define exceptions for? Not really. I think Haskell would be much better without `throw` and `throwTo`.
Python has loads of libraries and the development is faster, mainly because the learning curve is shorter. And some people really don't care about type-check and think it's just a liability. I wonder if they account for the time spent writing tons of test cases for things that could be proven straight on by a robust type system or worse when failures slip through right to production code.
I generally agree with this. But I'll add that there are situations where you do care about some classes of exceptions, but it's still best to use Haskell's built-in exception mechanism for them. If your code is anyway essentially IO, and in your (usually quite large) application you really don't want to deal with or specify these exceptions except in certain contexts where it makes sense, "converting" the exceptions to `Either/Maybe` can add significant unnecessary complexity.
Was that directed at me?
I won't comment on any of the other frameworks, since I have no domain knowledge in them. But I will say a couple of things about Reflex. &gt; Reflex-DOM doesn’t do DOM-diffing (at least not yet), so sometimes this choice has performance implications In general, DOM-diffing is not a necessary technique. With an efficient representation of behaviors and events, you can just change the DOM directly rather than producing an entire new tree and running a whole diffing algorithm. This can add some mental overhead on occasion, but usually not, since things tend to take dynamic arguments anyway, meaning they're already doing that logic. When it does come up, it's almost always a case of "`widgetHold` and its derivatives will redraw the entire child widget on each update." If you just keep that in mind, it's pretty easy to reason about what techniques will obviously cause problems. &gt; I’ve played around with Reflex about 6 months ago and felt lost due to the lack of a “UI architecture.” Most people (including me) have never worked with an FRP framework, and could use guiding principles while working with the library. I think this is a major pain point. In my experience using Reflex in some complicated code, there are some valuable guidelines for architecting things. But none of this seems to be documented anywhere.
I don't know really. It's among the minority of exceptions thrown in my day job. If it ever happens. But reading from a locked file? Why can't it yield an 'IO (Either IOFileError String)' instead of 'IO String'? There's a whole slew of exceptions that the type system _can_ handle but doesn't. And I'm against that.
It was in agreement with you.
Yes, encoding exceptions in the types incurs a burden, but that doesn't mean it's a bad thing. There are plenty of burdens we take on in programming because it's the more sound architecture. In large applications *especially*, I think it's irresponsible to throw semantics to the wind and say "eh I guess the caller will catch this, or whatever." If someone on your team calls that function from an unanticipated place, they're far too likely to be unaware of the exception. So they've probably just introduced a bug where an expected exception is now being treated like a failed job. Errors that mean more than "kill the job" ought to be encoded at the type level in 100% of your application.
Sometimes I wish Haskell only had asynchronous exceptions, and that Either would be used in place of synchronous exceptions. It can sometimes get pretty difficult to tell which exceptions are thrown by a library function and it would be nice to have an easy way to make sure you don't miss any. I am aware that Java already tried the checked exceptions route and people didn't like it, but in my experience the real problem was not being able to generalize over the exception type. For example, in Java, the argument to Stream.forEach cannot throw a checked exception, but you would really want to say that Stream.forEach(f) throws the same exceptions that f throws. In Haskell, we don't have this problem as we generalize not only over the exception type but over the entire monad. So I don't see why Haskell couldn't go the checked exceptions route (other than breaking pre-existing code).
Speaking of targeting javascript: Why isn't there a GHC and/or purescript build running on javascript? Alternatively, I'd take an ARM or JVM/Dalvik build. Seriously! I'm literally stuck with C, lua, and tiny tiny lisps on Android. "Java" is also kind of there (both ecj and clang come with termux), just don't think that any Java program will actually run, there's no proper JRE present.
This is actually a function I find myself wanting somewhat frequently. Seems like the kind that ought to be in `Data.Foldable`
It's great practice! Fortunately, it's easy to go between these two representations: try :: Exception e =&gt; IO a -&gt; IO (Either e a) rethrow :: Exception e =&gt; Either e a -&gt; IO a rethrow = either throwM pure Just follow exception best practices: you rarely want to `try foo :: IO (Either SomeException a)` because this catches way more exceptions than you need to. Unfortunately, because Haskell does allow pure code to throw exceptions, and because the language uses asynchronous exceptions, you still need to be aware of Haskell's runtime exception system, and handle things appropriately. This means using `bracket` and `resourcet` and friends to acquire/cleanup resources in the presence of exceptions, and ensuring that your application *can* handle exceptions that aren't necessarily documented. 
Right, in theory reflex-style updates should be faster than dom-diffing, since we can use statically known information about the dom structure to make updates directly. The downside is that it requires thinking about exactly what parts of your dom will change and when, to avoid unnecessary redraws. This can get hairy quite quickly, for example, the obvious way to switch between drawing two widgets in a sum types redraws too eagerly, so to get full performance you need to use custom code. On the other hand, I'm not sure how much of this is reflex overhead vs ghcjs overhead, it would be interesting to see that comparison or maybe I missed it
&gt; The downside is that it requires thinking about exactly what parts of your dom will change and when, to avoid unnecessary redraws. That has not been my experience. Most of the time, you just keep everything in `Dynamic` or `Event` for as long as possible, and you basically never have to think about when things are redrawing. The only exception is when you know you have to use a widgetHold derivative, and it's usually extremely obvious where the correct place to put that is. &gt; This can get hairy quite quickly, for example, the obvious way to switch between drawing two widgets in a sum types redraws too eagerly, so to get full performance you need to use custom code. I don't understand. If you are switching between two widgets, there is no way around redrawing whenever you switch between them.
Thanks! I have to admit I don't understand the difference between statically and dynamically compiled libraries...
[removed]
How do you deal with more than one type of exception?
No, the exception system is not willy-nilly throwing things to the wind, at all. By design, it allows you to deal with exceptions where they are relevant, in a very precise way. As an example, you can have an inner function that acquires data from a database, many layers of business logic functions that deal with the data, and an outer function that uses the result to render a web page or some other UI. The inner function can detect scores of different kinds of DB errors and throw richly-typed exceptions that represent exactly what went wrong, and the UI layer can present the proper response to the user in each case. For all the rest of the functions in the middle, all those DB error conditions are no different than out of memory, disk failure, network failure, someone hit the computer with a sledgehammer, and innumerable other kinds of failures that are just irrelevant to that code. It's silly to complicate it with a type that tries, but certainly fails, to encode every conceivable kind of failure. The result is more semantically precise, readable, maintainable code. Yes, I know the arguments for other approaches, and they also make sense. Representing the failures you care about at the type level has value in its own way. In reality, the best approach for any given application might be one, the other, or, most likely, a hybrid.
Awesome. Is anyone using this in production? What does this do to compile times? How much of a slowdown can one expected for a large webpage being rendered using this library?
I will try to get you the information! 
That's exactly why I said it depends on the application and the exception. If literally none of your code care about any exceptions besides the top level part, then yea, those exceptions are not semantically meaningful and don't (as far as the logic goes) mean more than "kill the job." That's a valid use of IO exceptions IMO. My point is that if you're catching a particular type of exception in a particular place for a particular reason, it probably should have been in the type system.
It depends on what your exception handling code is doing. If your code is not responding to exceptions in any meaningful way, i.e. you are simply bubbling up errors to the very top of the call-stack and just display them to the user, then what difference does it make if this job is done by the exception mechanism or the Either/Maybe monad? In most webapps this is usually the case. Therefore I've stopped worrying about most exceptions in my code (for my particular use-case).
[removed]
You will like Stack even more then! Stack has had support for [multi-package projects](https://docs.haskellstack.org/en/stable/GUIDE/#multi-package-projects) long before cabal and more importantly is considered stable. The new-* commands won't come out of alpha until late 2018.
What does "keyed" mean?
Long explanation at http://www.stefankrause.net/wp/?p=342
&gt; Why isn't there a GHC and/or purescript build running on javascript? What exactly do you mean by this?
Switch your types around just a little bit: Lens' s x -&gt; (x -&gt; (t, x)) -&gt; s -&gt; (t, s) Then that's actually just `id`, using the `(,) t` `Functor`. There's also a lens convenience operator for it: [`%%~`](http://hackage.haskell.org/package/lens-4.15.4/docs/Control-Lens-Lens.html#v:-37--37--126-). 
Author here. I doubt that it's used at the moment in production, because it's still a quite new package. A large webpage (let's say a typical page of wikipedia) consumes perhaps 2 min. compile time with -O3. Therefore it's advisable to put big pages into seperate modules and use -O0 for developping. Besides you can mix and match this with blaze, because both generate at the end of the day ByteString.Builder, so you can write an Convert instance for blaze and only change the hotpath to type of html...
Okay, yes the `%%~` operator is what I was looking for, thanks. &gt; ([1,2], [3,4]) &amp; _2 %%~ ht (Just 3,([1,2],[4]))
Hi, author here. I'd be glad to answer any question or to hear any suggestion!
I'm happy that someone finally tackled type-safe HTML seriously in Haskell. I'm the maintainer of [tyxml](https://github.com/ocsigen/tyxml/), which does that in OCaml, along with quite a few goodies. How much perfs does the elision of optional closing tag get you? My personal reaction is that it's a terrible idea that will cause some headaches down the line (and it must make the internals more complicated). As far as typing goes, after several years of feedback from users, My advice would be to not be too strict with the typing, but to definitely type attributes, which seems to be the most useful things in practice (and does not lead to error messages that are too insane). How flexible is the output? Can you, in particular, output non string-like types? One things that we found extremely useful for tyxml is that it's possible to output a wide variety of datatypes (text, but also DOM trees for client usage, virtual-DOM, FRP-nodes, ...). In all cases, well done, this is a very cool usage of type families/GADT! ;)
I believe something like subscription on reddit, would be the `watch` option.
The perf for the elision depends a lot on the usecase. On an average webpage it doesn't get a lot, but on stuff like generating a big table with numeric data it's quite good. I'd guess 30%, but I'd need to bench it (already made the bench on an older version of the lib). Do you suggest that I'd type Attribute analog to Element, but not type Element? That would decrease perf a lot. Or are you suggesting that I strongly type both as Kinds etc? That would increase perf but also increase a lot compile times. Note that Attribute is typed, but kinded only as * Anyway, thanks for the feedback, that's appreciated! At the moment, it can only spit out string like stuff (String, Text, ByteString, Builder). If you look at Html.Reify (internal module) you'll see that the stringification is quite short (~100LOC), so it is absolutely feasible to write another backend. But the untyped attribute complicates it... Hm. 
Yeah, our codes do differ, which makes it even more enjoyable. :) The LambdaHack code is based more on recursion, receiving state (Edge and Progress) modifying it and passing to new recursive calls. The computation is ordered so that the function call stack records what is left to do. On the other hand, your code (both versions) is based more on modifying state ([View]), which is not only received, but also returned from functions and is also larger, probably because it records some of the TODO info that is implicit in the call stack in LambdaHack. The code I pointed you to works in just one octant (in case of DFov, quadrant, IIRC), and assumes the actor is at point (0, 0). Well, its even documented: http://hackage.haskell.org/package/LambdaHack-0.5.0.0/docs/Game-LambdaHack-Server-Fov-Permissive.html What is not documented is that PFov is implemented without a vision radius (the radius was an old, never implemented TODO) --- so the radius is infinite. (DFov, being the algorithm actually used, has a sight radius, but the version I linked to has even more complex types of functions, because it's optimized for the particular setting.) Anyway the following function glues together all quadrants or octants, translating coordinates as required: https://github.com/LambdaHack/LambdaHack/blob/v0.5.0.0/Game/LambdaHack/Server/Fov.hs#L192 I'd love to see benchmarks and also to verify if our variants actually compute the same things, and if not, which is more accurate and which is faster. I suppose, one could adapt your code to v0.5.0.0 LambdaHack (current version, v0.6.1.0 is no longer so general and only DFov is left, so it would be harder) and run game benchmarks. Fov takes around .3 of game time, pathfinding another .3, AI picking enemy, item and action to perform, most of the rest. So the benchmark, with some fixed seeds, would show differences. I could also add a tweak that runs 2 FOVs and asserts their results are equal.
Correction: both my PFov and DFov are based on quadrants (ordinary shadowcasting is based on octants), they are just situated on the map differently: when progressing through quadrands of DFov, the algorithm covers larger and larger squares with sides parallel to x and y axes, while DFov has sides at 45 degrees to axes. Which makes adding radius to PFov harder. Also an extra condition has to be checked for PFov when permitting progress, which makes is less permissive than DFov (probably a good thing), but a bit more complex to code.
There are no shills here. There are people who prefer different tools for valid reasons. Cabal hell had nothing to do with version bounds; it was specifically a problem with global package dbs, which has been solved. Stack is not the one true way to get version pinning, as Nix and Cabal both offer flavors of the exact same thing. Stackage originated as a tool to use with Cabal, and I believe can still be used this way.
You don't even know what cabal hell is, do you? Are you so closed minded that you can't even comprehend the possibility that Cabal is becoming a good tool?
Not sure if this is the right place to ask but I was trying to get a better grasp of how ghc's optimizations work. I think I got the big picture but am a bit stomped with some things it does. mean :: Double -&gt; Double -&gt; P Double Int mean m n = go n 0 0 where go :: Double -&gt; Int -&gt; Double -&gt; P Double Int go x l s | x &gt; m = P s l | otherwise = go (x+1) (l+1) (s+x) main :: IO () main = do i &lt;- readLn let r = case mean 1 i of (P x y) -&gt; x / fromIntegral y print r At first ghc does a worker/wrapper transformation and then inlines both into main, leaving the core one might expect: main = ... (case x_a4oV of { D# ww_s562 -&gt; joinrec { $wgo_s55T $wgo_s55T ww_s55J ww_s55N ww_s55R = case tagToEnum# (&gt;## ww_s55J 1.0##) of { False -&gt; jump $wgo_s55T (+## ww_s55J 1.0##) (+# ww_s55N 1#) (+## ww_s55R ww_s55J); True -&gt; case /## ww_s55R (int2Double# ww_s55N) of wild4_a4Sm { __DEFAULT -&gt; $w$sshowSignedFloat $fShowDouble2 minExpt wild4_a4Sm [] } }; } in jump $wgo_s55T ww_s562 0# 0.0## }) but then it optimizes further and applies the full laziness transformation to the join point, destroying it in the process: Rec { RHS size: {terms: 31, types: 7, coercions: 0, joins: 0/0} $wgo_s57l $wgo_s57l = \ ww_s55J ww_s55N ww_s55R -&gt; case tagToEnum# (&gt;## ww_s55J 1.0##) of { False -&gt; $wgo_s57l (+## ww_s55J 1.0##) (+# ww_s55N 1#) (+## ww_s55R ww_s55J); True -&gt; case /## ww_s55R (int2Double# ww_s55N) of wild4_a4Sm { __DEFAULT -&gt; $w$sshowSignedFloat $fShowDouble2 minExpt wild4_a4Sm [] } } end Rec } main = ... (case x_a4oV of { D# ww_s562 -&gt; $wgo_s57l ww_s562 0# 0.0## }) main isn't exported so this can't make inlining it easier. I just don't get what this optimization is supposed to accomplish, it just seems to add an additional call at best and make further optimization harder at worst.. Does anyone have an idea why ghc does this? 
Seems that you know a lot more of what's going on than me. Let me know how it goes if the benchmarks are done.
Something you can run in the browser, nodejs, in general: A javascript VM. Having once tried to port GHC I know what a royal pain that is due to the build system, however, purescript, as "a mere Haskell program", shouldn't be that hard to do.
STM is not storage. It is not meant to replace a long-term storage. It is a mechanism to facilitate both safe and easy concurrent access to memory. In other languages you often hear about [thread-safe](https://en.wikipedia.org/wiki/Thread_safety) code. It is a code that ensures accessing shared memory across multiple threads is done in a safe manner preventing race conditions. But to do so often requires writing quite complex code and requires understanding of what you are doing. STM is a mechanism that allows to write thread-safe code, preventing race conditions. But at the same time it is simple to understand and therefore more (novice) programmers can write such code in haskell than in other languages. 
**Thread safety** Thread safety is a computer programming concept applicable to multi-threaded code. Thread-safe code only manipulates shared data structures in a manner that ensures that all threads behave properly and fulfil their design specifications without unintended interaction. There are various strategies for making thread-safe data structures. A program may execute code in several threads simultaneously in a shared address space where each of those threads has access to virtually all of the memory of every other thread. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/haskell/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
&gt; The downside is that it requires thinking about exactly what parts of your dom will change and when, to avoid unnecessary redraws &gt; I don't understand. If you are switching between two widgets, there is no way around redrawing whenever you switch between them. I may have misrepresented the issue, but I'm referring to the construction [here](http://anderspapitto.com/posts/2016-11-09-efficient-updates-of-sum-types-in-reflex.html) Is there a better way to make this kind of thinking unnecessary? edit: I should clarify that I think the performance of straightforward reflex-dom is quite good, but to do _better than_ virtual dom diffing requires some care (just like in react, for example) 
&gt; If you are switching between two widgets, there is no way around redrawing whenever you switch between them. I don't think this is accurate. You have a lot of control over the browser's compositor (you can force a new rendering texture on every major browser with `transform:translateZ(0)`), so it's pretty easy to get something rendered to a texture even it isn't actually visible in the final UI. When display (or anything else, for that matter) is solely handled by altering already-rendered textures' properties in the compositor, everything will be completely smooth, unlike the usual jank/stutter when the browser suddenly has to (re)paint a texture it needs to show on the fly. Once you experiment some with this, it's very noticeable when this is done properly and when it's not. To play around, use the Chrome dev tools and enable show rendering repaints -- it will show a big green flash whenever a repaint occurs, and those flashes indicate places where users (especially mobile!) will likely experience "jank".
It took me a while to discover it, but Reflex-DOM supports `jsaddle-warp` which actually makes the tooling story for Reflex-DOM *fantastic*. All of Reflex-DOM (and most of its ecosystem) compile easily with GHC (not just GHCJS). When developing Reflex-DOM apps, I can run my front-end and back-end code from the same server and get near instantaneous updates as soon as it hit "Save". This is possible with a `jsaddle-warp` server that gets run by `ghcid --test`. Every time I change the code, `ghcid` immediately restarts the `jsaddle-warp` server and my page automatically refreshes. Not only that, but I use `intero` (VSCode with Haskero) without any issues for Reflex-DOM code because all development is done with GHC (not GHCJS). I have just as much tooling with GHCJS as I do with GHC because I only use GHCJS to build the final JS output. Here's a snippet of my setup for auto-reload: https://gist.github.com/3noch/ee335c94b92ea01b7fee9e6291e833be
That's definitely a bit more complicated than it needs to be. In this case we just want to rerender when the sum type changes. So, we just use a `widgetHold` derivative (in this case, `dyn`) on that sum type around the widgets that needs to be redrawn. data A = ... data B = ... renderA :: (...) =&gt; A -&gt; m () renderB :: (...) =&gt; B -&gt; m () type C = Either A B renderC :: (...) =&gt; Dynamic t C -&gt; m () renderC cDyn = void $ dyn $ ffor cDyn $ \c -&gt; do case c of Left a -&gt; renderA a Right b -&gt; renderB b Though I suppose you might be referring to the desire to only do a full rerender when the sum changes, not when the value inside the sum changes. You can [use `eitherDyn` for this](https://github.com/reflex-frp/reflex/blob/3a4cb7966016c36a197a33bf9b394ec21dfe30e5/src/Reflex/Dynamic.hs#L296), which is a special case of the more general `factorDyn`. Point is, it gives you a dynamic that only changes when the constructor of the sum type changes, but the values will themselves be dynamics that change on their own.
Just added a nicer readme on github with screenshots of the performance...
If it's not already there may I request you to have this bit merged into the official reflex docs? 
Yes, Reflex handles some of this "jank" stuff for you in a number of ways. But you can get arbitrarily fancy with it yourself in Reflex. I mostly just meant "if you're ripping out the dom and replacing it with new and different dom, a diffing algorithm does nothing there."
That's actually pretty high on my priority list. I originally had the same verdict that you came to (it's still technically true for GHCJS itself). But once I discovered this (about a month ago) my feeling about Reflex-DOM tooling did a 180 and I'm happier with this setup than any other I've seen!
Exactly, at some point I felt like cabal was unusable. It was pretty hard to be able to do dependency resolution successfully on some projects. Then I started using stack and I was quite happy with it. I have a lot of respect for the developers behind it and for the stackage.org initiative. But when cabal started to offer sandboxes and later on nix-style local builds I saw a major improvements and I was able again to be able to build projects reliably. So, that was my major friction and now it's completely solved.
This is a *sorely* needed comparison. Thank you *very* much for your hard work and contribution on this issue.
Isn't that what GHCJS is? You can run GHCJS output on Node.
&gt; Though I suppose you might be referring to the desire to only do a full rerender when the sum changes, not when the value inside the sum changes. Exactly. `eitherDyn` works for `Either`s but what about custom types? We need to convert them to `DSum`, make tags, etc. It's just more to think about. I'm also skeptical that `DSum` introduces some overhead. [`data-constructors`](https://github.com/daig/data-constructors) eliminates that overhead but then we need to pull in template haskell, which is quite bad for compile-time on GHCJS
Yea, I see what you mean. But to be honest, I can't say it's ever gotten in the way for me. Doesn't really come up as a problem that often. The basics like `eitherDyn` tend to be enough, if it's ever necessary.
When you want to efficiently update a list of swapped (or sorted) child DOM nodes while minimizing destructive operations, reordering the nodes based on unique keys will help you do this. Most frameworks before react naively blew away and recreated all child nodes (some still do). This is extremely expensive and causes cascading updates of multiple DOM nodes. Most user-noticeable slow-downs come from this, and the fastest frameworks have extreme optimizations for this case alone.
Fortunately, I often go *weeks* between building with GHCJS. During development there's little reason to use it.
As an aside, I like it when libraries provide exception-free APIs because it's always possible to convert to exceptions by merely throwing `Left`, `Nothing`, etc. cases.
I'm aware of that. I guess I stick with Cabal in part because of inertia, and in part because I like the explicitness of a single .cabal file (my projects are not big enough for the .cabal to have become a nuisance). Also I wanted to play with Backpack. If I used Haskell professionally, perhaps I woud turn to Stack instead.
It would be nice to see react-hs on that comparison as well. It's currently what I am using in production. https://github.com/liqula/react-hs
As anders_ says they are bookmarks as well as likes. A lot of people consider the number of stars a repository has to be a meaningful representation of the package's adoption and usage rates. For some reason in the Haskell community people don't seem to star nearly as much as some other language communities where it appears the package's importance and adoption is comparable. For example `monad-control` is used by over 350 packages on Hackage, but has only 38 stars. A 10:1 dependency to star ratio is unheard of in the Elixir community for example. Just to pick one example there the `plug` library has 344 dependencies on hex.pm and 1479 stars on Github. It's not a "sexy" framework either, its low-level machinery which is important to the ecosystem as a whole (just like monad-control, although maybe its not as controversial). 
yes, good point! Last time I used reflex-platform, the default GHC build was webkit, and I never got jsaddle working fully satisfactory so sometimes I'd have to build with ghcjs to get an accurate rendering. Does reflex-platform use jsaddle by default now? Or what is your setup?
See my [other response on this thread](https://www.reddit.com/r/haskell/comments/6z8e3m/benchmarks_ghcjs_reflex_miso_purescript_thermite/dmtmbqd/).
&gt; Why isn't there a GHC and/or purescript build running on javascript? If you mean a port of GHC to Javascript...that doesn't exist because it would take person decades of work for very little benefit.
Something like it was proposed [10 years ago](https://ghc.haskell.org/trac/ghc/ticket/2042) for `base`. Maybe it would be accepted now? There is a bias in the standard libraries against exporting new functions that are simple compositions of existing functions, because they’re cheap to add but expensive to remove.
Thanks for providing this! However, I end up with "undefined variable: starting_up_msg". I can fix this by prepending "s:" everywhere it is used ... Have you or someone else had the same problem? In particular on archlinux with 0.2.0-r2?
If you're going to allow exceptions produced by the runtime to be handled by the programmer, you need `throw` at the very least, because you have to be able to rethrow exceptions you've caught but aren't currently relevant to your code.
Agreed. Have been looking for something like this for a long time. Thanks Saurabh!
I think he means running the compiler itself on Node. i.e. compile GHCJS itself to javascript. But I also think this was done with Purescript at somepoint. I remember seeing it but not where :(. 
Not really, `catch` only catches exceptions of the given type. If an exception isn't relevant to your code, you just don't catch it.
Well this more general version (no traversable constraint) is at least a bit more complicated. foldMapA :: (Applicative f, Monoid m, Foldable t) =&gt; (a -&gt; f m) -&gt; t a -&gt; f m foldMapA f = foldr (\a fm -&gt; mappend &lt;$&gt; f a &lt;*&gt; fm) (pure mempty) Not sure if that's sufficient to be in base.
The fact the moderators haven't banned your stupid ass speaks volumes to how worthless the mod team is on this subreddit, honestly. In any case: you should still delete your account, like I told you to last time.
They are not any better than `&gt;= 1.2.3 &amp;&amp; &lt; 1.4`, while the goal was to create something better.
I'm just guessing more boldly. :) Yes, I will let you know if I work on that in any way.
We had a go at porting PureScript to PureScript a couple of years ago. It ran very slowly. JS might be more easily portable in some ways, but it's very difficult to match the performance of GHC. Luite has also [compiled an older version of PureScript to JS using GHCJS](http://hdiff.luite.com/tmp/try-purescript.jsexe/), which says a lot about the power of GHCJS :D
Those accomplish something different. This is in *addition* to whatever you want to use for happy, alex, Haskell, and cabal syntax highlighting. 
&gt; you just don't catch it Sometimes you want to annotate it in passing. Of course, there are approaches that would allow that without an explicit re-throw.
Can you use it to deconstruct Html ? I like the way Drupal build a sort of ADT of html which can be modified with hook (not I really need though)
And importantly: no exception when looking up a missing key in a data, no exception for validation of application configuration. Leave exception creation to the system. This is probably my biggest and point of difference with the explanation of exception handling by fpcomplete.
There are two types of exceptions, the ones which are reproductible and depend only on the function arguments,(same arguments =&gt; same exception). this includes diviSion per zero, partial function, etc.... In my opinion, this shouldn't happen and I try as much as possible to make impossible to call it with the wrong arguments. That's where ADT are handy. Second type of exceptions are random (from the program point of view) and due to side effect. Examples are, disk full, out of memory etc. A function should work but doesn't. The solution is retry, restart the program and retry and finally reboot and retry. They are true exception : they are exceptional and there is nothing you can do about. They need to be catches as late as possible . Basically, pure functions shouldn't raise exception. IO can and I don't even catch them. 
It would at least be an interesting static analysis. You'd want to propogate them recursively upwards for it to be useful, so when analyzing `x` if `x` calls`y` calls `z` you'd expose the exceptions that might be raised by all three.
Well, it sort of constructs an type level ADT which you can already manipulate. Most constructors are exported. It'll get only stringified if you call a render function on it, but you can modify it beforehand. 
I guess the [WebGHC](https://webghc.github.io/roadmap) project (Summer of Haskell 2017) is worth a quick mention here. Not sure how relevant it is because of the nascent state of the project (and Web Assembly) but I for one am keeping an eye on it. There doesn't seem to be much discussion around this project though. Any ideas why? 
I've now understood one interesting difference: you generate a list of locations to check and then visit them in the order you generated them. This has the advantage that it's easy for you to impose a sight range even in PFov. But it has the disadvantage, that you have to keep a list of all views on the current distance from the start, not just the convex hull that is relevant for a location currently analyzed and can be forgotten when we analyze another disjoint clear area. You visit locations breadth-first, finishing those with distance n from start before tackling those with distance n+1. I visit locations view-depth-first, determining the extent of a given view and then recursively analyzing all further views that are visible through it. When it's finished, I look for another view at the current distance from start and do the same. Perhaps the best of both worlds, at least for PFov, would be to keep an initially generated set of all locations left to analyze (withing a sight range, or perhaps even within a circular outline, even though that's not a sphere in the chessboard metric (BTW, what you call manhattanDist is actually chessboardDist)), but visit them depth-first, to limit cache misses when accessing many unrelated views (of course, this is theory, benchmarks would be needed to confirm it). 
RamdaJS automatically shows a specialisation of some type signatures in the documentation.
Wow, thanks! h4skd3v knows they're trolling. They've been banned before. We could ban them again; we'd have a brief reprieve before H45KD3V (or whatever) would come back. Downvote them when they troll and move on. 
I am interested and also terrified about what might be coming. Honestly more terrified. How much implicit information with `^&gt;=` going to encode? Is there any way to know what we're heading toward? 
The documentation is accurate; no doubt about that. The problem is that colloquially I expect the explanation will be "`^&gt;=x.y.z` means `&gt;=x.y.z &amp;&amp; &lt;x.(y+1)`". In fact, that's what the announcement says: &gt; New caret-style version range operator `^&gt;=` that is equivalent to `&gt;=` intersected with an automatically inferred major upper bound. Granted there's some wiggle room there, and it goes on to talk about weak versus strong bounds (which is a brand new concept and not expressible any other way), but it seems ripe for confusion. 
What's a good Wire tutorial? All the ones I've found seem to be either out of date, or not beginner enough for me :(
https://en.wiktionary.org/wiki/Manhattan_distance And I'm not so sure on cache misses. The list of target locations is gone though lazily, so it's more like a double for loop than like an array being processed. But yeah, whatever's fastest and correct is what I'd use in the end.
In case anyone is curious, the likely root cause here is that the way we handle the compiler/linker flags in stack is kinda hacky* - we check for [the presence of certain libraries and compiler flags](https://github.com/commercialhaskell/stack/blob/master/src/Stack/Setup.hs#L579), we encode that information in a string such as `linux64-tinfo6-nopie`, lookup the corresponding entry in [stack-setup-2.yaml](https://github.com/fpco/stackage-content/blob/master/stack/stack-setup-2.yaml#L317), and then apply the compiler/linker flags from that file (which we knew from getting the string!). For added fun the string doesn't encode all the relevant information, so in practice many of them implicitly correspond to distros, and the filenames of the GHC binaries mention distros but not the underlying variant... What we really should be doing is using the flags determined locally and removing `configure-env` from `stack-setup-2.yaml`, so that we don't have duplicate entries for each possible set of compiler flags, but that kind of change is likely to break on all kinds of interesting corner cases, so I doubt anyone wants to take it on without some motivation for doing so...
How would I go about testing when passing say an environment variable to another function? What does testing that look like? More generally, how would I write a test for a function that returns an IO String ?
Yes! This would be great. Would there be a way to make it ignore exceptions that it can prove won't occur?
Yep, as they say, Manhattan is (x+y). OTOH, (max x y) is chess. Yeah, I'm not concerned about the overhead of the lazy list of locations. That's why I say in the best of both worlds it may make sense. What I'm concerned about is the list of views and that they are accessed and modified in turn, instead of focusing on one and drilling deeper --- hence cache misses, because lots of memory locations are updated in short spans of time. But perhaps it's moot for realistic dungeon sizes --- perhaps it all fits in today's caches without a problem at all (though on smartphones, which are great for roguelikes, it may still be a problem).
How do you manage your ffi calls? I had it working nicely pre jsaddle-warp, but haven't managed to make my code work with both jsaddle-warp and ghcjs. It seems to need two versions of my code managed with ifdefs (or I am doing something wrong...).
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/haskell_jp] [正しいスタティックバイナリのビルド方法が判明していた？](https://np.reddit.com/r/haskell_jp/comments/6zcbzr/正しいスタティックバイナリのビルド方法が判明していた/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
Major props to /u/saylu and /u/alexfmpe They're the ones who did the hard work! 
The [jsaddle README](https://github.com/ghcjs/jsaddle) explains it well. You don't *need* to write your FFI calls twice (once for `jsaddle` and once in raw FFI), but the JavaScript generated by GHCJS will be much faster if you do.
Oh did i do max x y? Dag. And yeah, the number of active views is usually 3 or less with this code. Unless there's like a scattering of 1x1 pillars. But for rooms and halls, very low view counts
i was talking with some folks at ICFP/HIW/etc about this precisely... theres certain type extensions folks want to have in ghc where you cant have type safety for those addons unless every effect is "explicit" (eg you can note a "may throw foo purely")
&gt; There doesn't seem to be much discussion around this project though. Any ideas why? Mentor of the student here: Mostly because we haven't been talking about it much. Ultimately, we've found the LLVM tooling around WebAssembly to be unsurprisingly extremely unstable, so most of the time has just been spent fixing up toolchain issues. These issues aren't of much interest to the Haskell community unfortunately. Work has begun on the GHC side of things, but it has (unsurprisingly) exposed further LLVM issues that need fixing. So until we really start to get to the interesting GHC-level work, like tweaking the RTS, it's hard to say much about it to the Haskell community. In the meantime, you can watch the toolchain development at [wasm-cross](https://github.com/WebGHC/wasm-cross). One of the nice things about the setup is that it's designed to work highly independently of the target, so we expect roughly the same general toolchain and Nix expressions to work for many LLVM targets. I recently got aarch64 working as a proof of concept, and am currently working on making it work for raspberry pi while Michael continues working on LLVM issues with WebAssembly.
Does this, or something like it, help you? https://hackage.haskell.org/package/QuickCheck-2.10.0.1/docs/Test-QuickCheck-Monadic.html#v:monadicIO How does that function create the IO string? You should, as much as possible, separate your code into IO-stuff and pure-stuff. You will have some logic that gets input from the outside world, and this should be as simple as possible. Ideally it's so simple it doesn't require testing. The pure-stuff contains all your business logic can be tested as normal.
You might also find it interesting to look at [Concur](https://github.com/ajnsit/concur) which is a new Haskell Web UI framework I've recently started working on. It's sort of midway between Elm and Reflex and tries to fix some of the conceptual problems with both. I answered a question about how it compares with Elm/Miso [Here](https://github.com/ajnsit/concur/issues/1).
FYI https://ghc.haskell.org/trac/ghc/wiki/Plugins/TypeChecker/RowTypes/Coxswain
Too caught up and lazy to look at more frontend frameworks :) And anyways, I'm not adopting anything on GHCJS till the tooling is fixed. If you are spending time on GHCJS, I'd strongly recommend contributing to the tooling problem first. I'm happy to sponsor [some bounties](http://www.vacationlabs.com/haskell-bounty-program) for quick wins.
Would you like to contribute these benchmarks? We have three [1] people who can guide you now. But beware, the PR is likely to get rejected because the benchmarks-repo maintainer doesn't like the GHCJS build environment (it downloads many gigabytes of data and seems to cause timeouts in Travis or Circle CI). [1] /u/saurabhnanda /u/alexfmpe &amp; /u/saylu
IMO, either jsaddle should be part of GHCJS itself (and needs to be maintained in lock-step with the complier+base libraries) OR the major editors (Intero, Atom, VScode, etc) need to be able to talk to GHCJS natively.
Isn't 2 minutes very long? What does `-O0` look like? Anything more than a couple of seconds prohibits a rapid code-compile-debug loop, which is essential when you're dealign with HTML.
There's code to handle sum types in a fully-generalized way (exactly what you two are discussing), it's just been sitting in a PR for a year https://github.com/reflex-frp/reflex-dom/pull/115
Just as a small note, if you use MP4 instead of gif, you can use gif-v or webm and the animated image will be *way* smaller in size without looking like crap. Fun project though!
Wow. This comes at a good time. I wonder how many of the complaints about records in Haskell this addresses (also especially relevant https://www.reddit.com/r/haskell/comments/6xkqk7/why_has_row_polymorphism_not_made_it_into_haskell/). What are the common shortcomings of other approaches in Haskell? I can never remember. This makes me want to learn about GHC plugins even more, and also find a way to torture type classes for a comparable result.
This is fixed now -- me being a terrible VimScripter... :)
Great! I wrote a bit about it in the readme: https://github.com/owickstrom/neovim-ghci#using-the-stack-repl
Hm? GHCJS and jsaddle do two completely different things. One is a cross-compiler, and the other is a library used with various GHC versions, including GHCJS. There's not really much sense tying jsaddle to GHCJS when it's equally meant to exist with GHC native and GHC cross. I don't really see what this would get you either. You'd still have to maintain separate setups for the warp and ghcjs builds of a jsaddle app. And GHCJS *definitely* won't be getting decent support from editor tooling any time soon. Frankly, it's a miracle it's got the *build* tooling it has. The only reason it does is because there's a network of special cases and workarounds for making it so. The fundamental problem is that GHC and most tools are not extremely friendly to cross compilation (of which GHCJS is just a funky form). The problem with editor tooling specifically is that it tends to need interactive GHC (ghc-mod just uses GHC as a library IIRC, but this of course incurs a different set of problems when cross compiling). GHCJS used to have interactive support in 7.10, but it never got updated for 8.0, and I don't think it was particularly friendly to editor tools (IIRC, you had to connect a browser to it before you could start doing anything). There has recently been a bunch of work on the new `iserv` feature in GHC proper, which will solve the problem much more generally (for many kinds of cross targets). But GHCJS isn't even updated for 8.2 yet; it'll take a nontrivial change to make it work with `iserv` (not that I'm even sure that's the right approach). Though again, I don't see how editor integration solves the problem with needing an entirely different build process for the developer-friendly warp version of your app. TL;DR: Cross compiling is hard. GHCJS is just a weird little cross compiler. Making tools work together is a ton of work.
No splits are a dealbreaker for me. But i really love the new keybindings
Great work 
&gt; GHCJS and jsaddle do two completely different things. They might be doing different things from a purely technical standpoint, but don't you think most people using GHCJS would need to get jsaddle (or something similar) working to solve the editor tooling problem? If there is an easier way to solve the editor tooling problem, obviously, that should be given higher priority. Whatever it is, it should come packaged with GHCJS to allow devs to get up &amp; running with a sane dev-environment without fiddling around too much.
Getting jsaddle working is mainly a matter of depending on the library and throwing the right compiler at it =P It's not really a hassle at all, and doesn't have much to do with GHCJS in particular. The worst part about it is that the default for GHC is the webkit-gtk build, which works fine, but I prefer the warp build. Switching it requires depending on `jsaddle-warp` and calling a slightly different function in `main`. Slightly annoying, but still pretty painless. Ultimately I think the issue is, as always, documentation =/
Do you wrap every use of `div` or `/`? Those can throw exceptions, after all! I don't. The thing is, using Maybe or Either has a real cost: it makes your code significantly more complex and harder to follow. It's plain *awkward*. And in a large, living, day-to-day codebase, avoiding awkwardness is a real priority—for which I'm willing to sacrifice *some* safety. My philosophy is simple: I use Maybe/Either/etc if an error is both *expected* and *recoverable*. Otherwise, I actively *prefer* exceptions. An error is *expected* if it's the result of an incorrect input to my program. It is *unexpected* if it's the result of an incorrect assumption or bug in my code. An illustrative example is indexing into an array or map: if the keys come from the outside, I'll use the Maybe-based functions and have explicit logic if they're wrong. If the keys are generated by my program and *should* be correct, I'll use the lookup functions that throw exceptions. Recoverability is the other thing to consider: can I do something meaningful about an error? If all I can ever do is log an error and abort the thread or process, I would *prefer* throwing an exception. If the command-line arguments to my program are malformed, I'm just going to fail with an error message anyhow. In these cases, I actually often turn Maybe and Either values into exceptions—our work codebase is full of this because we run a bunch of distinct computations on different threads/processes and have a monitor that logs and kills any computations that error out without affecting the rest.
I would potentially be able to do so yeah. Don't you already have GHCJS projects (reflex dom)? So I'm confused at to why adding another GHCJS project would make much difference. 
Good stuff!
I wouldn't recommend anyone adopt Concur in production at this time (or atleast not blame me when things go wrong) :) It needs a lot more real world testing of its core model (using a monad to handle events) which is a little bit radical. If anyone does get time to *play* with it, I would really appreciate feedback! GHCJS tooling (Spacemacs + Intero) usually works for me when nix isn't involved. But I haven't yet spent time adding the appropriate config and deps to Concur. I do plan to do that eventually.
&gt; torture type classes Hasochism! 
Two issues I have with this: * It makes it harder for newer, possibly better but unfamiliar, solutions to gain traction. Thinking along the line of: "This newfangled parser package has 10x less stars than Parsec so why even bother trying it?" * It makes github's bookmarking feature useless. I bookmark interesting projects I want to look at again later when more development has happened without necessarily being updated of all activity with "watch." If I bookmark all the dependencies of my various projects, the ones I actually care about will get harder and harder to find.
I can't actually answer your question, but 1. The new join point system is still in flux, with further substantial changes planned. 2. I see you're using 8.2.1 or so [*], which as a result of point 1 seems a bit out of date already. So you might find things making more sense when 8.4 comes out. [*] I know this because GHC HEAD hasn't produced `case tagToEnum# e of` for several months. That's always rewritten to case match on the tag.
Fair enough.
I remapped it too, but I use M-c and it's working really well
[removed]
That's not really an answer to your question, but I really like `stack test --fast --file-watch` for testing things. That's a turn-around time of maybe 2-3s, though I don't really work on large projects, so YMMV.
Exactly what I wondered when seeing the Movie Monad post the other day!
Knowing exactly which exceptions a function can throw is surely undecidable since `f = g &gt;&gt; h` throws the exceptions of `h`only if `g` terminates. It becomes even more impractical if you want to consider catching the exceptions (which I think you probably do want, otherwise every exception leaks through). `f n = if collatz n then g else catch g` or something like that.
We don't have a problem, it's the benchmark repo maintainer who doesn't seem to be too fond of it :) -- https://github.com/krausest/js-framework-benchmark/pull/214#issuecomment-315847194 Although if enough people submit PRs and have a viable way to get the benchmarks to build consistently on local dev machines and the CI environment, he'll be more than happy to merge.
&gt; Ultimately I think the issue is, as always, documentation =/ Could very well be. As a user, one definitely gets fatigued trying to figure everything out via IRC, Slack, Github issues, etc. This is the reason I gave up when it came to nix. ("Gawd, not another build tool. What's wrong with stack? Are we trying to compete with the javascript community with so many build tools?")
Why would I use cabal-install instead of Stack now?
I'm curious to know too!
&gt; The downside is that it requires thinking about exactly what parts of your dom will change and when, to avoid unnecessary redraws. The same is true for react or any other dom-diffing approach too though, because if you don't split/structure your compontents "smart enough" you'll still get lots of redraws. It's still probably a bit easier to think about this issue when having clear components...
&gt; seems to cause timeouts in Travis or Circle CI You can get around that (at least with Circle CI) with proper caching. See the [superrecord .circleci/config.yml](https://github.com/agrafix/superrecord/blob/ec031e9649104d50dcf5be904ae3e21c554fb0d3/.circleci/config.yml#L31-L61) for example.
Regardless of whether `g` terminates, `f` is capable of throwing an exception if either `g` or `h` throw an exception. That's the kind of information that I'd like to know. You don't need to know whether something terminates or not. It's true that you could filter out exceptions by type given a `catch`. That would be useful.
If `g` doesn't terminate then it doesn't matter what `h` is. If you just blindly propagate all the exceptions from all the functions mentioned, I think you'd very quickly get to a mess of useless information. However, I have no evidence to support this.
What's your goal with this language? How will it compare to Haskell for example?
Either the author accidentally made `g` an infinite loop, or they accidentally put `h` after an intentional infinite loop `g`, in either case: **that's a bug**. People tend not to publish code with bugs like that. It happens, but not on the scale you're implying. If anything, tool like the one I'm proposing would aid you in noticing that a function seems to throw more things than you expected.
Right, that's what I had in mind. All `error`, `throw` and `throwIO` are defined in terms of `#raise`, so really you'd look for `raise`, and then propagate upwards anything defined in terms of that and so on.
You could, I suppose, also add something that would go through all your exported functions and add like a `@throws Foo` in the docstring. 
Ok sure, but that's the simplest case of "function MIGHT throw". The more complicated case where you need to consider catches has the same problem, but you can't really say something is a bug because you can't statically determine if the exception is caught or not.
This is something I've been thinking about and I think this gets really unwieldly unless the language supports first class extensible records(Purescript) or open unions (Dotty/Scala3). The reason I say this is because sum types don't work well for representing possible error values that a function can return. Imagine we have two layers of function with the following call graph: (e.g. `funcA1` calls `funcC2` and `funcE2`) funcA1 funcB1 | \ / | funcC2 funcD2 funcE2 All of layer 2 (funcX2) can fail with errors. Let's say they only have one error type each so for example `funcC2` has the signature `Either ErrorC2 ()`. What should the signature be for `funcA1` and `funcB1`? You will need to construct a new sum type for each of `funcA1` and `funcB2`. Now imagine you have 3 layers of this (Validation/Business Logic/Database Access) where each layer can have its own failures. When I tried this for the sake of typesafety the result was: * Extremely unwiedly to write and refactor * Not helpful at all - because 99% of the time you simply just rewrap the error and pass it up * Doesn't really provide any more safety than simply catching exceptions at the top layer and you often don't pattern match on the sum type so the exhaustiveness benefit is not even exploited. I'm really hoping that there's a solution out there that I'm not aware of, as this issue has been on my mind for a while. Please tell me there's a solution! :) 
The simplest case, sure, and probably the only one that's interesting. False-positives are OK in light of dead code. If there's a throwable expression in the code, the only way it won't be thrown at some point eventually, is if it's dead code. `if False then error "Boo!" else return ()` is an example of dead code. If the author created an algorithm like `if x%7 then error "No!" else 99`, you don't have to prove that `x%7` can be encountered. The author intended that it would. Do you have an example demonstrating something different? I think a `catch` is a different discussion, that's a reasonable way of pruning but it seems like you're saying you need to prove reachability of codepaths for the data to be useful.
Could you tell me where is defined `requireUser` in [src/Web.hs](https://github.com/eckyputrady/haskell-scotty-realworld-example-app/blob/ff931551cf562f5181deae0a5732596a90bfa561/src/Web.hs#L74) ? I can't find it :(
Here you go https://github.com/eckyputrady/haskell-scotty-realworld-example-app/blob/master/src/Web.hs#L226 :)
An automatic solver is very much appreciated for dependent types or at least a tactic system. Furthermore, refinement types have nice programming properties.
Sure, I concede that you might as well ignore reachability when looking for possible throws exceptions. What I'm saying is that it seems like you need to handle exception catching for the data to be useful at all. Determining the minimal set of exceptions that may be left uncaught is definitely undecidable. The question is whether we can get close enough to it to be useful. If `head` only throws when it encounters an empty list, then saying that every function that calls head may also throw, is too pessimistic. The condition under which a function throws can be arbitrary complicated, and its complexity is entirely unrelated to how likely it is for it to be satisfied. 
Basically, to demonstrate that a general purpose, Turing incomplete language is possible, pragmatic and offers advantages (in comparison to Turing complete ones), in that order.
I'm using Data.Text to work with strings but instead of my code looking nice like this: strvar ++ "additional" ++ var2 ++ ' ' : var3 It looks like strvar `T.append` "additional" `T.append` var2 `T.append` ' ' `T.cons` var3 Which looks way less nice and cluttered. How do I get my code readable when working with Text? 
http://hackage.haskell.org/package/union-0.1.1.2/docs/Data-Union.html is at least an option to help avoid nested `Either`s.
itshappening.gif One thing I'm particularly excited about is how this allows real type-level sets, instead of lists normal-formed by sorting (since you can't use `~` with those).
[itshappening.gif](http://i.imgur.com/Hf1yqgr.gif) --- ^(*Feedback welcome at /r/image_linker_bot* | )[^(Disable)](https://www.reddit.com/message/compose/?to=image_linker_bot&amp;subject=Ignore%20request&amp;message=ignore%20me)^( with "ignore me" via reply or PM) 
You may want to look at Gremlin (rebranded as TinkerPop now it has moved to Apache) for a graph query language http://tinkerpop.apache.org/ (and I'm too lazy to check hackage to see if there's already a Haskell interface to it)
There would be some type-level changes needed as well. Types would have to be positive, or perhaps strictly positive. We'd presumably have to give up `TypeInType`. I don't really know what else.
Interesting. I guess one of the advantages would guaranteeing that programs won't get stuck?
Thanks, works fine now. I just needed to fix up my ghci prompt (used %s before) to make it static.
On a similar note to the last proposal, I've often thought about just demanding that operators have spaces on either side, with an exception for when they're directly adjacent to parens, as in sections (although the PureScript `(_ + 1)` syntax arguably has something going for it in case greater uniformity is required.) This would allow a wider range of operator/function names (edit: to be more specific, arbitrary strings of `[^\s()]`). Maybe this is Agda envy (I don't even know how Agda is lexed), maybe not.
I'm not sure if you've tried this, but rapid edit-compile-reload cycles could be served well by *interpreting* code instead while developing. You get the type-safety of Haskell EDSL templating while not having to deal with compile times at all. I've had a very nice experience building a Hakyll site that uses Lucid for templates and Clay for CSS, interpreting (`runghc`) files that output HTML or CSS that I write to `.html`/`.css` files. Reloads, at least for my case, are instant. https://jaspervdj.be/hakyll/tutorials/using-clay-with-hakyll.html
I always like thinking about syntax ideas and this has been on my mind since talking to Joachim at ICFP: map (10 * 20 +) [1..10] could be written as (xpost from Twitter) n…m = [n..m] map 10*20+ 1…10
Just tried it: a big page takes with -O3: 2min 30sec -O1: 2min -O0: 10 sec So it's not that bad with -O0, and with smaller pages or pages which are partly written in blaze it's nearly instant. Note that -O3 runs possibly faster on your machine, my machine has only barely enough memory (-O3 eats 4GB ram here). Anyway, I'll dig into why -O0 is so slow and push a new version if I can improve it (actually I think that it's quite possible to compile in 2 sec).
Thanks for posting this. While I am not keen the [context fixes proposal](https://github.com/ghc-proposals/ghc-proposals/pull/40), I really like the bulleted argument lists idea. When I have a function that takes several lengthy arguments, I basically already do this, except that I have to put parentheses around all of them. The bullet character, being non-ASCII, is objectionable, and I think I would prefer a keyword to introduce a section. So, for the example that Joachim gave: foo :: Baz foo = bracket • some complicated code that is evaluated first • other complicated code for later • even more complicated code I would rather have something like this (I'm using `argdo` as the keyword to introduce it): foo :: Baz foo = bracket argdo some complicated code that is evaluated first other complicated code for later even more complicated code I know that "argument do" already means something different in the haskell community, but I'm using the term to mean something else here.
Running interpreted in haskell is actually like compiling with -O0, see comment below. The type checker is just *very* busy in my case (you have to use -freduction-depth=0). But I'm sure to remove a lot of intermediate types. Consider that this lib was written in ~7 days (well, I started 2 months ago, but had only limited free time).
It's not just that: templating in files that you include into a larger library means any files dependent on your templates will also be recompiled, while the "output HTML to external file" approach avoids that (for a slightly less elegant setup).
I think it might shed some light on the whole exceptions vs explicit return types debate. Darwin226 is suggesting the result might be so huge that it would not be useful, but that would be an interesting result imo.
That’s a nice variant, although I think I prefer the clear visual marker at the beginning of the line. The `•` is just an example. If we are willing to steal syntax with this extension, then I’m fine with using simply `*`.
`analyzeExpr`... That seems rather wordy?! :) Re: Bullets, I think we could use an alias for `($)` which associates to the left for this. (§) = ($) infixl 1 § function § first very long argument § other very long argument § imagine more words Assuming we get fixity right (0 or 1?), we probably wouldn't need an extension. Unless we want this to interact with other syntax such as `do` notation. 
Is the proposal about `section` is strictly equivalent to the introduction of a subfunction? Such as: analyseExpr :: Bool -&gt; Expr -&gt; Expr analyseExpr flag = go where go :: Expr -&gt; Expr go (Var v) = .... If yes, I don't see the motivation for a new syntax. **edit**: I understand now, the article says: &gt; Consider a bunch of related functions So the issue is about syntax for many functions at the same time, which is achieved with the proposed syntax but not with the `go`. I'm still wondering, but I understand the use case. 
Seconded. I use this approach a lot, but don't generally repeat the type signature.
I haven't done much rust, but I really like their solution. There are no exceptions. Everything that could possibly error returns `Result`, which is effectively an `Either SomeError Result`. There's a macro you use to compose functions together that return this type so that you don't end with case matching indentation creep. Then in your example `funcA1` and `funcB1` are part of the same program, so you are supposed to have a `ProgramError` type that encompasses all of `Error{c,d,e}2`, and you are expected to fmap those errors into a `ProgramError`. And lastly, their `Result` type has an unwrap function that blatantly ignores the error, so that you can write quick scripts without having to catch every error, but they show you exactly where you are ignoring errors. Maybe there is some problem that doesn't solve that I'm missing, probably asynchronous stuff, but it seems really elegant to me.
Text has a Monoid instance, so you can use `&lt;&gt;`. (If you append together a text out of a lot of parts you might get better performance by using Data.Text.Lazy.Builder. Probably not noticeable for small amounts though.)
It could also be written as let meaningfulName x = 10 * 20 + x in map meaningfulName [1..10] What you're suggesting - and perhaps what is being suggested by Joachim - is closer to the Perl 6 spirit of things. I'm not making the trite "bad syntax == Perl!!!11!" argument, this is genuinely the kind of syntax the Perl 6 team explore, and personally I think less is more, when it comes to syntax, even if it literally means writing more.
I'll repeat some of my thoughts from Twitter, alternative syntax for contexts -- top-level let let flag in ... -- top-level lambda \flag -&gt; ... 
Does it even need an operator? Can't layout solve this? foo :: Baz foo = bracket x y z Means foo :: Baz foo = bracket x y z While foo :: Baz foo = bracket x alpha y beta gamma z Means foo :: Baz foo = bracket (x alpha) (y beta gamma) z It could also be written as foo :: Baz foo = bracket x alpha y beta gamma z This is a variant of/inspired by Z by /u/chrisdone (/u/chrisdone2 or /u/chrisdoner ?) http://chrisdone.com/z/
I recall reading in one of the first dependently typed Haskell papers that even before `TypeInType` that Haskell was inconsistent as a logic.
IIRC, `--file-watch` doesn't work if you change a file in another package, unfortunately.
I agree, catching is tricky and something to think about. If a function has a catch-all of SomeException and then throws that `e`, we don't really know what's inside it. 
Agda's lexer IIRC basically treats everything that's not a parenthesis as a valid identifier character.
That is actually how I originally envisioned this feature. But upon further reflection, I prefer a clearly visible marker rather than simply a line break with indention. I think the eye likes visual anchors.
Right, that is one way forward. The fixity we’d want is, I think, `-1`, so that it binds less tightly than `$`… Also, it would not allow function § first very long argument § other very long argument with § its own § complex arguments § imagine more words And finally I believe that function § first very long argument § arg1 § arg 2 § arg3 with more stuff and somewhere § arg 4 is more obfuscating than helpful, and hence enforcing the layout to have the bullets to be vertically aligned is IMHO a good thing.
Personally, I love handling exceptions with maybe/either, or even better, [Chronicle](https://hackage.haskell.org/package/these-0.7.4/docs/Control-Monad-Chronicle.html) when I need to do more complex exception handling.
To each their own but I personally agree with /u/ocharles, partially out of consistency, so far no other Haskell language feature has required both newlines and a preceding mark. They have either required just newlines (or replacing those newlines with some combination of `;` and `{}`), such as `case`, `do`, `where`, `let`. Or they have required some other symbol and the newlines have been optional, such as guards and list / tuple notation. Hell the feature you want can almost be implemented already, without a preceding mark, with `RebindableSyntax`, there is just an associativity issue: foo = do (+ 5) 4 where (&gt;&gt;) = id Works, but unfortunately: foo = do (+) 5 4 where (&gt;&gt;) = id desugars to: (+) (5 4) instead of what we want: ((+) 5) 4
Not an answer, since I'm in the same boat as you, but `idris-mode` is alien-cool for type development: auto completion, guessing what you want, case splitting, etc.
&gt; Does this overrule operator precedence? Yes! `a * b+c == a * (b+c)`. Now, THIS is going to enable some impossible to detect/debug typos..! I'm impartial on proposal one and two, but the last one is just terrible! 
On a tangent, I really wish people would write analyseExpr :: Bool -&gt; Expr -&gt; Expr analyseExpr flag = analyseExpr_flag where analyseExpr_flag :: Expr -&gt; Expr analyseExpr_flag (Var v) = .... It makes it a lot easier to see that you're doing something sensible.
[Duet](http://chrisdone.com/toys/duet-delta/) requires operators have spaces on either side. This means you can write `2 - -4` or `(- 2)` (though I haven't implemented sections) unambiguously. But then it also demands parentheses when using more than one operator at a time. That's more for the sake of newbies, and also because I'll be implementing a semantic editor for it anyway (a la [Lamdu](http://www.lamdu.org/) or [Unison](http://unisonweb.org/2016-03-16/semantic-vs-text.html)), so syntactic conveniences are no longer necessary, and rendering/layout of code is no longer a developer concern.
What specifically are the issues with GHCJS in terms of tooling? I have personally just used `ghcjs-base-stub` and `GHC` to get `hdevtools` and `ghci` working, then I just have `GHCJS` compile the final javascript output. So far this workflow has worked great for me. It would be kind of nice to just use `GHCJS` for everything, but it's definitely not a blocker for me.
I just wanted to say thanks for doing this, for me personally the biggest thing missing from Haskell is the ability to run it performantly on web / mobile, so between your project and reflex mobile I'll soon be able to efficiently use Haskell for basically everything I do. I also think that both of those projects could be huge for Haskell's market share, since it could put Haskell into best in class territory for cross platform front end development.
Yup I agree &gt; this is genuinely the kind of syntax the Perl 6 team *explore* Exploring is the right word, I explore different points in the design space for a good while before focusing on problems with it. There is no commitment in *considering* ideas and this helps me entertain multiple (possibly contradictory) ideas while pushing them to their limit which helps me understand them better
I don't get this part: interface State X = get : X | put : X -&gt; Unit dropEverySecond ( x :: xr ) = put ( not get !); if get ! { x ::( dropEverySecond xr ) } { dropEverySecond xr } `get`'s type is not that of a thunk so why does it need forcing? And why doesn't `put` require being forced too in that case? I guess that applying it to `not get!` already implies forcing it?
How powerful are type-checker plugins? Which GHC-Extensions could be written as one?
I use [`:kind!`](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/ghci.html#ghci-cmd-:kind) a lot. &gt; [...] If you specify the optional “!”, GHC will in addition normalise the type by expanding out type synonyms and evaluating type-function applications, and display the normalised result.
A frequent source of frustration for me is not being able to partially apply type-families or type-synonyms. However, type-classes can be partially applied. So, using type-classes instead of type-families when possible, even if a bit more awkward, can be handy. 
I like this variant a lot, especially since presumably it can reuse the existing machinery for layout. This is nice for implementors (who will have to write less parser code) *and* for users (who won't have to understand a new kind of indentation rule that includes an extra "line herald").
Type checker plugins allow you to reduce type-level expressions in a way that normally couldn't happen. For example, if I were using [`GHC.TypeLits`](http://hackage.haskell.org/package/base-4.10.0.0/docs/GHC-TypeLits.html) and had a constraint like this: ((5 + a) ~ 55) Normally, GHC would get stuck. With an appropriate typechecker plugin, this constraint would get simplified to: 50 ~ a To my knowledge, there are no GHC extensions that could be written as type-checker plugins.
Re bullets: why not make the function take on option record, and then explicitly write out field names? import Control.Exception.Brackety thing = bracket def { allocate = ... , release = .... , operation = .... } No new syntax is involved, and people would have nice hints about the parameters. Now, it might not play nicely with partial application (but then neither does the bulleted approach). or wrap the args in newtypes (so partial application is a bit more tractable)? import Control.Exception.ILoveNewtypes thing = bracket (Allocate $ ...) (Release $ ...) (Operation $ ...) Sorry for adding the parens though ;)
Most interestingly, it's not even a percent slower without the elision. That was definitely different with older internals... Thanks for pointing at that, it indeed simplifies the internals and speeds up a little bit compilation...
Or, without changing anything, you can already do this: thing = uncurry3 bracket ( allocate , release , operation ) 
Looking at your reddit profile, I may be engaging a troll, but I have to ask -- can you elaborate on the following with some examples: &gt; The former is what real programming problems needs. The latter does not solve real world problems and introduce new ones.
Is there anywhere I can read more about duet?
 {-# LANGUAGE RebindableSyntax #-} {-# LANGUAGE OverloadedStrings #-} import Prelude hiding (Monad ((&gt;&gt;))) import Data.String (IsString (..)) import Data.Char (toUpper) ------------------------------------------------------------------------------- -- Expression ------------------------------------------------------------------------------- data Expr = Lit String | App [Expr] deriving Show instance IsString Expr where fromString = Lit expr2 :: Expr -&gt; Expr -&gt; Expr expr2 f a = App [f,a] expr3 :: Expr -&gt; Expr -&gt; Expr -&gt; Expr expr3 f a b = App [f,a,b] ------------------------------------------------------------------------------- -- Boom ------------------------------------------------------------------------------- newtype M f b = M (f -&gt; b) (&gt;&gt;) :: M f g -&gt; M g h -&gt; M f h M fg &gt;&gt; M gh = M (gh . fg) bb :: a -&gt; M (a -&gt; b) b bb x = M (\f -&gt; f x) ($$) :: f -&gt; M f b -&gt; b f $$ M fb = fb f infixr 0 $$ ------------------------------------------------------------------------------- -- Example ------------------------------------------------------------------------------- -- | -- -- &gt;&gt;&gt; ex -- App [Lit "very long 1",App [Lit "very long 2",Lit "very long 3"],Lit "VERY LONG 4 AND MORE"] ex :: Expr ex = expr3 $$ do bb $ "very long 1" bb $ expr2 $$ do bb "very long 2" bb "very long 3" bb $ fromString $ map toUpper $ "very long 4" ++ " and more" 
You can still do this trick for multiple functions at the same time: (analyseExpr, analyseAlt) = distribute section where section :: Flag -&gt; (Expr -&gt; Expr, Alt -&gt; Alt) section flag = (analyseExpr, analyseAlt) where analyseExpr :: Expr -&gt; Expr analyseExpr (Var v) = if flag then change1 v else change2 v analyseExpr (App e1 e2) = App (analyseExpr e1) (analyseExpr e2) analyseExpr (Lam v e) = Lam v (analyseExpr e) analyseExpr (Case scrut alts) = Case (analyseExpr scrut) (analyseAlt &lt;$&gt; alts) analyseAlt :: Alt -&gt; Alt analyseAlt (dc, pats, e) = (dc, pats, analyseExpr e) where you can define `distribute` simply as: distribute :: Functor f =&gt; f (a,b) -&gt; (f a, f b) distribute f = (fst &lt;$&gt; f, snd &lt;$&gt; f) or for various other tuple types using `HList`s. distribute :: (Functor f, Tuple t, Tuple t', HSplit (Terms t), Terms t' ~ HMap f (Terms t)) =&gt; f t -&gt; t' distribute = ofHList . hdistribute . fmap toHList Of course, a truly dedicated programmer could still flip the flag: analyseExpr (Lam v e) = Lam v (fst (section $ not flag) e) That sort of perverse perseverence can be defeated with an anonymous function and an (IHMO) slightly more awkward syntax: (analyseExpr, analyseAlt) = distribute $ \flag -&gt; let analyseExpr :: Expr -&gt; Expr -- ... in (analyseExpr, analyseAlt) 
Wow, thanks!
I think • is too easy to confuse with &amp;middot;, which is commonly used as the prettier version of `.` when talking about composition.
I don't know whether I'd want this in Haskell by default, but as a pragma I'd definitely play with it.
So there's already a request for `do` to bind differently so that instead of replicateM_ n $ do ... You'd just do replicateM_ n do ... This could easily take advantage of that as well with good whitespace handling, as `do 1` is already equivalent to `1`: foo :: Baz foo = bracket do x do alpha do y beta gamma do z 
It's equivalent to a subfunction for each individual function, so for a group of functions in a section you could just have each one rewritten by the compiler to a standalone function with a where clause. But the compiler would be able to have some magic built in to ensure that the function passed in was the same for each subfunction (although that's not necessary in the desugaring at all since this is purely for programmer convenience and the construction of the section ensures this implicitly).
I think that's the only direct advantage, but it has advantageous ramifications that I think are overlooked. One interesting thing you should be able to do, is calculate exactly how much memory and CPU time a given expression will take to evaluate. Now, performing this calculation may take as long as evaluating the expression directly (and I would like to see how true that is in practice), but I think simplified calculations could be run to determine asymptotic bounding at least. If there turns out to be a good way to calculate runtime characteristics at a significant discount to running the expression itself, imagine how we could redesign operating systems. Rather than multiprocessing systems with timer-based interrupts and unpredictable context switching, we could break down programs into chunks and allow those chunks to run to completion and still have predictable, responsive UIs. Another interesting thing about expressions that always terminate, is that you can make the whole language itself available to the type system. I suspect there are far more implications that I haven't begun to consider yet.
 function § do first very long argument § do other very long argument with § do its own § do complex arguments § do imagine more words
For what you're calling "sections", see also the [GHC implicit parameters extension] (https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#implicit-parameters).
I also would like to see h4skd3v be banned. I am in favor of putting any obstacle in his or her place, even though it's possible to just create a new account.
&gt; I think the eye likes visual anchors Yes, but they don't like noise either. If you are happy to write half of parenthesis (one character), why not write both ? I personnaly think indentation is enough and clean. Identation has already a meaning, so I don't see a problem to extend it. It also nest naturally, I think that's great. No need for new operators .
It's still a WIP and the repo for it is currently private so that I can work hermetically on it, but [here's a gist copy of its README.](https://gist.github.com/chrisdone/cee493179a95987d611164bef918d875) 
As we all know, naming variable is one of the two most difficult things in programming. `meaningfulName` is not really meaningful, `plusTwoHundred` would have been better. Also it adds a level of indirection. Maybe in fact I didn't want `10*20 + x` but `10 * (20+x)`. Seeing it in context, might make it easier to spot.
I have to admit that, as a beginner, it took me a while, to get my eyes use to "group" things around space and parse `x:f y` as `x : (f y)` (instead of `(x:f) y`). I find it especially useful with things like `map toUpper.fst` etc ... and I remember wishing `.` was tighter than space. However, when both interpretation typecheck (like in `1 * 3+5`), it can indeed become a problem.
There's a ton of really useful information in here! It's great to see it all written up... In particular, it'd probably be useful to think about how to address some of the "API Notes" in the end... I feel a lot of this could be made a bit easier, though the type checker is *not* my forte... --- Tangentially related advertisement: one of the most annoying bugs for type checker plugins currently is [GHC Issue #7414](https://ghc.haskell.org/trac/ghc/ticket/7414), which causes unnecessary recompilation when using any plugin on a module. [Clash](http://clash-lang.org) uses several GHC plugins and this is hurting us a lot in some places... I imagine if people were to use this in anger, it'd have the same problem. Any intrepid hackers who would want to fix this should try! I've been meaning to, but my TODO list is 10,000 entries long. I think it's a big barrier to plugins right now and requires a little work to fix, but isn't unreasonable. You can also say you're a GHC hacker on your resume ;) BTW: if you're doing any kind of type level arithmetic, the `ghc-typelits-*` plugins [available here](https://github.com/clash-lang) are probably useful to you as well. :)
After looking into it I don't really know what you want to know. Sorry, U'm really new to this 
There's this proposal https://github.com/ghc-proposals/ghc-proposals/pull/52
Right, that is an alternative. It does still not give the guarantee that the parameter is not changed somewhere. It also affects the type signatures inside the “context”, but that can be considered a benefit :)
That’s a nice trick! Taking this further, I am sure that with enough type level hackery, one can define an operator (let’s call it `:::`) that takes an arbitrary n-tuple on the right-hand side, and applies the correct `uncurry` on the left hand side, and one can write thing = bracket ::: ( allocate , release , operation ) Thanks for the suggestion!
I don’t think so. At least no more than the question whether currently `foo a+b` is `foo (a+b)` or `(foo a) + b`. Just like the current rule “function application binds tightest” poses no problem to us after our first few days of Haskell, this rule would pose no problems.
Thanks, was not too far I should have find it ;( edit: I missed the comment in the github search saying `Showing the top two matches`
&gt; why not write both Because I have to scan for the other one, possibly having to count nesting levels. I certainly like your variant more than not having this feature!
Correct, I discussed this in my talk. I am looking forward to `ArgumentDo` and being able to (ab)use its notation like this.
&gt; I don't even know how Agda is lexed [Parsing Mixfix Operators](http://www.cse.chalmers.se/~nad/publications/danielsson-norell-mixfix.pdf)
`coxswain` author here. Thanks Austin! The NumCols type family reductions often result in constraints like `(NumCols p + 2) + 1`etc. Other plugins will definitely be needed. So much so that I've wondered, but haven't yet checked: can one plugin "import" another?
Nice implementation of this. If we now only had syntax to get rid of the boiler plate code in your first three lines… :-)
&gt; when I try to import the files I get the error message " Could not find module ‘Test.QuickCheck’ Use -v to see a list of the files searched for." What did you mean? when did you get that message? how did you get it? Did you write a command on the command-line and got it back? Do you know how to create a program you can run from haskell source files?
I'm especially in favour of either a ban, or the removal of several chunks of the reddit community guidelines if trolling is now considered to be fine. 
Or just stick with parens. GHC is complicated enough as it is. In fact, I would be totally fine removing `$` if not for the special case with `blah $ do ...`.
Section 4.4.2 [here](https://www.haskell.org/onlinereport/decls.html) lists fixities. If we want to use `$` with this, we'd need to have a fixity of `-1`.
Cool. Will definitely look into that. At first sight: https://hackage.haskell.org/package/gremlin-haskell Looks like its also mostly string based for more complex queries,but definitely much more userfriendly! Thanks!
I *think* you might be able to get away with this right now, but it could possibly be made nicer. Because a plugin has an exported value of `plugin :: Plugin` which is just a record -- you should, in theory, be able to do something like, uhhhhhhhh import qualified GHC.Some.Plugin (plugin) as Dep neededTcPlugin :: Maybe TcPlugin neededTcPlugin = tcPlugin Dep.plugin [] -- NOTE: `tcPlugin :: [CommandLineArgs] -&gt; Maybe TcPlugin` -- hence [] myTcPlugin :: Maybe TcPlugin myTcPlugin = Just $ ... plugin :: Plugin plugin = defaultPlugin { tcPlugin = const (neededTcPlugin &gt;&gt;= myTcPlugin) } or something like that. BTW: you should also look at [ghc-tcplugin-extras](https://hackage.haskell.org/package/ghc-tcplugins-extra-0.2.1/docs/GHC-TcPluginM-Extra.html), used by Clash -- maybe you could expand on it to keep your code cleaner and more focused? Might already have some stuff you can reuse!
`coerce3'` is ambiguous. Leaving `TypeApplications` shenanigans aside, there is no context which can instantiate the type variables `c` and `c1` of `coerce3'`, because they only appear in constraints, and there is no unification at that level. Furthermore, in the body of `coerce3'`, `coerce3` can't know that it should coerce `c1` to `c`, for similar reasons. {-# LANGUAGE RankNTypes, FlexibleInstances, ConstraintKinds, PolyKinds, GADTs, MultiParamTypeClasses, ScopedTypeVariables #-} -- BTW Reify is Proxy, but less good. coerce3' :: forall c1 c a b. (MyEq c1 c, c1 a) =&gt; proxy1 c1 -&gt; proxy c -&gt; a -&gt; (forall a1. c a1 =&gt; a1 -&gt; b) -&gt; b coerce3' _ _ x = unreify2 (coerce3 (Reify2 x :: Reify2 c1) :: Reify2 c) 
Anyone able to give me some feedback on some code? It's a NES emulator, about 50% complete (CPU emulation is 99% accurate). It's my first real-world haskell project: https://github.com/dbousamra/hnes/tree/master/src
Is `ArgumentDo` going to actually happen? I had given up on it. 
I do wish libraries like `wreq` with large classes of library specific and somewhat expected exceptions would expose both `get :: Url -&gt; IO Response` and `getEither :: Url -&gt; IO (Either HTTPException Response)`, where `get url = getEither url &gt;&gt;= either throwIO return`. I end up recreating these functions seemingly often. 
 This is the easy but flawed solution, IMO. Now the error type `funcA1` is lying - its errors will never be `ErrorE2` because it never calls `funcE2`. In fantasy land we'll have something like funcA1 = do funcC2 funcD2 and the type of funcA1 will be inferred as `Either (ErrorC2 | ErrorD2) ()`. I'm not sure whether Haskell today has the mechanism to do this (with acceptable ergonomics) 
Renaming `analyseExpr` is suddenly much more work, though. Also, `go` is short, so if you use it a lot, you can have less long lines.
&gt; Typically, equality between types is defined as: &gt; &gt; newtype MyEq a b = MyEq (forall f. f a -&gt; f b) Leibniz equality? That doesn't seem like a typical Haskell representation at all. The compiler already has a constraint `a ~ b` stating that `a` and `b` can be substituted for one another, and there is already a type [a :~: b](http://hackage.haskell.org/package/base-4.10.0.0/docs/Data-Type-Equality.html#t::-126-:) whose values are witnesses that this constraint holds. I would say that `a :~: b` is a much more typical representation of type equality than `MyEq a b`, but of course the two are equivalent: {-# LANGUAGE GADTs, RankNTypes, TypeOperators #-} import Data.Type.Equality toMyEq :: a :~: b -&gt; MyEq a b toMyEq Refl = MyEq id fromMyEq :: MyEq a b -&gt; a :~: b fromMyEq (MyEq transmute) = transmute Refl &gt; I wrote the code below in order to experiment with equality for all kinds. No need to write a specialized version for kinds other than `*`, as `:~:` and `MyEq` already work both kind `*` and with other kinds: {-# LANGUAGE DataKinds, PolyKinds #-} equalTypes :: Int :~: Int equalTypes = Refl equalTypes' :: MyEq Int Int equalTypes' = MyEq id equalBools :: 'True :~: 'True equalBools = Refl equalBools' :: MyEq 'True 'True equalBools' = MyEq id 
This is awesome. The Servant implementation seems to be in need of some love, who can get it out first? https://github.com/gothinkster/realworld/issues/73
That's true. My understanding is that one of the big bits is the unrestricted structure of Haskell types. See http://vilhelms.github.io/posts/why-must-inductive-types-be-strictly-positive/ for some brief discussion, and http://okmij.org/ftp/Haskell/impredicativity-bites.html for a deeper exploration. I'm not really the best person to give a real answer here; I don't know much about the topic.
In this case I really do think documentation is the primary issue. Like I said, I only discovered this gold nugget recently. That's a shame! It's not at all hard to use!
besides `lens`, I pad every operator with whitespace anyways. 
Scotty is one of the easiest Haskell web-libraries by far! It's a shame if there isn't a good set of examples somewhere, but I'd guess there are quite a few that are just hard to find. I love how Scotty provides a lot of utility without attempting to leverage a lot of advanced Haskell type-wrangling. Not that such things aren't valuable, but it's fantastic to have a good offering on the easier end of the spectrum too.
So after a while doing research i found it. Posting it for however needs help in the future. F = 2A + 3B = 2A + 2B + B. Multiplying by 2 means left-shifting by 1bit. So. 2A = a1 a0 0, 2B = b1 b0 0, B = b1 b0. Add them vertically and you get: ---------------- S0 = b0, S1 = a0+b0+b1, S2 = a1+b1, S3=Carry of S2. Use Full Adders and print each sum. Every Cout carries as Cin to next Full Adder.
But it very much isn't an aesthetic change. It's impossible to forget about an `Either` because the compiler will tell you, but it is trivial to forget about an exception by just not catching it. I don't see how semantically it is any different than native exceptions in terms of how many times you "check" the exception. You throw the exception once just like usual by returning `Left`, and you catch it once using something like `either` or explicit pattern matching, using the applicative / monad instance when you don't feel like catching anything yet. Also I don't see how `ExceptT` involves any more boilerplate than native exceptions.
It has always been absurd to me that some people think choosing programming languages is simply a matter of taste. There are more than enough criteria that can be objectively looked at. Obviously, some depend on the suited-ness to the domain. But the context in which those languages are used is (most of the time) the human brain, with all its limitations.
Thank you. Personally in the past I basically gave up on most mods, due to reporting things that never ended up going anywhere but a hole (here, once on an old account, and elsewhere on Reddit). I apologize for the implication you aren't doing your job, I am clearly wrong about that. I also appreciate we do have mods (like yourself!) now who seem to regularly post and participate, which is necessary. I'll hit the report button from now on.
Why is `PPU` data rather than newtype?
This is a kind of rough post, not as polished as I'd like, I think? But I think it conveys the idea. Let me know if there's anything I can clarify.
Seconded. Lots of languages just can't do certain things (e.g. the equivalent of type families is really rare, you can generally get some kind of generic but good luck having associated types).
I do it even with lenses because `m^?ix i._1` looks weird to me.
I dislike the whitespace precedence option: to me, just as appealing as the sparsity of parentheses in Haskell is the liberal use of spaces. I think most people are much better at tokenizing *words* than formulas, all else being equal (e.g. leaving out mathematics-style layout flexibility) -- even in the presence of syntax highlighting.
I mean `$` has zero effect on the complexity of GHC (besides the `runST $ do` thing which is funnily enough the part you are ok with) so removing it would be just terrible, even ignoring backwards compatibility. IMO `.` and `$` and similar are massively more readable than parenthesis. foo . bar . baz . qux vs: \x -&gt; foo (bar (baz (qux x)))
Honestly I don't understand why people write `x:xs` instead of `x : xs`. The former is just asking for confusion.
Wrong sub?
Newtypes can cause a lot of naming pollution, unfortunately. Can we please have PureScript-style records someday? :(
It will contain a lot more stuff than it does now (probs ~ 10 more fields)
I *really* hate the whitespace precedence idea. I feel like I'd be stuck a programming hell of typo paranoia.
[removed]
I'm not ok with it. I just don't know the issues behind it and what it would take to get `runSt (do ...)` to work as expected. And to each their own but I find parens (or explicitly delimited expressions) vastly easier to work with when reading, writing or changing. I don't have to have fixity, operator precedence in my head when reading, moving code around is much much easier both in Emacs (due to Lisp tooling) and Vim (due to vim-surround), it would vastly simplify formatters, your editor's indenting logic has a chance in hell of knowing where you want your cursor when you Enter to a new line and so on. The last one has a lot more benefit than you might think because a lot of times wacky indentation is a huge time saver for syntax errors over waiting for the compiler to spit out some arcane error message that points 20 lines below.
We are waiting for someone to write up a proper proposal and start the process.
I guess enjoy lisp then, i'm gonna stick to Haskell. To each their own and all that, and at least within 99% of Haskell, the less-parens squad has won. In my experience reading lots of parenthesis is a nightmare, as without some severe visual assistance it often isn't obvious which parens match with which. (a b ((c d (e (((f g h (i j k) l m) n o) p)) q r) s t))
Editors offer assistance, even with this pathological example. And you wouldn't write Lisp like this any more than having long points free runs with `($)`'s and `flip`'s and `(.)(.)`'s interspersed and furthermore I'm not even advocating that Haskell convert to S-expressions. If that's all I cared about I'd have moved on to other languages a long time ago. I just have no interest in more syntactic sugar when parens work fine.
Am I missing something, or did that happen two years ago? https://ghc.haskell.org/trac/ghc/ticket/10843
* Getting GHCJS installed via stack is not as straightforward as it could be. Being asked to use something as heavy weight as nix, just for this, is not acceptable. * I couldn't get GHCJS working with intero in a reasonable amount of time (for on-the-fly typechecking, etc) * Because I couldn't get the editor properly setup, I don't know what the story for hot reloads on the browser is. They're pretty standard for UI engineering now. * Closure compiler errors out on GHCJS output. * Didn't find an easy way to do on-demand loading of JS modules with GHCJS.
Classic type classes, at least, can be converted "easily" because the basic implementation of a type class simply represents the class instances as a data structure itself. Is this what you mean? In other words, the type class: class Exp a where dlit :: Int -&gt; a dneg :: a -&gt; a dadd :: a -&gt; a -&gt; a Is the same as: data ExpDict a = ExpDict { dlit :: Int -&gt; a , dneg :: a -&gt; a , dadd :: a -&gt; a -&gt; a } where every instance of `class Exp a` becomes a *value* of type `:: ExpDict a`. If you wrote an instance `instance Exp Foo`, then you'd have values of type `:: ExpDict Foo`. Then you pass those values around and use them to call type class methods. When you write the first example, GHC internally translates instances into the second example (essentially). The BB-encoding of `ExpDict` can then be given by: newtype ExpBB = ExpBB { unExpBB :: forall a. ((Int -&gt; a) -&gt; (a -&gt; a) -&gt; (a -&gt; a -&gt; a) -&gt; a) } This is in fact, the exact same data type given in Oleg Kiselyov's [Beyond Church encoding: Boehm-Berarducci isomorphism of algebraic data types and polymorphic lambda-terms](http://okmij.org/ftp/tagless-final/course/Boehm-Berarducci.html) writeup. (I just converted `ExpDict` type into a type class, essentially, so you can see that part, since Oleg does not show it.) --- It's unclear to me how well this basic idea holds up in the face of the &lt;infinite&gt; type class extensions we have, so perhaps someone else can elaborate. (I was never very good at this stuff.)
I think it does. It is more rules and more rules is always worse than less rules. Even more so when additional rules are just for superficial enhancement. When one is tired, It is easy to stare for an hour at a snippet, with a bug that involve this and not recognize the issue...
It works better with Nix, and I believe it might be slightly more friendly to cross compilation.
Wow. I'm tremendously stupid! Hahaha. It's absolutely obvious, thanks. Let me give a little bit of context and this will make what was on my mind a little bit more clear. When I found out about BB encoding (and other similar ones) I got very excited because with them I can simulate ADTs in other languages that doesn't have them. In particular, I could use sum types in Python and Go without emulating them with a verbose inheritance. Not that I intended to use them in real code, mind you. It's just that I could play for a bit. In Python it's very convenient and with the new type annotations I even managed to have some typeclasses encodes as Python classes. But in Go it's more difficult because you can't in principle parametrize a Go interfaces by a type, so I couldn't use the same workaround I used in Python. So I guess I asked the wrong question. My problem was not knowing how to encode typeclasses – that's trivial – it was how to parametrize them in a language with no parametric polymorphism. --- exit: I'm clearly way over my head. I have to read more about this. 
* You just copy paste some text into your stack.yaml and call `stack setup` don't you? That's what I remember doing. * I just use GHC + hdevtools + hlint for on the fly typechecking, so I guess I just don't run into that issue. * Not sure on that one to be honest. I often have my build script auto run on file change, so then once I'm done editing I refresh my browser and have the new program. Is hot reloads talking about not even refreshing the browser, seems kinda low priority to me. * That seems like closure's fault, unless GHCJS's output is invalid JS, which doesn't seem right since GHCJS's output seems to run fine on every browser I have tested it on. * Not sure about that one, I just use script tags to load the relevant libraries. Usually I just need like 1 or 2 js libraries (e.g react + react-dom) then the rest is in Haskell.
All of what you have told me are workarounds and hacks. GHCJS tooling (and docs) are far from ideal and the sooner they are fixed, the faster adoption will accelerate. Try developing in Angular JS v2 to understand what I'm trying to say. 
The first point is a hack? Literally copy pasting a small amount of text and pressing `stack setup` is a hack? The second point is also hardly a hack, if all you are doing is typechecking and finding which functions are in scope and so on, then why would you use a JS specific compiler, just use the standard one. 3rd and 5th one are so-so, but have not at all negatively affected my dev experience. And lol what, the 4th one is literally just pointing out it might not be GHCJS's fault, how is that a workaround or a hack? Sure GHCJS tooling and docs can improve, but it doesn't take a rockstar dev to do just wonderfully working with GHCJS. &gt; Try developing in Angular JS v2 to understand what I'm trying to say. Lol no, any possible advantages of the tooling get obliterated by the fact that I'm back to dealing with GarbageScript. I'll pass. You should probably try actually looking into my bullet points and perhaps discussing them one by one, rather than making a statement with no evidence and that is objectively at least partially incorrect.
I'm sorry - - I'll pass on this conversation. You and I have different opinions on what is considered "good tooling" and no amount of back and forth on a purely technical level is going to bridge this gap. I'm rooting for GHCJS btw. It's a fine piece of engineering. It just saddens me why people just abhor giving it the final spit &amp; polish it needs to become a rock solid product.
I'd appreciate an actual response to each of my 5 points rather than an at least partially incorrect blanket statement. But I guess I can't force you. And I mean if you aren't willing to do the final spit and polish yourself not pay someone to do it you really cannot judge IMO. 
As the mod team we choose our battles. Sometimes it's best to leave a trolling comment and let the community downvote it into oblivion. It sends a clear signal to anyone reading that the sentiments/tone are unacceptable. Same goes for the downvotes on your comment, and the reports about it... 
As the mod team we lean more towards quelling unnecessary drama than obliterating every comment that rubs someone the wrong way. As soon as someone mentions `stack` there is a sudden upsurge in reports coming in, and acerbic comments from both "sides" of this distracting storm in a teapot. I think we've repeatedly shown ourselves to be pretty good at *pragmatically* using our mod tools to steer the subreddit away from civil wars. Ultimately, though, I believe that this is all open for debate. Metadiscussions have a strong tendency to devolve into bitter wars of words which leave all sides jaded and distract us from the real reason we're here; but the subreddit's rules -- and even the modteam's conduct and role -- are always open for discussion. 
I _so_ wish I could agree with you both, but study after study fail to definitively separate languages. Programming in Haskell feels like building with I-beams and bolts, rather than sticks and mud, but I fail to convince my colleagues. Please point to the data.
I'm a fan of the modteam and the work they do. I was only trying to point out the conflict between having this: Warn in private, Warn in public, Then take action. and this: 1) Obvious trolls are obvious, and also useless, so they will be removed with extreme prejudice. in the Community Guidelines, and a statement from a mod saying that they're not going to ban someone they know is an obvious troll. If it's on us to downvote the trolls rather than the mods banning them, that might be fine - my only point was that if that is the case, then the Community Guidelines should probably be updated to reflect that so that people know how things are.
It's possible to do anything with a Turing complete language. You can create your own type families in javascript by making another programming language. Would you want to? Hell No! Not when there's already many great languages out there. If you're writing a language in js you're doing something seriously wrong. But in the end, everything becomes machine code which is the true limiting factor. Haskell and other programming languages are great because of the things that are abstracted away, but in the end, anything possible with one language is possible with another, just with a lot more work. Except some esoteric ones.
Yes, using exceptions are bad practice. Unfortunately, they are making a recent come back, which results in lots of libraries that cannot be used. History repeats and all that. Here is a library that works around it to some extent: https://hackage.haskell.org/package/spoon
Your page is very hard to read on a mobile!
It's extremely good to have such a comprehensive overview of the costs of laziness in one place like this. This is the sort of thing that ought to go in a book or on the wiki.
cool study! interesting that they take the angle that language choice affects your way of thinking. i think the much more obvious problem though is that when trusting study results, we really trust the algorithms and code written by non-programmers under time pressure without much of a type system to help them avoid at least the trivial mistakes.
When you rename a function you have to change all its definition sites and all its use sites. This is no different.
`runSt (do ...)` does work as expected. It's `$` that needs the special rules.
While we're here, what are peoples thoughts on `-XStrictData`? I like to use it as `default-extensions` (and add explicit lazy `~` when applicable) for code no one else has to work on, but I can see why this would annoy/confuse collaborators. Is there any reason not to accept it as a best-practice?
that's unfortunate. :( i'll have to figure something out.
I'm talking about things like what is mentioned in the following: http://amixtureofmusings.com/2016/05/19/associated-types-and-haskell/ Sure you can 'do' it in Java, but you're resorting to Polymorphism where you really only needed Monomorphism (which allows you to make much more compiler and proof friendly code).
Ha, yeah totally. I meant the weak form of "can't do" as in "that will be really awkward and probably slow". Also, a lot of languages are being written in JS at the moment, I'm glad that I'm not the only one who thinks its a crazy (but unfortunately useful) approach. 
&gt; As soon as someone mentions [redacted] there is a sudden upsurge in reports coming in, and acerbic comments from both "sides" of this distracting storm in a teapot https://www.youtube.com/watch?v=R_hlMK7tCks 
Video linked by /u/peggying: Title|Channel|Published|Duration|Likes|Total Views :----------:|:----------:|:----------:|:----------:|:----------:|:----------: [Monty Python's "Life of Brian" (Stoned to death...)](https://youtube.com/watch?v=R_hlMK7tCks)|artanis2alatariel|2007-06-13|0:02:22|1,550+ (98%)|541,428 &gt; Monty Python's - Life of Brian (Stoned to death...) -... --- [^Info](https://np.reddit.com/r/youtubot/wiki/index) ^| [^/u/peggying ^can ^delete](https://np.reddit.com/message/compose/?to=_youtubot_&amp;subject=delete\%20comment&amp;message=dmw6g7r\%0A\%0AReason\%3A\%20\%2A\%2Aplease+help+us+improve\%2A\%2A) ^| ^v2.0.0
&gt; I can see why this would annoy/confuse collaborators &gt;any reason not to accept it as best-practice? Honestly that reason alone is good enough for me. Sometimes you want strict fields sometimes you don't, everyone is used to lazy by default so no reason to change that and confuse people. 
I searched the docs for backpack and found nothing. Is there really nothing I need to know to use Backpack with Cabal 2?
Another copy of that same press release is on the [Computation Institute](https://www.ci.uchicago.edu/press-releases/mind-tools-how-computer-programming-languages-impact-science-and-thought) site. There is a note at the bottom of that copy which implies that one of the people pictured in the photo on the OP copy is Louis Wasserman, in 2012. Anyone know if that is true?
I think it's not quite correct to say that in seq :: a -&gt; b -&gt; b a is evaluated *before* b. It's just when the result of seq is needed it'll force both a and b https://hackage.haskell.org/package/base-4.10.0.0/docs/Prelude.html#v:seq.
I find its "switching the defaults" behaviour quite confusing tbh.
Ignoring your ghc-prim/base question for now: &gt; by reusing ghc frontend. I can compile some modules and retrieve their STG/Cmm representations Do you have this part as a repo shared somewhere by any chance? I've been meaning to explore Haskell-STG-to-X "transpilation" possibilities but previously got stuck on a sane clean fast smooth non-fickle way to arrive at a given (set of) module's in-memory STG "AST" (without dumping-and-then-parsing-the-dumped-txt)
Good catch, thank you! I'll update the post shortly.
Thanks for the writeup with tips that are immediately useful! I am still slightly confused when strictness annotations are beneficial, though. From my understanding there are three main cases for functions: f p a b | p = a * b | otherwise = a + b all arguments are used strictly in each branch so ghc will do a worker/wrapper transformation when compiled with optimizations. Annotations don't hurt but don't seem necessary. f p a b | p = a * a | otherwise = a + b b isn't used in the first branch so forcing it might reduce laziness. It likely isn't a huge thunk so a strictness annotation might help here and also propagate to functions that use f. Could strictness annotations make things worse if f is inlined? I guess case-of-case would fix it up? f p a b | p = lazily a b | otherwise = a + b Adding bang bang patterns here would reduce laziness and increase allocations in the first branch. This might still be beneficial based on the likelihood of p. So did I get this right? And I am assuming strictness annotations are usually used in the second case? Also kind of wondering how much nested cpr would help in the examples from the post.
I like to use it on single modules, with non-recursive data.
It's not exactly data, but an [essay by Paul Graham on Lisp](http://paulgraham.com/avg.html) contains a number of good points that also apply to Haskell.
That's an interesting idea. A possible way to do it would be something like this: type family Result a where Result (b -&gt; c) = Result c Result a = a class Uncurry f t where uncurry, ($$) :: f -&gt; t -&gt; Result f uncurry = ($$) ($$) = uncurry instance (f ~ (a -&gt; b -&gt; Result f)) =&gt; Uncurry f (a, b) where uncurry = Prelude.uncurry instance (f ~ (a -&gt; b -&gt; c -&gt; Result f)) =&gt; Uncurry f (a, b, c) where f $$ (x, y, z) = f x y z etc. This approach doesn't work with partial application, though.
Thanks, I'll look into it.
There's another instance of the same error: &gt; "By contrast, if you use five `seq` seven `seq` putStrLn ("Five: " ++ show five), it will (should?) always come out in the same order: first five, then seven, then "Five: 5". On the contrary, there's no guarantee that `five` will be evaluated before `seven`. 
Good post. What's maybe missing from this blogpost is explaining `seq`'s cooler sibling `pseq`.
1, 2, and 4 are already solved. 1. GHCJS installs trivially with stack. For example, this in stack.yaml will work - resolver: lts-7.19 packages: - . extra-deps: [] flags: {} extra-package-dbs: [] compiler: ghcjs-0.2.1.9007019_ghc-8.0.1 compiler-check: match-exact setup-info: ghcjs: source: ghcjs-0.2.1.9007019_ghc-8.0.1: url: http://ghcjs.tolysz.org/ghc-8.0-2017-02-05-lts-7.19-9007019.tar.gz sha1: d2cfc25f9cda32a25a87d9af68891b2186ee52f9 2. On the fly typechecking etc. works if you add a dependency to ghcjs-stubs and compile with GHC (just use the same resolver version as ghcjs). I don't have a pre-baked config for you right now but it's not very hard. 3. I haven't attempted hot reloads (it may or may not be possible/easy). 4. Closure compiler just works for me. If you have a test case that doesn't work then it's either a bug in ghcjs or closure-compiler. If you post the test case here or on the mailing list, the bug may get fixed soon by the OCD people of Haskell :) 5. It would be nice to get on demand loading of Haskell modules, which is a real lacunae. It's easy to load JS libs on demand (for example, inject script tags at runtime). If you want to break up and on-demand-load JS application logic then you would likely need to build tooling around it yourself (it's not a common use case since most people would want to put logic in Haskell). 
&gt; Why does the Prelude expose a function (foldl) which is almost always the wrong one to use? Hijacking this thread to get on my soapbox: Can we please make `foldl` in `Prelude` strict? I don't care if it doesn't meet the Haskell standard. It probably won't break anything but if it does I don't care. GHC should just unilaterally go against the standard here and make `foldl` strict (and `sum` for that matter).
Probably for the same reason we use camelCase, to save space so that a line can fit in 80 characters ...
One problem with this is when writting code with a pen and paper : spaces are not obvious.
Great point against this, I have seen even more radical proposals in the past where you can use more than one space to denote fixity (something like `1 * 5+5 - 4` = `1 * ((5+5) - 4)` I suppose)
I think the major problem with this approach is that finding the solution to pretty much any problem (with gradient descent or otherwise) is similar to the most pathological cases with real valued functions. The curve on which you're moving is extremely bumpy and I don't think the derivative at some point has any correlation with the chance that this direction will eventually produce a decent solution. How many times have you written a program where flipping a single character transformed it from broken to functioning?
Thanks. Another update coming through. The corrections here are much appreciated!
Duncan wrote a great post about this: http://www.well-typed.com/blog/90/ I would support any of the following (in descending order of preference): 1. Make `foldl` strict 2. Deprecate `foldl` and put `foldl'` in the `Prelude` 3. Put `foldl'` in the `Prelude` 4. Add copious documentation (that likely no one will ever see) to `foldl`. It's already got [pretty decent explanations](https://www.stackage.org/haddock/lts-9.4/base-4.9.1.0/Prelude.html#v:foldl), but a simple: __CAVEAT EMPTOR YOU PROBABLY WANT `foldl'`__ would not be amiss in my opinion
I honestly considered putting in some notes on it, but decided against it since it's not strictly\* necessary to understand the topic at hand. Given the [confusion that I demonstrated](https://www.reddit.com/r/haskell/comments/6zl88c/all_about_strictness/dmw79p2/) in explaining order of evaluation, I think it's good I left it out :) \* Pun intended
Very nice blog post. &gt; In particular, it's important to understand some crucial topics if you want to write memory- and time-efficient code: &gt; &gt; - Strictness of data structures: lazy, spine-strict, and value-strict There's quite a few available online blogs/resources on how to make data strict and force function evaluation to avoid space leaks and shorten runtimes. There's far less online about the real space and time benefits of going the other way, i.e. exploiting laziness, with one notable exception being Edward Yang's great collection of posts about Haskell evaluation. E.g. this cartoon: http://blog.ezyang.com/img/heap/leak.png In this series: http://blog.ezyang.com/2011/04/how-the-grinch-stole-the-haskell-heap/ So, as well as the useful "adding strictness" to reduce memory needs and runtime, it'd be great to see more "exploiting laziness" blog posts geared towards space and time efficiency.
Having said that, if you write code manually, you could underscore a full expression to put in bracket.
When building an app with `stack build` on windows, `stack` (presumably) changes the codepage of the terminal to 65001 (utf8). However, it does not when I run `stack test` - non-ascii characters in the output of test (`hspec`+`quickcheck`) result in `&lt;stdout&gt;: commitBuffer: invalid argument (invalid character)`. If I run `chcp 65001` manually and then launch `stack test`, everything works fine. Is there a setting or a flag for `stack` that would change the codepage automatically for tests? The issue can be systematically reproduced on both Win10 and Win7.
A first step would be to at least get rid of `foldl` in the implementation of `sum`, `product`, `maximum`, … and replace it by `foldl'`.
Right, the wikibook [chapter about strictness](https://en.wikibooks.org/wiki/Haskell/Strictness) is just a stub. If the author agrees, this entire post could basically just be pasted there.
It's not entirely related, but there's [a paper](http://www.bcl.hamilton.ie/~barak/papers/toplas-reverse.pdf) (that Ed Kmett pointed me to) that talks about implementing a lambda calculus with baked-in differentiation. It's a successor of the incremental lambda calculus (which might be relevant to your work, too) that specializes in computing gradients and what not. I said "not entirely related" as this work doesn't care much about data types IIRC and simply focuses on defining an extended lambda calculus with a quite general gradient operator (that you can e.g apply to itself).
`foldl'` would be better than `foldl`, and I wouldn't mind doing that. But it's still wrong, almost as often as `foldl`. As would be a `foldl''` implemented with `deepseq`, or what we would get in a strict-by-default Haskell variant. The fact is that for left folds, you need to control how deep the strictness goes in each case. I think that's part of the reason naive `foldl` has remained in the `Prelude` for so long. On the one hand it seems like there ought to be a left fold, not just a right fold. On the other hand, there really isn't any good alternative to `foldl`. Just alternatives that are a little less bad.
I disagree. As demonstrated in the post, you can always wrap `force` around the result of your folded function to promote `foldl'` to `foldl''`. You can't do the same with `foldl`. Also, not all data types are instances of `NFData`.
The assignment we have is to write a Blackjack game in Haskell. We have been given a Cards.hs file and a Wrapper.hs file. Both these files, as well as my Blackjack.hs file, use import Test.QuickCheck. However when I try to load any of the files I get the error msg : [1 of 3] Compiling Cards ( Cards.hs, interpreted ) Cards.hs:3:1: error: Could not find module ‘Test.QuickCheck’ Use -v to see a list of the files searched for. | 3 | import Test.QuickCheck | ^^^^^^^^^^^^^^^^^^^^^^ Failed, 0 modules loaded. I've tried cleaning the files and doing a fresh install of the full version, swell as the cabal command: cabal install Test.QuickCheck, but none is working. 
Real-time logging is a side effect. So yes, it needs to be in `IO`. Take a look at Kazu's [fast-logger](https://hackage.haskell.org/package/fast-logger). It's simple, does everything you need, and it's very fast. It's in use in production on many web sites, including some very high load sites. If you're using Yesod, there is quite a bit of built-in support. If not, you might want to steal some of that code for things like auto-formatting of log entries, logging levels, etc. It's in [yesod-core](https://hackage.haskell.org/package/yesod-core), in the `Yesod.Core` module. EDIT: Elsewhere in this thread /u/agrafix pointed out his package [simple-logger](http://hackage.haskell.org/package/simple-logger) that is a wrapper for fast-logger. It provides logging levels, and trace-like logging for pure code.
&gt; you need to control how deep the strictness goes in each case I agree. You cannot have *any* control over strictness with `foldl` but you can have *complete* control over strictness with `foldl'`. /u/snoyberg hints at this in the sibling comment, but here are complete examples of four different strictness patterns using `foldl'`. (The examples are artificial but I hope they're enough to demonstrate the point.) import Data.List import Control.DeepSeq data Lazy a = Lazy { unLazy :: a } lazyCons :: a -&gt; Lazy [a] -&gt; Lazy [a] lazyCons a as = Lazy (case as of Lazy as' -&gt; a : as') spineCons :: a -&gt; [a] -&gt; [a] spineCons a as = forceSpine (a:as) where forceSpine :: [a] -&gt; [a] forceSpine [] = [] forceSpine (x:xs) = x:xs deepCons :: NFData a =&gt; a -&gt; [a] -&gt; [a] deepCons a as = force (a:as) weirdCons :: a -&gt; [a] -&gt; [a] weirdCons a [] = [a] weirdCons a [x] = x `seq` [a, x] weirdCons a [x, y] = x `seq` [a, x, y] weirdCons a (x:y:z:rest) = x `seq` z `seq` ([a, x, y, z] ++ rest) -- Using foldl' to accumulate lazily reverseLazy :: [a] -&gt; [a] reverseLazy = unLazy . foldl' (flip lazyCons) (Lazy []) -- Using foldl' to accumulate strictly reverseStrict :: [a] -&gt; [a] reverseStrict = foldl' (flip (:)) [] -- Using foldl' to accumulate spine strictly reverseSpine :: [a] -&gt; [a] reverseSpine = foldl' (flip spineCons) [] -- Using foldl' to accumulate deep strictly reverseDeep :: NFData a =&gt; [a] -&gt; [a] reverseDeep = foldl' (flip deepCons) [] -- Using foldl' to accumulate in a way that forces the accumulator in -- an arbitrary way each iteration reverseWeird :: NFData a =&gt; [a] -&gt; [a] reverseWeird = foldl' (flip weirdCons) [] 
This is a far better explanation than mine.
Let me know how it goes!
Logging will definitely require IO, to either communicate the log info to a logging thread, or to perform IO to produce log output. Most useful transformer stacks have IO at the bottom, so the stack isn't just for heating CPUs. [MonadLogger](https://hackage.haskell.org/package/monad-logger/docs/Control-Monad-Logger.html) is built atop fast-logger, and is a pretty straightforward way to add logging to a transformer stack. You just wrap the bootstrap of your stack with an appropriate logger. 
&gt;You throw the exception once just like usual by returning Left He mean to catch real IO exceptions inside the function and return Left (one time). Then he check the return value of he function, which may be Left. So he does it two times. &gt; Also I don't see how ExceptT involves any more boilerplate than native exceptions. Due to the monad transformer stack and the lifting/unlifting necessary
The benchmark repo now uses circleci, which only timeouts if there's no output for a while. The maintainer is constantly plagued by javascript build issues and he's reluctant to give first class treatment to an ecosystem he knows nothing about (purescript frameworks were all merged by now due to ecosystem proximity). If/when one haskell benchmark gets merged, others have a clear path to follow. We've considered forking to better suit functional frameworks, but this is kind of a last resort. We'll see.
I usually think of a `seq` b as sugar for case a of _ { DEFAULT -&gt; b } which makes it clearer to me why b might be evaluated before a if commuting conversions move the case into b's body. By extension also why chained seqs don't force an evaluation order, I guess. 
I'd claim that /u/yitz and /u/codebje are wrong. Saying that "logging is a side effect so it requires IO" is like saying "running a program is a side effect so you'll need IO anyways". Sure, in a way it's true, but not in a useful way. There are plenty of ways to write functions that operate on a "promise" of being able to log in real time, but only ever touch IO when they finally get specialized to a concrete monad/transformer stack. 
&gt; On hackage I found the logging-effect package This is mine, what do you mean by "real time"? It can certainly be made real time, but the "stock" log handlers use buffering. `runLoggingT testApp print`, as shown in the documentation, will call `print` exactly whenever you log a message. If there are any places where the documentation is lacking or leaves you stumbling, please please let me know and I'll see what I can do. You can reach me here, or open an issue on GitHub - i'm happy to have "questions as issues".
well then, care to elaborate on some of those ways? I guess you could just build a list of log messages with the strict StateT and then flush the logs all at once at the end of your buisness logic, but that's not exactly "real time". If you want real-time logging, you'll need IO.
While we're at it, how about removing `nub`, or renaming it to something like `reallySlowNub`? O(n^2 ) `nub` is likely to cause severe performance problems at a lower `n` than `foldl`; in almost every real case it's better for the user to use a `dedup` function that removes consecutive duplicates, which combined with sorting can run in O(nlogn). And if the type isn't `Ord`, then it should damn well be made `Ord` (or `Hashable`), if the user wants to remove duplicates from a list of it in a real program. That's why languages like Haskell and Rust provide a `dedup` function but not a `nub` function, to encourage good practices. I swear I even remember seeing a GHC performance bug resulting from the use of nub, but I can't find the ticket now.
Didn't know that ghc head was that far, well, ahead. I am assuming that following head requires building from source but I wanted to learn more about ghc's internals anyway. Thanks for your answer!
&gt; Oh and a quick second question: Real-time logging forces me to use IO anyway, right? You could cheat and do something disgusting with `Debug.Trace` or other unsafe variations.
There's the `DuplicateRecordFields` extension that lets you declare types with the same fields. The accessors will work, but the inference is really awful and requires type annotations. But it does work. One thing that lessens the pain is `RecordWildCards` which interact pretty well with `DuplicateRecordFields`. Another is the `lens` library with which you can generate "lenses" for your types. Basically first class record accessors that are better than the built in ones in pretty much every way, but they're a bit more verbose to use. Less verbose than annotating all of your call sites though.
This is a well known pain point, and there are language extensions that might help, although I do not use them. &gt; This is really close to a total dealbreaker for me picking up this language as a hobby, how do you gals &amp; guys cope? Oh, wait until you try to update data in nested records! ;) I think there are three solutions to cope: * Stockholm syndrome : just claim it is not problem at all. This seems to work well for certain languages, and I personally got used to prefixing my field names. * There is a coterie of libraries that will help with that. I personally use `lens`, which does a lot more, and I am sure many others will be mentioned in this thread. The downside is that if you are starting to use Haskell, this will require quite a bit of cargo-culting, as those libraries use advanced concepts/extensions. * The aforementioned extensions, which I don't know much about.
http://foldr.nl/posts/2017-08-20-composable-loggers.html
Like this, for example class MonadLogger m where log :: Text -&gt; m () myFunction :: MonadLogger m =&gt; m () myFunction = log "hello" &gt;&gt; log "world" instance MonadLogger IO where log = T.putStrLn main = myFunction Now you can write your whole program the same way `myFunction` is written, keeping it completely pure. Sure, the `m` just gets specialized to `IO` in the end, but this is irrelevant. You retain all the reasoning you get with pure functions, and it's all still real time. There are other benefits as well, such as making all your code inherently testable. 
I know of three ways around this problem: 1. Do what you did: Put all the types in one module and prefix the field names with something unique. This is typically what I end up doing. It's annoying, no doubt, but you get used to it. Real world example: https://github.com/tfausak/rattletrap/blob/2.5.2/library/Rattletrap/Mark.hs#L7 2. Split the modules up and parameterize the data types. This way you break the import loop by not having to import the types into each other. module Customer where data Customer employee = Customer { server :: employee, ... } module Employee where data Employee customer = Employee { customersServed :: [customer] } Then you can define convenience types like `type ActualCustomer = Customer Employee`. Real world example: https://github.com/tfausak/rattletrap/blob/2.5.2/library/Rattletrap/PropertyValue.hs#L7 3. You actually can have mutually recursive modules, but I've never done this. Check out [the Haskell wiki](https://wiki.haskell.org/Mutually_recursive_modules) or these Stack Overflow questions: [Haskell recursive/circular module definitions?](https://stackoverflow.com/questions/8650297/haskell-recursive-circular-module-definitions), [Data structures with cyclic dependencies in haskell](https://stackoverflow.com/questions/13788676/data-structures-with-cyclic-dependencies-in-haskell) And then of course there's the option of changing what your data looks like. Maybe you could make it so that `Customer`s and `Employee`s are completely separate. Then you could add an `Event` data type that ties them together. Something like this: data Event = Event { eventId :: Int , eventDescription :: String , eventEmployee :: Employee -- ^ This employee was the server. , eventCustomers :: [Customer] -- ^ These are the customers that were served by the employee. }
Ooh, how exciting, what's so good about updating data in nested records?;)
Matt Parsons has a great talk about this: http://www.parsonsmatt.org/overcoming-records/#/. This is almost certainly Haskell's greatest wart, especially for those of us coming from OOP where field names are a huge part of how you write code. How do we cope? See the presentation for some ways. As I like to [say](https://twitter.com/eacameron88/status/907607060472352773): If #Haskell's laziness is the hair shirt that brought us monads, then #Haskell's "records" is the hair shirt that brought us lenses.
Is there any reason why we can't fwd declare stuff? Is it a limitation in the compiler, or the language design?
Almost... the logs won't appear in real-time _unless_ the `m` is specialized to IO, though. All other instances for non-IO monads will still accumulate a stream of logs and then, at some point, dump to IO all at once.
Very nice. My only problem now is that i’m going to have to refactor a lot of code :)
The problem is that even if your monad *theoretically* streamed log messages purely, the ability to *observe* that stream would require IO somewhere (whether hidden by parameterization or not). The fact that you not only want to observe the stream, but observe it *incrementally* (i.e. as it is produced) means that you need to interleave IO with your pure code. You could probably use some sort of lazy IO to interleave it even more subtly, but most folks agree that's too sneaky.
It is really bad! data Foo = Foo { a :: Bar, b :: Int } data Bar = Bar { c :: String } Now, in standard Haskell, written directly, it is horrible: updateC :: Foo -&gt; (String -&gt; String) -&gt; Foo updateC foo f = foo { a = a foo { c = f (c (a foo)) } } Something like `lens` completely solve that particular problem (and more), at the expense of introducing quite a few new concepts and dependencies in your code base.
For people not used to looking at core `case a of _ { DEFAULT -&gt; b }` is only accurate in Core and doesn't work with a regular case.
That's about as "real-time" as I need it. Line buffered output and lazy IO is fine, I simply don't want the user to receive all log messages when the program is done computing.
Sure, I could, but this violates referential transparency and is almost exclusively used for debugging. I want "proper", safe logging which doesn't rely on `unsafePerformIO`.
That looks more like an issue with variable naming than with spacing
Ah I see. I mean if it was Left in the first place then you'd instead have to do multiple things to switch back to use exceptions. Mtl seems to pretty much completely avoid any boilerplate in my experience. 
You can, sort of, with `.hs-boot` files. I don't know much about it or why it's necessary in the first place. The GHC documentation talks more about it: https://downloads.haskell.org/~ghc/8.2.1/docs/html/users_guide/separate_compilation.html#how-to-compile-mutually-recursive-modules
In this particular case you almost certainly want to have customers refer to employee IDs and employees refer to customer IDs. (Then you can put the records in different modules easily enough.) If you don't do this, then when you want to add an occurrence of a customer being served by an employee, now you have a new employee, so you have to update that in all the customers they have ever served, and now you have some new customers, so you have to update some more employees, and so on. You have to touch the whole (connected part of the) graph to make any updates.
There's also the [differential lambda calculus](http://ac.els-cdn.com/S030439750300392X/1-s2.0-S030439750300392X-main.pdf?_tid=090bdfe6-97c7-11e7-a0e8-00000aab0f6b&amp;acdnat=1505226856_3520ba0200fdb9c0b2f0b8c6e3ec2511), which seems to do more or less the same thing.
How about this: {-# LANGUAGE TypeFamilies, MultiParamTypeClasses, FlexibleInstances #-} module TupApp where class Uncurry t r where type Fun t r ($$) :: Fun t r -&gt; t -&gt; r instance Uncurry (a, b) c where type Fun (a,b) c = a -&gt; b -&gt; c ($$) = uncurry instance Uncurry (a, b, c) d where type Fun (a,b,c) d = a -&gt; b -&gt; c -&gt; d f $$ (x, y, z) = f x y z It works with partial application: $ ghci TupApp.hs GHCi, version 8.0.2: http://www.haskell.org/ghc/ :? for help [1 of 1] Compiling TupApp ( TupApp.hs, interpreted ) Ok, modules loaded: TupApp. *TupApp&gt; import Text.Printf *TupApp Text.Printf&gt; printf "%s%s" $$ ("hi","du") :: String "hidu" *TupApp Text.Printf&gt; printf "%s %s %s" $$ ("hi","du","da") :: String "hi du da" *TupApp Text.Printf&gt; (printf "%s %s %s %s" $$ ("hi","du","da") :: String -&gt; String) "partial" "hi du da partial"
For starters, how about cranking up the `line-height`? Right now the lines are too tightly crammed vertically. In your `#blog.content-section p, #blog.content-section blockquote` rule, increase the `line-height` and `font-size`: line-height: 1.5; font-size: 18px; Practical Typography's "line spacing" guide is pretty great (google it).
Well, we now have a proper proposals system in place to come to an “official” decision on language extensions in GHC: https://github.com/ghc-proposals/ghc-proposals
Edit: I read this blog post under the assumption we were working together with strictness analysis, which is implied by `-O1`. Your `average` example is not strict enough, even after inserting the bangs, ~~which actually aren't even necessary~~ that wasn't true, but the following yields strictly better results. The culprit is in `printAverage`, which is not strict in `RunningTotal`s `sum` because of the first branch. Annotating `sum` is enough to make GHC recognize `go` to be strict in both fields and unbox stuff. printAverage :: RunningTotal -&gt; IO () printAverage (RunningTotal !sum count) | count == 0 = error "Need at least one value!" | otherwise = print (fromIntegral sum / fromIntegral count :: Double) This single bang gets total allocations down to 80MB compared to 128MB when putting bangs in the other locations. The remaining allocations are due to the list that gets explicitly allocated. I can see no way around that, other than to use proper streaming abstractions or replacing `go` with a `foldl`-based definition to enable list fusion: printListAverage :: [Int] -&gt; IO () printListAverage = printAverage . foldl f (RunningTotal 0 0) where f (RunningTotal sum count) x = RunningTotal (sum + x) (count + 1) 43kB residency, 99kB total allocations. And that's with using `foldl`! Of course, it's all list fusion: `foldl` is implemented in terms of `foldr`, which fuses with the list literal. This is how `enumFromTo` is implemented for `Int`: enumFromTo (I# x) (I# y) = eftInt x y Now, it gets interesting if we look at the `RULES` for `eftInt`: {-# RULES "eftInt" [~1] forall x y. eftInt x y = build (\ c n -&gt; eftIntFB c n x y) #-} I'll just paste the Note exactly below that definition in [`GHC.Enum`](https://hackage.haskell.org/package/base-4.10.0.0/docs/src/GHC.Enum.html#line-426): {- Note [How the Enum rules work] ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ * Phase 2: eftInt ---&gt; build . eftIntFB * Phase 1: inline build; eftIntFB (:) --&gt; eftInt * Phase 0: optionally inline eftInt -} The formulation in terms of `build` allows this to completely fuse with `foldl`. This illustrates pretty much why I'd very much favor a stream fusion approach that solely relies on compiler optimizations instead of carefully crafted rules. By the way, the difference between fused and annotated, non-fused versions is in the order of two magnitudes. Which becomes appearent when we make the list to consume even bigger: The fused version takes like 16ms, whereas the non-fused version with annotated `printAverage` takes 1.2s, where 80% are due to GC. Appendix: RTS measurements Without: 144,744,856 bytes allocated in the heap 173,250,600 bytes copied during GC 42,022,368 bytes maximum residency (7 sample(s)) 670,240 bytes maximum slop 84 MB total memory in use (0 MB lost due to fragmentation) in loop: 128,098,712 bytes allocated in the heap 12,824 bytes copied during GC 42,856 bytes maximum residency (1 sample(s)) 30,872 bytes maximum slop 2 MB total memory in use (0 MB lost due to fragmentation) in printAverage: 80,098,712 bytes allocated in the heap 5,864 bytes copied during GC 42,856 bytes maximum residency (1 sample(s)) 30,872 bytes maximum slop 2 MB total memory in use (0 MB lost due to fragmentation) fused: 98,752 bytes allocated in the heap 1,752 bytes copied during GC 42,856 bytes maximum residency (1 sample(s)) 26,776 bytes maximum slop 2 MB total memory in use (0 MB lost due to fragmentation) 
&gt; And its result is also strict. I'm not sure this is even *meaningful* much less **true**.
I like the options, but I prefer 4 and 3 over 2 or 1.
I tend to use `monad-logger`'s `MonadLogger` as the interface, then use the `runStderrLoggingT` or whatever it includes in small apps, or in bigger applications I use Katip for structured logging through `monad-logger-katip` (currently not a released package, see https://github.com/NicolasT/kontiki/tree/hack/monad-logger-katip/ ) to handle logging from library code, and Katip proper in the application.
Yes, but Graham wrote that in 2001. That's a generation ago, and I still can't get a job in my town programming in Lisp, or Dylan, or Clojure. Symbolics folded in '96, LMI similar. The "Lambda the Ultimate..." papers are awesome; Common Lisp is _still_ awesome. I programmed in Lucid Common Lisp and Harlequin Lisp in the early '90s, but no more. Graham's choice is Lisp, but the existence of this subreddit is a result of folks rejecting Graham's choice and designing something better. I also can't get a job programming in Haskell in my town (or remote). I want to believe! How long must I wait?
&gt; you can't in principle parametrize a Go interfaces by a type [Never say never!](https://www.reddit.com/r/rust/comments/5penft/parallelizing_enjarify_in_go_and_rust/dcsq64p/?context=1)
Yes, also, this is bound to get trapped in some local optimum vs. the global solution for anything of reasonable complexity. 
Cool, even the default loggers (that buffer) won't block indefinitely, they have a configurable timeout before they flush: http://hackage.haskell.org/package/logging-effect-1.2.1/docs/Control-Monad-Log.html#t:BatchingOptions see `flushMaxDelay`.
What's your town? Why can't you get a remote job?
Great! I extended my solution with `Nat`s to handle partial application, but this is definitely much nicer.
This was just an example of how you can have circular dependencies with very simple code 
Here's a silly way of getting around this -- Customer.hs data Customer' employee = Customer { id :: Int, server :: employee } -- Employee.hs data Employee' customer = Employee { id :: Int, customersServed :: [customer] } -- SomewhereElse.hs type Customer = Customer' Employee type Employee = Employee' Customer 
&gt; move the case into its body What does that mean? I don't get it.
I agree.
[This version](http://lpaste.net/358386) takes 49s instead of 90s on my computer, but I think that ultimately a change in algorithm is required to beat C, which is using another approach.
Yeah I've seen this sort of things before, where you use type parameters instead... ehhhhhhhhhhhhhhhh? this is javascript level hacking!
&gt; Most of the developers know Python, Ruby, or JavaScript. All runtime typed langs. Tell them about the joys of strong typing! Refactoring with confidence, more errors become red squiggly underlines (instead of customers calling to report bugs), never forget to catch a nil/null (Maybe), etc. And this is not just static typing as we know it from Java/C++ :) This strong typing is more fun/safety then hassle. 
&gt; this is javascript level hacking! Huh? Doesn't seem anything like JavaScript to me.
&gt; Unfortunately, to my knowledge, there is no definition of a strict, boxed vector in a public library. Such a data type would be useful to help avoid space leaks (such as the original question that triggered this blog post). This really bugs me. Is there any reason `ghc-prim` can't have a `StrictArray# a` which behaves like `Array# a`, but forces all of its elements when it is forced itself?
I get an inordinate amount of fun from watching your different accounts interact with each other. XD Thanks for the great post.
How is it not useful when it's by definition correct? Also, your code isn't necessarily a "promise"? I can define a description of an IO action and never call it within an IO context. In fact, I can have a number of these and pick and choose. &gt; Saying that "logging is a side effect so it requires IO" is like saying "running a program is a side effect so you'll need IO anyways" In Haskell, you don't have a choice as "main :: IO ()" By definition in Haskell, running a program can only be in IO.
Surely one can just wrap `Array` or `Vector` and get strict, boxed versions?
Just use `monad-logger`. We have a bunch of functions in the code base that has type signature like `MonadLogger m =&gt; ... -&gt; m X` only side effects these functions can perform is logging. `monad-logger` provides two transformers, one for running ignoring logging (which amounts to running a pure function when you only perform logging effects), another one for actually logging in IO. 
No. Neither `Array` nor `Vector` will force their elements to get into WNHF.
Just use `monad-logger` with appropriate implementation (`runStdoutLoggingT` is fine for maany cases)
seems very likely, since it's all out of UChicago in the same timeframe: [https://www.uchicago.edu/features/20120528_wasserman/](https://www.uchicago.edu/features/20120528_wasserman/)
So, this has been sitting on my hard-drive for a while now, and thought I would share it with the hopes that even in its current form others might find it useful. Either people from this subreddit now, or others finding it via search later on.
No, you can just as easily declare that ability in your class. You can write your program without mentioning IO ever, except at the very top in main.
The point is to turn logging into a declaration and write code against that declaration. It doesn't matter what you use to implement that declaration.
You're asking how a tautology isn't useful? I don't think I have the philosophical skills to be able to argue that.
Perhaps I should have been less tentative: One *can* write a wrapper module around them such that all primitive operations do force the elements. You don't need a `StrictArray#` for that.
I just meant it felt hacky &amp; bad, to a similar level as javascript, i like bashing js at any opportunity you see
It's not at all hacky and bad. It's rather verbose but it's perfectly principled.
I've been really enjoying `katip` lately. The `stdout` logger does color if it detects it's on a terminal, which is nice! &gt; At the heart of my program is a (pure) monad transformer stack, and I'd hate to introduce stuff which composes badly with it. I would suggest programming against class constraints. Then you just add `WhateverMonadClass m =&gt; ... -&gt; m a` to your signatures that require logging, and let GHC solve the exact ordering of transformers for you. If you've got a mostly concrete pure stack that you're happy with, then you can parameterize it over the base monad: newtype AppT m a = AppT { unAppT :: FooT (BarT (BazT m)) a } which allows you to write: foo :: MonadLogger m =&gt; Int -&gt; AppT m () This retains your purity, and most of your functions defined over `AppT`, while also allowing you to shove an `IO` based realtime logger in there.
Thanks! :) I am currently benchmarking and investigating other approaches. &gt; [...] to beat C, which is using another approach. Actually it implements a tree data structure to get a simple dictionary/map which C does not have in its stdlib. The other (imperative) candidates use the default dictionaries of the language's standard library (as does the Haskell version). So I do not think the approach in C is unusual - but I have to admit that I have more experience in C than in Haskell. It's probably possible to implement this similar in Haskell, but I would welcome a more high-level approach - but I agree that there might be a more appropriate algorithm.
If you want to model a container that is continually adjusted or accessed by specific position, linked lists are not a good way to do it. Linked lists are a good model for processing queues where size in memory is not a concern, but not as a general container. You may get more mileage out of the `Vector` type from `containers`, which is structured to optimize random access. But ultimately I think the problem with performance is probably that you're trying to brute-force the solution - Haskell's strengths as a lazy by default immutable language rarely get to shine when faced with that sort of approach. 
I doubt Haskell's TypeFamilies extension will be covered in the study. Isn't that one of noZone's points in posting here? Here's one of the papers that made me appreciate type classes used in a similar fashion, [Structuring Graphical Paradigms in TkGofer (1997) Koen Claessen , Ton Vullinghs , Erik Meijer](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.38.5525&amp;rank=3)
Short preamble: GHC compiles haskell into an intermediate language called core. Core is simple and designed to match how the compiled code is executed, haskell features are complicated and designed to compile to core. For instance, if you write some haskell like (i+1, i*2) f !x = e then that compiles to something like let p1 = i+1 p2 = i*2 in (p1, p2) f x = case x of _ DEFAULT -&gt; e because in core all laziness comes from let bindings and all evaluation comes from case statements. Alright, answer time. Say you write not (null ls) If we inline the definitions we might get case ( case ls of (_:_) -&gt; False [] -&gt; True ) of False -&gt; True True -&gt; False This is terribly inefficient! We have to allocate the result of the inner case on the heap just to match on it immediately. Here we could share the same values for False/True throughout the program but we still add indirection and unnecessary work. This is also really frequent while compiling haskell. So there is an optimization targeted at this called case-of-case for obvious reasons. It moves the outer case into each branch of the inner case: case ls of (_:_) -&gt; case False of False -&gt; True True -&gt; False [] -&gt; case True of False -&gt; True True -&gt; False but now we have the form `case C of { C -&gt; e; ...}` and can apply the case-of-known-constructor transformation: case ls of (_:_) -&gt; True [] -&gt; False And there you go, the code you might have hand written, and without any unnecessary allocations. A lot of ghc's optimizations work like this, a chain of surprisingly simple (although not necessarily easy) transformations. If you want to learn more you might be interested in the reasonably approachable paper [A transformation-based optimiser for Haskell](https://www.microsoft.com/en-us/research/publication/a-transformation-based-optimiser-for-haskell/). So if we write ```a `seq` b``` then that becomes a case statement in core which might be moved into the body of b as an optimization. Therefore we don't know when exactly `a` will be evaluated, just that both `a` and `b` will be evaluated before we get a result. 
Logging is a side effect, so it does need IO. However, you can abstract over that IO. I have had great success with `monad-logger` in the past. You can always introduce your own "MonadMyLog" and run that into `monad-logger`'s `LoggingT` when you're ready to run your program with actual effects. I'm not sure how you'd do this with mtl-style typeclasses, but with free monads you can insert an extra, do nothing but logging interpreter in strategic places of your `foldMap`s to achieve this very cleanly. Completely decoupling the logging from the business logic of your application. Kind of like the "cross-cutting concerns" you see in aspect oriented programming, but without the ickiness of reflection.
The things I was expecting you to say is how you load the files, for example, you could open a terminal and write `ghci` and then `:load Blackjack.hs` which will load the files and then you could run all kinds of haskell functions. `cabal install Test.QuickCheck` didn't work because Test.QuickCheck is a module name and not a package name. packages contains many modules. you install packages and import modules. You can use this website called [hoogle](http://hoogle.haskell.org/?hoogle=Test.QuickCheck) to find which module contains `Test.QuickCheck`. In this case the first entry below "module Test.QuickCheck" you'll see a link colored in green containing the name of the package, specifically the name is [QuickCheck](https://hackage.haskell.org/package/QuickCheck). I recommend using the tool Stack to download package and run programs. If you installed the haskell platform you should have it already, if you haven't you can [Get Started Here](https://haskell-lang.org/get-started). You can use [this guide](https://haskell-lang.org/tutorial/stack-play) to learn how to play with stack. how to call ghc and ghci and how to install packages. For example, you could probably use stack exec --package QuickCheck -- ghci Blackjack.hs To run `ghci` and load the Blackjack.hs module and it's dependencies. You could also just run it using `runghc` instead of `ghci` if Blackjack.hs has a `main`. I hope this helps. if you have further questions feel free to ask.
Of course your program would be impure when it's run, but that ain't the point. The idea is that the logic of your program (and hence the tests) are not tied to IO anymore. Of course it's still IO at the edge of the world.
Not all pure intermediates require buffering the logs. You can use pipes: http://www.haskellforall.com/2014/02/streaming-logging.html ... or any ListT-done-right implementation: http://www.haskellforall.com/2016/07/list-transformer-beginner-friendly-listt.html
I feel like it's good practice to pad operators with spaces when writing code for beginners to easily read, since they have greater difficulty visually lexing the code when you omit spaces
Ideally, the strictness would be part of the data type, and not have to be enforced invert operation. See this for motivation: https://stackoverflow.com/questions/32307368/how-can-i-have-a-vector-thats-strict-in-its-values-like-a-normal-type-with-ban
Add also a bit of `deriving`, to show that types can help reducing boilerplate.
Bang patterns are still just a GHC extension, right? I'd love to have them without extensions.
Published a new version. Now we have: * even better performance (attributes are now ~20% faster) * everything is kinded (as well attributes) * validity of attributes is checked at compile time * faster compiletimes! (only ~4 sec with -O0 for a page of wikipedia) Now it's perfectly possible to render it to an term level ADT. :)
Then it should probably make its `Int` field strict.
It's recommendable to use where you can kinds different from *, this increases a lot the helpfulness of the compiler.
For a different take on this problem that tries to avoid monad transformers, take a look at [di](https://hackage.haskell.org/package/di-0.2/docs/Di.html).
Show them STM. It usually wows people.
I'm not so sure pipes is "pure"... `piped :: Producer String IO ()`, as in the blog post you linked. There is definitely IO in that type signature. I am frankly very confused at all the responses on to this initial comment. You _need_ IO to print something out, in real-time. **Every** other solution will buffer at some point, accumulating logs and _then_ printing them out using IO, all at once (or at least in chunks larger than the real-time logging). You cannot get around this. You cannot log to any external resource without IO. Every single other "pure" solution suggested just defers the logging until later. My argument is not that you _cannot implement logging purely_, is that you cannot print real-time logs in pure code... therefore any pure logging mechanism will inevitably either 1) use IO intermediately (in the case of the streaming examples), or 2) buffer the logs and then use IO either at the very end of the computation, or (depending on the abstraction) find spots to interleave the IO. Sure, the code that _seems_ to do the logging may _look_ pure, **but the actual logging action necessitates IO**. Am I going crazy or... ? I don't get it.
I think the key would be another representation of `Config`, although I have no clue what this would be!
Because it's not important to which monad the function ultimately gets specialized to. Everything you write eventually gets transformed and piped into the IO monad because the main function is the only thing that actually runs, right? So what's the point of calling anything pure then? The point is that by avoiding using IO explicitly (or the MonadIO class) you constrain the function so it can't do arbitrary side-effects. The function, as it's defined, is pure. In a way you do defer the IO, but not in a runtime sense... You defer it in an architectural sense. Just look at my example to your original comment. Would you say that `myFunction` isn't a pure function? It doesn't mention IO anywhere. Yet, operationally, it does real time logging.
This is what the Haskell Report is for. Haskell2020 is coming up. If you want something included, I suggest getting involved =)
Well sure, I'm suggesting newtyping `Array` or `Vector`!
The Haskell 2020 discussions seem to have stalled. Although I suppose there's no point in accepting a proposal this early? What work is left to do after a proposal is accepted? "Just" update the language specification? Actually, considering that some of the Haskell 2020 committee have complained that they don't have time to use GitHub because it's too heavy weight, I have a hard time imagining them finding the time to update a specification.
[They're being worked on.](https://www.reddit.com/r/haskell/comments/6zdc73/ghcdevs_a_type_checker_plugin_for_row_types/)
That won't do it. WNHF is something hardwired and that you can't override. Can you sketch out what you are thinking?
Nice. Well done!
TIL. I find it frustrating that [`pseq`](http://hackage.haskell.org/package/parallel-3.2.1.1/docs/Control-Parallel.html#v:pseq) is the one that will guarantee order while `seq` will not. The names imply to me that they should be the other way around.
To be fair, if you only need the record-accessing/updating part of `lens` you can use [microlens](http://hackage.haskell.org/package/microlens) instead (which also has better documentation).
Yes, but purity guarantees you can't tell the difference!
I personally always use my wrapper [simple-logger](http://hackage.haskell.org/package/simple-logger) around [fast-logger](http://hackage.haskell.org/package/fast-logger) for my production apps. It basically declares a global logger for you and then provides useful functions to log from IO based stacks and from pure code. Note that pure log messages are only outputted when the attached expression is evaluated. 
&gt; WNHF is something hardwired and that you can't override. I don't think I'm proposing to override it. &gt; Can you sketch out what you are thinking? Sure. Here's an example with tuples instead of arrays -- Notice that the datatype underlying the strict pair is not strict! -- -- This constructor must be hidden and StrictPair may only -- be manipulated through the API below newtype StrictPair a b = StrictPair (a, b) createPair !a !b = StrictPair (a, b) get1 (StrictPair (a, _)) = a get2 (StrictPair (_, b)) = b set1 !a (StrictPair (_, b)) = StrictPair (a, b) set2 !b (StrictPair (a, _)) = StrictPair (a, b) Notice that the underlying datatype is lazy but the API ensures that this is a value-strict datatype. You could do exactly the same thing for an `Array` or a `Vector`.
In principle, you can rewrite any lazy algorithm as an eager one, so you don't "gain" anything in a strict sense (heh). Rather, the benefit of lazy evaluation is that you can resuse existing algorithms more easily without performance penalty. For instance, you can write `minimum = head . sort` for a suitably lazy sorting algorithm and get away with O(n) running time complexity. See [an old post of mine][1]. [1]: https://apfelmus.nfshost.com/articles/quicksearch.html
&gt; some of the Haskell 2020 committee have complained that they don't have time to use GitHub because it's too heavy weight If you're going to make claims like that you need to provide a citation!
&gt; In principle, you can rewrite any lazy algorithm as an eager one Only if you use mutation. Many algorithms cannot be directly rewritten as eager ones without mutation, they will often incur a log factor.
See [this post](http://blog.ezyang.com/2017/01/try-backpack-cabal-packages/) by [/u/ezyang](https://www.reddit.com/user/ezyang) and the [`backpack`](http://blog.ezyang.com/category/haskell/backpack/) tag on his blog.
&gt; What principles can I demonstrate for them to adopt in their JavaScript or Python code? I've worked in a mixed language shop and helped some Python academic programmers tidy up their prototype code into something more application like. One thing that really helped there was understanding type signatures: yes you can return an int or an object or a string from the same function, and later on do a switch based on the type of the return value; but how about you decide they are three different functions? Or that actually that object contains all the info for later anyway? How about you even just try to tell me what types your functions will return? In Python, we used mypy as a motivation - it's a tool that gives some static ("compile time") type checking for annotated python code. Although the practical side of things mean we never got anything like full type checking, it was a way for those developers to think about their code was structured in different way to how they'd thought about it before.
https://github.com/haskell/rfcs/issues/15#issuecomment-302743558 I fear I may be crossing the line into being rude here. This is an open source project, so all efforts are voluntary and welcomed, and I am thankful for the work that has been done. I will let my comment stand for the purpose of drawing attention to the actual state of the Haskell 2020 process. Things can still turn out well if we do the work as a community. I'd be willing to help but am no expert and not really sure where to start.
Good suggestion. It made me think of a Python function I recently created which returns a string, and sometimes a None. This is isomorphic to a Maybe String. In Haskell you take a String, and "add to the type" by making it a Maybe String. I was wondering if it would be worth doing something like this is Python? Or should I just return None or a string, and they can check the type with "returned_value is None" or the like.
Sorry, I wasn't clear enough: logging is a side effect so it requires _being run on a concrete stack that has_ IO. You have to have IO at the bottom of your stack, that's all. The library I suggested has the `MonadLogger` class you describe below, but the _instances_ of it that perform logging all require `MonadIO` as well.
My preference would be to not say "you need to write this non-idiomatic python now!" and instead explain how Haskell nudges you into remembering that None might be returned. mypy (I think?) has option types that work with the usual Python idiom of returning None.
To be fair, the number of frameworks in the main repo exploded (over 70, if counting keyed/non-keyed and all the angular/react variations). Just wait till we start having an idiomatic vs performant axis. The sheer volume and js tooling being [the utter nonsense that it is] (https://github.com/npm/npm/issues/17979) makes this much more heavy maintenance than it should be. Now, I'd say that build concerns are more of a reason to reject JS frameworks than Haskell ones, but if someone asked me to merge/maintain a x100 slowdown framework, I'd probably tell them to fork off. Opportunity cost and all that. That said, the [second reflex-dom PR is even more alien](https://github.com/krausest/js-framework-benchmark/pull/240), since the benchmark is now on the reflex-dom repo, and it seems all it will take is have it 'disabled' by default and bundle the generated javascript. 
Yeah. I see this is possible, but I still think a `StrictArray#` would be useful. For example, in the strict variant of `IntMap`, you can find data IntMap a = Bin {-# UNPACK #-} !Prefix {-# UNPACK #-} !Mask !(IntMap a) !(IntMap a) | Tip {-# UNPACK #-} !Key a | Nil Sure, they could have left the fields to be lazy and maintained their invariant using smart constructors, getters, and setters. Yet it is _convenient_ to specify in the data that a field must be strict. You know that every time you see a `Bin`, its fields are evaluated. There is no corresponding way of having data IntTree v = Node !Int !Int !(ArrayStrict (IntTree v)) | Leaf !Key v Because `ArrayStrict` doesn't exist. Does this explain my point?
Also, realise that 20 minutes is basically enough time for you to cover almost nothing. You'll do a bad sales job if you try to cram in more than that in.
The current function application rule can be easily scanned for due to a presence or lack thereof of printable characters between terms. You're advocating behavior based on the relative space of nothing between terms. This is fundamentally different. Thankfully, GHC saves me from most indentation based errors - I have played this whitespace changes behavior game before, debugging python, and it is not a fun game.
Remove the print statements and keep the logging and the type changes to piped :: Monad m =&gt; Producer String m () Now it can be used both purely (in constant space) or impurely
&gt; I swear I even remember seeing a GHC performance bug resulting from the use of nub, but I can't find the ticket now. You might be thinking of [this issue](https://www.reddit.com/r/haskell/comments/1sh67u/the_reason_why_cabal_update_takes_so_long/).
Does a reference to porn inherently count as toxic masculinity? The concept of porn in itself does not say anything about the gender of the viewer or those on screen. 
This is what I do, and in fact it's necessary since most of my program is not in IO. No IO is haskell's key gimmick for me, so I wouldn't want to give it up just to log things. The other thing I do is that functions that return streams typically return `data LEvent a = Log Log.Msg | Event a`. That way I get the right interleaving, and retain laziness.
It's actually quite good to parameterize your data types. It often allows you to take advantage of all the standard classes that deal with higher-kinded types, which means you get to apply more standard tools to your code. 
Does that actually work with `type`? Those type synonyms look infinite to me. 
I would definitely second this. One of the main pain points I constantly see is "the stronger your types the more masochism is required to get anything done" when in reality there's a happy middle inside which Haskell resides. Derive all the things, then turn on derive functor and traversable, then blow their mind with derive any class and generalized newtype deriving. Then briefly mentioned free monads, lenses, and template Haskell's make lenses, and let anyone who's interested see you for more details. (And by briefly I mean in about 10 seconds) Edit: this only really applies if the talk is more about evangelizing than learning.
And also hangs indefinitely if you have recursion anywhere.
You can edit `prepack`'s shebang to give it more memory. The real problem is that it doesn't use any termination combinators. It's meant for initialization code anyways.
&gt;So, as well as the useful "adding strictness" to reduce memory needs and runtime, it'd be great to see more "exploiting laziness" blog posts geared towards space and time efficiency. I agree completely. Not that strictness isn't useful or even desirable in many cases, but Haskell is one of the few lazy languages and there's a lot of space to explore. I think it's hard to sell laziness - its benefits tend to be pervasive. While space leaks are dramatic, getting little boosts to performance here and there is less noticeable. I've learned to avoid generalizing about GHC's performance without actually doing the benchmarks. I added the `{-# LANGUAGE Strict #-}` pragma to one of my very small packages ([continued-fraction](https://hackage.haskell.org/package/continued-fraction)), and it made the benchmark I had jumped from 8.839 μs to 10.36 μs. 
&gt;Is there any reason not to accept it as a best-practice? It's always been 5-20% slower when I tried this. I haven't figured out a reliable way to eyeball Haskell performance, but if you're really concerned I'd suggest developing with a benchmark suite to guide you.
&gt; After searching a little bit, it doesn't seem like haskell supports fwd declarations to alleviate this problem, soooo....??? It [does](https://wiki.haskell.org/Mutually_recursive_modules) in theory using `hs-boot` file. On practice it doesn't really work (too complicated or bugged) The usual way to avoid this problem is to declare the two data type in the same module. Recursive data like this are usually a bad idea as it is really difficult or impossible to update. For example, if you want to modify a attribute of a customer, you need to update its employee so that the customer employee refer to the updated version of the customer (including the updated files but it also the "new" employee with the correct customer). 
General you have to avoid circular dependencies. It's scary at first, then you realize that 99% you can model it otherwise. In you example for example, you probablt don't need the back reference from customer to employee. Give a list of employees its easy enough to build a map customer -&gt; employee when needed. It's a bit of boiler plate but will save you some headaches later. If you really need to, you need to break the indirection using IDs or mutable reference (like IORef, MVar, STRef) which are the equivalent of pointer in other languages (after all even in C or C++ you can't nest structure recursively). If you use a database you'll have this indirection naturally via id. If 
It's not at all obvious to me why I would prefer the output of EasySpec to that of ordinary QuickSpec. In the example involving a b c and d the output from EasySpec was arguably less interesting than that of QuickSpec. Could you provide some more examples, maybe from Data.List or something that would convince me otherwise?
QuickSpec is used as part of the Hip* family of tools. This means that QuickSpec is used to discover lemmmas about functions involved in proofs by induction. The place to look at in particular is at the Hipster tool which does fully fledged automated induction for Isabelle: https://arxiv.org/pdf/1405.3426
If you want people to write solutions, you should state the problem in a clear way, describe the format of the output and give a few examples like programming challenges sites do (like HackerRank).
Using a sub-function is exactly what I do, does this not solve the problem -- even for a bunch of related functions?
I’m late to this thread, but better late than never, I suppose. For a long time, I felt the way you do: I wondered why `foldl` existed in Haskell at all. It’s useless, unless you’re doing something really wild with bottoms. You always want `foldl'`. Why not get rid of `foldl`, then rename `foldl'` to `foldl`? For a while, I thought that sounded good. But then I realized that `foldl` is not specialized to lists (not anymore, anyway), it works with arbitrary `Foldable`s. For lists, `foldl'` is obviously what you want, but does that hold for all `Foldable`s? I don’t have a great intuition for this, but in general, I think the answer is ***no***. You could have a list structure that stores a list “backwards”, or a tree structure that is potentially infinite in both directions. In that case, the usual understanding of `foldl` and `foldr`’s strictness properties might not apply. If I’m wrong about this, I’d like to understand why, but I don’t believe I am. And, given this, I think making `foldl` in the `Prelude` strict *without* specializing it to lists is an ugly design decision, even if it would, perhaps, be a highly pragmatic one. I am not necessarily arguing against such a change (I’ve personally never been in a situation in which I want lazy `foldl`), but I never see this discussion brought up.
Fair enough! Thanks for providing the citation.
I admit I didn't test it!
Seems you're right and it doesn't work. I don't fully grasp the reason for that given that `newtype` cycles work fine. I haven't thought about it very hard though. &gt; type A = Maybe B; type B = Maybe A &lt;interactive&gt;:4:1: Cycle in type synonym declarations: &lt;interactive&gt;:4:1-16: type A = Maybe B &lt;interactive&gt;:4:19-34: type B = Maybe A 
&gt; `foldl` is not specialized to lists (not anymore, anyway) `Foldable` `Prelude` sounds worse every day. I agree with you when you say &gt; I think making `foldl` in the Prelude strict without specializing it to lists is an ugly design decision 
When a linguist ended up with `nixos` on her laptop.
To each his own definitely, but as someone who sometimes re-defines operators in base (such as `^` as flipped `.`, since I rarely use `^`, and then `P.^` is fine) I'd even use `-` instead of `•`. Looks better than `*` since it's vertically centered. 
Also, I changed the function that wrote the output a bit, but there is perhaps a bit more to gain (1%/3%) easily by using a builder.
I agree with /u/darwin226 that log have nothing to do with side effect. Things could be accumulated in a list and returned this way. However, I also agree that logging in *real time* is a side effect and therefore requires IO.
Note that `mysum` and `average` from the 'Convenience operators and functions' section is also strict in its accumulators, so no need for `seq` or `deepseq` there. I get that this should mostly illustrate a point and that finding good examples of accidental laziness is hard, but this is slightly confusing.
This is a good point! My hope in writing this is not so much to give a good technique, but to demonstrate that at least one such technique is possible. My ideal scenario would be one in which a) we can do proper symbolic differentiation over the program definitions, rather than over their I/O behaviors, and b) we can substitute whatever particular details we want to make it more efficient. Also I think it's cool to be able to view two fundamentally different flavors of machine learning as actually the same, at the right level of abstract. :)
I wonder if I'm missing some assumption here, like everything being compiled with `-O0`. If I compile the `mysum = foldl (+) 0` example with optimizations on, `foldl` gets fused with the list literal, resulting in 48kB of total (!) allocations instead of the 53MB in residency as stated in the post. This should optimize this way at least since GHC 7.10. Of course, this isn't due to strictness but rather because some smart rewrite rules. In general, using `foldl` isn't as bad as it used to be, if only the compiler can fuse things.
&gt; Many algorithms cannot be directly rewritten as eager ones without mutation, they will often incur a log factor. This is true for some online algorithms (with additional constraints, I think), but has never been proven in general, as far as I am aware.
I think I've seen this and /u/HomotoWat's link before, and found it sort of.. orthogonal? Or at the very least not at all comprehensible to me? :\
There are always local optima given that it's ultimately inductive in some form. Like, you can fit your data really well, or not, and it's entirely dependent on your data as a subset of the true I/O relations. There's really no way to avoid this b/c induction of this sort is not inferentially valid, it's just fancy guessing.
Well, in both of those languages, the derivative can be taken over an arbitrary program. The question then is whether a version of gradient descent can be defined in those settings, and to what extent it's useful. It would be different from the technique in your post though, having no clear relation to edit distance, for instance.
Take something which means something for the audience, a brainfuck interpreter is only fun for programmers. On the other hand, solving a real life problem can be interesting because attendee can understand the "new power" you give them. Solving the Sudoku, a tic tac toe AI, a simple physical simulation, ... It all depends on your audience. I had the opportunity to teach a first programming course for engineers a few years ago, most of them will never write a program in their future job. I focused on showing them that after this course, they can solve their problem themself, or at least they know that someone can solve it for them. **Edit**: my course was longer: 2 hours per week for one semester, but here is some of the problems my student tried to tackle at the end of the semester: - Physical simulation of a falling body (student was a skydiver, he wanted to formally understand the exit order from the plane) - Plotting and extracting data from some sensors (GPS for a guy who was running, pressure sensor for the skydiver guy) - A few games, with AI - A few image processing tool, student wanted to understand how a computer can "see". You will not be able to cover that in one hour, well, it depends if they have to code or if it is only a presentation. About more theoretical ideas, it really depends on what they will do after (are they computer scientist ?). But a good introduction to complexity and data structure may change their life...
How would you use this construction? In particular, what type should applyMetaFun have?
Great point! I also might be a minority, but `foldl` was never a problem for me. When it becomes one, you read like one blog post about why it's bad and move on to `foldl'`. Also in the majority of cases, `foldl` isn't actually as bad, because since GHC 7.10 it fuses properly. `sum [1..1000000]` will not allocate with `-O1`, for example, but that's due to a totally separate concept. I also don't think it's `foldl`s nature that's bad here, rather that lists are the wrong abstractions to left fold over, e.g. the `Foldable []` instance.
I don't know if `applyMetaFun :: MetaFun k f g -&gt; ? -&gt; ?` is possible. I don't think so; you can't know how many arguments `f` needs before it "gets to" kind *. I've avoided the issue by having two functions: deleteFun :: MetaFun * a b -&gt; a -&gt; b demoteFun :: MetaFun (v -&gt; k) f g -&gt; MetaFun k (f a) (g a) and just applying them in the amounts necessary. I'm sure that a solution should be possible, but I don't know how to describe a variable amount of variables. I've had to make do with manually adjusting the number of applications of `demoteFun` as needed. I suppose you could work with DataKinds and [*], which would need a new data type, and... Hmm... Edit: never mind, some type variables could have kind * -&gt; *, which wouldn't fit in the list. 
When GHC sees that something has just been pulled out of a strict field, it knows that it's in WHNF already. It will use that information for optimization. No wrappers you install will be able to do that, as far as I know.
There is no `Vector` type in `containers`, and there never has been. Perhaps you mean the one in `vector`? Or maybe the `Seq` type from `containers`?
I suspect you're right, because it would require checking every function which uses the `StrictPair` constructor.
&gt; Does this explain my point? Well, I still don't understand your point. My point is that you can write `ArrayStrict` *yourself* by wrapping `Array`. Is your point along the lines of /u/davidfeuer's [sibling comment](https://www.reddit.com/r/haskell/comments/6zl88c/all_about_strictness/dmxwu0c/) that my wrapping suggestion, despite giving a strict array, would not be able to take full advantage of GHC's optimizations? 
Actually, these 'smart constructors' are exactly the way strict fields are implemented by GHC. Everytime you call a data constructor, you are not actually directly constructing data, but rather what you are calling is the data constructors wrapper function. This wrapper function contains the `seq` calls necessary to model the appropriate strictness. The actual data constructor worker is where stuff is stored, but these are totally lazy in their fields (well, except when fields get unboxed). Proof is in [Note [Data-con worker strictness]](https://github.com/ghc/ghc/blob/master/compiler/basicTypes/MkId.hs#L392-L407). To see this for the example of the `StrictList` type, we just need to peek at the core output: Main.$WCons [InlPrag=INLINE[2]] :: forall a. a -&gt; StrictList a -&gt; StrictList a [GblId[DataConWrapper], &lt;ommitted&gt;] Main.$WCons = \ (@ a) (x :: a) (xs :: StrictList a) -&gt; case x of x' { __DEFAULT -&gt; case xs of xs' { __DEFAULT -&gt; Main.Cons @a x' xs' } } This is after some cleanup. The data constructor wrapper function `Main.$WCons` is eventually inlined and will expose the lazy data constructor worker `Main.Cons`. Edit: Also [this](https://www.reddit.com/r/haskell/comments/6zl88c/all_about_strictness/dmxwu0c/) seems like valuable information.
&gt; Actually, these 'smart constructors' are exactly the way strict fields are implemented by GHC. This is true, but it's an important question whether GHC can apply optimizations to handwritten "strict smart constructors", or only the ones it generates itself.
&gt; also strict in its accumulators What do you mean? `mysum` without `$!` and `average` without `$!!` would not be strict. [EDIT: Accidentally a word]
&gt; I wonder if I'm missing some assumption here, like everything being compiled with `-O0`. Well yes, this is a tutorial about what strictness and laziness are, so changing the operational semantics with `-O` above `0` would be unhelpful!
But then in the conduit example, there's `$ stack --resolver lts-9.3 ghc --package conduit-combinators -- Main.hs -O2`. Well, I would be fine with assuming `-O0` if it was written somewhere. Edit: And I also think it's much more helpful to guide strictness analysis (which is pretty elementary for efficiency in lazy functional languages) by sprinkling bangs in just the right places rather than this approach of throwing bangs everywhere. I guess, what I want is this: Instead of just doing the job a strictness analysis could do, show me programs which don't optimize appropriately, because we are accidentaly too lazy somewhere or where the compiler couldn't figure it out. Then fix it by adding bangs in a principled way. I probably misunderstood the purpose of this post, which is more of an introduction to bang patterns/`seq` to force evaluation rather than actually analyzing a function to see if it is strict in its arguments. Sprinkling bangs at arguments makes a function probably strict in that argument, but most of the time a function is already strict in that argument by definition. It is when this is not the case that we need to think carefully why that is to find out where to place bangs.
It's on github [here](https://github.com/TerrorJack/ghc-alter). If you want STG of a set of modules, take a look at [Language.Haskell.GHC.Alter.Script](https://github.com/TerrorJack/ghc-alter/blob/master/ghc-alter-with-ir/src/Language/Haskell/GHC/Alter/Script.hs), the `compile` function shall suffice (it is similar to `ghc --make`, but retrieves all intermediate representations). The `IR` type is defined [here](https://github.com/TerrorJack/ghc-alter/blob/master/ghc-alter-with-ir/src/Language/Haskell/GHC/Alter/Compiler.hs) and contain all intermediate reps used by ghc. Currently documentation is lacking, sorry about that. Feel free to open an issue if you need help!
No, it also depends on context, as mentioned in some other comment iirc.
This still falls within what I mean when I say "must be in `IO`". EDIT: Perhaps a better potential counterexample is the logging for pure code provided by the [simple-logger](http://hackage.haskell.org/package/simple-logger) package, mentioned elsewhere in this thread. It is in `IO` under the hood, but hides it with `unsafePerformIO`. I think at the end of the day I would still say that qualifies for "must be in `IO`".
Interesting. You should post this feature request on Trac.
Right, David Feuer made an [excellent point](https://www.reddit.com/r/haskell/comments/6zl88c/all_about_strictness/dmxwu0c/) on that.
Can you provide more detail? What is your proposed syntax?
Awesome &amp; thanks, already itching &amp; looking forward to delving into it!
Do you have any examples where you actually use the `k` kind parameter? I'd love to see that! From what I can tell, your current examples can be written *without* `k` {-# LANGUAGE GADTs #-} {-# LANGUAGE PolyKinds #-} {-# LANGUAGE RankNTypes #-} import Data.Kind data MetaFun (f :: k) (g :: k) where BaseFun :: (a -&gt; b) -&gt; MetaFun a b LiftFun :: (forall (a :: v). MetaFun (f a) (g a)) -&gt; MetaFun f g safehead :: [a] -&gt; Maybe a safehead = foldr (const . Just) Nothing meta_safehead :: MetaFun [] Maybe meta_safehead = LiftFun $ BaseFun safehead demoteFun :: MetaFun f g -&gt; MetaFun (f a) (g a) demoteFun (LiftFun f) = f deleteFun :: MetaFun a b -&gt; a -&gt; b deleteFun (BaseFun f) = f 
I agree entirely with what you say, with the sole caveat that this article is a "baby's first guide to strictness" not a "Haskell experts' guide to performance".
In 20 minutes you won't have a lot of time. Why not create a binary tree ? Most of your attendee know what they are, so starts with: data Tree t = Node (Tree t) t (Tree t) | Leaf And explain about polymorphism (that's a `Tree` of `t`, whatever `t` can be) and sum types. Then show that you can build `Tree` easily, that type creation also creates constructors. t = Node (Node Leaf 1 Leaf) 3 (Node Leaf 5 Leaf) Make no assumption of "ordering" for now. Introduce the first function with pattern matching : sumTree Leaf = 0 sumTree (Node suba v subb) = sumTree suba + v + sumTree subb Discuss of case analysis is great, how the compiler will prevent you making mistakes, such as forgetting a case. Tell them that this function is statically typed (and checked), but so easy to write thank to type inference. Then introduce `deriving`: deriving (Show, Serialize, Foldable, Functor, Arbitrary, Ord, Eq) With one slide per deriving clause, to show that it reduces boilerplate. I like that introduction because it can show simple syntax, statically typed yet simple to write and the wonders of boilerplate reduction using `deriving`. I just uploaded a twenty minutes video (it was my lunch break) with something like that (be careful, French accent, not prepared, many mistakes, not for release quality ;) https://www.youtube.com/watch?v=A-fa6A3ypz0&amp;feature=youtu.be
Video linked by /u/guibou: Title|Channel|Published|Duration|Likes|Total Views :----------:|:----------:|:----------:|:----------:|:----------:|:----------: [Haskell Introduction with Generic Tree](https://youtube.com/watch?v=A-fa6A3ypz0&amp;feature=youtu.be)|Guillaume Bouchard|2017-09-13|0:00:00|0+ (0%)|0 --- [^Info](https://np.reddit.com/r/youtubot/wiki/index) ^| [^/u/guibou ^can ^delete](https://np.reddit.com/message/compose/?to=_youtubot_&amp;subject=delete\%20comment&amp;message=dmxzl7u\%0A\%0AReason\%3A\%20\%2A\%2Aplease+help+us+improve\%2A\%2A) ^| ^v2.0.0
I think that this is the disparity here, because I agree with both of those points. Logging real-time necessitates IO, but logging in some general form (in the sense of collecting messages during the execution of a program) does not.
&gt; I added the {-# LANGUAGE Strict #-} pragma to one of my very small packages (continued-fraction), and it made the benchmark I had jump from 8.839 μs to 10.36 μs. Interesting! Would it be possible to pull out a simple example from this library, with an explanation of why adding strictness increased benchmark times? A side note, the GitHub links on the continued-fraction hackage page return 404 errors.
From the blog post: &gt; minimum = head . mergesort &gt; &gt; that extracts the smallest element of a list. Given a proper mergesort, laziness will ensure that this function actually runs in O(n) time instead of the expected O(n log n). It'd be very cool if, for large input list of values, this lazy Haskell programs runs more quickly than an equivalent function implemented strictly in C. Did you try benchmarking this `minimum` example versus C or C++ to see if O(n log n) with C/C++ is slower than O(n) in Haskell?
I think there is no syntax, it is just a compiler thing. That's like `-fdefer-out-of-scope-variables`, `-fdefer-typed-holes` and `-fdefer-type-errors`: instead of generating a fatal error, the compiler just replace the erennous code by `error "defered to runtime"`. See for yourself: Prelude&gt; :set -fdefer-type-errors Prelude&gt; let f x = (not x, 2 : x) &lt;interactive&gt;:5:23: warning: [-Wdeferred-type-errors] * Couldn't match expected type `[a]' with actual type `Bool' * In the second argument of `(:)', namely `x' In the expression: 2 : x In the expression: (not x, 2 : x) * Relevant bindings include f :: Bool -&gt; (Bool, [a]) (bound at &lt;interactive&gt;:5:5) Prelude&gt; -- it was a WARNING, now f exists, see its weird type: Prelude&gt; :t f f :: Bool -&gt; (Bool, [a]) -- it can even be used, but it trigger another warning Prelude&gt; res = f 10 &lt;interactive&gt;:8:9: warning: [-Wdeferred-type-errors] * No instance for (Num Bool) arising from the literal `10' * In the first argument of `f', namely `10' In the expression: f 10 In an equation for `res': res = f 10 Prelude&gt; :t res res :: (Bool, [a]) -- Now, we want to acces the values Prelude&gt; fst res *** Exception: &lt;interactive&gt;:5:23: error: * Couldn't match expected type `[a]' with actual type `Bool' * In the second argument of `(:)', namely `x' In the expression: 2 : x In the expression: (not x, 2 : x) * Relevant bindings include f :: Bool -&gt; (Bool, [a]) (bound at &lt;interactive&gt;:5:5) (deferred type error) 
Reminds me of ~~natural~~ parametric transformations, which I played with [in a post about two months ago](https://github.com/rampion/kinder-functor#natural-transformations): newtype Parametric (cat :: k -&gt; k -&gt; *) (f :: j -&gt; k) (g :: j -&gt; k) = Parametric { runParametric :: forall x. cat (f x) (g x) } So to borrow your example: safeHead :: [a] -&gt; Maybe a safeHead (a:_) = Just a safeHead [] = Nothing safeHead' :: Parametric (-&gt;) [] Maybe safeHead' = Parametric safeHead And to choose a silly example: choose :: Bool -&gt; (a,b) -&gt; Either a b choose True (a,_) = Left a choose False (_,b) = Right b choose' :: Bool -&gt; Parametric (-&gt;) ((,) a) (Either a) choose' b = Parametric $ choose b choose'' :: Bool -&gt; Parametric (Parametric (-&gt;)) (,) Either choose'' b = Parametric $ choose' b -- = Parametric $ Parametric $ choose b You may be interested in [the discussion on reddit](https://www.reddit.com/r/haskell/comments/6i7nil/kinderfunctor_using_typeintype_with_a_polykinded/). I particularly recommend following the links in /u/edwardkmett's comment and reading through his implementation of Hask; his work in this area is really revealing and impressive. Edit: Replacing `Natural` with `Parametric` so I don't forget again. 
Be careful, the notion of naturality you are using there is really parametricity. While they are related concepts, parametricity is considerably stronger. If you go to do things like try to define products and coproducts using limits and colimits where you use this notion of parametricity in place of naturality you will get stuck! Parametricity gives you one function that is usable at multiple types (objects). Naturality gives you a set of functions indexed by the set of objects in your category, and can care about what those objects are so long as that doesn't affect the commutativity of the only diagram involved in defining naturality. While this diagram is implied by the free theorems involved, so are other diagrams, making parametricity a stronger property than naturality. Hermida, Reddy and Robinson's paper [Logical Relations and Parametricity - A Reynolds Programme for Category Theory and Programming Languages](http://www.cs.bham.ac.uk/~udr/papers/logical-relations-and-parametricity.pdf) is probably the best introduction to the issues involved and the general distinction between these two closely related, but distinct, concepts.
Definitions aren't necessarily tautologies. Your notion of tautologies is a non sequitur and thus irrelevant in the context of what you're stating. You're arguing a point &gt; I'd claim that /u/yitz and /u/codebje are wrong that by definition is wrong. It takes no philosophical skills to understand that. 
Yes, that was it, thank you, seems it wasn't as serious as I remembered.
Right. But people seem to be talking past each other in this thread. Some people are talking about *before* specialization ("without mentioning IO ever") and some are talking about *after* ("except at the very top in main"). I think the disagreement is artificial.
You told me this last time and it didn't stick, so I edited my comment so hopefully I remember next time. Thanks!
... And that's what I get for boilerplate copy-pasta-ing cabal files between projects. =/ Yes, the Vector type from `vector`, thank you.
I agree. But it could give the wrong impression that the Haskell optimizer does no work in this area when it actually does quite a lot. It's just the kind of thing that belongs in a footnote or something. NBD
Start with a brief quick walkthrough of the syntax and how to read type signatures. Then maybe, to catch their interest, find some bugs or issues you have encountered earlier in your work in the other languages, and show how Haskell might have been applied to eliminate these kinds of issues entirely (if possible, of course).
Nice article. In a way, the shape monoid is not so different from the set example you gave; you've just taken a set complement and so unions are replaced by interesections and the null set by the universal set ;). I disagree with one of the points though: &gt; In fact, we must not be able to tell or the abstraction is broken. Associativity requires this kind of information to be erased. This is the point of an abstraction: getting rid of unimportant details. A monoid does have generators. For a string, the generators have the special property that they are chars/strings of length 1 and are thus finite in number. So it's easy to determine if a string is "primitive" or not. If the number of generators is small, finding out whether the object is a generator might not be so hard. In the shape case, the number of generators is infinite (you can have disks of arbitrary radius) so it's not possible to give a yes/no answer but I think it should be possible to assign a probability by sampling the function repeatedly (e.g. a non-convex shape is definitely not a disk or a rectangle).
Oh whoops, the correct link is [here](https://hub.darcs.net/vmchale/continued-fraction). I need to fix the package. As it happens, laziness makes my benchmarks around 11% faster on GHC 8.0.2 and 50% slower on GHC 8.2.1. So I'd be wary of even saying strictness is bad. Just benchmark the code if in doubt, honestly.
Thank you for the nice comment :) Indeed, the shape example resembles predicates which resembles to sets (since we can see a set as a function which returns whether an element is inside the set - something that Clojure sets actually do). That is quite an interesting thought: to which point the concepts we play everyday with look like the standard examples of Monoids (numbers, sequences, associative containers)? Now regarding your remark, nothing forbids us to create a string of length 1 from a succession of an arbitrary number of `mappend` with the empty string. So, we are not able to say how a value has been constructed, however simple it is. My point is that the number of calls to `mappend`, and the whole process of constructing a value in general, has to be abstracted away for this to work.
Based on your username, I'm assuming your the author of Haskero. I just switched from spacemacs + intero to VSCode + Haskero, and the same file, which was type-checking in under 5 secs in intero, is taking ~5 minutes in Haskero. How can I understand more about this problem? Also, is there an official channel for bug-reports, etc? PS: If you are indeed the author of Haskero, thank you for doing this. I'm dying to get rid of Emacs and VSCode+Haskero seems pretty neat!
I just realised that I was actually replying to &gt; Given a value, we do not have to care how it was built, and whether it is a composite or not. We might not be even to tell but I quoted the footnote instead by mistake. Oops. My point was that, while I agree with "we do not have to care how it was built, and whether it is a composite or not", I disagree with "We might not be even to tell" -- you _can_ actually tell whether it is a composite or not -- if the element you have is a generator (which is easy to check if you have only finitely many generators), it is not composite. --- &gt; nothing forbids us to create a string of length 1 from a succession of an arbitrary number of mappend with the empty string. Yes, that's technically correct but it's kinda' redundant because inserting identity elements is a no-op. Generators are of course treated modulo the identity.
I agree that 20 mins is going to be difficult to cover most topics if the audience is unfamiliar with Haskell. If you show code, you'll need to take time to explain the most simple things like how `f x y` is `f(x, y)` in most other languages. You could try to gloss over this stuff, but curious programmers might interrupt you with questions and derail your presentation for minutes at a time.
&gt; You could try to gloss over this stuff, but curious programmers might interrupt you with questions and derail your presentation for minutes at a time. You pretty much have to say "I'm glossing over this stuff. Just believe me. Ply me with drinks afterwards for more info." and move on right away.
&gt; Finally, and thanks to the associative nature of the Monoid operator, we never have to care about the order in which these intersections take place. Correct me if I'm wrong, but I think you're talking about the commutative property particular to the union/intersection operators. In general a monoid is not commutative, and can care about what order the composition happens in. A simple example is string concatenation: `"he" &lt;&gt; "llo"` is different from `"llo" &lt;&gt; "he"`. Edit: maybe you are talking about the associativity, and by "order" you mean `(a &lt;&gt; b) &lt;&gt; c` vs `a &lt;&gt; (b &lt;&gt; c)` but this really doesn't seem clear, especially when you say: &gt; We can first intersect a rectangle with a disk and then a ring, or do it the other way around. It does not matter: given a shape, we never have to care how it was constructed. Might be good to mention commutivity.
&gt; it won't work with any other JS supporting compiler Is there another Haskell 2010 compiler that targets JavaScript that you're thinking of?
You can show off a simple automatic differentiation system. 20 lines of code can get you to differentiating polynomials, and it only takes a few more lines to add trig functions and the like. It's impressive and elegant—before I learned about it the whole idea seemed impossible; afterwards, it felt entirely natural. If you have more time after that, you could demonstrate a symbolic type for numbers where you produce and simplify an expression tree. Then you could plug *that* into your AD code and get a symbolic differentiation algorithm. The best part is that neither the AD algorithm nor the symbolic arithmetic type have to know anything about each other! If you're curious for more details, I wrote more details about this [on Quora](https://www.quora.com/What-are-20-lines-of-code-that-capture-the-essence-of-Haskell-Try-to-follow-standard-Haskell-style-Comments-and-spaces-between-code-do-not-count-as-lines-They-can-also-consist-of-individual-snippets-of-code-but-have-to-add-up-to-20-lines/answer/Tikhon-Jelvis?share=1).
I meant like in future. If a solid competitor to GHCJS came out all this code would have to be changed substantially to work on it. And older versions would never work on said compiler. Also if GHC enabled JS interop via node or via webassembly then again all this code won't work. 
Yeah that is exactly what I'm talking about. One thing I would note is that having a `-fdefer-ffi-errors-no-warn` or similar as well would be nice. As otherwise my tooling will spit out said warnings every time when I really don't need to see them.
I made an experience recently where I compare two similar implementations of a ray tracer, one in Haskell, the other in C++: https://github.com/guibou/smallPTHS (Pull request accepted, the code sucks I know, initially I wanted to copy the C++ code, but It ended with a few ugly tricks). The results in the readme are outdated, best to `git clone; stack bench` yourself, but I achieved 1.5x slower on 6 core hyper threaded in haskell compared to C++. There is still room for improvement, mostly there is still a space leak that I don't understand and unpacked sum types of GHC 8.2 may help a lot because most of the time is spent creating `Maybe`. This benchmark, as most, is useless, but if we want we can conclude that GHC can be enough fast for some needs, too slow for others ;)
Yeah, exactly. Do you know of any effort/interest in having this sort of array (or something similar) in GHC?
Indeed, I did not realized how confusing it might end up being. Thank you for the comment, and I will add an edit note on this.
Done! https://ghc.haskell.org/trac/ghc/ticket/14227#ticket
Ok, got it. In some cases indeed, and considering the identity as a no-op, we could be able to guess. You're perfectly right there. But then it depends on the Monoid. In many cases, take money amounts or shapes, or just integers, we are quite powerless in guessing. So I would argue my claim still holds: "we might not be even to tell". I think my second claim is wrong though (the first one you linked). Since indeed, you might be able to tell, but it does not mean that the abstraction is broken.
Good idea,
In Python I do it usually as follows: der fun_that_can_fail(args, ...): if (something_is_not_right) return False, 'description of problem' ... return True, result ... success, val = fun_that_can_fail(args, ...) if not success: err = val return False, 'fatal: {}'.format(err) result = val So I return True/False from the function and pack the Result/Error into the second return value (similar to `Either Error a`).
I'd spend 5 minutes letting Simon PJ explain how radically different the Haskell approach is [Haskell is useless](https://www.youtube.com/watch?v=iSmkqocn0oQ), and how, from that perspective, most other languages don't fix the problem (of engineering safety into a software product). Then I'd do an example app that uses Quickcheck for testing properties. Quickcheck has been ported to many languages and might be immediately adoptable into the company. Here's a web example: [https://www.schoolofhaskell.com/user/christianpbrink/quickcheck-and-webdriver](https://www.schoolofhaskell.com/user/christianpbrink/quickcheck-and-webdriver)
Haskell can get pretty fast. When it doesn't get fast enough, it can delegate out to C or C++ with fairly minimal overhead. It is not always straightforward to tune Haskell performance - But, the same can be said for many languages. Space-leaks are extremely overblown as a risk - When learning Haskell, you will encounter them, and in doing you will learn how to avoid them. Excessive memory use is something that you need to think about while writing Haskell, but it's generally not overcomplicated to avoid, and the language gives you many powerful tools to allow you to control memory use with a high degree of precision. All told, writing solid Haskell while being somewhat mindful of memory use will probably give you performance on par with a typical C# or Java implementation for most small programs. Whether or not tuned Haskell can surpass those languages, also tuned, varies based largely on context. But I have yet to see examples where well-tuned Haskell comes away from the fight with a black eye. As Haskell is not an industry leading programming language, (in terms of adoption) sometimes relatively popular libraries or frameworks for web development will have issues with performance at scale - Simply put, the man hours that go into tuning this code are nowhere near the amount of man hours that have gone into tuning frameworks for more popular languages. However, chances are high that you're never going to end up in a situation where the choice of Haskell is crippling your ability to scale. None of this is a reason to, or not to, write code in Haskell. You may want to learn Haskell if: * You want to expand your horizons and learn some useful new concepts * You're curious about programming languages and the theory behind them * You want a solid, strongly typed, general purpose language to solve a problem * You are looking for a language that absolutely excels at maintenance-free (or maintenance light) abstraction * You want to write a compiler * You want to write a language * You want to write a DSL that outputs assembly, but introduces strong type safety * You don't mind the idea that you'll have to spend some time writing your own libraries to solve fairly common problems You may not want to learn Haskell if: * You're looking for a language someone in the US will pay you to write code in * You want a language that interoperates well with legacy (early 2000s - early 90s) software solutions * You want to make a performance heavy, 3D video game. * You want stress-free cross-platform compilation (as in, when target differs from host. If you don't mind setting up a bunch of VMs for different target architectures, platform compatibility is less of an issue.) 
I would suggest implementing a small text editor for VT100 terminals. It would work on every machine (there's always an XTerm somewhere) - just support the classic commands (left, right, up, down, start-of-line, end-of-line, remove-last-char/delete, save and quit should be sufficient) - you could even go into parser combinators when implementing the escape-sequence (that you get from you tty) parser. Some other nice examples: - Tic-Tac-Toe solver (just brute force it) - Turing-Machine simulator - Paint-Clone - λ-calculus interpreter All of them should fit into &lt;200 LOC and afterwards people can play around with the implementation.
They are wrong in the way that I have described in my other posts in this thread. They are right in a way that I find useless, or at least, non-operable. Real-time logging functionality needs IO to _run_, sure, but then again so does everything else in Haskell. It doesn't need IO to be described. Fortunately our reasoning works on descriptions, so this is good enough. To be more direct, you could use the same reasoning to say that adding two integers requires IO. If you think this is sensible or _useful_ then I can only reiterate what I said in the comment you replied to.
&gt; When we tried implementing statistics as SQL queries in Postgres, we were amazed by the performance. When you use a real database, you get real performance. This isn't something you get when you use stuff backed by hype instead of decades of research. It makes me sad every time I read an article like this, and I hope that other people won't make the same mistakes with datastore technologies. If you are thinking about using ElasticSearch, at least one of these should be true: 1. Your data will not fit on a single host 2. You have more than 10,000 inserts per second (probably implies number 1) 3. You need good full-text search If none of these are true, you probably don't need ElasticSearch. And if you don't need ElasticSearch, you definitely don't want to be using it. I'm glad to hear that the team at Lumi figured this out, and I hope others don't have to go through this experience.
I've created two Rust versions, straight ports from the Java code. The Rust version A, it uses the ordermap and smallvec crates: https://gist.github.com/anonymous/90665da32d214727c43b3ec7d01c38b5 I've created the Rust version B, it uses just the ordermap, it cheats a little because it contains two tuning constants determined from running the first program: https://gist.github.com/anonymous/89d3a7a15ee9c73598684666bba0ea05 The timings on my PC, seconds: Python 51.40 Java 28.70 C 13.60 Rust A 4.45 Rust B 3.46 Python 3.6.2 rustc 1.22.0-nightly (opt-level = 3) gcc v.7.1.0 -Ofast javac 1.8.0_102 CPU i7 2.3 GHz
I can't disagree with you. We started with Rethink, and ElasticSearch was added when we needed search. In retrospect it's somewhat obvious that it wasn't the right choice, although it got us a lot quickly at the time.
I haven't actually used RethinkDB, but I'd like to get your opinion on something since you have used it. From my cursory perusal of the docs, my understanding is that the most compelling feature is that it has two compelling features: 1. Can push updates to clients when insert/update happens 2. Is distributed The second point should mean that you can store more data but that joins will be worse (potentially much worse) and that checking integrity constraints will be worse. Correct me if that isn't representative of your experience. The first feature is the one I'm more interested in because all modern relational databases offer something similar: triggers. The weird thing about triggers is that big enterprise environments (where multiple applications use the same database) seem to like them but startups (where only a single application uses a database) seldom use them. My theory is that, if only one application is using a database, triggers don't provide that much value. After all, you could just do the same thing in the application layer, assuming that your application doesn't have SQL inserts strewn all over the codebase. So, my theory is that RethinkDB's killer feature, pushing updates, falls in that same category. It seems like, in the absence of multiple applications, that you could just do the pushing in the application layer. Just some musings, but I'd like hearing any thoughts you have as well.
See these recent discussions: * [I want to write a configuration management system in haskell. ](https://www.reddit.com/r/haskell/comments/6xqsqj/i_want_to_write_a_configuration_management_system/) * [Funny, I also wanted to write a configuration library. What do you think about it?](https://www.reddit.com/r/haskell/comments/6y2gu5/funny_i_also_wanted_to_write_a_configuration/)
How to read streams by line?
So point number 1 is true you can use changefeeds from RethinkDB. It is similar to triggers in a sense, but easier to use. It is a cool feature, but wasn't providing us any benefit. On point 2 yes it is distributed and offers different configurations around that and sharding per table, etc. I am no ops expert and I know RethinkDB has never claimed to have worked on performance, but joins are painfully slow even when we didn't have data distributed. RethinkDB did allows us to iterate quickly as we grew being schemaless, but it was the right decision to switch to Postgres.
Have you considered using [jsaddle](https://github.com/ghcjs/jsaddle) and writing: #ifdef __GHCJS__ foreign import javascript unsafe "foo($1)" js_foo :: JSString -&gt; IO JSString #else js_foo :: JSString -&gt; JSM JSString js_foo x = jsg ^. js1 "foo" x #endif That should compile on GHC and also run (in GHCi too).
The whole point of this suggestion is to get rid of the `#ifdef __GHCJS__` since it disallows me from using many GHCJS libraries in GHC (as if those libraries don't also do `#ifdef` they won't be importable), bloats my code, and locks me into GHCJS. Any solution that still requires `#ifdef __GHCJS__` does not address my issue. I am not primarily concerned with actually running JS with GHC, since I have GHCJS for that.
It depends what you mean by traditional procedural/oop languages. Because Haskell will blow Python, JavaScript, PHP, Ruby etc. out of the water. And even Java, C#, Obj-C and so on are about the same speed as Haskell in the average case, and when dealing with "ideal" and highly optimized code Haskell is going to win due to it compiling to true assembly directly with complete type erasure. And as a side note in terms of memory usage Haskell is generally way better than Java. Only C, C++, Rust and similar are going to consistently beat Haskell.
How many rows do you have to search through? IME PostgreSQL's full text search scales up to a few million. Although I haven't tested it on a 50 million row codebase since like 2011, when it took a couple seconds to return a result vs milliseconds of Sphinx. Apparently it's near Sphinx speeds now. Might give it another try sometime.
In another post they give this suggestion: Look for an important bug that could be completely eliminated with Haskell type system and explain them why 
Just to be clear I am not against your proposal. I am just curious why you are not using `jsaddle`. &gt; The whole point of this suggestion is to get rid of the `#ifdef __GHCJS__` since it disallows me from using many GHCJS libraries in GHC (as if those libraries don't also do #ifdef they won't be importable) Any libraries in particular? I would be happy to help update them if it is possible (most of the time it is). &gt; and locks me into GHCJS. jsaddle works on GHCJS (it is just slower than JSFFI so it is still a good idea to have the `#ifdef`) as well as GHC and we can add support for other compilers that come along. &gt; Any solution that still requires `#ifdef __GHCJS__` does not address my issue. With jsaddle the `#ifdef __GHCJS__` is only required to get performant code on GHCJS (the jsaddle version will work on GHCJS, but it is slower). We could get around this with template haskell, but then compile time suffer. The long term solution might be to update GHC to output something for JSFFI that JSaddle could hook into.
I don't really personally like the name `safe` for a variety of functions that can all throw exceptions. If I call `safeFoo` on some non-bottom value I would be very unhappy to get given back `_|_`.
We're not at the point where that would be an issue for us yet, thankfully. Postgres can certainly handle quite a bit more than what we're throwing at it :) When we get to incorporating full text search, I might write another one of these with some performance numbers.
Ok, I will change the name and add versions with a Maybe result, but to avoid bad results while instantiating Num, I can only throw exceptions. Suggestions are welcomed.
How is the overall time? If the same code got 60% slower on 8.2 maybe open a ghc trac ticket so someone can look at what caused that regression. Or did the strict time simply improve so much?
PostgreSQL also has listen/notify to push updates to clients when data changes. Even with a single app, it can be useful for triggering background jobs or keeping application layer caches in sync.
&gt; Just to be clear I am not against your proposal. I am just curious why you are not using jsaddle. I'm not using jsaddle because it doesn't solve my problem. I'm not trying to run any JS outside of GHCJS. I am trying to type check GHCJS-only code with GHC, and I'm also trying to avoid any CPP compiler hardcoding boilerplate. &gt; Any libraries in particular? I would be happy to help update them if it is possible (most of the time it is). ghcjs-base itself is the main one I am currently having issues with, so right now I'm just using ghcjs-base-stub and trying to PR missing modules and such as necessary. But its a lot of effort and slows down development. &gt; jsaddle works on GHCJS (it is just slower than JSFFI so it is still a good idea to have the #ifdef) as well as GHC and we can add support for other compilers that come along. It would be nice if any new compilers that implement a JS FFI were fast right of the bat, but that is pretty convenient. &gt; With jsaddle the #ifdef \_\_GHCJS\_\_ is only required to get performant code on GHCJS (the jsaddle version will work on GHCJS, but it is slower). We could get around this with template haskell, but then compile time suffer. Well my requirements are essentially, high performance GHCJS, and type checking GHC. So therefore with jsaddle I still need `#ifdef` (plus a bit of extra code since I won't be just writing `undefined`) and some libraries still don't work. So it doesn't help for my use case. &gt; The long term solution might be to update GHC to output something for JSFFI that JSaddle could hook into. That would definitely be cool, I would love it if GHC supported javascript FFI, at minimum I am just focusing on the type checking aspect but actually running it would be nice.
If I might be presumptive, this will change the output but might be what you want: T.unwords [ strvar , "additional" , var2 , var3 ] You can replace `T.unwords` with `T.intercalate " "`, if you want to customize the separator. 
I think naming the types something that means strict / non-overlapping int (just not "safe") or similar and having `+` and similar throw is probably ok. But yeah having `safeAdd` return a `Maybe` would be great, thanks.
I know this isn't what you're asking for at all, but I thought I'd mention it: Having a jsaddle-compatible implementation is pretty valuable. Being able to test using webkitgtk or jsaddle-warp makes the dev cycle much much easier. And if you do have a jsaddle-compatible implementation, your app will likely work on WebAssembly for free in the distant future where we have that working and have a jsaddle backend =P 
I mean if ghcjs-base was made jsaddle compatible I would be fine with that, I just hate that right now I can't use any of ghcjs-base unless its also in ghcjs-base-stub. I also hate the large amount of boilerplate I need to define some custom JS FFI stuff. I mean most of the testing I am doing is testing the UI, so a lot of it is hard to test in isolation, but I can see how it could be helpful. Wouldn't a jsaddle backend for WebAssembly be just as slow as JS? Since it IS js? Or am I missing something. On a side note what is the timeline on GHC/Haskell to WebAssembly? I am ridiculously excited for that. 
Using the function-based representation of shapes, does this not mean that e.g. `mconcat (replicate 1000000 mempty)` will require a large mount of memory for all the closures (and run very slowly when you query whether a point is inside the shapes)? The problem I see with such a function-based representation is that it does not permit optimisation of the composition, since functions are black boxes.
now I have * intAddEx, intProdEx, intCastEx, * intAddMay, intProdMay, intCastMay, plus IntEN types that implement Num with the exception throwing variants.
based postgres
Deferred type errors is one of those things that I've known about, but haven't really used or seen them used. Thanks for the neat little example repl session! Interesting how `f` somehow forgets about the `Num` constraint on `a`; it should know at least that much about it.
Great! I appreciate the quick response to feedback, and I could definitely see this being useful. Have you benchmarked this at all? If the performance isn't too much slower than `Int` I could see it being useful, I suppose even if it is quite a bit slower it could be used for testing then switch to `Int` for when performance matters. Since for situations where performance isn't a major concern you may as well use `Integer`, so this to me seems like it would be for high-performance situations where you cannot afford overflow errors.
Why are you finding yourself writing so much JS FFI? `ghcjs-dom` (which is jsaddle-compatible by default) uses WebIDL to generate Haskell binding to most of the APIs exposed by the browser. &gt; I mean most of the testing I am doing is testing the UI, so a lot of it is hard to test in isolation, but I can see how it could be helpful. I'm not sure I understand. The native backends for jsaddle give you fully functional applications. You can do full UI tests just fine. &gt; Wouldn't a jsaddle backend for WebAssembly be just as slow as JS? Since it IS js? Or am I missing something. Well yes and no. The parts calling the browser will then be no faster than JS. But this is true of all WebAssembly code at the moment; you always have to marshal through JS. But the language itself will run much faster than JS. So for calculation-heavy stuff like Reflex, you will likely see a decent performance improvement. &gt; On a side note what is the timeline on GHC/Haskell to WebAssembly? I am ridiculously excited for that. Not Soon™ =P On top of WebAssembly itself still in the process of being standardized, the toolchains still need work, and GHC needs work. Only once all these stars have aligned can we even consider working on actually interacting with the browser from WebAssembly.
Was this actually what you intended to write or was this a covfefe moment? :)
&gt; RethinkDB did allows us to iterate quickly as we grew being schemaless What does this mean? I hear people say this about schemaless databases all the time, but I don't understand what is meant by it. Surely in the application layer written in haskell, your data had some kind of schema (or maybe it was actually all just `Map Text Text`). Do you mean that you didn't have to write migrations when you added new fields? Or are you talking about something else?
I'm just jealous that I'm stuck on MySQL.
So actually originally our api was written in JS with RethinkDB. Only later did we rewrite in Haskell. But yes we didn't have to write migrations as we were figuring things out. It isn't like it would have been a big burden to deal with Postgres. In the end I wouldn't say RethinkDB was the wrong decision, but I will say it was the right decision to switch to Postgres now.
Sorry for the radio silence! I prefer writing code than prose ;) In this post I wrote a bit about my experience and what I did in my project. Comments and questions are welcome!
Hi, I have not benchmarked it. I have written this as a consequence of some thoughts on Algebra and arithmetics, relating the *Num* typeclass to an algebra Ring and *Fractional* to an algebra Field, that I wrote at the Haskell wikipedia page section https://en.wikipedia.org/wiki/Haskell_(programming_language)#Haskell_Base_library_and_Algebra that you are invited to revise. I googled for addition/product implementations throwing *overflow* and I found that gcc does it through infinite precision routines https://gcc.gnu.org/onlinedocs/gcc/Integer-Overflow-Builtins.html but with the addition, testing the result for different *signum* function outcome is faster for the product I mimiqued *gcc*, using the unlimited precision type *Integer*.
&gt; ghcjs-base itself is the main one I am currently having issues with, so right now I'm just using ghcjs-base-stub and trying to PR missing modules and such as necessary. But its a lot of effort and slows down development. [jsaddle](https://hackage.haskell.org/package/jsaddle) itself provides a lot of the same modules as `ghcjs-base` are the ones you need missing? I would be happy to add more if it helps. 
&gt; Why are you finding yourself writing so much JS FFI? ghcjs-dom (which is jsaddle-compatible by default) uses WebIDL to generate Haskell binding to most of the APIs exposed by the browser. I'll take a look into `ghcjs-dom`, will it perform just as well as calling through the FFI directly? What should I use for documentation for it? &gt; I'm not sure I understand. The native backends for jsaddle give you fully functional applications. You can do full UI tests just fine. Oh wow, that's interesting, so then what would it take to say make [react-hs](https://github.com/liqula/react-hs) work natively? &gt; Well yes and no. The parts calling the browser will then be no faster than JS. But this is true of all WebAssembly code at the moment; you always have to marshal through JS. But the language itself will run much faster than JS. So for calculation-heavy stuff like Reflex, you will likely see a decent performance improvement. Ah I see what you are saying now. So I could run hopefully close to native Haskell (assuming WebAssembly works as planned) speeds whenever I am not directly touching the DOM. &gt; Not Soon™ =P On top of WebAssembly itself still in the process of being standardized, the toolchains still need work, and GHC needs work. Only once all these stars have aligned can we even consider working on actually interacting with the browser from WebAssembly. Aww, so does that mean its probably going to be 1 year+? I can't wait because I really think this + reflex mobile could be a killer feature for Haskell that makes it a lot more mainstream.
One thing I should note is that `Int` is already a lawful `Ring` even with overflow. It is of course sometimes more practical to want exceptions when `Int` overflows instead of silent behavior that may surprise people. And ah ok nice job, that all makes sense. I am hoping that things like branch prediction should keep things quick. I would suggest considering benchmarking, as I usually only use `Int` when performance matters since `Integer` is quite quick and has no overflow issues.
When compiling with `GHCJS` are they compatible with said `ghcjs-base` modules / types? Because the framework I use (react-hs) calls into `ghcjs-base` quite a lot, so that is probably needed for my purposes. As for missing modules `JavaScript.Web.Storage` is the one that I just added to `ghcjs-base-stub` that prompted me to create this proposal. Also if I imported said modules from `jsaddle` and compiled with GHCJS would they give me the same performance as the `ghcjs-base` modules? Because really all I want is fast GHCJS output and type checking in GHC, GHC performance / runnability is not a priority, but obviously it would be nice to have so if `jsaddle` gives me the things I need then I would be open to using it.
One thing I can think of is IIRC certain data structures such as finger trees only have the amortized time complexities asserted under lazy evaluation. With strictness + referential transparency you can generally break most amortized analysis by replicating the data structure many times right before it is going to do an expensive operation (for example reversing the back list of a bankers deque) and then calling the "cheap" operation on every one of the copies independently. Also I'm not sure of a particularly good way to do (without `ST` or `IO`) dynamic programming algorithms without something along the lines of using laziness to tie a knot on a data structure with `O(1)` reads like a vector. One thing also worth noting is that even if its theoretically possible to do it strictly, I can imagine it might sometimes be impractically difficult, since using a bit of knot tying can work fantastically to solve many problems very quickly and with very little code and not too much room for error.
&gt; I'll take a look into ghcjs-dom, will it perform just as well as calling through the FFI directly? What should I use for documentation for it? Yes. The difference between it and jsaddle-dom is that when built with GHCJS, it uses the JS FFI, and when built with GHC, it delegates to jsaddle-dom (which does its own thing). &gt; Oh wow, that's interesting, so then what would it take to say make react-hs work natively? react-hs would just have to use only ghcjs-dom and/or jsaddle for all its JS interaction. It can use the JS FFI directly as long as it also has a GHC version of the function that uses jsaddle. &gt; So I could run hopefully close to native Haskell (assuming WebAssembly works as planned) speeds whenever I am not directly touching the DOM. Right. And fwiw, touching the dom is basically never the most expensive part in any app, so WebAssembly should pretty much always be a noticeable improvement. &gt; Aww, so does that mean its probably going to be 1 year+? I would assume so. But anything could happen =P
&gt; When compiling with GHCJS are they compatible with said ghcjs-base modules / types? Because the framework I use (react-hs) calls into ghcjs-base quite a lot, so that is probably needed for my purposes. Those modules are only in `jsaddle` when compiled with `ghc`. When compiled with `ghcjs` `jsaddle` uses `ghcjs-base` instead. Although normally you would do something like: if impl(ghcjs) build-depends: ghcjs-base else build-depends: jsaddle Because of the performance issues with `jsaddle` on `ghcjs`. If you like you can think of `jsaddle` as being a bit like `ghcjs-base-stub`, but with working `ghc` functions. &gt; As for missing modules JavaScript.Web.Storage is the one that I just added to ghcjs-base-stub that prompted me to create this proposal Could you use the `ghcjs-dom`module `GHCJS.DOM.Storage` instead? `ghcjs-dom` has two implementations ( [Storage.hs in ghcjs-dom-jsffi](https://github.com/ghcjs/ghcjs-dom/blob/master/ghcjs-dom-jsffi/src/GHCJS/DOM/JSFFI/Generated/Storage.hs) and [Storage.hs in jsaddle-dom](https://github.com/ghcjs/jsaddle-dom/blob/master/src/JSDOM/Generated/Storage.hs)) and the correct one is automatically selected when you `import GHCJS.DOM.Storage` from the `ghcjs-dom` package. &gt; Also if I imported said modules from jsaddle and compiled with GHCJS would they give me the same performance as the ghcjs-base modules? Because really all I want is fast GHCJS output and type checking in GHC, GHC performance / runnability is not a priority, but obviously it would be nice to have so if jsaddle gives me the things I need then I would be open to using it. You can think of `jsaddle` as being a bit like `ghcjs-base-stub`, but with an implementation. The main difference is that instead of `IO`, `liftIO` and `MonadIO` you will need to use `JSM`, `liftJSM` and `MonadJSM` when you need to be able to run JS calls. On `ghcjs` they are the same thing so there is no performance cost. On `GHC` `JSM` is a ReaderT that identifies the JavaScript context to run the JavaScript code in. 
When building it is `stack` and `ghc` that are running, but for `stack test` you're running *your* code. In the latter case, on Windows, you need to set up UTF-8 handling yourself, in your test code. Read [this thread](https://www.reddit.com/r/haskell/comments/43tmt8/commitbuffer_invalid_argument_invalid_character/) for a general solution. Even if your test framework does not use `main`, you can still do `liftIO $ setLocaleEncoding utf8` in any `MonadIO` instance. Please tell me if that makes no sense. 😊
You don't need to build from source to use `HEAD`. For example, on Ubuntu, the `hvr-ghc` ppa by /u/hvr_ has a `ghc-head` package/application, which appears to be a nightly build (I assume). 
No, it works just fine without kind parameters! Thanks for pointing that out! I think I used them because my intended use for them had a kind parameter, but it turns out that that doesn't need them either.
Thanks for the reading! Interestingly, we have the same motivations for creating these types: variable-kinded Functor instances (though I'm also doing manual typeclass construction, a la http://www.haskellforall.com/2012/05/scrap-your-type-classes.html).
Well done!
&gt; Deferred type errors is one of those things that I've known about, but haven't really used or seen them used. I'm abusing them. `-fdefer-typed-holes` is always on during editing session or in GHCI, hence I can easily do some work in progress, and it replaces `undefined` in a smarter way: it is shorter to write, allows syntax / type checking and leads to a cool warning message with the needed type. `-fdefer-out-of-scope-variables`, and `-fdefer-type-errors` are always on during editing, ghci, testing: this is the coolest trick ever because you can incrementally refactor and test until everything works, instead of being forced to patch all the codebase. Python flexibility without its cost. They are off for final compilation. Actually I'm really annoyed by the current GHC behavior about errors: any error disable warnings, so my editor is constantly blinking between errors and warnings. Some usage of `-fdefer-*` fix part of the problem, but compilation succeed, which is not the intended behavior. This is even worse for syntax error for which there is no available option (no `-fdefer-syntax-error`). In comparison, gcc or clang for C++ are able to recover from most error, including syntax. They even show a meaningful location for the syntax error instead of the location of the first parsing inconsistency. This is especially cool or frustrating (depending on which tool you use) when refactoring on two parts of the same file. &gt; Interesting how f somehow forgets about the Num constraint on a; it should know at least that much about it. Good catch ;) I'll be tempted to say "Garbage in, Garbage out" ;) **edit**: largely edited, I reworded everything...
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/programming] [Haskell Project: Making Google Tasks Better](https://np.reddit.com/r/programming/comments/700r0y/haskell_project_making_google_tasks_better/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
AFAIK UHC supports all of Haskell2010 and has a JS backend. (Actually, it might have 2?)
If your editor doesn't show you matching parens you have bigger problems.
So a tagged union of sorts. But why not raise an exception? They're even accepted as a flow control method in Python.
Thanks to all comments. I should stop doubt about it and go for it again and again.
Packing them all together may very well be the most efficient way. You can use the [store](https://hackage.haskell.org/package/store-0.4.3.2/docs/Data-Store.html#t:Store) library for that. Although, that much extra memory is a bit surprising. It's kind of unclear what you're doing with the binary search, so maybe that's eating too much memory? I'd try benchmarking just storing the bytestrings vs trying to look one up using your method. PS: Why are you using `Double` as a key? I don't think it's causing performance problems but its a little weird since `Double` doesn't support equality
Are the errors switched around by any chance?
In fact, it makes a lot of sense, thank you=) However, this solution modifies the output encoding of my test suite, the terminal (`PS` or `cmd`) still uses its default `cp437` (Western European) codepage, which does not contain the characters I need. What I hoped for was a flag `--use-utf8` which would emit `chcp 65001` on windows machines before launching all the `stack test` machinery. It seems I'm stuck with a hand-made script that resolves this issue=)
I really enjoyed this tytorial. I think it's very well written. It's nice to see some approaches of how to model a game in haskell. I'll definitely play around with this later. Thanks! I'd recommend adding some sort of short video or a gif of the whole program, it will give people some idea of what this tutorial is about without reading it. I got to play with the [`Has&lt;Component&gt;`](https://github.com/soupi/haskell-play/blob/master/src/Play/Movement.hs#L21) approach in haskell and the [Row polymorphism](https://github.com/soupi/purescript-play/blob/master/src/Collisions.purs#L15) approach is PureScript. Which does not separate entities to separate components, can you comment on whether the ECS approach is better and if it is why?
Perhaps store them all contiguously in a ByteString, and extract slices from it. Apparently it costs 5 words per bytestring.
GHCi changes a bunch of subtle type checker and language extension settings to provide an experience better suited to an environment with fewer explicit type signatures. No idea what exactly is causing this particular discrepancy, but this sort of thing is not out of the ordinary.
I think the string is the key and the double is the associated value/payload. I might be wrong though.
If there's some redundancy in your strings, it may be worth trying the [`bytestring-trie`](https://hackage.haskell.org/package/bytestring-trie) package.
Hum, apparently `ShortByteString` overhead should be 4 words per string. For it to multiply by 10 the required space, it would mean your strings are significantly shorter than 30 bytes, or that something else is eating up memory. Have you tried making your fields strict (with a bang) ?
If there significant overlap at the beginnings of the strings, it may be worth to use a [trie](https://en.wikipedia.org/wiki/Trie) (prefix tree) data structure. You will probably still need to do other tricks to keep the memory usage low, though.
**Trie** In computer science, a trie, also called digital tree and sometimes radix tree or prefix tree (as they can be searched by prefixes), is a kind of search tree—an ordered tree data structure that is used to store a dynamic set or associative array where the keys are usually strings. Unlike a binary search tree, no node in the tree stores the key associated with that node; instead, its position in the tree defines the key with which it is associated. All the descendants of a node have a common prefix of the string associated with that node, and the root is associated with the empty string. Values are not necessarily associated with every node. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/haskell/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
As others have stated, I would likely start by saving them in concatenated form in a single heap object, import qualified Data.Vector.Unboxed as VU data StringArray = StringArray { backingStore :: !BS.ByteString , offsets :: !(VU.Vector Int) -- ^ index in bytes to first character of string i } index :: Int -&gt; StringArray -&gt; ByteString index i sa = BS.take (end-start) $ BS.drop start (backingStore sa) where start = offsets sa V.! i end = offsets sa V.! (i+1) 
That's really neat! I didn't know about that.
Thanks for doing this. I'm really excited to see `new-build` become the default in the future.
Good bot
Thank you MrMetalfreak94 for voting on WikiTextBot. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://goodbot-badbot.herokuapp.com/). *** ^^Even ^^if ^^I ^^don't ^^reply ^^to ^^your ^^comment, ^^I'm ^^still ^^listening ^^for ^^votes. ^^Check ^^the ^^webpage ^^to ^^see ^^if ^^your ^^vote ^^registered!
I would say that in this case the first error message is much more harder to understand than the second one.
Yes, the fields are all strict (I updated the post as I had left out the !) and they are even deeply evaluated (`rnf`) as they are built so I'm pretty confident it's not just a laziness issue. I'm also surprised at how much memory is taken up by this structure, but I see my processes memory go up ~50G when loading a big file. I assume that fragmentation, the extra indirections &amp;c are all taking their toll.
Yes, that is correct. Roughly speaking, the string is the key, the `Double` is the associated payload.
 Mmap the data. It's silly to carry 5 gigs of data in RAM. Mmap it as pointers and then sort / search the container by the return result of the pointer access. 
Thanks, I will try that. The strings depend on the input file (Which the user supplies), so in principle, they can be random strings, but it's not uncommon that they are structured and a trie could work well.
You're right, I misread that part. Tbh this sounds like the kind of thing a database would be good for, if something like sqlite makes sense for your application
&gt; The first program will print five and then Five: 5. It will not bother printing seven, since that expression is never forced. No, "Five:" should be printed first. `putStrLn $ "Five: " ++ show five` is a lazy operation too: `putStrLn` takes a string, which is a lazy list of `Char` and gets characters one by one (printing `Five: ` first), *then* it needs the value of `show five`. Quick experiment on OS X seems to support this reasoning: $ stack runhaskell lazy.hs Five: five 5 
Nice that you took the time for a writeup! Great job, congrats :) 
I profiled sqlite, actually, and the lookup times are too slow. At this point, using 50G is acceptable, but it has become limiting (as it means we cannot run that many parallel processes on the same machine).
FWIW: those problems are why a standard solution (in theory) is to track exceptions via a type-and-effect systems. So that programmers have to modify their code or types when they want to do something weird, just as we do usually in Haskell. The problem is limiting the annotation overhead to avoid something like Java checked exception. And allowing more polymorphism on exception than Java does (how do you type `map` without exception variables?). Algebraic effects (currently on vogue in research, and for good reason) are just one approach to implement/encode them, with some expressivity advantages and (at least for now) performance disadvantages. They often have the needed polymorphism, and they allow hiding effects from types when they are invisible. Haskell is waiting on either optimizations or fast but useful restrictions. EDIT: reading the OP better some of this is perhaps redundant, apologies. Leaving as-is as a self-contained summary.
The input data needs to be parsed to extract the strings and metadata (the `Double`), so this becomes equivalent to the suggestion of building a concatenated string in memory. Btw, for the type of work we do, 5G of RAM counts as "small memory footprint" :)
Thanks for the suggestion of using store. I was not familiar with that library.
&gt; GHCi changes a bunch of subtle type checker and language extension settings to provide an experience better suited to an environment with fewer explicit type signatures. I only know of one such change: ghci disables the [monomorphism restriction](https://wiki.haskell.org/Monomorphism_restriction). What are the others? &gt; No idea what exactly is causing this particular discrepancy, but this sort of thing is not out of the ordinary. I know that it is the monomorphism restriction which is causing this particular discrepancy, because I can reproduce ghci's error message in ghc by adding `{-# LANGUAGE NoMonomorphismRestriction #-}` at the top of `m.hs`, and I can reproduce ghc's error message in the repl by first typing `:set -XMonomorphismRestriction`. Although, with my version of ghc (8.0.2), I get a third error `Ambiguous type variable f0 arising from a use of pure` in addition to the `Ambiguous type variable t1 arising from the literal 2`, I guess /u/Ford_O's version of ghc stops after a single ambiguous type variable. Okay, so what is the monomorphism restriction and how is it leading to those error messages? Well, as the page I linked explains, it's complicated, but to a first approximation, the monomorphism restriction causes ghc to _restrict_ inferred types to _monomorphic_ types, that is, types without type variables in them. For example, the type of the literal `3` is `Num a =&gt; a`, but if you write `x = 3` as a top-level definition in `m.hs`, the monomorphism restriction applies and so its inferred type is specialized to `x :: Integer` instead. If we want the type of `x` to be `Num a =&gt; a`, we can either disable the monomorphism restriction using `{-# LANGUAGE NoMonomorphismRestriction #-}`, or more commonly, we can just add the type signature `x :: Num a =&gt; a`. In ghci, the monomorphism restriction is disabled, so typing `x = 3` in ghci gives you an `x` of type `Num a =&gt; a` which can later be used in any numeric context. All right, let's try to infer the type of `x = pure (1 2)`, with and without the monomorphism restriction. Here's what I think happens. The integer literals have type `Num t1 =&gt; t1` and `Num t2 =&gt; t2`, and since 1 is applied to 2, we learn that `t1` must have the form `t2 -&gt; t3`. Next, `pure`'s type is `Applicative f =&gt; a -&gt; f a`, and we can see from the type of its argument that `a` and `t3` are equal to each other. To summarize: Num t1 Num t2 Applicative f t1 ~ t2 -&gt; t3 t2 ~ t2 t3 ~ t3 a ~ t3 f ~ f Without the monomorphism restriction, we are happy with those types, and we can infer the signature: x :: (Num (t2 -&gt; t3), Num t2, Applicative f) =&gt; f t3 x = pure (1 2) There are a few issues with this type, but the first one which ghc notices is that the constraint `Num (t2 -&gt; t3)` is more complicated than what Haskell2010 allows, so it stops and ask for the FlexibleContexts language extension. With the monomorphism restriction enabled, ghc is not happy with those types, so it tries to specialize the type variables before it gets to the point where it would check for Haskell2010 compliance. It cannot find any specializations for `t2` and `t3` which would lead to a `Num` instance for `t2 -&gt; t3`, so it complains that the types are ambiguous and that it cannot find the instance.
Similar to the true suggestions, a minimized DFA might be a memory efficient way to store the list.
I have found that I don't need to apply the newtype constructors to the numeric literals. Since IntE{N} implement *Num*, its *fromInteger* method provides the type assignment if a type restriction is applied, as with regular Int{N} types. You can even use a *default* clause, presetting the type of numeric literals to one of the newtypes defined: default (IntE8) will bring numeric literals within the type range to the default type, when they are used as a first operand.
The two messages are about completely different problems. The inferred type is `(Num (t -&gt; a), Num t, Applicative f) =&gt; f a`, which has many issues: it requires the FlexibleContexts language extension in order to allow a constraint like `Num (t -&gt; a)`, because Haskell2010 only allows simple constraints like `Num a`. Also the type `t` doesn't appear to the right of the context, and you need the AllowAmbiguousTypes language extension to allow that ([but probably shouldn't](https://www.reddit.com/r/haskell/comments/6ufnmr/scrap_your_proxy_arguments_with_typeapplications/dlvbd1f/)). In one of the two conditions, ghc is encountering one of the problems first, and in the other condition, ghc is encountering the other problem first. You'll have to deal with both problems anyway. If you enable both language extensions, you finally get to the real error message: &gt; :set -XFlexibleContexts &gt; :set -XAllowAmbiguousTypes &gt; pure (1 2) error: No instance for (Num (t0 -&gt; a0)) &gt; :load m.hs -- with {-# LANGUAGE FlexibleContexts, AllowAmbiguousTypes #-} added on top error: No instance for (Num (t0 -&gt; a0)) error: Ambiguous type variable ‘t0’ arising from the literal ‘2’ error: Ambiguous type variable ‘f0’ arising from a use of ‘pure’ Plus some bonus error messages in the `:load m.hs` case because ghc is trying to specialize `t0` and `f0` to concrete types, but can't.
Unless the strings are truly random, a trie is likely to be a win in theory. For instance, if all the strings are expected to be English-y, that alone would be enough to guarantee sufficient overlap. Whether it's a win in practice for 30-character strings would depend on the implementation and lots of fiddly details, but you can probably very easily [just give it a try](https://hackage.haskell.org/package/bytestring-trie-0.2.4.1/docs/Data-Trie.html) and see what your results look like.
Depends on what you mean by observe. If you look at the heap then laziness is impure. If you look at the log file then streaming the log is impure. We don't do everything in io because the constraints makes programs easier to reason about. I don't really see the problem with a monad type class for logging even if it uses io in the non-test cases. Logging is operationally impure but still referentially transparent and it's useful to consider it a separate effect so it can be added to "pure" monadic functions. 
I agree with these examples, but the question is not whether the corresponding strict algorithm is ugly or impractical, but whether it is impossible. For instance, in the case of the dynamic programming, you can implement an explicit store and write a strict (eager) algorithm that essentially emulates the lazy one. This is obviously ugly compared to code in a language with built-in laziness. But even if ugly, it might be possible to do it in a way in an eager language that has the same time complexity as the lazy version; and I don't know any proof to the contrary. As far as I am aware, it's still an open problem.
DFA minimization is exponential, though, isn't it? Is there some more efficient way to build a minimized-enough DFA in this case?
DFA Minimization is polynomial in the number of states in the DFA, and you can start with a DFA that is basically a trie, which can be constructed in polynomial time and space. If you start with an NDA though, converting to a DFA is exponential, as is minimizing an NFA. DFAs aren't necessarily terribly fast to build, but they have potentially greater memory savings than a trie. 
That'll be the Vector type which makes the elements boxed. bgamari mentioned elsewhere to use in unboxed vector of a list of offsets. That'll be more efficient. I used a similar approach in the xeno package.
Perhaps an obvious advice: it might be that your strings share suffixes rather than prefixes - this way reversing the strings will bring more space savings.
The [xeno package](http://hackage.haskell.org/package/xeno-0.2/docs/src/Xeno-DOM.html#Node) takes this approach. It's very efficient.
Thanks, that was just at my level! I was able to get everything working on Windows 10 without any problems (using stack with lts-9.4). I mention this because you said that "things sometimes break on Windows with Haskell." In the past that was largely true, but it is unhelpful. My vote is to not discourage new users to Haskell (which will probably largely be Windows users). Perhaps you can mention that at least one Windows user got the project to work. Now, if the rest of the series focused on GHCJS, then I would eat these words (but I don't think there will be a problem with Yesod on Windows). Anyway, I look forward to the next article.
Thanks, adding a gif might be a good idea. It comes down to this: in an ECS*, useful pieces of game logic can often be translated into _very_ fast systems. Something like `rmap $ \(Velocity v, Position p) -&gt; Position (p+v)` internally iterates over the store of `Velocity` components, sees which also have a matching `Position` component, and then updates those components. That is an essential piece of physics, expressed in the most general way possible, while still being about as fast as it can possibly be. Another example is `cmap $ \(PoisonDuration t,Health h) -&gt; (PoisonDuration (t-dt),Health (h-1))`, which is again completely general but also very fast. You can probably emulate the semantics of an ECS with the approaches you described, but it's going to be difficult to get your code to be performant. This matters, because Haskell is notoriously difficult to write real-time software in, let alone software that runs at 60 FPS. For context, we could crank up the program in the benchmark folder to 350.000 active units before the game logic would take longer than 1 60 FPS frame. (*) I say ECS, but I really mean apecs as there is no clear set of definitions for what does and does not constitute an ECS. All major ECS libraries have very different APIs and performance characteristics.
Just a random thought - compression might help with space usage, depending on the distribution of characters...
I'm not /u/ChrisPenner, but I saw this in [this week's Haskell Weekly](https://haskellweekly.news/issues/72.html) and thought it deserved its own discussion thread.
I use `cabal new-build` in one of my pet projects and I love it. And it's the only way to use Backpack at the moment.
If you hash the text keys to a 128 bit hash (according to my browsing of the table [here](https://en.wikipedia.org/wiki/Birthday_problem#Probability_table)) you can store "many millions" of keys with very low probability of collision. 64 bit hashes might also be acceptable. If you're building this structure once and querying it many times, perfect hashing would be relevant, but I'm not too familiar with that. You could also just check for collisions as you initially build it and store the long text keys only in those cases.
I've only read a bit on ECS, but my naive generalization is that it eschews OOP hierarchies and nesting, and instead prefers a loose collection of maps and dictionaries (instead of static properties). One can think of this as a mini in-memory database with loose keys to referenced items rather than nesting inline. Relationships between properties are created with these "keys" and by doing lookups, but with an engine the most common operation for a world "step" is to perform a common operation to all the properties of a certain type (e.g. update all velocities). The orchestration piece just pulls things out of the maps and feeds them to functions to do work, so it is very much 'data-driven'. This is different than modelling game objects by composing record fields representing a single game entity (and in OO by using inheritance). The structure of the entities is very much created at run-time instead of statically enforced at compile-time (just like a "business-rules-engine) Does this characterization have some truth to it?
I have to admit this looks impressive. You did a great job! I'm looking forward to the "other 90%" getting completed.
Use a trie.
Thanks for the pointers. Looks like this area is indeed immature. This time it's not just I being unable to find things.
[This seems like a familiar concept](https://stackoverflow.com/questions/20318936/delimiting-the-io-monad/20319642#20319642).
Yeah, it's just a lot faster with GHC 8.2.1. Kudos to its authors!
this is one of my favorite things in Haskell to come out recently
100% correct
&gt; For instance, in the case of the dynamic programming, you can implement an explicit store and write a strict (eager) algorithm that essentially emulates the lazy one. I don't know of an immutable strict store with `O(1)` lookups and `O(1)` modification. A knot tied vector achieves this as long as the desired modification can be implemented by tying the knot. You may be right about it being (for non-live algorithms) an open problem. Now I kind of want to try and think of some algorithms that wouldn't be possible to implement performantly without knot tying or mutation, I'm hoping I can think of something, as to me it does feel as though purity + strictness is quite limiting.
Where do you stand on `-XConstraintKinds` these days?
&gt; Yes. The difference between it and jsaddle-dom is that when built with GHCJS, it uses the JS FFI, and when built with GHC, it delegates to jsaddle-dom (which does its own thing). Ah ok great, I'm having a bit of trouble finding some solid documentation, is there a place where I can just see all the functions and types and perhaps a brief description of each? &gt; react-hs would just have to use only ghcjs-dom and/or jsaddle for all its JS interaction. It can use the JS FFI directly as long as it also has a GHC version of the function that uses jsaddle. Awesome, thanks! And dang that's a shame, I guess I can just hold tight for a while and use ghcjs-dom and similar. 
I suggested MMAP because I had what sounds like a very similar problem to yours (pulling out discrete results, subsets, and/or discrete results from subsets) from an fairly large (20-40 gigs) dataset that I didn't want to leave in resident memory. What I ended up doing, to use more detail, was to to scan the file, and throw away everything but the byte positions of the contents of the file that I was interested in, then MMAP'd the whole file, and stored a single ptr and a tuple representing the byte positions. This initial pass ran in linear space proportionate to the size of the given bytestring parse - (excepting of course the result vector, which grows with size of input). So, a datatype like : `(Ptr CString,Vector (Int,Int))` Then, I didn't need to store several million strings, I only needed to store an unboxed vector of several million tuples of ints and a single pointer. In addition to saving me from memory exhaustion, the program also ran astronomically faster. The cost of the technique is that you pay an extra CPU / IO cost for passing over the file in order to identify the relevant byte positions. The benefit of the technique is that for every subsequent operation you make against the original set, you pay a fraction of the cost - So it's great for repeat operations against the base set, folds wherein the accumulator is smaller than the input, and situations in which memory exhaustion is a concern. It is not great for things wherein : you need the entire set of data to reach a conclusion, you can model your algorithm as a single atomically reducible fold over the input, or the cost of calculating your metadata from your source is extremely high.
It seems like instead of calling `jsaddle` directly it might make sense to call into `ghcjs-dom` and let it delegate to `ghcjs-base` and `jsaddle`. And as long as `GHCJS.DOM.Storage` allows me to interact with `localStorage` and store things persistently to a user's browser then that should work fine. Everything else you said make sense. I can see the benefits of `jsaddle`.
I'm not worried about it. That sentiment was pretty early in into my Haskell experience and it seems to be a very well accepted extension now. I didn't know the ecosystem or language as well back then. 
Since this doesn't add any new layers to the actual monad transformer, does this approach have any runtime implications for performance? Seems like entirely a type-level code clarity benefit? 
I'm getting this issue as well
it is happening all over S3 in us-east-1 !!!
It's working fine for me. The "Slow Down" message makes me think you are hitting some kind of rating limiting. Perhaps an errant build process is causing an explosion of requests or something similar?
us-east-1 is having issues.
That's correct, it improves clarity and limits accidental effects. It also provides the ability to choose your base monad later (for instance in tests), as I mentioned near the end of the post.
Ironically I hadn't seen that, glad to see that it lines up though!
Yeah, this seems to be the culprit: http://status.aws.amazon.com/
Seems vaguely related to capabilities that languages like Pony (and Monte?) use. Sketch out a basic building block set of permissions and then combine as necessary to build your appropriate IO action. I'll be honest, I find it mildly surprising that nobody seems to have standardized a good set yet for libraries like mtl, although I suppose this is essentially what systems like Eff and algebraic effect systems attempt to do?
Thank you! This came just as I was abandoning a simple game project. I had all three of my entities as separate records and I wasn't sure how to abstract the common physics logic. I'd been meaning to look into ECS, but I honestly thought it would be much harder to implement in Haskell. Just a small FYI: the handleEvent for the right mouse button does not have haskell syntax highlighting. (Edit: I meant the code block with that function in your article -- but it looks like it's been updated anyway.)
I, for one, really enjoy reading these kinds of things. Sure, I probably only really followed about 20% of it right now but it's quite useful to see how more experienced programmers think about and solve issues. Nice article!
I had actually worked on some libraries to provide a set of typeclasses for this purpose a few years ago (after I made that SO post), but never got around to finishing them. They're also probably horrendously out of date. I'd be glad to work with anyone who would be interested in working on them again. 
I really don't like the first option personally. But I'd be open to allowing more fixity declarations besides just 0 to 9.
Thanks! Your words are appreciated.
http://www.parsonsmatt.org/2016/07/14/rank_n_classy_limited_effects.html This takes the concept a little further, introducing rank 2 types to hide the underlying monad. Was posted here a while ago, definitely worth the read.
... as long as GHC specialises this to your concrete transformer stack.
If someone did object to the idea of more fixity levels, the extra dollar signs could be a language extension instead.
Here's the previous discussion thread on /r/haskell https://www.reddit.com/r/haskell/comments/6zf0n3/new_syntax_ideas_for_less_parentheses/
The same thing is enabled by the less expressive `ExistentialQuantification`, rather than `GADT`, with a different syntax. I'm not sure you can do anything like that without `ConstraintKinds` however. data T c = forall a. c a =&gt; T a Here's an old library defining the same type: [exists](https://hackage.haskell.org/package/exists-0.2/docs/Data-Exists.html). --- Some related stuff. vinyl has a different but similar looking [`Dict`](https://hackage.haskell.org/package/vinyl-0.6.0/docs/Data-Vinyl-Core.html#t:Dict) type. And last but not least, the [constraints](https://hackage.haskell.org/package/constraints) library provides all kinds of utilities to perform constraint-level magic.
It seems to me these suggestions make code more "readable" at the cost of making it less understandable.
I don't see how different variable naming would make the above look nice.
I would say I fairly frequently have things like: foo . bar . baz . qux &lt;$&gt; blah which to me is much more readable than say: fmap (\x -&gt; foo (bar (baz (qux x)))) blah
I don't personally like how that looks. I would much prefer: function $ do first very long argument other very long argument with $ do its own complex arguments imagine more words or similar.
That's part of why I personally relaxed the 80 character restriction to 100. All decent size laptops and non-tiny monitors can display 2 100-character wide files next to each other with no wrapping and a reasonable font size.
I personally don't like implicit parameters at all. They seem very magical and implicit with various edge cases.
Totally in favor of this flavor of MTL. I think the issue has always been finding common interfaces that everyone can agree upon.
Seconded - As a Windows using Haskeller, might I suggest the following qualifier - `'things which make heavy use of foreign language libs will sometimes break on Windows with Haskell.'` Realistically if you can keep it pure Haskell as much as possible the windows experience is pretty painless compared to most languages.