Honestly, I like writeups like this that remove the "magic" that parcel offers. It makes one appreciate and feel less in the dark about what parcel is doing
There's a link to the benchmarks on the crate page. 
It comes from the criterion benchmark run from my 2018 Macbook Pro : string encoding throughput/json_in_type/25600-bytes string time: [10.236 us 10.402 us 10.598 us] thrpt: [2.2496 GiB/s 2.2920 GiB/s 2.3292 GiB/s] I used to upload the benchmarks from my machine to github pages, by that was tedious, so I automated this process, and the benchmarks from github pages are now [generated automatically](https://travis-ci.org/lovasoa/json_in_type/jobs/515658692) on travis. The downside is that the figures from the shared travis workers are ~20% worse. I should update the project's README to make that clear.
Nice work. Would you consider adding an open source license to the repository? I recommend using the ISC license, it’s short, simple and very permissive. I have a comment about the cli arguments also but I’ll submit that in form of a pull request later.
The lost art of writing rasterisers.. nice to see. I have a long list of itches as it is. I will resist.
Separate traits are also useful for keeping the documentation organized by platform.
&gt; The downside is that the figures from the shared travis workers are ~20% worse. I should update the project's README to make that clear. I'm new to Rust/Travis, can you explain what this means?
`c` and `packed` have different semantics for how fields are laid out. ESR has a good blog post on it: http://www.catb.org/esr/structure-packing/ i wouldn't read much else by ESR tho. 
I absolutely would have used floats to define the function then when calling the arguments \`\_ as f64\`, but this was about learning and not feasibility. 
It sound like you'd want a ArcSwap from the arc_swap crate. When a produces a new value you just atomically swap the arc. The old value will get dropped when B is done with it. 
One of the reasons the provided C example of echo takes only a few lines is because the openbsd echo doesn't do as much. The version of echo in GNU coreutils is longer by a few dozen lines.
I think `diesel` after expansion produces code like this: let mut request = String::new(); request.push("SELECT"); request.push(" "); request.push("*"); request.push(" "); request.push("FROM"); request.push(" "); // .. It would be cool for it to be optimized into `let mut request = String::new("SELECT * FROM ");`,
These sentences struck a chord for me: &gt; Compilers built for speed, such as Turbo Pascal, D and Go, win praise and loyalty. Languages that struggle more with this, like C++ or Rust, get regular complaints and requests to speed up build times. Slow compilation speed is an issue that has been raised to me many times as a reason to reconsider Rust; no short-coming of Go seems to have that kind of braking effect on people. I have argued that Rust generates faster code and safer code, offers more ergonomic language support for handling errors, that it has an excellent dependency management tool, or that the language allows user to create zero-cost abstractions (at run-time), but the issue of slow compile times is raised again and again as a reason to not seriously consider Rust. On the other hand, I find that there are many short-comings with Go: the lack of generics, the verbose handling of errors, the absence of a tool to fetch dependencies and their transitive dependencies, etc. However, many of my colleagues will brush off all those concerns. The mains reasons are that Go is seen as simpler than Rust—a fair point—and that Go compiles fast. The ability for developers to iterate quickly is seen as something that is needed here and now and other concerns can be fixed in time upstream or we can just be "careful and principled" in our code. This is not limited to programming languages. 10 years ago, the speed of Git gave it a popularity boost that other tools (mercurial, bazaar, darcs) were never able to overcome. It didn't matter that the interface of git was more complex, that the support for Windows at the time was lacking, that there was no library to interact with git, that there wasn't a TortoiseGit, etc. Developers argued that either these things would be fixed in time or that if you found git complex, it was because you did not sit down and really learn how git works. Today, we know the results: git has so handily won the VCS wars that all other VCS tools are basically irrelevant for 99% of developers. Speed is an enabler: the fast compile speeds of Go makes iteration in that language quicker than in Rust; the speed of operations in Git that used to be slow (e.g., creating new branches) has opened entirely new ways of working with a source tree. I'm happy that compiler performance in Rust is not ignored and that we have some ways around it (e.g., using `cargo check` or using `sccache`); I'm just looking forward to the day when it can't be meaningfully used as an argument for avoiding Rust, even when Rust would be a great choice.
Travis is a service that I use. I put [a configuration file](https://github.com/lovasoa/json_in_type/blob/master/.travis.yml) in my repository, and it runs commands I choose for every new commit and new tag pushed to github. One of these commands [runs `cargo bench` and copies the benchmark results to a directory](https://github.com/lovasoa/json_in_type/blob/master/.travis.yml#L23), than, [another command](https://github.com/lovasoa/json_in_type/blob/master/.travis.yml#L27-L32) pushes this directory to github pages.
That quote, not having seen its context, is very selective. Of course slow compilers like rustc get requests to speed them up, I think that's kind of self-evident. But in no way does that mean that rustc *doesn't* get praise and loyalty. Just look at the number of people expressing love for its diagnostics, for example.
Oh, certainly. One can argue all day about which trade-offs are worth making. But you can look at, say, OCaml which has more features than Go but still compiles much faster than Rust, produces fast output, and has a high level of abstraction with a strong type system. It makes a different set of trade-offs to achieve this though.
Heh...personally, I consider your emphasis to be on the quotes around "more". :P
I've finished drafting my response. Warning: lots of bullet points to match my stream-of-consciousness thinking. :)
Thanks for the detailed answer - this is exactly the information I was looking for. :-) I just looked at the OpenBSD implementation linked in the Github comment: https://github.com/openbsd/src/blob/master/bin/echo/echo.c and tried something similar in Zig (using the iterator rather than using pointers). Sorry, I'm not familiar with the String internals in Windows. Maybe I'm wrong, but I guess splitting the echo implementation into POSIX-specific &amp; Windows-specific functions might be simpler. I used the `nextPosix()` function because it avoids having to pass in an allocator required by the cross-platform `next()` function (IIUC the allocator is required for the string conversions necessary to support Windows). Also, I noticed that the implementation in https://github.com/uutils/coreutils/blob/master/src/echo/echo.rs implements the GNU specific '-e' option to interpret escape sequences which adds to the complexity and is not supported by OpenBSD (IIRC the OpenBSD manual suggests using the printf function for such use cases). Anyway, Thanks once again for taking the time to answer. :-)
&gt;If you combine all of these assumptions, then you get [/u/JayDepp](https://www.reddit.com/u/JayDepp)'s [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=16cb0c13f4052a41d58838f135db7314). For the sake of completeness the answer I've received is: "Yes, you are. K.I.S.S." Thank you for you time. &amp;#x200B;
You can only downcast to types, not trait objects. Basically you need to pass the Subscription type as a type parameter so you can then downcast to the actual type that implements subscription. If the idea was to trigger multiple different subscription types from one message type, then that does not work this way, I think &amp;#x200B; try https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=9e478cd8176afd959ae7807730cd15eb
I actually looked at that earlier. Though it hasn't been updated for a while so it might be a bit touch and go at first. Heh, maybe making an Xlib binding would be a cool project to work on. Maybe find a few other people interested in something like that, get together and stuff. But I should probably make sure there's cake and grief counselling on hand first. :p
Give me a shout when you have Scala+Rust position in Ireland :p Would be my dream tech.
&gt; Sorry, I'm not familiar with the String internals in Windows. Maybe I'm wrong, but I guess splitting the echo implementation into POSIX-specific &amp; Windows-specific functions might be simpler. It would be interesting to even know what the behavior of your Zig program is on Windows with args that contain UTF-16 outside the BMP, and then even with args that don't contain valid UTF-16 at all. I don't know Zig, so I'm not sure. Given that it's called `nextPosix`, I wouldn't be surprised if it failed to compile (unless linked with cygwin?).
I agree with you. It felt like the GP's reply was along the lines of saying "Go doesn't need the Generics, look at this hand-picked example of sorting something that gets away without Generics. Therefore Generics are of no use!".
Ah, thanks for pointing that out - I've made the change in an upcoming commit. Thanks for taking a look!
It's very WIP as I figure out the right design, but right now it looks like: pub trait Handlers { type Method; type GetProp; type SetProp; type DynHandlers: Handlers; type Iface; } #[derive(Debug)] pub struct MethodInfo&lt;'a, H: Handlers&gt; { name: MemberName&lt;'a&gt;, handler: DebugWrapper&lt;H::Method&gt;, i_args: Vec&lt;Argument&lt;'a&gt;&gt;, o_args: Vec&lt;Argument&lt;'a&gt;&gt;, anns: Annotations, } #[derive(Debug)] pub struct PropInfo&lt;'a, H: Handlers&gt; { name: MemberName&lt;'a&gt;, get_handler: DebugWrapper&lt;H::GetProp&gt;, set_handler: DebugWrapper&lt;H::SetProp&gt;, anns: Annotations, sig: Signature&lt;'a&gt;, emits: EmitsChangedSignal, auto_emit: bool, rw: Access, } #[derive(Debug)] pub struct IfaceInfo&lt;'a, H: Handlers&gt; { name: IfaceName&lt;'a&gt;, methods: Vec&lt;MethodInfo&lt;'a, H&gt;&gt;, props: Vec&lt;PropInfo&lt;'a, H&gt;&gt;, signals: Vec&lt;SignalInfo&lt;'a&gt;&gt;, } 
Alright, good to know it is not expected behavior.
I am faced with a situation where a user gives me a path where I should save some output in a file. If a file already exists at that path (i.e. there is a pre-existing file with that name), then I'd like to take the file name component of the requested path, and add some sort of thing that will reduce the chances of name collisions as much as possible. I believe that this is where hashes come in useful? Should I just generate a hash based on, let's say, the originally requested file name, using something like: https://doc.rust-lang.org/std/hash/index.html ?
Sorry, I wasn't very clear here - that comment about splitting the implementation referred to the rust implementation in https://github.com/uutils/coreutils/blob/master/src/echo/echo.rs and not the zig snippet I posted.
If you get better performance by throwing more memory, then in fact they are inversely related. 
The workaround I've seen for that is, to make the field public but with `#[doc(hidden)]` so that the field will be harder to discover.
The new website looks nice. It says: &gt; Transparent Replacement &gt; &gt; MesaLink provides OpenSSL-compatible C APIs. Want to use MesaLink in curl or Android? No problem. Is there more information available on how to do this? Also it would be fantastic if mesalink was available as a cargo feature for tls on hyper and reqwest, has that been considered?
Mesalink is a C FFI wrapper around rustls and ring, primarily. And there's already support for rustls directly in hyper and reqwest.
Ahh thanks for the clarification. 
Would it be sound to transmute a `&amp;mut T` to a `&amp;UnsafeCell&lt;T&gt;`? (Or maybe a `&amp;mut UnsafeCell&lt;T&gt;`, but I'm not sure there's a practical difference.) I remember reading something about safely converting `&amp;mut [T]` to `&amp;[Cell&lt;T&gt;]`, and I wonder if similar logic applies.
Rust FFI is a huge topic. You might be interested in my talk "One Thousand Ways to Die in Rust FFI" at RustFest Rome. The video is available at https://www.youtube.com/watch?v=kGj-Fxg5txQ MesaLink provides OpenSSL-compatible C bindings for rustls and *ring*. So hyper users should consider hyper-rustls rather than MesaLink.
No worries &lt;3
Oh, I see. I think I was more or less just asking from the perspective of someone who hasn't used Zig and was idly curious what would happen with your Zig program on Windows. I guess it would probably fail to compile is my guess?
&gt; literally no weaknesses I do tend to feel this way about whatever my favorite language is at any given time :) But bringing things down to earth, here are some Rust drawbacks off the top of my head: - The steep learning curve. Those of us who program all day every day might enjoy mastering the difficulty, sure, but there are a lot of applications out there where you need something that beginners can dabble in without getting overwhelmed. I wouldn't write something like WordPress in Rust. - Compile times. There are two versions of this. Rust is currently slow to compile relative to e.g. Go. That might be expected to get better over time. But more importantly, Rust is a _compiled language_, and that's probably not gonna change. I wouldn't write the build scripts for my projects in Rust, because it's inconvenient to recompile a build script when you make changes. I think some people have tried to make it possible to write single-file "Rust scripts", but even if it works that's a pretty niche thing to take a dependency on. - Maximum portability. Rust runs on a lot of wacky microcontrollers thanks to LLVM, but it doesn't run on as many platforms as C. It might never beat C in that regard. - Tooling around unsafe code. If you plan to write a ton of unsafe code, the tools to help you get away with this are more advanced in C and C++. Many of them (like valgrind) can also work with Rust, but not everything (I think ASAN is still experimental). Also under "tooling" we might include "having a specified memory model telling unsafe code what it can and cannot do." That's on the roadmap for Rust, but it's not here yet. - Circular data structures, like graphs and linked lists. These are famously difficult to write in safe Rust, compared to in a garbage collected language. There are workarounds like using indexes in a `Vec`, and in many cases those workarounds are actually the Right Way to solve the problem. Also the problem arguably doesn't come up often in practice. But if I was setting out to write some piece of software that was going to spend 99% of its time managing a giant graph, I'd want to think very carefully about whether garbage collection could make my life easier. Again there are future plans to make optional GC possible in Rust, but nothing coming soon as far as I know. - Async IO. It's going to land soon, it's going to be great, but here in April 2019 environments like Go and NodeJS have stable, mature async IO and Rust doesn't. If I was writing the next generation Nginx web server or something like that, I think writing it in present-day Rust would be a risky choice.
I think the message is: you have to try to see the good things in everything
I was picturing something like that, well, as far as I know there isn't a simple one line solution. I used `cargo +nightly rustc --profile=check -- -Zunstable-options --pretty=expanded` to have a look at the source code after derive and there are Debug bound everywhere [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=e58ab5e0bde32efb72602fa9247e1cde).
Pretty unrelated but how did the UCF logo end up as the thumbnail? Also, go knights!
Could the macro do that optimization using `concat!`?
Make sure you don't have an old librocksdb-sys in ~/.cargo/git/checkouts/rust-rocksdb?
How about [this recent article](https://science.raphael.poss.name/go-executable-size-visualization-with-d3.html) on Go, where they are precisely complaining about Go's bloated executables, and analysing why it's that way. It seems that immense uncompressed line-number tables are one reason, as well as suboptimal machine-code generation.
If doing it to a slice of T is safe, then doing it to a single T would be too. And MIRI doesn't yell at me when I [try it](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=e2bf99e3c81dd331df3d82d0ce877f09) so maybe it is?
Super cool
Do developers need to treat built-ins differently from other functions/objects? Do they get any practical benefit from being required to type a special character for these? Is the character `$` restricted from use by developers?
I don't know why `reqwest::Body::new` requires `'static`, but note that there are other ways to construct a body including `From&lt;Vec&lt;u8&gt;&gt;` and `From&lt;String&gt;` so reqwest in general doesn't require that the body is static, only the `new` method does.
&gt; Building a language after 2010 without HKTs is a bit silly That is a rather strong opinion to express so definitely. HKTs have a *substantial* complexity cost in a language and in code written in that language, and they are not understood by *most* developers. Well before Rust 1.0, there were some that were pushing to add HKT; most were ambivalent, and a few objected on grounds of technical complexity, but I and a couple of others pushed back strongly on different grounds: marketing. A new language has a certain “strangeness budget”. A given developer when trying it out will abandon it if it does too many things differently from what they expect or understand. Expressed bluntly, at that time Rust’s strangeness budget was already strained on its ownership model (lifetimes) and algebraic data types. Adding HKTs to the language would have run the serious risk of relegating Rust to the sidelines. Once a language is popular, its strangeness budget grows; so Rust would have a better chance of getting away with adding HKTs now than it did at 1.0. (And we expressed it that way: that we didn’t object to Rust *ever* getting HKTs, but that they were a really bad idea for the next few years at least.) Then there’s another important consideration too: how exactly you’d implement HKT may not be evident, and HKT may not even be the most suitable feature for a language. In Rust’s case, I believe its type system is not inherently conducive to a straight port of Haskell’s HKT. (Bear in mind, however, that I don’t have a solid grasp of Haskell’s HKT, monads, *&amp;c.*—I have deliberately avoided learning these things properly to help me to continue to relate to the typical developer that doesn’t understand them.) And in the end, Rust seems to be heading in a slightly different direction, generic associated types, which are able to express just about all of the *practical* cases that I and others have hit where HKTs would be useful, in a way that better matches other Rust features. TL;DR: I disagree. 😛
_(fixed the code formatting, sorry for you having to read that lol)_ Yea, my goal was to stream bytes from the handler to the `reqwest` without reading them all into memory. Both `Vec` and `String` would be all in memory right?
Hmm, maybe a move is allowed to be used in place of `&amp;'static body`? It's concerning to me because passing in `'static` for something that _isn't_ static makes me think it's a memory leak. But perhaps it's just a flexibility.
I'm not sure what you're asking, but this would be a non-issue. Go executables are not that big—and it's not like Rust's executables are better—and they allow programs to be easily deployed to a server machine; it almost reminds me of the days of pushing a bunch of PHP3 files to an FTP server.
Is there any way of understanding how much of the OpenSSL API this supports? &amp;#x200B; \&gt; **Transparent Replacement**. MesaLink provides OpenSSL-compatible C APIs. Want to use MesaLink in curl or Android? No problem. &amp;#x200B; That doesn't make it super clear, I'm wondering if anyone has experience of using it as a drop in replacement for OpenSSL, without changing any code, and how often that's worked.
The executable in the blog post is 88MB stripped. That is rather big, and I suspect Rust could do better, for the reasons jimuazu stated. But it's also a bit of an extreme case, and given a choice between bloated binaries and slow compilation, a lot of people (including me) would pick the bloated binaries.
This kills the crab.
[Previous discussion](https://www.reddit.com/r/rust/comments/b6rupo/mirai_abstract_interpreter_for_mir/)
For those who have concerns about the "Transparent Replacement" claim on the website: MesaLink has a drop-in replacement solution for Android. With a JAR/AAR and a single line of code, an app can switch to MesaLink transparently. We've done it for some set-top boxes running Android 4.4. This solution is not open sourced yet but will be open sourced soon. For curl，this is done with its MesaLink tls backend. See @bagder's tweet [here](https://twitter.com/bagder/status/1040125792657846272). I agree this is far from complete. The decades-old OpenSSL has hundreds of APIs; but not all of the corresponding features are implemented in rustls and ring yet. We try our best to implement the frequently used ones.
Note that it is already not necessary to do this for lifetimes in impl headers. Quoting the [Rust 1.31 release notes](https://github.com/rust-lang/rust/blob/stable/RELEASES.md#language-2): &gt;[New lifetime elision rules now allow for eliding lifetimes in functions and impl headers.](https://github.com/rust-lang/rust/pull/54778/) E.g. &gt; &gt;`impl&lt;'a&gt; Reader for BufReader&lt;'a&gt; {}` &gt; &gt;can now be &gt; &gt;`impl Reader for BufReader&lt;'_&gt; {}` &gt; &gt;.Lifetimes are still required to be defined in structs. &amp;#x200B;
I don't think it would deter anyone who argued against Rust with me. 88 MB is very small compared to some of the containerized web apps that I've seen and given that only a single file is needed rather than a bunch of files + dependencies installed via `apt-get` or `yum`, this would be seen as another reason to pick Go.
That's really cool. There's even CI with code coverage (doesn't happen much in scientific code base!) I've implemented an FDTD-based Schrodinger solver some years ago (see [the pdf's](https://ruor.uottawa.ca/bitstream/10393/30511/3/Bigaouette_Nicolas_2014_thesis.pdf) page 113 for some nice figures of what this could do). It was in C++, parallelized with OpenMP and MPI. Had a ton a fun doing this and really liked C++. Today, I would totally do it in Rust instead of C++. I'm glad to see that someone did it! Last commit to Wafer was last summer, with a bunch of issues opened two years ago. Are you the author? Is it still being worked on?
Hey, I am the author of biscuit crate here. The limitation is because there is (IIRC) no such feature in ring, the crypto library I use, to do so. The only solution I can think of is to use the openssl crate instead. I don't have the time and motivation ATM to implement this, but if you want to give it a stab, please go ahead. Thank you for your patience.
Rust 2018 does this for lifetimes, and I think we should stop there. From what I can tell, this is an optimization for writing code, but comes at the cost of making it harder to read, IMO. So no, I hope nothing like this is ever added. I also disagree with pointing to Haskell as an exemplar, but I don't feel like going into details because I don't feel like getting into an argument with Haskell programmers tonight.
&gt; If people are interested, I can write the RFC. What do you think? Gankro recently [raised this](https://discordapp.com/channels/442252698964721669/443151225160990732/558699754884694016) as well. I think this is a good idea to explore so please reach on [#design](https://discordapp.com/channels/442252698964721669/443151225160990732). I've left some notes there for you to think about. I do think that this should be limited to implementation headers as a start because otherwise `x: &amp;'a Foo&lt;_&gt;` could just as well be global type inference which infers the type (possibly polymorphic + bounds, or possibly a ground type) for you.
It would be helpful to see example types your trying to convert between. Deserializing into a str, can be strait forward with serde, just need to add a lifetime and switch from String to str. The hard part is making sure the lifetime stays valid. But if your parsing from a \[u8\], it can get a bit more complicated depedning on how invalid utf-8 is handled. &amp;#x200B; Here's the example from [https://docs.serde.rs/serde\_json/](https://docs.serde.rs/serde_json/) converted from String to str. https://play.integer32.com/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=233382d95b578841a0aa350f67526c1e
I want to try it next
Values themselves are static, even if the references that point to them are not. If you transfer ownership of a value, you are granting its new owner the ability to decide the lifetime of that value.
Ah hah, thanks for the explanation!
lol
There's two approaches. You could store a Box&lt;dyn CellTrait&gt; in your array, which is the rust version of storing anything that implements a certain interface (trait). In this case, you should probably just use an Enum: enum AnyCell { Empty(EmptyCell), Text(TextCell), } Then any Cell can either be an AnyCell::Empty or AnyCell::Text, which contain the corresponding struct as their inner value.
IIRC some pushes can be constant and variable (e.g. `*` part), it may be still possible to do it, but it will be too complex for its worth.
Disable Defender or whatever AV you use during the rustdoc phase.
I'd suggest measuring this using Docker (https://docs.docker.com/engine/reference/commandline/stats/) rather than having the process report its own notion of what it's using. This is both easier, and more of an apples-to-apples comparison.
&gt;replace multiplication by 2.0 `std::ops::Shl`
&gt;We’re using the is\_err method on the Result to check whether it’s an error and therefore unset, which means it *should* do a case-sensitive search. If the CASE\_INSENSITIVE environment variable is set to anything, is\_err will return false and the program will perform a case-insensitive search. We don’t care about the *value* of the environment variable, just whether it’s set or unset, so we’re checking is\_err rather than using unwrap, expect, or any of the other methods we’ve seen on Result. Yes generally you do care about the value of an environmental variable, this is just an odd case where you don't. The key part to focus on here is the `is_err()` method. If `CASE_INSENSITIVE` is not set then the `env::var()` function will have an error result causing `is_err()` to return `true` to the variable `case_sensitive`. It's a double negative situation which is why it is confusing. 
This seems like an odd error, and it might be a secondary error caused by something else. Could you post the warnings you mentioned in here too?
 but I don't feel like going into details because I don't feel like getting into an argument with Haskell programmers tonight. Big Mood
Functional programming: You never mutate a variable and so it is always available in that state. You create new variables every time you want to change the value, and each new var- constant has a specific use-case. Object-oriented programming: Variables are cooked up before the final result and they CAN be changed. You cannot reference an old value. &amp;#x200B; Does this make FP inherently safer?
In theory, yes, as immutability precludes data races. In practice it is a win for some problems and not so much for others. See, some problems can be easily solved by an algorithm that changes stuff in-place and FP solutions have to include a lot of accidental complexity to work around immutability, which can lead to hard to debug inconsistencies because you have multiple versions of the same thing floating around and no longer are sure which one you should be using.
I wrote this blog post with a strong focus on the font fallback work, but I think there are lessons about writing Rust wrappers for OS services in general, and I'll expand on that a bit here. First, I think this is very important work, and plays into Rust's strengths. It's rare for languages to have good platform support. In some cases, like Java, you're in pretty good shape if what you need is in the standard library, but then it tails off pretty sharply. Other languages might be pretty good on one platform, but not so good across the board. Second, this is not easy. The linked [font-kit#37](https://github.com/pcwalton/font-kit/issues/37) highlights some of the difficulties. You have to design an API that abstracts the differences of what platforms provide without losing the power. I've had the benefit of consulting with pcwalton, and others at Mozilla about the font-specific questions, and it's still work in progress, involving multiple sub-problems. Third, though I didn't mention it in the blog post, I think safety is critical. Patterns such as [IDWriteTextAnalysisSource](https://docs.microsoft.com/en-us/windows/desktop/api/dwrite/nn-dwrite-idwritetextanalysissource) are common. In this case, the pointer returned by GetLocaleName has to be valid until the next call into the object. Figuring out how to express that as safe Rust is not easy. I *think* making it not Sync and disabling Clone should be ok, this should guarantee only one instance of the object is called at a time, but it's hard to be certain. Certainly there are other safety problems in dwrote, and for this reason and others I'd like to migrate to directwrite-rs. Connicpu has a different idea how to do the text analysis trait, basically requiring references to be valid for the entire lifetime of the object (so methods like this can be true `&amp;self` with no limitations on concurrent access from multiple threads) and I think that might be better. And overall there needs to be a lot of attention to the quality of such abstractions. There's exposing enough functionality and safety, and of course not doing things that kill performance or cause architectural problems (creating new threads for the convenience of the abstraction is a pattern I see too often in Rust libraries). But then there's compile time and code size. On my Windows box, font-kit takes just over a minute to compile and over 800k release code size. That seems high for something that's just loading fonts, but on the other hand I don't see any good way to get this down. I am hopeful though. As more and more of these kinds of abstractions are available, life gets significantly better for people who just want to write apps. I'm very pleased to be part of that effort.
Aha but that's why you always use unique, very obvious-use, very memorable constant names. What kind of complexity are you thinking of?
To my fellow Rustaceans, thank you so much! The MesaLink project just earned the 1000th star on Github!
I'd actually be really interested to see if we can make MesaLink a feature of the curl crate...
&gt; How do I select the Char component struct based on the textual value "char"? By using `serde`, which do this easily
Thank you for the help! The only issue I see for Box&lt;dyn CellMethods&gt; is that to initialize the "sheet" array, EmptyCell needs to be in a Box of new, which in turn needs to implement clone-able (Error: "error\[E0277\]: the trait bound \`std::boxed::Box&lt;(dyn Cell + 'static)&gt;: std::marker::Copy\` is not satisfied"). I also am curious on how an enum would work in this case, cause when you check the array, you'll still need to use match to have Rust know what object it is. I thank you for the help, but alas I am still stuck... 
I'm sure you'll find enough examples on the web. One famous classic is James Hague's [purely functional retro games](https://prog21.dadgum.com/23.html).
"Shl" doesn't work with floating point. "Add" works with everything.
True
If you implement `CellMethods` for `EmptyCell` and `TextCell`, then I think that you can the use [enum_dispatch]( https://docs.rs/enum_dispatch/0.1.2/enum_dispatch/) to implement `CellMethods` for AnyCell AnyCell' 
As someone who often works with GUI in Rust, this would absolutely be an incredibly useful crate for the ecosystem. Thanks for taking the time to address this Raph, best of luck in your endeavor!
If your IP and port values are clonable, you can .clone() them and return copies instead.
Thank you for the link c:
I upvoted purely based on the title. Godspeed to any poor soul who delves into this.
Your function is currently returning a structure which contains a reference to `x` or `data` which is not specified as a lifetime dependency in `SomeEnumType`. So as another poster suggested, you can clone the data into the enum, or you can try to make it `SomeEnumType&lt;'a&gt;`.
Is baidu recruiting in Europe / remote?
Thank you! I am also encountering an error with the enums due to the fact that TextCell has a field of type String, which is not copy-able. Aurghh! im just drowning in compiler errors...( [Rust Playground Error](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=0e06f07b5006cfc0a006b17fa191a40b) )
As of now I think the least annoying option is to make different debugwrappers for `Method`, `GetProp` and `SetProp`. Thanks for the support!
Rust used to not have its MIR, so it's entirely possible.
On CJK text, there's also Hong Kong Chinese which also has writing differences compared to Taiwan Chinese. What's usually marked as Traditional Chinese really just followed the Taiwanese standards. In the past, fonts that follow the writing style in Hong Kong are rare and most (if not all) of them are paid fonts. But finally Source Han Sans version 2.000 added separate glyphs for Traditional Chinese (Hong Kong). Hopefully its use will get more popular in the future.
Ohh you make the functions static, but the variables being used dynamic. Would that work to allow for not having direct mutability?
You probably shouldn't derive `Copy`. (`Copy` means that you can create a clone of an object by copying the memory directly bit by bit, and that doesn't work with strings). But if you don't derive copy, then you need to change `SpreadSheet::new()`. I think that the best solution is to use vectors instead of fixed size arrays so you get pub struct Spreadsheet { sheet: Vec&lt;Vec&lt;CellType&gt;&gt;, } You can populate the vector of vectors by using for-loop and `push()`. Alternatively you can be fancy and use [ iterators]( https://stackoverflow.com/questions/48021408/how-to-init-a-rust-vector-with-a-generator-function?rq=1) 
You could get the current process id using `std::process::id` and then launch a thread which regularly polls the memory usage using some external command (e.g. `ps` on Linux).
Psst: There's no image here.
Yeah, sure! I'll tag along then! :)
I'm making a simple wrapper around a map. But I can't get it to compile in either the `get1` or the `get2` version. It should be simple, right? #[derive(Ord, PartialOrd, Eq, PartialEq, Clone)] struct MyCow&lt;'a&gt;(Cow&lt;'a, str&gt;); struct MyMap(BTreeMap&lt;MyCow&lt;'static&gt;, MyData&gt;); impl MyMap { fn get1(&amp;self, c: &amp;MyCow) -&gt; Option&lt;&amp;MyData&gt; { self.0.get(c) } fn get2&lt;'a, C: Into&lt;MyCow&lt;'a&gt;&gt;&gt;(&amp;self, c: C) -&gt; Option&lt;&amp;MyData&gt; { self.0.get(&amp;c.into()) } } `get1` fails with `lifetime mismatch`, claiming that data from `c` is returned, which is wrong, as only data from `&amp;self` is returned? `get2` fails with `cannot infer an appropriate lifetime due to conflicting requirements` which I suspect is related to that it thinks it returns data from the key (rather than the value). This works: fn get3&lt;'a&gt;(&amp;'a self, c: &amp;'a MyCow) -&gt; Option&lt;&amp;'a MyData&gt; { self.0.get(c) } ...but that is not what I want, because it borrows `MyCow` for `'a` and not just the lifetime of the function. [Playground link](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=ea8f09edfb2bc3ebecab90befe2de352)
Use ctop :p https://github.com/bcicen/ctop/blob/master/README.md Think hard about whether it's worth it losing the jvm for 30mb of memory. I find 99p and max response time much more interesting metrics if we're talking microservices.
I was only partially joking. I've had to write significant amounts of this type of code, and type aliases were the only way to keep things sane.
\`fn get1(&amp;self, c: &amp;'static MyCow) -&gt; Option&lt;&amp;MyData&gt;\` , the reference of the key need to be static too. way did you put \`static\` in \` struct MyMap(BTreeMap&lt;MyCow&lt;'static&gt;, MyData&gt;); \` ?
It's the first image on the page. 
Why would I need a static reference to `c`? I only need `&amp;c` for a short moment to lookup the value in the map. &gt; way did you put static in struct MyMap(BTreeMap&lt;MyCow&lt;'static&gt;, MyData&gt;); ? Would it make a difference w r t this particular problem if I instead did `struct MyMap&lt;'q&gt;(BTreeMap&lt;MyCow&lt;'q&gt;, MyData&gt;)`?
&gt;This is the same as [\#56241](https://github.com/rust-lang/rust/pull/56241) except that it imports hashbrown as an **external crate** instead of copying the implementation into libstd. What does this mean? Does this mean we need to use hashbrown as extern crate (like *rand* or *regex*) or we just use hashbrown as `use std::some::place::to::HashTable`? 
I'm curious about this myself. Maybe it means that std imports it and adds a pub use for it. 
Is there a repo to follow? (assuming the work will be open-source?)
I did my bachelor thesis last year in Rust. The subject was computing Casimir forces. I didn't parallelize, but I did make use of Rust's ownership system to reuse allocated memory safely. The program, `casimir-fdfd` is on [Github](https://github.com/ThomasdenH/casimir-fdfd). My thesis can be read [here](https://gitlab.com/denhollander-thomas/casimir-report/-/jobs/artifacts/master/raw/Intersecting%20Discs.pdf?job=compile_pdf).
That's a great solution for a problem that didn't have to exist. I should really finish rust-rst. Markdown is just not a good format for technical documentation. rST roles are ideal for that.
I'm not sure how I feel about the standard library having dependencies in itself.
There is no mesalink on crates.io, why?
This is purely an implementation detail. Your use doesn't change at all. (It would be a breaking change otherwise, which isn't allowed.) Internally, std already depends on external unwind crate to print backtrace for example. This is no different.
It's part of the loopiness of rust's dependency story - self compiling was just the start. Please note that it's not new, and it's already part of how Rust works.
&gt; Does this mean we need to use hashbrown as extern crate That's how it works now. Why would they do all this work to change nothing? The way I interpret this is that the hashbrown HashTable is going to be the implementation that's in std, but in the Rust source code it's imported as an external crate as opposed to having the hashbrown code "ported", for want of a better word, into the Rust source code.
That's because cargo is not meant to be used that way. You should instead use cargo build, deploy the resulting binary (manually or with "cargo install" or even "sudo cargo install") and run the binary. Cargo is a build tool, and "cargo run" is just a convenience thing for when you're testing and don't want to type "cargo build" and then "cargo run" all the time.
Right, so if I went and downloaded the source for std-lib and built it it would download third party dependencies? TIL.
Yes. About *downloading* it depends on method of distribution - with source from git it would download. They are bundled with the official source tarballs, because Rust must of course be buildable offline. Fun fact, the 3rd party directory is about 25% of the source package.
Yeah, I noticed the lack of conversion feature in the Ring. I might add that feature in the Ring or add a helper library on the side to make it work. I'll make a PR if I end up doing that.
This looks interesting. I'm gonna try out something similar.
What does this mean to users exactly? Looking at the PR I have no clue how it'll effect my programs.
&gt; Would it make a difference w r t this particular problem if I instead did struct MyMap&lt;'q&gt;(BTreeMap&lt;MyCow&lt;'q&gt;, MyData&gt;)? yes, more option &gt; Why would I need a static reference to c? I only need &amp;c for a short moment to lookup the value in the map. because you bound `MyCow` lifetime to `MyMap`, so they need to be of the same time, don't ask me why that far belong my knowledge. I find you are doing something very odd, why not use a &amp;T for the key ?
Your HashMaps are going to be faster.
Sure; I respect OCaml's choices. Trade run-time performance for compile-time performance is reasonable and does not compromise on correctness. Type erasure is a reasonable strategy to take. When you have higher ranked types (which OCaml doesn't have afaik) then it becomes a necessity as well. This is one reason that GHC cannot monomorphize when you use e.g. `Whatever -&gt; (forall b. Show b =&gt; b -&gt; String) -&gt; String`. `rustc` does also employ type erasure for lifetimes since they are gone during codegen. Moreover, `dyn Trait` is a form of explicitly requested type erasure. One aspect of GHC is that monomorphization isn't part of the language specification, type erasure can always be employed. I believe it's not the same in Rust, but there are situations wherein `rustc` could elect to employ type erasure for better compile times and smaller binaries. It would need to prove that the function does not violate parametricity so as to avoid changing the dynamic semantics.
If your code uses HashMap, it will run faster. rustc itself is also known as "giant HashMap benchmark harness". It depends on workloads, but rustc sped up about 5%(!) end-to-end in average.
Only that any uses `std::collections::HashMap` will become faster and use less memory.
That's impressive. The last comment in the PR asks for a delay of a week, does this mean that hashbrown will likely not be in the next Rust release?
Yes. It won't be in the next release to maximize amount of testing.
Oh it is there, i didnt scroll far enough to see it lol
&gt; Has anyone succesfully done that or know of a workaround to do this? I wrote a crate for exactly this: [alcoholic_jwt](https://docs.rs/alcoholic_jwt/) It's used in a production environment and is specifically for the use-case of validating RS256 tokens with a JWKS key set. 
Oh, wow! This is fantastic! Thanks for sharing.
The author has a Github link at the top of the post. https://github.com/simmons/webrtc-sctp
Oh, not sure how I missed that, long day. Thanks! 
"could" "in most case"
I was actually looking into writing this, but soon realized that streams are hard, especially when converting between codecs and the automatic bridging that Asterisk does. Maybe integrating with Asterisk's ARI and not using dialplans at all could be done, but it would definately be useful to have a pure Rust solution.
&gt; "ported", for want of a better word, into the Rust source code The word you are looking for is ["vendored"](https://stackoverflow.com/questions/26217488/what-is-vendoring).
How did they achieve that? Using a different hash function? 
You just use the `std` `HashMap`/`HashSet` and those are actually `hashbrown`.
Server name: RustyRust IP: [54.36.246.27:2047](https://54.36.246.27:2047)
Try posting in /r/playrust and you might have better luck.
Wrong rust. This sub is for the programming language, not the game. I think the game one is /r/playrust
/u/Fox4ot: /r/playrustservers is the sub you're looking for
Does it use prime lengths rather than powers of two?
You could use jemalloc allocator and jemalloc's statistic API See https://github.com/rust-analyzer/rust-analyzer/commit/c7f4e3a401ec1919e1a578abe5938df430f46fc9 and https://docs.rs/jemalloc-ctl/0.2.0/jemalloc_ctl/
You are absolutely correct. However, the question wasn't: "what is the exact result of the merging of this PR on any hypothetical program", the question was "what is this PR about". It's about making HashMaps and HashSets faster. It's not about making them faster in all cases and it's not about making them slower in edge cases. Just generally faster.
https://github.com/Amanieu/hashbrown &gt; This crate is a Rust port of Google's high-performance [SwissTable](https://abseil.io/blog/20180927-swisstables) hash map, adapted to make it a drop-in replacement for Rust's standard HashMap and HashSet types.
Thanks All
 [https://www.youtube.com/watch?v=ae31-Cobmhs](https://www.youtube.com/watch?v=ae31-Cobmhs) 
/r/playrust
Thanks, isHavvy. Apparently without an image caption it didn’t show up on the iPhone or mobile. 
He knows, he's just spamming this vid into all subreddits that contain *rust*
&gt; no short-coming of Go seems to have that kind of braking effect on people. Pretty much any of the shortcomings you listed are enough to make me balk at using Go... I'm just silent in my choosing not to use it. It wouldn't surprise me if that's a recurring pattern. (ie. Rust's shortcomings invite bikeshedding more readily than Go's... which would make sense, psychologically, given how the term was originally described.) &gt; A reactor is so vastly expensive and complicated that an average person cannot understand it, so one assumes that those who work on it understand it. On the other hand, everyone can visualize a cheap, simple bicycle shed, so planning one can result in endless discussions because everyone involved wants to add a touch and show personal contribution. If I'm going to move away from Django's ecosystem of reusable drop-in apps for developing web applications, the value proposition for overcoming Python's maintainability shortcomings has to be *huge* and, so far, Rust is the only language with a combination of performance and compile-time correctness checking that's a candidate for it. Likewise, I have yet to see any viable Qt bindings for Go, while rust-cpython and setuptools-rust make it easy for me to use a "Rust backend, Python frontend" approach for developing a memory-safe Qt project. (I like to describe it as using Python as a QML for the QObject API.)
I'm just pointing out that some developers aren't just brushing off the inefficiencies Go has, as you suggested. Instead they're worried enough about them to do a lot of analysis of the problem and look for other solutions (although there seems to be no solution available within Go).
It wouldn't really make sense because the top level interface of mesalink is not a rust crate; it's an OpenSSL-compatible C library.
nice! did you by perchance have that on GitHub? or was it just a side sandbox play?
&gt; It wouldn't really make sense because the top level interface of mesalink is not a rust crate; it's an OpenSSL-compatible C library Why have no sense? There is a lot of `-sys` crates, it is just one of them. But in compare with other `-sys` crates, there is no need for `pkg-config` and so on thing to find c library, just add `c library` as `dependicies` and that's all. Much more simple for every one in compare with `cargo install` + `pkg-config`
I didn't get that far, even: just some initial research and looking at existing implementations. However, if you're looking into working on this, I'd be happy to help.
But unlikely to be desirable. The current AST borrowck was unsound after all.
Afaik, although Mozilla is the one pushing the language they language comitees are mostly independent from their structure. So I guess development would continue as long as popularity keeps it afloat.
IIUC you can use `mesalink` via `openssl-sys`/`openssl` with some configuration. But if you already have Rust project which is not dependent on OpenSSL, why do you want to use a C FFI wrapper and not `ring` and `rustls` directly, which arguably provide much better and more idiomatic interface?
I'm getting E-Nguyen started and it's main upstreams are Vulkano and sound server crates like libpulse bindings. An area of low-hanging trivia is whether monitors exist on OSX etc and whether libraries like Cpal have any potential to tap into them. 
As far as people go, very little of Rust is actually tied directly to Mozilla. Even if Mozilla disappeared, there is a pretty large community that could sustain the project. The people who were working there would have to find another place to work, but given how important Rust is becoming in several very large tech companies, that probably wouldn't be too bad either. 
Sorry, I didn't mean to diss on the technique in general. I think for this case I'm not very impressed, but it would definitely be very useful for larger systems of types.
If I'm not mistaken that means the hashbrown crate is no\_std compatible, meaning that the std implementation of the hashmap will thus be available to environments without the std.
Lots of companies, ones much larger than Mozilla, use and rely on Rust. I'd imagine it's in their interest to fund it. Google, AWS, Facebook, and Dropbox all seem quite invested at this point. And Mozilla isn't going anywhere.
I have some questions regarding hashbrown: - Does it get updated with the regular packages or only with `libstd` updates? - If I happen to depend directly on the same version of hashbrown as libstd, will it be reused or does the binary contain that code twice? - Do you audit new updates of libstd's third-party dependencies?
&gt; Does it get updated with the regular packages or only with libstd updates? It only gets updated with `libstd` because it's being vendored in.
this is exactly what I needed!
I wish! sadly between work and existing clients I have exactly negative 48 hours! I was just seeing if there was any prior art in this VoIP space, I know Python has a bunch of good libraries for things like SIP proxying and pen testing etc. Guess will have to give a few more years, It's a massive undertaking for anyone!
watch the video about swisstable
&gt;"what is the exact result of the merging of this PR on any hypothetical program" the correct answer is "this PR is trying to make hash collection faster in most case". But my comment was just to point out that thing are not as simple as "this will be faster, period", your message was a little too assertive in my opinion, when talking about benchmarking be assertive is not a good thing.
 Swisstable use power of two
they have talk about it: * https://github.com/rust-lang/rust/pull/58623#issuecomment-469964699 * https://github.com/rust-lang/rust/pull/58623#issuecomment-470088924 * https://github.com/rust-lang/rust/pull/58623#issuecomment-470187588
That's exactly the opposite of what this PR does. There was another version that used vendoring, but this uses `extern crate`. The answer to the original question is that `hashbrown` will probably continue to get updates outside of Rust releases (although I'm not sure how much change will be necessary at this point). `rustc` is just another crate here, so the same dependency rules will apply as with any other binary crate.
&gt; Added support for content in multiple languages Nice! 👏
There would be a painful transition for a while. For example, Mozilla holds trademarks for Rust and Cargo. In the worst case, say, if Oracle acquires Mozilla, we may have to rename, as Hudson renamed to Jenkins. Mozilla also pays CI bill for Rust.
What's the criteria for replacing the standard library data-structures? What happens if someone else comes up with a quicker hash map implementation in a couple of months? Is it going to swapped out again? Also as far as I understand there are optimisations in HashBrown that could be applied to Robin Hood, like the new_drop optimisation, was that taken into consideration? Apologies if I'm wrong on this account. 
Ah, sorry. Thanks for the correction!
Indeed! I didn't go into this in the blog post, but I do plan to fully support zh-Hant-HK, with fonts that have the coverage. In this case, it's not done by choosing a font at itemization time, but by passing a `locl` feature into the shaper so it can do Hong Kong specific substitutions of glyphs. Also, locales have gotten more expressive, it used to be people would say zh-CN for Simpified and zh-TW for Traditional, but now I would say zh-Hans and zh-Hant respectively. The ["add likely subtags"](https://github.com/projectfluent/fluent-locale-rs/issues/9) method does the necessary computations per locale, and I have an implementation of that I will PR soon.
&gt; What happens if someone else comes up with a quicker hash map implementation in a couple of months? Is it going to swapped out again? Yes, I believe so. This happened in the past: for example, pattern-defeating quicksort replaced Timsort.
Is the theme-API similar to hugo or jekyll? This way zola could gather hundreds of themes at once.
How is Google invested?
Is rustc taking already taking advantage of SIMD or will this be the start of it?
There might be more, but parts of the Fuchsia kernel are written in Rust
The new OS Fuchsia that their working on uses rust
The current situation as I understand it is: - Mozilla employs a couple people to work full-time on Rust itself. This is a small number, though I think is currently more than any other company. - Mozilla funds Rust's infrastructure - Couple legal things like trademarks (?) Mozilla's not the only company with full-time Rust employees, and it's not the only company that has offered infrastructure money to Rust. If Mozilla unexpectedly shut down, like, today, I can name a couple companies that would be interested in paying at least some of the folks who work on Rust at Mozilla to continue doing roughly what they currently do. I know at least one other company who could take over the infra (they have been trying to supplement our infra budget for a while, but the billing is tricky). Rust has very much been more-than-just-a-Mozilla project for quite a while now. It _used_ to be a Mozilla project, but there was a deliberate push to make it its own thing.
or python scripts could be written to port them over
Do you have any suggestions for what route to go (frontend to Asterisk vs complete rewrite) if I do decide to start this?
A non-trivial of us prefer the look of old Reddit and old Reddit uses a different markdown parser which doesn't support fenced code blocks, leaving it looking [like this](https://screenshots.firefox.com/KDBN9SJO5NFN6yNu/www.reddit.com). Could you please indent that by four spaces instead?
I think it's the other way around. What will happen to our programs? Their HashMaps and HashSets will be faster. Saying that there may be edge cases, and that HashMaps are not guaranteed to be faster, is accurate but beside the point.
I was wondering whether a company with little regards for "open source" (in large sense) would be able (if acquires mozilla) to make Rust less open and/or make you pay one way or an other (not pointint at any company in particular :wink:). I don't to what extent Mozilla owns Rust. It's not really clear to me (except the trademark you just mentionned). @staticassert mentionned that a lot of other companies rely on it and would fund it. However if Mozilla currently owns certain exploitation rights or pattent couldn't they use that as leverage to some profit ?
How?
thing 1) your lib needs to be compiled as a `cdylib`, the `dylib` is essentially for internal compiler use only. thing 2) your function in the lib needs to be declared with the ABI your main expects, so the lib also needs to be an `extern "C" fn` instead of just `fn`.
This was made with [https://github.com/src-d/hercules](https://github.com/src-d/hercules) BTW :)
done
How do you disable Defender on Travis?
&gt;And Mozilla isn't going anywhere. Hope not anyway, they've already been around for quite a while and seem to have their shit together. Funny enough, I've never asked myself this question when starting with C# (guess that seeing microsoft go away was even more absurd). But I'm investigating into adoptin Rust as main programming language for my game studio and wondered "what if" ... (I secretly hope that my studio will leave long enough so the disappearance of Mozilla is not something so absurd, not that I wish for it :P)
Rust is under Apache2/MIT, so the patent situation is probably pretty straightforward, I think. People can't also just decide to make it less open due to the license. I wouldn't say Mozilla owns rust, however Mozilla has been the de facto legal entity for rust stuff.
I just added the license! The cli arguments are pretty poorly made, where one argument represents three inputs.. Ideally there should be lots of changes there :X
This is about changing the hashmap used in libstd, not just in rustc. Yes, hashbrown will have it's own release cycle but those changes won't make it in to libstd without an explicit update PR, like this: https://github.com/rust-lang/rust/pull/59643. Each version of libstd will include one and only one version of hashbrown; it won't change randomly as if each user had a `hashbrown = "0.2"` line in their Cargo.toml.
Try [https://github.com/serenity-rs/serenity](https://github.com/serenity-rs/serenity) instead. It's much more uptodate and has far better examples.
I'd recommend using [serenity](https://github.com/serenity-rs/serenity) instead. There should be plenty of examples to help you out.
Thank you!! That will help a lot. 
What would give the impression that there was even a possibility of Mozilla shutting down? 
Looks like at the start of 2019 more than half of the existing source code was written in 2018, that's insane. Not that more code is necessarily better, but to a degree it still indicates how much work has been done last year.
I believe, though am not sure, that google is or may soon be the largest employers of primarily-Rust programmers in the world. They also allow their employees to contribute back; they’ve been instrumental in async/await, for example.
This release also has pulldown-cmark 0.4, which means that it gets faster rendering and better compliance with the (draft) spec.
Nothing in particular, (sorry I'm not withholding any earthshattering secrets about Mozilla situation ;P), I'm from the game industry so in my mind companies are not around for long, change hands, merge, projects are cancelled, replanned, etc... So it's simply my approach to things. But I'm well aware Mozilla is not a startup or in any particular difficulties at the moment. I'm being overly cautious with techs ^^.
That makes it pretty clear thanks ^^
\&gt; I'm from the game industry &amp;#x200B; Say no more, fam. I can totally understand being gun shy, then. But Mozilla is a keystone in the open source software community and has been around for a very long time. They'll continue to be here for a very long time, too. 
That is definitely a fact I'm going to use to convince my coworkers (and other people) to switch to Rust! :D &amp;#x200B;
&gt; (guess that seeing microsoft go away was even more absurd). Even if we imagine the worse case scenarios - all corporate sponsorship is gone, infrastructure too, and the most active professional developers can't contribute or consult at all, etc. - both communities have the legal rights in place to keep using the toolchain sources. Rust since the beginning, C# since ~2014. Check out the Blender project for a real-world example of software surviving one bankruptcy to become freeware, surviving a second bankruptcy and lingering license issues to become free software, and doing very well since then.
Yep, the spec compliance is definitely a big part from this release. The speed improvement is a neat surprise on top!
It has themes but I don't think you will be able to port them automatically due to the data structure/template engines being very different. It isn't very hard to convert a theme manually though. The only tricky one was https://github.com/getzola/book due to needing some features in Tera (the template engine used in Zola) that didn't exist at the time. There are a few themes I maintain in https://github.com/getzola but I forgot to update them for the 0.6 release. I'll do that this weekend but they might not be working right now with the latest Zola.
&gt; I just added the license! Great :)
I can't imagine how enervating it must have been to get it to this point. A huge thanks to all.
I wonder if there were mass rustfmt runs or other style changes that would explain this.
The easiest way to give your `DuktapeContainer` a stable location in memory is to `Box` it. That will let you move the binding to new locations without invalidating the pointer that you passed to C. Of course you still could cause invalidation if you destroy the `Box` before C is done referencing it or if you `mem::swap` the value out of it, so those are cases that you'll still have to keep in mind.
I think this is a link only valid for the creator of the video; the rest of us go [here](https://www.youtube.com/watch?v=VboA0dnEE_s). But it's about Rust the game, not Rust the language. /u/Tacoholics_117, you're looking for /r/playrust.
The edge cases you mentioned would actually be solved with wrapping the Box with Pin, so going back to OP Pin&lt;Box&gt;&gt; may be what you need.
I think it would be more elegant to have filter_not.
I can help with pulseaudio. I've used it before. Also I can test and try things in macOS.
Really looking forward to that one. It’s a mess right now with three different revisions competing against each other.
Aha, thanks. Do I do that before creating the pointer, i.e.: let container = DuktapeContainer { memory_used: 0 }; let boxed = Box::new(container); let container_ptr: *mut c_void = &amp;mut boxed as *mut _ as *mut c_void; or at some other point? I've tried doing the above but still seeing a segfault, it might be that I'm causing an issue elsewhere...
 #[macro_use] extern crate diesel Toss that in main.rs or lib.rs. It’s the old syntax but it works. 
I do have that, but the macros in the generated \`schema.rs\` are not defined.
Two, futures 0.2 pretty much doesn't exist.
It's futures 0.1, futures 0.3 and std::future.
What's the best vscode+rust setup today, on Linux systems (in my case, Ubuntu)? As in, rusfmt+auto-completion+showing errors automatically. My current setup seems broken: the autocompletion rarely works, external crates always show up as red, the computer freezes for a minute when I open a rust codebase in vscode, and so on. I'm thinking of removing everything but I remember having to fiddle with a lot of configuration - what things do you need to do *today* to get it to work? Even three month old guides may be out of date...
From the scale I am forced to conclude that until late 2018 Rust was less than 1.2 lines of code, it briefly spiked halfway to a million lines of code, and then we deleted all but about the original 1.2 lines. We changed a few characters in those lines. I'm not quite sure how you have a fraction of a line of code, that is a topic for future research.
When creating the boxed instance, you can just do `let boxed = Box::new(DuktapeContainer { memoy_used: 0 });` if you like. As for the new segfault issue, I think you want to make the pointer with `as_ref()`. Right now you're passing a pointer to the `Box`'s current stack location which contains a pointer to the heap value, and what you really wanna do is pass a pointer directly to the heap value. You can see here how you get different pointers depending on how you reference the box: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=78f60f47e85743194f2450ff7b768168
futures 0.3 and std::future is the same futures 0.3 re-exports std and just adds more utilities
The solution to this is [link](https://stackoverflow.com/questions/55537573/how-to-link-a-dynamic-rust-library-using-only-rustc-and-not-cargo), I asked the same question on overflow
Still nothing :-t (Reddit app on Android)
most of the official rust code ive had to spot fix lines on was _not_ already formatted with rustfmt. I kept having to turn off "format on save".
Just call it exclude
Not really, pinning does not prevent you from dropping the Box. &amp;#x200B; Pinning is for self-referential types, i.e. when there's a pointer inside the box that points to the box itself. Those pointers would break when moving out of the box, but dropping is totally ok. &amp;#x200B; You can always do drop(container) here and get UB when the callback is called, doens't matter, whether it is pinned or not.
Ah. Your right. I do believe however it would prevent a men::swap though from occurring, at least helping with some of it.
What if the nuclear powers suddenly start nuking each other? What if SF and some key industrial centers are suddenly gone? At a smaller scale, what if some rogue states start deliberately cutting undersea cables over and over again? All these questions are important. And some entity should definitely be sending tools, machines, and professionals away to places like Edmonton, Cape Town, and some even more secure and remote cities, as a contingency plan. But that's not the kind of thing that will be put in place as a response to a Reddit thread. And if we were to ever reach such a point, a lot would have had to happen along the way that may have made us forget about Rust already. The same applies to the possibility of Mozilla getting dissolved out of the blue.
Was i proven that all implementations of future need to be pinned (or at least all reasonable usages)? The note about pinning makes it seem that it's really implemented for async/await.
I’ve had the same experience, and as far as I know people haven't agreed yet on what the process of enforcing it in the Rust repo should be like – it could reject incorrectly formatted PRs but that might be annoying, or it could be applied after the PR is accepted but that could be too risky, or it could use the new-ish GitHub suggestions feature (but that may only work for changes within a single line, I'm not sure).
The question is not merely if transmuting is sound but if subsequent use is sound. If you have to ask the question then I promise whatever you're doing isn't sound. `UnsafeCell` requires that everyone who sees the data sees it behind `UnsafeCell`, period; if some part of your program has created a `&amp;mut T` then you've violated that requirement.
&gt;o sense? There is a lot of -sys crates, it is just one of them. But in compare with other -sys crates, there is no need for pkg-config inside build.rs and so o Author here. There's not a MesaLink crate on crates.io, for several reasons: 1. MesaLink is not like any \*-sys crate. \*-sys crates provide idiomatic and safe Rust interfaces for other Rust crates; MesaLink provides unsafe C APIs for C callers. So we do not want any Rust crate depend on us. 2. We've considered `cargo install`. But according to the [book](https://doc.rust-lang.org/book/ch14-04-installing-binaries.html), "you can only install packages that have binary targets". MesaLink is a cdylib. And we want to distribute MesaLink just like OpenSSL does. So we turned to Autotools and CMake. More details in my upcoming talk at RustCon Asia; the title is "Cargo meets Autotools". 3. MesaLink uses our own fork of rustls on github (check MesaLink's Cargo.toml). We added a bunch of features to turn on/off certain ciphersuites, elliptic curves, etc. But `cargo publish` does not allow dependencies hosted on Github. 
As for circular data structures, 99.99% of the time that can be solved using arenas, which _are_ indeed safe Rust.
My thinking is building just a core that by default exposes a local restful API, think Elastic Search style, and can be configured to lock it down should external web apps want to integrate. I would leave the front end, that would be for each CRM to hook into and build whatever solution that fits their requirements. But I guess a super simple web UI could be included? If it's done as a plugin design, then perhaps initially the audio conversion stuff could be done using existing open source programs? and then perhaps over time replaced with pure rust versions?
if using rustfmt is too risky for rustc, and they have a super test suite and build check, why the _heck_ are the rest of us allowed to use rustfmt. ;3
That case is close, but not quite what happened. Pattern defeating quicksort is a unstable sort, meaning it doesn't preserve order of equal elements, and was added as the algorithm for `.sort_unstable()`, while timsort is still the algorithm for `.sort()` since timsort is a stable sort. If a better algorithm for either stable or unstable sorts was found though, it would likely replace the algorithm for the respective sort.
Although REST APIs are easy, I think that a more real-time protocol is needed, such as websockets. Otherwise, there would be no way to be notified of incoming calls, or live events such as pressing numbers (DTMF) on the phone during a call.
My baseline implementation of Pulse in E-Nguyen is working* but not via cpal. Cpal might not implement any concept of monitors, so I can't decide what kind of stream to read with it yet. I don't actually grok the response here about some method of configuration https://github.com/tomaka/cpal/issues/259
\&gt; type Output = Self; This won't work, Self is a function pointer, but you are returning a closure.
Mmm, my code runs faster with zero effort on my part. Thanks to Amanieu and everyone who helped make this possible.
1e6 at the top, but I was similarly amused =P.
I'd say that providing a higher-order function that returns the complement of a predicate is definitely the most elegant and orthogonal way. Doesn't have to be spelled `!` though. Prior art includes C++'s [`std::not_fn`](https://en.cppreference.com/w/cpp/utility/functional/not_fn) (and its deprecated precursors `not1` and `not2`); Java's [`Predicate.negate`](https://docs.oracle.com/javase/8/docs/api/java/util/function/Predicate.html#negate--), Clojure's [`complement`](https://clojuredocs.org/clojure.core/complement). In Haskell you'd simply compose with not (`not . myfn`).
AFAIK this is mostly needed to support async continuations and generators that capture references in their state. It shall not be allowed for the pointees of those references to be exposed under a mutable reference where they can be replaced. Most of the futures should be `Unpin` though, so a pinned reference to such a future is equivalent to a regular one.
I'm still getting the segfault (sorry for continuing to bother you with this!). I'm wondering if something else I'm doing in my code is causing problems: extern "C" fn alloc(udata: *mut c_void, size: usize) -&gt; *mut c_void { let container = unsafe { &amp;mut *(udata as *mut Box&lt;DuktapeContainer&gt;) }; container.memory_used += size; return unsafe { libc::malloc(size) }; } fn create_container() -&gt; Box&lt;DuktapeContainer&gt; { let mut container = Box::new(DuktapeContainer { memory_used: 0, context: None, }); let container_ptr = &amp;mut container.as_mut() as *mut _ as *mut c_void; unsafe { let heap = duk_create_heap( Some(alloc), Some(realloc), Some(dealloc), container_ptr, None, ); container.context = Some(heap); }; unsafe { // THIS WORKS duk_alloc(container.context.unwrap(), 100); } return container; } fn main() { let container = create_container(); unsafe { // THIS SEGFAULTS duk_alloc(container.context.unwrap(), 100); } } That same `duk_alloc` call works inside the original function and fails outside of it, yet `create_container` returns a `Box`, so by my understanding that should be OK now. Am I missing something obvious?
I believe closures without environment can coerce to function pointers.
Change this: `let container_ptr = &amp;mut container.as_mut() as *mut _ as *mut c_void;` to this: `let container_ptr = container.as_mut() as *mut _ as *mut c_void;`
Hell would freeze over before Mozilla would let itself be acquired by Oracle.
Ah, my [Dracula](https://draculatheme.com) addition went out with this. Neat, now I can stop running a local copy of it.
TIL, enervating "causing one to feel drained of energy or vitality." I occasionally peak into how futures and async/await are coming along but I've held off on digging in too much because of the lack of stability, so I'm very excited about this. Is there a suggested resource for getting started? It seems like a great time to start playing around with these APIs in beta / nightly. &gt; Unlike other languages, the Future API in Rust uses a poll based execution model. What execution model is used by other languages? 
I will look into e-nguyen and message you later.
Thanks for your answer :-) Do you think it would be worth raising this with the Book people? These two little things seem like gotchas that make the Book a bit harder to follow than it needs to be.
I'm not an expert, but I think most (all?) pre-existing async/await impls are push-based: all futures are allocated on the heap, and when one completes, it internally invokes the code waiting on its result, which is exactly backwards from Rust, where the future that's waiting for a result invokes the future that produces it.
We will do this eventually and likely enforce it in \`tidy\` automatically; we just need to have \`./x.py fmt\` work and also we need a script so that everyone don't have to do a crazy amount of rebasing at once.
Ok so I'm trying to make the deserialization efficient. I have a `HashMap` of `Vec`s which behaves like a 2D array (list? table?). Each time I get some input (a map with strings as keys and numbers as values) I want to read the keys so that I'm sure they match the keys of my `HashMap`, parse the numbers and push them to corresponding `Vec`. The easy way would be to deserialize a `HashMap` from input and then push each value into corresponding `Vec`. Right now I'm trying to implement `DeserializeSeed` on `&amp;mut Storage` (which is a newtype wrapper around HashMap) in such a way I don't need to allocate a new `Vec` or `HashMap`. The reason for using Serde is that I want to parse input as JSON, CSV or TSV. But I'm almost sure I'm overcomplicating and there's some simpler solution to that.
I have a codebase that mostly manipulates hashmaps, switching out the previous stdlib `HashMap` for the `hashbrown` implementation drops my memory usage from 2.1 GB to 640 MB.
Maybe I don't understand correctly - how is that different from lazy evaluation?
That's true, but in the example code, `self` is being captured.
The trademarks "Rust" and "Cargo" would be the primary concerns in such a situation, I believe.
Hey folks! I didn't post this here because it only mentions Rust a bit, and so I wasn't sure it was relevant. But uh, yeah!
Matt Kulundis, CppCon 2017.
&gt; Mozilla is a keystone in the open source software community and has been around for a very long time. So was Red Hat. :(
(Hopefully)
can you elaborate a bit about the pro/cons of push/pull based async handling? or point me to some ressources? It seems strange, that polling is used (performance wise) but I think more intelligent people have reasons I really would like to know.
&gt; What's the criteria for replacing the standard library data-structures? What happens if someone else comes up with a quicker hash map implementation in a couple of months? Is it going to swapped out again? "Better" implementations, for some definition of better, can be swapped at leisure as long as they support the stable public API of the collection. &gt; Also as far as I understand there are optimisations in HashBrown that could be applied to Robin Hood, like the new_drop optimisation, was that taken into consideration? I do not think anybody tried.
No, that was not proven, but nobody made that claim anyway. While pinned futures will primarily be written as `async fn`s, that's not because pinning is some sort of sacrifice made to support async/await. It's the other way around- async/await is designed to *enable* pinned futures, not *require* them. That is, we want pinned futures regardless, because they enable us to eliminate unnecessary `Arc`s and other annoying or slow patterns required under futures-0.1. Async/await just so happens to provide a nice, safe way to write them. Further, baking `Pin` into the interface shouldn't make hand-written futures significantly worse- they can implement the `Unpin` trait, which allows `Pin&lt;&amp;mut Self&gt;` to coerce to `&amp;mut Self`, putting them right back where they started.
That's not the same, though. Two totally different levels of scale and interdependence. 
It makes sense to me, seeing as a lot of people that have been on the core team have made comments about Rust's incredible growth, and how hard it is to keep up with every change, while that used to be easier.
Yes but... ... this closure captures `self` by value, thus it has an environment.
as long as zola gets dictated by very strange design decisions and taste of its main developers -- i.e. by rejecting all patches and user requests for non-TOML front matters -- it IMHO will not become an alternative to other real open and user friendly SSG solutions. :(
When I saw the cool work that CloudFlare was doing with Wasm workers, I started to have a very strong suspicion that Steve was joining CloudFlare.
&gt; *-sys crates provide idiomatic Rust interfaces for other Rust crates this is not true, See for example cargo book: &gt; The library crate should provide declarations for functions in libfoo, but not &gt; bindings or higher-level abstractions. The most `-sys` crates just rust definition of C functions.
Rust 2011 being under 0.1 LoC is really impressive. That should be roughly, what, 8 characters?
If a vuln is found I'm sure they will update the version, altough it would maintain compatibility.
People do all kind of things for enough money.
Congrats!
Thanks!
I admint that in terms of minimalism and orthogonality a HoF complement is more elegent. In usage it sucks, however. I base my judgement on my experience in using both Common Lisp and Clojure extensively. Idiomatic CL usage is using -not versions of sequence functions, idiomatic Clojure usage is using a complement of the predicate. In my opinion using complement is both more bothersome to write and harder to read as it expresses the idea less clearly. Consider: seq.exclude(test) vs seq.filter(comp(test)) The latter has one more level of indirection for the poor sap reading it, and also one more level of indirection for the compiler to remove. With the HoF you either get a closure at runtime, or the compiler needs to generate the negated version (which is not possible if the test is not statically known), or the compiler needs to understand what comp actually does and instead call __internal_hidder_from_users_exclude with test after eliding the comp. (Yes, obviously standard libraries need HoFs like complement, but this is IMO not the place to use them.)
I'm not sure I understand the question. Lazy evaluation is unrelated.
Aha! It was the callback change that I was missing - I'd originally tried the reference without \`&amp;mut\` but it immediately segfaulted the first time the callback was run. Now working beautifully, thank you so much!
Rust futures rely on an executor, which only polls futures that have registered interest in some resource. The effect is, in principle, exactly the same as a hand-written state machine, which is generally considered to be performance optimal. In particular, there is no dynamic dispatch or heap allocation involved.
&gt; Also, locales have gotten more expressive. Yeah. Some websites are using the lang tag `yue` for written Cantonese, though they might actually want to use `yue-hk` or even `yue-hant-hk` (I'm no expert on this so I might be misusing locale codes). In the past they'd probably just whack in zh-TW.
Hey guys! I'm new to rust, so i'm making blackjack as a beginner project. I believe that i'm starting to understand the borrowing system, but have stumbled across a case which has left me baffled. &amp;#x200B; Below is the function containing the code that I'll be focusing on fn hit(player_cards: &amp;mut Vec&lt;Card&gt;, deck: &amp;mut Deck) { println!("-----------------"); println!("PLAYER CARDS:"); player_cards.push(deck.deal_card()); for c in player_cards { stringify_card(c); } println!("sum: {}",card_value_sum(player_cards)); } In short: The function adds a new card to the player's hand. Both function arguments are mutable loans. Therefore, my imperfect intuition tells me that this code will work, but (spoiler alert) it doesn't. Here is the error message error[E0382]: borrow of moved value: `player_cards` --&gt; src/lib.rs:159:39 | 156 | for c in player_cards { | ------------ value moved here ... 159 | println!("sum: {}",card_value_sum(player_cards)); | ^^^^^^^^^^^^ value borrowed here after move | = note: move occurs because `player_cards` has type `&amp;mut std::vec::Vec&lt;Card&gt;`, which does not implement the `Copy` trait error: aborting due to previous error My first thought was that this was kind of weird since player\_cards holds a borrowed value, it doesn't have any ownership, how is it moved? And what is even more bizarre to me is how I fixed the issue. It turned out that by changing for c in player_cards { to this for c in &amp;*player_cards { then the compiler won't complain anymore?!?! What is happening here? Why does the little ***&amp;\**** tricks fix the issue? My head is exploding...
You have to macro_use macros from your crate. Just #[macro_use] mod schema;
AFAIK, IntelliJ + Rust plugin is currently the best dev experience. Quite resource hungry though.
Now filed as https://github.com/rust-lang/rust/issues/59732
You can't add built-in without editing VM and compiler, but you can use function from dynamic library: \`var f = $load("lib.so","func",2) \` and then call this function and builtins is the same as functions and objects, they just located in another "place". 
I'm not 100% sure, but isn't glib's `GResult` type also pull-based (the executor here being the glib event loop)?
I wrote a decoder for JazzLight VM bytecode in JazzLight: \[link\]([https://github.com/jazz-lang/JazzLight/blob/master/programs/decoder.jazz](https://github.com/jazz-lang/JazzLight/blob/master/programs/decoder.jazz)).
Well, yes, but that would result in a new release of the standard library. There's no other mechanism for an update to make it to users.
Thanks. That's really not explained well in any of the documentation sources I've seen. &amp;#x200B;
The likely subtags data will expand plain `yue` to `yue-Hant-HK` and `yue-CN` to `yue-Hans-CN`. All this should result in pretty good results, I think.
Is this going to be more frequent going forward? Having pieces of the std (or even the language) built and maintained as external libs and then imported when building the compiler? Is there a policy on when this is a good idea vs not?
Lazy eval with state, I guess. In the sense that somebody that wants the result "calls" (polls) to execute the future. If the future is actually completely pure computation, then it's lazy eval in the normal sense.
Now you mentioned it, that makes more sense to use web sockets for the real time events Perhaps the configuration, CRUD could be over Rest, but the actual events can be all Websockets?
The term "polling" tends to give the wrong impression of how things work- it made me think of something spinning in a loop, wasting work. So if that's your impression, suspend it while I try to describe the difference: Push-based async is maybe better described as "callback-based." If you're familiar with pre-`Promise` Javascript or Node.js, that's the underlying pattern. To await some operation, you pass it a callback to invoke on completion. Async functions can be desugared to this pattern by automatically passing callback that advances their underlying state machine. The downside here, especially in the context of Rust, is that the awaited operation now has to hold onto the state machine somehow. This means if you have a chain of async functions awaiting each other, each one gets allocated separately so the thing it's awaiting can hold onto it. That means you've got an actual graph of state machines all pointing at each other, so you probably need a garbage collector. It also means you can't really cancel anything without threading "cancellation tokens" everywhere, which only makes that graph more complicated. Poll-based async is a lot closer to threads or coroutines. That chain of async functions awaiting each other is grouped into a single "task," which is "spawned" onto an executor and marked as ready to run. The executor polls tasks that are ready to run by handing them a "waker" associated with the task as a whole. Each async function passes the single waker, which it got from its caller, through to the thing it's awaiting. Only when the waker reaches an external event (like a network socket read) does it get signaled, marking the task as ready to run again. This collapses the whole push-based pointer graph into a single task object- outer state machines contain inner state machines by value, and the whole thing is owned by the executor. External events still hold onto *something*, but it's just a waker instead of a callback in that graph. This also solves the cancellation problem, because you can just drop a whole task without worrying about someone trying to run a callback that depends on it. (I left out one detail above- when polling a task that is resuming in some deeply nested async function, how does it get from the outer state machine to the one that actually needs to run? In Rust, each one re-polls the one it's awaiting to quickly rebuild the call stack. Then the innermost state machine either hands the waker to the next external event, or completes and returns to its awaiter, and this repeats all the way back out to the executor.)
In particular, this collapses a whole pointer chain of... [innermost future] -&gt; [the future awaiting it] -&gt; [etc] ...into a single task where each future owns the ones it's awaiting: [outermost future [the future it's awaiting [etc]]] This simplifies memory management quite a bit, because external resources only need to hold onto "wakers" instead of whole futures. And *that* in turn simplifies task cancellation, because you can drop a whole task at once instead of threading some sort of "cancellation token" through and forcing each individual future to quit when it's signaled.
We're not dead yet! The IBM deal hasn't completed, and even then I'm staying cautiously optimistic...
Ah yes, I’m not sure how my brain turned `libstd` into `rustc`. Thank you for the correction. :)
In terms of real-time APIs, GraphQL and gRPC seem the most promising to me. However, neither have full-featured Rust implementations, as they seem to mainly focus on JavaScript. [Juniper](https://github.com/graphql-rust/juniper) is missing WebSockets and subscriptions, and the several gRPC libraries are very alpha (e.g. not even published on crates.io) and have little documentation. While REST is very well supported, it has a fair bit of overhead (not like this would use much bandwidth, but still) and would require an application to connect to both the real-time API and the REST one. It also doesn't allow making multiple actions in one request, meaning that a simple action of making a call could need multiple separate HTTP request for simple actions. It would also be confusing to receive events in a completely different schema from requests, instead of just replying to an event. ___ Now that I think about it (and actually basically what you suggest), what about MQTT? That's what Facebook uses server-side, so live events such from both the server (user presses a button) and client (play a sound) are sent there. A separate GraphQL API for management would be used, as MQTT doesn't really support queries unless every entry is stored in memory. This would still work with the current state of Rust libraries, as no subscription system is needed. I might take a crack at this later tonight, as this seems like it world work.
Cloud**f**lare. Steve already got told off by his new CEO once (and then proceeded to make the same mistake 3 more times in comments)... ;)
Congratulations!
Thanks!
You could write a higher-order function for this.
Hey fellow Rustaceans! I'm trying to learn rust by "Automatizing the boring stuff" in my PC, however I'm stuck on the very first task :(. I can't understand how the std::process::Command works with the 'ln' (symbolic link) use std::process::Command; fn main() { let origin = "~/path/to/origin_file.txt"; let target = "~/path/to/target.txt"; Command::new("ln") .args(&amp;["-s", "-f", origin, target) .spawn() .unwrap(); } The above gives me the error `ln: failed ... no such file ... '~/path/to/the/target.txt'` And if i pass the 2 arguments in a line like this: use std::process::Command; fn main() { let origin_target = "~/path/to/origin_file.txt ~/path/to/target.txt"; Command::new("ln") .args(&amp;["-s", "-f", origin_target]) .spawn() .unwrap(); } creates the `target.txt` just that it is in the directory of `cargo run` and the file contains nothing. Any help will be greatly appreciated :)
FWIW, I would be interested in using MesaLink on my Gentoo server as a full-fledged OpenSSL replacement, but I guess that stage of completeness is probably still a ways off.
I'm having a hard time coming up with a simple explanation for this behavior. But the gist of it is that any `for` loop of the form `for val in values` is a *consuming* iterator. That means it takes ownership of the contents of `values` and thereby prevents their use later. Now at this point you're probably thinking "but wait a second. my `player_cards` variable is a `&amp;mut Vec&lt;Card&gt;`, not something I own!" But the trick here is that references are *themselves* values. They're real types like any other, even though their main purpose is to refer to other values and language has special handling for them for that purpose. The error message you get even hints at this when it says `move occurs because `player_cards` has type `&amp;mut std::vec::Vec&lt;Card&gt;`, which does not implement the `Copy` trait`. `&amp;mut T` references aren't `Copy` because they're supposed to be unique: You can't have multiple active mutable references around at the same time, so being able to freely create active duplicates of them would be Bad News. So why did writing `for c in &amp;*player_cards` make things compile? That's because dereferencing and then re-referencing a reference type actually creates a *new* reference whose lifetime is shorter than its "parent" reference. The parent reference is also rendered inactive until any reborrows derived from it go out of scope, which is important for preserving the rule that you can't have any other *active* references to a value when an active `&amp;mut T` is in scope. I've made a simplified example to hopefully make it a bit more clear what's going on: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=79b2b3453b17766a021454b3515eca46
Mozilla is a foundation, they can't be bought. If things go severely south they may need to stop having paid employees and operate as an unpaid board managing a trademark and holding copyright, but it wouldn't mean the end of the foundation itself.
Steve Klabnik would bring together all the comrades to work together for our Rust and keep it thriving.
Which nobody is using yet
Hrm? When did that happen?
I know that running rustfmt was in the works. I haven't followed it closesly, but that it seems very likely that that is the cause.
Thank you very much for an awesome explanation!!
Well, they might not be bought, but they receive their lion's share of money from other companies like Google. It would be painful for them without this income.
Congrats Steve!
`~` is a shell expansion. You can use std::env::var_os("HOME") to get the env variable. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=5dcd2d0462f19115b2ae2ea162d24c7b
I don't have my HN accounts mixed up do I? https://news.ycombinator.com/item?id=19584045 (as for your comments, I just ctrl-fed `CloudFlare` on the hn post with match case set to true)
No problem. I also updated the example just now with some more accurate comments about what's going on.
Oh, he's the CTO, not the CEO. Whoops! And yeah, I'll get used to it, heh.
Hmm
Did we figure out await syntax?
Permissive licenses mean that a proprietary takeover of the codebase is possible but it would require two things: - new contributions under a new, proprietary license - basically a fork which can't be freely distributed and modified etc. - that fork must tempt enough people and businesses away from the free fork that it loses momentum. For an actual example, compare BSD to its propreitary derivatives NeXT &amp; OS X. BSD is doing well now and Apple has opened a lot of OS X back up, but things weren't so rosy 20 years ago. My gut feeling is that lock-down scenarios depend on someone introducing a hardware platform. Permissive licenses don't stop them from hoovering up free projects as building blocks for their walled garden. Once that happens, the vendor can also fork those projects into private derivatives and enforce their rules as they see fit. iOS and to a lesser extent Android are the most nameable examples, but nearly all "consumer electronics" play that game.
r/lostredditors
Would you care to explicit ?
This is a great explanation. I'm just a little sad that there didn't seem to be a better alternative to the futures::task::current(). Something that guaranteed API use correctness at compile time.
I'm not sure what you mean- `futures::task::current()` was replaced by a `waker` argument to `poll`, a long time ago. This helps with API use by preventing people from calling `poll` outside of a task, and by making it a bit more clear that they need to do something with it if they want to be polled again in the future.
Geez, now I feel like facepalming real hard haha
Haha! Awesome. I must be out of the loop. I was wondering why it wasn't that way. And now apparently it is! Sorry for the noise.
I like the TOML front-matter, and it fits with the Rust ecosystem. Are there other examples of 'strange design decisions'?
Man, this is really hard to read for me. Rust source code lines where!? On github? In rustc? There's years in color, but also on the x-axis. I don't understand what this means at all. Is this addition of newlines per month? Number of total lines? Do the number of LoC really go down sometimes? Again, terribly confused by this graph.
That's a separate related feature that will be stabilised after this piece.
I love Zola. Was wondering though, zola only seems to auto rebuild on changes to posts. Sometimes, when I'm playing with the design, it would've been helpful to auto reload on theme and config files as well. Would that make sense? Also, with the advent of the `prefer-color-scheme` media query in CSS (Firefox beta has it!!!), would it make sense to add CSS support for syntax highlighting instead of inlining the colors? I understand this is mostly handled by Syntect, but from a quick glance at their code, it looked like users of the library can handle their own styling, if they want to. Again, this is probably specific to my needs, but maybe it can become relevant for others as well when `prefer-color-scheme` starts seeing wider support. That's my only two things I can think of to improve. Ergonomics and features are great. Performance is superb. Keep up the good work!!
see: [https://github.com/getzola/zola/issues/189](https://github.com/getzola/zola/issues/189) [https://github.com/getzola/zola/issues/317](https://github.com/getzola/zola/issues/317) &amp;#x200B; i already wrote and proposed the necessary code for YAML support ([https://gitlab.com/mash-graz/gutenberg/commit/1c6b8addb8ac4497aa25639a6a542ee356cd971](https://gitlab.com/mash-graz/gutenberg/commit/1c6b8addb8ac4497aa25639a6a542ee356cd971)) months ago, but it wasn't accepted cause of the already mentioned dogmatic maintaining habits and ignorance in this project. it doesn't matter, if a feature like YAML front matter support would be very helpful or necessary for better compatibility and more seamless exchange with other software, as long as the core developer do not like it, all user requests and proposed patches will be simply ignored. that's an unacceptable practice which IMHO doesn't work very well in the context of open source software development. in the long run it renders otherwise nice software to more or less uninteresting private hobby projects... 
It shows the addition of (net new) lines of code over the course of the year - and then the gradual removal / re-write / re-touching of those lines over time. It's like source code half life or something.
Any chance we can get the same chart with the order of the layering reversed?
Generally, what's caught by clippy that isn't caught by cargo check?
The color is the year the code was written. For example, in 2019, half the code had been written in 2018.
&gt;It seems strange, that polling is used (performance wise) The key here is that it's not like a busy loop; the OS sends the poll when stuff is ready.
This is an interesting experience report. I didn't know that compilation speed is such a deal breaker to some people. So you'd say fast iteration over code is worth the traidoff of a few percent slower execution time while developing?
I currently have this code: let mut html = "&lt;html&gt;&lt;h1&gt;juniper_warp&lt;/h1&gt;&lt;div&gt;visit &lt;a href=\"/graphiql\"&gt;/graphiql&lt;/a&gt;".to_string(); for testu in results { html.push_str(&amp;format!("&lt;p&gt;{}&lt;/p&gt;", testu.name)); html.push_str(&amp;format!("&lt;p&gt;{}&lt;/p&gt;", testu.age)); } let homepage = warp::path::end().map(move || { let mut testx = html.clone() + "&lt;/html&gt;"; Response::builder() .header("content-type", "text/html") .body(testx) }); But its dirty as can be, I feel like, to concate the strings, and then not really understanding the (move) || closure, using a clone() to get it to compile... Noob question, but could someone lent me a hand cleaning this up? :)
Other languages have a built-in event loop.
`bstr 0.1.1` has them, along with some explanatory docs: https://docs.rs/bstr/0.1.1/bstr/#file-paths-and-os-strings
Stores entries in a way that's very easily SIMD-searchable https://blog.waffles.space/2018/12/07/deep-dive-into-hashbrown/
I added some helpers for this in `bstr 0.1.1`: https://docs.rs/bstr/0.1.1/bstr/#file-paths-and-os-strings --- Let me know what you think!
Kinda like how nobody flys in a plane before it’s done being built. Its not close to ready, ergo, people don’t use it. 
Great idea, love it!
Something like ``` use std::char; fn not&lt;T&gt;(f: impl Fn(T) -&gt; bool) -&gt; impl Fn(T) -&gt; bool { move |v| !f(v) } println!("{}, {}", (not(char::is_whitespace))(' '), (not(char::is_whitespace))('.'), ); ```
Well, what I can see from your links, is that - in 2017, u/Elession refused to allow front matter pages to be written in YAML, motivating his decision with specific arguments ; - in 2018, he changed his mind and clearly stated that if given a pull request about it, he'd take it. On the other hand, I couldn't find [any such](https://github.com/getzola/zola/pulls?utf8=%E2%9C%93&amp;q=is%3Apr+yaml) pull request that would have been rejected. If you've already written the code, then please go ahead and submit a pull request, I'm pretty sure it would be accepted.
Futures are almost never pure computations. They usually involve IO
Google, Microsoft, Apple or Amazon may close down, but Mozilla will live forever.
That's is very cool! Would you permit me to use that image on my blog website, for maybe like a favicon or as an icon elsewhere on my website? I would be happy giving you credit for it, either in the image's cation/alt text and/or on my website's about page where I list the tools and resources I use, if that is acceptable.
Cool project (compiler writing is one of my interests)! You may want to post this in /r/ProgrammingLanguages as you may get more interest there. I wish you the best on your compiler!
&gt; UnsafeCell requires that everyone who sees the data sees it behind UnsafeCell, period I don't think this is correct. For example, RefCell&lt;T&gt; contains an UnsafeCell&lt;T&gt;, and it uses that hand out &amp;mut T's to safe code.
Thanks for your encourage! I love system and algorithm, so compiler looks so interesting for me. And thanks for your advice, I would post there to get it a try.
Yes. And?
Usher is a great name for a routing library.
Hmm. Maybe I am doing this wrong. Is uploading a .gif a bad idea here?
Sure, I'd be honored!
i already linked the patches in my last post... and the maintainers of gutenberg/zola are well aware of this particular solution... i don't kow, if it's still compatible to more recent revisions of the software -- but that's simply the consequence of not merging community contributed code. nobody likes to maintain software in parallel to the upstream code just because of stubborn refusal reasons.
The simple solution is that has fewer allocations is deserialize to \`HashMap&lt;&amp;'str, Vec&lt;i32&gt;&gt;\`, then \`Vec::append\` onto the Storage. I was able to get something that works without any temporary allocations for Serde's FlattenedVec example. But I suspect I may have over complicated it. https://play.integer32.com/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=790ea8fc06d29d4276c1d376df7b8c6a
In the form of what is to be the Zeroth Freedom's biggest counterpoint yet: Fuchsia.
You can write a trivial [`lazy`](https://rust-lang-nursery.github.io/futures-api-docs/0.3.0-alpha.13/futures/future/fn.lazy.html) future where polling is roughly analogous to forcing a lazily evaluated value, yeah, but it's not a very interesting case. The magic of futures is in composite futures knowing what to poll for progress, and in leaf futures registering with reactors and similar for notification of I/O readiness.
Brief googling didn't turn up any mention of such a type.
&gt; i already linked the patches in my last post... No, you posted a link to code that you wrote, but never submitted. The first issue you mentioned might have been closed abruptly, but hey, it's been *2 years*, and maybe it was closed in a bad day, who knows ? You've written some code that could become a valuable addition many people, so please let go of your bad feelings and submit it, alright ?
The underlying library for syntax highlighting is a bit annoying to work with at the moment. I had to hack it in a really annoying way to do something as simple as line counts. 
It's not directly a `pub use`, rather: use hashbrown::hash_map as base; pub struct HashMap&lt;K, V, S = RandomState&gt; { base: base::HashMap&lt;K, V, S&gt;, } I think it needs to be this way to avoid changing the default `S`, as `hashbrown` defaults to using `FxHasher`.
Have a look at https://rust-lang.github.io/rust-clippy/ – we list all the clippy lints there.
Congrats on finding somewhere new. 
Thanks!
Congrats! Build some cool things there with smart people :)
Mozilla is a no-profit though.
Never knew Blender's story was so crazy.
The tests are mindbogglingly slow to build, all the non x86 architectures are done with qemu
none of that changes my position though? perhaps I failed to see your point.
No, I'm just offering the reason why the test suite isn't a silver bullet against it. It makes it quite an expensive operation to run the tests, so doubling the number that need to be done after review isn't ideal.
Your first code snippet contains a typo: fn add(&amp;mut self, T value) -&gt; Idx { .. }
Does no heap mean we can use futures in no_std environments? 
Yes, this is one of the exciting possibilities Rust futures allow. You might need an executor designed specifically for embedded use, but that's straightforward to do as a library.
&gt;No, you posted a link to code that you wrote, but never submitted. come on! -- it's a publicly available git repository resp. commit! that should be enough to get/merge the code without much hassle -- there is no need that everybody uses/prefers oinly the services of one monopolist. 
Template engines are usually used for this type of thing, like [tera](https://tera.netlify.com/). If you're not doing very much templating it may not be worth the trouble. `move` closures move their captured variables rather than referencing them, so you can do `html.push_str("&lt;/html&gt;");`, though you could also move that operation before the closure. You could combine the format calls. let mut html = "&lt;html&gt;&lt;h1&gt;juniper_warp&lt;/h1&gt;&lt;div&gt;visit &lt;a href=\"/graphiql\"&gt;/graphiql&lt;/a&gt;".to_string(); for testu in results { html.push_str(&amp;format!("&lt;p&gt;{}&lt;/p&gt;&lt;p&gt;{}&lt;/p&gt;", testu.name, testu.age)); } html.push_str("&lt;/html&gt;"); Other than those small things the code seems fine to me. 
`cargo check` isn't all that special, it's just a faster `cargo build` because it stops after typechecking so you don't have to wait for LLVM to produce machine code that you're probably not ready to use yet.
In my opinion it's a shame that we do not encode the following requirement using type system: &gt;Once a future has finished, clients should not poll it again. Well, it's possible if `poll` would take a full ownership over feature and `Poll::Pending` would contain unfinished feature. But it will be probably really inconvenient and hard on compiler (it'll have to eliminate a lot of moves). And it's unclear how it can be integrated with `Pin`. Do you know if such approaches were explored earlier?
Is there an article which explains how executor handles `Waker` in terms of `epoll`/event loop? Also I am still don't quite get how we can mix asynchronous events from different sources in one application, for example: network, GUI, GPU, etc. Will it be 3 different executors which will pass futures to one another?
Can you make the static arena in the macro? In my head I have an image of a macro `arena!(arena: Arena[T; u__]);` that expands to something along the lines of `static arena: Arena&lt;T, u__&gt; = Arena::new(); struct Idx(u__);`, and the Idx then can deref to the static from the same macro. I'm constantly scared about macros introducing "secret" names though because if the macro is invoked twice in the same scope, what happens? The draft below avoids that by putting it in a expr context block. Draft: { struct Idx($u); static ARENA: Arena&lt;$T, Idx&gt; = Arena::new(); impl Deref for Idx { fn deref(&amp;self) { ARENA[self] } } &amp;ARENA } This only works if `Arena` is internally mutable, the static solution can't work and give out a `&amp;mut` because it's always legal to say `for _ in 0..10 { thread::spawn(calls_that_macro); }`. I'm not sure and am spitballing while needing sleep so I'm not really sure how coherent this idea is anyway /shrug
ZST allocations are hard to get right, and it's easy to just refuse to do them. There's at least one person arguing towards making `HashMap&lt;K, V&gt; where size_of::&lt;(K, V)&gt;() == 0` a panic because of this issue.
Yeah it makes sense to panic! for zero sized types. But maybe it's okay for zero length array? I'm pretty not sure...
u mad bro?
You can use `macro_use` as others have suggested but a much cleaner way to do it in 2018 is just import the macro as you would any other function. https://docs.rs/clap/2.32.0/clap/macro.app_from_crate.html For the most part I find this is definitely prefer, the only time that's not the case is if the macro uses other macros. For example claps `app_from_crate` uses many other macros and because of how macros work, they must all be in scope. You can get around this without macro_use with `import *`, but whether that's better idk. https://docs.rs/clap/2.32.0/clap/macro.app_from_crate.html
I've written a lot of docs. I don't use anything special. Most docs I write use the `///` variant. The only time I use the `/*! ... */` variant is for documenting a module where it's defined (instead of where it's declared), and also, of course, when documenting the top-level portion of a crate. As for what to write... I generally try to follow the conventions in the standard library. Start with the clearest most succinct version of what the function does---maybe a sentence or two at the most. Then dive into details, if necessary. Then divide the rest of the docs into sections via headings, where appropriate. e.g., `# Safety`, `# Panics` and `# Examples`. Examples are super important and I strongly encourage you to _strive_ to include an example with most or all public API items. The `///` might bother you now, but trust me, it disappears pretty quickly once you get used to it.
Use [`include_bytes!(..)`](https://doc.rust-lang.org/std/macro.include_bytes.html) macro. It will produce a static bytes array with data from the given file.
Congrats on the awesome move. I'm always very impressed by the technical blog posts they publish, sounds like a great shop. 
The possibility of Mozilla being dissolved is dramatically higher than any of those scenarios. It's not only decidedly possible, but in the medium term it's probably even likely. Mozilla's funding model is and is likely to remain largely undiversified and largely dependent on money from Google. Are they going to fold tomorrow? Probably not. Is this a risk over the lifetime of your average serious project? Absolutely. 
``` impl&lt;'a, T&gt; Bar&lt;'a, T&gt; { ... stuff we haven't read yet ... } ``` Are `'a` and `T` used above. We don't know until we read more. ``` impl Bar&lt;'_, _&gt; { ... stuff we haven't read yet ... } ``` Are `'_` and `_` used above? We have only read the first line and we know the answer is no. In my opinion being able to convey more information in the first line, while also removing some clutter (the variables `a` and `T` being meaningless, I consider them clutter) would help readability.
Great post with tons of good info! One thing that occurred to me while reading is, there's a lot of effort to make this generic and apply easily in all places, but if you're trying to take advantage of a smaller-than-pointer-size int because you know the collection will be smaller than u32 (or u16, or u8), you're probably in a position to just write an arena geared for your program. Perhaps it would be more fruitful to create tools that facilitate custom arenas, instead of one that works everywhere. Probably out of my depth, but just a thought. 
But that `&amp;mut T` was derived from the `UnsafeCell`. But in your original question, you've got a `&amp;mut T` which didn't have an `UnsafeCell` in its provenance; it's totally different. Let's put it another way: (a) how did you get the `&amp;mut T`, and (b) what are you going to do with the `UnsafeCell`? The answers are inevitably (a) someone up your call stack has ownership to a certain `T` but (b) someone else is going to mutate the `T` without having a chain of mut borrows back to the original owner. That's theft: the owner didn't authorize it with `UnsafeCell`. *Mayyyyyybe* if (b) only happens down-callstack from you, it's okay, but *definitely* if (b) happens outside of the lifetime of *your* `&amp;mut T` it's UB. I mean, all of this is grandstanding and speculation unless and until the unsafe WG specifies it... *CmonDoSomething.jpg*
That honestly doesn't really seem useful to me at all, and it would be a shame to introduce yet another thing that I need to resolve in my brain when looking at type parameters. Notable, the distinction between ``_` and `_` is _really_ easy to miss. Type parameters aren't things we should be trying to hide, except in circumstances where a default type parameter makes sense. Otherwise, picking `T` or `A` as a type parameter isn't a burden at all.
Thanks. Will this run on a machine with just the binary?
Mozilla's mission is free web, not prosperous Rust. It is at least conceivable for Mozilla to decide that Oracle is the best (the least bad, anyway) for free web. Remember, Mozilla supported DRM using a similar logic.
This doesn’t work with diesel last I knew. Their stuff is so nested. 
Not like this. You can tell without even knowing what's in the downcast_rs crate because in your code the variable `foo` is not well-typed.
Yes, the resource file will be included directly into binary as part of [data segment](https://en.wikipedia.org/wiki/Data_segment).
`include_bytes!` will merge the contents of the specified file into the binary at compile time as if you'd written its contents into your source code as a bytestring literal. There may be other things that need to be addressed to get something running on another machine (eg. building against a suitably old version of glibc if you're building for Linux), but something merged into the file using `include_bytes!` won't be what prevents it.
Are you sure the working directory is what you think it is? IIRC if you use `cargo run` the working directory is the crate root, where your `Cargo.toml` is, but when you run the binary directly it's the binary's location in one of the `target` directories.
Bad bot.
You’re looking for /r/playrust . This subreddit is about the rust programming language. 
Yeah I’m sure. If I’m in the src directory and I run cargo run I’ll throw an error
Thank you! I think I understand now.
Yeah I’m sure. If I’m in the src directory and I run cargo run I’ll throw an error
The responsibility for those doesn't belong to the executor, instead they are just "sources of events" that hold a waker and wake the executor when things are ready. The source of IO events built on top of epoll is usually called a "reactor," whereas other sorces of events like timers and so on can also exist. They all just interact with the executor managing this future by waking the waker they received.
they probably just *will* implement the unpin trait, without doing anything, because its an auto trait.
Can I ask why this is the case? Seems like ZST allocations and de-allocations can just all be no-ops?
rustfmt has nothing to do with tests? Apart from tests are code?
It's just "rustlang", and the cpu gets it. 
You probably don't want to stub out templates, because that would defeat thing like the `missing_docs` lint that makes it easy to find the things you need to write documentation for. When writing documentation, I like to use a tool like [livereload](https://pypi.org/project/livereload/) so my browser will automatically reload the docs when `cargo doc` rebuilds them. The [Documentation section of the API guidelines](https://rust-lang-nursery.github.io/api-guidelines/documentation.html) suggests the sections you might want to add for each thing you document. It'd be nice if there were an easier way to link to documentation items than manually hard-coding the paths that rustdoc generates, but Markdown won over reStructuredText, so there's not much hope there.
Yay! It may not have everything that would be nice like faliable collections or being able to select an allocator on a per-instance basis, but it's more than enough as-is to provide no_std heap allocation.
You don't upload images to Reddit; you upload them somewhere else (e.g. imgur) and then link to them here.
Oh! Thanks, isHavvy. I have never tried posting images here. I have edited the post to add a link to the work on Lospec.
Yes, you can. This is one benefit of the new `Pin` API. Some futures hold no references to their local state, and those can be moved around freely and used in pretty much any context. Futures that do hold such references can still be used without a `Box` and thus without the heap, but you will need to find another way to pin them to a memory location.
Looks like you're correct, macros are not exported from diesel in a way that would let you import them 2018 style. Adding a `pub` to `mod macros` would do it I think. https://github.com/diesel-rs/diesel/blob/master/diesel/src/lib.rs
&gt; the distinction between `'_` and `_` is really easy to miss I guess, although note that `impl&lt;'a, a&gt; Foo&lt;'a, a&gt; {}` is already valid Rust code, so it seems we've already made the decided that noticing that little tick mark `'` is important. Would you feel differently if all the same `&lt;...&gt;`'s were required. How would you feel about allowing `impl&lt;'_, _&gt; Foo&lt;'_, _&gt; {}`? The only difference here is that `_` would be a different variable than `a`, but `_` has the advantage of signalling that the variable is never used.
These are also coming! (Eventually...) * https://github.com/rust-lang/rust/issues/48043 * https://github.com/rust-lang/rust/issues/42774
That is not what makes Rust's approach unique. C++ has futures and no built-in event loop as well, after all. The novel thing about Rust futures is how they leverage static polymorphism to generate efficient stackless state machines, and decouple executors from reactors with the waker paradigm.
Thanks, will fix soon.
For the macro name hygiene, the uuid crate is my friend. I add an UUID to each unique identifier.
With futures, alloc and hashbrown based hashmaps stabilizing, 1.35 is shaping up to be one heck of a release.
You're right. Needing a static mut, though not uncommon in embedded code, could be construed as a code smell. In any event, the current solution won't need a static.
This is a stackoverflow page related to your last concern: https://stackoverflow.com/questions/50345139/why-can-i-return-a-reference-to-a-local-literal-but-not-a-variable (the question was asked by me).
You will need to either install Visual Studio 2017 community edition, or just the MSVC build tools: [https://visualstudio.microsoft.com/downloads/#build-tools-for-visual-studio-2017](https://visualstudio.microsoft.com/downloads/#build-tools-for-visual-studio-2017) &amp;#x200B; I thought the VS2017 build tools were also on that page but it only shows 2019. &amp;#x200B; If you go the Visual Studio 2017 route, select the \`Desktop development with C++\` workload in the installer and you should be all set.
Great thanks! 
When you poll a rust-future, it may respond with a result, or it may respond that the result is not ready yet. Therefore you have to keep polling until the result is ready. Standard lazy evaluation blocks the thread and performs the entire calculation, when it is called the first time. 
In vim, using [`rust.vim`](https://github.com/rust-lang/rust.vim), you end up with `set formatoptions=croqnlj` and an appropriate text width (100 is the rustfmt standard I believe). I don't know about VSCode or IntelliJ although there might be a neovim-backed editor plugin these days, but if you could find equivalent options, this set is sufficient for handling long sequences of `///` very comfortably. You get: letter meaning when present in 'formatoptions' ~ c Auto-wrap comments using textwidth, inserting the current comment leader automatically. r Automatically insert the current comment leader after hitting &lt;Enter&gt; in Insert mode. o Automatically insert the current comment leader after hitting 'o' or 'O' in Normal mode. q Allow formatting of comments with "gq". Note that formatting will not change blank lines or lines containing only the comment leader. A new paragraph starts after such a line, or when the comment leader changes. n When formatting text, recognize numbered lists. This actually uses the 'formatlistpat' option, thus any kind of list can be used. The indent of the text after the number is used for the next line. The default is to find a number, optionally followed by '.', ':', ')', ']' or '}'. Note that 'autoindent' must be set too. Doesn't work well together with "2". Example: &gt; 1. the first item wraps 2. the second item l Long lines are not broken in insert mode: When a line was longer than 'textwidth' when the insert command started, Vim does not automatically format it. j Where it makes sense, remove a comment leader when joining lines. For example, joining: int i; // the index ~ // in the list ~ Becomes: int i; // the index in the list ~ 
&gt; how does Rust prevent mixing up responses to clients Every language prevent it as long as the programmers code properly and add error handling. You've to do that in Rust too. Sorry, but your question itself is a bit wrong. Rust is not a wsywig editor where you worry about modules not working, it's a language where you code your logic. If you want the responses to not mix, then you can handle the errors easily. As for advantage of Rust in the context, the only thing I can write is that it will be harder to exploit certain vulnerabilities by attackers. It will be easier to allocate memory without collusions. I hope this answers the question. Btw, when your client sends a request, you can give a unique key to each one to handle this type of problem. If you use a rdbms, it becomes simpler to manage. This problem is not related to any language. It's more of a logical problem.
If its a threaded server like Rocket then its one thread per client, so you don't really think about it, you just read and write. If its an async server like actix-web, then its some kind of event driven programming thats implemented with dark magic, probably from https://tokio.rs/
Are you talking about HTTP requests? In that case, it's really simple - HTTP in its most basic form is a request-response protocol. That is, you send one request, and you get back one response, then you send another request, and so on. So assuming you have one connection, the client can't actually mix up requests and responses, because each response immediately follows its matching request. Also, this isn't really a Rust question, but an HTTP question.
It is already common from before, this isn't a new occurrence.
No, I understand the HTTP part, it is Rust interacting with an API that is not on it's server. The client is not connected to that API, right? Rust is acting as a proxy. How does rust remember or know to send the response it gets from that API server back to the client?
One thread per client? That sounds like PHP...
Thats Rocket.rs. Its fast though, and can handle plenty of load, you just can't use it for websockets because you'd run out of threads.
That depends on how your Rust program handles connections then. You could write it so that you have one upstream connection per client, and then just store that connection somewhere in the request handler. You could use a connection pool so you don't have to reopen a connection each time, but still get a connection that's exclusively available to one client at a time. You could have a shared connection with a request queue and a separate thread sending those requests to the upstream and then sending the responses back to the client - if you go this route, you'll have to track some sort of request to client mapping so you know where to send the response. 
Wonderful 
You can have a thread and just call "read" and "write" on it, linux will return you a file descriptor that binds a number to a particular connection, and you do your operations through that number [http://man7.org/linux/man-pages/man2/socket.2.html](http://man7.org/linux/man-pages/man2/socket.2.html) , and you're never confused because a thread deals with a single user, and you can do all your 3rd party calls on that thread dedicated to that user. Or you can use an async engine, like epoll on linux [https://medium.com/@copyconstruct/the-method-to-epolls-madness-d9d2d6378642](https://medium.com/@copyconstruct/the-method-to-epolls-madness-d9d2d6378642) , with that your applications will have a bunch of connections, thus a bunch of numbers, and it will check the kernel from time to time to know which numbers have data available, and you will have functions registered in your async framework to be called when data is available on particular connections, and your async framework will make it so that you also have a context available, identifying what user you are dealing with. That works (either through the use of Futures [https://docs.rs/futures/0.1.26/futures/](https://docs.rs/futures/0.1.26/futures/) or the soon to be async/await syntax [https://github.com/rust-lang/rfcs/blob/master/text/2394-async\_await.md](https://github.com/rust-lang/rfcs/blob/master/text/2394-async_await.md) Your particular network/server framework/library will make it simple for you though, that's why they're there. They will also make it cross platform (because the details change by operating system). All that stuff is not rust specific though, it works kinda similarly for all languages (os specific though). &amp;#x200B;
Look fam, I go to a restaurant, I sit down at a table, the table has a number on it. Someone comes to take my order (request), they go to the kitchen or counter(server), they put up my order, that order has my table number(IP Address), this way whoever brings my food knows where to bring it. The cook(Web App) looks at the order, makes (processes) the food (response), makes someone know the order it is ready, someone brings my food I eat and I am happy (request made it fine and dandy). That is easy... until we require a third-party. So with the third party, the cook gets my order, but realises that someone needs to go get fresh tomatoes from the garden (API Server). The cook orders Mr Garden (API) to go get tomatoes. The cook is busy making processing other orders that may or may not require Mr Garden. Eventually the cook looks over and there are tomatoes that where picked up from the garden on a table and PRESUMES they are for my order. Do you see why this would not be ideal in web dev?
&gt;!that's an unacceptable practice which IMHO doesn't work very well in the context of open source software development. in the long run it renders otherwise nice software to more or less uninteresting private hobby projects... This ia the kind of entitled behaviour that drives developers away from doing “open source” at all. Bluntly, the author owes you *nothing*. The project is not a business and no transaction has been made between you, it doesn’t have to adhere to any professional standards or your personal notions of what open source means at all. Saying it is “unacceptable” that the developer doesn’t merge your patch is ludicrous. If they don’t want it they don’t want it. 
Wait, so Rust does not do all of that out of the box? Because I was thinking one could write the app which would connect to an API like Shopify and have the app pull what is requested based on the request query string (e.g next 10 clothing items) from the Shopify store. I was wondering if Rust had a built-in way to accurately link the response(s) it gets from the API server back to the clients (who are not interacting directly with Shopify and it's API). So just to be clear, is it COMPLETELY up to the developer to accurately determine how third party responses are sent back to the original clients through the Rust web app?
It is as out of the box as any other language out there. They all do the same thing.
Basically, I was wondering about the response(s) from the API side (how they don't get mixed up because the client is not connected to the API). I was under the assumption that Rust had some things behind the scenes to prevent the mix ups, so if I read correctly, this is entirely up to the developer to determine?
Basically, I was wondering about the response(s) from the API side (how they don't get mixed up because the client is not connected to the API). I was under the assumption that Rust had some things behind the scenes to prevent the mix ups, so if I read correctly, this is entirely up to the developer to determine?
When I've been thinking about these things I've never been very concerned about the scenario of using an index with the wrong arena. It just doesn't seem very likely bug to happen. But I did add custom index types to the stash crate so that I can use my own index types. Which of course can be smaller than usize. So for example if I have two stashes, 'Stash&lt;Car, CarId&gt;' and 'Stash&lt;Truck, TruckId&gt;' there is no chance to use an index in the wrong stash. I would have to have two stashes with the same index type. Unlikely to happen often. And also important here is the improved readability/understandability of the code when using custom indices. The bigger risk I think is about bugs for slots getting reused. The stash crate has a uniqueStash type with generation stored in the indices to detect the problem at runtime. But it uses two usize for every index and recently I've been thinking if it could make sense to have a macro for having custom index types also here. They could maybe have custom number of bits for the generation and remaining bits for the offset.
So did the fuchsia guys reach out to you? Did you consider it?
&gt; I guess, although note that `impl&lt;'a, a&gt; Foo&lt;'a, a&gt; {}` is already valid Rust code, so it seems we've already made the decided that noticing that little tick mark ' is important. This is a form of argument I'm really not a fan of, and I don't accept it. In the five years I've been writing and reading Rust code, I've never once seen this. The convention is good enough, and the "possibility" of this happening does not negate my point. I don't think you're going to win me over on this. Let's stop being cute. The purported advantages on reading code with this syntax are effectively not existent in my opinion. That I know a type parameter is unused just isn't particularly useful knowledge to me. Note also that this feature was proposed seemingly as a benefit for *writing* code. IMO, changes like this just add to the churn of the language and we need to settle down. Even if you could convince me that this has some kind of tiny readability advantage in some cases, I'm still not going to agree with adding it because the juice isn't worth the squeeze. Just write the damn type parameter.
Exactly what I need! I was looking for a callgrind+kcachegrind equivalent for OS X. Is there any way to get the source mapping to work?
Right, you're completely responsible for the programs you write. There's nothing intrinsic to the Rust language that will prevent you from mixing up client responses if you write software that has bugs in it. There are certain features of Rust that will help you avoid writing software with bugs in it *in general*, though. Rust has a [static type system](https://stackoverflow.com/a/1517670), which eliminates bugs that you might find in Python or JavaScript where a value with an unexpected type gets passed to a function and causes unexpected behavior. Rust also has a unique [ownership system](https://doc.rust-lang.org/book/ch04-01-what-is-ownership.html) which eliminates memory access bugs like the one that caused [heartbleed](https://en.wikipedia.org/wiki/Heartbleed) in 2014. Also, if you use a library or framework like rocket or actix, it's more up to the developers of that library to prevent bugs than it is up to you. One of the advantages of open-source software is that if all of your dependencies are publicly available to view and used by a large number of people, there's a greater chance that bugs in them get discovered and fixed.
Does doing this increase the memory consumption of the application throughout the entire execution? Or is pulled out of the binary and into RAM as required?
&gt; Sometimes, when I'm playing with the design of my site, it would be helpful to auto reload on theme and config files as well. Would that make sense? It should already auto-reload on config change IIRC but I haven't tested that in ages... I'll have a look. Not sure about the theme autoreload as themes are not really meant to be edited directly. If you want to edit a theme you can override templates it in your own `templates` directory where the auto-reload will pick up the changes.
I use unchecked indexing, so I need to trust the indices.
&gt; that's an unacceptable practice which IMHO doesn't work very well in the context of open source software development. Where is the line drawn? Should every single PR be accepted because another SSG does something a specific way? &gt; ignorance in this project Nice, thanks. Feel free to fork it and turn it into an enlightened project :)
Cool suggestion, not gonna need it much right now, but will soon. It looks nice! @tera Thanks for the explanation and the bit of cleaning. :)
You want to run `rustfmt` without testing? It *has* caused code breakage in the past. `cargo check` *might* be enough however.
I would imagine it uses the date extracted from `git blame` — i.e. at any point in time, it creates a histogram of the last time any line of code was touched.
Another option may be [rust-embed](https://github.com/pyros2097/rust-embed). I have not used it yet, but I've bookmarked it for potential future use, and it looks like it may be a convenient solution.
If you can live with 64-bit keys (or 'indices'), an arena is just a poor man's [slotmap](https://github.com/orlp/slotmap). A `slotmap` is very convenient to use, actually allows you to safely re-use your memory (in an arena you might get spurious references), and it supports [key types](https://docs.rs/slotmap/0.3.0/slotmap/macro.new_key_type.html) which is the same solution as presented in the article, preventing you from mixing up keys into different slotmaps.
I think you mean 1.36? As I understand it from reading both this issue and the one for hashbrown, these will merge after 1.35 merges to beta. 
&gt;Where is the line drawn? Should every single PR be accepted because another SSG does something a specific way? some very basic compatibility issues should be seen as rather important for many users -- i.e. many typical webinterfaces markdown files in git repositories are not able to render TOML front matters but work fine with YAML (o.k. -- GitLab got TOML front matter support recently). But the particular example should be overrated. it's just illustrating some very realistic shortcomings. &gt;Feel free to fork it and turn it into an enlightened project well, i just lost my interest in gutenberg/zola and use other software again after watching this troubles for a while. why should i use some software any longer, which doesn't welcome contributions and active feedback from the user community? but at least i want to share this experiences with other people, because it could be helpful for others as well to avoid frustrating practical limitations.
Thanks for your work on this. I look forward to learning more about it. Can you discuss more about when Usher would be a better alternative than traditional approaches to routing? Is it mainly suited for use with APIs? 
Thanks for answering my questions. (And sorry for missing the part of the `basic_search.rs` example with searching on more than one field. I had checked that example before posting my questions, but I apparently skimmed over it far too quickly.)
That looks neat! You should file a RFC and see if it gets accepted, here's the link: https://github.com/rust-lang/rfcs/pulls
wrong rust bro
hadn't thought about using pub sub, but that's an interesting angle! If you do any experiments I'd be very interested in how it goes!
*OwO, what's this? * It's your **3rd Cakeday** Tm1337! ^(hug)
The current version doesn't use a procedural macro yet, so macro_rules hygiene already does the trick.
I would note that the particular issue mentioned for `HashMap` is that a `HashMap` with a ZST key can contain no more than 1 element, as there is only a single value possible for the key. I would still argue it's potentially useful in generic code, but it's certainly a degenerate case.
Connections aren't just thrown into a random pool. What you're really asking about is concurrency and how TCP/IP works. So in your example: `client &lt;-&gt; server &lt;-&gt; third-party`, here's what might actually happen in a web server ___ ... *I'm skipping initial connection/request* `server` knows `client` by it's socket: socket A. `server` knows `socket A needs something from third-party`. `server` connects to `third-party` at socket B and sends a request. While `server` waits for a response on socket B, it can do things for other clients (thanks to concurrency). When `server` gets a response from `third party` on socket B, it will go back to where it left off and send a response to `client` at socket A. ___ ^(This misses a lot of nuance. If you want to learn more you can research this yourself.) So how does Rust prevent web response mix-ups? It doesn't. No language does. Libraries, frameworks, and engines *probably* do that for you in most cases. As for concurrency, Rust uses system threads and Futures - which aren't stabilized yet.
This would be a lot more convincing if Rust hadn't been adding features all over the place with every minor version, instead of correcting some of the fundamental mistakes before it was too late. Your strangeness budget is not disappearing due to run-of -he-mill baseline features like ADTs or proper generics. I'd say large parts of your strangeness budget have disappeared into: - broken `Eq`/`PartialEq` - broken `Ord`/`PartialOrd` - special hacks for arrays/slices - generics with `&lt;&gt;` (only had 3 decades of knowing that doesn't work out, but hey) - needing macros to emulate varargs (and not even being very good at it, just look at `println!`, `format!` and friends) - missing tail calls - capricious special syntax around unit and bottom types All stuff that is strange, annoying, doesn't have any purpose, but we'll be stuck with it forever.
nice
The milestone assigned to this one on github is 1.35, so I drew my conclusions from there, could be wrong though
So, I googled for "Fuchsia Rust"... [https://i.imgur.com/CEAudZT.png](https://i.imgur.com/CEAudZT.png) :)
&gt; that will replace macros based combinators with functions Oh wow, I'm actually irrationally excited to hear that! This is actually the reason I've been using `combine` more than `nom` (both wonderful libraries) because the heavy use of macros wasn't fantastic for tooling and readability of errors. Very happy to hear that!
This is a relief. I think I should learn more about sockets.
A special keyword from the days of the compiler being written in OCaml...
There is hope, in fact, it works on nightly today ;) Well, for some definition of works, there’s still a lot of bugs, which is why it hasn’t stabilized.
Cross Platform? are android and ios in it?
I'm following the [rustwasm.github.io/docs/book/](https://rustwasm.github.io/docs/book/) tutorial, but don't know how to use wasm without npm. What is necessary for this to work using anything other than npm? I can't simply use the built .wasm and .js and add that to html.
Wait it was written in OCaml? What language is that? 
You're welcome! 
Is there a tracking issue or something I can subscribe to?
If I need to control the lifetime of something that gives a `&amp;str`, is it worth to use a `T` with bound T : 'static + AsRef&lt;str&gt; + Clone instead of just `String`, to offer the possibility to use directly things like `&amp;'static str` or `Cow`?
will you still write Rust code as part of this job?
My job isn’t to write code, so in some sense, no. Cloudflare uses Rust, and is using it more and more, though.
https://github.com/rust-lang/rust/issues/43466
Yes, it was written in OCaml: https://github.com/rust-lang/rust/tree/ef75860a0a72f79f97216f8aaa5b388d98da6480/src/boot. Google around if you want to learn about OCaml.
thanks for your answer!
thank you for your answer!
&gt; ~ is a shell expansion. I knew that on a theoretical level, but I would never have thought that this wouldn't work in some library. Thank you.
Intel x86 really needs to stop adding new features ...
I didn't thought of that part, but yeah...
nom is a great library and I'd love to help out. I will look into whether this is something I can help out with later this weekend!
Usually this is done through something like [dontenv](https://crates.io/crates/dotenv). The idea is to pass the configuration options through environment variables. In Linux with systemd, you would start your application through a `.service` which would setup all needed variables inside: [Service] Environment="SECRET=pGNqduRFkB4K9C2vijOmUDa2kPtUhArN" Environment="ANOTHER_SECRET=JP8YLOc2bsNlrGuD6LVTq7L36obpjzxd"
So, while in development it would read the values from a .env file and when run as a service, it would fetch the values associated to that service?
yep
That's perfect. Thanks!
[wepoll](https://github.com/piscisaureus/wepoll) is an implementation of the epoll API for Windows. For [Inko](https://inko-lang.org/) I am adding support for non-blocking IO, but for various reasons (that I'll hopefully write a bit more about in the near future) MIO doesn't cut it. This meant I had to write bindings for epoll and kqueue myself, which is not too hard. Unfortunately, I'm not familiar with Windows at all. I ran into wepoll when digging through the MIO issue tracker, and it seemed perfect. I ended up writing two bindings for it: * https://crates.io/crates/wepoll-sys (raw bindings) * https://crates.io/crates/wepoll-binding (safe bindings) I informed the MIO developers about this in https://github.com/carllerche/mio/issues/880#issuecomment-480443425, seeing as they might be interested in these bindings.
This is the subreddit for the Rust programming language. You're looking for /r/playrust
This is the subreddit for the Rust programming language. You're looking for /r/playrust
Looks interesting. Do you have any long term goals for it?
Use something like [directories](https://crates.io/crates/directories) to look up the appropriate config file location(s).
I don't think it's accurate to say that dotenv is the usual choice for configuration. It's pretty idiosyncratic, in fact.
Thanks, I feel kinda dumb lmao 
And shortly after publishing it, @pcpthm found a soundness hole. Expect a fixed 0.2.1 version soon.
I prefer to use clap/structopt and specify an environment variable name also, that way it's easy to use on the shell and as service.
I didn't know Linkered before this article. Super easy to use and helpful! 
Raph, I always enjoy reading your posts. Thank you for writing.
Awesome. I have an existing project that needs porting!
They were not, for precisely those reasons. It's simply not worth it- we have the same unenforced requirement with iterators and it doesn't cause any problems there either.
Yeah, we're not going to agree on this, but I bet we can agree the lang team has a hard job. :) However they decided on something like this wont change they fact they've done a good job. Maybe a happy middle ground is something like `impl&lt;'_a, _A&gt; Foo&lt;'_a, _A&gt; {}` or `impl&lt;'_unused, _Unused&gt; Foo&lt;'_unused, _Unused&gt; {}`.
This is such a cool graph! Thanks!
I will try to give a hand if i find some time. Thank you for your work. Nom is a great project. 
This seems like it could cause issues and I’m not sure how good of an idea it is in practice. Imagine a client serializing a struct with version 0.1 of a library, and a server deserializing using 0.2. If the value returned by the ‘Default’ impl changes between versions, then deserialization will produce wrong values. 
Dotenv is great, as mentioned above, but using envy is also great (search for the name on crates.io). It allows you to declare a struct with the environment variables you need. It doesn’t care about how they got to the environment, but only that they are there. It uses serde, so it has all the same flexibility you would expect. Defaults and the like. 
Exciting!
You're right. I might have to change the title (any suggestions?), but to be clear I'm not advocating against serializing default values. I'm just suggesting a way to do it, because it is my personal preference when it comes to CLI configuration. You wouldn't want cargo to write every possible field to your `Cargo.toml` for example.
Maybe in Rust, but in programming this is a common practice.
Thanks for the kind words. This is absolutely a goal of the skribo work, to make high quality text available to the Rust ecosystem as a whole, including UI toolkits, games, and document handling.
Pretty sure `GTask` or `GAsyncResult` was meant.
TL;DR some allocators don't allow zero sized allocations and many common pointer tricks don't work for stride=0 (such as `for(; ptr!=end; ptr++)` and low bit storage)
It’s no different than deserializing data when the schema has changed. Apps already have to deal with it, say, via versioning.
Yes, but schema versioning should be independent of whatever mechanism is used to deserialize/serialize data. 
No, single platform for now. I don't have any plans to port to Android or iOS unless they have direct screen drawing, and Piston supports it. So far as I know, there's no plans.
Well, `Iterator` is quite different from `Future` in this regard, citing `Iterator::next` docs: &gt;Returns None when iteration is finished. Individual iterator implementations may choose to resume iteration, and so calling next() again may or may not eventually start returning Some(Item) again at some point. Also don't forget about [`Fuse`](https://doc.rust-lang.org/std/iter/struct.Fuse.html). So ideally I think more strict approach should've been explored more carefully and not discarded right away. Considering that futures will not be usually polled manually it shouldn't be a problem in practice and it's far too late for such drastic proposals, but nevertheless I personally would prefer more strictness, not less.
I just downloaded the build tools and its working great now, thank you so much! 
Nothing was simply "discarded right away." It was discarded after discussion and investigation that found it to be impossible and not valuable enough to make possible.
Awesome! I'll look into the issues with \`Position::Bottom\`. Looking at the code, I am not sure how it works at all for me... it might be a nice coincidence of how my window manager handles things. &amp;#x200B; Someone (you?) has kindly debugged the issue with \`current\_avg\` vs. \`current\_now\`: [https://github.com/mjkillough/cnx/pull/31](https://github.com/mjkillough/cnx/pull/31)
Isn’t it already? Having implicit default values in serialized data can be done in any language, it’s not specific to Serde or Rust. Author is just proposing an easy way to do it with Serde.
dotenv is very common in a myriad of environments. It also received an additional push in the last couple of years because of containers (Docker, Kubernetes, ...) because config files are usually pretty awkward there.
I was looking to convert rustc target serialization to serde the other day. The current [`impl ToJson for Target`](https://github.com/rust-lang/rust/blob/8159f389f6cc8ec3e3ea009222d6926da77371ec/src/librustc_target/spec/mod.rs#L1235) skips default values like you suggest, so it would be handy if serde could automate that.
It sounds like you misunderstand how TCP server sockets work.
Can you please point me to this discussion? I am simply interested in arguments used at the time.
I've applied this pattern by defining a simple [utility trait]((https://gitlab.com/uklotzde/aoide-rs/blob/development/core/src/util/mod.rs). But a function should be sufficient as long as constructing the default value involves no cost and you don't need any alternative implementation. If there is a canonical default value (like an empty vector) that is unlikely to ever change it should be safe.
I like when things ale simple look here https://github.com/lovasoa/custom_error
It handles manual `Default` implementations better than my solution does since it compares a field's value with that of the struct's default rather than with the default of the field's type. If serde handled that, they should also take [`#[serde(default = "...")]`](https://serde.rs/field-attrs.html#default--path) into account.
From the [GitHub readme](https://github.com/llogiq/compact_arena): &gt; `SmallArena` uses 32-bit indices and can hold up to 2³² objects. `TinyArena` uses 16-bit indices and can hold up to 65535 objects, regardless of object size. `NanoArena` uses 8-bit indices and contain up to 255 objects. I think `Arena32`, `Arena16`, and `Arena8` are better names in Rust.
I think C++ futures can be seen as some kind of design mistake in retrospect. The original implementation didn't support any continuations and was thereby worthless for most tasks that require futures. And if it gets now updated through a concurrency TS it will still have the downside of a bad integration with executors, and a high overhead to due refcounted shared state. &amp;#x200B; However C++ coroutines might be more comparable to Rusts futures and async/await are highly interesting. On paper they are able to support the generator and async use-case, support zero-overhead IO completion operations (Rusts futures don't), and don't have the weird side effects where future composition through movement creates huge objects. With the slight downside of sometimes causing implicit memory allocations.
I see, thank you.
This is cool! I was trying to integrate with what seems the blessed error handling solution today though, i.e. failure.
To paraphrase Verne, "build something to astound the age".
AWESOME! We've been thinking about doing this for a while but never got around to it! Will be very useful for laminar in the future and amethyst. Plus hopefully other mio users too! Thanks, great work!
sorry for late reply. Found somewhat satisfying solution. \`\`\` \#\[macro\_use\] extern crate downcast\_rs; use downcast\_rs::Downcast; use std::fmt::Debug; &amp;#x200B; trait Base: Downcast {} impl\_downcast!(Base); &amp;#x200B; struct Foo&lt;T&gt;(T); impl&lt;T:'static&gt; Base for Foo&lt;T&gt; {} &amp;#x200B; fn run&lt;T: Debug&gt;(a: T) { println!("{:?}", a); } &amp;#x200B; fn run1&lt;T: Debug+ 'static&gt;(a: T) { let mut base: Box&lt;Base&gt; = Box::new(Foo(a)); if let Some(foo) = base.downcast\_ref::&lt;Foo&lt;T&gt;&gt;() { run(&amp;foo.0); } &amp;#x200B; } &amp;#x200B; fn main() { run1(2); } \`\`\`
I can't comment on your particular pain points, but I can say that Rust has come a long way in the last few year. I teach a Comparative Programming Languages course where Rust is one of the 4 languages (Smalltalk, Elixir, Haskell the others), so my use has been sporadic as typically I just do my implementation of the assignments. That said, a few years ago it was fairly challenging to write Rust, but it seems much improved. I just wrote a 2000 LOC web server (using Thruster) and it went quite smoothly.
Thanks!
That's great to hear! I actually read about Amethyst having similar issues with MIO in [this thread](https://community.amethyst-engine.org/t/sorting-through-the-mio-mess/561). Hopefully it proves useful enough.
Did you mean 200 LOC? 
Hello, new to rust (well, making my way through Programming Rust (Jim Blandy et al). 1. I don't understand why there are multiplication overflow errors if the for loop iterator goes to say, 60000. use std::num; fn ret_sq_fraction( fr: i32 ) -&gt; f64 { return 1.0 / ( i32::pow( fr, 2 ) as f64 ); } fn stored_accumulator( mut a: f64, i: i32 ) -&gt; f64 { a += ret_sq_fraction( i ); return a ; } fn main() { let mut a:f64 = 0.0; for i in 1..30000 { a = stored_accumulator( a, i ); } println!( "Val {}", a ) } 2. The accumulator value seems quite different to the values, say this python that gets quite close to pi. #!/usr/bin/python from math import sqrt def ret_sq_fraction( fr ): return( 1.0 / fr**2 ) def stored_accumulator( a, i ): a += ret_sq_fraction( i ) return( a ) a = 0 for i in range( 1, 600000 ): a = stored_accumulator( a, i ) print "%20.20f %20.20f" % ( a, sqrt( a * 6 ) ) Any help, gratefully appreciated.
I recently got Rust code running on a similar chip, the CC2650. I wrote up my notes at https://www.wezm.net/technical/2019/03/sensortag-embedded-rust-coding-retreat/ 
I'm not married to the names. I'm not quite sure if Arena*N* (for any value of N) really captures the intent behind the arenas, but I won't reject a PR if you want to send one. Or feel free to open a bikeshedding issue.
Awesome! I've been using RwLock&lt;Arc&lt;_&gt;&gt; a lot lately, --- &gt; It is possible to store other reference counted pointers (eg. if you want to use it with a hypothetical Arc that doesn't have weak counts), by implementing the RefCnt trait. I feel dumb for not having thought of this before... Any prefab solution that you know of ?
Hooray! Really like zola so far. Already have a couple personal sites using it. Coming from Hugo there’s a bit less complexity and you don’t need to understand go-templates. 
Yes; if it tripped you up, please file an issue explaining so. The book has improved by sanding off hundreds of these little snags over time. The proposed change doesn't need to be huge to be worth bringing up, and you might save someone else time.
1. Let's look at the signature for [`i32::pow`](https://doc.rust-lang.org/std/primitive.i32.html#method.pow): fn pow(self, exp: u32) -&gt; i32 So `pow` takes an `i32` and raises it to the power of a `u32`, returning an `i32`. `i32` is a signed 32-bit integer, so it can't hold any results larger than `2_147_483_647`. As soon as your iterator reaches `46_341`, it panics because `46_341^2 == 2_147_488_281`. The solution is to instead use `f64::powi` for floating point numbers. 2. You might have forgotten to do `sqrt(a*6)` in your rust code? [Here's](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=e96710eb80affae23e7fe539656090db) a playground link to the closest equivalent to the python code.
You can also use the `write!` macro to write into a string without creating a temporary string like with `format!`. use std::fmt::Write; write!(html, "&lt;p&gt;{}&lt;/p&gt;&lt;p&gt;{}&lt;/p&gt;", testu.name, testu.age).unwrap(); &amp;#x200B;
This only works up to a certain size though, an alternative approach would be to append assets to the binary after the build is complete, as suggested in previous threads. 
Same goes for a lot of (all?) mobile clients!
It comes from the Ruby world, and, as often happens, Ruby people have taken it with them when they move to other languages. Just look how many languages have an RSpec clone too! &amp;#x200B; But outside projects written by Ruby programmers, it's rather rare.
I'll do that soon, then. Thanks for the encouragement :-) I take it you mean via the Book's GitHub issue tracker?
&gt; very common By what metric?
As of this post, I've already been moving ahead on 0.2.x features, and have already frozen a first feature. Text justification - take a look at the project, you'll see the different types (also note the screenshot)
Thansk for your interest :) Cause now it's just my personal hobby project, the first thing I should accomplish is to make it work, which means I need to add all c11 features support to it, this should be an important stage, when it got this stage, then I can use it to compile read world applicatios and do some real benchmarks not just some simple test. Cause right now it's really new, you can see I started this project one week ago, and only me working on it, so it could be a long time for me to add all c11 standard (although it's actively written by me, I almost commit 7 times per day). So I will see as the progress goes on, if it raises some interests and more and more programmers are willing to contribute, then maybe that's the time for serious compiler component design, add IR, add multi language support, etc.
My team uses the convention that the first argument to a program is a path to a configuration file. It's up to your service definition, init scripts, cron job, etc to pass that correctly. So, in dev, you write: ``` target/debug/daemon conf/local.toml ``` And in prod, your start script says: ``` /usr/local/bin/daemon /etc/daemon/prod.toml ``` 
You can find raytracers written in almost every programming language too, but that doesn't mean that graphical programs usually use raytracing.
Thanks! This looks really interesting. I can see the benefits of not having to build non-source code into the binary during development builds.
Is that possible to do in a `build.rs` file?
Thanks! We have an awesome and friendly community. Join ussssssssss
I did talk with Fuchsia, yes. I can’t live in Austin and work on Fuchsia, so it didn’t work out.
I imagine that all the const fn stuff is helping significantly toward this end.
Mhm ok, most people coming and criticize that someone creating blockchain but people see they creating and learning how to do that now about energy waste in us many people still wasting electricity turning on and leaving all day night to run light bulbs ;) cars too vasting gasoline when only need travel few blocks. And you attacking that bitcoin wasting power... When most people do not realize that in simple mater wasting energy in daily life... In my opinion, there is inaf energy to run but not inaf people to realize how to use power in a smart way. In future, I think most electricity will be renewable or even free coz a lot now coming alternative energy sources ;) so better people not waste bad comments but butter says that they trying to do something or create a cryptocurrency that is not another shet or copy paste from GitHub... 
Ow and another if you don't want that bitcoin waste energy than why most here readers using bitcoin ;)? Or another alt coin that in protocol have POW ;)
I haven't worked with that chip specifically, but I do my embedded development via a hacked together Bluepill/Blackmagic Probe and have had a great experience with it. It exposes a gdb server over a serial device, so it's practically zero configuration needed. According to its docs, it supports cortex m3, so maybe worth a try? I wrote about my experiences [here](https://josh.robsonchase.com/embedded-bootstrapping/). At less than $3 a board, at the very least, it would be a cheap experiment!
If your intent is to prioritise reads over writes, you might want to look at using thread-local storage. Each instance would have a global value contained in an `RwLock`, a global atomic version number, and a thread-local value and version number pair. On write, you take the lock, update the value, release the lock, and then bump the version number. On read, you compare the local version number against the global one (relaxed ordering being fine). If they are the same you can just return your local copy of the Arc - you can even implement your "lease" functionality to avoid accessing the ref-count without holding a lock at all because the arc is guaranteed to stay alive thanks to the thread-local reference. If the values differ, you take the read lock, copy out the version number and then the value, and then continue as before.
Sounds great! I've been using nom 4 to write a [HCL parser](https://github.com/lawliet89/ferrous-chloride) for fun and I am glad to see the `CompleStr` and error handling being improved. Being a novice user, I'll see what I can contribute 😅
Fair - but even if you discount Google, the other companies are certainly invested. Amazon alone is investing in critical areas with rust - firecracker.
I saw that. Looked pretty interesting. Although I'm not sure how much they are actually using firecracker. I'm writing services in rust at IBM. And I've talked to people at Toyota that use Rust for some stuff. 
It doesn't sound like that needs thread-locals at all, just distinct handles like any other smart pointer.
Thank you! That's exactly the experience I want. I'll try it out.
Nice, thank you. I've been thinking about trying it out. Is it possible to build binaries and automatically attach them to a github release?
Cool stuff! Welcome to Rust. I'll leave a couple of thoughts: As your driver matures, think about how it might be used in other places besides a Raspberry Pi. It looks like we're using *Linux* I2C throughout our crate. But, what if we wanted to use this on our STM microcontroller, which isn't running Linux? Rust has crates for hardware abstraction layers (HAL), like [embedded-hal](https://crates.io/crates/embedded-hal). The good news is that, if we design our MPU crate to the embedded-hal traits, we can automatically use it on Linux! We'd use the [linux-embedded-hal](https://crates.io/crates/linux-embedded-hal) crate, which provides an I2C type that conforms to the I2C reader / writer traits. And then, we could also use this on our bare-metal STMs and on our Raspberry Pis. Keeping on the "where else could we use this crate?" theme, we have some other assumptions about running with an OS: there's a heap, and we're sharing a pointer to our I2C device throughout our `MPU6050` struct. We (probably) won't be able to use that on our bare-metal system. Rust has a feature call [\#!\[no\_std\]](https://doc.rust-lang.org/1.27.0/book/first-edition/using-rust-without-the-standard-library.html), which ensures that our code can work without an OS. Once you get more comfortable with Rust, check out how a no-std crate differs from a normal crate. Next steps: We may be doing a little too much sharing of the I2C device throughout accelerometer / magnetometer structs, and then sharing them with registers. Could we think of designs that eliminate the *shared*, mutable memory? What if things that needed an I2C device took it as a mutable borrow? How might our design adapt to that approach? Ask questions: what does having a `Register` struct really buy us? Could that just be a function that accepts a mutable I2C reference, and an address? Then, what do the `Gyro` and `Acc` structs buy us? Is it important to encapsulate that in a struct? If so, what if its lifetime were tied to the `MPU6050` struct, so that it couldn't exist without a `MPU6050` owner? Little nits: * Documentation comments will have three slashes (`///`) instead of two. Rust tooling and docs are great; using proper doc comments will help us keep the docs great here, too. * `MPU6050::new()` accepts a `&amp;str` (string slice) to represent the path. What about a [Path](https://doc.rust-lang.org/std/path/struct.Path.html)? Fun power moves: * We implemented a custom `Default` implementation for `Reading`. However, we could use `#[derive(Default)]`. Saves us some typing. [demo](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=f2395e44830b2581314d94032a4db1fa) &amp;#x200B; #[derive(Default)] // &lt;-- Since f64 is default, Reading is default! pub struct Reading { x: f64, y: f64, z: f64, }
Now, I wouldn't symlink rm and go crazy, but it seems to work well for whatever I throw at it. Would really appreciate feedback, as it's my first Rust program.
if you are on windows 10, compiling rust through WSL works pretty good. If you want to keep from polluting your windows install with a bunch of programming dependencies. 
Don't know if this is an "easy" question, but I'm trying to figure out how to use FnMut properly to modify a variable outside of the scope of a closure. Here's the code I've got as an example: type MutableSingleCallback = Box&lt;FnMut() -&gt; ()&gt;; pub struct MyCallbackStruct { callback: MutableSingleCallback, } impl MyCallbackStruct { fn new() -&gt; MyCallbackStruct { Self { callback: Box::new(|| { }), } } fn set_callback(&amp;mut self, callback: MutableSingleCallback) { self.callback = callback; } } pub struct ModifyableStruct { color: (i32, i32, i32), } impl ModifyableStruct { fn new() -&gt; Self { Self { color: (0, 0, 0), } } fn set_color(&amp;mut self, color: (i32, i32, i32)) { self.color = color.clone(); } } fn main() { let mut mcs = MyCallbackStruct::new(); let mut modifyable = ModifyableStruct::new(); mcs.set_callback(Box::new(|| { modifyable.set_color((2, 5, 1)); })); } And here's the error I get: Compiling playground v0.0.1 (/playground) error[E0597]: `modifyable` does not live long enough --&gt; src/main.rs:40:9 | 39 | mcs.set_callback(Box::new(|| { | - -- value captured here | ______________________| | | 40 | | modifyable.set_color((2, 5, 1)); | | ^^^^^^^^^^ borrowed value does not live long enough 41 | | })); | |______- cast requires that `modifyable` is borrowed for `'static` 42 | } | - `modifyable` dropped here while still borrowed I think this should be something simple, but I've never used closures. :( [Here's the playground if you're interested in helping!](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=c7ab2012ef7f60b3206eeb10b5397f7d)
Currently, this is black magic to me but I'd like to understand it in a few months (read: years) time.
Hi all, pretty new to Rust and what I'm trying to do is read a filename into a variable from the user, then plug that variable into the open function to open the file. It's not finding the file when it tries to open, but it works just fine when I manually put the filename in. This is basically what I've got, I've tried several variations, any help would be greatly appreciated. The filename is given in the form "name.txt" let mut file_name = String::new(); io::stdin().read_line(&amp;mut file_name); let mut input_file = File::open(file_name); // :( 
Why doesn't that loop thing work? `ptr == end` immediately, right?
`enum Foo {` &amp;#x200B;
I definitely agree about GraphQL, as I've had a few project ideas that would work perfectly with GraphQL's subscriptions, but were blocked by that missing feature.
Good to know, thank you! Unfortunately, I'm on windows 8.1 for now :)
When I have this: enum Foo { A, B }; Is it OK to assume `Foo::A as usize == 0usize`?
I've run into a load of problems with using function traits. It always seems very difficult and verbose, especially without generic trait aliases. I've opted instead for defining custom traits with a struct/impl for each "closure" (similar to how it works with Iterators) but it does feel a bit clunky, like returning the the days of java before lambda syntax for single method interfaces. 
Wow, thanks a lot. &amp;#x200B; I am using Linux right now, as I am the most comfortable with it. I've also written mini gpio and pwm libraries for linux, so I'm not sure if I'll be considering making it platform agnostic. Still, I wonder how exactly the \`embedded-hal\` thing works: The traits themselves are nothing more than...traits, right? So, to use the driver for either linux, or on bare metal, I'd have to implement both \`linux\_embedded\_hal\` and \`embedded\_hal\`, correct? The compiler takes care of the rest, when targeting specific platforms? I have my own read trait right now that implements a \`read\`, \`read\_raw\`, and \`read\_filtered\` (which I should really call \`read\_avg\`, as it does the simplest form of filtering: averaging). There no way to "extend" a trait with your own functions, right (in this case the \`embedded\_hal\` trait)? So i would have to provide my \`read\_raw\` and \`read\_filtered\` functions in another trait? Yeah, I knew you wouldn't like that i2c device sharing :D I don't really like it myself...But it made my calls so awkward, e.g. let mpu = MPU6050::new(/***/)?; let _ = mpu.gyro.read(&amp;mut mpu.device)?; I tried making things a little less awkward by writing helper functions let _ = mpu.read_gyro()?; let _ = mpu.read_acc()?; But I didn't like that either, as it seemed redudant. Well, good that things aren't final yet. &amp;#x200B; Great suggestion about path! Makes things more clear. Nice, default trait. &amp;#x200B; &amp;#x200B;
What does the ` impl Fn(A) -&gt; C` mean in the declaration fn compose&lt;A, B, C, G, F&gt;(f: F, g: G) -&gt; impl Fn(A) -&gt; C I have never seen this syntax before. 
slightly off topic but this website is *beautiful*
You can look at the procinfo crate and especially this function: [https://docs.rs/procinfo/0.4.2/procinfo/pid/fn.statm\_self.html](https://docs.rs/procinfo/0.4.2/procinfo/pid/fn.statm_self.html)
https://doc.rust-lang.org/edition-guide/rust-2018/trait-system/impl-trait-for-returning-complex-types-with-ease.html It’s returning a closure by value.
Nice. What’s performance like? Is there much overhead?
This is very cool! I'm also interested in programming language implementation but mostly stick to VM interpreters. Where did you learn x86 assembly, any resources you can recommend?
This is the one discussion on this topic I remember: https://github.com/rust-lang-nursery/futures-rs/issues/458. I'm curious what /u/Rusky is referring to cause I never saw any thorough discussion of this topic. (Not saying it didn't happen, I just never came across it.)
Can't comment on your specific requirements, but if you have no Rust experience yet it might be a good idea to wet your feet with some simple stuff so that you're not e.g. still fighting the borrow checker so much once the tooling is more favorable to your needs. Maybe along the way, you'll find it fun to contribute some of the libraries you need - and if not, you still got a head start with Rust once it can do what you need.
Thinking about this more, perhaps this is a better way to do it: let good_opt2: Option&lt;Vec&lt;&amp;str&gt;&gt; = good_res.map(|s| s.split(", ").collect()).ok(); `Result::map_or` would still be useful if you're looking to create something besides on `Option&lt;_&gt;` though, I think.
You could also just use "match" in this case as you're handling both Result cases here anyway.
At this moment nope. But I will be happy to add it. I never do this before. So just send me a link with documentation and I will be happy to implement `ci/binary-deploy-gh.yml`
Fairly cryptic question regarding callbacks ... this is one I've been trying to figure out for about a month. I finally reduced it down to a small number of lines. Bear with me: pub type SingleCallback = Box&lt;Fn() -&gt; ()&gt;; pub struct SimpleCallback { callback: SingleCallback, } impl SimpleCallback { fn new() -&gt; Self { Self { callback: Box::new(|| { }), } } } pub struct Simple { } impl Simple { fn new() -&gt; Self { Self { } } pub fn do_something(&amp;mut self) { eprintln!("Do something"); } pub fn build(&amp;mut self) { let simple_callbacker = SimpleCallback::new(); simple_callbacker.callback = Box::new(|| { self.do_something(); }); } } fn main() { let mut simple = Simple::new(); simple.build(); } One would think this should compile, but I get some really cryptic errors regarding lifetimes and static that I just do not understand: error[E0495]: cannot infer an appropriate lifetime due to conflicting requirements --&gt; src/main.rs:29:38 | 29 | simple_callbacker.callback = Box::new(|| { | ______________________________________^ 30 | | self.do_something(); 31 | | }); | |__________^ | note: first, the lifetime cannot outlive the anonymous lifetime #1 defined on the method body at 26:5... --&gt; src/main.rs:26:5 | 26 | / pub fn build(&amp;mut self) { 27 | | let simple_callbacker = SimpleCallback::new(); 28 | | 29 | | simple_callbacker.callback = Box::new(|| { 30 | | self.do_something(); 31 | | }); 32 | | } | |_____^ note: ...so that the type `[closure@src/main.rs:29:47: 31:10 self:&amp;mut &amp;mut Simple]` will meet its required lifetime bounds --&gt; src/main.rs:29:38 | 29 | simple_callbacker.callback = Box::new(|| { | ______________________________________^ 30 | | self.do_something(); 31 | | }); | |__________^ = note: but, the lifetime must be valid for the static lifetime... = note: ...so that the expression is assignable: expected std::boxed::Box&lt;(dyn std::ops::Fn() + 'static)&gt; found std::boxed::Box&lt;dyn std::ops::Fn()&gt; error: aborting due to previous error [Here is a link to my playground.](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=3aa168886c07f814bd70d10d5f97e2b4)
thank you!
What do you mean? It's just a templates for azure pipelines. Instead of creating a many files for your CI configuration you just link to this repo and configure what u wanna use. The goal is that you don't need to understand details - just copy azure-pipelines.yml and a few steps from instruction and you are done.
Wow the accepted answer is beautiful.
Look at it from another angle: If you write an arena for your program, you'd likely want to reuse it, so you'd put it in a crate. However, it's likely that you can just use this one, or possibly extend it – and I'll be glad to see your PRs.
AD talks LDAP so you can use any LDAP library with it: https://docs.geoserver.org/latest/en/user/security/tutorials/activedirectory/index.html
There's already an I2C abstraction in embedded-hal, and an implementation of it in stm32f30x-hal. Why roll your own? 
The chip I test does not follow standard I2C communication routine, for example it does not require a I2C address. Maybe for abstraction purpose I need to follow hardware I2C, but this experience may be used in other peripheral standards.
Thanks /u/mdaffin, but in my post I state that LDAP is off the cards. &amp;#x200B; To provide more context: I need to authenticate with username/UPN and password, then authorise user by reading their AD group membership. The client explicitly stated that they are retiring LDAP access to their AD, and we should instead look at the alternatives from Microsoft AD/Azure
In absence of a C library, it would appear that the only way forward is to port Python/Java/JavaScript version to Rust as source codes are available on GitHub.
It allows you to return a type that is unnameable. For example, a closure has a concrete known type, but there is no way for you to specify that type (as it is autogenerated by the compiler and doesn't have a name, unlike a type that you define). This syntax allows you to specify that the return type of the function is some concrete type that implements a known trait and the compiler will automatically fill in the correct type at compile-time. The user of the function can rely on the known trait as an interface to use the type. Other uses of this syntax are to return an anonymous `Iterator` (for example, that you made using combinators, whose type would be incredibly long and inconvenient to type and possibly an implementation detail) or `Future`. One current limitation of this syntax is that it cannot be used for trait methods. You cannot define a trait method that returns an `impl Trait`, because the `impl Trait` must resolve to a single concrete type at compile-time, but each implementer of your trait might end up returning a different type and there is no way to manage that.
I've used OpenDrain pins for that purpose before, as they can habe both at the same time. But you might have to add them to your hal yourself.
It doesn't do everything `map_or` would, but in your case, `Result::ok()` is absolutely what you should be using. It just replaces any `Err` values with `None`, and `Ok` with `Some`. Then you'd just do a normal map.
I think that would be the one I was looking at at the time, yes. I even considered to adding a support for it after a feature flag, but discovered it doesn't support some important operation I need (I *think* it's conversion back from a raw pointer). Then I postponed it and forgot about it, as I've never needed that.
Looked up the datasheet. Wow. Why would even do that ever. Anyway, if you're stuck with it, I guess your options are either use `OpenDrain` or reconfigure the pins for every write. There's no good generic "read/write pin" abstraction because switching from reads to writes (and vice versa) can be pretty complicated. 
Thank you! I've worked out both ways using reconfiguration (using macros to abstract) and OpenDrain with the help of other redditors. 
That's a possible solution, however, in the described form it has certain downsides. * The RwLock *can* at certain situations block. Guaranteed, for a short time only and only on rare occasions, but still. * You need to either hold the separate private handle separately or in a thread local. That's fine if you have just one, but will get more complex once you have a data structure containing multiple of them. Like, having a different routing table per network interface. * The private caching handle either needs to keep the data alive or contain a weak reference. If the latter, we get contention on the ref counts when upgrading. If the former, an inactive cache handle (the example from above, someone unplugged the cable from the network interface and no packets are going through it) will keep the data alive indefinitely. The data may be big and each cache can keep a different *version* alive, producing a potential problem memory-exhaustion problem. However, having this on top arc-swap for cases where it makes sense could produce interesting improvements, for those who can use it. So thank you for the suggestion, I'll write it down and maybe get to implementing it eventually.
Yes, and that's the problem. If `end` is calculated as `ptr + n * sizeof(T)`, you would normally expect to go through the loop `n` times (regardless of the size), but if size is 0, `ptr == end` immediately and so you go through it 0 times.
You don't need npm, the Hello World page has a section about wasm-bindgen to generate the .js to include in your html that will load your wasm.
I wouldn't wait to long on the futures features. Yes it will be a pretty big improvement. But in my experience , if you don't know how to do it without futures, futures arn't going to fix it.
Use the `.trim()` method to get rid of the trailing newline
By default, `Box&lt;Trait&gt;` means `Box&lt;Trait + 'static&gt;`. Since you borrow `self` at the offending closure, that closure only has a lifetime of that borrow. If you use `type SingleCallback&lt;'a&gt; = Box&lt;Fn() -&gt; () + 'a&gt;` and make similar changes where necessary, then you should be able to get it working.
It's also possible to use `impl` in parameters to make the code even simpler. ```rust fn compose&lt;T, U, W&gt;(f: impl Fn(T) -&gt; U, g: impl Fn(U) -&gt; W) -&gt; impl Fn(T) -&gt; W { move |x| g(f(x)) } ```
That's also a nice solution. Thanks for the suggestion!
Is the ES6 module the problem? You can pass `—target no-modules` to wasm-pack to get it to build something that can be included using a regular script-tag.
What you probably want is [wasm-bindgen](https://rustwasm.github.io/docs/wasm-bindgen/)
Using env as a primary source of configuration is a really bad idea. For optional overrides of some values - sure, why not. But it's like using global variables in your code. Also env gets inherited and you might have a clash in names with other apps. And looking at env you have no idea what keys belong to your app, what to OS, what to other apps. And env is visible to anyone at any time so you lack encapsulation and security as well. Just because someone likes to do it (Ruby from what I hear and Heroku from my experience) doesn't mean it's good. Best practice is to have a default config file location but also take cli option that can specify a custom path. And be able to specify config key-value pairs on the cli for some cases where you don't want to keep a config on filesystem, for simple tools.
Ohh that looks good too. I will definitely try that in this project. Thanks. :)
Yes. [Reference](https://doc.rust-lang.org/reference/items/enumerations.html#custom-discriminant-values-for-field-less-enumerations).
The `wasm-pack` currently produces a ES6 module-based WASM bundle. Browsers currently don't support this setup, so you need to have a JS bundler if you want to use it. /r/anlumo's solution will probably work for you. 
u/robojumper, many thanks, looks like complete programmer error on my part. 
&gt; And env is visible to anyone at any time so you lack encapsulation and security as well. The systemd environment variables are local to the spawned process in the `.service` file and therefor this is secure. In Linux you can also set local environment variables with `env`: echo $FOO # no output env FOO=bar printenv FOO # set local env, output is: bar echo $FOO # no output 
Is there a reason why documentation efforts like [the discovery book](https://rust-embedded.github.io/discovery/) aren't mentioned at all on https://doc.rust-lang.org/? I wish it was.
https://rustwasm.github.io/docs/wasm-bindgen/examples/without-a-bundler.html
Are there any channels/sites/rooms where you can pair-program with other developers (rust in this case) remotely? That will definitively help me.
The simple reason is likely that no one got around to add it. Sending a PR might be a good idea.
It should be theoretically possible, but not easy. The Rust compiler itself needs some work to enable new LLVM targets, and you'll probably have to expose some intrinsics for DSP stuff, too.
I combine the two and solve borrow puzzles for a sudoku solver.
Atomically swapping `Arc` is a really tough issue, with many potential applications, so it's nice to see more exploration of this space.
Yep, will do, thanks.
There seems to be an agreement to stabilize `std::future::Future` for 1.36, available in 12 weeks (~3 months). I expect to see a flurry of activity during the summer months to align the ecosystem on it, as it has been long awaited, and hopefully by end of September the major crates/frameworks will have migrated to it.
You are evidently not the mean programmer, or closely inside Rust’s primary target demographic. Most programmers are familiar with C-family languages, in syntax and features. To be sure there are a great many familiar with other classes of languages, but I do not believe it is contested that the substantial majority of programming work is done in C-family languages (e.g. C, C++, C♯, Java, JavaScript, Python, Scala). Rust’s primary target market is a subset of that (which, expressed very imperfectly as one language, would be C++). This influences strangeness budgeting. I shan’t address all your points, but here are a few conclusions from my first paragraph: algebraic data types are *not* a baseline feature; nor are guaranteed tail calls; most of these programmers are also used to generics with `&lt;&gt;`, and switching to anything else (e.g. `[]`, shunting indexing to `()`—which I may add I pushed for, but too late to convince people it was worth it) incurs a slight strangeness cost. With some of your other points, I am uncertain to what you refer; broken Eq/PartialEq and broken Ord/PartialOrd, for example: the definitions seem altogether sane to me.
On Windows I’m used to typing an emoji for the first time in most apps (for me, via WinCompose, but I would expect the emoji keyboard to suffer the same problem) causing input to lock up for up to a second or so, while it loads the font (Segoe UI Emoji). It’s a technically interesting problem.
That's a cool Rust themed profile picture!
Programmers will be tempted to bypass any internal configuration mechanisms that might separate one set of keys from the other and access all env vars directly. That is not safe. Not only with regards to security, but also to tight coupling. Like I said, it's the same as global/static vars, there'll be no isolation of keys between the code components that need and "own" them. In other words, you should prevent components from accessing data that is outside of their contract. Otherwise you'll get chaos - everything accessing everything, which will make your code unmaintainable and it will simply die as a project.
How much time did you spend trying to understand it? Yeah, it looks a little tricky to me too, but if I focused on it for 20 minutes I bet I would understand it pretty well.
As other answers suggest, you can use wasm_bindgen and avoid any need for node. This is what I did in my example fractal project (https://github.com/jsdw/wasm-fractal)
When you thought you were starting to "get" Rust...
&gt;support zero-overhead IO completion operations (Rusts futures don't) Can you please provide some details/references for this? It sounds quite interesting.
Sorry, to clarify, I didn't mean to ask if your specific templates could do it. I already looked for that. I meant to ask a general Azure question about whether it's possible. If I had a link to the docs showing how to do this, my question would be answered. I was hoping an Azure expert would know more definitively. :)
I want to support it anyway. It's look like azure has it build in: [https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/utility/github-release?view=azure-devops](https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/utility/github-release?view=azure-devops) So I just need to test it. 
didn't we have enough failures by now...
&gt;nested Thank you for all the advices :)
Well, in my experiments it has workd with several hundred megabytes without any issues (IIUC you simply need to have enough RAM to contain all your assets), so I don't think it will be an issue for OP.
IIRC executable are usually memory mapped, so resources will not be pulled to RAM all at once.
For the sake of brevity, I'll accept the points you have made and thank you for providing your point of view there. This means I have some time to talk about the last question you raised here: &gt; With some of your other points, I am uncertain to what you refer; broken Eq/PartialEq and broken Ord/PartialOrd, for example: the definitions seem altogether sane to me. Their core assumption is that there is _the_ definition of equality and _the_ definition of ordering, which is further driven home by `PartialEq` and `PartialOrd` being super-types of `Eq` and `Ord`. This is fundamentally not true, case in point: Floating-point types. The current design feels like people sensed that there was a problem there, but couldn't find a solution that addressed the issue. This gets you gems like `&amp;[0.0/0.0].contains(0.0/0.0) // false`, which are completely avoidable. The core lesson that seems to have gone unlearned is that some types have multiple valid implementations of equality and ordering, and it's not possible to smash them into a single function/typeclass. Saying "this type is a full `Eq`, that type is only a `PartialEq`" is an abstraction that is rather useless for three reasons: - It doesn't tell me _what_ kind of "Eq" it is, let alone allow me to pick which one I need. - `Eq` is a sub-type of `PartialEq`, which is a literal transcription of math's "a total order is also a partial order", which is missing the point that one can have multiple orders which are distinct from each other. - `Eq`'s and `PartialEq`'s implementations cannot differ, but even if they could, it would be useless due to the way `Eq` and `PartialEq` are used in the code. In conclusion: - Rust's (and Haskell's, Purescript's, ...) `Eq` and `Ord` are incorrect in the sense that they fail to address the problem they were meant to address. - There exists a better design that is correct, more straightforward and less complicated.
Evaluating the Rust ecosystem based on its availability of GraphQL is like evaluating Mercedes Benz based on its availability of an arm-rest refrigerator.
Thank you. I missed that.
It flatout ran my laptop out of memory and I had to REISUB 
Interesting. Thanks for the link!
You want /r/playrust
It's because Rust is not a functional language and trying to use it as one is inevitably going to end up being ugly, clumsy, and unidiomatic. The best way to write good Rust code is to write Rustic code and not try to replicate Java or Haskell or Perl.
&gt; Another downside is that our indices and arenas can no longer be Send nor Sync. If we could share an arena between threads, nothing would keep us from having two threads instantiate arenas from the same place in the code, which means they could mix up indices. I think this also applies to recursive functions, and so needs to be fixed in some other way (but, does mean that they can be `Send` and `Sync` once fixed). As you say, two arenas from the same place in the code can interchange indices, since the use of a type-marker (instead of a lifetime) results in the values being keyed off the lexical position, with no dynamic element, whereas as a lifetime acts as a marker for a particular stack frame (i.e. the particular dynamic frame, created at runtime).
I was just using "related" casually, to mean that there's *some* connection between them, not to mean "proportional".
Na, that was very good explanation. I just might have to rethink the way of structuring my code
Tried to write a generic "sum" function the other day for any iterable that contained elements that implemented the numeric "add" trait. Tried for 30 minutes and eventually gave up. Where would I find resources that would help me write that? I went through the rust book.
Aww thanks &lt;3
That's my answer! Kinda surprised too see myself pop up on the subreddit :)
On thing worth mentioning in this context is how to make it work if the functions to be composed use lifetimes. It's kind of hard to explain exactly why there is a problem, but the way that's easiest for me to think about is that for "normal" function arguments you want lifetimes to be resolved right when they are passed, but if your argument is a function that takes lifetimes, you want those lifetimes to be resolved when \*that\* function is called. To achieve that you need Higher Ranked Trait Bounds: [https://doc.rust-lang.org/1.5.0/nomicon/hrtb.html](https://doc.rust-lang.org/1.5.0/nomicon/hrtb.html)
Maybe check out the same thing in a different language, like Python? def compose(fn1, fn2): return lambda x: fn2(fn1(x)) Here's some interesting reading material: http://learnyouahaskell.com/higher-order-functions#function-composition https://wiki.haskell.org/Compose
Yeah I got what it was doing, but the Implementation was rather complicated (imo) with 5 or so different generics :D
Other than `image`, will there be any other repo which is transferred to `image-rs`?
[removed]
You can use the trailing_zeros method: https://doc.rust-lang.org/std/primitive.u64.html#method.trailing_zeros
Possibly [`u64::trailing_zeros`](https://doc.rust-lang.org/std/primitive.u64.html#method.trailing_zeros)?
Quoth the OP: &gt; Most of my projects consist of an embedded device being controlled by a graphql UI client. Or, by your analogy: "my job is to sell ice-cream out of a luxury sports-car".
Yes, the possibility of different feasible orderings is something that has annoyed my very occasionally. The workaround of a newtype to provide a different implementation is definitely not the most satisfying thing. And so the end result is that you end up with two variants of sorting things, e.g. `fn sort(&amp;mut self) where T: PartialOrd`, and `fn sort_by(&amp;mut self, impl FnMut(T, T) -&gt; Ordering)`. On `PartialEq` versus `Eq`: bear in mind that `Eq` is purely a marker that the equality function provided in the `PartialEq` implementation is in fact total; `Eq` provides no new methods as it doesn’t change the signature. `Ord` on the other hand does define a new method, since it needs a different signature to `PartialOrd`. Let us indeed take floating point types. Here, Rust has stuck with its preference for high-performance code, and its systems programming roots. Rust’s floating point types are an accurate representation of IEEE floating points numbers, where there is a partial equality only. That they do not implement `Eq` is, I am led to understand, necessary for performance, as hardware does not implement the necessary primitives for efficient calculations of total equality or ordering. And so, unfortunately, the extension total ordering that the IEEE does also define is relegated to a crate (as a newtype), with mildly damaged ergonomics. For scientific and mathematical programming, this may be unfortunate, but for most people it never comes up. I don’t *think* I’ve yet hit a case where I wanted `Eq` or `Ord` for a floating-point type. But then, I suppose I don’t deal in floating-point numbers very often, either, and am thus not qualified to remark on the matter. I am mildly disinclined to concur on your thesis that `Eq` and `Ord` are *incorrect*, but mostly on the grounds of the particular word that you selected. *Given the hardware* that the code is run on, there *is* one obvious and correct (however weird `NaN`s and infinities may be) definition for floating-point numbers. Though yes, there are others, and the inability to choose them ergonomically is a pity. &gt; There exists a better design that is correct, more straightforward and less complicated. You don’t seem to have mentioned what it is, and I don’t think I can guess what it might be, given the claims you have made about it. What I am imagining is something like named implementations of traits for types, with the ability to specify one as the default, but select others. Yet I don’t see how that would be more straightforward or less complicated (I’m imagining it basically ending up another generic parameter), so perhaps you have something else in mind?
Isn't there already the sum method in Iterator?
(1) Yup, embedded-hal is a collection of traits. If an `MPU6050` were designed to the traits, we would not have to provide anything else from the linux-embedded-hal crate, or any device-specific crate. linux-embedded-hal provides *implementations* for the embedded-hal *interfaces*. Think about how an equivalent approach might work in Java or C++: an `I2C` interface describes how to read to / write from an I2C device. An `MPU6050` accepts an `I2C` pointer on construction. Therefore, it can accept pointers to anything that implements `I2C` without knowing the specifics. Rust has the same thing; we do that with traits. The `MPU6050Read` trait can happily co-exist with any of the traits in the embedded-hal crate. Traits are like interfaces, and nothing in the embedded-hal crate describes how to read from an MPU6050. That's the responsibility of our crate! (2.5) That's good insight; it is nice to put the accelerometer and gyroscope behavior into their own types. But, what if we took advantage of Rust to model ownership? What if we have an `MPU6050` that *owned* an accelerometer and a gyroscope, and it provided mutable access to those things? We kind of have that now, but since we're using shared pointers everywhere, and since they're public members of the `MPU` struct, we can have an accelerometer that can out-live its MPU struct. pub struct MPU { // Note how the members are private... acc: Acc, gyro: Gyro, // Maybe other members... } impl MPU { pub fn get_acc(&amp;mut self) -&gt; &amp;mut Acc { &amp;mut self.acc } pub fn get_gyro(&amp;mut self_ -&gt; &amp;mut Gyro { &amp;mut self.gyro } } In this approach, we return mutable references to an `Acc` and `Gyro` types. We use the borrow checker to ensure that there's only one of these checked out at any given time. What if we took it to the next level? What if they were both lightweight adapters over an `I2C` type? pub struct Acc&lt;'a, I&gt; { i2c: &amp;'a mut I, } pub struct MPU&lt;I&gt; { i2c: I } impl&lt;I&gt; MPU&lt;I&gt; where I: I2C { pub fn new(i2c: I) -&gt; Self { MPU{ i2c } } pub fn acc&lt;'a&gt;(&amp;'a mut self) -&gt; Acc&lt;'a, I&gt; { Acc::new(&amp;mut self.i2c) } } Now, `MPU` owns an `I2C` type. We can use the `acc()` method to get an accelerometer type. That accelerometer type borrows the underlying `I2C` object to do its work. At this point, we don't need the shared pointers, since we're using references. This approach is much more complex in terms of lifetimes, and the associated type / function signatures. As you keep learning about Rust, consider how we can use lifetimes to enforce APIs like this. [Here's the above code, with some more code, in a playground.](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=532b58c3589d761d9178f966b99a1f61) "*Can I implement calculation traits without copying"* I don't believe so, or if we can, not easily. If we'd like to avoid copying / extra allocations, I'd recommend implementing the methods as custom `add(&amp;mut self, other: &amp;Reading)` and `div(&amp;mut self, factor: f64)` member functions that modify `self` (by taking `&amp;mut self` as the first argument. We could make them domain specific: instead of `div`, call it `scale`, etc. (4) We could look again to the embedded-hal crate, which has the [blocking Delay traits](https://docs.rs/embedded-hal/0.2.2/embedded_hal/blocking/delay/index.html) just for this purpose. An implementation on Linux could use a thread sleep; an implementation on a different, bare-metal platform could perform a busy-loop, or something else.
It looks like it can work: [https://github.com/xoac/rust-azure-pipelines/releases](https://github.com/xoac/rust-azure-pipelines/releases) but I need more time to make it work: Here is issue: [https://github.com/xoac/rust-azure-pipelines/issues/2](https://github.com/xoac/rust-azure-pipelines/issues/2)
You could dig through the source of the implementation in the standard library. [https://doc.rust-lang.org/std/iter/trait.Sum.html](https://doc.rust-lang.org/std/iter/trait.Sum.html)
Yes, but not until all concerns and issues related to the transition are resolved. This will save us time when moving the other repos later.
`Add` isn't enough, you also need the identity (zero) element. We can borrow the [`Zero`](https://doc.rust-lang.org/1.9.0/std/num/trait.Zero.html) trait in the [num](https://crates.io/crates/num) crate for that. [Playground link](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=5ac0f8f0415cff88faa15d768fb91bc9) 
This should on an intel CPU result in a single instruction (tzcnt) - but you might need to check your disassembly to make sure that this happens. You might have to tweak the compiler optimization level, and architecture. Count leading zeroes requires CPUs with the BMI1 feature set, but I can't find offhand a list of which CPUs have this feature.
On my Linux (Xeon E6-2520) I had to do the following to get the tzcnt instruction emitted: rustc -o bmi1 -C target-cpu=native bmi1.rs objdump -d bmi1 | grep -2 tz 0000000000007b40 &lt;_ZN4core3num21_$LT$impl$u20$u64$GT$14trailing_zeros17h5322bcb05f8fbebaE&gt;: 7b40: 48 83 ec 10 sub $0x10,%rsp 7b44: f3 48 0f bc ff tzcnt %rdi,%rdi 7b49: 48 89 7c 24 08 mov %rdi,0x8(%rsp) 7b4e: 48 8b 7c 24 08 mov 0x8(%rsp),%rdi But not that without optimisation this ends up in a separate function. You need -O flag to get the instruction inlined.
Rust has both functional and imperative language features. Having the other does not make Rust "not imperative" or "not functional". There are some aspects of functional programming (e.g. currying) that Rust doesn't well. That doesn't mean that e.g. iterator combinators work poorly. They work quite well and produce idiomatic, clean, and readable code.
Could I not use std::default::Default instead of zero ? 
In this case you could, I thought about mentioning it. But it does feel a bit iffy, mathematically. If you were to write a product function, you couldn't use it since the multiplicative identity is one, not zero.
Compose as a macro instead of a function would probably work best...
How about this? #[get("/&lt;isin&gt;")] fn latest(isin: String) -&gt; Json&lt;Value&gt; { match Price::newest_by_isin(isin, &amp;establish_connection(&amp;database_url)) { Some(price) =&gt; { Json (json!({ "status": 200, "result": price, })) }, None =&gt; Json (json!({ "status": 404, "result": null, })), } }
3rd week of Rust and I've hit the lifetimes road bump... It was bound to happen. What's a best practice for lifetime annotations for this? struct Control { pub id: i32, } impl Control { fn new(id: i32) -&gt; Control { Control { id: id } } } struct UI { pub control: &amp;Control, } impl UI { fn new(c: &amp;Control) -&gt; UI { UI { control: c } } } fn main() { let c = Control::new(99); let ui = UI::new(&amp;c); println!("{}", ui.control.id); } 
I wrote a simple learning project. It is more like a step by step tutorial. It is Rust wasm without npm or web-pack. Maybe it can help: https://github.com/LucianoBestia/mem1
If you return None, the you return a 404 Error by default. Any Some(x) is a 200 status. If you need some more control you could return a Result with Ok(Json(price)) or Err(NotFound(String)) where the String is the isin number. You could also create a custom responder for even more control.
Which part(s) don't you understand? 
Fair.
Currently: lifetimes and Box objects (Sized as well). The rest is pretty straightfoward. &amp;#x200B; I'm still going through the Rust book and it hasn't touched on these yet.
He's probably asking how the performance on the CI is like, for instance testing Rust on Windows with Travis CI is really, really slow.
&gt;Or am I missing a better way to transform &gt; &gt;Result&lt;T, E&gt; &gt; &gt;to &gt; &gt;Option&lt;U&gt; &gt; &gt;? I would just do this, requires no unstable library let good_res: Result&lt;&amp;str, &amp;str&gt; = Ok("1, 2, 3, 4"); let good_opt: Option&lt;Vec&lt;&amp;str&gt;&gt; = good_res .map(|s| Some(s.split(", ").collect())) .unwrap_or_default(); assert_eq!(good_opt, Some(vec!["1", "2", "3", "4"])); let bad_res: Result&lt;&amp;str, &amp;str&gt; = Err("bad value"); let bad_opt: Option&lt;Vec&lt;&amp;str&gt;&gt; = bad_res .map(|s| Some(s.split(", ").collect())) .unwrap_or_default(); assert_eq!(bad_opt, None); &amp;#x200B;
Hym.. I never used Travis so I can't compare. Here Windows is slower than Ubuntu too, but not so much difference in my opinion.
What I didn't like about the Option&lt;..&gt; route is that it doesn't return a JSON. I'm not a programmer by trait, so I don't know what the best practices for APIs are. But that seemed strange to me.
Rust and other languages like it use a process called "type inference" to deduce the types of variables. If you look up that term there is a lot of information about it online. This process is applied to all types, not just Vec. A consequence of this is that you can often write quite a bit of Rust code without actually annotating the types yourself. The compiler still checks everything, it just saves you from the burden of having to tell it the types it can figure out itself. 
Does that bring a change in maintainers as well? I've been experiencing fairly slow turnaround on pull requests to `image` and related projects.
Maybe this one: http://www.rustacean.net/
what does it return?
Mhm, I am not too sure if I like this. I mean it's certainly better to have something like this in rust than, say, C++ (because C++ has implicit conversions and you could insert string literals into a vector of strings), but I feel like this could hurt general readability of the code. Don't get me wrong, I am usually in favor of type deduction features (like auto/let), but only when the variable is immediately initialized with the value it's type is supposed to be deduced from. What if the vector is declared a the top of a long function and elements are inserted at the very end? It's really hard for readers to figure out what's going on. This design decision feels really weird given rusts usual focus on clarity and readability.
I had the same question initially as well. I am so glad that the change was made. The hidden state was confusing.
I just learned from some web tutorials about x86 64, and when I need some features, I will go search the instruction and find out how to use. So I think you should first try to read some fundamental introductions and begin to write some assembly code, then you can try to learn by doing.
Thanks again, I'm playing around with putting the caching on top of arc-swap and the benchmarks are *really* promising. Now I should write some tests too to check I'm not measuring complete nonsense.
That seems pretty reasonable. What's the `Clone` bound for, though?
In general, everything about Ferris has been put into the public domain; I’m not sure if there are any images of them that aren’t free to use.
But why would you declare a vector at the top, but use it much much later?
It’s a thing different people have different feelings about. I personally find languages with type inference more clear, as they don’t introduce extra names all over the place. And don’t forget this means everything is fully statically typed, still. If you use an IDE, you can have it display the full types of stuff, or show when you hover, etc.
One of the embedded books (I’m not sure if this one is it) is going to be listed as of the next release: https://doc.rust-lang.org/beta/
It’s not necessary, and there’s another reddit thread currently with more details.
Again, I am not fundamentally against type inference. I just think the vector deduce-from-insertion rule could lead to confusion...
It's my thread, since probably nobody saw this
https://en.m.wikiquote.org/wiki/Murphy%27s_law Why rely on the programmer doing the right thing when you can have the language enforcing it? 
Type annotations are a worthwhile price to pay for type safety. In the python example, the interpreter doesn't know if the return parameter of the first function is compatible with the second function until it actually runs it, and raises an error inside of the function's implementation.
The state of the buffered writer should still be in a valid state after a failed flush. Given that this is an NFS drive, I'd assume it's just somewhat bad error reporting of a network issue or something like that from the driver.
The problem is not that iterators or others not work well. Is that BUILD your own is DAMM HARD. Is rust, is VERY hard to make generic code.
Well if it's worthwhile strongly depends on your application. If you just need to try something quickly, it's easy to come up with the Python solution to do it's job and discard it afterwards (or wrap it in a try-except). The Rust solution is an engineering Challenge you have to really think about, but you'll have a stable solution afterwards to integrate into some Module or toolbox. Imo it's just different usecases.
&gt;We use the borrow checker to ensure that there's only one of these checked out at any given time. (2.5) So nice, thanks a lot! Once I get the \`embedded\_hal\` thing running, I'll take care of that :D &amp;#x200B; After reading the docs from embedded\_hal, I have some questions I'd like to ask, if you don't mind. The standard linux i2c-dev interface provides me with * `smbus_write_byte_data(REGISTER, BYTE)` and * `smbus_read_byte_data(REGISTER)` Of course there is more, but it's the basic building blocks for my driver. However, these operations are with single bytes only. I am confused about the Read/Write API from embedded\_hal. I think some of it is due to my lack of experience with microcontrollers, others due to the difference to i2c-dev * `fn read(&amp;mut self, address: u8, buffer: &amp;mut [u8])`: *Reads enough bytes from address to fill buffer.* What happens if my buffer is bigger than the what the address returns? Simply put in the front of the buffer? What happens if buffer is too small? Simply skips rest of data? * `fn` [`write`](https://docs.rs/embedded-hal/0.2.2/embedded_hal/blocking/i2c/trait.Write.html#tymethod.write)`(&amp;mut self, addr: u8, bytes: &amp;[u8]):` *Sends bytes to slave with address.* **Where is the Register access?** What happens, when buffer is too small? Simply skips the rest? * `fn write_read(&amp;mut self, address: u8, bytes: &amp;[u8], buffer: &amp;mut [u8])` *Sends bytes to slave with address and then reads enough bytes to fill buffer in a single transaction.* Again, where the register access? Do the \`bytes\` refer to them? Is it an array, in case we have a &gt; 8 bit register address? (4) I'll have to experiment with a the hardware timer for sleep/wake to control the reading frequency vs the Delay trait. &amp;#x200B; &amp;#x200B;
It may just be me, but I've never found it VERY hard to write generic code in Rust. Sure, it isn't as easy as it would be in Haskell or Idris, but relative to many other languages it is quite easy. Building your own isn't that hard as well. Oftentimes you can use many of the same patterns as found in `Iterator`. It should also get easier and easier to write generic code in Rust over time. That is certainly one of my goals as a language designer.
Is this what you intend to do? [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=8ee5e3090365fc6af066618c07a4f7dc](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=8ee5e3090365fc6af066618c07a4f7dc) As u/JayDepp said, you need to have a lifetime for the box, and also fix some mutability stuff (which is why I am not sure this is what you want).
The rust version everytime someone uses it the compiler tells them immediately if they did something wrong. The Python version everytime you have a new use of it you potentially get bugs you won't know about until runtime, which can go a long time without being discovered if it's in a rare path.
Interesting. I didn't know google was that invested in rust. Beyond fushsia, what google projects are known to use rust?
ctrl+f?
Oh, if you're going through the book, that's great! Feel free to ask on users.rust-lang.org when you get to those parts if you have trouble understanding them. Lifetimes can be tricky to understand, but `Sized` is just a requirement that an object have a known size at compile time. An example of something that can't have a known size until runtime is a slice: a function taking a reference to a slice as an argument must not assume the size of the slice, because it should be able to handle slices with any number of elements. As for `Box`, what programming languages are you already familiar with? It's somewhat similar to `unique_ptr` in C++. 
What I meant was that with Python you often times just code something up in the REPL and don't actually build it into some sort of system. You use it once to get an answer to some kind of Problem and it's never even saved to some file. That's when being able to "just do it" is immensely helpful and you gladly sacrifice the checks. Also: this composition is very common in Python and it often time just doesn't matter what your data is (for example for a cache) or other times it's obvious what kind of Data you need (Database synchronisation decorator: If you try to synchronize an int or something you're a dumbass and should have it break on you :D.). Again, it's different use cases and it often times is worth it, to not have that added security but have flexibility and an easy implementation instead.
Mount your NFS volume with the `hard` option.
You can also choose to do this at runtime without needing to change the compiler optimization level by using [`_mm_tzcnt_64`](https://doc.rust-lang.org/core/arch/x86_64/fn._mm_tzcnt_64.html), assuming that you follow instructions here for dynamic CPU feature detection: https://doc.rust-lang.org/std/arch/index.html
The workarounds you have correctly pointed out are needlessly complicated, but having a preference for IEEE vs. something else doesn't have really have any impact on resolving this issue for good. &gt; You don’t seem to have mentioned what it is, and I don’t think I can guess what it might be, given the claims you have made about it. Consider this: ``` // Equals trait Equals { fun equals(other: Self) -&gt; Bool; } impl Equals for Bool { fun equals(other: Bool) -&gt; Bool = self == other; } impl Equals for Int { fun equals(other: Int) -&gt; Bool = self == other; } impl Equals for Double { fun equals(other: Double) -&gt; Bool = self == other; } // ... other impls ```
I'm trying to use this with `hyper` but am running into the issue ``` error[E0277]: the trait bound `failchain::BoxedError&lt;error::ErrorKind&gt;: std::error::Error` is not satisfied --&gt; src/main.rs:68:10 | 68 | .serve(|| { | ^^^^^ the trait `std::error::Error` is not implemented for `failchain::BoxedError&lt;error::ErrorKind&gt;` ``` Is it intentional that these custom errors don't implement std's `Error` or is there a blanket impl somewhere that I'm missing?
&gt; other times it's obvious what kind of Data you need (Database synchronisation decorator: If you try to synchronize an int or something you're a dumbass and should have it break on you :D.). I have worked lots on Python code bases. On any non-trivial code base it becomes non-obvious very quickly. No type annotations means you can read pages of code without knowing what type anything is. Also you are only thinking of things where the type is hard to confuse -- there are lots of subtle mistakes people make and without ever realizing they are a form of type errors -- mixing up a list with the first element of the list, getting the order of arguments to a function wrong, forgetting an argument to a function, list of characters vs string, etc etc
&gt;def compose(fn1, fn2): return lambda x: fn2(fn1(x)) &amp;#x200B; More fair comparison is (I allowed myself to fix the order of arguments): from typing import Callable, TypeVar A = TypeVar('A') B = TypeVar('B') C = TypeVar('C') def compose(fn1: Callable[[B], C], fn2: Callable[[A], B]) -&gt; Callable[[A], C]: return lambda x: fn1(fn2(x)) c = compose(str, len) # reveal_type(c) # → Revealed type is 'def (typing.Sized*) -&gt; builtins.str*' assert c([1, 2, 3]) == str(len([1, 2, 3])) == '3' But Python is still easier to type because everything is a late-bound GC'd reference and this simplifies a lot - so there's no distinction between T, Box&lt;T&gt;, impl T and so on.
It’s very popular in Node, Go and PHP as well. I’m not familiar with other languages but I would assume that others use it as well. 
Probably should submit the slow bit counting loop as an LLVM `cttz` issue. I know of no reason not to use a binary search in the slow path.
Disclaimer: I am not an attorney. None of this constitutes legal advice… The Ferris trademark may be either abandoned, in which case its use is uncontrolled, or it may be registered and enforced, in which case some kind of license would be needed to publish any image of Ferris. I suspect the former. The copyright on Ferris images is separate: the individual content creator must grant a license for use of each published image of Ferris. Only those images that have been licensed under some free license would be free to use. Attorneys I have talked to have suggested to me that assigning IP to the public domain may not even be a thing in the US: the term "Public Domain" is a legal term of art, and there are specific statutes that apply, none of which mention assignment. At the least, somebody should probably create some SVG Ferris images and place them on http://openclipart.org . Alas, I am also not an artist, to speak of.
Sure. They’re technically CC0 for this reason. And obviously each new image can do what they want; I mean that this is the general trend.
How significant is the feature check compared to the operation itself? Is it worth it for a single op, or only when doing it loads of times within a routine?
What's more, there's a version with a very small lookup table plus multiply (based on a DeBrujn sequence) that uses no special CPU features and is likely faster than the binary search.
This is a design decision of the `failure` crate. The reasons for this are complicated, but at any rate, calling `.compat()` on your error, will give you a wrapper type which implements `std::error::Error`. 
Unlikely. You would want to refactor to amortize the check. See the memchr crate for a trick to make it even faster.
I would have to double check what was going on first, before I submit any bugs. 
Use [`serde_json`] and derive `Serialize` for `Price`, then call `serde_json::to_string(price)` to get a JSON representation of your struct.
Probably better to use the [`serde_json`](https://docs.serde.rs/serde_json/) crate for generating the JSON and let Rocket handle generating the status messages. More reliable and easier to read, I think.
[That's cool](https://en.wikipedia.org/wiki/De_Bruijn_sequence#Uses). I am skeptical that LLVM would take it, because of the table, but I could be wrong.
What about imageproc
Nice username.
Yeah, that's probably the way to go. Thanks!
I got this while reading from and writing to the same file from one thread
Yes, that's exactly right. I needed to do something like that; but I have trait objects, and introducing lifetimes into those is going to be a bit more complicated than I originally thought. This is for part of the Pushrod project, and I'm still trying to wrap my head around this. This is the first time I'm biting the bullet and playing with lifetimes, which I was hoping to avoid. (I wanted to keep things as simple as possible!) But it's good I'm running into these issues _now_, rather than way later into the project. Thanks, u/rafaelement and u/JayDepp!
In fact, Hexagon support got added in 2017. https://github.com/rust-lang/rust/pull/41524 explains how you can use it.
Where can I read more about updates regarding the "streaming" part? I tried using \`nom\` a few months ago to write parsers for certain polygon mesh formats. These files can get huge, so I absolutely needed a streaming parser. Unfortunately, I decided against nom back then, because it did not work for my use case. So now I have my own parsing utilities. I would love to switch to nom, if it would work for my case. So yeah: where can I find more information about this? \^\_\^
It would be useful to know the following to be able to help: - are you using a Redis client and if so which one? - can you provide a code snippet of your current approach? - how long disruptions do you need to handle (seconds, minutes, hours)?
I'm going to need to do some learnin' on unique_ptr. I guess, what I'm lacking, is use cases. I mostly work in Python, JS and, sometimes, C#. Pointer magic isn't my strong suit but I understand them.
Are animated gifs in the scope of this project? I only see simple ones in the test folder.
...ah, well, in that case you should learn about `Box` first, as learning about smart pointers in C++ would be a bit of a circuitous detour! Do you know the difference between `struct` and `class` in C#? 
We're getting into the nitty-gritty of I2C. SparkFun has [a great article about I2C](https://learn.sparkfun.com/tutorials/i2c/all). We'll pay close attention to the Protocol - Data Frames subsection, which says &gt;\[...\] most slave devices will auto-increment the internal register, meaning that subsequent reads or writes will come from the next register in line. Let's look at an abbreviated memory map of the MPU6050 family (available [here](https://www.invensense.com/products/motion-tracking/6-axis/mpu-6050/)): |Address (hex)|Register Name| |:-|:-| |0x3B|ACCEL\_XOUT\_H| |0x3C|ACCEL\_XOUT\_L| |0x3D|ACCEL\_YOUT\_H| |...|...| |0x41|TEMP\_OUT\_H| |0x42|TEMP\_OUT\_L| |0x43|GYRO\_XOUT\_H| |...|...| |0x48|GYRO\_ZOUT\_L| We observe that all the accelerometer, temperature, and gyroscope register are next to each other. And there's a good reason for that! By passing in a buffer that's 14 bytes large (`(0x48 - 0x3B) + 0x01 = 0x0E`, or 6 bytes for acc + 2 for temp + 6 for gyro), we can get *all* of the accelerometer, temperature, and gyroscope data in one read transaction! let mut buffer: [u8; 14] = [0; 14]; // Read 14 bytes, starting from ACCEL_XOUT_H... i2c.read(ACCEL_XOUT_H, &amp;mut buffer)?; let acc_x: i16 = (i16::from(buffer[0]) &lt;&lt; 8) | i16::from(buffer[1]); let acc_y: i16 = (i16::from(buffer[2]) &lt;&lt; 8) | i16::from(buffer[3]); // The rest of the values... If we did this as 14 separate calls (using single-byte `smbus_write_byte_data` functions), we have to initiate 14 separate read transactions to the same slave device. Given the speed of I/O relative to our processor, this may not be ideal, particularly for a low-power, slower MCU (we can apply the same ideas to database calls, or web API requests). We can answer the question "what happens if the buffer is too big?" We read from the next register, and we keep going until the buffer is full. Writes perform the same behavior: we write to adjacent registers until we've exhausted the buffer. Write-read is just a write, then a read; we follow the same reasoning.
Rust players aren't that amazing it seems.
&gt; Intent to stweb web compatible with wasm-bindgen In case anyone's wondering, I've just merged initial `wasm-bindgen` compatibility into `stdweb`'s `master`! 🚀
Saw the title, completly agreed, saw the content, sighed...
Just happened thirty minutes ago 
You’re looking for /r/playrust . This subreddit is about the rust programming language. 
Follow up: what about the `read()` and `write()` trait methods? * `write()`: to perform a write-only, the register would be the zeroth byte in the buffer, followed by the data to write. So, to write one register, we're looking at a minimum buffer size of two (one address, one data). Subsequent data bytes would be written to the subsequent registers, incrementing by one. * `read()`: this could be used to perform a read in two separate transactions. In practice, I've never used this; someone else might have to chime in.
&gt; Browsers currently don't support this setup out-of-box [I think they do now](https://caniuse.com/#feat=es6-module)
Author here. &amp;#x200B; Thanks for the feedback! &amp;#x200B; The blog post was never meant to be technical nor was it intended to go into details since it would have become far too long. It was just meant to show that it is possible to use rust in an "enterprisey" environment even though there might be a lot of hurdles to take. Especially with a widely unknown technology for a team that owns "critical components". Another message the blog post should have transmitted was that "it is worth it" to consider Rust as an alternative for the technologies currently used in enterprise environments. &amp;#x200B; It was just a (true) story I wanted to tell.
&gt; My two questions are this: If flush fails, can I try again later, or are the File and BufWriter in an invalid state? `File::flush` doesn't do anything (as documented, flush is for the intermediate buffers it doesn't fsync the underlying file). As for BufWriter::flush, it will remove any completed write from its buffer, but keep (and stop) at the first failed write's data. It will only flush the writer it wraps after it's done writing its own buffer.
I'm using the standard redis 0.10. Once I get back to computer I'll get a snippet. I basically want to retry after a certain interval say 30 seconds. I have my redis in a container, and when I'm pushing updates or it crashes, I need my consumers to actively try to reconnect if they fail to poll redis. 
That's not enough. They also need to support loading of `.wasm` via ES2015 module declaration. https://developer.mozilla.org/en-US/docs/WebAssembly/Loading_and_running#What_are_the_options &gt; WebAssembly is not yet integrated with &lt;script type='module'&gt; or ES2015 import statements, thus there is not a path to have the browser fetch modules for you using imports.
I also should say that my project is too complex at this point to go through and add lifetimes to try and get this working. I'm going to have to switch to triggering events to do what I want, unfortunately. I'll eventually figure this out, but this may make my library less usable. :( Could _really_ use some extra eyes on this project, but it's free and Open Source, so I get it. Peoples' time costs money. :)
Cool, I didn’t know that! But makes total sense. Lastly, the Write trait implements write, which doesn’t take a register address, just the bytes to write. But where? How can I pass a register address as well? I can’t thank you enough, seriously! 
Ahhhh. I hadn't thought of that.
Unfortunately the system is shared and so I don't think I have that sort of control over the mounting.
I've been looking into benchmark crates and [criterion](https://crates.io/crates/criterion) says to put files in `$PROJECT/benches/my_benchmark.rs` but how do I benchmark the functions in my project without having to copy and paste them? None of the examples show this being done.
Which code, rustc? All Rust code available on GitHub? ...?
nom supports arbitrary input types as long as they implement some (quite a few) traits that abstract indexing/seeking etc, so you can implement something that streams the bytestring from disk. You can then use the Incomplete-Errors that nom returns to determine whether you might need to stream in more data (although you probably want to stream everything on demand with some buffering? Never quite have done this).
The client receives the HTTP status code separately from the HTTP body. Rocket is already taking care of HTTP status codes for you. Hit your endpoint from the coomand line with `curl -v &lt;url&gt;`
I wrote it mainly because I want to work with Hyper itself, but it gets a little tiresome routing everything manually that way. There are a couple of existing routing libraries, but as far as I can tell, you're bound to their syntax. The traits in Usher are meant to let you design your own matching/parsing setup to suit your needs. It's a general path router, so I have a couple of use cases in hobby projects for filesystems too (I'm using it with Amazon S3 in a couple of places). I imagine most people might use it for the web side though! In terms of the actual routing implementation itself, it's little more than a basic tree - I'm sure there are more efficient algorithms I could put in place instead, I just don't know what they are yet :) 
There is an RFC as well as a PR with an implementation to add this to Neon. It's a commonly asked feature. However, you should be able to accomplish this by blocking in a libuv thread. What issue are you encountering? https://github.com/neon-bindings/neon/pull/375
To be specific, I'm trying to use rayon to execute a JavaScript function for each element in a neon array. It threw an error saying something like std::ffi::void cannot be sent across threads safely.
Just the memory implications (i.e., classes are more expensive than structs).
(Forgive me if this bit is obvious to you.) It seems the Redis client uses `TcpStream::connect` (rather than `connect_timeout`) and provides no reconnection strategy itself. It does expose read and write timeout config so that part should be covered. From your description I take it your Redis container is on the same host as the consumer. Normally, when you connect to a local process, you will get a quick failure because the OS authoritatively knows there is noone listening. Thus connection timeouts will not be a big issue; the likely cause for a long delay is that Redis is busy and it's a good thing you don't try to aggressively try to reconnect. In the above scenario, I would just wrap the client and try to recreate it if it emits I/O-related errors, with a suitable delay (e.g. 1 second). I take it this is what you are doing now. However, if the setup you are describing is a dev setup and you expect to have a consumers running on separate hosts/VMs in production, you may be in trouble as it may theoretically take a long time to get a ECONNREFUSED out of the client socket when you reconnect, aggravating your downtime because TCP retransmission logic is sluggish by modern standards. The simplest way to have this issue is if the ICMP messages from the Redis node are blocked by some packet filter. Also, Docker uses a proxy to bridge the ports, so similar issues may theoretically arise even in a single host if your container does not die when its Redis dies. In such scenarios, a small PR on the Redis client may be in order to allow passing in a connection timeout. Trying to solve this problem outside of the driver is problematic as it effectively means you would have to abandon sockets in the process of being connected. As an aside, if you don't mind losing the current job, you could also make sure the consumer dies on i/o failure and use a process monitor to restart it.
The register address would be the zeroth byte of the buffer, and the data to write would be the first byte. To (hypothetically) write to the MPU's USER\_CTRL register, we'd do let mut buffer: [u8; 2] = [0; 2]; buffer[0] = USER_CTRL; // The register we start at (assuming a const 0x6A) buffer[1] = FIFO_EN | I2C_MST_EN; // The value we're writing to USER_CTRL let res = i2c.write(MPU6050_SLAVE_ADDR, buffer); If `buffer` were 3 `u8`s large, the second value in the buffer (index 2) would write a value to PWR\_MGMT\_1, which is the next register in the register bank. let mut buffer: [u8; 2] = [0; 3]; buffer[0] = USER_CTRL; // The register we start at (assuming a const 0x6A) buffer[1] = FIFO_EN | I2C_MST_EN; // The value we're writing to USER_CTRL buffer[2] = CYCLE | TEMP_DIS; // The value we're writing to PWR_MGMT_1 let res = i2c.write(MPU6050_SLAVE_ADDR, buffer); This kind of behavior is useful if there are a bunch of (writeable) configuration registers next to each other, since we could set them all with one write transaction. No problem! Keep working on your driver; we need more ideas in this space. If you're looking for other examples of MPU drivers in Rust, you can check out the [mpu9250-i2c](https://crates.io/crates/mpu9250-i2c) and [mpu9250](https://crates.io/crates/mpu9250) crates. The MPU9250 is in the same family of motion sensors as the 6050, but it also has a magnetomter.
Yip, I looked into it and saw many things that looked like nom would support my usecase. However, I found that it does not. (I might be wrong though!) &amp;#x200B; The problem was that a nom parser requires complete its input to be in memory completely. You can't "pause" a parser and save its state somewhere and resume it after you loaded more data. So the solution would be to write multiple single parsers whose inputs can't get huge and call them in the right order/in a loop. So this would have worked, but I didn't like the idea to start a parser from scratch again just to load more data (now that I think about it: loading more data while parsing might actually be worse for performance, mh...). Furthermore, I tried to use nom like that and write some functionality for loading more data whenever the nom parser returned "incomplete" errors. But it got convoluted quickly. &amp;#x200B; And after a while I decided to drop nom and write the few helpful parsers myself. All in all, the code got less chaotic because I wasn't forced to use nom's "interface" and could do everything myself. So at that point I was happy to ditch nom, even when I needed to reprogram some small features nom would have given me for free. (Lastly, I wasn't really happy with how nom did error reporting, but I just might have misunderstood it) &amp;#x200B; Again: I could be wrong about that. If so, please tell me. I will try to reevaluate nom 5 in a few months. &amp;#x200B; &amp;#x200B;
Just to check, how are you running this? Did you use release mode?
Okay. A `Box`, `Rc`, or `Arc` in Rust is closer to an instance of a C# `class`, because a variable of one of those types is a pointer to an instance of another type, which must be stored on the heap. `Box` is the most basic, and simply represents exclusive ownership of the object in the heap. 
Ah, you can't send references to Js objects across threads. You would need to convert to native types first. However, it would need to be fairly expensive to see a speed improvement. JS Arrays are very inefficient for FFI because accessing each individual element requires crossing the FFI boundary.
Good question, I \_think\_ it's release mode... [https://github.com/denoland/deno/blob/master/BUILD.gn#L14-L20](https://github.com/denoland/deno/blob/master/BUILD.gn#L14-L20) [https://github.com/denoland/deno/blob/master/tools/http\_benchmark.py#L55-L58](https://github.com/denoland/deno/blob/master/tools/http_benchmark.py#L55-L58) [https://github.com/denoland/deno/blob/86aee7f13751bd4707f6c2fe367be2359fde84b2/build\_extra/rust/rust.gni#L254-L287](https://github.com/denoland/deno/blob/86aee7f13751bd4707f6c2fe367be2359fde84b2/build_extra/rust/rust.gni#L254-L287) Is there some way to confirm on the binary?
I am on my phone and not familiar with Debo’s build system, but if you’re not passing —release to cargo or -C opt-level=3 or -O3 to rustc, then that would certainly explain things.
Does the PR above include this issue? How do I address this issue or mitigate it?
It would partially help. However, what you are trying to do would be very slow. You would get much better performance if you converted to Rust types in a single thread, performed the parallel operation with Rayon and converted back to Rust types in a single thread. The Task API is designed to do this.
I've been working on using fewer `unwrap`s / `expect`s and transitioning to functions to return `Result`s instead of `()`. However, I'm confused about something: my functions which return `Result`s could fail at several points within them (e.g. parsing XML, writing to a file, etc.). So I get what the `Result` payload/value should be, but I don't know what the `Err` type should be since it could be a variety of errors. How should I handle this?
I tried what you guys suggested, and it still doesn't work. I could use some eyes on this code if you guys have time: https://github.com/KenSuenobu/rust-pushrod/blob/0.2.2/examples/simple.rs I am almost at a point of giving up and reimplementing this in a completely different way.
I loved the article! There is [https://crates.io/crates/quadrature](https://crates.io/crates/quadrature), but it predates most of the Scientific Ecosystem. So it may need some updating, PR's wellcome.
It doesn't seem to be passing `-O3` to rustc, though I could be wrong. Difficult to decipher this build system.
Good to see a numerical quadrature crate! A while ago (\~2016) I was looking for such a crate, and ended up having to use bindings to GLSL and QUADPACK. Having a choice of correctly implemented/tested quadrature methods in Rust is definitely important for numerical work.
Granted: impl &lt;T, E&gt; Result&lt;T, E&gt; { #[inline(always)] fn map_or&lt;S, Fn(T)-&gt;S&gt;(self, default: S, f: F) -&gt; S { self.map_or_else(move |_| default, f) } } or impl &lt;T, E&gt; Result&lt;T, E&gt; { #[inline(always)] fn map_or&lt;S, Fn(T)-&gt;S&gt;(self, default: S, f: F) -&gt; S { match self { Ok(v) =&gt; f(v), Err(_) =&gt; default, } } }
If you only use a known amount of different error types in your project and said amount is not that large, you could just define an enum holding all of them plus implement `From` for each one. Let's say, your functions return either an `std::io::Error`, an `MyXMLParsingError` or an `MyOtherError`. Now define: use std::io::Error as IOError; enum Error { IO(IOError), Parsing(MyXMLParsingError), Other(MyOtherError), } impl From&lt;IOError&gt; for Error { fn from(e: IOError) -&gt; Self { Error::IO(e) } } // etcetera Because of the `From`-impls, stuff is compatible with the try-operator `?`, so you don't need to wrap the results of function calls, that's done implicitly for you. fn foo() -&gt; Result&lt;(), Error&gt; { let x = open_something()?; // IO error let x = parse_something(x)?; // Parsing error do_something(x)?; // Other error } If you find that too tedious, you can instead just return a `Result&lt;T, Box&lt;dyn std::error::Error&gt;&gt;` which works with `?` just as well.
The hyper\_hello binary is 1/4 of the size of the debug version which leads me to believe it is passing some optimization level (not sure if -O3, have asked)... gn is definitely confusing.
Quick example combining Neon and Rayon: ``` #[macro_use] extern crate neon; extern crate rayon; use neon::prelude::*; use rayon::prelude::*; fn sum_of_squares(input: &amp;[i32]) -&gt; i64 { input .par_iter() // &lt;-- just change that! .map(|&amp;i| { let i = i as i64; i * i }) .sum() } fn js_sum_of_squares(mut cx: FunctionContext) -&gt; JsResult&lt;JsNumber&gt; { let buf = cx.argument::&lt;JsBuffer&gt;(0)?; let res = { let guard = cx.lock(); let data = buf.borrow(&amp;guard); let arr = data.as_slice::&lt;i32&gt;(); sum_of_squares(arr) }; Ok(cx.number(res as f64)) } register_module!(mut cx, { cx.export_function("sumOfSquares", js_sum_of_squares)?; Ok(()) }); ``` Running 10k loops on `Int32Array` with 100k elements: ``` native: 1783.766ms js: 1315.521ms ``` It's hard to beat vanilla JS on a simple task, but might be able to do it on a machine with more cores.
Is it possible that the binaries are being stripped? That could account for the reduction in size 
Great, thanks!
I'm sorry for this comment, I made it at night and was picturing an intermediate user like myself. I sometimes feel discouraged when learning hard things like this and that's how I pictured the parent commentor, as someone like myself throwing up their hands and saying "this will take months/years to learn". It didn't come out well.
Thank you for the reply! Its an honor to get reply from burntsushi!
Ah good point for the equality comparison!
I wouldn't want to see higher levels of abstraction that obfuscate the language, all in the name of generality. I think that usability should come first. However, I think there's value in trying things out. I personally don't have any intention to try pushing this sort of abstraction, but I'm curious to see what can be done with it. Reductions in learnability would be one of my first reservations too. &amp;#x200B; (I don't think it's entirely unreasonable to imagine that in some cases, APIs could be simplified with higher levels of abstraction; some of the type signatures in the standard library are already quite convoluted. But that could all be wishful thinking: it's difficult to speculate.)
In the `rust.gni` file which build configuration is getting used for the benchmark? If it's `is_official_build` then it's getting `-O` which is synonymous with `-C opt-level=2` afaik. Try explicitly with `-O3` or `-C opt-level=3` off the top of my head opt-level=2 will prefer a size optimization over a performance optimization if there's conflict. someone correct me though
I wasn't aware of it - thanks for pointing it out! I'll set some time aside to browse the codebase :)
[https://discord.gg/9395pj](https://discord.gg/9395pj) &amp;#x200B;
Wrong subreddit
&gt; What I didn’t like about the Option&lt;..&gt; route is that it doesn’t return a JSON. What do you mean by this? The response body? The content type header? A handler with the return type `Option&lt;Json&lt;T&gt;&gt;` should return a JSON serialized representation of T, with the content type set to `application/json` in the response header.
There is an issue on futures-rs which describes the problem: [https://github.com/rust-lang-nursery/futures-rs/issues/1278](https://github.com/rust-lang-nursery/futures-rs/issues/1278)
impl Trait sure made higher order functions a lot nicer.
Every time I hear something like this I have to mention that in the python code and the Rust code, the invariants are the same. The difference is in python those invariants are hidden and when triggered will blow up your program. I'd also like to mention that with a little practice the "Rust solution" isn't so much an engineering challenge as it just becomes second nature. The OP of that SO post was likely a Rust beginner, you'll get used to juggling lots of type constraints &amp; type params over time (though in the beginning I admit it does look like soup until your brain learns to parse it).
"Rust threads" aren't a thing. Rust uses OS threads. So it would be much more accurate to say "NodeJS FFI doesn't work with OS threads".
(Migration is currently ongoing. It should be fine throughout the whole process now, but any transient issues should resolve in the next hours. I'm keeping an eye on it...)
Or Java - something like... &lt;A, B, C&gt; Function&lt;? super A, ? extends C&gt; compose( Function&lt;? super A, ? extends B&gt; a, Function&lt;? super B, ? extends C&gt; b) { return x -&gt; b.apply(a.apply(x)); } ... Function&lt;Integer, Integer&gt; fa = v -&gt; v + 2; Function&lt;Integer, Integer&gt; fb = v -&gt; v * 2; var fc = compose(fa, fb); Just don't mention all of the versions needed for various combinations of specialisation over primitives.
Hmm. Interesting. There are definitely places where equality and identity may be different concepts. I find it interesting to note that in a systems programming language like Rust referential equality is actually a second class citizen, whereas in a nominally high-level language like Python, referential equality/object identity is given an operator of its own, `is` (and numbers will gladly trip you up: in CPython `255 + 1 is 256` yet `255 + 2 is not 257` due to small number interning); and in Java, object equality is relegated to a method, and in JavaScript the language simply doesn’t define any technique (both use `==` for primitive and referential equality). Some of your arguments on equality versus identity are compelling, but not others. Array membership is one where I’d consider requiring both equality and identity to be objectively wrong *in Rust*. (Perhaps not in general—though I believe it still would be—but definitely wrong in Rust, due to its value- rather than reference-orientation.) As a concrete example: an array of strings, `&amp;str` or `String`, I don’t mind which. You wish to be able to check the presence of an element, by string contents, using `&amp;str`. I am currently inclined to believe that your identity comparison function and Rust’s `Eq` trait are in fact representing different things. `Eq` is still deliberately about equality; a total equality, but equality all the same. Not identity. I can imagine it being useful (though not as much as in languages that box everything) to have a new trait to represent identity, but that trait is deliberately not `Eq` (and as discussed, manifestly cannot be). --- On ordering and the distinction between comparability and sortability, you have convinced me entirely that PartialOrd and Ord being required to be the same is an error, and that there are exactly two distinct concepts that would do well to be represented distinctly. With appropriate support from the language in specialisation, it could even be mostly fixed by a new trait, careful trait implementation adjustments (trait coherence would be the greatest hazard here—impl specialisation would probably be unsuitable), and where necessary new methods and old deprecations. This may be worth pursuing at some point (though probably not this year).
.. and on other CPUs it uses bsf, which does more or less the same thing, except for value 0, so rust needs to guard the case where n=0 with an if statement. &amp;#x200B; If you \- know for some logical reason that your argument is never 0. \- work with nightly \- you like running with scissors &amp;#x200B; You can also use LLVM intrinsics like [std](https://doc.rust-lang.org/nightly/std/index.html)::[intrinsics](https://doc.rust-lang.org/nightly/std/intrinsics/index.html)::[ctlz\_nonzero](https://doc.rust-lang.org/nightly/std/intrinsics/fn.ctlz_nonzero.html). 
Loads of clever approaches to this problem. See the list starting here.: [https://graphics.stanford.edu/\~seander/bithacks.html#ZerosOnRightLinear](https://graphics.stanford.edu/~seander/bithacks.html#ZerosOnRightLinear) The parallel one seems like it would be a decent compromise version on most CPUs (i.e. doesn't need any lookup tables or anything like that). &amp;#x200B;
Cargo can produce a static lib that you can just link in your build. For consuming and producing headers: [`bindgen`](https://github.com/rust-lang/rust-bindgen) and [`cbindgen`](https://github.com/eqrion/cbindgen), respectively. There isn't much C++ support, and as far as I've heard, it's generally preferred to just expose C-compatible types and functions to Rust. 
If you were using signed integers you could bitwise and the number with it's negative and get the lowest set bit from that. That would be very computationally cheap. let lowest_set_bit : i64 = num &amp; -num; let lowest_set_bit_index = log_base2(lowest_set_bit) //psuedo code Whatever power of two your lowest set bit is is the "index" of the lowest set bit. You could retrieve this by taking the log base two of your lowest set bit. See \#7 on [this page](https://catonmat.net/low-level-bit-hacks).
You'll need to integrate it into your build system somehow, which i'll leave to you. From there you probably want to use the [`staticlib`](https://doc.rust-lang.org/reference/linkage.html) crate type, which unsurprisingly produces a static library you can link into your application. [Heres how to set it using `Cargo.toml`](https://doc.rust-lang.org/cargo/reference/manifest.html#building-dynamic-or-static-libraries) For actually *using* Rust code from C++ you'll need to expose a C API from Rust and call that from C++. For setting up FFI you may find the follow links helpful [The (small) section on FFI in The Book](https://doc.rust-lang.org/book/ch19-01-unsafe-rust.html#calling-rust-functions-from-other-languages) [cbindgen, a crate to generate C bindings for you](https://crates.io/crates/cbindgen) and it's [github with a better readme](https://github.com/eqrion/cbindgen) [unofficial and slightly outdated FFI book](https://michael-f-bryan.github.io/rust-ffi-guide/) TLDR: expose a C API from rust, build a static library, link em all together.
Thanks for the detail! The C API that I would expose, could I for example have a rust function that would return a struct (or pointer to a struct) that could then be used in the C program, i.e. can I share structs between rust and C?
One small change you could make that would make your code a bit simpler and a little faster would be to avoid reading responses into a string buffer. Reqwest's [Response](https://docs.rs/reqwest/0.9.13/reqwest/struct.Response.html) type implements [Read](https://doc.rust-lang.org/std/io/trait.Read.html) and serde_json has a [from_reader](https://docs.rs/serde_json/1.0.39/serde_json/fn.from_reader.html) function that you can pass it to to deserialize.
What are the C-compatible types that can be exposed? Can I for example share structs and strings between Rust and C code?
I wrote a tutorial on how to work with wasm using *nothing* but the standard rust tooling you'd get when you install rust. No npm, no wasm-pack, no bindgen: https://www.reddit.com/r/rust/comments/9t95fd/howto_setting_up_webassembly_on_stable_rust/ I've used this method to write a toy wasm GUI application using this technique[1], so it's definitely viable. It's just a bit more work. 1: C++/Qt/Wasm for the front end, Rust/Wasm for the backend, linked via imports and js.
You can share structs, I’m not sure about strings and other vector based stuff. To use structs you need them defined separately in rust and in C. In rust you then need to tell the compiler to treat them like C structs using repr(C), where repr is representation.
Yes. I should also have mentioned the `std::ffi` module and the [`libc`](https://github.com/rust-lang/libc) crate, which provide types for FFI. Primitives correspond directly, structs (with `#[repr(C)]`) just work, `String` maps to `std::ffi::CString`, and you can use `libc::c_void` to represent an opaque pointer. The [`Nomicon`](https://doc.rust-lang.org/nomicon/ffi.html) page has more details, and there's plenty more information you can find with google. I brought up C-compatibility thinking of the other direction, though. If there are C++ types you need to expose to Rust, it's likely you will need to translate them to C-compatible types first, so just keep that in mind.
My guess is that it's because it's a weird workload. The latency for hyper is also the most variable, which when you look at the fact that it's simply the latencies for the req/sec test makes some sense. Without looking at how hyper is structured, I can't really speculate on why, but it doesn't seem unreasonable that hyper is optimizing for a more realistic workload.
&gt; String maps to std::ffi::CString I think you meant that C character arrays map to `std::ffi::CString`. Rust's `String` isn't null-terminated and C++'s `std::string` is a class that doesn't correspond to either C or Rust's stuff as far as I know.
What a swell guy! 
Yes, I did, thanks.
&gt; I’m not sure about strings and other vector based stuff. From what I remember, Rust's `String` and C++'s `std::string` have incompatible in-memory representations. However, as long as null termination isn't required, Rust's `str::as_ptr` and `str::len` methods can be used together to get a pointer and length for the memory backing the `str` which can be fed to C++ as long as you don't call down the wrath of the optimizer by breaking any lifetime or mutability invariants.
To have complete control over the response, you can use the [ResponseBuilder](https://docs.rs/rocket/0.3.17/rocket/response/struct.ResponseBuilder.html) to construct a response manually. See the linked docs for a good example. But more importantly: are you establlishing a database connection on each request? You really ought to be using a connection pool and the [State](https://rocket.rs/v0.4/guide/state/) feature of rocket for that. See the `r2d2` crate for a popular connection pool libary (it has implementations for postgres, etc and is easy to extend).
So if I can share pointers, it also sounds like I could share arrays right? So passing a char * back and forth should work? I also assume that I could share arrays of pointers to structs? If this is the case, then I think this would work for our system.
That pretty much matches my expectations. You basically provide what you would to C in either direction, and can the attempt to reconstitute it into something native.
The wild dropoffs in that graph make me suspicious of something not-controlled-for in the environment, but I don't have much experience benchmarking networking code.
Much much much better than Travis. I switched Tokio from Travis to azure and builds went from 90 minutes to 10... and that includes windows which Travis did not do 
Though it is a weird workloads 1400ms seems very high, and that node is handily below 10ms make me think it's a config/compile issue rather than something fundamental with hyper.
Yeah. Rust is designed with the intent that it be possible to incrementally rewrite C programs into Rust. As such, if a C library might expose such an API or a C program might expect such an API, Rust should be able to do it. As was already mentioned, [`std::ffi::CString`](https://doc.rust-lang.org/std/ffi/struct.CString.html) and [`std::ffi::CStr`](https://doc.rust-lang.org/std/ffi/struct.CStr.html) are what you want for `char *`. They're specifically designed to provide safe Rust APIs around `char *` memory. I'm not an expert on FFI, so I don't know the exact proper types to use for arrays of pointers to structs, but it is also possible.
Don't hesitate to follow up with me here or anywhere else if you have questions about what we're doing.
Still seems to be the same when passed -C opt-level=3 ! [https://github.com/denoland/deno/pull/2070](https://github.com/denoland/deno/pull/2070) 
Adjusted here, but doesn't seem to have an effect [https://github.com/denoland/deno/pull/2070](https://github.com/denoland/deno/pull/2070)
Doesn't seem to have an effect! [https://github.com/denoland/deno/pull/2070](https://github.com/denoland/deno/pull/2070)
Really cool create! 
Gosh darn, this is both defeating and super inspiring for me. I just started learning Rust too, but man you are ridiculous farther than me in knowledge. Definitely subscribing to your blog. 
Bad timing, actix-web is becoming 1.0 very soon, a bunch of things will change (although it seems it will be mostly backwards compatible). I think a big thing will be the usage of procedure macros to do things like routing.
It may be a bug, file a issue in hyper and see what they say. Hyper also probably has a gitter or something like that so maybe shooting a message there will be more efficient?
Am i wrong in understanding the trim method as just getting rid of whitespace on the ends? What im having issues with is the "\r\n" that gets attached to the end of all my user given strings
I asked on Gitter and the suggestion was Nagles (TCP\_NODELAY) which didn't seem to work. Will try and get it down to a bug-sized example.
r/playrust 
Could you be more specific about what doesn't work? The example ran fine.
Does this have windows support?
It binds whatever you're matching to a variable. [https://doc.rust-lang.org/1.30.0/book/second-edition/ch18-03-pattern-syntax.html#a-bindings](https://doc.rust-lang.org/1.30.0/book/second-edition/ch18-03-pattern-syntax.html#a-bindings)
Have you heard of a POD type before? POD allows for compatibility between C++ and C, and with that C and Rust. POD stands for, plain old data type, which is a standard data type for this sort of thing. If you can get your lead behind it, it might be more ideal (depending on what you're doing) to create Rust micro services, and then have them talk to C++ through Protobuf or similar.
Thanks and good luck with your project!
Have you heard of a POD type before? POD allows for compatibility between C++ and C, and with that C and Rust. POD stands for, plain old data type, which is a standard data type for this sort of thing. (It's a struct with some limitations. Strings will most likely be one of them. You'll need char*, but you can play around with the adapter pattern to smooth things out, or a similar pattern.) If you can get your lead behind it, it might be more ideal (depending on what you're doing) to create Rust micro services, and then have them talk to C++ through Protobuf or similar.
&gt; What are the C-compatible types that can be exposed? pod types. I wrote about this in another comment.
[https://github.com/web-dom/web-dom/](https://github.com/web-dom/web-dom/)
Looking at the source, seems so.
I have closed 0.2.2's branch, as I added a couple of other features to it. Version 0.2.3 has the bug in it - if you check out 0.2.3, you'll see the lifetime issue I'm working with, and why it doesn't help to add lifetimes where I thought they needed to be. Here's the code, and the offending source line: https://github.com/KenSuenobu/rust-pushrod/blob/0.2.3/examples/simple.rs#L87 While I understand lifetimes need to be added, I tried adding them to the project earlier, and it made no difference; in fact, it greatly complicated matters. I'm hoping this is a simple fix, but I can't figure out what that "simple" fix is. :(
Similar to tests, you `use` your functions to use them. See for example https://github.com/llogiq/bytecount/blob/master/benches/bench.rs (still using `extern crate` here, too – I'm unsure if we can remove this with the 2018 edition, but we'd leave it anyway for backwards compatibility).
Is it basically about running tests within containers? The description of "ensuring developers can replicate any error, any time, anywhere" makes it sound like there's a lightweight runtime component that you'd use in production code to capture much more than just a stacktrace (I've seen similar tech for JVM-based stuff, but not for native code). But reading the one blog post you have makes it sound like it's not that at all, and is more or less only related to testing.
Problem is I cannot simply add a `&amp;mut Tag` phantom type, lest all recursive functions fail to borrowck, see my `tree` test. A `&amp;Tag` feels like it should suffice, but it doesn't. Perhaps I should try to introduce a phantom reference to my Arena?
read the guide [https://rocket.rs/v0.4/guide/responses/](https://rocket.rs/v0.4/guide/responses/) &amp;#x200B;
If you want something like that which supports streaming parsing, there is combine. I am very curious to see how nom 5 comes out though.
Handy reference of "weird symbols": https://doc.rust-lang.org/book/appendix-02-operators.html
Can macOS customize the icon disappeared in the notification?
Hmm... Since its just an example I'm not sure whether this will be simple or not. The problem is essentially that you would need self-reference, so specifying lifetimes isn't gonna help you here. You are borrowing self in the callback, and then storing that callback in self. There are some workarounds, using Rc or an Arena-like thing. Again, its kind of hard to see exactly what's needed since it's just an example, and the do\_something method doesn't even need to be a method.
* work on more sdl2-sys wrapping code. I'm trying to move as many calls to sdl2-sys from main.rs into "nice_sdl2.rs" as I can. A few won't be rustified, but almost everything will be. I'd say I'm at about 90% of my near term goals. The goal is a little less pure safety and more in the direction of being sure that I read and understand every SDL2 function I'm relying on, possibly going all the way to the C source if necessary (though users could theoretically load in some future version eventually, so API contract still marks the limits of what can really be relied upon). * I need more sprite art. So far I have 2-frame grass and 3-frame hero boy. * I still have to decided if I want my backbuffers to focus on argb32 or rgb15 as the common pixel format, but I'm leaning towards argb32.
Still working on https://github.com/svenstaro/miniserve So, miniserve is a self-contained cross-platform CLI tool that allows you to serve some files via HTTP. It now features: - folder download - file upload - basic auth - random route generation - file sorting - and it has some nice themes ;) You may drop SimpleHttpServer now :) 
Still working on https://github.com/svenstaro/miniserve So, miniserve is a self-contained cross-platform CLI tool that allows you to serve some files via HTTP. It now features: • ⁠folder download • ⁠file upload • ⁠basic auth • ⁠random route generation • ⁠file sorting • ⁠and it has some nice themes ;) You may drop SimpleHttpServer now :)
All that is needed is to call a function outside of the scope of the closure. Right now, there's no way for me to access anything contained in "self", so the closure stuff is not only 100% useless, it's 1000% useless.
I never realized I wanted a t-shirt of the "safe vs. unsafe rust" one until now. Available somewhere, anyone?
Doesn't look like it, maybe a PR necessary: [https://github.com/frewsxcv/rust-notifica/blob/master/src/lib.rs#L85](https://github.com/frewsxcv/rust-notifica/blob/master/src/lib.rs#L85)
Well, containers, yes, but a new form of x86 Linux container technology that guarantees bitwise deterministic execution and outputs. In contrast, Docker containers, of course, allow arbitrary nondeterministic OS and HW behaviors. Software testing is the first area we’re going after with this approach (though reproducible builds, in the sense of reproducible-builds.org, also work nicely in these containers). So it’s not about capturing more info from the state of a crashed program (backtrace), but about ensuring that you can reproduce every step of the computation up to and including the error. 
How silly of me, i completely neglected type layout! &gt; The C API that I would expose, could I for example have a rust function that would return a struct (or pointer to a struct) Yes, but not by default. The Rust representation is not C-compaitable by default, but [you can control the finer details of type layout and for structs you intend to expose to C you should use [`#\[repr(C)\]`](https://doc.rust-lang.org/stable/reference/type-layout.html)
I'm doing last year's [Advent of Code] (https://adventofcode.com) puzzles in Rust, to learn the language a bit. So far I'm doing okay, I'm at day 14 now and there are a few tough ones coming up that I'm kind of dreading. All 14 days run in about 0.6 seconds at the moment. I had some help from /r/rust with one of them and looked at other people's solutions for some others. Having a lot of fun so far!
You'll need to clone an Rc of whatever you want to access into the closure, and that should work fine. I'll give a more thorough example tomorrow.
I did the similar thing. I used rust_swig for generation C++ interface for my Rust code and link Rust as static library into C++ binary, you can look on example here: https://github.com/Dushistov/rust_swig/tree/master/c%2B%2B_tests 
Have you thought about proposing your use case to the crate maintainers via an issue? I think you're not the only people who would benefit from a streaming operation; IMO it is almost an essential feature to implement for every codec/format that supports it.
This is what I did few times: 1. Replace build scripts with Cargo and `build.rs` (crates like `cc` and `pkg-config` make this task relatively easy). 2. Rename main function in C code and export it. 3. Import former main function `main.rs` and call it. 4. Gradually oxidize code.
Last touches on `ndarray-stats` before releasing 0.0.2!
ok, makes sense. My semester just started again, so I'll treat this as a side project ;) I hacked together basic read/write support via embedded\_hal last night, but will continue to work on the driver in my free time. I'll let you know when I'm finished/nearing the finish line. &amp;#x200B; Again, thanks so much for your help, have a good week!
This is for use within the compiler itself (maybe it should be moved to `rustc_data_structures`?), and we never allocate ZSTs. If we *do* want to publish any of these arenas on crates.io, we would have to clean them up and add special codepaths for ZSTs.
Also what is this magic [https://github.com/hyperium/hyper/blob/master/src/body/body.rs#L167](https://github.com/hyperium/hyper/blob/master/src/body/body.rs#L167) ? `pub(crate)` &amp;#x200B;
Option image specifier would be very cool. Do all platforms support that?
https://doc.rust-lang.org/stable/reference/visibility-and-privacy.html#pubin-path-pubcrate-pubsuper-and-pubself
Having tar-gz streaming certainly seems like it should be possible. If I'm not mistaken both tar and gz could be used for this, so the combination probably could as well.
It seems that we cannot specify the image directly but we provide a “app bundle” for the notification calls. “Script Editor” in this specific case. And that’s the icon shown.
I created an issue / feature request.
Yeah, some of these are what I meant by binary search. I'd probably use something vaguely like [this](http://github.com/BartMassey/trailing-zeros-rs/blob/master/trailing_zeros.rs). Reasonably small and fast.
Thinking hard about building a fuzzing crate that automatically finds side-channel vulnerabilities in cryptography crates. Going to use genetic algorithms and PAPI. 
https://github.com/rust-community/resources has many versions of ferris in the "stickers" directory.
I'm disappointed about the "option for remote work (within the U.S.)" restriction :-/
With Azure you should be able to auth using OAuth. Our IT kind of did the same (migrated users from LDAP to Azure AD) and I’ve used OAuth to setup auth for an app. I’ve used the Python/Flask example they have on github to figure out how things are working. Take a look at that. It’s pretty basic and easy to follow. 
Out of these, which one is equivalent to a normal `pub`? pub(in path) pub(crate) pub(super) pub(self) 
Before I showed up, my team prototyped a new service in Rust and were able to carry that forward to production implementation. Similarly ye olde gods on high dictated clone of an existing service of ours but on a different platform, we took this as an opportunity to radically update the API which also left scope for a different language for the service layer. Under the hood, we have to write a C wrapper around a bunch of our C++ objects and functions which is a bit of a drag. Obviously this is dependent on having a good cut line in your code where you can expose your interface. The upside is we have demonstrated other languages such as Go on top of the older C++ code.
Just out of interest, what Rust learning material did you spend time with before attempting the puzzles?
Oh, that's a very good point, thank you. :)
I'm aware of that, but I didn't want to wait :D Also, it might be interesting to write a post about migrating this app to 1.0. :)
Keep at it! :) You'll get there eventually.
At least put the version there, because otherwise people will find it while looking for proper tutorials. Outdated tutorials may be more throuble than help.
None of them. They all restrict the full `pub` to some smaller scope.
That's a good idea actually, thx!
None of them, as you can't use the privacy modifiers to export something from the crate. `pub` is basically `pub(the_outside_world)`. `pub(crate)` is basically the same thing if you're in a binary rather than a library though, I suppose, since you'd rarely (never?) do a public export there.
If you'll be working on migration it would be good to fill in our upcoming migration notes https://github.com/actix/actix-web/blob/master/MIGRATION.md#10
In [Ch 16.4](https://doc.rust-lang.org/book/ch16-04-extensible-concurrency-sync-and-send.html#allowing-access-from-multiple-threads-with-sync) it says: &gt; In other words, any type `T` is `Sync` if `&amp;T` (a reference to `T`) is `Send`, meaning the reference can be sent safely to another thread. This suggests to me there is a difference between a Type implementing a trait and a reference to a Type Implementing a trait. Which is doing my head in a little. Is my thinking correct, or what is this trying to say? 
Rho, a new/renewed language design project of mine, and my first experience at designing and developing a programming language. Aims to provide for Rust what Lua provides for C - a highly-integrated, lightweight scripting language. I mainly plan on using it as a scripting API within a game engine. Here are some of the things that I chose specifically for this design: - A simple set of types. The primitives are nonetype, bool, int, float, bytes, string, function, and type. Only compound types are list and table (no custom / named types at the moment). - Dynamic typing, but with strict coercion rules on operations (no weird "5" + 3 cases allowed here). - Reference-free data - all values are copied around from the perspective of the language itself (though heap-allocated items are usually reference-counted in the background). - Patterns, a way to conditionally match and unpack compound types. - Function definitions based on lambda calculus (Haskell). - Rust functions whose parameters/return values can be converted to Rho values can be called just like any function defined within Rho. This is still very much WIP, but I don't think I'll be changing these basic concepts any time soon. Repository at https://gitlab.com/tsukurou/rho is soon to be populated, if you want to follow it or contribute.
Here's a few things I noticed: - `.to_string()` is already done internally by the `{}` formatter. - `$input` will be evaluated twice, which might not be the best for performance and can cause duplicated side effects. Consider storing it in a variable. - It might be possible to generate a full format string and arguments in the macro, avoiding multiple calls to `format!`, but I'm not sure how to go about trying to do that. Maybe take a look at `format_args!`?
Why is the stabilized version not `1.0`? How does this differ from `serde`?
 let points = midpoints(n, a, b); // points is consumed and its memory is reused to hold `f_values` let f_values = points.mapv_into(f); let length = (b - a) / (n as f32); let integral_estimate = f_values.sum() * length; This still seems a bit wasteful, writing back the `f_values`, since you're only using them to sum anyways. I'm not familiar with `ndarray` really and did not get through the docs fast, but maybe something like this should work and edge out a bit of speed: let length = (b - a) / (n as f32); let integral_estimate = midpoints(n, a, b).iter().map(f).sum() * length; 
&gt; As a concrete example: an array of strings, &amp;str or String, I don’t mind which. You wish to be able to check the presence of an element, by string contents, using &amp;str. I think this should work with the design I described: `Identity` may fail, but `Equals` will be true. &gt; your identity comparison function and Rust’s Eq trait are in fact representing different things [...] have a new trait to represent identity, but that trait is deliberately not Eq Yes, absolutely. `Eq` in Rust is equivalent to `Equality`, the new trait representing identity is `Identity` (which does not exist in Rust). --- Thanks, it was a pleasure for me too!
It is indeed a bit wasteful: it would be better, as you suggest, to apply the function on a block of elements, sum them (leveraging SIMD instructions) and then move forward to the next block. This is currently not possible using the methods provided by ndarray on `ArrayBase`. jturner314 is doing some work in this area - see https://github.com/jturner314/ndarray-stats/issues/35 I still used the wasteful solution though, because summing floats is tricky: you can easily introduce a significant numerical error - we have a PR open on ndarray to introduce a better summation method and we are somehow waiting for specialization to merge it (see https://github.com/rust-ndarray/ndarray/pull/577 ). There is definitely room to improve here :)
I guess everything on github.com/rust-lang/rust
For integrating cargo into CMake based build system, you may want to look at: [https://github.com/SiegeLord/RustCMake](https://github.com/SiegeLord/RustCMake) I saved a template for the Rust / C++ ffi myself in a repository. It's a template of how to expose a single class \`foo\` with a method \`bar\`. [https://github.com/pacman82/cpp\_to\_rust\_template](https://github.com/pacman82/cpp_to_rust_template)
But if in my crate I have a module somewhere down in the module hierarchy, and I use a normal pub, that only makes it pub to super as far as I'm aware. Then the super scope has to declare it as pub mod or add a pub use for it, in order to propagate it visibility up the module hierarchy. Am I mistaken?
I actually export everything to make a good API doc. Even being a binary the internal workings may be properly documented, that helps a lot with maintenance.
It's documented at [https://cheats.rs/](https://cheats.rs/) x @ 1 .. 5 =&gt; {} Bind matched to x ; **pattern binding** [BK](https://doc.rust-lang.org/book/ch18-03-pattern-syntax.html#a-bindings) [EX](https://doc.rust-lang.org/stable/rust-by-example/flow_control/match/binding.html#binding). 
And in Haskell it's called "as-patterns": [https://www.haskell.org/tutorial/patterns.html](https://www.haskell.org/tutorial/patterns.html)
It seems like [`rust-notify`](https://github.com/hoodie/notify-rust) recently got macOS support, hence perhaps it would make sense to try to get the Windows-part of this wrapper crate included there aswell? That way one could have a single, powerful, cross-platform notification crate in Rust.
Not sure whether its helpful to you but i found the presentation "Patterns of Refactoring C to Rust: The case of librsvg" interesting: [https://people.gnome.org/\~federico/blog/guadec-2018-presentation.html](https://people.gnome.org/~federico/blog/guadec-2018-presentation.html)
How does it compare with [rr](https://rr-project.org/)?
This could be done correctly with associated impl trait
Good point. But it would have to wait for this RFC to be implemented [https://github.com/rust-lang/rfcs/pull/2515](https://github.com/rust-lang/rfcs/pull/2515), no? &amp;#x200B;
This is definitely macro magic. I can't find the declaration of the `decl_storage` and `decl_module` macros in that repo, either.
Yes, it is macro magic.
All of this is macro magic, as you can see via the call to `decl_module!` that happens in the line before. The `for enum` call could easily be confused with a higher-rank trait bound (https://doc.rust-lang.org/nomicon/hrtb.html) but it looks to me like macro magic.
Thanks very much.
Thank you.
Sorry for the late reply, and thank you all from the deep of my mind, as I understood something about rust that I failed to get until now
A journey of a thousand miles begins with a single step. I'm sure it won't be long until you'll be writing blogs like these and someone else will be inspired by your progress! 
I don't think there is a difference, it's `Send` and `Sync` being specially treated by the compiler. Still, you can express the quoted sentence in normal Rust: unsafe impl&lt;'a, T: 'a&gt; Sync for T where &amp;'a T: Send {} You won't find above impl in `std` though, but the one below (which is written the other way around): unsafe impl&lt;T: Sync + ?Sized&gt; Send for &amp;T {} Furthermore, you can implement a trait for a type *and* a reference to the same type coexisting. impl MyTrait for MyType { fn my_fn(&amp;self); } impl MyTrait for &amp;MyType { fn my_fn(&amp;self); } Nothing extraordinary there.
r/playrust is probably where you want to be. This sub is for the Rust programming language.
After going through all the phases and stabilisation, we'll still be in **active development** mode and won't necessarily guarantee backwards compatibility. `1.0` should be a backwards compatible version. To understand how it is different from `serde`, you can read the documentation and also, [this](https://www.reddit.com/r/rust/comments/b8ik4i/desse_ultra_fast_binary_serialization_and/) reddit post. In a nutshell, currently, this crate only handles `struct`s with size known at compile time and does most of work at compile time.
The issue already exists :)
Yes, `T: Trait` doesn't mean `&amp;T: Trait`, and vice versa. If `T` is a type, then `&amp;T` is also its own type. What complicates this is how the `.` works. A short but vague gist of how `x.do_this();` works is that it 1) dereferences `x` 0 or more times, 2) optionally borrows it once, and 3) calls `do _this` method on the result's type. I remember reading an excellent blog post that explains this clearly, but I don't quite remember where... Anyways, the end result is that you can call methods quite flexibly, without something like `-&gt;` in C. It also creates some confusion... but it's mostly useful. As for how to tell the difference, I'd say it's just whether the impl block says `for T` or `for &amp;T`.
I read a few chapters of the Book. Glad I did, I'm still reading it but haven't finished it yet. 
What source did you look at? It's got windows things right in the [lib.rs](https://lib.rs) file. Or did they add that in the past 6 hours?
Yeah, me too. This is a restriction imposed by a funding source, but as we get future funding we will likely branch out further and become more broadly remote-friendly. (We're impressed with GitLab in this respect.)
Cool crate, but you might want to change the notify method to return a Result&lt;(), SomeErrorType&gt; and don't call unwrap in your code. It is considered bad practice for a library to panic.
Excellent question ;-). Record and replay such as Mozilla rr or [Intel PinPlay](https://software.intel.com/en-us/articles/program-recordreplay-toolkit) (from my old group at Intel) is a different than deterministic execution like our work, [Determinator](https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Aviram.pdf), or [dOS](https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Bergan.pdf), but they do exist on a spectrum. At one extreme, rr will always create a trace file of recorded system-call-level behavior. For the same program, our container will typically create no trace file at all, instead ensuring that running with the same initial conditions (container image) creates the exact same outcome when the computation is reproduced. In some cases, that can have the same ultimate effect as record and replay (reproducing a bug) without spending a lot of disk space on traces. It also becomes easier to do other experiments, like modify the program slightly to print extra log information, that are lost when all you have is the rr trace. That said, they do exist on a spectrum. When you talk to external services outside the determinism "bubble", a deterministic execution system has no choice but to record them (trace file). Conversely, a record and replay system can reduce its trace file size incrementally by making execution more deterministic -- "semi determinism" as [Jason Flinn](https://jflinn.engin.umich.edu/) calls it. 
Cool article, but what do they mean by a "layer-5/layer-7 TCP proxy"? Isn't TCP a layer 4 protocol?
If documentation is the only reason, ou can use `cargo doc --document-private-items` to also document non-exported things instead. Exporting everything allows others to rely on internals of your library/module, so you can never change the internals without breaking them :(
For the non-french speakers: fifty-fifty. J’adore le nom 👌🏻
Could we have something like this? ```impl&lt;T&gt; std::ops::Not for fn(T) -&gt; bool { type Output = Self; fn not(self) -&gt; Self { |x| !self(x) } }```
Thanks
That's how `pub` works, but not how `pub(super)` works - in actuality, the visibility modifiers set the 'maximum' visibility of an item, regardless of the visibility of the parent module. [See this example](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=fe1b8877377f0f0558b052ec4ece1301) - the `pub(super)` item cannot be accessed from outside of `outer`, even though `outer` itself is just a normal `pub` module.
Still working on my discord bot over at [https://gitlab.nebulanet.cc/xacrimon/waz](https://gitlab.nebulanet.cc/xacrimon/waz)
&gt; You then will order the Rust book, see its size, *sigh* and get started. which book, the online and free one, just in print?
You might want to consider giving teardown a default empty implementation because only Windows needs a specific implementation :) 
I'm working on a small private phonebook api, based on rust-jsonrpc with a rust-diesel/postgres database to learn rust. The week before that i read the rust book until chapter 14, but decided that i needed a little project to try out the stuff thats in the book. 
[Not yet](https://github.com/frewsxcv/rust-notifica/issues/1)
Yeah, we need more maintainers!
&gt; As for how to tell the difference, I'd say it's just whether the impl block says for T or for &amp;T. Thanks for your info - I'm trying to digest the idea that a type and a reference to a type can implement different things, but in the meantime, how do I tell if I'm looking at an API doc? For example [Mutex](https://doc.rust-lang.org/std/sync/struct.Mutex.html) tells me that a Mutex implements Send and Sync. Okay. But my take-away from this is that a reference to a Mutex might not. How can I definitely tell if it does or not? 
I believe imageproc will move as well. The maintainer is a member of the new organization.
The underlying gif crate that image uses parses animated gifs just fine. I’m not sure if image exposes an API for getting multiple frames though.
Animated gifs are supported. Here is an example from the docs: https://docs.rs/image/0.21.0/image/gif/index.html#examples
&gt;For the non-french speakers: fifty-fifty. That would be *moitié*, not *moite*. The name translates to sweaty-sweaty.
I don't understand the purpose of this crate. Tuples and structs can be split into any number of parts using pattern matching or destructuring: ```rust let (a, b) = (42, 3.14); let Something { a, b, c, .. } = Something::new(); let (x, y, _) = a; ``` After looking into the documentation, I believe this is only implemented for a tuple `(L, R)`, so what can this crate do that destructuring can't?
Hmm Google asks: "Is it moist and moist?"
Could be very nice to have actions support if the notification tool supports it 
Well yes but actually no... You are right but that's just a shorter way to say it
French is my native language.
I just opened an issue about that, but suggested removing teardown completely and instead implement Drop for the Windows part. This enables exposing the Platform object to the user to reuse (and prevent the overhead of calling setup every time) without the risk of leaking resources.
I'm confused by that example. How does it determine where to perform the split and what problem is it intended to solve?
It came to all of those from Ruby. [godotenv](https://github.com/joho/godotenv): &gt; A Go (golang) port of the Ruby dotenv project (which loads env vars from a .env file) [phpdotenv](https://github.com/vlucas/phpdotenv): &gt; This is a PHP version of the original Ruby dotenv. [Node dotenv](https://github.com/motdotla/dotenv) indicates its heritage a bit more indirectly: &gt; Storing configuration in the environment separate from code is based on The Twelve-Factor App methodology. Twelve-factor came from Heroku, which is primarily a Ruby platform, and was influential in the Ruby community for spreading more widely. The Go, PHP, and Node communities have been heavily influenced by migrants from Ruby (particularly Go). If you look at other language communities where Ruby has been less of an influence - Java, C++, Python - you will not find wide use of dotenv. 
If you export everything, every modification of a data structure is a breaking change. Usually, implementation-specific details aren't exposed from a library, because they aren't part of the API, so you should be able to change them without breaking code.
But it's usually written as ["moit moit"](https://fr.wiktionary.org/wiki/faire_moit_moit). *(author of b-root here)*
There seems to be a lot of \`unwrap\`ing in this code base... are they all safe? Seems like a good idea to reduce the number of unwraps?
Wrong sub, Bro. Try /r/rustgame
+1. It's not good practice for a library to swallow or blow up on errors. Let the user of the library decide what they want to do. Also, perhaps the initialization could be in a `lazy_static`.
Trying to write a language in rust https://github.com/sn99/pakoda I have the a beautiful lexer using regular expression and now need to work on a parser, I intend to make x64 assembly in the end
It can only split things that implement `SplitMut`, and `SplitMut` is only implemented for tuples with two elements.
Looking at the docs, the info seems to be (kind of) all around the place. 1) The trait's documentation should list all implementors. Problem is that some may be generic and thus can't be easily found with Ctrl+F, and I don't think stuff from external crate don't appear here. 2) The type's documentation contains some of the impls for its reference type. For instance, [`u8`'s doc](https://doc.rust-lang.org/std/primitive.u8.html) contains things like `impl&lt;'a, 'b&gt; Rem&lt;&amp;'a u8&gt; for &amp;'b u8`. 3) The [reference type's doc](https://doc.rust-lang.org/std/primitive.reference.html) contains many generic implementation. So when only looking at the API doc, you could look at those places. Honestly, that seems cumbersome. Quick, kind-of-hacky non-doc way to check whether `type` implements `Trait` is to write fn check&lt;T: Trait&gt;() {} and see if `check::&lt;Type&gt;()` compiles.
A proper readme would have been appreciated for an announcement. A motivation and realistic example would be needed, to start with.