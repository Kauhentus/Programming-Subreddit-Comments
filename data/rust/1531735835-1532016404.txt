I was thinking along the lines of [this](https://play.rust-lang.org/?gist=8bf337ec99f07a397fe50b4b65af5c24&amp;version=stable&amp;mode=release&amp;edition=2015). Now that I'm trying it though I'm not sure how to make the macro evaluate the expr. `sizeof` is marked as `const`, but I'm not sure what the state of const evaluation really is...
As /u/savunit already mentioned, it is mentioned in the footer of each page, but to answer your question: I generate the blog itself using [Hugo](https://gohugo.io/) and use the [after-dark theme](https://github.com/comfusion/after-dark). The source files for the blog can be found in [this repository](https://github.com/vbrandl/vbrandl.net) if you are interested.
Your description and the error page give the impression that implementing it that way would be a "what length prefix of what has already been read?" operation rather than a "how many more bytes must be read to complete this?" operation. Implementing it as the latter would allow reading a single byte, then inferring how many more to read to have a valid UTF-8 codepoints based on its contents, which can be useful in situations where an input stream doesn't support any kind of pushback operation for pushing what wasn't necessary back into the buffer to be read by whatever next accesses it.
With some mental effort I can read that. But only because the text is in English, anything else would be unreadable. 
Not exactly what you want but I had good success using the jemalloc profiler. You can also trigger the dump programmatically via jemalloc api which can come close to what you want 
Why in Rust and not in Idris?
It would be a more efficient way to do it, but the existing code doesn't really care for it, and the existing API means you can return data after each call unless you literally got none. Though for TFA I'd expect you'd just read byte-by-byte into a 4-byte buffer until you got a valid codepoint and return that immediately. That is essentially what it's doing right now except less incorrect. The from_utf8 API also makes for returning data on every read unless you literally got none. Your version would need a second read to complete the current codepoint.
* **People, who can read Cyrillic**: What the FFFU.. * **Реорlе шно сап'т геаd Сугіlіс**: ТН15 15 АШЕ5ОМЕ!!! ^((I know Cyrillic))
Wow, that's pretty interesting! I work with boids for more than three years, and I love Rust. To see a project letting them together excites me.
Relations between records are not very programming-language friendly. Typically, I want to get the books written by the current author, with some syntax like `author.books()` or, if you dislike OOP syntax, `books_from(author)`, but all my RDBMS can give me is `books whose id is in the relation books_authors where author_id is my current author's id`, which has to be abstracted someway.
haha. probably true.
&gt; On the other hand, if the call was foo(&amp;s) instead, then only a pointer to the slice would be passed, adding a layer of indirection. IIRC, the compiler can optimize copies and moves to use a reference in case the passed type is very large. &gt; For general heap-allocated types though I'm not sure what you mean. Rust the language does not know about the heap, only the standard library (`alloc`) knows when to call the appropriate syscalls to interact with it. There are no "general heap-allocated types", everything is on the stack. Some types (`std::Vec` and friends) interact with the operating system at construction/destruction to allocate heap memory, but they are usually still using the stack. &gt; So how can you ever tell what &amp; is going to do exactly? It will usually create a reference (barring compiler optimizations). Note that Rust has [implicit dereference coercion](https://doc.rust-lang.org/book/second-edition/ch15-02-deref.html#implicit-deref-coercions-with-functions-and-methods), so it depends on context where the reference is pointing to. For example, functions idiomatically take a reference to a string slice (`&amp;str` which is equivalent to `&amp;(start, size)`) and not a reference to a string (`&amp;String` which is equivalent to `&amp;(start, size, capacity)`). Yet you can pass a `&amp;String` to a function expecting a `&amp;str` thanks to reference coercion: &gt; When the Deref trait is defined for the types involved, Rust will analyze the types and use Deref::deref as many times as necessary to get a reference to match the parameter’s type. This answers your question: the exact meaning of `&amp;` depends on context and how `std::ops::Deref` is implemented for your type and for the other types down the `Deref::deref` chain.
Very cool. Thanks for educating me on this. It turns out I knew surprising little about how vim handled text encoding!
To be more specific, more context is required. To put values on the stack, their size has to be known at compile time (the type has to implement `Sized`), there is now way around it. You might have to put the value on the heap using `Box` or similar.
That doesn't look like any boid simulation I've ever seen; it looks like your boids have no momentum i.e. you immediately change their velocity when they find a new center of mass instead of applying an acceleration force. Here's an example of what boids really look like: https://www.youtube.com/watch?v=QbUPfMXXQIY
If you just want to put them in a different file/folder, you can use `include!`. This is not idiomatic though.
Can the Rust compiler (or LLVM) unroll iterator based loops?
And then you want book.author() but it's not there as your "has-a" relations are only naturally traversable in one direction, and you go on and do a loop over all your authors, call books() on everything and see if one matches the book in your hand. If you don't want to type out select * from books where books.id == author.id be my guest, abstract away the `id == id` part and then write something like: books.allBy(author) But at least you didn't box yourself in by prematurely choosing a data representation which comes with very limited access possibilities.
You're correct that there're no acceleration or steering force which explains the weird changes of direction and unnatural movements. This is just basic flocking based on the three rules I did for fun. You can tweak this further by applying more advanced techniques. And this tweaking is left as an exercise to the reader. :-)
I've built an allocator that does this. 
Way too much punctuation. The nested $($...) expansion syntax is especially gruesome.
&gt; I'm not well versed in how current platforms approach this. I would guess that it strongly depends on the gui toolkit being used, but wether the os interface can be seriously abstracted over to provide an os neutral internal api, I can't really say. For what its worth, this has been [tried](https://www.qt.io) [many times](https://www.wxwidgets.org), with mixed success. As you say, making games work cross-platform is easier (eg with unity). But for regular apps there's lots of stuff that is platform-dependant; and which matters to users: - Font rendering - Load / save dialogs - Drag &amp; drop support - Ok / Cancel button placement (its reversed on windows / mac!) - Touch support - Menu behaviour - Save on close behaviour (On mac, apps should resume previous document state when re-opened. Windows should ask if you want to save). - Shortcut keys (ctrl+s vs cmd+s, alt+F4 vs cmd+w and cmd+q, ctrl+c/v vs cmd+c/v, etc) - What does it do when you close all windows? Many mac apps shouldn't quit if you close the last document window. As a user, I don't *want* the apps I use to be OS-neutral. I want them to feel native to the platform I'm using. At least for me, its super jarring when this is done poorly. The worst I've ever seen is inkscape on mac, which feels like its running a slow emulator of a different computer. Its hideous, and it violates basically every convention of the platform. It doesn't even respect the display's native resolution. I'm sure it would be possible to pave over a lot of this stuff, but many of the best cross-platform apps (eg google chrome) do their core application logic in a portable way, then use each OS's native UI libraries to implement the user interface on that platform.
Hmm, curious if anyone knowledgeable enough has started talking/thinking loud about a WASM CPU yet? (Most probably an FPGA prototype for now?) Or are there reasons why this would be a bad idea? [Sorry for maybe going too much OT.]
I wonder if you could use derive to derive a marker trait for your types conditionally based on their size.
Yeah, the $()s were hard to debug, even with vim highlighting paired parentheses.
&gt; I'm not sure what you mean. Rust the language does not know about the heap, only the standard library (`alloc`) knows when to call the appropriate syscalls to interact with it. There are no "general heap-allocated types", everything is on the stack. I think I misread [this section](https://doc.rust-lang.org/book/second-edition/ch04-01-what-is-ownership.html#stack-only-data-copy) as saying that everything that isn't `Copy` goes on the heap. My new understanding is that everything that isn't `Copy` is passed by reference. &gt; `&amp;str` which is equivalent to `&amp;(start, size)` ... `&amp;String` which is equivalent to `&amp;(start, size, capacity)` A `str` is of the form `(start, size, capacity)`, right? So then why isn't `&amp;str` of the form `&amp;(start, size, capacity)`? In fact, what's the difference? The capacity will still be sitting there in memory just behind the `size`, so any pointer to `start` will be pointing to the same location in either case.
In the event that memory fills up with *swap enable* my system becomes unbearably slow until I kill the offending process, disable swap, and enable it again. I prefer to let the OS kill the process instead.
Not really Rust specific, but is it possible to run wasm directly from inside a Firefox extension? I'm going through the Rust to wasm guide, and from all the examples I've seen it always has you load the wasm from an external resource, like the filesystem.
The value is on the heap and the size is known at compile time. Its a *const u8 and I wwnt to cast it to a T, but rightfully so the compiler complains, because I haven specified, that T musf have the same size as *const u8. The question is how do I say that T can only have the same size as *const u8.
Yeah i know! terrible = great :D
Sorry. But I found that funny: `$ cyrconv $(cat src/main.rs)` `цѕе ѕтd::fѕ::{Ғіlе};` `цѕе ѕтd::іо::{ВцfЯеаd, ВцfЯеаdег};` `рцв fп lоаd_тавlе(ратн: &amp;ѕтг) -&gt; Яеѕцlт&lt;(Ѕтгіпg, Ѕтгіпg), &amp;ѕтг&gt; {` `матсн Ғіlе::ореп(&amp;ратн) {` `Ок(fіlе) =&gt; {` `lет геаdег = ВцfЯеаdег::пеш(&amp;fіlе); lет мцт lіпеѕ = геаdег.lіпеѕ();` `Ок ( ( lіпеѕ.пехт().цпшгар().цпшгар(), lіпеѕ.пехт().цпшгар().цпшгар() ) )` `},` `Егг(_е) =&gt; {` `Егг("lоаd еггог. fіlе пот fоцпd.")` `}` `}` `}` `fп іпрцт(ѕтагт: цѕіzе, шогdѕ: &amp;Џес&lt;Ѕтгіпg&gt;) -&gt; Ѕтгіпg {` `lет мцт іпрцт: Ѕтгіпg = Ѕтгіпg::пеш();` `fог (і, _агg) іп шогdѕ.ітег().епцмегате() {` `іf і &gt; ѕтагт {` `іпрцт.рцѕн_ѕтг(&amp;шогdѕ[і]); іпрцт.рцѕн(' ');` `}` `}` `іпрцт` `}` `fп маіп() {` `lет мцт ѕтагт = 0;` `lет агgѕ: Џес&lt;Ѕтгіпg&gt; = ѕтd::епѵ::агgѕ().соllест(); lет тавlе = іf агgѕ[1].еq("flех") {` `ѕтагт = 2; lоаd_тавlе(&amp;агgѕ[2])` `} еlѕе {` `Ок (` `(` `"АВСDЕҒGНІЈКLМПОРQЯЅТЦЏШХЧZавсdеfgніјкlмпорqгѕтцѵшхчz 1234567890!"§$%&amp;/()=?,.-;:_'{[]}&lt;&gt;".то_ѕтгіпg(),` `"DGLQZdfglqz 1234567890!"§$%&amp;/()=?,.-;:_'{[]}&lt;&gt;".то_ѕтгіпg()` `)` `)` `}.цпшгар();` `lет іпрцт = іпрцт(ѕтагт, &amp;агgѕ);` `lет тѵес: Џес&lt;_&gt; = тавlе.1.снагѕ().соllест();` `lет мцт оцтрцт: Ѕтгіпg = Ѕтгіпg::пеш();` `fог с іп іпрцт.снагѕ() {` `fог (і, сl) іп тавlе.0.снагѕ().епцмегате() {` `іf с.еq(&amp;сl) {` `оцтрцт.рцѕн(тѵес[і]);` `} еlѕе { }` `}` `}` `ргіптlп!("{}", оцтрцт);` `}`
To complete the answer, have a look at `std::io`. You’ll find everything you need there, especially `stdin()` in your case.
You know what? 7¯/-/15 15 /\/\4[)/\/355. real 1337 doesn't have letters. Though I'm not expert :)
&gt; My new understanding is that everything that isn't Copy is passed by reference. No, everything that is not `Copy` is moved, which means you cannot reuse the value that was moved. Technically, passing something by immutable reference is copying the reference (`&amp;T` is `Copy` for any `T`, but `&amp;mut T` never is). &gt; A str is of the form (start, size, capacity), right? No, `str` is equivalent to `(start, size)` (or more precisely `(usize, usize)`). &gt; The capacity will still be sitting there in memory just behind the size, so any pointer to start will be pointing to the same location in either case. No, because `str` might not be pointing to a `String`. It's not the same as `&amp;String`! It could also be a string literal (living in the constant memory of the binary) or a different owning container that was verified to be UTF-8 encoded. For example, you could have a function `fn as_utf8(&amp;[u8]) -&gt; Option&lt;&amp;str&gt;` without involving any `String`. 
I need some shared state and want to use a RefCell for this. But I want to prevent the possible runtime panics that come with RefCell if possible. Is there any way to prevent other parts of a program from taking a reference from the RefCell and keeping it alive? My solution is to create a wrapper struct around RefCell and only allow access through closures. This seems to prevent the reference from moving out of the function call but I believe I am fooling myself. The closure gets access to the wrapped value and can return a result. This way reading and writing to the value are possible, albeit in an inconvenient way. struct Wrapper&lt;T&gt; { inner: RefCell&lt;T&gt;, } impl&lt;T&gt; Wrapper&lt;T&gt; { pub fn access&lt;F, R&gt;(&amp;self, func: F) -&gt; R where F: FnOnce(&amp;mut T) -&gt; R { func(&amp;mut self.inner.borrow_mut()) } }
Me either. And I can't really read real 1337, I feel like someone who can read Cyrillic but can't read the latinized cyrllic .:)
I certainly agree that it's more efficient to do it your way. It's just that looking at the posted code reminded me that, sometimes, restructuring things to do that is not an option. (eg. if you're operating within a larger program/framework which, perhaps for legacy reasons, expects you to pop off only as many characters as you need from the input and leave the rest.)
Yes e.g. https://ruudvanasseldonk.com/2016/11/30/zero-cost-abstractions
Yes, the problem is, exposing the SQL (or any other database query language) to all my program components is exposing too much of what should be an implementation detail. And what if I update the schema? How will I know which queries must be updated? Do I have to audit all my SQL queries? Probably, because as soon as I use something that is only interpreted at runtime (like SQL), I lose type checking at compile-time and get runtime errors instead.
But what does the name in ```Cargo.toml``` have to do with the compiler ignoring ```lib.rs```?
Funny it is. Nevertheless: [Useless Use of Cat Award](http://porkmail.org/era/unix/award.html)
I tried that, but that didn't satisfy the compiler.
Yeah, as I said, it's what I had in mind, but it's not really working.
What do I need to run it? Just `cargo run` doesn't seem to work.
Yeah, just cargo run. What’s the error? Haven’t tested anywhere apart from osx.
Rust beginner here. Why is this not working: fn main() { let c = { let d = "Inner String".to_string(); println!("{}", d); let e = d.as_str(); println!("{}", e); e }; println!("{}", c); } d never goes out of scope and is in the same {} block as e. However I get the error: 'd' does not live long enough. 
This was really helpful, thank you.
Haven't looked at your implementation but make sure you're not breaking linearizable semantics with your concurrent request handling.
Hopefully if there's no contention on the lock, it's just a couple of atomic compare-and-swaps? So slow compared to just copying a byte around, but probably still less overhead than the system call to actually read stdin?
`d` goes out of scope at the line before the last `println!`. You need to move the `let d` before the line where `c` is declared: https://play.rust-lang.org/?gist=730e037939ce2e45bc93ad32b8e0d050&amp;version=stable&amp;mode=debug&amp;edition=2015. 
&gt; "~5 fps encoding @ 480p" is the fastest today. A few months ago the fastest was orders or magnitudes slower than that You are confusing the encoding speed `libaom` which has multiple speed profiles, all still very slow at the moment, with the encoding speed of `rav1e`, which started as a simple encoder that just tries to produce intra-only frames that comply with the then unstable AV1 specification. That means hardly any of the complex tools that improve quality and significantly reduce encoding speed were used. Even today, a lot of those tools are still not used, and the encoder still has a long way to go before it starts to compere quality wise. &gt; simply because everyone was working on compression techniques and the bitstream format, and the reference encoder is meant to demonstrate techniques more than for practical use. \1. AV1 is a complex format, way more complex than previous standards. So the reason is not *that simple*. \2. While it's true speed optimizations are not the primary focus before finalizing the specification. It should be noted that, unlike MPEG reference encoders, `libvpx` and `libaom` are meant to be **usable** optimized high-quality reference decoders and encoders. `libaom` already has a lot of SIMD already. Further SIMD and logarithmic optimizations will continue to be pushed for years to come, of course. &gt; There is still a ton of room for improvement. When comparing with x264 note that its earliest git commit is from 2004, and even that is a 32k lines import from CVS. This is quite a head start in terms of work that went into optimizing the encoder. Again, AV1 is a complex format, way more complex than previous standards. Yes there is a lot of room for improvement. But if you are expecting an encoding speed similar to x265, let alone x264, down the line, then I hate to tell you you will be disappointed. It is also worth mentioning that it's not proven yet that the fastest encoding modes in mature AV1 encoders will provide any quality improvement over already mature HEVC or even VP9 encoders.
Sufficiently strictly typed languages (those include Rust) allow you to completely type your SQL. Not sure about also typing the schema side of things but yes such stuff exists. If you "update the schema" in OOP land, you have to do a complete rewrite of literally everything. Which is why noone ever does that. If you choose a proper normal form OTOH database schema changes usually don't invalidate many, if any, queries. Of course, all that might be overkill. OTOH, this whole argument started out as "ORM is OOPs fault", not "is using a database always the best idea".
Turns out Servo has a copy of `Arc` that [has the same problem](https://github.com/servo/servo/issues/21186). It also does not use fences, so you could try if tsan could catch this one?
It is worth mentioning Xiph is effectively a subsidiary of Mozilla nowadays. Everyone working on `rav1e` is on Mozilla's payroll.
Great. Thanks everybody. I know this is a micro-optimization, but I just assume rust have a way out of it :) 
How does this compare to the [rope library](https://github.com/google/xi-editor/tree/master/rust/rope) that ships with the [Xi editor](https://github.com/google/xi-editor)?
And I was thinking about flock(2), file locking. I spend too much time with unix.
\&gt;To elaborate: you're returning e from the inner scope, and that is a referecne to d. Since d goes out of scope at the end of that block, it is deallocated, and therefore e points to a deallocated memory address. Ahhhhh ok that makes sense. Because this works without any problems: fn main() { let c = { let d = 12; println!("{}", d); let e = d; println!("{}", e); e }; println!("{}", c); } That means that int have a Copy trait while Strings (both String as well as str, have a Clone trait, but that clone trait is explicit, meaning that I have to trigger it manually with X.clone() ). Is that correctß
`impl Trait` doesn't work like that - you still need a single return type, it just doesn't need to be explicitly spelled out. If you want to return objects of different types that all implement the same trait, you need to return a `Box&lt;Trait&gt;`.
Thank you. But do I have to `Box` it? It could be more graceful to do something without any `Box`es. If I have to, I'd, anyway, use a `Box`.
&gt; Sufficiently strictly typed languages (those include Rust) allow you to completely type your SQL. Not sure about also typing the schema side of things but yes such stuff exists. How do you do that (typing the schema side too) without rewriting a full SQL interpreter on the rust side? That is a very cool feature, but I'm not sure it's a good use of the community's resources (the time spent on rewriting SQL parsing not being spent on other tasks), plus I'm pretty sure it would make compilation even slower.
`impl Trait` is a placeholder for a concrete type, similar to an input trait bound (it's just that the concrete type is selected by the callee and opaque to the caller). So even if they match the same trait, you can't return different concrete types for an `impl Trait`, you have to return the same concrete type from all paths. Your options here are to return a trait object (`-&gt; Box&lt;Iterator&gt;` and box your iterator objects) or wrap the concrete iterators in an enum which delegates to the relevant object. Incidentally, Reddit does not support "fenced" code blocks, you must use a 4-space indent.
You are correct, the slow part is more the unbufferer reading byte-by-byte than the lock.
They're definitely targeting the same use-case, and have similar designs, so the comparison comes down mostly to the details. It's been a while since I looked at Xi-rope, so take all of these with a grain of salt. But this is what I seem to remember: * Ropey recognizes all 8 of the Unicode-specified line break characters/graphemes, whereas Xi-rope only recognizes Line Feed and CRLF. * Ropey is explicitly intended for use in other projects, with an up-to-date version on Crates.io, thorough documentation, and the goal to hit 1.0 (API stability). * Last time I checked (which was last December, and I was testing against the already-out-of-date Xi-rope on Crates.io, so take this with an especially large grain of salt) Ropey is a bit faster and takes up a bit less memory than Xi-rope for a range of workloads, and generally has more even performance characteristics. * Their APIs differ in various ways. For example, Ropey does edits and slicing in terms of char index, where Xi-rope does it terms of byte index. In general, Ropey provides a larger set of APIs. Of course, I am biased in favor of Ropey, it being my own creation. :-) But Xi is an absolutely amazing project, and obviously consists of a lot more than just a text rope!
The Rust book contains the [following snippet](https://doc.rust-lang.org/book/second-edition/ch08-03-hash-maps.html#creating-a-new-hash-map) fn main() { use std::collections::HashMap; let mut scores = HashMap::new(); scores.insert(String::from("Blue"), 10); scores.insert(String::from("Yellow"), 50); } which creates a `HashMap` from `String` to `i32`. But how does the compiler actually figure that out? The line that initializes the map doesn't have any type hints. Does the compiler actually read ahead to figure out the types? 
However, Mozilla has no decree that everyone must use Rust; people at Mozilla still write (and start new projects in) Python, Go, C, C++, and so on. The goal was always to make the experience of using Rust nice enough that people want to use it, without forcing them to use it (and we all know there's no faster route to hating a language than being forced to use it :P ).
Well, it does not work *yet*, but hopefully in future [it will](https://internals.rust-lang.org/t/extending-impl-trait-to-allow-multiple-return-types/7921).
[removed]
&gt; Does the compiler actually read ahead to figure out the types? That's exactly what's happening. It's called [type inference](https://doc.rust-lang.org/rust-by-example/types/inference.html).
Well what you say is right, but there's another thing at work here. Namely, your new code will also work with non-copy types. That is because you change the line `let e = d.as_ref();`(which creates a reference that will be dangling once d goes out of scope) to `let e = d;` which moves the value of `d` into `e`, which you return at the end of the block (and it gets moved into `c` then). 
Not quite. The difference between your two examples is taking a reference v. moving the value. In the first example, you make `e` a reference to `d` (this would be clearer, had you done `let e = &amp;d` which is vaguely similar to what `as_ref` does). But `d` goes out of scope at the end of the inner block and `d` isn’t allowed to reference it anymore. In the second example you move `d` to `e`. That is, `e` is a value all of its own and can survive the end of the block. The `Copy` trait only plays a role during the assignment of `d` to `e` in that `d` is still available afterwards. But the example would work with a `String` as well: fn main() { let c = { let d = "some".to_string(); let e = d; e }; println!("{}", c); }
I have a list of words in words.txt and I want to load it into a constant at compile time in a Vec/array called WORDS. Is this possible without external dependencies? This does not work: fn lines_from_file&lt;P&gt;(filename: P) -&gt; Vec&lt;String&gt; where P: AsRef&lt;Path&gt;, { // let mut file = try!(File::open(filename)); let reader = BufReader::new(File::open(filename).expect("Cannot open file")); Ok(io::BufReader::new(file).lines().take_while(Result::is_ok).collect()) reader.lines().map(|x| x.unwrap()).collect() } static WORDS: &amp;'static Vec = lines_from_file("words.txt"); 
Ok Thanks. I will have to look at this a bit more. But so far I can say one thing with 100&amp;#37; certainty: Strings in Rust are so ridiculously complicated. I really don't understand how a simple text-string can cause so much complication. All the other features are pretty straight-forward (structs, impls, Enums, etc...). I even understand the whole ownership/borrowing problem. But Strings really are extremely annoying. Sorry for the rant! :-)
Is as_ref and as_str the same thing?
&gt; * 20 days paid service interruption * 5 days paid sick leave * Paid public holidays Wow, benefits I have by law in my country. And besides that, what are you offering?
Depending on what exactly you want to do, you could get away with the [`include!` macro](https://doc.rust-lang.org/std/macro.include.html). If you want to write to a static variable, you probably have to use [`lazy_static`](https://crates.io/crates/lazy_static), which is an external dependency. It is the idiomatic solution for such problems though.
Are there plans to also add `libmvec` to the std library ?
Additionally, the default type for integer literals is `i32`.
Currently you need to use an explicit `enum` if you want multiple return values. use std::fmt::{self, Display, Formatter}; fn g(x: bool) -&gt; impl Display { enum D&lt;T, U&gt; { A(T), B(U), } impl&lt;T: Display, U: Display&gt; Display for D&lt;T, U&gt; { fn fmt(&amp;self, f: &amp;mut Formatter) -&gt; fmt::Result { match self { D::A(a) =&gt; a.fmt(f), D::B(b) =&gt; b.fmt(f), } } } if x { D::A(42) } else { D::B("hello") } } fn main() { println!("{}", g(false)); println!("{}", g(true)); } 
No disagreement here. [The reason](https://vimeo.com/269082446#t=6m52s) to use Rust was mostly technical. Still, to the outside world, Rust as a choice for a new project is less *fringe* and *cool* when it comes from within Mozilla.
&gt; Strings in Rust are so ridiculously complicated That's because Strings in general ARE complicated data structures. Python hides a lot of this because strings there are immutable and there's a lot of copying going on, which systems languages are trying to avoid. If you want to spend some time, check out how to do proper string handling in C :) Rust has improved upon this a lot imho.
You implementation does not have any constraints on the type `T`. However, `transmute` requires that `T` is exactly 8 bytes large. I don't think it is currently possible to specify such constraints using generics. (Unlike in C++, Rust only lets you use types in ways specified by constraints!) Did you consider using a macro instead?
Sort of. `as_str` specifically produces a `&amp;str` while `as_ref` comes from the trait `AsRef&lt;T&gt;` and can be used to make different kinds of references. It is so commonly used that both me and u/KillTheMule misread your `as_str` as `as_ref`.
The only way (I suppose) is filling issue on github with the smallest possible test case.
I've don't think I've ever seen type inference across multiple statements before.
[If Idris has the ressources to do it](https://github.com/david-christiansen/idris-type-providers/blob/master/Main.idr) then rust has them a thousand times over. You'd need to code-generate in Rust's case, but that's not much of an issue (Idris, like F#, can call out to the actual database server during type checking). It's not like typing SQL would be an arcane art.
Continuing work on [ggez](https://github.com/ggez/ggez/), a lightweight 2D game framework. Mostly a week of small things... updating examples, fixing TODO comments, fiddling with unit tests, etc. The big changes have all been made, I think, and now some of the detritus has been swept up too. The only large sub-projects left are fixing some irritating transform bugs once and for all, and reworking audio. After that it's just a matter of polish!
Thanks for your help!
It has a pretty rich history, but most mainstream languages only do deduction, not inference. So makes sense you might not have seen it!
i tried this: `static WORDS: &amp;'static Vec&lt;&amp;str&gt; = include_str!("wordlists/en.txt").split('\n').collect();` but I am getting `a collection of type `&amp;std::vec::Vec&lt;&amp;str&gt;` cannot be built from an iterator over elements of type `&amp;str``
&gt; I really don't understand how a simple text-string can cause so much complication. (Coming from Python) Python does a lot of possibly very inefficient things to make them easier to work with; this isn't acceptable in a language like Rust. Like everything, it's a tradeoffs. Strings are really this hard! They'll get easier with practice.
Haha I am definitely NOT checking out C then ! :-) Thanks for your help!!
&gt; I need some shared state and want to use a RefCell for this. But I want to prevent the possible runtime panics that come with RefCell if possible. These goals feel opposed; the whole point of `RefCell` is the panics. If you could demonstrate at compile time that you didn't violate the rules, you wouldn't need `RefCell` in the first place.
You can always pull the `tests` mod out into its own file. It'd be * `src/my_module/mod.rs` * `src/my_module/tests.rs` In that case.
wasm doesn't support SIMD yet, so it's just plain impossible in that case.
Oh wow, I hope not. Having branches able to implicitly result in different types is not something I would ever want from a language like Rust.
`split` and `collect` are not `const fn`, so this can't work. It should work with `lazy_static` though.
Јцѕт регѵегтеd міпd'ѕ ехсегѕіѕе іп регѵегѕіоп. Ғцппч ехсегѕіѕе.
Isn't Java's Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;(); an instance of type inference on the right hand side?
I'm not sure I'd call that "inference", but I also can't really articulate why. In my mind, it only applies to comparing multiple statements, I think?
If I knew how to do it without transmute I would do it.
up to $130k? ambiguity: Hong Kong Dollars? 
Just FYI, works fine for me on linux.
With all the open source experience behind package signature I prefer it. It’s a bit of work to set up PGP, but in my opinion that is necessary knowledge to credibly publish anything online. 
 $ RUST_BACKTRACE=1 cargo run Finished dev [unoptimized + debuginfo] target(s) in 0.10s Running `target/debug/flocking` thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: "Couldn\'t find any pixel format that matches the criterias."', libcore/result.rs:945:5 stack backtrace: 0: std::sys::unix::backtrace::tracing::imp::unwind_backtrace at libstd/sys/unix/backtrace/tracing/gcc_s.rs:49 1: std::sys_common::backtrace::print at libstd/sys_common/backtrace.rs:71 at libstd/sys_common/backtrace.rs:59 2: std::panicking::default_hook::{{closure}} at libstd/panicking.rs:211 3: std::panicking::default_hook at libstd/panicking.rs:227 4: std::panicking::rust_panic_with_hook at libstd/panicking.rs:463 5: std::panicking::begin_panic_fmt at libstd/panicking.rs:350 6: rust_begin_unwind at libstd/panicking.rs:328 7: core::panicking::panic_fmt at libcore/panicking.rs:71 8: core::result::unwrap_failed at /checkout/src/libcore/macros.rs:26 9: &lt;core::result::Result&lt;T, E&gt;&gt;::unwrap at /checkout/src/libcore/result.rs:782 10: flocking::main at src/main.rs:23 11: std::rt::lang_start::{{closure}} at /checkout/src/libstd/rt.rs:74 12: std::panicking::try::do_call at libstd/rt.rs:59 at libstd/panicking.rs:310 13: __rust_maybe_catch_panic at libpanic_unwind/lib.rs:105 14: std::rt::lang_start_internal at libstd/panicking.rs:289 at libstd/panic.rs:374 at libstd/rt.rs:58 15: std::rt::lang_start at /checkout/src/libstd/rt.rs:74 16: main 17: __libc_start_main 18: _start
Yes but how complicated is it to copy a simple string? My GPU can display millions of shaded polygons per second, but my Rust program is already overwhelmed with handling a few letters/characters? It probably is just my lack of knowledge, but it just seems so ridiculous that a simple string is performance critical. &gt;Strings are really this hard! They'll get easier with practice. I will definitely come back to strings once I finished the book. I’m sure it will make more sense then. Thanks for clarifying. If experienced Rust programmers agree that its hard then I feel lees dumb. :-)
Descriptions reads like it might be IOHK.
Does your monitor support 10-bit color depth?
Just an FYI, when you say "project management", that's a phrase already used for managing dependencies and interactions and planning for a project, rather than github/gitlab interaction with "projects". You may want to consider a different phrase to avoid confusion. 
I am a bit stuck with a compile error, using itertools `chunks()` method: let bytes: Vec&lt;u8&gt; = ... let size: &amp;usize = ... let blocks: &amp;[Vec&lt;u8&gt;] = bytes.iter().chunks(*most_likely_keysize).collect(); In this last line I get no method named `collect` found for type `itertools::IntoChunks&lt;std::slice::Iter&lt;'_, u8&gt;&gt;` in the current scope and a note: = note: the method `collect` exists but the following trait bounds were not satisfied: `&amp;mut itertools::IntoChunks&lt;std::slice::Iter&lt;'_, u8&gt;&gt; : std::iter::Iterator` Thanks for your help!
Rust macros are quite useful, but also a significant wart. There's a longstanding project of work on [macros 2.0](https://github.com/rust-lang/rust/issues/39412), which would be a cleaner redesign of the macro system, with nicer syntax, and proper hygiene. Not sure when it will be completed, but just want to let you know that a lot of people find the current system quite ugly and there is work being done on a replacement.
If you want parsing of the file to be done at compile time I believe the only way to do it is parsing the file in a [`build.rs`](https://doc.rust-lang.org/cargo/reference/build-scripts.html) file, having that spit out an array into a file, i.e.: &amp;["word1", "hello", "goodbye"] And then include that file: static WORDS: &amp;'static [&amp;'static str] = include!("words.rs");
I published my first crate, https://crates.io/crates/mscorlib-sys ! Initial version was based on mscorlib.tlb, which doesn't really display source code organization or modularization of each item. I'm currently working through the .Net reference source site to move each bound struct, type, enum, etc to the correct source code locations, as well as annotate details like what exactly the safearray is supposed to hold (ie, byte[] vs ParameterInfo[]) as well as inheritance details that aren't exposed in the tlb. 
US dollars!
Well if it were \`fn f() -&gt; enum impl Trait\` or \`fn f() -&gt; sized dyn Trait\` rather than \`fn f() -&gt; impl Trait\` it at least wouldn't be implicit. (I say \`sized dyn\` because this looks like a trait object, but with a closed number of alternatives, and a fixed size that is the size of the largest)
&gt; Yes but how complicated is it to copy a simple string? Doing that is not hard in Rust either; you type `.clone()`. The hard part is doing things *without* copies, which is necessary for performance.
Typically contract positions don’t tend to have a benefit package, as the main benefit would be being self employed. So this role is better than most we see. Besides that, they also pay for trips to tech conferences worldwide
That's great, lots of countries do not have that, like the US.
І ам наррч тнат І шаѕ авlе то кеер чоцг мооd цр.
^The linked tweet was tweeted by [@japaricious](https://twitter.com/japaricious) on Jul 14, 2018 22:10:19 UTC (9 Retweets | 60 Favorites) ------------------------------------------------- The Rust community is so awesome that they have already ported ~30 math functions in less than 24 hours. 🎉 [https://github.com/japaric/libm/blob/master/CHANGELOG.md#v011---2018-07-14](https://github.com/japaric/libm/blob/master/CHANGELOG.md#v011---2018-07-14) 11 more functions for [@rustwasm ](https://twitter.com/rustwasm ) support! [https://github.com/japaric/libm/milestone/1](https://github.com/japaric/libm/milestone/1) Go, Rustaceans! Go! ------------------------------------------------- ^^• Beep boop I'm a bot • Find out more about me at /r/tweettranscriberbot/ •
^The linked tweet was tweeted by [@japaricious](https://twitter.com/japaricious) on Jul 14, 2018 00:49:37 UTC (29 Retweets | 84 Favorites) ------------------------------------------------- Want math support in [@rustwasm ](https://twitter.com/rustwasm ) and in core / no\_std? Help us port libm to [@rustlang](https://twitter.com/rustlang) ! [https://github.com/japaric/libm#libm](https://github.com/japaric/libm#libm) ------------------------------------------------- ^^• Beep boop I'm a bot • Find out more about me at /r/tweettranscriberbot/ •
You're right about the hygiene and macro import system, but I haven't seen meaningful discussion of different *syntax*, which is what's being denounced as "ugly" here. (Deciding this using an esoteric example like this is questionable anyway.)
You need to get rid of `.iter()`. The `chunks` method isn't part of the iterator interface. Instead, it's [defined on slices](https://doc.rust-lang.org/std/primitive.slice.html#method.chunks). The `.` operator will automatically deref your `Vec&lt;u8&gt;` into a `&amp;[u8]`, so you can call `.chunks()` directly on the vec. Once you fix that problem, you'll his another error: `collect()` is going to complain that it doesn't know how to build a `&amp;[Vec&lt;u8&gt;]`. There are two issues there. First, `collect` doesn't change the type of the elements. You're asking for a collection of `Vec&lt;u8&gt;` elements, but the chunks iterator is going to give you `&amp;[u8]` elements. If you want to convert each chunk to a vec, you'll need to use something like `.map()` to do that. Second, `collect` doesn't know how to build slices directly. That's because a slice isn't a collection itself, rather it's a reference into something else, usually a vec or an array. I don't think you can build arrays with `collect`, so the most natural type for `blocks` is probably `Vec&lt;&amp;[u8]&gt;` (or `Vec&lt;Vec&lt;u8&gt;&gt;` if you do that `map` step).
Last time I checked pretty much all issues are at least claimed and most of them are merged by now.
But why would you care about what exactly you have under `impl Trait`? Does it make much difference for you as user is it manually or automatically constructed enum under the hood? You'll just use trait methods and you will not even know about "different types" without looking into source code. Yes, there is cost of enum branching in trait impl, but it is problem of crate author to write code efficiently and inefficient code can be written in a lot of different ways.
It seems like all the rust jobs are blockchain, which is a total red flag and complete deal breaker =/. 
Yes and that’s embarrassing for the US. The richest country in the world should have modern social security laws.
&gt; Wow, benefits I have by law in my country. How much do software engineering positions similar to the one being advertised pay in your country?
... no. Stdio has nothing to do with env::args.
Could you elaborate on the red-flag nature of blockchain jobs? I am guessing something to do with how over-saturated with hype blockchain is, that startups using it are probably not utilising blockchain properly, and the owners are just using it to make a quick buck? Something like that?
- I already know Rust pretty well, whereas I'm still beginning with Idris - Rust already has a bunch of libraries for functionality I need: data structures (indexmap), file handling (toml/json files, tarballs), git support, etc. - Rust lends itself to ok-build-times and very fast runtime performance; the last I checked, Idris was pretty slow on the build time front and its runtime performance was an unknown
Though just because something is claimed doesn't mean you can't work on it. Sometimes someone claims something and gets busy.
Yeah, basically. There's nothing inherently fishy about blockchain and it is indeed cool technology, but 99% of the blockchain startups are completely clueless and just trying to make a quick buck. I have no interest in working for someone who thinks "$X, but blockchain!" is a good business plan. 
Sorry for replying so late, but: OpenGL is depreceated, but not removed. I personally doubt that Apple removes it completely, since it would break many apps in their ecosystem. And there are many Apple users that don't use the latest OS, supporting a macOS version that doesn't have OpenGL would take a while to get adoption, so the people without OpenGL would be a very small minority. If Apple decides to remove OpenGL, this means that Firefox would no longer run on these platforms. Since Firefox uses webrender, this would mean that webrender needs to get ported to the new rendering platform (Metal), independent of azul. The current plan for this is to use gfx as a hardware abstraction layer across DirectX, Metal, Vulkan and OpenGL. [There was a talk on this here](https://www.youtube.com/watch?v=ApPJqWD9cDk). This is, however, independent of azul, you'll get more info talking to the servo team. The good news is that I don't need to move a finger to make that happen. And it is likely that Apple won't remove OpenGL for the next years to come, so porting shaders to gfx is a low priority. Right now, azul compiles on a Mac, but displays garbage due to window resizing bugs (i.e. the redraw event is for whatever reason not fired correctly, so it displays garbage when you resize the window). The problem is, I don't have a Mac and running a Mac in a VM is a legally grey area. So buying 500€ Mac hardware (mac mini is the cheapest I could go) just to support a free framework on an OS that I don't use or distribute software on is a bit much to ask. If someone wants to help with the Mac port and debug Mac-specific issues, he's welcome to help. However: For the product that I am currently developing azul for there is a company I know who almost exclusively use macOS. So if I can get them to license my software (written using azul), then I can officially support macOS (because then I would get paid to support macOS). Until then, macOS support is a low priority to me, but I'm happy to accept PRs.
Out of curiosity: what is the relative performance gain of using math support in wasm, compared to linking to the javascript versions, which if I understand correctly is the current way to call these math functions. Are we talking about an order of magnitude better, more, or less?
If Europe probably €60-70K depending on the cost of living. The cool part is that’s straight take home (mostly) healthcare and pensions are separate benefits (with maybe some of that number going to pension, depending). 
404 on the link
I'm pretty sure Brian Goetz calls this type inference.
The only way out of it is knowing the loop length in advance and unrolling it. If you don't know the length in advance, you could use a JIT compiler or several versions of partially unrolled loops that get used depending on loop length.
May I suggest a few improvements? 1. Instead of taking a slice of `u64` as a parameter of `compress`, it would be better to directly take an iterator of `u64`. If I have, say, a `BTreeSet&lt;u64&gt;`, I have no wish to allocate a `Vec&lt;u64&gt;` just to be able to call `compress`. 2. A number of methods are `pub`, which do not seem to need to. For example, what is the point of `read_current_value` being `pub`? 3. A library should rarely (if ever) use `println`; instead your structure should implement `Debug`, and users can print it wherever they wish.
Just a side note here, I didn't misread it, since you can not use `as_ref` here, because that function is polymorphic, that is, it can produce different types, e.g in this case it could produce a `&amp;str` (which is what `as_str` would give you in exactly the same way) or a `&amp;[u8]`. If you don't help the compiler figure out what you want, it will [balk](https://play.rust-lang.org/?gist=16ca278c4acd9d475ca87c46a5c7bea7&amp;version=stable&amp;mode=debug&amp;edition=2015). If you tell it what type [should be produced](https://play.rust-lang.org/?gist=b245f51668623e6eda09bbddeefc3967&amp;version=stable&amp;mode=debug&amp;edition=2015), it all works out and works exactly the same as if you had used `as_str`. 
I share /u/jackie_pwn_asses disappointment regarding rust jobs and blockchain. To me blockchain is a deal breaker for ethical/political reasons. "Fin-tech" is still finance, even if you add "tech" to make it more appealing to the IT crowd. I could expand on that but I think that would be considered off-topic for this sub.
Sure. But I don't think it's fair to really criticize a company for giving what amounts to a very nice package for a huge number of countries. 130k is also a really great salary for many.
&gt;I have no interest in working for someone who thinks "$X, but blockchain!" is a good business plan. YC encourages taglines like this. For example "the uber for X". They feel that this is a very concise, obvious way of expressing your company's value proposition (iirc). So it seems unfair to criticize companies for trying to appeal to VC.
In the scientific world, there's much value in experimentation and interactive environments. Having the classes and functions from numpy, scipy, and pandas available in IPython is the perfect sweet spot.
Healthcare is a separate benefit almost always in the US. It doesn't cut into your gross earnings.
Well, to be fair, YC backed startups are also a big red flag.
I think blockchain is nonsense but I am hopeful that at the very least that the nature of the technical challenges could lead to firming up some of Rust's networking and cryptography stacks. I think [parity](https://github.com/paritytech/parity) may actually be the biggest non-Mozilla Rust project out there.
Hey, I'm trying to do some windows input handling but stuck on how to send events/messages from my window procedure to my vector which is in main(). //main.rs struct Event { wparam: WPARAM } let events: Vec&lt;Event&gt; = Vec::new(); //some other file pub unsafe extern "system" fn wnd_proc( hwnd: HWND, message: UINT, wparam: WPARAM, lparam: LPARAM, ) -&gt; LRESULT { match message { WM_KEYDOWN =&gt; {} //I can put the wparam in my struct here but how do I send it to my events vector? _ =&gt; DefWindowProcW(hwnd, message, wparam, lparam), } }
Yeah, this is a good point, but I also worry about Rust becoming too strongly associated with a field that is full of hucksters and clowns. 
I basically want to enforce that any reference taken is dropped immediately after you've done what you're doing. Storing references would not be possible, so it could never panic.
Even for contractors ? Because it is not mentioned in the job offer.
Yeah, it seems Java does call this "type inference" itself: https://docs.oracle.com/javase/tutorial/java/generics/genTypeInference.html It's possible this is one of those things where different people have different definitions. I'd call this "type deduction". I could also be wrong! FWIW, TAPL doesn't seem to draw a distinction. I did some googling, and found that people seem to use it like this: * Type deduction: monodirectional: Java `var`, C# `var`, C++ `auto`, etc * Type inference: bidirectional: Rust, Haskell `let`, etc That said, I don't know enough of how this actually works in Java to say. I can see both, depending. Does `auto map = new HashMap&lt;&gt;();` work?
For independent contractors, it varies wildly from company to company. Some contractors may negotiate healthcare benefits with a lower salary, while others may just want the higher salary.
This might be related to a bug in mesa with intel graphics that doesn't support sRGB pixel formats. If that is the problem, upgrading to mesa 18 should fix it. [Here's a link to a piston issue about it](https://github.com/PistonDevelopers/piston/issues/1202), but there are issues in many other rust graphics repositories regarding the same mesa bug. If for some reason you can't upgrade to mesa 18, then disabling sRGB in the source of the program you are trying to run should work too.
This seems like a general talk; is there anything Rust-specific here?
Thanks. I'll be upgrading the entire system soon. Maybe that fixes it.
&gt; Yes but how complicated is it to copy a simple string? You're hitting on a core difference between what Python is doing and what Rust is doing. Many string operations in Rust *do not copy the string*. For example, `my_string.trim()` strips off leading and trailing whitespace. Since the result is always a sub-string of the input, `trim` returns an `&amp;str` slice of the input, without making any copies. That's important in a couple ways: - Making copies isn't free, of course. It's not a big deal for small strings, but if you have gigantic strings or a very long list of them, avoiding a copy can matter a lot. - Making copies requires allocating memory. Avoiding allocation means that `trim` works even in environments that don't have an allocator, like in the middle of the Linux kernel, or in the implementation of the allocator itself. It also works in situations where you're worried allocation might fail. All of this machinery around strings -- admittedly a lot of machinery -- is there to make this sort of thing work. Operations that don't need to copy a string don't have to make copies. Operations that don't need to modify a string can work on either owned (`String`) or borrowed (`&amp;str`) input. And when you do borrow, the compiler can make sure that the thing you're borrowing never changes out from under you.
So don't apply. But why pretend that they're doing something wrong when it's the advised behavior?
Finally!
Finally!
Fuck yeah!
There is definitely a [new syntax](https://github.com/rust-lang/rust/pull/40847/files). The big improvement so far is that macros are defined much more like functions: pub macro m($S:ident, $x:ident) { // ... } Because they can be imported just like regular functions, and can be made private, instead of having one big macro in which you have to include helpers within it via re-invoking the same macro with secret arguments, you can just write helper macros instead. This will cut down on one source of the ugliness. The other big source of ugliness is the pattern repetition syntax, like `$($e:expr),*`. It's true that I haven't seen a proposal for streamlining that. One thing to remember is that macros 2.0 isn't fully fleshed out yet. There is a preliminary implementation, but still a lot of work to be done, and there's still some room for more improvements than what has already been written up.
I don't know. Should it or should it not, for this code to work?
If you want to know how to write clean code, go read Robert C. Martin's book "Clean Code". Except that it contains examples on java, it's a great book, with a lot of useful information. I know, rust isn't really OO, but i've managed to adopt most of suggestions from this book to C language, which is also far away from OO languages. So I think most people would find it interesting. As well as other books, of course. 
I never said that they're doing anything wrong, I'm simply not interested in working for them. 
It should not. Most monitors have 8-bit color depth. Expensive ones sometimes have 10-bit but for some reason piston has issues with that. However, it's highly possible that's not your issue.
I've been working on a template compiler in rust. I built a pretty naive version last month, and I've been rewriting and optimizing it. I've tried to be as idiomatic as possible, and I'd love for some people to check out the code and critique it. https://github.com/benchpressjs/benchpress-rs/tree/master/benchpress_sys It's part of a larger project, BenchpressJS, which grew out of templates.js, a small but inefficient templating system. The original JS compiler and this new rust compiler have been great ways to learn about compilers and rust itself. The templating language has a few big constraints. First of all, the original version was _very_ forgiving: - allowed extra tokens - allowed partial property paths - weird helper function syntax - invalid syntax would just print as text - used HTML comment syntax - had inconsistent semantics in different contexts - had interpolation tokens that weren't surrounded in normal syntax The compiled version wanted to be as backwards compatible a possible, resulting in: - algorithm to deal with extra tokens after the first stage of the parser - algorithm to resolve property paths as - additional new, more consistent syntax Because of the fact that it had to tolerate invalid syntax, the lexer/parser had to be more complex than normal, especially since the removal of extra tokens had to be done before the parser tree was created. It was challenging to do this even in JS, but luckily most of the truly difficult work was done by the time I decided to try rust. The rust lexer was the hardest part, as in JS a used Regexs, but in rust I wanted to do it right. Please take a look at the code and let me know what I could improve. Thanks!
I'm working to get lldb into rustup. This week I managed to get everything building in the way I'd like. Then I found out that LLVM 7 had landed, so today I rebased everything. Once it builds, I am going to see how to make this default to mac-only; check to see if we can work around the code-signing issue (by using xcode's debugserver); move my clang and lldb repositories to rust-lang-nursery; and then finally send a PR.
On testing in Rust, you should check out https://github.com/altsysrq/proptest, which is more or less the state of the art of testing in Rust (in my opinion).
I obviously have not tested the numbers, but in many of these wasm posts its a really good idea to keep the fast, high profile code in pure wasm. As the FFI calls to JS can be quite expensive in comparison. For math operations I'm sure you wouldn't want to be calling into JS for a single function call.
Will do; thanks!
Best piece of news is that it will soon land in stable. That makes me happy !
If I am not wrong this kind of feature exist on c++ as well.
Yes that is correct. The "i" gets its data from ".enumerate()" (0,1,2,3,4, etc...)
Skip my Idea to build Rust webassembly target to create webapp for test and debug optical my Softwarerenderer. In the past i wrote a python portal based on wxPython Phoenix. So i created a rust target "cdylib" and create an easy python interface based on ctypes. It works great and safe some dev. time for ui. And its very funny to see the pain python numpy algorithm speed against the rust one :D :D. 
Others have already explained the problem, but you can use a little math as a workaround, if you're prepared to sacrifice a little readability. The following method behaves exactly like the one you've shown, and also compiles. Note that your methods crash when the direction is `Direction::Up` and `rows == 0`, and also for `Direction::Right` and `columns == 0`, because of integer overflow. fn each_start(self, rows: usize, columns: usize) -&gt; impl Iterator&lt;Item = usize&gt; { use Direction::{Down, Left, Right, Up}; let (length, offset, multiplier) = match self { Up =&gt; (columns, (columns * (rows - 1)), 1), Down =&gt; (columns, 0, 1), Left =&gt; (rows, 0, columns), Right =&gt; (rows, 1, (columns - 1)), }; (0..length).map(move |k| (k + offset) * multiplier) }
I wonder, is [this issue](https://github.com/PistonDevelopers/image-png/issues/80) appropriate for a TWIR call for participation? The gist of it is that the `png` crate blindly trusts the declared size in the input PNG image, so the amount of memory allocated to parse a single image is not bounded. This can be used to crash the program that's decoding the image or perform other kinds of denial of service attacks. Sadly I am unable to offer mentoring. The crate maintainers are not particularly responsive either - which is understandable for a spare-time open-source project. If not, is there a better way to highlight the issue? I cannot fix it myself, but I really want a memory-safe and DoS-resistant PNG decoder to exist.
It only doesn't cut into your gross earnings if the employer is paying for it completely. Contractors usually have no health benefits provided, and even standard employees are typically required to pay around 50% of the health insurance cost... or you can decide you don't need health insurance (though with that you pay a penalty tax)
I've been waiting for this!
That’s right bitches, I’m baaaaack!
An issue tracking merging this into upstream `tokio`: https://github.com/tokio-rs/tokio/issues/486
Is it not available for all toolchains? ```error: toolchain 'stable-x86_64-pc-windows-msvc' does not contain component 'clippy-preview' for target 'x86_64-pc-windows-msvc'```
The most direct way would be to put the vector in a static: // Don't need lazy_static if you're on nightly with #![feature(const_fn)] lazy_static! { static ref EVENTS: Mutex&lt;Vec&lt;Event&gt;&gt; = Mutex::new(Vec::new()); }
Yes, it can! [Here is the log](https://gist.github.com/pftbest/350c453af66fc5ea9e50374a50b300dd) and [the code](https://gist.github.com/pftbest/928138387029a3e391909ea74992d061) main.rs:23 is the line with `*m = 1u32;` All I had to do is add a small loop in reader, now I can even reproduce the original issue in std. [Here is std log](https://gist.github.com/pftbest/cd25cde9394c92c500ed3e3179365237). So thread sanitizer is able to catch this after all.
Great stream as usual. Just a question: In Packetizer::poll, you attempt to reconnect if self.state.poll returns an error. But if the server closes the connection [without any outstanding requests](https://github.com/jonhoo/tokio-zookeeper/blob/master/src/proto/mod.rs#L265) you don't return an error. Shouldn't you try to reconnect in that case if you're not exiting?
Components ride the trains like anything else; just because it landed in nightly doesn't mean that it suddenly automatically works with the previous stable :)
Yeah, the job would be almost 100% fitting for me except one thing: I don't know whether that "blockchain project" is actually legit and I don't want to develop scams. If they explained more about the project, it'd be helpful.
The component only exists in the nightly toolchain for now. It’ll reach beta and stable in the near future, if I’m reading that thread correctly. 
The requests and responses are actually all handled by a single event loop, which resolves pending futures as their responses come back. What kind of linearizeability violation were you thinking of?
Because someone will have to maintain that function, and e.g. a match where each arm is a different type is very unexpected and makes code much harder to reason about. It's the whole dynamic vs static type trade-off, and the type system is the main appeal of Rust to me. Dynamically implicitly deciding types would weaken it.
Thanks, that's very helpful!
I don't see what's hard about returning a `Box` and typing `.into()` where needed.
It's actually not entirely clear what should happen in that case. My understanding is that the ZK server should not close the connection unless we have sent a `CloseSession` request first. If it does, it's because the server has crashed or exited unexpectedly in some way. In that case, we won't get a "normal" exit from the server (because we won't get the trailing 4 NULL-bytes that we expect after a regular shutdown), and thus an `Err` will be raised. I think that in turn implies that if the server goes away in the clause that you linked it *must* be because we first sent a `CloseSession`, in which case we shouldn't be reconnecting anyway. But I could be wrong if there's a situation in which the server will simply decide to (cleanly) terminate our connection without us trying to exit first...
Yay! I was having trouble installing clippy just last night, and it worked first try installing it with rustup today. Here's how I installed it since my toolchain is set to default to stable (must also have nightly installed): rustup update rustup run nightly rustup component add clippy-preview Then in my project I can run: cargo +nightly clippy 
I've never met another person in the US that doesn't pay for at least part of their own health insurance.
Is there any way to speed up the RLS in projects with local dependencies? Any time I have a project with a library dep that's not on crates.io it becomes almost unusable, though it's great in most of the other places.
Appreciate the feedback! I'll incorporate these in an upcoming release :)
You're right, I wasn't considering copays when I wrote that comment.
Them problem for me is: * Any trait that is implemented for `()` (e.g. as a no-op or default) becomes a hazard with `impl Trait`, because a wrong `;` at the end will typecheck. * Things like `impl Iterator` might be satisfied by a stray `Option` value. Implicit dynamicalisation to me means less type safety. Making sure I return one specific type isn't something I'd want to have to do in my head in Rust.
Thanks for that. I didn't know until today that `rustup run nightly` was a thing! Solves the problem in my other comment :)
Your implementation of the algorithm for boids seems to be just wrong, if we look at videos with other implementations, which all state they implement the exact same algorithm of Craig Reynolds: [this](https://youtu.be/jPwP6aw1S9I) or [this(https://youtu.be/QbUPfMXXQIY). Additionally, it seems that you took illustration from [here](https://gamedevelopment.tutsplus.com/tutorials/3-simple-rules-of-flocking-behaviors-alignment-cohesion-and-separation--gamedev-3444). So instead of saying that you leave some "exercises" to the reader, you shall either (i) admit that you've implemented the algorithm incorrectly and correct it (ii) say that you implemented something different from the boids algorithm and update the post and the title or (iii) remove the post. The post is just wrong and misleading.
`auto` doesn't exist in Java. Though, they did add the keyword `var` in the latest update, so now you can write var i = 1; instead of int i = 1; which I believe is what `auto` does in C++. Now, if you write var map = new HashMap&lt;&gt;(); map.put("foo", 1); this will compile and run, but the map will be of type `HashMap&lt;Object, Object&gt;` rather than `HashMap&lt;String, Integer&gt;`. So you've lost all type information. Apparently, the compiler is going line by line and `HashMap&lt;Object, Object&gt;` was the best it could come up with. 
A brief google suggests this is the company in question - [https://iohk.io/](https://iohk.io/) At the very least they have a flashy website. Personally I'm not sure I would trust blockchain work. Definite whiff off of it at the moment.
&gt; Now, another question is whether this should be a data race. Maybe the standard should be changed to make this legal code, because maybe there is no optimization that relies on this. Also I wanted to say that there is a reason why C++ memory model doesn't deal with control dependencies. I think examples 5 and 4 of [this document](http://www.cl.cam.ac.uk/~pes20/cpp/notes42.html) show it.
Ok, thanks for the detailed answer. Now I'm wondering if [this arm's value](https://github.com/jonhoo/tokio-zookeeper/blob/master/src/proto/mod.rs#L413) can be matched, if the only way Ok(Async::Ready(())) is returned by poll_read is if if a CloseSession was sent (self.exiting is true) . 
You can also add `--toolchain=nightly` before or after the `clippy-preview` instead. Sort of undocumented, I think. This was how I finally figured out why I could never get RLS to work in emacs.
Ugh, I meant var, yes. Thanks for the elaboration! Very interesting.
Ah, yes, I think you're right. That arm probably can't be reached. I think I had it there based on an (incorrect) intuition that polling a reader that had no data (but wasn't closed) would yield `Ready`, but since that's not the case, we should never hit that case. So maybe change that to just do the match above, and then `assert!(self.exiting)` inside of it?
We're finally riding the trains!!! Wheeee!
I'm not even talking about co-pays. I pay $100 per month out of my paycheck and my employer pays the other half for my health insurance. No one I know has their employer paying 100%.
Does this include libmvec?
For those wanting to use clippy on their stable code, you can run: rustup run nightly cargo clippy This will build your code using nightly, but afaik stable is a subset of nightly, so that shouldn't give any problems. For installing clippy see /u/Tritanium 's [comment](https://www.reddit.com/r/rust/comments/8zdgn0/clippy_is_available_as_a_rustup_component/e2i55dd/)
You shouldn't make demands from someone who is just sharing something for fun and free. He may have just used Craig Reynolds' algo as history and implemented his own twist. Its ok. Relax.
My employer and many many others pay the full insurance besides copays. I get nothing taken out of my paycheck.
I recently needed to be able to pretty-print \`SystemTime\` instances in ISO8601 format. I couldn't find any existing crates which could handle the full range of \`SystemTime\` values, so I ended up porting over musl's implementation of \`gmtime\` using c2rust, wrote a bunch of tests, and then cleaned the result up by hand. I was very pleasantly surprised with how straightforward the process was, I basically didn't hit any unexpected snags, and the result works perfectly! Here's the more full example with links to the original source for anyone interested: [http://play.rust-lang.org/?gist=f9394b6a84444f21c27423d1a5fb8e73&amp;version=stable&amp;mode=debug&amp;edition=2015](http://play.rust-lang.org/?gist=f9394b6a84444f21c27423d1a5fb8e73&amp;version=stable&amp;mode=debug&amp;edition=2015)
Racer has a lot less information than the actual compiler. Specifically it can't really do macros or traits without additional type hints. We're stuck with this in emacs-land until the RLS (and the emacs-lsp package) is more stable. https://github.com/racer-rust/racer/issues/389 https://github.com/emacs-lsp/lsp-rust And I guess this package is a thing? Maybe worth a shot: https://github.com/joaotavora/eglot
shorter: \`cargo +nightly clippy\`
It seems you seriously misunderstood how proposed feature will work. Compiler will generate enum for you and implementation of the target trait. Crate authors will not have to write any additional code. So lets take an example: fn foo(flag: bool) -&gt; impl Display { if flag { 1u32 } else { "foo" } } It will be automatically desugared into: fn foo(flag: bool) -&gt; Self::AnonEnum { enum AnonEnum { B1(u32), B2(&amp;'static str), } impl std::fmt::Display for AnonEnum { .. } if flag { AnonEnum::B1(1) } else { AnonEnum::B2("foo") } } And you will not be able to match on `AnonEnum`, the only functionality available for function users will be `Display` method on this anonymous enum.
Hm, good points. This is why initially I've proposed to use [explicit macro](https://internals.rust-lang.org/t/extending-impl-trait-to-allow-multiple-return-types/7921/37), but I thought it didn't look quite nice.
Thanks! That could be a perfect way to solve my question.
Implementing skipping would be great?
If anyone would like to explore this for `num_traits::Float`, that would be great! https://github.com/rust-num/num-traits/issues/75
Would you be able to possible make an issue with the use case and I would gladly get implementing to support it :)
get\_next\_set's implementation is probably suboptimal. You loop over the bitset until you reach a bit set to one. Granted the density of this bitset is high as per your choice of number of bits. Still it is difficult to predict, so that a lot of branch prediction error. Instead you can use \`u64::trailing\_zeros\` which compiles to a single instructions : [https://github.com/tantivy-search/tantivy/blob/78673172d001a0c4c7c73cdd3d9923fc43fc0312/src/common/bitset.rs#L87](https://github.com/tantivy-search/tantivy/blob/78673172d001a0c4c7c73cdd3d9923fc43fc0312/src/common/bitset.rs#L87)
You'll have to keep in mind that adding a new return branch could then potentially be a breaking change on the public surface of a crate, which would be surprising and an annoying foot-gun. Having said that, being able to return the equivalent of `Box&lt;Trait&gt;` without boxing it would be a nice thing to have.
It is non trivial whether this code is actually correct for all u64 : [https://github.com/tomarrell/rust-elias-fano/blob/master/src/utils.rs#L33](https://github.com/tomarrell/rust-elias-fano/blob/master/src/utils.rs#L33) \[\`u64::heading\_zeros\`\]([https://doc.rust-lang.org/std/primitive.u64.html#method.leading\_zeros](https://doc.rust-lang.org/std/primitive.u64.html#method.leading_zeros)) is a better implementation of msb. Again it compiles to one instruction, and it does not require to study \`f64\` and its \`log\` implementation to know whether it is correct or not. 
I used to work at a shared office, which had a block chain conference every other week. It felt to a large degree that companies were there to take advantage of those who didn't understand blockchain. Namely, who didn't understand the long list of downsides of using a blockchain.
\`msb\` is actually very likely to be a bug on android. I don't know about other platforms.
The guy can do whatever he wants, i personally just don't like that he (or she) says that he implemented a pretty standard algorithm, puts description of it, and then puts a code and a gif that have very little to do with this algorithm (and even defends his post). I also don't like that people upvote this post without even trying to look at how an actual result shall look like (and probably not scrolling to the end of the post). (Omitting the fact that the result obviously doesn't look like flocks of birds). This spreads the culture of upvoting whatever stuff people post with click-baity titles and doesn't do any good to the community. This actually doesn't do any good to this poor guy. This doesn't do any good to the algorithm, which seems to have started a small area of research (the paper is [cited almost 10000 times](https://scholar.google.com/scholar?cites=16816699856673150878&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en) in peer-reviewed journals, it's quite a number). And finally, this doesn't do any good to anyone who will try to implement the algorithm on his own--he/she googles the algorithm, finds this post, and will implement or copy a wrong version. So i see only disadvantages in posts like this and actually think i did something good today :-) -- i tried to make sure that people know that this post is not very good!
That's fascinating, thank you for bringing these up! Just curious, what part of this would prevent it from specifically working on Android? All I see is calling the natural log on a float and then performing a multiplication on a constant. Is there something I'm missing about floats on Android?
Why do you think so? This anonymous enum should be completely opaque to its users, and adding variant should be no different than adding method to a trait with default implementation. Yes, some unsafe shenanigans can be broken with such change, but I don't think it's practical to consider it as part of stability guarantee.
Thanks. See Issue #4 and #5 
Yeah, I am definitely not confident about the stability or necessity of all these blockchain startups using Rust. If I felt that we needed so many blockchain companies in existence I would join in a heartbeat, but there is just no way so many blockchain companies can actually coexist and still be useful. There may end up being only a few actually useful blockchain companies. If you start extending the definition of blockchain to include everything, well then it's truly a moot point, as we have been using things like Merkle DAGs for revision control for a long time, which is much more elaborate than a chain. The point of these blockchains is distributed trust about the sequence of cryptography signed events and the truth is you can only have so many of those before they stop being useful and start having vulnerabilities because they are too small. Then somebody might say, "well lets build on Ethereum then." Okay, then what is it you are adding into the blockchain and why does it need to be part of an ordered public ledger. Usually, the truth is that none of the blockchain stuff should actually be part of such a system unless it involves the transaction of some sort of good or computation (in the case of zksnarks). As you say, many of the coins out there are just scams, and some of these startups are ultimately just temporary to provide tools to companies that wont exist for longer than the flicker of a candle. If somebody is trying to sell something as "blockchain" instead of its actual purpose (like "distributed trust computing"), then they probably don't have anything useful to sell you in the first place. Personally, I am much more concerned than enthused when I see a company trying to hire developers by selling themselves as a "blockchain" company, which is something I think they don't get and most of us probably feel that way. Not saying blockchain is bad or that all developments that use it are bad, but the word itself is definitely more of a red flag than a selling point, particularly to developers, and rightfully so.
My bad, since you round instead of truncating it has chances to give the right result for all values. I thought you were truncating. floating point operations are approximate. base 2 is a special beast because it has a good fit with the actual representation of floating points and some implementations might give perfect precision for powers of two for instance. In rust, it seems like on all platform we use a specific implementation for base2, but for android. On android, we just rely on the napierian logarithm, in which case truncation is very likely to be wrong.
I keep bookmarking your posts and you keep making more. Thats a good thing! Keep up the good work. Your libraries will be useful for my simulations =P.
Actually rounding apparently made it worse :) and your implementation seems bugged. See here: [https://play.rust-lang.org/?gist=a1f228ed6dade1e95858aeef94478514&amp;version=stable&amp;mode=debug&amp;edition=2015](https://play.rust-lang.org/?gist=a1f228ed6dade1e95858aeef94478514&amp;version=stable&amp;mode=debug&amp;edition=2015)
This is awesome news!
No, I understand it. But this if flag { 1u32 } else { "foo" } is surprising magic, and goes against everything that I appreciate about a statically typed language. It would not be hard to generate the enum with a macro, and instead write if flag { 1u32.into() } else { "foo".into() } This reduces surprise, is barely more effort to write, and requires 0 additional language features.
&gt; Now what I'd like to verify is that "i" in the for loop contains the position in the string. A location in an array, I suppose, is the best way I can name it. Not quite. `i` contains not the position in the string/array, but the position in the iterator you called `enumerate()` on. In this case you are iterating over the entire array so they are the same, but consider the following example: let s = "abcd"; let bytes = s.as_bytes(); println!("{:?}", bytes.iter().enumerate().collect::&lt;Vec&lt;_&gt;&gt;()); // prints [(0, 97), (1, 98), (2, 99), (3, 100)] println!("{:?}", bytes.iter().enumerate().skip(1).collect::&lt;Vec&lt;_&gt;&gt;()); // prints [(1, 98), (2, 99), (3, 100)] println!("{:?}", bytes.iter().skip(1).enumerate().collect::&lt;Vec&lt;_&gt;&gt;()); // prints [(0, 98), (1, 99), (2, 100)] (In playground: https://play.rust-lang.org/?gist=ba67cf499ed3911b2c616dfc792506d7&amp;version=stable&amp;mode=debug&amp;edition=2015) The first `println!()`, as expected, has all the bytes with indices from 0 to 3 (including). In the second `println!()` we skip the first pair `(0, 97)` but the remaining three pairs are the same - with the "correct" index. But in the third `println!()` I've swapped the `skip()` and the `enumerate()`, and suddenly byte `98` has the index of 0 - even though it's the second byte and its position in the bytes array is 1. How come? What's happened is that `enumerate()` starts counting on the `Iterator` you run it on, regardless of where the items in that iterator came from. In the third `println!()`, we start enumerating after we skipped the first item, so the "second" item `98` gets to be the first and have the index 0. In the second `println!()` we start enumerating first and only then skip the first item. So the true first item - `97` - gets that 0 index and then we skip both the item and it's index and reach the second item `98` with index 1.
Yes!!!! :) I've been looking forward to this for a year now. Thank you Vitiral!
The semicolon and unit values could fairly easily be linted against. And `Option` values tend not to be just laying around looking for a scope to return from. Even so, I'm 50/50 on this idea, because I don't use `impl Trait` but once in a blue moon. Most of the time I name the type I want returned and there's no ambiguity. And I *never* us it in argument position.
Sorry, but this not work: pub struct RelIter&lt;R&gt; { pos: usize, data: R } impl Row { pub fn into_iter(self) -&gt; RelIter&lt;Self&gt; { RelIter { pos: 0, data: self } } } impl&lt;R: Iterator&gt; Iterator for RelIter&lt;R&gt; where R:Relation { type Item = Row; fn next (&amp;mut self) -&gt; Option&lt;Self::Item&gt; { Some(self.data.row(self.pos)) } } //later for row in r1.into_iter().iter() { println!("{:?}", row); } It claim "Row is not a iterator" and suggest to put iter(), with that, "iter is not found"
This has nothing to do with a culture of up voting. Just don't upvote it, I didn't but enjoyed the read despite that. You just came across as rude and petulant. If you want to have positive change then look at his code and point out what was wrong or do it in a constructive manner. Build people up who share because not everyone does. Keeps the community together
What is the “:?”?
Awesome! Now we just need a decoder.
This might not be an easy question, but I'm looking to build out a long-running job that's going to run on a big-iron file server and do a bunch of file operations. It needs to be able to do this in the background and scale itself down if performance is taking too big of a hit (and potentially terminate if it's just not feasible to keep running because loads are too high). The server is running Windows. Is there a way to get info about how many requests for disk reads and writes are being made? Is there a library I should be investigating for doing Windows system calls? I should probably just do some googling, and I will, but I want some experienced advice too because I want to be careful about making wrong decisions that will be difficult to unwind later.
I pay $60 a month for an upgraded plan but for the regular plan, my employer would be paying the entire monthly bill. It probably has to do with tax deduction maximums that depend on the state or something.
Why doesn't rustup let you customize the installation path and cargo cache path? It seems like a serious omission to not being able to tell it where to install, especially because the default location on Windows is not at all where I want it installed (it winds up on a network share on my work computer).
cant semm to get it working anyone else like this? [https://imgur.com/a/EO9baso](https://imgur.com/a/EO9baso)
Congratulations on finally shipping. I recall having a discussion with you about Yew's routing solution a few months back. I'm glad you were able to put your solution to that problem to work. I see you are using Yew 0.4.0. As a word of warning, prepare yourself for some significant code churn if/when you upgrade to 0.5.0, which should be releasing in the near future. The move to an actor based system changes how a lot of Yew works, namely the removal of the Context object in favor of each component or agent owning its own services.
Prints something as Debug, in other words as the internal structure. Just `{}` prints the Display format which does not exist for Vec.
I'll be ready for it :) I fully support whatever design decisions the Yew author/s makes. That is a _fantastic_ framework.
This just in: people find books interesting :P
`.enumerate()` returns an iterator which for each iteration, yields a tuple of the count as `usize` and the current item of the supplied iterator. It's kind of like if you did this: let values = vec!["apple", "pear", "orange"]; let iter_a = (0..values.len()).into_iter(); let iter_b = values.into_iter(); for (i, v) in iter_a.zip(iter_b) { println!("Item: {} Value: {}", i, v); }
That's crazy. I pay $200 per month and its my only option. I'm jealous.
Looking at your `Cargo.lock`, you are pinned to tokio 0.1.3, which didn't have built-in support for timer 0.2. You need to upgrade it. The interval stream is just dropping the error, if you logged or printed in that map_err, it may have given you a hint that a clock wasn't setup :)
Uninstall any clippies that you installed from source, `rustup self update`, and then do `component add` again, that *should* fix it.
IIRC `println!` uses compiler intrinsics, so the definition is pretty much useless for anyone not working on the compiler.
I'm a bit drunk and read your whole post in Owen Wilson's voice for some odd reason, which made it awesome.
&gt; And Option values tend not to be just laying around looking for a scope to return from. That was just an example. I do sometimes end up with a value somewhere that I forgot to transform, and it's quite nice when the type checker catches that.
cant run \`rustup self update\` i get \`self-update is disabled for this build of rustup\` so i deleted \`\~/.rustup\` uninstalled rustup , purged the packaged and reinstalled rustup with the nighly packages and all to no avail. guess i see if anyone else is suffering the same.
Thanks for taking the time to take a look! Good catch on `guesses_remaining`. I haven't heard of failure::Error so I'll check that out. 
👏👏👏
The compiler is not ignoring lib.rs. It's compiling lib.rs separately from main.rs. To import the library from the binary you need to write `extern crate [crate name here]`. You seemed to be saying you didn't know the name, which is why I pointed you at Cargo.toml. Again, this seems to have gotten twisted around enough that you should just post your code and we'll fix it. 
How exactly do you propose to implement an arbitrary trait over an enum? In particular, ones which have functions with "Self" parameters (other than the first), or which return Self?
For fun I decided to implement actual momentum/turning. Here's the code I ended up replacing the flock code with: fn flock(&amp;self, boids: &amp;[Boid]) -&gt; (f64, f64) { let alignment = self.align(&amp;boids); let cohesion = self.cohere(&amp;boids); let separation = self.separate(&amp;boids); let angle = Boid::angle(self.vx, self.vy); let desired_vx = self.vx + alignment.0 * ALIGNMENT_WEIGHT + cohesion.0 * COHESION_WEIGHT + separation.0 * SEPARATION_WEIGHT; let desired_vy = self.vy + alignment.1 * ALIGNMENT_WEIGHT + cohesion.1 * COHESION_WEIGHT + separation.1 * SEPARATION_WEIGHT; let desired_angle = Boid::angle(desired_vx, desired_vy); let angle_diff = { let diff = desired_angle - angle; if diff &gt; PI { diff - PI * 2.0 } else if diff &lt; -PI { diff + PI * 2.0 } else { diff } }; let new_angle = if angle_diff &gt; 0.0 { angle + angle_diff.min(MAX_TURN) } else { angle + angle_diff.max(-MAX_TURN) }; Boid::velocity(MAX_SPEED, new_angle) } fn velocity(speed: f64, angle: f64) -&gt; (f64, f64) { let (sin, cos) = angle.sin_cos(); (speed * cos, speed * sin) } fn angle(x: f64, y: f64) -&gt; f64 { y.atan2(x) } 
This is awesome, I will try it out! But first, I need to learn how to draw triangles in Piston 😅
Your comment about using more of Rust's pattern matching makes sense and aligns with other code I've looked at. I hadn't thought of leveraging pattern matching that far. I'll keep that in mind moving forward. Thanks for helping me out!
Just started my first Rust project, and I'm keeping it easy with a wrapper over the unofficial SpaceX API. Running into an issue, and was curious as to what is the most idiomatic way to resolve it. https://github.com/twilco/space-rx/blob/4addff6dbb1081c7646d2c3ed057d37f0b69aa8e/src/lib.rs#L22 error[E0277]: the trait bound `&amp;std::collections::HashMap&lt;&amp;str, &amp;str&gt;: std::borrow::Borrow&lt;(_, _)&gt;` is not satisfied --&gt; src\lib.rs:34:22 | 34 | Some(map) =&gt; Url::parse_with_params(base, params), | ^^^^^^^^^^^^^^^^^^^^^^ the trait `std::borrow::Borrow&lt;(_, _)&gt;` is not implemented for `std::collections::HashMap&lt;&amp;str, &amp;str&gt;` | = note: required by `reqwest::Url::parse_with_params` Is this saying that the &amp;str type doesn't implement Borrow? If so, should I just require a full String instead?
Args are the text after the program name, e.g. `my-app my-arg-1 my-arg-2`. Stdio is a different input stream, e.g. when you type into the console while the program is running or when you pipe `|` output from another program into the stdio input.
Congrats on the release! I am impressed about the yew rewrite.
Are you using Arch Linux? Then wait for the new version of rustup to be released in a package repository (shouldn't take too long).
I've give creating a custom error enum a shot. After digging around I understand why `unwrap` and `expect` are appropriate for examples and but risky to use otherwise but it sure is confusing when learning especially since they are commonly used in examples. I appreciate the eyes! Thanks for taking a look.
What's happening is that you are passing an Option&lt;HashMap&gt; instead of HashMap to Url::parse\_with\_params.Pass map instead of params an it should work.
Wow...I was using the parameter instead of the Some(map)...doh. Thanks!
Which platforms does it support? Linux? Windows? Mac OS? BSD? Also, why vp9? Last time I checked encoding times on vp9 were a lot slower than vp8, and vp9 encoding was barely parallelizable. Can this record in at least 30fps?
I've successfuly used this: [https://phabricator.kde.org/dashboard/view/28/](https://phabricator.kde.org/dashboard/view/28/) ‒ it shows you how much memory was used through the time and what part of your program was responsible. If I remember correctly, I had to switch the global alocator to `system` for that to give any results.
It *should* support Linux/Windows/macOS. I used VP9 mostly because there were existing bindings for it - I originally wanted to use x264, and I even made [an x264 wrapper](https://docs.rs/x264) for this, but I couldn't be bothered making an MP4 muxer or AAC bindings (both of which should be easy, though). Still, it can easily do 60 FPS on my computer.
Ok, hopefully I'll get around to it soon. Sorry for being annoying, but I have another question: [Here](https://github.com/jonhoo/tokio-zookeeper/blob/master/src/proto/mod.rs#L263) you compare &amp;self.inbox[self.instart..] to &amp;[0, 0, 0, 0][..] which basically means you have a zero-length response. But in that case self.inlen() is equal to need which means you'll exit from [this](https://github.com/jonhoo/tokio-zookeeper/blob/master/src/proto/mod.rs#L255) loop, and the next time you enter you won't hit that condition and you'll return an error even for a connection that's been closed normally. I'm probably misunderstanding something, so I'll probably rewatch that part of the stream to check.
Thanks for writing this! I'm currently using a compression algorithm I've invented specifically for the task that uses prior knowledge of what the data typically looks loke, but that merely divides memory requirements by a constant factor. This might come in handy if/when I need even more compression.
Thanks a lot for the detailed explanation! 
I believe that you can set the install path with environment variables (see https://github.com/rust-lang-nursery/rustup.rs#choosing-where-to-install).
Maybe relevant: https://github.com/rust-lang-nursery/rustup.rs/issues/618 https://github.com/rust-lang-nursery/rustup.rs#environment-variables The answer is probably the one for a lot of such requests in open source land: Because no one yet has stepped up and implemented that. The linked issue seems to contain some discussion, but looks like it went silent some time ago.
This works: ```rust macro_rules! testfn { ($target:ty) =&gt; ( { let sl: &amp;[u8] = &amp;[0, 0, 0, 0, 0, 0]; std::mem::transmute::&lt;_, $target&gt;(sl.as_ptr()) } ); } fn main() { let _x = unsafe { testfn!(fn() -&gt; i32) }; } ```
&gt; Sort of undocumented, I think. This was how I finally figured out why I could never get RLS to work in emacs. It looks documented but you have to dive way deep, it's only in the help of `rustup component add` (and possibly other toolchain-relative sub-sub-sub-commands) so hard to find and easy to miss: &gt; rustup component help add rustup-component-add Add a component to a Rust toolchain USAGE: rustup component add [OPTIONS] &lt;component&gt;... FLAGS: -h, --help Prints help information OPTIONS: --target &lt;target&gt; --toolchain &lt;toolchain&gt; Toolchain name, such as 'stable', 'nightly', or '1.8.0'. For more information see `rustup help toolchain` ARGS: &lt;component&gt;... 
If anyone was wondering like me why the [previous attempt](https://github.com/japaric/m) was abandoned: &gt; libm is a port of MUSL's libm. MUSL source code proved much easier to translate to Rust, and more importantly it was easier to write a test generator that didn't require compiling C code and that worked on a bunch of different architectures. &gt; &gt; These two aspects make such a difference that we were able to port 30 math functions to Rust in less than 24 hours. &gt; &gt; -@japaric, 2018-07-14
Thanks that appeared to do the trick! I think I'll stick in an error trace for that
Cool it'd be nice to: * Have a countdown before starting * Allow users to select a screen portion
I managed to install the component, but trying to run it tells me `no such subcommand: \`clippy\``, do you know where that could come from? 
Why dont you change the systemd service type to simple and remove the pkill command? That way systemd will kill the rust api service using the built in support on stop and will also enable you to enable restart=always so that in case of problems your service will be automatically restarted. 
s/match/much/g Otherwise It's a good read
Wow, this is super cool and tickles all my fancies. Thanks so much for this.
Yeah, sure, pat yourself on the back for being rude and putting down other peoples work. Why won't people stop posting fun blog posts with code in them that isn't absolutely _perfect_ and are complete, full examples with tests, unit tests and extensive fuzzing? No, you did not do good. If you were constructive and positive in your post, maybe. Instead you give **demands** to OP of what he should do since his post doesn't live up to _your_ standards.
&gt; This was how I finally figured out why I could never get RLS to work in emacs. I am very interested in your setup. Do you have any post or gist where you can explain your setup? I would love to read it and learn from it.
Of course some restriction will have to be applied for "enumerable" traits, e.g. traits with `const` will not work as well.
I agree with the entire article. I very rarely use Rust but learning it has taught me how to write better Python code. It's nice to have the compiler explicitly tell you that you are attempting to do something that is going to subtly break another module in 2 months time, and to show you a better way of doing things. Yes it's useful to be warned about unused variables — in dynamic languages, more often than not, it means that you've got a typo. Unused variable "count"? Look out for the assignment to "cont" half a page away. Yes, it's useful to think of your variables as immutable unless mutability is required, instead of the other way around. It leads to cleaner interfaces and more readable code. Okay, I learned this one from Scala first — I guess it's generally a good idea to learn languages and ecosystems to see if you can find some value in them. So many things just clicked into place in my head after spending some time with Rust. I'd say it has advanced my coding skill as much as understanding pointers or object oriented programming did years before.
I don't even know that there is a clear distinction between "legit" and "scam" before a blockchain project becomes "successful". Well, there may be some that are *pure* scam, but there are many that have *some* promise but in the mean-time live on investor money.
It's not just about "Fin-tech" being mostly Finance though. It's about throwing huge amounts of resources at an old problem with existing solutions *because it's trendy* and because limited regulation has allowed some of the existing solutions to become big fat cash-cows. Or have I got it the wrong way around, and it's because the new solutions still have little regulation?
What is Artifact? It would be great if you followed Rust's example and wrote a few words about the project at the start in the release announcement.
Why Mac only? Is there some particular reason that lldb will only work properly on Macs?
100% agree!
Doesn't seem to work on windows `C:\Users\12345\Projects\keyserver_service&gt; rustup run nightly cargo clippy warning: custom registry support via the registry.index configuration is being removed, this functionality will not work in the future error: failed to run rustc to learn about target-specific information` `Caused by: process didn't exit successfully: C:\Users\12345\.cargo\bin\clippy-driver.exe rustc - --crate-name ___ --print=file-names --crate-type bin --crate-type rlib --crate-type dylib --crate-type cdylib --crate-type staticlib --crate-type proc-macro (exit code: 3221225781)`
Thanks for correcting thats what I meant with my original comment, I am originally from the US and living abroad, it *so* different when thinking about offers. 
Yes i'm using an arch based distro. I shall wait and see. 
There is a typo which says _prude_ instead of _proud_. Still, good work!
I'd recommend you get a native/very strongly fluent English speaker (preferably a writer) to proofread your articles before you post them. It's understandable but there's some mistakes that could be caught by an editor. Good read though!
Holly wars: when the wreathes get pointed.
Crate: https://crates.io/crates/cc1101 Usage: https://github.com/dsvensson/sparsnas-rs
What are the most promising WebAssembly host libraries? Ideally there would be one that is written in something very small and portable (maybe even C89) as an interpreter with reasonable speed. And another that is JIT-compiled and much faster, though a little heavier. In other words, what are the Lua and LuaJIT of WebAssembly?
I think the biggest issue is that [overflows are rampant](https://github.com/japaric/libm/issues/4). It is currently unusable in debug mode due to this.
Work had been done to reduce the overhead of those calls in both chrome and FF over the past few months so it's not as expensive anymore if at all
Holly berries are poisonous, so maybe there's something to it.
This data structure is very useful for safely storing data with unclear ownership with many inner references, such as graphs. The slot map is the owner of all values, and upon insertion gives back a weak key (sometimes called handle) to the value inserted. Unlike an arena allocator, values can be deleted from a slot map and the space re-used. Unlike [`slab`](https://github.com/carllerche/slab), keys are always unique to the value inserted, and even if the physical space gets re-used, the key will remain invalid.
What are the security properties of the keys used by SlotMap? For example, if you know one key can you predict what the next one might be?
A key is utterly predictable, and is unrelated to the term 'key' in crypto. It's more akin to a key in a hashmap. Under the hood a key is an `(index, version)` tuple, where `index` is used to find the item internally, and `version` is used to ensure even if the space is re-used a key will only ever retrieve the original inserted item. However, I don't really feel this is relevant. A user of the library does not and can not create `Key`s. The only way to acquire a `Key` is by inserting an item into the slot map. The exception to this is serialization/deserialization. Care has been taken that even if a malicious actor has changed the serialized data arbitrarily, usage is always *safe* and does not cause undefined behavior (albeit arbitrarily unexpected).
Great to see you've made so much progress, /u/vitiral! …but, as always: &gt; Artifact is a simple, linkable and trackable design documentation tool for everybody. It allows anyone to write and link their design documents both to each other and to source code, making it easy to know how complete their project is. Documents are revision controllable, can be edited in the browser and have a full suite of command line tools for searching, displaying, checking, exporting and formatting them.
Yeah, I'll have to read it some day. In the meanwhile, https://exercism.io/my/tracks/rust seems to be up again.
Maybe there's something wrong with the advised behaviour. Maybe there's something wrong with the investors, the venture capital model and the blockchain. Regardless of whether or not you agree that it is, I don't think "we're just doing what others are doing" should shield anyone or anything from criticism.
Yeah I wonder if the code for that particle effect is Rust. Flashiest mobile site I've seen in a while
The workflow I like to use for sub-sub-subcommands is: rustup help &gt; reads message notice command component !! component &gt; reads message notice command add !! add &gt; reads message notice option --toolchain Its not perfect, but cuts down on the typing making it less tedious
That's going to be really problematic in Rust - there's no fixed ABI, so you can't compile a plugin with a different compiler and load it into your core process. Do your plugins need to be Rust code? A scripting language sounds like it could be a good fit here.
Yeah, I read about the ABI problem just now. Essentially this would mean if my main program was written in 1.24 all the plugins would need to be compiled with 1.24 as well and other Rust versions would break things apart?
Yes.
If you want to use libloading, you will want to have your plugin interface be a C interface. Rust's ABI is unstable and may change between versions, but the C ABI is standardized. As a side benefit, your plugins can be written in any language that can export a C ABI.
If you want to expose a Rust API, then yes. Either you need to use a scripting language as suggested, or expose a C API.
I asked about it in our meeting, you can [check it out here](https://bot.tockos.org/tockbot-moz/embedded-bot/2018-07-16/?msg=113566&amp;page=3), but not likely at the moment. Has anyone worked on a Rustlang port of \`libmvec\` that you know of?
That's awesome. :D I don't understand why that loop on the reader side makes any difference, though... it really should not. However, as you said in std it still shows errors even after fixing the problem because it doesn't understand fences?
This seems great to be able to automatically have unique identifiers for entities, something slab also couldn't do due to lack of unique keys. Very useful.
Yes, entity systems for games and such are one of its intended purposes. For this purpose I've also implemented a `DenseSlotMap` which has slower random accesses (still O(1), just slower), but the values are stored contiguously so you can quickly iterate over all elements in a slot map.
What's the backend?
Well but the speculative write example there only works if the compiler somehow knows that the data is accessible in both branches. That's not the case here. But yes, this is all very tricky and I used plenty of "maybe" for a reason. ;)
If you look at std log closer you can see that there are 2 warnings: ThreadSanitizer: reported 2 warnings One of them is in drop_slow, and I believe it is there because of the fences, I can see it both on old and new nightly. But the other warning that is in main.rs:23 line, I can only see on old compiler, but not on the latest nightly.
Need to get some more work on my game done, as I didn't do much last week. Going to work on a design for the "build ui". It's a tile based strategy/resource management game. Each tile is 64x64. What i did was when you select a tile, id make a small tooltip appear next to it, with the icons of what to build, each sized at 32x32. This was too small to display cost of each to build. I doubled the size and added padding, but it needs more thought than that.
Oh, thats interesting. Was it implemented by using a secondary regular arena (like slab) with the indices of the dense map?
rust (still using nickel for the web server. I'm not going to decide what to rewrite in/whether to rewrite until futures stabilize).
Thanks for the feedback. I updated the release notes with more detail :)
Thanks. Honestly the yew rewrite from elm was _pretty easy_. The frameworks are very similar.
thanks, I also updated the release notes (whoops!)
I think right now, c++ assumes that the hardware can do speculative write (not the compiler optimization), therefore it is a data race. But in practice no real hardware does this, so it can be safely forbidden, as the document says. But they can't do it in the current model. There are also some [posts in lkml](https://lkml.org/lkml/2018/6/7/761) on this topic if you are interested.
I think https://github.com/retep998/winapi-rs is the de facto standard crate for calling Windows APIs. I don't know enough about Windows to suggest which APIs you'll need to call, but that crate should be fairly complete.
Essentially a dense slot map is implemented as a slot map that stores indices into a contiguous array. On removal the last element in the contiguous array gets swapped into the hole left by the removed element, and the index of the moved element updated in the slot map.
Lua is a small scripting language that can be easily embedded into C++. I assume it works similarly easily in Rust. Then you there are no worries about ABI compatibility. Wireshark, for example, allows loading Lua plugins.
what if I have 2 slotmaps and I use a key from the 1st slotmap on the second slotmap?
You'll eventually see a lot fewer of them, since [this happens with new technologies all the time](https://www.investopedia.com/terms/d/dotcom-bubble.asp). It will take a while for the cream to rise to the top.
Good question. Care has been taken so the result is *safe* (that is, no undefined behavior), but the results are not specified. Maybe the key is valid and it'll return an element, maybe not.
Is there any particular reason you chose u32 instead of usize for the first half of the key? Is the worry that 12-byte keys would be too big? Going even further in the irresponsibly large keys direction :) why not use a u128 for the generation counter? Then you could pretty much guarantee that the generation never wraps, even for cryptographic applications that might care about some wrapping attack.
Hey, I just sent in a pull request that addresses this (`Key` -&gt; `Key&lt;T&gt;`). It doesn't work though because it breaks with values that contain keys.
Speed and memory usage (and the latter in modern times where cache is all that matter is also, speed). Currently on a 64-bit system a `Key` fits exactly in a machine word, which helps a lot. But more importantly (again, cache), a `Key` is *small*. Consider a typical tree data structure, where you have a parent key, left sibling key and right sibling key. With a 16-byte key you're now looking at 48 bytes of overhead and cache pressure for each element in the tree. 
I'm not going to accept this, because types that contain their own `Key` and other recursive structures are explicitly a target use case. Also this barely adds any protection, I'd argue that in nearly any erroneous scenario where you're using the key of one slot map in another, they both contain the same kind of type.
Oh, cool, that's exactly what I need! Maybe it makes sense to make the key NonZero, so it will take less space in case of Option&lt;Key&gt;. What do you think?
That makes sense. I guess, for /u/vova616, the only way for compile time protection is wrapping the slotmap and keys yourself with a struct.
Yes! This is a planned optimization. Note that in a lot of cases the use case of `Option&lt;Key&gt;` can be simply fulfilled by having valid/invalid keys where `Key::null` is always invalid. A prime example is found in... the example :) https://github.com/orlp/slotmap/commit/f3de80a3e773b3dab48bb95960d15814ed1da518
Lots of information on this in the comments of this thread: https://reddit.app.link/jfAeVL9YCO
Need to check out Lua some more, thanks! I know Lua but have not used it anywhere.
Sold! Yes I see the Key::null, it's also an option ;).
That sounds reasonable, need to read more about C ABI. Thanks.
&gt; Though I guess that only helps with the size of references, and not with the overhead in the map itself. Maybe you could do some crazy thing where generations are u8 at first and then get rewritten if and only if one of them grows too big? Or even...have generations be () at first (in the map though not in the references), and only allocate storage for them if there's ever a removal. The issue is Key, not the storage. &gt; Maybe for applications that care about size, you could provide a conversion into some "miniature key" type with smaller ints. Then that conversion can fail (and probably panic the caller one way or another) if truncation is losing non-zero bytes. This is a more interesting solution, but I don't feel that it's particularly worth it. If I'll tackle this issue it'll most likely be in the form of `Key&lt;I = u32, V = u32&gt;` and `SlotMap&lt;T, I = u32, V = u32&gt;` where you can explicitly set the `I` index and `V` version type.
What about Arduino Zero ? I have seen a lot of people who successfully wrote programs for the Arduino Uno and Due but nothing for the Zero
Quick idea: what about starting with a different random version for each `SlotMap`? Meaning: if you create a `SlowMap`, a random integer is generated and stored in the map. All keys generated by this slot map start with the version equal to the stored integer. This makes it incredibly unlikely (though not impossible of course) that a key from one map is valid in another map. But yes, this would probably pull in the big `rand` dependency...
The implementation is not a bad idea, but why bother? It doesn't make sense to use a key from one map on another to begin with. And if I implement this I can see library users actually starting to rely on the fact that using the key of one map on another always returns `None`.
Yeah I think the most widespread way to run some sort of plugins with rust is to use lua. The rlua crate is maintained by Chucklefish, a game studio, and is quite mature. There was even a minor release in rust (1.24.1) that reverted a change in 1.24 that completely broke rlua.
Sure, guaranteeing behavior is difficult. I was just thinking about a "best effort quickly catch bugs" thingy. But yes, simply getting `None` for a key lookup might not indicate a bug. Maybe something like this: the map not only stores the starting version, but also the largest version that was used. Then the map could check on access if the key version is in bounds. If not, it can panic with "key from other map used". That's a quick way to notice bugs. But yes, I'm not arguing that this should be the default behavior or that it should be happening in release builds. Just ideas. But yeah, maybe it's useful for `debug` builds...
Very nice. It highlighted something I just now realized: using Rust really raises your expectations of software engineering practices.
Wow! Thank you. That will help me tremendously, I think. I am super excited to get rolling with this. I've had a need for some long-running, threadsafe, performant jobs and I think rust will be just the tool.
Native English speakers are very hard to find sometimes, and strong writers can be even harder! That said, I'm both, so have my suggestions: https://docs.google.com/document/d/1NAL_TzvFQNR5fqo0GzMJN_3FtK4WMXHZ__-0ABRF784/edit?usp=sharing
Proof that Trump colluded with Russia. Reeeeeee
You can easily create a wrapper for the `SlotMap`, which: * generates a random map id when it is created * appends the id whenever you retrieve a key * strips the key when you provide one, before passing it to the wrapped SlotMap * panics when you use a key with the wrong map id.
Your rustup wasn't updated. rustup has had the component for a week now, but it didn't have the binary in the path.
I've added an external link checker on https://github.com/Keats/gutenberg (a static site engine) and am going to mostly do testing and a few fixes here and there before releasing 0.4 If anyone is looking for a simple issue, https://github.com/Keats/gutenberg/issues/324 should be pretty straightforward to do.
I'd say that today it might be easier to write plugins in Lua (lots of games do that) or Python (gdb and lldb use it), because dynamic loading in static languages without runtime is not very convenient. However I am really excited about WebAssembly prospects here: it seems like an ideal technology for adding plugin capability to Rust projects. I don't know if any solutions exist yet, and they certainly unlikely to be production ready, but looks like we have all the pieces to at least start experimentation?
Arduino Zero is a SAMD21 microcontroller (ARM Cortex M0+), which is better supported than AVR. I've run Rust on the same chip, on my own board design. I think the most updated resource is https://github.com/wez/atsamd21-rs.
For those curious: the `zxid` maintenance inconsistency we found in `rust-zookeeper` was indeed a bug! See https://github.com/bonifaido/rust-zookeeper/issues/50.
Sanity checks that only work sometimes are generally a bad idea. People typically assume that since they were getting a sanity check error before and now they're not getting it, the code is fine, when it's really not.
Why do some operators (like Eq) take &amp;Self, and others (like Mul) take Self? I wanted to define all my operators taking &amp;Self, but for Mul I have to pass a Self?
&gt; Your rustup wasn't updated. First thing I considered, but it was up to date. 
In most cases, I think that behaviour is perfectly fine. However I can see the benefit of making a map "unique" in some cases, like in a game engine type situation where you have different maps for differently used entities that have the same data type. Here's an idea: Create an easy way to turn a newtype thats just contains a SlotMap into an actual SlotMap. Basically just wrap all the SlotMap methods with a custom derive macro, with the only difference being the Key type in the function signatures. Something like `Key&lt;MyCustomSlotMap&gt;` as the key type for `MyCustomSlotMap`. The usage of this could then look like: #[derive(SlotMap)] pub struct MyCustomSlotMap(SlotMap&lt;MyEntity&gt;);
When someone comes to this board with a legitimate job offer, seeing nothing but complaints that amount to "Well I have better offers" is disheartening.
Is there anyway to figure out which components are currently installed for a given toolchain?
/u/oconnor663 /u/phaazon_ /u/AshamedCantaloupe /u/frolvlad /u/belovedeagle /u/PrototypeMN1 thank you very much. I think I have done it right. The program can now take the string from the std and from the arguments. Not sure however, if the code is nice. [https://github.com/aspera-non-spernit/cyrconv/blob/master/src/main.rs](https://github.com/aspera-non-spernit/cyrconv/blob/master/src/main.rs)
Oh. Then no idea what happened.
Actually, Itertools adds its own `chunks` method for iterators. The catch is that it returns not another iterator but an iterable object (which needs to allocate memory on the stack to buffer the chunks). But if you have something that derefs to `&amp;[T]`, it's of course always better to use the slice `chunks` method.
Not at all! These are useful question! You make a good point. In theory the `[0, 0, 0, 0]` should be parsed as a `length` of `0`, which should in turn set `need` to `4`. Since `inlen()` is `4`, the loop should never even be entered. Which is weird, because we definitely saw the `bail!` below being triggered.. And if we hadn't read the `[0, 0, 0, 0]` before entering, then we should read that out and then loop again with `need == 4`, which shouldn't continue. I think you're right that we should have a `if need == 4 { return Ok(Async::Ready) }` under the loop, but it's probably worth investigating how we hit the current `Ok(Async::Ready)` at all! If you want to give it a shot, try running the test with some more print statements and see how the program flows?
There's really no reason to ever *not* take `&amp;self` for something like `Eq`, because you only need to look at the things you're comparing. But things like `Mul` may want to consume their arguments, rather than just look at them. Thus, it *has* to take `self`; if you want to take references, just implement `Mul` for `&amp;TheType` instead of `TheType`.
Yeah. Is there a separate registry of some sort for components? I had clippy installed separately (as a regular CLI tool) initially and removed it on the initial failure, but then the add or remove/add of the component version failed, and I tried to find if something was wedged in the component registration but couldn't find anything which looked like a registry of any sort (at least not in ~/.cargo).
I believe you are missing a link?
Could you add a PhantomData marker and generate a new one off type per SlotMap so that it's a compile time error to cross keys?
Interesting! It seems like they had to handle a lot of tricky details to make that work in the general case.
you couldn't implement the arbitrary trait , since all the user of the function knows is that the return type is \*something\* that implements a trait. Eg: `fn return\_debug() -&gt; impl Debug`. Here the user cannot name the return type anyway, and so can't implement other traits for it.
You misunderstand. Just because `A` and `B` implement trait `Foo`, it does not follow that there's a sensible `impl Foo` for `enum AB { A(A), B(B) }`; let alone one which can be synthesized by the compiler.
Fun to see others doing this for fun. Here's what I put together. It's still not ideal, but I'm not sure if I just need to tweak numbers more or if I'm missing a critical part of the algorithm. https://github.com/raydenuni/rust_boids I think if I revisit it, it will be to multi-thread it.
It might still be interesting to implement *in Debug mode*, maybe. If users rely on it, their tests will break in Release, so they should figure it out relatively quickly.
I have this code: `if t.len()? == 2 {` `let mut table_it = t.sequence_values();` `let x = table_it.next();` `let y = table_it.next();` `if let (Some(x), Some(y)) = (x, y) {` `return Ok(Self { x: x?, y: y? });` `}` `}` where [`sequence_values()`](https://docs.rs/rlua/0.14.0/rlua/struct.Table.html#method.sequence_values) returns an iterator over `Result&lt;u16&gt;`. Is there a more elegant way to do this?
If you study them carefully, you can often see that many projects are so nonsensical that there are only two possible explanations: the authors want to scam others or are incompetent, which is effectively a scam too since they pretend to be competent. There are indeed cases, when even smart people disagree on something being a scam. Ethereum is a typical example of this case. That's why I wrote a detailed description is missing - I have to assess whether it's a scam or not myself. "No, we aren't scammers" is obviously insufficient.
&gt; It doesn't work though because it breaks with values that contain keys. May I ask what the definition of `Key` ended up being? I find it surprising that you could not have a: struct Node&lt;T&gt; { value: T, head: Key&lt;Node&lt;T&gt;&gt;, tail: Key&lt;Node&lt;T&gt;&gt;, } And indeed [it seems to work on the playground](https://play.rust-lang.org/?gist=6095b6e947308602068aa5b0f0371ab7&amp;version=stable&amp;mode=debug&amp;edition=2015). 
Nice touch using a `wrapping_add` for the version number. It's an easy oversight to make, but `u32` can be overflowed :)
We really need better video infrastructure in Rust. Makes me almost want to dive into it. I work with video so much at my job and I'd love to have video processing tools. Rust is definitely a great language to implement some sort of abstraction that lets you demux any mpeg ts stream and use some sort of reversal of concerns through traits or closures to ask the user of the library what decoder they want. We could also do the same thing for encoding and muxing.
Probably not an easy question. So I'm writing some FFI that involves holding a bunch of *mut T raw pointers. I've found Unique&lt;T&gt;[Experimental, nightly], Shared&lt;T&gt;[Experimental, nightly], and NonNull&lt;T&gt;. So my question is about the following line in the documentation: &gt; Unlike `*mut T`, `NonNull&lt;T&gt;` is covariant over T. What precisely does this mean, in concrete terms? What is the impact on type inference? How about method calls? 
Since I started writing Rust code on a regular basis, I am quite often very offended by my own C++ code I wrote not too long ago. Whenever I get back to developing in C++, I have some new patterns in mind, but miss the tooling support which I get in Rust for free. Thanks for writing the article, good read!
See the [Rustonomicon](https://doc.rust-lang.org/nomicon/subtyping.html) for details. Short version: Variance in Rust only has an effect for types with lifetime parameters, because lifetimes are the only form of subtyping in Rust. When `T` is a type without no lifetime parameters (which is often true in FFI code), the variance of your pointer-to-`T` type doesn't matter, and you can ignore this. If you *are* using pointers to types with lifetime parameters, read on. `*mut &amp;'a Foo` is **invariant** over `'a`. This means that if `'long` outlives `'short` then you can't pass a `*mut &amp;'short Foo` where a `*mut &amp;'long Foo` is expected, nor vice-versa. (The former would let the receiver read a a short-lived reference as a long-lived one, while the latter would let the receiver overwrite a long-lived reference with a short-lived one.) `NonNull&lt;&amp;'a Foo&gt;` is **covariant** over `'a`. This means that you *can* pass a `NonNull&lt;&amp;'long Foo&gt;` where a `NonNull&lt;&amp;'short Foo&gt;` is expected, but not vice-versa. As the docs mention, this is the desired behavior for types like `Vec`, where it's okay to coerce from `Vec&lt;&amp;'long T&gt;` to `Vec&lt;&amp;'short T&gt;`, but not vice-versa. We don't need to worry about writing short-lived references to a Vec of long-lived references, because this can only be done by borrowing an `&amp;mut Vec&lt;_&gt;` which is invariant and prevents this coercion from happening.
"No luck" is pretty vague. We're not psychic -- many things can go wrong (especially on Windows) and they have different observable effects. What actually happened in each case? 
What do you mean by "can't run", exactly?
I'm currently working on a arduino mkr-zero project and wez's library is very good for it yes.
To expand on this, if you're writing the plugins in Rust, you'll want to have them by a `cdylib` crate type, instead of a `dylib`, you wind up having segfaults when unloading libraries, at least last I checked. See [this example](https://github.com/BurntPizza/dylib_tls_crash). Build `test_lib`, then run `dylib_crash`. Then change `test_lib`'s Cargo.toml to say `cdylib` and build it again and run again.
For non-Mac builds it is difficult to correctly pick the Python to link against. You'll still be able to build it if you want, it just won't be available via rustup. Maybe someone could figure out a way to handle this, I don't know. Meanwhile I think this will be enough to unblock debuginfo improvements, which is really my main goal.
 pub struct Key&lt;T&gt; { idx: u32, version: u32, value_type: std::marker::PhantomData&lt;T&gt;, } The example works, but not all the tests pass. Specifically, `insert_with_key` breaks. In the doc test, it tries to return a type `Key&lt;(Key&lt;...&gt;, i32)&gt;`
Rust, without a doubt, has improved the way I approach a program. I have trouble translating a non-Rust prog to Rust equiv still, but then after I do I'm like, "wow, I didn't consider that and that actually may be a better approach". I've linted out unused code for a while and did the _ if I didn't want to, but the real push to minimize mutable vars has also helped and has lead me to leveraging a more pure functional style in my more recent JS code.
I managed to create a better solution included in the new release (v0.1.3). It does not use temporal files and it is able to handle your example case: $ rnr '^' a * aaa.txt --&gt; aaaa.txt aa.txt --&gt; aaa.txt a.txt --&gt; aa.txt The new solver will change the renaming order if there is any solution. It does not consider cyclic renaming `a--&gt;b &amp;&amp; b--&gt;a`. I did not find out an input regex to cause that operation but it may exist. I've created several checks that cleans input to the solver to ease the resolution. I've uploaded a [diagram](https://mermaidjs.github.io/mermaid-live-editor/#/view/eyJjb2RlIjoiZ3JhcGggVERcbkFbU291cmNlc10gPT0-IHxSZWdleCByZXBsYWNlfCBCXG5CW1RhcmdldHNdIC4tPiBDKER1cGxpY2F0ZWQgdGFyZ2V0cz8pXG5DIC0uIHllcyAuLT4gRHtFcnJvci9FeGl0fVxuXG5CID09PiB8RmluZCBhbHJlYWR5IGV4aXN0aW5nfCBFW0V4aXN0aW5nIFRhcmdldHNdXG5FIC4tPiBGKEFueSBub3QgaW4gU291cmNlcz8pXG5GIC0uIHllcyAuLT4gRHtFcnJvci9FeGl0fVxuXG5FID09PiBIW1NvbHZlcl1cblxuSCAuLT4gSihSZW5hbWluZyBsb29wPyBhLT5iICYgYi0-YSlcbkogLS4gWWVzIC0-IG5lZWRzIHRlbXAgZmlsZSAuLT4gRFxuXG5IIC0tPiBLKGEtPmIgYmVmb3JlIGItPmM_KVxuSyAtLT4gfHllcyAtPiBjaGFuZ2Ugb3JkZXJ8SFxuXG5IID09PiBJW09yZGVyZWQgUmVuYW1lXSIsIm1lcm1haWQiOnsidGhlbWUiOiJkZWZhdWx0In19) that shows the flow of information.
You can do it with lifetimes, this crate does it for guaranteed checked at most once indexing: https://crates.io/crates/indexing
I managed to create a better solution included in the new release (v0.1.3). It does not use temporal files and it is able to handle your example case: $ rnr '^' a * aaa.txt --&gt; aaaa.txt aa.txt --&gt; aaa.txt a.txt --&gt; aa.txt The new solver will change the renaming order if there is any solution. It does not consider cyclic renaming `a--&gt;b &amp;&amp; b--&gt;a`. I did not find out an input regex to cause that operation but it may exist. I've created several checks that cleans input to the solver to ease the resolution. I've uploaded a [diagram](https://mermaidjs.github.io/mermaid-live-editor/#/view/eyJjb2RlIjoiZ3JhcGggVERcbkFbU291cmNlc10gPT0-IHxSZWdleCByZXBsYWNlfCBCXG5CW1RhcmdldHNdIC4tPiBDKER1cGxpY2F0ZWQgdGFyZ2V0cz8pXG5DIC0uIHllcyAuLT4gRHtFcnJvci9FeGl0fVxuXG5CID09PiB8RmluZCBhbHJlYWR5IGV4aXN0aW5nfCBFW0V4aXN0aW5nIFRhcmdldHNdXG5FIC4tPiBGKEFueSBub3QgaW4gU291cmNlcz8pXG5GIC0uIHllcyAuLT4gRHtFcnJvci9FeGl0fVxuXG5FID09PiBIW1NvbHZlcl1cblxuSCAuLT4gSihSZW5hbWluZyBsb29wPyBhLT5iICYgYi0-YSlcbkogLS4gWWVzIC0-IG5lZWRzIHRlbXAgZmlsZSAuLT4gRFxuXG5IIC0tPiBLKGEtPmIgYmVmb3JlIGItPmM_KVxuSyAtLT4gfHllcyAtPiBjaGFuZ2Ugb3JkZXJ8SFxuXG5IID09PiBJW09yZGVyZWQgUmVuYW1lXSIsIm1lcm1haWQiOnsidGhlbWUiOiJkZWZhdWx0In19) that shows the flow of information.
So the end result is that if I use NonNull&lt;T&gt; to hold a *mut T, then I'd get lifetime checking and lifetime subtyping, which I wouldn't normally get. The question then is if this is desirable in a wrapper over unsafe FFI bindings? 
Is it possible to get the index from a key?
It is not, intentionally. The idea that there is an 'index' at all is an implementation detail.
Would that actually work here? I feel like part of the design goal is for the Key to not be tied to the lifetime of the slotmap.
So, first, if your specific `T` has no lifetime parameter, there's no subtyping or variance and it makes no difference. If your type has "interior mutability" (if you can mutate a `T` without having a unique `&amp;mut` reference to the thing pointing to it) then you probably want it to be **invariant** over T. If it follows Rust's normal mutability rules (mutation is only possible with unique access) then you probably want it to be **covariant** over T.
Working on [documentation for edit-text](http://timryan.org/edit-text/book/). I've been working on the project for nearly eight months straight without focusing on documentation. Now it feels like reading my code and relearning some concepts for the first time :) Hoping to get to the point where docs can answer the majority of questions around first time use, but also document everything needed to submit pull requests.
I'm running into this as well, also after running `rustup self update`.
I just realized... I'd run `rustup self update` and installed the component in a different shell. I ran `rehash` in my current shell then was able to `cargo +nightly clippy`.
I suddenly realize I asked you this question and received the same answer before on an earlier iteration of this. Apologies for the the redundant question.
I don't understand the train reference :(
You can always invoke an external command (\`ffmpeg\`) to mux sources as they are recorded.
Make an issue on the rustup GitHub. 
Hey! Just wanted to say this comment was extremely helpful, thanks for linking the Powerpoint and explaining it from that perspective. After working at it for a few hours, and researching a bit more (this talk actually also helped alot: https://www.youtube.com/watch?v=4YTfxresvS8&amp;index=26&amp;list=WL) I think i've got a much better handle on the whole concept
That's cool. :D Care to run this on the tests for the [channel](https://doc.rust-lang.org/beta/std/sync/mpsc/fn.channel.html)? That's actually tons of code and it doesn't use interior mutability so we haven't proven it (other things seemed more interesting to prove).
Try changing the marker to `*const T` instead of `T`. `PhantomData` is used for variance and ownership; by using `PhantomData&lt;T&gt;` you are telling the Rust compiler that `Key&lt;T&gt;` *owns* a `T`, which is not the case. If you modify your patch to use `*const T` instead, it should work.
&gt; Unused variable "count"? Look out for the assignment to "cont" half a page away. If we see another Python competitor invented in the next few years, I wonder if they'll chose to distinguish between declaring a variable and assigning to an existing one. Even without types, it seems like that would catch a lot of bugs. And it would avoid the need for tricky features like `nonlocal`.
The compiler will do "speculative" write (well, not really speculative but still a reordering) across control dependencies in a situation like if (x) { *y = 42; } else { *y = 42; } Then it can move the write out of the conditional. &gt; There are also some posts in lkml on this topic if you are interested. That's interesting indeed, thanks. :) I particularly like that Linus is arguing for a "virtual machine" (I'd call it an "operational semantics") explaining all the concurrency stuff. That's exactly what I have been arguing as well, and [some progress is being made in that direction](https://people.mpi-sws.org/~viktor/papers/popl2017-promising.pdf).
If we see another python competitor I think it'll probably have optional static type checking integrated into the toolchain, which catches that bug, too.
TIL! It still doesn't work though. The error is `cyclic type of infinite size`. It seems to be a [limitation of rustc](https://github.com/rust-lang/rust/issues/35978) for now.
Had the exact same issue. Can you clarify what you mean by "setting a clock"?
This refers to [Software Release Trains](https://en.wikipedia.org/wiki/Software_release_train), a sort of release cycle. Every 6 weeks there is a new stable and beta release of Rust. The beta release is always one minor version behind the stable release. Currently we have stable at 1.27 and beta at 1.28. In two weeks the beta will become stable and the next beta will be 1.29. Aside from that, I'm honestly not sure how exactly rustup components integrate with the release cycle of Rust itself.
But then I seem to have to write &amp;(&amp;a + &amp;b) + &amp;c, which gets annoying?
As it says in the [tokio-timer docs](https://docs.rs/tokio-timer/0.2.*/tokio_timer/): &gt; These three types are backed by a Timer instance. In order for Delay, Interval, and Deadline to function, the associated Timer instance must be running on some thread. If you use a version of `tokio` that was updated to run a timer inside a `Runtime`, it will just work. Alternatively, you can manage a `Timer` yourself, but the former is much easier.
`PhantomData&lt;*const T&gt;` is not Send and not Sync. You need `PhantomData&lt;fn(T) -&gt; T&gt;`.
But not on this scale. C++ can specifically infer the template parameters of a function from its arguments, but AFAIK not much beyond that. For example, tye following won't be valid, since the compiler cannot infer Foo's template. template &lt;class T&gt; T Foo() { return T(0); } uint32_t x = Foo();
https://crates.io/crates/wasmi would be the foundation of this.
 I don't know of any crate that implements it, but you can always call the glibc `crypt` function with `'$6$'` as the salt parameter. Sadly it doesn't seem to be excited by the libc crate. I'm not behind a computer, but declaring the `extern "C" fn crypt(key: *const c_str, salt: *const c_str) -&gt; *c_str;` function should be a decent start. But an even better variant would be using the `crypt_r` variant, but that one is a little trickier (but thread safe).
You can use [`sha2`](https://docs.rs/sha2/) crate for hashing and [`base64`](https://docs.rs/base64/) crate for converting binary array to base64 string. IIRC to implement SHA512-CRYPT you'll have to write a simple loop.
I added more print statements and the reason turned out to be pretty silly: The server doesn't actually send 4 zeros at the end. The reason is that you resize self.inbox to "read_from + need" = "0 + 4" just before calling poll_read on the stream. "self.inbox.truncate(read_from)" if "n == 0" is needed to get the buffer back to its original state. After that we can just do the old check: if n == 0 { self.inbox.truncate(read_from); if self.inlen() != 0 { eprintln!("{:x?}", &amp;self.inbox[..]); bail!( "connection closed with {} bytes left in buffer: {:x?}", self.inlen(), &amp;self.inbox[self.instart..] ); } else { // Server closed session normally return Ok(Async::Ready(())); } } Another very minor thing is that "self.inbox.resize(read_from + need, 0);" sometimes tries to allocate more than necessary. read_from here should probably be replaced with original_len which is self.inbox.len() before entering the loop.
What does this mean for breakage? Are clippy tests now required to pass for PRs? 
For anyone that wants a native English speaker to proofread/edit their articles, I would be willing to do that. If anyone wants to take me up on that, send me a PM when you have something for me to read, even if you’re reading this in the future!
I'll get it included in Call for Participation.
Because you mentioned [libloading](https://crates.io/crates/libloading) in your post, I thought you might also want to look at the three libraries listed below that have libloading as a dependency. Since you're thinking the plugins might be written in Rust, the libraries might serve your needs after all: * [dynamic\_reload](https://github.com/emoon/dynamic_reload) \- " cross platform library written ... that makes it easier to do reloading of shared libraries (dll:s on windows, .so on \*nix, .dylib on Mac, etc)" * [live reload](https://github.com/porglezomp-misc/live-reloading-rs) \- Makes it possible for "your main host program \[to be\] a wrapper around a dynamic library that does all the interesting work of your game. This means that you can simply reload the library while the game is still running, and have your game update live" * [hotswap](https://github.com/draivin/rust-hotswap) \- " A library for hotswapping running code with minimal effort." Note: described as a "prototype." 
I had the same issue! I studied Russian a couple years in college, and now I can't help but read "СЧЯСОПЏ" as "schyasopts" (I had assumed Џ was a variant of Ц but I guess it's a [Macedonian / Serbo-Croatian letter](https://en.wikipedia.org/wiki/Dzhe)). Боже мой...
Rather than dynamically loading libraries, perhaps you could just use an IPC mechanism?
Man I love Rust but sometimes its syntax makes my eyes bleed.
I've been enjoying writing the backend for an application in rust, but I'm thinking I might want to write the GUI in another language. Would it be practical? Would it make sense? Can anyone with experience writing GUI code suggest what language I might want use? Thanks!
If I’m able to find a bit of money, where would I donate to where the money would most directly go to this research? (Specifically for rust )
Thanks, I've read it, it explains the state of the relation between arduino and rust well. I haven't try anything yet though, but got the intention.
Ohhhhhhhh, that's so silly! Care to submit a PR? I think the right thing for `poll_read` to do is return `Ok(Async::Ready)`, and then the higher-level code (i.e., `Packetizer`) could check whether that was expected or not. Ah, yes, you're right. Feel free to include that in the same PR!
[awesome-embedded-rust](https://github.com/rust-embedded/awesome-embedded-rust) is a solid starting place. If you want to use Rust with microcontrollers, I would recommend getting an ARM board and shelving the Arduino for the time being. Most of the Rust embedded work revolves around ARM devices, so they will be better supported. 
Currently PRs can break clippy and still land (we get pinged), but nightlies will not happen until tools are fixed.
The components have a manifest file, so \`rustup component add foobar\` works if there's a \`foobar.something\` file at some URL. They get pulled into the .toolchain folder somewhere (under \`bin\` i think) \_however\_, the \_shims\_ are hardcoded into rustup -- these shims exist in your PATH and when called will pick the right binary to proxy to. This is why the rustup update is needed.
I haven't had much time to work with Rust lately due to some changes in my personal life, but WebAssembly is very high on my personal interest list. I'll be bookmarking this for later, thanks for your hard work!
Is limn yours? It looks promising but I tried to use it and found the layout system to be confusing and difficult to use.
Yes, this is also the impression that I got after reading the comments of the post that pwoosam shared.
There's an easier way. The `SlotMap` and `Key` could be dependent on a type that is only used as a marker so you don't confuse keys to different maps. ```rust pub struct TypedSlotMap&lt;T, Marker&gt; { ... } pub struct TypedKey&lt;Marker&gt; { ... } pub type SlotMap&lt;T&gt; = TypedSlotMap&lt;T, ()&gt;; pub type Key = TypedKey&lt;()&gt;; ``` You could then use an empty struct as a Marker to ensure your keys to your maps have different types.
Thank you very, very much
I don't how good c++ a compiler can deduce types but for the first particular example it should be able to deduce. Your example is also true as well.
No, but for nightlies.
No I don't think it will work here, I was speaking generally about generative types.
Should [this line](https://github.com/jonhoo/tokio-zookeeper/blob/master/src/proto/mod.rs#L413) return an error then? Since we're not exiting but the TCP connection to the server was broken somehow.
Replace impl&lt;R: Iterator&gt; Iterator for RelIter&lt;R&gt; with impl&lt;R&gt; Iterator for RelIter&lt;R&gt; ...you probably want to increase `RelIter.pos` somewhere too or you'll get an infinite loop.
Cool! Inspired me to do this another useless thing: [glітсн тёхт апіматіоп](https://i.imgur.com/ZjbOxli.gifv)
Hmm... That's a good question. I think it probably should even though it was a "clean" disconnect from the server (i.e., not in the middle of a response). Returning an error also means that we'll try to reconnect, which is likely the right thing to do.
Check out the wasm-bindgen project, a way to communicate between rust and js that's endorsed by some of the core rust devs. Also web-sys, a project to generate rust bindings from webidl files
Alright, I'm all good up to here: let bar = sm.insert("bar") assert\_eq!(sm\[bar\], "bar"); sm.remove(bar); But what happens if I then try to access sm\[bar\] again?
Ok then, I'll submit a PR with the changes we've discussed. Thanks a lot for being quick to respond. I appreciate it.
What's the difference between doing `SPC-foo-bar` and `SPC-foo.bar`? I'm trying to understand why/when you would use the `[[.subart]]` syntax. Great work, by the way. I'm definitely going to use `artifact` in my next project!
That's an interesting alternative I'd never considered. Thanks.
-loose +lose Yes, otherwise nice article 
I've almost completed a post that is basically one big call for participation on a number of bugs before I received your reply. https://www.reddit.com/r/rust/comments/8zpp5f/ Now that I think of it, I would like to see it included. Sadly it's not particularly readable on old reddit's grey background.
It's awesome to see slotmap getting used outside of C++! 
The hero we don't deserve.
[stdweb](https://github.com/koute/stdweb), a similar project that predates wasm-bindgen, might be also worth a look.
Stm has boards with adruino-compatible headers, cheap too. 
This is great. I'm not a security expert, but this really makes me want to go bughunting myself.
I am not a security expert either. Fuzzing is almost point and click. The vulnerability this post is about was not found by me, it was found by the crate maintainer after I killed off all the other unsafes in the crate. You really do not need to be a security expert to fuzz code, or to fix most bugs it turns up, or to refactor unsafe code into safe.
Are you referencing that “Secret Hitler” card game? I've heard good things about it, but I haven't played it.
You can always write up a tiny lisp for a plugin language. GNU Guile is a full-featured scheme for that purpose but you can always roll your own a'la halo's BLAM.[http://halo.wikia.com/wiki/Blam!] (that being said lua or python is probably the easiest)
Uh...this is basically the same thing that would happen in a `BTreeMap` or a `HashMap`...if you want something that returns an `Option`, `SlotMap` also imitates the APIs that `std` trees offer with the [`get` method](https://docs.rs/slotmap/0.2.0/slotmap/struct.SlotMap.html#method.get).
[This](https://github.com/gnzlbg/cargo-asm) may be of use for inspecting results (or lack thereof) of optimizations in whole projects.
how did you do that?
This is awesome! By the way, it sounds like you’d enjoy cargo-asm.
Thank you!
Really impressive work! Thanks for doing such a thorough write up and promoting the fuzzing ecosystem of Rust.
Updated the post with it. Thanks!
Yeap. I haven't played it myself, just talked about it with friends. 
&gt;schyasopts doesn't sound too bad to me :) 
Oooh, indeed! This is pretty much what I was looking for. Is there a list of all external cargo subcommands anywhere? This is the second time I'm looking for something cargo-related and can't find it but someone points out it to me later. Now if there also was a guide on using `-Rpass-missed` and `-Rpass-analysis` on Rust code, refactoring unsafes into safe code would be much easier.
They can be extended by anyone, so there’s no complete list. “cargo foo” will first look for “cargo-foo” on your $PATH.
I'm coming from Python as well.. Signed/unsigned ints are pretty easy. What are you confused about? Strings however are a real pain in the ass for me currently. 
Rust has the best fuzzing integration I've ever seen, hands down. Worlds better than C, and the fuzzers were *designed* for C. I can literally make an in-process fuzzing target and launch it in under 5 minutes. I wish there was some kind of target reuse between fuzzers, though. I end up writing a target once and then copy-pasting it into a subtly different template for each fuzzer. https://github.com/rust-fuzz/targets does that if you put your target in there, but it doesn't build on stable, and putting your target in there means that the fuzzing target will be decoupled from the project source code and likely not updated for future API changes in your crate.
Welcome to computers! It is going to be fun!
There are a few lists of external cargo subcommands: * https://github.com/rust-lang/cargo/wiki/Third-party-cargo-subcommands * https://crates.io/categories/development-tools::cargo-plugins Neither is really complete, though.
Juts some fun things to think about for people who are new to this: * what happens when you add one to the biggest signed int? unsigned? why? how? what if you want to \*change\* what happens? * Is there a negative 0 and a 0? or just one 0? what about floats? * What happens when you use a 64bit int on a 32 bit cpu?
Please enlighten us!
&gt; Is the function secure now? Well, maybe. Maybe not. Unless we either rewrite it in safe rust (or prove its correctness, which is a lot harder) we will never know. If by "prove its correctness" you're thinking of rigorous formal verification, this isn't really a fair equivalence, since the compiler and standard library aren't formally verified. And there are some [known issues](https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3A%22I-unsound+%F0%9F%92%A5%22). I've been meaning to write a blog post questioning the fear people have of unsafe code (even if it is as trustworthy as standard library code), and faith in safe code. But I'm admittedly being somewhat pedantic, and the OP's work here is pretty awesome.
I don't know all the answers! Float do have a negative zero though! And here is a good article about overflow: [http://huonw.github.io/blog/2016/04/myths-and-legends-about-integer-overflow-in-rust/](http://huonw.github.io/blog/2016/04/myths-and-legends-about-integer-overflow-in-rust/)
I used [`console`](https://crates.io/crates/console) crate and list of homoglyphs from [here](https://github.com/codebox/homoglyph) Yea, I meant fun, not useless =)
&gt; cdylib Very interesting. I've been using `dylib` and not having trouble, but that may just be the particular way I implemented it was lucky not to hit this issue. For the lazy who want to know what cdylib is for: https://github.com/rust-lang/rfcs/blob/master/text/1510-cdylib.md
You'll notice in the code (and I forgot to mention it above) that it only comes into play with threads.
To be fair, the critical parts of standard library are undergoing formal verification. And they do find bugs in the process, but they're usually [subtle enough not to manifest in practice](https://www.ralfj.de/blog/2018/07/13/arc-synchronization.html). Of course, Rust safe code is still not 100% trustworthy because the compiler is not verified. But generally the risk of something going horribly wrong in Rust compiler is relatively low compared to something going horribly wrong in the kernel with millions of lines of C code in it that your Rust application code runs on, so it's a secondary concern. Ultimately, no software is perfect because it runs on real hardware in a universe with real physics, that does throw interference and whatnot at it. If you need really high assurance in your software, you design the system around it being imperfect. Erlang is pretty much the embodiment of "your software and hardware are imperfect, deal with it". And in a world where nuclear power plants run C kludges from the 80s, even mildly unsafe Rust is one hell of an improvement. As a side note, I really liked that paper where they have poked holes in LLVM memory model and then suggested a new one that was correct and also allowed optimizations that weren't possible in the old one.
&gt;what happens when you add one to the biggest signed int? unsigned? why? how? what if you want to *change* what happens? In debug mode, these panic. In release, they overflow to the smallest integer. You can change this behaviour using the wrapping_add/saturating_add/etc. functions instead. &gt; what happens if you transmute a negative signed number to an unsigned? what happens if you use "as"? 1. Never use transmute if you can avoid it. It is almost never correct. I'm not sure of the behaviour here. I'm not even sure if endianness matters here. 2. For the `as` cast, I'll just link to the [reference](https://doc.rust-lang.org/nightly/reference/expressions/operator-expr.html#type-cast-expressions). &gt; Is there a negative 0 and a 0? or just one 0? what about floats? There's only one zero, and it has the bit pattern of all zeros. Incidentally, this means that largest negative integer is one higher than the largest positive integer in signed ints. &gt; What happens when you use a 64bit int on a 32 bit cpu? The expected behaviour will be the same. Performance may vary though, depending on which instructions are available on the CPU. If the CPU has instructions for operating on 64 bit data, the compiler can just use those. Otherwise it has to use more instructions to do the operation. Note that 128 bit integers have the same issues today.
If Python programmer have used numpy to a certain extent, all those questions will be old news for him.
Same here. Hitting source on the comment revealed it. Here's the link for those who don't see it: https://www.reddit.com/r/rust/comments/4oxfe8/will_we_ever_see_rust_for_arduino/?_branch_match_id=547924739124471021&amp;st=JJPSZTAO&amp;sh=5e448946
Couldn't crates.io provide that, by scanning all published crates' Cargo.toml? 
Thanks so much. I have learned many other languages before but Rust is kicking me all the time :). 
Don't suppose getting a working browser is practical? That could really open the doors of functionality.
This borders on tautology! 
&gt;Never use transmute if you can avoid it. It is almost never correct. I know what you mean here, but whether it is almost never correct I think really depends on the problem domain. Like the libm port uses it all over (well, equivalent to_bits() instead) and simd code often needs to use it. But definitely something to avoid unless you are experimenting or know exactly why you need to be doing it. 
What's Rule 90?
I used Python for over 15 years before coming to Rust, I feel confident in my ability to use Rust, and I enjoy helping people, so feel free to poke me if you have any questions. (Including by private message, if you prefer, and questions about what crates to use are also fine. I've been lurking here since before Rust 1.0 and have been taking notes.)
Oh no, sorry for not getting back to y'all! I haven't had a lot of energy recently for rust stuff so i haven't been able to get to your questions. Here's what i can tell you offhand, though: * `CursorIter` will only change the cursor references when it successfully receives a page. However, keep in mind that it will also only update its own cursor references in the `Stream` implementation. If you're handling the calls manually like that, you'll need to look at `resp.response.next_cursor`instead of `followers_cursor.next_cursor`. * I believe the idea behind Twitter returning the timestamp like that is that you can sleep to that point and be fine. IIRC that timestamp is in UTC but otherwise that's the intended purpose. * (Looking at it again, it looks like i don't have `Clone` implemented for `CursorIter`! I'm not sure whether i can just derive it, though, since it holds the hyper Response, but your idea there won't work, sadly.) * The `Stream` implementation basically just bails when it encounters an error, doing no processing and instead passing it on up the chain immediately. It kinda made the transition from `Iterator` to `Stream` kinda poorly, because when the stream returns an error it's basically gone. Your best bet it to do what you wound up doing: don't use the `Stream` at all, and instead manage the cursor handles manually and use `call()`. Looking back at this, it's incredibly unfortunate and i should probably rework it somehow. IIRC a forthcoming release of `futures` changes how futures and streams deal with errors? Maybe i can tap into that whenever that comes around. * As far as i can tell, it's totally fine to lean on `core.run` like that. What that's doing is starting the future in the reactor and sleeping your thread whenever it decides to suspend its task. Thanks to how hyper and tokio are set up, that basically means that your thread is blocking on the network call, just like it were a synchronous call. It's not that great if this is in the middle of a big application and you need to deal with multiple threads' worth of Futures, but i use it in all the examples because it's the way to turn async code into sync code. `egg-mode`'s model of error handling is "as soon as i get an error, wrap it up and pass it on". As far as the types and stuff, that error enum was decided upon before `failure` and `error-chain` were a thing, so it's probably not the most idiomatic any more. This habit of bailing immediately has some sharp corners like the aforementioned `Stream` implementations. To be honest, i'm not totally sure the best way around it from a library design perspective, but i also haven't worked on `egg-mode` in months, so i bet there's something i'm missing.
Yeah, but that *is* what you said you wanted. If you don't want that, then implement `Mul&lt;TheType&gt; for TheType`, `Mul&lt;TheType&gt; for &amp;'a TheType`, `Mul&lt;&amp;'a TheType&gt; for TheType`, and `Mul&lt;&amp;'a The Type&gt; for &amp;'a TheType`.
It would be really nice if we implemented a "web of trust" or something like that with cargo. For example, say I want to publish a version of my crate called A. So when I run the cargo command to publish, cargo indicates me a crate update from crate B that needs to be audited. So I'd need to audit the crate B version and write a summary of the audit (found 1 unsafes, needs fuzzing, etc. along with respective Github issue links). Then if it's deemed ok, I approve the crate B version and it gets published. After that then my crate A gets available for auditing by some other crate randomly (or not) before its new version can be published. That would also probably solve the issue with name squatting. If someone could work on that idea and figure out a nice way to make something like that work, I think it would be pretty helpful for the whole ecosystem in general, and depending on how it goes, other package managers (ahemnpmahem) could possibly adopt the same system. And for that, inspiration on trust management systems and maaaybe Tangle (from the IOTA cryptocoin) might come in handy.
Well I've wanted to fuzz chrono for a pretty long time, but I haven't found the time. The only unsafe that is has is a couple of \`impl Send\` that seem correct, but it does a bunch of parsing that could potentially lead to panics or some other form of DoS. So if anyone is looking for a potentially high-impact project to fuzz...
If I had to guess, your path probably didn't get updated. You definitely need to open a fresh terminal after installing, and you may need to log out and back in (reboot if necessary). However, since you mentioned messing with your firewall, do you suspect that you're having trouble downloading something? If you give more information, we can probably get you up and running.
Does it though? I would imagine that in many cases, it could unroll the loop to avoid the check, but len would need to be known at compile time. I don't know if the compiler can partially until loops.
Do you have a link to that LLVM memory-model paper?
Just so you know, reading a mix of Cyrillic, Latin, and Hebrew? alphabets is painful. I'm glad you got it working. :)
I'm not sure why, but I was under the impression that there was a fuzzer-as-a-service like [travis.io](https://travis.io) that runs on these kinds of projects, but it would appear not. I agree with you that these projects deserve to be set up with fuzzers and auditers, but this kind of effort could go by the wayside eventually if not automated (as you pointed out, "you've got better things to do \[...\]" than audit your crates all the time). I've saved this post, and I'll come back to it once I've played with fuzzing more, as I am working on a project and automated testing will be a first-class priority (after my last job where there were 0 tests, I can easily say I've absorbed enough stress to want to go in the direction of the other extreme and test all the things).
`transmute` between `iN` and `uN` does the same thing `as` casts do: reinterpet the bits. For any `transmute` usecase where there is a safe alternative, *always* use the safe alternative (i.e. `as` in this case).
Both Libfuzzer from llvm and go-fuzz are similarly point-and-click.
[Quickcheck](https://github.com/burntsushi/quickcheck) and [proptest](https://github.com/AltSysrq/proptest) are basically a cross between unit testing and fuzzing, and that's pretty easy to put into any CI, including Travis. I am not aware of any continuous fuzzing services other than OSS-fuzz which is hosted by Google gratis, but that's for high-profile open-source projects only.
Found it: https://www.reddit.com/r/rust/comments/8wfu24/
It's not about how good the compiler is, it is all about what the standard defines
Awesome! This is super useful for game devs
Just an idea if anyone wants a project: make a website that greps for unsafe in cargo packages, sorted by number of downloads (ignoring `-sys` packages). Bonus points for a community voting system to prioritize them. I'd love to help, and having a TODO list would be a fun way of getting my feet wet. A sweet side-benefit is that we'd likely end up with more automated unit tests, benchmarks and fuzzing. It would also be cool to have something similar, but for code coverage, clippy warnings, etc.
There are already crates for counting `unsafe` and estimating how complex the code under them is various ways. One such crate was elected crate of the week just last week, see https://github.com/anderejd/cargo-geiger I agree that having such a continuous healthcheck for popular crates would be nice.
As far as I know, the browser is functional. I hope the servo engine from Mozilla becomes mature enough so they don't need to make their own.
Could you also have a sort of "secondary map" that is very similar, except it never allocates keys, but instead uses keys from other maps? So pretty much `BTreeMap`/`HashMap` with a `slotmap::Key` key, except you would not have multiple entries for different generations/versions, only for the latest one that was inserted.
There were some early comments about Servo that gave hope on this front, but later discussion with devs (I've had) indicate that it's fairly unlikely. At least there's no thoughts that Servo will be replacing Gecko. Gecko is *huge* and has taken many years to grow while Servo will continue to be considered a research renderer and successful parts of it replacing parts of Gecko. It would take a long time for Servo to get to the place where it supports the broad webstack in the way that the major browsers do. However they would like to see it embedded special-purpose applications.
Looks very similar to [Froggy](https://github.com/kvark/froggy). The main difference is that Froggy has built-in garbage collection, but the target userbase is the same ("game entities or graph nodes"). Could you add "Why not froggy" section in Readme?
Have you tried restarting your router?
Well, I think Redox is a special application.....
:) One of the examples I'm aware of is for use in VR, where it can benefit from high performance, high fps and full control over the content (don't send web tech that's not supported).
Oh no, it seems that the harmful Python2 approach to the module system "let it all be in the same scope" is still being pursued. The way it was shipped in the first version of the edition was fine. With only `extern crate` removed you have no idea if something is from the local crate or somewhere else. With this last minute major change you have now three options: root module in the local crate, item locally in scope, somewhere else. This will harm readability of Rust programs by a high degree. *already now* I'm wondering whether something comes from a local module or an external crate. Definitely not a positive sum change at all.
Looks like it uses [https://crates.rs/scrap](https://crates.rs/scrap) underneath, so Linux/Windows/macOS.
Hey Allan, I've watched your talk to make decisions during the design process (although I was aware of this data structure a lot longer). Make sure to snoop the source code. `DenseSlotMap` is what you describe, but `SlotMap` is a 'sparse' variant that has does not store its items contiguously, but right there with the generation/version counters. This saves an extra array access.
I don't get the fear of not knowing if something is from an external crate; shouldn't you know what the crates you've included are? I know `serde` is a bad example since everyone knows that crate, but how does `use serde` at the top of my file add anything? Or, for that matter, use `unic`? You already need to know what crates are included because they all can be `use`d. And for that matter, what does it matter, assuming agreeable naming of APIs, whether something is an external crate or a local module? (Modulo orphan rules of course.)
What, exactly, is a last-minute change? The removal of `extern crate` was proposed and accepted in 2017 with [this RFC](https://github.com/rust-lang/rfcs/pull/2126). I'm honestly interested to see if I find the new relative paths confusing. I have a suspicion I might share your initial impression -- I wonder if it would be possible to propose a lint like `#![deny(relative_imports)]`?
make sure you follow :) 
&gt; shouldn't you know what the crates you've included are? I don't have photographic memory. Sometimes I know &gt; And for that matter, what does it matter, assuming agreeable naming of APIs, whether something is an external crate or a local module For local modules, I generally inspect the source code to find out stuff about them, for crates I generally inspect rustdoc. Local modules I can edit, external crates I can't.
AFAIU, conflicts in use statements would produce a hard error, so use statements, at least, would always be unambiguous. I'm not sure what you mean with "root module". Non use path would resolve local scope -&gt; extern crate -&gt; prelude. The 2015 edition was local scope -&gt; prelude.
I was not aware of Froggy. From a quick look at it the main differences appear to be that it returns ref-counted smart pointers to the underlying storage whereas slotmap only ever gives back weak keys. slotmap is a lot lower level, essentially making you do manual memory management, with the caveat that you needn't worry about detecting dangling pointers. Wrapping slot map keys into reference counted smart pointers isn't that difficult to do though, if you so desire. And as always, any graph with cycles simply can not use reference counting alone for memory management. Froggy also doesn't appear to support `serde`, which for graphs is quite a killer feature IMO.
You're on the right path. The specific example you posted (different numeric types) will be easy to deal with after reading and practice... I suspect other issues will as well.
Opened my first PR in [Grin](https://github.com/mimblewimble/grin), next one on the way.
In what case are paths open across &gt;root module in the local crate, item locally in scope, somewhere else ? In the 2018 edition as I understand it, a path cannot start with a root module. The possible ways to start a path are with a keyword, a crate name, or in this proposed new model, which is listed as "available", a locally defined name. If you're really worried about accidentally confusing relative and absolute imports with this, you are still capable of starting paths with `::` to force them to be absolute. (I even was in favor of using `::`-prefixed paths always to get 1path.) ---- (This post is not intended to be in favor of against any particular modules change, just in an explore-the-position.)
Right, that RFC is old. But now it has been changed in some non-detail ways. The [thread](](https://internals.rust-lang.org/t/relative-paths-in-rust-2018/7883) is linked in the linked announcement. It was already pointed out in that thread that the change is last minute. &gt; I wonder if it would be possible to propose a lint A lint could be introduced to solve this for my own code, but if it weren't on by default, most codebases would probably not use it. So it wouldn't help me to understand codebases by third parties.
You want r/playrust
In external codebases in the 2015 model, you still don't know anything about crate versus module. If anything, they're more similar due to how `extern crate` just dumps the crate into your crate's namespace. In the 2018 model, without _or_ with local paths, the single leaf `.rs` contains enough information to know whether an import is from a crate or a local module. In the 2015 model, you have to check `lib.rs` to see what names refer to an external crate mounted into your namespace, and what is a local root module. Without local paths, a crate name is a level higher than a module name (which is `crate::mod_name`). With local paths, you have all of the information locally to know what names are local, and the others are therefore crates.
&gt; The possible ways to start a path are with a keyword, a crate name, or in this proposed new model, which is listed as "available", a locally defined name. Oh right. I've re-read the proposal. So it doesn't count the root module then. That means that the change doesn't increase the number of possible sources but also doesn't decrease it. Still, the situation is made worse due to the `extern crate` removal. With `extern crate` removed it's even more important to know when something is from an external crate and when something isn't. Packages imported in Cargo.toml often have the same name as the crates inside, but they don't have to.
I'm confused as to what you exactly mean, could you elaborate a bit (maybe with a little code example)? 
&gt; the single leaf .rs contains enough information to know whether an import is from a crate or a local module. There are glob imports. But it is definitely an interesting angle to look at the question.
You can skip the 'Scalar' and encode the columns as enum, e.g. ```rust enum Column { Int32(Vec&lt;i32&gt;), Int64(Vec&lt;i64&gt;), } ``` In this way you should be able to reduce the pattern matching once per column, not once per value. Take a look at my experiment, it looks close to what you want to achieve: [https://gist.github.com/luben/95c1c05f36ec56a57f5624c1b40e9f11](https://gist.github.com/luben/95c1c05f36ec56a57f5624c1b40e9f11)
Has there been an RFC for the new change? I would assume there has to be before it can be considered for the edition, especially since there were so many module system RFCs already. 
There are multiple approaches for this right now, all of them undocumented and unfinished at this point. 1) you can do the same that you would do in C, which involves a lot of unsafe code. I've written a blog post about that some time ago [here](https://coaxion.net/blog/2017/09/exporting-a-gobject-c-api-from-rust-code-and-using-it-from-c-python-javascript-and-others/). By following the C GObject documentation and expanding the C macros yourself and converting to unsafe Rust, this is probably the best documented solution so far. 2) (gnome-class)[https://gitlab.gnome.org/federico/gnome-class], which provides a procedural macro to write GObject subclasses in some kind of C#-style DSL. This currently does not have support for subclassing any existing classes from what I understand, and not GTK ones. So for your use-case it's not there yet, but any help would be welcome 3) (gobject-subclass)[https://github.com/sdroege/gobject-subclass/], which allows subclassing with (mostly) safe Rust by implementing various traits. I extracted that from the code I'm working on since quite some time to allow writing (GStreamer)[https://gstreamer.freedesktop.org] plugins in Rust, which basically also involves subclassing. There are a couple of companion crates for this: [gio-subclass](https://github.com/sdroege/gobject-subclass/tree/master/gobject-subclass), [gtk-subclass](https://github.com/sdroege/gtk-subclass) and [gst-plugin](https://github.com/sdroege/gst-plugin-rs). Each of these contains some glue for specific classes from the GIO/GTK and GStreamer libraries to allow subclassing. GIO/GTK don't contain much yet, but that's where stuff for `GtkWidget` and friends would be at some point. Only the latter is fully usable at this point and I'm using that one in production. For the latter I wrote some tutorials [1](https://coaxion.net/blog/2018/01/how-to-write-gstreamer-elements-in-rust-part-1-a-video-filter-for-converting-rgb-to-grayscale/) [2](https://coaxion.net/blog/2018/02/how-to-write-gstreamer-elements-in-rust-part-2-a-raw-audio-sine-wave-source/). That glue code for specific subclasses can be more or less autogenerated, and there's a PR for adding a mode to the gtk-rs code generator [gir](https://github.com/gtk-rs/gir/pull/604). For some comparison, thoughts of 2) and 3) and how they go together also see this [mail](https://mail.gnome.org/archives/rust-list/2018-July/msg00001.html) I wrote some days ago. ---- So in summary: yes it's possible but it's not completely there yet or very ergonomic. Your best bet at this point for fast results would probably be to help out with 3) to add support for the specific GTK classes you care about. I'd be happy to help with that, and (see the mail I quoted above) that will likely also be useable in combination with 2) at a later time.
 let entity = entities.insert(Entity {...}); positions.insert(entity, Pos(0, 0)); velocities.insert(entity, Vel(-1, 1)); In ECS terminology, positions and velocities are components. The cool thing though is that `SlotMap` could allow something close to an ECS but much simpler (or even have `specs` build on top of it). The positions/velocities "secondary maps" could be regular btree/hash maps, but that's less efficient than using *only* the `index` half of the slotmap `Key` as the map key, and placing the `version` inside the map value (next to Pos/Vel in my example), for checking. All of this *does* seem a bit error-prone, as `Key` is not tagged with the element type of the slotmap even, but it'd be cool to have at least as a basis for a higher-level API.
I dealt with this sort of thing in ggez, by borrowing a technique from Servo: a type that contains a unique ID in debug mode and contains nothing in release mode. In debug you can check which key belongs to which collection, and in release it all compiles down to nothing. Details: https://github.com/ggez/ggez/issues/326
That was the reason why I didn't mention a specific compiler like 'gcc' or 'clang'.
I see now. To put it in SQL terms, I'd assume that `positions` and `velocities` would be `FOREIGN KEY entity ON DELETE CASCADE`, that is if `entities.remove(entity)` is called, its components would also be deleted? 
That's a good point. I'm not aware of such an RFC. Maybe they'll declare it as resolving an unresolved question of the already mergedpaths RFC or something. Then it'd need only an FCP.
I'm considering implementing something like this, yes. 
Just to be clear here, as I explained on the PR itself, it's *impossible* to encode a distance of 0 in the DEFLATE format, *no matter how badly* you butcher it. The calculation starts with 1 then adds some powers of 2 and a variable width integer from the bitstream, so the only way you'd get 0 is by overflowing, but that's impossible given the maximum width of integer ever being read (which is hardcoded and malformed input can't bypass it). It'd be cool to use `NonZeroU16` here, but inflate supports old stable versions so that won't happen any time soon.
I had forgotten about `#![forbid(unsafe_code)]`. No documentation is needed to understand what it means so perhaps it should be added to the templates used by cargo new? 
This is also a pretty elegant solution, perhaps I will implement it.
All of the functions which have `?` after then return a `Result&lt;T, E&gt;`. (Either a result or an error) The `?` says "If the Result contains an error, `return` the error immediately." For example, the `let mut file = File::open("foo.txt")?;` line would wind up looking something like this without the `?`: let mut file = File::open("foo.txt"); let mut file = match file { Ok(f) =&gt; f, Err(e) =&gt; return Err(e) };
Thank you
/u/Shnatsel: This is a great writeup! Would you mind turning some of it into a blog post, especially the parts about your workflow?
Yes, but chaining the removes is impossible without a wrapper that contains both entities and components. I'd rather have that be a higher-level API on top of primary and secondary maps.
&lt;3 This research is funded, in particular, by an ERC (European Research Council) grant, a French national grant and various other public sources of research money. So, if you are paying taxes in the EU, you are already financially supporting us. :-) At MPI we are also pretty well-funded, and I don't know of a donation page. So, if you have a bit of money for donations, maybe send some of it to Mozilla and some of it to other open-source projects that you use frequently? Also, don't forget to tell your local representative that public funding for basic research is important. :D
Is it mandatory to use ? when return type Result&lt;T, E&gt; ..if i don't care returned error Below example code thrown compilation error when i missed to give '?' in the second line(SAYING " no method write_all). But when ignored the 3rd line '?' , it did not throw error.. fn editor_file_write (text1:String){ let mut file = File::create("foo1.txt")?; // error. if i miss ? file.write_all(text1.as_bytes())?; // no error if i miss ? Ok(()) }
I think you mean to post this to r/playrust This subreddit is about the programming language \`Rust\`; not the game :)
Perhaps I'll add a `key.slot_index()` and `key.slot_version()` API at some point. I'm a bit wary of adding it right now, as the internals might still change and exposing them in a public API will make people rely on them and make it harder to change things. Right now I'm still in the early design &amp; feedback stage, and would like to keep options open. --- Regarding the tagging of `Key`, I'm quite keen on a suggestion by /u/2brainz: https://www.reddit.com/r/rust/comments/8zkedd/slotmap_a_new_crate_for_storing_values_with/e2kcyac/
oh okay my bad, thanks tho!
Ignoring a `Result` is not an error, but the compiler will warn you about it. To ignore it, and let the compiler know you've thought about it, use this: let _ = file.write_all(text1.as_bytes());
Having Cargo manage pre-releases (beta builds) would be awesome. Currently it's possible to publish them (e.g. `1.0.0-beta1`), but they get little testing (unless you publish this yourself) and there's no enforcement e.g. that `1.0.0` is similar to the last beta (ideally it would be equal to the last beta with as many betas as necessary to get it right, but most devs don't seem to have the time for that). It would be awesome if say Cargo let you publish a candidate `1.0.0` and automatically released it as, say, `1.0.0-pre.0`, and then after review you could say "cargo, make the full release from `1.0.0-pre.2`".
Thank you so much for doing this and for thid very interesting writeup.
I like keeping the details private, which is why I thought having another map type in the same crate would help.
This is my first time in /r/rust, I joined because I'm interested in learning the language and I only understood about 80% of what you just said. But from that, I gain that you took a lot of effort in making things more secure for everyone, so thank you for your effort.
&gt;For instance, the concept of signed and unsigned integers and how machines represent numbers and characters in general, seems to be much more important to know when learning Rust. To make a really optimized program, one needs to know about how the machine works, but otherwise one can mostly view types as information to other programmers; this variable's values can only be positive (uXX), this variables values can have decimals (fXX), the minimum and maximum values of this variable are between these values etc. If one doesn't care about the performance then one can just use some bignum library's types the whole time or f64's just like in JavaScript and make casts when the compiler tells you to. :-) To make correct calculations with floating point values one needs to know a lot about them, but that knowledge is needed with Python too.
PSA: That `cargo install --force cargo-fix` invocation will go away soon as cargo-fix is now part of cargo itself! (Will land in nightly in a bit.)
You mean: it's required to read the `Cargo.toml` to understand which external crates are in use now. This is especially true if [external crates may appear under a different name](https://github.com/rust-lang/rfcs/pull/2126#issuecomment-325014433); I'm not sure what the status is on this (although partly I'm in favour: it allows direct use of multiple versions of a crate simultaneously).
Thank you very much for detailed explanation. I will read your blog post as well as check the crates you've mentioned when i got back home. I would like to help as much as I can. 
WASM does sound like a game changer when it comes to portable code. Somewhere I read that it could be used similarly to JVM applications with less overhead.
I shall read up on IPC. Thanks!
Neat, thanks for sharing, will get reading.
Would I be able to create C ABI compatible libraries with Rust?
You can use the `pwhash` crate, which provides a number of classic Unix password hashes. The following example uses a `crypt(3)` workalike to demonstrate that using the same inputs as your sample values would generate the same output; a more realistic program would probably use `sha512_crypt::hash()` directly. extern crate pwhash; use pwhash::unix; fn main() { println!("{}", unix::crypt("1234", "$6$WSaFG5yTXdRie1QQ").expect("hash")); } 
Lua was mentioned by someone else as well. I need to see if a scripting language or a DSL would be a good idea.
I'm a proponent of good defaults instead of good configuration. If adding it to the default template is a good idea, might it be a better idea to make unsafe forbidden by default instead? It'd not be a big burden on a crate that actually wants to use unsafe, but it would add an extra threshold. "Do I _actually_ want to use unsafe here?" I think it would be nicer to have `#![allow(unsafe_code)]` declared for crates that use `unsafe` rather than `#![forbid(unsafe_code)]` everywhere else. (In both cases the attributes could have a more local scope than crate level. The discussion still mostly applies.)
Here `file` is of type `Result&lt;File, io::Error&gt;`. That's make it obvious why there is no `write_all` method.
Sorry about that. Bad wording. I mean when I run it, a command line appeared and its suddenly closed. 
see my reply in u/K900_ comment
Try running it from a command prompt window. What is the output?
I already downloaded and installed rust manually via .msi. I've set the path manually too. I used to have an issue with network but now its resolved by recent windows update. 
Yes, I thought about that as well, but then I thought that unsafe is part of the language. It should be usable without having to look at the docs to figure out that allow(unsafe_code) needs to be added first. On the other hand I guess the compiler error could mention it.
Thanks, now its all clear. Didn't think of this before. Here's the output : error: it looks like you have an existing installation of Rust at: error: C:\\Program Files\\Rust beta MSVC 1.28\\bin\\ error: rustup cannot be installed alongside Rust. Please uninstall first error: if this is what you want, restart the installation with \`-y' error: cannot install while Rust is installed I installed rust separately via .msi a day before. 
Does it work now that you've uninstalled Rust?
Huh. I think that Servo should definitely be integrated as the main renderer into many browsers, because Gecko is getting old and slow...
&gt;The thing is, I'm pretty sure it's possible to rewrite this in safe Rust without performance penalty. We're not using set_len for this in miniz_oxide, and it was already slightly faster than c miniz on most platforms last time we tested, so yes, it should be possible. The unsafes at the moment in the inflate part of the library are some [unaligned reads](https://github.com/Frommi/miniz_oxide/blob/master/miniz_oxide/src/inflate/core.rs#L347), which are pretty clearly checked, and [initializing](https://github.com/Frommi/miniz_oxide/blob/master/miniz_oxide/src/inflate/core.rs#L1096) the decompression struct without zeroing everything in decompress_to_vec. Might be a good idea to see if we could avoid the latter one now with improvements in rustc.
I'd rather add pressure to read more documentation for adding unsafe code instead of adding pressure to _everybody_ to read more documentation for understanding the default template :)
It can be difficult to absorb everything. But.. at least the knowledge about how the computer works won't be limited to benefiting your Rust code. The knowledge will also boost your Python programming as well :)
unsafe code is already "opt-in" though the `unsafe` keyword. Why would someone be willing to use that keyword, but not also willing to remove `#![forbid(unsafe_code)]`?
The proposed changes to lifetime annotation make me rather uncomfortable. They seem to be following the recent trend in Rust of introducing implicitness and "magic" in return for less typing. That's not inherently a bad thing - features like plain old lifetime elision remove unnecessary visual noise and make code more readable. However, I worry that the recent changes don't have much benefit and are far too numerous. They all seem perfectly understandable and reasonable in isolation, but every bit of magic increases the cognitive effort of reading code. As the amount of magic increases and codebases get older and larger, code can become significantly harder to understand.
Thanks for the feedback! \- I'll add a countdown option, but I'm not sure how it should indicate to the user that recording has started. Does BEL even emit a sound anymore? \- It's probably best to wait for Rust-AV (or some other AV framework) to mature a bit before adding other types of codecs (or maybe I could just use FFmpeg, but that'd be too easy and boring).
Simple MMORPG server. Just for fun. At the moment I realized only the basic synchronization with the client. The client is the browser. But in the future I want to be able to use not only the websocket, but also my own protocols over tcp / udp. I use tungstenite as websocket implementation. Are there a zero-cost library for working with the websocket? Maybe I'll have to write my own implementation later.
First off, thank you so much for the tremendous effort! I'm so happy to see this post and if we ever meet in person ^(*hint* come to RustFest) I owe you at least one beverage of your choice! &gt; I wish there was some kind of target reuse between fuzzers, though. [You are not alone! :)](https://github.com/rust-fuzz/rfcs/pull/1) I'd be awesome to also move parts of the rust-fuzz/targets CLI to the cargo-fuzz tool.
&gt; it explains the state of the relation between arduino and rust well Does it though? I mean, this thread is two years old, surely things have evolved since then?
Disabling unsafe by default and requiring a module local opt-in would be something I would have definitely wanted to see in the 2018 edition, but I'm afraid it's too late for that. Next edition perhaps? And possibly even a crate global controlled cfg item for enabling unsafe (so that the use of 'unsafe' can be scoped to specific features) would probably also make sense.
I understand the sentiment. And personally, I can only wish I had better offers: that's a very enticing amount of money and an interesting set of technologies to work with. I guess it all boils down to what our definition of "legitimate" is.
I'd say just in the terminal do a 3, 2, 1 style countdown with an /r to clear the line etc... You probably wouldn't need a bell as users would know when it starts. Yeah ffmpeg I think has some bindings but that'd mean less pure rust and more library deps
This looks great; thanks for sharing! I've abstracted the storage in my [mesh crate](https://github.com/olson-sean-k/plexus) and have been considering moving from hash maps to slot maps. This may be just what I needed. Looking forward to experimenting with this.
Hey , Im new to this game and i wanted to know where is the most common place to find any kind of high walls preferably not wooden ?? I have a research table so even if i find one can I research it? 
Awesome, I'll keep it in mind!
Probably they have, yes. But for someone who knows nothing, it's a good start. Nevertheless, my impression is that the conclusion is same, there are works to be able to run rust on avr. Besides, arm is better supported than avr. But I'd be happy to hear that there are news that falsify these.
Awesome! I love handlebars. Thank you for all your work!
Have you read https://terrytao.wordpress.com/career-advice/theres-more-to-mathematics-than-rigour-and-proofs/ before? I've found it very interesting when thinking about Rust. I see these kinds of features as being for the pre and post rigorous, at the cost of the middle stage.
&gt; I installed rust separately via .msi a day before. You have to uninstall before you can install rustup.
You better point your research at https://www.reddit.com/r/playrust/ :)
I've heard people saying it works nicely using python + qt-bindings. Ping u/ssokolow.
You could save 2 lines this way: if t.len()? == 2 { let mut table_it = t.sequence_values(); let x = table_it.next()?; let y = table_it.next()?; return Ok(Self { x: x?, y: y? }); } For advanced shennigans, maybe you could implement [`FromIterator`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.collect) for `Self` in a meaningful way? You could also zip `table_it` with `table_it.rev()` and then just get out the first element. Would maybe save 2 more lines, but I wouldn't bother.
Are you referring to this downside specifically? (I honestly haven't been tracking the module changes in detail.) &gt; On the other hand, relative to the current 2018 design, you can’t always tell whether a given use statement is importing from an external crate or a local item (which, notably, is also the case in Rust 2015). This doesn't seem that bad to me, particularly considering that the common convention (that I've seen others use and I certainly use myself) is to separate `use` into blocks, roughly conforming to: `std` imports, third party imports and then finally crate-local imports.
Things are frequently adjusted outside of RFCs. The RFCs act more as a collection of comments. You'll have to follow the tracking issues to see the final decisions.
&gt; Rust has no mechanism for propagating security updates through the ecosystem. I was surprised to find that Cargo does not alert you when you're using an outdated library version with a security vulnerability, and crates.io does neither rejects uploads of new crates depending that depend on vulnerable library versions nor alerts maintainers of existing crates that their dependencies are vulnerable. A third-party tool to check for security vulnerabilities exists, but you've never heard of it and you have better things to do than run that on all of your crates every day anyway. This is an interesting idea to me. Is this done anywhere? Maybe we should consider it.
For me, it's simply that I always want a `&lt;...&gt;` to declare lifetime and type parameters so I can see at first glance without reading anything else if the thing is somehow parametric. So, this to me is again making things more unergonomic. Luckily for everyone who is not me I've run out of energy to constantly counter argue. I would argue for a lint to restore ergonomics for those that choose. But I doubt that would be accepted, and I'd probably be again accused of trying to fracture the community.
Now that I think of it, I could just `unwrap()` the `next()`s' `Option`s. I used the `if let` to handle a `None` inside the `else` of the first `if`, but this is actually impossible since I check for the table's length... Thanks for pointing this out! Implementing `FromIterator` seems a good idea if I ever need to do this again, I'll keep that in mind.
Overflowing signed integers in C causes undefined behavior. What happens in Rust?
The fun thing for me is that with the "every dependency is automatically added to prelude" strategy I'm in the situation where: * Code that isn't mine (external crates) can just show up in code without any kind of import or definition anywhere besides `Cargo.toml`. * My own code (modules), of which I have usually more, has `crate` prefixed imports. This feels like the complete opposite of what should be true. Now additionally my submodule imports will *look like* I'm importing from an external dependency, but I'm actually importing from a *child* of the current namespace.
[https://stackoverflow.com/questions/51141672/how-do-i-ignore-an-error-returned-from-a-rust-function-and-proceed-regardless/51142002#51142002](https://stackoverflow.com/questions/51141672/how-do-i-ignore-an-error-returned-from-a-rust-function-and-proceed-regardless/51142002#51142002)
I personally think that distributed cloud storage (aka cloud, but blockchain!) is a pretty good idea. There are companies providing this, and once the dust has settled a bit I'm gonna look into them again with the intention of using them day to day as an alternative to nextcloud.
Arithmetic overflow is guaranteed to wrap modulo 2^n in Rust.
&gt; Is it mandatory to use ? when return type Result&lt;T, E&gt; ..if i don't care returned error It is not, however it's a good convenient shortcut to "bubble up" the error if you don't want to handle it right there. If you're writing a quick and dirty script and you actively don't want to handle the error, you can `.unwrap()` it, this will panic (kill the process) if the call failed. The more time passes the less useful I find this, especially with [Result-returning main functions](https://github.com/rust-lang/rfcs/blob/master/text/1937-ques-in-main.md) and [the failure crate](https://boats.gitlab.io/failure/) which provide for simple bubbling up of errors without having to just hide them. If you "drop" the return value without even assigning it you'll get a warning because `Result` is flagged as `must_use` (the assumption is that you really should handle it properly but it's not a requirement).
IOHK is pretty cool. They also work with Well-Typed, which is a Haskell consultancy: http://www.well-typed.com/blog/2018/05/semi-formal-development/
Do we know whether this is being seriously considered by the llvm team? Had there been any public discussion?
Lack of a REPL is just a sad thing in general. I would so love to be able to interact with the filesystem and web servers with Rust. It would also just be so great for trying things out when developing to see if they would work. Fastest way to consume a library I just made to try something is with an example usually, which actually isn't so bad, now that I think about it.
It also panics in debug mode. Make sure to use Wrapping or wrapping_add/sub/etc. The release mode semantics are wrapping.
The new \`cargo-clippy\` proxy wasn't installed in the 1.13.0 package, but I've asked the maintainer to add it.
Here's a list ftom the index :) https://github.com/rust-lang/crates.io-index/tree/master/ca/rg
Isnt't python also getting that now, pretty much?
It would be a good idea to start your announcement with 2-3 sentences describing what handlebars-rust actually *is*.
Yes.
You are probably looking for /r/playrust .
Agreed. I see plenty of announcements of this crate and that crate posted here with an assumption that we all know what they are. We need to follow the link to learn whether or not it is something we care about or not. An introductory tl;dr would be nice.
Amazon's internal build tooling spits out warnings about old/unsafe libraries in your build. It's neat. Everyone ignores it and just carries on. 
It's got syntax support but to actually check types you have to install one of a number of static type checkers and configure your editor and CI to use it. For this reason, you can expected even seasoned python developers to say "what does this -&gt; Iterable[int] stuff do?" and consequently mess it up. It is considered a nice tool for specialists.
A little exploration of a teachable moment I had while working on a new Rust project yesterday.
You can disable panics in debug mode, although it is enabled by default. There are many ways to describe the situation. My preferred description is that Rust wraps, and additionally has "overflow-checks" code generation option, which is enabled by default in debug build.
Using the unsafe keyword feels like making a single hackish decision that we should fix later, but I'm pretty sure **I**'m right that this particular line is safe enough. Removing #![forbid(unsafe_code)] feels like making a policy change to make the codebase less safe. 
I saw that last week as well, and I might just have to play with it. I like the idea of having a TODO list, and a few days ago (actix-web related discussion) there was good discussion about including metadata in crates.io for estimating how unsafe a package was. There's definitely interest, but I just don't think I'm the right person to do it (maybe I will though, who knows).
Wasmi is great but I wouldn't suggest it as a foundation for a plugin architecture. It's orders of magnitude slower than native code. All the downsides of statically typed systems languages with few of the upsides. Source: I'm one of the maintainers.
&gt;interact with the filesystem and web servers with Rust Simple things like that are a lot more natural in a Bash shell (+ coreutils) or maybe Python. Rust can do it but there's a lot of extra work involved that makes it a bit over-the-top for the kinds of simple thing you'd be doing in a REPL.
&gt; rustc: stabilize the proc_macro feature YEEEESSSSS
I thought something as major as how paths should work would be total RFC territory?
Regarding checking for security vulnerabilities in dependencies every day, you might want to add Dependabot to your GitHub repo. https://dependabot.com
Yeah, but this seems like a little more than something that gets ironed out in a tracking issue? Maybe not. But the progression of module RFCs was from "let's overhaul the whole thing" to "okay, let's make some small backwards-compatible changes to make things better". Now we have this post, which starts off by saying the last RFC "didn't go far enough". So that kind of sounds like sneaking in more extensive changes than the community-at-large discussed. 
Unfortunately... &gt; Note though that despite the stabilization in this commit procedural macros are &gt; still not usable on stable Rust. To stabilize that we'll need to stabilize at &gt; least part of the `use_extern_macros` feature. Currently you can define a &gt; procedural macro attribute but you can't import it to call it! ...though, on the plus side... &gt; It's intended that this PR, once landed, will be followed up with an attempt to &gt; stabilize a small slice of `use_extern_macros` just for procedural macros to &gt; make this feature 100% usable on stable.
Lots of crates make many things even easier in Rust imo (like ergo). For some things I find it faster and shorter in Rust. Also, I'm not as familiar with Bash as I should be =X. To be honest tho, the main reason is Serde to serialize and deserialize files. Python would also be okay, but I'd much rather be working with native data types from a library in a typed language. It wouldn't work as well tho unless I had RLS running on my REPL.
Do the overflow checks also flow into your upstream dependencies when you build and run? In that case the author may have not intended for the checks to go away in debug mode. I agree that wrapping is not necessarily erroneous behavior if we agree to it beforehand, but some confusion could definitely arise when combining things together that may or may not have expected wrapping or if a code reviewer is specifically seeing a wrap happening without anything in the surrounding context to indicate why.
I am not involved in LLVM development at all, so I have no clue. Sorry.
Well, Linux package managers are doing it since forever. It's such a natural and obvious thing to do for me at this point, I was shocked to find out that it is *not* being done.
Yeah that's why I meant getting it, since they have been building out the syntax to support it I would kind of have taken it as a given that the build chain will support it at some time as well.
After thinking about it more, maybe you should just bundle up your code as a crate and they can customize it downstream by registering their own implementors of traits a'la zope components. I think there was a compile time hashmap where the keys were types somewhere but I can't seem to find it.
Personally I'd agree, but I don't have any influence there :) I'd love it if RFCs were "decision making documentation" so to speak. I still find it odd that `Ok` wrapping for `try` was discussed in the `?` RFC. Maybe the new proposed RFC format will make things more visibile, though I'm unsure.
That might be nice. Though I assume it would throw off the whole 2018 edition timeline in this case.
The Content-o-Tron mascot is totally seeyick!
Yeah, non-zeroing initialization is what nearly sunk `inflate`, so please see if you can get rid of it. I've actually fuzzed `miniz_oxide` and contributed fuzzing seeds to it, but I've never fuzzed it in a setup that could detect memory disclosure bugs such as this one.
Well, it is kind of a blog post already? On new Reddit it basically looks like a blog post with comments underneath. If you have a specific platform in mind where I could copypaste it to, let me know. But since there is already a lot of comments in here, I'm not sure it's a good idea.
The issue is that vulnerabilities tend to be limited in scope, and frequently live in some part of a library you never use. Thus going through these lists tends to be a somewhat painful trudge of 99% false positives, making it very easy to just give up and go back to working on whatever management is actually pushing you to do. It would be really nice if a tool took a more nuanced approach, and made an attempt to filter by specific usage when possible, to just reduce the massive false positive rate that happens at library granularity.
The rules are: * overflow is a “program error”, not UB * you must either check for overflow and panic, or two’s compliment wrap * when debug_assertions are on, implementations are required to panic on overflow This means release mode wraps today, but if it’s cheap enough someday, we could make it panic. If you want specific semantics on overflow, then you should use the various wrappers and/or methods that let you do them directly, rather than relying on any of the above.
Not sure how this would be done without huge overhead in the assembly. Rust was made for making optimized low-level libraries and applications. I'm not sure that having every library ping the internet to check for updates, and self-updating would be secure or efficient for the rest of the runtime execution.
That's weird, it should not change the code at all, the only difference should be to the compiler. Let us know what you find out.
I'd like to add a commit that I think is a big deal. - (`cargo: Make index lookup robust to _ vs -, but don't let the user get it wrong`)[https://github.com/rust-lang/cargo/pull/5691] This PR means that if you add `serde-derive = *` to your Cargo.toml then the error message will tell you that you meant `serde_derive`! It still requires you to make your Cargo.toml correct before you build for backwards compatibility reasons.
Not every library at runtime, but cargo at build time. Cargo can just download a manifest of vulnerable crates from crates.io every once in a while and cross-check dependency versions with it on every build. Oh! Cargo also supports installing binaries, so it should check the installed binaries for vulnerable dependencies after downloading the manifest. That's basically it.
&gt; Has anyone worked on a Rustlang port of `libmvec` that you know of? Not that I know of. I just thought that now that SIMD intrinsics are becoming part of Rust nightly things might stop to compile if `libmvec` is also missing.
The `paste` crate looks pretty darn cool, to be honest. I might host my own sometime.
I get it, I do. It's really hard to keep persuading management that security is a feature. That's the drum you have to keep on beating, though. The tool in Amazon makes it relatively easy to do the upgrades. It spits out the minimum version to upgrade to, you modify the build file and away you go. You might have a version conflict or two, but fixing those is often relatively straightforward. What gets to be a pain in the arse is if you ignore it for months on end and then you're trying to deal with multiple packages, a boat load of version conflicts and it ends up being a complete dumpster fire that you lose days to. Or in the worst case I saw, you've been ignoring the security warnings for multiple years, the version of framework you were using is so far out of date that what would have been trivial incremental fixes if you'd kept up with the upgrades, ends up being a complete clusterfuck that basically requires you to re-write your application from scratch.
&gt; But I doubt that would be accepted, and I'd probably be again accused of trying to fracture the community. I don't think so. There are many clippy lints that support widely different coding styles, and that you can enable for your crate if you want your code to look a certain way. I am pretty sure that if you send a PR with an off-by-default lint that detects implicit lifetimes and warns about making them explicit nobody would argue much against that. You can then turn the lint on for your crate to enable the `warning`s, and `deny` it to turn those into errors.
Is your project a library or executable? If it is a library, it could be onerous to require all your users to be on nightly. If it is an executable, I don't think it matters much personally. As for nightly breakages, in my experience things usually don't break unless they're being changed before stabilization, in which case the pain is short-lived.
If it was an unresolved question of the RFC, what happens is that one or multiple alternatives get implemented and experimented on nightly after the RFC is merged. Then, during FCP, the unresolved questions are "resolved", as in, the alternative chosen has to be justified, and people can still raise new arguments about it, which might end up in things being changed.
I actually have an [open issue](https://github.com/rust-lang-nursery/rust-clippy/issues/2850) on clippy about match ergonomics, but that seems like a hard sell, and hasn't seen activity in a month. The reception to the idea on IRC wasn't much better. I'd be happy to work on PRs, I'm just not as sure that they would be accepted and wouldn't be a waste. If there were a general sentiment with the clippy project that those lints are OK to be in, since they are opt-in, I'd have a list of things I'd love to be able to restrict. I even looked into making my own lints/clippy like tool just for these kinds of restrictions, but it's a lot of work, and I'd be bound to nightly for probably a very long time.
I also have never hear of someone getting full insurance bennies covered. That's great for you, but many many people pay each month for this.
Thanks for feedback! Some things just don't fit inside any existing categorization. Froggy is neither a ECS, or a low-level allocation library. And it's not the status quo, as you noted. I don't buy this to be a good reason to discard it, but honestly don't care too much either. It serves the needs of three-rs, and there is no decent alternative. Maybe if/when you add reference counting, we can consider a comparison.
Oh! Neat trick :)
Could you please link to the code which produces this error? I can certainly use `Key&lt;T&gt;` and `Node` in isolation =&gt; see https://play.rust-lang.org/?gist=7415b31495fcdcfdbc6ca96ab0c67224&amp;version=stable&amp;mode=debug&amp;edition=2015 so I am curious as to where you encounter this issue.
I like the changes to the notation of lifetimes in the preview. If I declare struct Foo&lt;‘a, T&gt; { bar: &amp;’a T } I think it’s pretty clear that the `T` has to be valid for `’a`. Even better, struct Foo&lt;‘a, ‘b, T&gt; { bar: &amp;’a &amp;’b T } It’s pretty clear that `T` has to outlive `’b`, which has to outlive `’a`.
The primary difference is simply that `SPC-foo.bar` can be declared _within_ the text of `SPC-foo`: ``` # SPC-foo This is foo. It is implemented by a few methods: - [[.bar]]: doing bar is necessary for foo - [[.baz]]: after bar we have to do baz because of putz. ## Unit Tests - [[.tst-bar]]: we test bar because foobar. - [[.tst-baz]]: baz should be tested too foo. ``` You can then link those subarts in your source code, giving your source code more transparency of _why_ you are implementing a function some way. The alternative (like you said) is to have `SPC-foo-bar` and `SPC-foo-baz` as well as `TST-foo-bar` and `TST-foo-baz`. This makes sense to do when `SPC-foo` is an "architecture" specification and bar and baz are rather large in their own right -- but I have found that having one-liner specifications is _really_ annoying -- it pollutes your specifications and your graph and makes your design documents really difficult to read. It is much better to define all "simple" things within a single markdown blob. For comparison, here would be that: ``` # SPC-foo This is foo. It is implemented by a few methods: - [[SPC-foo-bar]]: doing bar is necessary for foo - [[SPC-foo-baz]]: after bar we have to do baz because of putz. ## Unit Tests - [[TST-foo-bar]]: we test bar because foobar. - [[TST-foo-baz]]: baz should be tested too foo. # SPC-foo-bar doing bar is necessary for foo # SPC-foo-baz after bar we have to do baz because of putz. # TST-foo-bar we test bar because foobar. # TST-foo-baz baz should be tested too foo. ``` 
https://github.com/as-f/slotmap/blob/master/src/normal.rs#L231
I see, I had actually wondered whether defining a `.subart` meant I still needed to create another file to flesh out the details, but you answered that question. Thanks for clarifying!
If the value can never be 0, I'd stick a `debug_assert!(dist &gt; 0);` at the top of the function to both (1) document that it's an unexpected value and (2) ensure that if it ever happens during the tests, at least it's caught. Since it's compiled out in Release, it's free!
I would find interesting to get the alert; I'd certainly not want `cargo` to automatically upgrade without my consent. There are very good reasons for using old libraries, even if vulnerable: they've been vetted by your own tests and users far better than any other versions :)
Is there any need for people willing to edit/proofread blog posts for non-native English speakers? I would be willing to volunteer on that front.
In my opinion artifact was practically unusable without subarts and subtests. Clearly I am a harsh critic of my own work, but it was seriously painful. With subarts however it I have found it to be extremely usable. Along with the inline graphviz graphs where you can specify subarts directly it actually helps me do design :)
Though you asked about non-web solution, I can recommend you take a look at ECharts library, which is based on Canvas technology instead of SVG, which is used in Highcharts. In my experience, Canvas can significantly outperform SVG-based solutions.
Whoa, you almost solve all my problems! Thanks. I need to unpack the code but yes, encode using arrays make much more sense and in fact will align with the goals of my little lang better (and hopefully bring good performance because the locality)
Thanks for the rec. [Highcharts does actually have a canvas backend available](https://www.highcharts.com/blog/news/175-highcharts-performance-boost/). The issue is not so much in the rendering, but more in memory restrictions. Holding all of these numbers without manual memory management is a struggle. As a very basic example, you need to provide these libraries with Numbers, which are at least 8 bytes in V8 (though I believe they may be more). Reasonably, we could just use floats for our needs. So that close-to-halves the amount of memory we need on the Y axis, and we can probably make similar improvements on the X axis. Plus, rendering blocks the main/only thread in JS, whereas this can be split up more easily in a language like Rust. We're going to try to make JS work if it's actually as inconvenient to use a native platform like Rust or C++ as it seems to be, but we're also trying to keep our options open. =)
The feedback mechanisms could be better maybe? The Discord link has expired, the forum thread has zero posts in it so I don't know if anyone is paying attention to it, and the Github thread feels like it should be more for design issue than technical problems and asking for help. That said, tried porting `ggez` to 2018 edition and it works well, for being in beta. I like the new module system a lot; it's a little wordy but it also makes it 100% clear and unambiguous what the heck is going on. Being able to omit `extern crate` is nice... except if you use a crate with `#[macro_use]` apparently you still need to do `#[macro_use] extern crate serde;` apparently? And I managed to make the compiler panic by removing `extern crate winit;`, but that's why it needs testing.
I'm not aware of any good graphing crates, unfortunately. However, if you want to roll your own, the `lyon` and `rusttype` crates have all the rendering pieces one would need. Or you could just use QT from Rust, which I'm told is possible, albeit somewhat painful.
But…in this case, it's easy! It's clearly a Rust implementation of Handlebars! :-) :-)
Yes, that's why you need the 2nd and 3rd sentences. Best guess from the name: some kind of GUI widget?
The Discord link isn't expired. You just don't happen to be on the server. https://discord.gg/rust-lang
That's just one of the lifetime annotation changes. The other two mean that you can introduce named lifetimes in function arguments and `impl` blocks without declaring them, meaning that to answer the question "what does this lifetime refer to?" you can't simply look for `&lt;...&gt;` blocks, as before, but you have to just read the code backwards hoping you didn't miss the first use. This... somehow... makes the system easier to learn. 
`debug_assert()` is not sufficient, you need it to never happen in release builds. The probability of triggering it on valid inputs in debug mode is basically zero. I've added an `if` check in that particular function instead. Fun fact: the asserts I've added to that function after the if have actually improved performance instead of regressing it, probably by providing hints to LLVM optimizer.
I prefer the way you describe it because it makes it clear that we intend to treat overflow as an error unless it is specifically asked for in context. That way we won't have to worry about the wrapping concerns of various codebases.
I typically have been using unwrap() directly, rather than wrapping it conditionally. The only cases i do wrap it is when i know it might not exist, and that's okay. So when I'm fetching data out of a component storage, i know it may not exist yet by that entity. Where as things I create at the start and are never destroyed should exist, so i accept the failure possibility. Stack traces have gotten good at helping me find when I have a crash, which unwrap() caused it. That said, I do agree it's a good practice to be defensive and fail gracefully, which my game does not right now.
Thanks, but I understand the message. 
the new reddit link just redirects to this site again...
By the way, have you ever tried to apply https://github.com/CENSUS/choronzon to Rust code? It seems to be binary-only so it's not tied any particular language. It already codes with a PNG example, so that's going to be the easiest thing to try, but afl already covers that pretty well. It's probably going to work a lot better than afl and its derivatives for formats such as XML, it's specifically mentioned as an example in the slide deck.
rather than an interpreter like wasmi, I think building on top of code generators like [cranelift](https://github.com/CraneStation/cranelift) would be better...
Bicycles don't need a GUI.
Then you're probably already on the new reddit.
Note: this new variant is intended to be available **under a separate feature flag** on Preview 2 -- it's just an opportunity to try it out. No decision has been made about which variant will ship in Rust 2018.
That's great! What are you working on ?
&gt;debug\_assert() &gt; &gt; is not sufficient, you need it to never happen in release builds. As eddyb said, it is already impossible to trigger. Adding the asset \*as an optimization\* is fun though.
Aha, thank you!
Seems to work, but as a technicality, single quotes are not allowed in JSON. You need to use double quotes. What are you using for the JSON input and output? I would imagine that serialization libraries like serde would get this right by default. 
I'm working on grid based automatas that have cellular logic implemented as genetic algorithms with mating and crossover to induce evolution in the simulation. In one such simulation, I also used a reaction-diffusion equation as part of the simulation to make an interesting environment, but that ended up mostly just wasting processing time. The most recent one is evomata12 in the evomata group on GitHub. I am currently working on allowing simulations to run on multiple nodes that talk over arbitrary Read/Write implementors in rust by serializing the cells and data that moves between cells using serde and bincode so the edges of the grids can update each other on each node. You can check out that work on the abstractions also in the evomata group under gridsim. On a phone atm so hard to link to things.
Clever sampling is how most good charting setups work. At a given zoom level you only need so many points in the view, so you can subsample or use k-centroids etc. to display a fixed number of points at any given zoom level, and then smoothly resample as the axes are moved.
Nicely written article, but I have mixed feelings about the conclusion. The problem with defensive programming in general is that there's no bright line about when to stop. As OP says, it would probably be better to open the directory to avoid the race condition. Should you worry about bad implementations of `path_is_symlink()`? Maybe you should check that somehow. At some point you start worrying about "what if there's a memory error" and unless you're writing space shuttle code you just have to give up and accept that sometimes your code should just stop because it doesn't know what's going on. Note that in this example, the `read_link()` failure isn't being handled anyway: it's just punted up to the caller with `Option`. Caller is still going to have to decide what to do with the busted `Entry::Symlink` it gets back, and it has less information available than this code did because the error return from `read_link()` has been thrown away. Honestly, the way I would have written this example is probably more like this: if direntry.path_is_symlink() { let symlink = Entry::Symlink { path: direntry.path().to_owned(), target: read_link(direntry.path())?, }; return Ok(symlink); } If I didn't want to have an error return from this code, I'd just keep the original example and `unwrap()`. Better error message and simpler code.
For the second part, are you thinking about something like using templates? If so, Tera, Askama, and Handlebars seem to be popular rust crates.
Ooops I think I just crashed it. You need to handle the instance where someone POSTs invalid JSON.
Thanks. That's was the unwrap on serde\_json::from\_str I am matching the result and it should return the error now
that would be great. Iwill check them out. thank you.
Thanks for the info!
&gt; Rust safe code is still not 100% trustworthy because the compiler is not verified. ...and there are [several known cases](https://github.com/rust-lang/rust/labels/I-unsound%20%F0%9F%92%A5) where Rust does in fact generate broken code.
I am using serde already. Probably only in a very simple form but still. This is the request and response routine basically. Flex is a struct that has three Strings. .. let mut split: Vec&lt;&amp;str&gt; = request.split("\\r\\n").collect(); split = split\[7\].split("\\u{0}").collect(); // body begins at 7 println!("{:?}", &amp;split\[0\]); let response = match serde\_json::from\_str(&amp;split\[0\]) { Ok(mut flex) =&gt; { flex = post(flex); format!("HTTP/1.1 200 OK\\r\\n\\r\\n{}", flex) }, Err(e) =&gt; { format!("HTTP/1.1 200 OK\\r\\n\\r\\n{}", e) } }; format!("HTTP/1.1 200 OK\\r\\n\\r\\n{}", response) .. 
Is trait specialization going to be part of Rust 2018? I haven't seen any mentions of it recently, so my assumption was no.
Project on GitHub: [https://github.com/kuviman/glitchcat](https://github.com/kuviman/glitchcat)
Yeah, but I meant for output. Apparently `post()` is generating the JSON-with-single-quotes. 
aah. ok. i fixed that. It was the Display formatter for the Flex struct. But now it's returning HTTTP OK before the answer.
I was working on a twilio API wrapper (using async hyper) a few weeks ago, I released a beta version to cargo. It could use some more testing (the conversations api is untested). The main stuff is there though, sending messages and calls and generating twiml. It was a great exercise in trying to make an ergonomic API. If anyone has any suggestions, check it out: [https://github.com/leshow/twilio](https://github.com/leshow/twilio)
Nodes \`npm\` does this when installing packages, and has a built-in utility \`npm audit\` which generates a report of vulnerable packages. 
Haha, nice name
No, I think perhaps some of us are in regions where the new reddit is not yet enabled.
So actually if you write this into a markdown guide for safety audits this probably could be placed somewhere on rust-unofficial or the rust forge or the rust fuzzing book.
yesterday i figured out already that I should have used two columns for the mapping instead of two rows. It's more flexible like: {input}{output_option_1}{output_option_2}{output_option_3} instead of [input] [output] Now, I see that I was right being wrong in my cyrconv project. :)
A idea lifted in how currently I solve something that I need long-term (for a erp) is just use a webview for rendering only (with react or vue (what I use)). Then do ALL the calculations with native code. Send only the results to the webview and let it render. Now I'm exploring in building a little [relational/array/columnar library](https://www.reddit.com/r/rust/comments/8zr3d7/interpreter_possible_to_encode_tag_vec_and_not/) (just prototyping) so you could store the data in columnar format, do agregations and stuff. This must be fast. Or just let sqlite handle it for you, and pass the data across. ie: Have a invisible, low-level computing engine and use anything else for the UI. P.D: Delphi have [now a free community edition](https://www.embarcadero.com/products/delphi/starter/free-download) I never use a better tool for UI program, and left it behind because costs reason. But here are very good UI components.
on what measure is the US the richest country in the world?
Typically, even if it is a hard sell, if you put the work in a PR and it is off by default, chances are that if the PR is nice (tested), and the lint has an application, it will be merged, even if it isn't something that most people should enable.
Well... getting things ready for the Rust 2018 release is pretty much an impl period :/
I'll give it a try, thanks.
Why not both? ;)
&gt; is is an interesting idea to me. Is this done anywhere? Maybe we should consider it. https://internals.rust-lang.org/t/idea-security-advisories-as-part-of-crates-io-metadata/3899/38 https://internals.rust-lang.org/t/pre-rfc-security-advisories-as-part-of-crates-io-metadata/4045 https://github.com/RustSec/advisory-db https://github.com/RustSec/cargo-audit 
The rust fuzz book and rustonomicon already cover fuzzing and not messing up unsafe code. I do not feel I have much to add on the process for safety audits. What I very much would like to see is a guide on getting rustc to optimize your safe code so you wouldn't have to write `unsafe` in the first place. For example, [the post on improving smallvec performance](http://troubles.md/posts/improving-smallvec/) constantly talks about what compiler can or cannot optimize, and even after reading it I have no clue how to apply any of the techniques discussed therein to my own code. Also, I'd need tools to find out *why* certain safe code did not get optimized and how to fix that. LLVM has `-Rpass-missed` and `-Rpass-analysis` flags, but there is no documentation for them in conjunction with Rust. Plus there are lots of different optimization passes and I have no clue which ones I'm interested in for a particular piece of code. Just to get the ball rolling: both `inflate` and `miniz_oxide` crates currently have to explicitly use uninitialized memory for performance. We could start by eliminating the need for uninitialized memory use in those crates and make the first chapter of the "make safe go fast" book out of that, just to get a feel for how useful and/or doable this is. Sadly, I cannot assist in actually writing it because I have no clue how to do any of this. But I could try to actually use it and provide feedback.
You shouldn’t need to use it with macro_use, as you can use use instead.
I suspect \_starting\_ to write it and leaving gaps for others to fill might be a good start. At least, we should put your post above in a more permanent spot :)
Actually, I treat every character on a line as both input as output. And thanks for your cyrconv project =) I would not have created this if I didn't see it
Kind of a shame that the `Fn*` traits aren't stabilized, then the results of `compose` wouldn't need to be boxed.
&gt; I suspect _starting_ to write it and leaving gaps for others to fill might be a good start. Sadly, I know absolutely nothing on the topic, other than that those two LLVM flags exist. I'm afraid I won't be able to do that. &gt; At least, we should put your post above in a more permanent spot :) Makes sense. How do I go about it?
&gt; For continuous integration we'll be using GitLab CI. GitLab CI is GitLab's continuous integration and continuous deployment platform. You don't have to use GitLab's source repositories or other functionality to take advantage of GitLab CI! Do you have more info on this? I've been trying to find a way to use GitLab CI with a GitHub repo just out of curiosity, but I haven't succeeded.
How advanced you want your plots to be? Will simple lines with XY axes suffice? If yes, then you could try to use graphics API directly, e.g. via glium, gfx-rs or vulkano. They should handle 30k points/s pretty easily. For example I have a point cloud viewer which works with ~400k points/s.
Perhaps just stick it up on medium.com or dev.to? Those are easier if you don't want to set up a blog
I doubt I could improve on GitLab's documentation much: [https://about.gitlab.com/features/github/](https://about.gitlab.com/features/github/) This is what I'd used to implement this workflow before. Does it help?
this is dumb I love it.
Yes I have implemented a sparse version myself for the same reason - It's a question of whether the lookup performance or the iterate performance is more important for a particular usage scenario. It seems we are in agreement that both are valuable. Glad to hear the talk was helpful :) 
Somehow I missed that and thought their GitHub integration was only for EE customers. Interesting!
Since code is read many more times than written anything that hinders readability has to be carefully considered. Especially, since the actual coding part of tackling a difficult problem is usually shorter than thinking about it. How should an absolute beginner learn Rust? They don't have the basics and rigour down, which the paper talks about(written by a literal genius), to just forgo annotations that make the code more explicit. Let's be realistic and admit that most people using programming languages are not geniuses, nor people involved developing said languages. Your experience of working with the language is different from someone who uses it as a tool or someone who is just learning it. Similarly, imagine that you are a c++ coder some years from now, hypothetically the languages are comparable in available functionality, but since 2018 Rust has picked up some quirks that creeped up over the years. You could learn Rust for some added safety but you would have to learn the quirks of another language all over again(and how retarded some of those cpp cases were), why bother? 
How about using it together with `lolcat`? echo "I am a genius\!" | glitchcat | lolcat Example: [Imgur](https://i.imgur.com/yU8e3II.gifv)
Damn! How did I miss that?
Added to changelog.
I don't think so? There was a lot of design which had to happen first and allowed the Rust 2017 impl period to happen. I don't think there's another one planned this year, though there might be next year.
Yeah, the key snippet for anyone else reading this thread is: \&gt;If you have a public, open source project on GitHub you can now take advantage of free CI/CD on GitLab.com. As part of our commitment to open source, we offer all public projects our highest tier features (Gold) for free. While other CI/CD vendors limit you to running a handful of concurrent jobs, [GitLab.com](http://gitlab.com/) gives open source projects hundreds of concurrent jobs with 50,000 free CI pipeline minutes. Works pretty well as a TravisCI alternative. Main disadvantage with GitLab CI over TravisCI is that generating Docker images requires running your own GitLab CI instance. OTOH, I can hook up dedis to the public instance or my own with GitLab CI, which solves a lot of build time problems in my clients. I can't do that with TravisCI nor is it free software.
Are you thinking of a webapp or a desktop app?
In 90% cases when you want borrow checker to shut up, you are doing something wrong. Can you share more details about your problem? As for "get a mut pointer", I'll just cite the [Nomicon](https://doc.rust-lang.org/nomicon/transmutes.html): &gt;Transmuting an &amp; to &amp;mut is UB &gt; - Transmuting an &amp; to &amp;mut is *always* UB &gt; - No you can't do it &gt; - No you're not special 
If you don't know how to do it then you probably don't know enough to tell whether it's okay to do it. What are you doing, anyway? Are you sure force is needed?
Yeah I saw that, but... is it really? How could it be undefined (i.e. surely it's trivial to define)? Anyway, for the details: I have a list of values that I have a lock on. I want to do an n\^2 brute force search to find pairs that 'collide', by some definition. Then, for each item, I need to perform operations on it for each 'pair' found. Rough example: for i0 in &amp;mut items { for i1 in &amp;items { if i0 != i1 &amp;&amp; i0 matches i1 { // Mutate i1 } } } I can't form a list of 'mutations' and make them after the fact, because the order I loop through `items` isn't stable (i.e. it may change between loops) 
See other comment reply!
It depends how beginners are expected to code Rust. Because the Rust compiler checks so much, a beginner can simply try writing what they mean, and then see what the compiler says about it. If the compiler wants more lifetime annotations, then add them.
I would recommend sticking to safe code using `split_at_mut`. fn should_mutate(i0: &amp;i32, i1: &amp;i32) -&gt; bool { i0 + 1 == *i1 } fn main() { let mut items = vec![1, 2, 3, 4]; for split in 1..items.len() { let (before, after) = items.split_at_mut(split); let i0 = &amp;before[split - 1]; for i1 in after { if should_mutate(i0, i1) { *i1 += 1; } } } println!("{:?}", items); }
Can't you use indices? https://play.rust-lang.org/?gist=22d2d768878858a32d9fa7d529d9acd6&amp;version=stable&amp;mode=debug&amp;edition=2015
&gt;I can't form a list of 'mutations' and make them after the fact, because the order I loop through items isn't stable (i.e. it may change between loops) And are you sure you will not get yourself into iterator invalidation issues with it? The easiest solution will be to iterate over explicit indicies: let n = items.len(); for i in 0..n { for j in 0..n { if some_condition(&amp;items[i], &amp;items[j]) { // Mutate items[j] here } } }
Nope, it's not a straight list, it's an iterator that I get from a more complex function (I'm using specs, an ECS library)
Unfortunately this won't work, because the 'items' isn't a straight list, it's an iterator formed from a more complex function, and I don't want to have to collect it into a vec (this would introduce a fair amount of overhead AND be much more complex)
Won't get iterator invalidation issues because I'm not altering the list, just the items held in the list It's not actually a list, it's an iterator that I got from a more complex function (I'm using specs, an ECS library for joining together multiple lists of structs in complex ways), so doing any indexing will mean I need to collect the list and make a big heap alloc
Iterators are one-shot, so you'll need access to a backing store either way since you loop over it multiple times. Can you collect to a `Vec&lt;&amp;mut Thing&gt;` and do the loops, or get access to whatever the backing store of the iterator is?
You can collect mutable references into buffer and work with them. And if `items` in your code is iterator, then you are definitely doing it very wrong, trying to use the same iterator in both loops.
i think I will use for my [site](http://93.180.154.75:7878). Currently, the 'font' is randomly selected on_request, but it would be great if before the font stands still, each character changes. like in your glitchcat. Maybe, I'll do that tomorrow. 
How many elements do you have? Are you sure that creating (reusable) vector of pointers will be a too big price to pay?
It's a pretty tight inner loop, and I don't want to compromise on performance for my big fancy borrow checker Realistically, if I can just have 1 little unsafe block vs a way more complex solution with worse performance, I'm going to go for the first one
No, the iterator isn't actually the same iterator either, it's another iterator produced from something mutable - so I can't get the 2nd iterator because the first one is already borrowing the object
It's 2 iterators sorry, that borrows a single mutabe object (and I can't get the 2nd iter because the 1st iter is already borrowing the object)
&gt; but inflate supports old stable versions so that won't happen any time soon. Wouldn't fixing this be as easy as releasing a new major version?
Are you sure that it's not a premature optimization? And why you think that collecting mutable pointers into a single buffer will cost more than constructing two iterators with "complex function" and iterating over them? Note, that you with buffer reuse you will not reallocate every time, so it should be quite efficient. So my recommendation is: first write easy to understand indices based loop, then measure performance and only if it will be unsatisfactory start look for workarounds and optimizations. (plus you will have a baseline to compare with!) I am pretty sure you are not grasping all potential pitfalls into which you can get yourself with approach you have in mind.
I'm already constructing the two iterators regardless, the mutable buffer is just more code Collecting mut refs into a vec then another loop is strictly more cpu instructions AND not as easy to read What pitfalls are there? This is all singlethreaded, I'm not mutating the list, I have a lock on the list
It should be fine, at least as long as you do not try to write anything to that pointer, then you can break everything. This is like creating pointer with null value, as long as you do not try to dereference it, then it will be ok. The problem there is that you can easily break assumptions that were made in other parts of the program which will leave it in uncertain state. 
It's UB because the compiler is allowed to assume that no two `&amp;mut`s point to the same place. If you break that assumption miscompilation can (will) happen and program behavior is no longer definite.
Oh no I'm definitely writing to that pointer (and it's working as expected) but I know i have single ownership of the memory, and I'm not gonna fuck over any other writes - even then, is this still UB? Seems strange they wouldn't even explain it in the book?
Even creating the pointer is UB (IIRC), because the compiler is allowed to assume it doesn't occur, and can assume that codepath is unreachable. I think I remember an example of this in C, probably on John Regher's blog.
"Undefined behavior" doesn't mean that it doesn't work, it means that the compiler can do whatever it wants, which sometimes makes it work accidentally and sometimes makes it do something completely different. [This](http://blog.llvm.org/2011/05/what-every-c-programmer-should-know.html) article and the two following it are a good introduction to what it is, why it's dangerous, and why it seems like it works sometimes. C++ also has this restriction, but in a weaker form. [It is undefined behavior](https://stackoverflow.com/questions/3801557/can-we-change-the-value-of-an-object-defined-with-const-through-pointers) to mutate a value that was declared as `const` (equivalent to Rust declarations without `mut`), but fine to take a mutable value, make a non-mutable pointer to it, and then cast it back to mutable. In Rust, constant vs. mutable references are passed to the code generator with information saying that they cannot point to the same thing (the "[noalias](http://llvm.org/docs/LangRef.html#noalias)" model). So if you take a function like `fn do_thing(x: &amp;i32, y: &amp;mut i32) { *y += *x; *y += *x; }`, the Rust language says that a compiler is allowed to speed things up by only loading `x` once instead of loading it twice just in case `y` points to the same value.
Is there an example of this? I just don't have the knowledge to properly understand why this is an issue What about *mut, the compiler doesn't make any assumptions about those right? So if I transmute &amp; to *mut, then I can just dereference and mutate and be fine... no?
UB doesn’t mean that your program will now behave differently, it mean that anything can happen, and working correctly is the worst kind of UB, because you cannot be sure that one day it will break, in most unexpected, bizarre and dangerous way possible. 
Yeah, we're going to want things like history, zooming, etc. Ideally as much of it as can be built in would be better, so I don't think going this low level will be worth it.
Ahhhh this is a great example, thanks In my specific case, the function input is marked as mut, it's just I need 2 references to it concurrently to do some moving about of stuff, and one of these needs to be mutable - is it still UB to just hold 2 normal references then transmute to a mut ref? (And yes, I've already though about doing the normal stuff people suggest, like accessing via index)
Yep, that's what I'm worried about &amp; why I'm making this post!
For one, you don't even need to transmute to do that. You can just do `your_ref as *const _ as *mut _` and viola. It will typecheck just fine and it will be perfectly safe too, because *having* a raw pointer to a thing is not UB. However, if you use `unsafe` code to dereference that pointer and modify the value behind it, then you're in UBland because you've violated the invariant that things behind shared references can't be mutated.
Well, if you want to experiment you can just do this and see what happens: let val = 6i32; let mut_val: *mut i32 = &amp;val as *const i32 as *mut i32`; unsafe { *mut_val = 100i32 }; No idea if it is stable through optimization, and it definitely will not work for constants and whatnot, but give it a go and get some nasal demons. Hopefully someone will come by to tell me how stupid I am and that this will cause bad behavior for reasons X, Y, and Z and we can both learn something.
C's type-based aliasing is somewhat different than what Rust does though, so I'm not sure if the comparison is equivalent
To quote the [rustonomicon](https://doc.rust-lang.org/nightly/nomicon/transmutes.html): &gt;Transmuting an &amp; to &amp;mut is UB Transmuting an &amp; to &amp;mut is *always* UB No you can't do it No you're not special
Yeah, but I'm special;) On a genuine note, knowing the bounds of when i can / can't do this would be nice. I already have the ability to get a mut ref - why can't I get a ref, then make it mut? 
Why don't you show us exactly what you're trying to do, it's always worth trying to make a safe solution, and maybe there's a library function you don't know about that could help here. For example slice::split_at_mut allows you to safely have 2 mutable pointers into an array because they're separate subranges
Because the compiler is allowed to make the generated code not do what you intended, and sometimes it will.
Basically because the act of getting a shared reference involves making a promise that you won't mutate the thing behind that reference. This not only allows the compiler to have strong guarantees about your code that it can use to optimize things, but it also allows us users with our monkey brains to have a better understanding about the code. It's quite nice being able to pass a shared reference off to someone and know that the thing behind that reference won't be messed with, even if the function you give it to in turn passes the reference to a bajillion other places that would take forever to audit.
Bringing whole ubuntu to run statically linked application? This is how to properly dockerize such applications: https://github.com/containous/traefik-library-image/blob/7dec7b825ca16d0524626fbbca35284adfe3ef58/scratch/amd64/Dockerfile
I'm using a library called specs, which allows me to hold structs as a structure of arrays - for example, let's say I have a struct `Ball`, which has a `pos: [f32; 2]` and a `vel: [f32; 2]`. The specs crate allows me to hold a list of `Ball`s as 2 lists of `pos` and `vel` - so, something like `Vec&lt;[f32; 2]&gt;` - and then join them together when I need them both. Using this, we can build structs out of components at runtime, and get super cache efficient iteration! Let's say I want to take all the balls and add their velocities to their positions. I can do something like this: for (pos, vel) in (&amp;mut positions, &amp;velocities).join() { pos[0] += vel[0]; pos[1] += vel[1]; } Sweet! I currently have a more complex example, where I'm now trying to detect collisions between 2 entities. I have a third component type (on top of pos and vel) which we'll call 'coll', and this contains a radius that can be used for circle &lt;-&gt; circle collision checking. I want to do an n^2 loop over the list, to check whether a ball is touching any other ball in the list, then correct the ball's position if it is. Here is my code, pretty much verbatim: // Update entities that collide. for (e0, pos0, coll0) in (&amp;*entities_s, &amp;pos_s, &amp;coll0_s).join() { for (e1, pos1, coll1) in (&amp;*entities_s, &amp;pos_s, &amp;coll1_s).join() { // Make sure we don't check for collisions with ourself if e1 == e0 { continue; } // Find the vector we need to push ourselves in to resolve the collision let res = coll0.resolve(coll1, pos0.to_vec(), pos1.to_vec()); // Some bullshit transmuting to mutate pos. This is *probably* // fine because in this function we have a mut ref, and we're // just holding non-mut refs to some values? unsafe { // Get a mut ref then resolve the collision let pos0_ptr : *mut Pos = mem::transmute(pos0); (*pos0_ptr).x += res.x; (*pos0_ptr).y += res.y; } } } See, currently I need to do the funny unsafe block with UB to update the pos. I can't get a &amp;mut ref, because I need 2 iterators. I also don't want to collect a big list of mutations and map them to entity IDs, because this is just adding extra overhead, and rust is meant to give me zero cost abstractions! 
&gt; How could it be undefined (i.e. surely it's trivial to define)? The compiler assumes that the thing pointed to by an &amp; cannot change, so can use that to avoid loading it multiple times in a row, whereas just a raw pointer can change from underneath you at any moment. If there was even 1 case in the whole codebase where that didn't hold true, it would break the compiler's assumptions of it everywhere, and the optimization wouldn't be possible. So it isn't that they *can't* define it, it's that they don't *want* to define it, as the behaviour allows for a very desirable optimization. It would also worsen the situation if we pinned the compiler devs down and said "define this as something"; say they defined it as a panic happens when you mutably alias a memory location: suddenly the compiler has to insert code everywhere to check (somehow) for mutable aliasing and if so deliver a panic like they promised in the definition. Leaving it undefined allows the compiler to live in the happy world where it can pretend/assume that this situation just doesn't happen, and if you try it, you'll get whatever incidental behaviour happens to result from the code. 
So there's no way to 'force' the borrow checker? That reall sucks, because there ARE times when I need it, and otherwise have to sacrifice a fair bit of performance (generally in more heap allocs to keep track of a load of mutations that i should be doing later)
You should spend a second looking through this sub. Is there anything that looks off to you? :-)
Can lifetimes be introduced before an impl block?
There's still the risk of soundness bugs, especially with new features. I wouldn't want to release something critical based on nightly, but with sufficient testing, it's probably just as safe as writing in most other languages, if not safer. I definitely wouldn't want to support a product long term on nightly, but that's mostly because I don't want to deal with the near constant breakage.
You could try [QtCharts](https://doc.qt.io/qt-5/qtcharts-index.html) which comes with Qt (GPLv3). You can control graphs through QML, so something like a rust bin with basic QML bindings loading a QML file for the graph could be feasible. For a similar use case, I've used VTK inside a QML application two years ago. I wouldn't recommend it though; the C++ interaction was scary and full of issues, something that Rust would have gladly prevented me from doing ;)
Could you post the link to your talk?
"This one unsafe to force borrow checker to shut up" is a very slippery slope, see actix unsafe drama as an example. Because your examples are quite vague it's quite hard to give concrete solutions. Fundamentally you problem can be describe like this: you have an underlying storage for your items (does not matter if object properties distributed across several `Vec`s), you want to iterate over all pairs (btw why don't you use n^2/2 iteration with two mutable pointers?) by creating `&amp;` and `&amp;mut`. In this formulation it is safe what you are trying to do, because you can guarantee that there is only one mutable pointer to an item. But you want to express it with incorrect tools. Essentially you need to have mutable non-iterator-based access to the underlying storage and write an iterator which will implement the desired pairwise iteration, so you could write the following code: // `a` and `b` can be `&amp;mut Item` for (a, b) in items.pairwise_iter() { if condition(a, b) { // mutate a and b } } This iterator will take exclusive access to the underlying storage. It will use `split_at_mut` under the hood and can convert `&amp;mut Item` to `&amp;Item`, which is safe. Or you can just go with indices as was recommended earlier. If the only access to elements is through iterator (which I doubt), then I am afraid you are out of luck, and it will require changes in `specs`.
Thanks for pointing out those areas where I should have been more clear. &gt; The problem with defensive programming in general is that there's no bright line about when to stop. Addressing that was my intent with the mention of using `std::panic::catch_unwind(|| { ... })` or a blanket `except` at the "unit of processing" level.but I admit that I really got lazy on the conclusion. I should have waited until the following morning to finish it rather than rushing to post so I could get back to working on the project which prompted it. I've amended it with the following to fix that: &gt; In short, you want a thorough belt-and-suspenders approach to safety: &gt; &gt; 1. **Expected Errors:** Study up on ways that calls can fail, so you can avoid unnecessarily throwing away progress or giving needlessly vague diagnostic information with a coarse-grained recovery strategy. (I actually tripped over just this problem with serde_json in the same project, where it was difficult to diagnose and report [a bug](https://github.com/serde-rs/json/issues/464) because the panic message didn't contain enough information.) &gt; &gt; Despite that, this is still one of Rust's biggest strengths. For example, I never realized that `getcwd` could fail in over a decade of using it in Python. &gt; &gt; 2. **Unexpected Errors:** Identify your transactional unit of work (eg. a step in a processing pipeline that writes its intermediate products to disk, a single thumbnail in a thumbnailer, a single file in a downloader, etc.) and wrap it up in the most general error handler you can find. &gt; &gt;As your knowledge grows, the scope of expected errors will grow (filesystem race conditions being a good example of something people don't usually learn early on), but you'll never anticipate everything. (Nor should you. There's a curve of diminishing returns at play, and you need to balance robustness against programmer time.) &gt; &gt; Suppose you want to leave your computer to thumbnail thousands of images overnight. You don't want to spend weeks perfecting code for a single night of use, but would you rather wake up to find thousands of thumbnails and a handful of error messages in the log, or a few thumbnails and a panic message dating to not long after you fell asleep? ---- &gt; As OP says, it would probably be better to open the directory to avoid the race condition. In that case, it's not possible, since the initial read will always be outside my control. I've added an "or, if possible in your situation" to that line, and this paragraph after it: &gt; In my case, opening a handle to share between the two calls was not possible, because the initial query is done by the ignore crate, but I then have to call `read_link` myself. (I'll probably file a feature request for this, since it seems like an odd oversight in `ignore`'s metadata support.) ---- &gt; Note that in this example, the read_link() failure isn't being handled anyway: it's just punted up to the caller with Option. To be fair, that solution *was* rather specific to my use case. I should probably have concocted a better solution for the example rather than just using the code I actually wrote. Again, I was in such a rush to get back to the project that the article suffered. I've clarified it in the post by adding this: &gt; (In this case, the error resolution strategy is "surface the error in an e-mail from cron via `println!` so I can fix it when I wake up and send a 'best effort' entry to the index that this code populates".) Your code would actually not have the desired effect, because it would cause symlinks to be omitted from the index entirely, when this is supposed to be a companion to `rdiff-backup` to log stuff that I only have room to do offline backups of (eg. my media collection), so I know what to restore from DVD+R if one of my drives fails.
We're basically in it right now -- very few RFCs are being approved at this point, and we're tracking and recording progress on the 2018 Edition on a [weekly basis](https://internals.rust-lang.org/t/2018-edition-end-of-week-post-2018-07-13/7943/). I'm wondering if there's any specific aspect of the impl period you're interested in that you feel is missing right now?
save the criticism for when you stop commenting on things you haven't read.
For making a tiny detail of a private function's signature a tiny bit prettier, it's not worth the trouble.
Would interior mutability work? Ie Cell/RefCell, or their Sync equivalents Mutex/RwLock? Then you wouldn't need a mutable iterator. You do not want to transmute a shared reference into a mutable reference, at best it blows up in your face immediately. At worst it works, until you change some entirely unrelated code/compiler/dependency that causes to optimizer to make it stop working, and then it blows up when you have no idea why.
From what I can tell of of your code and the specs docs, it looks like you could probably do something like this: for (e0, coll0) in (&amp;*entities_s, &amp;coll0_s).join() { for (e1, coll1) in (&amp;*entities_s, &amp;coll1_s).join() { if e1 == e0 { continue; } let pos1_vec = pos_s.get(e1).unwrap().to_vec(); // I'm assuming to_vec ends the borrow on pos_s let pos0 = pos_s.get_mut(e0).unwrap(); let res = coll0.resolve(coll1, pos0.to_vec(), pos1_vec); pos0 += res; } } The unwraps should be fine as long as your storages stay consistent.
Well, I read and had issue with it. I've finished reading and still have an issue with it.
&gt; What pitfalls are there? This is all singlethreaded, I'm not mutating the list, I have a lock on the list The "pitfall" is that you're violating the language rules. In Rust, it's illegal to have two `&amp;mut` pointers to the same memory. When you violate the rules of the language, anything can and eventually will happen. 
Okay, I've created a Medium and copypasted the post there. https://medium.com/@shnatsel/auditing-popular-rust-crates-how-a-one-line-unsafe-has-nearly-ruined-everything-fab2d837ebb1
That's a bad idea, since now you should backport all of your bugfixes, or at least security ones. I found out that inflate went up to 0.4 while I wasn't looking, I need to remedy that too.
I've created a Medium and copied the post there. That way it's much more readable and not region-locked. https://medium.com/@shnatsel/auditing-popular-rust-crates-how-a-one-line-unsafe-has-nearly-ruined-everything-fab2d837ebb1
I'm part of a team that spent the last 10 months trying to do exactly that, at https://seasoned.software. We think such a service would be valuable, and it seemed like there was a lot of interest when we presented it to people. Unfortunately, we struggled a lot to find a single company willing to pay for such a service, so we've put it on the back burner for the time being. Our prototype is still running, so if you (or anyone else) thinks that such a service would be valuable to you, then feel free to reach out to me by pm or kristoffer [at] seasoned [dot] software :P
Not in this case if you don't control the code creating the iterators. If you do control it, you could create unsafe versions which return `*mut` and `*const` pointers, and thus never have multiple `&amp;/&amp;mut` pointers at the same time to the same data.
The problem is that 'forcing' the borrow checker won't help because it's just protecting you from getting bitten by the LLVM optimization passes. Doing so is like driving through a "bridge out!" sign on an OK-looking bridge and then getting mad when the weight of your car breaks through the damaged decking and you wind up in the river. It's your own fault for forcing your way through the safety measure.
A question. The columns are marked with `Rc`. Now, to build the internal DSL I think is easier/cleaner to use rust directly and only mark later with RC when build the interpreter. The problem is the frame, so what if I decorate this instead: enum Column&lt;'a&gt; { F64(Vec&lt;f64&gt;), STR(Vec&lt;Str&lt;'a&gt;&gt;), } struct Frame&lt;'a&gt; { columns: Vec&lt;Rc&lt;Column&lt;'a&gt;&gt;&gt;, rows: usize, } Hopefully, the code get clear and need only boxing in the frame. Don't see how delay until the interpreter have it: enum Exp&lt;'a&gt; { Col(Column&lt;'a&gt;), Frame(Frame&lt;'a&gt;), } 
Because you touch yourself at night.
[removed]
Because the Ubuntu image makes it easy to get up to date certificates.
Thanks for the suggestion. Content is edited. Seems I overestimated the popularity of handlebars language.
Sounds interesting. FYI, your SSL cert seems to have lapsed.
Looks like the blog is down.
It's like getting a car because it has cigarette lighter... 
This request is definitely too late for the 2018 Epoch.
Checkout \`std::sync::Once\`.
Similarly (web solutions), [Elm](http://elm-lang.org/) has some good charting libraries like [line-charts](https://github.com/terezka/line-charts) and its virtual DOM is pretty fast. Might be worth a try if you want to keep a web based approach.
I'll be nice: This subreddit is for a programming language called rust. You are, most likely, talking about rust the game. You should post at r/playrust
Another option is to use `lazy_static` crate if it fits your use case.
I did the `enum Column { T&lt;Rc&lt;Vec&lt;...&gt;&gt;&gt; }` so that I can move columns very fast between input and output frames - the `clone()` of a column will be just a counter bump.
Another one: for `x: i32`, is `x.abs() &gt;= 0` _always_ true?
I like the statement of letting the pipeline quanta being the level in which to add error handlers (and by its nature having to handle a general case where the message is simply "something failed", as the internals may have many different kinds of errors that will be raised). It seems obvious in retrospect as I have generally done that, but I've never tried to place it into words. Having read it now, it will make the process of doing error handling faster for me in the future since I will be able to recognize that instead of trying to resolve the same problem. Also side note: I learned that `getcwd` could fail early on because of my habit of leaving tmux panes open on directories that I'd already deleted.
It is okay to use unsafe in Such case, but _you_ have to ensure, that everything is and will remain safe 
Could we not have gone the other direction and forced the `use` statements to be as explicit as possible globally? As in no matter what we do a fully qualified path. People tend to argue against verbosity, but with tooling and language servers, it's such a minor nit that I would say it would be better overall. People can complain about resolution order, but there are no arguments against having to be fully explicit other than verbosity, which I have always found to be a relatively weak argument. The older I get, the more I realize that syntax sugar is something I only craved when I was less experienced, and I wanted my code to look good, but I wasn't focused on maintainability and stress reduction.
It's a way to tell a thought process, it makes sense to start from something more familiar and less likely to yield unexpected problems, and then optimize from there. I even prefer that way because when I eventually test Rust on Docker, I'll more references for basic issues, and what images have been tried already.
Hyper explicit is not always easier to read. &gt; retarded Please don’t do this here; it’s a CoC violation.
&gt; knowing the bounds of when I can / can’t do this would be nice. That’s easy: you can never do it.
What does the output look like before and after the removal of unsafe in https://github.com/actix/actix-web ?
At least this means the interface is stable — so you can start writing procedural macros on nightly today, knowing they won't break in the future
I'd file an issue in the repos and am quite sure that we can make that happen.
In some circumstances the use of interior mutability through `Cell` or `RefCell` can also be used to work around this issue.
AFAIK, the purpose of the LGPL license is that you can link dynamically to incompatible code. With GPL you can not do that. And with either, you need to have a compatible license to link statically to it. Finally, QT is also available under a commercial license. You can link to whatever you like; but, of course, you'll need to pay for a license. 
If you use static linking with LGPL library you must provide your own code open source OR you must provide a way the user is able to relink your application with its own LGPL library replacement.
If you're going to do this sort of thing, you have to put the target in an UnsafeCell. That's a lot of trouble, and almost certainly the wrong approach here, but that's part of the answer you're looking for in terms of how this stuff actually works. That's the magical type that tells the compiler you're about to violate it's aliasing expectations.
But it is easier to learn and understand. One of the challenges Rust faces is the steep initial learning curve and these features add to that. Not good. Sure it is inconvenient at one point when have a clear understanding, but there are tradeoffs.
It’s not always easier to understand; too much can no overwhelming. That’s what the original post is about.
Can you move some initialization from `main` to the `lazy_static` (potentially using another private `lazy_static` for the rest of the state you need) and just force-initialize it from `main`?
Why not define `pos: [Cell&lt;f32&gt;; 2]` or `pos: Cell&lt;[f32; 2]&gt;`? Then you don't need the mutable borrows at all.
There is a stable ABI between rust and those libraries because those libraries are stable. You can therefore link dynamically with them and be compliant.
This is great thank you for sharing! Also I haven't heard of those blog posts, and I have been looking for good category theory information, this is perfect
Sorry for the delayed response. I had one ready yesterday but forgot that Reddit no longer uses onbeforeunload, which means that Firefox's tab suspend/restore behaviour caused Reddit's "nonexistant by default" textarea behaviour to eat my response. Anyway... &gt; Would it make sense? As long as you can draw a decent line of separation between your backend and frontend code... but that's really just a guideline for any interaction between two different projects It's just a little more obvious when the two modules are in different languages. &gt; Would it be practical? Certainly. You'd basically be putting together something similar to what Qt does with QML. (For their Qt Quick widget API, you write reusable components in C++ or Python), then write the frontend in a dialect of JavaScript called QML.) &gt; Can anyone with experience writing GUI code suggest what language I might want use? If you're using Rust to write a compiled module to be loaded by another language, you can use any language you're comfortable with that has a good Rust bindings framework available. The important part is to be able to move data back and forth between Rust and the other language safely and comfortably, and to ensure that whatever you do doesn't somehow clash with it. On that metric, [Python](https://github.com/dgrunwald/rust-cpython), [Ruby](https://usehelix.com/), [Node.js](https://www.neon-bindings.com/), [Java](https://github.com/Dushistov/rust_swig), or [GObject Introspection](https://coaxion.net/blog/2017/09/exporting-a-gobject-c-api-from-rust-code-and-using-it-from-c-python-javascript-and-others/) make good candidates. I chose Python because, aside from C++, it's the only language with first-class support for Qt's QWidget API, and I want my applications to feel native on my KDE desktop. Though the project is currently on hold while I work on more pressing ones, I'm in the process of converting this from a Python prototype to a Python frontend on top of a Rust backend. https://i.imgur.com/2yQMBZI.png I wrote the frontend in Python 3 with PyQt 5 (because the official Python bindings for Qt, formerly PySide 2, weren't ready when I started it) and I load the Rust backend using a simple `import core` on the Python side. . I glue the two languages together using [rust-cpython](https://github.com/dgrunwald/rust-cpython) for the code and [setuptools-rust](https://pypi.python.org/pypi/setuptools-rust) for the build system. rust-cpython does a very nice job of seamlessly translating between Rust and Python data types via its [FromPyObject](https://dgrunwald.github.io/rust-cpython/doc/cpython/trait.FromPyObject.html) and [ToPython](https://dgrunwald.github.io/rust-cpython/doc/cpython/trait.ToPyObject.html) traits and comes with built-in implementations of them for all of the types you'd see in something like JSON. ([serde_python](https://crates.io/crates/serde_python) is another one available, though it currently only supports Rust-&gt;Python.) Beyond that, you can write your own implementations, use the `py_class!` macro to declare your Python classes on the Rust side, or use [cpython-json](https://crates.io/crates/cpython-json) to piggyback on anything Python's `json` module has serializers registered for. [PyO3](https://github.com/pyo3/pyo3) (which began as a fork of rust-cpython) provides an [even nicer user experience](https://pyo3.rs/master/rust-cpython.html) but currently requires nightly Rust. The main caveats I'd like to point out are: * If you're writing an importable module using rust-cpython, your crate type needs to be `cdylib`, not `dylib`. You'll get misleading error messages if you omit that one character. * The setuptools-rust example configures it for PyO3 rather than rust-cpython and the module name doesn't match that of the rust-cpython example code. (Both easy fixes, but you need to be aware of that.) * Python deduces the symbols to look for inside a compiled module based on the filename, so you need to make sure your `Cargo.toml`, `setup.py`, and `py_module_initializer!` macro all agree on what the module is supposed to be called. * I've only tried this in the "load a Rust module into a Python program" configuration. If you want to try the "embed a Python runtime inside a Rust program" configuration, you'll want to look at the example code I posted in [rust-cpython issue #121](https://github.com/dgrunwald/rust-cpython/issues/121) to help someone else out. * In my experience, `setuptools-rust` sometimes doesn't realize that the copy of the Rust build artifact that it puts into the Python side of things is out of date, so I advise installing [just](https://github.com/casey/just) and crafting a task like this one which you can use as a dependency for tasks like `just test` and `just run`: rebuild: rm python_src/YOUR_MODULE_NAME.cpython-*.so || true python3 setup.py develop 
If you are fairly new to Rust web stuff I made some tutorials on my blog that you may be interested in. Most deal with the Rocket web framework, but there are some tutorials that apply to any framework (like the vps and Linux ones for hosting your web apps). I would be interested to know if it's helpful to anyone, I know when I started my blog I had difficulty finding many good tutorials to help me get started.
...and I find the term "pipeline quanta" inordinately appealing. Thanks for that. :)
FWIW, your argument just made me have a deeper look at in-band-lifetimes and reconsider. Interestingly enough, the more I know about Rust, the less I feel the need for some of the ergonomics features (I still feel NLL will be a godsend). Not sure if that's just me getting used to Rust, or finally *getting* it. While I still think in-band-lifetimes will be useful for learning (mostly by making the transition from pre-rigorous to rigorous less painful), I too would now prefer having an allow by default lint against it. I might even try to implement it later this year, if no one beats me to it :)
If Qt and GTK+ were written in Rust, then you might be right, but Rust applications call into them using their native ABIs, which *are* stable.
Shouldn't `run_len_dist` be `unsafe` then? If it is unsafe if called with certain arguments? You would then push the `this-is-why-it's-safe` comment up to point-of-use where it may be more immediately clear that `dist &gt; 0` (although the fact that it's wrapped in a macro makes it a little hard to reason even there). 
Wow. That's amazing
/r/AV1 is a subreddit dedicated to AV1 encoder and news about it.
This is really helpful on a number of levels for me, thanks! 
You're not special, because if you try to do this, the compiler will do something that will break all your code. The compiler is 100% allowed to assume that no immutable reference will ever become a mutable reference, so it is always allowed to make whatever optimizations it can based on this assumption. Knowing those bounds is easy: there are no situations where you can do this.
The problem isn't the popularity. It's just one of the many names of the many tools developers use. Unless you're actively using it, chances are you might have come across it at some point and if you think really hard you might remember exactly what it was, but having it spelled out makes for easier contemplating what the news item means. This is why most big project announcements (and big as in Apache, Gnome, OpenOffice, etc.) always start of with a simple one line description of the project. Even though they are much more popular/noteworthy than something like handlebars. That said, great news! ;-)
lol. that guy has a funny name. almost sounds like my name, but much funnier.
If you need two references to the same thing and one of them needs to be mutable, you can use a [`RefCell`](https://doc.rust-lang.org/std/cell/struct.RefCell.html) which allows this (it kind of acts like a single threaded Mutex).
What do you understand under "pipeline quanta"?
&gt; Seems I overestimated the popularity of handlebars language. It seems unlikely to know about it unless you are doing web development.
Maybe this is a silly question but have you ever had glibc vs musl being an issue? Or is that not really relevant for most user applications?
Great work! So you really don’t need any C libraries? I remember crafting some funny code around X11 in a 64k demoscene compo… but I still relied on the relocatable object. I should read more about the protocol you’ve implemented.
"Quanta" is the plural of "quantum". (They're both latin words) Quantum, as a noun, has several meanings in physics but the common thread between them is "the smallest possible piece/degree". ("Atom" used to mean that, coming from the Greek "a-tomos" (Indivisible) before we discovered that they weren't the smallest pieces.) So "pipeline quanta" is a clever way to say "the building blocks of a processing pipeline which either succeed or fail in their entirety".
[GPL FAQ](https://www.gnu.org/licenses/gpl-faq.html#LGPLStaticVsDynamic)
Thanks! I'll try writing the UI both in rust and in python to get a feel for what I like more.
If your usecase fits it, http://gtk-rs.org/docs/gtk/struct.DrawingArea.html might possibly be enough, rather than implementing a whole new widget from scratch. I use a couple of `DrawingArea`s in https://github.com/FreeFull/monotile/ for my canvas and tile selection widgets.
There is definitely some way. You can always write assembly or intrinsic operations that guarantee loads and stores to memory. Maybe atomic operations would be required at some places. But you really need to know how memory on your target architecture works, how optimizers in LLVM work and do not mess it up in the end. You may also give up on some nice abstractions and write a lot of low-level code but it is definitely possible.
&gt; It should be fine, at least as long as you do not try to write anything to that pointer, then you can break everything. This is like creating pointer with null value, as long as you do not try to dereference it, then it will be ok. I don't really think this is true. I mean, let's take a step back and ask "Who decides what's UB?". It's easy to answer: The author of the compiler. That's because it's a statement about what the compiler assumes about your code. Of course, if a language's spec defines somthing is/isn't UB, then all compilers should honor that, but in the end, it's really exactly the compiler's code that is the authority about what's UB and what isn't. So I'd say this is a good (if somwhat loose) definition of UB: * Something the compiler assumes you're not doing * But the compiler doesn't warn or tell you if you do it anyways So of course simple mistakes most often aren't UB, but errors the compiler tells you about it. But UB is about the things the compiler can't or won't verify to tell you about, but assume you simply take care of yourself. For example, compiling for the wrong architecture might be called UB, because the compiler can't really tell what you're going to run the binary on, and who knows what might happen if you run it on the wrong architecture. Therefore the compiler simply assumes you don't do that. Yes, that's a contrieved and somewhat stupid example, just to show off what I said above. So in the light of the above, there can imho not be any arguing. If the compiler says "Transmuting &amp; to &amp;mut is UB", then that's it. Just the act of doing that will make it UB, because the compiler assumes you don't do it and acts accordingly. Even if one can't imagine what could go wrong if you do this but do not use your new &amp;mut, it's still UB and might wreak havok (or not have any consequences at all, sure). As a parallel, I've read a discussion I can't find anymore, where someone said "Well, reading uninitialized memory is UB, ok. But I'm reading it into a u8, so all bit patterns are valid, so it's not". That's the same fallacy, simply doing it is UB, any usage after that doesn't matter anymore. Of course, docs might be wrong/outdated/too conservative and all those things. But in the end, the question of "Why is it UB?" can only be answered by "Because the compiler treats it as such", and the consequence can imho only be: Don't do it, and follow that statement to the letter (not to how you understand it or how you think it should be).
Couldn't have explained it better myself, and thanks btw :)
Isn't that quite tautological (for integers)? I can see it being wrong for floats, NaN.abs() &gt;= 0 will probably return false.
Doesn't `cargo audit` tell the people to update ? I thought there was a website somewhere where you can mark all versions of a crate e.g. &lt; 0.5 as "insecure" and it would tell you exactly which crates would need updating. So you can just bump the major version to 0.5 and directly mark 0.4 as insecure if you want (or do that later). I mean, even if you stay with `0.4`, people fixing the version and people not updating their `Cargo.lock`s won't get any security fixes anyways..
Im aware of drawingarea, thanks though. I wondered if gobject subclassing works or not. I will check your project, seems like drawingarea is the only option (simple) for now
This means that all through my program, this data structure needs to be encapsulated in a refcell, right? This isn't really an option, the data structure is used so often and the whole point of my architecture is to minimise the size of these struct in-memory so I get super sick cache efficiency when iterating over them
Then there's no way I can 'force' the borrowchecker, so this just isn't a zero cost abstraction then, which is super disappointing
Because that requires some weird copying of shit and it makes the code for the rest of my program way more convoluted, because pos is used eeeeverywhere - I just need to force it for this one instance, I don't need it anywhere else
Ohhhhhhh, potentially this IS a way around it. I'll check this out, thanks.
Yep, I think i'm gonna have to dig deeper and make my own iterator. argh! thanks!;)
This talk is worth watching, Andrei Alexandrescu is hands-down the funniest speaker I've ever seen. I regularly burst into laughter when watching his talks :P Anyway, for those who can't watch the talk, a quick summary: Andrei talks about error handling in C++ and discusses a few known solutions with their advantages and disadvantages. The solution he arrives at is `expected&lt;T, E&gt;` which can either store the `yay` value of type `T` or a `nay` value of type `E`. Sounds familiar? ;-) So `expected&lt;T, E&gt;` is like `Result&lt;T, E&gt;`, but with the usual C++ unsafeties, (IMO) dangerous implicitness and crazy verbosity. I think the most important/interesting part of the talk is how he talks about local vs. global handling of errors. He argues that both kinds of handling errors are needed. The `expected&lt;T, E&gt;` type immediately allows for local handling with, for example, `has_value()`. This is exactly like our `Result&lt;T, E&gt;`. But the programmer can "switch to" global handling by writing `*expected` to unwrap the `yay` value (and yes, using `*` to unwrap was critized by Andrei). In case the `yay` value isn't there, the `nay` value is thrown as exception. And exception allow for global handling of errors. In short: **a sum-type based, `Result&lt;T, E&gt;`-like approach for local handing and using exceptions for global handling with an easy way to convert a `expected&lt;T, E&gt;` to an exception.** 
Well, it depends. Currently, if you plan to use OpenGL, it is still necessary to depend on the \`libwayland-client.so\` system libraries, as the opengl libraries use them.
Hopefully we can soon see a DE written in rust.
It's not an abstraction at all, it's a hard constraint of the language.
Then, a constraint that makes you make concessions on speed where C++ wouldn't
Well, this is a lot about what [smithay](https://github.com/Smithay/smithay) is about! But there still is quite a lot to be done, and we are not many working on it so progress is pretty slow... :/ You should definitely check out [Way-cooler](https://github.com/way-cooler/way-cooler) though. It's not 100% rust all the way down as it's based on [wlroots](https://github.com/swaywm/wlroots), but it's pretty neat!
Is it possible that you could point me in the direction of some resources like this? This is exactly the kind of thing i need!
Actually, you can now write proc macro crates on stable -- the `use_extern_macros` feature is only used to import the macro. The actual proc macro definition compiles on stable. 
Still down for me. [Site in Google Cache](https://webcache.googleusercontent.com/search?q=cache:wt3tcF1LxikJ:https://this-week-in-rust.org/blog/2018/07/17/this-week-in-rust-243/+&amp;cd=1&amp;hl=de&amp;ct=clnk&amp;gl=de)
if you want performance i would recommend against using two nested loops, n^2 blows up real quick. if you have more then 50 elements use some kind of tree.
Or just plain sum types, which have existed in Haskell since 20 years ago. 
yes? I think! 
An interesting part is rust developers come from various domains, web development, system programming, game development. No other language has diversity like rust.
For reference, I used QCustomPlot like you mentioned many years ago and it was lightning-fast with a big set of sample-points on the display. GUI with rust is a bit lacking still unfortunately. Depending on your setup, you could consider doing the GUI in C++,QT with the rest of the logic in Rust. Also as mentioned, something like Elm, might or might not beat Highcharts for web-rendered content. 
Yep, i just wanted a brute force algorithm until i got around to implementing spatial partitioning!
I've notified u/cmrx64 who maintains the server. Awaiting response.
Maybe there's something about exceptions I'm not seeing, but isn't this exaclyt what `Result` is? We can do local error handling by `match`ing or `if let`ing on a `Result`, otherwise just use `expected?` just as a normal value, and a possible error gets propagated up the chain. For binaries, that seems just the way it's done, you handle errors in `main` (mostly printing I guess), and everything else just uses `?` on `Result`s. What would be different if in addition Rust had exceptions and `?` would do that unwrap-or-exception thing?
Or in ML, from 40 years ago 😛.
[removed]
While we look into server issue of https://this-week-in-rust.org, a backup site is up at https://this-week-in-rust.github.io/
As I understand it * is more like .unwrap() than ?.
Or in Category Theory from \~75 years ago.
`value()` is like `unwrap()`, `*` has no equivalent in Rust because dereferencing an Err(T) is an UB. It would be some sort of unholy `unsafe_unwrap()`.
&gt; Maybe there's something about exceptions I'm not seeing, but isn't this exaclyt what Result is? It's somewhat similar conceptually, but removes the convenience methods and adds UB.
You're right about `value()`, he even shows an example where he checks the tag before calling it to check if the union has the right variant. But I think you're confused about `Err(T)`. It's not UB to dereference it, you just can't do it, because it's an enum variant, not a pointer (`T` might be a pointer, of course). Also in this case, `*` is not used to dereference in `expected` (which he criticises as mentioned above), but has the role of `give me the yay [=Ok] value or throw an exception from nay [=Err]` (brackets mine).
&gt; This is exactly like our Result&lt;T, E&gt;. But the programmer can "switch to" global handling by writing *expected to unwrap the yay value (and yes, using * to unwrap was critized by Andrei). As far as I know `*` does not "switch to global handling", dereferencing an errorneous expected is UB not an exception. `.value()` raises an exception.
So what's "more global" about throwing an exception rather than bubbling the Err up the chain? That's probably the core of my question.
&gt; Of course, if we got a bad variant, unwrap will panic, while value()... not sure, give out nonsense? `value()` specifically raises an exception. `*` is UB (and thus can do anything).
See my edit, I think you've got this backwards. Not a biggie, ofc.
My understanding is that the global part refers to exceptions being unchecked (in C++ at least), which means that if you call a function that can throw an exception, you don't have to write any code that deals with that exception. And when you don't do that, you automatically pass that responsibility to your caller. The alternative that Rust has gone for, is that each caller of a function that can return an error must write code that propagates the error upwards. This is the local handling that exceptions allow you to skip.
I haven't looked into the implementation of `expected`, but I would assume that `*` is just "syntactic sugar" for `value()`.
There is no "weird copying of shit". I'm not really sure where you want to go with this question. On one hand, you use a quadratic algorithm that you know and admit is inefficient. As far as I can tell from this thread and the other one (about "forcing" the borrow checker) you haven't used profiling, so you can't compare the performance characteristics of the various solutions that people suggest, and how they might compare to a hypothetically working example that uses `unsafe` and UB. And yet you *insist* on doing stuff with `unsafe` that *everyone* is telling you doesn't work, because "its' a pretty tight loop and stuff must be efficient". In addition, your code (or some minimal example of your problem, that compiles except for that one problematic line) isn't available anywhere so it's hard to suggest alternatives. People genuinely want to help, and writing high performance code is fun fun fun, but you're making it very difficult. Here, I'll hand you the rope to hang yourself: fn evil&lt;'a&gt;(foo: &amp;'a i32, bar: &amp;'a i32) { unsafe { // this is UB, and if you use this you're doing things wrong, // it's not clever. Just don't do it. It may *seem* to work. #[allow(mutable_transmutes)] let foo = ::std::mem::transmute::&lt;&amp;'a i32, &amp;'a mut i32&gt;(foo); *foo = *foo + *bar; } } let foo = 5; let bar = 3; evil(&amp;foo, &amp;bar); // maybe prints 'foo: 8, bar: 3' println!("foo: {}, bar: {}", foo, bar); evil(&amp;foo, &amp;foo); // maybe prints 'foo: 16, bar: 3' println!("foo: {}, bar: {}", foo, bar);
Ok, we're in kind of an edit-instead-of-reply circle, I'm trying to break that :) I just checked agaoin, at 0:39:30 the slide shows that `*` throws, and for local stuff you use `has_value` to check.
Ok, makes a bit of sense. Otoh, you could have that with `Result` too, if just every function would implicitly be converted to return a `Result` and the `?` would be implicitely added. Right? I'm not proposing this, I'm just trying to grasp the real difference.
I'm going after [p0323r7](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0323r7.html) (which seems to be the latest revision of the proposal). [Observers](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0323r7.html#expected.object.observe) specifies that: * `operator*()` "Requires: `bool(*this)`" and "Returns: `val`" unconditionally. From this it follows that dereferencing an unexpected is UB * `expected::value()` "Returns: `val`, if `bool(*this)`" and "Throws: `bad_expected_access(error())` if `!bool(*this)`. This is also coherent with std::optional which is mentioned in the proposal (though IIRC it was much more prominent in previous revisions). It is also coherent with usual C++ API design, in this case that an expected would be used thus and not incur performance penalties: if(auto exp = foo()) { exp-&gt;thing(); }
Oh ok, that might just be a difference between the proposal and the talk, then.
&gt; if not, I would consider that a bit strange. Welcome to C++, where efficiency is of prime concern and safety doesn't matter. `value()` is roughly equivalent to if (expected) { return *expected; } else { throw bad_expected_access; }
You can write the same code you would write C++ in Rust, you just can't do it with references. If you really, absolutely need to use unsafe and shared mutability, the way you do this at the bottom level is by using `UnsafeCell` and by passing around pointers, and then you pretty much get the same behavior you'd expect from C++ pointers / references. This is how things like `Cell` and `RefCell` are implemented in the std library. The reason it's UB to mutate through immutable references is by design. The fact that safe rust can prove aliasing xor mutability is incredibly useful for lots of reasons, but one of them is that you can tell LLVM about it and it enables faster code generation without having to include in the language something like C's `restrict` keyword. (I'm not a language design expert or anything, this is my non-expert take, also it's slightly more complicated than this because C doesn't have the ability to guarantee exactly what rust references do). You can learn all about "unsafe rust" in general from the [nomicon](https://doc.rust-lang.org/nomicon) if you're not already aware. It looks like there might be a solution for what you want to do though with specs in safe rust, so if that's true obviously you should really really try for that first. Even if you suspect it might be slower, it also might *not* be slower and you should try that first. Even if it is slower you should try to find every optimization that doesn't involve unsafe before the ones that do. If you want to live dangerously, you of course can, you just want to avoid it as much as possible because it's just really very hard. Writing sound unsafe rust is just about as hard as it is to write sound C/C++, so *extremely* hard. When you do end up having to do this, the benefits of rust become being able to reason about such code *locally* rather than having to reason about your whole program at once, which is an ENORMOUS benefit, but still... it's hard.
Mh, I see, apparently there is some confusion about whether `value()` or `*` raises the exception (and which one results in UB). From the talk I got the understanding that `*` raises exceptions. But that might be wrong, sorry!
It's clearly so in the talk, see the slide at 0:38:49. I think masklinn refers to an existing proposal, which of course does not need to feature the same details as the talk.
The talk does seem to give that impression (/u/KillTheMule provided the timestamp: 0:39:20), however that doesn't fit the proposal, or previous discussions I've seen about it, or the slide itself: right above the bit where it says `*foo` raises it also says that the idiom for "local checking" is `if (foo) use(*foo)`. This implies a double check which is usually anathema to C++ developers. Furthermore, `std::optional` which uses a very similar API does not have that behaviour (`*optional` is UB, `optional.value()` throws)
I *guess* it's about the "convenience" that you don't have to annotate exceptions in your type signature (as opposed to returning `Result` from all functions where an error can happen). So I guess exceptions in this model are a bit like `panic!()`: - function signature don't say if they can panic or not - you can catch panics (although, of course, it's rarely idiomatic to do so in Rust) - you don't want to handle panics up until the "very top" where you can print a nice error for the user or something like that
I'll ask the same question I asked someone else: So if we made `Result` be used implicitely and also used `?` implicitely (however that coud be implemented, never mind please), that would be the same as throwing an exception? This isn't as much of a difference I was made to feel like, that's why I'm asking.
C++ fans would argue that everybody stole the idea, and who did it earlier - did it wrong.
The oddity is that [an older revision of the slide deck](https://cppeurope.com/wp-content/uploads/2018/02/Andrei_Alexandrescu_Expect_the_expected_slides.pdf) specifically refers to an older revision of the proposal (P0323r5) and has the same statement about `*result` despite P0323r5 having the exact same specified behaviour as all revision around it: `*value` *requires* `bool(*value)` while `expected::value` conditionally returns or throws.
`impl Fn*` should fo it
&gt; that would be the same as throwing an exception? Yeah, I guess. I think it's a weird comparison, but I guess that would be semantically more or less the same for the user. On a technical level, it's different of course. The performance characteristics of return type based vs. exception based error handling are different. Neither is clearly better, but they both can be better than the other in specific situations.
Hehe, ok. For me, it's not very important, I'm onlu comparing `expected` to `Result`, and the only thing of note is that there's `local, where you check and use (UB if you forget the check)` and `global, where you just use, will throw otherwise`.
Sure, but if the traits were stable you could do something like: struct Composed&lt;F, G&gt;(f, g); impl&lt;F: FnOnce&lt;...&gt;, G: FnOnce&lt;...&gt;&gt; FnOnce&lt;...&gt; for Composed&lt;F, G&gt; { ... } for `FnOnce`, `FnMut`, and `Fn`. With `impl Fn` you only get one.
&gt; On a technical level, it's different of course. The performance characteristics of return type based vs. exception based error handling are different. Neither is clearly better, but they both can be better than the other in specific situations I'm not asking you to explain that, but can you point me to a resource that has details on that exact technical difference? That's what I'm really interested in. I learned to use exceptions 20 years ago, and learned to love Rust's approach some month ago, and while `Result` is just a return value (so I think I mostly understand that), I have no idea what exceptions really do "under the hood", if they don't implicitely mess with the returned values.
Yeah, the problem with unsafecell is that it just pollutes everything, now I need to write unsafecell everywhere and import unsafecell everywhere, which is a shame I get that the compile does optimisations given guarantees that stuff is not aliased, but surely this is on a local basis (i.e. can't I just say 'yeah there's gonna be some aliasing but only for this section of code)? Have I just misunderstood this? I have a safe solution, and there is a safe solution fairly often, it's just annoying that there's no option to do it the 'unsafe way' without it being UB since the whole thing about rust is 'hey we have all these sick features over C++, but don't worry you can always dig down and do whatever you were gonna do in C++ with 'unsafe'!'
Use unsafe and pointers if you want to. Making references that don't obey the rules for references has no purpose, it's just using pointers while lying to the compiler about it. If you lie to the compiler how do you expect it to work correctly? It's not possible.
I think the answer would be "nothing", looking at the slide (can't actually listen to the talk right now) it looks like "global" is defined as "not local" and "local" is defined as "function-local". So basically "global handling" is any time you don't handle an error locally but pass it to a caller instead.
Ignoring the safe solution I found (b/c given a more restrictive library API it's fairly easy to see that wouldn't be available), it's not even about the performance in this case - it's just way more work and way harder to read than being able to alias the pointers. Is there no way to tell the compiler that 'hey i'm gonna have pointer aliasing but only in this function, everywhere else we can go with what you say, I promise'? I don't mean right now can I do this, I mean is this possible with the current architecture? I have no idea, because it's not documented anywhere, I can't do something that seems incredibly intuitive with no explanation I don't want to know how to write my code in a 'safe' way (regardless of whether it ended up being the best way to do things), I want to know how to force the borrow checker and why I can't
Because C++ makes concessions on safety where Rust wouldn't. If you could get all the safety benefits of Rust without restricting anything you could do in C++, there wouldn't be any reason to have the language. You could write a linter for C++ and be done. But that isn't possible.
You can't just 'use pointers' because the whole ecosystem uses references, you have to give references to libraries and get references from libraries
...and a new Sum type were implicitly created that unified all the possible errors that could be thrown. Sure. But that's getting to be a pretty big "just."
Yes, that may not works for your use-case. But this is the proper idiomatic way of doing what you want to do (sharing mutable references). If doing so is too expensive, you could consider using another pattern (other than sharing mutable references). I can't help here because I don't know what you are trying to do exactly. But you should not, in any case, transmute a shared reference to a mutable one, even if it seems to work. That's not valid Rust (that's what «undefined behavior» means).
I was under the impression that `std::variant` was added for this purpose?
Is there a transcription available?
The way to do it with `unsafe { }` is to use `UnsafeCell`. The compiler has special knowledge of `UnsafeCell` and when it sees it, it knows that weird aliasing things might be going on. There are no other types that have this property. 
Generally you'd just store the data in `UnsafeCell` but have some kind of safe API for normal access. You really *don't* want the fact that something is stored in an `UnsafeCell` leaking everywhere, because it probably means that huge swaths of your program are potentially unsound. Read in the nomicon [here](https://doc.rust-lang.org/nomicon/working-with-unsafe.html) about how use of `unsafe` kind of "pollutes" a whole module to understand what I mean. You're correct though that unsafe rust is just in general more verbose than C/C++. I personally actually *like* this, because it makes unsafe code look as dangerous as it really is, and I think safe code looking so much simpler and being so much easier than unsafe code is really the right gradient to have, and it's honestly not *that* bad. Some people though have wished for a simpler nicer version of unsafe rust that's a bit less verbose, and I can understand the desire for such a thing. You generally see this when you're writing a library or something and the majority of the code inside the library is going to be unsafe because it's wrapping some other unsafe API, or you're mostly doing hardware level things in the embedded world. You can have APIs that return \*mut pointers though if you don't want `UnsafeCell`* in particula*r to leak through the API, but of course most anything you do with the returned pointers then requires unsafe. APIs like this are rare in the rust world because the culture is such that there has to be a* fantastically goo*d reason to have APIs like this that require the use of unsafe, and it's just pretty rare.
&gt; 'hey i'm gonna have pointer aliasing but only in this function, everywhere else we can go with what you say, I promise'? How does the compiler know that you don't have active references in other functions? This is part of the problem. To do what you're suggesting changes the meaning of `&amp;` *everywhere* not just in your function. 
rustc will only set the concrete type of `T` once, so it will fail since your `mapper` argument's `T` is not guaranteed to be `Disco`. You might need to use two generics, so you can have `Option&lt;Mapper&lt;T&gt;&gt;` and `Result&lt;Mapper&lt;U&gt;, Box&lt;std::error::Error&gt;&gt;` for example.
Unfortunately, no, due to budget constraints.
I don't really know good resources, but [this](https://monoinfinito.wordpress.com/series/exception-handling-in-c/) came up in a Google search and I guess it's accurate :P (only skimmed it). I think the gist is that exceptions are "active" where as return values are just passive (they are just values). I don't know how much you know about low level details, so just ask if any of the following is not clear! Also note: I'm about to explain stuff for x86[-64], it might not be correct for other CPU architectures or ABIs. I'm also skipping over a lot of detail. Like your program is just a bunch of instructions, yes? The whole program is loaded into RAM and a special first instruction is executed (basically the first instruction of `main()`). All functions (more precisely: their instructions) are just somewhere in memory. If you call a function, you basically but the function arguments in a special location, you put the address of the current instruction (the *return address*) in another special location and jump to the function. It just means that the execution is resumed at the first instruction of the called function. If the called function now returns a value, this value is written to a special location (like the arguments were), then the *return address* is read and execution jumps to that address. So now the CPU executes instructions of the calling function again. The "control" returned to that function. In case of `Result`, that function will now check the returned value and -- if it's an `Err` -- will return the error (to the function that called THAT function). So control of what happens is flowing up the functions. Exceptions work differently. If an exception is thrown, special exception instructions are executed. These instructions look at the function stack (piece of memory where meta data about which function were called is stored) to determine what to do next. For example, it determines which destructors need to run and then find the nearest `catch` block. The execution then jumps to that `catch` block. Note that from the point the exception was thrown up to the point we jump to the `catch` block, no instruction from your functions are executed. Your functions weren't in control! Something else "looked at the memory" and determined what to do. In that sense, exceptions are active and return values are passive. As an effect, calling function don't need to check for exceptions. In the `Result` case, the calling function has to have a branch to check whether the return value is ok or no. In the exception case, the calling function don't need to check, because if an exception were to be thrown, the calling function can be sure that it won't be executed afterwards. This means that return based error handling often means more branches. This sounds bad. And yes it can make your program slower. But it's not the whole side of the story as exception also slow down your application, just in a more nuanced way. Exception basically restrict the compiler and the CPU in what optimizations they can perform. 
If you too are wondering where that "~75 years" number comes from: https://en.wikipedia.org/wiki/Timeline_of_category_theory_and_related_mathematics
**Timeline of category theory and related mathematics** This is a timeline of category theory and related mathematics. Its scope ('related mathematics') is taken as: Categories of abstract algebraic structures including representation theory and universal algebra; Homological algebra; Homotopical algebra; Topology using categories, including algebraic topology, categorical topology, quantum topology, low-dimensional topology; Categorical logic and set theory in the categorical context such as algebraic set theory; Foundations of mathematics building on categories, for instance topos theory; Abstract geometry, including algebraic geometry, categorical noncommutative geometry, etc. Quantization related to category theory, in particular categorical quantization; Categorical physics relevant for mathematics. In this article and in category theory in general ∞ = ω. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
https://www.reddit.com/r/rust/comments/900jnl/what_makes_transmuting_a_into_a_mut_undefined/
I think you've misunderstood enums, because both what you're saying and the code you've written is very confusing. What are you trying to do? Your `Mapper&lt;T&gt;` has only one variant, and is pretty much useless. It's basically equivalent to `struct Mapper&lt;T&gt;(T)`. Additionally, `load_mapper` must return a `Mapper&lt;T&gt;`, where the *caller* gets to choose what `T` is. But you're trying to return a `Mapper&lt;Disco&gt;`, i.e. you've already picked `Disco` as your `T`. That's why it doesn't compile. It must work for *every possible* `T`.
Can gnu plot do updating plots? I keep meaning to learn it, seems much more powerful than either matplotlib or grafana, my two charting solutions. 
The c libraries for GTK and QT and dynamically linked. Thus you are fine using them under the LGPL without your own code becoming LGPL.
From the small snippet you posted, it's because you declared a type variable `T` that is used for both input and output, but then you return a concrete type instead of `T`. You would have to make sure the returned value is derived from the input `mapper` in order to get it to compile correctly. Here is an example: http://play.rust-lang.org/?gist=f28f9faeca7ca1b2cf45dc00280083a2&amp;version=stable&amp;mode=debug&amp;edition=2015 (uncomment the second function to see the same error you have posted here) If you are going to return a concrete type, then put that concrete type in the function signature. Usually when I've seen this error, it was because I was trying to return different types depending on some kind of runtime condition. If the return type is not known for sure until runtime, you'll have to Box the return type so that the compiler can know exactly what will be on the stack when the function returns
I don't know much about Wayland. If not OpenGL, which API can you access to draw stuff on the screen?
What other programming languages are you familiar with? If you look at, say, C, it forbids casting between different pointer types (with some exceptions), e.g. you're not allowed to cast `int*` to `float*`. You're not allowed to overflow a signed integer. You're not allowed to read from uninitialized memory. The question 'how can I force the language to allow these things' inherently doesn't make sense. You *can* write code that does all of these things, and sometimes it will even do what you expect. At other times the compiler will transform your code in ways that are perfectly valid unless you break those rules (and you did) and your program ends up doing something unexpected. Rust "the language" is designed in such a way that aliasing mutable pointers is forbidden. The borrow checker isn't some part added to the compiler because Rust developers enjoy chains and bondage, it's there to ensure that you don't accidentally bump into undefined behavior as is so very very easy to do in languages such as C. It's like a lint on steroids. You can't 'force' it to allow something because it inherently has no power over code generation; lifetimes don't exist at runtime. You can create a working Rust compiler without a borrow checker (e.g. [mrustc](https://github.com/thepowersgang/mrustc)! Even if you were to remove the borrow checker entirely from `rustc` (thus "forcing" it) mutable pointer aliasing would *still* be forbidden.
Sure, having both - `*` and `value()` - throwing an exception would be the most correct solution, but even having both to have UB would have at least some kind of consistency, but this is just the kind of C++ API design insanity I don't get. If the check in `value()` really might be a performance problem, because you have e.g. lots of `expected` values, then `expected` is just the wrong solution for the problem. This seems like some kind of fear driven API design which makes the life of everyone IMHO just harder. 
Wait, this is 30 months old?
(ah yes this makes more sense than what I assumed -- that the code was abbreviated and the other variants omitted)
I don't understand the question, but right now the edition doesn't prevent you from declaring lifetimes, it just lets you leave it out. 
I had a class in C++ that required some fairly complicated recursive behavior. We were left to choose out own implementation, provided it met the spec. Most of my colleagues did a fairly "traditional" OO approach with a couple huge classes and lots of interior mutability (mostly Java classes up to that point). I had experimented with functional programming, so I wrote mine in a semi-functional, semi-OO style with several small classes with limited mutability instead of one or two large ones. I feel like this enabled me to get a good solution more quickly since I could isolate my problems better. Understanding multiple paradigms gives you more choices in designing software. I think this is especially true when requirements change part way through a project (e.g. now it needs threading or run in a cluster).
&gt; Sure, having both - `*` and `value()` - throwing an exception would be the most correct solution, but even having both to have UB would have at least some kind of consistency, but this is just the kind of C++ API design insanity I don't get. What's the point to having two API doing the exact same thing? Surely if you have both `*` and `value()` you need some divergence between the two, a justification why you're not removing one of them? Furthermore you could say the same thing about Rust's `unwrap()` versus `match`, one of them panics and the other doesn't, that's not consistent. The answer is that as with Rust's `unwrap()`, `value()` is a convenience assertion.
You can do plain shared memory: you write your pixel contents in a memory buffer, then using mmap or a temporary file, you get a file descriptor to this buffer that you then share with the server. This is purely CPU drawing, so much less efficient than using OpenGL, but for some simple interfaces this can be quite sufficient.
Yeah, it wasn't meant as a way to do it, just a thought exercise. But as [explained above](https://www.reddit.com/r/rust/comments/904lmp/expect_the_expected_andrei_alexandrescu_talk/e2nxwgv/) it's not really the same, except from the programmers view I guess.
Yes; I did this interview long ago, and it was edited down. This is the unredacted version, which was newly published.
Thanks for the explanation! Feels clear, but let me just fomulate it in my own way: The difference is that `throw` overwrites the return address, and there's no return value written back, but the code flow of the `try`ing function is just switched to the `catch` block. So the "happy" path mostly works just as if there was no exception mechanism (except that the code for the function contains a `catch` section that's not reachable outside of this exception mechanism), but the function throwing the exception modifies the "path of execution".
I have a suggestion for a prettier serialization: If you merge the key and the
 &gt; What's the point to having two API doing the exact same thing? One is the syntactic shorthand and the other is the more explicit one. I would be fine not having the `*` and just having `value()` and `unsafe_value()`, but having the convenient `*` with the unsafe semantics just feels wrong. It would be nice to be able to write by default just: if (expected) { func(*expected); } and get the safe behaviour. &gt; Furthermore you could say the same thing about Rust's unwrap() versus match, one of them panics and the other doesn't, that's not consistent. `unwrap` is a method and `match` is an expression, so I can't see how you should compare them regarding consistency. 
I have a suggestion for a prettier serialization: If you merge `key` and `version` into a `u64`, you could use the result as serde key for a map structure. This is by far more intuitive than the current serialization with `value` and `version` since `version` should be an implementation detail. Additionally, if a user sees a map of values and changes the key, it's less surprising when the program won't work anymore than changing a version number.
If the enum named Mapper has two variants, then you may be looking for the following code. pub enum Mapper { Standard(HashMap&lt;char, char&gt;), Disco } pub fn load_mapper(mapper: Mapper)-&gt; Result&lt;Mapper, Box&lt;std::error::Error&gt;&gt; { // ... Ok( Mapper::Disco) } Perhaps you could try to explain with more words what you are trying to do. 
That could be interesting but I would not put too much trust into the numbers produced by cargo-geiger just yet. There're quite a few issues that needs to be resolved in the github issue tracker.
&gt; I would be fine not having the * and just having value() and unsafe_value(), but having the convenient * with the unsafe semantics just feels wrong. As I noted previously, welcome to C++, you probably won't like it there. I find it absolutely horrendous as well but there you are, that's the proposal, and that's how previously proposed **and implemented** APIs behave. &gt; It would be nice to be able to write by default just: &gt; if (expected) { &gt; func(*expected); &gt; } &gt; and get the safe behaviour. You do, it's checked then deref'd so it's safe (like any other pointer in a C++ context).
&gt; I don't want to know how to write my code in a 'safe' way (regardless of whether it ended up being the best way to do things), I want to know how to force the borrow checker and why I can't This sounds like you don't understand or appreciate the advantage of Rust in the first place. If you don't care about safety, you shouldn't choose a language which is designed around it.
Since `i32::MIN` is equal to `(i32::MAX * -1) - 1`, what would `i32::MIN.abs()` be?
What are the types of `entites_s`, `pos_s`, and `coll0`? If they only borrow the source data rather than exclusively borrow or own it, getting a `&amp;mut` is definitely nasal demons. What you have to worry about that you may be overlooking is thread safety. Unless you own the data or have an exclusive borrow, you can't safely mutate it without internal mutability because other threads can have references that are assumed to be too immutable data.
Umm; but how do I actually request this assistance for my blog post? Couldn't find any link/form/guide on how to do this... :/ or did I misunderstand the announcement?
I already lock the data, which is why i was so confused as to why I couldn't mutate it regardless
It won't be at launch, for sure.
I prefer changing the the distance to `NonZeroU16` *or* keep an `assert` inside. No need for unsafe then!
The problem isn't `Cargo.lock`s in applications, the problem is libraries with dependencies, e.g. `image-png`, which pick a certain version.
See also https://docs.rs/tokio/0.1.7/tokio/reactor/index.html#lazy-registration
Is there any reason to have a pointer if you don't ultimately intend to dereference it?
With `specs`, it makes a number of assumptions about how you want to manage the data. The best place to figure out how to do this is on a `specs` forum, or at least starting out saying it's `specs`. A very big potential problem with working around `specs` to do mutation is that it needs to guard mutation itself. This is due to how it manages the ECS. A potential solution is for `specs` to allow `Join`ing pointers to give out pointers. That said, I'm sure there's a way to do this safely, and if not, it's a shortcoming of `specs` currently.
Doing a read-only dereference would be fine in that particular case too
Aren't crates like failure ultimately intended to ease the global handling of errors?
There was a safe solution with manually joining stuff with the get() functions!
Adding it to the configuration with cargo new doesn't break existing crates. 
That somehow feels not right.