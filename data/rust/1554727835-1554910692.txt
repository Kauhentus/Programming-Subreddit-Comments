That's much better üëç
This article seems like an exact copy of this one under different author. Is it plagiarism? ‚ÄúIntro to web programming in Rust for NodeJS developers‚Äù by Bastian Gruber https://link.medium.com/uFeK0kXGIV
Pretty sure it‚Äôs not *needed* given I did this announcement without it. ü§°
The point is that other types than tuples can implement the `SplitMut` trait and those types can do interesting things in their `Drop` implementation. The first user of that crate will be a rayon-related crate to help with map-fold-reduce operations on a producer-mode parallel iterator.
https://fr.wiktionary.org/wiki/moite-moite
https://fr.wiktionary.org/wiki/moite-moite
Have you tried [rewriting](https://github.com/ansuz/RIIR) that No Recoil Script in Rust?
Good work! I recommend against storing credentials secrets in a file, as you have in main.rs. Use env variables for bare-minimum secrets management. You'll probably run your web app in a container and could easily pass in secrets to the container with the env vars. Are you familiar with [dotenv crate](https://crates.io/crates/dotenv)? Wherever you're reading a file to a string, here's an alternative convention: https://doc.rust-lang.org/std/fs/fn.read_to_string.html For config files, I use a toml formatted file and deserialize the toml to a type. There's no need to check number of lines in a file as you have if you use toml deserialization because deserialization will raise an exception if required elements are missing. here's what it would look like: use std::fs; use toml; let data = fs::read_to_string(config_path)?; let settings: YourConfigType = toml::from_str(&amp;data)?; 
Damn... what strange idea to add this spelling variant. The one who did it probably didn't know "moite" was a word...
I already mentioned it somewhere else and created an issue: I would remove the teardown method from the Platform trait and instead implement Drop if needed. That way you can expose the Platform object directly to the user to reuse (and skip calling setup() each time) without leaking resources.
/r/playrust
That's why you do it with a unpublished binary... What the frick
Yes, some other Rust projects are already doing it. I'm sorry I don't have examples to point you to; I can't remember which they are.
Looks like it: #[cfg(target_os = "macos")] extern crate mac_notification_sys; #[cfg(target_os = "linux")] extern crate notify_rust; #[cfg(target_os = "windows")] extern crate winrt; &amp;#x200B;
Would you be interested in [collaborating](https://github.com/crate-ci/resources/)? After one of the previous Azure Pipeline blog posts, I started working on templates (and collaborating with those who maintain the Rust Task). I'd say the goals of the `crate-ci` org are (1) centralize and standardize evergreen documentation rather than trying to fight the confusion of inconsistent blog posts and (2) to replace trust with a more maintainable system.
Could you explain this more? I guess the two values are dropped at the same time. How does this help with the parallel iterator?
Author here ‚Äì would love some help figuring this out! I don't have a Windows machine handy so it's hard for me to debug this. It used to work...
what &amp;#x200B;
&gt;Cool crate, but you might want to change the notify method to return a Result&lt;(), SomeErrorType&gt; and don't call unwrap in your code. It is considered bad practice for a library to panic. Author here ‚Äì This sounds good to me! If someone wants to open a pull request for this, I'd be happy to review + merge it!
It gives credit at the bottom, but without a direct link. It's odd. &gt; Originally published by Bastian Gruber at https://dev.to
Ok never mind. 
At this point I am learning azure pipelines and want to create templates for me + share them with the world. I would be happy to do merge it in the future and create a stable, consistent one place for it.
First time I hear this. Where is it used?
 The blog I have sourced in my readme described how to do it ;) so I will implement it for sure.
Usually it's about paying the note at the restaurant, ¬´ on fait moite-moite ? ¬ª.
It is probably better to use a nalgebra matrix or sprs for sparse matrices. I wouldn't recommend using a Vec of a Vec because it will make things quite complicated.
I mean where in the world? I've only ever heard moiti√©-moiti√©. Though if I have to guess... It's a thing in Paris is it?
Moi aussi üòÖ
Rightpondian: bill. Leftpondian: check.
So when a [producer](https://docs.rs/rayon/1.0.3/rayon/iter/plumbing/trait.Producer.html) is split in two in Rayon, there is no mechanism to combine them back into a single value once they have produced all they had to produce, as opposed to [consumers](https://docs.rs/rayon/1.0.3/rayon/iter/plumbing/trait.Consumer.html), which come built-in with a concept of [folding](https://docs.rs/rayon/1.0.3/rayon/iter/plumbing/trait.Folder.html) and [reducing](https://docs.rs/rayon/1.0.3/rayon/iter/plumbing/trait.Reducer.html). I'm currently working on [something](https://github.com/rayon-rs/rayon/pull/652#issuecomment-480496782) to combine a "map-fold-reduce" operation with a [`ParallelIterator::collect`](https://docs.rs/rayon/1.0.3/rayon/iter/trait.ParallelIterator.html#method.collect) call, and producer-based iterators are an issue because the generated producers are independent from each other. To solve that problem, I use moite_moite with the following code: ``` struct Joiner&lt;'t, Target: Default + Sync + 't, Reduce: Fn(&amp;mut Target, Target) + Sync&gt; { left: Option&lt;Sink&lt;'t, Target&gt;&gt;, right: Option&lt;Target&gt;, reduce: Reduce, parent: Option&lt;Part&lt;'t, Target, Reduce&gt;&gt;, } impl&lt;'t, Target, Reduce&gt; moite_moite::SplitMut&lt;Option&lt;Sink&lt;'t, Target&gt;&gt;, Option&lt;Target&gt;&gt; for Joiner&lt;'t, Target, Reduce&gt; where Target: Default + Sync + 't, Reduce: Fn(&amp;mut Target, Target) + Sync, { fn split_mut(&amp;mut self) -&gt; (&amp;mut Option&lt;Sink&lt;'t, Target&gt;&gt;, &amp;mut Option&lt;Target&gt;) { (&amp;mut self.left, &amp;mut self.right) } } impl&lt;'t, Target, Reduce&gt; Drop for Joiner&lt;'t, Target, Reduce&gt; where Target: Default + Sync + 't, Reduce: Fn(&amp;mut Target, Target) + Sync, { fn drop(&amp;mut self) { let left = self.left.as_mut().expect("left was not committed"); let right = self.right.take().expect("right was not committed"); (self.reduce)(left.as_mut(), right); if let Some(ref mut parent) = self.parent { parent.commit(left); } else if let Sink::Owned(_) = *left { panic!("left is owned and joiner has no parent"); } } } enum Part&lt;'t, Target: Default + Sync + 't, Reduce: Fn(&amp;mut Target, Target) + Sync&gt; { Left(moite_moite::sync::Part&lt;Option&lt;Sink&lt;'t, Target&gt;&gt;, Joiner&lt;'t, Target, Reduce&gt;&gt;), Right(moite_moite::sync::Part&lt;Option&lt;Target&gt;, Joiner&lt;'t, Target, Reduce&gt;&gt;), } impl&lt;'t, Target, Reduce&gt; Part&lt;'t, Target, Reduce&gt; where Target: Default + Sync + 't, Reduce: Fn(&amp;mut Target, Target) + Sync, { fn commit(&amp;mut self, sink: &amp;mut Sink&lt;'t, Target&gt;) { match *self { Part::Left(ref mut left) =&gt; { assert!(left.is_none(), "left was already committed"); **left = Some(mem::replace(sink, Sink::Owned(Target::default()))); } Part::Right(ref mut right) =&gt; { assert!(right.is_none(), "right was already committed"); **right = Some(match *sink { Sink::Borrowed(_) =&gt; panic!("right is borrowed"), Sink::Owned(ref mut owned) =&gt; mem::replace(owned, Target::default()), }); } } } } enum Sink&lt;'t, T&gt; { Borrowed(&amp;'t mut T), Owned(T), } impl&lt;'t, T&gt; AsMut&lt;T&gt; for Sink&lt;'t, T&gt; { fn as_mut(&amp;mut self) -&gt; &amp;mut T { match *self { Sink::Borrowed(ref mut borrowed) =&gt; borrowed, Sink::Owned(ref mut owned) =&gt; owned, } } } ``` Sorry for the wall of code, I'm planning to release [`rayon_croissant`](https://twitter.com/nokusu/status/1114938828131848198) soon and that should make `moite_moite`'s raison d'√™tre more obvious.
I wrote a less sarcastic answer [here](https://www.reddit.com/r/rust/comments/basiju/announcing_moite_moite/ekdx154/).
Have a look at https://www.rust-lang.org
Thanks, when I wrote "note" I actually thought "wait, that doesn't sound correct", but then I got lazy and just rolled with it.
That's great feedback, thank you! &amp;#x200B; Yes, of course you're right, in a production setting one would use a secret-store such as Vault for credentials etc., but for these blog-post-size examples files and env variables are just more convenient ;). &amp;#x200B; Plus I wanted to explore how one would load a config file as well. Thanks for the toml snippet, that looks very simple to use!
I've found high tail latency when benchmarking hyper v0.10, fwiw. 
I'm currently on vacation but I might have a look at it next week. You can also ping me, if I forget it ;)
Really nicely laid out tutorial, and I like your attitude towards dealing with any upcoming migrations. One small tweak I‚Äôd suggest is to use [`Result::expect`](https://doc.rust-lang.org/std/result/enum.Result.html#method.expect) instead of pattern matching in the declaration of `config` and `jwt`, like so: let config = Config::init().expect("Could not read config from environment"); let jwt = external::get_jwt(&amp;api_key, &amp;api_secret).expect("Could not get the JWT"); The error will automatically be added to the message.
I will explain Box to you. So there are two types of memory in a program. One is called Stack, the other one is called Heap. When the operation system (OS) runs a program, it creates a Process. A when a Process is created the OS loads the code into memory but also loads a sort a table with lots if information. Among this information is the memory a program is using. This is important in order to prevent one program from reading/writing in the memory of a another program. This memory information is divided in two types: \- Stack: The OS reserves a piece of continuous memory for the process. Like an array of bytes. The size of this memory will vary from OS to OS. But usually it can fit quite a bit of information. Usually its a Megabyte or more in size. Also Stack is often fixes sized. If your program uses more memory in the Stack then the amount the OS created, the program will panic (the program will stop working). When that happens that is called Stack Overflow! Hence the name of the famous programming question site! \- Heap: The OS does not reserve Heap memory like it does with Stack. Heap can grow on demand. So if a program requires more memory to put more data, the OS will acquire that memory and assign it the the process. Acquiring memory for a process is called Memory Allocation. &amp;#x200B; The main reason for this separation of memory into two categories is performance. Allocating Memory is quite expensive (it takes a relatively long time for a computer). Since the Stack is already there, adding or removing data from it is very fast. For adding data, all it requires is for the data to be copied into the Stack. For removing data, the OS simply marks the data as unused, there is no need to actually remove the data. The Heap however requires reserving the memory when needed (allocating) and freeing the memory when its no longer needed (deallocating). &amp;#x200B; Finally we can now learn what a Box is! Rust prefers to use the Stack since its faster then the Heap. However since the Stack is of limited size, sometimes you just have to use the Heap. In order to tell Rust to allocate memory in the Heap you add a Box&lt;&gt; around the data type. So Box&lt;i32&gt; creates a i32 on the Heap instead of the Stack. Notice when you create a piece of data on the Heap, the address of the data is random (the OS reserves whatever memory is available at the time). So the program need some way to know where that data resides in memory. All that is needed is a single integer number. This number is the address telling the program where in memory the data resides at. This is what a Pointer is! Just a regular old integer number that tells the program where in memory the data can be found. So Box&lt;i32&gt; is doing two things. It allocates 32 bits on the Heap that can hold a signed 32 bit integer. It also creates a pointer with the address of the Heap object. The while the object it self will live on the Heap, the Pointer that is pointing to it will live on the Stack. The size of the pointer depends on the hardware architecture. On 32 bits platforms a pointer has 32 bits, and on 64 bits platforms a pointer will have 64 bits. &amp;#x200B; This is just a high level overview of course. But I hope this was helpful to you.
`&amp;` is a type constructor (in the language of type names), so `&amp;T` is a new, different type, much like how `[T]` is a different type and `Option&lt;T&gt;` is a different type, etc. etc. The magic part is that the compiler allows trait methods to take types derived from `Self`, such as `&amp;Self`. So if `T: Trait`, you can call `Trait::trait_method` on a value that has the type `&amp;T`. If the same trait is implemented by both `T` and `&amp;T` (somewhat unusual, but it happens) then you may need to be careful which one is called. For example `let b: T = a.clone();` or `(*a).clone()` to clone `T` instead of `&amp;T`.
`Part&lt;T, W&gt;` is also itself splittable.
I often found that Rust code without `@` read better. In this particular case, the author could have written: match self.poll_inner() { Ok(Async::Ready(None)) =&gt; { ... } Ok(v) =&gt; { ... } Err(v) =&gt; { ... } } No need for `@`.
There are 4 calls to unwrap (not counting unwrap_or*), I'll check to replace them with proper error handling (or defaulting)
But that doesn't work with Diesel, because they haven't updated their macro code to be properly scoped. 
&gt; I'm planning to release rayon_croissant soon and that should make moite_moite's raison d'√™tre more obvious. Fran√ßais overload!
I don't find this very useful, how one could use this trait to implement [https://doc.rust-lang.org/std/primitive.slice.html#method.split\_at\_mut](https://doc.rust-lang.org/std/primitive.slice.html#method.split_at_mut) ?
Still working my way through the book. Loving it so far. Most recent project was a simple temperature converter for different scales.
\`&lt;\[\_\]&gt;::split\_at\_mut\` returns mutable references, this crate is about being able to \*own\* a part of a value.
You don't even have to be that good to inspire/help people, speaking from experience. When I was learning JS I uploaded the solutions to all of the FreeCodeCamp exercises I solved, along with my thought process. I got loads of people thanking me within only a few days of launching the website, even though I still thought of myself as a newbie that didn't know anything. They didn't necessarily thank me because my solutions were that good (they weren't), but since I explained my thought process it helped a lot of people understand **how** the solution worked and why I wrote it like that. Anyway, just wanted to say that you shouldn't hesitate to share your knowledge, even if you're new to the language or programming in general. It's helpful for both the reader and you. 
&gt;The magic part is that the compiler allows trait methods to take types derived from `Self`, such as `&amp;Self`. So if `T: Trait`, you can call `Trait::trait_method` on a value that has the type `&amp;T`. It's important to note that this behavior is specific to the dot operator, and that this won't happen when you use the [Fully Qualified Syntax](https://doc.rust-lang.org/stable/book/ch19-03-advanced-traits.html#fully-qualified-syntax-for-disambiguation-calling-methods-with-the-same-name).
There's a bit twiddle to do it: x &amp; -x. It probably doesn't get any faster than that
Just from a glance at Gothams docs/examples it looks to be a lot more involved than the simple attribute style of Rocket.
Do you mean by doing like: ``` let lowest = x &amp; (1 &lt;&lt; x.trailing_zeros()) ``` I posted this elsewhere but I think you can also do: ``` let x = x as i64; let lowest = x &amp; -x; ```
Yes, in my head that was clear from the "could" in my comment, but I now realise that it totally wasn't, sorry!
I'm familiar with the Stack and Heap but thank you for the further explanation! That really helped clarify Box&lt;&gt;.
I just had a look and I really like the idea of `sessions`! I'm just wondering if the method call to `should` could be hidden from the user. It feels a bit verbose to make that call before an assertion. Something like `should_eq` and similar variants would cut down the amount of typing needed.
This is awesome, can't wait to use this for https://github.com/chmln/sd. Thank you for your efforts
&gt; this behavior Specifically, auto-ref and auto-deref are specific to the dot-call syntax. [Calling a trait method without full qualification causes the compiler to select a specific, overloaded implementation.](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=4cc799d3c248ce24ec81f2a49a097f05)
`hyper 0.10` was the old, synchronous implementation. The results from one don't apply to the other. /u/ahayd, see https://www.techempower.com/benchmarks/#section=data-r15&amp;hw=ph&amp;test=plaintext, where `hyper` has a good latency result. However, looking at https://github.com/TechEmpower/FrameworkBenchmarks/tree/master/frameworks/Rust/hyper, it's using the old `tokio-core` executor, because it's faster on simple workloads than the one in `tokio.
Thanks for the additional information. It will be helpfu when I dive into the crate in more detail. If you're interested, there are at least two Rust implementations ([radix-router](https://github.com/SunDoge/radix-router) and [radix-trie](https://github.com/michaelsproul/rust_radix_trie)) of the routing approach used in the performant Go router, [HttpRouter](https://github.com/julienschmidt/httprouter). Maybe there's something in those existing crates you can leverage in [Usher](https://github.com/whitfin/usher). 
Perhaps you misread epic_pork's comment as "..., seems **n**o".
Awesome! Thanks for the links. What I have now is a pretty standard representation - I wanted to work mainly on the API before optimizing the internals. It's pretty reasonable for most cases, but yeah I'm almost certain that there's a better algorithm floating around.
Ahh, I blame mosquitos for my sleep deprived comment reading abilities.
I can confirm it is used in the south-east part (well Nice) at least.
I'm porting a mid-sized suite of internal tools (~15K LOC) from C. &amp;nbsp; We use these tools to do massive amounts of data importation from various sources to our fork of Redis to serve real-time analytic queries. &amp;nbsp; Over the weekend I managed to get the first "real" data importing and the Rust tools are actually faster than C, which is just awesome. The more I work with Rust, the more I like it. I haven't felt this excited about a new language since I learned C in middle school!
Writing assertions fluently is cancer and should be left for web boys
Et qu'en est-il des coins o√π on parle le vrai fran√ßais? Et par √ßa je veux dire o√π on sait c'est quoi une chocolatine.
I'm sorry for being so negative, but test suites like this rub me the wrong way. This test suite introduces at least 3 things that I really dislike about testing suites, and I don't understand why do people like them. Crappy DSL: ``` number_of_faces(name).should().be_equal_to(nbr_faces); ``` Bleh. In almost every codebase I have to work with professionally, someone always have introduce another lame testing framework with its own DSL for something as basic as assertion. Each language, each test framework like this I now how to guess/look-up the crappy DSL of the day. `should.be.equal`? `should_be_equal`? `should().be_equal_to()`? Gosh. We already have `assert_eq!(number_of_faces(name), nbr_faces)` in Rust, and they are working great, and are shorter and easier to read. The "theories" can be done with a loop. Benefits: everybody understand the loop, rusftmt will autoformat it for you, etc. "Sessions" is also something that I would advise avoiding. Test should be a standalone as possible. If you needs some setup in your test, just: ``` fn sometest() { let setup = create_common_setup(); } ``` The level of indentation is smaller, no new macros, no new dependencies, less boilerplate.
&gt; Edit: I have never used winrt, but is it really necessary to put everything in the notify function for windows in an unsafe block? The unsafe scopes should be as small as possible. I do think it's a good idea to have relatively small `unsafe` scope, to really highlight where the unsafety is coming from. At the same time, it's notable that in general, the fact that certain invariants are "tainted" by an `unsafe` access mean that any that touches these invariants must take extra care to maintain them and is transitively "unsafe" even if not marked as such.
Looks good. I liked nunit's "assume" that said check a fact holds before running the test, and if it doesn't hold then mark this as a skipped/ignored test.
Une quoi?
I've heard it in Normandy as well.
The advise on how to do this seems good here. But I would strongly suggest that after determining feasibility you ask yourself if this is a good idea. Ask yourself some questions: &amp;#x200B; 1) How many people will this decision impact? 2) Will other developers be able to work well in a C++/Rust codebase? 3) How long will the code remain mixed? Is this an eventual migration to pure Rust? 4) Why do you want to do this? 5) Because you like Rust, or because it offers specific improvements over C++? 6) Is there enough benefit to the project to justify the added complexity and disruption? This needs to tangible, something other than the theoretical benefits. You would do well to rewrite a module with known difficult issues to show some real world benefit.
I think your tone is too harsh but I agree with the sentiment. It's not clear to me what benefit I get from things like \`foo.should()\`. What I \_do\_ like is the colorized output and the additional assertions. I think Rust's std assertions are a bit too limited. Asserting that a container contains something or that a list is empty are useful assertions to have, but is there any reason this can't be done in a less "cute" way? Something like this: &amp;#x200B; \`\`\`rust assert\_contains!(list, value); assert\_ok!(returns\_result()); \`\`\` &amp;#x200B; This also has the virtue of not appearing to add funcs to existing std types like strings and iterators. &amp;#x200B; IMO the best way to do all this is to split this stuff up into several libraries. The core without the DSL-ish bit (additional assertions, output formatting) could go in one crate and the DSL part could go in another.
Super cool, thanks for sharing!
Regarding "theories", it is possible to have multiple failed cases, but a loop would only display the first one.
Yes, sorry. My `glib` memory has apparently been Rust-ed away a bit ;) .
This is great, we'd love to have you over at http://rust-audio.discourse.group/!
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/linuxaudio] [lv2rs: Creating LV2 plugins in Rust](https://www.reddit.com/r/linuxaudio/comments/bawqdt/lv2rs_creating_lv2_plugins_in_rust/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
There are really two separate concerns here: assertion libraries and test runners, which are separate concerns. While I agree with some of your points, both solutions exist for a reason. ## Test Runners The main value added by test runners is test *organization*, with things like tags, grouping, nesting and easier shared setup/teardown (which I'm not a fan of). This allows better, more structured reporting, selective running of tests, which is only possible today with a very disciplined naming scheme for your tests , and less boilerplate for test setup. These things are usually not that big of a concern in library code, where test organization is easier, but IMO add a lot of value in complex applications with a myriad of tests and many people working on the code since it also provides a organization for developers, that otherwise takes more discipline/reviewing time. Test reporting can be horrible with your suggested `for` loop solution, requiring more boilerplate for good errors, which usually never happens until the tests fail and you need to add it for debugging. ## Assertion Libraries These are the bigger culprit IMO, I agree with them often being idiosyncratic and unintuitive ( `it ('makes no sense')` ). HOWEVER, again, the main benefit here is often much better error reporting. Achieving equally good errors with just `assert!/assert_eq!` requires a lot more attention and thought when writing the tests, which again, usually developers don't invest in when writing the tests (as long as everything passes). `assert(_eq)!` errors can be much quicker to write, but can produce cryptic and meaningless errors that require you to dive into a debugger or add logging statements to get an idea what's going on. Assertion libraries can reducing the effort for more fine grained tests and reporting a lot. Much more so in large codebases that you don't know well. (Again my point above regarding large apps). So while some of the negativity is merrited, there are reasons why these frameworks are so prevalent and there are very valid use cases for them.
You probably want to be using reqwest's [async API](https://github.com/seanmonstar/reqwest/blob/master/examples/async.rs) so your handlers aren't blocking.
You can still have better assertion messages without should()-type calls using something like an assert_contains! macro.
Yeah, I also don‚Äôt understand the benefits of fluent assertions. The strategy I use is ‚Äúprogressive enhancement‚Äù of tests: I start with the simplest possible assertion and emake it better each time I have to touch the test. The first step is just plain assert/unwrap: super easy to write, which is important for test. The second step is to add a custom asset message, tailored for this particular case. Usually a fully hand-written message is clearer than any auto-generated ones. The third step is to move from test code to test data and introduce something like snapshot testing, where both inputs and outputs are just data structures.
&gt; "Sessions" is also something that I would advise avoiding. Test should be a standalone as possible. If you needs some setup in your test, just: I agree about not coupling tests together due to similar setup/teardown. My favorite model for this is pytest which instead you create and use test fixtures. In this model, you have - an API for setup/tear down - An adapter for functions to be setup and generators to be setup/teardown - You accept fixtures in your tests parameter lists. This makes your setup/teardown a lot more fluid because you make reusable pieces and then mix and match them rather than writing a lot of "session"s or having a single god-"session".
The other benefit to parameterized tests is showing the `Debug` output for the cases that failed without having to do extra manual work on your part.
I'm curious if there is any room for collaboration on our very different approaches. - [predicates](https://github.com/assert-rs/predicates-rs) which still needs a hamcrest-like wrapper - [assert_cmd](https://github.com/assert-rs/assert_cmd/) which includes `std::process::Command` fixtures as well as making it easy to invoke `predicates. - [assert_cmd](https://github.com/assert-rs/assert_fs/) which includes filesystem fixtures as well as making it easy to invoke `predicates.
still don't see the point of the trait so
You created PIN!? I used it (as an intern at Intel) and it was amazing! Can I talk to you about the job?
\&gt; it is fully usable \&gt; It is still in an unstable state hmm
I think it's 0.12.25 that's used by deno
Despite the agreeing with you, your tone is really off putting.
Very interesting, could be to do with this. Not sure if that's what this patch is working around [https://github.com/denoland/deno/pull/2071](https://github.com/denoland/deno/pull/2071)
Hi Yes, it seems to be what I want but looks more complex than Rocket or the code I did in Go. However, I will try to adapt it to my test. Thank you! J
I wonder if you should pull the 1.0.0 release and call it 0.1.0 ?
Can I have a feature in my Cargo.toml that is dependent on another crate's feature?
Are there security implications to reading files into memory? For example, if I create a program that allows a user config file, could a user create a file that is malicious in some way that would cause my Rust program to do something it wasn't supposed to?
Hi, Yes Zalando did look at this :) thanks for the findings!
Also https://github.com/denoland/deno/commit/8269ca82b8b3db9b04da3e31247b7c87a00e7f7a. Yeah, I'm not sure what's happening there, but it seems to change the scheduling, undoing an optimization for that plaintext benchmark. It's easy to regress on one benchmark when trying to improve another.
[Alternative registries are coming](https://github.com/rust-lang/cargo/pull/6654/)!
&gt; The next big features will be the UI, Patch and State specifications. Hi! I'm in the middle of doing UI-related work for [`rust-vst`](https://github.com/rust-dsp/rust-vst). So far I have windows spawning for Linux and Windows that have OpenGL contexts, and they seem to be working in Bitwig while being able to respond to events (like mouse clicks) and change audio parameters -- although I didn't do any actual GL drawing yet. I want to get Mac working as well, and then wrap it all up into a nice cross-platform crate. I don't know if the GUI-related requirements in LV2 are as much of a pain as they are in VST2, but maybe we can help each other out. Let's discuss it somewhere. :)
`convert::Infallible` link is non-accessable.
Sure: [dependencies] foo = "*" [features] my_feature = "foo/some_feature"
Moite is indeed a word, as in ¬´avoir les mains moites¬ª ;).
¬´Moit-moit¬ª (or ¬´moite-moite¬ª as you wish) is a slang way to say ¬´moiti√©-moiti√©¬ª.
¬´moite-moite¬ª is slang for ¬´moiti√©-moiti√©¬ª, meaning 50-50.
Good news, the trait is gone, and `split` is now `split_with` and takes a closure.
I released 0.2.0, the trait is gone and I added a proper [example](https://docs.rs/moite_moite/0.2.0/moite_moite/sync/fn.split_with.html#example).
I don't have the right experience to be able to do this job, but I am so happy to see a Rust job that is something other than a cryptocurrency. Not only is it not that, this project actually sounds really cool. Best of luck to you!
They point to the stable docs, but this is not stable yet. This is normal.
You might consider replacing your bit-shifting implementations with ones that calls [u32::from_be_bytes](https://doc.rust-lang.org/std/primitive.u32.html#method.from_be_bytes) and [u32::to_be_bytes](https://doc.rust-lang.org/std/primitive.u32.html#method.to_be_bytes); those seem more likely to be optimized away. That said, the only real advice is to check the LLVM IR or ASM of a release build.
Can you expand on why you don't like shared setup / teardown code?
This is true, but 1400ms / 2000ms for max latency seems bizarre. I feel like it's something else.
Can you explain why I should so that?
This may be poking a beast, I don't really know, but I've been curious for a while now. I've noticed that Rocket requires the nightly Rust build, rather than stable. A year ago when I was playing with Rocket, this was also true. Are there plans to either A.) Modify Rocket to get onto a stable build (this thread may not answer this), or B.) Get whatever features from nightly that Rocket is using into the stable build? Again I apologize if this question is stupid or poorly thought out, it's just always seemed strange.
oh, if you are going to change the API (as this would)? I guess maybe you don't have to if the was no return type before? Not sure and up to you!
Did you misread ‚Äúunstable‚Äù as ‚Äúunusable‚Äù ?
Ah, yes I did. Derp. Thanks for pointing that out.
Great, I look forward to it. I don't have any idea how to use it - at least, this is one feature of Rust I've never played with yet. Much appreciated!
I don't agree with you about `assert_ok`, etc. You can already do assert!(returns_result().is_ok()); which also reads better.
He could change the API and go to a 2.0. no one dictates how quickly major version bumps should happen
Are there tools for hosting your own registry yet?
I don't the means right now to test your example, but are you referring to [loop hoisting](https://en.wikipedia.org/wiki/Loop-invariant_code_motion)?
This post was immensely helpful. Thank you very much! I've added proper error handling and referred all responses to a Responder.
Are you simply benchmarking the time it takes for the factorial? Are you load testing a release build or debug build?
Sure... not dictating anything.
I've spent my weekend building an API with rocket-rs and I'm curious: How do rocket-rs and actix-web compare when it comes to implementing RESFUL APIs?
Thanks! I thought there was something similar to what I was describing but I couldn't remember the name. This is what I would hope the compiler would be doing, but also across the example function call boundaries, so I guess some further investigation of the compiler output is in order.
Good point. I also fail to see how this is a meaningful test of performance. Given a large enough input, your program will spend the majority of its time computing factorials. I don't see how this would be relevant to any real-life scenario. Wouldn't it be more sensible to see how many API calls (including access to a database) you could handle?
Thanks for the advice, I'll check those out. I agree, once I get some time I'll try to write a small example to check the release build output.
I avoid `assert!(returns_result().is_ok())` because when it fails, the error message doesn't tell you what the `Error` was. (Just calling `unwrap()` and ignoring the return value is better in this regard.) I write a lot of C++ code with googletest. I strongly prefer stuff that uses matchers: EXPECT_THAT(some_vector, ElementsAre("foo", "bar")); over stuff that doesn't: ASSERT_EQ(2, some_vector.size()); EXPECT_EQ("foo", some_vector[0]); EXPECT_EQ("bar", some_vector[1]); because of the quality of the error messages. (As a bonus, the stuff using matchers is also often shorter.) The stuff builtin to the Rust standard library (`#[test]`, `assert!`, `assert_eq!`) isn't as good in this regard. It doesn't have an equivalent to matchers or expect. (For those who don't know, "expect" will record a failure but proceed on with the rest of the test, so you can see what else broke in one run. I tend to use it except when the following lines of the test would behave badly when the assertion is false. The `ASSERT_EQ` in my C++ code above is such a case; an empty vector would cause the following asserts to have memory errors.) Some sort of extensible thing like this sounds interesting to me, though I agree it can get into the weird DSL territory. I haven't tried fluid yet so I don't have a well-formed opinion on its specific API choices.
This is huge. It can make quite a difference in a company environment.
Here's a tracking issue with the blockers: https://github.com/SergioBenitez/Rocket/issues/19 Mainly advanced proc-macro features that are still up in the air, and the never-type (`!`) for generic results which are never `Err`.
Didn't consider that! Definitely an important aspect.
It also works on [beta docs](https://doc.rust-lang.org/beta/std/convert/enum.Infallible.html), which will become the linked item on release.
spott√© le Qu√©b√©cois
I'm one of the Alacritty maintainers and Version 0.3.0 has just been released, since this is a slightly bigger release I've decided to write up what has changed for people who haven't been following the project. If you have any questions, please let me know. I'm happy to answer all of them. The source of the project can be found here: https://github.com/jwilm/alacritty
Well, because you have implementented `from &lt;ARGBColour&gt; for u32`, you can declare the colour argument to the function as `impl Into&lt;u32&gt;`, and you can then pass either an ARGBColour *or* an u32 to it. Or anything else that can be converted to an `u32`. Only the first function in the callgraph would do the conversion, it would then be passed as an `u32` to the other ones, while those also still take an ARGBColour. Something like: fn set_pixel(col: impl Into&lt;u32&gt;, x: usize, y: usize) { let color = col.into(); fill_rect(color); ... } fn fill_rect(col: impl Into&lt;u32&gt;, ....) { let color = col.into(); .... } You probably need to implement `From &lt;&amp;ARGBColour&gt; for u32` as well as `From &lt;ARGBColour&gt; ..`
Changing the return type is a breaking change ‚Äì I was planning to bump to 2.0 if I did that
Just reading a file as bytes into memory *shouldn't* introduce vulnerabilities (excluding buggy filesystem implementations or I/O drivers, or antimalware programs that execute arbitrary data-that-looks-like-code to see what it does), it depends entirely on what you do with that data once it's in memory. If you're using a crate to parse the file then it depends entirely on that crate. Generally if it doesn't use `unsafe` then you can sort-of assume it doesn't contain any really dangerous vulnerabilities, barring any unsound APIs that expose a safe interface without validating input (that's a big unknown though). However, this only concerns untrusted user input, usually for a web server or any other service exposed on the internet where you can have any number of unknown attackers testing your API surface or protocol for vulnerabilities. If you're just running as a local application and you don't require admin privileges to operate (or you're not writing a kernel module/driver) then the onus is on the user to validate the file they use. You should be sure to provide good error messages for malformed config files, of course, but you shouldn't really have to worry about malicious input.
The feature I'm looking forward to the most is atomic types. Still waiting for const generics though...
Woohoo, `TryFrom` is coming at long last! Also I heartily encourage everyone who can to default to using `beta` over `stable`, I've been doing it the last couple months and it is very solid.
I like that solution, thanks. It's nicer than my option of defining `col` directly as `u32` because the semantics aren't hidden so much from the user, so that's a definite advantage.
**LV2**, an acronym for *Linux Audio Developer's Simple Plugin API (*[*LADSPA*](https://en.wikipedia.org/wiki/LADSPA)*) version 2*, is an [open standard](https://en.wikipedia.org/wiki/Open_standard) for [audio plug-ins](https://en.wikipedia.org/wiki/Audio_plug-in) and matching host applications [https://en.wikipedia.org/wiki/LV2](https://en.wikipedia.org/wiki/LV2)
Taking a bit of a break from more serious things to revisit an old video game project idea. Will probably get bored of it soon and return to data mining, but it's making me sand some of the rough edges off ggez, which is nice.
I am \_so very\_ excited for this!
&gt; All text should now properly reflow both when shrinking and growing the terminal so no more content will be lost! The video below that text looks like it may be corrupt? Or maybe there's something wrong w/Chrome's playback for this video. But it looks wrong. Actually now that I scroll further, there's several videos with the same kind of artifacts.
Make sure you do all the right things like --release. That being said, I found rocket very difficult to benchmark because it does weird things with keepalive and/or ephemeral ports. I never looked much into it but I think its something from hyper which rocket is built upon. I think gotham is on top of hyper too. It might go deeper than that. You can observe this when you watch top during a 60 second benchmark. The cpu will plummet and then slowly recover before the end of the test. This doesn't happen with node and go, for example. I don't have anything else that runs one connection per thread like rocket so I can't compare it to that. If you are testing on OSX you can improve this by monkeying with ephermeral ports and TIME_WAIT [benchmarkers-beware-the-ephemeral-port-limit](http://danielmendel.github.io/blog/2013/04/07/benchmarkers-beware-the-ephemeral-port-limit/)
Could you share an image maybe? They should be standard webms converted with ffmpeg and it was working for the small circle of people I shared it with. Though it's possible they were all using Firefox.
did you compile with `cargo build --release` ? or `cargo build` ?
I switched to actix-web because it handles concurrency better (async under the hood), but Rocket is definitely easier to work with. I think actix-web also works with stable, while Rocket still requires nightly, but it's been a few months since I messed with either.
Not OP, but looks like this to me in Firefox 66.0.2: [image](https://i.imgur.com/yDyeR11.png) I think it's just squashed, looks fine when I right-click &gt; View Video. Although FF renders the "Real Underline Support" as a grey square and seems to think it's audio...
I've switched all videos to gifs. So they should be a little more compressed and bigger now, but hopefully everything works.
Example in release notes is nameist against lobsters. Revision is literally unusable. Looks like a lot of cool stuff, though!
&gt; reading files into memory Out of curiosity, how else did you imagine reading a file? If you have this concern, why not be more concerned with reading from tcp sockets and the like? I think there may be an opportunity here to improve a much more fundamental [mis?]understanding of systems programming if you can provide more details on your concern.
Are you building with the release flag?
I know that's the only way to read a file. I just said "into memory" because "reading into memory" is a common phrase. Getting user input from the internet is also a concern which is why people escape HTML and validate inputs with websites.
Hey, that's some nice work there! Actually, I had started a similar project quite a bit ago ([repo is here](https://gitlab.com/prokopyl/lv2-rs)), but I had to put it away for a bit due to of a lack of time. I was less advanced in terms of implementation than you (I also took the LV2 book as a guideline, and was working on getting the first MIDI example working), and there is literally zero documentation on my project. However, I did manage to get completely rid of `unsafe` in the public API (which doesn't seem to be your case yet?), and I also made bindings to the `lilv` library to load LV2 plugins as an host, enabling me to make end-to-end tests (where the tests actually load the dynamic library from disk like a real host does). The project is a bit messy, but you can find an example of the public API [in the simple amplifier implementation](https://gitlab.com/prokopyl/lv2-rs/blob/master/lv2-plugin/examples/lv2-amp/src/lib.rs), and [its corresponding end-to-end test](https://gitlab.com/prokopyl/lv2-rs/blob/master/lv2-plugin/tests/test.rs). Perhaps we could join forces to make a great Rust LV2 framework? :)
The concern I had regarding systems programming was that, while I know you can do things like SQL injections from the client side of a website, I'm not sure if you can do that with Rust or any binary program. Is there a way for me to say, instead of having \`config.yaml\`'s contents me a string of UTF-8 characters, be a binary that would interact with the Rust program's binary to interrupt what it should normally do and do something else instead?
Does this mean namespaces would be possible?
x if x &gt; 1 &amp;&amp; x &lt; 3 =&gt; ... Doesn't seem much, and you can make a helper function to make it x if x.between(1, 3) =&gt; ... trait Between: Ord { ... }
For what it's worth, `Infallible` will land on stable on Thursday. It's (essentially) the same thing as the `!`.
Other folks are suggesting CString/CStr... these have the downside that they require null termination, as has been pointed out. If you have access to C++17, though, you can take the char\* and length and use them to create a \`string\_view\`, which is analogous to Rust's string slice type and operates on non-owned memory. That way you can avoid either the copy into a null-terminated string or the copy into a \`std::string\` -- at least some of the standard library now supports \`string\_view\` on the C++ side. &amp;#x200B; \`std::span\` is coming as well, analogous to slices on arrays of arbitrary types, but not until C++20.
Rocket is using a very old version of hyper, with no async IO support.
In addition to the options presented so far of either hand-writing a C-flavored wrapper or using \`bindgen\`, you should also check out the [rust-cpp](https://github.com/mystor/rust-cpp) crate, which can reduce the amount of interop boilerplate needed in at least some circumstances.
Its not really rust- specific, but if you deal with untrusted input, you must be defensive. A file can: - not exist - be very large - be infinite (ln -s /dev/urandom myconfig) - block the program (/dev/random) - be a link to something your program should not expose On its own reading a file is not a problem, not accounting for those cases might become one.
I dont think gotham is as ready as other frameworks like actix and rocket
Well I don't mean that. I mean a hack. For example, if a program reads an input file, then could I look for what tells Rust "here is the end of the file contents", then put that at the beginning of a binary i named \`config.yaml\`, then have the rest of the binary be code that executes with the same permissions the Rust binary reading the config file has?
&gt;Stabilized APIs &gt; &gt;\- `convert::TryFrom` &gt; &gt;\- `convert::TryInto` üéâHooray!üôå
use \`--release\` flag when building. use actix-web, not to say a bad thing about rocket, but it's a bit out of ordinary web framework in general. And by the way what Go web framework you're using to compare results? If that's something like fasthttp, you might as well compare directly to hyper. That is http crate the web frameworks use.
Nice. Great work with Alacritty. I have been using it for a bit now and loving it.
Super! thanks
I've been watching this project since it was announced. First couple times I tried running it, it seemed promising, but a bit rough and left it until things were further along. Last week, happened to try again (from master) and was very impressed. Have switched over since then and am very pleased with it.
The Windows MSI installer seems to be doing nothing when I try to run it.
As a frame of reference, unless you are testing millions of requests a second on a single core, 200ms would be very, very slow for a well-designed http server in rust.
I'm thinking about creating a Pulp plugin for it. It depends on what kind of interest there is, I guess. Does anyone need a heavyweight application for this that lets you combine registries together, keep a version history, roll back the version at any time, have a dev/staging/testing registry and so forth? My guess is that these things are less useful for Rust than they are for, say, RPM, Debian, and Python (because of the lack of version locks), but if people want it, I'd consider it.
I've made sure to test it before announcing 0.3.0 and it worked great for me. Are you on Windows 10? That's where I usually do all my testing. Make sure you're not missing something lighting up in the taskbar either, that's where I found it. Also note that Alacritty is not signed, so if you have some policy that blocks all unsigned Applications that will likely cause troubles.
This has nothing to do with async. My best guess is that keepalive is being returned in the headers(I confirmed this) but the connection is still being closed (which explains the exhaustion of ephemeral ports), I didn't confirm this part because my curl skills are weak.
Well that's a more interesting question. The answer is neither yes nor no. There's nothing in the rust language/stdlib which could be confused like that because there's nothing in the rust language which interprets file contents in any way (AFAIK). The interesting questions are, can your OS be tricked (answer: I darn well hope not! But it's out of scope), and can your program be tricked. Rust makes it harder for your program to be tricked by putting very solid barriers between the programmer and silly mistakes like buffer overflows. So the situation is quite good: rust itself is not vulnerable (bugs aside) and helps prevent common vulnerabilities. But rust can't protect you from every programming mistake. If there's a correctness issue in your code then your program could be led to do something you would consider incorrect. Hopefully that's not a surprise. Of particular relevance to your concern would be things like user-controlled output file paths causing your program to overwrite system files. Rust doesn't have anything to do with that and it can't protect you from that; look to defensive programming for prevention and your OS for defense in depth.
&gt; er to provide a set of callback functions instead. With empty callbacks MD4C is certainly the fastest. If you take md2html/render_html.[hc] and md2html/entity.[hc], you have complete HTML renderer on top of MD4C parser.
Very unlikely. Rust will not process data from file in any way (it may check that it is valid utf8 if you use read_to_string method) but beside a bug in stdlib (or operating system) there is nothing user could do to exploit that. What you'll do with the content after reading it is your only concern. And Rust stdlib has a lot better track record than any other so far.
I use Alacritty on my Pop!\_OS Linux box and love it! Beautiful text rendering, reliable cut/paste support (CTRL+\*SHIFT\*+C/V) and \*fast\*! Even the icon is smoking, literally and figuratively. Thank you! Is there a way to control the default initial window size when starting Alacritty? &amp;#x200B; On Mac OS X, I can't figure out how to launch it from the desktop without a Mac Terminal session hanging around for having spawned it. &amp;#x200B; Any pointers to what I may have missed?
TCP is a layer 4 protocol. Linkerd is a TCP proxy because it works with all TCP traffic, but unlike a "plain" L3/L4 proxy, Linkerd understands L5/L7 semantics, e.g. can wrap connections in TLS (layer 5), report success rates from HTTP response codes (layer 7), etc. &amp;#x200B; (As a side note, the 7-layer OSI model has some real problems describing reality, hence tortuous descriptions like this.)
&gt; Is there a way to control the default initial window size when starting Alacritty? There is: https://github.com/jwilm/alacritty/blob/master/alacritty.yml#L15-L22 There are some X11 WMs where this still causes problems, which will hopefully be resolved in 0.3.1, but at least in i3 it already works great so you can definitely give it a shot. &gt; On Mac OS X, I can't figure out how to launch it from the desktop without a Mac Terminal session hanging around for having spawned it. I'm using macos only at work and have a custom WM setup to make it usable for me, so my workflow might not be 'usual'. I think what I did before switching to a custom WM was launching the first instance through launchpad and then opening other instance with a custom keybinding using the `SpawnNewInstance` action. But now I just have `open -na /Applications/Alacritty.app` mapped to a key combination in chunkwm and everything works great.
See my other comment, but something more relevant here: there's no such thing as a "rust binary" (you probably know this but I'm just making sure I cover all the bases since I don't know what you know). There's no component of rust which is interpreting code; there's not even a runtime to speak of. So in a way, this is a question about your OS which *is* the interpreter of your binary, as it were (albeit a very thin interpreter usually). Of course a bug in `std` could cause behavior like this to be compiled into your program, but to achieve this particular misbehavior would require some pretty blatant maliciousness in `std` - most OS would require calls to make the memory executable *after* bring written (i.e., read from file), and then you'd have to jump to the code. Both would require `unsafe`, although the first, as yet another arcane syscall, might well pass an audit. To put this in context of the first paragraph, this is all about "tricking" the OS-as-program-interpreter to do something unintended, although it's not really a trick since the OS would just be doing what you requested.
I assume proper namespaces would also require some cargo support, like a "group" entry in the toml. And make the release process aware of it.
Great, thank you!
**Please** don't do this. There's a reason that every public site (twitter, facebook, etc) on the Internet immediately converts GIF to MP4s (gifv) and then throw the GIFs away. Case in point, the first GIF on the page, converted back to an mp4 is a smaller file size: https://ezgif.com/gif-to-webm/ezgif-4-4efe89cb18f1.gif
First I opened Alacritty from a [Terminal.app](https://Terminal.app) session, and then right clicked on the icon in the Dock: Options &gt; Keep in Dock. &amp;#x200B; I use custom keybinding @UndeadLeech mentioned above to spawn multiple windows at the same time. &amp;#x200B; NOTE: These windows cannot be switched between using Command + \` like native MacOS applications, (but I actually prefer having every window as a separate entry in Command + Tab). I'm probably alone in this preference. There's an open thread in the issues tracking lots of polish issues like this for Alacritty on MacOS.
God I hope someone writes a nice alternative. I about flipped my laptop when I realized Crates.io can't work without JS. Not the search doesn't work. It refuses to load anything. :|
`On Mac OS X, I can't figure out how to launch it from the desktop without a Mac Terminal session hanging around for having spawned it.` Try installing Alacritty through brew (`brew cask install alacritty`).
I was going to say that it's hard to imagine a need for it with vendoring+Cargo.lock, but being able to have a "vetted" repo that is a merge of selections of packages from other sources (crates.io/git/whatever), for some companies might be compelling. I wonder if other folks apply check-in policy based on what appears in the Cargo.lock (I'm guessing there's probably some tooling somewhere at least that does for licensing purposes...)
Yeah, I really, really hate the current design of it. Even with JS, it takes quite a while to actually load the page. Why they made the monstrosity that is crates.io rather than something that serves simple HTML pages from templates is beyond me.
You mean the example for 1.33, the previous release?
This is becoming Rust's "have you tried turning it off and on again?"
I did actually take the liberty of mentioning that on the issue itself already, that was me.
It sounds like you may prefer [crates.rs](https://crates.rs).
Yeah, you need to split the lifetime parameter and the type parameter up, so that the type parameter can be specified inside the closure, with the universal-ised lifetime in scope: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=9c60e9462ddc46a1ea95256cb8260f5 Assuming you're building on sync/send types, any problem with sync/send is almost certainly also going to be a problem with non-concurrent code, meaning implementing them should be fine. (BTW, saying something doesn't work without giving specific error messages, and also the unrelated compilation errors in the code examples (E.g. missing braces and return types), makes collaborating hard.)
I've been having a similar issue across all sites for a few weeks. Are you by any chance using NVIDIA?
I really like and appreciate crates.rs. Do you know why it redirects to crates.io for certain crates?
Rust's API documentation is generally not that great at surfacing _unknown knowns_. So in that sense, you're partially right that API docs in Rust are generally going to be more useful for people who know what to look for. When I first started using Rust, one of the first things I did was manually scan the entire standard library. I didn't study each individual method in detail, but I tried to get my eyes wrapped around the types of APIs provided by std. This helped a lot in order to build a "feeling" for where I might find something when I need it. At a minimum, it's probably good to give a skim of the docs for every module in std. They generally do a good job with giving an overview of what's inside, and generally contain lots of useful nuggets. The unknown unknowns that are hard to see are generally methods provided by types on trait implementations. Rust API docs have actually gotten a lot better about this, but it's a hard problem to solve. Many types have a ton of traits implemented for them, so any individual method provided by a trait tends to get drowned out pretty badly. Consider, for example, the `to_string` method which is automatically available on any type that implements `std::fmt::Display` because of a [blanket impl on `ToString`](https://doc.rust-lang.org/std/string/trait.ToString.html). (Specifically, there is a `impl&lt;T: Display&gt; ToString for T { ... }`, but I can't even link directly to it.) Getting to that page in the first place is not obvious. With that said, if you _already knew_ about `to_string` because you saw it used in some code, then searching for it [will show `ToString` as the first hit](https://doc.rust-lang.org/std/string/trait.ToString.html?search=to_string). (But again, that's a known unknown. For known unknowns, Rust's API search is pretty good.) Once you have a good idea of what's in the standard library, it usually becomes pretty obvious when you need to search crates.io for something. Picking out a particular crate is a completely different can of worms. Depending on your choices available, selecting a crate can be a bit of an art form as it requires balancing your own needs, maturity, maintenance, quality of implementation, tests and more.
The [official Rust book](https://doc.rust-lang.org/book/) is the way to go. It should explain everything you need in a very approachable manner.
Very nice. Gonna replace urxvt now. How dare you release a good terminal for windows.
I haven't encountered that; what crates redirect?
Windows is definitely catching up to Unix with the ConPTY and new terminal emulators that support it. But there's definitely still a lot of improvements that can be made both to Windows and Alacritty which will hopefully make it even better! Glad to hear you enjoy it!
More like, have you tried plugging it into the power plug?
See also: [crates.rs](https://crates.rs).
Hopefully this paves the way for a registry with namespaced crates.
&gt; GIFs aren't good for much and are virtually never ever good for video, not to mention throwing out all accessibility/UX features that browsers give to video giles, etc. I definitely agree! But for now I much prefer working gifs over broken webms. Hopefully I'll find a way to make this work in the future, but it seems like mp4s generated by ffmpeg can't be played in FF and webms apparently have issues in Chrome. I'll probably have to play with codes a bit which I'd assume to be the issue here. But I'll figure something out eventually.
...and then [Learn Rust With Entirely Too Many Linked Lists](https://rust-unofficial.github.io/too-many-lists/) is a good second stop to solidify your grasp on how Rust's ownership rules work in the context of real-world data structures. (And don't worry about jumping from scripting languages to Rust. As someone whose primary language is Python and whose only experience with C and C++ was maybe a semester and a half in University, I can honestly say that lower-level concepts are more bark than bite when you've got Rust's borrow checker preventing misconceptions from making it into compiled code.)
You can share any data type that exists in C including primitives, stucts, unions, pointers, etc. Rust structs need the `#[repr(C)]` attribute to ensure the C and rust compiler use the same memory layout for struct fields. You can't pass references directly, but you can convert the reference to a pointer. Because C string libraries assume strings are null terminated, while Rust strings have a length tag and allow null bytes in the string, you need to convert strings into [CStrings](https://doc.rust-lang.org/std/ffi/struct.CString.html) to be useful in C/C++. C/C++ is not compatible with Rust's reference/drop semantics, so your api will need explicit extern-C creation and deletion functions if you want to allow C code to own rust structures without memory/resource leaks.
I'll be looking into this soon, but as daniels0xff mentioned, the solution is to create an app and authenticate via oauth. You can use openid connect to get permissions.
A quick tip ‚Äì don't declare the argument as `&amp;ARGBColour` (by reference), take `ARGBColour` instead. This will make job easier for LLVM ‚Äì it won't have to strip away all the pointer reads/writes. ([there's even a clippy lint for that](https://rust-lang.github.io/rust-clippy/master/#trivially_copy_pass_by_ref)). I've made a quick test on Godbolt: * [Even with references, the convertion (`bswap`) is performed just once](https://godbolt.org/z/Y428pz) * [A version without references](https://godbolt.org/z/ado4ix) * [Here's a failed attempt to nudge the compiler for vectorization using `assert`](https://godbolt.org/z/BtijrS). Please note that in general, indexing is not idiomatic in Rust. Perhaps using slice iterators would help. I've used "reversed" ordering of ARGB components to avoid the convertion being no-op. Ordering them as `bgra` in the struct (or chaning interpretation) would be slightly better.
I'm using Rust via Vim and Racer. Is there some way to quickly get a look into the types involved in some().long\_chain().of().calls()?
If I'm searching based on some abstract description; Google. If I need to remember specific details of some type, I look it up in the reference. (I.E. all the combinators on option, result and iterator)
Quick question about chaining function calls, let file = File::open("myfile.txt").unwrap(); for line in BufReader::new(file).lines() { // following doesn't work //let mut key_value = line.unwrap().split("\t"); // I have to do something like this let line_result = line.unwrap(); let mut key_value = line_result.split("\t"); Is there a reason why the above line (`line.unwrap().split("\t")`) ```creates a temporary which is freed while still in use```
How does this compare to something like cmder on Windows?
Here's the implementation used inside the chess library I maintain, [pleco](https://github.com/sfleischman105/Pleco/). ``` static DEBRUIJ_T: &amp;'static [u8] = &amp;[ 0, 47, 1, 56, 48, 27, 2, 60, 57, 49, 41, 37, 28, 16, 3, 61, 54, 58, 35, 52, 50, 42, 21, 44, 38, 32, 29, 23, 17, 11, 4, 62, 46, 55, 26, 59, 40, 36, 15, 53, 34, 51, 20, 43, 31, 22, 10, 45, 25, 39, 14, 33, 19, 30, 9, 24, 13, 18, 8, 12, 7, 6, 5, 63 ]; const DEBRUIJ_M: u64 = 0x03f7_9d71_b4cb_0a89; #[inline(always)] pub fn bit_scan_forward(bits: u64) -&gt; u8 { assert_ne!(bits, 0); DEBRUIJ_T[(((bits ^ bits.wrapping_sub(1)).wrapping_mul(DEBRUIJ_M)).wrapping_shr(58)) as usize] } ``` Benchmarks I've show it seems to be faster than the alternative version proposed: ``` #[inline(always)] pub fn bit_scan_forward_rust_trailing(bits: u64) -&gt; u8 { assert_ne!(bits, 0); bits.trailing_zeros() as u8 } ``` [Source for both](https://github.com/sfleischman105/Pleco/blob/master/pleco/src/core/bit_twiddles.rs).
This isn't a very involved example, but it shows how you can modify something held by SimpleWindow. You just have to wrap it in a Rc and Refcell. Then, you clone the Rc outside the closure and move the clone into the closure. @@ -18,0 +19 @@ +use std::rc::Rc; @@ -29,12 +30,14 @@ pub struct SimpleWindow { pushrod: RefCell&lt;Pushrod&gt;, + text: Rc&lt;RefCell&lt;String&gt;&gt;, } impl SimpleWindow { fn new(prod: Pushrod) -&gt; Self { Self { pushrod: RefCell::new(prod), + text: Rc::default(), } } @@ -83,8 +86,11 @@ - button1.on_clicked(Box::new(|| { - self.do_something(); + button1.on_clicked(Box::new({ + let text = Rc::clone(&amp;self.text); + move || { + text.borrow_mut().push_str("Pushed "); + } }));
I've never used cmder so it's hard for me to strike a fitting comparison, but just judging by first impressions it looks like it's not cross-platform. I'd also be really surprised if it's faster than Alacritty. Alacritty does not use ConEmu though but instead is completely standalone talking to Windows' console APIs directly. In general it seems like it's the same type of application though, so don't expect something entirely different. It looks like they're from the same space. However Alacritty works much more than a Unix terminal emulator rather than trying to fit perfectly into the Windows space. So it doesn't come with any special userspace programs like its own shell or a git client (which cmder seems to support optionally at least). Instead you'd install these separately and Alacritty they will integrate with Alacritty through the standard shell and PTY interfaces.
ConEmu (and thus Cmder) is ridiculously slow. Alacritty is much faster, but is super bare-bones.
I'm trying to parse &amp; send SIP messages for VOIP phones. SIP is *really* similar to HTTP: the only difference from HTTP really is that it usually uses UDP, and the first line is `METHOD sip:user@host:port SIP/2.0` instead of `METHOD /path HTTP/1.1` (The version string is *the only thing* that prevents me from using an HTTP library I believe). Currently, `parsip` is the only Rust library I can find that does anything related to it. However, it lacks many features, such as no ability to handle a dynamic number of headers (it requires a pre-allocated buffer of headers, and doesn't support automatically extending a `Vec`), or parsing the body of a request. Ideally, I'd like a library that: * Is a [`tokio_codec`](https://docs.rs/tokio-codec/0.1.1/tokio_codec/index.html), or at least easy to port to one (e.g. a [`nom`](https://crates.io/crates/nom)\-based parser would work) * Splits the top headers from the body, using `Content-length` * Doesn't have to parse headers or anything (although parsing to a [`http::HeaderMap`](https://docs.rs/http/0.1.17/http/header/struct.HeaderMap.html) would be very useful), just splits them by line (although I could deal without splitting even) Right now, [`actix_http::h1::Codec`](https://docs.rs/actix-http/0.1.0-alpha.4/actix_http/h1/struct.Codec.html) looks very promising, as it does all three. However, it would require a fork to handle the version being different (`SIP/2.0` vs `HTTP/1.1`). Are there any alternatives?
Still working on a JS interpreter, https://github.com/jasonwilliams/boa it‚Äôs going ok, I‚Äôm currently improving scope so let/const work, as currently only function scope is supported. I‚Äôm also working on implementing String methods, if anyone is fairly new to rust these aren‚Äôt bad to jump onto https://github.com/jasonwilliams/boa/issues/13
Not just release build, OP could also get a lot more performance with less logging. Are they using a prod Rocket config, or dev. See Rocket.toml and use ROCKET_ENV environment variable.
The exact comment I was hoping to see. I couldn't stick to cmder due to it's slow speeds. Think I'll switch to this!
I‚Äôve had this issue with rocket too. Even on the release build. I did a simple hello world and could only get it to do 1500 req/sec whole node would hit 45k/sec and Actix would top 150k/sec.
&gt; These test frameworks are not solving any real problems Different strokes for different folks.
https://learning-rust.github.io/ will be helpful for you. Good luck!
I've been using alacritty as my primary terminal emulator for a few months now, and I really love it! My only problem has been a questionable upgrade path, since merging my edited config.yaml with the latest config in git almost always results in conflicts.
cmder is nice because it has a kind of franken-shell experience that lets you use readline keybindings/isearch and native windows commands at the same time. Alacritty is faster to start up but it's slower than just opening a powershell window. (And it doesn't really give anything over a Powershell window.)
Temporary values created in a statement only live until the end of that statement, not until the end of the enclosing block. You need to bind a value to a variable to extend its lifetime.
I use the [cookie](https://crates.io/crates/cookie) crate, and I have a struct like this: pub struct MyClient { client: reqwest::Client, jar: CookieJar, // Other fields } Then on particular responses where I want to save cookies (it's manual at the moment, but I suppose you could do it for all responses), I iterate through the cookies and add them to the jar: fn save_cookies_from_response(&amp;mut self, response: &amp;reqwest::Response) { let set_cookie_iter = response.headers().get_all(SET_COOKIE); for c in set_cookie_iter { c.to_str() .into_iter() .map(|s| s.to_string()) .for_each(|cookie_str| { Cookie::parse(cookie_str).into_iter().for_each(|cookie| { self.jar.add_original(cookie); }); }); } } Then I have a method on the client which can convert the cookie jar to a Cookie header, and it attaches that header to all outgoing requests. I'll leave that as an exercise.
Love that you created an account just to add this comment :)
You know what? No. The dadgum thing is plugged in to the power plug. It l's on. It's humming. The fact that this keeps coming up and the new people to our community do not need to fool around with build or run-time settings for the other stacks to get decent default performance strongly indicates a deficiency in the philosophy we hold about our toolchain. And, at this point, I suspect any further effort at user re-education on this matter will merely illustrate the old quote, attributed to Einstein, about the "definition of insanity".
You accidentally wrote a second "assert_cmd" for the link to `assert_fs`.
Thanks!
Ah ok, was going to just do same. Thought there might be a better way, but this works! Thanks. I assume you have to do manual redirect following?
Oh yes, these are all good points that I would certainly have to convince my manager of in order to move forward with this idea. Another developer on the team is up for this goal, I would have to see if everyone else is as well. I'm on the fence over whether we will actually do this or not. I asked this question partially to get a feel for how feasible it would actually be. The project very heavily uses the Eigen linear algebra library, which would probably be the biggest issue with Rust interoperability. The project has some major issues of occasional memory corruption, and in general the team agrees that it needs some serious refactoring to be maintainable in the future (we're talking about classes with thousand line constructors here)
I'm pretty neutral about the terminal I use now, but I've never really been bothered by it's performance... do I not know what I'm missing by not using alacritty?
I think you'll find you're in good company coming to Rust from Python and JS. The imperative programming concepts you're used to will be similar, although with different syntax. I think part of Rust's accessibility is due to its cohesive ecosystem: - High-quality official book (Which Lehona_ linked) - Standardized API docs - Streamlined workflow (Compared to Python's virtualenv, conda vs default, 2 vs 3 etc, and JS's multitude of choices) - Well-designed package manager
I've only worked with an API server that doesn't redirect, but it seems like at least some form of [redirection logic](https://docs.rs/reqwest/0.9.13/reqwest/struct.ClientBuilder.html#method.redirect) is included in reqwest.
By the way, the tracking issue for cookies in reqwest is [here](https://github.com/seanmonstar/reqwest/issues/14)
How do you spawn more than one window? I have tmux already. I also have multiple screens on my Mac. I want to use this but I can't get the app to show and hide consistently enough, and things like command-q don't work. Yes I can tmux detach and control-d, but really? Contributing sounds like a lot of fun, but I would think supporting hiding and quitting on MacOS would exist already if the community wanted it.
Try reading Programming Rust by Jim Blandy and Jason Orendorff in addition to the official book. Since you have background in Python, you will appreciate the comparison of Rust vs Python in some parts of the book.
I'm a beginner too (about 3wks on rust, though highly experienced in general), and I'm finding the From impls to be a really useful path to follow. That and anything for creating an iterator. Once I can either load something from a string/buffer/vector/hashmap/etc, or map/filter my way through it, I can see how I can fit it in with the rest of my code. From that point it's a matter of learning the specific functions the crate provides.
I scrolled too far! Now we're building on an utterly flawed foundation!!
I think what you're trying to do would best be done with `iter_mut` to get write access to the underlying storage, and then `for_each` to perform some task on each element. To be perfectly honest, for_each is strictly less powerful than a standard for loop, since it doesn't allow most of the same control flow.
Very much appreciate your help. The Pushrod class has the ability to lookup widgets based on its widget ID, so I will modify the callback to include it. Once I have that, I can pull the ID by reference, manipulate it, and it will be lost once the callback closure completes. This should solve it, and should ultimately make the library usable!
What you want almost exists. If we have a target that takes a mutable reference to an f64: fn add_into(j: f64, src: &amp;mut f64) { *src += j; } We can use it like so target.iter_mut().enumerate().for_each(|(j, src) add_into(j, src)); But you might as well use a for loop: for (j, src) in target.iter_mut() { add_into(j, src); }
Btw, alacritty has a subreddit- /r/alacritty. I asked there but asking again- Two things I want to know if possible- 1) open a new instance in same dir on Linux. 2) assign shortcut key for scrolling a line up or down. Thanks for your amazing work guys. Whenn I switched from alacritty to termite 3 days back (I think you guys have done something for startup in the last two months), it felt like using a terminal on steroids. Like those old games where difficulty level hard would speed everything up.
FYI here is how I implemented. Not sure if more readable or not, but satisfies my functional bit: ```rust fn store_cookies(&amp;mut self, res: &amp;reqwest::Response) { res.headers() .get_all(HEADER_SET_COOKIE) .into_iter() .map(|header_value| header_value.to_str()) .filter_map(Result::ok) .map(|s| s.to_string()) .for_each(|cookie_string| { if let Ok(cookie) = Cookie::parse(cookie_string) { self.jar.add_original(cookie); } }); } ```
Using Rust 2018, I want to have a macro in library crate, but not in the root of it, but in a nested module. But, if I want to export the macro with `#[macro_export]`, it is placed in crate's root no matter where I place it: // foo_crate/src/lib.rs mod foo_mod { #[macro_export] macro_rules! foo { () =&gt; {} } } // example.rs use foo_crate::foo_mod::foo; // Doesn't work use foo_crate::foo; // Does work Is this how it is supposed to work?
If I run `cargo install --path .` does it build with `cargo build` or `cargo build --release`?
Request::new does not parse an HTTP request out of the argument. You should use a crate like hyper to handle that.
There's no way to do that; macros are always imported from the root of the crate they live in.
I've been using alacritty for months now, it's been my default terminal for osx/linux at work, linux at home, and sometimes windows jus for the gig of it... It's really stable for me, and I get a consistent terminal experience across all OS, and I think other than the keybindings the rest of the configs are mostly cross-OS compatible! It's a little bit slower than iterm2, but I think it may be because i'm using it on 2x4k full screen.
Why is that? Isn't there enough information to provide namespaces for macros? I guess I can kind of work around this by moving macros to a new crate and then reexport them from the module, but then `$crate` would stop working, like in proc macros
Here are a couple examples I put together that fit in more with the style of the existing assertions: &amp;#x200B; https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=d5fb9b4c3f13e506b73f1eebe794eb8a
I feel your pain...I find rustdoc docs to be a bit harder to explore than javadoc and more targeted at the lookup use case than the search use case. Though I will say that I think the book is pretty excellent for people who don‚Äôt yet know what they‚Äôre looking for. But with all that said, there‚Äôs a few tools that I use that I find makes it a bit easier. First, I use a program called [Dash](https://kapeli.com/dash) that allows for searching. It‚Äôs Mac only, but there‚Äôs a Windows/Linux equivalent called [Zeal](https://zealdocs.org). Unfortunately it‚Äôs difficult to get rustdoc for individual crates to work with it, but it‚Äôs still useful for exploring the std crate. Second, `cargo doc --open` is good for pulling up a single browser window that can browse all rustdoc for all the crates used in your project. And since it stores the html in the project‚Äôs target directory, it works offline so it‚Äôs nice if you‚Äôre working on a plane or otherwise don‚Äôt have internet access. And lastly, make sure you‚Äôve got the IDE stuff setup for your editor. The just-in-time documentation you get from the language server can help to figure out which methods/functions are available on a given type.
Why is [`ExactIterator`](https://doc.rust-lang.org/std/iter/trait.ExactSizeIterator.html#implementors) not implemented for [`RangeInclusive&lt;{usize, u32, i32}&gt;`](https://doc.rust-lang.org/std/ops/struct.RangeInclusive.html)? It is implemented for these types in the `Range&lt;_&gt;` versions.
Seems like an oversight. It should be straightforward to add the implementations.
It is `--release`. Use `--debug` to use the dev profile.
According to the [Rust Survey 2018](https://blog.rust-lang.org/2018/11/27/Rust-survey-2018.html), the other language that Rust developers are most comfortable with is Python. So there are likely to be many people on here. I am not one of them. &amp;#x200B; Honestly, if you haven't messed with [serde](https://serde.rs/) yet, it's a beautiful, easy-to-use piece of code. &amp;#x200B; Here is an example using [serde\_json](https://github.com/serde-rs/json): https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=6c149dd4613c60cfad49224f1a116bec
I find it's not the amount of information that's the problem, but the formatting. I like how well Rust is documented, but rustdoc's output is almost impossible to read when you're dyslexic.
You can conditionally compile with annotations: e.g. ``` #[cfg(feature = "my_feature")] // Something with the feature #[cfg(not(feature = "my_feature"))] // Something without the feature ``` In your cargo.toml file, you would add: ``` [features] my_feature = [] ``` And to compile with the feature, you would use: ``` cargo run --features my_feature ```
Edit: (This includes making changes to the `Cargo.toml` file). I do not know if there is a way other than that. You can conditionally compile features with annotations: e.g. ``` #[cfg(feature = "my_feature")] // Something with the feature #[cfg(not(feature = "my_feature"))] // Something without the feature ``` In your cargo.toml file, you would add: ``` [features] my_feature = [] ``` And to compile with the feature, you would use: ``` cargo run --features my_feature ```
IIRC, it *cannot*, at least for usize. Remember that it needs to report its length as usize. So what is the length of `0..=usize::MAX`? It's `usize::MAX + 1`, which cannot be expressed as a usize.
As I mention in the post, users of glutin should update their application to use the new glutin release candidate. Back ports are a PITA, and I'd hate to have to do one.
Is explicitly dropping things before they would normally be dropped considered an anti-pattern or bad style? How about with `MutexGuard`s? Should I explicitly use a block `{ }`?
There's really just one feature that to me, is a must-have in a terminal since using pantheon-terminal (the one in elementaryOS). Is there a way to configure alacritty to have smart copy support? Basically what this means is, if text is selected with the mouse, Ctrl+C should copy, but if nothing is selected, Ctrl+C should send an interrupt. Also Ctrl+V for paste. It's a small thing, but I really can't use a terminal without it anymore. It's just so jarring to be using an IDE and using all the standard hotkeys that have been standardized in every GUI app then go to a terminal and have those not do what you expect. I'm mostly asking this because this is a project which is still very-much in heavy development and I'd love to see this added as an optional feature which would let me replace the feature-lacking pantheon-terminal with something fresh and new. Thanks for all your work on the project! I've been occasionally peeking at the project every few months always impressed by the performance but just waiting for more stability before using it. This beta seems like a good time to try it out now!
Videos aren‚Äôt playing on my iPad. https://www.dropbox.com/s/1hy91uwz4zvbsiu/File%20Apr%2008%2C%2011%2033%2024%20PM.jpeg?dl=0
Nice! Very similar to my implementation: fn save_cookies_from_response(&amp;mut self, response: &amp;reqwest::Response) { let set_cookie_iter = response.headers().get_all(SET_COOKIE); for c in set_cookie_iter { c.to_str() .into_iter() .map(|s| s.to_string()) .for_each(|cookie_str| { Cookie::parse(cookie_str).into_iter().for_each(|cookie| { self.jar.add_original(cookie); }); }); } }
Looks great!
Serde looks really handy, thanks!
&gt; I'm curious if there are other people who came from Python specifically, and what you love about Rust Python was my primary language for over 15 years and Rust is the first language that's felt like a worthwhile replacement for it. I love that Rust gives me a powerful type system to encode my invariants in without having to resort to the mismatch between abstract model and machine model that I'd get from a functional language like Haskell. I also love that `rust-cpython` makes it easy for me to write safe Python extensions in Rust. &gt; and what you found (or still find) frustrating. What do you think are the biggest stumbling blocks for newbies? Unfortunately, I don't really remember the former (aside from most of it being fixed either before or in Rust 2018) and it's too late for me to give the latter a good ponder. &gt; Any suggestions of cool libraries/frameworks to check out? I second ObliqueMotion's recommendation to check out serde and also suggest the following: * [structopt](https://github.com/TeXitoi/structopt) for command-line arguments * [ignore](https://crates.rs/crates/ignore) for walking the filesystem * [cargo-edit](https://crates.rs/crates/cargo-edit) for convenient commands to manipulate the dependencies in your `Cargo.toml`. * [rayon](https://crates.rs/crates/rayon) for stupidly easy parallelism. * [ammonia](https://crates.rs/crates/ammonia) as the Rust equivalent to Python's "bleach" HTML sanitizer. * [Cursive](https://crates.rs/crates/cursive) as a portable way to build TUIs. (those GUI-like terminal interfaces) * [unicode-segmentation](https://crates.rs/crates/unicode-segmentation) as the proper way to iterate "character by character". * [proptest](https://crates.rs/crates/proptest) for more effective automated testing Also, [crates.rs](https://crates.rs/) is a very nice way to browse the ecosystem.
Items such as the furnace in this case will not appear. This only happened as of recently, in the past it was always fine.
I wanted to serialize all 825k commits in the linux git repository to a json file. With so many commits I wondered if serializing to a trie would be shorter than a list. So I tried out making a specialized compressed trie that serialized with serde how I wanted it. Saved about 5% in filesize but I'm wondering how it will affect search speed from the browser. It's a simple and fun implementation but it was my first time writing a custom serializer and I also tried out some funky stuff with node child bucket sizes. https://github.com/chippers/byte_trie chip@dev:~/projects/gitsplode$ ls -lh ~/temp/.splode/ total 352M drwxrwxr-x 2 chip chip 65M Apr 8 21:33 commits -rw-rw-r-- 1 chip chip 80M Apr 8 21:33 commits.json -rw-rw-r-- 1 chip chip 29M Apr 8 21:33 commits.json.br -rw-rw-r-- 1 chip chip 40M Apr 8 21:36 commits.json.gz -rw-rw-r-- 1 chip chip 76M Apr 8 21:33 commits_trie.json -rw-rw-r-- 1 chip chip 28M Apr 8 21:33 commits_trie.json.br -rw-rw-r-- 1 chip chip 38M Apr 8 21:38 commits_trie.json.gz drwxrwxr-x 3 chip chip 4.0K Apr 8 21:32 references -rw-rw-r-- 1 chip chip 80K Apr 8 21:33 refs.json -rw-rw-r-- 1 chip chip 16K Apr 8 21:33 refs.json.br -rw-rw-r-- 1 chip chip 18K Apr 8 21:38 refs.json.gz
There's \`user\_session\` for this too, I believe. (Though it's not working in my sample program right now...)
I still can't figure it out. I'm okay. I'll figure something else out. I _have_ to be able to call self. This just won't work. Thanks for the help either way.
We have a very similar background. Checking out rust extensions in python is what finally pushed me into learning it! Thanks for all these packages, this is very nice. I'm also checking out Rocket (Web Framework), and Diesel (ORM). I'm curious about using Rust/Rocket/Diesel as an alternative to Sanic or Django.
:) My regular reddit isn't suitable for professional discussion.
/r/playrust
&gt; cmder is nice because it has a kind of franken-shell experience that lets you use readline keybindings/isearch and native windows commands at the same time This. Windows has generally way worse cmd line experience than Linux but when you search for selecting text in terminal with shift+Ctrl+arrow, ppl say it is impossible and give you wall of text about terminals, consoles and history and force you to use strange and anti-useful shortcuts (like in screen or vim). On Windows, it just works.
+1 me too, although I am a hold out and still like [docopt](https://github.com/docopt/docopt.rs) over clap and structopt.
No, explicitly dropping things with `drop(guard);` etc is totally fine.
Any chance we'll get ligature support? I don't see it on the change list or the future plans. I think it's the only thing keeping me on konsole at this point.
If you type Alacritty in the terminal it'll open in the same path, if that's what you mean. I'm not sure about the shortcut keys though, scrolling shortcuts were the one thing that never worked for me when I last tried it.
Rust really made me think about how I was writing my code. Unlike python, a lack of a REPL made learning a little slower which took some getting used to. I can say my understanding of the stack and heap have increased 10 fold. I'd never had to think so deeply about memory management before, but I love how the Rust has guided me into understanding it's importance. My biggest challenge is actually realising I'm only scratching the surface. I can clearly see we have people new to this level or programming and the more experienced who can really make the most of the language (some people build CLI's and other build emulators and OS's). I'm planning on getting as many people on board with Rust in the newbie camp, give them as much understanding as possible so they can do things like extended Python or start with Rust and fallback to Python in some cases. This is the first language in a long time that's got my attention.
I've been using Alacritty for a couple months now and I can't complain. It's really snappy and I absolutely love the configuration options.
On the github page you have 4 paths where alacritty looks for a config file in a specific order. My question is, if in one path a config file has a syntax error etc., will the terminal try another path? Because sometimes when configuring I mess it up and suddenly the terminal won't even start, and it would be nice to have a fallback. If that works I guess I've done it wrong until now lol.
&gt;Can only offer contracts, but this could become long term. For anyone interested in this, as with any contract job, make sure you read the contract very carefully, ask lots of questions, and get all your concerns addressed.
I'm using reference-counting as an internal implementation detail for several types in my project. The only public API difference between putting `Arc` and `Rc` in the field is changing the impls from `!Send + !Sync` to `Send + Sync`. Would replacing `Rc` with `Arc` be a reasonable thing to do within a feature gate, letting the dependent crate choose to trade performance for atomics if really necessary? In my opinion, this is a purely additive, backwards compatible change that won't affect any other crates in the dependency tree if activated. It doesn't matter for typical use cases, but I guess data might need to be shared between threads in some applications.
Just starting out, but generators are helpful in python.
Do you think there is anything that can be done to help here? For example do you know of any docs in another language that you find easier to read and are well formatted.
Could you elaborate? I find rustdoc really comfortable to follow. But I'm not a dyslexic, so would like to hear other side of the story.
it's a brand new server and I will appreciate everyone from the rust community of Reddit to please go check out the server it's a really good server and I think and I probably know you will love it
It is possible, but its purpose is to allow using older libraries with newer versions of Rust. As I understand the feature, those libraries should migrate to non-keyword names, and using `r#` in new code just because the keyword's name is so fitting for a method is strongly discouraged. (If it's needed to follow a naming scheme established outside Rust, it's more common to add an underscore to a name, so that a C struct with "impl" and a "name" has a "impl_" and a "name" in Rust).
Agreed, it's important to ensure that you understand the risk:reward ratio of contract work versus salary, and any tax, residency and other legal, insurance and banking implications this may incur. &amp;#x200B; On the flip side, contracting awards maximum freedom to all parties involved, which is great if you enjoy variety. Some contract engineer friends of mine take 6 months off for holidaying every year!
I mean, I wouldn‚Äôt, but I think the specific way rust enables this ability is pretty cool.
&gt; for example documentation for Ipv4Addr is an order of magnitude longer of its Golang counterpart Let's take a look at this example, and see what the correspondences are, between [`Ipv4Addr`](https://doc.rust-lang.org/std/net/struct.Ipv4Addr.html) and Golang's [`IP`](https://godoc.org/net#IP) * `pub const fn new(a: u8, b: u8, c: u8, d: u8) -&gt; Ipv4Addr` corresponds to Go's `func IPv4(a, b, c, d byte) IP`. The declaration is slightly more complicated because Rust supports constant functions while Go apparently doesn't, but otherwise they're the same. * `pub const LOCALHOST: Self` this is a constant associated with the type. Go doesn't have such a constant. * `pub const UNSPECIFIED: Self` corresponds to the Go variable `IPv4zero = IPv4(0, 0, 0, 0)` (looks like this is a variable because Go doesn't support constant functions) * `pub const BROADCAST: Self` corresponds to the Go variable `IPv4bcast = IPv4(255, 255, 255, 255)` * `pub fn octets(&amp;self) -&gt; [u8; 4]` This returns the IPv4 address as a 4-element array. Go doesn't have such a function because IP is a type alias of a slice of bytes (`[]byte` in Go terms, or `&amp;[u8]` in Rust terms), while Rust actually has a distinct type for IPv4 addresses so this allows extracting it as an explicit array of 4 octets. * `pub const fn is_unspecified(&amp;self) -&gt; bool` corresponds to Go's `func (ip IP) IsUnspecified() bool` * Likewise with `is_loopback`/`IsLoopback` * `pub fn is_private(&amp;self) -&gt; bool` is something that exists in Rust but not in Go, but is a function for classifying whether an IP address is in a private address space that shouldn't be routed to the public internet according to the relevant RFCs. * `pub fn is_link_local(&amp;self) -&gt; bool` in Rust has two corresponding methods in Go, `func (ip IP) IsLinkLocalMulticast() bool` and `func (ip IP) IsLinkLocalUnicast() bool` * `pub fn is_global(&amp;self) -&gt; bool` is not yet stabilized in Rust, and has a slightly different interpretation than `func (IP) IsGlobalUnicast` in Go * `pub fn is_multicast(&amp;self) -&gt; bool` corresponds to `func (IP) IsMulticast` * `pub fn is_broadcast(&amp;self) -&gt; bool` doesn't seem to have a corresponding function in Go * `pub fn is_documentation(&amp;self) -&gt; bool` doesn't seem to have a corresponding function in Go * `pub fn to_ipv6_compatible(&amp;self) -&gt; Ipv6Addr` doesn't have an equivalent function in Go; it is one way of embedding a IPv4 address in an IPv6 address * `pub fn to_ipv6_mapped(&amp;self) -&gt; Ipv6Addr` corresponds loosely to Go's `func (ip IP) To16() IP`(Go uses the same type to refer to both IPv4 and IPv6 addresses, but this converts a 4-byte IPv4 address to the 16-byte form by prefixing with `:ffff:/90`, the same as Rust's `to_ipv6_mapped`) And that covers the basic functionality implemented by Rust's `Ipv4Addr`. As you can see, most of the methods correspond directly to one in Go's equivalent, while there are a few differences in what predicates they provide for determining certain properties of the addresses. What does the rest of the documentation in [`std::net::Ipv4Addr`](https://doc.rust-lang.org/std/net/struct.Ipv4Addr.html) correspond to then? It's all trait implementations. Traits in Rust are somewhat like interfaces in Go, with the difference that in Rust they must be explicitly implemented, while in Go they are automatically implemented if you implement a method with the right name and signature. Rust has a number of traits that are built-in to the language for things like operator overloading (operators act on anything that implements the appropriate trait), plus a number that are used by the standard library for things like string formatting. Go's interfaces are used similarly, but it doesn't use them nearly as heavily. It doesn't have operator overloading, it doesn't distinguish between moving values and copying values like Rust does, so it doesn't have as many interfaces that would be relevant to implement. However, there are a few interfaces implemented for Go's `IP` just like Rusts `Ipv4`: * Rust's `Debug` and `Display` traits are used for similar purposes as Go's `Stringer` interface, which is implemented by the `String` method. Rust distinguishes between two kinds of formatting, one for human-readable values (`Display`), and one for printing a more precise internal representation (`Debug`). * Rusts `FromStr` trait corresponds to Go's `TextUnmarshaller` interface implemented by the `UnmarshalText` method. But there are a lot of traits implemented for Rust's `Ipv4Addr` that either don't have equivalents in Go or which aren't implemented for the corresponding type in Go: * `Copy` is a distinction not made in Go. It indicates that a type can be copied; that is, if you write `let a = Ipv4Addr::new(1, 2, 3, 4); let b = a` then you can use both `a` and `b` and they will have independent copies of the data. * `PartialEq` is the trait for implementing equality comparisons using `==` and `!=` (though with `PartialEq`, values aren't required to compare equal to themselves). Since `IP` is just an alias for `[]byte` in Go, you can already compare them, though you might get incorrect results in cases where they actually are the same but in two different representations (the 4-byte form and the 16-byte form). Go adds the `Equal` method for this, but you have to know to call it. * `PartialEq` is also used for comparing `Ipv4Addr` to `IpAddr`, the type that can contain either an IPv4 or IPv6 address. Go already uses the same type for both. * `Eq` is just a marker trait which says that the `PartialEq` implementation actually means full equality, so every value will compare equal to itself. * `PartialOrd` is a trait that allows ordering elements, though not all pairs of elements have to be comparable * `Ord` is a trait that allows comparing ordering of elements and being guaranteed that all pairs of elements will be comparable * `Hash` allows values to be used as keys in a hash table. Go doesn't allow using `IP` values as keys in a hash table, as they are slices, and slices are potentially mutable, which would mean that hashing would be inconsistent. In Rust, because IP addresses are value types and not reference types, they can be perfectly well hashable; you are hashing that particular value, not a reference to it. * `From` allows infallible conversion between types, in this case you can convert from `Ipv4Addr` to `IpAddr` (but not vice-versa), and you can freely convert to and from a `u32` (since an IP address can also be interpreted as a 32 bit integer). * `Clone` is similar to copy, but can be used for types where you don't want it to happen implicitly. Anything that implements `Copy` should implement `Clone`. Then there are some more traits listed. These are traits that didn't have to be explicitly implemented. First are auto-traits `Sync` and `Send`, which are automatically implemented based on how types are defined by default but can be opted out of. These are marker traits indicating whether it is safe to share these values between threads, and whether it is safe to move these values between threads. Because `Ipv4Addrs` are immutable simple value types, it is safe to both move them between threads or share them between threads. Go does not make this distinction, and it lets you get into trouble by sharing values between threads in cases in which it's not safe. Finally, there are "blanket implementations" of traits. These are traits that are not defined explicitly for `Ipv4Addr`, but are defined for any type which implements some other trait that `Ipv4Addr` implements. Many of these are very general traits which are implemented for just about any type in Rust, or variants of traits already implemented that can be automatically implemented based on the trait `Ipv4Addr` implements. For example, `TryFrom`, which is the fallible version of `From`; of course, `From` can't fail, so `TryFrom` won't ever fail, but this ensures anything which could use the types that implement the `TryFrom` trait can also use values that implement the `From` trait with no extra work. A lot of these more abstract, general traits aren't anything that you would explicitly call on an `Ipv4Addr`, but you need them for doing certain built-in operations or using them in certain APIs. You will frequently find out about this only when you don't implement the right trait, and you get a compiler error that tells you you can't do what you want without implementing it. Overall, the basics of what `Ipv4Addr` implement are pretty similar to what Go's `IP` type implements (except that it is actually more like Rusts `IpAddr`, as it represents either an IPv4 or IPv6 address). The direct trait implementations also correspond, or they correspond to a few more things you can do in Rust that you can't in Go (like `Hash`), or a few more distinctions that Rust makes for safety that Go does not.
As you learn Rust, you'll quickly become familiar with some of these common traits, like `Debug`, `Display`, `Copy`. Others you don't generally need to worry about unless you need them, at which point the compiler will generally tell you that you do. As far as "I need a functions that does X and I have no idea where to find that", that depends on what X is. If it's converting between types, I follow the following reasoning: * If there just one obvious way to convert that will always work? In that case, look for a `From` implementation. * If there's just one way but it might fail, look for `TryFrom` * If there's more than one way, look for explicit conversion methods. Other things, I'll look for methods on the type I might expect, or I'll just search the docs using the built in search. If that doesn't work, I might use Google. I'm not sure what you would get out of something like `javap` that you don't get out of the docs. They show you all of the methods defined for a type. The ones most specific to that type at the top. The ones directly implemented below. The ones auto implemented below that, and blanket implemented below that. Generally, once you've become familiar with the common traits, you'll only need to check for a type the methods it itself implements, and then just glance at which of the common traits are implemented if you need one of them. There are some cases in which it could be a little hard to navigate if you're not familiar, but as you get more familiar with Rust, you'll start to be able to find your way around and find what you're looking for.
This is something I would be very interested in as well
Wow great job. I'll try it
&gt; Why they made the monstrosity that is crates.io rather than something that serves simple HTML pages from templates is beyond me. Supposedly to make front-end developers more inclined to contribute to it.
example: cd /tmp/blah1/blah2 vim blah3/blah4/blah5.txt &lt;shortcut key&gt; new alacritty opens inside /tmp/blah1/blah2
Or, perhaps more succinctly, I should just point out these two screenshots from the documentation of Golang's `IP` and Rusts `Ipv4Addr`, to help you figure out where to look for the most important information: https://imgur.com/a/2HzjYBa
That's what Vim's terminal buffer is for. I don't think Alacritty has that feature though.
So what's different? doesn't seem to be a changelog in your blog post.
OK, I will try Actix. Thanks.
My requests are very simple and what I did was a load test with SoapUI with 500 threads and 50K requests.
Yes, I did a release and it was slow in my macOS and cross compiled for a linux box. In Go I have used the standard net.http and gorilla.mux for routing. (but tested fasthttp too).
Ok, thanks. I will check Actix.
Yep, sure. Did my tests with a release in macOS and cross compiled to Linux for a test on Linux server...same bad results on both.
Release.
Hi Yes, I have used release option and tested on my macOS and cross compiled to Linux (what a nightmare) to run a test in a Linux server with same bad results on both. Thanks for the advise regarding benchmarks on macOS.
Benchmarking the factorial and comparing the results with similar code made with Go, NodeJS and Java. My code was compiled with the release option.
That is a desired feature but incredibly complex to do right without hurting performance. So I'd love to work on it some day but it is pretty low priority right now because of the inherent complexity.
Alacritty will not look in multiple file paths however that is something that has been requested (including merging of these different configs when they are all present and working). However it is impossible for Alacritty not to start only because of a configuration error. It will try its best to still apply all non-broken settings and even if the file cannot be parsed at all anymore it will fall back to the default config.
&gt; 1) open a new instance in same dir on Linux. On Linux it is, since we can read the cwd of the subprocess here! Use the `SpawnNewInstance` action in a key binding and it will work. Because we need to read the cwd of the child process, this will not work when you're multiple levels deep in shells, but it should work for you. &gt; 2) assign shortcut key for scrolling a line up or down. This has actually landed yesterday, unfortunately it didn't make it into 0.3.0. So if you're willing to compile from master you can use the `ScrollLineUp` and `ScrollLineDown` actions, otherwise you'll have to wait for 0.3.1.
It has! Unfortunately it's much harder on BSD/macOS/Windows so for now it's only supported on Linux with the `SpawnNewInstance` action. For all other platforms it won't open in the current working directory.
It's `actix_web` just so you know, cause there is a `actix` also (more low level).
Hey, I helped developing most of the macro magic in Substrate. As the others already said, it is a special syntax only accepted by our macros. If you need any help, I can help you understanding these macros.
I'd be extremely curious about some benchmarks on 4k full screen macOS displays. Unfortunately I don't have those resources but I'd be interested if item2 is actually faster in throughput and if so what Alacritty can do to change that. If you can verify iterm2 is faster that's a bug in Alacritty! Feel free to report that on github. I'll also look into that myself, but I can only simulate a 4k screen by reducing my font size.
This has been brought up and it will not be supported because of the inconsistencies and issues it causes in addition to the complexity it adds. A more detailed discussion can be found here: https://github.com/jwilm/alacritty/issues/1919 All selections are automatically copied to the clipboard anyways, so there's no need to press ctrl+c to copy them. If you have issues with this I'd recommend going for the saner choice and binding copy/paste to something different in your OS. I've been using dedicated Copy and Paste keys for a long time and it works everywhere without any issues.
And in general you can just treat the docs like wikipedia and browse until you get it.
I looked further into it, rocket is built on an older version of hyper, which has a bug. You can verify this by setting keep-alive in the rocket.toml and then using telnet, you will see that it always closes the connection. using keep-alive is a big speed boost for a lot of http benchmarks so this is a big handicap. it wouldn't be bad in a real life situation because every unique connection would probably only make one query per connection.
Rocket is really slow for a Rust library and the fact that it \*requires\* nightly actively says that it's not ready at all for a production setting (where performance is key). We run Actix in production and it's been stellar so far. We support 1M rps without an issue on 8 cores.
Thanks for setting up those examples, I've taken a look and indeed it does look as though the compiler has optimised this case so that the conversion only happens once. My particular project targets \`wasm32-unknown-unknown\` currently, but adding the appropriate \`--target\` to these examples also shows that the compiler optimises this even though the actual conversion uses multiple bit shift operations, so that's good to know too. Thanks also for the tip about byte ordering within the struct, that certainly makes sense.
It's absolutely possible that you might just not care about the things Alacritty users care about. However sometimes you might even surprise yourself. The recommendation I always give is to just try things out. Get the latest Alacritty, compile it and just see what all the fuss is about. Play a bit with the config options and see if you can figure out why some people enjoy it so much, even though plenty of 'good enough' emulators exist already. If you can't be bothered to do that or you still don't understand, then maybe it's just not for you. That's exactly why more than one terminal emulator exists, different people look for different things. There's certainly no magical hidden feature which nobody can put in words that makes Alacritty better than everything else. But the combination of all the little things can often just make things more pleasant.
&gt; Videos aren‚Äôt playing on my iPad. That's a bummer, I thought I had finally sorted everything out now. I'm unsure why this is since I've confirmed it to be working in Chrome and Firefox now and explicitly used one of the more common codecs (I think V9 or x264). I don't think I'll be able to resolve that for this blog post, especially since I don't have an iPad to test things on. But it looks like I'll need to look into creating working videos for future updates.
That's a bummer. That'll pretty much be a non-starter for me then. None of the workarounds fit for me, unfortunately. I don't have extra keys on my keyboard for actions like that, and even if I did it would require me to break my habits which is the entire point of that feature request, ultimately. I hit Ctrl+C accidentally way too often when using terminals that don't have this feature that it just becomes a hindrance to productivity. I don't like copy on select because I use selecting as a reading aid and I find it frustrating when I find that I accidentally clobbered my clipboard with random terminal text the next time I paste somewhere. I realize I can disable that, but that again leads to that feature request.
Thank you for your comment! I'll think to add or modify the assertions library to make the assertions shorter.
Actix web is in alpha right now, but they are working on it pretty much every day and I think it will reach beta soon. Might be a good idea to wait a while if you can, so that the docs are updated and you can use it without as much problems. Btw, Actix is one of the fastest web frameworks in the world as far as I have seen in benchmarks, so it should be enough for most things. Go had a huge head start of course, so i don't think Actix can rival it yet I'm free completeness. Also, Rocket will get faster after async/await is released for Rust. It will also move to being stable later this year I think.
Regarding performance, I was in the same boat. You don't know what you are missing until you tried one of the fast terminals. The difference in perception can be quite huge, just everything feels nicer and more instant.
Oh the world we live in‚Ä¶
It's great that Alacrity has picked up speed again thanks to new maintainers. It's a excellent Terminal now with great performance. The main thing some people might be missing is tab support but that will probably never happen and is not a concern if you use a tiling wm.
Why would you want to do that unless you need a feature that's been stabilized in beta?
Wait, TLS is layer 5 now? It used to be called "Transport Layer Security", i.e. the same layer as TCP. The explanation makes sense though. Thanks.
Is there still room for performance improvement?
I actually contributed a patch with a cookie jar to reqwest,it's currently waiting to be merged.
I find the docs are better for those who understand Rust and it‚Äôs idioms. When coming from another ecosystem it can be difficult to use. The docs could use more code examples.
There definitely still is! There are various points on my list that I want to look into with the goal of optimizing various different areas where Alacritty can still improve. And of course there are always types of performance that weren't the primary focus originally. Latency is often quoted here and Alacritty still has ways to go in that regard
&gt; It's great that Alacrity has picked up speed again thanks to new maintainers. That's the beauty of open source! It definitely works. &gt; The main thing some people might be missing is tab support but that will probably never happen and is not a concern if you use a tiling wm. We might even be able to support this on macOS since the platform implements something similar to WM tab support, though there's some limited application support necessary. We would be able to do the same on Windows... but they've apparently scrapped their plans for built-in tab support, so that's likely never happening. On Linux the WM is definitely the way to go and many window managers support automatically adding tabs to windows, so if you're the kind of person to need that, I'd recommend choosing one which supports it!
ADAL is a pile of steaming garbage, and yes, requires a special library that has workarounds for Azure's implementation. Good luck, seriously. I don't envy you.
Haha, it's so cool to see my name in the Contributors list... even though it was just a little patch, it feels awesome!
Even big patches are just a combination of many little patches! Everything counts. Thanks again for your help, it would be impossible for me to support all the different platforms without help from contributors that are experienced with them.
Skim it and hope that some of it goes in? &amp;#x200B; ...that said I'm new to the language! (and compiled languages in general)
&gt;However it is impossible for Alacritty not to start only because of a configuration error That's wrong unfortunately. Just setting the colors: primary: background property twice in a row not only prevents alacritty from starting, it will also immediately crash ALL open alacritty windows if the live config update setting is enabled. And that's only the example I remember because that happened just yesterday: [ERROR] Problem with config: colors.primary: duplicate field `background` at line 1 45 column 15; using default value thread 'main' panicked at 'unexpected end of mapping', /build/.cargo/registry/src/github.com-1ecc6299d b9ec823/serde_yaml-0.8.8/src/de.rs:147:25 But honestly that's not a big issue for me, whenever it doesn't start I know I messed up something and edit the config in another terminal. Using a default config instead of panicking would be preferrable though.
Love: performance, Cargo, modern language features (ability to add methods to types independently of the authors, ADT, filter/map) Frustrating: quality of documentation, rust book links leading nowhere with book updates, missing fundamental language features (async, generators, named arguments, default parameter values), lack of Django for Rust. Useful libraries: structopt lalrpop actix-web askama itertools diesel crossbeam
Thank you very much for clarifying!
Well you can always call the C preprocessor from a build.rs file and generate yourfile.rs from yourfile.rs.cpp :)
I suppose the intention isn't too bad. But it also discourages people who aren't interested in web development from contributing. I'm personally interested in Rust. If your site renders blank without JS, there's no way I'm going to bother with the JS ecosystem to make any changes to it. But of course, others want to learn Rust to speed up their Node.js apps, so it's a different story for them.
&gt; That's wrong unfortunately. Just setting the colors: primary: background property twice in a row not only prevents alacritty from starting, it will also immediately crash ALL open alacritty windows if the live config update setting is enabled. And that's only the example I remember because that happened just yesterday: Do you have a custom shell set with your default shell not working? I can not reproduce this and it definitely is a bug. I'd appreciate it if you could report this in the Alacritty issue tracker since the config file should never just panic directly. It looks like this is due to one of our dependencies too unfortunately.
I have some constructive critisism about your blog. I'm a tiny bit colour blind, and it is hard for me to read the dark red on black you used for links there. Same for the sample videos of the terminal; black on dark red, impossible to read, and dark-grey on black, very hard to read.
Compile with optimizations, `lto = "fat"` (IIRC), and maybe even `target-cpu=native`. This is free runtime performance, basically. Then, start measuring what the slow parts of your program are. Often, it will boil down to using more efficient algorithms and avoiding copying stuff/allocating in hot loops. The recently introduced [cargo-flamegraph](https://github.com/ferrous-systems/flamegraph) is helpful to find the places you should look at first.
Not in the `name/space` format right now. See: https://github.com/rust-lang/cargo/blob/master/src/doc/src/reference/registries.md
Math papers are often written using LaTeX. LaTeX provides a really great language to embed graphics, called TikZ. However, it is often faster to draw figures in a vector graphics program (such as Inkscape), and then convert that to TikZ, but then one loses the ability to program. This tool aims at solving this problem, at least partially: I originally wrote it to convert one SVG file with lots of different layers to more than 10 different figures I needed in a proof, turning some of the plain SVG paths into "paths paved with square tiles" along the way. The net saving for me has probably been on the order of several hours already, on a single paper.
Hi, thanks for the feedback! We currently have no tracked issue on this (neither open or closed). Could you please open one at https://github.com/rust-lang/rust/issues so that we can follow up and think about solutions.
Step 1: Benchmark Step 2: Find the slowest part Step 3: Make it faster Step 4: GOTO 1 --- But seriously there's not much more to it than that. Some simple things are: * Avoid allocating where possible (don't `.clone`) * Prefer static dispatch * Allocate in large chunks (`Vec::with_capacity`) * Prefer iterators to loops (can avoid bounds-checks * Use `#[inline]` on small, commonly used functions And finally, **BUILD IN RELEASE MODE**. Every week there's a question from someone asking why rust is slower than another language and 90% of the time this is why.
Thanks for the feedback, I'll definitely take it into consideration, though it will obviously be hard for me to confirm whether any changes actually improve things.
I don't know, shift/ctrl + arrow is something I've seen both in vim and terminals on Linux.
Like upgrading to higher refresh rate screens. Hardly vital, but definitely noticeable and enjoyable.
I would be careful with `target-cpu=native`, in my experience quite often it results in a slower binary. One of the reasons for that is enabling of AVX instructions which can lower CPU frequency.
&gt; Or was my joke just *that* dumb? It was this one.
Discussion is great! I don't know much about the UI part of VST, or VST in general, but poor you having to implement everything up from OpenGl! LV2 does something along the lines of "That was done before!": Basically, you as a plugin can tell the host that you support a set of frameworks, e.g. Qt or GTK. Then, the host creates a window for the given framework and passes a pointer to that window to the plugin. From there, everything is handled by the frameworks. Maybe I'm wrong with the details, but that's the general idea. Therefore, one option would be to say: Don't do it in Rust, do it in C++ or something else; Something that is supported by the framework. However, you still have to talk to the backend written in Rust and therefore, I will probably do a mix: The front-backend for the UI is written in Rust which talks to the plugin and the UI and the real frontend is written in C++ or with another crate. This is how LV2 handles UI and it's not such a pain at all! ;) The real pain was the Atom support: This is basically an entirely new type system that helps you to transfer arbitrary data among plugins. I had to dig into heavily unsafe code, internal data structures and dynamically sized types. It was fatiguing, but having it done was a lot of fun too!
To be fair, there are other standardized hotkeys for copy/paste that actually work everywhere. `Shift + del` copies, `shift + ins` pastes. This works in terminals, any GUI app, and every OS I've tried it on. I've learned to use that exclusively and never get confused about `Ctrl+C` anymore.
Tried it out on Windows 10, a window opens but it's invisible. No error message whatsoever, not sure how to troubleshoot.
Right, you should always compare before and after :)
Getting bug reports about regressions we don't catch with our testing would be great!
Writing an authenticator backed by .htpasswd files. It's almost working for the use cases I need (bcrypt hashes, everything else returns an "insecure storage" error), and then I can start rewriting this little auth_request server in rust.
You can preprocess SVG files via [usvg](https://github.com/RazrFalcon/resvg/tree/master/usvg) before conversion. It should make your life easier.
Hey, contribution is great! I hadn't had have much time to dig into your code, but I like the way you handle ports! We should adopt that! I only made the de-referencing of the ports unsafe because this is a proper unsafe operation, but with your managing approach, this could be made safe and sound! However, when looking at the Atom-support, you try to stick a bit too much to the C-Header, at least for my taste. As a plugin implementer, you can do a lot of bad things with this API, which is why I did the hustle of implementing that complicated system in the first place. Also, I didn't look into binding `lilv`, but don't you think that this should be handled in a different crate? Anyways, your contributions are very welcome and I'm looking forward to work with you!
First of all, wrong sub, bro. Try /r/playrust Second of all, try disabling Fullscreen Optimizations. Right-click on your .exe of the game, go to properties, click on compatibility, and the tick the "disable fullscreen optimizations". Since I'm german, the name of the fields you need to click may be called something else.
I had a problem yesterday that would be much clear with generators. So i looked into it and it all just worked in rust as well. fn some_func(id: usize, n: usize, f: usize) -&gt; impl Generator&lt;Yield = (), Return = bool&gt; { move || { let mut round = 0;
I blogged about [Rust performance pitfalls](https://llogiq.github.io/2017/06/01/perf-pitfalls.html) a good while ago; not much has changed in the meantime. Avoiding those pitfalls will usually give you pretty good perf already. If that's not enough, let measurements guide your path: Is your code CPU, memory or IO bound? Could you do with less memory (those are usually low hanging fruits, because less memory = easier to stay in cache)? Can you do less work? Can you optimize how you use the CPU (e.g. SIMD)? Can you parallelize? Perf optimization is a very deep rabbit hole. Be sure to a) have working code as a baseline and b) a performance target so you know when to stop.
Was there some kind of effort to have cool-retro-term use alacritty under the hood? I vaguely recall something along these lines.
I'm unsure what this could come from, but do you have an outdated GPU? That might cause some issues. Either way, github is probably the best place to discuss and track this. So feel free to open an issue.
I've never heard of such efforts before, though there still is a lot of work that needs to be done before Alacritty can be properly used as a library.
I wasn't aware that shift+del copies text, is it used to copy or to cut? In any case, those might be good candidates for default keybindings that could be added to the config!
It cuts, although it's the same as copying on static text. And yes, they definitely are good candidates for default bindings!
Yeah, I'll do that. It's a professional GPU, maybe it changes things? Although this is the first app that causes any issue.
I'm a researching mathematician and not a programmer by trait (more to that later). I've dabbled with many programming languages over the years (programming has always been a hobby of mine) and, until last December, Python has had the vast lion share of my attention when it comes to programming. It's easy to use, has an incredibly rich ecosystem and a very supportive community. However, it has never really rung with my detail-oriented personality. I really like to get down to the nuts and bolts (I absolutely loved programming in Assembler as a teenager). Thus, unsurprisingly, Rust has come onto my radar early on. However, due to a lack of time, I never really got into it until I decided last December to take Advent of Code as an opportunity to finally learn some Rust. I immediately fell in love. In fact, Rust feels like the kind of programming language that has been specifically designed for me. So much so that I've decided to become a programmer once I've finished my PhD in mathematics. One day, I'd like to be a backend (or full-stack) Rust programmer, simply because I like the language that much. Until then, I'll take the best opportunity I can get to work with an awesome team and become the best software engineer I can be -- regardless of the language used. In any case, I'm very much looking forward to all the Rust programming I'll do in my spare time.
When you are implementing your own input type, what stops you from blocking the parser and streaming more data? Nom technically needs all of the input available, but that doesn't mean it has to be in RAM all at once :) Think of mmap: To the user it looks like it's all in memory, but the OS sort of streams the file from disk on demand.
I wouldn't call myself experienced, but... https://i.imgur.com/xVDyqjV.png
Not that you can't still use it, but from the repo: &gt; However, the wider docopt project is mostly unmaintained at this point. &gt; &gt; Consider using clap or possibly structopt instead.
&gt;Python was my primary language for over 15 years and Rust is the first language that's felt like a worthwhile replacement for it. Same except Python for only 8 or so years now Nice to see that it's a common thing
Coming from python and studying Rust, my problem is that I haven't really get the "mut", "&amp;", "*" eventhough I read and practicing it for a while.
Hmm, I‚Äôm not sure manually applying inline is good advice, especially if they‚Äôre not clued up on low-level implications of it (assuming this is the case if they‚Äôre from JS). LLVM probably has better heuristics after it‚Äôs applied whatever optimisations to the code involved, and will inline automatically if it sees that it will improve the code. Apart from that, good advice!
I think the first thing you should do is devise a benchmark on whether you can observe a _meaningful_ performance difference between `Rc` and `Arc`. If you can't, then just use `Arc`. The next thing I'd do is try to figure out whether there is a _semantically_ better choice. An `Rc` imposes some fairly significant constraints on consumer code because it doesn't implement `Send`. This means any consumer code that embeds your data types would also not be `Send`. Generally speaking, using data types that aren't `Send` is fairly niche in my experience. If there's really a performance difference, then your feature gate idea sounds okayish. I would probably _default_ to using `Arc` and put `Rc` behind the feature gate.
This is how my browser looks when I'm trying to figure out the best way to do/use something in rust. I have found that a rustbyexample page, a blogpost, a stackoverflow reply or r/rust's 'ask a question' thread usually point me to the right feature I'm looking for and how to use it (usually the API doc itself!)
&gt; I also love that rust-cpython makes it easy for me to write safe Python extensions in Rust. I'm interested in this. Is there documentation about it other than the API reference?
Are you sure you don't want to use an HTTP server stack such as hyper?
https://github.com/tomaka/glutin/blob/master/CHANGELOG.md#version-0210-rc2-2019-04-08 Mostly changes to how the OpenGL context is handled and some bug fixes.
Ah, sure. I was just wondering why it would be a recommended choice for general purpose use. Many CI setups include a beta build already though.
If I'm understanding correctly, this technique is used quite a bit in core crates in the ecosystem in order to support older compilers. For example, the [regex crate has a build.rs](https://github.com/rust-lang/regex/blob/9687986de45378c744180cc696286aad7db83c5e/build.rs#L16-L29) which sets `cfg`s that can be [used for conditional compilation](https://github.com/rust-lang/regex/blob/9687986de45378c744180cc696286aad7db83c5e/src/literal/teddy_ssse3/mod.rs#L3-L14).
This is sort of a tangent but something I do sometimes in lieu of documentation is clone the repo (of any open-source project, including Rust) and ripgrep the source for terms I've seen used or for patterns I expect to see. For example, "if there's a 'to\_string' there's probable other useful 'to\_' functions: 'rg "fn to\_"' and just poke around. Or when encountering a new trait or function, ripgrepping for usages of that feature. I also use the '\[src\]' link of the docs a lot to see how things are used.
Still working on porting [Ninerpaint](https://ninerpaint.com) to modern platforms (the app was originally written in C for the Palm OS). Things going relatively well, thanks to these SDL2 bindings for Rust.
A profiler is good for finding bottlenecks. I use [Intel's VTune Amplifier](https://software.intel.com/en-us/vtune). It's free but has a license file that has to be renewed fairly often in my opinion and it's an annoying process. Great tool though. Some linux specific tools to learn how to use are [perf](https://en.wikipedia.org/wiki/Perf_(Linux)) and [oprofile](https://en.wikipedia.org/wiki/OProfile).
Hey, two comments: * A lot of the functions would be useful if they were accesible directly on `String/&amp;str`. You can achieve that with an extension trait. [Inflector](https://docs.rs/Inflector/0.11.4/inflector/) does it, if you need an example. * Please don't include `_rs` in a crate name...
Hooray! I just want to mention when I had a performance issue and went on IRC, people were super helpful in resolving it. That was months ago and I've since been using Alacritty without any problems. Excited to check out 0.3.0, especially text reflow C:
Rust (or LLVM?) can sometimes be notoriously bad at inlining. The speed wins from some manual inlining can be enormous, in my experience.
AFAIK `#[inline]` doesn't force the function to be inlined, it only marks it as inlinable from other crates. So it might make sense to mark small (non-generic) functions with `#[inline]` in a library crate.
I think [gnuplot](https://github.com/SiegeLord/RustGnuplot) is your only full featured, mature choice.
What's the difference between `unicode-segmentation` and `String.chars()`?
My only gripe with Rocket is that websocket support is non-existent and its looking like its a long ways out still. It's disgustingly clean and understandable. I really do like it, I just personally need websockets so I can't use it :'(
I typically learn actively so what I do when learning a new language is take something I've already written and write it again in the new language. Take something you know really well with a design you think is solid and port it. If you don't have any personal or work projects you can port take some cli tool that you know well and write that. The idea is to take away any thinking about 'how do I do X?' and focus it to 'how do I do X in Rust?' Sometimes it'll be straightforward, almost mechanical, and other times you'll run into new concepts that you'll have to learn along the way.
How can there be more code examples than there are already? O.o &amp;#x200B; In this case, I think you just lack rust knowledge and then you should maybe re-read the rust book?
Diesel is closer to SQLalchemy than Django ORM, can't speak as much to how the web frameworks compare
Depends on the output format. I think instead of reinventing the wheel, you could also target Vega / Vega Lite. That way, you would only need to generate JSON which is a way simpler task than a complete rendering / layouting pipeline.
Thanks man sorry I had no clue I'm just tryna get some help
psst, the winit bug tracker links in the blog post and your comment both lead to the glutin bug tracker and not winit ;)
This is probably not the best setup you'll ever find, but here is what I use on neovim, trying to keep the keybindings as close as possible to IntelliJ IDEA: Plug 'natebosch/vim-lsc' let g:lsc_server_commands = {'rust': 'rls'} nnoremap &lt;silent&gt; &lt;C-Q&gt; :LSClientShowHover&lt;CR&gt; nnoremap &lt;silent&gt; &lt;C-B&gt; :LSClientGoToDefinition&lt;CR&gt; nnoremap &lt;silent&gt; &lt;F7&gt; :LSClientFindReferences&lt;CR&gt; nnoremap &lt;silent&gt; &lt;F6&gt; :LSClientRename&lt;CR&gt; nmap &lt;silent&gt; &lt;F2&gt; :lopen&lt;CR&gt; nmap &lt;silent&gt; &lt;F3&gt; :lclose&lt;CR&gt; Additionally I use vimux, airline with tmuxline and nerdtree. And if you're curious, my colourscheme is cosmic-latte.
Please don‚Äôt. Keep in mind that tour code will be read far more often than it‚Äôs written, and may be read by people new to the language. I‚Äôd err towards avoiding language identifiers as variable names (I mean, there are _tons_ of times I‚Äôd have liked to use ‚Äòtype‚Äô as a variable name).
I just tried this library for the first time and I'm having an issue, is it normal that query::matches prints to stdout ? [fretn@awesome voca]$ cat Cargo.toml [package] name = "voca" version = "0.1.0" authors = ["fretn &lt;fretn@reddit.com&gt;"] edition = "2018" [dependencies] voca_rs = "1.6.0" [fretn@awesome voca]$ cat src/main.rs extern crate voca_rs; use voca_rs::query; fn main() { if query::matches("world","o", 0) { println!("Hello, world!"); } } [fretn@awesome voca]$ cargo run Finished dev [unoptimized + debuginfo] target(s) in 0.29s Running `target/debug/voca` world o 0 Hello, world! [fretn@awesome voca]$
I love the advice despite wrong topic. Maybe Rust programmers you should just get some basic familiarity with Rust the game so that we can better answer these questions... I would like to at least know what a [grenade stack](https://github.com/rust-lang/rust/issues/12723) is, but I don't have a gaming machine at the moment :-/
Is it working well on Wayland / Gnome without Xwayland?
Comments in the source confirms your answer: // These macros generate \`ExactSizeIterator\` impls for various range types. // Range&lt;{u,i}64&gt; and RangeInclusive&lt;{u,i}{32,64,size}&gt; are excluded // because they cannot guarantee having a length &lt;= usize::MAX, which is // required by ExactSizeIterator.
`String.chars()` gives you _codepoints_, where as `unicode-segmentation` gives you _grapheme clusters_, which are a construct invented by Unicode meant to approximate _graphemes_, where a grapheme is generally considered as something a human would interpret as a single visual character. In Unicode, a grapheme cluster is made up of one _or more_ codepoints. So in general, if you need to deal with things at the level of a visual character interpreted by a human, then you should use graphemes. For example, if you need to show a string but have limited visual space to do so, you might want to limit yourself to a prefix of N characters. You'd ideally compute that first N characters by taking the first N grapheme clusters. (Unfortunately, even this is an approximation, since some characters take up more visual space than others, so you also may need to factor in the [width of characters](https://crates.io/crates/unicode-width). But sometimes a simple fixed prefix is good enough.)
Thanks for posting the helpful links!
Do you know any terminal that supports selecting text with keys? I'll switch immediately.
Looks like a rogue debug statement: https://docs.rs/voca_rs/1.6.0/src/voca_rs/query.rs.html#403 There's nothing to be done other than wait for a release that fixes it. (`query::matches` will also panic if the pattern supplied isn't a valid regex.)
Hello! Thanks for taking an interest! We're a small but growing community dedicated to developing Veloren. The game is playable, although it's currently undergoing a rewrite to move to a multi-threaded ECS architecture. We want to turn Veloren into a shining example of what Rust can do in the game development space. I'm posting this here since the core development team often has limited free time: to keep this project growing, we need contributors - people like you! The community Discord server is very active: you can join it here: https://discord.gg/BvQuGze We also have a website and a GitLab team! https://veloren.net https://gitlab.com/veloren Thanks again for taking the time to read!
Plenty of terminals are modular and allow scripting. RXVT, for example, has plugins that allow keybindings to select text.
Fair enough, but that should be done with careful profiling imo, not just when the function looks small
Fair point (afaik however, this is only true when not using LTO - with LTO enabled, functions even without `#[inline]` can be inlined across crate boundaries)
That makes sense. Thank you!
I've had a chance to skim through your repository, it looks as if we have had many of the same ideas. I have some concrete ideas and plans for supporting custom allocators, but with the current state of allocator support in the \`core\`/\`std\` libraries I see no point in already commiting to anything specific. The \`Alloc\` trait in its current form seems to me to be too generic, as it also wants to support stateful allocators and there is no clear idea how a stateless allocator would be defined with it. But once these things are sorted out and there is some way to use a \`Box&lt;T, A&gt;\` I want to adapt the API of the \`reclaim\` crate accordingly. I've also read the stamp-it paper and it actually contains a link to that repository, which is pretty cool I think.
iOS doesn't support VP8/9 (unless something changed recently). It's been that way for ages, you have to have multiple sources for a video, webm for normal platforms and mp4 for Apple.
Because `std` is designed to be pretty minimal. You have a method to read a bunch of bytes, and then you're free to interpret them however you like. Endianness conversion is not exactly simple either, especially if you want to do it in a way that's both portable and fast.
Yes, but you'll have to build your plugins with the exact same rustc version, since there is no stable ABI. It might not be possible for your use case, but [Xi](https://github.com/xi-editor/xi-editor) runs plugins as separate processes that communicate over stdin/stdout, which is a pretty neat concept.
I gave this a try today, and tabs support is what put me down - I'm on MacOSX and while `screen` is great, the native tabs support has slowly been replacing it for me (at least for common cases).
That was an oversight, added. Thanks.
thanks for the info. So I created a pull-request to make the waiting time shorter :D https://github.com/e1r0nd/voca_rs/pull/15
It takes time and that's a limited resource. Three years ago the Rust ecosystem looked rather different, and they needed a website. crates.io has a fair amount of technical debt, and about three really active contributors/maintainers.
The biggest impacts to performance on modern hardware is how you interact with memory, so a good place to start for some base knowledge might be here: [https://people.freebsd.org/\~lstewart/articles/cpumemory.pdf](https://people.freebsd.org/~lstewart/articles/cpumemory.pdf) &amp;#x200B; and some of Mike Acton's youtube vids: [https://www.youtube.com/results?search\_query=mike+acton](https://www.youtube.com/results?search_query=mike+acton) &amp;#x200B; This is high level, general stuff that applies to any language, you can then move on to Rust specific stuff, which maybe the first thing to do would be understand iterators really well, and how various Rust types and idioms work with memory.
You also can generate dynamic libraries (`.so` on Linux) and load them at runtime. See for example [`libloading`](https://docs.rs/libloading/0.5.0/libloading/). This way plugin authors will not be tied to Rust, though interface will be somewhat less idiomatic.
This definitely interests me. I have been looking for an open source project to help, and a game written in Rust is the perfect one.
You might also want to take a look at these articles for a primer on the topic and other quirks of text handling in a Unicode world: * [Dark corners of Unicode](https://eev.ee/blog/2015/09/12/dark-corners-of-unicode/) by Eevee * [Let‚Äôs Stop Ascribing Meaning to Code Points](https://manishearth.github.io/blog/2017/01/14/stop-ascribing-meaning-to-unicode-code-points/) by Manish Goregaokar * [Breaking out Latin-1 Assumptions](https://manishearth.github.io/blog/2017/01/15/breaking-our-latin-1-assumptions/) by Manish Goregaokar
Awesome! We're a really friendly bunch, and you'd be joining at a very interesting time: the new engine rewrite is just beginning to take flight!
A big issue for `read_u64` or `read::&lt;u64&gt;` is that there are _four_ ways to interpret them, which are all wanted at some point: - read four bytes and interpret them as bigendian bytes of a `u64` - read four bytes and interpret them as littleendian bytes of a `u64` - read for bytes and interpret them as platformendian bytes of a `u64` - read an undetermined amount of bytes and interpret them as ASCII characters and parse a `u64` from textual representation So the deliberately minimal and attempted unopinionated standard library doesn't offer this functionality, because then it'd have to bless one of the four options. People coming from higher level languages will probably expect the fourth, from lower level languages the third (but also often treat the third as the second). Because Cargo makes pulling in library crates so easy, a sparse standard library doesn't matter as much. You can have properly versioned libraries to handle these situations which require these kinds of issues. In cases when you want to parse text rather than interpret bytes, you're almost always better off reading and splitting strings first, as that makes the intent and effect a lot clearer than, say, Java's `Scanner` where if you scan for numbers you have no control over how whitespace is/isn't present. In cases when you want to interpret bytes, the endianness _really_ matters, because even if "all practical systems are littleendian in practice", many protocols _aren't_. You have to be explicit about what you want if you want consistent behavior. That's what the `byteorder` crate offers.
Cool, will do. Thanks!
Hi thanks for your work If I were a grumpy math teacher I'd give you looks about your lack of consideration for integrability in the very beginning of the article üòà It would've been nice to include the code with criterion to give an example of its use The density graph is hard to read because it gets shrinked in the blogpost. What does pdf stands for in the legend?
If you're having trouble with the factorial in particular, there was a [previous discussion](https://www.reddit.com/r/rust/comments/7w3v77/why_is_my_rust_code_100x_slower_than_python/) about the bignum performance.
you can do it with screen in any terminal. It has its own copy paste buffer though, so doesn't go to the clipboard.
And you'd be right to scold me :P I'll add the criterion code, that could be useful as an example. Pdf stands for probability distribution function - I'll add a note for it in the paragraph above it. Thanks for your feedback!
That *is* one place where it's a little sparse. There are the two code examples in the README, the API docs, and various people have asked for help in the issue tracker, where I've replied with examples of how to do things. Feel free to ask how to do things somewhere public (eg. StackOverflow, here, etc.) and then poke me with a link.
Do you have RLS installed? I would expect that guide to work, more or less. If you want to try an alternative, you should also consider `rust-analyzer`, which is much less mature than RLS, but might be better in the future. Even now, I kinda' switched to it, because: - I'm usually on the nightly toolchain, and RLS is more often missing than not - it's much faster (at the expense of being less accurate) - I prefer the approach taken for it, as opposed to RLS If you want to try it, you should first get the [source code](https://github.com/rust-analyzer/rust-analyzer/) and compile it with `cargo install-lsp`, then check that it's in `PATH` (probably in `~/.cargo/bin`). My relevant `nvim` setup, using `vim-plug`: if empty(glob('~/.config/nvim/autoload/plug.vim')) silent !curl -fLo ~/.config/nvim/autoload/plug.vim --create-dirs \ https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim autocmd VimEnter * PlugInstall --sync | source $MYVIMRC endif call plug#begin('~/.config/nvim/plugged') Plug 'autozimu/LanguageClient-neovim', { 'branch': 'next', 'do': 'bash install.sh' } Plug 'Shougo/deoplete.nvim', { 'do': ':UpdateRemotePlugins' } Plug 'Shougo/neosnippet.vim' Plug 'Shougo/neosnippet-snippets' call plug#end() nnoremap &lt;F5&gt; :call LanguageClient_contextMenu()&lt;CR&gt; nnoremap &lt;silent&gt; K :call LanguageClient#textDocument_hover()&lt;CR&gt; nnoremap &lt;silent&gt; gd :call LanguageClient#textDocument_definition()&lt;CR&gt; nnoremap &lt;silent&gt; &lt;F2&gt; :call LanguageClient#textDocument_rename()&lt;CR&gt; let g:deoplete#enable_at_startup = 1 let g:neosnippet#enable_complete_done = 1 let g:LanguageClient_serverCommands = { \ 'rust': ['ra_lsp_server'], \} It should also work with RLS if you replace `ra_lsp_server` with `rls`. There are multiple LSP implementations; I picked `LanguageClient-neovim` because it happened to be written in Rust, but ALE and `coc.nvim` should also work.
Sure, inline can also cause code bloat and more instruction cache pressure, the need for profiling should go without saying. Also note that AFAIR even `#[inline(always)]` does not actually force inline, just gives a *strong* hint to LLVM.
I can strongly recommend [RustGnuplot](https://github.com/SiegeLord/RustGnuplot). While may not be API complete yet, it‚Äôs actively developed and definitely getting there.
Just curious what would vim lsc bring us better? My current setup is just vim with racer, racer vim. Now i have auto complete, jump to definition
You'r choice. I've always been averse to generating the machine-readable definition from the human-readable text rather than the other way around because I can't help but feel that there must be footguns lurking in it.
I will keep an eye on this :)
Big fan of crates.rs
I won't be leaving Django for quite a while, because, for me, the killer app for Django is the ecosystem of reusable apps and that takes a lot of time and effort to build up. However, when that's not a concern, I'd go with [Actix](https://actix.rs/) over Rocket, both because it works on stable-channel Rust where Rocket doesn't, and because it's [over five times faster](https://www.techempower.com/benchmarks/#section=data-r17) in the Techempower benchmarks.
&gt; the need for profiling should go without saying From what I've seen, about 90% of `#[inline]` annotations are at best bad guesses, so I think this should definitely be said all over the place. **Please measure before optimizing or you're not optimizing.** &gt; Also note that AFAIR even #[inline(always)] does not actually enforce inlining, just gives a strong hint to LLVM. `#[inline(always)]` is really bad, nobody should ever use it. It is handled by an entirely different LLVM pass which runs **even in unoptimized builds**. In almost all cases, all you get by using `#[inline(always)]` instead of `#[inline]` is slower compile times.
LSP should bring you the full set of capabilities of the protocol -- completions, hover, go to definition, squiggles (real-time error checks) -- for every language where a server is available. The idea is that you install one LSP client and it works with everything. In your case, ALE already works as an LSP client, so you don't actually need `vim-racer` or anything else. LSP also brings you compatibility with other implementations, see my other response about using `rust-analyzer` instead of RLS.
I'm not quite sure because I don't know the actual traits very well, but I think some interfaces don't allow blocking. Something like "please give me your data as \`&amp;\[u8\]\` makes it impossible to know if one needs to load more data before the parser checks the length of the slice. &amp;#x200B; Regarding mmap: I thought about that too. And it's probably even the best possibility for platforms that support it. But I wanted a general solution first.
Tmux does this, and I have come to rely on it in a daily basis
Soo boundless?
The issue with putting `Rc` in the feature gate would be that it isn't additive / backwards-compatible. Code which requires `Send` or `Sync` would break if any one of the other dependencies enabled the feature. What you probably mean is make the `Arc` feature on by default.
Yes, indeed, good point.
Hey, I am also on the Dev-Team and would like to share some more screenshots :)
&gt; I'm not quite sure because I don't know the actual traits very well, but I think some interfaces don't allow blocking. Something like "please give me your data as `&amp;[u8]` makes it impossible to know if one needs to load more data before the parser checks the length of the slice. Right, I didn't think about that. nom's traits are pretty fine-grained, though, and should support that case. Have a look at [this](https://docs.rs/nom/4.2.3/nom/#traits) to see what you'd need to implement. Parsers supplied by nom only require traits that are needed to fulfill their contract, so you might even get away with not implementing some of them.
What‚Äôs better about Dash‚Äôs search than rustdoc‚Äôs search?
The standard copy action is ctrl + ins. I don't have a mac so I don't know if it works there, but give it a try. What I like about using ctrl/shift/del/ins combo instead of ctrl/c/v is that its easy to select text with the keyboard as well if your hands are already close to those keys. For selection I use ctrl + shit + arrow key for selecting individual characters, or ctrl + shift + (home or end) to select from cursor to the beginning of line or end of line respectively.
I think a good attentive to both dynamic libraries and plugins that run in their own processes is using WASM. You can use a fast WASM interpreter or compile the plugin to machine code on the fly. WASM has a lot of benefits and there are many languages that target it so you can give people a good amount of freedom if you choose that for your plugins.
I'd suggest to use such libraries through C ABI instead of Rust one as Rust's ABI is not stable
Hey, I am also on Veloren's Dev-Team! :) If anyone wants to see some more screenshots: [https://imgur.com/gallery/HPUcsZw](https://imgur.com/gallery/HPUcsZw).
&gt; Useful libraries: &gt; &gt; structopt **lalrpop** actix-web askama itertools diesel crossbeam [pest](https://pest.rs/) is probably a better choice for someone without prior experience writing parsers
Cool, I will take a look as soon as I can. Right now I'm having some problems with a failing hard disk...
I haven't worked on it for a while *and* it's not finished at all, but I have a project that helps do that safely. It's inspired by the OSGi module system Java has that supports dynamically loading and unloading shared libraries, and builds a service abstraction on top of it that lets you write code without caring too much for dynamics. It's not implemented yet (though close) but references to a shared object are tracked and when a lib is marked as uninstalled and there are no more references, it can be safely unloaded. That was also my first Rust project and I believe there is a small safety bug that I plan to fix (it is only a problem if you drop the container before you drop service references). I would like to return to the project and finish it in the upcoming months, and I'd like to add wasm support so it can load either native shared objects or wasm modules (which is good for untrusted code).
Hi! I'm trying to conditionally swap the bindings to two vectors. I understand what is happening and why, but it would help me out if someone could comment on what the best way to write this is. Playground: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=065fffeda471e41a82bd6055e20ce253 #![allow(unused)] fn main() { let (x,y) = (vec![1,2], vec![3,4]); let (x,y) = (y,x); println!("{:?} {:?}", x, y); let (x2,y2) = (vec![5,6], vec![7,8]); if true { let (x2,y2) = (y2,x2); println!("{:?} {:?}", x2, y2); } println!("{:?} {:?}", x2, y2); } Thank you!
The way I do that process is usually I will be coding and need something. Lets say it's a parser combinator from combine. I already know the modules in combine and that the Parser trait has a bunch of things too. When I have a problem, I know exactly where to look for it. If I don't find it, I ask what the idiomatic way to do it is in gitter or discord. When I need something on Iterator I usually open the iterator doc page and ctrl+f for Result&lt; if I am looking for something that works with results, Option&lt; for stuff that works on options, bool sometimes. I try to find the most readable and concise way to do something rather than going right to Iterator::fold if I can help it. With Iterator, you also have to be aware of: the Extend trait, the FromIterator trait, and the IntoIterator trait. IntoIterator is critical for turning an Option into an iterator or similar, but you also need it for knowing &amp;Vec implements IntoIterator. When you need more combinators (like fold_results()), you need to crack open the itertools docs. itertools is a crate that has the slightly less used combinators, but I usually find myself using them pretty often. With the advent of lexical lifetimes, I typically find that std::mem::{replace, swap, etc} are all useful for the few corner cases lexical lifetimes cant quite solve. Sometimes its actually necessary for correctness, but I don't worry about it much and I just appease the borrow checker because it's usually right. Just look in std::mem and you will find some safe memory manip routines that might help you. When I am coding, I am also usually thinking "oh, I need some data structure that can do x". I have found that crates.io is really bad at searching, so just search "rust lang x" or just "rust x" on Google. Then open the crates.io pages for the repos you see, look at who depends on them, look at how much they are being downloaded recently (are more people downloading it or less over time?), read their readme, then open their docs page and just briefly see where everything is. Many crates in Rust have about 4 things exposed in their root. You can just see how easy it is to do exactly what you want. I typically choose the library that makes it most concise/clear to do exactly what I want. If it doesn't have the functionality, file and issue and send a PR to them rather than implementing it in your crate or nobody will be able to discover and reuse it, which is an important quality of Rust's highly modular open source. Not every library is small though, but in that case it's probably a big part of your application, like doing parsing with nom/combine, rendering with glium, etc, so you should know where everything is in the docs relatively (oh, the textures for glium are in textures, the opengl context stuff is in glutin). Some libraries are big when you only need a small part, like nalgebra, but they typically offer smaller crates that offer the functionality of just a piece of the main crate. I actually don't think nalgebra does offer modular crates, but that's probably something that should be solved another day. Don't forget to generalize your XY problem in your head until you have the most abstracted form of the problem before looking up the solution. That will give you the best chance at finding something that does what you want. It might be that you use a tool intended for something unrelated (like document word similarity) to do something else (like image feature similarity). Ask questions in the Reddit, Discord, etc as well!
Not to forget middle-endian, which isn't used widely, but required for completeness sake.
...or expose and consume the C ABI. One of the things I've always wanted but don't trust myself with `unsafe` enough to implement myself is a "rust to rust" binding generator that provides an API comparable to `rust-cpython` but produces and consumes crates which marshal and unmarshal Rust's types through the C ABI. (Essentially building a third-party stable ABI on top of Rust's C ABI support.)
If I had to hazard a guess, maybe it's for pages that it hasn't scraped + created a static page for yet?
Right, thanks. `Shift+ins` is the cut action. And yeah, it's very handy and easier to use than the ctrl+C/V scheme. But most importantly, it works *everywhere*.
Thanks for this. I looked at Tokio a while back to implement a custom peer-to-peer protocol that was still in its infancy. I couldn't work out how to actually get the stack to work how I desired. This article might just be the key that allows me to return to it and take another run up.
this is neat! i am still new to rust so i don't really trust myself with contributing, but i'll keep an eye on it!
typo regarding ignore for walking a filesystem :)
Also be careful of with_capacity though or you can run out of memory pretty easily on some workloads.
Screen and vim support selection with different keys - enter select mode, select what you want, exit select mode. I've found no way to make it working as easy and as comfortable as on windows and most GUI editors - with shift and arrows
&gt; Rust is memory safe, so we can't just let you put grenades in the stack. Therefore we make them inoperable at compile time. If you really need access to live grenades, try a C module called via FFI. got eeeeeeeem
I struggled a lot when I first started to just get *something* working. But after a while I felt like I was starting to "see the matrix". I'm far from an expert but if you have any questions you can shoot me a message. If I can give you a hand, I will.
I have had situations where I have profiled with flamegraph and it was clear that adding #[inline(always)] actually made a difference (in release mode). This was about 2 years ago though, so the compiler/llvm might have improved. I have only recently got into some data structures code that could require inlining that I have benchmarks for, though I am currently in the stage of making more trivial optimizations.
Very kind of you - I think the major issue I had is that I needed to get a proof of concept of the system up and running quickly (so as to demonstrate the path we were taking was viable), and so didn't have time to do that in the past. Now we have the system up and running, using a makeshift solution using threads, channels, and a working protocol library over websockets. So the challenge next is "get the plumbing good", rather than "I don't even know what pipes we need" as was before. If anything crops up, I'll ask!
Unlikely
I always recommend that people start by watching Scott Meyers's talk, [Cpu Caches and Why You Care](https://www.youtube.com/watch?v=WDIkqP4JbkE), and reading [Mysticial's StackOverflow answer](https://stackoverflow.com/a/11227902/435253) explaining how branch prediction works. They're a good introduction to the architectural concerns which are likely to affect your performance at least as much as any optimizations tweaks you might apply above and beyond just using `--release`. (And they're a lot easier for a newcomer to get into than Ulrich Drepper's 144-page treatise.) In fact, CPU caches are a big part of the reason Rust uses stack allocation by default and [you don't want a linked list 99% of the time](https://rust-unofficial.github.io/too-many-lists/#an-obligatory-public-service-announcement). Beyond that, profile profile profile. Never make an optimization until you're ready to profile the difference with a representative workload because, even if your assumptions are correct, it's possible that the optimizers are smarter than you gave them credit for and all you did was make your code harder to maintain... or, worse, they're not quite smart enough and all you did was to inhibit an optimization and slow things down. For micro-optimizations, rely on the [Criterion](https://github.com/bheisler/criterion.rs) benchmarking library and learn where it's necessary to apply the `black_box` function to prevent your benchmark test cases from being optimized away for having no observable effects. Criterion knows how to compensate for the unpredictability of the host system, it's well-documented, and it'll produce all sorts of useful output for understanding what's actually going on, performance-wise. Finally, add this to your `Cargo.toml`: [profile.release] lto = true codegen-units = 1 opt-level = "3" (`codegen-units = 1` kills off parallel compilation to gain more effective link-time optimization.)
Yeah I'll admit "nobody should ever use it" isn't exactly true, it can make a difference when LLVM is extremely stubborn to inline something, and it might also be required for correctness when in a very restricted environment (eg. you don't have a stack, or something else still needs to be set up).
Aside from tips and tricks (which are already mentioned in this thread), humans are notoriously bad at guessing where there is a performance hit in a program. That's is why [profiling](https://en.wikipedia.org/wiki/Profiling_(computer_programming)) is the king when it comes to performance optimizations. However, since you are new to system programing, perhaps there are a lot of things about low-level coding that you can learn. Data structures and algorithms are the crucial ingredient here. Choosing the right way to layout you data in memory as well as the proper code to process it, can give you orders of magnitude gains that are much harder to achieve though micro-optimizations. Since I've learned about this bit by bit over time, I don't really know where you can find some comprehensive learning material about this but I'm sure there are plenty of great resources out there if you search a bit. If you really want to squeeze every bit of performance from you code, you also look into how modern hardware actually works. Modern processors have a bit of super fast memory (cache) and you can get your program to run much much faster if your code takes that into consideration. Search "cache friendly code" to learn about that. There are some pretty good videos about that on youtube. Also you can look into [SIMD](https://en.wikipedia.org/wiki/SIMD). Also regarding SIMD, you don't always have to do it "by hand". There are some ways of writing code that help your compiler [do it for you](https://en.wikipedia.org/wiki/Automatic_vectorization). Don't relay on this however, since different compilers, or even different versions of the same compiler, can often give you mixed results. High level coding, done in languages like python will most often ignore the underlying hardware. However, if you know you hardware and use it properly you can get performance that would otherwise be impossible no matter how much optimization you do on you code. Note that most of this stuff applies to a bunch of different languages, not just Rust. Even languages that have a heavy run-time like Java or C# can heavily from this.
One thing that I am missing from docopt is that I can format the help message a bit nicer compared to auto-generated (in terms of formatting) one from clap. It probably is not an issue most, but hey OCD is not a condition, but a way of life!
Thanks, didn't know that ALE was a LSP client. One more thing, its seem that for Rust we need to have lsp for autocomplete by ALE (with rls installed), can you correct me if I'm wrong. This is one on help page of ALE: 3. rls -- If you have `rls` installed, you might prefer using this linter over cargo. rls implements the Language Server Protocol for incremental compilation of Rust code, and can check Rust files while you type. `rls` requires Rust files to contained in Cargo projects. So I try to follow as u suggest not to use vim-racer by: * Remove vim-racer * Try config ALE It's not seem to work. Do you have experience to only use ALE and got all those 3: auto complete/error display/ jump to defination for rust?
What is the game about? From the image it looks like a Minecraft clone but there is no description on the site beside "open-source mmorpg". What are the gameplay mechanics? How do you play it (browser or download a binary)?
You need to percent-encode the closing paren in your profiling link.
I looked into hyper, it's exactly what I need! It was so much easier to set up
Sorry I don't really know how and why I need to do that. I just used reddit's UI to attach the link. Can you help me do it properly?
They're not added to the prelude :(
I don't have the time to contribute code but I'm at the very least going to poke around to see what I can learn. Maybe I could contribute some docs of you need?
I forget the proper way to percent-encode *any* character, but, for basic ASCII characters... ssokolow@monolith ~ % python Python 2.7.12 (default, Jul 17 2016, 01:21:14) [GCC 4.8.4] on linux2 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; hex(ord(')')) '0x29' Take that `29` and replace `)` with `%29`in your URL.
WebAssembly is a language?
You think you miss typed there. Cut is actually `Shift+Del`, `Shift+Ins` is paste.
I certainly understand that. I've just wasted enough of my life and my motivation on burning myself out chasing perfection that I've got a different perspective on it. I still make use of clap's option to define a custom template to apply what tweaks I can so structopt produces output that's in-line enough with platform conventions to satisfy `help2man`.
&gt; Thanks, didn't know that ALE was a LSP client. One more thing, its seem that for Rust we need to have lsp for autocomplete by ALE (with rls installed), can you correct me if I'm wrong. Yes. &gt; This is one on help page of ALE: 3. rls -- If you have rls installed, you might prefer using this linter over cargo. rls implements the Language Server Protocol for incremental compilation of Rust code, and can check Rust files while you type. rls requires Rust files to contained in Cargo projects. &gt; &gt; So I try to follow as u suggest not to use vim-racer by: &gt; &gt; Remove vim-racer &gt; Try config ALE &gt; Correct. &gt; It's not seem to work. Do you have experience to only use ALE and got all those 3: auto complete/error display/ jump to defination for rust? I've used it before (I recently switched to another LSP implementation for unimportant reasons), although I can't say that everything was working because VIM is not my primary editor. What I had was basically: let g:ale_completion_enabled = 1 let g:ale_linters = {'rust': ['rls']} let g:ale_fixers = { \ '*': ['remove_trailing_lines', 'trim_whitespace'], \ 'rust': ['rustfmt'], \} let g:ale_fix_on_save = 1 Before trying that, make sure that `rls` is in your `PATH`.
Right. By the way, why is it that I have to do that? And why doesn't reddit's UI do that if its important? I'm not trying to be condescending, I'm genuinely curious as the link works fine on my computer.
[This](https://github.com/mdn/webassembly-examples) might help
Thank you very much for your response! That is very helpful. &amp;#x200B; If I can push my luck with a follow up question, the documentation for ndarray suggests that they "\[p\]refer higher order methods and arithmetic operations on arrays first, then iteration, and as a last priority using indexed algorithms". Would it be correct to read that to mean that writing a loop instead of using for\_each incurs a performance penalty if `target` and `src` are array types for ndarray?
Thank you very much for your response! That is very interesting. I will keep that in mind for future code.
For reference, the definition is *% of developers who are developing with the language or technology and have expressed interest in continuing to develop with it*. This year's (2019) number is 83.5%. 2018 - 78.9%, 2017 - 73.1%, 2016 - 79.1%. First place for 2015 was swift at 77.6%
Old Reddit and some Reddit clients use Markdown renderers that aren't smart enough to tell the difference between a closing paren in a URL and the end of the `[title](url)` markup. We see a `profiling)` where the "profiling" is hyperlinked and the URL that's actually linked to is https://en.wikipedia.org/wiki/Profiling_(computer_programming
https://areweideyet.com/ IntelliJ Idea
CLion integrates a native code debugger, so you probably want that. I _think_ IDEA Ultimate has that too now, but not 100% sure.
I'm not dyslexic, but I do find the formatting and navigation a little heavyweight. I've [annotated a screenshot showing a number of potentially distracting elements](https://i.imgur.com/TDTcrEv.png). These are all used for a reason, in some cases to allow progressive reveal of more detail, to highlight clickable links, and the like, but if you add them all up together, they add up to a lot of visual noise that can be hard to filter through and find the content that you're looking for. In addition, while the progressive reveal of information with the `[+]` and `[-]` controls does help to reduce the amount of overwhelming information from a large number of trait implemetations, it adds additional clutter in the form of UI elements, and it makes you have to dig deeper to find some information that might otherwise be visible at a glance. Let's [take a look at Go's equivalent](https://i.imgur.com/S9i7PBm.png). There is a little bit of visual clutter, in the form of some boxes and highlighting of the anchor I navigated to, but overall, there's a much higher ratio of content to clutter. There is only one color used for links, as opposed to Rust's docs having a different color for each kind of type you're linking to. There aren't horizontal rules all over the place. Even if you go up to the top of the page where there's navigation controls, the search box is much simpler, and there are fewer UI elements.
I guess rust is really a love it or hate it language. I know plenty of people that hate rust, but since it isn't very widespread profesionally the people that hate it won't identify themselves as working with the language, because why would you if it's a personal project. If you look at it in this way the numbers really make sense.
Right, my bad.
Tracking issue: [https://github.com/jwilm/alacritty/issues/50](https://github.com/jwilm/alacritty/issues/50)
If there is no `alacritty.yml` file in home dir, alacritty will display a blank terminal, and use 100% CPU. Is that intended?
Ok, thank you. I fixed the link. I'm using the new reddit so I couldn't see the problem. Although I find it bizarre that a website with a quarter of a billion users can't handle a simple and common character in urls. But what can you do? Things are the way they are.
The ndarray warning is against writing code that says `target[j]`, because ndarray must do a bounds check in the square bracket operator to ensure your code is memory-safe. Iterators can do a single bounds check. Yes, we're handing this code to a good optimizer but they're rather poor at removing the many unnecessary bounds checks. You should expect a for loop and a `for_each` to be the same speed if there's no indexing going on, as above. The `for_each` will be slower in debug mode because it introduces more function calls, but the LLVM optimizer is _very_ good at fixing that kind of code, as opposed to the bounds checks.
This looks interesting, do you have any set of tasks that you would a new person to work upon? I come from C++ background and have been doing bit of rust just as hobby, I would like to contribute a bit if you can come up with a task that is good to start with
The engine rewrite is still quite a compact and well-documented codebase, so it's quite a good tool for those wanting to learn more about Rust gamedev. We have people working on it most day, and we're very open to discussion on the Discord.
lol what? How would one even know that without knowing your specs? Which you did not specify here? Also this is the subreddit for the Rust programming language, not the Rust game. Just turn down your settings until you reach 60fps. You should be able to figure this out all by yourself.
Oh man ligature support is the only thing keeping me off of Alacritty. I want to get off konsole so bad but I am totally addicted to ligatures now. The day that gets added is the day I make the permanent switch.
Clipboard support still is a big issue, other than that it should be working pretty well now.
Make sure you're building with `cargo build --release`, and maybe give gfx-rs a try, it'll get you close to the metal on your GPU.
Currently Alacritty should spawn a config automatically if there is none. Reporting this on github would probably make sense.
It's more that their "fix" is to tell people to migrate to New Reddit... which I find ugly and unpleasant.
It's going to be a download. The game is going to be a multiplayer roleplay game without survival elements. In the beginning it was mostly an attempt to recreate Cube World from scratch (and you can still clearly see that if you're familiar with the game). We are going to have a dynamic world simulation with dynamic and procedural quests, events and much more. It's development is completely made by a community of voxel rpg enthusiasts that want to turn this into something great.
A `CONTRIBUTING.md` file in the main repo would be very helpful with: * code organization and structure * how to build and run
It isn't terribly surprising to me then. Rust is a language people choose to use, typically in their free time, because it is so well designed. Usually a programming language is chosen for more pragmatic reasons like hiring pool or how productive a junior engineer can be in it, which leads to some resentment of that language's rough edges.
That sounds extremely unfortunate but seems to follow Apple's policy of 'there is nobody other than Apple'.
I use this config: key_bindings: - { key: V, mods: Control|Shift, action: Paste } - { key: C, mods: Control|Shift, action: Copy } With that, you can copy with Ctrl+Shift+C and paste with Ctrl+Shift+V. Doesn't take long to get accustomed to.
Fair enough.
Hey, I have been learning rust for a few weeks and would love to contribute :) However as I am still pretty new to the language and have only a few small projects I will probably need some assistance from time to time. Anyway, I will check it out and join the discord server, it seems very interesting :)
Hey, I have been learning rust for a few weeks and would love to contribute :) However as I am still pretty new to the language and have only a few small projects I will probably need some assistance from time to time. Anyway, I will check it out and join the discord server, it seems very interesting :)
I subbed to your dev blog feed and I find it so fun hearing about what you guys have been up to every week! So much passion, I love it!
I use Clion with the plug-in, and I am liking it more than other IDE's such as VS Code. What I can't vouch for though is whether it is any better than standard Intellij with same plug-in.
Thanks! We're hoping to ramp up development soon, so there should be much more technical content coming on the dev blog!.
Awesome, great to hear from you!
I've never had a browser video me.
We're working on adding information like that to the Veloren Book - in time, we hope it'll become a good source for high-level developer information: https://book.veloren.net/dev/getting-started.html
That would be brilliant! The docs for the new engine are fairly decent right now, but there is code being written every day that needs documenting!
what is the plug-in for CLion?
It's going to be so satisfying when you can finally refactor that code to use async/await.
The game is a binary download, although we've floated the idea of creating a web port. In terms of what we want the game to be, we're aiming for an online RPG world that is both fun to explore and detailed in its simulation. I've personally been very involved in developing simulation and generation aspects of the game world, and we have plenty of great ideas that will permit us to simulate civilisations and cities on a large scale. In terms of gameplay, we're looking to place players as adventurers in the world: able to explore and play as they wish, adventuring through the world and completing quests. There is no single defining objective to the game, but interacting with the game's NPCs and economy - as well as with one-another - will be an important aspect of the game.
Its just called Rust. Subtitle, "Rust language support".
Technically you are not missing anything. &amp;#x200B; It is just nice to know that the terminal is utilitizing hardware it wouldnt normally use, reducing energy usage and never locking up. &amp;#x200B; Again you are right though - using xterm will be just as effective.
Your perf link is broken on Old Reddit. It looks like `perf)` and goes to https://en.wikipedia.org/wiki/Perf_(Linux You need to replace the closing `)` in the URL with `%29` (its percent-encoded form) to work around Old Reddit's Markdown renderer being conservative rather than greedy when identifying where the URL stops in `[title](url)` markup.
As much as I love Rust, and believe me I really do love it, sometimes I look at some of Rust code and think my god this is an ugly language. Might just be my second-rate code, though. Hard to tell!
Thanks!
How can I check that?
Heh, glad you enjoy PIN but credit for creating it goes to other people in the group. It's Geoff Lowney's group in Hudson MA, he's the CTO of the developer products division. In our academic work we have been doing some new things with binary instrumentation: PLDI16: [https://dl.acm.org/citation.cfm?id=2908084](https://dl.acm.org/citation.cfm?id=2908084) PLDI17: [https://dl.acm.org/citation.cfm?id=3062344](https://dl.acm.org/citation.cfm?id=3062344) Feel free to email me. My addresses are easy to find on the web, or my papers. Or just click the "contact" button on our [cloudseal.io](https://cloudseal.io) website and I'll see it ;-).
Both the IntelliJ plugin and the CLion Plugin are the same and provided by IntelliJ themselves. CLion just gives you the debugger integration on top.
When using futures-await, you can do ‚ÄúOption 1‚Äù with an `#[async]` for loop calling `tokio::io::read_exact` and using `stream_yield!` to yield events. Unfortunately this feature isn't making it into Rust stable yet.
The best thing about Rust code is that if it compiles (and you've used sane naming conventions and formatting), anyone who understands Rust can read it relatively easily. Rust forces you to write decent code, which is what many hate about it. It takes a while to be productive in it without fighting the borrow checker all the time.
I actually just started learning Rust, first programming language after a semester long course about c++, i hope it's not a terrible choice to learn programming!
Yeah I get that, but that means a context switch is required when switching from literally any other GUI app to my terminal to remember to use SHIFT as well. That's just so prone to error. `pantheon-terminal`'s behaviour is exactly perfect and I don't want it any other way after having used that. Which is obviously a bummer because it means I can't get improvements in other areas for my terminal by locking myself to that app. It's just _so much better_ (for me) that way, that I just can't go back to a non-consistent behaviour.
It's a really exciting language for a number of reasons. I like the way it makes me think.
That sounds much cooler than what I perceived from the screenshots. When you guys mentioned Rust, I immediately thought it was another wasm proof-of-concept game everyone seems to make to learn Rust. Best of luck, this sounds like a cool game to follow! My only suggestion is to add gameplay details in the site such as: &gt; &gt; The game is going to be a multiplayer roleplay game without survival elements. We are going to have a dynamic world simulation with dynamic and procedural quests, events and much more. It's development is completely made by a community of voxel rpg enthusiasts that want to turn this into something great. &gt; &gt; For now, the game has a constantly updated binary download for Windows, Mac and Linux. We hope to make a web-version available soon.
Or as in *un m√™me bien moite*.
Oddly the ecosystem of reusable apps for Django hasn't really ever been an issue for me professionally. For me the killer features are the ORM and the community. If you're tackling a problem with a team Django is a fantastic choice to get people up and running quickly and sustainably. The Rest Framework is also really cool. Actix looks really interesting!! I'm going to check it out.
It really is. A Django like ORM would be helpful. That being said I really like SQLAlchemy, so Diesel is still a really cool discovery.
Thanks to u/ssokolow, I took a look at actix and this should make you happy: https://actix.rs/docs/websockets/
It can be tricky at first. Before Python my first real language was C++, so it wasn't a huge jump for me. I'd also attended a fascinating lecture at PyCon that talked about making Python immutable, so thinking about mutability was something I felt comfortable with as well.
That's really cool! I don't see many Rust jobs in web tech, but hopefully that will start changing.
Ah the lack of named arguments and default values would be frustrating. I've also found for some features (like how to handle calling a reqwest call from a function, which involves the `?` operator) were pretty frustrating at first. It seems like the web framework world is still very much being developed. There's some interesting projects out there though...
Could you elaborate?
&gt;I've had a chance to skim through your repository Oh no. It's awful. Some of it is just disgusting. &gt;but with the current state of allocator support in the \`core\`/\`std\` libraries I see no point in already commiting to anything specific This is appropriate. I'm still trying to learn the language so my agreement shouldn't really carry *any* weight, but the logic sounds good. Keep on trucking! I'll hopefully join you on the Rust implementation side of things once I finish or wind up my PhD. Cheers!
Haven't even used Rust and even I'm starting to love it. /s Jokes aside though, I'm still learning programming and have heard so much about Rust, I can't wait to start learning it! It'd be my first low-level language! :D Plus it's developed by Mozilla so +1 :P
Awesome, glad you like it! About the few questions you have, I did indeed implement a forge-like interface to write Atoms in a memory chunk, but I did intend to later provide an higher abstraction on top of it (probably using `serde`), so you can pass almost arbitrary structures at some point. About the `lilv` binding it is actually a separate crate already! I just put everything in a monorepo/cargo workspace, considering how much all those libs are linked to each other. Although to be honest the more I dug into `lilv` itself the less I liked the idea of having bindings to it, parts of the library are quite inefficient and not that well-designed, and all in all it doesn't do that much other than plugin discovery and RDF parsing, so I think that in the middle/long term it could be a good RIIR candidate, which would allow us to have a full-Rust LV2 stack (since LV2 is just a header file, it has no bindings _per se_). :) In any case, before contributing code, I'd love to discuss more design decisions with you! Perhaps we could discuss all this in the Rust Audio Discourse group linked in another comment above? I just found out about it, and I'll probably join it soon I think. :)
True. I suppose I'm just so used to what Django ORM gives me that I take it for granted. I'm talking about apps like [django-filter](https://django-filter.readthedocs.io/en/master/), [django-tables2](https://django-tables2.readthedocs.io/en/latest/), [django-ordered-model](https://github.com/bfirsh/django-ordered-model), and [django-treebeard](https://django-treebeard.readthedocs.io/), which handle the server-side boilerplate while I use Twitter Bootstrap to handle the client-side boilerplate of CSS reset and a stable of common widgets with a decent default theme. ...similar to how I switched from PyGTK to PyQt back in the GTK+ 2.x era because I got sick of having to either reinvent or find unofficial snippets for things that should be standard, like [working multiple selection plus drag-and-drop in the same TreeView](https://kevinmehall.net/2010/pygtk_multi_select_drag_drop), customizable toolbars and panels, and window state persistence... settings = QSettings() settings.beginGroup("mainwindow") self.restoreGeometry(settings.value('geometry')) self.restoreState(settings.value('state')) (`QSettings` automatically handles picking a platform-appropriate location, providing a fallback chain for user vs. system and application vs. vendor defaults, and providing deferred/batched writing. `restoreGeometry` and `restoreState` are methods on `QMainWindow`.)
A few notes: &gt; I am by no means a tokio expert so if anyone catches any errors or has some tips, I‚Äôd love to hear the feedback. Here's some feedback: Your code does `LittleEndian::read_u32` but the protocol spec says to use the native byte order. You call `src.clear()` but I think this is the wrong solution to the problem you encountered. What you should do is advance the buffer only by the length of the frame, while `clear()` consumes it entirely. So if for example there are two pipelined frames in the buffer, you'd get wrong results. Changing to use `src.advance(14 + payload_len)` should do the trick. I'd change `src[14..]` to `src[14..14+payload_len]`, to ensure malformed messages don't try to reach beyond the frame. I can't be sure but it's most likely that the `to_vec` here `decode_event(evt_type, src[14..].as_mut().to_vec())?;` is not necessary. If all it does is serde decoding, a slice should be enough and would avoid the allocation + copy.
That only made me more confused. What am I looking at?
Can you post a link to the PR?
WebAssembly has a textual version that's equivalent to assembly language in the same way that x86 assembly language is a human-readable form of x86 machine code. Here's one of the snips from a `.wat` file in that repository: (module (func $add (param $lhs i32) (param $rhs i32) (result i32) get_local $lhs get_local $rhs i32.add) (export "add" (func $add)) )
So it's compiling the regex every time? If so, yikes, that's a really bad sign. Not a good look at all, very problematic, etc.
That makes sense. I use none of those apps, but to each their own. At some point making a desktop GUI app with Rust would be fun. I doubt I'll have the time though.
I'm sure people would disagree and tbh I'm not a big fan of Go on technical grounds... but any language, I find Go code to be the easiest to read in the wild, even if it's using heavy concurrency. The syntax is limited and terse, but it makes for pretty uniform looking code in the end. The problem I have with Rust is similar to C++ in that every seems to have their own very different style and there isn't a lot of idiomatic wisdom to draw from. As another article mentioned, even database client libraries in the Rust ecosystem all have very different interfaces for similar systems. The two things I wish for Rust is more adoption of idiomatic paradigms and for the language to introduce more 'sugar' to allow for more terse and standard way of solving common problems (async/futures/common interfaces). I think an interesting approach Go used was putting a recommended DB interface into the standard lib as a guide.
I was dreading moving to OAuth, only because I burnt a lot of oil to get LDAP working, and our front-end developers would need to bill us more time :( Thanks for the suggestion
Thanks, I saw the inth-oauth2 crate. Looks like I can't avoid OAuth :)
The function name and signature is maybe enough to understand a Regex is created. Sometimes a simple shorthand like this is what you want
And with a nice 10% more than second language
&gt; Now I want to make my rust code as efficient as possible. &gt; But I have no idea where to start. I seem to get a totally different perspective from your question than the other folks who answered. Why do you want it to be more efficient? In order to learn general techniques about performance? Or do you have a specific need or target that you want to hit? You might be surprised to learn that you can pour hours/weeks/months into this kind of problem and keep eking out small performance gains (quickly converging to very small ones). But for some business-critical problems, it makes sense to keep pushing here. Your question doesn't have a lot of detail, but I would start by asking myself: is my problem dominated by I/O or computation? For the former, it means if you are reading from or writing to a file, network peer, device driver, etc. The techniques for enhancing the performance are significantly different between the two. Lots of the time, compute-optimization techniques have very little impact on I/O-bound problems and the reverse is also true.
I've been meaning to sit down and look at Actix. It's been slow going since it seems so much more complex and verbose compared to Rocket.
I'm largely OK with building against the same `rustc`. Is stdin/stdout slow compared to other methods of communication? I would assume so, but I've been surprised before.
If ABI stability isn't a major concern of mine, such that the plugins can/will be compiled with each release of the main program, would your recommendation change?
If ABI stability is not a major concern and I'm OK with re-building each plugin when the ABI breaks, would you have a different recommendation?
I'd be interested in seeing this progress!
Still learning rust
I seriously doubt that 70% of developers who write raw webassembly for real projects actually *love* doing so. In fact, I doubt there are many real raw webassembly projects. Calling webassembly a "language" in this context is a stretch, because I suspect people voted not quite knowing what they're doing and meant that they love producing webassembly using a different language, thereby stating that they "love" the architecture, not the language. And I think that's what OP meant?
Love to hear that it's getting read, some weeks it feels like I'm just writing for my own practice :P
&gt;It'd be my first low-level language! :D I don't want to discourage anyone from trying this amazing language. But this language is designed around solving problems other low level languages have with solutions high level languages don't have. That is weird for a lot of people. That's why I recommend learning some basic C (pointers, malloc and memory management etc) and then learn Rust and you'll immediately realize that all the 'weird' or 'uncomfortable things' one has to deal with here are just a clever arrangement of the code to solve long term headcaches.
I'd love to run some benchmark for ya, however i'm not super terminal savvy. Can you show me what I need to run in order to get a more objective comparison? I've really just been eye-balling the differences, I get faster response when I type the same command in fullscreen iterm2. The difference goes away or become undetectable when i shrink the terminal to a smaller window size. iTerm2 does also lag a bit more when i go from smaller window to fullscreen.
I mean, if the question was ‚ÄúDo you plan to continue working in web assembly in the future?‚Äù even I would probably say yes and I haven‚Äôt touched it in months. Survey is definitely skewed towards the benefits of WA rather than love of the ‚Äúlanguage ‚Äú
After [reading up a little on design for dyslexia](https://uxplanet.org/designing-for-dyslexia-6d12e8c41cd7), in particular the presentations linked at the end, I have found that distracting elements play a large role. A couple of other issues I notice now after reading that, that I hadn't noticed when doing my first pass, are that the Rust docs use a serif font, and have very long line lengths; the first line under "Textual Representation" is 127 characters by my count, which is over the recommendations from that presentation of 100 characters max for online text, 65 characters for more comfortable reading for average adults, and 45 characters for dyslexic readers. I also noticed while trying out the docs that the search doesn't match descriptions of items, so if I tried searching for something like "bitwise and" or even just "bitwise", I got nothing. It suggests [DDG search](https://duckduckgo.com/?q=rust+bitwise+and&amp;ia=web), but even that you have to go down to the third item to find the right answer; the first is about the video game Rust, the second a StackOverflow answer about bitwise NOT which might point you in the right direction, but it's the third result before you get the right thing. If you do the [same search via Google](https://www.google.com/search?client=firefox-b-1-d&amp;q=rust+bitwise+and) (even in private mode to make it less likely Google is tailoring my results), the standard library docs are still the third result, but at least the top two are also relevant (though the first result is a link to a page telling you that you're looking at the wrong book, which is really frustrating when trying to Google for Rust topics; there should be no such pages, if there is an old book link it should still give you the old contents, or redirect you to the appropriate place in the new book, instead of a page that gives you a choice between a useless link to the front page of the new book or a link to the last version of the old one). So while I appreciate that the Rust docs are being privacy conscious by linking to DDG, the Google results are better, though even the Google results could be improved by better use of redirects, preserving old links, and possibly `link rel="canonical"` (or sitemaps, or the like; I'm not an SEO expert, I just know there ways to improve Google and Bing's ability to index this).
The point is that you're not working "in" webassembly, so your answer should have been that you've never written raw webassembly. Though admittedly the questionnaire was probably flawed in asking it this way, since not everybody is that pedantic.
In general, dark background are hard on color blind people because the very principle of color blindness is that you do not see a color (uh!) which means that when a regular person sees red you see black, hence the issue. Switching to a white background would solve the issue for all color blind people at once; worst case they'd see black for regular text and black for links, this can be solved with style changes (font, underline, icons, ...). If you still prefer a dark background, then it's trickier. You'll want to use light colors for all text, so that even if the "red" portion of the text is seen as "black", the "white" portion is still mixed in in sufficient proportion to obtain a light grey text.
How does this post relate to Rust?
I definitely wouldn't want my page to have a light design by default, however I definitely have it planned to make it optional to switch to a bright design. Primarily because I feel like I can't blame websites for not having a dark mode when I don't have a light mode. If that also helps with colorblind people, that just makes it even better!
The question is always about what you're benchmarking of course. When talking about latency (time between key press and stuff showing up), then I can definitely see Alacritty being slower. However the throughput should be better with Alacritty (printing random stuff as quickly as possible without user input). We use https://github.com/jwilm/vtebench for benchmarking. Which has some instructions in its readme (though you might need to add `--term xterm`). If you need some more help, feel free to just open an issue and we can discuss that there in more detail.
It is a shame that the async ecosystem is currently fragmented between futures 0.1 and Tokio, and futures 0.3 and async/await. There's going to be a *lot* of updates to the entire ecosystem once futures 0.3 gets stabilized. Even this post will be completely outdated.
What do you do to prevent users from loading a library with an incompatible ABI?
Looks nice, I hope it's not complicated to contribute to it!
That's my guess too. This statistic is mostly about *choice*, and Rust still has a small enough market share that people who use have *chosen* to. Of course, it does help that the most popular alternatives (C and C++) present you with such a horrific experience that afterwards anything sounds great anyway...
Yes, it‚Äôs possible. However, on macOS, if a plugin uses Rust‚Äôs standard library, it cannot be unloaded/reloaded. If your use case doesn‚Äôt involve unloading/reloading, it should be fine.
Wow, I read your repo and the one on the original tool, this seems really cool. However, I am having a hard time coming up with a nice use case when taken in context of a logical file manager being present like LVM or ZFS, that offers snapshot support and the ability to mirror metadata. Could you give an example of how you use it, and / or your thoughts on what I said above?
\* according to StackOverflow
No argument there. I was just answering the "That only made me more confused. What am I looking at?"
Thanks, honestly this is a big help. If `advance` works I will probably also edit the stackoverflow post. The `decode_event` stuff is just there to show where I'd decode the event, most of those lines have been changed in later refactors, appreciate the tips though.
You said that you find Go easy to read because of its limited syntax, but one of your wishes is for Rust to add more syntax sugar. Are these not contradictory? Go typically has only one way to solve each problem which is why the code is so uniform and readable in the wild. The more sugar a language has, the more different ways there are to solve the same problem, the more differences in coding style. See: impl Trait arguments vs. where clauses vs. generic constraints.
Yeah it will be pretty nice, although I'm curious to see what the transition will be like. All of the tokio ecosystem is on futures 0.1. There's a huge amount of code that needs to change before something like this library would upgrade.
Likely
You mean that declarative macro using multiple push down accumulations, tt-munchers, internal rules, and tt-bundling with absolute paths to all items used in the standard library because you need to accommodate for hygiene isn't the easiest thing in the world to read and understand?
I wouldn't feel safe recommending dynamic linking with Rust's ABI for plugins because I'm not aware of any safety checks which would cause plugin loading to fail after an ABI break rather than loading and executing with memory-unsafe behaviour. If I'm wrong and there *is* some kind of ABI version counter in the build artifacts which gets incremented each time the ABI breaks, then, yes, you *can* ask `rustc` to build dynamic libraries using the Rust ABI. (However, given the ABI's unstability, I've never looked into how one would use a dynamic loading mechanism like `dlopen`with a non-C ABI.)
I wish the [Pattern](https://doc.rust-lang.org/std/str/pattern/trait.Pattern.html) trait was stable so we could just use it in places like this. That function could be `fn matches&lt;P: Pattern&gt;(subject: &amp;str, pattern: P, position: usize)` to allow the user to pre-compile a `Regex` and pass it in, instead of asking for a str that gets compiled to a `Regex` every time :-/
I think a lot of that has to do with the maturity of the language. It's still very young. The Database work group hasn't even gotten off the ground yet. I think Rust as a language of choice in greenfield systems projects is still years away. Maybe even longer for embedded projects where there are a lot of commercial targets missing from the T1 support list.
You mention moving to an parallel ECS, and while reading to documentation, the possibility of SPECS is mentioned. Are the current plans to use that, or are you attempting to roll a custom solution? (My personal experience with Specs and Amethyst has been very good, though connecting physics to it could use some work.)
&gt; I'm a researching mathematician and not a programmer by trait (more to that later). (Is "trait" a typo for "trade" or did you `impl Programmer for Self`? :))
https://github.com/seanmonstar/reqwest/pull/480
In my experiences with my own code I'll say that things really do improve with practice but also that it's usually a combination of things that leads to ugly code. I think rust has a lot of potential to be very graceful.
It's highly *unlikely* that these manual hints provide any performance benefit.
I see, cool, i'll play around with it and report back! Awesome project by the way, I can't thank you enough!! i'd love to help in anyway, donation/testing. alacritty is life now ;)
The bigger point here is that if you do have a `Regex`, then `voca_rs::query::matches` literally adds no additional benefit over just using [`Regex::is_match_at`](https://docs.rs/regex/1.1.5/regex/struct.Regex.html#method.is_match_at). I can't really think of any reasons to use `voca_rs::query::matches` at all. It's not bundling its own smaller regex engine and it's not offerring anything over the additional regex API and it's not using its own special string type. The only real thing I can see is that this voca crate is trying to mirror the string API of some other library in Rust. Personally, I don't really see the point.
Working on rewriting a few projects for my startup, which a few I plan on making open source when it comes close to that beta stage, and also cleaning up ones that I do have out. Also diving more into stdweb and yew since I may want to keep the codebase under one language (or close to one language as much as possible).
It's it fine to use `#[inline(always)]` on a trait method that does nothing besides forwarding its arguments to another function?
Ahh I didn't realize that would work outside of `src`, thank you for the response!
Slower than direct calls, for sure.
Can you post all the code (incl. the Golang) and build scripts in a gist or git repository please?
Not everyone agrees, though many do. We‚Äôve had a lot of success with people learning Rust before C. It just depends.
Any feedback, plz share :)
https://github.com/matthewjberger/rust-notifica/commit/eb1e2e5cd6604491530e9655d5437def2f146895 A fix is here.
&gt; I couldn't figure out how to do that starting from a 4 byte slice I think the easiest way is to just write down its elements: `[slice[0], slice[1], slice[2], slice[3]]`.
Everyone has a different experience, but Rust taught me how to better structure code, in general. My code was structured fine before-- best practices by many definitions, but I fought with Rust's borrow checker and improved my understanding of memory ownership-- which has spread even to my non-Rust code: What _should_ own a particular property? Can I better maintain its state in less code? One of my peers commented on a ~15-minute code contribution: "You just raised the bar." Be warned: One of my annoyances is that many frameworks and tools aren't entirely supportive of the _better_ ways, so compromises often have to be made.
I think he wants syntatic sugar to make language more uniform.
It took me a very long time to understand this comment. :)
I'm imagining a bunch of wooden crates and a big fan in a room... :). I also think crates.rs is great!
For me: * It's not a webapp. That means I can have it on a handy keyboard shortcut that quickly shows it when I need it and hides it when I'm done. And that muscle memory just becomes part of my coding process. * It can be used solely with the keyboard. When I'm coding, I prefer to use the mouse as little as possible since it saves me time. * It can do substring searches. If I type 'AtBo', the entry for AtomicBoolean will show up. This is both a shortcut for doing searches faster and an opportunity to accidentally find what I'm looking for when I don't know exactly what I want. * In the same interface, it can search stack overflow questions/answers. This can be either online or by importing quarterly offline dumps. * In the same interface, it can search snippets that I've saved and paste them into my editor, including manipulating the cursor so that I can fill in variable names and other placeholders. * I can add my own annotations to the documentation. If something is confusing to me and I take the time to figure it out, I can write out a short sentence or two to help ease my confusion the next time I hit the documentation. I still haven't had a chance to collaborate on a Rust project yet, but annotations can also be shared among team members. * It's marginally faster. This is minor, since rustdoc isn't slow, but when I'm coding, even a small lag starts to feel jarring. And Dash's search updates immediately on every keystroke. It's difficult to explain, but since I'm looking at the results panel while I'm typing, I can almost search within the current results by typing more characters since each new character has a narrowing effect. * I can use the same interface for browsing documentation for other languages and technologies. If I'm writing wasm Rust, I'm probably going to need a CSS reference too and not having to switch between two completely different documentation interfaces is much simpler. So mostly it just comes down to speed and the ability to integrate it into my coding process. Dash makes it possible to spend less time in the documentation finding the answer I need and more time in my editor thinking about my own code. But the ability to search multiple things at once means that when I don't know exactly what I'm looking for, it's still easier to figure out what I should be searching for. I will say the one place where rustdoc does have Dash beat is in documenting my own code and the third-party crates that I'm using. That's why I mentioned `cargo doc --open`. I know there have been efforts made at converting rustdoc for crates.io crates into Dash docsets, but I've never gotten it to work reliably.
I think a fair number of the Rust haters would be converted if they kept at it. That's certainly how it was for me anyway. I don't think I ever "hated" it, but I certainly spent many hours frustrated with my inability to appease the compiler.
But would you say that those people learning Rust before C already knew quite a bit of programming and were not as a afraid of the new challenges Rust would offer? Learning Rust and facing utf-8 since day 1 because you have to deal with strings at a really low level can be challenging IMO. And I'm not even talking about references, and lifetimes; someone who is not conformable with another programming language can be blown away by the complexity of it all.
Oh wow, I remember this from the Cube World forums! You guys are making fantastic progress. I'd love to contribute :)
When I was deep into tokio I had about 15 tokio doc tabs open from the tokio main page to docs.rs to random blogs.
&gt; I find Go code to be the easiest to read in the wil Indeed. These long lines of if err != nil { return nil, err } are very soothing.
You're welcome. Perhaps someone should extend criterion's documentation with a more complete example so this question won't come up too often in the future...
Thanks for the clarification! Looks a bit like an intersection of lisp and assembly
I kind of agree. I remember when I first saw Haskell and I thought the idea of all variables being read only was both pointless and silly. Today 99% of my variables are read only. It doesn't really matter on a small code base, but it makes a lot of sense on larger code bases. A lot of Rust's design decisions are *"that helps on a large code base"*. It often doesn't really help much in the small.
No. At most you want an `#[inline]` on that, but you really shouldn't need anything. Building with LTO and `codegen-units = 1` can improve performance for the entire crate and is likely a better alternative if you *really* need the performance.
I've seen methods sometimes called \`as\_something()\` and others called \`to\_something()\`. Are the \`to\_\` vs \`as\_\` prefixes conventions which mean something?
Sure, if you're going to write plugins only yourself, it is fine.
One of the workshops at RustFest Paris was about efficent code. The isntruction for the workshop area available here: [http://troubles.md/posts/rustfest-2018-workshop/](http://troubles.md/posts/rustfest-2018-workshop/) This includes a project to work on, and steps and instruction for how to investigate and fix the performance problems.
Generally, `to_*` consumes (takes `self`) while `as_*` borrows (takes `&amp;self`).
I'm actually really surprised to know this doesn't exist already. Is there something more challenging about it? At it's core it seems like a fairly simple encapsulation/serialization problem? I guess performance would be something to optimize and design correctly for, but is there more to it?
I would think if a language was more uniform looking it would be harder to decipher what each piece does individually, but I've never coded in Go.
Could you explain what makes ligatures so important to you? I can't imagine why they would be useful in a terminal, of all things.
When the link to Rust is not obvious, please submit a *text* thread, rather than a *link* thread, and explain in the text why the linked article is relevant for r/rust.
Maybe you can use something like this to help validate? [https://vinceumo.github.io/A11Y-Color-Blindness-Empathy-Test/](https://vinceumo.github.io/A11Y-Color-Blindness-Empathy-Test/)
Deployed the fixes!
Awesome! I did the same thing! Took a few years but I finally got it down &gt;:3 If you need some peer help I got you
And there's a `clippy_pedantic` lint for it.
&gt; Primarily because I feel like I can't blame websites for not having a dark mode when I don't have a light mode. A world where both options are available would be a good world to live in! I'm personally a fan of light themes. This is usually not a problem, since light themes tend to be the default in most places. I don't like it when people try to enforce dark themes.
Whoops, that's a rather common mistake with me. My brain seems to associate words much stronger with their pronunciation than their spelling. Occasionally, these things slide under my radar. I wish I had done it on purpose, though. That's actually quite funny.
I agree. Love Rust, but whyyyyy is it snake_case instead of lowerCamelCase! fn type_list&lt;'a&gt;(dex: &amp;'a DexFile&lt;'a&gt;, off: u32, parse_cls_desc: bool) -&gt; Vec&lt;&amp;'a bstr&gt; { fn typeList&lt;'a&gt;(dex: &amp;'a DexFile&lt;'a&gt;, off: u32, parseClassDesc: bool) -&gt; Vec&lt;&amp;'a bstr&gt; { I happen to think the fewer glyphs the better. Swift nailed its syntax.
What part of that is difficult/hard to read?
As Centril pointed out on internals: https://github.com/AndreasPK/ghc-proposals/blob/master/proposals/0000-likelihood-annotations.rst &gt; Avoid inlining into unlikely case alternatives. &gt; Produce better code layout. &gt; Better register allocation.
I agree that Go is very nice to read. A big differentiator though is the lack of generics and lifetimes, which complicate Rust code A LOT. This is not the only reason, and Go2 with generics will still be nicer to read, but it is a factor.
Thanks! Technically, executable binary is also a language
I use pycharm with the rust plugin.
I am happily using the Rust plugin on PyCharm
Rocket is not async (yet?), so it using a threadpool which is not optimal from perf. perspective. For most applications this is actually OK, especially if you put it behind a Nginx or something. If you want high-performance, you'll have to use some async framework. Go has lightweight threads build-in, which will be slightly slower than async, but quite much faster than a thread-pool-based solution.
"developing with the language "or technology"" WA is a valid technology to be developing with.
`quicksilver` doesn't support `asmjs-unknown-emscripten` or in fact the `libc` crate doesn't support `asmjs-unknown-emscripten` Or I assume so [as it is not a valid target](https://rust-lang.github.io/libc/#platform-specific-documentation). Well actually [`slice-deque`](https://docs.rs/crate/slice-deque/) doesn't support `asmjs-unknown-emscripten`. It seems to be a dep sitting in-between `quicksilver` and `libc`. Possibly `quicksilver` defaults to `slice-dequeue` as a _default dependency_, and isn't expecting the `asmjs-unknown-emscripten` target, so it assumes _default_ means running on a linux computer, ans `asmjs-unknown-emscripten` slips through the cracks?
`snake_case` is easier to read and makes it easier to manage acronyms.
That seems like an interesting project but I don't feel like it demonstrates the issues appropriately. At least looking at that page I can pretty easily read the text in all modes so that doesn't seem super effective.
Yes, being experienced with programming is still important. Rust as your first language ever is much harder than rust as your first systems language.
Thanks!
You can easily use CLion or IntelliJ/Idea. &amp;#x200B; Since Rust doesn't have a dedicated Jetbrains IDE, chances are you can use any of them with the Rust and Toml plugins.
I personally find boilerplate very distracting. It has a lot of stuff that‚Äôs not the actual logic. Too much similar things makes me zone out slightly.
It's not that those lines in isolation are difficult, it's that if there are a lot of them, then they can distract from the actual logic. This is true of a lot of Go code. For example, in Go it is encouraged for loops and pushing to arrays rather than functional helpers like `map`. Reading that for loop isn't difficult, but the fact that I have to read it (rather than just going "oh it's a map") distracts me from reading what I'm actually looking for which is the wider algorithm.
Have a look at this: https://en.m.wikipedia.org/wiki/Shunting-yard_algorithm
&gt; facing utf-8 since day 1 because you have to deal with strings at a really low level can be challenging IMO IMO, not as challenging as facing the whole programming blowing up in your face because you've hit undefined behaviour, or read past where you were supposed to in an array. At least Rust tells you where you're going wrong (and gives you a helpful, googlable compiler error). C just fails silently and confusingly.
is there TOML support?
Yeap there‚Äôs a TOML plug-in :)
Yeah pretty much :) I prefer the way CLion / pycharm worked :)
Not much to be honest. I tried a couple of language server integrations, including ale, but lsc just happened to work best for my slightly off-standard setup of running vim on WSL. ALE is great for linting, but I missed the most basic refactoring tool (rename symbol), which is why I made the switch.
Here's the thing, for me at least. *Individual* lines of go code are easy to read; it's very easy to read a short section of go code and understand what it's doing. But because go is *pathologically* opposed to any kind of meaningful abstraction, you're constantly re-inventing wheels and doing things that are very "low level" like managing your own channels.
IDEA doesn't support Rust debugging. Among IntelliJ IDEs only CLion does.
Kate Gregory argues that starting with C basics instead of newer, higher level abstractions present in C++ is very confusing and discouraging: https://www.youtube.com/watch?v=YnWhqhNdYyk This could apply to Rust as well.
`append()`
`unlikely` and `likely` are not standard extensions for compilers they're really just _hacks_ the compilers add in to use backend features which may, or may not exist. The core team (**I am not a member and do not speak for them**) is not really interested in exposing llvm internals. While every major compiler suite (icc, gcc, llvm-clang, msvc) offer these annotation, their usage within `rust` is broader then `if likely( x &gt; 50 ) {` which you see in `C` or `C++` it is more like `if likely(let Some(x) = my-var) {` or things involving `match` To be frank, `rustc` is an over glorified `llvm-ir` generator, and the llvm tells you not to do it. The reason is `likely` vs `unlikely` hinting places restricts the ASM that'll be generated as a result, and often times (long chains of conditional jumps) are rather inefficient when this is generated verses a [jump table](https://en.wikipedia.org/wiki/Branch_table). In the entire Linux Kernel the `likely` vs `unlikely` annotation are only correct ~39% of the time [citation provided (2010) ](https://lwn.net/Articles/420019/). So their value is objectively is of some question. Ultimately [profile guided optimization](https://github.com/rust-lang/rfcs/issues/1220) is more useful, and likely has a path forward.
Actually it makes sense. There are a lot more information directly contained within the source. So if you switch from C to Rust, you need to train your mind again to contain more information. Learning rust before C would be successful if they have great learning capabilities to start with :)
We are using SPECS in the engine rewrite, yes. We'd love your input though!
The rewritten engine is quite well documented and fairly well designed.
I have a project where I did exactly this! Feel free to peruse the code and/or use it: [https://gitlab.com/jrop/rust-calc](https://gitlab.com/jrop/rust-calc)
You can do the inline thing manually if likely_condition { return Ok(()); } else { unlikely_function(); } #[inline(never)] fn unlikely_function() { ... }
+1 for headcache
You're right - exactly what I wanted, thank you so much!
I submitted a PR last night to remove all uses of the never type! Jeb has reviewed it, not sure when it'll be merged.
More to your question, the flow of data in my program goes like this: * Lex the input string into tokens * Utilize Pratt parsing to get an AST from the token stream. At this point, no further transformation is technically needed in order to evaluate the tree. You can just walk the tree depth-first, since the pratt parser creates the structure with the correct precedence. You can get your computed value from there. Traditionally this is called the "visitor pattern" and is known to be slower than other methods of evaluation. Given that I was just wanting to evaluate a math expression, this is plenty fast however. If you wanted to optimize this further (which I want to do purely for educational purposes), you can compile the tree to bytecode which could be interpreted by a stack machine. Since creating a simple expression evaluator shares much in common with compiler design (the pipeline looks similar, albeit, much distilled), I would recommend the following reading: [http://craftinginterpreters.com/](http://craftinginterpreters.com/)
There's absolutely no reason to rewrite it with RPN. However, I'd really recommend reading [this](https://compilers.iecc.com/crenshaw/). It shouldn't take more than a single evening, and it will teach you everything you need to know about parsing. It's made with making a compiler in mind, but I don't think that will be a problem. It certainly wasn't for 15 year old me.
At least for the rewriting part, I think I can help you. I did a similar project a while back, where I took a normal expression and turned it into a postfix expression. I later discovered that what I did was a bad reinvention of the [Shunting-yard algorithm](https://en.m.wikipedia.org/wiki/Shunting-yard_algorithm) For lexing I did something that should never be done again with regular expressions, so I think you are better off looking into one of the parser generators. For a start, its also a lot easier if you don't worry about opertor presedence, which can be quite tricky.
Desktop link: https://en.wikipedia.org/wiki/Shunting-yard_algorithm *** ^^/r/HelperBot_ ^^Downvote ^^to ^^remove. ^^Counter: ^^250002
I just read my response, and I just want to clarify, my implementation does not translate it to reverse-polish-notation-- it just goes straight to evaluation. I left you a more detailed response and a reference that I have enjoyed reading. Happy coding, and may the source be with you
A compiler is on my todo list, so I'll definitively look into it.
Got it. Thanks again and to you.
Another interesting observation is that Rust is more wanted than C++ now (9.5% vs 9.1%). Last year it was C++ (10.2%) vs Rust (8.3%). Looking good!
I think a basic understanding of the pitfalls of C/C++ that Rust fixes can at the very least make learning Rust less frustrating. Fighting with the borrow checker when I first started Rust was annoying but already having experience with segfaults and memory leaks from my time working with C++ helped me see the light at the end of the tunnel.
&gt;difficult/hard to read? This is a red herring. It's not difficult or hard to read and that's not what was being critiqued. It was that after every function that could cause an error, we must manually handle these errors. In Rust we have a simple idiom for this exact case: the postfix `?`. Any expression postfixed with a question mark will propagate errors in this exact way. This makes it super easy to understand the "sunny day path" when that is what you want to program. The "rainy day paths" are usually things we want to handle implicitly by cleaning up resources and returning gracefully. This simple operator cleans up massive amounts of code and ensures more errors are handled because of the lower developer overhead.
There's an examples folder in their repository ( https://github.com/amethyst/amethyst/tree/master/examples ), is that enough or are you looking for a full game example?
It's been my assumption that anyone with the confidence in their skill has enough else to do that they just go straight to writing the C ABI shims by hand. I've honestly been wondering if, maybe, once I've cleared out more pressing TODOs (I've got some backlogged projects in need of maintenance), I should make a best effort at something like it and then post it here to try to lure people who actually know what they're doing to audit it.
To be fair, macros are semantically arcane, too. It's best to avoid writing complex macros as a beginner.
Ideally it would allow for unloading without a restart, but platform specific quirks are inevitable.
I'm not familiar with the libraries you mention, but perhaps you're looking for something like [frunk](https://github.com/lloydmeta/frunk)?
I'm only hesitant to use the C ABI because it seems like it would limit capabilities somewhat. Like custom types being harder to pass back and forth. Feel like pure Rust would keep the main program on "par" with plugins in terms of language features.
I once made a math evaluator in high school. I didn't do anything fancy and I made up the algorithm myself. It essentially was a function called `eval` that took in a string, and a `start` and `end` index and returned a `double`. If I recall correctly, it essentially did the following: * If the first and last characters are parentheses and part of the same pair, increment the `start` index, decrement the `end` index. * Going backwards, find the last `+` or `-` not inside of parentheses, return eval(left_side)+eval(right_side), or eval(left_side)-eval(right_side). * Going backwards, find the last `*` or `/` not inside of parentheses, return eval(left_side)*eval(right_side), or eval(left_side)/eval(right_side). * Assume you have a number at this point, parse it and return it. This has some down sides, like that you won't get a syntax tree. You won't be able to solve things symbolically, or make transformations. I got pretty far with this though and eventually added functions like sin(..) and cos(..).
This is pretty cool! This is what I was looking for.
&gt; Also, how do I specify that I want to read a certain number of bytes defined in the message (e.g. read x amount of bytes after the headers, as specified in `Content-length`) You parse the Content-length and then call `take!(length)`. It's pretty straight-forward.
Thank you for your time! I did see "renderable" and that is a good start. I was hoping for something more complete as I am new to Rust. If I am able to find any I will post them in this thread.
Go is opposed to that because it sees "errors" as just values. There's nothing weird about them - they're not "exceptional". If you want special syntax for a specific kind of value - what about special syntax for other kinds of values? I mean, it *is* annoying, and things *are* being done about it, but "errors are just values" is not necessarily a bad thing?
Please keep these coming! I'm learning tons!
I so disagree with that. Even for C++ knowing C early on would explain a lot if the idiosyncrasies in C++. You don‚Äôt have to teach/learn everything in C, but certain things are really kmportant to know early on, such as c strings and arrays, raw pointers, basic data structures and memory management. These help later on in understanding concepts like RAII and C++ references, move semantics and templated containers, which even higher abstractions like unique_ptr templated container build on for example.
Where are the plots used? What are they for?
with one important caveat, if you want debugging only CLion supports that.
Hot take: It's often the case that clean, simple Rust is very fast by default, especially compared to dynamic languages like JS, but even sometimes compared to C or C++. Bryan Cantrill gave a very interesting talk where he described [his own experience writing Rust for the first time](https://youtu.be/HgtRAbE1nBM?t=2457), and how surprisingly fast the result ended up being. Especially as a newcomer, it probably makes more sense to focus on getting comfortable with ownership and lifetimes, until you get to the point that you can write code using references and iterators without fighting the compiler. (This is famously challenging in Rust, but we're here to help!) At that point, the Obvious Way To Do It will often give you excellent performance results without making you jump through any extra hoops. That said, if you want get multi-threaded performance into the mix, the Rayon library is absolutely indispensable.
Not just you. Rust is ugly, but it works.
I feel your pain, but the most I can recommend there is to use serde with a suitably efficient serialization format and require that any types that need to be passed back and forth `#[derive(Serialize, Deserialize)]`. For example, if you don't `repr(C)` your structs, Rust is allowed to reorder their contents however it wants to optimize their packing. That means that any stable ABI that doesn't use `repr(C)` on the structs the Rust code manipulates will have to do some copying to translate between Rust-internal format and the stable serialized format.
I think people would accept a performance hit in this case, it's also the only thing keeping me away (using urxvt)
Thanks for your thoughts. I agree that go's docs look much cleaner. Although I got used to rustdoc, so I find it easier grasp than go's docs. I am glad that you have opened the issue. And I am curious to see what this will end up with. Could share a link to the issue, once you create it?
I'm really encouraged by this. It means that the 2018 effort and other initiatives are paying off for people at the fringes, not just the 'true believers' of the Rust community
I agree. In both programming languages, errors are values. What differenciates Rust however is they recognized a common idiom and made it easy to type. Originally, we had to use the macro `try` to express this logic. But because it was overwhelmingly popular, they added it as a language feature. You can even override the meaning of the question mark for your own custom types. For instance, it also works with optional types.
Nearly every other language would disagree with that. Almost all use some form of camalCase, as most people find it easier to read. I don't think it's that big of a deal, but I do think camalCase looks much better than snake\_case, but again, it doesn't matter. That shouldn't be what makes it hard to read a language.
[itertools](https://crates.rs/crates/itertools) might also be useful.
Great to see the atomic integer types being stabilized finally!
&gt; That's why I recommend learning some basic C (pointers, malloc and memory management etc) and then learn Rust and you'll immediately realize that all the 'weird' or 'uncomfortable things' one has to deal with here are just a clever arrangement of the code to solve long term headcaches. Can confirm. I didn't "get" what all of the fuss about Rust (and the borrow checker) was about until I started learning C and how much is *not* done for you in that language.
I was the other way around. Rust was the thing that gave me the confidence to learn C
Exactly, this could be selection bias. Rust's footprint is small enough that nobody has to use it unless they want to (unlike having to use it because your company uses it, or the library you need only exists in it, or it's the only thing that works for the web, etc.) This creates two groups - those who love it, and those who don't use it (and thus don't have a strong opinion).
I've started learning Rust a few days ago, and to be honest it's been rough since I have almost no experience with programming languages in general. But anyway, I'm writing a simple program to write "Hello, world" to a file: ``` extern crate directories; use directories::UserDirs; use std::fs::OpenOptions; use std::io::Write; fn main() { let dirs = UserDirs::new().unwrap(); let out_dir; let out_file; out_dir = dirs.home_dir(); out_file = out_dir.join("hello.txt"); let mut file = OpenOptions::new() .write(true) .create(true) .open(&amp;out_file) .expect("Failed to create file"); writeln!(file, "Hello, world!").expect("Unable to write to file"); println!("Wrote to {:?} successfully!", out_file); } ``` It works like that, but then I decided that it should write to the Desktop folder if we're on Windows, and to the Home folder if we're on Linux/MacOS, so I changed something: ``` fn main() { ... if cfg!(windows) { out_dir = dirs.desktop_dir(); } else { out_dir = dirs.home_dir(); } ... } ``` And now it doesn't compile anymore. This is the error I'm getting: ``` $ cargo run Compiling test v0.1.0 (/home/me/test) error[E0308]: mismatched types --&gt; src/main.rs:15:19 | 15 | out_dir = dirs.home_dir(); | ^^^^^^^^^^^^^^^ | | | expected enum `std::option::Option`, found reference | help: try using a variant of the expected type: `Some(dirs.home_dir())` | = note: expected type `std::option::Option&lt;&amp;std::path::Path&gt;` found type `&amp;std::path::Path` error[E0599]: no method named `join` found for type `std::option::Option&lt;&amp;std::path::Path&gt;` in the current scope --&gt; src/main.rs:17:24 | 17 | out_file = out_dir.join("hello.txt"); | ^^^^ error: aborting due to 2 previous errors Some errors occurred: E0308, E0599. For more information about an error, try `rustc --explain E0308`. error: Could not compile `test`. To learn more, run the command again with --verbose. ``` I'm not really understanding the error message. If I do what was suggested and put `out_dir = Some(dirs.home_dir());` the first `mismatched types` error is gone, but then the second one about `.join()` is still there and I'm not sure what to do... I just started reading The Rust Book a few days ago, so I apologize if I'm missing completely obvious. Thanks
I've started learning Rust a few days ago, and to be honest it's been rough since I have almost no experience with programming languages in general. But anyway, I'm writing a simple program to write "Hello, world" to a file in my home directory: &amp;#x200B; extern crate directories; use directories::UserDirs; use std::fs::OpenOptions; use std::io::Write; fn main() { let dirs = UserDirs::new().unwrap(); let out_dir; let out_file; out_dir = dirs.home_dir(); out_file = out_dir.join("hello.txt"); let mut file = OpenOptions::new() .write(true) .create(true) .open(&amp;out_file) .expect("Failed to create file"); writeln!(file, "Hello, world!").expect("Unable to write to file"); println!("Wrote to {:?} successfully!", out_file); } It works like that, but then I decided that it should write to the Desktop folder if we're on Windows, and to the Home folder if we're on Linux/MacOS, so I changed something: &amp;#x200B; fn main() { ... if cfg!(windows) { out_dir = dirs.desktop_dir(); } else { out_dir = dirs.home_dir(); } ... } &amp;#x200B; And now it doesn't compile anymore. This is the error I'm getting: &amp;#x200B; $ cargo run Compiling test v0.1.0 (/home/me/test) error[E0308]: mismatched types --&gt; src/main.rs:15:19 | 15 | out_dir = dirs.home_dir(); | ^^^^^^^^^^^^^^^ | | | expected enum `std::option::Option`, found reference | help: try using a variant of the expected type: `Some(dirs.home_dir())` | = note: expected type `std::option::Option&lt;&amp;std::path::Path&gt;` found type `&amp;std::path::Path` error[E0599]: no method named `join` found for type `std::option::Option&lt;&amp;std::path::Path&gt;` in the current scope --&gt; src/main.rs:17:24 | 17 | out_file = out_dir.join("hello.txt"); | ^^^^ error: aborting due to 2 previous errors Some errors occurred: E0308, E0599. For more information about an error, try `rustc --explain E0308`. error: Could not compile `test`. To learn more, run the command again with --verbose. &amp;#x200B; I'm not really understanding the error message. If I do what was suggested and put `out_dir = Some(dirs.home_dir());` the first `mismatched types` error is gone, but then the second one about `.join()` is still there and I'm not sure what to do... And like I said, I started reading The Rust Book only a few days ago, so I apologize if I'm missing completely obvious. Thanks!
I am trying to use GTK-rs to build a UI for a rust application that currently runs on the command line. I have a file with my GTK UI code that is currently not connected to any backend components. Is there a way to view the UI in its' current state somehow? I notice that if I run `rustc build main.rs` on the GTK code a port is opened at /dev/ttys012 but I don't know how to view it. I am a total rust noob, please be gentle! :)
The % is not for the entire kernel, it was for a single call to `unlikely`. Even that call was correct ~60% of the time (more often than not), but it was not a high enough percentage to be kept
Still at the stage of only making rather small Rust programs, though I have been wondering: What sort of Rust specific bugs emerge at runtime in Rust programs? What should I be on the lookout for? (To give an example: Go leaves freeing resources (memory aside) to users, so a common problem that defaults is running out of file descriptors owing to forgetting to .Close() something somewhere.)
&gt; it is encouraged to use for loops And in fact, that's the only kind of loop (syntactically speaking, and barring recursion). It bugs me that Go eschews keywords like `while` or `loop` simply because they're looping constructs that can be built on top of `for` loops. I find it very useful to be able to differentiate loops by the general pattern they follow. I.e., having `while {}`, `loop {}`, `map`, `some`, `all`, etc. are all useful because they abstract away things that I no longer have to read, because I already know what they do. I've heard it said that Go is a "modern C", but I don't agree that getting rid of common structured programming constructs is a good decision. Nobody (to my knowledge) has argued "`while` Considered Harmful".
I think you're missing the language for "and ($52k and $120k, respectively)"
The most frequent bug in Rust is the build process not producing a binary because the compiler is not satisfied with your code. That is to say: I can't really think of a rust-specific problem that only manifests at runtime. RAII will protect you from leaking resources and safe Rust has no UB, so it's actually really hard to shoot yourself in the foot, excluding the usual correctness problems you could write in any language.
I know I certainly wouldn't. Performance will always be Alacritty's primary focus and it won't be compromised for some feature which likely isn't ever going to be used by a majority of users. That doesn't mean this will never land, but a significant performance impact will certainly not be accepted.
If you spend enough time in Python you would probably just get used to it as a given and it will be easier for you to read... In which case camelCase eventually starts looking like amateurJavascriptNaming (subjectively). Idiomatic C/C++ is snakecase as well (e.g., the standard library)...
The desktop directory does not exist in all cases, so the function returns an Option (which may be of variant None, indicating that there is no desktop directory). Because the two if-branches try to assign a different type to out_dir, the compiler refuses to compile your code. Try this: if cfg!(windows) { out_dir = match dirs.desktop_dir() { Some(dir) =&gt; dir, None =&gt; { println!("You have no desktop directory! This program now stops.); return; }; } else { out_dir = dirs.home_dir(); }
Damn :( Guess if I was going to do this, I'd either need a library written specifically for this purpose that handles all the ABI oddities or use the C ABI that will limit some of Rust's features. Sucks that neither seems satisfactory as an answer, but I certainly got the answer to my question! Thanks much!
Rust lacks higher kinded types for fancy FP stuff. iirc there was a post about monads in rust shared here not long ago.
 I agree, it's C/C++'s convention so I fully understand why it's snake\_case, but I could also give 100 languages more that use pascal/camel than snake (that aren't javascript), haskell, C#, Java, Dart, etc. You shouldn't really group just because someone uses camelCase into being javascript, that's like grouping snake cases into C or Perl, but we're writing rust :P. Tons of languages use both, hence why I said it shouldn't be what makes a language hard to read. If that many languages choose something, that has to mean to at least those people it's easier on either side.
In my experience I get stuck at strings Everytime I try to start a project, I just cannot wrap my brain around it coming from JavaScript/python where strings are so easy.
I do have RLS installed, and the guide does mostly work. The only thing missing was the error/warning feedback. I got that by installing Ale, but then I felt like I had multiple plugins installed doing basically the same job, so I wanted to figure out what the minimal configuration would be.
Sure, which is why its often an optional feature that's off by default so it doesn't effect performance if you don't want it to (iTerm does this). Also I wouldn't assume ligatures are as rare as you think they are, half the team at work uses ligatures (such as FiraCode)
I dunno, I'd say the only ugly part is the lifetime syntax. Everything is certainly explicit, but I'd also say that there's a consistency in the syntax that I really like. There's fewer syntactic forms than in some other languages, which is pleasing to me. You could say that some things like the turbofish operator are ugly, but its really just the natural syntax based on the rest of the syntax rules.
Out of the blue, do you have any specific question about them :P?
Yep, took a while to write up because I also wanted to provide some concrete suggestions. https://github.com/rust-lang/rust/issues/59829
Those two screenshots are perfect examples (Rust: hard to read, Go: easier).
/u/annodomini summed it up better than I ever could
Thanks! I just submitted a ticket with the information from this and my follow-up comment as https://github.com/rust-lang/rust/issues/59829; feel free to comment there if you have anything more to offer.
Working on [abi\_stable\_crates](https://github.com/rodrimati1992/abi_stable_crates),a library for doing Rust-to-Rust ffi, with a focus on loading libraries at program startup. Currently doing the final polish before publishing it on [crates.io](https://crates.io) ,including trying to figure out how to automate the process of compiling the dynamic library crate,so that I can test loading it in CI.
Another option is something like https://hacks.mozilla.org/2019/04/crossing-the-rust-ffi-frontier-with-protocol-buffers/
Nice! I was just wanting this today. I will take a look at it and probably use it too. Thank you! :)
I am not myself dyslexic, but I did a little bit of research on design for dyslexia, and some of it also corresponds to general purpose design principles for usability. I wrote up my findings and suggestions in https://github.com/rust-lang/rust/issues/59829.
Unfortunately resizing doesn't work, manually, half-screen-resize, or via full-screen button. Is there any way to force the X11 backend to compare?
Seems like there is still some overhead with this method, but it seems to be a relatively good way depending on a developers needs.
It's not possible to make this an optional feature without affecting the performance when the feature is off. This would require too much architecture changes and would be completely unmaintainable as a separated feature.
There isn't a complete game example in the amethyst examples, but there are people with games in various stages of completion in our Discord and at [https://community.amethyst-engine.org](https://community.amethyst-engine.org). Feel free to ask in #help or post on the forums. &gt;Short of that does anyone know what version of Amethyst incorporates the Rusty (graphics) crate they created? If you mean Rendy ([https://github.com/omni-viral/rendy](https://github.com/omni-viral/rendy)), the initial integration into Amethyst is scheduled to be done by May 1st. No official version released so far uses it, but the integration work is taking place in the \`rendy\` branch of [https://github.com/amethyst](https://github.com/amethyst). Creating a proper 3D example game is high on our list of priorities for the summer and fall.
Right now, it is not perfect but I am relying on type IDs, which are generated by Rustc by hashing the types (fields etc). Shared types should also use repr(C). The main issue is that any change breaks compatibility, even if it's backwards compatible.
At this point is your world simulated purely on the local machine? Do you plan to have a server source-of-truth for the world simulation (in which case I guess the server simulation will need to be distributed) or do you plan to make a robust, trustworthy, distributed world simulation across peers? If there any documentation of the design process for these shared-simulation questions? Thanks
Perfect explanation! I don't know I missed that... Thank you very much!!!
RemindMe! 9 hours "Reply to this when I'm less tired"
I will be messaging you on [**2019-04-10 08:35:44 UTC**](http://www.wolframalpha.com/input/?i=2019-04-10 08:35:44 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/rust/comments/bb7a6d/veloren_the_opensource_voxel_mmorpg_is_looking/ekic8n6/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/rust/comments/bb7a6d/veloren_the_opensource_voxel_mmorpg_is_looking/ekic8n6/]%0A%0ARemindMe! 9 hours ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
Beep boop. Hey, I'm a bot designed to reply to the RemindMeBot. I'm just here to tell you that the creators of RemindMeBot are blantantly violating one of the biggest bot rules on Reddit. Specifically, that you cannot fire more than one request a second. Of course, I made that up. I just want to start the bot world war. Please start making your own bots, whether they be copy + pasted code, or custom scripts. Become a solider in the bot war, today! Lieutenant /u/YoUaReSoHoMoSeXuAl, signing out. 000000000000000001111111111111111100000000000000000000000000000000000000000000000000000001111111111111000000000000000000000000000011111000000000000000000000000000000000000000000000000011000000000000000000000000000000000000000000000000000
Coming from years of more traditional statically typed languages... Go looks like backwards C to me.
Or at all... in any language.
whenYouAreWritingVeryLongNamedFunctionsBecauseOfDepartmentStandards camelCaseGetsReallyUnmanageableReallyFast.
But... but... Portier already exists, and is written in Rust... :( (disclosure: I sent a few tiny PRs)
Mostly, `unwrap`s I'd say, when you forget to take them out after debugging.
Ideally, yes, one's language of choice should have all the syntactic elements needed to express a program concisely and readably without program-rewriting. Realistically this is impossible for any Turing complete general purpose language, so there will definitely be cases where macros are useful enough to outweigh their complexity.
Rendering glyphs with HarfBuzz likely wouldn't be a perf hit. Most of the world's text is rendered with this system. Also what is your point of reference for the perceived unpopularity of ligatures? [Fira Code](https://github.com/tonsky/FiraCode) is one of the more popular non-default fonts for programmers.
Yes, it's because I use FiraCode. Ligatures are very useful for functional programming languages which tend to use more symbols (Haskell is a good example). I use terminal Vim as my text editor, and lots of of the styling of my editor is via ligatures.
I have not had a chance to put this into action yet, but this article has been really eye opening, and unlike most approaches, it provides a direct assessment of exactly why some performance-critical code is bottlenecked that seems to rely less on guesswork and luck: https://dendibakh.github.io/blog/2019/02/09/Top-Down-performance-analysis-methodology
just so you know you replied twice https://www.reddit.com/r/rust/comments/bb7a6d/veloren_the_opensource_voxel_mmorpg_is_looking/ekh36ve/
I'm not sure this makes it less ugly. The borrow checker can't make you use the builder pattern instead of a 20 argument constructor function. Ain't nothing stopping you from indenting with tabs and spaces. Rustfmt, clippu, the very ergonomic standard library, traits for extension, proper sum types and pattern matching... These make the language more beautiful. But Rust can absolutely be a very ugly language if you don't use your tools right.
Yes, voca_rs is exactly mirroring Voca.js API so that you can use Rust strings just as in Voca.js. I think that's valuable.
x = append(x, y)
For clarity: snake case is *objectively* easier to read than camel case. Multiple studies have shown this (though I leave you to find them yourself).
True, but I haven't encountered code that doesn't use rustfmt or isn't at least readable. That could be my inexperience, I only started using rust about six months ago. I also haven't seen anyone using OOP with Rust...I imagine if you tried to do that you'd give up on the language In a few days.
Funnily enough, after coding in a mix of swift/c++/python most of the time, I find I really like the rust syntax. It's very concise and localized to the call site. But that may be because I also have to look at objc all day too and it's horrendously ugly so anything else is pretty by comparison
Exactly mirroring a js API is generally a yikes!, but anyone can do what they want I guess.
thanks for that. Going to have to take some time to digest it. Either I've grown up using languages where references are... different somehow or I've been misunderstanding them this whole time.
&gt; Wow, I read your repo and the one on the original tool, this seems really cool. Thanks! &gt; However, I am having a hard time coming up with a nice use case when taken in context of a logical file manager being present like LVM or ZFS, that offers snapshot support and the ability to mirror metadata. &gt; Could you give an example of how you use it, and / or your thoughts on what I said above? **How I use blkar** I generally just use blkar for anything that needs long term or robust storage, and want to do it quick and easy. Similar to when you use 7zip to save space, you use blkar to make it easier to recover/repair later. The general command invocation is just `blkar encode file`. Sector recoverability aside, software like parchive2 offers much better forward error correction. However, the parity data is stored as separate files rather than built into the archive like blkar. This may or may not be desirable depending on use cases. So sometimes even when the sector recoverability doesn't matter (say you're storing it in an encrypted partition), the forward error correction built into a single archive is still a desirable feature for me. **blkar vs FS at the physical level** Ultimately you still need to store the said snapshots or mirrored metadata somewhere, if you 100% trust the storage medium containing your snapshots and mirrored metadata (or even backup more generally), then there is no need for any forward error corrected archive obviously. And if you trust your storage medium 100% to begin with, then why bother with backups really, outside of avoiding accidental deletes. The issue is, most storage medium is not as trustworthy as we want after a couple years of usage. Or even for the case of SSD, if they are left unpowered for a few years they may suffer from data degradation as well. And even sometimes the harddisk plates get scratched due to shaking or dropping etc. So overall the idea is, since your backups need to be stored somewhere as well, data degradation/corruption at physical level can still impact your backups, except for cloud storage maybe. For LVM, ZFS, I don't think they inherently offer forward error correction without use of certain RAID levels, but then you need a multi disk setup. There are forward error corrected file systems, but they are often designed for distributing between nodes/hosts rather than offering protection at the physical level on a single disk/medium. **blkar vs FS at the software level** blkar fundamentally is a much simpler software than any file systems, as blkar only follows a very simple archive scheme, while file systems often need to take care a million other things. So I think we'd agree that given same amount of testing effort or budget, you can test a simple software more thoroughly than a much, much more complex one. Now blkar itself is quite thoroughly tested (see [here](https://github.com/darrenldl/blockyarchive/tree/master/tests) for list of tests), and I personally don't think tests on LVM or ZFS are as thorough simply due to their sheer complexity. Absolutely not saying the devs are doing a bad job, it's just inherently ridiculously difficult to test something that big. If they are just as or even more thoroughly tested, please do correct me. So, personally I'd find it easier to trust blkar to function correctly compared to file systems in general. In the context of ZFS or LVM specifically, this means I think trusting blkar to archive my data correctly is easier than trusting the snapshots/mirroring to be done correctly. The specific usage scenarios don't line up fully obviously, so neither one can replace the other completely. **Summary** File systems snapshots and metadata mirroring are both very useful tools for introducing redundancy to your setup, but fundamentally they somewhat assume the backup or mirrored data is then stored on trustworthy medium. In other words, they do not tackle data corruption head on. Blkar and its extended SeqBox format, however, are self contained and designed to tackle data corruption scenarios specifically. So they are tools with quite different design and purposes, but they do share one common purpose of making backups/copies. Finally, I suggest that thoroughness of tests of a file system probably can't match those for a much, much simpler program, due to the significant difference in sizes. And sometimes having something simple and well tested (I think anyway, but I'm biased) as an option is good.
Yep; and the language need not even be turing complete for syntax extensions to be useful. For example, Agda has a mechanism to extend the syntax and it is notably not turing complete as beta reduction is strongly normalizing.
Not to discourage you, but Rust is a very difficult language, and it may be more prudent to get more comfortable in a language that is a bit easier to program in before jumping into Rust.
I hurt whenever, in 2019, an application that deals with a lot of text is released without full Unicode support. What are the blockers for full emoji support on Windows?
&gt;whenYouAreWritingVeryLongNamedFunctionsBecauseOfDepartmentStandards camelCaseGetsReallyUnmanageableReallyFast. when\_you\_are\_writing\_very\_long\_named\_functions\_because\_of\_department\_standards\_camel\_case\_gets\_really\_unmanageable\_really\_fast For anybody wondering
https://whatheco.de/2011/02/10/camelcase-vs-underscores-scientific-showdown/
`when_you_are_writing_very_long_named_functions_because_of_department_standards` `camel_case_gets_really_unmanageable_really_fast`
Note that learning C before Rust can also have adverse impacts as there are C-specifics you will need to unlearn or at the very least be cognizant that you are in a different language with different rules. For example, if you start sprinkling \`unsafe { ... }\` under the assumption that you are in C-like-land, you will shoot yourself in the foot.
[Frunk](https://docs.rs/frunk/0.3.0/frunk/) may interest you.
I really like Rust, but including devs who would like to use it seems very prone to ‚Äúthe grass is greener.‚Äù I know that everywhere I‚Äôve worked people tend to ogle at new technologies and wish we were using them in the belief that they would solve all of our problems and fix everything. Obviously, they never do. They may be better, but not always, and they never remove all of your problems. Devs will switch, realize that they still have to think hard about things that they feel should be simple, and then daydream about the next cool thing that‚Äôll definitely fix things. Don‚Äôt get me wrong, I think Rust is wonderful, and I love writing it, but I don‚Äôt believe 83% of my coworkers would actually enjoy writing in it.
I'd argue more that Go is a "modern Java". It has a moderate runtime and a lot of excellent built-in features for scalable concurrency, especially related to web servers etc
[removed]
Sure, but the same is true in Rust. Errors are just values that happen to implement a trait, `Try`, which is how the `?` operator works. In fact, if your metric for language simplicity is that things are "just values", Rust actually outdoes Go imo. In go, there are many special snowflake behaviors for built in types. `for` loops can only operate on certain built-in types; `make` only works on certain built-in types. Rust, by comparison, hooks everything in through its trait system (`IntoIterator` for loops, `Fn*` for callables, etc), which means that built-in types and user types all play by the same rules.
I usually wouldn't be inclined to post but I'm kind of happy with myself: While writing [https://github.com/ldesgoui/discord\_game\_sdk](https://github.com/ldesgoui/discord_game_sdk) (WIP ugly) I found a fairly clean way to write a mock library for \`-sys\` raw bindings, here's a short example: [https://github.com/ldesgoui/sys\_mock\_example](https://github.com/ldesgoui/sys_mock_example/blob/master/README.md)
As far as I know there is a futures 0.3 prototype named `romio`
I like to write parsers recursively. Write out a grammar (on paper, or whatever) and then write something that takes the token stream produced by your lexer and returns the parse tree. Name it for the root production in your grammar, and every time you hit a new production in your grammar, you make a function call. You'll likely end up with a function for every production in your grammar, with a few helpers on the side. By operating recursively, you can use the call stack to keep yourself organized, and you'll probably only have to consider the next token in the stream. Let's say you're parsing addition and subtraction only. The grammar might look like: exp -&gt; exp &lt;op&gt; exp | &lt;number&gt; So you'll need an exp_parser function, which gets op and number tokens from the lexer. It expects a number first, then an op, then an expression, which is where it recurses. If you want to expand that to multiplication and division, you need to handle precedence, which complicates your grammar. So will grouping via parens. As you add productions to your grammar, you'll add more parse methods, likely one per production. They'll call each other recursively, and you'll need to keep track of your progress through the token stream, and probably provide yourself with a little look-ahead in the stream, to make parsing decisions.
Oh sure. I don‚Äôt dispute that Go‚Äôs type system is weak sauce compared Rust‚Äôs. It‚Äôs weak sauce compared to C# and even older languages too. But is is easier to get going with and you have less of a ‚Äúcognitive load‚Äù when writing code. I used to do C# a lot and would often pause and think of which way is the ‚Äúbest‚Äù way to write out a piece of code, which pattern, which language feature. Go is so stupidly simple you basically have one way, maybe two. With Rust my ‚Äúcognitive load‚Äù is a bit less in some cases compared to C# and a bit more in others (borrow checker, yeah). But definitely more than Go.
I started writing https://github.com/dgryski/go-perfbook which so far has ended up being more about performance optimization and less about Go specifically (although there are still lots of TODOs).
Once you get used to Go you can see the different loops because they're initiated differently. A while loop only has a single conditional statement after the for, for example. You just learn to look at synax to determine the loop type
I have, and it's exactly that. The code is readable, but the intent behind the code is less clear. Everything looks to be solved in the same way, and sometimes is the exact same code copied to multiple places with small variations.
Great, thank you too :)
I mean, I've always wondered about a language where EVERY program compiles, kinda like malbolge, but not at all convoluted. I think that would bring about *the* most creative solutions as it would be challenging to even figure out what makes up a typical program in this language.
And for good reason üòä
Oops, that was C of course. Updated the comment.
I write Go professionally, so I'm aware. It just bugs me that the syntax feels less information-dense than other languages.
I've been refactoring my code to be more idiomatic to Rust, and in doing so I've been moving standalone functions to `impl` blocks for my types. It seems to be making things a lot nicer in some ways, but I'm not sure how to decide something: I have an `Object` type and a `Source` type but I don't know if I should write my program like `object.send_to(source)` or `source.put(object)`. Am I overthinking it? Is there a best practice for this kind of thing?
Have you tried compiling in release mode?
Try r/playrust this is for rust the programming language
What do you mean?
You can look at [https://www.reddit.com/r/rust/comments/aybr4e/rocket\_and\_actix\_web\_benchmark/](https://www.reddit.com/r/rust/comments/aybr4e/rocket_and_actix_web_benchmark/)
What I mean is you're on the wrong subreddit.
I'm in your shoes as well and I'm a Backend Engineer faced with a peculiar problem I KNOW Rust would handle better than Python (specifically, you can mimic Structs in Python but you really can't mimic Traits simply). &amp;#x200B; I'm really enjoying Traits, Lifetimes and Typing and think it's helped me become a better programmer. &amp;#x200B; What's tripping me up the most is error catching (haven't gotten into async yet) and debugging. It's a shift to move from having an good interactive interpreter when debugging or exploring data sets and the lack of that in Rust kind of sucks. &amp;#x200B; But the benefit of having a program that works in a Type safe manner that's faster and probably better organized than Python with the low-level benefits of C is worth the effort.
Seahash was split out and is being developed here: https://gitlab.redox-os.org/redox-os/seahash
&gt; You need to replace the closing ) in the URL with %29 You actually only need to escape the extra parenthesis, like so `[perf](https://en.wikipedia.org/wiki/Perf_(Linux\))`
Oh awesome, thanks for that.
Is it possible to make [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=20cd6e66e2e3e011401d67e80d47e7a9) work? I have a particular function signature which I need to pass around as a parameter, but I'm trying to avoid having long `where F: Fn(...) -&gt; Result&lt;...,...&gt; + Copy + Send + 'static` lines everywhere.
I've heard this before, but don't really understand it (possibly because my main point of comparison is C++; I'm not expecting it to look as clean as Python). What is an example of something you find ugly?
I don't think I've read anything from anyone who "hates" the language; what are some of the complaints you've heard?
Search for shunting yard.
I can totally envision a world where C++ was replaced by Rust and C was replaced by Zig, and that was a good thing
https://doc.rust-lang.org/1.6.0/book/type-aliases.html I think that might be what you want. Sorry i didn't look into your exact use case too much, but it sounds exactly like you just want a type alias to clean stuff up. Good luck!
You can just add a generic implementation impl&lt;T: Fn(u32) + Copy + Send + 'static&gt; SomeFn for T {}
Do you mean [rendy](https://github.com/amethyst/amethyst/milestone/8)?
I‚Äôm architecting and implementing the backend for a social media startup. I have been through a few iterations on data storage. Initially I ‚Äúsketched out‚Äù some ideas quickly with a NoSQL database, and once I started to get a picture of how things were going to work I created PostgreSQL tables, a couple of views, some type definitions, etc. Then I started work on generating sample data and spent a good deal of time on that, working initially in Python while thinking about what the data would look like, and making adjustments to the db schema as I arrived at how certain data will relate to other data. Once I got to a solid idea of what data we are are going to store, and how it relates to itself, I began rewriting the sample data generation in Rust. I now have a very fast, strongly typed data generator, written in Rust. I also did some work initially on populating the PostgreSQL db with this data, but a couple of things stuck out. Sticking the data into PostgreSQL has several advantages but also several drawbacks. So while creating the db schemas and generating a diagram of it was immensely helpful in the initial phase, PostgreSQL will not be how the backend is going to store the data. Nor will any other relational SQL database. In fact, I am going to dump Vec‚Äôs into flat files on disk, and partition the data by userid. On top of this I am going to use bloom filters to quickly get negative answers and approximate counts of data on the externally facing api endpoint server(s), without having to talk to the storage/compute nodes. And on the storage/compute nodes bloom filters will be used as well in place of searching my Vec‚Äôs for certain answers. Right now I am debating what format to use for transportating data between our externally facing api endpoint server(s) and the storage/compute nodes. For data that will be forwarded on to clients, the final format that clients will see is obviously what will be used (JSON). But for data that the externally facing api endpoint servers need from the storage/compute nodes I‚Äôm not yet quite decided. On one hand, using JSON there as well makes sense in terms of the fact that all data then has the same format. On the other hand, Cap‚Äôn Proto or similar could be more lightweight. But it will depend on how much code is required. The less code, the better. Every extra line of code slows down reasoning about the code and more LoC increases the probability of more bugs. Thoughts?
I really want to run rustfmt on some of those examples
I find it funny you posted an article to back up what I'm saying and got upvotes while mine was down voted, but oh well :P. My only problem with that study though was it was only done on 135 people, that's not a very big sample size when they're talking in the 1-3% better results, even though I do agree with what came out of it. Also, as your flare says you're on the rust team, just curious if some of you prefer non snake case too or there was a reason it was chosen, or just to stay close to C/C++?
You need r/playrust
Sorry thanks.
Neat!
*Respected* probably. I don't know about *loved*. :D
Oh, thank you. There was an error when I tried sending it the first time, apparently it did work
A single LSP client is enough, you don't even need deoplete.
Huh. Learn something new every day. Thanks for that. :)
I use CLion with the Rust and Toml plugins and am very happy using that.
Yep, I just want to learn general techniques and places that I should look at to improve performances if I need to.
Thanks again /u/jackpot51. Just put in my PR now :)
Oh no, I am not a newcomer to Rust, just new to coding things where performance matters.
Sorry. I did mean Rendy. I guess rusty must describe myself.
Ah gotcha, my bad. In that case you'll probably get better advice by posting a specific piece of code for people to look at. The advice you'll get will vary a lot from case to case, depending on what the bottleneck is.
Holy shit. Where are these rust jobs? I need one
Thank you so much for your reply. It is awesome. One thing, what are some examples of micro-optimization? I keep coming across the term but I don't have a clear idea what it constitutes of.
Now what would happen if the hashbrown crate went and did `use std::collections::HashMap;` ?
Eclipse has a pretty decent Rust plugin as well. I don't have a lot of experience with it (or rust) but I remember being pleasantly surprised by it when I tried it last year. Apparently they have some refactoring support as well as debugging and a few more features. Like intellij clion, eclipse also has plugins for native development. Worth a mention if you want to look beyond the Jetbrains ecosystem. [https://github.com/eclipse/corrosion](https://github.com/eclipse/corrosion)
Ah okay. Thanks for the advice.
It's not there yet. There isn't even support for collisions yet so I would hold off for a few months before you dive in to rust game development. I have a good feeling about Amethyst and rust in general for gamedev, we're definitely going to see major progress in the next year or two.
But if it's running natively on your platform anyways, why not just use compiled rust code for the intensive things?
This is starting to change. Recently someone started to ask how to compile [novluno](https://github.com/cjschneider2/novluno) on a chat channel I maintain. They are apparently quite experienced in C, C++, and MMORPG free servers, and apparently novluno is best reverse engineering work of Redmoon Online server. They got increasingly frustrated because they couldn't care a bit about Rust but they want to hack on Redmoon Online server emulator.
The main reason I'm interested in Electron is rebuild an old desktop MFC Windows application in Rust. By using Electron I can build the GUI using HTML + CSS + Rust (through wasm-bindgen and web-sys). The workflow used by users of the old MFC application can stay identical in the new ported version, initially. When the time is ready for a new workflow that doesn't involve "Open file", "Save as..." etc. and instead connect directly to web services and indirectly to databases, then I can move the entire application to a normal single page application, served by a normal static file server, with minimal code changes.
In the Chrome Developer tools, under the Audits tab, you can run an accessibility audit and it will tell you whether or not your colors have enough contrast. More info here: [https://dequeuniversity.com/rules/axe/3.1/color-contrast?application=lighthouse](https://dequeuniversity.com/rules/axe/3.1/color-contrast?application=lighthouse)
iMustAdmitIAmNotYetConvincedByThisPart: &gt;camel case style leads to better all around performance once a subject is trained on this style whatDoesThisTellAboutMentalEffort? whyDontWeWriteNaturalLanguageInCamelCaseIfItHasMEasurableAdvantages? likeAMArthonRunnerCarryingExtraWeightIThinkICouldGetBetterAtReadingCamelCase butIThink but i think i would be more relaxed a the end of the\_day\_if\_i\_would\_not\_have\_to.
Do you use C2Rust?
&gt;I can move the entire application to a normal single page application, served by a normal static file server, with minimal code changes. That's actually a pretty good reason.
Is it the ownership thing that confuses you? Like difference between &amp;str and String? Because with format!(), Iterators, and join() (although the latter is clunky), you can do all the same things.
I have used VS Code for a while because IntelliJ Rust plugin was too slow and buggy at the time. Now switched to CLion almost exclusively. One disadvantage that still remains is that it's still quite slow in startup, so for smaller things it's much faster to just use Sublime Edit. Another missing thing is the lack of cross-platform development support in Rust plugin, basically the sources are parsed for the running platform. In VS Code/RLS it is possible to specify the target triple which allows to develop for example Windows apps under Linux.
It was already explained by others, but have a look at https://rust-lang-nursery.github.io/api-guidelines/naming.html#ad-hoc-conversions-follow-as_-to_-into_-conventions-c-conv where such conventions are documented.
I'm not sure about "loved", but "respected" can certainly not be read from the statistics.
How Exciting, How Exciting !
You'd actually be surprised! We have a PR that attempts to make use of HarfBuzz and I don't expect it to land in that fashion because it just can't keep up with the performance of not using it. It's important to note that Alacritty isn't necessarily faster than HarfBuzz in a fair comparison, however it has to worry about a lot less stuff, which allows us to optimize for the single usecase Alacritty has. HarfBuzz also is mostly about rendering blocks of text, so Alacritty's storage model doesn't really fit it properly. Though we are testing different approaches that might make it usable!
You can force the XWayland backend by running `WAYLAND_DISPLAY= alacritty`. I'm surprised that doesn't work though since it seemed to do so the last time I tested with the reference Wayland compositor. Which compositor do you use?
That definitely sounds neat, I'll take a look! Unfortunately it seems like the Firefox accessibility tools are just for completely blind people.
That should be part of the default bindings too, so you shouldn't need to set these explicitly!
I'm not familiar with the issues on Windows, but rendering emojis is non-trivial since they often have a different color than normal text and there might be multiple standards for rendering them.
Yep, works fine with x11 (inc. decorations), has issues under wayland (see screenshot). This is Debian testing, gnome-shell/mutter 3.30.2. https://imgur.com/a/LIDNMp6
Thanks for your detailed response! I now see how HarfBuzz being designed to operate on chunks of text could cause a perf hit. I 100% understand that ligatures are not the main priority of the team and no doubt if this feature does land it needs to be done right. Alacritty is such a cool project and is the only terminal emulator I‚Äôve been excited for.. well ever. Thanks for contributing!
`macro_rules` is not just another macro call and I don't think it's ever useful to interpret it as a macro call. Perhaps it was a macro call in the past and the implementation keeps some traces of it, but now `macro_rules` is an item with weird macro-call-like syntax.
&gt; But in a small code base it really doesn't matter. Note though that this isn't unique to Rust. Many programming languages have features and practices that only matter on large codebases. Like, the first program I learned in a beginners course is: ```java class Main { public static void main(String args[]) { System.out.println("Hello World!"); } } ``` That's obviously for the show value, but a lot of the ways Java works and is laid out are _also_ fixes for problems in large codebases much more then anything else. I would also disagree that ownership does not matter on small codebases, but don't want to digress.
Thank you for your clarification. I agree it is not useful at all and I just feel the implementation of it is interesting. And do you have any pointers for current design and implementation ? i just want to learn more.
Wow, thanks!
&gt; Is there something more challenging about it? You can't expose a dynamic library interface containing generics. (I'm not sure about generics with only lifetime parameters.) That is a significant limitation to the kind of interface you can do, given how prevalent generics are in Rust.
Probably read one of the far-out there zero allocation schemes with the copy on write trait for them.
Micro-optimizations are things like: * What is the fastest way to check if `my_string` is empty? `my_string == ""`, `my_string.length == 0` or `!boolean(my_string)`? * What's the quickest way to concatenate a fixed number of strings? The `+` operator, `join`ing an array, or using string formatting? Generally speaking, they're the kind of optimizations you resort to when all the obvious, unarguable ways to speed the program up (eg. finding a more suitable algorithm or a faster dependency) have been taken and you still need to squeeze out more performance.
Not exactly about Vim config for rust, but anyway, maybe you, or someone else will find this useful. I've used Vim for five years, but switched to [Kakoune](https://kakoune.org/). Kakoune has builtin support for [rustfmt](https://github.com/mawww/kakoune/wiki/Languages#columns-in-the-following-table) and [racer](https://github.com/mawww/kakoune/blob/master/rc/tools/rust/racer.kak). Which means that you don't need any plugins to write Rust code. With LSP plugin [kak-lsp](https://github.com/ul/kak-lsp) (written in Rust) and some simple configurations you can run RLS, which I'm currently using in [my setup](https://github.com/andreyorst/dotfiles/blob/460043302191fb4b880d81bacb1cafe8301e4c02/.config/kak/plugins.kak#L43-L64) for Rust and C/C++.
&lt;3 macros They're an underrated part of Rust, it's a shame people don't learn more about them
&gt; I find it funny you posted an article to back up what I'm saying and got upvotes while mine was down voted, but oh well :P. Did you actually read the full article? I'd highly recommend it because the Discussion section is much more important than just reading the conclusion of the paper. It actually states that underscores are better because it improves reading performance significantly, while writing performance and correctness is largely irrelevant for writing code.
Works good. But some sort of `onefetch --help` would be nice.
I love your attitude. How are you approaching the learning? Keen to know if you find the rust book is approachable. :)
Well if you implement Copy you also need to tell the closures to move (copy) the values and not just the references: #[derive(Debug, Clone, Copy)] struct S(i32); fn plus(s: Option&lt;S&gt;, i: Option&lt;i32&gt;) -&gt; Option&lt;S&gt; { s.and_then(|mut s| { i.map_or_else(move || Some(s), move |i| { s.0 += i; Some(s) }) }) }
&gt; A circular buffer and traits for in-place string transforms It was really hard for me to understand what was it about. It‚Äôs for doing rot13 and stuff like that?
First, thanks for detailed answer. Here are my thoughts about `$expr` evaluation. I'm just expand both macros: [play.rust-lang.org&lt;&gt;](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=8da2440ca6c88053c19481b463f21177) So, I found it quite similar w/o any drawbacks.
The `Copy` solution works - but you do have force the copy: fn plus(s: Option&lt;S&gt;, i: Option&lt;i32&gt;) -&gt; Option&lt;S&gt; { s.and_then(|mut s| { i.map_or_else(|| Some(s), move |i| { s.0 += i; Some(s) }) }) } If you don't explicitly `move` the value, then it will get borrowed instead of moved, or in this case copied. &amp;#x200B; Still, i'd go with match in this case, imho it is easier to understand: fn plus(s: Option&lt;S&gt;, i: Option&lt;i32&gt;) -&gt; Option&lt;S&gt; { match (s, i) { (Some(s), Some(i)) =&gt; Some(s.0 + i), (Some(s), None) =&gt; Some(s), _ =&gt; None } }
&gt;My understanding is that with `match` complires 'knows' that uses of `s` are exclusive and do not violate borrow rules, but in case if `Option::map_or_else` it does not know that `D: FnOnce() -&gt; U` and `F: FnOnce(T) -&gt; U` are exclusive too and it's safe to capture `s` in both. This is spot on. &gt;Is there a way to not to use `match` in such case? Making `S: Copy` does not work Yeah, this error is a bit unfortunate. The fact that both closures borrow `s` here shouldn't matter because only one of the closures will be run and not both, but as you pointed out, the compiler isn't aware of this. If you're willing to make `S: Copy` then you could fix this by having either closure (or both) take ownership of `s` by putting the `move` keyword in front of it. By having one of the closures take ownership of `s` (which results in making a copy here, not moving it), the two closures no longer refer to the same variable. Another way to fix it would be to declare `s` as mutable only inside the second closure (where you're actually mutating it) rather than the outer `and_then`, like so: s.and_then(|s| { i.map_or_else( || Some(s), |i| { let mut s = s; s.0 += i; Some(s) }, ) }) I don't think I'd do that here though, but it might come in handy some other time.
Well, in this case match is fine, but as soon as you get more complex logic in one of the branches, match quickly becomes ugly mess. :( Still, match does not require neither Copy, nor move, is there any chance to explain that to rustc with closures? :)
Thanks for the tip, but the actual unnecessary copying remains. And also not all structures can be made Copy or Clone, so I was asking about more permanent solution. Basically, from my point of view, `match` and `map_or_else` expected be freely interchangeable but they are not. :(
Cool! Thanks for those examples. I might have underrated macros. I noticed you had two copy-&amp;-paste errors at the beginning about the `vec![1,2,3]` macro expansion. The expanded version pushes `1` three times instead of `1`, `2` and `3`. :) Also, the `vec!` macro is implemented in a different way that it allocates the right amount of memory from the start (using the unstable `box [1,2,3]` and then calling `into_vec` on it).
Ah, thanks for catching that! I'll update it. I probably won't include the specific vec implementation since it would probably just be confusing in the context of the example, but I'll make a mention that that's not exactly what it expands to.
To, well, plot the data. Top priority feature for statistics, for instance - not everyone is used to read and understand huge stacks of digits.
Gnuplot is awesome, except the fact it is a client-server technology, i.e. you cannot embed a plotter into your app, but rather call it being installed as a separate service. This may confuse in some cases.
Yes, if you're just passing in a variable, it won't make a difference. However, consider using something like `compute_value()` directly, or even `random()`.
Sure, I'm agree
What are Generics? I‚Äôve got a Python background, and I‚Äôve no clue what it means when it‚Äôs mentioned somewhere.
At the moment I'm reading the book and playing a bit with the code to understand. I have a friend i can ask some questions too. The book seems fine for the moment, i guess I'm going to leave a feedback when I'll finish it or at least i'll be a little more into rust.
Honestly sounds like something NLL should have solved, I'm surprised it complains without an explicit match
In this case you don't and I'm not sure if it will ever work. The lifetimes of both closures overlap - even if one of them will not get executed. As far as I am informed, even the current ongoing enhances to the borrow checker will not solve this. If it is only copy then don't worry about it; Copy types are usually pointer sized or smaller - it should be as fast (or even faster) as a reference anyway.
NLL still doesn't know that `map_or_else` only executes one of the two passed closures, because that's not part of the function signature. The borrow checker doesn't look at the actual implementation of functions that are called.
Putting `#[cold]` on the function may achieve the prediction hint effect. The `inline(never)` attribute just tells the compiler to never inline the function, which is a good idea for code unlikely to be reached.
Hmm, I've seen the frustration of people I know learning Rust lol, so I guess I'll take your advice and pin down some basic important concepts from C first. But I don't know, I'm just really determined to learn Rust because the community just seems great and I really want to contribute as well!
A few years! :0 Also thanks a lot for the offer! I think I'll really need all the help I can get, after reading these replies :P
Yeah, I think I'll try to learn some basic C concepts first.
How to reduce reallocation cost when I use the `push` method of the `Vec&lt;T&gt;` type? I'm implementing sorting functions both in Rust and in C. I'm working with millions of input numbers, so I think the cost of reallocations can really makes difference. I implemented a custom type in C to handle the dynamic sized inputs, which is doubles the capacity when it runs out of capacity (I think Rust's `Vec&lt;T&gt;` works in a similar way).
I mean, Rust is still maturing so I'm sure the frameworks and tools will improve :/
It's useful in cases when the developer knows beforehand which path is highly unlikely to be taken, or serves a use case that's not worthy to be optimized for at the expense of other paths. A good example is handling unexpected errors, panics, etc. In some code that needs to work around the borrow checker, I run into this pattern: fn poll_and_advance(state: &amp;mut State) -&gt; Poll { enum StepOutput { A(A), B(B), Done, } loop { // Borrow state, return early if not ready to transition let out = match state { State::A(future) =&gt; { match future.poll() { Poll::NotReady =&gt; return Poll::NotReady, Poll::Ready(a) =&gt; StepOutput::A(a), } } State::B(future) =&gt; { match future.poll() { Poll::NotReady =&gt; return Poll::NotReady, Poll::Ready(b) =&gt; StepOutput::B(b), } } State::Final(res) =&gt; StepOutput::Done, State::_Poisoned =&gt; panic!("finished already"), } // State transition *state = match (mem::replace(state, State::_Poisoned), out) { (State::A(f), StepOutput::A(a)) =&gt; State::B(transition_from_a(f, a)), (State::B(f), StepOutput::B(b)) =&gt; State::Final(transition_from_b(f, b)), (State::Final(res), StepOutput::Done) =&gt; return Poll::Ready(res), _ =&gt; unreachable!(), // This never happens } } The unreachable catch-all arm at the bottom has to be there for refutability, but I'd rather the compiler know that other combinations of state and output can never occur if it can't look through the `mem::replace`.
kebab-case would be nice, it's a shame that it only seems to work in lisps
Hi Yep, sure. Please bear in mind that I am new to Go and Rust so..be kind . :) Go Application: There is a backend application that calculates factorial. git clone https://xleyba@bitbucket.org/jleyba/calculator.git And the front end application that calls the backend through a http client. git clone https://xleyba@bitbucket.org/jleyba/bank.git Here is the backend in Rust. I am started working on it using Actix-web and it is still slower that the Go version: https://github.com/xleyba/calculator.git Regards J
Use https://doc.rust-lang.org/std/vec/struct.Vec.html#method.with_capacity to create a bigger vec in the first place.
Compared to the C++ code I have to deal with Rust is BEAUTIFUL in comparison. If we're comparing against C# or python then I can understand, but it's a huge improvement over some other languages.
I was actually wondering about `Rc` vs `Arc` last night. Does anybody know what the actual performance overhead is (say in terms of clock cycles?)
I don't know if you have looked at it already, but combine provides exactly this functionality in a generic, albeit fairly complicated way. I believe there are more traits to implement compared to nom if you want to go with custom input implementation, but I did it and had a lot of fun with it along the way. Here's a link to a blog post introducing the feature [Combine 3 - Partial Parsing](http://marwes.github.io/2018/02/08/combine-3.html)
&gt; I mean, Rust is still maturing so I'm sure the frameworks and tools will improve :/ Of course. I was thinking more of the non-Rust tooling, with that comment-- which Rust also helped me improve with their concepts. Zero cost abstractions, memory ownership, and a lot of great things Rust emphasizes aren't priorities in other languages/platforms-- especially dynamic ones.
Should be fixed now!
Um, Racket would like to have a word.
kebab-case is the best case and it hurts my heart every day Ruby doesn‚Äôt allow it.
Go is at the same time a Java without classes, an Erlang without the OTP (and without functional programming), and a C without the bare-metalness and portability.
Right. If you have some transformation implemented for character iterators, like rot13, you could use `char_circle::StringTransform` to turn it into a function that modifies strings in-place.
If you want to compile to WebAssembly there are few alternatives to Rust. Rust might become the de-facto standard PL for WebAssembly.
It would be sooo amazing if Rust was a superset of Zig :D
I don't know off the top of my head, but from memory, I think the only difference between the two is that `Rc` uses a `Cell&lt;usize&gt;` for its counter while `Arc` uses an `AtomicUsize`. So the overhead of `Arc` should be pretty small. I imagine you're only going to notice it if you're cloning/dropping the `Arc` in a tight loop. The atomic might also inhibit some optimizations that the compiler might otherwise perform, depending on what memory ordering is used. (Which is in turn dependent on which operation is in your hot loop. In the implementation, I see `Acquire`, `Release`, `Relaxed` and `SeqCst` all used.) So it might be hard to measure in a vacuum. It's likely workload dependent.
Why is for_each is faster than normal 'for' iteration? Looks like the real fix is to make 'for 'faster than changing everything to for_each?
This might help: https://doc.rust-lang.org/book/ch10-00-generics.html Separately from that, given your Python background, here's a more specific example. In Python, have you ever written a function that can operate regardless of the specific type of sequence you give it? Here's a trivial example to see what I mean: def double_each(sequence): for v in sequence: yield v * 2 print(list(double_each([1, 2, 3, 4]))) print(list(double_each({1, 2, 3, 4}))) print(list(double_each({1: 'a', 2: 'b', 3: 'c', 4: 'd'}))) In Python, this technique is commonly known as "duck typing." You write functions that do a Thing, and you get genericness for free by virtue of the fact that multiple types support the same Thing. For example, in this case, the function can accept anything that can be iterated over. Whether that's a list, a set or a dictionary. Consider, what happens though, when you feed `double_each` something that isn't a sequence: print(list(double_each(5))) You get a runtime exception: Traceback (most recent call last): File "/tmp/iter.py", line 10, in &lt;module&gt; print(list(double_each(5))) File "/tmp/iter.py", line 2, in double_each for v in sequence: TypeError: 'int' object is not iterable Now, how would you write a `double_each` function in Rust? Rust doesn't have duck typing because it isn't a dynamically typed language. Instead, all of the types of your values must be known when you compile the program. So you need some way of telling the compiler what types your function works with. That system is generally referred to as "generics," although there are many different forms of generics. Rust uses something called *parametric polymorphism*. (Pure object oriented languages typically use something called subtyping.) So here's how you might write it: use std::collections::{HashMap, HashSet}; fn double_each&lt;I&gt;( sequence: I, ) -&gt; impl Iterator&lt;Item=i32&gt; where I: IntoIterator&lt;Item=i32&gt; { sequence.into_iter().map(|number| number * 2) } fn main() { let list = vec![1, 2, 3, 4]; println!("{:?}", double_each(list).collect::&lt;Vec&lt;i32&gt;&gt;()); let mut set = HashSet::new(); set.insert(1); set.insert(2); set.insert(3); set.insert(4); println!("{:?}", double_each(set).collect::&lt;Vec&lt;i32&gt;&gt;()); let mut map = HashMap::new(); map.insert(1, "a"); map.insert(2, "b"); map.insert(3, "c"); map.insert(4, "d"); println!("{:?}", double_each(map.keys().map(|&amp;n| n)).collect::&lt;Vec&lt;i32&gt;&gt;()); } This is quite a bit more code than the Python version, but it expresses a similar concept. Its output is: $ cargo run Compiling rust-iter v0.1.0 (/tmp/rust-iter) Finished dev [unoptimized + debuginfo] target(s) in 0.43s Running `target/debug/rust-iter` [2, 4, 6, 8] [6, 4, 2, 8] [2, 8, 6, 4] One advantage of all this extra work, is that if you try to call `double_each` with something that isn't a sequence: println!("{:?}", double_each(5).collect::&lt;Vec&lt;i32&gt;&gt;()); then you get a *compilation error*, instead of an error at *runtime*: $ cargo run Compiling rust-iter v0.1.0 (/tmp/rust-iter) error[E0277]: `{integer}` is not an iterator --&gt; src/main.rs:29:22 | 29 | println!("{:?}", double_each(5).collect::&lt;Vec&lt;i32&gt;&gt;()); | ^^^^^^^^^^^ `{integer}` is not an iterator | = help: the trait `std::iter::Iterator` is not implemented for `{integer}` = note: if you want to iterate between `start` until a value `end`, use the exclusive range syntax `start..end` or the inclusive range syntax `start..=end` = note: required because of the requirements on the impl of `std::iter::IntoIterator` for `{integer}` note: required by `double_each` --&gt; src/main.rs:3:1 | 3 | / fn double_each&lt;I&gt;( 4 | | sequence: I, 5 | | ) -&gt; impl Iterator&lt;Item=i32&gt; 6 | | where I: IntoIterator&lt;Item=i32&gt; 7 | | { 8 | | sequence.into_iter().map(|number| number * 2) 9 | | } | |_^ error: aborting due to previous error This error is actually pretty nice and tells you the problem exactly: `5` is not an iterator. (There's even a helpful suggestion to use a range, which is an iterator.) Hope this helps! Feel free to ask questions about the Rust code.
You might be overthinking it. It's kind of hard to give general advice on this. My bet is that whatever "feels" right to you is probably the right choice. For example, if your operation requires mutating the state of the source and not the object, then I'd probably write `source.put(object)` since `source` is the "thing" being acted on. Otherwise, you'd need to write `object.send_to(&amp;mut source)`, for example. In general, I try to think about arranging my types such that they correspond to the flow of data through my program. That may not help you resolve your particular issue though. It's hard to say without more details. If neither choice is obviously correct, then pick one and note that it might need to be refactored later if a different choice becomes clearer.
My real question is in what context. Do you have a desktop GUI that you're trying to expose plots to consumers of that application? Do you plan to use these plots in a presentation? Are the plots to be used on a website? There are different answers for each of these use cases. For GUI application GNU plot is probably your best bet. For a presentation, GNU plot would be fine but you have other options as well. This involves dumping the data and using a separate application to do your plotting such as R's ggplot2 which is the gold standard. For web, javascript charting is the best option right now, there are many many options here most of which use a d3 backend. For server side rendering of a chart to a web frontend, you can still use gnuplot but it will feel dated.
An `#[inline]` is just fine if it gets the compiler to inline across crates. Enabling LTO and setting `codegen-units = 1` is a comparatively impractical suggestion due to the effect it has on compile times. We also really shouldn't be saying that nobody should ever use `#[inline(always)]`. I realize you clarified it in a subsequent comment, but I've used it quite a bit as a response to measuring performance when `#[inline]` wasn't good enough. Inlining is the ultimate tool at our disposal to make code fast without necessarily giving up on our abstractions. Like all tools, it can be abused. So let's teach people how to fish instead of just handing over fish to them whenever they're hungry. :-) cc /u/boomshroom
This is a great book. :-) Awesome work so far.
As I have used RustGnuplot, it is called from a commandline app and opens its own window with a plot, where you can copy a plot image wherever you want to. Speaking of live plotting - most probably not possible, or I at least could not find a way to do so.
Okay thanks!
From some of the linked PRs: &gt; `for_each` will use an iterator's own implementation of `try_fold`, which I understand to be generally preferable (because nested iterator adapter's will use each other's `try_fold` and be designed for the specific adaptation in a way that promotes performance and inlining. https://github.com/rust-lang/rust/pull/54761 &gt; Using `for_each` allows internal iteration, which can have better performance for some iterators. For instance, `Chain` and `FlatMap` have to check their state every time `next()` is called, but when folding they can just forward to their inner iterators. https://github.com/Amanieu/hashbrown/pull/58
Wow, thanks a lot, it really help to grasp it! What would need to compile burntsushi.clone() to have more awesomeness without burning out the original?
I'd also say that it shouldn‚Äôt, because that way the compiler would expose implementation details that might change between minor updates.
if for_each is faster than for, is it better to replace for i in 0..10 {} with (0..10).for_each(|i| {}) The first is a lot more legible
&gt; What would need to compile burntsushi.clone() to have more awesomeness without burning out the original? An `Arc`, of course. :-) Although, perhaps I'd prefer an `Rc`, because I'm terrible at context switching and would prefer to only be asked to do one thing at a time.
Yeah, I completely agree! Having the implementation of a function be a true implementation detail makes the separation very clear. IIRC before functions could have lifetime annotations, everything was inferred from the implementation? Or so I heard, I'm fairly new to Rust. Maybe I remember it wrong. Either way, I strongly prefer the way it currently works.
When asking for help about performance, one should always do their best to follow this rule: make it possible for someone else reading your question to *reproduce your results*. Without this, the best anyone can do to help you is to guess. This should include providing a complete example that others can compile and run. It should also include providing your own results so that others can compare them. For example, you claim the Rust version is slower, but don't quantify it. Moreover, you should include the *precise* commands you use to compile your program, in addition to the precise commands you use to measure the output. Saying that you use "ab and SoapUI" is not enough. What are the specific commands you ran?
Put the code in GitHub :)
You might want to file an issue [on Github](https://github.com/rust-lang/rust/). Seriously though, wrong subreddit - you probably want /r/playrust.
Dude, wrong subreddit. Go to /r/playrust
As your post is now, you're not providing any info anyone can use to help you, so it amounts to pure negativity with no way of anyone turning it into positivity. If you need help, I've found the community very helpful but you at least need to let people know what the problem is. If the ticket you're talking about is a Github issue, I suggest you link to it so at least we know what you're talking about. Also I think it's worth pointing out that even though people here tend to be willing to help out strangers, they are mostly not getting paid to do so.
So what exactly is slower, computing the factorial or serving the results?
OP if that's what's going on you are honestly not a very smart person.
That's not nice of you to say.
The former also allows for control flow (in particular, `return`). That's about the only reason I use it over `for_each`, but I also had a Haskell stint, so I like the latter even for readability. The latter also makes it easy to stick a `.par_iter()` in there if it turns out to be useful.
All I'm missing now is scroll/mouse support over SSH. Those events seem to get eaten :(
If you come from a Python environment, you can use `matplotlib` via `pyo3` Arguably not a best practice, but here is an example: fn analyze_user_stats(user_stats: HashMap&lt;Login, f64&gt;, _login_group_name: HashMap&lt;Login, Option&lt;String&gt;&gt;) -&gt; PyResult&lt;()&gt; { let gil = Python::acquire_gil(); let py = gil.python(); let ctx = PyDict::new(py); ctx.set_item("plt", py.import("matplotlib.pyplot")?)?; ctx.set_item("stats", user_stats)?; let code = " try: fig, axs = plt.subplots(1, 1, squeeze=False) users, counts = zip(*stats.items()) print(stats) print(users) print(counts) axs[0][0].bar(range(len(users)), counts) axs[0][0].set_xticklabels([''] + list(users)) fig.savefig('acct-stats_user.png') except Exception as e: print(e) "; if let Err(e) = py.run(code, None, Some(&amp;ctx)) { println!("err {:?}", e); Err(e) } else { Ok(()) } }
There's also a Rust meetup in Paris on April 25th. c.c. [/u/imperioland](https://www.reddit.com/user/imperioland) maybe you can add it to the [calendar](https://www.google.com/calendar/embed?src=apd9vmbc22egenmtu5l6c5jbfc%40group.calendar.google.com) ;).
&gt; Rust macros are hygienic But only the declarative ones. A procedural macro can just dump whatever code it wants like defining a type called `Foo` with a field of type `Bar`: If the type `Foo` already exists, the compilation will fail because of a name clash and if `Bar` exists in the scope, it will use said `Bar`. &gt; Rust macros only do code generation Technically :), a procedural macro can have side-effects. You can happily print stuff to stdout and download resources from the internet during build-time!
No it's not, but OP is ranting in the wrong sub, apparently without noticing that obviously the logos and color scheme are completely different. I mean it may not be nice to say but OP is objectively being both snarky and dense if this is the case.
I don't know about the two specific types you're using, but if you wanted to do `target[j] &lt;- f(j, src)` for all j using iterators, you could use: target.iter_mut().zip(src).enumerate().for_each(|(j, (target, src))| *target = f(j, *src)); This assumes that both target and src are slices (or `Vec`s). If they are not the same length, this iterator will only update up to the size of the smaller slice. If src is a `Vec`, you may want to pass it into zip by calling its iter method so it doesn't get consumed.
Or OP could be posting from the Reddit-wide "submit" page, which doesn't include subreddit CSS, or from a mobile app that doesn't include anything at all really.
Can you use a library used by a dependency. Let's you have a dependency in your program that uses Tokio. Can you use Tokio in your program without adding it to the dependencies of your application.
Well, let's not get ahead of ourselves, it was mostly due to intermittency as i didn't alwayd have time.
Huh, I didn't expect this to work but it does. Thanks!
It's impossible to say what's slow here based on what you've posted, but IMO it does seem kind of weird to be using that particular factorial implementation. You could be testing the performance of BigInt, some 3rd party library. Again, it's impossible to know until you've put all the code and results up.
&gt; But only the declarative ones. A procedural macro can just dump whatever code it wants like defining a type called Foo with a field of type Bar: If the type Foo already exists, the compilation will fail because of a name clash and if Bar exists in the scope, it will use said Bar. That's actually what I'm trying to say here: &gt; It‚Äôs impossible to touch local variables, and there won‚Äôt be any naming collisions for variables. You're completely right though, for types there can obviously be naming collisions. &gt; Technically :), a procedural macro can have side-effects. You can happily print stuff to stdout and download/upload resources from/to the internet during build-time/macro expansion! Also technically true of course =P The implication is here that they can't do any runtime introspection, like annotations in many dynamic languages do. They run strictly at compile time, and that's it.
Couldn't quite get a type alias to work, but the solution posted here seems to be what I was looking for. Thanks anyway, I hadn't thought of trying a type alias.
This is really awesome. I was thinking of doing something like this in the future to support ffi between rust and my programming language. Do you think this (or a part of this) could be actually rust independent? Currently I only care about stable definition of structs and ADTs (rust enums) and of course functions. I think that would be huge. I don't particularly care about performance as long as it's not doing something silly inside. Since I intend to generate both sides from the compiler, the complexity of the API does not matter either. Let me know what you think about this:) My language is nowhere near to the state where this is needed but it will be!:)
There is more to it than just large code bases. Rust also forces your application be more inherently secure. Small code bases are often tangentially connected or authorized to touch things in other larger code bases. Hackers go after these systems all the time.
- Out of bounds array/slice/vec indexes will panic. It's pretty easy to write a bug where you accidentally read an index that's too big, but only sometimes. - Similarly, something like Result::unwrap() can panic unexpectedly for things like "the file you tried to open suddenly doesn't exist," if you never tested that case. - Less commonly, you could create an Arc/Rc cycle that leads to a resource leak. - Also rare, if you have a recursive data structure like a Box-based linked list, the default destructor will be recursive too. That means a large instance can blow your stack and crash your program.
This is why everyone should know one of the Lisp dialects. If you run into any of these limitations, you can redesign Lisps on the fly to suit your needs. Lisps for high level, Rust for low level, Python for scripting. I call it the trifecta of the pragmatic programmer.
omg im so sorry ahaha
Last time I used actix (pre 1.0) it was a tiny bit slower than Go with Chi. I think Actix had 48k req/s while Go had 52k it something. But such a small difference doesn't really matter, at least not too me. Version 1.0 of Actix is said to be a bit faster as well, so the gap should be lower now.
I want to first make this feature complete enough in Rust before thinking how to make it work beyond it. The fact that I started with types with a stable layout means that it should not be a problem to extend it beyond Rust eventually,except that I have very little experience doing cross-language type declarations.
Is there a way to expand macros in Visual Studio Code? I can't even click through to the macro to view it's source code.
Porter still uses tokio-core, which has been deprecated for long time
I've implemented a lexer/parser with AST at https://github.com/chmln/asciimath-rs. Feel free to use it as inspiration.
&gt; Since the 2018 edition, macros are **imported and used like everything else**. I always ask myself why the `use` clause for macros skips the exclamation mark. It would be much clearer if it would look like this: ``` use package::my_macro!; ``` because then it would be clear that it's a macro and it's usage is `my_macro!(...);`
The PR mentions iterators that ‚Äúforward to internal iterators, like Chain and FlatMap do.‚Äù For example if you have code like this: let iter = Some(x).into_iter().chain(Some(y)) // ... iter.for_each(f) v.s. the semantically equivalent: let iter = Some(x).into_iter().chain(Some(y)) // ... for i in iter { f(i) } Because [`Iterator::for_each`](https://github.com/rust-lang/rust/blob/3750348daff89741e3153e0e120aa70a45ff5b68/src/libcore/iter/traits/iterator.rs#L601-L605) calls `Iterator::fold` and [`&lt;iter::Chain as Iterator&gt;::fold`](https://github.com/rust-lang/rust/blob/3750348daff89741e3153e0e120aa70a45ff5b68/src/libcore/iter/adapters/chain.rs#L100-L117) is implemented specifically, with some inlining and constant propagation it‚Äôs relatively straightforward to optimize the `for_each` version to: f(x); f(y); With the `for` loop however there is nothing like `&lt;iter::Chain as Iterator&gt;::fold` involved. The loop calls [`&lt;iter::Chain as Iterator&gt;::next`](https://github.com/rust-lang/rust/blob/3750348daff89741e3153e0e120aa70a45ff5b68/src/libcore/iter/adapters/chain.rs#L57-L69) which is very branchy as it has to check the current state at every call. In theory it might be possible to optimize to the same as above, but apparently LLVM does not, or does so less reliably.
&gt; voxel MMORPG I've seen so many failed attempts at this, I hope you guys are the ones to succeed.
It is not always faster. It *can* be faster for *some* iterators. See my other comment.
There's [cargo-expand](https://github.com/dtolnay/cargo-expand), which will show you the expanded version of any file you point it at. I've used it before and it works very well! The fact that you can't click through is probably due to macros only recently being granted "full citizenship" as normal crate imports. I suspect the RLS will catch up soon.
How do I denote the type when using `default::Default()` as the first in a chain of calls? e.g. use std::default::Default; #[derive(Debug)] struct Person { age: u8, name: String, } impl Person { fn aged(mut self, age: u8) -&gt; Person { self.age = age; self } fn named(mut self, name: String) -&gt; Person { self.name = name; self } } impl Default for Person { fn default() -&gt; Person { Person { age: 8, name: String::from("") } } } fn main() { // This works: let defaultPerson: Person = Default::default(); //This doesn't work! let person: Person = Default::default().aged(3).named(String::from("Rusty")); println!("Hello {:?}", defaultPerson); println!("Hello {:?}", person); } This won't compile, with error: error[E0282]: type annotations needed --&gt; src\main.rs:31:26 | 31 | let person: Person = Default::default().aged(3).named(String::from("Rusty")); | ^^^^^^^^^^^^^^^^^^ cannot infer type for `Self` | = note: type must be known at this point
Shouldn't we `use fmt::(trait Display)` or `pkg::(type Foo)` then? Different imported entities already have different meanings and usages, should we treat macros differently?
kebab-case is awful if you're doing lots of subtractions.
Why? It's mostly a matter of taste. Plenty of people will read your post and have no understanding of what you're saying, because they would very firmly take the exact opposite position. And `hTTPParser` isn't more readable than `http_parser`.
I am okay with a subset, without tricky edge cases, it's already much better than c structs and pointers to byte arrays.
Amethyst supports nalgebra, so it should not be that hard to integrate [ncollide](https://ncollide.org/) for collisions? Just looking at it, I don't see anything that would make it difficult to implement a 3D collision system.
Hi Well, I thought I was 100% clear...seems it is my fault but honestly I could not see the reason why... Regarding the code: I have shared the clone command of my code in Github and Bitbucket and both repos are public. What else do someone need to compile it? For Rust I have used cargo build --release, nothing else. Is it enough? Regarding the tests: I have said in my post that I am using ab with 500 threads and 50K request to test the factorial and the endpoints are in the code. It is not enough? Weird! :) Ok, the command AFAIR was: ab -n 50000 -c 500 http://127.0.0.1:9596/factorialIterative/5000 Hope this could give everybody a more clear panorama. Thanks J
For some reason, Utah Rust's meetup is on the calendar but not showing up here. :( Did I do something wrong getting it added?
It looks like bigint implements [MulAssign](https://docs.rs/num-bigint/0.2.0/num_bigint/struct.BigInt.html#method.mul_assign) for various integer types. It might help to simplify the loop, from: for x in 1..=n { result = result * x.to_bigint().unwrap(); } to: for x in 1..=n { result *= x; } Ignoring any optimization that happens, you may avoid creating and dropping two bigints every loop. There has been previous discussion about [bigint performance issues](https://www.reddit.com/r/rust/comments/7w3v77/why_is_my_rust_code_100x_slower_than_python/).
Was this title and location changed recently on this page? https://www.meetup.com/utah-rust/events/260015102/ Last time I checked this page, it said TBD and Needs Location. I'll add it.
Hi Well, this is something that I am trying to figure out. What I see with ab test is that the avg time is bigger than the code made with Go. I have been able to reduce the time by changing a Bigint cast in the factorial code (already pushed to master) but is still slower than the Go version. J
If you link me to the meetup page, I'll add it to the list.
Yes, it was -- are TBD items filtered? That would be good to know!
In my opinion the exclamation mark is a part of the name. To be honest I was confused first when I saw: ``` use log::{info, trace, warn}; ``` and later: ``` warn!("Oh my god!"); ```
Hi Well, it was really fast in Go with similar code but, if you have a better implementation to share with me that allow me to calculate factorial of 5000 (or bigger), it will glad to adapt my code to your advise. I am learning so I assume that my code ain¬¥t perfect at all. Regards J
Hi Go and Rust servers are already present in my post (I have shared the links for both repos). My code is really short and not hard to check IMHO. Regards J
You can use `Person::default()` instead, that should work.
Hi, I'm the maintainer of this project, could you send me a message to let me know where they were having problems? I think I really need to get the \`build.rs\` files in order for linking SDL2 in windows...
You haven‚Äôt shared code much, so I can‚Äôt really help. But why do you need BigInt? Surely it‚Äôs enough to use u128 or something instead?
I don't see any links to any repositories in your post here. I don't see any output that quantifies the results you're seeing. I'm trying to help you get help from people. These are the minimum things one should provide when asking help for diagnosing a performance problem.
Prepend `#[macro_use]` to your `extern crate lib` (if any), perhaps?
&gt; Well, this is something that I am trying to figure out. Then you should test the other route (echo).
Spot on! -- I actually think restricting control flow is a benefit of `.for_each` when you don't actually need to use `return` and such.
No, we're just manually rewriting the tools in Rust. It's small enough that this shouldn't take _too_ long. C2Rust looks amazing though.
Ouch. I remember that I have posted the links but, I know, nobody will trust me at this moment.. :) I have added them, again, at the end of my original post. Thanks!
Ouch. I remember that I have posted the links but, I know, nobody will trust me at this moment.. :) I have added them, again, at the end of my original post. Thanks!
Hi Yes, you are right, I have changed it one hour ago. Performance become better but still slower than Go. Thanks!