I am on the opposite spectrum. I got interested in cryptocurrency in general when I learnt that parity was one of the biggest projects in Rust. :)
Thanks for the reply. Sorry for being naive. I am trying to figure out a project to learn Rust and explore it use case. For example, [sample dll] (http://keterex.com/pubs/an2101.pdf) has following sentence: *"All functions in kxusb910h.dll are implemented as C functions (i.e. they are not contained within a class). The include file “kxusb910h.h” checks if the user’s compiler is C++ compatible and generates the proper import code"* Can I use such DLLs within Windows to communicate with the device? the Use case being that communication of devices in the lab could be done through Rust (and then handle in Python maybe) ?
Thank you so much!
/u/Kimundi has already mentioned the book. This is the second edition which is a complete re-write, and it includes lots of the new features that arrived at Rust. There's also the Rust Cookbook: https://rust-lang-nursery.github.io/rust-cookbook/intro.html. It's a collection of small examples divided into categories (Filesystem, concurrency...). This might be of help. There's the Rust by Example website too: https://rustbyexample.com/index.html. It slightly differs from the Rust cookbook, but it also offers examples in different areas. The docs website: https://docs.rs/ is important in case you want to read up on the different crates, either for knowledge or for a specific use. There was a recent blog post posted on this subreddit: https://www.reddit.com/r/rust/comments/7g9nn0/whats_a_reference_in_rust/. I included the reddit link because the comments might be of help should you need to consult them in the future. I hope these resources help you while learning Rust, and best of luck on your journey :) 
&gt; With your logic, the initial release of a crate on crates.io would be 1.0 and development would continue from then on. Is that such a bad idea? &gt; I have seen shitty crates with 1.0 version numbers and excellent crates with 0.1 version numbers. Which shows how broken it is to use v1.0 as any kind of quality signal, and why all crates should prefer to use v1.0+ for versions that they want others to use. However, I'm not saying crates.io should prevent people from uploading crates with a version number less than 1.0. Like the others said, you can release a v0.1.0 crate to make it easier to use in your other projects, or because you want some very early feedback for a crate that *is not* ready for others to use, with the version number being a very clear marker that "there be dragons here". Quoting the SemVer spec: &gt; Major version zero (0.y.z) is for initial development. Anything may change at any time. The public API should not be considered stable. But crates like Chrono and `libc` have been around since forever. It's hardly "initial development" any more, and worse -- they have tons of dependent crates. So much for not having to worry about breaking other people's code. Releasing 1.0 signals that these crates *understand* that they *are* and *have been* mature crates. They can still release 2.0 and onwards if they need or want, but SemVer makes it a lot clearer what it means to release a bugfix update on v1.y.z, compared to what it means to release a bugfix update on v0.y.z. Technically, *every* release of a v0.x.y crate is a breaking change, if we want to get too technically correct. The Rust community has redefined v0.x.y to have some concept of stability, which has just been bad for versioning in my opinion.
Maybe you need to use bufreader instead of raw opened files.
Hey, I am really curious with embedded developing using Rust lately. I am new to rust, but I have done embedded development using C. I stumbled on this article and would like to make a few questions: on src/led.rs: 1 - Regarding wrapping the memory reads and writes in unsafe code, doesn't it defeat the purpose of using Rust? 2 - I feel that this (*RCGCGPIO).modify(|val| val | (1 &lt;&lt; PORT_F)); is really cryptic and hard to read. The C version of this would be much simpler and more readable. Is there something we could do to improve this? are there other Rust projects that have done this another way? 3 - In the main part of the code the advantage of using code is clearer and we can see that we can use rust nice features (like iterators and stuff), and I guess this is the really cool stuff. So is this the main goal of taking Rust to ARM? having the nice high-level abstractions Rust provides? 
With npm yes 
If they're implemented as C functions, then Rust should have no problem calling them. When they say that `kxusb910h.h` "checks if the user's compiler is C++ compatible", I'm assuming they mean that it has `#ifdef`s tied to compiler-defined values that say "I'm a C++ compiler". I'm not sure how bindgen would interact with such a header but, in the worst case, you could always write the Rust `extern` declarations needed to call them by hand, following the instructions I linked to.
Thanks. Hope to find a way forward in this!
This one is the „semi-official“ one: https://discord.me/rust-lang
i saw the title and was so hoping for a procedural vector snowflake generator. this is pretty too, though.
Other answers should solve your immediate problem. In the long run, you may want to consider reorganizing the structure of your codebase. Extracting separate crates would help minimizing the impact of changing `[dependencies]` (e.g. your library crate probably doesn't need _clap_ for command line argument parsing). It is also likely to help with compilation times in those cases when you only modify one crate.
Might be a bit too functional, but fn parse_line(line: &amp;str) -&gt; Vec&lt;u32&gt; { line.split('\t').flat_map(str::parse).collect() } fn parse(s: &amp;str) -&gt; Vec&lt;Vec&lt;u32&gt;&gt; { s.lines().map(parse_line).collect() } You can inline `parse_line`, but I feel like it's more readable this way.
Wish I still lived in Boston. Moved to a dumpy college town in the middle of nowhere a few years back.
The original code is cleaner, but you can do iterator chaining: s.lines().map(|line| line.split('\t').map(|num| num.parse().unwrap()).collect()).collect()
Snow is fluffy ʕ☞ ﾟ ᴥ ﾟʔ☞
Now you have me confused. If you derive `PartialEq` it is going to generate some amount of code which, except for the degenerate case of C-like variants, is going to require code generation of size O(enum size). You simply aren't going to get away with not generating this code if you have derived `PartialEq`. Making the only solution to avoid this generated code to be not derive `PartialEq`. Is that what you wanted to get at? (If so, then this is not something unique to `PartialEq` or enums but is general to *any* use of `derive` regardless of trait or struct/enum. 
You could use a macro, or you could create three functions. fn binary_search_any&lt;T: Ord&gt;(arr: &amp;[T], val: &amp;T, comparator: fn(&amp;T, &amp;T) -&gt; bool) -&gt; usize { if comparator(val, arr[mid]) { ... } } fn binary_search_right&lt;T: Ord&gt;(arr: &amp;[T], val: &amp;T) -&gt; usize { binary_search_any(arr, val, |a, b| a &lt; b) } fn binary_search_left&lt;T: Ord&gt;(arr: &amp;[T], val: &amp;T) -&gt; usize { binary_search_any(arr, val, |a, b| a &lt;= b) } I haven't actually tested this code, so there may be a syntax error or two. But, that's the concept. My preference would be to just use a macro to generate the two functions, but I'm significantly more macro-friendly than most of the Rust community seems to be.
Releasing new major versions of things isn't free.
Someone's doing Advent of Code :)
It isn't, but misusing v0.y.z has a price of its own, and I would argue that price is higher.
You mean generating a vector and returning an iterator from that? Just use `Vec`.
[removed]
Why the need for the abstraction over the iterator type here? Can't we just return a custom `MyIterator` as-is?
&gt; I'm an ~~amateur~~ awesome programmer fixed that for you. This is really neat!
There is wonderful book, not about Rust instead it will teach you C and Assembly. It called Low-level Programming... by Igor Jirkov. I study in the university there the author works, so we have a course based on the book and it was amazing! Assignments are quite easy, but you will create such an interesting things as image processing library to work with BMP, your own malloc (seems hard, but it’s not), and a lot more. Just check out a few pages, and you will get me, can not exaplain how brilliant the book is in my poor English:)
You may want to get involved in the Redox community. Redox is an operating system and kernel being written from scratch in Rust: * https://www.redox-os.org/ * https://www.redox-os.org/news/ * https://www.redox-os.org/docs/ * https://discourse.redox-os.org/ * https://github.com/redox-os?page=1 * https://chat.redox-os.org/redox/channels/town-square 
Ohhh im new to rust, coming from js and hask.
I am a bit more fond of this approach. Rust will automatically pick up on the files in this directory and so will not need modifying of the cargo.toml file. 
I'll ask the others. The real outside part is stable (traits from num and std, etc), bit there are some constructors used by a.o. diesel that aren't very well done yet. Or rather, I'm not very fond of them yet :-)
This appears as pretty odd use of rust. Plain shell scripts are much better suited for this. Wouldn't this work just fine? for x in "$@"; do echo "set -gx PATH \$PATH \"$x\"" &gt;&gt; $HOME/.config/fish/config.fish done 
1) I think even in very low-level Rust code (like say the Redox os kernel), unsafe blocks constitute only a small portion of the total code base. So overall, it is a compromise worth taking. I don't think the research community has come up with any better solutions. 2) Yes, it does look a bit more cryptic than a simple *x = *x | (1 &lt;&lt; N) or something of that sort. But I think once the logic is understood, it is not that big an issue. It will be good to know if there are alternatives. 3) Yes, you can code at a much higher level of abstraction and also use the type system to obtain many interesting safety guarantees. Please refer the phenomenal work of Jorge Aparicio in this doman: http://blog.japaric.io/. Also of interest is the work being done by the TockOS team: https://www.tockos.org/
Does turning on backtrace make all rust programs slower?
Regarding unsafe: The whole point of unsafe is that it is impossible to do *everything* using just safe code. Low-level details like poking hardware and implementing memory allocators and some data structures cannot be done within the rules of safe Rust. Unsafe enables you to do those things, while wrapping them around in safe APIs. This is how the Rust standard library is done, too. Things like `Vec` use unsafe underneath to manage memory and do other low-level work. However, typical Rust programs use `Vec` using only the various safe methods and functions that the library provides. One can look at the stdlib source code to verify that the unsafe implementations of those methods is correct, just like one should do when writing C code. In C, your entire program is unsafe. In Rust, you can confine unsafety to well-defined blocks. Use it when it is necessary and wrap it around safe APIs to be called from safe Rust. The rest of your program can fully take advantage of all the nice safety and ergonomics (zero-cost high level abstractions) of Rust. If your program blows up due to memory unsafety problems, you know exactly where to look. It is guaranteed to be caused by one of your (hopefully well-contained and encapsulated) unsafe blocks.
Even if you just record via OBS (audio input and video) that'd be better than nothing, IMO!
I'm not saying that there is a bug in the compiler but that you should be careful with derive. And in some cases, manual PartialEq can be shorter, according to this tool.
Do you really need `Vec&lt;Vec&lt;u32&gt;&gt;` and not `Vec&lt;u32&gt;`.
We've been historically doing them on Wednesdays, but we really should be rotating around a few different days of the week just so that we don't exclude people who have fixed arrangements. I'll look into doing so for future events, and maybe the stars will align someday. :)
The meaningful comparison would be a shell which compiled in the order of seconds. I believe that FreeBSD uses tcsh as its default interactive shell; how long does that take to build? How does it compare to Ion in terms of features? Perhaps a useful exercise on the Rust side would be to build a replacement for sh/dash, focused on supporting a POSIX scripting environment, with no extra bells and whistles, with maximum safety and speed.
Hmm. I wonder if you could integrate pledge as part of the Rust build process. If you're building a static binary, can you make a complete list of every system call it might need? Could you then insert a pledge to not call anything else before main? Could you do further static analysis, vaguely lifetime-like, to find a set of points in main and its children after which certain system calls will never be needed again, and insert further pledges there? 
Thanks for your efforts maintaining Chrono!
I've certainly been looking for this! Just haven't found a nice design. My entrance point is basically: The case before we generalize it is a function that takes a mut reference to a vector, and we want to generalise that. Basically Vec::push and generalize it, and we want to include the case where the user wants a zero cost way to ignore the produced values too. This would be useful in many algorithms, to let the user decide how and if to store a sequence result.
If you're interested in following OS development through mailing lists, you might also like to take a look at the lists for FreeBSD (which i think means [freebsd-hackers](https://lists.freebsd.org/pipermail/freebsd-hackers/)) and Illumos ([illumos-developer](https://illumos.topicbox.com/groups/developer)?). IMHO those communities have higher standards for the behaviour of their community members, and are producing code at least as good and sophisticated as Linux. For databases, as an occasional PostgreSQL user, i have found the [pgsql-hackers](https://www.postgresql.org/list/pgsql-hackers/) mailing list an informative read at times. Again, a healthy community, producing excellent software. 
hey, perhaps the (1) and (2) can be abstracted away on a HAL written in rust and everything will look nice about (2), I think that *x |= (1&lt;&lt;N) is very elegant, and it is very readable. All this masking and setting and unsetting bits happens a lot in embedded, so we'd be giving away a lot of readability. and thanks for the references, I'll take a look at them
If this is advent of code then yes he needs vec of vec. 
What is the point of `Option&lt;&amp;char&gt;` anyway, btw? `char` is `Copy` so there shouldn't be ownership issues, and a `&amp;char` is actually larger than `char` on many platforms.
Interesting. That is pretty awesome.
It’s because the underlying generic type is &amp;’a T. It’s a stream reader kind of structure.
Cool. I am going to study up on this. 
Mullvad uses rust? Now I love their VPN *and* choice of programming language!
O.O, I guess we already crossed that barrier.
You either need to use a string field or manually implement deserialize. Thats not as hard as it sounds, check the serde book.
Conduit is a sidecar proxy for Kubernetes. The point is that it installs painlessly, and suddenly you have insight into latency, success rates, data rates, and a brand new "tap" feature that lets you inspect messages mid-flight. The proxy part is written in Rust, and there is a controller part written in Go (fits in with the rest of the cloud ops ecosystem). It's kinda fast. We made use of `tokio`, and invested heavily in creating the `h2` crate, with Conduit finding issues for us as we developed it. We also have a `grpc` crate that uses `h2`, and has sweet code generation, like most other grpc libraries. Website - https://conduit.io/ Repo - https://github.com/runconduit/conduit 
I would put parse_line inside parse, no point in exposing it if you're only using it inside parse fn parse(s: &amp;str) -&gt; Vec&lt;Vec&lt;u32&gt;&gt; { let parse_line = |line: &amp;str| { line.split('\t').flat_map(str::parse).collect() }; s.lines().map(parse_line).collect() }
Warning, information overload to follow, please don't be discouraged by the information contained within. There are plenty of opportunities to scale into all of these topics below. Note, if you want to jump straight into contributing as a way of learning, there are some resources at the bottom. If your goal is a Database Management system, You'll have 2 lobes of study: The algorithmic stuff, and the systems stuff. In order of (my own opinionated) priority : 1. Cache and Disk friendly data structures. 2. Scheduling and State Machines 3. Concurrency Control and consensus. On the systems front, (again my opinion) ordered by priority: 0. The OS/Kernel, Mutexes and Atomics 1. Memory 2. Network 3. Disk **Algos** For algos #1, I recommend looking at works by Nikolas Askitis such as https://github.com/naskitis/B-trie (which has its own bibliography) and HAT tries https://en.wikipedia.org/wiki/HAT-trie This will give you a taste of the task of how to efficiently make non-linear data structure pack (and be accessed) linearly. Regarding #2 and #3, they can be delayed for a while, as one could make a rather efficient single-threaded database that persists to disk, and avoid many concurrency headaches. That said, have a look at methods for formally modelling state machines : https://barrgroup.com/Embedded-Systems/How-To/State-Machines-Event-Driven-Systems https://barrgroup.com/Embedded-Systems/How-To/Introduction-Hierarchical-State-Machines Also https://en.wikipedia.org/wiki/Log-structured_merge-tree are a good area of study, they are a tad less relevant these days, as they were designed to optimize access to spinny disks by writing append-only. They are still very commonly used in high-write load scenarios as they solve both concurrency and making data serialization linear with the same data structures. And no dive into databases would be complete without a tour of MVCC (Multi Version Concurrency Control) https://en.wikipedia.org/wiki/Multiversion_concurrency_control **Systems** The 0th item is kind of sprinkled all around the other three. It wouldn't hurt to learn some high level information on the Kernel and how it schedules functions and processes, and which calls run in the process and which ones have to be scheduled in the kernel. Studying that is an excellent opener to see how the OS handles locks (Mutexes and Futexes) and how the CPU handles "Locks" memory barriers for atomic operations. 1st item : Memory managemant is probably the most important systems topic for a DBMS, learning how an OS deals with "pages" of virtual memory. Step number one, I'd look at the man pages for mmap() and some tutorials on how to use it at a high level: http://beej.us/guide/bgipc/output/html/multipage/mmap.html after that, dig into the guts of Linux VMem with https://pdos.csail.mit.edu/~sbw/links/gorman_book.pdf to get started. #2 For Networking, the canonical books to learn TCP/IP are https://en.wikipedia.org/wiki/TCP/IP_Illustrated . At this point, you might want to also dive straight into the Linux TCP/IP stack itself: https://github.com/torvalds/linux/blob/master/net/ipv4/tcp.c it is very illuminating. #3 Disk is tricky.. I'd presume these days that everyone is targeting SSDs or faster (NVMe) . MMap is a great place to start. That is, the process of mapping vmem to a region of disk, and when you write to that area of memory, it is transparently (or not so transparently) sync'd to disk. Note that most databases don't use mmap, as they need tighter control over how and when data gets flushed to disk, but again, with SSDs and NVMe it matters a bit less. Eventually, if you're on Linux, you'll want to work with AIO (which is a PITA of an API), but it allows you the fastest and most directly (and most error-prone) access to reading and writing disk. You can get started with that here: https://www.fsl.cs.sunysb.edu/~vass/linux-aio.txt *Some active open-source projects for you to emulate and also contribute* Rust's own [Sled](https://github.com/spacejam/sled) is a take at implementing a KV store using modern concurrency and disk paradigms. It is quite readable, although it is in early alpha. I am quite sure that the author would love help with documentation, testing, and cleanup, which would be a great way for you to dig into database programming right away. [LMDB](https://github.com/LMDB/lmdb/tree/mdb.master/libraries/liblmdb) This, IIRC, does use MMAP. It is wicked fast, highly respected, very stable, and only (last I checked) 6,000 lines of code! That is crazy small for a C program, and is a fantastic example of how to do low-level C programming in a simple and elegant way. [Mio](https://github.com/carllerche/mio) and [Nix](https://github.com/nix-rust/nix) are canonical polling based IO and Unix syscall wrappers. Contributing-to, or just learning these APIs will give you great insight into systems programming that is very relevant to your area of interest. [TiKV](https://github.com/pingcap/tikv) A distributed KV store written in Rust. This is a much larger project than those mentioned above, but it contains distribtuted consensus and concurrency control, as well as high performance network protocols, and more! [Raft in Rust](https://github.com/Hoverbear/raft-rs) - This is an implementation of Raft in Rust that as rather easy to read. Raft is a protocol for executing transactions, that is, getting multiple parties to agree on a value in the face of contentious data updates. A search for Paxos, and Raft, and Raft vs Paxos can be quite illuminating. Apologies if there is anything in the Rust community that I've left out, but this response seemed large enough. Also, if you have any specific questions, don't hesitate to ask here, or in IRC/#rust, or dm me. 
I was hoping for something like [serde-hex](https://github.com/forrest-marshall/serde-hex) but I'll do it manually then. Thanks.
This is great! What is Tower? Also, are there any usage examples of the grpc crate?
oh, it's nice to see this released :)
Tower will get a proper announcement soon. There are helloworld and routeguide examples of grpc in the repo, but the server parts are still being improved on. (We needed client first, and just recently needed server.)
When I have src/bin/foo.rs how can foo.rs do `mod util;` where util.rs is used by multiple binaries in src/bin? If I put util.rs in src/bin it complains that no main function was found; if I put it in src, how can I import it?
&gt; where util.rs is used by multiple binaries in src/bin? I would recommend creating a library for this, rather than using modules. If you really want to use modules, you can use `#[path]` to hack it up.
Can the util lib be in the same workspace? Every bin has to do `extern crate util;` then, right?
Ah, looks very nice. I am only afraid about name clash with https://crates.io/crates/conduit Maybe you could make a pull-request to add the project to our mighty Awesome Rust list? https://github.com/rust-unofficial/awesome-rust I'd be more than happy to approve it. It would be the first conduit there :D
ELI5 please? I'm just a lowly developer. Is this similar to Docker Swarm or completely different?
1. I'd argue that if you already have a library, this is functionality that's missing from it. So in a literal sense no, but you'd add it to the existing library. 2. the ones that want to use it, just like they'd need `mod utiil`.
It appears in some crates, though my personal opinion is that `use *` is horrible and hurts readability in the long term. I would rather not encourage users to adopt that style.
There is no lib right now, only the bins, so can I put the code of util.rs in project/util/lib.rs and then make project/Cargo.toml a workspace so that the bins can import the util lib?
This is more akin to something like [envoy](https://www.envoyproxy.io/). In the simplest sense you can think of it as a way to avoid worrying about network topologies from your application. These small services sit alongside your application on the same host and all communication goes in and out of it. It is becoming increasingly popular in large micro-service deployments where many languages are used.
You don't even need to collect into vecs for the advent of code thing :)
Thank you! That makes sense! I'll try to set something up with this to get a better feel for it. One other question: linkerd and conduit are both marketed as a "service mesh" so do they accomplish the same task?
If there's no lib, there's no need for a workspace. 1. move `util.rs` to `project/lib.rs` 2. `extern crate project;` in each binary you want to use the code from 3. use the code :)
One thing to note is that as part of this initial release, conduit only proxies HTTP2 (including grpc) messages. HTTP1 and plain TCP will be in the next release.
The article says &gt; Conduit is not Linkerd 2.0. Conduit targets a very specific environment—Kubernetes—and does not address any of the wide variety of platforms or integration use cases supported by Linkerd. For our many users of ECS, Consul, Mesos, ZooKeeper, Nomad, Rancher, or hybrid and multi-environment setups spanning these systems, Linkerd is the best service mesh solution for you today, and we’ll continue to invest in making it even better.
Looks nice! Couple of notes since I started from the link to the website instead of the blog post. The website should have a link to the repo; I browsed around a bunch, and saw references to blindly running some scripts, but I would have wanted a link to the repo to find out more about what I'm running (edit to add: ah, found it in the middle of the Getting Started guide, but a more prominent link on the header or front page would be nice). The website might also want to have a link to the blog post introducing it as well; the docs include a link to another post on what a service mesh is, but I spent some time browsing around trying to figure out how this related to linkerd before coming back here and clicking on the original article to find that information. Someone starting at the website might be similarly confused.
Is vec of vec a way of creating a 2d array?
Number 2 means you eternally don't have a patch version on most crates, only major and minor, which is a loss. It also means that many more bureaucratic (non-technical managers and such) individuals at organizations will reject the use of third party crates because their version is less than 1.0, so this creates a practical problem for Rust adoption even though the version numbers themselves shouldn't have that much meaning. Since the numbers don't have much meaning anyways, we should just start with 1.0 when we're ready for people to begin using our crates. Regardless, an informal discussion like this will likely change nothing, unfortunately.
Unfortunately that quote doesn't help me much. It targets Kubernetes, great! But so does linkerd.. so I'm still not sure what the difference is.
Not project/src/lib.rs?
&gt; functions define a static order of instructions that the compiler won't change around The compiler (and CPU!) are totally allowed to reorder instructions. They often do so to get better performance so long as the result after optimization is _as if_ the reordering were not done.
Thanks!
errr sorry yes you're right
Here's what I get out of it: Conduit is a specialized tool. Linkerd is a general tool. Usually, specialized tools are better at their specialty than a general tool is. The post also mentions things like performance and memory requirements.
Fair point about the non-technical managers seeing 0.x as inferior, but would these managers really care if the dependencies of a crate are at 0.x? This is what Diesel is [currently being accused of](https://www.reddit.com/r/rust/comments/7hkw6c/announcing_diesel_100_beta_1/dqs3euj/).
We are doing (2) while also trying to push crates to 1.0: https://blog.rust-lang.org/2017/05/05/libz-blitz.html
2 - Syntax: first you hate it, then you tolerate it, then you like it. At least, that's how I am with any language. Most of the time wrapper types like this are used to create a safe way to perform unsafe operations. In this case, using the `RW` wrapper is more of a stylistic choice, since it doesn't make the accesses safe. You could certainly just define `RPCGPIO` as a regular pointer, and use regular pointer writes to it. const RCGCGPIO: *mut u32 = (0x400FE000 + 0x608) as *mut _; *RCGCGPIO |= (1 &lt;&lt; PORT_F); 3 - I think there's potential for crates.io to be a big benefit for embedded. I imagine some utopian future where the standard library has been modularized, and you can easily use it anywhere as you need it. For example, want to make a WS2812 LED display that shows what the weather is: [dependencies] ws2812-rs = "*" # driver for ws2812 leds ralloc = "*" # rust malloc implementation smoltcp = "*" # rust IP stack darksky = "*" # darksky weather forcast api [dependencies.std] features = [ "alloc", "net" ] # enable the standard library with allocations and networking # made this syntax up 
Yes. The kind of bureaucracies that care about that kind of meaningless number care about transitive dependencies.
I'm pretty sure you can still use `fn` syntax for inner functions.
It is one way of doing it, yes. But there are many ways. A `Vec&lt;u32&gt;` could also be a 2d array, laid out in row-major or column-major order, depending on what you're trying to do and your access patterns. `[[u32; N]; M]` and `[u32; N x M]` are similarly two arrays, but are values and not necessarily heap allocated.
&gt; Please don't interpret this as me scolding you for having unstable dependencies, ?
Yes, however unlike most implementations of 2d "arrays", the rows can have different lengths.
There's definitely a need for that; I just implemented some hex serialization the other day that I could have used your crate for if I'd seen it. IMO, the names are a little terse. I had no idea what `StrictPfx`/`CompactPfx` did until I got to your description. Something like `PaddedPrefixed` or `&lt;Pad, Prefix&gt;` would be self-documenting.
I think 0.x.x version is usually used to tell users that they should expect breaking changes to happen relatively often and/or that crate has known issues which can be fixed only with breaking changes. I think, on thing which would help to 1.x-ify crates which Rust currently seriously lacks is ability to specify in Cargo.toml minimally supported Rust version. With this feature if version crate v1.1 is published which utilizes shiny new feature in say Rust 1.30, old Rust users will be able to use previous version automatically. But without it crate authors either will have to avoid using new features, or will have to publish 2.0, even if it contains no API changes, just due to the internal change which makes code nicer. There was several proposal, but I think they were rejected.
Conduit targets only Kubernetes; Linkerd tries to be more general purpose, so it needs to be more complicated to integrate with a number of different orchestration stacks. Linkerd is also written in a heavier-weight stack; Scala, the JVM, etc. So it's less appropriate for very lightweight systems with low overhead. So, if you use anything other than Kubernetes, if you have mixed environments with multiple orchestration stacks, or if you want something production ready now and don't mind the overhead, you'd want to use Linkerd. If you are in a pure Kubernetes environment, and want something lighter weight and faster that allows you to better utilize your resources for your actual application rather than for your service mesh, you'd be interested in Conduit (once it's production ready; right now it's fairly limited with just support for HTTP2/gRPC).
Yes, tower will get a formal announcement soon but the tl;dr is that tokio is being split. Tokio will focus on what is now tokio-core and tokio-io. Tokio-Service is being renamed to tower and will be expanded on there. 
If you have any suggestions for a 1.0 release of libsqlite3-sys, I've opened an issue here: https://github.com/jgallagher/rusqlite/issues/316
&gt; The staging part here is one of the huge advantages Git has over Mercurial Honestly I'm using it maybe twice a year. And back in 2011-2014, until I've finally figured it out, it introduced nothing but confusion. And these Mercurial users who actually want something like it (a superset of staging area, actually) are welcome to try `mq` extension (distributed with Mercurial since almost forever). &gt; GitExtensions, the GUI I mainly use for this, additionally takes control of committing and staging to another level by allowing to stage, unstage or reset individual lines in files. Patch lines or patch _hunks_? There's a difference and Mercurial's ["interactive commit"](https://www.mercurial-scm.org/wiki/CrecordExtension#For_Mercurial_v3.8.1_and_later) allows to (de)select individual patch lines with nice ncurses-based UI. &gt; TortoiseHg, which I used for Mercurial before, only allowed you to pick which files should be committed, and IIRC, even that was lost if you closed the window before committing. Well it's certainly not the case for last couple of years at least (ones I'm maintaining TortoiseHG package for openSUSE for sure) — THG can select which hunks to commit, not just files. True, it does forget selected changes after closing the window, but since you're decided to commit and maybe push/pull changes with GUI, why would you close it at all?
&gt; What is Tower There's a [repo on Github](https://github.com/tower-rs/tower). It has some [examples](https://github.com/tower-rs/tower/blob/master/examples/channel_service.rs) and some [doc comments](https://github.com/tower-rs/tower/blob/master/src/lib.rs). Based on that, it looks like it's a framework for implementing robust distributed RPC services using Tokio. It looks like it includes a rewrite of [tokio-service](https://docs.rs/tokio-service/0.1.0/tokio_service/trait.Service.html), but adds on top of it a lot of extra functionality for handling things like routing, buffering, backpressure, rate limiting, service discovery, and so on.
Thanks for the valuable information! I think I should start with Rust by Example.
&gt; Scott Myers Thanks, but can you please direct me to more specific content, like the talks they gave on OS programming? 
I think most of your explicit type annotations can be dropped. Haven't tried it, but... let mut v: Vec&lt;Vec&lt;u32&gt;&gt; = Vec::new(); Here the type of `v` should be inferred because you return `v` at the end of a function whose return type is `Vec&lt;Vec&lt;u32&gt;&gt;`. let mut inner: Vec&lt;u32&gt; = Vec::new(); Here the type of `inner` should be known because you later `push` it to a vector (`v`) whose elements are of type `Vec&lt;u32&gt;`. _I think_. That said, the functional approaches are more concise. I just thought I'd point that out.
I ran that code, and I knew what I had to correct, but after including the necessary libraries and prefixing a '*' to the 'a' in `printf`, the code compiled and ran successfully. I think what you want to demonstrate here is that we have a security hole here in the sense that we're reading a value that has been freed. Correct me if I'm wrong, but isn't this the motivation towards a modern language like Rust?
&gt; lacks is ability to specify in Cargo.toml minimally supported Rust version This exactly. And it would be awesome if Cargo could run tests both against the currently installed version as well as the minimum Rust version when doing `cargo test` (and warn if the minimum Rust version isn't installed).
OS programming specifically, no idea. Systems programming, almost any talk. Here are two to get you started: C++ and Beyond 2012: Herb Sutter - atomic Weapons 1 of 2 https://www.youtube.com/watch?v=A8eCGOqgvH4 code::dive conference 2014 - Scott Meyers: Cpu Caches and Why You Care https://www.youtube.com/watch?v=WDIkqP4JbkE Most of their talks are going to be through C++, but they're typically about systems programming in general. I would recommend just going through their talks, seeing which ones stick out as interesting, and queuing it up for later.
I'm definitely all for Rust being the go-to language for WebAssembly... I'm just a little iffy on seeing WebAssembly furthering the march toward offering software in forms that can't easily have offline backups made for future generations to experience.
That would work if you do define a specific iterator type - and in that case you don't need abstraction. `impl Trait` and `Box&lt;Iterator&lt;Item=XXX&gt;&gt;` are useful if you're just writing combinators over an iterator - if you're using methods like `.map()`, `.flat_map()`, `.filter()`, etc. to make up the body of the method rather than defining a struct and an Iterator implementation with a `.next()` method.
This is a great article and I agree with all it says... but I feel there's one part missing, and that is a *good* API for interacting with the browser. As far as I know wasm doesn't have this, and progress on it seems very slow. This results in anything you actually do besides pure computation needing a non-trivial amount of annoying JS glue code. Anyone know of good solutions to this, or projects endeavoring to build solutions?
I agree that wasm should be a focus of 2018. In fact, I think there should already be stuff done in the first half of 2018. If Rust only has a comprehensive wasm story at the end of 2018, it might be too late as others will have taken over. The market is not 100% unchartered as probably most people will just port their C++ codebases over, but it is definitely contested already now. Rust can definitely play a big role in the future, and I hope it does! &gt; The ergonomics initiative can still be brought forward into 2018 (NLL, ATCs, Incremental Compilation, and other nice things) The ergonomics initiative was about *language design*, so incremental compilation, while being a great thing and improving developer experience, had nothing to do with it. Also IIRC ATC wasn't counted officially to the ergonomics initiative, at least I can't find it listed in the [tracking issue](https://github.com/rust-lang/rust-roadmap/issues/17). I think the ergonomics initiative of this year was a huge mistake. Many of the proposals threatened the stability of the language. When can you learn the language and consider you know it? When can you be happy about a safety feature of Rust and when will the language team say "oh no this is too hard we must dumb it down"? Like with the proposals to do auto-casting of integers. Or when you are actually happy about the module system not being a mess and proposals come along that change almost *everything* about the module system, turning it into such a mess. The final proposal is okay, but until then it was a really bad process, for everyone :/. I don't want to continue writing about why the ergonomics initiative was a bad idea but it made me seriously question my trust in the maintainership of the language. It definitely should not be repeated. My personal wishlist for the 2018 Rust roadmap is here: https://gist.github.com/est31/bbdda3fecca39464cec6a44881389520
There were some interesting Twitter threads about this recently: https://twitter.com/slightlylate/status/937733101748236288 https://twitter.com/callahad/status/937728124451786752 Personally, I think the future for Rust in the browser is very strong. I think people underestimate the pull towards using a single language both on the front-end and the back-end: the ecosystem network effects and diminished learning curve from having fewer languages/stacks in the same application is real. I guess I'm a bit of an old-school full-stack developer, and so I don't care that much for webpack (nor do I use the IDEs that take advantage of RLS -- are JS devs used to that kind of feedback?). What I think will be more interesting is if WASM gets better access to the DOM, to the point that you can really write all of your app in Rust.
Good point! I was thinking in terms of strictness because the underlying code was much more picky about its input, but `PaddedPrefixed` is *much* clearer. 
2) You can't simply do *RCGCGPIO |= (1 &lt;&lt; PORT_F) because that will then be eliminated by the compiler during an optimized build. The RW object provides "volatile access" to the register associated with it which prevents the optimizer from eliding/reordering the read/write operations. 3) cargo/crates is really cool!
How do you see wasm changing this? I’m actually excited about the opportunity for more offline here...
&gt; In it, he states that no one has made any attempts to write kernels, shells, and system utilities in a memory safe language. Then he is profoundly ignorant. Even ignoring Rust, there's Singularity, and several others.
There's a recent wasm proposal (the "host bindings" proposal) that has momentum and should help out with this. It specifically removes the need for the GC proposal as well, so that should make it happen sooner. That said, there are also other approaches... I know of at least one person who's working on a procedural macro so that it can generate the JS glue code for you. We'll see!
You can!
Whoa. I'm extremely grateful for that. I've saved this answer for the convenience of my journey. I think I should start getting into Sled and LMDB. I'll start the reading part with Linux Vmem and AIO. Also, I don't think so, but is there an all-in-one book for all the stuff you mentioned above, which also suits mine level? Lastly, should I start learning Rust now without learning more C (as I mentioned, I've done C for 2 semesters, including pointers and implementing simple structures like BSTs)?
I think it's just fear of commitment. If you follow SemVer and have 1.0 software, you pressured to support that branch otherwise what's the point? Like how different `uuid` crate can be? Well, major bumps in this case are just bumps of `serde`. Which brings us to the actual problem - cargo doesn't understand between `api` and ` implementation` dependencies. Looks at how new `gradle` does it - beautiful. It's very hard to `clippy` to be stable since it breaks from time to time on nightly and yet only works on nightly. It's also just development dependency, so no one cares. `chrono` changes public API all the times and strictly follows SemVer. This is a good example. The author is just not happy with public API yet. If it was 1.0 then it will catch up to chrome version pretty soon. I think the only versions you need to fear is `0.0.x` and `0.1.x`. &gt; Use the Cargo/npm interpretation of SemVer It's everyone's interpretation of SemVer. 
The only aspect where I can imagine a change to happen is that right now you are forced to do XHR requests if you don't want to put your wasm module into a data url. So no `&lt;script scr="file.wasm"&gt;` support yet! XHR requests are harder to capture when downloading a web site, especially when they only happen at some user interaction. Not wanting to invoke the sunken cost fallacy but "the web is not permanent" is already now very much the case. E.g. it is very easy to stash a copy of Microsoft Windows from 2001 but try that with a google search, or some other interactive service. I would say though that the issue is mostly orthogonal to wasm.
risc-V support in linux is released in 4.15 : https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/arch/riscv?h=v4.15-rc2 And SiFive will publish a quad-core 64bits proc (asic) in Q1 2018. Then it can be possible that enable risc-v desktop in near future.
Yeah, the name collision is unfortunate. We only realized this after the train left the station. We're not _too_ concerned with there being confusion between the library and this project... and I don't even think we really have any good reason to try to publish the (non-library) proxy to crates, as it's not currently very usable without the rest of Conduit running. The supporting libs for the project will mostly be published into the Tower repos, if that helps clarify things at all.
Note that this rule is only for [caret requirements](http://doc.crates.io/specifying-dependencies.html#caret-requirements). If caret requirements followed SemVer to the letter, it would have been no different from specifying the version without any operator. So - even if we want to stick to SemVer, it would still be a good idea to let Cargo upgrade the bugfix version of `"^0.#.#"` dependencies. Those who don't want Cargo to update even bugfixes of their initial development dependencies will simply not use the caret. As for the packages themselves - the way I understand it, "Anything may change at any time" is more of a warning to the users than a permission to the library's developers - new features should still bump the minor version and bugfix bumps should be only for fixing bugs. All the initial development means is that the library makes no guarantees whatsoever to be backward compatibles. But - even without these guarantees, I believe only a tiny fraction of bugfix releases in initial development are actually breaking. Not because developers are careful to not introduce any breaking changes in bugfix releases, but because during initial development you usually bump the minor version. The bar for a minor bump is so low, that anything below it is unlikely to be big enough to break anything. Still - people who aren't willing to take that risk can just not use that crate as a caret requirement.
I think service workers are a big part of the story here, but yeah.
&gt; If caret requirements followed SemVer to the letter SemVer does not define requirements at all, so they're always made up: there is no spec.
TIL about service workers. They seem great :)
I actually saw a conference talk recently where the presenter put an entire Express app inside of a service worker; then you have both the server and client running on the client O_O.
Wow, didn't know that chrono has issues with maintainer time. If I can find some time to invest in it, I'll do! I heavily depend on it in two of my projects (most importantly the kairos crate which is an extension for chrono itself).
Is it friendly for a beginner like me? :)
Fair point! I missed that detail.
The helloworld and routeguide examples are server only?
Yes, it's only for caret requirements, but in Cargo, if you don't specify any modifiers you still get a caret requirement. For example, the cargo.toml file [dependencies] time = "0.1.12" means you have a caret requirement of version `^0.1.12` on `time`. This has its pros and cons as well (a huge con is the security implications: any of your dependencies can make a keylogger and release it as a patch-level update), but this is getting off-topic a bit.
&gt; Conduit is a sidecar proxy for Kubernetes. The point is that it installs painlessly, and suddenly you have insight into latency, success rates, data rates, and a brand new "tap" feature that lets you inspect messages mid-flight. You should put this at the top of your front page. I've never heard the phrase 'service mesh' before.
What contexts are you using this function in? Are you waiting for a computation from a different thread? From a web service?
When working on day 5 of the [Advent of Code](http://adventofcode.com/2017/day/5) I found myself using `usize` as pointers into a `Vec` and `isize` for offsets between pointers. I tried to add a `usize` to an `isize` and found that they would not add and I could not find a function to add them with. I eventually created a fairly simple function (written below), but is there really no standard way to add `usize` and `isize` or am i just blind? trait Offset { fn offset(self, offset: isize) -&gt; Self; } impl Offset for usize { fn offset(self, offset: isize) -&gt; usize { if offset.signum() == -1 { let offset = -offset as usize; self - offset } else { let offset = offset as usize; self + offset } } } 
Couldn't you use a `while let None = f()` statement instead? Just curious. I've only ever tried to destructure to Some() in a `while let` before.
I feel like this could definitely be simplified, depending on where you're getting the Option from. If there's some iterator yielding `Result&lt;Option&lt;T&gt;, E&gt;`, then I'd do: ``` .flat_map(|r| match r { Ok(Some(v)) =&gt; Some(Ok(v)), Err(e) =&gt; Some(Err(e)) }) ``` to get to an iterator `Result&lt;T, E&gt;`. Though it's really hard to tell what you need to do without more context. I've almost never run into needing to do this - it seems like in most cases it could be better handled by refactoring whatever is producing the `Option`s than by trying to reduce complexity of consuming them. What are you doing which requires this?
This looks like a cool project that solves a real need :) I know about another project that (at least to me) is very similar to Conduit: https://istio.io. Could you give us some information about the differences? 
My main concern isn't so much that wasm is a revolution in the direction of SaaS (we've already had things like asm.js, NaCl, Adobe Creative Cloud, etc.) but, rather, that it's sort of like what I have to deal with when I'm trying to help people dig up lost fanfiction that they loved when they were younger. (The vast majority of people just "trust the cloud" without thinking ahead and the end result is that, when the story gets deleted from Fanfiction.net, who opt out of the Wayback Machine using robots.txt, it's anybody's guess whether someone saved a copy which can eventually enrich the public domain.) wasm is one more piece on the "producing non-preservable cultural artifacts is much easier" pile.
Well, on some machines it could crash, on my machine it printed zero. You are correct, I gave example of use-after-free, which is potential security hole and cause of crashes. You are also correct that Rust eliminates these (and other) bugs.
That is fair enough, I know at least [winapi](https://crates.io/crates/winapi) skips out on derives because they bloat the compile times (and also because they don't tend to be necessary). Do you have an example of a shorter, manually written`PartialEq`? I can't think of a way to do it (given that it works equivalently to the derive version).
My main problem with service workers is that, last I checked, their UX has been implemented under a similar rationale as the `"offline-apps.allow_by_default=true` configuration change I pre-emptively countered in my `user.js` as soon as Planet Mozilla informed me of it. For that reason, I keep them disabled in Firefox and, for Chrome, rely on the fact that I only ever run it as an Incognito Window. Firefox 52ESR is already the biggest waster of resources of my system by an order of magnitude. (I'm hoping that'll get remedied when I finish writing my WebExtension to shove supposed-to-be-inactive tabs and sessions completely out of Firefox into an external data store.)
&gt; My personal wishlist for the 2018 Rust roadmap FWIW, a few of your points from the compiler section already exist. The compiler uses multithreading to pipeline the Rust side and the LLVM side of things. In some configurations, it also uses multithreading across codegen units, which are essentially "C-like" in that they are sub-crate, but also more flexible in how they are split up. I also think (cherry picking from your language section) const generics, SIMD, slice patterns, self-referential types, and macros 2.0 are excellent ideas for 2018. :) The idea of using slice patterns to elide more bounds checks is interesting, I would love to see how far that could be taken.
I got this too in my interpreter. I ran in release mode to solve this.
I like the way you use `Next&lt;T&gt;` !
Start learning Rust now. :) I think you'll have no choice but to learn more C. If you're interacting with a kernel, you'll probably at least need to be conversant in it. Learning *any* language will help you in your journey. But the added benefit of learning C is that it will help inform your understanding of Rust. I can't think of a book that covers all of those topics, but two of my favorite books are : * The Algorithm Design Manual - by Steven Skiena * Michael Abrash's Graphics Programming Black Book - now out of print, (but free!). Also it is not directly related databases, and some of the concepts are dated, but, wow does this really show what it means to optimize using low level programming. 
Can we see this function used in context? For example, if this were being used to strip all the `None`s off the front of an iterator, I'd use `skip_while` like so: let foo = [None, None, Some(1), None, Some(2)].into_iter(); for bar in foo.skip_while(|x| x.is_none()) { print!("{:?}, ", bar); // Some(1), None, Some(2) } ...but if you have an iterator that you want to remove all the `None`s from, I'd use `filter`: let foo = [None, None, Some(1), None, Some(2)].into_iter(); for bar in foo.filter(|x| x.is_some()) { print!("{:?}, ", bar); // Some(1), Some(2) } ...but if you're just testing whether an iterator contains any `Some`s at all, then that's what `any` is for: if foo.any(|x| x.is_some()) { println!("Contains a Some"); } else { println!("Nothing but Nones"); }
How about using the break-with-value feature introduced in v1.19? https://play.rust-lang.org/?gist=465a91f69af1a3d58f1a2c86ba980bde&amp;version=stable
You're right! Conduit and Istio offer similar features. We think it's healthy and fine for there to be multiple projects in this space. Istio is led by Google and IBM and will certainly see a lot of production adopters in 2018. With Conduit, we are building on our experience operating Linkerd with users to execute on a constrained, production-ready _essential_ Service Mesh. We will err on the side of having fewer features that we think are _essential_ to operating a Microservice at scale. Of course, only time will tell as these projects take shape.
I'd recommend using an iterator (0..) with filter_map or map+take_while Example https://play.rust-lang.org/?gist=4e461ecc618c19bd57b578ec74c6fef6&amp;version=stable
[Serde supports that with enums](https://serde.rs/enum-representations.html). In this case you have an "internally tagged" representation.
Since usize has a bigger positive range, it is impossible to add an `usize` to an `isize` without potential wrapping. For the challenge, I simply saved the current index/offset into the Vec as `isize` as well, converting to `usize` just for the indexing itself. (The challenge text just mentions that the Vec index will be out of bounds, not just bigger that `vec.len() - 1`, so it could go below 0).
&gt; 1) No, rustc cannot compile rustc on a 32-bit platform (currently), because it runs out of memory addresses. You can however cross compile a 32-bit version of rustc on a 64-bit platform, making this issue mostly redundant, as you can use this compiler to compile whatever 32-bit binaries you need on your 32-bit system. It is only relevant in a case like BSD, where it is demanded that the software must be completely self-hosting on a given platform. I was not aware of this, and I wonder: There is any particular reason because rustc cannot be compiled with a reduced memory budget? When compiling Rust code I'm always surprised by the amount of disk space the compiler needs to generate a few MBs executable, but I haven't noticed it ever eating my RAM even in release builds.
I'm playing around with [Vulkano](https://vulkano.rs/) right now and I was curious if there's a way to configure Cargo to detect a change to a shader file to know it needs to recompile my Rust code. Vulkano uses some special macros to trigger SPIR-V compilation of shaders, which means I would need cargo to re-build the Rust files containing the shader structs every time I update the shader glsl files.
Do you know what that means exactly? "Predicates are not composable?"
Does this at all make use of the experimental support for async/await/generators/coroutines?
He wants to actually use the result, and `while let None = f() {}` would throw it away (or require it to be called again)
No worries! To contact me, open a Github issue, or reply to an existing one if relevant.
I have nothing constructive to add, but I must point out that the alt-text is missing from the XKCD comic. Petty, I know. Great post! Looking down that list, most of the things needed are already in progress, if not done already (though lacking documentation), so 2018 should be a pretty awesome. One thing that might be nice if someone has bandwidth is to flesh out Rust/React integration. I don't think it makes sense to list here, but there's a pretty big opportunity to have one development framework for mobile, desktop, and web with React Native ([here's a post on Rust with React Native on mobile](https://medium.com/@marekkotewicz/building-a-mobile-app-in-rust-and-react-native-part-1-project-setup-b8dbcf3f539f), and there are projects for React Native on Windows, Linux and macOS). This is an area I'm definitely interested in and I may actually spend some time figuring it out next year.
Style pedantism, but I'd use `if let` instead of a `match`: fn try_and_try&lt;F,A&gt;(mut f: F) -&gt; Result&lt;A&gt; where F: FnMut() -&gt; Result&lt;Option&lt;A&gt;&gt; { loop { if let Some(r) = f()? { return Ok(r) } } }
&gt;&gt; While SemVer says there is no compatibility before 1.0.0, Cargo considers 0.x.y to be compatible with 0.x.z, where y ≥ z and x &gt; 0. &gt; &gt; what's the big deal between a package being at version 0.x.y versus x.y.z? Seeing that a package is at 0.x is a clear signal that the author of the library isn't committed to a stable interface. Note that there's no "yet" in that last sentence; it's an entirely valid choice for an author to conclude that they don't wish to ever commit to a stable interface. I'm actually thankful (no, really!) that people have latched on to using 0.x to mean that their interface is unstable, because the alternative is living in a world where people are exactly as resistant to stability and yet have no standard way to signal that. Meanwhile, the people are using 0.x to mean that they're not ready **yet**--IOW, that they're working towards stability, but still experimenting--can still approximate semver by using patch versions the same way that 1.x uses minor versions, and by using minor versions the same way that 1.x uses major versions. I think the situation is pretty reasonable. We don't want people to only publish crates after they're stable, because nearly every crate wants public feedback and real usage to inform its API. The only real problem is when a 0.x crate becomes so widely used that breaking changes become infeasible (there's a line in the semver spec about this: *"If you have a stable API on which users have come to depend, you should be 1.0.0."*), which is why the semver trick was invented (which will e.g. let us bump libc to 1.0 without another libcpocalypse).
Yes. You can specify it in a build script by printing `rerun-if-changed=&lt;path&gt;`, which can take a file or directory: http://doc.crates.io/build-script.html#outputs-of-the-build-script
&gt; If Rust only has a comprehensive wasm story at the end of 2018, it might be too late as others will have taken over. While I'd really like to see rust as the future language for writing full stack application with wasm frontends, I don't think a new technology should be thought as something has to be conquered. A fair competition is often a huge driver of progress and great chance to improve the general wasm experience. Even more I believe rust should focus on getting wasm supprt the right way instead of getting it done fast. Focussing on doing thing quickly could get rust-wasm in the position where js currently is: Highly used, yet [highly flawed](https://www.reddit.com/r/loljs/) und [loathed](https://hackernoon.com/how-it-feels-to-learn-javascript-in-2016-d3a717dd577f) for good reasons. Also mozilla's resources are limited and imho better invested in the core of rust than in taking over promising technologies. &gt; When can you learn the language and consider you know it? Actually you never can. There was always change and there will always be change, because a technology either has to adapt or it will die. Or to quote Bjarne Stroustrup: " There are only two kinds of languages: the ones people complain about and the ones nobody uses.". The rate of change is quite high in software development simply because it is a comparatively young and active displine, but there's no use in denying it with policy. 
Nope, we stuck with the stable compiler.
&gt; &gt; When can you learn the language and consider you know it? &gt; &gt; Actually you never can. That's not a great position to have. It's one thing to recognize a flaw in the status quo and quite another to embrace it as inevitable. We should strive to design our tools so they last a long time without needing a lot of churn. That's one of the core principles behind Rust's design in particular!
I think the original comment was noting that there was a lot of generated code for derived `PartialEq` in particular, which, as you say, could also apply to other more complicated derives. I agree that it wasn't the clearest it could be, though.
Oh wow, that's perfect. My apologies for not RTFM.
This is an issue I struggled with for a while, and after trying a bunch of hacks I came to the conclusion that the best solution is a lot of annoying duplication. The deserialization should be the easiest part. Something like this: ```rust #[derive(Serialize, Deserialize)] #[serde(rename_all = "lowercase", tag = "type")] enum Post { Photo(Photo), Text(Text), } #[derive(Serialize, Deserialize)] struct Photo { id: i32, url: String, image_permalink: String, } #[derive(Serialize, Deserialize)] struct Text { id: i32, url: String, body: String, } ``` Rust doesn't provide any way to inherit struct fields, so you have to define `id` and `url` (and any other shared fields) for each post type. If you have shared logic between the enum variants, the least fragile way I've found is to write more frustrating, duplicative code: ```rust impl Post { fn id(&amp;self) -&gt; i32 { match *self { Photo(ref photo) =&gt; photo.id, Text(ref text) =&gt; text.id, Foo(ref foo) =&gt; foo.id, Bar(ref bar) =&gt; bar.id, } } } ``` This is annoying, I know. But it has two benefits over using traits - the compiler will have your back if you add a new variant (enum matching must be exhaustive), and you don't have to juggle a whole system of enums, traits, implementations, and trait objects. Until the day Rust supports trait fields and special Trait-defining enums, this is how I would do it.
&gt; I myself hold a multitude of contradictory opinions on this particular topic. Most of them are held pretty weakly. You should definitely go into politics then! ;)
"If we want to secure a position for Rust in the future, this is it, and the sooner we get to making wasm a first class citizen in Rust and for web tooling the better off we'll be when wasm stops being something that a few people are working on and becomes the web." To me this kind of reads like they don't have much faith in Rust on its own merit, which I'm sure they do, but that's just how it reads to me. Also, the notion of having one language be synonymous with wasm takes some thunder away from wasm ridding the world of a language monopoly. However, I could kind of see a point in saying that if speed is your top priority when developing a wasm app, then aim for Rust since it is type-safe and has a nice package manager. While Rust is certainly an exciting language and has a lot to offer, this should be more about it being Wasm's time to shine more than Rust or any one language, imo.
Actually, chrono really messed up this year, by publishing a version with a serde bump from 0.9 to 1 with a patch version (0.3.1), breaking builds and causing confusion aplenty. 
Ah weird. If you look in the [diff](https://github.com/mgattozzi/mgattozzi/commit/89db3f3715d496c9180e3b644f806200a1d0c297) of the post I did put it there! Alt text is important! I'll have to look at why it didn't get rendered.
Sorry, I meant title text. Good on you for putting the alt text in there :)
Ideally, **crates.io** would analyze the code and determine the minimum supported Rust version automatically, but that's probably hard to do.
Yeah, I looked into it a couple of days ago an there seemed to be a non-trivial amount of marshalling and unmarshalling of data you had to do across the FFI boundary. Made things a bit tricky - hopefully the new proposals help. Also maybe something like Neon or Helix might be useful for avoiding interacting with the raw C API directly. Dunno.
I'm confused "the possibility of working remotely for extended periods of time." suggests there is a main location, but it isn't mentioned.
And potentially buggy. It would be awesome, though testing compatibility would be a decent first step.
&gt; That's not a great position to have. It's one thing to recognize a flaw in the status quo and quite another to embrace it as inevitable. Well I actually meant the inevitable fact that you can never fully know something that is still changing. (I'd go as far as to claim that you can never fully know anything that isn't a finite subset of mathematics, but that would go to far into philosophics). &gt; We should strive to design our tools so they last a long time without needing a lot of churn. That's one of the core principles behind Rust's design in particular! Agreed. But that's exactly as what I perceive the ergonomics initiative: Trying to make things better without too much churn. And that's also the reason why the bolder module system proposals didn't make it: They would have caused to much breakage. I'm also aware that changing ergonomics is always unpleseant when you found you're workflow, but I believe that sometimes you need to replace the old pattern for something newer and better, even if it feels like bad thing are happening to your favorite tool. ([xkcd for reference](https://xkcd.com/1172/)) In general rust seems to be steering towards a sane change rate, especially with the no-ecosystem-breakage promise in the epoch proposal.
I am not sure if it even technically possible, e.g. how you'll process macros and especially procedural ones?
Hey! Nice! I’m going to be there. Looking forward to it
I mean, hopefully there aren't so many changes to rust that pushing people to use latest stable causes a lot of heartburn. One of the big problems in Java land and I hear C++ land is that companies try to force people to use decades old versions of their languages for fear that new ones might break SOMETHING. I think this sort of attitude is corrosive and needs to stop. It isn't that it is totally unfounded, newer versions of languages/compilers, once upon a time, did tend to break everything. However, at this point most things are really pretty stable. Rust has really strong backwards compatibility guarantees and increasingly complex codebases that depend on it (see servo). I think the day and age of needing to repeatedly rebuild things with a fixed version of a compiler are history. * The only case I can see where this might not be feasible is the embedded realm where manufacture X forked rust at Y and decided to never ever support it again... Sucks, but it does happen.
Ah, interesting. I think this has put me down the right path, but I think I'm still missing something. The build script seems to be used to generate output that is then consumed by the Rust compilation (either by code generation or linking) but in my case the code is generated during the compilation step. mod vs { #[derive(VulkanoShader)] #[ty = "vertex"] #[path = "shaders/vertex.glsl"] #[allow(dead_code)] struct Dummy; } VulkanoShader is defined here: https://github.com/vulkano-rs/vulkano/blob/master/vulkano-shader-derive/src/lib.rs By my limited understanding, the macro expansion happens when my `render.rs` file is compiled and it triggers a compilation of the glsl code referenced in the struct. The problem is that the contents of `render.rs` don't necessarily change between runs, but the contents of `shaders/vertex.glsl` might. `cargo build` detects timestamp updates on `render.rs` but not `shaders/vertex.glsl`. Based on the way the docs are phrased, it sounds like the default behavior is supposed to trigger rebuild if any files in the crate change, but in practice I'm only seeing that happen if files with the `rs` extension change. I think part of my confusion is that I don't entirely understand the default cargo behavior.
How hard would it be to break these optional features into separate optional crates? Something like - diesel-core - diesel-chrono - diesel-libsqlite3 That way, if chrono never stabilizes or something newer/better comes along you can eject it and make a new diesel-atomic-clock or whatever and your downstream dependents could similarly and gradually swap in and out those diesel pieces that don't fit their needs.
It is not possible to provide this from another crate in Rust
Build scripts can do anything, including nothing, or just sending flags to Cargo like we want to do. They're just arbitrary code that's run during compilation. Looking closer at the docs (I submitted my original comment on mobile), it looks like it only re-runs the _build script_ based on those parameters, not necessarily the entire build (but I assume that if the build script needs to be rerun, then the entire crate should be rebuilt as well? Give it a try). If that doesn't work, I think you can also get the behavior you're looking for by using `include_bytes!()` or `include_str!()` on your shader files somewhere in your code. You don't have to use the return values of these macros, it just implicitly tells the compiler that your code depends on the contents of those files, which it also reports back to Cargo. The constants should get optimized away in release mode, if you're worried about file sizes.
Thanks, those are some good tips! I'll have to do some experimentation this evening.
Why is it not possible to create a single Rust project which wraps browser API interaction, such that new projects simply depend on this one project, and therefore does not need to deal with JavaScript glue itself? Isn't that more or less what the stdweb crate is trying to do?
I realize it's probably not your fault, but holy crap, "technical analysis" is a ludicrously broad term for something specific to stock markets. Honestly, I only clicked to see what you were actually talking about! :) 
I think this is kind of a historical thing, mixed with a little bit of language design. The very first scripts (running on some Multics precursor in the 60's?) would've been simple lists of commands that you piped directly into your shell. I don't know what the first shell was that supported functions, but the Bourne shell on Unix [didn't add them until 1984](https://www.in-ulm.de/~mascheck/bourne/). Later scripting languages like Perl and JavaScript inherited this style, partly because it makes sense for them, since a lot of scripts are short and don't really need functions. Compiled languages are designed more for larger programs, with code split up into lots of different files, so it usually makes sense to have a "main" function that says where the program starts. (Otherwise, how do we know what file to run first?) That said, plenty of compiled languages let the programmer do stuff "before main", as long you don't really care what order it happens in. For example, this Go program prints `foo!` before it prints `main!`: var my_global_variable = foo() func foo() int { fmt.Println("foo!") return 0 } func main() { fmt.Println("main!") } Rust is a little stricter than most other compiled languages, in that it completely prohibits this sort of thing. That was a design choice, partly because the designers thought "life before main" causes more harm than good. But for the most part, the "main function calls other functions" style of the language was simply inherited from C and the languages that came before it.
Let us know!
I think Rust can be strong in WebAssembly but you would be mistaken if you think it will be the only choice, or the obvious choice. As of this writing [Mono](http://www.mono-project.com/news/2017/08/09/hello-webassembly/) can run C# programs on webassembly. [Go is making strides](https://github.com/golang/go/issues/18892#issuecomment-347057409) towards running in WebAssembly also (channels are working?) and I'm too lazy to search but I'm sure Swift, Kotlin, etc. Are moving to that space also. As Rust has no runtime, etc. Potentially will always have a use-case for Webassembly but I think most people will stick to the language they already know and in a few months we will see strong libraries, etc from those communities on top of their Webassembly support. So, yes, let's do this, it's going to be big for all languages in 2018.
I hadn't thought of the challenge considering an exit out of the lower values as a possibility, though that is a good point.
[Gothenburg Sweden](https://www.google.com/maps/place/Gothenburg,+Sweden/@57.6903162,11.8480785,11z/)
This one doesn't panic on parsing error. This may be what OP asked though.
This seems like it would waste a lot of resources idling...
Best book to learn Rust? Maybe some good project ideas?
OK, so having dug into this a bit more, I think I have a real answer now. For the most part this idea wouldn't fit the usage model of Criterion.rs. In our case, you run the benchmarks once to establish a baseline, then tweak the code and run them again. The saved sample is then loaded and compared against the new sample. At this point, we no longer have the original function available to continue sampling it, so it's not possible to do as you say. In general, I don't expect this to change. It's too burdensome to require the programmer to duplicate all of the code in the benchmark to be able to compare the runtimes for the old and new code. It is valuable to have the ability to do that when needed, but it's not the main use case. Criterion.rs does have some functionality for comparing different implementations, but currently this is largely limited to generating extra plots with no additional statistical analysis. Possibly that functionality will be expanded in the future.
Yeah, upgrade your router with a firmware written in Rust.
There's [a list](https://github.com/ctjhoa/rust-learning) of learning resources! There's also [the official book](https://doc.rust-lang.org/book/).
Rust... In spaaaaaaace!
What are you using for drawing, windowing and sound? How is it working out?
That's to find such issues that we have [`clippy`](https://github.com/Manishearth/rust-clippy): ``` warning: use of `or` followed by a function call --&gt; src/main.rs:28:5 | 28 | rx.try_recv().or(rx2.try_recv()).map(|x: i32| { | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ help: try this: `rx.try_recv().or_else(|_| rx2.try_recv())` | = note: #[warn(or_fun_call)] on by default = help: for further information visit https://rust-lang-nursery.github.io/rust-clippy/v0.0.175/index.html#or_fun_call ```
Hi! It seems you're looking for the other subreddit, /r/playrust. This is a subreddit dedicated to the rust programming language, not the rust game.
Clarification: `lazy_static!` does not do initialization at program initialization. The first time you access the lazy static, the initialization is done.
What does it save? If it is a collection of each individual, previous runtime, these can be resampled with replacement to compare against the new version. In any case, I too was doing some digging after getting interested -- the Haskell Criterion linked to a super interesting paper that describes Julia-lang's approach to benchmarking, making a strong argument for using a min (https://github.com/bos/criterion/issues/122).
I definitely agree that it would be nice for cargo to have shorthand for documenting private types.
`use *` in the general case is bad, yes. The crates that have a specifically designed prelude to -avoid- minimize copy-paste declarations for the general case of the library may be on to something.
I dunno; this seems more like a fundamental misunderstanding of how control flow and evaluation works. Or possibly you're expecting magical behaviour that Rust just *does not ever* do. Like, D has lazy function arguments which could be used to make something like `Option::or` lazy, but Rust doesn't have anything similar. I don't know what your background is, but in Rust, you should assume by default that everything is fully and eagerly evaluated, then add exceptions from there. If you're unsure, assume it's eager and double-check.
Still working on graphics projection stuff for ggez, a 2d game framework. I discovered some *exciting* details about how resizing a window interacts with OpenGL contexts, but I'm sure we'll get all the edge cases worked out eventually! It also turns out that there's a lot of people out there thinking about distributed social network systems... And they all seem to be writing Rust. I think that you could replace "social network" with "web-like content publishing system" and it would be grand, but it's still fun to talk about with them.
Because it makes code easier to read. It doesn't take long to get used to distinguishing between the two kinds of numbers. Personally, I think that if you're writing code and you're not sure from context if you're dealing with integers or floats... that's maybe something you should address instead of trying to paper over it. The two can have *very* different semantics.
Continuing to work on [Criterion.rs](https://github.com/japaric/criterion.rs). So far, I've dug into the analysis code to figure out how it all works and taken copious notes. Going to write up some documentation on that. I also plan to add my own macro_rules-based benchmark harness (like the Bencher crate has). This will make it so people can just use `cargo bench`, because nobody wants to remember the arguments you have to pass now. Should be a nice ease-of-use win. Both of those should probably land this week, depending on how busy I am on the weekend. Afterwards I'll start working on a stable-compatible release.
you can test one `Instant` is greater than another. https://play.rust-lang.org/?gist=1c5bfe9bae1331e6c753c95b4f9bf528&amp;version=stable So, use this when you aren't sure: let now = Instant::now(); let has_5ms_elapsed = now &gt; prev_instant &amp;&amp; now - prev_inst &gt; Duration::from_millis(5); I've run into this as well - imo it's extremely easy to accidentally panic with `Instant`.
That hits all the marks for me, checking if a time has occurred, or will occur in some duration. Thanks! Any thoughts about what I noticed in the docs? After reading them a while neither `Instant` nor `Duration` are words to me anymore, so it's possible that I just misread (but I did go over it a couple times).
I agree with your point about the docs. Further, this would not be as big of a deal if it didn't panic - why not return a `Result`?
Haskell has a library called jsaddle which autogens bindings for GHCJS for all the browser APIs. I suspect stuff like that will be common. Furthermore, jsaddle supports abstracting those JS APIs such that you can even call them on a remote browser from a native haskell process, letting a native haskell program run as a much faster mobile or desktop app. The marshaling of data across this was totally negligible compared to the performance boost we got from not compiling to JS, so I'm not too worried about any marshaling required with WebAssembly. I'm extremely happy about the host-bindings proposal; the GC proposal is much too complex and invasive. But until I can call the DOM APIs from a thread that can block, I don't really care about it. I'm fine just marshaling data with jsaddle across a webworker using WebAssembly's existing FFI once we have haskell compiling to WebAssembly.
Welcome to Reddit. Before posting to a subreddit/forum/community, you should check to see what that subreddit is for. This includes reading the sidebar and the rules. You should also pay attention to warnings that you're posting to the wrong subreddit. Check /r/playrust. 
I think this is a little bit unsympathetic. For example, I think OP would probably look at the following and realize it is undesirable: or(rx.try_recv(), rx2.try_recv()) But this rx.try_recv().or(rx2.try_recv()) is a little less obvious, and personally, I think it's an easy misunderstanding to make (hence the clippy lint).
How does gradle handle it?
But they're no different. They're both calls with arguments, and the arguments are eagerly evaluated. That's why I said it seems like a fundamental misunderstanding of how the language works: it's just *not* how Rust works.
For some reason I thought this is part of gradle while it was part of android plugin for gradle — https://blog.mindorks.com/implementation-vs-api-in-gradle-3-0-494c817a6fa Basically, you have you specify is that part of your API or implementation which in return helps with detecting what needs to be recompiled.
I agree, it feels like `std::time` as a whole hasn't been getting a lot of love. The API is approximate, but also very strict. It's a weird combination.
I just wish I could do something like `some_float / 2`, I don't feel like I gain any readability at all from 2.0, maaaaaybe I know that it's definitely a float division &amp; not an integer division? Realistically I'm ploughing through easily 100 of these errors a day0.0
I have to agree with Quxxy. Coming from Python and other eagerly-evaluating languages, they're both equally clear... argument expressions are always all evaluated before the function/method call takes place.
What about blocking? With the existing libraries and applications we might want to port to wasm from many languages, it seems like we need to support the traditional execution model, which involves a lot of blocking. My plan for Haskell is to only interact with the DOM over a webworker boundary, using atomics to block the webworker when necessary. I think there should be a `libc` that does this, and which simply errors when run on the main thread. Having `libc` would help get rid of all the special case wasm stubs in the std crate for rust anyway. Does this sound reasonable to you? Should this be how Rust prioritizes moving forward?
I really feel like the difference of two instants should be an interval, not a duration, at which point it makes sense to allow negative intervals.
You can write 0. and 2. too. Currently that's just a quirk you'll need to live with.
To be honest, I do see your point. From my perspective, if we're going to infer whether floating-point literals like `2.0`mean `2.0f32` or `2.0f64` and whether integer literals like `2` mean `2u32` or `2i64` or the rest of the possible integer types, there's no real benefit to not also inferring whether or not a `.0`is implicit in an integer literal like `2` that's accurately representable in base-2 mantissa+exponent form. It's not as if it'd be allowing implicit type conversion of arbitrary values at runtime.
That did the trick, thank you! build.rs: fn main() { println!("cargo:rerun-if-changed=shaders/vertex.glsl"); println!("cargo:rerun-if-changed=shaders/geometry.glsl"); println!("cargo:rerun-if-changed=shaders/fragment.glsl"); }
To clarify, I don't think anybody is misunderstanding how eager evaluation works, I think this is just a mistake made in haste.
Sure, probably at /r/playrust though.
I don't find either really intuitive to be honest. I agree with /u/Quxxy that falling for this betrays a lack of understanding of strict evaluation.
For windowing I'm using `glfw-rs`, which works almost perfectly with emscripten other than it crashing when trying to call set_char_mods_polling. For graphics I'm using the `gl` crate, generating bindings for `Gles2` with the `StaticStructGenerator` (the struct generator doesn't work because emscripten doesn't yet generate bindings for WebGL 2 functions). Sound is somewhat tricky, since wasm doesn't yet support threads. I ended up using `rodio` for audio loading and `alto` for playback (rodio uses threads so it can't be used for playback yet). Not a perfect solution but it works. Overall it was surprisingly straightforward, the only real issue is the lack of thread support, but my game is simple enough that it doesn't matter much. The image crate's jpeg decoder also uses threads so you can't load JPEGs yet, but that's not relevant for my game.
It can be confusing at first, especially because macros don't obey the same "fundamental physics" as functions. `println!` is one of the first things you'll see and it *borrows its arguments instead of taking the value from them*, which is weird but unless someone calls attention to it easy to miss. It's possible for macros to evaluate lazily; `lazy_static!` is the only common one I can think of.
It might be because of `||` (and `&amp;&amp;`), which *is* lazy in pretty much every language, but that behavior is rather unique to these operators. For this reason, I believe `.or()` is both less useful and less commonly used than `.or_else()`. Besides, `.or()` is a strictly weaker abstraction than `.or_else()`.
You can even replace those closures with method references: skip_while(Option::is_none) filter(Option::is_some) any(Option::is_some)
Oh, yeah, but that's kind-of a given. *All* the rules go out the window once macros are involved. It's an excellent reason why they're explicitly distinguished from regular function calls *unlike certain other languages but I won't name anyone*.
&gt; Using or_else achieves lazy evaluation because "evaluating the expression" for a closure's definition doesn't execute the code contained within. I think it's best to teach that lazy evaluation (and consequently weird control flow) is what closures do. `||` even looks like a pause symbol, which may be a helpful mnemonic.
I use this style all the time because I'm lazy but if I'm being honest this makes even less sense than 0 and 2.
Here's a possibly better function to help with this: [Instant::elapsed\(\)](https://doc.rust-lang.org/std/time/struct.Instant.html#method.elapsed). Your approach: let earlier = Instant::now() + Duration::from_secs(3600); sleep(300); Instant::now().duration_since(earlier); could be rewritten as: let earlier = Instant::now(); sleep(300); earlier.elapsed() &gt; Duration::from_secs(3600)
It's really hard to tell without context, but if you have functions that need to be trampolined like that shouldn't they be returning `Option&lt;Result&lt;A&gt;&gt;`? And the whole thing sounds like a future.
Does the work on Tower result in any planned/future changes for Hyper?
Banning repeat offenders seems a pretty efficient way to solve that particular problem...
Probably, though not sure exactly what yet.
I ran into this a while back with insert instead of insert_with, it's one of those things you just have to learn once.
Well obviously it's a fundamental misunderstanding, but that doesn't change the fact that the misunderstanding happens. The language shouldn't change around this but perhaps docs should, or maybe the way evaluation occurs should be earlier in the book.
Honestly || and &amp;&amp; could be a trait implemented with a closure which the compiler can just optimize to the same anyway. In which case you could just `None &amp;&amp; Some(4)`.
Right. My point was that it doesn't seem like it's `Option::or`'s fault or responsibility to explain this; that should be done "higher up" the doc stack.
That part of my question was actually just to demonstrate a panicking call to `duration_since` that the docs say shouldn't be possible.
I think you're on to something. 
We just need the RESF to manage to get Rust in prod there and we're good to go.
For JavaScript developers to adopt Rust, it would have to become a *much* easier language to use. These are devs that are used to having a very lenient compiler. Forgotten a semicolon? Meh, that’s optional. Adding a float to an integer? Everything is a double anyways. Comparing a string with a number? The number is converted to a decimal string automatically. Memory management, what’s that? Along comes Rust, where the rules are so complicated that I with 30 years of programming experience and a small Rust project under my belt still have to use trial-and-error to get those pesky memory management rules right. Most of the time, the error message isn’t helping at all, pointing to the wrong part of the code or complaining about something completely different. I will still use Rust whenever possible, because I have the patience to get it right, but many web devs just want to ship something that’s good enough. That’s not possible when your code doesn’t compile because it’s not perfect.
That and iterators in Rust are lazy. Going through a connection won't do anything unless you ‘collect()‘ at the end.
There's a reason. It's so that it is completely clear what class of numeric types your literals are and what types the expressions are and so distant changes in your expression can't change how a portion is interpreted. Imagine you have the expression "1/2 + 3*4" Rust will interpret this as integer arithmetic so that the "1/2" portion of the expression has value 0 and the whole expression as value 12. Now suppose you changed this to "1/2 + 3*4.5", should the whole expression be converted to floating point? Just the multiplication clause? Consider Python. In Python 2, "1/2 + 3*4" evaluates to (integral) "12" while in Python 3 the same string evaluates to (float) "12.5". In Python 2, "1/2 + 3*4.5" evaluates to (float) 13.5 and in Python 3 the same string evaluates to "14.0". Bottom line: floating point and integer arithmetic can be very different and the compiler can't know what you actually want to do. In weakly-typed languages, the compiler tries to "help" you by guessing what you want, but this turns out to be a common source of bugs. Rust just asks that you tell it what you really want to do.
I don't know...Any actor framework after working with erlang is weird because it's lacking pattern matching in the function signature and scheduling is odd. 
I've taken it for transducers in Haskell.
Yeah the chance of bugs when auto-converting integer literals to floats is just too high. Rust has a strong type system with numbers and I consider this one of Rust's features. Yes, even I am annoyed sometimes when the compiler points out I need to add a .0 but I prefer this to discovering a bug where the compiler assumed something that is not obvious from the syntax and where I didn't want it to assume at all. This is what happens with C/C++ all the time.
Disclaimer: I don't really know anything about wasm. All the big js frameworks (react, angular) use this concept of a lightweight virtual DOM. Where the programmer's code updates the VDOM and the framework checks what actually needs to change and changes those things in the real DOM. I guess that's really good for performance because the DOM is big and slow. Would it be possible to do such a thing for rust / wasm in general? So the rust API would allow to change the virtual DOM and some js code would then update the real DOM and send the events into the wasm module. 
You'd be surprised of the number of "web developers" (I'd also argue that web development is very traditional...) that _already_ moved towards Rust. Indeed, even a sizable part of the team comes from there.
It seems the `wasm32-unknown-unknown` target still has quite a few rustc bugs, and quite a few LLVM bugs. From what I know the LLVM bugs will be fixed when either rust upgrades to the next version of LLVM (which might be a while) or rustc specifically works around them. Release mode works fine for though, so I'd say use that for now - it doesn't seem to have much of a disadvantage at least for small projects.
In *ring*, `digest::Digest` already allows you to write code that's generic over the algorithm, and it even allows for selecting the digest algorithm at runtime instead of compile-time. &gt; Additionally, working with Signature is not very economical at all (It doesn't implement any of the commonly expected traits like Clone If you want `Signature` to implement `Clone`, just submit a PR for it. If nobody submits a PR for it, it will never be added. In general, we never add features to *ring* that nobody requests. &gt; it's hard to write serialization/deserialization code for it, etc). `Signature` is already the serialized form of the signature. In fact, *ring* only deals with serialized forms of signatures.
That's what I'm planning to do in a few weeks after I flesh it out a little bit more! We *do* have an official repository on Github with a few projects already so it shouldn't be too much of a problem to get approval.
That's what I'm planning to do in a few weeks after I flesh it out a little bit more! We *do* have an official repository on Github with a few projects already so it shouldn't be too much of a problem to get approval.
Looking back I may have sounded a bit aggressive which wasn't the intention. I were just worried that there was either a bug with `PartialEq` + enums under certain circumstances that blew up compiletimes or that there was still a perception that it did that. &gt; I think the original comment was noting that there was a lot of generated code for derived PartialEq in particular, The thing is, as far as I can tell `PartialEq`, don't generate any more code that any other derive. Maybe it seems that way because `PartialEq` (and `Debug`) is the only two traits that are more or less always derived on a type... Still that is not a problem with `PartialEq` itself but more a consequence of being a useful derive. Also I doubt you'd actually detect any actionable information with `llvm-lines` on `PartialEq` derives since either you don't use the `PartialEq` and thus could remove it, but now LLVM will have removed the IR before `llvm-lines` sees it (`emit-llvm-ir` is done after LLVM has run optimizations), or you are using an `impl` and `llvm-lines` sees and reports on it but now you can't remove it since you actually needed it :/
&gt; Patch lines or patch hunks? Whatever you select. It can be anything from a single line to an entire file. &gt;but since you're decided to commit and maybe push/pull changes with GUI, why would you close it at all? Usually because I realized I needed to make another change outside the commit window before actually committing. Of course, I could just amend the commit after, but if I realize before it's committed I usually prefer to just stage stuff and make the change before committing. Once stuff is changed, I can then view the diff between the working directory and the staging area, so that I know exactly what changed since I last staged it and can easily pick out only the changes I want after doing whatever I needed to do. Without a staging area, the entire working directory is basically just your staging area and unless you actually make sure to reset changes you didn't want to commit (not convenient, since sometimes they may be stuff you want for debugging purposes or want to commit as a separate commit) you'd have to look over it again to make sure no unwanted changes snuck in every time.
If I'm not wrong mio -&gt; tokio -&gt; hyper. So if you want more control go for mio, if you want *simpler* (relatively speaking) interface go for hyper. I believe you should have similar results with all of them. &gt; Performance premium is on latency, not throughput What do you mean exactly? You want something that initializes quickly?
How do you do even loops in such environments? I always wondered about that. Events like kqueue and threads...
The context is the following function. I did not incorporate the (succinct) if let suggestion yet. `await_next_record` is more or less a poll loop that can return `Ok(None)`, and `Ok(Some(...))`. If it returns `Ok(None)` it should just be restarted. It's prototype is `pub fn await_next_record(&amp;mut self, wait_time: JournalWait) -&gt; Result&lt;Option&lt;JournalRecord&gt;&gt;`. /// Iterate through all elements from the current cursor, then await the /// next record(s) and wait again. pub fn watch_all_elements&lt;F&gt;(&amp;mut self, mut f: F) -&gt; Result&lt;()&gt; where F: FnMut(JournalRecord) -&gt; Result&lt;()&gt; { fn try_and_try&lt;F,A&gt;(mut f: F) -&gt; Result&lt;A&gt; where F: FnMut() -&gt; Result&lt;Option&lt;A&gt;&gt; { loop { match f()? { Some(r) =&gt; return Ok(r), None =&gt; continue } } } loop { let candidate = self.next_record()?; let rec = match candidate { Some(rec) =&gt; rec, None =&gt; try_and_try(|| { self.await_next_record(None) })? }; f(rec)? } } 
Rust is like so casual in this. In Ocaml once writes `0.5 /. 0.1` with `/.` for float division like a Mensch.
But the problem is that Rust _does_ when you write `1` automatically assumes this is `1u8` or `1i32` or `1isize` and what not based on whatever type checks. I don't feel that if you do that already updating it to floats is that much different. Especially when it defaults to 
No, not here. But it certainly might, if `f` is only checking, say, whether a package arrived. But here `f` is a sync wrapper around epoll.
I agree. It's not gonna be a choice between C++ and Rust. [GC support is coming to WebAssembly](https://github.com/WebAssembly/gc/blob/master/proposals/gc/Overview.md) which means it can be the target of pretty much all high level languages like Scala, ReasonML, PureScript, Kotlin etc. Also, I don't see wasm as something revolutionary (but a good progression), it's basically a faster and more compact version of JavaScript/asm.js. It's definitely going to be an important platform for Rust as it can help spread the use of Rust to new application domains.
Yes! That's nice. Thank you. That sounds like what I want.
[@slightlylate's latest tweet](https://i.imgur.com/1GLg93o.jpg) [@slightlylate on Twitter](https://twitter.com/slightlylate) - ^I ^am ^a ^bot ^| ^[feedback](https://www.reddit.com/message/compose/?to=twinkiac)
You are right. That's nicer. I wonder, why clippy does not suggest it.
I disagree: Result&lt;Option&lt;A&gt;&gt; is useful for a function that might fail (Result) and either returns something, or not (Option).
I don't think I've ever used `Option::or` or `Result::or` so far, really. The only instance where it makes sense -- both from the correctness and performance PoV -- is when you already have an inexpensive wrapped constant (`Some(foo)` or `Ok(foo)`), which basically never happens. It is much more common that you: * have an inexpensive, _unwrapped_ constant ("default value") that permits you to use `unwrap_or` * have an expensive unwrapped constant (like a `String`) which requires `unwrap_or_else` * have a fallback operation that you want to perform in case of `None`/`Err`, in which case you'd use `or_else` So given all this, and the fact that every instance of `.or(foo)` can be replaced with `.or_else(|| foo)`, I wouldn't even mind deprecating `.or` entirely, as it is apparently error-prone as well.
An issue has been opened: https://github.com/vulkano-rs/vulkano/issues/890
Great work! Btw, I wish there was a Rust library to talk to crypto exchanges like this: https://github.com/timmolter/XChange
I can't find any document describing the format or cryptography used. (Plus I don't see any zero-knowledge proofs, so I assume the author is another spideroak terminology victim?)
I have to say the Rust Playground WebAssembly output isn't particularly interesting given it seems to be dumping the whole Rust std runtime in there as well. It seems like module imports are an equivalent concept in WebAssembly to dynamic linking. Is there any plans to support this in Rust?
Yeah, that was me. 👍
I'm really excited that we're getting some good movement here; moving towards including [structured logging by default](https://github.com/rust-lang-nursery/log/issues/149) in the eco system is quite a win ^_^
One thing I don't really have a feel for is whether to write functions that take values or references for simple numeric types. As a trivial example, say I had a `Vec&lt;i32&gt;` and wanted to iterate over it and double each number, which would be preferred from a performance point of view: fn double(n: i32) -&gt; i32 { n * 2 } vs. fn double(n: &amp;i32) -&gt; i32 { *n * 2 } i.e. is it cheaper to pass around references and then dereference in the case of simple primitives, or is it preferred just to rely on copying the values?
Are your files dynamic? If they're not, you should probably just stick Iron behind an Nginx instance and let Nginx handle the big-file-serving - it's likely to be quite a lot better at it than whatever you roll yourself.
[removed]
Seems that way. The author even acknowledges it: https://github.com/zboxfs/zbox/issues/4
No doubt! But this is just a basic web interface to a desktop application, so Nginx is not an option.
They are a little different though, with `||` and `&amp;&amp;` you could do stuff like `foo() || return bar`, which cannot be rewritten using closures, it can be rewritten as `if foo() { true } else { return bar }`.
&gt; Like, D has lazy function arguments which could be used to make something like Option::or lazy Swift as well (`autoclosure` arguments).
I'm not sure it's a good idea to handle a virtual DOM in Rust, because this kind of data-structure (a mutable graph with cycles) isn't really simple to deal with efficiently in Rust. It's really simpler with a GC, and I think it could be more efficient also. I'm no specialist though and I'd like to hear more informed comments on that topic.
Yeah that's true. I've always said that "return" is super arbitrary in Rust and that it needs properly labeled returns. You often see weird constructs in Rust in order to "be able to use return" because Rust has no labeled returns. This is also a problem with the `?` operator.
I see that this has async hyper support. Does this operate on a single thread or does it use multiple (for example, one per core)?
The main issue is that Apache 2 includes a patent grant. Basically, this makes explicit that the authors aren't giving you code under a "free" license and then are going to surprise you with a patent lawsuit later. (See the license text for the real details.) This is generally considered a good idea. But... for historical reasons, the patent grant clause is incompatible with the GPLv2. The GPLv3 fixed this, but there's still a lot of GPLv2 code out there. Dual-licensing under Apache 2 + MIT means that anyone who wants the patent grant can have it by picking the Apache 2 part, and anyone who wants to be able to use your code with GPLv2 code can do so by picking the MIT part.
It would also be worthwhile to see request per second benchmarks vs a few other web frameworks
Actually you only need to add the dot not the zero to represent float.
Author here. Sorry guys, the term 'zero-knowledge' seems a bit misleading in the description. I'm gonna to change it to a more meaningful terms.
I see `or()` as just a practical way to specify constant defaults.
If you're asking when to use CString/CStr over a raw pointer: Pretty much always. If you're asking when to use CString over CStr: - `CString` for when your Rust code borrows a string to some C code. - `CStr` for when the C code borrows a string to your Rust code. - `CString` as soon as ownership of a string is transfered (moved) between Rust &lt;-&gt; C (ie. when the other side is responsible for freeing the string). * \* I you move the string from Rust to C, you'll have to use `std::mem::forget(the_string)` so that the string doesn't get deallocated by the CString destructor. ^I'm ^not ^a ^pro ^so ^I ^might ^be ^wrong, ^someone ^please ^correct ^me ^if ^that's ^the ^case.
LLVM does this optimization, if you remove the `#[inline(never)]`: https://godbolt.org/g/X1EZeB
Maybe use `unwrap_or_else`? ``` result.unwrap_or_else(|_| panic!("failed to pick a number with roll {}", roll)); ```
Whoa, the fact that Clippy recognizes this is really a good news for me. Just recently I've found exactly the same problem in Java with the same answer – to use: Optional#orElseGet instead of: Optional#orElse . Another reason to like Rust even more :)
It doesn’t use hyper, it uses tokio though. It is possible to run it on multiple threads
At this super low level, it doesn't really matter performance-wise, but passing primitives by value is more idiomatic.
I added some context below. I don't think I can use an iterator.
I mean this'd be fine if we didn't already have it in loads of other languages, I'm pretty sure most people would be fine with a standard method of coercion with your example of `1/2 + 3*4.5` (by that I mean `1/2` evaluates to 0i, `3*4.5` evaluates to 13.5f, and `0i + 13.5f` evaluates to 13.5f)
There is also 0f32 and 2f32.
Here is one such attempt: https://github.com/kryptan/webinden See example in the readme, or download it and run `cargo doc --package webinded --open` to see API that it provides. But it is largely incomplete, only simple examples do work.
You could use `unwrap_or_else(|_| panic!("Some useful error"))`
You shouldn’t be upset at Rust developers and Rust developers shouldn’t feel bad for wanting this to be rusts time to shine. None of us have an allegiance to wasm or an interest in seeing wasm shine.. there are no wasm developers. If you want to see wasm shine you should be excited to see every language race to support it best, and if you want to see another language shine, you should root for that language rather than say “slow down Rust”.
[This was brought up before.]( https://www.reddit.com/r/rust/comments/7gsq89/the_playground_now_has_a_wasm_button_for/dqlkjav)
TIL that Mensch is an insult.
No [quite the opposite](https://en.wiktionary.org/wiki/mensch#Noun).
If you want, I can build the game for you on a mac, so that macOS people can play it too. PM me your email if you want to!
TIL #2.
For me an interval has both a start and an end and not a signed difference.
Sorry, it may be that it's the morning, but I'm not entirely sure what you're asking. You're talking about wasm here, or Rust in general?
It absolutely is, and yes, that's what `stdweb` is trying to do. It's built on the emscripten project though, not on this target. Yet.
It doesn't eliminate JS, but React Native is a mobile framework (with efforts to port to desktop operating systems ongoing) that uses JavaScript fit the DOM stiff and fairly seamlessly integrates native code. If React were to get this same native code ability with WASM, you'd still have JavaScript, but you'd be able to integrate Rust the same way across platforms, so that's nice.
Possible, yes. Good idea.... maybe not yet. Wasm doesn't have direct dom access; you have to call through JavaScript. Now, the whole idea is that you're using the virtual DOM to batch up actions and interact with the DOM as little as possible, so it may still make sense... we'll see ;)
We have until about 2019 for that to happen, and even then, that only eliminates part of the binary overhead for runtimes.
There's actually a common criticism from many parts of the internet that Rust is bad because we have too many web programmers in leadership and in the community. I think you might be surprised at the ability of people.
I'm certainly not an expert on this, but from what I understand is that if you invent some new property of a type (e. g. is rational number), then you have to update all your functions that use such type to work with the property. So while it technically works, it's impractical. My idea was different even though it looks somewhat similar. The idea is this: bugs *usually* happen when writing to a variable or producing a value, but are *discovered* at places where the value is read from (used). Rust already uses this idea to guarantee safety. The library should provide convenient way to put the run-time checks on writes (as opposed to reads) and provide the compiler more information about variable it's reading. Example: Vec must always have capacity &gt;= length. Another: Buffer { slice: [u8], pos: usize, } the invariant is pos &lt;= slice.len(). Let's say we want to implement the Buffer struct. We somehow mark the structure to have invariant pos &lt;= slice.len(). Then we write the code the normal way we would, and the library ensures that: * we don't return mutable references to data which have the invariants. * at the end of each method, there's assert about the state of the structure (inserted by the library!) * at the beginning of each method there is unsafe { if !self.invariant_holds() { intrinsics::unreachable() }} If you return Self, there's a check and the final code actually returns Option&lt;Self&gt;. I expect it'd help with discovering bugs early and with optimization of run-time checks. I'd love to see the library to work, so I'll gladly mentor you. I'd write it myself, but just don't have enough time right now.
Yea I wrote that in a bit of a haze to be completely honest. I'm just a bit concerned that people seem to be thinking of wasm as a way to port JS to C instead of as a way to run C in the browser. My question was centered mostly around `libc`. I'm just saying: - `libc` ought to have support for blocking syscalls when running on a webworker. - Rust ought to just use `libc` rather than stubbing out stuff in `std` specially for wasm. - We should have good DOM access from said blocking webworkers, even if it's over a syscall-like boundary. - We should generally focus on this webworker method, since this is the traditional execution model for the languages intended to target wasm. Just wondering if you agree with these points. It seems like some people are more focused on just having the ability to call a rust function from JS.
wasm can't make syscalls.
Well, loops are just loops, but for threads and whatnot, you have to build a scheduler, wake up the other cores, and get them working.
You have to be careful if `cpal` builds. You may also have to update the fork here: https://github.com/fschutt/cpal for MacOS. The fork was due to https://github.com/tomaka/rodio/issues/148 - but when I received the answer, I already had written the code. The fix is very simple, the `run` function has to return `Option&lt;()&gt;` instead of `!`, you just need to fix the return type like [this](https://github.com/fschutt/cpal/commit/5b621f5d9901b9cdb5898d205f3a4a89a61c88c1#diff-702b544ec4c750c4a7f553d86ce3c930L267). I could fix it for Linux + Windows, but I couldn't test that cpal actually builds on MacOS. Since the fix was so simple, I did not bother to update the code to use `rodio` instead, since I was short on time. And linking freetype could be an issue - not sure in MacOS complies properly. But thanks, I'm happy if someone uses it.
Yeah, I did some benchmarking and performance was almost identical really. Knowing which is more idiomatic is good though, thanks.
Well sure it can. They just have to be emulated by the JS host ;) That's what I'm hoping to start working on soon [here](https://github.com/WebGHC/musl). Musl defines its stuff in terms of syscall primitives that JS gets to define, just like the process / kernel boundary
Yeah, I think we're using slightly different definitions of syscall here :) This kind of thing is certainly useful, it's basically the emscripten approach. The downside is that sizes are bigger. It's all tradeoffs :)
&gt; It might be worth warning about this in the docs and explicitly recommending the use of or_else when calling a function I would happily take a PR or issue about this.
&gt; it's lacking pattern matching in the function signature It's been a few years since I've used Erlang, and never *really* got into it, so forgive the beginner question but, you're saying that erlang has this, or doesn't? I thought it did.
I don't like this: it makes the `parse` function longer than necessary and adds an unnecessary level of indentation to `parse_line`. I would just not make `parse_line` public.
The level of abstraction you're talking about directly is Tokio, however, I think that hyper (through tokio) already does this, though I haven't dug into the internals enough to say. &gt; I would like to be able to achieve this without using someone else's loop, framework, or kitchen sink. Then, you're looking at using something like `nix`, making the syscalls directly, and going from there. There's a reason why these libraries exist!
It does.
So, Rust also has pattern matching in the function signature. Is there something specific it's lacking? I'll admit it's not the simplest thing...
Actix messages are statically typed. You can not send message if actor can not handle it
I haven't watched the video, but I like that the title is "Rust is successful, here is why" rather than "Here is why we think Rust should be successful". At some point we've got to abandon that idea that we're a niche technology, because that's becoming less and less true over time. 
Indeed.
This could significantly simplify deployment process for business applications, provided Rust sees adoption in that sector. What's your timeline for Windows support? Or are you looking for someone with more knowledge/resources in that area?
&gt; Furthermore, if you're modelling the DOM, you've got one of those data structures that Rust hates: a graph. But graphs don't have to be (reference counted) heap objects with pointers to each other. I've done some stuff with graphs in rust and it worked pretty well. Is there a writeup somewhere what the requirements for a vdom are? I would bet it would be not prohibitory hard to build a idiomatic and performant data structure for that.
Oh I'm not saying it's the worst, I'm just saying that it's not always the nicest thing, that's all.
That's interesting. I'll have to look at what happens in real programs.
I'm currently trying to write some code that takes IDL and outputs js so I can generate dom bindings. I should probably publish it if it works.
I'd argue the opposite. It's so annoying when implicit conversions happen in an unpredictable way, much better to error with a good message. Also what's with null, void 0, typeof _ = 'undefined', == null, === null, [] == 0, hasOwnProperty, (I could go on)
JS is really hard/weird!
Sorry, I misunderstood you there a little bit. Also, I didn‘t want to say its easy.
It's true, `std::time` has not gotten much love. During the push to stabilize Rust 1.0 it was stripped down to a bare minimum, with the idea that a more complete time crate could mature in the crates ecosystem. [chrono](https://github.com/chronotope/chrono) seems to be where that effort has gone, but it too has stagnated a bit recently.
It's all good :)
I consider SemVer to be fundamentally broken and this is one of several reasons why. The biggest issue with it at this point is inertia and lack of a clearly better alternative. I would love to see a version system enforced by a tool that lived on the package manager side. A package owner should be able to bumb things more aggressively, but should not be able to prevent bumping versions. We keep treating 0.x.y as this special thing that it shouldn't be.
What I don't like about what I see in the hyper 0.11 or tokio approaches is I have to "run" the work on a "reactor", which seems to take it off thread and basically mirror my current threadpool. Possibly I'm just not figuring out how to "run" the future in my scope. Thanks for pointing out `nix`, maybe I could Frankenstein something where I create a http request with hyper and send it with nix. 
I didn’t say that it’s a good language, but that it’s very different with a very different approach to getting things done. In JavaScript, you quickly have something that kinda works and needs bugfixing, while in Rust you need a long time to get something compiling, but then you've already done something right.
I’m not looking down on anybody. Indeed, I'm operating in both worlds myself as a freelancer. The basic concepts are just so different to each other. The inventor of JavaScript does not work on Rust. The tooling around Rust is indeed very similar to the tooling around JavaScript with cargo, but the languages themselves are not alike at all.
I meant when to use either type when I'm using a c function that takes the type c_char. Thanks
I operate in both worlds as a freelancer. I’m also writing a web application that augments a desktop application. At one point, the client asked me “why are you updating your framework again, you only did so half a year ago?”. I could only laugh on that, since in the web development work, half a year is a lifetime, and whole frameworks have risen and fallen in that time frame (I'm using a more stable one), while in desktop world, not much had changed in the last two years.
&gt; It might be worth warning about this in the docs and explicitly recommending the use of or_else when calling a function. It makes sense. If you really intended to do this, it would be better to write let arg = rx2.try_recv(); rx1.try_recv().or(arg).map(|x| { ... }) 
&gt; The inventor of JavaScript does not work on Rust. That's true, but he is a big part of the reason why Rust exists, incidentally. &gt; but the languages themselves are not alike at all. What I'm saying is, web programmers are in fact capable of learning more than one language, even one that's very different from their existing one. I totally believe that you don't *intend* to look down on anyone, but the words that you're saying imply that web developers are stupid. I don't believe they are.
&gt; At some point we've got to abandon that idea that we're a niche technology It's definitely a systems programming niche, but then... Rust has made systems programming accessible. 
Most important difference between 0.x.y and n.x.y (with n &gt;= 1) is that before 1.0.0 even new minor (x) versions can contain breaking changes. But if library follows SemVer strictly, is always OK to upgrade from v1.1.0 to v1.9999.0 and expect no breaking changes. As such, push for v1.0.0 in practice means push for stabilising library development so that breaking changes and new features stop being packed together in the same release.
On JavaScript projects, deadlines are always much tighter than anywhere else. I usually hear on Wednesday that I have to deploy a big new feature that’s been in development for two weeks on Friday. Companies like Facebook and Github use CI in a way that developer commits are on users' machines on the same day they happened. I don’t think that I could ever achieve that with Rust. “We can’t deploy yet, the code doesn’t compile!” is something that just doesn’t fly in web development.
Awesome! Great work, thank you very much!
Eh. I hear that a lot, but it sure seems like a lot of people want to write applications in Rust as opposed to "systems." Note: being an application developer, I'm not really all that sure what a "system" is. ;)
Sounds like my mio_httpc: https://github.com/SergejJurecko/mio_httpc It's not on crates.io yet but it works well from my testing. The reason I have no published is I'm still considering some minor changes to the API. There is a SimpleCall interface in which you give it your data and once it gets entire result it is returned and a streaming request/response interface that returns to client data immediately at every stage.
There is really no point in going lower level then mio. You will just be redoing a lot of tedious work that mio handles.
That is the hope!
System, the: Mysterious land "they" program in, not reached by the software we mere mortals program. It's related to AI, which has been defined (paraphrased) as: "Everything a computer cannot do yet. When a computer can do it it stops being AI and is just software - that's the reason there is never any progress in AI."
&gt; Many of the proposals threatened the stability of the language. When can you learn the language and consider you know it? When can you be happy about a safety feature of Rust and when will the language team say "oh no this is too hard we must dumb it down"? I think this is a pretty gross mischaracterization of the ergonomics initiative. &gt; The final proposal is okay This is exactly why the RFC process exists. The team should feel comfortable with figuring out various extremes and putting them forward knowing that the community will give them a better idea of where to settle down. This is not a shortcoming of the maintainership, this highlights why it's working well. &gt; It definitely should not be repeated. I suspect it will be; there are still a lot of things in Rust that are not easy to learn. In general the theoretical goal I think is that Rust should be something you can learn as a first language. That might not be practical, but it's a good goal to aim for.
I have a similar same complaint with the `futures` crate. Producing an error is producing *something*, and means the future has become complete. There's not much good reason\* for the implementation of `Future` to care about error handling. \*(Until recently Rustc wasn't as good at handling nested enumerations. So `Future&lt;R, E&gt;` was smaller than `Future&lt;Result&lt;R, E&gt;&gt;`. This is no longer true. The futures crate "leaks" this implementation limitation forevermore.) That said, the `join` combinator might want to cancel the other branches if one yields an error. But I think that's a good argument for something like this: `join_res(Future&lt;Result&lt;A, AE&gt;&gt;, Future&lt;Result&lt;B, BE&gt;&gt;) -&gt; impl Future&lt;(A, B), E&gt; where AE: Into&lt;E&gt;, AB: Into&lt;E&gt;`
I'm not upset at Rust developers or want them to feel bad. Nor did I say that Rust should slow down.
Didn't know rust was successful
&gt; This is exactly why the RFC process exists. The team should feel comfortable with figuring out various extremes and putting them forward knowing that the community will give them a better idea of where to settle down. This is not a shortcoming of the maintainership, this highlights why it's working well. The proposal is about the minimal consensus, and leaves the `mod foo;` question to be decided by a future change. I think it is already a great victory to have it out of the RFC but we might end up with the change down the line, especially if we are getting more of these "ergonomics intitatives". &gt; I suspect it will be; there are still a lot of things in Rust that are not easy to learn. If you are saying "we only stop if Rust is easy to learn" then you obviously define your goal in a way where you need to do one of those harmful ergonomics initiatives after another. Another issue is that many changes in the "ergonomics and learnability" initiative were positive about one of the two aspects, and negative about the other. Very rarely we had a change that improved both ergonomics *and* learnability. Take variadics for example (it is not been added, but it might be added in a future "ergonomics" initiative). It is "great" ergonomically but makes the language far more complicated and harder to learn, understand and read. Same for the "Ok wrapping" proposals that thankfully got postponed (but sadly not rejected yet!). Already one of these "ergonomics intitiatives" was harmful enough, I don't want even more of them!
There's a lot of middle ground where things get ambiguous, but there are also places where Rust is just a bad choice. 
&gt; System, the: Mysterious land "they" program in Not really. Systems programming (aka where Rust excels) is where you need manual memory management, for whatever reason. 
very cool - I will check this out for sure. 
&gt; you obviously define your goal in a way where you need to do one of those harmful ergonomics initiatives after another. Uh, yeah? This is the goal of the ergonomics initiative. Of course the goal of the ergonomics initiative will involve ... the ergonomics initiative. &gt; Take variadics for example (it is not been added, but it might be added in a future "ergonomics" initiative). I doubt variadics would be a part of the ergonomics initiative. 
The point - which I acknowledge may be based in ignorance, misunderstanding or not be worth pursuing - is to eliminate the overhead of sending the job to another thread to complete and return. The round trip to send and receive an int with mpsc is 5u in an optimistic microbench - small but real. Instead I want to busy wait my http request as part of a larger event loop. And if I knew how to eliminate the sys call and interact directly with the network device I would want to do that too. 
Erlang has it. I mean lack of that feature makes actors looks weird to me in any language other than erlang.
Consider replacing the match statements with "if let" where possible. You can also wrap your REDIS static in a Mutex to avoid unsafe code I think.
I have a question about the difference between `&amp;mut` and `ref mut`. I know one is a pattern expression and the other gets the mutable reference of a symbol. My question is more specific to returning mutable trait objects without `Box&lt;&gt;`. The question is posted in [stackoverflow](https://stackoverflow.com/questions/47680423/difference-between-mut-and-ref-mut-for-trait-objects) Can you help me?
Instead of a global mutable object that you have to use `unsafe` to access, try using `RefCell` or `Mutex` or `RWLock`?
The fact that Rust has a niche makes it successful. That it’s the niche it was designed to fill makes it especially so. All languages fill a niche. As an Erlang/Elixir dev primarily, I know this first hand. Know thyself. Being all things to all people is the definition of failure. Case in point: C++. 
I see, that is a really clear explanation.
Ah! Just so you know, you can pattern match in arguments in Rust fn takes_tuple((x, y): (i32, i32)) {
Awesome!
If you run into any problems please open an issue.
I do think there is a lot to learn from how the ergonomics RFCs went. They were very stressful for everyone involved, with some feeling that they were inevitably about to lose what they loved about the language, and others feeling attacked by hoards of insensitive contrarians. I do think that for the most part the language changes turned out okay. But next time we go to improve Rust's learnability, I hope we can figure out a way for it to go more smoothly. We've got some ideas already- eRFCs, the discussion around epochs of how important it is to avoid churn, an awareness of the "too many RFCs at once" problem, etc. Time will tell if that helps.
Just so you're aware, this only occurs for types that are copy or zero sized (like in your example). If you give it a non-copy element, that no longer works: https://play.rust-lang.org/?gist=648657103e2640d12f1c9403bf05d329&amp;version=stable Finally, while I don't know the exact reason `&amp;` doesn't work, I don't think the issue is two mutable references (otherwise it'd complain about the second mutable reference creation. What it's actually complaining about is "moving" the mutable reference out because its lifetime doesn't conform to it)
Isn't that just destructuring? 
Yes you did and are! That was he whole point of your comment.
&gt; there are also places where Rust is just a bad choice. Such as? I'm not disagreeing with you, just curious about your opinion of places where Rust is a poor fit.
&gt; &amp; I actually didn't know that. Thanks! Still, why it works being zero sized? 
There's zero data to borrow, so the borrow is also zero sized. It's basically a nice ergonomics thing because it realizes you don't need to borrowck something that doesn't actually exist. Note that you still can't have multiple mutable borrow to a zero sized type: https://play.rust-lang.org/?gist=d91276cbf709682c30cb1a561cd7d139&amp;version=stable
Yeap, in this particular case it's indicators :)
Compilers and to a lesser extent interpreters are the most obvious example.
You may be interested in this one: https://github.com/hugues31/coinnect However, it's far from providing native Rust experience.. That's why I came up with my own implementation of poloniex client: https://github.com/greyblake/poloniex-rs
Go behaves the same way as Rust, and I'm sure there are plenty of other languages that do as well. I'm not so sure that `1/2` *should* be `0.5f` instead of `0i` in the general case, though perhaps when the type *must* be a float, it could be interpreted as `0.5f`. So, `1/2 + 3` should be `3` (and probably a compiler warning if they are, indeed, constants), not `3.5f`, but `1/2 + 3f` should be `3.5f`. That seems a little confusing IMO. I think the best course of action here is to be strict since you'll likely just get into the habit of specifying the type (either `0f` or `0.0`), and erroring is better than hard to debug bugs.
Sure, destructuring is a feature of pattern matching.
Well, in erlang I can do this (example in rust because I can't stand erlang syntax): fn takes_tuple((x, y): (i32, 1i32)) { } fn takes_tuple((x, y): (0i32, 32i32)) { } fn takes_tuple((x, y): (i32, i32)) { } fn takes_tuple((x, y): (i32, i32)) when x.is_even() { } In case of rust (i32, i32) I see just as regular type. 
Got it!
Oh, believe me, the core team is acutely aware of the problems there, and hopes to fix them :) It's more of an "how do we make the RFC process work well" thing.
Ah yeah, so it's more about the syntax than it is about the feature. [Niko is a fan of maybe adding the syntax](https://github.com/rust-lang/rfcs/issues/1577).
Can you add multiple reactor examples?
In idiomatic Rust code is `or` or `or_else` more commonly used? You are right that the control flow is clear, `or` is implicitly more common by the nature being a very short word and should be reserved for the more common case.
That's an opinion that surprises me. I actually find Rust much better for compilers than C or C++: pattern matching is just such a joy! Or are you advocating slower languages?
This... is super cool! I'm really loving the trend of having nice yet simple websites for rust libraries.
Erlang has full pattern matching in function definitions, not just destructuring, you can define multiple functions with the same name with different patterns. Does Rust support that or just destructuring? That's what I meant to ask. 
Will do a little bit later. I am in the middle of deep refactoring. Will also add database and template examples.
See my other comment elsewhere in the thread.
No. The whole point of my comment was how the article came across to me and to remain more objective. I took care to not come across as anti-rust.
I figured out how to build the STD docs with what I currently have. [Here's](https://imgur.com/a/DRWjr) comparing `Shl` for `i32`, and [here's](https://imgur.com/a/47Ptg) comparing `PartialOrd` for `array`. I still need to fix the sidebar, as that still lists it the way it does currently, and I should make it not output the "Provided Methods" header if there are no provided methods.
I wouldn't call C++ a failure, but in my opinion it's going to be increasingly difficult to add new features to the language or the standard library without breaking anything or sacrificing ease of use. This of course also applies to Rust, but I feel that the foundations are much better, and Rust 1.0 was designed to be extensible. This design budget started to run out recently (see `dyn` keyword), but I think the better approach is to make small changes now (with only absolutely necessary breakage) and create the best language possible ready for standardization, than leaving everything as is.
Rust has what are called "algebraic data types", which is a fancy way of saying "structs and enums", but it means that by combining the two, you can express your data model with remarkable accuracy (though in Rust, you don't always get brevity). For instance, the structure you want would look something like: struct PhotoMetadata { image_permalink: Url, } struct TextMetadata { body: String, } enum Metadata { Photo(PhotoMetadata), Text(TextMetadata), } struct Post { id: i32, metadata: Metadata, } This removes the duplication of your version. It doesn't map perfectly onto the serde format you want, but if you write custom `Serialize` and `Deserialize` trait impls to flatten the structure, you'll get exactly what you want with a data structure that reflects your business logic.
&gt; The compilation in 32-bit platform issue, while real, is hardly a reason to deny altogether the opportunities that improving and including Rust code in their codebase could provide Why? If it doesn't fit into the established requirements for their project, why should they complicate their build process that has dubious benefits? Add to that the fact that Rust likely does not work on all platforms OpenBSD supports, so that's also a hard sell. I'm sure OpenBSD would be willing to include Rust in the base project, but only if it: - provided some tangible improvement (e.g. fixes a bug) - doesn't have any regressions - doesn't break the build for supported platforms - doesn't significantly increase build time Rust will have difficulty satisfying the last two and the person proposing a change to OpenBSD would need to satisfy the first two. I don't think the process is impossible, but it's definitely an uphill battle. OpenBSD cares a lot about safety and security, but well written C can also satisfy those requirements, so the more boring reasons need to be satisfied as well.
&gt;Or are you advocating slower languages? I'd suggest OCaml or Haskell. I'm not sure OCaml is notably slower (I don't have experience with it). The story with Haskell is complicated; it is possible to write performant compilers but not trivial.
But your anti Rust message was heard anyways
Great idea, turtle is how I learned programming!
Forgive my ignorance, but what keeps your window from just disappearing at the end of your main function?
My comment says "if speed is your top priority when developing a wasm app, then aim for Rust since it is type-safe and has a nice package manager." and "Rust is certainly an exciting language and has a lot to offer" and it's "Wasm's time to shine more than any one language" and you interpreted that to be anti-rust?
The last part is anti Rust because the core part of the article is that this is an incredible time for Rust and you wrote “shut up Rust fans this is wasms time not yours”. That is absolutely and without a doubt anti Rust lol!
No, this isn't how C works, 1/2 would go to 0i, and 1/2 + 3.0 would be 3.0, because 1/2 goes to 0 as an integer which gets added to 3. It follows the order of operations, unless I've got this really wrong._. It's always been pretty intuitive in c / java though, I've never seen the issue
Beta is the nightly as of the most recent release day, so it's anywhere from 0 to six weeks behind the current nightly. Importantly, all `#[feature(...)]` gates are disabled, the same as in stable.
Hello, I'm currently a student and I do some Rust work in my spare time. A project I've recently been tinkering with is a rust implementation of the popular JS library, Redux. It's been a good way for me to improve my understanding of the language and myself and another developer are hoping to have this available on crates.io sometime soon. You can check it out here: https://github.com/rust-redux/rust-redux
Thank you for your reply. Since Rust and libsodium are cross-platform, the most parts of Zbox should be able to run on Windows without problem. The only uncertain part is 'Path' and 'PathBuf', because that module is platform-dependent, I am not sure how it would be using separator '/' on Windows. Maybe it can work on Windows, but I just didn't test it. Maybe you can try it? Other than that, I can't see any other major obstacles.
Reposting this comment because it’s not showing up for me which makes me think you didn’t get it: The last part is anti Rust because the core part of the article is that this is an incredible time for Rust and you wrote “shut up Rust fans this is wasms time not yours”. That is absolutely and without a doubt anti Rust lol!
That's the second time you put quotation marks around something I never said. I never said "slow down Rust", nor did I say "shut up Rust fans". I don't need you to tell me what I meant but since you're having a hard time with reading comprehension: I LIKE rust. Satisified yet?
Right, I was just proposing something along the lines of what you proposed. &gt; It's always been pretty intuitive in c / java though For `1/2 + 3`, you get 3.5 in Java and 3 in C, Rust, Swift, and Go. Many (all?) scripting languages will return 3.5, though it's a mixed bag in compiled languages. The strongest argument I have for Rust returning 3.5 here is that Haskell does it, which is why I said that Rust *could* do it based on context (both Rust and Haskell intuit types in similar ways). However, changing it now would change behavior, which would violate Rust's backwards compatibility pledge.
I was actually surprised when I realized that all of the most popular languages are implemented in C/C++ in one way or another * C/C++ -- both GCC and LLVM are C++ * Java -- while javac is written in Java, HotSpot JVM is C++ * Python -- the most popular implementation, CPython, is in C * Ruby -- again, the canonical implementation is C * PHP -- the same? (not sure about this one) * JavaScript -- V8, SpiderMonkey, Chakra -- C++ I am not sure what's up with C#, but I guess CLR is also C++?
Interesting library, unfortunate name.
I can try when I get home. Should I just run the unit tests?
Hence I gave a talk about that.
Honestly, I'd argue that Rust is one of the better languages for writing compilers, outside of the ML family (although that's largely because of the ML influences on Rust so maybe you wouldn't consider it "outside")
If it wasn't, we wouldn't be using it, now would we?
No I’m pointing out exactly how what u said is anti the momentum of this thread.. obviously it’s not a direct quote and it wasn’t meant to be but that is the thrust of what u said.
&gt; Add a machine-readable JSON-output mode for Rust's libtest. Is there currently a way to plug in to the test output? I think it would be interesting to support custom test outputs, such as TAP and jUnit compatible outputs, but I don't think it makes sense to throw all of that into the testing framework. I haven't used Rust unit tests anywhere besides personal projects where I am the sole consumer, so I don't know what already exists. I would like to see support for something that Jenkins can consume (e.g. the [Jenkins JUnit plugin](https://wiki.jenkins.io/display/JENKINS/JUnit+Plugin)).
It sounds like you are upset with me and want me to feel bad, slow down and shut up. You're anti-me.
I believe that’s true actually. I don’t like what you’ve said here and for the good reason I explained several times now, and I don’t think you’ve been able to admit that what I’m saying is true despite you knowing it is. It’s made me anti you.
I see you guys here are less used to irony then r/memes community. By the way, some people use D, but would you call it successful because of it?
I don't admit it as you say because I already took the time up front to be clear, and then to immediately clarify with you what I meant when you took it differrent than I intended. That's all I can do but you're stuck on it, which is on you. But I'm sure no one has ever put words in your mouth in your life so you couldn't possibly understand where I'm coming from. Good day.
Oh, I didn't realise 1/2 would be 0.5 in java, maybe I've just been adding (float) all through my code out of paranoia. Yeah I understand it won't be changed, still a little annoyance. Maybe when tooling gets a little better it won't matter as much.
The main advantage of C I can think of is that it's more portable than anything else (this probably explains why Lua's interpreter is written in C). I hope Rust takes on the role of C/C++ where portability matters, though. 
Could I use it to render animations/images and safe them as `png` or something?
I'd agree there. But because of Rust's memory model, higher-order functions are going to be more difficult than is desirable. The main advantage over Haskell I see is writing portable interpreters.
wat. Haha. This is cool! Can someone explain how this works? How does Java execute WASM? I also wonder how it compares with traditional FFI, since [`regex` exposes a C library](https://github.com/rust-lang/regex/tree/master/regex-capi).
D has been successful.
It seems like a perfect case for a [lint](https://github.com/rust-lang-nursery/rust-clippy), if it hasn't already been done.
I have two pieces of backstory to that talk. First, the inspiration: My first conference was RailsConf Europe 2007. David Heinemeier Hansson gave the keynote and started to explain how Rails _had won_. I still find the framing as "winning" a bit odd, but in general, the talk was that Rails _crossed_ a threshold of adoption that will make sure it will stick around. I felt odd back then: Rails 1.0 was barely 2 years old, and there's DHH on stage declaring _victory_? What kind of person is that? Turns out he was right. DHH is a little more into showmanship then I am, but he's definitely also good at making a case. His case was (If I remember right, the video is not available anymore): * Rails is adopted by major players * It brought new development approaches into web frameworks * Its seen as a benchmark All of these were true. * Oracle and other major player were sponsors of the conference. * We don't remember it today as much, but working an agency job back then, the "build a blog in 15 minutes" video was awesome and foreshadowed a lot of the way web development would work in the following years * For the next years to come, languages would grow "Rails clones" and many of the modern heavy-weight backend frameworks are at least inspired by Rails. And finally, by the end of the talk, I knew what DHH was about: DHH was _happy_ that his project made a dent. And it already had. Rails has left its mark on the software world, if you like it or not. I feel like Rust has crossed a similar threshold. Wherever I go, I meet people have heard of it, have been using it or have some enthusiasts in their working group. I don't see that happening with D, for example. As I say in the talk, this is my _very personal_ reading. Yet, I think it's good to have the confidence to jump on stage and say that out loud! My second tidbit is that goto Berlin is organised by Dajana Günther, who used to be on the board of eurucamp with me. All I know about conference organisation, I worked out with her. She's much better at that, professional and all, but one thing I like about the goto Berlin conference is that despite being a business conference it _does_ show that it is organised by someone who did ample FOSS organisation before. 
The talk addresses both success metrics and (in the QA) D.
Check the repo the file is in, it’s an example for a WASM-&gt;JVM compiler
Sure, I wrote it. Most of the details are in the README at the [root of the repo](https://github.com/cretz/asmble). But essentially I wrote a compiler that compiles from WASM bytecode to JVM bytecode. It was hard to use other langs because so many targeted emscripten and the web. But when the `wasm32-unknown-unknown` target was made available recently, I wanted to try to run Rust-compiled WASM on the JVM. After toying, it was fairly straightforward. I compile the src/lib.rs you see there into a WASM file, then compile that into a JVM class file. Then add a bit of glue and done. There are a lot more details of course and I'd be happy to explain any piece of it. Highly likely doesn't come close to traditional FFI, especially with JNI. I have [another project](https://github.com/cretz/stackparam) where I use JNI/JVMTI and Rust FFI to accomplishj some things. That one is a bit complicated, but calling Rust via JNI API itself is quite easy and would be way faster. Wouldn't even want to leverage the C library, because JNI has its own C API I'd have to conform to anyways (see any of the `jni-sys` projects) before dropping into safe Rust.
Wow, this is really cool. Thanks for explaining. I think the bit I missed (probably from reading your README too quickly) was the JVM bytecode -&gt; WASM step. Seems obvious in hindsight. :)
Yes C++ is a language full of warts and corner cases. Even modern C++ is a giant pain, but to call C++ a failure is laughable.
Actually someone is putting words in my mouth right now, ana this is definitely not on me lol.
Pretty cool, I guess Rust just got a new backend :)
Is this how you argue with people, tell them waht their hidden meaning was so you can always be right? Because I'm not religious about programming language and didn't just say "Rust is the best" like you wanted me to so now I'm "anti-rust" in your eyes. It's sad because you're changing the subject, which is that no ONE language should claim dominance over web browsers anymore and so we can't even discuss that because you keep distracting from my original point. Maybe you're the one who doesn't want to admit something.
No prob, thanks for checking out the repo. Just a correction on the wording, it's not "JVM bytecode -&gt; WASM step" but "WASM bytecode -&gt; JVM step" (from WASM to JVM).
Ah right thanks! My brain is a bit scrambled.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/jvm] [Rust Regex Engine on JVM, via WebAssembly, Example and Benchmark • r\/rust](https://www.reddit.com/r/jvm/comments/7i1o2f/rust_regex_engine_on_jvm_via_webassembly_example/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Oh cool! And about the "Provided Methods" header, are you sure it's present even if there are no provided methods?
I pretty much learned Rust this way. Come over, they're friendly and will help you.
C++ got ugly when chasing many tails at once, but really since C++11 and forward it's very much the case that C++ has settled back into it's niche. Even if it has a large market share, it's still a niche.
This has everything one could want : * Typestate state machines (arguably the safest approach, but, as you say, cumbersome without the codegen) * Reachability and Termination analysis is a huge added benefit. We have several event-driven services in a distributed system which have to walk hundreds/thousands of simultaneous requests through various stages of db, queue, pubsub, and http requests. We were previously using a macro_rules! enum based system, but I have been secretly plotting to build a proc-macro approach that wasn't as good as the one you've built. This saves me the hassle. Thanks :)
Sidebar: &gt; No memes. &gt; Leave the image macros at home. Quite the crowd
Thanks for the kind words! I built this after messing up my state machines as they evolved: * I would accidentally break termination, or * not call `poll` on some newly created inner `Future` during a state transition, and therefore not register intent with `tokio`, and then dead locking because the state machine future wouldn't ever get `poll`ed again. By automating all of this away with codegen, I can fix the problem for myself once and for all :)
That would be caused by [an implementation of Drop](https://github.com/sunjay/turtle/blob/master/src/renderer_process.rs#L128) on `RendererProcess`
I like the Python 3 approach of having separate integral and floating point division operators: `/` for floating point, `//` for integral.
Hopefully jvm will be able to load wasm directly one day. 
Thank you! Yes, it is. That's only because I was stupid and didn't put it inside a check or anything like that. It'll be trivial to fix. Actually, one issue I've noticed with rendering is when there's that little [trait helper thingy](https://i.imgur.com/MTfnYgx.png). I'm not sure why it's doing that.
I've never worked with erlang, but I think it's this: you can have to functions `fn process(("foo", x))` and `fn process(("bar, x))` and depending on the first part of the message (here written in rust syntax as a tuple) it's decided which one will be executed. If no matching method is found, an error is thrown.
Using JSON is a bit of a pain in the a** compared to JavaScript (by design). If I'd write something that heavily relies on JSON (like a translator from one format to another), I would rather use node.js.
Yep, you can run both the unit tests and integration tests. If you have time, you can even try run the fuzz test located in src/bin folder.
I did once suggest that rust numbers be able to be widened into strictly larger types, like C#. There were a huge number of objections from people doing low-ish level code where they *really* cared about being able to know the true type of a number by looking at it. It's occasionally inconvenient, but it IS very nice when you get used to it.
Just a quick fix, in Java you also get 3. 
It would be an interesting distinction to make `/` actually not work on integers, though I suppose that's sorta equivalent to the above complaints about OCaml's `/.`...
What specifically, knowing whether a literal is floating point or integral? Why not just make us specify the exact type of a number every time, like 0f32 or 0i32 or 0i16?
/u/steveklabnik1 , I want a picture of your perl tattoo. :-p
https://i.imgur.com/VHLDh.jpg was taken shortly after I got it; it's worked into the rest of the art but that's why I put it there :)
&gt; my PR was somehow rewritten in a different way without any comment that's pretty rude.
Huh, I could've sworn I tested that before posting. I stand corrected. :)
I'm the author of this library, feel free to ask me questions!
Yes! This is correct! (I'm the author.) If you want to read more about this approach, it's talked about in detail in the [last chapter of the Rust book](https://doc.rust-lang.org/book/second-edition/ch20-06-graceful-shutdown-and-cleanup.html). 
This is a ridiculous discussion and you're both being overly combative here. Stop.
I just started learning rust a couple of days ago. My first project is a big one, going to try to write a SuperCollider server in rust. Today I got OSC decoding mostly working. After fleshing that out some more I’m hoping to start working on the audio bits this weekend. 
&gt; but in my opinion it's going to be increasingly difficult to add new features to the language or the standard library without breaking anything or sacrificing ease of use People have been saying that for decades now and IMO, they have always been right and still are. Yet C++ is going to get extended.
If people are interested in other forms of JVM tom foolery see * https://github.com/davidar/lljvm * http://nestedvm.ibex.org/ (MIPs emulator in Java running native code) * https://github.com/SimonKagstrom/cibyl Although I think WASM is the future. 
You can probably avoid all the `expect`/`unwrap` using `?` and returning a `Result` (with an error enum which includes Iron error). Using error-chain and potentially failure crates
I find that ... less than obvious. Rust seems well suited to building compilers and interpreters. Rust itself is written in rust (granted, using LLVM as a back end). What about Rust do you find stands in the way of it being a good choice for writing compilers and interpreters?
just submitted a pr w/ some draft language
I'm a little confused... if this is a local app that's being served by iron, then why does the server need to transfer files over HTTP? If the app isn't local, then why isn't nginx an option?
It was a good talk. Deep dive into regex and optimization. I understood ... a percentage of it. :)
Glad you enjoyed it, thanks for coming. :)
This is really really neat!
I have two questions about iterators: 1) If I have an iterator [a, b, ... z], what's the best way to get an iterator of its Cartesian product; that is, [(a,a), (a,b), ... (a,z), (b, a) ... (z, y), (z,z)]? 2) If I have an iterator [a, b, c] and want to use it to create an enum with data (a.method1(), b.method2(), c.method3()), what's the most elegant way to do so?
*&gt; But if you have a library in Rust, exposing it to the JVM sans-JNI is a doable feat if you must.* I'd be curious to see additional stats for using regex via JNI, to see how much overhead the WASM transformation adds, and then also the stats for just running the Rust benchmarks without the JVM involved at all, to see how much overhead the JNI imposes.
Playing with building a japanese tokenizer in web assembly.
Thanks :)
Thanks man! Fascinating
I'm hoping that wasm represents a backend to many platforms for a lot of languages.
Nice! I've been really wishing for something like this; ZFS is nice, but the licensing issue and out of tree nature make it hard to depend on, btrfs seems perpetually not quite ready, and while dm and md and XFS are all great, the tools to manage them are all different and can be pretty complex to learn and use together effectively.
Not yet, but maybe some day soon! Feel free to open an issue if you get a chance. That's on my list so I'll open one anyway in the next few days. 
&gt; Rust seems well suited to building compilers and interpreters. No, not really. &gt;Rust itself is written in rust There are lots of valid reasons to self-host. I think the Rust team definitely made the right choice there. &gt;I see below that you call out Rust's memory model as an impediment It's specifically the lack of higher-order functions, as closures are more constricted. &gt;at least WRT some advanced language constructs. Is there anything else? Those "advanced" language constructs are very much needed for work on compilers. It's not possible to express recursion schemes in Rust, as an example. The other thing to realize is that compilers tend to be heavy on manipulations of recursive discrete structures (at that point, it's not even *possible* to have an unboxed representation in any mainstream language). And most of those manipulations are pure, so a compiler like GHC can optimize them them heavily, meaning the performance penalty you pay from working in a higher-level language is minimal.
nginx absolutely is an option from a technical perspective. But I didn't want to add a new, major dependency to my project for this one feature. I just discovered Iron/StaticFiles, which looks like it will do the job. If not, the "chunked transfer encoding" option is fine.
I made the beginning of [this PR](https://github.com/iron/staticfile/pull/98) a long time ago for the "static" module of Iron. I think that's what you want, but it's not merged yet. You can also fork the PR and try it yourself. I've tested this feature with small (~500-600MB) files, but I haven't tested for files over 2GB. You can always try and see how it goes!
I don't have an elegant solution for #2 but the first one can be done with `.flat_map()`, if your iterator is repeatable (assuming it comes from a slice here): slice.iter().flat_map(|a| slice.iter().map(|b| (a, b)))
That would be inconvenient! ¯\_(ツ)_/¯
This is awesome! How was your experience with`darling`? I’m really excited to see someone using it.
I understand the HTTP game example, but do you have any others? What inspired you to make this, and have you used it any personal projects? It looks awesome but I'm wondering when it's appropriate to use. Would it work well for programming a network protocol, or is it more suited to higher level applications? I want to find a good problem to use this on and try it out!
Thank you for this article. It really shed some more light on the subject. Adding that to what people already told me on IRC makes the reasoning about owned/borrowed, stack/heap allocated, and control over memory.
Can you give a specific example where the expected and actual values are not enough to debug a failure and this proposed API would help $1 u/tippr
u/tomwhoiscontrary, you've received `0.00071672 BCH ($1 USD)`! *** [^^How to use](https://np.reddit.com/r/tippr/wiki/index) ^^| [^^What is Bitcoin Cash?](https://learnbitcoin.cash/) ^^| [^^Who accepts it?](https://acceptbitcoin.cash) ^^| ^^Powered ^^by ^^[Rocketr](https://rocketr.net) ^^| ^^r/tippr ^(Bitcoin Cash is what Bitcoin should be. Ask about it on r/btc)
Are you planning any new C++ projects?
Do you think that this library could be used in educarion for children to learn programing? 
It's rude for general projects, but super weird for crypto, where you need extra caution, and more discussions.
You might be interested in [ipc-channel](https://crates.io/crates/ipc-channel), though it appears to be SPSC only, uses sockets and doesn't explicitly say it supports Windows. But it might not be a bad starting point, and it's maintained by the Servo team.
I encourage people to count in unary just to be safe: `beta0`, `beta00`, `beta000`, and so on.
Talked about working on it last week, first version published to crates.io now: A flexible Merkle Tree implementation https://crates.io/crates/merkle-rs Looking for any and all feedback (and yes, documentation is just rustdoc for now, better docs will happen over time)
I'm somewhat unclear on what the question is. Implementing features quickly isn't necessarily the goal: the goal is to implement them such that they are useful and interoperate well with the rest of the language, without regressing safety and performance and all the rest. Some features are really small and get merged quickly, and some features take a long time and have to go through multiple iterations before their design and implementation are acceptable. Meanwhile we continue to discourage libraries from using unstable features, but at the same time we acknowledge that we do need some people to make use of these features and give feedback on the design and implementation. If in any doubt, then don't use unstable features, or use any libraries that require unstable features. If that means that Rust is yet unsuitable for your needs, then so be it. Use unstable features only if you're willing to give feedback to the developers and willing to suffer breakage as the design gets tweaked and implementation details change.
Hi /u/boscop, for some reason I can't fathom this post was caught in reddit's spam filter (maybe the tinyurl?). Could you please try submitting it again?
So beta10 becomes betaaaaaaaaaa? I like it.
I'm not good at programming with rust, neither in actor model but now I want to know more about it and go deeper into it ! I understand that it takes a lot of time to maintain a project like this one (actix + actix web) but I think a short series of blog post, scratching the surface of actor model and how to use it with actix (maybe a simple todo list you can edit from multiple clients through websocket) would be really awesome ! Anyway, I want to thank you for what you have already done.
Are you sure? It also says: &gt; A larger set of pre-release fields has a higher precedence than a smaller set, if all of the preceding identifiers are equal. Example: 1.0.0-alpha &lt; 1.0.0-alpha.1 &lt; 1.0.0-alpha.beta &lt; 1.0.0-beta &lt; 1.0.0-beta.2 &lt; 1.0.0-beta.11 &lt; 1.0.0-rc.1 &lt; 1.0.0. In particular **1.0.0-beta.2 &lt; 1.0.0-beta.11**
Author here. I generally avoid using unstable features, but in this case, I just couldn't, and since I'm going to pair this library with Rocket.rs, which uses many unstable features, I don't really mind that much. I think Rust teams approach is just right. Keeping features unstable is mostly about not rushing design decision and let the community and the devs chew on them for a while before we commit to having to live with them "forever". We don't have to look for the perfect combination of everything. Instead, we can just slowly and wisely evolve the language in a backward compatible way to avoid big mistakes, and make everything somewhat coherent. 
The "."s are important. "-beta2" is one alphanumeric "field" (which is sorted lexically). But, "-beta.2" is 2 fields (the second of which is sorted numerically).
You broke the CSS flow, as simple as that. :)
As for benchmark results: Rust uses fundamentally different regex engine than most other languages (rust uses NFA similar to RE2 library, other languages use backtracking). This explains a lot of differences seen. Sidenote: I really love Rust choice regarding regexes algorithm.
Hmm, I see thanks, I thought we were limited to 3 "fields" only. So it works as long as we never mix numeric and alphabetic characters (to avoid confusion) then. 
cute!
The main argument for writing LLVM+Clang in C++ as opposed to a higher-level language was space efficiency, and to a lesser degree speed. C++ programs are big. With template instantiations, ASTs can grow to a truly staggering size. Reducing the memory footprint of the compiler is therefore important. C, C++ and Rust can do that. Higher-level languages cannot. C++ compilers are slow enough as it is, despite a lot of effort going into optimizing them. Writing them in a higher-level language would not help.
I want this integrated in the Playground. It would be an awesome way to play with Rust in a prettier way than text I/O.
https://www.reddit.com/r/cpp/comments/75590f/whos_hiring_c_devs_q4_2017/
This seems like the kind of thing that needs a lint or a warning...
&gt; Writing them in a higher-level language would not help. This is simply false. Higher-level languages with better purity guarantees means more optimizations and offer abstractions that can make fast code dramatically easier to write. Rust can't do fusion, and fusion appears often in compilers. GHC is faster than rustc (on a per-line basis; not sure how meaningful that is), as an example. &gt;Reducing the memory footprint of the compiler is therefore important Not really, unless you're using it on some embedded system. It's not been a problem with GHC or OCaml. 
This looks awesome!
&gt;This, compounded with the nearly 300 language and library features, makes me concerned that the path to stabilization is like the Traveling Salesman Problem, where the goal is to find the best stabilization order of language and library features. Yes, language design choices are nearly infinite. Rust does not have (ergonomic) higher-order functions, dependent types, user-defined linear types, or hygienic macros, among other things. At some point you have to stabilize the language, but these unstable features allow Rust to stay cutting-edge while being productive. &gt;Or would a focus on compiler refactoring rob the community of much-needed momentum Are there actually any places a refactor would be desirable? I'm not sure this isn't just due to the inherent complexity of the task. 
Flights from Italy are like 50€ one-way. Cheaper flights are only to London.
I am discovering Rust through the aoc (/r/adventofcode) and have a question related to lifetimes inside closures. Consider the following snippet taking a standard input to parse it, and hoping to create a Vec&lt;Vec&lt;String&gt;&gt;: &gt; let stdin = io::stdin(); &gt; let input = stdin.lock().lines().map(|line| line.unwrap()); &gt; let input = input.map(|line| line.split_whitespace()); The third line triggers the following error: &gt; `line` does not live long enough After a bit of digging, I essentially understand the problem. As [described here](https://lobste.rs/s/oxuwzf/rust_vs_c_fine_grained_performance#c_0bhl8y), intermediate bindings have more semantics than in traditional languages in that they enforce a longer lifetimes to bound resources. In particular, I understand that precisely for this reason, the two first lines of my snippets could therefore not have been mashed together since we need to make clear to the compiler that the io handler must survive beyond the lock one. However I do not understand how to handle the question when inside of a closure, as in the third line, where an expression is expected. Any help or pointers are welcome. Thanks!
1. I'm impressed at the level of abstraction possible on Rust stable. 2. I would never ever use something like this due to the level of abstraction. When something is wrong you are absolutely fucked trying to understand what is going on. I feel like we are incorporating the worst part of the JS ecosystem. Frameworks upon frameworks to make up for the missing language features.
&gt; hygienic macros huh?? I thought they were always hygienic?
[Here's a cut-down version](https://play.rust-lang.org/?gist=2f12502aab92830c7b6f5684e97e1561&amp;version=stable) of some real code from an application of mine. Does that make things clearer? 
[ipc-channel](https://github.com/servo/ipc-channel) passes temporary (memory backed) file descriptors over unix sockets. Fast enough for Servo :) mmap does not give you send/recv semantics. So you'd have to implement your own signaling. If you're sure you can implement it in a fast, reliable (&amp; hopefully portable) way, and that's worth your time, go ahead :) But this is kinda reinventing the wheel.
It's not that readable, I prefer appending a whole beta, so it's beta.beta.beta.beta.beta.beta.beta.beta.beta.beta
I'm just looking into Diesel and this post will definitely be useful. Thanks!
The issue is that `.split_whitespace()` takes a borrow of `line` which isn't allowed to be returned from that closure. It also produces an iterator, so you need to collect it to an intermediate first: // this can all go on one line, I'm just splitting it to make the steps clearer let input = input.map(|line| // get our SplitWhitespace iterator line.split_whitespace() // convert the `&amp;str`s to `String`s, using the ToOwned trait in the prelude .map(|split| split.to_owned()) // collect all the string segments for this line into a single vec // we need to tell the `.collect()` method what container type // we want, but we don't need to specify the element type as // `String` as that's the only thing it could be .collect::&lt;Vec&lt;_&gt;&gt;() ) // collect the outer iterator yielding `Vec&lt;String&gt;` a vector, //using the same type hint with the redundant information omitted .collect(); 
Thanks for suggesting ipc-channel! It looks like it's exactly what I need. I'll give it a shot!
Small correction. &gt; It's specifically the lack of higher-order functions, as closures are more constricted. The ergonomics of higher order functions between, say, Rust and Haskell, are certainly very different. But it is incorrect to say Rust doesn't have higher order functions. It does.
`macro_rules` macros are *mostly* hygenic, but not entirely.
As a devop, semver is never blindly trusted. When in doubt, pin versions down to the patch.
[removed]
&gt; Are there actually any places a refactor would be desirable? I'm not sure this isn't just due to the inherent complexity of the task. For example, the whole type resolution mechanism is problematic, which also hampers development of features there.
A tokio reactor does not spawn another thread to run your future. A core just sends your future to the event loop where it is processed on the same thread once the operating system signals readiness.
Thanks. I think I'm more wondering is this: simply why there is concurrent development on so many features?
1. this is "rvalue static promotion" https://www.reddit.com/r/rust/comments/7i64sy/safe_function_returns_static_mut/ 2. no idea. I'm not sure what change it is that you make?
Is that because they don't capture crates and modules used when defining them?
I accidentally wrote the change incorrectly, fixed in the post. I think the change simply allows the optimizer to do constant propagation on everything. And while this is rvalue static promotion, I think it should not allow doing this with mutable references?
Yeah, I mean, this does seem like a bug, that is, this looks like two `&amp;mut` to the same place. You should file a bug!
items and crates, IIRC, yes
Thanks a lot for your detailed answer! It is a lot clearer to me. Only one detail: if I understand correctly, to_owned takes a shared reference to an immutable string and returns an owned string by making a copy of the original string. However here I do not intend to reuse the original string, and could therefore theoretically simply transfer the ownership without having to make a copy, right? Would that be possible in this context? Not that it would matter in my present use-case, but just to be sure I understand what is going on.
Nice
It's not simply two `&amp;mut` to the same place, it's a `&amp;mut` to a local variable on the stack! playground::gimme_static_mut: .Lfunc_begin2: push rbp .Lcfi6: .Lcfi7: mov rbp, rsp .Lcfi8: sub rsp, 16 lea rax, [rbp - 4] .Ltmp6: mov dword ptr [rbp - 4], 1234543 mov qword ptr [rbp - 16], rax mov rax, qword ptr [rbp - 16] .Ltmp7: add rsp, 16 pop rbp ret .Ltmp8: .Lfunc_end2: It returns `rax` with the address of the local variable `[rbp - 4]`. This is very very wrong! Further demonstration of mutable aliasing: [playground](https://play.rust-lang.org/?gist=5e19e59e8b64488171b76bfbf0383b06&amp;version=stable). Changing it to remove the mutability makes the compiler reference static data and will be safe. 
I prefer both, just to be sure. `1.0.0.beta.betaa.betaaa.betaaaa.betaaaaa.betaaaaaa.betaaaaaaa` ;)
Best news for me: - Rust in RISC-V - Oxidation: Mercurial in Rust 
&gt; it's a &amp;mut to a local variable on a stackframe that is no longer valid after returning! This is why I brought up rvalue static promotion, this isn't supposed to be on a local stackframe. &gt; I hope it's okay I created an issue It is always okay to create issues!
What magic is this abstracting away that you would consider harder to debug than the hand written version?
So that more than one feature gets developed at once, since you cant have dozens of people working on the same feature.
The thing I miss in Diesel is some magic like Django has where it generates the migrations based on changes to the codebase. I don't know SQL and for smaller projects maybe I don't *want* to know or write SQL. 
Not to be confused with turtl, which is also being written in Rust 😅
There's a lot of people working on Rust. Having 100 people working on the same feature doesn't work.
No, it's not unequivocally a win. "Structured logging" is really a kind of weird middle ground between regular logging that produces human readable output that's helpful in debugging, and actual proper _monitoring metrics_. The latter are used to diagnose the health of a service as a whole and either proactively or reactively _detect_ issues in it. Afterwards -- and often with the assistance of logs -- the problem may be appropriately diagnosed and resolved. This kind of conflation of concepts is evident in quotes like this: &gt; Most people are used to "there is one global logger and I give lines of texts" logging and ask "why all this hassle?". I myself became "a believer" once I was working on a heavy-duty production service written in Go, where all the data was logged to json, collected to elastic search cluster where business analytics and monitoring was performed on it. The "data" here is actually the aforementioned metrics, and these _aren't_ logs. They have different requirements for latency, storage, aggregation, or retention. Their only consumers are data pipelines that perform all the various sorts of queries that only then, after processing into aggregate results, are read by humans: as charts, dashboards, alerts, pages, and so on. I'm guessing that failure to make this distinction stems in large part from the immature or nonexistent infrastructure for monitoring and data pipelining -- not just in Rust, but in open source in general. Given how Rust wants to embed itself into the lower level parts of the stack of internet service, it'd be great to improve in that area. But trying to contort regular logging into serving those more specialized needs is not the direction.
1.0.0-beta.2 IS LESS THAN 1.0.0-beta.11 The example is correct and so is the spec. Not sure what the contradiction is??
I'm going to assume that "coatings" isn't the name of some insecure C++ programmer's creation to address the "threat" Rust represents to his view that C++ is the be-all and end-all of programming.
Your `BoundBox` struct has members such as `xmin` and `xmax`, but it never verifies that `xmin &lt;= xmax`, is this intended? Is any part of `BoundBox` actually used, except for the magic `translation_lambda` function (which doesn't appear to have any relation to `BoundBox`)? What is the point of the `ParserStateContainer`? It hides `ParserState`, but doesn't seem to provide any value over just using a naked `ParserState`, all of its methods could have been defined on `ParserState` directly.
&gt; For example, the whole type resolution mechanism is problematic, which also hampers development of features there. So that is why it is going thru a refactor; [chalk](https://github.com/rust-lang-nursery/chalk). And NLL required several refactorings, MIR and a new borrow checker. So YES, refactoring is a large part of development on rust today. 
Yes. This library (as well as the original logo programming language) was aimed at making programming more accessible for everyone, including children. 
Thank you!
I would love that! It's far down on the roadmap for now, but hopefully that will become the reality by the end of next year!
This is a good point, which hadn't even occurred to me. Just to clarify, you're saying that structured logging is bad when it's used *instead* of monitoring metrics; is that correctly understood? Because it seems to me that structured logging is still useful even when it's only used for human readable logs. I'm also curious if you have any good examples of how to do monitoring metrics? Anything we can learn from? I would also highly encourage you to participate in the discussion on the GitHub issue I linked to; nobody is actually working on a concrete implementation yet (as far as I can tell), so it would be great to get the feedback in there now :)
Cool! How does RustRegex in JVM compared to RustRegex in normal assembly? How much is lost (or gained!) by running this in the JVM?
This might be fine for adding a column, but for almost anything else it can't possibly know how you want to do the migration and will lead to data loss. Normally a schema migration comes hand in hand with a data migration. SQL is one of the easiest things you'll ever learn. 
This is a state machine generator, but not a generator for FSM/FSA, parsing-style state machines. For the individual messages within the protocol, I would recommend a serialization like bincode, or if you want a contractual interface, protobufs. For keeping track of the state of every connection that is executing your protocol and sending/receiving messages. I would definitely recommend this tool. As a a simplified example, consider a connection oriented server, maybe a pub-sub queue server like MQTT or RabbitMq. 1. A new connection is established. We don't know who this user is, so we create an object that represents the `Connected` state. Now the connect state will only let us call one method. `poll_valid_credentials`. That is, what we're stating, by type and by protocol, is upon connection, we can only next receive validated credentials (or an error) 2. When we do receive valid creds, we transition the object to the next state, which is `Authenticated`. Now the Authenticated type has more methods and messages available to it. It could be any one of : `Ping`, `Subscribe` or `Publish`. So we call `authenticated.poll_message()` which returns an enum that can only be one of Ping, Subscribe, or Publish. We can also set up a timeout event, which expects to receive a Ping event, and if it doesn't, it sets the connection into a `Stale` state. 
this will take some time, but I like idea of blog posts and websocket example.
Just go binary. 1.0.0.beta 1.0.0.BETA 1.0.0.BETAbeta 1.0.0.BETABETA 1.0.0.BETAbetabeta 1.0.0.BETAbetaBETA 1.0.0.BETABETAbeta 1.0.0.BETABETABETA
Most cases when you're developing a project adding tables and columns is what you want. Data migration will always be more tricky but can also be modeled using the ORM and not SQL. I might be biased because I worked with django and I enjoyed that it did not make me write any SQL at all in the 5 years I've been using it. 
I probably won't mess with it myself, but I bet Rust regex via JNI would be way faster (hard to speculate how much faster). As for the JNI overhead, the benchmarks wouldn't show much because the setup/teardown stuff is not usually measured so it's mostly the same as no JNI. The slowdown of JNI vs pure Rust prog is the JVM itself and all that brings. The bridge is negligible.
Just mentioned above, but I suspect you lose a lot. I don't know how much, I wasn't really planning on doing outside-of-JVM testing. 
Na, na, na, nananana, hey, Jude!
Note that `BETA &lt; beta`, so this sequence works like 1, 0, 3, 2, 7, 6, 5, 4, … &gt; 11\. … identifiers consisting of only digits are compared numerically and identifiers with letters or hyphens are **compared lexically in ASCII sort order.** 
Aha, so clearly the only _sensible_ way to do this is: ``` 0.0.0.BETA 0.0.0.BETa 0.0.0.BEtA 0.0.0.BeTA 0.0.0.bETA 0.0.0.bETa 0.0.0.bEtA 0.0.0.beTA 0.0.0.beTa 0.0.0.betA 0.0.0.beta ```
Also, alongside the other replies, library features have almost no dependencies on other library features and rarely on language features. So, even with as many as there are, it doesn't hurt to have lots of them.
The abstraction here looks extremely straightforward. What about it makes it hard to understand what is going on? * It converts the enum variants into structs. There have even been RFCs to put this in the language. * It generates an enum for each state transition attribute, containing precisely the variants you write, and implements `From` for it. * It generates a trait with one method for each non-final state for you to implement yourself. Honestly, what *would* satisfy you as an interface for non-blocking IO?
Any time you have a need for two or more functions that are identical except for a small difference or two, you should consider extracting the varying thing to a parameter or parameters. This holds even when the varying thing is *code*, not just a value. You just make the function take one or more other functions as parameters. 
You read my mind! I was thinking this would be good for something like MQTT. I actually need (or want, rather) an Rust-based MQTT server with some possible customizations on the protocol so I'll definitely be giving this a try when the time comes. Thanks for posting it!
&gt; Usually because I realized I needed to make another change outside the commit window before actually committing. Still can't see why closing it, sorry.
Because many of them need a good amount of time to settle the design. Even after going through the RFC process, which is largely theoretical (and not everyone likes contributing), feedback from actual use of a new feature can help make it better or more flexible - or maybe even show that it isn't sound and has to be redesigned. So this isn't something you want to have instantly in stable.
Yeah even when we didn't have closures -- which I advocated against! -- rust still had higher order functions. They're not exactly hard to have. C has them too.
Is the original `enum` -- the one you attach the `#[derive(StateMachineFuture)]` attribute to -- actually instantiated and used for anything at runtime? Or is the whole `enum` declaration basically *just* a DSL for setting up all the other things?
I *ABSOLUTELY LOVE* the idea of and potential for `darling`! Overall, it definitely saved me a lot of time and effort parsing meta items into an AST, and I do plan on using it for any future custom derives I write. But I did hit a fair number of speed bumps in the process of using it with this crate: * I would have really appreciated a complete reference of all the attributes that it supports and what they do. I was often resorting to looking at the tests to try and figure out what was possible or how to do *X*. I tried to provide a reference for `state_machine_future` with the "Attributes" section in the docs, for example. * In the same vein, in general, custom derives require *much more thorough documentation* than normal libraries, because they're creating a custom language that is sort of like Rust but sort of not, and users really need to understand the language in order to speak it fluently. A user can't get away with just using one function and only understanding that function's type signature; they pretty much have to learn the custom derive's language's axioms and the general shape of the generated code. I got some of this from `darling`'s docs, but other bits, particularly details surrounding working with `enum` variants, I was pretty lost. Again, I tried to avoid this scenario for `state_machine_future` users with the "Guide" section that shows both what the user writes and then what gets generated from that. It also helps that `state_machine_future`'s API is a lot smaller than `darling`'s though :-\ * As you saw, I was unable to forward `derive` attributes. AFAICT, they don't even make it into the derive input, unfortunately. * I had some issues around type parameters for things that used `#[derive(FromMetaItem)]`. I parameterize my AST over what phase of compilation I was in, [a la GHC](http://www.aosabook.org/en/ghc.html), and I only need `StateMachine&lt;Parsed&gt;` to implement `FromMetaItem` but the way `darling` is generating code is something like `impl&lt;T&gt; FromMetaItem for StateMachine&lt;T&gt;` so all of my phases need to implement `FromMetaItem` even though its unnecessary. If `darling` emitted `impl&lt;T&gt; FromMetaItem for StateMachine&lt;T&gt; where T: FromMetaItem` then I wouldn't have these issues. I realize this is a fairly niche situation, though. I think that's everything... But yeah, the biggest thing is documentation. What is there is good, but I kept finding places where either it was missing or I couldn't find it. Thanks for making `darling`!
Man, you got a whole herd of beta versions over there.
There is a pretty solid beginning of a broker/client at https://github.com/rumqueue/rumqttd we have some mqtt+tokio work planned for later in Q1 of next year, if you're keen to work on it, it would be good to collaborate. 
MIT license... while you are giving a patent license to facebook (IIRC it is a clause in the CLA that they require for any contribution), they don't give one to the community :/.
That's not what he was asked, though. He was asked about what he thought about using a memory safe programming language, to which he responded that people will always make mistakes in code, and so there isn't any point to using a memory safe language; and additionally got very defensive and stated that no one is building anything with memory safe languages, to which he was then given a few examples of projects that are doing just that, and he becomes more defensive in asking whether there projects are POSIX or not -- completely forgetting the fact that BSD and it's utilities aren't POSIX.
&gt; Or is the whole enum declaration basically just a DSL for setting up all the other things? Pretty much just a DSL, although the generated `start` method hangs off of it, and the polling/state transition trait that users implement gets implemented for it.
BSD core utilities aren't POSIX compliant though.
It'll never be more popular at this than python though 😦. CURSE YOU PYTHON
Guessing you missed this: https://code.facebook.com/posts/300798627056246/relicensing-react-jest-flow-and-immutable-js/
* Docs are definitely something I need to work on. I'll look at your docs and at serde's for more inspiration there. * I've started adding examples which parse input and print the resulting struct. I'll look at adding more of these and extending the docs further to have similar samples. If you have a chance to write up any tips for newcomers based on your experience, please file them as an issue on the repo and I'll use those in the docs. * If the `derive` attribute doesn't make it to `syn::DeriveInput`, how were you able to get it for your struct? * I tried to make that work, borrowing from the serde code, but I ran into a lot of problems dealing with `#[darling(skip)]` on generic fields. Serde seems to do a *lot* of bookkeeping to make that work. If I ever figure it out, I'd love to expose it to other proc-macro authors in `darling::util`. It's really exciting to see a real-world crate using it, especially one as awesome as this.
That still means that facebook can sue you if you use react in a way they don't like.
I appear to be mistaken. Rust has some hygiene, but there are still places (see [here](https://github.com/Geal/nom/blob/master/src/macros.rs#L171)) where the macro system could do a bit more to make things easier for macro authors. 
Nothing except local variable names (and nested macro capture names) is hygienic in `macro_rules` in fact.
Exactly, which is why I do `-beta.10` in our projects. I have my builds based on the number of commits since the last release, so the numbers can get quite high.
&gt; I didn’t even try to compile Rocket to wasm before this step, as it is obvious that Piston requires OS support. So Piston works with Emscripten ([link](https://www.reddit.com/r/rust_gamedev/comments/5lplno/piston_project_that_can_be_compiled_into_both/)) but not the WASM target?
Haha that's okay. Python is great! This library's API is largely based on choices made in the Python version (with a Rust twist). The goal of this library isn't to be bigger than anyone else, it's to teach people programming in Rust. :) Popular or not, this project is a blast to develop! :D
That's some bold 8/10/6 syllable structure you've got there, haiku bot!
&gt; Data migration will always be more tricky but can also be modeled using the ORM and not SQL. This can work when the database is small. When the tables get huge, piping an entire table through the ORM(which run on a different machine than the database!) can be considerably slower compared to SQL commands that do everything inside the database.
Yes. You can see Emscripten as a bunch of glue code to simulate an OS on the browser (though this is a huge simplification), while the WASM target is like targeting a microcontroller that can allocate and call foreign functions.
That's definitely one way of defining systems programming, but there's no single definition everyone agrees on. Historically though, systems programming has definitely included compiler writing, and indeed many classic systems languages were designed to help make it easier to write compilers or port compilers. BCPL is an early, classic example of this, and C is of course very strongly influenced by BCPL. A more universal definition that I personally like is that "systems programming" is building software that provides infrastructure to be used largely by other software rather than directly by end users. The lowest layers of system software typically have more implementation constraints (i.e. less other software to rely on, service levels that must be maintained, etc.) and have to interface more directly with hardware (or virtualized facsimilies of hardware), but there are also higher layers of system software that get to take advantages of some lower-level system software (operating systems, language runtime elements) and don't have to directly talk to hardware, but have special constraints that require the ability to manage low-level details of memory layout or concurrency models and other machine-level details so that consumers of their service (i.e. application software) don't have to deal with those issues as much. Plenty of systems programming tasks can be implemented just fine with a garbage collected language, but as you go down the software stack to the lowest levels of systems programming, it becomes increasingly necessary to be able to define layers that can't rely on the presence of any other software, such as in the implementation of a garbage-collected language runtime itself, or early machine boot code. Many people like to draw the line for what is a "systems programming language" such that such a language must be usable for the whole range of systems programming, from bootloaders to protocol stacks and database engines, and this definition often excludes languages like Go that can't implement their own runtime systems (or at least not with an acceptable level of performance) or can't produce programs that don't assume the presence of a large set (for varying definitions of "large"... C has a runtime too, albeit usually a tiny one if the machine model matches well) of functioning runtime services. But that definition is by no means universal, and I suspect the creators of Go stopped calling it a "systems programming language" more to keep people who prefer a more exclusive definition from complaining to them than because they don't think of it as a systems programming language themselves anymore. Rust definitely has a sweet spot vs. other languages for software that has certain constraints that overlap heavily with low-level systems programming, but applications programming these days can have hard concurrency, memory management, and data layout problems too. Trying to define a bright line dividing the things that are systems programming from those that aren't, or things that Rust is good for vs. things it isn't, is largely counterproductive IMO. TLDR: I wasted a lot of time just now arguing about terminology, and you probably will waste even more if you want to insist that terms like "systems programming" have only one valid definition or that all software can be binned neatly into categories or that there are hard rules about where some languages are applicable and others are not.
Various things like this are possible, though they're not done super often. You would need a type that both owns the original piece of data, and contains some information about how it's supposed to be sliced up. Here's [a toy example on the playground](https://play.rust-lang.org/?gist=efdaf031b6f36b7fe89d908d4f99655d&amp;version=stable). In that example we store the `start` and `end` of the slice we want, and then we construct the slice itself as needed in the `Deref` implementation. That works fine. People are often tempted, however, to try to store the slice directly, as another member of the struct. That's more or less impossible in *safe* Rust, though unfortunately it's hard to tell that from the flurry of compiler errors that result when you try it. The problem is that the field that owns the data the slice is pointing to, would have to be "permanently borrowed" in some sense, and Rust's type system doesn't really have a way to represent this. Even if it did, it would come with onerous restrictions; for example, it wouldn't be safe in general to move the whole struct (including returning it from a function), because you can never move a struct while one of its fields is borrowed. One of the reasons this is frustrating and confusing for a lot of people, is that if we're coming from C/C++, we know it "kind of should be possible." For example, if I have a `String`, I know that the bytes of that string are actually stored on the heap, so moving the owned `String` itself (the pointer-length-capacity triple) wouldn't actually invalidate any `&amp;str` slices that point into its heap allocation. A few details about that: - The safety of doing that is an *implementation detail* of the `String` type. The type could be implemented in such a way that moving it isn't safe. For example, a lot of C++ `std::string` implementations do a fancy optimization where, as long as a string is a little bit shorter than 24 bytes, it'll actually store the characters on the stack in the space it *would've* used for the pointer-capacity-length. If `String` did that, and returned `&amp;str` slices that pointed to that stack space, then moving the `String` would be just as unsafe as the compiler thinks it is now. There's nothing in `String`'s API that guarantees it won't do that in the future. - However, the _documentation_ for `String` (or at least the documentation for `Vec`, which backs it) does guarantee that it'll never do this. There's a crate that takes advantage of that fact, which you can use if you want to get really fancy: https://crates.io/crates/owning_ref. Take a look in particular at the [`StableAddress`](https://kimundi.github.io/owning-ref-rs/owning_ref/trait.StableAddress.html) marker trait it defines.
It's MIT licensed. That's not how that works. If you sign the CLA, that has nothing to do with the MIT license. You can still fork, modify, and do almost whatever with their MIT licensed work and you're _not_ giving them a patent license. If you choose to contribute those changes back to the mainline, then you have to sign the CLA, but you really should cite a source with claims as bold as what you're making about the CLA..
Drats, I was afraid of needing to write my own serialization code. Would you happen to know of any existing API library someone has created that solved this problem similarly that I could look off of? The docs for that go a little over my head unfortuantely.
I don't know exactly how django does it, but I'm sure it doesn't load the data into language objects and then spit it back into the database. The ORM statically analyses the models described and compares them to the previous database schema, and generates the migration SQL for the database. The migration is all SQL and handled by the database - the ORM runtime is not involved. Whilst not perfect I'm sure, the Django ORM has been doing this for a long time and has got pretty good at it. If it's not sure what you want it will prompt you for clarification, and the docs encourage you to manually check the SQL generated yourself. 
You should read the text again, because it's obvious you haven't understood what any of it means. The CLA applies when you want to contribute something *to* the React project. It is *entirely* irrelevant when you just use React for your own project.
&gt; I don't know exactly how django does it, but I'm sure it doesn't load the data into language objects and then spit it back into the database. According to [the official documentation](https://docs.djangoproject.com/en/2.0/topics/migrations/#data-migrations), it does just that: Person = apps.get_model('yourappname', 'Person') for person in Person.objects.all(): person.name = '%s %s' % (person.first_name, person.last_name) person.save()
I hadn't messed with the CSS for those parts. It turned out the issue was with the surround DIV's class; I changed it to "methods" and it's [rendered correctly](https://i.imgur.com/WaCaeLU.png) now. I also cleaned up the sidebar, so that's a bit easier to use now that it's not listing all 60+ `PartialEq` implementations for `Vec&lt;T&gt;`. Aside from the collapsing sections, which is more of a "would be nice" thing, I think I might be finished, unless I've introduced some bugs I missed.
ActiveRecord(Ruby on Rails' ORM component) took a less ambitious approach. It doesn't detect changes in the model, but does have a DSL for writing the migration without SQL.
Perhaps you can explain what an "event loop" in tokio terminology really is, then. I've just spent a few minutes looking at the [source code] and I still can't tell for sure where the jobs go. It relies on thread-safe data structures to store its internal state, which is where I got the idea in the first place that the work occurs in another thread. [source code]: https://tokio-rs.github.io/tokio-core/src/tokio_core/reactor/mod.rs.html#146-445
&gt; Just to clarify, you're saying that structured logging is bad when it's used instead of monitoring metrics; is that correctly understood? It's not that it's strictly bad, but it's a little like trying to hammer nails using a screwdriver. I can imagine it being detrimental to both kinds of output, because when log statements == monitoring events, you are compelled to either elide logging which doesn't have the associated counter bumps thus making the logs less useful for debugging. &gt; I'm also curious if you have any good examples of how to do monitoring metrics? Anything we can learn from? For a good example, take a look at the [Prometheus](https://prometheus.io/) project and the types of metrics [defined by their libraries](https://prometheus.io/docs/concepts/metric_types/). (The page about the entire data model is also interesting for a broader perspective).
Out of curiosity, what was the _Rust_'s RFC process inspired by? It seems to bear little resemblance to IETF RFC documents (which are more like standards already when they are released to broader world). Yet, it hits the spot pretty nicely, and at least at this stage of community growth is still quite effective (though it does seem to manifest some scalability issues already; the recent module system discussion is probably the best example).
Hey, 1. There is a function that is also called Luma. https://docs.rs/image/0.18.0/src/image/color.rs.html#64 2. ImageBuffer implements IndexMut trait, making syntax line struct[index] possible. https://docs.rs/image/0.18.0/src/image/buffer.rs.html#398-406 https://doc.rust-lang.org/nightly/std/ops/trait.IndexMut.html
I'm thinking that those concerns would be alleviated somewhat if it was easier to assay the expected waiting time until a feature is stabilized. Something to discern those which seem perpetually unstable (`fn_traits`) from the up-and-coming relatively soon (most `impl Trait` stuff) and those which are just one or two releases from stabilization (mostly `std` features). The ideal state would be some kind of dashboard or a website in the vein of caniuse.com that'd allow you to pick your set of "reasonable" features given a preferred stable release of your crate in X months in the future. Perhaps this could be done semi-automatically by scraping the GitHub issues and the roadmaps posted to users.rust-lang.org. Could be good starter project for some Rust newcomer ;-)
1. You are right, that syntax is for tuple-structs only. You can't normally do that. I tried it out and [I couldn't for a type I defined, but could for `image::Luma`](https://play.rust-lang.org/?gist=e5d3b58984a242c79fa6f97457774d06&amp;version=stable). That's odd. So I [checked the source](https://docs.rs/image/0.18.0/src/image/color.rs.html#60) (which is a macro that auto-generates the same pattern for a number of different types), and it turns out that there's also a function defined of the same name, which when invoked looks just like a tuple-struct. 2. This works by [implementing the `Index` trait](https://docs.rs/image/0.18.0/image/struct.ImageBuffer.html#impl-Index%3C(u32,%20u32)%3E)
I believe the rule is: all lifetime parameters for a struct have to be used in at least one of the fields. If none of the fields actually need the lifetime parameter, the solution is to use PhantomData: https://doc.rust-lang.org/std/marker/struct.PhantomData.html In your case, you'd import `std::marker::PhantomData`, then your struct would add a field that takes the lifetime as a parameter. This way you are telling the compiler: I need this struct to outlive `'a`, but at runtime `PhantomData` will be optimized out.
Yes, BoundBox can be removed entirely. I was initially planning to do the modification in rust struct rather than raw xml, but eventually gave up since serde-xml is not yet ready for serialization. The `xmin &lt;= xmax` part is also good point. How do define those methods on ParserState, which is an enum?
It sounds like you're concerned about people abusing structured logging. That doesn't make structured logging not a good thing.
I got your example to compile here: https://play.rust-lang.org/?gist=8b164f5de71d44bd5cd7581cec4f0edb&amp;version=stable I'm not sure if that's what you are looking for though
I got into programming when 11 years old thanks to Comenius Logo which used turtle graphics. If this gets more people into Rust, that'd be great!
Yeah I ended up getting around it with phantomdata, makes more sense needing this the more i think about it.
I didn't need PhantomData actually in my changes to your gist
Yeah but you make it into a reference, that's a very different data structure
The reason is mainly your `line` function: by taking `&amp;mut self`, it declares it needs all of `self` as mutable, and that means it could mutate `self.path`, thereby invalidating the iterator. There isn't a single "good" solution to this, but the one I would recommend is to separate out different functionality into different structs: the thing which draws stuff could be one structure, and the one holding a path another. Without more detail I don't know what the best solution is for your use case, but separating things out into logical subsets is the main way I've solved this.
The problem isn't that you can't borrow a vector. I believe the issue is that you're trying to borrow only part of your `PathDrawer` struct, but since each method on `PathDrawer` borrows the whole struct, you get the conflicts that you're seeing. Either way, you can probably solve this by restructuring things a bit. For example, why does the `PathDrawer` *contain* a `Path` inside of itself? Or why does there need to be a separate `PathDrawer` struct at all? It seems like `Path` could just implement drawing directly, or you eventually plan to draw more things than `Path`s, perhaps you'd want to have some sort of `Draw` trait instead of a struct.
You could use indices + copy https://play.rust-lang.org/?gist=9851d6610ff98536eff29d26348cfd20&amp;version=stable but it is probably better to rethink the mutable borrows.
btw, another idea: if you're using serde, it has a `#[serde(deserialize_with="path")]` field annotation. You might be able to do `Vector&lt;ParsedForm&gt;` instead of `Vector&lt;String&gt;` and use that annotation to do the parsing during deserialization without completely dropping down to the low-level msgpack api. Or maybe you could use `#[serde(borrow)] with `Vector&lt;Cow&lt;'a, str&gt;&gt;` (which may at least avoid a per-string allocation, though I imagine `std::mem::size_of(Cow&lt;str&gt;) &gt;= std::mem::size_of(String)` so it wouldn't avoid the 24 bytes of overhead per line I mentioned.
Why wouldn't you be able to define the methods on an enum? How do you think the methods on `Option&lt;T&gt;` and `Result&lt;T, U&gt;` are implemented? :)
Noob here, would `clone()`ing the points for the duration of the fill functions be an option?
Well first off our standard library is a lot smaller, you'll need to pull in things from crates.io a lot to get things working. Second off Rust architecture is generally more rigid than Python architecture. This makes it more reliable and easier to build guarantees around but "monkey patches" as I believe they're called in the Python world are impossible in Rust. Compile time is a concept mostly non-existent in Python whereas in Rust we try and accomplish as much at compile time as we can. Generally speaking Rust will hold the programmer to higher standards than Python but in exchange for that you get much faster and much more reliable software.
Here's a rust playground link demo that uses this bug to corrupt the length of a vec (tested with both nightly and stable in release): https://play.rust-lang.org/?gist=5e19e59e8b64488171b76bfbf0383b06&amp;version=undefined
More info at https://www.reddit.com/r/Citybound/comments/7i2wtc/november_2017_prototype_release/
I believe the best solution is define a `or!`(expends to `or_else`) macro in `std`, and then in documents use `or!` instead. Also introduce `or` with care.
1. Read the book. 1. Rust's philosophy is: "correct later is better than wrong now". If you don't accept that, you will be endlessly frustrated. The compiler *will* kick you ass, but it does it because it wants to help. 1. No, seriously, read the book. Yes, all of it. 1. It helps to understand what's going on at a fundamental level. Borrowing makes *way* more sense if you understand how the stack works. Trait object limitations make *way* more sense if you understand how vtables work. Be prepared to dig deep to get a better understanding. 1. Look, I know you *think* you already know what "module" means, but *read the book anyway*. *So many* problems are caused by people not reading the book because "oh, I already understand this" and decide to take shortcuts. You will cost yourself *so much* pain and frustration and wasted time by cutting corners on this. 6. Read the book.
Python, perhaps? The PIP process is fairly open; much more so than IETF RFCs.
Is it? It's well supported by serde for automatically serializing Rust data structures into JSON and deserializing JSON text into Rust data structures.
The term "RFC" is indeed taken from the IETF, but the process itself was largely inspired by the PEP process in Python, though intentionally a bit more informal (at first, anyway). The document establishing the RFC process itself became an RFC, so we can see the history in the repo itself: https://github.com/rust-lang/rfcs/pull/2 and https://github.com/rust-lang/rfcs/pull/6 (I'm the one who filed the former link, but I don't think I authored the document myself; I believe I just copied it in from a mailing list discussion where we were discussing and tweaking it). That said, the process has evolved substantially since then (the basic RFC template has come to demand more, the addition of the subteams varies the stakeholders, final comment periods are a thing now, etc). There are a few top-level documents at https://github.com/rust-lang/rfcs that lay out more information on how the compiler, lang, and libs teams all interact with the RFC process itself. Amendments to all these documents are done, of course, via RFCs as well, and the discussions can be found in the PR tab and the accepted documents (with links to the discussions for each) can be found in the "text" dir in the previous link.
That's fine as long as you're certain as to what data types and fields are used, and they never change. In my case, the data fields available depend on a type value in that JSON. My code is [available here](https://github.com/anlumo/HDPI_Blinkenwall/blob/master/src/server/connection.rs#L56), and it's about three times as long as it would be in JavaScript, because I have to type check everything manually and return error messages when it's not correct.
lol ok
Serde supports parsing conditional values, so your data structure would just need to represent that certain values are option with `Option`, whether it's a complex object or an individual field.
8. Unless you're a verifiable genius, or genetically related to Niko Matsakis (the former probably implies the latter), you should read the book again once you've finished reading the book.
Number 2 makes sense, thanks. The code you pointed out for 1 is still baffling. What is happening there?
You can try to write some simple rust code and compile it to python extension, then you can rewrite some of your python code in rust, in this case you work with familiar codebase and you can start rewriting with small portions of code
Check this out too: https://rust-lang-nursery.github.io/rust-cookbook/
As someone further along the same path, here's my advice: &gt; What should I know going in? 1. Rust's biggest weakness at the moment is that some parts of the library ecosystem are incomplete or immature. 2. Rust will bring you peace of mind whenever you're concerned about reliability. (A type system is worth a *ton* of automated tests.) 3. The added detail-work involved in manipulating strings means that Rust is *not* ideal for situations where you're unsure what string-related algorithm you're trying to implement and are rapidly experimenting with how different algorithms affect the output. (I prototype string-processing heuristics in Python and then translate them over once I get an idea of what I'm trying to actually do.) 4. Rust produces binaries which start much more quickly than Python scripts and can be much smaller than anything you'll get from a tool like `py2exe`. (See my [rust-cli-boilerplate](https://github.com/ssokolow/rust-cli-boilerplate/) repo for an example.) 5. Rust's offerings for GUI bindings are still quite immature, with the GTK+ bindings being the most developed of the portable offerings. 6. [rust-cpython](https://github.com/dgrunwald/rust-cpython) makes it very comfortable to combine Rust and Python in a project. (I use it to glue Rust to PyQt) [PyO3](https://github.com/PyO3/PyO3) does even better, but currently requires unstable language features. You can either build a Rust module that can be imported from Python and use [setuptools-rust](https://github.com/PyO3/setuptools-rust) to put `setup.py` at the top of the build automation stack or put Cargo at the top of the stack and use `include_str!` to embed your Python code inside the compiled executable alongside an embedded Python runtime. &gt; What are common gotchas in learning a first low-level language (specifically Rust)? I had a bit of prior experience with low-level concepts from various university courses, so I can't accurately say what you'll have problems with. That said, here are two things that took a while to click *despite* my prior experience: 1. There is no "this is a data structure" overhead in languages like C, C++, and Rust. In Python, a `class` containing a single integer variable takes up more space than just that integer variable because the runtime needs to keep track of things at runtime. In Rust, a `struct` containing a single `u32` has the same memory representation as just that `u32` because the compiler "throws out the drawn borders" and just specifically references the positions.(ie. `address_of_struct` and `address_of_struct + 1` instead of `bg_color.r` and `bg_color.g`.) Likewise, a struct containing a single `u32` and a single method takes up no more space than a single `u32` and a loose function which takes that `u32` as input. It's all just syntactic sugar that gets optimized away. This is why it's a good idea to create "newtypes" like `Inches` which are simply ordinary values wrapped in single-element structs. They take no extra space at runtime, but allow you to define rules like "Inches(32) + Millimetres(25) is a compile-time error unless one is manually converted to match the other first". 2. Rust is *really* fast compared to Python and it's got a good optimizer. Unlearn any habits built around making APIs uglier to optimize performance inside hot loops. Your intuition will be wrong and the optimizer can wipe away a surprising amount of abstraction at compile time. &gt; How do I need to change my mindset from a pythonic to a rusty one? 1. What has already been said. 2. Don't be afraid of external dependencies. Unlike with virtualenv+pip, avoiding them doesn't make even trivial programs easier to develop or deploy. 3. Recognize that, under the hood, Python is usually doing one of the "Ugh! Don't do that if you don't need it. It's wasteful!" options Rust offers. (eg. Python essentially uses `Rc&lt;T&gt;` on every variable so you don't have to think about it.) Unless your intent is to use it as a learning exercise, don't be afraid to `clone`, `Box`, or `Rc` to make your program work. You don't want to burn out chasing perfection and wind up with nothing at all. (If it was fast enough for Python, it's probably fast enough for you in many cases... though, admittedly, this is a piece of advice I haven't really followed myself.)
You can see [the macro definition a little above that point](https://docs.rs/image/0.18.0/src/image/color.rs.html#48-70). It get's invoked [down here](https://docs.rs/image/0.18.0/src/image/color.rs.html#208-213). Since the code is essentially the same for the four types, a macro is a convenient way to avoid a lot of redundant code. It's a bit harder to read at first glance however.
/u/tekerson answered already. I was confused because OP said that `beta9 &gt; beta10` while the spec said `beta.2 &lt; beta.11`. I didn't know the last "." was also considered as field delimiter (wrongly though that it was limited to 3 fields).
Also, to be clear, there are very few features actually being concurrently developed. What you see in the unstable book are: - Actual new features being iterated on - New APIs being iterated on - A whole _ton_ of "features" and APIs that are not for external consumption but instead enable special things the compiler and stdlib itself needs to be able to do (e.g. use intrinsics, define how panics work, etc) - A whole ton of features and APIs that existed in Rust before 1.0 which weren't removed because we may eventually revive them. Like slice_patterns and box_syntax. The vast majority of features are in the last two categories. Amongst the first two, the majority is mostly new APIs, which are self-contained and need a lot less work over features.
Got it! Thank you!
https://www.usenix.org/system/files/1311_05-08_mickens.pdf
Seem cargo-release has to support this kind of version bump
I'm afraid not. I haven't had the need to dig into serde yet. Everything I've done has been greenfield, so I've been content with whatever serde saw fit to give me. On the other hand, if I were trying to solve your problem on a short time scale, what I would do is write conversion functions to and from serde_json's loosely typed Value type, and have them function return a `Result&lt;YourType, serde_json::Error&gt;` and a `Result&lt;String, serde_json::Error&gt;`. Then you can just chain your conversions to `serde_json::de::from_str()` and `serde_json::ser::to_string()` fn from_value(value: &amp;serde_json::Value) -&gt; Result&lt;YourType, serde_json::Error&gt;; fn to_value() -&gt; Result&lt;serde_json::Value, serde_json::Error&gt;; And you would use them something like let input = "{}"; let value = input.from_str()?; let obj = YourType::from_value(&amp;value)?; assert_eq!(obj.to_value()?.to_string()?, "{}"); 
It is r/playrust
Yeah. *We know.*
Surely it should be: - 0.0.0.BETA - 0.0.0.BETa - 0.0.0.BEtA - 0.0.0.BEta - 0.0.0.BeTA - 0.0.0.BeTa - 0.0.0.BetA - 0.0.0.Beta - 0.0.0.bETA - 0.0.0.bETa - 0.0.0.bEtA - 0.0.0.bEta - 0.0.0.beta 
Low level hardly matters—all that matters is that not only are you delivered from exceptions for flow control; you are delivered from exceptions for exceptions. Exceptions are now only used for programming errors and called panics instead.
I have honestly no idea what constitutes part of the "standard" library for Python and I'm not sure if that is super well defined to begin with.
Cloning should work, but the extra work of copying all the points would be a waste of memory and cpu time.
We wouldn't go into /r/playrust/ and complain about it not being a subreddit about games built using our programming language. Please, afford us the same courtesy. A "TIL" post like this just wastes our time when it shows up in our RSS feeds.
I'm sorry, I honestly didn't intend to offend this thread, I just found it funny that I was ignorant enough to think that this was meant for the game. Sincere apologies.
https://play.rust-lang.org/?gist=e884ed3ae587c0017f7cf43e149ca9cc&amp;version=stable
Kubernetes is evaluating the Rust process as an evolution to their proposal process. The KEPs. Kuberenets Enhancement Proposals.
I agree with that. If you're going to use your logs to handle metrics, you should still use a proper metrics library to marshal your stats in an orderly fashion. Then the log just becomes a text-based transport. You pay extra for the parsing and indexing, but it can be worth it when you need context to make sense of a situation because you have _everything_ from a single source. Of course it doesn't replace dashboards for continuous monitoring &amp; alerting, I'd still _also_ send my precious metrics to a monitoring-specific solution. It would be nice if there was a [crate](https://crates.io/crates/dipstick) for that. :) Yeah, I'll add Prometheus support soon. 
The Python standard library is perfectly well-defined - [this is the reference implementation](https://github.com/python/cpython/tree/master/Lib), and [it's documented here](https://docs.python.org/3/library/index.html).
cargo-release already handles pre-releases nicely e.g. `--level beta` bumps `-beta.1` to `-beta.2`...oh, and you are the author, right? Do you mean it has to support `-beta1` to `-beta2` kind of thing?
The subreddit has been around 3 years longer than the game, so... yeah.
I have found the Rust RFC process difficult to follow at times. I was looking through the `repr(align)` and build system RFCs, but there are so many branches to the dicussion and it takes a lot of work to figure out what the state of the item is. The unstable book is a good listing of things that are in progress, but it's not clear which things are close to stabilization nor if they depend on each other. (This is basically the same sentiment as https://www.reddit.com/r/rust/comments/7i4mtc/is_stabilizing_nightly_features_boiling_the_ocean/) https://internals.rust-lang.org/t/rust-release-milestone-predictions/4591 is the clearest resource I could find for what is coming soon, but it doesn't cover anything else. Are there any plans for tying together the discussion around more complicated RFCs, or more generally clarifying their state?
Not strictly necessary here, but any time you think "I have an iterator and I want..." you should have a look at the [itertools crate](http://docs.rs/itertools/) - it has a wealth of adapters, and it has a `cartesion_product` too.
oh, checked the post again. `beta.10 &gt; beta.9` works for semver, that's how cargo-release uses beta version. No need to change anything in cargo-release.
Fair enough. I know what it's like to mis-read a situation. It's just that we've been seeing a lot of mis-filed posts lately so it's a bit irritating to see one from someone who recognized the problem, yet broke several of the rules clearly listed in the sidebar *anyway*. Specifically... 1. A TIL with nothing but "fuck" in the post body doesn't exactly follow the spirit of the code of conduct. 2. It's not constructive. (As the expander says, "Throwaway comments are just noise.") 3. It's off-topic.
I am no expert with tokio, but as far as I am aware tokio uses mio to create an event loop. This means basically it loops on a call to epoll (on linux). Whenever epoll returns, the tokio core looks through its list of futures and executes those which now are able to make progress (on the thread where the core lives). The thread safe structures used in the code you mention are only needed afaik to make it possible to submit futures to a core from any thread. 
As everyone is saying, the compiler doesn't know that you don't intend to modify `self.path` in `self.line()`. You should probably refactor (new structs, clone, mem::replace etc ...)
Developer here, happy to answer any questions :)
In fact, read both the books ;). `rustc` is a great compiler once you learn that it's trying to be useful, not cover your life in red ink. It is like pair programming for introverts.
The BSD+Patent license was bad if you were a big company yourself and you had enough money to file for these pointless and most times utterly trivial software patents. If you were a small company that can't afford all the money to amass a patent pool, you actually got a license for the patents. The move from BSD+Patents to MIT was good for the big companies, they have enough patents to defend themselves from facebook suits... every major patent pool has patents inside that every program above 10 thousand lines violates in some way or another. But if you are a small company, the move was bad. Yes, BSD+Patents is not nice either, but from the perspective of small companies, it is better than MIT only. The main issue here is that facebook is in control of software patents concerning react. That's why I've said they can sue you if you use react in a way they don't like: they give people a copyright license but leave the patent question unsettled. Now let's suppose you are a big company and you really want to sue facebook for an infringed patent of yours. If you use react, you will have looming danger that facebook sues you back with their patents over the react technology, even though you did nothing else than just *using* them. And the saddest thing is that facebook is cleared from this danger, even if you contribute to react and own patents on some technology concerning it, thanks to their CLA.
Indeed. But how do you hold an internal state with an enum?
It's on top of futures, then you need tokio to run it all. I dislike futures/tokio a lot anyway so this is just another layer on top of those. &gt; Honestly, what would satisfy you as an interface for non-blocking IO? Right now nothing because the language has no concept for it. In the future mio and whatever gets incorporated in the language. I am against frameworks which this is.
From a Rust perspective, dynamic languages create a sea of mutable references, that live 'just long enough' due to garbage collection. A system language typically can't afford the GC overhead (collection pauses and extra memory sloshing around). So it has to track lifetimes of references. The insistence that there can only be one mutable reference at a time is always going to be hard at first. 
I'm not sure I understand the question. The `enum` *is* the state. You can assign directly to `&amp;mut self` when you implement methods on an enum to modify its value. But I wouldn't implement most of the methods you currently have at all! Why have a method for each enum option when you can just as easily assign the correct option?
it's not clear to me how that would be done. could you write a minimal example? thanks! 
And a gorgeous site as well. Looking forward to some future Turtle Playground where the new magic of wasm can strut its stuff.
There's also MSYS2, which Git for Windows is based on. It basically gives you a full *nix commandline environment on Windows with a ton of packages easily installable and updatable via the "pacman" package manager from Arch.
&gt; The CLA applies when you want to contribute something to the React project. It is entirely irrelevant when you just use React for your own project. I never claimed that. You misunderstood what I wrote.
I wite Python for a living and I have been playing with Rust in my spare time, here are some things which I wish I knew when I started writing Rust: * Python makes the generator/iterator pattern very easy (functions which yield), due to Rust having stricter guarantees around how long data can live, it can be tricky to write generator style code here, you are probably better using Vec/slices/iterator chaining. * Iterator chaining is your replacement for list comprehensions, these are good methods for transforming one sequence into another example](https://play.rust-lang.org/?gist=0c0625d9504975ddb8cb180d7cb571e7&amp;version=stable), [Documentation](https://doc.rust-lang.org/std/iter/trait.Iterator.htm) * Speaking of, rust's documentation is very good, this makes it easier to learn new libraries. The documentation is also a good source of ideas about how to use built in methods on important types like `Result` `Option` `Iterator` etc to write more idiomatic code. * Speaking of more idiomatic code; install and start using [clippy](https://github.com/rust-lang-nursery/rust-clippy). In Python linters are to stop you from writing misleading code, in static languages this is still the case (although misleading code is harder to write) but they will also tell you more idiomatic/efficent/safe ways to do the same things (Option.unwrap_or vs match, dereferencing vs .clone() etc." * The borrow checker will kick your ass a few times but it is not as bad as people make out (Until you get to a point where you are putting references in your structs, then if you are unlucky things can get hairy). Rust wants you to structure your code and control flow differently to Python and the sooner you do this the easier life becomes. * String types in rust are interesting because there are two of them `String` and `&amp;str`, there are better explanations than I could provide [here](https://doc.rust-lang.org/book/first-edition/strings.html) and [here](https://doc.rust-lang.org/book/second-edition/ch08-02-strings.html) but to start with `.as_ref()` and `.to_owned()` are the magic incantations to convert between the two types. * Write some code! Pick a simple project you can do in a few hours that interests you and try it out. Notes: * Custom generators and references in structs are fine in Rust, but they are two things that bit me when I started. * I know `.to_owned()` is inefficient and it is better to have a strong idea of where you want each type but when you are starting out if you just want something to work converting as and when needed will let you get something up and running, later when the distinctions are more settled in your mind you can start using strings correctly.
Thanks for your suggestion :) I'm not using serde though, and I don't really see a use case. Or are you suggesting I should investigate using serde anyways? The way I see it right now is that I get handed a `Vec&lt;String&gt;` from the library anyways, and anything I do will be additional work I need to 'justify'. Actually, I wanted to ask another data structure question, but I'll open a new thread for that :)
What i don't fully understand is: The function holds a mutable reference to the whole object. Why can it not access all parts. &amp;mut self seems rather useless otherwise... 
Another data structure question :) My starting point is a `Vec&lt;String&gt;` that represents lines in a text file. When I get it, it has a clear `Index &lt;-&gt; Line number` relationship (i.e. `Line number = Index + 1`). There will be updates to the files, which I will also get handed as a `Vec&lt;String&gt;`, which I will need to use to update the original data. This seems to lead to a lot of index shifting. As an example, say I have lines 1 to 100 in my `lines: Vec&lt;String&gt;`, and I get an update so I have to insert a new line after line 3. In a `Vec`, that would mean that lines 4 to 100 (i.e. indices 3 to 99) will have to be shifted, so as far as I can see, I have to build a new `Vec`. The same problem occurs for deletion of lines, while just _changing_ lines is easy: `lines[3] = new_line;`. This feels somehow like the wrong approach. I will have a lot of lines (frequently in the range of 7 Million, probably up to double that in the next 2 years to come), and rebuilding the `Vec` everytime a line gets deleted/inserted feels very wasteful. So, the question is, what would be a good datastructure for that? About the usage: * Often, I will need to iterate over subranges of the lines. * I described updating above. I will never need to modify the lines themselves, i.e. the `String`s could be read-only. * Directly following an update I will probably need to use the lines structure or a part of it to update something else. * Not sure if that's relevant, but I plan on "batching" updates. I.e. if an update to lines comes in, and the next one comes in fast, I could collect updates for a certain time and then do a merged update. The "something else" part above is what's important, and if changes happen very fast, I'd delay that anyways. * If performance vs. memory usage is an issue, I'd very much value performance over low memory usage. I do not yet know if things are "fast enough" or so, so having something that "feels right" and could be optimized later is certainly a good thing. Ok, I hope I have described my thoughts well enough, thanks for any pointers!
&gt;if you use react in a way they don't like You can use React in any way you want and they can't sue you for it. The only requirement imposed by the MIT license is that you must give credit. The CLA does not affect your ability to do anything you want with React without getting sued.
I could, but I won't. There's plenty of examples in the standard library source. I've already mentioned `Option` and `Result`, and I'm sure there are more enums in there.
&gt; You can use React in any way you want and they can't sue you for it. They can, as facebook owns patents on technology used by react. &gt; The CLA does not affect your ability to do anything you want with React without getting sued. Yes, but it does affect facebook's ability. The CLA gives facebook a patent license for your patents, but if you use react, you don't get a patent license from facebook. So facebook can use your stuff while you potentially can't use facebook's stuff. Sure, it only applies if you actually contributed stuff to react, but isn't it still unfair that facebook gets a patent license while you don't get any patent license from facebook.
You're not just corrupting the length however, you're completely trashing over your stackframe. Both the Vec's capacity and its pointer to backing store got overwritten by your magic number. I'm actually surprised it doesn't crash when deallocating the Vec.
Maybe noalias bug?
*You* don't have to rebuild the `Vec`, the `Vec` does that automatically when you call `insert`. But you're right, the performance of this will be quite poor if you have millions of lines. The "textbook" data structure to use when quick insertions are needed is the linked list, but regular linked lists are pretty shitty in most practical cases. Lookups are O(i), and they have poor memory locality, which means frequent cache misses. A more suitable data structure would be something like a [B-tree](https://en.wikipedia.org/wiki/B-tree). With this, you can map abstract "line positions" to their `String`s. So if you insert a line between 10 and 11, that line could be inserted at position 10.5. The downside of this approach is that you can no longer get actual line numbers without traversing the whole tree and rebuilding the line numbers from scratch. But with batched updates that might not be a problem. Another data structure you can use is the [Rope](https://en.wikipedia.org/wiki/Rope_(data_structure\)). Unfortunately, I don't really know anything about these, so I can't help you there. 
**B-tree** In computer science, a B-tree is a self-balancing tree data structure that keeps data sorted and allows searches, sequential access, insertions, and deletions in logarithmic time. The B-tree is a generalization of a binary search tree in that a node can have more than two children (Comer 1979, p. 123). Unlike self-balancing binary search trees, the B-tree is optimized for systems that read and write large blocks of data. *** **Rope (data structure)** In computer programming, a rope, or cord, is a data structure composed of smaller strings that is used to efficiently store and manipulate a very long string. For example, a text editing program may use a rope to represent the text being edited, so that operations such as insertion, deletion, and random access can be done efficiently. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
* The borrow checker will sometimes yell at you for using two parts of a structure in one expression. You can work around this by binding one part with let, even though it looks like you shouldn't need to. The upcoming thing that's supposed to fix this is called non-lexical lifetimes. * When you don't need absolute performance and don't feel like fighting with the borrow checker to the bitter end, just clone one of the values causing a borrow check deadlock to get a brand new separate object. It's inefficient and it's giving up, but it can get the job done. * `Vec`s are your new arrays. `HashMap`s are your new dicts. The `Iter` trait and the `collect` method are your new list comprehension, though they're doing a bit weird-looking job at that. * Rust functions can either eat things or just take a look at them. Eating things fun and very simple, but then the thing is eaten and can't be used anymore. Using cloning to get around not being able to reuse the thing here as per the previous entry is even more wrong, but that's not saying you shouldn't ever do it while working out how to do things the right way. * Pretty much everything that's not a primitive number or a very small thing made up of what are basically primitive numbers will either end up eaten or needs to be tagged with the noisy "just taking a look" reference syntax when you start passing it around to functions. Generic types get very reference-happy with their API since they can't assume any of the types are cheaply copyable primitive numbers. * Traits are more mind-bending than they look. Standardized conversion traits like `From` and `FromIterator` can be used to express some neat generic code. Learning how to use the standard library traits idiomatically and when to implement your own functionality as a trait you implement for types is one of those tricky skills to learn with experience. * Strings are weird and complicated. Be a C and a C++ programmer and you'll sorta know why they're like that. Otherwise just accept that they're weird and read up the use cases from a cookbook. * If you come up with a really clever trick to imitate OO class inheritance for your one problem that really could use something like OO class inheritance to solve it, it's probably best to throw it away, grit your teeth and do things the more stupid and more idiomatic way. * Closures written in inline code are soft and fuzzy. Closures going in functions are nasty. Closures coming out of functions are nastier. Iterators are honorary closures in terms of nastiness when you want them to come out of functions. The upcoming thing that's supposed to fix this is called impl trait. * `Box` can be a magic cheat code for the woes with closures and iterators with APIs. It also adds some inherent inefficiency, which is why we don't tell everyone to just use `Box`. Worth trying before you ragequit though. * Error handling is cool at first. Then you get more than one error type and it's annoying again. Probably simplest to just start using `Box&lt;Error&gt;` at this point, inefficiency shouldn't matter that much when you're off the expected execution path anyway. * Speaking of error handling, learn to love `Option` and `Result`. Read the API docs for them, there's neat stuff you can do with their methods. Don't treat the `?` syntax for results as a deep and inherent part of the language, learn what it's syntactic sugar for and think in terms of that.
I disagree. You are right: as soon as you do alerting because of log lines, you are doing it wrong (in most cases). But, metrics lose data. Sometimes you want to investigate a periodic failure. It is easier to index structured logs and find a similar log from a previous occurrence.
Ok, please enlighten me if i'm missing something, but which method of `Option` is mutating its internal state and has a return type `()`?
This is kind of the sad reality of a lot of things that in theory should work. Also the way Rust defines SemVer is that a minor update can alter semantics of existing code because a new binding with identical signature can be selected over an existing one if you use the "method call syntax".
Maybe this [Rust and the case for WebAssembly in 2018](https://mgattozzi.com/rust-wasm): &gt;More concretely as goals for 2018 I think Rust should focus on the following: &gt; ... &gt; 5 Work on webpack integration &gt; 6 Work on NPM integration ?
I'd say many folks here love a good meme (case and point the end of the year last year) but at the same time we know that banning memes generally results in more meaningful conversation.
Did you report a bug/issue for this? This seems like a significant soundness bug in the compiler. If yes, could you please provide a link to the bug report? If no, could you please report it and provide a link to the bug report?
Have a look here: https://users.rust-lang.org/t/twir-call-for-participation, or here: https://www.reddit.com/r/rust/comments/7hw6qt/this_week_in_rust_211/. I also remember https://github.com/LeopoldArkham/Molten asking for support. This crate is somewhat anticipated in the rust world, looks like a good fit.
What does it matter, surely you see the pattern in methods such as `Option::take`? [Here](https://play.rust-lang.org/?gist=8af1c2b796996a17339533e4c0c0631b&amp;version=stable)is the example you requested. No need for a container object, you can just assign to `*self`.
I think this should work: ```rust struct MyStructWithDefaultImpl&lt;'a, T: MyTrait = MyImpl&lt;'a&gt; + 'a&gt; ``` `MyImpl&lt;'a&gt;` generalises `MyImpl` over the lifetime `'a`, but not necessarily `MyTrait`, which would be free to do anything. Adding `+ 'a` also makes `T` live as long as `'a`.
I'm surprised nobody has sent you here yet: https://github.com/rochacbruno/py2rs
Could someone explain what "boiling the ocean" means for someone like me who doesn't understand the expression?
It seems to be a regression: with Rust 1.20, it does not compile. --&gt; a.rs:2:9 | 2 | let ref mut x = 1234543; | ^^^^^^^^^ does not live long enough 3 | x 4 | } | - temporary value only lives until here | = note: borrowed value must be valid for the static lifetime...
Just want to pitch in that the parent comment is still correct. People seem to be confusing the recent removal of the custom patent retaliation clause, and a general patent grant. The custom retaliation clause was removed. But there were _never_ any patent grants. Partly the reason why Apache 2.0 is an excellent license is its patent clauses. They grant the user protection against patent litigation associated with any patents held by contributors to the project. The fact that Facebook actively has patents associated with React and is unvilling to provide patent grants through its licensing is still exceedingly scary.
Thanks for making rust-cli-boilerplate, it's a great starting point for a cli project!
Thanks for clearing that up!
I'd say it's the perfect post for r/rustjerk.
Steveklabnik1 is most likely right, an oversight in the rvalue static promotion which didn't account for `let ref mut` pattern match syntax to create mutable references. For more probing see [my reply](https://www.reddit.com/r/rust/comments/7i64sy/safe_function_returns_static_mut/dqwevcw/)
Steveklabnik1 is most likely right, an oversight in the rvalue static promotion which didn't account for `let ref mut` pattern match syntax to create mutable references. For more probing see [my reply](https://www.reddit.com/r/rust/comments/7i64sy/safe_function_returns_static_mut/dqwevcw/)
This seems like it makes sense, but I still get this 11 | struct MyStructWithDefaultImpl&lt;'a, T: MyTrait + 'a = MyImpl&lt;'a&gt;&gt; { | ^^ unused type parameter Note that `MyTrait = MyImpl&lt;'a&gt; + 'a` is a syntax error, so I had to move it to before the `=` I think the phantomdata solution makes perfect sense here
It is a 'small' oversight in the borrow checker when rvalue static promotion was implemented not accounting for the creation of mutable references through `let ref mut` pattern match syntax. I made an [issue](https://github.com/rust-lang/rust/issues/46557) for it
Aha, seems like I misunderstood the severity of it. I saw comments in this thread saying that it could be used to corrupt a Vec and the stack, so I kinda assumed it was a big problem. Thanks for the link to the issue.
There's discussion on this here: https://internals.rust-lang.org/t/improving-self-referential-structs/4808 I wonder if there are any plans to address this...
Oh no, it's a pretty big deal! You can create dangling references to objects on the stack with this bug. I put 'small' in quotes because it's a seemingly small oversight with such a huge impact :P
It looks like they both work: https://play.rust-lang.org/?gist=c76e8f2d315ab15d74310bac7f1d0513&amp;version=stable https://play.rust-lang.org/?gist=6d3c00d57fe23bcc70492ecd545d1bef&amp;version=stable
Also, as always with OTOH things: it doesn't actually work, you still need to use 'a in the body.
Ah, that's much better indeed. thanks!
OpenGL? And which version do you target if yes?
All talks from conference will be available in the next couple of weeks, things held up by rebranding and technical issues with the video editors :)
talks will be available in the next couple weeks, held up by rebrand and tech issues with video editing.
talks will be available in the next couple weeks, held up by rebrand and tech issues with video editing.
I'm very new to rust and playing around with rocket. I'm not sure how to Implement a Writer for [Data::write_to_Stream](https://docs.rs/rocket/0.3.3/rocket/struct.Data.html#method.stream_to), that writes to a String. Does anybody have an example or can point me to relevant documentation?
Rust isn't very good with the mutability if self right now. Rewrite your code so you set up Path outside PathDrawer, and PathDrawer can receive Path as an argument. PathDrawer could even be a trait, with a draw method that draws the path using whatever drawing strategy you want.
Yes, 3.2, using glium!
Are you using any existing crates to handle the GUI or is that custom code as a part of the game?
Does this solves your problem? https://play.rust-lang.org/?gist=3d5b013885cf137462220a4ea5a2e72d&amp;version=undefined
I've read that before--that's wonderful. :)
That’s imgui-rs integratedwith my custom engine
We've talked about it, but aren't sure how to make it happen, exactly.
&gt;* The borrow checker will sometimes yell at you for using two parts of a structure in one expression even though it looks like there shouldn't be a problem. You can work around this by binding one part with let. The upcoming thing that's supposed to fix this is called non-lexical lifetimes. I don't think NLL is going to fix any of the problems that look like that, at least directly. The times borrowck can't tell your uses are disjoint are when they cross function boundaries. For example, the expression includes a method call that *happens* to use only one field, but from the compiler's perspective it just borrows the whole struct. The one case where this might be improved is closures that capture the struct only to use some of its fields. [This RFC](https://github.com/rust-lang/rfcs/pull/2229) would enable borrowck to treat the closure as capturing only those fields. NLL might help the situation tangentially, because it allows borrows to end earlier and to exist only on some paths of control flow, but many of the problems you describe will remain. &gt;* Strings are weird and complicated. Be a C and a C++ programmer and you'll sorta know why they're like that. Otherwise just accept that they're weird and read up the use cases from a cookbook. Or, learn why they're like that directly! The book has a good explanation, the community is glad to answer questions, and most importantly understanding Rust strings is 100% attainable! There's no need to treat them as unknowable and mysterious. For that matter there's no need to describe `clone`, `Box`, et al as "cheating" or "giving up." Often they " *are* the best solution, including performance-wise. It's good to understand how to use references, and sometimes cloning is a fallback for productivity, but that's selling it short.
In the end, other web frameworks in other languages (Django, Rails, whatever) do the same thing. And really, it just feels incredibly redundant to write the SQL myself. I get that it can have it's advantages and I'm not advocating removing that. It's just...I wish there was something to do it for me, even if it was just for simple cases.
Funny, I'm trying to learn Python as a Rust dev, because to Tensorflow.
This is amazing! A lot of people complain that VBA is slow (it is), but writing .dll in C/C++ is not a viable option for many, especially newer programmers. Rust on the other hand is much more approachable and high-level. I predict a bright future to your library!
Good point. There should probably be a nice, visible link to /r/rustjerk in the sidebar to improve the chances of it being used in this situation.
One key insight around why Python can allow multiple mutable references while Rust can't is that Rust's mutable references (and owning bindings) are in in a sense *more powerful*. When you write via a mutable reference in Rust, you actually overwrite the object, and that can change its memory layout, which would invalidate any other references to its contents. This includes, for example, `Vec` growing and reallocating its backing storage, moving its elements to the new location. In Python, writing to a shared object never changes something's memory layout destructively like that. Lists don't store their elements directly, so if the interpreter has to reallocate one all the actual objects are unaffected. The way to tell Rust that you want to give up the extra power of mutable references, while retaining the ability to mutate shared objects, is the `Cell` wrapper type. It forbids anyone from talking a reference to the contents of it's wrapped value, which means it can be mutated even though shared references. So when you run into a restriction around shared mutation, one way to think about why it's there is to think of the extra operations Rust mutation can do that Python can't, and ask yourself if you actually need them.
It looks like you've just removed the default type parameter here
I did. Hope to be around for more. 
I've changed it to this: ``` #[derive(PartialEq, Debug)] pub enum ParserState { Xmin, Ymin, Xmax, Ymax, NoInterest, } impl ParserState { pub fn new() -&gt; ParserState { ParserState::NoInterest } pub fn no_interest(&amp;self) { self == ParserState::NoInterest; } pub fn is_interesting(&amp;self) -&gt; bool { return !self.no_interest(); } pub fn mutate_by_tag_name(&amp;mut self, tag: &amp;[u8]) { match tag { b"xmin" =&gt; { *self = ParserState::Xmin; } b"ymin" =&gt; { *self = ParserState::Ymin; } b"xmax" =&gt; { *self = ParserState::Xmax; } b"ymax" =&gt; { *self = ParserState::Ymax; } _ =&gt; { *self = ParserState::NoInterest; }, } } } ```
I guess what you want is to have something like this https://github.com/pinkisemils/shm_ipc Really, you just want the backing of a channel be mmaped and shared between processes, right? You might just want to copy the standard library code for MPSC channels and hack it so that you can store it in a memory mapped region.
There's no good options for cross-platform native GUIs at the moment. Functional [wxWidgets](https://wxwidgets.org/) bindings for Rust would help that significantly. ([Prior art](https://github.com/kenz-gelsoft/wxRust), hasn't seen progress since 2015.)
Abstract &gt; In the context of deductive software verification, programs with pointers present a major challenge due to pointer aliasing. In this paper, we introduce pointers to SPARK, a well-defined subset of the Ada language, intended for formal verification of mission-critical software. Our solution is based on static alias analysis inspired by Rust's borrow-checker and affine types, and enforces the Concurrent Read, Exclusive Write principle. This analysis has been implemented in the GNAT Ada compiler and tested against a number of challenging examples including parts of real-life applications. Our tests show that only minor changes in the source code are required to fit the idiomatic Ada code into SPARK extended with pointers, which is a significant improvement upon the previous state of the art. The proposed extension has been approved by the Language Design Committee for SPARK for inclusion in a future version of SPARK, and is being discussed by the Ada Rapporteur Group for inclusion in the next version of Ada. In the report, we give a formal presentation of the analysis rules for a miniature version of SPARK and prove their soundness. We discuss the implementation and the case studies, and compare our solution with Rust. Post by adacore team member to comp.lang.ada about project https://groups.google.com/d/msg/comp.lang.ada/H35QcYiWR1Y/jJNZ0tKqAAAJ &gt; So the main issue that we really address with this work is the issue of non-aliasing. Or rather the issue of problematic interferences, when two names, one of which can be updated, are referring to the same memory location. We're focusing on this issue, because it is the one preventing inclusion of pointers in SPARK, as for formal analysis we rely on the ability to perform modular analysis, where we make assumptions on the absence of problematic interferences. 
&gt; Right now nothing because the language has no concept for it. What makes `Future`-in-the-language any better than `Future`-in-a-library? It's the same amount of complexity either way in this case. Besides, this is hardly a framework. You never can seem to come up with coherent criticism of futures/tokio- it's never more than "this is too complicated" without any alternative. The way to make non-blocking IO easier to use is to put the state machine generation into the language, which is happening. But all that replaces is this library and combinators- the `Future` trait and tokio's adapting it to mio is still necessary in some form.
I was going to say a cross-platform GUI library too, but I was going to suggest looking into making the qt bindings generator easier to use. Not sure if it’s a good beginner project though.
Something I just ran into, there doesn’t seem to be a crate that offers a custom derive to provide reflection over the members of a struct. There are crates which implement such a thing internally for other purposes, by none that obviously expose it that I’m aware of. I would base the api on something like hashmap.
This looks good, I will have a look into it a little deeper later tonight!
Now this seems really interesting, but WASM is a new thing to both of us as well so this will be a double learn. 
There not being a good GUI crate was what pushed us away from writing our own thing anyway. We don’t mind if it isn’t a beginners project, but this kind of thing doesn’t interest us library wise.
Could you expand on this? This sounds extremely interesting but not quite sure exactly what you mean. 
I don’t know how many of these others have touched on. Use the rust-beginners chat room if you get stuck and need immediate help. If you feel like you’re spending a lot of time fixing compile errors, don’t worry, this is normal. If you’re doing it right, your program will just work more quickly after you get it to compile (often the first time) and will better cover edge cases.
There are lots of ideas here: https://www.reddit.com/r/rust/comments/74rbgl/what_new_rust_libraries_would_people_like_to_see/
Basically .iter(), .keys(), .values(), returning the field name and values for the struct, modeled after HashMap. You’d probably want to implement the IntoIterator trait as well. You’d probably want to use &amp;str for the keys and std::any for the values. .iter() would probably have an item type of a tulle and the &amp;str and any. This would require learning how to do a custom derive, which is a pretty common metaprogramming feature of the language. I looked for this a little last night and was surprised that I couldn’t find it. Rust doesn’t have built-in runtime reflection either that I’m aware of.
Another couple ideas
It segfaults if you change from release to debug.
I️ feel like dynamic languages create a sea of objects that live “at least as long as you need them to” is closer. The indeterminate lifetimes in python can be infuriating for someone used to RAII. 
I recently wrote a program that followed this exact model - Unauthenticated -&gt; Authenticated -&gt; Performed Action -&gt; Completed But it was in mypy so I was rolling my own, and didn't get the cool sorta work you've done. This pattern is *my favorite* and I love what you've built.
Sounds good :)
I mean, all you really need for machine readable versions is the ability to specify a git commit SHA if you do care about the **exact** version, or a major version if you don't, isn't it?. Where major version is incremented on API changes.
Thanks! I've been wanting to build a project that I've been waffling between doing in C# and Rust and I've been leaning towards C# because it'd be easier to build a GUI for, but a library like this makes me really want to use Rust now.
Yeah yeah I was lazy. If you change the function the vec moves around on the stack so it's a bit fiddly. Alternative is to pass in the offset from outside, but that meant even more manually disabled inlining. I thought about changing it to look for the expected values before overwriting or comparing the pointers but it was all just way too much effort I'm afraid. 
Unless there are multiple topics discussed in that thread, I don't believe it's the same problem. Both are definitely hard problems to solve in rust which there really isn't a solution too, but that's a 'self referential struct', while this post is about methods partially borrowing self? Self referential structures store data inside themselves which borrow from another structure. The problem here is not that, but rather methods which 'partially borrow self' that can't encode that in the method signature. Both are pretty similar problems from a technical aspect though: they both can't be solved right now in rust besides resorting to unsafe code, and they're both largely stuck on how to represent what we want to say in rust code (to my understanding).
And then read this book :-D http://cglab.ca/~abeinges/blah/too-many-lists/book/
What behavior would you expect for non-homogenous struct values?
&gt; `rustc` is a great compiler once you learn that it's trying to be useful, not cover your life in red ink. It is like pair programming for introverts. I hope this makes quote of the week.
I'm slightly curious if there are ways to get more developers or artists? But perhaps you are not at that point yet.
You can do `Data::data` and then use the `read_to_string()` method on the `Read` impl.
Im glad! When I have extra time, I’m slowly extending my design document and code documentation, which will hopefully get to a point where contributors can help more directly. Let’s see when I reach that point!
&gt; This means basically it loops on a call to epoll But, like, what loops on it? What is checking whether the future is now ready? Your program? The os? 
When the future is executed for the first time (upon submission to the core) it tells the reactor, which events to it is waiting for (e.g. waiting for a socket to be readable again). The reactor core then tells the OS (through epoll) that it is waiting for readiness of the socket. Then when new data arrives at the socket, the OS notifies the reactor (through epoll) which in turn executes the future (which handles the arriving of the new data). In this scenario it is always the underlying OS providing events. However there can be other event sources such as tokio_timer which basically spawns a thread that notifies the event loop (reactor core) after certain time intervals. I encourage you to read the documentation of tokio and futures, where these concepts are being explained better.
So you are asking for a homework solution or what? This looks like a pretty standard API for a BST. https://github.com/Jiyun-Cai/ECS40/blob/master/hw4
However, Rust has the potential to be kinda difficult for programming newbs. How do you expect that to go down?
c++ still has a niche. even if it was just compatibility for successful projects that people still use, that would be a niche.. but there's still things I find more pleasant to do in C++ than in Rust.
I dont think the problem with C++ is 'too many features' - it's incomplete or flawed features, which then have to be stretched in awkward ways to do things. Adding or completing the features actually simplifies use.
Make hdf5 crate working!
Yes, the difference is I have to use the iterators to create a tree
&gt; The CLA gives facebook a patent license for your patents It still does not do any such thing, unless you contribute code that relies on one of your patents, in which case they have access to *only* that patent.
getting an HList ?
Is there any interest in bringing the [Enlightenment Foundation Libraries](https://www.enlightenment.org/about-efl) to Rust? Unfortunately, the Enlightenment project has never enjoyed as much success/popularity as I think they deserve. They don't seem to be very good at outreach (or have the resources for it). One advantage to EFL is that the developers have mobile targets in mind, so it should be attractive to people working on touchscreens attached to various hardware. The EFL is also used in [Tizen](https://en.wikipedia.org/wiki/Tizen).
**Tizen** Tizen () is an operating system based on the Linux kernel and the GNU C Library implementing the Linux API. Tizen works on a wide range of Samsung devices including smartphones, tablets, in-vehicle infotainment (IVI) devices, smart TVs, PCs, smart cameras, wearable computing (such as smartwatches), Blu-ray players, printers and smart home appliances (such as refrigerators, lighting, washing machines, air conditioners, ovens/microwaves and a robotic vacuum cleaner). Tizen is a project within the Linux Foundation and is governed by a Technical Steering Group (TSG). It is controlled by Samsung and also backed by Intel. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
&gt; When a struct is packed to a smaller alignment that is still greater than one, bindgen cannot emit Rust bindings that match the input source. This is just a random thought, but could you hack around this by turning it into a union of a packed struct and something that has the correct alignment?
No, the compiler doesn't have a way to understand that only one of those closures will run. Why not use a `match` statement, though?
No. Rust deliberately stops reasoning about control flow at function boundaries. The compiler cannot see the branches *inside* the `map` and `unwrap_or_else` methods, so it can't reason about them. Even if it could, I doubt it'd be willing to construct two different closures that both move out of the same captured variable.
theoretically, it does though, since map only runs if the result is `Ok`, and vice versa. Why not match? Because pretty soon I'm like 150 spaces indented haha.
If I could teach you one thing, it would be this: struct Thing{ count: u64 } impl Thing{ fn say(&amp;mut self, words: String) { println!("{}", words); self.count += 1; } fn words(&amp;self) -&gt; String { String::from("blah") } } fn main() { let mut thing = Thing{count: 0}; thing.say(thing.words()); } This will fail because `thing.words()` borrows `thing` immutably, and `thing.say` tries to simultaneously borrow it mutably, which isn't allowed. Fix it like this: fn main() { let mut thing = Thing{count: 0}; let words = thing.words(); thing.say(words); } It's silly, but due to how the compiler is currently implemented it can't figure out that actually the `thing.words()` borrow doesn't need to stay alive when calling `thing.say`. In the fairly near future something called Non-Lexical Lifetimes will be implemented and this awkward dance won't be required anymore. But for know, be aware that the natural construction you wish to use may not work, and this is how to get around it. And hopefully before you know it the wart will be removed :-)
&gt; theoretically, it does though, since map only runs if the result is Ok, and vice versa. In this case, yes, but function declarations are opaque to the type checker, meaning Rust has no way of knowing the closure is called at all, let alone that it's called in a way that doesn't alias with some unrelated function. The only real way it could figure something like this out would be by either having crazy annotations on the type signature (which would work, but probably be a huge amount of overhead for very minimal gain), or inlining all the function calls (which, besides the blowup in typechecking time and the difficulty of figuring out what was going on from a human perspective, might not be totally valid in the presence of unsafe, since many unsafe functions rely heavily on the function signature preventing problematic code that might typecheck on its own).
&gt; Generic types get very reference-happy with their API since they can't assume any of the types are cheaply copyable primitive numbers. Nitpick: generics can exactly assume that their types are cheaply copyable. Thus: fn do_thing_with_cheaply_copyable_type&lt;T:Copy&gt;(item: T) { ... }
It is absolutely true that when considering the validity of a program Rust won't look past function boundaries. But, just as an additional note on this answer for curious readers, the optimizing parts of the compiler can definitely look across function boundaries, the most obvious case being inlining. However, even if you forbid inlining the compiler may decide to use knowledge about how functions are called to optimize them. For example in the release mode LLVM IR output from [this play](https://play.rust-lang.org/?version=nightly&amp;mode=release), the compiler sees that foobar is only called once and with a single constant parameter, but we've told it to not inline so instead it will take the constant parameter into the function and optimise as much away as possible, leaving a single addition.
I also just recently ran across this limitation of `expect`. Is there a good reason for `expect` to only take `&amp;str`?
Read the "traversal" link.
My hypothesis is that it's been difficult for new people mostly because of how we have been teaching Rust so far. There aren't a whole lot of comprehensive resources specifically aimed at complete beginners. For example, the Rust book (which is great) is aimed at people who already know at least one programming language. While Rust isn't necessarily easy to learn, it does save you from a lot of the things that another language like C++ wouldn't protect you from. People learn C++ as their first programming language, so it should be possible for people to learn Rust given that it makes a lot of things easier. That's all theory though. In reality what's going to happen is I'm going to try to teach Rust to beginners through this project and keep iterating until we learn how to do it. It won't be straightforward. No one has really done this before to the extent that I'm planning to go. The first two points that I mentioned are why I'm confident that it'll work. 
Whatever your passion is, build that. Then give your feedback on how Rust did/didn't meet your needs in building it. Having a vibrant and passionate userbase is its own gift to the community.
Thank you! I can't wait either!
Rust is in the midst of the 'impl period' There's lots of work that can be done at any level of experience. https://blog.rust-lang.org/2017/09/18/impl-future-for-rust.html pick a team and do a sprint?
Deserialize it as a `BTreeMap&lt;String, YourStruct&gt;`?
You know, I should have thought of that.
Type inference and guessing are pretty different. The former is solving a satisfiability problem; the latter is solving a psychology problem. 
what do u mean by traversal link?
https://github.com/Jiyun-Cai/ECS40/blob/master/hw4.md There is a link to this [article](https://en.wikipedia.org/wiki/Tree_traversal)
Actually I can complete the HW in the link. What confuses me is that how to set up a tree if I know that I'm gonna impl iterator to it? Is there any diffreence between this tree and a common tree without impl the iterators?
That'd be great if it was wrapped into serde's derive types, so anything that implements those traits would be able to have pseudo runtime reflection!
How is are: let x : i16 = 1; let y : f32 = 1; Different in assuming from the types that `1` is to be interpreted as an `i16` or an `f32`? In the case of: let x = 1; Rust decides that x is a `i32` so I don't see how parsing it into a `i16` or `f32` would be that much different.
You are not implementing the Iterator on the tree. pub struct IterPreorder&lt;'a, T: 'a&gt; { unimplemented!(); } What data is lifetime 'a referring to? (Here is a helpful link on iterators.)[http://dbeck.github.io/Learning-Rust-Iterator/] I hope that is enough and good luck! :)
They just released 0.11. What happens now? 
A fart app. 
Any recommendation for resources explaining on how stack and vtable work? 
Well, I learned the first by teaching myself assembly, and the second by monkey patching in-memory COM tables from Visual Basic by abusing Win32 API calls... ...so no, I can't really recommend anything in particular. :P Just keep reading explanations until you find one that clicks for you.
True, the problem there is that now T *must* be a Copy type. I was going for the thing where APIs want references as a "works for both cases" option, and that'll end up looking different than if you'd just written out a monomorphic API for a Copy type. Could've worded it more precisely.
It's kind of frustrating though how sometimes you can't use "elegant code" because of either the borrow checker or because of a lack of labelled returns and the whole `?` operator not returning to the top function any more from within a closure. Obviously code like: let foo = something.iter() .do_something() .map(|x| ... ) .blabalba( ... ) .filter(...) .collect(); Is generally considered to be most elegant but it's often not possible due to the borrow checker or exception handling so you have to resort to a manual loop which basically re-implements map and filter. 
Ultimately just depends on what you're interested in. Whether it's rewriting a Python project to be more energy efficient, contributing to make an existing library / application superior, helping with documentation of an existing project, or releasing a new crate that provides solutions for areas that Rust does not yet cover.
Maybe it's just me, but I kinda fail to see how reimplementing map, filter, collect is all that horrible, *when the reason why you need to do it is funky business with control flow.* 
Text processing is traditionally done with a gap buffer, and that performs well for typical text-editor tasks. If you have a *lot* of search-and-replace or other non-local transformations, there's a structure called a "rope" that may be worth the complexity of implementing it.
Llvm is going to inline such a trivial function and then it Does Not Matter because optimization completely blurs the line between local variables and references to local variables. 
The reason those library functions exist is because they encapsulate common logic. Having to re-implement them sort of defeats that purpose but in rust either the borrow checker or the lack of labelled returns often forces you. It would be considered supremely bad practice to re-implement the logic of filter, fold and map where those functions already exist but sometimes in Rust you just have to to satisfy the borrow checker; you know it's in theory perfectly safe to do that but you can't prove it to the borrow checker since it can't reason about control flow inside of other functions.
I think [rust-cpython](http://dgrunwald.github.io/rust-cpython/doc/cpython/macro.py_class.html#example) is the Python version of Helix.
I agree. It'd would at least be nice if you could overrule the borrow checker with `unsafe` in this situation. 
Well you can overrule the borrow checker with unsafe by transmuting lifetimes. Unsafe blocks don't magically disable the borrow checker I guess because in order to transmute lifetimes you still need to demonstrate you know what you are doing and they don't want people to just reach to unsafe whenever they fight with the borrow checker. In order to use unsafe to disable the borrow checker you have to understand _why_ it's doing that by transmuting lifetimes. In theory though a function signature could contain information about that at most one of those closures gets called and the compiler could also use that to reason but that would make the function signature quite complex.
While in most cases it's possible to transmute the lifetimes away, It's interesting to note that there are certain circumstances where even transmute is unusable. To be able to transmute, the destination type still needs to be well-formed, or the compiler will refuse to accept it at all. `'static` is usually used as the goto means to erase a lifetime, but it doesn't work in all cases, such as `Ref&lt;'a, T&gt;` where T does not have static bound. `'static` cannot replace `'a` here because such a type cannot exist at all, since it represents a contradiction. There was an RFC proposed to address this, but it was postponed pending work on the memory model.
Fast and reliable MQTT 5 server implementation. Then you can build a business around it with your friend :)
I used some ugly `str::split`/`str::trim` stuff for the bits I did in Rust. Kind of considering `nom` for today's task because it seems to be so well suited to it, but I might just write some throwaway Python instead.
I would be really happy if we had a GPU computation library that doesn't require a modern NVIDIA with CUDA support and can use just regular OpenGL shaders or something like that to perform the task. Ideally, it would use the first thing available of [CUDA, Shaders, CPU].
[Code for the entire problem is here](https://github.com/DenialAdams/aoc2017/blob/master/src/main.rs#L318) For something this simple I was happy using split, as /u/K900_ mentioned; the values are easily indexed. Then, you can use a neat if let like so ``` if let Some(&amp;val) = line_elems.get(2) { assert_eq!(val, "-&gt;"); ``` 
I did end up using nom for the day 8 stuff because i happen to have just learned it for a different project, but it's not easy or forgiving. for day 7 i just used split(' ') , get(1..len()-1) and .contains(',') --- FWIW all my solutions so far start with let data = parse( include_str!("../input.txt") ) where parse is a function i wrote, and most of the program just deals with &amp;'static str 
I'm fairly familiar with no and considered using it for these past few problems, but it was easier to just write a simple parser. All my parsers so far have taken the file as a strong, split it into lines, and then parsed each line. Parsing each line has been a sequence of splitting on whitespace and then calling next on the iterator for the known values, calling from_str and matching as needed. The function ends up looking a lot like what nom or the like would create, just done manually.
I fail to see how looping 4 times over the same set just for the sake of writing in a functional language style is more elegant than a single for loop.
Okay, let's take a real example. Let's say we have a generator that produces prime numbers as an iterator and we want the first 10 prime numbers greater than 100 000 in a vector: let primes = prime_generator .skip_while(|p|p&lt;100_000) .take(10) .collect::&lt;Vec&lt;_&gt;&gt;(); Let's say we actually do that in a loop: let mut primes = Vec::with_capacity(10); for p in prime_generator { if p &lt; 100_000 { continue } vec.push(p); if vec.len() == 10 { break } } let primes = primes // this line may be omitted but it makes primes immutable again which you sometimes want I find one to be not only shorter but significantly more elegant than the former; don't you? "Just for the sake of writing in a functional language style" might as well be replaced with "for the sake of writing terser, more elegant, less error-prone code" because that's what 'functional language style' tends to come down to.k
`chomp` is what I use because I can use it without the macros and understand what I'm doing. `combine` is also pretty good. I find `nom` really hard to pick up permanently: If it's been more than a few weeks I completely forget how to tie the pieces together.
There's no shame in asking questions that appear easy in hindsight! :) You may even leave the question body in case it can help someone in the future ;)
I used `nom` for day 7 and day 8, to learn parser combinators. It was overkill for the task, but learned a lot :) (Here is my parser)[https://github.com/gobanos/advent-of-code-2017/blob/master/day7_parser/src/lib.rs], comments are welcome !
Sure, but it doesn’t look to be as ergonomic. I think ideally what would be nice is if you could tag things with #[python] or #[derive(Scriptable)] or have something that could be added to build.rs to generate the python-specific functions automatically. Some kind of integration with swig would be nice too. Basically I don’t want to have to maintain a bunch of boilerplate wrapper functions. Any of those would make it trivial to extend a python library. That would be great for when you need some core speed or strong typing for the core of a library, but won’t get bogged down tracking memory management etc where you don’t need to.
Well, `u32` wouldn't since someone out there is targeting an architecture with a 16-bit address space (forget which one). Dunno about `u16`, but it *might* be a defense against a complete lunatic porting Rust to some obscure embedded CPU with less than 256 bytes of memory.
Have you heard of [frunk](https://github.com/lloydmeta/frunk)? I think you may find the ideas of hlist and the Generic and LabelledGeneric traits interesting. The author has [several detailed and interesting blog posts](https://beachape.com/blog/2017/04/12/boilerplate-free-struct-transforms-in-rust/) about it.
&gt; Rust deliberately stops reasoning about control flow at function boundaries. I always find it useful to know _why_ things are the way they are. It helps me better build a mental model of how Rust is supposed to work. In this case, as you say, this decision is deliberate, and the reason is so that code can be type checked locally. That is, Rust can look at your code, one function at a time, and without looking into the insides of any other function, prove whether your code is correct or not. Otherwise it would need to know all the code in your whole program to be able to prove a tiny part of it correct. And a tiny change inside some function could break code far a way in a program.
Another benefit: it helps humans do the same reasoning that the compiler does. This reduces human/compiler disagreements, which can often be absolutely miserable to try and debug. The smarter the compiler is, the hardest it is to understand what it's thinking when things start to go wrong.
Yes I guess this is why I find Rust code so easy to read :)
Unfortunately, the set of valid paths contains non utf-8 strings. Because path methods take AsRef&lt;Path&gt;, you can pass &amp;str and &amp;String to them. The reason there are so many types is because the rules for what is a valid sequence of bytes is different in different situations. str, CStr, OsStr, and Path all represent a block of bytes, but they enforce different constraints on what those bytes can be. Add to this the 2 different types for owned and borrowed (e.g. String and str) versions and you have the complexity above.
They could be implemented with target_feature.
&gt; Does this match people's experience so far, or did I just miss some tutorial somewhere? Once I realized that PathBuf is to Path what String is to &amp;str it all clicked for me. Regarding error handling and utf8, I find it refreshing to see where conversions may fail and be able to choose how to handle it instead having things fail in unexpected ways when the corner cases do eventually show up at runtime.
The number of different string types involved isn't as much of a problem as is the inconsistency between the operations they allow. So I disagree with the assertion that it just has to be this bad. If they were all full-featured string types it would not be as much of a hassle. Most of the frustration in working with them comes from str/string being the only built-out type, but also the only one that you can't losslessly convert to. I also question how common it is to actually run into files with names that have no representation in the utf-8 character set. This seems rather improbable given how large utf-8 is. In that case it might be better for the library to do conversions under the hood and return any (infrequent) errors with other io errors with result.
Could, but then you've got code that only works on *some* platforms. Generally, platform-specific features have to be opted into explicitly.
Hmm, I'm trying to think how i can be most helpful. Rust is definitely a language that catches corner cases at compile time, which is good for writing resiliant code, but bad for complexity. If you control which paths the program will be used with, you don't need this safety. You could create a lib that uses strings, but honestly you get used to std::path
I used the regex crate for this one and it went really nice. I tried nom first (on an earlier day) but eventually gave up.
Thanks, but as I said, I will not need to modify the lines themselves, that is, no "text processing", just keep the lines with their numbers, and insert/delete/exchange full lines/line ranges.
The "functional" code won't actually loop through the same set multiple times. It just sets up a chain of functions with conditions, in essence: the return value of each map/filter/etc operation is not the result of applying that operation, but a lazy iterator. Iteration only starts happening in the `collect` call.
You could in theory encode this kind of branch logic into the type signature of functions and say that a function that takes two closures will at max only call one of them. If a function is typed like that and obviously for it to be typed like that internally it needs to behave in a certain way then further lifetime analysis can take place at the call site to determine correctness. You could put this in a trait. Let's say `F: CallOneOf&lt;G,H&gt;` says that at max one of those three functions gets called.
My "favorite" problem is that CStr and OsStr are hard to convert between each other (?), but they shouldn't really be different on unix platforms (?)
Hm. Ok. That's a good explanation.
CStr is different because of the trailing '\0'
Parsing line by line is something I've found myself doing a lot in AoC puzzles, so last year I wrote a [macro](https://github.com/jugglerchris/aoc2017/blob/master/src/lib.rs#L13) to generate a regex-based parser which tries regexes until one matches. My [parser for day7](https://github.com/jugglerchris/aoc2017/blob/master/examples/day7.rs#L14) shows how to match multiple regexes: regex_parser!(parse_tinfo: TowerInfo { TOWER = r#"^\s*(\w+) \((\d+)\) -&gt; ([\w, ]*)$"# =&gt; | name: String, weight: usize, childstring: String| TowerInfo { name: name, weight: weight, children: childstring.split(',') .map(|s| s.trim()) .map(String::from) .collect::&lt;Vec&lt;String&gt;&gt;() }, TOP_TOWER = r#"^\s*(\w+) \((\d+)\)$"# =&gt; | name: String, weight: usize| TowerInfo { name: name, weight: weight, children: Vec::new() } }); 
When you work with path, always use `fn foo&lt;P: AsRef&lt;Path&gt;&gt;(path: P) {...}`. It solves most of the problems
Maybe Utf8 and Cstr should have been traits.
This sounds like premature optimization and you are heavily underestimating the productivity differences of Rust vs Elixir/Erlang as well as maturity differences in this space. Rust was not built from the ground up for building servers and servers only. Nothing comes close to what one can achieve using Erlang tech in a short amount of time. Of course if you are proficient in it. &gt; Python/Ruby/Elixir There are pretty big differences between the three. Especially Elixir vs others. 
I have done them all in Rust and managed to get by with split() and trim() and trim_matches() as the input was always well defined. Nom is very cool though. 
I built a small api for scraping a website's various pages that used Rocket, Reqwest, and Select. It was an alright experience. It gets a few hits a second with no CPU impact to my tiny server.
I've slowly accumulated a little [utility library](https://github.com/birkenfeld/advtools) that I include in every solution. It has a few often used crates/traits in a prelude (Itertools!), but the largest part is a set of traits for input handling. It allows constructs like for row in in iter_input::&lt;Vec&lt;String&gt;&gt;() for (a, b) in iter_input::&lt;(u32, u32)&gt;() // type annotation is of course optional if inferrable for (name, weight, children) in iter_input_trim::&lt;(String, i32, Vec&lt;String&gt;)&gt;("(),") (That last one is day 7.) With the latest changes, it can handle most days' input in a single line.
You probably meant to post this at /r/playrust
Wait there’s another sub... omg I’ve been fooled all this time
It would be really nice if you could tag a value as having a certain property (such as being valid UTF8 or being NUL-terminated) without it affecting the actual type (i.e. not just wrapping it). The advantage is that you can then use all the original operations of the base type. The problem is that you need some way to determine if those base type operations preserve the property or not. 
There is definitely a desire to build out the OS strong types with more methods, but nobody has championed that cause yet. With respect to invalid UTF-8 in file paths, yes, it does happen. If you release a cli tool that requires UTF-8 everywhere, then you will pretty quickly get a bug report saying as much. I know because it happened to me. Your transcoding idea is clever, but that will also break several important use cases. For example, if I want to print a file path (e.g. I am writing a find-like tool) then that transcoding step is going to prevent me from printing the path exactly as it was received. You certainly can't transcode back because file paths in many circumstances have no defined encoding.
I wrote [this](https://market.mashape.com/ishanjain28/random-quotes) in Rust. I come from Express.js and Golang background. I used Iron framework. It is different from express and Go. Lots of things which can be easy to do are not easy. For example, Reading Query parameters, Chaining Multiple middlewares etc. I asked around for help and people referred me to two articles on Iron framework which were helpful but not a replacement for documentation. Initially, It was difficult to use Iron because I just didn't understood it well but after 2 projects I have learned to use it well and now it's fun and considerably easy to use. In a unscientific quick and simple benchmark on my machine, A Nodejs server handles 82k req/sec, Go server handles 165k-170k req/sec and Rust(Iron) handles 230k-240k req/sec. So, Unless you have really strict performance requirements don't rule out other languages as they have a great support for building web servers and some of them will be much easier to use than Rust. In my application, I just wanted to provide a api which has larger collection of quotes for all the freecodecamp folks looking for APIs and I didn't had enough cash to throw on a separate ec2 instance, So I decided to do it in rust. My server handles 12k-15k req/day and doesn't takes any significant cpu resources. Go would've worked just fine but I wanted to build an application in Rust. 
After you've read something about stack and heap, I love pythontutor.com as a visualization tool. Write a couple really simple programs (like Fibonacci both recursively and as a loop) and watch the stack and heap grow differently.
If you have any other questions I'm happy to answer them!
what is your comment about and why is it here?
that's a lot of requests. what sort of people use your service?
The situation looks like it'll get a lot more nuanced, while retaining the opt-in, via the [portability lint](https://github.com/rust-lang/rfcs/pull/1868).
Usually I use `trim` and `split`, but for days like day 7 I used `replace` to ease the string a bit: https://gist.github.com/samueltardieu/23ad77ad84079c58ab8dddd876a77739#file-r7-rs-L8-L21
15k req/day is not a lot of requests. It takes about 20-35 MB RAM(under load) and 20MB at idle.
Handwritten documentation. It only has 2 simple endpoints. I had talked about it in quite a few communities and gave out links to my server and mashape page. Most people send a request to my server instead of using mashape to save roughly 500ms on every request.
- GUI - help with [limn](https://github.com/christolliday/limn) - Geospatial - make a Shapefile decoder / encoder. The packages on crates.io are defunct (empty crates). There is [this code](https://github.com/zcarto/zshp/blob/master/src/lib.rs), but it panics a lot / very very alpha - Fonts - make a decoder for PostScript based fonts (TTF and OTF exist, but not PostScript) - Embedded PostScript / PostScript decoder + encoder. Fairly "easy" to do, but it's a lot of serialization / deserialization work, since EPS formats are stack-based. 
I used iterators a lot. My Day 7 parser is pretty bad (lots of copying and stuff) but Day8 for example was zero copy. Code here: https://github.com/belst/Advent-of-Code-2017/blob/master/src/bin/day7.rs
boiling the ocean is basically impossible, he's comparing doing the impossible with stabilizing nightly features
Regex pretty much all the way. I got pretty comfortable writing the patterns doing AoC in python last year, so unless the input is really convoluted it usually doesn't take too long!
Same techniques, but you're manipulating lines, not characters.
Yup same here mine https://play.rust-lang.org/?gist=60d22e172dc4aa542d7f3efc4f914430&amp;version=stable
Have you looked at the internals of EFL? According to [this thread](https://what.thedailywtf.com/topic/15001/enlightened), there's a reason for the lack of success.
https://github.com/rust-unofficial/awesome-rust#web-programming TLDR: Rocket probably has the best website but there are others being actively maintained (at least Iron, Rouille).
Gotham had a last commit 4 days ago. Does not look like it is abandoned.
Oh yeah, I know. I meant among the older=, more stable projects. Gotham is fairly new.
The last I checked Iron seemed fairly barren, but it was a few months back.
Rocket also hasn't had any real updates (or commits) for more than two months.
Yeah I just noticed.
&gt; Latest commit aad97e6 17 days ago 
This commit doesn't contain anything useful, and the commit before this one was back in September. https://github.com/SergioBenitez/Rocket/commit/aad97e6be081f73e68db15f57b68ac3bea68d0be
I parsed the first few using basic iterators like lines and split_whitespace. I used lines + regex for a couple once the input got tricker. Finally on day 9 I used the chars iterator with peekable and hand wrote functions for that (it felt too heavyweight using a proper thing like nom or chomp). Ive found it quite refreshing actually - last year I did it in haskell and used parsec for everything, which was probably overkill but easy to use. Have a gander at http://github.com/jsdw/advent-of-code-2017 if interested :) 
A note on Gotham: there is book, but it is fairly limited and incomplete right now. However, the framework has fantastic API docs, nice design, and very little magic, so you can quickly and easily piece together the correct way to use it by spending half an hour poking around there. I made the mistake of just going to the book, seeing it was incomplete, and then assuming the framework was half-baked and undocumented, but when I came back for a second look, I found this was far from true.
split and split_whitespace when possible, and regex for more complex stuff, so far. [Source.](https://github.com/kazagistar/advent2017/blob/master/src/day7.rs) lazy_static! { static ref MATCHER: Regex = Regex::new(r"(\w+) \((\d+)\)(?: -&gt; (.*))?").unwrap(); } let captures = MATCHER.captures(input).unwrap(); let name = captures.get(1).unwrap().as_str(); let weight = captures.get(2).unwrap().as_str().parse().unwrap(); let children = captures .get(3) .map(|x| x.as_str().split(", ").collect()) .unwrap_or_default(); In newer problems, I have picked up a new, unstable only pattern, from a friend who is doing the problems in Scala, which is to use a slice match for clarity when possible. So for problem 8, where you have to match something like this: b inc 5 if a &gt; 1 You can easily see how it splits out with something like this: match &amp;split[..] { &amp;[target, direction, offset, "if", register, comparator, value] =&gt; {
... offtopic a bit, but I was very amused by [this perl solution](https://www.reddit.com/r/adventofcode/comments/7iksqc/2017_day_9_solutions/dqziwma/) to problem 9 that is in the form of a single "regex".
Well, I was inspired from [this article](http://bholley.net/blog/2017/stylo.html).
&gt; `?` operator not returning to the top function any more from within a closure. In some cases, you can make it work, using the collect implementation for Result (ie, iterator of results can be collected to a result of collection, short circuiting on the first error collected). let foo = something.iter() .map(|x| x.parse()? + 1) .collect()?;
For simple cases, like day 2 (whitespace-separated array of numbers), I throw together a combination of `trim`, `split`/`split_whitespace`, and `parse`. For anything complicated like what you posted, `nom`.
I just published nickel-0.10.1 (https://crates.io/crates/nickel), and am actively working on support for tokio/hyper-0.11.
What happens if an even more lunatic ports Rust to a [1-Bit architecture](https://en.wikipedia.org/wiki/1-bit_architecture)? ;) On a more serious side: There exits CPUs which have a pointer size of 8-bit but still can address more than 256 bytes of memory by using some kind of segmentation. Similar to https://en.wikipedia.org/wiki/Physical_Address_Extension for x86 CPUs.
**1-bit architecture** A 1-bit computer architecture is an instruction set architecture for a processor that has datapath widths and data register widths of 1 bit (1/8 octet) wide. An example of a 1-bit computer built from discrete logic SSI chips were the Wang 700 (1968/1970) and Wang 500 (1970/1971) calculator as well as the Wang 1200 (1971/1972) word processor series of Wang Laboratories. An example of a 1-bit architecture that was actually marketed as a CPU is the Motorola MC14500B Industrial Control Unit (ICU), introduced in 1977 and manufactured at least up into the mid 1990s. One of the computers known to be based on this CPU was the WDR 1-bit computer. *** **Physical Address Extension** In computing, Physical Address Extension (PAE), sometimes referred to as Page Address Extension, is a memory management feature for the x86 architecture. PAE was first introduced by Intel in the Pentium Pro, and later by AMD in the Athlon processor. It defines a page table hierarchy of three levels (instead of two), with table entries of 64 bits each instead of 32, allowing these CPUs to directly access a physical address space larger than 4 gigabytes (232 bytes). The page table structure used by x86-64 CPUs when operating in long mode further extends the page table hierarchy to four levels, extending the virtual address space, and uses additional physical address bits at all levels of the page table, extending the physical address space. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
Sergio said on IRC that he is currently traveling a lot, that's why Rocket seems to be so inactive. It is still maintained though
I'm currently in the process of this. Quxxy makes valid points. You'll be able to read other's code at about chapter 11, when you start understanding general concepts and the associated syntax of the language. For a slight bit more guidance on how certain features are used or what are common patterns, or even examples, try looking it up in [Rust By Example](https://rustbyexample.com). Additionally, I suggest you turn to the documentation as often as possible, when researching something. If you're using *rustup*, **rustup doc** will give you a local (offline) copy of the documentation. **rustup doc --std** and **rustup doc --book** will take you to the documentation index for the standard library and the books respectively. I suggest you also look at as much documentation as you can. 
Thanks for mentioning pest. For today's puzzle I was struggling with both combine and nom to get even the subparsers going but pest was nice and easy (though I'm still somewhat confused about the data structures it returns).
I love to know those kinds of things. BTW, http://nickel.rs/ is not licensed anymore? 
He seems to be saying this because you commented on being able to run multiple servers on one box, but that is a premature optimization. Unless you know what is going to be the bottleneck for your server, it might not be the language and its runtime at all, but rather some sort of io for instance.
I haven't used Iron, but I cant imagine the experience getting much better than Rocket from the projects I've made. Rocket automatically matches all the url patterns and can help with conversions to and from json making your code incredibly focused on just writing for the problem. Also, writing unit tests for Rocket is wonderful due to the mock server you can interact with. Testing might have been my favorite part. Again, I make no claim about Iron as I haven't used it.
I am working on async [actix web framework](https://github.com/actix/actix-web). It is close to next major release
I have a question about writing messages for `expect()`. For example, I want to replace `unwrap()` in the following line with `expect()` my_string.parse::&lt;i32&gt;().unwrap(); `expect()` takes a message argument to include with panic message if the `Result` is an `Err`. I am not sure how to write the message. Since it will be included in the panic message, my first thought is to state what went wrong, e.g. my_string.parse::&lt;i32&gt;().expect("unable to parse i32 from string"); However, it now looks like I'm saying that I expect the code to *not* be able to parse the string and I am tempted to re-write as my_string.parse::&lt;i32&gt;().expect("parse i32 from string"); I feel like I have seen both styles but I am not sure.
I used Rocket for a quick-and-dirty backend for a hackathon demo. The good: - Deployment was done by compiling locally, then `scp`-ing the binary over to a server and starting it. Couldn't be more trivial, made it easy to update constantly. - Despite being really quick hacky code (no database, data held in memory and written to a flat file on each update) the server was fast and I had strong robustness guarantees (which meant I had more time to spend on the front end). It also did a lot of the parsing/boilerplate I would have had to do myself for me. The bad: - Nightly-only (at the time and probably still the case now). I don't really have anything bad to say about it, it's no worse than sinatra/flask on any front, and better at a few things. Only slightly more code to write than what they would require. For a big project I'll probably look at Gotham, because there's less magic/opinionatedness.
Could you link the code in which you use chomp? I've been trying to figure out how to use the combinators within parse! macros, but without success.
Right, ok, I'll look into it, thanks :)
I just published a release candidate for oxide-auth (https://crates.io/crates/oxide-auth), a server side OAuth2 library. Current integration exists for iron only but the api should be open enough to enable other libraries as well.
I just rolled my own, using `str::split` and nothing else: let mut nodes = HashSet::new(); let mut children = HashSet::new(); let mut children_of = HashMap::new(); let mut weight_of = HashMap::new(); for line in lines.lines() { let mut fields = line.split_whitespace(); let node = fields.next().unwrap(); nodes.insert(node); let weight = fields.next().unwrap(); let weight: u64 = weight[1..weight.len() - 1].parse().unwrap(); weight_of.insert(node, weight); if fields.next().is_some() { let children_str = line.split(" -&gt; ").nth(1).unwrap(); let children_vec: Vec&lt;&amp;str&gt; = children_str.split(", ").collect(); children.extend(children_vec.iter()); children_of.insert(node, children_vec); } } 
In simple cases like this Rust follows traditions. In C, `int` is defaulted to be `i32`. This is not type inference, but a guess. For type inference, your two examples are no different: Rust finds the only result that could satisfy the rule that the type on both ends of an assignment must match. 
This sounds like it would be possible to do with traits when impl trait lands.
Yes, there was an issue with the registrar that we could never get sorted out. We are using http://nickel-org.github.io/ today.
&gt; It would be really nice if you could tag a value as having a certain property (such as being valid UTF8 or being NUL-terminated) without it affecting the actual type (i.e. not just wrapping it). This [used to be called typestate](https://stackoverflow.com/questions/3210025/what-is-typestate). &gt; The problem is that you need some way to determine if those base type operations preserve the property or not. And you nailed the issue on its head: this is not composable, introducing any new predicate requires revisiting all pre-existing functions to annotate them correctly, and most are in 3rd party dependencies you have no control over. :(
I tried out a few things a little while back: https://wiki.alopex.li/AnOpinionatedGuideToRustWebServers Since then I've discovered a few things that might be nice, such as [jsonrpc](https://github.com/paritytech/jsonrpc) and [actix](https://github.com/actix/actix-web)
If you had one closure it would be easier to just branch inside it rather than a special wrapper around it IMO.
I tend to agree with you, but its interesting that these code samples do different things if `prime_generator` doesn't generate primes in an ascending order. The equivalent would be `filter`, not `skip_while`.
Honest question...How worried are you about it? I generally don't consider 4 months between meaningful commits "abandoned" for more mature projects, and Sergio has made it clear that he's focused more on presenting Rocket than developing it in the last little while -- so this is an acknowledged hiatus, as it were.
I am not worried. Async and http2 are probably the most significant planned features for Rocket. Adding async doesn't necessarily make sense yet as there is a lot of work being done on Tokio and Hyper. Hyper will also get http2 support at some point, and Rocket should benefit passively from that. Doing nothing with Rocket right now might, therefore, be the most productive thing to do.
Better than client side?
Yet the former compiles and the latter does not which is my criticism. You need to do `1.0` in the latter case because it refuses to interpret `1` as an `f32` but is fine interpreting it as an `i16`
&gt; Why not match? Because pretty soon I'm like 150 spaces indented haha. FWIW if the indentation bothers you so much you can use C-style or `if let` and it's no worse than what you have now: match res { Some(_) =&gt; { let length = gimme_that(s); println!("expensive number = {}", length); }, None =&gt; { let _ = gimme_that(s); println!("Does it look like I care? I assigned you to _!"); }} or if let Some(_) = res { let length = gimme_that(s); println!("expensive number = {}", length); } else { let _ = gimme_that(s); println!("Does it look like I care? I assigned you to _!"); }
Here: https://gist.github.com/christophebiocca/142d009fd7ffb9601107881ad4ef7cf4 I'm currently using nightly but it should work on stable as well.
I've said it before, but it bears repeating: Hyper server is very usable on its own. With `futures-await` and a path routing component (like [`Shio`](https://github.com/mehcode/shio-rs) or my own [`reset-router`](https://github.com/kardeiz/reset-router) or just roll your own), Hyper 0.11.x is a joy to use.
&gt; I also question how common it is to actually run into files with names that have no representation in the utf-8 character set. * NTFS path names are UCS2 code units, since they allow unpaired surrogates they can not necessarily be transcoded to UTF-8 (that's a major if not the primary use case of [WTF-8](https://en.wikipedia.org/wiki/Wtf8)) * on most unices, paths are semi-arbitrary bags of bytes, they can be invalid data altogether or UTF8-incompatible encodings (e.g. ISO-8859-7), if the system does not know which encoding that is, it can't do any conversion
I especially like the second half of the talk. Rust has immutability, but... so does Idris. GHC takes pride in error messages. Rust checks the validity of all references at compile-time, ATS can do that too. Seeing what Rust does differently was immensely informative. 
I wrote [this](https://github.com/anlumo/HDPI_Blinkenwall/) in Rust, which is partially a web service. What I'm doing there is that the page itself is static HTML/CSS/JavaScript, and all communication with the server happens through a web socket. I'm using the [ws crate](https://crates.io/crates/ws) on a dedicated thread on the server, which transforms the requests to [std::sync::mpsc](https://doc.rust-lang.org/std/sync/mpsc/) to communicate with the main thread that handles the (stateless and nonblocking) requests. That all happens in the server module, the rest of the code is the actual business logic.
Btw setuptools-rust can pack rust executables starting from 0.8 version 
The only real issue I've run into so far is the lack of a builtin GC (if your higher level language has a GC and you need to evaluate expressions at compile time, as you do with dependently typed languages). Efficient compilers written in functional languages (at least, the ones I've worked on) generally don't abuse tricky functional features too much for performance reasons; Coq, for example, is written to minimize allocations and uses lots of in-place mutations to increase sharing. Rust is a lot more verbose, though, because of the explicit boxing / unboxing and lack of global type inference.
How exactly does that work? Is it just a way to glue Python dependency installation onto whatever "embed Python in a Rust executable" solution I've already put together?
Here is example https://github.com/fafhrd91/fectl/blob/b37b6d86a2037cd52be3da6e2dc9fd535a996bf3/setup.py#L86 This project does not use python bindings, but it still makes sense if you want to use rust binaries in python environment. You can use setuptools as a distribution tool
Coming from Python/Flask - testing in Rocket captured my attention. Do you have any links to articles (books?) that show how to test with authentication, db, configs, redirects, etc... Documentation for testing in Rocket is good, but I wish it had more examples.
Both my website and a small microservice I wrote in Rust for work have been relatively painless (minus some Futures code with Async Hyper). I found Iron to be a pain to use personally, but I know that's not what you want to use. I used rocket which made it super easy to work with. As for the microservice it's based off a small framework I have open sourced that is just a thin wrapper around Hyper that I've found to work real well. Ymmv but I think rust is in some good enough place for these kinds of things right now if you don't mind doing a little extra code yourself.
well, Iron is faster
the bottleneck = the amount of RAM available. that's it.
I'm experiencing this error when trying to use bindgen. `thread 'main' panicked at 'Unable to find libclang: "the `libclang` shared library could not be opened: C:\\Program Files (x86)\\LLVM\\bin\\libclang.dll"', src\libcore\result.rs:906:4` I have no idea what is going wrong because that path is the correct path to the libclang.dll. I am using version 5.0.0 if that matters.
I'm honestly just waiting for a framework to tackle the task like Django or Rails: being a complete framework which handles *everything* with first-class support for ORMs and whatever. Right now developing with some of the tools still feels rather cumbersome
I use `nom` for tasks like this. Much better than string splitting or regular expressions in this context. 
&gt;I use `nom` for tasks like this. Much better than string splitting or regular expressions in this context. Given how frequently people misuse regular expressions or string splitting, I'd say that was time well spent! Parsers are immensely useful despite how often we try to avoid writing them. 
I see. I wonder if this can be fixed while preserving the protection Rust offers in more complex formulae.
Rocket is your best bet when looking for web frameworks. Diesel has come a long way and can actually be really useful in most circumstances now. But the overall integration of the two and some related things can still cause quite a few issues. I'd build production web apps that are relatively simple with this stack. If you have a fairly complex CRUD application the Rust ecosystem is still a little bit unwieldy imo.
I'm building a simple web service. Rocket is nice, though there's plenty of room for improvement. I use diesel to query Postgresql. It's a bit painful particularly because I am not convinced to concept of ORMs ... . I was annoyed with template handling, so I started working on my own templating library `stpl`. Not benchmarks yet - I don't expect much traffic, so I don't care.
It looks like you installed the 32-bit version of Clang: it ended up in `Program Files (x86)`. You almost certainly want the 64-bit version, which should install to `C:\Program Files\`.
Note that python 3 cheats a bit there: they encode utf8-invalid bytes to some special string, which gets translated on every file operation...
The latter will have a more confusing panic message: parse i32 from string: ParseIntError { kind: IntErrorKind::_ } Without context, `.expect("message")` does read like you're expecting the error which is an unfortunate consequence of its naming, but wording it so that your code reads better would be much more confusing to the user, which I think is the greater disservice.
If you don't need anything frameworky, you can use hyper directly [pretty easily](https://github.com/ketralnis/secrets/blob/master/src/server/listener.rs#L60)
I like rouille. Simple, well engineered and doesn't force you to pull the entire kitchen sink in that comes with tokio/hyper.
&gt; Nightly-only why is that bad? not stable and is subject to change? is that it?
I might use rocket. I just don't like it being slower than iron.
Isn't there still a lisp machine with a 40 bit pointer size running in some museum?
A few years ago I saw a mixed 8 bit byte / 14 bit byte control computer running for a particle accelerator at Los Alamos National Lab. The 14 bit part is the original control computer dating from the late 50s/early 60s. The 8 bit part is a modern system that has been bolted on top. 
[removed]
I think you're looking for [this subreddit](https://www.reddit.com/r/playrust/).
Rust doesn't promise to run on all hardware. But 16-bit usize Rust targets already exist.
Cool. Any plans for OpenID Connect support? 
You're looking for /r/playrust :)
You're looking for /r/playrust buddy, this subreddit is for the programming language ;)
Yes, eventually. OpenID Connect is an **extremely large** extension to the Authorization Code Flow and goes far beyond what I can handle on my own at the moment. It would be very, very awesome to support it :) Plan of action would be to first figure out a nice way for basic extensions, such as the in my view more important, security relevant PKCE, and then build the open discovery etc. on top. You could help me speed this up, and not only with pull requests or code. Roadmaps, short write-up or incremental feature requests would also propel this development.
I’ve been poking away at a Rocket+diesel app for a few months now, intentionally shying away from doing API-only with a SPA in front; I’m doing the full stack there, and it’s been pretty nice. I do Rails all day for the day job and Rocket’s concepts have been quite refreshing. ...not to mention seeing regular sub-10ms HTML responses from the server kinda makes me giddy. Not a whole lot of solid number-y data here (on mobile), but just wanted to chime in and say that my developer-happiness using Rocket is pretty high (other than writing tests for it), don’t care about nightly-only, am hopeful for its future, and think it’s pretty damn resource-capable.
Btw, there are at least 2 existing osc crates. Why not use rosc? 
&gt; For bonus marks, because Rust is stricter about types than C, we don’t have issues like: int c_time = time(); Until the next "ergonomics" initiative comes along that auto-casts ints to each other...
I'm using Rocket + Diesel + SQLite in my side-project (https://github.com/flosse/openfairdb). Sometimes it takes some time to solve problems that would be super easy in other languages/frameworks but once you solve it it's super robust :) Compared to e.g. Node.js where updating libraries is a big pain maintenance with rust + cargo is super awesome :)
&gt;First, the exact same way I expected this to be followed by 'then' or 'next' but turns out 'first' was 'it'. Feels like a major part of the post is missing...
Let's remain *constructive*, shall we? That being said, I'm all for auto-casting. Really. The problem of not having auto-casting is that developers get used to resorting to `as`. When you train your users to ignore pointless warnings, you actually train them to ignore all warnings, and all you get is *less* correctness/security in the end. As a result, I'm all for auto-casting, *towards larger types*. It seems the best of both worlds, really: - it eliminates a significant chunk of `as` use, making the remaining ones more conspicuous, - it's also "danger-free", since a `u32` can always represent the value of `i8`, `u8`, `i16` and `u16`. The real complication is what to do with `isize` and `usize`. There is a portability issue in allowing auto-cast from `i32` to `usize`: this isn't guaranteed to work well in non-64 bits platforms. At the same time, since `usize` is used for indices auto-casting to `usize` would be a significant improvement. Trade-offs, trade-offs...
I'm surprised to see a code base being so heavily reliant on second-precision time calls, to be honest. In my experience, I've only encountered one of two cases: - accurate timestamps are necessary, micro-seconds or even nano-seconds, making any attempt to "cache" the timestamp impractical, - timestamps are used for computations, in which case they need remain *stable* across the computation, which means they are taken at the start and passed along as a parameter. I'm curious: what are the usecases making this scheme necessary in the first place?
Your repeated snide comments regarding the ergonomics initiative are both rude and unconstructive. Please stop.
Minor nit pick: `u32` can only represent half the `i8` and `i16` values. =)
well, rails is quite heavy, hence performance is indeed not good, compared to Rocket. however, if you take, say, Roda, would they be significantly different? 
when is it ok to use sqlite, for what kind of websites?
Crap, I meant `i32` :p Thanks for the comment.
I'm just pointing out the looming danger that it poses. Javascript, C++, are both "ergonomic" and do so many things for you but codebases written in those languages are also very hard to read and semantics are often very surprising to newcomers. How "learnable" is that? Go is very "learnable" while not very ergonomic (error handling is verbose, no generics). C++ is very ergonomic, while very hard to learn. By the very trade off between ergonomics and learnability any "ergonomics AND learnability" initative can't fulfill both of its goals. Rust is already *very* ergonomic compared to C. I think Rust has done enough progress on the ergonomics side! I agree with so many things that Rust is doing, to a really large extent. So let me at least voice my disagreements in the few areas where I think the walking direction is utterly wrong. 
I was also looking for page 2 or something. I was looking forward to seeing the Rust-onian way of doing this.
I was also looking for page 2 or something. I was looking forward to seeing the Rust-onian way of doing this compared to C.
One of the issues of auto-casting is that it hinders something I'd call "type bubbling". Let's say one starts writing function `spawn_server(host: &amp;str, port: i32)`. Then he finds out `port` should be `u16`, so he changes the type. Now the caller needs to change type etc. until it reaches point where the value originates. This is good, because the program is checked to be correct. So what impact casting to larger types has? Well, for example: fn set_time(&amp;mut self, timestamp: u32) { self.inner.set_time(timestamp); } It compiles, but `self.inner.set_time` takes `u64`, so now we have Y2038 problem. Also, any user of the API who uses `u64` internally would have to cast to `u32`. Callbacks have a similar problem.
&gt; I have a main loop which is time sensitive, so I'm trying to offload the get/post requests to another thread using Futures. Is the rest of your code in futures or are http requests the only thing? The point of async is that requests don't block. So unless you are extremely time sensitive (as in not even having the time to process http) sending it off to a different thread kind of defeats the purpose..
&gt; That being said, I'm all for auto-casting. Really. And I am all for not doing any kind of auto-casting between integer types. Already auto-casting for comparisons was very hard at the border for me. The ergonomics initiative serves as promoter for bad proposals like this one and I really dislike that. &gt; When you train your users to ignore pointless warnings, you actually train them to ignore all warnings, and all you get is less correctness/security in the end. This is a rehash of a very old and general argument against any kinds of security verification or checks. In general the argument definitely has a point but I think it can't be applied here, as you should already do as few casts as possible. The point is that `as` casting creates *pressure* to refactor your code to do less conversions between types and thus avoid any conversion issues. This improves consistency of integer types across your program and makes you think about the problem of integer types more. E.g. think of a case where you are adding three u16 values to one i32 value which should be a u16 value because of the problem at hand, but you didn't refactor or something, so you ended up with a i32. With current Rust, you'll most likely cast the i32 to an u16, or alternatively, refactor your code to be right. With "auto upcasting" Rust, you probably wouldn't notice this the first place and leave the code in the current, bad, state. Often integer types have semantic meaning. If you are storing something as `usize` you know it will most likely be an array index. In fact, I think it is already very bad that due to being a type alias, `c_uint` doesn't need a cast to `u32`. This makes your code less portable. Also, any kind of casting makes type inferrence weaker, and the local type inferrence that Rust has is I think one of its ergonomic advantages. &gt; There is a portability issue in allowing auto-cast from i32 to usize: this isn't guaranteed to work well in non-64 bits platforms. Beyond the portability issue, there is also a "negative indices" issue. Code like `let idx = -1i32; foo[idx]` shouldn't be allowed to compile.
One suggestion that comes to mind would be to use a safer mechanism for updating the files. At the moment the file is deleted and then written out with the new content. If anything goes wrong between those steps then I think the contents will be lost or truncated. Also any other applications that have them open (such as IDE/editor) may see the file disappear, then come back in parts depending on the size of the chunks use to write out the content. I’d suggest writing the new file out to a temporary file (in the same directory) and then move (rename) it into place. Rename _should_ be atomic if the source and destination are on the same file system: &gt; If newpath already exists it will be atomically replaced (subject to a few conditions; see ERRORS below), so that there is no point at which another process attempting to access newpath will find it missing. &gt; If newpath exists but the operation fails for some reason rename() guarantees to leave an instance of newpath in place. — https://linux.die.net/man/2/rename See also: https://doc.rust-lang.org/std/fs/fn.rename.html
Thanks for the reply. It's not extremely time sensitive, so I guess I could do on the same thread. For not http requests are the only thing. The problem with that is that self.core.turn(Some(Duration::from_millis(100))); or self.core.run(Future); would block the thread, wouldn't it? How do I run my program loop in the same thread as the core? 
So, well, the friend implemented HKT via `include!` macro. Initially, this was done by hard-coding the path (which is in another crate in the same repo), and he 'fixed' it by making build.rs copy that file into this crate. I have a feeling that this is very hacky, and there's probably a better solution. Any advices?
Disagreements are great! But snide passive aggressive comments like the one in the top of this thread are not appropriate. Please stop making comments like that.
I also used nom for parsing for some of the problems. Like you said, it's overkill, but a great way to get started with nom! I found it quite tricky in the beginning due to the errors rust macros generate, but once you get going it's really nice! I had some problems going from parsing one line to parsing multiple. My tip is to make sure the parser that parses one "expression" only parses what it needs and leaves any newlines in the end and crashes if there are any newlines or white spaces in the start. Then use many0!(multispace) in the parser that eats many expressions. Doing it this way really improved my experience!
I am very afraid that the 2018 roadmap will have an ergonomics initiative bullet point as well... I didn't think of that in my dreams, thought this was a done deal, but then I read that blog post which argued for even more of that initiative. I'm afraid that this has unsettled me. I personally have underestimated the importance of roadmaps last year and regretted it the entire time I had argued against many of the ergonomics initiative proposals (many of which were seriously toned down in the process), as there is more fun stuff to do than preventing Rust to do bad decisions in the name of ergonomics.
&gt; E.g. think of a case where you are adding three u16 values to one i32 value which should be a u16 value because of the problem at hand, but you didn't refactor or something, so you ended up with a i32. With current Rust, you'll most likely cast the i32 to an u16, or alternatively, refactor your code to be right. With "auto upcasting" Rust, you probably wouldn't notice this the first place and leave the code in the current, bad, state. You're assuming the person isn't doing as I do and writing a function where the differently-sized types for arguments and the return value ensure that overflow/underflow is impossible at compile time. The only reasonable refactor there (changing `i32` to `u32` since adding together `u16`s cannot underflow) would have no effect on the necessity of `as`.
You write your program as a future and core.run() it
Actually, rocket isn't using much from hyper and the maintainer is considering moving away from it.
For day 7 and 8, I thought about learning nom, but gave up because it looked intimidating, so I went back to using Regex. Day 9 looks very hard to do with regex (is it even possible?). So I guess I'll have to bite the bullet and learn nom and parse me a real AST.
Yeah, I see that this is the way used everywhere. However, that would mean changing the whole program to use futures everywhere. I just wanted to use it to send request asynchronously.
Servo uses both Harfbuzz and freetype2, so presumably they have bindings you could use?
My [mio_httpc](https://github.com/SergejJurecko/mio_httpc) may be of use.
Screenshots?
Come again? u32 can definitely *not* represent all values of i16. How could it represent -1? Do you propose we also make the cast from i32 to u32 automatic?
The principled thing to do is to require your users to provide them inside an attribute, so if you wanted your users to be able to do: ``` #[derive(Foo)] struct Quux; ``` you would actually make them write: ``` struct Barlike; #[derive(Foo)] #[foo(bar = "Barlike")] struct Quux; ``` That said, the *unprincipled* thing to do, which goes against the spirit if not the implementation of proc-macros 1.1's implementation of custom derive, would be to generate some name based on your associated type and the wrapped type. That's the only option when writing new custom derives, you don't have any access to the compiler's knowledge of existing types, you just have access to the tokens passed in to your function. For an example of this style, you'd make: ``` #[derive(Foo)] struct Quux; ``` after code expansion look like: ``` struct Quux; struct QuuxBar; impl Foo for Quux { type Bar = QuuxBar; } ``` If you *do* do that you should *definitely*: * document the exact algorith for how they're generated. * provide the escape hatch of the `#[foo(bar = "yourtype")]` attribute overriding the default. * consider adding a doccomment to the generated `QuuxBar` type stating its purpose and maybe that it's autogenerated, since it will show up in docs.