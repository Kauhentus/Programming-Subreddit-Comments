I am wondering if Rain might be suited for the use case commonly seen in particle physics. We usually have a large number of large input files distributed over many computing sites (Total in the TB or PB range). Essentially we want to do a map-reduce. Each computing site runs an analysis over a chunk of files which are locally available; producing a much smaller output file. All the output files of the different computing sites are then merged to one final output file which is presented to the client. Do you think something like this is a fitting scenario for Rain? The execution-graph of that use case seems to be very simple and the data send to each computing node is essentially a simple list of input files. The analysis which is to be run would be written in Rust (for example my [alice-rs](https://github.com/cbourjau/alice-rs/tree/master/examples/simple-analysis) project). Or is Rain an overkill here / I missed the point of it? Thanks either way and I am super happy to see more scientific computing in Rust!
&gt; As for expected completion and better scheduling (now it is really simple and we are working on a much better scheduler), the user should be able to give us hints on task time and data blob size (even a rough estimate will help a lot) and the scheduler should be then able to schedule more than one task "layer" (which is not really possible when you do not know which tasks take seconds and which hours etc.). This is well and good, but I would strongly suggest simply allowing for a timestamp as well (maybe even a few, like, this is the earliest I expect it to run, this is when it's late, this is when you should just give up). I'll have to read your documentation in depth to offer better feedback.
So would you like to try it on Rain? We would be happy to help and perhaps adapt it to your use-case. How do you run your code? Is it in Rust, or some external program? Is your code somewhere online? (We can discuss details at the project [gitter](https://gitter.im/substantic/rain) or just email me at gavento@ucw.cz).
Which RFC is the `extern crate` deprecation in? Or is it already in nightly?
Actually that part about brk in alloc might not be right. Libc malloc looks a little more complex in how it does allocations. Jemalloc still has alloc and free and seems to prefer mmap for them though.
Well, that is interesting. I am able to call gd on func and it jumps correctly. I can also call K and my status line prints "fn (value: i32) -&gt; i32. It is really a bummer that I apparently cannot use rls very effectively on rocket, gotham, or actix-web. Oh well. One last issue. If I put use::io::Read; at the top of my file neither of the two commands I am trying work quite right. LanguageClient_textDocument_hover on ::Read puts a link in my quicklist to the documentation (online), but I don't want to use a browser to view the documentation. Can I see this directly in Vim? LanguageClient_textDocument_definition on ::Read goes to /myproject/libstd/io/mod.rs which is an empty file. Any idea why this isn't going into the rust src so I can see the code? Thanks for your help so far! I'm excited to be able to actually work on a project soon. 
I belive that you missed the thread. If your question is about bidirectional communication of capnp, then yes, a single connection is used under the hood.
I’ve published an STM32L0x1 crate, do you have any advice or guide on developing the corresponding STM32L0x1-hal crate? Thanks! :)
The deprecation is in [RFC 2126](http://rust-lang.github.io/rfcs/2126-path-clarity.html), the path clarity RFC. Seems that particular aspect is not implemented yet however, according to the [checklist in the tracking issue](https://github.com/rust-lang/rust/issues/44660).
What is the size of the resulting file ?
https://github.com/rust-lang/rfcs/blob/master/text/2126-path-clarity.md
Fantastic! This, the proposed macro change and the recent change allowing nested uses really helps clean up the import junk that accompanied every rust file.
What is your main goal? no_std or small binaries only? If the latter, you can check this: https://jamesmunns.com/update/2018/04/01/tinyrocket.html You cannot use Vec, because in no_std, there is no allocator. Vec needs an allocator. In a no_std environment you can use the core library (of course it will not have vec): https://doc.rust-lang.org/core/
I personally just consider it to be a part of placement and would remove it based on me removing the rest of placement because it doesn't work as designed. A brand new RFC for box syntax on the grounds that it's a nicer way of creating boxes [0] is certainly possible if you want, but it's probably not appropriate to stabilise it for completely different reasons than the RFC was originally accepted for. [0] I agree, but wouldn't say it stands by itself as a language addition
My goal is small binaries (where small = up to 64 kilobytes). A bit as a demoscene exercise, but also just out of interest. I don't mind having to link to a few common C runtimes, for that reason. If I would be able to use the system allocator, wouldn't that mean that Vec should be able to function?
You can't even have `async` trait methods because there's no `-&gt; impl Trait` in traits yet.
So I suppose you would have to define the trait method to return a boxed Future and then have the impl wrap an `async` function?
But the RFC says that it doesn't use `-&gt; impl Future&lt;Item=T&gt;`, it uses the interior type `T`.
Hi and thanks for the problem statement. This does sound like a good match for Rain (definitely a use case we want to support as we frequently need something similarly simple) although there are two gotchas now. First, we do not support loading worker-local files now, but that sounds like an easy and useful addition (via the `open` task pinned to the right worker - what do you think /u/winter-moon ?). The other is Rust task integration: I must say we were not really prepared for so many people asking about it (although it is not a surprise here). Now the easiest way is to either run the computation as an external program accepting files (straightforward) or hack in a custom task into our worker code (similarly to [here](https://github.com/substantic/rain/blob/master/src/worker/tasks/basic.rs)). I think that Rain would be a plus even when a simpler solution would also do the trick: you get online monitoring (and we are working on post-mortem visualization as well -- the event logs are already there), specifying the tasks in Python might be easier than inventing some new config schema, the local files are cleaned up for you, and in the case one worker would be overloaded, the scheduler might move some data to another worker to process (although that is probably not relevant for your huge data). In any case, it looks like a nice use-case and we would be happy to help!
What is the reasoning here? Just curious :P
&gt; Futures which wish to have an error channel will instead of an Output which is a Result. of -&gt; have?
Yes.
Yes indeed -- I regret holding off on this for so long! The proposed API feels ... canonical.
/u/japaric is probably a much better person to talk to. I'd look at his [stm32f30x-hal](https://github.com/japaric/stm32f30x-hal) crate. I'm starting with implementing the GPIO pins and following the pattern I see. Things that change the performance of the pin like the output speed register the struct methods take mutable references to self. Things that change the functional behaviour of the pin i.e. setting it as an output pin or setting one of the alternate function modes consume self and return the new pin. This means if you set say a pin to an alternate function like UART and make a UART peripheral that takes it if you change the function of the pin while the UART peripheral still exists the borrow checker won't let you! Aside from that as well as device datasheet there is a processor family register map pdf which is more useful than the device datasheet. Found yours for you [here](http://www.st.com/content/ccc/resource/technical/document/reference_manual/21/bd/0f/bd/1c/88/40/f0/DM00108282.pdf/files/DM00108282.pdf/jcr:content/translations/en.DM00108282.pdf)
I am confused about why the restriction of async function to "return immediately". Isn't part of the point of async functions for part of their computation to start when the async function is called and then await is used to wait for the function to finish? Otherwise, if you have two async functions that you want to have execute in parallel you would have to alternately poll them and then change to just polling the one that finished second. This seems very weird
I'm having a blast reading all these reports. Thanks everyone for the hard work !!!
...but then only by using Xargo to do a custom compile of std that forces the use of the standard allocator (and other tricks mentioned in James Munns' post), I suppose?
`get_mut` is useful if you're unable to consume the `Entry`, as is required by `into_mut`. There's a comment in the rust source about this; both `get_mut` and `into_mut` defer to `Entry::elem`, which is a `FullBucket`. In the `FullBucket` implementation: /// Gets mutable references to the key and value at a given index. pub fn read_mut(&amp;mut self) -&gt; (&amp;mut K, &amp;mut V) { unsafe { let pair_ptr = self.raw.pair(); (&amp;mut (*pair_ptr).0, &amp;mut (*pair_ptr).1) } } //etc... /// Exchange a bucket state for immutable references into the table. /// Because the underlying reference to the table is also consumed, /// no further changes to the structure of the table are possible; /// in exchange for this, the returned references have a longer lifetime /// than the references returned by `read()`. pub fn into_refs(self) -&gt; (&amp;'t K, &amp;'t V) { unsafe { let pair_ptr = self.raw.pair(); (&amp;(*pair_ptr).0, &amp;(*pair_ptr).1) } } // etc... /// This works similarly to `into_refs`, exchanging a bucket state /// for mutable references into the table. pub fn into_mut_refs(self) -&gt; (&amp;'t mut K, &amp;'t mut V) { unsafe { let pair_ptr = self.raw.pair(); (&amp;mut (*pair_ptr).0, &amp;mut (*pair_ptr).1) } } So basically, they "do the same thing" if you ignore lifetimes; but because the `Entry` object must still have a valid reference to the map when it is `Drop`'d, it can't give you a full lifetime - unless it is `Drop`'d in the process. tl;dr: use `into_mut` unless you need to pass around and/or store `Entry` structs. Edit: I'm submitting a PR to make the difference clearer in the examples.
Are there any examples of docs generated with this tool? Would love to see an online version
Yeah. Or if you just want `core` but also `vec` and friends without the rest of the stdlib, then you can pull in the `alloc` crate which is where `std` itself gets the collections from.
Ah! I didn't realize `alloc` would contain collections. Thanks!
Not exactly... Async functions must return immediately so that we can *do things* with the result of the computation *before the computation actually finishes*. You can use *what the result will be in the future* to set up computations *now*, and then when you actually *run* the future on an executor, all the previously set up computations will actually be run.
The whole reason I ran into this in the first place is because I was using `get()` to return an immutable reference, which wasn't allowed due to the lifetime business. E.g. a simplified example: https://play.rust-lang.org/?gist=12357511c761792681f4b51f679ae593&amp;version=nightly It was a real headscratcher that I had to call `into_mut()` __to return an immutable reference__. There is no `into()`. Very confusing.
So from my experience, I would generally use async functions like the following: let future1 = asyncFn(param1); let future2 = asyncFn2(param2); await future1; await future2; I am coming from uC++ and Javascript so maybe this is just a language quirk
Breaking backwards compatibility is trendy.
I think this is irrelevant here. Whether function is implemented as async or as usual function is an implementation detail. What matters for callers is that it returns a future.
Wasn't there some clever solution for 'implicitly' threading through a `Context` (based on [`arbitrary_self_types`](https://doc.rust-lang.org/nightly/unstable-book/language-features/arbitrary-self-types.html)) without the need for TLS? What ended up happening to that?
I have checked crates.io and done some searching, but I do not see a bigint crate that has the properties i need. Mainly, I need this type to be able to create very large fixed size integers that behave just like the primitives do e.g. BigInt::new(256) will create a big integer, but unlike the `BigInt`/`BigUint` supplied by `num`, its size is fixed at creation, and operations wrap around as I256 should, and I can access the internal `vec`. I thought about copying and pasting from libraries but I do not know enough about licensing issues. I am not quite sure what to do.
The repo’s link is the tool being used on itself. that is, https://steveklabnik.github.io/doxidize/ Note this has several big bugs that have already been filed.
In JS you should actually do something like let f1 = asyncFn(param1); let f2 = asyncFn2(param2); await Promise.all([f1, f2]); Otherwise you only reach first yield point in `f2` and then wait for `f1` to finish before you continue `f2`. 
 Not true, those two have the same result. In javascript, await means complete until return
That's only the surface syntax, it desugars/lowers, at some level or another, to `-&gt; impl Future`.
Well, the Rust implementation of futures is indeed different, but a similar thing happens in other langauges conceptually. What you wrote above is basically syntactic sugar // setup computation let future1 = future::ok::&lt;_&gt;(|| { //do whatever }); let future2 = future1.and_then(|result1| { //do whatever with what's going to be the result of asyncFn }); // rust implementation detail executor.spawn(future2); 
The problem with auto-aliasing is forward compatibility. Imagine that a `foo` subcommand is added to `cargo` and suddenly your CI barfs up because everything became ambiguous, your README.md for new contributors has to be edited, etc... Whole lotta pain :(
Isn't `arbitrary_self_types` required for stabilizing `async`/`await`? Or is `Pin&lt;T&gt;` treated specially (in the meantime, I guess) just like `&amp;T`, `&amp;mut T` and `Box&lt;T&gt;` are?
Hm, I don't belive so... `await future1` would block until completion and then `await future2` would run future2 afterwards.
 fn poll(self: Pin&lt;Self&gt;, ctx: &amp;mut task::Context) -&gt; Async&lt;Self::Item&gt; Oh hey, it looks like the ["Explicit `task::Context` argument to `poll`" RFC](https://github.com/rust-lang-nursery/futures-rfcs/pull/2) got merged. That's a pretty big change for those of us who haven't looked at the inner workings of futures much since last year.
Yes, but they are called (ie the promises are made) before either is awaited. So both are active and then we wait for one to finish and then the other.
Would it be possible to be able, at the call site, to specify which `impl` should be called regardless of specialization? It seems this could be quite useful for *testing*, to make sure that both the generic and specialized versions agree on results in QuickCheck tests, for example.
Ah, right. I misunderstood your scenario. Anyway I see in another comment that you got the idea--async function returns an implicit future immediately so that we can continue execution and then await causes block on that future
I'm not actually working on such a paper right now, and putting this into Coq to integrate it with the rest of everything would still be quite some work. (We have some strange hacks that make this harder, and that I just recently found a way to get rid of, but that requires some other changes that I already wanted to make anyway -- but at this point we're talking about several weeks of just Coq implementation work.) And then there's the problem that a new paper should have a noticeable contribution on its own, which may take more than just one new API... I hope eventually someone (me?) gets around to formalize drop and #[may_dangle], and maybe even relate formally to NLL, and then we'd have enough novel stuff together to make it a paper again. But at this point we're definitely talking post-thesis for me. But yes, I sure hope to put this into a paper some day, and who knows---maybe at some point I'll have students that can figure out all the details and do the Coq work. ;)
There's also [`hexplay`](https://crates.io/crates/hexplay), which has a few more nice formatting options in case the bells and whistles are desired. :)
Oh. In this case, yes, there _should_ be an `into_ref()` method... because `into_mut()` is the only way to get a reference with lifetime `'a`. I'll make an issue about this, and see what people think about adding an `into_ref()`. Edit: Interesting note: this has been mentioned before, but was immediately closed when the poster found `into_mut()` ([#39099](https://github.com/rust-lang/rust/issues/39099)).
Ah excellent, thanks will check it out
`rustup` currently manages a per-user toolchain, so it's not *too* different from the per-user Cargo download cache. I think a good mix would be the system compiler combined with per-user `libstd`s built with custom feature flags (presumably by the system compiler, if not a pre-compiled `libstd` that can be downloaded).
&gt; right, so even though the async function returns immediately the future that is returns starts to execute the code of the async function concurrently or if possible in parallel? No, futures in Rust are lazy meaning they don't start to execute until you tell them to start executing. A future returned from an async function wouldn't start to execute until something causes it to do so -- for example by `await!`ing it, or by spawning it on an executor directly. &gt;And does await! wait for the next await block in the future or for the return? AFAIK, `await!` waits for the contained future to complete and then continues.
&gt; Async functions return immediately when they are called - none of the code in their body is executed. What they return is a future, representing the state machine of their body transitioning from await to await until it finally returns the final value. &gt; &gt; There are other designs which you could imagine in which futures eagerly evaluate up to the first await point before returning. We have decided to instead return immediately because we believe the mental model is simpler - you always know that none of the body of the async function will be evaluated until you begin polling the future it returns. For use cases which have a short intiailization step, the async_block! macro in the futures crate will provide a good alternative. Hi, I'm on the Dart team. Dart's async/await was designed mainly by Erik Meijer, who also worked on async/await for C#. In C#, async/await is synchronous to the first await. For Dart, Erik and others felt that C#'s model was too confusing and instead specified that an async function always yields once before executing any code. At the time, I and another on my team were tasked with being the guinea pigs to try out the new in-progress syntax and semantics in our package manager. Based on that experience, we felt async functions should run synchronously to the first await. Our arguments were mostly: 1. Always yielding once incurs a performance penalty for no good reason. In most cases, this doesn't matter, but in some it really does. Even in cases where you can live with it, it's a drag to bleed a little perf everywhere. 2. Always yielding means certain patterns *cannot* be implemented using async/await. In particular, it's really common to have code like (pseudo-code here): getThingFromNetwork(): if (downloadAlreadyInProgress): return cachedFuture cachedFuture = startDownload() return cachedFuture In other words, you have an async operation that you can call multiple times before it completes. Later calls use the same previously-created pending future. You want to ensure you don't start the operation multiple times. That means you need to *synchronously* check the cache before starting the operation. If async functions are async from the start, the above function can't use async/await. We pleaded our case, but ultimately the language designers stuck with async-from-the-top. This was several years ago. That turned out to be the wrong call. The performance cost is real enough that many users developed a mindset that "async functions are slow" and started avoiding using it even in cases where the perf hit was affordable. Worse, we see nasty concurrency bugs where people think they can do some synchronous work at the top of a function and are dismayed to discover they've created race conditions. Overall, it seems users do not naturally assume an async function yields before executing any code. So, for Dart 2, we are now taking the very painful breaking change to change async functions to be synchronous to the first await and migrating all of our existing code through that transition. I'm glad we're making the change, but I *really* wish we'd done the right thing on day one. I don't know if Rust's ownership and performance model place different constraints on you where being async from the top really is better, but from our experience, sync-to-the-first-await is clearly the better trade-off for Dart. 
&gt; the future that is returns starts to execute the code of the async function concurrently No. No code associated with either future is executed until an 'await' is hit. Once any await is called on any future though, all futures which are on the same eventloop (so both of them in this case) will execute concurrently. If no await call is made, no progress at all happens. The 'await' call is effectively yielding time to the event loop since, unlike js, there isn't already some global always-running event loop.
Why are they lazy? That seems like a weird way of doing them? Would it be possible to make a non-lazy future in the future?
Good point. However, the thing I was worried about with `Cell` was basically strange behavior: bugs that are difficult to reproduce, identify, and fix. You can definitely manage to use an atomic incorrectly (or `&amp;mut` mutation), but some things are more likely to result in demon bugs than others. Personally, that's where I put `Cell` - likely to end up causing strange behavior (and creating headaches) down the line.
The lack of support for `impl Trait` in traits is a *semantic* issue, not a syntactic one. An `async` function, regardless of notation, returns an `impl Future&lt;Item=T&gt;` and therefore semantically there is a problem. As for the problem in question: at the call site of `fn x() -&gt; impl Trait`, the compiler knows what exact concrete type `x` returns, and therefore can reserve the exact space necessary on the stack and call the exact implementation of `Drop` needed during code generation. On the other hand, if you were to call a trait method returning `impl Trait`, then either: - the exact concrete type would have to be the same for all implementations, - or the compiler would not know what exact concrete type it will be handed over, complicated code generation (and possibly impacting performance).
You should probably thank Simon Marlow. The Async/Await idiom was invented in Haskell, then ported to F#, then portes (with compiler changes due to its lack of expressiveness) to C#. That said Anders deserves credit for his relentless push for _practical_ improvement in imperative languages; and in particular translating good idea from pure functional languages over to impure imperative ones even when (as in LINQ and async) it’s required compiler changes to do it. 
Ah gotcha. Thanks.
So if you wanted a "non-lazy" future in rust it would be a combination of generators or threads and futures? The reason that I am asking is that this is supposed to help with async IO which includes db accesses and I would imagine that have many db queries happening at once while the current thread is doing some other intensive task might want to be done
Yes but my code was the following (copying from your example for comparison's sake) let delay = (time) =&gt; new Promise((resolve) =&gt; setTimeout(() =&gt; resolve(), time) ) let foo = async () =&gt; { await delay(1000); console.log('foo'); await delay(1000); console.log('foo2') } let bar = async () =&gt; { await delay(1000); console.log('bar'); await delay(1000); console.log('bar2') } let fooPromise = foo(); let barPromise = bar(); await fooPromise; await barPromise; Another things to note: let fooPromise = foo(); let barPromise = bar(); await delay(2000); await fooPromise; await barPromise; Will have basically the same run time (plus or minus the time it takes to print out the lines) which means that JS promises (futures) does start to run but still immediately return.
Indeed. Any type implementing interior mutability is a scalpel: useful in specific circumstances, but sharp enough that it should be handled with care. It is common in Rust to see a function call on a `&amp;T` and dismiss it as "cannot modify `T`", and this breaks down with interior mutability, challenging developer reflexes :) So, before reaching for internal mutability, ask yourself if it's worth the trouble and what the alternatives are!
I think the distinction might be a little different though, no? In the proposed Rust API, you *can't* just return a Future from inside an async function (or, you could, but you'd have a Future&lt;Future&lt;_&gt;&gt;). If you wanted that kind of API, you'd have to make a synchronous function whose type explicitly returned a Future which took care of checking if there was a cached Future that could be returned.
Congrats on the release. It's good that things are moving forward. Given that it looks like futures 0.3 is on the horizon and will come with breaking -core changes. Would you suggest that the ecosystem goes through two breaking changes (now and for 0.3) or should libraries like Tokio maintain support for both 0.1 and 0.2 and then have a single breaking change when 0.3 is released. My main concern is that, given the time cost of updating the ecosystem, by the time it is done, futures 0.3 will have been released and we will have to update it again.
😳 You're right. Of course. It seems obvious when I think of it now. Sorry. I've just seen too many `await foo(); await bar();` at work and I grew allergic to it.
Ah true, I hadn't considered that. However if that's a concern I'd rather not use any magic prefix for similar reasons, as there are only so many sigils not in use by shells (and thus don't need escaping) and I'm not sure saving four keystrokes is enough to justify such a shortcut as we may find something else we'd want to use such sigils for.
I think I'd fork `Vec` and have it use libc malloc in that case. Rust pointers keep track of the size of their target. (bounds checking of slices, `std::mem::size_of_val`, etc.) A Posix malloc is required to remember the size of allocations; a Rust alloc doesn't. So you *can* use libc malloc, just don't pass the size to free, but it duplicates the bookkeeping. 
Ok, thanks for the clarification.
My post. Basically ssh tunnel, but via Cloudflare so you don't actually need to set something else up yourself at the other end of the tunnel. disclosure: I work there, although it's not my product.
That is fair. At during interviews we asked a question about that exact problem to see if candidates would catch it. And you can rearrange them as long as there are pure with respect to each other.
Unfortunately, yes it has to be `'static`. I think the best hope to shed the `'static` requirement will be async / await. I definitely agree that docs on generated code is important! A lack of docs is one of the main reasons the tower stack hasn't been pushed to crates.io yet. I'll be focusing on rectifying all that soon.
Using `wee_malloc`seems to work: It uses `VirtualAlloc` under the hood (on Windows, that is). By using the unstable `global_allocator`feature Rust uses that as an allocator and it should be fine?
Async functions don't *await* immediately when they are called, they merely *return* immediately when they are called. This means that when you call an async function from another async function and then immediately await it, only one yield actually takes place. This works in part because Rust's futures are poll-based rather than callback-based. Calling the async function constructs the future, and awaiting it calls `poll` and yields in a loop. So while *calling* the function doesn't immediately run the first part of its body, *awaiting* it does- before the caller suspends. That should cover both your points 1 and 2, I believe. (Also, awesome to see you here on /r/rust! :) )
In Java/Scala, whether you're using Maven, Gradle, or sbt, you'd be using plugins to cover this use-case. They usually do a good job, either hooking into the standard phases, or adding new ones. However they're installed independently from other dependencies, and often they're not developed by the framework authors, which means that getting the right framework/plugin version combo can be difficult (and sometimes figuring out the right plugin is difficult). Also, each build system has got its own plugin system, leading to a lot of duplication of effort. I like the idea of using tasks to scope installed binaries at specific versions to a specific project, but even more so I like the idea of effectively merging the concept of "dependency" and "plugin". At the end of the day, they're one and the same, and I think that the fact that they're different in Java-land is just an implementation incident. As for the possible increase of build times, I think that's an orthogonal problem and should be addressed separately. If cargo became able to save build artifact in a global cache, and reuse them across projects, we'd have all the same benefits, and very little slow-down. 
Regarding the unresolved question of await syntax: imo `future.await` or `future.await()` would be nice, and play well with precedence of operators like `?`. 
It sounds similar to the python implementation of async/await actually. 
I think that "open" task is not necessary to use. As I understand the problem, the input data should not leave the node, hence it is not necessary to manage it by Rain as data objects. The missing thing is pinning tasks to workers; however, it can be implemented quite easily (at least with some basic Python API and a hack to scheduler). 
Thanks for the feedback! It's always great to get more insight into the development of other languages and ecosystems. The performance tradeoffs you discuss don't exist in the Rust implementation-- the difference we're discussing is exclusively a syntactic one, rather than a behavioral one. A "zero yield" in Rust is a total no-op given some amount of inlining. Also, the patterns you're discussing can be implemented in Rust given either convention. in the case of your `cachedFuture` example, Rust's ownership model and aliasing guarantees, combined with our poll-based futures model mean that this example would look significantly different. Rather than calling `startDownload` and storing a copy of the resulting future, you'd actually want to create a new "shared" future from the result of `startDownload`, store it, and await the result of that computation. The code would look something like this: async fn get_thing_from_network() -&gt; Arc&lt;Thing&gt; { // Arc is an atomically-reference-counted pointer // Declare a thread-local shared future that may have been initialized thread_local! { static THING: RefCell&lt;Option&lt;SharedFuture&lt;Thing&gt;&gt;&gt;: RefCell::new(None); } let thing_fut = THING.with(|thing| { // Initialize the future if it hasn't been created already if thing.borrow().is_none() { *thing.borrow_mut() = Some(future::shared(startDownload())); } // Return a copy of the shared future thing.borrow().clone().unwrap() }); // await the shared result await!(thing_fut) }
There is a macro, but it's a procedural macro (unstable), and it already relies on generators (also unstable, and a language feature already anyway). The RFC also addresses the question of "why don't we just stabilize procedural macros and generators instead?" There are several answers there- nicer lifetime elision, better composability with (eventually) generators-as-iterators and streams, etc.
&gt; Async functions don't await immediately when they are called, they merely return immediately when they are called. It's the "return immediately" part that can be a problem. If any other code can possibly execute between when your async function is first called and when its body begins to execute, then it's possible for race conditions to sneak in if you expect to be able to synchronous work at the top of the function. If that *isn't* the case, then, yes, you might be right and Rust will be fine.
You're right, the race condition confusion is a third point independent of the first two. I actually just left a comment on the RFC thread with a possible change to address that confusion without changing the execution model: https://github.com/rust-lang/rfcs/pull/2394#issuecomment-379382487
second*, at least: https://crates.io/crates/trait_enum &lt;3 u
Technically third, I also published https://crates.io/crates/rust_mvc about a year ago But this is the first one I actually feel is useful
If you need code to execute immediately when a function is called rather than later on when the future is polled, you can write your function like this: fn foo() -&gt; impl Future&lt;Item=Thing&gt; { println!("prints immediately"); async_block! { println!("prints when the future is first polled"); await!(bar()); await!(baz()) } }
Ah yes indeed! I'm under the impression this is a relatively local problem though, right? Or do the incorrectly type constants end up showing up in lots of places throughout the ecosystem?
Forking vec/alloc isn't necessary at all. The language already provides a mechanism (albeit an unstable one) to use the system's default allocator.
Have you compared this crate with https://docs.rs/rpds/0.4.0/rpds/ ? 
If you're writing a block which returns a `&amp;mut` reference which might point into a map and might point somewhere else? I don't know what uses it for sure, but the standard library does contain things that mere mechanism without policy. Creating `&amp;mut str` even though std can't do anything with it is another example. 
I really don’t like generating protobuf code with Cargo. It seems prost only supports x86 machines. It requires manual installation of protoc on arm devices.
I guess that's enough to merely prevent jemalloc from being linked. 
Yep, if you just want your binaries smaller. `Vec` is a good read though. 
I see that your hosting the [code](https://github.com/VictorKoenders/bitrange) on GitHub, please add a link to the repository to your manifest file so crates.io can link it. Easy access to the source is very convenient when exploring crates. You might also want to add link to the [documentation](https://docs.rs/crate/bitrange/) hosted by docs.rs.
Last time I used Prost it was trying to download protoc on Raspberry PI. It seems that it started to embed protoc but unfortunately it doesn’t embed arm32v7 binary. Aarch64 support is nice but Raspbian is released only for arm32.
Thanks a lot! I had completely overlooked the type Item = &amp;'a T in the implementation of impl&lt;'a, T&gt; IntoIterator for &amp;'a Vec&lt;T&gt;. So now I understand that I cannot directly have a non-consuming iterator that yields copies of my T, I have to do it manually. Thanks :)
Hi! It's because when the user presses the Enter key of the keyboard, it adds a newline ('\n') character at the end of input. So input is never equal to "a" but to "a\n", or "b\n" and so on... To remove this trailing newline character, you can use the method trim() which returns a &amp;str, so you only have to change this part of your code to make it work: match input.trim() { instead of match input.as_str() { You can see the documentation for trim() [here](https://doc.rust-lang.org/std/primitive.str.html#method.trim).
Thanks! That fixes the issue. 
Prost generates protobuf the way many other languages do, with protoc. All of your complaints would apply to just about every language [here](https://developers.google.com/protocol-buffers/docs/reference/overview). Your issues appear unrelated to Cargo.
Naive question: why can await only be used inside of futures? It seems like it would be more consistent to allow it everywhere and then you wouldn't need `future::block`?
Can’t wait! Terrific work. 
Yes, I realize I'm in a pickle at this point. Maybe temporarily revert support, I don't really know. See https://github.com/hyperium/hyper/issues/1481
Heap-allocation-free parsing.
A component of gRPC is that I can use a bunch of different languages. Will that still be the case if I use tower-web? Like, the service is rust, built on tower-web, can I still use some gRPC client like in Python to talk to it?
That's one of my favorite changes :) It makes it *much* easier for newcomers to Rust's async story (me a month or so ago) to understand the execution model, since I can see the `Context` object - it just makes it a lot more clear to me how the semantics around returning `Async::Pending` and "registering interest" work.
Looks useful, but it would be even more useful if it could capture a backtrace of allocations to make it easier to determine where an allocation is happening in code. Maybe this could be implemented using the [backtrace](https://crates.io/crates/backtrace) crate.
Wrong sub, go ask on [/r/playrust/](https://www.reddit.com/r/playrust/).
tower-web is HTTP. So you can use HTTP clients written in any language like Python tower-grpc is gRPC, so if you write the service with rust, you can use a python grpc client to talk with it.
You can choose to ignore the system compiler, but I want it to at least be *possible* to use as your daily driver too. Do you install your own toolchains for everything? Even the `cc` that `rustc` uses for linking? I want to see `rustc` become a part of the system like that, not forced to download on the side.
Everything I develop with I install my own toolchain for. It's basically the only way to have builds that work on continuous integration environments.
Perfect. Thank you.
Not sure if that’s given me clarification, other than wait?
Thanks a lot for the reply Steve! This was really helpful and illuminated a lot about the governance that I was ignorant to!
Yes, that was my understanding.
Great input, really appreciate seeing people with experience in other languages commenting here! &gt; Overall, it seems users do not naturally assume an async function yields before executing any code. As a mainly JS dev, I wanted to chip in that I *do* assume that async functions yield before executing any code.
For anyone who missed it, this is a massively big deal and welcome change. To quote the original article: &gt; The heart of the futures library is its task system. But historically, that task system was almost invisible: information about the current task in 0.1 was provided via implicit context (a thread-local variable): &gt; While this implicit context had some ergonomic benefits, it was also a major stumbling block for learning futures, and meant that you needed to carefully read documentation to know whether a given function could only be used “in a task context”. &gt; In Futures 0.2, we instead deal with task contexts via an explicit argument: I’m very impressed that the negative feedback about that initial design choice was listened to, and acted on. Very exciting stuff~
It kind of boggles me that Dart devs expect to be able to do synchronous work in an asynchronous function.
Mixing Rust and some old school ‘&lt;marquee&gt;’ tags is, ironic ;) I had to look up the tag, it’s so old it’s obsolete: https://developer.mozilla.org/en-US/docs/Web/HTML/Element/marquee Why no ‘&lt;blink&gt;’ tags? Just kidding! This is really awesome, Steve! Thanks for sharing. It will be interesting to see what some small Rust apps can do on the internet, served from tiny servers... with a large front-end cache.
Chucklefish has PS4 working as a compile target, but they started using Rust after releasing Stardew Valley so nothing from them released yet. Prey has a neat little [Easter egg](https://www.reddit.com/r/rust/comments/69s225/rust_makes_it_into_a_aaa_video_game_as_an_art/).
It looks like the binaries will still be kept separate - so from a code perspective, the 'merging' of functionality should add too much of a burden.
 1. When I'm reading something from RocksDB and have a `&amp;[u8]` rather than a `Bytes`, I'd like to allow `bytes` and `string` fields to borrow from that slice rather than allocating and copying. `quick-protobuf` has this feature. 2. Unknown fields. There's an [issue](https://github.com/danburkert/prost/issues/2). `protobuf` has this feature.
Kind of sort of. The vector is acting as an allocator; it doesn't care about the type or construction of the value per se. It only needs to know how much space to allocate and where it should put a pointer to that allocation so the space can be initialized. Neither of these problems are solved by making the type concrete; they're solved by making the *construction* complete. That's where the hard problem is. 
&gt; Last time I used Prost it was trying to download protoc on Raspberry PI. It seems that it started to embed protoc but unfortunately it doesn’t embed arm32v7 binary. Aarch64 support is nice but Raspbian is released only for arm32. Yeah, that's because there's no [official build](https://github.com/google/protobuf/releases) on arm32v7. You do have a few options, though: you can cross-compile, in which case you only need the `protoc` for the compile machine, not the target. Or you can pre-generate and checkin the `.rs` files. `prost` doesn't make pre-generation super easy, but it's possible to find the outputs if you dig into the `target` directory far enough. Other than the build-time dependency on `protoc`, the rest of `prost` is pure Rust, so at runtime it should work fine on any supported architecture.
FWIW there's an [open issue](https://github.com/danburkert/prost/issues/31) for #1 as well.
I will admit I don't understand exactly what Tower is after reading this. It sounds like Tokio reannounced under a different name, and yet Tokio still exists. I vaguely recall reading a comment from /u/carllerche that described Tower as "everything tokio-service and up" but I still think it's difficult to understand why they're two separate things and how all this stuff fits together. When futures and Tokio first came out, I understood the division to be that futures is for general purpose async computations and Tokio is for async I/O using futures. As of futures 0.2, that line is even more confusing because there are some I/O-specific things in futures itself. And now with Tower, it all feels more muddied.
Yeah I'm a huge fan. It just feels *righter*.
Here's a simplification. Tower is 2 things. - `async fn call(Req) -&gt; Result&lt;Res, Err&gt;` But as a trait, so it's easier to be generic over it, and compose it. The 3 types, request, response, and error are generic, since it's protocol agnostic. They could be HTTP, gRPC, Thrift, Mux, MySQL, Redis, anything that answers a request with a response asynchronously. - A collection of generic "combinators". Like `filter`, or `zip` on iterators. Again, things useful in many protocols. Like applying a timeout to every call, or logging, or load balancing. Or they could be more specific, such as in your app, a service that inserts an HTTP header to every response, but not otherwise caring what goes in or out. Those are a level above async IO, which Tokio is dealing with.
When Tokio was originally released, it was a blend between Tokio today and Tower. Since then, Tokio has been focusing entirely on being a runtime. It provides: Sockets Timers A scheduler Utilities for working with data at the byte level. Basically lower level stuff. Tower is focused on application level stuff. Specicislly for request / response level stuff So Tower will provide things like a web framework, grpc client and server, utilities around request response exchanges (retry, reconnect, load balance, etc If you are familiar with the java world, Tokio is like Netty and Tower is like finagle. 
Goodness, am I so old to remember marquee all over the web...?
There are other ways to reduce the size of the binary as well, like `-Z optimise-level=s` which optimises for binary size and `-Z lto` which does link time optimisations. If you let the binary be dynamically linked instead of statically, the binary size should go down as well. Finally, something that (IMO rustc should do by default) is symbol stripping.
1994, Gosford High School, Australia. Teacher, after complaining he just networked 20 Microsoft NT4 computers without the $10,000 in training he deserved told us to make a webpage. The manual had h1, blink and marquee. It was beautiful.
Taking bactrace is a slow operation, so you may need to disable it by default.
Oh that's interesting because as a JS dev I expect the exact opposite. I'm on m'y phone now, but I'm pretty sure it starts doing work before you await it.
Oh that's interesting because as a JS dev I expect the exact opposite. I'm on m'y phone now, but I'm pretty sure it starts doing work before you await it.
Well RocksDB has to read into some kind of buffer (it can't return a reference to its internal buffers a la LMDB, as far as I'm aware), so in theory that buffer could be a `Bytes` instead of a `Vec&lt;u8&gt;` or whatever it returns now.
`block_on` has very different semantics from `await!`: the former blocks your thread, and (IIRC) can panic if you are already in a futures context.
Unfortunately, my distro's package manager, by no coincidence, happens to be my favourite build tool. I've personally defined a package for xargo just to have it more conveniently in my path when using it. That said, it's reliance on my home directory has made we considered bypassing it entirely and defining it's functionality completely within the package manager. There's also the fact that I can't just install libraries so rust packages can link to them. I *have* to write a build script specifying the native dependencies.
This seems to be counterproductive. If you want people to experiment with the changes they need their dependencies using futures 0.2. Otherwise any experimentation would only be possible for completely standalone things and not even on top of tokio or hyper, and that would limit the amount of feedback you get a lot. Especially with regards to usability.
 (async () =&gt; { let asyncSleep = (seconds) =&gt; new Promise(resolve =&gt; setTimeout(resolve, seconds)); let f = async () =&gt; { console.log('start of f'); await asyncSleep(1); console.log('end of f'); }; console.log('running f'); let promise = f(); console.log('awaiting f'); await f; console.log('done'); })(); // output: // running f // start of f // awaiting f // done // end of f
I'd like to understand the relation between the `proc_macro` crate, which seems to be "sort of" a part of rust, and the external `proc_macro2`, `quote` and `syn` crates and what the "correct" way for creating a procedural macro would be on stable. Basically, my impression is that basically all of `proc_macro` is unstable, and you must use the other crates to use procedural macros in any meaningful way (for example, the quote! macro in proc_macro is unstable and you must use the one from quote).
Cool. A little write up perhaps?
My [bitfiled](https://github.com/dzamlo/rust-bitfield) crate do pretty much the same thing, but with a different syntax and more functionalities.
I know and I just copy-pasted rs files from target directory so did not used build.rs file. For me using protoc directly is much easier because you just need to compile protobuf only once without distribute proto files.
Hah I like how you used the IpV4 header as well in your example
docs.rs doesn't like building my crate so I published the docs on https://trangar.github.io/doc/bitrange/index.html I added the repo and docs link, thanks!
I think there is something wrong with your concurrent version... the ordering at your compare_exchange is too weak. See https://github.com/jonathanstrong/incr/issues/1
Not at the moment, but I will try to write it up today. In short: - simple Bézier paths support (no arcs and stuff) - text rendering - font family resolving (aka `'Arial', monospace`) - text geometry query: bbox, underline height, etc. - composition modes (currently only Clear and DestinationOut) - fill with pattern/texture - jpeg/png loading - extended stroke support (dasharray, etc.)
And heap-allocation-free serialization! I've said it multiple times that quick-protobuf is the only sane protobuf rust library. It does not force me to take data out of internal data structures and clone them into a serialization structure just so that data can be read and copied out to some send buffer. APIs almost never match internal data structures. prost and protobuf libraries only look good in examples.
Concerning concurrency primitives, when to choose a muted over a channel and vice versa? Is the decision an arbitrary one? Thanks!
I want to write a graphical application that can display log information in various ways that are configurable at runtime. I am imagining a window with horizontal and vertical splits where each shows a text log or a chart. I am really liking conrod so far but I am not sure if it is suitable for this kind of application. I am unsure about the split panes! Also, I need good chart support. Which of the GUI libraries would you recommend?
Can Future's Stream trait be used for pub/sub, or is it meant for something else?
Because you're not spawning an executor. You're submitting work to the executor.
Perfect, I’ll keep that in mind. Thank you so much! :D
So it's like [`plug`](https://hexdocs.pm/plug/readme.html) for elixir, but tied to the HTTP protocol? How will `tower-web` and `hyper` will interact together? Will the latter be built upon the former, would it be possible to write a `tower-web` service and use it with `hyper`, or will it be a different thing?
I've been using this crate for a while internally, and am fairly certain that it does what it purports to do decently well. I found I wanted to be able to intern regular slices as well as string slices, so I thought I'd generify this a little and share it around. The basic usage idea is that you have e.g. your `Lexer&lt;'a&gt;` struct which takes a borrowed `&amp;'a Interner&lt;str&gt;`. Then your lexer can easily intern its tokens over `'a` so that the lifetime marsh of string parsing is a little easier to wade through. And since the `Interner` uses a `Mutex` internally, it can be reused across all of your steps that want interning easily, even when multi-threaded. The other useage that triggered this generification for publish is interning slices of `char`. In my toy language, every symbol is passed through as an individual `char` in the lexer stage so I can handle the `&gt;&gt;` problem. At the parser stage, operators are grouped as a sequence of `char` with no whitespace. But creating a string to intern would require a heap allocation every time (or some tricky and unsafeish things to get a stack str). Now I can have an interner that stores `Box&lt;[char]&gt;` and more directly represent the operator as what it is; a sequence of characters. Barring comments or running into problems using it within the next week or so, I plan to publish this as version 1.0.
It's one possibility, indeed.
You don't need to transmute the slice itself, you only need a pointer conversion. I much prefer `std::slice::from_raw_parts(some_slice.as_ptr() as *const u5, some_slice.len())`. That way you have a pointer conversion rather than a slice transmutation, and I think it is fine to cast a pointer to `u8` into a pointer to `u5` in this case. I believe that a tuple struct (`u5`) that has only one element (`u8`) will always have the same size and alignment as the element itself, so this should work. I couldn't find a link to any such guarantee however. The slice transmutation is making more assumptions about the representation of slices themselves, and you don't need that.
LOL, 20 seconds ago I wrote `futures = "0.1"` into my `Cargo.toml`
Wow, this looks like an awesome library! &gt; Map entries will have a predictable order based on the hasher being used. Unless otherwise specified, all maps will share an instance of the default RandomState hasher, which will produce consistent hashes for the duration of its lifetime, but not between restarts of your program. There were some concerns about the standard `HashMap` being susceptible to DOS by figuring out the underlying hasher state (or an approximation of it) by inspecting the iteration order and spamming it with values that would create a large number of collisions. This was "fixed" by reseeding the hasher each time the map grows, which is not possible here. Does this mean that `im`'s `HashMap` is vulnerable to such an attack? Would it make sense/be possible to make the iteration order a factor of the modifications done on the map (insertions/removals), as in bluss' [`indexmap`](https://github.com/bluss/indexmap)?
Formatting is now fixed, but you're right: the very point of having a "suspend" primitive is so that libraries like `relm` don't need to be aware of coroutines. I'll ping you with concrete usage examples when I have an implementation of suspendable futures.
With the high level libraries, relm is nice, but requires a different way of thinking that most people are used to, azul is WIP, but has the potential.
No I mean, how I interpreted that is that if they do: ``` async a() { s1(); const promiseb = b(); s3(); const res = await promiseb; } async b() { s2(); } ``` they expect the statements to run in order s1, s2, s3. This is not how it would work in JS, which is why it boggles me. Also kudos to the twelve downvoters who thought my confusion was really bad.
Thank you very much, the `from_raw_parts` way seems much nicer. Unfortunately as long as I don't have a guaranteed memory layout for `u5` and `u8` I can't do any of these conversions. Since what I'm developing is rather security critical and doesn't need the performance I will stick with the "allocate a new `Vec&lt;u5&gt;`" solution for now. When `repr(transparent)` gets stabilized I will have a look at this again.
I know, but TLS is magic, and global staics are magic, so, it might mean slightly worse ergonomics, but I can't be happier without all that nonsense. The changes to Executor are very helpful imo. People are complaining their 'magic' libraries with magic global objects are harder to implement, but frankly, I really don't care. I'll take explicit and obvious anyday over ergonomic magic. 
What I interpreted the discussion above as, was that the called function would start running code until its first await statement, even though the calling function had not yet awaited it. See [my other comment](https://www.reddit.com/r/rust/comments/8aaywk/async_await_in_rust_a_full_proposal/dwyo63q/) for a better description of what I thought they meant. I probably misunderstood them.
Based on the comments above you probably shouldn’t change that until 0.3 gets released.
&gt; Also kudos to the twelve downvoters who thought my confusion was really bad. It's more of the way you expressed it; it sounds like you're shit-talking Dart/Dart programmers.
&gt;If any other code can possibly execute between when your async function is first called and when its body begins to execute, then it's possible for race conditions to sneak in if you expect to be able to synchronous work at the top of the function. ...but that looks like such a strange thing to assume?
Guess that's understandable then. Sorry about that.
I posted elsewhere in this thread, but... it appears it works exactly like that? https://www.reddit.com/r/rust/comments/8aaywk/async_await_in_rust_a_full_proposal/dwygp9f/ Here, I even adapted your example: { a = async () =&gt; { console.log('s1'); const promiseb = b(); console.log('s3'); const res = await promiseb; }; b = async () =&gt; { console.log('s2'); }; a(); } // output: // s1 // s2 // s3 Now, I don't know whether that's actually guaranteed in any way, but at least it's what chrome devtools does for me.
OCaml had issues with composing such "eager" futures, I think it was in the Lwt library... turns out that it's not a natural model at all, at least algebraically.
I just tested it and it seems I was indeed wrong! I thought it a "thread" would only yield to other threads once they finished running, or when they call await. I got this impression from the following paragraph in the documentation above: &gt; Each message is processed completely before any other message is processed. This offers some nice properties when reasoning about your program, including the fact that whenever a function runs, it cannot be pre-empted and will run entirely before any other code runs (and can modify data the function manipulates). So it seems like calling an async function (and NOT awaiting it) may still count that function's evaluation as being within the current message. I previously interpreted any non-awaiting call to an async function to be adding a message to the queue, but apparently this is not the case. I learned today, thanks for your insistence in correcting me. Here's the code I used to disprove my misconception: async function a() { s1(); const promiseb = b(); s3(); const res = await promiseb; } async function b() { return s2(); } function s1() { console.log('in 1'); } function s2() { console.log('in 2'); } function s3() { console.log('in 3'); return 'hello'; } a(); 
It happens!
Yeah, I'll try to be more conscious of it in the future.
Yes! I just [disproved my misconception](https://www.reddit.com/r/rust/comments/8aaywk/async_await_in_rust_a_full_proposal/dwyozwm/) myself elsewhere in the thread. I also explain what caused my misconception. Kinda weird part of the MDN docs, but I guess they want to give an overview, not an in depth explanation. I glossed over others' examples using setTimeout since I think those are unnecessarily convoluted, involving time and all. Doesn't feel like they'll necessarily be deterministic. Thanks for helping out!
What does C++ use ?
This isn't ideal. The good news is that your code will work in the future after non-lexical lifetimes get implemented and stabilized. It [already works](https://godbolt.org/g/kyw3cf) with the nighly compiler.
Can’t one just use an associated type for the future and be done with it ?
Can’t one just use an associated type for the future and be done with it ?
Ah, pretty cool that it works better with non-lexical lifetimes. I can really see the benefit of it now.
This also works on stable: if vector.iter_mut().find(|o| o.num == 3).map(|o| o.num = 99).is_none() { vector.push(other_object); }
Now that is pretty cool! Would you be able to explain why this works and the other one doesn't? On the face of it, it looks just like a match statement would?
I have been thinking about that, and it might be a better idea to do the following: - store the module's base address at the beginning of the file - walk back the stack a few time to find the allocation's origin (and maybe above, to avoid pointing only to `Vec` internal methods and such - have a post processing tool that reads the file, gets symbols or debugging info from the binary and output an annotated file 
Thanks
The way I understand it is: here the borrowing is always in a temporary; `iter_mut` borrows vector mutably, then `find` takes that borrow and still borrows `vector` mutably, then `map` takes that borrow and still borrows `vector` mutably, then `is_none` takes that borrow but does not need to borrow anything. In the original code, there is something like: match vector.iter_mut().find(|o| o.num == 3) { Some(o) =&gt; o.num = 99, None =&gt; vector.push(other_object), } This requires non-lexical lifetimes, as inside the `None` branch, the `Option&lt;&amp;mut Object&gt;` is still in scope so it is still borrowing `vector`, meaning that `push` cannot borrow `vector` mutably. Non-lexical lifetimes can see that in the `None` branch, the borrow is never going to be used again, so it frees `vector` to be borrowed mutably. As an aside, in *test2.rs* there are some `mut` and `&amp;` that should not be there. This is what is really required: let found_object = vector.iter_mut().find(|o| o.num == 123); match found_object { Some(o) =&gt; o.num = 99, ... This is because `o` is of type `&amp;mut Object`, you do not want to mutate the reference itself. In fact, that code does not compile in stable, but it does compile in beta because in 1.26.0, [pattern matching on references are now automatically dereferenced](https://github.com/rust-lang/rust/pull/49394).
What happens when a future that hasn’t been polled on is dropped? For example in the first println example of the RFC, what happens if one does not call futures::block_on? The RFC does not say anything about Drop :/
Another alternative explanation here. The equivalent code that works with match is actually this: let needs_push = match vector.iter_mut().find(|o| o.num == 123) { Some(o) =&gt; { o.num = 99; false } None =&gt; true, }; if needs_push { vector.push(other_object); } This works, as the borrowing temporaries, which are needed inside the `match` so that `vector` can be mutated in the `Some` branch, are out of scope in the `if` statement, so the borrows have ended.
Thats a great explanation and makes sense, thanks for taking the time to write it. I can see while inside the is_none() conditional branch the vector is not being borrowed anymore. I was using nightly but without NLL so that is probably why the second example was compiling.
You could argue the same thing about logging, that without a global logger (aka the log crate) you can’t implement logging. ...but I dont buy it. I feel like if people want to *opt in* to magic like that, sure... but it shouldn’t be *mandatory*, for everyone, for a few specific use cases. /shrug 
In my understanding, this was about including the functionality of `rustup target` into `cargo`. LLVM already provides cross-compilers, and the Rust toolchain needs still a linker anyway. So what `rustup target` does is download a pre-compiled version of `std` for the target you want to install. Building `std` for your project is useful in embedded scenarios, where the pre-compiled packages are not available, and this is what `xargo` does. But it also has other benefits, like allowing you [to get smaller binaries](https://jamesmunns.com/update/2018/04/01/tinyrocket.html). So if you think about it, it's not that strange for `cargo` to be able to build `std`, like it does for the other crates. So if I understood things correctly, this is the thought process behind the upcoming changes. 
Reading the article, unless I'm missing something, it seems like it's not just `rustup target` but the entireity of `rustup` which is being considered for engulfment.
Since the future compiles to a state machine, then that state machine gets dropped. Anything that it owns via either things captured from its environment or things defined within it will therefore also be dropped. The RFC doesn't mention it because it doesn't differ semantically from dropping a closure that's never called, or really from dropping any other type of variable.
Because a struct initialiser expects a *path*, not an *expression*. Even if the two look exactly the same, the compiler cares about the difference. Rust macros operate at the syntactic level, not the lexical level. Unfortunately, for reasons I've never bothered to dig through the compiler to ascertain, this particular construction doesn't work even if you *do* give it a path. So that's a bit naff. So, you've got two choices here: you can accept a single identifier (and require that whatever `struct` you're referring to is in scope), *or* you can accept a raw token sequence. To whit: use std::rc::Rc; mod m { pub struct S {} } use m::S; macro_rules! create_rc { (ident: $x:ident) =&gt; (Rc::new($x{})); (tokens: $($x:tt)*) =&gt; (Rc::new($($x)*{})); } fn main() { let _a = create_rc!(ident: S); let _b = create_rc!(tokens: m::S); } 
Yes, but `impl Trait` doesn't work yet with that.
I'm new to concurrent programming in rust and I'm a bit in the dark. I'd like to spawn a bunch of jobs that run a for loop, which either completes naturally, or ends gracefully after receiving a signal from the user. Something like this running in several threads (?) fn runner(foo: Foo) { for i in 0..100 { foo.update(); if recvd_abort { // How to get this? break; } } foo.exit_gracefully(); } How do I pass a signal like that through a thread? Is that even the right way to do this? Seems like a common pattern. I'm hoping someone could point me toward a crate or relevant documentation. Thanks!
http://pacman.wiki ? why not redirect to https://wiki.archlinux.org/index.php/Pacman until you have a ready site
Hello everyone! Let's say I have an iterable, for the sake of the example let's consider the iterator for ["a", "b", "c", "d", "e", "f"]. What functional style function would allow me to output an iterator over ["ab", "cde", "f"], or ["a", "bc", "de", "f"] depending on logic provided by a closure? In a more abstract point of view, how could I process together multiple entries of an iterator and output an iterator over those results? I want to use something like this to merge words into sentences from a split. Thanks in advance!
Yes exactly, the files are at a given node and should not be send around. Part of the "scheduling" is to figure out which files are where and to split the list of all available files into chunks which can be locally processed at a particular site. I guess that part needs to be hand rolled in any case, but it is interesting to hear that Rain might be a fit anyways!
What exactly does this enable?
Yep, it is totally woth the change imho. Making vs code to work was a hacky nightmare for me too.
Looks neat! Will you always need the standalone cloudflared daemon? I'm trying to keep my application super easy to deploy: one binary does _everything_, and all state in its embedded database on flash or its blob directory on disk. So I'd love if there were just a rust crate that you can use within your app to set it up and to establish the connection each time (giving it a hook to store the credentials). (btw, is the only credential file called `cert.pem`? Isn't there a private key in there as well as the certificate? I can see that naming leading to a cryptographically unfortunate mistaken disclosure.) How long does the certificate for the Pi&lt;-&gt;Cloudflare leg last? Does it live ~forever? Or does it autorefresh like letsencrypt certs? What can your local webserver tell about the client connecting to Cloudflare (and how, like a special header)? remote IP address? TLS channel ID? IIUC, best security practice these days is to bind a session cookie to a particular channel ID, and of course at least log the remote IP address.
/r/playrust
Why? Those two approaches work.
Welcome to Reddit. Before posting to a subreddit/forum/community, you should check to see what that subreddit is for. This includes reading the sidebar and the rules. You should also pay attention to warnings that you're posting to the wrong subreddit. Check /r/playrust.
JetBrains IDEs will expand macros (as opposed to being an opaque expression) and be able to parse, etc the resulting code. At least that's my understanding.
So what do you use instead of logging? Also even if you don’t use logging you still use APIs with localized implied contexts. Rust’s test framework uses an internal thred local api to handle print capturing as a simple example. The only sane way to handle deadlines/timeouts is to establish it for a block of code across calls. Allocators are often using thread bound arenas for better efficiency. i18n/l10n often is implemented with implied contexts etc. You can’t pretend this reality away. 
What happens if the expression panics? The vector must allocate space for the object before evaluating the expression, so that it can be put there in place, but the expression can panic :/
Coming back from travel with only intermittent connectivity. I wrote a [blog post](https://llogiq.github.io/2018/04/03/corners.html) in the meantime and have resumed working on [mutagen](https://github.com/llogiq/mutagen), [flamer](https://github.com/llogiq/flamer) and [overflower](https://github.com/llogiq/overflower), all of which received a rustup and should now work again. I just need to bump versions.
Not even Pascal :( It was always Pascal or C in these contests
Python might just be too slow
Perhaps it could, but it doesn't now, and given that is a wrapper around a C++ library I suspect using bytes would be hard. And I might end up using lmdb instead. Right now my app uses sqlite, but it's a little slow, and I haven't decided my desired final state yet. [issue](https://github.com/scottlamb/moonfire-nvr/issues/44)
[removed]
You likely wanted /r/playrust. Pro-tip: Next time before posting, look at the subreddit's sidebar.
I am hoping you will find reposting this in /r/playrust agreeable. Pro-tip: next time before posting, look at the subreddit's sidebar.
You likely wanted /r/playrust. Pro-tip: next time before posting in a subreddit, look at the sidebar.
You can use channels provided by `std::sync::mpsc` to send signals. Something like this: [playground](https://play.rust-lang.org/?gist=f4be5c23e0d8bb3bcd56973cb4a2233e&amp;version=stable).
You should file a bug.
&gt;keeps syntax and sugar to a minimum I disagree - I think Rust uses special syntactic sugar very heavy-handedly. It's largely for ergonomics, but there's already tons of magic hidden behind syntactic sugar.
it says in the article that havin impl Future&lt;&gt; as a return type is bad tho
It happens especially if you have a big project /source file - I have completions that take 40+ seconds to kick in and the whole ide (yes, the whole IntelliJ window) freezing for over a minute as well
Cargo statically links dependencies into the binary unless told not to explicitly.
Rust statically links all the (Rust) libraries into your binary, so a single binary will generally work on all computers.
I used to have this too. Updating the plugin/reimporting the project helped.
Applied it using the website. Hoping to get a reply .
Hmm, I do think this is a bug because you can construct `struct S;` and `struct S(i32);` using similar macros. 
You might be able to use [`Itertools::group_by`](https://docs.rs/itertools/0.7.8/itertools/trait.Itertools.html#method.group_by). 
To add to whats already said, the only area you might run into problems is with "`-sys`" crates. These wrap non-Rust libraries. My hope is that we're standardizing on those being statically linked by default ([example](https://github.com/rust-onig/rust-onig#linking)) so this shouldn't be too much of a problem.
The cooperation is not the relevant information here. Knowing how much time you have left to execute your operation does.
Rls is still so bad. Is there anything that runs rust check and shows errors inline in vscode like this paper talks about?
You'll probably get more takers over in r/playrust
With a rather beefy gaming laptop I'm getting a very stable 60/61 fps on FireFox. Though the movement speed is annoyingly slow for trying to move around, but also I'm just not enough used to [WASD ZXEC] movement.
You would probably want to capture the stack with some probability per-byte (rather than per-allocation).
uBlock Origin log seems to suggest that two filters are being hit: - Static filter `||fls-na.amazon.com^` from EasyPrivacy (_many_ times) - Static filter `/.*(\/proxy|\.wasm|\.wsm|\.wa)$/$xmlhttprequest,domain=github.io|rawgit.com|reactor.cc|sickrage.ca|streamplay.to|tubetitties.com|vidfile.net` from EasyPrivacy It looks like the second is blocking `*.wasm` from GitHub.
That's a really good point. Thanks for mentioning this; I feel a lot of the other discussion wasn't getting into enough detail on why exactly this would be problematic.
Yes, I also expect generating values in a range to be the most common use. I spent quite some effort into speeding up the range code. I think the docs do not entrely reflect that recent performance improvements for single-call use. The `Range` trait now has a `sample_single` method, which gets used by `Rng::gen_range` ([documentation](https://rust-lang-nursery.github.io/rand/rand/distributions/range/struct.Range.html)). What can be something to explore is fast but slightly biased ranges. Random sampling from an array is an area that in my opinion is something to work on for rand 0.6. We already have the `seq` module, but it is not as flexible as I like. If you follow the 'sampling algorithms' link, it could surely use your input. Especially for sampling with non-uniform probabilities it is hard to come up with a nice API (I do still have a bunch of unposted notes, but that issue is a start).
I just started learning Rust. As an exercise I'm trying to implement an old Java school project. But I'm not sure how to solve this. I have simplified the code to a small example: #[derive(Eq, PartialEq, Debug)] struct Foo { x: i64, y: i64, } impl Foo { fn move_foo(&amp;mut self, list: &amp;Vec&lt;Foo&gt;) -&gt; () { if !list.contains(&amp;Foo { x: self.x + 1, y: self.y + 1 }) { self.x += 1; self.y += 1; } } } fn main() { let mut foos: Vec&lt;Foo&gt; = Vec::new(); foos.push(Foo { x: 3, y: 5 }); foos.push(Foo { x: 4, y: 6 }); foos.iter_mut().for_each(|f| f.move_foo(&amp;foos)); foos.iter().for_each(|f| println!("{:?}",f)); } I know that there's no way for this to compile since I'm trying to look into the same vector that I'm mutating. What would be an idiomatic way in Rust to achieve what I'm trying to do. When calling the method `move_foo` it should know if there are any other foos where it's trying to go. I'm looking for a general solution to this type of problem since this is just a boiled down toy example.
This is exactly what I needed! Too bad it's in an external crate but it's no big deal. Thank you very much!
I'm really torn on the issue. On the one hand this was a major source of confusion for me when trying to learn Tokio. But on the other hand I do see the ergonomic benefits. Overall I think it would be good if Rust had some general convention for passing context information down the call stack, and if Tokio used that convention. That's not a small thing though, there's a lot of tradeoffs to be made regarding encapsulation (what modules can get at what context information) and scoping (making sure context propagation happens exactly when needed / expected). Doing an ad-hoc thing just for Tokio would be simpler but still feels dirty to me somehow. 
It's how C# and Javascript both work, so it sounds like a reasonable assumption to me.
RLS is actually very good at inline errors. It is indeed not that good at code completion though. 
yeah, after I got it set up, it actually felt snappier than intellij, and maybe it is easier to install it now than it was a in january. I really wish somehow the developers of the vs code extension could make the installation experience more user friendly, or just make a better documentation, of the installation steps.
It's pretty bad in VS Code, but Atom's support for RLS is currently much, much better.
&gt; the QT framework can (not only due to licensing details) not be statically Why can you not link QT statically given that you acquire the commercial license?
First off, I'd like to see more work along this line. I'm glad the authors took the time to do some science. On the other hand, I don't think this one is peer reviewed (or would pass peer review). There are plenty of typos including spelling errors which gives the impression the authors didn't even run spellcheck. The references seem really weak. I know for certain there were a lot of human studies in the 80s measuring programmers and none of that work was cited (and admittedly it can be hard to find these days because much of it has not be digitized). I assume there is more recently work but it's not an area I've kept up on. So, I like what the authors are trying to accomplish, but if I'm being honest this paper is pretty weak in the scientific sense.
Dunno about VsCode but Sublime Text does it even without RLS, with the Rust-Enhanced package. I'm using that for all my Rust coding. VsCode seems to have higher input latency..
Not quite a write-up, but I've updated my original post with a link to a Github repo containing the code (built for Windows).
You can, of course, do this. I did not expect OP to pay for a license. But there may be problems with updating, on Linux you can use the system-built-in QT versions, etc. Might not be the best idea to statically link it.
I tried that, but using `z` gave me a slightly larger executable. However, since there's so little actual functionality in there it's probably fairer to try that once there's some more code in there to size-optimize.
I am not good enough with iterators to find a concise way to do it, but I realized that: When you call `move_foo` on `&amp;foos`, do you mean that the `&amp;foos` is what `foos` started as, e.g. let temp = foos.clone(); //derive Clone to be able to do this foos.iter_mut().for_each(|f| f.move_foo(&amp;temp)); or do you want `&amp;foos` to change with each .next()? e.g. for i in 0..foos.len() { if !foos.contains(&amp;Foo { x: foos[i].x + 1, y: foos[i].y + 1, }) { foos[i].x += 1; foos[i].y += 1; } } Even if you do not intend for the second example, it should be clear that a `.clone()` is unavoidable.
Just curious, would any paper with [pie charts](https://www.perceptualedge.com/articles/visual_business_intelligence/save_the_pies_for_dessert.pdf) even pass peer review? (Not saying every paper has to be scientific though.)
&gt; as well as the missing "" in the "p1.add(p2)" line. What's missing is missing.
&gt; All participants were at least familiar with one of C or C++ and none of the participants had ever programmed using the Rust programming language. Then why doesn't the Rust book show up in Figure 5? It kinda seems like they just tried to learn from the examples and then googled for errors?
Prost doesn’t require allocations to encode messages.
Subscribe to issues here https://github.com/rust-lang-nursery/rust-wasm and come hang out in #rust-wasm on irc
This would have been very interesting, regardless of quality, if: 1. The participants were actually *experienced*, preferably greybeards (no negative connotations intended). 2. The participants were followed until they've done something non-trivial and useful with Rust (dealing with the ecosystem, libraries, distribution, infrastructure, etc).
Maybe you need to do it because you need to define special functions for your needs but there is the [uX](https://crates.io/crates/ux) crate if you need small unsigned and signed integers. I could never find a crate for arbitrary precision integers different from `num-bigint` until weeks later I changed keywords and scrolled far enough down the crates.io list to find `apint` which was what I had been missing so I thought you might have not seen `uX`.
`partial_min` was removed about 3 years ago in Rust 1.3.
I think you're misunderstanding my argument. My original comment was not about the entire special handling for uninitialized pointers (the whole `Placement` thing). I understand why this exists and why you need some kind of transactional interaction. I was only commenting about the process of initialization, where you want general functions of the form `(args) -&gt; T` to act like functions of the form `(*mut T, args) -&gt; ()`.
The way I understand it, the only thing that will be *really* needed by Cargo is some way to discover where to find the source code for the standard library (so that it can compile it when a non-standard configuration or target is requested). When rustup is used, rustup would download that source code when necessary. When rustup is not used, I imagine that there could be a system-wide configuration file that says where to find the source.
What's the practical difference between `&lt;Type&lt;'a, T&gt; as Deref&lt;Target=T&gt;&gt;::deref(&amp;self) -&gt; &amp;T` and `&lt;Type&lt;'a, T&gt; as Deref&lt;Target=&amp;'a T&gt;&gt;::deref(&amp;self) -&gt; &amp;&amp;'a T`? Can I treat the second as a superset of the first in functionality? I have an `Interned&lt;'a, T&gt;(&amp;'a T)` that I want to act as a smart pointer doing `ptr::eq` instead of `T::eq`, but I'd also like to easily treat it as if it were `&amp;'a T` so I can give out that `&amp;'a T` to people who want it. I currently have `Interned&lt;'a, T&gt; : Deref&lt;Target=T&gt;` and `Interned::&lt;'a, T&gt;::get(this: &amp;Self) -&gt; &amp;'a T`, but just being able to use the interned symbol in a place expecting `&amp;'a T` would be very useful.
error[E0382]: use of moved Steam key: `M2BBI-EVJ2C-BJD23` --&gt; r/rust:1:1
Thanks for the hint. I actually didn't even search for a crate like that, partly because I couldn't imagine that it exists. It's interesting to bee proven wrong on this assumption. Unfortunately my main problem (converting slices) isn't solved by it. And for the [project I'm using the u5 type in](https://github.com/rust-bitcoin/rust-bech32/pull/17) we try to avoid trivial dependencies for security reasons.
I am trying to use generic Traits to avoid duplicating code. I have the following working, but I'd like to do the same on a generic method. fn main() { let v : Vec&lt;&amp;str&gt; = vec!["a man", "a plan", "a canal", "panama"]; let vr : Vec&lt;String&gt; = v.iter() .rev() .map(|x| x.chars().rev().collect::&lt;String&gt;() ).collect(); println!("{:?}", to_nospaces(&amp;v)); println!("{:?}", to_nospaces(&amp;vr)); } fn to_nospaces&lt;T: ToString&gt;(v: &amp;Vec&lt;T&gt;) -&gt; String { v.iter().fold(String::new(), |a, b| a + &amp;b.to_string().replace(" ", "")) } Here is the same code working with different Trait impls for String and str. How do I make it generic for Vec&lt;ToString&gt; like I did above? Is that possible? I keep getting compiler errors. fn main() { let v : Vec&lt;&amp;str&gt; = vec!["a man", "a plan", "a canal", "panama"]; let vr : Vec&lt;String&gt; = v.iter() .rev() .map(|x| x.chars().rev().collect::&lt;String&gt;() ).collect(); println!("{:?}", v.method()); println!("{:?}", vr.method()); } trait Foo { fn method(&amp;self) -&gt; String; } impl Foo for Vec&lt;String&gt; { fn method(&amp;self) -&gt; String { self.iter().fold(String::new(), |a, b| a + &amp;b.to_string().replace(" ", "")) } } impl&lt;'a&gt; Foo for Vec&lt;&amp;'a str&gt; { fn method(&amp;self) -&gt; String { self.iter().fold(String::new(), |a, b| a + &amp;b.to_string().replace(" ", "")) } }
Yeah, I have the same question as you. From my elixir background I would naively expect async/await to spawn green threads to do work concurrently, but maybe that's just elixir using the terms oddly. For example to download two pages in parallel: t1 = Task.async(fn -&gt; download_url(a) end) t2 = Task.async(fn -&gt; download_url(b) end) # both downloads are now occurring in separate green threads # now we wait for each to finish: r1 = Task.await(t1) r2 = Task.await(t2) # total time elapsed is approx the longer of the two downloads This is probably just one of the many things my higher level language experience doesn't exactly translate to a lower level one like rust. How would you do this type of thing with the new futures constructs?
[boost::asio uses post](https://www.boost.org/doc/libs/1_66_0/doc/html/boost_asio/reference/post.html) [seastar uses submit](https://github.com/scylladb/seastar/blob/master/core/reactor.hh#L268). Java [ExecutorService](https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ExecutorService.html#submit(java.util.concurrent.Callable%20) and Python3 [`concurrent.futures.Executor`](https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor.submit) both use submit.
I like Scala's expressiveness and type safetiness, so either a native Rust API would be welcome, or using Rain from Scala. (So Rain wouldn't have to reimplement the Scala native "paralell collections" library. At least I'm optimistic that it could work without that, but maybe the internals of the Spark executor are too Scala tied.)
Nice work, /u/IntrepidPig! I would love you forever if you added support for significant figures. ;P Usually, I want to calculate using the maximum feasible precision to minimise rounding errors, but track sig. figs throughout so I know how precise the answer really is. I haven't thought of a case yet where sig. figs couldn't be determined from the expression string and context. I haven't had more than a cursory glance at your code, so I'm not sure if this aligns with your library's goals.
Yeah, this feels like an even more hardcore version of figuring out which overridden method will run in a complex class hierarchy.
This. If I'm ever in a slowdown (which happens, I get it) I'll go to `File &gt; Invalidate Caches / Restart` and let it reindex on restarting. Fixes the few slowdowns I've had.
&gt; Hey I would like to ask if there is a more concise way to convert between primitive types? Nope. You'll either learn to live with it and reach transcendence, or go mad trying. The general reason is that implicit conversions cause problems too easily, so you have to be explicit. &gt; And is this a good way to write this function if I know that I will use it with u16s, or should I take them as i32s so I don't have to cast this many times? If it's meant to work with `u16`, take `u16`. Changing it to take `i32` will just push the casts out to whatever is calling the function.
I'm not sure what you're asking. Mutexes and channels are completely different things. One is for managing shared access to a value, the other is for sending messages.
It sounds like an *implementation detail* to me. If I see an async function, I prefer to understand it like a concurrent thread, even if the underlying virtual machine executes *a part of it* as a regular function.
This is great! I have a RPi (v2 IIRC) and am in the process of writing a web server based on Rust/Gotham. I also have dynamic DNS 100/40 line. But then again I also have a $4/month VPS that would be faster, and all things considered, easier to manage.
are you using the "correct" vs code plugin? there's two on the marketplace, one called "Rust" that is unofficial and pretty much abandoned, and another official plugin called "Rust (rls)" which actually works.
Well, assuming it checks `rustc --print sysroot` (= `/usr`), then I think the relative location of our rust-src package should already work for that: https://koji.fedoraproject.org/koji/rpminfo?rpmID=13587034
Ah. That explains a bit :) I hope you continue to explore this area of research.
you are primarily a JS dev but completely misunderstand its execution model? yikes.
I'll be very interested in such an implementation. That could even be useful for a coroutine-based async gio.
&gt; A "zero yield" in Rust is a total no-op given some amount of inlining. It means you have an extra entry point, which can mean an extra branch.
Check out /r/rust_gamedev.
/r/rust_gamedev is real. However, tooling is much weaker than e.g. Unity. With the tight time constraints of a 48 hour game jam, you could likely produce a better game with a more established engine.
Exactly, that's the challenge.
I didn't ask there because I thought people fresh to the idea would give less bias opinions.
It's not a concurrent thread at all, though. The entire point of async/await syntax is to take a *single* thread of execution and let it suspend instead of block. The only time concurrency comes into play is when you *explicitly* run two of them at once, just like normal functions and threads.
[removed]
I've been writing my own game in Rust as a side project. I have it going on my Mac using Piston. I'm currently trying to port it to Android. There are issues. First, what level graphics API do you want? I wanted something relatively high level, but only 2d. E.g: piston2d, ggez or sdl2-rs. (Draw lines and filled rects, load textures from JPG files, blit rectangles from the textures to the screen (with alpha blending). These higher level APIs generally depend upon lower level graphics APIs. E.g. gfx-rs, glium or OpenGL. Gfx-rs and glium in turn use OpenGL. Because everything depends upon OpenGL at the lowest level, you need the appropriate shim there. Something to handle OpenGL context. E.g. glutin or SDL2. And then you need window management. This is either winit or SDL2. Finally you need some sort of packaging. On the desktop you can just build a binary, but to get things going on Android, you need to put together an APK. For that I've been using cargo-apk. You'll note that SDL2 turns up at a number of layers there. It has well regarded solutions at a number of those layers, and handles more than just graphics. Unfortunately it is not pure rust and so doesn't play nicely with cargo-apk. :-( You need to cross-compile your own library, and then get cargo-apk to use that library in the appropriate places. I managed to get libsdl2 cross-compiled for Android, but haven't yet succeeded in getting cargo-apk to build a working APK with those libraries. This also causes problems for anything that uses SDL2, at any level of abstraction (e.g. ggez currently, although this could change by swapping some shims lower in the ggez stack). I'm just about to try piston2d on gfx on glutin on winit, packaged with cargo-apk. Hopefully that combo will work... Sigh. 
Yeah, you got me there, I would indeed expect that to print hi.
Tried to compile vgraph, but ran into dependency issues
Sounds like a heck of a challenge. I say go for it! Making a top-quality game isn't the point of a game jam - the point is to experiment, try new things and come up with new ideas that you can then take and refine later. Maybe using Rust will work well for you, maybe it won't. Either way, you will have learned something. Practically speaking, you're going to have to spend more time coding than you would if you were using Unity or some other established gamedev tools. That's going to limit how much time you can spend on other aspects of your game such as the art. Use that limitation to drive your creativity! There are lots of games that don't require polished art, like puzzle games. Or, to take a different approach, maybe you could code your art - define your art assets programmatically somehow. Take the opportunity to learn about shaders or procedural generation, maybe. Or make a game about code - there are any number of existing puzzle games like that. If you wanted to go really meta, maybe even make a game where the player needs to write Rust code and the game evaluates it with MIRI or something like that. Take chances, make mistakes, get messy!
Ooh yeah sorry that project's way not ready for use anywhere other than my own system right now. I depend on `vrender` locally because changes with the two are often together. Now that this projects is done though, I'll be spending more time working on `vgraph` and hopefully have a working demo soon.
Looks great! Because I am not in the loop, is there a tl;dr of how Sentry uses Rust?
From what I understand now I believe that it was chosen to not do this so that how and where the execution of the futures happens is up to the programmer. It is the Rust ethos of explicity over implicity. 
They've posted about it a couple of times: https://blog.sentry.io/2016/10/19/fixing-python-performance-with-rust.html https://blog.sentry.io/2017/11/14/evolving-our-rust-with-milksnake and have a few public repos (stack trace symbolication, a cli for their api, proguard file handling): https://github.com/getsentry/symbolic https://github.com/getsentry/sentry-cli and a few other things it looks like: https://github.com/getsentry?utf8=%E2%9C%93&amp;q=&amp;type=&amp;language=rust
Trust me, I've tried it - Rust is the wrong tool for a game jam.
Agreed!
I want to try new things! 
I was looking for high level graphics api too. I won't be using android, yet ;). If you find anything let me know!
We could possible team up. That would be fun. 
It's just that I'm a little young, I feel like, for teaming up.
The term you're looking for is `newtype`. Take a look at [Rust Book 19.3](https://doc.rust-lang.org/book/second-edition/ch19-03-advanced-traits.html#the-newtype-pattern-to-implement-external-traits-on-external-types) and [19.4](https://doc.rust-lang.org/book/second-edition/ch19-04-advanced-types.html#using-the-newtype-pattern-for-type-safety-and-abstraction).
I have two things though that might annoy you. 1 - I have recently learned Rust, so I might have to reference several times. 2 - I might be a little to young for you, but I love game development!
I would gladly hit you up on Discord though!
\**starts having flashbacks to his own xml-based xml generation language; begins rocking back and forth in the fetal position*\*
protobuf has a serialization overhead. CapnProto or Flatbuffers are zero-copy, allowing computation to directly operate on `memcpy`'d data.
Prost structs need to own any String or Vec. 
Could the implemented task executor submit and return work from a 3rd party execution framework? 
Then by all means, give it a shot! 
I definitely will!
Kinda expected that. :)
If you use [shrinkwraprs](https://crates.io/crates/shrinkwraprs) and [derive-more](https://crates.io/crates/derive_more), you can easily crate easy-to-use wrapper types. #[derive(Copy, Clone, Debug, Eq, PartialEq, Ord, PartialOrd, Hash)] #[derive(Shrinkwrap, ShrinkwrapMut)] #[derive(From, Into, Add, Mul, AddAssign, MulAssign)] struct Dollars(pub u32); Yes, that's a lot of derives piled on top of that type. But there's reason for it: you can mix and match as many or as few of them as you want, depending on how you want your type to behave. There's also some more derives offered by derive-more that I didn't include here. I don't think it's _formally_ guaranteed, but `Dollars` here is indeed a zero-cost abstraction, meaning that once compiled, it will be as if you were just manipulating a `u32` instead of the tuple struct, so it is the same as an opaque type alias, just stronger since you don't get anything from the wrapped type by default. 
Ah ok, thanks. There's a function that returns &amp;Arc&lt;Node&lt;A&gt;&gt; for an internal node struct Node. I assume it has the same limitation since the Arc is still an intermmediary? I'm enjoying this exercise, it's right at the edge of my rust understanding. Is it somehow possible to safely to distribute a cloned Arc within the context of the Index trait? impl&lt;'a, A&gt; Index&lt;usize&gt; for &amp;'a Vector&lt;A&gt; { type Output = Arc&lt;A&gt;; fn index(&amp;self, index: usize) -&gt; &amp;'a Arc&lt;A&gt; { self.get(index).expect("Index out of range").clone() } }
Biggest feature for me is that you get lints as you type, rather than only as the aftermath of a save.
More or less. I think there does end up being a question of how to move data payloads around efficiently from framework to framework though. And presumably the direct input and output is mostly metadata since the frameworks tend to focus more on exposing task/job submission and tracking APIs.
&gt; I assume it has the same limitation since the Arc is still an intermmediary? No, that's fine because you have a pointer to the `Arc`, not a value. &gt; Is it somehow possible to safely to distribute a cloned Arc within the context of the Index trait? No, because the cloned value is owned by the `index` code.
If you're not using Android, then I'd probably start with either sdl2-rs or ggez. SDL2 has plenty of non-rust documentation and the thin rust layer in sdl2-rs makes it nice without making the docs useless. Ggez is another 'batteries included' experience. Piston was designed to be more modular, but in my experience the documentation is not at the level that would make that level of modularity easy to use. If you were doing anything commercial, I think SDL2 is the only option with that level of maturity. Or use something platform specific. 
I'm no expert on rust gaming. I've just been fighting to get my simple game going. Android adds a level of difficulty...
Right now mostly processing and CLI but we’re now also starting our first rust service :)
You're being very 'my way or the highway' on this topic. I don't think we can find any kind of middle ground under the circumstances. All I can say is if we have *another* **breaking** api change in 0.3 for some poorly articulated edge case, that'd upset a lot of people. So of there really is a good reason to do that, you're going to have to work quite hard to explain why what you're doing *cannot* be implemented with *any possible* work around. ...but, I guess, the onus is on you to do that at this point.
*sets fire to every xml document he has ever had to deal with*. I hate xml so much. With a fiery burning passion. I originally thought XML was fine, made perfect sense even, then I had to deal with it in it's many abused and bastardised forms. I've had to write hundreds of parsers processors (no, not an exaggeration) for XML based interchange systems. i can not express the disgust and hate I have for XML now.
I strongly recommend adding an example snippet to your readme file, or even an entire examples directory. I checked out your project on GitHub and still have no idea what your input format il supposed to look like.
Why use XML instead of something like jsp or razor for your template files? Correct HTML isn't parsable with an XML parser anyway, so you'll have to mix two parsers; you might as well choose nicer syntax than XML. Unless you demand XHTML for your templates? Will your custom tags be namespaced properly?
Just implement XSLT?
If I got a dollar for every person who thinks that the `prefix:` is important when using namespaces, instead of the Uri that the namespace represents... They made it way too easy in c#'s `System.Xml.XmlElement`: no, you *never* want to look at `element.Name` (it's a trap!), look at `element.LocalName` and `element.NamespaceUri` instead!
Proper HTML will be rejected by an XML parser. E.g. you're not supposed to close your `&lt;br&gt;` tags.
I have recently integrated Sentry into a Java/Android project. I am using Sentry for two things: crash reports (unhandled exceptions) and custom "crash-like" errors I want to report to Sentry as well. As a lesson from experience I didn't go and start writing `Sentry.report(...)` all over the code, I wrapped it in a `ErrorReporter` type, which is dependency-injected where it's needed. Users can log in/out of the application. So for the "user scope" of the application I create a separate `ErrorReporter` with the user context set. The correct instance is injected by the system. However, the Java Sentry client's unhandled exceptions handler goes and fetches a global `Sentry` and uses that for crash reports. This somewhat thwarted the scheme. I haven't dug too deeply, but with the Rust client, is it possible to just pass a `sentry::Client` around without settings up any global state? Rust doesn't have unhandled exceptions so at least that problem is not present (though maybe the new `Termination` trait can be seen as that...).
pertheusual has the right answer. Let me just (pedantically) note that "distinct type aliases" is kind of an oxymoron. A type *alias* by definition is just an alias and cannot be a *distinct* type.
The Rust client as well as the new javascript ones are using a scope stack which is thread/domain local. You can push a client on there and then all calls use that one. You can also additionally not just push a client but also bind contextual data. You can also pass the client around without binding it but then you can no longer use the convenience APIs. 
I'm rewriting an old school project (written in C++) to Rust, which relied heavily on polymorphism, and I'm having trouble figuring out how it would fit together in Rust. Essentially, I have: * A TextureInfo class (name of a .png and it's size) * A Sprite class, which has a TextureInfo * Various classes such as Player and Enemy, deriving from Sprite * GraphicsEngine class, which has a function draw_world, which takes a vector of Sprites. How would one model this in Rust? I suppose the most straightforward way of doing it would be to have a trait Sprite, containing just a getter for a TextureInfo, then impl that trait for the Player- and Enemy-structs, but this feels wrong somehow. My understanding is that traits are supposed to define behavior, and this seems more like an indirect struct-definition. I'm really struggling to find an alternative to this though. Ideally, I would want something that matches this (in C#, as I'm more familiar with that) interface ISprite { TextureInfo TextureInfo {get; set;} } public class Player : ISprite { TextureInfo TextureInfo {get; set;} ... } public class Enemy : ISprite { TextureInfo TextureInfo {get; set;} ... } public class GraphicsEngine { public void DrawWorld(List&lt;ISprite&gt; sprites) { // Redraw world using the sprites } }
I think the intention here was to differentiate from the (all but useless) typedef in C.
How does typedef is useless? Especially in plain C.
[removed]
[removed]
And the original syntax is valid Rust, but `type Dollar = i32;` is an actual alias, not a newtype.
I switched to using Intellij too. If you look at the commits on the repos, the VSCode plugin is not very actively developed. A pity, because I would like to settle on one editor, and I miss the debugging support, but I much prefer Intellij at this point. 
&gt; I suppose the most straightforward way of doing it would be to have a trait Sprite, containing just a getter for a TextureInfo, then impl that trait for the Player- and Enemy-structs, but this feels wrong somehow. It might be in C#, but that *is* how you're generally meant to model things in Rust. Really, it just comes down to whether you want open polymorphism with traits, or closed polymorphism with enums. That said, the details will vary a lot; whether the `TextureInfo` accessor returns a borrowed pointer, or a cloned `Rc`; whether `draw_world` takes a `&amp;[&amp;Sprite]`, or `It: Iterator&lt;Item=&amp;Sprite&gt;`; *etc.*
This is awesome, thank you!
Posts from new accounts often get caught in the spam filter - message the moderators and we'll approve your posts. Sorry for the inconvenience!
For single member newtype structs, derive_deref may be enough: https://crates.io/crates/derive_deref Shrinkwrap is useful if you have multiple members and want to deref to one of them. 
What database engine are you using? Also I'm having trouble imagining how you can be in a situation where you can't use the std library but do have access to a SQL database. Is the database accessed over the network or something?
CLion if you can for debugging, else IDEA community works fine
How else can I use `max` with floats?
Tomorrow I'll start my interdisciplinary project at university, for which I'll need to write code for a Cortex-M device. This support coming out today is the best thing I could have hoped for!
Using [`f64::max`](https://doc.rust-lang.org/std/primitive.f64.html#method.max).
The compiler actually gives you the right answer. 25 | fn test&lt;T: Update&gt;(&amp;mut self, mut bar: T) { // &lt;-- this code does not work | -- help: consider adding an explicit lifetime bound `T: 'static`... In the general case of T, the compiler can not ensure that T will not have references other than `'static` ones, so you have to tell it specifically.
Is there a way I can avoid forcing the parameter to have a `'static` lifetime? Static lifetimes can be very limiting.
I just removed the `'static` from call_me's type parameter and it seems to work: fn call_me&lt;F: FnOnce(f64)&gt;(f: F) // no 'static here 
Fantastic!
You define `call_me` (`fn call_me&lt;F: FnOnce(f64) + 'static&gt;(f: F) { ... }`) as taking a parameter that has a `'static` lifetime. How do you expect to be able to pass a non-`'static` closure to it?
I am working with the stdweb crate and I am calling the function `window().request_animation_frame(f)` where `f` is of type `FnOnce(f64) + 'static`, so I can't change the function signature. My goal is to be able to call the passed in variable in the closure that gets passed in, which is difficult.
This looks like it will pin a core as it continually tries to read and write to sockets without regard to blocking. A next step will be to investigate tokio to wait on sockets and react when data comes in. &gt;`Arc&lt;Mutex&lt;HashMap&lt;usize,TcpStream&gt;&gt;&gt;` This is a smell for me. Consider setting up channels for messages between readers and writers; but also for connection managers. like 'writer, be aware that someone left / someone joined' &gt;`panic!` Network errors happen. You need to handle them.
no mention of doxidize ?
I have to admit that I don't know much about it. Also, it's very unstable for the moment, maybe it's better to wait for it to be more complete before making a huge presentation, don't you think? :)
You might consider asking upstream to change the type from requiring `'static`. Relatively often, it turns out that at the end of a chain of `'static` requirements you'll find something requiring `'static` for no very good reason.
Is it included by default in thr Clion IDE? 
Maybe try 'Restart and invalidate caches`
I read it initially as a context guarded by a generic timeout mechanism (e.g. SIGALRM). But I still don't understand what you were proposing. Is there something specific you can share?
Wow. There's such a tremendous amount of work going into building language support into IDEA. It's a complete reimplementation of the front-end to rustc (in kotlin!). While this kind of approach is costly, it affords us to have a parser specialized to work with incomplete code, which is crucial in an editor. I'm very impressed by the efforts of everyone involved!
Mmany data structures use 1-based indexing for simpler calculations. Is there a better approach than `for i in myVec[1..].iter_mut(){}` ? Even better, is there a crate that wraps `Vec` and other containers and provides 1-based indexing? I do not want to - Reinvent the wheel every time I need it, - Allocate extra memory for the sake of simplicity of computation, - Complicate simple things for the sake of lower allocation. 
Yeah, I’m fine with you not mentioning it; it’s gonna be a long time before it’s feasible to actually use.
1. I would be using Microsoft's database engine/server 2. I planned for the database to be accessed over the network. The original plan was to have one device host the SQL engine/server and then all the other devices using the program would connect over internet to the server.
What's the equivalent to the [$crate](https://doc.rust-lang.org/1.5.0/book/macros.html#the-variable-crate) variable for procedural macros? Something like `quote! { $crate }`. Or am I supposed to hardcode the name of the crate?
Actually Capnp has some JS bindings that work in the browser (https://github.com/jdiaz5513/capnp-ts), however I had some problems with loading large files with it. But in overall the support is not great.
scanning to index takes a few minutes, works for another few and it's all the old story
&lt;3
Instead of writing a generic parser and renderer, another approach is to design use-case based parsers with meta-parsing https://github.com/pistondevelopers/meta This allows you to design the syntax as you like, and use different document formats with the same parser (e.g. XML + a custom domain specific language).
Ludum dare is about having fun~ Try writing a quick program or two and see if you like it? Its pretty unlikely you’ll be able to make much of a game given the state and complexity of the rust game ecosystem, but so long as you’re in it for the ride, not the result, I say go for it. :) I will say though, its very easy to get sucked down a rabbit hole and not make anything with rust; I really do recommend you have a good play with the tools before the jam starts. Its a lot to learn and do at the same time~
Can someone please explain the advantage doing work in Futures rather than regular threads?
C doesn't have verbose generic types like C++ and from what I've seen its common to write out full type names like `struct foo`.
I wanted something that provided some syntactic sugar to make the process more easy on the eyes, adding that parameter name took away a bit from that.
Nope.
You mean the "ident:" bit? That's completely irrelevant. I only added that to distinguish between the two approaches. Just pick one, delete the prefix, and you have the exact syntax you wanted.
So you can read about sidekiq directly. It has jobs declared inside your app, but execute it outside, in another process, and use redis for communication
I don't see that mentioned anywhere ... no wait I found it at the bottom of the readme. It would be nice to include it in the docs as well - and generally more info about how it works and what you need to use it. --- Now I know a bit about how it works it sounds like a nice idea - a higher level library around a pub/sub service. Does it communicate the same way that sidekiq/ActiveJob does? Ie, can you use it as a rust worker for a project that uses sidekiq/ActiveJob?
Okay, closing this topic. Thanks for the feedback.
There's no link between being single-threaded and what we're talking about. In JS, an asynchronous function runs even if you don't await it at any point. For instance, now that I'm on my computer: ``` async function foo(){ console.log("do work without being awaited"); return fetch("example.org"); } var x = []; x.push(foo()); // I store the promise somewhere but never awaits it. // prints: do work without being awaited ```
[`Message::encode`](https://docs.rs/prost/0.3.2/prost/trait.Message.html#method.encode) takes the `Message` by const ref. Have you ever used `prost`? You weigh in on every discussion but most of what you say is, well, wrong.
Getting any database driver to work without Rust's stdlib is going to be a challenge. They're all likely to depend on functionality from std, such as std::net and std::io, as well as things like TLS libraries (openssl). On a design level, it's probably better to have some kind of well-defined API layer between your client and server, so you can change the DB schema and such without having to immediately upgrade all the clients. You could do either a nice HTTPS+JSON API (probably harder to make work in no_std) or roll your own using libsodium and msgpack crates (pretty sure there are ones that will work with no_std).
[removed]
[removed]
&gt; You weigh in on every discussion but most of what you say is, well, wrong. What I find is the amazing length people go through to raise a straw man. At that point I usually give up. The point is that message itself must own any vecs, strings or sub objects. Passing it by reference is irrelevant. APIs rarely match internal data structures. As such you must clone or temporarily transfer your data (also often impossible) just so you can send it. This is why I said those two libs only look good in examples.
Sorry if posting links to twitch is not allowed...will delete if so
Thanks! Didn't know about that one. Seems to fill a similar role. I'll take a closer look. [faktory](https://github.com/contribsys/faktory) seems to be at least partly maintained by [the creator of sidekiq](https://github.com/mperham).
&gt; faktory seems to be at least partly maintained by the creator of sidekiq. Correct. My username is relevant in this regard.
Hah I didn’t even notice 😛 
Reminds me about AXR project. 
Not him but I get solid 60fps now on chrome.
Author of rpds here. One thing rpds 0.4 does not have is mutable methods, which has much better performance. The next version (0.5) will have those, and should be released in a few days.
Thanks, i did fixed some bugs cause sometimes Mac would use software emulation mode. 
The original is 60fps outside of castle, slideshow inside.
I don't think this is an intelliJ issue so much as it is a performance issue with the rust plugin. Completion shows up much quicker for other languages (TypeScript and Java are the ones I use most often these days). The plugin maintainers have acknowledged as much, and I expect at some point they will start focusing on performance.
&gt; APIs rarely match internal data structures I think what you're getting at is that it's rarely a good idea to expose Protobuf defined types in public APIs. I completely agree. Translating between the public API types and the Protobuf types doesn't have to require copying, though. Let's say you have a large `String` that you've received as input in your public API, and you want to serialize it and send it through a Protobuf API with minimal copies. It's possible to do this by _moving_ the string into the `prost` defined Protobuf type from the public API type. And once you've done this translation, which doesn't require copying or allocation, you can encode it without copying or allocation. Adding lifetime parameters to `prost` message types is a non-starter, because it would make it much more difficult to deal with messages in async contexts. Lifetimes and futures just don't mix well.
What's wrong with tuple structs?
Why would I need the commercial license to statically link Qt? I get that if I don't want to put my work under the GPL I might not be allowed to statically link, but what if I do so?
The [code of conduct](https://www.reddit.com/r/rust/comments/2rvrzx/our_code_of_conduct_please_read/) is a good guideline for fostering healthy online discussions as well as the [Recurse Center's Social Manual](https://www.recurse.com/manual). I noticed two occurrences in this thread were feigned surprise could have been slightly reworded to educate rather than chastise. * Typedefs make [function pointers](https://stackoverflow.com/a/1591492) much easier to understand. * Tuple Structs allow for [types to be wrapped](https://doc.rust-lang.org/book/second-edition/ch19-03-advanced-traits.html#the-newtype-pattern-to-implement-external-traits-on-external-types) it might be what you are looking for.
If you want to make a 2d game, ggez is a perfect tool for a game jam scenario imo. I am a bit biased since I've contributed to it though ;) Check out the examples directory on github! One of my friends who I introduced ggez to got this up and running in about a day having not used it before https://imgur.com/N1OSAEZ https://imgur.com/gnN4fWq 
You might look at how "units of measure" libraries are implemented, they solve many of the same problems. * https://github.com/Boddlnagg/units * https://github.com/jocull/rust-measurements * https://github.com/paholg/dimensioned * https://internals.rust-lang.org/t/any-rfc-for-units-of-measure/7154 * https://crates.io/crates/uom * https://crates.io/crates/rink * https://research.mozilla.org/2014/06/23/static-checking-of-units-in-servo/ Maybe /u/Boddlnagg would elaborate on the design of the library and how it applies to your question?
Why the hell are people downvoting you without explanation? I see nothing worth downvoting in your comment. Anyone care to explain?
Nice! I'd be interested to know how the participants liked the language and the experiment.
I'm very surprised to find out you think my surprise was feigned. :) I thought my questions were clear enough... I meant my comments as questions, not chastise nor making fun nor anything similar. I wrote "What's wrong with tuple structs?" because OP explicitly mentioned "apart from tuple structs", so I wanted to understand why he doesn't want tuple structs. I wrote "Have you ever used function pointers?" because I wanted to know whether OC never used function pointer or if he finds it easy enough to read to deem `typedef` unnecessary.
I understand, but some of these things are hard to convey across a reddit post. I appreciate the follow up.
If ergonomic improvements cause papercuts, that's just bad ergonomics - and to introduce them is to go _against_ the general trend of ergonomic progress in rust. That's not a reason to argue against ergonomics as a goal - unless you don't have faith in the Rust core team and developers to implement ergonomic improvements in the language.
I'm not sure I follow your example, what kind of simple ergonomics upgrade are you referring to? HashMap::get() returns an Option&lt;&amp;ValueType&gt;, an optional reference to the value type to avoid paying the price of cloning values. Rust cares about these kinds of details. If you don't like the * and &amp;, you can change your code to map.get(token).cloned().unwrap_or(47). Option::cloned is there for this purpose, clone the T if it is some turning Option&lt;&amp;T&gt; into Option&lt;T&gt;. 
Here is your example formatted and split onto multiple lines to make it readable: let map = HashMap::&lt;String, usize&gt;::new(); let data = Vec::&lt;String&gt;::new(); let translated: Vec&lt;usize&gt; = data.iter() .map(|token| *map.get(token).unwrap_or(&amp;47)) .collect(); 
typedef in C is useful for function pointer types.
There are two things. `unwrap_or` takes `&amp;usize`. I would say, that having autoborrowing (automatic coercion from `usize` to `&amp;usize` in this case) for at least Copy types would be quite nice. Second thing is actually autoderef, which again could happen here, since returned type is Copy. And actually this example is quite tolerable, but try writing some numerical code and you will stare on unreadable mess of * and &amp;.
Gotcha, thank you.
What error are you getting? The minimal example works... we have nothing to go on. Increase the complexity of the example until it breaks but then you will probably be able to figure out why if you can see the bit that breaks it.
You misunderstood me. I didn't say the ergonomics were introducing paper cuts. My point was not to fix some paper-cuts if it *could* endanger the robustness. The examples I showed isn't something I consider a paper cut. I consider that a real knife in the back from the language. And I'm not against ergonomics as a goal, but I feel like the fact the ergonomics won the poll overshadows other concerns from time to time. Sure, ergonomics are *good*, but not at any cost. I do have ‒ as you put it, faith ‒ in the core team, and the Rust community in general. And I even tried to write it in there ‒ if their work wasn't so damn good, I wouldn't *care* about rust and wouldn't be writing articles about it. But I do find myself disagreeing on some of the specific proposals I see in RFCs. And I do find the ergonomics discussions to turn into long and strained battles quite often. This in part was my attempt in trying to show the „other side“ what „my“ side argues for in these battles and *why*. In a hope it'll help in understanding each others' goals and make the discussions smoother next time. Looking at the comments around, I'm not sure I expressed myself well enough, though. One specific example are the `catch` blocks around error handling. They have some edge cases. Some further extensions were introduced, making the edge cases more pronounced, and there was a very long thread on the internals forum about that. It went silent after a time, but was quite unsatisfactionary to all the sides I guess. Even though I argue against the proposal and it wasn't passed (well, wasn't made into an RFC afterwards), the whole thing made me sad ‒ that such a long discussion was needed and there wasn't a consensus after all about what the step forward should be. Another example is, there was a suggestion (not really part of the RFC) that the suspension points in async functions could be automatic (effectively invisible). The argument was, it's more ergonomic not to have to mark them in any way and that other languages do it that way. And while I agree that the proposals would make the language more ergonomic to use, my point here is that ergonomics is not the *only* thing or, in my opinion, the most important one. Sure, it's only my opinion.
No error, just that params is empty in real world code, while example is non-empty
&gt; Come on! Auto-unwrapping of option is pure craziness, nobody sane would want that. That's *exactly* why I put the example there. As I said, these were examples on the very extreme of the spectrum. I wanted to demonstrate that not *every* ergonomics improvement is for the overall good ‒ which is obvious in this case. There are cases where it's less obvious or questionable and there are cases where the downsides are so small or nonexistent.
Agreed. I have done a few projects in Rust, and it's still baffling when are where something gets auto-derefed, so to be safe, I simply do it manually, and it does get rather messy. Consistency matched with ergonomics would be nice.
Actually I don't know yet. I'm only getting the board in 2 weeks, but until then I'd already like to get a look at how Cortex-M works in general, especially since this is my first time doing any embedded / SoC development.
Nice! Do you think your software would work with my cheap ONVIF 2.4 motion detection H.265 camera? Fwiw the built-in motion sensor would likely work perfect for my use cases. 
I agree completely, a lot of the changes people seem to want scare me. I like Rust as it is. 
I feel like you're missing the forest for the trees. In particular, you seem to be toting balance as a counter to absolutist arguments that I don't think actually exist. e.g., * ergonomics are good, but not at any cost * ergonomics is not the only thing * [ergonomic is not] the most important one I think you'd have a really hard time finding someone that would defend these principles. To me, that means you've built up a straw man. I think the key here is that *your* balance may be very different than *other* folks' balance. I think that's actually the case for a lot of people, and it's, I think, one of the reasons why ergonomic discussions are so hard to have. There's a gazillion points in the design space, and ultimately, figuring out the right place to land is very difficult. Here's another anecdote. I was actually weakly opposed to `?`, and favored just sticking with `try!`. At the very least, I do buy some of the arguments that `?` is a bit harder to see, especially when wrapping long lines. I held this opinion weakly because I predicted that I would just switch to using `?` and I probably wouldn't see it as that big of a deal. And that's largely how reality has played out. What I've found most interesting, actually, is not *my* reception of `?`, but rather, *everyone else's*. I can't tell you how many times folks have said something along the lines of "now that Rust's error handling story is much more ergonomic with `?`, I'm going to give it a shot again." It was an incredibly huge sticking point to a really large number of people. From my perspective, it all seemed so... trite. It was a minor syntactic change and people made *such a huge deal* out of it. I can either choose to remain fixated on my original position, or recognize the reality: mixing minor speed bumps, can, in some cases, have a baffling disproportionate impact on others' perception of the language. How far do we take this? Dunno. But that's why we discuss these things.
Maybe we should do some A/B testing before changing the language for the sake of ergonomics, to determine if *what we think* is easier to learn is actually easier to learn. E.g. we should A/B test `dyn Trait` syntax. I don't think it makes it easier to learn, and it's more to type. Not necessary IMO. Also I don't think the `T: impl Trait` *for arguments* is a good idea because then it's not orthogonal with `&lt;T: Trait&gt;` anymore and then there are 2 ways of making args generic (and one of them (`T: impl Trait`) is strictly less powerful), and it uses the same `impl Trait` syntax for universal quantification (for arg types) and existential quantification (for return types) which will confuse more people. So we could A/B test these language design alternatives with a quiz website where people who are interested in learning Rust (but don't know it yet) have to pass a virtual job interview for a Rust job by guessing what some code means, just by looking at the code.
Historical note: autoborrowing was proposed and explicitly rejected before Rust 1.0. You can read the result of discussion in RFC 241. Specifically, I am referring to the following quote: "(The design) does not introduce implicit borrows of owned data, since it only applies to already-borrowed data."
I completely gave up on predicting the effect of syntax changes. Your choice of the word "baffling" is exactly right. I routinely see posts on HN along the line of "I like most things about Rust, but syntax is so ugly, and it's a deal breaker". Temporarily, I am incredulous and suspect the poster is intentionally trolling, but I soon regain my sense and admit I am not normal and I don't understand normal programmers' reaction to syntax, at all.
This is a very good point. The more specific the compiler requires the programmer to be, the more likely it is that a compiling program actually exhibits the behavior the programmer intended. In general.
Have a quick question about proc_macros. Theoretically if I wanted to have a procedural macro that printed whatever variable was in scope, a, I would think it would look like: #[proc_macro] pub fn print_a(input: TokenStream) -&gt; TokenStream { let s = input.to_string(); let ast: syn::ExprLit = syn::parse(input).unwrap(); let a = syn::Ident::new("a", proc_macro2::Span::call_site()); let q = quote! { println!("{} {}", #a, #string_to_interpolate); } } I would expect when I use the macro in this way: let a = 1; print_a!("is the variable"); to print "1 is the variable", but instead I get that the variable isn't defined, cannot find value `a` in this scope I'm sure I'm misunderstanding something, but it feels like quote creates a sort of isolate scope. Is that correct? How could I achieve a macro like this?
The main difference is that simple-interner is, well, simple. Rather naively simple. Nothing ever gets cleaned up until the whole thing does, and insertion is a conservative double-read Mutex pattern rather than something cleverer. I'm not supporting staticly interned symbols, and the symbols that I give out are just regular (newtype-wrapped) `&amp;str`. I'm actually considering changing the `Symbol&lt;'a&gt; as Deref` target from `str` to `&amp;'a str`to make it easier to just drop the O(1) Eq impl and just use the &amp;str again. In actuality, this implementation is probably closer to an arena (in fact, that's the terminology used in the code). In the toy language I'm working on, after a zero-copy lexer, I wanted to have my AST use a _simple_ interner to store deduplicated strings for the various symbols that need to be actually tracked. Thus this was born, and once it got a bit of polish when I wanted to be able to intern slices, I pulled it out-of-tree to share. Oh, and it can intern anything (that goes in a `HashSet&lt;Box&lt;T&gt;&gt;`); I haven't seen another string interning solution do that. And the one bit of unsafe code is to make handling lifetimes easier as the interned symbols are guaranteed to live as long as the interner.
The biggest current hurdle to Rust adoption is its image as the language for people who either have CS PhDs or are language nerds who spend their evenings reading blogposts on static analysis and algebraic types. Rust really does need to work hard to dispel the belief which many people have that 'I'm just a normal programmer - Rust isn't really for me'. That means identifying and patching things like `?` in favour of `try!` - because pleasantries like that genuinely could make the difference between Rust being the preserve of enthusiasts and becoming a genuinely mainstream development tool.
CLion does require a license (of which you can acquire a non-commercial one for free if you are a student or teacher with a `.edu` address). For anything which isn't the debugging stack, though, you get the same experience with IntelliJ IDEA Community, which is free to use (even commercially). I've yet to try out debugging in CLion (I have an educational license), but the experience in IDEA is wonderful. JetBrains got their value out of their educational license with me; I'm hooked.
Would it be really useful without Stream trait?
Hey, this is my project! I wasn't expecting to see it here today. &gt; Do you think your software would work with my cheap ONVIF 2.4 motion detection H.265 camera? It doesn't support H.265 yet. (There's an [issue](https://github.com/scottlamb/moonfire-nvr/issues/33) for that.) If your camera has a way to switch to H.264, that should work fine. &gt; Fwiw the built-in motion sensor would likely work perfect for my use cases. Built-in as in the on-camera or on-NVR? It doesn't actually support either yet though. There are basically three must-have features that I haven't written yet: motion detection, authentication (I have a commit in progress for this one), and https.
Newbie myself here; but I would take a guess at (in server.rs) `use super::helpers::env`. (Also, there's a pinned post here for "easy questions". This might better suited there)
I'm not sure about your particular case, but I've written "two-part" APIs for async stuff in the past. It would mean having one "async" API which does not contain the core, and returns futures on every request, then having a "sync" api structure which holds the async API and the core together, and allows making synchronous requests. Some crates like reqwest have the async part marked as unstable so it can have breaking changes, so that could be an option too. The async API doesn't have to be a public stable one, but if you want people to use it (the async part), it probably should be. I don't generally think clients exposing Futures should contain their own cores - but it's very inconvenient for synchronous usage if the user always needs to manage a core as well. This is the main reason I'd go with a two-part API.
Add src/lib.rs which contains: ``` pub mod helpers; ``` then in bin/server.rs: ``` extern crate NAME_OF_YOUR_CRATE; // use a function from env.rs NAME_OF_YOUR_CRATE::helpers::env::some_function(); // or like this use NAME_OF_YOUR_CRATE::helpers::env; env::some_function(); ``` 
Sidenote: long code blocks in reddit are formatted with 4 preceding spaces, not ``` like regular markdown. I definitely agree with this answer.
What we actually get is evidence for what is actually more similar to other progoramming languages, not what is easier/intutivie. `impl Trait` in arguments makes sense not in the context of "I'm a Java programmer" but in the context of "I'm a rust programmer and already learned/am also learning about `-&gt; impl Trait`".
I disagree. The biggest current hurdle of Rust adoption is that Rust is so different from other programming languages, i.e. Rust is weird. Rust is basically the only programming language in common use with substructural typing. No amount of ergonomic improvements will change that. On the other hand, less hurdles are worth fixing, even if they are not the biggest hurdle.
OK, that makes sense. I guess what I'm struggling with is.. how would I expose a Future&lt;AsyncClient&gt; ? I guess I'd do something like: TcpStream::connect(&amp;addr, &amp;reactor) .and_then(move |socket| { Connection::handshake(socket, reactor) .map_err(|_| panic!("failed HTTP/2.0 hand shake")) }) .and_then(move |conn| { let conn = add_origin::Builder::new() .uri(uri) .build(conn) .unwrap(); Client { connection: FileHistory::new(conn), } })
People are happy to learn new things in general though - the exception is when they believe from the outset that those things are for 'people smarter than them' or whatever.
This works! Thank you &lt;3
I actually think `Trait` should mean `impl Trait` instead of `dyn Trait` since it is the common case, but that ship has sailed: 1.0 is out and any gain is not worth breaking backward compatibility.
oh... it worked
But that's just the thing; `-&gt; impl Trait` is existential quantification. As a rust programmer, it is strange to see the same syntax also used for universal quantification, especially when there's already a perfectly good syntax for that.
While I agree with your general principle, I cannot say I worry too much about Rust crossing the boundary here. So far, the RFC + stabilization process seems to work nicely, to my eyes. In particular, I find it ironic, that some of the examples you use as "non-ergonomic" (for example ? and I'm assuming .into()) are themselves results of experiments to improve _ergonomics_. Someone realized explicit handling of error-codes can get a bit tedious (Go, I'm looking at you), so they invented `try!`. Even then, some people found `try!` a bit tedious. After _long_ discussions, and lots of deliberation, the `?` operator (that you seem to appreciate?) was invented, for reasons of ergonomics - safety wasn't improved but also wasn't deemed weakened by it. I don't exactly know the background of `.into()` but I'll go ahead and simply assume reasoning along the lines of "We like explicit types. We don't want potentially dangerous automatic coercion. Manual non-standardized conversion is _tedious_. `Into` seems safe, explicit, and you don't have to look up every the rules for every type in the manual." Now, I agree with you. Automatic coercion WOULD have appeared even simpler than `Into`, and doing exceptions like most other mainstream would have been an easy route. But evidently, those were rejected. Clearly an indication that "convenience over safety" is not a tenant of Rust. My personal take on it is guided by the realization that people (especially programmers, myself included) are lazy. Hating the fact will not get us anywhere, so let's exploit it instead; "Make the right approach easy". It's just as important as actually finding the right approach. "Everything should be made as simple as possible, but not simpler.”
I recall some discussion, that in a future epoch, a bare `Trait` syntax will be introduced to replace `impl Trait`. At that point, we'd have `Trait` and `dyn Trait`. Is that not happening? On an aside, I personally hope that `dyn` will get introduced into type definitions, so we can write: ```rust enum Tree&lt;T&gt; { Leaf(value: T), Node(value: T, left: dyn Option&lt;T&gt;, right: dyn Option&lt;T&gt;) } ``` ...but that's a far way off.
Yeah, that's what I would do- then just return a `Box&lt;Future&lt;Item=AsyncClient, Error=...&gt;&gt;`.
No problem! Even though they have a bad reputation, I do mostly like the current futures setup. To be honest I keep forgetting that `impl Trait` is stable now. It's a better choice than `Box&lt;Trait&gt;` in all situations IMO.
I become a confused mess when I discuss language ergonomics, because I hold many opinions that are in clear contradiction with each other. Here's an example: I asked a few years ago why the receiver in a method call could be automatically borrowed. For instance, you can write this code: let v = vec![2,3,5]; assert_eq!(3, v.len()); Although [Vec::len borrows the vector](https://doc.rust-lang.org/std/vec/struct.Vec.html#method.len), you don't need to write `(&amp;v).len()`. But for any other parameter (i.e., not `self`), if the method expects reference, the programmer needs to manually borrow the actual argument, typically be prepending it with a ampersand. I believe it was Patrick Walton that said that the Rust developers had tried without `self` auto-borrow, but they found the language was too annoying to use, and so auto-borrow was added. On the one hand, I am happy that the Rust developers decided to auto-borrow `self`: there would be entirely too much verbiage in the language otherwise (not to mention that new and old Rust developers would probably be put off by the constant need for extra syntax). On the other hand, it is an extra, special rule in the language that hides from the programmer how a method truly works; the extra rule also adds extra complexity. There are other similar cases: comparing a `String` and a `&amp;str` (something I do a lot); passing a `&amp;Vec&lt;T&gt;` to a function that expects a `&amp;[T]`; the `?` operator with its hidden `return`; etc. How is it possible that I can enjoy having these features that make the language nicer to use, and yet be worried about the increased mental load and complexity that they entail?
Uh, what's the Eye of Sauron in this context? I haven't heard that one before
I have very mixed feelings about futures. It is the right choice for rust, I think. I'm hopeful for async/await.
&gt; I reach more ergonomics by accepting more programs... This is, to me, the moment the essay overplays it’s hand. There are myriad ergonomic changes that do not change the set of accepted programs — such as clarifying an existing error message. This reveals that it was not ergonomics, after all, that the essay should have been aiming at, but changes that result in new, valid programs.
The stability of gfx-rs API has certainly improved, but mostly because of HAL efforts. Otherwise it would keep evolving. I suggest reading the whole section about gfx-rs with a grain of salt: it has bold inaccuracies and missing important details. I'd also like to see some love for Three-rs, which wasn't mentioned. It's rough, but it's not like other engines are polished and shipping anyway :P
I honestly never thought about it that way... I don't think that's how most programmers view generics but it's an interseting point that in one the caller controls the type and one the callee. Either way, while a valid argument against `impl Trait` it doesn't matter to my objection above that such a survey would be measuring the wrong thing. As an aside I don't think `fn f&lt;T: Trait&gt;(x: T) {}` aka `fn(x: impl T) {}` is universal quantification, i.e. "forall T such that T: Trait, T -&gt; ()`. Rather it's a function generator `(T: Trait) -&gt; [(x: T) -&gt; ()]` that takes a type to produce a callable function that only works on that type. This is opposed to `fn f(x: dyn T)` which is universal quantification, i.e. `forall T such that T: Trait, T -&gt; ()`.
build something which is easy to use the wrong way, don't be surprised it will cause issues. A step ladder made of chocolate might be interesting from a constructive and artistic sense, but it's going to cause a whole host of issues if you leave the damn thing sitting around.
Of course! It's fun. I enjoy sharing everything I learn on this journey...
What would that syntax do?
I would be very surprised if it was possible. Identifiers aren't compared just with the name, they're also compared with the syntax context. Same name but different context means the identifiers don't match. This is done to prevent macros from being able to see things they weren't passed in the invocation, so that they can't be written to have magical implicit behaviours. This isn't a limitation of `quote!`, it's a deliberate limitation of the macro system as a whole.
Interesting, that does make sense though! I'll have to identify another way to do this I suppose!!
&gt; Not to mention eye of sauron (https://twitter.com/rustlang/status/839516423613464576). https://github.com/arielb1/rfcs/blob/80d4ce931598ace3c4acf282346cc783d968aae1/text/0000-eye-of-sauron.md 
As `(x as i32 - y as i32).abs()` is the difference between `x` and `y`, you could express it as `max(x, y) - min(x, y)` without casts. For the tripping through float math, though, you either need the casts or to re-express it in integer math. Here's my completely over-engineered attempt! U16 = { x ∈ ℤ | 0 ≤ x &lt; 2^16 }, U16x3 = U16 × U16 × U16, F : U16x3 -&gt; U16. F(x, y, z) = round(| x - y | / z). let d = | x - y | = max(x, y) - min(x, y). F(x, y, z) = round(d / z) = ⌊d / z⌋ + (if (if (z is even) d mod z ≥ ⌊z/2⌋ else d mod z &gt; ⌊z/2⌋) 1 else 0). There's probably a smart way to represent `round_div(a, b)` using only integer math and fewer branches, but I don't know it and I don't feel like trying to derive it right now.
This is really cool, but I'm more surprised that I hadn't heard that the ARM Cortex-M targets were available on nightly!
I keep getting email notices every day, so it looks to me Gfx is moving fast forward. Keep up the good work!
[Here's an informal proof that this works](https://play.rust-lang.org/?gist=b1cf15651ab8da9e4861cc3c0b25b8f4&amp;version=stable). Which one would you prefer using? (Use the casting one; it's much clearer on intent and shouldn't have any problems with float imprecision since you're only dealing with the range of `u16`.)
It'd be equivalent to `Box&lt;Option&lt;T&gt;&gt;`, but I'm not sure how it'd handle `Arc&lt;T&gt;` or `Rc&lt;T&gt;`. (I just want a more ergonomic way to write ADTs in Rust.)
I guess I'm not sure how that's more ergonomic, given that it saves only one character and overloads `dyn` to mean two completely unrelated things.
[removed]
[removed]
Got it thanks! I’m very pleased this is happening. I have taken a look and plan on incorporating it into a long-standing project of mine. I don’t have too much free time nowadays, but I’ll try to contribute where and when I can. Again, really happy to see Rust and Arrow intersecting. 
Now we need search for binaries on crates.io
[removed]
:D
If a language has 0-based indexing you should use that, using hacks to get around that is just going make your code confusing to read. But, If absolutely want to do this, you can create a generic wrapper around indexable types which makes them 1-base indexable. use std::ops::{Index, IndexMut}; struct Evil&lt;T: ?Sized&gt;(T); impl&lt;T: Index&lt;usize&gt;&gt; Index&lt;usize&gt; for Evil&lt;T&gt; { type Output = T::Output; #[inline] fn index(&amp;self, index: usize) -&gt; &amp;T::Output { self.0.index(index - 1) } } impl&lt;T: IndexMut&lt;usize&gt;&gt; IndexMut&lt;usize&gt; for Evil&lt;T&gt; { #[inline] fn index_mut(&amp;mut self, index: usize) -&gt; &amp;mut T::Output { self.0.index_mut(index - 1) } }
I personally a bit cautious about gfx-rs and think that Vulkan is a better candidate for "one cross-platform graphics API", especially after [the recent advancement](https://www.khronos.org/news/press/vulkan-applications-enabled-on-apple-platforms) on Apple products front. And even better if in future we'll get a working Rust -&gt; SPIR-V compiler. This [discussion](https://users.rust-lang.org/t/vulkano-vs-gfx-rs/11989) is a good read on vulkano vs gfx-rs topic.
The post contains this line: `Ok(goal_value(lex, value)?)` Is there any difference at all between that and `goal_value(lex, value)`?
If the error types of `goal_value` and its caller were different, there would be- the first version would convert the error, and the second would not. Since they're the same, it's not technically necessary to use the first version, but I prefer it because it expresses intent a little more clearly.
I don't think even Vulkan will be able to fill that role, without several more major political shifts. It may be a good compromise in a lot of situations, but unless Microsoft, Apple, Sony, and Nintendo all decided to support Vulkan natively, getting the best end result will still require writing to multiple APIs. I'd much rather see effort go to higher level engines and applications. IMO that's a more realistic way, politically speaking, to empower people to build cross-platform games- and it leaves room for that optimal end result.
Wow I was really hoping this was about body ergonomics but it was still a good article either way
I tried and it helped me to find bug by trying to add an unknown field on purpose, so after it didn't fail, I realized, something else must be processed.
Warning: if my first post weren't whimsical enough, this is. Thinking back at this I like the word ergonomics, precisely because it is about removing needless strain, without harming sustainability. I see it as something clearly distinct from I.E. convenience or comfort, that also came close to mind. Convenience is about sparing you the details. Ergonomics does not shield you from the details, but tries to avoid needless strain while you do the job. Convenience is like valet parking. (Of course we needed a car analogy) Spares you some time, but you will always have some unease about exactly what scratches and dents your car got this time. Ergonomics in comparison would be letting you park without _unnecessary_ effort; maze-like parking lots, long walking distances, congestion from poor design. Comfort is about avoiding discomfort upfront, not really caring about the future. Ergonomics is about well-being in the long run. Like how a big sofa-chair might be very comfortable now, but a good ergonomic desk chair might be less comfortable, but avoid back-problems for years to come.
&gt; On the other hand, it is an extra, special rule in the language that hides from the programmer how a method truly works; the extra rule also adds extra complexity. Actually, it removes complexity. You need to read api docs in order to use stuff from other people, and for your own stuff, you wrote the API yourself, so you know what’s going on with the autoborrows because the `&amp;self` parameter tells tales. Armed with that knowledge, I think it is clear that forcing people to state the obvious would be asinine.
&gt; So, while I know a lot of people want more ergonomics, I’m not sure it is what they need. You were supposed to destroy Rob Pike, not join him!
On the [mutagen](https://github.com/llogiq/mutagen) side of things, gnieto has found a strange interference of our [opportunistic mutations](https://llogiq.github.io/2018/03/03/opportune.html) with type inference and (probably) integer defaults. It appears trying to forward the `std::ops::Shl`/`Shr` traits as we do fails to correctly bind the `Output` type. I'm investigating. Otherwise I'm back from travel, so I'll do TWiR and possibly some Rust or clippy stuff if I find the time.
 Instant::now() - Duration::from_secs(1024 * 1024) thread 'main' panicked at 'overflow when subtracting duration from instant' Why??
&gt; I think you'd have a really hard time finding someone that would defend these principles. I agree that I'd have a really hard time finding someone actually consciously *stating and defending* these principles. Still I find people (usually not from the official teams, more often „bypassers“ like me) who defend some minor convenience in face of other several drawbacks. But you're probably right that we just may have huge difference in the balance so it *seems* to me they kind of forget everything else. Thanks for pointing that out.
Very simple but good summation of Rust gamedevv. Most big gamedev studios have 10-15 years of investment in their existing C++ tools, with the amazing power that brings... but if you are willing to depart from that and try Rust I feel the advantages are huge. Memory safety isn't a huge priority since they already have reasonably good ways of dealing with that, but being able to have sound multithreading, ah, that's a great advantage.
Nearing the 1.0 release of [tmpshare](https://github.com/zoranzaric/tmpshare) (yet another file sharing tool). Had 4 streams on [twitch](https://twitch.tv/zoranstreams) and archived them on [YouTube](https://www.youtube.com/playlist?list=PLzZiioPR-W-ZbMAdbvvsTPkFGz_uLwbjB). The only things missing for 1.0 are a method to remove files older than X days (Having this is the motivation for `tmpshare`) and serving multiple files at once.
 C:\Users\drk&gt;cargo script -e "use std::time::*; Instant::now() - Duration::from_secs(1024 * 1024)" Instant { t: 18245261528 } Dunno, works for me.
It worked for me last week as well...
Which means the problem isn't the literal code, it's something else, but all we have to work with is the code. What version of Rust are you using? Is it a weird OS? Is it in a VM? What's the date according to the OS? Is there more code you haven't shown?
&gt; latest rust *Which one?* There're three different release channels, and nightlies can be outdated really fast. What does `rustc -V` say? 
rustc 1.25.0 (84203cac6 2018-03-25)
Sure, but taken to the extreme this brings us to scripting languages where you never need to refer to the docs, where anything is permitted and always works. Sort of. One of Rust's strong points is its explicitness and its stubborn compiler.
Alright, works on stable 1.25.0 on Window 7. What do you get if you debug print `Instant::now` and the `Duration`?
Tangential question: would gfx-rs be a good library to use for non-game graphical applications? For example, a GUI library or a visualization?
[xcolor](https://github.com/Soft/xcolor) color picker got a new preview functionality that displays the color currently under the cursor. I think I'll publish the new 0.4 version later this week.
 Instant::now()=Instant { t: 207225223030190 } Duration { secs: 1048576, nanos: 0 } There it is I guess. Instant starts out insanely large though in time it is only 2.3 days (I assume it's in nanoseconds). I guess that is how long since I rebooted the OS. Isn't this going to randomly crash my Rust apps according to how large Instant starts out. 
Finally found some time to learn rust, after a half year of following this sub. This week I will continue reading the rust book and keep improving my rust tic-tac-toe game. https://github.com/flofriday/tictactoe
Unless one of your unique tokens has a zero value, I think your little program at the end would print nothing at all. The member operator== is not const-qualified and thus cannot be called on the const objects you have, so instead the compiler would implicitly convert both sides to bool and compare the results.
Yeah, it sounds like you shouldn't be using `Instant`, you should be using something like `chrono`.
Brilliant! Thank you.
Okay, thank you! So looks like there shouldn't be much problem in adopting that style, eh? IIRC, the MIT licence also allows one to make modifications as well so long as the original header is unchanged, right? Just in case, I should probably double check the licence details.
I think you meant to post it on [/r/playrust](https://reddit.com/r/playrust)
Can't say anything that yes, I'm in full agreement. Maybe that's what makes a
Implementation of [the Tsetlin Machine](https://github.com/KhaledSharif/TsetlinMachine) in Rust. I mainly translated [the C\+\+ implementation](https://github.com/222464/TsetlinMachine) from here. There's an example of a basic XOR function learning included too.
I'm having some trouble with using "sibling" modules (at least I think that's the right wording). The code layout is, as I understand rust, correct and not the problem. Here's the output of `tree`: arthurr@arthur-desktop:~/code/my-recipes-rs$ tree . . ├── Cargo.lock ├── Cargo.toml ├── recipes.sql └── src ├── db │ ├── create_schema.sql │ └── mod.rs ├── lib.rs ├── main.rs └── recipe.rs 2 directories, 8 files The `lib.rs` is: mod db mod recipe I would like to use the `struct`s and `enum`s defined in `recipe.rs` in `db.rs` so I have `use super::recipe` in my `db.rs` file. However when I try to build and run tests, I get: error[E0432]: unresolved import `super::recipe` It's the same error when I just have `use recipe` also. I'd like to understand how I can use `struct`s from `src/recipe.rs` in my `db` module (in `src/db/mod.rs`). I'm not sure exactly how/where I should be using `mod`, `use`, and `pub`. I feel like this is probably why my code isn't working (I'm really hoping it's not some terrible spelling mistake). I'm not looking for anything too specific on how I could better write my rust and lay it out at this stage, although any small hints would be great there too! Here's all the code if anyone wants the bigger picture: http://git.arthur.kiwi/git/recipe-rs.git/tree/ `main.rs` is just a scratchpad of code for me at the moment. This whole project is just for me to learn some rust and some database bits and pieces, nothing too serious, feel free to comment on other things I might be clearly doing wrong.
Moving saves me a clone only if I do not require the String anymore. This is very often not the case.
I think now that Swift has entered the world, and lite-MLs like Elm are getting traction, that Rust is increasingly not so weird. However there is a reputational thing to work on no doubt. Rust's reputational difficulties aren't its only fault: endless people on Slashdot blather on about Rust "politics" because it mandated a very basic code of conduct and -- even though almost every programming language has followed -- Rust still gets a disproportionate amount of grief. What Rust needs to get over the hump is a killer feature. Actix-web's performance in Techempower is a very good example. If Rust 2018's launch came with async/await, and was timed to coincide with another Techempower top-10, that would give the language a significant boost.
 use ::recipe::*;
I change `use super::recipe;` to `use ::recipe::*;` (and changed all the times I referred to `recipe::Ingredient` to just `Ingredient` (`Ingredient` being a struct defined in recipe.rs). I don't think it worked, because I get the following errors: error[E0432]: unresolved import `recipe` --&gt; src/db/mod.rs:10:7 | 10 | use ::recipe::*; | ^^^^^^ Maybe a missing `extern crate recipe;`? error[E0412]: cannot find type `MeasureUnits` in this scope --&gt; src/db/mod.rs:12:16 | 12 | impl ToSql for MeasureUnits { | ^^^^^^^^^^^^ not found in this scope error[E0412]: cannot find type `Ingredient` in this scope --&gt; src/db/mod.rs:49:31 | 49 | ingredient_with_measure: &amp;Ingredient, | ^^^^^^^^^^ not found in this scope warning: unused import: `::recipe::*` --&gt; src/db/mod.rs:10:5 | 10 | use ::recipe::*; | ^^^^^^^^^^^ | = note: #[warn(unused_imports)] on by default 
To be fair, this exact code is an example where autoconversion is the wrong solution. The way I would write the closure would be |token| map.get(token).map(|x| *x).unwrap_or(47) Suddenly there is no autoconversion issues, and instead you can see the real culprit of this papercut - map.get() returns a reference when we want a copy of the value. Now we can think about adding a function to get a clone or something. This actually fortifies the authors point more than his own examples - you need to be careful where you apply your fixes to the papercuts or you might end up introducing bugs in other places. In this case seeing &amp;47 both tells you you are working with pointers and not numbers, AND makes you think if working with pointers the thing you should be doing in this case.
It's probably because you're *also* pulling in `db` inside of `main`, but you didn't pull in `recipe`. Usually, you have `extern crate NAME_OF_CRATE;` in your `main.rs`, and access stuff through that. Otherwise, you end up effectively compiling all the code twice.
This is an interesting alternative to some of the other way to learn Rust. There's a series of broken programs that you need to fix. I did the first few of these today. It's not a particularly gentle introduction and dives in pretty quickly, but is fun nonetheless. The README notes the following: &gt; * It requires you to look at the docs! &gt; * It requires you to search the web. &gt; * It requires you to ask for help on IRC.
Absolutely. One of the users is shipping video processing tool in production. Nothing is particularly catered to games.
Hey, so I took a look at the code and after tinkering a bit, the errors are actually caused by the `main.rs` file. The initial way using either super or :: is fine. Just fix the main file and it builds. This is the first time I've encountered something like this and it's quite awful that the error messages were not helpful at all. Hope that helps
Thanks so much /u/redditfinally. /u/Quxxy helped me figure it out at just about the same time as you. Thanks for taking the time to pull down the code and go that bit further!
That's really good to know. Thanks again.
That sounds great. Thanks!
`foo: Box&lt;dyn Trait&gt;` is existential quantification. What `dyn Trait` is saying is that "foo is a Box that has some type which implements Trait" (what type that is is decided by the universally quantified `Box::new`). For more details I refer you to: https://en.wikibooks.org/wiki/Haskell/Existentially_quantified_types and discussion at https://internals.rust-lang.org/t/proposal-change-terminology-from-trait-object-to-dynamic-trait/7091/40
You should probably edit your original comment(s) to point out that you were wrong. Someone not reading through the whole thread could be misled.
good idea, thanks
The compiler could in theory infer mutable references, but there would be a problem: there may only be one mutable reference at a time, but there may be multiple immutable references. The `mut` keyword prevents ambiguity in this case. When you see `&amp;mut` you can (often) be sure the function mutates the argument (otherwise the compiler emits a warning, I think).
About the second question: you can't implement a trait for a struct defined in a different crate. You can, however, implement a trait for every type that has a specific trait implementation. For example: create a trait `MyTrait` and implement it for every type that implements `Rng`: extern crate rand; use rand::Rng; trait MyTrait { fn do_something(&amp;self) -&gt; i32; } impl&lt;T: Rng&gt; MyTrait for T { fn do_something(&amp;self) -&gt; i32 { 42 } } fn main() { let rng = rand::thread_rng(); println!("{}", rng.do_something()); }
Last week was mostly reviewing [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis) pull requests. This week I'm hoping to get those merged and then perhaps get back to the great thermodynamic temperature vs. temperature interval issue.
&gt; c++ compiler written in rust? Is there such a open source project available? AFAIK no, there aren't any open source C++ compilers written in Rust. &gt; type safety, concurrency and c++ syntax!! Writing a C++ compiler using Rust does not make C++ type, memory, or thread-safe.
Thanks for the answer. Just a clarification: &gt; Rust cares about correctness more than it cares about convenience. The "correctness" here is about the concepts of ownership and lifetime, right? Because nothing prevents me from redefining my function "generate " like this fn generate(mut generator : &amp;mut rand::ThreadRng) -&gt; u32 { generator.gen_range(1, 101); generate_deeper(&amp;mut generator) } fn generate_deeper(generator : &amp;mut rand::ThreadRng) -&gt; u32 { generator.gen_range(1, 101) } and temporarily borrow the object away to another function which mutates the state of my original object.
Seems like this would be nice to have integrated into `init` with a flag to disable for those projects that aren't planned to be published.
It's a general thing. Rust requires explicit `&amp;mut` because it's too easy to make mistakes without it. Rust panics on integer overflow in debug builds because that's often not what you want. It requires you to explicitly handle every `Result` and `Option` because it's too easy to forget. It's not just about memory safety, it's about helping fallible programmers not make mistakes that are easy to make. It's about having a pervasive attitude of "get it right, even if it's inconvenient". As for that example, rewriting it hasn't changed anything. From the perspective of the code calling `generate`, it is passing a mutable borrow into another function. What it does with it from that point is `generate`'s business.
Works fine and dandy. Thanks. https://gist.github.com/rust-play/4112e351c9a3d52404a705ff5094c7bd
[removed]
I think those libraries probably shouldn't try to offer anything, just have their normal APIs, and allow users to use them normally. People who want to use them on threads that shouldn't block can use thread pools to offload the work.
You are not alone. I've been concerned about the ergonomics initiative as well, for the general sacrifice of explicitness of the language (automatic match dereferencing anyone?). The auto-unwrap example is not appropriate though.
Neither Swift nor Elm has substructural type, which is the primary difficulty of Rust.
You’re not wrong, it’s stable in the next release.
The problem with the word ergonomics is that there are "code ergonomics" and "mental ergonomics", they aren't entirely exclusive, in that code ergonomics (e.g. currying, implicit casting, type deduction.... etc), can be equated with mental ergonomic in many situations, since they provide an easier mental model for the person writing, reading and refactoring the code. The issue with code ergonomics, as the article points out, is that they can often help a bit with mental ergonomic... up until they don't, up until they don't work as expected and obscure, hard to detect and hard to fix bugs break lose. There's good examples of languages with very un-ergonomic code that actually serve to make it more ergonomic to understand. Good examples of this are things like LISP and Golang, languages which have rather ugly code that's quite easy to understand, simply because they deal with a very small amount of concepts. In that sense, Rust is very ergonomic in a strange way, not because the code is ergonomic or because it deals with few concepts, but because it's very ergonomic to review, extend and refactor code. You can take a hacksaw to a Rust codebase and, as long as the compiler says you are in the clear, your changes are likely not to break the whole projects. Where'as refactoring a codebase in a very "ergonomic" (in terms of code) language can result in an array of obscure bugs which simply didn't show up in the original, because suddenly one of the mechanisms used to make the code smaller has meet with a buggy edge-case.
&gt; For now, I think I’m going to switch gears and finalize TLS support in the Resolver since the creation of 1.1.1.1 Very neat, any plans for HTTPS support as well? There are a lot of networks that will block 853 or traffic that isn't DNS or HTTP/S
Wait... What. I'm in a hurry, so I'll think about this more later, but I'd like to register my bemusement that types with a "forall" sign in them are called "existential" by haskell. There's probably a good reason but quite literally the definition of universal quantification is "forall x" and existential quantification is "exists x".
Hi fellow Rustaceans! :) Can someone explain to me what is the difference between my_string.as_ref() and my_string.as_str(), where my_string is a String? I thought they were exactly the same thing. However I ended up with a code that worked with as_str() but didn't work with as_ref(), getting me this error message: type annotations required: cannot resolve `std::string::String: std::convert::AsRef&lt;_&gt;`
Yes, the lack of `exists x.` can be rather confusing even to seasoned Haskellers, but there is a good reason. Read https://stackoverflow.com/questions/14299638/existential-vs-universally-quantified-types-in-haskell for some more notes on that.
Why do you need exactly those lifetime rules? A mutable reference works slightly different than an immutable reference. You might think that the code with the reference would work under any condition, but that's not true. Rust code has the interesting property of safety *not* being an emergent property: whether your code compiles should not depend on the implementation of add or the contents of Foo and Bar, just on the declaration of add and its usage in the main function. So, let's take a look at the following implementation: struct Foo&lt;'a&gt;(Vec&lt;&amp;'a Bar&lt;'a&gt;&gt;); struct Bar&lt;'a&gt;(Cell&lt;&amp;'a mut Foo&lt;'a&gt;&gt;); impl&lt;'a&gt; Foo&lt;'a&gt; { fn add(&amp;'a mut self, bar : &amp;'a Bar&lt;'a&gt;) { (self.0).push(bar); (bar.0).set(self); } } The above code would compile fine, since the lifetimes of the two arguments are identical. fn main() { let mut foo = Foo(Vec::new()); let bar = Bar(Cell::new()); foo.add(&amp;bar); } ... And now what? You can't add a second bar to foo, since then you could unwrap both Bar structs and retrieve two mutable pointers to the same struct. You can't drop bar before adding a new Bar structure, since then the bar reference in Foo would dangle. In other words: you're pretty much screwed. In reality, it's actually worse: you have bar and foo pointing to each other... Which one are you going to drop first? You accidentally created a reference loop. Those are the *worst*. In the case of shared references which do compile... The compiler applies some NLL variadic lifetime bullshit in that case. About the same reason that &amp;'a mut &amp;'a () pins the lifetime 'a while &amp;'a &amp;'a () doesn't. Sometimes, lifetimes are weird.
`as_ref` comes from the [AsRef&lt;T&gt;](https://doc.rust-lang.org/std/convert/trait.AsRef.html) trait. `String` implements `AsRef&lt;str&gt;` and `AsRef&lt;[u8]&gt;`, so `my_string.as_ref()` could be `&amp;str` or `&amp;[u8]`(or maybe some other types) depending on context. In cases rustc can't quite figure out which type it should be, rustc will give you the 'cannot resolve' error. `as_str`, on the other hand, is directly attached to `String`, and will always return `&amp;str`.
Dipping my toes in with the classic music-visualisation-via-an-LED-string, on a Raspberry Pi. I can report that the most frustrating thing I've had happen so far is the lack of implicit int coercion, so things are going pretty well. The main challenge will be implementing the Constant-Q transform, which is far superior to a regular Fourier transform for musical analysis. Credit to /u/pluxx who wrote the LED-string-to-Pi interface libraries I'm using!
First time writing rust after lurking the subreddit for years. Took a very simple C++ program (read text file by line and replace text using a regex) and rewritten it in Rust. It's incredibly faster on first try, I'm surprised!
Thanks! It puzzled me for a long time (several days actually :/). Because I passed this my_string.as_ref() to try_from, with the implementation defined like so: impl&lt;'a&gt; convert::TryFrom&lt;&amp;'a str&gt; for Sequence { (Sequence is just a type I defined). So I was doing something like this: use std::convert::TryFrom; let sequence = Sequence::try_from(my_string.as_ref()).unwrap(); As soon as I replaced as_ref with as_str, no problem anymore. If I'm not mistaken, deep down in Rust &amp;str is just &amp;[u8] right? So maybe that would explain that the compiler cannot be sure which one of AsRef&lt;str&gt; and AsRef&lt;[u8]&gt; I want? 
I'm a web developer and my "main" languages are Ruby and Javascript, so Rust is a bit of a curve ball. Here's one thing I can't figure out: Is it possible to use the index part of the `enumerate` tuple to compare against another part of the collection? [Here's a playground example](https://play.rust-lang.org/?gist=90ac1b401bce9de3298022339731b477&amp;version=stable) of what I'm wrestling with. Basically if the value of the current item in the Collection is equal to the value of the element half way around (treat the collection as circular): add it together. If not, add zero. [Here's how I did this in Javascript](https://jsbin.com/neyuqop/edit?js,console,output) if it helps.
IntelliJ's rust plugin is really good. 
Here's the pattern: *the core* should be push-based instead of pull based. Instead of providing T: Read or T: Write, call a function repeatedly with &amp;[u8] which 1. mutates an internal buffer and 2. provides whatever results it can, incrementally. Then, this API can easily be wrapped in one that deals in either Read/Write (for blocking code) or whatever the async equivalent is in tokio. And don't assume that just because this supposed de/compression library does CPU-bound work that it means it will always be used in a separate thread. It can be totally reasonable to asynchronously stream data from a socket to a decompression library in the same thread, as long as we can assume it will be doing incremental work on incremental data. 
Slowly adding more functionality to this simple markdown editor for linux [markdown-rs](https://github.com/nilgradisnik/markdown-rs). I'm building it mostly for myself, hopefully some day it will be useful enough for wider audience.
I might direct you to looking at Programming Ruby from O'Reilly. Chapter 10 is all about Enums and Patterns - it's a great book if you don't already have it. It is a great supplement to the Rust book that the Rust maintainers are writing. I've got it on Kindle and print, and I refer to it often. Don't worry - there's lots of tricks and ways to get things done that you want. It's a giant learning process with any new language. Rust is low-level enough that it's going to take time to master.
I put this down to magic. I don’t like magical things, it’s why I don’t like interpreted, dynamic languages. Into::into and ? are borderline magic, but at least they are explicit magic. For Into, to remove some magic and make code easier to read in non-obvious long chains of conversions, I often revert to Type::from instead, specifically to make the code more self-documenting. I get the fear on some of these things, but for example I’m very excited about impl Trait, specifically in return positions. If you’ve ever run into needing to return complex structures, especially boxed Fn or FnMut (I mean Box&lt;Fn&gt; not nightly BoxFn), then this is a god-send. One reason I’m very worried about the introduction of async/await is that it is very magical. Understanding what’s going on under the covers is not going to be clear for many, me included. Yes, I’ve read all the blog posts and I mostly understand why it’s safe and what’s going on, but it still is paving over a lot in the desire for ergonomics... Fear of the unknown, I’ll get over it.
&gt; If I'm not mistaken, deep down in Rust &amp;str is just &amp;[u8] right? So maybe that would explain that the compiler cannot be sure which one of AsRef&lt;str&gt; and AsRef&lt;[u8]&gt; I want? Yes, `&amp;str` has the same representation as `&amp;[u8]`, but no, it has nothing to do with the ambiguity. The point is that `as_ref()` is a method with a generic return type and no arguments. So unless the compiler can figure out the desired type from where you use the result, it has no chance knowing what you wanted. And `try_from()` is a method with a generic argument, so no help there. (You could argue that the compiler should look at all implementations of `TryFrom`, and recognize that there is none for `&amp;[u8]`. But that would make all this code break once somebody did add an impl for `&amp;[u8]` (or maybe generic `&amp;[T]`).)
Or to say what above comments have already pointed out in different words: the type safety and concurrency come from the compiler's input rather than its output, so obviously you'd lose these things if you change the input format.
There are particular reason your need a cortex over a generic microcontroller? 
The problem is that there's nothing stopping you from writing this: impl&lt;'a&gt; convert::TryFrom&lt;&amp;'a [u8]&gt; for Sequence { ...and then your second snippet would suddenly be ambiguous. From the compiler's view, `my_string.as_ref()` would be of type `&amp;T` where `String: AsRef&lt;T&gt;` and `Sequence: TryFrom&lt;&amp;T&gt;` (lifetimes omitted). While there's only one type(`str`) satisfying this in this case, there can be multiple matches in similar cases, and the compiler doesn't really try to solve this(It seems). As for `str` and `[u8]`, yes, `str` is just `[u8]` with UTF-8 encoding, but no, the type checker doesn't know that.
The borrow checker? Yes it's new, and yes it's hard. My point was that at launch, there weren't many industrially popular languages in the ML family. Since then Scala has continued to grow and Elm and particularly Swift have gotten a lot of attention. Hence the borrow-checker is now the only thing. Additionally NLL is addressing many of those paper-cuts. Any new language that's worth learning will have something unfamiliar: Java's use of interfaces was unfamiliar when it was launched; Python's use of decorators was pretty alien; C#'s async/await tool a lot of explaining; as did Go's go-routines and error-handling; Swift added ML type systems with associated types; and Rust adds linear-typing with a borrow checking. So long as it's just one new thing, I think it's fine. If Rust reaches parity in every other area, I don't see why it shouldn't succeed, particularly given that the borrow-checker gives you (mostly) compile-time memory-management and data-race detection.
As you noted, in Rust it is more complicated, because instead of a `Box` you might want to use `Cow` or `Rc` or `Arc`. You don't have to make that choice when just using garbage collection.
Thanks! Was searching for something like npmhub ;)
I wanted to write a post about this for a long time, and I'm glad someone managed to echo my thoughts on ergonomics so neatly :) There is definitely a balance to be struck there, and I feel Rust is increasingly tipping it under the usual excuse of "beginner-friendly". On an (un?)related note, I find it concerning that the author felt the need to preface his well-worded post with this strange, lengthy disclaimer. Are we really so eager to assume bad intentions from anyone who dares to criticize the language in general terms?
I do. Will get a api key asap
Thanks, I commented on the issue tracker, but now I'm not sure if `$crate`will solve my problem.
&gt; I am personally a bit cautious about gfx-rs and I think that Vulkan is a better candidate for "one cross-platform graphics API" This is super misleading, since [gfx-rs portability](https://github.com/gfx-rs/portability) is implementing Vulkan. gfx-rs (master branch) itself is pretty vulkanic. If you want to write pure Vulkan, great. You can then decide to use the portability layer to get it running on Metal/DX12/GL/more. Or you can call gfx-HAL directly right now to avoid C layer roundtrip.
Yess, this is so cool! Real excited to see what comes out of it! 🎉
&gt; I think the idea is to give you a quick initial estimate, including marking those functions which could use a dynamic amount of stack space so that you can manually analyze those to determine how their usage depends on inputs. That's is true for dynamic or divergent functions. For fully static call graphs I do want to give exact values, ie an upper bound rather than a lower bound. What I explicitly do not support at the moment are jump tables (because those are *much* harder to analyze than the other instructions, and can be disabled) and everything interrupt-related. Interrupt frames are not included in the estimations of this tool, and interrupts messing with the process stack are assumed to not exist to preserve the sanity of the endeavor.
Yeah, you can actually use it in rectangle mode by disabling the use of X11's SHAPE extension by defining `XCOLOR_DISABLE_SHAPE`. I guess I could look into how to do proper antialized shaped windows with something like compositing but I haven't gotten around doing that yet. 
I love what you guys are doing, but can I make a request? These updates would be _way_ more interesting if you gave a TLDR. Roughly what challenges did you face? What are the biggest additions? What is the progress on major goals? Thanks for everything you are doing, but I feel like these get completely ignored because they are missing _a few sentences_.
It seems that capnp starts spreading into other languages. Unfortunately, only the serialization is implemented for most of them, without the RPC layer. And RPC is probably the most interesting part of capnp.
I think Skype became a Skype killer. The latest versions are dreadful!
Works great, but I had to look very closely to find the Firefox version. Can it get a nice big image like the one for the Chrome webstore?
As an exercise in showing how LR works, this was an interesting article. However, I'm unconvinced that this would be a good approach to implement in a real system when the grammar might change in the future (and they pretty much always do). When things change, I think it'd be difficult to keep it correct, and there are lots of tools to help (such as bison and ANTLR). I've implemented several recursive-descent parsers; their simplicity makes it practical to do directly. But recursive-descent, if you're going to use it, seems to cry out for tooling. Does anyone have a different experience? 
I can't quite see how this statement can be misleading, as it's purely my subjective opinion and it does not contain any statements about gfx-rs API pros or cons. In short I fully agree with positions voiced by tomaka and rpjohnst in the internals discussion and I think there is no need to rehash them. &gt; You can then decide to use the portability layer to get it running on Metal/DX12/GL/more. Or you can call gfx-HAL directly right now to avoid C layer roundtrip. This can be read as "gfx-HAL re-implements functionality already implemented in C portability layers". Do you have any numbers about performance cost of the "C layer roundtrip"? By no means I am saying that work on gfx-rs is unnecessary (adoption in the Rust ecosystem speaks for itself), but in my opinion if you are not targeting platforms without any Vulkan support (e.g. consoles) it's better to use pure Vulkan.
What properties would folks verify? The formal certification stuff I've been most curious about is race conditions in lockless/wait-free data structures, because iiuc there's no other way to have any real confidence in them.
&gt; Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: &gt; The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. Yeah as long as you include it unchanged you should be fine
Author here! I agree, take everything with a grain of salt. A bit of context. As someone involved in a local gamedev community **and** a lot of interest of Rust, I was asked to summarize on a talk some information on the state of gamedev on Rust. This happened around late December. The article is just a transcript of my personal notes for the talk. This is also the problem with Three.js. It fall under my radar, I was interested in it, but at the time there was only a 0.1 release dated June 2017. I was not sure about how much momentum the project had, so I skipped it \(sorry about that!\). I wanted to integrate the article with more updates, but then this article pop\-up here... :\) Well, I will definitely put Three.js in the followup. I promise. :\)
The extra branch is that every call to `poll` needs to know if it's the first.
The high compression ratio for Rust binaries suggests that more could be done at the compiler or library level to reduce code duplication. I know that currently Rust generates more code than is strictly necessary when it comes to generics and most library authors (assumably including the authors of `std`) are not aware or willing enough of this to work around it
Goals * Develop formal foundations for the Rust language (RustBelt). * Extract required information from the compiler * Design methods to formally verify programs written in Rust * Investigate ways to combine program verification with broader testing frameworks https://rust-lang-nursery.github.io/wg-verification/ ;) 
Still working on the Rust plugin for lldb. Last week I found out that I need to implement namespace handling in the plugin, so I plan to work on that this week. That will make name lookup work in the expression evaluator.
I saw that, but I was looking for something more concrete.
&gt; I can't quite see how this statement can be misleading ... If find it misleading because it views pure Vulkan and gfx-rs as distinct alternatives. They hardly are. &gt; This can be read as "gfx-HAL re-implements functionality already implemented in C portability layers". Not sure what you are getting with. Do you mean gfx-HAL re-implements what is already implemented in Molten? Or gfx-rs portability? Neither would be correct. &gt; Do you have any numbers about performance cost of the "C layer roundtrip"? Not yet. We are currently focused on correctness. My [portability overhead](http://kvark.github.io/api/3d/vulkan/2017/08/10/gfx-overhead.html) article seems relevant, but it doesn't have numbers either. &gt; if you are not targeting platforms without any Vulkan support (e.g. consoles) it's better to use pure Vulkan. On windows, you might have to target DX12 soon: see slide 39 of [Vulkan-Whats-New](https://www.khronos.org/assets/uploads/developers/library/2018-gdc-webgl-and-gltf/1-Vulkan-Whats-New-GDC_Mar18.pdf). On MacOS, do you consider Vulkan to be supported? If yes, it's not much different than just using gfx-rs (with or without portability) 
Rust by example has the [answer](https://doc.rust-lang.org/stable/rust-by-example/attribute/cfg.html) for your troubles (you can also do [custom](https://doc.rust-lang.org/stable/rust-by-example/attribute/cfg/custom.html) configs).
&gt; It fell under my radar, I was interested in it, but at the time there was only a 0.1 release dated June 2017. I was not sure about how much momentum the project had, so I skipped it (sorry about that!) Generally, community members interested in rust-gamedev tend to track /r/rust_gamedev, where you could see [three-0.3 announcement](https://www.reddit.com/r/rust_gamedev/comments/7zx5e3/threers_03_is_released_with_gltfpbr_powers/). &gt; Well, I will definitely put Three.js in the followup. I promise. :) Thanks! Just make sure to not mistake three-rs with Three.js, ok? :)
Excellent!
I've participated in many online discussions and I know that even people that are *sure* of the intentions and know me in person can misunderstand written text. And I was aware this could lead to a nasty flame war. I wanted to forestall that.
The current desugaring produces two functions: one that constructs the future, and the other that dispatches on its current state and runs a segment of it. If the code up to the first await were moved to the constructor function, that would remove one state from the poll function. If the source function had no awaits at all, this would remove the need for a branch in poll. (If there were *one* await, poll would still need to dispatch between the first resume and the "resuming a completed generator" case.) This isn't very meaningful, but it does *technically* mean the current design *might* have an extra branch in a fairly rare situation.
Spent last week working on a HAL for the stm32f469 processor family. Got GPIO OutputPin and InputPin implemented and just programmed up an example program to put on my discovery board. I'll be continuing with my work on the HAL and the start of a board specific package for the discovery board. Also, at some point a crate for working with the stm chrom-art accelerator a 2D DMA engine for image processing stuff that's on the f469 and f479 processors.
I'm wondering how to run a task recurrently in **actix**. Something like [Running code on an interval](https://tokio.rs/docs/going-deeper/timers/#interval) from Tokio guide. Basically running some code every 15 minutes starting at some time point X.
do you have a use-case that you're using `uom` for? you remember that I developed [metric](https://github.com/coder543/metric/) awhile back, but since I don't have any actual use for a typesafe numeric library, I'm no longer actively developing it. You've been going strong on `uom` for a long time now.
Yep—it's a tension that I'm not sure is resolvable in Rust. I'd like the language to be more of an OCaml-style language, but I'm not sure possible in several key ways. (the example above is one.)
[removed]
This recent post may be helpful for the Rust side: https://www.reddit.com/r/rust/comments/8asfvz/the_state_of_game_development_in_rust_davide/.
Pretty much any language will do \_just fine\_ for game development, especially if you're just learning. Use whatever you're most comfortable with.
Use whichever language you know best. I've written games in Lua, Go, JS, C... it really doesn't matter.
That's an oddly specific date. Do you have any source to back up that planned release date?
I'm on mobile, but it was announced just like that on withoutboat's blog.
huh, and [so it is.](https://boats.gitlab.io/blog/post/2018-02-22-failure-1.0/) I definitely haven't heard anything about it. /u/desiringmachines
This is actually REALLY sweet! I've been theorizing in my head that between `serde` and `wasm` it should be possible to write most of the stack in a web app with only Rust...and now you've got this sick boilerplate. Kudos! I'm definitely excited to try this...
Is there a formal list of *all* active teams and WG's somewhere? A quick search didn't turn up anything concrete, all we see is these announcements being made from time to time, but I'm not seeing what the "big picture" is wrt. Rust language development.
To be that guy, groups don't play much of a role in Haskell. Groups are awesome, though.
&gt; On the other hand, it is an extra, special rule in the language that hides from the programmer how a method truly works; the extra rule also adds extra complexity. You've put your finger on one of the little things that has repeatedly frustrated me about Rust. Not so much the "big" things that are understandably novel and tough like lifetimes, which I'm somewhat equipped to study and understand (IIRC they're phantom type parameters on references used to track their allocation and drop sites at compilation time, with a subtype relationship between them to track which lifetimes outlive which). No, the things that keep frustrating me is the number of cases like this where the language does some implicit, invisible "magic" in the name of ergonomics that makes it so that I need some background knowledge to grasp some key fact about any line of code. You write some seemingly simple line of code but what it will actually do turns out to hinge on whether one of the types involved implements or not some built-in trait you've never heard about. And it goes right to the core—even assignment statements work completely different depending on whether the type is `Copy` or not.
 The Nim's readme say "its a compiled, garbage-collected systems programming language which has an excellent productivity/performance ratio. Nim's design focuses on efficiency, expressiveness, elegance (in the order of priority)." Nim include features like a deterministic soft real-time GC that allows for its max pause time and supports manual memory management. Other features, compile to C (C++, Objective C, or JavaScript), strongly statically typed, powerful meta-programming, compile-time execution, easy to read (Python like syntax), and local type inference. It is multi-paradigm supporting, imperative, minimal object-oriented (encouraging composition over inheritance), functional procedural styles. Some tools like a package manager (nimble), C2nim (C and C++ bindings), and Nimsuggest. Also these a game development framework and are two cons are the bus factor and not release yet. Rust's website say " is a systems programming language that runs blazingly fast, prevents segfaults, and guarantees thread safety." Features include, CFFI, immutability, robust meta-programming, RAII, modern type system, strongly statically typed, compiles to native code, safe rust by default (you can unsafe too), immutability, fine grained control over memory, and modules. It is multi-paradigm supporting, concurrent, functional, imperative, structured, and generic procedural styles. Some tools like Cargo (a package manager), RLS (Rust Language Server), rustfmt (formating), clippy (lints), and rust-bindgen (Automatically generate C or C++ bindings). Coming features are generators/async/await, SIMD, custom allocators, and compiles to WASM. Also verysus resources and strong game dev community. I took two intro programming courses well in school ( JavaScript &amp; Python). Both are memory safe and can do low-level programming and between Nim or Rust which one is more susceptible for game development? Thank you for the advice. :)
I think the first version of something like this was [hoogle](https://www.haskell.org/hoogle/).
Yeah, I feel similarly about the module system. I loved the simplicity of the old one and probably won't ever use any of the new sugar, but it's clear to me (just from looking at recent Rust repositories) that a ton of people were desperately waiting for it. I certainly wouldn't want to deprive other people of a module system they actually liked just because I thought the current one was really clean. As a counterexample of somewhere where I think an ergonomic change was almost made that could have hurt: I fought *vigorously* against stabilizing safe `catch_panic` without adding the `PanicSafe` speed bump, even though it's not a memory safety issue (the auto trait is safe, after all). I think that's a good example of somewhere where there was a lot of tension between ergonomics and correctness; at first, it had way too many false positives and people wanted it out. Fortunately, people were able to tweak enough that the primary use case (C FFI boundary catching) wasn't really affected unless you actually did have a possible panic safety issue. What I've learned from experiences like that (and the main thing that attracted me to Rust) is that the core team and community do generally care about correctness and rarely rush to make a decision if there are serious outstanding concerns and a concrete proposal to fix them.
You might as well look into D and Scala-native while you're at it.
Scala-native?
As a game developer, my main concerns are in portability. Rust needs to have official support on all platforms, PC, PS4, XB1, and Switch. You don't want to make something cool like shovel knight, and then be unable to do that switch release because you locked yourself into Rust. My other concern is performance. Theoretically this should be great, but it needs a killer app to highlight it. Like a single game demo that can do stuff that C++ could never achieve that would get people excited. 
then it has to be slightly different c++ compiler. (dialect).
Hello Rust! I'm working on a rust implementation of a Voroni Diagram construction, in which I have to construct a Doubly Connected Edge List. I'm having some trouble with getting a few of these ownership issues down. I got rid of the more irrelevant info, here's the code: struct Vertex&lt;'v&gt; { index : u64, x : i64, y : i64, incident_edge : Option&lt;&amp;'v Edge&lt;'v&gt;&gt;, } ... struct DoublyConnectedEdgeList&lt;'d&gt; { vertices : Vec&lt;Vertex&lt;'d&gt;&gt;, } ... impl&lt;'a&gt; DoublyConnectedEdgeList&lt;'a&gt; { pub fn new_vertex(&amp;mut self, x : i64, y : i64) -&gt; &amp;'a Vertex&lt;'a&gt; { let v = Vertex { index : self.vertices.len() as u64, x : x, y : y, incident_edge : None, }; let reference = &amp;v; self.vertices.push(v); &amp;reference } } I want the method new_vertex() to return a reference to a vertex which was added to the list of vertices in the DoublyConnectedEdgeList, but Rust doesn't think that the reference I'm returning will last long enough. What can I do here?
Thanks a lot for the explanation! Now it all makes sense to me, and I understand that the compiler did the right thing by refusing to compile.
Thanks, I understand now. The compiler is choosing the safest path by not compiling a code that may become ambiguous later (if someone adds an impl for &amp;[u8] as you say).
You have several options: 1. Just use tokio 2. Use [AsyncContext::notify_later()](https://actix.github.io/actix/actix/trait.AsyncContext.html#method.notify_later) or [AsyncContext::run_later()](https://actix.github.io/actix/actix/trait.AsyncContext.html#method.run_later]
It’s so amazing to watch how quickly the embedded work is progressing. Nice work! 👏
Why don't you do it? I'm sure it's open source.
Sorry for breaking the rules, this may fall under 'memes'?
&gt; And it goes right to the core—even assignment statements work completely different depending on whether the type is Copy or not We tried that, by the way, having to write "move" everywhere to move. It made the language really annoying to use: you'd have to write things like `bar(move foo(move a, (move b) + (move c)))`; So "moves based on type" was suggested by Niko and implemented.
what am I doing wrong? (ubuntu 16.04 vagrant) rustc 1.25.0 (84203cac6 2018-03-25) vagrant@homestead:~/webchat-rs/webchat-client-rs⟫ make run cargo +nightly build --target wasm32-unknown-unknown --release error: toolchain 'nightly-x86_64-unknown-linux-gnu' is not installed Makefile:13: recipe for target 'target/wasm32-unknown-unknown/release/webchat_client_rs.wasm' failed make: *** [target/wasm32-unknown-unknown/release/webchat_client_rs.wasm] Error 1 https://i.imgur.com/aHh4Znl.png 
Yeah, I'm also in the weird position of still using `try!` (unless the code I'm contributing to uses `?`) but not being opposed to `?` being added to the language.
Yes.
I'm not personally using `uom` for anything currently. I've used a similar library in another language at work and seen the huge value that it provides. The first commit was nearly two years ago now and it gives me something to do when I want to pretend I have much free time. There has also been a bunch of PRs from others recently which is exciting and is hopefully providing some value in the projects they're working.
I'm not very experienced with Rust and don't know anything about Nim, however it's true that the ecosystem is still growing (I would disagree with the language changing a lot still -- the language itself is stable though occasionally some non-breaking updates are added). That said there are definitely folks diving into game dev with rust -- see /r/rust_gamedev/. But if you choose rust be prepared to have to help build the ecosystem and not just be able to use freely available toolsets. I'm guessing the story is similar for Nim but I don't follow that language much.
Nim, Rust, D or Scala-native which one is more susceptible for game development? 
Even though this is probably fake, I could actually imagine a crazy back-end where this could make sense.
I'm using mi lights with a custom controller. does the color bulb have separate warm cold white leds together with the colored ones or they abusing them for white ?
I would strike D off that list. D is an okay language, but it just never caught on. D has been around for twice as long as Rust, but it still is only used by a small handful of companies usually in a limited capacity. Rust is already more widely used.
r/rustjerk
Is there a comparison between this and RocksDB anywhere? I’m not very familiar with either, but we might start relying on rocksdb at work, and I’d love to evaluate if we could potentially use this instead. Thanks!
Depends on what you're looking for? I can see cases where you can pick any one of those four and I can see cases where you might pick something different. Are you just trying to hack together a game? Pick up an off the shelf game engine like Unity or Unreal. Enjoy! Are you trying to learn game development? You should probably stick to something that you feel the most comfortable in; try to have fun and learn the concepts not the libraries. Are you looking to break into the industry? C/C++ is pretty much your only option, unless you're looking to make mobile games (even then, C/C++ is a huge boon). Personally, I'm at the "learn game development" stage and I've chosen Rust as my language. Why? Because I don't want to use a GC'd language and I like Rust. Pretty much it. Maturity of the libraries isn't too much of a concern for me, I just needed enough to get things running at a basic level so I could start rolling my own stuff. `ggez` and `amethyst` are pretty awesome, so if you go down the Rust path, check them out.
Extending rustc-perf so it can be used for local profiling, not just CI regression detection on automation.
Garbage collection is a no-go!
Rust API design has generally taken a pretty strong stance on `unsafe`, that it's meant *only* for operations that could cause memory safety violations, either now or sometime down the road. If this doesn't apply, then `unsafe` is not the right indicator. The concern is that frivolous use of it confuses the meaning and diminishes its utility as a flag for code review and debugging. There's obviously nothing stopping you from using it for something like this, but it's going to make anyone reading your docs very suspicious. IMO, just naming the constructor `new_unchecked` should be enough.
That's perfect! Thank you so much! Just so I understand, in order to make the reference I pass back match the lifetime of the DCEL, I need to specify the lifetime of self? I assumed that the lifetime of self could be derived from the struct name and "impl" name (which have 'a scattered around everywhere)
The lifetime parameter on `DoublyConnectedEdgeList` is for the `Edge`s in `incident_edge`. It doesn't say anything about the lifetime of the `DoublyConnectedEdgeList` itself. The edges could live longer than the list, or they could live shorter.
 Any technical reason to take D off? &gt; Rust is already more widely used. Rust doesn't even make it to the top 50 in the TIOBE index. 
I'm trying to level up my understanding of rust lifetimes, and I'm writing a small binary that reads a file, and grabs each "line" and then prints it to stdout. In writing my iterator I'm struggling with lifetimes, but I also think that I'm doing some bad juju with mutability as well. My immediate issue is an error about expecting ':' but getting 'mut' But, I bet I have some other no no's going on as well in this code. All comments are welcome and appreciated as I'm still learning some more advanced rust techniques. Thank you, https://gist.github.com/drusellers/4f0e8b0ca92298bd3db0d3fe35ea3cec 
Nim does not give you the same memory safety without overhead benefits that Rust does. In Nim, you use GC within a single thread, and copy data when sending between threads, or you write unsafe code. In Rust, is is possible to safely share data between threads, and the compiler can guarantee that safety without introducing GC overhead. For example, Rayon is a library that makes it very easy to write parallel code, which will break down a problem into smaller subtasks which will be farmed out to a thread pool, and for which the data is all borrowed from a variable in the parent thread; it's not copied between threads, and there's no GC or reference counting going on, each thread is just getting a sub-slice of the input data to work on, and other than using `par_iter` instead of `iter`, the code is exactly the same as you could write for the single threaded case: use rayon::prelude::*; fn sum_of_squares(input: &amp;[i32]) -&gt; i32 { input.par_iter() // &lt;-- just change that! .map(|&amp;i| i * i) .sum() } Rust is also a more mature project; it's reached 1.0 and so has backwards-compatibility guarantees. It's being used in bigger projects, like Firefox, for implementing quite complex tasks like GPU rendering and compositing in parallel in ways that are much easier to implement in Rust than in C++ or Nim because of this very feature, the ability to share data between threads safely (which C++ can't do) and without GC or copying overhead (which Nim can't do). By the way, there is a [rust compiler which compiles to C](https://github.com/thepowersgang/mrustc), though it's still a work in progress (it can compile the Rust compiler itself however, so it has pretty complete coverage), and Rust is able to compile to WASM which is a more appropriate target for running in the browser for a language like Rust than compiling to JavaScript (technically you can compile to ASM.js, a restricted subset of JavaScript used as if it were an assembly language, with Emscripten, but these days compiling to WASM is a lot easier). One thing I will note is that the learning curve for Rust will probably be steeper than for Nim. But I think that it will be worth it in the end, for code that is more maintainable, and gives both better safety and lower overhead. I'm not an expert in gamedev, but it looks like the libraries for gamedev in Rust are a lot more mature, and actively developed, than those in Nim. Of course, coming to the Rust sub you're going to get an answer favoring Rust; I see you've already asked in the Nim sub to get their thoughts.
For game dev I would go with Unity3d or c++ with Unreal Engine.
Any chance there could be support for just Rc? Persistence can be very useful in single threaded stuff too. I assume we need HKT in order to template everything on that though.
The competitor to RocksDB in Rust is [sled](https://github.com/spacejam/sled), but it's listed as being very early and not really ready for production use yet.
Wanted to be able to step thru unit tests in vscode, and ended up creating these launch.json and tasks.json files. Thought someone might find it useful. Requires jq. Inspired by this open issue: https://github.com/rust-lang/cargo/issues/1924
Yes, and wasm32-unknown-unknown target. I'll amend the instructions.
I believe it's the borrow checker and the gc simplifying a lot of the 'reference game'. Especially on collections. I think it's a bit telling that Rust has a weak 'collection game' on the stdlib compared to Java. It's just that hard to make it correct and safe. I'm not dissing the many clever hacks that rust came up with in their quest for safety, ergonomics and performance of their collections, but it's obviously not as easy to extend or add-on to them as in Java and things like guava, glazedlists etc.
Thanks! I did consider making the entire frontend DOM construction and code rust as well, but that would've been a distraction from the point of the exercise. Also, making the form submit handler that way would've been awkward I think.
I guess they abuse them. White is just 255 255 255 for them.
&gt; slightly different Try "fundamentally different". You could get _some_ modest memory safety improvements with a restrictive dialect of C++, but there are a couple of main reasons why nothing like this has ever taken off: - It's no longer C++. It might look superficially like C++, but it's no longer C++ in any sense that matters; you can't use any of the existing tooling that's out there. If your dialect allows using the existing C++ library ecosystem, then you're probably not getting much value out of the restrictions. If your dialect _doesn't_ allow using the existing C++ library ecosystem, then you have to build everything from the ground up (like Rust has had to do). - It's not enough of an improvement for anyone to care. The barrier to most people investing in a new language is _huge_. If you want them to put in that kind of effort, you need to show up with a lot more than "a bit more memory safety". Rust would never have enjoyed the success it is seeing now if it was merely C++ plus memory safety. So what I think you're actually looking for is either: - Static analysis tools for normal C++, and excellent tools like Valgrind to help you find your memory errors at runtime; or - Rust. If it was possible to have a "slightly different" dialect of C++ that gives you memory safety and that people would actually want to use, then Rust would have become that. 
&gt; Any technical reason to take D off? The last time I was playing with D was several years ago, so I don't know how out of date my problems are. I also don't do game development, so I don't have anything to go on there. I do know that D has been blocked from at least the AAA game space by its reliance on garbage collection. &gt; Rust doesn't even make it to the top 50 in the TIOBE index. True, but the TIOBE index has its limits. I've kept an eye on both communities, and the D community is by all indications smaller, less energetic, and progressing slower. A comparison of "companies using our language" pages reflects this: Rust has over a hundred companies listed, while D has only around 20.
The syntax error occurs because you can't "assign" a lifetime when you create a reference. The lifetime of each reference is determined by the compiler, and must then match or outlive the lifetime you require in the signature. After removing `'file` from the offending line, the remaining problem is that `self` is already a mutable reference, and you're taking another one with `&amp;mut self`. Just `self` is sufficient and makes the code compile: https://play.rust-lang.org/?gist=a10164b5f8fbcb0c52e5fd6c56ab99be&amp;version=stable
Hope to finish up an [old clippy PR](https://github.com/rust-lang-nursery/rust-clippy/pull/1467) that I took over. Once that's done I want to continue with 'Programming Rust' for the rest of the week.
Does the `/checkout` mapping work? I used to make it a symlink, but now RLS, at least, looks under the project root.
Yes, works for me, gdb and lldb. Haven't tried debugging unit tests with gdb yet.
Nice I just read about that.
If that's a reason to strike D off, it's even more of a reason to strike Nim off, surely? Is anyone actually using Nim? To be clear, i really like Nim - it just feels like a highly polished personal project, rather than a language with a viable community.
TIOBE is based on Google searches. I don't think that's a good measure of its use. I for one use Rust _a lot_ and I don't Google "rust language." Instead, maybe consult Github activity? Obviously the metrics here have their own problems- they don't capture closed-source work for one- but I think they're at least closer to measuring activity. https://madnight.github.io/githut/#/pushes/2018/1
Makes perfect sense to me, will allow someone else to talk about whether that's the correct view though!
It seems like timeouts are the maximally interval between units of work. This is useful for a totally different way of writing about time.
Perhaps. I've never used Nim or been in any of its community spaces, so I don't have any feeling for its suitability.
Hoping to submit a chapter this week of Rust in Action to the editors. Really want time in work on my 3D arficial life / procedural generation microapp that isn't quite finished
It's more that, given a deadline, each I/O call will internally calculate a timeout from that minus the current time or immediately time out if that underflows. I think this can be pretty easily implemented on top of the current timeout-based API; we don't need to deprecate it.
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://atilanevesoncode.wordpress.com/2018/04/09/include-c-headers-in-d-code/) - Previous text "dpp" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
It looks like with betterC you lose quite a few important features. Probably enough to break a lot of libraries. I'm sure that can be remedied eventually, but Rust already gives you no garbage collection without having to make compromises or discard libraries.
I belive Chucklefish have managed to get Rust running on the consoles, but due to console NDAs, it seems unlikely to get official support or Chucklefish's changes backported into official Rust.
Amazing work! Congrats to you /u/japaric and the rest of the team!
Rust has a small stdlib because most of the collections are in third party libraries, not because it's hard to come up with a safe interface to them. There used to be a bunch more included collection libraries, but they got outsourced to crates.io shortly before Rust was released. There are exceptions, of course (notably: intrusive collections are really hard to do in Rust, although pervasive use of Pin might make it easier), but overall I find it rather easier to provide a safe interface in Rust than I do in a lot of other languages, since I don't have to worry about preserving structural integrity on iterator invalidation or incorrect multithreaded access (which will break a lot of Java collections in subtle ways that are hard to debug). I do agree that the type signatures for stuff like HashMap can be pretty daunting though, but that's more because it's trying to do stuff like be generic over the hashing strategy, automatically apply conversions for you, and accept references or values equally well. A simpler interface that didn't have that complexity wouldn't be hard to write and would pretty much have the type you'd expect. As far as actually *using* the data structures goes, I think the only real struggle is when you want to take multiple mutable references into one at once--it can be unsatisfying to use interior mutability in those cases if you know for sure your keys are disjoint. That one can't really be helped though; a lot of collections rely on safe traits like Eq and Ord when comparing keys and values, so it wouldn't really be safe for the collections to rely on those implementations actually being correct when they wanted to determine whether the two keys you based in were equal. So even if you did have a proposed API that was able to handle that case safely, it would push unsafety onto the person who defined the key type, and probably require extra `SafeEq` bounds etc. on the type for those functions, which would make the type signatures *more* confusing.
Interesting approach! It would be nice if there was an easy way to find the name of the next branch to check out. Because this way one has to rely on the list in the readme.
Well, `Copy` really is a pretty fundamental concept in Rust, in the sense that `Copy` data is precisely byte-level duplicable data. For instance, `&amp;T` must be inherently duplicable for you to even be able to call a `clone()` function that uses unsafe code without threading through `T` in the type signature. That being said, it's not strictly necessary that "duplicable at the language level" coincide with "copying happens implicitly"; but it's clear that you want implicit `Copy` at least some of the time (integers are the example people usually bring up, but I think `&amp;T` is the better one). I would still like it if the two concepts were not conflated to the extent they are today, since it causes people not to declare types `Copy` just to avoid the implicit part even if they are byte-level duplicable.
There's [a brilliant blog post](https://vorpus.org/blog/timeouts-and-cancellation-for-humans/) by the developer of trio, an async library for Python which goes into details about the different ways to handle cancellation in async systems. I'd recommend it as a read for anyone looking into these things. Yes, it's a long article but it's worth it. They also have a few earlier posts which touch upon similar issues: * [Some thoughts on asynchronous API design in a post-async/await world](https://vorpus.org/blog/some-thoughts-on-asynchronous-api-design-in-a-post-asyncawait-world/) * [Control-C handling in Python and Trio](https://vorpus.org/blog/control-c-handling-in-python-and-trio/)
yes it does! you need to load the rs-files or wasm files asynchronously though. But it works pretty well. 
Why not to track the 1.0 milestone in issues?
This all assumes that the purpose of a timeout is: &gt; "I don't want to wait longer than t to get _all_ of my data". But half the time that I use a timeout it's because: &gt; "If time t passes with _no data_ then I assume something has gone wrong upstream." These are completely different. And both should be catered for.
But then it's hard to implement the opposite case. Instead of requiring all tasks to be complete by a deadline, what if I just want to assume failure if any particular packet is sufficiently delayed?
thanks
It would be extremely useful if you could copy the result to the system clipboard (you can use the [clipboard](https://crates.io/crates/clipboard) crate for that). It's sometime necessary when I develop websites that I want to pick the color of something on the screen, but there is no good color picker that I'm aware of - I often have to take a screenshot and then pick the color that way. Copying the result to the clipboard means that you could use it as a regular desktop app, via a desktop entry, instead of invoking if from the command line.
Yup, it may not be easy to support both strategies.
I've added git source and choice question to [kickstart](https://github.com/Keats/kickstart), a tool to create projects from templates. This was originally just a PoC I made for the internal discussion on Cargo templates (https://internals.rust-lang.org/t/pre-rfc-cargo-templates/5056) but I can see it being useful, especially if the actual Cargo templates end up being only for stuff in crates.io. I'm also going to have a second look at [SCL](https://github.com/Keats/scl), a language I made for usage only in configuration files inspired by nginx. The parser is working and most of the things in the README are implemented. I left myself a bunch of TODOs so I'll try to remember what past me was thinking. Feedback on both projects is welcome!
Also this might come handy: http://arewegameyet.com/
The majority of games these days can be made by using an existing engine. I would add Godot to your list, as the 'up and coming' engine which supports GD script (based on python) and I think they added C# support as well. Also for Unreal Engine, you can make games entirely with Blueprints (their visual programming language). 
Now that's interesting. Do you have a public repo somewhere ?
&gt; I replaced some multiplication/division operations with bits shifting when I could (so on power 2 numbers). Shouldn't that be done automatically by the optimizer?
Abortion should be abstracted from time. ie should be able to compose two futures so that the latter can abort the former ```` composeCancel(request, abort_at_specific_time) composeCancel(request, abort_after_T_seconds) composeCancel(request, abort_if_user_presses_ESC) ````
Is it even needed anymore on a modern desktop/server cpu?
Apparently not.
It is (I was surprised too). I had something between 5-15% of improvements thanks to this optimization.
It was fun to do! Unfortunately, the rust complainer(tm) is so good that some of the fixes are just compiler-driven development.
[removed]
That sounds like the C# "CancellationToken" idea I've seen a few people in this thread mention
Not sure it'd work then. The part loading the wasm is generated by wasm-bindgen, so I can't change how the loading happens without some ugly patching. Optimally I would use neither, but instead have a small shim able to load either wasm or wasm2asm compiled asmjs depending on browser compatibility.
Not sure it'd work, then. The part loading the wasm code is generated alogn with the JS glue code by wasm-bindgen, so I have no control over how it happens. Optimally, I'd use neither. I'd make a tiny loader that picks a wasm or asmjs (built using wasm2asm) version of the code based on browser compatibility.
How? Currently `write_all` and `read_to_end` are broken. Can you also describe what the documentation should say in respect to timeouts for these two functions?
The problem is that it doesn't compose. See my reply to your other comment.
Also see the forum discussion at https://internals.rust-lang.org/t/safe-intrusive-collections-with-pinning/7281
Sounds like a missed opportunity, I'd file an issue.
I'm writing a proc macro with the help of syn. In this proc macro I often want to do some transformations on the syn ast, e.g. adding a field to a struct instantiation or wrapping the return type of a function. Is there a way of doing those transformations without having to write the whole huge and verbose ast node yourself?
Not exactly: e.g. I might want a 10s timeout on individual operations, and 120s timeout on the overall operation. With just a single 120s deadline, I'd be waiting 120s if the first connection attempt has hung, when we could have aborted or retried a lot sooner. It seems like both would be needed ideally.
Isn't it actually possible to make the app 100% rust code with things like [yew](https://github.com/DenisKolodin/yew)?
Still trying to find a replacement for $DAYJOB but I try to fit some Rust in as well. This month's project is [orbweaver](https://github.com/icefoxen/orbweaver/), which is intended to be something like `bindgen` for web code. The idea is that it will suck in [WebIDL](https://heycam.github.io/webidl/) files and generate a Rust crate for talking to a web browser's API. Hopefully this well help let us start treating the Web as just another operating system Main hiccup so far is that WebIDL is a typical web standard... not done yet, has gone through several iterations, and each browser vendor has their own slightly different take on it. The `webidl` crate is very nice but the only browser that provides files using the latest-draft WebIDL version appears to be Servo, so I suppose that's where I'll be starting. On the other hand, as long as the IDL's type definitions are valid across all browsers, it doesn't matter what the source of the IDL actually is.
I don't watch the show - anyone care to provide context here?
Sorry for the late reply. We probably would not add Rust nightly support just because I do not think that it would be an appropriate production-level deployment tactic. I could be wrong, but we tend to think that most production deployments are on the stable releases.
There is no such thing as "generic microcontroller".
Double post, FYI.
No, the lldb plugin isn't really usable yet. Variables being optimized out isn't something that the plugin is likely to fix. That's typically a compiler problem instead -- either rustc or (more likely IMO, but still just a guess) LLVM. One typical solution is to disable optimization. 
doesnt quote do this? Maybe im misunderstanding the problem though
The behavior of bits shifting is different than multiplication/division. It's not done by gcc or clang too so I suppose it's expected.
[removed]
Yes these are very good posts. I felt the rust APIs are so far behind so I only focused on the simple problems. Adding cancellation to the discussion makes it even more complicated.
This is wrong. What is an "individual operation"? Is it a `read_to_end`? Because even for that the current APIs do not work.
Yeah, my comments were invisible for some reason after I posted them, and I thought I hadn't saved the first one so I rewrote it. No idea why, I'm somewhat new here.
Yeah, it's great that more tools become available. I think rust has a good setup to become *the* language to write wasm in.
Nice! The more the merrier. Out of curiosity, how big are your client wasm files? My current build gives 300-500KiB size and I'm looking into getting it down a bit.
Not at the moment, for a few reasons. We'll get there! Maybe we need a "working groups" working group ;)
&gt;(though you might want some provisions to defend against slowloris). &gt; Security is always a bummer. Even defending against something like that can cause extra strain, if you're disconnecting legit slow connections, which then reconnect with the same result.. 
Thanks for the link to that article. It is a good read, but I'm not convinced that the solution proposed by the author is as great as it sounds at first. His solution is essentially the same as cancel tokens, but he makes these cancel tokens global (or thread-local) state so you don't have to pass them around. And while it is convenient not to have to pass those around, the global state does look like it has all the negatives usually associated with global state. For example, if you call `websocket.send_message(msg)` you have no idea which pieces of code have set which timeout conditions. If you're doing only one operation with one overarching timeout condition, as is the case in his examples, then it probably won't be an issue. But imagine if you're building a webserver which handles multiple concurrent connections while fetching resources from AWS or from the web, while also talking to a database, a backup system, etc etc, all with different cancel conditions. In that case I would not want the cancel conditions to be hidden global state, I'd very much prefer them to be explicit, even if it takes a little more effort to pass them around. I think it's quite similar to the situation with Futures and their context parameter. In the initial implementation, this context was hidden away in thread-local state, but after [some discussion](https://github.com/rust-lang-nursery/futures-rfcs/pull/2) they came to the conclusion that that wasn't really a very good idea, and [it was changed in version 0.2](http://aturon.github.io/2018/02/27/futures-0-2-RC/). Don't get me wrong, I do think that cancellation tokens are superior to what we have right now. Just not as global state, or thread-local state, or any other form of what is essentially shared mutable state.
I said it on the forum already, but this is truly amazing. If this pans out you can have (temporary) cycles on the stack between items in *different stack frames on the same stack*, in safe code. I'm always optimistic about being able to express safe patterns in Rust somehow, but I did not believe it would be possible to do this without extending Rust in some way.
That's correct. A timeout only makes sense if you can estimate how long an operation will take: a `seek()` shouldn't take more than a second, no matter what the overall deadline for your process is, but you have no idea how long it'll take to read a file with an arbitrary size, so the only timeout you can use is the one determined by your business requirements, which will be better propagated down through your abstraction layers as a deadline.
I'm already using quote at some places, but it returns `Tokens`, so I can't use it to modify the ast.
You're right - the compiler would have to be able to prove that no overflow can occur.
With constants I'd expect the division to be optimized at least; it's pretty surprising.
Cancellation tokens and a deadline could be members of the context parameter.
Look at the whiteboard behind the character. To the complete right of the image, at head level, is a TELEMETRY box. Below that box, is a "CHILD NODE" box with a number of languages enumerated: JS, **Rust**, TypeScript, Go, Java, Python.
Goodness, you've got eagle's eyes to have noticed that oO
Yeah, I saw that. I meant like, why? Is it addressed at all? I was just curious if there was context from the actual scene. I guess it's unlikely, just a background thing.
Cool, this comes at just the right time for me to use at my next go at getting rust working on my nrf52840. Hopefully this time I will be able to get the led blinking!
This issue is now tracked on the IntelliJ-Rust issue tracker https://github.com/intellij-rust/intellij-rust/issues/2425
They should but I am only talking about talking about sync APIs in the post above so cancellation does not apply. For async then cancellation is necessary and that requires a different API.
Silicon Valley throws in a lot of little easter eggs like this for the tech people who watch the show. They don't necessarily address them directly unless it's a plot point. One example is they show a bunch of tech company buildings in the opening of the show that changes each season. In this currently airing one they had Juicero there and show the name fall off the building, much like how the company folded over such a dumb over engineered product. If you're in the know it's a fun little extra joke, if not then it doesn't impact the telling of the story!
The kind of example I'm thinking of is communicating with a remote device. I'll put a time limit on every single round trip, and also a limit on an overall operation (which is performed with a long sequence of round trips). This isn't coded in Rust at the moment.
&gt; leek-freedom I am glad to see you militating against the oppressiveness of the Wales state :P *(You might want to run a spell-checker, too, some words are mispeled)* Jokes aside, thanks for the analysis!
&gt; all with different cancel conditions. They they will probably be different scopes. I mean, even in C#, you would want to [link](https://msdn.microsoft.com/en-us/library/dd642265(v=vs.110).aspx) the cancellation tokens in this scenario, which mimics nested scopes. You are right that cancellation tokens can have more flexible lifetimes than lexical ones, which can be useful in some cases (for example, many UI frameworks have weird lifetimes around "screens", and when changing screens you want to cancel all on-going operations). However, the trio framework discussed in the article uses a strict ["structured concurrency"](http://250bpm.com/blog:71) approach, where everything is lexically scoped. In any case, the biggest problem the article identifies with cancellation tokens is "Cancel tokens are unreliable in practice because humans are lazy", which is empirically correct from the existing examples (C# and Go).
How is his post "wrong"? It seems totally reasonable to wait a much longer time on a server that's sending data slowly but steadily compared to a server that hasn't shown any sign of life at all. Especially if the operation you do is expected to take a relatively long time, like if you're downloading a big file that can take several minutes. It's not reasonable to wait several minutes before giving up if you're not receiving a single byte at all. So I do find the way that `TcpStream` works today preferable to having a single inflexible all-or-nothing deadline, even though it is susceptible to a malicious server that sends one byte per X seconds. The best solution, as usual, is neither black nor white, and should take both partial progress and total time passed into account.
Yeah, i meant mostly for the implementer. Rust is challenging to write 'original' concepts on that was exactly it. Imagine a project trying to create non-blocking lock free data structures. [Indeed you don't have to imagine it](https://github.com/spacejam/tla-rust#why-rust): &gt; Our goal is to create data structures that are mutated using atomic compare-and-swap (CAS) operations by multiple threads simultaneously, and also supporting reads at the same time. We choose not to sacrifice performance by using Mutexes. This means using Rust's Box::into_raw/from_raw, AtomicPtr, unsafe pointers and mem::forget. We are giving up a significant benefit of Rust for certain very high-performance chunks of this system. In place of Rust's compiler, we use the TLA+ model checker to gain confidence in the correctness of our system! This reads to me 'only to space wizards'. 
Yeah, implementing safe concurrent data structures in a language without GC is pretty much "space wizards only." That's not limited to Rust, though. I'm really glad they're using TLA+ though--it makes it way more likely they're doing things correctly!
A slight bit of context is that they're building a new decentralized internet. But no, nothing on that whiteboard was directly addressed.
*oops* thanks, fixed. :) (I do run a spell-checker, but it seems I have missed some cases. Just fixed some of them. If you find any more, I'd be happy about a PM. :)
Thanks for the details!
&gt; To understand why it is wrong first try to formalize what you want to guarantee Alright, if I would *implement* a system that should download a file from a URL, I would report a timeout error if any of the following 3 conditions happens: 1. No packet has been received from the server for the last X seconds. 2. At any point past the first X seconds, the total received bytes divided by the total duration of time downloading the file (in other words, the average download speed so far) drops below Y KB/s. 3. In case the size of the file is not known ahead of time, stop if the total bytes downloaded exceeds Z bytes. It could be even slightly more advanced, like gradually increasing the maximum time between 2 packets (in condition 1) as a larger and larger percentage of the file is downloaded. The implementation would not be easy and I would use the available primitives while implementing the timeout mechanisms myself. I would certainly not use `stream.read_to_end()`. Now if I only want to download a file from a URL in Rust, I would go to crates.io and look for the best library to use.
Are there any resources you can recommend to start learning about quantum computing?
I'm still confused about the nature of Pin and how it ensures that an object cannot be moved. I assume the reason for this is that a Pin can be constructed from a mutable reference, which ensures that while a Pin exists of an object it cannot be moved. Beyond that, I'm a little stuck on the usefulness. I'm trying to grok these articles so damn hard but something is just not clicking. Back to trying again.
Could you elaborate?
Look at the second URL. ;)
I second that. ;)
Guaranteeing that forward progress is being made within some time bounds is a cross cutting concern. It might make sense of have a context library that takes a closure, the closure would emit progress events that can could be handled by an event sink (callback, channel, etc) the problem comes in being able to cleanly shutdown the code that isn't making sufficient forward progress. This is where non-blocking calls come in, so that control can be regained w/o relying on something with undefined behavior like thread kill.
Wow. I wonder how long it would take to convert to floating point and do the div there then convert back :-)
&gt; I think it's quite similar to the situation with Futures and their context parameter. It's similar in structure, but I don't think `Future` uses the context parameter for cancellation.* Instead, I think a future is implicitly cancelled whenever it's dropped. I haven't used it heavily yet, but this seems like an extremely natural way to do things, and it almost guarantees that callers Get Cancellation Right by default. \* Instead, the context is for either scheduling a wakeup of the current task, or for spawning new futures onto the current event loop.
Let's assume the size is known because that's easier to implement: Deadline based: fn download_file(remote: &amp;SocketAddr, contents: &amp;mut Vec&lt;u8&gt;, size: usize) -&gt; Result&lt;()&gt; { let mut now = Instant::now(); let deadline = now + Duration::from_nanos(size * 1_000_000 / MIN_BYTES_PER_SEC); let mut buf = [0; 1024]; loop { let idle_deadline = now + Duration::from_secs(MAX_IDLE_SECS); let n = read_until(&amp;mut remote, &amp;mut buf, deadline.min(idle_deadline)); if n == 0 { break; } contents.extend_from_slice(&amp;buf[..n]); now = Instant::now(); } } Timeout based: exercise for you.
Same here. Would love to know about any resources to learn about quantum computing! Most papers I come across assume a lot of knowledge of quantum physics, but I'm more interested in the computation (CS) side of things. Do I need to learn quantum physics in depth in before learning about quantum computing/algorithms?
Please advise where to post this question. I know how to do non-blocking sockets in C and Java to process as many sockets in a single thread as possible, while doing non-networking logic between the calls to select(). What is the best way to reproduce that in Rust? After reading Tokio manual I'm still confused how to go about it. Can Tokio be polled on demand externally, from the thread I control, to let it do just one pass of select() and if any data were read call my function to operate on the bytes or something like that? Would it be too much asking how to implement that stuff on StackOverflow? Thanks.
My opinion should matter very little to you, but, in my opinion, custom Derives give the feeling that something is extremely generic and can be applied to almost anything, as well as being very decoupled from any one particular usecase. Therefore, I don't know if a custom derive truly matches up that well with what you're trying to use it for, from a user's perspective. I also don't consider the functional macro to be that jarring. So I'd vote for functional macro.
Seems a bit circular, but you can convert the `Tokens` to a `TokenStream` and then use `syn::parse`. 
Floating point division is indeed faster. You'd suspect it's because the mantissa of a 64-bits floating points is only 52 bits; but that's only half the truth. The other half is that there's high demand for floating point division, therefore x64 CPUs use more silicon to implement it (typical trade-off space/speed). So, it might indeed be possible that converting-dividing-converting back be faster. Not sure, since even though the sum of the individual operations cost might be lower, there would be data-dependencies which might foul up the pipeline. On the other hand, note that if converting to floating point, you'll be losing up on accuracy. If converting to `f64`, for example, you only keep the 53 most significant bits (there's an implicit leading 1 in the floating point representation). So, if you have between 33 and 53 bits, it may be worth trying; I'd be more comfortable if you have less than 32 bits though, since then you can just use a `u32` :)
Being fearless is definitely the one thing you want to be when programming Rust.
30 to 90 cycles on recent Intel architectures? Do you have a source? I remember it being around 18-22
I already thought about the dump-and-parse varaint, I just hoped there was prettier way :/ Thanks anyway!
Amazing work, all the Rust things in a single OPML :)
I'm going to get on that list
Finished adding support for [untagged interfaces](https://reproto.github.io/?input=reproto&amp;output=rust&amp;package=example.untagged) for reproto. Something I've needed to port another project I'm working on to the system. Next up will be evaluating [HTTP clients](https://github.com/reproto/reproto/issues/2) to implement for C#, Go, JavaScript, and Swift that should be used as targets to saturate the feature matrix.
I should blog more. Sometime soon I hope. I have two ideas for posts I'd like to get out, but very busy.
Yeah! At last today I got my copies of my book!
You would just have to reimplement them to update the timeouts between I/O calls. That's not unreasonable; their implementations aren't that complex.
Thank you! It did work. Now to absorb this into my mind. :)
When you say functional macro, you mean a `macro_rules!` macro, right? That's my go-to when I have a lot of boilerplate code that can't be applied polymorphically.
I might actually publish two blog posts this year! One should be done in the next few weeks, and I have an idea for another. But there is work yet to be done.
Chucklefish (Stardew Valley) estimated that it took them a week to get Rust compiling to those targets for their new games.
To get the current's machine address is complex. Your machine can have multiple interfaces, when you bind to 0.0.0.0 you bind to all of them. If your machine is on the cloud, the IP address might be easier to find because the machine isn't behind a router, but if it is, you need something like IGD to talk to the router and ask it what its IP is. You can always use something like http://icanhazip.com/ to get the address the machine shows up as on the internet.
Yeah, I'd be interested too in something like being able to parse a CSS file to get all the selectors, and then comparing against docs parsed with html5ever to figure out which selectors are never used anywhere in site. 
https://www.reddit.com/r/rust/comments/8b27rg/new_sysinfo_version_huge_performance_improvements/dx4gzvk/
Yup, that's what I mean.
IIRC you suggest to leave `write_all` and `read_to_end` as they are in stdlib and rely on an external crate to have `write_all_until` and `read_to_end_until` as in the post above?
"Quantum Computing for Computer Scientists" is one usual recommendation. As a computational model, quantum computing is a simple linear algebra of complex numbers, no more, no less. You actually need no quantum physics whatsoever to do programming. n-qubit register is a vector of 2^n complex numbers. n-qubit gate is a multiplication by a unitary matrix of 2^n*2^n complex numbers. And that's it.
Yeah, to start with at least. I know deadlines have been discussed before but I don't remember what came of it except that we have timeouts now instead of deadlines (likely because they preferred parity with the underlying OS APIs, which are all timeout-based). An external crate would be a great way to experiment with this API and get feedback that you can use to refine it before drafting a formal RFC.
There were some good resources mentioned in [this recent Hacker News post](https://news.ycombinator.com/item?id=16797193).
Make sure you're running the tests as `RUSTFLAGS="-Z sanitizer=leak" cargo test --target x86_64-unknown-linux-gnu` to prevent trying to sanitize the proc-macros. Having multiple `&amp;mut T` to a single `T` is a violation of Rust's memory guarantees, and may run afoul of optimizations. If the compiler sees an `&amp;mut T`, it knows it has the only active reference to the data, and is free to reorder/remove reads and writes as it sees fit. If you want multiple mutable references you need to use `*mut T` or `ptr::NonNull&lt;T&gt;`.
...Rust without all the speech codes. /shrug
Hold on, you are very much able to construct a pin from a mutable reference, /iff/ the type is Unpin: https://doc.rust-lang.org/beta/core/mem/struct.Pin.html#method.new I think that's important, you wouldn't need to Pin otherwise, the data is free to be moved. Unpin specifies that you are doing specific things that require the data not to be moved.
&gt; Having multiple &amp;mut T to a single T is a violation of Rust's memory guarantees, and may run afoul of optimizations. This can't be stated strong enough. Aliasing mutable borrowsis not "against the Rust philosophy", as the readme states. It is a violation of Rusts core model.
diversity is good thing.
That and a lot of patience 
I don't think Rust is a good language for developing full games. Rust is a systems programming language, meaning it is optimal to create software for application programmers, not for end users. In addition, a big advantage of Rust is its safety (and consequent security). But games do not have strong safety nor security requirements. Rust is complex, it is slow to compile and hard to debug, and so it has some disadvantages without needing the advantages. You should use Rust for a game engine though. For example, I would use Rust to implement the engine of Unity3D, but not its GUI development environment, nor the game logic.
/r/playrust
Sorry if this comes across as a bit harsh, but: If you're allowing multiple mutable borrows, you need to make your API `unsafe`. It's not sound rust to have a safe API expose this, period. See https://doc.rust-lang.org/nomicon/safe-unsafe-meaning.html: having multiple `&amp;mut` references to the same data is undefined behavior, and your crate currently lets _safe code do this_. At minimum, `borrow_mut` should be an `unsafe fn`. 
This post title is straight out of /r/programmingcirclejerk.
Completely agree. At least their web application is still usable. Zoom FTW!
What you might want to do as an alternative to this is a simple IRC server. Look up the RFC and implement a "minimum best effort" version. If you design it to use callbacks and such to handle not only user data, but also channel data, then you may be on your way to creating a highly distributed server that can either take on IRC as a replacement, or just base a highly distributed chat server on that tech. Think like Silicon Valley's Pied Piper. Create an MVP (Minimum Viable Product) and expand from there.
&gt; It looks like with betterC you lose quite a few important features. Such as?
Please do. It’s hideous.
[removed]
Dynamic arrays, associative arrays, classes, and the standard library's threading/synchronization support are what jump out at me. Dynamic arrays can be replaced with std.container.array and structs can be used instead of classes, but there isn't a clear replacement for associative arrays, threading, or synchronization. The betterC documentation doesn't make any suggestions, and I couldn't find any suitable packages that were mature or even under active development.
Try to implement some missing display features [set_maximized, get_current_monitor, set_fullscreen and set_decorations](https://github.com/tomaka/winit/pull/457) for [unrust](https://github.com/edwin0cheng/unrust) upstream crate [winit](https://github.com/tomaka/winit), which will benefit unrust and other game engines. 
do people who post this never _even look at the reddit_ before posting?
&gt; stuff that C++ could never achieve This is going to be a _long_ time away, since C++ can achieve pretty much anything with enough time/money.
Bah, posted incorrectly. Yes, that solved it. thank you. :)
Basically he's salty because he got muted on the Rust Discord server for not following the CoC (aka the speech codes).
&gt; Dynamic arrays Not available in C, use `malloc` and `realloc`, available in D under `core.stdc.stdlib`. &gt; Assoc arrays Again, not available in C, it's only a matter of implementing it once. &gt; Threading C11 threading is not supported across the platforms. Use `&lt;pthread&gt;` with `core.sys.posix.pthread`. `-betterC` is not perfect, as it currently lacks support for C preprocessor. However project `dpp` is helping you to seamlessly include C headers as you wish. As in one of the links I posted above it offers you a few (cost free?) advantages while being as low as C itself. And D compiled with ldc goes shares the same compiler backend as clang, no problem optimizing there. - Hence you even have templates and other metaprogramming features: auto mkdouble(T)(T x) { return x*2; } extern (C) int main() { import core.stdc.stdio : printf; printf("%i", mkdouble!int(12)); return 0; } - You have built in docgen, modules, scope(exit), package management, RAII (if required) and whatnot. Point is, unlike many other languages, D does not mind you using C idioms as much. 
My point is that the D ecosystem just isn't there to support betterC presently. Sure you can build out your own version of everything, but that's a sucky route to be forced down. Meanwhile, Rust as a language is rapidly reaching a similar level of maturity, and you have its entire ecosystem available.
The community needs to dial down the hyperbole
I think it might be nice to have a into operator, maybe `^`
Working on building [an EFI support library](https://github.com/reynoldsbd/libefi), making it possible to write EFI applications in purely Rust code. Rust's FFI support makes it astoundingly easy to write something like this using only safe code.
Are we talking about the game here?
I have done a sudoku solver with gtk3 gui. I've managed to run it in Linux and Windows just fine, but when I try to run the Windows binary on another Windows that doesn't have mingw, it says that many dependencies are missing (glib, cairo...). Is it so that the needed information cannot be packaged in the binary itself but the end user should also install mingw? This kind of destroys one purpose to use Rust over for example Python for me: I want to build little widgets for my friends that can be run without hassle and they don't need to use cmd. I know that I could use Windows API, but I would love the programs to work both on Linux and Windows. Also my development environments are Arch (desktop) and Fedora (laptop) so Windows API is not my preferred way to build guis anyway.
I don't know about the other folks on the list, but I am certainly not fearless. 🤔 And yes, I am one of the more prolific Rust bloggers. 😎
/r/playrust
&gt; At minimum, borrow_mut should be an unsafe fn. I don't think any of the graph-manipulation functions need to be unsafe since you never call into user code during them, and you don't allow sharing the structure between threads, but you might want to double check those two things. Aliasing mutable borrows is equally bad in unsafe as in safe code. A mutable borrow has to be always unique.
At least a (to us mods) very visible minority doesn't appear to read the sidebar. A rather large subset of those submits posts meant for /r/playrust. 
No, we actually have a Rust Language Discord server.
From a cursory look, I don't think you're *supposed* to statically link GTK. There's a [list of what you have to distribute on Windows](https://github.com/gtk-rs/gtk/issues/422#issuecomment-270259393) that includes things like image resources. If you want a single `exe` with no external dependencies, you might need to use something other than GTK. What that would be, I have no idea; the Rust GUI situation is not great.
Yes, but it's OK if someone lets unsafe code do that - because then it's the unsafe code's responsibility to verify that it doesn't. `borrow_mut` in and of itself does not create multiple mutable references, it only creates one. It's only when safe code is allowed to use it multiple times that it's actually unsound. If it were unsafe, it would be _sound_, because then the consumer would need to use unsafe code to create multiple mutable references, right? And if they verified their behavior, they could use it correctly and only have one at a time.
One way could be to consume a `Read` and provide another `Read` (eg. make a filter/wrapper of the read). Then you just need to make sure the library works well in face of not ready errors and propagate them correctly.
&gt; Is there an existing crate that supports this Short answer: no. Longer answer: Applying rules to a tree involves a lot more than parsing. And even there, the `cssparser` crate is very low level and leaves it entirely up to you what at-rules (such as `@font-face` or `@media`) and properties you want to support, as well as what their syntax is. In other words, you need to write parsing code for those. It terms of specifications, `cssparser` corresponds roughly to the [CSS Syntax Module](https://drafts.csswg.org/css-syntax/). Once you have a bunch of style rules that associated selectors with property declarations, *selector matching* tells you which rules match which elements in a DOM (or DOM-like) content tree. The `selectors` crate implements that and is generic over the tree representation and many aspects of selector representation. `kuchiki` defines a tree data structure (with HTML parsing from `html5ever`) and "connects" it to `selectors`. But in my mind it’s more a proof-of-concept than a full solution. It may make sense for you to define your own tree data structure. Once you have *that*, you still need to deal with selector specificity, the cascade, inheritance, and computed values before you can get to a single value for each property for each element. For Servo and Firefox, the relevant code for all this starts at https://dxr.mozilla.org/servo/rev/9a900ef019/components/style/stylesheets/stylesheet.rs#409 / https://doc.servo.org/style/stylesheets/struct.Stylesheet.html#method.from_str In my toy project Victor it’s https://github.com/SimonSapin/victor/blob/3b5bc0a9ba/victor/src/style/style_set.rs#L19, which is probably easier to read (since there’s a lot less code) but it’s also very incomplete at this point.
No, the contract of Rust is "&amp;mut is unique". Not "&amp;mut is unique if you only call me once and drop the previous borrow before". unsafety is not much in play here, it's the types definition. If we weaken this guarantee, a lot of things break and a lot of weird things happen. We have types and techniques for enforcing this invariant in Data structures, for example RefCell or Mutex. Alternatively, you can make the graph not Sync and Send and borrow the graph structure for the lifetime of the mutable reference you hand out. 
The article advocates Rust for smart contract scripting, but I am not sure it is a good fit. I think WebAssembly is an obvious candidate though.
I’ve become fearless in Rust, but it’s made me fear every other language...
You are right, if the type is Unpin none of what I wrote in this post and the previous matters. For Unpin types, `Box&lt;T&gt; = PinBox&lt;T&gt;` and `Pin&lt;'a, T&gt; = &amp;'a mut T`. As you said, `Unpin` specifies that we do not care about pinning and that the data is free to move at any time, even when pinned. But that's not the case to look at to understand pinning, because it is the case where pinning does not do anything.
I believe smart contracts need DSL to work well. Also, smart contracts are over-hyped and lately people think that putting everything into the blockchain solves every problem. (Currency that's impossible to be controlled by governments is useful, though.) Turing-completeness is not as useful as people think and causes problems. [Simplicity](https://blockstream.com/simplicity.pdf) seems like the best candidate to me so far.
It's much later, and I'm not sure how frequently you check these (by the time you do it might not even be possible to respond to this post), but what do you think of the new `Pin` APIs that are going around? From my perspective, it should make *using* self borrows in safe code much easier (the intrusive stuff is especially mindblowing), but implementing stuff to take advantage of them seems like it will require subtle unsafe code (maybe a lot of it? I'm not sure), so I don't know if it really addresses your concerns.
The cycles in my case is an ability to store tree's nodes as node's data.
You can take a more high-level approach by using [mio](https://github.com/carllerche/mio). Or you can implement it yourself by using [libc](https://github.com/rust-lang/libc#platforms-and-documentation) or [winapi](https://github.com/retep998/winapi-rs) (in this case you'll probably be using the windows approach of [IOCP](https://msdn.microsoft.com/en-us/library/windows/desktop/aa365198%28v=vs.85%29.aspx?f=255&amp;MSPPError=-2147217396)).
`#[derive(Foo)]` is the idiomatic way in Rust. Those cons aren't that bad IMHO - I've already tried it. The testing issue can be resolved by simply using integration tests instead of unit tests. What I found to be downside of derive is learning and comprehending `syn` and `quote` crates took me longer than learning `macro_rules!`. I don't regret it. Writing idiomatic code feels nice to me. :)
Thanks. I will fix this.
&gt; custom Derives give the feeling that something is extremely generic and can be applied to almost anything, as well as being very decoupled from any one particular usecase. I disagree. You can easily create derives that serve some specific purpose and don't work for some types. (E.g. only structs, not enums.)
Thanks. Currently I'm using my own `simplecss` crate that is way simpler (hence the name) than `cssparser`, but on other hand is a bit more high-level. I don't know about 'the cascade, inheritance, and computed values'. At the moment I'm simply setting the attributes to nodes by selectors. All the computation and inheritance are done later. Since I'm using this for SVG processing, which mostly uses CSS2 - it works fine. But I need a full-blown solution. And I thought that `cssparser` allows this. But after trying it out it turned out that it too low-level for my task. Basically I need something like `selectors` but even more high-level. So it will work by saying: set this attribute to this node. That's all. The *include*, *at-rules* and stuff can be simply ignored. Thanks for a detailed answer.
Scala implicits, while they have a lot of detractors, also handle this use-case well.
You can design a tree that conceptually doesn't have cycles, but actually does for technical purposes.
Since you can compile Rust to Webassembly, that wouldn't be a problem. The question he raises though is, if it would be feasable to replace the Ethereum VM with an x86 VM. I think asking for Webassembly in that comparison is much better. And I think Webassembly would be a better choice then x86. But crypto stuff rather needs a turned down VM with better security proofs and verifiability then WA does.
&gt; (Currency that's impossible to be controlled by governments is useful, though.) Off topic, but another solution would be an [independent central bank](https://www.ecb.europa.eu/explainers/tell-me-more/html/ecb_independent.en.html).
Does this count as a blog post: https://gist.github.com/alkis/9510a840f1965185ab0a02cb59761dd8#file-the-case-for-deadlines-md
Although not exactly ready for prime time afaik, there's a crate/an org dedicated to video codecs called rust-av: https://github.com/rust-av/. Came up on ready some time ago. Here's a link tp revious discussion: https://www.reddit.com/r/rust/comments/7sibi6/libav_developers_receive_51000_to_build_rustav/
Because there are cases in which you need to produce `&amp;mut` and _the production is unsafe_ (e.g, you got the borrow from an external source). Unsafe code is allowed to freely _assert_ (and check with any means it deems possible) that this `*mut` is indeed unaliased and then produce a `&amp;mut`. `unsafe` does not allow you to break rules of ownership and borrowing, it just _doesn't check them_.
If you only care about SVG attributes and not stylesheets you probably don’t need selector matching at all.
&gt; Unsafe code is allowed to freely _assert_ Can user-unsafe code not make this assertion based off of its use of the library? I mean if `borrow_mut` is a full `unsafe fn` with documentation on what invariants need to upheld before using it, I don't see how it's breaking the language. I _fully agree_ that while it is callable from safe code, it breaks the language and is unsound. `unsafe` code should not rely on safe code to ensure it's not making multiple mutable borrows, and that's what my original comment is about. When it becomes an `unsafe fn`, though, isn't this effectively passing the buck on to the user? Can't the "check this *mut is unaliased" step then just be passed on to whatever user opens an `unsafe {}` block to call it? I get that we can't trust safe code to ensure there's no multiple mutable borrows produced by `borrow_mut`. I'm still not sure why we can't trust consumer-written unsafe code which takes into account the full use of the library. I'm never suggesting we ever create multiple `&amp;mut` pointers, just that we don't verify ourselves that _other unsafe code_ isn't doing this.
It still does not click for me. Am I correct if I see PinBox somewhat similar to Arc in terms of where/how I would use it? 
Hmm... Thanks. It's more complicated than I thought. I somehow thought that listing dependencies in Cargo.toml was enough.
Wait, does that mean if you have something like `let val: *mut i32 = get_from_ffi(); val as &amp;mut i32` you are not allowed to encapsulate that in an unsafe function?
&gt;Although we'd like compiler-backed code completion, it is probably not happening soon, and mostly Racer is good enough for now. That's a tad disappointing, I've found racer to be quite temperamental. The last time I checked the intellij plugin was a lot better
"Doxidize": i've read this as "de-oxidize" as the opposite of oxidization (rewriting everything or parts in Rust) which made be sad.
Listing dependencies just compiles and links those dependencies. It doesn't do anything else.
Dox (Docs) - i - dize (I think!).
Nice idea. I'm coming from Django, so someoneshould really add an ORM to rocket.rs
I have to say I'm put off by the term "someoneshould". It sounds entitled to me. Maybe rather use something like "I would love to see"?
No, the _moment_ you are casting to "&amp;mut", you are saying "this is unique". I'm not going to explain it again. It's the types definition. It's not the job of calling code to do that, even when it is calling unsafe functions, at least not at this level. The only okay way would be a function that takes "*mut T" in and outputs a "&amp;mut T" and asking the user to only _pass_ in a pointer that is not aliased before. This API allows you to follow a "&amp;mut" pointer and generate two out of it. Yes, this _is_ breaking fundamental guarantees and _no_, this is not the job of the caller to ensure. This library is unsafe.
Hey, this is basically what [Not-Yet-Awesome Rust](https://GitHub.com/not-yet-awesome-rust/not-yet-awesome-rust) is for. Swing by and leave your use cases there! :) Indefinitely want to know which are missing from the ecosystem.
That's another situation. The situation this library is that it takes a borrow in and returns a borrow. A function that takes a `*mut T` in and returns a `&amp;mut T`, asking the user to ensure `*mut T` does not alias is fine, but that's a precondition of a very different kind.
&gt; Extend Pattern API to OsStr I'm excited for this one personally. :)
I'm pretty comfortable with it because it is not targeted at any one person or group of people.
Smart contracts can die in a fire. The amount of power wasted to make a single function call on ethereum for example can power a home. Cryptos are killing the environment. Just stop. Bitcoin for example uses more power than Ireland.
Which is a shame. I'm very impressed by what Intellij have achieved and appreciate their massive effort, but the IDE is just too heavy for me.
Consider the following C code. It's not mine, so I apologize in advance for the style. void jacobi_omp(long n, long m, REAL dx, REAL dy, REAL alpha, REAL omega, REAL * u_p, REAL * f_p, REAL tol, int mits) { long i, j, k; REAL error; REAL ax; REAL ay; REAL b; REAL uold[n][m]; REAL (*u)[m] = (REAL(*)[m])u_p; REAL (*f)[m] = (REAL(*)[m])f_p; /* * Initialize coefficients */ /* X-direction coef */ ax = (1.0 / (dx * dx)); /* Y-direction coef */ ay = (1.0 / (dy * dy)); /* Central coeff */ b = (((-2.0 / (dx * dx)) - (2.0 / (dy * dy))) - alpha); error = (10.0 * tol); k = 1; while ((k &lt;= mits) &amp;&amp; (error &gt; tol)) { error = 0.0; /* Copy new solution into old */ memcpy(uold, u, n*m*sizeof(u[0][0])); #pragma omp parallel for collapse(2) reduction(+:error) for (i = 1; i &lt; (n - 1); ++i) { for (j = 1; j &lt; (m - 1); ++j) { float resid = (ax * (uold[i - 1][j] + uold[i + 1][j]) + ay * (uold[i][j - 1] + uold[i][j + 1]) + b * uold[i][j] - f[i][j]) / b; u[i][j] = uold[i][j] - omega * resid; error = error + resid * resid; } } /* Error check */ if (k % 500 == 0) printf("Finished %ld iteration with error: %g\n", k, error); error = sqrt(error) / (n * m); k = k + 1; } /* End iteration loop */ printf("Total Number of Iterations: %ld\n", k); printf("Residual: %.15g\n", error); } Note the OMP parallelism. I replaced it with the Rust code below: #[no_mangle] pub extern "C" fn jacobi( n: c_long, m: c_long, dx: c_float, dy: c_float, alpha: c_float, omega: c_float, u_p: *mut c_float, f_p: *const c_float, error_tolerance: c_float, max_iterations: c_int, ) { let mut u = unsafe { ptr_to_mat(u_p, n as usize, m as usize) }; let f = unsafe { ptr_to_mat(f_p, n as usize, m as usize) }; let ax = 1.0 / (dx * dx); let ay = 1.0 / (dy * dy); let b = ((-2.0 * ax) - (2.0 * ay)) - alpha; for iter in 0..max_iterations { u = u.par_iter() .enumerate() .map(|(i, row)| { row.par_iter() .enumerate() .map(|(j, elem)| { if (i == 1) || (j == 1) || (i == (n - 1) as usize) || (j == (m - 1) as usize) { *elem } else { let resid = (ax * (u[i.saturating_sub(1)][j] + u[i.saturating_add(1)][j]) + ay * (u[i][j.saturating_sub(1)] + u[i][j.saturating_add(1)]) + b * u[i][j] - f[i][j]) / b; elem - (omega * resid) } }) .collect() }) .collect(); if iter % 500 == 0 { println!("finished iteration {}", iter); } } // Write to output pointer unsafe { for (i, row) in u.iter_mut().enumerate() { for (j, elem) in row.iter_mut().enumerate() { *u_p.offset((((m as isize) * (i as isize)) + (j as isize))) = *elem; } } } } The original C offers a 25% speedup compared to the Ruston my 2-core, 4-thread CPU. It is obvious to me that this code *can* be optimized, because by using vectors I'm causing memory to be reallocated a lot, which is avoided in the C version. I'm just not sure *how* it could be optimized.
I guess the problem is that those dependencies are different than dependencies on external dlls. I'm new to GUIs. It seems that with GTK the program tries to use libraries that it assumes already exists in filesystem. It kind of sucks that it seems there is no way around the problem. I can't assume that people are willing to install stuff on their computers to run my programs. But yeah, I guess that's how it is.
You're right. That's the only reason. I wouldn't encourage anyone to do a quick search for the word "retard" to see how often innocent usage results in people getting raked over the coals.
Please provide a way for people to run your program and re-create your results.
this print on github - [white](https://github.com/jstpcs/lnxpcs/blob/92f7cd8ece8177e6e457180a2c380d186843f219/cards/classic/rust-card.png) card and [dark](https://github.com/jstpcs/lnxpcs/blob/92f7cd8ece8177e6e457180a2c380d186843f219/cards/black/rust-card-black.png) all the other prints in playing cards [style](https://github.com/jstpcs/lnxpcs/tree/master/cards), [repo](https://github.com/jstpcs/lnxpcs) with all my pics previews of all pictures with links to github are on [linux.pictures](linux.pictures). info about [license](https://linux.pictures/about).
https://github.com/hxtk/569-Project-2 I'll edit it into my original post.
The clippy changes sound a bit worrying, to be honest. If anything we probably need more lints enabled by default, not less. I've also found the current balance of style and correctness in the default lints to be pretty good.
I tell people that don't know about it, and for the people that know about it and use it again, sometimes multiple times, it's a reminder. It's not a big offense that needs to be dealt with a mute. I've had multiple complains from different people stating that they were uncomfortable when people used the word "retard" on the server, so I need to moderate it. And hey, I'm very lenient on my moderation actions. I could just outright ban anyone for a minor offense, like I know happens on several other servers. But I like giving people the benefit of the doubt and a chance for them to change. If you don't know how to handle being muted because you spoke harshly to other people there, then it will take more than me to make you understand and follow Rust's CoC.
That's false. Anyone can read through your mod log and see that you often say things like, "Next time there will be no warning for anyone." You have even doubled punishments for particular people based on the perception that they were some how "extra bad," and skipped warning levels straight to more severe levels of punishment. You are *lying.* Not deliberately, I'm sure, but I believe you fail to realize how disruptive your actions are.
I mean, you don't have to read the sidebar to see that this is not the right place for /r/playrust. Just read the top-level post and decide if this is the right place...
Oh, and you can stop wasting time pretending that my problem with you is you muting me because I told that guy to fuck off. My problem with you is much deeper than that. -.-
Just a guess, but it looks like you are using `par_iter` in a nested loop/iterator. Creating such an iterator has overhead compared to a sequential `iter` which may outweigh the benefits of parallel computation. I don't know where your bottleneck is, but maybe you want to try to replace the [inner](https://github.com/hxtk/569-Project-2/blob/master/rust/jacobi/src/lib.rs#L49) `par_iter` with `iter`. 
Be honest: do you *genuinely* believe that the way you wield your little banhammer encourages anyone to provide you with honest criticism, or do you believe it encourages people to try to wield *you* like a weapon against others who have annoyed them? On three or four occasions, I have started to IM you to let you know that I felt you were being unfairly draconian, and that your actual processes (which start with a global mute rather than with any discussion or private notification of the action being taken) are abusive--but, you know, the fact that you hand out global mutes before handing out three-month-long warnings (whatever; I don't remember the actual length, but I'm thinking of the one star_wars got at like the beginning of the year) followed by promises that, "Next time, it's a ban!" doesn't exactly encourage dissent. Or does it? Do you *genuinely* believe that you are approachable in that way, or do you believe that you take actions intended to intimidate others and emphasize your power over them? Once again, I believe that--even if subconsciously--you have done the latter. This is my calm and reasoned attempt to explain my criticism.
I would love some more thoughts on [plopAhead / plopBehind](https://github.com/rust-lang/rfcs/pull/2390)
&gt;Also, I'm not sure how you'd do async IO with such continuations. &gt;Can you avoid having a specific event loop for async IO? Async IO would be handled by the event loop you're running on, for example gio. The logic is: if you can register an arbitrary callback on your async system, then you can await that callback in your coroutine. You'd do that by suspending the coroutine and providing the its continuation as the callback. This can be done by a utility coroutine, so normal code doesn't need to `suspend`, unless it directly talks to the underlying event loop. (One such example would be the `gtk_sleep` function in the Python [gtk example](https://github.com/hniksic/corocc/blob/master/examples/animation).) Of course, this will make those coroutines (that e.g. use gio for async io) require the event loop you're writing them for (GLib event loop on that example). That is the flip side of the benefit of being able to quickly hook coroutines into a callback based async system.
You should call local_addr() on the incoming connection instead of the listening socket. The listening socket remains globally bound, but the actual connection should be bound to the address the connection was made to by the client.
Write a serde crate that can serialize to XML. Not a big deal, but... would be nice at work. 
Nice, maybe, but to be motivated by ergonomics, it has to be shown to be a real ergonomic problem. Compare for example the strain on writability and readability without the `?` operator; `get_obj(a)?.method()?` To `match get_obj(a) { Ok(x) =&gt; match x.method() { Ok(y) =&gt; y, Err(e) =&gt; return Err(e.into()), } Err(e) =&gt; return Err(e.into()), }` I can't really see `.into()` being enough of an ergonomic problem to motivate a new operator.
There have been situations where people complained to me and I saw no need to take moderating actions, so I don't believe it would be easy to use me as a weapon. I do the straight up mute for a few reasons. One, it prevents any more immediate potentially harmful messages. Two, it's better to ask for forgiveness than permission. If there were someone being particularly bad to someone else, and I DM'd them "hey there, tone down your voice or else I'll need to mute you", what guarantees me that they won't be angry at me instead and start spamming the server and the users there? In my opinion it's better to mute first and if the user feels the moderating action was too harsh or unnecessary, they can appeal to a moderator in a private message. |&gt; followed by promises that, "Next time, it's a ban!" That user has a higher warning level than the others, so it lasts longer and allows me to give it more time to see if they are behaving nicely towards other users. And as long as the user is respectful when appealing or discussing the reasons for their warning, I see no reason why dissent would be discouraged. All the moderating actions are there to enforce the rules and protect other users. I don't really feel happy taking them, and I'm sorry if it looks like I'm mocking them or intimidating them. But they have to be taken regardless. As for the other people poking fun at those actions, I'll take more care to notice and deal with it accordingly next time. All that I'm trying to say is: be nice to others and follow the rules. If you break them, moderating actions are needed so that they learn how to follow the rules. In your warn message, I've explained why you were warned and gave you an idea of what to do to prevent similar situations. Do you not think it's enough? Or was it unnecessary? Or was it over the top? All that could be said in an appeal if you had chosen to send me one. If you claimed you were sorry and said that you would calm down, I'd probably have unmuted you and removed your warning, no problems. But instead you make a big deal out of it by leaving the server and creating another Discord server instead, which doesn't give me any valuable insights and feedback. If I hadn't found this post on reddit, you wouldn't have given me your feedback. Does that tell you if I value feedback enough to pursue it?
So do you mean one single actor sending messages to another single actor? I am pretty sure the order is deterministic in that case. But /u/fafhrd91 will be able to answer more confidently :)
Yes! That is what a meant! One single actor to another single actor, sending a stream of messages...
Order is deterministic. Actix uses mpsc queue for messages
First, it tells me you absolutely do *not* value feedback enough to pursue it, because you could easily have contacted me after I left--as did several other users. Second, the fact that you wanted this feedback in private rather than in public suggests that you do realize that your actions--particularly the immediate global mute, without regard for circumstances--are egregious and abusive. As for my specific instance, in my warning message, you included no information about how long I was going to be muted, and I saw no reason to hang out in a server where I'm not allowed to actually say anything. I left immediately on realizing that I wouldn't be able to talk--so, yes, *obviously,* I would say that your "warning message" was inadequate, unless you actually intended me to interpret your action as effectively an indefinite ban. You can say that it was to prevent further abusive messages on my part, but the fact is that you walked into an active discussion on programming and [knew, or should have known,](https://aronberglaw.com/knew-known-actually-mean/) that there was no ongoing problem, because you read, or should have read, the discussion in progress. I'm not sorry for anything I said, because in this instance star_wars, who you already know is kind of an asshole, had it coming. He was attempting to derail a discussion wherein another user was trying to understand an unfamiliar concept, and I didn't appreciate it. I did not, however, see any reason to involve a moderator, so I told him to lump it. Again, I made the new discord server some time ago after another of your over-the-top mod actions and simply never publicized it because I told myself, "Well, he's not that bad." Clearly, you have failed to learn from that experience and from many others.
...Oh, and I found it amusing that it's better for *you* to ask forgiveness than permission, but when other people take bold actions, that's a mute. :)
*Proof of Work cryptos are killing the environment.
there is something like this boiling https://github.com/SergioBenitez/Rocket/pull/571 and i think its as close as it can get in the near term. And to be honest i do think that this is enough of such an integration because i also want to be in a position to replace something like this as a framework user – and don't want to be to strongly coupled to diesel etc. (i really do like diesel, don't get me wrong)
While I agree that it is basically just linear algebra, the mathematical notation can be very specific to physics. It is uncommon to write vectors as `|x&gt;` or even `|0&gt;` and dual vectors as `&lt;x|`, and this notation is usually not explained in Wikipedia articles and papers.
Nice! Thanks!!!
If you are just interested in the computation, linear algebra and knowing the notation used in physics and maybe some physics-specific jargon should be enough. If you want to understand how it can be realized in nature, you need some understanding of quantum mechanics.
Yup, that's what I ended up doing. I put an edit at the top of the post. Thanks 
Some general remarks: Looks like you compile the C code with gcc. Mahbe try clang, too, as it uses LLVM (just like rustc). You can also compile your rust code with `-C target-cpu=native` to enable more assembly-level optimizations. LTO might benefit both C and Rust.
As you mention, the C code swaps between 2 buffers on each iteration, rather than allocating a new buffer in each round. Also, the matrix in the C code is laid out contiguously, whereas the Rust version is currently allocating a `Vec&lt;Vec&lt;_&gt;&gt;` which will involve an additional pointer chase on each access where you use `[i][j]`. [Here's a playground](https://play.rust-lang.org/?gist=d6c4fd80754f66bde5a4606f23f41410&amp;version=stable) where I use rayon's [`par_iter_mut`](https://docs.rs/rayon/*/rayon/iter/trait.IntoParallelRefMutIterator.html#tymethod.par_iter_mut) to iterate over a single contiguous buffer and fill it, and then use [`std::mem::swap`](https://doc.rust-lang.org/std/mem/fn.swap.html) to swap my old and new buffers without allocation. Hopefully this gives you some avenues to explore for finding additional speedups. For your purposes, rather than doing index math yourself to treat a vector like a 2d array, you should probably use a crate like [ndarray](https://docs.rs/ndarray/0.11.2/ndarray/)
I tried to contact you after you left, but Discord said I couldn't send any messages to you. Either you have blocked me, or your setting that people that don't share a server with you can't DM you is turned on. And I'd rather have this feedback in private so as to not clutter up the server. It's not a secret that people would rather see us argue in #offtopic than keep discussing whatever they were discussing previously. I'm perfectly fine having it here, though. As for the length of the mute, I forgot to say it. But you could have messaged me and asked, or seen that I had setup a 24 hour reminder to unmute you. And I read the discussion in progress and I read `couldn't give a shit`, `See if I care.`, `Yeah, I forgot. You fuckin' happy? We can also write it with fucking shift operators if you like.`. That sounds like a problem to me. You didn't have to lump him yourself. You could either have blocked him, ignored him, or told a moderator so that they could tell star_wars to stop derailing the conversation. You were completely in the right, but you lost that when you were rude to the other user, even if he was in the wrong. Also, uh... you aren't banned? From what I understood you left the server on your own, and you can easily join it back. And hey, if my moderating actions are wrong, congrats for being the first to tell me about it. Maybe if other people had told me sooner, it wouldn't have come to this. It's not like I'm not going to change after all that feedback of yours. Quite the contrary, I'll review my actions and strive for being a better moderator. I'm sorry you had to experience this.
This is super cool. Just for fun I swapped out `rmp-serde` with `bincode` and everything still works!
Your 18-22 matches the order of magnitude of 32-bits division (26 cycles on a Skylake); 64-bits is a tad worse off :(
Thanks! Did you notice changes in size or other aspects? I picked MessagePack somewhat arbitrarily, mostly since it was familiar.
I think it is not just about hardware. Mathematically, you can use iterative, approximate algorithms (like Newton's method) which are only possible with real numbers.
I’d encourage you not to use ORM, they often lead to creating non performant queries.
What do you mean by this? I can already use stack references in rust, but I can't reference a stack after it's closed. I can't think of what else there is - can you elaborate?
&gt; After running gdb it seemed the problem was in jemalloc, Rust's default allocator. I found that switching to the system allocator fixed my problems so didn't investigate further. Probably is caused by allocating pointer in Python-land and then freeing them in Rust-land or vice-versa. That oughtn’t be done.
Language mismatch, we agree on the algorithm itself. In base 2 it involves no multiplication (only bit-shifting): either you subtract or not, so the number of steps to perform (is greater: yes =&gt; subtract, no =&gt; move along) is bounded by the difference of the logarithms. Worst case, dividing 2^64 - 1 by 1 requires 64 steps.
&gt;* Someoneshould write a rustdoc backend to generate dash/zeal docsets There are multiple existing approaches to generate dash docsets from rustdoc documentatuon. I wrote [rsdocs-dashing](https://github.com/hobofan/rsdocs-dashing/blob/master/README.md), and some of the other solutions are linked in the README. One long-term goal of mine is also to get a Dash integration for docs.rs working, but there doesn't seem to be much interest on the maintainer side.
Is that a guarantee or an implementation detail?
Agreed. If nothing else, if we want to be serious about supporting non-utf8 paths, we need the same kind of tooling for `OsStr` as we do `str`, including `format!`.
Implementation detail, but I am not sure what guarantee are you referring 
Unfortunately I didn't do any testing other than checking that it works. I am on a windows machine ATM which is a bit inconvenient on top of the fact that I should be working... My goal was just to see if it would work since `bincode` is so closely tied to rust. If I can remember when I get home I will try and run them side by side to see if there is any difference. I created a fork for the change [here](https://github.com/FreeMasen/webchat-rs), though the changes are just the `Cargo.toml` line and the import/function calls in `src/lib.rs`.
Is there a conceivable case in which a change to the implementation would cause message order to change?
implementation is pretty simple, I don’t see any reason why would anyone want to change it
So, we don't use the lvalue/rvalue terminolgoy; we use ["place expression" and "value expression"](https://doc.rust-lang.org/beta/reference/expressions.html#place-expressions-and-value-expressions). You need an explicit deref, but you can do this with pointers https://play.rust-lang.org/?gist=4eb6f5060e4fa6a28ade1df637dbfce7&amp;version=stable more generally, placement has been worked on for a long time, but we're scrapping the current implementation and re-working things.
In rust a function could return a mutable reference, which could be deref into an lvalue. For example, `*vec.get_mut(0).unwrap() = 1;`
Maybe someday `mpsc` is not fast enough for some usecase anymore? `mpsc` is relatively slow compared to raw Iterators for example.
yup!
Actix messages queue is fast enough, but if it is really bottleneck, then you just use it as a control flow and establish separate fast channel between your actors. Actix does not force you to use only actix message queue.
I was late to mute you because I was distracted at the time. However, I got a complaint later from another user about you. So I reviewed the situation and took action. I muted so that we didn't start discussing there while I warned you. And as I said, even though I did not directly tell you the length of the mute, you could have figured it out yourself, since, again, I did make a public reminder to unmute you. Also, I didn't formally warn the guy that said "winapi" is retarded. I gave him a heads up, if I'm not mistaken. It's just a really tough thing, you know? I could allow use of the "retard" word, but then I'd go back to getting complains about people being uncomfortable with others using it. So what do I do? Ignore the complaint or try to tell people not to use the word? Also, anyone can talk to me about anything. I would never go "hey, I didn't like what you complained to me. Banned". That would be authoritarian. You only get repercussions if you break the rules. And anyone can say anything to me about my actions and decisions as long as they don't attack me and others personally and tackle the discussion respectfully and with the intent of helping both sides. To be honest, I'm trying to get the moderators from this reddit to come over to the Rust server, but they're not replying. I have been in need of more moderators for a while, and I've been trying to get ones that aren't from the server so that it doesn't reinforce the "toxic" atmosphere there, as you explained.
Yep I agree. For example implementing a data format for serde is so much easier with IntelliJ. Racer basicly refuses to give you any auto completion as soon Traits are involved.(Unless there was an update)
Apart from the issue of whether ECB is truly independent (I don't believe it is), I wrote "impossible to be controlled by governments". If there is a central institution, that institution can be coerced by government into doing whatever the government wants - government has police, army, tanks, ballistic missiles, jet fighters, bombers... ECB or any other central bank doesn't have an army capable of defending it, thus it ultimately can be controlled, if government chooses so. (History tells us that governments controlling financial institutions is likely scenario.) This is why Bitcoin was invented as a decentralized system: in order to attack it, a government would have to attack too many individuals, which would probably involve invading other countries etc. Even in the worst case scenario, when the government attacks enough miners to launch &gt;50% attacks, those attacks can do very little and are very costly (the cost is more than 12.5 BTC every 10 minutes of attacking). And even if the government chose to go this route, they would achieve a situation in which so-called PoW change is the justified and logical reaction of sovereign full nodes, causing even bigger costs for the attacker and rendering the attack ineffective. Conclusion: Bitcoin and other sound cryptocurrencies are physically impossible to be controlled by government and we don't know of any alternative that can achieve the same thing.
Wars waged by governments are killing the environment even more. Where did governments get the money to create nuclear bombs, capable of destroying whole planet and already destroying thousands of innocent lives? From two sources: coercing people into paying them taxes and money printing. Bitcoin is a scheme to make governments incapable of waging wars. I would rather live on somewhat warmer planet with some environmental problems than die in a nuclear strike, which completely destroys everything living as well.
Some observations from just looking: * The saturating arithmetic seems unnecessary, since you already check for the edge conditions. * `saturating_add` doesn't do anything useful here unless the array size is `usize::max_value()`. * You're accessing `u[i]` instead of just `row`(-&gt; bounds checks) * I don't know but there might be `skip` and `take` on parallel iterators that let you skip the first and last row/elem altogether, better mirroring the indexing in the C version.
Hm, that's interesting. It was a good while ago but I can't remember anything that was obviously like that. Cheers though :)
I remember reading somewhere that Rust functions are implemented as state machines (or something along those lines). What exactly does this mean and how does it work?
Looks good so far, based on minimal testing. Log integration is a very big plus. Will do some more testing later this week in a multithreaded environment to see if any issues crop up.
Oh, nice. FYI: https://github.com/kesselborn/rsdocs2docset has been deprecated (as of today or yesterday, IIRC).
Uh.... That'd be some interesting shit if that's how it worked..
&gt; You're accessing u[i] instead of just row(-&gt; bounds checks) I agree with the rest of your points. In fact, I now think that the saturating arithmetic might make my code less safe by allowing a logic error instead of program crash if I forgot to bounds check, but I wonder if using `u[i]` instead of `row` really makes the code any less safe, versus the readability benefit it gives by making the `ay` terms consistent with the `ax` terms.
Yeah I'm pretty perplexed by the problem too, hence my post.
Are you trying to have it let them edit the same file and see others edits live?
The real question is whether Actix will commit to never allowing unordered messages. If Actix ever supports distributed systems it will get expensive to support this. Most other Actor implementations do not much such a guarantee, and leave it up to the Actors themselves to enforce this using whatever mechanism they choose (an explicitly ordered queue, FST/ causal ordering, etc).
I set this up in Haskell+STM once. Shouldn't be hard in rust other than managing all the connections somehow. Tokio, I guess? Tokio is very hard to work with last I checked though. The general idea goes like this: The canonical document was kept by the server. Edits to the user's version (character by character) would send an edit request up to the server, which would then process all edits and broadcast the series of changes. There's generally not a conflict, so it works out. If two people try to edit the same spot at the same time you get kinda weird results of course, but even then they're still made consistent since it all runs through the server.
Hi there, reddit flagged this as spam somehow and so nobody got to see this. If you would like to resubmit, please do so and reply to this comment here to remind me to check the filter for it.
Hi there, reddit flagged this as spam somehow and so nobody got to see this. If you would like to resubmit, please do so and reply to this comment here to remind me to check the filter for it.
I'm think I'm trying to let multiple users add to a .txt file (not remove anything) simultaneously, so that the next time the file is opened it contains both edits. So if the contents of the text file are "ABC", and user1 adds "DEF", and user 2 adds "GHI" at the same time, afterwards the file would read "ABCDEFGHI"
You probably mean *async* functions, which get compiled into state machines. This is a proven way to create coroutines, which can be used to implement async code.
actix does not provide ordering guarantees on sender side, it guarantee not reordering messages inside actor's mailbox. distributed queue ordering guarantee is way outside of project scope
It wouldn't be less safe, since the bounds are checked. But if the bounds checks are not optimized away, they will take some time. I'm not saying you should change this, since I agree with the consistency argument, but it would be interesting to see if it makes a difference in the timings. (I'm still pretty bad in predicting what will.)
What do you mean? :)
I think I misspoke, it's more that a mutable reference implicitly creates a pin because the object must outlive a mutable reference. As long as there is a Pin, the object will be located at the same address (because how else would the ref be updated?). Objects that implement !Unpin also cannot be moved for the duration of the Pin, but the semantics change - now it is unsafe to modify the Pinned reference. 
i think we are talking about actor to actor communication guarantees. i.e. if actor A sends messages M1 then M2, actor B should receives M1 first and then M2
I realized after I wrote this that another option for you would be to try starting doing gamedev in Python or JavaScript, which you already know. The games won't perform the best, there may be some GC pauses, but for simple 2D games, you can get started in those languages. That would mean learning about the gamedev specific aspects without also having to learn a whole new language, so you could separate out learning a new language with learning about game development.
hi, kibwen, i resubmitted the post, [here](https://www.reddit.com/r/rust/comments/8bjftw/i_create_open_source_related_pictures_and_upload/) the link. thanks and may the rust be with you.
&gt; Going back on more technical aspects, you'll find articles saying that Rust and Go don't play in the same park, that Rust is a systems language because it doesn't have a GC, etc. I think this is becoming less and less true. **Rust** is climbing higher in the stack with great web frameworks and nice ORMs. It also gives you that warm feeling of **"if it compiles, errors will come from the logic I wrote, not language quirks I forgot to pay attention to"**. I didn't expect to find such a nice summary of what makes me think Rust is a joy to use in an article about Go ;) Apart from that, I really appreciated the article; but it's about Go.
Nice! I don't work on the packager myself, but I'll forward this internally for awareness. FWIW, the R in RPM is no longer for Red Hat -- it's now a recursive acronym: RPM = RPM Package Manager. (Also, Red Hat should be written as two words, despite the logo appearing as a single word "redhat" -- this is something to be fixed by the [Open Brand Project](https://www.redhat.com/en/blog/open-brand-project-what-problems-do-we-need-solve).)
Check out *ring*: https://github.com/briansmith/ring
&gt; (if false { 1u32 &lt;&lt; 2 } else { ::mutagen::ShlShr::shl(1u32, 2, 42) }) That's a clever way of forcing type unification without actually having to guess the type!
Issue is that ring is not completely rust native (yet), they still depend a good but on BoringSSL.
&gt; For a dose of WebAssembly magic, right click on `main.c` and select: &gt; … that’s right, Clang Format is also compiled to WebAssembly, runs locally, and works great. What is the footprint of the Clang Format tool compiled to WebAssembly?
Given that Actix 0.3 was already 7th of TechEmpower (plaintext), do you have a prediction on how high 0.5 could rank?
[https://www.youtube.com/channel/UCiHGZz2gt1a0okR5\_lwrtNQ/videos?view\_as=subscriber](https://www.youtube.com/channel/UCiHGZz2gt1a0okR5_lwrtNQ/videos?view_as=subscriber) you can check here my friend for funny and more videos.
How does a struct know which methods are available to it at runtime?
You can probably use Fortran's `ISO_C_BINDING` module to have your code work with Rust through the FFI (Foreign Function Interface).
&gt; Shifts happen You take your upvote and get out of here
This is really exciting. I've got a couple large projeccts I'd love to port over to actix at some point but I'm pretty skittish on moving over to another pre-stable framework. Do you have a roadmap for 1.0?
It doesn't: method resolution is done at compile time. 
It's more of a temporary thing; there are a bunch of lints with lots of false positives that we want to turn off. Also, this isn't many lints, it's like three. Mostly we spent time better categorizing the lints. And clippy is meant to be used with liberal application of manual lint level setting, so it really doesn't matter much.
[`strum`](https://crates.io/crates/strum) has been a more recent library that operates in the same space as the `enum_str` crate that you mentioned in the OP. Check that one out too!
ffmpeg? I am not sure about good bindings, though.
With this API, I can have a type like `Collection` as in the blogpost that has a temporary pointer into an `Entry`. An `Entry` just needs to be `Pin`'d, and this can be done on the stack; while it's not the case in the blog post, a `Collection` type structure can *also* be on the stack. So with this API, the container (in an older stack frame) can temporarily hold a pointer into a pinned entry (in a younger stack frame); the pinning invariants ensure that the younger entry will clean up the old reference before we return to the old stack frame. Thus, we're not actually referencing a stack after it's closed; we're taking advantage of the fact that the cyclic reference is only temporary, with a known lifetime.
Hi, I've visited the link but I can't approve it and the user is listed as [deleted]. Did you delete the post?
N/m that other comment just now, I just read the modmail :)
https://boats.gitlab.io/blog/post/2018-03-20-async-vi/ solution to the async I/O issue. https://www.ralfj.de/blog/2018/04/05/a-formal-look-at-pinning.html - What are the formal guarantees? and https://www.ralfj.de/blog/2018/04/10/safe-intrusive-collections-with-pinning.html - an application to intrusive data structures (quite exciting to me!).
Two suggestions for different scenarios I see: * If all you're doing is appending, like you mention in a sibling thread, then you only need a queue of strings received at some server that appends to a file. That case is much, much easier than full collaborative editing. * If you DO want to do full collaborative editing, then you'll probably want to start with a good library to take the hard part out. Luckily, [Ditto's string CRDT](https://docs.rs/ditto/0.1.0/ditto/text/struct.Text.html) would cover most of that -- you'd essentially be wrapping that data structure with whatever your application needed to communicate changes to clients.
This is super-neat! I'm looking forward to seeing this grow!
Chrome dev tools shows `clang-format.wasm` weighs 2.7M and requires another 32K of JS glue code
&gt; terminolgoy *terminology FTFY. :)
I'm wondering if that is even possible with the current API and XML's many ways of representing objects (attributes, tags). I guess only a subset of XML could be used, which would make it much less useful.
Took me two days to come up with that solution. I initially had an active `if` condition (and the SO answer reflects that), but that would have impacted coverage measurements.
I WILL NEVER LOG OFF!!!1! (Sorry, I just had to, y'know?)
it is very hard to tell, especially that TechEmpower now uses new hardware. i think plaintext benchmark in round 15 is largely bounded by hardware and that is the reason why top results are very close. i expect 0.5 should stay at similar position on new hardware, 0.3 would be lower, but we should wait till next round.
i am waiting async/await for 1.0 release. i do not expect any major api changes before 1.0 in any case. i'd say 0.5 is perfectly safe for production. i have some performance related ideas for 0.6, but that should not affect any of public api. 
ugh, thank you
Perhaps you misspelled "hug." Would you like one? 🤗 --- I'm a bot, and I like to give hugs. [source](https://github.com/as-com/reddit-hug-bot) | [contact](https://www.reddit.com/message/compose/?to=as-com)
[websocat](https://github.com/vi/websocat) - the async version. [When](https://github.com/vi/websocat/issues/1) I finish the basics and publish the crate, I'll announche it in a separate post.
This is a general issue I've run into with Rust. Debug builds don't build with debug versions of the standard libraries, so things like that are harder to diagnose. I've had this issue with with passing null pointers to [`std::slice::from_raw_parts`](https://doc.rust-lang.org/beta/std/slice/fn.from_raw_parts.html). See this point &gt; p must be non-null, even for zero-length slices, because non-zero bits are required to distinguish between a zero-length slice within Some() from None. p can be a bogus non-dereferencable pointer, such as 0x1, for zero-length slices, though. Ideally there would be a debug assertion in there, but you can't get it because there isn't a debug version of the libraries.
Hahaha I second this. I'm amazed by how many times the compiler tells me exactly what I need to change
For an assignment at uni this sem I hacked a serde serialiser together over the top of quick-xml. When (Australian) semester ends I’m going to tidy it up and ask for permission to open source it. It wasn’t suuuuuper friendly to tie it in with serde, but I managed to give developers control over whether things serialised as attributes or child tags just from their Serialize impl. Get keen 
Cool crate ! Might be interesting to make it even more generic (not only str but use generics)
Reporting in from the future with a correction to your correction. In the blog post, you added &gt; Rust has a special syntax for requiring two types to be equal in where clauses, notably the surprisingly unsurprising `where T1 = T2` Not quite right. This only applies to associated types: `where T1: Trait&lt;Assoc=T2&gt;`. If for some reason you need other type equality in a where clause, you still need a `Same` trait. 
I know that rust favours traits over function overloading, and I quite appreciate the intention after seeing ziggurat methods such as something like the following in a codebase I used to work on quite a few years ago: void sendEmail(String mailType, String from, String to) { sendEmail(mailType, from, to, null); } void sendEmail(String mailType, String from, String to, String bcc) { sendEmail(mailType, from, to, null, null); } void sendEmail(String mailType, String from, String to, String bcc, File Attachment) { // do stuff } (Yes, one idea to correct that behaviour in java would be to just create a Mail object and populate it, but that's besides my question, methods with additional parameters were added year after year, and even if the behaviour is centralized it needs to be tested). My question is: what is the favourite way to cope with lack of function overloading, with regards to object constructions or incremental addition to APIs? Is there any way to guarantee somehow that if today I have a method send_email with three parameters, existing callers can still call it with three parameters and new callers can call it with four or five? Without having someone on my team who just recreates the pattern by defining fn send_email(...) ... fn send_email_harder(...) ... fn send_email_with_a_vengeance(...) 
Bad bot. Of all the times for that bot to show up...
Thank you, ErichDonGubler, for voting on hug-bot. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://goodbot-badbot.herokuapp.com/). *** ^^Even ^^if ^^I ^^don't ^^reply ^^to ^^your ^^comment, ^^I'm ^^still ^^listening ^^for ^^votes. ^^Check ^^the ^^webpage ^^to ^^see ^^if ^^your ^^vote ^^registered!
No worries! It's be insane with all the writing and communicating you did if you didn't make a *single writing error* every once in a while. Thanks for making Rust docs awesome! :)
&lt;3
There are several options. - Use arguments of type `Option&lt;T&gt;` - Have one argument which is a struct containing required and optional arguments (so also `Option&lt;T&gt;`) - Use the [Builder pattern](https://www.javaworld.com/article/2074938/core-java/too-many-parameters-in-java-methods-part-3-builder-pattern.html), which can be [automatically derived](https://crates.io/crates/derive_builder) 
&gt;To any Java developer this definitely looks like a try / catch (DecodingException ex). So Go does have exceptions, uses them internally but tells you not to. One could argue that Rust also sneakily implements exceptions because `std::panic::catch_unwind()` is a thing, but I can't think of any examples of anyone actually trying to abuse the API like that.
Yep, that's how I would do it. Write a `iso_c_binding` funcion in Fortran, write the corresponding declarations in Rust and done! `iso_c_binding` is a fortran 2003 feature, so if you need to use older code and can't/don't want to write a wrapper, you can also use the old tricks for calling fortran code from C and apply them from Rust. The main issue with the old tricks is that they are compiler dependant (name mangling and array ABI are the main things to look for here).
Why not just [`select`](https://docs.rs/futures/0.1.18/futures/future/trait.Future.html#method.select) between a make-a-request future and timeout future and throw away the returned future?
Does anyone know how, in actix-web, how to accept unstructured Jon, i.e. not easily serializable from a set struct, in a request handler?
is it json? you can use `Json&lt;serde_json::Value&gt;` or you can desalinize request body to a `String` or `bytes::Bytes` just replace `body: Json&lt;Info&gt;` with `body: String` or `body: bytes::Bytes`
Thanks for all the pointers! For what it's worth, I've considered trying to upstream some of this stuff via https://github.com/rpm-software-management/rpm but thought I'd wait until it isn't vaporware
It will be compressed over HTTP though, and it compresses fairly well. gzip -9 brings it down to 914kb.
I'm really picky as you could see in my above comment. And it was killing me the amount of open PRs and issues in Rocket without any feedback. I think it has improved lately but still. The author of Actix-web is running the project how I like it, no PRs are keep open for long, issues are addressed immediately. Definitely things will change in the landscape. I'm hesitant of recommending you to jump ship as it may happen that something new and shiny will come next (tower-web maybe?) and if you keep migrating your app, you'll get nothing done. If you are happy with Rocket, keep at it. Maybe consider Actix-web for your next project.
I guess it's also useful at the framework level, like in a test framework, to assert that it fails with a specific error. Or maybe as a global error catcher that instead of dumping the stacktrace to STDERR will format an email to send to the developers (if the user approves, of course)
&gt; but I can't think of any examples of anyone actually trying to abuse the API like that. The problem is that if you try to use this API for error handling, and some point later set `panic=abort`, you are basically screwed.
Thanks, works really well.
I was also thinking about this when reading that part. This doesn't work when panic = abort, though, so a sane library should generally avoid using this in their control flow.
The reason the program is crashing is because you're unwrapping an `Option::None` -- which `input.parse::&lt;f32&gt;()` will invariably return if you're not `trim`ming the input you're getting from `read_line`. Why's that, you ask? Well...`read_line` doesn't trim the newline by default -- so you should get the reference that calling `trim` on your input returns and use that to parse. See [this playground](https://play.rust-lang.org/?gist=0d256731aa27d56d7751cedc5b1049c4&amp;version=stable) for a quick working example. Other thing: there's nooo reason to be using `unsafe` here. I imagine you put it there to see if that would make things work, but that's something you would ordinarily do to pass compiler checks, not run-time checks. ;) 
Counterpoint: [A small group of people feasibly coercible by a government controls ~90% of the hashrate, and sometimes gather in physical proximity](https://mobile.twitter.com/lopp/status/673398201307664384?lang=en)
The gist of your problem seems to be that you're calling `unwrap` when `parse` is returning an `Option::None`. That's expected behavior, and this will actually happen no matter what you type into `stdin` right now. The problem is that `read_line` doesn't trim the newline when it gives you a `String` back -- so you'll want to call `trim()` on it and use `parse` on the reference that the `trim` call returns instead ([here](https://play.rust-lang.org/?gist=0d256731aa27d56d7751cedc5b1049c4&amp;version=stable)'s some quick example code). You'll probably still want to handle the case where you fat-finger the keyboard and type something wrong, though! Other thing: there's nooo reason to use `unsafe` here. I imagine you were using it while experimenting to determine the problem, but think of it this way: you use `unsafe` to convince the *compiler* that you know what you're doing when it's refusing to compile your program based on ownership. If you're already able to compile and run the program, then you probably don't need `unsafe` to fix problems you're seeing -- in fact, it might mean you should take a good hard look at your `unsafe` usages to see if you really need them!.
Keep on pluggin'! We want to see you succeed. :) Anything we can do to help you out?
I [forked](https://github.com/Thiez/569-Project-2) your project and [wrote some Rust as if it is C](https://github.com/Thiez/569-Project-2/blob/master/rust/jacobi/src/lib.rs). We lose nice properties such as bounds checking, but it's a nice goal to work towards with a safer implementation. Oh, and I dropped Rayon. On my machine it's about 4 times faster than the OpenMP implementation, but ymmv.
You're probably still crashing because you're not clearing `temp` after reading a line into it. The [docs for `read_line`](https://doc.rust-lang.org/std/io/trait.BufRead.html#method.read_line) says (emphasis mine): "Read all bytes until a newline (the 0xA byte) is reached, and **append them to the provided buffer**." So, when you iterate through, here's what's happening: $ ENTER ALL TEST SCORES $ 12 // `temp` contents: "12\n" // This will parse, woo! $ 14.0 // `temp` contents: "12\n14.0\n" // PROBLEM: `temp.trim()` will now return "12\n14.0". ``` Is there a reason you need global variables? This seems a pretty easy case of just making your variables local.
I am using globals because my Professor, who has openly admitted to never using Rust, is demanding we do not pass EXAMSCORE to any function, yet still use and change it in multiple functions. I understand it's a bad practice in Rust, but if I don't do it how he wants I will lose points. And so I just need to do temp.clear(); ?
Such as [serde-xml-rs](https://docs.rs/serde-xml-rs/0.2.1/serde_xml_rs/fn.serialize.html)? 
&gt; I am using globals because my Professor, who has openly admitted to never using Rust, is demanding we do not pass EXAMSCORE to any function, yet still use and change it in multiple functions. I understand it's a bad practice in Rust, but if I don't do it how he wants I will lose points. Really? He wants you to use Rust without having used it himself??? Interesting! Do you know his motivation? :) Anyway, just want to do my due diligence in making sure you know best practices. That's kinda meh that your professor wants to enforce globals without a technical justification, but then...I guess that that sort of gets you in practice for when you don't agree with others' decisions at your eventual day job! &gt; And so I just need to do temp.clear(); ? I'm betting so. :) I edited my post above to make that explicit, but it looks like I was too slow!
https://www.youtube.com/watch?v=P2mooqNMxMs
Good work on the new release! We have been working on migrating from Shio to Actix-Web for a project we're using. I have to say that /u/fafhrd91 is impressively responsive on issues that I have stumbled across. I feel like I am driving the ClientRequest development as we have to proxy a lot of services. Are there any migration guides for `0.4` to `0.5`?
i will add it shortly
porting is easier than new design/implementation.
added [MIGRATION-0.4-0.5.md](https://github.com/actix/actix-web/blob/master/MIGRATION-0.4-0.5.md)
Dude your teacher is *really* stupid.
Also, the stack trace gets written when the panic occurs, not when it's caught, if stack traces are turned on. There's a reason there aren't any libraries like Go's JSON implementation using panics under the hood like that.
&gt; Really? He wants you to use Rust without having used it himself??? Interesting! Do you know his motivation? :) Sounds like the price-wheel assignment method. "Let see, Joe gets Java and... (spins wheel)... C. Bill gets Java and ... (spins again)... Nim! Neat-O! Chudleyjustin gets Java and... (spins one last time)... Brainfuck. Hoo boy, you're in for a fun semester!"
As pointed out in the article, `encoding/json` was recently changed to use normal error returns instead of panic for control flow.
Given the rather ridiculous constraints you're under, that actually looks quite nice. Well done!
Your `::new` function should be `unsafe` as well, raw pointers can be freely created to point to anything.
Since no one has mentioned it yet you could remove the unsafe code if you want to by wrapping the global in a `Cell` struct. This will work for single threaded code.
Whoa, awesome, thanks!
Good to know, thanks!
I think you're talking past each other. This is probably due to your framing here: &gt; This API allows you to follow a "&amp;mut" pointer and generate two out of it. This is incorrect. The API lets you take an `&amp;mut` pointer and generate a single `&amp;mut` pointer out of it. You will not be allowed to do this again; `Self` will be borrowed until you relinquish the borrow on the inner pointer. This is how all `&amp;mut -&gt; &amp;mut` APIs work. It's how they've always worked. The way you generate two out of it is if you clone it first, and then call it on the two refs. That's well in the purview of "misuse of an `unsafe` API by the caller" as /u/dabaross is arguing. Depending on the specifics of what we decide in the unsafe code guidelines work, if this API was `&amp;self -&gt; &amp;mut T` it would indeed be unsound (as in, "totally broken even if marked `unsafe`") because you still have the `&amp;Self` around (and not "locked" by the borrow). However in its current state, `&amp;mut -&gt; &amp;mut` locks the original `&amp;self` so in and of itself the API isn't broken, as long as it's marked `unsafe` ------------------ You are 100% correct that if unsafe code breaks the `&amp;mut` aliasing rule it's in just as hot water as safe code. However. It is totally okay to have an `unsafe` function that _if misused_ lets you alias `&amp;mut`, with its guarantees documented. For example, the following function is totally okay to write: /// precondition: `rc` is a unique reference unsafe fn mutate_rc&lt;T&gt;(rc: &amp;mut Rc&lt;T&gt;) -&gt; &amp;mut T { } One can imagine this being a building block of something like `Rc::make_mut` or being called immediately after construction of an `Rc` (perhaps you wish to do an in-place operation so can't do this before construction? Perhaps the `Rc` was in fact initialized by FFI code that you can't control? Perhaps it's a DST!) There's a distinction between unsafe-as-in-broken and unsafe-as-in-makes-it-possible-to-break-things. I've [written about something similar before](https://manishearth.github.io/blog/2017/12/24/undefined-vs-unsafe-in-rust/). "unsafe-as-in-broken" code, i.e. code that exhibits UB, should never exist in Rust. "unsafe-as-in-makes-it-possible-to-break-things", however, is totally fine, provided it is only within an `unsafe fn` and you document the preconditions that make it not-break-things. This is literally why `unsafe fn` exists. 
&gt; Rust is one of those friends that take some time to get along with, but that you'll finally want to engage with for a long term relationship. QOTW?
Ah, I see, so it's exact as long as it isn't "dynamic", meaning someone can get a guarantee on stack usage by ensuring everything is "static" (which seems like a good idea). Thanks for explaining.
looks like my vscode.
We use `catch_unwind` in rayon to protect the thread pool from panics, so stolen jobs won't ever reference a stack that has been unwound elsewhere, but we always `resume_unwind` eventually to make the caller deal with it. If the program is configured with `panic = abort`, that's fine too.
That's not a coincidence, the editor is powered by Microsoft's Monaco library which VSCode also uses.
Glad you liked it. Thats kind of the point I wanted to make! Rust is thought to be difficult to get started with because "the program doesnt compile." But the team has done such a great job with the error messages that the compiler rather than be a blocker becomes your friend.