I have updated my post with this version (or close to it). Thanks. Posting my attempts to here is really teaching me a lot via the feedback I receive from everyone.
[Here](https://bitbucket.org/minno/rust-playground/src/c78299e5337b95a78fc6030fbfe2d0da5a79aadd/pjeuler/solve2.rs?at=master) is my version, from a fair number of Rust versions ago. This was also before I knew about the `Class::new()` tradition for constructors, but otherwise I don't see anything especially nooby in there.
Yea, I missed that, of course they should return `Option&lt;Item&lt;'a&gt;&gt;`.
Thanks for the iterator implementations. This is the kind of thing I was after, but the docs don't really mention custom iterators much. I'll add this to my solution when I get time. 
I run [brooklyn.rs](http://brooklyn.rs), but have been very poor about actually calling meetings. Excited to see other stuff cropping up!
micro benchmarks of typical usage patterns (iterators, error handling, ...) should already be possible tho, one has to start somewhere :)
Added to the [calendar](https://www.google.com/calendar/embed?src=apd9vmbc22egenmtu5l6c5jbfc%40group.calendar.google.com).
higher-kinded type (template template parameters in C++)
If you're interested in discussing the Rust video game, /r/playrust is where you want to be. If you're interested in talking about Rust servers, /r/playrustservers is the place. This subreddit, /r/rust is for a programming language called Rust, which is unrelated to the Rust video game.
This talk went really well! A great introduction.
It wasn't nice, but wasn't spam either.
Thankyou. Also never heard of Rust and am a 1st year Computer technologist program. So I may look into this on my freetime.
There's the [Trigonometry Intense Floating Point Benchmark](https://www.fourmilab.ch/fbench/fbench.html) where Rust performs rather favorably. If we rolled our own math library into libstd (à la [rlibc](https://github.com/mahkoh/rlibc)) instead of using the system's libm, I bet we could do even better though ;) 
ok thanks, unfortuntely I was busy and wasn't able to jump in, I'll wait for the recorded video.
&gt; nmatsakis: rustfmt is indeed often requested. I could even imagine automatability would be a factor in the style guidelines. That would be great. If there is one lesson I took from Go is that `gofmt` has completely killed the styles debates: write code, `gofmt`, no nitpicking during review about spaces/tabs, less/more indenting, comment styles, opening the brace on the same/next line, ...
And what's the problem with using my definitions? The demos do exactly what you want, just working on individual elements instead of slices. You could make a mutable sliding window iterator with it, for example.
It was presented live, we don't have time travel yet ;)
there's PartialOrd now ? are there versions of those functions (max,sort) for that?
I've updated the post and code to use an iterator and added some timing results. Naturally the iterator is much faster. Again, many thanks. This is a great way to learn a lot about Rust, slowly, but surely. Make mistakes and fix them with help from those who are more experienced.
PartialOrd has been around a long time: http://doc.rust-lang.org/nightly/std/cmp/trait.PartialOrd.html
Moving/renaming happens after the closure is called... I couldn't find a way to match `io::File`'s API (cleanup resources when moving out of scope), since I need to be able to give the user errors during teardown.
To me, these two concepts look similar and should be merged if possible. :)
 fn fib(n: i32) -&gt; i32 { fn inner(a: i32, b: i32, n: i32) -&gt; i32 { if n == 0 { b } else { inner(b, b+a, n-1) } } inner(0, 1, n) } Is the best I can come up with. I benched it against your one and I had to keep putting the number down because otherwise your one wouldn't finish (and also some numbers were too high to be represented by 64-bit integers). In the end I was benching how long it took to calculate the 30th number of the sequence. test bench_fib_dynamic ... bench: 10 ns/iter (+/- 1) test bench_fib_recursive ... bench: 5139562 ns/iter (+/- 27244) Here's the benchmarks in case I screwed something up. My method seems like it was way too fast: #[bench] fn bench_fib_dynamic(b: &amp;mut Bencher) { b.iter(|| { test::black_box(fib_dynamic(test::black_box(30))); }) } #[bench] fn bench_fib_recursive(b: &amp;mut Bencher) { b.iter(|| { test::black_box(fib_recursive(test::black_box(30))); }) } 
Good catch! And there almost certainly are. Ideally I'd have `rust-core-graphics-sys` bindings, and a higher level `rust-core-graphics` RAII api.
Oh you're right. Although it's not on [crates.io](https://crates.io). 
Perhaps for loops should support two types of iterators.
There also exist generic methods that take `&amp;Foo` *and* `Foo`, with different semantics (e.g. IntoIterator is proposed to act like this on collections). One can have "conservative" autoref (only autoref if necessary to type-check), but it makes it a bit fuzzier, in my mind.
This would be awesome.
I sure wouldn't mind unsafe blocks as long as it actually works.
The problem is that many operations on non-`NaN` floating point numbers can produce `NaN`. Unless the values are immutable, it would be really hard to adequately convince yourself of something like that in general, I suspect (especially given how fun floating point math is) and I doubt you could enforce it in the existing type system. By contrast, there aren't any operations in safe code that make references null.
There's nothing inherently preventing a static mutex (that doesn't protect data) from being recursive, no. In fact, the one on Windows was recursive until very recently (unfortunately, this was also in a non-static context, so it was unsafe). Rust just doesn't expose one in the standard library yet. That being said, I find that it's *very* rare that well behaved code acquires mutexes recursively. It's usually a warning sign that you are not adequately controlling the order in which you lock your mutexes, which usually means that you can deadlock in other ways.
:) I tried to help with easy questions in the chat, hope I wasn't overbearing.
As someone who does favor explicitness, my current feeling is that Rust is already eliding references often enough that we're not going to be happy anyway, so it might as well be consistent and autoref :P If there's a future syntactic reason to avoid it, as Gankro suggests, it becomes less clear, of course.
sure. Tracking down NaN cases is indeed 'fun' as you put it. but it is possible to work a system to a point where nans don't appear (if you have control over the inputs, you'd need to verify things on creation or reading in)
Looks interesting. I have some code that needs just this functionality. Notes: - To have the `link`/`unlink`/`rename` actually commit, you'll probably need to fsync() the source and dest _directories_. IIRC from the last time I read into this, posix is rather unclear on the actual semantics here. - Linux has an API to create files that don't initially exist in the filesystem's namespace but can be linked into place. It would be cool to take advantage of that. 
Re: your second point, last time I actually tried to use that API it had some bugs, and I couldn't find anyone who knew how it worked in sufficient detail to help (tried on #kernel even). But it might be different now.
Damn that would be sexy, if aturon is right and we can do this in a backward compatible fashion, I think it would be great to generalize the API! +6.0221415×10^23
There seems to be [something](https://github.com/rust-lang/rust/blob/583c5c589ed02e5b6b14a576e35e0ce68988d949/src/libstd/sys/windows/tty.rs#L135-L148) for windows while the same method is [unimplemented](https://github.com/rust-lang/rust/blob/583c5c589ed02e5b6b14a576e35e0ce68988d949/src/libstd/sys/unix/tty.rs#L41-L43) on any unix. This method is exposed, however, on [the return type of `std::io::stdio::stdout_raw`](http://doc.rust-lang.org/std/io/stdio/struct.StdWriter.html#method.set_raw), not `stdin_raw`. Also, the `_raw` suffix (confusingly) refers to the lack of Rust-specific buffering, and it's unrelated to the raw mode.
&gt; steve: Not a big fan of reddit because it's not consistent with our values; would rather be off it. /u/steveklabnik1 could you expand this quote? I'd be interested in understanding the clash in values here. FWIW I really enjoy following this sub. It's been my main source of information and food for thought about all things Rust for many months. And since I'm not an IRC person (my English is not fluent enough, so I get lost pretty easily on the multiple simultaneous conversations), maybe I wouldn't be around anymore if this sub didn't exist/was abandoned.
I'm on mobile, but I'll just say I mean 'Reddit' not /r/rust. This place is mostly pretty okay, because it's not like the rest of Reddit. That said, many people don't know that, and I'm not interested in promoting Reddit as a whole. And if this didn't exist, I'd hope you would have joined us in the Discuss instance.
80% of the time I spend on Reddit I'm on /r/rust (the rest would be mostly /r/science, /r/netsec and /r/linux), so maybe I'm seeing Reddit on a better light than it deserves. I think I see what you mean though.
Lots of low quality benchmarks, at least when they compare games (by systematically comparing drivers and video cards with games like OpenArena that uses the id Tech 3 engine, first developed in 1999 and open sourced in 2005).
Shutting down the mailing list without telling the folks using it isn't very nice. I'm also not a fan of shutting it down at all, esp. given the outcry on the ml when people found out someone was considering shutting it down. Of course, they only found out about this because someone happened to notice a discuss post :( Edit: and we're shutting down /r/rust too? &gt; Can also work with the reddit mods to help them move people to discuss
Check out the closed PRs on rust/rust-www. TL;DR is that it's for core language dev, not for general usage. This second instance will absolutely be linked.
&gt; so multiple calls to .next are safe, even when the previous reference wasn't discarded. If you end up here, then I don't really see how you have a streaming iterator. [erickt explains.](http://www.reddit.com/r/rust/comments/2sxnk8/an_initiation_for_a_mapreduce_framework/cnuxho0) ([The demo](http://play.rust-lang.org/?code=trait%20StreamingIterator%3C%27a%3E%20%7B%0A%20%20%20%20type%20Item%3B%0A%20%20%20%20fn%20next%28%26%27a%20mut%20self%29%20-%3E%20Option%3CSelf%3A%3AItem%3E%3B%0A%7D%0A%0Astruct%20Buffer%3CT%3E%20%7B%0A%20%20%20%20data%3A%20Vec%3CT%3E%2C%0A%20%20%20%20pos%3A%20usize%0A%7D%0A%0Aimpl%3C%27a%2C%20T%3E%20StreamingIterator%3C%27a%3E%20for%20Buffer%3CT%3E%20%7B%0A%20%20%20%20type%20Item%20%3D%20%26%27a%20T%3B%0A%20%20%20%20fn%20next%28%26%27a%20mut%20self%29%20-%3E%20Option%3C%26%27a%20T%3E%20%7B%0A%20%20%20%20%20%20%20%20let%20x%20%3D%20self.data.get%28self.pos%29%3B%0A%20%20%20%20%20%20%20%20self.pos%20%2B%3D%201%3B%0A%20%20%20%20%20%20%20%20x%0A%20%20%20%20%7D%0A%7D%0A%0A//%20I%20demoed%20this%20with%20a%20closure%20because%20of%20an%20issue%20with%20associated%20types%20that%0A//%20makes%20%3CI%20as%20StreamingIterator%3C%27a%3E%3A%3AItem%20not%20known%20to%20be%20%26%27a%20T.%0Afn%20map_collect%3CT%2C%20I%2C%20F%3E%28mut%20iter%3A%20I%2C%20mut%20f%3A%20F%29%20-%3E%20Vec%3CT%3E%0A%20%20%20%20where%20I%3A%20for%3C%27a%3E%20StreamingIterator%3C%27a%3E%2C%0A%20%20%20%20%20%20%20%20%20%20F%3A%20for%3C%27a%3E%20FnMut%28%3CI%20as%20StreamingIterator%3C%27a%3E%3E%3A%3AItem%29%20-%3E%20T%20%0A%7B%0A%20%20%20%20let%20mut%20v%20%3D%20vec%21%5B%5D%3B%0A%20%20%20%20while%20let%20Some%28x%29%20%3D%20iter.next%28%29%20%7B%0A%20%20%20%20%20%20%20%20v.push%28f%28x%29%29%3B%0A%20%20%20%20%7D%0A%20%20%20%20v%0A%7D%0A%0A%0Afn%20main%28%29%20%7B%0A%20%20%20%20println%21%28%22%7B%3A%3F%7D%22%2C%20map_collect%28Buffer%20%7B%0A%20%20%20%20%20%20%20%20data%3A%20vec%21%5B0u8%2C%202%2C%203%2C%205%5D%2C%0A%20%20%20%20%20%20%20%20pos%3A%201%0A%20%20%20%20%7D%2C%20Clone%3A%3Aclone%29%29%3B%0A%7D) from /u/eddyb looks neat. Note that `collect` is only implementable via `clone`.)
I know it's /r/programmingcirclejerk but this makes even less sense than the usual circlejerk material.
Can we ban this bot? Or ask them to exclude this subreddit? I don't like the idea of other parts of Reddit leaking in here...
Good point, thanks. I'll send a message to the mailing list tomorrow.
A lot of subreddits ban bots, I think it's just a matter of the mods banning the user.
It's possible for the mods to ban that bot, which would be nice.
I would disagree that forums are better than reddit for some questions. Forums are linear while reddit is threaded, and voted. If you're looking at an older discussion/question (like "What's the best way to ...") it's much easier to find the good responses on reddit than trolling through pages of responses on a forum. Reddit discussions simply scale better. Also remember that reddit was started as a news aggregator, and I personally think it's great for it. News discussion is great because the threaded comments keep different discussions compartmentalized - perhaps it's not better for participating, but it's excellent for reading the discussion. 
What's wrong with you? If anything, this article is a great counter example to your opinion here. I think it's a good introduction for people who never heard of servo before: what, who, when, why, ... All given! And it still has new information for people who know what's afoot, e.g. what rust code will land in gecko first. All while being short. Great summary!
On Unix the easy thing to do is shell out to `stty -echo`.
That's great! I doubt you were overbearing. The moderator picked the questions marked with "Q" out for me, so I didn't need to watch the chat while I talked, and could concentrate on... saying lots of words. :D
I don't think Rust will ever have that. If that kind of syntax is something you *need*, stick to Haskell.
Oh yeah, reddit's search feature is awful. Though if you're careful with your wording it can be okay on small subreddits like this.
I believe that in the long term perspective discuss's destiny is what is planned for internals.rust-lang.org Since language is going to be stable soon and more people investing time into learning, most of questions will move out: - to SO - to blog posts (to be precise, answers will be there)
Reddit has a few isolated islands of niceness. Like this subreddit, for example. I'd be upset to see it gone.
And reddit is a place I visit quite often. I don't even know the URL to the supposed replacement of this sub. Do I need another account as well? Edit: I found the link and read a bit. It seems more like a place for the people who make rust itself rather than for users of rust. IMHO.
Note that this isn't crazy at all - this is exactly how D does its collections (except it uses duck-typing rather than traits). If we do this, we should look at how it works there, as they have spent years evolving this API and making sure it's efficient (note that they make heavy use of CTFE to ensure that). * Some of the primitives involved: http://dlang.org/phobos/std_range * A tutorial about usage: http://ddili.org/ders/d.en/ranges.html You should be able to follow the latter without knowing D, providing you're familiar with C/Java, and know that the template declaration syntax uses `()` rather than `&lt;&gt;`.
There is a crate for this too -- using tcsetattr to be clear -- termio.rs.
Is there actually any need to recreate all these complications with a lot of different types many of which are the same, e.g. DWORD, ULONG, ULONG32, UINT, UINT32 are all u32, why not just use u32?
Rust used to have a repl in mainline, but it kept bit rotting. People are working on it so presumably it will exist at some stage. Whether it's integrated into mainline or blessed ala cargo probably won't be known until a working version appears.
&gt; If the rust developers want to abandon this sub, fine, but at least hand over the control to a couple enthusiasts. Ohh, come on, can we do it without a drama? :-) CORE developers weren't pretty active here (at least last year) and moderation team are actually enthusiasts (except huon) so de facto nothing changes.
&gt; Research activity happens where core developers. Not to the exclusion of other locations. /r/haskell has plenty of very interesting stuff going on that pushes the limits of what the language and library ecosystem can do without very many (any?) haskell commitee members posting regularly. Research can be as simple as trying to maximise the safety of a common api implementation (libc springs to mind) or a malloc or a GC or whatever other things are traditionally reserved for C/C++. I don't see any justification for a claim that research activity requires the core devs to be around.
&gt; moderation team are actually enthusiasts (except huon) I'm not enthusiastic enough? :) (I am on the core team, but I am not a Mozilla employee: my Rust work is volunteering.)
Thanks for the answer; yes I've seen the recent issue/PR regarding the mutex on Windows being recursive. How would you implement a recursive static mutex in Rust though? How would a thread "know" whether the lock on the static mutex was previously acquired in the same thread?
Maybe he was just surprised? Even though his comment gives off the aura of being annoyed, it might be he worded it to give the wrong impression by accident.
It's still more polite to ask the author the permission. He might prefer to wait for the project to be stable enough before advertising it.
&gt; Research can be as simple as trying to maximise the safety of a common api implementation It seems we're talking about different kind of researches. I though about language changes and/or std lib changes - both of which have a specific workflow in Rust - pushing an RFC and discussing it, which kind a requires core devs around.
Might just be someone who is confused about copyright. A lot of people seem to have absolutely no idea about how copyright works.
I joined Reddit just for /r/rust, and have it hooked into my RSS reader. The layout is very dense which is excellent, and it is fast. Whatever is intended to replace it needs to be (more or less) as good or else it will discourage discussion.
It's okay, don't beat yourself up over it :P I'm mainly just surprised that people would find this library, which has nothing but incomplete bindings to WinAPI without even a nice wrapper around it, interesting enough to share on Reddit.
It isn't my job to judge the usefulness of a typedef. If it is in the Windows headers, then I include it in the bindings. It is the job of fancy wrapper libraries to provide a nice safe interface without the typedef insanity.
Cargo is bundled but it doesn't use the same repository as rust.
It's nice that the Flask (python) team is looking at rust :) I would love to see a flask inspired web framework in Rust. I was trying to make a Jinja2 clone, but realised I'm stupid and need to study jinja internals first.
The docs always need improved. Where did you look before?
&gt; where core developers are and they're almost unpresented here. What? There are devs from the core team on this subreddit, and they're pretty active too.
Sounds great to me :)
&gt; I aim to replace all existing Windows FFI in other crates with this set of crates through the "Embrace, extend, and extinguish" technique. I'm already embracing it. 
That still applies to cargo as well
Let's try to keep the discussion courteous. Facetiousness is a difficult thing to gauge minus any social cues.
This one covers to really interesting ideas that the title really covers: making `using` crazy, and allowing easier usage of struct-of-arrays layout (vs the much more common array-of-structs -- basically amounts to transposing the 2d-array an array-of-structs represents so every value of the same field is contiguous). # Crazy `using`: Basically everything is a namespace. Everything. This is sort of similar to how we use `Deref` and auto-deref to "forward" things, but taken to a logical extreme. I'll do all the examples in pseudo-Rust, since the syntax doesn't matter. So, say we have some nice simple entity struct. In most languages, a layout like this: struct Entity { position: Vec3, orientation: Quaternion, } Is used like this: fn foo(entity: &amp;Entity) { println!("{} {} {}", entity.position.x, entity.position.y, entity.position.z); } But we can "hoist" the entity's members by using it: fn foo(entity: &amp;Entity) { using entity; println!("{} {} {}", position.x, position.y, position.z); } Same thing, but with using hoisted into the args: fn foo(using entity: &amp;Entity) { println!("{} {} {}", position.x, position.y, position.z); } And we can do it to sub-fields: fn foo(entity: &amp;Entity) { using entity.position; println!("{} {} {}", x, y, z); } But we can also do it in the struct itself, making all the fields of position "look" like they're on Entity: struct Entity { using position: Vec3, orientation: Quaternion, } fn foo(entity: &amp;Entity) { println!("{} {} {}", entity.x, entity.y, entity.z); } And we can get all the inheritance-like functionality of C++ in the same way, but without forcing vtables and struct layout: struct Door { open: bool; using entity: Entity; angle: f64; } // both work foo(door); door.x; Note that you can be using arbitrarily many things, which exposes you to multiple-inheritance issues. Also note that `using`'d fields can still be referred to by name, if you want to get all of the Entity's position at once. This empowers us to refactor the layout of structs to be more memory-effecient without affecting how they're accessed in high-level code. In addition, you can `use` things that are behind a pointer, and it will Just Work the way you want. In particular he gives the following example of cache-optimizing an Entity so that the "hot" bits that are needed in tight loops are allocated seperately from the "cold" bits that are needed in high-level game logic. Fields can be moved from cold to hot freely *without changing how code that uses Entity works*. struct Entity { // hot bits are stored contiguously on an array somewhere using hot: &amp;HotEntityBits; // cold bits are stored in a seperate array to get them out of the way using cold: &amp;ColdEntityBits; } Edit: You can also `using` a function, which is basically Deref for us. In this way you could e.g. only store a `u16` instead of a proper 64-bit ptr and `use` a function that uses the index to retrieve the "field". ----- Still watching the SOA bits.
Why are LR grammars so freaking popular? I hate them, the error messages suck.
my idea for this was to make tuples auto-deref their components. i.e. imagine if `foo:(&amp;A,&amp;B,&amp;C)` could let you access named fields of `A,B,C` I think that could be retrofitted to Rust, since tuples already don't have named field access.. and you've also given a specific order to resolve ambiguity. this would achieve the same result. You could start with one 'class' (foo:&amp;X) with fields, then split it up into foo:(&amp;A,&amp;B,&amp;C).. A,B,C have the fields of X divided..), and code that uses it would still look the same .. just compose component references into a tuple, and perhaps they could auto coerce to different subsets (code that takes (&amp;A,&amp;C), (&amp;B,&amp;C) etc). I haven't watched his whole vid yet.. the using thing still makes one of the types special in the function, but with tuple deref you could have 2 entities e.g. `fn collide(first:(&amp;A,&amp;B), second:(&amp;A,&amp;B)) {.. }`
yes.. perhaps with more complex ambiguity it would be safer to report an error and require explicit disambiguation e.g. foo.0 .1 .x vs foo.1 .0 .x . 
I note that this hypothetical syntax: fn foo(using entity: &amp;Entity) { println!("{} {} {}", position.x, position.y, position.z); } ...could be emulated today by patterns: fn foo(&amp;Entity {ref position, ..}: &amp;Entity) { println!("{} {} {}", position.x, position.y, position.z); } Not only does this seem less prone to namespace pollution (and thereby accidental collision), it also doesn't obscure the aliasing and ownership concerns (which, given Rust's unique focus, seems to throw a wrench into OP's "everything is a namespace" credo).
That's effectively the same thing as having multiple `using` statements like Jonathan Blow does around the 27:00 mark in his video. The only thing is that this is a huge version compatibility minefield. There's a rule in Java that any published interface cannot have new methods added to it*. This is because when you publish your new version of the interface, you force all implementations of the interface to have to have to add the new method, or not compile. In C++, there's there diamond problem where if you inherent from two classes that have a member function of the same name, you cannot disambiguate, or something like that. When you use two using statements, you get a similar effect to both of these. You cannot add a field to any published struct because you cannot know whether somebody has written a function using your struct while using another struct that has a field of the same name that you just added. As such, every struct change is backwards incompatible and requires a major version number change in your semantic version. The same exact situation happens with autodereferencing tuples in the way you specify. Edit: This also looks a lot like the `with` statement in JavaScript. Only instead of having the shadowing ambiguity happen at runtime (which is insanely bad, and the reason no sane programmer should use `with` in JavaScript), it happens at compile time with the harshest point being when you update your dependencies or add fields to structs. *: Java 8 added default method implementations in interfaces which alleviates a lot of the issue when adding convenience methods. At least, I think it does. There might still be some issues with the shared namespace of class method names.
Seeing as you're here (hi): * Good job. Keep fighting the good fight. * How do you handle unions in structs? * Is there any reasonable way to set up tests for this?
A scala worksheet like application could also be useful.
/r/playrust
Thanks for paraphrasing! You probably just saved me 1h of my evening! (I would've watch on 1.5x speed, though ;)
Yes, that's the goal. Although, you could imagine still getting better perf if a Foo has dozens of fields, and you're only interested in a few of them (but still accessing them in the "traditional" manner). It also incidentally lets you give less fucks about field ordering, because e.g. struct { a: u64, b: u8, c: u64, d: u8 } will need massive padding junk between b and c if laid out as C would, but if SOA'd each field will be in a tightly-packed array of the same type.
Yeah, there are definitely benefits there, but there's also tradeoffs. The refactoring complexity moves from a change in my data structure causing all my code using the dot operator everywhere to be changed to a different chain of dot operators into having to rename a field because some other struct is already using that name for its own field. A little more thought on this, and it could be fixed with some extra explicitness. `using x, y, z in door.entity` instead of `using door.entity`.
This is squintingly similar to Javascript's 'with' and prototypal inheritance. Note that 'with' is pretty universally regarded as a mistake in that world.
&gt; to a different chain of dot operators into having to rename a field because some other struct is already using that name for its own field that field rename is definitely the lesser evil, by a **long** way. e.g. Its' easy to search the existing source base for currently used field names and pick something complimentary.. or rename an offending field and rename the uses by the errors. Also a very common use will be to *start* with packed, AOS code (its' intuitive, logical), *then* divide it up into components. Similarly you will sometimes want to do the reverse. So complimentary field names is probably a good habit to get into if in doubt. The cases he's dealing with would most naturally and logically be written in AOS form - fields in a single struct -until you told someone otherwise. &gt; A little more thought on this, and it could be fixed with some extra explicitness. using x, y, z in door.entity instead of using door.entity. That does sound like a nice tweak, but I think he's dealt with the most important pieces first. I would gladly use what he's created here as it stands.
It already does auto-ref for method calls and more so the problem you mention already exists. It is currently inconsistent and has the issue of verbosity *in addition* to that issue. The lack of this sugar was the rationale for limiting the numeric traits to primitives... and that kind of decision choice hurts more than theoretical problems with auto-ref *ever* would.
Common sense.. I don't think people would compose a vec3, vec4, vec2 with their x/y/z's clashing; but they might compose a position, velocity, name, inventory, bounding_box
Yep. Any bot that shows up in /r/programmingcirclejerk is instabanned with joyful cruelty.
&gt; This is a perfectly consistent rule The design is inconsistent because auto-referencing is used in some places but not others, even though the compromise is identical in each case. There is obviously a "consistent rule" applied by the compiler because that's how software works...
&gt;&gt; refactoring the interface if the effect is completely invisible? because its' the effect on data layout thats' absolutely critical for performance, whilst logically nothing changes. (infact, making it *clearer* that its' logically the same is a huge bonus) Fundementally most code would logically be written with packed structures - then it would be divided up into separate passes as an inconvenient necessity based on feedback from the profiler about cache misses. Then these hidden indirections let you keep the same logical code, whilst using optimised data layouts.. and as the logic evolves, you can still re-arrange and optimise further. (e.g. if there are 3 components A,B,C, the first pass needs A,B the second pass needs the B,C. but you original code using the packed original can be cut-pasted around and it will still look mostly the same. For gamedev, this is solving real problems that we deal with. There's no language that's been designed around cache optimisation.. its' always required code to be logically butchered and written in a less intuitive way. This is easily as important for gamedev as safety is to a web browser. This could easily be his languages' pillar feature that draws people to use it.
No, the compromise is not identical. There is a syntactic "place where the magic happens" that is easy to spot. The alternative would be for the autoref magic to be everywhere, which dramatically increases the number of places a programmer has to look to find out where references are happening. This is the exact same design that, for example, Go came to: pointer references are explicit, except for possible auto-ref on the left-hand-side of a dot-like operator.
No, it's not: function call notation, including the constructors of structures, arrays, and so forth are exempt from the rule, especially with UFCS. Let bindings are additionally exempt. (Also, I don't know what you mean by "attribute access": field projection does not autoref, it only autoderefs.) If the rule were applied everywhere or near-everywhere, there would be no need for the question in the OP.
Function calls don't have generic / type-based look-up so it's not a problem there. Rust already pays the price where it exists. The performance of Rust code isn't transparent when it comes to references and dereferencing. &gt; Also, I don't know what you mean by "attribute access": field projection does not autoref, it only autoderefs. It's the same kind of magic, with the same costs. It hides indirection / costs and in the case of method look-up it causes confounding situations. The combination of auto-referencing and auto-dereferencing tends to lead to issues like infinite recursion too *in the case of methods* due to wrapper types being idiomatic. &gt; If the rule were applied everywhere or near-everywhere, there would be no need for the question in the OP. You always resort to misrepresenting my comments and arguing the semantics of words, despite the intended meaning being obvious.
I'm not aware of any existing compiler support for any of this. Not familiar with that acronym. maybe they optimise internal struct layout, but this is all about *how data is divided between structs*. e.g. switching from `Vec&lt;(Logic,Motion,..)&gt;` to `(Vec&lt;Logic&gt;, Vec&lt;Motion&gt;,..)` (but still being able to write `entity:(&amp;Logic,&amp;Motion,..)` and code looks the same , ... so you don't need to butcher implementations to change the distribution of what is still logically one entity between different collections.)
Is this only for Rust experts or those who just got interested in Rust can come as well?
&gt; I don't understand how this is relevant in the first place, but function call notation certainly does have type-based lookup! Trait methods don't have to have a self parameter. No, it doesn't have type-based lookup. The function is identified by a path, and it's the same function regardless of the types that are passed to it. In the case of methods, a totally different method may be called based on the types that are involved and the combination of auto-referencing and auto-dereferencing with that generic look-up can be ridiculously complex. &gt; As I explained before, I don't know what "attribute access" means. I'm not a fan of the rules around autoref for operators; I would prefer that they be completely explicit, but that ship has probably sailed. The left hand side of the dot or indexing operator is the only place where it's truly necessary to have the autoref, and I wish it weren't, but it's justified by being syntactically distinguished. It's not any more necessary to have it there than elsewhere. It's apparently quite necessary to have it for function parameters because the alternative is the core developers ripping out support for generic code because references are too verbose. That's a far higher cost to pay than extending auto-referencing would be, because all the issues with function parameters exist with method calls already *along with far more serious ones* due to the type-based look-up with trait methods.
Hello people, I am the site's author. First of all, thank you a lot for your feedback. I have updated the site copyright regarding your suggestion :) Thank you!!! Story: I remember I purchased the "BuiltwithRust.com" domain at the night [Rust Alpha 1.0 release](https://news.ycombinator.com/item?id=8863451) (after spending half of the day browsing and looking for Rust projects just for fun). My intention is just trying to collect as much as projects that I think it is useful and cool and put them on the site to showcase the Rust lang. And to make it look more "formal", I thought I should write something "about" the site and arbitrarily put the Copyright footer-redirect to Rust-lang.org (I really thought it all means to credit the Rust-lang site's authors), I am so sorry for the confusion guys. I'm sorry. I wake up this morning and checked my email, oh wow, I got 3 first submissions which makes me want to put some more time on the site. Thank you sanxiyn for introducing the site. I welcome for new submissions and I promise I will continue searching for more Rust projects frequently. P/s: thanks for your submissions and feedback. 
&gt;"You yourself admit over here that the most logical way of writing the struct does not suffice." Yes. But this lets you have your cake and eat it. Write code the most *logical* way, and then re-arrange data the *fastest way*. That is the advance here that can't be done elsewhere so easily. &gt; I'm sure this works fine on something like a game console where the hardware and software are standardized, but in any other context it seems horrifyingly fragile. cache optimisation still works on PCs. and sure, he's mentioned how he wants to support different fine tuning per platform using the same source base (because they have different cache sizes, &amp; cache-line sizes): thats ' another big benefit to what he's doing. The packing might be different but you'd only have to change a small amount of code per platform (e.g. batch sizes, distribution), the code that actually uses the logical entities remains unchanged, thanks to this new system. The way to do cross platform development is to deal with the lowest common denominator.. you know your code has to work on the smallest cache. &gt; in order to hopefully coerce the capricious optimizer into granting you its favor. Not so: this is unambiguously describing data layout. This is all concrete, not hints. &gt; into whatever format a one-size-fits-all optimizer happens to like best today its' not based on the *optimizer* - the process is to use the *profiler* to tell you exactly why its slow. There are tools which report cache misses accurately, and their use is essential to get anywhere on a console (or similar consumer device). They can tell you on a line by line basis if there's an an i-cache miss or a d-cache miss. The course of action to fix it is different in either case. This is compelling functionality - this would make a **much** bigger difference to gamedev than Rusts' safety. Maybe rust can look at retrofitting something similar. Basically we're talking about element delegation. ( I wonder how far you could get with macros )
Hi xSnowCrash, No, builtwithrust.com isn't using Rust yet. ^^ This question really makes me to consider developing site with Rust. Thanks.
Definitely open to beginners! I've updated the meetup description to make that clear.
&gt; Not so: this is unambiguously describing data layout. This is all concrete, not hints. The SROA paper that I've linked below is one example of how this is less concrete than it seems on the surface. Fiddling with your data layout is undeniably effective, but as far as the optimizer's concerned it's still just a hint. My stance is only that instead of contorting our code to fit the optimizer, we implement ways of signaling to the optimizer what we actually mean.
thanks for the link - interesting. If i've understood correctly, "Scalar Replacement Of aggregates" - is addressing a different issue: its' about optimising for registers - by turning local struct components into scalars, which can go in registers, allowing individual component accesses to be optimised out (unused aggregate components stripped away, etc). ok its' related in a way, because its' talking about optimising using 'different subsets of a struct' .. but for registers rather than memory. Of course it is still "caching".. caching in registers vs caching in L1. You probably brought this up because of the similar term SOA (Structure-Of-Arrays) The refactoring jonathan blow is talking about relates to how data is distributed between arrays in *memory*, mostly to do with *cache coherency*, reducing cache misses and cache misses. ( and the SOA stuff relates to how easily it can be used by SIMD instructions, another issue again). e.g. What happens is a function that is too big overflows the icache. The profiler reports it. Then to speed it up, you divide that function into separate smaller passes. Now you observe the different passes don't require the whole structure, and they thrash the d-cache because they each only use a subset of the original data, but read the whole thing in multiple times. So now you divide up the data into separate arrays of components, and each pass only refers to the components it needed. Each pass may need a different permutation .. a different subset of the same fields. In doing so, your original code is completely butchered. But with jonathan blows design, it becomes more 'cut-paste' from the original, because you can still address different components as logically being part of the same 'object'. I had wondered if a pure-functional language could figure out this sort of things behind the scenes (since its' got a higher level description of whats actually going on), but I haven't heard of any attempts to do this.. they'd be shouting it from the rooftops if practical implementations existed.
I like the reasoning, and it seems like an interesting and clever abuse of C++. The proposed syntax/solution is not Rusty IMHO because: * It recreates existing functionality, and there should only be one way to do something. * It's very implicit (it implicitly takes all the fields, that you can't really know without actually looking at another piece of code which might be in another crate). * It allows for collisions in different parts of the code. As many have said before: fn foo(using entity: &amp;Entity) {} Would better be: fn foo(entity{position: position}: &amp;Entity) { The advantage is that we explicitly tell people where position is coming from, instead of having them have to look up the definition of entity and realize that position was belongs to that. Also we are using the existing method. So with that said we realize that Rust already offers us a pattern and we just have to add some hypothetical syntax to allow this within struct definitions: struct Entity { hot { hotField1: hotField1, hotField2: hotField2, hotField3: field3 }: &amp;HotEntityBits; cold { coldField1: coldField1, coldField3: field3 }: &amp;ColdEntityBits; } Notice that again we know what fields Entity has just from reading the definition of Entity, no need to read what are the members of HotEntity or ColdEntity. You can still access `Entity.hot` to access all the members it has. Any namespace issue is solved by people explicitly setting it. A nice feature of using patterns is that you could make fields pointing to certain position within a tuple or an array. Methods should be solved by using Traits instead. impl HotTrait for HotEntityBits { ... } impl HotTrait for Entity { // Basically fowards all methods to use Entity.hot instead. } impl ColdTrait for Entity { // Ditto for Entity.cold } The nice thing is that if `HotTrait` and `ColdTrait` have two clashing methods, casting to the trait (`Entity::HotTrait` and `Entity::ColdTrait`) will solve the issue, or calling the method from `Entity.hot` and `Entity.cold` explicitly should solve it. So in short: a better syntax to do this would be to allow structs to define members with patterns.
Imagine `Entity` is defined like this: struct Entity { position: Vec3; velocity: Vec3; mass: i32; age: i32; id: EntityId; name: String; flags: Flags; // ... and lots more } The details of the fields are irrelevant, except that there are a lot of them. Now say we want to store an array of 1000 Entities and iterate over them to update position and velocity every tick of our game loop. If `sizeof(Entity) == 80` (let's pretend) and our cache size is only 4000 bytes, then at best every 50 Entities we'll have to wait for main memory again to load the next batch into the cache. Basically, this happens because the cache predictor is dumb and doesn't know what we want. When we access the the `position` and `velocity` of the first `Entity`, it's going to load up the `mass`, `age`, `id`, etc of that `Entity`, along with many of the Entities that come after it in the array. This wastes time loading stuff we don't want and filling cache space that could otherwise be used for stuff we do want. So, the way to use the cache more efficiently is to something like this: struct EntityHot { position: Vec3; velocity: Vec3; } struct EntityCold { mass: i32; age: i32; id: EntityId; name: String; flags: Flags; // ... and lots more } struct Entity { using hot: &amp;EntityHot; using cold: &amp;EntityCold; } Note that `Entity` contains pointers to `EntityHot` and `EntityCold`, so the hot and cold parts can be allocated in different places. Now we can allocate 1000 `EntityHots` in an array and since `sizeof(EntityHot) == 32` (maybe — I don't know how Rust packs structs) we'll get less than half as many cache misses when we iterate the hot array than in the original example. And the cache will be holding nothing but values we actually want to use — no more waste. Now, it might be the case that this change doesn't help much or makes things slower for other reasons. The real benefit of `using` is that it let us make this change and profile it with very little effort because code using `Entity` objects can still access fields like `entity.position` with no change (it becomes sugar for `entity.hot.position`). In many other languages just checking to see if this hot/cold change is worth doing would take a lot more effort.
You don't have to explicitly mention the "HotEntityBits" part. So you can put the "hot" bits in one big array, and the "cold" bits in another big array, and then have an entity array that just transparently splits up its guts by pointing into a specific element in those arrays.
&gt; However, if you're scanning through both of them, and they're in different places in memory, would the one array blow away the other's cache line? Yes, indeed, SOA and components for cache efficiency aren't the same. SOA is about SIMD. *sometimes* they work together, sometimes they work against each other. Infact we all said the same thing when intel told us about SOA, "hang on a sec, isn't that going to kill the cache.." To fix that you can do batches, 'AOSOA'.. e.g. 4 elements in a struct ..`struct EntX4 {X0X1X2X3,Y0Y1Y2Y3,Z0Z1Z2Z3,F0F1F2F3 } /* 4 entities interleaved*/` then arrays of those.. I've done this sort of thing in real use cases, something slightly messier on custom processors sony platforms used ages ago. And PS4 SPU's could be used with AOS data in memory which could be permuted *on load* into SOA, then dealt in batches of 4 with by SIMD, then results permuted and stored again. Its' an ugly mess, but fast when it works, and his language is aimed at making this sort of thing much easier to deal with. 
What do you mean by this? Something that is part of the CI pipeline that helps track regressions easily? Or something else entirely?
See http://en.wikipedia.org/wiki/Man_or_boy_test and http://rosettacode.org/wiki/Man_or_boy_test. Its interesting to note that we explicitly need closures with shareable environments here, due to the shared access to `k`, `x4` and `b` from both inside and outside of the closure `b`, and that `b` is able to capture a reference to itself with the help of `Option`, thus enabling recursive calls.
What about regular old fields (not methods)? Can you forward those using traits? What about the pain to have to manually go through and forward all the members of large struct? The whole value of this is that it's easy to try while doing performance optimization. As soon as you have to do any kind of mechanical work to do it you've lost the point.
Considering the site's author PM'd me to thank me for my suggestion with regards to CC0 and then implemented it, I think I contributed well enough. ;)
To be clear, I just replied at the end of the chain, it's not just you. &gt; it's not malicious, Yes it is. At best, you're making fun of someone who has a misunderstanding. Which isn't very cool. But they actually don't have a misunderstanding, and are completely correct about copyright law. 
True, but still more painful than if `min_by` used a comparison function. I don't think it is totally clear how `Float::min` handles `NaN`s either.
It treats them as missing data as specified by IEEE754 for the `minNum` and `maxNum` operations. The alternative implementation is propagating NaN even if only one value is NaN, but that's not how it's defined.
I was under the impression that alternating between the two should still be a significant improvement, no? It's not like the cache is *that* small. And if you need to loop over everything in both anyway..?
"asdf".to_string() produces a temporary instance, and I think currently without assignment the value is freed right then and there. This was posted the other day, I think it demonstrates it better than I said: http://nercury.github.io/rust/guide/2015/01/19/ownership.html 
Cache optimizations aren't "horrifyingly fragile" because literally every cache system is based on the ideas of temporal and spatial locality. If you take data that is accessed at the same time together in memory, and you group your memory accesses by location, you will gain performance. Do otherwise and you will lose it. It's not really about layout within a struct- The using-a-pointer thing lets you put the hot data all in one spot so that most of the time you just access it all together in one spot, but other code can still use it like you used to before you figured out what was hot.
Ho boy, I wish you could do that in gcc as easily.
Really? I guess I've only ever installed Rust through the Cargo installation instructions.
Try using `Some(ref mut c)`.
I have tried that, as well as `Some(box ref c)` and `Some(box ref mut c)`, but still couldn't get it working. That code is buried somewhere deep in my Git repo, but I think the complete branch looked like Some(ref mut c) =&gt; { (*c).close(); self.conn = None } And the error was something to the effect of "unable to move borrowed reference." BTW, I am assuming you think that struct SKSqliteStore { path: &amp;'a str, conn: Option&lt;Box&lt;rusqlite::SqliteConnection&gt;&gt; } is an okay foundation to work from?
the problem you can have with SOA is you need more 'ways' of the cache if you need to access more components at the same time (more clashes)..remember a component now is an individual field e.g. posx,posy,posz,velx,vely,velz,... thats 6ways of cache straight away .. and the granularity is coarser. AOSOA can give you the SIMD use and keep things tighter in cache lines, but is probably even less intuitive.
Either `ref mut` (which gives you `&amp;mut Box&lt;T&gt;`, which you can call methods on via autoderef) or `box ref mut` (which gives you `&amp;mut T`, but `box` is unstable syntax) should work. I believe your problem is the `self.conn = None`, which you are trying to do while still holding a reference to the object inside the `Some`. With the SEME proposal, it would just work (detecting that you weren't actually using the reference, despite it still being in scope), but in lieu of that, you have to set it to None outside the block.
I mean, I personally interpret text in an LL fashion, so it really puts me off when my error message is framed in terms of an LR parse.
This only applies for automatic error reporting. You can frame error messages any way you want if you do it manually.
But that will give you a Thread struct and not an ID so it's not comparable?
You should leave a local variable to keep the value. It's like this code in C++: auto dangling_pointer = std::string("temporary").data(); dangling_pointer will point to illegal address because the std::string has been deconstructed.
The new orphan checking rules are very restrictive and, as I understand it, [buggy](https://github.com/rust-lang/rust/issues/20477#issuecomment-68861156). Hopefully something better will replace it before 1.0. Anyhow, I think a wrapper struct might be the most idiomatic here. I e, something like: struct Handle { h: ffi::Handle }; impl Drop for Handle { fn drop(&amp;mut self) { ffi::unref(h) } } pub struct MyFoo { h: Handle } pub struct MyBar { h: Handle } 
Provided that the thread struct fits in a word so you can use atomics (which you can guarantee by `Box`ing it; see also the old `AtomicOption` type, though it seems to have been removed from the stdlib) and that `PartialEq` is implemented for `Thread` (if it's not, I'd file a bug), it should be a reasonable substitute. *Edit* Link to the old implementation: https://github.com/rust-lang/rust/blob/470118f3e915cdc8f936aca0640b28a7a3d8dc6c/src/libstd/sync/atomic.rs *Edit 2* Actually, `AtomicOption` won't quite do it because the API is too resticted (I remember this now :|). You do really want a thread ID. I expect there's some way to do it with the `park` and `unpark` primitives, but that would require you to implement queueing yourself (which shouldn't be necessary here). You can still do this by assigning a unique ID to each thread though...
Can you use `let conn = self.conn.take();` in this case? That should replace the value with `None` and return the replaced value.
`self.conn.take().map(|c| c.close())` should do the trick.
Have you seen some of the solutions on that Rosetta code page? I'm just glad we can use closures at all ;)
&gt; Is this desired or a necessity? Well, it does not surprize me. So, yes, I expect this not to work. I know that this involves creating a short-lived temporary `String` object. So, storing a borrowed pointer (the string slice) that points into this `String` object is subject to borrow checking which in this case, thankfully, is rejected because you would otherwise have a dangling pointer. That is exactly what Rust is trying to prevent. Rust does not (yet?) magically increase the lifetime of temporary objects to the satisfaction of the borrow checker. Just in case such a line really appeared in your code: You don't have to create a `String` object at all. You can also write let x = "asdf".as_bytes(); 
I did not know I could do that. Thanks.
You're no doubt right that `self.conn = None` is *a* problem (and I appreciate your explanation thereof), but it's not *the* problem; I've tried moving it outside the pattern match block, and still got errors WRT to the `c` variable.
Thanks, I'll try that.
Call `map` on a non-sequence? Seems weird, but I'll try that too if I have to.
For a string literal, it's even shorter: `let x = b"asdf";`.
[You can](https://gcc.gnu.org/onlinedocs/cpp/Common-Predefined-Macros.html).
Is his message really mean or rude? &gt; I hate them, the error messages suck. If we are this pedantic about what is mean or rude, than we need to take a good look at 4chan for a moment. What is mean or rude about that statement?
Maybe a Macro or such could be done, but I think that the Rusty solution is being explicit and, yes, having to repeat yourself a little bit, because no one has said what members exist in this struct. There is a precedent for this: the way in which Rust imports modules requires being explicit and showing the whole thing. Indeed we'd have to change the way in which use works to make it work as it's done here.
Ultimately the pattern matching could have some sugar code such that A{B, C}: SomeStruct Is converted into A{B:B, C:C}: SomeStruct But this is pretty easy to fix. If you are complaining about having to explicitly declare what fields are imported, understand that it's no explicit and may have unexpected side effects. Imagine that I want to do this with two things from different crates. How can I fix it when one of the crates causes a name clash? How could this crate know of the other crate? The precedent is set by the use syntax, which requires importing multiple things.
I agree. The "SOA"/"AOS" feature Blow talks about is compelling. Basically, anytime you'd have many instances of a struct, you'd like the ability to declare whether it will be laid out in memory "horizontally" or "vertically" (I'm sure there are much better words to use, but hopefully you intuitively get my drift). Essentially, we (sometimes) need to control memory layout precisely. But the way we want to "think about" our structs needs to be higher level, so that all the code that uses the structs doesn't have to be coupled to the low-level detail of the precise memory layout.
It's one thing if the core contributors, who actually represent the language development team, self-represent in offensive ways. I actually agree that would be bad. But people wandering in with questions? Are we really gonna hold them to the same standards? Would any reasonable /r/rust subscriber? And my point, which you completely ignored, is still valid. If someone is frivolous and sensitive enough for the very *presence* of unsavory nicknames to put them off of a programming language entirely, that person has bigger issues that will almost inevitably manifest in destructive and dramatic ways regardless.
See, that's so much more explicit than anything I've said in this entire conversation. And on that note, you've clearly already made up your mind for the entire community, and the only thing I can hope for out of this conversation is more downvotes and arguing past the other person. I'm done. If it makes you feel better, your policy has made the language more inviting by convincing me to finally unsubscribe from this subreddit and abandon the language entirely.
That's how it always begins, but things grow out of hand. Even if we are dealing within the same project, multiple people may finish handling the code. The precedent of `use` still is valid.
One would intuitively expect it to last at least until the semicolon...
It could work if you require all the fields to be defined within the same namespace beforehand. That is, you declare all the structs within `A`: struct Foo { x: struct { a: i32, b: i32, } y: struct { c: i32 } } Like the record type hack in some languages (I have used it but forget which one) where the field names always have to be unique for inference to work. Or kinda like anonymous unions in C (IIRC this is how they work). You can imagine different syntax (not restricting them to one struct, or maybe even allowing them to be split up among modules, giving them proper type names, and tagging them with a particular namespace?) but the basic idea is that you'd have a namespace where all field names were unique. This simple restriction prevents all possible multiple inheritance issues, and considering that in many languages variants have *global* namespaces I don't think this is even that onerous in practice. With first class record types it would be even better since you wouldn't need to declare methods for a particular substructure (you could just type alias then, e.g. `type A = { a: i32, b: i32 }; type B = { c: i32 }; type Foo = A | B`... sorry for the incoherence, I'm musing a bit). I guess my general thought is: this is a good idea but there are probably existing examples of this done correctly in the literature that don't require introducing multiple inheritance with all its problems.
Color me naive, but how hard would it be and would it be desired (more important) to have Rust extend the lifetime so that this works (either to the semicolon or intelligently extend as long as it is consumed as the next input)? This isn't a particularly important instance of this problem, but it does readily illustrate the larger problem of a common programming idiom fighting the compiler.
rusqlite::SqliteConnection has close() in destructor. self.conn = None is all you need.
&gt; Since Sqlite lacks write concurrency, I can't use a persistent connection; it will be necessary to connect and disconnect multiple times during the life of an application I don't quite get how the "lack of write concurrency" is related to persistent connections. Most databases don't have any concurrency inside a connection, so if you want the concurrency you have to establish multiple connections. However, since SQLite "lacks concurrency" there's no real need to have multiple connections, you can use a single connection with some locking. A useful simplification could be to obtain an exclusive lock and begin a transaction in the same method, e.g. `... database not locked yet ... {let transaction = database.begin(); ... database is locked here, methods outside of transaction will block ...; transaction.commit(); ... database no longer locked ...}; ... transaction rolled back if it wasn't commited, database no longer locked ...`. (I did that kind of exclusive locking, minus transactions, in my C++ driver (cf. https://code.google.com/p/libglim/, SqliteSession) in order not to debug various locking issues arising in a more complex locking schemes, such as the one used by the SQLite itself). Anyway, you can have perisistent connection(s) to SQLite regardless of whether it supports write concurrency or not. Having a persistent SQLite connection is usually important in order for the SQLite cache to work, avoiding some filesystem calls. Not to mention the overhead of creating and destroying connections.
Such a wrapper struct can also make constructors more elegant, e g, consider: impl Handle { fn new(h: u32) -&gt; Result&lt;Handle, ()&gt; { if (h == 0) Err(()) else { Ok(Handle { h: h }) } } } pub struct MyFoo { h1: Handle, h2: Handle, } impl MyFoo { fn new() -&gt; Result&lt;MyFoo,()&gt; { let h1 = try!(Handle::new(ffi::getHandle1())); let h2 = try!(Handle::new(ffi::getHandle2FromHandle1(h1.h))); MyFoo { h1: h1, h2: h2 } } } Notice that in case the call to `getHandle2FromHandle1(h1.h)` fails, then the first handle will be properly closed. 
I suspect the main problem is it'll get complicated, because if the temporary's lifetime is extended it may conflict with other lifetimes. You'll then need to define the lifetime as 'from here to where it doesn't conflict', and that makes it far less clear what the actual lifetime is. I think it's better to make it explicit with a variable.
I don't think you can access environment variables from GCC.
I have a question here. Say I have a struct: struct Example { pos : Vec3, vel : Vec3 }; If I mark an array of Example as SOA, i probably get in memory two arrays, one for positions and one for velocities: pos0, pos1, pos2, ... posN vel0, vel1, vel2, ... velN But position and velocity are arrays themselves, so that layout results in the following memory layout: pos00, pos01, pos02, pos10, pos11, pos12, ... posN2 vel00, vel01, vel02, vel10, vel11, vel12,... velN2 Now say that when I access position in my algorithm, i always access all components (e.pos[0], e.pos[1], e.pos[2]), but when I access the velocities, my algorithms first access all the 0 components, then all the 1 components, and then all the 2 components. That is, for positions pos[e][x] is stored in row major order for better performance, but for velocities[e][x] should be stored in col major order as follows: vel00, vel10, vel20, ..., velN0 vel01, vel11, vel21, ..., velN1 vel02, vel12, vel22, ..., velN2 How can I specify with the SOA approach easily how the memory layout of sub-fields in structs will be laid? How can I control it for different subfields? What if my struct contains a dynamic vector of elements? Is there a way to automatically handle a jagged vector? struct Example2 { val : Vec&lt;f64&gt; }; =&gt; (Linearly in memory) val[0][0] val[0][2] val[0][3] val[0][4] val[1][0] val[1][1] val[2][0] val[2][1] val[2][2] Would that be resizable? Appending to the end of each sub vector would be O(N)since you probably have to increase the memory buffer, perform O(N) swaps to the end to make place for new elements, and then insert the new elements. To gankro: i wrote a SOA vector container in C++ that sees a struct as a tuple (it just destructures it), and stores each component in a different vector, and then zips those vectors, and allow you to iterate over it as if it were a simple vector of struct, but I use type level keys instead of member access to get the element (C++...). Maybe in Rust something like a SOA vector would also be possible as a library, without need for language support. Link: https://github.com/gnzlbg/scattered I basically gave up with it because you want to allow the user to customize how the members of the struct might get further destructured, and that would have required too much C++ metaprogramming to remain sane. 
I don't think you understood what I said. Right now, we can write fn generic_func&lt;I: Iterator&gt;(mut it: I) { let x = it.next(); let y = it.next(); let z = it.next(); } *because* the compiler *knows* that the existence of `x`, `y` and `z` *never* freezes the iterator *because* of the the way the trait is defined *irregardless* of how you implement that trait. If you made this depend on the `impl`, you would loose the type/borrow checking of this generic function and delay it until monomorphization and only at monomorphization time the compiler would be able to see that (potentially) the presense of `x` actually freezes the iterator which makes the following lines violate the borrowing rules. But this error is detected too late. We don't want to delay errors until monomorphization. We want monomorphization to always work as opposed to how C++ does it and ends up with potentially horribly long “template instantiation backtraces” where it's not that easy to figure out what went wrong.
Yes, that's preferable in this case. There is a difference, though: It won't give you the UTF8 encoding of a string literal containing non-ASCII characters.
I don't know. It might make the deduction of lifetime variables more complicated. But this is definitely not my area of expertise.
It hits stack overflow at 15. I really hope there is a simpler way to write this in rust.. then again, it's just a stupid "stress test"
If you mean in C++: const char* return_pointer() { std::string local("temporary"); size_t size = local.size(); char* ret = new char[size + 1]; memcpy(ret, local.data(), size); ret[size] = 0; return ret; } Returning pointer is not a good idea in C++ though, better to make a class with proper copy constructor to wrap the resource, or sometimes use shared_ptr, to perform RAII. For Rust, normally functions don't return borrowed type. Well, compiler will remind you that anyway. So return String instead of &amp;str, etc. 
Yea, this would need an extra bound on the lifetime of the associated type `Item` of the `Iterator` trait. But this does not need to be delayed until monomorphisation, this can be done just like other lifetime bounds.
Rust already does this, this line works after all: let l = "foo".to_string().as_bytes().len(); The issue with the snippet posted by the OP is that they want to keep the `&amp;[u8]` around _after_ the semicolon.
Please show us how these bounds would look like in the case of a “streaming” iterator and a “normal” one.
Try this: https://gist.github.com/bombless/48e741da9a28a456380a , and you may prefer this article for a long explanation: http://chrismorgan.info/blog/rust-fizzbuzz.html . In short, a &amp;str from a String lives as long as its owner, the original String. So you need to let that String live long enough, that said, live longer than your Vec. But you can see that it's not possible for your case. 
I would like to imprint this into the package docs -- is it possible?
Didn't know about `format!`, thanks, that helps a lot. 
Yeah, I was thinking of just checking that it links. Obviously not calling the APIs, because that wouldn't really make sense. But maybe there is a way of detecting if a signature is wrong. &gt; Rust doesn't really provide a sane way to handle unsafe unions at the moment. Ok, so do you pick one of the variants (the larger one), or use a raw type like a byte array?
Thanks! On the first glance that indeed seems to work (at least I couldn't make it fail on the obvious test cases). There's just one "but": how would you construct a static initializer for RecursiveMutex akin to std::sync::{MUTEX_INIT, StaticMutex} so the initial example in this thread (a function with a static mutex as a closure wrapper) would be possible? (for one, I don't think there's a static initializer for std::sync::Semaphore..)
You can use `Option` and move out of it with `.take()`. You can return both values as a tuple from a single `self`-consuming method and let the user decide whether to keep one or both or none. You can use `std::mem::replace` to swap the vectors out with empty ones without getting a move error.
You can move fields individually, you just can't call any more methods on the struct after that.
Looks like there's no PartialEq for Thread indeed; filed it on rust-lang/rust.
That does not make sense to me. To me, it looks like you did not understand what I was talking about.
 with (s) i = j; You can't quickly tell what that does - does it set s.i or local/global i? Does it assign s.j or local/global j?
Yep. Videos aren't skimmable, which despite me being interested, I just won't watch unless they have a high ratio of content I don't already know about. It's also profligate with bandwidth vs docs.
I'm on my phone so I can't give you a full solution in code, but the general idea is that you have an overarching chain which contains your "global" middleware, like the router and templating middleware. This chain will always run so that templating runs after all routes in the router. EDIT: Code: let hbs = HandlebarsEngine::new("./src/templates/", ".hbs"); let mut router = Router::new(); router .get("/", frontpage) .post("login", loginpage); let mut main = ChainBuilder::new(router); main.link_after(hbs); Iron::new(main).listen("localhost:3000").unwrap();
Yes, this is the why that I couldn't specify, the use of the temporary string. Good call.
He accesses the temporary again on the next line via `x`, but the temporary string it's based on went away after the semi on the previous line.
I know of one ECS that addresses this issue. It's called Ash and it introduces the concept of Nodes. In Ash, Systems are designed to process a specific subset of Components on any given Entity. Basically if an Entity contains a set of Components matching a System, a Node is created for the Entity containing those Components. The Node is then added to the System's Node list (which is really a linked list). Its a pretty organic solution. But it requires a little more work to sets things up as you have to create Node containers in addition to Components, Entities and Systems. For more info on Ash check out the following link: http://ashframework.org
I don't understand why you're using the qualifier 'only' - yes, that's the issue, it invites breakage from a distance. And so would this. The fact that it would usually (though not always, i.e. if an introduced field had the same type) get caught at compile time rather than runtime is an improvement but it doesn't negate the fact that otherwise innocent upstream changes can completely change the meaning of local code. 
ahh good call thanks
Thanks. Will check out.
Imagine you visit a large foreign city. You witness a mugging that happens in front of a large crowd. Nobody does anything. On the one hand, muggings happen in all sorts of cities, and there are statistically more muggings in large cities, so thee is nothing particularly unusual about a mugging, no matter how unpleasant it is. On the other hand, the crowd not doing anything about the mugging... That is disturbing. And so it often is with trolls, or people who go out of their way to cause offence. They are a statistical normality. But the response of the community to those trolls or offensive people... That often makes all the difference to how the community as a whole is perceived.
So you'd rather import specific fields module wise rather than specify them within the struct itself? It still has the problem that it links one piece of code (the struct definition) to another, not directly related, piece of code (the `using` statement). You are worrying to much about writing a piece of code that you'll only write once, and ignore the fact that it'll make it harder to read every time the 100s of times you'll go looking for the code because you forgot how the `struct` is defined. Moreover I don't think that the ability to import a specific struct but only with certain fields would ever be useful. I think it's fair to expect that a `struct` should list all it's member fields. After all if I see some code like the following: struct A { explicitMember: someType } fn main() { let a = A{explicitMember: 0}; println!{"{}", A.implictMember}; // This is equal to at least 2 wtfs/min } Honestly I don't see how doing something like struct A{ using explicitMember; } Is really that much better than the above case. It only tells me that the one line is going to add a bunch of unknown members and that I need to make sure that no new member clashes with it on either side.
Was there a video for the talk? Is it available?
This is awful, but here: https://gist.github.com/pythonesque/5bdf071d3617b61b3fed#file-static_recursive_mutex-rs **Do not use this.** Use an OS recursive mutex. **Edit** I just fixed it, it wasn't working previously. Again, no guarantees, please please please do not use this. Beyond the obvious (no guarantees), using Rust's mutex type forces some unnecessary inefficiencies into the system.
What is this programming language? Does it have a name and do you plan for it to be useful one day?
Holy cow! Thanks! Will sure take me a while to wrap my head around that... looks quite scary to be used as is :) But it's a good example of messing with sync primitives and atomics and does theoretically solve the initial problem. 
Thats the version of GCC. Not an arbitrary thing. You'll have to make do with -D
I just deleted my comment because, not only do you have good points, but I totally mangled the explanation of what I was trying to say, and I don't want bad ideas polluting everything. I'll have to do some more thinking.
Do you realize that you're basically making the same argument as the one you're arguing against? Some people are worried that people will be turned off by offensive nicknames. You're worried people will be turned off because their offensive nickname isn't allowed. But you can't do both at once, so you have to pick the one that does the least harm. Is it more reasonable to be offended by offensive nicknames or offended by the inability to use an offensive nickname? Which will cost /r/rust the most users/contributors/community members: offensive nicknames or inability to use offensive nicknames?
But just to be clear, since /u/iGaijin is new, we don't actually have monads or functors in Rust. Yet.
Is there a story to read about each of the people in the core team? Many of the names I've never seen before yet they seem to be world-class compiler and browser engineers.
Any slides or presented material available ? Thanks in advance.
huh strange. I have (and have had consistently) all tests passing. What version of rust did you update to? I just ran rustup and have: $ rustc --version rustc 1.0.0-nightly (29bd9a06e 2015-01-20 23:03:09 +0000) and still get the illegal instruction.
4 hours ago* (last edited 2 hours ago)
I didn't check the original version but it was 1.0-a when it first came out I believe. I now have &gt; rustc 1.0.0-nightly (29bd9a06e 2015-01-20 23:03:09 +0000) I'm testing on win64, I can test on arch/manjaro too if you want. I think you should maybe even reboot at this point (you never know) and try cargo clean, cargo update, then test and bench. To note, that last error with a call to unwrap on Err is not good-- it's curious why it passes now and not then.
I am definitely attending this. Is this the first rust talk at fosdem ever? Please don't talk too long about hello world stuff and jump right into the exciting stuff oike the borrower or whatever memory management magic there is in rust
I agree with your post, but I find the framing dangerously simplistic. Most people who run afoul of the code of conduct are not noxious "bros". There's plenty of room for misunderstandings, hurt feelings, culture clash, language gap — oh, and legitimate disagreements about politics and society. A code of conduct gives concrete standards of behavior, that we *all* follow, and we help each other follow it. It's not just "no sexism etc.", it's also about how to discuss programming languages online without being a jerk, which (for me anyway) doesn't always come easily. Having a detailed code means that we can discourage specific behaviors, rather than judging who in the community is "one of THOSE people", which often leads to dangerous escalation. Of course, there are communities which fail spectacularly at enforcing a code of conduct, writing invisible exceptions on how to treat people in demographic groups deemed "privileged" or "part of the problem". That is *not* how the Rust community will operate, and I encourage anyone who has concerns of that nature to contact me privately.
&gt; Is this the first rust talk at fosdem ever? This will be my first FOSDEM, so I have no idea. &gt; Please don't talk too long about hello world stuff The talk is not an introduction to Rust, it's more about language design.
Or, would a more idiomatic solution be to just clone the final value? For example let i = "something".to_string().as_bytes().clone(); But that would probably perform another allocation (I'm not familiar with how Clone is implemented). There should be a way to extend the lifetime.
Exactly! It just uses the platform libraries on Windows and Xlib on Linux. I've been planning (mostly just in my head) a GUI library that would run on top of this.
The slides I used are [here](http://manishearth.github.io/Presentations/Rust/) (the online version is a tad outdated, I need to update it with my local changes)
jdm gave a talk last year on Servo, though I'm not sure about Rust the language.
And what happened to Graydon Hoare? Is he still involved with rust? If not why?
Thanks for coordinating this. Please add the Applicative session to the [calendar](https://fosdem.org/2015/schedule/event/servo_the_parallel_web_browser_and_you!/) when it's arranged.
Awesome work! A question: what is the best way to use it with a fall back to no-sse?
Thanks for filling me in! I did watch a lot of the video, but videos aren't the best format for scanning for info.
Well, you want the largest possible value because you want to avoid overflow (though you could certainly configure it if space is precious, but due to alignment most of the time it will probably not matter). You probably really want a big integer, but this is a toy example and Rust does not have a builtin big integer library. Of course, big integers can allocate, and allocation can fail, but again: toy library, and we're already allocating here (mostly for spurious reasons, I might add :(). (usize would be sufficient with the current API, I think, because you need at least usize::BYTES space to store each guard, but if you changed the API to allow for locking / unlocking without guards, that wouldn't work anymore).
Reading between the lines, it sounds like he was hard to work with and was pushed aside. So he left the company to go somewhere he felt more appreciated. Does that sound about right?
I don't think you understood my point. The compiler can generate two different versions of the code, one for each layout, *without* indirection and *without* requiring butchering your logical code, by special-casing for each layout variant. You should be able to choose between this and indirection, just like you can choose between static and dynamic dispatch, and you should be able to use different layouts for a logical type in the same program. The using solution only addresses dynamic layout (which is just a generalization of DSTs, IMO, which would also be worthwhile), and it conflates the issue of how the data are *presented* with the *names* of the fields.
&gt; the different components can be different sizes, so you can't just have offsets As long as the sizes of the different components are known at compile time, which they often are, this is a nonissue.
?! how can you get data from multiple pieces? you could start with an index, then calculate an address for each. but you'll want to re-use those addresses surely, rather than recalculating for each access? Also if you're stepping through linearly, you could generate the addresses by addition, rather than multiplies from an index.
I have never heard from anyone that he was difficult to work with. That was certainly not my impression of him from our limited interactions when I was a Servo intern two summers ago. I expect that he was simply tired and needed a change.
He was not hard to work with. As an external contributor, I worked with Graydon for six months, and he reviewed my SIMD patches. I can state without hesitation that he was the best open source project leader I interacted with, by far. I am deeply disappointed to see his involvement with Rust decreased.
What I dislike is that you have `None` only for initialization - whenever using the actual value, you assume it to be a `Some`. That's a common idiom in C (aggravated because C is unsafe) but I would expect that it could be avoided in Rust..
&gt; I'd be interested in understanding the clash in values here. Well, today, some random person wandered into the code of conduct thread to tell us we need to allow obscene nicknames because it's traditional on Reddit. (Funny, because the defense for the awful subreddits is always that they're separate self-governing communities.) That's just one person; nobody really agreed, and they got downvoted. But this is a problem if it keeps happening. It's not the only instance lately of the wider Reddit-verse leaking in.
Cool! I'm experimenting with [a library](https://github.com/huonw/simd) ([meager docs](http://huonw.github.io/simd/simd/)) that does similar things, but I'm using [LLVM intrinsics](https://github.com/huonw/llvmint), rather than inline asm, in the theory that LLVM understands them a little better than raw asm, and so can hopefully optimise better. (It is *seriously* experimental though; and it's not rare to e.g. make LLVM crash by misusing the intrinsics.)
That allows for easy composition. For example with hashes: $ cat t.rs #[derive(Hash)] struct A { b: u64, c: String } $ rustc t.rs --pretty expanded [snip] #[automatically_derived] impl &lt;__S: ::std::hash::Writer + ::std::hash::Hasher&gt; ::std::hash::Hash&lt;__S&gt; for A { #[inline] fn hash(&amp;self, __arg_0: &amp;mut __S) -&gt; () { match *self { A { b: ref __self_0_0, c: ref __self_0_1 } =&gt; { ::std::hash::Hash::hash(&amp;(*__self_0_0), __arg_0); ::std::hash::Hash::hash(&amp;(*__self_0_1), __arg_0); } } } } 
One reason I could thing hash takes a mutable is that it could be saved off internally if it is an expensive calculation and expected to be called a lot. I have no idea if this us actually done, but could be a reason.
It is a problem because it means you can't actually reuse any code you write here. For instance, in the example from my other comment, if you have an array of [{x,y,z}] you would not be able to write one function that operates on each pair. Of course, you could just use an iterator for that, so maybe it's not a big deal (but then, you can already emulate most of this stuff...).
While I am from the post-Graydon era, I have literally never heard anyone say something negative about him.
I think you're misunderstanding the point of these traits. `Hash::hash` is not used to generate a hash, it's used to *add* to a hash. Say we have our own struct with three elements, all implementing `Hash`. How would we implement it for our type? * With your trait, we'd have to implement all the hashing logic for the elements again. `Hash` can only give us a final hash, and you can't just combine three hashes somehow to get another one without losing some desired properties. * With the stdlib `Hash`, we simply call `.hash(formatter)` on each element. This adds each element to the hash using their `Hash` impl. No duplication of logic needs to happen. There is a top-level function called `hash` in the `std::hash` module that is used for generating final hashes. `Hash::hash` is a function you'd rarely see in application code. `Show` is the same - `fmt` adds something on to a Formatter, so that showing a type with multiple elements is more efficient and doesn't need to duplicate showing logic. `Show::fmt` and `String::fmt` are also not meant to be used directly in application code in most cases - use the `format!` macro or one of the top level functions in `std::fmt`.
Code reuse and refactorability go hand in hand. They are both just different expressions of modularity. If you have refactorable code, it means that you can easily modify part of your program without having to change the rest of it very much. This is pretty much the same thing as being able to write a new component (the second version of the first part) that relies on the same shared code (the second part) as the old component (the first version).
The problem here is allowing `b` to reference itself. A different solution might be using a "no-op" closure to initialize the cell, instead of using `Option`. This gets rid of the `unwrap`s, FWIW. fn a(k: i32, x1: &amp;Fn() -&gt; i32, x2: &amp;Fn() -&gt; i32, x3: &amp;Fn() -&gt; i32, x4: &amp;Fn() -&gt; i32, x5: &amp;Fn() -&gt; i32) -&gt; i32 { let k = Cell::new(k); let no_op = |&amp;:| 0; let b_cell: Cell&lt;&amp;Fn() -&gt; i32&gt; = Cell::new(&amp;no_op); let b = |&amp;:| { k.set(k.get() - 1); a(k.get(), b_cell.get(), x1, x2, x3, x4) }; b_cell.set(&amp;b); if k.get() &lt;= 0 { x4() + x5() } else { b() } }
This is going into rustc itself?! :o
I'll first admit I know nothing about HDL programming, but really curious to see the opinion from rust folks about this intriguing ultra-low level language, and if there's anything rust can do within this domain.
The problem is that hardware is fundamentally different then software. You can't write hardware like you can in software because hardware is fixed. For example, there's no concept of a loop with an unknown iteration count. If you're laying out hardware, the iteration count needs to be known at compile time. I havent used anything besides VHDL and Verilog, but there's such a large fundamental difference between HDLs and general programming languages that I'd be surprised if there's much to take away besides possibly 1st class state machine support.
Yes. Caching is pretty orthogonal. I am working on it separately.
This is about code maintenance: Both paths would have to be tested and otherwise maintained.
The concurrency patterns you asked about in that thread should be working really soon (hopefully before the beta). The APIs are set up so it will ideally be backwards compatible. Once that's in, I don't think you will need unsafe very often at all in most concurrent code. Most of the patterns for which you'd use unsafe in single threaded code are "actually" unsafe in parallel, so safe Rust is very well suited to modeling concurrency, especially when you factor in atomics. The actual primitives exposed by the current `sync` library are not always sufficient, but I am confident that libraries addressing that will spring up pretty quickly. BTW, while you call that pattern (concurrently accessing data on another thread's stack) "common", it doesn't exist at all in most languages. The minimal thing you need is an *existence guarantee*--you need to know that the memory you want is actually alive when you access it. One way to make this work is just to never free memory (this isn't that dumb, a lot of concurrent C programs rely heavily on static memory) but that's obviously limited once you want to allocate. At that point, without either global garbage collection (`Arc` counts as this) or strong ownership guarantees like Rust has, it's *really* hard to preserve that in the presence of threads*, and Rust's is the only one of those that even leaves open the possibility of using stack data. \* It *can* be done, but things like read-copy-update are, like, totally insane.
Sounds good. They were a pain in the ass to find the first time.
Awesome. Hope rustc will become more like clang in this area.
&gt; Code reuse and refactorability go hand in hand. Sometimes, but as a general rule? I'm not sure: This feature definitely improves refactorability - and you're claiming it goes against code re-use :) &gt; it means that you can easily modify part of your program without having to change the rest of it very much. The difference here is , its about changing *data-layout* without having to change 'the rest of it very much'. For anyone who's worked on this kind of cache-optimisation on consoles... the benefit will be very clear. "intuitively" written C++ has to be regularly butchered to hell to make it fast. It means programmers can continue to write intuitive code, and when it comes to optimisation, it doesn't have to be changed much. I really don't understand why you think its' a problem. All he's done is generalise the concept of 'this', and generalise inheritance into allowing *any* composed components to work like a base, and,if you like, provided a shortcut for rolling 'getters' with indirection. He's addressed cases which are used *universally* in high performance game/engine code, and perhaps more specifically, addressed the *processs* of achieving high performance. so with this language you can leave code closer to its logical, intuitive , original form, but change the data-layout, requiring fewer changes to the functions that use it (just cut paste bits around between fragments, when dividing larger functions up, without having to faff around changing 'this' or putting in calls to getters) its' perfect for the problem its solving. If the world can have a specific language features for vtables, or for Tagged Unions, or for interfaces ... surely it can have one for this. I mean do you go to Go forums and insist its' interfaces are pointless ? etc..
This looks pretty sweet! Recently with racer I've been trying to figure out how to lever rustc's type inference to avoid duplicating the same work. Actually baking this stuff into rustc with additional ast nodes might be the best route
It is good to know that this specific pattern will be fixed in near future. The fact that d is in stack is irrelevant here, it might as well be in the heap. Otherwise the code in that post is the classic fork-join model and there is fairly common. Unsafe languages like C can definitely represent this without GC or even heap allocation and it is a perfectly safe thing to do (just not statically verified). That is why I wanted to know if there are rust constructs specifically for unsafe concurrency.
I would keep them in-tree, but I don't really feel that strongly about this, as long as there is at least one "blessed" version for the major editors that is linked to from the rust website, and preferably is used by the rust devs themselves. Do please avoid the situation where there are as many versions on github as there are developers, and it's not clear which one actually works with the current version of rust. You ~could use git submodules to document the "blessed" versions, but submodules were still a usability nightmare last I checked. 
I don't think this conversation is likely to go anywhere at this point (we're both just restating our points) so let's just agree to disagree on this one :)
This is great! I'm working on a text editor in rust, and hope to integrate with rust tooling as much as I can. Having something like this would be so helpful!
Anyone else think that it's kinda stupid to name something `fmt` instead of `format` just to save three characters?
I need to update the readme a bit - racer does complete methods and fields (e.g. it completes the example in https://github.com/rust-lang/rust/pull/21323) and performs some type inference. However finishing type inference so that it is feature-complete with rustc would be a very large undertaking - I'm keen to lever rustc's type inference wherever possible! 
It is unfortunate. We now have a stronger policy on breaking `#[stable]` APIs, but many APIs remain to be `#[unstable]` to allow exactly this kind of improvements (and breakages).
You'd think, and in general I'd agree, but it's an internal function (not usually called directly) and `fmt` is a common shortening. `format` is also used as both a macro name and a top-level function, so perhaps `fmt` is less confusing there (though there is `Hash::hash` and `std::hash::hash`, so...).
So for now it is safer to use inline assembly. Maybe when LLVM intrisics became more usable then I will use it as native backend. For now I prefer ASM. Also I'm thinking about adding fallback for CPUs that are unsupported or doesn't have SIMD instructions. 
2 things: - I think this might be harder to do, but it is superior solution in the long run when compared to hooking something like SDL. - Arent you trying to do a bit too much for a single lib?
That's fun to think about! I wonder how far you could go back, documenting hashes of compilers and their sources as they bootstrapped each other. Could make for an interesting geneology. Who knows, maybe you would even find some compiler that ~does have a hack like this in it. I wouldn't be shocked if some compiler at least had an easter egg in it that no longer shows up in the code... 
Mailing lists make sense when the project is small. Sure you can make your forum software send email notifications, but that's just makes it practically a mailing list.
Oh, you really weren't kidding about the seqlocks then. Awesome. 
&gt; but that's just makes it practically a mailing list **For the people who want that**. That's the point. I don't want it so I wouldn't have any mail notifications.
Of course it could. Think about Github "issues". That's basically a forum specialised around bug reporting, which is mostly what the mailing list is doing anyway (just in an ad hoc manner). No one goes crazy with that, precisely the opposite in fact.
&gt; Which will cost /r/rust[1] the most users/contributors/community members: offensive nicknames or inability to use offensive nicknames? This is the question to ask. I dont know for sure, but I would wager that its the latter, we are on Reddit after all, such nicknames are not uncommon. But seems like the mods somehow know for sure that its the former, without any discussion on the topic...
As much as I hate to break up the debate - this is not the place for interpreting the code of conduct or discussing what is or isn't a violation. Please try to remain on topic.
Now you're just being asinine. Just because Linus didn't personally do it, doesn't mean it doesn't scale just fine. Linus uses bugzilla for bug reporting already, that's almost certainly why he hasn't switched to Github issues. And announcements and so on would obviously be handled in some other way. A forum is perfectly fine for this and having it be on some mailing list doesn't add any new capabilities or advantages.
Also, given the complexity of all the analysis involved, I wouldn't trust anything written in C/C++. My preference is something higher level that could interpret, rather than compile - that way, it can be much closer to a true executable specification than an optimizing compiler. But that's a big vague, and I'm not aware of any attempts in that direction, other than [a Redex model](https://github.com/anasazi/rust-redex) - which I am not sure how useful it is.
&gt; It's not that we're on reddit and happen to be talking about rust; it's that we want to talk about rust and happen to be on reddit. Is that the case with most users in this sub though? Seems like a question which can be answered by statistical analysis of the users. Are /r/rust users mostly posting in /r/rust, or mostly posting in other subreddits with minority of overall posts in here?
This should definitely be exposed as a library with caching, or as a long-running daemon which reads input and produces output based on a fast cache. Otherwise, people are going to find that autocompletion lags behind what they're typing noticeably, as currently happens with the likes of racer on my system.
I'm not about to go digging through people's posting histories, but I can tell you unequivocally that the majority of active commenters to this subreddit can also be found on irc.mozilla.org. If the list of moderators seems unfamiliar to anyone coming from IRC (or Github), it's because I consciously avoid appointing "the usual suspects" to positions of responsibility in order to put more power in the hands of the community at large.
&gt; I hate mailing lists, it's a terribly inefficient means of communication compared to a forum. A lot of big projects are using mailing lists and these are high volume lists, and if you've an email reader with threading support, a mailbox for each mailing list, where you can easily hide already read mails, then you can quite efficiently consume a lot of mailing lists. There's no way I could follow the same amount of projects by visiting their forums. But there already was technology better suited for discussions like mailing lists: NNTP, but it's not used that much in the open source world, but having some kind of protocol for discussions seems just to be the right way to go, then you could still have a web interface for it or a standalone application. 
When talking about "a" text editor in Rust, at this point in time it's probably "the" text editor in Rust: https://github.com/gchp/iota
There is no way to detect if the signature is wrong. For unions, neither. Instead I file RFCs: https://github.com/rust-lang/rfcs/pull/724
&gt;There's no way I could follow the same amount of projects by visiting their forums. Of course you could: just set up each of those forums to send you email notifications. Your NNTP proposal is not bad.
No, there is one forum. It has different areas. An announcements area, an "issues" area and so on. You have that today with most project mailing lists (e.g. my-proj-dev, my-proj-ann, etc.). And for me it's better because it's more convenient. Since most projects use these annoying mailing lists, I'm probably on about 20 of them. So I can't have this noise showing up in my inbox. I'm forced to create rules every time and give a "spam" address to collect the mails.... which means I never see anything unless I explicitly go into the folder for that project. Which is even worse than going to a forum because I would need additional setup to know what actual threads exist (and threading software isn't perfect, someone messes up the convention and then my "thread" is missing some important information, etc., etc.). I don't bother to set this up so when I want to check on a project again I go look in the folder to find hundreds or maybe thousands of more or less random messages. True, I can search them but I could do that on a forum. I have zero advantages over a forum but it's extra effort for me to get this working (as opposed to... clicking a link).
And for loops in Verilog are used for generating hardware. for example something like (pseudo code): for i in 1..n-1 begin tab[i] &lt;= tab[i-1]; end The values will be passed all together, it is not imperative. The Cx stuff looks rather cool, but may miss a huge point which is the efficiency of the synthesis (going from code to logic gates) which is the most important part in hardware design.
The main worry about compiler backdoor attack is that it can fool source code audit. If you are not doing source code audit, I agree, it's a silly thing to worry about. If you are, it isn't.
You said: Think about Github "issues". That's basically a forum specialised around bug reporting And then: And announcements and so on would obviously be handled in some other way How is that not two different systems?
&gt; I hate mailing lists, it's a terribly inefficient means of communication compared to a forum. From my perspective, ML is the best of both: Your mail box look like a forum and you have direct access to the content without seconds of wait. [Discourse](http://www.discourse.org/) is a ML inside a web page IMHO. The feel is the same.
As I said, I agree with the specific decision concerning nicks. I still think any "signal" thinking is dangerous and should be avoided. I can get behind exclusion based on bad action, but I can't really support exclusion based on "signal in and of itself" of probable bad action. I am not moderating this sub, but you are, and I understand avoiding "signal" will result in higher moderation burden, which I am very reluctant to force on you. But (using the example given elsewhere on this thread) I feel wrong about firing teachers for past porn appearance. I also feel wrong about excluding someone from this sub because, for example, someone wrote posts advocating fascism or homophobia on their personal blog, if they don't bring those topics to this sub.
I didn't find the original comment offensive. But /u/sanxiyn did, which is his right, and he called it out respectfully. You have just as much right to take issue with his offense, but responding with "who the fuck cares?" denies sanxiyn the same respect and lowers the level of discourse. Don't do that. Furthermore, though you'd never know it from how superb a speaker he is, English is not sanxiyn's first language (it may not be yours either, for all I know!) and so the connotations that he associates with certain words may vary from your own. Please keep this in mind.
1. I use NoScript and RequestPolicy but these can't protect against malicious JavaScript injected directly into the TCP stream (a problem at coffee shops). 2. Verizon's famous tracking header.
Not sure, the main site seems to be hosted on a different server (GitHub pages), try to access https://www.rust-lang.org/ and look at the cert.
True. It seems to require moving www.rust-lang.org to a different server. Still, it won't require spending money on other certificate, which is nice :)
Am I the only one getting confused by those graphs? To be honest I just have a hard time understanding the information exposed... From the graph I get the idea that a RWLock is slower than a Mutex which is slightly counter-intuitive.
&gt;Arent you trying to do a bit too much for a single lib? Probably. I've thought about splitting it up so that each top level submodule (audio, image, input, math, video) is a separate crate. If the code ever gets to be too big, I'll probably do this, but for now I don't feel compelled to do it yet.
How is it counter-intuitive? `RwLock` provides more functiinality and requires more book-keeping than a `Mutex`. And besides, if `RwLock` was faster than `Mutex`, why would you ever have the latter, in the first place?
&gt; Mailing lists make sense when the project is small. In contrast to web fora or IRC, mailing lists scale very well. The benefits of organizing workflow around email are immense, especially in combination with VCS. Try sending patches to a web forum … 
Would be nice to be (mostly) sure that my repressive government is not convincing me that certain APIs validate inputs when they don't, and then planning to take advantage of that later.
&gt; From the graph I get the idea that a RWLock is slower than a Mutex which is slightly counter-intuitive. It's consistent with everything I've heard from other Rust programmers. As eddyb said, the RWLock has extra book-keeping. It might pay off with lots of concurrent readers, but usually not.
(I didn't downvote you, i swear) I get it, and that's fine, but I wanted to let my opinion known also. And that can be through expressive language, so I'm not lowering the discourse, I'm just speaking my way.
Usually it is best practice to read the sidebar of subreddits before posting to them. Also you did not reply to jpfed, you only made another top level comment .
Fair point.
Every ML I join means a bunch of boring setup on my side. And all the effort gets me in the end is something inferior to a forum.
Because the structure can be mutated during the peek. In particular, pointers can become invalid. That's also why it doesn't have a method that clones the data, because a deep clone could follow a freed pointer. 
`catch!`? In a try-catch control structure, the try block is the optimistic code path, while the catch block is the on-error code path. With the `try!` macro, the rest of the function is the optimistic code path. So, analogously, `catch!` would be the name of a macro that makes the rest of the function the on-error code path. The macros essential represent an inversion of their respective control structures.
+1 about region based mm. Is there a simple paper or other doc somewhere describing how to do this ?
I fixed some benchmark bugs and have pushed some new graphs that look much nicer, imo.
Man. The BGM is freakin' intense. 
Omg yisssssss
 try_return!() or try_to_return!() 
I'm working on a 2d graphics engine right now that should be done in a few weeks. I'm basing it off of the Love2d game engine if you want to look at that to see if it would fit the bill.
I was actually planning on using love if I could find nothing for rust! It would be awesome if you could let me know when your graphics engine is complete, or better yet, just post it here.
It seems that it will take far more work to reference that, than simply include the line myself.
At the highest level, this is a `Mutex` which also supports an unlocked, by-value `read`. You'd want that because it performs well in situations with frequent reads and infrequent writes. The downside is that the read may retry internally when interrupted by writers. The other downside is that you copy the whole structure on every unlocked read. Above is the safe interface. Since it's relying on `memcpy` and has no way to run destructors, the `Copy` bound is a must. A `Sync` bound would defeat the purpose of a mutex: synchronizing access to a non-threadsafe object. `peek` is indeed something of an implementation detail. It gives you unlocked access *without* copying the data inside. The catch is that the data structure can change out from under you at any time. This is something that `&amp;T` doesn't allow, but `*const T` does — iirc, that's why it was renamed from `*T`. Anyway, `peek` could be a lot more efficient if you only want to read a few fields of a large structure. When your function reads inconsistent values, it's allowed to return nonsense, which will be discarded before the retry. But it must avoid [undefined behavior](http://doc.rust-lang.org/reference.html#behavior-considered-undefined), which would corrupt the data and control flow integrity of the whole program. I'm sure that I don't perfectly understand all the corner cases with this kind of thing. It's a bit murky because, I mean, the first bullet point on the undefined behavior list is "Data races" :D This library is still a work in progress, especially the docs. Thanks for taking a look, and let me know if you have any other suggestions :)
Although the windows stuff is a bit... Ugly, to say the least. I assume it'd be fun to translate to rust, though (currently on ~10th episode).
I appreciate your tremendously helpful words to keep things into perspective, have my upvote sir! 
Yeah I'm up to the 39th episode, I highly recommend it! I was actually comparing his simple bmp file parsing with a rust version of the code the other day ;)
wouldn't piston generally help here?
I'm having a hard time getting piston to build, that's why I decided that maybe I'll make my own.
Alright, I added you to the repo. The project doesn't build right now due to dependencies being broken though.
This was the solution I was looking for! And I was planning to write up the working code in detail ... except that as soon as I tried to take the next step forward with my code, I ran into another very similar error, and this time I can't use `take()` to solve it. Argh! I hope somebody will write a more advance tutorial on pattern matching, with non-trivial examples.
I imagine integrating in the compiler itself would be good: Its important enough that it should drive the compiler API. Autocomplete might be the main thing keeping me in C++ (it's possible with autocomplete I'd appreciate the whole idea of traits more , you'd get autocomplete in generic code, whereas at the moment I dislike having to refer to them explicitely). dogfood. autocomplete being more readily available should help anyone trying to get into the rust ecosystem.
and don't forget to remove mailing list link from the sidebar :)
Do you want to make a graphics engine or a game? Rendering graphics in rust is just as hard as in any other language. You could use [gl-rs](https://github.com/bjz/gl-rs) and [glfw-rs](https://github.com/bjz/glfw-rs) if you want to go low level, you will need some knowledge of OpenGL. Or you could use [piston](https://github.com/PistonDevelopers/graphics), a higher level abstraction. Most of these come with examples, I had no problem getting something up and running quickly.
That also raises a question: do I need to to implement `Drop` for my wrapper struct to ensure that the `SqliteConnection` destructor will get called when the wrapper goes out of scope? I'm looking for documentation on that, but haven't found it yet.
What sort of issues are you having? I'm successfully building my game on Windows, Mac, and Linux using Piston and should be able to walk you through any build troubles :D
In my experience, reading code only gets you so far. For where the documentation fails to answer questions when writing code myself, I find #rust on IRC to be my best bet.
Oh, good. That's what I needed. Thanks!
Daww, I'm blushing. Both Rust and Piston do an excellent job at "just working". Just for that, I will do a writeup tonight.
&gt; however, upon reviewing the SQLite FAQ I see that the lock occurs when you are actually writing Oh, there's a whole page regarding the locking http://www.sqlite.org/lockingv3.html besides the FAQ. Basically, COMMIT and ROLLBACK, *if they are successfull*, should release any write locks held.
This is embarassing... I meant to link to /u/tomaka17.
&gt; Finally, all those languages and frameworks (MATLAB, R, Python+Numpy, Julia) use the same FORTRAN77 code behind the scenes... Could you please explain this in more detail? 
Speaking as a (ex-, I suppose?) scientist user... for me, scientific computing is 99% about the available libraries, and not about the language features directly. Granted, Rust might make it hard for people to create those scientific libraries... but that really would be the only practical impediment to scientific usage of Rust. Give me a nice, efficient matrix library (a clone of C++'s Eigen would be nice), some analysis/machine learning libraries, nice plotting (I personally made a nice plotting library for my scientific Rust code) and I wouldn't touch Numpy/MATLAB with a 10 foot pole. Whenever I did some analysis in a REPL, I regretted it as it has 0 maintainability (even over a span of a few minutes). Whenever I used Python/MATLAB as a prototyping language, I regretted it, as it was too slow and I had to waste time to convert it to a different language. I might as well have prototyped it in C++/D and had it be fast from the beginning. 
FYI, many ISPs in China will intercept HTTP requests occassionly (or frequently, it depends on the ISP) to put nasty ads in the corner of the page. I'm using Adblock Plus so I don't see the ads, but I can see the page title is gone because it's framed.
Seems cool! Could you explain how it's different from a `Vec`, which seems to be essentially a coat check where the tickets are `isize`s? I'm assuming the coat check does not guarantee uniqueness of inserted values? Edit: looking at the source, it seems like it's a wrapper around `Vec` that makes it easier to manager the indices?
Cool! Some feedback: your main function should not take `String` as a parameter; `&amp;str` is much more flexible and doesn’t require unnecessary allocations. Alternatively (but I’m not necessarily recommending this), you could create an `EmojiFormatter` newtype which wraps around a `&amp;str` and implement `std::fmt::Display` for that, removing the need for large allocations altogether. Unfortunately, you’d have to ditch `regex` to get that to work, and thus it’d probably be harder to implement (hence me not *necessarily* recommending this option).
Neat! I did something similar: https://github.com/xmppwocky/gcarena
Thanks for the input! I'm actually looking into migrating the whole thing to &amp;str, i'm just still a bit confused on the details of String vs. &amp;str. I'll look into the newtype solution, it sounds really interesting!
The Fortran code being referred to us probably LAPACK and related libraries (LINPACK, EISPACK, BLAS, etc.). I know MATLAB and SciPy/NumPy use LAPACK for fast matrix operations, and others probably do as well. MATLAB started as basically an interactive shell for LINPACK. A lot of MATLAB courses focus on teaching how to write code that is mostly matrix operations, eschewing for loops and other built in control flow as much as possible, because the underlying Fortran libraries are so much faster than the MATLAB interpreter.
One of the suggestions in the OP was if_ok_return, but I think yours might be better.
Different domains, really. I can imagine Rust could do well for a larger scale simulation software or something like that, but for a one-off program for a very specific dataset is better off being done in Python+Numpy or Nim or something. (Nim would be a great choice, IMO.)
/r/rust is for the Rust programming language. You want /r/playrust.
Note that high-performance Haskell code uses similar techniques. Applications that concatenate lots of strings use the [`Builder`](http://hackage.haskell.org/package/bytestring-0.10.4.1/docs/Data-ByteString-Builder.html) type, which is basically a function that writes to a (mutable) buffer. There's a bit of magic that goes into wrapping that in a pretty API, but the core idea is the same.
@TopHattedCoder beat me to it
Use &lt;Cat as Meow&gt;::call() instead. http://is.gd/KrdIqR 
Wow, I didn't know that was already implemented!
Alternativly, you can write let m: Cat = &lt;Cat as Meow&gt;::call(); so that the compiler knows *which* implementation of `Meow` you meant to use. Type deduction does not help here because you defined `call` to always return a `Cat` regardless of the implementation. But I don't think that this is what you actually want. It seems more likely that you really wanted `call` to return `Self` like it has been suggested. Anyhow, `Self` somehow has to be uniquely determined. Either via type deduction (this requires `call` to use `self` or `Self` somewhere in the signature) or by specifying `Self` via the `&lt;ConcreteType as Trait&gt;` syntax which refers to an implementation of `Trait` for `Self`=`ConcreteType`.
Whoops, I think it could; I was thinking that an `EmojiFormatter` would work on a `Reader` or something instead of a `&amp;str`, but it doesn’t have to.
Are you sure there are no other directories containing libstdc++6.dll on the PATH?
Exactly this. Can't even add anything, except that yes indeed, Numpy, Julia and R are also based on those libraries
Nice job! I see the author is already past the point of AST evaluation, going for a compiler and interpreter. I've been fiddling around doing the same thing, but it's a more naive approach (for now ;)): https://github.com/razielgn/ostrov I encourage anyone to do the same: my experience is filled with huge "ha-ha!" moments, especially regarding memory management. It's a valuable Rust lesson.
Oh, yeah. Eventually, this macro should be expanded at compile time, but I haven't gotten around to it yet :)
Rust has zero-cost, high-level abstractions, easy FFI and awesome performance. Thus I'd say it's absolutely appropriate for certain applications in scientific computing. Not for one-off scripting, I think Julia and Python are better suited for that. But where Rust could really shine are simulations. It is imho very well suited to replace those horrible pieces of C/Fortran77 simulation stuff out in the wild. The point is, scientists tend to design their software so poorly, that it takes an entire thesis to implement a conceptually simple feature. (This happens a lot in my experience.) Rust could help out in that regard with its abstraction capabilities. However, whether Rust can eventually compete with such ancient languages is a question about scientists' attitude, and not so much about language features.
I would have thought that `RwLock` would excel in the scenario given (lots of read, few writes) because it allows parallel readers which a simple `Mutex` does not (serializing every access), whereas a `Mutex` would excel when most/all accesses are writes. Am I missing something? Maybe reading the graphs wrong? Or maybe it depends on how long you keep the lock...
&gt; Hah! Nothing would been more Canadian of me than to have named the language Rush. Every time Rush got installed, the intro to Tom Sawyer would play. `Rush is ready to roll.` *PSSSSuuuuuuooohhh...*
gfx-rs had something very similar to this for a long time for handling GPU resources.
Yup, that's one reason to move them out.
No, it's about ~~10x~~ 1.3x slower but the use cases are totally different. You would use a CoatCheck when you want to give someone else a value but still be able to talk about it (i.e. when registering a callback, making a request, etc...).
Uploaded in Debian NEW a day ago: https://ftp-master.debian.org/new/rust_1.0.0~alpha-0~exp1.html Waiting for approval
&gt; a clone of C++'s Eigen would be nice oh yeah, i used that in some R lib i develop that was too slow. so i sped it up using Rcpp and … RcppEigen. pretty cool.
This actually bumped out of my mind when I read through this thread, but when I saw your words I began to think about similar syntax of PHP, lol. Anyway, I guess current syntax is good enough. 
Playpen: http://is.gd/KHni1o Example: `let a: Option&lt;i32&gt; = num::from_str_radix("FF", 16);` BTW: feel free to submit a PR with an example ;)
Yes, I am working hard on adding examples, hoping to have an example for every single API call by the time 1.0 hits.
Oh, sure! I would have added it myself already if I weren't too lazy to register there. :P EDIT: Oh, you mean the rust specific repo - either way its a yes.
Changing i32 to String and FF to 41706f70686973 does not work, Why cant I use the Option of String? What Can I do to get a String out of '41706f70686973'?
&gt;&gt; " is a question about scientists' attitude, and not so much about language features." or learning curve. a scientist has a head/schedule full of science, so they might have a different tradeoff for productivity.
Oh, good to know about that! I had made my own rust-vim repository that I was updating manually.
1. Create an *empty* gh-pages branch. 2. Put the hook in '.git/hooks/post-commit' and make it executable. 3. Commit a change. On commit, it will re-compile the documentation and replace any files in the gh-pages branch with the new documentation. It shouldn't eat your babies but it might so read it over and backup before using.
At [lib.rs#L17](https://github.com/sindriava/rust-emojicons/blob/master/src/lib.rs#L17): // Why `\\` twice? I think you're trying to escape `+` and `-` // but you shouldn't need to. Most things are literal except for // `\`, `-`, and `^`. And `-` at the right is literal. static REGEX: Regex = regex!(r":([a-zA-Z0-9_\\+\\-]+):"); // This works for me static REGEX: Regex = regex!(r":([a-zA-Z0-9_+-]+):"); [Playpen](http://play.rust-lang.org/?code=%23!%5Ballow%28unstable%29%5D%0Aextern%20crate%20regex%3B%0A%0Ause%20regex%3A%3ARegex%3B%0A%0Afn%20main%28%29%20{%0A%20%20%20%20let%20regex%20%3D%20Regex%3A%3Anew%28r%22%3A%28%5Ba-zA-Z0-9_%2B-%5D%2B%29%3A%22%29.unwrap%28%29%3B%0A%0A%20%20%20%20println!%28%22{%3A%3F}%22%2C%20regex.is_match%28%22%3A-1%3A%22%29%29%3B%0A%20%20%20%20println!%28%22{%3A%3F}%22%2C%20regex.is_match%28%22%3A%2B1%3A%22%29%29%3B%0A%20%20%20%20println!%28%22{%3A%3F}%22%2C%20regex.is_match%28%22%3Abasket-case%3A%22%29%29%3B%0A})
[because brson so graciously tickled my ego](http://www.reddit.com/r/rust/comments/2tg5pf/is_it_hopeless_to_try_and_make_a_2d_graphics/cnyxir7), I made this little guide. Would love any feedback and grammatical/technical nitpickings! Also, if the Piston people want to put this under their umbrella, I would be more than happy to transfer the repo.
Well, not the same thing, right? IIRC, &amp;str is Unicode aware while char* isn't.
This is endianness-dependant though, right? So technically slightly less portable.
I wonder how much of an overlap there is between Rustaceans and Schemers... Looks like there's quite a bit. quick edit: FTR I use Scheme and I'm learning Rust. :)
Comcast and Verizon are hijacking HTTP for advertising purposes too (though I've only heard about adding headers, not straight modification of HTTP body)
I'm happy to just let the matter drop and call it closed. We can probably agree that arguing further is a waste of time for everyone involved. I do have to hand it to you - your distinction between Rust community and Rust room inside reddit is perfect, and reveals one of the greatest underlying problems of this conversation: that you have the exact opposite interpretation as I do. I think mine is justified, because this place is literally and structurally a subset of reddit, but it's not my kingdom to rule.
Sorry, I missed this before. With higher-ranked trait bounds (HRTB) you should be able to write ```` trait ByRefAdd where for&lt;'a&gt; &amp;'a Self: Add&lt;&amp;'a Self, Output = Self&gt; {} ```` but this does not seem to be working today. (I believe the `for` syntax here is currently limited to coming after the colon, but that's not a fundamental limitation). In any case, that was the planned way of recovering constraints for generics. I will talk with Niko to see how far away we are from providing the syntax above.
FWIW, there is no longer any `Num` trait, and the traits remaining in `std::num` are *not* intended for this kind of generic programming; they are basically just extension traits proving some methods for the primitive numeric types. The plan has been to grow APIs for BigInts, generic numerics, and numeric hierarchies externally in crates.io, since there are many possible designs/constraints and we did not want to make a commitment in `std` yet.
I fully agree that we should allow generic programming over types that implement `Add` for specific combinations of by-value and by-reference. This was carefully considered when the changes to the traits were made. Although it's not quite working today (see [my other comment](http://www.reddit.com/r/rust/comments/2srz0g/by_value_operator_overloading_problems/cnzyxv7)), the plan is for higher-ranked trait bounds to allow you to define your own custom traits restricting to any by-ref/by-val implementations you want.
I have an old graphics driver (opengl 1.4), (and I'm probably not the only one) so the example doesn't work. I don't want to create some bleeding edge 3d game. I just want some basic graphics. What sould I do? edit: The exemple compiles but doesn't run since it "[can] not create GL context".
That's exactly what I tried. But it does look like `for` is not allowed to come before the colon. I'm glad to read that it *should* work. And seeing this constraint for `Output`, it makes me wonder about how easily it will be to support compile-time checking of units (meters * meters = meters squared). I think, this might be an area where ad-hoc generics actually work better.
Woah, this is really neat! It would be great if you had a way to escape back to regular rust code inside of an element! Something like this: let names = vec!["bob", "cindy"]; let markup = html! { ul { ${ names.iter().map(|name| html! { li {name} }) }} };
Is s mutable?
Unfortunately, I don't think Piston supports anything below OpenGL 2.0 by the looks of [this](https://github.com/PistonDevelopers/shader_version/blob/master/src/opengl.rs) :/ You could try giving [rust-sfml](https://github.com/JeremyLetang/rust-sfml) a whirl. rust-sfml is actually what I used before Piston, because I came from a C++/SFML background.
I'm no MinGW expert, but it's strange to me that you also had to put the .dll's in the mingw lib folder.. but I'm glad it worked!
Thanks for the input! You can achieve a similar result by rendering each list item separately, then splicing it in at the end: let names_html = names.map(|name| html! { li $name }.render()).concat(); let markup = html! { ul $$names_html }; but that feels a bit icky tbh. As I mentioned in my original comment, I'm planning to add some kind of `for` syntax which should cover your use case.
The compiler does strange things with nested macro invocations ([bug #16617](https://github.com/rust-lang/rust/issues/16617)), so the obvious solution won't work.
Very cool! And I get why "maud" is related to Pinkie Pie, but am I missing something about why "maud" is related to html or does the name not have any significance in that regard?
no, nothing changed in gl-rs
Good question. For me, naming a project is a deeply multifaceted process of self-discovery, crossing the disciplines of science, engineering and art. In this case, the reasoning comes down to three points: 1. "Maud" and "markup" have ~~two~~ three letters in common 2. The library is efficient and austere, just like the character 3. Because [HTML5 rocks](https://www.youtube.com/watch?v=sC-269K01Qk)
Is there anything we can do to make building SDL/freetype with the right compiler on windows easier?
Sure. Rust's `BinaryHeap` already has an [`into_iter`](http://doc.rust-lang.org/std/collections/binary_heap/struct.BinaryHeap.html#method.into_iter) method that does that, except that the items are returned in arbitrary order.
Looking at the documentation for stringColor in sdl2_gfx, it takes a `*const c_char` rather than a `*mut i8`. When you have fixed that in the ffi declaration, the following should work: let cs = CString::from_slice(s.as_bytes()); unsafe { ll::stringColor(self.raw(), x, y, cs.as_ptr(), color.as_u32()) } Notice that if you don't bind the CString itself to a variable it will be immediately destroyed again and you will get a "does not live long enough" error.
So my post could be summarized as a feature request for an `into_sorted_iter` for `BinaryHeap`. (edit: I think it's not the same than `into_sorted_vec` and getting its `iter()`, because turning it into a `Vec` would do all the work upfront. But I'm not sure this use case is worth adding more to the API, that is already quite big..) (and I see, `PriorityQueue` isn't a thing since [2 months ago](https://www.reddit.com/r/rust/comments/2ljfnd/warning_some_collection_methods_have_had_their/) - when I searched for priority queues in Google, it returned a link to the 0.11 docs..)
Wrap the build with cmake and let that handle the details. Sdl2 has cmake support. I normally just have cmaje download and build a static version for me instead of relying on things in the system.
&gt; Luckily for you crazy kids, C has a stable ABI, so you can simply plug in the binaries I have produced! Said no tutorial writer ever :P Thanks a lot for this! In general tutorials always differ from the real experience in some way or another (due to system differences, etc), which can make the whole experience much worse. Fixing the dependency issue (which seems like the common point of failure) by providing binaries -- perfect!
The generated HTML is invalid, you should output `br /` as `&lt;br /&gt;`, same for img and many other! 
Can this assumption be encapsulated by using a fix-point operator in Rust? 
I was thinking about this, but fix expects a function (which isn't a problem in lambda calculus because there everything is a function) A solution could be a recursive let ([like this](https://www.haskell.org/haskellwiki/Tying_the_Knot) - also works on OCaml by the way, which is strict) - but I suppose recursive lets would complicate memory management? I can't find any discussion of them regarding Rust.
What's so difficult on Windows? Just download SDL2 binaries, copy SDL2.dll into Rust/bin and wherever your final binary is and it should work right away. That's how I'm running hematite. EDIT: If Rust complains get TDM MinGW64.
Rust really needs to get rid of MinGW dependencies.
Yes, `String` and `str` in Rust enforce UTF-8 while `std::string` and `char*` are just arrays of bytes in C++. But ignoring that, minno's analogy is helpful.
For now there is no way to implement Eigen in Rust (no integer generics) so there won't be any compile-time matrix size checking. Only way (for now) is to use run time checks using `Vec`.
Ack. Compare UnrealEngine: Apple iOS, Android, HTML5, Linux, OS X, Oculus, Playstation, SteamOS, Windows, Xbox. 
Honestly, why? 
Yeah, a lot of the confusion was cleared up when I realised that String dereferences to str, which makes a lot more sense :)
You right, of course. It must have stayed there from before I discovered raw string literals. I've pushed a fixed just now!
I've always been meaning to ask, are you the same as eibwen from IRC? Or someone else? (Or not active on IRC/GH at all, I have no issue with that) Of course, no need to respond if you don't want to.
First example from the docs does not compile for me: main.rs:9:18: 11:7 error: borrowed value does not live long enough main.rs:9 let markup = html! { main.rs:10 p { "Hi, " $name "!" } main.rs:11 }; main.rs:1:1: 13:1 note: in expansion of html! 
I went with this. Thanks.
Thanks for all the feedback. I went with `return_if_ok!`, which I feel describes best what the macro actually does. By this logic, the `try!` macro could be named `return_if_err!`, but that doesn’t matter much as [it will likely be replaced with a `?` operator](https://github.com/rust-lang/rfcs/pull/243). I’ve published a small crate with only the `return_if_ok!` macro [on GitHub](https://github.com/rust-lang/rfcs/pull/243) and [on crates.io](https://crates.io/crates/return_if_ok). Maybe it could be added to libstd later, in the meantime it can be used with just `#[macro_use] extern crate return_if_ok;`.
There *is* another [RFC](https://github.com/rust-lang/rfcs/pull/573) on changing them to `isz` and `usz` respectively.
There are performance implications as well. Accessing an array in a for loop implies a bounds check on each access, which is unnecessary but it may not be possible for the compiler to optimise it out (it's quite hard to do). Using an iterator avoids the bounds checks while still providing a safe interface.
Speaking of that video - is there a way to watch it that doesn't require you registering to some oreilly bs?
Thanks for your reply! I actually thought of doing that, but gave up because I ran into problems with the move keyword: src/main.rs:29:26: 32:6 error: can't infer the "kind" of the closure; explicitly annotate it; e.g. `|&amp;:| {}` [E0187] src/main.rs:29 let loginpage = move |_: &amp;mut Request| -&gt; IronResult&lt;Response&gt; { I tried to read about the move || {} closure from the Book, but it just mentions that it exists, and gives no proper examples...
This is brilliant! Someone please do this :)
Sort of: just put "First", "Last" and "a.b@c.com" in the three required fields..
Now THIS would be awesome.
&gt; Rust lifetime parameters are particularly cluttering IMO and, unfortunately, unlikely to change since it has passed 1.0 Alpha. I personally agree, but it stayed the way it is because of community feedback.
let n: i64; let bytes = [n &gt;&gt; 56 as u8, n &gt;&gt; 48 as u8, n &gt;&gt; 40 as u8, ..., n as u8]; Or let bytes = (0..7).rev().map(|i| n &gt;&gt; (8 * i) as u8).collect::&lt;Vec&lt;u8&gt;&gt;();
Fair enough. I just wanted to be able to use the meme, because I've never used a meme before :)
Hey folks, Wanted to share my thoughts and maybe get some feedback on things. I'm excited to work on my first crate for Rust and want to do things nice!
Looks like `mktemp -d` isn't valid on Mac (at least) without a prefix. ➜ raft git:(master) mktemp -d usage: mktemp [-d] [-q] [-t prefix] [-u] template ... mktemp [-d] [-q] [-u] -t prefix
The way you are using is the current correct way. It's not cloning the entire socket, they're actually just shallow structs that keep reference to the socket internally. I do the same in hyper's tcp code. The IO reform will change so it seems less bad, by providing reader() and writer() methods. 
Side note: status::Ok with a Redirect? 
There have been a handful of cases in subsequent PRs where the compiler couldn't infer the type, so I had to put them back in. Thanks EddyB for helping me out on that PR :)
I didn't know you could define structs inside enums like that .. (cool!)
Multirust: truly pushing the limits of MAXIMUM RUST!
Yeah, it's awesome! Especially because you can move them about the network and I/O!
I imagine Python versions 2 &amp; 3 have the same problem as D 1 and 2. Most GHC users install (complex packages) with cabal AFAIK. What Debian is good at is providing the ghc and cabal to begin with. But hackage.haskell.org isn't going to be well-represented in Debian any time soon, IMHO, so the GHC example is actually a negative one. Don't know about Go. Basically, it's quite a burden for a Debian newby to make and submit a Debian package properly, and there is no automation for this AFAIK, so seeing all those crates.io packages in Debian is unlikely. Maybe some of the most popular will get the attention and a mainteiner to be packaged, that's all. (It would be interesting to see someone automating this, though, like making a service to package and submit most/some of the crates.io packages). As for the Rust version, yes, it's quite common to have multiple versions of the language packaged. Take gcc for example.
Oh, right. But those were all examples doc comments, no? They could've probably looked nicer with explicit type annotations, I would. In any case, the bulk of them was pretty straight-forward.
I looked at the hyper source code and it actually helped me solved one of my other problems, which was passing the event handling function into a thread so it can be used. I sort of understand how it works, but only slightly. Am I correct in saying that you are tacking on the Sync + Send traits, which allows a resource to pass into a thread, on to functions (in this case that match your request/response parameters)? Previously I was just trying to call a closure from the thread, and the compiler did not like that.
Is that so? I thought maybe the LTO parts are shipped as a part of the library, so you can have a binary `rlib` and still LTO to it?
You have to recompile with dynamic linking too because there's no ABI stability.
&gt; Using an iterator avoids the bounds checks while still providing a safe interface. Iterator *adaptors* often add similar costs.
One thing to be careful of is that every instance will take up the size of the largest variant, if you have very different sizes and mostly have instances of the smaller sized variant(s) then it may be better to box data inside larger ones to bring them more in line with each other. As always it's a memory usage vs performance trade off.
I disagree. Debian has reasons for most of its policy, and the policy does provide some benefits. When larger free software world doest not support those reasons (yes, there has been movement in that direction for a while), cost to Debian increases, and cost may outweight benefit in some cases. This does not automatically make it "Debian's problem".
This is a general problem of every dynamic language eco system against the package management systems. Most of the issue is that the eco systems encourage a large and deep dependency list and package-managers, because each one needs to be maintained by a person, try to keep dependencies and shallow and un-complex as possible. But since this is ipso-facto also the Cargo community and it's still under development, I wonder if we can figure out a better way to 'pass the baton'. What if Cargo (or some service that interacted with Cargo), auto-generated a debian package for each semver major (and maybe minor) release. If Cargo (and/or the dependent service) Then Cargo or the secondary service operates as an auto-PPA. Then the Debian folks would only have to pick and choose the projects they wanted to be package managed in Debian and would white-list them to update based on cargo's updates. The annoying part is then package D-1.0 and D-1.1 and D-1.2 .... are all possibly in the debian package system assuming all those subversions are separated depended upon for different upstream packages. On the other hand, there's a lot less human labor, and it would only fall to the auditing, and QA. This would be super-useful on the deployment side. At work, we have separate processes for deploying python package dependencies from other OS-level things. If it were a single cargo command to build your project into a debian package, then deployments would be a dream (both for programmers and devops folks). The other advantage is generally OS package manager installations and language package managers often fight about where packages are installed or where they're found. If this were done in an automated/coordinated way, then presumably both would be able to 'see' that something had been already installed or custom-updated and possibly take advantage of it (or at least avoid not clobbering each other).
Yep, Vec would not be an issue. Though I think a vec is three pointer-width values rather than just one pointer, so it may be slightly larger on the stack/in a structure than you think.
Well, it would be nice to be able to play nicely with debian. ...just remember that apart from a very *very* few people, in a broader context, most dont actually care. Its also very important *not* to break how things work on the various other platforms; specifically windows, where dependency libraries are not package managed. Dont always link statically (unlike go) is a reasonable path; dont link statically (ever) is not fesible, or even up for discussion.
In my experience, auto-generated packages are pretty useless. The amazing, wonderful thing about Debian is that every package has had a human look over it and think carefully about how it might affect or be affected by other packages, and how to make it useful for people who might install it. Auto-generated packages are often more trouble than they're worth. That said, Debian have written tools to automate the automatable parts of package creation, with special support for things like [Go](https://packages.debian.org/sid/dh-golang) or [Lua](https://packages.debian.org/sid/dh-lua) or [Python](https://packages.debian.org/sid/dh-python), and I'm sure once Rust gets popular, somebody will write a tool to turn a Cargo crate into a first-draft Debian package... as long as Cargo packages aren't designed to make it difficult, like Ruby gems.
I rarely run into people using dpkg or rpm for application-level management, though. Something like a Rust binary I'd probably put into my own deployable solution. Especially with CoreOS and containerizing, package management for application-level stuff is largely a forgotten thing for me and every employer I've been to for over five years. Just getting a Python or (God help you) Rails app running consistently across distros is a nightmare, in my experience, if you use the package managers. Why bother -- virtualenv, Rocket, whatever. Something simple like running a script after RPM installation requires this whole build process, and directory layout, and process invoking process invoking process, it's like building native code with gcc. I always have to have a reference on hand. The old "use the system package manager to be clean and consistent" thing lost to practicality for me ages ago. That's just my experience, though, and perhaps yours differs. Edit: Soften a bit, sorry for biting hard on the pet peeve.
You're right. I'm too loose with "industry." Perhaps "Web industry?" Edit: I toned it down a bit.
Nice. Philip Rogaway was my crypto professor at UC Davis. I always thought OCB mode should see more usage, seeing as it kills two birds with one stone
Rust does not seem to target web industry. So I believe concerns of web industry, while important, are of less priority.
`isize, usize, weallsize`
Oh, is that what the conversation I wandered into was about. :-) I don't think this is hard to resolve at all: just include ABI versions (the first component in semver) in the name of the package. So A (an app?) gets packaged as `a`, B and C get packaged as `libb-1-rust` and `libc-1-rust` respectively, and both `libd-1-rust` and `libd-2-rust` are in Debian. It's totally fine for installing `a` to recursively pull in both `libd-1-rust` and `libd-2-rust`. There's a bit of dependency purgatory here, but not hell, provided that there aren't too many ABI versions of D running around. It's no worse than if you were just using cargo. (If upstream D 1.0.0 through 30.0.0 are all used in 30 active projects, you probably have dependency hell well before you're thinking of OS packaging.) This limits the security patches to just the ABI versions of D that are actually used in the archive. Occasionally it will be Debian's responsibility to update an abandoned library to use newer versions of its dependencies, but that's part of a packager's responsibilities anyway. I believe that the naming scheme for Rust dynamic libraries means that `libd-1-rust` and `libd-2-rust` will ship `.so` files with different names already, but if not, Debian can rename things to make this work (either working with Rust upstream, or independently). A little more important is that `libd-1-rust` 1.1 and 1.2 both install the same filename, but that can be solved with symlinks to the real name, if nothing else. This isn't unprecedented in Debian. For an example with C packages, [libgnutls26](https://packages.debian.org/search?keywords=libgnutls26) (GnuTLS 2.x, providing `libgnutls.so.26`) and [libgnutls28](https://packages.debian.org/search?keywords=libgnutls28) (GnuTLS 3.x, providing `libgnutls.so.28`) both exist in the current stable release; after a bit of work, everything using 2.x was updated to 3.x in testing, so the upcoming release will only have `libgnutls28`. There are a lot of versions of [Berkeley DB](https://packages.debian.org/search?keywords=libdb), especially in older releases, named things like `libdb4.6` and `libdb5.1`. And so forth. It's up to the libraries to work correctly if multiple versions are loaded into the same process (and some, like GTK+ 2.x and 3.x, refuse), but if they do, Debian policy is fine with this. (The `libfoo-rust` naming scheme is inspired by the Perl module naming scheme, where Foo::Bar is `libfoo-bar-perl`. There are other possible schemes, and perhaps just `libfoo` is the right one, especially for Rust libraries that offer C ABIs.)
It is Rust's problem insofar as people will be running Debian systems and want to `apt-get install` Rust libraries and applications, and a systems language that isn't available in `apt` is a weak story. This is a social argument, not a technical one. It's entirely possible that the technical changes should all be made on Debian side, but it's in the Rust community's inherent interest to see them made and follow through with making sure things happen, way more than the Debian community's.
May Nix save us all from the hurdles of legacy package managers. Cargo's design fits very well, just need someone to maintain integration. (I know `cargo2nix` has been done already, months ago, but it could have become outdated.)
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Galois/Counter Mode**](https://en.wikipedia.org/wiki/Galois/Counter%20Mode): [](#sfw) --- &gt;__Galois/Counter Mode__ (__GCM__) is a [mode of operation](https://en.wikipedia.org/wiki/Block_cipher_modes_of_operation) for symmetric key cryptographic [block ciphers](https://en.wikipedia.org/wiki/Block_cipher) that has been widely adopted because of its efficiency and performance. GCM throughput rates for state of the art, high speed communication channels can be achieved with reasonable hardware resources. It is an [authenticated encryption](https://en.wikipedia.org/wiki/Authenticated_encryption) algorithm designed to provide both data authenticity (integrity) and confidentiality. GCM is defined for block ciphers with a block size of 128 bits. __Galois Message Authentication Code__ (__GMAC__) is an authentication-only variant of the GCM which can be used as an incremental message authentication code. Both GCM and GMAC can accept initialization vectors of arbitrary length. &gt;==== &gt;[**Image**](https://i.imgur.com/4oH7Aeh.png) [^(i)](https://commons.wikimedia.org/wiki/File:GCM-Galois_Counter_Mode.svg) --- ^Interesting: [^CLMUL ^instruction ^set](https://en.wikipedia.org/wiki/CLMUL_instruction_set) ^| [^IEEE ^802.1AE](https://en.wikipedia.org/wiki/IEEE_802.1AE) ^| [^Sophie ^Germain ^Counter ^Mode](https://en.wikipedia.org/wiki/Sophie_Germain_Counter_Mode) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+co124tt) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+co124tt)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Debian's policy does not work for rust and never will. You would need to remove cargo basically. In Python land Debian stated to hand patch vectored libraries against the system installed version, even if they are incompatible :-/
This is also a source of a problem. e.g. Riak ships their own fork of leveldb and underperforms with mainline leveldb. Some maintainers mess with the package though and remove their leveldb fork, using the system one. http://vagabond.github.io/rants/2013/06/21/z_packagers-dont-know-best/ [1] Ruby had similar problems, with the debian packages being fundamentally broken for any practical use for a long time. I ran a support board for years and 90% of all Debian problems were fixed by "just install from source". [1]: if you read through the whole post and find that the link to the follow-up is broken: http://vagabond.github.io/rants/2013/06/21/zz_packaging-and-the-tide-of-history/
One difference is that Rusthon aims for readable generated code: https://github.com/rusthon/Rusthon/wiki/No-Haxe-Backend
I feel that integer literal constants are one of the things that Go got just right. Maybe Rust should take a hint in a future version? In Go, integer constants are more like macro invocations in that they don't get a type until they are used. Instead of a suffix, the regular type inference rules could be applied.
The error message already says it: You can’t index a slice with an `u16`. Try `self.r[i as usize]` instead.
&gt; artificial barriers Well, not just artificial barriers. For example, suppose I pick a random package from cargo and try to build it for armv8 (as required by iOS starting in February). What's my probability of running into issues? What about PPC (PS3, Xbox360, Wii U)?
I meant more in terms of the use of external C libraries that are tied to a particular architecture, having support for various ABIs in the build infrastructure etc. I know LLVM supports all of that but can I just cross-compile with the rustc driver or does the world crash and burn if I try to do it? Will I need a PPC build server to create PPC binaries?
&gt; The trouble is, my shell won't let it. You'll have to be more specific. Is there some particular error message? Can you produce a minimal test-case? etc. etc.
&gt; "none of them are actually required at all". Unfortunately, [two were](https://github.com/rust-lang/rust/pull/21511#issuecomment-71315715).
The problem with Ruby packaging was that Ruby ships with a stdlib and Debian decided to split that into multiple smaller packages in a way that was decided by some maintainer and left there. (we're not talking about rubygems here, mind you, just base Ruby) It took another maintainer multiple years to get those packages right again. Another blunder was that the newest Ubuntu LTS ships a completely broken Ruby package that will stick around because of backwards compatibility. It's not that rubyists don't want system packaging, the experiences with it were... less then stellar. The problem with Riak is that it doesn't ship a third-party library. The leveldb distribution in Riak is forked and maintained by Basho. It only bears the name and shares API compatibility with leveldb. It's runtime behaviour is very different. That's also intended usage of leveldb, it is intended to be vendored (e.g. you cannot install leveldb from source, it comes without install scripts). I've come to the conclusion that there should be a differentiation between system packaging and user-space packaging.
For sure. But you'll have to recompile only your program, not the "100 packages", wouldn't you?
I agree with that, but you'll have cases where it could be EITHER `i32` or `isize` and that causes it to dispatch to a different method. So you kind of want to have suffixes anyway.
&gt; cargo unconditionally builds its own C libraries Do you mean `cargo` itself, or just cargo packages in general? As far as I can tell, many of libraries `cargo` itself depends on use [pkg-config](https://crates.io/crates/pkg-config) to (try to) [conditionally build the C lib](https://github.com/alexcrichton/git2-rs/blob/92063af1510ecdab6e2ba369044b26b85a4d8ecd/libgit2-sys/build.rs#L15) ([another example](https://github.com/alexcrichton/ssh2-rs/blob/f125dbfd31473fc5958955ac7546b06fafd04530/libssh2-sys/build.rs#L11)). (Maybe there's a bug with that handling?) &gt; cargo doesn't even plan to support any kind of sandboxed/offline build Do you mean that there's no current plans for it, or that there are plans to not have it ever?
Multirust is my favourite set of shell scripts!
I believe Rust does that already -- we have enough type inference that you don't need suffixes in most cases. But there are cases where a method can accept more than one type and then you either have to explicitly qualify it with the `::&lt;T&gt;` syntax or explicitly annotate the literal. (Go doesn't have generics, this problem doesn't appear)
Well, you would have to rely on "extern 'C'" as well, which isn't really intended when using Rust libraries.
Debian package IS the source tree, sorry if that wasn't clear. I guess "cargo deb" is misleading, should have been "cargo debian". As for the dependencies, it's trivial for the cargo to include them as subfolders.
Which means to fall back to the C ABI, because (currently and near future) Rust cannot provide a stable ABI?
My guess is that it is a Rust implementation of The Raft Consensus Algorithm. https://raftconsensus.github.io/
Also, not exporting traits, etc. So, it's not very practical.
It would still be something. A message in the lines of "T cannot be indexed using I" would probably be better than the current message.
Hey man, looks like a cool library. Have you played with using macros to make this a little easier to use? (Not to say that this is hard-to-use, or that I have any ideas to make it easier...)
I haven't done anything with macros since I do not really have an idea of what the macros should make it easier to write. I suppose that the major loss in expressiveness from parsec is that we do not have a true substitute for 'do' notation. It is possible to emulate it with the try! macro though you need to pass the input manually for it to work so it is not as convenient as it could be. let (d, input) = try!(parser.parser_state(input)); let (d2, input) = try!(parser2.parse_state(input)); //etc I don't think it is possible to make this any easier through macros though. I did have an "environment" struct in the beginning of the project which kept track of the input letting you write: let mut env = Env::new(input); let d= try!(env.parse(parser)); let d2 = try!(env.parse(parser2)); return Ok((d, d2), env.into_inner()); I removed it later since I did not use it internally.
^(Very cool. Why choose to use an invalid identifier as the crate name? I hope this doesn't become a trend, it's a bit silly -- "rustc-serialize" as rustc_serialize)
PriorityQueue is now BinaryHeap. Sounds like you just want to implement a custom iterator that wraps a BinaryHeap and `next` is just a call to `pop`?
Maybe rewrite a linker (in Rust, of course).
https://zinc.rs/ might be interested. They only do ARM currently, but it doesn't look like they want to.
Honestly I saw rust-serialize and a few others using that convention so I though that was the way to name it even though it looks a bit silly. Since I aren't exactly attached to the name I didn't give it much more thought than that.
Not sure I understood it correctly but it is only possible to create data structures from a stream of chars. Not the other way around. For instance, what should the or parser generate since it can apply multiple different parsers?
The documentation doesn't really talk about this. The closest I found just now is [here](http://doc.rust-lang.org/reference.html#machine-dependent-integer-types): "can be used to calculate differences between pointers into an object or array" is about as close as I see. It's just not obvious from the documentation what the indexing rules are or why it shouldn't work for `u8`/`u16`/... [EDIT] Also, since `my_array[7]` works and the index type isn't labeled, it's not obvious what the index type is either.
Indexing is generalized using the [`Index`](http://doc.rust-lang.org/nightly/core/ops/trait.Index.html) trait, which can take more or less anything. It would technically be possible to index with any kind of integer, but `usize` is practical since its size is adapted to the target architecture.
I'd move `Box::new` together with the unwind harness out of the unsafe block. Then I thought `transmute` consumes the value, so you shouldn't need `forget`? Otherwise looks about right.
Whether -EINVAL is good or not depends entirely on the plugin host API. For `plugin_run`, I would go with transmuting to box and calling `forget` at the end. However, it's "known" that boxes and references to statically sized values are in essence pointers, so something like this would work too: let borrowed = unsafe { &amp;*(p as *mut Plugin) };
Is there a doc on what is already done? I see no 'main' just tests.
Haven't seen a way yet for an Uno, but I'd love to be able to.
AFAIK that backend is incomplete and bitrotting since a while…
Some poking around in the build file showed that it was supposed to be LIBCLANG_PATH=/usr/lib/llvm-3.5/lib/ cargo build (Not LD_PRELOAD) And then this issue (https://github.com/crabtw/rust-bindgen/issues/110) suggested that symlinking the library names was enough
&gt; If cargo can provide a way to generate the sources so that they can be built without internet access, either bundling all dependencies as sources into the tarball or allowing to override those at building time, then the rest becomes quite normal. It already does, so it should be fine. 
&gt; * cargo doesn't even plan to support any kind of sandboxed/offline build This is outright false.
Yes, it's a pointer to the data, a length, and a capcity.
Yes exactly!
There's an [interesting discussion on the IETF TLS mailing list](http://www.ietf.org/mail-archive/web/tls/current/msg15015.html) about adding OCB ciphersuites to TLS 1.3 (and maybe 1.2). Also I see that OpenSSL has an implementation now (and an explicit patent grant).
And further reading reveals that the instructions did indeed say so from the beginning. Doh!
It's not the end of the world, though
Right, but with a new version every six weeks, is that really feasable/acceptable?
&gt;I am bad at ref in patterns You are not alone, for some reasons I always forget the rules and every time I see them I have to start thinking about what references what - quite a mental overhead. There's something very counter-intuitive in them.
Please leave comments *directly on the RFC threads* to help centralize discussion.
&gt; Whether -EINVAL is good or not depends entirely on the plugin host API. The plugin host API will end up calling strerror for the error code I return, and present the resulting string to the user. But I can't find any standard errno that would translate to something like "Internal error", "panic" etc... &gt; For plugin_run, I would go with transmuting to box and calling forget at the end. Ok. It just feels like a reference is more "the right thing" somehow. Could one perhaps transmute a reference to the pointer into a reference to the box instead, would that work and have the desired effect?
If you think of `ref` as destructuring in some way, it'll be confusing. Instead, it and `mut` modify bindings.
&gt; I'd move Box::new together with the unwind harness out of the unsafe block. Not sure what you mean by this, `unwind::try` is an unsafe function...? &gt; Then I thought transmute consumes the value, so you shouldn't need forget? You're right, thanks! Now that I look closely, the call to forget causes a lifetime error (use of moved value "a").
There's no reason you need to package every release of the compiler. Debian stable packages are often years out of date; a few six-week cycles won't even register. If you're a Rust developer and want the latest and greatest, you'll be using Cargo anyway.
That is helpful. Thanks. I think it would be good idea to list those good examples somewhere along with *rust by example*
This is true and is something I thought a bit curious when I implemented the position related code (using parsec as a guide). I suppose that parsing is done almost exclusively on char streams which makes it such a rare occurrence to need something else for a position type that it never seemed like an issue. I may need to think about how to go about changing this though since I'd rather not make it more complex to work with the common case. EDIT: It might be possible to do this quite easily though to do it without affecting the Stream trait it is necessary to have where bounds on associated types which isn't implemented yet or so it seems. trait Positioner { type Position; fn update(&amp;self, position: &amp;mut Self::Position); } impl Positioner for char { type Position = SourcePosition; fn update(&amp;self, position: &amp;mut SourcePosition) { //code for update } } pub trait Parser { type Input: Stream where &lt;Input as Stream&gt;::Item: Positioner; } Adding the bounds on the Stream::Item type inside the Stream trait instead forces the knowledge of 'Positioner' on the Stream which is not strictly necessary though at least it works for a bit further until we run into an ICE when compiling.
They do allow Rubygems, though, so that's not a super strict policy.
Only one version per gem though.
No, I mean that you can install and use Rubygems to grab whatever you want from rubygems.org. The only thing they do is patch it to remove `gem update --system`, though they may even allow that now too. (EDIT: it looks like they do, it used to print a 'sorry nope' message but now starts installing stuff)
This has to be included in the docs. Nice explanation!
I'm working on an LLVM AVR backend currently, link [here]( https://github.com/dylanmckay/avr-llvm). It is forked from the repository that /u/DroidLogician linked earlier in this thread. I have added machine code outputting support, and an assembly code parser is in the works. I also have a fork of Rust which uses AVR LLVM to support the output of AVR ELF files [here](https://github.com/dylanmckay/avr-rust). Contributors very welcome! EDIT: fixed link
`#debian-mentors` I realize that the people there don't represent the opinions of everyone; I just wanted to get a discussion going.
There's a style guide point here as well. It may just be me, but I find this pair: let mut x = &amp;y; let z = &amp;mut y; Much easier to read and reason about than: let mut ref x = y; let ref mut z = y; There's something deeply unsettling about the order of modifiers on the LHS completely changing what is going on with respect to the RHS. 
It says you cannot nest try-catch blocks, so I guess if the call stack trying to construct the plugin has another `unwind::try` up there, there'd be trouble. What you are saying about panics in callbacks is alarming, and the FFI chapter in the Rust book does not have anything on this. I should do some testing of my own...
We're doomed to fail~! Panic! Panic!
The reason we might want rust packages in debian is if you want to include an application in Debian that is built with Rust. The difference in installation ease for a user is this. Scenario 1: sudo apt-get install rust cargo git git clone git://example.com/myapp.git cd myapp cargo build &amp;&amp; sudo cargo install Scenario 2: sudo apt-get install myapp Obviously scenario 2 is better.
If you have a `Cargo.lock`, and your dependencies exist (possilby through a `cargo fetch`), then Cargo does not make an HTTP request during a build. And what would HKT have to do with Cargo?
I wasn't aware of that part of the policy.
Oh I agree 100%. That should totally be possible, except for the comment you said elsewhere about no dependencies in the same package. That's really unfortunate.
Thanks, I think it's a great idea to really call for comments.
Right. Details help. So using less just spits out the file, as if I used cat. Vi says that it's using open mode, then complains that open and visual mode must be used interactively. Nano claims that it recieved SIGHUP or SIGTERM. Emacs says that stadard input is not a tty (when run with -nw flag). Vim just hangs. All of these are just trying to read the readme I wrote for the shell. This is the code for executing arbitrary (not built-in) commands http://pastebin.com/9piGYvyJ 
It's rather frustrating. The only argument for it is the security one - that you don't want to have to update 100 apps if a single library gets a security fix. I'd personally like to see this policy lifted, but I don't think realistically that's going to happen. Every time I've brought it up in the past, I get many passionate responses as to why we need the policy as is.
I feel the same.
The interesting point here might be, whether Rust can be sensibly classified as a "safe subset of C++". I have never perceived it as such. Admittedly I can't think of much it adds in expressiveness, but there are certainly some restrictions. On the flip side, a lot of what is an awkward afterthought in C++ is well integrated in Rust.
To make this story a little more complete, we're actually looking at 4 combinations (mutability of binding * mutability of reference): let a = &amp;y; let b = &amp;mut y; let mut c = &amp;y; let mut d = &amp;mut y; Which if I'm not mistaken respectively correspond to: let ref a = y; let ref mut b = y; let mut ref c = y; // EDIT: as dbaupp pointed out below, let mut ref mut d = y; // these two lines aren't accepted by rustc I like how in the former style it's clear which `mut` applies to the binding and which applies to the reference. I think the style guide should definitely discourage the latter style and reserve `ref` bindings for "interior bindings" (I mean as in `let Foo(ref mut x) = getFoo();`). In fact, I would go as far as making use of `ref` on a top-level binding an error or warning, but that's generally the domain of a linter and I'm not sure to what extent rustc should act as a linter.
Cross-posted [here](http://www.reddit.com/r/rust_gamedev/comments/2trkw9/functional_reactive_event_handling/) as it probably is both of general interest to the Rust community and specifically to the gamedev people.
First off, you should read [this section](http://doc.rust-lang.org/book/crates-and-modules.html) of the Rust Book ("Crates and Modules") if you haven't already, as well as the [Cargo guide](http://doc.crates.io/guide.html). To start a project, first run `cargo new [library name]`. This will generate the following source tree for you to put your project in: [library name] ├── Cargo.toml └── src └── lib.rs All the code for your library you should put in `lib.rs`, making sure to export anything others outside of the project will want to use with the `pub` keyword. As for those naming conventions, it seems like you have a Java background. Rust does things a little bit differently. If I want to call my library `jsoup`, I don't have to call it `org.jsoup`, I can just call it `jsoup`. It is then simply imported with `extern crate jsoup;` to bring in the crate, and `use jsoup;`. Make sure to add it to your dependencies in cargo, too.
Counter-quote: &gt; C's big claim to fame and the reason Dennis Ritchie deserves the Turing Award was because he did something they said couldn't be done. He created a high level language that was portable, at high performance, leaving no room for a language lower than assembler. We can niggle about the C declaration syntax and other things that didn't work out so well, but it's really important to recognise that those are side experiments that were details in a much larger thing that he accomplished. Now, advance another decade. 1979 and early 1980s – Bjarne is working at Bell Labs on C++ and what he accomplished there was to take a systems programming language that was portable, with strong abstractive power especially with classes and templates. He proved that you could actually do a portable systems programming language with strong abstraction and strong typing. That was a major advance. I would love to see somebody tackle the challenge of demonstrating that you can create a portable systems language (meaning that it has performance equal to C, C++, Fortran) that is portable, type safe, and also memory safe. To add that on top of classes and templates and the portability of C, to add strong type safety (which requires a form of garbage collection) and not leave performance on the table – that would be something. That would be the first strong competition to C++ on its home turf. \- Herb Sutter
&gt; a portable systems language (meaning that it has performance equal to C, C++, Fortran) that is portable, type safe, and also memory safe. Sounds like Rust! When was this quote said?
I got the opposite impression. "There are things that you simply cannot add as an afterthought..."--but Rust's safety is *not* an afterthought, it was a key design goal.
I'm a bit confused – is using "move" keyword orthogonal to closure being Fn, FnMut or FnOnce? If I understood right, the latter is decided by the using this kind of annotation: |&amp;:| for Fn, |&amp;mut:| for FnMut and |:| for FnOnce. Then, what does move || correspond with? There seems to be two cases where a captured value is moved, copied or borrowed: when a closure is made (creating the struct with function pointer and the relevant environment) and when a closure is called. Did I understand right: move keyword means that a value is moved into the struct when a closure is CREATED. And Fn, FnMut and FnOnce decide how a value is moved/borrowed from the struct to the function body when a closure is CALLED?
Yeah, that's an important distinction. If you're for sure keeping the exact version of the compiler, then you can have an exact version of the libraries. FWIW, C++ gets away without having a really stable ABI, and it's not the greatest, but it does 'work' well enough. We might be able to do better.
I thoroughly agree. Memory safety is *the* key affordance differentiating Rust from C++, and Mozilla and the many, many other contributors simply would not have gone to the effort of creating a brand new programming language if they could have instead simply resolved the issueby defining an approved subset of C++.
 &gt; I think there may be some lingering unsafety if you try to reuse your Plugin struct after a panic, although I could be wrong. I don't think it would be unsafe in terms of memory unsafety, but certainly the Plugin could be in a very surprising/unexpected state if the panic happens in the middle of something.
&gt;`let ref mut x = y` is identical to `let x = &amp;mut y`. How do I read the former? In c++ the rule is "read from the right", i.e. " x is a mutable reference to [type]", but that is obviously, and confusingly, wrong here. Reading it from the left is hard: "[type] reference to mutable"? The latter makes sense reading from the left: "x is a reference to a mutable [y]"
Super cool! I wrote an FRP library in Ruby after watching a talk on Bacon.js, so I think this is a time honored tradition for FRP libraries, ha!
Would the stdin, stdout, and stderr methods for a Command help? I'd like to do as much as I can in Rust, but I'll try to interface with C if I have to.
But that's the whole gist of the quote: you *can't* define that safe subset in a way that is attractive, but have to start from scratch. -&gt; Rust
Oh, sorry. I should have checked first.
It's been moved to `rustc -Z unstable-options --pretty=expanded`
Here's a general question for people with knowledge on the stabilization process, will there be a defined ABI for Rust 1.0?
ARM, MSP430, non Arduino AVR systems, ATMEGAs I for one would love to see Rust or a subset of it on the Parallax Propeller (Could be cool with concurrency as it's an 8-core CPU)
Can't `lift!` be made to work like `println!` and take any number of arguments?
I'm gonna be in town, so as good an excuse as any :)
That works great, thanks! EDIT: The relevant change was in [#19964](https://github.com/rust-lang/rust/pull/19964).
I was really frustrated with the absolute garbage quality of the slides (and the whole presentation "center" itself), so I did some digging: [High quality slides (PDF, 896KB)](http://event.on24.com/event/91/63/72/rt/1/documents/resourceList1421777603222/programming_in_rust.pdf) [[Mirror]](https://dl.dropboxusercontent.com/u/854167/programming_in_rust/programming_in_rust.pdf) [Entire audio (128kbps WAV, 83.3MB)](http://event.on24.com/media/news/corporatevideo/events/91/63/72/rt/25982867.wav) [[Mirror]](https://dl.dropboxusercontent.com/u/854167/programming_in_rust/programming_in_rust.wav) [And here's the play time for each slide](http://pastie.org/9863962), if you can figure out what sort of timescale "ondemandoffset" is. The slide index is the "id" - 25920982. Good presentation though! &amp;nbsp; EDIT: [Correct (I think) slide times](http://pastie.org/9864268), thanks ipjk ... and thanks for the gold!
Great presentation! If anyone doesn't want to give their details to O'Reilly, you can put junk in all the fields and it'll let you watch.
Mega props, thank you!
(ondemandoffset / 1000) / 60 = time mark.
Is Scenario 2 possible if you statically link all your Rust dependencies?
Yep, you want to call the .stdin(), .stdout() and .stderr() methods with the InheritFd enum value. stdin should inherit fd 0, stdout gets 1 and stderr is 2 as per Unix tradition. 
Yes it's possible, but each static dependency still must be packaged as a separate Debian package.
Hey thanks for sharing, great stuff! I like that you focused on the specific filter example and kind of tailored it for your audience. Someone coming from C++ will see Rust in a different way than someone coming from Python or Java. 
Somewhat related: What is your experience with this pretty printer? The couple of times I tried it, it didn't result in code that looked that pretty to me (especially with functions that have many parameters including generic ones). At the same time I'm trying to stick to Rust conventions. So, for now: I do manual formatting.
Oh, that’s interesting. Just when I happen to be in town! *Signs up*
I just use it for debugging, not for actually formatting my code. Since my latest project involves a lot of macros, I find it useful looking at what a particular fragment expands to.
I like it. Personally I'm a bit more familiar with the ReactiveExtensions version, which has quite a few more functions that are really useful, such as scan, throttle, delay and more. See e.g. http://rxmarbles.com I've also used RxJS to make a (partial) TodoMVC implementation to test-drive it a bit, based on [Andre Staltz](http://staltz.com) Model-View-Intent blog post. You can see a better implementation in his [Cycle TodoMVC](https://github.com/staltz/todomvc-cycle/tree/master/js). Since I'm also mainly interested in game development for my hobby projects, I'm interested to hear your thoughts on where and how you want to apply FRP.
Thanks, the playlist is fixed. Actually I wanted it to 'show' the latest episodes on top, not to play from the latest episode - apparently that's not possible. Your note about the dev-compiler makes total sense - for some reason I was assuming they are on nightlies as well.
What does that mean concretely? Could it compile a standard Arduino program?
(shameless plug) You might be interested in [this RFC](https://github.com/rust-lang/rfcs/pull/742).
`--pretty=expanded` and `--pretty=typed` are not `rustfmt` (which doesn't exist yet, but hopefully will) ; not meant to be used for formatting code. They're tools for debugging macro expansions and types respectively.
&gt; Could it compile a standard Arduino program? No. Although, it is not too far from achieving this. There are three main problems that are blocking this. 1. **Assembly parser support is broken** Currently, in order to compile inline assembly or regular AVR assembly files, an assembly parser is used. The assembly parser is a very recent addition to the project, and as such, it is missing features and no doubt has a few bugs. 2. **Machine code support has a major bug** Generating plain text assembly files from LLVM IR is well supported. This however requires you to use an external assembler in order to actually generate an executable. The machine code generator has not been tested much (it's very hard to test without an assembly parser, which only recently landed). The biggest bug I have found is documented [here](https://github.com/dylanmckay/avr-llvm/issues/25). The `LD` and `ST` instructions are nontrivial to implement, and I have not yet been able to fix it. 3. **Instruction support** Currently, only a [very useful] subset of the ISR is implemented (see a list of supported instructions - [AVR_SUPPORT.md](https://github.com/dylanmckay/avr-llvm/blob/avr-support/AVR_SUPPORT.md)). This is enough so that all LLVM IR is able to be lowered into real AVR instructions. The only exceptions are the instructions which are only possible using inline assembly (LLVM IR has no concept of interrupts or watchdog timers). Attempting to compile an Arduino project using AVR-LLVM (assuming the two aforementioned issues were fixed) would likely lead to unknown instructions errors - the Arduino libraries would make use of `cli`/`sei`/`break`/etc. Currently, these unsupported instructions are marked "not implemented" in AVR_SUPPORT.md. This problem would be the easiest to solve of all, because all of the unimplemented instructions either: * do not require pattern matching for lowering from LLVM IR * have simple binary encodings * are derived from a common base instruction format, such as the BRHC, BRIE, etc branching instructions, so would only require a few (10 maximum) lines of boilerplate code to be fully supported You can currently compile a basic LED blinking program, although the resulting binary will be slightly broken as to be unusable (only due to problem #2). For such a simple program, problems #1 and #2 do not come into play, in fact, they are only problems if you plan on using inline assembly. EDIT: fixed formatting
Interesting, I think most of these could be implemented eventually using the primitives provided. For example, `scan` is just `accumulate` + `updates` or you can build it directly using a stream loop (coming soon). Judging from the examples, Rx events might have a built-in notion of time, which Sodium and thus Carboxyl avoids. This makes things such as throttle easier, of course. The rationale behind the Sodium approach is, that time is just a cell like any other. This avoids dealing with time, when you don't need it, and gives you a certain flexibility as to how you deal with time. But then you have to explicitly snapshot time with a stream to allow stuff like `throttle`. Nonetheless, there certainly is some bikeshedding due, as to which higher-level functions to include in the library. Concrete API suggestions are very welcome! ;)
really!? It wouldn't give me the cargo command. maybe its the nevironment variables
Another quote from the interview: "... It is particularly ironical that languages with fixed structural patterns for statements and data types, and with constructs for modularization and information hiding, are widely regarded as restrictive, cumbersome, and creativity-hindering. Indeed, programming with a structured, strongly typed language usually requires a greater amount of careful deliberation, and this is considered as detrimental (remember that programming is advertised as being easy). The irony of the matter is that the time gained by not having been required to comply with structural rules, is lost many times over by finding errors later on - in the field, perhaps by the dissatisfied customer... "
There's an option while installing to add the installed binaries (including `cargo`, presumably) to the `PATH`.
https://crates.io/crates/encoding can do ISO-8859-1 and a lot more.
This post inspired [this other post](https://www.reddit.com/r/programming/comments/2tt72b/main_is_usually_a_function_so_then_when_is_it_not/).
Yes, Rx events are timed. Definitely interesting that Sodium/Carboxyl events aren't, but for a lot of use cases I would think time is very useful to have. I'll keep watching this library, as I'm definitely interested in where you're going with this.
Thanks for the reply. &gt; There is no unsafe code in Carboxyl, so ref-counting definitely works. I'm sorry, I expressed myself bad. I was asking because reference counting is a problem when there are mutual references (`A` contains a reference to `B`, and vice versa; both objects will never be released). If a sink cannot contain a reference to another sink, I guess that there should no problem. 
OK. This is what we use. I wonder if there are other options.
What is your concern with Encoding? I'd like to hear about that. Also, as far as I'm aware there is no alternative character encoding implementation, mainly because it is very cumbersome to make one. There might be rust-iconv though (I cannot recall if there were).
I just tried to use VisualRust from the AppVeyor build, but I cannot find the rust project templates. Are they missing or did I miss something?
No, it casts each byte to `char` then (implicitly) pushes it as a UTF-8 sequence. This exploits that the first 256 characters of Unicode are equivalent to ISO 8859-1, and is loseless.
I'm most of the way through the first one, but I can already say you've done a fantastic job with this. Your pacing and editing is good, and you've got a great voice for this sort of thing. I like the train-of-thought/process explanations a lot too. About the iterator/counter/loop issue - if you're using `map` to run some effects on each element, a for loop is the way to go.
They showed up for me using yesterday's AppVeyor build. http://i.imgur.com/gpMb5qL.png Completion worked after I manually compiled the latest version of RACER and set a RUST_SRC_PATH environment variable. If the project types aren't showing up for you, I'm probably not the person to ask, sorry.
I got to keep leftovers as a reward for a good talk. :-)
I am glad you like it ! Especially that it's so obvious what kind of style I am trying to achieve here. After all, my role models are Scott Manley and Northernlion - they made me want to do this kind of thing myself with topics that I believe I can talk about. Episode 3 is in the making, and I have beefed up the sound quality even more. Episode 1 and 2 have been audio-monitored with my TV-set, which turned out to hide all the echo and reverb that's still going on in there. Now my monitor is a closed headset, and thanks to extreme proximity to the pop-filter and lower audio gains there is much less room for disturbances. In other words, now it sounds good even with headphones on. About map and iterators: Yes, I believe so too, this is the first real-world code I am handling and sometimes, I am misguided with some features and *when* to use them.
They're good for anything really. Especially things where you often have to behave deterministically, like in an EKG machine :0, or video game client. alloc (or free, depending on your which allocator you use) is often one of the most expensive calls you can make. In addition, it is a call that gets slower the more you use it, due to virtual memory fragmentation. Using the Arena allocator, you can alloc 100 of a data structure at a time, then when they're all used, free the arena and allocate 100 more. It could also be used in conjunction with a free-list, so you allocate a bunch of your data structures, and implement Drop to put the data structure back in the list to be used again. 
I'm *really* bad at benchmarking (it's ~2x faster...).
No, NUL characters are permitted in Rust strings, as they are in Unicode text.
Ah, I see. What would be the difference with using `Vec::with_capacity` at the beginning? Is it because the `Arena` allocates space for storing all of them contiguously?
Cool! Do you know of a software that is able to play back slides with an audio track like that?
During the talk, someone asked why the loop { } construct is built-in, when while true { } seems to be just as good. I said I didn't really know; aesthetics? But it turns out there's a really good reason for this! A loop { } expression has no outgoing control flow graph edges, unless you add a break statement somewhere. Suppose you have a function like this: fn f(...) -&gt; T { loop { ... return E; ... } } with no break statements in that loop. This loop does exit, via the return, but the loop expression itself never produces a value, and thus doesn't influence type inference. This means that only E needs to have the return type T. If we had instead written: fn f(...) -&gt; T { while true { ... return E; ... } } then T would need to be (), or else we'd get an error complaining that the type of the 'while' loop doesn't match that of the function. Naturally, the compiler could treat 'while true' specially; but that's pretty gross. So the upshot is: if you're going to be an expression-oriented language, you end up imputing types to things that used to be statements, like 'if' and 'while' structures; and then never yielding a value at all becomes something that's worth making explicit. (Thanks to Graydon Hoare for explaining this to me.)
Will do my best to get into the flow. For episode 3, I had to spend 2.5h to cut 40m of raw material into 10m of polished output. It's fun, even though I hope to improve that ratio to one day finish the quest :) ! After all, it's part of something much bigger and I wonder if such a format is maintainable. For example, I would aim for 8h of programming a day and about 3h of cutting/storytelling. Recording 8h in 1080p@60fps means 20GB per day, and of course much more material to work through. And that's just some of the logistics behind that. But of course I am optimistic about it all, as I am just a beginner and certain patterns will evolve over time to make all this much more feasible than it appears to be now.
Try /r/playrust
But how will you know what the last byte in a stream is? Is there a different end-of-file symbol?
Thanks for the explanation!
Yeah! I understood it now. All ISO-8859-1 related characters are 1:1 mapped into unicode codepoints so there is "just" the fact that the UTF-8 encoding is using multi-byte encoding for them which makes the difference "bytewise" between both representations.
I just had the feeling that there must be something easier and there is, considering: println!("{:?}", (196u8 as char).to_string().as_bytes()); println!("{}",'Ä' == 196u8 as char)
You can look at `src/test/bench/shootout-binarytrees.rs` in the rust repo for an exemple.
Ok, so I've gotten far enough that I can call gpgme functions. \o/ Any chance you could point me towards an example or two (say, another c wrapper) that does wrap pointers in structs and implement `Drop`? My understanding of what that means is kinda vague, so any help would be very useful.
Have you tried debugging, how is that?
It's not implemented yet. Supposedly [cv2pdb](https://github.com/rainers/cv2pdb) can be used but I haven't tried it.
Ah, I've been thinking of the Java's "modified UTF-8" then! Never using the 0 byte has been a useful property.
It's not about the unicode character, it's about the UTF-8 byte! Some systems (notably Java) use the "modified UTF-8" encoding which never produces a '\x00' byte. So strlen over "\u0000" would return 2 instead of 0 on such systems. It has been a useful property in my experience.
Please do!
Episode 3 is marked as private? In any case, these videos are awesome, keep it up!
[Here's a wrapper I wrote myself for Freedesktop Fontconfig][1], a utility on some Linux distros provided for searching for font files. I haven't looked at GPGME's API but basically if it ever does any allocating, or requires a `*mut *mut T` to return a pointer in, then it's going to have associated functions for deallocating or decrementing the refcount on the pointed-to struct. Fontconfig's API does this with `FcPattern`: * `FcPatternCreate() -&gt; *mut FcPattern` * `FcPatternReference(*mut FcPattern)` * `FcPatternDestroy(*mut FcPattern)` `*mut FcPattern` is just a pointer to a ref-counted heap allocation. `FcPatternCreate()` allocates a new struct on the heap and sets its refcount to 1 (how you get an `FcPattern` instance in the first place), then `FcPatternReference()` increments the refcount and `FcPatternDestroy()` decrements it then deallocates when it is 0. This is necessary to not leak memory. I wrapped this in the `Pattern` struct which I implemented `Drop` for. All it does is call `FcPatternDestroy()` on the pointer it contains, since that's the only type that needs manual cleanup work. It actually isn't working right now as I was spending a lot of time last night trying to debug segfaults that weren't even occurring in my code. I wasn't making any headway so I decided to move on to another project. [1]: https://github.com/cybergeek94/fontconfig-rs/blob/master/src/lib.rs
&gt; "modified UTF8" :cry:
There's my comment with likely cause and potential fix in the [linked issue](https://github.com/PistonDevelopers/VisualRust/issues/4#issuecomment-59541891). If you tried it it and you still have this problem open a new issue.
What I heard in my mind when I read the title: "Billy Mays here with Oxischeme!"
There's already a [project to write libc in Rust](https://github.com/mahkoh/rlibc). It's not near complete, but something like this could be a realistic possibility for legacy C code in the future. A Rust libc could improve security and reliability in a number of ways, even if the interfaces to application code are the unsafe libc APIs. We could also augment those APIs with safer alternatives. `asprintf` is a classic example but there are lots of other things you could improve. It would be great to have an array-slice type with bounds-checked slicing, a struct wrapper for owned vectors, etc. Even without lifetime checking, a nice set of abstractions goes a long way for safety. Why not code in Rust instead? Well, I probably *would*, but I'm always interested in ways to incrementally bring some of the safety benefits of Rust to existing codebases. tbh just rewriting glibc in C again would probably produce a vastly saner result. But it has plenty of competitors in the C realm already.
&gt; I'm always interested in ways to incrementally bring some of the safety benefits of Rust to existing codebases I find this possibility quite interesting as well. The fact that Rust doesn't need to be all-or-nothing is a very strong pro. It will be exciting to see libraries written in Rust landing on Gecko, for example.
There's one thing I just realized: by chance, this is a deprecated function that people shouldn't be using anymore (and `libstd` isn't). But had it been something else (like [getaddrinfo](https://github.com/rust-lang/rust/blob/master/src/libstd/sys/common/net.rs#L223-L228)), even Rust programs could have been affected by this vulnerability. Since the Rust standard library defers many things to the system's libc, we aren't isolated from these problems, even if the Rust layer itself is safe (unless rlibc or something like it becomes mature enough that Rust programs start using it instead of the system's libc).
I keep getting this issue too,, though using `multirust update nightly` works for me (I'm using Multirust). Updating cargo seems to be what's required.
If we get to that point then I think libstd IO, allocation, etc. shouldn't go through the libc interfaces at all. You'd still have the `libc` crate when you need it.
Getting a 404 for "Replace most of the collections API with ranges and iterators. Gankro has a crazy far future idea." Does anyone have the link? 
Oops...
I have a question. I am pretty much completely new to rust, but I have been attempting to make a parser which will parse sums of integers and return their result. For example: "1 + 2 + 5" should become 8. I have written [this](https://gist.github.com/avwhite/94a76e0718f095d5cfdc) code. It outputs: Parse error at line: 1, column: 12 End of input Which seems weird to me. Shouldn't `chainl1` just stop when there is no more input? Also, general comments on the code is appreciated.
That's certainly not true. Source: used to censor my mailing lists
It got moved to crates.io: https://crates.io/crates/num
I'm not sure who to flag about this, so I'll just comment here. Would it be possible to rewrite `discuss.rust-lang.org` to `internals.rust-lang.org` as a server-side rule?
Rust by itself does not need gcc (but some 3rd-party libraries will need it for compiling C codes). It comes with a stripped-down version of gcc for linking, so it likely is a conflict between multiple gcc commands available. Try to remove *any* installation of MinGW first, including those bundled in other programs (e.g. GHC). If you can edit the environment variables, you can instead try to remove any suspect directories from `PATH`. (Also, the error message actually means that you have gcc available anyway. It naturally accepts a source code or object file as an argument, so it indeed is a fatal error when there are no arguments.)
The plan is to reuse `discuss.rust-lang.org` and set up a new discourse instance there for discussions about *using* (not *developing*) Rust. So I think a redirection is not happening. (That will defeat the purpose of the renaming.)
Okay, that really explains the problem... (That's why we need exact error messages :) You have GLFW3 external library not yet installed. ("cannot find -lglfw3") [Download and install pre-compiled binaries first](http://www.glfw.org/download.html).
thanks, I downloaded the preinstalled binaries into the C: . then i put the dlls in syswow and systems32. i also put the stuff from include in minigw include. lib in minigw libs and same error. think you can hold my hand a little longer. :/
Just noticed this myself. I guess I should start using the AUR packages now?
Answered: http://stackoverflow.com/questions/28183497/gcc-exe-cannot-find-lglfw3-when-using-glfw-rs/28184100#28184100
/u/bwicesoldier was getting these packages from thestinger's personal repo (not the AUR) (myself as well), but how they're gone from both. Would someone be willing to adopt the AUR package? 
Thanks so much!
How would `asprintf` be implemented in Rust, considering that as far as I'm aware, there isn't a standard way to allocate and safely detect allocation failure? Just panic on allocation failure instead?
That package was the one that was in [community]. The nightly builds were based on a modified version of the package from [community] fetching from master instead.
=/ Thanks for checking. It would be real nice to have that passed in because then we can use it within the program without defining it twice, once in manifest and again in the source code.
&gt; to add strong type safety (which requires a form of garbage collection) I am just curious here, why does strong type safety require garbage collection? Anybody know?
You can either use the official nightly builds via an AUR package or do your own builds via the `rust-git` package or the one I removed from that unofficial Arch packages repository. It just won't have the convenience of daily updates through the package manager. The official builds also have a significantly larger download and installation size along with using against an old glibc ABI and not installing stuff like Vim support. I'm not interested in investing any more time in Rust, so these had to go because they keep needing maintenance.
Here is an example of using rust FFI to make an extension to ruby that optimizes a scoring algorithm: https://github.com/hjr3/selecta/blob/rust/score/score.rs
Is it possible to add some punctuation to titles of "This week"? I keep reading "Rust 67" as a toponym :-)
I maintain an AUR package with the nightlies that auto-updates every day - handy for use with version tracking AUR helpers like Aura and Yaourt. https://aur.archlinux.org/packages/rust-nightly-bin The updating is just every 24 hours, but I find it works well enough (improvements welcome).
Yep that is a bug in the library. It appears that if the many parser receives an input that was marked as consumed it will itself also act as being consumed which means that your 'plus' parser fails (the chainl1 parser only returns Ok when the operator parsing fails without consuming). I have a quick and dirty fix for this particular case but I think I might have a solution for all cases, just need to give a bit of thought so I don't miss an edge case.
edit: snipped paragraph for /u/strncat's pseudonymity. IIRC rust playpen and the alternative standard lib that was suitable for low level applications were also his creations and he wrote/rewrote a big chunk of the compiler as well as pointing out a lot of technical mistakes the core team have made or were about to make. I guess he's burnt out fighting for things he sees as clear-cut, but you should probably ask him.
You can also try https://github.com/thestinger/rust-gmp as a fast alternative 
I'm sad to see you leave, /u/strncat.
Among other things, he pushed for external iterators (current Iterator trait) instead of internal iterators. [Rust #5810](https://github.com/rust-lang/rust/pull/5810). I think this is an extremely important contribution that all Rust users should be grateful for.
I didn't call it that. Jurily did.
Don't think he ever got a friend of the tree either. The politics has always seemed little strange. Tis a big blow to the project if he leaves entirely :(
`Arena` and `TypedArena` offer the fastest way to "dynamically" allocate and deallocate memory (except using the stack, but that only works if all allocations are "static", i.e. known beforehand).
Hey, I've seen it! Would be nice to have a method getting a "Modified UTF-8" C string out of the Rust UTF-8 str, in case one needs to pass a UTF-8 string into a `const char*`. Do you plan having such a method in your lib? Also, I have found no easy way to `malloc` a C string with your lib (use case would be returning a `malloc`-ed string from a `#[no_mangle] pub extern fn` Rust function).
I just looked at it and most of the implementations are marked as unsafe. I'm not well versed in rust yet to get much closer to it than that, but wouldn't that kind of beat the purpose? If not, why?
[It sucks](http://www.w3.org/Provider/Style/URI.html) that all these links are broken. Please consider making the old domain a redirect, even if it means you have to pick a new name for the non-internal forum.
He is most likely. The core devs and him doesn’t get along, and because of earlier disagreements that they took personally they’re passive-aggressively interfering with his contributions, which in effect helps to sabotage Rust. I just wish he (eventually) decides to actually fork the language, but I fear he won’t.
Nice write-up. It's good to see Glium develop that quickly. :)
Thanks. That sounds good.
It's not very common for C libraries to work meaningfully with "Modified UTF-8", Note that it is not valid UTF-8, so C libraries that expect valid UTF-8 sans the NUL character will not work with all CESU-8 strings. If you actually need it for e.g. interfacing with JNI, you may want to try https://crates.io/crates/cesu8 I saw no need to facilitate allocation of new C strings on the Rust side. In any case, it's trivial enough to do with `libc::malloc`; to get RAII, you can wrap the result with `c_string::OwnedCString::new(ptr, c_string::LibcDestroy)`. Feel free to file wishlist issues at the GitHub repository.
For your Travisci problems you should check out circleci they have 16gb of ram
That's pretty damn impressive! Next time I play with GL, I'll definitely give it a spin. One thing I'm curious about: do you know why it's taking so long to compile? Is it just a case of Rust being slow to compile, or is Glium doing something really weird? I'm just curious from a "trying to get a sense for how Rust compile times scale with complexity" standpoint. :)
Why `discuss` and not `forum.rust-lang.org`?
POSIX doesn't care the slightest about `/usr/lib`. &gt; A description of the historical /usr/tmp was omitted, removing any concept of differences in emphasis between the / and /usr directories. The descriptions of /bin, /usr/bin, /lib, and /usr/lib were omitted because they are not useful for applications. In an early draft, a distinction was made between system and application directory usage, but this was not found to be useful. Please go troll somewhere else.
Why the hostility?
no, i do use the github version but i've tried both. i will check again on my computer as i'm currently commuting. i've never used any flags
That would be it then, thanks for clearning that one up. There _has_ been a weird tension at least since I started following the mailing list I distinctly remember a post /u/strncat made advocating the use of native threads and getting rid of the dependency on libuv somewhere around 0.5 or 0.6... It's unfortunate when personalities and goals clash. edit: libuv not libusb, it's weird when work leaks into my redditing...
The first extra slide after "The End" scared me a little bit: enum IntOrString { I(isize), S(String) } #[test] fn corrupt_enum() { let mut s = IntOrString::S(String::new()); match s { IntOrString::I(_) =&gt; (), IntOrString::S(ref p) =&gt; { s = IntOrString::I(0xdeadbeefis); // Now p is a &amp;String, pointing at memory // that is an int of our choosing! } } } I had to go compile that to make sure, but that comment was just a hypothetical "corruption" that would be the case if the borrow checker wasn't doing it's job. But it does :) src/main.rs|11 col 17 error| cannot assign to `s` because it is borrowed src/main.rs|10 col 28 n| borrow of `s` occurs here 
I've been using these for quite a while, thanks! However, it isn't clear from the package description whether this contains Cargo or not. E.g. ``rust`` from the official repos doesn't AFAIK.
I don't know, maybe it's me, but I read anger in his comments throughout this thread. I want to know why. Comment like "It's still good for teaching Rubyists about C++." come off as trolling, but I remember his user name and for me that means that he generally contribute good posts (otherwise I wouldn't remember him).
Just uploaded the fix for this (both to github and crates.io). The fix was rather involved but it should make sure it never reappears as well.
okay, so i created a new cargo project to try glium out and i'm using the github version. when compiling cargo says that it compiles image and stuff, and it compiles fine, but glium doesn't detect that image is enabled. i'm using the 'image' example from your repo too. [Cargo.toml](http://pastebin.com/VZheqFNc) if you want anything more please ask 
If you don't care about an extra copy, you could construct the string with `std::ffi::CString::from_slice`. Link `strdup` in an `extern "C"` block and pass it the `CString` buffer obtained with method `as_ptr` (the method is on the slice to which `CString` auto-derefs). This has the added benefit that it will _panic_ when there's an interior NUL in the input data. Which is a good thing, since input has to be validated against misinterpretation: there is any number of security vulnerabilities due to being able to inject NULs where they are tolerated and then pass the string to a C API which will see it truncated. If you don't like panics, `c_string::CStrBuf` offers nicer constructors returning `Result`. Do you need to pass the string allocated, so that its ownership is taken by a C library? That sounds like a strange API to work with. Note that the `free` used by a C library that will deallocate the string has to come from the same library that provides the `malloc` available to your Rust crate. This is not always the case, notably not on Windows.
That seems like a bad plan in light of all of the broken links. Any previous "this week in Rust", any RFC, any Reddit threads, any blog posts that reference older discussions will now be broken. Wouldn't it be possible to just pick another name for the user facing discussion, like "discussion", "forum", or "talk" (to throw out a few possible bikeshed colors) in order to leave the "discuss" redirect around and not lose a year or so worth of history?
&gt; That sounds like a strange API to work with. Not at all. That's a popular pattern in C land. &gt; Link strdup in an extern "C" block and pass it the CString buffer obtained with method as_ptr Thanks. &gt; In any case, it's trivial enough to do with libc::malloc I guess it's pointless to point out again that this is not "trivial".
The rush to 1.0 just gives way to poorer designs and less planned APIs, which is why I'd much rather have the fork done as early as possible to be honest.
&gt; they never really have any real arguments when asked about, for example, why f128 support was removed Support for `f128` was removed because it supposedly complicated the compiler implementation of float literals. This was clearly stated at the time.
It was stated but not substantiated last I checked, I'm still not sure what was the problem exactly (mainly because that discussion was not done in the open once more...). And more generally it's pretty rude to remove an active contributor's code without even a head's up and some explanations. It's not the end of the world but I can understand why strncat was annoyed (or anybody who actually used f128 in their code).
Which of these points from the meeting notes is false? "acrichto: We support enough to tell LLVM that a variable is an f128. You might be able to have a literal for it, but certainly not in the entire range f128 supports. You can't print it. The support for it is so small. It's getting to the point where the burden of having f128 is more than the benefit of having it."
Thanks for explaining your rationale. This makes sense. I bring it up only because I want to see Glium succeed! :) Some food for thought, have you considered exposing a thread safe (Send) and non thread-safe implementation? The user could be able to opt out of thread synchronization by using the builder, I think. Something like: .with_no_synchronization() .build_glium(); I clearly haven't thought through this as much as you have, so I'm curious if you think this is possible. Unfortunately I just know 100% that there will be developers who see the mandatory synchronization and abandon the library immediately. Especially if they went to use it on an embedded platform (Rasberry-pi only has one core, for example). I think an opt-out flag when building the context would be ideal.
Probably not the best place to restart this discussion but those are not very good arguments IMO. If the issue had been raised prior to the removal somebody might have stepped up to add the missing features (adding printing and literal support doesn't sound tremendously difficult to me but I might be wrong). Also, it still doesn't tell us what this "burden" was. That's the key point IMO. I don't even care for f128 myself, it's just an example of the core devs taking controversial decisions without even taking the time to explain them. Maybe they had a very good case for the removal of f128 but for some reason they refused to state it and it creates tensions in the community. I think things have improved since then though, that type of change would probably go through an RFC now. That being said the RFC acceptance procedure is still very opaque in my opinion, some of them get fast tracked with very little discussion while others receive massive community support and linger for ages in a pull request with little attention from the core devs.
Whether a struct implements `Send` or not is determined at compile-time, so you can't do what you suggested. The only way to make this correctly is either to duplicate most structs in glium (one thread-safe version and one thread-unsafe version, like Arc and Rc), or to add a template parameter to them. The non-thread-safe versions still wouldn't be safe, though, as two windows in the same thread would conflict.
Saying that "they never really have any *real* arguments" is not conducive to discussion. You are free to disagree with their arguments, but please do not pretend that language changes are the result of random dice rolls. It is true that the removal of `f128` was dreadfully mishandled. I myself went completely ballistic at the core devs and removed myself from language development for several months. The entire fiasco was predicated on the notion that experimental features were immune from the need for RFCs, which effectively meant that the core developers could destroy various features at any moment without discussion. It was not intentional malice, but it very much was uncharacteristically exclusionary for a language whose development is as open as Rust's. As a result of our ruckus, policies were enacted that made the developers no longer immune to the need to submit RFCs to tinker with experimental features. Furthermore, the core team has been gradually expanding to include a greater proportion of non-Mozilla employees (it should be a surprise to nobody that Mozilla currently happens to employ the world's largest concentration of Rust experts, making their original domination of the core team entirely natural). Given both their willingness to change policies based on community feedback and their continued effort to dilute Mozilla's influence, your vote of no confidence in the current leadership is entirely premature.
Yes the warnings he gave about M:N threading being a dead end were very prescient, in retrospect.
They are great, thanks!
Is it possible to avoid link breakage? Or otherwise inform Google that it moved. edit: actually this is discussed [there](http://internals.rust-lang.org/t/please-don-t-break-existing-discuss-rust-lang-org-urls/1470), I think the 301 redirect is excellent (but may be hard if Discourse doesn't support it). Perhaps it would be better to not reuse http://discuss.rust-lang.org for another forum (but use something else like http://help.rust-lang.org or http://forum.rust-lang.org), even though it's a very nice URL. Another minor thing, there are "discuss.rust-lang.org" references scattered through the site, such as in the [TOS](http://internals.rust-lang.org/tos), suggesting that Discourse internally still thinks the site name is discuss.rust-lang.org. (also, it's a bit odd that the [FAQ](http://internals.rust-lang.org/faq) is a Discourse generic faq, not related to Rust)
It's very fun to watch your videos &gt; .. and look at that, it actually works, amazing! Well, let's define "works". Haha
&gt; Also, it still doesn't tell us what this "burden" was. That's the key point IMO. Every compiler feature that we support has a maintenance burden. It increases our LLVM and runtime dependencies, we have to keep the translation code up to date, we have to keep the parsing code up to date, and so forth. The Rust compiler is *not* a stable compiler; if you've ever worked on the Rust compiler, you know that patches bitrot almost instantaneously from the massive amount of compiler churn that happens all the time, so every feature requires constant maintenance. We have to draw the line somewhere. Removing features is important to keep the project from growing without limit. Every project does this: Firefox has removed countless features over the years, LLVM removed some very useful functionality like the C backend (and has a policy of aggressively removing backends that do not get enough maintenance). Some languages, like Go, are so wary of feature creep that they basically never add any new language features; Rust is not as conservative, but we've all been aware since day one of the dangers of having a language that's the union of all features, and we've made sure to remove features aggressively where appropriate. It's nothing personal and it never has been; it's unfortunate that accusations of personal malice fly so freely in Rust. The number of features that I wrote that have been removed from Rust probably outnumber the features that are still in with all the type/trait matching system rewrites. But I'm not offended by it; that's how software works. &gt; That being said the RFC acceptance procedure is still very opaque in my opinion, some of them get fast tracked with very little discussion while others receive massive community support and linger for ages in a pull request with little attention from the core devs. I don't see that happening anymore, with the "shepherd" process. That's what the process was designed to counteract.
&gt; Whether a struct implements Send or not is determined at compile-time But if I'm developing a Rust app that depends on Glium I could enable or disable optional features through Cargo, right? Which trigger a recompilation, but it's okay.
&gt; He only really has that mentality because of a lot of his work and what he says is ignored by the core devs though I wonder if that has something to do with him repeatedly treating those core devs like shit. If I treated Brian and Patrick that way, I would get fucking fired. Only in open source software is it considered unfair to give someone less time and attention because they're impossible to work with.
&gt; To be fair while strncat is extremely competent and knowledgeable he can also be very aggressive during technical discussions. He has that "torvalds" mentality, for better of worse. That can be off putting unfortunately, even if sometimes it gets shit done. Other times it poisons the discussion to the point that nobody is willing to get back to it by fear of getting "flamed to death". We have made it clear for a long time that people like that are not welcome in the Rust community, no matter how strong their technical contributions. I'm not sure why strcat is now complaining about selective CoC enforcement because he's surely benefited more than anyone. Even if strcat does the work of 50 "ordinary" contributors, it's not hard to imagine him alienating at least that many if he's running the show. And that's not counting the constant drain on morale for the people who *do* put up with him. You can look at what's happening to the Linux kernel. They're failing to attract contributors from the younger generation of developers because their project is known for verbal abuse and antiquated patch workflows. I'd be happy to see a strcat fork of the Rust community. It would be very attractive to the people I don't want in *my* community.
Yeah, that is 100% my observation as well. I mean, he's landed over 700 patches to Rust. All the same I think his abrasive style sabotages his own technical arguments, and this may contribute to the core team not siding with him as often as he'd like. I think that's completely fair. In a technical discussion it is *your* responsibility to present your views in a respectful way. If you fail to do so, and your ideas aren't adopted, that failure of technical communication is on *you*. Almost everyone involved with Rust understands this. Almost everyone I've worked with in my software career understands this. It's kind of a basic part of how people work together in the world to build amazing stuff. Some OSS projects operate by the opposite rules, but it's clearly not the only model for a successful project, and it's clearly not the one Rust will take.
All the discussion that happened is in the meeting notes. All of it. I was there. It's also the case that the meeting notes are a somewhat shorthand form, it's hard to transcribe verbal meetings in realtime (I took those notes).
Since time immemorial, Rust has been an idealistic language whose philosophy could be best summarized as "you can have your cake and eat it, too!" To an observer of modern Rust it may seem obvious that it would be possible to make a memory-safe language that was as fast as C++, but in the early days of Rust they had no idea how they were ever going to achieve that. Early designs envisioned pervasive garbage collection that would have put Rust more on the level of D or Nimrod. The fact that they stumbled onto the borrow checker was just a serendipitous effect of Niko's involvement in the project, and it would be years before they concluded that the borrow checker was powerful enough to do away with the planned GC entirely. I must reiterate this: the borrow checker began not only as a long-shot experiment, but an experiment that Graydon himself did not necessarily believe would bear fruit (to be clear, Graydon was aware of region analysis from the literature but doubted that we could design a simplified system whose ergonomics would be accepted by typical programmers (and he may even have been correct, given the evident difficulty of explaining Rust's modern lifetime system :P )). For a long time this attitude of boundless idealism was the rule, not the exception, and was applied to other areas of the language. The most obvious examples of the failure of this philosophy involve internal iterators, split stacks, and libgreen, which were all things that strcat (being notably more pragmatic than idealistic, and having a concrete vision in his head of what Rust ought to be) campaigned against. But I'm not going to fault the Rust devs for trying to both have their cake and eat it, given that in at least one area--the borrow checker--this philosophy has produced a system that few thought was feasible. Rust straddles the line between an industrial language and an academic one, but the fact that the developers are willing to acknowledge the failures of idealistic features in favor of more mundane ones shows that Rust ultimately teeters towards the former. Note also that there are other areas today where Rust still exhibits the cake-eating philosophy, such as the trait system's insistence on both instance coherence and implicit typeclass selection. I've seen at least a few academics who are predicting doom-and-gloom over this particular decision. :)
It doesn't look like rust is in the official Arch repos anymore (probably won't be until 1.0). The old packages likely didn't include cargo because the official rust distribution didn't until rather recently IIRC. rust-nightly-bin does include it (again, likely because it's in the official rust distro now).
&gt; I feel that if you didn't want to support f128 in the core team you could maybe have asked if somebody in the community wanted to do it? How does that work with a core compiler feature? What happens when a core team member fixes a bug, but in the process breaks f128, and the person who's responsible for it can't be found? If there's some way to implement it in a crates.io library, that's a totally different story. That's why I'm so interested in compiler plugins. It's a meta-feature that makes the language a lot more flexible, while keeping that complexity out-of-tree. &gt; Not to mention the amusing conspiracy theories about Mozilla. Yeah, I find those pretty absurd, as a Mozilla employee who's been through the protracted RFC process several times, for features I was going to implement or already had implemented.
Link to project https://github.com/fitzgen/oxischeme
&gt; You can look at what's happening to the Linux kernel. They're failing to attract contributors from the younger generation of developers because their project is known for verbal abuse... I'm not so sure about that. It's pretty common knowledge that Linus will only get angry at people making mistakes that he feels they shouldn't be making - and that means you need to be a very experienced contributor with a fair bit of responsibility. I don't think the risk of a Linus-flame is putting too many people off. The antiquated workflow certainly could though.
"rude" is a quite mild and generous summary of strcat's attitude towards the Rust project, going back some months if not years. When you treat people that way, this kind of outcome can't be a surprise. Quoting him from a recent RFC thread: &gt; I respect people as a default but it can be lost, as is the case here. The example set [...] is that everything is personal. If you think there is a larger pattern of mistreating former contributors to Rust then I'd be very concerned, but I haven't seen it. Most people seem to leave the project on friendly terms.
How about having a single `Send` but not `Sync` context type that can only be constructed by the means of a global lock? You could then make sure only one thread has access to the OpenGl functions at a time.
I'm nohow related to Rust, not a developer, nor programmer, I'm jut observing this project, from what I read here, just wanted to say thank you for your work!
&gt; https://crates.io/crates/cesu8 I'm the author of the `cesu8` crate. Right now, it handles strict CESU-8, and not Java's special extension for `\u{0000}`. But I'm happy to add APIs to handle Java strings and other special cases, as described in the documentation at http://www.rust-ci.org/emk/cesu8-rs/doc/cesu8/ Please feel free to file GitHub issues describing what you need at https://github.com/emk/cesu8-rs Also, if changes to the Rust API break the crate, I normally try to fix it within a few days, but if you need it fixed faster, please file a bug. I would like this crate to be useful!
An interesting benchmark idea, actually. Performance of I/O libraries is important in many programs. Aside from the fact that a rewrite of `std::io` is planned (i.e., the current version will probably not get optimized any further), there are a few unresolved questions: How often was the test run? Is it of any use to benchmark writing stuff to `/dev/null`? Is using `time` a good way to measure?
The rewrite to drop support for M:N threading and move to native APIs already happened.
Very nice intro page!
I am looking at making Erlang NIF modules in Rust. They are normally written in C. The entry point into the module is a function called "nif_init" that returns a pointer to a static ErlNifEnv which describes what the module provides. The C macro that creates a nif_init() for you is here: https://github.com/erlang/otp/blob/maint/erts/emulator/beam/erl_nif.h#L271-291 There *is* a Rust example (https://github.com/lavrin/erlang-rust-nif/blob/master/rust_src/src/lib.rs) that sets up the ErlNifEnv at runtime. I think this particular implementation provides pointers to freed memory, but if you fix that problem then you have the issue of leaked memory when the module unloads. (there is no nif_destroy() function that could mop things up.) The whole ErlNifEnv really needs to have static lifetime.
Added to the calendar.
Read through the issue and yes, it is not really something to do with the library. Haven't got enough rep on stackoverflow to comment (and I don't have anything to add that would warrant an answer). Anyway, since you do not capture anything in 'prop_value' you could factor that out into a generic free function which should fix your specific issue (repeating what Vladimir Matveev wrote). I would like to know what you didn't understand in the documentation as well. Edit: Just a guess but is it how to deal with factoring out parsers into free functions? Since the types created gets quite large I understand that it is annoying to write out the types for them. There are two ways of dealing with this, either write the function with the wrong type and then copy paste the type that is output when the compiler errors or you write it into a free function as described in the second example in the docs [here](http://marwes.github.io/parser-combinators/doc/parser-combinators/index.html). I should maybe add a line to explain that this can be used both for mutually recursive parsers and for factoring out parsers into smaller units.
Only 27?
The types of the rust code are bad: the method variable can only be 0 or 1. So you should use an unsigned integer and the smallest possible: u8. The rounds variable also doesn't make much sense to be signed, so u32 should be used instead (or even u64 if you want to test bigger files) The c version variables also should be unsigned
No it didn't, and you're well aware of that. This incident started when you guys called be incompetent and trashed my contributions. I posted a satirical remark in response to that at the end of my comments on this RFC, and now you're totally misrepresenting the situation. It's funny that you think it's totally okay to insult a person behind closed doors and even in public, but yet you have a major problem with expressing strong opinions about an idea. I'm astounded by the manipulative behaviour that you continue to demonstrate. There's really no limit to how much you'll abuse your power.
in the case of internal/external itarators, a C#/python style yield statement turning functions into generators would be a way to have your cake and eat it! &gt; and he may even have been correct, given the evident difficulty of explaining Rust's modern lifetime system :P i somehow repeatedly read “postmodern” here. i need sleep.
Hmm, the second example in the docs does not actually work for your case when I think about it since it does not allow for additional parsers to be passed. I guess that using the compiler to generate the type is just a workaround. If you don't need absolute efficiency you can always box the parser and return it. The only other way that I can think of right now to make it work for you is to define a new type yourself and implement the parser trait for it.
that discussion always misses the huge point that linus’ rants are *always* targeted at people whom he trusted to make good decisions, and whom he now saw to violate his trust. go ahead as a kernel noob and try hard while making the same mistakes, and he’ll be nice as can be.
Actually I did expect rust to be faster than the c default due to the fact it knows it doesn't have to lock stdout every time. C has "27 years" of legacy pile up including threads and locales being added after the fact, so you pay for a lot of expensive locking you don't need in many cases. Even friggin isspace() does locale checks, even if you just care about ASCII, which can require a mutex :-( So, so much crap in glibc that should die....
their side seems to be that you are great on a technical level, but [“repeatedly treating those core devs like shit”](https://www.reddit.com/r/rust/comments/2tx7vj/psa_thestingers_rust_packages_for_arch_linux_are/co3o9j8) there are always two sides to a story, but whoever is more or less right: i’m sad to see you walk away from something that obviously was very important to you. that must hurt.
&gt; The types of the rust code are bad: the method variable can only be 0 or 1. So you should use an unsigned integer and the smallest possible: u8. This sort of use case is fundamentally exactly what (C-like) enums are for. Just use those, and it'll handle the sizing and numbering for you.
It might be worth it to include something like this in the library. This way you can pass in anything you need as the state parameter when you construct the parser. EDIT: Just remembered that the reason something like this is not in the library is that it should be unnecessary once the compiler sorts out the orphan checking. Then I can simply implement Parser for all functions (impl &lt;F: FnMut(...) -&gt; ...&gt; Parser for F {} ). extern crate "parser-combinators" as pc; use pc::*; use pc::primitives::{State, Stream}; pub struct External&lt;S, F, R, I&gt; { state: S, parser: F } impl &lt;S, F, R, I&gt; Parser for External&lt;S, F, R, I&gt; where I: Stream , F: FnMut(&amp;mut S, State&lt;I&gt;) -&gt; ParseResult&lt;R, I&gt; { type Input = I; type Output = R; fn parse_state(&amp;mut self, input: State&lt;&lt;Self as Parser&gt;::Input&gt;) -&gt; ParseResult&lt;&lt;Self as Parser&gt;::Output, &lt;Self as Parser&gt;::Input&gt; { (self.parser)(&amp;mut self.state, input) } } pub fn external&lt;S, F, R, I&gt;(state: S, parser: F) -&gt; External&lt;S, F, R, I&gt; where I: Stream , F: FnMut(&amp;mut S, State&lt;I&gt;) -&gt; ParseResult&lt;R, I&gt; { External { state: state, parser: parser } } fn main() { let mut parser = external(digit(), |this, input| { this.parse_state(input) }); parser.parse("1"); } 
&gt; @brson: I'm not interested in your self-righteous bullshit. People who endlessly spread FUD and play nasty political games don't deserve any respect. You're not a neutral party and I don't consider any of you as having any credibility, so you're wasting your time. &gt; &gt; Being passive aggressive and manipulative in ways that seriously damage the project is the modus operandi of the core developers. Then you dare come here and act as if you're superior because clearly nasty politics is so much better than honest speech. Is not satire.
The relevant comment thread is here: https://github.com/rust-lang/rfcs/pull/741/files#r23589802 Misrepresenting the situation further isn't helping.
That's not the comment that is being referenced.
Ok, I'm sorry for making an incorrect assumption, although in that case I genuinely don't know what's being referred to here. Regardless, I stand by the basic point that no one is disputing your competence here, only civility.
Lying to someone about a job interview, lying to them about a work week, blocking their contributions with invented obstructions and spreading lies about them behind their back is uncivil. You've never done anything to wrong me and you weren't around for the vast majority of this, so it doesn't make sense to get involved in this. I had already stopped contributing by the time you were involved in Rust.
You aren't aware of what happened so you're getting the details wrong yet you're speaking from a position of the authority on the matter. That's resulting in a misrepresentation of the situation, even though the mistake was obviously unintentional.
I have never directly participated in the kernel, so I can't speak to that, I just know that The Internet has been talking about it a lot.
&gt;If you don't need absolute efficiency you can always box the parser and return it. When I try to pass the boxed parser to functions like `try` or `many`, it complains that the size is not known at compile time, which seems like a reasonable thing to complain about. Is there any way around this?
Why not? I thought `static` meant something that actually ends up in the binary, and `const` is some compile-time constant. Suppose the OP wants the strings to be available in the binary somehow, perhaps even with a name accessable to code in a different language, surely `static` is the right choice?
Also, none of that thread is satire, unless I have a rather different concept of satire. (Maybe you point out where wycats' claimed you lack technical rigour in your arguments and coding? [This comment?](https://github.com/rust-lang/rfcs/pull/464#issuecomment-68075092))
Yeah. I'm all for better information flow in both directions. It's important though that the core team doesn't have to follow the community's vote 100% of the time. If we'd kept every feature that was popular in its day, Rust's design would be a discordant mess like so many other languages. Making the hard choices sounds like a thankless job, and I'm sure that the personal attacks don't help. On the other hand, respectful criticism of the core team's management of the language is a great thing, and is necessary for the kinds of procedural reforms that have occurred. Funny enough strcat was usually on the side of removing features, just not f128, which was never popular but was one of his personal additions.
I'd be curious to see this either substantiated or refuted.
We have a rustdoc bug open for it.
I think having multiples is very healthy, so I'm glad you shared! Nobody should feel that just because some library exists, another that does something similar (or even exactly the same) isn't useful. Monocultures are bad.
Oh totally, I just mean so you know what the status is :)
I noticed this was compiled with -O, which is equivalent to --opt-level 2. I wonder if the gap is any smaller if it's compiled with --opt-level 3
Their website is hot. 
I hit this often when using SpiderMonkey in Servo, and I haven't found anything better than http://mxr.mozilla.org/servo/source/components/script/dom/bindings/error.rs#103
I just did a quick one-off to see about buffered writes through `stdin`/`stdout`. Writing to `/dev/null`works a little too well, so I did: fn main() { let mut out = std::io::stdio::stdout_raw(); let bytes = [0u8; 1 &lt;&lt; 16]; for _i in range(0, 1 &lt;&lt; 16) { out.write(&amp;bytes); } } and fn main() { let mut input = std::io::stdio::stdin_raw(); let mut bytes = [0u8; 1 &lt;&lt; 16]; let mut read = 0u64; while read &lt; (1u64 &lt;&lt; 32) { read += input.read(&amp;mut bytes).ok().expect("read error") as u64; } } piping the output from the first program to the second looks like Echidnatron% time ./gen | ./main ./gen 0.02s user 0.57s system 56% cpu 1.035 total ./main 0.04s user 0.47s system 49% cpu 1.035 total Caveat: may be many things wrong with my methodology, but looks a bit more optimistic. I have no idea what the c numbers are. [Edit: this is also with one core pegged doing some other unrelated compute, so could get even better when that wraps up]
Yeah. I brought it up to mention a drawback of that style, but I think enough has been said on that. We have our own norms and they're written out quite clearly. What the Linux community does is for the most part irrelevant.
@strncat in the link you provided, wycats and nick29581 have already apologize. I think you should forgive and continue your contribution to Rust. Everyone values your contribution. wycats added a note a day ago @thestinger I unreservedly apologize for using the phrase "technically sloppy" to refer to your work. nick29581 added a note a day ago @thestinger Apologies, I do not mean to be condescending. I don't think anyone should question your competence because you've clearly demonstrated it, and because I don't think anyone should question anyone's competence 
At its core (heh), `std` loads the dependencies via `extern crate` and reexports the functionality via `pub use`. (There's sometimes extra traits defined/modules introduced.)
It need not be a technical fork initially, but merely a community one (which also would benefit from an early start). It seems clear that the current situation allows for ideas that are politically driven to persist in the language/implementation regardless of their technical merit. Fix that one issue with the community fork, and technical reasons to prefer the fork will come in no time. I don't really except this issue to be resolved in the current Rust leadership, as it is rapidly trying to solidify its control by restricting the community only to tightly moderated venues.
I already stopped contributing some time ago. I'm not going to contribute to the project again. I have an irreconcilable feud with a few of the core developers. There's no amount of money you could give me to make me continue torturing myself by interacting with those people. I'm tired of Rust's world of FUD, underhanded politics and contrived political correctness. I *deeply* regret spending so much time contributing to the project and will be strongly recommending that no one uses it or contributes to it from here on out. Rust is very interesting and had a lot of potential but ultimately it's not good enough. It hurts productivity too much and the memory model isn't nearly flexible enough. The high-level feel is created by aborting on out-of-memory and the memory model forces too many performance and memory usage compromises. The applications where the compromises are acceptable would probably all be better off with tracing garbage collection anyway. I think it's a solid foundation for another language to improve upon but I don't think it's deserving of success itself. I can't see it significantly displacing other systems languages but rather it's going to get used at a server / application level by people who think it's cool but don't really need it and would be more productive with another language. I'm not going to exhaust any further effort on a sinking ship. It brings me misery and it's hardly worthwhile because it's not actually useful. I do think it's a slightly better choice than C or C++ in most cases if you ignore the library ecosystems, portability and more but that's not good enough... most of those uses of C or C++ could just be done with a high-level language.
it is, and if you use it daily in your python programming, you see how useful that is. but double-ended iterators are an interesting thought. maybe there is a way to ensure that some code is reversible and allow that for double ended yield? there is [some](http://www.dcc.fc.up.pt/~acm/questionsv.pdf) [theory](http://www.researchgate.net/publication/221302730_Clean_Translation_of_an_Imperative_Reversible_Programming_Language) on the topic. probably not worth the gain when used just for yield, but interesting nonetheless.
&gt; Yelling at them in public would very rarely be considered sound management practice the problem is that linus has one thing distinguishing him from every other kernel contributor: people agree that his kernel is the canonical one. he neither pays people nor has any other influence on their work other than accepting or denying patches. in this context, his yelling *is* professional, because it’s the only way to distinguish between “here are issues, please fix” and “you should not have tried this in your position of knowledge and trust and i’ll have to look more closely at your contributions than i used to before you tried this. your code violates essential rules of kernel development that you knew for years.” if he had any managemental power, the second one would be a demotion or a hearing or something. i’m a scientist. our main rule is proper scientific practice. if i knowingly violated that, i’d get all those things, and digust and disbelief on top.the only tool linus has here is language though…
Interpreting `&amp;'static [u8]` as `raw::Slice` and pulling the first field (`data: *const u8`) out of it also works, but results in LLVM error when done in a constant expression. extern crate libc; use std::raw; extern { fn puts(s: *const u8) -&gt; libc::c_int; } const RUST_SLICE: &amp;'static [u8] = b"a constant c string\n\0"; // Get the address of the slice const RUST_SLICE_PTR: *const &amp;'static [u8] = &amp;RUST_SLICE as *const &amp;'static [u8]; // The address of a slice is the address of its first field const RUST_SLICE_DATA_PTR: *const *const u8 = RUST_SLICE_PTR as *const *const u8; // Dereferencing of raw pointers in constant expressions leads to LLVM error const C_STRING: *const u8 = unsafe { *RUST_SLICE_DATA_PTR }; fn main() { // It works unsafe { puts(*RUST_SLICE_DATA_PTR) }; // And it doesn't unsafe { puts(C_STRING) }; }
If https://github.com/rust-lang/rust/issues/18465 is implemented, then byte string literals will be thin pointers, and you both will be happy :D
But not NSFW hot.
My bad forgot about this [issue](https://github.com/Marwes/parser-combinators/issues/6). You should be able to to this but associated types are still a bit buggy.
Maybe http://users.rust-lang.org ?
I'm not sure what this will mean, practically speaking. &gt; If this seems painful try to be reassured that we dearly want your &gt; crates to work on the stable release channel and will do everything we &gt; can to make that happen as fast as reasonably possible. In the coming &gt; weeks there will be a concerted effort to lift as much of the cargo &gt; ecosystem onto the stable subset of the language as possible. A nobel goal, but lets be practical. It's not going to happen. You'd have to have every author of every create on crates.io continually update their crates over the coming weeks to get a feel for what features are or are not going to be 1.0 stable, and provide feedback. There's no incentive to do this painful work. Realistically, a few popular crates will do this, and the majority of them won't. ...and because there's no automatic CI on crates.io, we'll end up with a big broken list of crates, which, is basically what we already have, so I suppose it won't be particularly better or worse than it already is. If you *really* want this to happen, force every crate on crates.io to use CI; if it fails the build for a new release of rust, place a *GIANT RED FLAG* on crates.io/crates/broken_thing when you visit the crate, remove it from search results and email the author. At the very least it'll prevent the current 'search crates.io, add dependency, build, swear, remove dependency, search crates.io or alternative dependency, visit github page to check travis, repeat...'
Rust's primary promise is safe and robust programming at the large. If your goal is to make things quickly (which is of course reasonable), Rust might or might not be your language. If you care about the correctness of your code and often complain about the lack of static (that is, well before the actual execution) promise, Rust might be really promising. There are some annoyances not related to this goal, including the "overly complicated lifetime system" (we do have some particular pain points considered harmful) though, and it will hopefully be accounted after 1.0.
Allowing derefs of unsafe pointers in constants is a bug IMO. There's no possible general implementation.
&gt; Even if strcat does the work of 50 "ordinary" contributors, it's not hard to imagine him alienating at least that many if he's running the show. While the thing about alienating contributors may be true, I don't think it would have a noticeable impact. Essential work is always done by individuals, not by wide community. I can't imagine any number of "ordinary contributors" replacing, for example, Niko Matsakis.
Maybe, but at least the disallowing should not be done with ICE :) By the way, they are allowed in C++ (with some restrictions, e.g. `reinterpret_cast`s are prohibited, and UB leading to compile time error).
Respectfully, if you think Rust is anywhere near the complexity (and ugliness) level of C++, then you have yet to spend a decade discovering and realizing new and interesting things about C++. There are some aspects of Rust which I think are more complicated than they *need to be* and which I wish could have been done better (thinking primarily of the types vs. modules, functions vs. methods, and associated items area), but relative to C++, there is no comparison. Most of the apparent complexity relative to the high-level dynamically typed languages is due to the low-level control and manual memory management. If you don't need that, and want something with greater simplicity and "cleanliness", look to Haskell. &gt; With C++ you have a decade of posts on mailing lists,stack overflow with do's and don'ts for most of the features and paradigms used in project. A very large proportion of those are likely to be about how to deal with or mitigate problematic aspects of C++ which are not present in Rust. :-)
As a non-native speaker i have probably misled you. What i meant to say was that it looks to me (to me specifically as i would be generalizing too much if i would say "most" of the py,rb people). To be really fair my only experience with Rust is from reading (and by reading i mean randomly checking out) docus or posts about it. 
Buffers hide the issue. Using buffers you can get huge IO in any language: even Python or Ruby will have excellent throughput. The problem is the overhead of Rust's IO, and using big buffers sweeps it under the carpet by making less IO calls with more data, and thus decreasing the uses count of the IO subsystem and its impact. Small IO *is* a problem right now in Rust.
This is slow because it all goes through `write_all`, which is fine for large writes, but abysmal for small ones like `write_u8`. `write_all` does a memcpy and a bunch of size checks, in this case just to copy a single byte. The overhead is nuts. By implementing a specialized `write_u8` on BufferedWriter, I get: C: test_rounds=100000000 test_method=1 /usr/bin/time ./bencc &gt; /dev/null 0.19user 0.00system 0:00.19elapsed 100%CPU (0avgtext+0avgdata 1244maxresident)k 0inputs+0outputs (0major+63minor)pagefaults 0swaps Rust: test_rounds=100000000 test_method=1 /usr/bin/time ./bencnew &gt; /dev/null 0.18user 0.00system 0:00.18elapsed 100%CPU (0avgtext+0avgdata 6080maxresident)k 0inputs+0outputs (0major+767minor)pagefaults 0swaps Didn't check what's eating up the memory.
It's an amazing idea, I have been doing work on writing codecs in Rust, and it can help you avoid a lot of pitfalls. My main interest is in making codecs safer, since it's very hard to write them safely in C.
Surely the whole point of isspace() is to abstract out locale checks and the like so you get an honest answer to the question "is this a spacing character of some kind"? If you just want to know if this byte is the one corresponding to an ASCII space then you want `c == ' '`.
I don't disagree that small IO is a problem in Rust. (And `String` IO is a wreck.) But for my purposes (analyzing multi-gigabyte natural language copora interactively via parallel map/reduce-style code), small IO is too slow in _any_ language I've tried. I'm personally far more interested in whether I can someday reach a gigabyte per second using a custom column store. But some of this will need to wait until Rust stabilizes a bit, and it will require redesigning my processing algorithms to do as much pre-computation as possible when importing data.
I posted my numbers and example code for two reasons: 1. I've spent a fair bit of time benchmarking Rust I/O, and `fill_buf` is one of the highest-level APIs that still gives decent performance. This helps narrow down the performance problems that people are trying to find. (For example, the `String`-based stuff is just awful. `malloc` is not your friend here.) 2. Anyone who wants to do high-performance I/O in Rust might benefit from knowing which existing APIs are fast, and which are slow. Also, about half the Rust I/O benchmarks I've seen around the web forget `--release`, which makes an _enormous_ difference. Anyway, to avoid further derailing this discussion, I'll withdraw now.
Over time, we'll figure out what the good things are. You can't figure out what the good things are without hundreds of projects written in the language to figure out what's bad in the first place! Generally, most of the features in the language as it stands are non-overlapping and provide significant expressive power that isn't there without the feature. I think that's a good benchmark for whether any given feature is "bloat" - on the other hand, C++ has a lot of overlapping, poorly named features so that it can be difficult to figure out which ones you need to use.
I would add "3. Closures" to the list. I have limited experience so far, but I have found trying to use all of the above simultaneously to write high level code to have quite a steep learning curve. I am hopeful that more mature docs as well as more powerful type inference, will mitigate this. i.e. it doesn't matter if some function has a really gnarly type signature, if the compiler is so good at inference that you never actually have to actually write it, and the function declaration syntax is easier to grok. Keep in mind, we are far, far, from 1.0. I applaud the stability push, but I personally think alpha was celebrated too early, given that foundational things like I/O and integers are still unstable. 
Part of our goals with instability before 1.0 is to get feedback about the things people need, to be able to focus efforts. Furthermore, [1.0 is explicitly not the end of language or library development](http://blog.rust-lang.org/2014/09/15/Rust-1.0.html). You may have to wait for 1.1, or 1.2 for your favourite/necessary feature to become stable, but you would've had to wait until then for 1.0 anyway, if it were to block 1.0. (I.e. there's no guarantee that delaying 1.0 would make features be stable faster.) &gt; In addition; the std library cannot compile without unstable features, servo cannot compile without unstable features, and so on. But still it seems like most Rust users are expected to use only stable features. Users are expected to use whatever channel they feel is appropriate. [Tools](https://github.com/brson/multirust) are provided to make switching between channels as easy. If someone is writing code that is meant to be stable and supported long term, then the stable 1.x releases are appropriate. If they need or want non-stable features, then nightly is appropriate. We will encourage (and try to help) people to use stable, but will not make using nightly difficult. &gt; The std library contains a lot of useful things that are currently unstable, and during the alpha cycle so far we haven't seen any massive effort to make the unstable things stable (except for the std::io rework, perhaps). The IO rework is *huge* and encompasses much of the instability in the standard library. Looking at [the stability page](http://doc.rust-lang.org/nightly/std/stability.html) most modules that have &gt;50% 'unstable' are covered by [the IO changes](https://github.com/rust-lang/rfcs/pull/517) or are related to them and had RFCs: - `std::ffi` - `std::old_io` - `std::os` - `std::path` Another big chunk is `std::rand` which has [an RFC](https://github.com/rust-lang/rfcs/pull/722) and yet others are "obviously" going to be unstable, `std::rt`, `std::intrinsics`; leaving very few that haven't a lot of effort put into them. (That's not say that these modules will be 100% stable at 1.0, but there has been effort and thought put into them.) I'm sure it's not so obvious for people tracking the RFC repo, but it's unfair to say that there hasn't a massive effort towards stabilisation: there has, just most of it has been on making sure everyone is happy with the design rather than doing the implementation. &gt; Or if people wanted to do the same as std - say having a repo with several crates in it, one being the stable one and the other ones unstable. The stability system that handles `std` is explicitly designed only for use there, but having a stability system appropriate for use outside the main repo is definitely a priority. [This comment](https://github.com/rust-lang/rfcs/pull/507#issuecomment-68499183) (and surrounding discussion on that RFC) clarifies.
As far as I know, all the existing Rust input compressors and decompressors plug in at the `fill_buf` layer, and avoid byte-by-byte input. I haven't looked at the output side.
That problem is "types are too heterogeneous", not "the language has too many features". In any case, that complaint is still one I don't agree with. `Box`, `Vec` and `String` are heterogeneous because there's no way to represent them in a homogeneous way. If you try to reduce them to a single idea of an "owned pointer to `T`" (as the old `~` sigil did), you run into the problem that `Box` is a true owning pointer, while `Vec` and `String` are resizable.
The Linux kernel has trouble attracting contributors because it's hard to write kernel code, the kernel is mostly done, and changes (especially simple ones) have little direct impact on users. "Verbal abuse" has nothing to do with it. 
That's an exaggeration, you have to know about monomorphization of unboxed closures in order to write a wrapper for virtual dispatch... Passing around closures in Rust is worse than Hitler right now
Yes it is in a loop. I was confused by another loop where same code works, but there a immediate return or panic after call to `send`. I just needed to add `break` in one of this match arms to compile this. Thanks. Borrow checker is so smart.. but the error is still confusing.
[Episode 4 is now online](http://youtu.be/hHo4B0ev9aM) . This time more dramatic than ever ;).
I successfully built and tested a Rust cross compiler for Raspberry Pi a couple days ago following instructions here: https://github.com/npryce/rusty-pi/blob/master/doc/compile-the-compiler.asciidoc
Know if that repo will get updated anytime soon, seems a bit inactive.
For my part, I've successfully used [prebuilt binaries](http://luqman.ca/rust-builds/) on the rasberry to compile a simple [hello.rs](https://github.com/npryce/rusty-pi/blob/master/src/hello.rs) Not sure if useful, but fun :-) Now I'm trying to build on the RPi a recent rustc from this binary... *something* is compiling, but not sure of the result (and it **is** slow)
I don't know. I actually didn't look at it much yet beyond that bit of setup documentation.
Wow, I thought those arm-unknown-linux-gnueabi binaries only worked on ARMv7 devices, and not on the RPi which is ARMv6. Could you do me a favor? I'm setting up automation to build *unofficial* ARM nightlies of rust and cargo, could you check if the binaries actually work on the RPi? I'm building the binaries on the ODROID XU (which is an ARMv7 processor), and they work fine there, but I don't know if they'll work on an ARMv6 processor, and I don't have a RPi board to test. Of course if you don't feel comfortable running untrusted binaries, I understand! Binaries [here](https://www.dropbox.com/sh/qfbt03ys2qkhsxs/AACxFoD1OrxDXURzj5wX0IYUa?dl=0), build scripts [here](https://github.com/japaric/ruststrap) (haven't push my latest changes though)
I'm happily using Rust on my ARM computer, so if you want not only to be able to run Rust programs on ARM, but also to *run rustc* on it, you can use [this guide](http://github.jfet.org/Rust_cross_bootstrapping.html) to get a working `rustc` on ARM. From then on, you can recompile `rustc` directly on ARM if you wish (I guess that it would swap a lot on Pi, since it uses about 1G of RAM). Note that if you compile `rustc` for ARM with intention to build next version on ARM directly, make sure you are building version listed in `snapshots.txt`.
Absolutely!
&gt; Part of our goals with instability before 1.0 is to get feedback about the things people need, to be able to focus efforts. Fair enough. I need e g weak pointers, but I'm not exactly sure how and to where I should feedback that information. &gt; We will encourage (and try to help) people to use stable Right, so that's what does not add up for me, on one hand encouraging people to use stable, on the other hand keeping everything from `to_string()` to PI constants as unstable. &gt; I'm sure it's not so obvious for people tracking the RFC repo, but it's unfair to say that there hasn't a massive effort towards stabilisation: there has, just most of it has been on making sure everyone is happy with the design rather than doing the implementation. Ok, let's hope that the stabilisation makes it into the implementation too then :-)
Try writing the same table for C++, and let us all know once you've succumbed to oblivion after staring into the abyss for so long. :)
Coming back to this... do you know how that Linux-specific API is called? I can't seem to find anything on this.
héhé, I've already found [your nightlies](https://github.com/japaric/ruststrap) while I was looking for a cargo binary for the rpi, and (at this moment) the one of your github didn't work. I tried cargo-2014-10-28-947a62b-arm-unknown-linux-gnueabihf-64c89c311c69046c569740748ab49a9dab6cc81c.tar.gz but I can see new build on your dropbox ! I'll give a try ! I'm not really a C/Rust/... developer (much more javascript, python, ...), but with some help, I'd love to try !
That doesn't seem to exist yet?
If people are downvoting due to rule 4 then thats stupid, the entire thread is basically violating rule 4. I hate rule 4.
Do you imply that it's essentially impossible to catch and handle the out of memory error in current Rust?
nice job. Perhaps BufferedWriter could enforce that the buffer size must be &gt;= 8 or some such, if it wants to be able to optimize for tiny types? EDIT: just to clarify the &gt;=8 thing, that saves a potential branch in your write_i32 etc. The most you have to do is flush what you have, then you know your buffer has room for the i32, unlike the unbounded write() case. i looked at the memory usage some more. Looks like dynamic linking more than doubles the max used RSS. But even with static linking, its 2x what the c program is. The 64K default buffer size is also pretty aggressive, 1k-4k would be typical of C that I've seen. I also looked through the io source code. Overall I'm impressed, but error handling on flush/drop needs some work (RFCs have comments on that now). Nice to see that slice::copy_memory can assume no aliasing between a &amp;mut[] and &amp;[], and use straight up memcpy.
&gt; If you want to use it like C but with smarter strings, you can do that. Huh ? I have been trying to manipulate strings (and text I/O) in Rust several times, and each time I gave up and went back to another language. This is my personal worst nightmare. When you look at the examples and doc, first reaction is "WTF?". Then you say, well, that's the canonical way of doing it, or, well, that's an old way of doing it, and you start looking for a modern, simple, effective way of doing it. There you get the second reaction: "WTFF, there is no other way?!". And you switch to one of the other "modern" languages or even back to C. No wonder it is the main thing that has still to be redesigned.
&gt; All the rant about Linus is the worst kind of political correctness I have ever seen ! It comes from kids who always had what they want being denied something for the first time in their life. Sorry, no. But as I said above, this is very offtopic here.
Provide the O_TMPFILE flag to open().
It simply aborts, so yeah. Failure allocates memory and is too coarse to be a viable way of handling it even if it didn't. At best, Rust could have an out-of-memory handling callback which is not a real solution.
/r/playrust
At this point the only thing I've tried was calling some Rust functions from a basic libnds example in C. Later I'm going to try rewriting the whole example with only Rust and no C, but still using libnds. After that, I'll see if I can go without libnds, but it might not be worth it.
&gt; when he insults someone it is always deserved When somebody writes this, no matter who "he" refers to, I am sad because it reflects a failure of imagination to conceive of a world in which technical decisions are made by slow consensus rather than by slapfights.
Why do you think that the core / most productive devs would not also be alienated? They're the ones who have to deal with this crap on a daily basis. Niko joined the project at some point (2011?) and presumably had plenty of other options at that time. There's no way to directly measure this effect. The project will just dry up if technical discussions are characterized by bitter, personal fights. Everyone from Niko to the first-time contributor with a typo fix has better things to do than deal with that.
Are there parts of it suitable to run in a GPU? (I'm seeing some OpenCL implementations like [this](http://www.multicorewareinc.com/video.html) so I suppose there are substantial gains). I think that a good library would either run it 1) entirely in CPU; or 2) optionally run some or the majority of code in the GPU; or 3) optionally use some specific hardware support (when it appears), letting the caller decide. It would be nice if a Rust library tasked to do 1) had an architecture to accommodate 2) and 3).
Now is always a good time to start learning. Dive in.
I have the version, I want the author.
And it's getting worse with the new versions of C++, of course, as it further fractures the community (still stuck in C++03 for my part...)
The core team members still have to go through the RFC process, don't they?
Well. That probably means it can't be used to develop an OS then. And it makes the language essentially useless (for me).
Cheers Daniel.
I've been using these for a few weeks and for the most part they've been great, but I have run into a few problems. For example, at least with the GNU eABI HF version, none of the trigonometric functions work, they just return whatever you give them. I don't know if this is an ARMv6 vs ARMv7 issue or what.
1. filter creates a new iter while retain modifies the Vec in-place 2. Java collections also define a retain method, which is one precedent
I know, I know, obviously I wasn't completely serious. And I clearly had no intention to belittle contributions of other people interested in performance, but may be they could be more.. vocal, in RFC discussions for example?
&gt; Why is it that you have to build a separate rustc to compile for Raspberry Pi? What you really want is not the compiler, but the libraries (core, std, etc) built for ARM, i.e. the libraries are ARM binaries. With an off-the-shelf rust nightly, you can do this: // core.rs #![crate_type = "lib"] #![no_std] `rustc --target arm-unknown-linux-gnueabihf core.rs` OK However, you can't compile this: // app.rs fn main() { println!("Hello world!"); } `rustc --target arm-unknown-linux-gnueabihf app.rs` You get `app.rs:1:1: 1:1 error: can't find crate for std`, because you don't have an `std` crate built for ARM. But, if you built the rust compiler with `./configure --target=arm-uknown-linux-gnueabihf,..`, you'll end with an extra `arm-unknown-linux-gnueabihf` folder under `$LIBDIR/rustlib` which contains the usual crates but built for ARM. Once you have those ARM libraries, you can compile the `app.rs` crate, and run the resulting binary on an ARM device. HTH
And you guys say that strncat has problems with his communications? Rust team never even tried to contact him and ask him "Are you still using this for anything?" Do you think any person reads every meeting notes post if they're not employed by Mozilla? You realize that strncat did all of this work for free, so he can't even go "Well, I wasted x hours of my time, but at least I got $50x for it". This is why I kind of don't want to contribute any code to the compiler. I feel like it would be removed eventually and if strncat can't get hired by Mozilla then what chance do I have even if I put in a ton of work into Rust? There's no way I would even contribute half of what he's contributed.
Browsing the docs, [this enum](http://tomaka.github.io/glium/glium/enum.BlendingFunction.html) really struck me as an example of how good Rust's semantics are. In C, that functionality is only implemented as a set of *global* flags which are manipulated using three different functions (plus a couple of deprecated functions), in a grotesquely type-unsafe way. Even in the best C++ library, expressing those semantics would take either some clunky OO solution, a `boost::variant` (with all the complexity, verbosity and increased compilation time which that implies), or a bunch of `enums` and `unions` which the user is expected to wrangle by themselves, memory-safety be damned. In Rust, it's just a damn type, the way it's supposed to be.
I haven't said anything of the sort, and have not contributed to any of these discussions at all except for that one point, which is that there is no magical decision making cabal. The justifications for decisions are laid out in the meeting notes or, these days, RFC PRs and discourse threads. I don't expect everyone or even anyone to read all the meeting notes. Even I don't read them these days, I'm busy with other things.
In C++ there is, and it's glorious. Rust should have user-defined literals too, and a microseconds type.
&gt; It'd be nice if I could use some of the standard library (especially when it comes to defining lang items like Copy and so on). You can and should use `libcore` which is a fraction of `libstd` that doesn't need anything from the underlying system, but gives you closures, string literals, `Copy`, `Send`, `Sync`, and other stuff. I expect that you should be able to compile the `core` crate with `rustc --target=$NDS src/libcore/lib.rs`, and then build crates linked to `libcore` with: #![crate_type = "lib"] #![no_std] extern crate core; fn fun(s: &amp;str) { let mut a = |&amp;mut:| {}; a(); } As for porting `libstd` to the NDS, I'm afraid that I can't give you advice, but the folks in the #rust-osdev IRC channel probably can. They should be familiar with low resource devices without OS support (i.e. bare metal), since they build OSes with Rust! Good luck and have fun!
If anybody is looking for an ARMv5 target, I think I did some things here with some instructions I found on the mailing list from somebody who hacked and slashed the compiler a bit to get working: https://github.com/nelsonjchen/rust/commits/armv5 I really hope something official gets put into mainline for armv5. 
&gt; Fair enough. I need e g weak pointers, but I'm not exactly sure how and to where I should feedback that information. There's no good channel at the moment, but we will be providing more guidance as the IO rework starts to finish. &gt; Right, so that's what does not add up for me, on one hand encouraging people to use stable, on the other hand keeping everything from to_string() to PI constants as unstable. To be clear, we will be encouraging people to use 1.0.0, not 1.0.0-alpha. The former is still 2 months away (or more); lots of time for library development and stabilisation. &gt; Ok, let's hope that the stabilisation makes it into the implementation too then :-) The entire point is to put it into the implementation. These efforts are blocking 1.0.
An update: https://github.com/rust-lang/rust/issues/20022#issuecomment-72004618 the issue has been placed on the 1.0-beta milestone.
I've mostly been exploring Rust coming from a C# and C background. The String and &amp;str types are definitely on the list of things I want to get to know better, but it will come.
This is true of current Rust, but there is no reason that the borrow checker cannot be further improved at the cost of additional complexity, and in the past you have suggested ideas for how to help make intrusive data structures work. Perhaps I am naive, but I think that if it became an explicit goal, there is a real possibility that they could be made safe (or at least, mostly safe). I understand why you're skeptical, though, and I certainly understand why you don't want to work on the project anymore.
Now it does!
Ah, I'd probably not refer to that timeline article. &gt; The standard library is nearly feature-complete. The majority of APIs that will ship in 1.0 stable will already be marked as #[stable]. Is flat out wrong. They weren't and still aren't. We're already had several people pick up the alpha thinking this is correct and get annoyed when they're told that all the apis are changing and will continue to change for the rest of the alpha. 
You can, but it's somewhat limited, since you can't expose a safe API that provides multiple mutable references at the same time (and there are times where you really do need that). And the implementation is still generally unsafe, modulo cute tricks like zippers.
You can do that by making the fields of your data structure use RefCells or Cells. This is, for example, how the Servo DOM works, so it is definitely possible. (The Servo DOM is a safe, intrusive doubly-linked list.) In the future I would like to propose more ergonomic sugar for RefCell, since it is an important abstraction. &gt; And the implementation is still generally unsafe, modulo cute tricks like zippers. If implemented properly, the linked list code should only have to be written once, thanks to generics.
Well, if you truly need an unbounded number of mutable references to an object, with zero overhead, then you want something that's unsafe. That's because you can hold a reference to an inside of an object while then going around via some other pointer and freeing it. So Rust won't let you do that without typing "unsafe", by design. Does this mean that all systems programming is inherently unsafe? No, and systems like the Rust compiler and Servo, as well as the various OS's written in Rust, have shown that. You just don't need multiple mutable references that often, and in the uncommon cases that you do, you can use Cells and RefCells. The overhead of a RefCell is essentially the same as a write barrier in a GC'd system, which is not an unexpected or unreasonable cost to pay, especially when you just push RefCell to the edges. &gt; It's important to remember that there are many other intrusive data structures, too. Of course, the same could be said for all of them, but I am not sure they are all as easy as intrusive linked lists to provide a safe interface for. You can do the same trick for arbitrary trees too. In fact, I started on an implementation (rtree) of this first, because trees are just a generalization of linked lists.
I do notice the similarities between Rust and modern C++, especially with RAII. Unfortunately, I stopped using C++ before I could really master the new style. Maybe after I graduate I'll land a job that forces me to get better at it. Yes, the docs were improving a ton around the time I started. The guide, the playpen, and Rust By Example were all invaluable.
&gt; Unfortunately, I stopped using C++ before I could really master the new style. Maybe after I graduate I'll land a job that forces me to get better at it. Maybe you can get a job coding in Rust :)
I'll keep my hopes up for that. :)
Are there slendermen in the page? http://i.imgur.com/kFZT3MJ.png Actually I get that on doc.rust-lang.org too. Seems like a font issue with &amp;. Using Chrome 40 on Windows.
How wouldn't it?
The same could be said about using the collections with internal `unsafe` code rather than writing more efficient code with intrusive data structures. A doubly-linked list or red-black tree requiring allocation / deallocation for insert and remove is already poorly suited or unusable (dynamic out-of-memory error condition) in low-level code like a kernel.
Obviously I don't understand unsafe.
Rust is probably the best place to learn it, as mistakes are caught by the compiler.
I came from Scala and have been loving it immensely. Rust is great at scratching the "I like how this code reads, but it could be really really fast if I tweaked the internals" itch.
I think it took me a few weeks or so before I really understood the borrow checker and the type system.
Quite an old problem. I'm surprised it hasn't been fixed though. 
As I said before, I believe it is possible to write intrusive data structures in Rust and expose a safe interface, as long as you dynamically enforce the `&amp;mut` uniqueness semantics. The Servo DOM and flow tree essentially do this already.
I have been (on IRC at least) one of the biggest proponents of the idea that Rust needs statically checked intrusive data structures to be useful for all traditional use cases of C/C++. There are a few equivalent descriptions of the ideas involved, but one presentation is that all of these data structures correspond to a tree with an additional set of non-tree edges. If these non-tree edges can be expressed by a regular language (on trees, not strings), then you can use the nice properties of regular languages (basically everything about them is effectively computable) to implement a type system. More formally, this corresponds to the decidability of satisfaction and entailment of monadic second-order logic on graphs with bounded tree-width. One of the first examples of a practical system based on these ideas is [PALE](http://cs.au.dk/~mis/pale.pdf), although the same underlying logic has been applied to analysis of data structures many times since then. Since the logic is decidable with effective decision procedures, it should be possible to produce actual counterexample inputs for any type error. The downside is that it requires user-provided loop invariants, at least when simple heuristics fail. There are limitations, e.g. it is difficult to extend it to include invariants like the red-black or AVL tree invariants without creating an undecidable logic. If you want to have a decidable theory of data structures it is probably the furthest you can go; for many useful logics there are theorems stating that any decidable class of graphs has bounded tree-width. This shows part of the problem with the concept of a "systems language". By the original meaning of "systems language", that is "a language used to implement the operating system", Rust 1.0 would not be considered a systems language, because it is inadequate for implementing an operating system kernel. It's still great for other use cases. When designing a typed programming language (as opposed to a glorified macro assembler), your goal is generally to to ascribe meaning to programs via a finite description expressed via the type system. It isn't terribly surprising that different use cases with different intended meanings require radically different type theoretic techniques to ascribe them meaning. Instead of using vague and ethereal concepts like "systems language", people should pick specific use cases and focus on them. This would remove some of the confusion regarding the goals of language development, since you would always have concrete examples to discuss in order to drive decisions.
If the result is useful, it counts. And I think it may be. Not for everything, maybe not for a kernel. I just thought that this was interesting. It explores what we get if we only use the safe part of Rust — I hope people will respond with better ways or cooler stuff that you can do. This was inspired from a more complicated linked structure: I took the graph in rustc and implemented remove node / remove edge for that.
I'm still working on it.
It took a month or so of full time use before I could write usual programs without actively fighting the compiler every step. This was early 2013, between 0.5 and 0.6. I taught myself. Anecdotally, Rust is a lot easier to learn these days.
This is redirecting to http://internals.rust-lang.org/ edit: figured out the right link [is at users.rust-lang.org](http://users.rust-lang.org/t/psa-important-info-about-rustcs-new-feature-staging/82) - discuss.rust-lang.org is giving a 302 redirection, preserving existing links! (it's great, but I think it should be 301)
yes, I was looking for retain :) I wonder why my 3 days of googling and searching through the vec documentation didn't give me this :/
I'm aware of Google's solution and the OWASP cheat sheet. While I do plan to support other escaping modes eventually, I've still got a lot of stuff to implement before I get to that stage. So consider it on my (already very long) to-do list for Maud 1.0. As for Google's auto-escaping: I think something similar can be implemented as a lint, which warns when a variable is spliced directly into a `&lt;script&gt;`/`href`/`onclick`/whatever. The only way to silence such a warning would be to call the correct escaping function provided by the library. That's all hypothetical though, and as I said it'll be a while before I can start on something like that.
I first looked at the syntax and quirks. I write mostly C++ so it was a bit jarring to move to a language where the compilar has an iron grip on your code. It's taken me about 2 months to be able to get to the point where now the only parts of Rust I'm unfamiliar with are lifetimes, borrowing and the standard library. So basically most of Rust hah. One thing thats helped me learn is small projects like reproducing the GNU coreutils and other projects I've done
Could you expand on this? Isn't the problem ensuring that the lifetime of the object is longer than the time the object is in the container? I suppose you could use Drop on the hooks to remove the object from its list before it dies but this adds additional overheads that proper usage wouldn't require.
Is the Daala format frozen yet? I was under the impression that it was still being developed. Implementing a non-finished spec on a non-finished language? Sounds like fun :)
Yeah I didn't expect the IO RFC to be the most commented on RFC ever when I made that comment :(
But then, nearly all of standard libraries are unusable in OS context. Which means you need to reimplement everything yourself. However, that is probably not a surprise because traditionally, OSes have their own internal "standard libraries", developed just for these OSes. Ok, so only `box` allocates on heap via `alloc` crate? Everything else is stack only?
Yes, all allocations in `std` go through the `alloc` crate, e.g. `box`, `Rc`, `Arc` are defined there, and data structures like `Vec`, `HashMap` call functions from `alloc`. &gt; Which means you need to reimplement everything yourself. &gt; However, that is probably not a surprise because traditionally, OSes have their own internal "standard libraries", developed just for these OSes. Yeah, exactly. I think Rust has a better default situation than e.g. C, since there is a large chunk (`core`) of useful functionality automatically usable for very many situations.
I read somewhere that they want to finalize the bitstream format end of 2015…
Yes, if you want a language with control over memory allocation/layout and want to squeeze out the last percent of performance, Rust is probably the best option out there (when it reaches v1.0). However, in many ways it's not as convenient and powerful as Scala (or Haskell). The type system is less powerful for functional programming (no HKTs etc.), the object/module system is inferior to Scala's, lack of GC, far less libraries (if you don't count C libraries), much worse IDE's/tools ATM etc. But on the plus side there are no null reference/pointer problems, total control over memory management, specialization of **all** generic functions/data types (this is a real problem on the JVM, but there are some half baked solutions for Scala), native compilation (but you can run Scala on Android/iOS as well). For general programming where performance/latency is not crucial I would greatly prefer Scala, but for games or other programs requiring high performance and low latency Rust is a very good option (C++14 is not bad either though).
This is a shame.
It depends what you mean with fluent, took me a few weeks to get used to the borrow checker and being able to understand the API docs without having to consult external resources. But I dont consider myself fluent with rust, I just learn stuff when I need it. I think too many ppl read about rust instead of actually trying it. Just to port a simple program you wrote in another language to rust, thats what I did the first time.
I come from Java and its not the memory management that is a problem for me, its the Java way of thinking thats hard to get rid of. There is no interface, polymorphism or inheritance in rust, in the beginning you will really have problems thinking differently, well I did and actually still do.
 let (x, y): (i32, i64) = (5, 6);
Why do you think storing them in a vector has overhead? I think it's interesting that we focus on that -- the vector backing on the other hand means possibly better cache locality and much fewer trips to the allocator. What is the overhead really? The benchmark in [the ixlist repository](https://github.com/bluss/ixlist) shows that iterating this List is exactly as fast or a bit better than iterating a DList. This suggests that following indices in the vector is "the same" as chasing pointers in a regular linked list! For the iteration benchmark I'm using a randomly jumbled list (i.e. alternating adding to the front and the back). I suspect the Rc impl would be much worse, especially since you'd have to use RefCell.
Repository is here: https://github.com/bluss/ixlist I apologize, I should have included that link earlier.
I think that's the only answer there really is. Nobody's written huge programs in *today's* Rust. Sure, there's rustc itself but it's a patchwork hodge-job of pretty much every single Rust version ever. Nobody has a *clue* what idiomatic Rust looks like at a large scale. Nobody has any practice dealing with, say, lifetime quirks spanning multi-millions of lines.
A brief look over the code didn't indicate anything notably out of the ordinary, but it's 1AM here. Ping me on IRC later and I'll take a closer look. 
I don't write much Rust but I can say the benchmark implementation it's not really idiomatic. Like passing lots of &amp;Vec around.
[Maybe this PR that also changed some lifetime scopes](https://github.com/rust-lang/rust/pull/21657)
So, in your example: let Point(x, y) = Point(2, 3); Would that declare and initialize x and y to 2 and 3? Cool! But what would happen to the Point itself? It could probably have a constructor which would run and then the object would be discarded? Also, is the destructuring in variable declaration just syntactic sugar (i.e. a compiler trick), or does it carry a runtime overhead?
Closures weren't on the heap before - but you can have some issues switching from "boxed" closures to unboxed, if you move them downwards on the stack instead of passing references to them.
So how can a safe interface enforce this? It seems like the only option for insert is to either accept a static reference, which clearly is limiting, or accept a raw pointer and document the lifetime requirements which means the function should be unsafe.
You're asking about exactly how optimised that statement will be. You can pretty easily check for yourself: here's [the example on the playpen](https://play.rust-lang.org/?code=%23!%5Bfeature%28test%29%5D%0Aextern%20crate%20test%3B%0A%0Astruct%20Point%28i32%2C%20i32%29%3B%0A%0Afn%20main%28%29%20{%0A%20%20%20%20let%20Point%28x%2C%20y%29%20%3D%20Point%282%2C%203%29%3B%0A%20%20%20%20test%3A%3Ablack_box%28x%29%3B%0A%20%20%20%20test%3A%3Ablack_box%28y%29%3B%0A}). Click the "asm" button to compile the code and return the generated assembly. The relevant part is this: movl $2, (%rsp) leaq (%rsp), %rax #APP #NO_APP movl $3, 4(%rsp) leaq 4(%rsp), %rax #APP #NO_APP That's it loading the literal `2` and `3` into registers, then immediately discarding them (`test::black_box` prevents the compiler from optimising the variables out, without actually having to *use* them for anything). So the answer is: the `Point` never existed in the first place... *in this instance*. That's the problem with optimisation: it's hard to be certain whether it'll happen in general. Also, I don't know if destructuring constitutes a "trick" or not. In simple cases, it's the same as just reading the values out yourself. In complex ones, it can let you bind multiple non-copy values that you might otherwise have difficulty extracting.
&gt; Rust is probably the best place to learn it, as mistakes are caught by the compiler. For a purely learning exercise, I disagree. It's like the difference between having your parents tell you climbing trees is bad and fencing off the trees, and you climbing a tree and hurting yourself. Rust doesn't have garbage collected memory, but I wouldn't say it's manual either. The compiler handles allocation and freeing, and complains when it can't. That's very different from letting you handle it. As such, rustc doesn't really catch *manual* memory management mistakes. I suspect someone moving from C to Rust (what I did) would have a much better time than someone moving from Rust to C. Rust babies you, while C lets you learn your own lessons. If your goal is to learn about totally manual memory management, I think C is better. You need to actually manually manage memory to learn about manual memory management.
&gt; Rust babies you, while C lets you learn your own lessons. People have many different learning styles. This one isn't always appropriate.
I love C, and I think it's a great way to learn, but I think it's also important to acknowledge that you don't teach every child to swim by throwing them into the deep end of the pool immediately, unless the possibility of drowning is acceptable. (I'd hope it's not) To put it another way, I don't think suffering is inherently neccesary as first steps when learning. Sure, eventually, pick up C and feel some pain, but _requiring_ someone to start there just means you'll lose a large number of students who give up right away. Students need help to learn. Static analysis is an automated helper.
&gt; but I think it's also important to acknowledge that you don't teach every child to swim by throwing them into the deep end of the pool immediately, unless the possibility of drowning is acceptable. (I'd hope it's not) Yep, I definitely agree with this. &gt; To put it another way, I don't think suffering is inherently neccesary as first steps when learning. Sure, eventually, pick up C and feel some pain, but requiring someone to start there just means you'll lose a large number of students who give up right away. I don't think learning with C necessarily has to involve suffering, certainly not as a first step. Manual memory management in the style of C is dangerous by nature (hence Rust), so if manual memory management is what you're trying to learn you're going to hit it someday. I agree with you on the whole though - static analysis can help learning, and throwing people into the deep end is not a great strategy. I just think Rust is separated enough from "manual" memory management that C is a more worthwhile teacher. As mentioned elsewhere in this thread, if deterministic memory management is all you're after (rather than manual), Rust's a fantastic language for learning.
Yeah, I think we agree, we're just emphasizing different things. :)
It does complicate the internal design of the library, but it makes it easier to use as a crate because it's easier to call `.get()` on a `Future` instance if you want the value immediately than it is to construct your own if you want the value later.
I'd like to get started with Rust sooner, rather than later, but I don't want to start on any large projects only knowing the basic features of Rust. I've spent a lot of time reading technical articles and RFCs, trying to learn more, but at the moment I think I should go cold turkey on Rust until a good and comprehensive book is released, and stick with C++ in the meantime. I'm not saying the official documentation is bad, in fact I think it's fantastic compared to most open source projects.
As the one who made that change, I'd like to say that I'm sorry that it caused you such trouble. AFAICT, I copied clang's behavior, so I'd be curious if you see a similar problem when compiling C/C++ with clang without specifying a target (assuming that it's feasible to get a test case...). If not, maybe rustc can be improved to handle this better.
&gt; Manual memory management in the style of C is dangerous, so let's stop doing it. Also you can play with `malloc` and `free` and raw pointers from Rust. Implement your own `Box&lt;T&gt;` or `Rc&lt;T&gt;`. It's an instructive exercise and is definitely about manual memory management -- but also how to *abstract* manual memory management with a safe interface, which isn't something you get to practice in C.
&gt; Trying to incorporate so much assembly in a Rust project would be extremely difficult to do safely, and if it can't be proven safe, then essentially you've only duplicated the work of x264, so why bother using a Rust encoder? Yeah. However if you're writing a new encoder, for a new codec or because you need to replace x264 for some other reason, then I think Rust is a good choice. Inline assembly is still buggy in Rust, but I've done non-trivial things. I'm pretty sure we need a huge user such as a video encoder to shake remaining bugs out. In other respects it's cleaner and more pleasant than C, and you can still provide a C API.
Insert would surrender ownership of the object. You specify which list or lists you want to insert the object into. I imagine there would also be a way to insert an object that's already in one list into another list as well.
There are two industries that call their clients users: drugs and software.
I actually just pushed an [update](https://github.com/dradtke/mpack/blob/1cf2b143a256b7abe81806a9e6be6f44cdd06a07/src/rpc.rs#L83-L117) to my repo a little bit ago to support three different ways to get the response: synchronously, async via Future, and async via callback. They all have their pros and cons, but it's a good showcase of the various different ways to support an operation like this.
I had huge issues with the thread, as it was digging out a lot of things that don't make a difference and somehow forcing some people to make a statement about internals that I don't feel mattered.
Nice initiative! I would be interested to know if you found the time to compile rustc/run make check has gotten much bigger when running inside the VM. I would expect that to be the case for CPU-intensive jobs such as this, but maybe I haven't been following virtualization technology close enough :) 
Maybe off topic in /r/rust but I don't think the C++ is correct in terms of standards compliance. `reinterpret_cast` does not make any guarantees that the bits of the LHS will be related to the bits of the RHS. All it guarantees is that if you reinterpret *back and forth* then you get the same bits. What you need is a `memcpy`.
That's great news! Thanks for pointing me to it! :)
So, I have found it to be somewhat larger, but not incredibly larger. I think that some of the better virtualization providers (vmware) should be pretty close in performance. I may follow this up with a dockerfile, which should provide pretty close to native performance. 
Chuck Norris beats borrowchk and syntax every time. Mortals have to use #rust at least from time to time.
Dude I haven't been able to sleep properly for like two weeks; just have to try this experiment in Rust?; what if XYZ is a great way to optimize rustc?; dude what if vector indices is the solution to all rust collections? ;-)
No worries. It has taught me that you actually need to tell a processor (at boot) to enable SSE features. With that, I could again use the rust target cpu. I have never written a kernel in C, so about the llvm options I wouldn't know.
You could add a &lt;meta name="robots" content="noindex,nofollow" /&gt; to the archived page to make sure it doesn't show up in search results.
That's my plan. Going to make a game networking library. 
Yes, the only docs are the RFC :( My priorities for "recently done and has zero docs" was basically * threading * closures * associated types Been finishing up #1 and working on #2. I'll get there :/
&gt;Yeah. However if you're writing a new encoder, for a new codec or because you need to replace x264 for some other reason, then I think Rust is a good choice. I agree. Rust would be an excellent language with which to write a reference implementation of a new codec, or a similar computationally intensive project. Even if parts of the codebase must use assembly in order to perform well, the rest of the code can be written in Rust, which I would prefer much more to C/C++. 
Cannot tell you how many times I was sad that I couldn't simply call `std::cmp::min`/`std::cmp::max` on a couple of `f32`/`f64`
Lest anyone get the wrong idea: I suggested this to him yesterday after dropping by, and was about to mail the mods today to suggest the same. I figured the mods and most of the thread participants had no desire to cause any pain or reputation damage, and that his preferences (to quietly disengage from something that had stopped being enjoyable) would probably be understood and respected. Personally I've no attachment to that conversation, would just as soon it was recycled as more constructive bytes.
This is what `partial_min` and `partial_max` are for :) If you *know* it can't be `NaN`, `unwrap()` it! If you don't, Rust just saved you from potential bugs.
Currently working on a path tracer in rust. Rust works pretty well, because after you've created the scene, you can pretty much treat it as immutable and pass stuff around as Arc-refs
It was a little bit ago, anyway. The price will fluctuate as people list copies, as it's a reselling site like Amazon. Edit: Sorry, wrong sub. Deleted.
&gt; Personally I've no attachment to that conversation, would just as soon it was recycled as more constructive bytes. But, [supposing the bytes remember the words they had encoded...?](https://books.google.com.au/books?id=WzUFi46vNHwC&amp;pg=PA40&amp;lpg=PA40&amp;dq=discworld+the+truth+%22supposing+the+metal+remembers%22&amp;source=bl&amp;ots=mAnLnI8TUJ&amp;sig=6E7JCzpT4kD8uU3kK2OYsx6q8lk&amp;hl=en&amp;sa=X&amp;ei=KzTMVNqQH4G8mQW8l4DIBg&amp;ved=0CB0Q6AEwAA#v=onepage&amp;q=discworld%20the%20truth%20%22supposing%20the%20metal%20remembers%22&amp;f=false)
&gt;How do I declare a feature which only applies when `#[cfg(test)]` is in effect? Replace `#![some(attr)]` with `#![cfg_attr(test, some(attr))]`. [Source](https://github.com/rust-lang/rfcs/blob/master/text/0194-cfg-syntax.md#detailed-design)
Permission was gotten from all members of the conversation to post this. Things I'm going to note is that the book didn't explain it well enough to given even a basic explanation of what they are, and even people who think they know what lifetimes are, are getting confused. It'd be really nice to have some educational effort spent on determining the best way to teach lifetimes.
куда ты постишь, чучело)
I wrote this (extremely simple) library because ID creation should never have a noticeable performance impact. However, on my machine, generating random 64bit IDs (not guaranteed to be process-unique) takes 66ns, generating time-based IDs (again, not guaranteed to be process-unique) takes 20ns, and generating IDs using a global atomic unsigned integer takes ~11ns. This library combines a global counter and a thread-local counter for average case ~1ns ID generation.
Awww, I'll be out of the country still. Good luck!
Your first example ('`Illegal, foo is still borrowed`') has happened to me a lot. `Sharp` mentions how introducing a new scope would fix it: &gt;1-30 07:30.59pm &lt;Sharp&gt; lahwran: That's why the borrow checker makes you do dumb things sometimes, like randomly introduce scopes {} &gt;1-30 07:31.16pm &lt;Sharp&gt; lahwran: Because it can't handle anything but a simple enclosing scope. ..and a new scope does fix it, but why is it that even though `.borrow()` doesn't need `foo.value` anymore, and `println!(foo.value)` doesn't need it anymore, I can't say "Yes, I borrowed this, but I am done with it now." without introducing a new scope? I'm sincerely asking if anyone has given any thought to the "dumb things like randomly introducing scopes" thing. I don't know enough about this language to suggest any alternatives. I just got my first little project to recompile with `1.0.0-dev` after a long break (only 64 unstable warnings).
I have written several of these (...erm... One per distro since I started bouncing back and forth on this laptop...)--obviously not *nearly* as complex as this one (I wrote them while everybody was grabbing snacks before the game!), but it's cool to know I wasn't the only one who considered it. It looks like you use the same basic approach (I think that gen_range() thing is actually straight out of the guide book thingy, so that's no big surprise, right?), so here's my question (because I know nothing about how these statistics shake out): I'm guessing that, for your application, which sticks around in memory in between rolls, this is totally kosher... But what about an application that runs and then vanishes from memory? Will this gen_range() thing give decent quality randoms when it spits out only one value before the program closes and starts up again?
Definitely interested. I wrote a baseline h.264 encoder several years ago (not in Rust) and I'd like to take on a baseline decoder too.
&gt; the book didn't explain it well enough to given even a basic explanation of what they are, I'm a fan of getting feedback on my work, but please try to keep it somewhat constructive. Reading this post and conversation was really hard for me. There's good stuff in here, but it's wrapped in a lot of dismissive-ness.
I see, plenty of people already on the case. Good to know :)
I've not had the time to track the frequent language changes as Rust stabilised. I hope to pick up development again after Rust 1.0 is released.
Why SHA1? I don't want to be alarmist, but SHA1 is not on a good trajectory. Perhaps you could focus on, say, SHA256?
Is this Twitter's algorithm?
&gt; I'm trying to print contents from a mod (are they just like classes?) with an enum into the main method. `mod`? That's a module, they're namespaces, they have nothing to do with classes. Rust doesn't have a direct analogue to classes, though a `struct` plus a trait can feel like it sometimes. &gt; I keep getiing trait 'core::fmt::show' not implemented in list::list Two things: Idiomatic naming conventions would be pub enum List { Eggs, Fruit, Snacks} And, it's true, you don't implement the `Show` trait. You implement itself, impl std::fmt::Show for List { fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result { match self { Eggs =&gt; write!(f, "Eggs!"), Fruit =&gt; write!(f, "Fruit?"), Snacks =&gt; write!(f, "Snacks@?!@!"), } } or, you can use `String`: #[derive(String)] pub enum List { Eggs, Fruit, Snacks } and fn main() { println!("{:?}", list::List::Eggs); } `Show` and `String` have been re-named to `Display` and `Debug` as of sometime last week, so when you update your Rust, you'll need to use those instead.
Here's a tricky one that took me some time to understand: struct Foo&lt;'a&gt; { str1: &amp;'a str, str2: String, } impl&lt;'a&gt; Foo&lt;'a&gt; { fn test(&amp;mut self, s: String) { self.str2 = s; self.str1 = &amp;*self.str2; } } This code fails: error: cannot infer an appropriate lifetime for lifetime parameter 'a in function call due to conflicting requirements help: consider using an explicit lifetime parameter as shown: fn test(&amp;'a mut self, s: String) Now if I do what it says, what happens? What's the difference between `fn test(&amp;'a mut self)` and `fn test(&amp;mut self)`? Well, the `&amp;'a mut self` means, if I understand things correctly, that self.str1 borrows self for the lifetime of self, which effectively makes the object unusable! Which is probably not what you want. What you want is probably to tie str1 to the lifetime of str2 somehow, and promise Rust that whenever you update str2 you will also recalculate str1. But I don't know if that's possible to express safely in Rust..?
Getting a job requires social skills as well as technical skills. Somebody who is extremely productive but stops the people around them from doing *their* jobs is not preferable to somebody who is moderately productive and helps the people around them do their jobs better. Part of what it means to contribute to an open-source project -- in fact, to any software project -- is to share ownership of it. If you cannot abide the thought of writing code, only to have somebody else remove it from the project later, it might be a better path for you to work on your own projects without collaborators. Personally, I find the rewards of working with other people (and most people *are* fun to work with) to far exceed the pain of having my contributions get superseded or made obsolete. 
Sorry, I actually haven't read that section on the book in months to give constructive feedback. I was more saying that in this specific instance, the book did not instill enough information into the two readers to get the big idea. Don't take it too harshly, as untyped lifetimes are a new concept to many people outside of the C/C++ community and typed lifetimes are new to everybody, so getting teaching materials right for everybody is a hard problem, though a good problem. I've read your documentation quite a bit, and it's always been helpful and understandable for me.
For anyone else who needs to fact check "right to pseudonymity," here is a link: https://www.eff.org/issues/anonymity While I'm in favor of protecting that right, I also think using pseudonyms deliberately to protect your reputation while flaming someone is an abuse of that right. People who do so should expect to be taken less seriously and politely encouraged to invest in one reputation. Would "Please don't use multiple pseudonyms in this community" be a valuable addition to the CoC, or would there be no point because it's unenforceable?
At least on Windows, it's installed with the compiler.
Probably somwhere in `/usr/share/doc/rust/html` or a similar directory.
It's at /usr/local/share/doc/rust for me. 
Thanks for explaining. I think the pieces that I'm missing is seeing things clearly in action. Now, I'm someone who hasn't worked with static languages professionally for over five years, so I have a handicap to begin with, but one thing that I find myself wondering so often when trying to learn Rust is that I never know how to do what people say I need to do. So, `bar` borrows `foo` in the above example. I cannot assign to `foo` until `bar` is gone. That's fine, I can understand that. But how do I work around that? How do get `bar` to go away? If I can't, how would I restructure my code so that it's not a problem anymore? I feel like the "by example" type things are lacking when it comes to documentation, especially regarding errors that are a bit confusing but also common. I guess that also includes nomenclature and methodology that is mostly rust specific. Or, if they do exist, they're not easy to find.
inner blocks usually: fn main() { let mut foo = Foo { value: 100u32 }; { let bar = foo.borrow(); println!("{}", bar); } foo.value = 200u32; // bar no longer exists, now fine to do this } You can also explicitly use 'drop(bar)', but Id argue thats less idiomatic and generally speaking a bit weird.
The issue is that floats do not have a total ordering, as `NaN` != `NaN`.
Excellent! That was better than what I was hoping for.
Oh yes, there's so much to do. All I meant to say is that determining what is 'common' is very hard, because we don't have a ton of data. Each individual will have different 'usual's, and they're shaped by our experiences. I'm extremely interested in collecting experiences like yours, because they help us figure out what the common case even is, so that we can then improve in exactly those ways. The post I responded to and this one are both _extremely_ helpful in that process, so thank you. (oh, and I didn't write Rust by Example: we inherited it from the community. It was abandoned for a little bit, and was always patched together by a number of people, so it will be quite rough in places. I have it on my list to go through it all and double check things and make it more cohesive, but I haven't found the chance to yet.)
That part of rustbyexample is simply wrong now, obsolete by the addition of additional lifetime elision rules for function signatures. If there is only a single reference as argument and a single reference as return value, you can elide the lifetime names and the compiler will assume that you meant to have them linked. If you have more than one reference argument, or return more than one reference though, then the compiler will complain about not knowing what you meant.
It is something that is, in a fundamental sense, impossible with something in the shape of the language at present. Consider traits versus C++ templates; trait bounds let you prove something acceptable categorically, templates let you try doing all sorts of things which will mostly work, bit somewhere along the way you might hit a tiny snag and all of a sudden the whole thing falls apart. Similarly, any attempt to allow references to siblings would require a redesign of the object model away from one of coherent objects where an object is an object and anything inside it is opaque, to one where you actually need to know what is inside an object and how it is used in various places before you can reason about what you may or may not be able to do. I really can't see Rust ever heading there—it’s just so radically different a philosophy.
Thanks, that seems to work beautifully.
Thanks for sharing, keep it up. I also find it a struggle at times to get to grips with Rust’s way of doing things, so it's good to another’s thought process when hitting similar problems.