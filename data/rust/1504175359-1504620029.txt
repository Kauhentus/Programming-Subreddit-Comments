Looks really nice. I took a look at circular. Shouldn't it have a different name? Perhaps I missunderstood the implementation, but from a quick glance it seems to implement a queue/buffer hybride with amortised movement of the data. The main point of a circular/ring buffer is to provide O(1) insert/removal and this implementation does not seem to do that. If you want to combine buffer reading with a circular buffer, the fastest implementation of it is to do a normal circular buffer implementation, then map the queue's memory twice in a row.
There has been two major choices: to not use wildcard at all, or use it when imports are spanning too long. FYI, in the Java community IntelliJ IDEA has the defaults of collapsing (turn into wildcard) the imports at the amount of 5, and some also choose to disable it. (reference: https://stackoverflow.com/questions/3348816/intellij-never-use-wildcard-imports) Regarding function and module, my rule is basically: - for functions, import the parent module. - import structs (and other upper case prefixed types) directly.
I semi-strongly prefer the 'before'. EDIT: Downvotes for sharing an opinion? Great
You don't need GAT to use HKT (at least for use cases like this). GAT only makes it slightly more convenient as long as you don't have any trait bounds on the HKT, then both the current syntax and the GAT syntax become equally bad again (which is where HRTB would need to be extended). There might be uses cases that GAT enables, but ContainerFamily, SyncFamily, LockFamily, PointerFamily, ... are all already possible.
&gt; Just FYI, that article is flat out wrong on (at least) several of the C# examples. I'd challenge that statement, just based on the fact that I'm _quite_ positive that Tomas knows wtf. ;-] &gt; Correct me if I am wrong, but rust generators seem to be far more similar to C# IEnumerables (using the yield keyword). Yes, they are, exactly; who said otherwise?
/r/rust only has one skin type and that is calcified orange crust /r/playrust may be more informative
In Go all blocking operations implicitly cause (from my simplistic understanding) the calling coroutine to be parked, IO to be performed on IO threads, and a coroutine that's ready to be run to be scheduled by the Go scheduler. As the developer you've no idea of any of this.
I'm using https://github.com/flier/rust-mqtt to good effect. Passing around decoded packets gets complicated because the `Packet` struct only stores references to strings it parses out of the packet bytes, but that means that it's also zero-copy.
Oh my wrong, i am sorry
If you're feeling particularly silly you could wrap your `Arc&lt;T&gt;` in `Rc` for a beautiful/horrible `Rc&lt;Arc&lt;T&gt;&gt;`. You pass the `Arc&lt;T&gt;` to other threads, but "inside" a thread you immediately wrap it in `Rc`, so you have only a single atomic increment/decrement per thread, and non-atomic reference counting "inside" each thread. Depending on how often you are cloning those handles the double indirection *might* be worth it.
Sorry, but what is a GAT? Google has no results.
This is... a good idea? I think it is! Would it still be good if T were a Mutex&lt;T&gt;?
The article is accurate on all of the C# examples. You are however understanding the async keyword correctly. The problem is that some developers don't understand the async keyword correctly and screw up using it in C#. The design of the async keyword is what leads to these problems whereas the F# design of async does not lead to the same issues.
I'm 100% certain Rust doesn't have HKTs. Can you provide a code example that compiles?
[Generic associated types](https://github.com/rust-lang/rfcs/pull/1598)
In case you don't know, you can also use symbols without `use` at all; the `::` prefix marks an absolute path: println!("{}", ::std::u64::MAX);
I'm not sure how I could prove it to you, it's really best just to try them yourself. Clearly no one said otherwise, I just wanted to point out that if you want to compare Rust's async pattern to something in .Net, the relevant concept would be IEnumerable, not async/await.
It probably wouldn't be, because the `Mutex&lt;T&gt;` is performing atomic operations anyway each time you lock it, so an extra atomic increment and decrement here and there wouldn't really make much of a difference. But the only way to know for sure is to benchmark!
Good point. I guess if you had a Mutex that was *really fast* under no contention, and a use case to match.
Also, since I happen to know the answer, I might as well tell you. The first time you start Rust, they randomly generate a skin color and tie it to your Steam account. You can't change it. (So there are many colours of people and it wasn't their decision... just like in real life.)
oh ok thx
&gt; it's really best just to try them yourself. I have. What's the problem..?
Oh, TIL you can `use` within a function.
A function body is zero or more statements followed by an optional expression. Statements can be items. `use` is an item. Therefore, you can use `use` in a function body. Rust is really quite pleasingly consistent.
If you had that you could use it to make Arc similarly fast too.
The cost of an `Arc` has nothing to do with branch prediction, but with the fact that it imposes sequential memory consistency.
The banner server thing is interesting. From the comments: &gt; Resources like This Week in Rust are great, but it seems that there is a need for some official Rust new source. I propose that this be called [Izvrustia](https://en.wikipedia.org/wiki/Izvestia). 
**Izvestia** Izvestia (Russian: Известия; IPA: [ɪzˈvʲesʲtʲɪjə]) is a long-running high-circulation daily broadsheet newspaper in Russia. It was a newspaper of record in the Soviet Union from 1917 until the dissolution of the USSR in 1991. The word izvestiya in Russian means "delivered messages", derived from the verb izveshchat ("to inform", "to notify"). In the context of newspapers it is usually translated as "news" or "reports". *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
Just to clarify : utf-8 is not involved here. A char in Rust is a 32 bit value representing a unicode value, independant on the actual encoding. Any u8 value is indeed a valid unicode value, and the as operator just performs a direct cast.
I would make a type that should be able to use `Rc&lt;T&gt;` or `Arc&lt;T&gt;` generic over `AsRef&lt;T&gt;`. In that case, it will even work with a simple &amp;T.
If you wanted to share an opinion, you probably should have put some more explanation into it, because as it stands it's not contributing to the conversation really. I'd be curious as to your reasons why.
My opinion doesn't contribute to the conversation? Thanks! &gt; The ergonomics are so much better here, it's astounding! Zero "explanation" here, yet I didn't downvote despite the fact that I don't see it as "more ergonomic". &gt; I'd be curious as to your reasons why. My reasons have to do with locality and limiting scope, and avoiding excessive shadowing. But I wouldn't want to risk contributing. :-]
This may not be full on HKT as GAT provides (I'm not aware of any cases, but there may be), but it definitely allows writing libraries that are generic over ContainerFamily and co. I set up a little slab-like container in the playground, that can be used with both Vec and LinkedList. It uses those internally for the slots and additionally counts the allocations per slot (just so we can see that it can instantiate the container differently multiple times). main then uses the default new constructor, which instantiates a Slab using Vec internally, and later on main creates another Slab, but this time one that uses LinkedList internally (and str slices instead of i32). https://play.rust-lang.org/?gist=e29150c80d38074be5642f4bc451830e&amp;version=stable Again, this may not be full on HKT, but it's definitely enough for these cases.
All u16s are also valid right so why can't you cast a u16 to a char?
Borrowing across an await! is different to borrowing across a normal call, so borrowing errors might be more confusing if you don't know where the awaits are.
&gt; I'm confused by the message. I understand that the value is not a valid character, but I thought char was 4 bytes, so where does u8 factor in? It should be noted that _if_ you managed to get an invalid character into a char which can only be done with `unsafe` that using it for almost anything is undefined behaviour. The standard library assumes that every `char` falls within a defined unicode scalar value. You can definitely do `const XYZ : char = unsafe { mem::transmute (0xEF8888u32) };` if you so desire to get itin there but even using println on it is undefined behaviour then.
Sure thing. I can give you the high level, and if you need more details you can pm me. If you think about what a spellchecker does, it tests every word in a sample set against some database of words that it knows to be spelled correctly. If the word isn't in the database, it is because of one of two reasons. 1. The word is misspelled, or 2, the database hasn't been populated with that correctly spelled word. So how can we efficiently look at every word in a sample and then compare it to every word in our dictionary? One approach would be to put all of your dictionary words into an array, and loop through them for each word. It could work, but I think there is room for optimization there. The way you optimize it is you put all of your dictionary words into an index. An index is basically a tree type data structure that can quickly test whether a sample word might exist in it. There is a more advanced class of indexes which can match in a fuzzy way, and also recommend spelling correction options. This is what is employed by most word processors, IDE's, browsers, etc. There is another class of spellchecker which is an auto-complete "live search" this is what you see when your IDE or search bar auto completes your words for you by guessing what you're typing. It accomplishes this in a similar way as spellchecking, but uses a different data structure which is optimized to find the end of the string given the prefix (that you've started typing). It is up to you to determine how advanced you want to get. I don't want to do all of your work for you, but if you start googling and researching spellchecking, you'll find a wealth of knowledge, and the algorithm mentioned most often is aho-corasick for building an index of candidate strings for matching. A ternary tree is often used for the auto-complete style of index, but can be used for testing whole strings as well. After you have researched these topics a little bit.. I'd recommend maybe making a basic, naive spellchecker using an array of words to do your tests.. then see if you can make it better. You can find a list of words to build your dictionary here http://wordlist.aspell.net/
Effectively you'd be writing a 'screen' or 'tmux' replacement. There are some interesting applications of this if someone has a library to do it, e.g. automation of console applications that weren't designed for that. (I don't know of any suitable library myself.)
Some general rules of thumb that are (almost) always applicable. * Divide standard library imports, third-party imports, and local crate imports into separate chunks of `use` statements, spaced with a newline. * You can freely import most if not all `std` names. * Use wildcards only on modules that are intended to be imported this way. Some libraries have a (small) baseline collection of symbols -- typically with a module called `prelude` -- that you are supposed to star-import. For other stuff, import it in such a way that they can be unambiguously attributed to their source whenever you use them. This rules out things like `use serde_json::from_str;` -- either refer to it as `serde_json::from_str`, or alias it via `use serde_json::from_str as from_json;`. In other cases, when a name is sufficiently unique on its own or just common (like `Regex` from the `regex` crate), it's perfectly to import it w/o namespacing.
Nah I get it... But any help would be appreciated if I get stuck :) &gt;There is a more advanced class of indexes You talking about trees and hash algorithm?
I never meant that, my bad. There is way more help available for C++ or Java, and one of the best resources for Rust help is this subreddit... I can't go probably elsewhere :(
I like it.
Well I'm new to Rust and learning it, and I love it compared to other languages. Java looks like cancer, C++ is still good.
You might want to find a small example that shows the problem. https://stackoverflow.com/help/mcve
Interesting. You've used higher-ranked trait bounds to create something similar to GATs :D The difference between this and GATs is that with this solution, the container family provided doesn't need to be generic, and you need to state every type you want to be able to put into it in a `where` clause. Also, I'm not sure about the expressiveness of your code. It looks like it should allow you to do everything GATs allow you to do (e.g. a generic `map` function); which would be quite impressive, but I haven't tried yet.
You were correct, I apologize, I have edited my post to say such.
I've experimented a bit with CEF as well, trying to port an old nightly crate from 2015. I've got it launching a CEF window on Windows, macOS and Linux and navigating pages fine, but there are a lot of work remaining to cleanup and resurrect code that I commented out to get things compiling on stable rust. It is very much a work in progress and not ready for production use, but feel free to pitch in if you have the time: https://github.com/anderejd/cef-rs 
So why one RFC instead of splitting it, one for the changes to `use` one for `pub`?
My understanding is that atomic operations can also mess with compiler optimizations, so the impact may go beyond just the cache misses etc. Feel like I heard that a long time ago - I would be interested in hearing more details if anyone knows.
If I bundle up some data in a struct so that I can pass it around in one block (for example as a context for some algorithm), is there a point in giving each reference a distinct lifetime? struct Context&lt;'a, 'b&gt; { stuff: Stuff, something: &amp;'a Something, other_thing: &amp;'b mut OtherThing, } vs struct Context&lt;'a&gt; { stuff: Stuff, something: &amp;'a Something, other_thing: &amp;'a mut OtherThing, } And usage often looks something like this: fn do_a_thing(smth: &amp;Something, other: &amp;mut OtherThing) -&gt; Outcome { let context = Context { stuff: Stuff::new(), something: smth, other_thing: other, }; context.do_the_thing() } The only difference is if I want to take those references out of the struct, right? If I'm not gonna do that, then I can just give everything the same lifetime? 
Much of this stuff builds off of each other, so it makes sense as one RFC. That is, it's *really* hard to see the big picture when you're only looking at each individual piece.
I suspect something else, /u/shaqhacks: is `a` a public module? If not, `cool_function` is not actually public to the world.
I'm currently handling downloads (streaming) on one thread, and uploads in another, how should I structure my program?
&gt; How context dependent are they, Performance is highly dependent on how much competition between threads there is. If there is high contention for an atomic variable performance is going to be awful.
I think `.await()` would be better than a macro (if a Future is even a trait?). Then a future result could just be 'result.await()?' etc. Macros just 'feel' hacky for something that is as crucial as async.
This looks really awesome - I'm going to think twice about my hand-written C-&gt;Rust bindings now...
May I ask why?
So this is the polar opposite of `bindgen`? What currently does not work?
We just announced [the lineup for Rust Belt Rust 2017](http://rust-belt-rust.com/sessions.html) and we'd love for you to attend! RBR2017 will be in Columbus, Ohio on Oct 26 &amp; 27 2017. [Tickets for both days are on sale](https://www.eventbrite.com/e/rust-belt-rust-conference-2017-registration-36237335847) for $200 for general admission and $75 for students. The first day includes workshops, a RustBridge, and an unconference, while the second day is packed full of talks and opportunities to interact with your fellow Rustaceans.
Yes, you can give all references the same lifetime and you probably won't feel it
In python, doing so would actually be impossible, because finding out what the next value is requires executing arbitrary code inside the generator to decide if it reaches a yield or a return, which contains the decidability problem. The only real option I could see is something like a "peek" wrapper, like for iterators, that stores an optional buffered value, and keeps the generator one step ahead of the output values.
True that! As someone who bernt out of the conversation when it was still in internals I just got to thinking, the conversation around modules got more productive when we split it into two smaller ones. This rfc one and the un-published one. And so I was wondering if it could have been made smaller still. Congratulations to those who stuck thure and made this hapen.
&gt; atomic operations can also mess with compiler optimizations This is correct. Atomic operations (usually) place some kind of restriction on how instructions can be reordered.
&gt; So this is the polar opposite of bindgen? That's what it seems to say: &gt; (See also the popular bindgen project which works in the opposite direction.)
The recently merged generator support is still experimental but it was added to the Unstable Book (although the book itself wasn't updated yet to contain the new chapter). [Here's](https://github.com/rust-lang/rust/blob/6f7594d50679c2513d2daf2c75b38e1a4fc20823/src/doc/unstable-book/src/language-features/generators.md) the documentation from Github. You can also find some information in the [RFC](https://github.com/rust-lang/rfcs/pull/2033) and the merged [pull request](https://github.com/rust-lang/rust/pull/43076). EDIT: [this post](https://internals.rust-lang.org/t/help-test-async-await-generators-coroutines/5835) might also be helpful.
How does this compare to [rusty-cheddar](https://github.com/Sean1708/rusty-cheddar)?
It makes you wonder...if it's that easy, why don't we have an `AtomicF64` out of the box? Does it just need to be implemented?
These are really interesting arguments. The rust compiler already does *significant* code transformations and we don't bat an eye. I think it's a matter of perspective and familiarity. Maybe in ~10 years we'll all be used to this and someone will create a language that will be *radical* and you won't have to specify this transformation. I wonder why evolution of programming languages happen in small steps, so slowly. About your second point, these categories should not matter when you are writing an algorithm. I think these are architectural decisions. When you write code like this: let a = foo(); bar(b); all you express that foo() will be executed and it returns something and then bar will get that something. This is a high level view of the algorithm and it says absolutely nothing about the execution and I think that's a good thing. The same algorithm is used when foo() blocks and when foo() happens to be asynchronous. I think when you write your code all you should worry about what you use and what you provide to your callers. It should not matter how someone will use your code (in a sync or async way), it should be fully transparent. But I understand that many people have strong feelings about this and maybe it's a too big step for rust.
&gt; Depending on how often you are cloning those handles the double indirection might be worth it. I suppose it's possible to write a `RcArc&lt;T&gt;` type with four counters: two for the unsynchronized part and two for the synchronized part, but without a double indirection.
The semantics are different. You can't do floating point ops atomically. You'd have to convert to bits, do your op, then CAS back. 
You can define types inside a function, implement a trait for them, return the type, and say the return type is `impl Trait`. [Well, on nightly](https://play.rust-lang.org/?gist=cdb22f5813ad78db96967d5d2a9e33ef&amp;version=nightly).
I played a bit with the python gstreamer bindings, and I had to use [`util_set_object_arg`](https://lazka.github.io/pgi-docs/#Gst-1.0/functions.html#Gst.util_set_object_arg) to use plugins' enums without having access to the actual enum. How would I do this with this crate? I found the function in `gstreamer_sys`, but it needs a `*mut GObject`, not an element.
I was reading it on Reddit's android app, and for some reason it was only displaying the wasm javascript code. When I finally got home was already too late to fix my dumb comment.
&gt; Generator support Woot! Is this a pre-req for async/await having nicer syntax? They seem closely related.
Yup, it's pretty nice for examples, tests, etc. I see it used quite a bit on shared code on this subreddit, and I'm guessing it's also used quite a bit with conditionally compiled functions.
You can use [GObjectExtManualGst::set_property_from_str()](https://sdroege.github.io/rustdoc/gstreamer/gstreamer/trait.GObjectExtManualGst.html#tymethod.set_property_from_str) for this (i.e. `your_element.set_property_from_str("prop-name", "the-value")`). I assume this is for flags/enum properties where the type is not available in bindings? For these cases you can also use more safe API (with error reporting, etc), as in [this](https://github.com/sdroege/gstreamer-rs/blob/15d05ed3ac10c838baa159835188f22acbb95be6/examples/src/bin/playbin.rs#L24) commented out code. For `gstreamer_sys`, that's the unsafe FFI bindings and you should only really fall back to them if there's no other way. But then you can use the translation traits from `glib` to convert to raw pointers (e.g. in this case `your_element.to_glib_none()`, which returns a tuple struct where the 0th item is the raw pointer).
... or its successor [rusty-binder](https://gitlab.com/rusty-binder/rusty-binder)?
&gt; Java looks like cancer Hey now, watch out for the "No zealotry" rule. We all like Rust here, but please don't badmouth other languages. To build on what /u/coder543 said, [there are other avenues for help as well](https://www.rust-lang.org/en-US/community.html), such as a IRC channels. Try a few and see which medium you like best. Good luck and have fun!
Yes that's it. I wrote a program to convert my audio library to 64k vbr opus, and couldn't use [GstOpusEncBitrateType](https://gstreamer.freedesktop.org/data/doc/gstreamer/head/gst-plugins-base-plugins/html/gst-plugins-base-plugins-opusenc.html#GstOpusEncBitrateType) directly. The bindings look really solid, I'll rewrite my encoder with this.
A single 0x80-0xFF value is not itself a valid UTF-8 byte, but it's still a legal codepoint in a (u32) char, translated to two bytes in UTF-8.
I'm currently on mobile so the only advice I can give without more information is: Diesel's Gitter room is pretty active :)
Due to the pace the RFC is progressing I wonder: At which date and time was the podcast recorded?
Yesterday. Normally the episode is released a few hours after recording, I was just busy yesterday so I finished it at night.
Considering that we already have `.wait()` which blocks the thread, these 2 methods would probably confuse new users.
Hey, thanks again for digging into this with me. No a is not a public module. I had originally made the function `cool_function` public in order to access it from b, however that resulted in the warnings I am now trying to make go away.
Good stuff :) Minor spelling fix: s/becuase/because/g
The associated constants and functions I think are huge in making this language easier for people from other object-oriented programming languages to adjust! Huzzah!
I thought I fixed this :( Fixed in https://github.com/rust-lang/blog.rust-lang.org/commit/01dba4b16aa51b0922053a5ef8a96a1bc8466b9c, thanks!
Yes! So that's your problem. The lint is transitive, that is, if it gets used, but only by functions that aren't used, then it will also trigger the lint. Is b public or used?
You can use https://github.com/iron/router and its `url_for`https://docs.rs/router/0.5.1/router/macro.url_for.html
How would you distinguish cross-thread sends from within-thread clones then?
Perhaps make it not `Send` (and clones will increase the unsynchronized counter), but add a `.send_cross_thread()` method that returns a zero-cost wrapper (just `struct Wrapper(myrcarctype);`) type that implements `Send` (and *its* cones will increase the synchronized counter). It's like the `Rc&lt;Arc&lt;T&gt;&gt;` =&gt; `Arc&lt;T&gt;` transformation, but without following a pointer.
True, but couldn't/shouldn't spawned processes be async as well? So `.await()` would replace`.wait()` in that case.
b is used in this case as part of an external function in our lib.rs. Edit: Looking at it now there are many modules(c,d,e,etc.) that have similar behavior and uses as b, but only b is throwing errors. It might be a problem with b. In my lib.rs should I be exporting b as part of an `pub extern fn`? http://imgur.com/a/C2QOS &lt;- in this case b would be the one using the match nodes::containing_block
Another one: unweildy → unwieldy.
&gt; `Take::get_mut` I thought for a second that `take_mut` crate is now standard! On a more serious note, good stuff with associated constants. I also _really_ like `compiler_error!`. There has been at least one situation recently where I had to resort to just panicking on unsupported `cfg`, which is obviously better to catch at build time.
&gt; In my lib.rs should I be exporting b as part of an pub extern fn? No need for extern, it would just be `pub`. 
I'm interested to learn the answer of this. This use-case is one that I am definitely eying for future(sadly not near) implementation, so I would like comparison information for reference.
Thanks. Gah!
Well, he already says he understands it isn't a valid character; the question was about the confusing error message. Probably something like `0x1F63B` would have been a better choice for the post, I suppose.
I was looking for exactly this feature a week ago for an image decoder I was writing. It's awesome news. 😃
`impl Trait` when ;_;
One of my colleagues said it looks like the `wasm` backend was enabled but not mentioned in the release notes. Is that true?
Because `value` is a `&amp;mut` reference. LL intuition: "calling `.get_mut` locks the map for writing during the `match`" Non-LL intuition: you must finish your business with the mut reference before doing anything else with the map."
It's in the release notes, but not the blog post. For more: https://github.com/rust-lang/blog.rust-lang.org/pull/192#discussion_r135879041
Quick question: is it currently possible (or planned) to allow the resume call "return" a value *to* the generator? I.e. calling gen.resume(42); would cause x to be 42 in let x = yield; Redux-saga for example uses something like this for handling side effects. It might be useful in general to allow the caller to give the generator some new inputs... Does anyone have any insights if that is on the roadmap or even compatible with the ownership/borrow rules?
With tokio, I'd do one stream/Future for downloads, and one stream/Future for uploads, then call `core.run` on a one of those futures joined with the other. You can think of a Future as a chain of execution - almost like a thread, but completely paused and stored as a state machine when it's waiting on IO.
Sorting r before p is a bold move from the Rust language designers but I think we can all agree it will pay off in the long run.
Has there been any progress on main result rfc?
It was accepted, but has yet to be implemented.
Note that it explicitly said sorting on the first letter only.
The comment struck me as a joke, which made me chuckle a little.
It had that strange thing where exit code was 2 right?
Thought that article will be about binary size reduction...
&gt; As you might imagine, less constraints often means faster results. If you don’t care about stability, these sorts may be faster for you than the stable variants. This is why I always reach for a nightly toolchain whenever I need to sort things fast.
I misunderstood what the OP was saying, actually, because I was a little worried that this particular subtlety would be lost. I did giggle at it though. And [merged a PR](https://github.com/rust-lang/blog.rust-lang.org/pull/194).
That's an "unresolved question", to be determined in implementation. Seems that most want it to be 1. (I do.)
Ok that was what i was afraid of Thanks for the response!
That's kind of a weird use case. Maybe you could change the example to use tuples sorting on only one element?
Ahhh I can't come this year and I'm so disappointed. I hope everyone has a great time!
Three years for that RFC to be kicking around, glad to see it see the light of day. That could be a good topic for the podcast. `"Old" RFCS that are still coming and where are they now.` Especially for those of us that keep up with Rust now, but not back then.
You want r/playrust
It seems like more of a pit of success type issue. `Promise.all` or the `await *` syntax would be fine, but the ecosystem doesn't naturally pull you into that solution because you can do it the other way just as easily. If, for example, there was _only_ the multiple-await version, it might more naturally capture the right idea.
Is there a RFC tracking issue on rust-lang/rust that lists all accepted but not yet stabilized RFCs with a link to the relevant tracking issue?
Possibly; it's just how I was taught it.
What dude??
I don't think there is one, but [this](https://github.com/rust-lang/rust/issues?page=1&amp;q=is%3Aopen+is%3Aissue+label%3AB-RFC-approved) is just as good. As you can see there is a surprisingly large amount of them, good thing the impl period is coming I guess.
Sometimes, parts of them have been, but not all of it. For example, on the run up to 1.0, there were a number of RFCs that were basically "we implement the backwards incompatible bits now, but not the other parts, we'll get to it later."
Does this mean emscripten is not used anymore? Or that I don't have to explicitly install it as it is supported by llvm now? I can see the new target still has emscripten in its name. I guess I just don't understand the implications. 
From what I've seen, `rusty-binder` looks like it's no longer being developed. There was an issue created almost a year ago and another one more recently, both asking how the project is going and if they can help.
Ooooh that's a nice bike shed you've got! 1 seems like a great color.
I haven't been super involved, so I'm not sure. I know it's "using llvm's stuff" but that's about it.
Hah, no, this one is about *little* tools! I mean, err, *tiny* ones! You know, ones that are not large! Argh, English!! Just… have a link: https://lifthrasiir.github.io/rustlog/why-is-a-rust-executable-large.html
Right, you can’t do atomic arithmetic but maybe it could still be useful with load/store/CAS?
What's that style / site generator / theme?
It's run on webrender_bindings in gecko, which slurps a bunch of types out of euclid and webrender proper. If you mark things as extern/repr(C) properly it basically finds everything properly. The biggest issues for us is that it requires nightly (unstable compiler options) to do macro expansion to find all the types/functions. 
Thanks!
Jekyll (Github pages) with custom CSS based on &lt;https://hackcss.egoist.moe&gt;. See the source: https://github.com/killercup/scribbles
Yeah that's not gonna possible. The app is months in development and has multiple threads running various complicated tasks.
Then I'd suggest moving to `reqwest`, rather than staying with hyper 0.11. Hyper has transitioned from being the synchronous client to being a future-based one. This new version supports greatly increased loads, but has the disadvantage of being a completely different architecture. [`reqwest`](https://github.com/seanmonstar/reqwest) is the new synchronous client - it's built on top of hyper 0.11, and provides a very similar interface to hyper 0.10. Hyper 0.10 -&gt; reqwest will be a much smaller change than hyper 0.10 -&gt; 0.11, if your app is this far along.
I can finally deprecate [`guilt-by-association`](https://crates.io/crates/guilt-by-association)!
&gt; all you express that foo() will be executed and it returns something and then bar will get that something. This is a high level view of the algorithm and it says absolutely nothing about the execution and I think that's a good thing. I see this very differently than you - that is a bad thing. Computers are not theoretical constructs, but machines with very concrete behavior which need to be understood and tailored to. Consequently, programming languages are not pseudo code. Some languages approach this (e.g. Python), but as soon as you reach the performance limits tailoring to the machine gets hard - especially since it is hard to understand how Python code transfers to instructions sometimes. For example, in C++ though I cherish that I can reason about somebody choosing a `std::unordered_map` over a `std::map`- though it expresses the same algorithm, the author probably cared for the difference. When I read the code using it, I understand that one has constant time lookup and requires a hash function and the other traverses a tree. I understand the pipelining and the memory access implications better and can reason better about scalability and performance. This matter to me - because I care what the machine does. The same argument I have for a yield in a coroutine. I care that the author expect this *function call* to take many orders of magnitude longer than others and that it yields control to other parts of the program. I work on performance sensitive code, I want to have a direct mental model from code to machine behavior. My bottlenecks are never IO, but always CPU, this definitively defines my different perspective. 
It's the end goal, but the ability to compile to wasm without emscripten's LLVM fork hasn't reached even nightly yet, let alone stable. See [this update](https://internals.rust-lang.org/t/moving-webassembly-support-forward/5460/39) (and the general thread) for more.
this is an amazing crate name
Hoping there will be some movement on box syntax soon so there's a proper and safe way to allocating big (non-vec) stuff on the heap without messing with unsafe
To be honest, while I used to use `.wait()` a lot, these days I'm no longer a fan of this method. I think we should deprecate it in any case so I wouldn't be against replacing it with `.await()`.
Just a small note - I suspect this might be better the other way around: &gt; &gt; struct Buffer_f32 { &gt; float data[8]; &gt; size_t len; &gt; }; &gt; &gt; struct Buffer_i32 { &gt; int32_t data[8]; &gt; size_t len; &gt; }; &gt; &gt; Here you can see an instantiation of Buffer is generated for each use of `Buffer&lt;T&gt;`. &gt; &gt; Additionally, cbindgen can output template specialization’s to make using Buffer more ergonomic. &gt; &gt; template&lt;typename T&gt; &gt; struct Buffer; &gt; &gt; template&lt;&gt; &gt; struct Buffer&lt;float&gt; : public Buffer_f32 { &gt; &gt; }; &gt; &gt; template&lt;&gt; &gt; struct Buffer&lt;int32_t&gt; : public Buffer_i32 { &gt; &gt; }; &gt; Wouldn't it be preferable to do this? template&lt;typename T&gt; struct Buffer; template&lt;&gt; struct Buffer&lt;float&gt; { float data[8]; size_t len; }; template&lt;&gt; struct Buffer&lt;int32_t&gt; { int32_t data[8]; size_t len; }; typedef Buffer&lt;float&gt; Buffer_f32; typedef Buffer&lt;int32_t&gt; Buffer_i32; Inheritance allows two types to be interchangeable in many cases, but not *all* of them; in the first case `Buffer&lt;int32_t&gt;` and `Buffer_i32` are still different types, which may be troublesome in some cases. In the second case they are the same type.
aaaaaand it's over
i guess we can do ```T::one```, ```T::zero``` , nice
I'm excited about this feature, too! I'm thinking this could help me replace a bunch of massive switch statements with trait implementation. For example: enum A { X, Y, Z } impl A { fn width(&amp;self) -&gt; u32 { match *self { X =&gt; 10, Y =&gt; 20, Z =&gt; 30 } } fn height(&amp;self) -&gt; u32 { match *self { X =&gt; 100, Y =&gt; 200, Z =&gt; 300 } } } becomes trait A { const width: u32; const height: u32; } struct X; impl A for X { const width: u32 = 10; const height: u32 = 100; } struct Y; impl A for Y { const width: u32 = 20; const height: u32 = 200; } struct Z; impl A for Z { const width: u32 = 30; const height: u32 = 300; } It's not any shorter in this case, though as the number of constants goes up it should become more effective. But I like how all the values for one "case" end up in a single place rather than scattered across a number of functions. Massive switch statements were always supposed to be a "code smell" anyway, right? Downside: have to introduce type parameters to functions using `A`: fn do_something_with_a&lt;T:A&gt;(item: T) { ... } whereas it used to be: fn do_something_with_a(item: A) { ... } So, tradeoffs.
Thanks! Would Tokyo accelerate TLS requests ?
I thought the open question about how to seek community involvement earlier in language design without people getting burned out was really interesting and am keen to see where we end up on that. It's the first conversation I've seen that's spanned multiple threads, with many alternative proposals floated at the same time, and gone through multiple formal RFCs before reaching its current state.
We should open a PR for Clippy to lint English errors too. 🤔
Can you get a spellchecker into your CI system? 
Hmm. Clearly the rest of us missed something.
Not really, since constructing `num_bigint::BigInt` involves `Vec` constructor which means it cannot be represented as `const`.
I'd happily take a PR for such; it's not trivial given that there's so much jargon.
Let's compromise and call it 1.5
Could `Vec::new()` be a `const fn`? Or maybe generic constants could provide `std::vec::EMPTY: Vec&lt;T&gt;`? (edit: though that only helps `ZERO`; `ONE` would need to work without allocation too.)
Would `u8::max_value()` and friends have been associated constants if we could turn back the clock?
is that something that can eventually be fixed ? you should be able to represent a non-changing one/zero value stored in a global . would a bbignum use the small vector optimisation, so it could be done without allocation. could something be done with associated types ( a type could be associated with a different type for it's constant versions, whatever)
Nit: "less constraints" should be "fewer constraints", since constraints are countable. 
Are you aware of [num-derive](https://crates.io/crates/num-derive)? Well, probably not, because it totally lacks documentation (PRs welcome!), but this enables `#[derive(FromPrimitive, ToPrimitive)]`.
No problem! Tokio won't accelerate single requests, but it will allow for making a huge number concurrently, with very little system load. A client which makes 10,000 concurrent requests, or a web server which accepts that many, would be impossible (or very slow) under Hyper 0.10, but almost nothing in hyper 0.11. Tokio's advantages come into play when you have enough requests that spinning up an operating system thread for each one would have too much overhead. It can handle any number of IO connections in a single thread, which is essential for a web server, or a highly concurrent client.
No I wasn't to be honest. I've been writing this pattern for a while now and each time I look it someone written this and I never saw num-derive. fwiw, my crate provides both with just #[derive(Primitive)].
I'd also like an RFC that lists all RFCS which do not list themselves.
I've never heard of an unconference before. Can't wait. :-)
Vec::new doesn't allocate, so I'd imagine it could be const.
This subreddit is for Rust the programming language, not Rust the game.
At first I thought this title was generated by a Markov chain. :P So is Cernan intended as a replacement for Heka, or does it augment Heka? I ask because I see that Heka has been superseded by Hindsight, which appears to also be maintained by Mozilla, and it would be interesting to see if Mozilla would be willing to toss out Hindsight for Cernan (though I'm not getting my hopes up :P ). Also, is Cernan the only Rust in production at Postmates? I've seen Postmate's logo on https://www.rust-lang.org/en-US/friends.html for a while now, but it would be great to get some more illumination as to what it's being used for. :)
There's also this: error[E0493]: constants are not allowed to have destructors
This is interesting! I'd note that the old and new versions do do things differently at runtime - the old one will have one function which does do a switch on the types, but the new one will have a different `do_something_with_a` in the binary for each struct passed in. I think I might try to do this in some of my codebases too - as long as 'A' is never stored in a data structure with other different instances of 'A', it would be fully compatible, and totally more efficient!
I've been thinking about ways we can make this *even easier* and I think having a `stdcli` crate that does `use stdx::*` but also includes more libraries for writing cli's would be AMAZING. Some other libraries that would be useful: - [cargo-script](https://crates.io/crates/cargo-script): this wouldnt be in `stdcli`, but is an important one to know! Quickly write and run cli scripts with crate caching. - [structopt_derive](https://crates.io/crates/structopt_derive): you already mentioned this one, it's great. - [tabwriter](https://crates.io/crates/tabwriter) easy formatting of data into a table using `\t` character for alignment - [self_update](https://crates.io/crates/self_update): auto update/upgrade the compiled binary - [ansi_term](https://crates.io/crates/ansi_term): colors in the terminal - [fern](https://crates.io/crates/fern): easier logging for clis - [fs_extra](https://crates.io/crates/fs_extra): to remove some of your tiny functions - [ctrlc](https://crates.io/crates/ctrlc): easy handling of unix AND windows signals
You are misinformed. ARM Cortex-M is a microcontroller through and through, and the community is massive. You can even use Arduino software with many of the boards.
That's true, I think that's being relaxed, IIRC?
&gt; At first I thought this title was generated by a Markov chain. :P :) &gt; So is Cernan intended as a replacement for Heka, or does it augment Heka? I ask because I see that Heka has been superseded by Hindsight, which appears to also be maintained by Mozilla, and it would be interesting to see if Mozilla would be willing to toss out Hindsight for Cernan (though I'm not getting my hopes up :P ). They sit in similar spaces but they've got different focuses. Hindsight, for instance, comes with a load of base plugins where in cernan-land you're kind of on your own. Cernan's development focus has been on the Sources – the ways information is gathered or ingested – and the Sinks – the places to which information is pushed. The Filters – the cernan analog of heka plugins – we've developed inside Postmates are all closed source. I'm also not totally happy with the filter API, tbh. I'd be real happy to talk to Mozilla folks, in any event. Even if cernan doesn't quite fill the need that Hindsight addresses I'd like to know that and work in that direction. I guess I could do a Rust Meetup talk on cernan. Heh, I do work just a mile away from the Mozilla offices. &gt; Also, is Cernan the only Rust in production at Postmates? I've seen Postmate's logo on https://www.rust-lang.org/en-US/friends.html for a while now, but it would be great to get some more illumination as to what it's being used for. :) Right now all our Rust is inside the Infrastructure team. I'm hoping to open-source some of our project management tools – reacting to Github events, historical system telemetry – in the first half of next year, if things proceed smoothly. Cernan is for sure the big one, that said. 
Interesting use case! I've only ever done it the way your code does now, since I usually care about what message the server has sent alongside it's error status. If you do want to discard the message though, like I see you are with CustomError, I believe you can do this: .and_then(|response| { let status = response.status(); if status.is_success() { Box::new(response.body().concat2()) as Box&lt;Future&lt;Item=_, Error=_&gt;&gt; } else { Box::new(future::err(CustomError { code: status.as_u16() })) } }) A box is required since you aren't always returning the same type. This way, `and_then` can return any different kind of future, and they'll all have the same end size (the size of Box&lt;Future&gt;).
For a short period of time, a crate called cargo-canoe was adding everyone (?) as its owner. I was surprised to find it listed on my crates.io dashboard. The docs still have the beautiful roster of owners: https://docs.rs/crate/cargo-canoe/6.7.8-putting-the-rust-in-crustacean
`structopt` looks fantastic. I'll be in my bunk.
Any clue what was going on?
Ah, I found [RFC 1440](https://github.com/rust-lang/rfcs/pull/1440), amended in [1817](https://github.com/rust-lang/rfcs/pull/1817), tracked in [rust#33156](https://github.com/rust-lang/rust/issues/33156). 
Yes, and they probably still will be, though the functions won't go away.
you need to use String in struct and query, not &amp;str if i remember correctly change name to Stringg and name.eq("str") to name.eq("str".to_string())
The `map_err` and `map` branches of the future handling are disjoint and lazy. So if you first check the status code and then call `map` and `map_err` appropriately, you can avoid doing any work on `res.body()`: let future = self.client .request(client_request) .and_then(|res| result(match res.status() { StatusCode::Ok =&gt; Ok(res), _ =&gt; Err(CustomError {...}), })) // ... here's a mocked-up example: https://play.rust-lang.org/?gist=912c79fbc444d18e2e14b4f069ec43b4&amp;version=nightly
I wouldn't call it bikeshedding, considering how [some exit codes have standard meanings](http://www.tldp.org/LDP/abs/html/exitcodes.html).
Interesting, I see the shadowing happening, but I don't really think it's a problem. I've seen it be used in Rust code commonly enough, to the point that I might say that avoiding shadowing is not a goal of idiomatic Rust code. This is specifically in regard to locals, there may be other cases of shadowing that we'd want to strongly discourage. I don't really understand why this library requires the shadowing, is it a result of a quick implementation leveraging the existing framework they had in place, or in inescapable artifact of how generators and await work? Seems to me like the former, but that's a guess really. I don't understand the issue with locality and scope, can you elaborate please? The reason I prefer it is honestly due to very superficial reasons, namely reducing boilerplate and line-noise (all the and_then and from_err). Also, in the old version everything is threaded through with the top level connection object, which doesn't make sense to me: what if I needed to talk to to different async things, and combine them? I'm sure there's a way, but will it be as obvious as simply awaiting both on two lines and using both results?
the trait `diesel::Expression` is not implemented for `String` 
Great to hear about open-sourcing your tools! And I'd be happy to get you in touch with Erick to get you speaking at the SF meetup. :)
Heya /u/final_bawse! You can find the live stream link [here](https://air.mozilla.org/bay-area-rust-meetup-august-2017/)! It starts in 51 minutes!
`use` is very flexible. If you're stuck in a Java or C++ mindset, maybe [something like this](Permalink to the playground) will pleasantly surprise you like an old time highway advertisement. (Burma-Shave) The only things needed at module level are types and traits for your trait bounds and function signatures. I prefer to import just modules so that `rc::Rc` for example is obviously not a type defined in this module. Within function bodies, don't be shy with globs. The compiler will tell you if a collision occurs, so don't be scared of them. You could also define a `mod prelude` full of `pub use` statements and `use self::prelude::*` in your `impl` bodies. I haven't worked out a best style myself.
You mean it implements `Countable`? XD
That's too metal.
Inner functions may go at the end of a function body. Makes for an interesting way to factor error paths: `return error_handling(whatever);` Afaik, jumping to error handling is the last accepted use of C `goto` and Rust has this instead. 
is it just allocation that prevents a const Bignum, or is it any sort of call to a constructor (I wondered if 'bignum' could be implemented with a [small-vector optimisation](https://github.com/servo/rust-smallvec), hence avoiding allocation for one and zero constants).
Is "Advanced Bash-Scripting Guide" a universal standard now? I'm not against your comment, but the supporting source seems dubious.
For some context: https://twitter.com/ag_dubs/status/903312366649126912 (read the entire chain, not just a single tweet)
Seems like a Voldemort type.
Pretty similar, yeah!
I wouldn't it sets the standard - but it does document an existing standard. Or, at least conventions. Not sure if there is an official POSIX standard(the page I linked to is just the first Google result), but it does seem common for exit code 2 to mean - to some degree- "_misuse_". Few examples: * Syntax errors in `bash`. * Running `ls` with non-existing files. * Running `test` with a order comparison operator and string arguments. * Running `diff` with different node types(e.g. directory and file) Also, some programs may expect these conventions. For example, [Supervisord does not restart by default processes that exited with 0 or 2](http://supervisord.org/configuration.html#program-x-section-values). Code 0 because it means the program exited normally, and I can't find an official reason but I think it does not restart code 2 because it means something is wrong with the command. So... maybe "standard" was too strong a word, but there sure are some conventions.
Heya /u/troutwine! I'd love to have you speak about cernan at the sf meetup! Could you private message me your contact info?
It's bold, but it's necessary if we're ever going to beat Python.
Today, what I see in the RFC repo is more like: close the RFC but open a new RFC with a subset of it, then accept the new RFC. I wonder when the process changed from what you describe to this.
I'm not sure that really counts as returning a private type, since, as far as code outside `internals` is concerned, the only thing that you can do with the returned value is no more than you could do with any type that implements `PubTrait`. Even though the `Private` type may be what is residing in memory, that's no more public than a private field is; you can't mess with it without resorting to `unsafe`.
On first read it seemed like it would be similar to Java's `serialVersionUid`, though I don't believe in Java you can directly access that field on `Serializable` classes.
&gt; Massive switch statements were always supposed to be a "code smell" anyway, right? It depends. On an interpreter I'd expect to see a massive switch somewhere. Also, if it's very unlikely that you will add a new variant, a massive switch may be warranted. Your solution is better if adding new cases is more likely than adding new operations. (This is called the expression problem)
One of my personal favorite tips is to forgo using `clap` and instead match on the arguments directly as a slice.
To got to medium sized tools we need solutions for logging and configurations (and where those files end up!)
Rust doesn't have constructors.
That's true, but only of some RFCs. It generally happens when an RFC is contentious. Cutting scope makes it easier to come to consensus.
Sure thing! 
/r/playrust
Lol thanks mate
Genesis here: https://twitter.com/isislovecruft/status/903309426257530884 Initial code here: https://twitter.com/steveklabnik/status/903311939601920000 Unfortunately, with everyone owning the code, and telling everyone to run it, there's a huge risk of arbitrary code being run on arbitrary people's computers. So, I (technically not but the details don't matter) removed everyone as an owner and yanked all the versions. Really, this was basically a proof-of-concept for "we need https://github.com/rust-lang/crates.io/issues/924"
but it can still enforce the need for creating things via an initializer function (which does the job of constructors), by making the members private? it's just the encapsulation is based on modules rather than 'classes' (glorified structs in C++), right? e.g. you can only create a ```struct Vec``` by going through 'constructor functions' that comprise it's 'public interface'? (```Vec::new()``` etc..). I've seen people refer to those as '[constructors](https://aturon.github.io/ownership/constructors.html)' even if they're not a separate type of function/language construct
In the shell world, an exit status of `2` has always been used to denote that a command exited due to a bad argument, whereas `1` is the universal exit code to indicate a general failure. And of course, `0` indicates success.
I need to try surrogates (shouldn't work) and non-characters (should).
But even those conventions are likely limited to some ecosystems (like families of programming languages or operating systems) and some conventions also flat out suck(not saying that is the case now). Adherence to posix is not always 100% even from people trying to support it. The POSIXLY_CORRECT situation in GNU provides an example. The discussion of how much to respect existing practices should probably occur(particularly if there isn't obvious consensus).
I prototyped this awhile back with [cfg-specialize](https://github.com/alexcrichton/cfg-specialize) which supports per-function specialization, although I was mostly going at it from the angle of SIMD stuff so it may not be quite what you're looking for. You may find it interesting though or perhaps draw some inspiration from it!
Hey all, I made a [gist with some benchmarks](https://gist.github.com/andrewcsmith/6ade174b36e20698ffb60f682f30c1fc)! Long story short, I basically ignored `clone`, because the speed of cloning is irrelevant for my use-case. I quickly realized that `Arc&lt;Cell&lt;f64&gt;&gt;` was silly. I also incorporated /u/SimonSapin 's suggestion around `f64::to_bits` and `f64::from_bits`, and found that it indeed slowed things down more than just (unsafely) casting a pointer. There's some other stuff too, such as whether it's quicker to test for `None` or for equality. (Looks like it's a wash.) I would love to see nitpicks / revisions of my benchmarks, keeping in mind the factors above. As far as the use-case goes, I'm trying to implement sound sample-level feedback between multiple threads, keeping everything in sync to 1/96000 of a second. Or even faster than that, to be honest, looking at ultrasonic sound.
Yeah SIMD stuff here too. Your crate looks great, I'll have a poke around and see how well it matches what I'm doing. Thanks!
Hmm. To consider this a bug, or not? I guess in this case `impl Trait` is essentially equivalent to wrapping a private type in a public type that implements `Trait` only, so no bug I suppose.
aka you're complicating the standard library to accommodate webdevs.
personally i use it sth like this (found in example on diesel.rs, DbEr is just alias for database error) pub fn get_user(user_id: i32) -&gt; Result&lt;User, DbEr&gt; { use self::users::dsl::*; let conn = establish_connection(); users.filter(id.eq(user_id)).first::&lt;User&gt;(&amp;conn) } also, did you derive Queryable for Post?
Thank you, King Stannis
I've been using [moz-cheddar](https://github.com/mozilla/moz-cheddar) at work because rusty-cheddar doesn't seem to be maintained any more - was just basing it off what [mozilla/mp4parse-rust](https://github.com/mozilla/mp4parse-rust/) was doing. Would be interested to know if there are plans to replace it.
Clearly in this case it would work out nicely, so I think the answer is yes.
Haha, I always laughed when he corrected people. RIP
Welcome to Reddit. Before posting to a subreddit/forum/community, you should *check* to see what that subreddit is for. This includes reading the sidebar and the rules. You should also pay attention to warnings that you're posting to the wrong subreddit. Check /r/playrust.
You can't "return a type", you return a value whose type is a private struct. The return type is `impl PubTrait` which is public. You could always return values whose types are private with say trait objects or just wrapping it in a public type; it's about that the return type is public. Edit: the same thing by the way could've also been written `should_compile&lt;T: PubTrait&gt; () -&gt; T` in theory; if Rust allowed that which it some-how doesn't that would achieve the same thing as `impl PubTrait`; this is easily allowed in function arguments which already shows how you can via this mechanism put a "private type in a public interface".
I haven't done any extensive testing yet. From some quick tests, `await!`, does make things a touch slower. This is almost certainly an artefact of this being so new and experimental and not something fundamental. Somewhat related, consider that a large performance benefit is going to come when the future-returning libraries use `impl Future` instead of `BoxFuture`. Several unnecessary boxes are created in the postgres example that'll go away when that's stabilized. `#[async]` uses this under the hood.
&gt; I don't really understand why this library requires the shadowing, is it a result of a quick implementation leveraging the existing framework they had in place, or in inescapable artifact of how generators and await work? Seems to me like the former, but that's a guess really. The reason tokio-postgres requires this is this is a low-level library where you are working directly on a connection. You cannot use a connection that is currently in use as SQL queries must be executed in sequence on a single connection. So the library takes ownership of the connection object on each request to prevent you from misusing it. In another language without such powerful ownership semantics this would likely be an _exceptional_ case. I imagine a higher level interface might allow otherwise, except in the case of transactions where you definitely need to enforce serial execution.
One nitpick: filenames (at least on *nix) don't have to be valid UTF-8, so making functions that require a `&amp;str` to open/read them isn't the best choice. Consider instead `AsRef&lt;Path&gt;` (which is what `File::open()` uses, for this reason)
might want to take a look at [https://docs.rs/sid_vec/0.1.0/sid_vec/struct.IdVec.html] and the discussion here, [https://www.reddit.com/r/rust/comments/6h6bfe/vectindex_parameterised_index/] the concern raised below is valid but I suspect you might like i32 indices (there'd be a hazard if intending to get your code onto retro 16bit machines, I guess that's not out of the question for a 2d game) 
Wouldn't your should_compile claim to be able to construct a value of any type that implements PubTrait? The OP's version only claims to return a value of one such type. It's basically the difference between a universal quantification and an existential one.
Ahh interesting, so definitely sounds like it's not related to the fact of using `await!`, just usage for this specific library, makes sense.
Yeah that's actually a good point I didn't consider. A function with that signature would be able to type check in any context that demands a specific instance whereas `impl Trait` only in a context that supports _all_ instances.
This. And this is not only limited to `impl Trait`. You can also do this [using `Box&lt;Trait&gt;`](https://play.rust-lang.org/?gist=6cfe64bf4cf1a85dd3edd51fd108184f&amp;version=stable).
My `stdlib.h` defines these: /* We define these the same for all machines. Changes from this to the outside world should be done in `_exit'. */ #define EXIT_FAILURE 1 /* Failing exit status. */ #define EXIT_SUCCESS 0 /* Successful exit status. */ Ninja edit: and `man 3 exit` says: "The C standard specifies two constants, EXIT_SUCCESS and EXIT_FAILURE, that may be passed to exit() to indicate successful or unsuccessful termination, respectively."
Aha, so that's the syntax. I've occasionally tried to say `std::foo::bar()` when I only need a single call, but then the compiler shrugs its shoulders, so I was just importing it after all. Is there any interest in having a special-case lint message when you try to use `std` like that?
May I recommend that whenever you feel angry, you take some time off, go walk outside for a bit or even just sleep on it? This gives you some time to really figure out the edges of your arguments and reasoning so you can present a coherent argument. It may also help you to realize you're ranting on the wrong subreddit ;) /r/playrust
Welcome to Reddit. Before posting to a subreddit/forum/community, you should *check* to see what that subreddit is for. This includes reading the sidebar and the rules. You should also pay attention to warnings that you're posting to the wrong subreddit. Check /r/playrust. Also, you should probably turn your capslock off.
deleted ^^^^^^^^^^^^^^^^0.5611 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/67138)
i'm so sorry
I thought about adding a list of crates… but it's so hard to _stop_! Should I mention itertools? dialoguer? indicatif? reqwest? loggerv? assert-cli? difference? unindent? tempdir? _I͠ ͢can't ͟s͘tòp!̢!_
That's very useful. I've been looking for that feature in Rust since it was one thing I still needed C for. I've been using ifunc in [gcc](https://gcc.gnu.org/onlinedocs/gcc-4.7.1/gcc/Function-Attributes.html) which is supposed to be supported in newer [clangs](https://clang.llvm.org/docs/AttributeReference.html#ifunc-gnu-ifunc). That does the dispatch at load time, but only work's on Linux (elf). This looks like it should work about as well short of the very minor one (or few with racy calls) time dispatch. This probably works on all x86 platforms instead of just linux. And this looks far easier to deal with since it seems to effectively have static ifs (as long as the optimizer handles ifs with constant values) instead of separate c files for each platform. Now I just need to wait for inline asm on stable Rust, then I should be able to port some performance critical code over from C.
Good advice! And in general I agree, in this particular instance the input path is from a CLI arg though, which already gets converted to a String. I know, it should probably be an OsString… maybe another time ;)
Using `structopt`and `error_chain` to kickstart your project puts you right in the heat of the action in a couple of minutes, it's awesome.
I am big fan of the `unimplemented` change match foo{ ... rest =&gt; unimplemented!("{:?}", rest) } 
`ed_config` holds a borrow of `h1`, but `h1` only exists for the lifetime of `init_editor` I think the problem here is `init_editor` doesn't do anything. It has no mutable state and it doesn't return anything; we can't really tell you how to fix something that doesn't do anything in the first place
Thank you for your quick response. The code referred to, is incomplete. I am trying to test the program by adding a feature at a time. For the time being, all I want to do is to simply to set a reference to the field hl_syntax in the editor_config structure. From what I have understood, this reference should have the same life timer as the editor_config. So how do I go about it? 
Interesting. Is there a plan for what to do when someone writes a script to claim all unused crate names of up to X characters in length? That's a crates.io hypothetical that comes up from time to time when talking to fellow Rustaceans.
Take a look at the [error-chain] crate to help with exactly this kind of thing. [error-chain]: https://docs.rs/error-chain/0.10.0/error_chain/
Well, you need `hl` to live longer than the function then. Your problem is, `hl` is created inside `init_editor` with a lifetime local to `init_editor`, it's getting destroyed at the end of the function, and so the reference to it from inside `ed_config` would be destroyed too. `ed_config` is also local to the function though, so all you should need to do is initialize `hl` before `ed_config` (values are dropped in the opposite order of creation)
To continue the C# parallel, the Rust `Iterator` trait is equivalent to `IEnumerable`/`IEnumerator`, which exist independently of `yield` too.
It should be called 'Count' in Rust.
Hi, I'm trying to read text files to strings, specifically targetting german words. File::read_to_string panicks with a StringError("stream did not contain valid UTF-8") as soon as there is an umlaut (ä, ö, ü), ß, €, §, ° or ´ inside the file. Is there any other option to read in such files correctly?
good job implementing more features, meanwhile you did nothing to improve compile times in a meaningful way. Like how you PROMISED to do
How could you ever sanely lock a mutex without at least one atomic write?
In this case, I'd rather use the Either future and box the whole resulting future chain, if necessary. https://docs.rs/futures/0.1.14/futures/future/enum.Either.html
Thank you. Got it!
Sorry, this might not be an easy question. I wonder if I should post it separately. Anyway, here goes. One can specify type aliases, which are simply another names for a type. One curious thing about type aliases is that you can also "partially apply" the generics that appear in the original type. Besides creating aliases with `type`, one can also re-export stuff with a different name using `pub use ... as ...`. (A side question: is there any difference in the items created by an alias and a re-export?) Now, my question is: is it possible to create an alias for a generic function that partially or fully applies the generics? I tried to do so, but I couldn't find a way. (Using `type` complains the item being a function, not a type.) To prevent XY problem, I'll tell what I'm attempting to do: I created a generic helper function, and now I'm trying to register it to Rocket: .mount("/api/items", routes![ api::crud_helper::get_all::&lt;models::Organization&gt;, ]) ...but it doesn't accept that: `expected identifier, found &lt;`. It should be entirely possible to wrap the function by hand to a non-generic function that has otherwise similar API and calls the generic one, but that kind of defeats the purpose, which is to avoid boilerplate.
So, what encoding the files are in? If you don't know, it's likely that they are in ISO-8859-1, a.k.a. ISO Latin-1. Check this crate out: https://crates.io/crates/encoding Also, you might find this interesting: https://stackoverflow.com/questions/28169745/what-are-the-options-to-convert-iso-8859-1-latin-1-to-a-string-utf-8
[Play ground link]( https://play.rust-lang.org/?gist=2ea9629e4ce93f92ab72dbceb025a5fe&amp;version=stable) Is there a way to ignore generic type K in this gist? 
I'm not worried about this. Rust core team has shown a history of adding features only after thinking them through, and even then only if they fit into the language well. 
If you don't care about the value of K type and don't use it, you can stuff `()` in there. But if the users of `BufValExtractor` care about the K type (that is, if you want to make a `BufValExtractor` that can handle all kinds of `Bufs`), you'll have to parametrise the type: `BufValExtractor&lt;K, V&gt;`
&gt; You can't "return a type", you return a value whose type is a private struct. Yes, I apologize for not writing that out but the title was already quite long. &gt; The return type is impl PubTrait which is public. You could always return values whose types are private with say trait objects or just wrapping it in a public type; it's about that the return type is public. Yes, I understand why it works, I just think it's pretty cool and a useful consequence. 
I think this is a major feature, actually. If the point of your function is to return "something that does _this_", where _this_ is specified by some trait, returning a type that happens to implement that trait means that you're locked into that type, while returning `impl Trait` means you can do whatever you like with that type as long as it still implements that trait.
Except for the fact that incremental compilation made it to nightly this year. `cargo check` is in the stable channel, rls is in beta both of which should help you avoid a full compilation cycle.
Thanks, that was the push i needed to get it working. The files are indeed in ISO-8859-1. I'm reading the file into a Vec and then decoding it afterwards. I was hoping for some kind of Reader where you could specify the encoding, maybe even decide it on runtime, but this current approach works for now too.
Perhaps it would be possible for a dictionary textfile to be provided of "ignore" words? Edit: I may try to PR this later. http://blog.eleven-labs.com/en/how-to-check-the-spelling-of-your-docs-from-travis-ci/ Seems to cover it pretty well.
Yup, `should_compile() -&gt; impl PubTrait` could be translated to something more like this: should_compile&lt;F, R&gt;(f: F) -&gt; R where F: for&lt;T: PubTrait&gt; Fn(T) -&gt; R That is, it takes a continuation that can accept *any* `T` implementing `PubTrait`, and returns the result of calling that continuation on the actual `impl PubTrait`. This literal code doesn’t work because Rust doesn’t have higher-rank polymorphism except for trait bounds, but it could in principle.
Look everybody! They admitted guilt! *starts witchhunt*
If you've ever programmed in Python before, `use` is effectively `import`, so rules like what you've used in Python can be useful in Rust. 
I understand your frustration, but it's not a trivial thing to fix. The entire trait resolution system is being rewritten, incremental compilation should be ready this year, and MIR borrowchecking is also worked on. These things also enable rustc to generate better LLVM IR, which means less time spent in LLVM and also potentially faster binaries. And the core team is also aware of the issue, I think this is the reason behind the 3 month long [impl period](https://internals.rust-lang.org/t/announcing-the-impl-period-sep-18-dec-17/5676) starting soon.
We'll see when and if it happens. It hasn't happened in other ecosystems.
There's no way to tell that these kinds of things are "constructors", though, because the compiler can't know the difference. They're just functions that exist, like any other function.
&gt; (although the book itself wasn't updated yet to contain the new chapter). It is: https://doc.rust-lang.org/nightly/unstable-book/language-features/generators.html
I guess what we're debating here is the definition of constructor... is it a specific language feature, or 'a function whose sole purpose is to construct an object'; You could say that the traditional OOP idea of a constructor merely formalises a pattern which many C programmers would have a naming convention for (and automates calling). I suppose the 'default value' does the job of the 'default constructor'
Not only this, it gives you the API freedom to change the type you are returning at any point without breaking consumers. It's pretty powerful.
As far as the compiler is concerned there's no such thing as a "constructor", so with regard to your original question ("is it any sort of call to a constructor" that prevents a `const Bignum::new`) the answer would be no. There are currently various restrictions on what sort of constructs are allowed inside `const fn` (e.g. destructors and `if` are currently disallowed), so as these features are gradually implemented in a const context it will allow more and more code. What Steve is trying to get at is that there's no "constructor" feature, as a constructor is just an informal term for a function with a specific use, so the question as posed is insufficiently precise.
The current phase of incremental compilation is being tracked here: https://github.com/rust-lang/rust/issues/42293 . A bit of a hold up at present as michaelwoerister is currently on vacation, but it is summertime after all. :P
ok now I remember the error messages I encountered in another scenario might have been along those lines ..it's actually the destructors that are outlawed for globals? I'm sure you understood what I meant :) It seems rust *does* have [destructors](https://doc.rust-lang.org/std/ops/trait.Drop.html), which to me would make going with the [less formal version of the term constructor](https://en.wikibooks.org/wiki/C_Programming/GObject#The_Constructor) more logical (can't destruct something that hasn't been constructed, surely). 'constructor vs Constructor' I guess this is like talking about *methods* in c++. Some people will tell you C++ doesn't have them, just *member-functions*. But if you say method, it's pretty clear what they're talking about. Getting back to the spirit of the question, would there be a way to handle a subset of the bignum with a small block allocator slotting in as a one/zero (e.g. if it was possible to represent the one/zero values without performing allocation) .. or would that still be outlawed by the fact that such a type still needs to call a destructor to check what it is to free memory (if needed)
Can associated types on traits have where bounds? Let's say that I don't care the type itself fulfilling some bound, but a reference to that types fulfilling it. (Or, let's say for another example, a vector of the associated types fulfilling it) Where bounds would make it possible to express that the implementations should provide types that match those requirements. Again, here's a concrete case, where a where bound would be needed, but I'm not sure if I can provide it: &amp;&lt;&lt;I as api::crud::CrudHelper&gt;::DbTable as diesel::associations::HasTable&gt;::Table needs to implement diesel::query_builder::AsQuery To ease up reading, the type can rewritten as `&amp;Crudhelper::DbTable : diesel::query_builder::AsQuery`. Note the *reference* – we aren't talking about the type `Crudhelper::DbTable` itself!
The easiest way to disable `Sync` in a type IMO is to add a `PhantomData&lt;*mut ()&gt;` member. See https://play.rust-lang.org/?gist=9e872bc9c364a47fe7079fc1db1a1bb7&amp;version=stable
Ah, I got already a hang of it. You don't specify the clauses on the associated type where it's defined, but at the trait definition, like `where Self::AssocType : SomeTrait`. Edit: Btw. I couldn't find this documented anywhere in the official documentation. Now that I noticed about it, I remember having seen it countless of times on crates that (ab)use heavily generics.
There's still some features in C++ yet to come in Rust that are beneficial to templated maths libraries (specializations/[type-parameter constants](https://www.ibm.com/support/knowledgecenter/en/SSLTBW_2.3.0/com.ibm.zos.v2r3.cbclx01/template_non-type_arguments.htm), and sometimes traits actually get in the way IMO.). But those *are* on the Rust road-map. I'm also not sure if rusts SIMD is stabilised (better ask someone who has actually dealt with it though). It's not clear to me that it's *worth* replacing C++ in every role (Industry: https://vibratingmelon.com/2011/06/10/why-you-should-almost-never-rewrite-code-a-graphical-guide/). The problems you'll have in numeric code are different (to the problems rust is trying to solve), and Rust wouldn't be replacing the role of python in that field either. machine-vision/computation may need to be ported to [custom DSP-like processors](https://uploads.movidius.com/1463156689-2016-04-29_VPU_ProductBrief.pdf) and C/C++ remain great for this role; there's going to be [more devices like this](https://en.wikipedia.org/wiki/AI_accelerator_(computer_hardware)) and in interfacing with hardware you're often beyond the zone where the language can help. A lot of rusts benefits are about *removing* certain abilities from C++, which could be enforced by [static analysers](https://clang-analyzer.llvm.org). **Having said all that, on the plus side**: the functional feel of Rust is pleasing for computation, and if the 'proper immutability' translated into [aliasing hints](https://en.wikipedia.org/wiki/Pointer_aliasing), that would extremely helpful. As a little sweetener, imagine if they built the [F16 type](https://software.intel.com/en-us/articles/performance-benefits-of-half-precision-floats) into the language; things like that could appear quicker in the younger, more agile ecosystem, than in C++ with it's decades of momentum.
Things I've had experience with in this space: * For abstracting over numeric types, [num](https://github.com/rust-num/num) is the de facto standard. It is a little awkward to use (which is one reason why it was extracted out of the standard library), but the situation is slowly improving. * For guarding against mismatches of units-of-measure, there is [dimensioned](https://github.com/paholg/dimensioned), which provides a zero-cost unit-checked wrapper around numeric types. * For linear algebra, there's [nalgebra](http://nalgebra.org/)—an astounding feat of type system abuse that gives you typed-checked matrix operations. * (Bonus) [Rayon](https://github.com/nikomatsakis/rayon) is great for parallelizing programs. These libraries compose very naturally with each other. 
&gt; But if you say method, it's pretty clear what they're talking about. Indeed, in an informal context, but the compiler doesn't understand informal contexts and so asking if constructors impede CTFE is like asking if the color purple impedes CTFE. :P Perhaps one *could* think of struct literals as "constructors" (e.g. `Foo { a: 0, b: 1 }`), but those don't allow arbitrary code to run, unlike what we consider "constructors" in other languages (and hence struct literals have always been allowed in const contexts). &gt; would there be a way to handle a subset of the bignum with a small block allocator slotting in as a one/zero (e.g. if it was possible to represent the one/zero values without performing allocation) .. or would that still be outlawed by the fact that such a type still needs to call a destructor to check what it is to free memory (if needed) From the above it sounds like reason that `BigNum::new` isn't `const` is that it internally calls `Vec::new`, which isn't const because it returns a type with a destructor. AFAICT this particular use case doesn't have anything to do with allocation, only the current restriction on use of destructors (see https://www.reddit.com/r/rust/comments/6x8aj5/announcing_rust_120/dmehw8e/ ), which looks like it might be in stable Rust 1.22. But even allocation shouldn't necessarily be a hard blocker for CTFE; I can imagine a const function doing some work that requires allocation at compile-time, but that ultimately produces a value that does not require allocation.
Yes that would be optimal, but to my knowledge you're not allowed use templates in an extern "C" block in C++. Otherwise I don't think you'd even need to do mangling for Buffer_f32, Buffer_i32, you could just use the templates everywhere.
&gt; It's not clear to me that it's worth replacing C++ Never mind C++, they should never have left Fortran in the first place!
right; it's just the word association firing quickly .. * "I remember some problem with destructors/globals" -&gt; * "there's restrictions r.e. RAII types in constants/globals" -&gt; * "is there a restriction with constructors" ? I really meant 'the whole RAII thing..' I am encouraged to see that RFC, [https://github.com/rust-lang/rfcs/pull/1440], it would have streamlined a use case I encountered.
heh. I can't tell if this is enthusiasm for Fortrans's inbuilt array handling I hear about, or sarcasm :) I think C++ is way beyond fortran in expressive power, and although it has a lot of cruft, I don't actually think it's beyond hope. There was a long dark period in which it stagnated, but in recent years fixes and improvements have started coming through.
Reading the dimensioned example illustrates the mixed feelings I have about this:- // Calculates speed as before, but now we can use *any* unit system. fn generic_speed&lt;L, T&gt;(dist: L, time: T) -&gt; Quot&lt;L, T&gt; where L: Length + Div&lt;T&gt;, T: Time, { dist / time } I found myself losing patience with the trait bounds eventually.. for certain use cases they get more verbose than the function itself. When you have computed intermediate types, reading/figuring out/writing the types gets progressively harder. People have suggested dropping back to macros for 'typeless helpers' but that seems messier to me.
Some major differences that I can see: - cbindgen can use types from dependent crates, rusty-cheddar only works for a source file - cbindgen can handle generic structs - cbindgen uses syn, while rusty-cheddar uses syntex_syntax - rusty-cheddar doesn't seem to be maintained anymore There are also some miscellaneous things, like formatting control and C++ output. As for rusty-binder, that seems like it has the same differences and is also not being developed anymore.
I will also throw my [metric library](https://github.com/coder543/metric/) out there as another zero-cost library for unit-safe computation. `dimensioned` and `metric` have different sets of ergonomic trade-offs. I like the way mine works, of course. In the [benches folder](https://github.com/coder543/metric/tree/master/benches), you can see a small nbody example using each of `dimensioned`, `uom`, `metric`, and `raw` (which is no unit safety).
many of those are already in `stdx`, but I know what you mean!
I think the indirection there particularly unpleasant (i.e., `dist` is an `L`, which is a ...) , but that situation will improve with `impl` in argument position ([RFC1951](https://github.com/rust-lang/rfcs/blob/master/text/1951-expand-impl-trait.md)). In practice, I haven't written anything with _dimensioned_ that's _that_ generic. For instance, I used _dimensioned_ recently in a _slightly_ over-engineered beep function, and it was cool expressing [in the type signature](https://docs.rs/beep/0.1.0/beep/fn.beep.html) that `beep` consumes _anything_ that can be converted into a frequency that's measured in hertz: pub fn beep&lt;F, N&gt;(frequency: F) where F: Into&lt;Hertz&lt;N&gt;&gt;, N: Num + ToPrimitive { ... } 
Indeed in the article the examples are not enough to support the claims. Still I do agree that rust is one of the best thing to have ever happened to PL and in this article a simple presentation of an experience is given. It would have been way worse of a post if the author tried to showcase all that make rust special
&gt; For linear algebra, there's nalgebra—an astounding feat of type system abuse that gives you typed-checked matrix operations. That's quote of the week material right there!
The thing we learned is that you should not add literally everyone as an owner of your crate.
Looks pretty good! One thing though, https://github.com/coder543/metric/blob/master/src/lib.rs#L2 doesn't seem compile anymore.
I agree with most of your original post, but I think you underestimate the importance of memory safety and *sane compiler messages*. I still get the odd segfault in my numerical C++ code. That is the number one reason I would like to swap to Rust. The hours I've wasted tracking down memory bugs... I have also wasted hours deciphering pages of template instantiation errors from libraries. I *love* Eigen to bits, but it suffers so badly from nested template errors that they added macros to print out LOOK HERE FOR THE ERROR in the middle of pages of compiler output. I am waiting for integer type parameters and decent SIMD (up to AVX) to land in Rust before looking into it properly. I don't see an Eigen equivalent manifesting before both of those happen. And without that as a base to build on top of, sadly C++ it is for me. 
interesting. I have fixed it, and I have now pushed a new version to both GitHub and crates.io! It's been a little while since I've worked on the `metric` crate, so I guess things had changed over time. EDIT: I really need to write some documentation for `metric` at some point... right now, the examples are the documentation.
memory safety isn't free though; you pay for it in extra annotations and finding helper functions. in IMO numerical code the time goes into debugging the maths/logic; pointer bugs might still happen but they're not such a big deal compared to that: and C++ has the tools to avoid raw pointers these days (things like emplace back, and lambdas allow re-ordering code to not need iterators out in the open) Even with the template error messages, my finding is you're just shifting the work. I'm also curious if it would be possible to tame error messages with a sort between version control information and the error (filter the overlap of changed lines &amp; error message lines)
For linear algebra, the [stainless steel](https://github.com/stainless-steel) organization has decent bindings for Blas and lapack.
Hey! I'm an owner too
Ah I see. You could still make them equal types with that constraint, it's just more annoying to write out (but I guess it'll be generated anyway): struct Buffer_i32 { ... }; struct Buffer_f32 { ... }; template&lt;typename T&gt; struct Buffer_typedef; template&lt;&gt; struct Buffer_typedef&lt;float&gt; { using Type = Buffer_f32; }; template&lt;&gt; struct Buffer_typedef&lt;int32_t&gt; { using Type = Buffer_i32; }; template&lt;typename T&gt; using Buffer = typename Buffer_typedef&lt;T&gt;::Type; (Last I checked C++ didn't let you specialize typedefs directly without the intervening `struct` encoding? Could've changed in the meantime.)
Personally, I think I've lost more time to obscure memory bugs than I have to logic problems. Logic problems you can usually reduce to a toy problem and then see quite fast - memory issues are hunting in the dark. And yes, modern C++ does help. But a major library I use is dragging their feet on going to even C++11, which doesn't help. While I see where your idea is going, identifying the top-level line is not the problem. Understanding the relationship between that line and the bottom of the template stack is the problem.
Oh man the number of months, I've wasted trying to find out why my Fortran code would randomly seg fault due to a subroutine taking in an array larger than it should have been allowed or just so many other things like memory leaks in C libraries that I was calling. It's incredibly frustrating especially when you're dealing with legacy code that you've inherited. I'd like to try out Rust as well, but it just doesn't seem to be quite there yet in terms of tools needed for the HPC community. 
It's a crate by the people and for the people.
Let me know if more code or explanation is required, please! Here's the full project: https://github.com/potatofarms/printer-api
&gt; nalgebra—an astounding feat of type system abuse thing is, that doesn't sound like an improvement: if we want *'astounding feats of abuse'*, we already have C++ ...
Been waiting for these for days, glad they have finally landed. 
and the file that the gist references: https://github.com/potatofarms/printer-api/blob/master/src/api.rs#L115
&gt; I'm also not sure if rusts SIMD is stabilised (better ask someone who has actually dealt with it though). The compiler may vectorize things when it feels like, for explicit SIMD, not on stable yet.
My point is that this is not bikeshedding, because the exit codes **are** meaningful. Even if different programs use slightly different meanings for them, it doesn't mean we can just "pick whatever exit code we want because it doesn't matter".
Undefined behavior can be a nightmare to debug in numerical code, because unlike math it can make the bugs non-deterministic.
Truth be told, I mistook the meaning of "bikeshedding" in the context. I agree that there is good cause to attach value to being specific on return values. My apologies if my confusion muddied the conversation a bit. 
I must immediately admit that I have not read this in detail but glazed over it. My first thought is: Please use the tools that already exist the way they were meant to be used. `cargo install` is meant to be used for development tools. A great example of this is `diesel` (`cargo install diesel_cli`) and a bad one (not the tool, the installation method) is `cargo install ripgrep` because `rg` is a generic search tool, not a development tool only. I run macOS and install everything I can through [homebrew](https://brew.sh/) as do all of the other macOS-using devs I know. The last thing I want is yet another package manager or a thing that tries to be part of a package manager. I could have my foot in my mouth in saying all this but I already dislike Rust devs throwing all of their binaries up on `crates.io` instead of using existing distribution channels. Please feel free to tell me how wrong I am with this view or with the way I have expressed it. If there is an easier way for developers to get tools in the hands of end-users that doesn't require too much work on the end-user's side then I absolutely agree we should explore that.
First to answer your specific question—yes if you were using tokio on multiple threads you would need one Core per thread, constructed in each thread. That being said, assuming your web framework lets you handle requests via futures, it sounds like you don't need more than one thread. Simply use async API requests and handle their futures. *edit: ok on second look I realize futures-based web frameworks may not be popular/exist yet...? I rolled my own with `hyper` for an earlier project.*
Taking 40 minutes to install (and compile!) 3 development tools isn't okay. Most project's development environments separate themselves from the user's environment. What we need is python's `virtualenv` but for binaries. Languages like python or golang get away with having their package manager as their dev-tool distributor because those languages compile extremely quickly or at run time. This doesn't work for rust. Homebrew is not a solution for creating cross-platform virtual development environments. First of all it only works on mac, second of all I don't think that is how it is designed to work.
If your remote calls are using futures, you don't need separate threads. Juste use [join_all](https://docs.rs/futures/0.1/futures/future/fn.join_all.html) to retrieve the results. Otherwise, if you *do* need threads, look at [Remote](https://tokio.rs/docs/getting-started/reactor/), at the bottom of the page.
Oh yeah, the talk from Sean Griffin was hilarious :D
I haven't heard of the futures, but after a quick google, it looks like it's the equivalent of a javascript promise? Basically the ideal control-flow I'm going for with these threads is they make a request to a printer's API to check the status of the API api key (authenticated, or unauthenticated). The thread will return once they're authenticated. Then, the rest of the program can continue after the for thread in threads { let _ = thread.join(); }
I'm not using futures. They look like promises like I've used in Node.js, which makes me nervous to use because my project depends on a lot of code that should be synchronous in nature (I think -- things HAVE to finish before something else can begin).
I glanced at the code but I'm no expert with the win32 API. I think you'll want to find generic win32 GUI programming guides and translate what you find there to Rust. I suspect the problem you've run into is specific to that API and not generally a Rust thing (or win32 bindings issue). Edit: Maybe this sample code is helpful: https://github.com/genuinelucifer/mypad/blob/master/main.cpp
Always confuses me why they'd choose Python over Julia, when Julia has a simpler syntax, supports all the best-in-class scientific computing libraries in it's standard library, and has better performance due to JIT LLVM compilation of Julia scripts.
Yeah, exactly, it's a promise. All of tokio runs on futures :) If you want to go with the thread-based approach, one way to do it might be using `rayon::ThreadPool`. 
Clearly, to achieve world domination Rust must sort r before c.
In libsyntax, [`scan_unicode_escape`](https://github.com/rust-lang/rust/blob/f861b6ee46465097eec266c160ac53e230df7cf0/src/libsyntax/parse/lexer/mod.rs#L1012) calls [`char::from_u32`](https://github.com/rust-lang/rust/blob/f861b6ee46465097eec266c160ac53e230df7cf0/src/libcore/char.rs#L129), which calls [`char::try_from`](https://github.com/rust-lang/rust/blob/f861b6ee46465097eec266c160ac53e230df7cf0/src/libcore/char.rs#L274), which indeed only has a gap for the surrogates.
"Understanding the relationship between that line and the bottom of the template stack" what I imagine is "line 2381 (that you changed) is part of an error ending here:&lt;last line&gt;.... (click to see the full error)", i think it might want the option of showing 'both ends' if you change something that breaks 'in the middle' e.g. F calls G calls H, you change something in 'G', causing an error in a call to F. ( I guess in practice the important part is going to be one end or the other)
"Understanding the relationship between that line and the bottom of the template stack" what I imagine is "line 2381 (that you changed) is part of an error ending here:&lt;last line&gt;.... (click to see the full error)", i think it might want the option of showing 'both ends' if you change something that breaks 'in the middle' e.g. F calls G calls H, you change something in 'G', causing an error in a call to F. ( I guess in practice the important part is going to be one end or the other)
Note that the C standard doesn't specify the values of those constants only their presence. Some operating systems like VMS use 1 to indicate failure. edit: man 3 exit actually notes this: &gt; The use of EXIT_SUCCESS and EXIT_FAILURE is slightly more portable (to non-UNIX environments) than the use of 0 and some nonzero value like 1 or -1. In particular, VMS uses a different convention. 
While I agree with the general sentiment of this blog post, I can't help but be reminded of the standards XKCD when you propose creating yet another package manager... https://xkcd.com/927/
Exactly - Rust looks really interesting but it's not quite there yet. That's okay, it's still a young language, I can wait a while yet!
Um, that's pretty much what GCC and Clang do already with template errors. They will tell you the line in your code that is broken, and then step down through every line in every library that is also broken, until you reach the bottom of the template stack. The trouble is that with a library like Eigen, it's not F -&gt; G -&gt; H. It's A -&gt; B -&gt; C -&gt; most of the alphabet. Often only the top and bottom of the stack are important, but once or twice I have had to tediously go through the whole stack to find out which assumption I've violated. I think 'concepts' are supposed to make this better, but only by introducing another layer of C++ complexity I will have to learn.
the suggestion would be to help with cases where you modify something in a generic function, e.g. F-&gt;G-&gt;H, you change something in 'G' .. but the default behaviour would be to show 'the call to F' is what is broken (with the long explanation)
Sounds like you want a [streaming iterator](https://github.com/sfackler/streaming-iterator).
Well, Tokio is built upon futures, streams and sinks, so if you want to avoid async at all costs, that is definitely the wrong choice. You can't really do anything useful with Tokio without futures. &gt; They look like promises like I've used in Node.js, which makes me nervous to use because my project depends on a lot of code that should be synchronous in nature (I think -- things HAVE to finish before something else can begin). That's an issue of dependency ordering, not an issue of synchronousness.
But there *isn't* a standard for general binary distribution. There are package managers, but they are always designed for their particular OS. One possible tool is 0install (as mentioned), but it's hardly "standard".
It is similar but not the same as promises. The general pattern is similar, but there are differences. Cancellation is a big one that comes to mind.
This is only somewhat related to this, but it may be relevant enough, so here we go. I was working on [ODE.rs](https://github.com/DonRyuDragoni/ODE.rs) as a kind of complement for my undergraduate thesis. Having to rush a lot of things (and the professor instructing me on using Matlab) delayed the project a few months. Once I could breathe again, I coded a bit of what I originally envisioned, and that's what you can see on my github. Yes, I'm aware it needs more care and refactoring. I do plan to finish and improve it someday, even if it ends up forgotten in the middle of better libraries, and even if it takes me 100 years to do so. Hopefully it won't.
I don't get the problem actually. Isn't distributing binaries the role of a distribution package manager ? Why would you want to go a different way (yet again) ?
&gt; and a bad one (not the tool, the installation method) is `cargo install ripgrep` Please see: https://www.reddit.com/r/rust/comments/6rgszy/exa_a_modern_replacement_for_ls_written_in_rust/dl6bpxu/
That's probably because generalizing binary distributions for every platform is nigh impossible, for the same reason that generalizing binaries themselves is impossible. Every platform has different and incompatible conventions. I understand that long compile times are frustrating, but the reason that every programming language has its own package manager is not that nobody has tried to solve cross-platform packaging before. 
That and package managing is hard. I think we'd be better off helping distributions making it easier to package rust stuff.
&gt;My first thought is: Please use the tools that already exist the way they were meant to be used. &gt; &gt;`cargo install` is meant to be used for development tools. &gt; &gt;A great example of this is `diesel` (`cargo install diesel_cli`) and a bad one (not the tool, the installation method) is `cargo install ripgrep` because `rg` is a generic search tool, not a development tool only. Where has this been stated? I've been following Rust for a couple of years, and I've never heard of Cargo only being for dev tools. &gt;I run macOS and install everything I can through [homebrew](https://brew.sh/) as do all of the other macOS-using devs I know. &gt; &gt;The last thing I want is yet another package manager or a thing that tries to be part of a package manager. &gt; &gt;I could have my foot in my mouth in saying all this but I already dislike Rust devs throwing all of their binaries up on `crates.io` instead of using existing distribution channels. &gt; &gt;Please feel free to tell me how wrong I am with this view or with the way I have expressed it. If there is an easier way for developers to get tools in the hands of end-users that doesn't require too much work on the end-user's side then I absolutely agree we should explore that. Do you only package for Homebrew? What about apt? pacman? yum? rpm? What about Windows, where there basically is no package manager? And do you do this for every release? This is why devs usually just opt for the language's package manager. 
honestly, /u/burntsushi's reply in this topic [said it best](https://www.reddit.com/r/rust/comments/6xgj36/ergonomics_installing_rust_tools_and_binaries/dmg08y6/): &gt; But I didn't do anything to get ripgrep into the Archlinux repos, Fedora, Nix, RHEL, Gentoo or Chocolatety. Other people did that, and I'm grateful that they did. But it's not something I'd spend my time doing, not because I don't want to or don't think it's valuable, but because I don't have enough time to do it and maintain it. It's just not practical. All the other distribution managers are built for *their* systems. They don't work with generic packages distributed on the web, with a private key maintained by that package's maintainer. If it was easy for a maintainer to distribute binaries that could be installed on ANY linux or mac OS, that would be a huge boon.
that's not true. If you compile statically using `musl` your package can run on ANY linux distribution.
Other than the atomic load used by cfg-specialize, I believe that the two approaches are almost the same. GCC multiversioning, IIRC, relies on switching the pointer stored in the Global Object Table set up by the dynamic linker. It still requires the indirection of loading a function pointer from a location in memory.
&gt; honestly, /u/burntsushi's reply in this topic said it best: But this doesn't mean that developing yet another package manager is the way to go. Having an easy way to create a package for these managers from a cargo project might be at the end a lot more useful.
The problem is that your iterator struct is self referential. The (optional) pattern struct contains a reference to another member of the iterator struct (the module) and that is unsafe. The Row type for the iterator output would need to have 'p be something like 'self, that's why it won't work. You can either implement it with a raw pointer and make sure you know nothing will go wrong or you can reconfigure it so it's not self referential.
Thanks for the link! Microsoft examples are pretty bloated. I will try to reimplement it and hopefully get it working.
So I just came across [this blog post](https://dzone.com/articles/isolated-development-environment-using-nix) and realized that the [Nix package manager](https://nixos.org/nixos/about.html) can solve most of my needs. In particular I actually like the functional packaging language.
Sure, that's great if you can do static binaries. That automatically rules out any applications that use system libs like openssl. Also, what about Mac and Windows?
&gt; it really harms rust as a language that tools like rustfix, cargo-edit, etc have to be installed through cargo. I know that this is not the abstract point of the article, but for these specific crates, may I suggest that they could become part of cargo/a component you can install with rustup? (rustup is the tool we already have for rust-toolchain specific binaries. Also, that's actually my plan for these tools :)) 
The only real abuse is typenum, which will presumably be removed in favor of const generics as soon as those are a thing.
I'm curious-- what made you decide to start using tokio if you want to avoid futures?
can't openssl be linked statically as well?
that would be really great, but it would be nice to have a fast way to get them in the meantime :) I'm hoping there is continued development in this space and there will ALWAYS be a backlog of tools to add to cargo/rustup... while those tools are unstable it would be nice to be able to install them quickly.
Indeed not, but even if said tool existed, I'd still need to learn the submission guidelines for every package repository.
&gt; then throwing an exception is often the cleanest way to deal with something that should not happen. Isn't Code Contracts the proper way to handle something like that in C#? You can define a precondition for the method that requires calling code to provide an int.
Please see rule 4
I only used Tokio because the example for making an HTTP get request on hyper's website used it. Before reading some of these answers, I didn't really know what it was at all!
Ok, I think I am confused, because now that I re-look at my code I think I am using futures. https://github.com/potatofarms/printer-api/blob/master/src/api.rs#L64 The thing that confuses me, though, is the whole "and_then" part of this function (I got most of this code from hyper's website). In javascript promises if I called .then(data =&gt; {}); on a promise, I'd have to put the code that depends on the promise completing inside that closure, where in Rust futures, it seems like it's waiting for the whole thing to finish before returning the function.
Not to my knowledge. It's not written in Rust. And it's just one example anyway.
Not to sound too negative, but I'm quite disappointed. The only talk worth watching (to me) was Sean Griffins, and that mostly for the humor rather than the content... ( I think with half an hour extra it could have gotten very interesting)
Rust. I'm in the right one
I'm a physicist who does mostly computational work, and I've recently started using rust instead of C++ for things that need to be heavily optimized. There are some definite pros and cons of rust at the moment for general numeric work. (I'm unfamiliar with CV in rust specifically.) The two obvious cons are the lack of stable libraries and the somewhat immature state of numerical optimizations from the compiler. C++ has fast-math and verbose auto-vectorization guidance. As far as I know neither of those features are readily available in rust yet. There's also the nature of parallelization in rust: memory-safety makes it different than in most languages, and it requires some extra attention. As for the pros * It's a young language. C++ often feels like three different languages that have been bound together against their will. * Safety. Many, many typical runtime errors become compile time errors in rust. This means they get caught early by an IDE. * Functional syntax. Easy to appreciate with a maths or CS background. * Speed. Rust can largely hold its own against C/C++/FORTRAN in numerical performance, and the above points can definitely help in faster production of correct code. I'd say the biggest issue is whether you need libraries that are not represented in rust. Most of what I do was already *de novo* even in C++, so I could switch languages without worrying about losing major dependencies. 
My best guess is that it's just more popular in general, and as such there's no need to learn a different language if they're doing something not data-sciency that isn't supported well by Julia. 
This is the subreddit for a programming language named Rust which has existed for longer than your game. (So, if anything, it has more claim to the name than the game does.) The game named Rust is in /r/playrust/
A lifetime bound on a struct or enum means that it doesn't last very long. `'a` means "this isn't real data, only some kind of helper for accessing real data." Most likely the `EditorConfig` (it looks more like state than configuration) should contain the `HighlightSyntax`, or own it via one of these types: - Box - Rc - Arc I call them "link" types. If the HighlightSyntax is mutable, it should probably go in a Box, or directly into the `EditorState` struct. 
How legible are compilation errors when using nalgebra?
The typical way to do what you want is to write a tiny closure or `fn` which calls a monomorphization of the generic. (The macro may need to call a fn. I'm not familiar with it.) Don't worry about the overhead. It's zero in release mode and "hopefully not too bad" in debug. --- Edit: I think you've guessed that's a way to do it. Imo closure syntax is *fantastic* at hiding the boilerplate - one of the best in Rust. (Implementing `ops` traits is pretty rough by comparison.) The macro may not accept a closure; if so you do need a named function. I write such small functions (one line, no branching) in abbreviated style like fn tiny(&amp;self) -&gt; Other { self.chained().calls() } However, that deviates from the Style Guide - you're supposed to give the `}` its own line. I spent a fair bit of time with Python and don't mind that shape. To each their own.
I mainly do C# and Rust dev. Just curious what libs are you missing from .net?
To be compatible with the `Iterator` trait, all items produced by the iterator must be able to be alive at the same time. Otherwise, methods like `collect` wouldn't work.
it looks like it is possible: https://github.com/sfackler/rust-openssl/issues/183 I suppose it might be on a library-to-library basis, which could make things somewhat difficult for a few libraries.
I don't think Rust is suitable for web development right now. As far as I know, there isn't any consensus about HTTP/2 yet. [Solicit](https://github.com/mlalic/solicit) and [httpbis](https://github.com/stepancheg/rust-http2) exist, but I'm not really sure if they're ready yet. I also just remembered that [h2](https://github.com/carllerche/h2) exists, but I think that it has a similar status to the other HTTP/2 libraries. The existing web frameworks are still quite young, and the most mature one, [rocket](https://rocket.rs/), only works on the nightly compiler at this time. If you want to do web development in Rust right now, you should expect to write a lot of the building blocks yourself, and the existing pieces may not be production ready. The good news is that some of the underlying infrastructure is looking to be stabilized by the end of the year. Specifically the [http crate](https://users.rust-lang.org/t/announcing-the-http-crate/12123) and a [synchronous HTTP server/client](https://internals.rust-lang.org/t/announcing-the-impl-period-sep-18-dec-17/5676) built on [Hyper](https://github.com/hyperium/hyper).
If you're looking for strictly web stuff, you may want to check out Erlang, elixir, or go. 
I help maintain [RustFFT](https://crates.io/crates/rustfft) and [RustDCT](https://crates.io/crates/rustdct) for computing the FFT and the various DCTs RustFFT is stable and mature and very much ready to use. Its performance is one of its strong points. It doesn't match FFTW, but it's fast enough for the vast majority of use cases. RustDCT is still very new and has a long way to go, but all its calculations are correct at the very least.
Where are the workshop videos?
What kind of content would be more interesting to you?
Sounds more like a complaint that system package managers are fragmented. And that's not going to get fixed. edit: I see you've discovered Nix. Nix (or Guix) are the best you're going to get for the very simple reason that you cannot avoid dependency hell in a better way. That said, Nix has to exist as a parallel package manager because short of an actual holy war, no one's going to force the distress to switch to it.
It may be easier to go with [Reqwest](https://docs.rs/reqwest/0.7.3/reqwest/) to start with, it is based on hyper but presents a synchronous interface which is easier to use.
oh so we are talking years, thats just great
You are absolutely using futures, yes. &gt; In javascript promises if I called .then(data =&gt; {}); on a promise, I'd have to put the code that depends on the promise completing inside that closure, where in Rust futures, it seems like it's waiting for the whole thing to finish before returning the function. I'm not sure I understood that part. `and_then(some_closure)` just means "run `some_closure` when the code depending from it is done running. Looking at your code, there are clearly things that are not going to work. Essentially, you are trying to mix synchronous code that calls asynchronous code and then returns to the "synchronous world". The only way this can work is by running the async code on a Core and waiting for it. In order to get the most performance out of the system, you (usually) should stay in the async world all the time (if performance doesn't matter, stay with sync). The drawback with async is that you lose a lot of what makes Rust useful (no borrowing across async calls, values that need to be threaded, difficulty to implement complex workflows). Take your `auth_result` function for instance, you are essentially chaining "promises", running the promise spaghetti over your core, and then you are back into the "synchronous world". Presumably, that's also what you intend to do in `auth_check`, because the current implementation gets some async code to run, but the function returns before it does anything useful (maybe it's a work in progress)? One last thing if you stick to Tokio, in `auth_request` you can take advantage of `flatten()` to avoid nesting your `and_then` and limit the "pyramid of doom" effect.
http://www.oreilly.com/programming/free/files/why-rust.pdf
One feature of Rust that I rarely see mentioned as a selling point is `enum`s. Rust's `enum` is not your grandma's syntax-sugar-for-a-number `enum`, it's a proper ML-style sum type that can store additional data and be destructured completely safely (with compile time checks!). Want to implement a tree? enum Tree { Leaf, Node { data: i64, left: Box&lt;Tree&gt;, right: Box&lt;Tree&gt; } } Want to walk it? match node { Leaf =&gt; { return }, Node { data, left, right } =&gt; { println!("{}", data); walk(left); walk(right); } } Want to add a third variant? Well, your `walk` code is now a compile error because the `match` is not exhaustive. The standard library is full of `enum`s too. `Option { None, Some(T) }` and `Result { Ok(T), Err(E) }` are the most common idioms for error handling that are not in any way "magical". An IP address is `IpAddr { V4(Ipv4Addr), V6(Ipv6Addr) }`. And so on, and so forth.
I *think* I'll be able to clean up the ergonomics a lot with specialization over associated types too, but I've been waiting for it to stabilize to play with it. If I'm correct, I'll be able to teach the compiler that performing arithmetic on dimensioned things will always give you something in that same unit system, and that you always can perform said arithmetic, removing the need for many where clauses.
@nwydo Thank you. That worked.
&gt; What do you think of the future of the two languages (Such as all the history c++ carries)? Rust has more room to maneuver, certainly. &gt; It seems Rust emphasizes Safety, but I've never really had much safety issues in C++, Hard to say. I don't think you really can guarantee the C++ has the same level of safety by inspection. 
If the last time you tried it was pre 1.0, it's definitely worth trying again. pros:- * no stupid header files * enum/[match](https://doc.rust-lang.org/1.5.0/book/match.html) (see [other answers](https://www.reddit.com/r/rust/comments/6xk3ja/cdev_here_sell_me_on_rust/dmgjf1k/)), * better lambdas, and better [type-inference](https://en.wikipedia.org/wiki/Hindley–Milner_type_system) (I list together because this is where it's most noticeable, versus c++'s auto: scenarios using high-order functions) * [expression-based syntax](https://en.wikipedia.org/wiki/Expression-oriented_programming_language) (writing everything initialised is easier, great with match) * traits: * allows '[extention methods](https://en.wikipedia.org/wiki/Extension_method)' (C++ missed out by rejecting [UFCS](https://isocpp.org/files/papers/N4165.pdf) or concept-maps) * unification of generic bounds &amp; vtables is elegant * immutable by default, (fewer 'muts' than 'consts') * handles '[move semantics](https://rustbyexample.com/scope/move.html)' more cleanly * better [standard library](https://doc.rust-lang.org/1.6.0/std/) (e.g. it's iterators more like [ranges](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4128.html), &amp;built around option types) * inbuilt [tuples](https://rustbyexample.com/primitives/tuples.html), (and .0 .1..) makes using multiple return values easy * safe/[unsafe](https://doc.rust-lang.org/1.18.0/reference/unsafe-blocks.html) boundary is a fundamentally good idea * better [macro system](https://rustbyexample.com/macros.html) (e.g. writing serialisers, shader parameter passing etc is easier) * easy-to-grep syntax (we have great IDEs in c++ but this is still handy) cons:- * no option for ~~ad hoc/~~unbounded polymorphism .. trait bounds can be more work for some types of generic code than in C++; setting up operator overloads is more work * inside the unsafe boundary , punishes you further with verbosity * safety means looking up more helper functions to do basic things (compile-time safety is an over-estimate ) * still waiting for a few features in the template system e.g. [constants as template parameters](https://www.ibm.com/support/knowledgecenter/en/SSLTBW_2.3.0/com.ibm.zos.v2r3.cbclx01/template_non-type_arguments.htm) (incoming..) * loses the middle ground of [C++ references](http://www.cprogramming.com/tutorial/references.html) (safer than ```*```, but less work than the borrow checker/annotations) * community momentum - important libraries are C/C++ first; you need to go through binding layers My own verdict.. ambiguous. Fundamentally there's a lot I like about it, but I'm still more comfortable in C++. Future.. modules and concepts will keep C++ interesting; I'm also looking forward to Rust eventually getting the template consts parameters and '[ATCs](http://smallcultfollowing.com/babysteps/blog/2016/11/02/associated-type-constructors-part-1-basic-concepts-and-introduction/)'. Rust being younger can move a bit faster. If C++ ever got [UFCS](https://isocpp.org/files/papers/N4165.pdf) it would win for me, conversely if Rust ever got some 'options for less fussiness' it would win hands down (the intent of the [ergonomics initiative](https://blog.rust-lang.org/2017/03/02/lang-ergonomics.html) is interesting)
One thing I personally love about Rust is that it has native modules support :)
Work on numerical computations, had to debug 2 segfaults to day. They only happened with 8000 cores, when the computation had gone for a while. Took the whole day to debug it, using 8000 cores. That's 8 x 8000 x 0,20€ = 12,800€ + the opportunity cost of others not being able to use these cores + my 8 hours of salary. One segfault was access a variable with improper alignment, the other was use of uninitialized memory. They wouldn't have happened in Rust. We are 40 coworkers, this happens to all of us once per week. Rust would save my company at least 100k€ a week, and probably way more (a college did the same thing today on 20.000 cores), and a colleague did the same last week on 78.000 cores. Needless to say, I try to avoid thinking about how much each minute of my debugging time is costing while working... My point being, memory unsafety and data races aren't free either. We probably have data races, but don't have enough money to debug them at this scale.
it would have taken longer to write it in the first place. Rusts safety isn't free. if there's an estimate of potential 100k/week saving, I'm sure you can afford a commercial static analyser, rather than taking the risk of a rewrite
* Clean Friendly Primitives. * No Exceptions. * Traits over inheritance. (It's a pro for me.) * Multiple returns through pattern matching (currently only on let clauses but eventually this should be expanded.) * Self-packing structs. * True generics. * No null, no nil. * Exhaustive branching handling. * Destructors are implicit and come free. * Move semantics default over copy (both can be derived.) * Build system. * Error messages (which will get even better when NLLs land.)
Thanks. The macro indeed accepts only named functions. But here's a nice trick I came up with: you can define an associated function on a generic type, and then define a type alias to that type. That way you can have a generic function item that doesn't contain generics in its item path. However, the macro wouldn't accept even that – it seems that it accepts only free functions. I'm looking into sending a PR that would allow associated functions on types too. I also think that since we have type aliases, we might have function aliases as well. But writing a RFC is a lot of work :(
Improper alignment and uninitialized memory would have tripped up valgrind the very first time they were hit. Is there any reason you can't use it?
deleted ^^^^^^^^^^^^^^^^0.7197 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/10351)
I've been watching a lot of CppCon talks on YouTube recently, and I've noticed a pattern. Pretty much every feature introduced in C++11/14/17 is piling features on top of existing C++ that Rust supports natively; things like move semantics, `auto`, `std::array`, `std::string_view`, `std::unique_ptr` and `std::shared_ptr`, `std::variant`, lambda expressions, and structured bindings. While it's fantastic that C++ supports these features now, it feels like it's constantly playing catch-up with Rust's native feature set. It seems intent on gradually making itself a worse language by adding more and more complexity to the absolutely titanic pile of syntax rules and language features that it needs to maintain backward compatibility with C, and even itself. I had never realized how scattered and arbitrary much of C++'s object syntax feels, and how hacked-together a lot of the feature set is, until I experienced how much more consistent and sensical Rust is.
I don't like the idea of another package manager like pip for python. I'd rather have an automagic way to prepare packages for a distribution. Sure you wont have the time to maintain the package yourself. But why do so ? As soon as you have a user base, I'm pretty sure people will be willing to do that. Afterall it's the tool they want to use on their favorite distro. 
This year when choosing talks we tried to go for accessibility, and talks that would be useful to the widest audience. The conferences you mention are multi-track, which makes it easier to cater to everyone. But yeah, this is a good thing to keep in mind for future years. I certainly would love talks like those. (I do want to try and push for next year's RustConf to be at least partially multi track, I highly prefer that model)
deleted ^^^^^^^^^^^^^^^^0.6958 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/45566)
[removed]
&gt; no option for ad hoc polymorphism Traits are exactly ad-hoc polymorphism.
I've learned the hard/frustrating way that parsing command-line args is not a problem that should be solved for each new program ;) Especially if _anybody else_ will use the program, they will have expectations about flag semantics (e.g. collect together short flags etc). I do find `clap` a little overkill for dinky programs though, so naturally I solved the problem again for my programs (`lapp`).
I've been playing with the Plugin Pattern, and getting some weird results. The rules of this game is that there is a program, and a shared library (`libloading` is brilliant). Both the program and the shared library are dynamically linked against the Rust runtime, so we can be sure that we're always using the same allocator. Entry points in the shared library are loaded dynamically. If they return things like `Vec&lt;String&gt;` then things are dandy Now, if both the program and the plugin link against a trait `Trait`, I was hoping for the plugin entry point to return a `Box&lt;Trait&gt;`. This is a classic way of doing plugins in C++, and it doesn't work. Any attempt at calling methods of the returned trait objects fails badly - which feels like a screwed-up vtable problem. This may be a limitation of current toolchain, of course. Any clues?
This might gather a lot of downvotes here, but I'll say that for some types of numerical computation, Rust is currently not the right programming language. Specifically, if you're doing highly generic numeric computation, or computation with "big" numeric types, by which I mean types that aren't `Copy`, and that are pretty expensive to clone, like BigIntegers, arbitrary-precision floating point numbers, [dual numbers](http://jliszka.github.io/2013/10/24/exact-numeric-nth-derivatives.html), etc., Rust just isn't there yet. For example, like /u/jswrenn said, for abstracting over numeric types, num is the de facto standard. But num is far from perfect. Num's [`Float`](http://rust-num.github.io/num/num/trait.Float.html) trait requires `Copy`, which makes it completely incompatible with arbitrary-precision floating point numbers. And the [`Num`](http://rust-num.github.io/num/num/trait.Num.html) trait requires (through the [`NumOps`](http://rust-num.github.io/num/num_traits/trait.NumOps.html) trait) that numerical operations take the arguments by value, which incurs needless (and potentially expensive) cloning if these arguments are "big" types. Similarly, nalgebra requires your scalar types to be `Copy` most of the time. In C++, I've used libraries for `Matrix&lt;T&gt;` where the author probably didn't consider that `T` could be expensive to copy. And it just worked, perhaps not as optimal as it could've been, with some unnecessary copies here and there, but at least it worked. But in Rust, a `Matrix&lt;T&gt;` type that requires `T: num::Float` will never work with "big" `T`s. Similarly, nalgebra cannot work with big types unless the author of nalgebra changes the library itself. I tried implementing a "proper" numerical library myself, but ran into a number of language issues. The [orphan rules can be a pain](http://smallcultfollowing.com/babysteps/blog/2015/01/14/little-orphan-impls/), [supertraits aren't as general as they should be](https://github.com/rust-lang/rust/issues/20671), [the primitive numeric types don't implement `AddAssign` (et al) with reference right-hand sides](https://github.com/rust-lang/rust/issues/32094), etc. I've even [tried to fix that last issue myself](https://github.com/rust-lang/rust/pull/41336), but there was a very minor backwards compatibility issue, and the almost religious devotion of Rust to backwards compatibility made me weary. So in summary, if the kind of numerical computation you're planning to do is with regular `f32`s or `f64`s, Rust should work for you, but if you're planning to go off the beaten path, well, I've tried but I went back to C++ (for now).
btw: how do i implement `unpack` on `Cons`? [playground](https://play.rust-lang.org/?gist=3266f852fe41f834962bb1df8766574b&amp;version=stable) EDIT: its not getting better ( [playground](https://play.rust-lang.org/?gist=de9a4dbfcc3250ae14815bcd64e219a9&amp;version=stable) ) maybe i am just to tired ... 
A joy to use. Amazing tooling. Great community (with the exception of me as I'm a bit of a dick).
Because the following C++ code: void foo() { auto s = "hello"s; bar(std::move(s)); std::cout &lt;&lt; "foo: " &lt;&lt; s &lt;&lt; "\n"; // s is used after move } void bar(std::string&amp;&amp; s) { std::cout &lt;&lt; "bar: " &lt;&lt; s &lt;&lt; "\n"; } Is a compile time error in Rust: fn foo() { let s = "hello".to_string(); bar(s); println!("foo: {}", s); } fn bar(s :String) { println!("bar: {}", s); } Error message: 140 | bar(s); | - value moved here 141 | println!("foo: {}", s); | ^ value used here after move
First of all, thanks for the feedback. I had similar to RustFest Kyiv and I can definitely see where that is coming from. I also have to say that the conferences you mention are happening in a vastly different space: they can fill a whole room with _very experienced_ practitioners of the language. That makes such talks _very_ worthwhile. As an conf organiser, I admit that I constantly struggle on this axis, especially as I have to set my _own_ expectations back and anticipate the audience expectations. But there's another thing: _all_ the rather deep technical talks end up as fringe things later. The most successful talks at RustFest? (On the event and later on our YouTube account) A Williams about how to bring Rust to your org, L Baillies talk about their journey into Rust (which is just great entertainment) and lislis talk about programming a very simple game in Rust. We're talking about a magnitude of 10000 views to 300 here. Obviously, YouTube views isn't the reason to run a talk at a conference, but it gives you some statistics. There's huge interest in these entry-level things and RustFest is definitely a good spot for local people to just come in and dip into the community. For experienced people, it's a great meeting spot, that's also why we have a full day allocated to _that_. RustFest 2016 had a really technical keynote and the feedback after that was that some people felt steamrolled (which we anticipated, that's why we put it first). That gives you a feel for the audience. I assume that this situation will get better soon, maybe some conferences will grow a second track and have more _hard_ subjects, I'd definitely be looking forward to that! Please continue giving your feedback and please also watch out for the RustFest Zurich video release. (coming... maybe... in October)
HTTP2 is not currently implemented by any of the major web frameworks (mostly because hyper does not have it yet). I do think you can do web development in Rust but it's not nearly as convenient/easy as Java/C#/Node/Python etc. The libraries to do most things do exist, but they are generally not as mature as their counterparts in other languages. Compile times can get annoyingly long (20 seconds to 1 minute after a small change in debug mode) and documentation is often lacking (with some notable exceptions like Rocket). However! When you get past all that, you are left with a fantastic, modern language with an excellent type system that produces super fast code that consumes almost no resources, predictably (like a tenth of the RAM usage of an equivalent Java project), has a ton of compile-time guarantees and almost never crashes. 
This is a big one for me. Since moving to Rust, while trying to catch up to the new C++17 features I noticed myself frequently muttering "this is much easier to do in Rust".
Use Elixir or Erlang. Rust is great but not in this area. Elixir and Erlang were languages pretty much built for writing servers.
A static analyzer does not guarantee safety though.
It's probably is better now, but last time I tried Julia it had a massive overhead. Just importing the plotting library took a minute every time, making it unfeasible to replace Python scripts.
&gt; // Seen this one in constructors more than once &gt; // to initialize member references to null… That's UB as hell though, it's completely crazy, a major draw of references is that they can't be null.
deleted ^^^^^^^^^^^^^^^^0.6739 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/82179)
I don't know of any such crate in Rust, though you should probably do a bit of searching on crates.io to make sure. And if you're going to write one yourself, you may want to take a look at Python's dateutil.relativedelta (and maybe dateutil.rrule as well), the ICalendar concepts it reifies, and possibly Java's new Date API (JSR-310).
deleted ^^^^^^^^^^^^^^^^0.5182 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/38212)
&gt; It is not only "how do I use rayon", but how is rayon implemented, why is it implemented this way? how does the workstealing algorithm work, what desgin patterns can be found in rayon, which parts of rayon are "ugly", why? which language features could help? etc. Is this just an example or have I missed this talk?
&gt; `std::array` Bad example, until Rust gets const generics. ;-]
&gt; All of my examples are undefined behavior. Yeah but the others have at least some subtetly to them and are easy mistakes, creating a null reference has no subtetly and is closer to wilful malice. &gt; If you only have great developers that never make any mistakes you don't need Rust. The moment you start having huge legacy code bases with 100s of developers of all possible backgrounds and skill levels you start to appreciate how a language that requires you to go way out of your way to do the wrong thing becomes valuable. &gt; Introducing these types of UB is not impossible is Rust. It is actually quite easy. The difference is that in Rust the trivial way doesn't work. The language requires you to explicitly contort yourself with many "i know what I'm doing" checks to be able to shoot yourself and everybody else in the foot. Sure, I completely agree, which is why I use Rust. C++ terrifies me, I see people casual with C++ the same way I see people casually juggling live chainsaws after a few shots.
Moving a `char const*` is the same as copying it, so that code is actually technically safe. ;-] `auto s = "hello"s;` would prove your point, or `std::string s = "hello";`.
Erm, no. Ad-hoc does not mean "compile-time" here. Ad-hoc refers to the kind of duck typing approach of C++ templates. You don't have to say anything about a template parameter's requirements in order to use it. Sometimes this is more convenient than being forced to name requirements. Sometimes it's more annoying especially when the compiler outputs multiple pages of template errors. 
A fast and pretty way to handle routing. I'm looking for something like Express for Node. And as I mentioned, HTTP/2.
deleted ^^^^^^^^^^^^^^^^0.4533 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/14380)
my C++ is a bit rusty
Besides a 30x slowdown? No, no reason, we do use it. It doesn't scale. We also use Asan, UBSan (this was caught by UBSan, but you still have to debug it and fix it), MSan and TSan.
We do use various static analyzers (clang-tidy and static_analyzer), and fix/silence all the issues they report. None of them catches real memory or thread safety issues in modern C++ code bases. They have false/true positive ratio of 100-1000 to 1. We fix them all, yet the real positives are typically trivial, and the false positives take a lot of work to silence. The reward of using static analyzers on Moder C++ code bases is close to zero. We have tried commercial ones (VPS Studio i think was called) and they are not better. I really cannot remember the last time I said, "wow, this bug would have been really hard to debug if it weren't for the static analyzer". Probably that never happened.
To be clear, I'm not participating in a prescriptive debate here. I have no interest in philosophizing on package managers. Opinions in this arena are a dime a dozen. What I'm saying is descriptive based on my own experience. In my case, I was very fortunate to have the users to do the packaging for me. But not everyone has those users, and indeed, there is a chicken and egg problem here, because a big part of getting users in the first place is providing super easy install steps.
If I had to summarise I would say that the main con is that Rust still is very young, with all what it implies: libraries (a lot of libraries are bindings around C/C++ libraries themselves), tooling and the ecosystem in general is not there yet, but "slowly" getting there. And there is lack of certain features (like generic arrays as pointed out, better support for SIMD, some sort of HKT and more metaprogramming in general etc. etc.) because of it, but a lot of them are planned or in process of being implemented. The main pro is that is a young language, with all what it implies: no baggage and little to none technical debt and legacy code to support and a more well-rounded and consistent language over all. You can tell Rust has a very talented group of computer language theorists and designers behind it. Writing Rust (when you get some proficiency) is very pleasant, when you read/write C++ you can feel that a lot of it has been patched up and hacked over the years, for me personally is not pleasant (even if you write it 'correctly' and 'safely'). Also Rust has a more functional feeling and approach (if you want to use it that way, you are not forced to, you can write Rust as a modern version of C if you want). That plus all the features that are usually promoted. Oh, and enums! Love Rust enums and pattern matching.
There are only a few bitwise operations available on atomics (essentially: load, store, compare-and-swap). Many useful operations such as atomic increment/decrement, etc... can only be implemented with CPU support, and could not be provided. As such, the interface for a `AtomicF64` would be painfully limited, to the point one wonders if it would be worth it.
Note: micro-benchmarks run the risks of being rather unhelpful here, as the principal cost of atomics on x86 is reordering issues which may not show up if there is nothing to reorder...
For those who are (like me) struggling to understand the rfc: https://request-for-explanation.github.io/podcast/ep4-literally-haskell/index.html
Actually, foo's `s` is not moved at all. You just initialize bar's rvalue reference to alias foo's `s`. But yeah, the much simpler move semantics in Rust is one of those things I keep mentioning, too, whenever I compare the languages. :)
Me too, I've got a couple `panic!("unimplemented - {:?}", rest)` that I can finally get rid off.
Very interesting stuff. Lack of documentation might be a barrier though.
Yes, I've seen that one. I just had this sliver of hope that an in-depth video would exist. :)
Rust ABI is not defined [issue 600](https://github.com/rust-lang/rfcs/issues/600), so the only way to get defined behaviour for plugins is `extern "C"`. Afaik, this is technically *also* true of C++. There are draft ABIs, but nothing stable yet. The difference is that the Rust compiler is changing too quickly for the "cross your fingers and hope it doesn't break" strategy to work. `extern "C"` should work perfectly fine, but you don't get vtables for free.
&gt; I could have my foot in my mouth in saying all this but I already dislike Rust devs throwing all of their binaries up on crates.io instead of using existing distribution channels. As has been stated, the issue is that there is no "aggregated" publisher, so that a separate publication must be made for each existing distribution channel which is ridiculously expensive time-wise. At this point, I think the way forward would be a change in cargo itself: - to automatically publish new versions on existing distribution channels, - to automatically fetch from the appropriate distribution channel (based on the user's machine) if available, and fallback to compiling otherwise. It would, probably, be a massive work, and not all distributions would enjoy this (as some wish to manually vet the distributed binaries).
[Like this](https://play.rust-lang.org/?gist=0123caed3dc20c23b01361c343276d16&amp;version=stable)
Stack, unless you specifically put it on the heap.
You probably would have liked my earlier drafts of the talk more. I focused on making the talk accessible to everybody in the audience.
I wouldn't expect that a developer of a tool also creates packages for all these managers. I'm also just putting my tools on crates.io.
I need this as well and plan to implement the minimal features tomorrow. I plan to base this on chrono. Unless you find a good crate that does this, in that case let me know :)
I don't see your point. Just because HTTP2 seems to be missing, doesn't mean Rust's ecosystem isn't superior to C#'s.
I just started implementing such a thing. If you can hold back for a few more days, until monday I should have a base set implemented (and my blog post published on it - the publish date for the post is planned on 04th Sept.). If you cannot hold back anymore I'd share my blog post with you, privately, and we can discuss things after you read how I want to tackle this. 
I got a start on some subset of these futures last week, https://github.com/stephanbuys/timestrings - happy to provide assistance or take PRs.
Hm. Interesting, but I have a completely alternative approach to this, actually.
&gt; I think a point I did not mention is that maybe my expectations of the conferences are just wrong, that is, I might not be the audience the conference is targeting. Or maybe I am just part of an audience that the conference is only tangentially targeting. No, your expectations are right, we just (currently) don't deliver. That's a problem, but we have to manage quite a couple of them. RustFest has a kind of fuzzy name precisely because it kind of is. Any of the conferences is organised by a different team at a different location (with some people sticking around), we reserve the option to change the format drastically anytime. The continuity is the passing on of the torch, not the style of the content.
&gt; Is Rust too low level/unsuitable for web development? Rust is not too low level for web development but it doesn't sound like it's ready enough for you. The low level trickiness mostly comes up in data structure and library development but if you're just gluing together libraries [it's pretty easy](https://rust-lang-nursery.github.io/rust-cookbook/net.html#make-a-http-get-request). The network stuff in Rust is still cooking. If you need to do something soon you should look elsewhere. That said, I want to make the pitch for Rust webdev once everything is working. The most important thing that's happening is that Rust currently has a community consensus around the async abstraction (Futures, which are pretty close to JS Promises), the service abstraction (Tokio, like an extended WSGI or Rack), and the http types. This is significant because many languages don't have a consensus so there's converting back and forth between multiple conventions. In node the async difference shows up as the difference between Promise APIs and node callback conventions where you have promisify and/or libs that return a Promise if you leave off the optional callback parameter at the end, etc. Relatively minor issue in dynamic languages but it's a real pain in statically typed languages where the boilerplate is more involved. The importance of the service abstraction is that it should allow for middleware and for business logic to be wired up after it's written. Have a web app that you want to serve over QUIC instead of TCP? That should be doable. Want full application tracing wired into Zipkin? The same middleware should work for your load balancer, app server, and db connection. Need to make a service call? The response from an http client call [can be passed directly through the web framework](https://github.com/mehcode/shio-rs/blob/master/examples/proxy/src/main.rs) (~10 LoC http proxy) because everything is using the same abstractions. All this stuff is version 0.1-0.3 software and people are still experimenting with it. There's an experimental macro-based async/await kicking around. The http2 crate was announced last week. Things are rough. Rust software tends to run pretty well once it's written and pioneering folks are using it in production so it probably isn't blowing up daily on them but the APIs are very unstable and it's likely the code you write 6 months from now for doing web dev won't look very much like code you'd write today but I think the potential is there. So, aside from an all-singing magic async future, Rust has a couple other things going for it that should make it better than most of the current mainstream explicit statically typed languages for doing this stuff. The first is macros. Macros have the potential to remove significant amounts of boilerplate. If you look at [serde](https://github.com/serde-rs/json#parsing-json-as-strongly-typed-data-structures) parsing JSON into a struct for use isn't much more complicated than writing out the struct you want to extract. I'm reasonably confident that anything involving significant amounts of boilerplate (e.g. wiring up routes) will wind up getting macro'd in a mature Rust web frameowork. The second is traits. Traits allow ad-hoc polymorphism so you can wire up your own data structures to participate in other people's abstractions as you see fit. It's a statically checked way to do the same thing as duck typing in dynamic langauges. One of the major annoyances of static languages is having to write boilerplate to convert types back and forth. An example would be that the filesystem APIs take a `Path` type and not a string so every time you want to open a file you need to `Path::new(&amp;the_path)` from the string you have on hand and then pass that in. One of the better ergonomic improvement in Rust is the [`From`](https://doc.rust-lang.org/std/convert/trait.From.html) and `Into` traits which allow automagic conversion. The filesystem APIs actually take an `Into&lt;Path&gt;` and Into is automatically generated when you implement `From` so by implementing the `From` trait for string and `Path`with a one-line function returning a new Path you can pass strings into the FS APIs and the conversion to `Path` will happen automatically. The stdlib already does this so there's need but that's the general idea of conversion traits. What's important about this is that you can implement it for anything. You could implement it for, say, SHA1 hashes if you have files named by hash or for dates if files are named by date somehow. I mention the conversion traits because Rocket is currently the most ergonomic web framework and conversion traits are one of the key ideas for cutting down boilerplate. Rocket isn't restricted to returning a string or a buffer. It returns anything that can be converted into a Repsonse (the `Responder` trait). Class based langauges can do this by implementing an Interface but to do that you need to control the class defintion while with Traits you don't. If you really wanted you could define a conversion trait from the DB results to a Response and just return the db call. More importantly, Rocket has the idea of request guards. Request guards serve most of the same purposes as middleware but they're wired on a per-handler-parameter basis using the `FromRequest` trait. When Rocket matches a route it will call `from_request` for each handler parameter. If all the conversions succeed, the handler gets called. The trick is that you can perform validation and business logic during the conversion. This means that your handler *doesn't* need to validate that all the parameters are present or that they're of the right type or parse them from strings. All of that happens in one place (the model) and gets reused everywhere. Request guards aren't restricted to just form data or path/query params, the rocket docs have an example of [a db connection pool](https://rocket.rs/guide/state/#connection-guard) and with that boilerplate in (they plan on building it into the framework in the future) you can just write `conn: DbConn` and when the handler is called you'll have an established connection and it will automatically close when the handler ends due to Rust's ownership system. This can be taken further. A common problem in web backends is that, say, 30% of your routes need your User data. You can either look it up in all the handlers that need it or put it in middleware. The problem with looking it up is the boilerplate, the problem with the middleware is that it happens on every request even if it's not needed which pushes you to a db caching layer. Implementing`FromRequest` for your `User` struct by pulling the userid out of the cookies and using that to pull the User from the db means that putting `user: User` as a parameter is all you need to have a valid user. Have admin users? typedef user to `AdminUser` , reuse the `User` guard, check the admin field, and use the `AdminUser` type instead of `User` in the admin routes. The tl;dr of this (which got quite a bit longer than I expected) is that with the guard system, your handlers just have to implement the happy path and the non-happy path can be implemented once and reused automatically everywhere. The non-happy paths are what absorb all the time in writing a web service. Rust doesn't break a ton of new ground in terms of language features (other than ownership) so this pattern may be usable elsewhere but I have not seen it and I've explored hundreds of web frameworks in several dozen languages. The combination of ad-hoc polymorphism and macros is fairly rare (Clojure and Nim afaik) and the combination is what makes Rocket ergonomic. People complain about Rocket using unstable features but I think the patterns it has are both novel and good.
Can I pull this with rustup, or do I need to clone and build from github?
Thank you so much for taking the time to write that detailed reply. I think you're right - Rust probably isn't what I'm looking for right now. I was attracted by the speed, thread safety, and so on. I want a mature language with an ecosystem like JavaScript's, but without the quirks. I don't really know any candidates like this. Some have suggested Elixir/Erlang but they are a little too close to Python for my liking. I think I'll have to go with C# after all, unless you have any suggestions? Thanks.
It's just the RFC, the implementation is not there yet.
Is it possible to define type aliases for associated types, inside traits? Writing `&lt;&lt;Self::DbTable as HasTable&gt;::Table as AsQuery&gt;::Query` many times gets old quickly, so I'd like to write something like `type TableQuery = &lt;&lt;Self::DbTable as HasTable&gt;::Table as AsQuery&gt;::Query` and be over it. Of course, I could just define `type TableQuery` as a normal associated type, but it needs to equal that other type, so there would need to be a some kind of "these types equal" kind of assertion in the where clauses. I don't think where clauses support that.
I feel like there's no content there for intermediate Rust developers. Someone who's worked in it for a while and would like to know things like: * Let's take apart the Tokio/Futures crates. Why are the types designed the way they are? How can you use those principles in your own code? * How would you write procedural macros? When? * How are libraries like Rayon implemented? * How is async/await implemented? What does it translate to under the hood? When will the abstraction break down, and how? I'd like to echo the point above: the videos felt very much targeted to people who've just started to dip their toes into Rust. That's not an issue (the community has to be grown, after all, and maybe this is the right focus for the foreseeable future) - but just an observation.
Oh, I found the relevant issue: https://github.com/rust-lang/rust/issues/20041 So, it seems that they ought to be supported, but they aren't yet. Even the compiler goes `error: equality constraints are not yet supported in where clauses (#20041)`. As of late, I've been writing highly generic code, and it's frustrating. I could think of at least two improvements that would immediately improve the quality of life: 1) Supporting type equality constraints, because it allows expressing monstrous types succinctly. 2) Better error messages: at the moment all types and traits are shown with fully qualified paths, which makes the error messages messy and tedious. If it would check which ones of the types and traits are already in scope and leave the path prefix off of those, the error messages would be a lot cleaner.
Ohhh yeah sorry I misread. Damn.
So next I did `extern "C"` as suggested, but made the entry return `*mut Trait` from `into_raw` on the `Box`. And I can (unsafely) call the 'trait pointer' methods successfully! So it turns out, yes, we can use vtables, just can't return a box value and expect it to work.
&gt; Ad-hoc refers to the kind of duck typing approach of C++ templates. I am not sure that that is true, see https://stackoverflow.com/a/6885445/24817 which cites TAPL. With the addition of specialization, Rust broke parametricity, and is therefore ad-hoc.
&gt; I think I'll have to go with C# after all, unless you have any suggestions? Kind of hard to give you a specific suggestion since you're coming from JS and don't have any requirements other than http2. Go isn't my favorite language but banging out web services is what people use it for and people seem to like their http2 implementation. I don't write C# so I don't know what's going on there. I do write some F#, which has Suave which is a decent api. You can tap into the .Net ecosystem with F# but the F# native web stuff is kind of spartan. Kestrel is looking to be a pretty good app server but I don't know exactly what's going on with .Net core. I've put more time into the JVM. I wrote Clojure professionally for two years and think that Aleph with Ring handlers is pretty good. I expect someone has written a decent http2 library on top of netty but I honestly haven't tried it. Kotlin would be the other language I'd use for JVM stuff. I don't know how the native Kotlin stuff looks but Dropwizard or Play should work (though I haven't looked at Play in years). Scala has Finagle, which is pretty nifty and the major inspiration for Tokio's service model, but I don't like Scala. It sounds like you don't really want Ruby or Python and that's it for the really big ecosystems. Elixir is syntactically like Ruby but I expect it'd scale much better than Ruby or Python due to the Beam VM.
Puns!
I can only imagine popularity being the only reason. Julia may ship with all the best numerics and scientific computing libraries by default, but it's also a general purpose language, which can also import C and Python libraries.
Rust is very much like C++, it will put everything on the stack by default. To store things on the heap you have to do so explicitly (usually by wrapping them in smart pointers like `Box` or `Rc`). Note however that (also as in C++) some types may "implicitly" perform heap allocations e.g. `String` or `Vec` are on-stack structs but one of the members is a pointer to a heap-allocated buffer.
Thanks for the explanation! I think I will swap to reqwest then. I don't really think I need the async. All this code in the api.rs file will be running on a separate thread from the rocket server. It's going to be (when it's done) fetching data from the printers on 5 minute intervals and storing it in the database. Also, yes, the auth_check function is incomplete. That's where I got stuck on the error in the OP.
Does this mean it will be possible to create a non-allocating iterator over chunks of a file (or any `T: Read`), like in this [playground example](https://play.rust-lang.org/?gist=01412cf44c65a0e4abb4aa83d06d9b81&amp;version=nightly)? 
It doesn't even require non-parametricity; traits are ad-hoc polymorphism (see: https://wiki.haskell.org/Polymorphism#Ad-hoc_polymorphism)
It also occurred to me (when I was first facing the `rustc` Wall of Red) that abbreviated types would be helpful. So the user would be presented with `HashMap&lt;String,String&gt;` which is easier for humans to parse. It's confusing with multiply-defined types like `Error` tho, but the compiler is in a better position to detect ambiguity than an external clean-up script
Watching the keynote made me excited for the ergonomic improvements that will land after the “impl phase” this year and it also made me excited for the book being released in December. I’m curious about the relationship between these two. Will the book contain the ergonomic enhancements? Or will the book’s content already be a little bit behind where Rust will be at that time? 
I think I see the misunderstanding. Rust traits are not the same as C++ traits. Rust traits are like Haskell type classes and have nothing to do with templates.
You will be able to get it with rustup's nightly channel the moment it's available, but I wouldn't expect that for a good while.
Yes, `Error`s are easy to confuse. However, I think that since the error messages are at the moment maximally verbose, there is room for more succinctness without introducing confusion. Heck, the type I used as an example earlier was actually `&lt;&lt;&lt;mycrate::mod::Type as mycrate::mod::Trait&gt;::DbTable as diesel::associations::HasTable&gt;::Table as diesel::query_builder::AsQuery&gt;::Query`. 
What is the borrow checker , if not a 'static analyzer' if you need to annotate lifetimes, that could be built into a new type of smart pointer IMO.
&gt; Traits are exactly ad-hoc polymorphism. they're controlled polymorphism; I use the term ad-hoc to refer to overloading *without* traits, and generic type-params *without* trait bounds 
 const int&amp; bar() { int a = 2; return a; } Any decent compiler will give you a warning there, and you can select warnings=errors. There's no scenario where this is valid , so despite being within the language definition, it wont break any working code to disallow it.
 // Seen this one in constructors more than once // to initialize member references to null... const int&amp; a = *(int*)0; The time i've done this is to break to the debugger (there's usually a better way to do it), or in 'decltype' expressions (and there's now a way to do that properly, ```std::declval&lt;T&gt;()```) There's no scenario where you *need* this , so again it could be warned about (the compiler warning could tell you the alternatives), and outlawed.. an easy thing to exclude with a static analyser if your compiler doesn't already.
&gt;&gt; it feels like it's constantly playing catch-up with Rust's native feature set I can say the reverse. There's still features in the C++ template system that I'm waiting for in rust. I don't like the 'too much complexity' argument: a lot of the pain comes from 'half working' features/ommissions, and the extra features completing them make the language *simpler* to use. Millions of LOC in the language saves 100's of millions of LOC for users. For example, 'initialiser lists' are a new feature, but they simplify the language, in that the existing literal syntax becomes universally applicable. I do prefer the [rust-trait way of doing vtables](https://alschwalm.com/blog/static/2017/03/07/exploring-dynamic-dispatch-in-rust/) , but the OOP system in C++ does still have valid use cases ... there's been discussions in the rust community about demand for "thin-pointers". Using [dynamic cast](http://en.cppreference.com/w/cpp/language/dynamic_cast) you can sometimes handle a use case a little like an variant *with variable size* (rust-enums are padded out). I think [scala](https://www.scala-lang.org) does go and provide a match-like syntax for using classes ([case class](http://docs.scala-lang.org/tour/pattern-matching.html)?). This would be 'yet another retrofit', but one I'd welcome.
I think you'll find people here use those terms differently. A generic type param without a bound is what PL theory usually calls parametericity. Since you know nothing about the types the variable will be instantiated at you are forbidden from doing anything specific with it in the definition. Therefore, the definition is very uniform with respect to the type parameter. Ad-hoc things are those that allow you to provide special cases, such as overloading for different types. Bounded parameters are a bit of both. The bound excludes some types but also increases the set of operations you can use on the unknown type. I recommend checking out TAPL (if you haven't already) and the SO link that /u/steveklabnik1 shared below.
While learning rust I tried to write a windows function for iterators and got pretty frustrated that I couldn't store the ringbuffer in the iterator itself. Didn't expect rust to support this for a long time, I am seriously amazed how quickly rust is improving without losing track of long term goals. Awesome work!
Thanks for your comment. I added a link to a documentation page (https://pikkr.github.io/doc/pikkr/) on README.md of the GitHub repository. However, the documentation page does not have enough information for now. I will write documentation fully. Thank you very much for your advice.
whilst your concerns are different issues to mine, this is certainly parallel to my observations; For all the criticism it gets, C++'s template/overload system is actually *good* at handling numeric code over various types, and I've always missed things about it when trying other languages, including Rust.
For the record, nix solves this problem on Linux/Mac. Of course, I understand that isn't quite as useful as something that works on Windows + BSD as well. 
Should the ecosystem have a crate like the HTTP crate that contains traits that various implementation crates can use? I imagine that some use cases might want zero allocation on a fast path when doing date time operations while other users might want a more complete and correct implementation with complex calendaring — but it might be nice to have common traits between them. 
&gt; If it was easy for a maintainer to distribute binaries that could be installed on ANY linux or mac OS, that would be a huge boon. Nix does this already. 
I love our ongoing json benchmark wars. /u/dtolnay had some other ideas to speed up serde_json, and we haven't yet played with avx, so we have some room to catch up. It's great to have competition. :) Have you tested your parser against this suite of [tests](http://seriot.ch/parsing_json.php)? Could this be integrated into the serde ecosystem? It'd be great if we could deserialize into structs. 
How does it solve it? Isn't it just another package manager that only allows people that use it to download your nix package?
I've suffered with the C++ equivalent, although Rust is miles better at being _definite_ about compile errors. But man, those types!
It's not what you're looking for, but the `dow` crate might come in handy.
Maybe, but I'm doubtful that this is possible without ending up with something that is not C++ anymore. Lifetimes are not enough, you also need Rust's move semantics. In any case, it does not exist right now.
Thanks for your comment. It would be nice if pikkr's idea, approch or itself would be integrated into serde, which is one of the most popular crates. By the way, I noticed that [json](https://github.com/maciejhirsz/json-rust) is much faster than [serde_json](https://github.com/serde-rs/json) when I was executing benchmark: https://raw.githubusercontent.com/pikkr/pikkr/master/img/benchmark.png https://users.rust-lang.org/t/json-rust-0-9-0-released-cuts-parsing-time-by-half/6564 says that [json](https://github.com/maciejhirsz/json-rust) cut parsing time by half. I have not read this post thoroughly yet but it might be helpful for [serde_json](https://github.com/serde-rs/json)'s performance improvement.
&gt; you also need Rust's move semantics. C++ has [move semantics](http://www.cprogramming.com/c++11/rvalue-references-and-move-semantics-in-c++11.html), it just needs explicit ```move()``` sometimes (I do prefer explicit ```.clone()``` instead, but it's not a deal-breaker), and we'd need a static analyser or compiler warning to tell us if we try to re-use a moved value
I don't believe those were recorded events.
Traits are less ad-hoc polymorphism ;)
Suppose I want to move a value out of `Rc`. Why isn't there a method like `fn(Rc&lt;T&gt;) -&gt; T where T: Clone`, only `make_mut`?
The official VSCode extension `Rust (RLS)` has the feature "Update RLS", where exactly does this install the RLS components? It doesn't seem to use or overwrite the already installed RLS in the system path. Also, how can I instruct the extension to use the system RLS that I already installed with rustup? I don't want to maintain and update two separate RLS installs every time. --- edit: It looks like it installs the components into `.cargo/bin`, while the rustup rls is installed into `.rustup/toolchains/xxx/bin` (which I forgot wasn't actually in my path before). I removed the executables from the former and added the latter to the path, and now the extension notices its existence. 
Going through practice problems to get more familiar with generics and traits. If I can wrap my head around the generic associated types RFC by labor day I'll be happy. Learning Rust is a slow process for me :)
&gt; we'd need a static analyser or compiler warning to tell us if we try to re-use a moved value That's what I mean't. Move semantics without that are making the language less safe, not safer.
Maybe this should have gone in the "working on" thread, but i really wanted a way to cache values without binding the cache to the actual type of the values cached. This means keeping track of allocations yourself, in BTreeMaps, and making sure to make room and evict old values (and manually running their destructors, which turned out to be quite non-trivial) Anyway, i hope someone finds it useful, and i'll be doing some more databasey stuff in the coming time, which was the motivation for this crate in the first place.
Yes and no. You can make a trait for streaming iterators as they are typically called (The RFC even uses them in its motivation) but you can't use the Iterator trait. 
Would you accept a PR that adds a constructor for single threaded caches? (No code duplication, just HKT)
I agree with this. I'd consider myself a roughly intermediate developer in Rust (I've written around 5-6k lines of relatively high performance Rust). There are not many resources on how to best use the features of Rust. For example, I'd love to see more information on * How can I use the existing type system to ensure even more correctness at compile time? * What is a good set of practices to best leverage compile-time checks for the fastest performance? * How do I reason about performance logically when writing relatively high level code without having to dive into assembly? I learnt some cool new things from Sean's talk, but I wish there was more along those lines in the community.
Most likely yes, but i'm aiming at having it work on stable. (actually 1.20 is required atm, because of ManuallyDrop, but this might actually not be neccesary)
You could have a debug build with a flag that is set, giving a runtime error in a test . That would require [coverage](https://en.wikipedia.org/wiki/Code_coverage) of course but it would be better than nothing
You should be able to use `fn(*const ManuallyDrop&lt;u8&gt;)` instead of `Box&lt;Fn(*const ManuallyDrop&lt;u8&gt;)&gt;`, which would avoid a heap allocation.
Could you explain what feature of [`get`](https://github.com/krl/cache/blob/master/src/lib.rs#L385) guarantees that the `transmute` is correct? That is, what prevents me from inserting a `(usize, usize, usize)` and getting a `String`? I do not see any run-time check, and in the absence of such checks `get` would be `unsafe`.
Would it be a big faff to work on the feature myself? I haven't done much open source dev before, certainly not on a project this big. Would I end up writing thousans of loc then having my PR rejected because I'd gone about it in a non-idiomatic way? Or would it be merged in, and an issue added for refactoring or whatever? Obviously putting aside the complexity of the topic.
This is cool. Sure, I wasn't expect a breaking change to the `Iterator` trait. It'll probably be a new trait as the RFC suggests.
I had no chance to test it on MacOS, because I am Linux user, so it may not work as expected. A feedback is welcome)
I don't think it's productive to change the name of the conference. RustConf is mostly accessible-to-all talks _now_ because that's what the community _needs_. As the community grows we'd probably evolve the kinds of talks we have. This isn't a permanent choice.
I remember I was using something similar for Ruby, this can be pretty useful. Also looks it's enjoyable to use if compilation time is short, and less enjoyable with big projects.. Anyway, thanks!
I don't know how complex this work is. I suspect very. However it's worth [asking on the tracking issue](https://github.com/rust-lang/rust/issues/44265), at the very least I bet there are smaller tasks you may be able to do that help. Generally if folks step up to implement something we do mentor them, so you'd be able to get realtime feedback for how to design your code. I wouldn't worry about having code thrown out, as long as you keep in touch as you make progress. 
You want `chrono` and `chrono::Duration` https://crates.io/crates/chrono
To help with the typing, you can have something like type TableQuery&lt;HT&gt; = &lt;&lt;HT as HasTable&gt;::Table as AsQuery&gt;::Query; And then call it with `TableQuery&lt;Self&gt;` or `TableQuery&lt;Self::DbTable&gt;` There's also a nightly `#![feature(associated_type_defaults)]` where you can default the normal associated type in the trait itself, e.g. trait HasTable { type Table: AsQuery; type TableQuery: Query = TableQuery&lt;Self&gt;; } But yeah there's not truly a substitute for equality constraints on where clauses, unless perhaps you can encode that equality into a trait bound but I'm not clever enough to do so quickly.
After you do `make_mut()` you can do `Rc::try_unwrap()` and just panic in the error case since it's guaranteed unique: // Ignore the result here because we only care that the `Rc` is unique let _ = Rc::make_mut(&amp;mut my_rc); let my_val = Rc::try_unwrap(my_rc).ok().expect("Rc was supposed to be unique");
The PR will be code reviewed &amp; iterated upon until it is idiomatic
1. Static values go in the static memory of the program. 2. Values contained within types that do heap allocation (`Box`, most containers like `Vec` and `HashMap`, `Arc`, `Rc`, `String`, etc.) go on the heap. 3. All other values, including the fixed-size portions of the types listed in #2, go on the stack.
"early next year" maybe
On the performance talk: Since he mentioned perf, you can use hotspot as a graphical analysis tool: https://github.com/KDAB/hotspot Right now you can load perf.data files with it, but zooming in and inspecting the functions is a lot easier than running Brendan Greggs svg script.
This feature is really about refactoring the trait system to support is better, so it would be hard for someone without that context to take the whole thing on. As Manish said, there are probably mentoring tasks involved though (someone just has to write them up). (If you think about it, methods have their own type, so they are a kind of associated type. We have generic methods, so we have generic associated types. You just can't do anything with them.)
Just one question: is it smart enough NOT to start a new `cargo test` command if one it started is still running? On projects with a longer compilation/test time, it would quickly overload the machine otherwise.
Dangit. After implementing 2k lines someone tells me that there is already such a thing. Thank you very much.
this can't be overstated. I wrote a big-ish comment about this recently: https://www.reddit.com/r/linux/comments/6vi7oq/10_years_ago_we_did_the_same_with_10x_less_ram/dm1prna/
tagging u/DirtySciencePirate so maybe they end up seeing this
You are correct, and i should mark unsafe, or save TypeId on this one, good catch!
Wow, thx I think I was sleepwalking :D
&gt; I want a mature language with an ecosystem like JavaScript's, but without the quirks This doesn't really exist. Python and Ruby are good, and I'd say Python has very few quirks, but their ecosystems don't beat JS at this point. I think Rust will be able to fill this spot in the future, but I'd guess it's a year away from having everything one would expect, and 10 years before it has an ecosystem to rival JS... (though having looked at express, express-session, etc, I can't say the JS ecosystem impresses me much. It's enormous, but quantity isn't quality.)
Ah, should checked the Haskell wiki; thanks!
I'm not sure it's safe to create trait object in one crate and call them in another (but it's no surprise that it works when both were built by the same compiler). 
~~rc.clone::&lt;T&gt;()~~ should do it. Just need to call the right implementation of `clone`. ETA 2: This doesn't work because `Clone` doesn't have a type parameter. `rc.borrow().clone()` doesn't work because somehow the type inference becomes confused. `rc.deref().clone()` works; so does `(*rc).clone()` (which (almost) is the same thing, but a bit surprising to someone who hasn't fully internalized what an lvalue expression is...) I suppose that `Rc&lt;T&gt;` could implement `ToOwned&lt;T&gt;` but it doesn't. I haven't quite figured out why `rc.borrow().clone()` doesn't work. It seems that type inference can't quite connect the dots. Edit to add: There is an implied call to `deref` behind the scenes to convert `Rc&lt;T&gt; -&gt; &amp;T`, implied by the member dot. Otherwise you might need the `&amp;*`... uh... sigil thing, or could call `deref` yourself with `use std::ops::Deref`.
Fixed in 0.1.4, using TypeId.
It really, really depends. I can't say too much more because it's a lot and I'm on mobile right now, but what I can say is that 1. The online book will still be updated regularly and 2. The print version will be refreshed periodically. A lot of the ergonomics stuff will kinda "just happen" even without writing stuff in the book; consider the match ergonomics RFC. Since it was proposed, I can't even count how many times I wrote some code, got an error, and went "oh that will Just Work someday." So I expect people to just stumble on it and not even realize.
They were not.
Thank you, this worked just as a drop-in replacement! I've never used the fn type before, but it was a pain-point of the design for sure.
They are fairly legible, in my experience. This program: extern crate typenum; extern crate nalgebra; use nalgebra::{zero, U2, U4, MatrixNM as Matrix}; fn foo() -&gt; Matrix&lt;f64, U2, U4&gt; { unimplemented!() } fn bar(input : &amp;Matrix&lt;f64, U4, U2&gt;) { unimplemented!(); } fn baz() { bar(&amp;foo()); } Produces this error messages: error[E0308]: mismatched types --&gt; src/main.rs:14:7 | 14 | bar(&amp;foo()); | ^^^^^^ expected struct `nalgebra::U4`, found struct `nalgebra::U2` | = note: expected type `&amp;nalgebra::Matrix&lt;f64, nalgebra::U4, nalgebra::U2, nalgebra::MatrixArray&lt;f64, nalgebra::U4, nalgebra::U2&gt;&gt;` found type `&amp;nalgebra::Matrix&lt;f64, nalgebra::U2, nalgebra::U4, nalgebra::MatrixArray&lt;f64, nalgebra::U2, nalgebra::U4&gt;&gt;` Sure, that isn't the _most_ legible error message one could imagine receiving in this situation (and, as /u/Ralith [notes](https://www.reddit.com/r/rust/comments/6xf92t/whats_the_state_of_rust_for_numerical_computation/dmg494j/), improvements are on the horizon), but _nalgebra_ successfully steered me away from some dumb mistakes when I used it.
We've gone after separate optimizations. `json` emphasizes deserializing `JsonValue`, such a custom tree type, and short string optimizations. serde_json on the other hand is focused on deserializing into native types. According to our benchmarks, we're about [twice as fast](https://github.com/serde-rs/json-benchmark) as `json` when we don't serialize to our Value type. I'd love to merge our projects some day, but who has times for things these days :)
ya! I came across Nix after writing this blog post, and added it to the end of the post as an edit.
`rc.clone::&lt;T&gt;()` isn't the right syntax. `(*rc).clone()` should do it, or `&lt;T as Clone&gt;::clone(&amp;rc)`, but that doesn't actually move the value out as u/jDomantas wanted (but then again they asked for `T: Clone`, so maybe there is some confusion about what moving means...). For that /u/DroidLogician has the answer.
What I am suggesting is a parallel package manager. After discovering it, I'm diving deep into Nix. I plan to package my project ([artifact](https://github.com/vitiral/artifact)) in it, as well as use it in my arch linux system for a while and write a follow up blog post. Stay tuned! I'm going to write a rust-script that can automatically generate the `*.nix` file for packaging it. I want to get a good idea of how easy it is to distribute via their binary channels before I make the suggestion, but it looks super promising!
It's pretty easy to write `unsafe transmute&lt;&amp;T, &amp;mut T&gt;` if you haven't been specifically warned. Or even if you have and are a bit of a slow learner. (I may have...) Rust makes it possible to audit use of `unsafe`, but if you let the genie out of the bottle and allow your less-technical contributors to use it, best to show them what Rust looks like when it's shooting at your feet.
I am wondering if we will be able to change some traits definitions in a backward compatible way to use this. For example, I'll be very interested by a new Index trait like this: trait Index&lt;T&gt; { type Output&lt;'a&gt;; fn index(&amp;'a self, index: T) -&gt; Self::Output&lt;'a&gt;; } because this mean we could return reference-like wrappers with the `foo[i]` syntax. This would greatly improve ergonomics in quite a few place of my code ! -- currently, the trait is defined like this: trait Index&lt;T&gt; { type Output; fn index(&amp;'a self, index: T) -&gt; &amp;'a Self::Output; } which means that we need to return a 'real' reference to the data.
Yes, for that it's smart enough. It does not run more than one `cargo test` in a moment of time.
While playing around with [vertex attributes](https://www.khronos.org/registry/OpenGL-Refpages/gl4/html/glVertexAttribPointer.xhtml) in OpenGL, I found this interesting `GL_UNSIGNED_INT_2_10_10_10_REV` format. This format is useful for passing 4 values to shader, however, 3 of them have much better precision than the last one. I suspect it might be useful for storing color with alpha, where a good alpha precision is not required. This crate has `Vector` struct that helps to read and write this representation.
You can install it on various flavors of Linux. It downloads binaries and precompiled artifacts, while cargo gives you source code and then you have to wait for it to compile.
Playing around with this more I discovered that `rc.borrow().clone()` doesn't work. Probably because type inference can't quite make the connection that `Borrow&lt;_&gt;` is `Borrow&lt;T&gt;`.
Giving it a read right now
No problem. If you wanted to take &amp;self you'd need a separate method which returned both head and tail as a reference (in this case you'd keep them as separate methods, only reason to put them together is because we need to take self)
There is no way to make this backwards compatible (except introducing indirection through a new trait).
tr1/c++11 is way older than rust. No catching up there. C++ backwards compatibility is one of its main selling points. Sure this adds to its complexity but I am working on a project now that was started in 1998. I am writing all the new code in c++11/c++14 all of which will be running on an AIX system. While the rest of the project can stay as it is. 
making it possible to distribute for multiple platforms via cargo would be excellent, especially since `cross` makes it possible to compile for gnu, musl, osx and windows in x86, ARM and other platforms *from a single platform*. `cargo publish` could include a toml file for how to build all of these, and it would automatically compile and publish for all platforms. This would be pretty awesome, and I can't imagine it would be *that* difficult to add.
I'm new to Rust. Currently I'm using the Rust plugin for Intellij, but I'm having an issue where the IDE can take 30+ seconds to show me a syntax error. The Rust plugin is the only plugin that I experience this issue with, everything else is borderline instant. Is there a better way to write/debug Rust code? Or, is there a generally accepted Rust edittor that people prefer?
Yup, and now we have n + 1 package managers to target. There will be lots of people who will not be willing to download nix just to get your program, no matter how great nix may be.
 main.cpp:17:29: warning: 's' used after it was moved [misc-use-after-move] std::cout &lt;&lt; "foo: " &lt;&lt; s &lt;&lt; "\n"; // s is used after move ^ main.cpp:16:5: note: move occurred here bar(std::move(s)); clang-tidy is your friend. 
This was a great talk. 
&gt;making it possible to distribute for multiple platforms via cargo would be excellent, especially since `cross` makes it possible to compile for gnu, musl, osx and windows in x86, ARM and other platforms *from a single platform*. I'm not sure you understand what `cross` is. [It states pretty explicitly that what you just described is not possible.](https://github.com/japaric/rust-cross/blob/master/README.md#i-want-to-build-binaries-for-linux-mac-and-windows-how-do-i-cross-compile-from-linux-to-mac)
Well, there's going to be that implementation period later this year. I'm sure GAT will be available sooner than we `.expect()`.
Absolutely. I'm love seeing crypto (and security in general) work being done in Rust, and would be thrilled to see wider adoption through for example a viable replacement for OpenSSL.
The executables in .cargo/bin are managed by rustup: https://github.com/rust-lang-nursery/rustup.rs#how-rustup-works The solution you used is probably not what you want. The "Update RLS" command of the extension just runs `rustup update`: https://github.com/rust-lang-nursery/rls-vscode/blob/master/src/rustup.ts#L26-L43 How did you install RLS? Were you using a nightly compiler (required for rls at the moment)?
I installed RLS with `rustup-init.exe`. `nightly` is the only installed toolchain and `default`, all necessary components are installed. When I switched from the unofficial Rust extension (set to RLS mode) to the new official one, it complained that RLS is not installed until I chose to install it from the popup. Also, a few days later I ran `rustup update` to get the newest nightly, and when I started VSCode minutes afterwards I was still greeted with "RLS is out of date, want to update?" and an update was performed, although I had just updated the toolchain. edit: After updating to the `2017-09-02` nightly, the executables are still only in the .toolchain folder. Are you sure rustup is supposed to copy them to .cargo?
The ci that I use on a couple of my projects (see the repo [here](https://github.com/japaric/trust)) works well for me. I've used it on a couple of my projects.
Nix's advantage is, apart from reproducibility, its ability to integrate with other language toolchains. As far as I'm aware, nobody has implemented this for Rust yet, but NixPkgs has _excellent_ Haskell support. As an example, nix-shell -p 'haskellPackages.ghcWithPackages (p: with p; [lens])' --run ghci Will drop you in `ghci` with `lens` installed - but `lens` will not (necessarily) be installed in your user environment at all! There's no list of all the supported languages, but [this](https://github.com/NixOS/nixpkgs/tree/master/pkgs/development) is pretty close. Why don't you write Rust support in NixPkgs?
Another thing on the Rust 2.0 list, then.
One thing that you should consider is that it's very unlikely that any talks on those subjects would be meaningfully more effective as a conference talk than they would be as a blog post. 
I've been using the Rust plugin for a while now and I've noticed this as well, but only recently. Perhaps it is a regression? I've been very happy with it so far otherwise.
my strong, knee-jerk reaction to this news is two-fold: - congratulations, this sounds awesome! the more of these core pieces that can be written in Rust, the better! - "elf" is a so-called "reserved" name in this context of deep/low level systems programming. Elf is unambiguously associated in the minds of everyone in this space as the name of the binary format for Linux, among other OSes. This allocator is not at all related to the binary format directly. I would much prefer a less confusing name.
How can I `inspect` all values in an iterator without `collect`ing it? For example, see this code here: get_my_iterator() .inspect(|q| debug!("{:?}", q)) .find(|q| q.is_good()) .ok_or("none found!"); If the closure in `find` returns true for the first value, only the first value is `inspect`ed and printed, but I want to `inspect` all possible values. Is this possible?
I had much the same reaction.
Do you consider rustls viable?
I've been wondering how much `unsafe` might need to be used to avoid things like timing attacks.
Nice way to pack vectors. Minor detail: the library name is 2-10-10-10, but the `new` function expects the values in 10-10-10-2. It is not important, but I was confused for a second.
I use that as well (and mentioned it in my post), but I'm talking there about `cargo publish` being extended to consume something similar to the `.travis.yml` files in those templates.
As somebody who doesn't know crytpo, why would you need to employ `unsafe` for that?
huh, look at that... I must have misunderstood on that one. I'm pretty sure `cross` can be used to compile for embedded systems -- but that is completely different, since their toolchains are purposely distributed to run on systems that aren't embedded (obviously). Thanks for correcting me!
To clarify, does this allocator require any bits from the stdlib? I ask because you mention a concurrent data structure. I'd be interested to use this in a no_std system.
This is the first program I've made in rust. I just started learning it yesterday and it's been a lot of fun.
Right now, yes, we have a dependency on std. However, we're hoping to phase that out. In particular, in order to do that, we'd need: - crossbeam's [epoch-based memory management](https://docs.rs/crossbeam/0.2.10/crossbeam/mem/epoch/index.html) would need to support no-std - the collections in libcollections would need to be parametric on allocators Long-term, our goal is to have the core code have 0 system-specific dependencies, and to have anything system-specific be parametric. This should allow us to easily compile not only for different OSs, but also for a no-OS environment. For example, I'm hoping to eventually be able to compile Redox using elfmalloc. We're much farther along with making the [slab-alloc](https://github.com/ezrosent/allocators-rs/tree/master/slab-alloc) crate no-std, so if you'd like to see what no-std would eventually look like for elfmalloc, that's a good place to look. The TL;DR is "traits all the way down."
To circumvent the compiler's optimizations possibly introducing different runtimes, critical parts are often handwritten in assembly, which needs unsafe.
As a new Rustacean, I use the IDE's complaints a lot to tell if I'm doing something wrong. It's rough when I find out that there's actually something wrong, it just took a long time to see.
Probably because in OpenGL it's named `2_10_10_10`, but the standard format for channels in OpenGL is RGBA.
which way round does msb / endian-ness work in this naming convention (and is it is it RGBA or ARGB.. [here](https://www.khronos.org/registry/OpenGL-Refpages/gl4/html/glTexImage2D.xhtml) it seems to give formats for both) the 2bits being alpha or W is certainly the best use, regardless, and I would indeed have expected alpha to be in the upper bits of a packed pixel value 
Does it provide any security features for consumers (ala https://chromium.googlesource.com/chromium/blink/+/master/Source/wtf/PartitionAlloc.h#80), or is the assumption that you'll use this exclusively with memory safe languages?
idea.. could you make a macro to roll all permutations of bit-packing i.e. 1_5_5_5, 2_10_10_10 etc (does it have name concatenation, I can't remember). Would associated constants now allow us to throw in Type::num_alpha_bits etc
No, it doesn't. We do provide a `malloc` interface, though (that's what our performance benchmarks use), so it wouldn't be out of the question for us to add features like those. It's certainly not a priority yet, though, since we're so early on.
That's good feedback. We had considered it, and maybe we'll end up changing the name at some point.
I sort of agree with the second point as my first thought was something like "what does it has to do with ELF?", however my second thought was "it's probably nothing to do with it, maybe the author likes elves...".
Ahh, that makes sense. Guess I'll go with plain old for loops, then.
Hmm, hadn't considered that. I ended up going with a different solution, but I'm still getting the hang of lifetimes, so it's good knowing this. I'm not entirely sure how that could have been restructured to avoid being self-referential, though, seeing how I need to specify the lifetimes of the references I'm keeping and the point of using iterators is to keep the evaluation lazy, so I can't really keep a full list of owned Patterns in my module.
Can it be used instead of default allocator? Nightly-only?
It's nightly-only right now (and probably will be for some time, as I don't expect the `Alloc` trait to be stabilized any time soon). The short answer is that it can't be used as a Rust allocator. The longer answer is that it can if you use the system allocator, compile elfmalloc as a C allocator (so that it implements the `malloc` API) and then use `LD_PRELOAD` to load elfmalloc. More details [in the documentation](https://docs.rs/elfmalloc/0.1.0/elfmalloc/general/index.html). However, we absolutely plan to change that. That is blocked on libcollections being upgraded so that its collections take allocator parameters, but once that happens, we should be able to make it work as normal.
Nice little project! Some comments: 1. I'm curious why you used floats for calculations? 2. I don't think you need to explicitly write `.display()` when you format something 3. You can improve the error handling like this: - Make `render_file` return `Result&lt;(), String&gt;` - Change the match statements to: `let mut file = File::open(input_path).map_err(|e| format!("Couldn't open {}: {}, ...))?;` - Add one match in main that prints the error and then exits That works similar to the match statements you have now, except it returns the error instead of panicking. You can then change the other methods to return Result as well. The second edition of the book has more on error handling: https://doc.rust-lang.org/book/second-edition/ch09-02-recoverable-errors-with-result.html Happy rusting :)
Not exactly what I'm looking for, considering I'm not actually changing the internal state of anything on iteration (just ensuring Module or any of its sub-structures can't be mutated while they're being iterated upon). Something like this seems like it would (in my case) rely on the Module owning an instance of Pattern internally and returning a reference to that, whereas I'm trying to return an owned Pattern to be used and discarded before being able to iterate again.
It's actually just a dumb acronym - Eli (@ezrosent's first name) and Liebow-Feeser (my last name).
As for #1, the intermediate results are floats and the linter seemed to indicate I should be explicit in my casts. Thanks on the tips.
interesting to see this. Question: it says it can work as a drop in replacement for ```malloc```, but is it designed first and foremost for the '[user-tracks-the-size](http://en.cppreference.com/w/cpp/memory/new/operator_delete)' approach , which I gather [Rust does support at it's lowest level](https://doc.rust-lang.org/1.6.0/alloc/heap/fn.deallocate.html) (i.e. the allocator doesn't track sizes, it relies on the user to pass them in on freeing). (in which case the C-like 'malloc/free' support would just allocate a bit extra, and put the size there) The old C malloc/free interface is actually one of the things I wish we could purge from the world. C++ new/delete have been extended to support the user-tracked-size case. I seem to remember Rust also gives a C-FFI friendly interface for user-tracked sizes aswell, I can't remember what it is though.. __rust_alloc() __rust_dealloc(ptr,size) .. something like that 
Great question! elfmalloc is designed like a normal C allocator in that respect - its layout is designed with the _pointer -&gt; (size, alignment)_ lookup in mind, and currently, we actually implement the C API directly (rather than in terms of the Rust `Alloc` API). However, we also have `malloc-bind`, which is a crate that takes an instance of the Rust `Alloc` API and implements the C `malloc` API in terms of it, and we're hoping to soon switch elfmalloc to using `malloc-bind` instead of implementing the C API itself. `malloc-bind` requires a `LayoutFinder`, which is a type that can map from pointers to a `Layout` (basically, a size/alignment pair). It uses the `LayoutFinder` to find a `Layout` to pass to the Rust API. Edit: If you're interested in contributing, we have an outstanding issue for that conversion ;) https://github.com/ezrosent/allocators-rs/issues/12
ok I was just reading [https://github.com/ezrosent/allocators-rs/blob/master/malloc-bind/src/lib.rs#L114] , I got the impression the 'Layout' stuff might do that. I'm ambiguous on my commitment to Rust(vs c++), but an ecosystem based on passing sizes to allocations would be a big draw. I was encouraged to see Rust has considered this. maybe I'll take a look.. tangentially there's this interesting talk [https://www.youtube.com/watch?v=LIb3L4vKZ7U], the interface he suggests is 'struct Block{void*,size} , fn allocate(s:size_t)-&gt; Block, free(b:*Block)', but thats a minor detail. I prefer the functions I saw in rust's lowest level. He shows some interesting ideas on composing allocators I think I'd also be interested in an interface with some hints bits ('thread local/inter-thread , short or long lifetime, likely to be growable or not ..', prefer a [freelist](https://en.wikipedia.org/wiki/Free_list)/dont use a freelist) but it's more questionable that something like that could be standardised. I imagine something where the flags could be ignored, and you could bypass the flag passing to use a default Contrary to what alexandrescu says, I *do* personally like the fact that C++ considers the type in allocators, e.g. the ability to separate out allocations per system. passing some 'hint bits' would be an attempt to get some control in the middle ground there.
Ah yes, so I should've also mentioned that there's a separate concern on allocation. Functions that _take_ existing pointers need to do the _pointer -&gt; (size, alignment)_ mapping, but functions that _produce_ pointers also need to infer alignment (since, in most of the C allocation API, only size is given). The code you linked to is `malloc`, so we have the latter concern. To see `LayoutFinder` in use, check out [free](https://github.com/ezrosent/allocators-rs/blob/master/malloc-bind/src/lib.rs#L137). Edit: Re: the talk you linked to: I've seen some of Andrei Alexandrescu's allocator work, and it's really cool. I haven't seen that particular talk tho. @ezrosent might have - I'll see if he has thoughts on any of this.
I was aware of that but should have mentioned this. (I was on mobile and short on time yesterday) What I need is a Duration that is `Month` and `Year` aware, which have the pesky property of having varying lengths, and thus currently not being supported in `chrono`.
How's this compare to Redox's [ralloc](https://github.com/redox-os/ralloc)?
Edit: @ezrosent has corrected me - apparently he tried about a month ago, and at that time, ralloc didn't compile. We haven't compared ourselves to ralloc yet, but that's probably something we should do! Just reading over their docs I already see some good ideas that we should probably adopt (e.g., emitting symbols so that we play nicely with Valgrind).
You may be able to make your iterator `peekable`, but that comes at a cost in memory. In the general case, iterators don't need to be finite, so we cannot inspect all elements anyway.
Cool. Pinging /u/ticki_ for any insight he might have here.
sometimes I (admittedly sloppily) swap the words generic/template; I know the systems are different, but there's a big overlap of use-cases. just like the difference between 'methods' and 'member-functions' .. maybe the world needs a single word to correctly describe the subset of overlap between the two..
I'd expect no problems across static crate boundaries but always have to be a little careful with shared libraries to make sure there's a shared allocator. So everything has to be dynamically linked. It technically has to be unsafe because of the pointer dereference but I would also be surprised if it broke badly with same compiler versions. 
r.e. benchmarking, is there any hazard of distortion r.e. interface, e.g. what if you're benchmarking the 'malloc/free' case, but the long term plan would be the rustic 'user-passes size' case. The latter *should* be more efficient, but what if an allocator designed for that looks inferior (to C allocators) when emulating the C use case. Hopefully all the Rust APIs standard library would go through the rust interface, so if you're benchmarking *the performance of rust* (rather than a raw allocator test) then it should be ok ,I guess..
I always wondered if one can inspect the stack to get the location of caller and use that as the 'hint bits', potentially even inferring arena sizes, etc.
Not a bad acronym then! It does give the impression that this would be a linux-only project though - which might not be what you want :p.
I had high expectations about this program after this one: https://codisec.com/wp-content/uploads/2016/12/binary_visualisation.png from here: https://codisec.com/veles/ Are you going to strive for level of veles? By the way this: let mut file = match File::open(input_path) { Ok(file) =&gt; file, Err(why) =&gt; panic!( "Couldn't open {}: {}", input_path.display(), why.description() ), }; you can write little simplier: let mut file = File::open(input_path).unwrap_or_else(|why| { panic!( "Couldn't open {}: {}", input_path.display(), why.description() ) });
interesting, i guess the idea would be 'locality in the call graph correlates with expected locality/temporal behaviour of data used'.. maybe something like that would be a default that is better than nothing, if no further information was given.
So two answers to that. First of all, we'll be getting strictly more information from the Rust API than the C API, so there's no reason to believe that the Rust API version would be slower than the current C API version. Second, if we switch to the Rust API and then implement the C API in terms of the Rust API and the `LayoutFinder` thing I mentioned above, there could be concern that that would add bloat. We'll obviously have to benchmark that when the time comes, but I'm hopeful that LLVM will optimize out any added bloat that's written in the code (e.g., inlining functions and such). Most of the added cost would be in the form that should be trivially optimizable.
sad that i can't really [build](https://play.rust-lang.org/?gist=40bf2dd423f1852a4a9510dfe61724bf&amp;version=nightly) functions to create and append to that List. I guess impl trait uses monomorphisation and we can't have branches in impl trait functions returning different types that implement that trait :( (string_append is wrong either way but i stopped there realizing its a dead end)
It's almost like it's a hard problem and correctness is more important than speed
Where do associated constants live? Will they appear in the struct repr, or are they type level only? struct Foo { len: u16, const opcode: u16 = 0xABCD, time: u32, } When this is untagged, will it be 48 bits wide or 64? What happens when it's `#[repr(C)]`?
I forgot to say, congratulations on the release, and great job on the fast performance!
At the moment ralloc doesn't work with the new allocator API. If I can understand the code base enough I might send in a PR to fix that.
I assume you mean the standard library's channels, [`mpsc`](https://doc.rust-lang.org/std/sync/mpsc/index.html)? I personally am not that familiar with it, but I've read documentation and a bit of the source code. `mpsc` channels have 3 modes: "one shot", "stream" and "shared" - the one shot mode is optimized for sending a single message, stream is optimized for single sender, and shared works with multiple senders. I'm not entirely sure when it switches from one shot -&gt; stream mode, but I know it'll only switch to 'shared' mode when the sender is cloned. side note: almost all of my knowledge here is from looking over the `mpsc` source, and the comments within it. According to the documentation in the source code, locks are avoided by using an atomic counter. Only when there's contention will it fall back onto a Mutex for synchronization. In the best case, I guess it never needs to? I didn't find the source code to be _too_ unreadable, although it is a bit large. If you're interested, [this](https://doc.rust-lang.org/src/std/sync/mpsc/mod.rs.html#128-276) would a good place in the module to start at.
Thanks!
&gt; /pull/69/ nice
[removed]
_ɿ_ɘƨɘɘᖷ-_w_odɘi⅃ _i_lƎ rwialloc?
in that example , I'm guessing 'some_address' would be returning a raw pointer, i.e. the direct equivalent of rust unsafe code; the use of raw-pointers would be controlled in modern C++ sourcebases (I realise legacy code could do anything). I'm not claiming that C++ is safe, but the modern style is a lot better than it used to be (and with emplace back and lambdas it's a lot easier to eliminate the use-cases of raw pointers.. e.g. I used to use an vector interface that effectively let you 'allocate at it's back' by returning a raw ptr where you could construct inplace; no need for that today) It would be a more complex, but if you can 'warn about unsafe' in rust (the implication is that a project can raise alarm bells when source files with unsafe blocks change.. easy to add to some script on checkin or whatever) .. you could certainly do that in a C++ project - i.e. you expect most day to day work wont use raw pointers, and any raw pointer use is constrained within custom collection-classes/custom smart pointers. it would take a clang-based tool to do it, but the cost is divided by the entire c++ community. At this point I would suggest adding that as a warning to the compiler ("warning, raw pointer used outside of class encapsulation.."), when using anything at or over std=c++11
deleted ^^^^^^^^^^^^^^^^0.5726 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/67761)
deleted ^^^^^^^^^^^^^^^^0.3560 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/15054)
Anyone have a full list?
_El_i _Li_ebow Elli Alloc. Sounds cute :)
deleted ^^^^^^^^^^^^^^^^0.6950 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/82339)
what's the point of this? why do you want to allocate memory yourself? purely for unsafe?
I recommend reading the documentation for the types in the std lib that are used to implement concurrency and message passing between threads. Start [here](https://doc.rust-lang.org/std/sync/), also get familiar with the concepts of send/sync (marker traits) to know when you should/shouldn't implement them directly. This is not a tutorial but should give you an idea on the tools you have to implement concurrency in a safe way. The concurrency story in Rust is not very different in essence to that of Java (or most languages), and while it won't translate 1:1 you will find similar types for managing concurrency and the same concepts apply regarding opportunity costs (locks and barriers, resource acquisition and concurrent reading, message passing between threads etc.). As long as you don't steep into "unsafe" territory the borrow checker has your back so you don't have to fear about experimentation, but the fundamental concepts are the same. Then you can explore libraries that can help you on implementing concurrency and have their own documentation, Rayon is a popular one. One important thing to keep in mind with Rust concurrency is that you can statically guarantee unique writing access and readers never collide (avoid data races) so you can design your concurrent structures around that fact to leverage concurrency in a way in which other languages is harder to pull out, aside from that the concepts are the same to other languages (which support multithreading, so not Python).
Thanks for your suggestion, I am going to check standard library
The benchmarks look really impressive, good work!
My pleasure :)
After being recently burnt by regrep benchmark (comparing regrep on multilpe cores to single threaded grep) I am somewhat sceptical of this. When I see benchmarks from 'neutral' 3rd parties using this in a large codebase is when I'll get excited. The nasty part with benchmarking in a void is that it's really hard to mimic a real scenario (when the caches are being shared by multiple processes and the processes themselves do a lot of internal context switching)
Not yet, I do not think that it is well tested enough, and it is too early to drop support for non-forward secure connections. Too many servers still do not support Diffie-Hellmann.
[You can](https://play.rust-lang.org/?gist=8e14bbd5e5b36f7380cbd930f0391085&amp;version=stable)
You mean ripgrep?
[You can still get things like deadlocks though fyi.](https://doc.rust-lang.org/nomicon/races.html) Rust can only do so much with the type system.
Listened to the episode and it went on a short tangent about streams in haskell. Laziness allows you to stream lists naively in constant space but that still involves constantly allocating and freeing list constructors which would be orders of magnitude slower than a loop so virtually nobody relies on this. [If anyone is interested in the actual implementation, here is a somewhat accessible overview of the haskell equivalents of iterator.](https://www.google.de/url?sa=t&amp;source=web&amp;rct=j&amp;url=http://fun.cs.tufts.edu/stream-fusion.pdf&amp;ved=0ahUKEwibiJ3RiInWAhWCJlAKHZdEBNsQFgg1MAM&amp;usg=AFQjCNHUpaH5I9w6kbPAtO9KQMVodj9E1w) TL:DR: The end result is kind of like zero cost futures in rust, building a state machine and only boxing at the highest level. Each list function actually is defined as something like `map f = unstream . mapS f . stream` and neighboring `stream . unstream` pairs are removed by a library defined compiler rule. Then all the stream functions are (hopefully) inlined and constructor specialization and commuting conversions optimize them into a jumps. The paper isn't quite up to date anymore, the Skip constructor could be removed nowadays thanks to join points and the Vector library actually uses generallized stream fusion which can pick between different data representations, e.g. to memcopy a bunch of iterator items at once instead of one by one if applicable. Still gives a good overview, though.
Now that I think about this, I'm sure it is unsafe. Look at what a trait object is: - pointer to data - pointer to array of function pointers [std::raw::TraitObject](doc.rust-lang.org/std/raw/struct.TraitObject.html) What defines these facts? - the length of the vtable - the concrete type of each method - the offset of a particular method in the table, such as `Plugin::initialize` The first two you control but the third is a problem Trying to express this in Rust, I'd say that `plugin.initialize()` compiles to transmute::&lt;*mut (), fn $SIGNATURE&gt;(transmute&lt;&amp;Plugin, *mut ()&gt;(plugin, TraitObject).vtable.offset($OFFSET))() As programmer you control the type signature of the method. But the complier may use *any algorithm* to assign $OFFSET into the vtable. If the plugin and host are built with different compiler versions, they might not agree. So your unsafe call to `Plugin::init` may turn into a call to `Plugin::event` with the wrong function signature, which corrupts the stack, and, well *boom*. There is no useful way to construct primitive trait objects in unsafe Rust and there won't be until the ABI is defined. So here's what you can do instead: delegate pattern. Define a `struct DynamicPluginSocket`. It has fields like `v_init: fn extern "C" () -&gt; c_raw::InitErr` which define the signature of each function. (v for virtual) Then you `impl Plugin for DynamicPluginSocket` #[inline(always)] fn main(&amp;self) -&gt; Result&lt;()&gt; { unsafe { (self.v_init)().into() }} On the plugin side you define unsafe fn extern "C" V_init() -&gt; c_raw::InitErr { // catch_unwind } 
yeah sure! i think i wanted a usecase for impl trait so hard .. i am wondering if i can build a function creating such a list based on an actual `String` or something else in runtime. But i think this is where this `compile time linked list` needs to end, right? You can't have user-input for creating such a list, right?
Memory allocation is a dirty job, but *somebody's* gotta do it.
Check this out https://rust-lang-nursery.github.io/rust-cookbook/
True, but there's no way of knowing that without looking at the definition of `bar`. 
impl Trait doesn't enable anything that wasn't possible before (other than returning closures). You still have to return a single type from your function, or box it. 
I'm somewhat-new to Rust. Could you give me a link / description of what you mean?
Thanks!
Yeah, so we've tried to be open about the limitations of these performance numbers (see, e.g., paragraph two of the [performance doc](https://github.com/ezrosent/allocators-rs/blob/master/info/elfmalloc-performance.md)), but there are definitely limitations. That said, we're actively looking for allocation-heavy Rust programs to provide a real-world benchmark for both elfmalloc and slab-alloc. If you've got ideas, let us know!
what do you mean by &gt; burnt by regrep benchmark Is there some link or article that has found different results? Or is this in terms of your personal findings.
&gt; I watched one about `asm!` the other day from the cologne group that was more in the direction of what I am expecting Do you have the link of the video?
&gt; You can convert a pointer to an integer in both Rust and C++ just fine. sure, but you have to do that explicitely with a cast - easy for some clang-based coding-style enforcer tool to exclude; *there's no need to do that at all in application code in modern C++*. You needed it in plain C, to cast the result of ```malloc```; but even old c++ fixed that with a typed ```operator new```. There's a strong incentive to use the right types: the language via overloading (and IDE, via dot-autocomplete) leverages types to find functions for you. Your example made it look automatic, under a plain ```*```. &gt; they can't guarantee memory safety even for trivial data-structures like std::array. But it's trivial to add bounds checks to C++. it's one of the simplest pieces of debug code to put in. I have far more to think about than that. &gt; if you are writing a data-structure, turn all the checks off. I don't get what point you're trying to make here; So if you want bounds checks, in C++, you easily have the control to do it. Similarly, *implementing* datastructures like 'small-vector' *in rust* absolutely requires ```unsafe``` blocks. The compiler *doesn't* verify whats going on for you, it just lets you mark the dangerous parts. We can say 'any use of a raw pointer' is dangerous. So, source files that contain them are your 'unsafe blocks'. It takes a complex tool to do, but the cost of this is amortised over billions of LOC. user-side/application-code (the equivalent of rust safe) doesn't need raw pointers. &gt; retrofitting even basic memory safety into C++ is impossible. crazy conclusion. It's a straw man argument. Modern C++ has the tools for memory safety. Old C++ lacked various tools so you needed raw pointer workarounds more frequently. Rust and modern C++ are really not that different. They can represent the same concepts. There's a tradeoff: i.e. modern C++ can be done as a gradual migration for legacy code; the world has a lot of software written prior to 2015 which is still in use , being gradually evolved, whilst Rust requires the risk of a rewrite (which can be the death of an organisation). To illustrate the problem , **consider what it would take for rust to be *truly* self hosting, i.e. re-writing LLVM. As is stands today, rust *itself* still depends on C++.** Conversely , imagine adding this to any popular C++ compiler.. #pragma(unsafe) //quiets warnings given by using raw pointers in the subsequent block, etc Compare the effort of that, to the effort of *rewriting LLVM* There IS consensus about the elimination of raw pointers in 'good code' , so something like this is within the realms of possibility.
The version of ptmalloc used in the benchmarks doesn't seems to be the newer one with a per-thread cache from [glibc 2.26](https://sourceware.org/ml/libc-alpha/2017-08/msg00010.html). It would be interesting to see if replacing the system-default malloc is still worthwhile. 
I propose [The Eye of Sauron](https://youtu.be/tH_pdYyqK4o?t=1590) be renamed _The Eye of Turon_, in honor of the man who [stabilized the `core::ops` traits](https://github.com/rust-lang/rust/commit/e921afddd8c12d676205bb951deff1aa5761bedf#diff-0283b5f16e1f7cf368f3f56668838f4b) leading to the pattern.
&gt; my project depends on a lot of code that should be synchronous in nature (I think -- things HAVE to finish before something else can begin). You can have a future run after another one completes.
Out of curiosity, why must it be a rust program ? Couldn't this be used with a C/C++ program by linking against it (e.g similar to jmalloc) ? Or is a non-zero overhead compatibility layer needed ? If the former is true I'd try any browser or even better a popular database that comes with it's own benchmarks, hell I'd try it on a piece of software on which I work (10,000+ alloc per second, mostly small~ish objects and we have loads of perf monitoring going on, I'd be glad to post the benchmarks but the code is closed source, so not sure how valid they'd be). If the latter is true why not try it on firefoxe's rust components ? After all playing nicely with other alloc is also a valid usecase (right ?) so it would be an interesting benchmark.
I think for a new library it doesn't make sense to support old protocols.
AFAIK forward secrecy will be required in TLS 1.3, which is still just a draft. There are plenty of TLS 1.2 (the current version) servers out there which do not support forward secrecy. This prevents rustls from being a viable replacement for OpenSSL.
It'd definitely be worth it to try with the latest ptmalloc2 - we used 2.19 IIRC - but I doubt that the newer version matches jemalloc in performance, which would be what would make it a really interesting benchmark to compare against. Of course, we haven't benchmarked it, and I'd love to be proven wrong on that.
I haven't checked, but generally, consts are inline for each time they're used, so I assume it's the same with associated constants.
It doesn't actually need to be a Rust program, that's true. Any program that can have an allocator `LD_PRELOAD`'d would do just fine. I think a browser or a database would be a good idea (although I suspect that performance-critical software like that might statically link their own allocators to guarantee better performance - just a hunch). We'd be happy to see benchmarks from your software! It might not be terribly informative if it's closed source, but it'd be interesting nonetheless - especially if that software is allocation-bound.
You're looking for /r/playrust 
In this concrete case the iterator implements `ExactSizeIterator`, so it's definitely finite. How would the operator chain look like to do that? I just want an expression that resolves to a single value but iterates through all existing ones. `peekable` only offers `.peek()` for a single value, I don't see how I'd be able to achieve it with that - I've also tried to chain `.collect::&lt;Vec&lt;_&gt;&gt;().iter()` in the middle of the expression but I run into lifetime errors doing so.
/r/playrust is what you're looking for. Here is Rust the programming language.
It's mostly I/O bound actually, but there are allocation related bottlenecks at times which have become more apparent. Once I'm back at the office I will try running a test instance with this, I'm quite curios how it would perform. Also, would dynamic linking hurt performance beyond the initial few seconds ? Like, would the .so take up more space in the code cache than if it was statically linked ?
Ohhh okay thank you guys I posted over there. Haha 
My completely un-tested hypothesis is that dynamic linking will cause overhead in the form of being unable to optimize. Namely, static linking allows for function inlining and other optimizations that are unavailable with dynamic linking. As I said, though, it's just a hunch.
You could try TypeScript.
http://harmful.cat-v.org/software/dynamic-linking
Ok, just to clear the air, I never said dynamic linking is good and I never claimed (even in the case of something as widely used as an allocator) that it improves performance due to lower code cache footprint. I just asked if on a modern linux system (kernel v4.+) it is harmful to performance in any way. The link you gave are quotes (Some of them outdate with modern computers, see the one talking about increasing RAM size) about people that hate on dynamic linking for making development and portability harder with little benefit. Which, again, I agree with (in most cases at least), but it's irrelevant to the discussion.
Make sure you're not on a network that might be blocking certain ports required for steam (you shouldn't need to forward anything but it's possible they might be getting fully blocked), there's [a nice list here](https://support.steampowered.com/kb_article.php?ref=8571-GLVN-8711), you shouldn't need them all but at least the "Steam Client" ones Also make sure anything like windows firewall or any antivirus isn't blocking Rust or Steam (temporarily disabling them is a good way to find out in a pinch), and of course [verify the game files](https://i.imgur.com/NWsZyNt.png) &amp; try restarting your PC if you haven't already But, for the future, the sub you're looking for is /r/playrust - good luck :)
I agree, but I feel that in a nextgen TLS library I'd rather not have adhoc protocols like TLS pre1.3. From a cryptographic point view, these protocols have basically been designed without a security proof in mind, and as a result have ended being patched many times over. I'm hoping that within 4-5 years we have deprecated non TLS1.3 servers and clients. But yeah, in the meanwhile it does make sense to support the old protocols. I guess I was just being an idealist.
You can save the iterator returned by `inspect`, then use `find` to check for a value, and explicitly iterate to consume the rest. [playground example](https://play.rust-lang.org/?gist=2f10ef5b13e06caec01580e6a50bf8d8&amp;version=stable)
I could, but I really want to move away from JavaScript. It's served me well but I need proper, compiled OOP now.
Maybe I should have mentioned I know next to nothing about computers... so what the hell is a port? 😅
If there's someone running your network (like someone in your family or something) I'd talk to them and ask if they're blocking any games or anything like that on the network, though it's pretty likely in my experience to be something like an antivirus or windows firewall on your PC that's blocking Rust or steam or something I'd make a post over on /r/playrust (that's the subreddit for the game, this subreddit is for a similarly named but unrelated programming language), /r/Steam or maybe /r/techsupport and ask for some more specific help there, those places can probably help much better than I can
It's sad, that many projects from ticki don't compile. I criticized this in an issue, but he keeps pushing non-compalible code... To be honest: I have lost trust.
[removed]
A memory allocator is used whether you use it explicitly or not
What's the state of play with LLVM interface these days? https://github.com/TomBebbington/llvm-rs is the most recent thing I know of, but it looks like it may have a few safety problems. Of course if I start NIHing up my own thing on top of `llvm-sys` that will come with even more safety worries. ;-)
[removed]
Judging by the epochs RFC, this sort of "2.0 wishlist" of breaking changes is never going to happen. Even across epochs, changes will have to be small and avoid introducing too much churn.
Hi, I'm trying to parse plist files and I was hoping to understand how this works. I'm using the plist crate but can't wrap my head around how to use it properly. **Example plist file**: &lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;!DOCTYPE plist SYSTEM "file://localhost/System/Library/DTDs/PropertyList.dtd"&gt; &lt;plist version="1.0"&gt; &lt;dict&gt; &lt;key&gt;Author&lt;/key&gt; &lt;string&gt;William Shakespeare&lt;/string&gt; &lt;key&gt;Lines&lt;/key&gt; &lt;array&gt; &lt;string&gt;It is a tale told by an idiot,&lt;/string&gt; &lt;string&gt;Full of sound and fury, signifying nothing.&lt;/string&gt; &lt;/array&gt; &lt;key&gt;Birthdate&lt;/key&gt; &lt;integer&gt;1564&lt;/integer&gt; &lt;/dict&gt; &lt;/plist&gt; **Code snippet** extern crate plist; use plist::Plist; ... let parsed = Plist::read(file); println!("{:#?}", parsed); **Output** Ok( Dictionary( { "Author": String( "William Shakespeare" ), "Birthdate": Integer( 1564 ), "Lines": Array( [ String( "It is a tale told by an idiot," ), String( "Full of sound and fury, signifying nothing." ) ] ) } ) ) My **question** is: How do I cleanly access the values contained within the result? For example, in var "parsed" in the code snippet above, if I wanted to access both the Strings within the "Lines" array, would I do something like this: println!("{:#?}", parsed.unwrap().as_dictionary().unwrap().get("Lines").unwrap().as_array().unwrap().get(0).unwrap()); **Output** String( "It is a tale told by an idiot," ) Apart from the ugliness of unwrap, this doesn't seem like the right way to go about pulling out individual values I need. The library documentation is here: https://docs.rs/plist/0.2.3/plist/. It shows two examples, neither of which seem to be helpful to my use case. - One using a struct to deserialize parsed - And the other using match. In either case, that doesn't to be a good way to parse if I only need a few things out of the whole file. (Or is it?) Any comments appreciated!
Is this on master or other branches? If in master, do they not compile b/c of environment configuration or code issues?
There is some good discussion of Rust's channel design in [this blog post](https://stjepang.github.io/2017/08/13/designing-a-channel.html) 
This is big news actually. Especially the: &gt; The project is under review for inclusion in KDE. If that comes true, that means (1) it will be maintained; and (2) KDE'ers will be heavily tempted to use Rust (over C++ and some Python that is currently in fashion). Qt was a joy to work with for me, and works pretty much everywhere. Combined with Rust, good combo. I wonder if some security/performance critical bit of KDE may benefit from this in the longer run.
oh? then for what would I start to use elfmalloc explicitly? I still don't know
Hahah yeah I noticed. Almost as many upvotes as the post itself. I guess we'll have to rename. Any suggestions, folks? So far: - /u/Spaceshitter: Elli Alloc - /u/dotzak: rwialloc
Would I, then, need to have my whole server code run inside a future? Because I need some setup stuff done, then my Rocket server launches. That was the problem I had with JS promises, it seemed a lot like .then() nesting overload.. but I might misunderstand the way it's supposed to be done.
At least PostgreSQL uses its own allocator (which runs on top of the system malloc) to speed up allocating and freeing small short-lived data and to avoid leaking memory. Replacing malloc there wont matter much since PostgreSQL does not have a high malloc/free workload.
Today, futures are unergonomic like that, yes. But an await syntax is being introduced to solve this (see for example [here](https://www.reddit.com/r/rust/comments/6wxuo0/experiment_with_async_await_in_shio_formerly_salt/) and [here](https://www.reddit.com/r/rust/comments/6wvozj/help_test_asyncawaitgeneratorscoroutines/); note it just landed on nightly!) It will work [like Javascript's await](https://ponyfoo.com/articles/understanding-javascript-async-await).
Thanks for the links!
What languages/libraries would you normally look at for this sort of problem?
&gt; The project is under review for inclusion in KDE. Woah this is big
Another suggestion: **ezjoalloc**, using the first two letters of your usernames
I probably would've used: Python's || Rust's ---|----|--- [curses](https://docs.python.org/2/howto/curses.html) |instead of| [termion](https://github.com/ticki/termion) [PIL](https://github.com/python-pillow/Pillow) |instead of| [image](https://github.com/PistonDevelopers/image) [click](https://github.com/pallets/click) |instead of| [structopt](https://github.com/TeXitoi/structopt) [colorlog](https://github.com/borntyping/python-colorlog) |instead of| [loggerv](https://github.com/clux/loggerv) I don't know if this is a fair 1-1 comparison, but these are most certainly the libs I would've chosen if I had done this in python. Maybe I'll re-implement it in python so I can compare execution speed and SLOC for the heck of it.
This is one of the two biggest features that I'm excited to eventually get, along with `const fn`.
orcmalloc
I would hope an allocator built from the ground up for rust's interface (user-tracks size/align and passes it into 'free') versus C's interface (size must be tracked inside the allocator, even through clients like Vec&lt;T&gt;/std::vector&lt;T&gt; can generate the size themselves from type information) could be superior 
You'd actually be surprised - the mechanisms that most modern allocators use for inferring size information are pretty fast these days. It's not no overhead, but it's pretty close.
&gt; It's not no overhead, but it's pretty close. nothing beats actual zero overhead. whatever the profilers says today, omitting work entirely is an opportunity for further streamlining.. the idea of size being tracked by the system probably looked better back in the days before generic/templated collection classes . it might have been more interesting if the official interface included the ability to recover that size information aswell .. but tying it to types at the user side always worked well IMO.
I modified the field hl_syntax in EditorConfig to the Box type: pub hl_syntax: Option&lt;Box&lt;HighlightSyntax&gt;&gt;, Now I want to call a function defined in another module that will return a reference to the HighlightSyntax structure or None (based on some condition). I am not all clear on how to use "boxed" type with functions. I need help on: o Defining the function signature. The function should return a reference to the HighlightSyntax structure (Box?) o The caller then should use the return value to set the hl_syntax field in the ed_config structure. Could you please guide me on how to go about it?. Thank you. 
How can I express to the core dev team that a crate (such as [text_io](https://crates.io/crates/text_io)) should be adopted in the standard library?
Ah, that is true, or at least sounds plausible enough. Currently we do compile with jmalloc rather than linking it dynamically, so any gain from thi allocator may be lost due to that difference. However it's still a test I'd like to try, after all I'll take a drop in speed any day if I get more consistent resource usage and my biggest fear with allocations is spikes, not overall performance.
...or **jezoalloc**
The logo is perfect. Is this a separate project from [Rust-Qt](https://github.com/rust-qt)?
Yes, it's separate and a different approach. Rust-Qt is Rust bindings for Qt. Rust-Qt lets you call Qt code from a program Rust. Rust Qt Binding Generator (RQBG) lets you write the building blocks of Qt programs (QObject and QAbstractItemModel) in Rust. The UI is then still C++ or QML. RQBG let's you add Rust to existing KDE and Qt projects.. Also, it's just a generator, no library, so you could generate binding code once and work from there and only depend on just Qt and Rust. In the Qt code, you do not even notice that the code backing the QObjects is written in Rust. You could replace their implementation piecemeal. 
Yeah, I agree. I would be surprised if it weren't _somewhat_ faster - I'd just also be unsurprised if it weren't _a lot_ faster.
Things these coroutines can do: * Wait a single frame * Wait for another coroutine to finish * Wait for arbitrary logic, by yielding a boxed trait object * Start another coroutine from inside a coroutine Things I started that made me realize they were way out of scope for a weekend project: * Wait for a specified number of seconds (how do you get access to the number of elapsed seconds since game start/level load/etc? RefCell&lt;f32&gt; inside a lazy static?) I feel like I've only done the easy part. Unity coroutines need the ability to access and modify the game's state in a convenient way in order to be useful, as immediately demonstrated by my difficulty in implementing WaitForSeconds. In my quick research I wasn't able to find any established game state management system in rust. Anything I tried to make here would end up being a giant unreadable pile of RefCells and lazy statics. I'd love to hear people's thoughts on how to make these more useful -- especially insight on state management in Piston.
When I started getting to know Rust, coming from C++, I felt enums were a minor curiosity. Now I feel they're the most important thing.
deleted ^^^^^^^^^^^^^^^^0.1571 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/66894)
&gt; RQBG let's you add Rust to existing KDE and Qt projects.. Also, it's just a generator, no library, so you could generate binding code once and work from there and only depend on just Qt and Rust. &gt; &gt; In the Qt code, you do not even notice that the code backing the QObjects is written in Rust. You could replace their implementation piecemeal. Wow, that is COOL! This approach could really help boost Rust adoption.
Interesting! But if the exe and the .so are built with the exact same compiler, with exact same trait definitions in common, then it follows that the vtable will be organized in the same way. Otherwise, _regular_ dynamic linking would not work. What one cannot do is assume that a Rust type like `Box&lt;Trait&gt;` can be returned successfully, but a `*mut Trait` _can_ be successfully used - and in fact can be immediately put back into a `Box&lt;Trait&gt;` when received. (This can only drop successfully if we make sure that the allocators used are the same, hence the need for dynamic linking to the runtime) 
`thread_local!` is better than a static (which would have to be `AtomicUsize` on stable), and when you have a cheap-to-copy type, you should always use `Cell` instead of `RefCell`.
Cool! I was wondering about something like NCrunch for Rust :-)
&gt; double frees, RAII prevents that. granted double moves might be a hazard, but a static analyser or debug build could catch those. &gt; uninitialized memory, in one project we ensured the defaults for the types we used everywhere would always clear themselves. Easy to do with constructors. (actually it turned out to be a performance hazard so we disabled it, but with emplace back etc ethere's now more ways of doing this sort of thing cleanly.. always setting thins up with the right constructors, and if performance was secondary to safety, we could have kept it) &gt; Show me an STL implementation where the debug code to detect iterator invalidation on std::vector most projects I've worked on used a custom vector implementation. it's not that hard to do for the use cases we needed. Again you could swap something in that doesn't have all the specialisations for optimisations, but just works (using the same interface), and has the checks. **you're straw-manning all over the place.** &gt; You can trivially write a small vector implementation in Rust without unsafe using a pattern similar to: enum { SmallN([T; N]), Large(Vec&lt;T&gt;) } ... missing the opportunity to use a more efficient encoding of the small vector ('use the top bit of size', 'if size&lt;smallvecsize' or whatever), as you can do in C++. There's many ways to do it. Making use of every last bit will extend the range of use cases. (note that **every project I've worked on, trimming every last byte was critical** .. even for parts that weren't space critical, trimming bytes helped with cache-coherency. **This is where the effort went**. It wasn't enough to get code that 'just works', not by a long shot.) Rust can match all the options you have in C++ for this.. so long as you drop back to unsafe code. &gt; "I also partially develop C++ static analyzers (they interface with the STL) and I don't know of any that lets you write neither std::array nor std::vector without turning almost all (or all) of the memory safety checks off." I still don't see what you're saying here. if you want the checks, you can have the checks. you don't have to use stl, you can drop in your own types which use the same interface. You could even fork STL itself. The analyser could be modified to look for different names ('std::vector or something else..'). &gt;&gt; "You say that it is possible to retrofit memory safety into C++," Memory safety is just the prohibition of various patterns, detected at compile time. Now that is not built in to C++, but C++ has the tools to represent a safe program. (the only thing C++ doesn't have is lifetime annotations, but you could make a naming convention for a reference wrapped in a smart pointer to do that, which your analyser could read, and I even suspect you could infer that 'forward' for compile-time polymorphism. there might be a problem with vtable based stuff, but you could just prohibit non-trivial use of references for that. Rust did discover that most of the annotations can be eliminated.) As such , it is logically inferable that C++ *can* be made safe. you've given me a load of straw mans above. I didn't claim it was easy, but if anything the existence of rust proves that you *can* make something to detect 'use of moved values', etc etc. &gt; "So I don't know where you are getting your misinformation," working on projects that shipped. I've seen how we can drop types in to fix all sorts of problems (again forget simple memory problems, more effort went into eliminating QNANs). There was a cause to drop in a wrapper for bools. (anything involving maths &amp; conditionals had cause to think twice about how to do it) Memory safety is nothing compared to interfacing with hardware (the nastiest memory bug I ever saw was to do with interaction between a streaming system and a bug in the OS on a console , which would have been beyond the realm of the borrow checker.. i.e. something to do with the integrity of the page table. DMA was in progress evidently to physical memory, and instigating other safe-looking memory operations shifted the page table.. hard for us to track down, it was an error in the communication between different parts of the OS evidently.. assumptions between the people working on the memory system and the people working on the graphics API. CPU, GPU, Drive DMA all involved in the same region) &gt; "I write all my side projects in Rust, and honestly, " &gt;"C++ is give the illusion of memory safety for C++ developers that never need to write any data-structure" Sounds to me like you might be fed up with your day job and are blaming C++ for the problems, which *wont* actually go away in Rust. The world will suffer from the effort to do all the rewrites. People rely on these C++ programs, all over the place. The path from C to C++ made the right trade offs at the right times to get working, efficient programs, in the scenarios that people needed. Efficiency remains important because of battery life and data-centre electricity bills. I've been there (r.e. being fed up), but my own frustration with C++ is very different (again I've documented it.. the stylistic/modularity problems to do with the way header files and classes interact). straightforward memory bugs were nothing really. My main draw to rust was actually that traits get closer to allowing 'extension methods' (and again I have frustrations there, it's not quite as open as I'd like). C++ with UFCS (as presented by Sutter) would have been my ideal scenario. I got my interest in functional programming from the patterns we needed in order to tame the xbox360 and ps3 (ILP guided manually, due to the use of in-order processors). I launched into Rust with great enthusiasm but was eventually disappointed with it for reasons I've explained at great length on this forum. &gt; Have you actually used Rust to write anything non-trivial? I did a 3d quake level viewer , had an abstraction layer to run it on android, and I wrote this https://github.com/dobkeratops/rustfind, something to generate linked HTML view of the source e.g.http://dobkeratops.github.io/rftest/librustc/lib.rs.html#222 . This was all pre 1.0, it's long since bit-rotted. The reasons I haven't stuck with it .. are well documented. I found ultimately it wasn't really fixing the problems I had... they also removed 2 of my favourite Rust features (the sigils, and trailing lambda 'do' notation), and made the system even fussier. And it actually removed parts of C++ that I genuinely *like*. &gt; " even though it is clear that C++ will never be there." for me, a debug mode option that detects double moves would go a long way, but we have proof that compile time check for double moves is possible .. so tell me, is there any **logical** reason that prevents this from being super-imposed as a check in C++ build (and maybe even retrofitted to the compiler as a warning you can enable, I'm sure the whole community would get behind it). **There's only one thing I can think of preventing that: commercial interests**, i.e. the vendors static analyser products might may pay people in the various communities to hold them back (and yes I've heard of concrete examples of that sort of thing happening elsewhere, before you reject it as a conspiracy theory. When there's patent trolls out there trying to bar the use of basic algorithms, it shouldn't be surprising that this sort of thing goes on) There'a another 'softer' explanation, that memory safety or performance are 2 contrasting extreme requirements and most programs fall into one or the other, as such no one has been arsed yet going all the way with provable safety in C++ because if safety was the most important factor, they're using C# or whatever already. But given the development of 100's of klocs of Rust for MLOCs of browser, I would assume the world *can* afford the development of the appropriate analyser tool to apply to the *billions* of LOC of C++ out there (which gets back to the 'commercial' argument.. some speculator probably already figured that out and funded it, and now wants to protect his investment from being destroyed by the appearance of a free version)
...in comparison to Node. I have spent a few hours looking for a nice HTTP server library. I found one. And it was severely broken.
deleted ^^^^^^^^^^^^^^^^0.5512 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/18161)
This is a great feature of Rust, but for awareness: C++17 is getting `std::variant` which is slightly more cumbersome to use but provides all the advantages you mentioned. With some [syntactic sugar magic](https://github.com/SuperV1234/scelta) you can have decent lambda-based pattern-matching as well.
It's weird that the only code in the README of a Rust repository is in C#...
I was vaguely aware it's a thing, but the problem with it (and any other new C++ feature, really) is that it'll take years for it to be adopted by the ecosystem.
deleted ^^^^^^^^^^^^^^^^0.4174 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/17476)
deleted ^^^^^^^^^^^^^^^^0.8155 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/17325)
Thanks, but I tend to stay away from library code containing `uwrap()` and `panic!()`. I've been bitten by this before.
&gt; Show me an implementation of array&lt;T, N&gt; or vector&lt;T, Allocator&gt; that is statically checked. we're talking about 2 things, runtime checks (bounds) and static checks. For my own purposes I would not use runtime bounds checks, but I have frequently added bounds checks in debug mode, along with other checks (avoiding NANs for numeric types). If I found double moves to be a serious problem , I'm sure I could figure out a debug mode runtime check for that too. I know that people here want runtime bounds checks everywhere. Thats why I keep saying: if you want them you can have them.
&gt; "Remember that you cannot use any extra storage since in every project you have worked on "trimming every last byte was critical"." You can use more memory in debug mode. Most console devkits did actually come with more RAM than the target machine, for this reason 
deleted ^^^^^^^^^^^^^^^^0.4877 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/59184)
Awesome! That's exactly the kind of tool I had in mind when writing that article. I'm very glad it inspired you to write something in Rust! :) If you want some feedback: I'd - change all the unwraps to `?` (add some more foreign errors like `std::io::Error` or `std::fmt::Error`), - use an early return instead of `if !opt.no_render { … }`, and - maybe try to replace the nested for loop with an iterator (when the std lib doesn't have the iterator thing you need, have a look at the `itertools` crate – in this case, you can use its [`iproduct!`](https://docs.rs/itertools/0.6.2/itertools/macro.iproduct.html) macro).
&gt; Rust doesn't require any extra memory or run-time cost for this check. then we can replicate the logic behind that in a similar static analyser in C++ . I know that's a lot more work, which is why I suggest the immidiate fix of a runtime debug check (which would work for me because I need those for many other reasons). &gt; Now you are willing to waste bytes and cycles, in **debug mode**, yes. As I explained, console vendors have long been aware of this which is why they often give make their devkits more memory than the consumer device. There can't be any runtime failures in the finished product. I keep saying how the prevalent use of bounds checks wasn't suitable for us. Those are an admission that the product has not yet gone through sufficient testing. &gt; yet your handwaiving that "this is doable" demeans the work we do on C++ static analyzers, I'm just stating a logical inference. You kept saying "it can't be done". I'm saying logically it must be possible, because rust and C++ can represent the same patterns, hence rusts existence (achieved with a smaller 'budget' than the world assigns to the C++ community) proves it is doable. I never said it was easy
deleted ^^^^^^^^^^^^^^^^0.9835 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/03903)
&gt; and 2) never have to worry about introducing any of these while refactoring code. if you refactor code you have to run it through tests anyway, incase you changed behaviour. People automate tests these days. I've blended the two issues because there is overlap, and I'm suggesting if a 'static double-move detector' hasn't yet been perfected, a runtime version can be added to the issues you test for in the Debug build.
Perhaps you could use a channel that emits game loop events? There is a library for AI behavior trees: https://github.com/pistondevelopers/ai_behavior This is a bit similar to what you want to achieve with coroutines. AI behavior trees are not as flexible as coroutines, but the advantage is that you can serialize them. 
What's the state of play with LLVM interface these days? https://github.com/TomBebbington/llvm-rs is the most recent thing I know of, but it looks like it may have a few safety problems. Of course if I start NIHing up my own thing on top of `llvm-sys` that will come with even more safety worries. ;-) (posted this on last week's thread just before changeover, reposting here for visibility)
deleted ^^^^^^^^^^^^^^^^0.2096 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/60181)
deleted ^^^^^^^^^^^^^^^^0.4518 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/15344)
&gt; No, you are saying that if C++ can encode in its type system the same patterns than Rust, it can, the only thing it can't do is lifetime annotations, but you can bind extra information to a wrapped reference just fine. &gt; You seem to hint in some places that you would be ok with breaking backwards compatibility to get this feature. old programs would certainly have to be cleaned up, but this is nowhere near as bad as a complete rewrite. these programs already have users - they've showed their current level of safety is enough to be *useful* you say you're working on analysers yourself... if rewriting was feasible, no one would be paying you to do that (or you wouldn't be spending your own time and money on it). &gt;&gt; 'But this is a hypothetical scenario that will never happen because whatever results from this will not look like C++ at all' most C++ programs use some preferred subset. this is no different. references: Rust already showed that with one set of assumptions, most lifetime annotations can be elided. So use those assumptions for the standard reference type. then use a ```ref&lt;T,N&gt;``` for the others. Nothing there stops it 'being C++' &gt; because what you need cannot be expressed in C++'s type system. yes it can. you can do optionals and variants (doing the job of enum). &gt; Since memory safety can't then be zero-cost if you succeed in replicating rusts checker then you'll have achieved it for zero cost. This must logically be possible. I'm not about to do this myself, so I will stick with the compromise of debug builds with extra tests. (I keep telling you , I need those anyway. There's *other things* that have to be verified.) &gt; Since achieving it without an Affine or a Linear type-system is really hard C++11 has move semantics. we just need an analyser (or empirical debug build ..) to eliminate 'use after move' . This isn't intractable. &gt; Rust's type system using comments, not comments, template with type parameters. ```ref&lt;T,ID&gt;``` &gt; the 3-10x slowdowns that MSan currently enforces These things are a sliding scale. With what I've seen I think we can catch enough. That's how we've managed to actually have a games industry for the past few decades. Rust isn't a definitive win to switch to: memory safety is just one of several issues . Compile times - ease of **iteration** (experimenting with features) is another. Thats why we need something which in some places behaves like C, whilst in others can behave more like a scripting language, but with the ability for code to migrate from one extreme to the other. I've talked about this extensively in my posts here. (incidentally thats what they achieved in the system for 'Jak&amp;Daxtar' - they had one language which could both do dynamic hot swapping for 'level scripting', entity logic, *and* handled the low level custom instructions of the PS2's DSP-like vector-units.. impressive stuff) Rust is not well targetted for the specific problems of gamedev. On the other hand take a look at jonathan blow's talks, I agree with what he says. He does have ideas on making memory bugs easier to fix, but he's prioritising the iteration time issue first and foremost (after his first video he invited email comments.. I suggested to him "why not fork rust", given I was already looking into it, and he re-iterated the reasons he rejected it. I was far more forgiving of it than he was. He uses the term "friction". I explained the features I think Rust would have needed (e.g. recovering the sigils, the 'unsafe everywhere' option , etc) and he still thought Rusts overall choices ruled it out, making it beyond hope, estimating that embarking on his own was preferable to doing this fork; and I have to say his progress has been very impressive. Writing a language isn't that difficult, what is difficult is getting consensus on the features. I know that Rust has changed a lot in it's existence, and it's feature set has been hacked down. I made several other requests (like (T;N), anonymous structs) which I discovered Rust actually *had* earlier in it's life, before I discovered it , lol. )
deleted ^^^^^^^^^^^^^^^^0.5412 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/78469)
&gt; The lifetime system requires linear types to work, the lifetime system requires annotation. An external analyser could read those annotations. the 'move-semantics' (tracking the moves of owned pointers) are different. we just need the analyser to highlight 'use after move'. all that rust does is makes 'move' the default (i.e. almost if you wrote 'move(x)' everywhere. with C++ it's the opposite, as if you wrote '.clone()' everywhere, (* with the caveat that it has 'auto-borrow' when confronted with reference arguments) &gt; You are the master of Rust that has never written anything on it, I have. " the master of C++ static analysis" never said I was the 'master of static analysis', but I'm inferring what should be possible. Swapping 'moves()' and "clones()', and 'auto borrows', thats' all. (there's a transitivity assumption on const , but we usually roll that where needed. Posts here have shown rust isn't using the aliasing assumptions as well as C++ yet) you're claiming Rust has some extra exclusive magic. All I can see is extra is lifetime annotations, which is just adding a name really. there's uninitailzied variables too, but it's easy to eliminate those (you could eliminate all primitive types, replacing with types that always construct themselves, and modern C++ has made it easier to forward args to constructors, hence emplace back )
&gt; productive &gt; The amount of test you have to write in Rust is a fraction of the tests you need to write in C++, I suspect you're comparing classic C++ to Rust . besides, the tests and debug code I write are for issues beyond the scope of the borrow checker. Numerical stability (how many approximations for speed can you get away with). (I keep talking about the NaNs, we assume 'there are no NaNs and test until this is true. A NaN at runtime means you have more work to do to ensure they never appear. What's your physics supposed to do with a NaN??? we don't encounter singularities in day to day experience, lol. Before that I implemented car physics back in the days of fixed point maths, which of course meant ensuring values stayed in predictable ranges. ) Efficiency of encoding, integrity of data structures after transformations. Memory bugs are not that big a deal. If they *were* the biggest problem we'd have invented rust ages ago.
Sounds great. Will try it out soon. What about panic safety? What happens if rust part panics? I know that it's UB in rust, but what about your project?
deleted ^^^^^^^^^^^^^^^^0.5122 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/77696)
If Rust panics in the GUI thread, the program dies. If it does in a worker thread, that thread dies and any channels it has to the GUI thread will give errors. Qt code generally does not have many ways to report errors. If you like to report errors from Rust to Qt, you best add an error: Option&lt;String&gt; or similar to the binding, so you can report this via an appropriate way to the user. 
It’s particularly interesting to see this [written in C++](https://cgit.kde.org/scratch/vandenoever/rust_qt_binding_generator.git/tree/src/rust.cpp).
&gt; higher-ranked trait bounds trait bounds aren't needed for safety, they just control error messages. safety could be dealt with at the point of instantiation. NEXT. the use case where I was shown this was an awkward workaround for the type inference , not being able to handle the simplest case ('non-escaping references in a lambda'), it had to be spelled out. &gt; typed generics Rust has lifetime parametricity read type parameters. C++ has 'template template parameters', rust can't do that yet. &gt;interior/exterior mutability c++ has a mutable keyword for bypassing const &gt; make templates fully constrained not needed, thats a choice on ergonomics not safety. &gt; you would need to make ```std::move``` destructive ok i've seen that after you move form a value, you could re-assign to it. so lets make a new function, '```std::consume```' perhaps or ```std::destructive::move```, which is intended to be semantically destructive. swap it in as a *non breaking change*. &gt; change the meanings of const I for one have never used 'const' without wanting it to be transitive. I think some of the old C libraries break that assumption, but we can deprecate those. &gt; This list can be summarized in one sentence: you would need to make C++ be Rust. if you truly believe this, inform whoever is paying you to work on analysers that they are wasting their money on a lost cause, and tell all the companies clients to use Rust. Go back in time a couple of years and explain all this to Jonathan Blow before he got his fully functioning alternative going. &gt; "you would need to make C++ be Rust." but there's other differences. C++'s overloads are more open ...and I actually prefer that. **I strongly dislike the inclusion of the trait in the method namespacing** . C++ has internal vtables, they still have use-cases. one thing Enum's can't do is variable size... the enum must be padded out, *incase* you mutate it. Conversely, C++ embedded vtables cover a use case of variable size, located by one pointer from the users' POV. C++ has template-tempalte parameters, nestable types with shared parameters, template parameter consts, variadic templates .. All that is orthogonal to safety. Retrofitting safety to C++ would not turn it into Rust.. it would be 'safe C++'
deleted ^^^^^^^^^^^^^^^^0.8417 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/12927)
/r/playrust
&gt; No, when lifetimes are involved they also control soundness, it's just where they're checked. C++ relies on checking *at the call site*, so each instantiation needs to be checked separately, that's all*. and I'm sure this is the cause of extra complication in Rust. I don't agree that checked generics are always a win.. thats one of the main reasons I haven't stuck with using it. (* and in the absence of runtime polymorphism , I still wonder if that means you could eliminate annotations...)
Just updated [Handlebars](https://github.com/sunng87/handlebars-rust) to pest 1.0 last week. I'm going to fix some leftover issues and review the public API against Rust API guidelines. Then I think it's time for a 1.0 release, after almost 3 years of development. The next major release after 1.0 will be adding compile-time template support. 
Pseudo-French: allocateur Pseudo-German: allokator (Imagine Rammstein pronouncing this: *Ich will. Alllokatorrrr.*)
deleted ^^^^^^^^^^^^^^^^0.6357 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/81396)
&gt; "Lifetime parameters are not type parameters. They are a different kind of parameter." as I understand rust wants to check everything locally (to control error messages); but if you can trace everything from the original point of instantiation, you'd have exact information. I would have to work through some examples in detail to convince myself that you'd still need annotations at all. I think whats really going on here is a tradeoff (paying the cost in extra mark-up, versus bigger errors) I can see *runtime* polymorphism would need annotations, but you could just say 'no references passed into a vtable function can be cached' (effectively they must be 'the shortest possible lifetime' , which incidentally i'd like a special direct syntax for.. thats where I was shown 'use the for&lt;'a&gt; notation' which seemed clumsier. ) the main use for *returning* references is accessors for collection classes (hence rusts 'self lifetime' assumption, should be easy enough for a C++ analyser to copy)
The transmutation between `Box&lt;T&gt;` and `*mut T` is fine. There are library calls for that purpose. Freeing a `*mut` obtained from a non-Rust source using `Box::drop` is undefined - you're right to be worried about this, but what you're doing is likely reliable. The completely safe answer would be to pass pointers back to the original plugin and call `Box::drop` there. You would need to do this with a C library. The problem comes from transmutation of `*mut ()` into `*mut T` whenever `T` has an undefined representation. Undefined behaviour often - typically! - works until it mysteriously stops working. This is why testing isn't enough. Undefined representation means any struct, enum, or fn that isn't C-safe, and any closure or trait used as a concrete type. [Nomocon definition of C-safety](https://doc.rust-lang.org/nomicon/other-reprs.html). As far as I know drop flags are no longer a concern. Dynamic loading fetches pointers using c-string keys. But vtable layout doesn't use the symbol table. (I'm pretty sure.) It's in rustc's memory during compilation, then it's gone. (Even if that knowledge is encoded in the symbol table, you're not decoding it and adjusting vtables, are you?) There is no guarantee that separate invocations of rustc will agree on the mapping between methods and vtable indices. The names *might* be sorted. Or they might not. Who knows? The compiler developer's know, but they say "there is no ABI yet; we'll change things as we see fit." 
I have a long shift at work today, but I'll check back tomorrow.
deleted ^^^^^^^^^^^^^^^^0.1672 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/61619)
404 :/
We have a plain C-like function exported and loaded dynamically by name; it returns a pointer transparently - that's fine. What that pointer points to is in question. If there was no guarantee that separate invocations of rustc would agree on the vtable structure given the same trait definitions, then I suspect that regular dynamic linking would also depend on undefined behaviour as well. We don't need a stable ABI, just agreement between shared libraries compiled by the same version of the compiler. 
Can't you use a `cfg` attribute?
What would the story be like for packaging/deploying to Windows/macOS in a user friendly format without requiring the user to have specific Qt installed? Can cargo build a binary .exe with Qt included on Windows?(getting higher than 5.6 Qt with Python's Conda is a pain atm).. If it outputs C++ to compile with Rust code in a separate binary I guess there's a bit more work to package that into an .exe .app? A github mirror would be nice too!
Heading into [week 6 of my Gameboy emulator](https://github.com/simon-whitehead/chemboy). Last week my goal was to get MBC1 support happening and I did successfully after a couple of failed attempts. Now that it works though, this gives me basic support for games that use MBC1 such as Kirby's Dream Land. I [had some rendering issues early on](https://user-images.githubusercontent.com/2499070/29776841-54a8cec6-8c4d-11e7-866d-318024198b42.gif) because [I had some improper rendering logic for things like sprite colour palettes](https://user-images.githubusercontent.com/2499070/30027892-2b31b570-91c6-11e7-9a19-9233d0f54875.png) and sprite attributes. I fixed those up though and [Kirby is running really well](https://user-images.githubusercontent.com/2499070/30028002-99830786-91c6-11e7-8433-e81ac6b49e72.gif) 😀 This week I plan on finishing up some small rendering things I have missed. There are some things I don't support yet like Y-axis flipping of sprites, the top half of Kirby disappears when you fly close to the top of the screen, etc. These are the sorts of bugs I want to iron out this week before I move on.
&gt; Can't you use a cfg attribute? How? You can compile on `linux/amd64` to `android/arm`, `cfg` attribute in `build.rs` will be related to `linux/amd64` while you need cfg values for `android/arm` to generate correct code
Back from vacation (again, it's a tough life) and getting back into [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis) work. Thermodynamic temperature/temperature difference work on hold while trying to make the underlying storage type based on traits in the `Num` crate instead of fixed `f32` and `f64` implementations.
With Rust Qt Binding Generator you can choose any build system you like. The project itself uses Cargo to build a static library with C FFI. That is linked into an executable with Qt libraries by CMake. This should work on any platform. Perhaps some special libs that Rust needs should be added in the CMake link step. You could use other build tools too. Shipping the executables to Windows and Mac OS would be the same as for any Qt project. Main KDE projects have readonly mirrors on GitHub, so depending on the outcome of the review that would happen.
&gt; (comparing regrep on multilpe cores to single threaded grep) Assuming you're referring to ripgrep, could you please point out where I've done that? In my blog post, I tried to focus on benchmarks that compare GNU grep performance with ripgrep performance on a single file, in which case, both programs are single threaded. I would love to entertain any critical feedback you might have, but I'd like to ask you to be very specific.
[Drow](https://en.wikipedia.org/wiki/Drow_(Dungeons_%26_Dragons\))malloc?
A prototype is available here: https://github.com/kosta/date-iterator I'll try to get this or something similar into `chrono` where this belongs (I think).
I've done a gist that doesn't match your library exactly, but demonstrates the possible pattern you could use use std::collections::HashMap; enum Thing { String(String), Number(i64), Name(String), TrueOrFalse(bool), Array(Vec&lt;Thing&gt;), Map(HashMap&lt;String, Thing&gt;), } impl Thing { fn as_string(&amp;self) -&gt; Option&lt;&amp;str&gt; { match self { &amp;Thing::String(ref s) =&gt; Some(s), _ =&gt; None } } fn as_map(&amp;self) -&gt; Option&lt;&amp;HashMap&lt;String, Thing&gt;&gt; { match self { &amp;Thing::Map(ref s) =&gt; Some(s), _ =&gt; None } } } fn get_thing() -&gt; Result&lt;Thing, ()&gt; { let mut map: HashMap&lt;String, Thing&gt; = HashMap::new(); map.insert("message".into(), Thing::String("Tale told by an idiot".into())); Ok(Thing::Map(map)) } fn main() { match get_thing() { Ok(Thing::Map(map)) =&gt; { match map.get("message".into()) { Some(&amp;Thing::String(ref s)) =&gt; println!("{}", s), _ =&gt; panic!("Same as outer") } } _ =&gt; panic!("Incorrect result, could handle error or just panic") } } You can match multiple layers at the same time, but you need to make the hashmap (or whatever map collection you use) call in a new expression block.
Fixed :-)
So nice of you. Thank you! I have made some progress, but I am unable to assign the reference back in the ed_config structure. First I redefined the variable as: pub hl_syntax: Option&lt;Box&lt;HighlightSyntax&gt;&gt;, // Current syntax highlight. Here is the code snippet: let boxed_hl: Box&lt;HighlightSyntax&gt; = Box::new(HighlightSyntax::new()); let unboxed_hl: HighlightSyntax = *boxed_hl; let mut ed_config = editor::editor::EditorConfig::new(&amp;args[1]); if HighlightSyntax::get_hl_syntax(&amp;unboxed_hl, &amp;args[1]) { println!("unboxed_hl.keyword {:?}", unboxed_hl.keywords); //let ed_config.hl_syntax = &amp;unboxed_hl; } I made several attempts to assign the address of unboxed_hl to the structure member hl_syntax. But the compiler didn't accept any of them. 
Thanks for this!
Well, comment wasn't meant as a criticism to rg, but sure, I tested it on multiple files generate from a database at work. One of said files (which I have in front of me right now) is 48304960 lines &amp; ~11GB (It's just hashes of various values so I can freely share it if you want to test it yourself). And the performance I get when doing time rg 18067901277480319615 test.csv is 19.66s user 2.14s system 93% cpu 23.282 total Whilst with grep time grep 18067901277480319615 test.csv it's 5.58s user 2.46s system 99% cpu 8.091 total (well, values vary over several runs but not by a huge margin, and generally using rg results in slightly less system time for some reason) Benchmarked on various other large files I had on hand varies from slightly better to a lot worse, but I've never managed to get an amazing increase in speed from rg. It get's even worse when I feed it line by line via cat, though I guess it's not necessary to optimize for that. Running the example on the github repo for example (-w 'Sherlock [A-Z]\w+') will result in a slightly better time for rg but the difference is between ~3s(grep) and 2.2s(rg), not anything as staggering as a 3 fold increase. But the point I was trying to make is basically: ripgrep claims to be above and beyond grep: &gt; It can replace both The Silver Searcher and GNU grep because it is faster than both. But doing some benchmarks of my own work where I sometime need to use grep (on relatively sizeable and diverse files) I couldn't see it. I'm not saying your specific benchmarks are false or not well done, I'm just saying that it would be quite easy to think they were doctored in such a way that rg would come up first and using them to claim it's faster "in general" rather than "faster on some machines, for some files, for certain patterns" which seems to be closer to the truth. I mean, don't get me wrong, it's a great tool by the simple fact it provides very nice default options, as in, it's enough for me to recommend it to people. But it's a recent example of how I wasn't able to really reproduce some rather incredulous benchmarks when tweaking a tiny element (in this case the file used). 
maybe a little help with rocket? it currently doesn't support custom helpers...
I also started a new program after seeing that article. It's a really good article but I had a bit of the opposite reaction. Namely with error chain. It feels like there is a lot of magic going on, and working out how to use the magic is not obvious. I had errors where I felt I was unable to pick out the bits I needed, to then start working out how to debug the error. But I've got a lot more done I am churning through my CLI. I think Rust is a really nice language, but that has a higher than normal barrier to entry. I've also said this many times; but Cargo is fucking awesome, and this is from someone that hates build systems. Normally I see a build system as like medicine; you need it, but you don't enjoy it. Cargo is one of the few build systems I enjoy using. Namely because it works, isn't dog slow, and the config is in a sweet spot of short, straight forward, and yet powerful. It's refreshingly idiot proof. Only thing I'd change is to integrate `cargo add` and `cargo remove` as standard. Rather than via a plugin.
&gt; The next major release after 1.0 will be adding compile-time template support. \o/
Had fun writing my own Trie which can be saved/loaded on the local filesystem: https://github.com/sevagh/surge/tree/master/fs-trie I intend to use it in surge. I realize there's existing solutions for saving data structures to the filesystem but it was a learning experience. I think I should implement the Entry API, and there's probably ways I can make the struct smaller.
They're pretty great, even if you just use them as a compile-checked tagged union. For example, consider [this example from a Stack Overflow](https://stackoverflow.com/a/252568)): enum Type { INTS, FLOATS, DOUBLE }; struct S { Type s_type; union { int s_ints[2]; float s_floats[2]; double s_double; }; }; void do_something(struct S *s) { switch(s-&gt;s_type) { case INTS: // do something with s-&gt;s_ints break; case FLOATS: // do something with s-&gt;s_floats break; case DOUBLE: // do something with s-&gt;s_double break; } } Becomes [this (playground link)](https://play.rust-lang.org/?gist=ee55b12552931c8b854ea327c6fdae61&amp;version=stable): enum Type { Ints([i32; 2]), Floats([f32; 2]), Double(f64), } fn do_something(s: &amp;Type) { match *s { Type::Ints(val) =&gt; println!("int array: {:?}", val), // do something, Type::Floats(val) =&gt; println!("float array: {:?}", val), // do something, Type::Double(val) =&gt; println!("double: {}", val), // do something, } } If you'll notice, they tag went away, so you can't work with them incorrectly. In the C example, I could do: void do_something(struct S *s) { // didn't set the tag s-&gt;double = 3.14; // access without checking the tag s-&gt;ints[0] = 4; } In Rust, you can't forget setting the tag or misinterpret the data while using safe code. Oh, and the code is simpler as well, so that's a plus :)
I must second this. I've been building a couple web projects in Rust and, while there are some good libraries (I've been using Rocket and Iron), the ecosystem just isn't there yet and there are glaring issues, such as: - no websocket upgrades on an HTTP server (have to use two ports in most cases) - "best" frameworks are inefficient (Iron and Rocket both use threads instead of async i/o, though this is in the works) - limited ecosystem (web on Rust is young) So, for serious projects, I use Go, but for other projects that *will* become serious soon (6+ months), I'm using Rust behind an nginx proxy (to handle https and because I don't trust it yet to run as root). I have two main projects underway in Rust: - game server (wanted the game and server in the same language) - online service that will hopefully hit production within a year However, I just can't recommend Rust over Go right now for anything that needs to be deployed *now* (within the next 6 months to a year) as a web server. It can work great linked in to a Go webserver though (e.g. write your code as a library and link it in with Go).
&gt; And as I mentioned, HTTP/2. Is this a requirement *now* or does it just need to happen "soon". As in, would having it work in 6 months to a year be acceptable? That's roughly the time scale that I think `hyper` will have it by, but that's my undereducated guess from the sidelines (I don't work on hyper), though I may work on it within that timeframe since I'm trying to ship something in 6 months to a year.
Thanks for the feedback! I'm struggling to see how you got burned here, and I'd love to hear what I could do to improve benchmarks. Surely, I can't cover every case. But if we could find a way to reproduce your benchmark in a controlled way, then I'd be happy to add it to ripgrep's benchmarks next time I update them. &gt; I'm not saying your specific benchmarks are false or not well done, I'm just saying that it would be quite easy to think they were doctored in such a way that rg would come up first and using them to claim it's faster "in general" rather than "faster on some machines, for some files, for certain patterns" which seems to be closer to the truth. There's no such thing as a flawless benchmark. The performance difference between GNU grep and ripgrep will differ based on not only what you're searching, but the pattern you're using. I think talking about them being "doctored" is a little out there. I went through great pains to [document my methodology](http://blog.burntsushi.net/ripgrep/#methodology). If you want to, you can try to reproduce the benchmarks in my blog post or even add your own without too much fuss at all. If all you're really getting hung up on is some wording in my README, then I have [tweaked that](https://github.com/BurntSushi/ripgrep/commit/f9cbf7d3d4febc44e7834003eec1f25498da111f). I can't *literally* claim ripgrep is faster than everything else in all cases because I can't test all cases. All I can do it come up with evidence that it's faster in enough cases to matter. To do that, I had to select corpora. I selected a popular codebase, a huge file of English text and a huge file of Russian text. That feels like a good representative sample, although it notably doesn't cover the case of *random* text, and it sounds like that's what your use case is. &gt; Running the example on the github repo for example (-w 'Sherlock [A-Z]\w+') will result in a slightly better time for rg but the difference is between ~3s(grep) and 2.2s(rg), not anything as staggering as a 3 fold increase. Not for me: $ time LC_ALL=C egrep -w -c 'Sherlock [A-Z]\w+' OpenSubtitles2016.raw.en 5268 real 0m7.468s user 0m6.238s sys 0m1.230s $ time rg -w -c 'Sherlock [A-Z]\w+' OpenSubtitles2016.raw.en 5268 real 0m2.376s user 0m2.103s sys 0m0.273s This is after multiple runs. Both times stabilized. I don't really know how to explain your results. I'm using grep 3.1. All I can really do is run the benchmarks and report the results because I don't know every relevant detail of your environment. &gt; One of said files (which I have in front of me right now) is 48304960 lines &amp; ~11GB (It's just hashes of various values so I can freely share it if you want to test it yourself). Yes! I would like to test it. I'm not sure how to get a 11GB file from you though! Invariably, any two search tools that use different algorithms to implement search will differ in some cases. The trick is figuring out how to strike a good balance. I wouldn't be surprised if the different boyer-moore heuristics are impacting things. Literal optimizations are both the secret to ripgrep's (and grep's) speed, but can also be their downfall when they trip over "pathological" cases. The key is that ripgrep and grep have different pathological cases, so it's possible to trip over one and not the other. Another possible explanation is that you're running these searches on a VM, and if ripgrep is using memory maps, then it might be paying penalty for that. You can disable memory maps with the `--no-mmap` flag. &gt; But it's a recent example of how I wasn't able to really reproduce some rather incredulous benchmarks when tweaking a tiny element (in this case the file used). But it's *not* a tiny element. The corpus has a *huge* impact on the performance of a tool. This was actually a point I tried to drive home in my blog post by using an English and a Russian corpus in the single file benchmarks. Look at the relative time differences between them. Some tools get *destroyed* on non-ASCII text. Even in the simple literal cases! If you find the benchmarks incredulous, then I'd encourage you to try to reproduce them. I spent *a lot* of time trying to figure out how to produce a fair benchmark, and in particular, this required knowing a lot about how other tools worked and what exactly could impact performance. It is *non-trivial* to reproduce them in off-hand experiments because there are many variables at play. That's why I put so much work into making it possible for initiated readers to reproduce the benchmarks. You can even [look at the raw data](https://github.com/BurntSushi/ripgrep/blob/master/benchsuite/runs/2016-09-20-ubuntu1604-ec2/raw.csv) if you want to. Notice how each run for each tool is carefully crafted to have the right flags so that the results are comparable (to the best of my knowledge).
I would *like* to use it right now if possible, but it isn't necessary. If HTTP2 is coming to Hyper in the next 6 months I will absolutely begin learning Rust (I would anyway just because it's such a pretty language).
If you look at the third line of the output, you can see that it tried to backtrace the other thread but couldn't generate any frames. It seems like a bug in the Windows backtrace logic.
&gt; * Wait for arbitrary logic, by yielding a boxed trait object Too bad we have to box it and can't somehow use a lifetime that says "_from `yield` until execution returns to generator_"...
On master, because of code issues. Mostly because of syntax errors.
You’ll need to use `std::env` at some point. I suppose a constructor parameter might be useful to keep `std::env` calls in `build.rs` in case you’re moving some on the code generation logic out of that file into a library?
That's disappointing...
After a few months of deliberating and getting comfortable with Rust I finally started to do work on [Jiyunet](https://github.com/jiyunet/jiyunet) with some friends, which is basically a distributed messageboard on a blockchain, but it's more than capable of doing more things. I spent the last week and a half getting together something partially complete. I have no idea how I'm going to do GUIs and things to make it easy to use but I am really excited to be using Rust for a big project.
So as someone that's just starting out learning Rust, which one would be better to use to have a Qt GUI?
Is there any benefit to user-tracked sizes besides saving size_of::&lt;usize&gt;() bytes of memory?
Not up to date but might be helpful, 01. https://github.com/cis198-2016f/slides/blob/gh-pages/10/content.md 02. https://github.com/cis198-2016f/slides/blob/gh-pages/11/content.md
Nobody is currently working on http2 for hyper right *now*, but it actually did have support for it on the old synchronous version for a while. Its very likely to get it again soon™.
If it's just for learning, choose something that's easy to set up. So try one with a simple tutorial and if that works, go for it. 
If I'm using VS Code, which Rust plugin do I use? vscode-rust or rls-vscode?
Yes. Most modern allocators (ours included) are organized essentially as a collection of simpler allocators, each of which is responsible for allocating objects in a particular size range. If you don't know the size up front, then you first have to figure it out in order to figure out which of the underlying allocators to free an object to, whereas if you are given the size, then you can bypass this lookup.
Yeah, from clean architecture point of view keep `std::env` calls in `build.rs` is good. But parsing `std::env` somewhere deep inside code generation crate is much more convinient for user, so I can not decide which one variant to choose. And I know only one wide used crate that should care about this - `bindgen`, but looks like it have no option for that and not parsing `TARGET`, just ignore that host may be not equals to target: https://github.com/rust-lang-nursery/rust-bindgen/issues/942
I don't have a good link, so I'll try to explain here (assuming you are familiar with what the stack and heap is, if not it should be easy to find resources on that on google.): If you want to allocate something on the heap on stable rust at the moment, you have a few options: The most common way is to use a Vec (The default growable array type, i.e std::vector in C++ and similar to ArrayList in Java, List in C#, lists in python etc..). For small types, like integers and floats this is generally fine. If you want to put a single value on the heap in rust, the common way to use that would be to use the `Box&lt;T&gt;` type (or alternatively, `Rc`/`Arc` that use reference counting if you need the ownership to be shared.). On nightly rust, there is a special keyword to create boxed values: `box`. E.g `let value = box [20u32;100]`. Since the `box` keyword is unstable, on stable rust you have to use the normal constructor, `Box&lt;T&gt;::new` instead. The issue with that is that if the type contains or is an array, e.g (`[u32;100]`), the compiler does at the moment [have trouble optimizing out the temporary values that would be emitted when doing something like `let foo = Box::new([10;100])`](https://github.com/rust-lang/rust/issues/41160). This results in slowness and using up a lot of stack space since even in optimized mode, this statement would result in an 100-length array being created on the stack, then filled with the value of 100, and finally the value would be copied on to the array that was allocated on the heap. In debug/non-optimized builds, the problem is even worse, as there will be *several* copies of the array on the stack, and thus it's really easy to create a stack overflow. (Even if the issue with optimization is fixed.) Now, there are workarounds to this, but they are all a bit clunky: * If the type implements the `Default` trait, one can use Box::default() instead (which is simply `box Default::default()` internally). This won't work if you want to e.g create an array larger than 32 since those don't implement traits at the the moment (due to the lack of const generics, though that's being worked on, the RFC looks like it is close to being accepted.) * A few collection types can be converted to a Box&lt;[T]&gt;, like Vec. The downside of this is that you won't have the length info as part of the type, which is useful for evading bounds checks. * You can manually allocate with `libc` (the rust standard library has allocator functions but they are not stable), or alternatively using a Vec&lt;u8&gt;. That does however involve unsafe and means you will have to manually transmute between types which can get ugly. It also means you can't use the Box type since you can't guarantee that it will be deallocated with the same allocator that was used to create the value. Eventually we will also hopefully get support for `placement new` functionality (construct a value in-place in some specified memory location) but that [isn't implemented and the details aren't decided on yet.](https://github.com/rust-lang/rust/issues/27779)
It depends on how you define freedom. Those same holes and exploits impinge on your freedom by allowing malicious third parties to hack you and spy on you, especially if you're a valuable target. Freedom from those vulnerabilities would be valuable to many. Virtually no one jailbreaks iPhones in 2017, compared to 2010.
I don't really see a problem here. I've never purchased products that required 'jailbreaking'. Just don't buy iOS and other locked devices?
Software bugs are not a source of user freedom. Just because you can subvert something and control it does not mean you have the *right* to do so, which is what user freedom is all about. Besides, if you have the hardware in your hands, there is nothing anyone can do to stop you from gaining total control, bugs or not. You can rewire the machine to do what you want. Rust doesn't effect any of this.
yup. vulnerabilities will always exist, but safe memory management, whether done by professional systems programmers or by the compiler, definitely rules out a class of hackability
I'm still working on my [voxel-based procedural planet generator](https://github.com/coreh/universe/). Progress was sorta slow this week: I laid the initial foundation to allow transformation between different reference frames with decent precision and numerical stability: This should (eventually) allow for the transversal of astronomical-scale distances between planets and solar systems, while still retaining fine precision on a local scale, by nesting different reference frames on a [spaghetti stack](https://en.wikipedia.org/wiki/Parent_pointer_tree) and finding the "shortest" conversion possible between them. I'm now implementing the logarithmic depth buffer described [here](http://outerra.blogspot.com.br/2009/08/logarithmic-z-buffer.html) to accommodate for the crazy range of draw distances involved without noticeable z-fighting.
Sorry, I should have been more specific, the 'Sherlock [A-Z]\w+' example was run on the same files I mentioned. As for the ~11G file I mentioned, it is basically a file full of numbers, with some amount of repetition, so I will xz next morning and share a link with you, overall I'd imagine it could be compressed to 200M or so. And yes, I do imagine that things like the target encoding and even just the content treated as ASCII could have a huge impact, but that's why I disagree with the statement of "faster" rather than "Sometimes faster" or "comparably fast in most scenarios and even better in some"
Given the choice, I'd rather have a phone I cannot jailbreak than a TV that can be used to spy on me.
&gt; I also started a new program after seeing that article. That makes me really happy :) Do you think I should add a disclaimer to the error-chain section? A lot of people don't seem to be comfortable with its amount of magic, but I quite like it the way it is personally. &gt; Only thing I'd change is to integrate cargo add and cargo remove as standard. Once we have a working format-preserving TOML reader/write I'll make that PR to cargo myself!
Thank you for writing out a lengthy explanation. I come from a C/C++ background, so I know what stack/heap is. I understand Rust's Vec and Box types. However, I did not understand why a `box` keyword is needed. I still don't. From how you described it, to me it sounds like the it is a compiler issue/bug that the compiler isn't smart enough to recognize what you are doing and optimize it accordingly. Introducing a whole new keyword into the language just to work around it seems like a hack/kludge. Sounds like the only disadvantage of the regular constructor is that the compiler is too stupid to optimize it. Is there any additional new information that the `box` keyword actually communicates to the compiler? Why exactly is it needed? What is the advantage? Simply adding new syntax to the language for seemingly no reason seems ugly to me. I understand the workarounds you describe and the drawbacks of each. Thank you for that. 
Nice! If you want to reduce the boilerplate around CLI args and errors a bit, [I have some tips](https://deterministic.space/rust-cli-tips.html) and would love to know if they could help you :)
Or, `File::open(input_path).expect(&amp;format!("Couldn't open {:?}", input_path));` which display the original error as well, [but not quite as nice](https://play.rust-lang.org/?gist=3650e49b5cd39b2048553e8561d495ed&amp;version=stable). (I'd use a custom error that impls `From&lt;std::io::Error&gt;`)
The problem with python is the deployment. All that pip dance as opposed to just dropping single static binary. Heck, the target host doesn't even need internet connection. Python is great as long as you stay within stdlib.
The party most likely to use the TV to spy on you is the TV's manufacturer.
Do you plan on continuing this with other platforms such as Gameboy™ Advance or even newer ones?
With more and more devices gaining undesirable "features" this would, in the long run, boil down to "just don't participate in society".
&gt; Just because you can subvert something and control it does not mean you have the right to do so Actually, at least where I live (Europe), it *does*. As long as you don't endanger others in the process. Edit: It's legal in the US and Canada as well. The US even specifically crafted a general exemption to the DMCA to that effect.
While I don't own any Apple devices, I have installed custom ROMs on virtually *all* my Android devices, mostly because the manufacturer stops supplying updates long before the EOL of the device. Granted, my last couple devices also had manufacturer support for unlocking the bootloader to do so, but support for that option is waning in the market.
Right, at the moment rust-bindgen leaves you on your own to pass appropriate parameters to clang through `clang_arg` or `clang_args`. This could definitely be improved. I think it would be reasonable for bindgen itself to use `std::env` by default to look up varibles set by Cargo, and automatically configure clang for cross-compiling. Of course with some API to disable/override this behavior.
Saying that you can rewire it is such bullshit. I'd love to see you rewire an iPhone to run arbitrary software. This type of thing is not feasible for anyone.
For comparison, here's a similar program I have written before. The main difference is that I used half-block characters, so a single character ends up being two pixels. https://github.com/FreeFull/termimage
Support for that is not waning, from anything I've seen. If you want to use custom ROMs, buy phones that don't prevent you from unlocking the bootloader.
The best way right now is encapsulating the game logic in systems that access indexes of components for each entity ID (a less typical implementation of ECS, but easier to reason for concurrency). There are plenty of ECS's in Rust for this purpose, I recommend [specs-rs](https://github.com/slide-rs/specs). That library has a facility for sharing a global context value between systems, which is where you might store your engine state e.g. a frame counter or elapsed time. Due to the safety constraints in the language, it can be a little non-intuitive applying conventional game engine programming patterns.
If it doesn't get it by the time my projects are about ready to go public (I'm hoping within the next 6 months or so), I'll probably work on it and contribute it to the hyper project. That's not a promise or anything, just a hopeful estimate. And yes, since it had it in the past, I'm guessing it'll come soon^TM too. :)
It seems hard to know where to store the object being referred to. Local variables are stored inside the generator object, so how do you refer to them when the generator object might be moved 
'unboxing' frees the box memory and moves the struct back into automatic memory, which will be freed when the function returns let local = *boxed; Instead, you can just use the box pointer almost anywhere you could use a borrowed pointer. The compiler will convert `&amp;Box&lt;T&gt;` to `&amp;T` automatically. Same for `&amp;mut` 
Data science is mainly focused on Python and R. I'd recommend learning those. Rust is great for writing actual production code, but Python will allow you to complete school assignments in less time.
Are you allowed to choose your own language for the assignments? That seems strange for a class focused on data structures... If you know Rust already, then it's not a bad choice. Assuming you can't use the data structures in the standard library, you should make sure you're familiar with unsafe Rust as well. If you don't know Rust, then you should probably use something with a bit less of a learning curve for you. It might be difficult to do assignments *and* learn a language at the same time.
I'm not very experienced with Rust yet, but that might be doing it in hard mode unless you know when to use unsafe. Some data structures might be really hard or even impossible without unsafe and it might be frustating to implement those when you can't recognise yet when you need unsafe.
Many of those devices are, frankly, out of my price range. Especially the "hackable" device market is a niche and the devices are relatively pricey for what they can do due to the small production runs. I had to replace my Samsung S2 this year due to hardware failure. It took me *two weeks* of research to even find a moderately useful replacement (Moto G4) for ~$150, which was money that I'd rather not have spent. Most recent phones have switched to fixed batteries, which is just not acceptable, and the manufacturers that haven't will do so soon according to their respective roadmaps. I just do not see that *abundance* of great options you speak of.
I'm probably going to get grilled for this opinion, but I would say probably not. I mean.. it depends on how much time you have available and what those exercises are. I'm new to Rust and still learning, but one of the first things I attempted to write was a trie tree in rust. I've done it before I Java back in University and thought it would be a good way to get my feet wet with rust. I spent hours trying to please the borrow checker before I even knew about std::mem::replace and the take function on option types. I eventually realized I picked the wrong project to learn rust with and found: http://cglab.ca/~abeinges/blah/too-many-lists/book/ If you're going to do it, then definitely try 'too many lists' first. I think after going through that you'll be able to do it or at least aware of what you might run into when Implementing data structures in rust. I put the trie tree project aside and instead decided to reimplement a text based game called Hunt the Wumpus to learn rust and it's been going good so far. I've done it before in C#, this time I want to make it testable which requires dependency injection. So I'm running into all sorts of interesting design decisions between static vs dynamic dispatch. I'm so used to working in OO languages it's hard for me to know what is going to end up as a better design in rust.
This week I'm working on an early version of a game engine in Rust, backed by `gfx`. I'm choosing to take a different approach than current Rusty engines. Backstory: For probably around a year I've been fiddling with a rendering engine in `gfx` and waiting for a good-looking game engine in Rust to come along. However, having seen a couple come and go, it seems I'm looking for something different than folks are currently focusing on. Talking some more about those differences: - Current game engines in Rust seem to be spectacularly obsessed with ECS. I come from a JavaScript background and have done most of my 3d work in WebGL—games I worked on in JavaScript did not use ECS, or if they used a similar pattern it was close enough to normal JS that it didn't take a third-party library to implement. ECS is not the only pattern for managing game state, so I don't know why all current engines choose to have it baked-in at the lowest possible level. - The biggest thing current engines seem to lack is a comprehensive scene graph. I'm talking about a tree-based hierarchy with transforms at each node and model instances throughout. I'm utterly baffled that there are so many engines, ECS libraries, 2d rendering libraries, etc. and not one great scene graph implementation. With those stark differences between my expectation and the current state of things, I've got an early vision of my ideal Rust game engine—a rendering engine with a scene graph, camera, and asset management, which all work together out-of-the-box. Consumer chooses how to integrate with a state-management solution of their choice. One final aside: Most current engines I've seen fail to hide their underlying complexity well, and instead require the programmer to learn a lot of the underlying mechanisms in order to use the engine. The Rust module system, `pub(crate)`, etc. make it really easy to hide complexity and expose carefully crafted APIs, but I've not found any examples of this in the Rust game-dev world.
+1 for Python. I'm not too familiar with R but Python + e.g. Pandas/NumPy/SciPy is pretty popular within data sciences. OP also mentions he's a "moderately inexperienced programmer", so if he's already had exposure to say Java, it's probably better to stick with that. After all, the objective is to learn algorithms and data structures. Once learned you can translate that knowledge to other languages. Also if you stick with more mainstream languages, any problems you might encounter are more easily "googleble" (i.e. found on stackexchange).
The iPhone is not a free software system. Rust doesn't make it more or less free because as you, myself, (and others) have pointed out, the barriers to software freedom are hardware access and the law. Either way, not knowing how to do something is irrelevant to the discussion of whether you are actually allowed to do it.
A lot of types will require that you call some kind of `finish()` function that can return an error, and produce a panic if you let it drop without calling finish(). It's usually a pattern that seems to work out pretty well.
It was a good article. &gt; Do you think I should add a disclaimer to the error-chain section? Tbh, no. Your article does it's job of being *'here are some libraries I find useful and why'*. If you want to expand on error-chain then I'd do it as a second post, and link to it from the first. It was a good article btw.
That's more a political problem than a technical one. You should lobby politicians to ban devices with firmware that can't be replaced by the user.
I rather have a TV that's a TV and not a surveillance device. I simply have no need for an internet connected TV with outdated WebKit and some custom manufacturer spyware added on top.
Just for you, I added a section with rust code.
I've seen [code like this](https://github.com/diesel-rs/diesel/blob/036985ed2c2d2ac1b927f810b89af54d5852826d/diesel/src/sqlite/connection/stmt.rs#L156-L170)
Which is also kind of bad, as now any panic path needs to call finish (which is hard to ensure), otherwise you will immediately get an abort. I feel like Rust should have some type system support for handling this better. (TryDrop or something)
My issue with this pattern is that it doesn't blend very well with e.g. the try! macro. If a function returns early because of some error while using a resource, extra code is necessary to ensure the finalizer is run in that case as well. I have no good solution to this. The closest I got to one was by letting the constructor of the resource accept a function which gets called witht the resource. See the rust-atomicwrites package for how that looks. I wish I knew a better solution though.
That's a really bad idea unless you also want to put in a lot of time and effort to learn all of Rust and learn it well. [Learning Rust With Entirely Too Many Linked Lists](http://cglab.ca/~abeinges/blah/too-many-lists/book/) should illustrate why. Data structures that are easy to implement in other languages are often much harder in rust because of how ownership and the borrow checker, which guarantee memory safety, work.
Super weird to see the domain name crate.io! After having typed crates.io _a lot_ the last 3 years, it looks like a typo 😅 Sorry, will now read your post!
Yeah i think at that point we are just mincing words, especially given the amount of days i provide in the form of benchmarks. But if you give me your data i will do a full analysis and report back. :-) if it winds up with anything interesting, i will try to add it to my blog post and readme!
Is that code attempting to detect if an unwind is already happening and then log to stderr in that case? 
yep
Yes yes....because the free market always helps the users, right? There are not that many companies building phones. There is 0 incentive for them to give users more control.
Your game engine description sounds a bit like three-rs. What did I miss ?
Like I said, I'm not really looking for a solution, just some general thoughts on the topic. How do you feel when the cool thing you create gets "weaponised" by someone else? As an example, the FSF has made it quite clear that, yes, they are aware that GNU software could be used for military applications and for the creation of weapons and that they are, in a sense, OK with that. Their stance on software freedom is absolute. Freedom to use and modify GNU software applies to **everyone**, including militaries and also "evil" organisations. I'm sure if someone of the "inner circle" (as far as Rust even has such a thing) were asked to make an official statement towards my original post they would reply in a similar vein. The prospect of making the various software system that impact our lives daily *safer* and less error prone trumps the rather remote potential of more vendor lock-in.
Thanks! :) Added a note. I'm planning on writing an article on CLI integration tests, but I'll probably need to write a few crates first…
Why do you think the likes of the Google Pixel / Nexus lineup is so strong? Because it gives users more control over their Android phones, in providing a default Android environment, and making it convenient to install custom ROMs.
three-rs fills me with apprehension and uncertainty, for a few reasons. - Seems to fill the prototype/visualization niche, with focus on productivity for prototype-quality programs. This is the same as three.js—you'd never use it for a complex 3d game, because it's optimized for ergonomics and productivity with a runtime penalty. You'll never see anything approaching AAA quality—or even better than solo indie quality—with three.js or three-rs because of this, even if you jumped through significant hoops to try to do so. This is the first stated goal of the library. As such, I'd be hard-pressed to recommend it as a rendering engine - Aspires to mirror the object-oriented nature and API of three.js. This is a neat experiment, but in the end I think forcing a JavaScript/OO API into Rust is just going to cause problems. The author even seems to acknowledge this. - Implements an ECS. I understand it's a good fit for his use-case, but consider this: ECS libraries are the most saturated and competitive slice of Rust game-dev libraries, but every game engine implementation removes that choice from users. If these ECS libraries are so good (some of them really are), users should be able to pair the ECS of their choice with their rendering tech. - More minor, but: Author wrote gfx, three-rs, froggy (the ECS it uses), and probably other crates it uses AFAIK. I have nothing but respect for kvark and his abilities, but I don't want to rely on him for every single layer of my game stack. What if he gets hit by a bus? etc. EDIT: Just to clarify, I don't want the tone of this reply to come across as harsh. Three-rs is a great project that I considered starting myself at some point, but I'm nowhere near dextrous enough with Rust to pull it off. It has a lot of potential for the various use-cases that Three.js are good at, but I don't see a universe where I sell a $30 game using it.
&gt; LineageOS (formerly CyanogenMod) lists all of the well supported devices, That's great. Unfortunately my old phone had the audacity to break right after CyanogenMod had gone down and LineageOS hadn't quite set up all their resources yet. I' sure that added considerably to the time I had to spend on research (and to the anxiety about CM/LOS's uncertain future at that point, I *really* like their work). &gt; There will always be manufacturers making phones with removable batteries Probably, but that market *is* getting smaller. Being able to switch batteries is relatively important to me, personally. I mean, c'mon I was using an S2 in 2017 ;) It was on its 4th or so battery. &gt; This has nothing to do with the topic of discussion I agree, this is veering rather off the original topic, but hey, it's not like we go limited space here. :) Maybe [my answer](https://www.reddit.com/r/rust/comments/6y1emf/can_rust_be_a_threat_to_user_freedom/dmkaw10/) to /u/est31 illuminates a bit better where I'm coming from. 
For some of the work loads shown in these benchmarks, elfmalloc is faster and/or uses less memory than other common allocators, especially in multi-threaded programs.
How would a `TryDrop` be any better than a `finish()`? Dropping is normally done transparently by the compiler, so I can only see two potential ways it could change things to add some form of fallible drop to what Rust already has: 1. Allowing programs to turn the drop into a leak by refusing to drop. (It's not as if Rust has a GC that can come around and try again, after all.) 2. Implementing a form of [linear types](https://gankro.github.io/blah/linear-rust/) by allowing types to disallow implicit drop. I could see #2 being useful, but, so far, I've bundled everything else under the heading of "`kill -9 &lt;PID&gt;` and physically pulling the plug/battery are `Drop` failures that can never be countermanded or compromised on. Plan for them and let that solution handle the other kinds."
Hmm, so it's one additional subtraction and a load from memory. How much such thing matters in practice? Don't allocations suppose to be rare in the first place?
Yeah, it would need to force you to manually handle the dropping or possibly auto early return the Error similar to the question mark operator. Maybe there could be wrappers to say that you just want to unwrap / expect the Result and then you have a normal Drop type again.
OK, then the proper name for what you're asking for is "opt-in linear typing" as far as I understand it. ...and I'm always in favour of more ways to catch mistakes at compile time as long as there are no show-stopping hidden caveats. Proper linear typing would certainly be a stronger alternative to `#[must_use]` for implementing session types which enforce that the program reaches an intended terminal state. (`#[must_use]` being similar, but resulting in a warning rather than an error.)
No, unfortunately allocations are often the hot path of applications. And modern allocators are optimized enough that a few instructions makes a meaningful difference. For example, in the fastest case, our allocator takes ~12 clock cycles to perform an alloc/free pair. That's an unrealistic microbenchmark, but it should give a sense of how much of a difference a couple of instructions could make.
&gt; Shipping the executables to Windows and Mac OS would be the same as for any Qt project. I'm not that familiar with the process as I'm not a C++ dev and I've read of Qt being a pain to build on Windows(Conda devs cited 300 hours getting their first recipe package that built Qt). One of the things I liked about Rust was that getting a .exe was fairly straight forward, I've not had to try ship with something like Qt before. Might be something for docs/wiki in future?
* Don't worry, big corporations are usually slow to use Rust (or take security seriously). It will take a long time until they get it. * You can always become competitor (unless governments stop you via regulations, patents, etc). [Purism](https://puri.sm/) is an interesting example. * Security enhances your freedom because it protects you even from the most powerful entities which take away the largest amount of your freedom: the governments.
&gt; The logo is perfect. I'm happy it's appreciated, thank you :)
&gt; How do you feel when the cool thing you create gets "weaponised" by someone else? Obviously its not great if your product gets used by someone for a bad purpose (whatever you define as "bad"). On one hand, its good if pharma companies deny to sell lethal medication to states with the death penalty still in place. On the other hand, I don't think that manufacturers of technology should retain as much control over it as they do now. E.g. what happens in a possible future where pacemakers are internet connected, and the manufactuer has full control over any of their products remotely. Regardless of whether you as manufacturer think or say you never want to deactivate pacemakers, I don't think you should even have the ability to do so. I mean what if it is revealed that a top terrorist is using a pacemaker created by you? When bad media is printed, depicting you as terrorist supporter because you don't deactivate the pacemaker? When your HQ gets raided by military and you get commanded to give that terrorist a lethal shock remotely? Now pacemakers are an extreme example and it might sound like sci-fi, but I think we are already heading towards such a future for cars, where they can be controlled remotely. This of course might stop car thieves and will probably also mean an end of police chases, because the moment police wants a car to stop they can simply make it stop with a remote command, but it also enables bad actors (hackers, terrorists, CIA) to let people they want dead to be involved in car "accidents" or it even allows mass murder if you gain control over all cars of a given manufacturer. I think its deeply troubling to give manufacturers or the government root/update access over the devices they created, and allowing people to override the firmware with their own is an important first step of stopping that.
Did you try entering a non-number? Try https://play.rust-lang.org/?gist=f952f9e63abf94b9d04a534658cd048e&amp;version=stable If you want to loop until the input is a number, you have to stick the beginning of the `loop` at line 4.
You're gonna have a very bad time once they get to trees and graphs, Rust is great but ownership gets very hard when it comes to these two data structures that are gonna come up in this class
Your code hangs in an endless loop when the parsing fails: loop { let fahrenheit: f32 = match fahrenheit.trim().parse() { Ok(num) =&gt; num, // the continue will jump to the start of the loop and try to parse the same thing again and fail again. Err(_) =&gt; continue, }; ... } You may just want to print an error message and return immediately on error.
That's interesting. I got the impression from Rust's "zero-alloc culture" that allocations are ridiculously slow. Do you have stats on average cases?
Ha beat me to it. I think this is a good use for the while let None = fahrenheit {} type loop Edit: [here](https://play.rust-lang.org/?gist=d429845fd7b532c50414bfd5b0d05ccf&amp;version=stable) is what i mean, unhappy about the unwrap though.
Maybe in the summer you can re-do your old assignments in Rust as a learning experience but Rust - although I love it - will add a lot of mental overhead that you don't need with a full university courseload.
&gt; Now pacemakers are an extreme example and it might sound like sci-fi Not at all: https://www.fda.gov/MedicalDevices/Safety/AlertsandNotices/ucm573669.htm (TL;DR: FDA forced the recall of a pacemaker that allowed *unauthenticated* firmware updates over wifi.) &gt; I think its deeply troubling to give manufacturers or the government root/update access over the devices they created, and allowing people to override the firmware with their own is an important first step of stopping that. Yes, making user control of bought devices mandatory would be a great first step. Rather unlikely unfortunately.
Go uses the `defer` keyword for that purpose. It's a nice way to ensure that something gets done no matter how you go out of scope. It avoids boilerplate-y manual drops and allows you to group initialisation and destruction (A plus in my book, YMMV).
Thank you. Would you mind elaborating a little more on how that is done? I tried to add a println!("") message to the Err(_) =&gt; myself but couldn't get it to work. Honestly I think I'm not quite grasping how best to handle getting an int value from the user input in general as I'm running into issues with this trying to implement the "print n digits of fibonacci" program too. I feel like I'm missing something basic. The only way I've seen this done so far is in the Guessing Game tutorial where it goes: loop { println!("Please input your guess."); let mut guess = String::new(); io::stdin().read_line(&amp;mut guess) .expect("Failed to read line"); let guess: u32 = match guess.trim().parse() { Ok(num) =&gt; num, Err(_) =&gt; continue, }; println!("You guessed: {}", guess); } Maybe I need to keep reading? edit: here is the code I ended up using in my Fibonacci program fn get_num() -&gt; i32 { // gets user input and returns it as i32 let mut num = String::new(); io::stdin().read_line(&amp;mut num) .expect("failed to read input."); let mut num: i32 = num.trim().parse().expect("invalid input"); num }
https://gankro.github.io/blah/linear-rust/
The scopeguard crate gives you this, if you like that.
Data science? Anaconda pls. It's a python distribution including all the data science batteries. 
Not at this time, no. This is really my first journey into emulator development so I'm just enjoying this project for now. I'll see how I feel once I get closer to completing this one :)
Looks like you are reinventing futures, TBH. Compare your should_resume() method to Future::poll(), for example. If you adopted Future's infrastructure, you could express arbitrary resumption conditions without boxing anything.
They're definitely slower than stack allocating, which is next to free. And also, that 12 cycle number is the absolute best case - if you're operating on a cold cache, for example, or if there's high contention across cores, your performance will be considerably worse.
Just throw the sodding thing away. Phone budget = $500/year. No negotiation. They're disposable, perishable items at this point, and cost far less than their utility value.
Great idea! How would you like to wire me the money? I'm sure I can accommodate your preferred payment option.
&gt; Rust combines advancing an iterator and getting actual element value in a single method, next, while D allows repeated access to front at any time. Former is more elegant in a sense that it doesn't require any specific convention of how methods should be called but makes implementing some algorithms a bit awkward if they require checking iterator state from different contexts without advancing it. Check out [`Iterator::peekable`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.peekable). After calling `peekable()`, you get access to `peek()` which is similar to D's `front()`. &gt; One big language feature missing right now seems to be Higher-Kinded Type support to address that streaming iterator problem. There is a library called [`streaming-iterator`](https://docs.rs/streaming-iterator) which provides streaming iterators without higher-kinded types. The `stdin.byLine` example could be implemented using this, and the compiler will guarantee that the caller cannot misuse the borrowed buffer. &gt; bool empty () { return input.empty; } &gt; void popFront () { input.popFront(); } &gt; int front () { return input.front * 2; } ~~This looks like a bug -- `front()` will give you a different value than `popFront()` right? It sort of makes Rust's single method more appealing. ;)~~ &gt; One can define empty to be constant equal to false letting compiler figure out it is an infinite range at compile-time. This is equivalent to always returning `Some(...)` in Rust and should optimize the same.
&gt; makes main Rust selling point much less pointy. Lol. I've hit the same issue with Iterators that you did (no lifetimes). I ended up just writing a while loop that calls next() explicitly, which I agree is inelegant. I don't know if the core team have any plans to fix this; I hope so.
Thanks, I did not know about streaming-iterator. Will check it out.
Interesting. I'm familiar with the idea of futures, but I'm not super clear on how to use them to do what I'm trying to do.
rls is new and suppose to be better but didnt work for me. id suggest u check out both.
&gt; expect(&amp;format!("Couldn't open {:?}", input_path)) But this is bad habit, you allocate and format string always, even if all ok and you do not need it. I suppose `clippy` warns about such code.
&gt;Now, imagine a future where all these OS and firmware components are written in Rust and are largely free of memory bugs. What if consumer-hostile companies use these safety properties to restrict their users even more, and this time without a possibility to break free from the corporate overlords? Security is an arm's race. It always has been. It doesn't matter whether or not you encode your json responses in a GIF, or prevent your software from leaking memory under trivial usage. If someone is determined to fuck you, they will do it. The best you can do is make them work for years, or exhaust all who try. There will always be someone who's willing to do literally whatever it takes, though. Also, Rust provides a marginal improvement over C++ in terms of memory safety. It's not impervious to leaking heap allocated memory, though, and that's just as dangerous as a stack allocated buffer that's been exploited via overflow. 
It is optimizable, yes but: (a) if that is a performance problem, congrats, your app is otherwise disturbingly fast and (b) instead of refactoring it to longer code I'd add a custom error type (trivial with error-chain) :)
Are you even going to use a programming language? My advanced data structures classes were all pen and paper. Many datastructures are made much easier if you have a garbage collector, and much harder if you have a borrow checker. I'd recommend python over rust. If you're a data science student, more python experience is also always a good thing.
(Please recycle, not landfill, your phones)
Does it support QML 2? I'm no expert in Qt but it was on my learning list.
No, especially for a beginner it's difficult to find help with Rust. Generally they will pick the language for you, but if you have a choice I would go with Python, Java, C#, or something similar. In Data Science, you will really mostly work with R or Python, or maybe the rare company with Java/C#/C++/Scala.
Leaking heap allocated memory can lead to out of memory crashes taking your program down, but buffer overflows lead to arbitrary code execution giving full control to the attacker. I'm not entirely sure how those are of equal severity
You might have better luck posting in /r/playrust /r/rust is for the programming language named rust :)
&gt;Leaking heap allocated memory can lead to out of memory crashes taking your program down, but buffer overflows lead to arbitrary code execution giving full control to the attacker. I'm not entirely sure how those are of equal severity /u/isHavvy, what do you think a memory leak represents? Just an invisible demon that does nothing while the program operates? If you think a memory leak is good for only triggering OOM, you're wrong. It's bound to the process, which means it can still be read or written to. If the base memory address returned from malloc is next to an already allocated slab, then it's possible to overflow the region and put your data into the next, already used block. That could go anywhere. In fact it's more dangerous because you're more likely to be able to point your instruction pointer to it without a violation because, guess what, that's not on the stack, which these days is almost always forbidden from having executable privileges.
I don't think there's anything specific to error_chain in this problem. Since you already know the exact behavior you want, the only problem remaining is wrapping it into a nice API. Ad-hoc traits help a lot here. [Take a look.](https://play.rust-lang.org/?gist=312d064fbdaedb511234f0234976e8bf&amp;version=stable) I feel like this is a somewhat generalizable pattern, but then it's 4am so I'm not thinking straight. 
You are correct in that nothing is specific to error-chain. But then again, getting it to work nicely with error-chain -- that is, not breaking the chain and losing any information before this -- is the more difficult part, as you've cleanly illustrated here.
Thanks for your suggestion :)
I have created [an RFC in the futures-await repo](https://github.com/alexcrichton/futures-await/issues/20) for this.
Not sure if there's a better way for one timer, but if you have multiple timers you can spawn a thread, let it sleep for one second, check if there are closures to be executed, sleep again. Depending on the precision you need you might have to run the closures in a different thread. This solution is still a bit messy (you'd have a thread rough-idleing), preferably you would let the thread sleep exactly until a timer is due (this is more difficult to implement though). There might be a way with event loops as well, especially if your program already has one for I/O.
The main "terrible" things about that approach: - it's not persistent, if the computer reboots, or the process has to be restarted, which is a concern for such long running tasks - more than a hundred tasks is going to start having a noticeable impact on memory usage, I think. For few, short lived tasks, that approach is good. For what you're describing, it seems like it would make more sense to have a list of events, each with a target timestamp and some data, sorted by timestamp. As each event occurs, remove it from the front of the list, and hand the data to a standard function, which can then do whatever is appropriate. This data structure could be persisted on disk between events, and loaded at startup, using Serde or whatever. I don't think it's possible to safely persist closures to disk, so that's not what I mean by data. For a non-persistent version, it could be the same as above, but with a timestamp and a closure on each event. But, there are lots of ways to approach this.
Those are good concerns. I think that the idea of something like a BTreeMap holding the timestamp (unix epoch format) and some kind of struct of data would be a good way to keep track of the individual reminders, while being low on memory usage (since BTreeMap auto sorts). As for persistence, this process will stay running pretty much constantly (only going down to update it), so what I could do is periodically check if there's any current reminders every few hours via a repeatedly sleeping thread or something), and write them to disk to be pulled back into memory on startup. (Running them if the process has been down during the time the reminder was supposed to hit) I highly doubt I'll get too many reminders at one point, and I could always limit the max time to something like two days as well, and save the disk from getting written too much. As for running them when they occur, I could check every 1 min or so (low precision needed) to see if the timelapse of the first entry has elapsed, then run the standard function you mentioned, passing and consuming the first tree entry. I'm still looking for suggestions though, so I'll just store this as a possibility. 
[This variant](https://play.rust-lang.org/?gist=a766dd4998ddcd6d3a657f32efb345ad&amp;version=stable) abstracts-away the `map_err(|e| vec![e])`.
I am trying to implement an additional function for `Iterator`s. After some research and experimenting I ended up with this implementation: trait InspectAllIterator&lt;'a, I: 'a&gt;: ExactSizeIterator&lt;Item = &amp;'a I&gt; { fn inspect_all(&amp;mut self) -&gt; &amp;mut Self; } impl&lt;'a, I: Clone + 'a, T: ExactSizeIterator&lt;Item=&amp;'a I&gt;&gt; InspectAllIterator&lt;'a, I&gt; for T { fn inspect_all(&amp;mut self) -&gt; &amp;mut Self { { let orig = self.cloned(); for foo in orig { debug!("foo!"); } } self } } Am I right that this should add the function for all types implementing `ExactSizeIterator` which's `type` implements `Clone`? I can use this function on array iterators without issues: let foo = [1, 2, 3, 4]; let bar = foo.iter().inspect_all().find(|p|true); But trying to use it with [an iterator from a crate](https://docs.rs/vulkano/0.6.1/vulkano/instance/struct.QueueFamiliesIter.html) doesn't work; E.g. `queue_families().inspect_all()` (see [here](https://docs.rs/vulkano/0.6.1/vulkano/instance/struct.PhysicalDevice.html#method.queue_families)) results in an error I can't extract much information from: error[E0599]: no method named `inspect_all` found for type `vulkano::instance::QueueFamiliesIter&lt;'_&gt;` in the current scope --&gt; src\main.rs:130:5 | 130 | .inspect_all() | ^^^^^^^^^^^ | = note: the method `inspect_all` exists but the following trait bounds were not satisfied: `vulkano::instance::QueueFamiliesIter&lt;'_&gt; : InspectAllIterator&lt;_&gt;` = help: items from traits can only be used if the trait is implemented and in scope = note: the following trait defines an item `inspect_all`, perhaps you need to implement it: candidate #1: `InspectAllIterator` `QueueFamiliesIter` definitely implements `ExactSizeIterator`, and the `Item` type in the `Iterator` impl implements `Clone`, so all requirements should be satisfied, or am I wrong? 
The example uses `import QtQuick 2.6`, so yes. 
If the process handles low amount of tasks, use a minutely/hourly cron and check task expiry on every run. Else, maybe tokio can help.
Your feedback has been extremely helpful. I could successfully set the hl_syntax field in the structure. Thanks a lot! 
&gt; Just throw the sodding thing away. Phone budget = $500/year. No negotiation. They're disposable, perishable items at this point, and cost far less than their utility value. *If you're living in US
Conceptually, you are waiting for some event to happen without blocking the current thread. This is exactly what futures were designed for. Your YieldInstruction:: should_resume() serves the same purpose as Future::poll(), except that poll() may optionally return a result. The other two variants of CoroutineCondition may also be expressed as futures. The CoroutineManager is basically an event loop, similar to one found in [tokio_core](https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Core.html).
I asked the same question on the community forum. Here is the discussion https://users.rust-lang.org/t/private-drop-or-rust-could-be-better-at-raii-with-a-rather-small-change/12322 
What I would love is a #[must_consume] lint, which produces a warning if you don't consume its value (e.g. by calling `close(self) -&gt; Result&lt;...&gt;`). I think a warning would be sufficient because all error handling is based on warnings anyway (#[must_use]).
This is great! I'm hoping for the best re inclusion in KDE :) I tried to understand the project and the demo code yesterday though and failed. I'm not really familiar with how Qt works, probably that's the issue. From what I saw, you create a kind of component in Rust with an interface defined in that JSON file and then connect the component to a Qt GUI element through some kind of binding? A tutorial for people not very familiar with Qt would be appreciated very much.
This looks really cool! /r/proceduralgeneration might be interested in this. The purple and dark gray text colors, on a black background, are hard on the eyes.
Drops (as in, the implementation of the `Drop` trait), should not fail. It cannot return a result, and as you mention it shouldn't `panic! ` either. What you can do, however, is provide a separate cleanup method that returns a `Result`. Then, in in `drop()`, you can just call the cleanup method and ignore (not panic) any errors that occur. An example of such behavior is the `TcpSocket`. It has a [shutdown](https://doc.rust-lang.org/std/net/struct.TcpStream.html#method.shutdown) method that returns a `Result`, while the `Drop` implementation closes it without reporting any errors. 
&gt; it shouldn't panic! either. What's the justification for this? Is it unsafe in some way or is it just that unwinding becomes aborting and that's annoying?
I'll write one and add it to the project and blog it. Quick poll: are you more interested in writing Widgets or using Qt Quick? Desktop applications are mostly Widgets, but KDE Plasma has a lot of Qt Quick. Mobile applications are Qt Quick. For now an answer here. Personally, I've mostly written the old style widgets, but Qt Quick is fun too. The demo has three 'styles'. It shows off Qt Quick and Qt Widgets. That's entirely different code. But that application logic underneath is the same Rust code. If you want widgets, read demo/src/main.cpp. If you want Qt Quick, the declarative syntax, look in demo/qml. Quickest way to start is to clone a template from the templates folder. Easiest is templates/qt_quick. The templates use cmake to compile (which calls cargo for the Rust code). For a Qt Quick projects the important parts are the .qml files, the .json file for the data binding and of course rust/src/implementation.rs. You'll need to put rust_qt_binding_generator in a path where cmake can find it. It's quite a few moving bits to get set up. A cargo only way to get going would be a nice way for new developers to get going. And a contribution to the project I would greatly appreciate.
It's the later. Actually, it becomes aborting only if you panic in a drop that was caused by another panic (eg you can't double-panic). It's the same as with C++ and double exception.
&gt; Am I right that this should add the function for all types implementing `ExactSizeIterator` which's `type` implements `Clone`? Almost. It applies to an `ExactSizeIterator` yielding _a reference_ to an `Item` that implements `Clone`. According to [the source](https://docs.rs/vulkano/0.6.1/src/vulkano/instance/instance.rs.html#1063-1066) `QueueFamiliesIter` yields `Item=QueueFamily&lt;'a&gt;`, which is not a reference, so your `impl` does not apply.
Since types are part of namespaces you can create a new `Iterator` trait that supports it.
I just started to build a kind of jump'n'bump game with ggez. And I really enjoy ggez so far! My code (graceless, messy, uncommented) is [here](https://github.com/rap2hpoutre/aknit) and a video is [there](https://imgur.com/sQ8wvS4) I posted it on /r/rust_gamedev too. I would be happy to have a code review! (I already know there are many design errors)
reqwest+select is my choice.
&gt; This looks like a bug -- front() will give you a different value than popFront() right? It sort of makes Rust's single method more appealing. ;) &gt; No, `popFront` doesn't return a value - it has a void return type ;-) 
I know reqwest and select and I used it for webscrap, but how would I use it to send forms and accept/use cookies?
There's no perfect cookie jars, but cookies-rs is quite good. For forms, you just supply data and POST™.
Oh! I see your issue now.
This is the answer to the OP, but without linear types, the second best option is to implement drop and make it always panic to require the user to call finish manually. Maybe we could have a derive macro to annotate types with ExplicitFinish or similar, and a clipper lint for this idiom to detect calls to drop for this types and warn you at compile time.
I suppose these things could yield futures instead of CoroutineCondition. Maybe I'll look into that next weekend.
This is almost definetly a premature optimization but if you only care about the next notification and not necessarily seeing an ordered list of upcoming notifications you could use a BinaryHeap instead. If you do care about having everything sorted, another premature optimization would be to just keep a sorted vector and inserting based on what `.binary_search` gives, since you probably won't be looking up notifications by their time. Again, these are premature optimazations that, from the sounds of it, will definitely not make a difference in your application, but are alternatives none the less
Good call! I somehow assumed the same signature as Rust's `next()`.
I am trying to write a Bash shell using Rust. I've gotten a few parts of the shell down such as built-in commands, and I'm working on redirection. I'm using the Libc crate in order to call functions like open, close, and execvp. Libc documentation found [here](https://doc.rust-lang.org/1.12.0/libc/). My problem is that I don't understand how to use the Libc fucntion execvp, especially the parameters. The documentation has this for execvp: pub unsafe extern fn execvp(c: *const c_char, argv: *const *const c_char) -&gt; c_int I don't understand how to get *const *const c_char. I've managed to fulfill the first parameter by using Struct std::ffi::CString to convert my command, but I have no idea how to get the second parameter. Can anyone help me understand and figure out this problem? Some history: Currently, I'm working on the output redirect. (Still need to work on input redirect). I've successfully got the output redirect to work (Example: cat example.rs &gt; foo.txt), but the program will halt, and I will have to use Ctrl+C to exit my shell. The txt file does get filled though. I believe I still need to call execvp in order to successfully finish the output redirect process. EDIT: My program runs built-in commands, but I have not implemented forking processes yet. I'm still trying to figure that out as well using Libc. 
Thanks for the reply! &gt; Check out Iterator::peekable. After calling peekable(), you get access to peek() which is similar to D's front(). You are of course right that I should have mentioned it (will add!). But I actually use it already - https://gitlab.com/mihails.strasuns/example-iterators-calendar/blob/master/src/split_adaptor.rs#L17 . Problem with `peekable` is that it still advances iterator internally when you `peek`, which means you can no longer pass original iterator as-is unless copy was created. In my experiment I ended up explicitly accepting `Peekable&lt;T&gt;` instead of `Iterator` in downstream functions which works but screws up composition a bit compared to D approach. I definitely need another paragraph about it in the article itself. &gt; There is a library called streaming-iterator which provides streaming iterators without higher-kinded types. I know, reason why it doesn't help much is explained in "Sad Tale of Streaming Iterators" block. Higher-kinded types are needed so that default stdlib iterators, streaming iterators or any custom iterator one may write in app code could still interact with each other and any existing iterator adaptors. As long as one have to reimplement all utilities like `map` for streaming iterators and can't use them in place of standard ones with random 3d party libraries, the problem persists. &gt; This is equivalent to always returning Some(...) in Rust and should optimize the same. I don't think that allows you to, say, issue custom compiler error message when trying to pass infinite iterator into `collect` (which is possible in D). Or am unaware of some Rust feature that allows it?
Rust will make it harder to complete the tasks because you'll have to think a lot harder about them. Rust doesn't save you from dealing with any of the details, it just makes sure you can't accidentally forget about them. You'll learn more by doing the course in rust than just about any other language out there, but that means it will be more difficult. If you have the time I'd do it, if not, a GC'd language will mean you will have less to do.
Woahahaha! So this is what happens when you make stuff and then other cooler peeps build on top of it! Great work. Glad noise-rs could be of use to you! Pretty crazy it's running in a web browser - would never have picked that as a goal initially! Just want to give a shout out to: - [Razaekel](https://github.com/Razaekel) who was the driving force behind the refactor with all the smaller `NoiseFn` structs that makes this application possible, and has done a much better job of keeping things maintained than me - [amaranth](https://github.com/amaranth) who seems to know much more about noise than me and has been a great help in reviewing PRs - [Cifram](https://github.com/Cifram) also did a bunch of tricky work designing OpenSimplex noise.
&gt; Where has this been stated? I've been following Rust for a couple of years, and I've never heard of Cargo only being for dev tools. Same thing here. And while there are some guidelines and tips for publishing libraries to crates.io, there aren't many for how you are supposed to publish Rust applications. Personally, not having much experience in this domain, I must confess I was a bit like "well, this looks like it work, might try it". I think having things a bit more centralized (even only having some guidelines) would help. I'm not necessarily suggesting "yeah another package manager", but e.g. if you have a platform for Rust applications (like crates.io for libraries) I think it would be possible to provide pre-built binaries for existing system (e.g. "you use debian? well, add this to your sources.list and just apt-get install this-cool-rust-app").
Yes I have an easy question. Why is it reccomended that functions have snake case name. I find it more readable thisFunction than this_function.
deleted ^^^^^^^^^^^^^^^^0.5868 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/77255)
Style guidelines are usually opinionated and subjective, that's why they differ so much between languages, companies, projects, etc. (For example, I like snake case better) The advantage of a style guide is that different code bases using the same guide look more uniform and are easier to read once you make yourself familiar with style.
Thanks! *I feel stupid now* 
I'd make a system with two threads. 1. A dispatch thread using a [min-heap](https://github.com/rust-lang/rust/issues/15947) 2. A worker manager thread, this recvs messages from (1), creates a new thread and runs the closure in it. You *might* have multiple of these depending on your scheduling concurrency
I find this rule very weird. I understand the technical problem, but A `panic!` essentially means "_this was not supposed to happen - if it happens it means there is a bug in the code_". So "no `panic!`" means "no bugs" - which is something we should be striving for anyways...
I find it funny that the compiler gave me a style recommendation. 
What we seem to really need is a way of hinting to LLVM not to optimise key sections (on a per-function or even per-block basis) - maybe by using some kind of annotations that are passed through to it via rustc
Agreed, TLS 1.3 is a huge step forward (it is massively simplified, yet also supports superior crypto), supporting TLS 1.2 and especially lower would be intentionally hamstringing the library from the start, and encouraging inferior security
Yes, I think that in a server kind of situation, you'd try to log the problem (if it really isn't fatal to the process), and carry on. The operator is expected to check their logs. In a GUI kind of situation, you could also log, and you'd need something to pick up those logs (e.g. on startup, or from another process) and report the problems to the user, if it's something that the user could do something about. Another possibility is that if the operation being attempted by the drop fails, then the code just puts it on a queue to be handled later. Then that code that handles it later can report errors normally. (The queue could be the normal deferred-execution/timer queue that is executed from the main loop.)
Mostly Widgets. Me and /u/rnestler are trying to sneak Rust code into http://librepcb.org/ :) The setup and build system wasn't a big problem. I saw the templates and could run them. (I had some troubles getting it to run with qtcreator, might be easier with qmake.) The things was more that I did not really understand how the C++ code, the Qt types and the Rust code interact. But that might just be because I'm not really familiar with Qt. (Also a question that popped up: Is it only possible to write self-contained widgets, or is it also possible to interact with other classes in the existing C++ codebase?)
One reason it's integrated into the compiler, rather than just a lint, is that Rust has a pretty unique feature: *some types are actually functions too*. If you define a simple tuple type like this: pub struct PixelWidth(pub usize); Then the word `PixelWidth` behaves as a function let x = PixelWidth(42); // Looks like a function call, right? You can actually use it wherever you'd expect to use a function: let function_pointer = &amp;PixelWidth; // Wait, what? Take a reference to the type name? let y = function_pointer(42); // Constructs a value using the constructor pointer assert_eq!(x, y); // The values are equal In fact, the symbol `PixelWidth` has type `fn(usize) -&gt; PixelWidth`. It isn't just similar to a function, it *is* a function. This means that the name space of functions collides with that of types. This would create madness if the styles weren't enforced. When I read code and see someone call a `CamelCaseNamedThing`, there is no type information I could use to determine if this is a function or a value constructor. The name is the *only way* I can tell, and with camel case I'd expect this to be a constructor. 
`wait` and `await` are too similar, why not rename one?
It helps a lot to give types, functions, and globals different styles. It doesn't matter so much what those are, but trust the compiler's wisdom that they should be distinct.
ELI5 or some good sources on this topic (regardless language if it's more general topic), please. :) (I mean, I read content behind this link and am not sure about what exactly is event loop and how `wait` could block something)
The standard library Mutex needs to propagate panics from one critical section to others that touch the same data. It does that by detecting panics in the drop of MutexGuard and keeping error state in the Mutex. Think about what is possible or no longer possible or no longer safe after a failed deallocation, and propogate the error at those points. If the errors are ignorable, provide a hook and default to log-and-continue behaviour. 
you mean like in javascript. Both constructors and functions are functions but to distinguish them constructors start with a captial letter. 
The reasons for this rule (that you can't have multiple exceptions/panics at the same time) are more technical than conceptual. I don't know much about Rust's internals, but in C++ catching exceptions is done via something similar to a `goto` from the where it's thrown to where it's caught (of course wrapped so that all appropriate destructors are called). Because of this, you can't have two exceptions active at the same time. If they were implemented differently (as a sort of a list or stack), you could have multiples at the same time, but handling would be much slower. I imagine it's the same in Rust, where this limitation comes up even less often, because panics are not the standard error reporting mechanism. Also, a `panic!` doesn't always mean there is a bug in the code. It's either something that is so exceptional that it isn't worth having proper error reporting for it, or an error that we can't really recover from. An example are out-of-memory errors: In C, you can check the return value of `malloc()`. But in C++ or Rust, initializing a vector has no way of reporting an error. Finally, "no panic" definitely doesn't mean "no bugs". You can always have logic bugs. 
If we simply rename, code that currently use `wait` will either break or will not work as expected. `await` returns immediately, while `wait` blocks.
I think that error-chain would happily take pull requests: https://github.com/rust-lang-nursery/error-chain/issues/1
cmake or qmake can both be used i suppose. The build system needs to call rust_qt_binding_generator. The binding.json describes a data model that is shared between the c++ and the rust code. It also generates getters and setters and signals. You can modify the data objects from both rust and c++/qml. Every part of the data model is registered as Q_PROPERTY so QML can see all properties and so can the c++ code.
I think you'll have to refine your idea of "time" a bit. Let's say it's Saturday, 9am and you set a reminder for "in three days" or "in 72 hours". What do you *actually* mean by that? Do you mean "exactly 259200 seconds from when I hit Enter" or do you mean "Tuesday 9am"? What if there is a DST change in between? What if the user crosses time zones while the command is running? Do you now mean "Tuesday 10am" to keep the relative distance, or do you still mean "Tuesday 9am" which is now 255600 from when you hit Enter. What if your target time is a time that doesn't actually exist (i.e. DST skipped hour)? What if you run it on a laptop and at the time the reminder *should* happen it is suspended? There are APIs to get woken by the kernel at the appropriate time, but they are mostly non-portable. [This blog post](https://utcc.utoronto.ca/~cks/space/blog/programming/WallclockSleepDesire) has some info on the subject and even links to a utility "similar" to your idea. Also: Obligatory [Relevant XKCD](https://xkcd.com/1883/) 
What part of loops confuses you? Note there are 2 versions: a `for` loop that can iterate over some iterator (like a range), and the `loop` keyword which is equivalent to `while (true)` in C. I'm not sure what you mean by constant size for functions? you mean that you can't make overloads with different number of arguments? Coming from C++ it's a bit restrictive, but it enables better type inference, so I'm all for it. As for your fibonacci function, it's a little poorly indented, but I think you might find an iterative version simpler than the recursive version: fn nth_fibonacci(n: u32) -&gt; u32 { let mut i = 1; let mut j = 1; for _ in 1..n { let tmp = i + j; i = j; j = tmp; } i } fn main() { println!("{}", nth_fibonacci(5)); } Responding to your edit: Arrays have fixed size because everything is inline, you can allocate them on the stack. This is useful for static buffers etc. If you want something that grows (on the heap), you'll want to use `Vec`. This is equivalent to using bare arrays in C++ versus `vector` It seems you're not only new to rust but also to a bit lower-level programming. I highly recommend reading the [rust book](https://doc.rust-lang.org/book/) and not just jumping in 
Try [Tokio's documentation on tasks](https://tokio.rs/docs/going-deeper-futures/tasks/). In a nutshell:- &gt; am not sure about what exactly is event loop When talking about futures in Rust, we are simply referring to [tokio_core::reactor::Core](https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Core.html) and driving those futures to completion using [Core::run()](https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Core.html#method.run). &gt; how `wait` could block something If you call `wait` on a future, it blocks the thread until that particular future is complete just like what other synchronous code does. If you include it in `async` code then when the future that that async code produces is polled, it won't return until `wait` returns thereby blocking the event loop itself.
This would effectively require await to be a macro, but look like a method (the actual AST rewriting would be done not by macro-rules but a proc macro on the containing function). Seems too confusing IMO. 
The word 'wait' is overused. Why not rename `wait` to `block` or `ablock`? The `wait` keyword could still be there for a transformation period and later be removed.
&gt; then it's possible to overflow the region and put your data into the next, already used block. Yes, and that's called a buffer overflow. Memory lying around, unfreed, doesn't do much on its own. On the other hand, buffer overflows *can* hurt without other vulnerabilities.
poorly indented? You mean badly written as in the code could have been clearer. Or the process by which I solved the problem could have been approached in a better way. I edited my post. I meant arrays instead of functions. And the thing that confused me was when I wrote something like this. while i&lt;5{ i = i + 1; i = i + 1; print!("{}",i); } } It outputs six. But I thought the loop should end once i reaches a value that is greater or equal to 5. Other thing is. When dealing with a for loop it seems to me the only option is this for(let i = 0; i&lt;x; i++) but let's say I want to do this for(let i = 0; i&lt;x; i+=2) How would I do it.
Another problem is implementing this in a macro, given that they don't have access to type information. It would have to *guess* that any method named await is called on a future, which doesn't seem very reliable IMO.
Not really. `await` doesn't need to be a macro. It will be a method returning a generator. Edit: To support the `?` operator we will then simply need to implement `std::ops::Try` for that generator.
Having insecure devices that one can jailbreak vs freedom from being hacked is a false dichotomy and false choice. If people cannot hack their own devices in totality, they will then be forced to use a more free solution, ie buy hardware that is in their control. If you can hack it, someone else can hack it. I'd rather not rely on accidental freedom.
&gt; It outputs six. But I thought the loop should end once i reaches a value that is greater or equal to 5. The loop condition is only checked each time the loop restarts, not after every single line of code inside the loop. So if `i` exceeds 5 inside the loop, it only bails out once it gets to the bottom and re-checks the condition.
I don't think the recursive version is harder to understand, OP's version is just a bit overcomplicated: fn fibonacci(n: u32) -&gt; u32 { if n == 1 || n == 2 { 1 } else { fibonacci(n - 1) + fibonacci(n - 2) } } As for OP (/u/petar02) : you might want to consider using a larger integer type, you'll overflow i8 on `n = 12`. 
See my other comment on the parent... Edit: I clearly didn't understand your comment at first. Thanks for pointing this out!
&gt; but let's say I want to do this for(let i = 0; i&lt;x; i+=2) How would I do it. there is an experimental function on range (in nightly) which allows you to specify a step size, but I would just use loop and break: let i = 0; loop { if !(i &lt; x) { break; } // do stuff that you would normally put in for-loop body i += 2; }
yes, but then you get into efficiency issues (though OP probably doesn't care about those)
I agree: if, for some reason, you need an efficient fibonacci number generator then don't go with the recursive version. Since OP was doing recursion already (and I assume this is just a learning exercise) I just wanted to show a clearer way of achieving the same thing.
&gt; The word 'wait' is overused. Why not rename wait to block or ablock? IMHO, keeping it with whatever name we call it in the futures library does more harm than good. Please see my other arguments in the RFC for removing it entirely. It's not just an issue of confusing names. &gt; The wait keyword could still be there for a transformation period and later be removed. This is exactly what I'm trying to achieve by proposing that we deprecate it first.
Very nice! I bet this would be fun to hook up to the WebAudio API too and generate some soothing auditory noise patterns :).
And what will the Try impl do when the generator yields? 
Poorly indented as in the indentation (basically how much whitespace there is before each line) makes the code hard to read. Here's your code with proper formatting that conforms to the coding style used in most Rust projects: fn main() { let x = nth_fibonachi(5, 0, 1, 0); println!("{}", x); } fn nth_fibonachi(n: i8, b: i8, s: i8, z: i8) -&gt; i8 { // 1 1 2 3 5 8 // x y x y x y println!("{} {} {}", b, s, z); if b == n { z } else { let s = z + s; let b = b + 1; nth_fibonachi(n, b, z, s) } } 
I feel like you may be biting off too much. I did this when I was younger because I thought I was bad ass. Although I may be a bad ass, reducing the free variables and getting the most out of the material has been more productive for me. Learning is not unlike designing experiments, not a lot can be derived from changing to many things at a time.
Just adding some formatting and a helper functions makes things much simpler ([playground link](https://play.rust-lang.org/?gist=03cb971e87db6fef9f6a766beb65e329&amp;version=stable)): fn main() { for x in 0..10 { println!("nth_fibonacci({}) -&gt; {}", x, nth_fibonacci(x)); } } /// Compute the nth item in the fibonacci sequence pub fn nth_fibonacci(n: usize) -&gt; u64 { // Use a helper function to simplify the signature of the main function nth_fibonacci_count_up(n, 0, 1, 0) } /// Compute the nth item in the fibonacci sequence fn nth_fibonacci_count_up(n: usize, b: usize, s: u64, z: u64) -&gt; u64 { println!("n: {} b: {} s: {} z: {}", n, b, s, z); if b == n { z } else { nth_fibonacci_count_up(n, b + 1, z, z + s) } } - For items like the fibonacci sequence, we want to use unsigned types, because we know they will all always be positive. I chose `usize` for the index variable, and `u64` for the counters, so we'll have a reasonably high max value before overflow. - Corrected spelling `fibonachi` → `fibonacci`. - This recursive version isn't prone to combinatorial explosion, which is nice, but it sets the 0th item of the sequence to `0`, which isn't. - For a non-combinatorial non-memoizing fibonacci implementation, the [iterative version](https://www.reddit.com/r/rust/comments/6y7hx9/my_first_day_with_rust_made_an_nth_fibonachi/dml76i0/) is better. 
First of all, I should reply to this: &gt; If I'm writing a library I strongly prefer to pass any and all error conditions up to the application layer where they can be dealt with. You're right, this is what you should do. And the idiomatic Rust way to do this is to try to minimize how much you use `panic!` as much as possible, and try to use `Result` as often as possible. The rule of thumb is: if it could possibly happen during normal execution of your program, use `Result`. Use `panic!` only for things that can only occur as a result of programmer error. But anyway, that doesn't give an answer to your question of &gt; What's the current state of the art for dealing with errors during drop? Panics in Rust are very similar to exceptions in C++ code. They both unwind the stack until the next appropriate `catch` block (in C++) or the next `std::panic::catch_unwind` (in Rust). If there is no such catch block, C++ just terminates the process, and Rust does the same but still unwinds the stack first. During this unwinding, any destructors or drop functions are called of all locals on the stack, and if those throw or panic again, the whole program aborts. There are 2 big differences between Rust panics and C++ exceptions (that I know of), and I think both languages got one right and the other wrong. 1. The first difference, as I already mentioned earlier, is that Rust still unwinds the stack after an "uncaught" panic, but C++ doesn't. I think Rust does the right thing here. 2. The second difference is small but pretty important. Rust aborts the process whenever you `panic!` while in a drop handler during another panic, while C++ only terminates the process if there are 2 exceptions "in flight" at the same time. The difference is that an exception is *not* considered "in flight" during a destructor triggered by that exception. That means that you *can* throw an exception during that destructor without triggering a process abort, as long as you catch that second exception before the destructor ends. The same is [not true in Rust](https://play.rust-lang.org/?gist=ab269311ee8565ca838f6a64551ad61a&amp;version=stable). Whether or not you catch the panic before `drop()` ends doesn't matter: the process aborts. This means that if you want to avoid aborting the process, then instead of wrapping the body of a potentially-panicking `drop()` inside a big `std::panic::catch_unwind`, you have to add an `if std::thread::panicking()` around each `panic!()`, which is not only a lot more work, it might not even be possible if you're calling library code. I do think that C++ does the right thing here, not Rust. In fact I'm considering filing an issue on Github.
Hey - thanks for all your work making this possible as well! I actually am currently relying on a fork for this to work. There's a bug in the Emscripten compiler pipeline where the `mul_add` intrinsic isn't available which caused the library to not compile at first. I made some changes and put in a PR for your library which is open if you wanted to merge those upstream. Anyway, thanks again for the awesome library!
https://github.com/tantivy-search/tantivy
I'm aware of two: https://github.com/tantivy-search/tantivy and https://github.com/pipedown/noise I've also been working on one for a long time (I had a costly false start), but it's at a much lower level of abstraction than any other search engine library I know of. It'll be a while before I'm ready to publish anything.
Do you mean a web browser engine? Servo is kind of that, but it'll be a while before it can be used as a production web browser.
Maybe we should find a way for the compiler to warn you when you call a blocking function from an async one. Some kind of annotation that means "careful I'm a blocking function" that applies transitively to your callers, which the standard library could apply to all it's sources of blocking?
Your argument seems to be that leaking memory is as dangerous as a buffer overflow because it makes buffer overflows more dangerous. But that argument requires that you're susceptible to buffer overflows in the first place. Ultimately, it's the buffer overflow that's dangerous and we don't need to worry about those in safe Rust. As such, your argument has failed to convince me that leaking memory is of equal severity.
Oops! Thanks for pointing out this glaring hole in my logic! You are totally right. Leaving it as `await!()` is better. I will update the RFC to only lobby for deprecating `wait()`. Edit: Done. Thanks once again.