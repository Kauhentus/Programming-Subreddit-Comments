I finished implementing sparse/dense matrix operations in sprs, and now I'm starting to focus more on linear algebra solvers, starting simple with triangular solvers.
No language *needs* an IDE, but they're useful. There's nothing specific to C or C++ that makes them not need an IDE. The level of excellent tooling that Visual Studio+Resharper (C#) or Intellij IDEA (Java) bring have nothing to do with the languages themselves. The verbosity of the languages might make the IDEs' benefits more apparent, however.
What features do those IDE's have that make them so desirable? I'd imagine refactoring tools in those languages are difficult given how incredibly dynamic they are.
While this is strictly speaking true, that transformed version will be identical to the iterative form, just with the iteration replaced with recursion (and TCO will make the two forms have identical machine language code as well)
Think I'll try atom I;ve been hearing about it alot I guess because rust and github are hand in hand at the moment.
I thought the iterative version was actually faster than the closed form.
&gt; Thanks for the discussion! Likewise :) I certainly prefer parser generators, but I understand and accept that lots of intelligent and reasonable folks will disagree with me strongly on that point. There's room for both approaches. You mention Racket and while I haven't used it before, I know of it. It's pretty interesting and I like the direction they're moving in. Borrowing features to make rust into a play ground for new languages would be quite interesting.
Core i7-3667U
This isn't guaranteed to work forever, but at the moment you can do: `wget https://crates.io/api/v1/crates/aleph/0.0.1/download` Loading the same URL in a browser doesn't work (maybe because of `Accept` headers?).
I personally use vim, I havn't really used rust yet though
great to see.. I really must pick rust up again sometime Q1 how will autocomplete interact with type-inference. (i'm thinking specifically of 'dot-autocomplete' where knowing the type of a variable, after pressing 'dot' you get the drop-box of available functions) in C++ etc, the type inference is limited - forward only; however in Rust it often works backwards from the return type specified in the function signature. I guess at worst it could merely behave like C++, there's nothing lost. (Q2: A related tangential question: could rust benefit from something like ```decltype(return)```, i.e. a shorthand for referring to the return type within a function body.) Q3: was there any interest in the 'haskell holes' inspired idea of being able to write a wildcard symbol which the compiler parses into its' AST, and tries to infer types as far as possible, and gives you a list of options in the error message. e.g. you'd write ```let qux=foo._(bar,baz);``` where ```_``` is a wildcard; on trying to compile it, it would tell you any suitable functions that take and return the appropriate types for the '_'. I thought this could be a way of leveraging 2 way type inference for discovery (doing a similar job to 'dot-autocomplete'). It could go much further too, being able to make more sophisticated queries. It could also have been a 'stopgap' giving some of the benefits of an IDE before its' ready. Imagine an IDE that actually leveraged this, spawning a drop-box on each 'wildcard' that you entered, refining the options gradually..
It is arguable that Smalltalk without its IDE is nearly pointless. I can't really imagine programming in it without the browser. Ugh.
Yessss the guy who makes ides go boom favours mine!
Pharo kicks ass, pure and simple. I don't use Smalltalk at work, but I keep a Pharo image on my work machine and fire it up from time to time just to gape at it when it brings up the entire VM with IDE in less than a second. I don't mind Eclipse, Visual Studio, or IntelliJ - but they all have a ways to go IMO. It's a good reminder that the state of the art is still catching up with the original vision. Oh, also, is there anything like Pharo for Lisp that isn't Emacs?
Can you call Sublime an IDE? I always saw it as a text editor with plugins.
kmc's fuzzing tool also found some examples of images that were not being properly decoded, which is more what I was wondering about.
Please avoid subreddit : /r/rust - the inhabitants seem to only talk about some programming language, unlike /r/playrust. Just a heads up to check the subreddit you're in before posting. ;-)
A1: See the videos at https://www.reddit.com/r/rust/comments/3omf33/videos_racer_rustc_typecking/ by the author of Racer (who also posted that thread, so leave comments there if you wish to ask him more questions directly). A2: I'm not sure what this would be useful for. If you have a long and unwieldy type, use a type alias if you want to refer to it in many places. A3: Dunno if anyone has that specific idea in mind, but we do already allow holes e.g. `let x: Vec&lt;_&gt; = foo.iter().collect();`.
Working on an Actor library for a school project (which means that i get school credits for doing rust \o/), it's planned to be highly inspired from akka. I got the basics working last week (having a pool of workers that can send messages to each other) and I am working on having them answer to each other. Since I'm fairly new I had to spend some time reading code from libstd, libcore and the rustonomicon to know how to play with low level rust without being bit to much by the borrow checker.
&gt; take things that are proven to work, build them right This was an explicit design goal of Rust. Don't do actual research. dropck is the only major violation I'm aware of (and it has consequently been a huge source of trouble!).
I think the definition of "small" varies here. For inputs on the order of like 10, I think iteration is fastest. For input on the order of 1,000, the closed form solution is probably fastest. When floating point doesn't suit your purposes, then you should start looking into matrix exponentiation...
I'll love playing with this
There's no way to know if it's going to wait forever or if the first thread will some day release the lock. Maybe the first thread just performs a task that takes a really long time - the second thread can't know this, so it waits.
Use an extra indent of 4 spaces to format a code block on Reddit (or anything using Markdown): use std::thread; use std::sync::{mpsc}; fn main() { let (tx,rx) = mpsc::channel::&lt;i32&gt;(); println!("Starting... "); for _ in 0..10 { let j = rx.recv().unwrap(); println!("{:?}",j ); } println!("before---&gt; "); for i in 0..10 { let tx = tx.clone(); thread::spawn(move ||{ tx.send(i*10); }); } println!("after---&gt; "); } To answer your question, no, the Rust compiler is not able to detect a deadlock situation like this.
Would it be practical to check whether the thread holding the lock is the one trying to reacquire it, i.e. check whether there actually is a "second thread"?
Sort of, it would involve atomics or another mutex otherwise you'd have a potential race condition (what if you check the thread_id but between that time and acquiring the mutex the mutex is reacquired, etc - so you need more synchronizing primitives). There is likely a better solution to what you're trying to do - if you explain it I, or someone else, can probably give you a more standard approach.
I have no idea what I'm doing, but here's a program that evaluates if an integer is odd or not based on whether it compiles: https://play.rust-lang.org/?gist=ff378392b91c41a00619&amp;version=stable Got the starting of some arbitrary boolean algebra in there.
It'd be great if we could find a way to make racer easier to install, perhaps either a brew package (for OS X, .deb for Debian, etc.) or include more of the functionality with rustc itself :-)
This seems like as good of a place as any to leave a link to a little known project way ahead of its time - a live programming environment made by Sun using Self and good JIT compiling. https://web.archive.org/web/20010217143325/http://www.sun.com/research/ics/kansas.html
I only write small experiments with Rust as I am still not "sold" about it. I wrote most of my Rust with Sublime, it has nice integration with both cargo and racer. I've tried a little bit of Visual Studio, it's very very nice but somehow I prefer to keep using cargo because I feel it'll make it more editor independent that committing to a Visual Studio solution. I hope the VS plugins evolves into something that can use cargo (perhaps it already can and I didn't see it?) 
&gt;Oh, also, is there anything like Pharo for Lisp that isn't Emacs? Why not Emacs?
One problem is that Rust's typechecker sometimes runs into non-polynomials when the type bounds are naively specified. /u/paholg found this with his dimensioned library, where types for higher numbers could easily take hours to compile. Even with [typenum](https://github.com/paholg/typenum), which uses a binary encoding and thus should scale logarithmically, we experienced linear build time (to the number types we compiled) unless we were very careful with encoding generic type bounds. Edit: I just wanted to add that this doesn't make Turing completeness go away, but actually *using* it may be impractical unless one is very careful with generic trait bounds.
&gt;Hmm.... Does Haskell have anything like [SPARK](https://en.wikipedia.org/wiki/SPARK_\(programming_language\))? Haskell has Liquid Haskell (http://goto.ucsd.edu/~rjhala/liquid/haskell/blog/about/) which users an SMT solver. &gt; but if you're looking for "most expressive", then you'd likely have to name Lisp or maybe Perl before Haskell. Both of these are dynamically typed languages, so you can't really express *anything* in the type system. We're not taking about the language, just the type system as a formal logic for expressing constraints on your code. Consider: map :: [a] -&gt; (a -&gt; b) -&gt; [b] I don't even have to tell you what this does, even if you don't know the function map by name. And this is only the beginning sum :: Num a =&gt; [a] -&gt; a
It is impossible AFAIK to guarantee deadlock free code when using manual locking. Rust allows this since it is a systems programming language and it doesn't violate memory safety. For higher level (application) code I think one should never use manual locking. Instead use higher level abstractions such as fork-join. 
You can probably do it with a single atomic if you build it from scratch.
.cloned() does this though, but filter would also work.
I want to be using Visual Studio, but the integration isn't ready yet. In the meantime, I'm using Emacs + racer. Works well enough, but I still long for a proper IDE.
Glad to hear that. Looking forward to your release!
Will this actually be sound after impl specialization? The soundness argument for the ST monad version of this relies heavily on parametricity, and impl specialization destroys parametricity (well beyond its current violations). I guess the limit of this technique is that you can't use it to get simultaneous mutable pointers to two indices?
Maybe 'quick analysis' would be a better name? 
In my incremental type analysis prototype rustc seems to deduce 'f' correctly in the following code, so I'm guessing this is a workable solution. fn foo() -&gt; Foo { let f; f }
Rust home is one block away - /r/playrust 
Yeah, I'd love to have something like [infinitest](http://infinitest.github.io/) for my Rust code!
Yep, it's like an embedded MongoDB.
Yes, if you are "only" interested in memory and thread safety, then all the layers *above* the highest "unsafe" layer are automatically verified. Everything unsafe, and everything unsafe relies on functionally, still needs manual verification. Also, as far as I recall, they actually verified that the *assembly* code has certain properties. Getting that result from my work would require a verified Rust compiler, and a connection between that operational semantic and mine.
When the [new](https://github.com/rust-lang/rfcs/blob/master/text/1200-cargo-install.md) cargo [install](https://github.com/rust-lang/cargo/pull/2026) lands, all binary crates will be much easier to install.
&gt; another question what would happen if i were to execute this on playground? would it be blocking the entire infrastructure? Try It and See: http://is.gd/qWQ2AD You'll see `playpen: timeout triggered!` after a few seconds. The playground has a timeout, and runs playpens concurrently, so don't worry: deadlocking there won't bring play.rust-lang.org down :)
[But why?](http://i.imgur.com/4Zrfpe8.gifv) Seriously, is a leading + ever useful in any context? I can think of a lot more cases where it would be an error.
I believe the right keyword is *generative abstraction*, a popular subject of discussion in the ML community. I also believe Scala refers to the same concept as "path-dependent types". `ST` just corresponds to plain-old lifetime checking, I think, with the exception that Haskell doesn't have subtyping relationships for them, so they can only be invariant. I haven't seen it used for other tricks, like this one -- I'm not sure if that's because it wouldn't work, or because they have better options.
https://github.com/rust-lang/rfcs/pull/1210
I've often thought about what a language would look like if it embraced full on meta programming - every function could be an argument passed to a compile time function. It feels to me that C++ is going into territory of lots of meta programming for much more generic libraries, but it is stretching templates to an awkward area. Even things like enums and for loops are syntactic sugar. I think it would be incredible to just accept that this is necessary and make it easy, so thing like static if, variadic templates etc. are no more difficult that anything else. Not to mention situations like a generic vec function that declares things like vec2f, vec3f, vec2i, etc.
Great work. I keep doing a 'git pull' on your repo waiting for something cool to show up :-) I really like the functionality that shows the type. Currently I have to put in a bogus type, compile, and grab the real type from the compiler error. I'm grateful for the work you do on Racer. Thank you. 
*Some* fn pointers can be cloned, closures can't, and because of that `iter.map(fn)` can be cloned but `iter.map(closure)` can't.
Does [this pattern](http://is.gd/UkpyO9) help?
Thanks, I'll try to make those changes. There is an alternate libmad API, which might allow frame-by-frame decoding. 
Yep. This broke [Ares](https://github.com/TyOverby/ares/issues/32) last week. Fortunately we had the tests in place to catch it, and fortunately we don't have any users that would be broken by it. Could have been worse for sure.
I actually suspect that such type systems could be made to work in practical programming... the target would probably have to be lower level than what Rust is good at, though.
There are a lot of licences up on github for some reason people giving them away... I reported it on github but it's fairly prevelent,
You are misusing it :p. Better example: http://is.gd/ShXIoQ Edit: My fault. I didn't explain what it does. The method `borrow_mut` returns a tuple containing references into all fields. You then bind the references you need into variables and use them. No need to borrow again from the original reference.
Why are you using `unsafe` code for such an example? :/ let x: Succ&lt;Succ&lt;Succ&lt;Succ&lt;()&gt;&gt;&gt;&gt; = unimplemented!(); works just as well.
What do you mean? Did you (help) write sublime? Or just a fan?
Oh yeah I just meant the one I use. :D
Sound excellent. Any public description? The L4 people claim wonderful performance relative to microkernels, but comparisons to regular (e.g., Linux) kernel services seem to be apples to oranges. What kind of userspace would one put on top of L4? you mean userspace drivers, allocators schedulers etc, or stuff that would be userspace in Linux as well?
What about interlaced jpegs? Would be kinda funky for piston to support. 
Right, I think I understand the caveats. So program verifiers (human or automated) would not need to reprove the guarantees that rust itself claims, including anything encoded in the type system. Very cool.
I'd love the ability to factor out a closure into a struct that implements the appropriate Fn trait.
The reason this happens is due to the way events are processed: the window has an event queue, which `.events()` pulls from. Update events are pushed onto the queue at regular intervals, but Render events are only pushed onto the queue when the last Render event has been processed. This means that if your update processing takes too long, up to one render event may be waiting in the queue, but any number of update events can be added. This results in the behaviour you see in the video where the frame-rate gradually gets worse until it stalls for a bit, as there are a block of update events with no render events on the queue. Although improving performance will fix it in your case, you would ideally want performance to degrade a bit more gracefully. You can do that several ways: detecting poor performance and reducing the update rate, or capping the number of updates that can happen between a render.
Yeah, but infinitest only runs those tests whose code paths have changed.
`perf` on linux and `Instruments.app` (Time Profiler) on OS X are my top choices.
I'm using vim. It's pretty nice, but I would definitely like better Rust integration than what rust.vim provides!
ObOleg: http://okmij.org/ftp/Computation/lightweight-dependent-typing.html#Branding
There seems to be a lot going on, on a week to week basis! You guys should do what rust-lang/rust does, and add a `relnotes` tag to PRs that are meaningful, and each week, when you release TWiRedox, you should link to the PRs, along with summarizing them.
Is it Posix compliant?
What about letting the user choose whether to accept a leading `+` or not?
The main feature that would need to be added is a way for the type system to express a pointer that borrows only some of the fields of a struct. Adding generics over such pointers would be tricky, because you would have to specify boolean relations between sets of fields.
How much `unsafe` is used? I might look into contributing, but I'd hate to introduce memory bugs in an OS.
**T**om's **O**bvious, **M**inimal **L**anguage. https://github.com/toml-lang/toml
I've been playing with different ways to represent numbers in macros. There's the "N = sequence of N tt's" encoding in this book, which is kind of ugly to operate on (lots of `$()*`) but pretty easy to increment, decrement, add together and even multiply by a constant. I'm also partial to what I call the "Zermelo encoding" (where 0 = (), 1 =(()), 2 = ((())), etc) but it's only practical for incrementing and decrementing (counters, for example!). Also fun is parsing numeric "literals" which can be done as long as you write spaces between the digits (i.e. `parse!(0x 4 2)`). Obviously you have to raise the recursion limit for larger numbers.
Does the file you're reading end with a newline?
To make sure, I removed the file printing in the match: match print_file(suspend_file_path.to_str().unwrap()) { Ok(s) =&gt; println!("{} is SUSPENDED.", user), Err(_) =&gt; println!("{} is not suspended.", user), } Still prints a newline before the suspension notice.
Ahh, I forgot about that. I will do some testing. Thanks for checking this out. nijaedit: That was it! Thanks. I can't believe I didn't notice. I wonder why the suspension reason wasn't printing twice? Hmm.
Beats me!
[removed]
Try grepping for it, last I checked with `git grep 'unsafe' | wc -l` it was quite a few lines excluding the in tree rust std source
What could this be used for?
I'm attempting to learn Rust (finally) by writing a simple AI project I've been stewing on for the last couple of weeks; I have some time to throw it together so I figured it would be as good a project as any to learn Rust on since it's non-trivial and would take advantage of Rust's ridiculous speed (compared to Python, my normal language of choice). Unfortunately I'm getting my ass absolutely handed to me by the type system and I'm about *this* close to giving up the whole thing because it feels like it's not worth my time. Why the hell is the syntax so cryptic and bizarre? Why does the lifetime system even exist? It seems tedious and totally unnecessary except in very, very specific circumstances. The book/compiler error explanations only provide really rudimentary explanations of what's going on, and when I try to apply them to even the simplest example of real world code, I just get more confused. Is there a better resource out there, or am I just doomed to trial and error forever? (Sorry in advance if I offended anyone that worked on either of those resources-they're much more complete than most "new" programming languages I've ever seen ^looking ^at ^you ^Godot ^built ^in ^not-python but the fact remains that I feel like I'm using a dull hand saw to cut through solid steel...)
Pretty much the entire thing is unsafe so far. But it's not clear to me how much actually *has* to be unsafe, it seems to be being applied fairly conservatively.
I should note that I have not made prototypes of the below concepts, so they might be flawed. I was largely envisioning a safer (as in type-safety, not memory-safety sense) version of AnyMap, where you can know, by the type, that what you're looking for is present. For example, Iron's Request type contains a TypeMap that middleware can add to and read from. But if a middleware is added that tries to read, say, a map of Cookies but the cookie middleware hasn't been run first, this will fail at runtime, not compiletime. However, if Request&lt;T&gt; contained an HList of type T instead, this would be a compilation failure. I'm also wondering if this could be used for a type-safe dependency injection mechanism, but I don't think I understand dependency injection well enough to be certain.
You know, you could make an implementation of algebraic effects with this. 
You can always help out in userspace! I'm currently working on ZFS and it has very few unsafe blocks (and the blocks are usually one liners to cast pointer/reference types). EDIT: But in general don't worry about breaking things, the team is chill, and redox is in a very early stage.
Thats what you get when you try to use a plasma cutter as a hand saw ;-P Seriously though, we're all somewhere on this learning curve, and what a steep one it is. Many of us are here to help. Perhaps if you tell us what exactly you are trying to do and where you fail, we can actually do so.
Thanks! I don't really understand your answer, but it points me in a direction to read more. I'd skipped the nomicon, since the intro says that it isn't necessary. But I'm starting to suspect that parts of it are actually pretty essential. Would you say that your change is equivalent to adding an explicitly named lifetime 'b, as below? fn get_yip&lt;'b&gt;(&amp;'b mut self) -&gt; &amp;'b mut Yip&lt;'a&gt; { &amp; mut self.y } I'm beginning to suspect that my understanding of lifetimes is superficial at best. 
I mean, you can multiply by a constant (by taking the counter and repeating it N times). I'm not sure how you would multiply two "variables", except with iteration, but if you raise the recursion limit that high then you blow the actual stack...
Meh, who needs eager evaluation. Continuation passing style all the way!
There are lots of contexts in which a leading '+' is useful. For example if you are parsing exponents in scientific notation (e.g. 6.25e+15).
I try to talk to all my university peers into this, especially for this same reason. My main suggestions for this are writing most of your code in English (sans Comments), shifting some daily tasks from Spanish to English (changing OS language, movies and TV series, reddit!) and joining some learning course. I don't mean you should disregard anything written in Spanish, but rather become acquaintance with English as soon as possible.
Check out [this](https://github.com/aochagavia/rocket/blob/3f96150b3dd3152824ff0974f859d4d54e22cd5e/src/main.rs#L44). ups = updates per second.
Awesome, I figured it'd work but wasn't sure about some details like /u/desiringmachines mentioned. And there's definitely no surprise about it being slower because of the virtual calls, going about things in a round about way like that is certainly more difficult to optimize.
This is so clever! You have no idea how many times I tried to implement some variant of this and I was convinced you could only do it using specialization! Edit: A different thought---it would be great if OIBIT-s supported type params to enable something like: pub trait DoesNotContain&lt;T&gt;: HList {} impl&lt;T&gt; DoesNotContain&lt;T&gt; for .. {} impl&lt;H, T&gt; !DoesNotContain&lt;H&gt; for Cons&lt;H, T&gt; {} pub trait HList: Sized { fn push&lt;N&gt;(self, item: N) -&gt; Cons&lt;N, Self&gt; where Self: DoesNotContain&lt;N&gt; { Cons(item, self) } } 
May I suggest a more ergonomic trait to allow a more `AnyMap`-like interface (i.e. `list.get::&lt;i32&gt;()`): http://is.gd/ENMNSI The gist of it: pub trait Get&lt;I&gt; { fn get&lt;T&gt;(&amp;self) -&gt; &amp;T where Self: Find&lt;T, I&gt; { self.find() } fn get_mut&lt;T&gt;(&amp;mut self) -&gt; &amp;mut T where Self: Find&lt;T, I&gt; { self.find_mut() } } impl&lt;L, I&gt; Get&lt;I&gt; for L where L: HList {} (assuming the `Find` trait is changed to use `find` and `find_mut` as method names)
You should perhaps look at [typenum](https://github.com/paholg/typenum) (we use the type system instead of macros, but the underlying ideas should be transferable).
You *cannot* replace a macro counter with a type counter; by the time you even *get* to the type system, you have to have already finished all your macro expansion.
What exactly do you find unpalatable about defining a type for each merge policy? Alternatively, it seems like you could write a higher-order function. What kinds of invariants do your merge policies have? ~~For example, if the data isn't sorted, then I imagine you'll need quite a bit of memory to implement any merge policy that looks at duplicate keys.~~
What you are looking for is fold(), the book has more details: https://doc.rust-lang.org/stable/book/iterators.html
I don't know why. By the way, to understand the discussion better we need to mention the third type family involved, function items (anonymous function types), which is the type produced by an expression naming a function. It's only a function pointer if cast or coerced. - closures `[closure@&lt;anon&gt;:9:18: 9:28]` - anonymous / unique type - is neither Copy nor Clone - function items `fn(i32) -&gt; i32 {modulename::double}` - anonymous / unique type - is Copy, not Clone(?) - coerces to function pointer - function pointers `fn(i32) -&gt; i32` - is Copy, is sometimes Clone, only as far as non-variadic generics allow
No, I meant using a binary representation instead of what boils down to peano arithmetic.
`FromIterator` builds a collection from an iterator of items, there can be duplicate keys in the iterator because its source could have been anything.
Yup for instance you could be building a dependency map from a list of graph edges (e.g. a `dot` digraph), or a reverse-lookup map (value-&gt;keys, the same value may be mapped from multiple keys in the source), or [a multiset](https://docs.python.org/3/library/collections.html) using a hashmap.
&gt;languages like Go (“C with GC and CSP”) CSP? Also not being super innovative and being cobbled together like a car from mad max was rust'sgoal right? Put all the cool scrapped features together to make a theoretically awesome yet practical lang....
Wouldn't effects be fairly useless without a notion of purity? There's not a lot of point modelling the effects a function has if it can do other things without complaint. [I would /love/ an effects system in Rust, I think it's probably my favourite thing about Idris]
I'm working on improving performance in [Playform](https://github.com/bfops/playform), specifically the amount of time it takes to generate/place a tree. I also moved voxel octree and voxel brush code into the [rust-voxel-data repo](https://github.com/bfops/rust-voxel-data), and voxel-to-mesh code into [the rust-isosurface-extraction repo](https://github.com/bfops/rust-isosurface-extraction). Hopefully somebody else will find those useful, and will be kind enough to let me know where the pain points are when you aren't familiar with the code!
I use Qt Creator for C++, so it wouldn't hurt if I could also use it for Rust development. For Rust, I am currently using Atom, which has a rust-language plugin that provides syntax highlighting, and a racer plugin that provides autocompletion. If your Qt Creator plugin would provide these, it would be a reason for me to use it over Atom. It would also be nice if go to definition and symbol fuzzy search would work, as they do with C++. Maybe even renaming symbols. Of course these would take a lot of work to implement, but these are the main reasons I would use an IDE over a plain text editor. Oh yeah, and it should integrate with Cargo, as it does with CMake for C++. You can just load a CMakeLists.txt, and use it as a project file.
Oh yeah, no-op default collection constructors strike again! This gets me thinking that, actually, if instead of `vec![]` we used `HashSet::new()` (to remove duplicate values), this may be a motivating usecase for [#27243](https://github.com/rust-lang/rust/issues/27243) (and associated PR [28916](https://github.com/rust-lang/rust/pull/28916)) Edit: formatting
Hi, I am currently working on a Rust plugin for Qt Creator. It is not yet usable for any purpose, but the basis is here, with a CI system setup and running. Contact me if you'd like to contribute to this project. https://bitbucket.org/olivren/rustycreator
Have you guys given any thought on what Oxide is going to be like? I ask because I've never found an OS package manager which I've liked but (as a user) I absolutely fell in love with [Julia's](http://docs.julialang.org/en/stable/manual/packages/) which kind of behaves deterministically (in that you tell it what packages you want to use and it ensures that only those packages and their dependents are installed, if you remove a package it also removes any dependents that aren't needed). Edit: Which, thinking about it, is also how Cargo works. Is there any reason this idea hasn't been applied to OS package managers?
Oh, duh. I completely forgot you could access them by index. Every time I've used them I've just pattern matched.
Make your own walled garden of sanity. What is IO a except for some wrapper around Fn() -&gt; a?
Maybe. We firstly need to see how will Ion work. Current idea is to make it PowerShell like which will make coreutils kind of unfitted (but still possible to install and use if one want to). So we will see how it will end.
Right, but even then monads don't *enable* that behavior, they simply make it possible to give it a sane user experience for developers.
 Last week I released https://github.com/arthurprs/metrohash-rs, which is pretty much your best choice for 16byte+ keys hashmap needs. This week I'm updating/releasing by Burst Trie container https://github.com/arthurprs/burst-trie which is a plenty fast ordered container. 
Yes please! Will it support autocomplete?
&gt; Embrace the iterators: :D indeed, even without returning `Result` it already helps a lot in the for loop. Thanks.
I was aware of the RFC, I was not aware of the syntax change (let vs !let) though, I think I prefer the new one.
The source isn't a hashmap, only the destination.
`fold` isn't reusable though. The main thing I'm interested in is reusable building blocks that allow me to build custom collectors without writing the whole thing every time.
You can make it more generic if you want. I personally believe that complex requirements warrant *actually writing code*. I don't want the standard library to become a dumping ground for enabling random people's special cases to be some elegant one-liner.
Something has to hold on to the `String` backing the `&amp;str`. Converting to a `&amp;'static str` would mean a memory leak, anything else would mean use-after-free. What you could do is store the result of `format!()` in the enum itself and return a reference to that.
Looks like you have to choose between returning a static `&amp;'static str` or making your type own a `String` and borrowing a `&amp;str` from it in `description`. It seems, usually it's the `Display` implementation that generates a comprehensive dynamic message and `description` returns a simple static one. See the [io::Error impls](http://doc.rust-lang.org/src/std/io/error.rs.html#277-296).
I'm expressly *not* asking about libstd functionality. A crate on crates.io would be wonderful. I haven't found this functionality, and I'm interested to see if anyone who's run into this has come up with one themselves. Edit: I just looked through a codebase containing around 250 collects, and only a few (&lt; 5 maybe) were incompatible with regular old `collect()`. So the need isn't dire for something like this.
 struct Error { string: String, } impl Error { fn description(&amp;self) -&gt; &amp;str { &amp;self.string } } This is what all the other comments say to use, but I wanted to just write it out as code. It works thanks to ~deref magic~ 
Looks neat, though sadly I'm too busy to contribute at the moment. :) You may also want to try /r/rust_gamedev (or #rust-gamedev on irc.mozilla.org) since that's where a lot of the folks interested in general computer graphics hang out. The gamedev community also has Glium (https://github.com/tomaka/glium/), which is the gold standard for taking an unsafe C API (specifically, OpenGL) and wrapping it in a safe Rust interface.
Thanks :) I will definitely check out Glium. However I find it sometimes hard to understand the choices and the procedure taken by the authors just by examining "finished" code. At the moment I am trying to create bindings from the C headers and it's quite challenging. Maybe I choose an API that is a little complex for a first time. But even if I can't finish it I will have learned something :)
Autocomplete is not my initial focus. I have multiple goals: 1. I want it to be a ready-to-use IDE for Rust. On Windows, you download and run the RustyCreator installer, you open the IDE, you select "new Rust project" and press the "Run" button and it will compile and run a Cargo-based project. You press the "Deploy" button and your library will be published to crate.io. 2. I want to pick the low hanging fruits first, and the biggest pain points I hit when I code in Rust using Qt Creator myself. For now, this means integrating existing syntax highlights configurations for Rust sources and Toml config files. One of the next things will be to parse the output of the compiler. 3. I'd like to integrate with Qt Creator by following its philosophy. For example, I could implement custom Rust build steps easily today, but instead I am investigating how to leverage the concepts that already exist in Qt Creator (the devices, the kits, the compilers, the build tools...). I hope this will allow the plugin to be as featureful as the C++ support (cross compilation, distant debugging for example). In fact, I'm not in a hurry for autocompletion. Racer is nice, but I'd rather wait for the future "compiler oracle", [described in this RFC](https://github.com/rust-lang/rfcs/pull/1317).
Perhaps you could do that with a syntax extension as you can see in this StackOverflow answer (http://stackoverflow.com/questions/32959672/use-a-program-identifier-in-a-syntax-extension/32959840#answer-32972964). You cannot use external identifiers without the `SyntaxContext`, but as you send other parameters to your macro, you can get the `SyntaxContext` from them.
It may be nicer for you while you are writing this code but when someone will read it it will be non-obvious that this macro does something with `context`, `context` may even look like an unused variable.
Because not everything needs to be free, and anyways it's his code, he can do what he wants with it.
I dunno, to me it looks so much neater. But then again I suppose I'm blinded by the fact that I wrote it. 
Fair enough, I'll just have to stop being lazy I suppose. Thanks. 
You could even write a function that takes `HashMap&lt;K, V&gt;` and `(K, V)` and apply it with fold, to keep method chaining ergonomics.
I was just planning to dust off and work on my [side project](https://github.com/kazagistar/okasakish), reading through Okasaki and implementing some persistent data structures. It is still very rudimentary and probably won't be suitable for production any time soon, but, just out of curiosity, which data structures would you find the most useful? I had kinda overlooked singly linked list because of how rudimentary they are, but I certainly need to add them.
Are all instances of the `if let ... { ... }` in a single function? If so, you can define the macro in that function and it will work fine. E.g. fn foo(context: ..., span: Span, ...) { macro_rules! plugin_try { ($action:expr, $span:expr, $msg:expr) =&gt; { ... } } plugin_try!(...) }
Good point, thanks
I think bugs in rustc are marked with things like "easy" and something that indicates someone will help you through it as well. I'd find a bug, go from there.
I'm willing to mentor! https://github.com/rust-lang/rust/issues/21775 should be doable in less than a week. I've [left a comment](https://github.com/rust-lang/rust/issues/21775#issuecomment-148551744) with some info on where to get started. This is something you might be able to figure out yourself without that info too, but it will take longer (feel free to go either way, ping me here or on IRC for more help) https://github.com/rust-lang/rust/issues/19668 is also quite easy. The first part of [this out of tree implementation](https://github.com/Manishearth/rust-clippy/blob/master/src/utils.rs#L282) is what needs to be done. [Code goes here](https://github.com/rust-lang/rust/blob/master/src/librustc/lint/context.rs#L434). Also something you can figure out yourself. Searchable docs for the rustc internals: manishearth.github.io/rust-internals-docs/rustc/ 
Hmm - how come Rust doesn't do it that way?
That's awesome.
`HashMap&lt;String, Box&lt;Command&gt;&gt;`? I don't know how you're registering the commands in Java, but in Rust you'll need to do it explicitly somewhere (no static constructors).
I was thinking of doing something similar, do you have the code hosted somewhere? 
&gt; In practice you often want to access an allocator from caller-provided context Can you elaborate? Are you saying that e.g. if a call to `bar()` would allocate some objects via the default scheme, then you'd want to be able to do `SomeAllocator.run(bar)` and have all of bar's allocations transparently happen according to SomeAllocator's definition?
I don't know what to tell you. The closest thing you can get to Java's dynamic class loading is runtime library loading with [`std::dynamic_lib`](http://doc.rust-lang.org/nightly/std/dynamic_lib/index.html) but I really, *really*, **really** wouldn't recommend it. It requires `unsafe` and nightlies and it's ~~probably going away or changing drastically before long~~ [going to be deprecated](https://github.com/rust-lang/rust/issues/27810#issuecomment-142964003). There's been some attempts to "fix" it (edit: see previously linked Github issue) but I don't foresee having a solid solution for quite a while. Remember that Rust is on *bare metal*, it can't do the kind of dynamic hackiness that the JVM can behind the scenes and get away with it. Subcommand binaries is the safest approach I can think of; you can probably serialize all the data you need so you can pass it via stdio.
Holy crap. I had no idea.
Aha! Nice and easy, thanks :) I suppose I should actually track down some more Piston docs to learn some things like this.
I'll definitely check out caching the draws. That seems like a easy win to improve performance. The verlet integration is [here](https://github.com/mythmon/rust-nbodies/blob/master/src/particle.rs#L50-L57). The relevant code is fn update(&amp;mut self, ctx: &amp;UpdateContext) { let cur_pos = self.pos; self.pos = cur_pos + (cur_pos - self.prev_pos) * ctx.dt / ctx.prev_dt + self.accel * (ctx.dt + ctx.prev_dt) / 2.0 * ctx.dt; self.prev_pos = cur_pos; self.accel = Vec2::zero(); } It is different than yours in two ways that I see. 1. I'm using position based verlet, instead of velocity based. I'm storing the previous and current position, and sort of extrapolating velocity from that. 2. Mine accounts for variable length ticks. I don't understand this part as well, but without it I wasn't getting a consistent orbit. It sort of spirographed around the center instead of creating a stable ellipse. I got the formulas from [from Wikipedia](https://en.wikipedia.org/wiki/Verlet_integration#Non-constant_time_differences).
Perfect thank you! 
&gt; Perhaps a language-supported construct for dynamic binding would be better? IIRC Rust used to have a conditions system (resumable dynamically bound exceptions-like system) which would probably have worked nicely, if it were fast enough (no idea how fast it was): an allocation request would be a conditions signal, and configuring a new context would translate to handling an allocation request, the default behaviour being to handle it via the default allocator. Of course questions arise with respect to closures (do they capture their creation's dynamic context? Can you still override it?)
When you say "iterate over all subclasses of Command in the classpath" I'm not really sure what it is that you want. It sounds like you want the program be able to use new commands without recompilation of the main program just by adding new shared libraries into some directory. If so, you want dynamic loading of code. The support for this in Rust is almost zero for now. You'd probably have to try system-specific things and see how well it works. If dynamic loading is not what you need, I don't see what the problem is. Just create a `HashMap` and populate it with the appropriate commands manually at startup. Rust doesn't have any kind of reflection. Runtime reflection would require runtime metadata and a bigger runtime library. Hardly anyone wants this for a system language. This is something you don't even get if you compile Java code to native code via GCJ, for example. So, you either have to do this by hand or you put some effort into generating this kind of HashMap-populating code at compile-time. Rust offers a macro to include some file's content into an *.rs file. And Cargo lets you run arbitrary Rust code at compile-time to generate things. I did this for computing a [CRC24](https://github.com/sellibitze/crc24-rs) lookup table at compile-time. Ideally, Rust would support *compile-time* reflection to make this easier. But it doesn't.
Sorry for interrupting the thread but I was thinking about looking for a mentor also with the same goals. Is anyone willing to mentoring me? thanks!
Though we do have *one* nomination with *one* vote, I'd appreciate some additional participation. So here's a reminder to nominate and vote. Happy Rusting!
Are you worried that they'll have to have all sorts of bounds in type params e.g. `Find&lt;Foo, I&gt; + Get&lt;I&gt; + Pop&lt;I&gt;` etc? If that's the case, see my playpen example; notice how the function at the top only binds on `Find&lt;&gt;` but uses get in the implementation. If you make `Find` a subtrait of `HList`, then it's enough to bound a type with `Find`, and you'll get `Get` for free: the `Get` bound is inferred automatically (since `forall T, I. T: Find&lt;T, I&gt; -&gt; T: HList -&gt; T: Get&lt;I&gt;`). I think I would rename the `Find` trait to something which suggests that the bound means 'this list contains T'. Then users may find it intuitive to require bounds only on `L: Contains&lt;Foo, I&gt; + Contains&lt;Bar, J&gt;`; then they should automatically get all the other traits `Get`, `Pop` etc. The downside is that they'll still need to `use` all the individual traits. One way to work around this is to have a `hlist::prelude` that you expect users to glob import (`use hlist::prelude::*`). Some libraries (e.g. Iron) do that---it helps with when you have a large no. of traits that you expect users to have in scope.
But it's obfuscation nonetheless. By having the subcommands registered by reflection, there's no way to tell up front what commands are implemented, where their code resides, or what their command string is. You basically just have to `grep` the repo for the command name and hope for the best. While it's admittedly rather clever, in the end it simply just makes it harder to find the information you're looking for as someone working on the project. Personally, if I were a prospective contributor and I saw something this hacky, I'd probably walk away then and there. And honestly, it looks like it requires a lot more code than it would to declare the list of subcommands explicitly.
Clear as mud. You mentioned wanting to do it differently than in Java, not registering commands at runtime, and... that's about it. And from what I can tell, you're still expecting at least a little bit of magic: &gt; They'll all be in the same codebase, this is just to ease development to point that adding a new command is just a case of writing a new command file without having to touch any of the bot's core code. That's not really possible in Rust. Somewhere in the bot has to be some code where all the subcommands are declared and dispatched upon. [I gave that exact solution to you in an earlier response](https://www.reddit.com/r/rust/comments/3oxk7n/help_a_java_user_figure_out_rust_abstraction_ad/cw1lq09) and you seem to have glossed over it. That gave me the impression that that wasn't what you wanted.
That's *one kind* of abstraction: runtime polymorphism. Yes, Rust supports that. It's one mode of how traits can be used. You could write something like this: use std::collections::HashMap; trait Command { fn exec(&amp;self, args: &amp;[&amp;str]); } struct Foo; impl Command for Foo { fn exec(&amp;self, args: &amp;[&amp;str]) { println!("command foo with args: {:?}", args); } } fn main() { let map = { let mut tmp: HashMap&lt;String,Box&lt;Command&gt;&gt; = HashMap::new(); tmp.insert("foo".into(), Box::new(Foo) as Box&lt;Command&gt;); tmp }; // within some message loop you do let userinput: String = "foo this that".into(); let parts: Vec&lt;_&gt; = userinput.split(' ').collect(); if parts.len() &gt; 0 { let command = parts[0]; let args = &amp;parts[1..]; match map.get(command) { None =&gt; println!("Sorry, I don't know a command \"{}\"", command), Some(cmd) =&gt; cmd.exec(&amp;args) } } } It might make sense to define a second trait for the "command host" so that commands can "call back": trait CommandHost { fn send_message(&amp;mut self, msg: String); ... } trait Command { fn exec(&amp;self, args: &amp;[&amp;str], callback: &amp;mut CommandHost); } (or something like this) So, basically, a trait works like an "unsized type". Dealing with "unsized types" requires indirection (some kind of box or reference).
TL;DR; it is possible to develop like in Rust like you do in Java; the likely project structure: command_dispatcher - requires nothing; is abstraction command_x - requires command_dispatcher - implements command x main: - requires command_dispatcher - requires command_x - loads config and forwards input to command_dispatcher The approach I would suggest is this: Have some kind of `command_dispatcher` module (or crate), that contains dispatch abstractions such as `Dispatcher` and `RunCommand`. You will want to use `RunCommand` as an interface in Java, that means making it a [`Trait Object`](http://doc.rust-lang.org/nightly/book/trait-objects.html). In rust, traits become `TraitObjects` (you can call methods on interface without knowing concrete implementation) when they are referenced over some pointer: borrow &amp; or Box&lt;&gt;. Note however, that Trait Objects have many downsides in Rust, the most important one is that they can't use generics the same way. Put command implementation(s) in second module (or crate), which uses `command_dispatcher` and implements Concrete `RunCommand`. Your `RunCommand` will most likely have a method to determine if it is the one you should run for some string input. The third module (or crate), whould be the `main`. It will be responsible for: - Importing all dependencies. - Loading the config. - Creating the dispatcher and putting "available" commands based on config. - Redirecting user's input to dispatcher. Here we go, we took care of dependencies the way you wanted. However, out "main" has to know about all the things, but same thing is true with similar approach in Java. The difference is, you have to put things that exists in some kind of list, while you do it in java by putting them in namespace.
This is exactly what Jai is supposed to do: https://www.youtube.com/watch?v=ciGQCP6HgqI (dives right into allocators)
I'll have to look at Redox documentation because I don't understand your comment: files come with an API (open, close, etc), URLs don't have an API, so I don't understand what you mean by 'we are using URLs instead of files'.
There is an example available now: https://github.com/cyderize/rust-websocket/blob/1fab3a438a5f11e97760acddfcfd8c9504094987/examples/hyper.rs
Well, I've been working on my [allocators](https://crates.io/crates/allocators) crate, since before I saw the talk. I liked the idea of composable allocators so I rigged up a few primitives last night (that are very rough around the edges). Before that, I was just going to implement a few different memory allocators that people could mix and match, but composability seems pretty convenient as well.
[Stable `AsRef`](http://doc.rust-lang.org/std/convert/trait.AsRef.html): no implementation for `Box`. [Nightly `AsRef`](http://doc.rust-lang.org/nightly/std/convert/trait.AsRef.html): implementation for `Box`. [The PR in question](https://github.com/rust-lang/rust/pull/28811). It's a breaking change, but appears to have been deemed insufficiently breaking in practice.
You might be interested in: https://github.com/PistonDevelopers/hematite
About the silly questions stuff, both Stack Overflow (with a `rust` tag) and #rust on irc.mozilla.org are excellent!
Awesome, can't wait.
I really like where Octavo is going, but can we, as a community, in good conscious point users to a cypto crate that is so immature?
[removed]
I have looked into game programming before but rust has still a lack of libraries. Most are either too low level, too general while sacrificing performance or have a weird and overly safe interface, that makes them nearly unusable. Of course it needs new libraries but you either want to contribute own libraries or get your project done. Trying both doesn't work. Rust is often verbose in comparison to C++. You often need to find workarounds to satisfy the borrow checker, add lifetime parameters, put the Objects in RefCell and then access these. All things that you don't need to do in C++. When I switched from C++ to Rust the security felt a bit exaggerated by wasting too much time for writing and gaining very little usable for everything except web-related stuff (I think different now). When you go deeper into rust you will notice other features that are helpfull for games: * Enums provide an easy, beautiful and actually faster way of polymorphism than inheritance although they sometimes lack useful features. * In C++ libraries are just for special features or algorithms but rarely for datastructures and common algorithms. I would never pull in a library just for a new iterator adaptor because writing you own is often easier to understand and debug. Rust has better generics and cargo makes adding and updating dependencies easy. The required properties of the types are not just in templates and documentation (haha) but guaranteed and checked by the compiler. The safety rules ensure that you don't accidentally end up with undefined behavor (oh, it returned a null pointer). So instead of writing more code to satisfy the borrow checker you write less code because you can use more libraries for simpler tasks. Libraries are used by many projects and so gain more quality and stability over time and finally you can write your own libraries and don't need to write similar code twice. For the functional programming: Many people here write very little rust code in a functional style but you can often use fp if you like. For example I prefer `.filter` over a for loop with inner if and I often use chains of `and_then` and `or_else` where many other programmers use if-let and match.
I'm currently playing around with Rust on an ARM Cortex-M3 microcontroller (Atmel SAM3X8E on an Arduino Due board). It's working pretty well. If you're interested in details, I've been writing about pretty much everything I did and learned so far: http://embedded.hannobraun.de/ Edit: Here's a direct link to my code: https://github.com/hannobraun/embedded
Took a quick look at this, looks good. Now I don't have to collect it, I will use that.
In the last slide it mentions Rust.
I think I can TL;DR this from the Rust perspective. Ben is implementing push notifications for the web, the backend for which requires maintaining many millions of concurrent connections. In this scenario, memory usage per connection = $, so reducing memory usage is the most important concern. Somewhat surprisingly, Go, despite being such a great server language, does not offer seem to offer significant advantages over Python when it comes to predicting and controlling memory usage (at least in this case). The last slide is suggesting that the next revision of the Mozilla web push implementation could move to Rust since it gives great control over how memory is used. If and when this happens it will be a huge proof of Rust's maturity since Mozilla will be deploying many, many web push servers that must be completely reliable. This story is similar to others we've heard from companies investigating Rust: if you want precise control over how your software utilizes its computing resources, and you want to be confident in its reliability, Rust is *the* option. 
Not directly related: I'm the owner of the crate `telegram-bot`. I'd like to know your experience with it... if anything is annoying, confusing or anything just tell me. Thanks! :) 
https://wiki.haskell.org/Mutable_variable
Not every strategy can, in fact, be expressed this way. Namely, some strategies require a finisher in addition to an accumulator. Consider, for instance, `HashMap&lt;K, Vec&lt;V&gt;&gt;` where vec is sorted.
I don't think Rust threads would perform better. The comparison here I think is between Go coroutines, Python twisted, and Rust mio. Certainly for this use case, they would go straight to mio since they want the most efficient thing possible.
I [added documentation recently](http://doc.rust-lang.org/nightly/book/custom-allocators.html) for the compiler's support for custom allocators, and hopefully it'll help answer your scenarios!
That's the triple that I used. I did this on a Debian armv7 image for it, not sure if it works on raspbian. I had to get a cross compilation setup working with rust on my x86_64 box to be able to get cargo going since cargo seems to require cargo to build and didn't have an arm version it could find to use to start. It does take a few hours and more ram than the rpi2 has to build a release version of the compiler rather than debug so I had to add some swap. I can upload the binaries somewhere if you'd like since getting a complete cross compiling environment took a bit to get all the libraries for cargo. The biggest thing to watch out for was that cargo will build without ssl support if you missed the openssl libraries for curl-rs. Without ssl support however it will claim it doesn't support http instead of https. I should make a blog post about this to help people out... Getting std to work wasn't hard at all, ran into no issues getting that compiled directly on the pi2
I want to get some preliminary things squared before I start looking at specific issues. I'm wondering: * What is the best way for me to contact you with questions? You mention IRC, what is your handle on IRC and which server(s) are you on? I currently only use freenode, but if you're only on the mozilla IRC then I could join that to. * Is it okay if I contact you by email? * Are there certain mailing lists (or other information channels) I should subscribe to to communicate with the rustc team? * Is there any getting started guides I should be reading. Like a new developer guide for rustc? Coding standards, pull request styles, commit log style, things to know about branches, etc? Thanks!
Yea I can understand that it'd take more to support that in the end. I did it largely because I plan on using the rpi specific libraries and don't expect a good experience trying to use them in a cross compiler, mostly from.c cross compiling experiences
Yep! Not caring about safety sure is convenient!
I'm on both Mozilla and freenode, with the same username. Online 24/7, but of course I'm not awake or available all of that time (only way to find out is by pinging me, I don't have any set times for being around) You *can* contact me by email if you wish but I'd prefer we discuss these things in public, in a channel like #rust-internals on Mozilla IRC. That way others can help or benefit from the discussion. We don't have a commit log style, and coding standards get enforced by `make tidy` (reports style issues, but you have to fix them yourself). Do what you want with git, try to maintain a clean commit history (no merges, etc). http://www.ncameron.org/rust.html is the closest we have to a new developer guide. 
The pain points of the old proposal are well-understood. Any RFC to reintroduce `become` would almost certainly make it a compiler error to use it in a function where local variables have destructors; this could later be relaxed backwards-compatibly if demand calls for it.
But, why can't the local variables that would be dropped, be destroyed just before the `become`?
Hello. I'm sorry if we've given you the impression that we were asking to do all our research for us. It's a bit difficult expressing what we really are asking for because we're not 100% sure too. It's a new class and we are a bit lost... We will try to be more detailed in our question, but please keep in mind that we are reading every information that is given to us and trying to find out more about Rust everyday. We just really don't know what we are looking for and it makes it a little bit difficult to do the work. I will try to explain better, for instance if you have a calculator the use case will be the buttons for adding, subtracting, dividing and multiplying, so for Rust what are the main points that the creators are more interested in developing. Our project is not about the coding part but about the contributing and all the stuff around it. Rust is a product like any other for us. :)
Certainly! Just having `extern crate alloc_system` should be enough to force usage of the system allocator.
You could try, but you'd need to be very careful with lifetimes to avoid fn print_more(msg: &amp;str) { let longer_msg: String = format!("{}*", msg); become print_more(&amp;longer_msg); // whoops, use-after-free }
`f64` is like `double` from other languages (64 bits floats), and `f32` is like `float`. You use `f32` if you need extra performance and can trade away some precision (eg: if you are writing a game), otherwise use `f64`. `u8` are unsigned bytes (8 bits, 0 to 255), `u16` are 16 bits, etc. `i8` are signed bytes (-128 to 127), etc. The default integer type is `i32`. `isize` is an integer large enough to address the whole address space (it's 64 bits in 64 bits machines and 32 bits in 32 bits machines), but it should be used only if you need an integer to index a vector or some other memory operation. You should not default to `isize` for performance reasons: even on 64 bits machines, `i32` may be faster because it takes less cache space. Additionally, relying on `isize` to store user data may make an application non portable between 32bits and 64bits processors.
I prefer `to_owned()`. My rationale is that `into()` might require extra work for the type inference machinery (and therefore, less clear error messages) and until specialization lands, `to_string()` is less efficient. I'm not sure if those are good reasons. On the other hand, `to_string()` is actually clearer to the reader. (or is it?) Converting `a : String` to `&amp;str` is easy, just type `&amp;a`. The caveat is that you may get bitten by the borrow checker when you try to use your `a` again etc (but then, learning Rust is basically learning to please the borrowck)
It's really a byproduct of strings being so useful. It's three or four different interfaces that are all applicable for different reasons...
jemalloc is a much, much better allocator than the system default, which is why it's bundled. Unless you have an actual reason to need low memory, and can't dynamically link (which will reduce your binary size to a few kilobytes, by the way--I suggest you do that before you change the allocator), I highly recommend not switching it. I certainly don't think it shouldn't be the default. jemalloc also supports features like sized deallocation which aren't by main malloc.
Why is `to_string` clearer to the reader? There's no type being formatted here, there's just `&amp;str` going to its owned form.
I'm pretty sure jemalloc has runtime arguments that will ask it to acquire less memory upfront.
Yeah there's also this point. But I don't think `to_string()` is just about string formatting, it's more about converting a type to `String`. The `&amp;str` implementation should be equal to `to_owned()` if we had trait specialization, the reason we implement it through formatting is because we have a blanket implementation for `T : Display + ?Sized`. I think that since `to_string()` returns a concrete type, it may generate clearer error messages. But `to_owned()` is nice too, I like the concept.
So functions called with `become` can only accept moved/copied arguments?
Or entirely new values, but not something borrowed from the locals of the caller, otherwise the drop semantics get too complicated. Or perhaps I'm not understanding this very much (feel free to correct me).
Would you mind expanding on what those 3-4 interfaces are?
You absolutely could. But that's a potentially surprising bit of semantics and we'd need to make sure it's done soundly (destructors today are already probably the shakiest part of Rust's soundness). In contrast, forbidding destructors entirely entails fewer risks and doesn't preclude us from implementing a drop-before-become scheme in the future.
&gt; Somewhat surprisingly, Go, despite being such a great server language, does not offer seem to offer significant advantages over Python when it comes to predicting and controlling memory usage (at least in this case). To expand a bit, I think this is due to the different approaches to concurrency. When a Python coroutine is 'descheduled' (i.e. yields) it only needs to store the local variables, which is maybe a few tens or hundreds of bytes. A Go green-thread has a stack that needs to hang around even when it is descheduled/yields, which is a minimum of 2 KB (previously 8 KB). Hence, the Go threads keep around more memory than they need to. (The problem with Go is a problem that afflicted Rust's old green threading runtime too; another reason it wasn't an awesome solution to this sort of problem.) I believe the mio approach is to basically write a Python coroutine manually: any values that need to be preserved across a 'yield' should be stored in the thing that implements `Handler`, and this is all the state stored for a coroutine that's not running.
* `.into()`/`from()`: generic trait for converting something into another thing * `.to_owned()`: generic trait for converting a borrowed value into its corresponding owned value * `.to_string()`: converting something into a string I think there's another one or two but those are the big ones off the top of my head.
Yep, that's the plan.
* `String::from_str` * `format!` * `.chars().collect()`
Perhaps we should have a section on this in the string docs page?
Couldn't we have some sort of plugin that converts from a function that `yield(_)`s to the corresponding state machine?
(All modern hardware uses mutation under the hood, so even the purest functional languages end up changing bytes in memory at some point, but I guess you're not talking about this level.) &gt; A huge draw of affine typing is that it permits principled mutability, though I don't think Rust went down that path. Could you expand on what you're meaning by principled mutability?
That would depend on both the system and workload. Also it's not only about binary size, but memory profile. Edit: That said, I don't argue that jemalloc wasn't a good default – I suggest everyone do the measurements to find out if it's good for their workloads.
This is great! I love getting feedback of this nature, especially because I think Rust has a promising future role in programming education.
`cargo edit` was [already submitted](https://www.reddit.com/r/rust/comments/3obsmu/cargo_subcommands_cargo_add_cargo_list/) a couple of days ago, but it just gained the ability to add the latest version of a crate, without you having to look it up, and I thought that was worthy of resubmission. With the [recent prohibition of wildcard dependencies on crates.io](https://github.com/rust-lang/rfcs/pull/1241), it has become more important than ever to use precise SemVer bounds, and `cargo add` helps with just that: instead of having to look up the latest version of a crate then add it manually to your Cargo.toml, you can just run `cargo add &lt;crate&gt;`. Even easier than adding "*", and much nicer on your users, who won't have to figure out why your crate breaks without them changing anything! Note this isn't a native cargo command, but a utility that has to be installed: https://github.com/killercup/cargo-edit#installation
Nice! I was actually just thinking of doing something similar. I'd be interested to know what's the performance impact of doing this instead of the character-based machines.
This is an awesome feature. Does it add "X.X.X" or "^X.X.X" or something else by default? (for versions &gt;= 1, the caret version is the best dependency, assuming they follow semver correctly).
No, you're right. At least, I think. Maybe new values count as moved in a call context. I'm making this up right along with you. :)
This is great! I have a python project that I want to migrate to rust and I use a lot of Jinja2 there (twig and Jinja2 have almost identical syntax). I also found [jinja2-c](https://github.com/jroweboy/jinja2-c) but seems unmaintained. 
I don't necessarily mind changes like this, but a heads-up about breaking ones would be nice (or a website where one can get notified in case they happen). Things just randomly breaking on CI that worked the day before is a bit disheartening. I know one can do it by reading RFCs, but that's quite a bit of a time investment for one very specific purpose.
Well, actually, the whole *point* of `become` is to run the destructors early, before the call (which is backwards incompatible due to resulting borrow restrictions).
Awesome!
You should not put the DLL into the build output directory in the project. Have it somewhere else like the project root or a dedicated folder. MSBuild will copy it to the build output directory by default. Otherwise, this is mostly identical to using any native DLL from .NET. One should also set the calling convention in the DllImport attribute to Cdecl, because the default is Winapi aka Stdcall, which may result in stack imbalances if you call a Cdecl function using Stdcall.
There is https://killercup.github.io/bitrust/ if that helps (the PR in question is unfortunately not there because the breaking-change tag had been omitted). I can’t quite agree with „random“ breakage. Even though you’re working on nightly, this breakage must have happened after you updated the nightly version on your CI. If you don’t pin the version things like this will keep happening.
Thanks for posting this again, /u/filsmick! Also, I want to thank you and all the other who have contributed since I posted this last week! I have, for example, merged a PR for the completely new subcommand `cargo rm` as well as bugfixes for it -- from two people completely new to the project. :) tl;dr you guys rock
I saw that site, but as you said this PR wasn't mentioned at all, which gives me some pause. It is random breakage, because the code is written to compile on stable, so it's a reasonable assumption that it will continue to compile on the 1.x nightlies.
&gt; who would actually read papers Not all of them did, but some. They were between 2nd and 6th bachelor semester; most of them just CS, some with focus on math, some cognitive science. And I guess they didn't read the whole paper, but knowing, that there is an interesting paper with in-depth information, is a nice feeling ;)
Glad to hear that my stuff is useful for someone :) Is anything you're working on public? I'd love to take a look.
It seems like `string` is a regular C string. But I'm not sure, there doesn't seem to be much online about C# ffi. https://github.com/zsiciarz/rust-ffi-stringtools/blob/master/c_sharp/main.cs
Just for those who don't know about it, there's also the [Rust FFI Omnibus](http://jakegoulding.com/rust-ffi-omnibus/) that contains examples for several different FFI scenarios. That said, we can *always* use more FFI examples, particularly ones involving messy things like strings and arrays. I just went through to check, and ~~are you~~ is the author sure the C# one is right? I mean, ~~you're~~ they're not encoding the string as UTF-8. IIRC, it'll try to pass it as UTF-16, which is obviously going to explode violently. I don't know enough about the other languages to comment.
Isn't it what re2 does? re2's author reports: "Compiling out the UTF-8 makes the compiler a little more complicated but makes the matching engines much faster: they can process one byte at a time in tight loops." ( https://swtch.com/~rsc/regexp/regexp3.html#step3)
`String::from_str` does happen to be deprecated, although `String::from` pretty much took its place.
Hi. The borrow checker does indeed mystify me. I've read a few things about it, but rust-lang.org is limited, and doesn't seem to explain constructions that I see in similar questions. Anyway. My 'hello world' project is a recursive descent expression parser. It starts with a string str, which is then converted to str.trim().chars().peekable(). That seems to give me an iterator where I can look ahead one character. I could manage to convert a string of digits to a number, but this piece of code, which is very similar in the way it uses the iterator, stumps me: let rt1 = term(str); match rt1 { Ok(t1) =&gt; match str.peek() { Some(&amp;')') =&gt; rt1, Some(&amp;'+') =&gt; { let xxx = str.next(); let rt2 = term(str); match rt2 { Ok(t2) =&gt; Ok(t1 + t2), Err(_) =&gt; rt2 } }, term() returns the result from parsing str up until the current point, so then the program wants to check what's next. If it's a right parenthesis, it should just return the result. If it's a '+', it should skip the + and parse the next part of the string. At the point where it says let xxx = str.next();, the compiler tells me "cannot borrow `*str` as mutable more than once at a time", and I can't understand why. I can solve the problem by changing the algorithm a bit, but I would prefer to understand what's going on. Why can't I use the iterator at that point, while in the number parser it is allowed? let mut value: f64 = char_to_digit(ch); loop { match str.peek() { Some(&amp;'0'...'9') =&gt; value = 10.0 * value + char_to_digit(str.next().unwrap()), _ =&gt; break } }; 
Does anybody know if I can crosscompile from OSX to a Linux ARM Raspberry Pi? I'm currently doing it from linux, but I would prefer to do it from OSX.
Yeah, I checked the C# one (do a lot of C# at my day job) and was a bit concerned by this. Unfortunately marshaling UTF8 (both directions) in C# isn't all that easy. C# generally has a rather clean FFI if you're targeting just UTF16 or ASCII.
I guess I always assumed that byte based would be faster, because UTF-8 decoding becomes part of the matching machine as opposed to this separate step you have to call. I certainly assumed it was necessary for a memory conscious and efficient DFA implementation (but I could be wrong about that). However, it is necessary if you want to build automatons that search other automatons. In that case, you're not searching text, which means you can't just stop and say "decode this region of text."
Yes, this implementation is based on the one in RE2's compiler, which in turn I think is based on the one in Ken Thompson's `grep` (according to Cox).
Is there any plan to integrate `cargo edit` in the official `cargo`?
Yes, but that doesn't mean the allocator itself is composable. To get maximum performance, you often want to be able to do things like align core-local allocation buffers at well-known points in the address space, which you can't do if you don't have access to the entire address space.
There are remarkably few real workloads where jemalloc will be worse than the system allocator. I don't think it's necessary to ask people to test every single aspect of their configuration, especially something as subtle as allocator performance in microbenchmarks (for instance, jemalloc is pretty good about actually *releasing* memory when it's done with it, which benefits other programs on a user's computer but won't help it win microbenchmarks). If you think the allocator is a problem, sure, test other options. But it's one of the last places I'd look.
Not that I know of. Should be possible, though.
Right now it is [here](https://github.com/gamazeps/RobotS) but it's still a rough draft (most/all of the updates are on the dev branch for now).
For most of the benchmarksgame workloads, the allocator is obviously not the bottleneck, but jemalloc takes a 6MB allocation upfront, which makes Rust look rather memory-hungry in direct comparison. Thus my interest in the comparison. I haven't actually done the measurements yet, so I won't argue which one is better.
Yes: http://doc.crates.io/crates-io.html#using-cratesio-based-crates &gt; **Caret requirements** allow SemVer compatible updates to a specified version. &gt; [...] &gt; If no operator is specified, this is the default requirement (e.g. `1.3` is the same as `^1.3`).
Is adding `foo = "*"` in a file much faster than `cargo add foo` in a terminal?
There are some shell packages. Not sure those might work for what you want. Personally I hope jet brains picks up a rust ide :D.
It is the best way. That's why I added `CString::{into_ptr,from_ptr}`, as it was missing. Just needs to filter out to stable. You could also allocate memory space in the FFI side and write to it in Rust side, but it's a pain. 
These examples use `CStr::from_ptr`. It doesn't care how the memory was allocated and doesn't free it. `Box` and `CString` (that is just a `Box&lt;[u8]&gt;`) have `from_raw` and `into_raw` and you must use them together. Before stabilization `CString`'s functions were called `from_ptr` and `into_ptr` potentially causing some confusion but now they're consistent with `Box`.
I had similar observations, but the state machine generation code *still* needs a lot of compilery things even to get if/loop/for working. And yeah, the type issue is also there. I think this would be much easier as a rustc patch.
Typically vacuous modern Slashdot discourse. So sad.
When you do `for var in collection`, you call `IntoIterator::into_iter` on that collection, which calls [this implementation](https://github.com/BurntSushi/walkdir/blob/master/src/lib.rs#L289), consuming the struct. You'll need to clone it first to be able to use it after iterating through it, or just make a new one.
What is the problem you're trying to solve? Specifically, what are you trying to do by printing `homedir` (which is an iterator)?
You want non-consuming iterator probably: for entry in &amp;homedir { This is equivalent to (borrows value for iteration): for entry in homedir.iter() { What you had was equivalent to: for entry in homedir.into_iter() { Which consumed the iterator (hence the error about `use of moved value`). Most of this can be deduced by studying the return types of `iter` and `into_iter`. The `iter` returns `&amp;T` (which borrows), while `into_iter` returns `T` (owned/moved value).
&gt; All the top-rated comments either give no reasons at all or focus on language popularity. Disappointing. Getting the feeling that you haven't read any Slashdot comments for the past ten years. :P
Neither: for entry in &amp;homedir { or for entry in homedir.iter() { worked. They returned src/main.rs:8:5: 11:6 error: the trait `core::iter::Iterator` is not implemented for the type `&amp;walkdir::WalkDir` [E0277] and src/main.rs:8:26: 8:32 error: no method named `iter` found for type `walkdir::WalkDir` in the current scope src/main.rs:8 for entry in homedir.iter() { respectively. I had tried `&amp;homedir` earlier and it didn't seem like that was the way to go. I learned from this thread that `.into_iter()` consumes while `.iter()` does not. Pretty cool.
I feel like it should be themed more like Vec, so String::new tied with the macro str! or string! I guess format took that slack. I think the majority of cases is someone wants an actual String, and secondly may want &amp;String. What's the reasoning for not keeping things similar to other parts of the std lib?
Honestly, I don't think that lib solves your provided use case the best way. Assuming you don't want to allocate Vec of all returned files and you still need a count, you can just [modify the example from docs](https://doc.rust-lang.org/std/fs/fn.read_dir.html#examples) and add count to it, like this: use std::env; use std::path::Path; use std::fs; use std::io; fn main() { let count = visit_files(&amp;env::current_dir().unwrap(), &amp;|entry| { println!("file {:?}", entry.path()); }).unwrap(); println!("count: {}", count); } fn visit_files(dir: &amp;Path, cb: &amp;Fn(&amp;fs::DirEntry)) -&gt; io::Result&lt;usize&gt; { let mut count = 0; if try!(fs::metadata(dir)).is_dir() { for entry in try!(fs::read_dir(dir)) { let entry = try!(entry); if try!(fs::metadata(entry.path())).is_dir() { count += try!(visit_files(&amp;entry.path(), cb)); } else { cb(&amp;entry); count += 1; } } } Ok(count) } No external libs needed.
It's repeated characters anywhere, not just next to each other. That repeats e a tonne
Except dynamic linking adds X bloated DLL dependencies; no thanks. Plan 9 had it right to throw out dynamic linking altogether. Edit: with the obvious exception of `libc.so`/`libSystem.dylib`, which does serve to contain the system's bloat.
&gt; I feel like I could be doing this with fewer memory allocations. The `WalkDir` type should probably implement `Clone`, but your code is essentially doing the equivalent of what a native `Clone` impl on `WalkDir` would do. I don't think you need to be cloning `homedir`. You could count the number of entries as you print them. As it stands now, you're recursively iterating over the directory twice. (Which actually will be quite fast in practice, because of the file cache, unless you have an exceptionally large tree.)
 grep -E -v -e '(.).*\1' -e "'s$" /usr/share/dict/words | awk '{ print length($1), $1 }' | sort -n | tail ambidextrously
Hmm, I just noticed that you pulled it straight from the `std::fs` docs. Perhaps that is not the best example for `read_dir`!
Same word I got, curious what the `time` is for that, compared with a release build of my code 
Yeah, I've been comparing it to a similar `find` command, which is significantly slower on the machine I'm doing my testing on! On a directory with about 70k files, `find` took about 5 seconds, while the rust program took only 3. Pretty awesome. &gt;You could count the number of entries as you print them. As it stands now, you're recursively iterating over the directory twice. Duh. I didn't think of that. Thanks for all your help /u/burntsushi\-sama.
Thanks for this information. On point 1, is this because of the recursive call?
Yes, and specifically, it is not in a tail call position, so it is never eliminated. (Which Rust doesn't guarantee anyway.) The `walkdir` crate uses an explicit stack and no recursion.
Another thing I wanted to mention was that using `walkdir` yielded the correct count, while using the example from the docs did not. It was more than a few thousand off, even when making it count directories.
Oh interesting. You have symlinks in the directory, don't you? The example in `std::fs` is using `fs::metadata(entry.path())`, which traverses symbolic links! `entry.file_type().unwrap()` or `entry.metadata().unwrap().file_type().unwrap()` will *not* traverse symlinks. The default behavior of both `find` and `walkdir` is to not follow symbolic links. You can enable it in `find` with the `-L` flag, and you can enable it in `walkdir` with `WalkDir::follow_links(true)`. I bet if you enable following links, you'll get the same count as the `std::fs` example (perhaps modulo an off-by-one error).
[I'd recommend using the lines iterator](http://is.gd/ihh1xA), although saying that is easy when I have access to the docs :D I used the [letterpress dictionary](https://github.com/atebits/Words) and got "dermatoglyphics" EDIT: modified it to give all the longest words, there's also "uncopyrightable"
It's an HDD. I'll get you the specs shortly.
This is probably the first Slashdot discussion I've ever actually read, and I'm probably never going to read another.
and will use java for writing it? no thanks...
[An issue in the repository](https://github.com/zsiciarz/rust-ffi-stringtools/issues/3) notes that `string` most likely marshalls to/from `wchar*` (UCS2 code units), and you should probably transcode to/from UTF-8 by hand.
As a general rule of thumb, one should not underestimate the speed of standard Unix utilities like `grep` and `awk`. They are hard to beat. (Despite the fact that the regex is using backreferences, and therefore, a DFA is insufficient on its own. But a DFA can still be used for part of the search!) In this case, the algorithms are very different. `egrep` is using a highly optimized regex implementation. The Rust version is building a new hashmap for every single word and doing *two* hash lookups for every *character*. Particularly with the default `SipHasher`, that's going to be very slow. (This is not an indictment of the OP! Simple implementations are good! Just pointing out that the comparison doesn't make much sense without analyzing the algorithms employed.) [EDIT] Well, time for me to eat crow. I didn't realize you were running an unoptimized version! Once I do that, the Rust version is indeed much faster. :-)
&gt; $ rustc main.rs probably forgot a `-O`
Do you have a lot of symlinks in your directory? I think the docs example follows symlinks, which can take *significantly* longer if you have lots of symlinks.
It's not that surprising that it's faster than `find | wc`; in addition to whatever overhead `find` and `wc`'s featurefulness may introduce, `wc` has to perform an additional read() for every file in the directory because of the pipe.
Yeah, I read "The hardware has pointers. Why obfuscate?" and "They don't like C because they haven't been taught it properly and instead go for things that are just trying to re-invent the wheel." and thought that well, if someone's still posting on slashdot in 2015, I guess it's not that surprising that they'd still believe these things in 2015.
Pretty cool, thanks. I'm not sure why the counts are different.
Yeah, the only reason I was surprised was because the documentation stated the results would be similar, but one `find` test I ran took 2 seconds longer than the rust program did. Which seems like a pretty good improvement.
I wrote a small C API for a new Rust library today, and it was my first time doing so. I wrote up my experiences for anybody else who's interested. My main difficulties stemmed from: * working with a nightly compiler on a libary that supports both stable and beta (lolz) * string FFI is always more complicated than it first appears * figuring out the best way to write automated tests I'm pleased with the result, though! It was a fun way to spend a few hours on a Saturday.
Another possible reason to prefer the system default over jemalloc: your system's malloc has randomization (such as on OpenBSD) and you want to keep that.
&gt; writing equivalent C header files for the low-level bindings I'm actually working on a [plugin which does that for you](https://github.com/Sean1708/rusty-cheddar). It's *very* early days (doesn't even handle pointers yet), but it's getting there.
Can't you just keep track of the count yourself, ie let mut count = 0 and then when iterating you just do count += 1 
Yes, I can. I didn't think of that until another user mentioned it in a different comment thread :) I just didn't update the OP with that fix. Thanks for the suggestion.
But we have 2 new in this case. Is it "ok", or should be a better approach?
Frankly? I had no idea the latter existed. Most of the time I've spent working on this has been figuring out how `libsyntax` and friends work so I'm certainly not opposed to doing a complete overhaul. Thanks for the link.
I used to have a five digit user ID. I see /. discussions now, and wonder if it's gotten worse or I've just grown up.
Better solution is to create a mutable counter and increment it inside the loop, then print the counter instead of creating a new walkdir.
 *Box::new(try![std::str::from_utf8(unsafe { std::ffi::CStr::from_ptr(std::ffi::CString::new(foo).unwrap().into_raw()) }.to_bytes())].replace("", "").clone().clone())
I think this is similar to the module I created ([some tests using it](https://github.com/mdinger/rules/tree/master/tests/range_set)) though mine is specialized differently because I require things like [union and set difference](http://mdinger.github.io/rules/rules/index.html#set-operators) for character classes. I don't expose it in the docs so I can't just point to it.
/u/steveklabnik, this should be in The Book.
It looks a bit strange at a glance, but actually makes sense. We generally don't clone the previous iterator, instead we create them on the fly. e.g., a = vec![1, 2, 3]; for x in a.iter() { ... } for y in a.iter() { ... } `a.iter()` is effectively the same as `WalkDir::new` because they both create a new iterator, not reusing the previous one. I find this idiomatic. Of course, in this particular case the OP encountered, employing a counter variable will be more efficient because system calls are expensive even with caching.
This is really great. Do you know how to pass a node Buffer to Rust?
Attempting to figure out the best way to use the json desealiation libs. It is turning into some very ugly code. 
Immutable updates in functional languages are done by creating a new version of the value, while leaving the original one untouched. Mutable updates, on the other hand, do everything in-place. If another thread has a reference to the old value, then it sees the updated version. In an affine or linear type system, you can actually get the best of both worlds. Your update function should consume its input (making it unavailable to the rest of the world), and return a new output. Under the hood, it's just doing an in-place modification; but because the rest of the program is guaranteed not to have a reference to the value you consumed, semantically you get all the guarantees of immutable updates. This is why I got excited about substructural typing in the first place. I like Rust, but to me it's just a stepping stone to greater things :)
Haha. I still find myself skimming Russ Cox's articles quite a bit, so I don't think I'm quite there yet. :-)
Note that time is only monitoring `grep`; if you want to time the entire pipeline put in in brackets: $ time { grep -E -v -e '(.).*\1' -e "'s$" /usr/share/dict/cracklib-small | awk '{ print length($1), $1 }' | sort -n | tail }
Hi, I have a question regarding Rust regex libraries (I'm not sure which are extant, but I believe there are at least two, one that build the automaton at compile time and another that read the string at run time). Do they take in account [this](https://swtch.com/~rsc/regexp/regexp1.html)? (*Regular Expression Matching Can Be Simple And Fast (but is slow in Java, Perl, PHP, Python, Ruby, ...)*)
By the way, it's parsed in Rust using [toml-rs](https://github.com/alexcrichton/toml-rs), which uses either the old `rustc-serialize` (by default) or `serde` (the "new" serialization system). But it looks like [Cargo doesn't depend on toml-rs](https://github.com/rust-lang/cargo/blob/master/Cargo.toml) and instead [does its own `rustc-serialize` thing](https://github.com/rust-lang/cargo/blob/master/src/cargo/util/toml.rs) and I don't understand why.
What about `rustc -O`?
Its worth noting that 'extern "C"' and 'extern "system"' are different. There was a long discussion on #rust about this the other day where tomaka found window was using stdcall, causing crashes. From https://doc.rust-lang.org/book/ffi.html: &gt; Most of the abis in this list are self-explanatory, but the system abi may seem a little odd. This constraint selects whatever the appropriate ABI is for interoperating with the target's libraries. For example, on win32 with a x86 architecture, this means that the abi used would be stdcall. On x86_64, however, windows uses the C calling convention, so C would be used. This means that in our previous example, we could have used extern "system" { ... } to define a block for all windows systems, not just x86 ones. tldr; Mark your functions as `#[no_mangle] extern "system"` if you want it to be portable; The c calling convention isn't universal.
The C# one really should have the calling convention specified. I don't know what the default is on Mono, but on Windows/.NET it is Winapi, which means Stdcall on x86, which Rust probably does not use.
COM components use stdcall as well.
I had a feeling I was missing something obvious, thanks for the info. FYI I had to re-bind some of the key-maps since ctrl-alt-t opens a terminal on my machine.
yes I did
sorry, I've just added it
Cool! Rust emits really unoptimized code and relies on LLVM for emitting what you would expect. For example, Rust doesn't guarantee that a move (`let x = y` moves `y`) happens without a copy, this is a LLVM optimization. But, the good news is that you can emit debugging symbols even with optimized ("release") builds (`rustc -g -O`, which is the same as `rustc -C debuginfo=2 -C opt-level=2`)
you can change you bindings in Atom directly by editing the keymap.cson file. In my keymap I use F5 to run and F6 to select target. &gt;'.platform-linux atom-workspace, .platform-linux atom-text-editor, .platform-win32 atom-workspace, .platform-win32 atom-text-editor': &gt; 'F5': 'build:trigger' &gt;'.platform-linux atom-workspace, .platform-linux atom-text-editor, .platform-win32 atom-workspace, .platform-win32 atom-text-editor': &gt; 'F6': 'build:select-active-target' 
Playpen link: http://is.gd/MVx36M
Wow, I didn't know about this cool tool. Thank you.
&gt; I understand what Sized trait is trying to do, but I don't understand what exactly is the compiler claiming to not be Sized. `error::Error` is [a trait](http://doc.rust-lang.org/std/error/trait.Error.html). Traits can be implemented by any number of structs which can be any size, so when the compiler sees `error::Error` by itself it can't know the actual size of the value. The default formulation of `From&lt;T&gt;` requires that it be sized (since it doesn't bound `T` to `?Sized`) and `error::Error` doesn't match that requirement. Thus the compilation error.
Your minimal program doesn't compile, here's one that does. http://is.gd/VcnmyF I removed the `From&lt;error::Error&gt;` implementation, though, because it's probably not what you are expecting. Here's the problem: * `std::error::Error` is a _trait_, so the actual size of the thing implementing the trait is not known. It could be a structure of 8 Bytes (std::str::Utf8Error) or 1 Bytes, (std::num::ParseFloatError). Thus, it is not _sized_, because the compiler does not know which size the type has that you want to put in there. * At the same time, From is intended for _constructing a new struct of a type by consuming one of the old type_. That means passing ownership to from is the intended way to do. * The important thing here is that in case of errors, the pattern is intended for converting one _specific_ error into _another error_. So you should implement something like `From&lt;Utf8Error&gt;`, but never using the trait `From&lt;error::Error&gt;`. That way, you _reinterpret_ specific errors into other specific errors. See an example here: https://doc.rust-lang.org/src/std/ffi/c_str.rs.html#308-314 * Finally, trying to convert any `error::Error` to a specific error would be the equivalent of the "catch all" pattern we often mock in Java (this is sketch code!): try { some_very_complex_operation_involving_a_file_read(); } catch(Exception e) { return "error reading file"; // we lose all specific error information. Maybe we ran out of memory? }
Like that it works. I've got no idea what I did wrong. Thanks for the help! You can see my simple expression parser here, if you're interested in how it turned out: https://play.rust-lang.org/?gist=52d2f96805e4375a5d52&amp;version=stable
You're welcome! And sorry for the delay, I didn't expect to get a new comment on this five-month-old thread. :P Next time I'd suggest just submitting a new text post to the subreddit itself and/or asking on StackOverflow.
Also, your code looks really great for someone who's just getting started with the language, can I ask what resources you've been using to learn?
I believe you can use the [ref-array](https://www.npmjs.com/package/ref-array) package. There's an [example in the Omnibus](http://jakegoulding.com/rust-ffi-omnibus/slice_arguments/).
Just curious, have you actually tried any of their IDEs? They're pretty damn good. I used to think that I didn't like Java, turns out that with IntelliJ, it's actually alright.
Actually Throwables that Java throws when out of memory are Errors not Exceptions which that catches. I know cause I have actually catched all Errors... Which is extremely bad idea and leads to bad times.
This is precisely the comment why I wrote that this code is a sketch and not an exercise of correctly catching all errors in Java... I know the specifics of the problem, I didn't bother for making that point.
`#[fundamental]` plays a big role here. I think it calls for a trait coherence flow chart to explain this! :-) - Is the type local? - Is the trait local? - Is the Self type a fundamental type parameterized by a local type? - Is there a blanket impl bounded by a fundamental trait?
&gt; working with a nightly compiler on a libary that supports both stable and beta (lolz) Do you use [multirust](https://github.com/brson/multirust)? It makes switching between/testing on different releases a breeze, e.g. your global default compiler might be 1.3.0, but you can use `multirust run nightly cargo build` to quickly test on the nightly release channel.
Oh, right. Makes sense.
Win32 mostly uses stdcall. It does use cdecl in a few places, and there's even a couple fastcall functions. For x86_64 there is vectorcall but that's relatively new and I'm not sure how well LLVM supports that, but very little should be using that anyway. COM does not actually use what C thinks of as stdcall. C++ stdcall member methods (which is what COM is implemented with) actually treat the return value slightly differently if it is an aggregate type within a certain size range than what stdcall does for a non-member function. Unfortunately LLVM doesn't expose this calling convention to us at all, but it can be worked around by tweaking the function signature to match the actual calling convention. Note that this means the C version of COM in the official Windows headers can actually cause crashes for the affected functions.
I filed https://github.com/killercup/cargo-edit/issues/41 for this. There are a few questions of how to implement this.
I'm in the same age-bracket as you. And I think it's probably a bit of both.
At the point where `From` will be used, all concrete possible types of downstream errors will likely be known. I would recommend a 1-1 mapping for each of them.
That now makes sense why my code is broken. As I pointed out in my other reply to /u/masklinn, I think I get it now that I should be creating ```From``` implementation for a specific implementor of ```Error``` trait. Going to try that now. Thank you for your help. 
3-digit here. I remember the chips &amp; dips days. There was a brief period of time before trolling became a sport, where the quality of discourse was more honest and with much higher S/N, which ended circa the appearance of Meeept, et al. However, even those days were more hostile than I could stomach at my present age, with lots of flaming. I'm relieved to see higher standards of civility today in other forums. Strange to see how far Slashdot has fallen, though.
Wouldn't you want to use [`filter_map`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.filter_map)? use std::io; fn main() { let mut vec: Vec&lt;f64&gt;; loop { let mut buffer = String::new(); io::stdin().read_line(&amp;mut buffer) .ok() .expect("Could not read input"); vec = buffer.trim().split(",") .filter_map(|s| match s.parse() { Ok(num) =&gt; Some(num), Err(_) =&gt; { println!("Error"); // Or whatever None }, }).collect(); for i in &amp;vec { println!("{}", i); } break; } }
This just removes invalid fields, it seems like he wants to skip the entire line if there are any invalid fields.
Ah! transmute can also straight-out change lifetimes. unsafe { mem::transmute::&lt;&amp;str, &amp;'static str&gt;(&amp;*string) } I got there because I don't like transmuting `Box`. Actually I think that approach wouldn't use forget() unsafe { mem::transmute::&lt;Box&lt;str&gt;, &amp;'static str&gt;(box_str) } // box_str is consumed now, forget() is neither required nor possible.
Thanks a lot for the external source!
Replace `T` with any type, `E` with any type. Replace `F` with `FnMut() -&gt; Result&lt;T, E&gt;`, which is type of closure that takes `()` (nothing) as argument and returns `Result&lt;T, E&gt;`. This function will execute your specified function (closure) until it returns Ok. If it returns ok, the loop will exit with the same result, otherwise it will ignore the error (but you can `print an error message if you want`). 
`take_while` is a transformation on iterators, that truncates the iterator the first time it's argument returns false on an element. The argument in this case, is the closure: `|s| if let &amp;Ok(_) = s { true} else {done = false; false}`. The closure checks that the string parsed correctly (it's an `Ok`). When the string didn't parse correctly, we set `done` to `false`, so that we know to try again. It might make more sense if we add some spacing |s| if let &amp;Ok(_) = s { true } else { done = false; false } The following `.map` line is because while we know that the `take_while` line means that no `err` will ever occur here, the compiler doesn't, so the element is still of type `Result&lt;&amp;str, _&gt;` when we want it to just be of type `&amp;str`.
As author I repeat after /r/Kbknapp, not yet. It is too immature to be used, so it isn't suitable for CotW. When I finally implement basic TLS support then maybe, but even then I would wait till it is peer reviewed - it is crytpto, so it is serious stuff.
I avoid doing lookahead by transforming the NFA with possibly non-input-consuming transitions that look *one char* ahead or behind into an char-based NFA with only input-consuming transitions. This transformation adds one or two states per non-input-consuming transition, but then I can usually also prune a state or two using simple heuristics. After the transformation, I convert from a char machine to a byte machine. Cases like r"\b.\b" are not so great (~1000 states for the minimized DFA), but I don't think there's any combinatorial explosion -- it's just the machine for \b is complicated...
I might be missing something, but though at the point where ```From``` is used all downstream errors are known, the number of such points is not limited to one, which means every single one of them is subject to change.
Interesting. What version of rust are you using? It works for me on the playground, and on my computer. I tried it on the current rust 1.3 (`rustc 1.3.0 (9a92aaf19 2015-09-15)`, `cargo 0.4.0-nightly (553b363 2015-08-03)`), and on my ancient version of rust that I had sitting around (`rustc 1.0.0-nightly (c89de2c56 2015-03-28)`, `cargo 0.0.1-pre-nightly (72f2af1 2015-03-29)`)
I had a similar idea using bits and u32's: https://gist.github.com/iscfrc/870969313ff734fc5a64 It's fast, but it's naive and only handles the A-Z alphabet as you mentioned.
 $ rustc --version rustc 1.2.0-dev But regardless, why shouldn't `vec` be mutable? If the loop iterates more than once it will be reassigned. EDIT: Just tried on rust-nightly (1.5.0-dev) and it gives the same error.
This is not the subreddit you are looking for, try /r/playrust.
I think you might be interested in building rustc yourself with `--disable-jemalloc` option.
As I see it, `vec` can only get assigned to once. The `Ok(v)` branch of this loop vec = match result{ Ok(v) =&gt; v, Err(_) =&gt; continue, }; is the only place where `vec` gets assigned to, and the break statement ensures that this branch can never run twice. On the other hand, when the (repeatable) `Err(_)` branch runs, `vec` never actually gets assigned to. That seems pretty non-trivial for the compiler to pick up though, which is why I was so impressed that (my) compiler gets it. I just tried my code on nightly on my computer, and it doesn't report any errors. It seems like if one of our compilers reports errors, and the other doesn't, that's probably a bug and we should report it. What OS are you running on? I've tried it now on OSX and Linux, and it's worked on both. Also, are you compiling with any flags? I'm just using `rustc test.rs -o test`. (We can continue this in PMs if you want)
This is just a simple script that can be used to build and test `rustc` with `cargo`. Supports building stages if you can follow how to use `rbuild_stage`. Mostly it serves as a convenient way to build a cross-compiled `libstd` sysroot for an arbitrary target (flexible specification or built-in). [Note that there is currently an ongoing effort to do this full build all fancy and proper like.](https://github.com/alexcrichton/rust/tree/cargo-build)
Awesome. This looks like exactly what I needed.
/u/paholg has actually done 99% of the work, I just tried to add small pieces of code and docs here and there.
* [typenum](https://github.com/paholg/typenum) has just hit 1.0.0, so we're (virtually) partying 😊 * I'm still chipping away at the building blocks for my Cow lint for clippy * Trying to benchmark the effect of jemalloc vs. system allocator on Rust's benchmarksgames entries (perhaps I'll blog about it too, if I find the time) * Preparing my clippy talk for the Rhein-Main Rust meetup * After discussing that rust should be able to create write-only types, I just started a [wom](https://github.com/llogiq/wom) (write-only memory) crate that will hopefully work for the required cases. I'll also add a lint to detect reading attempts at compile time once the basic design is done (pinging /u/tomaka who may be interested in this) * I still have an open RFC and a pre-RFC that I didn't get around to flesh out so far, but I won't have time for it this week either 😞 * As always, too much work Also pinging /u/Manishearth to make this sticky.
Either ask some questions in the comments of [the relevant RFC](https://github.com/rust-lang/rfcs/pull/1183) or open an issue on that repo. Don't forget to read the RFC itself ;) I've not seen mentions of `lib_allocation_crate`/`exe_allocation_crate` target specifications anywhere else. Overriding them in a custom target might just do what you want. Note that the standard library does not link to any particular allocator. 
No, I'm afraid we don't have benchmarks yet. However, we took a lot of effort to keep the compile time within O(log n) bounds despite Rust's problems with `where` clauses (our first version of subtraction actually devolved into O(n) once, but paholg managed to fix it). Just one data point: Our current test suite compiles within ~10 seconds. The runtime overhead is exactly zero, because there is no way to instantiate the number types. Edti: And now thanks to bluss, we also inline all functions that can be called without instantiating anything, which should help LLVM to do the right thing (only on github for now, but I expect another version bump soon).
I'm not sure; I don't really know when it's all evaluated. It may be worth righting some code with and without it and comparing the assembly. It should also be noted that division is *not* O(log(n)) right now. I think it's O(n). We may be able to optimize the code further, though, to get it where it should be. Improvements to Rust's type system may also eventually fix it.
Well I started a CS degree last week but have yet to write a line of code for it, so to keep myself in practice I am writing a logic gate simulator. Hopefully it'll end up being GUIfied with gtk. Not particularly interesting or useful, but there you go :)
After we made much progress on [cargo-edit](https://github.com/killercup/cargo-edit) last week, I think this is where I'll spend most of my "Rust time" this week as well. Unless something else catches my eye, of course 😏
Yeah, I feel like it might be quite be a slow start as I've already done a decent amount of programming before and the modules assume no prior experience. I have a decent amount of free time, but I do live one floor above the bar so we'll see how that works out :P
Not really. It is a nice-to-have without a time frame I think.
Ahhh true. Well it's odd then they my compiler is throwing errors then
Oh goody, yet another environment variable to set/folder to add to my `$PATH`. I can grit my teeth and live with `$HOME/.cargo` being a thing, but now we're putting *executable binaries* in some wacky folder rather than the folder defined by the specification to be for storing executable binaries.
Thanks; interesting reading. I've been curious about Swift, but given I have no iDevices, there's really not much point.
Which specification? As far as I know, about the only place that's guaranteed to be in `PATH` by default is `%SYSTEMROOT%`, and putting stuff there is basically littering. Never mind the per-user concerns...
As I mentioned above. I'm pretty new to Rust. I don't really know clearly what I can contribute to Rust project. If I gotta choose, I would love to work in small projects such as utility (helper) library, vim-like text editor app.... 
The [filesystem hierarchy standard](http://www.pathname.com/fhs/pub/fhs-2.3.html). Which doesn't really apply to Windows, but given that there's a standard that applies to pretty much every other platform that people generally run Cargo on, it would be nice to follow the standard on those platforms.
&gt; Rust also adds the concept of “slices,” which provide access to segments of arrays, and are heap-allocated as pointers to a given item in the array and a length (number of elements) included. Slices, in their most common variety, `&amp;[T]` are just lightweight references paired with a length, there is no implicit heap allocation going on.
One such helper library I happen to work on is [clippy](https://github.com/Manishearth/rust-clippy). It's a collection of lints for Rust and incidentially also contains some of the first Rust code I wrote :-) Apart from that, I think I've read about someone writing a text editor in Rust, but I don't remember the link.
I was actually thinking of XDG, since the FHS stops at `/home`.
Baring some combinatoric tragedy they will happen *eventually*. But cleaning up the compiler is higher priority right now.
&gt; Apart from that, I think I've read about someone writing a text editor in Rust, but I don't remember the link. There are a few: [Iota](https://github.com/gchp/iota) and [Rim](https://github.com/mathall/rim).
In Rust, a crate is a self-contained unit of compilation. It does not know about other crates, unless you introduce them with "extern crate". What you are doing currently is basically reusing the same source tree for two different crates. They don't actually know about each other, so they don't know that the code you intended to share could actually be used by another crate. What you want to do is create a third crate, and put the shared code inside it. Then you can introduce that 3rd crate to your binary crate using "extern crate". Here, I have forked your example to demonstrate what I mean: https://github.com/crumblingstatue/dead-code-rs I have made use of the conventional paths that Cargo looks for, so you don't have to write as many things into Cargo.toml. For example, if Cargo finds a `src/lib.rs`, it will assume it contains a library crate. Similarly, if you put stuff into `src/bin`, it will assume they are binary crates. It's useful for small programs.
Without optimizations turned on it appears that's the case, but with `-O` the beginning/middle/end of the `match` all bench at 0 ns/iter, so I'd say it's generating a table as you would expect.
&gt; if let - statement for safe unwrapping things from Optional Rust's had that for a few months now (and it was literally stolen from Swift).
Nice! I am especially interested in the realistic lighting through wavelength functions part. I wrote part of a path tracer over the summer and couldn't figure out how to do that.
Fair point. I guess after my experiences with other applications, I just see red whenever XDG comes up. I really hope Cargo ends up being a modern application that follows best practices.
Well, if you care a whole lot, it is open source ;)
Higher kinded types are much requested, but I don't think any one is working on them. It remains to be seen whether they can be added in a backwards compatible way. Let's hope so.
Whaat? Why?
For "fun" ^(also compile times and performance things)
Got a typo in your link
Will be continuing with [twig-rs](https://github.com/Nercury/twig-rs) templating engine. Got a good chunk of parser done, will work on compiling AST into instructions for [little-rs](https://github.com/Nercury/little-rs) interpreter I wrote earlier. This is going to be fun.
&gt; the need to prefix every field access with `self.` Which language allows you to omit `self.` and how do I destroy it?
For me it was the opposite. When I first learned haskell I considered it a bad idea and feared masses of user defined libraries with horrible interfaces. Actually it turned out that it also allows some beautiful libraries, whereas in other languages these have to either rely on verbose function calls or misuse existing operators. There is also [hoogle](https://www.haskell.org/hoogle/) which is a great search engine for haskell related stuff, including operators.
Fixed, thanks
Alternatively, just put `#[allow(dead_code)]` on your functions.
It's also nice just to verify that we have the language semantics defined well enough for another implementation, and for 'trusting trust' issues...
Does somebody have a configuration file to tell `cargo install` to, by default, install everything in `/usr/local/(bin|lib|share)` and when specified some flag (`--system` or `--for-all`) to install the stuff in `/bin|/lib|/share`)? At least in OSX and the Linux distros I use `/usr/local` is pretty nice because doesn't require `sudo`, and it's available on my path by default for running binaries, linking, and finding man pages. 
&gt; Or OSX, What do you exactly mean? For installing binaries and libaries from source OSX follows the `/bin`, `/lib`, `/share`, ... + `/usr/local/bin|lib|share|...` directory structure, which is the same I've seen in any Linux distro I've ever used. I don't know which standard that is, or if OSX does completely follow it, but I've never had any trouble installing any unix application there due to the directory structure. 
It's part of an approach that's called physically based rendering. It's meant to model the way light works as closely as possible. One of the advantages is that it's easier to model reality with a more physically based model of light transport, since you can, in theory, just plug in the numbers for the spectrum of an actual light source and get an accurate representation. 
Rust has 12000 stars on GitHub. Only 900 for Terra is still an indicator that it isn't hopelessly niche at least.
I obviously haven't tested this but I think it should be as simple as: In `.profile` (or your shell's equivalent): export CARGO_INSTALL_ROOT=/usr/local When you want to install into `/bin|/lib|/share`: $ cargo install --root=/ &lt;crate&gt;
Understood, but why write your shaders using CIE color space when they are just a linear mult on the incoming light? If you want to pick colors in CIE space you can always convert them to an RGB triplet before they gets used by your renderer.
&gt; stolen from Swift Ugh, I hate it when folks say ideas are 'stolen'. It was _inspired_ by Swift.
Oh I see, thank you very much. I will look into this tomorrow in more detail, but I think this already helped a lot!
I wouldn't read too much into it. Obviously nobody thinks the developers are doing anything immoral by taking inspiration from other languages, it's just a figure of speech.
It looks it should be enough to create `~/.cargo/config` and ensure it includes: [install] root = "/usr/local/bin" (I'm not 100% sure the `/bin` is necessary or not.)
Just a comment, someone that is already using the language could search it [on Hoogle](https://www.haskell.org/hoogle/?hoogle=%3C*%3E), and also search for its signature [Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b](https://www.haskell.org/hoogle/?hoogle=Applicative+f+%3D%3E+f+%28a+-%3E+b%29+-%3E+f+a+-%3E+f+b). But yeah, that is not ideal - only knowing it comes from `Applicative` would enable people to make a Google search.
Sometimes it's worth to give syntax sugar to really common types (eg: lists in Haskell have a special constructor).
It landed as unstable to serve as the shared counterpart to `Unique`, factoring out common semantics between `Arc` and `Rc`, i.e. mostly an implementation detail of `std`. It'll remain unstable until an RFC is written &amp; accepted. ([#27730](https://github.com/rust-lang/rust/issues/27730) is its tracking issue.)
I like his first code example. It's a real nice and easy (and it's important and solves real life issues) example. Also, this page is a series and only the first part is a Rust post (I didn't notice until I got confused trying to follow the flow between different posts).
&gt; If so, this is exactly the kind of design I mentioned as being actively hostile to system package managers, as crate installs now mutate a single shared state, rather than being separable by way of (say) installing individual drop-in files to a directory. I really dislike this, as it forms an ABI which (even if not public) will be a pain to change later - and if not changed, makes interop with system PMs needlessly difficult and fraught. &gt; By having a central state, a naive implementation simply appends new installs to the state file. If that is done, then installing crates which are independent of each other is not commutative - this breaks PMs. That's also my worry. `cargo install` should be good enough so that distros simply call it (perhaps with appropriate parameters or env variables) while building Rust packages. It would be a shame if they had to do something else to "fix" Cargo behavior.
How does Terra compares to Rust? Does it enable memory safe low-level programs?
Working on a raster image editor (with support for plugins). It's quite an early WIP so far, but I've built one before in Java (and it went through so many redesigns that I think I've worked out how to do things right the first time). School finishes in a few weeks so I'll be able to work on it a lot more then.
It's strengths are simplicity, minimal pointer/array arithmetic, and Lua as the preprocessor instead of an ad-hoc mini-language, but it doesn't really have Rust's strengths except for speed and proto-object potential.
&gt; I can't use mode… Because...? Did you use the trait it's defined on? Methods from traits aren't automatically available.
Why do you say you can't use `mode`? On Unix (which you're presumably using), there's an implementation for `PermissionsExt` on a `Permissions` object. So, if you import `PermissionsExt`, you can use `mode()`: use std::os::unix::fs::PermissionsExt; fn perms() -&gt; std::io::Result&lt;()&gt; { let meta = try!(std::fs::metadata("foo")); let perm = meta.permissions(); println!("{:?}", perm); println!("{:o}", perm.mode()); Ok(()) } fn main() { perms().unwrap() } Gives me (if I have a file "foo"): Permissions(FilePermissions { mode: 420 }) 644 If you're trying to use this cross platform, you're right, there isn't something you can get. Rust doesn't have a cross-platform abstraction of permissions, because permission models differ widely between Unix and Windows (and even different flavors of Unix; while they all generally support some kind of mode plus ACLs, the ACL support differs in non-trivial ways).
Adding `use std::sys::ext::fs::PermissionsExt;` and `println!("{:?}", meta.permissions().mode());` yields the following: src/main.rs:10:5: 10:38 error: trait `PermissionsExt` is private src/main.rs:10 use std::sys::ext::fs::PermissionsExt; ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ src/main.rs:177:38: 177:63 error: source trait is private src/main.rs:177 println!("{:?}", meta.permissions().mode()); What am I doing wrong here? Could you point me to some documentation?
This will only be used on *NIX environments. I said this is a different comment: ---------------------- Adding `use std::sys::ext::fs::PermissionsExt;` and `println!("{:?}", meta.permissions().mode());` yields the following: src/main.rs:10:5: 10:38 error: trait `PermissionsExt` is private src/main.rs:10 use std::sys::ext::fs::PermissionsExt; ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ src/main.rs:177:38: 177:63 error: source trait is private src/main.rs:177 println!("{:?}", meta.permissions().mode()); What am I doing wrong here? Could you point me to some documentation?
You're skimming. *Look* at the path being used. You're trying to use the internal, private name. The *public* name is the one being used in that example *and* in the documentation.
Of course we'll find you a mentor. But I suggest it should be someone who knows the code base you'll be working on.
Yeah, it can be frustrating sometimes because the compiler reports certain errors based on their final, private name, rather than the name they have been publicly re-exported under, leading to this kind of confusion. It's a [known bug](https://github.com/rust-lang/rust/issues/26454), hopefully it should be fixed at some point to avoid this kind of confusion.
Can you please keep me posted then. I'm looking forward to it. 
I mean, I should do proper research instead of relying on the compiler. Thanks for the help :) EDIT: Thanks for that bug report haha. Got a laugh. Basically me: &gt;I was tripped up by this today. Tried using .mode(..) from OpenOptionsExt. Compiler recommended: &gt;candidate #1: use `std::sys::ext::fs::OpenOptionsExt` &gt;Adding that results in &gt;error: trait `OpenOptionsExt` is private &gt;It was non-obvious to discover that I actually needed: &gt;`use std::os::unix::fs::OpenOptionsExt;` 
Well, porting a complete game from Scala to Rust is definitely a large project itself. That said, with JVM languages you often have to work extra hard to get your objects under escape analysis, otherwise you have to deal with GC. Since you appear to want more control over how your code keeps track of its memory, you need a systems language. Once you've made that decision, choosing Rust will not only give you a modern language with many of the amenities you appreciate Scala for, but also a vibrant and friendly gamedev community with libraries like glium (which brings some much needed sanity to OpenGL coding), piston and many more.
The even better part is that [pnkfelix](https://github.com/pnkfelix) (/u/pnkfelix here on Reddit), who submitted that bug report, is a member of the [language design and compiler teams](https://www.rust-lang.org/team.html). So don't worry about it; this doesn't just affect beginners, this affects even some of the most core developers! That definitely indicates that it needs fixing. Add to that the fact that one of the design goals of Rust is to allow you to *lean on the compiler*, or work your way from incorrect code to correct just by trying something, seeing what doesn't compile, and taking the suggestions or making the most obvious changes possible to get a little closer to compiling. While you'll never be able to have the compiler simply DWIM, you can get close if it always gives you good suggestions for what to try next and you are able to get where you need to go by intelligently following a chain of those suggestions.
Ok, here's the deal: Browse [clippy easy issues](https://github.com/Manishearth/rust-clippy/issues?q=is%3Aopen+is%3Aissue+label%3AE-easy). If you happen upon one issue you'd like to work on, add a comment that you want to take it, then I'll mentor you personally. If you don't find any, we'll look into other projects (and hopefully find you a mentor there).
No sorry, my blog is just one big page. Hopefully it wasn't too confusing. :|
Very cool! Any reason to do the wavelength functions and CIE color space stuff before path tracing for realistic lighting effects? Path tracing (or some other global illumination method) will give really great results even without simulating wavelength dependent effects like dispersion. Although you will definitely want gamma correction in some form for your rendered images (I'm not familiar with CIE space so I'm not sure if it includes a gamma correction term like sRGB).
Wavelength-dependent phenomena, like dispersion, for instance (which OP did not list as a planned feature). Otherwise RGB works just fine.
No, it's cool. I just pointed it out in case it threw someone else too. It didn't throw me for but 30 sec probably. Your second post is cool too. Same thing happened to me the first time I saw travisci, used with rust which had like 40k commits and 10 commits landing a day all passing their huge testsuite and I thought "I didn't even know that was possible and they're using it on a massive scale and it's free and other people can use it too. It even builds their docs!". Some of these crates are written by really smart people who program really well and you could easily wonder if trying is even really that useful. Looks like you've got a pretty good outlook about it. +100. Nice blog.
&gt; What do you exactly mean? That OSX does not follow or abide by the FHS. &gt; For installing binaries and libaries from source OSX follows the /bin, /lib, /share, ... + /usr/local/bin|lib|share|... directory structure That's the historical Unix filesystem hierarchy inherited from OSX's unix roots (via BSD), said hierarchy also being the starting point of the FHS. Doesn't mean OSX follows the FHS. OSX [has its own filesystem hierarchy](https://developer.apple.com/library/mac/documentation/FileManagement/Conceptual/FileSystemProgrammingGuide/FileSystemOverview/FileSystemOverview.html) extending the "UNIX-specific directories". Note for instance that OSX doesn't have `/home/` (it has `/Users/` with a well-defined — if extensible — hierarchy), doesn't have `/boot/` (the kernel binary is `/mach_kernel`), doesn't have `/root/` (replaced by `/var/root/`), and all of `/etc/`, `/tmp/` and `/var/` are symlinks into `/private/` subdirectories.
Yeah, and you haven't even looked into other great things like closures, traits, the type system, docs (and doctests), macros and compiler plugins (sorry, nightly only), tests, benchmarks (sorry, also nightly only) ... the list goes on and on.
Ah, this must be a misunderstanding on my part, I thought that (s)RGB alone could not be used for realistic color mixing, because I've tried it before. Right now, it seems like I just have to find the right blending function to mix two colors, eg. add, screen etc., though I'm not too sure about this... EDIT: I just checked your posts and noticed to your tray_rust raytracer. Maybe you can elaborate on how you've mixed the colors? Or does your raytracer not really require color mixing because it does not support colored lights (from what I can see in the example pictures)?
My first CS semester was pretty awesome, a whirlwind tour of programming, testing, runtime complexity and verification culminating in writing an Eiffel interpreter in Eiffel, and I learned Java as a side project (this was during the 1.0 days).
Currently on standby on my wayland projects. There is some discussion going on with the waylands devs to make the protocol specification more type-safe. As this will most likely cause breaking changes to integrate this in my bindings, I prefer not to build too much things on these before all these questions are settled.
* `Read` is a trait, you should use it if you read data byte by byte and you wan't your code to be generic. * `Bytes` is just an iterator over bytes, you should not use it directly. * `Cursor` is a wrapper over some types like `&amp;[u8]` or `Vec&lt;u8&gt;` and provides you with `seek` (`set_position`) and `position` functionality, which is useful if you're doing not just sequential reads.
&gt;I am a mediocre programmer. For right now at least. Often I’ll find something that completely blows my mind, or I’ll discover a project someone else is doing and I’ll be amazed at what it does. There are so many things I don’t even know exist that people are experts on. When you find those things they can make you feel mediocre, like you are so far away from that thing that just blew your mind. Thanks for the enlightenment , now i can evaluate myself. Rust language blows my mind 
I think it's more that (at least when I've considered the idea in my own head) that postfix `?` doesn't work because it's ambiguous with prefix references -- is `&amp;String?` an `&amp;Option&lt;String&gt;` or an `Option&lt;&amp;String&gt;`? -- and prefix `?` "works", but (`?&amp;String`, `&amp;?String`) crosses over the line of acceptable density of arcane symbols for my taste. Others might have a different subjective evaluation though.
Well, we already have parens: `&amp;String?`, `(&amp;String)?`, `&amp;(String?)` But yeah, generics are ugly but robust to this sort of thing.
I've been working on [BASMAP](https://github.com/buntine/basmap). It's a relatively simple command-line tool for health checking a sitemap.xml file. It will report on whether or not site pages are resulting in HTTP errors, etc. It's something I've wanted to add as a post-deploy hook to some of our projects at work. It's my first non-playground Rust program and my first foray into systems programming. So far I've enjoyed it quite a lot. Especially tagged unions, complex pattern matching and the sheer lack of runtime errors.
I like to model Rust as an unforgiving language design bandit. Cyclone got *mad* jacked up. 
Awesome reads :) thank you for all that. I actually didn't know that was a design creature of the compiler. I mean, I know that compiler usually try to tell you what's up, but it's cool to see rustc actually say, "Looks like you forgot an import. Try this, buddy!"
Probably libraries and solving issues that don't have solutions obvious to someone just starting to use the language. 
So does it first look for the variable in local scope, then look for the class variable? What about global scope?
Thanks, I appreciate the feedback. I will fix that right quick. :)
Yeah, I have a couple of maths modules and they seem a bit tougher than the other ones, but more interesting as well! 
And more specifically, sum type. Technically, structs and tuples are algebraic data types too. They are product types. Enums are sum types because an enum has a number of states equal to the sum of the number of states of its variants -- `Option&lt;bool&gt;` has 1 + 2 = 3 states -- whereas structs and tuples are product types because they have a number of states equal to the product of the number of states of their fields -- `(Option&lt;bool&gt;, bool)` has 3*2=6 states.
Also finding/fixing compiler bugs and pessimizations. Terra is a fairly complex project with a [single maintainer](https://github.com/zdevito/terra/graphs/contributors) and few users. There are bound to be a lot of rough edges. The projects I'm working that would benefit from staging or code generation are also the projects that are pushing the edge of my ability, so I'm leery of piling on any extra risks.
Sorry for the downvotes. Probably because your comment doesn't contribute much. What makes this thread great? How does it help you? I'd live to know :)
I am the OP and I quite enjoyed this thread, myself :) I know your comment is a bit out of place but I'm glad you posted it. Thanks :)
I'm working on a peg parser for CQL, the Cassandra Query Language. I intend on utilizing it in a compiler plugin to get compile time syntax checking of Cassandra queries, similar to the postgres compiler plugin. 
These answers are only from the info presented, I haven't dived into your code (some of the questions would need to know how your system works to give a really good answer). 1. Does it need to consume `self`? Is it a problem if `self` gets used again in the calling scope? If not, take `&amp;self`. 2. Does it need to consume the message? Is there a problem if the message gets used again in the calling scope? If not, borrow. 3. Taking an `&amp;str` lets you take `String` or a `&amp;String` automatically, because `String` dereferences to `str`, and deref coercion will be applied in this context. 4. `tags` as a slice may require an extra allocation if the caller stores the tags in a form other than an array/vec of tuples. The generic way to do it would be to take an `I: Iterator&lt;Item=(&amp;str, &amp;str)&gt;`, which could be pulling them from a vector or a hashmap or anything else. 5. I don't see immediately how you would apply the builder pattern to this API here. In general, it shouldn't impact the types of arguments to its methods, but usually all of the methods take `&amp;mut self` and return `&amp;mut Self`. 6. Unfortunately, deref coercion isn't applied to take `Option&lt;String&gt;` -&gt; `Option&lt;&amp;str&gt;`. You have to perform the coercion yourself, the most idiomatic way is to do `option.as_ref().map(|s| &amp;s[..])`, which takes a str-slice of the entire String.
&gt;Taking an &amp;str lets you take String or a &amp;String automatically, because String dereferences to str, and deref coercion will be applied in this context. Not quite. `&amp;String` is coerced to `&amp;str`, but `String` is not. Taking a `T: AsRef&lt;str&gt;` and calling `as_ref()` on it should work.
What does FCP mean?
[How about extracting the error with a `match`?](https://play.rust-lang.org/?gist=d228d5144cd6d9c96a26&amp;version=stable)
Reddit has an equivalent to a +1 button.
&gt; @autoclosure is certainly weird and has an equally weird history in Swift but basically, they're used to ensure that the right-hand side of expressions like (x &amp;&amp; y) isn't evaluated unless necessary (i.e. if 'x' is false, 'y' is never evaluated). It's a situation where 'y' is actually interpreted by the compiler as a closure, even though it looks like an expression. Swift allows you to write your own short-circuiting operators? I'm not sure if I'm impressed or horrified.
Thanks. I'm not sure why did it even happen in the first place.
Thank you! I'll try to implement these answers.
The point where I started hating it was when someone imported Prelude without `.`, then redefined the order of `.`.
Rather than having a specific mentor, you can also try joining the #rust IRC channel on irc.mozilla.org and simply read what others are saying and ask any questions that you may have.
I noticed that rust-url tries to do [something similar](https://github.com/servo/rust-url/blob/master/src/form_urlencoded.rs#L119). I'm not sure why it's taking an `IntoIterator` instead of an `Iterator`, and also, why does it consume it instead of borrowing.
That is actually the most generic thing it looks like. `IntoIterator` is a trait for types that can be iterated over, like vectors and maps. It takes it by move instead of borrowing because it `IntoIterator` is implemented for e.g. `&amp;Vec&lt;T&gt;` et al as the equivalent of `vec.iter()`. That signature is exactly what you want, I guess: you can pass &amp;vec, &amp;hashmap, etc to it and it will work. However, this is where there's a trade off (at least unless some better solution is arrived at). I myself find `I: IntoIterator, I::Item: Borrow&lt;(K, V)&gt;, K: AsRef&lt;str&gt;, V: AsRef&lt;str&gt;` really difficult to follow when I read it in documentation. There's 3 different traits involving 4 different type parameters just to say "it takes a bunch of str pairs".
I think better names and newlines helps a lot: where StrPairs: IntoIterator, StrPairs::Item: Borrow&lt;(S1, S2)&gt;, S1: AsRef&lt;str&gt;, S2: AsRef&lt;str&gt;
Aren't they using Kotlin? 
Further reading from some quick Google results: https://www.reddit.com/r/rust/comments/29wwzw/error_handling_and_result_types/ http://lucumr.pocoo.org/2014/10/16/on-error-handling/ https://news.ycombinator.com/item?id=9545647 https://news.ycombinator.com/item?id=7792438 http://programmers.stackexchange.com/questions/258012/why-design-a-modern-language-without-an-exception-handling-mechanism And so on and so forth. There's mixed opinions on the lack of exception handling machinery in Rust and how automatic or not error handling is, but I personally quite like the lack of exceptions. Rust is, from what I've seen, very much a language where you're forced to acknowledge and handle the edge cases. Sure, there are times where you just `try!` over and over until the function is over, but often there's another way to express what you're doing that doesn't require repeated use of the macro (e.g. `map`). By forcing writers to handle errors themselves rather than let them pass invisibly through the function, code becomes more obvious at the cost of verbosity. Additionally, in my opinion, it reads better later, once you no longer have the documentation in front of you. In other languages I grow unsure of when and where errors can occur with time.
I mostly agree. Forcing the return type of `Result&lt;&gt;` and using `try!` as the advantage of making error handling explicit. You completely define the functions, by what values and what errors it can return, it's not possible to have some deep code in an obscure codepath throwing an unexpected error that breaks everything afterwards. In a general sense, I'm in favor of making things explicit, even if it makes things more verbose.
The more verbose code is the harder it is to understand what it is actually trying to do. When I look at the Rust example I see a lot of error handling code, leading me to believe it is a vital aspect of that function. but it isn't. All it's doing is proxying the error back to the caller. Indeed, in the example used in `std::result` the function does no error handling at all. The needless verbosity just makes the code harder to maintain, and leaves open somebody forgetting to add appropriate handling.
&gt; well, maybe a generic `do` with `&lt;-` would be better :) It would essentially have the same semantics `try!` currently has (at best, I'm not sure how it would call `From::from`) with all the logic errors you assert `try!` leads to, and requires HKT which Rust doesn't currently support.
&gt; Well, not really. I was opposing automatic implicit try!, which OP had suggested (sorry if that wasn't clear). Ah no, re-reading your original comment I'm the one who skipped over the "magic" part, sorry about that.
I dispute that you would end up with `Result&lt;&gt;` on all your functions. You should neatly separate I/O from pure code (I do this in Java too, just standard good practice for testing), then most of your code (the pure stuff) does not return `Result&lt;&gt;`. It's no worse than declaring `throws AuthenticationException, ProcessingException` in Java. I agree that `try!()` is a bit verbose, especially if you're chaining functions `try!(try!(socket.send(...)).send(...))` is plain silly. I'm a big fan of the proposed `?` operator: `socket.send(...)?.send(...)?` looks much nicer. The blog post also questions the need for `try!` or `?` at all. I wish I could quickly scan the body of a method in Java and see _which_ calls throw and which do not; it's usually 2-3, but while the signature tells me exceptions can happen (`throws ...`) it doesn't tell me _where_ they happen (which may be important in the presence of invariants---exception safety---etc.).
I don't have time to read the whole post but what I did read sounds a lot like the [Trait-based exception handling](https://github.com/rust-lang/rfcs/pull/243) proposal.
&gt; I don't consider it difficult to maintain exception safety in C++. I believe you. But please keep in mind that not everyone is an exceptional programmer like you. For some of us, even writing a constructor that won't leak anything when an operation can throw takes mental effort. &gt; But perhaps more important, I don't see how Rust in any way avoids that problem. &gt; Using try! still allows returns to happen at arbitary points in a function thus bypassing any code following it. It in no way forces the programmer to write error-safe code. Rust will handle resources correctly even on early returns (by inserting `drop`s where applicable). Also please note that early return is *not* the problem – or do you suggest banning `return` statements, because they "bypass any code following" them? What about `continue` or `break`? Now I get that you may be advocating against implicit `return`s. Fine, but when you handle an error, there's nothing to do *but* return it by default. If we ask people to do it explicitly, they'll write a `try!` macro to save them from repeating the same `match` statements over and over. Better to give them a good implementation up front (that is very probably better than what they come up with). Don't laugh, that's actually how we got `try!`. Yes, it's a compromise, but I argue it's a good one. Finally, no one forces you to use `try!`. If you can handle an error within your function, you're better off doing so directly. But if your function can return an Error, its return type will tell us. I note that we haven't discussed the ultima ratio regum, `panic!`. Note that unlike `try!`, it actually unwinds the stack, also dropping values where possible (one can use RCs to create loops, thus creating a leak, but this is rarely done carelessly), and cannot be caught except from another thread. This leads to some quite nice erlang-like properties (a bit diminished by the fact that Rust uses system threads).
This is mostly a matter of programming philosophy. Some people like to ignore errors and catch them up top. This is easy to do, but if something changes you might be hosed. Others like to explicitly handle or bubble errors. There's less of a chance of missing something here. But it's more verbose. This fits in to Rust's theme of compile time safety. The post talks of exceptions as if they're a concept foreign to Rust language designers. They're not. They're something the language explicitly decided not to add. &gt; Languages must face the reality that most function calls can fail, and only a handful of functions will actually know how to deal with errors. The vast majority of functions will simply proxy errors from their callees to their callers. Languages must also face the reality that people are not going to document their code well, which leads to a host of problems in languages with exceptions. Having to proxy errors is a reasonable cost to pay to avoid this. Tradeoffs.
Most languages and codebases show the contrary: implicit error handling means errors won't be handled. This happens from C functions returning an int representing a pointer or a null, to getting a Python exception coming from a dependency of a dependency of a dependency. Explicit error handling can seem verbose, but is actually a powerful way to check code is correct. Finding the unchecked error in C is a lot harder than finding an `unwrap()` in Rust.
&gt; The requirement to do explicit error handling will result in error handling just not being done. This is exactly what happens when I write Python. Not because I'm lazy, but because I'm so overwhelmed by the fact that *errors can happen at any time, on any function call.* In contrast, while writing Rust, I can say with reasonable confidence that my error handling is nearly perfect. In that pursuit, I've paid a tiny cost in the amount of code I wrote and no cost in mental burden.
You probably have `I: IntoIterator&lt;Item=Borrow&lt;(K, V)&gt;`, which is subtly different from the quoted parameters. This bound requires that the item _be_ the trait `Borrow&lt;(K, V)&gt;`, which isn't viable because trait objects are unsized. What you actually want is that the item be any type `T where T: Borrow&lt;(K, V)&gt;`. This is possible using two syntaxes, the one above or another: * `I: IntoIterator, I::Item: Borrow&lt;(K, V)&gt; ...` * `I: IntoIterator&lt;Item=T&gt;, T: Borrow&lt;(K, V)&gt; ...` Writing code that's this abstract gets pretty fraught. I think (?) this will also mean that you no longer need the `'static` bound, which you may have added responding to other errors related to the compiler thinking you wanted the items in this iterator to be trait objects.
My perspective on this is that *all* panics mean "well, I'm out of ideas, I give up". You say that panics should be tagged, but then say that OOM shouldn't. Why not? The rules, whatever they are, should be consistent. The other problem is that once you start tagging panicking functions, you'll probably end up tagging a *lot* of code. Such annotations are only really useful if they're rare. I just feel like annotating panicking functions would be a big burden for not much gain. The *reverse*, however, could be useful in contexts where you absolutely can't afford to panic.
You're trying to dereference an integer. The reason is uses `_` is because you *also* haven't provided enough context for the compiler to decide *which* integer type you wanted, so it's using the placeholder to mean "I don't even *know* what type this is supposed to be". This works: fn main() { // immutable_box is of type Box&lt;u32&gt;. let immutable_box = Box::new(5u32); println!("immutable_box contains {}", immutable_box); // This *completely different* immutable_box is of type _ (fallback to i32). let immutable_box = 4; let mut mutable_box = immutable_box; println!("mutable_box contained {}", mutable_box); mutable_box = 3; println!("mutable_box now contains {}", mutable_box); } 
All panicking functions should say so in their documentation, and under what condition that occurs. If the function is implemented using a panicking facility (for example indexing a vector), but it doesn't expect to ever panic, then it does not need to document this. Any panic would be an implementation bug. See also [RFC 236, Error Conventions](https://github.com/rust-lang/rfcs/blob/master/text/0236-error-conventions.md), a very handy document.
I want to protect from unnecessary `unwrap` usage in libraries, and from other explicit panics. Maybe the library writer can't deal with an error and panics, maybe he does that by mistake (say an unnecessary unwrap which only fails under certain conditions). Maybe I can deal with the error in my code. OOM (and some others) is different as it's no explicit, and it could really happen everywhere, and there's not much to do to handle that. That's an "unpreventable" panic. So yeah, lets not tag that. But if someone used `option.unwrap` and later wanted to change to proper matching but forgot... then yeah, I would like to know about this. Much like I like I want to know which functions are `unsafe`. We do tag `unsafe`, but not panics. An undocumented panic could be just as bad as `unsafe` code. Maybe your server will crash, maybe you'll loose some data. EDIT: deleted an unfinished sentence
Because you're trying to treat a `Box&lt;u32&gt;` as an integer. It's no different to declaring an integer variable and then trying to assign a string or an array. You might want to read the [The Stack and The Heap](http://doc.rust-lang.org/book/the-stack-and-the-heap.html) chapter of the book. As an aside, you should indent your code by four spaces on each line for Reddit to format it correctly.
Thanks a lot!
You need the docs to use the function correctly. Anyway. And you like everyone else will take care to not cause any contract violation (thus panic). Regular code should not panic, it's a bug. I understand tagging or compiler support would be nice, but how do we handle the cases where we wrap panicking functions, correctly, and it *should* never panic? I don't understand what you mean by the thing with exit.
I don't think that there are just a few error handlers. Sure, it is often just the log or the UI that displays the error to the user, but for many other cases the failure is not passed straight forward but modified. For example loading a file can either cause an IO- or a decode-error. The result-aproach forces you to combine these two into one type, so that you later just have to handle the general failure case and don't need to care about the exact reason for the failure. With exceptions you can easily decide to just let the exceptions pass and handle it later but then you need to know all the errors that internally occur. 
I've often thought that it would be nice to have a user defined warnings system. There sometimes seems to be a desire, for example, to tag a function as 'unsafe' when actually it's perfectly memory safe, but simply a bad idea to use in most circumstances. A user-defined warning system would allow you to tag an unwrap() method, or an unparameterised DB method as dangerous, and only useful for specific contexts. The developer could then choose to either: * Use a different method * Explicitly acknowledge/squash the warning * Compile at a different 'warning level' The latter would allow people writing quick examples or proof of concepts to override less important/more opinionated warnings.
"preventable" panics are an anti-pattern in rust. Panics should only occur as a result of programmer error, rather than adverse runtime conditions. If a library is panicking rather than giving you the option to handle such an error via a Result type, you should report an issue.
I would like to have something like this, at least as a lint, and thought a lot about it. Unfortunately some panics like calls to `unwrap` that are never actually called and especially `unreachable!` which was made for this case are in basically every function. That means there is need for something analog to unsafe, that just enables panics and promises to never actually call them. Then how do you want the two types of unsafe to interfere? Does unsafe automatically enable unsafe_panic? That may cause unpredictable calls when someone wants to prevent undefined behavior just by calling panic before. Should you have to write both? That would add a lot of useless annotations because too often you need both. There is also the case that a possible invalid input may be discovered long time after the function has been written. Protecting against this case with a panic is easy but with compiler checks it breaks the backwards compatibility. I think we just have to accept that there is no way to make a completely safe and still usable language without escape hatches. Although I just got an idea: Couldn't rustdoc lint against forgotten panic sections on function documentation?
`do`-notation does not strictly require HKTs. HKTs would definitely help with error messages and correctness, but if we are willing to have errors like "no method named bind found for type u32 in the current scope", as well as allowing mixing different monad types in the same block and not even adhering to monad-laws, then we can just duck-type the whole thing. Having a generic `Monad` trait is *hard* since we have so many different variations on signatures which have to be considered as implementing `Monad` in Rust (due to lifetimes, explicit listing of trait-requirements for type-parameters, ownership and not inferring things in signatures). So if we really want a generic `do`-notation it should probably just avoid the whole issue of a single `Monad` trait since that would limit the use of it significantly with the current limitations on traits.
Unchecked error handling doesn't fit in a language which calls itself safe. Everybody has their opinion but I think the Rust is on the right path. Look at Java, checked exceptions haven't stopped it from becoming one of the most used languages even tho there are many haters.
Fair enough, but that would require duck typing, which is even more unlikely to happen in Rust than Hand-Knitted T-Shirts, err I mean Higher-Kinded Types
&gt; Rust is, from what I've seen, very much a language where you're forced to acknowledge and handle the edge cases. Yup. This can create ergonomic issues, but I really enjoy this aspect of Rust. Robust software is all about properly handling edge cases.
&gt; we can just duck-type the whole thing. https://crates.io/crates/mdo
If you're interested in nickel you are more than welcome! For example, I'd love to see someone create some web apps using nickel, improving documentation where needed. If you're interested in improving the framework in itself I'm sure we can find something as well. Come join our [chat on gitter](https://gitter.im/nickel-org/nickel.rs) if you want to discuss this further and get some help to get started.
This can be done with custom lints. IIRC this is already how many similar warnings are implemented, and is a well-used technique in Servo to deal with scary JS interop cases.
I strongly recommend that you read this article: https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-yuan.pdf. Your continued assertions that programmers will deal with exceptions just fine are not borne out in practice. Studies and experiences like this are a big reason why Rust does not encourage the use of exceptions for error handling.
The `Monad` trait requires it, yes, but the notation itself does not. It just requires some syntactic sugar over calling `and_then` on the values, and just leave out the `return`/`pure` method of the `Monad`, instead letting the user use the appropriate constructor (eg. `Some` or `Ok`). This will only help with reducing the noise when doing stuff like error-handling within a function, since you will avoid most of the nesting or use of `try!`. It will not help with simplifying error handling in general or being generic over monads (eg. treating `Option` and `Result` identically in a generic fashion) since that will require HKTs. There are already macros which provides the notation, one example is the one Steve Klabnik linked.
They should be, or at least it should be possible to mark a function as panic-free and have a panic-free block. But it won't happen for a while, I suspect.
Blergh, I don't think many libraries _do_ actually use it. It's more a case of people writing lazy examples (to avoid unwrap in the specific example you give you would have to wrap the thing in a function which returns `Result&lt;&gt;` and then `try!()` instead). Agreed, it would be better if the examples were better.
I am very happy to see this project blasting forward!
IMO, t's a bit more like adding `throws MyException` to `public static void main` rather than `System.exit`. Still bad real code, but OK in examples.
I think it would be better if docs used `try!()` instead of `.unwrap()`, but that requires a bit more set up in doctested examples and people are lazy about docs. 
Sure, my point is that it encourages bad coding practices. This is not a minor bug that someone is introducing, this is a hard exit to a running app.
How about imagine any `unwrap()` replaced with `assert()` calls in C. Would you want to stop C applications from using `assert()`? It's a valuable tool, it says: "if this is false, then bringing down the application is better than the alternative".
Is this reference to Discworld Octavo? Or some existing library? Anyway nice project! Great code coverage too.
Yes, you do. There is a higher level interceptor that catches the exception and let's say turns it into a standard HTTP 500 response (if let's say the request came in via a REST call). So this is the disconnect I am feeling when looking at Rust examples.
Btw - if your SQL query is not run in the main thread, not the entire process will exit, just the thread. This might be acceptable behavior in some cases, too.
Correct me if I'm wrong but doesn't Hyper also catch panics in request handlers and generate an HTTP 500?
Well, for ease, any library can add `abort()`, and suddenly you don't even get the choice to catch the panic at all. For unwrap, however, it _is_ best practice to never panic from a library, unless you're really in a situation with no alternative (usually, just return a `Result`).
&gt; this is a hard exit to a running app No it's not. It's a panic. Panics can technically be caught and recovered from if you truly need to. If a library calls `unwrap` and panics, then it should likely be considered a bug that needs to be fixed. Banning or discouraging `unwrap` is the same as banning or discouraging `xs[i]`. It ain't gunna happen. &gt; Sure, my point is that it encourages bad coding practices. Given the choice between an obfuscated code example (or worse, no example at all because they were too burdensome to write) and an example that eschews error handling, I will pick the example that eschews error handling every time. Examples are worth their weight in gold, and their existence should be valued above all else. Error handling is a thing in Rust that someone simply has to learn. [The book has an error handling guide](https://doc.rust-lang.org/nightly/book/error-handling.html) that is over 10,000 words long. It's a complex topic that is not feasible to encapsulate in short examples meant to demonstrate the specific functionality of a library.
Same here. Error handling in Rust has been the most pleasant for me personally out of any other language I've ever tried.
Ah, thanks...that is the part I **was** misunderstanding. I understood unwrap() as a hard immediate exit, not an actual panic that can be caught somewhere else, *if necessary* Thank you for the clarification
&gt; One popular criticism of exceptions is that they have hidden, or extraordinary program flow. I consider that a weak argument, but I’ve heard it used to justify monads before. If that is somehow the motivation for std::result then I should point out it fails here anyway. try! has the same perceived “problem” as exceptions: it is hiding a conditional and return statement. But using `try` is explicitly labeling the exit points, so I can't possibly consider it to be comparable to exceptions-like hidden paths.
Panic can even provide something of a stack trace if you invoke the binary with `RUST_BACKTRACE=1`: &gt; ./test thread '&lt;main&gt;' panicked at 'Oh no!', test.rs:12 &gt; RUST_BACKTRACE=1 ./test thread '&lt;main&gt;' panicked at 'Oh no!', test.rs:12 stack backtrace: 1: 0x106b74c95 - sys::backtrace::write::h71ee98355e9ff89fUss 2: 0x106b77bb0 - panicking::on_panic::h3058b136d38637c267w 3: 0x106b73902 - rt::unwind::begin_unwind_inner::h1a353d5ea12e1abeVBw 4: 0x106b7272c - rt::unwind::begin_unwind::h17668976269890081559 5: 0x106b7268e - baz::ha2208fb622832accwaa 6: 0x106b7262d - bar::heedca8669b3ae8dcqaa 7: 0x106b7259d - foo::hc378c8f72c1f3572kaa 8: 0x106b7256d - main::hb98dadea7f4ec223eaa 9: 0x106b774dd - __rust_try 10: 0x106b787cd - rt::lang_start::hd654f015947477d622w 11: 0x106b725ee - main somewhat less useful on optimised builds though: &gt; RUST_BACKTRACE=1 ./test thread '&lt;main&gt;' panicked at 'Oh no!', test.rs:12 stack backtrace: 1: 0x109c1be55 - sys::backtrace::write::h71ee98355e9ff89fUss 2: 0x109c1ed70 - panicking::on_panic::h3058b136d38637c267w 3: 0x109c1aac2 - rt::unwind::begin_unwind_inner::h1a353d5ea12e1abeVBw 4: 0x109c19b96 - rt::unwind::begin_unwind::h9166995373452891331 5: 0x109c19b0d - main::hb98dadea7f4ec223eaa 6: 0x109c1e69d - __rust_try 7: 0x109c1f98d - rt::lang_start::hd654f015947477d622w
Am I missing something, or should [this](https://github.com/zcdziura/pumpkin/blob/master/src/prime.rs#L120) be `&amp;two`. Also, is it an issue that this algorithm is far more likely to select some primes than others?
And it fits very well with the *explicit* philosophy too.
&gt; For some of us, even writing a constructor that won't leak anything when an operation can throw takes mental effort. To be fair, that's more a matter of how C++ is taught; it's extremely easy not to leak in C++ (and easier since C++11), you just have to get into the habit of not allocating memory... Unfortunately, since many C++ programmers were taught C first and then had a quick talk about "C++ niceties", they usually allocate all over the place...
All that because moves can throw in C++ :(
Of course, the problem of Java is that it cheats with its special-case exceptions bypassing the checks...
&gt; Thus, because we can be confident that the generated candidate number is truly random (or as close to truly random as the user can hope), we don't need to do more than five iterations of the Miller-Rabin test to ensure primality. Can you explain why being truly random has any bearing on primality?
I assume you meant Optional in Java? (I find Optional to be an awesome thing to have, but also *very* amusing) Option&lt;T&gt; can be null, but it's not a problem since consumers must explicitly handle it.
It's pretty subtle thing, actually (and one I should probably explain better in the README). Generating large primes is a trade-off between performance and correctness. If we had all day to create truly prime, large numbers, then we could go through the process of sieving numbers and checking the candidate against them. However, we don't want to do that since it would take a while! Instead, we go through the primality checks as laid out in the README. The reason that the randomness of the candidate matters is because it adds to the assertion that the generated number is prime. There exist a set of numbers called Carmichael Numbers which, while not prime, will pass the Miller-Rabin test. Because they're not prime, however, they aren't suitable for cryptography. Luckily, there are relatively few Carmichael Numbers, so the probability of randomly choosing one is exceptionally small. By choosing a number randomly, rather than accepting one as input, we can be reasonably sure that the generated number is, in fact, prime. I hope that helps clarify things! For a bit more reading about this, check out [this comment from another thread](https://www.reddit.com/r/crypto/comments/3n59xx/how_does_gnupg_generate_prime_numbers/cvlbvx2) (which I happened to start, full disclosure).
Wow, this is brilliant! I'm surprised I hadn't heard of doing this sort of thing before. Is validating one's behavior against another library/application that is supposed to do the same thing a well established practice?
It also leads to a lot of confusion for new people, it's a common question in IRC.
&gt; leaves open somebody forgetting to add appropriate handling. Well no, because it wouldn't compile if you didn't handle the error.
I too agree that Rust's semantics regarding error handling are good. Exceptions are black magic which often have hard to understand remote affects on your local code. Once someone changed a function somewhere else (could be even a 3rd party lib!) and your code that was perfectly fine till now is now suddenly and more importantly silently broken. Given the above, I do agree that ergonomics could be improved as others already mentioned with some syntax for general do notation. The other thing that I'm wondering is whether the type of error should be exposed in the function's signature. I think it could be more readable to have something akin to c++ nothrows() but with the reverse boolean logic: so, I'd like something like this: [throws] fn write_info(info: &amp;Info) { try { // Early return on error, threads the statements via implicit monadic do-notation let mut file = File::create("my_best_friends.txt"); file.write_all(format!("name: {}\n", info.name).as_bytes()); file.write_all(format!("age: {}\n", info.age).as_bytes()); file.write_all(format!("rating: {}\n", info.rating).as_bytes()); } } note that it is much cleaner looking and without the clutter, yet still fully explicit with the exact same semantics. 1. The [throws] handles the wrapping of the return type with a standard Error&lt;T, E&gt; wrapper. 2. But unlike exceptions I have to handle the error when calling write_info - current Rust semantics. 3. Unlike Java with checked exceptions, no need to add boilerplate that catches and rethrows exceptions just to convert YourException into MyException, instead, Rust already implements this with the From/Into traits. tl;dr - Rust has good semantics, needs more syntax sugar for better ergonomics.
&gt; I agree that `try!()` is a bit verbose, especially if you're chaining functions `try!(try!(socket.send(...)).send(...))` is plain silly. Wouldn't you use `map` and friends in those situations?
The algorithm picks a random, odd candidate along the number line and walks forward until it finds a prime. Therefore, the probability that an individual prime will be selected is proportional to the size of the gap between it and the preceding prime. The average distance between primes increases as they become larger, so larger primes will be selected disproportionately often.
Isn't this just moving errors to runtime? Or would the compiler being doing some sort of weird magic behind the scenes?
With custom panic handlers you should be able to make panic == abort for your application. I know at least Dropbox wants this.
In that case, I can update the library to randomly choose another candidate number, rather than incrementing the candidate.
I just have this dream of a utopia where all errors must be handled at compile time (I know this probably isn't actually possible).
(Assuming your analysis of the algo is correct) Even if the average distance didn't change, the fact that they aren't evenly spaced to begin with would still make it skewed to certain primes over others. For each pair of [twin primes](https://en.wikipedia.org/wiki/Twin_prime), one of them is going to be significantly more likely than the other. E: this is not to say that it's a *concern*, just that it's a *thing*.
Not just Dropbox :)
You're right, he seems to have taken something very personally.
I like my Eclipse :&lt;.
Alternatively, you may just be using the library wrong (your inputs are out of bounds or summat).
You could look in ranges. Say, look 500 odd numbers before &amp; after your given random number; if no primes are found, start with another random number. You could choose whether to look before or after by whether the initial LSB is 1 or 0.
As far as I can tell, effect systems (what you're suggesting) are bloody *exhausting* to work with. We can sort of get away with it for `unsafe` specifically because we can say "you really really really really shouldn't be using anything that's unsafe". Consequently little code interacts with this effect. Literally if you run into Rust's only effect system, you've basically fucked up (or are asserting you're brilliant). But even with unsafe, it's just a huge pain the ass when you're doing pervasively unsafe things. libcollections has historically internally used `unsafe` rather arbitrarily (including incorrectly) because "ugh who cares". It's only interesting at API boundaries.
Yea you can abuse runtime exceptions but that's frowned upon just like using unwrap() where you shouldn't. Every respected library will use normal exceptions and leave it up to the user to deal with them.
Cool! As a potential user of this library (SafeBrowsing lookups are an important part of user safety in Firefox), Servo would be most interested in being able to have more control over the network request, rather than delegating to this library. rust-websocket has a nice [example](http://cyderize.github.io/rust-websocket/doc/websocket/client/request/struct.Request.html) of this kind of API.
At that level the plan is that you could catch them. We're not quite there yet, but check out [this RFC](https://github.com/rust-lang/rfcs/blob/master/text/1236-stabilize-catch-panic.md).
You're looking for /r/playrust.
See the front page for Feed and iTunes links: http://www.newrustacean.com/
No compiler magic needed, just translate the syntax to method calls and let name resolution select the instance (like [rust-mdo](https://github.com/TeXitoi/rust-mdo)). I mean, the *magic* here is the method name resolution itself. Two different types may implement the `.test` method, so calling `a.test()` selects the right method when the compiler knows the type of `a`. What doesn't work is making code polymorphic to accept any type that implements `.test` (one would need traits for that).
Actually I need to mark that Octavo is unsafe and no one should use it yet more explicitly. There was voices to make it Crate of the Week twice, and twice I need to vote against. Not that I don't want that, but Octavo isn't ready yet. There is a lot work to do (AES, DH, ECDH, RSA whitening, etc.) and a lot of documentation to write (everything what is written till now should be marked as deprecated, I need to rewrite it ground up).
About a month ago, I figured I should look at Rust again. The last time I picked it up was around version 0.3 when I used it primarily to solve the [Matasano crypto challenges](http://cryptopals.com/) (They seem to be in a bit of a flux right now. When I was working on it, there was one guy reading through all code submissions manually, and then sending the next round of challenges if you passed. Obviously, if you challenge the internet, that's not a viable strategy. So right now, they seem to have published all challenges, and people grab them as they please. If you're looking for small, modular projects that will nevertheless challenge you, I can only recommend them.). Anyway, I was looking for a small project, so that I would be able to enjoy some results, but still it shouldn't be Hello World, or how to sort a big batch of numbers. I wanted a sort of project, where I would stumble over things that I might encounter in the real world using Rust. Brotli seemed like a good sized project, while still being fairly low-level with many small details that all need to be right for it to work. So, with virtually no knowledge of Rust (it differs so much from 0.3 now, that it could just as well be a different language), and no prior experience in compression, I set on the journey. It was fairly demanding, took me about a month, had me ask so many dumb questions on #rust (all of which have been answered very helpfully and friendly without exception), got me a small mention in Google's brotli repo for making the tiniest suggestion to simplify the spec draft, and actually taught me a lot about borrowing, moving, and how to properly fear any mention of lifetimes. While the implementation as it is right now decompresses all the test files in https://github.com/google/brotli/tree/master/tests/testdata it is not fully complete yet. It's only a minor part, that should be merely typing work, without a lot of thinking required, but it needs to be finished before it can really be considered a complete implementation. This detail is the word transformations – in case anyone is familiar with Brotli – that can be applied to words referenced by a distance that reaches into the static dictionary. Also, the code is not optimized, or even tidied up. I was so excited when I finally saw all green "ok" from the test runner, that I couldn't wait to upload the project. For sure, I will organize the code better, probably allow a consumer just to pass a &lt;Read&gt; instead of requiring a BitReader, figure out how to optimize for speed while maintaining some readability. Oh, I would probably also remove the deflate and gzip parts. I implemented those before Brotli to learn a bit more about what I should expect from the lz77 family of compression algorithms. They ended up in the same repo. Maybe they can stay, and it will be a family of compression algorithms. And now I realize I'm rambling. I'd be happy about feedback about anything, really. Documentation, idiomatic Rust, speed improvements, repo structure on Github. I know I have committed many atrocities in all of those topics, and I would be very happy to correct them. 
So, about this example, fn write_info(info: &amp;Info) -&gt; io::Result&lt;()&gt; { let mut file = try!(File::create("my_best_friends.txt")); // Early return on error try!(file.write_all(format!("name: {}\n", info.name).as_bytes())); try!(file.write_all(format!("age: {}\n", info.age).as_bytes())); try!(file.write_all(format!("rating: {}\n", info.rating).as_bytes())); Ok(()) } What would be a good way to minimize the calls to `try!`? Perhaps using `.and_then` and friends?
[Brotli](https://en.wikipedia.org/wiki/Brotli) seems to be a decompression algorithm for anyone else who had no idea what this was. [EDIT] FWIW, I probably half expected to see pictures of broccoli.
Yes, sorry. I've been so immersed in the project that I completely forgot that not everyone might know every detail of it. Brotli is a decompression algorithm developed by Google's Jyrki Alakuijala and Zoltan Szabadka. The claim is that it improves compression by roughly 20% (on text files), while remaining comparable in speed. If it can live up to those numbers, it could have a substantial impact on online traffic. Some browsers (off the top of my head citation needed) already accept brotli: encoding, and I'm pretty sure I've seen a module for nginx somewhere. Widespread adoption might take a little longer, but I think it would be worth it for ~20% savings.
&gt;Google's Jyrki Alakuijala and Zoltan Szabadka. As an aside, those are some awesome names. Completely unpronounceable (except for maybe "Zoltan") but awesome nonetheless. 
Jyrki and Zoltan sound like a duo of fantasy heroes.
Are you going to release a crate on crates.io? Would it be called compression or would you rename it to something else? Documentation for most crates are built by travis (automatically with each push) and linked on the readme like [libc](https://github.com/rust-lang-nursery/libc) does.
I agree, the examples are written as if the user already knew how to do proper error handling, but this is not always the case.
For algorithms with non-trivial output (where direct verification isn't easy), it is reasonably typical to use a reference implementation of it to compute what the output should be. That could either be a naive version that's much slower/more specialised but is "obviously" correct, or an external library that's considered reasonably reliable.
I particularly like the external library approach because it serves as a circular integration test. Regressions/bugs in one can reasonably be detected by the other. Would be really cool if Octavo started finding bugs in OpenSSL because of this (I don't really expect their bugs to be so shallow, though).
I think that's why lots of modern research on effect systems is focused on effect inference, so it may be something feasible to add at some point... depending on how far Rust is willing to budge from "everything's in the signature" anyway.
Are you wanting something like this? (Playground link: https://play.rust-lang.org/?gist=88b7d783f1a82a415a5f&amp;version=stable) use std::io; fn lock_stdin&lt;'a&gt;(stdin: &amp;'a io::Stdin) -&gt; io::StdinLock&lt;'a&gt; { stdin.lock() } fn main() { let stdin = io::stdin(); lock_stdin(&amp;stdin); }
Oh, the shields at the top (for example, [serde](https://github.com/serde-rs/serde)) are found from http://shields.io/ and can be applied like the top few lines of [this readme](https://raw.githubusercontent.com/serde-rs/serde/master/README.md). People use them to link to travis, coveralls, their license, or just to list the version number (there are a lot of icons). Gotta make everything pretty.
&gt; yet still fully explicit with the exact same semantics I would argue it is not precise. The issue with wrapping a bunch of code in a `try` block is that, just by looking at that code, I have no idea which call or calls in there might return an error. What's wrong with using `map` and `and_then` and the like?
I can argue in a similar tone against any higher level abstraction, e.g. using iterators isn't precise and just by looking at the code I can't know where the loop counter is modified. Why not just use regular for loops as in c? A try block as I explained is just syntax sugar for and_then() and map() calls. This is called do notation in Haskell. And this removes redundant boiler plate details. 
No, the idea was to pass in a string and return an enum that might contain a StdinLock or other things. I suppose its not the end of the world if I require the caller to pass in a Stdin that might not get used.
A commenter on HN noted that there was a bit about this published in the journal Bioinformatics the other week: http://bioinformatics.oxfordjournals.org/content/early/2015/10/19/bioinformatics.btv573
Previously here: https://www.reddit.com/r/rust/comments/3og2ro/rustbio_a_fast_and_safe_bioinformatics_library/
You can use `lazy_static!` to create a `Stdin` with a `'static` lifetime so you can then have a `StdinLock&lt;'static&gt;` guard: Cargo.toml: [dependencies] lazy_static = "*" Code example: #[macro_use] extern crate lazy_static; use std::io::{self, Stdin, StdinLock}; lazy_static! { static ref STDIN: Stdin = io::stdin(); } pub fn stdinlock() -&gt; StdinLock&lt;'static&gt; { STDIN.lock() } It's not an optimal solution (`lazy_static!` introduces an unavoidable leak because Rust won't run destructors in statics) but it's surprisingly concise, and it works. I guess the only real concern is that this locks stdin as long as the lock guard remains, which could be putting yourself or your library's users at risk for deadlock if they try to read from a different instance of `Stdin` on any thread (as locks in Rust currently aren't reentrant AFAIK).
Might be cool to have a short list in the next release blog post. BTW, I've successfully run `cargo install --git https://github.com/killercup/cargo-edit.git cargo-edit` and `cargo install --git https://github.com/nrc/rustfmt.git` :)
Do you plan to add a compressor? 
It's scheduled for the 29th of this month (about a week away).
Some "allocation" failures are panics, like requesting a `Vec` with capacity that would be too large.
You can write a macro that allows writing multiple tries, e.g.: macro_rules! try_all { ($($e: expr);*) =&gt; { { $( try!($e) );* } } } which would allow writing that code as: let mut file = try!(File::create("my_best_friends.txt")); // Early return on error try_all! { file.write_all(format!("name: {}\n", info.name).as_bytes()); file.write_all(format!("age: {}\n", info.age).as_bytes()); file.write_all(format!("rating: {}\n", info.rating).as_bytes()) }; Ok(())
Cool! If that's really the best way to express this, perhaps `try_all!` should be defined in the stdlib.
&gt; I couldn't quite figure out how to create a collection of functions. See [this playpen](http://is.gd/VjpAzI). The trick is to specify the function pointer type explicitly somewhere. Every function has its own, unique type, so you need to give the compiler enough type hints that it knows it needs to coerce them to a common type. Also, there's really no point in returning `String`; `&amp;'static str` will work just fine and not require any allocations.
Seems like a silly but fun and good for learning project! ☜(⌒▽⌒)☞ I should try something similar when I get to test the waters. One question I have is, in your macro, why do you use a f32 (floating point) instead of a, say, i32 (integer)? Shouldn't all expressions length be integers?
I'm working on challenges from /r/dailyprogrammer trying tondo as many as possible using rust even if that means making a dylib to call from Python
The verbosity of `try!` is a bit annoying and hopefully we're getting the syntactic sugar `?` for it, but the conversion of error types with the `From` trait is really great and there's a reason why a lot of Haskell code using the `Either` monad has a `String` as its error, because the conversion between different error types is annoying.
`expect()` only panics with a different error message. A big problem is `Err()`s with no error message.
Maybe that will happen one day. Currently it is much to early for that. Currently I am looking for any kind of support for the project. After first release I want to start BountySource campaign for Octavo to keep developers and users attached to project. Yesterday I've added [GetBadges](https://liboctavo-octavo.getbadges.io) game just for fun, but if this will help me to attract people then I would be very happy :)
Hehe, having many Polish friends and colleagues, Szabadka didn't actually strike me as that exotic. :) I probably would have spelled it Sobotka if I hadn't seen it written out, but I wouldn't have had thought twice about it being hard to pronounce or remember.
Unfortunately it's not there because the alternative is worse - it's there because someone was lazy or didn't know better. 
Alternatively, if you _really_ want to do things at runtime, you can have the annotations on the vector: https://github.com/timClicks/cool_faces/pull/4/files
Counter-example: a simple config library shouldn't be able to terminate a service holding the state of n customers just because of a utf-8 encoding problem in a dynamic config update. 
In the meantime, this might work (but doesn't look pretty): /// A doc test using `try!`: /// /// ```rust /// # { /// let x = try!(package.open()); // danger, might explode /// x.insert("valuables", 42) /// try!(x.close_and_reactivate()); /// # }.unwrap() /// ```
I still don't like the idea of storing binaries in yet another place on my system. I'd have preferred `/usr/local/bin/` - is it too late to change?
There's also [a calendar](https://calendar.google.com/calendar/embed?src=mozilla.com_ts4qudb88i0tbjef8rche4a6v4@group.calendar.google.com&amp;ctz=America/Los_Angeles).
Every test having to return a result seems a bit every handed. Not all examples can fit neatly into a single function. Certainly, this space is worth experimenting with though! I'm not actually sure what this has to do with `#[test]` though. In this context, we're talking about doctests, which serve as both examples and tests.
&gt; Just in case you weren't aware, Ramp implements overloads for Int/primitive pairs that are often more efficient. At the very least, they avoid needing to allocate for the small number. Oh, I didn't notice that. Thanks for pointing that out, I'll make a few changes then!
Just don't call it bro, it's _problematic._
FYI, I have now followed your suggestions, and * integrated with Travis, using travis-cargo (thanks, huon!), * auto-generated [documentation](http://ende76.github.io/compression/compression/), again using travis-cargo, * added a shield to the README to indicate build status. I plan on adding a shield for the current version at some point, because I generally found them useful when I was looking at crates myself. Again, thanks a lot for all your help, your suggestions have been invaluable to me to figure out some standards that simply are expected of current projects.
Is there a list somewhere that shows what's in 1.4? Same for nightly.
Great episode! Minor, nitpicky feedback: all of your examples for returning an Option are where I'd return a Result, as they're all about _errors_. Over-using Option is really common for people coming from dynamic languages to a language with optional type. "I used null to indicate errors in Ruby, so I'll use Option in the same cases." * Option: presence or absence * Result: success or failure But like I said, this was really minor: using option in those cases would be sub-optimal (😉), not outright incorrect.
That's a good point. You're right that they use the non-lookup API.
The standard used in the stdlib is /// A doc test using `try!`: /// /// ``` /// # fn f() -&gt; io::Result&lt;()&gt; { /// let x = try!(package.open()); // danger, might explode /// x.insert("valuables", 42) /// try!(x.close_and_reactivate()); /// # Ok(()) /// # } /// # f(); /// ``` (Also, note that it is not conventional to use `rust` in API docs, and you can omit the call to `f()` if you want the same as `ignore`.)
I assume you're trying to make somekind of fixed timestep routine. Check this link http://gafferongames.com/game-physics/fix-your-timestep/
For anybody looking for a good beginner project, integrating this into Servo should be fun and edifying! You're going to want to hook into [StreamedResponse::from_http_response](https://github.com/servo/servo/blob/master/components/net/http_loader.rs#L407) as well as modify `set_default_accept_encoding` as well. See the [github issue](https://github.com/servo/servo/issues/8156).
Use `RUST_BACKTRACE=1` to find the location of the panic.
My go-to set of things that make Rust code nicer: - Run [rustfmt](https://github.com/nrc/rustfmt). - Add this to your `lib.rs` file(s): `#![deny(missing_docs, missing_debug_implementations, missing_copy_implementations, trivial_casts, trivial_numeric_casts, unsafe_code, unstable_features, unused_import_braces, unused_qualifications)]` and fix stuff until it compiles again. - Use [clippy](https://github.com/Manishearth/rust-clippy) (e.g. [like this](https://github.com/killercup/vibrant-rs/commit/ed503e49ee1aa9e87552965eb7ffa7ef016b00e8)) and fix even more stuff until it compiles again :)
I figured as much. I may implement that, but it's not something I plan on doing too soon and it's a fairly complicated protocol and Firefox would probably want fine grained control over it. My next projects are the virustotal API and a whois library. I may revisit GSB afterwards.
If you're using unwrap/expect as an assertion in "production" you're running an optimised build and not under backtrace, [which would probably be useless and/or unreadable anyway](https://www.reddit.com/r/rust/comments/3pn25i/should_unwrap_be_banned_or_discouraged/cw7swdi).
It's a setup I made for my latest project so I thought why not share for those that wish to have a similar setup!
[`Iterator::cloned`](https://doc.rust-lang.org/stable/std/iter/trait.Iterator.html#method.cloned) does exactly what you want.
[Rendered](https://doc.rust-lang.org/nightly/book/documentation.html) or [source](https://github.com/rust-lang/rust/blob/ca998fc2f100bce4eab9b4609bd5a0a5c5789872/src/doc/trpl/documentation.md), there is no `try!`: https://github.com/rust-lang/rust/issues/29234
Yeah I wasn't sure what was appropriate here, but thought to myself... Hey repeatedly doing the same thing, why not try out a macro?
What range does `rand::random&lt;i32&gt;()` return? Is there an equivalent of Python's `random.randint`?
Thanks a lot! I did work through the hundreds of complaints that threw up. At the very end, I had to remove missing_docs, because it complained about missing crate documentation, and I couldn't figure out where to those doc comments. After my sort of "traumatic" experiences with 0.3 way back, I'm sort of hesitant to switch to nightly, which it appears I would have to do to use rustfmt and clippy. I might do that at some point, but would like to reserve that for a later time, when everything else is settled. I do absolutely want to use those tools. I have already received and merged a pull request that fixed a ton of stuff that I had not been happy with, just by following suggestions from clippy, so clearly those have very good value. 
Thanks very much for this. I was struggling a little bit with the signature. Returning `&amp;'static str` agrees with my intuition. For some reason, I thought it would be more polite to return `String` to the calling function as the data will be copied out from my module
Just wanted to say thanks to everyone for their comments and PRs. Really appreciate it.
It would be helpful if the Community Calendar linked on the front page showed Rust releases.
I guess posting an offer and linking the url here would make the deal.
Due to Rust's newness I think it's actually more along the lines of not enough jobs so there's a lot of passionate Rust users out there who'd be willing to take a job that involves Rust.
I think what you are looking for is "a type of kind `* -&gt; *`". (Not a monad, necessarily, but the type parameter `m` for a monad is required to have kind `* -&gt; *`). 
Oh, I definitely agree that true randomness matters; I just don't see why it would affect the primality checks.
If I recall correctly, one case is that not all allocators are relocatable and therefore the supposed move devolves into a copy (ie, a stack allocator might inhibit the move operations applicable to its container to avoid issues)
Thanks!
I can see where he's coming from. He uses this feature, likes the advantages, sees no disadvantages, has written extensive tests, knows from experience that it's useful to have and only wants to see it as experimental flagged feature for others to try out. Why not?
I haven't looked at the crate enough to know if this is impossible or not (but I don't know why it would be), but I'd replace any functions that take a Url/&amp;Url with one that takes T: AsRef&lt;Url&gt; or Into&lt;Url&gt; to make it more generic and have a nicer interface.
Because the rabin-miller primality check is stochastic, not determinate.
This might be a dumb question… Does servo require nightly?
I don't necessarily disagree with what he's saying, but he's behaving as if them not include the PR is a personal affront to him. I dunno, I just don't think the way he was behaving was particularly helpful.
One does indeed exist already: https://github.com/rust-lang/rust.vim Not sure what the differences are. Oh. Your repo is fork of it. I thought it already had syntastic support? What did you add?
i think he just got increasingly frustrated. we’ve all been there i guess. i’d say, with no commitment to be made, maybe they can simply trust him and merge his complete, test-laden patch as experimental feature
FWIW, the comment wasn't quite on topic, so people may be correct in downvoting.
Couldn't we just add drone.yml file to our github project ( of course drone would has to authorized to github repo) and get a build ? Something on lines of what Travis does for rust projects?? Last time I checked drone did not have inherent support for rust projects..
Ok, I asked because I couldn't work out how to compile it against nightly on Travis. I would get an error similar to "…does not have feature `nightly`". I'm sure it's a trivial fix, but I couldn't get to it yet, because a few dozen other trivial things were in line first. ;)
I am not quite sure what you mean. When you add a .drone.yml file you are not adding drone support right away, you merely provide a configuration file so that if drone is enabled it knows what to run in which docker container.
Eh, I tend more towards neutral, but I suppose that's a matter of opinion and hard to pin down to hard guidelines.
You're welcome :) (I assume the missing crate docs were `//! abstract docs` in the `lib.rs` and `mod.rs` files? Edit: [Yep](https://github.com/ende76/compression/commit/2824fee5034650603658952bb6d9650014cc8783).)
Oh, one more tip. In docs, separate paragraphs with empty lines. This way, rustdoc renders them nicely. (Docs are actually rendered as markdown.)
It was //! Documentation here At the very top of src/lib.rs, as opposed to ///! Documentation here which is how close I got, before I gave up thinking I couldn't possibly figure it out by myself. ;)
Thanks :) I was a little skeptical about testing it out... 
Neither can it be joked about because that's not ok.
Yeah, it isn't a general parser, it's very tuned for this specific benchmark. We could do the same, in theory.
It has only rustc -Zno-parse checking support, which does not take into account things like unused variables, unused imports, invalid imports, type errors etc. They basically don't tell you any more than syntax highlighting does. Cargo's error messages are much more helpful, and Clippy's are even more helpful still. I've got ```let g:syntastic_rust_clippy_post_args = ['--release', '--', '-Dclippy', '-Wclippy_pedantic']``` in my .vimrc, which warns on use of unwrap and so forth. EDIT: changed to accept ```g:syntastic_rust_clippy_pedantic```
Regular garden-variety vim ```make``` supports cargo too, this is just for Syntastic. Also, ```make``` (and I assume ```neomake```) do the transformation step, which takes a lot of extra time if you just want to check program correctness. The standard rust.vim clist support for the make command is also not great, it prints out a bunch of things that aren't errors (this might be fine in neomake).
I am not sure it is tuned for this specific benchmark, at least this is not the impression I got from the post on dlang.
I was wondering on how to setup drone build for a github project; on the same lines of travis. say if i have https://github.com/harrydevnull/redis-rs/blob/master/.travis.yml on my github project and is configured on travis; it would build automatically on travis. i was trying to emulate the same behavior on https://drone.io/ 
There was some discussion on the Redox chat whether this was OK or not. It was pointed out that a number of other RFCs had similar +1 or thumbs up with no additional comments. Not that it's right, but its where they were coming from. 
I very much doubt that algebraic traits like `Field` or `Ring` would make it into `std` in one hop. Putting those into a separate crate is definitely the right path here. If those traits are indeed broadly applicable, then they could wind up in `std` if the crate proves popular (but I doubt they are broadly applicable *enough*). Perhaps they could end up in a blessed crate or something though.
The only novel thing it's doing is not validating that the unread fields are valid JSON, which seems pretty sound to me. If I tell serde to deserialize some JSON to a struct I honestly couldn't care less what any fields not specified by my struct look like. Other than that it can do SIMD because it knows it's working with an array, and not a general stream.
To be clear, I'm doing an ELI5 in that post. I skimmed the code (without knowing D) and nothing is actually hard coded for the benchmark but the code is obviously designed for this use case. If your goal is only to extract the data you care about does it really matter if the parts you don't care about are valid or invalid?
Well, I use cargo-clippy and cargo -Zno-trans respectively, neither of which do a full compilation. You're right though, it does take significantly longer than the rustc Syntastic extension. I use it with Syntastic's passive mode and have ```:SyntasticCheck``` and ```:Errors``` bound to a key combination.
&gt; unwrap() is not simpler (and less idiomatic) than try!(). &gt; &gt; Can't we modify #[test] (and the equivalent doc system) to support fns that return a Result? I hope we can, because that sounds like a good idea to me, but in practice, there is more than one `unwrap`/`try!` in an example, and often they have different types. If the fn returns a `Result&lt;T, E&gt;`, what is then your `E`? `Box&lt;Error&gt;` maybe? That's the question you don't have to answer when you use `unwrap()`, which is why I call it simpler.
Hmm, ok, so I guess that's another idea for a crate for me ;) Are you (or anyone reading this) maybe aware of any crate that implements something similar? I wouldn't want to duplicate someone else's work.
[This-week-in-Rust](http://this-week-in-rust.org/) has a section about job offers. It's usually empty, which is a bit sad. Give them a shout at e g @ThisWeekInRust on twitter and likely you'll get some free exposure for your job offer :-)
That doesn't say it's tuned for a specific benchmark, just that the parser skips entirely over unused sub-structures. In a way that's an idea similar to boyers-moore, don't check/process what you don't care for.
The [`num`](http://doc.rust-lang.org/num/num/traits/index.html) is the closest thing I know of. It has `Zero` and `One`, but not any of your algebraic traits.
Except that you probably want to make `f32` and `f64` an instance of these traits … and addition on those is not associative.
Speaking of blessed crates, is there a list of them somewhere? I assume a crate is considered blessed if its docs are hosted on rust-lang.org (eg regex, time)? I've stumbled upon a few of them by googling.
https://github.com/rust-lang-nursery
Ahh. Passive mode is the trick. Nice.
thanks, it works now. What would clamping delta time look like?
If we get specialization with the [lattice](https://github.com/rust-lang/rfcs/pull/1210#issuecomment-139635004) rule you'll be able to write: ``` trait Either {} impl&lt;T&gt; Either for T where T: TraitA {} impl&lt;T&gt; Either for T where T: TraitB {} impl&lt;T&gt; Either for T where T: TraitA + TraitB {} ``` But currently, you can't do this purely in traits because it's unclear which implementation applies.
The important question is: How often do you need the specific properties of such traits and how much time is needed to write every possible function in a generic instead of straight forward way? I don't consider it that important to have specific types in a library. In Mathematics it is often important to know that an inverse exists but in programming you ensure the mathematical properties before. When you specify that a type needs to support `Add` and `Zero` then you can expect it to have some monoid-like behavior and don't need to manually encode everything. Another example: how often do you work with generic vectors? You either have an application for mathematical computations one generic vector type present or you need some specific but fast for computer graphics (like 3 dimensions) and don't need to write code that works for both cases. Even Haskell does not have most. It makes extensive use of Monoid because that has some properties that become useful with the MonadPlus type and some fold-variants but often you just specify some behavior and let the programmer ensure the correctness manually.
I was thinking of something along the lines of `algebraic-traits`, but maybe that's narrowing the scope a bit too much (I can't really think of what could belong there except what I already mentioned in the OP). Do you have any suggestions about what could be included in such a crate?
I was wondering if there was a good way to do that. Thanks a lot, will make that change soon. If I don't get much more feedback I'll probably write some more tests and slap 1.0 on it.
Right. I'm not saying it's not valid, even. Just that it uses an aspect of the benchmark that the other implementations don't. So you can't really draw a decent conclusion about this until they all do the same thing. Or at least, you can only draw certain kinds of conclusions.
This is a bit of a misnomer. `f32` and `f64` may not be conventionally associative, but that doesn't mean our intuition about them really needs to change. For `a, b, c : f32` it is fine from a programmatic context to assume `(a + b) + c == a + (b + c)`. Yes, there are instances where it matters, but the spirit of association of generic types wont overlap with algorithmic error concerns (which can be applied regardless of the underlying type). The automated tests proposed could then add in the missing detail, i.e. the actual pseudoassociative law: `(a + b) + c == a + (b + c) + O(e)`. Where O(e) &lt;= machine epsilon. This is of course assuming you're working with IEEE 754. I'm not too familiar with hardware or fringe architectures, but that seems reasonable to assume. As a runtime check this seems reasonable.
&gt; There's no support for MP3 or FLAC. The only crates to decode these formats are under GPL. If its GPL 3.0: For people that self-compile, that's no issue. The Apache License is compatible with the GPL and only of interest if you distribute the result. So, for personal use, having a feature that turns the binary into something that must be shipped by the terms of the GPL is fair. 
I was guessing/hoping that the doctest changes could work similar to #[test] -&gt; Result changes. Maybe a #[test_result] (so the test harness would expect a Result). Again, not doctest specific - but perhaps there could be a reusable way to define doctest fns that returned a result too? Edit: I suggested #[test_result(T, E)] below. Maybe some ideas there? 
I vote make the separate crate! It would definitely be interesting to play around with.
And direct link to the design patterns (WIP): https://github.com/nrc/patterns/blob/master/README.md
I'd like to try another example. Someone mentioned the Rust PostgreSQL library only had 3 uses of unwrap. Great, but... what if 1 use of unwrap was when the postgresql server process was dead and the author of the library decided to unwrap() instead of returning a Result. This is bad because if I had a Result I could handle that by talking to the backup server instead of crashing my app. I apologize if this is actually a StrawMan. I just wanted to make the point where I think it's justified to be worried that library authors may use unwrap/panic in ways that seem logical but in fact arm land mines I may step on later. It would bring me comfort if a library advertised that it would not intentionally cause a panic. 
Sure, but if .add_event() is moved to EventQueue, then deconstruction is not required. You can mutably borrow each member of self inside the function independently. But once a member is mutably borrowed, self cannot be passed to any function or method, even if they don't touch self or its parts at all, that's the problem.
&gt; After my sort of "traumatic" experiences with 0.3 way back, I'm sort of hesitant to switch to nightly, which it appears I would have to do to use rustfmt and clippy. One good trick is to use [multirust](https://github.com/brson/multirust), and then just use nightly when you need it, for features like rustfmt/clippy, e.g. [`multirust run nightly cargo clippy`](https://github.com/arcnmx/cargo-clippy).
Thank you so much for the link. I'm going to read it and share it with conference organizers at school. &gt;They were unprepared, and that is squarely the fault of the FOSDEM organisers for not providing proper procedures and training. I really cringe when I go to a conference/hackathon/whatever and it feels like the organizers are winging it. You put a few hundreds (E: or thousands!) of strangers together in a room, many of them socially awkward - lots of things can go wrong. Are you aware of any work that collects best practices on the subject? Whether a blog article, a management book, whatever.
Thanks a lot, I will absolutely consider this! Seems like the best of both worlds.
don't forget Default as a trait, very common in library design where the result is the default for the type. 
when linking to github lines numbers, make sure you pick a commit first, that way the link stays relevant
I actually wonder how mature it is, at least relative to usual multirust. The latter always worked flawlessly for me. Is it worth trying to upgrade?
An option is to code things generically, but only stipulate requirements that you actually need for each operation. This requires a separate trait for each operation with an associated type, and some extra boilerplate, but it works well. For example, here is how I've implemented the dot product between 3-vectors as generically as possible: pub trait Dot&lt;N = Self&gt; { type Output; fn dot(self, rhs: N) -&gt; Self::Output; } impl&lt;M, N&gt; Dot&lt;Vector3&lt;N&gt;&gt; for Vector3&lt;M&gt; where M: Mul&lt;N&gt;, &lt;M as Mul&lt;N&gt;&gt;::Output: Add, &lt;&lt;M as Mul&lt;N&gt;&gt;::Output as Add&gt;::Output: Add&lt;&lt;M as Mul&lt;N&gt;&gt;::Output&gt; { type Output = &lt;&lt;&lt;M as Mul&lt;N&gt;&gt;::Output as Add&gt;::Output as Add&lt;&lt;M as Mul&lt;N&gt;&gt;::Output&gt;&gt;::Output; fn dot(self, rhs: Vector3&lt;N&gt;) -&gt; Self::Output { self.x*rhs.x + self.y*rhs.y + self.z*rhs.z } } ``` Doing it this way would even let you use the same vector type, for example, for an inner product space and for a more restrictive vector space.
The IRC channel links on the community page all employ the `irc://` protocol. For the subreddit sidebar I link to these channels as well, but instead of `irc://` I just link to the channel via the mibbit web client. Something to consider. For the User Groups page, how does one get their user group listed there? Whose job will it be to de-list user groups when they go dormant?
https://internals.rust-lang.org/t/casual-rfc-for-rust-playpen-upgrades/2820
\#protip: press y. On any page.
/u/acrichto, /u/Diggsey, /u/edunham and I are working on a plan to completely overhaul the Rust installation and distribution experience, replacing the shell-based rustup.sh/multirust/rust-installer combo with rock-solid Rust code, largely based on Diggsey's work here. I would be cautious though - the existing shell scripts are quite well tested, and this project is still in something of a prototype phase. And furthermore I expect we'll (Diggsey will) yet be making a number of significant design improvements over the current multirust experience. Still, give it a try, report and fix bugs. Nice work, Diggsey. 
https://doc.rust-lang.org/std/collections/#entries https://doc.rust-lang.org/std/collections/hash_map/enum.Entry.html
whoa awesome :)
I updated ArcadeRS to rust-sdl2 0.9 last week, and I'm almost finished writing ArcadeRS 1.7 (image rendering &amp; Rc&lt;RefCell&gt;).
Glorious. &lt;3
I think i tried `grep -c` but it printed the number of matches on each line grep parsed, not the total number of matches found in the directory. I had to redo it with `wc` to get it to work.
&gt; What irks me is that rust keeps calling itself a systems language, and its design goals are oriented around giving me control and speed while keeping me memory safe. I really strongly agree with this. Although I do like Rust as a language right now, its constructs are very high level and not actually geared towards systems programming. The core features Rust has are mostly focused on safety, and they work fantastically. Most of the few lower-level features are unstable and will be for the foreseeable future, which would be fine without the stigma the community seems have against using the nightlies. Rust isn't really in a position to advertise itself as a competitor to C/C++ because, frankly, it can't do a lot of the cool things those languages can. I understand that features like SIMD support, in-place allocation, making syscalls directly, and more are on the way, but calling Rust a systems programming language implies that they're already here.
Ah, it reports per-file in recursive mode, and so do all those other tools by default. There is `ack -ch` then, or just carry on with `|wc -l` :)
Default doesn’t really have any algebraic laws that make it meaningful, though. In Haskell, at least, I’ve only ever used it for configuration objects, to produce some set of reasonable defaults that I can play around with—e.g., in the REPL, or with a library I don’t understand yet.
A thousand times this. Really.
First, thanks for pointing out that I forgot to merge the CI fixes to nix master. I fixed it on a branch but forgot to merge. It wasn't anything related to nix being broken but Rust changed the directory layout of some files and I used some hacks to get nix to run 32 bit CI. Second, Rust doesn't currently have signal handling **exactly** because it is a low level systems programming language. It turns out that implementing signal handlers correctly is very hard (see discussion here: https://github.com/carllerche/mio/issues/16). Other languages that you may be thinking of (Java, Go, Ruby, Python, whatever) live in the warm embrace of a VM that can coordinate the complexities of signal handling with the execution of the language. Rust does not have this. You also get signal handling in languages like C &amp; C++, but unless you know exactly what you are doing, odds are you will shoot yourself in the foot. I'm hoping that somebody who does know what they are doing (not I) steps up and writes a high level signal handling library that covers the 90% case as well as guards against as many potential bugs as possible...
RAII guards are even more convenient in Rust than C++ because lifetime semantics prevents the reference returned by the guard from outliving the guard. You can safely handle all sorts of resources this way. See, for example, RefCell for which borrow/borrow_mut create guard objects that look and feel like `&amp;'a T`.
&gt; features like SIMD support, in-place allocation, making syscalls directly They *are* already here... on the nightlies. :P
Default is great for configuration objects. I agree that no one seems to use it though # Example let some_lib_config = Configuration { customized_field = 5, // I want to change this .. Default::default() // Defaults are fine for the rest };
Eh...I don't really use webapps. The only one I know I use is email and for that I use a local client. But I'll take your word for it.
Ok, it won't assume responsibility to dealloc the underlying memory, but who will ever take responsibility for deallocating the actual slice? A reference to a slice involves at least these three things * (1) a pointer to some RAM * (2) a size * (3) a whole bunch of stuff stored in ram, starting from the pointer Obviously the slice won't dealloc (3). But who will deallocate (1) and (2)?? When my reference to the slice falls out of scope, nobody is going to deallocate that... The docs say &gt; The lifetime for the returned slice is inferred from its usage. To prevent accidental misuse, it's suggested to tie the lifetime to whichever source lifetime is safe in the context, such as by providing a helper function taking the lifetime of a host value for the slice, or by explicit annotation. But I confess I have no idea what "inferred from its usage" means. If I put it in a box, will it die when the box dies?
Not to state the obvious but they have been [busy implementing the almost 60 RFC PRS which merged](https://github.com/rust-lang/rfcs/issues?utf8=%E2%9C%93&amp;q=merged%3A2015-05-15..2015-10-23+) since 1.0 which cover a huge variety of different topics. On top of that, there's [almost 50 more](https://github.com/rust-lang/rfcs/pulls) undergoing discussion before possible implementation. Have a little patience. You're comparing a language a few months after release to languages which have been out for years or even decades. It takes a little time to ripen.
Wow, there really is a Java class called [AbstractSingletonProxyFactoryBean](http://docs.spring.io/spring-framework/docs/2.5.x/api/org/springframework/aop/framework/AbstractSingletonProxyFactoryBean.html). Naturally it's a "convenient proxy factory bean superclass for proxy factory beans that create only singletons."
What does the .. operator do exactly?
The expression after `..` should evaluate to the same type as the struct it appears in, and all of the fields that aren't identified will be taken from the struct that expression evaluates to, so this will set all of the other fields of the `Configuration` type to the values defined in `Configuration::default`.
C++ does not have SIMD support, does it?
So, are you surprised at seeing an aptly named Java class? Or at the fact that someone deemed such a class useful enough to write it? :-)
I'm about 65% sure that the author of that class did it purely for giggles.
Thank you so much /u/llogiq. I want to keep you updated. Fortunately, I have a mentor willing to train me in his spare time. Once I am familiar "enough" with Rust lang, I will look into the issues you mentioned, and hope that you and my mentor could help me improve :)
I've never waded into the internals of Spring, so I can't answer that. But I question whether I'd arrive at a similar design if I set out to create a Spring clone. Do we have any rust dependency injection frameworks of similar scope for comparison?
GCC Clang and MSVC all have support. Standard c/c++ do not.
&gt; Anti-patterns &gt; TODO thread + catch_panic for exceptions Isn't catching panics by the parent thread pretty much the only way to create a fault-tolerant Rust app?
Is it gstreamer inspired?
Yes, `catch_panic`/`recover` has to exist for fault-tolerance (especially with other languages calling into Rust: a panic shouldn't bubble out of Rust), but panics should just be used for truly exceptional/unexpected/"impossible" conditions and `catch_panic` is just to ensure that those cases can still be handled. It's not designed for use with errors that are expected to happen in correct applications, like trying to open a missing file.
I think this anti-pattern should named unwrap+threads+catch_panic because the real issue is turning a recoverable error (a `Result`) into a panic and *then* later catching this panic. I'm not familiar with `recover`, is it about catching panics in the same thread?
Yes. RUST ALL THE THINGS!
[Hmmm...](http://imgur.com/0oEOULw)
Damn, the link is dead. EDIT: [Patch sent.](https://github.com/redox-os/website/pull/9). Hauleth (who are webmaster) will probably merge it later.
The majority of Servo's codebase is HTML/JS tests. Use `./mach grep` to avoid them
Maybe that was too vague. What I mean by bug is "a condition that the library author thought should never happen due to **deterministic** invariants which should be upheld by their code" (deterministic as opposed to I/O). A good example of this is `assert(self.capacity &gt;= self.len)` in a `Vec` implementation. It's OK for a library to panic in this case, since (a) if the implementation is correct this should never happen, (b) if the implementation is incorrect, all bets are off: best case scenario a segfault will be triggered, worst case silent data corruption and loss of real $$. Saying &gt; I do not believe library authors should panic is like saying "I do not believe library authors should use `assert`". If that's what you think, I disagree and I'd recommend this [great post](https://web.archive.org/web/20090707025230/http://www.ddj.com/blog/cppblog/archives/2007/07/assertions_vers.html) on why `assert`s are great and what their proponents think they're for.
Thanks for the examples. Do you think it is possible to deref to a type that holds two or more slices?
Yes! In choosing types, one should strive to make illegal values (like only one option set) unrepresentable. That's not always possible, because our type systems are too weak. But it's a good rule of thumb to aim for.
Maybe there isn't such a clear justification to apply the pattern on all collections. It's more like we're talking about smart pointers to arrays - that can be resized - because the pointers are smart. You implement Deref because that's what smart pointers do. The pattern also talks about "ordered collections" implementing Index. It confused me because I'd call BTreeSet ordered.
The primary reason for rewriting it in rust was to get windows support. For the moment, I'd call it a reimplementation rather than an upgrade: there are three obvious additional features: 1) windows support, 2) can be installed without conflicting with an existing rust installation, 3) can install toolchains for other targets (for example, allows having both 32-bit and 64-bit rust installations, or on windows, both -msvc and -gnu versions) It *is* still quite immature, but given time it will improve. It's also currently the only option for windows users who don't want to install msys, and furthermore, maintaining complex shell scripts is a massive pain.
It might be interesting to have a library that does full evaluation on debug builds, and fast partial evaluation on release builds.
Additionally I believe the performance should improve as well. Something I noticed is the noticeable delay added to `rustc` and `cargo` invocations if you have set a lot of overrides. It seemed that parsing the `.multirust/overrides` file triggers plenty of processes to be spawned, which caused the slowdown. I might add that I am working on OSX, where spawning processes seems to take longer than on linux.
Unlike cargo or rustc, multirust does not require itself to build: cargo is sufficient. Currently the compilation and upload of binaries is automated for 32 and 64-bit versions of linux, windows and mac using a combination of travis-ci and appveyor, so for those platforms installation is trivial. It's also possible to install multirust from source with a single command (documented in the README) as long as you have a valid rust installation: multirust-rs doesn't conflict with an existing rust installation, so this shouldn't be problematic. 
Isn't Spring famous for things like this?
&gt; I'd say taking options as parameters is almost never rusty. In many languages, boolean arguments are considered a smell. :+1:
For Android there is https://github.com/tomaka/android-rs-glue I haven't tried it, but it's made by tomaka (the guy who made glium) so it's probably great.
Warning: if Configuration has dtors, they will run for the value passed to `..`!
Note that for e.g. Mutex the only thing gained is that you can get pointers into the guarded data soundly. If you could provide `get` and `set` (like Cell, basically) totally soundly in cpp. On the flip side, C++ lets you specify that a value is unmovable (you can kinda hack it Rust a bit...), but that's way more marginal IMO.
&gt; I would love for everyone to drop what they're doing and work on higher kinded types. Oh no they got to Steve. ;_;
 Friendly reminder, we have no nominations for the CotW for this week's TWIR! Please nominate and vote on rust-users (or here if you dislike their interface). Previous crates of the week were: * clap * lazy_static * quickcheck * itertools * conrod * glium
I know some people who still use it. Big companies are probably slower to adopt newer frameworks.
Fair enough. I work for a big company, but I guess we're a bit more flexible than others. OT: You should definitely check out Dagger 2 if you haven't, it's pretty neat: no reflection, just clean generated code with great compile time error messages.
Even Rust's ubiquitous iterators rely on the ability to render the underlying structure immovable (usually temporarily). And I'm not really sure how intrusive structures are "lazy design," that doesn't follow to me (especially keeping in mind that static allocation is useful in a variety of contexts, not just kernel engineering). I really think you're just being too quick to dismiss the usecases here. Edit: Oh, okay. Sure, interior pointers are more important to get right. I guess I just take issue with the word "marginal" :P I definitely don't agree with the *number* of &gt; signs there.
I like monads, okay?
We already *have* Options! QED HKT is DOA.
&gt; **Anti-patterns** &gt; &gt; * [...] &gt; &gt; * TODO taking an enum rather than having multiple functions ...why? Is it also an anti-pattern to return a `struct` rather than having multiple functions? The two are just duals. (I only realized a couple of months ago that this is why sum types (disjoint unions, our `enum`s) are sometimes called "coproducts".)
Its use may not be as universal as the previously nominated crates, but rust-csv deserves recognition for being excellent.
I would imagine that this is a variant of the "boolean parameters are a code smell" philosophy.
The problem is less one of parsers and more one of applications. In some contexts, where the source is known to be good (ie, it was validated earlier) it certainly could make sense, however for unknown inputs it can be begging for problems: - when you realize that the last 6 months stored have an incorrect object and are forever corrupted, you are in trouble. - when your application is growing and you start parsing a formerly ignored field and suddenly realize it's become crap sometimes in the last 6 months, you are in trouble. I think as long as it is not the default, and is used responsibly, it's a sound feature. At least, as sound as the ability to use binary-search on non-sorted sources.
Right. I'm not saying that taking an enum is always a bad thing, I'm just saying that I imagine in some cases, you're emulating that kind of thing. Taking an enum is often a good thing. Nick will have to elaborate. :)
That shouldn't work, as `return` from `try!` wouldn't stop at the sorrounding block. A pattern which I saw on IRC once was `(|| Ok({ ... try!(...); ... value }))()` (and you can add `.unwrap()` at the end). This was in a macro though, and it's pretty noisy to repeat everywhere.
Thank you for posting this. I knew regexes were much slower than hand-crafted parsers, but a performance difference of _two orders of magnitude_ is more than I expected.
Yeah overloadable move is IMO not worth the trade.
Not something the compiler called implicitly, but a trait more like `Clone`, entirely optional to support.
In GCC, Clang and MSVC all intrinsics are officially available on stable versions of compilers. There's no need to work with some alternative build of a compiler with version pinned to git commit to get the work done.
 &gt; I just want to perform the very basic task of canceling a thread a la pthread_cancel. I google around, and I see that the only way to terminate a thread in rust is to pass a message to it via shared memory, because literally the only method rust exposes to control a thread is a blocking join(). That's great and all if you have a shallow loop I/O, but I have a recursive tree search and now every search node needs to obtain a lock just to see if it's still supposed to be running! FWIW, you can also check an `AtomicBool` variable at every point you'd like to be a cancellation point. &gt; But from where I'm sitting, it's pretty tough to make a posix system call from within the standard library. use libc::c_int; extern "C" fn syscall(num: c_int, ...) -&gt; c_int; That's what you need. The boring problem is that all headers that declare syscall numbers are in C (and per arch :-( ), so you'll have to write those definitions too. Or use bindgen, but I haven't tried that lately, so not sure how well it works these days. Btw, for handling Posix signals, I think [chan-signal](https://crates.io/crates/chan-signal) is what I'd try first.
I think a lot of people are missing this point. There is a real community stigma against using unstable features even though sometimes they're the only option. The reasoning behind it is clear and makes sense. I'm not arguing against that. Things that are in the nightlies are not guaranteed to make it into stable Rust, so you should be wary of using them. With that in mind, it's not really accurate to say that features that are in the nightlies are part of the Rust language. To me, they are more like features that may at some point become part of the Rust language, and are still being iterated upon. It's very common for someone to ask a question in this subreddit or on IRC about how to do something, and receive an answer like &gt; You can use feature X... if you're willing to use nightly. These kinds of answers definitely show the community aversion to using nightly features, but that same community often uses those nightly features as examples of the capabilities of Rust. I think that's fairly disingenuous. Why should we shame people for using the only possible tools to get a job done? Why does using nightly have to be a bad thing?
Thanks, I've noted this on the bug tracker.
Any struct can implement a trait, so traits are unsized: the type name doesn't tell the compiler how much space it must reserve or allocate. Vecs require sized objects (for obvious reasons). The ways to fix this are to either use traits as type bounds (static dispatch &amp; homogenous vec) or to store `Box&lt;Trait&gt;` or `&amp;Trait` ("trait object", dynamic dispatch)
That's just std::move and it's super not worth it. Let's walk through the consequences (edit: maybe you disagree or I'm misunderstanding): It *needs* to be an OIBIT, because e.g. `Option&lt;T: !Move&gt;` can't be Move. So we have an OIBIT Move which says whether you're movable. Then we have to add another trait Relocate for actually being relocatable (you can fold this into Move with some blanket impls, but I'm sure everyone will protest that they want `!Move + !Relocate`). Now everyone wants the standard library to handle Move/Relocate, so now Vec says `T: ?Move + Relocate`, and *everyone* has to implement Relocate. Probably have to blanket `impl&lt;T: Move&gt; Relocate for T`. Vec now has to handle move constructors and the associated exception safety, Rust becomes C++, and everyone weeps.
Anything to give it a size will do, you can use Arc, Rc, &amp;...
Are the `regex!` macros worth using? Last I heard, we weren't supposed to use them because they were slower than the runtime regex stuff.
Placeholder to remind myself to have a look later. I just made a topic exactly like this the other day, maybe I can provide some insight later.
I have added more shields to indicate that the crate works with stable/beta/nightly. I believe I can keep that information up-to-date, since I test against all three of those on Travis.
Can't you try downcasting `Any` to the proper type, for every type you want to try? Since you receive an `Option` that returns `None` if this is the wrong type, then it seems to be safe.
This does need expanding - I should note that this is often not a bad thing to do, but often it is used as way to write less code when there are better ways (extracting common code as smaller functions or closures for example) - a function which takes an n-variant enum and then has a big match on it and does n different things is a bad design (violates the one function doing one thing principle). Likewise, a function which computes the fields of a struct independently then puts it together and returns it is probably better factored into smaller functions, whereas one where computing the fields is not independent is probably better as one function.
I was thinking something. What about an option to, when calling a C++ library, turning C++ exceptions into Rust panics? (but not turning Rust panics into C++ exceptions when calling from C++). That is, when the C++ library is compiled with the same version of LLVM. Then one would be responsible, on the Rust side, to write a wrapper to turn those panics into appropriate `Result`s. But all of this would be written in Rust. This, plus some form of inheritance / virtual structs in Rust, could enable Rust to directly call *some* C++ libraries (ones that don't do too many crazy things), without a C wrapper. Perhaps even Qt or other big-name libraries.
I'm not sure how feasible or how user friendly a c++ library would be without a proper solution to inheritance. Once some concept of inheritance is incorporated into the language I believe we will see a plethora of c++ bindings. 
Holy shit what. What are even the semantics... Oh I guess it just memcopies the fields without touching the original? Edit: someone somewhere once filed an issue against Rust because using Foo { x: 0, .. Foo::default() } ran the destructor on the default, and didn't, I guess, mem::forget it?
It seems like this is a consequence of a flaw (or at least asymmetry) in Rust's design rather than some kind of fundamental thing, then. (Which is reasonable I guess; we are after all writing the code in Rust.)
Even there it's either `do (Foo data)` or `do $ Foo data` (and both `do` and `data` are keywords) :P
I sent a PR that simply adds regex automata caching to the benchmark. The datetime library should cache, too, with lazy_static.
Hm. I agree with you. Recommending to_owned() over .to_string() is mostly confusing busywork for something that we want to fix to be equivalent eventually anyway. Not sure why I don't think the same about `format!()`, but I know it's using trait objects, so it will never statically dispatch to specific implementations that way. I also prefer regular rust API with functions, methods, traits in favour of macros when it's possible.
[removed]
I've never seen anyone shame anyone for using nightlies. It's more the fact that the people asking the question might not consider using nightlies a proper solution, so the people providing the solution are a bit hesitant to suggest nightlies.
I'm on my phone, but basically, _one_ way to think about monads is "a computation with a context." So you can write functions that take a context object, but chain them together without being explicit about continuing the context without explicit syntax. Oh no now I've tried to explain monads, I'm sure that this is terribly wrong :P Oh, and higher kinded types are a requirement to implement monad.
Exactly the person that I wanted to see in this thread. :)
That makes it more difficult, but you can ask clang for the mangled name and then tell rust what the real name is. See https://github.com/servo/rust-mozjs/blob/master/src/jsapi_linux_64.rs#L3369 for some examples.
&gt; Can you describe how this lib compares to, say, OpenMP? Much less fancy: this lib basically offers a parallel `for` loop and iterator `map`s with one knob to tweak (the number of threads in the thread pool), while OpenMP can do reductions and generally has more flexibility and control, covering more data parallelism than just running a closure on a pile of inputs (e.g. SIMD, GPGPU, tasking). Also, the various OpenMP implementations have had person-years invested into them, while simple_parallel might get to double-digit person-hours, maybe. This means that they'll likely have much lower overhead. That said, I'm pretty sure that Rust is expressive enough to reimplement most of OpenMP as a library (although automatically SIMD-ifying/GPGPU-ing an arbitrary closure is probably not possible without some sort of compiler plugin). &gt; Why not? It doesn't handle panics well, I haven't invested enough effort into testing edge cases, and there's a ton of overhead. It uses a `Mutex` internally for distributing work which is orders of magnitude more expensive than necessary. It should really be using a blocking mpmc/spmc channel, but I haven't found a one that is faster than the `Mutex` yet.
*cough*[`rust-pcg`](https://github.com/DanielKeep/rust-pcg/)*cough* :P
See also [this](https://github.com/rust-lang/rust/pull/29240#issuecomment-150736487) where a different version is added which primitives and aliases instead of underlining all the links.
I'm not sure the question is particularly meaningful. New APIs are added as unstable so the instability in the stdlib is changing, not strictly decreasing: we won't get to zero unstable things in the foreseeable future. https://github.com/rust-lang/rust/issues?utf8=%E2%9C%93&amp;q=is%3Aopen+label%3AT-libs+tracking+issue gives some idea.
IMO, there aren't many cases where this is actually important with values with heterogeneous types, and most of those are specialized enough that they could be implemented with a regular byte buffer. I do want strong update, though :(
Should I know who this is? I feel like they have a reputation that I am unaware of.
They are slower in some cases yes, particularly if your regex has a literal prefix. regex! basically needs a complete overhaul. I've been putting it off until dynamic regexes have a more complete story (e.g. a DFA).
Among other things I'm a [roguelike](https://crawl.develz.org/) developer with a healthy interest in PRNGs. I actually migrated Dungeon Crawl to use PCG earlier today. kibwen has been encouraging me to overhaul the rand crate^*. My reputation is entirely a figment of his imagination. (^* I think there's an irreconcilable schism between people who are interested in keygen and those who do simulation.)
What drives this sometimes is that forgetting the train model will make it appear that so much time has passed if you look at the version, when in reality so little time has passed.
The regex crate likely utilizes SSE2 (memchr) and also uses a very fast Aho-Corasick DFA in some scenarios (literal prefixes). Both of these things can be improved, but the beginnings are there.
If this is happens in more places you should consider using a [builder pattern](http://doc.rust-lang.org/stable/style/ownership/builders.html) for your API. One project I remember is [imgui-rs](https://github.com/Gekkio/imgui-rs) that uses a builder pattern for creating bindings for [imgui](https://github.com/ocornut/imgui) (C++) which has default args and overloads everywhere. That may serve as reference/inspiration.
I don't think people in the community would go so far as to shame someone for using nightly, but a lot of people have definitely said "I would use [crate|feature] if it wasn't on nightly". It's fair to say that using nightlies isn't a proper solution, since a lot of us really do care about stability guarantees. My only point is that when so many things that systems programmers would really like to have are unstable and therefore don't have a proper solution in Rust, it isn't really appealing to them to call it a systems programming language. Anyway, I won't say any more on this topic, since it's honestly not all that important. I hope you can all see my point as something more than meaningless nitpicking, but for now I seem to have incurred the Wrath of the Rust Community for holding this opinion.
It'd be really cool to get a [KISS-UI](https://github.com/KISS-UI/neo-kiss-ui) backend going for Redox, if and when I get around to actually designing the framework and the frontend API. 
True, but not so bad as firefox which is at version 41 now and probably 45 in a year. I really hate that number inflation.
Also be neat to see time::strptime. 
Signals are a bad abstraction that have broad implications. They significantly complicate memory allocation, error handling, and locking. Stay away if you can. On modern Linux systems, the only reasonable way to use signals is for them to immediately write the signal number to a file descriptor that is read on the other end in an event loop, or by a thread that can deal with the signal in a controlled context. Please, do not expose signals. Pretty please. Expose a reasonable abstraction around them, if that is even necessary. No need to perpetuate brain damage.
Is that 1.5 referring to the next beta? The Rust downloads page says 1.4 stable is coming out next week.
Shame it doesn't build relationships: { "users": [ { "id": 1, "name": "Lauren" } ] }
good start.. next step a swagger client generator for rust.
Apparently, there already is an `algebra` crate. I haven't yet had time to check what exactly is in there and if it even compiles (it's quite old), but at a glance it looks like it's what I wanted.
&gt; If that's enough for you to say that C++ doesn't support SIMD, then you shouldn't be able to say Rust supports SIMD until it's on stable. And that's exactly what I am saying: both *compilers* propose extensions that are *not standardized yet*.
That's awesome. I have been toying with a rogue like idea but I can't figure out how I should handle ranged weapons. Do they work in turn based rogue likes? Does the rand crate not want PCG because it hasn't been proven secure?
&gt; with the current pace of development, you can't really argue that support for those use-cases will be adequate in less than 5 or 6 more release cycles We almost stabilized libcore for 1.5, in beta next week. It isn't happening, but will be in 1.6. We've been working on cross complation, and actively talking to people who are writing operating systems or embedded development to figure out these pain points.
The benefit being that in this case you'll get static dispatch as opposed to dynamic dispatch using a Box&lt;Trait&gt;.
Thanks! For sure the extended generators can get confusing. I might have to reach out to Professor O'Neill about them. I will look over your code for sure. If you ever want to pick up steam again or find an error in my code let me know :)
It seems like the rand crate might want to split in two. (like piston is a bunch of different crates). Maybe something like `rand-sim` and `rand-crypt` Any package that claims to be secure shouldn't use the sim crate. I know from experience that changing the minds of some of the more security conscious developers can be hard. I have friends like that and they bugged me when my website only got a B in its SSL security. 
Nice explanation. I actually stole that approach from you for one of my projects a while ago. Regarding the problem of having to loop over the connections for every tick: I just have a vector of all reset connections in my event loop struct that I update when a connection is reset, so I don't have to construct the vector in`tick`. That vector is cleared at the end of `tick`. I'm not tracking my idle connections though, but I don't see any reason why you couldn't do the same there. Also, iterating over a slab is probably even less efficient than you think, since the iterator doesn't just traverse all the connections in the slab, but potentially has to traverse the entire slab, even if most of the slots are empty. (I know because I wrote the iterators for slab. The slab data structure doesn't really allow you to answer the question "what's the next non-empty slot" without iterating over all the empty slots between the current position.)
cc /u/hjr3 (the original author)
Functions consume their arguments. 
Does reddit understand that `cc` thing?
There are definitely a whole lot of issues (templates are another fun thing to think about), but none of them are unsolvable, and going through a C API is just straight-up infeasible for libraries that make pervasive use of templates.
If the target user has reddit gold, they do get a notification.
Ah, I didn't know that was guaranteed. Thanks!
Right, just wanted to clarify that mentioning someone ~~does~~ can indeed notify the person :)
To me it seems that using the slab has a lot of complexity overhead and I am not sure that it is that much better. For my use-cases using a HashMap is quick enough. With this approach I can simply increment the next_token to infinity (almost:) and there will be no collision, ever. If there is any error on a socket I can simply close it and that will stop any potential event for that failed token. That is all, what am I missing? 
They extended it to non-gold users a while back.
Maybe something like:https://github.com/ChrisMacNaughton/rusty_json/blob/master/spec/rusty_json_spec.rb#L127 ? I built this in a couple of hours because I was parsing a massive JSON blob and tired of writing the rustc_serialize parser by hand :)
it _should_ be doing relationships, what isn't working right now (and I'm working on now) is doing arrays of relationships, [{object}].
indeed!
I've failed to compile Hyper on Windows and switched to Linux now, OpenSSL failed every time whatever I tried ....
Should be. At least for certain cases.
Get rid of the &lt;T&gt; in your fn, you don't need to declare it again 
Your initial declaration of the trait says "types that implement this trait will implement a generic method `FooBar` which, for any type `T`, will return an object of type `T`". Your `impl` then seems to be trying to provide an implementation that implements `FooBar` for only one type `T`, the type covered by the generic parameter of the `impl` block. Do you want these `T` types to be the same, such that the trait can be implemented with an implementation for all types `T` that satisfy `Bar`, and the `FooBar` method will return an object of that type? If so, the method shouldn't be generic; rather, the trait should be generic. Here's an example, with some of the elided stuff filled in to make it actually compile ([playpen link](http://is.gd/F2P1kU)) pub trait Bar { fn new() -&gt; Self; } pub trait Foo&lt;T&gt; { fn FooBar() -&gt; T; } impl&lt;T&gt; Foo&lt;T&gt; where T: Bar { fn FooBar() -&gt; T { T::new() } } If you didn't want these types to be the same, it's hard to say what you want. How would you be able to implement a generic `FooBar&lt;T&gt;() -&gt; T` method, without any constraints? That is saying "for any type you give me, I will produce a function that can return objects of that type, without being able to depend on any existing objects of that type or any traits that are known to produce objects of that type." If you can provide a little more information about what you're trying to accomplish, it might be a little easier to answer your question.
I struggled to get `rust-openssl` installed on windows as well, but finally got it to compile (on the other tool chain, I haven't tried msvc yet). I note that Microsoft's docs say `LNK1181` probably means the .lib file was not found. This is the same issue I had with the other tool chain. What I did was look at the command the linker was called with (in your case it's the second to last `note`). I looked at the linker's documentation to find which directories it looked in by default or which flag in that call was explicitly specifying a directory to search for the library. Then I pasted the libraries there. A couple other possible gotchyas: the .lib has to match the target (32 vs 64 bit etc.); and I think you might need to explicitly `cargo clean` after changing environment variables to prevent a stale build cache. Here are the notes I took when I went through this (specific to the other tool chain): &gt; For the files that `rust-openssl` suggests one could copy to "locations that Cargo can find", any of the directories preceded by "-L" in the "gcc" command will do. `ld` is the linker; `gcc`'s "-L" flags are specifying extra locations for the linker to find the libraries to link. &gt; I see "-L" "C:\\OpenSSL-Win64\\lib", so it seems to me like maybe something _tries_ to be setup to not require the manual pasting, but it just isn't quite there. 
&gt; Much of the core SMP code was baked from byuu's higan source code ...but since higan is GPL3-licensed, surely this code must also be GPL3, instead of BSD? (I'm not immediately sure what 'baked from' means in this context) Either way, that's pretty cool - emulation is one of those use-cases where C++ is hugely popular for its efficiency and its expressiveness; if Rust can become popular in that space it would be huge validation.
(Looks like `LNK1181` can also be caused by spaces in paths.)
&gt;I note that Microsoft's docs say LNK1181 probably means the .lib file was not found. I've gotten it to compile on both, the issue is actually using it with the msvc, the most basic test case `cargo test` within `openssl-sys` itself fails for msvc. &gt;I note that Microsoft's docs say LNK1181 probably means the .lib file was not found. The issue here is I'm not even trying to statically link it. The msvc binaries for OpenSSL don't include a .lib, so I have to use dlls, the build script is just straight up ignoring this though. I just don't know enough about the OpenSSL project to pick the right files that I'm missing and *know* it'll work. Thanks for the advice though :)
You can introduce a wrapper type `MyIter(...)` where `...` is the long type you just mentioned. Or you could just create a struct that takes the inputs your big iterator takes and implement `Iterator&lt;YourOutputType&gt;` on it, and avoid the huge types entirely. Alternatively, if you're willing to sacrifice an allocation, you can just `Box` the whole thing and store it as a `Box&lt;Iterator&lt;Item=YourOutputType&gt;&gt;`.
Sorry for the misdirection, good luck!
Every data structure. Every generic piece of code which: * wants to be maximally useful * and moves a generic value
Why can't your struct be parameterized by `I where I: Iterator`? The literal meaning of a type parameter is "this type is the type of this expression over here".
Fixed :)
I compile hyper and openssl on windows regularly, and the only issue I know of is when passing `OPENSSL_STATIC=1`. Other than that it works fine, you just need to ensure the environment is setup correctly, and if using msvc you need to make sure you have the correct binaries. I've added additional information to the bug report, so you can see exactly the appveyor script I use, which should be easy to reproduce locally. edit: Also, it's possible to get it to work even with `OPENSSL_STATIC=1`, which is what I use in my appveyor script.
There is no particular issue storing iterators in structs. You just have to use a type parameter. `MyIter&lt;T: Iterator&gt;(T)`. If you need to return the struct from the function in which the iterator is instantiated, you'd need one of these proposals to be implemented for the same reason you need it for returning an unwrapped iterator.
Seems to just be a workaround to the issue, but nevertheless its progress. Thanks! I still wasn't able to get it to run the tests, but I did get the libraries to try and link.
[Yes!](https://github.com/rust-lang/cargo/releases) It's been like this since April.
&gt; I'm extremely new to rust, and am still getting familiar with best practices `.unwrap()` is saying "Compiler, I promise that this is _always_ `Some(T)`. If it's not, just blow up." As such, good Rust programs should use `unwrap()` sparingly. However, your program also doesn't have to be "good" to start. I've enjoyed just always using `unwrap()` to get going, then coming back and adding better error handling afterwards. In this case, the example is using `unwrap()` because: https://github.com/tomaka/cpal/blob/master/src/lib.rs#L91 If no device is available, it's not much of a demo, so just blow up. If you were making a real program, you'd probably want to inform your user of the error and exit a bit more gracefully.
Thanks (/u/Gankro too). So, is there any way to ask the compiler (or linter) to not allow unchecked unwraps?
Why doesn't Rust 1.3 come with Cargo 1.3 (for example)?
`unwrap` (on both `Option` and `Result`) is overused in code examples because they allow the example skip error handling. See [this excellent article](http://blog.burntsushi.net/rust-error-handling/) and [this book chapter](https://doc.rust-lang.org/book/error-handling.html). The tldr is: if you have an `Option` that represents an error condition that you can't recover for the `None` case, use [`ok_or`](https://doc.rust-lang.org/std/option/enum.Option.html#method.ok_or) to turn it into a `Result`. Handle results as usual (with `try!` and so on). Implement `From` conversions from an error type to another in order to make `try!` more ergonomic. If you have either an `Option` or a `Result` that you can recover in case of error, use [`unwrap_or`](https://doc.rust-lang.org/std/result/enum.Result.html#method.unwrap_or) if you can recover regardless of the error condition, or more elaborated code inspecting the `Err` variant of `Result` (ultimately using pattern matching). If you *intend to crash* when there is a problem (perhaps because this is a simple command line program, or because there is no way forward), you should still use [`expect`](https://doc.rust-lang.org/std/option/enum.Option.html#method.expect), in order to have better error messages. If having a `None` or `Err` is *plain impossible* but the Rust type system is not smart enough to detect it, use `unwrap` or even pattern-match and call [`unreachable!`](https://doc.rust-lang.org/core/macro.unreachable!.html) (this amounts to the same thing, but *documents* that you believe the `None` branch is unreachable).
Yeah, Rust have two methods to differentiate "I'm unwrapping because I'm lazy" and "I'm wrapping because the Rust type system isn't smart enough to know that in this situation, `None` or `Err` is an impossible value". The programmer can make their intentions explicit in the second case by pattern-matching and calling `unreachable!` in the error branch. But since it's more verbose, I believe most won't do that.
What's the chance of having a design like this in the stdlib?
Versioning them separately means that Cargo can have a breaking change without bumping the Rust version, I guess. 
Note that unwrap can be "the right thing" to use in some cases. For example you may lookup a value in a hash map and you know it's there, but the compiler doesn't.
&gt; IMO, immovable objects only exist because something is observing the address, i.e. interior pointers What about position-indepent (relative-addressed) references? Semantically it's just like `&amp;`, but its value necessarily depends on its address, so it's only safe to move around using code that fixes it up (i.e. an explicit `relocate()` or such).
Ah, I should say the pattern's talking about _slicing_ with Index. It says if a collection `&amp;c` implements `&amp;c[..]`, then it should `deref()` to that and hopefully implement some of its methods that way. I'm a bit confused by using the phrase "ordered collection", because that makes me think "ordered set" and BtreeSet (or Map if you prefer), which don't follow the pattern. I guess BTreeSet should be able to implement the pattern if it wants to, it just hasn't yet. E.g. iteration could be implemented through BTreeSlice. clear() could be implemented through BTreeSliceMut. It just doesn't look like the current `BTreeSet::range()` work. That's returning an iterator directly. I'd be confused if some collections deref()'d directly to iterators (and others to a slice type which has to be converted to get an iterator).
One way is to have a function like: fn make&lt;R: Rng&gt;(r: &amp;mut R, lo: f32, hi: f32) -&gt; Pnt2&lt;f32&gt; { Pnt2 { x: r.gen_range(lo, hi), y: r.gen_range(lo, hi), } } and just call that.
I didn't intend the compiler would understand it or anything; just that there is a method called todo (yes I can do it in my own projects with a trait or fn).
I would like to stress that this is actually a better idea. Even when abstracting over this kind of functionality, you get more flexibility by just requiring a function instead of a more specific trait.
Definitely seems like a tradeoff
That's how type parameters work w.r.t input (function arguments) not output (function return types).
Is there an RSS or atom feed available for that blog? 
http://blog.phil-opp.com/atom.xml
Yes, at http://blog.phil-opp.com/atom.xml Edit: added a link on the page
Not with a plain memcpy.- the target of the reference is given by the offset it stores added to its own address, so bitwise-moving it to a different location in memory changes where it points to. Definitely no good. What you're probably thinking of is that if you implement interior pointers *using* position-independent references, then you can bitwise-move the reference *together with its referent* and it'll all stay consistent. I don't fully understand the relationships here... absolute references can be memcpyd at will, but their target must stay at a fixed position, while relative references need fixup-code to move them separately, but can be memcpyd as a package with their target. It feels like some kind of duality.
Please note that new articles are _at the bottom_ (unlike traditional blogs). The latest (2015-10-23) is [Printing to Screen](http://blog.phil-opp.com/rust-os/printing-to-screen.html).
Cargo isn't ready to be called 1.0.
Thanks for putting this together, it's very valuable documentation. :)
Great resource. I [proposed it to rust-learning](https://github.com/ctjhoa/rust-learning/pull/23).
Is `#[deny(missing_docs)]` new? I was under the impression discussion was ongoing to add it. `#[deny(unsafe_code)]` seems undocumented in the reference. Actually, a few of them are missing.
Ah ok
IIRC it's been around for a year or so.
I'm not sure when this was added, but it works on stable (says `multirust run stable rustc -W help | grep missing-docs`).
This is a pretty great introduction to OS dev! It's a lot more readable than many other tutorials I've read. I haven't gotten to the Rust stuff yet but I'm looking forward to it. I have a question, though. In the "Enabling Long Mode" post, under "Enable Paging" I'm seeing what looks to be some redundant moves in the assembly: enable_paging: ; load P4 to cr3 register (cpu uses this to access the P4 table) mov eax, p4_table mov cr3, eax ; enable PAE-flag in cr4 (Physical Address Extension) mov eax, cr4 or eax, 1 &lt;&lt; 5 mov cr4, eax ; ... ; enable paging in the cr0 register mov eax, cr0 or eax, 1 &lt;&lt; 31 or eax, 1 &lt;&lt; 16 mov cr0, eax Is there a reason why you use `eax` for scratch space instead of doing the bit-manipulations in the target registers themselves?
What will the cow lint do?
It's because `cr0` and `cr4` are special [control registers](https://en.wikipedia.org/wiki/Control_register) and support only load/store. For the `or` operation you need a general purpose register such as `eax`.
Thanks for writing the article. This is a great selection of tips. I'd like to add that on nightly one can put benchmarks in the `benches` subdirectory and have `cargo bench` run them.
Just what I was hoping! Awesome. Thanks.
I think the code would benefit from running clippy and fixing the warnings. I don't have time right now, but if you like I can do that and push a PR.
rustc has been in the community repo for a while. 
The struct can't abstract away the type of the iterator because the compiler generates a different struct for every iterator that that struct is used with, because each iterator has a different layout in memory. If you want to erase the type parameter you have to use the trait object abstraction, which causes their representation within the struct to be consistent (two pointers).
But my point is that this a problem with output types, not with storing iterators in structs. If you don't need to return the struct from the scope in which the iterator is instantiated, type parameters work fine. Your actual problem is not in storing the iterator in a struct, but the fact that that struct is in the output position. &gt; It also doesn't let anybody neatly write an abstraction, struct MySimpleIterator(MyHellishIterator), unless that abstraction leaks a type parameter, which really isn't much of an abstraction at all. I talked about this in a sibling, but the only way to avoid type parameters is a trait object. This wouldn't change if any of the proposals to allow output types were implemented.
I was doing this: let cap = re.captures(buffer.as_ref()).unwrap(); println!(" {}", cap.at(0).unwrap()); Thanks for your input :) I'll try it out.
I figured it was something of that nature but I just wanted to make sure. Thanks! 
I'm not really sure if there's a script for this already, but otherwise this should be a nice way to get some of the extra cargo goodies easily. Cargo-watch and cargo-check are notably awesome (open up an extra terminal, cd to the directory, run "cargo watch check" and your life will change forever! :p). Also FYI cargo-outdated is [currently not working](https://github.com/kbknapp/cargo-outdated/issues/6), so don't expect that to work for the time being.
Yes, unless it is a non-inlineable function across a crate boundary or you're using dynamic dispatch on a method in a trait object or you didn't enable optimizations.
&gt; otherwise this should be a nice way to get some of the extra cargo goodies easily. This is one of the reasons `cargo install` was born. Scripts like this are still useful till that hits stable, for sure!
Yes
Every step of the way, it seems like Mac OS X is preventing me from following this tutorial! I've [cross-compiled binutils](http://blog.phil-opp.com/rust-os/cross-compile-binutils.html), built &amp; installed [objconv](https://github.com/vertis/objconv), built &amp; installed [grub2](http://savannah.gnu.org/git/?group=grub) (with some hacks around `flex`), did a bunch of `brew install` for dependencies `grub-mkrescue` doesn't bother to tell you about... Edit: built a cross-compiling gcc from source, rebuilt grub-mkrescue with the ELF toolchain, and FINALLY saw a little green `OK`!
Does `cargo install` install to `/usr/local/bin/` by default? That's my usual complaint with some other language-wide installs, just putting them into `/usr/bin/` even though they're not supposed to. ~~Also it would be nice for an uninstall, but without being an OS-level package manager it's understandable if there isn't.~~(Looks like there is one!) edit: It looks like it will be useful for making distro packages, from the bit of experience I have of Gentoo ebuiilds anyhow.
It installs to `~/.cargo/bin` by default, but you can change the default with a setting. It's not meant to compete with your system packages, so `/usr/local/bin` isn't really the right place.
According to my git repo I've been using `#[warn(missing_docs)]` since August 2013. So, it's been around for a while, and certainly available in stable Rust since 1.0. Edit: Actually… I've been using `#[warn(missing_doc)]` (without the s), which was later renamed.
I see that now, looking at install's `--help`. It sounds like it will be really nice to have once it hits stable.
When in doubt, throw extra cores at a problem. Try `make -j 4`.
Really awesome! I couldn't find the source code. It would be awesome if there was a link for it. Maybe it's me, but I'd like to get it working and running before investigating how it works.
I just wish `Pattern` would get stabilised so I can make `cargo-script` work on stable. That, or just copy+paste all the string matching code out of the stdlib... but I'm not sure I want to go *quite* that far. **Edit**: I've replaced all use of custom `Pattern` stuff in `cargo-script` with regexen, so it *should* build on stable now (can't test due to an unrelated issue with 1.3+multirust-rs). **Edit 2**: Oh! Forgot to mention; `cargo-script` is now on crates.io, so you can also get it that way (including via `cargo install cargo-script`).
That's what I was thinking of, relative exterior pointers seem extremely unsafe and cannot easily be contained (unless you use lifetimes to freeze the source - but it's still too damgerous and I'm not seeing the usecase).
Yes, but the operation is mostly idempotent, so the race isn't a problem.
An unusual choice.
Interesting. I'd have to look at the compilation of the regex more closely to see where it could be improved. Off the cuff, replacing `\d` (Unicode aware) with `[0-9]` might be worth trying, although I doubt it will do much.
- I have been experimenting with [type-safe dependency injection](https://github.com/Nercury/di-rs/issues/1). I am calling it ownership-driven DI, and it looks promising. Looks like it would require a very different workflow. - Plugged in interpreter into [twig-rs](https://github.com/Nercury/twig-rs). Had some issues with sub-template loading at runtime (the included template may not be known at compile-time), solved them by adding interrupt instruction to interpreter, so the parent template can be placed into stack while child template is rendered. This week will start lowering AST into instructions.
This would be even simpler, if `Vec2` and `Pnt2` implemented `From&lt;(T, T)&gt;` (which they _really_ should). Then it would just be a matter of: struct MyStruct { p: Pnt2&lt;f64&gt;, v: Vec2&lt;f64&gt;, } impl Rand for MyStruct { fn rand&lt;R: Rng&gt;(rng: &amp;mut R) -&gt; Self { MyStruct { p: rng.gen_range((0.0, -1.0), (1.0, 1.0)).into(), v: rng.gen_range((0.0, 0.0), (1.5, 2.0)).into() } } } This is a flaw in nalgebra. But, you can still use a newtype without having to 're-implement the 40-something traits', by using it only for generation: pub struct Ranged&lt;T&gt;(T, T); impl&lt;T: SampleRange&gt; SampleRange for Ranged&lt;T&gt; { /* ... */ } impl&lt;T&gt; Into&lt;Pnt2&lt;T&gt;&gt; for Ranged&lt;T&gt; { fn into(self) -&gt; Pnt2&lt;T&gt; { Pnt2::new(self.0, self.1) } } impl&lt;T&gt; Into&lt;Vec2&lt;T&gt;&gt; for Ranged&lt;T&gt; { fn into(self) -&gt; Vec2&lt;T&gt; { Vec2::new(self.0, self.1) } } // Then: struct MyStruct { p: Pnt2&lt;f64&gt;, v: Vec2&lt;f64&gt;, } impl Rand for MyStruct { fn rand&lt;R: Rng&gt;(rng: &amp;mut R) -&gt; Self { MyStruct { p: rng.gen_range(Ranged(0.0, 0.0), Ranged(1.0, 1.0)).into(), v: rng.gen_range(Ranged(0.0, 0.0), Ranged(1.0, 1.0)).into() } } }
I've just finished working on [BASMAP](https://github.com/buntine/basmap), a simple command-line tool for auditing the sitemap at a given URL. It's my first non-tirivial Rust project and considering I did it primarily on the job, I'm guessing I'm one of the first programmers in my city to get paid to write Rust. :) I'd also love to hear some feedback if anyone has a moment to check it out.
[Octavo](https://github.com/libOctavo/octavo): - benches (speed up code and make it comparable to [other libs](https://github.com/briansmith/crypto-bench)) - maybe finally AES? - block cipher modes - learn Homu - find some friends to help me with maintain codebase Personally: back to the university.
Hey there! Here's the source code from the video. https://gist.github.com/gkbrk/40aa741ad744b46449bf I didn't have time to make it pretty, sorry about that.
 Tick some more TODO boxes in my BurstTrie collection https://github.com/arthurprs/burst-trie Add a decent README and Redis protocol for my Floki MQ project https://github.com/arthurprs/floki 
Benches are a must in these type of crates, I'm not sure if it's a bad of a good thing though. 
Just letting you know the "Start from the beginning" link goes to a 404. By the way thanks for the tutorials, been interested in rust, any pointers for someone that comes from python. Also anyone know if a learn rust reddit is in the plans, like the one for python?
Hmm, unfortunately I don't have any Mac experience… But feel free to [open an issue](https://github.com/phil-opp/blog_os/issues), maybe we find a solution for future users. 
Thanks, it should work in a few minutes, when github.io updates. I haven't heard on anything on reddit, however you might want to take a look at http://rustbyexample.com/ for practical example that you can edit and run in your browser. Also, you might be interested by [rust-learning](https://github.com/ctjhoa/rust-learning), a list of resources on the Web.
My rule of thumb is: `.unwrap()` outside of `main()` (or small functions that are used to group `main` a little) is a code smell.
I'm preparing the [Rust meetup in Cologne this Wednesday](http://rustaceans.cologne/2015/10/28/second-meetup.html)!
I agree that that's the current model of the world. One could say the same thing about functions! But here we have an RFC that allows the programmer to omit the specific return type and say "it's something like this, you figure it out. I guarantee it's only a single type". I'd like the same capability for structs - if the struct is ever created with two different concrete types, a compiler error could be generated, but otherwise, I'd like to be able to say something like struct MyIterResult (Iterator&lt;Item=i32&gt;); This would indicate to the compiler that there is exactly one concrete type that this struct will be initialized with, and that that type has the constraint `Iterator&lt;Item=i32&gt;`, but that I, as the programmer, don't want or don't care to describe it in soul-rending detail.
As an example, I have [this](https://github.com/bfops/playform/blob/848b802e8574ba3088e9b00e1081a2634d667209/common/surroundings_loader.rs) data structure. Its purpose is to provide an update function which takes an updated player position, and provides a list of "load tasks". As part of this, it stores an iterator that simply iterates outward though the surrounding "chunk" positions. This whole data structure (`SurroundingsLoader`) is stored in a number of places for a variety of reasons, both in server code and client code. They all use the same iterator type internally. They will all only ever use the same iterator type internally. The person holding the `SurroundingsLoader` really doesn't and *shouldn't* need to know about the internal iterator type, that's silly. It's even sillier when I have to keep propagating the type parameter upwards! It seems *insane* to force the type of something high-level like `WorldState` to be parameterized over the tiny implementation detail of which iterator to use, or to otherwise incur a runtime cost. Is the runtime cost high? No. But there's no reason to incur any at all, and this strange trade-off seems at odds with the general principles of Rust. Luckily, the iterator here is fairly simple, so it's not horrible to write down. If it were more complicated, it would become a lot more unreasonable. Even in this simple use case, I had to "unwrap" the closures and manually implement `FnMut` on a new data structure so that the type could be described at all. All of that extra work could be eliminated if I could use `Iterator&lt;Item=Point&lt;i32&gt;&gt;` as a contract to describe that there is only one type, and it implements that trait. From the point of view of the writer, that's much less horrible. From the point of view of the reader, it saves the gory details. From the point of view of the compiler, it's not unrealistic. &gt; The only way to avoid type parameters is a trait object I replied in that sibling. I agree that this is currently the only way to do it. Where I differ is in the claim that that's a necessity.
Hey Phil, I'm loving these posts so far! Unfortunately, I'm stuck on something that I cannot make heads or tails of to save my life. I'm running Debian on a recent Intel Atom (so it's x86_64), and everything works in my code up to and including setting up the GDT and the segment registers. However, when I try to jump to the long_mode_start, QEMU seems to hang. As far as I can tell I've copied your code exactly, and I've tried every method I can think of to debug this, but I'm not really getting anywhere. Additionally, at least on my machine, when I try to `make run` your code in the "entering_longmode" tag on the github, I get a boot loop. Do you have some special magical version of QEMU or something? I'm pulling my hair out over here trying to figure this out!
I've started to implement an irc server in rust. The goal of the project is that I learn rust so it is not likely that it will be as feature rich as the famous ones. It does not mean that I don't want it to work:) So far I've learnt that the irc protocol is surprisingly not well documented with its countless RFCs, and the public implementations are all approximations, full of backward compatibility hacks and various tricks. Writing an irc server in rust is still fun:) The [code](https://github.com/elszben/alyro) is at github but it is not usable yet. 
I'm on Debian x86_64 as well, and I haven't gotten to that part yet, so we'll see....
Thank you! You are awesome!
But it makes sense, I think. 
Yeah, those are in the foreground... ... Do not question my science :P
More Imp. I finished [primitives, aggregates and negation](https://github.com/jamii/imp/blob/master/diary.md#primitives). Hopefully this week I'll be able to make some more realistic comparisons to sqlite. I was looking at the [TPC](http://www.tpc.org/default.asp) benchmarks but I can't find any implementation for sqlite (I want something that already has sensible tuning and measurement so I know I'm not messing up the comparison). Another option is importing a [Fossil](http://fossil-scm.org/) repository and comparing some basic commands. Is there some SQL equivalent of [TodoMVC](http://todomvc.com/) that I can use? 
Test unit will always be executable. It need to, how otherwise would you run tests? Of course you can create "test library" that would need to be run by external tool, but I see no reason for that.
? Possibly you don't understand what I'm asking. I want my binary that is reflective of the test to run on a different machine than where I am compiling it. I don't want to cross compile, so I'd rather just statically link. I've figured out how to statically link a library, but the tests for those isn't statically built.
You can connect gdb to qemu's built in gd stub and debug your program that way.
&gt; But how do I get my actual binaries produced by the compiler itself to be fully statically linked? By default, `rustc` should statically link everything but `glibc`. If you also want a statically linked libc, you'll need to try out MUSL: https://doc.rust-lang.org/nightly/book/advanced-linking.html#linux (hoping to make this easier in the future)
Building a wrapper around KVM, bhyve, and Hypervisor.framework's low level interfaces. Initial support will be for KVM/x86_64, but it's built with the other targets in mind.
Tried that-I get a sigtrap I can't step out of every time I hit a breakpoint so it's basically useless.
I've been a long time lurker, but have been doing some work in Rust. I decided to work with Rust and [githubarchive](https://www.githubarchive.org/) to write a simple tool which can fetch and run queries on the data obtained from that site. Probably not as impressive as some of the projects on here, but [if you wish to take a look](http://github.com/psyomn/gar). Still needs quite a bit of work though!
Finally a rust project at $job! It's a process monitor/classifier kinda like [cgrulesengd](http://manpages.ubuntu.com/manpages/trusty/man8/cgrulesengd.8.html) using rust-cnproc with mio. I'm currently looking into adding REST control api, but it seems painful to integrate hyper into mio loop.
Awesome thanks!
Damm, the diary is a great read.
Actually, I don't think the multirust "use" subcommand is available ... I tried multirust update musl, but that didn't work... So I wanted to check that a musl option was available to download and what it's name would be. Looking [here](http://static-rust-lang-org.s3-website-us-west-1.amazonaws.com/dist/2015-10-26/index.html), I can ctrl+f for musl, but when I try to do: multirust default musl, musl gets appended in the wrong place needed to resolve the url.
You need to first tell multirust what the 'musl' chain is. Like I said, I ran some sort of command, but don't remember what that was, you'll have to read their docs.
You're welcome!
I was setting breakpoints on assembly labels. I added debugging symbols to compilation and used `file` to load the binary file so I could read the symbols and break on them properly.
\u\gclichtenberg and I have been making lots of progress on [Ares](https://github.com/TyOverby/ares), a scripting language (it's a lisp) where the main focus is easy embedability in Rust projects. The main usage of Ares is to use it as a library. I hope to eventually use it as a scripting language for games, but right now the biggest program using it is [Stormtrooper](https://github.com/TyOverby/stormtrooper) which uses Ares as a scripting layer for controlling industrial laser cutters.
Your readme there is impressively extensive, but can you quickly summarize how clap compares to other argument parsing libs?
What is OSC?
OK, so gdb has two ways to set breakpoints: 1) Write a breakpoint instruction, while keeping the old version of that byte(s) squirreled away. 2) Touch the hardware debug registers directly using a lower level protocol than just read/write. In the case of 1, the breakpoint will cause your emulated machine to triple fault since you don't have an INT3 handler. I'd try an "hb" command to set a hardware breakpoint (which will be internal to qemu).
I have a more general question about githubarchive. Do you know of any way to use it to gauge the number of Rust projects on Github? I've attempted to determine such a thing in the past but was frustrated with the discoverability and documentation of their data set.
http://doc.rust-lang.org/std/io/struct.Cursor.html#examples is a form of DI. You pass in the dependency, the writer, you 'inject' it. Rather than have it being something purely internal, a write() method that takes no arguments. It can of course get more complex than that, and there's things like IoC containers yadda yadda, but at its core, DI is just "pass in stuff rather than rely on internal state"
I've heard a lot of people rave about it.
I'm working on a (rust) png image loader on and off. I know that libraries that do this already exist, I just wanted to try it myself, after spending a couple of weeks in the (C) libpng source code for a University Assignment.
oh, didn't know that! Way back in my OSDev class, we installed ISRs, hence why regular breakpoints must have worked.
I think that &gt; I want my binary that is reflective of the test to run on a different machine than where I am compiling it. and &gt; I don't want to cross compile, [...]. is in a disagreement. Unit tests are meant to be run on specific machine and bringing *that* machine is your responsibility. Actually, I wonder if your code is really platform-dependent (many pure-Rust codes don't); [explicitly showing your problem would be helpful for further advice](http://xyproblem.info/).
It may not matter but the arewefastyet [preview render](https://github.com/servo/servo/wiki/Meeting-2015-10-19#arewefastyet) doesn't load. I'm not sure if it's still not ready for viewing or what.
They're not in disagreement. Both environments are x86, so it doesn't make sense to cross compile because the difference is *specifically* in the difference in the libraries that are available on the target. The reason being that I'm developing on an ubuntu linux, but deploying to a minimal, buildroot constructed, environment where the TCP is far less. We want our binaries to run on both the dev and production machines, and we're not targeting another architecture. So the way I see it, if I can just tell the compiler to link in all dependencies including glibc or whatever, I'll go with that because cross compiling is a significantly greater headache than a compile flag (if I could find that damn flag). For that matter, I think there's at least some value in being able to specify target binary properties for a unit test target where the actual crate type itself is a library. 
Ahh, that makes sense. Thanks a lot!
Haha. It's kind of somewhere in between the two.
I'm working on a Lisp dialect. It doesn't have a name yet. The general goal is for it to be an easy-to-use scripting/extension language for Rust programs. I chose to make it Lisp-esque because the syntax is braindead simple.
You can use any exit code if you wish: https://doc.rust-lang.org/std/process/fn.exit.html
Still poking around on my [organn](https://github.com/monsieursquirrel/organn) Changes since I last posted: * Midi input with some support for midi CCs * Audio processing is now multi threaded * Frequencies changed to more accurately resemble a hammond organ
Well: https://github.com/rust-lang/rust/blob/master/src/libstd/rt.rs#L15-L17 ``` The APIs in this module are highly unstable, and should be considered as private implementation details for the time being. ``` I'd consider the return code of `lang_start` an API.
"Mecanism" should be spelled mechanism with an "h" right?
System packages aren't usually put on `/usr/local/bin`, it's usually safe to install there as a default directory for global installs.
You might also be interested in the [`stack`](https://crates.io/crates/stack) crate which has a `StackVec` type. Sadly, no `Write` impl from the looks of it.
`write!()` does in fact work with both `std::io::Write` and `std::fmt::Write` implementors, but both cases are string based (they enforce valid UTF-8 when using formatting). By the way, you can use `b'\n'` in the match, and you won't need the comment.
Yeah, there have been enough changes in the past week that it's in a limbo state while we put the finishing touches on https://github.com/dhananjay92/saltfs/commit/61896ce164188a5f33baf75a9172c43fafd49c95 .
Thanks indeed for your great answer. I could very well imagine an option for rustc to give the exit code in case of panic, or some other way like that - but it looks like relying on 101 for now is OK.
Yeah exactly this; a strangely fancy term for something a lot of people probably do without thinking. &gt; "Dependency Injection" is a 25-dollar term for a 5-cent concept. http://www.jamesshore.com/Blog/Dependency-Injection-Demystified.html
Full disclosure: it was my second piece of Rust that I wrote, so I'm sure it is not the *Rustiest* way to implement our challenge. Feel free to submit a PR with your changes if you want: it will be really appreciated :)
Some style notes for the author. I found the lines too crowded because of the use of long variable names. I find collecting the iterator to a `Vec`, checking its length and then indexing it easier to read than `.next().unwrap()`. On a less serious note, if you are careful enough to use `usize` for the fields that index into memory, you should use `u64` for timestamps, since 2038 will eventually happen (well, will happen before we have more than billions of train stations)!
As a .Net programmer who's done a bit of Rust programming but no low-level C or C++, what could I do to get involved?
I have decided to start a list of various areas people can look into for writing/improving libraries on Windows. Feel free to look into things on that list, or suggest additions. https://github.com/retep998/winapi-rs/issues/233
My rust learning has sort of stagnated, my problem being I just don't want to wrestle Roth the type checker anymore. I feel I'm having to resort to the Orc for explanations on what I'm doing wrong or google searches for what to do but not why it must be done like that!
One possible motivation is that not all questions suited for users.rust-lang.org are suited for StackOverflow.
Damnit, now I need to learn how to use a debugger I guess.
No, the ArrayVec implementation uses std::mem::uninitialized().
What is the state of the DWARF debug info for rust? Last time I tried (1.0 beta) there was limited support for pretty printing data structures and the experience was a bit rough around the edges.
Cool. I'll think about adding `Write` there when I have the time.
The `rust-gdb`/`rust-lldb` wrappers have improved many of the pain points.
env_logger is just one backend for the log macros. There are others on crates.io, such as fern and log4rs. And if you can't find one that works with sys log, you can impl log::Logger yourself. 
Whoa, it caught on? Haha, I just made it up. This is amazing.
[**@steveklabnik**](https://twitter.com/steveklabnik/) &gt; [2015-10-27 15:51 UTC](https://twitter.com/steveklabnik/status/659034597062262784) &gt; It's official: `::&lt;\&gt;` is 'the turbofish', aka "Rust's uglyist syntax imho" https://github.com/steveklabnik/rust/commit/4f22b4d1dbaa14da92be77434d9c94035f24ca5d#commitcomment-14014176 ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
Unfortunately rr does not work with shared memory (last time I've checked it said that it is a design decision and will not be changed).:( It is super easy to tell why something happens if you have a time machine and can inspect anything during the execution.
While this may be true for some tags, we on stackoverflow under `rust` tag are trying hard to be as gentle and as welcoming as possible. It is a known fact that stackoverflow is usually the first site displayed by search engines when they are asked about something about programming, and most people know that this is *the* site to search answers on programming questions. Asking more questions (of course, suitable for it according to its rules) and giving answers is most certainly helpful for developers in Rust, both novices and experts. Also, I don't think it is really correct to call stackoveflow one community. People with different interests and/or areas of expertise tend to stick to their respective tags. Stackoverflow is also moderated; I seriously doubt that direct offense against someone there will be tolerated.
Thanks! 
Looks great.
 lua one is pretty short rust is one of the longest :(
Implementing the request literally requires reading the raw byte-memory of each argument, which rust thinks (correctly) is unsafe (TBH, rust may be going overboard here, it's probably always safe to view an object as a slice of `u8`, equivalent to the C trick of casting to `char*`, but I guess you could have an architecture where that's unsafe...?). https://play.rust-lang.org/?gist=9bbc7c12112416233b05&amp;version=stable is an implementation which uses some shady `unsafe` code to extract the binary value of the data. It builds on top of `println!` itself and it should be obvious how to port it to `write!` or `format!` if needed.
Huh. I was feeling extremely *something* (strong disagreement but not so dry, if that makes sense) towards your starting statement of: "SO has enough bad corners that providing an alternative environment for Rust users is justified (even if that env will have to be complete in the services it provides compared to competitive SO)". The example you just gave is... bad enough, I guess; but for a personal case. I really doubt this's bad enough to justify what you're advocating with a separate platform for Rust community as opposed to the popular and, for its size, quite civil and stable, SO. You really, *really* don't want to be cushioning a community in this way. Especially given that a programmer or *whatever else* going to ask a question about Rust on SO is still for all intents and purposes asking on SO: SO's place, SO's rules. We shouldn't be making learning or working in Rust require admittance to the golden gardens of Certified-Nice Rust Community Sites. This's not a criticism to the intent, just the realization of it so far. Edit: Really? Downvote for a contrary opinion? If I mistook something, mention that. Or.. yeah, whatever.
yes and Qt Creator being C++ oriented it may actually work better than Eclipse when it comes to pretty-printing rust variables. Last time I tried with Eclipse, the results were inconsistent.
Honestly, this sounds like it's just lacking a good IDE. I was introduced to debugging in MATLAB where it's beyond simple. You clicked `play` for a normal run. If you clicked in the sidebar and enabled a breakpoint, `play` stopped at your breakpoint (I don't think you had to explicitly run debug mode...but it's been a while). The learning curve was non-existent so there was never a reason to not use debugging. If you chose to not use it, that was just your own fault. Even profile was the same, click `profile` and it spits out a bar graph pointing to your hotspots. No learning curve. No reason to avoid it. The fact that I have never found a free python IDE which I liked with debugging support basically makes it a non-starter to me. I'd imagine it might be similar for others too (or at least makes debugging much more difficult to even attempt if they're interested). rr sounds awesome though.
I don't entirely disagree, but frankly the mechanics of setting breakpoints aren't the thing that I find most annoying about debuggers (`break file:line` and `break foo::bar::baz` in gdb/rust-gdb is fine). One of the pieces I find hardest is working out where to actually put the breakpoints: early enough so that stepping forward will hit the bug, but not too early that you have to step over a pile of irrelevant junk; and, then, if you step over something that you realise you wanted/needed to investigate in more detail you basically have to restart (and then values may change).
&gt; Try to write: &gt; &gt; * The least alphanumerical characters Something tells me Haskell has this one in the bag.
the haskell one is actually super long, but ya I guess it has lots of symbols
&gt; A question asked on the Users forum will most probably help no one in the future... I don't see why that's true. The forum has a search feature.
&gt; early enough so that stepping forward will hit the bug, but not too early that you have to step over a pile of irrelevant junk So, some tips in case you are curious about using breakpoints in a debugger when rr is *not* available... 1. a trick I used to use pretty heavily earlier in my career was to use conditional breakpoints and breakpoint scripting as a way to delay a breakpoint until some other condition had been met. (It got to the point where I was writing little state-machine diagrams for myself to understand how the chain of breakpoint-enable calls should work. That was only for the really nasty bugs though.) 2. The other thing to explore is just the built-in support for breakpoint counters. The counter decrements every time the breakpoint is hit (and then it is skippedover), until the counter hits zero, at which point the breakpoint stops execution as normal. So the big trick here, when you are dealing with a deterministically-reproducible bug, is to set the counter to a huge value and then either 1. directly determine the desirable counter value (i.e. if you're dealing with a crash or some other situation where the debugger itself will stop and you can query the breakpoint's current value), or 2. use binary-search over the space of possible counter values to figure out the right one where you stop *right before* the bad condition arises. (Or a few iterations before, whatever, as you like.) Having said that, I have to admit that I don't resort to these tricks all that often anymore. Once I learned about hardware watchpoints, I realized I was employing breakpoints for scenarios where they were the wrong tool.
Not a fellow.
Using `.to_uppercase().next().unwrap()` is very likely a bug. As other comments mention, the result may be more than one `char`.
Why do we care about being competitive with SO? Especially since I posit SO is unpleasant. If tons of people are happy with it, then great! But that doesn't mean people shouldn't be allowed to seek help however and wherever they're most comfortable, and making alternative spaces that *are* more comfortable. Telling people they're wrong for using Users for things traditionally relegated to SO is *awful*. I don't care if you want more information in one place. They're not obligated to satisfy you.
I wasn't really gonna comment on it, but since you've already kicked it off... This is an interesting case for a couple reasons. 1) It's unmoderateable. You can't get people to downvote only for legitimate reasons. For all we know the downvoter is someone coming in from another community trying to subtly undermine the community with strategic downvotes! There is no way for a community to manage this behaviour. 2) This may be an example of the platform itself being toxic, and making *all* communities hosted on it worse. There is no reason that a downvote button *must* exist. Indeed, platforms like facebook and twitter have long survived with only ways to signal boost (like, comment, repost), giving only a nuclear option (flagging). HN and SO meanwhile portion out the ability to downvote based on reputation (not obviously better/worse, just interesting!).
You're definitely right so what is definitely needed is a really nice IDE which uses rr by default. Then we have the best of both worlds.
Some people have problems with different forums. I know some people who are reluctant to ask questions on SO because of it's reputation of being overly aggressive about closing off-topic or overly vague questions. I think that it's generally fine to let people ask questions in the forum they feel most comfortable, whether it's SO, Reddit, or users. While I frequently find a lot of answers on SO, since it's designed fairly well to let people find answers in the future in ways that other forum software isn't, I do still find information on other forums as well when searching. I don't think that SO is so amazing that no question should ever be asked in a different medium. And if you're concerned about making answers searchable, I hope no one ever mentions to you the existence of IRC.
I think I chose the wrong word. What I wanted to say is `exit` is for *intentional termination*. What happens when the program panics is for unintentional termination.
the gdb integration with emacs is actually pretty nice as well, you can insert/remove breakpoints, inspect the value of variables, and continue/skip/restart/... I guess that's 99% of the stuff I do in a debugger. Like the author, I have to "relearn" them every time I use them, which increases the barrier of entry.
To be precise, rr doesn't work if memory is shared between a recorded process and a non-recorded process, and the non-recorded process writes to the memory. It works fine if memory is shared read-only, or if memory is shared between multiple processes in the same recording session. Multiprocess Firefox does that a lot and rr works great with that.
Whoops, missed a "not".
the rust impl do a lot of check and report work,some cumbersome，repetitive.there should be improvable space. the C++ one only put parameters into compute function. lua is same. 
That is just the basic stuff every debugger is supposed to support.
Rust can be dramatically shortened by using iterators and the right Vec interfaces. A lot of the size is in those parts. https://github.com/captaintrain/csa-challenge/pull/19/files#diff-92045302e434ba8ca90e5a74ab4f38e2L81
Using the BufReader.lines() iterator will shorten the main function a bit at least. I have a PR in the works.
Base it on pull #19... :) https://github.com/captaintrain/csa-challenge/pull/19
I find it is easier to simply train in a Tibetan monastery for 17 years writing code that is deleted every night until you write flawless code so that you may never need a debugger. But that's not for everyone I suppose. 
&gt; the experience was a bit rough around the edges The main reason for this is that debuggers don't actually know that Rust exists. We are posing as C++ programs more or less, and try to rustify as much as we can in via pretty printers. But there are limits to how much can be done this way. The next step is to directly add Rust support for debuggers.
Thanks, but really, I should be the one thanking you for your work on debuginfo and rust-gdb!
That's exactly what I came up with :) I just changed some `Vec&lt;_&gt;`s to `&amp;[_]`s, too.
Visual display of running threads, parallel tasks, parallel watch variables, expressive break points with syntax highlighting and completion when writing them. Edit code and continue in the middle of the debugging session. Custom display formatters for data structures (back when I used GDB Python visualizers weren't supported). REPL interactions with the loaded code. Simple navigation across the code stack with automatic update of all watch windows. Ability to control scheduling behavior of specific threads. Navigation between profile data and the code in the debugging session. Visual Studio does reverse debugging, just drag the arrow backwards. 
You got me interested but it turns out it needs a Nehalem (i7) processor on x86_64 (no 32-bit cpus need apply either) whereas arm is never going to be supported. Otherwise it's great indeed :)
You can build it on anything x86, true, but it detects the cpu at runtime so the binaries are probably meant for 32-bit mode.
Yeah, it uses a byte array cursor to build the string, but AFAIK when used with `write!` it will produce a UTF-8 byte sequence unless intentionally screwed. Kudos on the `string-wrapper`, will be good to have the on-the-stack string building functionality in a crate.
What were you working on previously?
I post it here as I want some insights from you guys. What do you think? Maybe you have some other ideas how to make it?
Yeah, clippy stopped warning about it. ☺
I feel purposefully misunderstood, but that's somehow okay :). Does it perform better after optimising for clippy?
&gt; If you're not aware of the risk when you hit this, you'll waste more time than you've ever saved by this. Fair enough. I just don't think, realistically, it can happen, given that all code going into `rustc` is verified to be able to compile itself. &gt; I consider this normal usage. OK.
Pfft, I write open source software. Bugs are just puzzles for others to find...
Kind of like [Ares](https://www.reddit.com/r/rust/comments/3q9eho/whats_everyone_working_on_this_week_442015/cwdujhq)?
&gt; I just don't think, realistically, it can happen, given that all code going into rustc is verified to be able to compile itself. Modulo `#[cfg(stage0)]`.