 Awesome. Thanks.
JavaScript and python, yes. Scala also has slow compilation as one of its main drawbacks, however.
On average - slower then C++ (gcc/clang).
It sounds pretty heavily Haskell-inflected :). I can't think of any time I've actually used a `flip` function on an `Either`. The lack of an `unwrap_err_or` is one of the places where Haskell gets it right and I hope Rust finds its way with error handling (or perhaps I learn Rust better lol). 
&gt; Clone can have arbitrary complexity. `Clone` is a general trait that works on anything, so in general, you are correct, but I think that for `std::collection`s we should limit this to `O(collection.len())`. How to do this, I don't know. Ideally, we'd have a `Collection` trait that requires `Clone` and specify the semantics of `Clone` over there but right now the best one can do is probably specify this on each `impl` of `Clone` for a `std::collection`. 
&gt; Is a move equivalent to a copy (in terms of actual duplication of bits) for a type that implements Copy? Yes. &gt; I don't know why I had it in my head that moves were copy-less. This is a surprisingly common misconception. The classical counter-example is an array of `Copy` types like `[f64; 4096]`. Moving such an array is done by a bitwise copy of the object, but because the object is _huge_, this is expensive. So... if you learned that moves are free, unlearn it, and learn that "a move is a bitwise copy of the object content" instead. If the object is small, like a `Vec` (3x `usize`), then a move is fast. If the object is huge, like an array, then a move is "not that fast". When talking about `collection`s, it make sense to think about the complexity of the operations. Most Rust `collection`s have `O(1)` move, that is, moving a `collection` has a cost independent of the number of element in the `collection`. This is great. Rust arrays have `O(N)` move.`SmallVec&lt;T, M&gt;` has `O(M)` move where `M` is a constant, so while that technically is `O(1)`, whether this is good or bad depends on the number of elements in the `SmallVec`. In particular, a Rust `SmallVec` implementation is always going to move those `M*Ts` independently of whether the storage is in the heap (where this is not necessary) or the stack (where moving _all_ `T`s isn't necessary either). So this costs are different to, e.g., C++'s `small_vector&lt;T, N&gt;` which can customize move to move only as many elements as necessary
Meson is using python 3 as a build tool, and somehow devs aren't being turned off from that!
The Rust Compiler project takes 1h:35m to compile on my machine. And even with incremental builds, it's painful to change something little and have to wait +30min to compile the changes.
Do you plan to add a multiplayer feature?
It the name a Star Trek reference? :)
There is a ton of interest in other language communities that don't have package managers. See this post for C++ for example: http://pfultz2.com/blog/2017/10/27/universal-package-manager/ Also see this post: https://www.reddit.com/r/rust/comments/79xqad/cisco_has_built_a_c_package_manager_written_in/ One of the big selling points when I came from C++ to Rust was in fact cargo. And from experience with package managers from other languages (npm, pip, cabal), cargo sucks the least :).
\**claps*\*
&gt; SemVer is a lie &gt; &gt; Creates can add more exports without updating their major version. As far as I know, Rust simply does not check versioning concerns, and does not handle version-bumping for you (as e.g. Elm does), so SemVer is solely the concern of the crate creator who, being human, can (and will) fuck up regularly. I mean AFAIK you can change your entire API and claim "patch" update, and no rust tooling will notice.
Random thought, what would you think about adding symbols or coloring to identify which rfcs are currently on stable, on nightly, or currently being implemented?
I'm not saying one should use `Result` instead of using `Either`. I'm saying one should write their own enum instead of using `Either`.
Are you just here to troll? You're going to make sweeping and harmful generalisations with armchair psychology and then back it up with clickbait?
&gt; As said the problem with friendly people is that they need social pressure to stand for an ideal and will stand for oppression just as easily if there is social pressure that way. I don't believe people are friendly for altruistic reasons; they're friendly because they want to be liked which means they will go along with the dubiousness of their peers and there's research which corroborates this idea which finds that unfriendly people are more likely to stand up against their superiors and their peers when they do something that's morally wrong. Sorry, but this is complete nonsense. Friendliness is just one attribute of a person and defining it in way that it automatically includes the obeying of authority doesn't make that much sense, and at the end isn't very scientific. The whole point of friendliness in a community isn't to disallow discussions or different opinions, but to be respectful in discussions even when the opinions differ. One might even say, that a friendly community makes it easier to express a different opinion. 
You need to define what the access and memory ordering semantics are for this piece of shared memory - ie. if two threads access the same register at the same time, what should happen? It sounds like you want individual register access to be atomic? You could do this by allocating a block of `AtomicUsize`, so your memory might be represented by an `Arc&lt;Vec&lt;AtomicUsize&gt;&gt;`. This type implements `Send` and `Sync`, so you can easily share it between threads. 
We haven't really set up an infrastructure for communication yet. For the most part, we've just used the [bug page](https://bugs.kde.org/buglist.cgi?component=general&amp;list_id=1473078&amp;product=rust-qt-binding-generator&amp;resolution=---) or hijacking Reddit threads.
&gt; I've been writing Rust for a long time and have felt the urge to use a generic either type maybe once. I've written plenty of enums with two variants though! huh?
So that everyone reinvents the wheel over and over and over again?
If it was, I wouldn't tell anyone.
The banning will continue until moral or subscriptions improve.
While I've not used it yet, I like the generality of [`literator`](https://github.com/kmcallister/literator) over maplit
The JavaScript project I'm currently working on for money also takes 1-2 mins to compile. These days, the code the browser sees has only a passing similarity to what you’re writing, there's babel and other compilation stuff going on.
This virtual machine's registers and memory are similar to x86 architecture, but far simpler. So, registers in this VM are i.e. r0, r1, r2, r3, they are modelled after x86 registers like eax, ebx, ecx, etc. Memory is also similar to what we have on x86: a continuous block of memory that is able to be addressed on byte-boundary, but allows to be interacted with by using dwords and qwords as well, like this: ; x86 assembly code, Intel notation mov eax, dword ptr [1234]; mov al, byte ptr [1234]; On this VM I'm trying to implement, the code above would look like this: # custom VM assembly code load_const 1234, r0 mov dword ptr [r0], r1 mov byte ptr [r0], r2 Currently I'm using `Vec&lt;u8&gt;` as a data structure for the global memory, and I'm using unsafe `transmute` when I'm reading or writing dwords/qwords to it. When two threads access the same memory at the same time, the result is unspecified by virtual machine's specs; that's why the virtual machine implements the "lock" and "unlock" instructions, so the user can use locking to create critical sections. Register access is not an issue, because each thread has its own set of registers, so each thread "owns" its register set.
You can use `unsafe` and just send a pointer over, but then if the code running inside your VM does something stupid, the entire VM will probably explode. If you want to avoid that, you need to decide what the "correct" behavior will be and choose the right type for how you want to implement it.
https://www.reddit.com/r/rust/comments/7a29xw/cargo_for_other_languages/ very similar topic. also, https://www.reddit.com/r/rust/comments/79xqad/cisco_has_built_a_c_package_manager_written_in/ but right now, you absolutely can build c++ code with a build script in cargo. it's just not something any c++ dev I know I going to use.
Yeah, I was floored when I recently realized that the pervasive use of Babel means that Node developers have become accustomed to huge compile times (relative to other dynamic languages, anyway).
&gt; SemVer is a lie I wouldn't call that one out. Yeah, might happen, but whatever. The real issue is that the more `extern crate`s you add, the more likely it is that you'll have the same dependency linked twice, just differing in the version number. Most likely reason: You wanted to `extern crate a;` in the latest version, whereas your `extern crate b;` pulls in an old version of `a`, just because the dev of `b` was too lazy updating his dependencies, while also having too strict restrictions on `a`'s version. &gt; Loops don't return a value [Err... sure, they do.](https://play.rust-lang.org/?gist=42ec1b826475e051dda7c5d9810591c3&amp;version=stable) A recent change. &gt; [...] you often just end up not using concise iterator methods because jumping the error out is too hard. There is [`Itertools::fold_results`](https://docs.rs/itertools/*/itertools/trait.Itertools.html#method.fold_results) for that. There are many other ways for handling `Result`s and `Option`s within iterators, including [this one](https://www.reddit.com/r/rust/comments/799fuy/what_are_some_of_the_things_provided_by_the_std/dp0l919/). &gt; Specialization isn't there yet Unless you are on nightly. So, in a way, if one really-really needs that, like `rocket-rs`, then you can have it now. &gt; No param[e]trization over type size I.e. const generics. The one thing I am waiting for. If one asked me, that would be the top priority bullet point for the impl period, dead line yesterday. =)
Sorry, I had just woken up when I wrote that. What I was trying to say was: 1. I've rarely, if ever, wanted an actual generic `Either` type. 2. However, there are plenty of cases where I want a sum type with exactly two variants. I've found it much clearer to write out a specific type for it rather than reach for a generic `Either` type.
The compiler is a special case though, due to being self-hosted. Not only must it build the entire thing three times, but debug mode doesn't help because it means that compiling the subsequent stages of the compiler will be so much slower that it would offset the gains from debug mode. Servo is the more representative example that we ought to be using as the benchmark for huge Rust codebases.
Yea, I've done both. Having cargo call cmake to build c-libs and cmake calling cargo to build some rust lib and linking the result.
I really dislike how `?` operator was implemented. For me having operator that implicitly returns from function is quite bad idea. Instead I would like it to be “coalesce operator” that would be complementary to `try!` macro instead of replacing it. Also lack of pi-types is quite annoying, but there is work towards it. 
Hi there! Over the last few months I have been playing with Rust and tried to use it to analyze some of [ALICE](https://home.cern/about/experiments/alice)'s publicly available data. This is my first bigger project with Rust and I bet that there are much better approaches to the problem at hand. If anybody of you could find the time and take a quick glance at it I would love to hear your feedback! So what is the problem at hand? ALICE records millions of particle collisions and saves them to disc for later analysis. The amount of data at play is generally huge and parallelism is unavoidable. The publicly released data is in total 6.5TB, which is considered a "small sample". Furthermore, the data is provided in the [ROOT](https://root.cern.ch/) binary format. That format is unfortunately quite poorly documented and I have not been able to drop ROOT as a dependency. However, I was able to drop the 5M lines of ALICE specific code, making this a very satisfying endeavor ;) The general idea was to provide an iterator over the recorded events. That iterator should then be split up into `M` chunks. Each chunk (still being an iterator over events) is then `fold`ed into a particular analysis. Thus, we end up with `M` analysis results. Those are then merged into one and visualized with `gnuplot-rs`. So long story short: Its a map-reduce pattern. Initially, I wanted to implement a proper analysis recreating published results. I actually made a lot of headway with it, but I am afraid that it will be too obscure for an initial release which is more about the architecture than the physics. So I only added a very simply analysis example which demonstrates how the different sub-crates work together. There are more READMEs in the repository. Either way, I would love to hear what you think! PS: I want to thank all the good people who helped me out on IRC and in various github issues! 
As an aside, is there any chance we will get a [short string optimisation](https://stackoverflow.com/q/21694302/116639) in Rust? Strings are currently 24 bytes, so if you could somehow figure out how to hide a flag in there (high bit of the data pointer?), you could potentially have strings up to 23 bytes long live entirely on the stack. 
[removed]
the code is getting executed exactly once, and usually on less then 1000 values. the copy needs to happen anyways, cause the data needs to move from the binary to the dynamic memory. So i do not really think that performance is too much of a concern. if you actually need everything done at compile time, then phf is probably the right tool.
No wonder you're poor. You post in the wrong sub. Post to /r/playrust. This sub is for the Rust programming language by Mozilla.
&gt; I distrust friendly people; they're only friendly because they want you to like them and their opinion isn't worth much as they'll never say it how it is—they're invariably waaay too sensitive to social pressure. This myth (that I've seen repeated throughout the Internet) needs to die in a fire. Friendliness and honesty are not mutually exclusive qualities.
How hard would it be to extend rust to have classes and inheritance? Say I just wanted to do it for fun or for a project and had a couple months of time to dedicate myself to doing it. Alternatively say I wanted to create a basic language with classes with a java/c# like syntax and inheritance with an ownership system drawing heavy influences from rust, would this be doable in a couple months?
It is fantastic! Thank you! It would be great if it could be add to [cross](https://github.com/japaric/cross).
&gt; What would be the Rust way of dealing with such unsynchronized shared memory problem? The whole point of Rust is to not do that! So, you have to explicitly work outside of the normal Rust way of doing things. I would be tempted to manage the reference to the global memory as a [raw pointer](https://doc.rust-lang.org/book/first-edition/raw-pointers.html). That is easy to create, easy to pass around, and unsafe to dereference - which is exactly right, as in your program, accessing the shared memory *is* intrinsically unsafe; safety has to be ensured to correct user-level usage of mutexes. 
&gt; However, there are plenty of cases where I want a sum type with exactly two variants. I've found it much clearer to write out a specific type for it rather than reach for a generic Either type. Is that a general thing, or is it very very very specific to Either vs an Enum with two variants?
&gt; the Rust community is shamelessly ageist and defends it Um, what? Source? I’ve been here a long time and have never seen or heard overt ageism, or defense of ageism. I do think the Rust community has its problems, but overt -isms of any kind aren’t one of them. 
You might want to call HashMap::reserve() if you want the comparison to be fair (the insert approach is definitely slower than collect() if the HashMap has to realloc).
&gt;or maaaaybe C++ interfaces C++ doesn't have a stable ABI either.
Hmm, I don't think I understand your question. If I want to represent `A` or `B`, then I find it much clearer to define a type for `A` and `B` that is specific to the problem I'm trying to solve. One thing that might prompt me to use the `either` crate is if I would benefit from the combinators/impls it provides. I haven't had this use case though.
To elaborate on the learning curve part, although the first part is indeed really learning and understanding the ownership/lifetime system, there's a second part that some people don't know is there. There's a number of patterns and tactics you have to learn in order to implement certain kinds of things. If you're in the stage after you learn the lifetime system but before you learn the patterns, you can still end up banging your head against the borrow checker trying to figure out a way to make things work. An example of this is graph data structures, where you have to know the options like Rc&lt;RefCell&lt;T&gt;&gt; and arenas and the tradeoffs. Another somewhat related large thing to learn is the heaps of standard library functions that allow you to avoid pattern matching all the time. Beginner Rust code will often involve way more pattern matching than an experienced Rust user would write, just because the beginner doesn't know about all the combinators that exist. The first two significant projects I did in Rust I ended up quitting Rust for a few months before picking it back up again because I faced so much friction that I attributed to the borrow checker, because I understood the rules (kinda) but didn't know how to solve my problem. Even my later big Rust project that took me from novice to reasonably competent, early on I made the decision to go with Rc&lt;RefCell&lt;T&gt;&gt; for my graph, but later on I realized I really should have used an arena, but it was too late and switching would require a major overhaul.
&gt; SemVer is a lie I'm not sure what alternative you are envisioning. If you are pedantic about backwards compatibility, then fixing a bug can be a breaking change and would warrant a new major version. However, this is not how people are using version numbers.
&gt; but right now, you absolutely can build c++ code with a build script in cargo. You can, but then you have to implement your entire C++ build system in `build.rs`. IMHO, building C++ with cargo would be having some convention for the file structure, and then cargo figures out how to build it, like it does with Rust.
There’s a persistent troll who says that says github requires you to be 13+, we’re ageist. This rule is due to US law, and we also are interested in having non-GitHub logins to crates.io, but nobody has taken the time to implement it. See https://www.reddit.com/r/programming/comments/77n91s/report_ageism_in_the_tech_industry/dopdjj6/?context=3 and the conversation linked from it, for example.
Surely the macro would initialize the hash map to the correct size.
"friendly" is an interesting thing - in some cultures it's just expected. For other cultures, it comes across as fake. Not universal in the US either, as I recall from visiting Boston and experiencing the famous irritation - but once I got over being so English it was such a relief, I could be direct. Though courtesy is important in cross-cultural interactions - rudeness is counter-productive. Being an old dog myself, I'm curious where this perception of 'shamelessly ageist' comes from. 
There's 2 ways you might be using `transmute` and neither is a good fit for this: `Vec&lt;u8&gt; -&gt; Vec&lt;u??&gt;`: This can lead to out of bounds accesses and general memory unsafety. You should just grab a slice of bytes and convert them afterwards `[u8; 4] -&gt; u32`: This will mean that your VM's endianess is the same as the host's (so programs written for your VM can't rely on a defined endianness). Use something like [byteorder](https://docs.rs/byteorder/1.1.0/byteorder/) and you won't have that problem.
With [cc-rs](https://github.com/alexcrichton/cc-rs), it's really not that complex, you just have to say which files need to be compiled. If you defined a convention, then you could make a little tool that would generate a new Cargo project with that build script and with a starter c++ file in the right place. I don't think making cargo itself a polyglot build tool is within the scope of the cargo developers, since it would inherently make it a lot more complex. Keeping that complexity contained to the build script has advantages, but I still don't personally know a single c++ developer who would consider using another language's build tool. Maybe they're out there.
links in post titles can't be clicked, just FYI
There's no chance, no: https://internals.rust-lang.org/t/small-string-optimization-remove-as-mut-vec/1320
Ah, from your example instructions, it wasn't obvious that you were distinguishing registers from memory. Anyway, an "unspecified" result is different from "undefined behaviour". If you allow programs on your VM to access memory without using atomics, then your VM has undefined behaviour. This is why, if you look at something like the JVM, all pointer reads/writes are performed using atomic instructions: it doesn't prevent poorly written java programs from exhibiting unspecified behaviour, but it does prevent the JVM exhibiting undefined behaviour, which is normally considered an important guarantee of a VM.
The thing is, the optimizer can elide the copy in many circumstances. So you have to split what's happening semantically from what might actually run.
fully static isn't possible, at least not without restricting code you can write today, and so would be backwards incompatible. I forget if eager was impossible or just too foot-gunny, but we rejected it as well.
&gt; When two threads access the same memory at the same time, the result is unspecified by virtual machine's specs; that's why the virtual machine implements the "lock" and "unlock" instructions, so the user can use locking to create critical sections. Ok. Given that the answer is mostly "it doesn't matter" but (I assume) the VMs shouldn't be able to crash the host, there are a few options, but my recommendation is `Arc&lt;Vec&lt;Cell&lt;u8&gt;&gt;&gt;`: `Cell` allows you to mutate through a shared reference as long as the underlying type is a `Copy` type (and has no space overhead). `u8` fits this constraint. What you get: Unspecified but safe behaviour when people try to read-write at the same time. Edit: Turns out `Cell` doesn't implement `Sync` so this won't work. Will think of something else. [AtomicU8](https://doc.rust-lang.org/std/sync/atomic/struct.AtomicU8.html) exists, and could be used for this (`Arc&lt;Vec&lt;AtomicU8&gt;&gt;`), but is nightly-only.
Dependencies are immutable, and downloading once is the default behavior for Cargo.
&gt;# A community full of friendly people &gt; &gt;I distrust friendly people; they're only friendly because they want you to like them and their opinion isn't worth much as they'll never say it how it is—they're invariably waaay too sensitive to social pressure. That sounds like a 'you' problem.
Of course, it's hard to say for sure without getting into specifics, but generally, all of the typical benefits of Rust apply here. Surely, if you want to filter millions of packets in real-time, Rust is a great choice for that.
I think many people would favor rocket as web framework.
Compared to C/C++ I think they are fairly minor. Rust may not have your library, but aside from that it the drawbacks are fairly minor (teaching Rust may have fewer resources than e.g. C but I don't really know). Other comparisons are a bit meaningless in my opinion. Rust and Haskell (for example) are pretty much orthogonal.
It depends greatly on what you compiling, for small library or CLI app without complex dependencies it could be just several seconds or less, but for example my small 3D graphics app written with Vulkano takes almost half of minute to compile in release mode after small change. (this is the time with precompiled dependencies) Another example GTK example apps, while compiling all dependencies in release mode can take several minutes and more than a minute in debug mode, compiling app after small change takes only several seconds.
&gt; The real issue is that the more extern crates you add, the more likely it is that you'll have the same dependency linked twice, just differing in the version number. Cargo needs a way to let the user control this better, like saying "this crate must be linked only once". Someone here on reddit told me that rayon used a hack to do this (because you can't link two rayons at the same time). And any C library should in general be linked only once. But the greatest problem of this is when a crate has types or traits from another crate in its public API. This means that if you have those types coming from two different crates, if the crate is the same version it will compile; if not, compilation will fail. This can be solved with public dependencies in Cargo.toml (I've seen a proposal around this I think). On the other hand, pure Rust dependencies that don't leak to the public API of other crates can often be linked many times without any problem. This is the case for utility creates, macro crates, etc.
&gt; Loops don't return a value Rust has support for folds on iterators, which is the same thing if I'm understanding your comment correctly. 
Safe Rust has no undefined behavior. There are a few compiler bugs that can introduce it, however. They're bugs. Unsafe Rust can absolutely introduce undefined behavior: https://doc.rust-lang.org/reference/behavior-considered-undefined.html
&gt; I wouldn't call that one out. Yeah, might happen, but whatever. Elm enforces semVer when uploading so that at least type signatures match up and all the old functions are present. I have no idea how hard it'd be in Rust but it's a really nice feature.
&gt; Every language that is unique in some way has a vocal part of the community that are practically fanatical about it and will insist it is the only true way. For Rust this is type safety and avoiding unsafe code. Actually, I'd say that type safety is one of the areas Rust gets right. It's a relatively low-weight feature given the guarantees it gives you. I don't think I would want to program in a language without sum types at this point.
I'm sure it does, I'm saying your code doesn't ;)
That's not actually relevant to the article, so I should probably take it out if people are going to complain about details instead of paying attention to the actual content. It's not an argument I actually want to argue.
&gt; Rust claims to be an expression-oriented language but most looping constructs are not capable of returning a value You can return a value from a loop in Rust via `loop`, e.g. `let x = loop { break 42 };` You appear to be aware of this, given that you say "most looping constructs", but it's not clear to me how would would add this behavior to `while` or `for`. The key thing about `loop` is that it guarantees at-least-once semantics (which is why `let x; loop { x = 2; break }` works), which `while` and `for` do not (and I don't see how they ever would). Without such a guarantee, one would risk using uninitialized variables. In addition, AFAIK it's not a requirement for expression-oriented languages to be able to return values from loops, e.g. while I'm no OCaml expert, I think that idiomatic OCaml code uses `for` strictly for side effects, requiring `for` bodies to evaluate to `unit`. And even with the ability to return values from loops Rust still doesn't pretend to be 100% expression-oriented; variable declarations are intentionally not expressions (not to be confused with assignment, which is an expression that always returns `()`).
I'm not saying it's not getting it right. I'm saying people take great steps to avoid unsafe code by using the type system to create convoluted hard to use messes. Or they try to shoehorn Rust into being what it is not, a high level language. One must take a very critical eye to every crate they use. Lots of libraries that people promote are crap.
Is there a reason why this has a dependency on tokio? It doesn't seem like the crate is doing any IO.
Oh, this stupid shit. Trolled before coffee, damn.
This is very similar to C++ shared pointers and their variants. Thank you for your detailed response. Boost libraries has a good collection of building blocks for simplifying managing lifecycle of objects. 
The projects I work on take 1 to 2 minutes to build too, but it's a non-issue because the watch cycle takes 1 to 3 seconds.
/r/playrust
You can control whether you want to let someone extend the lifecycle by making the reference count private in C++ and just expose it via operator overloading. The way boost intrusive or shared pointers work. 
Actually, if I'm understanding what you mean, coalescing errors is the purpose of the [`catch` section in the original `?` operator RFC](https://github.com/rust-lang/rfcs/blob/master/text/0243-trait-based-exception-handling.md#catch-expressions). That sound right? :)
Having gone down the rabbit hole of designing build systems, I'd say the basic problem is that legacy projects have very tangled build specifications. The code itself can be a joy to read but the build is done with some unholy mess. Peter Drahos has a project lua-dist which aims to build the whole Lua ecosystem consistently in CMake, and the big problem he found was reverse-engineering the build process so it could be clearly expressed. 
Try [`reqwest`](https://docs.rs/reqwest).
So I played around with this for a bit, and one thing I noticed is that a sufficiently large part of what you're benchmarking in your example is actually the allocator. Adding benchmarks or additional warm-up and/or changing the order in which the benchmarks are executed I can get either implementation to appear faster, or have them as fast as each other. I'm not saying that this is the case for your code in your actual project, but the benchmark you've shown is flawed in that regard and doesn't actually allow to draw any conclusions. I would be interested in an example that is closer to your actual code though. One thing that comes to mind might be aliasing information, which would differ the most when your tuples actually contain references, because when they're passed as individual arguments, each could get the `noalias` attribute, but when passed as a tuple, only the whole tuple gets it, so LLVM has to assume that the pointers might alias something. For those who care, I stumbled upon the flawed benchmark, because I wondered whether using pattern matching for the function argument, i.e. `(a, b): (Vec&lt;T&gt;, Vec&lt;T&gt;)`, is slower than binding the whole tuple and indexing into it, i.e. using `x: (Vec&lt;T&gt;, Vec&lt;T&gt;)` as the argument and `x.0` and `X.1` in the body. We do perform an extra copy in the pattern matching case, which seems useless in this example. Turned out that yes, the code with the simple binding _looked_ better, because a whole set of memcpys was missing, but the benchmark said that it was slower. And after some digging, I found out that this _most likely_ can be attributed to the allocator contributing so much to the runtime of these functions, and its initial state, at the start of the individual benchmarks, can skew the results in one direction or another. 
I'm not an expert but I'd think the problem with being able have a labeled return from a closure is either your "return" now means "maybe throw an exception", or you need a borrow-checker for these labels If I have a closure that has a labeled return to a surrounding scope, and then I pass it to another function, which passes it to another function, and another, and finally it gets called... what happens? Okay, it unwinds the stack down until it finds the given scope where the exit was defined, and goes there. Okay, so you take the same closure, and *return* it from the function where it was defined. Then it gets called, it tries to return to the given label... where is it supposed to go? That label no longer exists. The stack frame where it is defined went poof long ago. Perhaps you say "okay it will walk the stack unwinding frames as it goes until it finds a matching label", and you've re-invented exceptions. The pros and cons of exceptions are a different argument, I'm just pointing out that this is what this behavior is equivalent to. Okay, so instead you say "a closure is only valid when the stack frame where the label is defined still exists". But a closure is just an object, so you can stuff it into a struct on the heap and leave it there and call it from an entirely different thread if you want. So suddenly you need a way to track when the *lifetime* of the closure is still valid: The borrow checker needs to handle these labels. This idea maybe isn't totally crazy, actually, but isn't an especially trivial endeavor either. Frankly there's looooots of other things I'd really like from Rust, *especially* from closures, before I care about having the borrow checker deal with non-local exits. Plus this still becomes very similar to exceptions because you still have to unwind the stack outside of a panic. I recall this being something Rust wants to avoid, but I can't recall quite why; my guess would be because it makes borrow-checking hard.
Yeah. Something like this. However I still would prefer making such things library-way instead of language-way. 
I don't get the issue here. What problem isn't solved by using python 3?
I wouldn't want to take this on at the moment, but I may be interested in at least contributing at some point in the future. I'm vaguely planning to make a music player (itunes alike) in Rust (but I'm waiting for the GUI story to sort itself out first) and MusicBrainz integration would be really useful.
Sure. That's totally orthogonal to how lifetimes work though.
Biggest pain in my butt is the inability of an iterator to own data but produce items that borrow from that data. I think. Am I describing this right?
&gt; When you look at Rust contributors the vast majority of contribution seems to come from North America. I suspect this is underestimating the distribution of Rust contributors. Taking a quick look at the top 50 all-time contributors to the Rust repo, I count three from Germany, two from Australia, two from France, two from Russia, and one each from Italy, Lithuania, New Zealand, Romania, South Africa, and South Korea. That's not counting the Indian-American (I've never asked if he was born/raised in India), or the one whose accent I can't place but whom I suspect is Middle-Eastern. (And it's also not counting the four Canadians, who are indeed North American but who probably wouldn't appreciate being lumped in as "North America" when that so often is just used to mean "United States" :P ). I think we're actually doing quite well in non-U.S. contributors, given how U.S.-centric (or, at best, Anglophonic) most modern OSS is otherwise. Which isn't to say we can't continue striving for better, of course!
But `?` isn't implicit, it's an explicit marker that means "this might return from the function", exactly like `try!` was. Not to mention requiring the function signature to explicitly announce a `Result` return type...
Unless this is lambda. And still I would never expect operator to return, macro by default mean “here be dragons”. 
Took me a sec to realize that this was supposed to link to the page at http://www.codemesh.io/codemesh2017/andrew-stone , rather than expand to an image. OP, I'd recommend you delete this and resubmit the link.
I think the main criticism of eager drops was the use of timers.
The remaining stuff I mostly agree with. Except for that statement I replied to above, it's a nice article :)
Another UB that is easy to hit is int &lt;-&gt; float conversions. 
IMO futures and streams covers practically everything. We also have actix for actor based concurrency.
I will be trying to use Rust for kernel development. So far nothing new, but the target is [Schillix](http://schillix.sourceforge.net/), an OpenSolaris/Illumos distribution. Does anyone have experience setting up Rust dev on OpenSolaris and how to link to the kernel? Which obstacles will I have to look out for? I have found [the platform support page](https://forge.rust-lang.org/platform-support.html) and [this thread](https://internals.rust-lang.org/t/building-rustc-on-solaris/3599/22) on rust-internals, but am unsure how to proceed. Do I have to cross-compile?
You need to install and build dependencies yourself for one. Then the dependencies are different (in more than just package names) across distributions. For instance, there's not even agreement on what versions the executable names refer to, like `pip`, `pip3`, `python`, `python3`, `virtualenv`. I have a `python3.6m` executable on Arch for some sadistic reason. This would be fine if you didn't neet to ship these incredibly fragile wrapper shellscripts around that tried to identify what linux box this is. Then, if you use asyncio in python &gt;=3.5 you may need ppas or equivalents. If you want to run on CoreOS (say) then python only worked with static pypi. Not sure if this is still true. Then, there's private repos, which may or may not need special access. There were other options as well we looked at like PEX and shipping it with a docker container (to run docker in docker), but they all sounded too insane to use. Personally, I think python deployment on anything that isn't a known host or a docker container is a complete mess.
There is UB by design in unsafe. And see the "unsound" tag in the bug tracker.
&gt; like saying "this crate must be linked only once". This is what the `links` key does. &gt; rayon used a hack to do this IIRC, it's more that they split out the core into a separate crate, which will never go to a 2.0, so that you only ever have one copy of the core.
This is the kind of thing I'm looking for, thanks. I shouldn't need to enlarge the file ever, so this is perfect.
Yes, but if you use llvm as your C++ compiler, have intimate knowledge of rustc, and don't need all C++ features - if you're Servo/Mozilla - you can get the two calling each other in ways that go beyond what C specifies. That's what I mean by "maaaaaybe".
I did think about it, would be great to have people play simultaneously. I'll study more on it. At the moment, one can use other tools like `screen` or `tmux`to share terminal sessions.
Unfortunately its nightly only, and doesn't support async hyper. But I agree it has the best foundations, and aside from maybe Rouille it feels the most like a "rust webframework" and not a port of some other language's design patterns.
&gt; It is fantastic! Thanks! &gt; It would be great if it could be add to cross. cross seems like a very cool project. There are a few requirements for my script, including having a custom compiled wine, so its not very lean on requirements yet. I hope that my wine issue gets fixed, and my msitools releases a new version with [my fix](https://github.com/GNOME/msitools/commit/b01459f9eee8566423f795283c48e1f38570adfd). Once there are fixed wine and msitools versions available, and they are inside official ubuntu releases, it should be easy to integrate. Until then I'm not sure. What can be done instead is to maybe settle with the 2015 build tools at first. Maybe they don't require the wine fix? Either way some way to extract the msi file is still needed... maybe msiexec from wine? /u/japaric what do you say?
I think a (simple) custom language would be faster and let you focus on your problem more. Hacking it into rustc would be very interesting no doubt, but it's a huge codebase that you'd have to learn and modify at several levels; compile times alone are pretty brutal. I won't link because I'm on my phone, but Dyon is a scripting language written in Rust that shares some of its semantics, might be worth looking at what they did. And if you do decide to have rustc, or have deep questions about the ownership system, the rust-internals channel on irc is where you'll find the people who know. I'm half-tempted to flame about why you'd want OOP in Rust, but I'll refrain ;) Good luck!
I also don't understand how such an idea could even start? I'm friendly because it makes interactions with people nicer and simpler, not because i want my opinion to mean any more or less. It's basic common courtesy when interacting with people. And, as you said, honesty is not tied to that, it's just... weird to me
So you've constantly been reimplementing subsets of Either?
The last chapter of the rust Book version 2 shows you how yo make a basic http server from TCP primitives. Maybe that's a start? I'm not currently aware of any others.
&gt; SemVer is a lie &gt; &gt; Creates can add more exports without updating their major version. SemVer doesn't require updating the major version just for adding more exports. You can make backward-compatible changes with a minor version bump, including adding new exports.
Thanks for looking into this. It's easily possible this is distorting my real-world example since the struct in question is somewhat large/complicated. In my actual case one of the structs in a 2-member tuple has several layers (3-4, depending) of struct members with struct members, with plenty of generics along the way. It was daunting to try to replicate it in a playground so I opted for a simple example. Nothing on the heap, though. The question I have after reading this is - how do I mitigate this effect when benchmarking? There's no obvious way to me to solve the problem you present. 
Yup! I guess it's even worse than that. I re-implement subsets of N-arity generic sums too.
If there's nothing on the heap in your real world code, then the allocator doesn't come into play and we can take this off the list. I've sometimes seen "not so good" interactions between some LLVM optimization passes that can turn what should be a simple contiguous memcpy into serious of lots of small copies. That needs a look at the generated LLVM IR / asm, but also isn't something that should account for a whole 100ns. Are you using pattern matching on the tuple argument like in your example? If so, please try whether it makes a difference when you avoid that and access the tuple members using the `x.0`, `x.1` syntax. The would avoid a copy of the tuple members introduced by how pattern matching works at the moment.
I'm not trolling. You haven't answered any of my questions. You've only rephrased the same statement over and over again, so I've tried to simplify the questions more and more. I am genuinely surprised you don't see the irony in the statements you've made so far. But you have ripgrep in your flair, so if you're the author, I'm all ears for a real, objective comparison of pros and cons between a common Either type and everybody reimplementing a subset of it and why you think the latter is better. But please note, criticizing your statements and/or decisions doesn't mean bad faith. Also, "I simply like doing things this way" doesn't mean it's an objectively better thing to do. EDIT: Also, you'll have to convince me why the Haskell people are wrong to provide a general Either type.
Thanks for that at least. :D
Ok I take this as one more argument not to let this project die completely. (One option I'd not be exactly proud of is to publish to crates.io and just help users when they report something in the issues tracker... 😬)
I just used it for the first time this weekend to describe the return type of a function that builds either a `RegexFilter` or a `PoolFilter`. This was to avoid boxing the return type. I could have just written a custom enum to do the same thing, but I didn't because A) I named it 'Filter' at first, which wound up being the name I wanted to use for the filter trait, and B) I wanted to try the crate.
I don't really have a reason why I would want it. I'm trying to come up with an idea for my final year project at university and want to do something rust or programming language related. I had the idea that Java wouldn't need a garbage collector if it contained a system like this. Just an idea still not fully thought through.
A few of the subtle issues I've hit. --- `tokio`/`futures` is okay, but getting all your libs that use `tokio` to share the same reactor (the core epoll abstraction) can be painful. Different library will mange how `epoll` is _polled_ differently which and lead to you doing _soft_ thread per connection when you need to cross library boundaries. Also while _most_ libraries expose a way you can bind a pre-existing `tokio reactor` to them, this generally won't have many examples. --- Building a stateful stream protocol in `tokio` also feels extremely painful. I've yet to see good solutions to this. I've ended up implementing `Stream` for a struct, and storing a `Box&lt;Stream&gt;` internally to cope it feels messy. You end up with this massive god `poll(&amp;mut self` function. --- SSL/TLS support is kind of a shit show. `native-tls` is fairly nice and goes miles to solving the problem. But if you compile and deploy on different (Linux) distros (or package in docker) with different OpenSSL's versions you run into issues right off the bat. I suggest statically linking OpenSSL via modifying `openssl-rs`'s `build.rs`, but this can greatly impact build times. --- `musl` support is in a weird place, if you deploy on Alpine Linux. This can make C/C++ deps painful as they also need `musl` support as well and it is lacking a handful of glibc specific symbols. --- DNS support isn't a first party citizen. So most crates require you to handle DNS out of band, this isn't super painful but annoying. --- Libraries heavily over use `error_chain`. This makes understanding what is failing pretty hard. You'll end up digging into dependencies to understand where errors come from, to understand how to log them, when to affect your health check, what is fatal, what isn't. Your error checking will become pretty recursive when you have multiple levels of `error_chain` garbage, like `MyDep::Os(io::Error)`, and `MyDep::Http(HttpLib::Os(io::Error))`, and `MyDep::Http(HttpLib::ItsDep(InnerDep::Os(io::Error)))` 
Hmm...Not sure I understand what you mean. Would that be exposed as a macro instead? /me is curious what you mean now.
…but not above the Fortran programs that don't manually unroll the loops.
I'm glad to see redhat backing Rust, but why would I use this over rustup?
My point is that the missing optimization is not SIMD, it's loop unrolling. 
Looks interesting. a) would definitely be an interesting project, not sure what b) entails but perhaps I could try and see if interest grows organically? Licenses and where the code is hosted are non-issues to me.
IME, if you’re in the position to ask this question, you’re not the target for this kind of tooling. There are many places where you’re only allowed to use software provided by a whitelist of vendors; this kind of thing is for them.
Cargo is a build system and a package manager for _Rust_. You are looking for cross-language build systems, which there are a few, including CMake and Bazel.
That's true, thanks!
&gt; Generally the Microsoft linker is seen to be superior to the gcc one. For those curious what this is referring to, this is because it supports linking with Windows-native libraries and produces Windows-native debug info for use with e.g. the Visual Studio debugger and WinDBG, while GNU LD does just enough to produce a runnable exe without supporting any of that.
I neither believe my opinion is objectively right nor do I believe that Haskell people are wrong. So it seems there is nothing to convince you of at all! :-) &gt; everybody reimplementing a subset of it and why you think the latter is better. My previous comment was serious: if you're going to tell me that not using `Either&lt;A, B&gt;` for every single sum type with two variants is tantamount to "reimplementing" `Either&lt;A, B&gt;`, then it necessarily follows that every single non-generic sum of `N` variants is itself a reimplementation of `Any&lt;A_1, A_2, ..., A_N&gt;`. If that's true, then it seems the implication of your argument is that non-generic sums shouldn't be used at all. But *of course*, that is an absurd conclusion to draw, and I'm reasonably convinced you don't believe it. Ah! But that means "reimplementation" isn't the full story here---there's some other criterion one needs to use when deciding to either use a generic sum type or a concrete problem specific sum. What is it? Perhaps it is frequency? What else? That seems like a giant grey area to me, and I don't think there is anything trivial about grey areas. In my world, "what else" includes "code clarity." There's really nothing objective about code clarity. Sometimes a generic type helps code clarity, and other times, I think it hurts code clarity. Reasonable people can disagree over these things, and this is invariably why I come down on the side of not using `Either&lt;A, B&gt;` in favor of problem specific sums. Problem specific sums benefit from having better names, not only in the variants themselves, but in the operations defined on them *and* the documentation. Of course, that doesn't preclude using a generic sum, but if the generic type isn't pulling its weight or buying you anything, then why bother with it? I don't come on the Internet to win arguments, so if your standard of evidence to be convinced on this is some sort of objective argument, then you won't get it from me and we should just quit now. Me? I'm happy to live in the grey!
**No const generic** *problem*: making things like fixed dimension array hard. *(partial) solution*: 1. Use macro to generate impls. 2. Wait for const generic lands (Not until 2018 I believe?). 3. Use [`typenum`](https://github.com/paholg/typenum) **Can't borrow a part of struct** *problem*: You can't write impl T { fn x(&amp;mut self) -&gt; X { &amp;mut self.x } fn y(&amp;mut self) -&gt; Y { &amp;mut self.y } fn z(&amp;mut self) { let (x, y) = (self.x(), self.y()); } } So sometimes you can't create a shorthand `.x()` for `.bla.bla.bla.x` *(partial) solution*: 1. A `split` function **No return type deduction** *problem*: 1. When you are returning `.map(...).filter(...).map_err(...)...`, you know... 2. Sometime the output lifetime is so obvious but still have to write it. *benefit*: Make analyzing rust code could be done locally. *(partial) solution*: 1. `impl Trait` **`clone` everywhere** *problem*: 1. Every time when working with something like `Rc`, I wish there is a shorthand (maybe `~x`) for `x.clone()` 2. When working with closure, you have to write the following boilerplate most of the time . { let x = x.clone(); let y = y.clone(); || { ... } } *benefit*: Move by default improves efficiency. *(partial) solution*: 1. Type faster... **`f32` and `f64` don't implement `Ord`** *problem*: 1. Can't simply write `Vec&lt;f64&gt;::sort()` 2. Can't even write `min(0.1, 0.2)` *benefit*: Force programmers to handle `nan` properly. *(partial) solution*: 1. `.sort_by(|a, b| a.partial_cmp(b).unwrap())`. 2. Use `(0.1).min(0.2)`. **No default arguments** *problem*: Can't have a function like `fn f(flag: bool = true)` *(partial) solution*: 1. [Builder pattern](https://aturon.github.io/ownership/builders.html) (But double the code length). 2. Use macro to simulate (Hmm...). **Lot's of things you won't know before digging a lot of docs** *problem*: 1. Easily confused by other's code until you notice `impl FromIterator&lt;Result&lt;A, E&gt;&gt; for Result&lt;V, E&gt;`. 2. Rare case, but sometimes you need to know `for &lt;'a&gt;` syntax. 3. Bunch of new feature. *(partial) solution*: 1. Read docs/rust repo/reddit when you have free time. **Need to know some essential crate** *problem*: 1. For example, Error struct generator (e.g. `error-chain`), `lazy_static`. 2. Or else you're writing a lot of boilerplate. *(partial) solution*: 1. Search `crate.io` first. **Hard to refactor** *problem*: 1. If you sudden find out a variable `x` has to be wrapped in `Rc&lt;RefCell&gt;`, you'll have to replace every `&amp;x` to `x.borrow()`. *(partial) solution*: 1. Think more before you code... **Some other** 1. Module system is a little confusing. 2. What can be done in `unsafe` is not documented clearly (Or maybe I missed it?). 3. No inherent, can't create a simple wrapper that change only a function. **Wish list** 1. Destruction, so we can write `(x, y) = (y, x)`. 2. String interpolation. Really want something like `"X = {x}"` instead of `format!`. 3. Return outer function from closure, something like `.map(|_| return@outer)`.
I might be missing the something here, but don't most people these day use react in such a way that they only look at state in order to do a re-render? They use pure-components which only respond to shallow state change comparisons.
You get the benefit that our developers and QE make sure this is well integrated with the rest of RHEL. If you're doing your own packaging or container development, it's easier to be able to get the toolchain directly from normal repositories. And once this gets promoted from tech preview, you'll get the usual Red Hat support available for rust-toolset too.
Also, for me, everything that requires less than 3 characters should be considered implicit. Honestly I know no other language that would fire early return from function with only one character. Also I think that this behaviour is exceptional among all other languages (in all other languages I know `?.` or similar operator works locally and do not change behaviour of whole function). I still believe that reduction of scope of `?` RFC (aka merging `catch` behaviour with `?`) would be better solution. 
&gt; [loops returning values] What? They don't in statement-oriented imperative languages because that's how the statement-oriented paradigm works. And they don't in expression-oriented functional languages because those languages don't even have loops. The language provides tail-call optimization, which allows the standard library to write `fold`/`inject`. The only thing that makes sense is a "labelled return" or "break with value" and Rust recently added that feature. If you're thinking "I'd like to return a value from a `for` loop," you probably mean `fold`, and a value from a `while` loop, perhaps `map` `take_while` `last`.
Yes, but that's for component re-renders. After doing the component re-renders, React itself diffs the resulting virtual DOM and applies that diff to the real DOM. What happens in Glimmer.js (and similar libraries) is that the virtual DOM diffing step is skipped, and the state changes are directly applied to the real DOM. This is only possible because it knows exactly what parts of the DOM can change, based on the template definitions. JSX/vDOM needs to at least diff the virtual DOM of the components whose state changed.
That's an impressive amounts of effort instead of just installing the thing in a Windows environment and swiping the necessary binaries and libraries.
You are right, these two qualities are not mutually exclusive, but people often take criticism as personal attacks. I've seen cases where friendliness became a more important factor in a community than honesty, and that kinda held back the community members from improving (criticism was replaced by back-patting - this was a group of 3d artists). I'm not saying this is the case if you look at the rust groups, but it surely can happen. 
11am PDT happens when this comment is 43 minutes old. You can find the live countdown here: https://countle.com/H91883O5a --- I'm a bot, if you want to send feedback, please comment below or send a PM.
I believe it entirely doable for a structural diff of external surface between two libraries. We should actually calc semver IDs with optional manual bumps. The test code should be separated into interior and exterior facing modules. The could help maintain semantic invariants. 
So close. In *24 hours and 42 minutes* from this post.
I've definitely waited more than an hour for a Scala project to compile before ;)
There are more issues described in [retep998's comment here](https://github.com/rust-lang/rust/issues/39915#issuecomment-280805056): &gt; MinGW's linker has a variety of issues ranging from a lack of ASLR to no bigobj support. I do hope one day we will be using LLVM's linker, `lld`, on all platforms, since it's quality and performance is much better than `ld`'s or `link.exe`'s.
Thank you. That is a much more reasonable argument than all of the "I don't even know why the Either enum exists" comments, both here and on the RFC to remove std::either from ~3 years ago. I agree with the argument on code clarity. I'd lean towards using the Either type because it's simple enough to remember "either this or that" and comes with all kinds of practically useful combinators for free. Haskell reminds you that Left is for the error, and Right is for the success (because it's right). So it's easy to remember. Why the same reasoning doesn't apply to `Any&lt;...&gt;` is because everytime you add a variant, you double the possibilities, adding more potential for confusion. Sometimes code clarity will take a hit, especially if you represent a certain process that is problem specific in terms of those general combinators, no doubt, and that's when I would personally wrap the chain of calls in a function with a reasonable name. A lot of things are being designed and developed over the internet, so it's very reasonable to expect a certain level of rigor when arguing. I don't come to have arguments either, but happy-dreamy statements on technical topics without any reasoning are a waste of everyone's time, and most definitely confuse newcomers.
That's fair, but it goes both ways. People can mistake personal attacks for criticism too!
* Most of the Rust users are coming from C/C++. This can be a bridge. This is not true. Rust has sizable numbers of people coming in from other languages, most notable Python. (Note that the question is "What language are you _most_ comfortable with). https://blog.rust-lang.org/images/2016-06-Survey/what_language.png The problem I see is here: * And, at least C/C++ will get a well-built project and package management system. For cargo to become appropriate tooling for C/C++, we'd have to take over its package management and convince projects to use it. We'd be another player in the field. If the project already _uses_ an appropriate competitor, we could just as well using a build script like many `-sys`-crates do. Which would open a huge can of worms. And given the amount of people we have, I agree that in an ideal world with infinite resources, this might be a good move, but currently, I don't see this happening. 
I’ve had more problems with cargo than modern cabal, though “modern cabal” is relatively recent. I have high hopes for cargo in the future.
Speaking as someone who once firmly believed that every nice person was either a liar or stupid, I cannot stress enough how wrong I was. It is entirely possible to be honest and critical while still respecting people and their emotions. Sure, it's more work to communicate that way, but it's so totally worth it.
Python is slow. I use software written in it and I appreciate it but... it’s still slow and I sometimes want to rewrite things. 
Tokio is not okay but a mess and people jumped on that bandwagon way too fast. TLS it's best to compile openssl statically yourself and point .cargo/config to your lib dirs. 
Well I wouldn't interpret that to mean "don't use sum types." Rather that some invariants are possible to check statically, but a real pain in the ass in practice: for example, when serializing JSON, you shouldn't ever write the same field to an object twice. That *is* a good rule in principle, but expressing that rule in the type system and putting a potentially huge burden of proof on your user to satisfy this type can be a real pain in the ass for something that was never much of a practical issue in the first place.
No, his point is perfectly valid here. He values people who are willing to challenge him over people who are not in the name of politeness. This isn't a myth and it isn't an idea that needs to go away.
I'm aware. First, the windows installer installs a bunch of stuff that is not really needed. Here I only download and extract the needed things (or well, a smaller superset of it at least). Second, I wanted to help people who don't have a windows installation around. Third, I loved the challenge of it :).
This should be solved once we have Associated Type Constructors, no?
&gt; C++ doesn't have a stable ABI either. For a given platform, the C++ ABI is more or less fixed; and on most it's the Itanium ABI (obviously Windows prefers a different one...).
&gt; Libraries heavily over use error_chain. This makes understanding what is failing pretty hard. Is this error chain's fault? Is the problem with error chain or people not considering what their error hierarchy should look like? Do you have a suggested alternative? Personally, I consider my wrapping my deps as an implementation detail and would like error chain to not expose what types I wrap. If someone wants more detail in the errors, they can open an issue and I can add it.
That is my understanding.
&gt; He values people who are willing to challenge him over people who are not in the name of politeness. The point is that this isn't a real dichotomy. You can challenge someone while being polite.
To add to the others - Language / stdlib immaturity. Not all RFCs are implemented. Not everything has been formalized into an RFC. One example I ran into recently is I wanted to implement the `Fn` trait. Apparently, you can't (yet?) and they don't make that clear. Another is lack of visibility on `enum`. - Implicit behavior conflicting with explicit behavior. We wanted to implement `From&lt;IntoIterator&gt;` on a type but also `IntoIterator`. Unfortunately, this conflicts with `From&lt;Self&gt; -&gt; Self` which is implemented for all types.
You can also climb mount everest but I would rather make decisions based upon the norm than the outlier. edit: to be clear here, you may think you're being polite, but the person receiving the criticism is more likely to take it negatively. That's human nature, and I'd rather be around people who are honest enough in their interactions to avoid the hole of "politeness" as a value.
Seems like there's 1) SIMD support 2) loop unrolling.
I suspect they want `?` to be a coalescing operator (`catch`-by-default, sort of) and then `try!` (a library solution) as the big surrounding syntax.
You talk about `Rc`, `RefCell` &amp; co., so I thought I might as well ask a question regarding them. I have never actually used them extensively myself. Currently, in 30K lines I use `RefCell`only once, and `Rc` zero times. The one use of `RefCell` is to work around some mess in windows, and I am sure I could refactor it out. This leads me to wonder what people who use them more extensively actually use them for. Am I just not writing the kind of code where they are useful? Am I missing something?
I don't think we're likely to agree here, so I'll bow out now. You're conflating far too many things that are on separate axes, as far as I'm concerned.
Excellent work! Thanks for sharing this this information. It will undoubtedly come in handy in the future. I have not dabbled with compiling for Windows yet so -if it's not too much to ask- could you expand on why using Wine + an msi Rust installer would not be a good idea?
&gt; could you expand on why using Wine + an msi Rust installer would not be a good idea? Do you mean installing the Rust compiler using an msi installer? That won't change much other than that the Rust compiler now runs with Windows as its "host". You will still need the SDK and the build tools for the `-msvc` target.
&gt; Am I just not writing the kind of code where they are useful? I'd believe so, yes. I too very rarely use Rc or RefCell.
Does creating an enum with two units instead of reusing `bool` also considered "reinventing the wheel"? Instead of this: fn take_liquid() -&gt; Either&lt;Water, Poison&gt;; // ... match take_liquid() { Either::Right(water) =&gt; { water.drink(); }, Either::Left(poison) =&gt; { poison.toss(); }, }; I'd rather have this: enum Liquid { Water(Water), Poision(Poison) } fn take_liquid() -&gt; Liquid; // ... match take_liquid() { Liquid::Water(water) =&gt; { water.drink(); }, Liquid::Poison(poison) =&gt; { poison.toss(); }, }; Didn't have to reinvent an entire wheel, and I got actually meaningful names instead of having to carefully look into what's `Left` and what's `Right`. Sure, I don't get all these combinators - but are they really useful? With `Option` and `Result` the combinators are mostly for minimizing the overhead of having to deal with the possibility of failures/no-values - and thus their asymmetric design. But with `Either` - that intentionally avoids setting a standard meanings for it's branch - are they actually useful?
As a person only interested in producing a binary that works on Windows for end-users, can I use the -gnu target instead and avoid needing the SDK and build tools? (Please bear with me. I really am clueless)
umm... have the closure return true on Err and on Ok(correctval), and false on Ok(wrongval)? find would return an Option&lt;Result&lt;T&gt;&gt;, if the option is None it hasn't found anything, it it is a result it found either the correct value, or an error
lol This is so neat. But hitting the up arrow and then playing anything makes it explode. It locks up, makes a horrible noise, and I can't even interrupt it. Also, thank you for introducing me to http://www.multiplayerpiano.com/
You are asking for alignment issues with that code, no?
Short answer: Yes! Longer answer: The SDK and the build tools are only needed for the -msvc target. For the -gnu target the needed .lib files are provided for you by your copy of the Rust toolchain, and by winapi. Usually you depend on winapi already so you don't need to do anything extra to get the SDK. You will still need a linker though, but it is usually already packaged for you by your distro so it is very easy to install compared to link.exe. As with the -msvc target or with any other custom target you will also need copies of the std facade, but they are easy to install via rustup (rustup target add &lt;target_name&gt;).
Memory maps are always aligned to page boundaries, at least according to Wikipedia, so that's not an issue. You could pass in a byte slice of any alignment, but you could also argue that that's covered under `unsafe`. If they took `memmap::Mmap` and `MmapMut`, respectively, or just asserted the alignment before the conversion, you could avoid that footgun.
Steve Klabnik is challenging you politely *right now*
Anecdotally I would say far more productive disagreement happens in the Rust community than most places on the Internet. The RFC process's success is a testament to this.
&gt; but are they really useful? Absolutely not. What are all these dumb computer scientists and category theorists doing anyways, right? It's not like they give us powerful and composable tools or something.. ~~no.. you show them, you keep on going, you'll get places.~~ ~~So yeah, never decide to write a library please.~~ Because I expect to be able to do things like liquid.and_then(). Granted, the naming in Rust is horrendous and is biased towards `Something` and `TheOppositeOfThatSomething` which is a special case rather than the general case for an `Either`/`Result` type, but that doesn't mean the general concept is terrible and useless just because those that write the Rust stdlib don't know better. Also `type Liquid = Either&lt;Water, Poison&gt;` if the name was bothering you so much. What I was proposing would be something like `alias Water = Liquid::Right`.
`Left` and `Right` is a smell: poor abstraction. Abstractions are costly and should be avoided unless the gain us something important. I see people constantly not be aware of it, and in the name of DRY adding complexity to their/our code to save a couple of superficially similar lines somewhere. Unless there are some generic operations to be commonly performed on `Either`, there is no point in having it. `Either` seems like an abstraction that would be applied just when coincidentally a function can return two outcomes. And that's it? What's the point? Where is the real gain? What if tomorrow it will have to return one of three outcomes? The abstraction was premature and refactoring is necessary. Enum with 2 variants, IMO, is more apropriate abstraction 99% of the time, and let you name each variant appropriately, documenting your code. `Result` on the other hand expresses failable operation abstraction, which is very common, and needs interoperability. 
&gt; That format is unfortunately quite poorly documented and I have not been able to drop ROOT as a dependency. However, I was able to drop the 5M lines of ALICE specific code, making this a very satisfying endeavor ;) What code were you able to drop if you didn't drop ROOT?
I'd definitely be curious what those problems were. I haven't had any problems with cargo, so I'm curious where it hasn't worked for others.
`~x` used to be equivalent to `Box::new(x)` AFAIK. That would be confusing for a shorthand for clone. If you can (on your structs) you should derive copy (read: if you can - copy copies bytes directly iirc). This doesn't need an explicit call 
&gt; Plus this still becomes very similar to exceptions because you still have to unwind the stack outside of a panic. I recall this being something Rust wants to avoid, but I can't recall quite why; my guess would be because it makes borrow-checking hard. Because it leads to all the exception-safety problems with C++. "Magically" returning from a closure is likely to mess up all the stack frames in the middle.
[removed]
 //Why must a be mut for this to work? I know any is breaking my code below `a` is an iterator. calling `any` causes it to iterate, mutating its internal state that keeps track of the iteration. //How to shorten this? like this: let z = a.any(|x|x.is_err()); Which does the same thing, just is nicer looking. //Any must have fucked this up. Yes; by calling `any`, you exhaust the entire iterator, so by the time you get to the `for` loop, there's no more iteration to do, so it loops zero times. Does that make sense?
&gt; Absolutely not. What are all these dumb computer scientists and category theorists doing anyways, right? Please see rules 4 and 6.
If you want to be able to acquire a mutable borrow of an object using two independent code paths you have a hard time getting away from a `Rc&lt;RefCell&lt;_&gt;&gt;` pattern. If you have a shared buffer between two independently operating hunks of code, for example, it is pretty common. At the same time, this is actually what I would expect the code to do, and don't have any regrets other than how verbose it is.
Yes but it's confusing. How do I have it not touch my array/list/vector? (I'm not sure what the term should be. It's container in C++, might be collection or ienumerable in C#). I'm ok with map modifying my data but any should just leave it alone. is_err is so much nicer! I may need to reread the book but I think I should code a bit more
It doesn't touch the data, it touches the iterator.
Better?
&gt; How do I have it not touch my array/list/vector? It's not touching the vector. It's *the iterator itself* that is mutable. &gt; is_err is so much nicer! I may need to reread the book but I think I should code a bit more This isn't in the book, you'd find it in the API docs. Result has many useful methods!
You copy/pasted the same snippet twice. I don't see any closures under &gt; When working with closure, you have to write the following boilerplate most of the time 
I mean, sort of. The float -&gt; int cast UB may be a "bug", but it is now four years plus that https://github.com/rust-lang/rust/issues/10184 has been open, right? Sounds like it might close soon, so perhaps the issue could be "longstanding bugs are left unfixed in the ongoing struggle between perfect and good". There is also the "`Box&lt;Any&gt;::downcast` leads to UB with hash collisions" bug; not sure if that is being tracked. Edit: not trying to be difficult, but there are three issues listed as unsound but not bugs: https://github.com/rust-lang/rust/issues?utf8=✓&amp;q=is%3Aopen%20is%3Aissue%20label%3AI-unsound%20-label%3AC-bug Maybe that should be updated, if the lack of the C-bug tag keeps them from surfacing.
How do I clone the iterator?
In large projects, big bugs can last open for a very long time. Doesn't mean they're not bugs. There's only so many hours in the day, as you allude to. Honestly I'm not more surprised that we haven't found issues like this one, or the infinite loop one, over the years.
In that specific context it was, yes. That is, if x is some kind of value. There's other details around specifically how certain types worked that are now irrelevant.
Cloning the iterator won't achieve what you want, because `map` is lazy. You can `collect` the results of `map` to a new vector, then iterate over that. [Here's an example](https://play.rust-lang.org/?gist=7f68bf6c0a0426bb84f431279aa470d2&amp;version=stable). Edit: also, you can simplify the last loop with `if let`: for x in a { if let Ok(x) = x { println!("Number is {}", x) } }
Unfortunately, I don't think that you can get a strong type system, high-level abstractions &amp; predictable performance at the same time. Rust chooses the first two, which is a great choice. Abstractions are always going to be ugly compared to e.g. Haskell because of all the low-level stuff like references, uniqueness, etc. no matter how higher-kinded we get. 
https://crates.io/crates/semver The issue seems to be that Rust is up for breaking SemVer lightly, if the fix involves certain types of changes (e.g. changing method calls to UFCS, not relying on type inference).
&gt; I distrust friendly people; they're only friendly because they want you to like them and their opinion isn't worth much as they'll never say it how it is—they're invariably waaay too sensitive to social pressure. I've been around online a while. I'll mention that if anything I've noticed that friendliness is much more productive in discussions. When folks are blunt or uncivil it ends up moving the discussion away from the topic because folks get sidetracked and feel personally affronted. There's a lot more misinterpretation of each others' arguments that happens. When folks are friendly, this never happens. I've said this before, and I'll say it again: **Civility is not the antithesis of technical discussion, it is its foundation.**
That looks MUCH nicer. What does `Vec&lt;_&gt;` mean? Or what is it called so I could look it up. I may skim book1 because book2 left a few things out like macros. I found something explaining iter and into_inter I'm not sure why they can't be defaulted so I can do blah.filter like every other language
&gt; Err... sure, they do. A recent change. Not all looping constructs do, yet. I think that needs another RFC. It also needs one to solve the problem of unexecuted loops; i.e. you need something like `for ... else`.
/u/subtly_homoerotic look at what you started. Everyones comment on what you and burntsushi said (parent comment)
`Vec&lt;_&gt;` means "a `Vec` with contents of type `_`, which is a placeholder for type inference. `collect()` is implemented for many collections, so I need to explicitly state the type I want to collect into - in this case I did it by using the "turbofish" `::&lt;&gt;` syntax, but I can also do `let a: Vec&lt;_&gt; = ...`. I can also write out the entire type, in this case something like `Vec&lt;Result&lt;usize, &amp;'static str&gt;&gt;`, but I don't have to, because the type checker is smart enough to know what type the results of `map` are. The reason `iter` and `into_iter` aren't "defaulted" is because `iter` gives you _references_ to the values in the vector, and `into_iter` consumes the vector and gives you the values directly (as if moved). There's also `iter_mut`, which gives you mutable references to values. Edit: [here's the same code with a `HashSet` in place of a `Vec`](https://play.rust-lang.org/?gist=d52cc9638a0a8ee3d98cc65abbaac1cd&amp;version=stable). Now the order of the numbers changes every time you run it :) Edit2: another cool trick for the last loop (though sort of non-obvious): for x in a.iter().flat_map(|x| x) { println!("Number is {}", x) } This works because `Result`s can be iterated over, and yield the value for the `Ok` case and nothing for the `Err` case. You can also use the awesome [itertools](https://docs.rs/itertools/) crate: extern crate itertools; use itertools::Itertools; // ... for x in a.iter().flatten() { println!("Number is {}", x) } `flatten` is pretty much just an alias for `flat_map` with an identity function. Edit3: and another cool trick: you can actually `collect` an iterator of `Result&lt;T, U&gt;` into a `Result&lt;Collection&lt;T&gt;, U&gt;`, [like this](https://play.rust-lang.org/?gist=673bf56b0fe5093ba62373b774a15d89&amp;version=stable). The conversion will [stop at first error](https://play.rust-lang.org/?gist=980a235cd9090302f70c826059c8f93e&amp;version=stable).
There's a `catch {}` block that's been proposed that is like labeled returns for errors, fwiw. But only for errors (i.e. it works with `?`, not with `return`)
&gt; That's not counting the Indian-American (I've never asked if he was born/raised in India) I'm from Boston. I have spent significant time in India as well.
no, he's disagreeing with my opinion. If you don't understand the difference I have no interest in talking to you further.
I know about the catch block but the last time I saw it it can only downscale the scope from which you return the error as well not upscale it and it doesn't solve the closure problem.
I also have no interest in talking to you further. :)
[removed]
&gt; macro by default mean “here be dragons” Really? I've never had that impression from Rust's macros. You could make the case that `unsafe` means "here be dragons," but I personally throw around `#[derive]` with relatively little worry.
I guess the point is, someone was asking for limitations or things they should watch out for. For the past four years there has been easy-to-access UB by casting `257.0f` to a `u8`. I'm not trying to knock the speed or goals of the team, but there is UB and probably will be known UB for a while (these aren't 0-day issues; ergo Rust is not appropriate for sandboxing). **Edit**: and now that I write that, and to be a bit difficult, .. the rust-lang.org homepage has said "Guaranteed Memory Safety" for as long as I have known of it. The team knows that this is false, which is a bit gross. I mean, I get why you don't want to change it, but .. maybe "Design Goals" rather than "Featuring"?
You solve the closure problem by returning an error from the closure. We should add better inference to closure bodies. I don't see cross-function boundary named returns happening in Rust. Closures are functions (well, methods). Being able to jump to outside of a function is not something functions can do; and would require ABI changes as well as a lot of other things. That said, due to Rust's lifetimes, it actually _is_ possible to reasonably build something that can enforce a closure with weird returns to stay within the scope of that return; however I am very skeptical such an RFC will get accepted.
Hey so I don't actually understand this. Lets take this code for example. The closure in map creates errors for values 5+. The line `let z = ` checks for errors. I understand it'd be more desirable to end the loop in map but maybe a map_err implementation can fix that. It doesn't *seem* hard to get errors from closures. But I only started rust last week so i'm technically still a rust idiot. fn main() { let a = vec![1, 2, 3].into_iter() .map(|x| if x &lt; 5 { Ok(x) } else { Err("E") }) .collect::&lt;Vec&lt;_&gt;&gt;(); let z = a.iter().any(Result::is_err); if z { println!("There was an error :("); return; } for x in a { match x { Ok(s) =&gt; println!("Number is {}", s), Err(_) =&gt; () } } }
&gt; Rust's resolution of identifiers actually has a hierarchy which means that something can "slip in between" Note that most languages have this problem, and no language attempts to solve this, except for Javascript (because someone updating their browser shouldn't break code). JS goes to crazy lengths to make this work; sometimes adding APIs as static methods instead of as real methods. With Rust it's just "a compiler/dependency bump may cause some code to stop compiling in a trivially fixable way because there's now an ambiguity". This is true for basically all languages with overloading or nontrivial resolution. As well as languages that let you dynamically replace methods. (We also do crater runs so if something like this actually is breaking crates; we find out.)
Okay, then how do you explain that for instance the average total number of working hours per year are low in places where people are rude like Netherlands and Germany and comparatively high in places like the US and Canada where people are friendly? German business culture is known for its efficiency which involves telling people how it is and not being friendly which can produce culture shocks for people not used to it but they get stuff done on time.
And that would involve logic that is significantly more verbose than just re-implementig the `find` logic in a for loop. Hence losing the "convenient" error propagation.
From what I understood, nalgebra makes sense mostly if you want to work with n-dimensional and/or dynamic vectors and matrices. For 2D and 3D computer graphics, I settled with cgmath for now. It seems pretty nice so far!
Most other expression oriented values have loops that can return values in Scheme an imperative `do` loop indeed just computes the last value returned and even has special syntax to return another value and `while` loop also does that and both may define an escape closure to return a value anyway. It is in theory possible to return from _any_ loop not just `loop` with `break` but in the case of another loop this involves a python-like use of `else` where you say that an else block is attached to the loop which is executed when the loop doesn't break and returns that value then. Saying that you probably meant to use `fold` or another iterator construct is way too limited, it doesn't always work that way at all and obviously you _can_ return a value from a loop if the loop is the only expression in the function by just using `return`; this is why I think on so many levels that unlabeled returns are arbitrary; it should be possible to return from _any_ enclosing continuation; not just the enclosing continuation that is the nearest function body.
Yes, but the problem is that in Rust adding a new export is _not_ backwards compatible. The way Rust works a new export can just break existing behaviour either by producing an error if you are lucky or compiling but silently introducing different behaviour and that's a big theoretical problem though not a big one in practice.
I'm not self-censoring, I'm not bothering to waste my time on someone who thinks I'm "less as a person".
I disagree with that premise. Folks are frank, not rude, and that works out fine. I'm not going to get involved in debating shaky correlations drawn between various stats.
Oh absolutely! Maybe I should have been stronger with the "there are bugs" bit, but that's what I meant by saying that. You gotta check the bugs; they're all footguns!
"less of a person" is a personal attack. We don't do that here. Feel free to discuss; but no personal attacks. (Also, steve is not self-censoring, he's saying he finds this discussion pointless at this stage)
Ehhh, if you think FOSS is US-centric you've been indeed living in a US bubble. If you go look at say Linux development or systemd development US-based contribution is an absolute minority. Like over 50% of Rust contributors come from North America and yes I mean North America. I said North-America on purpose and not the US because Canada shares the friendliness culture with the US. Rust is unusually North-America-heavy for a FOSS project. And no I don't mean this "heritage" stuff that North AMericans love to call into to make stuff seem more diverse than it is; I also wasn't born in the Netherlands; I'm still Dutch; it is my nationality and native language.
The actual creation story of the either crate was that I needed an iterator of two parts frequently, and I had enough of defining one-off two-part enums (as I was convinced one should do). Definining the enum over and over is fine but each added trait impl on top of that is a drag. So the either crate is really that, a two part iterator where you don't prefer any of them over the other. It's just case A and case B or as it's named in either -- case Left or case Right. I'm not exactly unhappy with that, I think it is fine. But if I *would* be critical, one can sense the imbalance in the either API and its trait definitions, caused by the choice to implement `Iterator` and the choice of how to do it.
&gt; Edit: not trying to be difficult, but there are three issues listed as unsound but not bugs: I'd mark them as bugs, the "bug" tag is new, maybe this is an error. Well, i tagged two out of three; the stack probes one could be construed either way.
&gt; Being an old dog myself, I'm curious where this perception of 'shamelessly ageist' comes from. Well for one Crates.io requires Github which has a "no people under 13" exclusion. And when you point this out people tend to defend this saying it is supposedly totally different from excluding other classes with arguments like "being under 13 is temporary, you grow out of it" and I'm like "Yeah, so are curable ilnesses which are expected to heal so can you just exclude everyone over an irrelevant disability which expected to pass?" and then I got no answer eh.
I'm not actually gonna ask this cause it's kind of an obnoxious question to ask, but what I _want_ to ask is: What's a ballpark ETA on _all_ of the following libraries/features being 1.0/stable: tokio, async hyper, impl trait (including use in traits), async/await syntax, and procedural macros? My main hold up in both using and recommending Rust is having to answer "soon" to that rather than "now." I wouldn't ask this formally cause the obvious answer is that lots of talented and dedicated people are working on it, and they'll be ready when they're ready. I'm not unappreciative of all the contributors' hard work.
There's no possible way to give a proper answer there. Especially "including use in traits", which as far as I know has no RFC at all. Tokio and Async hyper already do work on stable.
This is the cause of the allocation error, reaching the max_map_count. It was growing continuously over the life of the program until running out. As to why it made so many mmaps, I'm not sure, but on a hunch I replaced all BTreeMaps with HashMaps and now the map count stays fairly steady. This can't be the whole story, because I (and I'm sure many other people) write other BTree-reliant code without hitting this limit. For now at least, the program works.
Yes a lot of languages have this problem though in some it just produces an error always (Haskell) In Rust this problem though is intimately tied to why we don't have specialization yet and why only the owner of the type or the owner of the trait can implement it so it's a bit more of a problem. I never liked it and I feel it should warrant addressing. There are also languages that just discourage "opening" modules heabily encouraging that you always qualify like OCaml and if you open then you accept this risk. The thing with Rust is that you accept this risk the moment you use the `foo.bar()` notation but using UFCS everywhere is just extremely unergonomic.
How could Tokio be better so that it wouldn't be a mess in your opinion?
&gt; You solve the closure problem by returning an error from the closure. We should add better inference to closure bodies. Of course you can write logic that does the same thing but it loses the ergonomic error propagation. While exceptions are theoretically objectionable I feel (unless they are checked exceptions where a function's type indicates the exceptions it may throw) they are very ergonomic in terms of propagation so rust provided `?` to bring some of that ergonomics back to Result and I like this because it makes explicit on a call what call can fail but these ergonomics are gone once you use an inner closure. &gt; I don't see cross-function boundary named returns happening in Rust. Closures are functions (well, methods). Being able to jump to outside of a function is not something functions can do; and would require ABI changes as well as a lot of other things. A closure that has a labeled return to outside of itself would be treated the same as a closure that contains a reference with that scope. As such it can't leave the lifetime of that scope any more. &gt; That said, due to Rust's lifetimes, it actually is possible to reasonably build something that can enforce a closure with weird returns to stay within the scope of that return; however I am very skeptical such an RFC will get accepted. I'm just as sceptical sadly; it should've been there from the start but it's a big pain with error handling and loop returning and a lot of other things that "return" in rust is arbitrarily special hooking on to a specific arbitrarily chosen exit continuation while there is no theoretical reason it cannot hook up to any arbitrary exit continuation that encloses it. Rust broke one arbitrary thing already with labeled loop breaks which is really convenient at times. Only being able to break the inner loop is very arbitrary.
There's no "incremental" compiler build, because when you modify a file it incremental builds stage 1 and then _always_ builds all of stage 2 :) The only difference between fresh and incremental is that you don't have to compile llvm and some of the beginning crates in fresh.
And yet so many people who come to Germany, Netherlands or Denmark report the culture clash that people are extremely rude. "frank/direct" and "rude" are just pairs like "terrorist" and "freedom fighter" in the end.
impl Trait in traits is introduced in RFC 2071: https://github.com/rust-lang/rfcs/blob/master/text/2071-impl-trait-type-alias.md Perhaps my question was not clearly phrased. I meant, for the libraries on this list, when will they be 1.0, and for compiler features, when will they be stabilized. So in the case of Tokio and Hyper, I'm eagerly awaiting 1.0.
Yes, and folks are frank (not rude) within the Rust community too. You're fighting a false premise here.
&gt; Okay, then how do you explain that for instance the average total number of working hours per year are low in places where people are rude like Netherlands and Germany and comparatively high in places like the US and Canada where people are friendly? Ehm, sorry, German business culture is not rude. Germans may be frank, but rudeness is as much out of line as everywhere else. The thing (some) Germans have understood is that longer hours don't necessarily lead to more productivity. &gt; German business culture is known for its efficiency which involves telling people how it is and not being friendly which can produce culture shocks for people not used to it but they get stuff done on time. Nope, efficiency involves planning and good review of failures, not shouting people around. Also, German business culture is also known for not being able to finish an international airport for 5 years, among other things. If Germans are known for one thing, it's precise formulation of problems.
Ariel just added a new one five minutes after your post. :)
Been speaking my mind about Rust since before this sub existed, often argue against the popular opinion. Being articulate is way more effective than being unfriendly. The truth is, being unfriendly just means you're wasting time talking about something irrelevant, like how much you don't like so and so, or going on and on about how much they screwed up or something. These aren't means of communicating technical reasoning.
Its not so bad because incremental compile time are actually really short once the compiler is warmed up and in watch mode for active development. I have a work front-end project using webpack + babel that takes 30-120 seconds to compile including minification depending on the machine, but the incremental compile times across all of our hardware is usually measured &lt;1 second in most cases.
I apparently don't understand the difference. Can you help? What does "challenge" mean to you, if not disagree?
No it isn't, it's an observation that certain activities and thoughts actively retard your growth as a person. If that observation is too much for this subreddit then **ban me now**. Because I will not change my behavior. 
I think the worry is that the way people *are* using version numbers still leads to breakage. I screw up semver, and that makes people sad. The Rust folks make changes that are semver violations (e.g. minor breaks that you can fix with UFCS, but which still cause code to break). If you are a company with a reputation for quality software, you should understand that if you rely on semver and do not pin to a specific version of each dependency, you do not own your own destiny wrt "does code still build". This could be fine, or it could be scary, depending on what sort of org you represent.
Maybe I'm misunderstanding what you mean; that seems to do the opposite. For example, in drawbacks: &gt; There are potentially simpler ways to achieve some of the goals of this RFC, such as making impl Trait usable in traits. Ah yeah, 1.0 is tougher. Dunno about hyper, but Tokio is shooting for a big 0.1 right now, so....
I'm sure sometimes Either is a right thing to do. I just don't think it's common to be interoperability abstraction. Also sounds like derive macro might help with the boilerplate. 
The comment you're citing came after your declaration, which means you have now chosen to be dishonest. You don't have to be afraid of honesty and truth, but it does require you to be willing to engage in it yourself. And yes, I absolutely judge you for that. It absolutely makes you less as a person. It means you are less than you could be. I understand why you would consider that hurtful, but it's also the point that was made before about fake politeness and not being able to trust those who engage in it. 
**challenge** https://duckduckgo.com/?q=challenge+definition&amp;atb=v45-3_s&amp;ia=definition &gt; A demand for explanation or justification; a calling into question: a challenge to a theory. **disagree** https://duckduckgo.com/?q=define+disagree&amp;atb=v45-3_s&amp;ia=definition &gt; To have a differing opinion ---- Challenge is active, disagree is passive. If your coworkers are not challenging you on your design and code decisions then the software is less for it. You cannot write good software without that ability by everyone involved. And Steve Klabnik's response is a perfect representation of the follies of valuing politeness and agreement over everything else.
I don't really want to defend this person, but they have the point that if you replaced "12 year olds" with a protected class the community is interested in, you would probably pivot away. If Github required valid federal identification to confirm your identity because the govt said so, for example, I would wager the team would (rightly, imo) determine that this is regressive and we should do something different. I prefer the answer that "shamelessly ageist" is different from "not willing to take one on the chin for every cause", and while Rust has chosen to fight some fights they aren't fighting all of them and that is fine. 100 years from now we will all be embarrassed that we ate dolphins and didn't give them github accounts.
&gt; Absolutely not. What are all these dumb computer scientists and category theorists doing anyways, right? It's not like they give us powerful and composable tools or something.. They originate from computational theory models. These models usually use a minimal "syntax" required to be Turing-complete - and the combinators are a "standard library" that improves the expressiveness of the base mathematic model. For example - let's take the [logic combinators of lambda calculus](https://en.wikipedia.org/wiki/Lambda_calculus#Logic_and_predicates). The model's syntax is minimal, and does not provide operators like `OR` or `NOT` - so these were created as combinators. `OR a b` is both more ergonomic and more readable than `(λp.λq.p p q) a b`. But... what about `IFTHENELSE`? Sure, `IFTHENELSE p x y` is more ergonomic than `(λp.λa.λb.p a b) p x y`, but due to the nature of lambda calculus you could simply write `p x y`! Thing is - `p x y` does not convey the meaning of what you want to do, making `IFTHENELSE` more readable - even though it's less ergonomic. But - that's because lambda calculus does not have an _`if` statement_ like almost every programming language. Would you write in Rust `ifthenelse(p, || a, || b)`? Probably not - you would write `if p { a } else { b }` instead. Because you have syntax. Now, I don't say combinators are useless - they can be useful to create "library syntax" that increase the expressiveness. What I'm saying is that combinators that **decrease** the readability compared to regular syntax are useless, because readability is important enough that you should prefer the regular syntax over them. `Result`, for example, has `map`. Map is more ergonomic than a `match` that does the same thing, but more importantly - it conveys the meaning better. It says - "I want to do this in good-path" - implying bad path should be left as is. `Either`, on the other hand, has `map_left`, which says "I want to do this with left" implying right should be left as is. It may look better than a `match` on `Either`, but if you compare it to a match on a custom enum it's less readable - because it doesn't tell you what's `Left` and what's `Right`! So, to rephrase my statement - these combinators are not useless compared to `Either` without them - they are useless compared to custom enum without combinators: match take_liquid() { Liquid::Water(water) =&gt; { water.drink(); }, Liquid::Poison(poison) =&gt; { poison.toss(); }, }; take_liquid().either( |water| water.drink(), |poison| poison.toss()) The `Either` version is shorter - but I say it's worse, because you need to guess what's `Left` and what's `Right`. Which brings us to: &gt; Also `type Liquid = Either&lt;Water, Poison&gt;` if the name was bothering you so much. What I was proposing would be something like `alias Water = Liquid::Right`. Congratulations - You just aliased `Water` to poison! Please don't `drink()` it. It's `Either&lt;Water, Poison&gt;` - so `Water` is on the left and `Poison` is on the right. I assume you copied this from my own example, where I placed it deliberately - but it's just as easy to make this mistake by mistake, and if `Water` implements `toss()` and `Poison` implements `drink()` the compiler won't be able to stop you from doing this. To have such a bug with custom enums you'll have to either put `Water(Poison)` in the `enum` branch, or `Liquid::Poison(water)` in the `match` branch. If you do that, just looking at the code would screams _wrong_ - as it should.
Sorry, I've fix that.
Yeah I mean, I also hear that, but at the same time, this is something you can't just pivot away from. That is, yes, some laws are unjust, and I think this law is dumb. But there's not much that can be done about it, or at least, not by Rust. You can't pick a different provider; this is going to impact us no matter what. Even moving outside of the US doesn't help here. &gt; I swear I'm not going after you today or anything Haha no it's all good. Totally get it :)
I think you're misreading the RFC. The quoted line means that of the RFC's goals, among which is the use of impl Trait in traits, there could be simpler ways to do it.
Possibly. Maybe I'm also misunderstanding what you're saying. To me, "impl trait in traits" means "I can have a trait that has a method that returns impl Trait". There have been too many RFCs, heh.
What you described as a challenge is what Steve is doing here. Idk what to tell you.
The RFC makes it possible to return an `impl Trait`-style anonymous type from a trait method. It does not allow `-&gt; impl Trait` syntax in trait definitions or implementations.
Ahhh I see it now. Thanks!
no reasonable person is going to agree with that, sorry. what steve did is say "we're not going to agree so I'm done". That's not challenging for any reasonable use of the word. And with that characterization I now consider you a bad actor, have a good day.
You're getting what I mean. The RFC allows this via associated types. It's not as clean as `trait Foo { fn bar() -&gt; impl Baz }` but it'll get the job done.
There is a compact example in [rust-cookbook](https://rust-lang-nursery.github.io/rust-cookbook/net.html#ex-url-basic)
Well, compare with other big languages. Nobody can materialize big features like that in zero time. Pick just one of those and it's a pretty big feature, like easy to use and powerful async/await is **huge** if it can exist. What's the corresponding Swift, C#, C++ story for that?
&gt; Am I describing this right? Can you be more specific about which part of your butt feels the pain? Is it a dull pain, or more sharp and sudden?
I don't think Rust is any different or worse than other languages in how fast it's developing. If anything, Rust is faster. I'm merely expressing how much I'm looking forward to the future when these things are available. At least in my areas of the programming world, it will make a massive difference in both using Rust and convincing other people to use it.
&gt; Unfortunately, I don't think that you can get a strong type system, high-level abstractions &amp; predictable performance at the same time. What I like about Rust is that I thought this too, and they have been pretty consistently good about adding the things that you can get with these properties, as appropriate. They will always be behind languages that only care about 2 out of 3, but I've been impressed. I am not a PL researcher, so that shouldn't count for too much.
Ah yeah, I see that now, thanks :)
`cross` works with docker images, which this seems like it would be doable to package into one.
On Arch, I never use pip. I wrap every package I ever need in an AUR package and install that. Every project has a requirements.txt that can be installed via `pip3 install -r requirements.txt` for development, and `pip3 install my-published-package` also works just fine. Having anything but the most recent python3 and python 2.7 on your system is useless, but no matter what you have, it's very simple: - python: links to either python2 or python3. Avoid. - python2 links to python2.7 - python2.7 last python 2 version - python3 links to the most recent python3.x - python3.x one or more python 3 versions
Will it be here in /r/rust? When can we ask questions here on reddit?
I believe it's on https://hashnode.com/ama/with-rust-language-team-cj99mv7s101yw4rwtk5zntk8k
You should send Walter to me. It'll help you focus more.
&gt; this community doesn't want to hear that some of the things they do actively hurts them. This is inaccurate. This very thread is all about which behaviors hurt people's and project's growth, but only the comments arguing that it's okay to be uncivil are being moderated or downvoted.
ROOT makes it possible to serialize pretty much anything to disk. In ALICE the analyses are always made on the ALICE specific "Event" objects. Those objects are huge and are composed of many more ALICE specific classes. Bottom line is, that the those convoluted ALICE specific classes were originally written to disk. Initially, I thought that it will be pretty much impossible to read and use the data without the ALICE framwork, but turns out that ROOT allows access to the primitive types of each class. So this is not really a RUST thing, but surprising never the less. The (small) downside of dropping the official framework is that one has to re-implement a few things by hand, though. To be fair: not all 5M lines of code are used for the IO part and the steering of analyses. A lot of the LOCs are also reconstruction. and old analyses.
Maybe, but I never said as much and you put words into my mouth. I just said friendly people want you to like them and are too sensitive to social pressure; that's what _causes_ friendliness—wanting to be liked and following social pressure.
Tokio may be painful to use directly, but it's a necessary layer for async/await, and it's worth porting libraries to it so they can prove out the design before we commit to it too hard. Nobody's forcing you to quit using the pre-tokio versions of anything.
This is really cool! Nice job!
It's at the link. You can always ask questions on reddit; we're just explicitly making time tomorrow over there.
So you use it for polymorphism? That makes sense. Too bad all these left&amp;right combinators convinced people it's a good idea to use it as a sum type... Anonymous sum types as a language feature could be really neat: trait Foo { fn foo(self); } struct Bar(...); struct Baz(...); impl Foo for Bar; impl Foo for Baz; fn qux() -&gt; { Bar, Baz }; // qux' result can be either Bar or Baz. qux().foo(); // Both Bar and Baz impl Foo - so their sum type automatically impls it. match qux() { // The branches are anonymous too - so we use type annotations for match branches. bar: Bar =&gt; { ... }, baz: Baz =&gt; { ... }, } 
Here’s a variant of it with a few things taken to probably-undesirable extremes. Note that iterating on a slice yields references, hence the `&amp;` in closure’s arguments pattern to bind `x` to the integer inside the reference. Also if you have an iterator of `Result&lt;T, E&gt;`, you *could* collect it to `Vec&lt;Result&lt;T, E&gt;&gt;`, but you can also collect it to `Result&lt;Vec&lt;T&gt;, E&gt;`, with it producing `Err` if any of the items in the iterator is an error, or the vector of `Ok` items if they all succeed. fn main() { for s in match [1, 2, 3].iter().map(|&amp;x| if x &lt; 5 { Ok(x) } else { Err(()) }).collect::&lt;Result&lt;Vec&lt;_&gt;, _&gt;&gt;() { Ok(numbers) =&gt; numbers, Err(()) =&gt; { println!("There was an error :("); return; }, } { println!("Number is {}", s); } }
The non-destructuring example (using `x.0` and `x.1`) implementation is coming in about 50-100ns faster than the one that uses destructuring in the function signature. In the course of this I checked the `mem::size_of` for the largest object I'm working with, and it's 488 bytes. I don't know if that's huge, medium or small compared to what other people find themselves using. 
Isn't part of the beauty of Cargo how it meshes with the language to ensure breakage doesn't happen due to things like trait coherence? These guarantees would be much harder to ensure for C++
The problem I ran into (twice, once causing several hours of lost productivity) was due to the fact that `cargo` allows you to depend on multiple versions of the same package. It's the diamond dependency problem, and I haven't seen a good solution to it outside of `cabal`, though other solutions may exist. I ran into it trying to upgrade `hyper` once and another time due to `serde` (which was well-documented in the crate so I didn't waste as much time).
Huh. I imagine there are some incongruities due to Rust supporting a more imperative/OO approach than Elm.
I am trying to create a trait object nominally isn't object safe so doesn't work: trait A { fn foo&lt;T&gt;(&amp;self, arg: T); } struct Hello { a: Box&lt;A&gt;, } This fails with: 27 | a: Box&lt;A&gt;, | ^^^^^^^^^ the trait `ffi_service::A` cannot be made into an object | = note: method `foo` has generic type parameters I don't actually want a trait object for all types of 'T'. For example, I'd like to make a trait object out of A with T == u32. Is there a wrapper I could make to allow me to make a specialized trait object here? Other uses of this trait need the generic parameter. This use only needs the trait for one specific T. Is there anything I can do here?
We have been using Conan for C++ packaging at my work. It's better than everything else I've seen.
Probably conflating friendliness with passive-aggressiveness. Or because you're trying to justify being an ass hole yourself.
I'd say it's not just worth it, but actually necessary for healthy teamwork. People naturally have a very hard time taking negative feedback if it's perceived as a personal attack. Rudeness leads to a vicious toxic cycle that destroys teams.
I thought this was a joke at first, and realized it wasn't. I can't imagine what must happen to a person that makes them distrust friendly people.
The implementation I see here only uses futures and not tokio: https://github.com/alexcrichton/futures-await 
I mean, compiler is yuge and has tons od deps and all top of that it has to be compiled multiple times (stage 0, stage 1, stage 2). 
It uses tokio if you want it to do any IO.
&gt; Not all RFCs are implemented. I mean, that will be true forever. The language will continue to evolve, like all languages do.
Only because stdlib has no async support. How can Tokio be a necessary layer of async/await when there are no plans to make it a part of stdlib. Tokio is a higher level framework. 
I don't think it's unfair to ask. Just today I was doing some work in Rust for a crate involving wpa supplicant and udev, porting C++ over, and found myself including the same band-aid crates I was almost a year ago (rental, strum, etc). And the other annoyances were pretty much the same, having to specify &amp;'static str on all the consts and so forth. Couldn't find a simple select implementation to wait on the libudev crate I was using. Initializing strings instead of paths because of no const fns. I'm probably not even going to try to get async working. It's taken me roughly 2x as long to port to rust as it did to write the C++ in the first place. There are things I like about rust, but even though this year has been the ergonomics initiative, I haven't noticed too much change about the pain points of the language. I'm not expecting things to be done in zero time. It feels like most of a year has rolled around and there's mostly been incremental changes. I want rust to be successful, but there's so many special cases of having to include this or that library and learn some counterintuitive workaround to make things work. It's hard for me to see less talented programmers being able to use it without getting lost or frustrated and giving up.
If the stdlib had async support, it would work much like Tokio does. It would have to provide the same functionality, go through the same design process, and have libraries like hyper run on top of it. So yeah sure, if the stdlib had async support, futures-await could use it instead of Tokio. But that's a meaningless distinction, because it says nothing about how that async support would actually be implemented.
My problem was passing the raw pointer across threads. I couldn't find a way to add `Send` to `*mut u64`, but I've found a way to add `Send` to some wrapper structure (`SharedState`). Here's an abomination that does this: use std::mem::transmute; use std::thread; use std::thread::JoinHandle; #[derive(Debug)] struct SharedState { mptr: *mut u64 } unsafe impl Send for SharedState { } fn mod_thread(v: &amp;u64, data: u64) -&gt; thread::JoinHandle&lt;()&gt; { let mptr: *mut u64; unsafe { mptr = transmute::&lt;*const u64, *mut u64&gt;(v); } let msg = SharedState { mptr: mptr }; thread::spawn(move || { unsafe { *msg.mptr = data; } }) } fn main() { let value = 0u64; mod_thread(&amp;value, 123).join().unwrap(); println!("value={}", value); mod_thread(&amp;value, 456).join().unwrap(); println!("value={}", value); }
Absolutely, I totally agree!
I got the privilege of getting to teach CS 242, Stanford's Programming Languages course this quarter. I remade the whole curriculum from scratch, and of course had to include Rust!
It doesn't do any IO, but currently the `reactor::Core` does two things. It watches IO and is an executor. I use it to ask „please run me again once this future resolves“, with `handle.spawn`. I want to get rid of this hard dependency. There's an ongoing discussion around tokio and it seems the next version will split these functionalities apart. Once that happens, I expect to get rid of the dependency. I didn't invest the time to do that yet, because in my use cases, I need tokio anyway to get anything meaningful done. But it is in the TODO list and I'll of course accept proposals or merge requests how to do it in the current version.
You can return custom types with nom, which means you can in theory take in a `(&amp;str, Loc)` and return a `(&amp;str, Loc)`. If anyone has a better suggestion I would be interested in hearing it though. 
The trait `A` above requires lots of different `foo`s, one *for every possible type* `T`. It sounds like what you want is trait A&lt;T&gt; { fn foo(&amp;self, arg: T); } This instead creates lots of traits, each which only has one function `foo` for one particular type. Now the trait `A&lt;u32&gt;` is object safe. 
&gt; Your task is to implement the above function but without using a clone: &gt; &gt; pub fn reverse&lt;T&gt;(v: &amp;mut Vec&lt;T&gt;); &gt; &gt; Rust provides no way to do this safely, so you will need to explore using unsafe methods, specifically the ptr::swap function. What about `std::mem::swap`? 
Hello, You can use https://github.com/fflorent/nom_locate for this if you're working with text (it will store the line number and position in the line).
`std::mem::swap` cannot be used due to aliasing (there would be two mutable references to the same array which borrow checker doesn't allow). That said, Rust does provide slice `swap` method which can be used to do so. pub fn reverse&lt;T&gt;(v: &amp;mut Vec&lt;T&gt;) { let n = v.len(); for i in 0..n / 2 { v.swap(i, n - i - 1); } }
Oh, didn't know that one existed, I'll add it to the list. Thanks!
Check the subreddit you're posting to !!! /r/playrust
Well, you could combine `mem::swap` with `slice::split_at_mut`, couldn't you?
&gt; They originate from computational theory models. These models usually use a minimal "syntax" required to be Turing-complete - and the combinators are a "standard library" that improves the expressiveness of the base mathematic model. &gt; &gt; For example - let's take the logic combinators of lambda calculus. The model's syntax is minimal, and does not provide operators like OR or NOT - so these were created as combinators. OR a b is both more ergonomic and more readable than (λp.λq.p p q) a b. &gt; &gt; But... what about IFTHENELSE? Sure, IFTHENELSE p x y is more ergonomic than (λp.λa.λb.p a b) p x y, but due to the nature of lambda calculus you could simply write p x y! Thing is - p x y does not convey the meaning of what you want to do, making IFTHENELSE more readable - even though it's less ergonomic. &gt; &gt; But - that's because lambda calculus does not have an _if statement_ like almost every programming language. Would you write in Rust ifthenelse(p, || a, || b)? Probably not - you would write if p { a } else { b } instead. Because you have syntax. &gt; &gt; Now, I don't say combinators are useless - they can be useful to create "library syntax" that increase the expressiveness. What I'm saying is that combinators that decrease the readability compared to regular syntax are useless, because readability is important enough that you should prefer the regular syntax over them. &gt; &gt; Result, for example, has map. Map is more ergonomic than a match that does the same thing, but more importantly - it conveys the meaning better. It says - "I want to do this in good-path" - implying bad path should be left as is. Either, on the other hand, has map_left, which says "I want to do this with left" implying right should be left as is. It may look better than a match on Either, but if you compare it to a match on a custom enum it's less readable - because it doesn't tell you what's Left and what's Right! I agree until here. &gt; So, to rephrase my statement - these combinators are not useless compared to Either without them - they are useless compared to custom enum without combinators: This however is what I have a problem with. You want to implement all the combinators over and over again for every enum with two variants because of readability. That's why I'm asking you to never write a library, because 1) I expect combinators to be available outside of what you may think I - as a user of your library - will need, and 2) I don't want to deal with the bugs you may introduce that have already been fixed in the stdlib because you refuse to reuse what's already available there. It's just the wrong decision to make, and I think my idea of aliasing variant names will give you all the `Either` combinators for free and solve your readability problem. If you plan to continue this argument, you need to convince me why this still doesn't work for you. &gt; The Either version is shorter - but I say it's worse, because you need to guess what's Left and what's Right. Which brings us to: There's no need to guess, if it's `SomethingGood` and `SomethingBad`, the good/success is right and the bad/error is left: https://downloads.haskell.org/~ghc/latest/docs/html/libraries/base-4.10.0.0/Data-Either.html "The Either type is sometimes used to represent a value which is either correct or an error; by convention, the Left constructor is used to hold an error value and the Right constructor is used to hold a correct value (mnemonic: "right" also means "correct")." &gt; Congratulations - You just aliased Water to poison! Please don't drink() it. It's Either&lt;Water, Poison&gt; - so Water is on the left and Poison is on the right. There's a bug in your definition, you're not following a more than decade old convention about left and right. Either way, tomayto, tomaato. You would write the aliases yourself (as the author of the type), so a mistake would be less likely - you know your enum's variants well. &gt; To have such a bug with custom enums you'll have to either put Water(Poison) in the enum branch, or Liquid::Poison(water) in the match branch. If you do that, just looking at the code would screams wrong - as it should. I agree. But writing the correct alias is way less work than rewriting all the combinators on Either over and over again. If you really want to continue this argument, as I said, convince me the name aliasing doesn't give you 1) the combinators already available and 2) the readability you ask for. You'll also need to convince me that it's less likely you'd make a mistake reimplementing the combinators than writing the correct alias.
Sure. use std::mem; pub fn reverse&lt;T&gt;(x: &amp;mut [T]) { let len = x.len(); let (left, right) = x.split_at_mut(len / 2); for (a, b) in left.iter_mut().zip(right.iter_mut().rev()) { mem::swap(a, b); } }
I will probably feel dumb, but what is an AMA?
Thanks! So the non-destructuring version using a single tuple is almost(?) as fast as the one using multiple arguments, right? On my box, I get a measurement of about 10ns for a single memcpy of 488 bytes. Though I guess it's unlikely that the code in your actual program ends up as a single memcpy, most likely LLVM's SROA pass will split that into multiple smaller copies, which might lower performance a bit. The test I used is: #![feature(test)] extern crate test; static A : [i64; 61] = [0i64; 61]; #[bench] fn copy(b: &amp;mut test::Bencher) { b.iter(|| { test::black_box(A); }); } If you could tell me the timings you get, that would be helpful. If time permits, I'll also try to look into getting the compiler to avoid those extra copies when you use pattern matching in function arguments. Might take a while though ;-)
By the way, strictly speaking the vector type in Rust is called `Vec`, not `Vector`.
Ask me anything. 
What I would do is use Rust for the actual processing on a node and Erlang for the distributed networking parts. This takes advantage of what both languages are good at. 
My timings for my project [Sausagewiki](https://github.com/maghoff/sausagewiki): rm -rf target CARGO_INCREMENTAL=0 time cargo +nightly build --release 119.91 real 372.41 user 17.49 sys rm -rf target CARGO_INCREMENTAL=1 time cargo +nightly build --release 84.04 real 360.55 user 19.57 sys touch src/main.rs CARGO_INCREMENTAL=1 time cargo +nightly build --release 3.70 real 3.18 user 0.55 sys trivial edit CARGO_INCREMENTAL=1 time cargo +nightly build --release 3.50 real 3.02 user 0.51 sys &gt;*Note:* these timings are based on the release profile because, today, incremental doesn’t help much with debug. That will be changing in the very near future. Oh! I would have thought debug builds were the most interesting use case. The incremental build times I measure for release are indeed shorter than those I measure for the debug build.
They really should also address how Mozilla is anti "free speech" and passionately hates Christians even if they *invented JavaScript* and make it to the position of CEO of their own company. Mozilla to Brendan Eich sorta feels a lot like the UK government to Turing.
The problem with `catch` is that what should: catch { return 1 } Do? 1. This returns `1` in place so catch is equivalent to `|| {}`, then why additional syntax? 1. This return from outer function, then how to distinguish which types catch and which pass to outer function? Macro is less opinionated and IMHO is more readable (due to it’s verbosity). 
&gt; /u/gay_is_a_free_pass &gt; Talking about Turing ok.jpg
The conclusion of that thread isn't "there's no chance". It's "it is probably possible, but it's not clear that it would improve performance, and we value the simplicity of not doing it".
Rust doesn't have a good GUI solution yet. There are a number of attempts on crates.io, but no standout solution. Part of the problem is that rust is not OO, whereas most platform's GUIs are OO. This makes the bindings messy. People are working on things like relm, or game solutions like conrod, but it isn't where I wish it was. :-)
[Timely Dataflow](https://github.com/frankmcsherry/timely-dataflow)?
Thanks! I've enjoyed following your progress on your gameboy emulator. A few years ago I started writing a DMG emulator in python, even got some games rendering, so it was fun seeing all the terms pop up again: MBC, scroll y etc.
For what it's worth, you [don't have to specify the `'static` lifetime for `const`s any longer](https://play.rust-lang.org/?gist=57ed0e8947aa06a4d07a010501801638&amp;version=stable).
Would be interesting to implement the [Erlang Distribution Protocol](http://erlang.org/doc/apps/erts/erl_dist_protocol.html) for Rust though, that way you could just have Erlang distributed nodes in pure Rust (just as you can implement OTP nodes in Java).
Unfortunatelly, it is not fault tolerant.
More like Brendan Eich feels like the UK government to Turing considering his donations to homophobic propositions... Fucking grade A analogy you have over here.
Afaik the latest update added async hyper support?
Double ended iterator, swap the back and front element and continue until the ends meet.
I am thinking about creating EPMD alternative implementation in Rust that would use TLS to communicate between nodes. 
Your high hopes have to do with the upcoming "public dependencies" work?
&gt; There's no need to guess, if it's `SomethingGood` and `SomethingBad`, the good/success is right and the bad/error is left: https://downloads.haskell.org/~ghc/latest/docs/html/libraries/base-4.10.0.0/Data-Either.html &gt; "The Either type is sometimes used to represent a value which is either correct or an error; by convention, the Left constructor is used to hold an error value and the Right constructor is used to hold a correct value (mnemonic: "right" also means "correct")." That's the Haskell convention - in Rust we have `Result` for that purpose. `Ok` is good/success and `Err` is bad/error - you don't even need a convention or mnemonic for that, just a basic understanding of English words. In fact, since with `Result` the `Ok` type is on the left - making it the official Rust convention! - it's easy to get confused and use the same style with `Either`. Unless, of course, you have a strong Haskell syntax and you are writing Haskell in Rust. The article specifically says that you use `Either` when you can't make such a good/bad distinction between the two branches: &gt; Structurally, however, `Result&lt;T, E&gt;` is just an alternative between the types `T` and `E`. You may want to use such an enum for other purposes than representing results of fallible operations. Unfortunately, because of the strong inherent meaning of `Result`, such usage would be unidiomatic and highly confusing. But that's just one article, right? Well, how about the creator of the `either` crate? They say here, in [a reply to this very post](https://www.reddit.com/r/rust/comments/79yx2o/indispensable_rust_crates/dp7h830/), that they needed `Either` to impl `Iterator`(and from the look of it, several other traits) on it that'll delegate to the used enum branch. **Not to differ between the branches**, but to unite them. And they used it in their own [itertools](https://crates.io/crates/itertools) crate - as [a way to decide in `partition_map` which elements to put on which partition](https://github.com/bluss/rust-itertools/commit/900c1fb6210d9d7e48e10e663c442213dae96762). Here `Left` means "first" and `Right` means "second" - which makes sense, because code is written from left to right. But it makes sense here - not in the general case! And it's definitely not the Haskell right/wrong convention - [the example in the docs is doing it the other way around](https://docs.rs/itertools/0.7.2/itertools/trait.Itertools.html#method.partition_map).
I am shocked to hear that Brendan Eich has been forcibly chemically castrated at the hands of Mozilla.
Nice! Does it also allow querying "related track" data?
You could implement a helper method fn first_middle_last&lt;'a, T&gt;(&amp;'a mut [T]) -&gt; (&amp;'a mut T, &amp;'a mut [T], &amp;'a mut T) using `split_at_mut`, and then implement `reverse` using it. fn reverse&lt;T&gt;(slice: &amp;mut [T]) { if slice.len() &gt;= 2 { let (first, middle, last) = first_middle_last(slice); mem::swap(first, last); reverse(middle); } } Voilà! No `unsafe` required! 
It would sure be nice if nom supported something like this by default...
I'm impressed that the benchmarks so far are showing such huge improvements even for a full rebuild! Great work, compiler team!
And with `#![feature(slice_patterns)]`, which should be stable sometime: #![feature(slice_patterns, advanced_slice_patterns)] use std::mem; pub fn reverse&lt;T&gt;(v: &amp;mut Vec&lt;T&gt;) { reverse_slice(v); } pub fn reverse_slice&lt;T&gt;(mut v: &amp;mut [T]) { loop { match *{v} { [] | [_] =&gt; return, [ref mut first, ref mut middle.., ref mut last] =&gt; { mem::swap(first, last); v = middle; } }} } fn main() { let mut vek = vec![0,1,2,3,4,5]; reverse(&amp;mut vek); println!("{:?}", vek); }
lol free speech means the government can't arrest you for saying things. That's it. Doesn't mean your views don't have consequences. Companies can fire who they want for practicing or saying things they don't think sign with their company goals.
I see. How raw is the data? Is it e.g. corrected for detector efficiency or would you have to reimplement this in Rust as well? If I recall correctly, the reason why it took them a while to publish the data is that the raw data is of limited use without the analysis framework, which is why they published them together. 
from my point of view, nom supports it: it provides a way to define your own input type and work with it. I try to keep the library small, because a lot of use cases will be very specific. Input handling is often specific to the file/IO code the program is using.
JavaScript is pretty shit so this seems OK tbh.
I haven't looked into it too much, but I've used timely_dataflow before, and I think combining TD with some fault tolerant message queue + ack might be one of the best options there is right now in Rust.
I don't like what happened with Brendan Eich but "passionately hates Christians" is fucking overboard. As for anti free speech... Sure, they might be politicized in ways that might not be conductive to progress and we might want to address that *in the proper venues* but a post about Rust language which is way more than Mozilla at this point being taught in a school is absolutely fucking absurd. 
If i read this right, this means that even the warmup build for incremental is faster than the regular build? Isn't it expected to be slower, because cache checking overhead? IIRC i observed this behaviour locally, but dismissed it as inacurate measurement.
&gt; Companies can fire who they want for practicing or saying things they don't think align with their company goals. That's not really true if other laws get in the way. If I say my goal is to have "only heterosexuals" I can't fire someone for "being in favor of 'the gays'" or something like that. I don't think the way the Brendan Eich issue was handled was proper regardless of how much of a legal issue it is. Witch hunts are seldom smart and often quite hypocritical. Not that it's easy to argue against emotion. 
I found that surprising as well, so I've rerun the cold builds a couple of times, and they stay consistent with what I reported. I could speculate that maybe the incremental compilation code path simply has seen more optimization by now, but somebody else might be able to answer this authoritatively :)
What issues have you had with cabal/nix?
Use [RLS](https://github.com/rust-lang-nursery/rls) with [LanguageClient-neovim](https://github.com/rust-lang-nursery/rls). * _RLS_ is the [LSP](https://langserver.org/) server for rust. It provides editor-agnostics IDE-like features like code completion, linting, and the ones you seem to need - finding the declaration of a symbol and finding all the usages of a symbol. * _LanguageClient-neovim_ is a LSP client for Neovim(that [recently got Vim support](https://github.com/autozimu/LanguageClient-neovim/pull/151)) that connects to RLS(or any other LSP server) and provides a UI to use the features it provides inside (Neo)Vim.
Is there a list of universities teaching Rust? I know a couple of others in Germany.
&gt; I don't think the way the Brendan Eich issue was handled was proper regardless of how much of a legal issue it is. Eichs donation was for a push that was later ruled unconstitutional and had an actual damaging impact quite some Mozilla employees. In his position, Eich was directly involved in managing these people and to be a beacon for what Mozilla stands for. In a C* position, the whole "but it's just private" doesn't work. This has nothing to do with a witch hunt. Please don't frame outrage as witch hunts.
Well, I'm not sure what exactly that involves but pretty much any approach to the diamond dependency problem that doesn't repeat past mistakes I'd be amenable to.
Uh, I knew about LanguageClient-neovim, but did not realize that LSP gives you sourcebrowsing capabilities. I'll try that out, thanks!
The data is pretty raw. The reconstruction is down, but nothing else. Simulations were not published, so one is essentially restricted to analyses where the efficiencies cancel out in some way. Alternatively, one might take some published distributions, recreate the distributions from the uncorrected published data, and calculate the efficiency from that... There is actually a [figure](https://github.com/cbourjau/alice-rs/tree/master/simple-analysis) in the repository for the simple analysis. That figure just shows the total number of particles summed over many collisions. If the data were corrected, you would expect something reasonably smooth for the φ- distribution. As you can see, thats not the case (due to the detector deficiencies). I are right, I should really put some plots up which are easier to find! An example of a more sophisticated plot is [this](https://imgur.com/a/a6wfw). Imgure somehow at the labels, but it shows the average particle distribution of a single event in φ (x-axis). Take the y-axis to be some sort of probability density. A single event is not isotropic; the anisotropy seen in the figure maps back to the initial anisotropy you have if two lead nuclei collide slightly off-center. The figure is made from the published data, and is really close to [published results](https://arxiv.org/abs/1109.2501). Detector effects cancel out in that particular analysis. 
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/yFuhyiF.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) 
&gt; Even if you correctly alias Water = Liquid::Left(actually, the correct Rust syntax is use Liquid::Left as Water;) - the combinators will still be named .left(), .if_left() etc. There it is. The problem would be with naming the combinators. Thanks!
Well, I am teaching Rust at California State University San Bernardino, as part of [my Programming Languages class](http://www.proglangs.com/). I [talked about it at Rust Conf](https://www.youtube.com/watch?v=0PhfaFkzdBA) :D
You should have some kind of struct (`ItemStack`) representing an "inventory item" that has the item ID, quantity, and any other metadata tou want. And then you inventory is just a vector of `Option&lt;ItemStack&gt;`.
Yup - that was the problem from the beginning - that the names were not conveying the meaning of the branches.
Have you looked at Maven? It's by far the best *everything* I've had to work with. Its error messages are quite bizarre but its dependency management is by far the best I've worked with and it's extremely extensible.
It depends a bit as well if you need ownership of the cloth or if you are just borrowing it
RFC: https://github.com/rust-lang/rfcs/blob/master/text/1977-public-private-dependencies.md The short version IIRC is that cargo and rust will provide the tools to manage diamond dependencies, with fields in cargo.toml, a resolution algorithm that takes them into account, and better errors wen resolution fails.
What's blocking it then?
Why not just use a Vec&lt;ItemStack&gt;? You don't need the Option, do you?
* Lack of good libraries. * Lack of good libraries. * Lack of good libraries. Examples: * hdf5 crate cannot read hdf data into variables. * html5ever (which should be super good crate) can only read utf-8 html. * machine learning libraries are not good. * deep learning libraries are not good. And the second point is that most of the stuff you google up in Python and download from pip works and has sufficient quality. In crates there is so much stuff in prealpha versions, which just drives me crazy. 
Empty item slots, perhaps?
[removed]
i would probably drop caches in between all these steps.
We left in the API, which means that we can't do it.
Most of the results seem to be from a *nix based system, so here's one from Windows with a project I can't share, measured using PowerShell's `Measure-Command`. Step 7 is the same as step 6, but with incremental build disabled. (3) Full Build: Run 1: TotalSeconds : 155.2955441 Run 2: TotalSeconds : 157.7728211 Run 3: TotalSeconds : 157.6875925 (4) Incremental Build: Run 1: TotalSeconds : 85.7908256 Run 2: TotalSeconds : 86.3268027 Run 3: TotalSeconds : 84.2470012 (5) Incremental Touch Main: Run 1: TotalSeconds : 3.779623 Run 2: TotalSeconds : 3.7279978 Run 3: TotalSeconds : 3.7038541 (6) Incremental Trivial Change: Run 1: TotalSeconds : 4.8812941 Run 2: TotalSeconds : 4.9039526 Run 3: TotalSeconds : 4.8912308 (7) Full Trivial Change: Run 1: TotalSeconds : 45.8185163 Run 2: TotalSeconds : 45.922492 Run 3: TotalSeconds : 45.9282374
What everyone else is saying is, you probably want /r/playrust instead. ;-)
Dull and throbbing on the left hand side, near my hip actually. I guess a doctor would call it hip pain, almost.
Hi all. Here are my slides from our Rust meetup this week. It's an introduction to FFI (plain C -&gt; Rust and JNI -&gt; Rust) based on a concrete example (this library https://github.com/dbrgn/candidateparser/).
Hmm, doesn't work nicely, sadly. GotoDefinition (what I really need) did work for some queries, but pretty soon it stopped, can't find it. I'll vendor the libs and see if changing their use statements makes it possible.
It was noted in the original PR that incremental compilation seems to improve performance across the board. :)
Just racer and its go to def works fine for me. With neovim.
&gt; Do I need to vendor the sources manually and have the tags made? [rusty-tags](https://github.com/dan-t/rusty-tags) builds tags for all dependencies. 
You can implement `Index` for your struct, or however you're storing your matrix.
I bet you're a fun student in class. ... ;)
Looks interesting ... Will this talk be available somewhere online?
Do incremental builds produce similar machine code as non-incremental builds? Does LTO work for incremental builds?
The answer is already fully established in the RFC: `?` does not desugar to `return`, so *all* `return` expressions simply leave the function. Only `?` expressions interact with `catch`.
I'm confused. Why hasn't anyone mentioned `[T]::swap` yet? for i in 0..v.len() { v.swap(i, v.len() - i); }
Not yet, but there's work on ThinLTO which should make things on par, and should be stable soon (hopefully).
You get "no answer" because there isn't really anything else to talk about. It's not that *Github* has a "no people under 13" rule, it's that *US Law* does. Facebook, Steam, and most Google products have the same restrictions because they are based in the US. It would be great if this wasn't an issue, but it is. The Rust team doesn't have unlimited resources and so decisions have to be made regarding what issues get worked on and which don't. I have yet to see this actually be a problem for anyone under 13. 
If I was actually pedantic about details I would say this is `&lt;[T]&gt;::reverse`, as those methods don't actually come from `Vec` itself ;).
Isn't it weird that there's no test for a non incremental non full build? The full builds contain building all the dependencies, which you usually don't need to rebuild. So shouldn't this also be tested against a change in your crate without fully rebuilding the dependencies?
*gives wedgie, steals lunch money*
To show how it could look like. I actually admit I like this solution :). fn reverse&lt;T&gt;(items: &amp;mut [T]) { let mut iter = items.iter_mut(); while let (Some(a), Some(b)) = (iter.next(), iter.next_back()) { mem::swap(a, b); } } 
You need to check them for noneness separately (one before the other) to not run into fusion bugs. It will work fine with most iterators or if the unfused side effect is acceptable.
Hmm that might work, if index returns a line of my array, then I can index the columns as normal. I'll give it a try.
I was thinking more along the lines of `m[x, y]` returning the exact value.
Please don't use `usize` to check for units.
Even better, I didn't notice index could take multiple params.
I hope your students don't Google and find this thread, which has lots of implementations of the solution already. The problem with referencing homework on Reddit; you've managed to [nerd-snipe](https://xkcd.com/356/) a bunch of people into providing a lot of easily Googleable solutions.
Can't be `m[x, y]` though - it has to be `m[(x, y)]`. Returning a line of the array could be a problem too - see https://www.reddit.com/r/rust/comments/74k2lk/design_help_for_a_c_dev_question_about_using_the/
It doesn't have that yet, i.e. it only fetches a small number of relationships by now, but the API for relationships could be significantly improved in this crate anyway.
In a particular project, this works: let mut records: Vec&lt;Vec&lt;Scalar&gt;&gt; = vec![]; for record in reader.records() { let values: Vec&lt;Scalar&gt; = record?.iter().map(|s| s.into()).collect(); records.push(values); } But this does not: let mut records : Vec&lt;Vec&lt;Scalar&gt;&gt; = reader.records().map(|record| record?.iter().map(|s| s.into()).collect() ).collect(); cannot use the `?` operator in a function that returns `std::vec::Vec&lt;nullvec::prelude::Scalar&gt;` I guess in the second case there is a closure which has a type Result&lt;something here&gt; because of the ? Still, why needs to be implemented for Scalar here? 
&gt; This is really cool and really close to what I've been doing with my syntax plugin, we even share the same name :P This may be awkward but... I also have such a plugin, and I also share the name. :P It isn't released anywhere yet though, and I'm not sure when/if it will be; it's part of my work-in-progress experiment at creating a React-like web framework in Rust based on my [stdweb](https://github.com/koute/stdweb) crate.
I feel like you answered your own question? Can you elaborate what you want to know? Is this a question about the crate you are using?
You can also use a 2-array for the indices, I prefer that workaround (ndarray supports both).
I don't think I need a line. Tuples are probably 
I wanted verification of the theory. Lucky that I was right, does not happen often :)
How would it skew the results? All the tests, for both incremental and non-incremental, have to build the target directory from scratch.
RLS is using Racer behind the scenes, so unless there is some recent relevant commit in Racer that not yet in the release RLS uses - I don't think Racer will show better results.
This is related, but quite a bit more than you're asking: https://github.com/weld-project/weld/ If I were to build this today, I'd use Kubernetes or Nomad to handle scheduling and fault tolerance. For the workers, I'd just build a basic REST service for each worker to receive its batch of work. Kubernetes services load-balance by default, so you can have a master service which would responsible for doling out the subset of the work by just posting it to the `service` and let k8s handle the load balancing. If you don't get a post-back to the master node from the child, then post the job to the service again. 
If you expect the user to lock and synchronise (and therefore do not provide safety guarantees to the hosted language) then you can use unsafe code. I would suggest giving the hosted language guarantees over memory safety, however, since this will mean less time debugging. You could make it a hard error if the guarantees are violated (using `try_lock()?`) and then have a switch that puts it into unchecked mode (you can make some `MutexLike` trait that proxies all of the `Mutex` operations and then swap it out with a noop version in unchecked mode).
There was a project in Rust for comparative programming languages at KULeuven two(?) years ago. Though the languages change each year.
&gt; /me notices that it assumes an existing understanding of OCaml Man, this looks a lot cooler then my programming language course was.
I love this solution!
Ah, ok. Another thing you could try is add type information to the `into` call. `into&lt;Scalar&gt;` and see what happens ^^ As I don' know the particular crate, I cannot tell you which functions return what. Consult the crate documentation to find out what `record?.iter()` returns.
You could write one!
YouCompleteMe works with vim and uses racer.
Which makes whole change even worse IMHO. 1. It adds new and easy to miss flow control behaviour which is completely different from any other language. 1. The easiest way to prevent writing unmaintainable code is making writing such impossible. Ex. currently the only way to prevent long `catch { … }` blocks (which is de facto `try { … } catch (…) { … }` with weird syntax) is to use linter. With `?` being coalesce operator it would be impossible to write such code. I understand that `try!` alone was problematic, but current solution is problematic too. I still would prefer `?` to be equivalent to `::and_then` instead of `try!`.
At first I was wondering who at my old university was teaching Rust. Then I read the user name and it all made sense. Glad to hear that Rust is (still) getting some love at CSUSB! 
As a side note, unless `num_records` is going to be different from the actual length of `records` at any (observable) point, you should remove it from the `struct` entirely. It’s wasting space without giving you any gain, since `Vec` stores its length directly anyway.
LLD does not have hard-coded library paths (see [this comment](https://github.com/rust-lang/rust/issues/39915#issuecomment-298145698)). If you want to use LLD, you can set your `RUSTFLAGS` environment variable to `-C linker=clang -C link-arg=-fuse-ld=lld`, assuming you have Clang and LLD installed (and this works on all platforms). Clang is **needed** to automatically pass the right platform-specific libraries to LLD. 
Or RIIR. :^)
Yes, `Vec&lt;T&gt;` `Deref`s into `[T]`. https://doc.rust-lang.org/std/vec/struct.Vec.html#impl-Deref
If you give me the time (UTC) at which the AMA starts, I could create a sticky notice for it ^^ *It says 6PM in the link, but I wonder in which timezone...*
Note that ThinLTO is not fully on par with LTO yet, from the CppCon talk they gave. There are apparently a number of inter-procedural optimizations that are in the work, but not quite there. Of course, it does not matter for *unoptimized* builds, so the winning recipe is: - Incremental + ThinLTO for Debug, - LTO for Release.
Strongly disagree. `?` is not new *or* easy to miss- it may be *easier* to miss than `try!`, but at worst it's an early return. Hardly invisible unbounded unwinding, and certainly not grounds for calling code "unmaintainable." Arguments about length apply equally to early returns in functions themselves. The response is the same: keep your functions small. (With the usual caveats [like these](http://number-none.com/blow/john_carmack_on_inlined_code.html).) In the end, the results speak for themselves. Rust code has become easier to read, not harder. People who opposed the `?` operator have come around to it. We'll never please everyone, but `?` works well the way it is.
That was a really interesting read! I know @Michael-F-Bryan is rewriting his FFI guide ([rendered](http://temp.michaelfbryan.com.s3-website-us-east-1.amazonaws.com/)) using the example where someone is creating a Qt GUI program which uses That for the business logic. Maybe you could collaborate with him or give some input on the associated [PR](https://github.com/Michael-F-Bryan/rust-ffi-guide/pull/41)?
I'm curious why that is- for some of the smaller benchmarks it looks like full rebuilds with incremental are slower than full rebuilds without, but for large ones the performance is significantly better.
[mles](https://crates.io/crates/mles) looks like it might be useful for building such a thing, but is fairly low level. I've wanted a similar (though much smaller scale) type of syso, and considered writing something like Celery atop mles. If all you need is reliable batch processing, is there some reason you can't use a cluster computing system such as SLURM?
*gives wedgie, steals lunch money, years later loses job to*
&gt; In the end, the results speak for themselves. Rust code has become easier to read, not harder. People who opposed the `?` operator have come around to it. We'll never please everyone, but `?` works well the way it is. And what alternative they had? I agree that in `Result` heavy code it could improve readability, however it is somehow bold statement that “people have chosen” when they had no choice (use `try!` or `?` isn’t choice as I am not opposed to `?` operator per se, but rather to it’s behaviour). 
By "come around to it" I don't mean "gave up and started using it," I mean "explicitly changed their opinion on whether `?`'s behavior is a problem." FWIW, there *are* also some who deliberately avoid `?` and continue to use `try!`.
And I am among them, because I have no other choice. I have proposed another solution multiple times during RFC process however there was a few who wanted to listen. I will repeat, I would like to keep `?` operator as is, but merge it’s behaviour with `catch` or alternatively dump it and introduce `?.` operator that would be like “happy path call”. 
I believe [mesonbuild](http://mesonbuild.com/) aims to minimise what it depends on. I thought I saw something in their [FAQ](http://mesonbuild.com/FAQ.html) or their [design rationale](http://mesonbuild.com/Design-rationale.html) but I couldn't atm.
I just realized that I didn't understand iterators in Rust as well as I thought I did.
The idea of a coalescing operator was not ignored during the RFC process, it was considered and rejected.
Are you compiling in release mode? That code generates 436 lines of IR on the playground in release mode. [Link](https://play.rust-lang.org/?gist=85d742c484e3c02576daa9a0f437b449&amp;version=stable)
It's not completion I'm after though, but to dig through the code to find out where that error originated I'm seeing.
It started an hour ago, when you replied to me O_O
You can use `rusty-tags` if you want to read the source. I don't know about finding documentation however.
here are representative results. I find that the whole suite tends to go up and down with each other by ~50ns but the relative times are fairly consistent. hopefully the names are descriptive enough to understand. I came across this when trying to understand if it would be faster to mutate an object passed to a function or create a "new" object from taking parts of the old one via destructuring and using them in a new one. tests::it_clones_a_large_enum_variant ... bench: 194 ns/iter (+/- 3) tests::it_clones_a_small_enum_variant ... bench: 1 ns/iter (+/- 0) tests::it_converts_with_from_impl_that_uses_destructuring_sig_by_mutating_tuple_member ... bench: 519 ns/iter (+/- 6) tests::it_converts_with_standalone_fn_no_tuple_in_sig_mutates_obj_passed ... bench: 441 ns/iter (+/- 2) tests::it_converts_with_standalone_fn_no_tuple_in_sig_uses_struct_destructuring_to_create_new_object ... bench: 427 ns/iter (+/- 2) tests::it_converts_with_standalone_fn_passed_tuple_incl_destructuring_in_sig_mutates_tuple_mbr ... bench: 532 ns/iter (+/- 5) tests::it_converts_with_standalone_fn_passed_tuple_no_destructuing_in_sig_mutates_tuple_mbr ... bench: 496 ns/iter (+/- 5) tests::pure_copy_of_static_i64_array ... bench: 10 ns/iter (+/- 0) 
YCM supports code browsing too.
It's not about docs, it's about digging through the source. I'll give rusty-tags a shot, thanks.
YCM supports code browsing too.
Uh, that I did not expect. I'll have a look, thanks!
Uh, that I did not expect. I'll have a look, thanks!
Uh, that I did not expect. I'll have a look, thanks!
Uh, that I did not expect. I'll have a look, thanks!
That's just screaming for someone to create a complex Macro to replace the majority of those steps. I mean, you've done half the hard work, which is to figure out how to handle each of the most common problems you'll encounter. Now we just need a Macro that lets you define some configuration parameters for how to proceed and what names to use, and the tedious work of making it do each step.
Ah! So it was in 6 PM UTC :D
I reread whole discussion and neither [this post](https://github.com/rust-lang/rfcs/pull/243#issuecomment-177045710) or [this post](https://github.com/rust-lang/rfcs/pull/243#issuecomment-180504407) even mention discussion about coalescing behaviour. This is always `try!` vs `?`, not `try!` and `?`. All I see is support for `catch { foo()? }` while rejecting `try` word as opposing to `try!` macro. What I was proposing was to keep current behaviour and implementation of `try!` macro and just add `?` operator to it, so it would simplify chaining.
I wonder what Cloudflare is using Rust for: &gt; We are looking for people in a number of teams including our data team (Go, Kafka, Spark, Flink), our platform team (Kubernetes, Go, Mesos and Marathon), our edge team (Nginx, Lua, C++) and **JS performance (JS, Rust, Node, Go, Lua)** are working on some interesting projects, and we always need Go engineers to help connect all of these things together and establish new standards for how we do that. The DDoS team is hiring low level engineers (C, Python, golang and packets wangling, TCP/IP, DPDK, netmap, patching kernel). I thought I'd find Rust where C++ (edge team) and C (DDoS) are, for system-y things. Any guess?
I'm new to rust, and I'm having troubles grasping the iterator concept, I have something that works, but it isn't the solution I was hoping for: fn add_n_inplace(v: &amp;mut Vec&lt;i32&gt;, n: i32) { for i in 0..v.len() { v[i] += n; } } Can this be done with an iterator (and .map() ? ), I tried this, but it doesn't work: fn add_n_inplace(v: &amp;mut Vec&lt;i32&gt;, n: i32) { v.into_iter().map(|i| *i+n).collect::&lt;Vec&lt;i32&gt;&gt;(); } 
Yes, I (and the team who made the decision) are *fully* aware of coalescing operators. It was considered since other language have it. You don't have to keep explaining it.
You can implement Index for multiple types. For instance, on a matrix struct I wrote, I implemented Index&lt;usize&gt; to return a slice (a row of the matrix), and Index&lt;(usize, usize)&gt; to return an f32 (a single element).
What is the `Deref` trait used for?
Depending what exactly they mean, JS performance seems perfectly systems-y, e.g., compilers, JITs and language runtimes. I imagine edge and DDoS are IO-sensitive, so the immaturity of Rust in that space is limiting.
Thank you for doing these threads! Might also make for a nice analysis a few months down the road, to see how the number of Rust mentions changes over time.
A while ago I posted my `static_assertions` crate. This is a walk through of my process of creating the macros that spawned that project. I tried to make it as easy as possible to follow. For mme, Rust macros was the second hardest thing about the language after lifetimes so I understand that some things don't make much sense initially. This is my first blog post so feel free to critique my writing, my code, etc. I'm hoping to write more about tech and do so coherently. This post was inspired from speaking about this project to some other Rustaceans at the Boston Rust meetup last night.
Wow, I didn’t expect another CSUSB alum to be here! Hey Jason!
How is it going?
/r/playrust
Agreed. What I care about is how much incremental builds affect my edit-build-run cycle. Build times of all dependent crates is (mostly) a non-issue.
&gt; I agree with the argument on code clarity. I'd lean towards using the Either type because it's simple enough to remember "either this or that" and comes with all kinds of practically useful combinators for free. This seems like you could the best of both worlds by implementing #[derive(standard_combinators)]?
Wrong Rust, my friend.
We don't have guaranteed TCO in Rust, so your function will easily overflow stacks (in debug mode), while the function of /u/MysteryManEusine will not.
The University of Twente uses Rust in (at least) one of their computer science courses.
The ever disappointingly slow sentry-cli achieves 22 secs for a "touch" on a file in debug mode with incremental builds on now. Without incremental it compiles in debug mode in 42 seconds.
You're really close! Since you're trying to mutate in place (rather than create a new iterator) you actually want to call `iter_mut` and then loop over all of the elements, incrementing each one. Example: fn add_n_inplace(v: &amp;mut Vec&lt;i32&gt;, n: i32) { v.iter_mut().for_each(|i| *i += n); } Also, since you don't need to grow or shrink the `Vec`, general best practice is to accept `&amp;mut [i32]` in methods like this.
Indeed, this is why we shouldn't be celebrating just yet. Incremental compilation still has a long way to go before it comes close to competing with non-incremental. Though for a lot of people it might be very valuable even in its current state as a middle-ground between debug and release mode; out of curiosity, how much slower at runtime is a normal unoptimized `cargo build` version on your machine?
with the second one, you're creating an entirely new vector, but then you're throwing it away by just having a semicolon at the end and not returning anything from the function. Here are two separate implementations that you might find interesting: https://play.rust-lang.org/?gist=f7d5e81c5b076262075fcf12455ee01e&amp;version=stable
You're probably looking for `Iterator::for_each`, e.g. `fn add_n_inplace2(v: &amp;mut [i32], n: i32) { v.into_iter().for_each(|a|*a += n) }`. I'm not sure why it was added though, because writing a `for` loop is usually clearer.
Not easily, no.
It's to allow types to dereference to another type. E.g. the `String` type derefs to `str`, so we don't need to write `.as_str()` in many places where we call `str`s methods on `String` references. This is called `deref coercion` and is considered an anti pattern; as such should be used sparingly.
Great! Well-played! 
I think incremental release is supposed to be faster than inc. debug? From what I've seen upthread
In addition to that, I've heard from some of their London team that they are rewriting the Ragel codegen in Rust as part of the response to [February's incident](https://blog.cloudflare.com/incident-report-on-memory-leak-caused-by-cloudflare-parser-bug/). Interestingly, Ragel previously had support for Rust codegen, but it was removed at some point.
For fun, here's a [cheaty version that goes up to k=58](https://play.rust-lang.org/?gist=017341d723b24e34c8713ccdc0f999a2&amp;version=nightly). Based off of the [Go version](https://rosettacode.org/wiki/Man_or_boy_test#Go) on Rosetta. Also available in [BigInt flavor](https://play.rust-lang.org/?gist=5da825278013cf77bd2ccfbead5d3850&amp;version=nightly). Here's my [Godbolt workspace](https://godbolt.org/g/cprRPP) I came up with while testing. The cheaty version is 38 lines of ASM, the Rust cell version is 253 lines, and the [D reference](https://godbolt.org/g/aXSNen) is 222 lines.
You can get it down to [263](https://play.rust-lang.org/?gist=813771569ba279ddabb44a4411b9afc6&amp;version=stable) by eliminating the Fn and the Option. You can certainly get rid of `Cell` by replacing it with `*mut i32` and `unsafe`, which takes it down to 253, but is probably sub-optimal. This is the first time I've heard of this problem so I'll play around with it a bit more to see if I can come up with something else. 
For anyone interested, here's a [direct link](https://onesignal.com/careers#senior_backend) to our Rust opening. Note that the job title does not include Rust since we found it was detrimental in attracting people not already familiar with the language. It is however very much a Rust job.
I guess once size_of is const the second macro will be a lot easier!
Given the combined complexity here, I think the only scale that matters here is a Logarithmic scale of Rust releases (6-week intervals). So on that scale, what do I think? * 1 release -&gt; automated testing * 10 releases -&gt; the 0.1 version of a few significant features (like MIR, custom define macros) We haven't had enough history to estimate further, but mature versions of all of those compiler features seem to me to be closer to 100 releases than 10 by estimating to the nearest power of 10 releases.
I wrote support for a rust generator in ragel way back when, but they shifted over to only “releasing source code with every release” model, which made it difficult to keep it up to date, so it atrophied away. 
Did you read? They didn't argue "This is super unfortunate but there's nothing we can do" they justified it as a good thing saying children _shouldn't_ be allowed in.
I would in particular support the latter idea, of using tuples. Tuples cover the homogenous and non-homogenous cases, so it's powerful that way. On the other hand indexing via arrays could be generic in the number of dimensions, once const generics arrive (and that's more likely to happen soon than any kind of varargs for tuple generics).
I wish the brackets in tuple syntax were optional, so `matrix[x,y,z]` would be equivalent to `matrix[(x,y,z)]` and `Some(a,b)` would be equivalent to `Some((a,b))`.
This is a version that works without using `Cell`, but really, there's nothing wrong with a nice `Cell` abstraction. Do you consider the following code ugly? If so, that's good. It **is** ugly. But, the other languages' solutions are just as ugly, because this problem is designed to mutate state across abstraction boundaries with aplomb, which **is** ugly. Rust will give you the control you need to solve problems however you deem best, but that doesn't mean it's going to let ugly solutions look pretty. type FnPtr = *mut FnMut() -&gt; i32; unsafe fn a(mut k: i32, x1: FnPtr, x2: FnPtr, x3: FnPtr, x4: FnPtr, x5: FnPtr) -&gt; i32 { let k_ptr = (&amp;mut k) as *mut i32; let mut b = (&amp;mut || 0) as *mut FnMut() -&gt; i32; let b_ptr = &amp;b as *const _; b = &amp;mut (move || { *k_ptr -= 1; a(*k_ptr, *b_ptr, x1, x2, x3, x4) }); if k &lt;= 0 { (*x4)() + (*x5)() } else { (*b)() } } fn main() { println!("%{}", unsafe { a(10, &amp;mut || 1, &amp;mut || -1, &amp;mut || -1, &amp;mut || 1, &amp;mut || 0) }); } #[test] fn result() { assert_eq!( unsafe { a(10, &amp;mut || 1, &amp;mut || -1, &amp;mut || -1, &amp;mut || 1, &amp;mut || 0) }, -67 ) } 
Its error message is better though. It tells you that the sizes aren't the same. Whereas with the first, it tells you about subtraction overflow, which is irrelevant what the expression has.
[removed]
Not exactly Rust related, but like our survey they explicitly solicit opinions from those not using Haskell. I know I would want other communities to share our survey like this, so doing the same for Haskell.
&gt; This is called deref coercion *Dons pedant hat* My understanding is that you've described is _auto deref_, not deref coercion. Auto ref/deref occur when calling methods. Deref coercion specifically is when passing a reference of one type to a function accepting a reference to another type (or any other coercion site), e.g. passing `&amp;String` to a function accepting `&amp;str`. fn foo(s: &amp;str) { } fn main() { let mut s = String::new(); // foo(s); // fails to compile foo(&amp;mut s); // deref coercion here: &amp;mut String -&gt; &amp;str s.len(); // auto-deref while searching for inherent/trait methods } &gt; and is considered an anti pattern; as such should be used sparingly. Given the definition above, deref coercion itself is not an anti-pattern; it's fundamental to the language! It's particular usages of `Deref` that constitute anti-patterns. One case is when a type `T` is not conceptually the same as the type `U` to which it derefs. So `String` to `str` and `Vec&lt;T&gt;` to `[T]` are not anti-pattern usages because both the owned and borrowed variants have the same logical meaning: "sequence of utf-8 code points" and "sequence of T". The fact that they own the memory is somewhat incidental to their semantics. The `Mp3` to `Vec&lt;u8&gt;` example [in the new book](https://doc.rust-lang.org/book/second-edition/ch15-02-deref.html) probably classifies as an anti-pattern example. An `Mp3` is not semantically a `Vec&lt;u8&gt;`, even though you might store it in memory as one. It's also an anti-pattern is abusing `Deref` to get somewhat OOP-like inheritance behavior where you implicitly delegate methods to a field even if it's logically an implementation detail. An example here might be if `Vec&lt;T&gt;` deref'd to `RawVec` to make use of a `cap` method instead of its own `capacity` method. I had a discussion with /u/Manishearth about this many months ago in [this thread](https://www.reddit.com/r/rust/comments/5lk1lw/hey_rustaceans_got_an_easy_question_ask_here_12017/dc07cdn/?context=7).
To be clear, it _is_ an antipattern to implement `Deref` on things which are _not_ smart pointers to get the coercion/autoderef. However, it is totally ok to implement it on your smart pointer types, and to make use of autoderef and deref coercions.
Hey y'all! i've been tinkering around with this for a while. I published my first prototype in july. [Reddit post](https://www.reddit.com/r/rust/comments/6l6klk/community_automation_explaining_rust_syntax/). This is the second prototype. I wasn't happy with the markdown output and wanted to play with CSS highlighting. Anyways, now comes the actual work: covering rusts syntax. I'd like you to submit snippets which you'd like to have covered. These will be adapted into the syntax studies, on which this library will be built on. P.s. @ServoDevs, please forgive the generated "html". Tar and feathers will be ready -( ^-^)-
I agree about `matrix[x, y, z]`, but `Some(a, b)`? The compiler will have to know about the type in order to desugar - isn't this a big no-no?
To be honest, I see absolutely no benefits to your proposal and several downsides: 1. When reading code, it's easy to mistake `-&gt;` for `~&gt;` and vice-versa when you're distracted or tired. (One of the reasons why `...` is being replaced with `..=` for the inclusive range syntax rather than stabilized.) 2. It's another piece of punctuation to be memorized (all of which are hard to learn if you don't know about the Rust syntax index). 3. The fact that you need to hold Shift to type `~` means that I'd consider it more of a hassle to type than `some`. (It takes noticeably more effort to type quickly when I have to manage the pressing and releasing of Shift in addition to the main stream of keys.) ...not to mention, being so eager to add a new piece of punctuation just doesn't *feel* consistent with the design philosophy of the rest of the language.
Cool idea! I don't see a license file. Could you maybe add one?
Is the source code of the assignments available publically?
I didn't even notice the tilde and I was reading through it pretty attentively trying to understand what you were getting at. I don't think this would work.
Whoopsie! MIT + APACHE 2.0 Thanks!
Hey! This subreddit is for the rust programming language. I think you're looking for the gaming sub. https://www.reddit.com/r/playrust/
I didn't know nailguns were a programming concept. Interesting! Seriously, though, you've got the wrong sub. /r/playrust is probably what you wanted. This one is for a programming language also called Rust.
And this can be made cleaner with `while let` loop. #![feature(slice_patterns, advanced_slice_patterns)] use std::mem; pub fn reverse&lt;T&gt;(mut v: &amp;mut [T]) { while let [ref mut first, ref mut middle.., ref mut last] = *{ v } { mem::swap(first, last); v = middle; } }
One issue is programmer ergonomics, the other is data access patterns. You would need to measure against your use case and how you visit the elements. * https://en.wikipedia.org/wiki/AOS_and_SOA * https://en.wikipedia.org/wiki/False_sharing Don't assume that having the start of a row at some aligned address will yield the best results. Sometimes alignment will bite your bandwidth.
**AOS and SOA** In computing, AoS and SoA refer to contrasting ways to arrange a sequence of records in memory, with regard to interleaving, and are of interest in SIMD programming. *** **False sharing** In computer science, false sharing is a performance-degrading usage pattern that can arise in systems with distributed, coherent caches at the size of the smallest resource block managed by the caching mechanism. When a system participant attempts to periodically access data that will never be altered by another party, but that data shares a cache block with data that is altered, the caching protocol may force the first participant to reload the whole unit despite a lack of logical necessity. The caching system is unaware of activity within this block and forces the first participant to bear the caching system overhead required by true shared access of a resource. By far the most common usage of this term is in modern multiprocessor CPU caches, where memory is cached in lines of some small power of two word size (e.g., 64 aligned, contiguous bytes). *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
I'm not exactly sure why I remember disliking the enum representation so much! It was back in the first few commits of Pleco. Most likely had to do something with boilerplate code, `match` requiring all possibilities to be exhausted, readability, etc. I've just recently changed a square representation to a Struct(). I might experimentally revert to an Enum again and see if any readability issues appear.
Yeah, shame there isn't a way to have a custom error.
Thank you!
I guess that's probably why nobody was talking about it here when I searched. Thanks, sorry for being a dingus
Nice, thanks for detailed answer!
I'd support something like Some(a, b,)
If you're performing a `match` against all variants, I feel like you're doing something wrong 😅
meson is probably a sensible cmake substitute afaikt. If we used it for our projects, we would probably just put meson in our build container and build those projects with `lal` to get versioning and prebuilt libraries out of it. This doesn't actually try to compete, we need to work with most of the build systems and maintain forks anyway.
great, I get it now!
This will reverse it two times, that is, no change to `items`?
Not at the moment (just for Stanford students), but that may change in the future, in which case you'll find it on our github (https://github.com/stanford-cs242).
Alas, yes, I didn't realize how excited people would be to implement `reverse`.
I think I could get used to crowd-sourced copy editing!
It seems like that at first, doesn't it? The trick is this bit from the [`DoubleEndedIterator` docs](https://doc.rust-lang.org/std/iter/trait.DoubleEndedIterator.html): &gt; It is important to note that both back and forth work on the same range, and do not cross: iteration is over when they meet in the middle.
See the PR discussion: https://github.com/rust-lang/rust/pull/42782 For some iterator types, `for_each` (-&gt; `fold`) can be much faster than a plain `for` loop. What looks clearer also depends a lot on what you're doing, e.g. I think `for_each` looks better with longer iterator sequences. It also makes it easier to switch your loop to rayon's `ParallelIterator::for_each`.
A for loop is the most idiomatic solution here, though `Iterator::for_each` as others have mentioned can have the same behavior. Your second bit of code is also idiomatic, but doesn't add "in place" (it creates a new vector).
serialize to a [value](https://docs.rs/serde_json/1.0.5/serde_json/enum.Value.html), then call `as_object_mut().insert(key, value)` 
A story we'll be telling our grandchildren.
Do any of these have Rust internships too? I'm looking at company sites and that doesn't seem to be the case :-/
just wait until they hear about bubble sort!
I had an idea for eliminating labeling which I *think* is workable. The key is instead of declaring a `const`, make an empty `impl` block for a useless struct. The assertion goes in the `where` clause. I illustrated it [in the playpen](https://play.rust-lang.org/?gist=a8cef3ae10a0965a6d5804a89ecd8636&amp;version=nightly).
Would a custom subtrait work? E.g., ``` trait B: A { fn foo_u32(&amp;self, arg: u32) { &lt;Self as A&gt;::foo(arg); } } impl&lt;T: A&gt; B for T { } struct Hello { a: Box&lt;B&gt; } ``` I'm not sure if the `:A` constraint on `B` disqualifies it from being object-safe or not.
how is fold faster than a for loop?
The author said on lobsters that it was inspired by ours.
It could be done without a great deal of difficulty: if in a function call or tuple declaration (I’m considering tuple struct/variants to be function calls) it gets to the last member but has more than one thing left, it converts the remaining items into a tuple. So given `fn(X, Y)`, foo(x, y, z)` would try to unify `Y` and the type of the two-element tuple `(y, z)`, which only has a chance of succeeding if `Y` is generic. This translates to patterns without much trouble. This solves varargs as well. Whether the solution is a *good* solution, however, is another matter. The biggest problem with this approach of doing it implicitly is that `T` and `(T,)` are different types, and so there is essentially a discontinuity present if this is all done *implicitly*. (Perl essentially has this feature woven into the language, but it’s implemented through what is essentially *mandatory* list flattening, so that—in Rust terms—there is no distinction between `T` and `(T,)`, `((T, T), (T, T))` and `(T, T, T, T)`. We do not have that option.)
You can have `record.id` be a `Rc&lt;String&gt;`, instead. This is a reference-counted, immutable pointer to a string, so the two will share the data they point to. An `Rc&lt;String&gt;` is `AsRef&lt;String&gt;`, so it can easily be coerced to a `&amp;String`, and thus a `&amp;str`, so it shouldn't change how your code works too much. The exception is if you ever need to mutate the `String`; an `Rc` is like having immutable borrows all over your code at runtime, so for safety's sake, your `Rc` is now fully immutable\*. If you need to change the value of the field, you'll have to replace the `Rc` with a new one containing a brand new `String` (so that the other "borrow" of the string, i.e., the other `Rc`, isn't changed.) \*The exception is that Rust is smart enough to let you mutate the contents *if* the reference count is exactly 1; see `Rc::get_mut`.
It's annoying but possible to use `?` in iterator chains. You just have to use the collect-into-result trick ([example](https://play.rust-lang.org/?gist=8d4e95601a36592317cf3a5f18c3e534&amp;version=stable)). Crates that might help are itertools (with `process_results`) and fallible-iterator.
Thanks, I decided to use option 3 for now, and that was quite easy to implement. I'll definitely read up to understand the first and second options though. 
This is less a question, and more a comment that doesn't quite warrant its own selfpost that I figured people might still enjoy: Procrustean (adj.) 1. Attempting to alter a solution to a problem you've come up with so that the Rust borrow checker will allow it to compile, instead of writing it in a `rustc`-friendly way from the start. *I ended up having to store the allocator state for my GPU-side OpenGL buffers in a `Rc&lt;RefCell&lt;_&gt;&gt;`, which is a bit of a procrustean solution.*
 error[E0116]: cannot define inherent `impl` for a type outside of the crate where the type is defined --&gt; tests/const.rs:19:5 | 19 | const_assert!(FIVE &gt; 2); | ^^^^^^^^^^^^^^^^^^^^^^^^ impl for type defined outside of crate. | = note: define and implement a trait or new type instead = note: this error originates in a macro outside of the current crate Not possible because you can't make an `impl` block for types not defined within the same crate 😕
What kind of internship are you looking for? Which tech area? Which geographic area (or remote)? Paid or unpaid? I could ask my boss if he wants to hire an intern but it'd probably be remote (work from home)... 
Swift is saturated with tuple syntax sugar. It can lead to ambiguity for someone who's reading your code. I _much_ prefer how explicit Rust is in handling tuples.
Super cool! How did the students feel about Rust?
For instance, `Chain::next()` has to check its state -- whether to pull from its first or second iterator -- every time it is called throughout a `for` loop. But `Chain::fold()` can check this once and do a tighter unconditional fold over just the first iterator, then the second.
Follow-up question from the AMA: Niko said this in response to a question about improving compile times &gt; even doing some simple things such as inlining of smaller functions should allow us to reduce the amount of code we supply to LLVM. I remember Chandler Carruth mentioned in his 2015 talk at CppCon that clang tries to separate concerns between the compiler's frontend and the backend. By contrast, Jonathan Blow has objected to this approach specifically because he values compile times very highly. Is this optimization in the frontend something we'll see more of in rustc? Is it something you're interested in doing pervasively, or do you also value separation of concerns?
My brain has been so conditioned from other languages that I keep getting tripped up on v = middle; (re-assign a function parameter). I like it, but I'm having a hard time rewiring my brain. Am I alone in this?
Drat. I'm not sure I'm on to anything, then. Inherent impls are the only type of item I can think of where you can repeat it without changing anything.
Hey, thanks for the reply! I'll send you a PM instead of discussing details here ...
For the record, I would've applied if it was remote friendly.
The problem comes when you have this: // crate a; pub struct Bar; // crate b; impl Bar { pub fn thing() { println!("b thing"); } } // crate c; impl Bar { pub fn thing() { println!("b thing"); } } // crate d; extern crate a; extern crate b; extern crate c; use a::Bar; fn main() { Bar::thing() } What happens? This caused problems for Haskell which allows for something like this: the compiler ends up unable to uniquely decide which code it's supposed to use. So you either get unpredictable linking behaviour, or you get libraries that cannot be used together. Now, you might think, "but what if we just named them so we can decide which one to use?" You've just re-invented traits.
yes, but this problem would be solved by having un-pub-lishable, or only crate-publishable trait implementations. i mean im sure that someone else has thought of that, and there is a reason against it, otherwise should i write an rfc ^^?
Ok I see that's a bad idea. Maybe I don't understand traits fully. Can I implement a trait for a type declared outside my current crate?
in case you are facing the problem right now you can get around it in many cases by just wraping the type you want the trait to be implemented on in a new struct with only one field, and implement the trait for that. you can also implement Deref so things are comfortable to use.
Do you mean like a hand-written Rust-style interface, or something very direct (or auto generated from bindgen?)
I should add that, if you want things like `.push()` to work, you could implement `Deref&lt;Target = Vec&lt;(K, V)&gt;&gt;` (with `DerefMut` also) instead—that allows you to get a `&amp;mut Vec&lt;(K, V)&gt;` out of it, and then its `Deref` implementation ensures you still get the `[(K, V)]` methods.
Instead of having the user supply a unique function name, would it be possible to autogenerate one using `file!`, `line!`, and `stringify!` macros?
If you defined the trait, yes. If you didn't, then no, because you end up with the same problem again.
Well what if you just combine crates `c` and `d` together? The problem still exists, you've just moved the parts around.
`G: 'static`?
None of those return `ident`s unfortunately.
It looks like it's asking for opinions of those who do and do not use it. Not just explicitly those who do not. I left a few comments myself because of some of the frustrations I have with it at work -_- Don't get me wrong I do like it, but god the documentation is lacking.
And it's kind of necessary, otherwise you'd get two references to the same item for odd-length slices.
Man, 10 releases is &gt;1 year ... I don't think I can count to 100.
[removed]
Obligatory: [explain this!](https://github.com/rust-lang/rust/blob/master/src/test/run-pass/weird-exprs.rs#L34-L54)
The solutions here don't really work for the homework, because they are required to use `ptr::swap`.
That I tried, but still the same error: Compiling playground v0.0.1 (file:///playground) error[E0597]: `m` does not live long enough --&gt; src/main.rs:15:5 | 15 | m.get() | ^ does not live long enough 16 | } | - borrowed value only lives until here | = note: borrowed value must be valid for the static lifetime... [Playground link](https://play.rust-lang.org/?gist=f3bf8cc0f61900fad168f2c6a9561207&amp;version=stable)
A lot of talk about my Australian uni planning to use Rust, but nothing confirmed yet. However, one postgraduate is writing a compiler for a language that will eventually be used for courses in Rust, so maybe were halfway there...?
Because you're over-constraining the lifetime. fn foo&lt;G: 'static + for&lt;'a&gt; Get&lt;'a&gt;&gt;() -&gt; Result&lt;G, Box&lt;Error&gt;&gt; { let m = Message {}; m.get() } Think about what you're asking the compiler to do. The bound on `get` links `Get&lt;'a&gt;` and `&amp;'a self` to the same lifetime. So when you say `Get&lt;'static&gt;`, it can *only* work for static `Message`s, which is obviously not what you want. You also can't use `foo&lt;'a, G: 'static + Get&lt;'a&gt;&gt;` because the *caller* decides `'a`, which means `m` cannot possibly satisfy that, either. What you *want* is for `G` to satisfy `'static`, and also to to support `Get` for *any arbitrary lifetime*. Hence `for&lt;'a&gt; Get&lt;'a&gt;`.
Not exactly related to Rust, but on topic. Is it common for universities to teach languages for the sake of learning those languages (and teach concepts in the process, seemingly incidentally), rather than demonstrate concepts using whatever language fits?
https://play.rust-lang.org/?gist=8e9704e0a879237ea7d6e82a636fe1f4&amp;version=stable You don't want the 'a lifetime in the get method to be the same lifetime as the reference to the Message, that would mean whatever it returns will only live to when that reference is dropped, which is the end of the method. 
I have a very productive Vim Rust setups. Relevant sections: call plug#end() (...) """ deoplete let g:deoplete#enable_at_startup = 1 let g:deoplete#omni_patterns = {} let g:deoplete#omni_patterns.rust = '[(\.)(::)]' let g:deoplete#omni_patterns.go = '[(\.)(::)]' let g:deoplete#omni_patterns.scala = '[^. *\t]\.\w*\|: [A-Z]\w*' let g:deoplete#sources = {} let g:deoplete#sources._ = [] let g:deoplete#sources.scala = ['buffer', 'tags', 'omni'] let g:deoplete#omni#input_patterns = {} let g:deoplete#omni#input_patterns.scala = ['[^. *\t0-9]\.\w*',': [A-Z]\w', '[\[\t\( ][A-Za-z]\w*'] " use tab to forward cycle inoremap &lt;silent&gt;&lt;expr&gt;&lt;tab&gt; pumvisible() ? "\&lt;c-n&gt;" : "\&lt;tab&gt;" " use tab to backward cycle inoremap &lt;silent&gt;&lt;expr&gt;&lt;s-tab&gt; pumvisible() ? "\&lt;c-p&gt;" : "\&lt;s-tab&gt;" (...) command! CtagsRust !ctags -R --links=no --languages=C,C++,Asm,Go,Rust --c-kinds=+p --c++-kinds=+p --fields=+iaS --extra=+q . (...) " Rust "" Racer let g:racer_experimental_completer = 1 au FileType rust nmap gd &lt;Plug&gt;(rust-def) au FileType rust nmap gs &lt;Plug&gt;(rust-def-split) au FileType rust nmap gx &lt;Plug&gt;(rust-def-vertical) au FileType rust nmap &lt;leader&gt;gd &lt;Plug&gt;(rust-doc) "" Neomake autocmd! BufWritePost,BufEnter *.rs Neomake cargo " Capitalization doesn't work in Rust comments autocmd! BufEnter *.rs setlocal spellcapcheck="" " Rusty-tags autocmd BufRead *.rs :setlocal tags=./rusty-tags.vi;/ autocmd BufWritePost *.rs :silent! exec "!rusty-tags vi --quiet --start-dir=" . expand('%:p:h') . "&amp;" autocmd BufRead *.rs :setlocal tags=./rusty-tags.vi;/,$RUST_SRC_PATH/rusty-tags.vi augroup Rust function! RustOnBufEnter() hi Error80 cterm=underline gui=underline hi Error80 cterm=underline gui=underline hi Comment cterm=italic match Error80 /\%&gt;80v.\+/ " anything past 80 setlocal fo+=t setlocal tabstop=4 shiftwidth=4 softtabstop=4 expandtab textwidth=80 setlocal textwidth=80 if filereadable(glob("rustfmt.toml")) let g:rustfmt_autosave = 1 else let g:rustfmt_autosave = 0 end endfunction autocmd! autocmd BufEnter *.rs call RustOnBufEnter() autocmd BufEnter *.rs call ColorSchemeFixes() augroup END (...) " Ag " http://robots.thoughtbot.com/faster-grepping-in-vim/ " The Silver Searcher if executable('rg') set grepprg=rg\ --vimgrep let g:ctrlp_user_command = 'rg --files %s' let g:ctrlp_use_caching = 0 elseif executable('ag') " Use ag over grep set grepprg=ag\ --nogroup\ --nocolor " Use ag in CtrlP for listing files. Lightning fast and respects .gitignore let g:ctrlp_user_command = 'ag %s -l --nocolor -g ""' " ag is fast enough that CtrlP doesn't need to cache let g:ctrlp_use_caching = 0 endif " bind K to grep word under cursor nnoremap K :execute " grep " . expand("&lt;cword&gt;") . " " &lt;Bar&gt; cw&lt;CR&gt;&lt;CR&gt; Whole file: http://sprunge.us/JXSQ You want to use Neovim for best results. Install `ripgrep` `rusty-tags`, `rustfmt` and `racer`. Use `gd` and `ctrl+i` to jump between tags with racer, or` ctrl+[` and `ctrl+t`with rusty-tags. Use `K` for recursive (rip)grep. `ctrl+p` for opening files. Completion included. If project contains `rustfmt.conf` it will be automatically reformatted on every save. On every build, you will get `cargo-check` and you can use `:lne`, `:lpr` to jump between errors. Feel free to ask me if something is not working or is not clear.
Pls no. We would then have same issues as with Scala implicits, where is basically impossible to tell where is the code coming from. https://stackoverflow.com/a/41709221/1391392
thanks a lot for the info, I had no idea that into_iter().map() creates a new vector :) what's the difference between `&amp;mut Vec&lt;i32&gt;` and `&amp;mut [i32]` ?
but the thing is that if you run clippy that it gives some warnings about the regular for loop, that's why I thought it's better to do it different: warning: the loop variable `i` is only used to index `v`. --&gt; src/main.rs:12:5 | 12 | / for i in 0..v.len() { 13 | | v[i] += n; 14 | | } | |_____^ | = note: #[warn(needless_range_loop)] on by default = help: for further information visit https://rust-lang-nursery.github.io/rust-clippy/v0.0.168/index.html#needless_range_loop help: consider using an iterator | 12 | for &lt;item&gt; in &amp;v { | ^^^^^^ 
Ah, the `for&lt;'a&gt;` construct. I only need it once a year or so, so it's easy to, if you excuse the pun, **for**&lt;'a&gt; **Get**&lt;'a&gt; about it. Thanks!
&gt; if you excuse the pun I don't. The police will be arriving presently to *pun*ish you.
You changed the `Get` trait to not take `&amp;'a self` but `&amp;self`, so this one won't work: you can't implement that correctly for `&amp;'a str`. Quxxy provided the right solution I believe.
If you want the same behavior as in Kotlin, where you have to import those extension functions IIRC, just define your own trait with that extension method, which you can then implement for the foreign type.
I guess I dont know the full picture here, Get doesnt have any methods?
Something like this should work. #[macro_use] extern crate serde_json; use serde_json::Value; fn main() { let input = r#" {"a":"This is an A"} "#; let mut v: Value = serde_json::from_str(input).unwrap(); // Add to the object. v["b"] = json!("This is a B"); println!("{:#}", v); }
I've started and scrapped a few Rust projects trying to do this in the last year or so. I wish I had the time to do it properly.
map doesn't create a new vector, collect does. Vec&lt;T&gt; is a growable, dynamically sized, heaped allocated array of items. [T] is an ungrowable slice of items. Vec can be borrowed as a slice. If your function doesn't need to change the size of a vector, it's better to receive a slice, because then you wouldn't restrict the user to using a vec.
Yeah, explicitly soliciting opinions of those who do not does not mean they do not also explicitly solicit opinions of those who do :)
Is that a standard thing? I can't find it anywhere...
In haskell-land, the trait implementations found in modules other than where the type or trait are defined are called [orphan instances](https://wiki.haskell.org/Orphan_instance), in case anybody here wants a buzzword to search for to read more.
I'd recommend only taking on a project you are actually interested in, and not just for the sake of it, because for example I was actually interested in the project and it's potential use case and still ended up dropping it, as there are more interesting ones to work on I guess. Anyway I guess I will update the issues in the repo to reflect some of the missing things etc.
Fair enough, I suppose seeing what I can contribute is a good starting point. As far as motivation goes through, a beets replacement is something I would use if it existed.
I'm trying to find the cleanest way to get the first `Some` value from a method on a item in an iterator. Best described with code: let iter = Iterator&lt;T&gt;; let y; let x = for i in iter { if let Some(a) = i.method(y) { Some(a) } } else { None } This is the gist of it, what's the best way to do this in valid code?
You can add methods to a struct from a different crate using traits: // From external crate pub struct Bar { pub foo: i32, } // From your crate pub trait BarEx { fn do_stuff(&amp;mut self); } impl BarEx for Bar { fn do_stuff(&amp;mut self) { println!("Do stuff"); } } fn main() { let mut b = Bar { foo: 1 }; b.do_stuff(); } The only downside is that you have to import `BarEx` to be able to use those methods. You can make this easier by exporting common traits with `pub use` in a prelude module. 
Which “RBE Activities” are you referring to? I know [Rust by Example](https://rustbyexample.com/std_misc/fs.html) as just that: a collection of code examples for various things.
So you teach ocaml but not haskell? What was the reasoning?
Makes sense!
The OP wants to implement a trait for a struct where both are from external crates.
&gt; You can certainly get rid of `Cell` by replacing it with `*mut i32` and `unsafe`, which takes it down to 253, but is probably sub-optimal. No, that would be an UB. It's forbidden to have multiple mutable references via anything else than `UnsafeCell::get()`. `Cell` is just a thin wrapper around `UnsafeCell`.
To the best of my knowledge it does not currently exist, which is why I did someone could implement it 😀 But that could take enum Liquid { Water(u8), Poison(u32) } And generate all the relevant methods with appropriate names - `.map_water()`, `.poison_or()` and so on.
One way to solve this would be "impl crates". You put the `impl` into separate crate, then instead of depending on concrete crate the crates that want to use it depend on `impl trait_crate::Trait for type_crate::Type`. Finally the `--bin` crate chooses *single* implementation for each such dependency.
Maybe, but you spend half an hour clearing out trees so you can get at an iron deposit only to find you're short on furnaces, then it's back to the stone patch, but you forgot coal for the burner drills... pretty frustrating.
You can use [`Iterator::filter_map`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.filter_map). let x = iter.filter_map(|i| i.method(y)).next();
Just out of curiosity, why does the full-stack position have a lower upper salary then other positions (backend, android etc)?
`rock.clone();`
*Or*, you could pass around an `Rc&lt;Rock&gt;`, and then you only need to carry one rock and share it. Shame about needing batteries and a controller, though.
It's quality is really impressive. File size is significantly larger than GIFs generated with ImageMagick or Ffmpeg and rendering takes some time, but if you want the best available quality in an animated GIF this is just great. So much fun with an obsolete format :)
Fortunately those stone drops help with that. Fists as a weak backup tool/weapon would be nice though. BTW I think you may be rooking for /r/playrust
The implicit values used by the Scala compiler are controlled by normal scope/import rules (with some exceptions). I totally agree that implicits should be used sparingly, mainly for "type class" instances, but it's extremely useful to be able to define a type class instance for a type from an external module (an orphan instance). It's definitely something I miss in Rust.
I should have known this, I red this in the book. Thanks
In case you're only interested in remote/onsite positions: ONSITE: - OneSignal - Cloudflare - Headlands - AdGear - DiamondHead - Immunant - Onai (visa) - One Codex - FINBOURNE - TenX - Starry - Ahrefs - Thought Machine REMOTE: - Immunant (US-only) - TenX - Ahrefs - Qtum Not specified: - Prevoty - Dwelo
I wish you could do it within the main program, but stick with the current restrictions between crates. The problem is the current restrictions prevent you from making 2 crates inter-op in certain circumstances.. but if you could put the appropriate impls in your main program (where they wont ever cause clashes in updates for *other* users), you could then have a stopgap whilst you ask 'crate a'/'crate b' communities to provide the support you wanted
You are probably looking for [extension traits](http://xion.io/post/code/rust-extension-traits.html).
Makes me regret I'm not rich and californian, my university is still stuck teaching java 7.
I would be interested in knowing which universities in Germany use rust, as I am considering studying there next year.
It's possible to get rid of `Option` by initializing Cell with actually usable value. For example. fn unreachable() -&gt; i32 { unreachable!(); } b = Cell::new(&amp;unreachable);
I'm a guest lecturer at the University of Konstanz, which teaches both the basic OS course in Rust as well as a full introduction lecture. Saarbrücken hosts the Rust Belt project: http://plv.mpi-sws.org/rustbelt/. The other one is... Hannover, I think?
That was not the impression that I had gotten; it looked like that was a suggestion for how to implement it, under the mistaken impression that there were not other safe ways to split or swap items in a `Vec`.
I'm accessing them sequentially for the moment so that's not a problem.
Sorry, I don't understand the problem here. If `b` implements a trait and that is only visible inside that crate, then how is the combined `c+d` implementing it again an issue? It should never be ambiguous which impl to use.
Python does it essentially exactly this way, the tuple operator is the comma rather than the parentheses. It seems to work okay, but in practice one often ends up using parentheses anyway, and Python doesn't have to try to deal with type inference or static types. It does result in matrix indexing in numpy being tuple driven exactly as one would want, which is nice, but making that work nicely with rust's strong typing is tricky to begin with. To get something as generic you'd need to be able to index by a (variable length) array and have the dimensionality of your return type depend on the length of said array.
My thinking was "making it private doesn't help if you're in the crate with the private impl, and there's a non-private impl somewhere up the dependency chain". Remember that a new impl could be introduced at any time. Another reason private impls are sketchy: imagine that you have `pub fn foo&lt;T: SomeTrait&gt;(v: T)` defined in `b`, which has a private impl of `SomeTrait for Bar`. `c` cannot call `foo` with `Bar`, because the impl is private. But if `c` adds a private impl of `SomeTrait for Bar`, and it calls `foo`... which implementation does `foo` use? The one the defining crate knows about, or the one from a totally different crate it thought couldn't exist? How does it propagate that information? What happens if it has to then call a function in *another* crate that doesn't have either of those private impls? What if it has to call a function that relies on the impl of particular types being the ones it thinks are the only ones to exist? It was trying to sort that mess out that made me shelve my proto-RFC for named impls a while ago. :P
Now I'm suspecting that this whole post was a setup for this pun.
This should be fixed now :)
Thanks for cross posting this here! I look forward to reading what Rustaceans think of Haskell :) 
&gt; So much fun with an obsolete format :) I was bewildered five years ago when I came on Reddit and saw people using GIFs as if it were a normal thing to do. (At least they had learnt to use multiple palettes for more colours!) After some time, I got used to it and didn't think of it. Then also, it's not usually actual GIFs these days, even though people call it that, is it?
Why the need for `Cell` in the first place? The code is a bit hard to grasp.
This feels extremely long to me.
Since [Index](https://doc.rust-lang.org/std/ops/trait.Index.html) and [IndexMut](https://doc.rust-lang.org/std/ops/trait.IndexMut.html) are traits you could do that yourself. Something like https://play.rust-lang.org/?gist=115c1cfb27082a5e6687a4e196acb3ab&amp;version=stable, although that won't compile.
&gt; Then also, it's not usually actual GIFs these days, even though people call it that, is it? It depends :) Some platforms allow uploading of GIFs and then silently convert it to a video (WebM or MP4 mostly) to save bandwidth. Imgur also pushed their GIFV "format", but that's actually just a fancy marketing term for using MP4 instead of GIF. But still pure GIF files are used frequently (I just recently saw one in the latest Windows 10 update feature page). It still has the advantage of being supported virtually everywhere (e.g. Github will show animated GIFs, but not video files), and as long as you keep things small and short enough the large file size might not matter too much for loading (but still eats away bandwidth of mobile users). But as the author of a GUI tool to record animated GIFs I'm frequently amazed how people don't know about GIF's limitations and expect it to be the perfect format for HiDPI full screen recording :D
Is it possible to have a generic string to other type conversion function? [This guy](https://github.com/sinhrks/rust-nullvec/blob/master/src/generic/mod.rs#L12) Can hold a lot of types, It is used in [this project](https://github.com/sinhrks/brassfibre) to read data from CSV and I think it works because that version of the csv library uses the old rust-serialize crate. I want to get rid of the dependency, changed the code but now my code does not know how to convert the strings from the csv file into their type. I thought I would write it by hand but somehow this naive approach did not work: impl&lt;'a&gt; From&lt;&amp;'a str&gt; for Scalar { fn from(value: &amp;'a str) -&gt; Self { let result = value.parse::&lt;i64&gt;().or_else( value.parse::&lt;f64&gt;().or_else( value.parse::&lt;bool&gt;().or_else( value.parse::&lt;str&gt;() ) ) ); result.unwrap().into() } } It complains with "The trait bound `std::result::Result&lt;str, _&gt;: std::ops::FnOnce&lt;(std::num::ParseIntError,)&gt;` is not satisfied" Which as newbie to Rust give me no hint of what's going on. Is there an easy way to achieve this? 
Some sections have “activities” where you try to make code that doesn’t compile work. There’s not a “here’s the canonical answer” section though, no.
I know this doesn’t answer your question in the least, but after trying out various possible ways to be generic over string (or rather `[u8]`) types, building ever more confusing traits, and still not being happy with the results from an API user perspective (not to mention all the tick-ladden where clauses on the impl blocks), I eventually decided to just go with [bytes::Bytes](https://docs.rs/bytes/0.4.5/bytes/struct.Bytes.html) as a reasonable compromise.
[`or_else`](https://doc.rust-lang.org/beta/std/result/enum.Result.html#method.or_else) expects a function, but you've given it a value. So it's telling you that the type of the value (`Result&lt;str, _&gt;`) is not a function. You can see the definition of `or_else` at that link: fn or_else&lt;F, O&gt;(self, op: O) -&gt; Result&lt;T, F&gt; where O: FnOnce(E) -&gt; Result&lt;T, F&gt; So the argument is supposed to be a function/closure whose parameter is the original error type and it returns a new `Result` with the same `Ok` type and a possibly different `Err`
Is it just me that's a bit afraid of companies that list more than 4 languages in a job posting ? I mean, I get the whole "we have a scripting language, a system language and these other 1 or 2 languages we used here and there because personal preference, libraries or due to us slowly migrating to them". But, once I see people shut shoot a huge number of languages I feel like they are either lying to get more people or have a really autistic team. I mean, I can see why a company like Google would use very language under the sun, but if you're still bellow the "Spread out on multiple continents" mark I feel like some unity when it comes to language would ease the learning curve needed to enter the company and make internal tooling much easier. (Note, not saying using multiple language is bad, personally I always try to be up to date~ish with as many language as possible by using them in various projects, but I'm not a company, my goal is to learn stuff and have nerdy fun not make as much money as possible with as little work as possible)
AAAAAAAAA, don't say the Python solution is OK. The number of times I did the following ``` some_function_call( arg1, some_complex_expression_for_arg2, arg3, ) ``` "Oh I'll need that expression in a different place so I better save it to local variable! I'll cut and paste the line and there!" ``` my_local = some_complex_expression_for_arg2, some_function_call( arg1, my_local, arg3, ) ``` And now my local is a `tuple`. Bonus points if your code crashes later (or not at all) because you _were_ expecting an iterable. 
Is this a hobby project, for learning, or work? Don't reinvent the wheel unless you are doing this for fun or learning. It is very hard to get the fault tolerance right (I make my living finding bugs in distributed systems and battle hardening them, and would love to have more business, but please don't make the lives of your coworkers miserable for greedy reasons). If you're doing this for learning or fun, you have a lot of paths you could take. It totally depends on what you're more interested in learning about. There are tons of interesting processing-related scheduling papers out there. You should decide up-front how much you care about throughput, low-latency, fairness, and cluster utilization. [This page](http://www.dockermall.com/classic-papers-google-uses-borg-for-large-scale-cluster-management-chapter-7-chapter-8-acknowledgments-references/) has a quick overview of some of the relevant papers to dig further into, if that's your thing. Spark was the first Mesos scheduler for a reason. Mesos gives you way more flexibility than k8s/swarm/nomad/yarn but you have to do more work to get the thing running. Companies with complex needs tend to choose mesos for this reason, and write their own scheduler. But there is more buzz about k8s because it's google's cloud migration onramp, and they advertise it heavily (without saying as much). K8s may be better for a resume, and will be applicable to more general purpose problems. Mesos is for problems that require more specialized solutions, it's harder to use and there are fewer companies looking for mesos people. Nomad gets out of your way more than the others, and this may be the best choice if you don't actually care about gaining expertise in a scheduler, and want to spend your time doing other stuff. Fault tolerance is its own beast. For data processing, everything needs to be idempotent. Servers will lose connectivity from the coordinators and then come back with finished results later, and this can't mess up the identical results that got rescheduled somewhere else in the interlude. Map/Reduce semantics are fairly simple to partition with, and you don't need to do any complex data dependency graph analysis like what something like Flink handles. If you care more about interesting processing, maybe check out Flink or Druid first. Spark, Samza, Drill, Storm and Mapreduce still have uses and are widely deployed, and you may find their architectures interesting. Feel free to PM for more specific info or pointers about things, I love talking about this stuff.
&gt; The other idea I've had is to turn the "simulation" portion of the game into a library, then create two separate cargo projects, one for each rendering method, that use the simulation library. This is the route I would take. No need for separate Cargo projects though, you can use the Cargo Workspaces feature to have multiple crates in the same project. In my experience, a shared library with separate top-level entry points works better than a single entry point with lots of conditionals (in all code, not just Rust).
you may try [actix web](https://github.com/actix/actix-web), it supports websockets, long polling, etc. but it still very young.
I poked at trying to integrate Rust with Nginx, and found I was not nearly experienced enough to make it work. Its possible that their edge team is purely Nginx only, and like me, figuring out how to integrate Rust with Nginx was too much of a pain? (I'll give it another try at some point in the future, because if I could make it work, it would be a fairly obvious place to integrate Rust into our mostly JVM stack. I keep hoping someone who is better at unraveling C build scripts figures it out and saves me some of the effort.)
One other area where this exact problem comes up is platform-specific code. In that case you use `cfg(target_os = ...)` instead of `cfg(feature = ...)`, but it boils down to the same thing. I have tried both the trait based and the *different versions of the same struct* approach, so I can comment a bit on those. I don't know about the library idea, but assuming that it does not have some hidden pitfalls it might actually be quite nice. The advantage of the trait based approach is that the compiler ensures you have the same functions for both structs, and prints nice errors if you don't. The *two structs* approach creates much more messy errors, as you get one error for each place you use the missing function. The trait approach does however mean you have to `use` the trait wherever you want to call its functions, which you avoid with the struct approach. Except for that, both approaches are pretty much the same. I have ended up using the struct approach for now, and I have also seen other crates do that. However, I might change that in the future.
Thanks! I took over a lot of your config, removed some things I don't want, and reorganized a bit since I like using `after/ftplugin`. Did you realize you have 2 calls to `setlocal tags` on `Bufread *.rs`? Ok, fzf seems to be working, not sure if I keep that. Rusty-tags is working, but does not find the right definitions (I'd not expect a tag based approach to work for rust, though). What does not work is `gd`, as well as those other commands. I'm using dein instead of vim-plug, could that hur with the `&lt;Plug&gt;` definitions? Any idea how to debug that?
Why does `Get` have the lifetime? Without methods, I don't think there's a reason for it and most cases with methods also don't need it.
I tried, but it does not work as it... well, as I'd want it. I don't thinks tags can really work here. See https://www.reddit.com/r/rust/comments/7ab15j/how_to_dig_through_sources_with_neovim/dpajj63/ if you're interested on the specifics.
Heheheh, that's certainly a valid complaint.
Fair enough, though I was thinking more along the lines of "if a crate that isn't the trait or type definer tries to impl the trait, the implementation must be private", which seems like it would solve at least the diamond-dependency problem. The desire for being able to implement trait `a::Foo` on type `b::Bar`, where you control neither `a` nor `b`, is usually *not* "I want to re-export this implementation", it's usually either "`b` should implement `Hash` on this type but the author forgot", or "I want to make `a` and `b` work together somehow". Forcing non-original implementations to be private makes both these cases possible. I do agree that the generic-constrained-by-trait problem is pretty sketchy, yeah. Trait objects don't have this problem, since "which implementation do you use" information is passed along with the object itself in the form of its vtable pointer. Hmmm... I would *hope* that if you just say "the trait impl that the caller knows about is the one that gets used, always" then everything might fall into place and be consistent. The caller will only be able to know about one trait implementation for a type at a time (until trait specialization happens I guess but that's a different issue), and if you know the trait's definition you should know everything that the callee might be able to do to the object. However, I can't prove that this is the case yet, and "how does it propagate this information" is another very good question I don't have an answer to. ;-)
Thinking on it, this broad take on estimation may be too big to be useful. I mean, if you were to classify languages with this scale, you'd end up with: * 1000: assembler, lisp, fortran, c, c++ * 100: java, c#, f#, python, ruby, lua, JavaScript, Haskell, etc. (pretty much every language after lisp that uses garbage collection) * 10: rust, go, swift, jai On a logarithmic scale, 3.33... is the splitting point between 1 and 10, and 33.33... is the splitting point between 10 and 100. Another way of thinking about it is an estimate of 10 releases would mean between 3 and 33, and an estimate of 100 is between 34 and 333. I feel safe estimating that getting to that 1.0 stability with that wide amount of libraries is going to take more than 10 releases, and fewer than 100. On which side of that logarithmic spitting point of 33 releases would I estimate? I personally have no idea. 
Maybe try wrapping with Arc.
&gt; A new scientific truth does not triumph by convincing its opponents and making them see the light, but rather because its opponents eventually die, and a new generation grows up that is familiar with it. -- [Max Planck](https://en.wikiquote.org/wiki/Max_Planck) _rust programmer since 1858_
My only experience was that there was a "Programming languages" class where the purpose was not to teach specific languages, but to demonstrate the conceptual differences between various *kinds* of languages. If I recall correctly it looked at C, Scheme, Prolog, and maybe one other I can't remember.
Someone will add linear type annotations to Java soon enough.
/u/playrust
Thank you for the suggestion. I checked out the GitHub repo and from the examples it seems fairly easy to use. Although, I'm looking for a more widget-centric web-framework which allows web-development in similar fashions as desktop-gui frameworks which I fathomed may not what actix-web intended to be. Am I wrong? By the way, I noticed you are the main author. From the examples, the API looks clean and easy to follow. Congrats on that!
lol thank you
Yes, you are right. Arctic web is a micro framework for rest stile services. I don’t think you’ll find any desktop like web framework in rust ecosystem.
I am aware that my `.vimrc` is a mess. :D `plug` has `:UpdateRemotePlugin` and I don't know how `dein` handles that`. Make sure to have `racer` in path and set `RUST_SRC_PATH` ``` RUST_SRC_PATH=$HOME/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/src ````
Thanks for the clarification.
They're in the middle of the first assignment, so I'll have to get back to you on that!
A big reason is just personal familiarity--I've used OCaml much more than Haskell, it's closely related to Standard ML which was the language of choice at my alma mater. I think OCaml is also a little easier for functional newbies than Haskell since allows for side effects (don't have to introduce monads up front) and has an eager semantics. 
Look at [Rocket](https://rocket.rs/) (recommended because very easy to use), [Gotham](https://gotham.rs/), [iron](https://github.com/iron/iron) or [other frameworks](http://www.arewewebyet.org/topics/frameworks/). For database access, I've used [rust-postgres](https://github.com/sfackler/rust-postgres) successfully, so I'd recommend that (raw SQL). If you want an ORM, use [diesel](http://diesel.rs/) - postgres + mysql backend. In the Rust world, it's not so much "one toolkit that does everything". Since cargo makes putting things together rather easy, you pick and choose what you need. There is no 2d painting thing, however. You'd need to use regular HTML, CSS + JS on the frontend.
Come do a PhD, I get paid to be here :-)
I think you're constructing a false dichotomy. In this course for example, I started designing it by deciding what language concepts I wanted to teach (object systems, formal foundations, coroutines, etc.) and then picking the appropriate languages for each. However, if for each concept you picked whatever language fit the best and ended up with, say, a dozen languages, that would be a worse experience for the students than picking three languages with a slightly worse fit but capable of accommodating all the necessary concepts. I say worse experience both because there's a learning curve to understanding a new language's syntax and semantics, and also there's less utility for the students since they won't be able to leave the course actually able to program anything in any of these languages, instead they'll just have a passing familiarity with each. Here, the selection of Lua, OCaml, and Rust was (in my opinion) a sweet spot in terms of diversity of languages and concepts.
Why do you prefer a 2-array vs a 2-tuple?
Oh right, yeah. Try this: for item in &amp;mut v { *item += n; }
I've handled `:UpdateRemotePlugin`, and I do have racer in the path and set `RUST_SRC_PATH` correctly. I tried to call the mapped functions directly, but nothing happens, not even an error message or whatnot. I'll dig into that later, thanks for your help!
Hey! I do rust stuff for Prevoty and work remotely! Most of our engineers are in the LA area, but remote is definitely a possibility.
Thanks for mentioning rust-postgres. That's what exactly I'm looking for, for database connectivity. Since Rust is very young, it seems you are right on that. My chances of finding such a thing are slim. After posting here, I found this website http://www.arewewebyet.org/ (similar to http://arewegameyet.com/) which seems to clarifies all the info on the current status of webdev support in Rust.
Some of that depends on what the company's product is. If it's something service-related where all of those languages are hidden behind some sort of web api/site, then I would agree, more languages aren't necessarily a good thing. But if the product is something like a library where the core is written in C/C++/Rust and bindings are provided for other languages, then it makes sense to try to get as much coverage as possible to attract the most customers, and listings for lots of languages are unavoidable.
Thank you, this is exactly it.
In my experience, the problem is nginx is that it doesn't have a very well-specified plugin system. Basically, the only way that you can be sure that your plugin will work with the nginx on a particular system is if it was compiled against the exact same source with the exact same compile flags as the nginx that it's going to be used with, which makes it a pain for anyone but distro maintainers or people who are cool with managing the nginx install from the source up to get a custom plugin working. After a day or so of messing with it and coming to that conclusion, I decided that since we already have some lua/nginx integration, it might be easier to go the nginx-&gt;lua-&gt;rust route. It's a bit roundabout and might not be as performant though. Haven't gotten around to building it out and testing it. Alternatively, have you looked at the [jni crate](https://github.com/prevoty/jni-rs)? The JNI is surprisingly easy to integrate with, though it's pretty much all reflection once you start working with java objects in rust.
Ok, Racer is working, it simply can't find what I have it looking for. That's a bit surprising, since RLS at least finds some of the things.
I prefer the resulting syntax, easier to read and type.
I find it useful to see a flair on users to see how they're involved, it's a good thing! Of course, that kind of mandates that things stay current, which might be quite a hurdle... but implementation details besides, I find them useful :)
is it possible to have links? I'd prefer to just have a link to my github there.
Technically impressive, even if I believe using gif for video require death penalty. 
In my opinion, it increases the discoverability of libraries. So I see "oh that guy is working on X, it has an interesting name, let's check out what it actually is". Sure it's bragging, but it's fairly modest and there's nothing wrong with being proud of making useful libraries. What's the worst that could happen, someone puts libraries in his flair that don't belong to him or doesn't exist? This would only lead to more people checking out that library, so it'd be shooting yourself in the foot. Flairs lead to recognizability. "Hey you are the dev of X, I have a question regarding that, I'll shoot you a PM". That kind of stuff. GitHub is sometimes a bit too "formal" for these types of conversations. I'm personally indifferent towards flairs. Currently flairs are "curated", so you have to have a well-known library before you get a flair. On the other hand, you could also let people design the flair how they want (not only library names, maybe twitter handle, company, funny quote, etc.). 
I find it useful. When the flair is missing, it does not make the "authority" go away, it just makes it invisible to newer members of the community, the outsiders. Basically, it feels like a democratization of social knowledge, which is more positive then negative.
The company I currently work for uses: - Python (scripting), - Java (a lot), - C++ (latency-sensitive stuff), - Verilog (very latency-sensitive stuff). I *mostly* work on the C++ stuff, but being a small company I'm expected to be able to debug Python and Java stuff as well, our FPGA engineers are expected to use C++ and Python and a handful of engineers can actually code in any of the above 4 languages. I wish that at some point Rust will make its way in, and then we'll have 5 languages. *Note: I am excluding SQL, even though some report queries are definitely SQL monsters.*
There are also activities where one is to add functions, for example, to otherwise well-formed code. How is anyone supposed to know if they have a canonical/canonical-enough solution in such cases? If one has trouble constructing a solution, how is one supposed to work it out and/or research it? [begin rant: I've seen a lot of tutorials for various languages over the years and too often the ones over which people go, "This is the best one eva!" end up being insufficiently developed. RBE is starting to look that way as well. end rant]
Initially I think flairs were helpful because there were so few of them, so when you'd see flair like "rust", you could be reasonably sure that the person knew what they were talking about. As the community grows, there are so many flairs with no explanation for what the flair means, or why anyone should care about the flair, that it just blends in and doesn't mean anything. I think it'd be better to have something like the hats on [lobste.rs](https://lobste.rs/) where a user could choose to apply a flair to individual posts, like "Rust Community Team" when talking about community issues. Having flairs always displayed reminds me of email signatures that include tons of certifications, even if they aren't relevant to the discussion.
RBE is in kind of a weird spot; it was originally written by someone and then donated to the Rust project. People who don't like my writing style often like RBE, so I don't want to work on it too much and ruin that. Nobody else has stepped up to really make it their own; we've had some significant contributors in the past but like most projects, they've since dropped off.
Ok thanks, were not sure whether there was a different reason other than aesthetics.
I mean, those aren't awful solutions, and might be worthwhile, but its like... I would have to argue why we don't just do the nginx integration with Lua if we have to pay the overhead anyways? But nginx is kinda an ideal use case: internally, we can easily recompile for the version of nginx we use, we have a need for some higher performance custom logic being pushed up into the nginx layer, and we would rather not expose ourselves to a bunch of primarily Java programmers writing C code. I will dig through the JNI crate though, thanks for that link. Maybe a solid use case will come up there as well.
&gt; One good way to get the kind of info you're thinking about is to post on https://users.rust-lang.org/; Thanks. &gt; People who don't like my writing style often like RBE I know I will sound stupid for asking this but who are you in relation to Rust?
&gt; Rust-tags takes you to https://github.com/KillTheMule/nvimpam/blob/master/neovim-lib/src/rpc/client.rs#L117, which is not right, but https://github.com/KillTheMule/nvimpam/blob/master/neovim-lib/src/session.rs#L141 is the right target. That's just how tags work, if you've multiple tags with the same name, then you might have to jump multiple times. You're aware of the `:tnext` command in vim? I've mapped it to: `nmap &lt;silent&gt; &lt;M-t&gt; :tnext&lt;CR&gt;` 
I personally find it especially useful for identification. When someone asks a question about a crate and I see a reply by a user with that crate as flair, the answer naturally attracts my attention (even if being recent it is ranked lower) because I expect it to be more accurate.
It's all good! I shouldn't have assumed :)
In general, you could use the ? operator and propagate the error code the caller. I'm sure in the final version you do not really want to print out an error and just ignore it. Using this strategy, it becomes something like this (I also removed some type annotation): let conn_params = connect_params?; let mut connection = Connection::new(conn_params)?; loop { let local: DateTime&lt;Local&gt; = Local::now(); let ts = local.timestamp(); let schema_set = connection.exec("SET SCHEMA MYSCHEMA")?; println!("SCHEMA SET") let query = format!("INSERT INTO MYTABLE VALUES ({}, 'sdfasdf')", ts); let response = match connection.statement(&amp;query) { Ok(hd) =&gt; { hd }, Err(err) =&gt; { print!("Encountered error while running query {} \n {}",query , err); return; } }; match response { HdbResponse::SingleReturnValue(srv) =&gt; { match srv { HdbReturnValue::ResultSet(rs) =&gt; { println!("{}", rs) }, HdbReturnValue::AffectedRows(ar) =&gt; { println!("{:?}", ar) }, HdbReturnValue::OutputParameters(op) =&gt; { print!("{}", op) }, HdbReturnValue::Success =&gt; { print!("Success"); } } }, HdbResponse::MultipleReturnValues(mrv) =&gt; { println!("{:?}", mrv); } } }
const generics might be a point in the array's favour. But that's not finished yet.
Managed has explicitly told me I need flare so I can't say I do.
What about ZeroMQ?
I wasn't, and it's very helpfull indeed. Thanks! I googled for `[{`, and now tags seem more helpfull than rls. Is there a way to make tags work with external, non-vendored dependencies? E.g. stdlib?
You can implement `Display` or `Debug` for `HdbResponse` then do all your pattern matching, custom printing within the `fmt` function. Then in your main body just type: `println!("{}", response);`
This one seems to be the future for glyph rendering in rust https://github.com/pcwalton/pathfinder. There's also https://github.com/redox-os/rusttype and https://github.com/servo/rust-freetype. Fair warning, there is a lot of churn in this domain. ~6 months ago I was looking into this and even since then there has been a lot of changes. It could be that there are lots of things I don't know about because they've appeared recently.
It would be nice to put the `use std::mem::{transmute, forget, uninitialized};` inside the `fn $label` so that as long as you used labelled assertions, the user wouldn't have to import those themselves. I don't think you can do that in a way that will allow the import to be constrained to a smaller scope with the unlabelled assertions though :-/
Either the trait or the type has to be defined in your crate; they can't both be external
I left that out in the post but the actual definition in the crate does exactly that: https://docs.rs/static_assertions/0.2.3/src/static_assertions/lib.rs.html#226-238.
In this situation `main` is the only method so where would you handle an error and not die?
zmq is a fairly complex messaging library, and could play a part in a solution if that's something you want to use for handing out tasks, but I feel like it's a strange fit for a throughput-bound reliable distributed work scheduler. It handles interesting communication topologies over TCP_NODELAY sockets, but I assume you'd want at-least-once semantics so chunks of the input data don't get dropped on the floor. zmq is used more frequently in latency-bound work queues without strong durability requirements. You can build durability on top of it but why not just use kafka or rabbitmq at that point? It's a framework, and you can bend it to work for this use case, but it feels a little out of place in this domain to me.
I like flair, it lets you know that someone is involved (and with what) and sometimes lets you discover new libraries; I found flame that way for instance. Plus it's nice for the author himself, a bit of acknowledgement for some valuable work they did; nothing wrong with that. 
&gt; My understanding is that iter() iterates over &amp;T and in copy type for &amp;item in list.iter() { item is already type &amp;i32 so &amp;&amp;i32 doesn't make any sense. It's the opposite; `&amp;item` is a pattern that says "hey I'm gonna match a `&amp;T`, give me the `T`. This works because `T` is `Copy`, otherwise you'd get "cannot move out of borrowed content".
Well, you need a second function for that. I'm not saying that this particular example with these particular constraints can be done in a much better way but in general, it is possible, I think.
Nope, text only.
I find flairs useful for newcomers. It enables them to get some bearing who people are and what they do. I don't think of it as "being an authority", but more that it gives a little context.
Noted.
&gt; For non copy type, if I put the extra reference sign the compiler would complain In this case, the complaint is that the pattern `&amp;item` can't extract/copy the item out of the reference. &gt; For copy type if I don't put the extra reference sign the compiler would complain In this case, I suspect the complaint is not with the loop itself, but with `item &gt; largest`. That's trying to compare `&amp;i32` to `i32`, which isn't implemented. But it should also work if you wrote the loop like: for item in list.iter() { if item &gt; &amp;largest { largest = *item; } } Whereas with the `Point`, your use of `.x` and `.clone()` automatically dereferences as needed.
Now's as good a time as any to remind folks: if you would like us to put the name of your project as your flair here, you can PM the mods at any time to request it!
&gt; E.g. stdlib? Have you read the README (sections `Rust Standard Library Support` and `Vim Configuration`) of rusty-tags?
I like to advertise the projects I work on so if you like to join you'll know where to look.
No I didn't, I kind of went into "let others tell me what to use" mode, and there was so much to walk through right now that I neglected to inquire this myself, after so much hassle with rls. Thanks for pointing it out :)
Multi-project repo is one way, as mentioned. Works best if you need to separate dependencies. Another is - have a library with multiple binaries, running it like 'cargo run --bin text' for the text version.
Interesting I have the *show my flair on this subreddit* checked?
Oh weird, it's only showing up on *new* comments? That's bizarre. :P
My hour old original comment shows it on my machine o.O
&gt; For copy type if I don't put the extra reference sign the compiler would complain The complaint is for a different reason. In your example, `&amp;item` has type `&amp;i32`, therefore `item` has type `i32`. You can fix the problem by rewriting it as below: let mut largest = list[0]; for item in list.iter() { // now, item has type &amp;i32 if item &gt; &amp;largest { largest = item.clone(); } } largest Notice the `&amp;largest` in the comparison. You cannot compare `&amp;i32` against a `i32`, but you can compare `&amp;i32` against `&amp;i32`.
This wouldn't be happening if Reddit was written in Rust!
Can you link to what `links` does? After a quick search I've been unable to find it (is it on `Cargo.toml`?)
*RIIR intensifies*
Oh really? I've been here like two years and always wanted flair.
I seem to remember there was one sub that allowed you to link to your steam profile
http://doc.crates.io/build-script.html#the-links-manifest-key It's not *exactly* what you need here, as it has extra semantics, but we could do something that does exactly the right thing if it were to be a big deal. &gt; Cargo will always only include an unique 1.x version right? It's more subtle than that; Cargo attempts to unify your versions as much as possible, so if you had ^1.0.0 ^1.1.0 you'd get 1.1.0 in each case, but if you had =1.0.0 = 1.1.0 then it'd include both. You have to go out of your way to do this though.... the default behavior is `^`.
ah I see, so does compare `i32` against `i32` compare the content or the address? Do I need something like *item &gt; largest
&gt; But as the author of a GUI tool to record animated GIFs I'm frequently amazed how people don't know about GIF's limitations and expect it to be the perfect format for HiDPI full screen recording :D To which the only proper response is defaulting to webm encoding, of course.
In this case it just seems you're printing this stuff out so if you implement `Display` you could just have one value be put in aa print statement and have it be printed out. You could also implement [std::error::Error](https://doc.rust-lang.org/nightly/std/error/trait.Error.html) for your error type and just have it act like in the example there. I wrote about this as well [when dealing with nested types](https://mgattozzi.com/russian-dolls) so it might help you out. All this code will still have to exist in some place but if you have to pattern match this in multiple places you don't have to keep redoing it each time. Those traits are super useful for a slightly larger code base.
hmm, for non `copy` type, why can I not extract the item out? is it because moving one of the item in the list out will invalidate the entire list, is there a way I can make a copy of the item?
Usually I find flair off-putting because it's associated with some kind of authority, real or not. Here it's just "so and so wrote a parser" or whatever. Which I think is great, because it's up to each of us to decide whether or not we think that makes them cool. The key is that the requirements can be met by anyone in the sub.
ahh, that makes alot of sense, so what is the rust way of iterating an object and return that object without taking ownership and influencing the original object?
&gt; Or might it tend toward bragging, argument from authority, etc. I think that danger exists, but folks in the subreddit so far have not abused it that way. It's more of a quick way to learn more about community members, and in cases where someone is talking about their crate, it highlights them. I kinda like the old colorful flairs but those are probably more prone to argument from authority.
A reference just *borrows* the data, but it must be released back to the owner eventually. Moving the item out would be destructive, leaving the owner with invalid state, whereas using `Copy` leaves the original untouched. Calling `clone()` is the right way to make a manual copy, but you can't do that from the pattern.
Congratulations on your new `flair` flair
I don't really care one way or the other.
No, Rust compares `&amp;T` against `&amp;T` the same way `T` is compared with `T`. To compare addresses, you have to convert them to raw pointers first.
[I made a stupid tree](https://play.rust-lang.org/?gist=c28c4179f75139737d2ff47cd0c6378d&amp;version=stable) as a learning exercise. It compiles and behaves as expected... how many things are wrong? Obviously, it's not terribly useful, but I'm interested in feedback about best practices and how dirty my code is.
Would like an Ion flair, maybe, given [my work on the Ion shell](https://github.com/redox-os/ion/graphs/contributors)
I like to see flair because it can help me remember who is who. With differing usernames between Reddit, GitHub, and the forums, and places where people commonly use their real names like blog posts, StackOverflow, and actual git metadata, it can sometimes be hard to keep track of who's who. The flair can let you recognize "ah, yeah, that's who that is." One example I can think of off the top of my head is /u/Quxxy. I never would have realized that was Daniel Keep without the flair, though it did take some time to map between "His Holy Macroness" and "The Little Book of Rust Macros". I think that the value goes down the more items people have in their flair; at that point it seems to get more to the point of bragging. I think one to two is preferable, three is OK if you really have three you're known for and they aren't obvious from each other. For instance, I think `fedora` and `rhel` would be a bit redundant, but `num`, `fedora`, and `rayon` are all different enough that people might recognize you based on one but not the other. Four is probably too much. So I'd encourage people requesting flair, and the mods granting it, to pick out the ones they really think best represent what someone might be known for rather than just a laundry list of projects they've contributed to.
Definitely too much pattern matching. Would do well to learn all the methods for `Option` and `Result` so that you can use them instead of `match` everywhere; and definitely take advantage of the `Display` trait and `?` early return operator.
Let me ask you a question, /u/valarauca8 - What do you think of a person who only does the bare minimum?
And further simply that by implementing `Display` for `HdbReturnValue` and `HdbResponse`. 
Ah, I just put in a request for all 4! The main reason I wanted to add RHEL is that in the link I shared about the rust-toolset beta, it wasn't immediately clear to folks that I was directly connected. Fedora can be a lot of people from that community, but I am specifically from Red Hat too.
I see I have chosen well.
&gt; it feels like a democratization of social knowledge I like that take on it!
It is done!
/u/mgattozzi quick! Publish a `flair` crate and make it real!
&gt; While the RLS is in preview, it will will use a 0.x.y versioning scheme, where 'x' corresponds to the Rust version. So the first version of the RLS distributed with Rust 1.21.0 will be 0.121.0. This is an interesting snag in semver that I've been thinking about for a while now. The use case that I had in mind was actually about decoupling the version number of the language from the version number of the compiler; in other words, being able to imagine breaking changes to certain rustc APIs (e.g. the command line interface) while maintaining the backwards-compatibility of the language itself. This will matter more when there exist alternative Rust compilers, and, hopefully someday, an official Rust specification document. And in the meantime, not only do we have to couple rustc's version number to Rust's version number, but now we've got tooling (RLS soon, perhaps Cargo eventually, etc.) that will be coupled to rustc's version number. There is actually a potential solution already in semver that we could leverage for this use: the optional build metadata field, denoted by a `+` following the patch number. Using this, RLS could increment the minor version as usual (instead of the plan in the OP, where version 1.199.0 will be followed by 1.1100.0), and it would look like "1.0.0+rustc-1d21d0" (the build metadata field only accepts alphanum and hyphen, so I'm using "d" for dots). Hacky, but perhaps less of a hack, and might scale better if rustc itself ever does manage to decouple its version number.
I love rustic banter. The amount of mutual respect and humor in here is way better than *other* programming languages. Keep on rusting.
You'd use `item` instead of `&amp;item`, and then you'd use the reference.
Does reddit have this sort of "hat" ability at all? I've seen that moderators can choose whether to speak in that role, but that's it.
Only moderators and admins have the ability, yeah.
It is sort of both. I have to do some Commoncrawl processing at work (where batch processing using map reduce from Hadoop fits very well). But using anything related to JVM just makes me angry, so I am looking for other options. And also there are lots of good libraries, which are not present in JVM enviroment. If it was only work task, I would just harden the fuck up and go with JVM tools. But I see this also as an opportunity to learn something, so I am asking for pointers, how to implement quite simple distributed job. And I want to avoid reinventing the wheel as much as possible (so I definitely want to reuse file systems, resource management, etc.). So basically the question is: What is the simplest way to write distributed map reduce in Rust?
The next logical step is a demangler for the semver metadata.
Oh no another side project that I want to make now.
It's everything I could ever want
I wasn't so brave, yet, but at least WebM is supported ;)
&gt; Creating a string, which is one of the most common operations you do in any language, requires 14 extra characters? Creating an owned string directly from a `&amp;'static str` literal is actually not that common. It's needed here because the HashMap wants to own the `String`.. You could instead write it like: let mut scores : HashMap&lt;String, usize&gt; = HashMap::new(); scores.insert("Blue".into(), 10); scores.insert("Yellow".into(), 50); But that requires specifying the type of the `HashMap`. You could also use a `HashMap&lt;&amp;'static str, usize&gt;` but while that would make the example very clean and short it wouldn't work very well for anything *but* the example.
Ah, see. I know RBE only from back then when it didn't have that :D
Not sure if WindowsBunny or maintainers of rust-fuzz should get a f҉͏̡u̴̡zź̶̛y͘ flair
First example, yes, this is necessary. `String` and `str` _are strictly different types_ and you have to treat them as such. However, you can simplify this slightly by taking advantage of the trait impl for String, `impl&lt;'a&gt; From&lt;&amp;'a str&gt; for String`, and `impl&lt;T, U&gt; Into&lt;U&gt; for T where U: From&lt;T&gt;` (you are already using the former impl) let mut scores: HashMap&lt;String, isize&gt; = HashMap::new(); scores.insert("Blue".into(), 10); scores.insert("Yellow.into(), 50); This is stressing the point, though: you have a `HashMap&lt;String, isize&gt;`, not `HashMap&lt;&amp;'static str, isize&gt;`. You would have to define a lifetime bound if you wanted to store `&amp;str` and all of the keys would have to be bounded by the same lifetime. Hardly ideal, because this usually means all your keys have to be bound on the special `'static` lifetime. For the second one, there's a lot going on here. Your version of the code is not possible because Rust (very purposefully) does not allow function overloading. What is `zip` supposed to mean here? You might want to zip into a `Vec&lt;(A, B)&gt;`, you might want to zip into a `HashMap&lt;A, B&gt;`, or maybe you have a custom data structure you want to zip into. The Iterator and FromIterator traits allow the `collect` pattern so the functions you want to use are encoded in the types and their associated methods rather than overloading the meaning at each type impl block. If you wanted the way you provided, the std library would need to have `zip_into_N` where N is every data structure that could conceivably be desired here.
I very agree! I can't count the number of times I've been posting here and not known a particular user was associated with a particular project. I find it very helpful.
Yes. Rust is, in contrast to Clojure and Haskell, a language that cares about very tight control. Let's talk about `String` first. Rust has 2 main types of "bunch of characters"-representations. One is the immutable `&amp;str` (often called "string slice"), the other is the _heap-allocated, mutable_ `String`. It's not quite true that no other languages have that distinction, just the lingo might be different. If it helps, these types are often compared to `String` and `StringBuffer` in Java, the first one being immutable, the other also a bit verbose and to be explicitely set up :). That brings me to the _why_ of `String::from(...)`: it represents a heap allocation and as such should be visible in Rust. There are no literals in Rust that directly force a value on the heap, strings are no exception, so this needs to happen. Indeed, from Rusts level of working, Strings are _not simple, nor fundamental_. We tend to use them in tutorials through, as heap allocated data is easier to work with in the beginning. There is a shorter way to writing this, which is `"some string".into()`, which uses type inference to figure out that a `String` is necessary here, but that is avoided in beginner tutorials, as it requires understanding from a few chapters later. It's rarely a concern in actual code though, when do you ever allocate a whole vector of strings by hand? Coming to iterators: there's three classes of iterators in Rust - non-mutating (`iter`), mutating (`iter_mut`) and consuming (`iter`). On top of that, they are external. The compiler can't easily tell how you want to iterate, so one explicit call to `.iter()` is necessary. In this case, one of the `.iter()` calls can be safely dropped. let scores: HashMap&lt;_, _&gt; = teams.iter().zip(initial_scores).collect(); (`zip` knows about the chosen iteration already and can do the conversion itself). The `collect` call is necessary as something needs to kick the iteration off - Rust Iterators are lazy. Other options would the `for` loop or just calling `.next()` many times ;). Clojure and Haskell are problematic in comparison there: Clojure does, AFAIK, not do lazy iteration and Haskell, on the other side, is all built around resolving lazy statements automatically. By the way, your second example is not the same as the previous. Finally, I have to say that Rust is a language built for larger pieces of software, and tiny examples are rarely pretty. Rust can often be very on-point, if still detailled, for example in this piece of HTTP server code: https://gist.github.com/mjohnsullivan/e5182707caf0a9dbdf2d#file-http_server-rs-L33-L49
Oh, I thought `zip` was more standard than that. In all the languages I've used it always takes two arrays and zips them together into a hash map. Does not the pareto case of sensible defaults apply here? That is, if this the intended behavior &gt;80% of the time, maybe there should be support? I guess it's not an easy answer. Also, maybe having some sort of syntax or special function for making these kinds of strings so they don't clutter up the code?
&gt; core transformation logic is obscured by all these calls to `iter` and `collect`? Thing is `.zip` directly on the collection could do 9 different things (or more): - `a.iter().zip(b.iter())`: The one used here and the most common. - `a.iter_mut().zip(b.iter_mut())`: Useful if we're modifying each collection based on the other one. - `a.into_iter().zip(b.into_iter())`: Consumes the collections and moves their contents. Much more efficient (and arguably the one this example should have used). - Every mix of the 3 above.
I've only ever seen it with mods as well. It could probably be done with some sort of subreddit styling, but that'd probably be prone to breaking. Unfortunately, I don't think it'd be useful enough for reddit as a whole to be implemented as a global feature.
Oh, this changes things. Hmm...
&gt; In all the languages I've used it always takes two arrays and zips them together into a hash map. That is definitely not a "standard" meaning of `zip`. E.g. in Python 3, you get an iterator of `(A, B)` tuples. In Python 2 and Haskell, a list of such tuples. Ruby seems to do a similar thing as a method on arrays.
Oh, I guess you'd need separate functions then.
I would like some `flair` to go with my `BANNED`
&gt; Once type checking can reliably be done incrementally, we can take advantage of that in the RLS to give much quicker responses. We should then be able to use the compiler for code completion, Aha! Good to know, I'd been wondering what the plan was to move off of Racer.
Isn't WebM rather a container format?
As soon as you enter the match arm you are acquiring ownership if you don't mark all non-copy fields as `ref`. https://play.rust-lang.org/
Let us look at a simpler case that produces the same error: struct Foo { bar: String } fn baz(foo: &amp;Foo) { let bar = foo.bar; } fn main() { let mut foo = Foo { bar: String::new() }; baz(&amp;foo); foo.bar.push('x'); } To understand why this doesn't work, let's move the body of `baz` into `main`: fn main() { let mut foo = Foo { bar: String::new() }; let bar = foo.bar; foo.bar.push('x'); } Why this fails should be obvious - since we **move**d `foo.bar` into `bar`, we can no longer use `foo.bar`. In the original version of `main`, we did not move `foo.bar` - we only **borrow*ed it into `baz`. This is why we could use `foo.bar` later. But if we could move `bar` out of `foo` inside `baz`, it would have violated `baz`'s caller's right to use `foo.bar` later. That's why why you can't move fields out of borrowed structs and you have to use `ref`.
If I have a vector of function pointers, say let v: Vec&lt;fn() -&gt; ()&gt; = Vec::new() How would I compare equality to the pointers in the vector, for example when testing, fn test_function() {} let v: Vec&lt;fn() -&gt; ()&gt; = vec![test_function]; assert!(v.get(0).unwrap() == &amp;test_function); Throws a big error saying that it can't compare during compile time. Any help would be greatly appreciated, thanks!
&gt;Functional transformations are so common, and, coming from the land of Clojure/Haskell, I'm wondering why or if all these superfluity is necessary. I have a background in Haskell as well and Rust really doesn't get any "better" in terms of code reuse or prolixity. Haskell is unusual in that it's much more expressive and concise than most languages. Rust is a "modern" language and you get a lot of the things that come with that (folds, maps, sum types) but at the end of the day it's an imperative language which emphasizes zero-cost abstractions. &gt;Creating a string, which is one of the most common operations you do in any language, requires 14 extra characters? Does all this visual noise not bother anyone else? I'd use "Blue".to_string() in that case. &gt;Does anyone else think it makes the code much harder to follow/parse at a glance when the core transformation logic is obscured by all these calls to iter and collect Readability is mostly a function of familiarity. It's distinctly less elegant here but you have to understand that vectors in Rust aren't the same thing as linked lists in Haskell.
I think WebM is Matroska contaning VP8 video and Vorbis audio, or VP9 video and Opus audio.
A smart person who read and understand that specification
Well list and iterators are pretty much the same in Haskell anyway
It can't coerce for some reason, but `== &amp;(test_function as fn()-&gt;())` works. (In fact even `as _` seems to be enough but I wouldn't rely on that.)
Oh shit , i mess it up ^_^
Randomly choosing between left and right could just be: use rand::Rng; ... let mut rng = rand::thread_rng(); if rng.gen() { // ... } else { // ... } `rng.gen()` there generates a `bool` thanks to the type inference. You can rewrite the entire `add` logic into a `match`: fn add(&amp;mut self, x: i64) { match (&amp;mut self.left, &amp;mut self.right) { (child @ &amp;mut None, _) | (_, child @ &amp;mut None) =&gt; { *child = Some(Box::new(Node::new(x))); } (&amp;mut Some(ref mut left), &amp;mut Some(ref mut right)) =&gt; { let mut rng = rand::thread_rng(); if rng.gen() { left.add(x); } else { right.add(x); } } } } 
I mean, if they don't know what a gif is, they probably also don't know what a gif isn't.
`zip` is provided from the Iterator trait as a default method and takes another iterator to produce a new type that impl Iterator&lt;Item=(A, B)&gt; (an iterator of tuples of values from both underlying iterators). Like Streams in Java land or generator functions in Python land, Iterators do nothing until they are consumed (i.e. `collect()`, for each syntax, `next()`). The iterator abstraction means you can consume a concept of a stream of zipped values in any way you want without having to deal with inheritance. The `futures` crate provides a similar trait, `Stream`, that allows asynchronous value creation. In real-world code you will rarely see situations where you have to perform String-str conversions. One reason is that you will rarely work with strings directly in the first place unless you're truly needing a string. The other is that many APIs that _need_ strings will often be generic over `S: AsRef&lt;str&gt;` (allowing both &amp;str and String or even &amp;String to be passed) or return a value like `Cow&lt;str&gt;`; `HashMap` happens to not be that way because it's generic over any key and value type, not just strings.
`.to_owned()` works just as well and is probably more efficient as it bypasses the Formatter machinery.
Newer versions of Rust specialize `.to_string()` on `&amp;str` to bypass the formatting machinery anyway, so it doesn't matter which method you use.
&gt; Coming to iterators: there's three classes of iterators in Rust - non-mutating (iter), mutating (iter_mut) and consuming (iter). I assume one of those is a type for `into_iter`?
AFAIK there has been some discussion about making it a special case to `.unwrap()` result values when using the `?` operator inside `main` so that new developers can get used to it without having to jump through the hoop of defining a separate "inner main." Or something to that note.
For hash maps...Let me just drop this here: https://docs.rs/maplit/1.0.0/maplit/ Yeah. Hashmaps can be less verbose. macros are such a big part of Rust I wish they were pushed a little more to newbies. I also really think this macro should be included with stdlib.
Not that it is a very significant point, but the key following the `~` would be a `&gt;`, which requires shift to type as well
Point. I always make stupid mistakes like that when I'm too tired to realize how compromised I am. (It's one reason I like Rust. It's more likely to yell at me immediately when I make a stupid mistake rather than waiting until I've written a mountain of tests.)
Can I have the "rust-sdl2" flair? Thanks!
That last one is the `into_iter`. It's pretty straighforward to remember, say you have a Vec, you want to transform it *into* an interator, discarding the Vec altogether.
A neat way that takes advantage of type inference, inspired by [https://github.com/tomaka/hlua](hlua): if let Ok(scalar) = value.parse() { return S(scalar); } if let Ok(scalar) = value.parse() { return I(scalar); } if let Ok(scalar) = value.parse() { return F(scalar); } if let Ok(scalar) = value.parse() { return B(scalar); } Since you're putting the resulting value into the appropriate enum variant, the compiler knows which variant of `parse` to call. Of course, for your last one, you might like to save the `Err` value so you can return it instead of having to make your own.
It can be arranged!
In programming there are many things that can be done in a cheap-but-risky way or in an expensive-but-safe way. Different languages may have different policies about these tradeoffs. Haskell and Clojure, that you have mentioned, have chosen to solve this with managed memory(GC) and immutable type systems(there is mutability, but it is provided by the standard library - not as a language feature). These properties have their own problem, but they do tend to solve this tradeoff problem. Your `zip`, example, for example - what happens to the sources?
smh at people who don't even know the difference between MUST and SHOULD as defined in [RFC 2119](http://www.faqs.org/rfcs/rfc2119.html)
To add on to this: the `ref` pattern syntax would IMO have been better as `*`. Since pattern matching syntax is otherwise always the same as construction syntax, you'd get this: // construct an S from an i32, then de-construct it back to an i32 let x = 5; match S(x) { S(y) =&gt; ... } // "construct" an &amp;i32 from an i32, then "de-construct" it back to an i32 let x = 5; match &amp;x { &amp;y =&gt; ... } // go the other way: "construct" an i32 from an &amp;i32, then "de-construct" it back to an &amp;i32 let r = &amp;5; match *r { *y =&gt; ... } This was decided against because a mutable binding would look like `*mut y`, which looks just like a raw pointer *type*. :( To add on further: the [match ergonomics RFC](https://github.com/rust-lang/rfcs/pull/2005) will let you ditch the whole mess and just write this: fn tree_weight_v2(t: &amp;BinaryTree) -&gt; i32 { match t { BinaryTree::Leaf(payload) =&gt; payload, BinaryTree::Node(left, payload, right) =&gt; { tree_weight_v2(left) + payload + tree_weight_v2(right) } } } And then because you're trying to match a `BinaryTree::Node` against a `&amp;BinaryTree`, the members will automatically be bound by-reference.
&gt; Rust is a language built for larger pieces of software, and tiny examples are rarely pretty ^ This! If Rust was so patronizing that it made all those choices for you that would make your example work, it would be more like Haskell and it would leave (language design) space between Rust and asm. And then people would complain that Strings can only be on the heap and would design a language where that isn't the case... So Rust has it's raison d'être. Rust is the language that tries to leave no language design space between it and asm while being as high-level and ergonomic as possible, so that it works for systems programming as well as all other kinds of applications.
Just serialize a VOMIT^\[1] to JSON, lzma compress it, encode in base64, and append that to the version number. Obviously much simpler and more flexible. \[1]: "Version Object Model In Transit". *Obviously*.
I've created a tool called Rerast. It runs as a cargo plugin ("cargo rerast") and lets you transform rust code with search/replace rules. Rules are matched based on their syntax trees being equivalent, not based on textual matching. Rules can contain placeholders, which are typed, possibly with generic bounds. Suppose you had an API that was deprecated and used throughout your code. For example Customer::new("Alice".to_owned()) and you wanted to transform that into Customer::builder().name("Alice").build() - you could do that with rules like the following: fn rule1(name: String, name_str: &amp;str) { replace!( Customer::new(name_str.to_owned()) =&gt; Customer::builder().name(name_str).build()); replace!( Customer::new(name) =&gt; Customer::builder().name(&amp;name).build()); } Here we've got two rules. The first rule that matches wins. So if Customer::new is passed an &amp;str with to_owned() called on it, the first rule will match. Otherwise the second rule will pick up an actual String being passed. Eventually the plan is to have Rerast search the crates your crate depends on for rules that should be applied to your code. This would allow automatic migration off deprecated APIs - at least in cases where there's a straightforward transformation that can be applied from the old API to the new one. Feel free to file bugs / feature requests or let me know if you have any feedback. Help also welcome. 
This is one of the few subs where I find user flairs genuinely useful. Quite often, contextualising posters' backgrounds adds an extra dimension to their comments.
Hopefully I can get a response fairly quickly. I'm having issues compiling a project for class involving Diesel and Rocket. The error I'm getting currently pertains to Diesel: ``` error[E0252]: the name `conference` is defined multiple times --&gt; src/sports_ball/database/schema.rs:1:1 | 1 | infer_schema!("dotenv:DATABASE_URL"); | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ | | | `conference` reimported here | previous import of the type `conference` here | = note: `conference` must be defined only once in the type namespace of this module = note: this error originates in a macro outside of the current crate ``` This doesn't make much sense to me at all. It looks like it's defining where the previous import of `conference` is, but there's nothing there, leading me to believe that it's imported twice in the same schema? How the hell do I fix this?
This is the subreddit for the rust programming language. You're looking for /r/playrust
Or just wait for rust the language to become quite stable, and have a complete specification besides the compiler. Then you can have different version numbers for the language and compiler, like most other programming languages in existence. And until that occurs I'm not sure there's much purpose in differentiating them.
This is making me wonder if this is a first step into supporting IDE refactoring.
if you're comparing to garbage collected languages (clojure/haskell): it does matter more what type of string it is (how it's allocated, whats the lifetime/ownership). Here there's a tradeoff between performance (size and speed) vs convenience. (and of course compared to C++, safety comes into that set of tradeoffs)
For simple static mappings a match statement should usually be faster than a hashmap anyway.
I thought the course focus is teaching new concepts (eg. rust memory managament == uniqueness, ocaml memory management == immutability). Purity fits this very well imho. 
Great work! I hope this opens the door for fixing Rust's syntactic design mistakes (in epochs). Like the fact that `A: B` means both "type A implements trait B" and "variable A has type B", which make syntax additions increasingly awkward, e.g. for const generics and especially for higher-kinded types outside of traits. This tool would make it easy to migrate to the new syntax/epoch. 
The Java community is [here](reddit.com/r/java)! *(I just couldn't resist)*
I wish someone did a binary ABI of the language server protocol so that you could create a lib that could be linked in to the editor. Alternative nr 2 would be to use grpc that is way faster and eccicient than jsonrpc. 
I taught [a Rust lecture in Osnabrück](https://github.com/LukasKalbertodt/programmieren-in-rust), but sadly, this is not a regular thing. I hope to be able to teach it once more, but I don't expect more than that. Luckily, the lecture is fully documented and recorded (see link above), so you can watch it at home. Not as good as listening to it live, but still ;-)
Yes! Consuming is `into_iter`. Thanks for catching.
Hi! This looks like a very interesting job offering! Is this about this one? https://www.etsy.com/careers/job/b16e8919-ac93-4243-927f-201f06208ba5
Can rustup update have an option to update to the next nightly that has a working rls, clippy and rustfmt?? Our ci breaks on nightly every time rustfmt and clippy cannot be built... it's not tragic but one can't trust red or green builds at all.
Heh... what?! Please *do* explain! Why is a return allowed in places like this?
One of the papers is about formalizing guarantees for unsafe code in Rust: [RustBelt: Securing the Foundations of the Rust Programming Language](http://www.mpi-sws.org/~dreyer/papers/rustbelt/paper.pdf) Ralf Jung, Jacques-Henri Jourdan, Robbert Krebbers, Derek Dreyer 
Oh well, while we are at it, could my flair be changed to `wayland-rs · smithay` ?
i.e., using `.collect()` at the end in Rust is similar to doing `list(zip(...))` in Python 3.
Looks cool! I'm not gonna be helping, but I love the "Generic Notice: This is an unstable project yadda yadda yadda use it if you dare thanks" portion! Giggled a bit :D 
Oh Thanks. I have been trying to do this in the past, I had no idea I should dereference item 
From the article (emphasis mine): &gt; If you want to keep using the RLS you will need to either stick to a nightly release which includes the RLS (either by avoiding `rustup update` or by updating to a [specific nightly](https://github.com/rust-lang-nursery/rls-vscode/issues/181#issue-269383659) which includes the RLS), or use the stable or beta channels. **We realise this is sub-optimal for nightly users and we plan to mitigate this somewhat with UI improvements to rustup.**
IMHO `.to_owned()` is much clearer though. `.to_string()` to me reads like convertion non-textual data to its text form. When it's already a `&amp;str`, what you're doing is not that, but simply making a copy of the already textual data to get exclusive ownership.
Only use an owned type if you *need* to. A borrowed type will generally be more useful in terms of accepting values from more source types. Note that, in the example you gave, there's no benefit to using owned types. No matter *what* the input is, you're constructing new values. All using `String` and `Vec` would have done is bloat your memory usage for no gain.
You use references when you dont need ownership, not when you need immutability. That’s their different uses, String is used when you own the value, &amp;str is used when you just need to borrow it. There’s also &amp;’static str but I’m not sure if it is relevant.
It's also worth mentioning that if you specify the actual type of the HashMap (required in languages like Java), you can shorten/simplify the code: let mut scores: HashMap&lt;String, i32&gt; = HashMap::new(); scores.insert("Blue".into(), 10); scores.insert("Yellow".into(), 50);
So it's correct of me to have a `Vec&lt;String&gt;` as the output, too?
Yes, because it *can't* be borrowed, since it's constructed inside your function.
I guess that makes sense
An owned fixed-size array is still ok, right? Stack allocated and all that?
If you *need* the locality, or you *need* to minimise heap activity, or you *need* to restrict the number of elements, sure. Using borrows is about letting other code give you access to the storage they already have, which will almost always be faster than having to allocate and/or copy new storage.
/u/arielby I am sold.
How do you become a guest lecturer in Germany (if you don't mind asking) ?
Huh! I thought arrays would be slightly cheaper because they didn't need to create a reference. Guess I've been fooling myself :P
Nothing's that simple. It depends on how big they are, how they're accessed, how often you need to copy them, how big the rest of the data you're accessing is, what platform you're on...
`()` is a type that has one value. So this means that error can happen, but you don't get any more information than that, because `()` doesn't carry any information. It would be equivalent to use a new unit struct, and the error type would have a proper name: struct ReceiverError; impl&lt;T&gt; Stream for Receiver&lt;T&gt; { type Error = ReceiverError; ... }
I've seen `()` used for both purposes. If errors are impossible, it should be using an uninhabited (*a.k.a.* void) type.
The professor got in touch. It's a pro-bono thing, they are just spicing up the course. So, to be clear: I give one of the lessons, they are giving the whole lecture.
Let's take an example: - Really big - Never copied or consumed, only borrowed What would you recommend here?
Rust is a system programming language. Clojure and Haskell have different applicability. System programming is usually done in Assembly, C or C++, and in such languages (well, at least in projects started before 2011), functional transformations are rare. `&amp;'static str` and `String` are different types, corresponding respectively to `const char[]` and to `std::string` in C++. String literals have type `&amp;'static str`. Maybe you suggest to add a syntax clause for `String` literals, but there is not such strong need. A shorter way to convert a `&amp;str` into a `String` is this: scores.insert(format!("Blue"), 10); scores.insert(format!("Yellow"), 50); Regarding iterators, the standard `zip` method is thought to work with iterators, not with collections. The `iter` method creates an iterator from a collection, and the `collect` method creates a collection from an iterator. The `Vec` generic type has no `zip` method, and you cannot add it, but you can write a `zip` function: use std::collections::HashMap; fn zip&lt;T1, T2&gt;(first: Vec&lt;T1&gt;, second: Vec&lt;T2&gt;) -&gt; HashMap&lt;T1, T2&gt; where T1: Eq + std::hash::Hash, { first.into_iter().zip(second.into_iter()).collect() } let teams = vec!["Blue", "Yellow"]; let initial_scores = vec![10, 50]; let scores = zip(teams, initial_scores); 
Pick something, and if you suspect it's a performance bottleneck, profile. Modern CPUs and compilers make a complete mockery of the idea that you can just pick an efficient design apropos of nothing. Never mind the fact that in Rust this choice *also* depends on how you've structured the code. Sometimes I've used borrows, sometimes I've used owned types, sometimes I've used hybrid types. In one case, I built a tri-state borrowed/heap owned/inline owned type because I was being pathological. I'm sorry, but there isn't an easy answer here. But for those who insist on having an easy answer: "use a borrow unless you can't". Hence my answer. :P
Ask yourself does `Generator` need to *own* consonants and syllables? There are two reasons for it to do so: * Does it ever need to change them? * Does a `Generator` object stand on its own? For example, can it be returned from a function and be expected to work outside of the immediate environment where it (and the consonant/vowel data) was created? If one or both of the above are true, you probably want `Generator` to own the data.
On the other hand, a borrowed type will be much harder to pass around by value. Storing a value (in this case an owned version of vowels/consonants) and a reference to the same value (the `Generator`) in the same struct [is notoriously difficult](https://stackoverflow.com/q/32300132/1600898).
If the design requires a borrow structure you can't reasonably encode, or that is prohibitively difficult to work with, that counts as needing an owned type.
I think it depends on how you are using the output. If you wanted, you could go further and define a new type for a syllable:- struct Syllable&lt;'a&gt; { consonant: &amp;'a str, vowel: &amp;'a str, } and then return `Vec&lt;Syllable&lt;'a&gt;&gt;` instead of `Vec&lt;String&gt;`. You might then want to implement `Display` for your syllables so you can `syllable.to_string()` if you need a `String`. This should further improve your type safety and reduce your memory footprint but whether it's worth it or not depends on what your program is doing with those syllables and how far you are willing to go. Also if `make_syllables` was public, I think it would be nicer to return `Vec&lt;Syllable&lt;'a&gt;&gt;`.
That would be awesome. This and integrated code coverage in cargo are The only things that block us from using Rust in high-reliability applications.
Using a borrowed type is an optimization. I think it's perfectly fine to start working with just owned types until you can see and spot those places where you only need scope-delimited or temporary read or read-write access, and uses slices or references for that.
The diesel gitter is pretty solid, usually, you may want to ask there too.
&gt; like most other programming languages in existence I'm not sure this is true.
To me it's the opposite. `to_string` says exactly what you want: to get a `String`. `to_owned` only belongs in generic code.
I'll experiment with both and see what feels best, thanks!
Rust prefers not to have "default" behaviors for ambiguous code. When something could be ambiguous, you write out explicitly what you want to do, instead of hoping that it does the right thing (zipping into a HashMap is not standard in a most languages, for example sometimes zipping produces a list of tuples, sometimes an Iterator of tuples, etc...). The Pareto principle would not apply to your String question either anyway. Creating an owned String from a `&amp;'static str` (a statically defined string literal) is uncommon, and thus doesn't need to be optimized for at the expense of other more common practices.
the reason array3d[x][y][z] is not popular is because you would have to expose 3 sub types ( row , collumns , depth?) and impl index for each of them. (because array3d[x] and array3d[x][y] would also be a valid expression ) 
it appears to be statically typed and it has generics, that's impressive!
Hey there! I also have the makings of a rust api library on my PC, but have only really gotten as far as to implementing auth and some simple endpoints without regard to api limits so far. As far as I know reddit sends back headers with each api request with information about rate limits, and my plan was using that almost entirely to do the rate limiting, as it has the added benefit of being able to run multiple instances of your api lib concurrently om the same account and you can be certain you'll never exceed the limits if you obey the headers reddit sends back, which is something that will be pretty much impossible if you were keeping track yourself. I haven't had a chance to look at your code, so maybe this is how you did it, but I'll try have a look if I get a chance. Good job! The other rust reddit api libs seem to be dated and unmaintained as far as I can tell 
Will this support emacs?
Emacs already supports this: https://github.com/emacs-lsp/lsp-mode
Uneducated guess from my side: Return itself is an expression, therefor its syntactically legal in these positions. The type error doesn't occur, because the return changes the control flow, making the while loop dead code, so it never gets to typecheck because its not generated? That's at least what godbolt says, even in debug mode: https://godbolt.org/g/3tZPqb
&gt; appears to be statically typed I've been working with statically typed languages so much that I didn't even think to mention that it is statically typed :D While it does have generics (and type inference!), currently it doesn't have anything similar to traits. Implementing them would make the language a lot more powerful (and a lot more similar to Rust), but I'm a bit scared to try to implement that.
How do you manage memory in plank?
This looks great, good job! Any thoughts on implementing this for rustc's MIR? I can think of some awesome uses for this for when MIRI/HolyJIT are ready for the real world, especially if you could combine higher level and lower level transformations operating first on input Rust syntax and then on the resulting MIR. 
Hm... I think I usually want the behaviour changed to another owned type though, e.g. when refactoring a function that operates on paths you get from a config file from `&amp;str` to `&amp;Path`, because you only just discovered that serde can deserialize `Path`[`Buf`]s.
`Result&lt;T, ()&gt;` is equivalent to `Option&lt;T&gt;`, just with a different API.
`array3d[x][y][z]` is automatic when you make an array of arrays (of arrays). 
Currently it is only possible to place stuff on the stack (imagine C without globals and `malloc`). I didn't try to include a memory allocator yet because it is not in the requirements of the course. A dynamic memory allocator written in pure plank is currently impossible (or at least pretty painful), because plank does not have global variables. Fixed size arrays and global variables would improve the situation a bit without going straight to dynamic allocation, but I am reluctant to implement them because then I feel like then I would also need const generics.
Unrelated: There are a lot of repeated prefixes and suffixes. Consider leveraging the module system for ergonomics. Suggestions * `HdbError -&gt; hdb::Error` * `HdbError::IoError` -&gt; `hdb::Error::Io` * `HdbResponse -&gt; hdb::Response`
It could!
[removed]
I'm fine with including patched builds of wine, etc. as long as the patches are documented, or have been submitted upstream, or are backports -- we already do something like that for a few Android targets. I'm concerned about redistributing Windows binaries in the Docker images though. IANAL but does the MSVC EULA, or w/e it's called, allows for redistribution of the linker and the MSVC libraries where you skip explicitng agreeing to the EULA? If there's no legal issue then fill free to send a PR or open an issue in the Cross repo. Great work, by the way :+1:
Thanks! :)
Do you also envision his being used for AoP?
That it is. It's for a position on my team so there are more details I can share :)
This looks really cool. If it were able to match macros pre-expansion, I could maybe have used it for [this project](https://github.com/rust-lang-nursery/rust-clippy/pull/2154).
So could you use this to perform high level optimizations? Detecting certain code patterns, and replacing them with more optimal, equivalent patterns?
Close, though it's not that typeck skips dead code. Instead `return` has type `!`, which unifies with anything, because it will never actually be used, so typeck succeeds.
I'd recommend using Diesel instead of rust-postrgres directly. Better performance, and your queries are type-checked at compile time.
&gt; as long as the patches are documented, or have been submitted upstream, or are backports The patch has been submitted upstream, and soon (few weeks) I hope it will be included into wine. Then it will live in the "backports" category. &gt; I'm concerned about redistributing Windows binaries in the Docker images though. IANAL but does the MSVC EULA, or w/e it's called, allows for redistribution of the linker and the MSVC libraries where you skip explicitng agreeing to the EULA? Maybe we can let the docker image download the binaries? Then we could avoid that issue.
Uninhabited type exists in Nightly as `!`. It can be used to indicate that a function can't fail: ``` #![feature(never_type)] fn cant_fail(x: i32) -&gt; Result&lt;i32, !&gt; { Ok(x+5) } ``` Most of the time, it is better to return `i32` in this case.
This is really impressive work. Could it possibly be embedded in an application as a scripting language, for example in a game?
Oh geez thanks for the note about Reddit's own ratelimiting info, that would be so much easier and better to implement. It would also let me run the tests concurrently (I've been using `--test-threads=1`).
Okay, most other really important ones, I guess. C, C++, Java, Lisp, Lua, C#, Scheme, Javascript, Haskell... Notable exceptions, where the reference implementation is basically the spec: Python, Ruby(?), Rust, Erlang, Clojure(?), D, Go, F#... This is kinda fun to think about. Which ones am I missing? There's sorta in-between cases as well, like Python and Lua where a reference implementation and a specification have the same version number. But it's still entirely possible for third party implementations to target, say, Python 3.4 or Lua 5.2 and have that be meaningful (and there ARE such implementations). To the best of my knowledge, nobody's going to be writing a compiler targeting "Rust 1.19" for a while because there's no guarantees that the Reference is complete, and certainly isn't versioned in such a fine-grain manner. This is actually an interesting question in Rust's future; at what point are people going to say "version X is basically the de-facto oldest version worth targeting"? Anyway, it's not happening this year! Probably not next year either. Maybe 2020!
&gt; Maybe we can let the docker image download the binaries? Then we could avoid that issue. Yep, that's an option. We are considering doing something like that for the android emulators (right now we are using QEMU to test the android targets but we can't test anything android runtime related with that setup) but we haven't looked into it yet.
I believe you can do it using [cpython](https://github.com/dgrunwald/rust-cpython) crate, plus [numpy](https://github.com/termoshtt/rust-numpy) crate for more convenient handling of numpy arrays.
Looking at the code in this case it's used to indicate that it never returns error. Ideally we should have `never-type` (`!`) here, but it's still on nightly. I've never seen `()` to be used as a real error type and I think it should be strongly discouraged as a bad practice.
Indeed it makes life easier because as long as you obey the headers you should be fine, also it sorta makes sense in my mind to do it that way because clients won't necessarily have knowledge of other clients, but the reddit servers will always have knowledge of all of the clients and is also the enforcer of the rate limits, so it just makes sense for them to help us not violate those limits. It wasn't always like this, and praw had some interesting solutions to allow someone to make multiple reddit objects for different threads (I think they spawned another process that handled all of the actual requests, so there was a big warning on the docs that you couldn't have two instances of praw running on different machines or what not because there was just no way for them to do rate limits that way). So with them deciding to include headers for us they vastly simplified the client side bit. Also I believe that the rate limits for oauth authenticated accounts (well this is now mandatory, wasn't always) is 60 Requests per minute, double from what it was way back. If you have questions about reddit api I know a thing or two that I picked up by myself over the years that just wasn't available in any docs which are in a bit of a bad state, so feel free to ask / pm me if you have questions, if there's a small chance I could help I'd be happy sharing my knowledge 
It's a low level language and was not built for such purpose, so I think it would not be worth it. But I also am working on a language that is intended to be eventually used as a scripting language in a game engine, you can find it here: https://github.com/jDomantas/interpreter. However, its interpreter is very much work in progress, I will announce it properly once it is good enough to be usable.
When I've wanted to do ML in rust I've found that simply writing an entirely separate service/ codebase in Python, exposing an HTTP API, and hitting it from Rust is the simplest way to go. The rust code is clean, the python code is clean, and you can follow standard patterns for client/ servers without worrying about mixing up your language patterns.
I just noticed it is somewhat similar to the image I use on AreWeLearningYet: http://www.arewelearningyet.com/images/rust-9000.png
There has been some discussion of this [on the issue tracker](https://github.com/rust-lang/rust/issues/39575).
Just a small correction: just like Rust's, Clojure sequence operations *are* lazy and if you want to "materialize" a lazy seq you need to call the appropriate constructor such as `vec`. Doing that is rarely necessary though as typically sequences are operated in a fire-and-forget manner.
&gt; The libs team discussed this a few weeks ago at the last triage and the conclusion was that we'd prefer to see concrete evidence (e.g. a proof-of-concept) showing the memory unsafety here. At that point we'll consider remediations but for now we're fine just adding some documentation that "care should be taken" This is kind of bad... I in the other thread suggested a possibility of an `AsyncSafe` marker trait that gets inherited by closures similarly if all their calls are `AsyncSafe`
i think its hal
Thanks for the suggestion. I checked out the documentation and eliminating runtime errors by checking at compile time seems interesting. Although ORMs have some nice features, for me in general, ORM gets in the way and I feel more at home with raw sql queries, specially that I'm not writing heavey-duty database code and it seems overkill for my simple queries. Furthermore, I sometimes mix relational databases with documents (json/jsonb) in PostgreSQL which I believe won't be achievable using an ORM.
Can it generate [LSP text edits] (https://github.com/Microsoft/language-server-protocol/blob/master/protocol.md#textedit)?
Agreed. It's better to return a `&amp;'static str` that describes the error - the only extra effort is having to write that description, which is certainly an effort one should make!
Ruby has a standard but it's based on an *extremely* old version of Ruby that was old when the standard was written; nobody uses the standard. &gt; This is kinda fun to think about. Agreed! I think where you come from really colors your perception on if this normal or not. &gt; at what point are people going to say "version X is basically the de-facto oldest version worth targeting"? I assume that our LTS strategy, whenever it happens, will play heavily into this.
I'm guessing the problem with macros like those is that they expand to different code every time, since they presumably include file name and line number in the expansion. Macros like try! can be matched OK. It might be possible to make it look for the expansion of the macros that output file and line number and make them match each other even though they expand to different expressions. For an overview of how it works see the comment at the start of [lib.rs](https://github.com/google/rerast/blob/master/src/lib.rs)
I actually disagree that a borrowed type will generally be more useful. You're forcing your caller to own the values. Sometimes this is fine, but often it just makes it difficult to wrap that value. There's maybe an argument that `Cow&lt;'a, T&gt;` is more generally useful than `T` (ignoring the fact that it forces a lifetime to enter the picture), but honestly saying any of these are "better" in the general case is just bad advice.
It can't at the moment, but it looks like it would be pretty easy to generate. I'd be very interested in RLS integration at some point. I'm guessing the RLS team is probably busy working towards 1.0 at them moment and this is perhaps a post 1.0 kind of feature
My instinct is that such optimisations would be best performed at the MIR level in the compiler.
&gt; Strings are *not simple, nor fundamental.* I think this is a lot of the real takeaway. The more you know about strings the more you realize that there is an incredible amount of inherent complexity there. Most languages try to hide the complexity so they can Just Work^^TM about 95% of the time. Rust does not 
Thanks for posting this! I'm in the middle of making my first statically typed language myself, but I lack any formal education. This is a pretty huge resource for me (and I can actually read it)!
How much normalization does this perform? For example, in would your rule for `a + 1` match `::std::ops::Add(a, 1)`?
For some kinds of refactoring I think this could be useful. In particular ones that relate to how specific APIs are used. For others like extract function, I'm not sure it would help. Although I guess perhaps after extracting a function you might be able to use it to look for equivalent code that could also use the new function.
One thing that helped clarify this for me was to understand that `let` always uses patterns, and that `let ref x = y` is the same as `let x = &amp;y`. The main difference in pattern matching is that you can't control what would have gone on the right hand side of a let binding. So you can think about it like this -- pretend that we could actually state that some variable had the type of a single variant. In that case what you'd want to write is: `let left = &amp;t.0`. Because we would have wanted the ampersand on the right side, we will need `ref` in our pattern.
UDP is connectionless. You just create, (maybe bind? I don't remember) and send your message.
You don’t need to own a value to call something that borrows it, do you?
wrong sub
For the "address family not supported by protocol" error, `UdpSocket::bind` takes `A: ToSocketAddrs`, and you are passing `(&amp;str,u16)` which does does dns resolution in its `ToSocketAddrs` implementation, however localhost [will often resolve to ipv6 first](https://play.rust-lang.org/?gist=a1e16a16528ddb0aeabddb7b345ca30c&amp;version=stable), even if the system doesn't support it. The "network unreachable" part of your problem is most likely (judging by the names of your gists) that you are running code on the rust playground which does not allow uploaded code to access the network (as noted at the bottom of the [help page](https://play.rust-lang.org/help))
Something has to own it. If it's not you, it's your caller. 
That language reminds me a lot of [Gluon](https://github.com/gluon-lang/gluon).
I'm not super familiar with AoP, but I'm unsure about using this as part of a build process. You'd lose the original line numbers.
[](/pinkiepoint) /r/playrust
This reminds me of the proposal for `Option::filter`, I could see a Filter trait that does what you want and also applies to Option, Iterator, etc. I believe that there are probably generic (HKT/ATC) constraints that would prevention the same trait applying to both iterators and simpler traits, though.
Yes, we plan to do something like this. I'm not exactly sure what the UI will be, but that is the use case we're targeting.
If hadoop fits well, and this is for work, it is sort of unethical for your coworkers for you to go off and build your own thing that is guaranteed to be worse. The hadoop ecosystem has enormous existing library support. I've seen so many systems that were created out of curiosity but without the will to actually put in the excruciatingly hard work to make the fault tolerance work well in a dynamic work environment. The result is really painful for people, and costs a huge amount of blood sweat and tears to use. The JVM has complexity, but once you learn it you can reuse those skills for a huge amount of other world-class systems. The complexity you impose with your bespoke implementation is far higher, and has zero outside reusability for your teammates or whoever has to pick up this system when you move on.
AFAIK, no, there's no `take_if` in `std`. Seems like you have an implementation all ready to go, though, so you could just publish a crate with your trait and import it as necessary. If this is specifically about `filter_map`, it sounds like what you actually want is [`filter`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.filter). All you need then is code like `your_sequence.iter().filter(|item| item.is_something())`. If what you're actually after is a way to manipulate `Option` and `Result` types, they both offer a [map method](https://doc.rust-lang.org/std/option/enum.Option.html#method.map) to streamline the cases where you inherit some predecessor type, and want to act on it if possible.
[`and_then`](https://doc.rust-lang.org/std/option/enum.Option.html#method.and_then)
They also exist in non-nightly as `enum Foo {}`. The difference is that the nightly Never type implements all traits IIRC.
whops
Well, forks work via copy-on-write, so the moment you try to write something, the fork will have it's own copy of that data that's not shared with the parent. Also applies to Arc'd/Mutex'd data.
There is the [`boolinator` crate](https://crates.io/crates/boolinator). The description is a bit ironic/funny, but I honestly think it's a nice and useful crate. Of course, I'd rather have it in std directly (at least some of the stuff). Anyway, with said crate, you can write: x.is_something().as_some(x) This might still fail to compile, but once we have 2φb and NLLs it should work fine (*I think*),
You're definitely talking about [filter](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.filter).
that's not a bad idea, but the whole point of the program is to spit out whole strings at the end, so I'd have to combine them into a `String` anyway
&gt; with a turbofish I love you.
So to answer that: * No * Maybe So does that mean I should go with `Vec&lt;String&gt;` just to be safe? It's these sorts of semi-vague situations that really confuse me. 
Nice to know! Are you planing to address The code coverage issue any time soon as well? 
Wrong subreddit, you're looking for /r/playrust
Meet the [filters crate](https://github.com/matthiasbeyer/filters), which was written to simplify such predicate definitions!
Nasty bug, try to convince everyone to rewrite Rust in Rust.
Someone always has to own it, but if you ask for a reference your caller can either own it or not. What do you mean by “You are forcing your caller to own the values”?
Afaik `filter_map` is best used when your have code that returns Options. In your case you could just use `filter` alone. About your implementation, I wouldn't name it "take_if", because you're always taking the value even if the predicate is false, because it consumes self. Also you should use FnOnce as the closure type.
The internal memory layout of `Vec` and `String` is private and might change in future standard library versions. You cannot access it directly from C. Similarly for enum types where some variants carry data (a.k.a. "non-C-like enums"), the language explicitly makes they memory layout undefined in order to enable future optimizations like https://github.com/rust-lang/rust/pull/45225. For the former, you should pass around (pointer, length) to represent a slice in a C-compatible way. (And be careful about the life time of things.) For the latter, there is not really a good way at the moment but there’s a proposal: https://github.com/rust-lang/rfcs/pull/2195
We are; but this is really interesting work! It would be great to start experimenting with the kinds of transformations we could do using this via the RLS
"I want to construct an instance of Foo, with a new vec of bar and return it" is now impossible. If you're interested I could give some more concrete examples of why Diesel had to leave rust-postgres much later tonight, but they're basically all variations of that story
What do you mean by code coverage? If you mean missing information for certain tokens, then yes, in fact I've been working on that this week (e.g., https://github.com/rust-lang/rust/pull/45709)
D'accord, thank you, so I will probably have to add another translation layer... So if I want to keep the layout mostly similar to reduce cognitive load, how would would the best way to do this be? If I understand correctly, if I have a struct like ``` enum Car{ Fast(FastCar), Slow(SlowCar) } struct Foo{ bar:Bar, car:Vec&lt;Car&gt; } ``` I will need to map it to something like this (writing pseudo-C) ``` struct C_SlowCar{ ... } struct C_FastCar{ ... } /*on the c side, have a struct+ union Car made up of the rust type?*/ /* union union_car { C_FastCar, C_SlowCar } enum Cartype{Slow,Fast}; struct C_Car{ union_car, Cartype tag; } */ bar:C_Bar, car: *void,//C_Car carlength:usize } ```
I don't think those would match since HIR still has binary op nodes in it. There is however code that makes UFCS and method call syntax be considered equivalent provided they resolve to the same method.
I think I am misunderstanding your point really badly, because I have no idea what your example has to do with anything. If you don't mind, can you give me a code example?
For me it looks pixelated, which suggests to me that it is on purpose, to go for some kind of "retro" style
I meant integrating this into cargo. Like doing cargo cov and having code coverage information generated in format x (e.g html) for tests, doc test, examples, ... using LLVM code coverage instrumentation with branch counters and everything. We _need_ to know whether we are hitting every code path, and we'd like to know which with % of input values we are hitting each one (e.g. Are we missing extreme cases) 
Well, it's still has a connection, as in client tells the server which port it's using, so the server can reply. It just doesn't have the session, therefore you can send packets pretending to be someone else.
Corrode is great but not really good enough to just automatically port large things. Most ports I’m aware of don’t use it. Ports can often be faster; see Stylo in Firefox as a recent real-world example.
Thank you!
"all traits"? What about traits that have "static" methods?
What is 2фb?
It's unfortunate that answering "I've stopped using Haskell" means that your'e not allowed to have an opinion on build systems or what the problems with the language are...
I'm surprised that doesn't get normalized earlier. Given that there are only ~2 dozen operators that seems like something that would be normalized as early as possible (my understanding was that pulling out the impls for primitives was the only thing that happens late)
&gt; 2φb WTF does that even mean
We shall never get an answer...
What if malloc took a closure?
Ah, thanks for the correction!
Two-phase borrow. Not my idea to use this shorthand; I saw some team member use it in a GitHub thread. But I doubt I can find the thread now :/ 
See [this comment](https://www.reddit.com/r/rust/comments/7at0hq/anything_similar_to_kotlins_takeif/dpcvnsn/).
https://github.com/rust-lang/rust/issues/38899#issuecomment-322265484
Thanks
It's not that stupid, phi is used to signify the phase of a wave in signal processing so it makes sense, sorta
Is there any shorthand for this? If you ever pattern match on a borrow, there's nothing you can do but use ref, and it's a pain to type it in for every variable name.
Being generally accepted as meaning "this can never happen" is a pretty big difference IMO
The only question is: what will we, as a community, do with all the time saved by not typing three words? /s
googling for the phi symbol is such a time saver.
They're [adding one](https://github.com/rust-lang/rfcs/blob/master/text/2005-match-ergonomics.md) but I don't think it's complete yet.
In Scala, Option sort of works like a 1 element collection, so any collection methods work on it including filter. val s = Option(5) s.filter { _ &gt; 8 } // None Does this not work in other languages?
It looks like rfcbot's avatar is the character [Gremio](https://www.spriters-resource.com/playstation/suikoden/sheet/3394/) from the Playstation 1 RPG [Suikoden](https://en.wikipedia.org/wiki/Suikoden). I've never played the game myself, so I'm not sure what significance that might have.
**Suikoden** Suikoden (Japanese: 幻想水滸伝, Hepburn: Gensō Suikoden) is a role-playing video game series originally created by Yoshitaka Murayama. The game series is loosely based on the classical Chinese novel Shui Hu Zhuan by Shi Naian. Shui Hu Zhuan is rendered as 水滸伝 in Japanese, and read phonetically as Suikoden. Each individual game in the series centers on relative themes of politics, corruption, revolution, mystical crystals known as True Runes and the "108 Stars of Destiny"—the 108 protagonists who are loosely interpreted from the source material. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
Rust is more verbose, but it gives you more control in return. let x = Some(3); let y = x.iter().filter(|&amp;&amp;v| v &gt; 3).next(); println!("y: {:?}", y); [Playground link.](https://play.rust-lang.org/?gist=cc8c57a08d6b4961c3b9e5642c17f1e5&amp;version=stable)
I mentioned `filter_map` just because that's where I most recently would've found this useful. As /u/quodlibetor suggested I was trying to apply a filter to an `Option` essentially (`and_then` with `take_if` inside), making it fairly concise to use apply additional . Honestly though with Rust's syntax that looks noisier than doing additional `filter` and `map` calls.
Correct, that is the focus. I agree purity is important and we do discuss it, but throwing someone who's used to an imperative language into a 100% pure environment is still a shocking transition. OCaml at least provides you an "escape hatch" if you need it.
I'm not sure what is the correct nomenclature here. Seems to me that session is a higher level concept, and on TCP/UDP we're talking about connections.
Hmmm actually no, I am getting that on my computer. I just uploaded on gist for easier access.
This kind of question generally requires detailed knowledge of both `rustbox` *and* `termion`, which is probably why you're not getting much help. The number of people who have used both is probably very small. I opened up the documentation for `rustbox` to learn what the significance of `Event::KeyEventRaw` is, and I must admit that I don't understand why you're not just using `Event::Key`, which maps very closely to `termion`'s `Event::Key` enum. From reading `rustbox`'s documentation, source code, and even googling, I can't figure out what the three fields of `KeyEventRaw` even really mean. What is the difference between `key` and `ch`? But, no, there doesn't seem to be any equivalent to `KeyEventRaw` in `termion`. Is there a reason you can't just use `Event::Key`?
Hey guys, just trying to run a clean petition here. If you agree with the petition please consider signing! If not, no worries! Thanks guys
I think you've got the wrong subreddit here. /r/PlayRust seems to be what you're looking for. 🙂
Hey thanks! :)
Do you guys use rust with hadoop? I'm asking because the spark bit in the description.
For changes to the language, compiler suggestions combined with rustfix is also a good option
ωhατ, γου δon'τ υsε α kεγβοαrδ lαγouτ thατ inclυδεs thεµ?
I'm not aware of the details. But I think those should work?
You seem to be arguing a point I never made.
I recommend checking out ML. Modules are a whole lot more powerful than traits, and I think that it's a better abstraction in general. Also, good modules for free is good :D
I'm actually flying tomorrow half-way around the world. Guess working on my Rust projects is out of the question
IMO it looks like its on purpose
Love Agda and Lean's symbolic input modes btw. So lovely to type `\-&gt;` and get a lovely `→` and `\all` to get `∀`.
`#[repr(Whatever)]` does **not** change the representation of the field's structs - it only changes how the structs are laid out (and for enums with `#[repr(u16)]` and similar, how big the discriminant is. I'm not entirely sure `#[repr(C)]` interacts with enums with fields. I'd *expect* it to only change the discriminant size, and leave the actual fields undefined still, but I'm not sure.
I can see the convenience, but it would be seriously magical for a nothing-returning function to do this. Such special cases pile up and cause more confusion than just defining a `fn run() -&gt; Result&lt;(),Box&lt;Error&gt;&gt;` explicitly.
Oh nice! I didn't knew that ! unifies with anything, but that explains why panic! und unimplemented! don't need to typecheck either... thought it was a compiler hack
(On nightly, that is most explicitly represented with the unstable `!` type, [as in this example](https://play.rust-lang.org/?gist=4375db11ee143f806368fbc4034b2d33&amp;version=nightly).)
I was doing something fairly similar back when I was learning rust. [Here](https://gist.github.com/lanedraex/bc01eb399614359470cfacc9d95993fb) is the code I wrote. The message sending is a little broken, but it connects and everything works for the most part. Hope it helps you in some way.
 New [playground link](https://play.rust-lang.org/?gist=3b26ddd6375945193ccad5df84506f62&amp;version=stable) with a little more context, including Quxxy's correct solution.
New [playground link](https://play.rust-lang.org/?gist=3b26ddd6375945193ccad5df84506f62&amp;version=stable) with a little more context, including Quxxy's correct solution.
Both XeLaTeX and LuaLaTeX should do pretty well with a bit of tweaking.
I suppose you are related to Alex?
If you redefine all your structs with C layout, you need to copy a lot of data. Unless you want to copy, I'd suggest exposing C functions which retrieve data from one "big" C struct (which internally just points to your `Foo` struct).
Using special error type is much better. E.g. for translation purposes.
Same :)
あし~~~~
How’s Etsy doing these days? Has the drama subsided?
A feature-gated version is implemented on nightly (add `#!(feature(match_default_bindings)]` to your crate root)
 fn test_function() {} fn main() { let v: Vec&lt;fn()&gt; = vec![test_function]; assert_eq!(v[0], test_function as _); } The issue is that functions are their own unique types (as this allows using them generically without having to waste space storing pointer to a function). There is a coercion that allows converting that unique type into a function pointer, but for some reason it is not triggered, but it can be forced with `as _` (or if you prefer a full name, `as fn()`).
If you want to use rust-postgres, take a look at [r2d2](https://github.com/sfackler/r2d2) for connection pooling!
And this can be further simplified to `if rand::random()` to avoid calling `rand::thread_rng`.
I feel that I can't really fill out the survey either way. I've played around a few times with Haskell over the last few years but never did a real project with it. I can't tick "I never used Haskell". On the other hand, I didn't really stop using Haskell, but I'm not actively using it either. Since I never did something bigger than single-file programs, I didn't really use build tools either. I guess I'll pass this time :) Writing good surveys is hard.
thanks!
What advantage does this control confer here?
so, here, we could do three different things. With just an integer, none of them are interesting, but if we were dealing with a large struct, they would become interesting. Our choices are `iter()`, `iter_mut()`, and `into_iter()`. - `iter()` will create an iterator that references the elements in the collection - `iter_mut()` will create an iterator over mutable references to those elements - `into_iter()` will take ownership of the items in the collection, and iterate over those. `Option` is a collection of either 0 or 1 elements. Once we have the iterator, we could pass that iterator to *any* function that needs an iterator over elements of that type, which is powerful in itself. Depending on what we needed to do here, we could use `iter()` to create an iterator that does not invalidate `x`, and then we could still hand `x` to some other function later on, since we only needed to temporarily reference the element that might exist in that Option. With `iter_mut()` we could even transform the value inside `x`, if it passed our `filter`, or whatever other things we wanted to do or check. With `into_iter()`, we would basically be saying we're done with `x` and we won't need to use that variable again, since it gets consumed by the `into_iter()` function. At the end of the second line, we call `next()` to go ahead and force the iterator to iterate. I've never used Scala, so I had to research it just now, but it appears Scala's iterators are lazy too, which means /u/lelarentaka's code example is incomplete -- it needs to call `next` on the iterator for it to really get to `None`, so this part is no different between Rust and Scala. The main difference is the call to `iter()`, which is 1 of 3 main choices, depending on what you're doing.
Would a dedicated programming language be useful to describe the rules? I can imagine tooling support benefitting from this. Great there is now a rust implementation.
I'm actually pondering that possibility - but type-changing combinators are hard: * `Either&lt;Water, Poison&gt;.map_left(|w| Puddle(w)) -&gt; Either&lt;Puddle, Poison&gt;` - but what will be the type of `Liquid.map_water(|w| Puddle(w))`? * `Either&lt;Water, Poison&gt;.as_ref() -&gt; `Either&lt;&amp;Water, &amp;Poison&gt;` - but what will be the type of `Liquid.as_ref()`?
The filter method on `scala.Option` is implemented directly on the class, not through a conversion to an iterator. So the filter method directly returns another Option. You can see similar usage of filter in the [official doc](http://www.scala-lang.org/api/2.12.3/scala/Option.html)
gotcha, that's interesting!