QtWidget-like multiplatform native-looking GUI, written in rust, without external dependencies (one binary file executable, with reasonable size)
The link to vim.org on the site is broken.
Ok, thanks man!
Not on Debian ;-) https://old.reddit.com/r/rust/comments/9xewrn/debian_rust_and_librsvg_lwnnet/
I did leave myself an escape hatch in form of a `#[callback = "some_function"]` for situations like that. So you could have a token with regex `r#*"` that kicks into a callback where you manually bump the lexer until you get the tail of the raw string. It's a bit tedious and I've hidden the actual internals behind an undocumented trait now so it would be a hack, but eh. JS also has context dependent issue in form of regex expressions, where `/` that follows an expression is division, but when it starts a new expression it's regex, so I wanted to be prepared for that.
If you have the time and possibility, could you please share your code/benchmarks? I'd love to take a look and see how we can improve performance!
Perhaps they look similar when you are using c++ as 'c with classes'. OP, how often do you use `new` in your c++ code?
The first thing the lexer does after it finds a new non-whitespace byte is use that byte as an array index for a handler function, which is O(1), so having extra knowledge about which tokens are allowed next wouldn't speed that process up, _unless_ that specialization also can get rid of the LUT entirely and use a match for couple bytes that hopefully Rust can optimize into a jump table. As for separation, it depends I'd say. If you have reasonably simple grammar like JSON, you probably don't need a lexer. For anything complex like programming languages though you'd have to have some other nice way to abstract out the complexity.
Yes, it ignores whitespace by default. There is no way to change what it considers a whitespace right now, but that shouldn't be hard to add. If you want to use whitespace for formatting (for Python-esque languages etc.) you have two options: 1) Create a token that matches new line indention and handle that in a parser. 2) Use the [`Extras`](https://docs.rs/logos/0.6.1/logos/trait.Extras.html) traits that has a `on_whitespace(&amp;mut self, byte: u8)` function on it just for that reason (I'll be using this for handling automatic semicolon insertion in JS). This is currently not very well documented, but if you look into tests you will find it :).
The compiler has `cap-lints` to make deny a warning again for this reason. Is that not being used for builds? Cargo uses it.
&gt;hi all, I'm author of the crate , it is the source code of a new Chinese Rust book. &gt; &gt;another online docs: https://ruststudy.github.io/tao\_of\_rust\_docs/tao\_of\_rust/ &gt; &gt;GitHub Repo: https://github.com/ZhangHanDong/tao-of-rust-codes &gt; &gt;I don't know who post it here, I'm sorry if you are bothered. hi all, I'm author of the crate , it is the source code of a new Chinese Rust book. another online docs: [https://ruststudy.github.io/tao\_of\_rust\_docs/tao\_of\_rust/](https://ruststudy.github.io/tao_of_rust_docs/tao_of_rust/) GitHub Repo: [https://github.com/ZhangHanDong/tao-of-rust-codes](https://github.com/ZhangHanDong/tao-of-rust-codes) I don't know who post it here, I'm sorry if you are bothered.
Cool. Will definitely give this go! (no pun intended ;))
Not yet, but that's a good suggestion, I'll try to write that soon. Meanwhile, you can play with our repositories at https://nest.pijul.com/pijul\_org/pijul
\`pijul pull my-full-login@my-very-long-url --set-default\`
The article's headline is very deceptive. "You need to learn Rust" sounds like there's demand right now. Reading the article makes you realize that there's actually no demand right now, just that some Rust advocates believe there will be. All the quotes are from the same programmer. There is nothing from, say, a technical lead at a financial company saying they're looking into it. The whole thing is completely lacking in substance, and the only thing it will likely achieve is to further the RESF hate.
I'm just missing something [here](https://gist.github.com/ian-p-cooke/b4d74a8459814d881c6f6510bf1c6f7b). I know I can change the `tags` field to be Vec&lt;Vec&lt;u8&gt;&gt; and push `field_number.as_bytes().to_owned()` instead but what if I don't want to? Is it possible to "extend" the lifetime of package and/or document in some way? I tried putting them in a box, adding them as a field to the returned struct, etc but nothing works. This seems like "Lifetimes 101" but I can't see the solution. Any ideas?
proc-macro2 is only important if you need to support \*older\* than the latest compiler.
read\_export\_file() panics if exports file contain line of space symbols. let lines: Vec&lt;String&gt; = f .split("\n") .map(|s| s.to_string()) .filter(|s| !s.is_empty()) // removes empty lines .filter(|s| s.trim().chars().next().unwrap() != '#') // " " is not empty, but " ".trim() is, so chars().next() is None .collect(); Both those filters can be rewritten as .filter(|s|{ if let Some(c) = s.trim().chars().next(){ c != '#' // ignore comments }else{ false // ignore empty or whitespace only lines } } or shorter but less clear .filter(|s| s.trim().chars().next().filter(|x| x != '#').is_some())
I mean, that post is about how it \*is\* on Debian....
I used the CodeLLDB extension for vscode and it seemed to work without a hitch. Again I'm super new at rust so I didn't deal with any crazy debugging scenarios as of yet.
That's certainly true, but the list of gotchas in Rust is tremendously reduced, therefore a somehow competent developer can get really quite near to the state of saying: if it compiles it works. The only other language I had the same experience was Haskell. Sure, it's really hard to market this without sounding like hyperbole.
I have been thinking about this as well for a project of mine. Do you know if there is there a crate that lets you offer both ways with minimal boilerplate?
&gt; Going in an infinite loop is not a memory leak. Why? If a thread goes into infinite loop and doesn't interact with other threads or doing any IO it is essentially a memory leak. E.g `thread::spawn(|| loop {})` leaks all resources associated with the thread.
Some CIs allow you to set up cross-build caching which may help.
It’s the border between the two that’s usually painful — e.g., sharing massive amounts of structured data between your Python prototypes and Rust/C++, at least in my experience.
Just started with Rust and finished the Wevserver example from the Book. I want to continue with it a little, so I tried to extract a a proper Server struct. Now I get an error I cannot grasp: `error[E0277]: \`std::sync::mpsc::Sender&lt;threadpool::Message&gt;\` cannot be shared between threads safely` `--&gt; src\lib.rs:24:23` `|` `24 | self.pool.execute(|| {` `| ^^^^^^^ \`std::sync::mpsc::Sender&lt;threadpool::Message&gt;\` cannot be shared between threads safely` `|` `= help: within \`&amp;Server\`, the trait \`std::marker::Sync\` is not implemented for \`std::sync::mpsc::Sender&lt;threadpool::Message&gt;\`` `= note: required because it appears within the type \`threadpool::ThreadPool\`` `= note: required because it appears within the type \`Server\`` `= note: required because it appears within the type \`&amp;Server\`` `= note: required because of the requirements on the impl of \`std::marker::Send\` for \`&amp;&amp;Server\`` `= note: required because it appears within the type \`[closure@src\lib.rs:24:31: 26:14 self:&amp;&amp;Server, stream:std::net::TcpStream]\`` The full code can be found [here](https://gitlab.com/alkern/rust-server-example). The previous commit works fine, but extracting the server messed it up. I hope someone can give me a lead to understand the problem. Thank you! &amp;#x200B;
Yes, you can enable crate's feature with a feature. Syntax is like: [features] my-feature = ["crate/crate-feature"] Here's the [document](https://doc.rust-lang.org/cargo/reference/manifest.html#the-features-section)
If I understand correctly what you need, this is indeed possible. Try the following: ``` [features] tls-termination = [“actix-web/tls"] ```
Wikipedia may be bigger than Dropbox, but I still think Firefox has more users than Wikipedia.
A bit late... &gt;My advice: if you work with Rust, just get a desktop, with decent specs. and the sheer performance improvement will make the problem disappear, at least for small to mid-size projects. Is the 15 inch Macbook Pro (2018) enough?
by moving things into a struct you created some borrowing/threading problems... the closure you pass into `pool.execute` contains a reference to `self` and `self` has a `Threadpool` as a field and `Threadpool` isn't safe to send between threads. It might help to read the error from the bottom up: 'your closure uses `&amp;&amp;Server` but `&amp;&amp;Server` isn't `Send` because `&amp;Server` isn't `Send` because `Server` isn't `Send` because `Threadpool` isn't `Send` because `Sender` isn't `Sync`. Note that handle_connection doesn't actually use `self` so it doesn't need to be a method of `Server`. Some things are just functions and that's ok... not everything should be a method on a struct. If you really want it to be in the impl, remove the `self` parameter and call it as `Server::handle_connection`. The easiest thing to do is pull handle_connection back out of Server. Once you do that, you'll run into some other problems in your code (different borrowing problems) but those are easier to understand/fix. One is the signature of `execute` should borrow `self` not consume `self`. The other is that you should pass a reference to `self.address` to `bind` instead of the value.
`Arc&lt;RefCell&lt;T&gt;&gt;` is not `Send` or `Sync` (thanks to typeclass system). How would you shoot yuorself in foot then?
Considering it is faster then a lot of desktops, yes. Fast-clock/big cache CPU, 16G RAM, SSD.
Ok lets imagine we work on a big project with 5 remote locations. Would I need to always specify the url?
I personally don't have too much issue with compile times in general. Once it gets too long I usually split it into smaller crates, in the same workspace. This is good to do anyway, at least for testing purposes.
That sounds like cheating, although correct. Is it easy to leak when using reference-counting, and is it easy to detect and solve such leak?
Who should detect it? There's no GC, but you can use a GC library like shifgrethor for your cyclic data structures, or arena allocators etc. It depends on the use case. 
Rust may run without an OS, and in this case memory shouldn't leak at all.
I agree with you that Rust suffers less of those issues than C or C++ typically does, but the issue I have with such strong claims about Rust's guarantees is that it comes across as 'zealotry' or 'evangelism'. This will make people gloss over the strong points Rust actually does bring, which is a shame IMO.
&gt; Because you can implement those traits for &amp;'a T, which means generating references, mixing references and values, which gets ugly Basically to cleanup my maths I can make my vector types #[Copy] .. but this restricts potential uses, and there comes a boundary between copy and reference types (low level types assembling into intermediates and high level types .. at some point on that continuum #[Copy] stops making sense. and yet you can express 'lerp' (linear interpolation) for some quite weighty objects. One counter argument I was being given as to why 'consuming' makes sense is re-using storage, however at low level (and indeed for high level) borrow is used to enable re-ordering/perallelism (this appears both at the instruction level and between threads. the bulk fo the maths in a game loop is working on read-only structures - the data for the 'previous frame' can be read in parallel for generating each object next state and/or feeding the graphics pipeline, plus there are many immutable 'resources' like collision meshes)
https://www.twitch.tv/panterstvyt
Fun discussion about memory leaks being considered safe or not: https://github.com/rust-lang/rust/issues/24292
Wrong subreddit: /r/playrust
No, then you would write something like the following in \`.pijul/meta.toml\`: \`\`\` \[remote.remote\] address = ["pmeunier@nest.pijul.com](mailto:"pmeunier@nest.pijul.com):pijul\_org/pijul" \`\`\`
You can actually make this work without copying with very little modification. The issue you're running into is that the borrow can't be tied to the input string like you've written. The `Package` struct returned from `sxd_document::parser::parse` doesn't borrow the input string; it's likely copying inside the parse function. This means that you're trying to return borrows that outlive the data they reference since `package` doesn't escape `parse1()`. A simple fix is to parse the document outside the `parse1()` function and then pass a `&amp;Package` into it so that it can return borrows to it in `LengthTags`: // doesn't need to return a `Result` anymore pub fn parse1(package: &amp;Package) -&gt; LengthTags { // body is unmodified besides lifting `parser::parse(...)` and // changing the return statement let document = package.as_document(); let mut length_tags = LengthTags { tags: vec![] }; let fields = evaluate_xpath(&amp;document, "/fix/fields/field")?; if let Value::Nodeset(nodes) = fields { for node in nodes { let el = node.element().unwrap(); let field_type = el.attribute_value("type").unwrap(); if field_type.to_lowercase() == "length" { let field_name = el.attribute_value("name").unwrap(); let field_number = el.attribute_value("number").unwrap(); println!("{} : {} = {}", field_name, field_type, field_number); length_tags.tags.push(field_number.as_bytes()); } } } length_tags } fn main() -&gt; Result&lt;(), Box&lt;Error&gt;&gt; { let xml = r#"&lt;fix&gt;&lt;fields&gt;&lt;field name="blah" number="1" type="LENGTH"&gt;&lt;/field&gt;&lt;field name="blahblah" number="12" type="STRING"&gt;&lt;/field&gt;&lt;/fields&gt;&lt;/fix&gt;"#; let package = parser::parse(xml).unwrap(); let length_tags = parse1(&amp;package); assert_eq!(length_tags.tags.len(), 1); Ok(()) }
please don't pepper your text with bold fonts. it makes it harder to read.
&gt; which means generating references, mixing references and values, which gets ugly I don't quite understand why this gets ugly. Isn't it simply to implement the operator for references of a type that you want to borrow and implementing it on the direct type when you want to consume? Could you perhaps give an explicit example of the "uglyness"?
Yep, not available in Germany.
I prefer the Rust way, I find it more expressive, as it allows mixing moving/consuming and borrowing, and is always clear and explicit. For example, I like that I can have `cons + &amp;borr` or `&amp;borr + cons` where I know that `cons` is being consumed, which allows a more efficient implementation equivalent to `({cons += &amp;borr; cons})`. I do not find `&amp;a + &amp;b` similar to pointer arithmetic. If you `let rb = &amp;b` and then use `&amp;a + rb` I see how that might look like pointer arithmetic, but then in that case you could `let ra = &amp;a` as well and then use `ra + rb`.
How big is the difference between something like WAVM which uses LLVM for optimizations and code generation?
I thought that Arc implements Sync where T: Sync + Send and RefCell implements Send + Sync. 
AIUI, Cargo uses cap-lints for dependencies, but not when you build and test a crate directly.
[removed]
You just need to use the cfg attribute twice, on both the extern crate and the pub mod.
dzięki! :)
I was told not long ago that splitting a project into crates does not make it compile faster. Rust already has incremental compilation to re-use object files.
I don't know about it being easy to detect--you probably have to find them manually--but they're fairly easy to solve if your data structure is hierarchical. Just break the cycle with a weak reference wherever most appropriate: struct Parent(Rc&lt;Child&gt;); struct Child(Weak&lt;Parent&gt;);
Exactly what I feel 
Just a tiny piece of feedback for possible improvement: The runtime crate is pretty much `#[no_std]`-capable. Just fall back to `use core::ops::Range;` instead of `std` and you're golden. Also... have you measured the performance effect of the `unwind!`-macro usage? Because the usage code looks more like ICache pollution than a real gain in speed. Other than that: Very nice crate. I really like the proc-macro ergonomics of it!
How fast is cranelift ?
because you generate values, then you have to borrow them straight away. 
I have never wanted addition or multiplication to consume something. and yes going back to plain C there's plenty of times when passing a pointer does mean consuming it. It's not like the concept of consuming is *new* to me, it's just the imposition of it as a default is.
if you're going to skim it highlights a few key points. I dont expect everyone will have the patience to read it all. Mixing highlighted text gives me the opportunity both to express something salient, and expand.
I tried that but it seems tonconflict with the macro_use on the extern crate. Should they be stackable? Ie the cfg attribute, then on the next line macro_use and finally extern crate?
Thanks. I'll give that a try and see if it works.
Congratulations! Just one advice, do not commit commented code, like [this](https://github.com/adam-mcdaniel/maroon-lang/blob/master/tools/src/evaluator.rs#L48), that feels unnecessary, you have git at your disposal and the tools it provides.
I'll need to post my setup at some point and fix some stuff as well but this would be good to write up when I get the chance
Good. Is there a schematic circuit diagram? 
If you're interested, I did some work this week to do something similar, only using `wasmi` instead of `cranelift`. The code is filthy and it doesn't work fantastically right now, but it can run its own benchmarks compiled to wasm and outputs the correct time taken for them. Code at https://github.com/Vurich/runwasm
Are you looking for r/playrust by any chance? r/rust is for the programming language.
Uh oh
Really impressive work! I'm stoked to see how fast you translated a not-so-short EBNF grammar. I'll try to see if I can find any place to improve, but the grammar looks good at a first glance. Do you happen to have some benchmarks for this?
r.e. mixing + &amp;... i guess there's also the sinking sensation realising the other side of that... pointer arithmetic... *is going to stay ugly* (.offset(...))
No benchmarks yet. I'm busy applying the xml conformance tests, at least as far as verifying that the non-well-formedness tests fail, and the well-formedness tests pass. On that front, it looks like I do have some grammar problems that I'll need to fix. But yes, I'm absolutely interested in getting good benchmarks in place. My end goal is to publish my grammar crate as a high quality, high performance foundation for writing sax, pull, and dom parser crates that are more complete than the ones already out there.
Thanks so much, it was really fun to make! I haven't updated the README yet, but it supports Pred as a mathetical expression now :))))
Not yet. You can find the used pin in the source code. That's planned. You can open an issue to know when it's done, and it will motivate me to do it fast ;-)
I don't know what you mean by "recursive descent parsing is shit" - it's used by many of the major production compilers, because it's the fastest, easiest to understand, and most powerful. For example, rustc and the three major C++ compilers all use (a variant of) recursive descent.
The story isn’t so great on Windows 
Notice that the standard library contains an implementation impl&lt;'a, T&gt; IntoIterator for &amp;'a mut [T] Therefore you can still pass a byte slice (`&amp;mut [u8]`) into the function. You sinply gain flexibility to also use other types by implementing the function generically. Essentially in the generic functiob you are passing a reference ‚by value‘ which amounts to passing by reference.
Extremely cool release video! Will be playing around with Modulator a bit, if I have time.
That makes a ton of sense. Thank you!!
Absolutely fantastic! &amp;#x200B;
Maybe… a math! macro environment that adds borrow for you?
Thanks for this! Going `#[no_std]`totally makes sense. I did measure `unwind!` and it is a performance gain. I don't actually know _why_, initially I just wanted to put the repeats inside the loop, as one might expect, will have to check the ASM output later.
the extra nesting level (and uncertainty when seeing a macro that can do so much else) would cause more distress than reverting to named functions and manual borrows. it seems to the be mix of operators and manual borrows that I strongly dislike. It might be because of the implications r.e. pointers and there I have it : graphics code is - unsafe blocks (with some raw pointers) for organising data for the GPU, and maths. C++ has the awkwardness of header files &amp; classes (the two interact really badly) ... it should be possible to improve on it with a clean design. What i've found disappointing is the amount of ugliness/akwardness Rust has managed to add in other areas. C++ still feels more natural for 'creative coding'
That would actually be kinda cool, something like valgrind or a library with an instrumented version of `Rc` that could warn you if it detected cycles might be a useful debugging tool.
Strong plus one here. To be more precise, production compilers and IDEs use a combination of recursive descent and Pratt parsing. Pratt is important here: pure recursive descent is indeed a bad fit for parsing "arithmetic" expressions.
Yeah! Pratt parsers are great.
The normal vscode C++ debugger seems to work for me, but maybe i don't know what i'm missing?
Sorry. I got it wrong. We learned in class that predictive recursive descent parsers are only okay. It's because if any production first sets overlap, contain empty string, or have possible infinite recursion, the method we're taught breaks. That's paraphrased straight from a slide, btw. Compare that with backtracking or shift reduce parsers, which we didn't really discuss. So yeah, I meant predictive recursive descent parsers. Out of curiosity, what does Rust and other parsers do instead? Does really use predictive recursive descent parsing, because having to think about first sets seems like a real pain?
Yes, if there are more people interested in such a thing please let me know :)
Yes, it's a beast. Doing a lot of typescript which is notoriously slow I don't find the rust compile times an issue at all.
I sort of disagree on the non-recursive-descent nature of pratt parsers - in the code I write, at least, it looks like let parse_infix_operators e0 op1 = let e1 = parse_expression_no_infix in match next_token with | Token.Operator op2 -&gt; if prec op1 &lt; prec op2 then let rest = parse_infix_operators e1 op2 in Expr.Operator (op1, e0, rest) else let lhs = Expr.Operator (op1, e0, e1) in parse_infix_operators lhs op2 | _ -&gt; Expr.Operator (op1, e0, e1)
Wrong subreddit, you probably wanted to post this here r/playrust
Now I had to check what `unwind!` does and was a bit disappointed ;) I think `unroll!` would be a better name, especially since "unwind" already has meaning for Rust?
Anything with an i5 or better, and 16GB of RAM, should be plenty. The MBP certainly meets those criteria. However, I get frustrated when I hear the topic of Rust's compile times repeated. Could they be better? Certainly. But they don't feel any worse than C++ compile times. I do wonder if part of the problem is that Rust projects, with Cargo being so easy to use, are more likely to pull in external dependencies, which are statically linked, and increase compile time that way. C++ tends to use shared libraries, which don't need to be recompiled every time the project is built.
A well predicted branch could be much faster than an indirect call (ideally free). It kinda depends on how much you blow up the instruction cache by having all these specialized lexer functions I guess. 
Just let me be sure, you are advocating for the operators to borrow its arguments by default, just like C++ operators always taking references, right? Unfortunately Rust has already stabilized on operators taking ownership by default, just like functions, partly for consistency. To change it to borrow by default, I suggest you write an RFC detailing your motivation and goal, and initiate a community discussion about its benefits, costs, consequences and potential transition routes. If it doesn’t break many code, then maybe it will make way into a future edition. Rust RFCs: https://github.com/rust-lang/rfcs In the meantime, the best way to experiment with new semantics is with macro. Macro is powerful, but just like function is powerful, and you gain confidence in what it does by familiarity. If it eventually enters the language, then the macro is no longer needed and the nesting problem is solved. If you feel C++ serves you better, it may also be a good choice not to care about sunk cost and go back to C++. Not that I want to see you leave, but changing fundamental semantics such as operators is going to take a long time. The choice is always yours. Good luck! Oh and Happy Thanksgiving!
Great video! I'm sorry for triviality of this question, but what music is he using?
Oh dear. Yes. It's meant to be a loop unroll, not loop _unwind_, I don't know why my brain confused it. I'll rename it :).
That demo video though holy shit. 
I primarily wrote C#, but I learned Rust before C++ and C. Rust definitely helped with understanding the semantics of C, and the habits learned in Rust help avoid many pitfalls when writing C that I wouldn't have thought about in a language where the GC smoothes over them for me.
For shared reference too. Pretty much all containers do this. Hence you always use container or reference to it in for loop
Yeah, I mean, if you'd like to read what a "real" predictive recursive descent parser looks like, you can look at rustc; or, what I think is a bit more readable (because it's so much simpler), you can look at my language [epsilon](https://github.com/ubsan/epsilon/blob/master/src/parser.rs)
This is awesome!!
Looks like the tracking issue is here: https://github.com/rust-lang/rust/issues/55628 Thanks!
regarding intuition/comfort.. i'm being quite generous. I'm kicking up a fuss about operators out of place - when actually behaving as a 'rust evangelist' i'm surprised at the number of people who can't get over the initial hurdle of seeing "fn" or "mut". 
I tried putting them in the same `#[]` but got a syntax error. Is there a way I should be combining them? I'll try again when I get home. Thanks
To elaborate on what /u/tspiteri said: If operators were defined on references (for example, if \`add\` took \`&amp;self\` instead of \`self\`), code like \`let c = a + b;\` would always necessarily result in an additional allocation (memory for \`c\` would have to be allocated, as \`a\` and \`b\` would be borrowed immutably). So you couldn't reuse memory used by \`a\` even if you knew that you will no longer use it. On the other hand, if you don't want to consume values with consuming operators, you can always implement them separately for the reference type and use \`let c = &amp;a + \&amp;b;\`. Granted, it's more explicit and requires those \`&amp;\`s, but at least both use cases are still possible. So, to summarize, doing what you're suggesting would break a possible use case for the operators.
Sweet, I'll have to check your language out. I did look at a little bit, and saw some uses of UnsafeCell. What made you decide to use that, instant of going with pure Safe Rust?
I'm not really following your code - maybe you can provide (quite a bit) more context? I'm not sure why you even mention \`this\` - or what \`this.x\` and \`this.y\` refer to, since that's not idiomatic Rust, but looks more like C++. Maybe it's not clear to me what you're posting here that's Rust code vs what is your intermediate programming language. In general - pretty sure the advice is to not use \`UnsafeCell\`. Use Rust's compile errors to make you really really think about your design, and find a way that keeps the compiler happy. Sometimes, it may feel like there are a few valid designs and Rust is "forcing" you to choose one of them, but that's OK. It probably means that design is easier to reason about the ownership of various fields. &amp;#x200B; I myself would only think about putting my hand into \`unsafe\` territory if I had an already working codebase but wanted to experiment tweaking the implementation for performance reasons. With \`UnsafeCell\`, you don't only have to worry about making sure you are getting your logic right, but you probably have to benchmark things as well -- based on the docs, I believe using an \`UnsafeCell\` means [you prevent the compiler from being able to make some optimizations](https://doc.rust-lang.org/stable/std/cell/struct.UnsafeCell.html) (since it can no longer make guarantees about non-simultaneous mutable / immutable access). &amp;#x200B; But maybe more code can help demonstrate out why your codebase would be the exception rather than the rule?
Hi, it's pretty impossible to read the code in your post. In general, it's not a good idea to use UnsafeCell. Think about unsafe blocks like this: `unsafe` doesn't lift any fundamental rules. You still have to follow the same safety rules, only you need to do it manually. It's hard! I would advice in general, look at why the RefCell (in this case) forbids this pattern, and how to work around it in safe Rust. Gradually working like that will have you understand borrowing and safety rules better, and that gets you closer to programming confidently with occational `unsafe` code blocks too.
First of all, I'd like to tell a huge thanks to everyone involved into development of ndarray and ndarray_linalg crates which layout the foundation of a program I am working on part-time. Without all of you, it would not have happened. I wish I could help you in your efforts, unfortunately, my insufficient level of intellect and a not yet approved budget for the next year do not allow me to make such a commitment. =] But, if you pardon me, I'd like to share a few thoughts on the topic with you and suggest you increase the list of inspiration with other libraries and commonly adopted textbooks, apart from NumPy and Julia. Recently, I ported Kendall's tau-b method, and I find, Apache Common Math's variant is much cleaner than Scipy's. Another argument, why it is maybe important. The very first link of a search result for a Cramer’s V method is http://changingminds.org/explanations/research/analysis/cramers_v.htm. And there, in the "Phi (f) Correlation" section, they state that "Phi varies between -1 and 1", yet somehow you supposed to compute it by "sqrt(c^2 / N)". What I am trying to tell is that mathematical statistics is hard in a deeply philosophical manner. =] And if you are not careful enough, you may end up with a program logic mathematically incorrect though works successfully in a production for a half a year. Another point of concern is that methods such as f-statistic or rank correlations are not applicable to variants of a different type, e.g. discrete ordinal, nominal and continuous. Let's say in a program a discrete variable is represented as an integer and a continuous variable is represented as a float. Then you will have to convert a vector of integers into a vector of doubles, and that is dictated solely by library's API rather by a reasoning. The above leads us to the following idea. Exist rare cases when you have multiple discrete and continuous variables and you want to calculate pair-wise correlations between them. In these situations, it is more convenient to have a function which takes these vectors as separate arguments of different data type and to have column-major matrices by default. Also, quite commonly beside just computing t/f/etc-statistics, you need to compute their p-values. There are a few crates on the crate.io which helps to do this. But it is not always easy to find them. (Examples: fishers_exact, statrs). In this respect having a crate that brings all the necessary tools into a single place looks attractive yet it is not clear if it is doable with all of the possible requirements being satisfied.
So I have [store_at](https://github.com/playXE/Jazz/blob/master/src/class.rs#L112) function that borrows HashMap as `&amp;mut` and [load_at](https://github.com/playXE/Jazz/blob/master/src/class.rs#L119) that borrows HashMap as `&amp;` and with RefCell I get BorrowMutError when I first borrow HashMap as `&amp;mut` and then as `&amp;` or vice versa, with UnsafeCel I don't get segfaults or other errors, it just works as need
That'll only reduce the size in memory if other applications also link again your dynamic library. 
"I know enough about unsafe code that I don't need to worry, and I can create a good safe abstraction" (and it's also way more fun)
&gt; What I am trying to do is compile my rust project with dynamic linking to reduce the size and provide .so (or .dll on Windows ) files with application just like Qt does for android. That won't help for two reasons: 1. `.so` files save space by being shared between multiple programs. 2. Rust doesn't have a stable ABI, so even the most minor update to your Rust compiler (eg. one nightly to the following nightly) might break compatibility with existing `.so` files. &gt; and now when I try to run my program I get this error That's intentional. Avoiding footguns is part of Rust's design philosophy and allowing things which link against an unstable ABI to Just Work™ (until they suddenly don't) is a huge footgun. Think of it as "If you need to ask how to make this work, you don't have a deep enough understanding to grasp why it's such a bad idea.")
Why is there a manual `.advance()` instead of simply implementing the `.next()` from the Iterator trait?
Ah, ok. I've never heard of an interner before, so I was a little confused. :) I'll also have to check cafe out as well.
i get ur point sir, but i still want to know where are those libraries that rustc is linking to my executable from ??
Regarding operators, I think the way Haskell does it is probably the best I have seen, allowing any function to be infixed and custom operators easily defined, and can even go so far as to use Unicode symbols for operators. Maybe there is an RFC towards that direction. 
RefCell is specifically not Send or Sync because that would be unsafe
WAVM uses LLVM for code generation and optization. Wasmer uses Cranelift for code generation and hopefully soon for optimization (they are working on it). Right now optimization shouldn't really make a big difference since usually the compiled wasm code is already optimal (since it relies on LLVM for generating it through emscripten, or through Rust compiler, for example). &amp;#x200B; Both should be quite fast once code is compiled. From [my experience](https://twitter.com/syrusakbary/status/1048694728781434880) with both, wasmer is much faster compiling the code than WAVM.
Interesting! Thanks for sharing :)
&gt; I think the way Haskell does it is probably the best I have seen, allowing any function to be infixed indeed it's very elegant in many ways, What I like most about their setup is it gets rid of any parameter being special (no 'receiver') whilst that `infix` option and other forms let you write code with 'chaining' (without nesting) . However I know a lot of haskell's elegance involves a runtime cost (i'm not always clear at what point a vtable would appear or disappear) Methods are a reasonable compromise, at the expense of having a 'special parameter' (the receiver) One of the thigns I like most about Rust over C++ is traits being seperate from the type, so you can 'bolt more methods on' (like extension methods) , without having to couple excessively into one centralised class definition. My biggest gripe with *C++* (trying to remind myself why Im here..) is 'the way headers and classes interact' .. the fact that to get the infix notation you want to put more things into the class, which in turn bloats dependancies in the headers. UFCS could have improved C++ alot , unfortunately that got voted down (grrrr).
Ah, yeah, they're used all over compilers for data that's long lived, copied many times, and required to be quickly comparable - identifiers, types, functions, stuff like that.
Last time I checked, Wikipedia used a wildly obsolete version of rsvg that was faster but less correct than the current version. Also, rsvg with Rust has been released just recentrly and Wikipedia has probably not updated to it even if they are updating that lib at all.
Thanks sir, 😁
Cryptocurrencies are their own microcosm, and their approaches are taken with a kilobyte of salt by the rest of software engineering world
That is an excellent question! There are a couple of reasons: 1) When writing a parser, you often run into cases where you want to look at the next token without consuming it, this is not possible with an iterator by default and forces you to wrap it into a [Peekable](https://doc.rust-lang.org/std/iter/struct.Peekable.html). The drawback here is that every time you want to `.peek()` or `.next()` you have to do extra checks that you would have to do otherwise if you could access the token directly, which slows you down. 2) Lexer gives you extra information about the token, like it's location in the source, that you don't always need. You could have an iterator that returns all the information and throw it away when you don't need it, hoping the compiler optimizes it for you, but I find that to be a hassle. 3) In terms of ergonomics, iterators are very useful when you can use them in a `for` loop and/or chain them into/with other iterators. The former you don't really do with a lexer except for maybe tests and benchmarks. The latter you wouldn't do either unless you wrote the entire parser as an iterator, which might unnecessarily restrain you in some ways. 4) I also found it much nicer to work with when I treated the end of source or errors as just regular token. It then becomes yet another unexpected variant when you do error handling without having to code any special case handling for it. So, all in all, while on the surface it's not most idiomatic, I found that this approach gives me both better performance and makes it easier to reason about parsing.
Well, if your question is "Can you write code with unsafecell that doesn't segfault and works", well of course the answer is yes :) But... How about its performance? How about the code's maintainability in a few years from now and people keep adding layers and refactoring pieces, making the system more complex? Are you are your code won't break in certain scenarios like handling hundreds of thousands of operations per second? By using unsafecell you're basically saying, "Thanks other programmers for your hundreds of hours making sure that safe code is robust in all scenarios.... But I'm going to try going my own way" I'm sure there are times where this is fine, as even refcell uses unsafecell internally. But it's not a decision that should be made lightly unless you really know what you're doing (or if you're just writing a toy project). I'm actually out today so I won't be able to give you a more concrete answer based on the code you linked to but I'll try to take a look within a day or two, unless maybe someone else beats me to it!
Wow i which we could have the Narrator and overall Style for a "Rust 2018 overview" Video – mindblow!
If you have an &amp; and an &amp;mut at the same time, that’s UB. Sure, maybe this compiles okay for now, but that doesn’t mean it always will. Given that the refcell panics, that seems like what’s happening.
I'm confused about that. I tried using `use` to import macros instead of `#[macro_use]` but it didn't work. I'm on Rust 1.30. Am I missing something?
Source code is documentation that is never out of date.
It seems to be made by Arturia MatrixBrute: https://youtu.be/NSO_tMcAHos .
I'm not confusing anything. Industrial compilers generally use recursive descent to implement grammars, especially for those languages which are not context free (like C++). Both GCC and MSVC have switched from a yacc-based approach to recursive descent, because it's simpler, faster, and more correct for the C++ standard.
i thought it might be possible to make a backward compatible fix by enabling auto-borrow per type ```#[Autoborrow]```: no existing source base would have that enabled so no breakage would occur. I also wondered if operators could be 'used' into scope, just like we can have many definitions of a named function with contrasting signatures, and use sorts them out. ```use std::ops::autoborrow::{add,mul,div...}``` &gt; you can always implement them separately for the reference type and use let c = &amp;a + &amp;b; this 'just looks really gross' .. it might sound irrational but programming involves building up intuition over years and this breaks a lot of that. I know people who give up at ```fn``` , ```mut```, and I've already spent many years fighting my instinct on other issues. I have a threshold where enough is enough. it might be because of the implications for raw-pointers arithmetic (a whole other subject) but also the way you learn to read + and &amp; as operators (and learn to read them meaning different things in prefix/mid-fix contexts) . + &amp; just looks like an typing error. I'd rather revert to named functions at that point.. a.vadd(&amp;b) causes less discomfort despite being more to type. I already expect th e "." to auto-borrow. the second &amp; is unfortunate but there's only one. named methods can be more useful in other situations (i.e. they can be more pleasant regarding nesting and operation order.. you can write a sequence of operations in the order they'll be done)
Ah, that may be true. I just noticed the name in their tech stack.
Any plans to run the Rust compiler itself in Wasm as a test case? LLVM can already run in browser (with some modifications) https://github.com/tbfleming/cib
Any examples where traits cause problems in Rust?
That would be such an interesting project! We will research a bit in the near future about it and if we can get some easy wins for sure we could make it happen!
I strongly disagree with the rest of the comments here. I think the nomicon is foundational material that will really help people get better at Rust quickly. Indeed, I think the name is a huge mistake because it implies arcane and impractical knowledge, and dissuades people from digging into it. Really it's just a nice explanation of what the various machinery you use in Rust is actually doing and how it works. Read the Nomicon.
come to think of it , a named function with an autoborrow option would be preferable to ```&amp;a + &amp;b``` ... ```a.vadd(b)``` 'autoborrow' already happens for 'a', it's not unexpected for it to happen for 'b' aswell. it might be that named functions but just getting rid of the ampersands everywhere would be enough 'de-noising'. Writing a function, I have a clear idea of whether I want it to borrow or consume; as such the expectation will come from the function name and context. I already expect a mixture because of time with C (```free(p)``` effectively consumes p,etc)
Can anyone ELI5 what this is used for?
I haven't stated anywhere that it's impossible to get them in Rust, so IMO this is imputing and arguing with things that I haven't said. I meant that in my daily experience with Rust these problems are totally gone. I don't have to worry about them at all. Yeah, they can technically still happen if you really try, but it's a huuuge difference between C/C++ where you can just make a silly mistake and get them, and Rust in which you have to "accidentally" use `unsafe`, or write `std::mem::forget`, or go out of your way to make a a cyclic graph or reference counted pointers. :) And people who want to dismiss Rust, because it sounds too good to be true, and technically you still can have all these issues, are probably not going to change their mind no matter what and it's totally fine with me. :)
http://termbin.com/5qs8x
To be fair Python is over 25 years old and all its native toolkits are pretty much dead. Most Python programs I know of use pyqt.
What is also very interesting is the insight that a compiler or build tool should not only be able to enumerate all the input files which a module, library or compilation unit depends from, it should also be able to name the files along the include path which would alter the result of the compilation if they were created anew. A slightly braindead example in C: Lets say I have a program calculator.c which depends in /usr/include/math.h . Let's say I install an alternate math library which lives in /usr/local/lib/libmath.a , and has the include file /usr/local/include/math.h Now, if one uses "make" and just does "make calculator", make would not recognize the changed dependency. It would be necessary to issue a "make clean" before. redo, with proper compiler support or appropriate manual build rules, would recognize that some dependencies have changed and a re-build is required. 
What version of emacs are you running? Also is it pure emacs or something like spacemacs? I'll see if I can duplicate the bug on my side. 
Learning Rust via "The Rust Programming Language". I was hoping to make a simple, but dynamic website with nginx bindings. How much more work would this produce compared to writing the backend in, for example, Java? Although this is just a hobby project, I don't want it to be too time consuming. Is it still too early to start building anything web-based with it?
Congratulations! This is very nice!
It's the latest version. I believe 26? It's pure Emacs. I do have a config with a few modifications though.
Let me see if I can simulate with a clean 26 config and get back with you tomorrow. 
Now that we have crossed most items for version 0.1.0 we will have to broaden it again - good to receive suggestions on what is missing :) The original reason I wanted to build the stats library on top of ndarray (into ndarray actually) is to provide a foundation for machine learning use cases. And I think that for that purpose it makes more sense to provide these functionalities on n dimensional arrays.
Thanks! I appreciate it
I agree, the tone of the article coupled with the factual inaccuracies are very prone to evoke a negative reaction in people, but the actual information that's coming through in the article leads me to believe that there will be more Rust jobs soon.. &gt; there's actually no demand right now, just that some Rust advocates believe there will be A lot of developers at companies have a say in which technology/language will get used. As more programmers fall in love with Rust, they will suggest to their CTO to use Rust, which will lead to more demand for Rust developers. Also, once the demand is high, you'd have a higher chance of getting the job if you already have a lot of experience in Rust, so I wouldn't recommend waiting until there's demand..
Who is narrating this video?
I think it's more like Ada is a niche language and Rust is also not mainstream so very few people need Rust/Ada interoperability, that's why no one has written specifically about it.
When you write a function, you want it to accept as many different inputs as it could handle. In the case you were showing, `foo&lt;I:IntoIterator...` can handle more cases that `foo(&amp;[u8])` cannot. So the former is preferable. Technically, in both cases the input argument are consumed: it is just happen to be the case that `&amp;[u8]` is reborrowable, so you can write ```rust fn foo(bytes: &amp;[u8]){...} let bytes = &amp;[1,2]; foo(bytes); //&lt;-- reborrow happens, a temporary reference was crated and passed and consumed foo(bytes); //&lt;-- so `bytes` are not consumed ``` but not ```rust fn foo(data: impl IntoIterator&lt;Item=u8&gt;){...} let bytes = &amp;[1,2]; foo(bytes); //&lt;-- reborrow does not happen //foo(bytes); //&lt;-- `bytes` are consumed, you cannot use it again ``` So yes, there is a hole here, and here is some discussions about this: https://internals.rust-lang.org/t/a-puzzle-and-why-generics-are-not-generic-enough-right-now/8042 An RFC (closed for future reopen) https://github.com/dhardy/rfcs/blob/reborrow/text/0000-formalise-reborrows.md 
What I'm missing in vscode/win is several values, ostensibly "removed due to optimization" in debug builds.
OK，thanks
How does this relate to 1. [https://github.com/CraneStation/cranelift/tree/master/lib/wasm](https://github.com/CraneStation/cranelift/tree/master/lib/wasm) 2. [https://github.com/CraneStation/wasmtime](https://github.com/CraneStation/wasmtime) ... Is there any overlap or do all 3 happily co-exist?
[https://github.com/gfx-rs/gfx](https://github.com/gfx-rs/gfx) is expected to be quite stable in early 2019.
I 100% agree with your problem statement. In C++ most operators would operate on const&amp; values and I’d call it a day. In Rust almost every library implements math vectors as copy. And crosses their fingers that the compiler will do a good job optimizing.
Dynamic linking can definitely help if you're building a set of rust utilities in a single go (say for an beefy embedded platform).
I tried to use esperanto as a package name for node binding, but it's already taken.
automotive uses MISRA C, and I wouldn't be surprised if the others did too these days. The reason defense contractors have used it less and less that I've heard is that it's just incredibly hard to hire for compared to C.
Have you tried the approach suggested by /u/rakenodiax ? The Rust katas I tried in Codewars all use that approach. For example, for 8 kyu Multiply problem, they have: \`\`\` \#\[test\] fn returns\_expected() { assert\_eq!(multiply(1, 1), 1); assert\_eq!(multiply(2, 1), 2); assert\_eq!(multiply(3, 5), 15); assert\_eq!(multiply(6, 7), 42); assert\_eq!(multiply(12, 9), 108) } \`\`\` Let me know if you have further questions.
What happens on panic!?
_You_ panic.
I found this article interesting https://www.adacore.com/press/deep-blue-capital-financial-system-development
Basically... If you look at the videos, I had no way of actually controlling it so I would just kill it or slowly descend it lol. I did end up breaking an arm once and several propellers.
Great point, I think the reason that no one thinks Ada is useful outside Defense and Aerospace industries. And that Rust is still in its infancy is what attracts me to want to utilize them both in some mainstream projects. 
You’d need to modify the compiler heavily; for example, wasm has no threads yet.
Windows: deploy on whatever windows versions you think your user should be using the cli into, like win7, 8 and 10. Linux : Debian for distro that use deb packages (Ubuntu etc). Make rpm packages for people that use that, and lastly (but not that necessary) an AUR package for Arch (not that necessary because arch users tend to make those themselves once they start using stuff) Apple: i don't really know. All in all if you need to know what to compile your tool to: i686-pc-windows-(gnu or msvc) i686-unknown-linux-gnu i686-apple-darwin i686 for 32bit (can be run on 64bit machines too) and x86_64 for 64bit (can't be run on 32bit machines) 
64 bit windows, linux (you can use cross for cross compilation to arm)
Do not use RefCell unless you absolutely need runtime overhead. Use Cell instead
In regard Debian, we (the rust-pkg debian team) are happy to package whatever is DFSG-free as long as it's maintainable in a sensible way (which most of the Rust crates are). It gets built for many architectures, and also drips down to derived distributions such as Ubuntu. Of course it makes sense to have your software in a state that you want distributed in such a way, as the versions packaged with a Debian release tend to stay around for quite some time.
You're right, if that's possible it should be used. We haven't investigated this yet, the problem is currently not too large (yet?). We have kind of a special case in our company, as we distribute the software as Debian packages which always get built from scratch, so the caching is a possible solution during development, but not when packing up a release.
How mature is the Rust packaging infrastructure for Debian? Like what should I do if I want my Rust programs easy to distribute in the Debian main apt repository?
True. I was operating on the assumption that you'd be doing something like Qt on Android or BusyBox, where the added complexity of splitting your tooling across multiple binaries with share an unstably ABI'd library doesn't really gain you much.
ah! ok, got it. It seems obvious in retrospect that to make it live longer I should create the package and document before calling my method to parse it. [Here](https://gist.github.com/ian-p-cooke/b4d74a8459814d881c6f6510bf1c6f7b/aab54d349839f15ce73a7798ad81a1d3c21d9ba9) is the final version of my example that works based on your suggestions. I changed it a little to show why I wanted to keep the tags as &amp;[u8] (because I will be given &amp;[u8] later that I need to compare it to). Thanks!
You raise a valid point, even though we are still early days. I think that a well-designed API, with good documentation and a clever use of the type system, can go a long way in pointing the user in the right direction. Nonetheless a tool remains a tool and it does require some knowledge to be used correctly. Thanks for bringing out Apache Common Math, I'll make sure to have a look at it!
&gt; I wanted to make `handle_connection` a method to give the server an API to configure the routing So if you did that you would want to pass `handle_connection` the routing information instead of `self`. Something like: let routing_table = self.routing_table.clone(); self.pool.execute(move || { handle_connection(routing_table, stream); }); that way you give the function just the info it needs instead of all of `self`.
I’m going to put in a vote for amd64 FreeBSD as well. [trust](https://github.com/japaric/trust) makes it possible to build for FreeBSD on Travis CI or you can use the native FreeBSD image on [sr.ht](https://meta.sr.ht/).
It surely still has some issues to be ironed out, but these are mostly in the organizational and infrastructure space (e.g. how do we determine which binary packages are affected when we update a library crate; how do we prevent updates from breaking [build-]dependent packages). The process of packaging is rather robust, and all crates by default get packaged up as source code trees that serve as vendored dependencies when building binary packages. **TL;DR for below**: easiest for us is if you keep your dependencies up-to-date. Apart from getting everything build on different architectures (of which debian supports many), the most issues come up with non-coordinated updates of dependencies, resulting in having multiple versions of the same crate in the dependency tree. We usually try to package the latest version of crates only, and push upstream to update to this version. Sometimes this is not easily possible, because e.g. crate A has decided to drop compatibility with older compilers, crate B which depends on A has decided they want to keep the compatibility, so they don't upgrade even though it would require only little changes. In these cases, we patch in the new version of crate A as a dependency to B.
Or just the ARM controller
If you have a concrete project you would like me to take a look at (even if it's not ready for packaging yet), just drop by in #debian-rust and ask me, or write me an e-mail. You'll find my e-mail on the relevant package descriptions, e.g. in the uploaders link at [https://tracker.debian.org/pkg/rust-hexyl](https://tracker.debian.org/pkg/rust-hexyl)
Amazing video! Is anybody know the name of color theme of VS Code in this video?
A quadcopter that doesn't crash? I want that!
Should just be the emscripten variant, you can’t do much with a random `wasm32-unknown-unknown` file that only exports a main function because it can’t do any I/O. The reason to use emscripten is that it allows it to do I/O.
This reads like an article in my local newspaper about any technical subject. I would guess they found a few people with knowledge of the subject, took a few quotes from them and made an article about it. It's not very accurate, and I get the feeling the writer doesn't really know what's a well-known fact and what's just someone's opinion. Probably just a journalist trying to do their job — I would be really surprised if this was written by a developer. Which, as you pointed out, means that Rust is getting more mainstream attention!
Yes.
It sounds like your compiler doesn't properly return the borrowed references to the fields hashmap. You should look into why that is.
At last some sense :) we should have the option, right? And it should be possible to non-destructively retrofit because it could be an opt-in , whether it's per type or per source-file (the operator is a name, and we regularly 'use' to get different functions into scope)
 Wiring section added to the readme.
You might try to use strace to look at what files the program maps into memory on startup.
:( oh well that's a shame
I'm interested in using these abstractions in my backend as well, to be able to define request handlers with closures. Would it be possible to factor out these actix abstractions into another crate that's separate from the exonum framework?
This man voice sounds like he gargles caltrops before going out dressed as a bat at night in a eastern european country.
For Apple, you probably want to create a formula for Homebrew. Also, on Apple, there is probably no point in creating a 32 bit distribution.
Hi, I'm new in rust and I'm starting to play with third crates. I come from C++. I wanted to generate a random number so I used the crate `rand` with a cargo add rand When I compile this code, it's works but I don't understand why. ``` fn main() { println!("{}", rand::random::&lt;u8&gt;()); } ``` WTF ?! I didn't write any `use` or even a `extern crate rand`. So I assume rust compilation creates implicitly a new scope CRATE_NAME for each crate. Here this is the crate `rand`. --- When I compile this code it doesn't work : ``` fn main() { println!("{}", ::rand::random::&lt;u8&gt;()); } ``` WTF 2 ?! So rust create a namespace rand but it does not include it into the global namespace ? --- This code works, so it confirm my thoughts : ``` extern crate rand; fn main() { println!("{}", ::rand::random::&lt;u8&gt;()); } ``` --- But when I try to compile it doesnt work : ``` use rand::random; fn main() { println!("{}", random::&lt;u8&gt;()); } ``` Why ? namespace rules doesnt apply for `use` statements ? --- These two codes work (the only difference is `::` in `use ::rand::random` line : ``` extern crate rand; use rand::random; fn main() { println!("{}", random::&lt;u8&gt;()); } ``` ``` extern crate rand; use rand::random; fn main() { println!("{}", random::&lt;u8&gt;()); } ``` So I a bit lost how rust handle namespaces Can u enlighten me on the subject ? Or maybe do you have some links ? Thank you very much
&gt; This can be solved by making Vec3f derive from Copy. I know this. But that solution makes me uneasy. Agree 100% what we need is the option to allow both parts. going back to game maths after delving into ML/AI I want to retain the generality for n-dimensional vectors; I don't want to impose the narrowing of copy as a hack to reduce the number of &amp;s peppering the code. related posts https://www.reddit.com/r/rust/comments/9zdqf5/maths_frustration_borrow_vs_copy/ https://www.reddit.com/r/rust/comments/9znafw/autoborrow_optionfeasibility/ can we get enough support to get this fixed - it should be possible to get the best of both worlds a #[autoborrow], or a per module option perhaps. Its ok if people say "it's too hard to retrofit" , but I'm fed up with this community making excuses 
&gt; Sure it's not 'pretty' code, but that's irrelevant. No it's relevant. the language has to sell itself. people have to pay a cost getting used to it. Rust has a reputation for being **UGLY** and this is one reason why. Paying the cost of throwing C++ away it should be possible to get a 100% improvement in every use case as a reward, but this community keeps making excuses for these omissions
stop making excuses. we have auto borrow for receivers, and it works fine.
 duck_and_cover(self)
Is it UB even if you use UnsafeCell? Wouldnt disabling optimizations that assume a mutable borrow is exclusive also remove the UB?
Plus the lack of support for HDF5 to be able to communicate large amounts of tabular data to e.g. Python and other applications. But it's in the works :)
&gt;Any ideas around integrating lexing and parsing? Alexey said: &gt;A nice trick to make parser more general and fast is not to construct parse tree directly, but emit a stream of events like “start internal node”, “eat token”, “finish internal node”. That way, parsing does not itself allocate and, for example, you can use the stream of events to patch an existing tree, doing minimal allocations. This also divorces the parser from a particular tree structure, so it is easier to plug-in different tree backends. [https://matklad.github.io/2018/06/06/modern-parser-generator.html](https://matklad.github.io/2018/06/06/modern-parser-generator.html)
I found a begin of a response : https://blog.rust-lang.org/2018/10/25/Rust-1.30.0.html#module-system-improvements
Could you clarify a bit the differences between i686-pc-windows-gnu and msvc? i.e should I create deployments for one, both..? Linux is still the most complicated for me to understand. I plan on deploying to i686-unknown-linux-gnu, but TBH I don't know what else. I honestly don't understand terms like ARM, Amd64. Could you dumb it down for me to simply understand? Mac is pretty simple for me to understand, I'm most likely deploy with x86_64-apple-darwin as a homebrew formula.
Did you take a look around this subreddit before posting? If not, do it now and let me know if you still think it is for the Rust game?!? 
I once tried writing one as well.
There are already some experiments around this issue, see [here](https://github.com/rust-lang/rust/issues/44619).
Yeah... I really didnt look sweet spoiler though, saved me a bunch of time. Much obliged.
As others have mentioned, you've accidentally found the wrong subreddit. It happens from time to time here so no big deal. /r/playrust is what you're looking for. In the meantime server wipes are pretty much what they sound like. Servers get reset periodically back to a base configuration. It's apparently different per server but there are mandatory ones for patches and such. It resets all progress but it also gives people and chance to start over from scratch and rebuild things. I don't play the game so you can get more info from the people in the rust game subreddit. But I've played games with similar concepts and I don't work today so I did a quick check on their subreddit for you. I hope you have a good day and if you decide to take up programming we'll be here for those kinds of questions for you. =)
Thank you for the information very helpful. I read a brief snippet about rust programming whist looking up the game. I'm currently learning python extremely slow(hobby and it's free to learn). If I ever switch to rust I will be back. Thank you again for the information and the redirect to the right sub.
Hi, thanks for asking, we must have missed the notification. Sorry for the delay! Generally, there's no team tending for CC of the videos (we tried to build one, also for translations, but currently have not takers). It's a best effort by the youtube channel team. If in doubt, you can always ping through community@rust-lang.org. Thanks for the fixes and we'll make sure to keep a better eye there! Best, Florian
`drop(copter)`
You still have to avoid data races. It’s not a license to do whatever you want. In my understanding, since the ref cell panics, you are still causing a data race.
Although rust has fast updates, it has extensive CI infrastructure, and I don't think there have been many (any?) regressions from stable, so it's not quite the same as version 2.0, 3.0 etc.
Not a language problem per se, but...tooling.
What do you mean with avoiding data-races if it's not Sync? Is that possible? The only thing I could see is using some kind of _nonoverlapping with mutable references that do overlap. But if you use UnsafeCell + that you are asking for trouble, you better be extra careful.
I’m speaking generally. As I said, I don’t consider myself an unsafe expert. But “refcell panics so I just wrote unsafe to get around it” *smells* bad to me. If it were okay, then refcell would work. (And refcell uses unsafe cell inside so that’s not the difference here.)
You are completely right, this just smells bad. But I would like to know why RefCell panics.
It's totally free to learn rust too. Tons of resources and the community is wonderful. Python is a wonderful starting language though. You can be productive very quickly. Feel free to shoot me a message if you ever need help or resources and if you decide you need the speed and power of rust for a project this is a great place to get advice and starting points. Good luck in both the game and your programming hobby.
It's amazing.
Msvc or gnu doesn't really matter from an user standpoint, it depends on what tool chain you have. If you are on windows and installed the visual studio build tools go for Msvc, otherwise gnu. Arm is another architecture and is generally found on embedded devices (like mobile phones). Amd64 is another architecture. 
Except you're 100000000% wrong and arguing in extreme bad faith, changing the argument to make yourself "right" by qualifying with "if it does no work at all", something that was not mentioned before. Which proves my point, going in an infinite loop is not a memory leak. You have to further qualify it with "does no work". Or are event loops that have work memory leaks too? They'll loop infinitely until the program closes, or maybe the program stops them. You might say it doesnt count if the program can stop them, but the main thread can close a child thread too, so now you have to further change the argument to be "right" by adding "keep no reference to the child thread", moving the goalposts further back.
Have you looked into [sccache](https://github.com/mozilla/sccache)? It handles automatic caching of intermediate build artifacts. I have no idea what storage reclamation features it supports, it any. &gt; My idea is that each time you would run "cargo build" it would populate in the ~/.cargo folder a database containing where is located the Cargo.toml file of the project and its current dependencies (transitively even perhaps). When cargo would download a crate it would also keep track of the usage of the dependency. It would allow cargo to "reference count" the usage of crates for the local project using the dependencies. Personally, I worry about this being brittle. I think a simpler approach is tracking the last time an intermediate artifact is referenced ("atime") and delete old items.
&gt; accidentally forgetting to remove items from it when you're done with them. Then thats A) a bug and 2) Yes? Thats leaking memory? But Drop will be run when the hashmap gets dropped. Why do you all need "Drop is not run on items currently in use" spelled out for you? I would think thats a fairly simple concept but apparently not. &gt; The fact that you can cause pretty much the same behavior by just stuffing something in a cycle of two Rc's. Cycles should be considered a bug IMO. &gt; it has to be in a "safe" state afterwards where you can't cause memory unsafety by using its normal API. Memory leaks aren't considered unsafe, so i'm not sure what you think changes if "Drop is going to run *except* in these specific circumstances" vs the current "Drop doesn't exist, there are no guarantees it will run, which includes at the end of your scope, with no panics or other references, or forgetting it. No guarantees!", and your entire invalid argument hinges on something about that changing even though i never said it would.
&gt; Even if your destructor just prints to the terminal or something it's a behavior that doesn't occur in any of the leaking cases. So? That might not happen now either! Theres no difference! &gt; And the language doesn't take the stance that "destructors don't exist". Yes it does, by virtue of having no guarantees about destructors there, even safe code can't rely on them, *thats what **no guarantees** means*
[ccache](https://ccache.samba.org) for Cargo is desperately needed IMHO: I've been thinking this for a while. I would prefer the approach ccache uses of keeping a separate binary cache directory on my machine somewhere and building dependencies into that instead of `target/`. I really am ready for stuff to stabilize so that we can start using shared libraries instead of statically-linked binaries, but in the meantime I think this is about the best you can do.
it is an interesting approach. It might not be well supported in every operating system, alternatively cargo might log this simply instead of the sort of dependency graph with versioned I imagined. As you said way less brittle.
`!Sync` is an unstable way to specify that a type does not implement Sync.
Ok, so that clarifies up Windows for me. As for linux, with something like i686-unknown-linux-gnu, what does this mean? i686 -&gt; 32 bit unknown -&gt; unknown what? linux -&gt; OS gnu -&gt; required toolchain So suppose I only build this toolchain on Linux, will this cover everything (except embedded, which I'm not really aiming for either)?
No need to preempt the kernel for realtime performance?
Unknown because you can't possibly name every single distro out there 
&gt; It might not be well supported in every operating system, alternatively cargo might log this simply instead of the sort of dependency graph with versioned I imagined. Sorry I wasn't clear; I was imagining sccache tracking this rather than relying on the OS, which was why atime was in quotes.
Is there a specific concern with sccache? I've not used it myself but it seems like some people are using it regularly.
&gt; the current "Drop doesn't exist, there are no guarantees it will run, which includes at the end of your scope, with no panics or other references, or forgetting it. No guarantees!" idk where you get that idea from. When they say that "destructors are not guaranteed to run" what's meant is that they aren't guaranteed to run across the entire possibility space of Rust programs in general. If you run a specific program like struct Blah; impl Drop for Blah { fn drop(&amp;mut self) { println!("Blah"); } } fn main() { let blah = Blah; drop(blah); } one million times, that destructor ought to also run one million times, because this particular program represents a specific sequence of unconditional instructions.
Historically the reason was because it introduced ambiguity between less/greater than operators and such. I believe an RFC was accepted to change it though.
Turbofish is the ::&lt;&gt;, so why it's ugly is up to you, I actually like them. As for why they exist, it's because it's freaking hard to parse without it. There actually is a poem in homage of it being hard, so nobody ever tries to remove it again. The poem is. Beware travellers, lest you venture into waters callous and unforgiving, where hope must be abandoned, ere it is cruelly torn from you. For here stands the bastion of the Turbofish: an impenetrable fortress holding unshaking against those who would dare suggest the supererogation of the Turbofish. Once I was young and foolish and had the impudence to imagine that I could shake free from the coils by which that creature had us tightly bound. I dared to suggest that there was a better way: a brighter future, in which Rustaceans both new and old could be rid of that vile beast. But alas! In my foolhardiness my ignorance was unveiled and my dreams were dashed unforgivingly against the rock of syntactic ambiguity. This humble program, small and insignificant though it might seem, demonstrates that to which we had previously cast a blind eye: an ambiguity in permitting generic arguments to be provided without the consent of the Great Turbofish. Should you be so naïve as to try to revolt against its mighty clutches, here shall its wrath be indomitably displayed. This program must pass for all eternity, fundamentally at odds with an impetuous rebellion against the Turbofish. My heart aches in sorrow, for I know I am defeated. Let this be a warning to all those who come after. Here stands the bastion of the Turbofish. You can see it here: https://github.com/rust-lang/rust/blob/master/src/test/ui/bastion-of-the-turbofish.rs
Read up on the architecture, dingles are parts of a version with conflicting content, ie what a merge conflict is in git, except versioned instead of being outsourced to a text wrangling tool like diff
It leads to ambiguity in some cases. See https://github.com/rust-lang/rust/blob/master/src/test/ui/bastion-of-the-turbofish.rs. Also, your first example can be written as just `let n: u8 = "7".parse().unwrap()`. 
Unfortunately there is currently no Rust support for the ESP32. Apparently an LLVM backend for xTensa processors is being worked on, at which point Rust support would be feasible.
No it wasn't accepted yet. See the RFC here -&gt; https://github.com/rust-lang/rfcs/pull/2544
Thanks for the clear answer, I'm not the only guy who think this is an heresy a notation like this
Any of the Arm chips would work fine here running bare metal. I've worked on multiple drone C controllers running on baremetal controllers in that performance bracket (PIC32, dsPIC33, etc.).
This sounds awesome, I hope the conference is a huge success. I'm very tempted to apply (with some of my music/game/UI work) and am posting this as an initial gauge of interest.
Here's one suggestion for an implementation strategy: &amp;#x200B; [https://github.com/rust-lang/cargo/issues/5931](https://github.com/rust-lang/cargo/issues/5931)
Ok, that's very helpful. One last thing: Should I be using things like Musl or what I mentioned before?
Haven't tried plain Vim with Rust, but Neovim+ALE+RLS combo is freaking fantastic. But yeah, Vim's learning curve...
Thanks!
Yeah but is it possible to use this syntax only in this situation ? And avoid it in all others (which means 90% of cases)
This is one peice of Rust ugliness I actually accept the need for; in C++ you can write ```a&lt;b,c&gt;d()``` and you can't parse it until you know the definitions of the symbols, so the include order becomes critical. The turbofish notation allows parsing of the structure without this constraint. it's ok because it's not needed in the *type* context, and usually the types are inferred. I suppose you could have a special case for a *single* parameter , i.e. ban being able to write operator &gt; on the result of operator&lt; but that doesn't help with multiple parameters
Maybe some of [these](https://stackoverflow.com/questions/413477/is-there-a-good-valgrind-substitute-for-windows)? I can't tell whether they work with Rust binaries or not, but that's a place to start at least.
Thank you!
I've used drmemory successfully. 
I know it should be a difference on used libraries for system calls and whatnot, but I can't tell you the specific differences. Also you need to install the required toolchain while there's a pretty good chance you already have the one for gnu
Uh I think it's fine. I'm nearly linking it for you. Might want to chill on your user of inflammatory language. That stuff doesn't fly around here and doesn't produce any useful discourse
How does this compare to the lexing capabilities of (`lalrpop`)[https://lalrpop.github.io/lalrpop/tutorial/004_controlling_lexer.html]? Is there any way to reproduce the 'tiers' of tokens so I can have some regexes prioritized over others? Otherwise it looks like a simple wrapper would be sufficient to replace the lalrpop lexer with this, which is exciting!
Not even just that, but which rules do you use when? How can you know how to without type system information which only comes after parsing? It's basically impossible
I think you'd want something Nix-style for this, like [cabal-install's Nix-style local builds](https://www.haskell.org/cabal/users-guide/nix-local-build-overview.html). I.E. just hash up all your exact build inputs and store the cache at a path with that in the name.
The problem is that sccache somehow includes the path in the cache key, which means multiple projects using the same dependency will not share anything.
`&amp;*boxed` gets you a slice reference, which can be converted to `Vec` with `.into()` in a context that infers the `Vec` type.
\&gt; Do you think this idea is worth exploring further or maybe it is an already existing idea ? \&gt; What is your opinion ? Cargo maintainer here. There are \*a lot\* of good ideas worth exploring in this space! There is even some existing implementations. Like [sccache](https://github.com/mozilla/sccache) (used by rustc build system it self and Firefox) that provides cloud caching of artifacts, but requires setup and needs maintainers to push it to be more ergonomic for other uses. Or cargo's built in support for specifying a shared \`CARGO\_TARGET\_DIR\` witch works grate but dose not clean up after itself. `cargo-sweep` is a tool for providing that clean up functionality, that is very young and needs to be tested and the corner cases worked out. You suggested another approach for keeping track of what needs to be cleaned, please give it a try and let the cargo teem know how it worked out! The Cargo teem discussed this briefly at the lats meeting. The consensus was that we want these gc tools to be made, try any idea you want! If cargo is actively making you life harder, we will consider changing it. If there is data that is necessary for the tools to develop, let us know and we will try to make it available. We want to encourage a diverse ecosystem. Previous discussion: https://github.com/rust-lang/cargo/issues/6229 https://www.reddit.com/r/rust/comments/9ram5g/rust_recompiles_same_crates_in_different_projects/ https://www.reddit.com/r/rust/comments/9owc1o/more_space_for_cargo/
Somewhat unrelated to your question, but I do recommend people to migrate away from the old `MessageItem` enum to the newer generic `arg` infrastructure instead. You can't implement `arg::Append` and `arg::Get` for `rlua::Value` (and `rlua::MultiValue`) in a third crate due to Rust's orphan rules, but that should be possible to work around with a simple newtype, so you can write stuff like: m.method_return().append1(MyNewtype(&amp;myLuaValue)); That will be both more performant and more ergonomic, I believe.
And in C++ there are contexts where you don’t know how to parse it until *template instantiation time* which would be pure madness, forcing you to disambiguate with the `foo.template bar&lt;&gt;()` syntax which is quite a bit uglier than the turbofish.
How exactly is digging up three-week-old comments and taking a piss on someone's head for disagreeing with you a constructive use of your time? The only thing you've accomplished here is convinced me to ignore you from now on.
I've enjoyed your talks before so I'd be interested in seeing you talk more personally
It's finally stable
Wasn't this the old `ref_slice` that got removed?
No. It is always ambiguous for parser.
Yeah, I used a Pi in a quadcopter a while ago. It had 7 minutes if I flew it slowly previously, down to 2-3 minutes with the Pi (but with obstacle avoidance, which is nice). A better solution if you need the processing power of a Pi is to do the data processing on the ground and use a low latency/high reliability protocol to communicate.
This is the [cache](https://github.com/mozilla/sccache) you're looking for.
In theory. After upgrading to 18.09, it doesn't work for me anymore. But I haven't really investigated. Before that I post-processed the output with sed so that it would parse ;) What version are you using? How is your setup/build scripts?
Figuring out the borrow checker and understanding lifetimes. Also, traits are a weird concept but fairly easy to get the hang of, and I think actually more intuitive than classes.
Go [does this](https://golang.org/cmd/go/#hdr-Build_and_test_caching). It also caches test results. It is definitely worth exploring.
Sorry for the following ramble; I've only had one coffee today thus far. The biggest (in general) is architecture. Rust really doesn't like conventional object-oriented designs. Simple ones are okay, but anything involving object graphs or dynamic casting will make you miserable. That said, if you're coming from C, that's probably much less of an issue. What will be an issue is how strict Rust is about pointers. A doubly-linked list is actually hard to do in Rust, because the pointers form a cyclic graph and Rust *hates* cycles. The other thing Rust hates: sharing+mutation. If you start to reach for it, consider if you *really* need it. If you do, carefully consider how you're going to do it, because every solution involves trade-offs. In terms of advice... probably the biggest thing is this: you *need* to see the compiler as an ally. You will almost certainly find yourself getting frustrated at the compiler rejecting code you *know* is correct. Take a deep breath and remind yourself that the whole reason to use Rust is because humans are fallible, and the compiler is doing its best to compensate. It's trying to help; if you can accept that, and accept that it has limitations of its own, you'll be a *lot* happier. If you maintain that attitude, you will *eventually* reach a point where your reaction to borrow checker errors stops being "this garbage piece of crap know it all hateful bastard akjhaksdfo98&amp;$*()&amp;@!(#*&amp;!", and instead becomes "oh right, you can't understand that; I'll try another way". ... well, that or you'll all go insane and start eating each other. Beyond that, you need to force yourself to consciously consider what kind of pointers you're dealing with. Specifically: is it owned or borrowed, is it shared or unique, and do you need mutation. Speaking of borrowing: make sure you spend some time grokking the limits of the borrow checker *before* you get into any serious design. It's not that hard to design yourself into a corner you can't get out of. Possibly the most important insight on the borrow checker: with the exception of `'static`, lifetimes always come from a stack variable. If you can't explain how the stack lifetimes are going to work for a design, you haven't thought it through enough. If you catch yourself thinking "heap lifetime", then your design is probably a non-starter. Prefer structurally simple solutions where possible. The compiler can "see" through direct struct field accesses, but not accessor methods or functions. Public fields are not an anti-pattern. Which reminds me: expect to have to compromise on encapsulation. Sometimes, the only reasonable way to make something work is to expose the borrowing structure to the user. For my current project, I wrote an "iterator" that required two levels of setup on the user side due to how the borrows ended up. I couldn't use the standard `IntoIterator` trait as a result, but oh well. It was that or giving up on having an iterator at all; it happens. Sometimes, going a more functional route can help a lot. Again, current project: I replaced a lot of inline mutation with functional copy, update, replace. Code ended up a lot cleaner... and I could now throw `rayon` at the problem. The dumber, more copy-happy code ended up being ~60x faster on some data sets as a result. Finally: don't be afraid to give up and resort to copying and heap allocation. It's *real* easy to get stuck trying to satisfy the compiler whilst still maintaining maximum efficiency, when you could have solved the problem two hours ago by just copying that damn variable. Although, to be honest, that's really more a reminder to myself...
I don't actually use it. I just played with it a few weeks ago and it produced Nix expressions that seemed really good to me. Maybe open an issue on its issue tracker if it's not working for you?
You'll likely struggle with the borrow checker and lifetimes at first. The compiler is fairly strict with what it'll accept. This was very frustrating for me at first, as it was often a battle to even get my code to compile. Another thing is that many operations force you to handle errors in some way, and others ensure you can't get errors (e.g. `for x in xs` can't have out-of-bounds access). Often you'll see functional-esque code to deal with Option/Result/Iterator types, as they often ensure you don't have runtime errors, e.g. `some_option.map(|x| x * 2)` will skip the multiplication if some_option is None. These patterns might be unfamiliar at first (depending on prior experience), and the team might miss out on a lot of the power of rust by falling back to C-esque patterns. This is a concern for much of rust, e.g. Vec as a more general array, String always being utf-8 backed by a Vec&lt;u8&gt;, and things like parallel iterators (rayon) making tricky work into something you barely need to think about, in many cases. As always, when learning a new language, try to suspend the opinions you hold until you've worked with it for a while, and can evaluate aspects of it independently of other languages, and then draw comparisons.
This is a step past initial learning, but if you try to get into async programming, you'll find that the ecosystem is in flux, there's a steep learning curve, the error messages can be hard to grok, because they involve lengthy type signatures, and the documentation isn't quite there yet.
I've been trying to recreate a project at work that heavily interacts with Windows syscalls. Arguably the hardest part for me right now is trying to figure out a way to represent all of the bitfields used in the structs since Rust does not support them at a language level. The winapi and bitfield crates handle this by using macros to define getters and setters for the fields, but it feels so bad. There are so many structs that I've been debating writing a tool to do translations, but then I'm creating another problem for myself when it'd just be easier to write it in C. So to answer your question: the ecosystem and language still don't seem mature enough to jump into rewriting "simple" projects without investing more work into creating the necessary translation layers.
could trait-object vtables be used for dynamically (re)loadable modules / plugin architectures ?
The discussion in that RFC is really cool, the though process of how changes fit into the edition life cycle / trade offs between complexity for the parser vs rust users is interesting.
You and I are in violent agreement I think. Cargo built-in ccache-like functionality. 
A bit of a stretch, but could you not change the signature to take an `impl IntoIterator` instead? That would support passing a `Vec`, a `slice`, OR an `Option&lt;MessageItem&gt;` (so you'd simply pass `Some(item)`)
Thanks! I am really looking for cross-project integration with Cargo. Will this do that? 
Yep, there is already [an issue about this](https://github.com/maciejhirsz/logos/issues/16) :)
doesn't that defeat the purpose using the tool in the first place?
There's definitely no Arduino support for Rust currently. 
Having to let go of your security staff
I advocated rust to use [] for generics in the early days but people wouldn't listen
This is a brilliant post. I think there should be a document clearly outlining all the things rust cannot do so that as a learner I know where not to beat myself up . I have invested in rust and am glad I did but the learning curve would have been smoother I'd I already knew which patterns are hard in a clear separate section. 
I wouldn't advise this approach for large projects. Overusing the heap and Arc&lt;T&gt; will result in a bad design that's really quite difficult to incrementally refactor into a design that doesn't need that overhead.
We did have it for a while; we switched back. Both have the same downside, &lt;&gt; is more familiar.
Maybe you can use a pi zero w?
Hey there! This subreddit is for the Rust programming language, and as cool as it is and as much as we love new people coming along, you’re probably looking for /r/playrust 
It is worth mentioning [crossgen](https://github.com/yoshuawuyts/crossgen) I'm planning to write a couple of CLIs and FFI libs, and my strategy would be: use crossgen to build the multiplaform template for Travis, and use GitHub releases for installation scripts. This integrates well as precompiled package for Homebrew, Chocolatey and Arch AUR. My previous experience with packaging for Linux distros, I used [FPM](https://github.com/jordansissel/fpm). I've haven't used it with Rust tho.
Would you be able to shine some light a little on how you worked around that issue? And what you use Ada/Rust to interop for? 
Nah, the Pi could run the control loop at 140Hz.
I like this one [http://www.iri.upc.edu/people/jsola/JoanSola/objectes/notes/kinematics.pdf](http://www.iri.upc.edu/people/jsola/JoanSola/objectes/notes/kinematics.pdf)
Dang you're everywhere, my sensor crates are forked off of yours [https://github.com/martindeegan/i2cdev-sensors](https://github.com/martindeegan/i2cdev-sensors)
I sent a few pesos to your BTC address, but I did not find this video helpful. I kept waiting for you to go deeper into/explain some individual component or dissect an idiomatic example or something, because you're obviously very knowledgeable. Maybe I'm just missing a bunch of prerequisite knowledge that let everyone else follow better, but most of the video felt like: "so we'll poll all the futures and then go to sleep. Sort of. It's not actually a sleep, but we'll call it sleep. Meanwhile some other thread 't' sees a network packet arrive that the other future from earlier wanted, which had given its task handle away because it wasn't ready. I'm not going to talk about what's in a task, but you can easily imagine a task being something like a mutex, and now I'll answer this viewer question and refactor this block of code into another thing that's almost a future but isn't...".
Try to use rustup to manage your Rust toolchain(s). If your distro offers a rustc or cargo package you can try them out but I've had no end of pain from those. Use the 2018 edition: `edition = '2018'` in your `Cargo.toml`. It will be stable on December 6th 2018, so if you're trying things out before then you should use beta. The borrow checker improvements include much better error messages and fix a lot of cases where you code is _obviously_ correct but the 2015 checker rejects it.
Wait what?
Your first month should be 100% dedicated to fundamentals. Don't begin to port your work until month two. Give yourself permission to learn.
I also have a quadcopter written in rust :) Mine also targets the RPi3 but ideally will move onto a different (more powerful) SBC. 1. What's your IMU sampling rate? 2. What's your PWM update rate? 3. Since you're using the PCA9685, have you had any signs of saturating your i2c bus between reading from the IMU and writing to the PCA? 4. Did you experiment with computing vertical velocity (world coordinate z-axis) with the EKF by fusing the altimeter and barometer?
Yeah, it's quite a problem, but it's actually trickier to solve than it seems. There's an issue for that: https://github.com/mozilla/sccache/issues/207
Yeah, but the main advantage of `[]` is that these always exist in pairs, while `&lt;` and `&gt;` not always.
&gt; Unfortunately there is currently no Rust support for the ESP32. There is kind of... mrustc can build for it but last I knew it was held back on an old version of Rust, so might not be all that appealing. There is a similar ARM chip to ESP8266 though with small form factor [here](https://m.seeedstudio.com/productDetail/3139)($1.90), not sure if that's easy to get Rust working on or not? There's a development board [here](https://m.seeedstudio.com/productDetail/3140)($2.90). u/pcjftw
"Lifetimes always come from a stack variable" This wasn't obvious to me and improves my understanding immensely.
I highly recommend looking at the book "Programming Rust", not just the official rust book. I feel like the official rust book just gives you the key ideas, but "Programming Rust" is more practical, explaining common usages, patterns, and pitfalls, and some "why/how" which gives you a more wholesome understanding of the kanguage.. I guess I'm trying to say something like "even if you understand the theory, sometimes you just need more experience".
That you have to recommend a third party crate that involves macro generation *and* a secondary container to do this just serves to prove my point. :) I didn't say it wasn't possible; the issue is that you can't do it the obvious, simple way. You either have to use shared ownership and interior mutability, or "fake" it with a separate container whose elements are woven together with indices. In C, you just set up pointers and you're done.
I ran into this a bit back as well. In my case I was writing out files for the user to read and it was all one long line on windows. I never found a solution, but notepad is adding or has added unix new line support. https://blogs.msdn.microsoft.com/commandline/2018/05/08/extended-eol-in-notepad/
Isnt the lockfile stored in the project directory, not target dir?
You could do a pointer solution in Rust aswell using unsafe. Just like in C there would be all the same traps and invariants. So maybe it should rather be said that a doubly linked list is just as hard to implement as in C, but then Rusts borrow checker won't help you as much? I haven't tried to implement a doubly linked list using unsafe, but technically it should be the same, shouldn't it? But I fully agree with the rest of your points regarding the transition to Rust. Especially realizing that the compiler is your friend. I like to think it's my heavily mathematically inclined pair programmer, which always wants explicit proofs of my statements in the program. 
If I understand your post correctly, using `UnsafeCell` is _unsound_. If you `insert` into a HashMap, if it is at capacity, then it will re-allocate all of its contents. If you have a reference to something in the HashMap when that happens, that reference suddenly points to uninitialized memory and you've got yourself lots of undefined behavior.
Thanks! 
if you write byte by byte, replace `\n` with `\r\n`, perhaps?
A link to the book would be nice 😊
I'm talking about the files created by the build system.
I'd probably stick it in the method and/or in the documentation for the struct. If it does something really strange, having it in the struct documentation itself will be much more visible. I don't find myself looking at the documentation for trait implementations at all, really.
Ah, whoops.
It wouldn't have solved this problem. You're trading an ambiguity with relational operators for an ambiguity with array indexing. I was the one who advocated for angle brackets, because they're more familiar and don't really introduce any problems that square brackets don't have.
So? 
1 The whole thing was \~100Hz. 2 I updated the motors @ 100Hz. The PWM period was 2ms. This was the largest I think BLHeli ESCs could handle? 3 I never actually used the PCA9685, I was running software PWM. 4 I didn't get around to that
What computer did your friend run the parallel application on?
For others who are interested in working on a Rust quadcopter project, I started writing a [board support crate](https://github.com/JoshMcguigan/betafpv-f3) for the BetaFPV F3 flight controller. The benefit of this board is that you can also buy a ready to fly drone based on this controller, so you don't have to buy all the pieces separately, assemble the drone, etc. I also wrote a couple blog posts documenting some of the work ([one](https://www.joshmcguigan.com/blog/betafpv-drone-flight-controller-hello-rust/) / [two](https://www.joshmcguigan.com/blog/betafpv-drone-flight-controller-board-support-crate/)). The downside to using the BetaFPV F3 is that you have severely limited options when it comes to troubleshooting/debugging. I had to write a custom [bit-bang-serial](https://github.com/JoshMcguigan/bit-bang-serial) crate to send data back to my PC. But I didn't get nearly as far as OP, so congrats on that. Do you plan on going any further with this? I can imagine a future where the dominant drone flight control software is written in Rust. 
what is syntax non-ambiguity :S
Hey guys, this is my first post here, apologies if it's not formatted right. Rust is my first language, and I'm having a great time learning it. Having a little trouble with this project I'm working on, the loop in the code below works for the first iteration, however once it goes back to the beginning it gets stuck on "input the initial price" any pointers on how to fix this would be great, thanks! use std::io; fn main() { lifo() } fn lifo() { let mut initial_price = String::new(); let mut final_price = String::new(); let mut initial_list: Vec&lt;i32&gt; = Vec::new(); let mut final_list: Vec&lt;i32&gt; = Vec::new(); loop { println!("Input initial price"); io::stdin().read_line(&amp;mut initial_price) .ok() .expect("Failed to read line."); let initial_price: i32 = match initial_price.trim().parse() { Ok(num) =&gt; num, Err(_) =&gt; continue, }; println!("\nInput final price"); io::stdin().read_line(&amp;mut final_price) .expect("Failed to read line."); let final_price: i32 = match final_price.trim().parse() { Ok(num) =&gt; num, Err(_) =&gt; continue, }; println!("\nDifference: {}\n" ,final_price - initial_price); } } &amp;#x200B;
To further expand on this, I know it has to do with the return handling, for some reason when I enter an integer on the second loop iteration, rust takes a string, and the continue return then results in an infinite loop. &amp;#x200B; ps - don't mind the vectors up top. 
I am working directly with Andrea on exploring what we can do with Rust. Previously we worked together on the custom soft body physics tech and later the custom networking architecture for our engine. The current idea is to see if it isn’t possible to develop future engine modules purely in rust and expose their use to the rest of the engine by statically linking against a C api. I’d be happy to field any questions!
Yup! He had to kinda whisper so that his audio recording wouldn’t interfere with other people who were working. He was a little worried he sounded like a phone sex operator but I think the voice worked out really well :)
&gt; I’d be happy to field any questions What are some of the initial modules you’re targeting? What language is gameplay scripting in? What do designers / level designers interact with? Is the renderer going to be in Rust? What are you using to profile run-time performance? Have you run rust code on consoles yet? How was that experience? What Rust libraries do you currently depend on? What have the biggest pain points been? Biggest technical? Biggest non-technical? What have the biggest surprises been? Biggest positive? Negative? Ok I’ll stop there. :)
I know he uses the Fira Code font and the theme is part of a huge pack that comes bundled as an extension. Let me ask and I’ll get back to you!
Why is does `[]` have the same downside? We don't have `[` and `]` as infix operators? 
This might be helpful: https://dpc.pw/the-faster-you-unlearn-oop-the-better-for-you-and-your-software
This is a stretch.
Thank you! 
Hello, there is godotengine wich is written in c++ and then it exposes a c api, so users can create modules or bind languages such as rust, and there is rust binding for it. I can't comment on the technical details about it other than poiting it out (I'm an artist not a dev) I know that u/nicalsilva dev from firefox is working on the rust bindings for it on his spare time, maybe you can try to contact him and ask about his experience about it. Here's the link for the rust bindings of godotengine, if you want to take a look: https://github.com/GodotNativeTools/godot-rust
1. Learning curve: Required 3 month of full time work to reach 2/3rds of my velocity. I was a t 1/3 after the first month. It depends on the libs used as well, everything works differently then what I used to in C++ and Java 2. I quit my dayjob as a quant at a mayor bank to learn rust. If I could hire right now I would look for similarly dedicated people. I found it's very hard to master rust as a hobby, learning it requires dedication, and full time practice, a lot of it. When hireing be prepared to allow your Rust people to do their research: there is a lot of knowledge going around in the rust space on community chats, github, blogs and the like, but these aren't visible on the surface, and also require time investment. 3. I would write libs in rust and expose them to C. That way you dont have to deal with your C++ classes and their C-ism in rust. Saves lot's of effort, and can start small, attack a particular minigame logic first or some handlers on the backend(if exists). 4. Fragmentation happens, it's also called tech debt. Fear of it is no reason not to refactor for the better. 5. I use VS Code because it's fast, an IntelliJ Rust ocasionally, there are some nuances with both, but workable for me. Static code analysis does not exists, but we have rustc instead which is the single strongest compiler I have ever seen. 6. I have ~10 years of C++ and Java, and 3,5 months of Rust (web backends). I am on the jobs market looking for suitable remote Rust jobs. Virtually none exists. Everybody is hoping for that one expert who know everything to come along. Addendum: I found that there are two ways doing rust the 'supposed' right way: idiomatic Rust as haskellites would define it and idiomatic Rust as low level ever-optimizers would define it. For example low-levelers would prefer to pass refs of slices around and not Vecs refs os str and not String, etc.. I try to resist this urge because if I was happy using a String and a Seq in Scala, then I have no need to start worry about such things when using Rust. I worry about that kind of things when optimizing certain aspects of my code, but try not to think about it too much too early. Addendum 2: Immutability is godsend. I managed to build my webapp concurently serving pages in 3 months without ever encountering any double frees and other memory issues being concuert or not. TLDR; Do not force Rust on people, look for people passionate about it or even dedicated ones. Look both internally in your company and externally. One needs to love Rust to be willing to continue to fight through those monts spent fighting the borrow checker, the lifetimes and the 'was hard to write must be hard to use' external crates from cargo and find what works best for your usecases.
I wouldn't call it bytecode. For better or for worse, we seem to have settled on this nomenclature as an ecosystem: * Bytecode: What virtual machines execute by interpreting or JITing into machine code. * Machine code: What the CPU pretends to execute directly. * Microcode: What a modern x86 CPU actually executes, which is responsible for decoding machine code into its internal more-RISC-like language.
What you could realistically do is to prepare for the next project in Rust by running a bi monthly hackaton event with tiny ambitious goals. You grade the team opinion, you see the pitfalls and also build some know-how for the team. Build something that might touch the stronger points of the language. That said I think C# also kills an amount of problems you mention :)
Pretty sure it means: The only time lifetimes are needed is for variables allocated on the stack. If you're using heap allocations (like Box), lifetimes aren't relevant. But, I'm new too rust, and would love for someone to correct me if I'm wrong.
iirc there are clippy configs that will do this for you, though I'm not sure that's an acceptable solution for your needs. 
Why boxed trait objects over impl Trait?
Forget about `'static` for a minute. If you see a lifetime, *any* lifetime, it came from a stack variable somewhere. At the root of all borrows is a stack variable. If you borrow the inside of a heap-allocated `Box`, the lifetime you get is the lifetime of the `Box` handle stored on the *stack*, because heap lifetimes aren't a thing. When you borrow from an `Arc`, the lifetime comes from the specific `Arc` handle on the stack you used to access the value. This means that different threads can simultaneously borrow the same heap storage with different lifetimes, because again, heap lifetimes aren't a thing. And every time you borrow the storage behind an `Arc`, you get a different lifetime: the lifetime of the stack variable you accessed that storage by. If you have a type with a lifetime parameter, but no borrows whatsoever, that lifetime *still* originally came from a borrowed stack variable somewhere, somehow. ... except for `'static` which is the exception and lives forever. CC /u/DaSoldat
The funny thing is, the whole "testability" side of things drove me to a middle-ground between OOP and functional programming in Python long before I encountered reasoned arguments for it. (In Python, there are no structs (just classes without methods). Too much OOP design and all that abstraction and state makes testing painful. Too much FP design and my code got uncomfortably awkward because of all the state I was passing around as arguments... and I've never liked "one class per file" design (I use gVim) so, if I was "struct"-ing my data anyway, I might as well use classes as my namespace scopes.)
About oo designs, when are trait members dropping in, anybody knows?
Spend actual time to properly learn Rust before trying async and futures
9:00 CET happens when this comment is 59 minutes old. You can find the live countdown here: https://countle.com/7AWa0Qoj3 --- I'm a bot, if you want to send feedback, please comment below or send a PM.
It’s still not clear to me what files you mean. `Cargo.lock`? Changing newline style would be a case-by-case thing in code that generates those files.
&gt;Learning curve for the programmers that already knows C++. My guess is that it would take a few months to learn the best practices/architecture and not just write C++ patterns in Rust. I don't think it is very difficult to pick up Rust when you are already familiar with C++, that being said Rust forces you to think very differently. Your programmers have to learn how to treat mutability, but I think results in a net win. For example I remember when Unreal Engine 4 was released to the public. I tried to understand the `CharacterMovmentComponent` and that was very challenging because multiple other modules had a pointer to it and it was very difficult to understand when and where something was actually mutated. I relied heavily on the debugger with breakpoints, just to understand what was actually going on. I am saying this not to criticize the code, but something like this just won't work in Rust. And Rust isn't always all sunshine and rainbows, in some cases the code can look a bit awkward. I encourage you to read some of nikomatsakis blog posts, especially on something he calls the sentinel pattern. &gt; 3) The engine use a lot of inheritance which makes FFI harder. Adapting the engine to expose C interfaces could be time consuming. You could have a look at how Remedy Games use D, or how Godot exposes their native bindings. Especially `proc-macro` can be very helpful with the boilerplate. **But** I don't think you will see much benefit of using Rust, when you only use it in the gameplay layer. I guess I would start to look at components of the engine that have to be rewritten anyway or components gave you a lot of trouble with regards to memory safety. Just expose a ffi, which you can then use in your c++ codebase. Of course that sounds easier than it probably is in practice, depending how intertwined everything is. I don't think you have to go all in with Rust, just see how it plays out by replacing a few systems and see what your programmers think. I encourage you to write something more complex in Rust because that will expose some of the weaknesses much quicker. If you are a C++ dev, I assume you will quickly run into some self referential issues. You could also try to open source some parts of the code, so that you can get better feedback and improvements from the Rust community. That being said, maybe you should just stay with C++ and look at [GSL](https://github.com/Microsoft/GSL) to see if that could be an improvement for you. Although it probably won't be as safe as Rust.
I mean the files generated by cargo new, which populates a project folder with the main source file, Cargo.toml, and git files.
If \`PCMIn\` and \`PCMOut\` share a lot of state I would go with the generic solution. However if they do not share any or share few internal fields, I would go with the "Traits without inheritance". &amp;#x200B; I don't see what value the \`PCMPlayback\`/\`PCMCapture\` traits brings as they are very specific, and will most likely only be implemented for your specific types. I understand that it's a bit of boilerplate implementing \`PCM\` twice, but perhaps you could provide a default implementation for some of the methods. That way you would only have to implement the functions which directly interfaces with the state of your struct twice, and the rest would have a default implementation.
Youtube link is not working
The first thing I'd do is to stop continuing in the face of errors. Just unwrap them, so that if there's an unexpected failure, you can see what it is via the resulting panic.
Thanks for your thoughts. Providing default implementations is something I didn't think of. Maybe one could provide access to a common state by having a trait PCM { fn get_common_state(&amp;self) -&gt; &amp;PCMCommon } ...where `PCMCommon` contains the common state. Then the default implementations could access the common state as well. It's a bit leaky that `PCMCommon` then needs to be public, but as long as there is no way for the user to create such a struct, it's not the end of the world. Also the method and the struct could be `#[doc(hidden)]`.
I believe you are not aware of two great talk at rust conf, one about how introduce RUST https://www.youtube.com/watch?v=0IMe7C5y3PU and the one about RUST in game development https://www.youtube.com/watch?v=aKLntZcp27M Both talk are real experiences, so I believe they are extremely valuable to make your own mind up and set up a strategy.
Yeah that could work. Maybe instead of making it hidden from the user, you could define it as a builder type for a input/output? That way I could setup the PCM state that I want and use the same state to create both a `PCMIn` and a `PCMOut`. Further than you wouldn't need to have a gidde public API (which is probably not a great pattern?). 
After this bug showed up in the build process we wrote a small definition file that syncs between the two systems; like a ".def" file for MSVC which specifies the ordinals of the functions - and a python script processes that. We have a financial pricing and market data library in C++ which is being ad-hoc moved to Rust for gains in performance and threading. I think most of the gains are coming just from having a fresh implementation of the code (so the improvement would have come whether we had rewritten in C++ or Rust). We see the value-add of Rust is in the robustness of the code and testability, without compromise; especially in the memory allocation and threading space. We noted that previously std::string was consuming a lot of space and time due to allocations that we could remove using &amp;str so that was a large gain. We also saw improvements with fine grained threading specifically using futures related to market data IO and processing; previously we would read a big amount of data and then process it, now we could stream it. I'm sure we could do this in C++ but it was easier to write and test confidently in Rust. We already had a no compiler warnings policy on C++ and that now extends to no warnings on Rust Check/Clippy either. I wish there was some inbuilt coverage tool for Rust in the same way there is the #test interface. That's been invaluable.
&gt; I've never heard anyone call something as innocuous as a disagreement about syntax `heresy` (other than in this post). I would like to introduce you to hyperbole. It's just way more fun to call something heresy than to say "I have never seen this in any other language and consider it aesthetically displeasing".
Have you tried profiling it? I honestly doubt allocation is your bottleneck here. 
I will when I'm back to work on Monday. I still would like to know if custom allocators are possible?
Without having profiled, where do you feel the bottleneck would be? To be fair, it may indeed be, this is as fast as it can go. It's "good enough" for us right now, and it's only curiosity that is driving me to learn more.
&gt; I hate the idea of having two inconsistent newline styles across separate files. You can convert all other files to LF newlines. I always used Windows and never understood why would I want to use CR LF newlines in my text files.
It ridiculous even as hyperbole,it's just a disagreement.
Yes, you can use an arena allocator or change the global allocator for the entire program. 
1. Learning curve is almost fine. It takes \~1-3 months to write production ready code and \~1-3 more to start writing code that compiles without issue from the first attempt. Especially if you have C++ background and know all this stuff about dangling pointers etc and you don't ask "Why I cannot return reference to the local?". It may be frustrating to implement recursive structures like DOM where children has references on its parents, but there are standard patterns to work with it, see [https://github.com/rust-unofficial/patterns](https://github.com/rust-unofficial/patterns) 2. That's true. But it's ok to learn it, because you can spend 75% of your time on learning Rust and get everything at time :) But being said, it's probably won't take more than several weeks so you probably are ok. 3. And this part is a real pain point. I've been writing opencv wrappers for a while, and I came with some patterns that I used in this library. E.g. [C part](https://github.com/nebgnahz/cv-rs/blob/master/native/hash.cc) \+ [Rustish part](https://github.com/nebgnahz/cv-rs/blob/master/src/hash.rs). Unfortunately, it's unlikely you would be able to interop with rust until you expose complete C API to everything. So this is where things gonna be complicated... No, wrong term, it would be time consuming and boring. You probably would like to write some codegen like OPENCV guys did for their python bindings. 4. There wouldn't be a big fragmentation imho. 5. Tooling is not that good as it is for C++, of course, but it has huge benefits and is even better in some scenarios. For example, you don't need all there CMakeLists.txt, you just write your dependencies in TOML and it just works like a charm. It never works this way in C++ :) Speaking about IDE, I'd like to warn you: RLS is nearly dead, see [here](https://internals.rust-lang.org/t/2019-strategy-for-rustc-and-the-rls/8361) and [comments here](https://internals.rust-lang.org/t/announcing-rls-1-0-release-candidate/8239). It's completely unusable in large projects, because it's really buggy and has some architecture issues that couldn't be solved without rewriting from scratch. Unlike C# language sever, for instance, that works fine. But it's not that bad. There is an [official JetBrains plugin](https://intellij-rust.github.io/) for Rust. It works in any IDEA-based projects, but sadly it has debugging enabled in CMake only (for several reasons). However, it works fine, it has refactorings/gotos/types highlighting/code snippets/... Everything you could expect from IDE. It has some issues (e.g. resolving types declared via procedural macro or under conditional compilation), but in most cases it just works. &amp;#x200B; &amp;#x200B; 6. I have personal bias against consultants, but it's up to you :) &amp;#x200B; &gt; Anyway, is this hybrid of C++/Rust been done in a AAA game engine? What pitfalls can you foresee? What would you do in my position? The best twitt I can recall: [https://twitter.com/AndreaPessino/status/1021532074153394176?s=19](https://twitter.com/AndreaPessino/status/1021532074153394176?s=19) &amp;#x200B;
Yes. That part I have profiled. I was getting 10-15ns/float last time I looked so you indeed might be right. Some of the files are often 5million+ floats across many keys, which contributes around 50-75ms to the total time. Given roughly 150-200ms total time now, I still think there's more performance left on the table. &amp;#x200B; I will read up on arena allocators this weekend and see if that makes a difference on monday and revert back with some results &amp;#x200B; Thank you
The code looks cleaner too, with []. I hope the 2019 edition can bring it back. 
Rust has a lot of pain points for people trying to learn it, I wouldn't make this decision without A. knowing your team is enthusiastic, B. Having a lot of experience in it already yourself, and C. being able to teach it. I've been learning rust by writing a raytracer for a uni project and it's forced me in to understanding lifetimes and dealing with it in a multithreaded setting, perhaps a non-trivial project like that could be a good way of getting your team interested (or frustrated) The general rust consensus is not to rewrite entire projects in rust, but to rewrite small components that can be interfaced with. I suggest following that advice, it's there for a reason. 
So why would you just repeat what somebody else said without knowing why?
I'm on the 19.03 unstable and trying to run carnix has libc complain about the `RUSTC` environment variable not being set.
If you would read the entire file in memory (or `mmap` it) you could get away without allocating any further strings by taking slices of your input. This comes with its own challenges, but depending on how you use the parsed results this might be a win. And as /u/K900_ says, float parsing can be pretty slow.
Lol I'm wondering who needs to chill here 
Because the comment implied that nobody was aware of the \[\] syntax for generics,when the parent comment mentioned it.
Do you even CFL bro?
Multi language debugging can be quite annoying. Depending how often you would like or have to be able to debug into the engine code, this might be an issue. I think this was one of the main reasons why Unreal4 gone away from its scripting language and now prefer C++ even for the higher level stuff. Also profiling might get harder with multiple languages.
Everybody I guess?
Oh, that’s behavior of cargo test. Check out https://stackoverflow.com/questions/25106554/why-doesnt-println-work-in-rust-unit-tests for solution. Hope it helps. 
Maybe not a builder struct - but maybe it does not hurt to have the `PCMCommon` struct public anyhow? It could implement `trait PCM` by just pointing back at itself. Maybe it could be useful for some users...
I don't know,will remember this conversation if it does happen though.
/r/playrust
You may want to post that in r/playrust. This subreddit is about rust the programming language :)
The 2018 edition is shipping in two weeks,if a change like this happens it would have to happen in the next edition (don't remember what year that is,definitely not 2019 though).
&gt; I quit my dayjob as a quant at a mayor bank to learn rust. If I could hire right now I would look for similarly dedicated people. I found it's very hard to master rust as a hobby, learning it requires dedication, and full time practice, a lot of it. I didn’t quit my day job as an hft quant, and managed to learn rust quit well in the meanwhile. I agree that it’s not easy to master rust as a hobby, but it’s not impossible if you’re passionate enough and are willing to sacrifice a major portion of your free time...
Being said, with CLion it's pretty easy, you just step into native code and fall into the C code seamlessly. 
What about context-free grammars? (Unless you meant [*Canadian Football League*](https://en.wikipedia.org/wiki/Canadian_Football_League). or [compact fluorescent lamp](https://en.wiktionary.org/wiki/compact_fluorescent_lamp) for some reason)
I always thought rust had a very nice community
Okay 2020 then. 
The current rendition of the physics system is a reflection of the fact that we were still learning the best way to make things physically move when we made it a foundational part of our tech. Personally I’m hoping rust grants us a bit of an organizational do-over :) Our scripting system is in-house and not tightly tied to the experimental rust research. The thing that makes rust so appealing is the fact that it can be locally contained, and it isn’t a foundational design choice governing a yes or no answer to a complete engine rewrite.
First try to rewrite your code using iterators instead of looping over indices. When you’ve done that it will be quite trivial to use [rayon](https://docs.rs/rayon) to parallelize the outer loop.
Move the let mut initial_price = String::new(); let mut final_price = String::new(); into the loop - the Strings are used as a buffer by io::stdin().read_line(&amp;mut buf: String) and are NOT empty after the first loop - the previous line(s) are still in there.
I feel like 3 months is a *huge* underestimate of how long it would take c++ developers to become proficient in Rust. Learning the syntax is easy. The difficult part is learning the architectures of programs that the borrow checker will be happy with. People are still trying to work out a good architecture for GUI apps in Rust. Also if you really spent 75% of your time on memory issues in C++ I think there is probably a lot of low hanging fruit that you could do first, e.g. always using smart pointers, static analysis, clang's sanitisers. Rust is good because it (more or less) *guarantees* memory safety but there is a big cost for that guarantee, and if you don't need it it might not be the right choice. I would definitely try doing a Hackathon or something like that before committing.
&gt; Static code analysis does not exists It exists, see [Clippy](https://github.com/rust-lang/rust-clippy).
Hi, I indeed wrote a large part of the godot rust bindings but in this case I think that my most relevant experience is my work on [WebRender](https://github.com/servo/webrender) and its integration into Firefox. Before I get into the details I want to say that I am having a great experience working with rust in a large c++ code base. The language really pays off and does remove these common mistakes that take weeks to debug (memory corruptions, use after free, threading issues etc.). The pace of development in WebRender is much higher than other projects I've been involved with in the C++ parts of the browser and I think the language plays a large part in that. I strongly believe it was the right choice for us to go in this direction. The way we go about rust in Firefox is to pick isolated parts that need to be written or rewritten and do them in rust. Ideally we pick something that doesn't need to tap into all other components of the engine, for example starting with a parser, a decoder, or some other isolated feature, tec. Now we have an entire rendering engine in rust, as well as other large components with larger API surfaces. Doing this with isolated components allows you to not have the ffi boundary too much in the way and lets you develop the whole feature in a style that fits the language rather than have to adapt to how surrounding code works in C++. In our case the ffi boundary enforces a clean separation between older and somewhat convoluted code and the new rust code which has helped a lot with keeping things sane even though we try to move fast. &gt; 1. Learning curve for the programmers that already knows C++. In our team everyone learned rust very quickly. C++ is such complicated language to use correctly at scale that after having spent years on a large code base you quickly understand where the people who design rust are going and why/how it addresses problems. The rest is syntax which isn't a challenge to any good programmer. For seasoned game devs I think that the learning curve isn't going to be a problem. Now, developers are very opinionated animals and there's always a chance that someone in your team will refuse anything that isn't C++ whatsoever. Be careful about this as it can create tensions (it did in my team). I don't have a good solution for this. &gt; 3. The engine use a lot of inheritance which makes FFI harder. Adapting the engine to expose C interfaces could be time consuming. If you chose to work on isolated components of the engine this shouldn't be a problem (it isn't in Firefox which is also awfully object oriented). If you want to put rust code in places that need to tap into all parts of the engine, it's still possible with tools such as bindgen which is even able to work with templates and other obscure features. It won't be easy or nice to implement in rust a sub-class of a C++ class but you can still call into C++ code with class hierarchies. Another approach which is time consuming to set up but probably worth the effort is to have a description of the ffi boundary (in json or something else) from which you can generate bindings automatically in any language. This is what godot does and it works very well. Godot's API is also very object oriented and we are still able to make all features accessible to rust. This kind of thing makes it easy to add scripting languages and other tools where they make sense. &gt; 4. Fragmentation of the code base between C++ and Rust. This comes back to picking an isolated component of the engine. For us this hasn't been a problem and it has even been a good way to keep things clean. There are some parts of Firefox we'd have a harder time rewriting in rust because of that though. &gt; 5. The tooling is not as mature as Visual Studio with C++. Tooling isn't in a bad spot but in my opinion its most lacking area is the debugging experience. Optimized binaries lose a lot more debug information than equivalent optimized C++ code and debuggers aren't always able to call the functions you want to call or inspect some types of structures. It's not very bad, it's just little things but they are there. That said you can use [rr](http://rr-project.org/) with rust as well as a lot of C++ tools which just work (profilers etc.). Other than that, especially if you are shipping on consoles, I suggest you reach out to some of the few studios that have been working with rust on these platforms so that you don't have to go through the pain of making the standard library work on these platforms. This boring work is already done by people who can't make it open source because of NDAs but I'm sure some of them will be happy to share it with other people who are under the same NDAs.
Thanks, it's much more easy to search when you know where to dig. I found detailed description of this behaviour in rust documentation [https://doc.rust-lang.org/book/second-edition/ch11-02-running-tests.html?highlight=--nocapture#showing-function-output](https://doc.rust-lang.org/book/second-edition/ch11-02-running-tests.html?highlight=--nocapture#showing-function-output) So, we need to use --nocapture option to see all output in tests. But looks like we can't tell to Codewars to use this option. In fact I can use one incorrect test to make output always visible on Codewars and it help me to go further. But I think it will be good to have such option in future. &amp;#x200B; Thanks again.
&gt;The unique opportunity in front of us as I see it is that we could write the game part (AI/Gameplay/UI) in Rust while the rest of the engine runs in C++. The model would be similar to Unity with C++ as the engine and C# for the game part. Rust is more suited to engine than gameplay code. I think you'll suffer more for the interfacing. I also think Rust manages to be uglier than C++ in a 'creative' context (there are tweaks that could improve it but they go against the 'huge/secure software' concerns). I agree with the POV jonathan blow presents on the subject. this i the chicken/egg situation rust faces. 
So I would prefer if Rust would use `[]` instead of `&lt;&gt;` for templates. I think that it could even be that it would always be `::[]` for type, so we would have `Vec::[usize]` to get rid of ambiguity and 2 syntaxes. It would increase gibberish in the deeply nested templates though. 
I don't know Windows, but I can answer this &gt;What's the minimum I have to write in a Cargo file to use LLD instead? On *nix systems, you don't configure via Cargo.toml. This is the cleanest way I know to build with LLD, a pair of RUSTFLAGS, nightly, and the musl toolchain: `RUSTFLAGS="-Clinker=ld.lld -Zlinker-flavor=ld.lld" cargo +nightly build --target=x86_64-unknown-linux -musl` You can do some of this configuration with a .cargo/config file.
I think you don't necessary need to adapt your engine codebase to expose C interfaces. You can do inline c++ code in your rust code via cpp crate and use stuff like Dear ImGui or something directly without bindings/etc 
I took a quick glance at websocat in terms of readiness for Debian. The license and the source tree look fine. There are a few issues that would have to be resolved though: * Several dependencies are up-to-date for the project, but not yet available in Debian. We usually upload all dependencies on the lowest possible layer, then the ftpmasters either accept them or reject them and we have to fix the remarked problems and re-submit. This causes the whole tree to take time until it is up to the level that websocat requires. * `smart-default` would have to be updated, as it depends on other old packages in version 0.2, but these are updated and already available in Debian for 0.3. * `hyper` would have to be updated, because version 0.10 has a dependency tree with several old dependencies in the tree. I started working towards `hyper` 0.12, so that will probably be the first version that we package, if no newer version is available by the time we are there. * `websocket` would have to update their dependencies (which also contain `hyper` 0.10 and `bitflags` 0.9 of which the single dependency pulldown-cmark got updated to a `bitflags` 1) * Regarding the architectures on which it builds, I would not care too much in a crate so far up the tree, because these issues usually get fixed in the lower levels. Once these are fixed, the upper levels need to be rebuilt, then they start working. These are the problems I could identify with a quick glance, so there may be details to discover once we have the dependencies available in Debian.
Your code passes the vector with the results as mutable. This makes threading complicated for the borrow checker. Instead, just return the vector with the results and then use functional constructs. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=a9edfe7fb7d96d719c0a79d62b815d53 
Until 0.11, we were not really at the stage of optimising this. It'll get better over time, at least in terms of time performance. We could also use less space by collecting unused part of repositories earlier, and/or compressing the database. Our backend, Sanakirja, is not particularly optimised for space, its main feature is database branching.
That's right, but I have to 500000 steps or more per simulation. Each can have like a 50000 particles. So creating such arrays at every time steps is not a good idea I am not much familiar with parallel programming, but in c++ I see they parallellize such loops by using openmp. They put something like `pragma_openmp`. Which doesn't make me to loop one time. In the present case I have to loop over twice or thrice depending on the number of variables I want to update.
And/or use a smallvec if most Values contain only a few items
I feel like this ought to make it into the book somehow. I imagine it would make things super clear to people coming from C/C++.
I've always thought Windows also accepted `/`. But I can't test, unfortunately.
That might have been nice, but I think that would have made array indexing harder? (you'd have needed a .at(i) method, or overload the call operator?). I do remember debate about that, and was curious to try [T] in my pet language aswell.
Indeed. In the abstract, I myself prefer the choice of Scala (using `[]` for generics) but it comes at the cost of being unfamiliar for generics *and* indexing: in order to avoid ambiguities, Scala uses `()` for indexing instead of the traditional `[]`. I still think it's a win, syntax wise, however it certainly increases the complexity budget for someone picking up the language. In a language like Scala, which is otherwise relatively similar semantics-wise to mainstream languages, a slight syntax tweak is not asking much. In a language like Rust, where newcomers already struggle with Ownership &amp; Borrowing, such "gratuitous" syntax bumps are a much tougher sell.
Not necessarily harder – you could use `arr(i)` to retrieve a value from an array, and as suggested `arr.at(i)` to create a pointer to that cell.) I would strongly prefer this, it would make the language more regular and would enable a clean distinction between retrieving a value and taking a pointer.
Rust definitely does not take a few months. We did a experiment in my company. We wanted to compare learning time for Kotlin, Go, Rust and Haskell. Since we were primarly a Java shop, Kotlin was the fastest to pick up. Go was second. Rust was third and Haskell was last. You can become functional in Rust in about 2 weeks. Maybe another 2-3 weeks to write really idomatic Rust. 
If a boxed object contains a borrow, that borrow is still rooted in a stack variable. If you unwind the stack, the lifetime goes away, so the boxed object must also go away, or else the borrowing rules would have been broken.
&gt;But you're going to be trading all of the C++ memory problems for problems that have to do with Rust being relatively immature. This really resonates with me, it sums up perfectly the dilemna! 1. We've discussed internally about using it for some tools. Most of our tools are in C# or python. I did not think about server-side deamons and I'll keep it in mind. I like it because it's tied to the game and the game programmers might have to read/write some code in Rust. If the Rust code only lives in some area far away from the game like the build system, the game programmers might never see a single line of Rust code. In a few years when a new project starts, we'd be back in a similar situation with the addition of some in-house knowledge of Rust as you stated. 2. I did suggest Rust -&gt; C++ model and you are suggesting C++ -&gt; Rust. You are right that it is an easier path. On top of my mind the areas where this model fits nicely is where 3rd party are habitually used. Audio framework (Wwise/Fmod), Pathfinding (NavPower), UI Framework, Physics (Bullet/Havok), Networking (Raknet). Since most of those parts are mature, we'd need to focus on new tech not filled by traditional 3rd party like /u/AntiTwister mentionned with the Soft Body Physics tech. &amp;#x200B; This route has the initial overhead of settuping Rust build system, making it compile on consoles, learning curve, etc. If this is all done for a 1000 lines module it would not be worth it. To make it worth the overhead, we need to identify multiple small modules or one big module.
It's you want multiple threads to access and modify the same data you have to wrap it in a mutex, but before you do I think it's a good idea to try a simpeler solution to see if creating such arrays is actually a problem. What does and does not make a program slow can often be surprising, so measure, don't guess. 
[Here's](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=ef6d860b4a5fcc7730d634bcb5aed03b) some code on rust-playground to show you how to parallelize the outer loop.
Slight nitpick: there is no such thing as trait inheritance in Rust. `trait T: U` declares that implementors of `T` must also implement `U`, not that `T` inherits from (i.e. is a conceptual extension to) `U`.
In general yes, but in this case not at all. This is an embarassingly data parallel problem that can be easily parallelized using rayon. The corresponding c-code would look like: ``` #pragma omp parallel for for (int i=0; i&lt;n; i++) { for (int j=0; j&lt;n; j++) { // manipulate the data } } ``` The only difference is that with C you need a language extension (openmp), wheras with rust this can be implemented easily in a library.
Wait a second... How are you profiling this?
I think your main problems are, in order: - (6) There's no Rust expert in the studio. We could hire an expert or bring a consultant to get the team up to speed and set the best practices. - (2) It's harder to find a Rust programmer than a C++ Programmer. We'd have to hire good programmers and teach them Rust. - (1) Learning curve for the programmers that already knows C++. My guess is that it would take a few months to learn the best practices/architecture and not just write C++ patterns in Rust. In the absence of an expert, you cannot realistically teach Rust, and you'll be hard-pressed to find the right design for integrating Rust into an existing C++ codebase. It'd be a case of the blind leading the blind and everybody stumbling along; it's bound to be a very frustrating experience as foundational pieces have to be rewritten a couple times until a good-enough architecture emerges, with knock-on effects each time. In short, you'd be trying to learn Rust along with your team by diving into the deep end. **Alea Jacta Est**. --- I'll be honest, I don't think your studio is ready to use Rust for a big title. It'd be a clay-footed colossus. Instead, you'll need to accept that you first need to prepare the terrain and grow in-house expertise before embarking on such an ambitious project. It's too late for this title, but you can make it for the next. My suggestion, thus, is to use Rust for *simpler* and *well-defined* tools. Start with hundred/thousand lines scripts; move on to small tools of a couple files; build on your libraries to get bigger tools; ... For areas: - You probably have an asset pipeline, where assets need be adjusted/cropped/downsampled/... a batch process (I/O in, process, I/O out, done) requires little dependencies, it's a good starter project. - You probably have some continuous integration pipeline, perhaps with gnarly bash scripts, check if some could benefit from a Rust rewrite. Scripting is not necessarily Rust forte, but the scripts should be small enough to be amenable. - You probably have some monitoring or statistics collection. The backend which collects and stores the result is a good candidate. Long-running daemons, some network activity, perfect to get your toes wet with event-loops and async programming. - ... In short, focus on learning one thing at a time (file I/O, network, async, graphics, ...) and on growing little by little (groking more and more about how to architect programs). Also, spread around the work: let Joe start with a small tool, then ask Bob to do the next (asking help from Joe if needed), then Dale the next, etc... the *whole team* needs to gain expertise and understand the paradigm shift to be able to contribute to design decisions when D-Day happens.
I really could care less what a throwaway /r/pol account thinks. I stand by what I said.
I hope that this tool will be useful to the Rust community. I'm waiting for tons of feedbacks and suggestions!
On the other hand, I'm coming from JavaScript and was feeling pretty good about my Rust experience until now. Probably going to jump off a cliff today.
I use LLD to link my hobby OS on Windows. It works well. That has a custom target specification, so I'm not sure how to use it on regular projects, it seems like the other comment has instructions though!
This is a place where rustdoc could be improved. It'd be great if it allowed a doc comment above the impl and highlighted your custom comment in the generated docs. You should open this as a GitHub issue to get it on the rustdoc team's queue.
Take a look at [this post](https://www.reddit.com/r/rust/comments/8edbj2/rust_at_chucklefish_pdf/). It's a whitepaper from Chucklefish Studios on how they utilize Rust in their newest game engine for Witchbrook. They also did an [AMA](https://www.reddit.com/r/rust/comments/78bowa/hey_this_is_kyren_from_chucklefish_we_make_and/), hopefully it might answer some of your questions.
I hope you don't mean that literally! But don't worry. I came from JavaScript too, and I had no idea what the Stack and the Heap were. Luckily the Rust books (first and second editions) have a chapter on that :) https://doc.rust-lang.org/book/first-edition/the-stack-and-the-heap.html https://doc.rust-lang.org/book/second-edition/ch04-01-what-is-ownership.html#the-stack-and-the-heap
Well sure, but if you are going to do that then you are losing a lot of the benefits of using Rust in the first place.
I literally just imported hamcrest into my project to try and increase readability and error message usefullnesd in my project. How usable is this at the moment? I might consider switching.
It is usable, but there are almost no assertions at the moment: https://gitlab.com/Boiethios/fluid-rs/wikis/assertions. The reason is that I am waiting for some feedback before implementing them. If I write, like dozens of assertions, and someone gives me a great idea of modification, the refactoring would be much more longer… If you need one or some particular assertion(s) in your project, I can gladly add them. It would took me literally a bunch of minutes, now that the framework is there.
This reminds me that I should make a hamcrest clone using [`predicates`](https://docs.rs/predicates/1.0.0/predicates/) which is already heavily used by `assert_cmd`, `assert_fs`. It allows building up expressions, shows intermediate results, and has a good number of tests implemented (including rendering string failures as a diff). I want to expand the string diffing some more and want to add directory diffing but otherwise its fairly complete as far as I'm aware.
Yes, *unless* you try compiling WebAssembly on windows, as I've learned.
Indexing is already not "some special syntactic construct". It can be implemented on any type, for any index type, using the `Index` and `IndexMut` traits (though there are open design problems around `IndexMove`, which does not exist though it would be very useful -- design problems that Scala does not have because it does not have Rust's ownership model). Using `[]` for generics would not change the fact that generics' arguments are types while indicing's argument is a value.
Yes that is a good point. I wanted to highlight that technically you can do pretty much exactly the same things as you do in C, it's just that Rust will make you explicitly opt out safety. This means that you're back to the situation you have in C where it's the programmer's responsibility to uphold essential invariants. I do think using Rust without unsafe will nudge you in a good direction as a programmer. Personally I use a lot of the concepts I learned from Rust in other languages, except then it's me that's enforcing it instead of the compiler. 
Yep, `Index` and `IndexMut` made `[]` for indexing completely useless, because the redeeming (and false) argument that "if you see `[]`, you know it's a simple memory access" fell apart. Use `[]` for types, `()` for values. Problem solved.
&gt; The general rust consensus is not to rewrite entire projects in rust, but to rewrite small components that can be interfaced with. right that statement makes sense, but for a C++ game engine, the interfaces *are* C++. its just not feasible to retrofit it into C++ projects. in the world of websites/web servers etc, components communicate over the wire.. retrofitting components is easier.. but in game engines the interfaces are fine grain, in memory, and rely on language details
It's an archaic holdover that MS has never bothered to correct.
Admittedly I'm not too familiar with rust, nor have I really seen any benefits by working with it so far (if anything, it's made things more difficult for me, though I've enjoyed the experience). I personally think the idea that rust will replace C++ in game dev is unrealistic as things stand right now, though I'm excited to see a few companies here and there adopt it and I really hope we see a move towards something like cargo within the C++ standard some day. I still think it's possible to find places where you can integrate rust in a game engine without sacrificing much, especially when compared with the prospect of rewriting an entire engine in a relative immature ecosystem with a team that has no experience in the language. I'm not saying it's necessarily a good idea, but I find that approach much more palatable to OP's desire of a full engine rewrite.
If you ever plan on putting your code anywhere that other people can access it, please standardise on LF line endings. CRLF is an anachronism that needs to die.
If the API of your existing engine uses C++ features like: * templates (functions, variables, classes, ...), where the user can pass its own template parameters: you can't really create those types in Rust and use them to instantiate C++ templates * function overloading: you have to wrap those in C FFI * inheritance, virtual functions, etc.: you can't create a Rust type that inherits from a C++ type or anything like that And probably many many other things. If you want to write code in both Rust and C++ and get it to work together, currently, you have to do so by wrapping it through a pure C API. Whether this is ok or not depends on what engine you are using, how its API is supposed to be used, what Rust components you are writing, etc. 
You might also look at existing approaches to string interning, such as [string-intern](https://github.com/tailhook/string-intern) or Servo's [string-cache](https://github.com/servo/string-cache). Also note, if you `mmap` the file, then you get undefined behavior if somebody else change the file contents while you've got it mapped. To me, the inability to `mmap` a snapshot of a file is one of the saddest things about filesystems in the modern era (if it was widely supported, I'd use it for file loading in xi-editor and save a ton of allocation and copying).
Could people extend this with custom matchers, like Rspec?
You obviously meant to post this picture: [https://proxy.duckduckgo.com/iu/?u=https%3A%2F%2Ftse2.mm.bing.net%2Fth%3Fid%3DOIP.FHMSwKbnYgbuHA469IuXDgHaD7%26pid%3D15.1&amp;f=1](https://proxy.duckduckgo.com/iu/?u=https%3A%2F%2Ftse2.mm.bing.net%2Fth%3Fid%3DOIP.FHMSwKbnYgbuHA469IuXDgHaD7%26pid%3D15.1&amp;f=1)
That’s because React and Redux were inspired by OCaml and Elm respectively, and thus they have their preference of immutability rooted in functional programming. Incidentally the first Rust compiler was written in OCaml as well. Before React it was jQuery ruling the JavaScript world and everyone was mutating the DOM from who knows where. jQuery is still a nice fit nowadays for small and straightforward stuff or for maximum backward compatibility. 
I wonder, is it possible to somehow use `Self` in the default trait implementation? I was thinking something like this: trait XY { fn size() -&gt; usize { use std::mem::size_of; size_of::&lt;Self&gt;() } } &amp;#x200B;
Thank you for your answer! I can't wait for continues of this series about Rust) You are doing really important and interesting things with Rust and prove on your self-example how good this language! Thank you, guys)
The borrowck improvement is mainly non-lexical lifetime, which currently can usually be worked around by introducing a local scope around the borrow to tell the borrowck where it ends.
is it an in-house engine? if so maybe you could look at gradually refactoring the C++ to the point where it's interfaces are easier to transfer to mimic in rust (differences in namespacing/overloading will bite) personally i think if you have a C++ engine, you're stuck. Rust is for engines not gameplay code.
Wrong sub. 
Thank you for your advise. I find IDE's an absolute nightmare, much the hardest and time consuming part of learning a language. I started off with Intellij Idea, spent several miserable hours trying to make it 'work' (see below). Seeked help from JetBrains. Basically a waste of more time. I then received an email from JettBrains that begun:- "I'm a CLion support engineer. The debugging feature for Rust is available only in CLion for now:" (See my reply to deep\_fried\_eyeballs.) And so it goes with each line of approach. I had previously tried to load the Rust toolchain into Eclipse. Eclipse is product most aspects of which I find totally confusing. Then comes along Corrosion, seemingly a significant 'project'. The Eclipse downloaded with Corrosion now seems significantly different from the Eclipse I am used to. What an idiot I feel ever thinking I could simply achieve this myself in order to learn a language. Now I am finding problems that I feel are directly related to using what I feel is a 'satisfy a minority hack-on' to a foreign (Java orientated - just about OK with C) tool. I was looking for 'Corrosion support' as distinct from 'Eclipse support' when Google landed me here. \-------- What do I mean by an IDE 'working'? At least I must be able to create count-delayed breakpoints which if activated brings up the appropriate lines of source code and allows examination of all in-scope variables. It then must allow single step. IMHO if it does not do that it is hardly an IDE. It must do this for ALL facilities offered by the language. It should work with a 'virtual' command line. (I am not interested an an 'IDE' that does not offer anything that could just as easily be done from the command line.) Really nice:- Breakpoints activated by a variable name that when in scope reaches a particular value. Assembler listing around the issue. Virtual environmental values. Relevant memory dumps. etc. \------------- I feel that each line of approach has its own enthusiasts. I believe in all cases they would have at least tried to achieve the above. If they have not achieved it then there is a problem that will be way way over my head. I.e. If it does not work 'out of the box' or after following some instructions, I might as well straight away give up on the approach. I am, after all, a brand newbie at the language. I want to concentrate on learning it by manually porting project(s) that are solely mine, currently written or started in some other language. \&gt; Rust works well for me in both intellij and VS Code (with the rls plugin) How come you had so much more intellij success than me? What did you achieve with it? I do not really get on in the slightest with Windows, or many Microsoft products for that matter. However, I am so far forced to use Virtual Studio to develop ATmel AVR products. (Fantastic processors, atrocious software support. Oh dear I don't want to start a flame war.) I run it in Virtualbox which is a pain. Have desperately tried to get the AVR toolchain into Eclipse. (I believe there is a 'project' started for that now (:-)). Also Codebocks. I suppose if it really does solve all my problems I might use VS for rust as well. But -Oh dear! If anybody else sympathises with my problem, to simply have a working IDE for Rust, can they help me? &amp;#x200B;
I'm thinking about this, but I'm not sure about how to do that technically for now.
The relevant code is at https://github.com/rust-lang/cargo/blob/ad239245a144ee7db053133a7dcec156a32e14a8/src/cargo/ops/cargo_new.rs and currently has no support for changing the line endings. I can open an issue on the Cargo repository to make a case to add that support, but I don’t know if a lot of people are gonna be interested.
Traits are `?Sized` by default which means Self` might be unsized. You need to restrict `Self` to `Sized`: trait Xy { fn size() -&gt; usize where Self: Sized { … } }
[https://www.youtube.com/watch?v=nZNd5FjSquk](https://www.youtube.com/watch?v=nZNd5FjSquk) [https://www.youtube.com/watch?v=CFzuFNSpycI](https://www.youtube.com/watch?v=CFzuFNSpycI) If you have a couple hours, run through these videos. 
Sure, you can do this just fine, and the code you've written above will almost work. You need to add a type constraint: trait XY where Self : Sized { ... } Otherwise the compiler will complain about not being able to know the size at compile-time. Then you can just impl that trait on any type and your method will return its size.
I've read your reply to pLesur, and I'm going to disappoint you: it's extremely unlikely that either Vim or Neovim will ever provide everything you want, plugins or no plugins. Bear with me for a bit, the rest is going to be a bit of a rant, with pros and cons (mostly pros, I'm biased) of Vim and Neovim in no particular order. Both Vim and Neovim are _insanely_ powerful text editors, and if you take the time to learn either, you will never be able to look at most IDEs without despair, since the fact that they are basically glorified notepads will become sharply evident. Delete a word under a cursor? There is a key sequence for that. Delete two instead? Sure, with a minor modification to the former. Even better, there is a well defined logic behind key mappings, and you only have to remember their building blocks, not the combos, for they are infinite, and you can construct them on the fly to suit your needs in any way you want. Then there are plugins. ALE, which I mentioned, stands for 'Asynchronous Lint Engine', and is a wrapper over many other programs and plugins, including RLS, that provides in-editor, fast, highly inobtrusive markers about errors, potential problems and so on in your code. If you plug RLS into it, you will pretty much be free from the need to switch to a different terminal\window to compile your code and see errors and warnings - they are going to be right under your cursor and in the special quickfix window, if you want to open it. It is not perfect, and doesn't handle conditional compilation via `#[cfg(whatever)]` well, but in most cases it'll do the job. That's what I meant by 'freaking fantastic', because that's more or less all I want from an IDE. Oh, and you can run any shell command without leaving Vim. Better yet, there is a nice little command called `:make`, which can be configured to run `cargo` for Rust code, and collect error messages in the same quickfix window I mentioned in the previous block. Now, breakpoints and step-by-step execution. Personally, I've never cared much for this, so my knowledge of what Vim offers here is limited. But what I do know is that if I really want to have this functionality, I'm better off using a dedicated program like `gdb` (which, as I've just checked, works fine with Rust programs). `gdb` offers you a lot more power than any IDE's debugger - the full list of its commands is ludicrously long, and back when I programmed in C for fun I used about three. There probably is a Vim plugin for `gdb` integration, but Neovim offers another option: it can open a terminal inside itself, and you can run `gdb` or whatever else debugger you want it it. I don't know if you find such a solution acceptable - it is certainly not as easy or convenient as clicking on a line and selecting 'place a breakpoint here'. But it's an option, and a great one if all you care is power. Assembler listings, virtual environment values, memory dumps? No idea, sorry. Working out of the box? As a text editor - yes, definitely. As an IDE - only after some setup, more for Vim, a bit less for Neovim. At the very least you'll want a plugin manager. If you do choose to use ALE with RLS, you'll have to read the docs to set it up right. If I remember correctly, RLS integration also requires a language client plugin, and you'll have to opt in into using RLS in ALE settings explicitly, which means some more reading. Nothing super difficult, but not 'out of the box'. There is also one more thing about Neovim in particular that I think I have to mention. There is no official GUI version, it's purely a terminal program. I think there are unofficial GUIs, but I have not investigated them - I prefer good ol' terminal to GUIs. Vim does have an official GUI. If I forgot to answer some of your questions or did not explore them in enough detail, please let me know. Sorry for the rant. BTW, did you consider using Linux for development? It more or less turns your _OS_ into an IDE, and is a lot more pleasant experience than trying to set up Windows for programming, especially if you want to code in different languages. I can't imagine the hassle of setting up, say, Python, two C compilers, Haskell and Rust on Windows. On a Linux machine you probably already have half of it installed from the very beginning.
You can shorten `trait XY where Self: Sized` to just `trait XY: Sized`. Also note that you might not want to restrict `Self` to `Sized` for the whole trait as this prevents the creation of trait objects. That makes sense if you provide other methods that might work on trait objects.
&gt;No - you are trading an ambiguity at the parsing phase with an ambiguity at the semantic analysis phase. And at the semantic analysis phase you can have type information which can be used for resolving the ambiguity. That not contradicting what they said at all though.
Both of these sound like good things to try
I looked at interning but I thought you have to know the strings that would come up because you compile it into the program static. I'm not able to do that at this stage in the parsing. However I think with the crates you highlighted seem to be dynamic at run time.
Cool. Was trying to learn it for ECS. Any twitter account.
@pi_pi314
One more problem was found. [https://drive.google.com/open?id=1jtCVOUQWqOAscbBBu\_Bsev0Z5LDydX1e](https://drive.google.com/open?id=1jtCVOUQWqOAscbBBu_Bsev0Z5LDydX1e) Original kata on Python use html markup to display chess desk. I used same approach in c# and rust translations. C# runner display html text correctly. My Rust translation generate correct html code (at least chrome can display it correctly) but rust test runner show only symbols without correct html formating :(.
I am reading the advanced lifetimes here ([https://doc.rust-lang.org/book/second-edition/ch19-02-advanced-lifetimes.html](https://doc.rust-lang.org/book/second-edition/ch19-02-advanced-lifetimes.html)), and it seems that the error message is a little misleading. Here's the snippet: struct Context&lt;'s&gt;(&amp;'s str); struct Parser&lt;'c, 's&gt; { context: &amp;'c Context&lt;'s&gt;, } impl&lt;'c, 's&gt; Parser&lt;'c, 's&gt; { fn parse(&amp;self) -&gt; Result&lt;(), &amp;'s str&gt; { Err(&amp;self.context.0[1..]) } } Then, the error message is: error[E0491]: in type `&amp;'c Context&lt;'s&gt;`, reference has a longer lifetime than the data it references --&gt; src/lib.rs:4:5 | 4 | context: &amp;'c Context&lt;'s&gt;, | ^^^^^^^^^^^^^^^^^^^^^^^^ | note: the pointer is valid for the lifetime 'c as defined on the struct at 3:1 --&gt; src/lib.rs:3:1 | 3 | / struct Parser&lt;'c, 's&gt; { 4 | | context: &amp;'c Context&lt;'s&gt;, 5 | | } | |_^ note: but the referenced data is only valid for the lifetime 's as defined on the struct at 3:1 --&gt; src/lib.rs:3:1 | 3 | / struct Parser&lt;'c, 's&gt; { 4 | | context: &amp;'c Context&lt;'s&gt;, 5 | | } | |_^ It seems to me that 'c and 's are independent. Why does the error message say that 'c has a longer lifetime than 's? Is there an elision I'm not aware of? Can someone clarify and elaborate more on it? I am really new to Rust, and lifetime is the topic I'm struggling with so hard. I want to grok it. Thank you.
Get a 30 days tryout license and see if it works for you. Take it on the road, etc. I understand your concerns about license checking. You seem to have high expectations from the IDE, rust being relatively new you may find some of the tools still lacking, better stick with C for now.
Nice. Could you make your voice a little louder (or type out what you're saying)? Because currently your keyboard is louder than yourself (so it's a little hard to hear what you're saying)
&gt;Beyond that, you need to force yourself to consciously consider what kind of pointers you're dealing with. Specifically: is it owned or borrowed, is it shared or unique, and do you need mutation. So, I took a vacation and was doing a lot of programming in rust during it. Then I went back to work and started programming (in Java). I did a double take when I realized I was passing the same mutable object into two different places and it wasn't being copied. Like I questioned just what was happening. That was an enjoyable moment for me - these rules Rust abides by do settle in over time.
I'm not referring to dependency locking but lock files. Only one build at a time can run for your c|ate. You can notice this if your editor kicked off a build and then you try to.
I havnt noticed this when my editor kicks off an RLS build and i run a normal one, but i guess they have different target subdirectories
That's what blue switches get you 😅 I'll try to speak up next time and maybe I'll make a transcript for the YouTube uploads. I already posted there, but thanks!
I think your concerns would get in the way of you getting to grips with the language. Other than lifetimes and generics, there's not much to the syntax that an interpreted language wouldn't also have. Start with the Rust book and just work your way through it. It introduces concepts intuitively and you may find your concerns unfounded
Don't bother learning how to write macros in that case. I think most of the things in the Rust book have to be understood to write Rust code, but don't be too intimidated, and check out the Rust discord or irc if you want to ask people for advice. In time you will see that much of the syntax of Rust is consistent and limited compared to some of the things in other languages, but it can be very different than what you are used to. Over time you will start to feel more comfortable using generics and it will be more natural to write `where` statements.
If you want to do what I did, use VS Code with the rls plugin and there are tutorials online with how to set up breakpoints (its like one json script to edit, so not bad). You can also use Visual Studio itself to debug Rust code, but definitely use VS Code and not Visual Studio proper to edit Rust code.
I need one final correction to my code. I added nearest neighbor search algorithms and I should call it before the inner for loop. It looks like ``` fn contact_force( d_x: &amp;[f32], d_y: &amp;[f32], d_fx: &amp;mut [f32], d_fy: &amp;mut [f32], s_x: &amp;[f32], s_y: &amp;[f32], s_nnps_id: usize, nnps: &amp;NNPS, ) { for i in 0..d_x.len() { // get the neighbours of particle i let nbrs = get_neighbours(d_x[i], d_y[i], s_nnps_id, &amp;nnps); for &amp;j in nbrs.iter(){ let dx = d_x[i] - s_x[j]; let dy = d_y[i] - s_y[j]; d_fx[i] += 1e5 * dx; d_fy[i] += 1e5 * dy; } } } ``` Since the updated parallel way of writing this is ``` fn contact_force_par( d_x: &amp;[f32], d_y: &amp;[f32], d_fx: &amp;mut [f32], d_fy: &amp;mut [f32], s_x: &amp;[f32], s_y: &amp;[f32], ) { d_fx.par_iter_mut() .zip(&amp;mut *d_fy) .zip(d_x.par_iter().zip(&amp;*d_y)) .for_each(|((d_fxi, d_fyi), (d_xi, d_yi))| { // Note, the `_i` parameters are references to what would be `[i]` indexes. // You can `.enumerate()` the iterator if you also want that index. // Now write your inner loop -- could also use `par_iter()`, but // it's probably fine to keep serial. s_x.iter().zip(s_y.iter()).for_each(|(s_xj, s_yj)| { let dx = d_xi - s_xj; let dy = d_yi - s_yj; *d_fxi += 1e5 * dx; *d_fyi += 1e5 * dy; }); }); } ``` How to use the neighbour indices in the inner loop? Full version can be found at [source](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=9d2ab64557af5ec45be7f38c63208e82).
Going simpler - how about utilizing `wkhtmltopdf`?
I will try that tomorrow and reply. I am on mobile. Thank you.
Hello! I'm sorry to hear you didn't find it helpful. To be fair, I do cover what executors actually do when a future/task isn't ready later in the stream, but perhaps you haven't gotten to that part yet? Let me see if I can explain why I did things the way I did though, and provide you with some references for where you can learn more about the things that I skipped over or only covered very superficially... There are a lot of ways to cover Futures/async/await. The first is to talk about them purely from a "mental model" perspective; what are asynchronous computations, how do futures fit into that, and what does async/await add on top. Basically to cover just the "what" and "why". That's what the RFCs ([`Future`](https://github.com/rust-lang/rfcs/pull/2592), [`async`/`await`](https://github.com/rust-lang/rfcs/pull/2394), [`Pin`](https://github.com/rust-lang/rust/issues/55766)) primarily do. The second is to cover the "execution model"; how are futures executed, how does `async`/`await` *work*, and how does pinning enable `async`/`await`. This is basically talking about what [executors](https://docs.rs/tokio/0.1/tokio/executor/index.html) are, what [tasks](https://docs.rs/futures/0.1/futures/task/index.html) are, task [notification](https://docs.rs/futures/0.1/futures/executor/trait.Notify.html), what [`Pin` does](https://doc.rust-lang.org/std/pin/index.html), and why it's needed for `async`/`await` (because of self-references). All of the above I covered in the stream. The *third* way to cover it, and I think what you're asking for, is to talk about the *mechanism* that is currently used to execute futures. That is, the *implementation* of [`tokio`'s executor](https://docs.rs/tokio-executor/0.1/tokio_executor/) or the [WIP `futures-rs` executor](https://github.com/rust-lang-nursery/futures-rs/tree/master/futures-executor). This would include stuff like how the executor represents and manages of tasks, how notifications are implemented, how executors make progress when tasks aren't ready, etc. This you are completely right that I did not cover in great detail. I did talk a little bit about tokio's threadpool executor, and how that works, but we didn't go digging into the code. However, I very intentionally did not do so. How an executor is implemented differs a lot between different executors, and also changes over time, so any such information would grow stale pretty quickly. Instead, I chose to give some general intuition + a naive implementation, because that is all I think you need in order to work with futures. The exact mechanism isn't terribly important (I think) for people who want to understand futures, even if they are going to implement them themselves. It's an internal detail of whatever executor you choose to use. The two first aspects are much more important, because that is the interface you are programming against, and what the executors guarantee; they generally give no guarantees about execution mechanisms. I also think it'd be hard to understand these mechanisms without first understanding the higher-level execution model. All that said, I think it is absolutely *interesting* to understand how an executor works internally. It probably won't affect how you work with futures, but it might be interesting from an engineering perspective. For that, I recommend starting with the [tokio runtime model](https://tokio.rs/docs/internals/runtime-model/), and then dig into [tokio non-blocking I/O](https://tokio.rs/docs/internals/net/). Notice that even there though, there are warnings like "This is not the real implementation". If you want to go all the way down to the execution code, you should start digging into [`tokio-threadpool`](https://github.com/tokio-rs/tokio/tree/master/tokio-threadpool), and let the code guide you :) I hope that clears up why I did things the way I did!
Did you read chapter 4? it has nothing to do with stack vs heap. It has to do with ownership. If the value is moved into the function call, the calling function can no longer use that value. By passing a reference, the function is allowed to look at the value, but it is not given ownership.
Thank you, and apologize for not being clear. My point is that: the error should have been "we don't know whether 'c or 's lives longer. So, there's an error cause 's must be explicitly defined as living longer than 'c". Or, in other words, I'm not sure how it arrives at: `in type \`&amp;'c Context&lt;'s&gt;\`, reference has a longer lifetime than the data it references` when, in fact, we don't know whether 'c or 's lives longer because their definitions are rather independent.
Good luck!
You can also probably tune your microphone to make the switches quieter and your voice louder which would help even more.
Is there a crate for splitting `str`s on whitespace that takes into account escape characters and quotes? i.e. Something like this "foo bar".my_split() // "foo", "bar" "I said 'foo bar'".my_split() // "I", "said", "foo bar" "foo \'bar\'".my_split() // "foo", "'bar'"
Things only get copy if you define it yourself. Usually it's as easy as writing "#[derive(Copy)] on the line above your struct.
Good question. I just hadn't looked at how to get consistent types out of nalgebra but setting the buffer argument manually gets it right. The iterators aren't boxed now.
Wow, your crate is cool! Do you plan to update it? `#[test_case]` will probably be reserved: https://blog.jrenner.net/rust/testing/2018/08/06/custom-test-framework-prop.html and it seems that you did this project before the stabilization of proc macros. Maybe I will explore the module generation as well, thanks for the tip!
It's published on YouTube. The link is in the description of the stream
How do you create a global Mutex protected file handler? Context: REST API on flat file db. struct ExportFile { file: Option&lt;Mutex&lt;fs::File&gt;&gt;, } lazy_static! { static ref EXPORT_FILE: ExportFile = ExportFile { file: None }; } 
https://www.twitch.tv/videos/340069405?t=48m14s
Do you really want methods like `set_sample_rate`? Dynamically changing things might be tricky, any a recipe for race conditions. If not then would recommend the following approach: Move all common things into structures like `StreamConfig`, or `PcmStreamConfig`, which could be defined as struct PcmStreamConfig { nr_channels: u8, sample_rate: u16, buffer:size: usize, } Then you can create playback/capture/etc instances from it, using `PcmOut::new(PcmStreamConfig)`. You can also implement accessors on it, and then implement `PcmOut::get_gonfig(&amp;self) -&gt; PcmStreamConfig { self.config }` Then you can access (but not change) the configuration later with sample_rate = stream.get_config().sample_rate() You might want more than one configuration object. Think about what is similar between different use-cases (e.g. nr of channels and sample rate), and what might be different (a PCM stream might have different properties than an encoded stream). 
There's absolutely no relation between `'c` and `'s`, so the compiler cannot deduce anything about them. The error might indeed be better phrased as "reference might have longer lifetime than the data it references". 
if you want to take streaming seriously you should get a better mic, theres a lot of hisses and such which is annoying imo &amp;#x200B; and nice to see some amethyst dev! keep it up
Well, you can't modify statics just like that. In your case I suggest to push `Mutex` up - wrap the whole value, instead of keeping it inside the `Option` (which you are now unable to modify): struct ExportFile { file: Option&lt;fs::File&gt;, } lazy_static! { static ref EXPORT_FILE: Mutex&lt;ExportFile&gt; = Mutex::new(ExportFile { file: None }); } fn main() { EXPORT_FILE.lock().unwrap().file = Some(fs::File::open("export_file_sample").expect("Error: Unable to read exports file!")); } 
just a heads up, this is the subreddit for the rust programming language
The two alternatives I know of are [shlex](https://docs.rs/shlex/) and [shellwords](https://docs.rs/shellwords/). They seem pretty equivalent, though the latter is newer and possibly more maintained.
Off topic but I love blue switches ❤️
AKA the Holy Grail :P
Why are macros due to rust being a compiled language? As i understand it it is mainly used for places where functions won't work, such as having multiple arguments, but couldn't that be resolved by just making functions more versatile? 
Wow, these are exactly what I was looking for. Thanks!
Thanks :) but my crate is only small subset of yours :) Ive seen that test_case is reserved. Anyway, you can hide builtin one with `use test_case_derive::test_case` so it is not a big issue. Me and my colleagues use it a lot at work so I'm updating it whenever there is any issue (there weren't many so far btw). I will definitely try to release 1.0 if it works on stable rust. 
Macros are a compile-time construct? Dynamic languages can have metaprogramming which achieves the same result, often when the file is loaded, but it still happens at runtime and can happen multiple times if invoked.
Sure but at a surface level you don't need to think about any of that when you're starting out and what they really mean in the context of a compiled language. IMHO rust is very python like in that you don't need to know much about the language or details to get started. It's when people start saying you need to understand all of the intricacies of a compiled language that you scare people off. Of course there are differences, but for a beginner, you're really not going to run into them or even if you do, you likely don't need to care too much about the details.
Macros aren't necessarily an alternative to functions, though you can treat them like that. They specifically expand out code at a given point based on the code you give them. That can let you do much more than replace a function, because you can have them generate large amounts of code if you wish. For example the derive Debug and Serde ones will generate implementations for you. nor are they necessarily only something a compiled language can do. It's just that compiled languages are typically the only ones that support an expansion/preprocessor stage. But you could add them to python if you so desired and I've seen people do just that (though I wouldn't recommend it).
It's tricky though. That move fast and break things is exactly how you get in OPs position. "Just quickly iterating on the gameplay, looks like it's working. Oh it's crunch time/X other priority, no time to refactor this". &gt; On the last game we shipped, in my team about 75% of the last year was spent on issues that Rust promises to prevent. Double free, Dangling pointers, out of bound access, threading issues, non initalized variable, null pointer, etc. 
Try https://learning-rust.github.io . It might be helpful for you to learn Rust basics quickly. Rust is not that much complicated to learn but still we lack some learning materials which can be used to learn things quickly from a single place.
Hey, thank you again. After sleeping on it for several days. I now understand why it doesn't work. Even we, as human, know that, eventually, `var` will live longer than `scope`. The compiler has no way to know that by looking at that function's body. For more context, I'm building my own compiler and processing a semantics tree. I now understand that, if I traverse the tree the second time, and add `var` to `scope` in the second time, the compiler will be able to deduce that `var` lives longer than `scope`. If I really wanted to traverse the tree only one time, then I would need to use `Rc` (this makes code a lot more verbose) or `unsafe`. This is such a paradigm shift for me. Thank you again for helping me.
Can anyone help with this error, that I cant seem to be able google elsewhere. I'm trying to convert an error from a third party crate to my own error type using From; but getting an error I don't understand. &amp;#x200B; `use xladd::variant::{Variant, XLAddError}; // Third party crate` `use failure::Fail;` `use std::convert::TryInto;` `use std::convert::From;` `use std::error::Error;` `// PDF from prices` `// Random forest train/predict` `// portfolio sim with vol and drift from pdf` `#[derive(Debug, Fail)]` `pub enum AARCError {` `#[fail(display = "F64 Conversion failure")]` `ExcelF64ConversionError,` `#[fail(display = "Bool Conversion failure")]` `ExcelBoolConversionError,` `#[fail(display = "Conversion failure")]` `ExcelStrConversionError,` `}` `impl From&lt;XLAddError&gt; for AARCError { // This should work?` `fn from(err : XLAddError) -&gt; AARCError {` `AARCError::ExcelF64ConversionError` `}` `}` `pub fn normalize(array : Variant, min : Variant , max: Variant, scale : Variant) -&gt; Result&lt;Variant,AARCError&gt; {` `let min : f64 = min.try_into().map_err(|e| AARCError::from(e))?;` `Ok(Variant::from_str("foo"))` `}` &amp;#x200B; Error I get is &amp;#x200B; `error[E0277]: the trait bound \`basic_stats::AARCError: std::convert::From&lt;!&gt;\` is not satisfied` `--&gt; src\basic_stats.rs:24:48` `|` `24 | let min : f64 = min.try_into().map_err(|e| AARCError::from(e))?;` `| ^^^^^^^^^^^^^^^ the trait \`std::convert::From&lt;!&gt;\` is not implemented for \`basic_stats::AARCError\`` `|` `= help: the following implementations were found:` `&lt;basic_stats::AARCError as std::convert::From&lt;xladd::variant::XLAddError&gt;&gt;` `= note: required by \`std::convert::From::from\`` &amp;#x200B; What is this From&lt;!&gt; trait? How do I implement it, why do I even need it? 
So basically when using lie algebra yes? Because the tangent space is linear?
With the integration of futures in to std, is there a reason why std::Result doesn't list IntoFuture for trait implementations?
Got it now. Thank you!
Yea sorry new to reddit 
The orientation subspace of the KF's state space is SO(3). The full state space is usually just the Cartesian product of SO(3) (orientation) and R^(n) (all the other state variables), which itself is also a continuous manifold. It's a really good paper.
So, you just submit to some subreddit without checking whether it's the right one? I don't see a difference with being a spammer, to be honest. 
&gt;Going simpler - how about utilizing wkhtmltopdf? I considered that, but how do I use html to do exact layouts? I need labels that can be folded in a certain pattern and have text blocks on the right places on the outside of my box. I want to able to specify the exact position that items appear on the page. Perhaps wkhtmltopdf can do that, but I didn't see a good path.
I'd enjoy hearing a few words about how difficult it was too setup the foundation and which options/structure were chosen and why.
Yes please!
Not gonna lie, this feels like putting the cart before the horse. I like the enthusiasm behind amethyst; but I’d like to see it ship some target games. If that’s successful then maybe a foundation makes sense.
Presumably, the result of `&lt;Variant as TryInto&lt;f64&gt;&gt;::try_into` is a `Result&lt;f64, !&gt;`, not a `Result&lt;f64, XLAddError&gt;`. `!` is the "never" type, meaning the conversion cannot fail, so you should probably just unwrap the result of `try_into`. I can't check because the crate has no online docs.
Updating my OAuth-like project to latest Rocket and Angular
&gt; how difficult it was to setup the foundation It took us several weeks and mounds of paperwork. =) The list was something like this: 1. Write Articles of Incorporation 2. Write Bylaws 3. Incorporate in the state of Washington 4. Register for an EIN with the IRS 5. Apply for non-profit status with the IRS via form 1023 or 1023EZ 6. Open a bank account, add signers 7. Hold initial board meeting to ratify the org structure. \#5 was probably the most tedious. There are many categories of entities in the US that qualify for tax-emption. This site has tons more info: [https://www.irs.gov/charities-non-profits](https://www.irs.gov/charities-non-profits) You have to find out where you fit amongst those categories based on your mission. Fortunately, there's a short (20 something page) checklist to help you figure it out. I'm happy to go into more detail on any particular point if you want. Basically just start at your state's Secretary of State website and follow the instructions. &gt;which options/structure were chosen and why. Foundation doesn't have any special meaning in the US. The state you are in keeps a list of registered corporation names, and they have rules about names. Washington's are here: [https://app.leg.wa.gov/RCW/default.aspx?cite=23.95.305](https://app.leg.wa.gov/RCW/default.aspx?cite=23.95.305). We fall under 2a. So all we are is a regular C-corporation incorporated for a specific purpose. The key differences are: 1. The corporation is not divided into shares, so a non-profit cannot raise capital via an IPO or similar 2. We cannot pay out dividends to shareholders; all revenue must go back into the non-profit 3. We cannot engage in political activity (there are other structures for those that want to do that) 4. A for-profit corporation cannot have volunteers, a non-profit can 5. A non-profit can pay people a fair wage, but not outrageous salaries 6. The non-profit structure allows us to continue operating with volunteers and to accept donations. It also allows donations from US citizens to be tax deductible. 7. The board members and officers (C-level equivalents) have to follow strict conflict of interest rules As you can see, there are a lot of tradeoffs. We are all volunteers and community-supported, and it was important to us that Amethyst always remain free and open-source. But as we grow, we are also accumulating costs like build servers and such. Many companies offer reduced or free service to non-profits. So it made the most sense for us. Let me know if you have more questions. 
They're gitbooks, right? You might be able to `diff` the source code. /u/steveklabnik1 would know.
Awesome, thanks!
We did discuss that. It is something of a catch-22, though. To make a game engine, you have operational and capital costs. These costs have so far been absorbed by a few individual members, but that isn't sustainable. The second thing is stewardship of IP. A non-profit exists as its own legal entity, so even as people come and go, there is continuity of the project and a legal process to deal with things like key members disappearing for months. Third, outside of donations, non-profits are eligible for free or reduced services from many companies. Even if we never received any donations, this would reduce our costs quite a bit. Companies also prefer to deal with other companies, rather than a collection of individuals. Hope this helps clarify why this made sense for us right now. &amp;#x200B;
Correct me if I'm wrong, but the ESEKF is just an EKF w/ the state as a manifold? I'll have to take a look at this paper. It looks like it's just an Unscented Kalman Filter using the manifold representation of the rotation group. I am actually in the process of implementing this exact thing. UKFs are super easy to implement compared to the ESEKF, the only thing I was slightly iffy about was taking a weighted average of rotations. I think I found that the kinematics of a three axis gyro is linear in the rotations (R\_t+1 = R\_t\*exp(w\_t)) and I just grabbed the middle sigma point. I'll have to check out what this paper does in that respect.
Wait, what? What does this mean? Generally you access a trait by passing it to a consumer expecting that trait, right?
Curious why these two don't agree: Works ``` let a = Box::new(|v| v - 1); println!("{}", (a.clone())(1)); println!("{}", (a)(2)); ``` Doesn't work ``` let b: Box&lt;Fn(i32) -&gt; i32&gt; = Box::new(|v| v + 1); println!("{}", (b.clone())(1)); println!("{}", (b)(2)); ``` So I guess my question is, what is the typing of `a`, and why does `b` not work? https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=dd84259a0256684e75458c0387e7c4d0
Wow, thank you for that amazing reply. This really lends credit to your dedication in the project. Having some amount of this effort "show through" on your foundation announcement post might help too.
If you want to know the type of something, force the compiler to tell you: let a: () = Box::new(|v| v - 1); = note: expected type `()` found type `std::boxed::Box&lt;[closure@src/main.rs:2:26: 2:35]&gt;` You can clone `a` because the compiler knows exactly what type it's dealing with, and closures automatically get a `Clone` implementation if the compiler can derive one. You can't clone `b` for two reasons. First: `dyn Fn(_) -&gt; _` doesn't implement `Clone`. Trait objects only let you do things defined by the trait in question, and the only thing you are guaranteed to be able to do with a `Fn` is call it. Second: you can't call `Clone` through dynamic dispatch, *ever*. It's fundamentally not compatible with dynamic dispatch. The simplest way of getting this to work (aside from changing your code to not need it) would be to define a new trait that defines "call" and "clone_box" methods, then implement it for a wrapper type that takes a cloneable closure. Then, you could use `Box&lt;CallClone&gt;` instead.
The `|v| v + 1` is actually a function pointer, not a closure, since it doesn't capture any values from the surrounding scope. Check out the playground link below. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=d4fee57b4fe45ba02a64c1be9ed45116
I can't find it. mind just linking your youtube channel here?
Crikey. I'm not. I'm German/Polish
https://www.youtube.com/channel/UCyKF9FafoRauY2F05eE1ZwQ
One thing I see is that you're writing to a const type which strikes me as strange, possibly incorrect. Another thing I see is that you cause undefined behavior if your two types are the same length. You've basically defeated type safety for Rust in general by doing this. 
Sorry I'm not following... &gt; you're writing to a const type which strikes me as strange, possibly incorrect `addr` is an `&amp;mut Ipv4Addr` in the gist and the compiler won't allow more than one mutable borrow from the slice. Note sure what "const type" you are referring to. &gt; Another thing I see is that you cause undefined behavior if your two types are the same length Which two types? There's a generic T for conversions from `&amp;[u8] -&gt; T` and `&amp;mut [u8] -&gt; &amp;mut T`. Regarding Serde, I didn't see it support a `repr(C)` style binary format. I'm reading/writing network packets with IPv4, TCP, etc. headers so I need strict control over the format. I've used [byteorder](https://docs.rs/byteorder/1.2.7/byteorder/) but looking for something w/less boilerplate for POD types.
You can do all that and more with CSS. https://css-tricks.com/absolute-positioning-inside-relative-positioning/ https://css-tricks.com/absolute-relative-fixed-positioining-how-do-they-differ/
Havent gotten to error handling yet, will look into this, thank you!
Sorry, maybe I'm not the best person to give advice here. My background is primarily in C/C++ (working with network data flows as well) and still learning Rust. Here's one specific issue I see: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=dd3d9091c7471643a9ab255334b5fbed The borrow has unbounded lifetime which means that your bytestream has to exist for at least as long as any reference exists.
Why `r/rust`?
&gt; The borrow has unbounded lifetime I don't think this is true. The `&amp;T` or `&amp;mut T` will have the lifetime of `&amp;self` or `&amp;mut self`. See [Lifetime Elision](https://doc.rust-lang.org/nomicon/lifetime-elision.html) in the Rust Book. The compiler error in the link you sent is expected. You are assigning a reference (`addr`) that lives outside of a scope (and thus longer) than the thing it references (`buf`). The lifetimes are behaving as expected/desire. Here's a [simple example](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=14a03d8eff33c2f2807f9d67e3b1c6b2) of what you are saying is an issue but is expected w/Rust lifetimes.
I did this at some point in a side project, but then switched to something else that feels less terrifyingly unsafe: I have structs whose fields are not actually used, but serve as input to a proc macro that computes field offsets and generates a method for each field that reads bytes from a slice. (And runs a "from bytes" conversion step, for example for reading big-endian.) https://github.com/SimonSapin/victor/blob/3736fe406a1139f059b1cddccf701514b983a11f/proc-macros/src/lib.rs My new parsing code contains very little unsafe code, and I should be able to remove it entirely when `impl TryFrom&lt;&amp;[T]&gt; for &amp;[T, $N]` is stable in the standard library. ----- Now, if you still want to go down the unsafe route: I didn’t use `#[repr(packed)]` because of potential UB with unaligned references. I had a `#[derive(Pod)]` proc macro that implemented a `Pod` trait, checked that all struct fields also implemented it, and checked that the struct had an identical size as another struct with the same fields and `#[repr(packed)]`. (The TrueType spec "manually" specifies unused fields where there would be padding.) Then there’s alignment. In the case of TrueType, the spec require every table to be 4-bytes aligned from the start. I chose to not use types that might require more alignment than that. (Namely my `LongDateTime` struct contains two `u32`s instead of a `u64`.) On the input side, I check at the start of parsing that the byte slice is properly aligned. This is almost always the case of `Vec&lt;u8&gt;` since most allocators align everything to 8 or 16 bytes. (`malloc` in C doesn’t have an alignment parameter.) For a static byte array from `include_bytes!` I have a hack with `[u32; 0]` to force alignment. Finally, rather than `transmute` I used pointer casts. (See `Pod::cast` and `Pod::cast_slice`.) https://github.com/SimonSapin/victor/blob/cd34c194d5645423df53690ba2ff288c89493ae4/proc-macros/src/lib.rs https://github.com/SimonSapin/victor/blob/cd34c194d5645423df53690ba2ff288c89493ae4/victor/src/fonts/ttf_types.rs https://github.com/SimonSapin/victor/blob/cd34c194d5645423df53690ba2ff288c89493ae4/victor/src/fonts/ttf_tables.rs
I see. I guess I'm incorrect. I myself have stayed away from any transmute usage because of the huge amount of possible UB it can cause.
This looks interesting, I will take more detailed look at what you are doing soon :) However, it's a fair amount of non-trivial code I'd like to avoid. Also ya I'm aware of the potential UB w/`repr(packed)` but I think I can get away w/just `repr(C)` in my project. It seems the transmute I'm doing w/the size + alignment check should be pretty safe if I'm going to use `repr(C)` instead of `repr(packed)`?
One other thing to consider is that hashmaps are really slow when compared to the speed of most Rust code. In a language like Ruby, hashing is rarely a significant cost, but it is often significant here. If you can restructure your code to simply push (key, val) tuples onto a Vec, it would be interesting to see how that affects performance. You can always sort the Vec by the keys at the end and then use the built in binary search to access particularly interesting keys.
This looks interesting, I will take detailed look at what you are doing soon :)
For a moment, I thought you said "jump off a *diff* today".
You might also be interested in: https://www.reddit.com/r/rust/comments/6hznoz/a_zerooverhead_refcell_variant/
Check out my crate [struct_deser](https://crates.io/crates/struct_deser) It's designed exactly for that purpose. Practically zero boilerplate (just one attribute on struct and attributes for specifying endianess), does the right thing (deserializing with byteorder). Casting has tons of problems: alignment, padding/alignment of packed fields, endianess... I don't recommend trying it unless you are professional who needs super fast code for HFT or something similar.
You can write plenty of useful programs without using every feature of the Rust language. I personally don't reach out for a language feature unless I have a very very very compelling reason. I would say learn the base language, then lifetimes, traits and generics and you should be good to go. These features aren't really riddled with gotchas. I also believe Ruby is more riddled with gotchas than Rust is, so it should be comfortable for you.
Except it won't work if at least one field type is not `Copy`, or your type has `Drop` trait.
why exactly should programms written specifically for redox work on other platforms? 
In fact, it's even more complicated, because you need to be able to query the device for what configurations it supports. My example is simplified just because I did not want to make the post even longer.
*raises hand in the air* 🙋‍♂️☺️
This looks nice. How does it compare to bincode?
Mdbook, a rust port of gitbook. And yeah, you can diff them, though you have to use the git tag for the previous versions as of a few days ago.
I'm not following all of your thoughts, but callbacks are tricky in Rust, because that would require integration with some mainloop, which is something Rust does not have by default. (Unless you mean blocking the entire thread waiting for more samples to read/write, which is not something I want to enforce for all users of the library.) As for `std::io::{Read, Write}`, they deal with `&amp;[u8]` and samples are usually larger than a byte, and making it possible to write half a sample is a footgun I want to avoid. I'll probably end up with something generic w r t sample size here, but that is a later design question. Not sure about what you mean by RAII, do you mean you're getting a new struct when you start a stream, and then the stream is stopped when you drop that struct or what?
`Future::then` expects a function `FnOnce(Self::Item) -&gt; B where B: IntoFuture`. The closure you provided returns `()` (because `println!()` returns `()`, and `panic!()` diverges), which does not implement `IntoFuture`. I'm not very familiar with futures, but I think you could either: 1. Change it to return `Result` (it implements `IntoFuture`): get_trains(&amp;client) .then(|response| { match response { Ok(trains) =&gt; { println!("{}", trains[0]); Ok(()) } Err(err) =&gt; panic!("Failed to get trains.") } }); 2. Use `map` instead of `then`.
There's a guy on YouTube who's got a channel called "Tensor Programming", I posted about him before. He's got some really good videos about rust.
[Learning rust](https://learning-rust.github.io/ ) is a quick intro. Make sure to read the chapters about ownership, borrowing and lifetimes. [Rust by example](https://doc.rust-lang.org/stable/rust-by-example/) is also good.
Cool, thanks. I am an old-school C programmer and the last time I learned HTML it was before CSS. I always found the web stuff super annoying because it appears to be completely different every time I look. I guess I will go play with web stuff again.
/r/playrust
I believe you may want to try posting this in r/playrust. This subreddit is for the Rust programming language, not the game.
How do i post it there ??
chicken-egg 
You also probably want to click reply to answer people, instead of making new top level comments.
I think there's easily enough free coding time in the Rust community to produce a full strength game engine. The real limit for producing shipped titles is *art*. the real problem is getting everyone behind one.. the types of people who are interested largely want to make their own but , Rust has the advantage that it *is* easier to combine code form different sources (thanks to traits and better compile time checks). What if you were thinking more about 'the broader support through the crate ecosystem' rather than a single game engine
A good place to just ask questions is IRC [https://www.rust-lang.org/en-US/community.html#irc-channels](https://www.rust-lang.org/en-US/community.html#irc-channels). The most important channels are #rust-beginners and #rust. It's not like a personal mentor but the hive-mind offers a lot of good answers to well-posed questions.
Like bigger open source foundations I’m guessing the biggest donations are not expected to be from individuals, but from companies. 
I see that you are using read_volatile for delays, isn't it going to depend on mcu frequency? I'm currently writing a Si4463 driver and I have a similar problem, I need to make some microsecond delays and I don't know a good way to do it.
What shall I do when I eventually update dependencies of rust-websocket and websocat to recent versions (it may be already hyper 0.13 or 0.14 by that time)? File a Request for Package? By the way, are dependencies overridden with `[replace]` OK for Debian standards (currently `tokio-core` is overridden in websocat)?
And also zooming it a little would help.
I hadn't seen Learning Rust before. That is a wonderful tutorial for beginners. I'll make sure to remember that one to share in the future!
It was already suggested during the stream and later on I recompiled my terminal emulator. But it's a great suggestion and something I haven't thought about before
If you are writing the generic instead of using it then you are the one accepting the trait and then you are calling its methods.
&gt; [...] We use @github, and @RiotChat for communication because privacy matters [...] If you value your privacy you don't use GitHub. GitHub probably doesn't do anything wrong (just yet), but you're still supporting Microsoft.
but if we have nothing private on github, why should we care too much?
What is wrong with iterators and map/filter? A typical use case for python like list comprehension can be simply done with: let new_list = list.filter(|x| x == 0).map(|x| x*x) But offers a lot more power and flexibility while being more idiomatic to rust style. What advantage are you looking for in these libraries that iterators make more painful (genuinely curious)? It might just be me but I always found pythons list comprehension to be backwards in the way I want to read it.
As soon as rust libraries come to depend on system libraries and become part of larger systems - I think yes.
Its a bit wordy, but in the pig latin code you can use `s.chars().nth(0).unwrap();`. You may additionally want to handle the case where the string is empty where `nth(0)` (or just `next()` if you prefer) gives back `None`. In this case you might return the original string or make the function return an `Option&lt;String&gt;` so you can return `None` when it can't convert.
Agree. Python's list comprehensions are equivalent to map and filter, which you can do in rust using mdaffin's syntax. It's not as neat as list comp syntax, but is idiomatic rust... much in the same way Python leadership doesn't like map/filter!
Btw I thought the rust team was officially trying out Discord, am I miss-remembering this? Shouldn't it also be on the community page linked above, because I can't find it there?
Yes, there are actually two Rust Discord servers. One is the community and one is the core team and working groups. I can't remember where I found the link to the core team one, but it may have been an internals thread.
So quite a while, then. ABI needs to be stable first, right?
Check out the repo linked in this comment: https://github.com/rust-lang/rfcs/pull/1546#issuecomment-304033345
Try asking on r/playrust. This subreddit is for the Rust programming language, not the game.
Everything is a year old...
Which are just fork of `i2cdev` crate... :)
So that’s why they’re responsible for some multi-million dollar cryptocurrency bugs...
Writing a RFP is the best way. If you put [pkg-rust-maintainers@alioth-lists.debian.net](mailto:pkg-rust-maintainers@alioth-lists.debian.net) on cc, it appears on the team QA page [https://qa.debian.org/developer.php?login=pkg-rust-maintainers@alioth-lists.debian.net](https://qa.debian.org/developer.php?login=pkg-rust-maintainers@alioth-lists.debian.net) (at the bottom) and the team members receive an e-mail. About the `[replace]` I think this is stripped from the distributed `Cargo.toml` file and in-lined by an exact version dependency. I know somebody in the team had such a case, but I don't know the exact solution they applied. An option would be vendoring the dependency into the debian package. Although we usually try get these problems fixed in upstream. What is the reason why you have to use this exact version? Is there some issue that upstream `tokio-core` can't or doesn't want to fix for some reason?
Consent is a tricky one though as they’ve had updates that will suddenly re-enable old disabled switches.
Whats the rationale for fixed duration sprints?
I just read this as, "We don't take our job seriously." Anarchy is just that: disorder. No one is going to choose to work on the boring but crucial bits. "Bug fixes? Maybe later. New features? Sign me up!"
That happens in normal process anyway. Gotta keep delivering new features so the business team actually believes work is happening. 
It's not protection against an adversary, someone with permissions could discover the file and change it. And the copying is with reflink? Aside from the possibility of an attacker changing the new files, that sounds like about the right thing.
Yeah, if I had an OS on the target platform and the tick was high enough resolution. That's why it needs to be behind a trait because different platforms need to do different things.
Just today I hacked on an Arduino project with an attached SD card and thought "they surely made this very easy, but would be nice to write it in Rust". Now it suddenly looks much more possible :)
Well, as I mentioned above, there are advantages other than only the ability to accept donations. Feel free to join our [forums](https://community.amethyst-engine.org) and post your asset server idea, we'd love to hear more about it. You are correct about the art pipeline being the bottleneck for many studios; though a not insignificant amount of time is spent dealing with engine issues. 
You're welcome! We opted to keep the initial post short and to the point, but if there's interest, I'm happy to write a more detailed post on the process....once I recover from filling out all the fracking paperwork, anyway.
Alright; even though this is only tangentially related to Rust I am willing to let the post live... ... however since the discussion occurs on r/rust, it will have to follow the rules of r/rust. Comments which do not will be expunged, post haste.
They exist to force you to break up big chunks of work into smaller chunks that you can do in single sprints, so that what you're promising each sprint is achievable. In turn, this helps with deadlines for everyone else - you know that the developers can't deliver everything in 3 months, and ask for a coherent set of features and fixes instead of the least useful 80% of a bigger set
&gt; No one is going to choose to work on the boring but crucial bits. I am very sorry to hear that you've never worked with people committed to quality. You've missed out. I have the chance of working in the company of people who care, and there is no such issue. At the moment, in a team of 10 people: - My boss is contiguously monitoring the CI pipeline, trying to make it more stable and faster. - A colleague is investigating our complex web of CMakefiles, trying to optimize the structure of libraries and standardize the build rules to both simplify it, make it more intuitive, and reduce the time of incremental rebuilds. - A colleague barely finished improving our network captures pipeline. Those are not new features, this is pure infrastructure work with absolutely no "outside" visibility. They tend to work on them during "downtime", for a couple hours a week worth of effort. In the past, I've myself worked on tracking down quirky multi-threading bugs. They've generally end up being "silly" mistakes making me yearn for Rust's Sync/Send traits, and 90% of the time "fixing" them is actually tracking them down. Of course, along the way I've also tried to introduce an abstraction or two to more systematically address the issue... although in the absence of type system support it's far from being foolproof. If your team cares about quality, then they will prioritize whatever stands in the way of quality, be it bugs, technical debt or missing features. And in this case, developer anarchy is likely work. Thinking on it, I guess my own team is actually close to developer anarchy; we tend to have personal "goals", but ample personal freedom to go about them and pick up side tasks.
If you work with multiple scrum team it makes sense that every one delivers at the same rythm, even more so if you rely on API or features delivered by another team
"Anarchy is just that: disorder.". That is historically inaccurate.
I would say that if you get frustrated with the borrow checker, just start cloning things.
&gt; Scala uses () for indexing instead of the traditional `[]` Is there any reason to keep brackets for indexing besides familiarity?
&gt; Can you elaborate on that? Are you suggesting we should set up a place where people can upload their art? honestly it's just a vague notion. Perhaps i'm suggesting - an asset server combined with exactly what you suggest: an online interface to upload and search assets (similar to the sites for 3d printing models) &gt; but we're hoping to solve that issue by providing good scripting support. I view the desire to mix scripting and core language as evidence that there's *still* space to explore in a language for games. Someone wanting to make a leap to a new language might want to wait for JAI. I put time into Rust because it did tick some of my boxes (immutability, no headers, seperating methods from types); i was pleasantly surprised also about ADTs, but disapointed in other areas (I think C++ handles vector maths better than Rust)
&gt; I need to learn rust as fast as possible Just curiosity, but why?
ok thanks for the link, I'll take a look. 
Nah, it’s not the same. In what you are describing people are still driving the product forward. Maybe it’s with short sightedness but it’s still going forward. OPs post is much closer to ‘do what you want’.
I worked at a place like this once. It was lovely for a while and then quickly turned pretty sour. In hindsight I’d never want to work like that again. Maybe if it were experimental or prototype work with no aim to ship a business product. It was to such an extreme that releases were done when we felt like it. *”Fancy releasing this week?”* is literally how it would go. Things change without you knowing. When you and someone else are working on the same feature you’ll find your interpretations never match up. Same goes with the business interpretation of what you are building. So you end up rebuilding lots of work. Where I was at we had no time limits either. This allowed you to ‘perfect’ things, but they quickly turned into projects that were forever unfinished. There was always no end in sight. I felt like I was just drifting. You have no idea what other people are doing. They have no idea what you are doing. That can make your work feel pointless. Would anyone notice if I stopped coming in? That sort of thing. Things are always a bit shit, and no one wants to ever fix that. Because it’s the ugly technical debt. It’s the code no one cares about. Just put up with it. What planning you do can be easily washed aside in an instant. There is no incentive to keep to a process.
Historically inaccurate and ignorant. Anarchy is by its definition, order. It's even encoded in its symbol: A inside an O.
I'm not opposed to this feature at all, but I do feel like it's another example of Rust getting as close as it can to what are indeed the *benefits* of some kind of class/inheritance model, without actually going all the way for what would seem to be mostly political reasons. Personally I think some form of straightforward *single* inheritance (**not** multiple) would fit in just fine with the rest of Rust and not be any more disruptive than any other new feature. It wouldn't be noticeably "weirder" than what we already have with stuff like trait objects.
In the Mythical Man Month there is a good point that the bigger the scope, the more the time is likely to drift. Generally speaking, we are more accurate at making estimations for small tasks. So if you keep the work small then it’s estimations are probably more accurate.
&gt; Can you elaborate on that? ok here's the original notion , 10months ago. like I say I haven't put any time into it. [piston discussions](https://www.reddit.com/r/rust_gamedev/comments/7p6fml/texture_server_any_existing_workscopeinterest/) just brainstorming really
Web browser
Ah, thank you!
I want to to this: my_vec.iter().for_each(|s| my_hashmap.insert(String::from(s), "value")); But I cannot because `insert()` on a HashMap returns an `Option&lt;T&gt;` while the `for`\_each() on an iterator expects `()` from the closure, so this will not compile. So I do this: my_vec.iter().map(|s| my_hashmap.insert(String::from(s), "value")).for_each(|_| ()); And while this works this is certainly not the best way to do it. I just don't want to care about the return type from `insert()` \- how can I just ignore it?
Hi Rustaceans, I have questions with small examples. Here's the link: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=64b7e05b795996464cb98cc74acadf8a](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=64b7e05b795996464cb98cc74acadf8a) Here's the code: struct Something {} struct Data&lt;'b&gt; { something: &amp;'b Something, } struct Var&lt;'r, 'b:'r&gt; { data_opt: Cell&lt;Option&lt;&amp;'r Data&lt;'b&gt;&gt;&gt;, } fn main() { let something = Box::new(Something {}); let data = Box::new(Data { something: &amp;something }); let var = Box::new(Var { data_opt: Cell::new(None) }); let mut map: HashMap&lt;String, &amp;Data&gt; = HashMap::new(); link(&amp;var, &amp;data, &amp;map); link2(&amp;map, &amp;var, &amp;data); } fn link2&lt;'s, 'a:'s, 'r:'a, 'b:'r, 'c, 'd:'c&gt;( map: &amp;'s HashMap&lt;String, &amp;'a Data&lt;'b&gt;&gt;, var: &amp;'a Var&lt;'r, 'b&gt;, data: &amp;'c Data&lt;'d&gt;, ) { var.data_opt.set(Some(*map.get("key").unwrap())); } fn link&lt;'s, 'a:'s, 'r:'a, 'b:'r, 'c, 'd:'c&gt;( var: &amp;'a Var&lt;'r, 'b&gt;, data: &amp;'c Data&lt;'d&gt;, map: &amp;'s HashMap&lt;String, &amp;'a Data&lt;'b&gt;&gt;, ) { var.data_opt.set(Some(*map.get("key").unwrap())); } This yields two error messages: error[E0623]: lifetime mismatch --&gt; src/main.rs:31:22 | 27 | map: &amp;'s HashMap&lt;String, &amp;'a Data&lt;'b&gt;&gt;, | ------------ these two types are declared with different lifetimes... 28 | var: &amp;'a Var&lt;'r, 'b&gt;, | ----------- ... 31 | var.data_opt.set(Some(*map.get("key").unwrap())); | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ...but data from `map` flows into `var` here error[E0623]: lifetime mismatch --&gt; src/main.rs:39:22 | 35 | var: &amp;'a Var&lt;'r, 'b&gt;, | --------------- | | | these two types are declared with different lifetimes... ... 39 | var.data_opt.set(Some(*map.get("key").unwrap())); | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ...but data from `var` flows into `var` here I have two questions: * Why are the errors different considering that `link` and `link2` do the exact same thing? * Is there a tutorial/blog post how to around this kind of error? I can't seem to understand the error. More explanation is welcomed here as well. Thank you.
I have working driver for the Si4463, it's not polished yet, that's why it's not up on GitHub yet. But reimplementing doesn't make much sense, so I'll put up what I have (+ some rudimentary docs). I'll send you a message once it's up.
&gt; Writing an engine and creating behavior for a level just have completely different requirements and other target groups. conversely, (i) this has been done - on the playstation - a custom LISP was written which had low-level support for unusual DSP units *and* could handle the dynamic 'per-level' ad-hoc coding use case. (ii) dynamic loading of code code is possible for shaders, which have now generalised to *compute shaders* .. so consider that actual high throughput bulk compute power can be run in a dynamic, reloadable way, whereas core engine code can't .. how did we end up there.. I think this is all indicative that there's more space yet to cover. Frustratingly, when I originally discovered Rust, it was closer in feel to the middle ground with the sigils (which made the language look a lot less 'beaurocratic' - the sigils could melt away leaving you to read the salient points of your problem. I think somewhere between full inter-function inference and gradual-typing , the distinction between 'scripting language' and 'systems language' could fall, if done right.
There also is a trick to access chars with indexes other than `0` in O(1). s[index].chars().next()
I should get a copy. I replied on sibling that fine grained schedules are crucial, but I don't get how scrum helps meet that. 
Using Javascript or WASM is not an option: * lack of multithreading * WASM is sandboxed and needs JS to open files which is bad for performance
Isn't it enough to use \`#\[cfg(target\_\*="")\]\` functions to implement delay?
Unfortunately 'target' only gives you the architecture of your microcontroller and days nothing about which RTOS you have (if any) or your timer configuration. The best solution is to take some T where T implements some Delay trait. You can then plug in any compatible implementation (busy-wait, wait for timer interrupt, pend on semaphore, etc) at compile time with zero run-time overhead. Monomorphisation is brilliant for embedded systems. 
I understand the multi threading issue and a web browser solution surely isn't a solution to your issue however: &gt; and needs JS to open files which is bad for performance Just how quickly are you going to be dragging and dropping?
Wouldn't that require s[index..]?
I’m reading it right now and it’s an interesting read. I’d argue one should take it with a grain of salt. It was based on software processes of the 60s. So many of the solutions are quite outdated. Between the lines there are issues which still hold true to today. If I had of read it at University I’d have probably dismissed it. It’s only after doing software engineering for years that I feel I really understand what he’s saying. Because it has these layers of outdated stuff on top. For that reason I’d say it’s a bit of a tricky read. I’d definitely recommend it.
I did scrummed projects with whimsical client changes jumping into front of queue and the marble floors getting shined while there are walls to build 😩
This is the GetText approach. Some love and others hate it. I find it much more structured and maintainable to use a key-based approach, such as `I18n.t('some.translation.path')`, with the translations (including English as the default, or another language) coming from an external source like a YAML file.
It's how Facebook runs engineering. They're not tiny...
You are right!
Afaik &lt;input type="file"&gt; html element would obtain the data from the operating system and copy the data from Javascript to WASM afterwards.
Honest question: what dictionary do you use? The first definition I find is: &gt; a state of disorder due to absence or nonrecognition of authority &amp;#x200B;
Go talk to some Facebook engineers - at the IC level, you do what you think is best.
Thanks! Makes perfect sense.
True, but an adversary with user permissions could also attach to the process and change any memory (like gdb for example). I think this is impossible to prevent and makes mmap as (in)secure as copying the file into memory traditionally. Yes with reflink.
I use gtk-rs and their drag-and-drop functionality. I'm assuming you want a simple UI toolkit to provide this, which GTK isn't really, but I wrote [a simple example here](https://github.com/gtk-rs/examples/blob/master/src/bin/drag_and_drop.rs) and [another one here](https://github.com/gtk-rs/examples/blob/master/src/bin/drag_and_drop_textview.rs)
&gt;It's not as neat as list comp syntax, but is idiomatic rust Disagree,I prefer not having to learn a separate language just to be able to operate on iterators. The only language (that I tried) for which I like this kind of syntax is [Scala](https://docs.scala-lang.org/tour/for-comprehensions.html)'s for comprehensions,since the nested loops resemble nested iteration,and require less visual parsing to read when formatted.
Process is about scaling teams to build larger-scale software. A good rule of thumb is that *any* process will work with a project staff of ten or fewer really solid people. Make any three of those people terrible, or add five more to the project, and most processes break down completely.
I found this very helpful for my thesis. [http://ethaneade.com/lie.pdf](http://ethaneade.com/lie.pdf) Excellent notes and derivations for all sorts manifold groups used in computer vision &amp;#x200B;
Single inheritance would entail much more pervasive subtyping as compared to what we have today; this would make reasoning about the dynamic and static semantics of Rust more complicated than it already is turning language design into a mine field; subtyping and type inference also don't mix particularly well. The subtyping we already have causes headaches particularly wrt. variance and is generally a source of confusion when coupled with unsafe code; let's not make matters worse. I also think inheritance is not particularly good for code quality and maintainability...
To be fair, the proposed library (slotmap) seems to use unsafe quite liberally.
Extension. Because the trait is Extending the functionality of the struct. 
Right. For those who like the key-based approach, there is [https://projectfluent.org/](https://projectfluent.org/). Personally, I do not like this approach, because it puts the string far away from the use. You always need to look at two positions when reading code or changing the code, and remember what are the parameter and so on. Having the string inline is much easier and readable. For the same reason there are lambda as a language feature. (Think about grepping for an error message to find out what part of the code is throwing it out. Using the key-value approach, you'd have to grep twice) Also there is the fact that the keys are strings and are not checked at compile time.
My disagreement was about the neatness of list comprehension syntax in python in comparison to Rust iterators(Maybe I should only quote the statement I disagreed with?).
Some counter-arguments: 1. Separating the string from the usage is similar in concept from separating data from behavior, which is one of the selling points of Rust (e.g. idea behind Trait system over inheritance). It may be more readable in a small project, but if you have thousands of strings peppered all over the code, it can actually make it harder than a symbol-based approach. 2. The string can change due to non-functional requirements (e.g. labelling changes in the product). Separation allows changing text without changing the program. 3. The same string can occur in different places, and updating them by changing every place in the code is more of a hassle than just changing the translation. You only change the code if you want a different (or no) string to appear, not to change what the same string says. 4. Sometimes, the same English string is translated to different non-English strings, depending on context. With GetText, you need to remember File+LOC the string came from, which is harder especially if non-developers need to work with strings, such as your translation team. With symbol-based approach, you instead work with the string path, which can be more logically structured for translations than File+LOC. Finally, why can't we check for keys at compile time? Is this just implementation limitation? In theory, one could, at compile time, preprocess all I18n invocations, and check the keys for existence or correctness, before building a static map of strings for use at runtime. I'm not sure if it's possible with Rust's macro system though.
&gt; my_hashmap.insert(String::from(s), "value") Put a semicolon behind the insert statement like `my_hashmap.insert(String::from(s), "value");`. The issue is the implicit return and the semicolon disables that. 
`winit` library does support file drops. If Azul doesn't it means it doesn't pass that event to the user. I haven't worked with Azul but my guess is that it shouldn't be hard to extend it to support this.
Valid points. Made me reconsider my view. Admit that I have not seriously tried Rust yet in any projects.
Oop isn't just political. It's generally considered bad. Scalas creator himself has said Scala 3 would have composition and no inheritance (If I understood him correctly) 
That's pretty cool, I find developer process fascinating - just look at this thread, opinions abound. I've found agile to be really great when there's \*full team buy in\* and understanding. Anything less than that and it seems to fall apart completely. I've experienced many, many different attempts at process for many different types of teams (data science, engineering team, detection and response). I've seen process that went amazing in one team completely and absolutely fail in the worst possible ways in other teams. Sounds like this process is working for your team - that's awesome. I wish I had advice, like 'stick with it' or 'careful for' but the whole area is so complex I wouldn't know where to begin. I'm happy to see anecdotes like this though.
It's funny - I've heard similar criticisms of agile! Bug fixes can't get prioritized because eyes are on the prize - features. The reality is that it almost always comes down to how developers feel. In agile, if developers can make themselves care about bugs, those will be in the next sprint. If they can't, features.
Yes, we're lucky rustc diagnoses them :)
Maybe, I don't see how a rust like implementation would look, but this seems like a terrible idea.
It looks like you're using the intra-rustdoc links feature: https://github.com/rust-lang/rust/issues/43466 It hasn't fully landed yet, so maybe it's only on nightly? What happens if you run cargo +nightly doc?
I think both of the issues mentioned can be solved by tooling, cannot they? I'd imagine the inline issue to be solved by having a plugin inform your text editor/IDE of choice about the actual value of the key; and the same plugin could validate that the key exist at the same time, otherwise displaying a warning.
Having never worked on translation stuff, maybe this is a dumb question ... with the key-value approach, how do you make sure that every key used in the program has a value for every language? I'm guessing if you made a "master list" of keys somehow, you could check all the YAML files against that as a schema at build time, but then the question is how do make such a "master list"...
Thank you Josh! It is so obvious now... I needed to add `{}` around the statement as well. my_vec.iter().for_each(|s| { my_hashmap.insert(String::from(s), "value"); }); &amp;#x200B;
I'm targeting B1 since I can source that one for very cheap (~1.50$), but I may end up testing (and thus integrating) C2.
&gt; let display = tr!("There is one new message" | "There are {n} new messages" % msg_count)); How do you handle language where the number of plural cases differ from English? For example, checking the [Localization and Plurals](https://developer.mozilla.org/en-US/docs/Mozilla/Localization/Localization_and_Plurals) from Mozilla: - No plural: example, Chinese. - Singular/Plural, 0 is plural: example, English. - Singular/Plural, 0 is singular: example, French. - Last digit is 0/1/other (3 forms): example, Latvian. - Is (1 or 11)/(2 or 12)/(3-10 or 13-19)/other (4 forms): example, Scottish Gaelic. - ... That is, is it possible to implement custom logic based on the value of `n` in the "text"? And if so what is the point of having 2 messages to start with since most languages besides English will do the split differently?
I also have a crate that has been affected by changes to intra links behavior. I've opened 2 issues about it: &amp;#x200B; \- [https://github.com/rust-lang/rust/issues/55364](https://github.com/rust-lang/rust/issues/55364) \- [https://github.com/rust-lang/rust/issues/55365](https://github.com/rust-lang/rust/issues/55365) &amp;#x200B; See if these are the same issues you've run into as well. &amp;#x200B; Since it's not confirmed whether these are bugs or intentional changes, I just updated my links to conform to the new behavior.
&gt; `let display = tr!("There is one new message" | "There are {n} new messages" % msg_count));` This is sooo breaking on languages with multiple pluralrs or rules for plurals that don't exactly match English. There has been a lot of work over the years for every major translation system, with multiple transitions and API breaks in some cases, and it would pain me to see you go through all that all over again. I suggest looking at how gettext and other similar frameworks do plurals so you can actually handle them correctly. 
Not true, I worked at a company where the process didn't make it work with two developers. Basically, the CEO didn't trust me with all of the credentials or access to everything which made it impossible to do my work, and the other dev didn't care. I ended up leaving, the end.
Uh, lisp had macros for a long time
This is handled by gettext. The idea is that the source code is always english (with two forms). The translations can have all the many forms you describe. The fact that the original program has to be written in english is a limitation of gettext, but it could be changed in the future, by extanding the syntax to support more forms.
Any *sane* process. Also, if the other developer didn't care, I'd say your team was 50% fail… :-)
67% since the CEO was in charge of it (despite not being a technical person)
Imgui-rs Highly recommend
&gt; benefits of some kind of class/inheritance model, without actually going all the way for what would seem to be mostly political reasons. This is like saying that tools like `Rc` or `Cell` are getting as close as they can to the benefits of juggling sharing and mutability, without going all the way by just throwing away the borrow checker.
I mean, the original macros were for assembly, which is dynamically typed
Touché
Let's take a look. ``` fn link2&lt;'s, 'a:'s, 'r:'a, 'b:'r, 'c, 'd:'c&gt;( map: &amp;'s HashMap&lt;String, &amp;'a Data&lt;'b&gt;&gt;, var: &amp;'a Var&lt;'r, 'b&gt;, data: &amp;'c Data&lt;'d&gt;, ) { var.data_opt.set(Some(*map.get("key").unwrap())); } ``` We have an `&amp;'a Var` moving `map.get("key")` into itself. `Var` is constrained on lifetimes `'r` (which is how long the **reference** to the inner `Data` lives) and `'b` (which is passed through into `Data&lt;'b&gt;`). The `HashMap` contains references with lifetime `'a`. In order for something to be moved into `Var` it must have lifetime `'r`. We see that `'r: 'a`. However, the `HashMap`'s `'a` lifetime **does not** live as long as lifetime `'r`. We only specify that lifetime `'r` lives as long as **`'a`**. So the problem is that the `HashMap`'s references' lifetimes do not live as long as `Var` needs them to. This can be fixed by changing the lifetime on `HashMap`'s references to `&amp;'r Data&lt;'b&gt;`. Similarly with `link`. (Sorry for the wall of text. I hope I answered your question!)
You are making very good points, and there is advantages to both approach. 1. It is correct that one should separate the data and the behaviour. It's just that string literal is not necessarily the right level of separation. Having the translation system forcing that on the developer is not a good idea IMHO. First of all, when they deserve to be separated, tr!() call can still be separated. (For example, you can still return an `Error` enum all over your code, and then have all the strings within the `impl Display for Error`.) Forcing the separation would be like removing numerical literal in the code under the premise that hard-coded value are bad. Most non-translated application do not separate all their strings. (rustc doesn't) 2. It is still possible to change a string without recompiling the program, by providing an english translation. (english to english that only retranslates the strings that needs changes.) I admit this is just a hack. It is quite annoying that you cannot fix a small typo in the original text without invalidating all the translations. (Although gettext tools makes that somehow easy) 3. If the exact same string is occurring at different place, one can attempt to seperate it by placing it in a different function. (Or assigning it to a variable) 4. When the same string occurs with different context, it is possible to add a context in the macro (that's the `"context" =&gt; ... ` syntax in my crate). The comment above the translated string is also extracted by the `xtr` tool and shown to the translator as a comment. I think you are being mistaken that File+Loc is used for anything else than information to the developer. Yes, you are right that the keys could be checked at compile time. It's indeed an implementation detail. It's just that currently, Fluent does not do it, AFAIK. Overall, I still very much prefer the gettext approach over forcing a key/value system. But maybe this depends on your application and its exact needs. 
Doesn't require a PL research background to see would either mean changing the implementing data size hiddenly or attaching heap allocated data. which is why I say I don't see a more clever of implementing it, but it does seem like two terrible options.
[Inertial Navigation System](https://en.wikipedia.org/wiki/Inertial_navigation_system)
I'm trying to follow the rule given: "Keep in mind the details about UTF-8 encoding!". So as much as possible I would like not to choose an arbitrary number. \`nth()\` is nice, I note that it consume the returned element.
&gt; This is like saying that tools like Rc or Cell are getting as close as they can to juggling sharing and mutability, without going all the way by just throwing away the borrow checker. I don't think that's an accurate analogy.
I would generally disagree that inheritance is specifically, by itself what makes a language "OOP" simply by existing. Composition while useful for many things also is just a fundamentally *different* concept than inheritance, and not a universally applicable way to represent every construct. Not everything can accurately be described as "a collection of otherwise unrelated things that have been attached to each other in some way that builds a useful final result".
I obviously can't speak to any of the points about technical implementation difficulties that might arise in that context, and I'm sure what you said in that regard is true if you say it is. As far as "code quality/maintainability" though, personally I've seen some bizarre trait object constructions out there that would very likely be much more cleanly representable via simple linear inheritance.
Error handling in Rust is either pretty convenient (the ? operator, and occasionally unwrap/expect for errors that should never happen) or extremely verbose (matching). If you find it getting annoying, maybe skip to the chapters about the question mark. Otherwise, if it's not slowing you down, verbose matching is fine. It makes it clear what's going on under the covers anyway, which is always nice.
Anarchists want disorder and the more disorder you want the anarchister is is.
I have the exact opposite problem. Agile, in my experience, can mean that you have to constantly deliver new features and rarely get the opportunity to spend time on the accruing technical debt. Of course, the plural of anecdote is not data.
That's not a project with two solid people. That's a project with three people, two of whom are terrible. A leader who doesn't let poodle do their jobs is terrible and someone who doesn't care is terrible for that project even if they might be good on another project.
Keep in mind if you get a mutable reference to an iterator, that is also an iterator. That means you can continue to use the iterator afterwards. let mut it = s.chars(); let c = (&amp;mut it).next().unwrap(); let n = it.count();
I am well aware of iterators but I like python-like list comprehension better in most cases.
I'd be more than happy to! For anybody responding to this thread: if you're interested, NYAR maintains a list of potential Rust mentors here: https://github.com/not-yet-awesome-rust/mentors
Not related to your rust crate, but do you have any good resources for learning the sd/mmc protocol? I have been working on a toy OS for the raspberry pi and have not been able to figure out how to write an SD/mmc driver
Thanks so much for this!
All the big tech companies are like this. Google, Amazon, Fb Microsoft
It's a pretty bad idea to write non idiomatic code on purpose regardless of language. I like python myself but would not consider something like this. 
Sure. But in many cases management will prioritize features over quality, hence the criticism. Maybe it's the right call but that isn't really my point.
Yep. The process starts to kick in when a single team can't do the whole software anymore. And really 10 is optimistic: seven is a more realistic bound in most cases. 
Put offsets in the vtable like you do with function pointers is the first thing I think of. Pretty trivial change.
Also it's javascript.
&gt; Rust looks like an incredibily complex language packed with features and gotchas It has more features than I'd like but there aren't that many "gotchas". &gt; what concepts or patterns would you recommend to skip when learning Rust ? Seems like a bad attitude to have coming in to learning a new language.
Tangentially Rust-related. It's mostly an overview of how I got embedded debugging bootstrapped with minimal equipment. Hopefully it's useful for others looking to break into embedded development with Rust. Blog generator is still a WIP. Comments/suggestions on general site wonkiness/formatting are welcome :)
What does that even mean
If the forces in your program are short ranged, then you can use a [neighbor list](https://en.wikipedia.org/wiki/Verlet_list) or a [cell list](https://en.wikipedia.org/wiki/Cell_lists) to keep track of pairs of particles that are close to each other. This will make your force calculations O(n), but constructing the lists will not be O(n). I think that a neighbor list will help more than parallelizing the loup. 
They are used for array indexing in expression context, so you have the same ambiguity.
Types and values are in separate namespaces in Rust--you can have a type and a value with the same name. So no, you can't resolve the ambiguity that way.
Parentheses indicate function calls, which in Rust are never lvalues (unlike in C++). You would need to solve that somehow. Now you're potentially talking major surgery to the entire borrow checking system. 
The reasoning behind having index operators was *never* "`foo[]` is a simple memory access". The reason is to have an overloadable operation that takes an argument and produces an lvalue. Functions don't produce lvalues.
To be honest,I find this: let new_list = list .iter() .flatten() .filter(|x| x &gt; 5) .map(|x| x * x) .collect::&lt;Vec&lt;i32&gt;&gt;(); much easier to read than this: let new_list = vecc![x * x; for row in list; for x in row; if x &gt; 5]; The latter one just looks backwards to me,refering to variables introduced later in the expression is confusing. Compare this to the equivalent Scala syntax,[for comprehensions](https://docs.scala-lang.org/tour/for-comprehensions.html): val new_list=for{ row &lt;- list; x &lt;- row; if x&gt;5 } yield x*x This reads better than the list comprehension syntax,following the order of iteration nesting,and is just as powerful.
This is only the source syntax (which is in English), the translation files can specify multiple plural forms, and gettext will pick the right one based on `n`
One major drawback of using gettext is that gettext doesn't support arbitrary inflections/linguistic cases: only plurals. For proper language support you need to handle declensions as well (and sometimes conjugation). E.g. if you're writing an instant messenger app and need to use a username in a sentence, you may need to correctly conjugate verbs to match the user's gender. Sometimes you'll need to decline substituted nouns, and that's tricky too. (it gets worse with languages that decline proper nouns, but that's a general problem not specific to the API) Gettext handles the main problem: plural cases, but doesn't handle other linguistic cases and inflections (and the one-dimensional mapping approach isn't very amenable to this). Fluent is flexible enough to deal with this.
Awesome
Hi! I'm one of the authors of Project Fluent. We've explored the source-string-as-key model for quite a while and found it to be fundamentally flawed. That's of course just our opinion based on our work on the Mozilla project, but maybe you'll find it useful to read through our reasoning - https://github.com/projectfluent/fluent/wiki/Fluent-vs-gettext
So just from taking a quick look at your post (i haven't run your code myself) I can immediately see two possible issues. The first is that your for loops are slightly different: your rust loop should just be `for denom in 2..curr`, as using `..` only goes up to the end value but does not include it (see [here](https://doc.rust-lang.org/std/ops/struct.Range.html). If you wanted to include the end value you would use [`..=`](https://doc.rust-lang.org/std/ops/struct.RangeInclusive.html). The second is that you mention running `cargo build --release`, but you don't mention how you ran the program, which makes me think you might've just done `cargo run` after it. `cargo run` will always run the debug build, `cargo run --release` will run the release build, and there's no need to perform a `cargo build` before either of these.
&gt;The idea has been tried before it's called abstract classes and it's universally known as a terrible idea. Uh, what do you suppose traits and trait objects amount to? Do keep in mind traits were at one time literally called interfaces in Rust.
Hey, thank you for you resource. I already implemented it. I actually was more concerned about the parallelization. You can find the updated package https://github.com/dineshadepu/prestige
I will release a playable demo for free once I'm there. But the amethyst developers themselves have developed a game for Ludum Dare (the last one I believe) which is much more complex and complete than the examples. It's on their GitHub: https://github.com/amethyst. Meanwhile the entire source code of my game I'd: https://gitlab.com/pi_pi3/arewegamedevyet
So once I run `cargo build --release` I'm running it with `./target/release/find-prime` (there's obviously more code that takes the input for the nth value but the code I shared above is the core function for finding the prime). That's why it is so puzzling, because I think I'm definitely running the correct code. Also thanks for the tip about the range, that was definitely a bug so I fixed that (although that doesn't improve the runtime). Here's the repo if it helps as well: [Repository](https://github.com/liamross/rust-prime-finder)
&gt; This is kinda disappointing, and a little discouraging since I'm trying to learn Rust because I have heard it is extremely quick. For starters, I want to give you some numbers to back up this idea. will say that [Rust *is* generally faster than JavaScript](https://benchmarksgame-team.pages.debian.net/benchmarksgame/which-programs-are-fast.html) (labelled Nodejs here, since it is run with Node). In these highly optimized benchmarks where the JavaScript code is often using C libraries to accelerate its performance, it is still 4x to 5x slower than Rust in the median case. If we look at [these benchmarks](https://www.techempower.com/benchmarks/#section=data-r17&amp;hw=ph&amp;test=plaintext&amp;l=yyku0v-1) we can, again, see that Rust is generally significantly faster than JavaScript. The cases where it isn't are with synchronous web frameworks... async is *necessary* to get good web framework performance out of Rust, that's just how networking is with languages other than the few like Go that use green threading / goroutines. Rust also makes it a lot easier to take advantage of all of the cores in a computer for parallel computation in a single process, where you have to launch a process per core with JavaScript, which makes it much harder to do shared computation. Now that this is out of the way, my *intuition* is that you've written was is literally a textbook example of an easily JITable function. It operates exclusively on its arguments (so there's no global state), the function is absolutely tiny, and the only operations that it does are purely numerical. Chrome's V8 JavaScript engine is able to take this function and optimize it into machine code that is as efficient as what Rust would generate, because it doesn't have to keep checking the types of things, and it doesn't have to worry about anything going wrong inside the optimal machine code that it generates. The problem is that these properties don't hold for real-world JavaScript programs, so this microbenchmark gives the wrong impression. Real-world code is much larger and less well defined, so the JavaScript runtime has to be a lot more careful. As for the results you're seeing, I'm not seeing them. Running `console.time(); find_prime_iterative(20000); console.timeEnd()` in both Chrome and Firefox, I get `3953ms` and `3925ms` respectively. With Rust, I get `3.944s`, which is `3944ms`. Optimal machine code is optimal machine code, and our JavaScript JITs are magical pieces of technology for tiny, numerical functions like this. The end result isn't any faster than what Rust makes here. Screenshots all around: [Chrome](https://i.imgur.com/tLkL4iw.png) [Firefox](https://i.imgur.com/AVZfydi.png) [Rust](https://i.imgur.com/vbX2tXl.png)
There's a logic error in your rust code - The for loop runs until the initial value of `curr` (and doesn't update its limits when `curr` is increased). This probably changes the behavior enough that the total runtime increases (as well as giving the wrong value)
I think this was covered: https://www.reddit.com/r/rust/comments/a0g730/new_to_rust_discouraged_by_slowrunning_code/eahi2yw/
Ah yeah, great catch there. The issue is that the range struct is generated once at the beginning, but the javascript loop condition is evaluated continuously. I bet that would explain the runtime difference.
I tried running the code myself and did see the same behavior you did. See my comment [here](https://www.reddit.com/r/rust/comments/a0g730/new_to_rust_discouraged_by_slowrunning_code/eahj7mb/) for the fix! Props to u/mutabah for spotting the issue.
Replacing the iterator with a while loop yields the same performance (or slightly faster than browser) on my computer. ``` fn find_prime_iterative(initial: u32) -&gt; u32 { let mut prime = 1; let mut curr = 1; let mut prime_count = 0; while prime_count &lt; initial { let mut denom = 2; while denom &lt; curr { if curr % denom == 0 { curr = curr + 1; continue; } denom = denom + 1; } prime = curr; curr = curr + 1; prime_count = prime_count + 1; } return prime; } ``` I am not an expert on loop vs iterators, however, and don't know when and where iterators become slower than loops.
First off thanks for taking the time to write all of this! Maybe it's just my computer that is taking so long with the computation I'll have to play around with that.
This isn't due to iterators, but actually due to the loop condition being continuously evaluated instead of having the range constructed at the beginning of the loop and not being updated.
That changes what the code does so it's not the same algorithm as what the JavaScript code is doing. I don't think the current edition is *right*, necessarily, but it is the same between them, plus or minus one iteration.
This change had no impact on the performance on my computer.
Are you sure? This dropped the runtime of going to 20k from 8.7s to 2.4s for me.
Regarding the flash configuration fields: I haven't worked around them within the confines of the `cortex-m-rt` crate provided linker script, but I've done [this](https://github.com/jmesmon/mmaze/blob/master/ld/armv7m.lds.S#L24-L42) in the past. For working with the linker script provided by `cortex-m-rt`, instead of using section location specs, using separate memory regions may be possible. The complication will be whether gnu ld will be happy with 2 `SECTIONS {}` blocks or not. Still will need some small changes to the `cortex-m-rt` ld script to support this properly as it presumes that interrupt vector always goes in `FLASH`, along with everything else. Using a seperate memory region would require that the user (via `memory.x`) has control over where the interrupt vector goes (`REGION_ALIAS` may be useful here). For getting this all working initially, writing a custom `link.x` (with a different name to avoid conflicting with `cortex-m-rt`'s) may be useful. Alternately, working on `cortex-m-rt` is the way to go.
[Absolutely sure.](https://imgur.com/a/qHYh0aO) You can see that I'm catting the code before running it each time.
Interesting. What version of rustc do you have? I'm on 1.30.
I was on 1.29.2, but I did a `rustup update`, and the results are unchanged on 1.30.1. The results *shouldn't* be different anyways. That's not how Rust loop iterators work. The expression `2..(curr - 1)` returns an `Iterator` immediately. That `Iterator` is then iterated on for the duration of the loop, which is until it returns `None`. It absolutely doesn't create a new iterator with each loop as you edit the curr value, because that would be super magical. It would feel a lot like having both an immutable and mutable reference at the same time, which is not allowed.
You're right about how the Range version works, but you're missing the difference with the new version. Because we're now using a while loop the loop condition is evaluated fresh every iteration. Because we change curr inside the loop, this causes a change in behavior.
Ok, you're right about that... the second version is mutating the target while iterating, but why would that make it faster? It's just raising the ceiling as you keep iterating, not lowering it.
Longer assembly can sometimes be faster, the length is hard to use as a predictor of performance on modern architectures. It would be nice if you could post some screenshots of catting the code and then seeing it take significantly more or less time doing it the two ways. I've tried to be as transparent as I can about the results I'm getting, and I don't see why there would be a marked difference in performance elsewhere. I assume we're all using x86_64 processors, not something weird like 32-bit x86 or ARM.
I did higher up. https://i.imgur.com/CrPWwwQ.png
Traits attach functionality after the fact, where as abstract classes attach data before the fact. The difference is subtle but also huge, functionality is cheap and easy to change. Data is forever and hard to manage, therefor it's better to not change the underlying data but instead use composition of data if you want to extend something. Also interfaces almost got it right in other languages but again they had to be attached before the fact removing the ability to ever extend certain types with generic functionality.
Interesting. If it makes you feel better, adding `target-cpu=native` makes the `while` loop version have longer assembly than the range iterator: https://godbolt.org/z/ovPW-I But, yeah, this is some weird stuff.
&gt; where as abstract classes attach data before the fact Not really. Actual abstract classes in whatever language are just that: abstract. They're just collections of methods, largely identical to the concept of interfaces. &gt;Also interfaces almost got it right in other languages but again they had to be attached before the fact removing the ability to ever extend certain types with generic functionality. I'm struggling to think of what language you might even be referring to here.
Is that your retention or you think people don't retain information?
It is possible to have multiple SECTIONS, if you insert them at the right place using INSERT AFTER. With that, I've succeeded in assigning different memory areas for some large buffers using the default `link.x` [in my `memory.x`](https://github.com/birkenfeld/stm_display_rust/blob/master/memory.x). It's also now mentioned in the quickstart's template.
Very nice post! How would it look like if you used the new async/await syntax?
Their page says: &gt; We designed BOLT to satisfy three important requirements. It needed to &gt; &gt; - Compatible with code generated by any compiler or a mixture of code from different compilers. &gt; - Able to support any code that does not have source code available (such as vendor-supplied libraries). &gt; - Able to support code manually written in assembly in order to optimize its layout. So it likely should work.
That is pretty much my Agile experience, and if you want to have some technical debt we had to pretty much had luck and a epic fall out of the release schedule..
I personally think it is too little of a gain to be worth adding complexity to the language. Wouldn't it be better to make it a macro?
Is it a good idea to use println inside the measurement? I guess it changes the results significantly.
Not directly related to your question, but that `continue` should be a `break`.
After having received a lot of PRs from /u/barskern for \[\`cargo-with\`\]([https://github.com/cbourjau/cargo-with](https://github.com/cbourjau/cargo-with)) over the last few weeks I am planing on pushing a new release this week. \`cargo-with\` is a small cargo-plugin that helps you run your binary/test/example through external tools such as gdb.
Never heard of this awesome plugin. Thanks for sharing!
My first (rust) crate [iso639-1](https://crates.io/crates/iso639-1) ... just an enum. Happy day :)
Oh my, I have not seen this posted here. I totally understand the skepticism, I was skeptical myself for a long time, but after almost 2 years and watching the company grow from a bit over 10 people to 70-ish, with 50 or so developers now, and everything still working, the empiricist in me has to take over the doubts. Programmer Anarchy doesn't mean we aren't organized, the organization is just not enforced top-down but emerges bottom-up around tasks in ways participants see fit. We also do have some processes to follow across company, like a pretty strict policy about code reviews.
The formatting is at a different layer of gettext. (gettext does not do the formatting, the translated text can be in any format) &amp;#x200B; I did not know ICU MessageFormat, perhaps it is a good idea to use it or a variant of it as the formatting back-end of the \`tr!\` macro.
Not a direct answer to the post itself, but: it takes less than 3 sec to count all primes below 10^10 in Rust if done correctly: https://github.com/huonw/primal - it would be microseconds to get to 20,000th prime.
A `break` doesn't work either, but yes, the loop is borked in both the Javascript and Rust versions. The 100th prime is 541, but OP's code gives 389. The playground appears to currently be borked as well, but here's some [corrected code](https://gist.github.com/BartMassey/0fa845b7a1d9a910b26db10e401995c6) including a bunch of versions of this thing.
&gt; There was very similar work presented at this year's LLVM developers meeting which may interest you: https://www.youtube.com/watch?v=F-lbgspxv1c Oh that's pretty cool thanks for that, was a good watch :) He mentions BOLT at the end, seems they're doing similar stuff but they're not related? So LLVM is working on having something like BOLT features built-in? &gt; Yes, except it is something the nightly Rust toolchain could do already. It would just require a nontrivial amount of unstable infrastructure (you need PGO and LLD support, both are unstable). I suppose if some test cases or benches were supplied with the source being compiled, they could be run to automate certain workloads that could be profiled and optimized? Or I guess that might not work as well as an actual run of the binary with some parameters/input. So you're saying one day, Rust compilation might be able to offer similar benefits BOLT does? The features required to do so are just unstable atm?
Because the "unfixed" version counts fewer false primes than the "fixed" version before stopping, so it takes longer to terminate. See [my comment](/r/rust/comments/a0g730/new_to_rust_discouraged_by_slowrunning_code/eahs3q8/) which corrects the bug.
I've got a function that is generic over both integers and floats (using the `Num` trait from the `num_traits` crate). I've got a problem where I need to call `.floor()` if it's a float, and do nothing if it's an integer. Here's a link to the code in question: https://github.com/phayes/tallyman/blob/master/src/quota.rs#L66 I *think* I just need to wait for trait specialization before I can do this, but maybe there is another solution?
Thanks . Its the best one
Hey this looks super handy. It would also be great to be able to get the name of the language as a string (maybe both in english and the name of the language in the language itself). 
Darn, I've used these in other placs and figured it'd work here too :( Thanks for cleaning up my mess.
This isn't exactly the most pleasant solution, but you could write a trait `MyFloor` and implement it for both floats and ints. Have your float impl call the usual `floor`, and have your int impl return the value unchanged. I am assuming you're using generics / static dispatch, though. If you're using trait objects / dynamic dispatch, I'm not sure what a solution would be.
I've been spending some time implementing the [Cryptopals challenges](https://cryptopals.com/) in Rust. I've just finished Challenge #12, and I feel like I have superpowers. I'm taking every opportunity to throw Rayon at my code to make things magically faster -- I can't believe how _easy_ Rayon is. I've also been doing some network packet-esque bit packing, which is not the most pleasant task in any language. Rust makes it easy to `#[test]` everything as I go, though.
I’m using generics with trait bounds. Would I need to implement it for all types under the sun? Or could I impl on top of existing Float and Integer traits (that exist in num-traits crate)? Im hoping to auto-include 3rd party numeric types (like bigints) that are also implementing num-trait traits. 
You could probably do blanket impls for Float, Real, and PrimInt from the `num_traits` crate. You'd still need that bound on your function, since not every custom Num may also impl one of those three traits, but this might cover most of what you care about. If there are any weird types out there that are Num but not Float, Real, or PrimInt, if one needs to get used with your function, the caller can implement a no-op `MyFloor` for it.
I made a program that can analyse file names (let's say podcasts) and decide which podcast, season, and episode it is, then suggest a new name based on a pattern, for example citation-needed/s01/citation-needed.s01e02.mp3 I turned it into a microservice, so other scripts of mine responsible for collecting files, can use it.
When I wrote an SPI/SD/FAT stack in C years ago, I referenced [the SD specifications](https://www.sdcard.org/downloads/pls/index.html). (I think it was Part 1 -- the Physical Layer spec -- that's relevant here.) Specifications are never particularly friendly, but they're usually the most precise source you can find.
I have both B1 and C2, so I can test both if needed.
Keep working on my programming language https://github.com/playXE/Jazz
rust code is very noisy to look at - part of that is unavoidable (additional annotations to achieve safety) ; I would argue being too explicit everywhere (on top of that) is too much. I think the context will make the preference between move and borrow clear - maths functions want to borrow; amending containers and spawning threads would want to move. If you get it wrong, the compiler error messages are good. we already have auto borrow for receivers, and I've only ever found that helpful
I had some down time this weekend and made this little macro on top of the objective-c rust crate that eases some pain points for me: [https://github.com/jgall/obj\_c\_rust\_test/blob/master/src/class.rs](https://github.com/jgall/obj_c_rust_test/blob/master/src/class.rs). &amp;#x200B; Specifically it lets you declare an objective-c class in Rust in one declaration (with instance variables). The next step will be for me to add in some syntax for adding methods to said class. 
There are lots of good answers below, including minor changes to the code and the suggestion to compile with "cargo build --release -- -C target-cpu=native" which, combined, should help a lot. I'll share 2 ideas that would improve your Rust code and you JS code equally. 1. When testing for primality by checking mods, only check up to the square root of the number being tested. If it has any nontrivial factors, that is factors besides itself and 1, then one of these factors must be less than or equal to the square root of the number in question. Meaning that if you don't find a nontrivial factor below or at the square root of the number, we can say it is prime with 100% confidence. 2. If you use a vector to capture the primes as you find them, you can get away with only testing for mod 0 against elements of that set. All numbers can be expressed as a product of prime factors, so if your candidate cannot be divided evenly by any primes up to its square root, it cannot be divided evenly at all. These ideas, which are still not the best way to find primes but are easy to explain and implement, will greatly improve your Rust and JS run times.
&gt;Tangentially Rust-related. It's mostly an overview of how I got embedded debugging bootstrapped with minimal equipment. Hopefully it's useful for others looking to break into embedded development with Rust. Thanks for sharing!
Good job
Thanks!
Looks like good
Replying to myself, though I am pressed for time just now, because I am not a huge fan of people saying "there are even better ways . . ." and not elaborating. So I wanted to say that for finding the lower primes, the Sieve of Eratosthenes may be faster on finding the first N primes for relatively small N. But for larger N, and more to the point, larger candidate primes, you can shave even more time off of your algorithm by subjecting the candidate to the Miller-Rabin primality test before moving to trial division. A true prime will always pass Miller-Rabin, and in general a composite will fail it 3/4 times per iteration. So for very large candidates, you can easily establish with 100% confidence that it is composite or 99.99999% confidence that it is prime. In the latter case, you might use trial divisions to achieve the full 100%, but in the "100% confidence it is composite" case, i.e. it failed even just one iteration of Miller-Rabin, then you may discount it as a possible prime and move on without any trial divisions. I may elaborate more later but the long weekend is over. It's time for me to go to work.
&gt; As far as "code quality/maintainability" though, personally I've seen some bizarre trait object constructions out there that would very likely be much more cleanly representable via simple linear inheritance. Perhaps; I am sure there are occasions where inheritance can result in simpler code but in general I don't find that this is the case. Oftentimes you just want an `enum` to represent the closed number of states; where `enum`s are currently lacking we can work on improving them to support [GADTs](https://en.wikibooks.org/wiki/Haskell/GADT). The use of trait objects make sense when you have an open number of states/types or you want to keep the situation open to extension. However, with inheritance, you are both open to extension as well as the type-case functionality, i.e. `instanceof`, which is an easy way to violate parametricity in surprising ways and Liskov's substitution principle. &gt; What in particular is it about inheritance that you think by its very nature/presence reduces quality/maintainability? Traditional inheritance as done in Java combines and conflates data and behavioral ruse. It is more flexible to break these down into parts by having data composition through simply adding fields to structs, and specifying behavior through traits / type classes that allow for ad-hoc extension after a type has been defined. Behavior reuse can then be achieved with provided methods / defaults. Where there is boilerplate, a more flexible approach to eliminate it is delegation. Here are nice articles: - https://www.parsonsmatt.org/2017/02/17/ooph_data_inheritance.html - https://doc.rust-lang.org/book/second-edition/ch17-01-what-is-oo.html &gt; Or, more specifically, why (in contrast with basic inheritance, or any inheritance) is something as abstract, unprecedented in other languages, and arguably less useful as adding member fields to traits "just another day at the office" as far as features go? I have not been convinced yet of the utility of fields in traits so you'll have to ask someone else (e.g. Niko Matsakis) about that. I believe the main reason why it is desired is to solve some issues with intraprocedural analysis wrt. borrow checking. There may be other solutions such as having regions of data in `struct`s instead worth investigating. &gt; And how is it not "OOP", by whatever definition of that we're using? I think the main difference is the subtyping. Personally, "OOP" strikes me as a meaningless term since no one can agree what it really means. Here are some candidate interpretations: 1. Method call syntax (`x.f(y)` and properties `x.prop`); OK -- then Rust is OOP, but this is a fairly shallow syntactic idea what OOP constitutes that's not worth considering as a programming paradigm. With type classes and custom operators you can even get this in Haskell. 2. Encapsulation with privacy (`pub`, `private`, ...); OK, this is a nice and thing that many languages have, including Haskell; Given that many functional languages also have such facilities it doesn't seem to me that this is unique to the OOP "paradigm". 3. Dynamic dispatch; Also a nice thing to have, and both Haskell (via `-XExistentialQuantification` / GADTs) and Rust (via `dyn Trait`) has it in a clean way as far as the type system is concerned. 4. Inheritance and subtype polymorphism; These are the bits that are arguably unique to OOP and I think these are problematic from the perspective of a type system and for code quality.
&gt; CLI for RLS You really need a CLI for LSP - then you could use any backend. However, as far as i can tell, there isn't one, which i find rather surprising.
Rewriting my OBS plugin (to capture OpenGL windows on Linux) in Rust!
Doing some maintenance work on my jackaudio mixer/connection server [Over here](http://github.com/snowlabs/jamyx) Might start writing an equalizer if I can find an easy enough to use fast Fourier transform library...
3D looks are so pre 2010, now flat stuff are in. Joking, it is nice, maybe darken the background a bit so the glow is more effective
&gt; So LLVM is working on having something like BOLT features built-in? Yes, that was my understanding from the talk.
I love it! Any updates you make to it, you should post!
You may be right. I do have that feeling that it is faster overall but I don't have any figures to support it.
Wouldn't the rust compiler be smart enough not to create a range at all?
So you'd have struct members that you'd bind as trait fields somehow. If it was a monomorphized usage then it would be determined at compile time. But where it gets interesting is with dynamic dispatch. So like you have function pointers in the vtable now, you'd also have to have *just* offsets in the vtable *in addition* to the function pointers, and the ordering can be determined statically by the compiler. Then when you want to get a pointer to the trait member you take the pointer to the containing struct and add to it the offset in the vtable, and that's it. Unless I'm misunderstanding things there shouldn't be a reason why that wouldn't work.
Can't tell for sure, but neither seems unlikely to me.
Creator of the `gettext` crate here. `tr` looks great! I have pondered adding some macro / message extraction stuff to `gettext`, but I do not have any experience with things like procedural macros. I saw this mentioned in the README: &gt; Currently, the backend is using the `gettext-rs` crate, but this could be changed to something like `gettext` in the future Are there any features currently missing from `gettext` that would prevent this?
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rustjerk] [A Rust wallpaper I created, in case anyone needs to jerk off](https://www.reddit.com/r/rustjerk/comments/a0jrst/a_rust_wallpaper_i_created_in_case_anyone_needs/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
The second part of crafting interpreters by /u/munificent and the bit on VM in game programming patterns
I'm interested.
I'm reading that at the moment actually! But it stops just before control flow :(
Ah. I see it [here](https://github.com/dineshadepu/prestige/blob/master/src/physics/dem/equations.rs#L23). It looks nice. One small nitpick: It looks like you are calculating all interparticle forces twice. First you calculate the force of particle i acting on j, and subsequently you calculate the force og j acting on i. This means that you are doing the expensive work twice. One idea is to calculate all the relevant distances first and store them in an array. Subequently you can use the array to calculate the forces (I guess that this could work with rayon). Alternatively you can use [spatial decomposition]( http://cacs.usc.edu/education/cs596/03ParallelMD.pdf).
RON stands for Rusty Object Notation. It's a just a textual data format that has been a pleasure to use in [WebRender](http://kvark.github.io/webrender/debug/ron/2018/01/23/wr-capture-infra.html), Amethyst(https://github.com/amethyst/amethyst/blob/master/examples/pong_tutorial_05/resources/bindings_config.ron), [rust-analyser](https://github.com/rust-analyzer/rust-analyzer/blob/master/crates/ra_syntax/src/grammar.ron), and more! The package for Sublime Text 3 has been around for a while, but only now it is officially registered with package control, so installing it today is a breeze. There is also a [vim](https://github.com/ron-rs/ron.vim) plugin for more sophisticated users ;)
Yeah, I can try that. I had also posted this question in users rust, https://users.rust-lang.org/t/help-with-parallelizing-a-nested-loop/22568/9. I that post I did some performance checks. Do you think I can have any improvements in my code? Is there any other way if executing it in parallel?
&gt;assembly &gt;dynamically typed I understand why you're saying this but it doesn't really make sense to talk about types in a machine language. Macros in most assemblers are "stringly" typed (like C's macros), and you could *kinda* say assemblers are weakly typed since you can pull values out of registers in loose ways. But dynamic vs static doesn't really make a lot of sense.
Today I gave a Rust dojo at my company and I guess you could be interested in making the exercises yourself. Enjoy!
Very cool! How did people like the dojo, and the language? 
thank you for these useful feedback
https://github.com/ron-rs/ron - some more info on Ron (saved you a google :) )
&gt; The variants could have the full language name in the docs. I just sent your a PR for this. 
I don't know if there are other ways to execute in parallel. You could use mutexes, but I suspect that it is expensive to have a mutex for each particle (untested guess) In [get_neigbors](https://github.com/dineshadepu/prestige/blob/master/src/contact_search.rs#L147) you allocate a vector to store the neighbors or a particle. I don't know much about the allocator, but if you allocate a new vector for every particle for every time step then it might be expensive. (You can test for this by [profiling](https://github.com/rust-lang-nursery/rustc-guide/blob/master/src/profiling/with_perf.md) the code) BTW: You should have a look at the [lumol](https://github.com/lumol-org/lumol) project. As far as I understand they focus on small systems, so they haven't added neighborlists yet, but they have written a nice extensible MD-engine with a beautiful design. Perhaps it can serve as an inspiration. BTW: What are your goals? Is this part of a molecular dynamics course or a thesis? Is yout code a proof of concept or are you planning to use it for a long time. Will it be judged by a physicist or a computer scientist? 
Thank you for writing this :)
It was great! It's not like we are going to use it anytime soon, but people were enthusiastic. I think we managed to explain the strenghts and limitations of the language, so I hope we might end up using it if there is a project where it would be benefitial.
I started to use the `gettext-rs` crate because it is simpler, as the original GNU gettext already takes care of finding the catalog from the environment variable, while, with the `gettext` crate does not. I guess eventually, the `gettext` crate is more flexible and should be used. So to answer your question, what is missing is a:`get_catalog_from_locale(domain: &amp;str) -&gt; Catalog` where domain is the name of the crate, which somehow magically find the .mo file to open using the `LANG` or `LANGUAGE` environment variable in some paths like `XDG_DATA_DIRS` (I don't know exactly). I'm not sure where this function belongs. (in the gettext crate or in the tr crate)
The WebRender team have quite a lot of expertise in this space: https://github.com/servo/webrender/graphs/contributors also GTK-rs https://github.com/gtk-rs/gtk/graphs/contributors and Azul https://github.com/maps4print/azul/graphs/contributors
Super nice work! How does one use the pretty printers outside of CLion?
Found my answer [here](https://github.com/ortem/intellij-rust/blob/master/debugger/src/main/kotlin/org/rust/debugger/runconfig/RsLocalDebugProcess.kt#L57).
Reminds me of the game "pod" 
Yes, you found the way! Also, we’re going to open a PR to rustc once both lldb and gdb printers are done.
I like that minimalistic approach, I will look into it on the weekend!
What happens with code like crypto, where timing sensitivity means you can't reorganize parts of the code? Does it need to be excluded as a separate lib and linked dynamically?
Thx for the snippets! Do I need non rust dependencies to build gtk and 3rd party libs? How big would the resulting executable be?
I had a similar experience a year ago comparing JITable python compiled with pypy
Working on launching a side project (backend in rust) - finishing up google sheets integration and am moving on to SMS integration (via plivo). At work, I'm hunting down a bug with git hook before open sourcing it (the hook is written in rust).
Alright, the extension is called "Rainglow" themes by Dayle Rees; he used "Lichen Contrast (rainglow)" in the video.
Miller Rabin has a deterministic variant for the 2^64 integers (and further). [`primal`'s source is instructive.](https://github.com/huonw/primal/blob/master/primal-check/src/is_prime.rs#L81) Sieves are faster for linear tests, but if you just want to check if a small number of moderately-sized primes, that algorithm is a godsend.
I am writing it for thesis and future use. This design is straight away a copy from pysph. My professor wrote it. My plans are to make it parallel and run it on server so that there is not much a difference in speed from mine and pysph software. Right now I am close, but it is around 2x, faster than my software. It should be fast, that's it. Nothing much is expected. But it should produce results. 
&gt; As long as the arguments are directly passed to the tr! macro, this can be handled by the formatting code. I don't see how you would handle passing down a gender-tagged string in this macro. The transcript thing allows you to store a dict, which is great for substituting other strings from the program, but not for when the case itself isn't fully determined.
You guys rock
Looks great on my Ubuntu desktop and serves as a reminder to study Rust! Thanks.
More stuff on `ggez`, a lightweight 2D game framework. I got a decent bunch of simple unit tests hammered out, finally, and am feeling game to take on the Great Graphics Projection Bug again. I THINK it's basically fixed for drawing basic sprites and meshes, but other drawing-related subsystems (sprite-batches, text and canvases) still need to be worked out. Also, apparently the `gfx_glyph` crate has had some updates, and is now a thin layer over the `glyph-brush` crate which does all the layout stuff and caching through hooks. So it SHOULD now be pretty easy to make it tie into ggez's existing `gfx-rs` rendering setup so it uses the same projections and command buffers and such without any changes, instead of operating alongside it. That oughta be fun.
[removed]
Awsome. Thanks!
What I'm trying to say is that it doesn't really make sense to talk about types in that way in assembly. It's like talking about static vs dynamic types in CSS.
Assembly lacks compile time checks, therefore it is compiled, but not statically typed. Static typing was invented later.
I am writing a function that takes in two `DoubleEndedIterator`:s as arguments and I would like to skip over common elements at the start and end of both iterators. Something like this (in pseudo-code): let (a, b) = (a.peekable(), b.peekable()); a.by_ref().zip(b.by_ref()).take_while(|_| a.peek() == b.peek()).last(); a.by_ref().rev().zip(b.by_ref().rev()).take_while(|_| a.rev().peek() == b.rev().peek()).last(); // Do stuff with a and b Have to peek to not also skip over the first non-common element. Currently, I am thinking that I'll have to write a custom `PeekableDoubleEndedIterator` since `_.peekable()` isn't double-ended. Would be thankful if someone could point me in the right direction.
This community is glorious!
Oh, I didn't know... Would just have it in tmLanguage from the start. Thanks for the tip!
Fira Code &lt;3!
Thanks Florian, Thanks to the whole team and rust community for all you are doing. I'll think of pinging community@rust-lang.org next time ! Much appreciated. 
This is going to be so useful! Thank you. 
Assembly doesn't have checks at all, that's the point. You don't "get errors", your program just crashes. Assembly isn't compiled, *assembled*, it's a (roughly) 1:1 mapping with the underlying hardware. There exists things that the hardware can do that can't be easily represented by a higher level language. Like try to invoke `int 80h` in C without using inline assembly.
Sounds like a pretty good idea, but similar to you, I have no clue as to how feasible and complete such a tool would be. Also, you should probably include `std::process` in the list of things to check for.
It's not 1:1 because it has macros, which is what we're talking about in the first place
The solution suggested by jkleo works like a charm, this way I can focus on the functionality and an icon on the drop surface later: &amp;#x200B; `use std::path::PathBuf;` `fn main() {` `let mut events_loop = winit::EventsLoop::new();` `let _window = winit::Window::new(&amp;events_loop).unwrap();` `events_loop.run_forever(|event| match event {` `winit::Event::WindowEvent {` `event: winit::WindowEvent::CloseRequested,` `..` `} =&gt; winit::ControlFlow::Break,` `winit::Event::WindowEvent {` `event: winit::WindowEvent::DroppedFile(path),` `..` `} =&gt; {` `/// compress(path);` `winit::ControlFlow::Continue` `}` `_ =&gt; winit::ControlFlow::Continue,` `});` `}`
&gt; I must say I was not expecting so much negativity over the gettext approach. That's a general consensus of the intl/l10n community as far as I can see. The source-string-as-key model, as I said, is considered a mistake and has been disqualified by Unicode when designing Message Format, and by Mozilla when designing Fluent. I do not know of any modern localization system which would repeat it. Saying that, I maintain my position that it's an opinion, no matter how informed, and if you like it, you should continue using it. I'm just saying that I don't believe it results in good code architecture and brings more problems which you don't seem to consider to be important (fuzzy state, declarative DOM localization - see https://firefox-source-docs.mozilla.org/intl/l10n/l10n/fluent_tutorial.html#markup-localization for an example). That allows, in turn, features such as live language switching etc. So, to sum it up. I understand what you like about it. My experience and others in the industry indicate that as you scale your project you hit fundamental limitations of this approach. You may not hit them, you may not scale that far, or you may not care about them. Your mileage may vary :) But for projects which try to design a generic, modern localization library such as MessageFormat and Fluent, we believe that key-based approach is the only good choice.
Here's an example of the new lifetime elision for `impl`, from libcore: https://github.com/rust-lang/rust/pull/54687/files
My project here is to learn Rust. I have very strong opinions as to the direction software should go in. Particularly in areas such as KISS (keep it simple stupid) and 'small is beautiful' code size. I saw an interview with Obviously if the tools lack, changing IDE will not fix the problem, but I thought it was reasonably mature now. &amp;#x200B; My project here is to learn Rust. I have very strong opinions as to the direction software should go in. Particularly in areas such as KISS (keep it simple stupid) , 'small is beautiful', 'applications in containers', and 'Not wanting to engage in cyber wars is no excuse not to brick up gaping holes in walls right besides locked doors, however good or bad the lock'. Also Safe, uncrashable coding principles. If I won a fortune, I would try to donate to the world an operating system, emphasis on system not code. I would try to make it easy, and reliable to use at a lower level, yet flexible to adapt for those that want to go more deeply. I would then spend money persuading governments and educational institutions to use it. I saw an interview with Jeremy Stoller, (RedoxOS), and may of his views seemed similar to mine, especially about kernels. That interview persuaded me rust is the way to go. I believe it should be well worth the time investment. Perhaps one day I might even try to join in shaping the way all this evolves.
But wouldn't that require an external function? That's why I included \`extern\` in the list of things to check.
No, just unsafe. Unsafe rust can do anything C can do. 
Java is pretty much the only language that I know that has/had something like that implemented, fine-grained permission system, and it failed pretty spectacularly. And that's with a language with a dedicated VM runtime and which at least had the feature somewhat designed in, whereas Rust really doesn't have very much to support such analysis. I feel such system can only bring false sense of security; I imagine that potential attackers would readily circumvent it.
&gt; I suppose if some test cases or benches were supplied with the source being compiled FWIW, the CPython build system has a flag `--enable-optimizations` which builds the interpreter (which is a C codebase) with PGO enabled, then runs the entire test suite to collect profile data and recompiles using it. This is probably less-than-ideal, but any substantial codebase should have tests, and any codebase that cares about performance should have bench tests.
That means that the `Floorable` trait is not "object-safe" -- which it isn't, since it exposes the underlying type for which the trait is being implemented. This means you can't take a `Box&lt;Floorable&gt;`, since if you could, you could call `floor` on it, which would return a type which you have no way of knowing. AFAIK, object safety matters when you're doing dynamic dispatch (using trait objects). Static dispatch (with trait bounds and parametric polymorphism) shouldn't be affected by this, since the parametrized function knows about the concrete type at compile time.
Yay the language server is no longer preview!!!!
I see that anchored paths vs uniform paths are still being tested. I think they both offer pluses and minuses. I'm just happy that it's going through a lot of thought and testing before a decision is made. Either one will be great. Here's the past discussion about it. https://www.reddit.com/r/rust/comments/9toa5j/anchored_and_uniform_paths/
In order of your paragraphs: I have caused a confusion, and I apologize. When I wrote `:make` (note the leading colon), I have never meant GNU make or any of its more modern reincarnations. Heavens forbid, it a royal PITA to use, I concur. I meant Vim's command of the same name, which is not limited to running GNU make, even if it is the default. Configuring it to use `cargo`, Rust's package manager and build system, is relatively easy. Are we talking about the same `gdb`? The package I installed it with is 10MB big. Maybe more if I include dependencies. Can't really argue here. As I said, it's extremely unlikely that Vim will ever provide this. It's kind of not the point. Actually, being able to plug any toolchain into it is one of Vim's great strengths. I have successfully used it with C, Python, Haskell and now Rust. A cheeky remark: that's precisely what Emacs does. Except maybe for Stallman himself.
Thank you so much for doing this! As an aside: the futures and networking working group can always use more help -- if you'd be interested in getting directly involved, please ping me on [discord](https://discord.gg/rust-lang) on the #wg-net-async channel!
&gt; . You should use impl&lt;T: Float&gt; Floorable for T, not impl Floorable for Float. You don't want to implement this directly on Float, you want to implement this for every type that also implements Float. Aha! This just gave me an AHA moment. I'm suddenly understating traits just a little bit more than I did before. I suspect what's going on is that the compiler doesn't know how to handle a theoretical type that might be both `Float` and `PrimInt`. I think I may need to wait for trait specialization: https://github.com/rust-lang/rfcs/pull/1210 to land. 
Sure! I'd definitely suggest working with `&amp;[u8]` instead of `&amp;str` (and use `&amp;str` instead of `String`, anyway, since lots of things can be sliced as `&amp;str`, not just `String`). When we're working with plaintexts and ciphertexts, we don't really care that the data is in the UTF-8 encoding. As far as we're concerned, we could be encrypting a program binary. This also happens to be more flexible, because (as you noticed!) you can always call `.as_bytes()` on a `&amp;str` to get a `&amp;[u8]`. There's also a _super helpful_ method implemented on `u8`: [`count_ones`](https://doc.rust-lang.org/std/primitive.u8.html#method.count_ones). If you use this, you can cut your `.map()` call down to essentially one line. I also have a personal preference to use the desugared form `Iterator::zip(a.iter(), b.iter())` when it comes to `zip` specifically. I feel like using the method form suggests a preference for the left sequence over the right sequence. It's not _wrong_, but reinforcing the idea that these two iterators are being mutually zipped together isn't a bad thing to do either. Here's what I ended up implementing. It's pretty close, when you take advantage of `count_ones`! ``` fn hamming_distance(xs: &amp;[u8], ys: &amp;[u8]) -&gt; usize { Iterator::zip(xs.iter(), ys.iter()) .map(|(x, y)| (x ^ y).count_ones() as usize) .sum() } ```
Yep, that's pretty much where I'm sitting too. What a shame. :(
I'm getting "error: Found argument '-C' which wasn't expected, or isn't valid in this context" when I supply those build args
I believe it would be the same as with fluent, just with a different syntax. How do you do it there? I guess something like this will work: println!("{}", tr!("Thanks, {username} !", username = user.name, gender = user.gender)); Then the translation could be a script like `|/|$[if (Ts.vals("gender") == "male") {return "Obrigado"} else { return "Obrigada" }], {username} !` Or, if using MessageFormat for the format: `{gender, select, male {Obrigado}, female, {Obrigada}}, {username} !`
Oh wow, beautiful! Thank you so much for your input!
Thank you *so much* for your help. Even though it's not ideal, this was super useful to get a handle on. I decided to use trait specialization, even though that means I'm tied to nightly for now. Solution is here: https://github.com/phayes/tallyman/blob/master/src/traits.rs 
This dojo clearly illustrates how one of the most basic programming operations (string handling and management) throws people in the Rust deep end right away (#actually, to be fair, it's the intersection of the Rust ownership/reference/slice hierarchy + lifetimes + Unicode that makes stuff incredibly ugly). &amp;#x200B; AFAIK, the distinction between `String` and `&amp;str` is not one of mutability, but that `&amp;str` is a `String` slice (or a slice into the backing memory holding the bytes of the `String`) - in fact, you can have an immutable `String` and an `&amp;mut str` (but you can't do much useful with the latter). The fact that you get lifetimes in the weirdest possible way with static strings helps not at all. &amp;#x200B; I think it would be more illustrative (both in terms of helping people understand what's going on, and helping people see the connection to other types of slices) to talk about `String` as the basic type, and `&amp;str` as a window into (possibly a subset of) the string, and `&amp;'static str` as a read-only window to a string that's effectively allocated and owned at compile time and stored in the binary.
Worse, even linting for unsafe isn't enough. Any unsoundness bug in the compiler could similarly be exploited to execute arbitrary code... 
&gt; Update: Apparently this isn’t quite true yet, and we are waiting on a rustup update here still 
&gt;Can a "gettext" program work without any translation file available? Yes, if there is no translation available, the original string is displayed. It would also be possible to have an english translation, and use `tr!("some-translation-path", nb_messages)` if one really likes key/value.
Is there a lint to point out where the code can be cleaned up like this?
I know, just happy that the RLS is moving into the big leagues :)
Has this been fixed yet: https://gfycat.com/SmallCarefulDiamondbackrattlesnake
 extern crate libc; fn kaboom() { unsafe { let fd = libc::fopen("/etc/passwd"); ftruncate(fd, 0); } }
How is the performance for rustfmt these days? I tried auto-running it on save in sublime and found it too slow.
&gt; I feel like using the method form suggests a preference for the left sequence over the right sequence. I prefer the method form for that exact reason, due to the "short-circuit" from the first iterator if `None`, described in [docs](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.zip).
Did you make sure and put the double hyphen to the right of the word "release"? That's the one possible cause that comes to mind at the moment. Without it, it will complain.
super interesting blog post!
I'm incredibly excited to be able to debug an individual test. This has been the biggest issue souring my experience. Thanks for the good work!
Yes I did that, but it doesn't seem to marshal it down to rustc. I'm on version 1.30.0
I have been working on the fastest division algorithm I could find for 128 bit integers [here](https://crates.io/search?q=specialized-div-rem). I think it is finished (besides a few tweaks involving integers with their MSBs close together). Should I open an issue to replace the current algorithm with this one (for CPUs with 64 bit hardware division)? I also generalized my algorithm to work with smaller divisions, and does someone with a 32 bit CPU mind benching the \`u64\_div\_rem\` function?
ah, that works i guess
ugh, doesn't that enforce order between variants? How would you make an equivalent of: ``` key = { $gender -&gt; [male] Obrigado { $name }! *[other] { $name } Obriagada! } ``` 
In fact, it will short-circuit as soon as _either_ iterator hits None.
So, is async/await not in scope for Rust 2018 anymore?
Hi there, this subreddit is about Rust (the programming language). The Rust (game) subreddit is over at =&gt; /r/playrust.
That doesn't make sense, function pointers are global to the type. What we are talking about is member fields that come with every instance of the struct. Imagine this case, you have a type in a library A, now you have another library B which creates + implements a trait for a struct in library A. Library A performance goes down the drain because everything has to be dynamic dispatch or Library B can overwrite the compile size of the struct (which would mean size of structs would be unsafe to use), neither things you would want. And this all comes back to: traits that adds member fields changes the memory layout, which should never be changeable any other place than the source. 
What is the magic incantation that you need to make gtk-rs compile and link correctly on Windows 10? Every test program that uses gtk-rs that I've tried has failed on linking. After following all the advice that I found through searching, nothing has worked.
&gt; Not really. Actual abstract classes in whatever language are just that: abstract. They're just collections of methods, largely identical to the concept of interfaces. No abstract classes are unique in that they allow inheritance of data. &gt; I'm struggling to think of what language you might even be referring to here. The standard mainstream ones, java/C#/Go 
The backcompat-breaking changes (keywords) go in at the start of [2018], but the actual implementation will follow during the life of the edition.
I think there's definite value in what you're talking about here. Obviously this is "survey" type data, not hard core "audit" type data, but the survey can tell you where you \*don't\* need to look for (if it detects network port usage in a crate, you don't need to audit it for network usage). I know the company I work for audits some of its products for network port usage and things like that. A note on word choice - "rights" makes it sound like you're talking about copyright license permissions, not system resource privileges/access.
Cool! By the way, is anyone going to write a robust audio resampling library? It would be nice to have one but I have no time to write one. And it would be especially nice to have x2 upsampling and downsampling (probably using a polyphase filter) for cases where you use upsampling to counteract aliasing.
I've just published the final article on creation a web auth server with actix here https://hgill.io/posts/auth-microservice-rust-actix-web-diesel-complete-tutorial-part-3/
I'm sorry, I blew it. Typing previous replies from my phone and got it wrong. If you replace "build" with "run" it will compile and run. I don't know why it won't work the same with just a build.
where does parse_string() come from? What is it exact type signature? It seems like parse_string borrows the string, then returns a type containing that borrow, so parse_string(&amp;'a) -&gt; &amp;'a since your string only lives until the end of the constructor, the xml will be invalidated as it ends, but you're trying to return it within the struct. You need to ensure that when returned, the string still exists. You could try adding a field containing the xml_str to the return struct. It's an ugly hack but still works. You could possibly get something working using `Rc&lt;T&gt;` I think.
Yes, GTK is a library you'd link to. So it wouldn't be statically linked. You could compile my gattii program to see how big it is
\&gt; where does parse\_string() come from? What is it exact type signature? Hes comes from here [https://github.com/vietanhto/dummy\_xml/blob/master/src/parser.rs#L112](https://github.com/vietanhto/dummy_xml/blob/master/src/parser.rs#L112) 
Ok! These are great goals. Just expect things to be imperfect and learn to appreciate the why and hows. Programming is ultimately a human activity and we're a fickle bunch. Happy rusting.
&gt;You could possibly get something working using Rc&lt;T&gt; I think. Interesting, you have a one example? &amp;#x200B; I made this commit with current source that i am trying build: [https://github.com/fernandobatels/blitz-money/commit/3f813aca382ba68b12619b9edcc9c832bba837cb](https://github.com/fernandobatels/blitz-money/commit/3f813aca382ba68b12619b9edcc9c832bba837cb)
Oh my bad. I seem to have misunderstood what the RFC meant. I thought it was for demanding that a trait require a struct to have members of a particular type and provide a way to access them.
Great. I have in todo to write a set of microtonal synths, and it may a good idea to implement `Module` for them. Right now though I have only [xephys](https://github.com/suhr/xephys) and it lacks a proper exciter (luckily I know how to implement one). I also tried to write a sampler that changes the pitch without affecting the time, but it did not work well. 
just converted one of my crates for the first time. is it correct that `extern crate` is allowed, just not required?
Wouldn't a recursive analysis reveal that this depends on an `extern "c"` function call? Which (I assume) it does?
Some are declared as `extern` directly, some are through macros. But even then you can go lower and use direct syscalls which do not need to be declared as `extern` on some platforms ( *nixes generally have stable syscalls interface, while Windows do not). And even in such case you can just have array of bytes, unsafely cast it into a function and run that (that is how JIT works). So no matter what you came with there is no guarantee unless you run application in isolated environment. And even then it would be as safe as your isolation tools. 
I used to use IntelliJ for web dev(around 2014-2015), have been using Atom for most things now, and considering VSCode, but the IntelliJ rust support really makes me want to give it a look for doing Rust dev. Has anyone compared experiences across these? I guess VSCode and Atom are fairly similar, but IntelliJ seems to have quite a few unique perks or alternatives to what you'd find elsewhere? Is there anything it's not as good at? I'm using Linux these days, iirc IntelliJ products have the GUI built with Java? How well does that fit in with DEs? I think only GTK and Qt tend to look native? I have heard with KDE Global menu, other toolkits like Java don't work?
I just ran it on a small crate and it was pretty much instant, actually first time running it and wow I need to be able to customize it because it does some serious damage to some of my code style. also `where` is supposed to be flush with `fn`??
Thanks for sharing. Both of those talks were very high quality. Did you write your own treiber stack implementation? 
If you had a separate lint for `unsafe`, would that cover it?
It would give you a hint that something can be wrong here, however I believe that determined party would still find a way to inject dangerous code into project. For example via `build.rs` or other dynamic code. Macros would be the main way of injection there. 
It might not technically be creating a range struct, but it still has to obey the behavior of the code you wrote, which in this case says that the end point of the loop doesn't change. If you change your code then the behavior can change.
It shouldn't. I'm not using it inside the function itself that i'm benchmarking, i'm only printing its return value to verify correctness. If I did have a println inside the loops then yeah that probably would hurt performance.
Yes, it's queue.rs in the synthesizer-io-core subdir. I'll be breaking stuff out into separate crates as I figure out proper module boundaries.
I use CLion on Linux. It looks good (albeit very dense). I use Linux pretty exclusively, except for games. 
I've been working with old futures on a personal project, and the more I get into it, the more I wonder what the real use cases of async/await are. I have not ever wanted to stop and wait for a single value. I have wanted to check a future/stream if it has an item ready and skip over it if not to check other futures/streams, but never wait for it to have an item. What is all the hype for?
Man I got looking at the thing, and I see that it is not working as intended. It will return 27 as a prime for example. All the wall o text below is about the brokenness of the algorithm. I could not find the reason Rust is so much slower at this. I will look more for that, but in the meantime I will post the below rant. &amp;#x200B; The algorithm is broken to start with. I don't know if this is a part of what's going on, but I made some counters and a println!, and I can see that the whole thing is traversing the inner loop 1,101,463,179 times to get the 20,000 primes. I use "first 20,000 primes" here loosely because I am not completely sure that is really what the program is finding. What the counters show is something like this: I get inside the inner loop with a given curr, say 4 (because the inner loop only lets me in when curr is 4 or higher). Keep in mind the loop is defined to work from 2..(curr-1) exclusive. So when curr is 4, this thing will "loop" from 2..3 exclusive, or 1 time. Put another way, it will pass through the loop once this time. And generally, it will pass through exactly (curr-3) times. So anyway inside the loop with curr=4, it checks for 4%2==0 and gets a true. This causes it to increment curr to 5, after which it hits the continue instruction. That continue does nothing, being at the end of the loop anyway, and if you comment it out your program will not do anything different. Anyway, now curr is 5, and you have reached the end of your 1 inner loop. Having completed that, the program sets prime=curr=5, increments the prime count and sets curr to 6, and you begin again. Now when 6 enters the inner loop, the 2..(curr-1) calculation is done, and you will loop 3 times inside the inner loop this time. 6%2==0 is true, so you enter the conditional. There curr becomes 7 and denom becomes 3. But when we bounce to the beginning of the inner loop, (curr-1) will not be evaluated again using this new curr. Nor will denom be set back to 2. We have 2 loops left to test 7, using denoms of 3 and 4. 7 "wins" and we exit the inner loop to make prime now equal to 7. Probably by now you see a pattern. So far we have gotten the right result for the wrong reasons. And every time we find a prime, the system is set right again temporarily. Now we do 8. 8 will get 5 loops in the inner loop. 8 "loses" on the first loop to a denom of 2. 4 loops remain, so we will test 9 with denoms of 3, 4, 5, and 6. Except the next curr, 9, loses to the denom of 3, and curr becomes 10. 10 defeats the 4 but loses to 5 and we just escaped having a composite come out as a false prime. Now 11 is curr with 1 inner loop left of those that originated when curr was 7. 11 tests against a denom of 6 and wins (primes always win the test) and comes out as prime. As before, our finding a prime resets the system. Now we have a curr of 12, meaning we get 9 inner loops. I'll spoil the story, 12 is defeated by the first denom, 2, and then 13 defeats all the rest being prime. Now 14 is up and gets 11 loops with denoms of 2 through 12 inclusive. 14%2==0, then 15%3==0, then 16%4==0, and then the true prime 17 cleans up. 18 introduces another 15 loops, denoms of 2 through 15 inclusive. 2 defeats 18, and 19 being prime comes out on top. By now you are probably sick of the repetition, so I will jump to the first spoiler. This program passes 27 as prime. Let's see how. After 23 was correctly ID'd as prime, 24 got into the loop with 21 iterations in store: denoms from 2 - 22 inclusive. Well 24 is defeated by 2. Then 25 is defeated by 5. 26 is defeated by 13. (Note 26 should have been defeated by 2, but we are working our way through 24's loops still, and after 2 we have to get all the way to 13 to defeat 26). Now 27 will face the remaining denoms, 14 - 22 inclusive and defeat them all, thus being declared prime falsely; 27 never faced 3 which would have defeated it. I'm sure I've talked about this issue more than enough now. I am not sure if g++ handles the loop differently, but it must be optimizing some of it away.
I still care tho, there are things like ugly forced line breaks that can be removed by creating intermediary variables.
It's still using Java rather than GTK or Qt for the GUI though right? So DE integration is less solid?
Note that we can use `pub(self)` instead of `priv` if we don't want the new keyword. That also suggests an edition migration path if we wanted to change default trait visibility -- migrate to requiring an anotation, then allow no anotation again as private. However, I agree that equally visible members is the default desired state of trait members. I think the best path forward would be to add sealed traits (cannot be implemented outside the current crate), and then allow those traits to have non-fully-public members. Whether that's via still being pub-by-default or making a sealed trait default to private, I don't know.
Wouldn't the analysis be at the codegen level (ie, the same level that rustdoc operates at) and therefore be able to understand macro code?
I can't see how to do it deterministically, due to some potential injections via unsafe transmutes, but you could do it as an opt-in thing. Packages could declare themselves to be analysis safe (which would prevent them from using or depending on (non-std) unsafe code), and then you could do the analysis as described. There's only so far you can get with opt in systems, but the same can be said of semver stability. Having more 1.0.0+ crates is a sign of ecosystem health and stability, and having more crates be opted-in to usage analysis would be the same.
The below will find the 20,000th prime on my computer in about 14/1000 second. It incorporates the 2 bullet points I gave above and eliminates a bug in the original program. The continue statement was not doing what the OP appears to have thought it was. Now a comparison of this with g++ would be interesting. I will not be surprised if g++ still wins the race, but the below lacks much inefficiency that one compiler might optimize away and the other not. fn main() { println!("{}", find_prime_iterative(20000)); } fn find_prime_iterative(initial: usize) -&gt; u32 { let mut primes_found: Vec&lt;u32&gt; = vec!(); primes_found.push(2); let mut prime_found; let mut curr = 3; while primes_found.len() &lt; initial { prime_found = true; let mut index = 0; while primes_found[index] &lt; f64::from(curr).sqrt() as u32 + 1 { if curr % primes_found[index] == 0 { prime_found = false; break; } index += 1; } if prime_found == true { primes_found.push(curr); } curr = curr + 1; } return primes_found[initial-1]; } &amp;#x200B;
I'm not really sure, but I'm guessing maybe you're misunderstanding what the async/await syntax does. With regular futures, you have to write callback functions to handle results when they become available. With async/await, you get to write "synchronous-looking" code, which *looks* like it's just waiting on a value, but is actually transformed under the hood to the same callback-style that you had to write previously. In the end, it's syntax sugar, but it's one that can make a huge difference in the readability and size of complex asynchronous code.
You can also use inline asm to invoke a syscall manually. And there's probably lots of creative ways to create function pointers to libc without directly referencing it.
All of this is already possible, though, even if slightly less ergonomic. You can simply inherit from a public trait that is in a private module, and if you want the trait method to be implementation-only, make the function accept a struct that you otherwise can not create (except with unsafe transmutes). Here's some examples: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=8655749fa71078bf609f8e71cc8ef7aa
Another area where trait visibility is a big help is implementing stdlib traits like `From` for errors. This can push implementation details into your public API. Not sure of a good workaround for that besides "don't do it".
How so? I'm not sure if I can picture the use case, and how `From` would benefit from it.
+1 to the confusing bit about different defaults. I found it quite surprising when I first encountered that you can't write `pub fn` in a trait.
If it’s any consolation, I found clion’s DE experience with Budgie (Solus) and plasma to be great. Didn’t feel as foreign as a lot of other software often does, and I can’t think of any pain points, though obviously that varies by user and DE blend. 
&gt; We want to export a_cool_function. That function accepts as second argument a type that must implement the Foo trait. In order for the function not to leak private symbols, Foo then must be public. However, we don’t want to expose its internals (the Cons associated type nor the compute method). Why we would want to hide those? I have several points: &gt;* If you look closely at the implementation, a_cool_function requires its second argument to implement Foo. Not exposing the internals would then force people to use stock implementors and will prevent them from providing new ones. This might be wanted for several reasons (unsafe traits, performances, etc.). If you want to restrict the use to a known set of implementations, you can change the `foo: T` argument with an `a: MyEnum` or `a: &amp;MyEnum` where all the variants impl T. &gt; * A more sensible reason: imagine that the associated type Cons required a bound on a very specific trait that is there only because of your implementation details / choices (like a trait from a dependency). That would leak that trait into the interface, which is not wanted. If the type has a bound only because of the implementation, then I don't think it should be a trait bound. &gt; As corollary, not exposing the internals of a trait would enable you to change the definition of the trait without inducing any breaking change, which is an interesting feature. Traits don't have internals, implementations do.
Ok but what does it actually mean? The last thing I've read was that RLS should become 1.0 even though it's not "ready". So how does the non-preview version actually differ from the preview version? The preview version had huge latency &amp; CPU usage on my ~24kLOC project whenever I tried, so I had to disable it again :/
On github at https://github.com/firecracker-microvm/firecracker
The backwards incompatible changes were decided. The rest of the language is going to have additions every 6 weeks until the end of time, so it shouldn't be surprising to see one more change being planned for the future.
In my particular case, IntelliJ is just too power-hungry and slow of an application to use - clicking some random button accidentally freezes the program for up to 12 seconds. VSCode, despite its foundation in Electron and mildly greedy power usage, is far less unwieldy in both regards, and its plugin’s support for Rust is good enough.
*lip smack* noice
I created a new version, slightly darker as several commenters suggested. Hope you like it! [https://imgur.com/qviNstB](https://imgur.com/qviNstB)
&gt; IntelliJ is just too power-hungry and slow of an application to use - clicking some random button accidentally freezes the program for up to 12 seconds Oh, is that still the case? I think I remember something like that when I used it for web dev. I can't quite recall why I switched away from it years ago. It does sound attractive though for Rust dev, at least from what I've read about it compared to current state of RLS? &gt; VSCode, despite its foundation in Electron and mildly greedy power usage, is far less unwieldy in both regards, and its plugin’s support for Rust is good enough. I've also been eying that up as an alternative from Atom, though I think feature wise they're quite similar in regards to rust dev? Are you using it on Windows or Linux? I remember trying to use VSCode for some python work a year or so ago and many of the extensions failed to install/work for some reason.
Still the case for me - I use IntelliJ for Java because few choices are better. I’m on macOS, and VSCode worked fine. I did have some problem with the extensions when I first installed it, but that was quite a while ago. Eventually, everything was fixed by just downloading the right programs or following some questions online - can’t quite remember the specifics.
This is similar to enums- it makes relatively little sense to have private variants or private trait methods; and variants/signatures aren't normal items either. So privacy just applies to the thing as a whole.
You may want to update your rust toolchain, check it: [https://rust-lang-nursery.github.io/rust-toolstate/](https://rust-lang-nursery.github.io/rust-toolstate/)
``` Firecracker was built by developers at Amazon Web Services to enable services such as [AWS Lambda](https://aws.amazon.com/lambda/) and [AWS Fargate](https://aws.amazon.com/fargate/) to improve resource utilization and customer experience, while providing the security and isolation required of public cloud infrastructure. ``` Wow, I was completely unaware until now how lambda actually worked. This is very cool.
This. is. so. cool. It was sort of single-handedly changed my opinion of AWS engineering very quickly, that this exists, was greenlit, had the technical background to use rust and crosvm... Color me impressed. And nosy, I'm curious if this is from the EKS team or a different team...
I'm blown away by the amount of high-quality programming, presentations, and blog posts you've been doing over the past months. You're truly an inspiration. Thank you.
Feels like we’re trending to a point where lifetimes may become unnecessary in most cases.
I hit an issue that kept pegging my CPU, it went away, then came back, and now seems to be ok again. Crossing my fingers that it stays stable, bc at this point I really appreciate and hate having to temporarily disable it.
Some suggestions taken into account - see [https://docs.rs/iso639-1/0.3.0/iso639\_1/](https://docs.rs/iso639-1/0.3.0/iso639_1/)
&gt; Was the original chrome os version also in Rust? Yes it was. Previous discussion [here](https://www.reddit.com/r/rust/comments/72ouil/an_unrelease_chrome_os_component_written_in_rust/).
Can anyone elaborate on this quote: &amp;#x200B; "This means that every function or container group can be encapsulated with a virtual machine barrier, enabling workloads from different customers to run on the same machine, without any tradeoffs to security or efficiency." &amp;#x200B; What is it about a regular container that yields some kind of sub-optimal security or efficiency situation? If anyone has more resources on this that'd be awesome.
From quick search, this seems to be a very good question without an easy to find good answer on the web. [Russell Coker (2010)](https://etbe.coker.com.au/2010/09/29/pre-forking-good/) (whom I read for years and generally trust) mentions ~2400 forks per second.
I agree that the algorithm is broken, but it's the number-crunching I find interesting here. So let's took a look at the disassembly: &amp;#x200B; gcc: (-O3) \`\`\` 10a5: 44 8b 44 24 04 mov 0x4(%rsp),%r8d 10aa: 45 85 c0 test %r8d,%r8d 10ad: 74 75 je 1124 &lt;main+0xa4&gt; 10af: 41 83 f8 01 cmp $0x1,%r8d 10b3: 76 6f jbe 1124 &lt;main+0xa4&gt; 10b5: bf 01 00 00 00 mov $0x1,%edi 10ba: be 02 00 00 00 mov $0x2,%esi 10bf: 90 nop 10c0: 83 fe 02 cmp $0x2,%esi 10c3: 74 6b je 1130 &lt;main+0xb0&gt; 10c5: b9 02 00 00 00 mov $0x2,%ecx 10ca: 66 0f 1f 44 00 00 nopw 0x0(%rax,%rax,1) 10d0: 89 f0 mov %esi,%eax 10d2: 31 d2 xor %edx,%edx 10d4: f7 f1 div %ecx 10d6: 85 d2 test %edx,%edx 10d8: 74 3e je 1118 &lt;main+0x98&gt; 10da: 83 c1 01 add $0x1,%ecx 10dd: 39 f1 cmp %esi,%ecx 10df: 72 ef jb 10d0 &lt;main+0x50&gt; 10e1: 89 f0 mov %esi,%eax 10e3: 83 c7 01 add $0x1,%edi 10e6: 8d 70 01 lea 0x1(%rax),%esi 10e9: 44 39 c7 cmp %r8d,%edi 10ec: 75 d2 jne 10c0 &lt;main+0x40&gt; \`\`\` is inlined into &lt;main&gt; in gcc. Note that I've specified the size of the loop counter via stdin, and print the calculated number, so either compilers can't do unrealistic constant propagation. &amp;#x200B; (cont.)
rustc: (cargo build --release, opt-level=3, overflow-checks=false, target-cpu='native') (it was too long to post here) [https://pastebin.com/81r67Xqx](https://pastebin.com/81r67Xqx) &amp;#x200B; Both are full of conditional jumps and tests, but the Rust code is (unfortunately), much longer and slower. I'll want to take a look into this with \`radare2\` to visualize where Rust goes wrong. I wonder how fast Rust's conventional programs stack up against C++ in terms of speed.
I came to post this to /r/rustjerk 
Rust makes it just too easy to do things in parallel.
And isn't is also the only way to await more than value if the order of when the results are returned is not known?
I'd typically encourage this rather than changing the configuration of the formatter itself. If you can fix your style concerns without changing the rules, then you're still being consistent with most other code out there. It's a little bit difficult at first (to this day I avoid Elixir's formatter, because I spent a couple of years writing before it existed), but I have to admit that reading Rust source is so much easier when it uses the formatter than when it doesn't.
Purely speculating on security , but I wonder if it's possible to spill data via CPU caches. If context switches were very frequent, you could expect that L2 or L3 would still contain data from a previous workload.
ctrl+shift+A -&gt; type "toggle hints"
Yeah I agree, I use the defaults and I will never change it. Being idiomatic has a definite value
Containers share the same kernel, it could lead to data leaks, privilege escalation, etc. Vms don't share the same kernel and are easier to isolate, as the surface are is smaller and better defined. 
Another solution might be to pass file\_contents to new() instead of file\_path - ie read the file prior to calling new(). That way you have ownership of file\_contents and can make sure it outlives your Ofx instance.
Yes it would work. The formatting layer is not yet set in stone, this was really a first iteration of the crate. The idea was to stay as close as possible to reduce the load on the developer. I am wondering how, in fluent, do you handle this case? (i'm just basing that on the example, not sure if it's correct) let mut bundle = FluentBundle::new(&amp;["x-testing"]); bundle .add_messages( " welcome-message = Welcome in { $country } country-usa = United States country-france = France country-portugal = Portugal ") checkbox.set_values(&amp;[ bundle.format("country-usa", None).unwrap(), bundle.format("country-france", None).unwrap(), bundle.format("country-portugal", None).unwrap(), ]); checkbox.on_changed(|country| { let mut args = HashMap::new(); args.insert("country", FluentValue::from(&amp;country)); label.setText(bundle.format("welcome-message", Some(&amp;args)).unwrap()); }); How would you translate the welcome-message in French? It has to be "Bienvenue aux États-Unis", "Bienvenue en France", "Bienvenue au Portugal"(the english 'in' is translated 'aux', 'en', 'au', depending on the country). This code is quite verbose, while the equivalent with the tr! macro would be: checkbox.set_values(&amp;[ tr!("United States"), tr!("France"), tr!("Portugal") ]); checkbox.on_changed(|country| label.setText(tr!("Welcome in {}", country))); I'd say this is quite simpler code. (but that's my subjective opinion. To your defense, I guess you could also make a macro that'd read `fluent!("welcome-message", country)`) And in the French translation, the translator just has to annotate the name of the country to register the right preposition in a hash table. (as it is done in [https://websvn.kde.org/trunk/l10n-kf5/fr/messages/kdeedu/kgeography.po?revision=1529117](https://websvn.kde.org/trunk/l10n-kf5/fr/messages/kdeedu/kgeography.po?revision=1529117) with `pose-genre-etendu`)
I have one nit with "When you write a function like `fn show&lt;T&gt;(x: T) where T: Display`, here `Display` is not a trait: it’s a *bound*." I would say that it is wrong, since using `Display` in that way doesn't mean you're not "using" the trait there or that it suddenly isn't a trait anymore. Instead you're placing a requirement on some generic type `T` such that `T` implements the `Display` trait. Following on from all of that, I believe that would make `T: Display` the bound, and not `Display`. So the sentence would be better and more accurately written as "When you write a function like `fn show&lt;T&gt;(x: T) where T: Display`, here `Display` is used as part of a *bound*."
So given that `Any` is only implemented for `'static` types, why does [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=0b21a5d241ef63bf5daf82c5544d0c6e) work? I'm glad that it does because its definitely useful, but I'm a little confused on why.
Yes, IDEA and CLion work great with macOS menu bar. As for Linux, there is \`Experimental features -&gt; linux.native.menu\` option for Unity and KDE (not sure about others) in the last 2018.3 release, but it is still experimental and might not work.
I’ve only skimmed through your post, but I think **existential types** (that hopefully come soon to Rust as a completion to impl Trait) might be exactly what you’re looking for. https://github.com/rust-lang/rfcs/blob/master/text/2071-impl-trait-existential-types.md
Where is this used?
Actually, in this case `x` has type `NonStaticType&lt;'static&gt;` because of rvalue promotion, and thus implements `Any`. You will see an error if you try to do let a = 3; let x = NonStaticType{ v: &amp;a }; downcast_test(&amp;x); `downcast_test` is a valid function because `Any` allows to downcast you to types with any lifetime, the restriction is only on making `Any` trait objects out of non-`'static` stuff.
I personally call `Display + 'a` a bound and `T: Display + 'a` a constraint (as that is the terminology in Haskell). Tho perhaps `Display + 'a` should be called something else entirely.
Sorry to double dip, but I just did challenge 6 in set 1. This is so satisfying to do! Again, thanks for linking this. It's great stuff.
Wasn't actually aware of that terminology in Haskell, although I am only a beginner with Haskell. I'm willing to admit that it seems like the terminology here is a bit fuzzy. &amp;#x200B; P.S. I can definitely tell you're a Haskeller just by your username :p
I'm working on [Funki Crab](www.github.com/zesterer/funkicrab), my optimising Brainfuck compiler written in Rust. Today I'm going to be adding multi-iteration loop analysis In an attempt to unfold more kinds of loops either into linearised procedures or conditionals.
Rust (and Haskell, Idris, ...) have the power to enforce quite strict notions of referential transparency which is enough to lock down almost anything problematic except for non-termination attacks which are ridiculously hard to achieve anyways; In Rust this would be achieved with `const fn`; it is currently not powerful enough to encode abstractions but you should expect that to be a temporary limitation. Unlike runtime mechanisms, this is statically verifiable analysis. Once we have expressive `const fn`, we should be able to encode strict [mandatory access control (MAC)](http://hackage.haskell.org/package/mac) regimes where we can reduce the trusted computing base significantly. &gt; I feel such system can only bring false sense of security; I imagine that potential attackers would readily circumvent it. I don't agree; One could similarly argue that "unsafe" brings a false sense of security but it is an important measure to rule out a dangerous class of bugs or that obfuscation is a bad idea because it can be reversed. With `const fn` we can rule out even more bugs and we could also rule out panics as well. Security and safety should be done **in depth** with a hail of bullets instead of thinking that a silver bullet will catch all.
Well, you're welcome to become one of us down the line... should ya feel the need etc :P
Using `extern crate test;` is the intended solution for now. Note that using `extern crate test;` in the root module will add `test` to the "extern prelude" so you can still use `test::Bencher` to refer to its contents from anywhere instead of `crate::test::Bencher`, just like you would if it was declared in `Cargo.toml` as well. There are ideas around being able to declare builtin crates as dependencies in `Cargo.toml`, but nothing fully designed/implemented yet.
Agreed, the dive into the actual numbers is interesting. I know that Rust can, when it's on its game, run with C and C++ because I wrote a SHA3 implementation that can hash a 1.8 GB file in about 8.25 seconds vs. 8.5 average for Linux's sha3sum for the same hash function. Even that was a bit of cheating because my implementation uses 2 threads where sha3sum uses 1. in an apples to apples comparison, the best I got was about 10 seconds from Rust. But still in the ballpark, unlike here. Here, the 2 compilers / linkers have gone separate directions to Rust's great disadvantage. It definitely seems like an opportunity for improvement in Rust, if the issue causing the run times difference can be solved. Unfortunately it is time for work again. I will have to return to this after. And then will see how much of the assembly I can understand. I have written simple programs in assembly, but that was a long time ago...
I must want to say that your username had me giggling for a good 5 minutes and I have no idea why.
&gt; Wasn't actually aware of that terminology in Haskell, although I am only a beginner with Haskell. Cool. :) That's an excellent choice and it should help you in Rust as well since they are closely related (and great) languages. &gt; I'm willing to admit that it seems like the terminology here is a bit fuzzy. Yeah I agree; I've also heard "predicate" used so that's a 3rd term. &gt; P.S. I can definitely tell you're a Haskeller just by your username :p Hehe; It's an oddly imperatively phrased username, "etareduce" can be interpreted as a command *to* etareduce. I'm otherwise known as [Centril](https://github.com/Centril/) when not on reddit.
The enum trick doesn’t work because of what /u/theindiegamer said. I had thought about that but it makes the overall thing harder to use, and has a runtime cost.
Enums are (in theory) dynamically dispatched. Traits are not (unless you use trait objects). So it does make a lot of sense to me. :)
Nice response, very well written. Have my upvote.
I've definitely wanted private trait methods before, and I also think it's conceptually a little odd that the traits work differently from structs in "propagating" their pubness to the contained items. I would like more discussion on this! 
If there was a vote going, I'd vote to never have this feature come anywhere close to Rust. Sorry, but the implementation and usability problems are just enormous, not to mention the runtime cost of looking up member fields in vtables all the time. If you want that sort of data-dynamism, use `Box&lt;dyn Trait&gt;` and/or composition.
That would basically make the trait private from the outer world (no doc on it, etc.), right?
&gt; If the type has a bound only because of the implementation, then I don't think it should be a trait bound. The type has a bound to be part of “all possible acceptable values”. The trait may – or may not – add any associated types and methods used privately in the crate.
Sounds like a good opinion. Are there macros that let you pretend that there is inheritance?
Interesting thoughts. The “cool” side-effect (and I’m a Haskeller, I hate those normally!) with fixing the privacy of traits would be that we wouldn’t need sealed traits anymore.
Explicit lifetimes are already unnecessary in the vast majority of cases; for anyone out there who started using Rust after 1.0, note that the original RFC for lifetime elision from 2014 eliminated 87% of the lifetime annotations in the standard library. If you want to get a taste of what using Rust was like in 2014, imagine writing seven times more lifetime annotations than you do today. :)
This version looks a *lot* better.
So, I’m not an author of this, but I’ve chatted with the team that worked on this project. The team that worked on is in the EC2 Foundational Technologies organization, which supports EC2, container, and Lambda at AWS. The containers organization _tends_ to focus more on the problem of operating many many many containers at scale (which is a very challenging problem!) rather than more low-level VVMs.
And doesn't prevent race conditions.
/r/playrust
Thx just realized that 
I would recommend attempting to redesign your architecture if it depends on inheritance. It's not a necessary paradigm for good software development and tends to complicate both the developer-visible architecture and the generated code (a lot of vtables and dynamic allocation are usually bad for cache coherency, and hence performance). Trait objects are a good compromise, however. If you combine them with type parameters, it's possible to produce code that behaves in a somewhat similar way to inheritance, without so many of the negatives. For example: ```rust struct Base { some_data: u32, } impl Base { fn some_method(&amp;self) -&gt; u32 { self.some_data } } struct Derived { base: Base, some_more_data: String, } impl Derived { fn some_method(&amp;self) -&gt; u32 { self.base.some_method() } } ``` There are probably macros that simplify the above code, however. I've just never used them. If you want polymorphism, trait objects are the way to go: ```rust trait MyFakeClass { fn some_method(&amp;self) -&gt; u32; } impl MyFakeClass for Base { fn some_method(&amp;self) -&gt; u32 { self.some_data } } impl MyFakeClass for Derived { fn some_method(&amp;self) -&gt; u32 { self.base.some_method() } } // You can now use these types in a polymorphic manner, like so: let my_vec: Vec&lt;Box&lt;dyn MyFakeClass&gt;&gt; = vec![ Box::new(Base::new()), Box::new(Derived::new()), ]; // my_vec now contains both Base and Derived trait objects. ``` Type parameters can help simplify generic OO-like code when you want to have a generic base type like the following: ```rust struct OtherDerived&lt;T: MyFakeClass&gt; { base: T, } impl&lt;T: MyFakeClass&gt; MyFakeClass for OverDerived&lt;T&gt; { fn some_method(&amp;self) -&gt; u32 { self.base.some_method() } } ``` As I said before: I recommend moving away from an object-oriented mindset if you want to write good, performant Rust code. Object-oriented design doesn't tend to square very well with Rust's data-oriented approach to programming and will probably end in you either hating the language or hating the compiler for refusing to play nicely with what is considered reasonable code in other languages that make abundant use of vtables and garbage collection.
I don't think using VMs protects against such side-channel attacks, unfortunately. But the attack surface of a hypervisor is still much reduced compared to a regular container which has full kernel syscalls.
nm I thought this proposal also included private impls. Below is my explanation anyways. Say my crate is using `globwalk`. I could have a `impl From&lt;globwalk::Error&gt; for MyError`. What if I decided I needed more control and wanted to switch to `walkdir`. I might then switch my impl to be `impl From&lt;walkdir::Error&gt; for MyError`. The problem is that `MyError` is in my public API and exposes the `From&lt;globwalk::Error&gt;`. By removing that `impl`, I have broken compatibility. If I can instead have `pub(crate) impl From&lt;globwalk::Error&gt; for MyError`, then I can take advantage of the `From` with `?` while not impacting my public API.
Yeah, I think so too... Too bad it's hidden here in a comment and is not immediately visible in the post :-(
I posted an updated version as a comment... Unfortunately it's not immediately visible when visiting this post :-(
Rust belt rust moves around the rust belt, so while it may not be in Michigan, it will probably be close, relatively speaking. It was in Ohio the year before and Pittsburgh the year before that. https://www.reddit.com/r/rust/comments/a0ujpc/oxidizeconf_a_conference_about_embedded_systems/ was also just announced...
&gt;OxidizeConf was also just announced... Good timing! Thank you! I'll probably do Rust Belt &amp; OxidizeConf this year. Thank you for your suggestions.
Agreed. I'd definitely use this and other sorts of "cross-crate lints" if someone were to cook up an analogue to Clippy for them. For example, there's a tool named [rustig](https://github.com/Technolution/rustig) which is on my "to try" list which inspects a binary to identify code paths leading to the panic handler, and it'd be really nice if that could be added to the paradigm I currently follow with Clippy, where I set very strict rules and then `allow()` lines which legitimately need exceptions to them.
tangential question: one approach I don't think I've seen done is to write the struct with it's alignment as it is in memory, instead of packed (i.e. with padding intact). The memory could then be directly cast to the target struct (yes?). Would this be the fastest possible way to read (faster than packed) at a cost of storage? I'm thinking lz4 could deal with space/io and then you have ready-to-go structs. Is transmute to a [u8; _] array the best way to "serialize" in this way in rust? (obviously this is for trusted inputs otherwise it'd be insane).
Demo on GitHub [https://github.com/korepkorep/russian-post](https://github.com/korepkorep/russian-post) 
Yeah, crate-public impls do seem like a feature that I'd want in the language, especially when implementing a foreign trait on a foreign type - although I'm not too sure if the latter is implementable easily enough.
Man you guys don't make it easy for the bot. And here I came thinking it was something relevant.
Running `cargo fmt` in the Servo repository (`find -name '*.rs'|wc -l` says 1005 files) takes ~2.5 seconds on my laptop.
What you're describing is essentially an [effect system](https://en.wikipedia.org/wiki/Effect_system). If you Google for "Rust effect system" you'll find some related prior discussions such as https://internals.rust-lang.org/t/start-of-an-effects-system-rfc-for-async-etc-is-there-any-interest-in-this/7215/29
 "Don't do it" is also called pythonism. We don't want to be like python... Trust me :P
If you find yourself with some free time I'd suggest contributing this to azul. I know the developer is very active so I'm sure he could help you out if needed.
&gt; Of course, I could define methods in a trait and then implement that trait for a struct and then mock that trait for my tests. But this feels like Java in the '00s so it kinda feels like I shouldn't be doing that. It doesn't necessarily have to be a trait as long as the function receives the "platform provider" as an argument in some way or other, rather than hard-coding it. That's what I did in one of my "should probably be a python script" projects. It gave me two added benefits: 1. I can use `&amp;self` vs. `&amp;mut self` to distinguish between functions without side-effects (eg. get volume label for drive) and functions with side-effects (eg. eject removable disk), ensuring that the normal unit tests for the platform provider layer will fail to compile if I accidentally try to call something with side-effects, because they're trying to feed in a non-`mut` binding to the provider. 2. If I decide to support Windows too, all I have to do is write a Windows platform provider and add some `#[cfg]` attributes for conditional compilation.
no, they don’t. you couldn’t parse `&lt;&gt;`-Rust into a token tree without the turbofish being there to disambiguate. you could parse `[]`-Rust just fine. Just the semantics could be ambiguous which is a far lesser problem that still occurs in other parts of the language.
For editor integration - code completion, etc. 
I'll leave this link up since, weirdly, Amazon has two entirely separate blog posts about, but please concentrate comments at https://www.reddit.com/r/rust/comments/a0rph0/aws_firecracker_microvm_is_all_rust/ .
This is one of two different blog posts discussing this tech so I'll leave it up, but please concentrate comments at the post for the Firecracker website: I'll leave this link up since, weirdly, Amazon has two entirely separate blog posts announcing this, but please concentrate comments at https://www.reddit.com/r/rust/comments/a0rph0/aws_firecracker_microvm_is_all_rust/ .
This file might give you some insight on how they harden the VMs to make this harder: [https://github.com/firecracker-microvm/firecracker/blob/56301df8c4c39e84ec367fe803bed22afbf135d8/docs/prod-host-setup.md](https://github.com/firecracker-microvm/firecracker/blob/56301df8c4c39e84ec367fe803bed22afbf135d8/docs/prod-host-setup.md)