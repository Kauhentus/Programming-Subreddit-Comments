Thanks :) I am glad you like the idea
Speaking of spacemacs, I'm fairly new to the system. Every time I boot up emacs, I lose all of the configuration, and rust mode. I have to re download every time I start emacs. I'm not sure why it's doing that, do you know how do I make it permanent? 
Your configuration goes by default in the `.spacemacs` file, and your private layers go in their own directory. Where/how are you configuring spacemacs? (A better place to ask would be in their [gitter](https://gitter.im/syl20bnr/spacemacs), it is very active and people are very helpful there).
Explaining another way: The basic problem here seems to be a confusion between the `String` and `&amp;str`type. What you want at the end of the process is a `Vec&lt;String&gt;` - that is, a vector containing a bunch of strings which it owns. You don't want it to be borrowing references to strings stored somewhere else. The problem is that the default methods for slicing a `String` generates `&amp;str` - borrowed references to string data owned by the `String` being sliced. You need to take those borrowed `&amp;str`s and make them into owned `Strings`; fortunately, this is what the `str::to_owned` method does. So every time you call `.split()` you'll need to call `.map(str::to_owned)` on the result, which will transform those `&amp;str`s to `Strings`. Following Veedrac's simplification of your code, we get this: let mut headers = Vec::new(); let mut res = String::new(); loop { res.push_str("test"); let new = res.split("t").skip(1) .flat_map(|s| s.split("e")) .map(str::to_owned); headers.extend(new); } This code compiles.
Do you have a link for that? I'm curious how many and what level of severity of bugs are in what pieces of code.
The problem is, that wouldn't work, because you need packages not in MELPA (racer and the rust source). I have some private layer which does the racer initialization stuff as per their instructions for emacs.. Just run M-x and search for "layer".. there you can create your own with your rust/racer settings.. :) 
Share! Layers can be made configurable (e.g. disable racer by default and require some path to enable it, same for rustc). I think there is a new way in the develop branch of spacemacs for handling arbitrary packages that might be worth checking. EDIT: found it: `dotspacemacs-additional-packages` is a new variable that installs and maintains arbitrary emacs packages.
https://github.com/alexcrichton/toml-rs
https://github.com/kvark/ron
This is what I was looking for! Thank you kindly
When using the pacman option I get this? Repositorium mingw64 1) mingw-w64-x86_64-binutils 2) mingw-w64-x86_64-crt-git 3) mingw-w64-x86_64-gcc 4) mingw-w64- x86_64-gcc-ada 5) mingw-w64-x86_64-gcc-fortran 6) mingw-w64-x86_64-gcc-libgfortran 7) mingw-w64-x86_64-gcc-libs 8) mingw-w64-x86_64-gcc-objc 9) mingw-w64-x86_64-gdb 10) mingw-w64-x86_64-headers-git 11) mingw-w64-x86_64-libmangle-git 12) mingw-w64-x86_64-libwinpthread-git 13) mingw-w64-x86_64-make 14) mingw-w64-x86_64-tools-git 15) mingw-w64-x86_64-winpthreads-git 16) mingw-w64-x86_64-winstorecompat-git 
The syntaxes would be similar, of course the differences in semantics wouldn't go away.
Yes, if you changed the syntax to be similar to C-style syntax, the syntax would be similar to Rust, which has a C-style syntax.
How is this different from dependent types?
Just press enter to use the default selection of all of them. You'll also want to install the `mingw-w64-x86_64-openssl` package.
While some cases are not bad at all, there are some packages which just don't seem like they should grab the name. For example "logger" is a plugin for logging in iron, which is a pretty bad even if accidental naming :-( 
Cargo doesn't support linking against arbitrary binary artifacts: it is designed to build any dependencies from source. You can depend on a local cargo repository via the `path = "..."` field, e.g. in your `Cargo.toml`, [dependencies] name_of_dependency = { path = "/path/to/dep" } 
Yes, I have this. So if I just want to distribute a library, how do I use it in Rust?
If you're distributing a library to be used in others' cargo projects it should be distributed as source, e.g. a git repository or published on crates.io.
I thought I remembered seeing racer support in the default rust layer. https://github.com/syl20bnr/spacemacs/blob/master/contrib/!lang/rust/README.org (only "basic" support though)
So Steve's answer is the official one, but I just want to add that namespacing doesn't solve the problem, just moves it. In your scenario I know have to specify *whose* cli crate when talking about it and using it. Which means having to remember some random internet username. When you want to use a name and find it's taken, it sucks, but I'd prefer that to having 5 identically-named crates distinguishable only by who made them (which then makes it difficult if a crate transfers ownership). 
Ima workin' on it! The RFC has been approved, just need to get implementation done. This has turned out to require a fair bit of refactoring in the compiler to get done. (Implementing the intrinsics is easy, getting them to have an effect requires the extra work). Match expressions require special handling, but I plan on writing a follow-up RFC for them, I already did a quick proof-of-concept implementation so I just need to get the likely/unlikely ones done. 
No, i don't think it works that way, because spacemacs will download any packages from MELPA (so emacs lisp packages that will be compiled by emacs on windows, mac, linux). But for racer, emacs would have to download some binary file or compile racer itself. And emacs doesn't do that. Emacs also won't download the rust source code. Maybe one could build a package that does all that, but it's not how it is usally done.. So, you will need to build racer yourself and also tell emacs where racer is and where your Rust source code is. May rust-racer packages.el file looks like this (make sure you set up the paths correctly!): https://gist.github.com/buster/9776ab49f48d29ffd3db 
Where does it have racer support? spacemacs can't install racer, because it wouldn't know how to compile and build racer and also not where to get the rust source code.. 
What's the naming convention: my-library or my_library?
&gt; could you simply rewrite as nested if/else's with the most likely if statement occuring earliest? Yep, that's the first thing I tried. It didn't have any effect on performance. I suspect the optimizer is involved but I don't know assembly well enough to check the generated code for myself. I can force the ordering using the logical `or` operator and introducing variable dependencies or something with side effects, but I don't want to do something that ugly just yet.
Thank you for working on this!
&gt; Be aware that it's just "grammar". This query api should not change much in the future. Now I will start to work on query builder, which will this api will use. Something really convenient would be to have not only a model-based querybuilder, but also one which is literally just a Rust syntax for writing SQL, it would be necessary to configure a dialect (for the backing DB) but no using a model, no verification of column types, no nothing, just the ability to write (and compose!) SQL without having to munge strings. That's something I think is missing from SQLAlchemy, a layer below Core which doesn't use specific Table and Column objects. Also while the syntax of your filters seems inspired by Django's I can't say I ever found them great compared to peewee or SQLA.
`my_library`. (See also [RFC #940](https://github.com/rust-lang/rfcs/pull/940).)
Hi, thank you for comment. Sorry but I don't get it, can you please elaborate how can I use it? Thank you for comment.
I have made a quick book: http://azerupi.github.io/mdBook/ It's not a very complex / complete example, but it shows how far I am in the development :)
Be aware that the Rust ABI is not stable. You won't be able to use the artifact with other versions of the compiler. Rust uses the system ABI for such purposes - you could build a `.a` instead of an `.rlib` - cargo has support for linking against those.
While we do have an official answer in the linked document, I would like to add one more point for having namespaces: The barrier to entry. Currently, if I am working on a package which does something that does not exist in crates.io, I get the chance of calling my package whatever I like, for example, I can easily call it `xml`. However, especially if I am not an experienced Rust developer, or a free software contributor, I cannot guarantee to continue developing or improving it. So, if I ever give up on the project, I will now be squatting a rather valuable name. I think this takes the commitment requirement rather high and prevents people from contributing. Personally, this is one of the main reasons I haven't put my JSON-RPC implementation in crates.io. Lastly, I am not sure if it is a good idea to ask people to come up with short, rememberable, maybe witty names. Naming is already one of the hardest problems in the area of computer science.
I don't really understand the problem then since AFAIK emacs doesn't have to do any of that. It would be nice, but for company mode with racer it would be enough to require the user to provide a path to its racer and rustc installations.
Obviously I don't know the exact structure of your match statement, but maybe it is possible to rewrite it as a decision tree? If possible, that might save you a lot of comparisons.
Why do you default to `--release`? Debug builds have their use, too.
I'm usually using debug for gdb and valgrind to test things more than I use release.
This is the first time I worked on a project like this. I don't have much experience with micro-optimizations, so please bare with me. &gt; If you are getting into optimizations that deeply I'm surprised pure Rust would be your choice. Pure rust isn't a strict requirement, but I'd like to see how far I can get without falling back to platform specific tools. This is a good chance to evaluate the limits of Rust and llvm. Nevertheless, thank you very much for mentioning ISPC. I definitely plan on taking a closer look at it if I can't get the program's throughput up to my target rate. &gt; Have you payed close attention to memory order? Are you using SIMD effectively? Each branch handles the data very differently (some branch off further and consist of multiple operations, while others are noop). That's why I don't think SIMD would make much sense in my case. Please correct me if I'm wrong. As for memory ordering, I have not paid any attention to it. I'll research this topic further. I appreciate you mentioning it. If you have any more advice or reading suggestions, I'd love to know them. Thank you.
ISPC isn't platform specific, it also uses LLVM. In any event you don't need to worry about it until you get your memory structure straightened out, which will be a breath of fresh once you do. If you post some examples I can take a look, my guess is that there is still a lot of fat to be trimmed. Branching with few instructions under the branch and branching with lots of instructions under the branch both incur very little cost in modern processors. Medium sized branching that is unpredictable is the real killer. That may or may not be your situation, we can see. If you haven't designed around memory order that is priority #1 for optimizing. Once you do that it is likely that SIMD can be used if you are doing branches with few instructions under them. ISPC can deal with branching and mask off values that shouldn't be touched. The simple ideal situation is basically this: Instead of looping through each element once and doing everything to it, loop through many times, each time doing only one thing. There are many reasons why this works so well, but the main reason is that the prefetcher will keep the processor busy. There was a great video by Valve that I saw yesterday that explains these things better than I've seen before. https://www.youtube.com/watch?v=Nsf2_Au6KxU 
I'm just curious, have you witnessed any serious wins from these yet? I've never been clear on how much these annotations would actually help out LLVM.
hi, i don't think just reading the content-length header will solve the problem because there are a lot of services which do not write that header in the response
You aren't going to find people distributing binary-only versions of libraries if they need to ship eleventy different versions. Its bad enough with the MS C++ ABI being broken every few years. I would hate to think how bad it is with the ABI potentially being broken every six weeks.
The MS C++ ABI breaks every few years and thats annoying enough to deal with. I would hate having to ship eleventy different versions because Rust breaks the ABI every six weeks. Its part of the reason why i'm not even considering proposing Rust to the team I work on.
There's nothing to stop you from naming your crate tongucyumruk_xml if you so desire.
Having DNS issues, working on getting them sorted, sorry.
I would like it if the crates.io name spacing more easily facilitated large projects to break themselves up into multiple crates, instead of having ad hoc conventions like `project-subcrate` naming. Username namespacing doesn't seem great to me for the reasons others stated.
What are the two giant wheels on the right?
&gt;I fundamentally question the method of shipping binary. Many languages do very well without. (Haskell, Scala, Go, just to name a few compiled languages) Haskell and Go are pretty niche in the grand scheme of things. AFAIK there are basically no closed source developers creating commercial libraries in those languages. Scala is a JVM language and the JVM is fairly stable.
If I had to guess, src/test and maybe src/llvm?
The idiomatic way to make a nullable pointer is to use `Option`, since it's represented the same way.
 pub static mut socket: Option&lt;extern fn(c_int, c_int, c_int) -&gt; c_int&gt; = None; That did the trick, thank you 
Incidentally, `__attribute__((constructor))` could be replaced by fn init() { ... } #[link_section = ".init_array"] static INIT: fn() = init;
Thanks! I will check that out.
Idea, could you bubblesort on an arm during a successful match? Arms with the highest probability to match would float to the top. Another idea, fuse all the pure match functions into a single run of if-free code, pin this to the top followed by the more expensive checks.
This time I tackle `std`'s traits, when to implement them and how to use them. If you find an error or something I missed, feel free to comment here.
Do you set `OPENSSL_LIB_DIR` and `OPENSSL_INCLUDE_DIR`when running `cargo build`? E.g.: `OPENSSL_LIB_DIR=/c/OpenSSL-Win64 OPENSSL_INCLUDE_DIR=/c/OpenSSL-Win64/include cargo build`
To my knowledge, the entire libs (maybe even core) team basically agrees Partial\* was a mistake. We'd kill them if we could. Maybe specialization has an escape hatch. 
So you support only one C++ compiler?
&gt; Aside: Just before Rust 1.0.0, someone actually implemented Add for String to mean concatenation. It took yours truly (among others) a heartrending plea to the Rust gods until they mended this particular error. It's not clear to me why this would be a problem. Seems like a fine idea to me. &gt; Like with all operators, be wary of implementing those for your type unless you have specific reason to, e.g. it may make sense to define some of them on BitSets (which by the way are no longer part of the standard library as of Rust 1.3.0) or on types representing large integers. Why should implementing ops for types be avoided? I didn't know implementing `From` gets you `Into` for free. Really good to know.
Concatenation is a different operation from addition, and people didn't like it. I don't know if consensus was reached to not include it so much as it wasn't reached to include it. Overloading `+` to concatenate sequences is still a possibility, I think, and the main alternative is to introduce a binary `++` operator which means concatenate. Operator overloading is often considered confusing if the semantics of the operator is not the same as the operator's normally defined semantics. If you implement an operator to perform some other operation - say `impl Shl&lt;String&gt; for Stdout` which writes to the data to stdout (*cough*), it can be unclear to other developers what your code does.
This is the first officially hosted version! There's lots of work to do, so I wouldn't necessarily distribute this to tons of other sites or anything. Patches/issues/comments welcome, though! Everything is at https://github.com/rust-lang/rust/tree/master/src/doc/tarpl
You may want to note that negative impls of `Send` and `Sync` are only possible on the nightly branch, because that feature has not been stabilized.
And then what happens when maintainers switch or someone forks? What if rob/auth is a fork of bob/auth but totally unrelated to sharon/auth? A better solution is just to ban/reserve empty crates for overly generic crates like cli and rust_cli. While having crate names relate to their function is useful, the main way to search for crates will probably be based on description/keywords or recommendations.
The sheer amount of italics used is making me uncomfortable.
*Feel free to remove it!*
BTW, a tool that allows me to know what traits are being used for a particular type in a particular function would be sooo useful... for example, the version for i32 works both with and without the &amp; in (&amp;a, &amp;b). Why not the generic version, then? ok, in the &amp; version, we seem to need a copy. What are we missing for the (a,b) version to work? A Mul bound modified to take references? Tried Mul&lt;&amp;'a T, Output=T&gt;, that doesn't work, gives me: lib.rs:10:17: 10:18 error: binary operation `*` cannot be applied to type `&amp;T` [E0369] lib.rs:10 sum = sum + a * b; 
And floats would just explicitly break that contract?
`rustc` has just prevented you from a user-after-free bug. Congrats! :-) The problem here is that `FindCaptures` borrows the regex. However, when `find_matches` returns, your regex is dropped (i.e., freed). If Rust let you return `FindCaptures`, then it would contain a pointer to freed memory. Whoops! What you're trying to do is actually pretty reasonable, but the regex API simply doesn't support it. It would require the `captures_iter` method to take ownership of the regex. This would remove the `'r` lifetime parameter, but it could also make using the regex more clumsy or inefficient. i.e., You'd have to clone the regex to use it again, or ask the iterator to yield ownership back to you when you were done. (Yet another way is if the iterators used `Rc`, which is kind of an interesting idea.) In any case, you should probably change your code so that the iterator returned by `captures_iter` is consumed in the same place that the regex is created.
I wonder if the shape of things is that IEEE754 floats not having (in hardware, at least) an equivalence relation resp. total ordering *inevitably* leads to pain somewhere no matter how language designers accomodate the fact (or don't), and no matter what they do, the pain eventually leads them to conclude that their design was probably wrong.
Floats w/o NaN wouldn't, to my knowledge.
Sure. I think Sussman or Abelson (don't remember which) was right that languages should have first class support for rationals, and higher level languages that aren't performance oriented should just have BigInts and BigRationals as their numerics instead of dealing with ints and floats, but Rust has to support IEEE floating point, which have NaN. I guess what would be nice is if the derive macro for Eq and Ord automatically derived PartialEq and PartialOrd. IIRC that was an idea just before stabilization that was rejected for some reason? I just think being able to specify whether you need a total order or a partial order is useful.
Yeah I think that'll happen eventually. Anyway the main point is that NaNs are relatively rare, so it's not unreasonable (in my opinion) to just accept floats on the assumption there aren't NaNs and caveat that "dumb stuff will happen" if there are.
Yeah I think everyone just agrees on "Fuck. Floats." when it comes to comparisons.
You might expect that addition adds the elements of the vectors.
&gt; I only want to compute the captures once, but I plan on adding additional features that let you print out additional info. It doesn't make much sense to pass a bunch of booleans to the print_matches function, since it should be mains responsibility to decide what features to enable. Would it be best to instead just return a vector of the capture details that I care about to pass to each feature? You could do that: https://gist.github.com/anonymous/cd705476576864f9220e --- The problem is that all of your match locations need to fit into memory. You might be OK with that. Another route is to have a "second" main function that returns a result which is then handled by the real main. That way, you can just write your regex/captures_iter inline and avoid the lifetime or allocation issue: https://gist.github.com/e3d67c521a3e0bf09765 &gt; Rust seems like a magical world that sacrifices a tiny bit of flexibility for the sake of guaranteed safety. Not a bad thing, but sometimes it feels like I'm looking for workarounds half the time. Pretty much, yes. Rust's core value proposition is that you care enough about safety to put up with the borrow checker. The good news is that after you write enough code, you'll internalize these rules and it will seem less magical. :-) Of course, some things will remain hard (like cyclic ownership schemes).
I like Partial*
Huh, it looks like Add&lt;&amp;str&gt; for String was kept, but Add&lt;&amp;[T]&gt; for Vec&lt;T&gt; was dropped. That's interesting.
I coudn' t make it work with references either, we'll need someone more experienced to answer this.
So, now we have Basic, Unsafe and Advanced Rust Programing Language?
Advanced is just Unsafe rebranded.
I went with the first option: [retest.rs](https://github.com/coderstephen/retest/blob/787dc489eed52c438f8a4835fc511301da021b29/src/retest.rs). It's a small enough utility that storing the matches shouldn't be too much of a problem (it might be if the input was very large, but this isn't meant to be a `grep`-like tool). The resulting code feels much more organized and functions are more single-purpose. Thanks for the pointers (pun intended)!
Since `Sync` and `Send` were mentioned, I'm going to ask a probably dumb question I've been confused about for a while. Isn't `Sync` the only necessary trait? If something is `Sync`, it should be safe to send it to different threads, right? The concept of `Sync` data (i.e. shared data between threads using synchronization primitives like locks) is something I'm familiar with from other languages, but I don't see an analogy for `Send`. Are there types that are `Sync` but not `Send`? Are there types that are `Send` but not `Sync`?
*RULE 3* ETA more italics
In this line here you are destructuring the references. This only works for copy types. for (&amp;a,&amp;b) in a_s.iter().zip(b_s.iter()) { One problem lies in your trait bounds. If ```a``` has type ```T̀```, ```&amp;a``` has type ```&amp;T```. ```Mul&lt;T, Output=T&gt;&gt;``` means that a variable ```a```can be multiplied with a variable ```b``` if both are of type ```T``` and it will return a variable of type ```T```. The right hand side can be a reference, but then you have to write ```Mul&lt;&amp;T, Output=T&gt;```. You noticed that already, but you still need ownership of the left hand side or a copy bound. It's also advisable to introduce another generic Type for the right hand side so you can be generic over ```T``` and ```&amp;T```. I don't see any reason for using slices. Any slice can be iterated over and iterators are more general. Though I see I did the same thing on [RosettaCode](http://rosettacode.org/wiki/Dot_product#Rust) with slices as well. 
Don't rationals have unacceptably bad performance (beyond just "not implemented in hardware, heap allocation, etc." like BigInt), due to the whole `1829 / 1357` = `31 / 23` thing and having to do factoring (which is hard) to normalize?
Oh no, I feel the need to make PDFs and EPUBs again. Also: Yay! Furthermore: _“Implementing Arc and Mutex […] TODO: ALL OF THIS OMG”_ :( I want more book!
But actually I am actually currently stripping a lot of it. The text is so *bland* now.
&gt; Both these are reasonable answers No they're not. It's only in brain-damaged programming languages that were too lazy to add an actual concatenation operator that people think this out of pure desperation to justify their otherwise indefensible actions. `impl Add&lt;&amp;str&gt; for String` is a monumental mistake that threatens to undo every last scrap of good that Rust has ever achieved and plunge us straight back into the middle ages. Mathematical inquisitors will scour the land, torturing anyone so much as *accused* of misusing operators until they repent their heretical ways. Tens of thousands will die; more will be made lame or blind. Is that the world you want? *Is it?!* Seriously, though, it's just stupid. `~`, `::`, `++`; Rust should've added [*something* for concatenation](https://github.com/rust-lang/rfcs/pull/203). It still can. It's not too late!
One only needs GCD to normalise, which is pretty efficient (e.g. via Euclid's algorithm).
I'm surprised nobody mentioned it yet: C++ doesn't have move semantics by default, it does implicit **clones**. Also, not implementing `Copy` just because the type is large won't save you from `memcpy`, because moves do the same thing (modulo last-use semantics, or lack thereof). At least the even worse reason for not implementing `Copy` (iterators) isn't here, that's reassuring.
It has to do with the `for` loop expansion and how iterators would be copied/moved instead of mutated in place, and instead of making the `for` loop expansion smarter, or adding a lint, `Copy` was removed from types that are iterators.
The lifetime specifier has nothing to do with `Cell` rather it is that your type `U8RegLowByte` has a pointer in it, but Rust doesn't know what the lifetime of that pointer is. Try doing something like: ``` struct U8RegLowByte&lt;'a&gt; { parent: &amp;'a mut U16Reg, } ```
Some languages make it easy enough to avoid NaN, so I don't think this is inevitable.
I was just joking with you. Every time a wip Rust document is posted here with a note not to distribute it, it's on HN in three minutes.
As much as concatenation with `+` gets moaned about, I've never seen it actually cause a problem. The argument always seemed a theoretical one to me. Similar with C++'s overloading of `&lt;&lt;`. This one I agree is absolutely horrid, but I don't think people ever actually get confused about it type-wise. I've never seen it passed to a function generic over shift-ables, say. The practical difference in the two cases is that a concatenation operator is really convenient and a print operator just isn't.
I can accept people disliking `+` for concatenation, but I *really* don't want another operator. Method call syntax isn't that bad, and certainly not bad enough to justify more syntax. (FWIW, I like `+` for concatenation. I don't think Rust should do it, though, given how irrationally scared many people are of it.)
In the example about memory layout: struct A { a: i32, b: u64, } struct B { x: i32, b: u64, } which has the accompanying claim these are not guaranteed to be laid out the same way, the rename of 'a' to 'x' isn't helpful, I feel. Because I assume the more important point is that even two structs with identical *everything* aren't guaranteed to have the same layout. Having one field name different weakens that point, and makes one wonder such irrelevant things as: "why would a field name affect layout", which it obviously doesn't (edit: I assume...).
Yeah, totally! Go for it! :D (will happily review)
[Here](http://is.gd/W5r7pd) is a really generic version: this version will allow the use of any combination (value-value, ref-value, value-ref, ref-ref) of the arithmetic operators. This works because of the `IntoIterator` part: slices implement an `IntoIterator&lt;Item = &amp;T&gt;`, so for two slices the `ref-ref` version will be chosen. If you really wanted something that only works on slices then /u/mbrubeck's suggestion is your best option: [example](http://is.gd/yphFQj). EDIT: Compile this on the `Nightly` channel, it's the only way this works on playpen, but for your project consider using the `num`(https://crates.io/crates/num) crate instead of `std::num`.
Thanks, I will add that.
&gt; I understand that you have never written any JavaScript. ;-) Near enough, but that's different because Javascript does casting nonsense. If you restrict it, as Python does, to objects of the same type, those problems go away. &gt; I've said it before and I'll say it again: **Concatenation is not addition** If we wanted to stick to the mathematical definition, we wouldn't have allowed asymmetric implementations of `Add`. &gt; I'd really like a concatenation operator (and in fact I was about to propose adding a `Div` implementation to `Path` so one can say `basePath / subdirectory` instead of `basePath.join(subdirectory)`), but it shouldn't be `+`. Let's not use `/` for string concatenation, though, lest `Path::new("/") / "foo" / "bar"` becomes too confusing.
`Eq` simply specifies that the equality relationship defined by `PartialEq&lt;Self&gt;` is a *total* equality, not just a partial one. Having separate operators for the two would be rather silly.
I didn't mean to suggest that there be two separate operators, but rather that deriving Eq should not require deriving PartialEq. In most cases total equality is expected so having to understand what PartialEq is and then also adding Eq is confusing. Currently I must have #[derive(PartialEq, Eq)] if I want total equality, I'm asking why I can't simply have #[derive(Eq)] when my type allows for total equality
In other words, the `==` operator is defined by PartialEq, not Eq. Someday, deriving Eq may magically derive PartialEq as way, to reduce boilerplate.
Great book. Here is a small nitpick: The table of contents scrolls to the top, wherever I press a link to load a new page. Therefore I have to keep scrolling the top. I don't know if one can avoid that easily.
I think there was an RFC about this. It also made #[derive(Ord)] imply #[derive(PartialOrd)]
Do you happen to have a link (I haven't been able to find one)
I agree with this. I think limiting exotic operator overloading is a cultural decision really, about what style of code is considered "good", "elegant", or "clean."
Because it would make it impossible to derive `Eq` but manually specify `PartialEq`; same with `Ord`. Also, it would break *all* existing code that relies on this. I suspect Rust would need some kind of `weak impl` construct for it to work, but the original RFC didn't cover that, if I remember correctly.
Me too. The "bad" thing about all of those traits is that one *can* fail to implement them correctly, at which point usually all hell breaks loose (for those who haven't yet implemented their own `Comparator` or `Ord` relation, just trust me on this one). I think it *could* be possible to write a lint that uses symbolic execution to `Deny` implementations that fail to fulfil the contract (e.g. asymmetric or non-transitive relations). That would be a really nice research project.
Fixed. Thanks a bunch!
This may not address breaking existing code, but couldn't both Eq and PartialEq implement the same methods? Currently they look like this pub trait PartialEq&lt;Rhs: ?Sized = Self&gt; { fn eq(&amp;self, other: &amp;Rhs) -&gt; bool; fn ne(&amp;self, other: &amp;Rhs) -&gt; bool { !self.eq(other) } } pub trait Eq: PartialEq&lt;Self&gt; { fn assert_receiver_is_total_eq(&amp;self) {} } but wouldn't this also work pub trait PartialEq&lt;Rhs: ?Sized = Self&gt; { fn eq(&amp;self, other: &amp;Rhs) -&gt; bool; fn ne(&amp;self, other: &amp;Rhs) -&gt; bool { !self.eq(other) } } pub trait Eq&lt;Rhs: ?Sized = Self&gt; { fn eq(&amp;self, other: &amp;Rhs) -&gt; bool; fn ne(&amp;self, other: &amp;Rhs) -&gt; bool { !self.eq(other) } } where the two traits are independent. This way you would only need to specify one, which is sufficient since only one is required to specify the type of equality
&gt; I understand that you have never written any JavaScript. ;-) I believe that's because of type coercion, not because of the operator itself? &gt;to propose adding a `Div` implementation to `Path` But concatenation definitely isn't division either? I don't have a particularly strong opinion about overloading operators like this, only that one must be careful to weigh the benefit of convenience with the fact that the code is now less explicit. I don't see how concatenating `Path`s with `/` is in any way different to `String` concatenation with `+`.
The naive implementation would not be backcompat because if you derive both Eq and PartialEq (as many people do now), youd have two conflicting PartialEq implementations. I don't think there's an obvious way to avoid that with the info available to derive macros right now either. For this reason the change (which also affected Ord and Copy/Clone) was proposed like a week before beta but didn't make it in. Edit: and it didnt make it in for the reason quxxy said, which I forgot
Then Eq types wouldn't meet PartialEq bounds, which they should. You could blanket impl PartialEq for Eq types, but that would probably cause overlap issues right now.
Sorry, i didn't realise since the name was just rust. Would you like me to remove this post?
Ok, to make this clear, the `Div` implementation should have `RHS=Self`, not `RHS=&amp;str`. The latter would most certainly be a mistake.
1) The majority of the base is above 80% but there are areas where the stability is quite low (under 15%). 2) Since this base was designed as it got built there were many times things had to get changed such as ways to get from room to room or staircases. 3) You could keep the crates in a number of places such as in the small attic area, snow corridor at the bottom of the stairs or many other areas. I show more in the video but if you walked around you would see there a lost of good places.And yes it is quite modular. I think there are 3 different foundation levels that this base is build on because its on a very steep hill. 4) Since the server wipe was happening the night after building the base I will have to rebuild. I'm planning on making a YouTube series on rust so if you want to see the process of building a new interesting base check out my channel. I'm going to try build with a similar style in a weird location. 
Haha sorry I was just yanking your chain; I play both the game Rust and program in the language Rust. Both have stability systems, crates, modules and a history of breaking changes. :D
No, but it is custom in most filesystems to denote the concatenation of two paths as `/`. With a bit of squinting, one could even say that a subdirectory is a *division* of the base directory.
With rfc pr 1148 we could have way more than two mutually exclusive traits. :-P
It hasn't had a word said about it in over a month, let alone being merged, implemented, tested, usable in nightly, in beta or in stable. There's *no point* in qualifying everything based on features that may or may not exist at some undefined point in the future. I mean, keeping likely future developments in mind is one thing, but I've noticed a tendency for some in the Rust community to talk like the future is already here (*cough rust has safe scoped threads cough*).
Ah. `join` is currently `AsRef&lt;Path&gt;`, which means it accepts `&amp;str`s. `join` works for `String`, `&amp;str`, `OsString`, `OsStr` *and* `PathBuf`. If you're not allowing anything other than those, most of the time you'll be better off using `join` - in which case you might as well use it everywhere for consistency. I don't see why `RHS: AsRef&lt;Path&gt;` would be a mistake, though.
&gt; This sounds like something that is hard to do in general. Absolutely. On the other hand, even checking some easily checked subclasses of this would have some value. &gt; Also, it would probably require dependent types. Not on the compiler side, but the lint would need to do something similar.
Because that would make `/` concatenate `&amp;str`s (while converting them into `Path`s) as long as you have one `Path` on the left side.
Are you the one distributing the epub version of the other book? That's been very handy for me, it helped learn Rust while commuting. I would love an epub version of this one as well.
I'm confused. `Path::new("/") / "foo" / "bar"` would do the same as Path::new("/").join("foo").join("bar") Python is the only language I know that has this, and it works this way: from pathlib import Path Path("/") / "foo" / "bar" #&gt;&gt;&gt; PosixPath('/foo/bar') 
Yep. So exactly where are you confused?
I think we should do some real user experience science here and figure out if adding it would make Rust better or not.
Is there a way to make this require something like Into&lt;ExactSizeIterator&gt;? The scalar product is defined for equal length vectors and simply zipping and folding quietly produces bogus output. Edit: Nevermind, I figured it out. One can restrain the associated type in the where clause like this ```I1::IntoIter: ExactSizeIterator```
At first I wondered if Rust 89 was a coding standard. Like C 89.
Note that, strictly speaking, it is `Eq` which is more specific - sets with total ordering form a proper subclass of sets with partial ordering. In other words, each total ordering is also a partial ordering, but not vice versa. How and if this distinction is useful in programming languages and in Rust in particular is an open debate, however.
I really appreciate all the work you guys are doing to get rust to play nice with MSVC.
Could you revert the change, please? Are you on IRC, so we can discuss it a bit more?
You are absolutely right. Last time I wrote a small linear algebra library complex where clauses with associated types kept on ICEing, that's why I default to type parameters (this was several months ago [well before 1.0], I'll have to revisit that code to make us of the new features).
&gt; Why should implementing ops for types be avoided? Because they don't give their intent a name and it's far too easy to misuse them. The big problem is that operator overloading is subject to a kind of tragedy of the commons: In the beginning, `+` means arithmetical addition (and at worst set union or string concatenation). Now along comes our very clever programmer Abe. He has seen that he can overload operators, so when he writes his `Foo` class, he naturally wants it to be able to add `Bar`s. Likewise, Ben, Charlie, Diane, Eric, Frank, Giancarlo, Henrietta, Jacob, and Karla, following Abe's example, try to be clever and extend their classes to `Add`some things – with wildly different results. Now `Add` is no longer addition, and when you see `a + b`, you can no longer be sure of the intent of the code. Type inference makes stuff even more implicit, so you have to juggle the types of things in your head. Luckily this only applies within functions. Moral of the story: Don't try to be clever.
There has been a lot of iterations on the eq/ord design, it had a long time to stabilize, and I never read any complaints about the current situation. Thus, I am very doubtful about your assertion. 
I would expect that when one gets NaNs is determined by the IEEE and the operations one writes, not which language one writes them in...?
I just finished an RSA implementation for my students: https://github.com/getreu/rust-play-rsa . This code does not provide "real" security, I wrote it for pedagogical use. 
You're also allowed to throw. Python does this. No doubt you're also allowed to return `Option&lt;f32&gt;`s instead.
A simpler method might be having `r32`/`r64` types with operations that result in `f32`/`f64` types, and putting some `Option` methods (like `unwrap`) on `f32`/`f64`.
Add more exclamation points! :-) Seriously, though, I think Rust really is exciting, geek that I am.
From the comments: &gt; Rust is going to compete with Go to some extent and has a uphill battle for mindshare. Given the content of the article, I'm *really* struggling to see how this keeps happening. Is there *another* language called "Go" that's much more similar to Rust than Google's? Next thing you know, we'll be competing with Haskell because Rust has type classes, Ruby because it has a package manager, and OpenCL because it uses LLVM as a backend.
Done.
Why do you use `fold`? wouldn't `.map(|(a, b)| a * b).sum()` work as well (apart from requiring the "iter_arith" feature)?
I DO! 
Quxxy *can* compete with Quxxy, because Quxxy answer's Quxxy's comments.
One thing I have been cheering for as late as a few weeks ago was Rust's stability promise. As Huon puts it in the article, "code that compiles now should compile with newer versions for the foreseeable future". However, we've already seen the first breaking changes, and code that ran with 1.0 has been broken (and was subsequently fixed). Maybe I'm just bitter that my RFC PR still lingers with next to no chance of implementation, but I don't see a too stable language yet. Please don't get me wrong, I enjoy coding in Rust tremendously, but I guess we will need to wait some versions until the strange corners have been cleaned and we see some actual stability.
Summarizing the different arguments brought up in the "Go vs Rust" debate in a monologue, brilliant! Most of them are true if looked at with a different point of view.
Thanks. While I would generally agree with you in preferring the more general solution, in this case requiring slices guarantees contiguity, hence should ensure cache friendly execution. An iterator is allowed to be more expensive than I want to allow in this case. 
I'd be happy with the ability to restrict packages to specific Rust versions. I'm OK with small breaking changes that can be proven to not affect anything in practice *or* that are fixing sufficiently serious problems. That said, renaming `connect` to `join` is just weird; hopefully an alias or something is added before promotion. &gt; Mad fever dream: abstract out the parsing part of the compiler into an isolated component so that `rustc` can ship with multiple internal versions, all sharing the same underlying representation. That way, when Rust 2.0 comes along, it's not a big deal, because the compiler just parses everything no problem and everything is puppies and unicorns and cheap streaming New TopGear without having to pirate it because Amazon don't support your country even though you *just* got through this garbage with Netflix why do they keep geoblocking things arghghgahgsh!
`iter_arith` is exactly the reason. The example I wrote compiles on stable and beta if one uses the `num` crate instead of `std::num`.
The reason you can't modify u16reg is because you have a mutable reference embeded in u8reg. Until u8reg goes out of scope, that reference will always be there. Think of &amp;mut like handing a book you've written over to an editor. They don't own the book but they can make changes and do all kinds of things too it. As a result you can't change or do anything to the book yourself. That's what is going on here. u8reg is the editor and u16 is the writer. You could make it so that it's not a mutable reference and have u8reg own u16reg. That's when you have to start implementing lifetimes though. The compiler doesn't know how long it needs to keep the parent field around before deallocation. If I'm correct it seems like you want to essentially add whatever is in u8reg to u16reg. This might work out better if you do something like this: struct U16Reg { value: u16, } struct U8RegLowByte { value : u8, } let mut u16reg = U16Reg { value: 0x0000 } let mut u8reg = U8RegLowByte { value : 0x00 } u16reg.set(0x1200) u8reg.set(0x34,&amp;mut u16reg) // u16reg == 0x1234 Where set for u8reg would be defined as: fn set(&amp;mut self, reg_value: u8, u16reg: &amp;mut u16reg) { u16reg.value += reg_value; self.value = reg_value; } This would give you temporary access to the u16reg and define which one you want to change. It should also get rid of all your lifetime woes. I'm not sure if this will work with the Read,Write traits to implement them that way though. This is something that might help with those ownership woes. I recommend getting a firm understanding of Ownership and Borrowing because it will make fighting with the compiler less frustrating. (Every Rustacean has been there before.) If you have more questions or if this code isn't what you need (I wrote this off the top of my head on my non-dev platform so I'm not sure if it will work as written) let me know.
&gt; Mad fever dream My own mad fever dream is [RFC PR #1147](https://github.com/rust-lang/rfcs/pull/1147). It's not only the parser, but also the type checker, borrow checker, lifetime elision and standard library. Alas, it probably *is* too much work for those actually working to bring the Rust language forward. Maybe in a few years, when things have somewhat settled, Rust 3000 can give a real stability guarantee.
And how many languages have an [`arewewebyet.com`](http://arewewebyet.com/) tracking progress? How many get something like `mio` as fast as Rust did? These are both things that are *strongly* desired by people who *want* to use Rust. They're not likely to just run away in the middle of the night, leaving Rust web development a barren wasteland. Sure, "we're not there yet", but you'd have to be *blind* to think there's no hope of Rust *getting there*, and in relatively short order. The best thing Rust has going for it are lots of people who really *care* about extending Rust like an invasive weed into every little nook and cranny it can reach, because even if it's not a perfect fit, it's so damn *good* at writing reliable code! Your incessant negativity just projects an image of Rust not caring about these domains. Sure, *some* people are going to read too much into quick, off-the-cuff remarks. So what? That's going to happen no matter *how* careful you are. People *looking* for a reason to rag on Rust are going to find one no matter *what* you do. Sure, talk up what Rust can do now, but we should *also* be talking up what it *could* do *soon*. What people *are actively* working on. What Rust sub-communities *care* about making the language work with. *That* is the best way to attract more people who want to help make Rust the best it can be, not going all "rust is crap at web and game and IO go play with your silly go rust is 4 srs cs gurus only" and scaring people off. Anyway, I'm done. We clearly disagree and shouting at each other over the internet isn't likely to do any good. Also, get a haircut, ya bum.
&gt; I think it has to be that way. You are probably right, but it still is somewhat dubious marketing.
It's not *that* bad. Rust is way more stable than it was just a few months ago. I remember having to rewrite parts of my code every week or so; it was terrible. Now, the breakage is mostly simple to fix. I still think we need a proper version handling. It would be great if your RFC, the target version, was accepted, but it's only part of the solution. My dream is to have more release channels, with backports of critical fixes to older releases. Something like the latest three releases, with releases being made 6 months from each other and breaking changes being allowed if they are necessary (that's subjective, of course). That leaves projects plenty of time to make the switch to a more recent release, without fear of being left behind in terms of security / codegen fixes. 
Yes, it's only part of the solution, but it's a vital part, if we want to realize all of the others.
&gt; I plan to submit tarpl as my master's thesis in January Italics aren't allowed in theses.
Actually, it's /r/playrust, without the `_`.
Too soon!
Why ~~do you say that~~ [sorry, my misunderstanding] zip continues beyond the end of the shorter? [1] seems to do the right thing. I am not sure how adding ExactSizeIterator would help Zip do the right thing anyway, need to decide to use the shorter of the two... [1] https://play.rust-lang.org/?gist=d7e76270eeafde1d1b5d&amp;version=nightly
&gt; My dream is to have more release channels, with backports of critical fixes to older releases. We will probably have some kind of LTS release in the future, it's just too early for such a thing yet.
Wouldn't having a LTS release and a stable every few months or so solve most of the issue? Breakage is allowed from one stable release to another, and projects concerned foremost about stability target the LTS release.
Have you tried gperftools? I seem to remember pcwalton mentioning that some subset of those tools work on Rust code out-of-the-box.
The recently posted advanced Rust book has a chapter on this: [Higher-Rank Trait Bounds](https://doc.rust-lang.org/nightly/adv-book/hrtb.html).
At first I thought there were some deleted comments... This is amusing.
What breaking changes (changes that *actually* broke code) are you referring to?
&gt;mutably owning 6-year-olds It makes me very happy that fun is allowed in the Rust community. 
So, I understand it like this: //This is legal impl std::convert::From&lt;Car&gt; for String { } //But this is not legal impl std::convert::From&lt;Option&lt;Car&gt;&gt; for String { } But the following is equally illegal. So I am not sure why ``From`` is any better or worse than ``Into`` and why we have the two traits that pretty much do the same thing. impl std::convert::Into&lt;String&gt; for Option&lt;Car&gt; { } 
That repr(rust) section is really interesting but I have just as many questions that I got answers :-) Like, &gt; (in practice there's no particular reason why they wouldn't, other than that its not currently guaranteed). If one of the structs implements `Drop` and the other one does not, would that be such a particular reason? Also, is `struct Wrapper&lt;T&gt;(T)` guaranteed to have the same size/layout/alignment as `T`? At least if `Wrapper` does not implement `Drop`? &gt; **Note: this is a hypothetical optimization that is not yet implemented in Rust **1.0 Does this refer to the above section about struct field orderings on generic types, or the below section on enums (or both)?
The recent `.connect(..)` to `.join(..)` rename comes to mind. Sure, that was a minor thing, but it doesn't exactly inspire much confidence in the stability guarantee. Perhaps I'm taking this too seriously. Perhaps the minor breakage really is acceptable (and hey, working on clippy, which uses unstable code left and right has us following changes in the compiler API on a monthly if not weekly basis – so why should I complain?), especially when compared with the instability of pre-1.0.0 Rust. But I really hope that some day we will be able to use a then-current rust version and run 1.0.0 code without errors. Then, and only then will we have fulfilled the stability promise.
I love abusing the macro system and I love seeing such beautiful abuses of the macro system.
Not yet, but I'll look into them when I find the time.
The connect/join rename doesn't break any existing code.
You can use `cargo build -p &lt;package&gt;` to build a specific dependency. `cargo build -j1` can also helpful when trying to work through multiple failures, since it forces Cargo to build one package at a time, making the build steps a bit more predictable.
Any existing code on crates.io, that is. Now that Rust is public, you should no longer rely on being able to see all Rust code in the wild.
By type parameter, I mean the `T` in `impl&lt;T&gt; Trait for Type`.
How is `connect`-to-`join` breakage? The old method is still around.
OK then. Perhaps some people `#[deny(warnings)]`, which is why some builds break on deprecation. Disregard what I said earlier.
This is the function of `beta`, to give us six-12 weeks to find out if stuff is broken. closed source users can and should yell at us if bad things are happening.
...even if some people seem to run away from it...
All the stuff you setup to build `rust-openssl` separately, you have to set it all up for how your IDE invokes cargo. Often this means setting the environment variables when running your IDE.
FWIW, [multirust](https://github.com/brson/multirust) is pretty close the wand that can just be waved, e.g. `multirust run nightly cargo test` will run `cargo test` with a nightly compiler.
*It looks like* this *and is really confusing*.
&gt; This is equivalent to one of `repr(u*)` (see the next section) for enums. The chosen size is the default enum size for the target platform's C ABI. I had to do a double take on that. I initially read the `*` as a pointer.
Not if you're selling a binary-only library.
Its a hell of a lot easier to support when you don't have new releases every six weeks (we only support MSVC, GCC, and Clang). But anyway, its clear the Rust community doesn't care about this so i'll take my leave.
Uhhh. Any code that used `connect` will continue to compile. It was deprecated, not removed. [EDIT] I see what you're getting in another comment. I guess "breaking change" is a loaded term. Technically, just about any *addition* to the standard library is a breaking change [because of glob imports](https://github.com/rust-lang/rfcs/blob/master/text/1105-api-evolution.md#minor-change-adding-new-public-items). I guess causing a lint like `deny(warnings)` to break code would fall under a [minor change](https://github.com/rust-lang/rfcs/blob/master/text/1105-api-evolution.md#lints) (like just about any addition to `std`).
Oh, what is happening is that `rust-openssl` is linking to `eay32` and `ssl32` which are two native libraries. However because `rust-openssl` is just a static library, Rust doesn't actually link in those native libraries yet. Instead that is deferred to the point where a binary is created, when the linker is linking your executable. So you need to figure out where the `libeay32.a`/`eay32.lib` and `libssl32.a`/`ssl32.lib` libraries are, possibly download them if you don't have them, and make sure they are in a location that Cargo/Rust can find. If you're using MSYS2 then it should just be a matter of installing the appropriate package. EDIT: Upon further inspection it appears none of MSYS2's packages have those libraries, this isn't good. Yeah, I absolutely hate OpenSSL on Windows. I mean, I don't even understand how I managed to get Hyper working for me on Windows since I use MSYS2. I really need to prioritize working on that schannel library, because openssl is just a nightmare.
Well it is for importing functions from somewhere, not necessarily a DLL, but yes, you cannot use `extern` blocks for defining stuff, only importing stuff. That said, I see no reason why it couldn't be extended to support defining stuff. Perhaps you should consider writing an RFC?
Weird. I updated and had `connect`-using code fail due to a missing method... at least, that's what I *thought* it was at the time. The docs do *indeed* say it's still there, so I'm not sure what happened.
Panicking, in general, sucks. The trait's documentation, as well as the types, don't suggest anything about failures being possible, so if I saw a random `From` implementation lying around, I wouldn't expect it to explode in my face. I'm working on a [crate of conversion traits](https://github.com/DanielKeep/rust-conv) to hopefully clear this up. One of the pairs is `TryFrom`/`TryInto` which let you write failing conversions like the above. The crate's not quite fully baked yet, so it might be simplest to just steal the `TryFrom`/`TryInto` traits for the moment. (I think I have, like, four other crates, each with their own definition of `TryFrom`/`TryInto`, or something very like them, because of this.)
Ok, this is the one that did it. Before reading this I felt I had a moderate understanding of rusts types system. I've read this article 3 times through now and I feel like everything finally just clicked into place. Huge thanks from me! A few questions if you don't mind. &gt; As such, you could say that they represent the smallest possible subset allowed by the language; a type can contain elements, but it cannot contain other traits or tangible types. What exactly does element mean in this sentence? Is it an instance of the type? I'm guessing not because then you would have said value. Or is an element a single unique member that the set encloses? Also, could you give a more explicit definition of what you mean by tangible type? Edit: one more question &gt; Types implement the Sized trait, a property which may not be possessed by normal traits, due to the fact that they do not carry any data. This explains the error message shown when attempting to define a function which accepts a trait instance as an argument: In this sentence when you say, due to the fact that they don't carry any data, you are referring to the fact that since all traits only define behavior and don't contain data, none of the set of all traits intersect with the sized trait? Does it make sense to even consider sized a trait then?
&gt; sentence? Is it an instance of the type? I'm guessing not because then you would have said value. He means values, unless I'm grossly mistaken. Maybe the word element is meant to emphasize the concept of type being a *set* of all possible values that belong to that type. &gt; Does it make sense to even consider sized a trait then? sized is a marker trait that states that its members have statically known size. It, by itself doesn't carry any value-level data (unlike types, which have some memory layout and in that layout, contain values), so it's perfectly fine to consider it a trait. But the types that are *members* of sized, they are types. They contain data. They aren't traits. (Although they implement at least one: their own, implicit trait.) Edit: One thing that the article didn't mention specifically, is that there is some types that are not members of sized, but they still are types in the sense that they can have runtime values that are stored to memory. They are called dynamically sized types.
The main reason why this pops up has nothing to do with the languages themselves. If rust wasn't sponsored by Mozilla you wouldn't see those comments.
Thanks for the link. However, I don't that was what /u/Gankro had in mind. It seems that he doesn't like the Partial* traits altogether. 
FWIW, the link in the note at the end to issue #26472 has the wrong URL.
I've been working on my own project lately that uses Iron with the Router middleware and rustc_serializer for JSON. 
There is more than one reason they are controversial. The reason I laid out is just one that comes to my mind if I could do things differently. 
Here's an "hello world" [example](https://github.com/defyrlt/heroku-rust-cargo-hello) for Heroku using Iron + rustc-serialize. [Deployed](https://sheltered-citadel-6521.herokuapp.com/Hello)
One of the examples from Rustful is a relatively simple JSON server: https://github.com/Ogeon/rustful/blob/master/examples/todo.rs There are of course other alternatives, like Iron, Nickel and Rustless, and I'm sure the same techniques can be applied there.
On my phone, but does it work if you do: impl From&lt;i64&gt; for Option&lt;MyType&gt;
Agreed, multirust is awesome! It made setting up travis for optional so painless that even I, someone with just about no knowledge about travis, could do it. I still don't know how it works. I figure it must slowly drain a large reservoir of awesome somewhere.
Nope, [coherence violation](http://is.gd/SRqvWW).
That could be added back in an RFC, at least (and I hope it is).
You can find the precise answers to these questions in https://github.com/rust-lang/rfcs/blob/master/text/0458-send-improvements.md (but /u/dbaupp covered most of it).
Exactly. Even ``Into`` trait will not work for the same reason. This leads me to the confusion where several blog posts claim some sort or relative merit of ``Into`` over ``From``. I don't understand that. I also don't understand why we have two traits to do the same thing. Any help in understanding this will be appreciated.
The problem is that concatenation isn't commutative IMO.
Yes, I tried that, but then how to pass it to c1 and c2 as reference?
- [rust-postgres](https://github.com/sfackler/rust-postgres) for connecting to PostgreSQL. - [rust-mysql-simple](https://github.com/blackbeam/rust-mysql-simple) for MySQL. - For others, see [the list of popular database libraries for Rust](https://github.com/kud1ing/awesome-rust#database).
I'm positive I don't have to inspect the source code of all those lib-s to get the answer to my question which is quite simple.
There is no generic in the english sense of the word. But these libraries allow you to connect to the database.
there isn't one universal way of interfacing with a database, so no
&gt; Errors and Warnings should not suggest how to fix the problem. I don't get this. Generally speaking, I want to see the suggestion of the compiler (but it's okay to have a flag to suppress them)
I'm not saying interfacing, I'm saying connecting.
I'm happy for you. I do know.
Sure via sockets or something.
Nice!
Just a private opinion not authoritative in any way, but I would sure hope not.
Internetting via phone -- should be updated.
Sorry for being off topic, but I love the theme of your blog; it's so clean and professional, but the huge unrelated images at the top give it a lot of personality. Probably one of the prettiest programming blogs I've seen!
I'm not aware of any, and yeah, you're right, factorisation definitely doesn't work well with addition.
Is there some version of the slides that is viewable on mobiles? Can't click anything on the linked slides. 
Do the arrows in the bottom right not show? huh
You can fold with `f64::max`. Its nan behavior is specified (ignores it, result is the non-nan argument.) Something like this ought to work: `vector.iter().cloned().fold(-1./0. /* -inf */, f64::max)`
Raw version: http://cglab.ca/%7Eabeinges/talks/iter/index.md
Hi, As an programmer being used to python, surely A vec should have a max method/trait as standard. It would be easier to read, and future programmers wouldnt have to reinvent the wheel All the time. I realise my post reads like it is ranting at you, and im sorry about that, but i can not see a good reason For not giving vector an easy way to max / min it.
Thank you for a very good answer. I see now how using ``From`` from a function is more verbose than ``Into``. &gt; ``Into`` consumes self, ``From`` doesn't. This I am not sure about. I am most probably misunderstanding you. But, I can certainly implement ``From`` for ``&amp;T`` and avoid a move. pub struct Car { model : String, year: u64 } impl &lt;'a&gt; std::convert::From&lt;&amp;'a Car&gt; for String { fn from(c : &amp;'a Car) -&gt; Self { format!("Car. Model: {} Year: {}", c.model, c.year) } } 
An iterator does have a `max` method, it just doesn't work with `f64` because `f64` doesn't have total equality. If `f64` implemented `Eq`, `vec.iter().max()` would work perfectly. However, because with f64 values it isn't always true that `x == x` (specifically, `NaN != NaN`), `Eq` isn't implemented, and a custom fold is required.
:(
Oh that's right, I picked the wrong infinity. Whether to use infinity or nan for an empty iterator.. that's the user's choice.
True, it's not necessarily a bug. Which way is a better definition depends on the circumstances. Assuming zero would be consistent with the behaviour of .sum() and .product().
Is it necessary to use `i64`? Perhaps it would be better to instead use `u32` if that's large enough, and only convert to `i64` and then negate it when required. Since you require the value to be negative anyway, you could do away with a "broken" `From` implementation and instead only concern yourself with the magnitude of the value.
That's wonderful! Thanks for sharing 
It depends on what precisely we mean by 'undefined behaviour'. The transmutes into `Err(_)/Ok(_)/_` are obviously a terrible idea, and I do agree those are 'undefined' because they can break all of the safety built into the enum system. I also think, since we can create blank private fields in structs to get the same effect, that empty enum instantiation is currently rather useless and nothing would be lost if it were impossible to do. But I do not think it is technically 'undefined behaviour' in the sense that until and unless the compiler is changed, it should work everywhere without errors. The Void instance is a transmute of `()`, which is nothing at all, so the compiler is not going to do anything with it besides type checking. There is never going to be anything called a Void in the program at run-time, so the LLVM will never know that it 'exists'. But, I do get why you may want the *absolutely* "cannot be instantiated enum". You may already know, but in Scala (my other favorite language) there is a [special type called `Nothing`](http://www.scala-lang.org/api/current/index.html#scala.Nothing). It is like a combination of diverges `-&gt; !` and the `()` type. `Vector[Nothing]` would per definition be an empty vector, and so you could write: `val empty:Vector[Int] = Vector[Nothing]()` and vice versa, it is a cute trick. In Scala there is also pattern matching, and I just checked but it is not smart enough to realize that `Some[Nothing]` is never needed in match blocks. (although in Scala that is just a warning, so it does still compile) Perhaps the empty enum should be defined in the Rust language as a divergence whenever it is the return type. That would make transmuting into a Void also become a compiler error: because the unsafe block is returning a Void, which is a divergence, which is not allowed to return. And once you have that, there is a much stronger guarantee that Void cannot exist (even with crazy people like myself writing unsafe code) and then empty enum fields could be more safely excluded from pattern matching. Exclusion from patten matching errors should be easy and cheap to implemen~~t, [as it is has already been done for `()`](http://is.gd/gVobeb). But m~~*( I am an idiot. o_o )aking the compiler do both type-checking and recognizing that something is a divergence at the same time is probably much more difficult, as at first glance it seems that [divergence and types are handled separately by the type-cheker](http://doc.rust-lang.org/rustc_typeck/middle/ty/enum.FnOutput.html). So, I dunno. I can see the merits of simply 'declaring' that it is undefined behavior because it is easy; but then why have blank enums *at all*? If they are not going to give us some novel compile-time guarantees, what is their use? If they really ought never to be instantiated, then it is already given that a function returning a Void must diverge or contain some undefined behaviour.
ODBC, https://en.wikipedia.org/wiki/Open_Database_Connectivity ? I think it lets you connect pretty much to anything else through its generic interface. Albeit even that fails short in some cases. For example, nobody seems to know of a way to connect to the embedded MySQL with it: http://forums.mysql.com/read.php?58,186300,186300
That impl is over &amp;T. If you impl'd that for Into, &amp;T would be self. (self doesn't always imply it doesn't involve a reference). Same with From's type parameter. &amp;T is, after all, a type.
Personally, I just run `cargo update` every so often. You could do something like ``` cargo update &amp;&amp; git diff --quiet -- Cargo.lock ``` Of course, this only makes sense if you have an application, as you don't commit your lockfile for libraries.
I just pushed a fix for that. Thanks!
or a feature for cargo itself. It might be neat to display a list of the used dependencies with used and current versions side by side: foo 1.0.1 - 1.1.0 bar 0.2.0 - 0.5.0 etc
Possibly relevant issue: https://github.com/rust-lang/crates.io/issues/127
This is so cool, +1 thousand 
Are the talks going to be uploaded somewhere in video form?
For me too.
Mainly for the links :)
You can set up a test run that is allowed to fail that runs `cargo update &amp;&amp; cargo test` instead of the default command.
I've been doing a bunch of work wrapping some libraries with FFI lately, and have needed to convert to/from C string types. It's not always obvious how to go between all the types given there are quite a few variations, so I thought of making a table showing all the possible conversions to/from all the relevant types. Here's my first cut - feel free to edit and improve it. If it's useful, perhaps it could be incorporated into the documentation or something. I also thought it might serve as a guide to some conversions that would be useful but aren't yet supported. A good example is iterating over the `Chars` in a `String` with an iterator (created by `chars(&amp;self)`), processing or filtering them and then reassembling a new `String` with the result. 
Ah yes, good ol' `wchar_t` - I forgot that one. I assume that is to represent UCS-2 native strings on Windows? Yup, as soon as you touch FFI, you have to deal with all the messy uncertainty of encodings. Perhaps a separate table just for FFI interaction would be useful? If the CStr/CString are intended as the conduits to pass platforms strings back and forth, it could be simplified somewhat.
&gt; You should always be using `to_owned(). to_string()` is the generic conversion to a `String` from any type implementing the `ToString` trait. Very useful link, thanks. I'll add it to the table. But see this makes me wonder - if it's such a common idiom, shouldn't there be a single method?
There's yet another way to create a `String` from a `&amp;str`: `s.into()`. (Although, this will require type inference or explicit instantiation.) None of `to_string`, `to_owned` or `into` are actually defined on `&amp;str`. All of those methods come from implementations of `ToString`, `ToOwned` and `Into`, respectively. Each of these three traits serve different purposes. It just so happens that the intersection of implementations for `&amp;str`/`String` provide three different ways of doing very similar operations. It would be nice if we could just always recommend `to_string`, but AFAIK, this goes through the formatting machinery, which is unfortunately expensive. AIUI, the formatting machinery isn't necessary, but we don't have the tools in the language to say, "the impls for `ToString` are find and dandy, but for `&amp;str`, we can do it slightly differently that will be much faster." Once we get a tool like that (e.g., specialization), then we can all hopefully coalesce to `to_string`. (Although, I do like `into` because it is so short---in cases where the type system can infer the return type to be `String`.)
Wouldn't [this](http://is.gd/htt1J9) do? You can get a `Lines` iterator from a String / &amp;str later on, when you need it. 
Part of this is that I just want to know how to do it, but also I'm going to be implementing an iterator so I'll need something to index into, and I don't want to split the string each time I call `next()`.
This was exactly what I was looking for, thanks! 
Of course, you can achieve even more flexibility by copying the signature of `File::open`: pub fn new&lt;P: AsRef&lt;Path&gt;&gt;(path: P) -&gt; FastaFile
I want something like `OsString` or `CString`, but for UTF-16. I've been meaning to write it myself by wrapping a vector of `u16`, but I don't really know how to implement the unsized variety (`Utf16Str`). (I tried `struct Utf16Str([u16])`, but got stuck in converting this to/from the owned variety that I defined as `struct Utf16String(Vec&lt;u16&gt;)`)
I don't get the `Drain - 🍼T` part (well 🍼 don't render here, but it seems to be a [baby bottle](http://graphemica.com/%F0%9F%8D%BC)), was it a joke? (also I don't what "higher-kinded-whatzits" is about - higher kinded traits? higher kinded types?)
This is sorely needed, but I can't say I'm sold on a couple of things: 1. The token strategy, but as long as I can throw a pointer in it, I can hang my callbacks off a struct which seems fine. I'd rather have the dispatch done by the compiler machinery than my own hash lookups that could be avoided or replaced by pointer chases. 2. Forcing an event loop on the user. If I understand correctly, I can't use the mio async sockets without going through the defined event loop? But those are things that can be generalized in the future, and hopefully this gets more love by others.
Still off topic, what are your qualms with ghost? I was looking around for a blog engine, and it seemed nice. I went with Piecrust2 in the end, however. I'm curious what people think of Ghost.
The videos should be coming out soon where Carl goes into more detail on why he went with Tokens, etc. I'm not sure where or when they'll be released, but I'm sure they'll post the link here and/or twitter.
Mixing owned and and borrowed types doesn't seem like a good idea. Especially having `const char*` represent both.
`Box&lt;str&gt;` is also a thing -- basically a runtime constructed `&amp;'static str`.
&gt; Is there a way (in stable Rust) to use generics to reduce the number of functions I need? No there isn’t, but it is a known issue and desired feature: https://github.com/rust-lang/rfcs/issues/1038 Until that gets implemented you could use a macro instead.
Mainly for the cute pictures of tools, I'd have thought :-)
Now I can say that Rust is ready for prime time. Cue in the business applications.
You can use one array trait to have all the repetition in one place, then base the rest of the code on trait generics. [ArrayVec](https://crates.io/crates/arrayvec) does that -- see [trait Array](http://bluss.github.io/arrayvec/doc/arrayvec/trait.Array.html) in the docs, although it's hidden since I don't want it to be depended on directly.
It's not a static site with a flat file system, quite frankly.
Can it force open RARs with a broken header?
The windows string conversion functions are the trickiest since they don't show up on rust's documentation, because the documentation isn't generated on windows. https://www.reddit.com/r/rust/comments/37k1ij/converting_str_to_utf16/crner29 http://aochagavia.github.io/rust/std/os/windows/prelude/trait.OsStringExt.html http://aochagavia.github.io/rust/std/os/windows/prelude/trait.OsStrExt.html
They are. Confreaks did the recordings. We can't commit to a timeframe.
Looking inside the documentation, I see what you mean. The low-level function `RAROpenArchive` returns a NULL handle when the header is broken. Tried out the alternative `RAROpenArchiveEx` and it also returns a NULL handle (additionally to setting the open_result to `BAD_DATA`)... Unfortunately, with a NULL handle, there is nothing I can do. Surprisingly, the `unrar lb` command works... If you want, you can write an e-mail to dev@rarlab.com. Or I could do it instead if you wish.
Hi there :) How about both? That is, adding a new event in `eventbuffer` and automatically resizing as well? Is there a particular difficulty in doing that? I don't see why the user would not want to cellbuffer resized automatically. It's not as if there was a reason for *retrieving* information that has been put there, so there's no possibility of pulling the rug from under the user's feet.
Gankro: During the talk you mentioned that traits that abstract over collections would require HKTs (if I understood you right). It seemed unrelated to the StreamingIterator issue mentioned in the slides. If I understood you correctly, why is this?
Same here. Rust is finally ruining my everyday language. Scared.
XD Hi again, That sounds like a good idea. Catch the resize, resize the buffers to match and push an event onto the queue to notify the consumer that a resize has occurred?
Come on man, it's been over 24 hours! It should have been posted 72 hours ago!
Indeed, please try it and let me know how you get along! DXR is a code search and navigation tool. It gives many of the benefits of the code search stuff you'd expect from an IDE, and then some. E.g., jump to the definition of a variable, field, type, etc. Hover over a name to see its type and (if it is immutable) how it was initialised, find callers/callees of functions, implementations of traits, etc. Plus syntax highlighting (although I must admit, this is nowhere near as good as in most editors). There are however limitations, in particular it cannot currently index generated code, e.g., macro invocations (even simple ones like `println!`) and also language features implemented by desugaring: `for` (yeah, this is sad), `if let`, `while let`, etc. You can also run it on your own projects, it's not just limited to the Rust repo. I'm working on Servo, but that has some niggles. Smaller projects should work without problems. However, it is a little bit of an adventure setting up DXR (see https://github.com/mozilla/dxr for the source and instructions), if you're keen to try feel free to ping me on irc for help (nrc) or ask in #static where the DXR folk hang out. If you find bugs, please report them at https://github.com/nrc/rust-dxr. There's loads to hack on too - if you're interested, ping me!
Hey I have one recommendation - termbox assumes the yerminal is using ansi escape codes. You should not! All terminals specify a terminfo file which associates their codes with abstract capabilities. The term library already exists to parse this, but its incomplete. If all terminal apps are bound to ansi escape codes, a better protocol can never replace it. There's no reason for this when a terminal neutral format exists.
you can search for ` function:last` which will find just functions/methods called last. This is using the filters feature, checkout the drop down menu on the right of the search box for more filters. You can search for a specific function implementation too (useful for new), e.g., `function:&lt;Arc&lt;T&gt;&gt;::new`. The syntax is a bit odd due to accommodating UFCS and should be fixed. Because last is implemented for `[T]`, it is even buggier and you need to search for `&lt;T&gt;::last`. If there is only a single result, DXR should jump directly to that result, rather than show you the search results, but I think you have to hit enter, rather than wait for search-as-you-type to catch up.
Rust: Time travel is okay, but please please _please_ don't move out of a borrow.
C++ string doesn't overload `&lt;&lt;`. It overloads `+`.. Streams overload `&lt;&lt;`. `+` has problems with performance since people are happy to sprinkle `a+b+c+d` into an expression where they want `concat(a,b,c,d)`. This is like, performance bug #1 for Java programmers.
&gt; C++ string doesn't overload `&lt;&lt;`. I am aware. &gt; `+` has problems with performance For C++ and Java, not Rust. FWIW, I don't believe this is the fault of `+` even then, as there's no reason to think an equivalent method wouldn't have the same problem. It's problem with immutable strings in Java and a type-system safety issue in C++, not a problem naming it `+`.
&gt;I'm confused as to why `/` is in the path string in the example. It's a bug. Not necessarily; though it depends on filesystem semantics. &gt; I'm also surprised that you actually use that. I thought everyone uses `os.path.join(foo, bar)`. I'd be surprised if many people *knew* about `/` on paths, which makes your surprise a bit puzzling.
And here is the quote of the week ! :D
That's nice!
&gt;search source for usages simple text search usually works good enough &gt;jump to definitions racer can do it &gt;check what type/signature some name but this is truly invaluable for a language with type inference. tooltips with struct definitions are also a very useful shortcut for "jump to definition"
&gt; Although there are some very smart people coming from Idris who are working on RFCs, so it may get better. Really? This is awesome. Is the work happening in the open somewhere I can take a peek?
I am getting: Compiling rustty v0.1.8 (file:///Users/developer/Downloads/rustty) src/core/terminal.rs:17:23: 17:35 error: unresolved import `nix::sys::epoll::epoll_create`. Could not find `epoll` in `nix::sys` src/core/terminal.rs:17 use nix::sys::epoll::{epoll_create, epoll_ctl, epoll_wait}; Mac OSX. Rustc 1.1.0.
&gt;Not necessarily; though it depends on filesystem semantics. It's a bug. The whole point you're using Path and joining using path methods is because you want to be operating system neutral. Prepending a `/` removes the neutrality. &gt; I'd be surprised if many people knew about / on paths, which makes your surprise a bit puzzling. If you think not many people know about `/` on paths, why would it be puzzling?
Well it's true that there are a lot of details that I don't know about Rust, but the main optimization I'm talking about here is that each invocation of a concatenation may need to allocate more memory. If everything is put into a single call (or `toString` call as in the case of Java's `StringBuilder`) then there only needs to be a single allocation that is the length of the final aggregate string. If Rust somehow avoids this using the `Add` trait, then I'd love to know more about how it does this.
Have you been using rr lately? :)
Done.
I'm also very interested in this. I'm taking my laptop with me all the time and was in a spot without WiFi for about 3 hours. Local docs would have been a great help.
Option 2 seems redundant. You can use channels with an iterator interface (or at least you could last time I used them.) Between 1 and 3, 1 looks like the lowest overhead option (though this obviously depends on what you're actually doing), while 3 is what I'd like to use as a user of an API, personally. Since you can emulate 3 very easily using 1, (The callback just pushes the event into a channel.) I would probably go with the callback.
Everyone should use rr. Best thing to happen to debugging in years.
Is the [llvm.debugtrap()](http://llvm.org/docs/LangRef.html#llvm-debugtrap-intrinsic) intrinsic not exposed to Rust at all?
It causes a "breakpoint trap", which a debugger uses to detect that a breakpoint has been hit. Usually the debugger puts the "int 3" instruction into the code itself, see http://stackoverflow.com/questions/3747852/int-3-0xcc-x86-asm for a nice explanation.
Good job
Thanks for this factoid/anecdote, that was really interesting.
Yep! The receiving end of a channel can [easily](https://doc.rust-lang.org/nightly/std/sync/mpsc/struct.Receiver.html#method.iter) become an iterator.
It's in the same position as Rust's macro !- `Array!(int)`, for example.
Ah, that makes a little more sense.
Nice. I've updated this repo's docs to just point towards the intrinsic.
What I mean with that is that you need to keep a JVM on all your machines/containers, make sure it's set up in a similar manner, and if you share them (across containers) you have to ensure that there isn't too much competition amongst the different programs sharing it (though the JVM right now is very good at not having universal locks). With Go you don't have to worry about that because each program is completely encapsulated, they each run their own GC (which could actually make the JVM faster, but that isn't the problem, it's scaling). You just run the Go program on a clean machine and it works without needing a separate VM installed (the run-time is included in the executable).
It's too bad there isn't a way to do this in stable Rust: the intrinsic is marked unstable, and this crate relies on inline asm which is an unstable feature. I guess it could be done in stable Rust by shipping a `.c` file which contains a single, exported function that uses inline asm (available in every major C compiler I know of) to generate the interrupt, and adding the [`gcc`](https://crates.io/crates/gcc) crate as a build dependency.
I think OP was referring to a compiler plugin style of macro, which could unrar an archive at compile time :-) 
As a user, I like 3 much more than 1. I think asynchronous callbacks make code a lot less readable. But you can build a channel interface on top of callbacks. But that isn't an obvious solution to everyone when they look at a callback interface, especially if they're not very familiar with both. I wonder if there's a generic shim in that? I guess it would just be a function `fn&lt;T, F: FnOnce(T)&gt;(tx: Sender&lt;T&gt;) -&gt; F { |t| tx.send(t); }`, which is pretty minimal. Or maybe it wouldn't be so bad to expose both APIs? You could define the API in terms of the callbacks, and then provide a second channel method built on top of that.
Thanks. I didn't realize that Rust's `Add` mutated. In that case it's more apt to be compared with `operator+=`. I should have suggested that from the start. (For completeness, the following is from GCC's `libstdc++-v3/include/bits/basic_string.h`): /** * @brief Append a string to this string. * @param __str The string to append. * @return Reference to this string. */ basic_string&amp; operator+=(const basic_string&amp; __str) { return this-&gt;append(__str); } &gt;¹Although they could probably manage having secret shared buffers. I'm not sure why they don't, but I doubt it matters much. Most strings are very short so there's not much point. In fact, if I understand correctly, `libstdc++` has a local buffer for short strings so no allocations need to take place. Maybe a JIT could figure out that two strings could be shared somehow, but that's a lot of book keeping for a minor savings in memory that will just be flushed down the toilet by the ever hungry JVM. You seem to have a really good knowledge of these topics things so I don't think my posts are really adding anything.
How are you sandboxing the compiler? Last time one of these was made, it was pointed out that building docs allows for arbitrary code execution.
Monitoring repos/crates.io is definitely something that would be useful, but currently, no. A PR made with an empty commit should trigger a regen, though &gt;_&gt;
Honestly for no other reason than I hadn't used epoll yet and was itching for a chance to use it XD. I've been working on replacing epoll with select or poll however I'm having difficulty integrating it, and for that matter anything, with signals at the moment (multithreaded signal handling makes me cry inside).
Ah, I forgot C++ returned from its compound assignment. Yes, Rust's "Foo".to_owned() + "Bar" + Bash" + "\n" is like C++'s (((std::string {"Foo"} += "Bar") += "Bash") += "\n"); &gt; Maybe a JIT could figure out that two strings could be shared somehow The optimization I'm thinking of is actually much simpler than that, but makes `+` on strings just as fast as `append`ing to a `StringBuffer`. One could store strings as struct JavaString { length: usize; capacity: AtomicUsize; buffer: *mut u8; } as Rust does. The first `length` bytes of `buffer` are immutable. One implements `+` as fn add(&amp;mut self, &amp;other: String) -&gt; String { unsafe { let new_length = self.length + other.length; let mut new_capacity = self.capacity.swap(0, SeqCst); let mut new_buffer = self.buffer; if other.length != 0 &amp;&amp; new_capacity &lt; new_length { new_capacity = new_length.next_power_of_two(); new_buffer = allocate(new_capacity); ptr::cpy(self.buffer, new_buffer, self.length); } ptr::cpy(other.buffer, buffer.offset(self.length), other.length); String { length: new_length; capacity: new_capacity; buffer: new_buffer; } } } To be clear, Java's current `+` looks something like fn add(&amp;mut self, &amp;other: String) -&gt; String { unsafe { let new_length = self.length + other.length; let new_buffer = allocate(new_length); ptr::cpy(self.buffer, new_buffer, self.length); ptr::cpy(other.buffer, buffer.offset(self.length), other.length); String { length: new_length; buffer: new_buffer; } } } If the JIT wants to inline a `String` (such that `capacity` is no longer shared), it must first set `capacity` to `0`. 
The thread on placement new is really interesting. I hope the arrow syntax wins :)
The syntax seems nice enough. I do worry though that in some distant day after we have HKT, we'll want to add some mondaic do-notation-style sugar and wish that we'd kept the standard operator around for bind. I wonder how folks would feel about something like `PLACE @= VALUE` for the placement syntax instead (Assign this value *at* this arena).
Any sufficiently advanced macro is indistinguishable from magic. (Albeit this is more a compiler plugin, rather than a mere macro.)
I think the examples are missing passing the receiver (`obj`) and the selector (`op`) to `objc_msgSend`, no?
A centralized rustdoc service would be nice, even better if we figure out how to get all the crates to crosslink correctly.
Can methods be called (in either direction) across the language boundary, or does data crossing the boundary have to be "C-compatible"?
I feel like I missed something. What is placement new?
&gt; Rust FFI expects nul terminated strings. Given that PHP is (apparently) giving you (ptr, length) pairs for strings, which is what Rust *wants*... why don't you just change the Rust function to take that? Then you don't need the "copy string into a NUL-terminated string" step at all.
They would already crosslink correctly, at least, in the naieve way of just putting all the generated docs in a single spot.
&gt; we'll want to add some mondaic do-notation-style sugar I doubt that. Placement new seems far more important than pretending to be Haskell.
Thank you. I have now created a sized type (all pseudo code from here): pub struct EventBridge { event_handler: *mut SomeTrait } The C function to register a callback takes a void* like this: fn register_callback(o : *mut libc::c_void, /*other things*/) I am trying to call it like this: let mut o : EventBridge = ...; register_callback(&amp;mut o); But this is failing to compile. expected `*mut libc::types::common::c95::c_void`, found `&amp;mut EventBridge` (expected enum `libc::types::common::c95::c_void`, found struct `EventBridge`) [E0308] 
This is true, I am hopelessly at a loss in the FFI space beyond simple things. :( &gt; A raw void * can't possibly be a callback I left the callback function parameter out in ``register_callback()`` for simplicity. &gt; and FFI (which includes a section on callbacks) I have read the FFI guide. I understand it. But it makes no mention of registering a trait. So I am having to find a work around using a bridge as you had suggested. Anyway, as you have stated here Rust will not cast pointer types. The trick seems to be to declare the external function like this: fn register_callback(o : *mut EventBridge, /*other things*/) This is working. Now I can focus on memory management (making sure the bridge object stays alive long enough). Thank you for your help. I am past the immediate hurdle. I will post separate questions if I need to.
&gt; I left the callback function parameter out in register_callback() for simplicity. That's a bad idea because I (and anyone else trying to help) will be working blind and will have to guess at important details, which makes it that much harder to give you accurate information. &gt; The trick seems to be... Don't do that. It's far too easy to accidentally write the wrong signature. You can cast pointers in an unsafe block (`unsafe { ptr as *mut libc::c_void }`), which is *marginally* less bad (it will, at least, stop you from casting between sizes). &gt; Now I can focus on memory management (making sure the bridge object stays alive long enough). This depends on the API. There are some unstable (*i.e.* you need a nightly compiler) calls on `Box` that let you go between Rust boxes and raw pointers (`into_raw` and `from_raw`, I think?). If the API doesn't have any sort of destruction logic, you might just have to use `forget` and leak memory, or use lifetimes to restrict when the callbacks are allowed to exist. FFI is hard. *shrug*
Note that `into_raw` (which is just a wrapper around `transmute`) consumes its argument so `forget` isn't needed.
Thank you again for your help. &gt; Don't do that. It's far too easy to accidentally write the wrong signature. I take your point. For what it's worth, the FFI guide seems to be doing what I did. The C function: int32_t register_callback(void* callback_target, rust_callback callback) Rust FFI declaration: fn register_callback(target: *mut RustObject, cb: extern fn(*mut RustObject, i32)) -&gt; i32 
The naive approach would somewhat work, I'd imagine having packages with differing version requirements would make things somewhat strange though. Also the search might become a bit unweildy?
* I'm not too sure if type macros are powerful enough for that, but I can look into it at some point. * I don't allow moving Rust values into C++, every value which you close over is passed by reference, and I only allow you to see types in C++ which are `#[repr(C)]`. I'm not intending to allow arbitrary mixing of rust and C++ code, simply making the interface a little bit nicer to use. * Yes, moving C++ into rust requires using new, because rust can only see C++ values opaquely right now, unless they are `#[repr(C)]`. I have no intention to change this. * Rust's semantics practically are the same as C++'s integers due to llvm, but yes, they have technically different semantics. I think that this is worth it for ergonomics (especially because this already requires `unsafe {}`).
Ah, yes, I forgot about versions, I was just considering the namespacing in URLs.
What it does is a linear scan through the string, since strings can't have random access based on the codepoint ordinal. It is literally implemented with `char_indices`: fn slice_chars(&amp;self, begin: usize, end: usize) -&gt; &amp;str { assert!(begin &lt;= end); let mut count = 0; let mut begin_byte = None; let mut end_byte = None; // This could be even more efficient by not decoding, // only finding the char boundaries for (idx, _) in self.char_indices() { if count == begin { begin_byte = Some(idx); } if count == end { end_byte = Some(idx); break; } count += 1; } if begin_byte.is_none() &amp;&amp; count == begin { begin_byte = Some(self.len()) } if end_byte.is_none() &amp;&amp; count == end { end_byte = Some(self.len()) } match (begin_byte, end_byte) { (None, _) =&gt; panic!("slice_chars: `begin` is beyond end of string"), (_, None) =&gt; panic!("slice_chars: `end` is beyond end of string"), (Some(a), Some(b)) =&gt; unsafe { self.slice_unchecked(a, b) } } } (I'm the author of that snippet by the way)
But magic is cool if used properly :) BTW: your comment remind me about Zetsuen no Tempest
Boundary is currently only "C-compatible". Unfortunately, I don't get rust type information until after I have generated all rust code, which means that I can't generate the `extern C` functions for each of the methods which would be necessary for that. If you want to be able to do that, you have to declare the `extern C` functions yourself, and currently re-declare them in a `cpp_header!` block (though there may be a way to do this automagically with macros in the future). Passing C++ classes across the border is a surefire way to cause complaints from the C++ compiler (as you are returning C++ classes from an `extern C` function), and I'm pretty sure that stuff will break at some point with it, I don't think it's worth getting to work for compatibility &amp; stability reasons.
In a way I agree that C++ is terrible, but there are a lot of libraries written in C++, and right now people have to manually write wrappers around them. This might make it easier for people to do this and stop having to write C++ even close to as much in the future. That being said I also have some C++ Stockholm syndrome - the templates are just so beautiful...
Not really irrelevant with the borrow checker. `vec.push(vec[0].clone())` works, `vec &lt;- vec[0].clone()` doesn't.
I don't understand how this can possibly be more popular than https://github.com/mystor/slag Let the world know that today was the day that everyone on the internet was wrong.
I wonder if running `rustdoc` in a container would be sufficient sandboxing?
So explicitly using wrapped arithmetic is strictly not needed anymore (except as documentation for anyone reading the code), even considering compiler optimizations?
Scala has it too, and seems like a closer precedent for Rust. The impression that I get is that HKT is very likely to happen, just not in the short-term. If so, someone's gonna write a do! macro, even if there isn't built-in language sugar. It'd be nice if we didn't make that super awkward just because we happen to have this spare token sitting around now. Precedents exist for mondaic `&lt;-`, I'm not aware of any precedents for placement, so why not use `@=` or whatever else.
Now use `Option::map_or` to get rid of the inner match clause, as in `self.left.map_or(false, |node| node.contains(key))`.
When did that happen?
It is still needed, because you will get panics in debug mode if you don't use wrapping operations. Also, there could be some compiler flag that enables this panicking behavior in release mode. Therefore you should always try to use wrapping operations where they make sense. Relying on the defined behavior should be a last resort.
Please note rule #4, no need for language bashing, in jest or not :)
Isn't it optimised into the same thing?
No, you need to use wrapped arithmetic if you actually want the wrapped result, or else the code may "randomly" panic when it isn't meant to. E.g. in debug mode, or, if it is a library, if the user of the crate activates `debug_assertions`.
In practice, creating a walled garden has *never* worked for making a language popular. Many would-be popular languages are casualties of this attitude: Delphi, Eiffel, Ada, Lisp, ML (pre-OCaml), Smalltalk, etc. Java is the closest thing to an exception, but the JNI was highly developed before Java ever became popular, which I suggest is not a coincidence. Python, Perl, PHP, Javascript, Lua, C++, Objective-C, Scala, etc, all have a history of being readily bound to a system that was already popular.
It would be nice to hear from your perspective, what are the things currently missing in the compiler that would allow this extension to function in a non-hacky way. From what I can see so far, you need: - a way to examine the types Rust variables that will be passed to c++, after all type inference has been done, - a way to inject extra library search directories from a lint plugin, - if clang is used as a c++ compiler, it would be nice to have it generate bitcode, which could be injected along with rustc bitcode modules before LLVM optimization passes, - in order to use c++ templates (without declaring all required specializations upfront, that is), I think we'll need some form of generic extern's in the language.
No. Use the default rust syntax. Hahahahaha.....:-) 
I feel like PartialOrd should define partial_max..
I've found a better way to annoy those pesky semicolons lovers: fn fun(n: u32) -&gt; u32 { ; let x = 4 ; let y = n * x ; x + y } Not really sure if I'm just kidding... EDIT: better, faster, stronger
Rust's demographic is *much* more dependent on placement new than monads. It's not unreasonable to expect nearly every Rust user to use placement new in the near future, whereas do notation will be wanted by only a small fraction of users (most of whom should really be using Haskell/Scala instead). (And it's hardly "super awkward"; one could throw nearly any syntax at it - `bind foo = bar`, `foo =&lt;&lt; bar`, `foo := bar`, etc.)
https://doc.rust-lang.org/stable/std/ffi/struct.CStr.html#method.from_ptr has no length attribute. I am happy to use something else. This is also what I used to glue Ruby (which using nul terminated strings) to the same Rust code.
I didn't know either! My first version had fn fun(n: u32) -&gt; u32 { let x = 4 but now is much better so don't add that lint! 
Does your partial_max returns the same value as [the function](http://doc.rust-lang.org/stable/std/cmp/fn.partial_max.html) Steve linked? I mean, for every a and b, assert_eq!([a, b].iter().partial_max(), std::cmp::partial_max(a, b)); (seems like a test like this fits [quickcheck](https://github.com/BurntSushi/quickcheck))
Finally, I've been wanting a new hoodie :)
https://www.reddit.com/r/playrust ?
No it doesn't and it isn't supposed to. if `a` were for example `2.0` and `b` would be `NaN`, `std::cmp::partial_max` would return `None` because it has no way of comparing them. The `partial_max()` in this crate excludes `NaN` such that you get a total order. It would be equivalent to calling `[a].iter().max()`, you know, if `a` were `Ord`. It requires the items it iterates over to be `AlmostOrd`, meaning just what I said above for floats in a generic way. There is a total order, but only if you exclude some values. Those values would be all `NaN`-values for floats. Maybe the method should be called `.alm_ord_max()`.
&gt; Rust's demographic is much more dependent on placement new than monads. &gt; It's not unreasonable to expect nearly every Rust user to use placement new in the near future, I did not and do not argue otherwise. It's a cost/benefit thing. If there's little cost to just picking some other operator, it's probably worth it. 
This is the subreddit for the Rust programming language. The subreddit for the Rust game is /r/playrust.
Or a service integrated with it.
According to Rust twitter account, they prepared the crab stickers at Rust Camp. But is he/she not the official mascot yet? https://twitter.com/rustlang/status/627519181114609664
So it sounds like you too would like `v.push(x)` to be fixed to "just work".
[**@rustlang**](https://twitter.com/rustlang/) &gt; [2015-08-01 16:40 UTC](https://twitter.com/rustlang/status/627519181114609664) &gt; We have tons of stickers! \#rustcamp &gt;[[Attached pic]](http://pbs.twimg.com/media/CLVlXdiUwAA0BKP.jpg) [[Imgur rehost]](http://i.imgur.com/58185AX.jpg) ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://www.np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
I don't think it *can* be without introducing weird special cases into the language.
Tip: pasting the whole code into https://play.rust-lang.org/ and sharing the link is the best way to get people to try your code, and help you.
That's pretty ugly. Totally out of alignment. Here, this is much better: fn fun(n: u32) -&gt; u32 {{ ;; let x = 4 ;; let y = n * x ;; x + y }}
Hello! I'm new to Rust and audio programming in general, and I was wondering if PortAudio (and thus these crates) was suitable for "real time" audio. :) Thanks, Louis
I kinda already have the first one, but in an admittedly hacky way. (I use a lint pass to get type info). Definitely need to be able to modify the search path. Also would like to be able to get the output directory without re-parsing the command line arguments. It would be nice to do bitcode, but stable rust will never give that low level access, because it's impossible to stabilize, so I wouldn't start with that pipe dream. In addition, LLVM IR is not stable between versions, which means that I would have to build my own copy of clang with the same version as rustc - in summary it would get ugly pretty quickly :-/ Generic externs are not going to happen, so I wouldn't even worry about that. I don't think that this code should ever support templates across boundaries TBH, adds too much unnecessary complexity, especially when talking about specific cases is usually powerful enough. Unfortunately, the cpp! macro doesn't really work in generic situations, but that's not really a thing which I can see a way to fix. rust-cpp should probably detect if it is used in a generic context (as you are probably doing something wrong if it is), and warn/error out.
Something like a new calling convention, right? Yeah that is not so workable. Although it could be communicated by magic types? yes.. magic.. please?
Wrong subreddit, head to /r/playrust
Thanks, you are correct! Fixed.
Oh sweet, my blog post is linked there! That's a nice surprise.
&gt; IMO, it would be a totally reasonable thing to require having the same version of clang if one would like to use cross-language inlining. Otherwise, clang could still be used - in the native object output mode. Yes, rustc would need to consume an extra file with bitcode, but I don't see why this would be impossible to stabilize. I don't think that rustc wants to expose the fact that it uses llvm outside of compiler internals, but if they were OK with that then it could potentially work. &gt; Why not? If the scenario is compelling enough, I am sure it would be considered. The problem is that a generic extern doesn't really make sense, as you have no way of ensuring that the functions at the target of the extern are actually generated... The only way it would work is with a plugin like rust-cpp which hooks in and generates the code behind the generic ffi, which I don't think is going to become a standard feature in rustc.
Totally puts me off too.
&gt; &gt; &gt; What you want to do is use both haystack.as_bytes() and needle.as_bytes() and perform the search on bytes. Couldn't this produce spurious results by partially matching from the middle of a multi-byte char? (or does the UTF-8 encoding prevent it?)
Encoding will prevent it. The first byte in a codepoint starts with as many 1 bits as there are bytes in the codepoint (excluding itself) and then a zero. The rest of the bytes all start with '10'. This implies that the byte sequence for any codepoint is not fully contained in the byte sequence of any other. 
Yep, generic ffi doesn't make much sense without automatic codegen to instantiate these generics. On the other hand, I don't really see a practical, ergonomic way to interface with c++ templates without something like that.
Thanks for the advice! [Here is the code then](http://is.gd/3wG6iE) (also updating the original post). However the Playground is giving yet another error which doesn't appear when compiling the code locally, about being unable to `use rand;`. Am I doing something wrong? If not, do you know where this kind of bug should be reported?
Inf fits perfectly fine in the order, doesn't it? `inf == inf` is `true`. And everything but NaN is `a &lt; inf`. I think you're right about the error propagation but this should be dealt with in a crate focussing on this float-specific behaviour. Numpy's behaviour would need our generic methods to have NaN &lt; everything and NaN &gt; everything. Ideally I'd like to see NaN and normal float values be separated via enum so that this special casing becomes part of the type system like with nullable pointers.
I was wondering if it was only me feeling that way about the `WeightedChoice` api. I'll take your advice if there is really no other clean way, but I really dislike it on principle...
Got it. Too bad. Editing the code to remove the `use rand;`.
&gt; It's a cost/benefit thing. Sure; I'm saying the nice syntax should go to the thing everyone is going to use.
I've just realized why I don't agree with this objection. People complain about `fXX` types because they don't implement `Ord`, not because they contain `NaN` values. It's not a correctness issue per se; we seem to be coping with `NaN` fine. The inability to just run `max` on things, however, is a pain. And when you want to run `max` or whatever, something like values.flat_map(f64::to_option).max() is upfront enough to be self-evident. Later silent casts to `fXX` don't matter, because the intent isn't to prevent `NaN`. Yes, one can argue that `NaN` is just another `null` pointer, but in my experience it's not. `NaN` tends to cause far less harm and mostly comes about at appropriate times.
I think that wins the obscurity award. :) How would one convert to/from one of these?
There were 3 posts recently, I just wondered..
I added `into()` to the table, and checked the others have the trait. At least `to_string` is broadly available and applicable, albeit costly. You've made me want to go explore these traits and write a blog post ...
I think I'd rather have the gear on the front, and rust-lang.org text on the back-- very minimal
&gt; You've made me want to go explore these traits and write a blog post ... That would be most welcome. The `Into`/`ToOwned` family of traits were added relatively late in Rust's history, so they may not be as well known (as compared to, say, `ToString`, which has been around for a while IIRC).
Thank you for your clear explanation. :) 
This would be the best shirt.
thanks man i will be posting it there.
You are not the first one that has that concern, but that not gonna happen. The reason is simple - it has runtime cost. FIN
`String::from("Angular Master Class")` continues to be the best `str -&gt; String` conversion.
Or conversely, `"Lateral Apprentice Class".into()`, if I'm not mistaken.
Like fontsize 0?
My argument for From is that it says what is being made, and is also wrapping the literal (literal.foo() looks weird).
True, but in the given case, it should work.
I agree.
Awesome :)
 fn S(s: &amp;str) -&gt; String { String::from(s) } I don't get it. Why do you need a syntax extension for this?
What I do: impl Workshop { pub fn new(title: &amp;str, url: &amp;str, icon: &amp;str ... ) -&gt; Workshop { Workshop { title: title.to_owned(), ... } } } But, I agree that the mystery of owned strings is a big ergonomic pain. It seems having "xyz" be allocated and &amp;"xyz" be a reference makes a lot of sense. Obviously not going to change at this point, though. The "&amp;str is so unergonomic, we had to make String even worse so people wouldn't use it instead" argument hurt to read. :)
This is great! I did [something similar](http://jaredonline.svbtle.com/creating-a-php-extension-in-rust) not too long ago [=
Should it be an SVG rather than GIF? SVG supports animation natively and is a proper vector format for graphics. See: * https://developer.mozilla.org/en-US/docs/Web/SVG/SVG_animation_with_SMIL * http://www.w3.org/TR/SVG/animate.html
I'm going to rename the crate to `ord_subset` unless I'm coming up with a better name over the next days. All methods will likewise go from `partial_X`to `ord_subset_X`. I'd prefer `SubsetOrd` for the trait, but `subset_ord_sort()` sounds worse than `ord_subset_sort()` imo. I'll be happy to hand over the `almost_ord` name on crates.io if someone is interested in the future.
And also `p!(a, b, c..)` and other stuff. Rust macros are very non-intuitive: this was my first design (run [here](http://is.gd/6NiJrH)), macro_rules! p { ($($($x:expr),*);+) =&gt; { $( $( print!("{:?} ", $x); )* println!(""); )* }; } fn main() { p!(5); p!(1, "x"); p! { "a", 1; "c", "d"; }; } But I had to change it radically to include an option to use `Display` instead of `Debug`. Also, what I *really* wanted was to always print strings without quotes (always use `Display` with them). I've learned that syntax extensions can do this, but `macro_rules!` can't.
Nice! I like it. :)
I [pre-emptively licensed Ferris as CC-0 / public domain](http://www.rustacean.net/). So the sprocket-logo is still in legal limbo (&gt;:() but the rustacean in itself shouldn't be waiting on Moz legal, I would think.
The 1.0 stickers were [slightly different (they came on sheets in a few different variants)](https://twitter.com/whoisaldeka/status/568264649705005056) and I printed them of my own accord with the proceeds from the first t-shirt batch. (I then gave like half of them to brson so they could get distributed at the parties.) I was thrilled to see the new printing at RustCamp! "Officialness" is a state of mind :)
I was thinking of building a centralized rustdoc service with an alternative frontend/renderer some time ago. I wanted it to collect rustdoc's json output in a database (read: play with postgres' json type) and dynamically generate pages with crosslinks to other dependencies (with correct versions, of course). Searching would happen server-side and could (optionally) include all known items in all crates.
I'd love to have this!
String literals would already be helpful. But distinguishing between strings and other values using the type system would be awesome. Perhaps the [impl specialization RFC](https://github.com/rust-lang/rfcs/pull/1210) could help with this.
I think it's mostly the official / unofficial distinction, I think. I have my own frustrations here, but the inside info is that I think it's almost all settled.
I'm noone but +1 to both changes.
I wrote a slightly different version of this macro for my own debugging/development. It also prints the source code of the expressions being printed. macro_rules! p { ($($e:expr),+) =&gt; ({ $( println!("{} = {:?}", stringify!($e), $e); )+ }) } #[derive(Debug)] struct Point { x: i32, y: i32 } fn main() { let point = Point { x: 42, y: 100 }; p!(point.x, point.y * 2); } Prints: point.x = 42 point.y * 2 = 200
Sounds easy, doesn’t it? Sadly, CSS animations don’t work consistently across browsers (and moreover you can’t animate something inside a clip-path in Firefox which is needed to keep the R in a stable position while rotating the rest), and IE/Edge don’t support SMIL. (I have, however, constructed a SMIL version of this which works in Firefox and Chromium and a CSS version that works in Chromium but not Firefox.)
Neat! I think I will add something like a `_` prefix (using some other symbol) to steal your `println!("{} = {:?}", stringify!($e), $e);` if you don't mind :P I also wanted to have a call to `p!()` print just a newline, but with my current code this would require creating another macro (because every call that ends with , or ; end up calling `p()!`). I wish `macro_rules!` had some form of grouping productions. Like `(prod 1) | (prod 2) =&gt; { x }` expanding to `(prod 1) =&gt; { x }; (prod 2) =&gt; { x }`. And/or `(prod a?) =&gt; { x }` expanding to `(prod) =&gt; { x }; (prod a) =&gt; { x }`
Better call that (and the OP's version) `debug!` or something more, *more*, than just `p!`. Your call ;)
Interesting. I always thought programs used the default loading icon because of ~~laziness~~ pragmatism.
Well, I think his version is generally more useful. So I decided to just do what he does (`p!(x)` do the same as `println!("x = {:?}", x)`). The old behavior works when starting with a colon, like `p!(:x)`.
The longer name is also nicer for quick find.
for #1 http://doc.rust-lang.org/arena/struct.TypedArena.html and http://doc.rust-lang.org/arena/struct.Arena.html For #2 do you want channels? http://doc.rust-lang.org/std/sync/mpsc/fn.channel.html - even though this is mpsc, it has an optimized case for spsc in the implementation.
Thanks for the links. I am mainly interested in value types that don't require any destruction. All I'd need the arena to do is to reset its pointer on the free call. I definitely need multiple types support. I'll look at TypedArena and Arena to see if I can get enough to make one of my own. As far as I can understand the Channels (mpsc or spsc) interface doesn't allow constructing structs in place on the ring buffer. It also doesn't seem to be based on a ring buffer, given the infinite buffer description. The use case seems to be creating some object (again mostly on the heap AFAIK) then passing ownership to the consumer via the channel. This would imply a heap allocation or copying for stack allocated objects. Instead I'd want something where I can say give me 5 MB of contiguous space on the ring buffer. The ring buffer would then block till 5 MB (plus framing for message type etc) was available and finally give me that space. I could then decode a JPEG image directly on that 5 MB space for example, and pass it onto another thread.
About the Copy type - thanks that makes sense. I'll attempt to build what I mentioned as a ring buffer + framing protocol in https://www.reddit.com/r/rust/comments/3fz113/common_c_allocation_patterns_in_rust/cttbmnw My rust is so weak that I need to stumble and fall a few times before I can collaborate on any level :( Currently all my Rust == Unsafe { write C }
Ok, but then you don't support the "streaming data" case I was talking about (producer writing chunks of 256 samples and consumer reading chunks of 320 samples). :( That's the case I would be interested in for audio or SDR processing. Of course, with a fixed chunk size we can compute the least common multiple to avoid non-contigous chunks in the circular buffer. But I don't know if I want to restrict myself to a fixed chunk size and this could also make the buffer rather big. The channel you want is doable in Rust and it shouldn't be that difficult.
Each message itself is a fixed chunk, but the messages themselves can be of different chunks. I am not sure I understand how it is different from passing pointers to vectors that you mentioned before. The producer can send message 1 with 42 bytes and then message 2 with 49 bytes. It doesn't need to fit into any compile time known chunk sizes. As long as the length is part of the message, the consumer knows enough to read the data as it wishes. EDIT: I think you mentioned that with vectors too the consumer can't read other chunk sizes without having a warapper over two vectors. My solution would be similar in that case minus the actual vector allocs/frees. AFAIK the most elegant solution to something for your use case is the mmapped ring buffer presented here - https://fgiesen.wordpress.com/2012/07/21/the-magic-ring-buffer/
/u/going_up_stream, before you print this: I plan on updating this page just after the 1.2 release (i.e. tonight or tomorrow). 
Hi Steve, you are right about storing the data somewhere outside of the program. This particular piece of code will actually be fetched from a server later. It's currently just there for mocking purpose. But even then I'd love to have an easier syntax. I didn't know Rust had this in the past. I do understand this would make it easier to over allocate but on the other hand there are plenty of things one can do wrong regarding memory/performance (e.g. using Vecs for lookups instead of HashSets). I'm not sold that a less convenient syntax is the right way to protect against that ;)
Well shortening the function name leaves you still with `S("some string")` which is still three extra characters. 
damn it, im already 2/3 done printing. would it be possible to get a "diff" Pdf which just has the changed parts? or are there changes all over it?
Diffs for that amount of text are hard. It shouldn't be too much stuff that changed, though. Aside from some typos here and there, Steve wrote some PRs with new content yesterday. Have a look at these: - [Add opaque structs to TRPL:FFI](https://github.com/rust-lang/rust/pull/27542/files?short_path=165971d#diff-165971d22f27d83f92bfe270d3e0fc77) - [Expand further on &lt;&gt; syntax in TRPL.](https://github.com/rust-lang/rust/pull/27538/files?short_path=e645ffd#diff-e645ffd715d6646d4837aad4a580e5d6) - [Add more infor about function pointers to TRPL](https://github.com/rust-lang/rust/pull/27539/files?short_path=26f91a5#diff-26f91a5e47b08b0c1b1bcdf611de0080) - [Add object safety to TRPL](https://github.com/rust-lang/rust/pull/27536/files?short_path=904e416#diff-904e4165c1d725fea854335e33b3065c) (Some are not even merged yet!)
Can't they be automated?
That is strange. I always saw it as a static r, but for completion: http://i.imgur.com/BTAra6G.gif (I also updated the repo)
You can generate a diff for the markdown source, but for PDFs it'd be a very different story. If you have some good ideas about that, please share!
The magic ring buffer is really neat, thanks a lot for sharing this!
How are you replicating the book? Is there a program you are you coping and pasting into libreoffice then formatting?
You can use [tempdir](https://crates.io/crates/tempdir) to create a temporary directory for the test. It will be removed automatically when it fall out of scope.
Slightly stronger. Not only are they not a prefix of each other, they are not a _substring_. A vaild Hufmann encoding would allow 'AABC' and 'AB' as codepoints. UTF-8 also prevents cases like this. The way it's done is really relatively simple. Imagine you've got some binary representation of a number 'xxx ... x', then the n-byte encoding, (based on the no. of x-s) is: * 1-byte: 0xxxxxxx (ASCII compatibility for 0...127 FTW) * 2-byte: 110xxxxx 10xxxxxx * 3-byte: 1110xxxx 10xxxxxx 10xxxxxx * 4-byte: 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx * etc. Note that starting bytes never look like continuation bytes (the former never start with '10', the latter **always** start with '10'). So: * The first byte in a codepoint will only ever match the _first_ byte of another codepoint. * Any two codepoints whose first byte matches have the same length. These two things explain why doing string searching on bytes will work. You're essentially scanning the haystack for the starting byte of the needle; as established, you'll only ever get a match at the _beginning_ of a codepoint. Once you find one, you know the codepoint that follows has the same length as the one in the needle, so you won't accidentally match a prefix. Once a full codepoint matches, grabbing the next byte from both haystack and needle will give _starting_ bytes for new codepoints in both of them. Rinse and repeat.
Giving different names quickly hits a complexity wall if you have functions with lots of knobs that have good defaults but can be changed independently. For 'n' such arguments you get 2^n possibilities in that you either specify an argument or don't. Combine this with named arguments and they still show intent.
&gt; how is memory freed in the Area? It's freed all at once if you drop the arena.
You can avoid running by marking with `no_run`, they'll still be built.
Yes, there are situations when my advice simply doesn't cut. An other idea is to use a settings struct where the arguments are fields. This is essentially the same as named arguments with default values, but without any special syntax, and allows some nice things like using the `Default` trait (or any other construction method, to be honest): let settings = FooSettings { a: Some(a), b: 42, ..FooSettings::default() } foo(settings); Builder patterns (`foo().with_a(a).with_b(42)`) are also an alternative. There are ways around the problems, but they are not always as nice as one would wish.
1. It is memory safe language that has no runtime so it is great as FFI lang for high level languages (like Ruby/Python) 2. Has a lot nice features that helps you with programming in other languages 3. It doesn't hurt 4. You will never know when knowledge from Rust (like ownership) will helps you with "that weird one heisenbug". 4. We are great and open community, it is fun to be one of Us!
For low level programming, the main alternative is C. Programs written in C are commonly vulnerable to exploits due to the prevalence of unsafe memory access. Rust ensures safe memory access by default, and the type system that ensures this can be used to ensure the absence of many other bugs as well. On top of that, Rust has a number of modern features that are absent in C, such as sum types, closures, type classes, and so on.
From The Pragmatic Programmer, Tip #8 "Invest Regularly in Your Knowledge Portfolio": &gt; Learn at least one new language every year. Different languages solve the same problems in different ways. By learning several different approaches, you can help broaden your thinking and avoid getting stuck in a rut. Rust makes different tradeoffs than other languages-- for example, I come from primarily using Ruby and I'm enjoying the brain-stretch I get from Rust's static typing, ownership, and lifetimes. It's also teaching me about lower-level systems programming, which will enable me to write faster code than Ruby does, and its safety means I'm not terrified like writing C makes me :)
In the standard library, we often use try! And wrap the examples in a function, which is never called. I think tempdir is probably better though.
Great explanation! Thank you, and you're right, it is pretty straightforward, but brilliant.
Move semantics by default will probably force you to look at your code differently, even when programming in another language.
You could try making some simple games, if you like games. http://jadpole.github.io/arcaders/arcaders-1-1/ You could have a lot of fun building a nicely visualized game of life. 
To me it boils down to the C-like low level with Traits and a modern, well designed, fairly cross-compatible std lib, and awesome community. Of course that came with fighting the borrow checker in the beginning (which is much easier now) which is sort of keeps memory and concurrency safe, but those were secondary factors to me.
I do two projects whenever I want to learn a programming language. The first (and easier) is to implement a [Sieve of Eratosthenes](https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes) that counts the number of primes up to some limit, and gives back what the largest prime is. You can also keep track of all of the primes while doing this, and report back a list to test against. Then, you can profile the code using the benchmarking facilities (or make your own). As a part 2, write the odds-only and 2357wheel versions (you can look them up on rosetta code for hints). I wrote my own implementation [here](https://github.com/cedelmaier/primeSieveProjects/tree/master/rust_primes). So here are the project requirements. * Count the number of primes up to limit N * Find the largest prime up to limit N * Find the list of primes up to limit N * Pass in N as a command line argument * Write an eratosthenes(limit N) function in a library * Profile code for speed * Write odds-only version * Write 2357wheel This gives a pretty solid foundation in the language, using command line parsing, function calls, external library calls, algorithm development, and benchmarking. Also, as people have suggested, making a Conway's Game of Life game would also be a good introduction. I'd also check out /r/dailyprogrammer for ideas. 
Rust really shines at big programs more than scripts and request-to-database-query servers.
SMIL is [deprecated in Chrome 45+](http://blog.chromium.org/2015/07/chrome-45-beta-new-es2015-features.html).
That's unfortunate, alternatives don't seem to be much better.
I'll just say why I started learning Rust. I had an idea for a project. Since I was worried about efficiency, I started writing it in C. It was going along quite nicely, but seeing the amount of mallocs and frees in my code, I could already picture the memory leaks I would be fighting in the future. Then I heard about a new language reaching version 1.0, one that addresses exactly the weaknesses of C while keeping similar performance. I started reading more and developed the impression that it is exactly what I'm looking for. So now I'm rewriting the project in Rust. I'm still getting used to it, a lot of nice features are still considered unstable and many libraries don't have wrappers yet, which forces me to create my own, so it's progressing slowly, but I still feel that Rust is what I was looking for. I'd say, just read [the book](http://doc.rust-lang.org/stable/book/) (it's not that long) and see for yourself if it looks like it could solve some of your problems ;)
Implement multithreading in https://github.com/birkenfeld/rick :)
I don't know whether or not I can consider myself experienced, as I only have one year of professional experience hacking a large Ruby on Rails project, and some tinkering with various unfinished projects (including one with Rust). But here's my humble 'beginner' backstory: I'm writing Ruby/AngularJS code on a daily basis, and wanted to learn a new langage for some time now, for having fun and discovering new things/concepts, as I'm mostly doing repetitive tasks at work currently. I took a look at Haskell first, but it didn't appeal to me. I discovered Rust then and fell in love with it. Memory safety is surely something that attracted me, as much as learning new concepts and improving myself as a general purpose developer, but I also used to love C++ and kind of felt I could hack some bits without having to endure the worst parts of it.
&gt; The balance between these numbers will determine Rust's fate. If all goes well I will expect the defense industry to standardize on Rust along side Ada and Java. If that happens the future of Rust will be great indeed. Personally, this is my hope and this is why I am investing time in learning Rust. I hope Rust's primary benefits will not be improving ways to kill and terrorize people. I'm hoping for increased security in computing all around. Crypto libs in pure Rust would be particularly nice.
i didn't know of /r/dailyprogrammer , thank you that's a great subreddit. Also thanks for the ideas
On the other hand, Ruby has `p` and it isn't too confusing. (also, an option is just to remove the calls to `p`when you're done debugging, but I'm not sure how feasible is this)
In regards to your first attempt, what does it mean by "unresolved name `b` "?
Yes; every language has runtime. Rust has only about as much runtime as C. C++ had (still has?) the whole horrible iostream executable bloat, D has full blown garbage collection which is optional but hard to avoid, Java has the JVM, etc. Rust is small. Rust is modern. Rust does good work at compile time so the runtime can be small.
I've been wondering the same. Here's what I think, in the hope that a signal expert would come and correct me: You should be able to avoid undefined behaviour by having your signal handler just invoking a closure with `Send + Sync + 'static` bounds. In theory. In practice, this does not solve all problems - e g, just taking a mutex might deadlock your program. (In this case, `thread.unpark` actually takes a lock. Not sure if it actually has to, but that's the current implementation at least.) Also, anything using TLS might be problematic (and potentially even unsafe?). Not sure. However, if you're just interested in sending the signal to a thread, there is [already a crate that does just that](https://crates.io/crates/chan-signal). Which is probably your safest route anyhow.
Rust covers much of the same skills as Standard ML (or Objective Caml.) It is a functional programming language in C's clothes. It is very good for writing memory-safe programs with minimal footprints. It comes with a mind-blowing new concept (borrowing &amp; lifetimes) which will make you a better programmer (see: every lisp ever, every strongly type functional programming language ever, and believe it or not, Java)
In that case there is only one language that has no runtime (unless you link to libc) - ASM. Any other language will have some runtime, no matter what you do. But Rust (as /u/mhd-hbd said) Rust has minimal runtime, almost as small as C, so in "common terms" we can say that there is no runtime.
What kinds of programs are you writing, or planning to write, in Rust?
This seems interesting, but I couldn't easily find a link to the docs you mentioned. Maybe you could add one to make it more approachable.
I just heard about a beta PragProg book called [Exercises for Programmers: 57 Challenges to Develop Your Coding Skills](https://pragprog.com/book/bhwb/exercises-for-programmers); I haven't read it yet, but it sounds along the lines of what you're looking for.
Sorry, I tend to rely on those little banners at the top of the readme for all the relevant links. Added one for context in the text itself.
Games. I tend to start a new project every once in a while without finishing the previous one though. Right now I'm working on [this](https://github.com/mbuffa/hellorust/tree/piston).
I don't really understand your question, a statically sized array is written like `[T; N]` in Rust, where `T` is some type and `N` is the number of elements. E.g. `let arr: [f64, 4] = [1.0, 2.0, 3.0, 4.0];` (or simply `let arr = [1.0f64, 2.0, 3.0, 4.0];` in this case and let the type inference sort it out). AFAIK C does not allow returning an array from a function, but you can create a struct with `#[repr(C)]` that should be compatible with C, e.g. #[repr(C)] struct Foo { bar: [f64; 4] } which should be compatible with a type in C that looks like this: struct Foo { double bar[4]; }; I'm not sure if C actually defines `double` to be 64 bits, but I suspect it will be on any machine that the Rust compiler supports so it's not important.
A crate name should *never* have a “rust” or “rs” prefix or suffix. Never ever.
This is the praise the UTF-8 encoding deserves!
I'd say write your REST API server in Elixir (it's also on the BEAM, like Erlang). The Phoenix web server is going to be v1.0.0 soon. I tested it back in v0.6, and it was solid then, so it should still be solid. For your message queue, I'm not sure which language is better. If you like Go, it would probably be a good choice here. I feel like Erlang/Elixir would be equivalent in speed and CPU usage as Python. Rust could do it, but it'd extoll a cost in programmer time that is probably disproportionate to the gain in computer time.
yet there already are a lot of these crates and naming conventions like "-sys" are only emerging. A "how should I name my crate" guideline would be nice to.
Thanks. The gap in my knowledge was #[repr(C)] prompt. It does exactly what I need.
&gt; I suppose if rust can make sending data down a channel safe then we should be able to implement "nice" rust signal handlers, otherwise they are unsafe as hell. Indeed. That's why I wrote [`chan-signal`](https://github.com/BurntSushi/chan-signal). Instead of async signal handlers, it blocks signals and [does a `sigwait` in a separate thread, then does a non-blocking send on the subscribed channel](https://github.com/BurntSushi/chan-signal/blob/master/src/lib.rs#L203-L213). You've gotta make sure to set up your subscriptions before launching any threads though...
Oh I have a passion for programming. But balancing a full time job with standby, a wife's nursing schedule, physical recreation and children, there's not much room left for programming for fun. So I don't think that's very fair.
I have the same issue as OP, and would love a solution. Your suggestion doesn't quite work because there is no main function; these are unit tests. If you put `env_logger::init().unwrap();` at the top of each test, it panics, presumably because env_logger is initialized multiple times. If you remove unwrap(), it doesn't panic, but it still seems klunky to require this at the top of every test function.
Awesome! Good compiler. :)
Similar on the return. A return val larger than a register gets returned by created an implicit argument that takes a pointer to the destination to write the value. Most commonly, this will be a location in the stack frame of the caller, so pretty efficient. I'm unsure how well the forwarding works when you have multiple layers, but LLVM can be pretty magical.
The ABI is very much unspecified and unstable at the moment and I believe is tweaked somewhat regularly.
But in a contest of which language has the *coolest* runtime, the award goes to FORTH. That is some pointer-wizardry calling convention right there; not to mention it scales seamlessly into basically an entire operating system.
Is it possible to add some of those to traits? This doesn't affect the usage (unless some corner case forces the use of UFCS) but it allows the use of generic code. However, as a downside, it makes type errors messages more confusing.
In current Rust, you can't be generic in `T` in [this way](http://is.gd/MMikGz) (the linked code compiles; but if you remove the commented out code it doesn't). That is, if `T&lt;A&gt;` is a type, you would need HKT to be generic in `T`. So, once Rust finds out `T` is a type parameter, it says: error: type parameters are not allowed on this type (dunno about the `StreamingIterator` thing)
There's a bug between my browser settings and playpen which removes a lot of characters from non-gist playpens, so correct me if I've misread it, but you're saying the issue is that you can't have type parameters like `T&lt;K, V&gt;`? I don't see why you need `T` to be parameterized by `K` and `V` if you know that it implements `Get&lt;K, V&gt;`. [This seems to work fine.](https://gist.github.com/6a160911b3daa901a1b4) In fact, some maps (such as `VecMap`) are not parameterized by their key, but would still have an impl of (e.g.) `Get&lt;usize, V&gt;` despite not being a `T&lt;usize, V&gt;`. Is there something I'm missing?
https://github.com/rust-lang/rfcs/issues/600
Yup, it's a very common way that our industry has bias against certain groups of people.
How exactly is it broken?
RTTI and Exception handling. The rest it shares with C. Stack initialization, and, on many platforms, support for thread local storage. (errno isn't per-thread by design, but by runtime "fix-up", since it existed before threads did in Unix).
Sadly enough, a struct composed of 3 32bit floats will still be passed as a pointer. I believe it would be more efficient to pass it by value in one of the xmm registers? https://play.rust-lang.org/?gist=ac59b771ad9b44a88570&amp;version=nightly
Cool! You *can* accomplish this without the helper using a [general higher-kinded type pattern][pattern]. However, it's messier, and you need to add constraints for each type you want to instantiate it on instead of just the end points. [pattern]: https://play.rust-lang.org/?gist=cffcd29ee7c167197254&amp;version=stable 
One of the things I wrote to start with was an in-place quicksort. I took the [second (in-place) pseudo code from here](http://rosettacode.org/wiki/Sorting_algorithms/Quicksort), then implemented [a version for vectors of i32](http://is.gd/8dP5w9). That was relatively straightforward, [slices](http://rustbyexample.com/primitives/array.html) are great. Then I [generalised it for PartialOrds](http://is.gd/s4sx4O). Turned out the copy trait being on the i32 had made it all much easier than the generalised version which I wouldn't have been able to do without the kind help of the folks on Rust IRC. It's of course a much smaller project than other suggestions on here but then that might be a benefit if you're new to this (like me).
I posted this on [forum.rustplatz.de](http://forum.rustplatz.de/t/rust-uebung-quicksort-fuer-i32-vecs-und-dann-partialord-vecs/22) initially and just noticed the (very few) comments are in German. I think you'll be alright though.
Well, this is a small semantic nit, but every Rust compiler supports cross-compiling to every platform Rust supports. You may need to get a copy of the standard library cross-compiled for the target platform first, which is what you're actually looking at, but that's a property of the distribution, not the compiler itself.
With latest Go release, it is completely free of C code [&lt;link&gt;](https://golang.org/doc/go1.4#impl). Even though it is mentioned rust compiler is written in rust [&lt;link&gt;](https://github.com/rust-lang/rust#notes), Still g++/clang is a dependency [&lt;link&gt;](https://github.com/rust-lang/rust#building-from-source). Why is it so? Any plans to remove?
Yeah, why bother writing your own backend when you can instead have the richest company in the world paying to improve something for you. That said, I _do_ think such a project would be good. Diversity of implementations is really important for health, another Rust implementation would help with people having "trusting trust" attack concerns, clarify language semantics....
That's a nice question. I currently understand that it's 16%, 62%, 32% and 35% faster, respectively.
It'd be pretty cool if the ABI was documented somewhere, even if it's not stable.
I find it easier to just make the extern block to use the native rust data types. I.E.: extern { fn make_struct( f0 :f32, f1 :f32, f2 :f32, f3 :f32) -&gt;strc; } Means I don't constantly have to dip into more verbose libc::c_int and libc::c_double (while I guess this creates platform problems I'm ignoring them) (yes I'm aware libc::c_double isn't f32 but f64 generally). 
Once you document things, people come to rely on them. And documentation of unstable things is by its very nature, not likely to stay up to date.
Thanks! Reading your code, I just realized I can actually make the domain of the Coyoneda existential by using the same HKT-trait trick, so that the signature for the function becomes just: fn add_and_to_string&lt;T&gt;(y: Coyoneda&lt;T, i32&gt;) -&gt; Coyoneda&lt;T, String&gt; I updated the docs already, take a look if you're interested.
That's exactly what it means, though. "two times faster" = "three times as fast".
Now that I think of it, what if you only use `libcore` (i e, no std), and the signal safe libc functions, would you be safe and sound? Libcore cannot allocate, nor call any dangerous libc functions. 
I'm aware that it used to have segmented stacks back in the bad old days of libgreen. The reason it can't transition to contiguous growable stacks however (not that it would necessarily be a good idea) is the lack of a precise GC. Go reassigns all pointers when it grows a stack.
It would likely just be a codegen and not a complete implementation so it wouldn't really help with that. But I agree that a Rust-only toolchain would be great. It works very well for both Ocaml and Haskell, performance-wise.
https://en.wikipedia.org/wiki/Speedup
Consider 1x = 100%. 100% faster would mean... As opposed to 100% as fast.
Every time speed-ups/performance comparisons are listed on the internet, there's always confusion one way or the other about what exactly the numbers mean. It's always kinda vague with some people understanding one thing, and others understanding others... in fact, people interpret it so inconsistently that it doesn't really make sense to give set-in-stone prescriptive definitions (whether or not one is technically correct or not). In this case, I believe the intention is the numbers are the ratio `old/new`, i.e. if a compile of hyper previously took 10s, it now takes 8.6.
You did show some Haskell signatures; wouldn't it be better to show Rust signatures? (ps: I'm not actually seeing a fmap implementation for Coyoneda [on the sources](https://srijs.github.io/rust-coyoneda/src/coyoneda/lib.rs.html))
Why do you omit the "x" suffix? `1 = 100%`, but "1x" is not the same as "100%". Even if it was, English is unsuitable for equational reasoning anyway, so your argument is invalid.
If you're counting dependencies, sure.
Isn't '2x' just short term for '2 times'?
Why can't they just give actual data, meaning for example how many seconds each is?
It is. That's why you can't replace it with 200%. Because of the "times" part.
Thanks! I never saw that function within the API initially. Rust's API is great but its a bit overwhelming with the functions overlayed with a crap ton of code snippets lol
Aside from hiding the unhelpful information with the `[-]` button, once you get used to the conventions you can guess what the name of the function is. `into_` functions do destructive conversions into owned types, `as_` functions do non-destructive conversions into views. If you do ctrl-f with either "as_" or "bytes", you'll find `as_bytes` pretty quickly.
You can use an [enum](https://doc.rust-lang.org/book/enums.html) for this: struct HintCell { // fields go here } struct InputCell { // fields go here } enum Cell { HintCell (HintCell), InputCell (InputCell) } This is what's called an algebraic type.
I end up using a 2D-grid in a lot of situations, and this roughly tends to be how I implement it in just about every language since it's intuitive and easy to understand. With that being the case, could you explain why you think this is bad and offer an alternative? (And yes, I guess this would be more properly considered polymorphism. Sorry about that.)
It isn't bad. It works. However it feels a bit to *dynamic* for its use case (or at least I suppose so, I don't know Kakuro). If the grid is not dynamically sized using a single array of size n * n it's a better use of resources (less allocations, possibly the whole structure can be stack allocated, and more cache friendliness). That's may not be your primary concern but is a strength of rust that can be useful to learn.
The width and height of the grid varies (it typically does when I use this type of implementation). I usually have the width and height set by the user in the constructor, properly size the vector then, and since the user doesn't ever access the vector directly, everything should be fine assuming the implementation does its job correctly.
Do you have a link to the RFC issue? (also, the "someone" in there was actually you! I'm dlight on #rust). Are all proposals regarding the allocator API listed in [this issue](https://github.com/rust-lang/rfcs/issues/538)? It would be good to ensure that proposals are actually compatible with this kind of "trick" to avoid reallocating buffers.
If you're in a non-IT career, I agree and sympathise. But if you're in tech, particularly in software, then it's simply part of your job to learn new approaches to doing things, whether new languages or other tools. If your employer doesn't let you do that, that may be a sign that they don't take your career seriously.
The corollary to that though would be in improving ways to save people's lives.
`b` actually is a compile time constant in this code (you have hard-coded its value). Why would you not just use a real compile time constant instead of implementing a trait on two zero-size enums? I took it from the OP that the value of `b` has to be dynamic, and it seems to me like the performance killer is a huge number of redundant conditionals (since there seem to be many `a`s per `b`).
I just liked to note that `#[inline(always)]` is a bit of an anti-pattern. It forces inlining to happen as early as possible forcing LLVM to optimize the same code over and over through the whole pipeline. Seriously hurts compile times. And honestly, llvm was going to inline that function away anyway. Let it do it the way it wants unless you see it doing something obviously wrong.
Because it's impossible to parameterise a function based on a constant in Rust? **Edit**: I thought it was pretty clear that `b` was a compile-time constant. Otherwise, the bit about a templated C++ function makes no sense.
I'll make you a deal: gimme associated `const fn`s, and I'll stop abusing `#[inline(always)]` like a safety blanket. :P
What does parameterizing the function get you compared to passing the constant as an argument?
I was not under the impression that LLVM could partially specialise a function based on its arguments unless it inlines the whole thing. This creates two different functions that are independently optimised for different shift values. To put it another way: since the primary complaint was about performance, and I *know* this formulation *does* trivially inline, it has a better chance of being what the OP wanted.
I hope LLVM inlines the whole function, since its only about a half dozen instructions, but I don't know anything about massaging LLVM. To be honest, I don't think the clarity/concision trade off favors doing this to avoid writing a different function for each constant.
The pattern abstract class X; class X1 : X; class X2 : X; ... GenericAdd&lt;X&gt; x; x.add(new X1); x.add(new X2); ... is in fact a poor man's (read: Java programmer's) way of implementing sum types, aka. tagged unions. Read the Rust spec's description of [enumeration types](http://doc.rust-lang.org/reference.html#enumerations) for more info.
I considered the Rust signatures multiple times, and every time I wrote them out, it just seemed like so much visual clutter that I wasn't sure it would be helpful in getting the point across. Do you feel you would understand it better if you saw the Rust signatures directly? As for the `fmap`, yes, my fault. I didn't make the Functor trait generic enough at first to be able to implement it for Coyoneda. I changed that now, though.
And many crates implement this. What's the canonical crate to recommend for a 2d array like this?
Which `#[feature( )]` flag do I need to use in my comment to make it work? :/
Mathematically, a functor F from **C** to **D** is something that assigns to every object A in **C** an object F(A) in **D**, and to every morphism (mostly a fancy word for function) f : A -&gt; B a morphism F(f): F(A) -&gt; F(B) (and there are some axioms about composability of this all). A concrete type is not a functor, a functor (in programming) maps types to types and functions to functions. The function that maps f to F(f) is called `fmap` in Haskell. So for instance, `Box&lt;&gt;` (note the missing generic) is a functor, in the sense that it maps a type `A` to `Box&lt;A&gt;`, and we can define `fmap` that maps a function `A -&gt; B` to a function `Box&lt;A&gt; -&gt; Box&lt;B&gt;`. And `[]` is a functor that maps the type `A` to `[A]` and a function `A -&gt; B` to a function `[A] -&gt; [B]`. To compose `fmap`s you just need compatible function signatures of `fmap`.
There is actually a link at the end of the paragraph.
That's likely due to the fact that the file/folder structure and the module system is tied together, so you can't just reorganize files without updating a ton of references. 
Use enums or traits.
Showing rust signatures would definitely help me.
You can, of course, `write(2, "\nSegmentation Fault\n", strlen("\nSegmentation Fault\n"))`. You can read/write to a heap buffer, as long as you use appropriate lock-free synchronization (which technically isn't supported by POSIX, but is still available on most platforms). You can also fork and exec an helper process and communicate with it over a pipe. 
&gt; My naive function has poor performance, however. Can I see evidence of this? I'm struggling to see how this would fail to inline. Are you sure you compiled with optimizations?
In some cases it can certainly feel like Python with curly braces. There are certainly some Python influences here and there. Yes, Rust does have first-class functions, but is not really advertising itself as _functional_ language. At the core Rust has its own rules, however they allow programs that feel functional, imperative, or even object-oriented. As far as the docs go, they are great: if you really want to get a feel of the language quickly, check out this page: http://rustbyexample.com/index.html
This would be great!
The basic idea is that you say `become` instead of `return`, and then it's a tail call. It will always be an opt-in kind of thing.
If you're creating the vector on the fly in get_bytes, you'll have to return a Vec&lt;u8&gt;, not a &amp;[u8]. Returning a slice implies that you're borrowing memory from one of the function's parameters, but since you're not, the caller must own the vector.
Changing the return type and removing the as\_slice call fixed it, thanks. That error message was _really_ unclear, and I didn't know that about returning slices. Thanks again for your help.
Lately I only ever write Rust or Python. 
Do you have C++ experience? It's equivalent to char* get_bytes() { std::vector&lt;char&gt; res; return &amp;res[0]; } or C: char* get_bytes() { char* res = malloc(BUF_SIZE); free(res); return res; } A slice is just[^*](/read_the_title_text "It's actually a pointer+length pair, but close enough") a pointer. You can't return a pointer to a local variable, since local variables stop existing when the function ends.
That's really something I've been missing when doing state machines, since there's no goto. Right now you have to use trampolines which feels awkward.
For me, "0.5x faster" is two times slower. Anyway, you may have a point that even saying "multiplication" doesn't guarantee people will take that literally. Some will still have "+" in mind.
Sounds a lot like D.
In the words of [Rust for functional programmers](http://science.raphael.poss.name/rust-for-functional-programmers.html): &gt; Although no current Rust manual dares putting it so bluntly, Rust is a functional language, inspired from recent advances in programming language design.
I always just write the indexing math myself.
Unless your encrypted text is valid utf8 (it probably isn't), you shouldn't be working with strings anyways. Where does the string come from?
Couldn't you use a static array via associated constants? Or does the language not support using them as array sizes yet?
&gt; Always operate on raw bytes, never on encoded strings. Only use hex and base64 for pretty-printing. Just take a byte slice (`&amp;[u8]`) and return a byte vector `Vec&lt;u8&gt;`. You can create a literal byte slice like so: `b"literal byte slice"`.
That's the job of the RFC with the actual proposed design. It's not clear to me what the details should be.
Maybe you could, instead of making `S2` contain an `S1`, have an `Into`/`From` implementation making an `S1` from an `S2` easily?
The whole point of `become` is to run destructors on the live variables (which are not passed into the call) *before* the call, unlike the existing semantics, which is to run them *after* the final expression in the block. This is what /u/jessypl was referring to by "RAII", I believe. GC-only languages get away with guaranteed TCO almost trivially, at least those without deterministic destructors, as reodering the cleanup of the variables is not observable (if there's any code needed to run at all, GC "drops" can be noops).
You specified both `xs` and `ys` as type `T`, so they must both be of the same type. If they can be of different types, you have to introduce two different type parameters.
One of the obvious problems with adding guaranteed TCO is that you have to add `NoDrop` traits on everything polymorphic to avoid a situation where tail call optimization depends on [whether or not a type parameter has a destructor](https://play.rust-lang.org/?gist=27d9638840cff8125083&amp;version=stable).
Do you *need* to store an instance of S1 in S2? You can instead add methods to S2 which construct an S1 as needed - the borrow will only last as long as the S1 is kept around.
Dealing with Rust iterators sometimes feel like functional programming (eg. maps and folds are there). The best part is that a lot of iterator code avoids allocating intermediate structures (you allocate just when you call `.collect`), which is awesome for performance. Under the hood, an iterator is something that lets you keep calling `.next()` to access further elements, as seen in [this presentation](https://www.reddit.com/r/rust/comments/3fffw0/cant_be_at_rustcamp_here_are_ugankros_slides/). And obviously we have first class functions, closures, etc, so [`x.map(|&amp;y| 2 * y)`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.map) is idiomatic Rust (in there, `x` is an iterator, and it returns an iterator too). Regarding functional idioms, whenever you can get away with a simple functional expression go ahead with it. Another example, the code example [here](https://doc.rust-lang.org/std/result/enum.Result.html#method.map_err) is idiomatic (by the way: for more complex error handling, implementing [`From`](http://blog.burntsushi.net/rust-error-handling/#the-from-trait) to map from a library error type to your own error type is usually better, because it works out of box with `try!`). But Rust is fundamentally a multi-paradigm language, and functional code is almost always a minor part of your program. You're more likely to care about whether, say, you code allocates memory than whether it is referentially transparent. For example: when you receive a borrowed reference (a `&amp;Something`), it usually means that this something is immutable - that is, you can't call mutable methods and so on; you would need a mutable reference (a `&amp;mut Something`). Well... except if `Something` has [interior mutability](https://doc.rust-lang.org/std/cell/). In Haskell, it would be a dangerous hack to allow something like this, but interior mutability is *idiomatic* in Rust and needed for things like reference-counted pointers to work. PS: a long time ago Rust used to have a `pure` keyword, but it was removed (as discussed [on /r/programming](https://www.reddit.com/r/programming/comments/1t8y6g/why_rust_ditched_pure_functions/) and [on HN](https://news.ycombinator.com/item?id=6940624); and earlier, [on this Github issue](https://github.com/rust-lang/rust/issues/2753)).
Another way of making it less wordy is to use trait references instead of generics. You take some runtime penalties, though. fn draw_plot&lt;K: Datatype&gt;(xs: &amp;mut Iterator&lt;Item=K&gt;, ys: &amp;mut Iterator&lt;Item=K&gt;, name: &amp;str);
The trouble is that Rust enums are closed. You can't add a new variant in a separate code. But trait objects seems to fulfill the "abstract" part - that is, `X` is a trait, `X1` and `X2` implements it. Of course, this requires dynamic dispatch; but it allows overloaded `.add` (one can implement it for `X1` and `X2` as separate methods, instead of pattern matching over all variants at once)
Rust is extremely different from Python. Besides static typing and memory management, the struct and trait system (including sum types) is very different from Python's class-based system. There are also differences in reflection (which I wish Rust had, but I understand the drawbacks), access control, and a million other smaller things. To me, it feels more like a Haskell/C hybrid.
&gt; In Haskell, it would be a dangerous hack to allow something like this Not really. Rust's `Cell` is pretty similar to Haskell's `IORef`, and so are the two communities' attitudes: "use it if you need to". I think purity would have been a good fit for Rust, though not [in a way](https://www.reddit.com/r/rust/comments/30n9k4/algebraic_side_effects/cpwhbm3) anyone else was contemplating (so, not `pure fn`). Essentially `&amp;Fn` could've been pure modulo its inputs (e.g. if it gets an `&amp;mut bool`, it gets to mutate that `bool` but not anything else).
&gt; Haskell additionally lets you express ones in which it can't. That's what I mean: Haskell can talk about referentially transparent operations (modulo `unsafePerformIO`), and Rust actually can't.
Because it's a huge performance issue when you THINK it's going to do a tail call, but the compiler doesn't agree because you wrote it wrong. It should really not even compile if your intention was to do a tail call, but you wrote your function in a way that it doesn't.
I think I might be a little bit off. I read your question as "I need a struct where a member is a pointer to another memeber." It's a little late here, but that's what I thought you needed, and that's what owning ref does. It's also possible that I'm wrong because of some detail, I haven't used owning-ref yet, I just know that's the high-level view of what it does.
This is a distilled example, the real code is more complex - S1 contains more than a reference to a piece of memory. (And if I were to store everything that S1 contains directly in S2 instead, then the API of S1 will be quite ugly.) Also, constructing an S1 initializes the memory in a certain way. And then you can later call methods on S1 which depends on that memory being initialized, so if you would be able to call those methods without S1 initializing it first, then you could potentially break S1.
I think the problem is that `OwningRef` is immutable. If there was a mutable version of it, then one could potentially create a `OwningRefMut&lt;std::cell::RefMut&lt;&amp;mut [u8]&gt;&gt;` and have S1 take that instead of just an `&amp;'a mut [u8]`.
Servo upgraded serde and landed bincode support this morning: https://github.com/servo/servo/commit/6b32e5d7a71430e6b0acec2965279c1c35aa2b08 Many thanks to everyone who helped make this possible!
&gt; expression problem Yep, [here's it described on c2](http://c2.com/cgi/wiki?ExpressionProblem). It's nice that Rust can do both (static dispatch on an enum, dynamic dispatch on a trait object). Generally speaking, enums seem to be "more idiomatic" in Rust, if only because of static dispatch. But I was just saying that the enum approach isn't *necessarily* superior; there are tradeoffs to consider.
If you write draw_plot(xs.iter(), ys[..111].iter(), "sine2.png"); both iterators will be of the same type. It's probably preferable to `ys.iter().take(111)` at least if you know that there are at least 111 items. But you should still use distinct type parameters for the iterators to make it more flexible.
Yep. I would really have liked if Rust had the easy ad-hoc overloading of the C++ family, but I guess that is incompatible with the HMTI algorithm.
Apart from the core language, you might also like Rust because of its "surroundings": * cargo: the default package manager that makes it really easy to publish and depend on other libraries. * easy unit testing and benchmarking * the friendly community
Slightly off-topic, but there was an idea [to introduce "anonymous type" to the language.](https://github.com/rust-lang/rfcs/pull/105) Which will make the following possible: fn draw_plot&lt;K: DataType&gt;(xs: impl Iterator&lt;Item=K&gt;, ys: impl Iterator&lt;Item=K&gt;, name: &amp;str) This is far more readable and has less cognitive burden IMO. However, there were some objections because they thought making two different ways that do the same thing was not worthwhile. This RFC was closed to find a better alternative after releasing 1.0 first, but I hope a similar approach would land someday.
Minor typo: &gt; This will enable Servo to use bincode for **it’s** IPC protocol.
Based on the crates.io numbers the rustc-serialize is still the most popular library (https://crates.io/crates/rustc-serialize) with Serde (https://crates.io/crates/serde) being the second in popularity. Note that Serde's JSON support has been moved to a separate crate (https://crates.io/crates/serde_json) today. See also http://doc.rust-lang.org/rustc-serialize/rustc_serialize/json/index.html#the-status-of-this-library
Neat! &gt; a 10x improvement from 4GB/s to 15GB/s *cough*. :) Is it easy to explain how to use the benchmarks with a different serialization protocol? I'd be keen to try out [abomonation](https://github.com/frankmcsherry/abomonation), but I'm not really sure how the benchmarking works.
There is still one absolutely huge difference between Rust and Python's approach to code: Rust only has expressions, Python is a very statements-oriented language. That means Rust lets you nest constructs in pretty much every way you feel like, in Python that requires extensions to the language itself if things are not currently supported (e.g. ternary)
Usually when Rust refuses to be accomodating because something is unstable, I put `#![feature(...)]` in my crate and it works! I was hoping the same would work with steveklabnik!
&gt; As far as I know, neither rustc-serialize nor serde fulfill these criterias. It might need some tweaking of your Serde code, but I believe it's doable. &gt; Works on Rust stable (no plugin). https://www.reddit.com/r/rust/comments/36i5eg/serde_04_now_supports_syntax_extensions_in_stable/ &gt; Allows me to parse JSON files that contains objects which have a field named type (even though type is a keyword). Serde has a `rename` annotation, cf. https://github.com/serde-rs/serde/blob/abf28ee16749a4bf03de501ef0df927c8053e84b/serde_tests/tests/test_annotations.rs &gt; Allows me to parse JSON files where the type of some elements can be one of several different things (for example either a string or an object). YQL currency quotes API returns either an object (for a single quote) or an array of objects (for multiple quotes) in the "rate" field. I'm parsing it with Serde by manually implementing a part of the parser (cf. "Serialization without Macros"). `visit_map` handles the object case and `visit_seq` handles the array of objects case. Just my two cents.
One of the core aspects of functional programming is that a function behaves like a function in the mathematical sense: it's result is fully determined by it's arguments and it doesn't change anything but it's result. Mutable references are very unhelpful if you want to guarantee this.
I have to disagree here. For real functional programming i think at least the concept of guaranteed pure functions would be needed. In that sense C++ which has constexpr functions now, is a better fit for functional programming.
There is no class keyword. In Rust, you create a struct, in which you define your class fields. You then write an "impl block", in which you can specify methods, to work on that data. There also is a thing called traits, which work kind of similar to a Java interface (but you can also specify default implementations) that is a kind of inheritance. I recommend you read the online book on rust-Lang.org (thanks /u/flakybit), it will show you how to do it. (I'm on mobile at the moment, and don't feel like trying to write code on mobile. 😊)
Interior mutability is dangerous (meaning hard to reason about safely) in rust too. But since it doesn't corrupt memory, it's defined "safe".
I think you meant https://www.rust-lang.org/.
[RFC 1210](https://github.com/rust-lang/rfcs/pull/1210) would bring the trait system closer to inheritance (I wouldn't call it "trait-based inheritance" as it stands now), and aturon says that he has a proposal building on it that would be an implementation of actual inheritance using trait objects, which sounds very interesting.
Oh dear, it's quite a pain that I wrote all the deserializer/serializer for my self defined type due to unknowing the rename annotation. Sad..
An even better guarantee would be the "pure" keyword Rust used to have. Still sad that it got dropped
Thanks for the answers. The impl blocks are a weird concept, but it are both easy to implement in runtime and compiler. Can a struct restrict access to its members, or is that not possible? I'm thinking of the public, private and protected keywords in other languages.
&gt; But one struct is not the parent of the other I know, I was trying to give a more general explanation of the concepts
I too think that having this indirect way of inheritance using traits is good. I think it is more flexible than the classical way, and the diamond shaped problem won't occur. I forgot it's name &lt;OffTopic&gt;, but it occurs when A is parent of B and C. B and C are parents of D. The problem is about resolving a call to the functions which D inherits from A.&lt;/OffTopic&gt; But as I said, this is (so I think) not a problem in Rust.
Thanks, this really helped! But how about functions? Are all functions in impl blocks always public?
Struct members are private by default - which means they are only accessible within the same module.
From that page (as of this comment's timestamp): &gt; Functional programming languages, especially purely functional ones [...] have largely been emphasized in academia rather than in commercial software development. However, prominent functional programming languages such as Common Lisp, Scheme, Clojure, Racket, Erlang, OCaml, Haskell, and F# have been used in industrial and commercial applications by a wide variety of organizations. As far as I know, Haskell is the only language on that list which guarantees purity at the type level. And even then, you can still use `unsafePerformIO` if you really want to. I think what's important isn't so much whether pure functions are *supported*, but whether they are *culturally* favored. In Haskell, the existence of `unsafePerformIO` is not a practical obstacle to reasoning about our programs in terms of pure functions, because no sane Haskell programmer would use `unsafePerformIO` to break referential transparency. So instead of arguing about dictionary definitions, I'd much rather learn about the established culture. In Montreal, at least, there is a lot of overlap between the Rust and Haskell meetups. So, fellow Rustaceans, do *you* use Rust as a functional language?
&gt; a 10x improvement That's within +/- 0.5 orders of magnitude of reality, close enough!
`pure` served too many masters, and all of them poorly. One of those masters is compile time computation, and that's coming back as `const fn`.
There was some rounding and fudging going on because I didn't quiet trust my precision :) The capnpc benchmarks were a little noisy, and waivered between 14GB/s and 15GB/s. It'd be fun to get abomonination into the mix. My benchmark suite is here: https://github.com/erickt/rust-serialization-benchmarks if you want to add support for it. It is based off of Cloudflare's https://github.com/cloudflare/goser go language benchmarks, which tests the speed of various go serializers on a struct message. It shouldn't be too hard to copy how I'm doing the rustc-serialize or serde since I think abomonation has fairly similar traits. 
Why does this introduce runtime penalties?
It's passing a table of function pointers into the function instead of deciding at compile time which functions to call inside the body. This means there's an extra memory access on each member function call and inhibits other optimizations.
Rename isn't stable, though.
need to be mutable (`&amp;mut Iterator`) to actually be iterable.
Check out 'cargo rustc'.
I'm going to give you a tip to make it even more verbose! Almost every time you use an `Iterator&lt;Item=K&gt;` bound in a function, you can use `IntoIterator&lt;Item=K&gt;` instead. This allows you to accept more kinds of arguments. Converting the argument into an iterator requires an explicit `.into_iter()` call too.
This is what [`unreachable!()`](http://doc.rust-lang.org/std/macro.unreachable!.html) is for. Would be nice to have smarter exhaustiveness testing, though.
As long as your can organize your data into object-like structures and you can implement methods (functions specialized to an instance of an object), then you can do object oriented programming. You can do it in C if you like -- its a methodology, not a set of keywords. And under that methodology there are various language features that may or may not be implemented, none of which make an language capable or not-capable of OOP. The features are there to enable certain development patterns that the languages creator deems safe/effective/useful. Rust provides encapsulation via "struct", method definition via "impl", and type variance/relationship definition via "trait" and generics. Rust is capable of both static and dynamic dispatch of method calls. It doesn't provide direct type inheritance, so you wont be creating multi-level structural inheritance hierarchies like you might in Java or C++. That being said, you get type-class behavior, which can be (just as|more) powerful. 
Ooo, is this new? Edit: OOOO it totally does what I want!
A panic in the `_ =&gt; ` branch isn't *necessarily* a runtime check. You've got an advanced optimizing compiler at your disposal, it may very well just remove that branch if it can prove it unreachable.
Just a PSA: Stack Overflow [is awesome](https://stackoverflow.com/questions/tagged/rust) for asking Rust questions, simple or complex.
I _think_ it's new in the Cargo that comes with 1.2, yes.
I was reading your *Purity for (almost) free* and I'm quite intrigued by it! Is there a library that implements this and builds in stable Rust?
Hmm. This is an interesting question. I haven't been trying to speak to this, since its not something I feel that I could speak to. I *mostly* am trying to communicate my frustrations as they occur as I learn Rust, from *my* perspective. However, I can say this: as frustrating as this is, debugging segmentation faults can be even more frustrating. 
Well it wouldn't be one of my blog posts if it wasn't filled with typos. It's how you know it's me, and not some replicant :) Fixed it, thanks!
It is if you use [syntex](https://www.reddit.com/r/rust/comments/36i5eg/serde_04_now_supports_syntax_extensions_in_stable/). 
Thanks! And nah :) I'm not sure if that would make any sense in Rust-as-it-exists. You *could* define the marker types and so on and require passing them explicitly for the given library, but it doesn't gain you much if nobody else in the ecosystem is playing by the same rules. You pay the costs without getting the benefits - you *can't* assume any `&amp;Fn` to be pure because anyone else could still have put a `println` in it. You would essentially have to fork the language, *at least* the `std`lib and `crates.io`. Possibly you could get away without forking the compiler... as long as you don't want to make it pass around the capability tokens for you automatically (which, however, you most likely would).
I would argue that unless you're using function pointers stored in the struct (or something linked from it) you're not doing OOP in C. The innovation of OOP was allowing different behavior for different instances or subtypes of a type by storing the functions along with the object. It's still technically syntactic sugar but not as simple as you're making it out to be. Interestingly enough, I give an interview based on this concept for work and something like 80-90% are only able to think of OOP as you have described it, despite many of them putting OOP design on their resume, and can't solve the problem.
I'm not sure how it works on a release rustc but on a nightly: [dependencies] serde = "0.5" serde_macros = "0.5" serde_json = "0.5" And the README example is: #![feature(custom_derive, plugin)] #![plugin(serde_macros)] extern crate serde; extern crate serde_json; use serde_json as json; #[derive(Serialize, Deserialize)] struct Point { x: i32, y: i32, } fn main() { let point = Point { x: 1, y: 2 }; let serialized_point = json::to_string(&amp;point).unwrap(); println!("{}", serialized_point); let deserialize_point: Point = json::from_str(&amp;serialized_point).unwrap(); println!("x: {}, y: {}", deserialize_point.x, deserialize_point.y); } 
I've had some bigger projects myself and I have to admit with class inheritance and interfaces you end up creating a mess, most of the times. The only way to fix that is to generate proxy objects, which will clutter your program with objects you shouldn't need in the first place. Example: You decide that you have an Animal (Class A) which will give it's methods to the Bird (Class B) and Clownfish (Class C). Now for a long time, you won't need to difference the kind of eating/moving they do, so you create an method on the Animal (A) that will give the eat/move method to the Bird (B) and Clownfish (C). After some more time, you will invent the fly method for the Bird (B) and the swim method for the fish (C). Down the road you realize you have another type of animal, the Puffin (P), which can both fly and swim. So what will you do? You have the fly method on the Bird (B) and the swim method on the Clownfish (C). In Rust you would solve this by simply using Impl and say that it can swim/fly. But the "real" OOP-ways have a hard time struggling with those type. I've read guides on how to use OOP correctly which make you insane. There is so much to care about that it's absolutely crazy peope did not invent something more useful. Now with Rust, I can see how many of these problems fade away.
The phrase is 'composition over inheritance,' and many people have spilled a lot of virtual ink on it. Searching for that should get you a number of perspectives.
Rust doesn't have a (official) REPL I'm afraid. For me TDD works well with Rust. Generally I have a Guardfile that runs the test suite each time I save a file, which makes the process smooth enough. :)
Sorry about that, I pushed up `build.rs` and added a [clone benchmark](https://github.com/erickt/rust-serialization-benchmarks/blob/master/rust/src/goser.rs#L979), which is roughly 2GB/s for me if my math is right that the total Log structure would be 584 bytes. bincode serializes down into about 400, so it's probably not that far off with all the aliasing. Here are the results from my laptop: test goser::bench_clone ... bench: 288 ns/iter (+/- 86) = 1902 MB/s test goser::bincode::bench_decoder ... bench: 1,281 ns/iter (+/- 446) = 312 MB/s test goser::bincode::bench_encoder ... bench: 119 ns/iter (+/- 33) = 3361 MB/s test goser::bincode::bench_populate ... bench: 887 ns/iter (+/- 149) test goser::bincode_serde::bench_deserialize ... bench: 1,126 ns/iter (+/- 648) = 317 MB/s test goser::bincode_serde::bench_populate ... bench: 899 ns/iter (+/- 284) test goser::bincode_serde::bench_serialize ... bench: 156 ns/iter (+/- 50) = 2294 MB/s test goser::capnp::bench_deserialize ... bench: 332 ns/iter (+/- 76) = 1349 MB/s test goser::capnp::bench_deserialize_packed ... bench: 693 ns/iter (+/- 116) = 486 MB/s test goser::capnp::bench_populate ... bench: 442 ns/iter (+/- 186) test goser::capnp::bench_serialize ... bench: 29 ns/iter (+/- 13) = 15448 MB/s test goser::capnp::bench_serialize_packed ... bench: 513 ns/iter (+/- 123) = 656 MB/s test goser::msgpack::bench_decoder ... bench: 2,180 ns/iter (+/- 649) = 131 MB/s test goser::msgpack::bench_encoder ... bench: 679 ns/iter (+/- 144) = 422 MB/s test goser::msgpack::bench_populate ... bench: 909 ns/iter (+/- 437) test goser::protobuf::bench_decoder ... bench: 2,020 ns/iter (+/- 471) = 141 MB/s test goser::protobuf::bench_encoder ... bench: 762 ns/iter (+/- 122) = 375 MB/s test goser::protobuf::bench_populate ... bench: 841 ns/iter (+/- 474) test goser::rustc_serialize_json::bench_decoder ... bench: 26,320 ns/iter (+/- 2,432) = 22 MB/s test goser::rustc_serialize_json::bench_encoder ... bench: 2,898 ns/iter (+/- 673) = 208 MB/s test goser::rustc_serialize_json::bench_populate ... bench: 877 ns/iter (+/- 87) test goser::serde_json::bench_deserializer ... bench: 4,852 ns/iter (+/- 1,927) = 124 MB/s test goser::serde_json::bench_populate ... bench: 877 ns/iter (+/- 134) test goser::serde_json::bench_serializer ... bench: 2,109 ns/iter (+/- 742) = 286 MB/s 
Yeah, Rusti is cool, but I've found it not quite as polished as I want it to be. Certainly keeping an eye on it though.
&gt; In that sense C++ which has constexpr functions now, is a better fit for functional programming. C++ constexpr functions are not pure since it is possible to write a constexpr function `constexpr int counter()` that returns a different value every time that it is called.
I think the MO with Emacs is that if a package doesn't have a feature you want, you can ask the author nicely to add it or put up an issue on Github, or else you have to write it yourself.
Maybe not quite what you're looking for (I'm not sure), but have you tried flycheck-rust? As the name suggests, you get warnings and errors highlighted on the fly as you type.
&gt; I do a lot of functional programming in emacs, and in pretty much all of those environments, I can do things like C+C C+L to type check (but not compile) my source and receive immediate feedback in a minibuffer from the type checker. Is there anything like this in Rust? I have rust-mode, but this command doesn't seem to be there. If you use [flycheck](https://github.com/flycheck/flycheck), it comes with a basic checker for Rust. If you're writing Cargo projects though, [flycheck-rust](https://github.com/flycheck/flycheck-rust) is essential. It's a little broken right now, though (see [issue #8](https://github.com/flycheck/flycheck-rust/issues/8))
&gt; I don't know how to hook it into emacs, but running cargo check will do a test compile without passing the result to LLVM for codegen. If you can look up how those other environments hook into emacs, you can replicate that. It's probably sufficient to do: M-x compile&lt;RET&gt; cargo check&lt;RET&gt; from any Rust buffer. You can run it again with `M-x recompile&lt;RET&gt;`.
That sounds like an implementation detail more like an aspect of duck typing though. I'm basing my reasoning here on the saying "If it looks like a duck and walks like a duck etc., it is a duck" and this definition from wikipedia: &gt;Duck typing is concerned with establishing the suitability of an object for some purpose. With normal typing, suitability is assumed to be determined by an object's type only. In duck typing, an object's suitability is determined by the presence of certain methods and properties (with appropriate meaning), rather than the actual type of the object. Generics with trait bounds would fit this in my opinion. I recognize, that the term "duck typing" is strongly connotated with dynamic typing, though.
I use Atom on all platforms and it works really well, has plugins for syntax, linting, racer, and will execute basic cargo tasks for you.
I fixed up the docs, thanks!
I agree that it gives the benefit of duck typing, but there are many differences. Duck typing would basically not have types associated with valurs, types are associated with behaviors (imagine if Rust only had traits).
It'd be great if the type system could prove the pattern unreachable, though.
Can you even use range patterns on arbitrary Range types? They aren't the same as range expressions. This isn't proposing refinement on values, only on the exhaustive ess of range patterns. I don't think it would be surprising for this inference to only apply to language primitives.
Works fine for me. Might be intermittent connection issue between your network provider and the crates.io host. Try again in a few hours and see if it works or not.
Feel free to delete this post when the problem is fixed.
works back for me, too. Thanks.
There are sometimes DNS issues, we haven't been able to figure out what's up. It's very intermittent, and only happens to some people :/
&gt; &gt; &gt; One thing that would be nice is if you explained what .map(|node| &amp;**node) does, which you do in a few examples. From what I understand Yeah you got it exactly. (filling an issue on the repo would help me remember fwiw)
This happened to me yesterday. I switched my OS to use the Google DNS server and the problem instantly went away.
&gt;Can you even use range patterns on arbitrary Range types? They aren't the same as range expressions. `error: only char and numeric types are allowed in range patterns`. Nope
+1 to this. I got a hang of how references and borrowing works by working through this (Still only understand about 40%, but its a start).
I understand virtual methods, I just don't think OOP strictly requires them
Arrays are quite simply magical. They implement several operation via compiler magic, because there's no way to actually talk about arrays in a way generic over `n`. However what you're trying to do is convert the arrays into a trait object and dynamically dispatch on them. If this actually worked, this would be Very Bad. In principle, every single value of `N` would need its own vtable! Virtualizing arrays is the job of slices. You can explicitly request a slice in your signature, or ask for a generic Index impl: http://is.gd/q6I2qD use std::ops::Index; fn foo_generic&lt;Arr: ?Sized + Index&lt;usize, Output=i32&gt;&gt;(a: &amp;Arr) { println!("{:?}", a[0]); } fn foo_sliced(a: &amp;[i32]) { println!("{:?}", a[0]); } fn main() { let arr = [1, 2, 3, 4]; // [i32; 4] foo_sliced(&amp;arr); // &amp;[T; n] coerces to &amp;[T] // foo_generic(&amp;arr); // But coercions don't happen for generics let slice: &amp;[i32] = &amp;arr; // Manually coerce to &amp;[T] foo_generic(slice); // Now it works! } The generic impl will notably be monomorphized exactly once for all slices. Nice! Using a slice as a trait-object doesn't really work right now because the system expects the &amp;Foo you turn into an &amp;Trait to have Foo sized. This is not the case for `Foo = [T]`.
&gt; Having to forward declare methods is a PITA. Where is he forward declaring methods?
Thanks! I'm still having some issues, but I opened an issue on the project repo with error details. Reading the code, is there a reason you don't have the `capnp` message building as part of its serialization benchmark? It seems like that is where a lot of the serialization actually happens (re-laying the fields out in contiguous memory).
You may want to look at [dimensioned's peano numerals](https://github.com/paholg/dimensioned/blob/master/src/peano.rs) or [shoggoth-rs's binary numbers](https://github.com/epsilonz/shoggoth.rs/blob/master/src/ty/nat/mod.rs) – both are type-level implementations of numbers that should work today (although I see that epsilonZ hasn't pulled my fixes yet even after a month).
That's awesome, thanks for writing this! Any chance we could get an epub version of this book?
To add a little bit more to this, there are two solutions I see to this. The first, more OOP way (IMHO), is to add a fish class that inherits animal and have the two puffin and clownfish inherit the fish class. But I think this isn't possible in rust. (But easily doable in C++ or Java.) The second, which I would characterize as a more "generic programming"-like method, is to create interfaces (traits) animal, swimmable, and flyable and have the classes (structs) implement the relevant interfaces. I'm not sure which is better. Which would you prefer and why?
For the first solution I don't see how it would fix the problem that you don't have to redefine the method already created in either Clownfish (C) or Bird (C)? In most programming languages you can only have one parent. You would either have to: 1.) Put those methods inside Animal (A) which will clutter the class and change your programs drastically. 2.) Create a wrapper-object that will delegate it's method calls to either Bird (B) or Clownfish (C). For the rust way: I would actually choose two traits, one with Flying and one with Swimming. And the already made trait (Animal) I would not have to change. Which one I prefer? The trait method. Why? Because I have easily testable objects and I don't have to change my whole sourcecode when I get new requirements. FYI: I did choose Clownfish (C) instead of Fish (F) to make it more easily understandable. You can just ignore the "Clown".
[*cough*buginrustdoc*cough*](https://github.com/PistonDevelopers/image/blob/master/src/buffer.rs#L217-L220)
It seems very common for people to associate duck typing and structural typing (I see it in StackOverflow answers explaining duck typing, for example), but I'm not sure that they're related. I think its just a fact of history that there aren't any nominally duck typed languages (because all duck typed languages that I know of are dynamically typed). To me duck-typing just implies a value's type is solely determined by the functions which can be applied to it. It doesn't matter what the representation of the type is in memory. Conceivably in a much higher level language than Rust (like on the level of Ruby), you could have a statically typed system based entirely around something like trait objects, and no concept analogous to non-abstract types. I don't know if that's actually possible, but I think it would be an interesting idea.
But what if you want a function that both becomes another function at times and returns at other times?
I think you mean delegate,not forward declare. A forward declaration is where you declare an item exists so that another item can use it before it is fully defined. It was a useful trick to make writing compilers easier in the 70s. It's not needed in today's compilation environments (yay, smarter compilers) and does not exist in Rust.
Any macro still distinguishable from magic isn't sufficiently advanced.
Yes many traits that are implemented for slices are implemented for `[T]`. I'm not sure what you mean about using &amp;Trait outside of self.
I'm not quite understanding what the difference is other than an attribute.
Haha, I always forget that stuff and wrote that probably at 2am!
Yeh, it's up there with higher kinded types. Everyone wants it, but it's kinda complex to get right, so it's on the back burner til someone picks it up and runs with it.
I meant declaring/implementing the methods in a Trait (e.g. `HasAnimal` and implement it for `Animal` and `Cat`), writing a delegate that calls the method of `Animal` in the impl of `Cat`, or implementing a `Deref` of `Cat` to `Animal` (these are the 3 ways of doing this that I know of). I would like to just write something like struct Cat { using animal: Animal // the keyword/syntax for this is bikeshedable } so that `Cat` gets all the method impls of `Animal`, all the Traits impl of `Animal`, and a `Deref` to `Animal`.
See: https://www.reddit.com/r/rust/comments/3gc6dv/oop_in_rust/ctxz71q
That sounds actionable, but I'd like to see it experimented with, possibly as a compiler plugin? struct Cat { #![using(animal: Animal)] ... }
Don't worry about it, you probably have better things to do than worrying about us ex-haskellers :)
After a quick conversation on #rust, something that delineated the difference between template types and associated types would be helpful. In all the examples I see, it seems you could just use standard template types for the same thing.
Great to hear I've made a good example! Let me know any questions left if you have any.
"append" isn't etymologically directional, but think how confusing you would (I assume!) find a book or article whose appendices came at the beginning.
In terms of data layouts, 'append' has fairly strong precedent for being directional. When you append to a string or file, there's no doubt about which end you're talking about, which is reflected in any definition of the word in reference to computing. In a number of programming languages, including in the Rust standard library, appending to a list-like structure means adding elements at the end, not the beginning. The word 'prepend' exists solely to contrast with 'append'. There is no 'postpend'. It's not terribly important, but I did find it confusing, and I'm sure others would too.
You would not need to explicitly type `become`, and can just leave the last expression automatically return its value. For example: fn fac(i: i32, acc: i32) -&gt; i32 { if i == 0 || i == 1 { acc } else { fac(i - 1, acc * i) } } and I wouldn't need to type `become fac(i - 1, acc * i)`. It would also be easier to tell just by looking at the function declaration that it is tail recursive, instead of having to search its body for any occurrences of `become`. 
Note also that `append` is a generic libcollections term for "combine" -- BTree and HashMap can support append, even though it's not a sequential notion. Although in libcollections parlance it's a destructive operation (moves everything over from one to the other). Does preserve allocations, though (it's equiv to a.extend(b.drain())).
Don't know if this can be meaningfully expanded, but it seems like one example of associated types might be enabling the same structure to work with both `Rc` and `Arc`: https://play.rust-lang.org/?gist=fbfe3dbcc79a12e17c87&amp;version=stable
If you're confused by the graph example, ignore it. There are better use cases.
looks like a small enough task to start experimenting with compiler plugins :)
That's another great explanation of how you can *use* associated types, but again it doesn't offer much to support the 'input/output' distinction as *definition*, esp. given that `connected` explicitly uses `Node` as input.
The fact that there are better use cases doesn't mean you can just ignore another legitimate but confusing example when you're trying to understand a concept. That's how bad assumptions get formed.
Well, it's an input of a method, but an output of an implementation. The point of output type is that it is defined by the implementation. User can't use a different `Node` type for `NeighbourListGraph`, because this type defines `Node` to be a concrete type `usize`. I think that traits like `Add`, [`Index`](http://static.rust-lang.org/doc/master/std/ops/trait.Index.html) or [`Deref`](http://static.rust-lang.org/doc/master/std/ops/trait.Deref.html) are perfect examples on the difference between input and output types. Usually input types (generic parameters) are used as arguments in methods and output types (associated types) are used as their results (`Index` trait being an example), but it's not the rule (`Graph` being an exception). You can think of output type as a *property* of an implementation. Let's focus on `Index` trait, `&amp;[T]` implement both `Index&lt;usize&gt;` and `Index&lt;Range&gt;`. The implementation for `usize` input parameter *defines* the indexed value to be `T`, and implementation for `Range` *defines* it to be `[T]`. So a structure can implement multiple indexing methods, but each of them can have only one output type.
Well think of the following. What is a Graph? Well it's a series of Nodes connected by Edges. Think of Nodes as circles and Edges as lines connecting those circles (with a number associated). So we create a data-structure that works like a graph. Now how do we represent the Nodes and Edges? Well it depends on how the graph is represented internally! In other words if we had a type Graph&lt;Node, Edge&gt; Node and Edge would have to be compatible with the real graph's implementation. It's exposing the internals and forcing us to do something like: impl Graph&lt;MyGraphNode, MyGraphEdge&gt; for MyGraph {...} There's no case were a user would want to do something else. Yet to anyone using your Graph trait they would have to be aware of these types that are part of Graph's internal trait, so you'd be writing something like `&lt;N: GraphNode, E: GraphEdge, G: Graph&lt;N, E&gt;&gt; all the time. It's not that obvious, it's not that clear what the intention is, and it's overly verbose. Associated types let us say, a `Graph` implementation must also define the implementations for its `Node`s and `Edges`. Which is what we really want. Now on to your specific questions: 1. No, it starts by saying associated types let you not have to type boilerplate by showing that some types in a trait are part of the implementation, not the trait itself. 2. It's mostly for things such as iterators and such. There are cases when you want to be able to constrain, but the RFC doesn't go into much detail of why you'd want that because it was too early to fully understand the use. 3. The example doesn't implement a full example, but merely showcases some facts. The display part is to show that associated types can have constraints. Also it makes sense that you can show an node (which is a thing) on its own, but it doesn't make sense you can show an Edge (which is a relationship) out of the context of the Graph. 4. The implementation that's silly is meant to show some of the more elaborate things that could be done. Associated types are very similar in how you can constrain. The big difference is that an external user cannot choose to change the type you use by changing the type parameter, they can only use the type you give, which makes sense. 5. Same as the above line. An assoc type doesn't have to be define, and cannot be redefined easily by the user. The addition example comes to mind, think of something as follows `let x: i64 = (5 as i32 + 6 as i32);`. In the old system this would imply to the compiler that we want `i32::Add::&lt;i32, i64&gt;` which would be a pain if the developer forgot it. Instead with associated types we know the trait is `i32::Add::&lt;i32&gt;` and it's output type is `i32`, the compiler can then realize it needs a cast. This can only happen if the programmer specifically states his intention that the result type depends on the input types with an assoc type, otherwise the compiler would have to do "some magic" which the developer would have to learn, or it would do the "reasonable but wrong" thing. In short if we have something like the following: trait T&lt;A, B, C&gt; { fn f(self, A, B) -&gt; C } The user of that trait would **always** have to be aware of what C is and how it works. OTOH if we have something like fn Trait&lt;A, B&gt; { type C; fn f(self, A, B) -&gt; Self::C; } The user doesn't have to care about C, because that's just an implementation detail, not something that defines the trait. Again: * Type Parameters: Types **that define the trait and change its properties**. * Associated Types: Types **that are defined by the trait and are its properties**.
Isn't that 0.0.0.0? (I am bad at networking, so I'm assuming there's some difference)
Interesting. I was working on something similar to peano numerals; from what I've seen, it's pretty damn cool. Especially: impl NonNeg for Zero {} impl&lt;N: NonNeg&gt; NonNeg for Succ&lt;N&gt; {} Gotta love recursion! All we need now is to have `const fn` as associated functions, so we can determine the size of an array at compile-time.. :-)
`Add`, `Index`, and `Deref` all use their associated types exclusively as output of a method, so it isn't really helpful to call them out as perfect examples of the difference b/w input &amp; output types when you're explicitly trying to explain why `connected` can use its associated 'output' type for method input. It further confuses things that implementations of `Index` and `Deref` are typically going to use the generic 'input' type of the container/smartpointer they're defined for as their associated output type. "Property of an implementation vs property of usage" makes a lot more sense to me, and seems to capture all the possible use cases w/o the weird ambiguity w/ method input/output. 
I can only speak for Linux / Win32, as steve mentioned, 0.0.0.0 should generally work, as should :0 for binding to a random, unused port. One thing to watch out for though is that 0.0.0.0 isn't a valid receiver address under Win32. So why would you ever want to send a packet there in the first place? Well, rust only features blocking recv() functions and setting timeouts on a recv() call is currently considered [unstable](https://doc.rust-lang.org/std/net/struct.UdpSocket.html#method.set_read_timeout) so one workaround to unblock the recv() call and exit any reader thread cleanly is to send a empty packet to the bound address.
I have never seen it defined as anything other than zero. If it would get added to Rust, I'd just be adding it as zero. It seems like something that might be nice to have, but today, right now, just use zeros. Certainly on all versions of Windows, Mac &amp; Linux, it's 0 today. That ought to be portable enough for most.
Random thought: Hmm, using the "Null Pointer" optimization in Rust, an Option&lt;IPv4&gt; address could have None mean inaddr_any, and it would have the right representation as zero!
I really like your writing style! Please continue to write more! And thank you this book.
Care to pass it up to the team? :)
Hi, Not sure this is valid? There's no volunteers to host August meetup yet. :-(
I think Windows IoT will have to become a bit more popular before you'll see information on it popping up on Google. Also, I don't know if the Rust compiler currently has Windows ARM targets, so that would put a damper on things. I think it's a little early (for both projects) to expect that kind of support. I feel like the only reason that you'd want to use Windows 10 IoT on a Raspberry Pi 2 is to take advantage of the Visual Studio tools. If you wanted to use Rust on a Raspberry Pi 2, you might have better luck with a Linux distribution.
You should comment here: https://github.com/rust-lang/rfcs/issues/271 that way it won't get lost.
i thought flycheck-rust already looked at Cargo (it seems that racer does at least). But anyway it works here, and t's amazing!
An additional instance where I wish Rust RFCs weren't called **RFC**.
If you're on Linux or OS X, I recommend the rust and racer tools for Atom. It's not perfect. It has a hard time finding macros, for instance, but the winter support alone actually goes a long way.
This sounds pretty awesome.
You keep trying to explain, which tells me you're missing the fundamental point I'm trying to make, which is that using the 'input/output' explanation of associated types isn't very pedagogically effective.
No, I've already stopped explaining. And speaking of definitions, I think that the others already provided the answers. Also, I've agreed that input/output naming is confusing. But I didn't invent input/output explanation. It's purely a naming convention, which I've used. Could call it Left and Right or whatever. It's common to call parameters of trait "input types" and associated types "output types" when talking about Rust (maybe in other languages too). And that naming doesn't have anything to do with method input/outputs (ok, I see you've edited your comment, so I guess you've realized that).
This is fairly easy to misunderstand because trait parameters can be both input and output while associated type parameters can only be output. Furthermore, the motivating example in that RFC which suggests associated types are required doesn't need associated types to work anymore. See [this question](https://users.rust-lang.org/t/clarification-over-benefits-of-associated-types/1313) for more details. Associated types doesn't make traits more expressive. Associated types makes the trait more usable for *users* of the trait when using generics. In other words: // A generic function using a specific trait might look like this: fn foo&lt;A, B, C&gt;(c: &amp;C) -&gt; i32 where C: TraitC&lt;A, B&gt; { ... } // With associated types, the same generic function looks like: fn foo&lt;C: TraitC&gt;(c: &amp;C) -&gt; i32 { ... }
Nooo, I'm already in the area, does anyone want to meet at a coffee shop?
I'm *pretty* sure there isn't an August 32nd available for a Paris meetup... :)
Visual Studio has some support in Visual Rust (from the Piston developers). Rust DT is an actively developed Eclipse plugin for Rust. We (the tools and compiler sub-teams) are planning on having some more official support (and changes to the compiler to make that support awesome) soon.
Now it seems to be fixed?
Cool! I've just installed the 1.2 release so I'll check what's new.
It's a pity that Intellij Rust plugin was abandoned. I hope someone revives and improves it.
Is there a list of 3rd party cargo subcommand? These are the ones I know of: - [cargo-outdated](https://github.com/kbknapp/cargo-outdated): A cargo subcommand for displaying when Rust dependencies are out of date - [cargo-check](https://github.com/rsolomo/cargo-check): This is a wrapper around `cargo rustc -- -Zno-trans`. It can be helpful for running a faster compile if you only need correctness checks. - [cargo-edit](https://github.com/killercup/cargo-edit): A utility for adding cargo dependencies from the command line. (Can also list dependencies as tree) - [cargo-dot](https://github.com/maxsnew/cargo-dot): Generate graphs of a Cargo project's dependencies
Well, it's better to have two and one of them maintained than one abandoned.
This is awesome ! It would be great if it was merged in Cargo :-)
Looking at my table again, the free borrowed-&gt;owned conversions category seems like a brainfart. :p
https://github.com/JakeMick/idea-rust I collected some improvements and completed the Cargo support. The parsing isn't quite right. I haven't figured out what should happen with the test cases or how to add new ones. Once that's done I think autocomplete and find definition could be handled by Racer. Find usages like functionality would be nice. Maybe if it's improved enough then Vektah would hand over the project.
You can get pretty decent code completion using any editor that integrates with [racer](https://github.com/phildawes/racer). I know that it works nicely with Emacs, including error navigation. To the best of my knowledge racer does not provide any refactoring support though. Lastly, I don't have much experience with debuggers but you might be able to use gdb/lldb integration in Emacs for debugging.
In general, a GC makes ad-hoc sharing much faster and more pleasant. Rust emphasizes flatter, nonrecursive structures. If you know you can avoid reference cycles, you can use a reference-counted pointer to the substructures. This will probably have significantly more overhead than the equivalent in Haskell, since naïve reference counting is expensive, but it will work. If you can't avoid cycles, there probably isn't an automatic way to deal with the problem. (One might consider arena allocation, if you're lucky enough for it to work.) There might be good manual solutions, though.
The rustty api seems totally broken to me: - Chinese characters are usually displayed using two cells in terminals - Then there are [combining characters](https://en.wikipedia.org/wiki/Combining_character) which can mean several characters for one cell, combining of characters over several cells, ...
You should look into [dxr](https://github.com/mozilla/dxr) and see if you can't use some of their logic for implementing "find usages", "find references", etc. It's a cool tool, but I prefer it to work in an editting environment and not in a read-only format (although that does help getting used to new code).
[travis-cargo](https://github.com/huonw/travis-cargo) &gt; This provides a standalone script travis-cargo that manages running cargo and several other related features on Travis CI.
You can share immutable state between objects, but the borrow checker will enforce lifetime guarantees, which sometimes makes it cumbersome to use (the lifetime of the original value affects where you can refer to it). In those cases you can use Rc or Arc to wrap the value in a reference counted container that can be shared more freely.
&gt; winter support ???? Autocorrect maybe?
Github wikis are somewhere I never look. (But I updated the page with the links I posted above.)
There's also: [cargo-script](https://github.com/DanielKeep/cargo-script) - designed to let people quickly and easily run Rust "scripts" which can make use of Cargo's package ecosystem.
Yeah, I meant 'linter'
There's also [SolidOak](https://github.com/oakes/SolidOak) which integrates vim and racer nicely out of the box.
That's a great answer, thank you!
Looking at the type signatures in the library, most of the functions (e.g. insert) are taking ownership of the data structure to produce the new version. So I'm not quite sure what benefit there is, compared to mutation, if I can't have two instances of the HAMT share structure at the same time?
This is true, though maybe they should.
Why do you warn against `LinkedList`? Also, is it "Manish Earth" or "Man Is Hearth"? 
All the slowness from exceptions is already there to handle running destructors- the reason you can't catch panics is for safety.
I recently counted all rust code I've written so far and found about 5.5kloc. Given that, it's probably funny that I'm listed as a mentor. Then again, I have actually been helpful in the past on a few occasions.
If that's the desired result, boxes do a great job -- I think once people start to catch on to just how smart the Rust compiler is, it's use is really going to take off. That being said, the whole reason we strive for immutability is so we can share state, so maybe Rc makes a bit more sense.
I've been sitting on this for a couple months now (that's not your first thread on that subject is it?), thanks for the reminder. I had a quick look at the issues tracker, #113 and #114 look easy enough. I'll have a look at it and maybe even come up with a PR if it's not too far outside of my rust comfort zone. We'll see how it goes.
If you (or someone else) knows Java: Would it be fair to say that the Java equivalent without associated types would be class SomeImpl&lt;T&gt; implements SomeInterface&lt;T&gt; { // code here } and the associated type version would be class SomeImpl implements SomeInterface&lt;String&gt; { // code here } ?
It's a classical data structure that is suboptimal for most use cases.
Servo (like every other browser engine) uses persistent data structures in its style implementation to save memory and copying. The code is heavily autogenerated so I can't link you to something easy, but the general trick is to share parts of your data structures using Arc (or Rc) and then, when you want to mutate, use `Arc::make_unique()` (or the Rc equivalent) to acquire a mutable handle on the part you want to change while leaving the rest alone.
Ah ok, I thought they *were* considered a fairly niche data structure by most people. 
Yep! Let me know if you need help -- I intend to eventually put hints on the bugs, but I need time to do that. Please leave a comment on an issue if you plan to take it so that others don't clash with you :)
Nope. As /u/Rusky says, that cost is paid already. There's a number of different angles you can look at this decision from: 1. Rust used to be a N:M threaded, no-shared-state language. SOP in those languages is to just terminate and re-start threads. 2. Given that history, even when we moved away from N:M threads, exception safety is still something that's really hard, and so you shouldn't really use exceptions. 3. However, unwinding across an FFI boundary is undefined behavior, so if you want to write robust FFI code, you need a way to stop unwinding. As the RFC says, we don't plan on making this the way you handle errors in Rust. This should still be extremely rare. Catching panics is really just for the FFI case, and possibly things like threadpools. Please keep using `Result&lt;T, E&gt;` for a recoverable error.
The [unicode-bidi](https://crates.io/crates/unicode-bidi) crate might help if you want to implement right-to-left (RTL) support. Warning: It's still fairly new and untested. I doubt that any terminal supports vertical scripts.
Oops, I just made a PR for #113. Sorry :)
I'd also mention the [Build plugin](https://atom.io/packages/build) which now has support for Cargo and allows you to build Rust projects without having to drop down to command line. These three plugins have made Atom my go to choice for a Rust IDE.
What's with the link to http://smallcultfollowing.com/rust-int-variations/imem-umem/guide-unsafe.html ? That's way old, isn't it?
You never know with leap seconds these days
Well your PR gives me a good idea of what's needed to write a lint, I guess i'll use that as study material to get started ;)
I like warm fireplaces, and I like getting paid, so I wouldn't particularly mind :)
Oh cool, I will just happen to be in town that day :)
I don't know, sorry
My first thought is that it's a bug, as a `move` closure should be `FnOnce`, not `FnMut`.
Calling `FnMut` borrows its environment, so you can not move something out of it. You can either change closure type to `FnOnce`, or use `Option` and move value out with `Option::take`: [example](http://is.gd/LuTPri)
Yeah it depends on the application I guess. I'm probably biased from the last time I did an AST :) But that's the great thing about Rust, it allows you so much precision in describing what guarantees you want and trade it of for various capabilities.
`move` is orthogonal to closure being `Fn`/`FnMut`/`FnOnce`. `find()` expects `FnMut`, so the closure is assumed `FnMut` (because find will call the closure more than once). The problem lies elsewere (in moving pattern match), compiler even suggest how to correct it (by adding `ref`).
VS Code and VS are incompatible, so Visual Rust won't help with VS Code, but VS Code has built-in Rust syntax highlighting, and you can easily configure VS Code to run cargo directly (though per-project), see [here](https://mobiarch.wordpress.com/2015/06/16/rust-using-visual-studio-code/) (you have to escape the backslashes is the regexes, else the current VSC version won't accept it) I'm actually using VS Code as my main cross-platform (Win+Linux) Rust "IDE" right now!
I used to be very shy about putting my work out there on public repositories. Now, I throw most whatever I'm working on out there under some license. I figure if someone finds value in the code (as a reference, actually using it, etc) then at least someone is better off for it.
what edit: oh uh http://cglab.ca/~abeinges/misc/tc-archive/533tribalChallenge.gif
I do believe atom works on windows as well. Otherwise I completely agree that atom is currently the way to go for rust dev! There are plenty of vim plugins that feel similar, as well though.
One way to fix it would be this: https://play.rust-lang.org/?gist=ea6c9d13da755d313b15&amp;version=stable Here, rather than moving the value, you simply reference it instead. This may or may not be acceptable depending on what you're trying to achieve.
D'oh. This clears some things up anyway.
Maybe try /r/playrust instead. This is for the Rust programming language by Mozilla :)
Uh, no he isn't. This is appropriate, /r/rust_gamedev would also be appropriate (but that's pretty inactive). OP, I think what you want is to change `.into()` to `.build().unwrap()` from glancing at the docs, but it's been awhile since I've used piston, so I could be wrong. 
(adding onto [krdln's comment](https://www.reddit.com/r/rust/comments/3gmmd6/is_this_code_invalid_or_compiler_error/ctzhs85)) Even though you use `move`, the method `find()` takes an `FnMut` closure. `FnMut` closures *must be reusable*, so *even with `move`*, you can't move out of non-`Copy` variables. Since `E` isn't `Copy`, the first time your closure would be called would completely use up `e`, and then `e` wouldn't be accessible to use when the closure is called on the next element of the iterator.
I have no remorse publishing on crates.io small experiments that I threw together in a short time and then moving on. If people file GitHub issues or submit PRs I try to be helpful, but I also tell them if I have no intention of maintaining a given package, and offer them to take over if they’re interested. Even without going to that extreme, you don’t have to take on more responsibility than you want to. I’ve found that being straightforward when people seem to have expectations mostly works. Some examples of responses (paraphrased) that I’ve used: “Yes, that’d be a nice feature to have, but I’m not planning on making it myself. I’d review a pull request, though!” Or: “I wouldn’t know how to review or maintain that. Could it be in a separate library if we add some hooks?”
This attitude has helped me ship code. The number of people who would spend time digging through code, to then go on and say "this is shitty" are very few. That would just be trolling anyway. If people see code that's ripe for improvement they may just send you a PR!
I'll be giving a brief recap of my talk, discuss the great talks at the conference. And I'll spend some time going over my experiments with mmap creates in Rust!
In my experience, the only places where it doesn't work are long macro-related errors and (which is quite annoying) the "mismatched types" error. For the latter it will only extract the first line, "mismatched types:", which is not particularly helpful (but the full cargo build output is shown in the sidebar anyway, the regex is just for inline error tooltips).
Ah, that makes sense, I've never played much with lints; didn't know they were an ide thing.
Good to know, thanks!
Cool, I see why we want these then. Thanks
&gt; And I'll spend some time going over my experiments with mmap creates in Rust! I'm curious what your experiences are. I'm the author of https://github.com/danburkert/mmap, have you had a look at it? 
(That isn't really a subcommand, and definitely isn't meant to be used manually, but I guess it does fit the theme.)
I also found it strange at first, but there are actually a few compelling reasons: 1. They make simple functions concise. e.g. `fn increase(n: i32) -&gt; { n + 1 }` 2. In Rust, nearly everything is an expression, which has a value when evaluated. Blocks are also expressions, so you can write `let a = { let b = 1; let c = 2; b + c };` and `a` is set to `3`. A function closely resembles a block, so it is not strange that they behaves similarly syntax-wise. 3. It is consistent with other control statements' usage of distinguishing normal flow from abnormal flow. For example, you do nothing for a `for` loop to run it until the end. Only when you need to break the loop earlier, you use `break`. Likewise, you do nothing if your function runs normally. Only if you need to return earlier, you use `return`.
Of any single thing in the language, implicit returns are probably the foremost thing that newcomers will raise a critical eyebrow at. I myself called it "the worst thing in the language" upon reading my first Rust tutorial in 2011. Fortunately it doesn't seem to take long for people accustomed to statement-oriented languages to realize why this rule works so well for Rust in particular. :)
Yep, https://github.com/rust-lang/rust/issues/26839
These types have no public fields -- you have to go through their `new` functions. use std::net::Ipv4Addr; fn main() { let v4addr = Ipv4Addr::new(127, 0, 0, 1); let addr = std::net::SocketAddrV4::new(v4addr, 5514); }
The compiler message seems to be a bit misleading. When you see the documentation for [Ipv4Addr](http://doc.rust-lang.org/nightly/std/net/struct.Ipv4Addr.html) and [SocketAddrV4](http://doc.rust-lang.org/nightly/std/net/struct.SocketAddrV4.html), it says "some fields omitted", which means, the internal of the structure is hidden from you. You must use one of the static methods to construct a value. Use `Ipv4Addr::new` and `SocketAddrV4::new` instead.
&gt; Especially in Java Having more than a decade of Java experience, I wonder where you take that from. Though I *do* see a lot of `TreeMap`s from less experienced devs, `ArrayList` is the go-to `List` implementation of just about every Java developer I know. Well, apart from uncommon concurrent cases where the false sharing problem outweighs the cache effects of pointer chasing, but then it'd be a LinkedBlockingQueue or something similar – although if I wanted to get really fancy, I'd use a [disruptor](https://github.com/LMAX-Exchange/disruptor) instead.
Rust is not positioned as a backend language, and the existing control structures suffice for all code. If you really wanted, you could litter your code with `loop { ... /* add continue or break here */; ... break; }`. On doing this, you may probably want to consider a career change, though. :-P
Agreed. Case in point: My own [optional](https://crates.io/crates/optional) crate is but a small experiment on how to implement space-efficient optional values for various primitives. When I first published it on github and crates.io, the README [said](https://github.com/llogiq/optional/blob/265ef82e5ecb716e2136a1a1186729425f845ca9/README.md): &gt;This crate is experimental, has no docs and almost no tests. Honestly, I mainly publish it now to embarrass myself. But you know what? Publishing on crates.io motivated me to add docs (and finally read that TRPL docs chapter I had skipped until then) and tests, and now it's actually a semi-decent crate. And I [learned a lot](https://llogiq.github.io/2015/07/23/unsafe.html) from the experience, too! TL;DR: Had I missed out on publishing on crates.io, both my Rust-Fu and the crate would have been worse off.
You can use boxed slice, `Box&lt;[Pixel]&gt;`. It can be created either by boxing an array: let arr: [u32; 4] = [1, 2, 3, 4]; let boxed: Box&lt;[u32]&gt; = Box::new(arr); or out of a `Vec`: let vec: Vec&lt;u32&gt; = vec![1, 2, 3, 4]; let boxed: Box&lt;[u32]&gt; = vec.into_boxed_slice(); Boxed slice is just like a regular slice `&amp;[u32]` except that it owns the data. Therefore, it "knows" the length of the data at runtime. Because `Box&lt;T&gt;` implements `Deref&lt;Target=T&gt;`, you can call regular slice methods on a boxed slice directly, so it is just as easy to work with as regular slices or `Vec`s.
If you wanted more than slices can give you, you could write a wrapper around `Vec` that doesn't expose methods that change the size. Laborious, but it would work. And I'm not sure what there could be that Vec gives you but slices don't that doesn't involve resizing.
Unfortunately, I'm not the one who came up with that "solution". So it probably shouldn't count. :)
To the second: yes. And yes: it would be nice. 
What's wrong with using an immutable Vec? You won't be able to call methods that modify it. There is no reason for Rust to implement a FrozenVec, because you can just freeze a Vec using the language semantics. If you really want something like this, you could implement a struct FrozenVec containing the Vec and implement Deref on it, returning the slice of the Vec.
I've got an answer already, but I will answer this anyway. In a couple of the examples I've given, the Vec is contained within another struct. You cannot make members of a struct constant (AFAIK). The "constantness" of the field depends on the struct that contains it. Also, I may want to modify the contents of the Vec, but not the size of it. To the second point, yes I could do something like that, that is a good suggestion. However, that adds yet another abstraction upon an abstraction, and whilst Rust claims these are "zero-cost", I'm not entirely sure that that would be the case. I'm effectively trying to ignore some features of the Vec. However, those things are still there! (like the push() function... I won't be able to call it, but it will still be there!) As I've mentioned, someone has already told me how to get what I wanted: A boxed slice. You have to construct a Vec to get it (grr...) but you can get a fixed sized array that you own from it, and discard the rest of the Vec that you don't need. :D
&gt; Vec&lt;Vec&lt;Pixel&gt;&gt; Bad idea. The two layers of indirection are unneeded and will only introduce bugs down the line. Just use a Vec&lt;Pixel&gt; that's width*height long and implement the logic for accessing a pixel. [Check out how the image library does it](http://www.piston.rs/image/src/image/buffer.rs.html#209-220), it uses a generic backing that the user can decide on if they want (but is usually a Vec).
Yeah, I know of that way, and I would usually do the simulated 2d-in-1d array myself, I put the 2d Vec in the example because... I don't know why! :P
&gt; Of any single thing in the language, implicit returns are probably the foremost thing that newcomers will raise a critical eyebrow at I'm not sure about this. First of all, everyone having previous exposure to functional languages and/or Ruby will know that. I prefer it - `return` indicates a complex return case and the value flow fits well into the expression-based flow the rest of the language has.
&gt; However, that adds yet another abstraction upon an abstraction, and whilst Rust claims these are "zero-cost", I'm not entirely sure that that would be the case. The only cost of `Wrapper&lt;Vec&lt;T&gt;&gt;` above the wanted `Box&lt;[T]&gt;` would be one extra `capacity` value that you'll never touch. This is *really cheap*, since it's at most an extra `usize` to move around. This is because newtypes are literally free memory wise, and inlining will completely remove any indirection costs. &gt; You have to construct a Vec to get it (grr...) There should be no "grr" here; `Vec`'s allocation is not more expensive than any other allocation.
I see it constantly suggested and defended in /r/java . For example [here](https://www.reddit.com/r/java/comments/3f0qyc/how_does_you_lowlevel_code_knowledge_effects_you/ctk79rj) the user asks "how does low level knowledge affect you" I say "It means I almost always use array lists" and he counters with a quotation from his book about linked lists having fast middle insertion times. It might just be the case that most that I interact with in the reddit and other internet places are somewhat young and inexperienced, but I do run across it a fair amount. I have to admit that in my professional work, I almost never see someone use a linked list. I've only ever had one coworker who thought that linked lists should be used everywhere. Though I have seen a monstrosity where they created a "sortedLinkedList" and to insert they binary searched the linked list (IE, list.get(searchIndex))... Yeah, that was a fun discovery that I killed pretty quickly.
I'd recommend using [multirust](https://github.com/brson/multirust)
check your version by running rustc --version in the terminal
yup. and for updating you just run `multirust update` and it updates all 3 installed versions(e.g. nightly, beta, stable). its really awesome and easy to use.
I've never had that problem. Did you try building your project after setting up your dependencies?
Actually, it's *not* `let &lt;pattern&gt; = &lt;value&gt; in &lt;expr&gt;`, which we have, in the form of `match &lt;value&gt; { &lt;pattern&gt; =&gt; &lt;expr&gt; }`. The difference is the rvalue scope: `let x = Some(&amp;vec![1, 2, 3]); ...` fails to compile because the reference doesn't live long enough, while `match Some(&amp;vec![1, 2, 3]) { x =&gt; {...} }` works. This property is used in some desugarings, such as `format_args!`, to bind values to names while keeping all temporaries live.
Yes, I might be a little edit happy... Some of this I was posting on mobile, and it was hard to look over what I wrote in the small screen. I realize that there are concessions that Rust makes. (Bounds checking on arrays, for example, that can matter when push comes to shove, but most of the time it doesn't matter, and I guess you're right that you can delve into unsafe rust when you decide it's necessary.) Having useless memory floating around doesn't sit right with me, however. If the optimizer will remove it for us, very well. All in all, I've spent too much time arguing about stuff that I don't have the best handle on in the first place, and doesn't really matter to me. I started this post asking for a Dynamic array, people have shown I can get the Rust equivalent. I would suggest to anyone in a position to do anything about it that it would be nice to be able to skip the step of creating a Vec&lt;T&gt; when you only want the Box&lt;[T]&gt;, but I wouldn't be the one to know how exactly to do it. Thanks for your input to the conversation. Cheers.
&gt; I started this post asking for a Dynamic array, people have shown I can get the Rust equivalent. I would suggest to anyone in a position to do anything about it that it would be nice to be able to skip the step of creating a Vec&lt;T&gt; when you only want the Box&lt;[T]&gt;, but I wouldn't be the one to know how exactly to do it. I would be quite curious to see a benchmark that demonstrates that such a construction would actually be beneficial.
Wow this project is super amazing :) props
&gt; I wouldn't be the one to give it. ;) As I just admitted, I've probably been talking about things I don't really understand, only relying on information I've heard second hand, and probably misunderstood. Oh no, totally! I didn't mean it as a challenge. I would just be genuinely curious if *anyone* could provide such a benchmark. &gt; It just seems clunky when I'm writing it. I didn't want a Vec, I wanted a Box&lt;[T]&gt;. Why must I go through hoops just to get that one thing? Well, try to keep this in context: you wanted a `Box&lt;[T]&gt;` because it lacked a method. That reasoning seems a little artificial to me since the extra methods aren't going to result in any perf penalty. If you want to use a `Vec&lt;T&gt;` in code that isn't allowed to grow the `Vec` but can modify it in place, then simply pass `&amp;mut [T]` around.
Note also that if all you do is `vec![0; size].into_boxed_slice()`, then that extra temporary `usize` field is most likely not going to appear in the compiled code at all, because llvm will see that it gets initialized to the same value as the size and then ignored, so it will be dead-code eliminated.
Thanks!
If you do CI, have it test against all three versions, for development, it's okay to work on nightly, but just know what features work and what don't in beta and stable. A lot of users stick to the stable channel now so that they aren't using APIs that might change. So, I'd say, test in beta and nightly, but write for stable (if you can). Though, you're more than free to use Rust however you like :)
That actually would be a really nice feature of Cargo. I don't know that Cargo should necessarily download the Rust toolchain, but it'd be nice if it would allow you to specify the toolchain if multiple are installed. I feel like Cargo actually downloading the specific revision is somewhat scope creep on what Cargo is supposed to do.
I'd just install it into a custom prefix and nuke the whole prefix every time you upgrade.
&gt; They seem dirty, After some expirience with Rust explicit returns will start to seem dirty
Hm okay. I'm not a Cargo maintainer or anything, so I was just speaking from personal experience. That would be a cool feature though.
Im not knocking cargo -- i think the whole toolchain is the best thing going right now.
I wasn't trying to imply you were. Cargo is definitely a great tool and puts Rust miles ahead of traditional systems languages like C or C++ (since they lack a package/dependency manager).
In Arch Linux you just use pacman (the package manager) ;) Isn't it available as a package in your distribution?
Anything that takes an IP address takes an enum that specifies the address family, you just need to handle both cases explicitly.
http://imgur.com/QzE8YF7
A great multirust feature is that it can pin a given project to a given Rust version (with `multirust override`), while your other projects use another. This reduces the friction of switching to unstable if you need a certain feature. The `rustc` in your PATH is just a shell script that checks your current directory to run the right Rust version (this way, `cargo build` respects your override without even knowing about multirust).
I don't know about OP but I'm in for something like that. I have a reasonable amount of programming experience but only just now getting into rust.
Or use Linuxbrew to make that easier. 
Ripped straight from Python :)
I would agree. In Scala world, downloading a new version of SBT is almost the same as downloading a normal project dependency. It's just a java archive (*.jre) which is then run. In Rust, however, dependencies and `rustc` seem to be very different beasts.
Feel free to PM me drafts if you need someone to catch typos and proofread.
Except via `try!()`...
The other languages I use all have `return` or `yield`, but I looked at Haskell for a bit and found the functional approach really cool. When I first saw the implicit return in Rust I didn't really stumble over it. The borrow checker, *yes*, but not implicit returns. I actually prefer it now, and I really like pattern matching and `let` binding. Now it feels weird to look at an unnecessary `return` in Rust.
`vec![x; n].into_boxed_slice()` is basically optimal modulo placement new shenanigans because the capacity is perfect. Should even optimize to a memset or whatever when possible (like, actually -- llvm doesn't need to be super smart for this one like Extend).
What a gapbuffer is and why to use it is a really important part of this. Comparing different data structures for text buffers: from naive array, to naive 2d array, to gapbuffer, *possibly* even on to ropes and finger trees. And there's a gapbuffer crate on crates.io btw. :-)
The intrinsic will get you the exact same thing. It sounds like the generic target you're compiling for doesn't necessarily support the instruction - is it 32-bit x86 by any chance? See `target-cpu` and `target-feature` in `rustc -C help` for a way to enable CPU features that are not on by default. 
I don't know what the problem is but both Stdout and File implement Write. You should be able to use a generic BufWriter&lt;W&gt; and instantiate it with the correct inner value depending on the switch. What code did you see break? Probably there is a simple way to refactor it to make it work.
Something like that probably: use std::fs::File; use std::io::Write; use std::io::BufWriter; use std::io; use std::fmt; use std::env; fn main() { let mut output : BufWriter&lt;_&gt; = BufWriter::new( if let Some(filename) = env::args().nth(1) { File::create(filename).unwrap() } else { io::stdout() }); output.write_fmt(format_args!("It works\n")); } I also don't know solution. 
Your option sounds pretty swell, an alternative might be to just use a `Write` trait objects to elide the BufWriter (and its type parameter) from user code entirely: http://is.gd/QRBi2I The dispatch will be a bit less efficient (since it'll be dynamic rather than static), and it requires an additional heap allocation (unless you can use `&amp;mut Write` through the code) but I'm guessing that'll be invisible compared to the cost of IO itself.
Already great answers here. I just wanted to add another way to think about it: Imagine that the `;` is just a binary operator that first evaluates the left operand, discards it's value, evaluates the left operand and uses it's value. The "everything is an expression" idea is pretty nice. Although it's not exactly how it works in Rust. When thinking about it, early returns via `return` keyword are actually the dirty ones, that are strange.
A la C's comma operator. Good point.
Following [This Week In Rust](http://this-week-in-rust.org/) is really the best way to keep abreast of that kind of thing without diving into the active repositories. It summarized the reports from the different teams and also has other Rust news. A list of features and their status would be hard to maintain comprehensively because the project is somewhat decentralized and what counts as a feature and what counts as working on it is something that can actually be ambiguous. As to type-level integer parameters, currently there is no RFC proposal.
You don't need the casts if you type output as a `BufWriter&lt;Box&lt;Write&gt;&gt;`, which is slightly shorter overall. And the `BufWriter::new` invocation can be outside the conditional since both branches return a `Box&lt;Write&gt;`. So you can define `output` as: let mut output : BufWriter&lt;Box&lt;Write&gt;&gt; = BufWriter::new(if condition { Box::new(File::create(filename).unwrap()) } else { Box::new(stdout()) });
I'm already following TWIR and it's great but it doesn't offer the exact information I want (probably because nothing was happening about type-level integer, I haven't read anything about it, hence I didn't know). Sure it's always a bit hard to keep something like that up to date, but I guess its possible ;) I remember that someone (I think steve) posted a huge text on the internals forum about important things after `1.0`. Maybe we could at least track those?
Yep, gouvernance makes me uneasy. Have FinanceJobs.com any special relation to the rust community ? I mean, if we need mailing lists, I believe several people (including me) would be happy to host a mailing list server under lists.rustaceans.org or something like that...
I agree with @levansfg. Something under the governance of Mozilla's seems a better solution here (and the fact it is FinanceJobs.com makes me really uneasy).
&gt; Something under the governance of Mozilla's seems a better solution here (and the fact it FinanceJobs.com makes me really uneasy). Mozilla closed their rust-dev mailing list. Although I could be wrong about this, but it was deliberate to show that they didn't want to be seen as controlling the community as well as the language by hosting the main communication channels too. Could I ask why you find that Finance Jobs makes you uneasy?
&gt; But Rust thinks that each closure/function has its own unique type. Well, they *do*. Every function item has a unique type to help the optimiser do static dispatch in more cases. To get around this, you need to explicitly cast the function item type to the common function pointer type: let x_get = get_x as fn(PointAndRadii) -&gt; f32; In most cases, there's enough information to allow most of that to be inferred: let x_get = get_x as fn(_) -&gt; _; 
&gt; do people actually want such mailing lists Some people prefer mailing lists over website forums, lots of open-source projects use them, much of the IETF's standards work are done over mailing lists, and there is nothing stopping from mirroring the mail on rustaceans.com. In fact, we'd be happy if people did!
&gt; but it was deliberate to show that they didn't want to be seen as controlling the community as well as the language by hosting the main communication channels too. I'm not sure where you got that idea? Mozilla supports [users.rust-lang.org](https://users.rust-lang.org/). AIUI, the mailing list was shut down in part because it was hard to moderate.
`lib.rs`: mod doc; // make rustdoc pretend Document was defined *here* #[doc(inline)] pub use doc::Document; // ... `doc.rs`: pub struct Document { ... } // ... 
whoa thanks
Normally RFC pull request don't show up here on Reddit, but I think it may be interesting to some, and would like to get some eyeballs :)
&gt; As to type-level integer parameters, currently there is no RFC proposal. I just discussed this, and I think the in-progress associated constants will/may lay all the necessary groundwork for this. Basically making associated consts work at the type level (`[T; A::LEN]`) is the same problem as implementing type level integers.
We just opened one Issue per unstable feature, with the hopes of making a dashboard out of it.
You are right, I was thinking about using Vec&lt;_&gt; until integer as type parameters land in Rust. Your trait interface is better anyways ;-) Just a note about performance, using pointer to function is dynamic, using trait as bound of type parameter is static. 
Just wanted to say, I'm also interested and this sounds amazing.
You could make the BufferedWriter's inner value a trait object, like: struct BufferedWriter { writer: &amp;Write, } impl BufferedWriter { fn new(inner: &amp;Write) { return BufferedWriter { writer: inner, }; } } But then the File/io would have to outlive the BufferedWriter. You'd probably want this anyway, however.
The `&amp;` isn't correct: just `get_x as fn(...)` is what you need.
Yes.
As a newly hatched rustacean I would find this if great interest too.
Cool thanks. I was just wondering since I'm not going to be at a Rusted computer for a couple of days.
We do this with [clog](https://github.com/clog-tool/clog-cli), where the default is to write to `stdout`, but a user can pass in a switch (or use a TOML configuration file) to write to a file instead (of course shell redirection works as well). But we also have to deal with depending on certain command line switches, the writing can be done in different formats (Markdown vs JSON). The point behind this, the easiest way to accomplish this is to use a a generic function parameter over a `Write` trait. (We also use a custom trait for handling the JSON/Markdown differentiation). For example, the function to do the actual writing could be something like: fn write_output&lt;W: Write&gt;(w: &amp;mut W, stuff: &amp;str) -&gt; io::Result&lt;()&gt; { write!(w, "{}", stuff) } You could call this function using either `stdout` or a `File`. Here's an over simplified version, but you should get the idea. let mut f = File::create("some_file.txt").ok().unwrap(); write_output(&amp;mut f, "stuff to write") write_output(&amp;mut io::stdout(), "stuff to write") Now this doesn't address things such as if it's a good idea to use a command line switch to denote an output file or not, or just use shell redirection, but only you'd know that for your particular use case :) For the interested, I've been working on a series of posts related to exactly that; designing a CLI. Edit: Also, it should probably be noted that a `BufWriter` would be way more efficient, but the concept is the same because `BufWriter` implements `Write`.
Nifty PDF but if you don't know what MIR is like I do (obviously it's about the [russian space station](http://www.crunchyroll.com/fairy-tail/episode-153-song-of-the-stars-609391) which wikipedia pulls up at seach) or why MIR is desired, it's a little less helpful. [EDIT] Ah, it's in the title of the third RFC listed there.
I wrote a quick summary on HN the other day too https://news.ycombinator.com/item?id=10041924
That's good. Honestly, a lot of these RFCs need a "Summary for dummies" at the top for those people who just dropped in to look at it and don't know anything about it. Even the RFC summaries aren't always helpful unless you read the a lot more than the summary.
Yes, and integer type params must be, too
This is what I wrote [coalesce](https://crates.io/crates/coalesce) for, it provides macros around enums that have types that are distinct but similar / share a common trait. For example: #[macro_use] extern crate coalesce; use coalesce::Coalesce2; let mut output = if let Some(filename) = env::args().nth(1) { Coalesce2::A(File::create(filename).unwrap()) } else { Coalesce2::B(io::stdout()) }; let output = coalesce!(2 =&gt; |ref mut output| output as &amp;mut Write); output.write_all(b"stuff!").unwrap(); This doesn't do heap allocations, but will use dynamic dispatch through the trait object. If possible, though, desiringmachines' example is the best approach to take.
This subreddit is for Rust the programming language, not Rust the game. Did you mean to post this to /r/playrust ?
Did you ever figure something out for this?
&gt; #!/bin/sh -eu Did not occur to me that this would actually work. Can you explain how `#!/bin/sh -eu` gets past the compiler? Why Is it valid rust code? Also, as far as dropping cargo goes, you can cram it in a one-liner in true lambda fashon. Meet Darf's predecessor: //bin/true Darf v1.1; BIN=$HOME/.`basename "$0"`.bin; [ \( -x "$BIN" \) -a \( "$0" -ot "$BIN" \) ] || rustc -o "$BIN" "$0" $ARGS || exit $?; "$BIN" "$@"; exit $?; 
&gt; Install syntax highlighting for rust I think `rust.vim` does much more than that ... but I can't find a good documentation for it
The `sh` script says: * comment line ("shebang") * comment line * if the binary is older than source, or if binary does not exist, re-compile * start the binary * end-of-script marker !# The `Rust` program says: * mysterious line starting with "#" that is dropped off by `rustc`. (Thanks, rustc :) * a Rust attribute * /*comment starts * comment ends*/ * the Rust code of your script
If you try to combine the types, functions, etc. of two different versions (such as storing, on the same `Vec`, types coming from different versions of the crate), there will be a type error. They are considered different crates. I find this Cargo tendency of matching different versions concerning. At very least it should give a warning; and Piston, in particular, should match their `Cargo.lock` files across their crates to never have different versions of their own internal dependencies. But there should be a facility to prevent this from happening. It's sometimes unavoidable: for example, if there's a data structure package with a 1.x and 2.x versions, both mutually incompatible, used by two crates for two unrelated tasks. But it should be a last resort - say, until one of the crates is updated to use the 2.x interface. Otherwise there's an increase in compile times, code bloat, etc.
That's a neat trick. I'd never twigged that you could use attributes to set up a multilanguage program between Rust and bash. There's also [`cargo-script`](https://github.com/DanielKeep/cargo-script), which does *broadly* the same thing, but cross-platform. It doesn't yet allow direct execution of a Rust script, as I'm waiting for `cargo-install` to happen before I tackle that. It also has a few other tricks up its sleeve (executing expressions and loops, automatic cache cleanup, versioned dependencies).
While a neat trick, I would rather like to see Rust adopt the same approach of other languages with a dual REPL/JIT, AOT backends.
Sorry, this time my writing is rather dull and I don't even come up with a solution... but hopefully we shall at least have an interesting discussion here.
Would it make sense to add even more coercion, on closures, so that `over(left, right, is_exp_equal)` would work?
The representation of `P&lt;Vec&lt;T&gt;&gt;` isn't bitwise identical to the representation of `&amp;[T]`, so we would need a shim function to translate between the 2, and that would be problematic.
Given one is just going to wrap it anyway, what's problematic about doing it automatically, especially if it makes eta equivalence obvious?
I went that way for a while but the Document struct is the main reason behind this crate so this is a no-go
Pre'dback?
Better IDE integration, specialization, non-lexical borrows, stable plugins, cargo install...if you folks can deliver that, there will be many very happy Rustaceans indeed.
On a side note, in your twitter bio: s/Rustacian/Rustacean/
This is a great vision statement and execution plan. The Rust ecosystem is leaps and bounds ahead of C/C++ in many ways, I'm really looking forwards to what it'll be like in a year's time.
The slides should all be linked, and the videos will come out sometime, we can't say exactly when.
Thanks for the feedback! A stable ABI is absolutely something the core team is interested in, but it hasn't been a near-term focus for a couple reasons: - General instability of language internals. Even our calling conventions for the function traits are unstable at the moment. While we pushed hard for user-facing stability in 1.0, there's still some way to go before we're ready to make any representation/ABI promises for language internals. - Given where Rust is right now, it's likeliest to be used for components of a larger system, in which case the C ABI is usually the right option anyway. Hopefully this will change over time, but this post is outlining priorities for the next year or so. - Reaching a stable ABI for Rust is a massive undertaking and, in our judgment, applying our limited bandwidth to the items outlined in the post is likely to have a bigger impact within the next year. All that said, the priorities we gave in the post are of course not set in stone, and it would be great to at least start discussions on what would need to be done to make this happen -- I'd encourage you to start a [discuss thread](http://internals.rust-lang.org/) on the topic. We also have a [stub tracking issue](https://github.com/rust-lang/rfcs/issues/600) which should be filled in with the various known obstacles/big questions for doing this with Rust.
Right now, borrows are based entirely on lexical scope: fn main() { let mut v = vec![1, 2, 3]; let r = &amp;mut v[0]; println!("{}", r); v.push(5); } This code fails, because `r` lives until the end of `main()`, and so `v.push()` causes two mutable borrows: error: cannot borrow `v` as mutable more than once at a time v.push(5); ^ note: previous borrow of `v` occurs here; the mutable borrow prevents subsequent moves, borrows, or modification of `v` until the borrow ends let r = &amp;mut v[0]; ^ note: previous borrow ends here fn main() { } ^ With non-lexical borrows, this code would work: the compiler can see that `r` isn't used after the `println!`, and give up the borrow there instead. What's interesting to me about SEME regions/non-lexical borrows is that it's a great example of a tradeoff: Right now, the borrow checker's rules are very straightforward: references live for the entire lexical scope that they're alive. However, the downside of this is that sometimes you want the scope to end early, and so you have to code around it. With non-lexical borrows, the rules get much more complex: borrows are determined by the control flow graph, not lexical scope. However, you no longer need to code around those edge cases. So the question of which is better really comes down to a question: do programmers find reasoning about lexical scope or the CFG more intuitive? It would appear the latter is the case, which is kind of surprising for me, but maybe it shouldn't be.
One of the major motivating examples is allowing something like the following to work: let mut v = vec![1, 2, ...]; match v.get_mut(n) { Some(x) =&gt; *x += 2; None =&gt; v.push(n) } `get_mut` is `(&amp;'a mut self) -&gt; Option&lt;&amp;'a mut T&gt;`, that is, the return value is a borrow out of the vector. It's a mutable borrow, meaning can be no other accesses to the vector while it exists. The code above uses the borrow in one arm, but has an arm that literally can't interact with that borrow at all (the `None` doesn't store any references). The compiler currently disallows the code, because the borrow extends for the whole `match` and hence the call to `push` is considered dangerous, but non-lexical borrows mean the compiler understands that the borrow doesn't apply to the `None` arm; the compiler will be able to "follow" the control flow of the actual borrowed references.
Thanks Steve. I see 3 talks missing the slides here, I'll wait for the videos then.
Ah! i'll track them down, I thought we had all of them.
The problem is that there are a bunch of roadblocks the team must overcome before they can land specialization. Apparently, it is currently blocked on pnkfelix' dropck pruning as well as a number of bikeshedding issues.
&gt; Are you aware of https://github.com/rust-lang/rfcs/pull/1210 Yes, that is the specialization RFC. What I meant is that I wish the other "missing" pieces of generics in Rust were also on the roadmap.
IIRC what I read about the MIR said that it would allow developing these features faster but I sadly don't know enough about rustc internals to understand/fully appreciate the MIR RFC.
&gt;We're working right now with some academic groups to produce a small formal model of Rust's type system that will make it easier to explore extensions. What does this mean/ involve?
Is there a timeline for this? A smarter borrowchecker seems like it would have a huge impact on adoption.
Anonymized return types do not require HKT by themselves. The original `impl Trait` RFC also has other features, such as anonymous generics (in argument positions) and anonymous associated types (in trait definitions), maybe one of those does?
When I first heard about Rust, I imagined the CFG-based borrow would be the default! I was surprised to see lexical borrows.
The latter is what I had in mind (in the presence of generics on the functions that `impl Trait` is used in).
Great, I look forward to it!
[Here's a link directly to the youtube playlist](https://www.youtube.com/playlist?list=PLE7tQUdRKcybdIw61JpCoo89i4pWU5f_t)
That helps a lot, thank you. Could you elaborate on the foundations of these mathematical models? Is this something like category/ type theory?
awesome!
It has its roots in type theory, yes. But the approach that Derek's group takes involves building a whole language of assertions about programs (sometimes called a "program logic") and then interpreting types as particular assertions (which would imply things like "never dereferences a null pointer"). Then you prove that the type checking done by the compiler actually guarantees that the corresponding assertions are true about the program. The advantage of this approach is that the type checker isn't the *only* way you can prove these assertions -- which is exactly what we want when validating that unsafe code meets the contract for safe Rust. There's a whole grant proposal on this topic; if you email me at aturon@mozilla.com, I'd be happy to send it to you :)
The MIR replaces the omnipresent AST in the compiler. If you know what an AST is, imagine you *didn't* have it, but instead were using slices of the original string input, and you would reparse every time you wanted to know what an expression does. Moving from the AST to the MIR is just like moving from such a shoddy string contraption^1 to an AST. ^(^1 Actually, JS engines employ that string scheme with varying degrees of success, keeping ASTs and control-flow graphs around only when interpreting or JIT-ing a function.)
Update: there's a real one now! https://internals.rust-lang.org/t/psa-stabilization-tracking-on-the-libs-team/2493/2
Definitely; we've known for a while that you can "encode" HKT by lifting out parameters and using assoc types in many cases. But I'd rather not grow up an ecosystem around this encoding if we can avoid it :)
See the [thread above](https://www.reddit.com/r/rust/comments/3gzidr/rust_in_2016/cu2yeiu) for some comments on this.
I know emscripten support is an RFC out there and I get its not high priority or anything, but I was curious - when you eventually get around to it, would the tracing hooks feature be something that could actually be used or helpful in that scenario to interact with javascript code running in the browser?
Bashing rust with rusting bash, cool!
We're making a lot of progress in this direction -- see the reports for this week (libs in particular)! https://internals.rust-lang.org/t/subteam-reports-2015-08-14/2509
[Here's the lexer hack that makes this work](https://github.com/rust-lang/rust/blob/master/src/libsyntax/parse/lexer/mod.rs#L470). It's checking that the first two tokens are `#!` and the third token is not `[`. This does exclude some valid shebangs that run the `[` command...
A bit off-topic but I was curious if there was going to be a request for feedback from the attendees. Would possibly be good to get a sense of what talks were most relevant/useful to benefit future events.
Looking at the schedule listed next to each talk, it looks like the second of the two half-length talks that preceded her talk bumped it from the website's schedule.
Mouse events aren't part of the compiler or the standard library, and probably never will. 
Damn so promising. You are doing things right.
The thing is, not everything can be a priority. Regardless of how real the concerns are, we can't focus on every feature or shortcoming. What on that list do you think should be replaced? Work on crater? Maybe IDE support? The massive compiler restructure that the MIR will bring? Don't get me wrong, I'm not saying your concerns aren't important, it's just that while the language itself has stabilized massively, the internals are still in significant flux. A stable ABI is like a second 1.0, there's no going back. We'll get there eventually, but there's just so many things to address first that we can't focus on it in a meaningful way. 
Not exactly. This is actually quite likely to happen (for all collections, too, HashMap and BTreeMap included) once we get an allocator API and make `Vec` generic over it. Then it would be re-exported from std, with a default for the allocator type parameter.
Well Rust didn't even start with a borrowing system. Furthermore, **borrows** are based on dataflow, but **lifetimes** are not. We detect the overlap in the lifetime of a borrow. If this wasn't the case, things like breaking from a loop would cause errors in cases where a value is borrowed in a path, but control can't actually go down that path twice, (for example in a loop with a conditional break). This basically just applies dataflow reasoning to lifetimes as well. It's trickier than lexical scopes and less obvious.
Depressing. Why are embedded systems stuck in the 70s, and why can't Rust help!
Here are some suggestions. Project: 1. It is great that you picked a tangible goal to start with. And that you seek help. However please remember that this has to be your project if you want to learn rust. So step one is always keep the scope very very limited and specific. No Feature creep. Since in this case, you want to make another NotePad, you can do a lot of good by listing the feature set. 2. It is much easier for you to get help if you start an online repo and invite reviews. It may seem a bit "out there" when you consider yourself as a total newbie and don't know where to start. But, You already took the first step and posted here. Starting a repo online is also like that. At this point all it needs is a good README explaining your goals, and hopefully tracking your progress. 3. You can use the online repo as a notebook to collect relevant info, like research into data structures, libraries/crates and snippets from online and real life discussions. TL;DR : 1. Freeze requirements. 2. start a repo, 3. keep it updated with your progress. Product / Technical: CLI args parsing is the easiest part. Please look up clap [ https://crates.io/crates/clap ]. There are other options like docopt and getopts too but I hope you will find the time and interest to evaluate them, make a choice and write about your "why". Please do post a link to your repo here.
Mouse events are handled by glutin/xlib/some other libs
Dependencies in Piston crates are cross-checked as much as possible but there's a lot more crates than there are active contributors, and not all of the crates depended upon by Piston are in the team's control. You can help: if you see redundant crates being built, try to find their dependants in your `Cargo.lock` and let those crates' owners know. Also make sure you're checking your own dependencies' versions. If you have two different crates that pull in the same dependencies but different versions of them, one of them might be the wrong version itself. 
Full ack; it's already getting somewhat unwieldy with Iterators.
Agreed. On the other hand, I remember sometimes having to introduce let bindings for certain things to appease the borrow checker. Perhaps this *has* lead to improved code, but I paid for it with more development time, the readability isn't measurably better, and the generated LLVM IR would be the same.
I agree, It's a shame that this example was used in the blog post. Currently, the borrow checker is kind of acting like a lint for that example.
Been waiting for this, thanks!
I think Gecko is a bit hard to embed, but Blink is easier. https://bitbucket.org/chromiumembedded/cef might help too, Servo has bindings for that in one direction.
Dependency conflicts has become a major productivity problem. On the upside it breaks less for users. There are plans to use a tool for detecting libraries that needs update and it should also be able to detect dependency conflicts, see https://github.com/pistondevelopers/eco. Plans are ready, all we need is implementing them. PRs are welcome!
Because embedded systems is a very general concept where there's a lot of "defined per system" datapoints such as the memory layout. It's hard to do anything abstract when you can't assume a heap actually exists.
Can you have a vector or tuple data types with static memory?
Tuples don't need to grow dynamically, so they can absolutely be placed in static memory (and this works today: `static FOO: (i32, i32) = (1, 2);`).
It was a unique talk about a subject I care about and we should all be aware of. Wherever it is I hope it's recovered.
Rust enums definitely spoil me when writing state machines too. Having tuple structs as variants, solid typechecking, and exhaustiveness in patterns makes for some really beautiful code you pretty much know will work (so long as you reasoned it out properly). Is the concept of making an enum variant a type itself still a possible addition to the language? What would that look like? The ergonomics benefit alone would be great.
The most elegant finite state machine would probably use tail calls for transitions and enforce legal transitions via the type system.
If you want the variants to be types, you probably want a trait and structs which implement it, rather than an enum.
CEF is *the* way to embed a rendering engine right now, although DOM manipulation is trickier.
Yeah, this is pretty tame. Who wants to implement a FSM directly anyway, that's what Ragel is for. 
At least in the debug mode, the [if-let](http://is.gd/iPk6H5) and the [match](http://is.gd/tqCYdh) variant produce the same ASM code, while the code produced by the [for](http://is.gd/0hsnRL)-variant is longer. In release mode they are all the same. What a nice optimizer we have...
And there's also of course `a_opt.map(|a| println!("{}", a))`.
Maybe it's just me, but I'm not a big fan of `map`s having side-effects. I'd much prefer an if-let here.
Not necessarily. Traits are open to extension via future implementations while enums are closed to extension. The want here is so that you don't have to do... struct X; struct Y; enum A { x(X), y(Y) }
Say the variants were types -- would the enum become a trait? A quick perusal of the docs suggests that Rust does not have subtyping.
Both solutions fail to signal the needed alignment for the struct to rustc. In this case you can solve it easily with `_align: [u32; 0]`.
This is actually my favorite for simple operations on the `Option` value. I just think it looks clearer in those cases.
correct
&gt; Adding a Java-like proper enumeration listing might be useful, but I guess it would require **several unstable features** such as **syntax extensions** and custom #[derive]s. [Pfft](https://github.com/DanielKeep/rust-custom-derive/blob/master/tests/enum_iterator.rs#L55-L64). &gt; `unsafe { transmute::&lt;_, Color&gt;(i) }` [Pfffffft](https://github.com/DanielKeep/rust-custom-derive/blob/master/tests/enum_try_from.rs#L57-L68).
was about to comment, that there was a cef-rs project, but was a bit outdated, turns out it is your project and seems updated since the last time i check it out.
Tuples don't rely on std.
Use `opt.and_then(|v| print!("{}", v); Some(()))` then :-)
&gt; a tagged union, which is also called an algebraic data type Algebraic data type is not another name of tagged union. Algebraic data types also include product types (tupples and structs). They are called algebraic because there are certain algebraic properties.
I also think if let is far better in this situation. In the for variant I have to be aware of the context: Ok, so this is an Option, ergo the loop only runs once. In the if let variant, everything is expressed explicitly and I have two brain cycles left for more important things than syntax. Also, since if is an expression, it's more flexible. You can easily extend it to something like let o = Some(1); println!("{}", if let Some(v) = o { v } else { -1 }); It's a bit contrived here I'll admit.
 if let Some(a) = a_opt { println!("{}", a); } is much Rustier in my opinion, and it certainly makes more instant sense than iterating over a single value. It also tells the compiler that the inner block acts like a FnOnce instead of a FnMut (the latter of which is subject to stricter rules since it can be called multiple times). This means that if you want to send 'a' to a consuming function you cannot do it with the for trick you have shown. Also, if you do a single-nontrivial-arm match expression rust-clippy will tell you to use an 'if let' and rust-clippy is the ultimate repository of all knowledge both past and future.
Will not compile, the fn passed to and_then must return an Option.
&gt; opt.and_then(|v| print!("{}", v)) This won't work - the closure you pass to `and_then` must return an `Option`: http://is.gd/hUXiS1
It's still nowhere near ready for a release yet though. Keyboard input is tricky. It works alright with a pending PR to glutin on Windows, but other platforms will be more fiddly to get right. There's also no semblance of documentation yet.
Due to laziness, Rust's `Iterator` is actually pretty close to Haskell's built-in "list" type, `[]`.
Another way of encoding FSMs in Rust is simply to use call by value: struct A; struct B; struct C; fn start(A) -&gt; B; fn loop(B) -&gt; B; fn end(B) -&gt; C; Though of course it only really works if the state transitions only occur at compilation time.
We'll do something about it: https://github.com/Manishearth/rust-clippy/issues/182
This just made me realize that `filter_map` is completely redundant as `flat_map` can do exactly the same and more. fn main() { let a = [Some(1), None, Some(2)]; for i in a.iter().flat_map(|x| x.as_ref()) { println!("{}", i); } for i in a.iter().filter_map(|x| x.as_ref()) { println!("{}", i); } } 
I am not sure whether this is needed, but I was bored and made this. Please tell me what you think :)
Auto completion is also supported in Emacs via Racer and Company mode. Also, is there a difference between "auto-complete" and "code completion"? Some tools mention auto-complete while others code completion.
Thanks, added. I think, there's no difference; reworded everthing to "code completion".
Atom has also a few packages for rust: - [language-rust](https://atom.io/packages/language-rust) *"Adds syntax highlighting and snippets"* - [linter-rust](https://atom.io/packages/linter-rust) *"Linting your Rust-files in Atom, using rustc and cargo."* Basically this gives you all the compiler errors directly into Atom. Saves me a lot of back-and-forth between my code and Cargo. - [racer](https://atom.io/packages/racer) *"Providing intelligent code completion and "find definition" for Rust via Racer"* There are other packages for Rust but I haven't tested them :)
Added to https://wiki.mozilla.org/Areweyet
Thanks, thats exactly what I needed
Yeah Atom is pretty good for Rust, I like it a lot :) &gt; Though, if Racer ever becomes a proper library/long-lived process and YCM adds a semantic completer for it, I'll probably switch back to Vim/gVim. I have never given vim a real try. I use it when I have to edit config files from the console but that's about it. ;)
At this point, I can't really use a text editor without Vim-style keybindings, so if it doesn't have a package for it, I can't really be effective. I'm too used to switching between insert and command mode and using those text navigation shortcuts. I love Vim, but Atom is nice and modern. It's just that Vim isn't always the best editor for the job with everything. Also, Atom will always look prettier than Vim :)
Data is a too generic name. It works in Haskell because they unified structs and tagged unions IIRC.
I put them onto the list. Getting crowded :)
There's also ctags support for vim and emacs with rusty-tags
Thanks :) It's maybe worth mentioning that the linter package does not only "lint" but gives you all the errors from the compiler. Syntax errors, borrowing errors, ... 
https://github.com/Geal/nom
Yeah, aliasing `&amp;mut` is nasty. Your approach seems better in this case. If only we had `#[field_offset(0)]` like C# does... 
I need them for C ffi, unions inside structs are often used there. And union variants can have different sizes, in which case `transmute` won't help.
I got to say, I find tools like racer (and merlin for OCaml) to be such good ideas: provide a service that any editor can query and use at its own discretion. Also, it brings the Emacs, vim, Sublime and Atom people together, because we all benefit from a single tool.
I just used PhantomData because the compiler complains if I don't really. It doesn't handle alignment.
My problem is that atom's keybindings aren't complete. It doesn't have all of the modes :(
Yeah, there's still a way to go (if they even intend to fully emulate Vim keybindings), but it's better than nothing.
Do you mean like this: https://plugins.jetbrains.com/plugin/7438?pr= ? I'll add that tomorrow, thanks ;)
I use vim exclusively (and with a relatively small .vimrc). I was wondering what the features of IDEs that people want are, that aren't enabled for Rust? Not at all combative, just curious to see what the features of these workflows are.
&gt; This means that if you want to send 'a' to a consuming function you cannot do it with the for trick you have shown. Well, I just did it, so it doesn't look like there's any problem with `FnMut`: enum Test { A { b: i32, c: i32 }, B(i32, i32), C } fn f(x: Test) { match x { Test::A { b, c } =&gt; println!("A, b = {}, c = {}", b, c), Test::B(x, y) =&gt; println!("B, x = {}, y = {}", x, y), Test::C =&gt; println!("C") } } fn main() { let test_opt = Some(Test::A { b: 1, c: 2 }); for test in test_opt { f(test); } }
Recursion limit is only a problem for really large structs in this case, and in that situation recursion limit isn't your largest problem :)
Never managed to make it work ...
Would be good to have support for debugging as well (gdb or lldb). This is what I miss the most.
RustDT has: https://github.com/RustDT/RustDT/blob/latest/documentation/Features.md#features
I *didn't*. Turns out you can raise the recursion limit in stable, so I stopped worrying about it too much. To give you an idea of how far you can get before that happens, in the [`arith.rs`](https://github.com/DanielKeep/rust-custom-derive/blob/master/newtype_derive/tests/arith.rs) test, it makes it to *roughly* `NewtypeShr(&amp;self)` before it runs out of headroom.
Besides having syntastic+rust.vim for syntactic checking as others already said, vim has ultisnip+vim-snippets that provide a few rust snippets.
Have you seen http://stackoverflow.com/questions/30869007/how-to-benchmark-memory-usage-of-a-function/ ?