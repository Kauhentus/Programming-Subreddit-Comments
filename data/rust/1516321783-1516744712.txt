How do you plan on getting around the allocator size problem? Are you (can you?) going to distribute it as a separate WASM module?
There are plans to allow dynamic linking between wasm modules, but its not possible yet. For now, we'll leave it as-is. As mentioned in the article, it isn't *that* bad since its a one-time fixed cost, and is not going to grow if we port more of the JS bits to wasm. Longer term: dynamic linking, so that everyone can share the allocator implementation, and replacing the global allocator with a smaller one once that's stable.
&gt; Python has several kinds of format strings these days. Some Python examples: &gt; &gt; '{0}, {1}, {2}'.format('a', 'b', 'c') &gt; or &gt; &gt; 'Coordinates: {latitude}, {longitude}'.format(latitude='37.24N', longitude='-115.81W') &gt; In the case of your string "Steve Jobs", it's still a format string, just one that has no placeholders to be substituted with real values. But, println! still needs to know that there are no substitutions to be made, and it can only know that if the literal string "Steve Jobs" is the first argument. If it isn't, the println! just sees a blackbox. &gt; &gt; println! inherently uses the first argument as a formatting string. println!("{}", name) provides a formatting string that will have one substitution, and then you provide the substitution as name. You could do something like println!("{} lives at {} in the great city of {}", name, address, city) and it would substitute in those three parameters at the locations of the three placeholders. I'm actually not at all confused about how to use placeholders and what makes them awesome. I was just so confused about why I can't simply print out a variable. This is like the most basic task EVER. :-) From a few other comments in this thread I got the impression that this is mostly a design decision, but you writing this: &gt;If println! allowed you to pass in a format string which is not a string literal, as an identifier, then everything would have to be done dynamically at run time, which would be less efficient than determining exactly how to print the string efficiently at compile time, when it doesn't matter how long it would take. When done dynamically, it also wouldn't be able to type check the substitutions in that format string, or check how many placeholders are in the string versus how many arguments are provided. Rust likes to catch mistakes at compile time, before your code is deployed to production. sounds like there's also some "sense" behind this. I promise this is the last question about this: How do other compiled languages handle this? I just googled how it's done in C, and it's done in the same way, meaning (placeholder, variable). Is this the case for all/most compiled languages?
&gt; I promise this is the last question about this: How do other compiled languages handle this? I just googled how it's done in C, and it's done in the same way, meaning (placeholder, variable). Is this the case for all/most compiled languages? It is done similarly in most languages that I know, but there are differences. Rust is one of the only ones that provides compile-time safety on the print function. In C, you might say `printf("%d years old\n", age)`, but it doesn't *check* anything at compile time. It doesn't even check most things at runtime. It will just dynamically *attempt* to print `age` as an integer, because `%d` is for integers. If you say `printf("His name is %s\n", age)`, then it will try to print out `age` as a string, even if it's just an integer, which could result in your program doing anything... C makes no promises. Crashing the program, erasing your hard drive, or charging $1000 to your credit card, who knows what it might choose to do! Additionally, in C this is all done at runtime. It has to waste time parsing your format string and doing other things while the program could be doing better things. In Rust, the format string does not even exist at runtime. It is analyzed at compile time, and broken down into the actual chunks that are needed. Most languages are safer than C when it comes to format strings, and they will just dynamically realize something is wrong at runtime and guarantee that they will just create an exception, which could crash your program, but it definitely won't erase your hard drive or cut down the tree in front of your house... or whatever undefined behavior might occur with C. There are very few guarantees in C about what will happen if you violate your promise to provide a variable of the right type to `printf`. With Rust, you have much stronger guarantees that are enforced at compile time, even if the syntax is very similar to what most other programming languages do.
That did indeed confuse me, thanks for clearing that up. And once again: Thanks so much for your help. I know this is a ridiculously basic and unimportant problem. But when it comes to things like this I have a little OCD :-) When I started learning Python I was a bit too dismissive when it came to small problems like this. I was like "Ahhh it doesn't matter now, if this comes up again I'll look into it", and in hindsight this cost me a lot of time and confusion, so I'm trying to do it better this time around with Rust! :-)
Yes, I'm familiar with that. Python has a very similar syntax in that regard. Thanks for your help!!
&gt; (Not to mention, it starts to feel more like the "just do what I mean" aspects of type systems in scripting languages like PHP or Python, which are simpler and more comfortable... until they unexpectedly break or silently do the wrong thing because they guessed the wrong intentions from what little you gave them.) Exactly my problem, since I'm only used to Python! :-) Also many thanks to you for going into that much detail. I have to admit that I didn't understand everything you wrote just yet, but I copied and pasted it into my "view later" folder. Not fully understanding things like that bothers me because I really want to get into Rust and really understand what I'm doing instead of just following some workaround and doing it half-assed. Just one last question out of curiosity: On a scale from 0 to 10 how hard was it for you to answer my question? Did you know all this by heart or did you actually have to look things up and actually do some "active thinking"? :-) And how experienced are you with Rust? Are you a hobbyist or a Rust developer? Is this a question that is Rust specific or is this more a compiled-language question in general? Ok sorry, that was more than one question! :-)
as I noted at the tail end of my response above: use std::io::{stdout, Write}; let name = "Steve Jobs"; stdout().write(name.as_bytes()).unwrap(); is the same thing as your hypothetical `println!(name)`. There's no format string anywhere in there, it just prints `name`. The function `write` requires an array of bytes, so we have to convert the string to an array of bytes by ourselves. So, yes, it is just a design decision. `println!(name)` could work just fine, doing the same thing that the `"{}"` format string would do, but the design decision was done to be consistent, as someone else mentioned. But, the entire feature was designed with a focus on preventing code from compiling if it isn't correct, and `println!` asks for a string literal to be the first argument, and it considers anything else to be incorrect.
Wow, I knew C is a lot more complicated/tedious when it comes to memory management, but I didn't know that even basic things like this are a problem. Good thing I'm learning Rust instead! :-) So - once again - Thanks so much for your help! You have gone way out of your way to help me understand this. I appreciate it!
No problem! People here definitely want to help! Rust has a steep learning curve, so it's always nice to have people around who can try to explain things.
Yes, this actually (and more so: finally!!) makes sense to me now! 
Makes sense, thank you. I am not sure how is that done. I think you might lost some information in converting to/from f64
You have a typo: `$id = $id + $string;` should probably be `$id = $id + s;` or even `$id += s;` Of course, `s` si a `String`, and you need to do `String + &amp;str`, so it would need to be `&amp;s`. But, even that won't work. `0..($($string),*)` is going to expand in place in an unexpected way. In your example, it will expand to: let mut id: String; for s in 0..(a, b) { id = id + s; } To do it your way, you want this: macro_rules! conc { ( $id:ident, $type:ty, $($string:ident),* ) =&gt; { let mut $id: $type = Default::default(); for s in &amp;[$($string),*] { $id = $id + &amp;s; } } } We need to initialize the string first, so we use `Default::default()`. Then we need an array of strings, not an integer from 0 to the array of strings. Using this version, it expands into this: let mut id: String = Default::default(); for s in &amp;[a, b] { id = id + &amp;s; }; But, we could simplify this further: macro_rules! conc { ( $id:ident, $type:ty, $($string:ident),* ) =&gt; { let $id: $type = [$($string),*].concat(); } } so, it will expand to let id: String = [a, b].concat(); which does the same thing using fewer allocations.
You should really work through [this](https://os.phil-opp.com/) instead of a 4 year old program. Using Rust v0.7 doesn't make sense in 2018. It barely made sense in 2014. `enum` is not dependent on the stdlib, even that far back, I'm pretty sure.
It's definitely [this one.](https://en.wikipedia.org/wiki/Rust_\(video_game\))
What version of Visual Studio are you using, and what parts have you installed? I don't personally develop on windows often, so I don't know *every* issue, but maybe the info in https://github.com/rust-lang-nursery/rustup.rs/issues/1003 can help.
I'm pretty familiar with the SVD spec, and also how poorly vendors make use of those features. Though as you point out, some of this can be mitigated by rewriting the SVDs. &gt; &gt; I spent some time on this exact problem and don't think it's the right approach. &gt; If I may ask, what makes you say so? The first reason is that it's not always obvious what is the best way to structure the common peripherals. There are cases where peripherals are identical except for a few fields, cases where some peripherals are supersets of others, cases where peripherals have both common registers and MCU-specific registers, etc. There are also plenty of naming issues: if you have two or three incompatible variants of a peripheral, what do you name them if the vendor has given them the same name? It’s possible to embed the logic for this directly in the tools that you use to generate the common crates and resulting code, but in my experience that makes things opaque and brittle. Someone that thinks that a crate should be organized slightly differently can’t just make a pull request for the change itself; he or she must know enough about the common crate generator to make a pull request there, and then must make sure that the change doesn’t accidentally break dozens of other crates that others are relying on. I think it’s better to have an intermediate description that explicitly lays out the MCUs and consolidated peripherals and that can then be used for code generation. This allows contributors to collaborate just on the crates that they care about without having to become experts on the tooling. Which brings me to my next reason, which is… There’s a ton of important stuff that SVD just doesn’t cover. Just as an example, it has no concept of variants, so you can’t specify that one variant has 4 UARTS and another just has 2, or that the ADC on one variant has a few more options than the other. It doesn’t know what a GPIO pin is, or what an Alternate Function is, or what a DMA channel is, among other things. It also doesn’t understand relationships between peripherals or fields within a MCU; that a particular bit in the RCC is connected to a specific peripheral, or that in a Kinetis MCU, PORTA is related to GPIOA. It doesn’t know about memory layouts, so you can’t use it to automatically create linker files. And it has no concept of modules, which is why there’s this effort to infer common peripherals. These are just a few things off the top of my head. Because of that, there’s a hard limit to how expressive an API can be if it is solely generated from SVD or even a collection of SVD files. And there’s really no leverage that the Rust Embedded community has to change the SVD spec.
&gt; should probably be $id = $id + s; yes of course that's why I did the " for s in .. " :) &gt; let mut $id: $type = Default::default(); Ok. Just checked. value of a default String is an "" string. I try to remember, however I don't understand, why I have to initialize $id, when I am about to assign a value to it two lines later: let s: String; s = "Hello".to_string(); works. Why not in the macro? &gt; &amp;[$($string),*] Stands for an array of (here) string slices of variable size (before expansion). Wow. Thank you very much. That was of great help.
&gt; because this s variable hasn't been initialized, so how can you add something to it? ahh. now I get it, makes total sense :) thanks One more question.. The macro expects type:ty the body however can only handle types that provide a concat() function. So it works with Strings. If String is the only type that has a concat function type:ty would be useless. So I wonder, if I could compare the type of type:ty with the type of $x:expr ( $id:ident, $type:ty, $($x:ident),* ) =&gt; { if $x/*...reflection.type */ == String { let $id: $type = [$($x),*].concat(); } else if $x.type == f32 { let $id: $type = [$($x),*].to_string().concat(); // conversion to string before concat } } Is something like that possible?
Dynamically switching on the type *might* be possible, but I'm not sure how. You can definitely do this: macro_rules! conc { ( $id:ident, $type:ty, $($string:ident),* ) =&gt; { let $id: $type = [$($string.to_string()),*].concat(); } } so your example would expand to: let id: String = [a.to_string(), b.to_string()].concat(); which would guarantee that each value is converted to a String.
Actually, if you wanted to switch on the `$type`, you could do it like this: macro_rules! conc { ( $id:ident, String, $($string:ident),* ) =&gt; { let $id: String = [$($string),*].concat(); }; ( $id:ident, $type:ty, $($string:ident),* ) =&gt; { let $id: $type = [$($string.to_string()),*].concat(); }; } Now there are two cases. Either the user provided String, or they provided some other type. I don't see how the second case could ever be useful though, since the result would have to be a String.
Yep, that issue seems to be what I'm seeing now. I'll uninstall everything and try again
&gt; Any thoughts on what a next wasm oxidation project might be? The Firefox devtools have a JS translation of Gecko's C++ CSS lexer. One idea is to replace this with a wasm-compiled lexer from Servo. See https://bugzilla.mozilla.org/show_bug.cgi?id=1410184
&gt; You can guarantee that when the file was discovered it was that type. BurntSushi presumably does not mean that you can't indicate in the type system that the file is, say, a pipe, but that you can't indicate in the type system that a path corresponds to a file that exists at all. (Since, as you note, the file might be deleted at any time.) So the *type* can't guarantee that it exists, at all. I *really* don't understand how this guarantee works with deserialization—when I deserialize a value, am I also creating paths and failing if I can't?
I think it's worth noting that a local TOTP manager can still work for other threat models that don't involve malware being installed on one's desktop or laptop. A database breach, insecure or reused password, and even various phishing scams could still be mitigated by a local TOTP generator. Of course, one could be more protected by keeping TOTP codes off the same device where they enter their password. But sometimes convenience can be a huge win for raising the bar just a little bit.
can you elaborate on why you think int is preferable for representing currency? I've been using d128 in my code, it works well, but I'm interested to hear the argument. 
`n &gt;= len`, which leads to the panic, is in most cases programming error, so a panic is prudent. Requiring an unwrap on yet another Result has its own ergonomic downsides as well.
Alright, hope that works! There are a number of local windows experts here that may be able to help too if it doesn't. If all else fails x86_64-pc-windows-gnu always works, as long as you aren't linking against C libraries which don't use it.
It borrows the target of `var123`. Since Rust has many pointer types (anything that implements `Deref`), this "rebororrow" notation has the effect of temporarily converting a pointer to a reference with a new lifetime. If the type of `var123` is `&amp;'a T`, this is equivalent to copying the reference and giving it a new lifetime `'b` such that `'a: 'b`. But if the original pointer is anything else, it's *not* the same. For example if you have `let v: Vec&lt;f32&gt;`, then `&amp;*v` has the type `&amp;[f32]`. Also, `v` will count as "borrowed" whenever that derived reference is live, so you can't call `v.push` or `v.clear`. This combination of operators is equivalent to calling `std::ops::Deref::deref` directly. That equivalence helped me understand.
[removed]
`*` is the deref operator: https://doc.rust-lang.org/book/second-edition/ch15-02-deref.html If `var123` is sometype `&amp;T`, then yes, `&amp;*var123` is equal to `var123`. The trick is when `var123` isn't directly a reference, but something else which implements [`std::ops::Deref`](https://doc.rust-lang.org/std/ops/trait.Deref.html). For example, if `var123` is `&amp;mut i32`, then `&amp;*var123` gives you `&amp;i32`. If `var123` is `String`, `&amp;*var123` gives you `&amp;str` (String implements `Deref` with `Target = str`). Here's a playground demonstrating this: https://play.rust-lang.org/?gist=e5fc35cd2ad006d4ffc5bbea65c504c5&amp;version=stable
This sounds right: but you need to think very closely about what you need from these different enums. I mean, all traits are implementable on enums and structs. It's up to you to know what methods you'll want to call on these enums, and create the trait with those methods. At this point, it shouldn't matter at all to your algorithm that it's an enum or a struct, since accepting the trait, you only have access to that trait's method.
What a lovely answer. I have nothing to add but a thank you for sharing your knowledge. Cheers!
So similar to doing embedded dev on microcontrollers with no_std?
What's the new doc tooling?
No, because `or_die` prints out a message to stderr and immediately terminates. I think it's not useful to expose _end-users_ to stack traces - it always struck me as sloppy when Java programs blew up when I fed them the wrong command-line parameters.
You also see this syntax for getting a reference from a raw pointer. Raw pointers don't seem to do this using the `Deref` trait, presumably just because dereferencing a raw pointer has to be unsafe and `Deref::deref`is not unsafe. 
This video is not directly related to rust but typically for informational purpose or something to think about when someone wants to design such things in rust
Modern C compilers actually check the printf() format string and emit a warning if it seems wrong. But only if it's a string literal. Otherwise you're on your own. 
`Eq` is still good to have around as long as you can guarantee that `a == a`, which applies to almost everything except floating point (NaN doesn't equal NaN).
If there's an ordering to the keys, and you want to make use of that ordering, consider BTreeMap. Otherwise, use HashMap. 
Your implementation as it stands is very inefficient. 1. If you’re working with strings already, you’re incurring an unnecessary UTF-8 check when you call builder.string() at the end, as well as introducing uncertainty by virtue of having `Result&lt;String, FromUtf8Error&gt;` instead of `String`. 2. `FromBytes` produces a `Vec&lt;u8&gt;`, meaning a mandatory allocation each time. `&amp;[u8]` is *extremely* strongly preferable for something like this. You end up with two options: use `Cow&lt;[u8]&gt;` so that you can at least bypass allocation for `&amp;str`, `&amp;[u8]`, `String` and `Vec&lt;u8&gt;` while still allocating for `u8`, `char`; or else, refactor it so that lifetimes aren’t a problem, and that instead of `ToBytes` with a method that produces bytes, you have `AppendToVec` with a method that takes the `Vec&lt;u8&gt;` and does the appending itself, thereby allowing *all* methods to bypass allocation. I feel that this approach leads to doing the bytes-to-string conversion in the wrong place. `[u8]` and `str` may be represented in the same way, but semantically they’re quite different; you should generally aim to isolate the places where the conversion and related error handling occurs. Really, I think that for almost all situations `String.push` to push a character and `String.push_str` to push a string is *exactly* what you want. Allowing you to push bytes and bytestrings is a misfeature; rather, then, you should embrace the with `Vec&lt;u8&gt;`, where you have `.push()` to append a `u8` and `.extend()` to append all items in a `[u8]`, leading to `.extend(x.as_bytes())` to append the UTF-8 bytes in a string if you really need to (and I suppose `.extend(x.encode_utf8(&amp;mut [0; 4]))` would do for characters).
As a bonus example, not of a compile language but of a dynamic one: In Ruby, you have (at least?) three different functions to print things. There is `puts(foo)` to just print out a single value, `p(foo)` to debug print a single value and `printf("%s is %d years old\n", name, age)` to print something using a format string. Because ruby is a dynamic language, you can of course also write `printf(foo)` and this will mostly just work... except when `foo` out of bad luck or malicious input contains a placeholder like `%s`, then you'll get a runtime exception because you are missing a paramter. Rust only defines the format string version for you, as that one is the most useful in real programs, but you can easily define functions to just print a single value yourself. Here is a playground link with an example of a `puts(x)` function and a `dp!(x)` (debug print) macro. I personally don't find the `puts` too useful, but the `dp` macro (which also prints out the expression together with the value) can be nice to have. https://play.rust-lang.org/?gist=3a6c88e27f5a229b354ad77ad1aaca43&amp;version=stable
Quick question: what about a linked hashmap? Java has that, it's where you can process each key pair in order of insertion, like a mix between linked list and hashmap. Afaik, it's the only one Rust is missing that Java has.
Not really. All I need is `Path` alternative which will panic on error. So no `to_str` and less `unwrap`.
Speaking of `println!()` am I the only one that finds Rust's I/O extremely convoluted? println macro should able to accept any variable or literal that has the `Display` trait, it's absolutely a no brainer. Furthermore, afaik, the `print!` macro flushes stdout while `println!` doesn't? Why is this? Thank god [text-io](https://crates.io/crates/text_io) crate exists. Otherwise simple I/O in Rust is even more verbose and ridiculous than C++. Granted, I'm not very proficient at Rust but can it get any better (apart from the bc fix)? use std::io::{Write, stdout, stdin}; fn main() { print!("Enter your name: "); // Yes I want the prompt in the same line let _ = stdout().flush(); let mut buff1 = String::new(); // Oh, can't have another mutable ref down below stdin().read_line(&amp;mut buff1).unwrap(); let name = buff1.trim_right(); print!("Enter your age: "); let _ = stdout().flush(); let mut buff2 = String::new(); // Just make a new buff instead because I want to keep my sanity stdin().read_line(&amp;mut buff2).unwrap(); let age = buff2.trim_right().parse::&lt;i32&gt;().unwrap(); println!("Hello, {}, {}", &amp;name, age); // You didn't want to consume the name, remember? } As opposed to: #include &lt;iostream&gt; #include &lt;string&gt; int main() { int age; std::string name; std::cout &lt;&lt; "Enter your name: " &lt;&lt; std::flush; std::getline(std::cin, name); std::cout &lt;&lt; "Your age: " &lt;&lt; std::flush; std::cin &gt;&gt; age; std::cout &lt;&lt; "Hello, " &lt;&lt; name &lt;&lt; ", " &lt;&lt; age &lt;&lt; ".\n"; } It gets even better import std.stdio, std.string; void main() { write("Enter your name: "); stdout.flush(); auto name = readln().strip(); int age; write("Enter your age: "); stdout.flush(); readf(" %s", &amp;age); writef("Hello, %s, %s.\n", name, age); } 
Maybe you're searching for https://crates.io/crates/ordermap ?
Just FYI, the `std::flush` manipulators in your C++ code are extraneous since `std::cin` is [`tie`d](http://en.cppreference.com/w/cpp/io/basic_ios/tie) to `std::cout` by default.
Ah, thanks for pointing that out.
Looks like it. Thanks!
Your post is badly formatted and you assume that everyone knows that your tool is a GUI for PostgreSQL administration. A better way to start would be: "Hi, I've been working on Diwata, a GUI for PostgreSQL for a while and was wondering if someone could help me out with finishing feature X." I'd remove the "but why" section, nobody asked you yet you immediately "defend" your idea.
Okay, thanks for the tip.
&gt; Please try not to refer to traits as superior to oop; They are just different design paradigms which are in fact quite similar. i don't agree. basically my argument is * OOP is not a zero-cost abstractions. * OOP is not obvious | simple. On a binary level, vtables are a very basic and old concept. OOP is the language level support for calling and casting nested structs. You can emulate this in rust. ---- Let me go on a short rant here. OOP crept into business and schools on the promise of extraordinary re-usability and everybody could do it. So it must be valuable right? As far as i can tell it is a complex invention that promised to make everything simpler ( 25+ years ago ) and it hasn't. It's a solution looking for a problem. In functional terms, it is the opposite of pure functions. Instead of passing in 'the world' as an argument in a way that imperative programs do, you get to pass in a billion worlds of which you have only seen a fraction. I'm not saying nothing good every came from OOP languages. It's just too high up in a class 'Programming 101'. It's current form* simply does not abstract computation. *search for smalltalk
Do all types implement `Drop`? Weird question perhaps, but I've just written down the sentence "While all types implement `Drop`, explicitly calling `T.drop()` is illegal." and wanted to check that it's true.
for example,&amp;*r means a new reference to v, r and &amp;*r point to same address,but themselves have different address. let v = vec![4, 8, 19, 27, 34, 10]; let r=&amp;v; println!("{:p},{:p},{:p},{:p}",r,&amp;r,&amp;*r,&amp;&amp;*r); output: 0x7ffeef1031b8,0x7ffeef1031d0,0x7ffeef1031b8,0x7ffeef103280
So, is it actually possible to have this code used by npm-library?
I've read your design documents, it looks pretty similar to Minetest I must admit :). Regarding the scripting language document: there is a further option of including a wasm interpreter. This allows you to include a native language (like Rust!) and sandbox it very efficiently.
In the article
There is a lively thread on embedded Rust on the official forum: https://users.rust-lang.org/t/rust-for-embedded-development-where-we-are-and-whats-missing/10861
&gt; [...] no runtime check or `unwrap` required. What to say ... perfect. Thanks again for your work.
Actually, I thought of it a few weeks ago, but I couldn't find any fast WASM interpreter/jit. If you have any information on that I am EXTREMELY interested. :-) 
The ones I know about are: Interpreters (slow): * https://github.com/icefoxen/nanowasm * https://github.com/paritytech/parity-wasm * https://github.com/joshuawarner32/rust-wasm * https://github.com/kanaka/wac JIT (fast): * https://github.com/sunfishcode/wasmstandalone I haven't tried a single of them so it is very likely that some of them are not mature yet. The first interpreter I would check out would be wac as it seems to be the most mature one. After that maybe parity-wasm, as it is written in Rust. It seems that the best wasm JIT engines are inside JS runtimes now... sadly. But I do think that in the non JS space there is going to be a lot of development, so maybe in a few months already we are going to have mature wasm JIT engines. I think the best idea is to start with one of the interpreters and wait until fast JIT for wasm becomes available, and then switching to that.
[discussion over in /r/programming](https://www.reddit.com/r/programming/comments/7q6ida/jai_libraries_discussion/)
&gt; Our memory sizes are low enough that we don't typically consider pre-emptive or cooperative threading though. Futures and generators don't imply threads in the traditional sense of each thread has a, say, 1KB stack space, though. They are more like green threads / userspace context switching. They are like protothreads / Duff's device in C. &gt; I think there is some object oriented features providing this... which means vtables These are just plan old methods that will get statically dispatched. The compiler can and will inline them. In most cases there won't even be function calls (`bl` instruction) in the output machine code. Rust also has dynamic dispatch in the form of trait object; those involve vtables as you say but I'm not using any here, or in the HAL, or in the drivers. Everything is statically dispatched. &gt; I wonder if Rust will find a place in low cost, bare bones MCU projects that have typically used simple time division based schedulers. Have you seen [Real Time For the Masses](https://docs.rs/cortex-m-rtfm/0.3.1/cortex_m_rtfm/) framework? It's basically a hardware based scheduler. It uses interrupts to implement tasks and achieves multitasking using pre-emption / priorities; it also provides a lightweight lock-based mechanism, `Resource`s, for sharing memory between tasks -- the compiler ensures that locks are only used where required for memory safety (data race freedom). We have been meaning to add timing semantics to it but haven't had the time yet. By timing semantics I mean things like you specify "task A runs every 10 ms; task B runs 5 ms; and task C runs every 1 ms" and the framework uses some timer like SysTick or device specific one to trigger the tasks (interrupt handlers) at the specified times. Timing semantics also mean having the framework derive the task priorities for you if you specify things like "this task should complete in 2ms and that task should complete in 3 ms" -- I'm not super familiar with how that last part works but the co-author of RTFM who's an expert in real time systems knows the theory behind it.
As far as the compiler is concerned, `Drop` is not implemented by just any type: https://play.rust-lang.org/?gist=ed3f1a4725a7d8c4b5bd6333ee62e4ba&amp;version=stable You'll get a "`drop()` method not found" error for `String` and it will fail to satisfy the bounds of `is_drop()`, while `Vec&lt;u8&gt;` will satisfy `is_drop()` but get the "calling a destructor is illegal" error when calling `drop()`. This is because `Drop` is special. The compiler looks through the fields of a composite type (struct, array, enum) for any types that need their `Drop` impl called when falling out of scope, and emits a destructor function to be called for that composite type. Thus, `String` gets a destructor function emitted even though it does not implement `Drop` because it contains a type implementing `Drop` (`Vec`). 
&gt; What is the best supported board for Rust currently? I maintain the board support crates for both the Blue Pill and STM32**F3**DISCOVERY but I do more development on the Blue Pill exactly because it's small and easy to mount on Things. &gt; I'm looking to build a midi sequencer and fancied using the project to learn Rust. Bluepill looks far too small for my needs. Not familiar with midi sequencers. Do you need more digital I/O pins, more PWM pins than the Blue Pill provides or do you need something else? If the former, maybe an I2C-based I/O expander (e.g. PCF8574) or an I2C-based PWM driver (e.g. PCA9685) could do the job? Both the PCF8574 and the PCA9685 are on my TODO driver list.
&gt; I'm interested to see what the tock-os guys think of this. [:-)](https://github.com/rust-embedded/rfcs/issues/39#issuecomment-358776449) I think their userspace APIs are higher level than what embedded-hal currently targets but I think they could use embedded-hal and generic drivers in kernel space (i.e. to implement capsules) to more easily extend their platform support to other microcontrollers.
&gt; r and &amp;*r point to same address, &gt; but themselves have different address. I don't understand this point. Those are rvalues/expressions, why would they have addresses at all?
I watched the whole stream a week ago and just clicked through the video to collect some keypoints. The most important topic is Blow's new module culture. I don't know if I have written down everything about it, so just in case, go over to the [thread in /r/programming](https://www.reddit.com/r/programming/comments/7q6ida/jai_libraries_discussion/). * design of namespacing in Jai (some points made, but nothing really innovative) * versioning * naming/overloading conflicts, treeshaking * maybe module parameters in the future * new module culture * neither cpp nor npm culture * **cares about being reliably able to "rebuild their projects even 15 years later"** * libraries should be downloaded once and then reside with the project together * downloaded libs should be included in version control * packages should not be precompiled unless they are too big
Most of the time I see this, it's because of `RefCell` or `Cell`. If you have a `RefCell&lt;MyType&gt;` and you want a `&amp;MyType`, you could write it as `&amp;my_cell.deref()` or `&amp;*my_cell`. Both do the same thing, but one is shorter to write.
Update: after putting in a lot of effort, I finally managed to release it. However, I feel like setting up CI is more painful than it was last year (I managed to do so for my other crates without issues): docs.rs uses a rust-nightly from september 2017, so the docs don't render there cargo doc-upload fails for me for some reason I don't understand yet, so... I can't upload docs to gh-pages either :( travis macosx builds take forever, so even though the whole CI is green, crates.io reports it as failing (instead of as "in progress/building" or something like that... the build bots haven't finished just yet...) setting up code coverage is still in progress... want to set up docs first cross doesn't support any of the *BSD flavors so... I can only hope that the library works there :/
It already looks like it can! I somehow haven't managed to make it work yet, but that is on me!
It already looks like it can! I somehow haven't managed to make it work yet, but that is on me! Is there a guide somewhere explaining step by step how to set up a new project using cargo-travis + github + coveralls/codecov + doc upload to gh pages ? Like from `cargo new` up to the final result ?
And let me guess: but you don't have time to answer because you are busy compiling x264-sys.2.856
Agreed. I've been known to use an "ordie"-like approach in tiny utilities. Usually as a macro though. Agreed that showering a stack trace/panic to an end user in normal operation should *always* be considered a bug.
All these libraries are implemented on top of MPI I/O, so you can just use that directly, is as easy as that. HDF5/Netcdf basically build a file-system on top of a single file, so that you can have different files allocated inside it. HDF5 makes this more obvious that Netcdf, but whether you think of a matrix inside your file as a "part of the file" or as "another file" doesn't really matter. They let you create folders and put objects inside. If you don't need any of that you can just write bytes using MPI/IO and be done with it.
You can create a pointer to a function that has a `-&gt; impl Trait` return type without providing any types parameters to it because the function is not generic. But as you say, you can't create a pointer to a generic function, you need to create a pointer to a monomorphization thereof.
Just to confirm: The screenshot on the linked github page are from a _gtk_ program? I didn't knew that you can do such nice things with GTK! This is awesome, thanks for sharing!
It's a bit unclear to me whether this is meant to be a database administration/development tool (PgAdmin replacement) or something more like Microsoft Access targeted at end users.
I think that pushing for a good online story first was the right move to create a community, easy sharing... But a strong offline one seems to be something that is starting to be needed in places!
In this case, you would have to put mod handlers; mod routes; in lib.rs or main.rs (whichever is your entry point), mod index; in handlers/mod.rs and then use ::handlers::index; from routes/mod.rs.
Hi there! We are inviting all Rust developers to Kyiv, Ukraine to Exonum workshop. Our core developers will go through the service creation at private blockchain written on Rust. The event is in Russian. However, we are planning similar events online and in other CIS and European countries. 
As much as I'd love to see a better replacement for PgAdmin (which is usable, but not very good) I'm not entirely sure I see why you'd need Access/Excel style forms in an admin/development tool, since most of the time is going to be spent in a query editor anyway.
because they are reference, a reference is a value of pointer type, and the value requires an address to store
I've been working on a ground-up re-write of Rustdoc. It's still fairly early, but after some initial spikes, I think I have something I'm pretty happy with. It's not generally ready for public consumption yet though.
because I want non-technical people may still be able to use it, such as business owners who wants to see everything that is going on in his company (without building/spending and admin specific to their own apps).
If you're the same person as on IRC, you're not installing the right C++ files. You need the build tools, not the redistributables.
I personally make new binaries in `src/bin` to do this. I'd really like to have something like `npm run`, but haven't written up an RFC yet.
Oh, thanks a lot for talking about my work! :) But for the records, a lot of others great contributors weren't mentioned either, I suppose they just had a lack of space?
Have you tried deoplete?
Thanks for the detailed answer. &gt; The first reason is that it's not always obvious what is the best way to structure the common peripherals. There's a simple way to structure common peripherals: if they are *exactly* the same then they are the same type; if they differ in the most minimal detail, e.g. the reset value of a register or one is missing a bit field in some register, then they are different types. Not perfect but already slashes the amount of code duplication by some tens of percent. &gt; I think it’s better to have an intermediate description that explicitly lays out the MCUs and consolidated peripherals and that can then be used for code generation. I almost always prefer the bottom up approach than the top down approach and under normal circumstances I would have go for implementing something better than SVD but: (a) it requires very careful design work; (b) it's also a lot of work to get a single, not even complete, crate out; (c) it will require iterating, and having users and iterating just multiplies the amount of work that will need to be invested; (d) with SVD there's a non zero chance that the vendor will realize SVD files for new parts whereas with anything else we'll always have to do the work to support new parts; (d) I saw the Zinc project do something similar and collapse under its own weight; and (e) I don't think embedded Rust growth should be delayed any further. That's why I'm putting my efforts on the `embedded-hal` traits: that layer isolates us of whatever is at the bottom so basically I'm working from middle up. The generic drivers will continue to work regardless of whether the implementation of the `embedded-hal` traits is based on svd2rust or something better. Not that I think that the bottom layer is not important; it is! It will potentially reduce the amount of work we need to do to support new parts. It's just that I think that's not where my efforts are best spent right now. &gt; There’s a ton of important stuff that SVD just doesn’t cover. I think putting some of that stuff you mention in the intermediate format exclude some current / future chips. The nRF chips don't have the concept of "alternate functions"; you can use any pin for anything so instead of configuring a pin for some function you do it the other way: you write the pin number you want to use for, say USART_TX, in a register. IIRC, those chips don't have a RCC either instead peripherals get enabled automatically as you write their registers, or something like that. (They also have this interesting concept of tasks and events where you can, for example, build a PWM, for which there are no PWM specific registers, by using a timer TIMEOUT register as an event and a I/O pin OUT register as a task -- but I guess that's not really relevant here). I didn't look at DMA on the nRF but I wouldn't be surprised if it doesn't use the concept of DMA channels; it might even be possible to implement DMA behavior using the tasks and events system. I'm not sure if linker scripts should be generated from the intermediate format; I consider them to be more application specific. &gt; Because of that, there’s a hard limit to how expressive an API can be if it is solely generated from SVD or even a collection of SVD files. I wholeheartedly agree but I think that's OK. I think SVD are good enough to grow embedded Rust for the time being. We can always replace the SVD files with something else and continue using all the generic driver crate ecosystem, with zero changes, as well as RTFM, with zero or minimal changes. That being say I really look forward to whatever you come up with. Happy to be proven wrong on everything I said as well.
&gt; and the value requires an address to store It doesn't though, not if your code itself doesn't require it.
&gt; println macro should able to accept any variable or literal that has the Display trait Here's one controversy already: why `Display` and not `Debug`? &gt; Furthermore, afaik, the print! macro flushes stdout while println! doesn't? Why is this? You're almost, but not quite right. Neither one flushes. However, most terminals when encountering a `\n`, flush. So it's *the terminal* that's the cause of this difference, not Rust itself.
Making a whole new binary is a lot of effort when we're talking about 1 line command line tasks.
2.6: I'd be happy to see a conference outside of Europe/US (and, indeed, stay tuned for more), but conferences _need a local team_. We'd be very happy to support, please get in touch with community@rust-lang.org if you want help setting something up. Even if it's just a Rust day.
&gt; Any recommendations? Ideally something that is not too expensive either. I'd say you'll end up writing more drivers by buying external components instead of another board; most microcontrollers pretty much have the same set of peripherals and boards with on-board sensors can be expensive. At the end of [this comment](https://github.com/rust-embedded/rfcs/issues/39#issue-289457410) there's a list of external components that you can get for a few dollars from AliExpress / eBay / etc. and that don't have a driver yet. Maybe you'll find something that interests you in there.
While this all makes sense, why can't `println!` accept single identifier arguments and simply translate that to `println!("{}", arg)`? Or is there another macro that does that already?
I believe BTreeMap also has better cache coherency which means iteration through the elements can be faster. Cache hits save a tremendous amount of time.
what kinds of things do you do with one liners in Rust?
So in terms of code coverage there is the [cargo-tarpaulin](crates.io/crates/cargo-tarpaulin) crate (disclaimer I'm the author). There's still plenty of areas to improve and it's only available on Linux, but for a lot of projects it does offer a better solution than tools like kcov. In my likely biased opinion. 
Have you looked at the [wabt](https://github.com/WebAssembly/wabt) toolkit's interpreter? I don't know how fast it really is but it's developed by the WebAssembly team and intended to be fast rather than minimum-viable-product, so.
Have you looked into cargo build scripts? https://doc.rust-lang.org/cargo/reference/build-scripts.html Seems like a hook you could hang anything off.
'smallest example' .. I think the smaller the example , the more likely that inheritance is ok. The advantages of traits are about scaling, decoupling, reusability.
Commands like `cargo run --bin fortress -- --map "./map/castle.map"`, `cargo +nightly test --features "clippy"`. I'm sure there will be a lot more in the future.
That isn't what I'm after. I want to be able to create new commands, or tasks, but specific to that project. For example in an NPM project you may have `yarn run test`, `yarn run test:watch`, `yarn run build`, `yarn run build:dev`, and so on. Internally they'd call the build system with all the relevant command line args for that project.
Wait, I must be seriously misunderstanding you. &gt; cargo run --bin fortress -- --map "./map/castle.map" is exactly what I'm advocating.
I'm sorry, I don't quite follow what your solution is.
I remember you being a superhero :)
Writing a 10 line program, for a 1 line command, seems a bit silly. I'm also not building a tool, or a new program. It's just a task for the project so I don't have to remember or write out the command line args every time.
I also moved to a place that didn't have local rust gatherings. My solution was to get together with a friend and start our own. They've been fairly small for now, capping out around 10 participants per meetup, but this month (next week!) we're doing our first one that's focused on newcomers, and we've got 17 people registered! Starting a meetup has actually not been too difficult, and it's a great way to help build the rust community around you. If your company is using rust, all the better! You might be able to get them to sponsor a space to meet, or provide pizzas or snacks. If OP or anyone else is thinking about starting a meetup, and wants to trade ideas, or is just looking for moral support, I'd love to talk more.
&gt; Here's one controversy already: why Display and not Debug? Detail of implementation, I would prefer Display because Debugs may require custom formats. Or, leave it upto the users. Or create a new macro for debugs, there's already a new macro `eprintln` iirc. Whether the standard picks Display or Debug or both or any, in any day, `println!(myVar)` is far more desirable than `println!("{}", myVar)` imo. 
And I remember you being part of the superheroes' team! :p
All this static dispatching is exciting. RTFM sounds alot like an RTOS implementation. I am at the edge of my rust knowledge here though (and thats not very much). I think I need to learn some more about rust. Thanks for answering my questions!
&gt; AUCTeX was a pain to set up with regards to completions (and I really need a TeX editor to have completions), there were conflicting instructions, and someone had to take the time to carefully break down the process before things clicked. That's probably the only reason why I was able to make it work. &gt; &gt; I just added the latex layer to spacemacs and it just worked (it uses flyspell in my machine to generate completions, and ispell/aspell for auto-correct).
&gt; it is marked extern "C" so that it is publicly exported in the final .wasm file. Maybe a silly question, but why are wasm functions marked as "C"? Shouldn't it be "WASM" as that's the FFI interface here instead of C?
 impl MyTrait for u8 { // ... }
Well, you could use `let path = PathType::new("some/path.txt").unwrap_file()`. Panicing on error is kind of an odd requirement -- what's wrong with unwrap?
I'm going to downvote for now because it's factually wrong, but you're close to understanding. Cell types aren't pointers; they don't implement `Deref`. What they do have is methods like `RefCell::borrow` and `Mutex::lock` which return pointers (`Ref` and `MutexGuard`). So the idiom is `&amp;*rcell.borrow()` or `&amp;mut *mtex.lock()` etc. The cell's method describes how the borrow is achieved: `RefCell::borrow` counts the number of borrows and panicks instead of breaking the uniqueness rule. `Mutex::lock` waits for the mutex to be available. `Cell` doesn't allow you to borrow the inner location but it gives you operations like `set`, `get` and `replace` directly. `Arc` and `Rc` *are* pointers, however.
&gt; you can't indicate in the type system that a path corresponds to a file that exists at all. This is basically impossible to guarantee _ever_. I would argue that being able to write: ``` struct MyPaths { files: HashSet&lt;PathFile&gt;, dirs: HashSet&lt;PathDir&gt;, } ``` And knowing that those paths _once existed_ and _once corresponded to the right type_ will help reduce unexpected behavior, but YMMV. &gt; how this guarantee works with deserialization Yes, when paths are deserialized they are guaranteed to exist at the time of deserialization. I think I am going to add another type, `PathSer`, which allows you to specify that you don't want that check in place. A benefit is that you can "trust" that the data sent to you contains _actual paths_ (at least, at the time of deserialization). A disadvantage is obviously that there is overhead and it is _kind of weird_, so there is definitely a use-case for `PathSer`.
&gt; since it's a single array. with holes. AFAIK BTreeMap is implemented as a tree of arrays, so might give you better cache coherency depending on the array size
&gt; That's why I'm putting my efforts on the embedded-hal traits: that layer isolates us of whatever is at the bottom so basically I'm working from middle up. The generic drivers will continue to work regardless of whether the implementation of the embedded-hal traits is based on svd2rust or something better. Not that I think that the bottom layer is not important; it is! It will potentially reduce the amount of work we need to do to support new parts. It's just that I think that's not where my efforts are best spent right now. I think what you are doing is incredibly valuable, and the tradeoffs make a lot of sense. In particular, the middle-level traits are useful no matter what the lower level implementation looks like and will allow people to start getting real work done. Having a SVD-based toolchain available right now gets people doing embedded development right away, which increases the pressure on the broader community to make Rust itself better for this purpose. &gt; I think putting some of that stuff you mention in the intermediate format exclude some current / future chips. The things that I mention are all optional, so you don't need to use them if they don't make sense for a particular chip. On the other hand, if they are available, it makes it possible to construct higher-level type-safe abstractions. For instance, you can assign a specific pin (i.e. PA5) to a specific signal associated with a peripheral (i.e. TX for UART1) and have the type system verify that the connection is consistent with the AltFn table at compile time. &gt; That being say I really look forward to whatever you come up with. Happy to be proven wrong on everything I said as well. Any time I see one of your blog posts, I'm inspired to put more effort into getting my own code cleaned up, documented, and published. Sometimes it's intimidating, given the standard that you set!
Yep, went live yesterday. I'm planning on making a blog post on that this weekend, actually!
Your title sounds like you are trying to sell me something. "The next modern platform" sounds like a startup pitch. Looking at your code and what it does, it looks pretty cool to be honest. But the approach seems dishonest. I think I would have prefered a straightforward "I made a Postgres GUI Manager in Rust" Or "Diwata: A Postgres Gui tool in rust".
I had a look at these and no one seems suitable for embedding just yet. I am looking forward to wasmstandalone and nanowasm, but I guess mods will be statically compiled *for now* (on the server side). This should be reasonable, and it would still allow a mod to enable modding from scripting languages.
I want to point out to people, to please avoid using &amp;* for things like going from &amp;String to &amp;str. Please use .as_str(). It makes your code easier to understand.
That's awesome. Right now it seems, that having 3D tensors would be very beneficial, but I can live with it.
It's unrelated to the associated type. The error is on the method definition, because you've used `Self` to fill the generic parameter `B` of `Foo`, and generic parameters are all bounded to be `Sized` by default. To remove that default you can write `struct Foo&lt;B: Blarg + ?Sized&gt;`.
I agree as one as pointed out. I have no experience with marketing and pitching whatsoever, and not an english speaker either. This is just my attempt on how to do it, and it seems wasn't going well. :(
I think it's illegal for a type to be both Copy and Drop.
You probably want to use a parser library rather than creating one from scratch for anything that isn't trivially simple; I'm not too familiar though so I don't know what the best Rust parser crate is. You may already be familiar with haml, but if not, look at it. It's an interesting template language for html. The design is quite ruby-centric though.
Thanks for the detailed response. I regret writing this crate really as I am learning more from your comment than any of the coding I did. 1. I suppose I could have use the unchecked version of `from_utf8` to avoid this. 2. I had originally returned a byte slice in the `ToBytes` trait but that led to problems with u8 and char as you said. I could refactor this a bit but after reading the rest of your response, it seems like a moot point now. Again, I appreciate the constructive comments!
Firefox 57 only supports Rust 1.19 https://wiki.mozilla.org/Rust_Update_Policy_for_Firefox In which case it builds perfectly fine, and the policy of allowing no warnings in production means no possible bugs or ambiguous code can make its way into production. I'm sure they don't have warnings as errors turned on in development, but production for a huge commercial project like Firefox needs to have stringent standards to avoid falling quality and turning into a complete mess of a codebase.
Disagree. Every codebase I've worked in, where warnings-as-errors is policy, has been significantly cleaner, more maintainable, and more reliable. In every language. Fix your warning.
&gt; BTW a `Vec` (actually a Queue) that can be pushed to by multiple threads is basically what a `Sender` is! Yup! The foundation of actors is really just a `Sender`, for instance. :) I obviously hadn't considered you needed multiple threads -- sorry about that! Thanks for taking the time to respond -- you published a very interesting writeup. 
I haven't tried cargo-tarpaulin, but I have had a lot of success with codecov's [rust example](https://github.com/codecov/example-rust). Maybe cargo-tarpaulin can learn something from it?
A point to make is that Rust's println!() isn't equivalent to Python's print(), but rather print(format_string.format(...)) Bare in mind that in Rust there are two ways of formatting something as a string: Debug and Display, and the format string is how you choose which is used. Without a format string, how would println!() know which string method to use on something? 
Somehow people have avoided mentioning `Box` so I just thought I'd throw out there that nearly every time I use this it's because I have a `var123: Box&lt;T&gt;` and `&amp;*var123` is a way to get a `&amp;T`. 
My thinking was that while println! shouldn't necessarily know this, the compiler certainly should.
I didn't know that. Sounds like a good community-involving strategy. One more resaon to like Rust. :-)
I think the best way in Rust of putting several things together into a string is to use format!(), which works identically to println!() except it outputs into a String rather than stdout :) Bare in mind also that unlike a lot of languages (Java/Python/...) in Rust, String is mutable (it is just a Vec&lt;u8&gt; underneath), so you can do .push_str, and += on a string. 
It probably could, you're right. Here's the relevant code for using format strings (copied verbatim) from `libstd`: macro_rules! format_args { ($fmt:expr) =&gt; ({ /* compiler built-in */ }); ($fmt:expr, $($args:tt)*) =&gt; ({ /* compiler built-in */ }); } Given that it's baked into the compiler, they could absolutely just add special behaviour for the nonliteral case. As for _why_, you'd have to ask Niko or Alex ;) I can only speculate. [This comment](https://www.reddit.com/r/rust/comments/7rcz6f/rust_is_defying_the_logic_part_of_my_brain_when/dsw8ftx/) farther down also might be why.
Agree. I have been trying to use Rust in my company but 1. domains with `rs` is blocked. docs.rs is not accessible 2. Dependency on crates through network
&gt; I'm sure they don't have warnings as errors turned on in development, but production for a huge commercial project like Firefox needs to have stringent standards to avoid falling quality and turning into a complete mess of a codebase. It should be the other way around: turn warnings into errors for debug builds, if you must, but not for release builds. The reason should be obvious - new compiler versions will introduce new warnings. &gt; Firefox 57 only supports Rust 1.19 And that's a problem. I'm not downgrading my Rust version for a broken piece of software.
Well I guess the thing is that it sounds like marketing is what I am saying. If you were trying to sell it to a business, you are on the right track. If you're trying to get contributors, start off with the tech side.
Don't hash tables typically contain about 40%-75% occupancy? I would think that for large structures the arrays being scattered would be more problematic. Unless B was the size of the cache row and started at the beginning somehow.
Doesn't `cargo` pass `--cap-lints=allow`? Or is that only for external dependencies?
yes. the current repo is here: https://github.com/steveklabnik/rustdoc however, i'm working on a private fork at the moment, for Reasons. I hope to have something to publicly announce soonish.
&gt; It's not worth your time to meet the hygiene requirements of the codebase you're working in? I'm not working on Firefox. I'm just a user trying to install that dumpster fire on my source-based distro. &gt; First of all, when you work in teams, it's important to define and adhere to code quality standards. If a team decides that warnings-as-errors is the right policy (and let's be clear, it nearly always is), then it's your responsibility to live up to that, and without bitching about it on public forums, too. *Befehl ist Befehl?* &gt; Second, you might think this is an insignificant warning, but it's actually important, for code maintainability. So have it only in debug builds, because you can abuse your team mates all you want, but it makes no sense to break a release build on a user's system. Why is this basic notion so hard to get through? &gt; The right solution is to fix the code. For the bloody developers, not us end users. Don't break my build because of your "purity of code" fantasies. I don't give a shit about warnings. Those are the developer's problem. I need your stinking pile of shit to keep compiling when a new version of the compiler introduces new warnings. Why is it so hard to understand?
&gt; Why is this basic notion so hard to get through? It's one thing to disagree on something. It's quite another to be insulting. Good day. 
You can define both Display and Debug for a type, my point is the compiler would have to make an arbitrary guess as to which one you want to use, so instead of that they just made it so you have to specify every time without exception 
Interesting project. It would be really interesting if it was extensible: for instance if I could create my own component like : ``` img_tag(href="google.com")(caption)(credit) ``` That would generate an the html code for the image + the caption + the block for credit. I'm using markdown a lot, but I really miss this kind of features.
&gt; It's one thing to disagree on something. It's quite another to be insulting. It's one thing to annoy developers. It's quite another to shit on your users. &gt; Good day. Good riddance! 
&gt; I insist on using a source-based distro but I won't bother following the proper steps to compile software for it This is entirely your own problem.
Now that I think of it `println!();` as shorthand for `println!("");` when thru this exact processes not so long ago. [link](https://github.com/rust-lang/rust/pull/36825) Also thank you for starting this conversation. Now that it is in public, google can help people educate themselves in the future. Good language/ecosystem documentation is a sedimentary process. 
There is also the broadly named project [cargo-travis](https://github.com/roblabla/cargo-travis). I started using cargo-travis first; so no idea how it compares.
Yeah, I was referring to plans for the `source-map` library. I think that between 1. bundlers statically linking wasm modules together so they all share an allocator, and 2. with dynamic linking the allocator from a CDN across wasm modules, similar to how depending on jQuery works today, we will have the tools to tackle this issue in the broader sense.
&gt;&gt; I insist on using a source-based distro but I won't bother following the proper steps to compile software for it &gt; &gt; This is entirely your own problem. "emerge firefox" is the proper step to compile this particular piece of software on Gentoo. Is this clear enough, or do I need to make up quotes and straw men to get my point across?
Yes, I hope to publish the new version on npm in the next day or so. Just tying up a couple loose ends first.
Yeah, that would make sense. I'm honestly not 100% sure what's up here, or if there are plans to change this.
Regexes are not enough for the language you want to parse. I would write a recursive-descent parser by hand. The parser itself can be very simple. In the lexer, you would have to take into consideration a few tricky things: can comments be nested? can strings have escape sequences?
Thanks for the link. This is super informal. Is it usually like this? Some guy on the Internet just stops by and says....hey let's do XXX like this. I kinda like that! :-)
The **proper way to compile this software** is to use the version of Rust they tell you to use, don't get mad that it doesn't work because you weren't following instructions 
&gt; It's quite easy to use a different version of Rust by using rustup I'd rather not. I prefer having a single point of control for all my software - the distro's package manager. &gt; If you have a problem with a big project having specific version requirements, clearly you've never worked on a big project at scale Clearly. How experienced do you need to be to consider warnings as errors in release builds a good idea? &gt; it really isn't a big deal No, of course not. Fuck the users. Mozilla's revenue was $520,000,000 in 2016. They have better things to do than fret over user experience.
Or just deref coercions, which let you write `let s: &amp;str = &amp;some_string;` (or, more often, `f_taking_str(&amp;some_string)`).
How does a company decide to block a country TLD?
&gt; the trivial solution The trivial solution is to never ever treat warnings as errors in release builds, no matter the language or the compiler. Don't do it in C++, don't do it in C, don't do it in Rust, don't do it with LLVM, don't do it with GCC. 
Looks a lot like `stpl`. Eg: https://gitlab.com/hackeraudit/web/blob/master/src/tpl/base.rs#L87. I wonder if something could be done around it for text editing.
To clarify, /u/huweishan, values that don't have their address taken can be stored in registers (which have no address) or be folded into other computations and cease to exist. (For that matter, if the address is never used other than to dereference it, those optimizations can still happen.)
I don't really agree. It's not especially hard to create a parser, and it's a nice skill to have in my opinion.
&gt; "emerge firefox" is the proper step to compile this particular piece of software on Gentoo Then Gentoo isn't doing their job if they don't pin it on rust 1.19.
You're working under the assumption that only developers compile code, and also under the assumption that warnings will never have false-positives. Warnings produced are heavily dependant on the environment used, mainly the compiler version; I get problems whenever I upgrade to a newer GCC version for example, because some idiots still believe `-Wall -Wextra -Werror` is a good default build flag configuration when GCC 7 nags about every single thing. Use it in your CI builds, but not as your default build flags please.
Rust pvp
&gt; Then Gentoo isn't doing their job if they don't pin it on rust 1.19. That's one way of looking at it. The other is that Firefox 57 would compile just fine with Rust 1.23.0 if only they knew not to treat warnings as errors in release builds.
&gt; At this stage in Rust and Firefox development, I think you'll get the blame pointed at Gentoo maintainers for prematurely trying to force system Rust on Firefox when Firefox and Chrome both have a history of bundling custom dependencies, like their APNG-patched (PNG spec-violating) libpng. I'd rather blame those who treat warnings as errors in release builds. This is a systemic error which will needlessly prevent using newer versions of the compiler. Gentoo's error of not specifying a Rust version in the Firefox dependency list pales in comparison. This whole discussion is not even about Firefox or Rust. It's about best practices.
So I created tarpaulin to be much more user friendly that kcov. You can replace everything in the after-success with: cargo install cargo-tarpaulin &amp;&amp; cargo tarpaulin --out Xml &amp;&amp; bash &lt;(curl -s https://codecov.io/bash) &amp;&amp; echo "Uploaded code coverage" Tarpaulin's better than kcov in some things, and generally with the --no-count option it's equivalent. There's just the odd instance where there might be a false negative, but those get less and less each day :)
cargo-travis just handles all the kcov installation and running for you, because it can be tricky to get all the options right etc. So it's a mixed bag. There are somethings tarpaulin can do that kcov can't (correctly handle coverage results for templated code) but there are still some benefits to kcov. But kcov in my experience has a lot more false negatives. 
Am glad I checked. That sentence felt fishy.
In general, I expect Rust's HashMap to be pretty packed, yes. The catch is that if you have removed elements, the array doesn't shrink by itself, so your occupancy may be plumeting down.
Interesting. So if you know that you will be iterating through a fairly stable set of key/value pairs often, you might use BTreeMap regardless of other characteristics. Sorry I should read the docs but so you know if it's possible to tweak the size of the backing arrays?
Congratulations on mastering English well enough that readers assume that you are a native writer, so readers are willing complain about the tone and nuance of your text. :) Phrases like "next modern platform", and "aligned with the goal", are not commonly heard when programmers speak with each other. Instead, these phrases are more commonly heard from a salespeople or a CEO/CIO, and I think this is why people complain that the text "sounds like a marketing pitch". The nuance here is that you are indeed trying to market or pitch your project. A good approach in this situation, with this audience, might be to focus on demonstration: show specific things does and specific problems it solves.
You're free to blame whoever you want, but your current attitude is abrasive enough that it's more likely to get you added to the block/ignore lists of people with the power to change things under the heading of "Ugh. I'm too busy and under-caffeinated to deal with this s##t". You're not paying them, so you don't get to make demands about the order in which they address problems with their codebase.
This thread has turned rather uncivil: - your opinion may differ from the OP's, - the OP may have used a slightly aggressive title, but that is no reason not to keep things civil. Respect and courtesy are expected of *all*.
Might make sense to create GitHub issue about that then, so it at least can be discussed before it's too late. https://github.com/rust-lang/rust/issues/47599
This is the least formal way it can go, but a pretty common way. For **Big** changes the posses is: 1. (Optional) Pre-RFC: a post on internals.rust-lang.org to discuss the idea. 2. RFC: a pr to https://github.com/rust-lang/rfcs with a formal description. 3. Discuss/Edit till consensus is reached. 4. The Sub team decides to merge, postpone, or decline. 5. The RFC is now in Final Comment Pearead, the discussion will continue for an additional week. 6. If the consensus still holds than the Sub team adoptes the PR. 7. Development happens in the code, but behind a feacher flag. So one can only use the new feacher on the nightly release with an explicit opt in like `#[feacher(nll)]` 8. When all the bugs and bikeshading have been worked out. 9. The feacher is now in Final Comment Pearead, the discussion will continue for an additional week. 10. The team approves the feacher and it will be in the next beta. For smaller changes some steps are skipped, afften all the way down to the `Some guy on the Internet just stops by` system from that pr. The **Best** part is that everyone follows this process, eavan the core team! No BDFL deciding that everything is changing. No pay to play board coming down from on high with the new release that they haven't told anyone about. 
&gt; Fix your warning. You are assuming that the OP is a developer. Compiling sources is used in a number of distributions (such as Gentoo, I believe), in which case the OP is merely a user and may neither have the knowledge nor the willingness to modify the code they are attempting to compile. Please avoid such sharp rebuttals, they just spark conflicts.
I have been scalded by GCC too, mostly because GCC has historically had a number of flimsy warnings in those flags. There is no reason to assume that rustc suffers from the same issue, and therefore that practices from GCC should be reused with rustc without further examination. Also, given its much smaller user base, even if there currently are issues with rustc, we have the opportunity to fix them because they become entrenched!
Haha, yeah I figured it isn't THAT easy every single time! :-) Thanks once again for your detailed explanation!
What would be the easiest way to obtain a glfw::Key from a string? https://docs.rs/glfw/0.20.0/glfw/ Since you can't loop over enum values, it's not as easy as just comparing strings with `stringify!(enum_value) == string_value`. Surely something like this should be possible?
Hello /r/rust! So I've written this little toy programming language that compiles to some stack machine instructions. The instructions are represented as an Enum. Something a little like [this](https://play.rust-lang.org/?gist=4806ce9c4ab3f5351522efeb3cacccae&amp;version=nightly). I'd like to write a little "optimizer" for this. So for example if the ``instrs`` vector contains `Swap, Swap` anywhere I could just remove the two instructions since swapping twice does nothing. Or if there is `Const(20), Const(30), Add` I could replace that with just `Const(50)`. I've been wondering if there is any thing in rust (maybe a crate) that could help me with this. So essentially I'm looking for patterns in the vector.
Thanks for the feedback I'll take note of this, and I would definitely use your advice on my next post on future updates.
Thanks, I would try again to rephrase it on the next update.
The warning-as-error showing up is just a symptom of the fact that **you are using the wrong compiler**
&gt; The warning-as-error showing up is just a symptom of the fact that **you are using the wrong compiler**. I wouldn't be so harsh. There are many things that the Rust compiler gets right. We should not throw everything away just because its most important developers should know better than treating warnings as errors in release builds.
I'm quite keen to help organize some low key events around here (Wellington, New Zealand). Have organized the local PyCon before, so do have some experience. And Xero is a friend of Rust, so there is some local commercial support. But I need to get my book finished first before taking on more projects!
There are many ways to deal with this issue. For example, one could imagine having a specific flag for the compiler to simply ignore all lints, which would be used by distributions. It would nicely distinguish between the different needs of "developer" and "user".
Another New Zealand resident! Where are you based? I'm in Wellington. Perhaps we could have virtual meetups over hangouts that are timezone friendly?
&gt; This thread has turned rather uncivil The bigger problem is that it turned rather censored. Being able to freely discuss technical matters in public is more important than the comfort of keeping things civil.
I agree. Though, honestly I kind of wish WASM would ship an allocator instead. It would be nice if things compiled to WASM could simply rely on the allocator that is likely already bundled with the browser (Though, that might be somewhat dangerous keeping memory safety... still, could be worth it).
Deref coercions don't affect trait dispatch. You often need `&amp;*` when passing to a generic function. (See for example: everyone using `r2d2_diesel` prior to Diesel 1.1)
I would not say “somewhat welcoming community” this community will help you to get into the language. They are he most helpful and kindest community. Personally what I don’t like is all he webframeworks, I don’t think rust was designed for that. From my research it was designed for systems. Don’t get me wrong web frameworks are cool, but is that the best use for rust?
Oh, and a belated question: how index-based and pointer-based data structures compare performance-wise? I know that indexes allow for a more efficient arena allocation, and that you can sometimes use `u32` for indexes, saving some space. However, I've never actually benchmarked the two approaches. Is there any interesting blog-posts/papers with such benchmarks?
I think `pom` is more sane and concise than `nom` you will have shorter code to write and easier to read. https://crates.io/crates/pom
I'd say `as_ref()` is possibly more confusing and/or ambiguous depending on the context. It's also a trait, `AsRef`, but unlike `Deref` any type can have multiple `AsRef` implementations. If you have `&amp;*var123`, you know there's exactly one type that produces (the `Target` of `Deref`). With `var123.as_ref()` there are multiple potential targets, and in most scenarios where you need `&amp;*var`, the compiler is already missing that information. I mean, `String` implements `AsRef&lt;OsStr&gt;`, `AsRef&lt;Path&gt;`, `AsRef&lt;str&gt;` and `AsRef&lt;[u8]&gt;`. I agree on `as_str()`, but I'd usually prefer `&amp;*x` to `x.as_ref()` if those are the only two options.
That's fine. I did run in to the issue with the latest nightlies, so hopefully your patch gets merged soon. My free programming brainpower is highly variable, but if that patch gets merged soon, I may take a stab at updating your MSP430 crates. It would be really neat to use rust on the MSP430 platform.
You're equating OOP with java's implementation of OOP. I agree that the advantages of java design paradigms are largely exaggerated in schools and (still) overhyped in buisness, but OOP ain't java. But even then java has Interfaces, which are essentially a more limited version of traits. OOP in general also doesn't make things simpler than let's say plain functions, but it is undoubtedly an incredibly useful paradigm for abstracting, structuring and reusing. &gt; OOP is not a zero-cost abstractions. Neither are Traits. rust has trait objects, which also require dynamic dispatch. But even if you don't use trait objects and monomorphize everything, you might still end up slower than with a vtable due to cpu caching. &gt; OOP is not obvious | simple. Without prior knowledge (esp. in mathematics), OOP is as comprehensibile as Traits. When used with generics (which afaik all major language except go do) both get complex. Now in defence of Traits of traits I have to say there's one big advantage of traits: Traits are additive, while inheritance is hierachical. This is what I believe the perception of traits being more simple comes from and that's why I prefer them as design pattern.
Seems weirdly inconsistent, especially because println!("x={}"); is an error, but let s = "x={}"; println!(s); would not.
&gt; Don't hash tables typically contain about 40%-75% occupancy? That is true for classic implementation, but there are much more efficient ones [Modern Python Dictionary by Raymond Hettinger](Don't hash tables typically contain about 40%-75% occupancy?). I wonder if something like this can be ported / implemented in Rust. You basically get the best of both worlds -- it is an efficient, ordered dictionary without memory waste.
&gt; 0 Releases ಠ_ಠ
HA! :) It's more for naming web server releases that simply progress and aren't semantic. We're building an automation for CI/CD and I was playing around with making a stable release name that's easier to read than a git-sha.
Ok, but you should dog food the tool and make a git-release-name release with a name generated from git-release-name. 
this looks like a great tool though! IMO it should be released with a self-named version, 0.1.0-drawlingly-about-scapegoat or something like that?
Have you looked at the [`Key::name()`](https://docs.rs/glfw/0.20.0/glfw/enum.Key.html#method.name) method?
Congrats!
Yes, but I would like the inverse.
I'm 90% process name is just the executable name of your executable file? If you rename your file and re-run it, it should take that new name.
Argument 0 of println must be a "constant string" and never a variable name. Even ig the variable value is actually constant. The reason behind it is that println is a macro and it does magic behind the scenes with the first parameter instead of using it as a normal string.
Fair point. But then another macro to do this would be a welcome addition.
lol: ```rust fn main() { Game::from_toml("examples/adventure/game.toml").exec(); } ```
/u/oconnor663 thanks for your answers. I just formatted by myself: logger.send(Severity::LOG_INFO, ["Fancy: ", "adjusting Fan ", &amp;pipe.fan.id, " to ", &amp;(step.rpm.to_string()), " rpm"].concat()); and it seems ok now. Renaming the executable wasn't a suitable solution to me :)
An important option to keep in mind is that you can swap SipHash for Fnv to speed up the hash table (in exchange opening you up to much worse performance when dealing with pathological or malicious data).
https://www.reddit.com/r/rust/comments/7p75ab/why_rust_what_i_want_changed_for_rust_to_help_way/dsffe19/
You can't use a for loop there. `$x` is not properly expanded in the _body_ of the for loop, because it's got no `$(...)*` around it. Basically, at that level `$x` is still _multiple_ identifiers. You can do something like let mut $id: $type = $initial_value; // has to be somehow initialized $( $id = &amp;id + $x; ) Though I'm not sure if that would work with `$id` inside the dollar parens, macro may get confused what to expand (on mobile right now, cannot check). If that's the case just replace `$id` with whatever identifier and declare the binding to `$id` at the end of the macro.
Yes, I know about this one! It's a better experience than kcov for sure! But line coverage is really frustrating as is, and a more in depth analysis is probably non-trivial to implement. (I only tried the crates a few months ago, please do correct me if I'm wrong!) 
Well, macros are always things you should be wary of.
It's nice to know tarpaulin's a better experience as that's what I was aiming for. Line coverage is a bit poor as coverage goes. I'm hoping to have branch and condition coverage done this year - branch isn't too difficult, but condition is quite tricky. But, if you have condition coverage you can use the same implementation to make branch coverage so I'm going for the more tricky one first. So hopefully good coverage will be in Rust 2018!
It's not actually clear to me how strong the hash function needs to be to avoid bad performance with malicious data... anyway, Fnv is *really* fast for cases where that's not a concern; I tend to default to it in any project that doesn't have DOS as part of its threat model (or for which DDOS is trivial for reasons other than the hash map implementation).
You don't have to name your releases if you never release anything! #rollsafe
Quick shoutout to the excellent library [ordermap](https://github.com/bluss/ordermap)! Keys are ordered by when you inserted them, but you can call `sort_keys()` to do an in-place sort.
hehe, touche! Except it was for naming a sha a human readable string instead of reading "ab34de2f".
Good point! I can update circle to tag each commit after it builds :)
Wouldn't a &amp;* on &amp;String simply give you the &amp;String back? I'm thinking you'd need to it to a direct String to get &amp;str, or equivalently &amp;** on a &amp;String.
I'm from Melbourne and we have a meetup every month or so. We could probably arrange for it to be streamed so people on the same side of the world could listen in (at a reasonable time).
Totally down for that if it's feasible. Recording might work better for me though (kids &amp; work make blocking out time to watch stuff on my PC a bit tricky)
How can I make the following function work: pub fn parse_vecstr(value: Value) -&gt; Result&lt;Vec&lt;String&gt;, Error&gt; { if let Value::Array(v) = value { v.into_iter() .map(move |e| match e { Value::String(s) =&gt; { s.into_str().ok_or_else( || failure::err_msg("non-utf8 values in array"), )? } _ =&gt; return failure::err_msg("nonstring value in array"), }) .collect() } else { return failure::err_msg("cannot parse array"); } } The `Value` type is from `neovim_lib`, but I don't think it really matters. What I need to do (and it mostly shows above, although it does not compile) is: * Check if I got passed an `Array(v)` where `v` is a `Vec` and extract `v` * Run through `v` and for each element, check if it is a `Value::String(s)` and extract `s`, and call the fallible `into_str` on it. The result of this call is a `String`, if successfull, or `None`. * This way I should get a `Vec&lt;String&gt;` in the happy case. If any of the above fails, I just need to return an appropriate error, the moved argument `Value` can be discarded. What I'm struggling with is the `map` call, since every error I can possible return inside is would just be stuck into the final result of `collect`, but not return from the function, so I can't possibly form a `Vec&lt;String&gt;` when `into_str` returns an `Option`. Or....? Can I? I assume that's sort of a commonish problem, but I can't think of a solution, nor of proper google search keywords. Any help appreciated!
If you're willing to use nightly the slice_patterns feature makes it pretty easy to do with arrays. Without that it would probably be easier to build an AST and match on that. https://play.rust-lang.org/?gist=272be05e355d1f0f9564e8cc63df6905&amp;version=nightly
The video of the talk is now up here as well: https://www.youtube.com/watch?v=Cy9NUVaiYUg.
thanks, I will check it out!
Thanks for info. I am not familiar with those term but will definitely research it!
i looked at haml but it was more focused on indentation than brackets. I also thought to write parser using library but got confused with nom, not sure how to bite it.
I don't know any part of inheritance which prevents any of that. Especially when you allow it dynamically.
thanks! you can combine it with handlebars! (use partials) the idea is to clean the html parts.
If I don't install untrusted software on my computer and don't want any slowdown, should I still install the meltdown windows update? How likely is it that it can be exploited from js in a website?
But... can't you just get around this by removing the line?
This is actually a very cool idea that seems obvious in hindsight! Since Rust has such an expressive type system, why not take it as far as we can?
I am literally dealing with this right now. I'm building a CLI app, and thanks to it growing, i'm just starting to eke out my own config struct... this is much, much nicer! Excited to give it a try soon :)
You're ignoring the important part, what the time complexity is relative to. Let n represent the number of items in your hashmap / hashtree let l represent the average length of the item you are putting into the tree. n is obviously going to be far bigger than l in most cases a hashmap is going to be O(l) -&gt; linear in relation to the length of the input a btreemap is going to be O(log(n)) -&gt; logarithmic in relation to the number of items in your tree In the majority of cases l &lt;&lt; n and such O(l) is faster than O(log(n))
A few other things I remember from watching it - Checking in dependency source into source control (i.e. have a 'support' folder) - avoids relying on crates.io to be immutable. - Let main program inject things into libraries name spaces. - Let libraries have an 'exports' list that works rather like std's prelude does in rust.
A means of passing configuration changes callbacks or a notification of configuration change could be interesting.
Capability-based security is awesome, and this is a nice application of that model to API design! Very clean and intuitive. 
I have gotten around this internally using `cargo vendor` to interface with crates.io manually. I'm also using `cargo raze` to build rust with bazel.
When I gave it a go, it didn't keep all the css styling. Also, (I ran it through wine) I couldn't use the numpad. One other issue was with the gtk overlay. It defaulted the background to gray, even though I hardcoded it to transparent, which causes the beer color in the glass to be gray tinted. Any idea on how to fix those issues? It worked great otherwise :)
I don't think this is related to the RustBelt conference -- just a coincidental name collision?
Correct.
This talk was dense, but awesome. Great work!
ordermap crate
Habit from rust mostly, and I like being able to see when a name is from the top-level (instead of being a local)
The [itertools](https://crates.io/crates/itertools) crate has a ready-made solution for this in the form of [fold_results](https://docs.rs/itertools/0.7.6/itertools/trait.Itertools.html#method.fold_results). You can write a slightly worse version of it using regular fold only: [playground](https://play.rust-lang.org/?gist=cb10d3f61e1aacb47a192a3db6128dcd&amp;version=stable) 
Just published a blog post: https://redd.it/7rnyg8
You may need to copy over any additional theme assets. I only copy the exe and dll's for now. You also may need to modify the gtk config in the share folder. If it's not one of those issues I can take a look.
This is such a beautiful library -- and I'm really enjoying the emerging pattern with this, [failure](https://github.com/withoutboats/failure), and [structopt](https://docs.rs/structopt-derive/0.1.6/structopt_derive/) of using custom derive to make things as simple as "write your struct and go".
In my case, it doesn't bother me because I normally write Python with my "IDE" being Vim + Syntastic (PyLint + Flake8) + `git gui` + a Quake-style slide-down terminal I use for running my creation, firing off test runs, etc. Moving the Syntastic part to being a clippy command I run periodically in the terminal isn't a big bother.
For that specific repository, it should be stable-able using now-stable custom derive. See [derive-more](https://github.com/JelteF/derive_more) for an full example.
This seems like a more general form of dependency injection, how do you currently handle it?
[removed]
What's the easiest way / standard practice for conditional compilation that affects a lot of how things are handled? Say I have the following in my Cargo.toml: [features] default = [] extra_feat = ["some", "crates"] Then in one of my source files I have a struct that has a different set of fields if it's compiled with `features = "extra_feat`, so its `impl`s have to change too. Is the way to do this really just a bunch of `#[cfg(features = "extra_feat")]` and `#[cfg(not(features = "extra_feat"))]` everywhere (including on the `extern crate` and `use` statements)? That seems incredibly tedious and a bit distracting for people reading the code later. 
There's a very classic StackOverflow answer explaining why you can't use regexes to parse a language like this (like HTML, for example).
I did more words because I got a couple requests for it. I added the `doc-upload` functionality to `cargo-travis`, so thought I'd share the full CI setup that I'm now using for my own projects. Hopefully it helps someone else out in setting up a great CI stack.
Thanks for the reply. Midi sequencers need lots of IO and as much memory as possible. 10-30 buttons with matching LED's, depending on the design. Usually a display, I'm looking at a TFT over SPI. 3x UART for Midi DIN in/out and multiple PWM for Control Voltage. Memory is the big killer. Sequence data needs to be in ram to allow for non-stop access. It's no use playing a 1 hour set and you need to pause the sequencer and load data after every song. Also timing needs to be tighter than a gnat's chuff. Midi clock should be less than a millisecond drift if possible. I'm currently looking to prototype using Micropython on an ESP32 but will move to Rust for the proper usable build. I'll know I'll need to MUX heavily to support the IO requirements. This well trodden ground in the DIY community. The Midibox project builds on a STM32F4Discovery with C++ and is a great platform. It's right up against memory limits though, something I'd rather avoid. 
I never know what people mean when they say "dependency injection," but we don't really handle it in any insightful way: main() { pgpool = pgfool_init(env); foo = foo_init(env, pgpool); bar = bar_init(env, pgpool); // hand foo and bar to everything that needs it } In particular, `foo` and `bar` essentially live for the lifetime of the program and are initialized at program startup. So what I'm talking about is just initialization. It's true you could extend this idea to arbitrary dependencies throughout one's program, but that may be a harder problem to solve. I don't know. cc /u/desiringmachines 
Hi everyone! New to rust, so decided to write a simple string processing tool...felt a little more complicated than expected, given that `char` and `String`
With rocket how do I do work off the main thread in a request? I can't work out how to get a reference to a thread/threadpool/channel into a request handler because rocket's managed state requires `Send + Sync + 'static`. Thread Pools are usually just `'static` and even channels are `Send + !Sync + 'static`. Tips?
Thank you so much for writing this! Keep up the good work! Any chance that cargo Travis can generate coverage information for doc tests ??
I have read the documentation at e-rights.org a few times over the years but still don't really get how capabilities work. Any pointers to other material?
why use git exclude? isn't that what .gitignore is for?
This library looks great, but something about the required use of a global static rubs me the wrong way. Is there a reason the `Configure` trait can't look more like this: ``` trait Configure { fn generate_with&lt;C: ConfigSource&gt;(config: C) -&gt; Result&lt;Self, Error&gt;; fn generate() -&gt; Result&lt;Self, Error&gt; { // Call generate_with with the global source } // ... Similarly for regenerate ... } ``` I may be wrong but I don't think this should impact compile times too badly as the default impl for `generate` should monomorphize `generate_with` during the library's compilation and no further monomorphization will need to be done unless a user calls `generate_with`
Rust for embedded is promising, but in a very early stage. I’d suggest going with more proven technology and more resources available to get help. I would recommend also asking in r/embedded. 
There are some macro crates like [cfg-if](https://crates.io/crates/cfg-if) that can help you clean it up.
The reason I use git exclude here is that the IDE files are user-specific. If I expect every person to hack on the project to be using IntelliJ IDEA (or most users), I'd append the [JetBrains GitIgnore](https://github.com/github/gitignore/blob/master/Global/JetBrains.gitignore) to the `.gitignore`. But because the purpose here is to pretend that the IDE doesn't exist, we ignore the files in the exclude file, which isn't commited to the repository. [Github: "You can use this technique for locally-generated files that you don't expect other users to generate, such as files created by your editor."](https://help.github.com/articles/ignoring-files/#explicit-repository-excludes) [BitBucket: "For example if you have a custom logging setup, or special development tools that produce files in your repository's working directory, you could consider adding them to `.git/info/exclude` to prevent them from being accidentally committed to your repository."](https://www.atlassian.com/git/tutorials/gitignore#personal-git-ignore-rules) [Git-SCM: "Patterns which are specific to a particular repository but which do not need to be shared with other related repositories (e.g., auxiliary files that live inside the repository but are specific to one user’s workflow) should go into the `$GIT_DIR/info/exclude` file."](https://git-scm.com/docs/gitignore)
The last two have been recorded: https://m.youtube.com/channel/UCxZkky-NG6W-vtp5eRkekIg
Is there a way to run `cargo clippy` so that it lints test code? It doesn't do that by default and I can't find any option for it.
It seems like a good way to implement command queueing, sending the work to a thread pool etc too and make it easier to later refactor the code to use such techniques.
std is barebones by design since crates are so easy to bring in. If you just extract the prompt routine and wrap main it gets cleaner though: use std::io; use std::io::prelude::*; use std::error::Error; fn run() -&gt; Result&lt;(), Box&lt;Error&gt;&gt; { let name = prompt("Enter your name: ")?; let age: u32 = prompt("Enter your age: ")?.trim().parse()?; println!("Hello, {}, {}", name, age); Ok(()) } fn main() { run().unwrap() } fn prompt(text: &amp;str) -&gt; Result&lt;String, io::Error&gt; { print!("{}", text); io::stdout().flush()?; let stdin = io::stdin(); let line = stdin.lock().lines().next().unwrap(); line } With NLL enabled, the last 3 lines of `prompt` can be shortened to `io::stdin().lock().lines().next().unwrap()`, and `run()` becomes unnecessary once [RFC 1938](https://github.com/rust-lang/rfcs/blob/master/text/1937-ques-in-main.md) is implemented.
Oh thanks! That looks pretty neat! I guess I could use nightly but I'd rather stay on stable... But that is a nice feature. Very tempting. &gt; Without that it would probably be easier to build an AST and match on that. How would I do that? So I take the vetor of instructions and build and AST out of that?
First the positive: the code is simple to follow, and you have a test section. You could however add some docs to your code. There are some unneeded clones, e.g. `program` (if I haven't overlooked anything), and possibly some unneeded collect operations. Running [clippy](https://github.com/rust-lang-nursery/rust-clippy) on your code might yield more suggestions.
I'm used to dense mathematical notation but Ralf's notation really is remarkable!
Cool, looks neat! I don't see anything wrong at all with the rust source - it's a pretty small utility, but it's well written. The two things I could think of to improve this: - binary releases - for small utilities like this it's always cool to download a compiled binary and run it yourself. https://github.com/japaric/trust is a super nice template for using CI systems to compile &amp; provide all the binary release you need for each OS - possibly make a library? This is a pretty cool thing to do! I think it'd be awesome if you could separate the "transform text to vaporwave" and "command line program" parts of your program into `lib.rs` and `main.rs` respectively. If you have `lib.rs` have `pub` functions which do the functionality, they'll be usable by both other crates depending on your crate, and you can do `extern crate vape;` in `main.rs`, and use them there too.
Look at https://github.com/contain-rs/linked-hash-map
Hi, ordermap is very useful, but note that it is different from a linked hash map.
I saw a blogpost about Linux zircon microkernel on Phoronix. I have been amazed by people quoting RedoxOS as their wishlist. Huge project !
The slice_patterns is need to use use match nicely against the array. The simplest work around is to copy the first few elements into a tuple and match against that, you'll probably want to add a nop instruction to pad the tuple when near the end of the array, since that'll make the patterns cleaner than use a tuple of Option&lt;Instr&gt;. https://play.rust-lang.org/?gist=9d0b4ff3f549f6e1fe86af651c960c18&amp;version=undefined For an example of an AST you can google for one of the rust calculator examples, one used to show up on the front of rust-lang.org as an example. The [lalrpop tutorial](https://github.com/nikomatsakis/lalrpop/blob/master/doc/tutorial.md#calculator4) generates one later on, though that's more about parsing with lalrpop, and is for things a bit more complex than a stack machine.
Sure. I wrote ordermap, but it has differences from linked has map because it uses a different data structure. No pop front in ordermap, no freshen key in ordermap, and no order preserving remove in ordermap.
If you want to do this competitively, you should get a second screen so you can search the Rust docs while your code compiles/runs! This way, finding [str::repeat](https://doc.rust-lang.org/1.23.0/std/primitive.str.html#method.repeat) is just a few seconds away ;)
Oh, I didn't think about that. You're right there.
I have some ideas around that, I'll throw them your way when I'm a bit more prepared!
Sounds like you might be better off with a Raspberry Pi, so you can run Linux.
This looks really cool. What i missed in this post (maybe there is a part 2 in the future) is how we grant those capabilities. Maybe it is 100% obvious but i would certainly increase the value of this post if we could grasp a glimpse of what the author have in mind in that regards. I would certainly go for something like a capabilities factory where i have to put an authenticated user object in and a capability i want to use. Inside this factory its checked if this capability is granted to the user (via Roles or whatever measure you like to implement) and i get back a Result wrapped capability. We should also make sure that we cannot create capabilities outside this factory like steve described [here](http://words.steveklabnik.com/structure-literals-vs-constructors-in-rust) very nice idea indeed and as some other here mentioned it would be interesting to see how this turns out in practice, systems like this tends to be exhausting if they get really big.
There is definitely a need need for a configuration library. I have tried using serde for configuration but declaring default values inline isn't really working. So I ended up with two configuration structs, one that has all its parameters under `Option&lt;&gt;` that serde can then deserialize and a second one that has the parameters not under `Option&lt;&gt;` which I construct from the first one using unwrap_or. That's quite ugly... The workflow suggested here looks much nicer via using a default impl. If there is a point to criticize then its probably the use of global mutable static variables. They do make your life easier for the simple use cases but in the other use cases they make it harder. For example, what if you want to use multiple instances of a library, each with its own configuration? I've heard people ranting about the Steam VR API about it only letting you connect to one device because it all works through global state... Configuration never stops being a parameter. All you do is hiding it, making it harder for people to find out there is an option for configurability at all, and if some parts of a library depend on configuration while others don't you have no idea either except if the docs are mentioning it which is unlikely. I'm not sure whether the endorsement to always provide a non-singleton way to set the configuration is enough or whether the library should stop endorsing the singleton pattern completely.
I'm slowly building a list of why I should install a second screen for streaming. Though in this case, the time threshold to win so ridiculously low it wouldn't have helped! I didn't want to compete, I succumbed to chatter pressure. :) At least I have a good excuse for failing though, not knowing the language and all.
Hey thanks! I don't want to clone, but you reminded me that I don't have to use the iterator adapters, but can simply construct the vec upfront and then run through the function argument with a plain `for` loop and do my stuff. Works, thanks again!
I really like the idea but after reading your post, I'm not sure how to use it. Should I check permissions in the `CanSave::save`? Or maybe I should check permissions only once, when creating `Db` and I should have Dbs like `AnonymousUserDb`, `NormalUserDb`, `AdminDb`? But then, how can the type system help me?
Even if you don't want to do this under time pressure, it was great fun watching you :) (I only viewed a few segments of the recording, though.)
I found the line db.perform(Find(user_email))? kinda interesting. user_email is a String and the result type of perform doesn't take part in instance resolution which is rather the point of associates types. But that means that the only possible query with a string input is `email -&gt; user`. I know type inference would take but wouldn't it make sense to parametrize over the result?
You don't need to clone, that's just because the original iterator was over references. Since you're doing `into_iter` both `fold_results` and the hand-rolled version will work without it: [playground](https://play.rust-lang.org/?gist=e59a134ee0cd2ba2a193058af21364d6&amp;version=stable)
Ah yeah, right, I kinda missed you passed in a slice in your first example. Thanks :)
&gt; I'm not sure whether the endorsement to always provide a non-singleton way to set the configuration is enough or whether the library should stop endorsing the singleton pattern completely. I would really avoid singletons altogether, if possible. Parallel testing becomes a nightmare, if nothing else.
How to see the source code?
Can you tell us a bit more about it? (Did you have any difficulties in the process? Which crates are you using? How long did the rewrite take?) 
[removed]
Take a look at lalrpop. It is really nice!
Can't you just use `mem::replace`?
Could you explain to me *why* exactly the MSVC target/linker is superior? Everyone just keeps saying "use msvc, it is better than gnu", but I never really see anyone provide specific reasons why. What's wrong with the GNU target/linker? It seems like the GNU target is much easier to set up and get working and does not require dealing with messy proprietary Microsoft crap. There better be some great advantage to the MSVC linker that justifies all this effort and ugliness.
Rust is still in a very early stage for real world world embedded projects. Certainly doable, but I've had school projects suffer from feature creep all the time. If this was a project with no deadline, by all means. Since it isn't I'd strongly recommend [ROS](http://www.ros.org). It comes with all the tooling you will need with lots of documentation and software maturity. "Kinda sorta" programmers are not going to be able to pick up a new language and write complex code. The [Erle-Rover](http://erlerobotics.com/blog/product/erle-rover/) comes with support OOB and should be able to carry whatever you need. I am sure there are cheaper alternatives if you want. Best of luck!
I would second using ROS for anything in which you're going to have to do complex mapping and localization. It has a significant learning curve, but a much lower one than developing your own SLAM on an embedded device. You can run it on an embedded ARM board or a small Intel board. Using Linux with ROSS takes care of most of the points you mentioned. In addition, using Linux will allow you to write userspace rust if you would want to continue using rust.
Cool concept! However, I'm puzzled by this particular default choice: &gt; If that env var is not set and there is a Cargo.toml manifest &gt; present, we will look up the bar member of the &gt; package.metadata.foo] section of the manifest. It seems strange to have `Cargo.toml` files floating around when _deploying_ a program. Surely a better default is the `bar` member of a `foo.toml` file? 
I have started doing it (also one of my colleague plan to do it). Do you know any such group? I'd like to consult about some stuff :) I am only blinking the led from C. From rust, it is always on. I suspect the "sleep" mechanism...it seems too few "nop"...and I don't have an oscilloscope at hand (my father has a very old, big and heavy one from the USSR or GDR. Maybe I will borrow it).
That is a really nice explanation of dithering!
The `CanSave` trait isn't one that I would necessarily suggest actually implementing. Its discovery helped guide me to the `Capability` trait, which has the power to do the things you asked about. Because `Capability` is generic on its "input" type, you can create multiple implementations of `Capability` on a given type that do the kinds of things you're interested in. Suppose we have a `SQLite` type that implements a bunch of methods for interacting with our database. We might want to grant the capability to a function to save new comments on a thread (just as an example), but want to always first check that the caller has permission to do so. We could achieve this by implementing a new capability for our `SQLite` type. I'm just sketching code below- don't expect this to run as is. ```rust struct SQLite(Connection); // Post will contain the `Comment` we want to save and the `User` that is trying to post the comment. struct Post&lt;T, U&gt;(pub T, pub U); impl Capability&lt;Post&lt;Comment, User&gt;&gt; for SQLite { type Data = Comment; type Error = DBError; fn perform(&amp;self, post_comment: Post&lt;Comment, User&gt;) -&gt; Result&lt;Comment, DBError&gt; { // Here is where we can check permissions and do the save operation. if self.user_can_post_comments(post_comment.1) { self.save_comment(post_comment.0) } else { Err(InsufficientPermission) } } } ``` This assumes we have some methods like `user_can_post_comments` and `save_comment` on our `SQLite` type, but the point is that these capability implementations are just functions we're writing. They can do anything you want, and accept any type you want. We could now write a function that requests this new capability. ```rust fn handle_comment_post&lt;DB&gt;(db: &amp;DB, comment: Comment, user: User) -&gt; Result&lt;(), DBError&gt; where DB: Capability&lt;Post&lt;Comment, User&gt;&gt; { db.perform(Post(comment, user)).map(|_| ()) } // ... impl Handler for MyRequestHandler { fn handle(&amp;self, req: mut Request) -&gt; IronResult&lt;...&gt; { // Suppose `MyRequestHandler` wraps a `SQLite` // And that we've loaded a `Comment` and `User` from the request handle_comment_post(&amp;self.database, comment, user) } } ``` This way, capabilities get passed into functions from any of the function's call sites. I could have, instead of writing the `handle_comment_post` function, also have simply made `MyRequestHandler` generic on its contained values and used the `Capability` trait to specify the capabilities that it wants to have. ```rust struct HandleCommentPosts&lt;DB&gt; { database: DB, } impl&lt;DB&gt; Handler for HandleCommentPosts&lt;DB&gt; where DB: Capability&lt;Post&lt;Comment, User&gt;&gt; { fn handle(&amp;self, req: mut Request) -&gt; IronResult&lt;...&gt; { self.database.perform(Post(comment, user)) } } ``` In this scenario, I can restrict the capabilities of my functions, request handlers, etc. in my `main` function, when I set up each handler. The point here being that `Capability` is a trait, which means you can implement it on any type you want. If you wanted to create a new type that maybe wraps `SQLite`, you could implement capabilities for that type that only grant a subset of the capabilities had by `SQLite` itself. Furthermore, since `Capability` is generic on its input, you can define any other types you want, like `Save`, `Post`, `PostButCheckPermissionsFirst`, etc. to only allow callers to use a specific implementation.
What makes this different from a Vec?
Seems good! Let’s get this upstreamed. 
502 Bad Gateway
Dependency Injection at it's core means each component takes parameters instead of creating it's own dependencies, I think it's a confusing term because that is already the natural thing to do. I think handwritten code generally starts out in the simple way, but slowly evolves to depend on global state in the form of static Singletons (eg. Loggers) or configuration properties (eg. Env Vars, static config map). I think the point of confusion is that when people say dependency injection, they mean 'automatic dependency injection' where you would write something like main() { let app = inject!( pgpool = pgfool_init; foo = foo_init; bar = bar_init; // declare rest of available resources); } and have all of the parameters instantiated in the correct order. Back to configuration injection, if we steal from the java standard for injection, [jsr330](http://javax-inject.github.io/javax-inject/api/javax/inject/package-summary.html), the configuration api could look like this instead, impl struct Thing1 { #[Inject] fn Self new(#[Named("libname.tls.cert)] tls_cert: Option&lt;PathBuf&gt;) { // ... } } impl struct Thing2 { #[Inject] fn Self new(#[Named("libname.address")] socket_addr: SocketAddr) { // ... } } which then is conceptually easy to extend to more generic [automatic] dependency injection, though with additional setup required. 
&gt; "Kinda sorta" programmers are not going to be able to pick up a new language and write complex code. They'd have to pick up C++ as well. Most of them have Matlab and/or Java and/or Python experience only.
Nice sample. It's a little slow for me, but such is life. You can optimize a little bit the palette extraction by using a `HasSet`: use std::collections::HashSet; let mut colours = HashSet::new(); for pixel in target.pixels() { let rgba = pixel.2.to_rgba(); colours.insert(rgba); } let colours = colours.iter().cloned().collect::&lt;Vec&lt;_&gt;&gt;();
The css is actually compiled into memory just like the glade file. I tried modifying org.gtk.Settings.ColorChooser.gschema.xml in the share folder, but it didn't seem to change anything.
The best kind of deprecation in getting it upstreamed :). Thanks a bunch /u/japaric &lt;3
Seems like a no-brainer if we already have `Option::take`.
Sorry, should have been more specific. I meant share/gtk-3.0/settings.ini, I set the theme to Windows10 there. It may be overriding some of your settings. I'll try to take a look later today.
Awesome, thanks :)
I was agreeing with you :) If we already have `Option::take`, I think having a method for the case where you want to replace the value with `Some` instead of `None` makes perfect sense.
Looking forward to how we integrate xargo into cargo. This is a good small step for that to happen.
They’re agreeing with you, saying if we have one, we should absolutely have the other.
EDIT: Sorry I'm not a native english speaker and miss understood "no-brainer". Sorry about that :heart:
You can have one `mod` for each set of features to reduce the amount of `#[cfg]`ing you have to do. Also, don't forget that `#[cfg]` can be applied at more granular levels than just the item if desired.
No problem &lt;3
Not gonna respond to that, because I find your comment very unconstructive.
The implementation does not appear to be gamma correct: the error should be calculated in a linear colour space (hence why the dithered version appears brighter around the edges than the original, and why the two-level version appears to have rings)
Hi, thanks for your comment. You are correct, I haven't done anything special in this implementation, just implemented a very basic algorithm. I must admit I'm not too familiar with working in different colour spaces, do you have an example of how the algorithm could be altered to work as you suggested?
I've been trying to write a NES emulator in rust (not concurrent), and I'm wondering what the best way to implement memory is. The general idea of my architecture is that each component is glued basically by the memory. The problem is, it's not just the cpu that accesses and modifies it. The video and audio circuits, and controllers do too. I'm running into issues with mutability. The plan was to have a Cpu struct contain a mutable reference to anything that has `get` and `set` methods with the correct signature, but then nothing else can write to memory. I don't want to have to pass around mutable references to memory in the main loop, but I'm not sure what else to do.
If we implement `Capability&lt;Find&lt;String&gt;&gt;` then we can only query for a single type (User) by giving a String. I mostly was unsure whether it is worthwhile to do trait Capability&lt;Input, Output&gt; Instead of trait Capability&lt;Input&gt; { type Data = Output Which basically just trades possible wrapper type clutter for possible type annotation clutter. 
yeah, not everything is smooth yet
tera, hyper, diesel, serde_json, lettre. The difficulties I had were figuring out how to glue together all the crates, as well as how to usem individually and the borrow checker. 
closed-source
An interesting special case of accessing configuration is accessing secrets, such as passwords, SSL certs and AWS tokens. At Faraday.io, we use [Vault](https://www.vaultproject.io/) to generate temporary secrets on the fly (it can also store longer-lived secrets). Vault enforces security policies, logging, secret revocation, etc. To access our secrets from Rust, we use the [credentials](https://www.vaultproject.io/) crate, which can fetch secrets from either Vault or from the environment (if no Vault is available). It has pluggable backends, so that you could easily add support for Vault alternatives. I wonder how this might be able to work with your `configure` design?
Maybe it sounds crazy but, could this be used in rustc?
Your RGB values will usually be in the sRGB colour space, which is a logarithmic colour space (ie. a constant increase in value of a channel corresponds to a multiplicative increase in the amount of light emitted). When dithering, you want the amount of light emitted, when averaged in space, to be as close as possible to the original image, which means you must perform the dithering in a linear space. See here for the exact formula for converting between sRGB and a linear colour space: https://en.wikipedia.org/wiki/SRGB#Specification_of_the_transformation You can ignore the XYZ part of the transform - you just need the sRGB =&gt; linear RGB part of the transform. The dithering algorithm stays the same as before, but you must convert to linear RGB before processing, and then back to sRGB after outputting it. (You can probably figure out how to optimise it so you never actually need to store the whole linear RGB image, which would have to be done at a higher precision)
You can abuse proc_derive to get proc_macro on stable actually. So this might actually be possible.
I thought the same thing when reading this. I like your idea, if I understand what you’re suggesting, given a UserAuthentication object with some set of associated UserAuthorization, implement a common method to discover if a User has a specific capability. This could for example come from a JWT... Keeping the code paths clean seems like a challenge where you may not want capabilities to be defined to deeply on a call path.
Ah, I see what you mean now. I personally opted to only accept one generic parameter because it keeps the interface simple in most cases. There's nothing stopping us from writing things like `Capability&lt;Find&lt;String&gt;, Data = User&gt;` and `Capability&lt;Find&lt;String&gt;, Data = Comment&gt;`. Though I personally think it'd be take the idea of designing a more expressive API even further, and advocate against using `String` for too many things. 
Perfect, thanks for the information!
I'm sorry, but I am not quite sure exactly what you mean by posting this old thread (1.5 year!) here. Did you forget to ask a question or leave a comment?
I can also recommend the Stellaris/Tiva-C Launchpad, which I maintain the support crate for. It's got three PWM LEDs, on-board USB JTAG programmer and good open source programming tools. See http://www.ti.com/tool/ek-tm4c123gxl and https://github.com/thejpster/stellaris-launchpad/ 
Ah! In this case, you can easily: - put a comment yourself, after posting the link, - or make a text post, and link within your explanation. Or even, simply pick a title with a question/prompt to action :)
Thank you for the clarification! I didn't pay attention to it because often I see direct links to RFCs and people comment about it, but it isn't so clear in this kind of discussions.
Thank you for the suggestion!
AFAIK, index-out-of-bounds as compile-time error is mostly a pipe-dream at the moment. To understand, the complete functionality require *dependent types* as found in Idris or Ada/SPARK. That is, it requires the ability to reason symbolically about run-time values at compile-time; for example: fn make_array&lt;T: Clone&gt;(t: T, n: usize) -&gt; [T; n]; would be an example of *dependent typing*. The value `n`, only known at run-time, is used in a type! There are no projects that I know of to get *dependent typing* in Rust any time soon, and certainly not in 2018. An alternative could be to develop strong pre-condition/post-condition/invariant support in a linter; in short to replicate SPARK in Rust. There are no such initiative that I know of. --- A *nugget* of functionality could be introduced for cases where the result is *known wrong*. With the advent of MIR, it could be possible to teach some basic range-reasoning to rustc, so as to diagnose cases such as: fn increment(array: &amp;mut[i32; 3]) { for i in 0..4 { array[i] += 1; } } as a bonus, in any case the compiler can statically prove that the bounds check is necessarily correct it could elide it... ... however the truth is that LLVM performs such range-analysis and bounds-check elision already, so it is not clear that rustc could optimize better than LLVM (providing it forwards all available information). --- And then, it is necessary to examine the benefits: - the second approach is rather unlikely to catch any mistake; in most cases the bounds are unknown, which is why idiomatic code uses iterators rather than index-access. - the first approach could catch such issues, whether by integration into the type system or annotation, could yield much better benefits, but would be extremely costly. It would require creating the linter, dutifully annotating the libraries, and it would only be leveraged when the user goes the extra mile and annotates their own code. In short, I am dubious that the efforts are worth the rewards. At best, I view this as a "stretch goal", a few years down the road.
Congrats on the release! I used pest initially for one of my projects, and it is really nice for prototyping a new language. I'll be sure to take 1.0 for a spin to check out the new goodies.
For the author and others, come and hang out with some of us in #rust-sci on IRC too. As the author of ndarray, I agree with almost everything in your post. And ndarray needs to be converted into a multi-person project for it to be successful. I don't think ndarray necessarily is an important part, it could be replaced by another crate. Integration with netcdf/HDF5 is certainly important, and I believe that has a place in the integration story as a whole too.
Found a typo: cargo install cargo-update || ehco "cargo-update already installed" `ehco` -&gt; `echo`
Interesting idea to run `cargo install-update -a`. What I've been doing instead is the [much uglier](https://github.com/cobalt-org/liquid-rust/blob/master/.travis.yml#L32) if [[ `cargo-when --version` != *$WHEN ]] ; then travis_wait cargo install cargo-when --force --vers $WHEN; fi What are the pros/cons of uploading during `script` vs `after_success` (what I've normally seen)?
&gt; A nugget of functionality could be introduced for cases where the result is known wrong. We already [have it](https://play.rust-lang.org/?gist=1758f9a6079fba46e30460a99e5a486a&amp;version=stable), but it detects only simplest cases and even with it can sometimes produce false positives.
Oh my gosh, I was totally going to give a shameless plug for [Not-Yet-Awesome Rust](https://GitHub.com/erichdongubler/not-yet-awesome-rust), but I was floored when I saw it linked in this blog post! I'm glad you think it's useful enough to mention! For anyone else reading: there's lots of issues in the pipe to add to this list. It's supposed to be actionable as possible, rather than a wish list, for the Rust ecosystem. [Take a look](https://GitHub.com/erichdongubler/not-yet-awesome-rust/issues) if you're wondering what your next impactful Rust project could be. :)
I have this code which works: let timeasint = time.parse::&lt;i64&gt;().unwrap(); let timespec = time::Timespec::new(timeasint, 0); let utime = time::at_utc(timespec); let stime = utime.ctime(); I'd like to make it more consise, like: let stime = time.parse::&lt;i64&gt;().and_then(|t| time::at_utc(time::Timespec::new(t, 0))).ctime(); But, as you can see, I don't have a great grasp on this syntax. I get the error: let stime = time.parse::&lt;i64&gt;().and_then(|t| time::at_utc(time::Timespec::new(t, 0))).ctime(); | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ expected enum `std::result::Result`, found struct `time::Tm` Any hints?
Good thinking on the energy. We're currently using 8 rechargeable AAs in a bag essentially. This should be somewhere in the neighborhood of around 10 Wh? The pi seems to draw 4W, and I don't know how much power the motors draw. So it's probably OK. But I will definitely keep an eye on it.
It's a fair amount of boilerplate if you ask me, but you can do this using the `#[serde(with)]` attribute, which lets you hook into both serialization and deserialization with custom functions: https://play.rust-lang.org/?gist=40e3317b2ce3f292764ff8cb4909664b&amp;version=stable
I've been really impressed with this plugin. The inline error checking and compiler comments is amazing. Looking at the link notice there is a lot of other things... I need to read up and explore what else it can so to help.
See, I tried to use pest a few times already, but it never really "clicks" for me. For example, I read the documentation and everything, but when it comes the time for me to use the parser to transform a file into an AST, I get easily lost in the Pairs API. Not to mention the `state` function, which I always see in the documentation but never have seen it used anywhere else and don't know if it would help me write my parser. I guess the point that I'm trying to make is that I'd love if there were more and better documentation. For example, I still struggle to understand what exactly a `Pair` is supposed to be or represent. I could do with more examples for that. Also, it would be great if the book could be finished sometime soon. I feel like it would help me a lot to understand what I explained above. Once those pain points (at least for me) get worked on, I'll be more than glad to start messing with it again! :D
Did anyone give wrapping arrow a go?
there's full support for playback operations (play, pause, stop, skip, add track to queue, remove track from queue) but no support whatsoever for track searching. feel free to contribute if you're feeling generous ;)
Maybe the [`input`](https://crates.io/crates/input) crate?
If you're talking about using this [libinput](https://www.freedesktop.org/wiki/Software/libinput/), there are rust bindings there : https://docs.rs/input/0.4.0/input/
While I love rust and actively support its use, I don't think it there yet for your use case. Especially when you have a deadline to meet. Others have suggested a raspberry pi 3, you might also want to look into a beagle bone. Just like the pi, it runs Linux and you can still use ROS and rust in userland if that is your desire.
&gt; For example, what if you want to use multiple instances of a library, each with its own configuration? These libraries do not have a global static. There is a global static for the source of configuration for all libraries.
&gt; Parallel testing becomes a nightmare, if nothing else. What do you want to test in parallel that this static makes problematic?
Yea, I've thought about secrets - or more generally, when what's in the config source is a reference to the actual item you need in configuration. Still working on whether or not its something that can be configures responsibility
This fallback is for local development environments. Production/staging/etc should use env vars.
Working on a booklet right now, but it's still WIP. :D I'm open to accepting any help I can get on the docs.
that's the api doc, I need a tutorial.
I have. I'm going to use the dtolnay trick to always re-export the static from version 0.1.0, so that every version of configure uses the same static. I will not make breaking changes to the API that the static exposes.
The dockerfile is here https://github.com/etrombly/rust-crosscompile. I ended up changing the css and glade file to use relative paths, and changed the font to Segoe UI. I had to manually copy over the icons, but after that things looked mostly right. It still seemed like the transparency wasn't working though (this was on windows, not wine). Looks like I'll have to add some options to specify other assets you want included in the package. Also you'll probably need to make a build script that checks the target os environment variable and swaps out the glade and css files. As it is the program looks fine, other than when you mouse over the close and minimize icons.
Have you compared the performance with peg crate?
Thanks, that works. I'm not sure I entirely understand *why* though. Sync means it's safe to access concurrently right? So what does Send mean? I don't understand what resource wouldn't be safe to send between threads.
Well, this crate is maintained by /u/drakulix and afaik no tutorial specific for it exists. So your best course of action is likely to find a tutorial for the C libinput and map it to the risk crate using its API docs. 
I'm still not sure what is the profit of using `Capability` trait instead of simple `trait DB { fn post(); fn save(); ... }`. Don't get me wrong, this idea sounds very interesting to me but I still don't see what kind of problem it solves. Becuase when I have, let say, a couple of handlers like yours, and I use `Capability&lt;Post&gt;` and `Capability&lt;Save&gt;` in my code then I cannot create and use db that will only implement `Capability&lt;Post&gt;`, becuase my code will not compile. So the question is, what are the benefits of using `Capability&lt;Post&gt;` and `Capability&lt;Save&gt;` instead of `trait DB { fn post(); fn save(); }`?
I found a path to the IR receiver and did this: cat /dev/input/by-path/pci-0000\:00\:1d.2-usb-0\:1\:1.0-event-ir | hexdump -x I feel like a hacker in the Matrix at the momemt, but don't know what I can do with the great insight: UP(+) 0000000 b24a 5a63 0000 0000 6a3c 0009 0000 0000 0000010 0001 0073 0001 0000 b24a 5a63 0000 0000 0000020 6a3c 0009 0000 0000 0000 0000 0000 0000 0000030 b24a 5a63 0000 0000 094e 000c 0000 0000 0000040 0001 **0073** 0000 0000 b24a 5a63 0000 0000 0000050 094e 000c 0000 0000 0000 0000 0000 0000 :)
That's way to complicated to me :( I need something like: let device = Device("The IR receiver"); device.onEvent(|| { if event.code.eq("0073") { //do magic } });
`Vec&lt;u8&gt;` implements `Write` and `&amp;[u8]` implements `Read`. So you can just `Write` to a vector, then pass `your_vec.as_ref()` to rust-postgres.
&gt; &gt; &gt; I guess the point that I'm trying to make is that I'd love if there were more and better documentation. For example, I still struggle to understand what exactly a Pair is supposed to be or represent. I could do with more examples for that. I can only second that assessment. I got a parser working but I have no idea what it is with these `Pair`s. That said, I still found it easier than nom and combine.
Looks like a native implementation is [in progress](https://github.com/jihoonson/iron-arrow), and [bindings](https://github.com/jihoonson/arrow-rs) (of unclear status) as well.
I guess it makes complete sense to add more detail about the Pairs API both in lib and in iterators. Will try to focus on that in the next few days.
For that, I would first have to write all csv data to be able to pass them to rust-postgres afterwards. So the whole result must fit in memory twice (once in maps/structs and once serialized). Which is probably good enough, at least for now. I was looking for a solution where I could just use a constant amount of memory as a serialization buffer that would get passed back and forth between csv writing into it and postgres reading from it. Does something like that exist?
I don't think something like that exists in the standard library (and it can't, really, because it has to pull the data from somewhere), but you can implement `Read` for your own type.
I'm not an expert, but I think that is very unlikely that something like rustc (or any compiler with a similar size) will be written using a parser generator. The amount of corner cases is so big that it is easier to write the parser manually. Parser generators are still very important because most use cases don't need to deal with that level of complexity, so it is much better to write your grammar on top of them.
This is really interesting! Thanks for posting this.
Cool, when I have figured out how to use it, I'll write a mvc web framework that parses html-templates like: ... &lt;p rl:text="${user.name}"&gt;&lt;/p&gt; ... and maps rust idents and expressions to the parsed html snippet struct User { name: String}; let me: User = User { name: String::from("John")}; to: &lt;p&gt;John&lt;/p&gt; Easy. :) grammar = @{"rl"} attribute = @{ "for" | "if" | "incl" | "replace" | "text"} value_type = @ {"#" | "$"} value = @{ ('a'..'z' | 'A'..'Z' | '0'..'9' | "_" | "-")+ } html_tag = _{ "&lt;" ~ soi ~ grammar ~ ":" ~ attribute ~ "='" ~ value_type ~ "{" ~ value ~ "}'" ~ eoi ~ "&gt;" } 
How would you solve this problem: `copy_in` doesn't return until the statement is completely processed? If the data is small enough that you can keep it in memory, `Vec&lt;u8&gt;` is the simplest solution. If it's not, you can split it among processes/threads, and a pipe is the traditional Unix solution. For whatever reason Rust doesn't include them in the standard library (Posix `pipe`, Windows temporary named pipe). I would start by reading crates off of crates.io.
This is very likely me still being a noob and trying too many things at once, but functional programming and `#![no_std]` don't mix well, right? If I have a collection, then in a no_std environment it will have to be through a slice, and since I can't allocate, the slice has to be mutable and I have to do changes in place, which violates the core tenet of functional programming. Is this right or is there a way to make FP and no_std and collections work that I'm not seeing?
I would like some help with tests and files in rust. I am finally getting around to adding tests to my rust project and I have first split up my project into smaller more modular rs files, instead of a large lib.rs. I have then gone and created tests in each file. My questions are, is this considered a "rustic" program structure and am I setting up my tests correctly? You can find my code with the split files [here](https://github.com/RyanWarnock/taskers/tree/error_handling) and before they were split [here](https://github.com/RyanWarnock/taskers/tree/master).
Thank you for your job! I use it to parse jsonpath and it works really well.
I’d say it’s totally possible to use parser generator for a real programming language in a production compiler. IIRC, GHC uses a parser generator, and gcc used to use a parser generator as well. And I believe it is actually easier (less work) to use a parser generator. However, the crucial benefit of a hand written recursive descent parser is quality: you can hand craft very precise diagnostics, and you can recover from errors in a reasonable manner.
Xargo has been so great for no_std hackers, and no_std hacking will hopefully find an even bigger audience when Xargo's features are in Cargo. Thank you /u/japaric!
Dropping in for routine downer comment: As simple as it is to add, its addition can cause code that previously compiled to now not compile. That has a cost.
I think traditionally the main advantages of capabilities are (i) principle of least privilege and (ii) transferability. The trait version you propose doesn't have PoLP but does have transferability (you hand out the ability to do many things with the implementor of `DB`, all of which could leak if you call random code with a handle to the capability). If you had a `T: DB` you could mint capabilities for `Save` and `Post`, at which point you could hand them out to code you may or may not understand, with higher confidence than if you hand out the `T: DB` (imagine you also have a `fn erase()` method in the trait; how comfortable are you calling some user-supplied closure with a `T` vs a `SendWrapper&lt;T&gt;`?).
Oh wow, awesome! I knew there was something better than looping `read_line`. Had to change stdin_lock to be mutable from your example, by the way.
But then it only works on `str`. Maybe a trait implemented for `Display`, but really, why complicate things when a simple macro does the job?
In what cases could this cause code to break? Not doubting you, just not entirely clear myself on the impact this kind of change would have.
A macro doesn't have the ability to inspect the type of an identifier. 
It's trivial to disable the mitigation — see https://support.microsoft.com/en-us/help/4073119 (go to the 'Verifying that protections are enabled' section).
There are simpler approximations in common use. `x.powf(2.2)` for gamma =&gt; linear, and `x.powf(1.0/2.2)` for the other way. It's also common to note that 2.2 is approximately equal to 2.0, and optimize it to be `x * x` for gamma =&gt; linear and `x.sqrt()` for the reverse. For these `x` is your color channel as a number between 0 and 1.
What do you mean? `println!` does that just fine, and a macro that just expands to `println!` would work just fine as well.
I wanted pictures!
Does `failure` allow chaining multiple errors to the same base `Error` enum? I have a generic `Error` that I throw all my conversions into, and I want to have a specific error type for errors that an API throws. That would be another enum with its own `impl Display` that can't be handled by the main `Error` enum. Is there a way to have a shorter form of `Error(ApiError::SomeApiError(args))`? This is probably more a language restriction than `failure`, come to think of it.
I'll check clippy out! Regarding the one unnecessary clone, it was in the [getopts demo code](https://doc.rust-lang.org/getopts/getopts/index.html), likely for readability purposes which I don't need since I only need it one time. Nice catch, thanks!
It is a [hash table](https://en.wikipedia.org/wiki/Hash_table) It has similar performance characteristics of `std::collections::HashMap`, better iterator performance and you retrieve the keys in the order they were inserted (assuming you don't do a remove).
**Hash table** In computing, a hash table (hash map) is a data structure which implements an associative array abstract data type, a structure that can map keys to values. A hash table uses a hash function to compute an index into an array of buckets or slots, from which the desired value can be found. Ideally, the hash function will assign each key to a unique bucket, but most hash table designs employ an imperfect hash function, which might cause hash collisions where the hash function generates the same index for more than one key. Such collisions must be accommodated in some way. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
This was a great interview! Thank you for posting this.
I'm not sure if there's anything additional failure-specific, but I like to just add `pub(crate)` methods to errors to do this sort of thing. Something like this would make it nicer: impl Error { fn api&lt;T: Into&lt;ApiError&gt;&gt;(err: T) { Error::Api(err.into()) } } This would be alongside something like this, if I understand your post correctly: // top level error enum Error { ..., Api(#[cause] ApiError) } Then you could just do `Error::api(args)`?
So I ran into something I think I'd like to write a macro for, but I'm not sure whether it's possible/easy/the right thing to do. Basically I'll have a struct with a whole bunch of options with the following types: * String * Vec&lt;String&gt; * bool * Plain enums I want to convert these into flags for a `std::process::Command`, so taking the name of the struct field, prepending - and converting _ to -. Then taking the type and either just printing it if it's a string, separating it with commas if it's a Vec&lt;string&gt; or just printing the field name if it's a bool, and printing the field name and variant name in the case of an enum. Any help appreciated.
The two best ways I can think of: - PR `glfw` to optionally depend on https://crates.io/crates/enum_derive and use `#[derive(EnumFromStr)]`, and use that - Manually -preferably using find-and-replace- make a utility function with a large `match` block yourself.
Thanks!
Thanks!
It has been incredible to watch it grow!
Wow, thanks for the feedback! Crate things: * I am currently manually compiling for linux amd64 and manually uploading the binary every release, but trust looks very cool and I will investigate further! * I definitely considered separating into `lib` and `main`, but didn't want the binary to unnecessarily have the lib's dependencies. I tried seeing if you could separately specify deps for lib and bin in `Cargo.toml` rather than the global `[dependencies]` [but I don't think it's possible yet](https://github.com/rust-lang/cargo/issues/1982). If you know otherwise, please let me know! There is a workaround in the issue discussion but I don't want to do that. Rust things: todo
&gt; fn perform(&amp;self, Operation) Does it use deprecated [anonymous function argument syntax](https://github.com/rust-lang/rfcs/blob/master/text/1685-deprecate-anonymous-parameters.md)?
That solves another question I was thinking about but didn't pursue; I didn't know what Rust's package-private equivalent was. That'd work well. Thanks.
It's been a while since I made this project, so I don't have too many at hand. Here’s a couple I found on my computer. https://imgur.com/a/Ewwe7 https://imgur.com/a/fokYq
It seems simillar to trait system itself. What's the point of using Database: Capability&lt;Save&lt;User&gt;&gt; instead of Database: Save&lt;User&gt;? Composing seems like using newtype to restrict it's trait impls.
The reasons I don't do this: * Every library would then have to expose a method that is parametric over `ConfigSource` for this to be of any use. If any library you depend on does not expose that method, you have to use the static. * Libraries might *only* expose this method, meaning users who want to use the static would have to do this as well. * Using both the static and this would mean creating two instances of the config source, which at best is duplicate work and at worst could result in a logic error. * Libraries could - much worse than any of the other downsides - select a ConfigSource themselves, and only be compatible with that ConfigSource (probably the default source). This would be a completely incorrect use of this API, which the static-based API does not enable. But perhaps the most compelling reason not to do this: vague uneasiness about using a static is not a reason to add new APIs to a library. There is no reason not to use a static, a static is the correct solution for this use case.
I want to abstract mapping a function over an `Option&lt;Vec&lt;T&gt;&gt;`, but I can't get the type signature right. So far I have: fn map_op_vec&lt;T, U, F&gt;(sv: Option&lt;Vec&lt;T&gt;&gt;) -&gt; Option&lt;Vec&lt;U&gt;&gt; where F: FnOnce(&amp;T) -&gt; U, { sv.map(|v| { v.iter().map(|n| { f(n) }).collect::&lt;Vec&lt;U&gt;&gt;() }) } The error I'm getting is: error[E0507]: cannot move out of captured outer variable in an `FnMut` closure --&gt; src/util.rs:85:13 | 78 | sv: Option&lt;Vec&lt;T&gt;&gt;, f: F | - captured outer variable ... 85 | f(n) | ^ cannot move out of captured outer variable in an `FnMut` closure I get the same results if I change `iter()` to `into_iter()` and `F` to `FnOnce(T)`. The explanation doesn't make much sense to me because I can't tell what's being borrowed and not working.
You should check if obtaining a lock is any better than not obtaining it though. `stdin` also has a `read_to_string()` method and I'm not sure about what the differences are under the hood. That might further simplify the code and may even make it more efficient.
Does it do error recovery, so that it can be used in IDEs for small languages?
_nobody_ was reprimanded in that thread, either in public or in private. _nobody_ gets reprimanded for posting memes. The meme-breaking is something the reddit moderation does (bear in mind, the subreddit is an unofficial channel with different rules and moderation), and is basically a way of having fun every now and then. When the subreddit does go into "memes allowed" mode (usually at the end of the year, for fun), everyone is allowed to post memes. If you're talking about the joke rule in the sidebar, it's a joke. Jokes are allowed on this sub, always have been. It's image macros that the subreddit mods have issues with. This is probably the only comment I'll post on this thread because frankly I'm tired of relitigating the same thing again and again. But "the mods don't follow the rules" is, plainly, a lie.
Yeah, I can give plenty of examples off the top of my head for things Mozilla really needed that did not really move forward much despite Mozilla's need. SIMD, integer atomics, allocators, and fallible allocations. This certainly used to be the case, but I don't think it is anymore. At most, implementation work may get prioritized but that's only fair.
In the JS world, Redux is pretty useful for such, you get a single state object that is immutable(any updates replaces the state object with another, usually the prior version + the new change, had some term for it I forget). You could have a tile watcher active that when the file changed, read the changes and updated the state object, any logic(predominantly UI usually as Redux and React worked so well together) that was linked to that state object would get updated via uni directional data flow. It was really simple to use. It was simple and dynamic, not sure how well that'd apply to Rust. I guess you can have a struct and references values(I assume that'd still need some trigger to update UI though, along with additional logic for all that without something like Redux/React?
Glad it works! There's a reference about `pub(...)` syntax [here](https://doc.rust-lang.org/reference/visibility-and-privacy.html) if you're interested.
I'm 90% sure the problem here is using `FnOnce` rather than, say, `FnMut`. There are three types of function types in Rust, and each has a different usability: - `FnOnce` can be called exactly once. This means it can capture outside variables, but if you accept it, you _can only call it once_. - `FnMut` can be called any number of times, but you need a mutable reference to it, so you can't call it twice simultaneously - `Fn` can be called any number of times, and can be called simultaneously The problem seems to be that you're accepting an `FnOnce`, but want to use it on every item in the vector. Since it can only be called once before it's used up, rust is complaining that you can't use it again for every other item in the vec. (`map` requires `FnMut` so it can call the closure once per item, but `f`, being `FnOnce`, can't be called more than once).
A macro looks like the right solution for this. Specifically, I would recommend using a [procedural macro](https://doc.rust-lang.org/book/first-edition/procedural-macros.html). It'd probably be good to have some trait representing this functionality, named something like `CommandFlags`, then you could add a `#[derive(CommandFlags)]` using a procedural macro. Here's a guide on doing that! Or starting with procedural macros, at least: https://doc.rust-lang.org/book/first-edition/procedural-macros.html
That makes sense. Changed to a `FnMut`, `mut f: F`, and declared some types because it couldn't infer enough. Managed to abstract it into what I want (mapping `to_string`) with a wrapper. Thanks.
Here is another, with the slight change of drawing variable-sized ellipses instead of circles: https://imgur.com/a/th71H. You can also check out https://rogerjohansson.blog/2008/12/07/genetic-programming-evolution-of-mona-lisa/ for a probably better approach.
This is someone else's idea that I read in a comment on some RFC somewhere a while back, but I can't find it. Sorry!
What would that solve? I find none of the examples very motivating.
[He comes!](https://stackoverflow.com/a/1732454)
Some more thoughts from a practicing data scientist - string processing is a strong suit of Rust, yet natural language processing options seem very weak - interoperability with Excel and SAS should also be medium high priorities for a community of data scientists - deep learning is great, but don't forget simple models.. a scikit-learn of Rust with decent implementations of well worn models would be very useful - interactive computing (Jupyter Notebook) is a very common workflow - can that approach be supported by Rust? - would prefer a dataframe API than needing to deal with the details of arrays myself - very excited by the plotting/dataviz possibilities provided by Rust 
Looks like you forgot to link the channel
Web is not a GUI.
Hm, does [this](https://github.com/zserge/webview/blob/master/webview.go#L14-L21) help?
Wooo, happy to see my StateFn approach being used :).
I wonder if `println!` could infer some default format string. It can warn it would like to have an explicit format string but still could work without it. For example, in case the format string is missing it assumes `{}\n` for each passed argument. ``` println!(a, b, c) ``` Is an equivalent to this: ``` println!("{}\n{}\n{}\n", a, b, c); ``` Rationale is rather simple. People coming from dynamic languages are used to printing variables. Javascript: `console.log(randomVar)`, Ruby: `puts random_var`, Python: `print random_var`. You may encounter an error if the object doesn't provide string representation, but most (if not all) built-in classes do provide it. 
It looks like an interesting solution to both if-let-chain (`if let a == b and c == d { then } else { else }`) and refutable let. Feels really funny to me though.
So did you post this reply with curl? :P
It sounds like a bad idea. Consider the code let no = &amp;is_it_hammertime_yet; This is not just a let binding, it is a promise. Due to lifetimes: * `is_it_hammertime_yet` will keep its value as long as `no` exists; * `no` will always be equal to `is_it_hammertime_yet` for the entire lifetime of `no`. Given the example, this RFB just broke both assumptions, and the entire point of having immutable references in the first place. While it is not as bad as mutating an immutable reference (`no` keeps its value the entire time), it can cause hidden state changes, unexpected value updates and all around confusion. I don't condone it.
What they mean is Website =/= Desktop Application
I'm seeing the same error on FreeBSD (with the recommended `webkit2-gtk3` package installed).
Interesting. I've been looking for something in Go or Rust to build a small production dashboard with. I'll definitely try it out.
Congratulations on the 1.0 release! Pest is used in handlebars for template parsing. It fits all my requirements for a parser! handlebars 0.30 that uses Pest 1.0 is also released.
&gt;What that results in are native apps that work on most OSes (Windows, Mac, Linux) that don't require any web-stuff to render. That work and look like crap on most OSs you mean. At least you can make a webview app look good.
I suggest you finding contact with Peter Hutter. Maybe start on his [blog](http://who-t.blogspot.com.au/). Maybe you can find him somewhere on IRC. Also Gnome and KDE devs (I guess at least Martin Graesslin) should know a little about libinput API. Maybe they could help you.
Thank you for writing the word "pipe"! :) It seems this crate does exactly what I want: http://arcnmx.github.io/pipe-rs/pipe/ (I searched for "read[er]" "write[er]" "buf[fer]" etc but not "pipe").
And as soon as something better comes along it will be used. Until then it is the only cost effective way.
Agree but it's better to have at least some options for a GUI than none :) A lot is already possible with this..
But Gtk doesn't work with msvc on Windows, right? If you have to link to a lot of msvc libs, you can't also link to Gtk, right?
I'm interested to see what you do with this. Please report any issues you find :)
GTK works only under the GNOME. That's it.
&gt; String template literals Actual string interpolation (like in Perl/Ruby/C#/Python) may not fit very well for Rust, because it allocates and allocations in Rust should be explicit(ish). But maybe a sugar for [`format_args!`](https://doc.rust-lang.org/std/macro.format_args.html)? To borrow Python's syntax: `f"Foo{bar}"` will be desugared to `format_args!("Foo{}", bar)`, and we could write: println!("{}", f"Foo{bar}"); Of course, now it will make sense to make `println!` and friends support [`std::fmt::Arguments`](https://doc.rust-lang.org/std/fmt/struct.Arguments.html) in the first macro argument: println!(f"Foo{bar}");
Memory is just raw data, so have you considered making every byte/word a `Cell`? I e, your memory will be a `Vec&lt;Cell&lt;u8&gt;&gt;` instead of `Vec&lt;u8&gt;`. That way both you can have both get and set take just `&amp;self`. That said, `cpu.tick(&amp;mut memory)` is not an uncommon pattern either.
So... One can style GTK elements with CSS? Or is this some kind of electron thing there?
I've opened a PR that gets it running on Linux and FreeBSD https://github.com/Boscop/webview-rs/pull/1
Now that this PR is merged, you're not getting the error about the missing header anymore? How did you fix that?
IIRC you can `rustup add toolchain 1.20.0` (am on mobile, cannot check).
Different configurations? If a function relies on the presence of the static rather than having the configuration as a parameter, then testing this function in multiple different configurations requires serializing the tests to avoid data-races on the static.
Currently pulling my hair out with conrod, maybe I'm missing the point?
That was fixed by using pkg-config in the build.rs to add the WebKit include paths to the build. https://github.com/Boscop/webview-rs/pull/1/files#diff-a7b0a2dee0126cddf994326e705a91eaR18
&gt; **safety-critical applications** I think Rust could really help, but we all have our own interests so it feels perfectly fine if people wanting to use Rust on WebAssembly would rather work on that rather than embedded. The only caveat, of course, is that it would be nice if one or two people from the Teams would step forward and help shape the language/compiler/tooling to make it *possible* or *easier* (such as upstreaming xargo). &gt; **Idea of data structs/classes** - This is taken from kotlin lang’s data classes, where you can prefix a class with data keyword and your class automatically gets a default all params constructor and getters and setters too. In rust this can translate to a `#[derive(new, getter, setter)]` or a `#[derive(DataStruct)]` on top of struct declarations. There are times we just want to aggregate bunch of fields together in a struct and just access or set them later. So this abstraction really becomes handy in minimizing boilerplate code. What's the point? Why not simply make all data members public? I'll be frank, I think auto-generated setters are a plague: - if your struct has no invariant, you might as well make all fields public, making auto-generated setters pointless, - if your struct has invariants, then auto-generated setters cannot possibly enforce them, making them pointless. The only argument I see in favor of auto-generated setters is that *later* you may want to add an invariant. And that's all kinds of wrong: 1. YAGNI, 2. The day you do add the invariant, you'll be breaking backward compatibility, in which case a mandatory interface change is better as it helps the user finding all use sites and check them against the new rules.
Posting to r/programming will have a better audience too
I found this little gem thanks to http://readrust.net/rust2018/ The author mentions a couple of points which I think deserve specific mention, namely: - documenting memory allocations, - documenting complexity. However, I wonder if it would be possible to go *beyond* and couple the *documentation* of memory allocations and complexity with a *linter* which would check that the documentation is correct. Proven asymptotic complexity bounds seems useful to detect potentially unreasonable algorithms. I remember writing a (supposedly) O( N^2 ) algorithm years back, which turned out to accidentally call a O(N) function. My unsuspected O( N^3 ) algorithm passed the tests, and ran for a day or two in production without issues as N tended to be small, and then a client came with a N = 1,000 case. Timeout...
Try [cloned](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.cloned). I e, `contents_bytes().iter().cloned().skip(20).collect()`. This is what some examples on the same page seems to use so I assume that means it's idiomatic :-) Side note: In many cases, you can replace `iter()` with `into_iter()`, which would have been even better - but it does not work here, assuming what you have is a slice. 
Continuing my reading of http://readrust.net/rust2018/ .... &gt; **Improve the RFC process** &gt; - A summary of the discussion with major pros and cons. &gt; - A simple usage example, right at the beginning. &gt; - The next steps towards stabilization. I think this would just be **awesome**. I've regularly wandered over a RFC only to be greeted by a couple hundred comments spanning a year and a half. The first few comments are generally completely out-of-date, and do not match the current state of the RFC, and it's not quite clear which of the comments were ignored/dismissed (and why), which were incorporated, etc... And of course, it's never clear where exactly we are with the RFC: it is dead? approved but in limbo? actively being worked on but unexpectedly difficult? or maybe whoever was working on it lost steam? Is there a resource available to help keep up with the RFCs that I am unaware of?
I just wanted to say, I am working on a GUI toolkit [here](https://github.com/maps4print/azul). Currently CSS cascading and caching work (somewhat) and the API is fairly nice. The drawback of frameworks like yours is mostly extensibility, for example using a desktop version of OpenGL behind the UI to draw a game or a CAD application (you can use WebGL, but that has severe limitations / lacking features). But nevertheless, this is a very cool project.
Yes, it's not the final solution, that's for sure, I just made it in a few days because it seemed like a low-hanging fruit to give the Rust-GUI-story a boost, and it's suitable for many use cases that would otherwise reach for Electron (e.g. non-graphics heavy applications). I bookmarked your project, it seems very ambitious and will hopefully supersede this one. For our main use case, we are looking for ways to create child windows on a given parent window, so that we can make GUIs for Rust VST audio plugins. We have forked winit to add child window support but currently our only option to render on it is [conrod](https://github.com/Boscop/easyvst/blob/master/examples/conrodgain.rs). Will your GUI lib allow the creation of child windows on a given parent window?
This is an interesting use-case that I haven't thought about yet. azul can handle multi-window callback systems, but you'd have to initialize the parent window from an ID. If you can do it with winit, you can do it with azul, because it's using winit. &gt; but currently our only option to render on it is conrod. Take a look at [limn](https://github.com/christolliday/limn). I contributed to limn, but the author is not very active and the API design isn't really all that great, which is why I started azul. There is also a project that uses [yoga](https://facebook.github.io/yoga/) + webrender with RxJS / React Native, but I can't remember the name. For VSTs, I can definitely see why you'd want to go with a mature library like webview. And it builds and works on my machine, so that's definitely a plus.
Ain't that similar to https://github.com/softprops/envy?
I've been following your questions on the original webview github repo just waiting for you to drop this :) Looking very good! I'm curious though, if this is using a browser to render, why does it look a bit blurrier than, for example, chrome? Also, I would suggest using the builder pattern instead of the (really ugly) run function. Very good job!
You're wrong.
Thanks! My screenshot is from the Windows build, so it uses IE11's engine. What do you mean exactly be "blurry"? To me it just looks more pixelated than chrome (e.g. css shadows), but I think there are a few [MSHTML engine settings](https://github.com/zserge/webview/issues/54) that still need to be tweaked. Yes, I will change the API to a builder pattern and maybe even do automatic url-encoding for embedded html as part of this crate, too..
right, there're a lot of improvements needed.
Love this post! Favorite rust 2018 take so far. It has all the things I want to see in rust, and many things I didn't know I want, haha. Performance documentation is a great idea. 
Thanks, I will look at those projects more closely.. Actually, the VST situation is more complicated, because multiple instances of the same plugin dll could run in the same thread (because child windows have to run in the same thread as their parent), the winit event queue has to delegate the events to the proper child window etc.. And for the graphics rendering in a spectrum visualizer/EQ or stereo imager, it's not ideal to have to eval js to render it with lowest latency.. In my first VST I rendered the FFT using [custom shaders](https://i.imgur.com/2iLwRe4.gifv) (writing the FFT to a texture, passing that to the shader, like shadertoy does) but it wasn't pretty or user-friendly.. Maybe webview would have to be rewritten in Rust / merged with my existing winit fork due to the complications in child window event handling (which I already implemented in the winit fork).. Not sure how useable webview will be for VSTs in the end, but it will be useable for many other use cases at least.
Ah, right. I hope it works for /u/LousyBeggar now too..
yes, pixelated is the better word to describe it, specially in fonts. From the link you provided it looks like it's getting worked on, can't wait to have to see the future of this crate!
Yes, I think it will be fixed soon. I hope people do lots of cool projects with this :)
In similar situation I often use the following pattern in my code: fn foo(mut data: &amp;mut [u8], n: usize) { // .. while data.len() &gt;= n { let (l, r) = {data}.split_at_mut(n); data = r; // do stuff with `l` } // .. } Inspecting assembly usually shows quite optimized results. Maybe it could have been useful for this use-case as well.
It's very strange to see an HPC post without discussions on Message Passing Interface (which is kinda a workhorse on supercomputers) and of OpenMP (which is another workhorse). Rust essentially has Rayon in place of OpenMP, as far as i understand, but this shall be discussed then, i think. A question: can Rust (i.e. LLVM) compile to the IBM Power architecture (which is often used on supercomputers)?
That's basically what the `exact_chunks()` iterator is doing. Doing that manually gives more or less the same results, but the code is rather ugly now :) ```rust test tests::bench_exact_chunks_1920x1080 ... bench: 1,965,631 ns/iter (+/- 58,832) test tests::bench_split_at_1920x1080 ... bench: 2,046,834 ns/iter (+/- 35,990) ```
The part about const generics was discussed in the PR. There are use cases for a generic and non-generic variant of this. You could not always know the chunk size at compile time.
So it's saying you're iterating over `&amp;u8`s, so calling collect would produce a `Vec&lt;&amp;u8&gt;` so you want to make them be just `u8`. You could call map() with a lambda that just dereferences it, OR use the dedicated method for this, called cloned(). 
Thanks for the extra points! (I agree that I've just scraped some of the surface of scientific computing). - I've done a bit of string processing in Rust myself. What I found most surprising is that (1) most beginners' "Hello World" in Rust is a parser; (2) and yet I couldn't find an appropriate go-to crate for typical text mining tasks (although there are crates for specific algorithms, such as SnowBall stemming). Using the standard library alone is often good enough, which is also impressive. - I use Jupyter myself, but building a kernel for interactive Rust would require dealing with the main challenge of making an interactive Rust. I wonder how far we've got on this end. Nevertheless, it might be more feasible to expose a Python or Julia API to a Rust solution (integration!) - The lack of a `pandas` equivalent has also been mentioned at #rust-sci yesterday. Let's stay informed of new initiatives.
It depends if you want to make the API for your data expose the fact that it's protected by a Mutex or not. If you implement methods on Tmp, any consumers will have to call lock() before they can use them. If you implement methods on TmpMutex that call lock() before using the Tmp data, then consumers can be written in blissful ignorance.
Only if you take it literally. 
GTK works just fine with MSVC; it’s just that you lose the pkg-config stuff that makes it tolerable to build from source, and there aren’t any prebuilt binaries for it (you can find prebuilt binaries for GTK+2 and older versions of everything, but I haven’t found any for 3). See https://wiki.gnome.org/Projects/GTK+/Win32/MSVCCompilationOfGTKStack for instructions on building it, and then set the [GTK_LIB_DIR](https://github.com/gtk-rs/sys/blob/b08fc0e16fc525dc07953d69c27511eda6bfdb14/gtk-sys/build.rs#L43) environment variable and it should all work. But repeating what [meekstadt said about it](https://www.reddit.com/r/rust/comments/7eklri/wip_unofficial_gtk_rust_tutorial_series/dq68v19/), you may be the first person to try this with Rust.
Theres many GTK bindings and Conrod. I wouldnt say there are no options
thank you, I’ll try your advice.
I had forgotten to publish it. Thanks for pointing this out! I have now published it on [GitHub](https://github.com/paulkernfeld/future-by-example) and [Docs.rs](https://docs.rs/future-by-example).
Check https://learning-rust.github.io/docs/d3.modules.html or https://medium.com/learning-rust/rust-lets-get-it-started-bdd8de58178d . Also check Crates and Workspaces section, you will be an expert on modules :)
I can't seem to find your lib on cargo..
Thanks ;)
I've added [another paragraph](https://coaxion.net/blog/2018/01/speeding-up-rgb-to-grayscale-conversion-in-rust-by-a-factor-of-2-2-and-various-other-multimedia-related-processing-loops/#split-at) at the bottom about this.
Someone posted it here: https://www.reddit.com/r/programming/comments/7ryiih/redox_os_crash_challenge/
I must admit I'd prefer a complexity annotation which would indicate what `n` stands for. As a typical example, the complexity of Insertion Sort is generally given as O(N log N). No mention is made that `N` stands for the number of invocation of the comparison function and that it has a worse case O( N^2 ) in terms of moves. No mention is made, either, than a binary search over a sorted range is not too cache friendly as it keeps jumping around and is unpredictable.
A large chunk of it is debug symbols. `strip hello2` should help you get rid of those. Another large chunk of it is the standard library, libcore, and the jemalloc allocator. All of those can potentially be removed or replaced (and you will have to do that if you want to write your own OS).
[users thread with a bit more info](https://users.rust-lang.org/t/why-is-hello-world-4mb/14196)
Why? Because in someone reality GTK is better than Qt?
found an article on the web. I could bring it down to 399K so far. The guy made it 5072B. The optimized hello_world.rs (lol) : use core::fmt::{self, Write}; struct Stdout; impl Write for Stdout { fn write_str(&amp;mut self, s: &amp;str) -&gt; fmt::Result { let ret = unsafe { libc::write(libc::STDOUT_FILENO, s.as_ptr() as *const _, s.len()) }; if ret == s.len() as isize { Ok(()) } else { Err(fmt::Error) } } } #[start] fn start(_argc: isize, _argv: *const *const u8) -&gt; isize { let _ = writeln!(&amp;mut Stdout, "Hello, world!"); 0 }
that doesn't change much. $ strip {binary} brings it down the most..
The term you were looking for is probably "persistent data structures".
thanks. readring through.
Very nice post! I completely agree.
[cargo-make](https://sagiegurari.github.io/cargo-make/) is what you are looking for. I wrote it exactly because I got frustrated writing command by hand and not having some task runner like in other platforms.
LLVM is generally fairly good at optimizing away bounds checks, so the overhead in real programs is often negligible. You can also help it by rewriting your code using iterators - that way no bound checks are performed at all. You can also bypass the checks entirely with something like `array.get_unchecked_mut(i) += 1`. That's `unsafe` though, so you'll have to do it inside an `unsafe` block, and if things explode, you have no one to blame but yourself.
See [this post](https://www.reddit.com/r/rust/comments/7rxrka/speeding_up_rgb_to_grayscale_conversion_in_rust/), it touches exactly on that.
GTK works fine under KDE. Also there are non-GNOME GTK based desktop environments like Cinnamon
In a [blog post](https://coaxion.net/blog/2018/01/speeding-up-rgb-to-grayscale-conversion-in-rust-by-a-factor-of-2-2-and-various-other-multimedia-related-processing-loops/) that was submitted here yesterday `assert` statements were used to allow the compiler to elide the bounds checks.
[Link for the lazy](https://people.mpi-sws.org/~dreyer/papers/rustbelt/paper.pdf)
Is using a vector any slower than using an array? I'm only going to have at most two items, but I'm slightly worried about speed.
I was just thinking about how great it would be if heap allocations were automatically documented as well the other day. This is a really inspiring post!
Unless you're sure that most uses will involve threads, prefer exposing `Tmp` without mutex. This way users will be able to choose whether they want mutex, or rwlock or none of them.
I don't know of any metadata information section, but someone else with more compiler knowledge might. If you're concerned about information being leaked, binaries do by default include absolute paths of source files. xi-core compiled on my system, for example, includes strings like `/home/daboross/.cargo/registry/src/github.com-1ecc6299db9ec823/dtoa-0.4.2/src/dtoa.rs ` and `/home/daboross/Projects/CheckedOut/xi-editor/rust/rope/src/tree.rs`. 
&gt; Also I wonder if as developer we should have the possibility of disabling any runtime check to have more control over the code that will be produced. https://doc.rust-lang.org/stable/std/primitive.slice.html#method.get_unchecked Generally, the only way to see the overhead is to measure. It really, really depends. Others have touched on how sometimes these checks are optimized out, but they also branch predict well, so it just depends. I used to have a link to a great comment about this, but can't find it now :(
There are also actually successful non-web UI frameworks like [this one](http://avaloniaui.net/). The Web was not built with GUI in mind. In fact many people who use the Web to display Gui don't use it directly but through a framework.
I have to agree. It feels like a solution in search of a problem which would just add extra significantly more cognitive complexity and learning burden than it would alleviate.
If you really want to clone it you can reference the source here: https://github.com/itafroma/zork-mdl I took a different approach with https://github.com/olson-dan/rustzork :) 
Because it makes you have to deal with memory issues instead of accidentally writing a bunch of exploits. It make memory explicit. Even more so than C. Sure the safety heuristics aren't perfect but NLL will fix up a lot of them.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/cs140e] [A group to go through Standford's new cs140e OS class? • r\/rust](https://www.reddit.com/r/cs140e/comments/7rzh4t/a_group_to_go_through_standfords_new_cs140e_os/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
And XFCE, lxde, etc. But it still looks like garbage. On Windows and macOS everything is much worst. Qt designed to work under all major OS'es (yes, a lot of problems under macOS), but GTK+ is designed strictly for GNOME. Yes, "it works", but that's not enough for most people.
After working with C++, Rust was a breeze. And I don't think that Rust is hard to learn, but system programming is.
I love this Rust 2018 "event", and your blog post is among the most exciting and uplifting!
&gt; Because it makes you have to deal with memory issues instead of accidentally writing a bunch of exploits. That's mostly inline with what I wanted to express. It is a good thing it makes you *not* write the exploits. But when you're trying to learn, the exploits are usually good enough to get you going and you can improve over time. Rust isn't necessarily harder to learn, you just have to learn it all at once, fast, no excuses.
It is odd that there was no mention of MPI or like replacements in that post. Although, it does appear that there is some work being done in bringing MPI bindings to Rust: [https://github.com/bsteinb/rsmpi](https://github.com/bsteinb/rsmpi). Although, I haven't looked too closely into this, but it looks like it's mainly one guy doing all the work here. So, I'm sure it wouldn't hurt to bring more attention to this crate and see what the community can do to help make it better. Also, I wouldn't mind seeing examples comparing how to do things in both Rayon and OpenMP. So, if someone is coming from C, Fortran, or C++ and is familiar with how to do something in OpenMP they can easily see how to do it in Rayon. For example in OpenMP, I know you can tell the code for certain parts I only want one thread to be working on something while all the other threads go and work on something else. Then you can have everyone join back and work on things after they all meet at a barrier. Granted I'm more unfamiliar with Rayon, but it would be nice to see what the equivalent code would be to doing something like that. I bring this one example up because in heterogeneous parallel codes that utilize OpenMP and MPI you might have one thread sending and receiving data to other nodes, while all the other threads do some local work in the mean time.
Under what OS/DE?
I don't understand why you're getting all the hate for keeping your commercial product closed-source. A man's gotta eat! Open source is great, I contribute to open source projects, and I've open sourced many (but not all) of my projects. I'd also love to see your code, but it's your project, and it's your choice weather or not to show people your source. People should respect that.
Author here! I felt like a section on MPI would be somewhat orthogonal to the thesis of "super ungodly fast code for everybody" as machines which would benefit from MPI are usually pretty expensive. It's definitely something which would make Rust much more appealing to large organizations, though.
Opensuse, kde, Standard theme
I don't know what to tell you but gtk3 uses Windows and macOS native components as backends on non Linux systems. They just look native. Just because gimp looks like crap doesn't mean all gtk guis do
&gt; I don't know what to tell you but gtk3 uses Windows and macOS native components as backends on non Linux systems. https://github.com/GNOME/gtk/search?utf8=%E2%9C%93&amp;q=nsbutton&amp;type= No it does not.
/r/playrust
&gt; I don't consider Rust more difficult than C at all to be honest. &gt; &gt; I mean the point of Rust is that it holds your hand and warns you whenever you make a mistake; I often don't dare to touch C because you're always afraid of that you secretly invoke undefined behaviour or pass the wrong type or whatever since even though a function signature says it takes 4 different types all those types are secretly aliases of int_32 so you can pass them in any order anyway and the compiler doesn't complain. Agreed. I've always felt that, when people claim C is simple, it's because it cheats. Sure C itself is simple, but that's only because it foists 90% of the requisite knowledge off on the underlying machine model. With Rust, it may take longer to learn than C, but "what I need to know to use it" isn't a miniscule subset of "what I need to know to use it safely".
[print does not consume](https://play.rust-lang.org/?gist=78eb0fa39775b345c3fd27bcbcd804b0&amp;version=stable)
[removed]
Your position is unusable on any delivered product.
Cool. I was expecting to see a Z-Machina implementation when I saw the title.
I have to say, as a beginner, sometimes it feel like rust is difficult on purpuse...
I've programmed PHP and C# for the past 10 years and jumping into Rust one weekend was enjoyable and easy to pick up. 
I think this article is great for capturing this issue. Having followed Rust since 2013 I certainly think in terms of "Rust used to be hard to learn, but with the book and new features it's easier each release". But there is a sharp cliff with learning a systems programming language at all, and Rust by default doesn't compile unless you, by equivalence, write bug-free C++. Expecting newcomers to write bug-free C++ will always be challenging, and we should do everything we can to make that process easier.
I fail to understand what your supposed intelligence or the nature of your project have to do with binary sizes generated by the Rust compiler… 🤔
Right. But that is the way it has to be for low level system programming.
I don't really agree with this: &gt;Discovering that it’s possible to both write and run programs fast at the same time instead of having to choose. My programs run fast, but only after a long time of thinking about lifetimes and borrows
It's easier.to write c unsafely. It's harder to write c safely because there is no compiler help for it. Those complaining of slow rust compile times have never experienced the good ol days of running c under valgrind and then exercising the program to try and find leaks.
Well I'm obviously talking about writing code that does not have an error in it and undefined behaviour is a grave error of course. That Rust nags you at compile time about these errors instead of letting it pass and then results into undefined behaviour later at runtime doesn't make Rust "harder"; it just makes it easier to see you made a mistake; you only think C is "easier" because you don't realize that what you wrote isn't correct C.
A couple weeks ago, someone posted in the weekly help thread about something related to this. Their example function looked like [this](https://gist.github.com/Measter/e18eee546a09f930050c05da9d3812ed#file-calc-rs-L9-L18). For my benchmark, the arrays were set up like so: let mut r = vec![0.; Y]; let x = vec![0.1; X]; let y = vec![0.2; X * Y]; And X and Y were passed in as the remaining parameters. On my PC, benchmarked under [Criterion](https://crates.io/crates/criterion), the benchmark results were as follows: * [Plain Loops](https://gist.github.com/Measter/e18eee546a09f930050c05da9d3812ed#file-calc-rs-L9-L18): took [~1.27 ms](https://i.imgur.com/tgDUMHf.png). * [Asserted Loops](https://gist.github.com/Measter/e18eee546a09f930050c05da9d3812ed#file-calc-rs-L39-L52): took [~1.27 ms](https://i.imgur.com/bc6awns.jpg). * [Unchecked Loops](https://gist.github.com/Measter/e18eee546a09f930050c05da9d3812ed#file-calc-rs-L20-L37): took [~0.35 ms](https://i.imgur.com/O4SgPz0.jpg). * [Pre-Sliced Loops](https://gist.github.com/Measter/e18eee546a09f930050c05da9d3812ed#file-calc-rs-L54-L67): took [~0.35 ms](https://i.imgur.com/0Xkbau5.jpg). * [Iterators](https://gist.github.com/Measter/e18eee546a09f930050c05da9d3812ed#file-calc-rs-L69-L82): took [~0.35 ms](https://i.imgur.com/Uj4KmMo.jpg). I was actually a bit surprised at the asserts not appearing to help. I assume I messed it up somewhere, but I can't see where.
I’ve noticed that learning most of the Rust doesn’t seem to involve reading a big fat book, unlike C++ or even C.* That seems kind of odd for a language that’s considered pretty hard. *The K&amp;R book on C is short but is it enough to be useful with C. 
Pretty much the same experience on my end. I learned Rust after having learned C++, Scala and Go and I started writing code which I'd call "reasonable" very quickly. I also feel like it would be quite easy from someone coming from a C or Java background. Most of the arguments that the author makes would apply to any system programming language and many people coming to Rust may not be familiar with a system programming language so it's harder for them to learn than, say, python or php. But even the more "unique" features (compared to other popular system languages), like manual lifetime management, the macro system, are by far way fucking easier to learn than basic generic programming concepts in C++ (e.g. compile time "iteration", using SFINAE, placing things in a non deductible context... etc). I would probably struggle to name many strongly&amp;statically typed languages that are EASIER than Rust to pick up and use correctly.
It really depends. An array is on the stack so you can pretty much guarantee it's always going to be in-cache, at least if it remains in the top few frames. However, this is something you'd have to test with your use-case. In practice, a vector isn't going to be significantly slower. But when you say "at most two", I'm guessing you're sometimes going to have fewer than that which is going to be hard to manage with a bare array. You might like to try something like [arrayvec](https://crates.io/crates/arrayvec) which gives you a vector-like wrapper around an array so you can have variable length (but fixed capacity) while not requiring a separate heap allocation. However, because it has fixed capacity, any additions to the vector over capacity will fail, which is something you have to keep in mind. 
The difference in difficulty between C/C++ and Rust depends on the results you're looking for. If you just want code that mostly does what you want, C/C++ gets you there faster. If you want safety, Rust is a lot easier. Usually when people say one is harder than the other, the goal is implicit.
We certainly don't want it to be! A lot of the work this year was about making it easier. And we'll keep doing so in the future.
The official book is ~500 pages, and many people were surprised at how big Programming Rust was. I don't have my copy on hand, but it's pretty thick.
It's not published to crates.io yet. Do you think it can be published in the current state (no code docs (but examples though)) and the API of the run() function will change soon to use a builder..
Rust is difficult because most programmers abuse shared mutable state and Rust makes you sacrifice your first-born to be able to to do it. 
As a small example, `Rc&lt;RefCell&lt;T&gt;&gt;` is unsafe to send between threads. You can clone `Rc` any number of times with the same inner memory, so if you sent it to another thread, you could potentially use `RefCell::borrow_mut()` multiple times. `RefCell` doesn't use atomic integers, so it's possible to introduce race conditions if it's used in multiple threads. For the reason, and because `Rc` itself also doesn't use atomic integers, it's unsound to send either to a different thread.
You are correct, there is a large possibility that this will fail. And following through on projects that I've started is my weakest point. I've often dealt with this problem, but what I noticed is that not finishing something isn't the end of the world. At some point I can pick it up again, code doesn't grow stale or rot. Or someone else picks it up, changes it, remixes it, does something better. Even if my project would die, the ideas and concepts it spawned will live on. For now, webview is a good choice if you want to just get something going, absolutely. But I am trying to build good software or at least get close and that takes time to design and implement. At its heart, each software project is an idea. Even if the implementation fails, the idea lives on. I didn't make this because I wanted just to "rewrite GTK or QT in Rust". I made this because I thought that the conceptual model of how we build GUIs is wrong and error-prone and Rust just happens to be a language I quite like. My idea was to make a purely functional GUI system - if you pass in the same application state, you always get the same UI back. azul is innovating, not just re-implementing existing frameworks. It's not scratching an itch, it's scratching a wart. Building good abstractions in desktop (and web) GUIs has been hard and I think I came up with a better concept of how they should be built, so I'm testing if it is feasible. As for a time plan, maybe somewhere in summer it'll be usable. 
I have used rust-peg for several projects now and I'm pleased with it. Will it be worth it for me to switch to pest?
I second that. I would say that Rust isn't *hard* compared to the alternatives for the same use-cases. But it does requires *effort* to learn, simply because it's different from most of the mainstream languages.
Why not? It may not be ideal for desktop applications, but it's certainly a way of writing GUIs.
What color-space are input pixels in? Isn't this conversion incorrect because you are not taking gamma into account? You should probably first convert to linear color space, then convert to grayscale, then convert back to non-linear; otherwise your conversion to grayscale will change luminance of colors (make them darker). Looking at the [code](https://github.com/sdroege/bgrx-to-grayscale-benchmark.rs/blob/1ee74df8a75a4bb5d84acae4122424fbded70e52/src/lib.rs#L6) I see these constants: &gt; const RGB_Y: [u32; 4] = [19595, 38470, 7471, 0]; Where do these numbers come from? I think they should depend on the color space of the original pixels. For the most common color space for video (Rec 709) they would be different.
&gt; Isn't this conversion incorrect because you are not taking gamma into account? You should probably first convert to linear color space, then convert to grayscale, then convert back to non-linear; otherwise your conversion to grayscale will change luminance of colors (make them darker). Yes, that's correct. This does not do any gamma correction and is rather simple, but that was not the point of this exercise :) I think I mentioned that in the original blog post where this code comes from, and also the below. Might be worth repeating here, thanks! I'll add something about that tomorrow. &gt; Where do these numbers come from? I think they should depend on the color space of the original pixels. For the most common color space for video (Rec 709) they would be different. These are the numbers for BT 601
I just published it to crates.io :) https://crates.io/crates/web-view (It's the first crate that I actually published.)
Depends on which abstraction level you want to use it at.. If you want to use webview, you don't have to worry about the X server etc., you just have to know some html, js (or a lang that compiles to js) and css.
Writing `data` instead of `{data}` will result in the following [error](https://play.rust-lang.org/?gist=ad7c025a5502b8715937704fd4c7bd7f&amp;version=stable): "cannot borrow `*data` as mutable more than once at a time", so it's kind of a hack to circumvent it. There probably should be an issue for it, but I did not bother to search. Also not sure if NLL will fix this problem.
I would be very happy if someone succeeds building GTK with MSVC for rust on windows and makes a blogpost about it.
Now we just need someone that compiles GTK with msvc..
Thanks, I really hope for something like this to eventually exist in Rust. I also really like the functional approach to UIs, that's why I got into Elm and PureScript (after being disappointed by Polymer).
Awesome list! Hope all of these things can happen in 2018. Would love to use a "rust embedded 1.0" in 2019.
Not needed. C ABI of MinGW is compatible with MSVC and vice-versa.
The way I see it is, the web is a platform, and writing websites without a framework that "compiles" to this platform manually is too low-level to be productive/pretty, so everyone uses some kind of framework. So the direction of the platform will shift more and more towards low-level so that frameworks can make use of more low-level features (e.g. see CSS/Houdini, giving the user control over CSS interpretation/rendering), asm.js, wasm. In the end, we may up with 80% of websites being actual apps, compiled to wasm with raw dom access and raw css pipeline access. Maybe in 20 years, all the high-level js/html/css features will be slowly phased out.
One comment on: &gt; The no_std / std gap I see this as a function of adoption. Growing interest will lead to contributions making libraries of interest compatible with `no_std`. Currently, I can totally see maintainers avoiding doing so, because it means opting into features - highly unstable ones at that. The stabilisation efforts are important to tackle that problem. 
Do you have a link to a Rust project using GTK that builds with rustc-msvc? I'd be very interested in that :)
This. I'd trade the "difficulty" of learning Rust to the real difficulty of troubleshooting (often hastily) written C/C++/multi threaded code. It is _so worth it_, that the article is borderline incorrect. I think the author was lucky he never had to troubleshoot some of the more esoteric issues with C++ and or libraries.
I am actually using emscripten right now, I thought wasm-gc is for the new unknown target? I will try anyway, thanks)
What frameworks will become or not become doesn't change the fact that most Web frameworks that exist today are fat and slow and low-quality. If you want to do GUI, you shouldn't be forced to choose between multiple different bad frameworks and learn their arbitrary descisions for workflow. Instead you should have a dedicated system to write graphical user interfaces. If the web was the best solution to create GUIs then all of google and apple and microsoft would stop creating GUI frameworks but would all jump on the web bandwagon. Mozilla tried that with their FirefoxOS but they failed spectacularly. Google makes most of its business from its operation of its Websites, many of them inside the top 10 worldwide. And what did they build? flutter! It doesn't build on the web but instead uses a bunch of high quality, non-web libraries as its basis.
That's the one I think :) Does Rust have something like this? It's sort of like Copy on Write(CoW) I guess? Letting you have a chain of modifications/versions without making new copies of prior memory which may be required usually.
Ok, tried that, but it did nothing for me
&gt; If the web was the best solution to create GUIs then all of google and apple and microsoft would stop creating GUI frameworks but would all jump on the web bandwagon. You could argue that this is because the current web platform is not low-level enough: wasm has no dom access yet, and access to other APIs of the web platform. Google had to address the market asap, couldn't wait for wasm to gain dom access. But the web platform will mature and allow more low-level access. What I dislike mostly about web dev is the missing typesafety of it all.. But yea, I'm also very much looking forward to an even leaner Rust-GUI lib that also allows rendering some parts with glium with lowest latency etc.
&gt; I don't have any problem with LTO in release mode That's because that issue has been already fixed. &gt; I'm seeing funny effects with identical functions showing up (and being used) multiple times, like core::result::unwrap_failed. That may be ThinLTO (enabled by default on the release profile) not being on part with regular LTO. You can try building with `-Z thinlto=false` to see if that affects optimization.
There was a time where Rust didn't have stable custom derive. When it arrived all the web backend people were really happy. I think that Rust really has potential in the embedded sphere. Especially as there are few really good competitors. We could rock the market!
&gt; Currently, I can totally see maintainers avoiding doing so, because it means opting into features - highly unstable ones at that. Yes, that is the case now. I mentioned `extern crate collections` in the post; that requires a feature gate. That's why I also mentioned the portable lint, or perhaps it had some other name? My vague recollection of what it's supposed to do is: you use lints (?) to indicate that a crate can use `std::vec::Vec` but not any other abstractions that requires an OS (e.g. `std::fs::File`, `std::thread`, etc.) and this magically makes the crate work for (compatible with) a bare metal target that lacks OS abstractions like threads, files, etc. Of course, that crate would also work for a fully fledged target like Linux. All of `std` is stable and so is any subset of `std` so using only a subset of `std` -- unlike using a crate *behind* the `std` facade -- should require no feature gate. --- Maintainers not wanting to accept patches for no-std compatibility because of unstable features means a non zero chance of people forking the project, applying the patches and publishing the fork on crates.io. I wouldn't want to see crates like `serde-nostd` popping up on crates.io so I hope for a timely solution to the problem. 
So I have a query builder and it was using a not-very abstracted non-Rust way of doing things. struct Query&lt;'a, D: std::fmt::Display&gt; { inner: Vec&lt;(&amp;'a str, D)&gt;, } The building functions used to be e.g., fn push(&amp;mut self, key: &amp;'a str, val: D) { self.inner.push((key, val)); } which worked, but wasn't particularly good for one-liners with multiple arguments. I've looked at a couple of articles and crates and the method that seems most appropriate for me (given that the keys are `&amp;'a str`) is taking and returning `&amp;mut self` / `&amp;mut Query`. This works up until the final stage, where I have to take ownership of the query to prevent lifetime issues when I pass it to other functions. fn build(&amp;mut self) -&gt; Query&lt;'a, D&gt; { ... } I'm not sure how I collect everything back up and take ownership. Currently I have let mut q = Query::new(); for (k, v) in self.inner.into_iter() { q.inner.push((k, v)); } q which gives me the following error: error[E0507]: cannot move out of borrowed content --&gt; src\query.rs:59:23 | 59 | for (k, v) in self.inner.into_iter() { | ^^^^ cannot move out of borrowed content However, changing the signature to `build(self) ...` prevents it from taking it out of a borrowed context (i.e., even trying to take ownership). How do I proceed?
This all looks like a black box to me. While I am happy to have very performant code I'd prefer having a way to know what is not so good in my code so I can build upon it (explicitness). The example with more iterators shows that it is not so simple. But anyway congrats! I have some good candidates for exact_chunks!
Replacing `into_iter` with `drain` should help.
So we're talking between one and three bytes, right? Yeah that's pretty wasteful to heap-allocate. An arrayvec is still somewhat wasteful because it has to contain a length field which is either 4 bytes (32-bit) or 8 bytes (64-bit). You might be better off designing a container around `[u8; 3]`; you could fill the array with NOPs or something when an instruction is shorter than 3 bytes.
For inline assembly, there is a [pre-RFC](https://internals.rust-lang.org/t/pre-rfc-inline-assembly/6443/53) that you might want to look into.
I wish there was support for ESP32/ESP8266 in Rust. However, since there's only a backend for gcc available right now that's probably a very long way off.
Compiles and passes existing tests. Thanks.
I dunno about that, every time I see Rust code it makes me think that C++ is very elegant and beautiful language. The syntax is killing me, for some reason. Love the idea of traits, though.
Thank you for the link. I would be interested in any more you have to provide. I'm going through the Rust book, and someday hope to actually digest https://github.com/rust-unofficial/awesome-rust. 
I think Rust just "shifts" the difficulty: - In C/C++ you have to worry about pitfalls like buffer overruns and thread safety, even after the compiler gives you the OK. I'm always constantly having to think *past* what the compiler will catch. - In Rust, the compiler makes sure you can't do that sort of stuff but gets mad at you more easily, so you have to fix your problems (and maybe understanding of the memory model) up-front. Overall, I would choose to pick up a Rust codebase over a C++ codebase any day of the week. You never know what (memory-related) landmines the last person unintentionally placed in C++ until you audit every single line of code very thoroughly; in Rust a lot of the issues will never make it into the code in the first place.
&gt; interactive computing (Jupyter Notebook) is a very common workflow - can that approach be supported by Rust? It can be made interactive with a web UI, either in the browser or standalone with [web-view](https://crates.io/crates/web-view) :) &gt; very excited by the plotting/dataviz possibilities provided by Rust Me too..
Is it possible to not include these paths?
can you elaborate a bit on what you mean by that?
By “works” I think that you meant “is nice and a good idea”, under which definition I generally agree with you; but all the downvoters interpreted it as “functions”, under which definition your statement would be wrong.
Yes, that would be useful indeed. 
I'd like to see `libstd` be made more modular and use cargo features for functionality not in `libcore`. Basically we'd have features like `threads`, `files`, `collections`, etc. and crates would default to using all features. `libstd` with no features would be equivalent to `libcore`. If you found a crate which actually doesn't use all these features, it would be a one line change in `Cargo.toml` to fix it. We could even block publication of crates not using the minimal set of features. 
I think it is in nightly, but the feature hasn't been stabilized yet. Issue about this: https://github.com/rust-lang/rust/issues/40552 Unstable feature docs: https://doc.rust-lang.org/nightly/unstable-book/compiler-flags/remap-path-prefix.html
`wasm-gc` works for literally any WASM files, but emscripten target might already be doing what `wasm-gc` does. It's associated with the new unknown target because the rust compiler doesn't do this trimming in the compiler (and it should in the future). If you really do want smaller binaries, switching from emscripten to `wasm32-unknown-unknown` will get you that. There's a lot more capability out of the box in emscripten, but that comes with a large overhead- `wasm32-unknown-unknown` will let you do things with much smaller files.
&gt; where it's just used because it' I think that's a noble desire. Perhaps a little bit of newbie education on why some things are the way they are is in order. (I'm not saying the Rust team needs to take on this endeavor) Whenever I start learning a new language, I write FizzBuzz in the standard C-style naive way. After learning a little bit more, I attempt to write it in the idiomatic &lt;insert language I'm learning&gt; way. Learning that Rust had two types of strings, and it wasn't easy to just coerce one into the other was a little off-putting. I took a hiatus before learning why it had to be that way. I assumed it was like some sort of "boxing", but never got too into it. Something rekindled my interest this weekend and I wanted to see how easy it would be to connect up to Postgresql and do some rudimentary work. Surprise!, it's incredibly easy. Kotlin (and its community's poor documentation) made the process very painful... Rust just worked, in a very simple imperative way. I just see a few things that cause me to say, "but why?"
 let mut is_it_hammer_time_yet = false; let no = &amp;is_it_hammer_time_yet; let { is_it_hammer_time_yet = true; } is equivalent to: let mut is_it_hammer_time_yet = false; let no = &amp;is_it_hammer_time_yet; let is_it_hammer_time_yet = true;
Hmmmm, my programs only run after I question my life choices.
Is there a specific example out there that strikes you as hard on the eyes?
IMHO: Rust is harder to learn, easier to use than C. For all the reasons you mention. The "harder to learn" part does matter.
Rust: spend your lifetime thinking about lifetimes.
A lot of the experienced c++ hackers at Mozilla had effectively the same response when I later asked them what they thought of rust. The borrow checker wasn't the issue, they already modelled code in a similar way in their mind and they appreciated the model. Folks had various speed bumps on the way but nothing they felt strongly about.
This is already partially solved by some parts being split off into separate crates like `alloc` and `collections`. `std` is just the aggregated facade that was stabilized first. It would be easier to split more APIs off into their own crates and then reexport them from `std` so existing usages still work.
This coincides nicely with a lot of what other people are saying: Rust should extend itself to more platforms. Wasm, embedded/no_std, other Tier 2/3 platforms (I'd be most interested in the BSDs and Haiku) have come up frequently. A lot of the people working on Tier 1 platforms are talking about how 2018 should be boring, and a lot of features already underway should be wrapped up. I think those two complement each other quite nicely. Let's keep making the language better with big features we've started in 2017, and let's extend the language we have to other markets!
Rust is hard because safety comes at a cost. You either sacrifice speed or you sacrifice the ability to do unsafe things. We tend to think about problems in terms of shared mutable state because when we're in the physical world that's usually the simplest way to solve things. Thinking differently is hard. Not being able to solve problems the way you always have is hard. 
static, mut, and unsafe aren't *that* hard to type;)
Python guy here. The concept of setting lifetimes is absolutely foreign to me! So was borrowing variables, but that was easier to understand
Sometimes the turbofish bugs me Enumerating over structs is at times a pain in the ass; example struct Foo { fields } struct Bar { other fields } enum FooBar { Foo(Foo), Bar(Bar), } I would really like to just have the enum varints be the structs I already defined, since you can't make impl blocks of enum variants
The new book focuses on &amp;str vs String for exactly this reason FWIW
But *unsafe* makes you feel dirty. I have had to write *unsafe* code in C# and it made me feel like I did something wrong at first.
Speaking as the author of rust-adorn and Clippy, both should become stable later this year. Adorn was never a serious project, more of an example crate for proc macros. It needs to be rewritten to use the new proc macro infra, which _will_ become stable sometime this year. I'm surprised it even works right now, I haven't maintained it. It's a bad example of production readiness. We've planned this for clippy as well, clippy is moving into rustup so stability won't be an issue anymore. ---- In general I don't think either of these reflect the production readiness of the language. Being able to extend the language with arbitrary compile time code is not a common feature, it's something many ecosystems do perfectly fine without. And requiring nightly to run a tool is annoying but doesn't impose nightly in you users, just on your personal development workflow. Not great, but not terrible either.
I think a lot could be done to improve the situation here. The core primitive for shared mutable state is `Cell`, but that has two ergonomic problems. First, you have to wrap your types with it use it, so you can't easily apply it to library types. Second, it doesn't allow any internal references so you have to apply it to every "leaf" value individually, making the first problem even worse. But that's not technically required for memory safety. The only kinds of shared mutation that lead to unsafety are the kinds that change the "shape" of an object- reallocating a `Vec`, changing an enum to a different variant, etc. Other kinds are totally safe- writing a scalar value in a struct field or array element, writing a non-owning reference, etc. The [`as_cell` RFC](https://github.com/rust-lang/rfcs/blob/master/text/1789-as-cell.md#cell-slicing) includes `Index` impls to allow going from `&amp;Cell&lt;[T]&gt;` to `&amp;[Cell&lt;T&gt;]`, but with language support this could be extended to allow going from `&amp;Cell&lt;S&gt;` to `&amp;Cell&lt;FieldOfS&gt;`. `Cell` could also perhaps support normal assignment syntax. Alternatively, the pre-1.0 `@mut T` reference type was primarily designed as a GC-ed pointer, but it also allowed shared mutation. We could potentially bring it back as some kind of `&amp;cell T`. This approach might be more problematic, though, since you wouldn't be able to convert a `&amp;cell T` to a `&amp;T` (though you would be able to convert it to a hypothetical `&amp;const T`, but then you'd want everything to take `&amp;const T`s instead of `&amp;T`s, and neither `&amp;const` nor `&amp;cell` could be sent across threads or use noalias optimizations).
What this means is that it is included in the documentation that gets built and distributed with the Rust compiler. This wouldn't have happened without the dedicated work that /u/projektir championed in https://github.com/rust-lang/rust/pull/46196.
GC integration as well IIRC?
Kind of yeah. But that also became not-a-priority for Mozilla
Great article. It would be nice if we can push to crates.io from travis if tests and other checks pass for tags. Not too sure how it should work exactly though
Every other month or so I get motivated to write an Xtensa backend for LLVM, but then I dig into the LLVM docs and get discouraged. If you or anyone else knows anything about writing LLVM backends, by all means, let's make it happen.
I've never seen anyone type an actual sharp before.
That’s good to hear. I’ve yet to check the other posts in this subreddit yet. (Or any pinned posts or whatever) is this “new book” the Oreilly one?
Hey man, I know I get salty about it sometimes too. Sure you lose some frags or sulfur or whatever it is, but in the end it's just a game my friend. If you ever need a pal to play with to maybe increase your odds of survival I'd be willing to help out my dude. Good luck!
Sadly, I have no idea about this. I'll keep my ears open.
As a big fan of Rust (but not its monopoly on my love), RISC-V, and operating system development, I look forward to seeing more. I do wonder what happened to https://os.phil-opp.com as he hasn't made a new post in a year.
It wouldn't actually be too hard. I'm not sure exactly when Travis builds for a tag, but then it's just a matter of having a build job that does `cargo login` and `cargo publish`. [There's actually an travis-ci/dpl issue for first-class support of this](https://github.com/travis-ci/dpl/issues/233). Of course, the perfect solution would also double-check semver compatibility with something like [semverver](https://github.com/ibabushkin/rust-semverver). Maybe I'll look at doing something like this in the coming months.
whoops, fixed!
I would put the blanket JetBrains IDE ignore at my machine's global level, but I have several single-user projects that I use git to move between machines, and I want my shared IDE settings to be shared for those.
This week I'll see what I can do to improve the API of my [web-view](https://crates.io/crates/web-view) crate. Probably some kind of builder instead of the singular [`run()` function](https://github.com/Boscop/web-view/blob/master/src/lib.rs#L14-L19)... And doing url encoding of data into data-urls instead of requiring the user code to do it.. Btw, any idea how the lifetimes in this lib can be improved?
I totally agree with your reading on this - the longer that situation persists, the messier it will become.
I think the "new book" is the second edition of https://doc.rust-lang.org/book/
&gt; That's because that issue has been already fixed. I also don't recall having had one last year.
Start with listing the ones you looked at and why you found them lacking.
&gt;Rust isn't necessarily harder to learn, you just have to learn it all at once, fast, no excuses. I think that's a major part of it. But I think it goes beyond that. It forces you to write a memory-safe proven correct program the first time you write the program. For every new program you write, it won't even compile until it's memory safe. That's an amazing feature for sure, one major reason to use Rust over C or C++... but it's frustrating. For me, learning the language I just want at least the program to compile, at least run and print a couple debug messages to make sure it's doing at least part of what I want it to do. But with Rust, nope, no love at all. Your program isn't perfect yet, won't compile. Seeing even a buggy program run is satisfying when you're developing. After you spend a couple of hours on something, you want it at least to compile and spit something out so you can feel rewarded, segfault or not. But you don't get that satisfaction with Rust, and compiler errors will have you tear your hair out while learning. It'll make you feel like you haven't learned anything, because you won't have anything to show for the hours you spent. It's the best feature of Rust IMO, but it's also the most frustrating. 
aahahahahahahahahaha
Okay so I'm legitimately asking here but say something like Applicative Functors which I rarely even see in Haskell code and feel at that point just make code unclear compared to just writing it out directly—how would those be useful in systems programming?
No, sorry. Why aren't you using rust-gnu btw?
How did the Termination trait stuff break your no_std usecase? Termination trait is defined in libstd and is not used below libstd. 
You may need to compile it with a different flag to get c++ autocomplete working. I am on my phone so I can't look it up easily right this moment. I switched to neovim and use deplete these days, but YCM worked on most every language I used up until I made the switch. 
I have a [csv library benchmarking game](https://bitbucket.org/ewanhiggs/csv-game). It's not a comprehensive test but it should tease out whether there are performance issues (e.g. lalrpop has serious problems - it took too long and I've had to disable it). I have a [Peg example](https://bitbucket.org/ewanhiggs/csv-game/src/9604dc176b6303ef9fcee1d9fc46d40bc786a569/rust/peg-reader/?at=master) that performs ok where the grammar looks like this: #![arguments(sum: &amp;mut u32)] #[pub] record = f:field ++ "," {} field = "\"" [^\"]* "\"" { *sum += 1; } / [^,\n]* { *sum += 1; } I tried to make a [pest version](https://gist.github.com/ehiggs/23c025db600a3f433cc10ecd32506286) but it just hangs. I haven't been able to fix it in my time box. Patches welcome! :) 
Because I have to link to many msvc-built libs..
I came from C (at least on the systems side — my other usual language is Haskell) and use `unsafe` blocks and low-level tricks freely in Rust. I find, even subverting certain safety checks, Rust lets me write safer `unsafe` code than would be feasible in C — algebraic data types and parametric polymorphism are particularly helpful for doing so in my experience. 
"something" does not implies "any" nor "many". &gt; You use something to refer to a thing, situation, event, or idea, without saying exactly what it is. 
Last week, I've started working on a client library for the [public stash API in Path of Exile](http://www.pathofexile.com/developer/docs/api-resource-public-stash-tabs). When done, you should be able to use Rust to digest the item market data and write applications such as trade bots, or backends for a websites like http://poe.trade. But that's still pretty far off :) Right now, it's seems mostly like an ambitious exercise in data modeling. If you don't know about it, PoE has _fantastically complex_ itemization which has also been updated and enhanced over the past several years. As a result, the API is rather crufty is somewhat poorly specified; trying to fit into a strongly typed data structures proves rather challenging So far, Rust's structs and enums are holding pretty well though :) I've got most of the deserialization code done (skipping items-in-sockets for now since no one cares about those anyway) and should be ready for 0.0.1 release soon. Of course, the real test would be to ingest the entire 20TB item database and see how terribly it breaks over numerous broken edge cases and bugged items it contains :)
This is impressive and certainly lives up to its name. The only issue I noticed is the lack of documentation. For example, neither the github readme nor crate documentation describe 1. What the parameters of the structopt directive are 2. What the main macro does behind the scenes You should also consider adding the example on github to the root of the crate's documentation. As a user who searched and pulled your crate directly from crates.io, the first thing I would have looked at is the documentation generated by `cargo doc`. Cheers!
&gt; Because I have to link to many msvc-built libs.. If they are C libraries you can generate .dll.a files and link to them with MinGW. &gt; Btw, you could do a hello world in GTK that builds with rustc-msvc to get the ball rolling for people who have to use rustc-msvc :) I'm using rust-gnu. I find it unethical to support MSVC and therefore avoid it whenever possible.
I think I agree here, but if you talk HPC, it is those big expensive machines with a fast interconnect (InfiniBand or &gt;= 40GbE (Ethernet)) you are targeting. But in the end performance improvements will benefit everybody (a bit). And while I doubt that you'll knock down Fortran of C/C++ anytime soon, providing an alternative (that squashes several bug categories right away) is always a good thing. Thanks for the post.
There may be a `Termination` in std but the termination PR also added a termination lang item and changed the signature of the `start` function (cf. [this commit](https://github.com/japaric/cortex-m-rt/commit/245f959122c0fd8a1f8eb33c96e6e480abb12773#diff-8d266caa79fae92fe89c14e0730c69ddR27)). The change in `start` forces you also define the `termination` lang item (i.e. a `Termination` trait) or your compilation crashes in LLVM (LLVM assertion or LLVM error; don't recall which one now). 
I needed an nlp library in Rust which could do part-of-speech tagging, and I couldn't find one, so I just started on a [smol](https://github.com/cmdd/smol) nlp library (which doesn't yet support pos tagging... but it will soon™)
&gt; On the other hand, if you declare upfront that your language needs to be able to solve any hard problem anyone thinks of, run fast and be safe to use then you’ll probably get your wish, but it’ll hardly be simple. That's a *hard* problem in my opinion. Sure, compare with C++ and look at how many safety problems they didn't solve: free use of pointers, iterator invalidation, undeclared exceptions, accidental type conversion via implicit constructors, exceptions thrown in destructors (okay, Rust doesn't solve that last one either, but at least `panic` is supposed to be unrecoverable).
It's not simply a learning problem though. There is plenty of code that you could write in C++ that is perfectly safe, but Rust would disallow because the borrow checker isn't smart enough to work out that it is safe (NLL is a trivial example but there are other more complex ones). If it were simply a learning problem, and once you are good enough it is easier than C++, then how come nobody has worked out how to do a good GUI API in Rust yet? (Without cheating by using C or JavaScript to get around the borrow checker)
Handmade Hero in Rust, as usual
Last week, I didn't get much done on my tutorial series for [using Vulkan with Rust+ash](https://github.com/bzm3r/ash-sample-progression). This week, I'm hoping to get more done. Writing this here so that I feel like the commitment I have made is more solid. 
Ahh I see what you are doing there. I first was confused why you used the same signature as the `libstd` `lang_start` function, but you really want to mimic that. I created this pull request and never thought of such a use case :/ I think that this could also be gated, so that you don't require the `Termination` trait if you are not using `libstd`. Would you be interested in such a patch?
I don't know.. given that the Wikipedia [redirects](https://en.wikipedia.org/w/index.php?title=High-performance_computing&amp;redirect=no) "High-performance computing" to "Supercomputer", i think MPI and OpenMP are the main things that you could discuss, it's just what this phrase historically means (computing on large computers with many many cores—and GPUs these days). Or the main things at least.
**Compose key** A compose key (sometimes called multi key) is a key on a computer keyboard that indicates that the following (usually 2 or more) keystrokes trigger the insertion of an alternate character, typically a precomposed character or a symbol. For instance typing Compose followed by ~ and then n will insert ñ. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
Lucky you! People tend to report me everything that breaks in no_std land so I get to see all the bad and ugly.
Yeah I feared something like that when I daw it using SyncSender&lt;T&gt;. Thanks for making me aware of os_pipe!
I saw some post by /user/whitequark on some ESP forum a couple of days ago (that's when I stumbled upon it, not when it was posted), while researching the current possibilities for Rust on ESP, that indicated interest of theirs in working on making Rust + ESP32 happen. You might want to get in touch?
I added a paragraph about that here too now, to prevent people from cargo culting an incomplete solution. &gt; Note: This is only doing the actual conversion from linear RGB to grayscale (and in [BT.601](https://en.wikipedia.org/wiki/YUV#SDTV_with_BT.601) colorspace). To do this conversion correctly you need to know your colorspaces and use the correct coefficients for conversion, and also do [gamma correction](https://en.wikipedia.org/wiki/Gamma_correction). See [this](https://web.archive.org/web/20161024090830/http://www.4p8.com/eric.brasseur/gamma.html) about why it is important.
It (the LLVM optimizer and it's behaviour on specific code) is indeed kind of a black box. With the approach here you can get some kind of feeling how it behaves though, and find a solution that works for your case. Or in the worst case go down to `unsafe` code for the couple of lines that are suboptimal. But even without going down the optimization rabbit hole, the output of the compiler is IMHO quite impressive even on the original function with proper assertions (without assertions the compiler can't possibly know). I would hope that in the future the optimizer could be improved to at least give consistent results for basically the same code, which currently does not seem to be the case (e.g. the much slower iterator version with assertions should be exactly the same).
Awesome stuff! How does this relate to Patrick's [Pathfinder](https://github.com/pcwalton/pathfinder) project?
I was talking more about stuff like GADTs, first class (dependent) types, refinement types, effect systems, etc. Less about concrete library stuff like applicatives.
It doesn't matter for `u8`, but for types where cloning is not free, you might want to `skip` before `cloned`.
it's true there's a certain amount of unavoidable difficulty if you're comparing to garbage collected languages. in C++ you pay with extra debugging, in Rust you pay with extra markup and compiler errors (safety isn't free , and requires a provable *over* estimate)
I think there's a certain level of difficulty inherent in it's mission statement
I wanted to get back into rust recently and tried to write the equivalent of this struct: data Store s a = Store (a -&gt; s) a My first try was struct Store&lt;S, A&gt; { value : A, reconstruct: Box&lt;FnOnce(A) -&gt; S&gt; } Which doesn't work because box isn't callable or something like that? I could have used FnBox or make the struct generic over the function and used impl Trait but both are nightly only. Is there a way to do this on stable? I don't know.
Not yet. I will eventually. My advisor did try it for a bit and was very pleased with the provided functionality but had some problems with fine tweaking the debugging functionality.
&gt; I'd be most interested in the BSDs and Haiku BSD support is mostly good. But [RFC: Target extension](https://github.com/rust-lang/rfcs/pull/2048) really needs to be implemented soon…
Thanks! This is a topic that deserves a writeup of its own, but I'll try to summarize here: First, Patrick and I work for the same company, we talk a lot about our findings in lyon and pathfidner, and it's fair to say that both projects have had an influence on the other over the past year. Lyon is built around a tessellation algorithm that let you produce a rather simple output (vertex buffer + index buffer) without assuming anything about your rendering engine (other than that it can draw triangles). Pathfinder in its latest iterations has two main algorithms: one for small things like text, and one for larger paths (typically SVG-like things, or if you decide to zoom on some text to the point where it fills a lot of pixels). These algorithms are also geometry-based (as opposed to shader based approaches like the vector texture or slug), but instead of trading in terms of triangles the main one generates trapezoids with some work to do on the GPU and the other one is a (quite innovative take on the) stencil and cover approach. Pathfinder defines how you render things rather than giving you complete freedom over how you do it, which is great because it provides the solution for tricky things like good anti-aliasing and rendering curves. Lyon is a lot easier to embed in your renderer but doesn't solve anti-aliasing for you (not yet anyway). The other big difference is that pathfinder's trapezoid partition is resolution-independent and is great at rendering curves while not as good as a monotone tessellator like lyon's at generating geometry for polylines. Lyon's current tessellator first approximates the curves with line segments which means it is not resolution-independent, but generates on average half the amount of vertices you get from trapezoidal partitioning on polylines. If you are wondering which will end up in servo/firefox, definitely pathfinder. If you are making a game and want vector graphics, lyon might be more adaptable to your needs. As mentioned in the post, I want to add a resolution-independent tessellator to lyon that may look like pathfinder. It could be that the two crates will gradually come closer and share code, or that I choose to take a completely separate route because pathfinder already exists and thus it would be more interesting to experiment with different things (right now I am leaning towards following pathfinder because the alternative is so much work). Damn, I suck at summarizing things.
I was able to find a solution for avoiding FnBox with paramterless closures. trait Task&lt;T&gt; : Send{ fn call(self: Box&lt;Self&gt;) -&gt; T; } impl&lt;T,F : Send + FnOnce() -&gt; T&gt; Task&lt;T&gt; for F{ fn call(self : Box&lt;F&gt;) -&gt; T{ (*self)() } } And then using a RwLock&lt;Option&lt;Box&lt;Task&lt;T&gt;&gt;&gt;&gt; as the type for the struct. (Needed concurrent access as I was experminentig with a java-like ExecutorService + Future API.) Dunno if this is adaptable to functions/closures with parameters.
I've got a lot of string-like arguments for which I want to accept String, &amp;str, etc. The signature currently looks like this: ``` pub fn new&lt;S1, S2, S3, S4, S5, S6&gt;(document_type: S1, uid: UID, pid: PID, title: S2, url: S3, abstract_text: S4, description: S5, content: S6) -&gt; Self where S1: Into&lt;String&gt;, S2: Into&lt;String&gt;, S3: Into&lt;String&gt;, S4: Into&lt;String&gt;, S5: Into&lt;String&gt;, S6: Into&lt;String&gt; { /* ... */ } ``` How can I make this better?
Ooh, nice! This definitely helps provide more context. Glad you're both are doing work in tandem, and helping each other get a better idea of the problem space!
It collapses deeply nested pattern matches shaped like: ``` if let ... { if let ... { if let ... { ... } } } ```
For the record, this is why for the C++ portion of the Firefox build `--enable-warnings-as-errors` is an opt-in setting. We enable it for our CI builds where we control the toolchain in use, but we don't do so for developers building locally with whatever toolchain they happen to have installed, because it's virtually impossible to guarantee that code will compile without warnings in that case.
I tend to agree. I come from a fp Scala background, and Rust seemed very difficult and foreign... at first. After a few weeks of struggling, things just started to click. Now, my biggest worry is that all my knowledge of Scala will fade away, because now I only want to code in Rust. After using cargo, sbt seems like some kind of medieval torture. 
Right now, Lyon seems to be the only viable option since Pathfinder has no documentation.
I think would require implTrait for my use case: struct View&lt;S, A, F&gt; { value: A, // i think box doesn't really add anything? rebuild: Box&lt;F&gt; } fn mk_view() -&gt; View&lt;String, Char, ???&gt;
&gt; I picked up Go really quickly, it is a simple language with simple patterns. The thing I've found with this is Go is simple until you want to do something more complex. Pointers are not simple, nor is thinking about concurrency and shared mutable state which puts a large burden on the programmer while programming. When I program in Go it is also sometimes not clear when I'm copying and when I have a pointer (especially due to interfaces...) which can lead to some iffy situations. A side note: I really hate the patchy `defer` statements. It is just pseudo-RAII that doesn't work scoped which means that locking a mutex/rwmutex can easily lead to deadlocks if you aren't careful or if you don't scope the locking behavior into other functions.
Because that's not how pointers work. In terms of the physical (*i.e.* in-memory) layout, a `Box&lt;Bottle&gt;` is equivalent to `*mut Bottle`, so a single native word sized pointer. A `Box&lt;Shelfable&gt;`, assuming `Shelfable` is a trait, is equivalent to `(*mut (), *mut ShelfableVtable)`. This is because a type can implement any number of traits (including traits that didn't exist when it was written), so it can't use the same RTTI design found in languages like C++ or D. This means that a pointer to a concrete type, and a pointer to a trait object are physically incompatible: you absolutely *cannot* just reinterpret the first as the second; you *have* to perform an actual conversion step that creates a new value. This explains why you can't turn `&amp;Box&lt;Bottle&gt;` into `&amp;Box&lt;Shelfable&gt;`: you're trying to turn a "pointer to one pointer" into a "pointer to two pointers", which cannot possibly work.
True, there is a tradeoff. I still wish to counter the notion that 'it must be this hard' (for handwavy reasons, as in 'systems programming is hard' keeping us from pushing the limits of how easy systems programming really *can* be. So while yes, there is some inherent complexity involved, and Rust's learning curve is indeed steep, we should not stop looking for shortcuts, or for ways to give people a lift, without compromising on 'fast, safe, productive'.
Indeed. This is what prevents me from putting `#![no_std]` on most of the [pathfinding](https://crates.io/crates/pathfinding) crate. The size of most graph explorations is known in advance, and either stack or static mutable structure could be used.
As /u/Quxxy says: what you want can't be done. However, you don't need a `Box` to make a trait object, why not make a `&amp;Shelfable`?
Thanks for the clarification! 
That's exactly what I ended up doing, but I couldn't explain why casting the box failed.
/u/nasa42 QOTW?
I'd say that difficulty of learning programming language is inversely proportional to difficulty of using that language. The simplest language I've ever learned is brainfuck. It took me 2 minutes, but writing anything more complex in it took maybe 100 times longer than in most other languages. On the other hand, learning Rust took me month and writing *correct* code in it is a breeze.
&gt; Those complaining of slow rust compile times have never experienced the good ol days of running c under valgrind and then exercising the program to try and find leaks. I and my colleague have just spent about two months of chasing some crashes in our code. What is slow now?
&gt; nobody has worked out how to do a good GUI API in Rust yet? I believe that the whole GUI design is broken. Redesigning and implementing it from scratch takes time.
Thanks for the feedback! All the documentation you see was written yesterday evening, and I'll gladly add more :) 1. I totally forgot to link to &lt;http://docs.rs/structopt-derive&gt;! My mistake! 2. I just added some documentation to `main!` in addition to some new features (see &lt;https://docs.rs/quicli/0.1.1/quicli/macro.main.html&gt;). "What the main macro does behind the scenes" is something I don't really want to document because then it becomes part of the public API. :) What information do you think is missing? Currently, the docs say: "Inside the block, you can write code using ?. An Ok(()) will automatically be appended." (and then go on and talk about the new parameters.) Yeah, adding more module level docs is also planned. I want to add some more examples and show them in a nice way, but I'm not yet sure how best to do that. (Maybe I can finally use a `docs/` folder with Jekyll and parse the md files in there with waltz to test the code on CI!)
More work on [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis). Last week I made some documentation improvements and implemented a bunch of standard traits: `PartialEq`, `Eq`, `PartialOrd`, `Ord`, and `Default`. This week I'm trying to solve a compile time [issue](https://github.com/iliekturtles/uom/issues/52) ([easy question thread](https://www.reddit.com/r/rust/comments/7s3pul/hey_rustaceans_got_an_easy_question_ask_here_42018/dt2392g/)) where the "privacy checking" pass is taking nearly three minutes when all features are enabled!
Listen. I've reiterated over my points multiple times across across both this thread and previous ones. I even distilled them into two simple points that anyone can comprehend. Rust developers come from a diverse set of backgrounds and values. What may seem acceptable to you is not acceptable to others. The moderatorship committing to the two very reasonable points in my previous comment will go a long way towards alleviating these issues. &gt; I'm tired of relitigating the same thing again and again. That makes the two of us.
Wowzers, this is great! I love how the vector graphics family is growing. 
Amaing work, this looks promising :) Random question, is anything related to the french city of Lyon ? 
Have you considered using the NVIDIA OpenGL extension `NV_path_rendering`?
Oh cool. Thanks!
&gt; There is plenty of code that you could write in C++ that is perfectly safe, but Rust would disallow because the borrow checker isn't smart enough to work out that it is safe What people forget is the other end of the spectrum, viz. that plenty of code one could write in C++ is unsafe. Some of it obviously so, but some of it subtly enough that breakage will become evident much later, or when a component's functionality is extended, or when the original component is integrated with other code. Rust's borrow checker is imperfect insofar as it will fail to recognize some safe constructs, and that expressing certain kinds of data relationships is tedious and/or awkward. This should be weighed against the fact that what it _does_ accept has an exceptionally high probability of being memory- and data race safe. It's a tradeoff which one can accept, or not; what's distinctly unhelpful is trivializing the problems that the borrow checker attempts to solve.
Still working on a way to analyze data from particle collisions recorded by ALICE at the LHC in pure Rust. [My current implementation ](https://github.com/cbourjau/alice-rs) has all but the IO part written in Rust. However, the IO requires the ROOT-c++-framework for reading the available binary files. However, besides of wanting a Rust solution for its own sake, the ROOT framework also exhibited strange race conditions when called from multiple threads. This weekend, I finally managed to replace all that c++ code with a pure Rust parser based on nom. This week, I want to clean up the code and run a few comparison benchmarks between the cpp and the Rust parsers. Once done, I'll certainly post the results here. Exciting times!
Yep :) I grew up there. I am not very good at naming things and there was already a vector graphics related project named after a city (cairo) so... 
Thanks for all you great work, Nical! I’m using your Bézier curve implementation for keyframe interpolation!
Trying to get back into my pet compiler project... I keep switching between C# (because I find it easy), and Rust (because I love this language even though I find it frustrating at times). I'm currently on Rust.
Do you really need ownership of a String? If not, just take `&amp;str`. If you really need ownership of a String? Just take String and let the user take the slightly more ugly syntax when they want to use literals. If you really want to provide a pretty API for users, consider wrapping the arguments in a custom struct and define a trait to abstract away all the generic parameters: [playground](https://play.rust-lang.org/?gist=205c6e50eed490deca5c0c3fa70e3794&amp;version=stable) I hope this helps. 
Yes, /u/optimisticlockexcept is correct
https://doc.rust-lang.org/book/second-edition/
Continuing to work on [nanowasm](https://github.com/icefoxen/nanowasm), a small and simple WebAssembly interpreter intended for standalone use or embedding and extension. The actual interpreter part of it is mostly done, albeit a bit buggy, so now I need to run it against the official webassembly test suite and see where it falls down. After that comes the fun bit, profiling and optimization. 
Is this not part of debug info / symbol tables? Can it not be removed with `strip`?
What is the question you're asking?
&gt; Automatically published version of the package `rustc_errors` in the rust-lang/rust repository from commit *snip* It seems like these are parts of the compiler that are automatically extracted into crates in case other people want to use them? I don’t know for sure. There’s a chance a new version is released (with major number incremented) every nightly with changes in that module. 
The only dependent crate on this crate family seems to be rustfmt. They are publishing these crates most likely just for rustfmt so that if some contributor breaks libsyntax, rustfmt can still ship.
I had no idea these crates existed. This is awesome! I wrote many of the web-interface error messages for Pyret, and I wonder if I could compile these crates to WASM to improve our error reporting for CLI errors.
Oh.. I forgot about semver. I think I don't have to worry then.
It would be an interesting experiment. With lyon I wanted to go for a completely portable solution, so NVPR was out of the question for the core of the crate. That said I would love to have as many alternative approaches implemented because choice is healthy and there is much to learn by comparing different solutions. Now, I am also willing to challenge the idea that NVPR is the fastest you can get. The stencil-and-cover approach they use tend to suffer when there is a lot of overdraw (many shapes on top of each other which is typical for SVG drawings) where lyon and pathfinder can render opaque pixels front-to-back using the z-buffer with hierarchical depth culling to great effect. Once it has been tessellated, rendering the geometry produced by lyon is actually close to the fastest thing GPUs can work with since it's exactly what they have been optimized for since their invention. NVPR does have an advantage if you are re-generating the paths every frames though, since there is very little CPU work for them, while lyon/pathfinder come with an up-front cost of generating the geometry the first frame, and subsequent frames are very fast.
I have a feeling some of the arguments will be string literals `&amp;'static str` and the others `String` but the API can't predict which ones will be. By using the same generic parameter you force the user to either use `&amp;str` for all, or `String` for all which doesn't sound very friendly.
Nice! And thank you :) The geom crate is one of the parts that has received some very meaningful contributions from ignition, pizzaiter, and other [contributors](https://github.com/nical/lyon/wiki/Contributors), I have to share the credit here.
This is what [stdcli](https://github.com/vitiral/stdcli) is supposed to do! Get away from my use case! :P /s On a more serious note, it would be SO NICE to be able to reexport macros on stable so the user didn't have to add struct_opt directly to their Cargo.toml. Also having things like [`hashmap!{...}`](https://crates.io/crates/maplit) at your fingertips make rust "feel more like python" when writing CLIs.
Phew, any way to order it without the hefty of shipping from US?
As somebody who's done a fair amount of vector and 2D graphs (but so far not on GPU), I just want to say I'm happy to see all the activity, especially the diversity of approaches. GPU is sufficiently different that it's not obvious what's going to be the best solution, so it's great to have lots of things to evaluate.
I’m right there with you, my HTML might as well be made in MS Paint
Or simply split `std` into several crates, so `std` is only a facade. If you write `no_std`, you can still depend on all the crates.
How did you calculate 500 pages? Looks like it's around 100 to me
Nice! Good to see another physicist in here. I’ve been dying for an excuse to rewrite some of our experiment software in Rust (currently written in a proprietart scripting language from the 90s 😩), but then I wonder about whether anyone who comes after me will know how to modify or debug it. There’s also the small issue of needing to defend at some point 🤷‍♂️
Couldn't you define an intermediate crate that has these defines these macros under a different name? e.g. stdcli-macros-compat depends on all the macro crates and then defines `hashmap_compat!()` which just expands to `hashmap!`. Then stdcli could revert that by having a macro called `hashmap!` that expands to `hashmap_compat!()` from std-cli-macros-compat.
if you've written C programs *that work*, rust is finding explicit markup and someone elses names for things you intuitively deal with already
i clicked on the print button to get it on one page, then printed to pdf.
As someone who has no experience with graphics whatsoever, where’s a good starting point for learning about the graphics stack? I’m primarily interested in GUI.
Thanks for your work, it is very much appreciated!
/r/playrust
Thanks, that's quite a compliment, hehe.
You're saying `sudo: false` but use sudo afterwards. Should that work? 
I like this post, but something worth considering is that none of these problems are unique to Rust. If this existed it could apply to any technology.
Coding up a toy XMODEM implementation
Bored at work, here's how my suggestion could be worked out for your specific signature: [playground](https://play.rust-lang.org/?gist=71563c65b80b38ed32478d14b9e034c4&amp;version=stable) use std::borrow::Borrow; pub type UID = u32; pub type PID = u32; pub struct Arguments&lt;S1, S2, S3, S4, S5, S6&gt; { pub document_type: S1, pub uid: UID, pub pid: PID, pub title: S2, pub url: S3, pub abstract_text: S4, pub description: S5, pub content: S6, } pub trait TArguments { fn document_type(&amp;self) -&gt; &amp;str; fn uid(&amp;self) -&gt; UID; fn pid(&amp;self) -&gt; PID; fn title(&amp;self) -&gt; &amp;str; fn url(&amp;self) -&gt; &amp;str; fn abstract_text(&amp;self) -&gt; &amp;str; fn description(&amp;self) -&gt; &amp;str; fn content(&amp;self) -&gt; &amp;str; } impl&lt;S1: Borrow&lt;str&gt;, S2: Borrow&lt;str&gt;, S3: Borrow&lt;str&gt;, S4: Borrow&lt;str&gt;, S5: Borrow&lt;str&gt;, S6: Borrow&lt;str&gt;&gt; TArguments for Arguments&lt;S1, S2, S3, S4, S5, S6&gt; { fn document_type(&amp;self) -&gt; &amp;str { self.document_type.borrow() } fn uid(&amp;self) -&gt; UID { self.uid } fn pid(&amp;self) -&gt; PID { self.pid } fn title(&amp;self) -&gt; &amp;str { self.title.borrow() } fn url(&amp;self) -&gt; &amp;str { self.url.borrow() } fn abstract_text(&amp;self) -&gt; &amp;str { self.abstract_text.borrow() } fn description(&amp;self) -&gt; &amp;str { self.description.borrow() } fn content(&amp;self) -&gt; &amp;str { self.content.borrow() } } pub fn consumer&lt;T: TArguments&gt;(_data: T) { // do stuff with data } fn main() { let data = Arguments { document_type: "document_type", uid: 42, pid: 27, title: String::from("title"), url: "url", abstract_text: String::from("abstract_text"), description: "description", content: String::from("content"), }; consumer(data); } 
I really think the use of `dyn` will alleviate some of the confusion around trait objects.
Maybe ask for advice/mentorship from Dylan McKay (LLVM/Rust AVR developer)? Their blog is [here](https://dylanmckay.io/blog/rust/avr/llvm/2017/02/09/safer-microcontrollers-almost-here.html).
You can still use a `Box`, but you have to create a new one: let object : Box&lt;Shelfable&gt; = Box::new(*bottle);
It has some API documentation now. Still working on design documentation.
I don't know, I've never tried that! I'll have to give it a go. Is it that simple for the `derive` ones as well? (I've never written one)
I'm really excited to experiment with Pathfinder!
Oh, right. That's shadowing. Thanks for the correction. 
No, that's an awesome summary. :) As I said on IRC, I wonder if we should at least merge the Pathfinder path utils crate and Lyon's geom and path crate. The latter crates are more polished and have more community mindshare and I'd be happy to consolidate the effort.
at a guess: why does this take so long and how can it be sped up?
RFC 2025 is more along the lines of NLL (and is being implemented at the same time). It'll certainly help a common case of "`&amp;mut` exists but I'm not using it so why can't I have a `&amp;` for a bit?" I think the new NLL error messages will be absolutely crucial for that to work well, though. If you start to expect the general ability to alias when one is unused, it will be all the more mysterious when it fails, unless the compiler points out exactly what operations are confounding its ability to analyze the situation. And yes, I also suspect `&amp;mut` needs to remain a "unique" reference rather than merely a "mutable" one- not only to prevent logic errors, but to preserve memory safety around `unsafe`.
Oh nice -- I didn't know this existed! &gt; it would be SO NICE to be able to reexport macros on stable so the user didn't have to add struct_opt directly /u/vitiral/ + /u/fgilcher: You can re-export macro_rules macros, _and_ you can re-export proc-macro/derive macros -- it's just a matter of `pub use thingy::*;` and that's what I'm doing. The issue is that the proc macros might do some clever stuff (see [this tracking issue](https://github.com/killercup/quicli/issues/9)) to access their main crate's types.
None that I know of, besides issue trackers for specific repos or libraries. For your specific papercut, maybe [submitting an issue to `rustdoc`](https://github.com/steveklabnik/rustdoc/issues/new) would be the best thing to do?
Exactly. Why is the "privacy checking" pass taking so long. What can be done to reduce the time? Is this bad design in `uom` or a bug in `rustc`? Just an inefficient pass that optimization can clean up?
wait... this actually _works_??? #[macro_use] extern crate serde_derive; mod reexports { #[doc(hidden)] pub use serde_derive::*; } pub mod prelude { pub use reexports::*; } ... I know nothing about rust. I though you couldn't `use crate::macro` _at all_. Are the separate modules even necessary or is that to just provide some level of organization? If all this is true, why is [this even an issue anymore](https://github.com/rust-lang/rust/issues/29638)? Can you post a short guide to that issue explaining that this is _all actually possible in stable rust_? 
I stole that from diesel/weiznich from the diesel team actually -- who IIRC said they saw that in serde. (I have a feeling this all goes back to /u/dtolnay!)
&gt; unless the compiler points out exactly what operations are confounding its ability to analyze the situation. Yes, that bit is crucial. &gt; but to preserve memory safety around unsafe. Do you have an example? I didn't read the nomicon yet. 
I am not sure how you'd make it work. Today, features are additive, not substractive: - are you proposing to add substractive features? - are you proposing to add a way to specify a "default" list of features? - something else?
Finally getting around to implementing digest authentication for [mio_httpc](https://github.com/SergejJurecko/mio_httpc). Shotout to [pest](https://github.com/pest-parser/pest). The 1.x.x release is really really nice.
It does go back to /u/dtolnay See https://github.com/dtolnay/semver-trick
That follow up article shed enough light on LTO for me to understand it. Thank you, Kevin (don't know your name tag here). And thanks for `clap`.
&gt; Released 2017/01/22 We all do it, but it's 2018 now. :)
I think this is partly just a symptom of the function taking too many parameters. Doubly so as so many of them are strings, making calls to the function difficult to both read and write. You could use the builder pattern instead or, as another commenter mentioned, a custom struct.
You’re on the wrong subreddit - you’re probably looking for r/playrust
Does anyone know why none of the books that are generated in this style ever set the title tag properly? I realize this isn't the greatest place to ask, but I was reminded again when I went to bookmark this new location. My bookmark currently looks like "Introduction - " which is just not that helpful. I would have expected it to say "Introduction - Rust By Example" . This happens with just about every book I have seen in this format.
I think it’s a configuration issue. Have you filed bugs?
I am writing a simple server that collects some information of the status of the Bitcoin blockchain. I'm using both rust-bitcoin and reqwest. But, I'm having the following conflict: error: Multiple packages link to native library `openssl`. A native library can be linked only once. Package `openssl-sys v0.7.17` ... which is depended on by `openssl v0.7.14` ... which is depended on by `openssl-verify v0.1.0` ... which is depended on by `hyper v0.9.18` ... which is depended on by `jsonrpc v0.8.0` ... which is depended on by `bitcoin v0.10.6` ... which is depended on by `blocker v0.1.0 (file:///home/dellis/dev/rust/blocker)` links to native library `openssl`. Package `openssl-sys v0.9.24` ... which is depended on by `openssl v0.9.23` ... which is depended on by `native-tls v0.1.5` ... which is depended on by `reqwest v0.8.4` ... which is depended on by `blocker v0.1.0 (file:///home/dellis/dev/rust/blocker)` also links to native library `openssl`. I understand what this error means, but I don't know how to resolve it. Any pointers would be helpful.
I solved this by using [form](https://github.com/djmcgill/form) coupled with [rustfmt](https://github.com/rust-lang-nursery/rustfmt). Navigating into your .cargo/ registry, you can use `form -i ./src/lib.rs -o ./src` for any of the hefty libs. it will split it into logical mods, each with a single line of code, which intellij is able to index. Using `cargo fmt` will make it legible for when you click into the definition.
"Much" is quite an exaggeration. If [this image](https://flutter.io/technical-overview/#layer-cakes-are-delicious) is to be believed, the native components it builds on are a dart VM, skia, and a text rendering engine. skia is a generic 2D rendering engine that has nothing much to do with Chrome. Yes, it is being developed by Google and Chrome is using it, but that doesn't mean that skia is specific to Chromium or something. Correct me if I'm wrong but from what it seems, the dart VM doesn't use anything from V8 but is doing JIT itself. Not sure though whether the dart VM is actually being used though. Maybe there is AOT compilation instead, or dart is compiled to JavaScript and then uses the target phone's JavaScript runtime (as JITs are forbidden by Apple). 
&gt; I’m not sure why there is a decrease though, as that seems counter intuitive. Probably because your compiler is inlining extremely small functions over crate boundaries, since without LTO every function call to an extern crate compiles down to a `call` instruction with its additional bloat. So instead of mov -4[rsp], eax mov -8[rsp], ebx call extern_crate::sum::someadditionalhash mov ebx, eax we get add ebx, eax
It’s all good. Against the rust repo is probably best since it affects all of the docs. Maybe the issue for TRPL was fixed recently and so that hasn’t made it to stable yet. We’re also not on the latest mdBook so it might be that too.
I first parsed this as "gore-leaser" and had a hard time getting anywhere :D
Yup, I subscribe to every word you say! Our framworks are obscure when written in c++, but sometimes you just stumble over a 25k line file of Fortran77. Living on the edge :D This project of mine is really just a fun project at this point, but I learned so much by writing it. That being said, I see a few opportunities for some analyses which would be almost impossible in the official framework.
&gt;The only kinds of shared mutation that lead to unsafety are the kinds that change the "shape" of an object- reallocating a Vec there's still logical issues though.. of rusts restrictions, it's stance on shared mutable state is the one I like the most
Possibly? But they are there by default. `strip` doesn't remove everything for me, the same paths are still there for me visible in `strings` after stripping the binary. I'm not sure why these are there though - it could be logging metadata maybe?
OP mentions in the subject that they are trying to do this with a `&amp;Box&lt;T&gt;`, not a `Box&lt;T&gt;`. I'm pretty sure your example doesn't work when `bottle : &amp;Box&lt;Bottle&gt;`. But I wonder why anyone would ever pass a `&amp;Box&lt;T&gt;` to begin with, as I don't think it has any advantages over just passing `&amp;T`...
[The boxfnonce crate](https://crates.io/crates/boxfnonce) seems promising here, although I have not used it myself.
How and where do you intend to distribute the binary? I'm asking because GTK+ is LGPL, and you may not be allowed to under the terms you want to. It's the main reason language runtimes linking GMP for bignums run into problems.
Out of interest, what was so painful about the Kotlin experience? Did you have previous experience using Postgres from Java? Or were you new to the whole JVM ecosystem?
How to join a Vec of Rc&lt;String&gt;? Something like this: use std::rc::Rc; fn main() { let strings = vec![ Rc::new("aaa"), Rc::new("bbb"), Rc::new("ccc"), ]; let joined = strings.join(", "); println!("joined: {}", joined); }
What were the effects on the other dependencies inside ripgrep with those optimisations?
I'm starting down this path myself. I've committed to learning Vulkan since it unifies compute and graphics APIs, and rust has a good Vulkan library in vulkano with examples to get you started.
I don't know if it's the most efficient, [but you can use a fold](https://play.rust-lang.org/?gist=6000c31cefa648a09a8692ec8d3f664d&amp;version=nightly). I'm not sure how to do it without requiring the trim or making the fold expression kind of ugly: https://play.rust-lang.org/?gist=3d1b0481a81da992ea96d6d4378283e9&amp;version=nightly
It would be helpful if you included the specific compiler error that you wanted help understanding. That said, I see a few things that look wrong, and maybe one of them will be the specific thing that's tripping you up: - `user_query` is a `String`, as you've initialized it with `String::new()`. It's not a `Result&lt;String&gt;` or an `Option&lt;String&gt;`, so it doesn't make sense to `match` against it. - The `expect()` call that you're doing tells the program to panic if `read_line` returns an error, and otherwise to unwrap whatever's inside the `Ok()`. This "consumes" the `std::io::Result` that `read_line` returns, so the return value of `expect` isn't a `Result` anymore. (In this case, because `read_line` returns `std::io::Result&lt;usize&gt;`, the return type of `expect` is just `usize`.) - `None` and `Some` belong to the `Option` type, not the `Result` type. If you wanted to match against a `Result`, you'd need to use `Ok` and `Err`.
I don't tinker with CPU emulators so I don't know what's typically done here. It'd be a little tedious writing them all out, but you could represent instructions as an enum, so you have variants with 0, 1, or 2 arguments.
unfortunately, the only real way to fix these errors is “update the bitcoin crate so it doesn’t depend on the old version of openssl anymore”. it’s an annoying part about the rust ecosystem 
Do you think the same of the `*`, `/`, `+`, `-` operators ? Because I think it can be of the same order of magnitude as the `as` keyword: be overrideable and use for any type. If you compare the sharps edges of the saw with the lossy conversions I don't think it's what anybody want, or with a warning at least. I don't want to deprecate `as` in favor of a lot of trait implementations, I want to group the two features: a simple keyword `as` that is in reality a call to the conversion method `Into::into`, permitting to everyone to implement conversions and simplify the usage of them, as the same as `Add` or `Eq` work with the `+` and `==` operators.
Is it possible to optimize different dependencies differently? For example, maybe in `ripgrep`'s case argument parsing is a small fraction of the run time regardless of the optimization level, so we'd want to optimize `clap` for size and then optimize the rest of `ripgrep` for speed. Is this sort of thing possible?
I must sadly say that this post starts of very well, but then goes into minutiae. I must say though that it's a very good first post! There's a _ton_ of job platforms out there, writing one of the size of a minor startup just for the Rust community is neither necessary nor do I expect it to be doable. Pros will still run circles around you. I also wouldn't know why it has to be build in Rust, but that's another thing. Like, our job platform isn't devoid because no one of us cared about it, but because no one advertised! Sadly, the post fails at researching what the actual problem is: why is no one hiring for Rust jobs? Or at least not openly?
One of the other people who responded to your PR mentioned a preference for deprecating `as`. No, I do not think of `as` as being comparable to an arithmetic operator. I've been using it for years in other languages where it serves as just a way of converting a thing into another thing that, in some sense, it *already is.* For example, `BasicAuthProvider` might be used `as IAuthProvider`. This is legal not because I have implemented some conversion but because the compiler already knows that, under the hood, the two are interchangeable. ...Note that `BasicAuthProvider` to `IAuthProvider` is a lossy conversion. I can't safely go back to `BasicAuthProvider` from `IAuthProvider`, and I can no longer access any members specific to `BasicAuthProvider` after the conversion. I see none of this as a problem, of course. I see it as *what I meant to do.*
This is fantastic, I'm just building a keyboard firmware with RTFM and the latest changes are really useful! How would you do power management with RTFM? Where you want to shut down a number of peripherals for a while, and then wake them back up later? This probably requires access to registers that you don't have fully available anymore after init has run, and depending on the sleep mode you might need to reconfigure some peripherals after waking up again. Merging your split up resources back together seems sketchy, maybe it could just completely reboot and re-run init?
Yeah that compiler error is telling you that the type of your two match arms (`Option&lt;String&gt;`) doesn't match the type of the thing you're feeding into the match (`String`). The official docs take a little bit of getting used to, but if you look at https://doc.rust-lang.org/std/result/enum.Result.html#method.expect you can see that both `unwrap` and `expect` act on a `Result&lt;T&gt;` but return a `T`.
Thank you for your response. I don’t mind a little annoying effort. I just don’t yet understand the steps involved. Would you mind laying some crumbs? Do I need to fork the project T GitHub, it can I perform the modifications locally?
The logo is like if [Doge.svg](http://i.imgur.com/iVegJ35.png) and [standard_tiger.svg](https://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/Ghostscript_Tiger.svg/1024px-Ghostscript_Tiger.svg.png) had a baby, it's good
With an enum you can have: enum Instruction { Nop, OneArgOp(u8), TwoArgOp(u8, u8), } So the representation of the instruction and its arguments are tied together.
There is. match c { x if x.is_alphabetic() =&gt; println!("alpha"), x if x.is_whitespace() =&gt; println!("whitespace"), _ =&gt; println!("other") } https://play.rust-lang.org/?gist=28d3081a24ec9692451f8fc9b9473896&amp;version=stable
Oh this is really good. I need to have a poke around to see if we (rust-geo) can use or adapt the Bentley-Ottmann implementation to use for Polygon self-intersection checks. In return, we have [a really nice convex-hull implementation](https://github.com/georust/rust-geo/blob/master/src/algorithm/convexhull.rs), based on QuickHull…
I don't see how that will help here. The problem is that the OP believed value and trait object pointers are interchangeable, not that the trait object was monomorphic. `dyn` is just syntactic noise.
This is what regular `if` expressions are for. if c.is_alphabetic() { … } else if c.is_whitespace() { … } else { … } I recommend only use `match` where it adds something. For example, if you need to care about the value of the comparisons in multiple branches (e.g. if for two booleans you need to care about all four cases, `(true, true)`, `(true, false)`, `(false, true)` and `(false, false)`—`if` would still work, but would be messier).
I didn’t compare it to only an arithmetic operator but simply an infix operator, like the [`InPlace`](https://doc.rust-lang.org/std/ops/index.html) one. In Rust the `as` keyword work only for converting into primitives so it’s not possible to cast into an interface, but it’s not even possible to convert to Trait with the `Into`. I think @burka is right about `as` actual behaviors https://github.com/rust-lang/rfcs/pull/2308#issuecomment-359592378
Not intending to distribute it, just really want to know how to statically link c libraries in rust.
Yeah, I knew how to do it with if statements, just wanting to figure out more about `match` even if it's not necessary in this case. And hey, I read your fizz buzz blog earlier today!! Gave good insight!
Going to try and make some actual progress on tarpaulin for the first time in what feels like too long, going to try and chip away at some issues and think about how to make tarpaulin more accessible to first time contributors. Also, working on a blog post but that's on my main machine and an nvidia driver update has taken that temporarily out of action... 
In this case specifically, I think you'll need to fork &amp; PR the https://github.com/apoelstra/rust-jsonrpc crate to use the newer `hyper` version. Since `hyper` switched from blocking to non-blocking in 0.11, you might want to switch to `reqwest` entirely for it too. If you fork it, it's definitely possible to override your local dependency (or in this case `bitcoin`'s dependency) using a cargo patch: https://doc.rust-lang.org/cargo/reference/manifest.html#the-patch-section. I'd recommend submitting a PR to the original repository which updates it too, but that might take a while to get merged &amp; released.
Let's not discuss semantics; you understood what I meant. The use case I demonstrated is from what I'm doing at work right now, which is written in C#, but there is a similar use case in Rust: https://doc.rust-lang.org/book/first-edition/trait-objects.html My intent was only to demonstrate that this use of `as` is familiar to programmers from other similar languages.
`singleton!()` for the world. Yay!
Ah, thanks. But it seems to still execute sudo commands [successfully](https://travis-ci.org/Boscop/web-view/jobs/331733611#L527), right?
Though if you use Pathfinder's ECAA mode then you have many of the advantages and disadvantages of NVPR: poor overdraw support and state changes, but near-zero up-front cost.
It sounds like there's some reason you need to have an `Option&lt;String&gt;` that you're not telling us. That's another piece of context that would help us give you better advice. Also I think the `to_string` call there is a no-op, and you can omit it.
Do the lack of AA, and emphasis on lines rather than curves, imply that lyon isn't really aimed at text rendering yet? Most 2D vector applications - mapping, charting and other infographics, games - have at least some text in them.
IMO there are three axis on which Rust can be difficult: - the APIs - the concepts - the diagnostic errors The API design in std is actually quite nice in my opinion, but can and is being actively improved. The concepts _are_ hard, and there's work to remove limitations that are not inherent to the concepts (NLL, for example). The diagnostic errors can be obtuse, but they don't need to be. Very few cases I have come across rustc errors that couldn't be improved upon in order to take the chance to 1) teach the language and 2) point out appropriate solutions in-place. In some cases you can consider it silly that rustc knows that you can change the code in a certain way and it'll work, why not accept the code as valid and let you go on your merry way? I believe that there is value in keeping the language with a regular grammar (so that certain constructs are not accepted, specially around `&lt;` comparisons and type ascription) and in keeping things visible (like `String` coercion into `&amp;str` and vice versa). Not everybody agrees with these positions, though.
&gt; Do you think the same of the *, /, +, - operators ? Because I think it can be of the same order of magnitude as the as keyword: be overrideable and use for any type. I don't think being able to overload `as` is necessarily bad thing, but using existing, quite heavily used trait for such overload is bad. Figure out a good name and drop it into `std::ops` and it would be a lot better.
Correct. Lyon is best suited for filling large paths and a dedicated algorithm that doesn't need to worry about fill rate and focuses on high quality AA would be better. I do want to have that at some point but with the amount of time I can dedicate to the project, I haven't gotten to it yet. The easiest way to render text with lyon is probably to draw glyphs on the cpu with freetype or rusttype, cache them in a texture and render then as quads like most 2D engines do. In other words it's boilerplate that isn't provided by lyon at this time. Pathfinder is great at rendering text, though (can also use it alongside lyon). 
Kotlin the language is not bad at all. It's mostly a much nicer Java (I used to say that about C#) My specific gripe was while working with this postgres lib: https://github.com/mauricio/postgresql-async. Then I worked a bit creating a Vert.x prototype. All docs made the assumption that I'd be using an IDE that would perform all the magic steps (imports/etc). Being tied to a tool in order to accomplish rudimentary tasks is something I loathe. So the pain is really in the assumptions of the community/ Jetbrains. Learning Scala was a much different experience a few years ago. I felt like I just needed to pick up a book and start typing examples and playing until things made sense. (I've also done plenty of Java and JRuby)
We may very well get an auto-rustfix some day, but for that the diagnostics have to be waterproof, which many currently aren't. 
I accidentally used `as` instead of `Into` the other day on an enum that coerced to a u8 (iirc), and only found the bug much later. I think the compiler should raise flags on any non primitive `as` usage. 
Thank you for explanation.
Enum to primitive integer conversions are _very_ useful when doing bit twiddling. This is correct behavior, and there's no reason to make the compiler warn users. On the other hand, I believe Clippy has lints exactly for this. So if you had used Clippy, you may have found your bug sooner.
I was thinking it might be cool to get a ^ operator that does into instead
In theory this can be done. In practice monomorphizing compilers really frustrate this problem because most generic code (read: a lot of rust) only has its types filled in by downstream crates which may have different compile options set. Dynamic linking involves the same set of core trade offs for monomorphic compilers.
At the lowest levels, Rust is as interchangeable with C as C++ is for the following reasons: 1. You can use `extern` and `repr` to specify that the calling conventions and data formats used are identical to the platform convention for C. 2. Like C, Rust has no heavy runtime that requires its state to be saved and then loaded as control flow moves back and forth between Rust and other languages, nor a garbage collector that needs to know how to play nice with some other language's garbage collector. 3. The vast majority of languages expect to be extended in C because C's the only widely-used, GC-less language with a stable ABI... and most of them are written in C or C++ too. Those points mean that your question boils down to "How well does Rust provide a zero-cost abstraction over my preferred language's extensibility APIs?" I only have experience with [rust-cpython](https://github.com/dgrunwald/rust-cpython) but crates which provide a safe extension API like that generally do it by providing macros, functions, and data types which provide stronger type-checking than the language runtime's own C API can, but then get collapsed away during compilation. (Rust borrows the C++ term "zero-cost abstraction" which means that, barring a compiler bug, the comfy, high-level abstraction should compile to the same optimized machine code you'd get from doing it the hard way.) One simple example that you can use in purely Rust programs would be the "newtype" pattern: If you wrap an integer in a single element struct like `Celsius` to make sure that `degrees_c + degrees_f` is a compile-time error and call `degrees_c.pretty_print()`, it'll produce the same machine code as `pretty_print(my_integer)` because, in a language like Rust or C without runtime introspection support: 1. A struct has no overhead at runtime but you can use them to limit what the compiler will allow. (eg. `Celsius + Fahrenheit` not being a valid operation) 2. Something like `myStruct.foo` compiles to `ADDRESS_OF_myStruct + OFFSET_OF_foo_WITHIN_THE_STRUCT`. 3. Methods compile to plain ordinary functions that you just didn't have to manually pass `self` to. That's why the standard library's `Path` is a single-element struct which adds new path-related methods and validity constraints to `OSStr` and `OSStr` does the same thing around a chunk of memory. Under the hood, converting a `Path` to an `OSStr` has no runtime cost because the data representation is identical... it's just a question of which functions the compiler will allow you to call on them.
Embedding isn't fundamentally different from extending. The runtime for the language you want to embed provides a library which exposes C functions like `Py_Initialize`, `PyRun_SimpleString`, and `Py_Finalize`. The corresponding Rust crate then wraps those up in a safe API designed to get collapsed away by the compiler.
/u/Kbknapp
there's no example of how to apply it to a piece of markdown. how to use it?
How close is `bindgen` to being "done"? Like one thing that I don't see listed here are any big projects that are now really usable with `bindgen` where before they weren't. For a general release announcement to r/rust, I'd love to see these highlighted.
For C, it is pretty close, though there are still issues surrounding bitfields (and particularly their portability). For C++, there is a lot of work to be done, and even boundaries and goals to be defined. There is also some more general usability (vendor / download libclang) things, as well as reliability (more fuzzing) work to be done.
Awesome! Serial ports are a little anachronistic but they're still widely used in the embedded space. I'm not certain what the architecture looks like for a GUI app using wasm to talk to serial ports, but I know that the GUI space is quite lacking in Rust and this is a great area to keep exploring. I could easily see Rust applications primarily relying web technology for rendering. I see you're using my `serialport-rs` crate, but you're the git version. There's very few fixes that haven't been pushed in a version, are you blocking on any of those or would 2.0 work for you? 
I would humbly suggest that issue [#753](https://github.com/rust-lang-nursery/rust-bindgen/issues/753) is a blocker for more than a few people. 
&gt; For C, it is pretty close, though there are still issues surrounding bitfields (and particularly their portability). What about [the preprocessor?](https://github.com/rust-lang-nursery/rust-bindgen/issues/753)
The talk was very clear and helpful to get started. 
These assets can be embedded in the binary, then temporarily written to disk when a path is required.
One of the easiest languages to embed is Guile, and is also a good way to learn how this way around works.
Not a diesel user, but I would assume it's because `NewTag` is for inserting data; `&amp;str` allows you to provide a string borrowed from something else without having to copy it. `Tag` probably needs `String` because it's being returned *from* the database, and the structure can't borrow from the internals of the database (it might be on disk, in a different encoding, *etc.*), so it has to own the string it returns.
How does this explain that you can do `let object : Box&lt;Shelfable&gt; = bottle;` according to OP?
TIL. I think I have some unnecessary copies lying around.
&gt; [...] you *have* to perform an actual conversion step that creates a new value. The coercion there *is* the conversion step.
I don't know how likely it is for js to exploit it. I definitely recommend updating. It's not worth the risk.
I'm fairly uninformed, but isn't this mitigation literally stopping programs compiled with LLVM from exploiting spectre variant 2? Maybe I'm misunderstanding the way this is fixed and what the fix does though, so I'll leave that to someone else. As for adoption, unless it's going to be backported to LLVM 4.0 too, it will be blocked on https://github.com/rust-lang/rust/issues/43370. There's been steady progress since that issue has opened, but to my knowledge there's still significant work needed before LLVM 5.0 can be the supported version in rust.
Absolutely. And I should disclaim my disclaimer. I haven't done vector graphics or path rendering on GPU, but I did just write a fast text renderer for xi-mac using OpenGL. The [code](https://github.com/google/xi-mac/tree/master/XiEditor/XiTextPlane) should be pretty accessible, and was in turn heavily inspired by alacritty. I joke that it's a pretty good game engine but the game needs to be more fun.
&lt;3
I hadn't thought of that, and in hindsight makes perfect sense. Thanks!
I second using a CSS framework like [bulma](https://bulma.io/), combined with any of the templating engines. I think bulma is pretty straightforward to grok for non-web developers. I'm on mobile so I couldn't look at exactly what you need, but if you've got an idea of what you want, please feel free to reach out. 
Simply beautiful. Can you talk about how long you have been working on the project for, and how "consistently" you work on it week to week? 
(i love project romances) Who do you guys work for?
I've got a Vec&lt;u8&gt; buffer from STDIN obtained with Read::read_to_end() and I need to treat it as 16bit LE. I've been using the byteorder crate but it feels clunky. I'm pretty new to Rust so I wonder what I've been missing. Is there a more elegant way? let mut cur = Cursor::new(&amp;buf); for i in 0..length / 2 { let val = cur.read_i16::&lt;LittleEndian&gt;().unwrap(); println!("{}", val); }
Couldn't clap be compiled as lib with minimum size, and statically linked when compiling your binary with optimization for fast runtime?
A [simple notes application](https://github.com/jmcph4/rsnotes), mainly to learn Rust itself. I was running into [issues](https://stackoverflow.com/questions/48363897/cannot-find-glutin-in-glium-when-using-conrod) with Conrod but I solved them now. While it was ultimately my fault, I still think Conrod's documentation and example code is lacking in both clarity and depth.
Relatively new to Rust, working on [matcha](https://github.com/andrewvy/matcha), a hobby distributed microblog blockchain. It's currently in a state of scaffolding and a collection of ideas. The main difference is that this cryptocurrency is around delegated proof-of-stake consensus, instead of the more energy-intensive proof-of-work algorithms. The usage is being able to publish/favourite content on the blockchain, while the client does all the off-chain heavy-lifting (getting latest content, following users, ignore lists.) This project also isn't meant to be as serious, just an education one. So far it's been really difficult picking up futures and tokio, but things are really starting to click! Still lots of things to do before it's a functional thing, but I'm quite excited!
It does seem a bit clunky this way - I'm not sure byteorder works best on slices that you've already read. I'd recommend just reading directly into a Vec&lt;u16&gt; from stdin. Not sure this is the best way, but what do you think of something like this? let stdin = io::stdin(); let mut stdin = stdin.lock(); let mut out = Vec::&lt;u16&gt;::new(); loop { match stdin.read_u16::&lt;LE&gt;() { Ok(v) =&gt; out.push(v), Err(e) =&gt; match e.kind() { io::ErrorKind::Interrupted =&gt; continue, io::ErrorKind::UnexpectedEof =&gt; break, _ =&gt; panic!("read error: {}", e), } } } println!("{:?}", out); 
Fixing Spectre is intels Job. Nothing anyone else should do.
Using a recursive function would probably make most sense in this case. There is an example of one in the [JSON test](https://github.com/pest-parser/pest/blob/master/pest/tests/json.rs#L337). Also, you should probably join us on Gitter for any other questions. :)
Amobg other things, latest llvm implements retpoline, which is a mitigation strategy prevents the cpu from speculating on an indirect return address. This makes spectre harder to actually exploit. https://stackoverflow.com/questions/48089426/what-is-a-retpoline-and-how-does-it-work is fairly informative
Added to [rust-learning](https://github.com/ctjhoa/rust-learning)
Thanks, this seems more intuitive. Still wondering if there's a more efficient way? This looks like it's also doing a check on every single read just to populate a buffer.
Interesting! How does this compare to sciter?
Thanks, should I use your code above to check if I'm still vulnerable or whether Windows has already installed the fix update?
&gt;Ahh okay, I think I was able to solve it by casting **the option** into another variable like so: I think you missed /u/oconnor663's first bullet point. Your variable is not an option, it's a string and it stays a string. If you're doing something like: let user_query_option: Option&lt;String&gt; = Some(user_query.to_string()); let query = match user_query { None =&gt; return Err(From::from("expected 1 argument, but got none")), Some(query) =&gt; query, }; Then this is equivalent to: let query = user_query; What you're doing is: wrapping a `String` into an `Option&lt;String&gt;` with the `Some` constructor, and then use a `match` construct to recover the embedded `String`.
does distributing the source code suffice? they can always rebuild the program from source...
So why drop the “Early Access” pretense? “Part of leaving Early Access is making the development more stable,” Facepunch reasoned. “That means that not rushing in features and fixes that end up breaking something else. For that reason we’re going to be transitioning to monthly updates.”
Wrong subreddit. Consider /r/playrust instead
Pff, who cares, I will continue using nightly!
Correct. Tag will be the owner of the data the DB gives you, so it can't contain a reference. NewTag is just a temporary view you use to insert data, so it doesn't need to own its data (and rust will make sure the referenced data is valid while we send it to the DB).
When I tried to use conrod for the first time it was also confusing, even though I was already familiar with Rust itself. Maybe it's better to use a simpler gui lib while you're still learning Rust, to limit the frustration.. Btw, I recommend always asking questions on IRC to get the fastest answer. But yes, for such a notes application, web-view would be very suitable (but then you have to know some html,css,js). You can also start writing the app like a normal web app with a server with REST API, and then you can use all the tools like chrome dev tools and tools to auto-refresh the browser when you change the frontend code, like browser-sync. And when your frontend is finished, you can then migrate it to embed it with web-view. You could embed a small web server that listens on an ephemeral port with hyper/nickel/rouille etc. to smoothen the transition to standalone app. And then change the communication to use the two-way js bindings (or just keep using the embedded server)..
Looking at some [old commits](https://github.com/nical/lyon/blob/55e3c3bf81bf6d79a30d91d28859592e504f77b7/geom/src/monotone.rs#L419), I was already toying with path tessellation in October 2015 (!) There isn't a lot of code from that time that is still in the master branch today. For more the last two years I think that I've always worked at least a little on lyon every week except in exceptional cases, like when traveling without a computer. But the more difficult question is how much brain power I have left after work to implement complicated stuff in lyon, and it varies. There are big features like resolution-independent tessellation that I have been meaning to implement for a long while and even have a description in the wiki written two years ago. When I am tired I tend to work on simple things which is good for polish and usability, but doesn't drive major changes. So there is always something going on and you can see it [on github's graphs](https://github.com/nical/lyon/graphs/commit-activity), but I can plan accurately when the next very complicated feature is coming. Lyon regularly receives contributions from other people, although nobody is sinking the same order of magnitude of their spare time as me yet, understandably.
Also, I thought Spectre wasn't limited to Intel?
If you release open source code, you don't get to control what computer your code runs on. So it'd be nice to give a hand to people who are impacted by this bullshit.
Is it open source?
Yeah Spectre is most things that do any sort of speculative execution
I need to try those. For the moment I have exceptions which need to be validated at regular basis.
Power management is not something I have delved into yet so take my words with a grain of salt. I don't know which microcontroller you are using but, IIRC, the STM32 micros have a *stop mode* (IDK if other micros have it) that puts the micro in low power mode by shutting down some clocks and clock gating most peripherals. When the micro wakes up from this mode the peripherals don't need to be re-initialized. Would that work for you? With this approach it wouldn't be necessary to re-initialize peripherals. There are several other low power modes with different trade offs as well. 
Yes. In that case, the same rules as with the GPL apply. The terms that make the LGPL distinct only really have meaning if part of the program is closed-source.
Thanks for your feedback! Hmm I agree, there are a lot of job platforms, I just had an idea to replace rustjobs.rs with something that's actually developed in a way that takes the community into account. Jobs were advertised though, just not on rustjobs.rs ;). As to Rust hiring, I'm afraid that's not something I can really provide insight into, given that I don't live in a country where Rust is being more widely adopted :)
Hmm, it is a tough problem, I feel what may happen with Rust is that a company wants to adopt it, then someone within the company works on that new codebase rather than hiring someone new. Having said that, the Rust developer I know was hired to work specifically on Rust.
One thing you could do... I don't recommend it, but you *could*. #[derive(Debug, Default)] struct Arguments { artist_id : ArtistId, album_type : Option&lt;AlbumType&gt;, country : Option&lt;Country&gt;, limit : u64, offset : u64, } fn artist_albums(args : Arguments) -&gt; ... {...} fn try() { artist_albums(Arguments { artist_id : 0, ..Default::default()}); }
LTO might de-duplicate some identical functions which would otherwise be duplicated (e.g. trivial accessors or generic specializations where the generated binary is identical for multiple types)
I believe it is a standard Rust formatting convention that both constants and statics are named as all-caps.
Spectre affects CPUs of all vendors, not just Intel. It was only Meltdown that was Intel-specific (and that one affected some ARM processors too).
As /u/rayvector said. The convention is to use uppercase for both constants and static variables. There's a built-in lint that will raise a warning if you don't use uppercase. [playground example](https://play.rust-lang.org/?gist=dd78fd9e899adafb3ec50bb515cd2851&amp;version=stable)
For Atom &amp; Rls users I released [**ide-rust**](https://atom.io/packages/ide-rust) 0.11 earlier today. The main new feature is handling when the nightly toolchain is missing Rls with automatic detection of the latest nightly that isn't. If you're an Atom user why not give ide-rust a go and help us improve this package. As always the more important development in this area is ongoing over at [rust-lang-nursery/rls](https://github.com/rust-lang-nursery/rls), _so all the more reason to have the latest working Rls release_. github: https://github.com/mehcode/atom-ide-rust
Awesome. I've been meaning to try Atom for Rust programming. So just to be sure: I need nightly for RLS, but I can still compile with stable (while using RLS), right?
This seems to be a crate to support [Functional reactive programming, FRP](https://en.wikipedia.org/wiki/Functional_reactive_programming). OP: Congratulations on making something! It would really help if you had explained anything in the post title, as well as defining "FRP" in your documentation before using it.
**Functional reactive programming** Functional reactive programming (FRP) is a programming paradigm for reactive programming (asynchronous dataflow programming) using the building blocks of functional programming (e.g. map, reduce, filter). FRP has been used for programming graphical user interfaces (GUIs), robotics, and music, aiming to simplify these problems by explicitly modeling time. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
How would one take the mean average of a generic collection type? Suppose I have a generic container Thing&lt;T&gt;(Vec&lt;T&gt;); impl&lt;T: Clone + Sum + Div&lt;Output=T&gt;&gt; Thing&lt;T&gt; { fn mean(&amp;self) -&gt; T { let sum = self.0.iter().cloned().sum::&lt;T&gt;(); let count = self.0.len(); sum / count } } where `T` would be a primitive numeric type. This currently does not compile, as `len()` returns a `usize`, the primitive types do not implement `From&lt;usize&gt;`, and `as` can only be used with primitives (which `T` is not guaranteed to be). Currently, I have a working solution that uses a custom trait trait FromUsizeForReal { fn from_usize(source: usize) -&gt; Self; } which I implement for the primitives I need as impl FromUsizeForReal for i32 { fn from_usize(source: usize) -&gt; Self { source as i32 } } impl&lt;T: FromUsizeForReal + ... &gt; { but this feels clunky. Is there a better (canonical) way to do this in stable Rust?
Very nice, thanks!
go-releaser, gorlser, goser? Or let's puch this further: goloser, gore-laser, gowrestler, rustaintgolang.
go-releaser is supposed to be the right one :P
According to his Twitter: &gt; Patrick Walton &gt;@pcwalton &gt; Research engineer at Mozilla
Mozilla
Is this a GTK feature, or are you saying that this is theoretically possible but world require work? Do you have examples that do this?
Intresting. I see you rolled your own `Either`. You could use [this one], which also comes with some nice helper methods, (https://crates.io/crates/either) for interoperability.
I would also point out that there are cases where parsing speed *can* be important. When it's possible to parse several thousands, tens of thousands, or hundreds of thousands of arguments (`ripgrep` has this potential use case) parsing speed can quickly add up to be non-trivial. I would agree that in the normal case though, parsing is always fast enough (in the thousands of ns) that compiling for size may be beneficial.
&gt; not rushing in features and fixes that end up breaking something else It really sounds like they need a better TDD story. Without writing tests, how can you be confident in any change you make?
Are late resources put into the `.bss` segment of the executable, or do they take up space in the flash image? What about non-late resources that happen to be initialized to binary zero? Thanks.
Which option is your favourite?
[removed]
Interesting. Congrats! I made [something similar](https://github.com/danylaporte/rust-asyncplify) 2 years ago when I was learning rust. I found implementing FRP in rust quite challenging: - Box must be used sometimes on multi publishing. - Multi-thread requires to duplicate all operators to support sendable callbacks. When they annouced the Tokio framework (tokio), I stopped working on the project. 
&gt; just really want to know how to statically link c libraries in rust. Each `-sys` crate should give you the option to choose the form of linking that you want. For example, `openssl-sys` reads a `OPENSSL_STATIC` environment variable, and if it's set, will statically link.
Does tokio allow for frp?
I haven’t tested it yet. The current implementation is ultra simple, with in mind the possibility to have mutual-recursion – mightn’t be flawless though, I need to perform more tests on that.
I'm saying that "needing a bunch of data files and stuff" should not be an issue for statically-linked binaries in theory. When I still worked with GTK, I recall there were few functions that required paths as arguments. I would need to store the contents of that file in the program as a binary blob, write it to disk on start up, and clean up before exiting. This was long ago. GTK might have improved since then.
&gt; It's the masterful description that piqued my interest: "I made this. It's a thing." Interesting, I didn’t know about this one. Thanks!
Yeay!
Thank you. This does look exactly what I'm after.
If people are that interested in it, I can change / enhanced even more the documentation, of course.
[Reqwest](https://docs.rs/reqwest/0.8.4/reqwest/) is nice.
You can use a GResource from the gio library to embed that content. Here's the link to the Rust bindings for it: http://gtk-rs.org/docs/gio/struct.Resource.html
I think you're thinking in app resources (which could be embedded using http://gtk-rs.org/docs/gio/struct.Resource.html ), but the OP may be thinking in other config files, such as the .gtkrc file, etc.
It's only for when you want to make a standalone app with a web frontend. The `todo-purescript` Rust example (the one whose screenshot is in the Readme) [is only 300kb](https://i.imgur.com/zIhtL5B.png) (keep in mind that the rust compiler by default links statically to the rust runtime, unlike C++), and 153kb of that is the uncompressed included `bundle.html` (the app.js is inlined into bundle.html by the build script and then the rust code embeds `bundle.html` as a string (uncompressed)). With electron each app would come with huge amounts of bloat.
No direct experience in Rust, just an old fan and admirer of a language that fits in 200kb.
My comment was about the way you named your topic. Car enthusiasts are more likely to click on a post titled "car" than a post titled "this". If you want interested people to know about something, and I assume you do because you made a post about it, then it would serve you well to state what it is in the title.
You should probably `static` that instead of `const`.
Some of us want to play Rust at work and that requires stability
Box allocate on the heap. It is not zero cost abstraction. I was trying to be as fast as the iterator.
I worked with you on fixes for said crate. :) Yeah, I just need to update and check that it works.
Two things: First, `iter` borrows the values, it gives you values of type `&amp;u8` in your case which are references. Second, `collect` is "generic over the kind of container". I guess you expected to get a `Vec` but at some point you have to make type deduction agree with your expectation. &gt; I hit this which is a pretty simple thing I think I could do in most other languages without problems. [...] but I have no idea how to accomplish my goal What *is* your goal? let borrowed_slice = &amp;contents_bytes[20..]; // refers to a part of the vec's buffer let my_own_vec = contents_bytes[20..].to_owned(); // has its own buffer (copy) let my_own_vec2 : Vec&lt;u8&gt; = contents_bytes[20..].iter().cloned().collect(); // Type hint necessary because connect is generic over the result type let my_own_vec3 : Vec&lt;u8&gt; = contents_bytes.iter().skip(20).cloned().collect(); // Type hint necessary because connect is generic over the result type 
Cow may help with that?
Have you used it with success? Copy pasting some examples from the docs but none of them work
What exactly do you mean by "don't work"? 
Looks like a pretty comprehensive (total) beginners guide. Exactly what Rust needed. 
I don’t use any `Box` inside, I use `Vec`, but that’s the same thing.
Interesting! I was actually using that crate, but didn't know about the unstable feature. Although the name 'unstable' doesn't really inspire me with confidence. I'll give it some research, Thank you!
&gt; Moreover, writing other tooling such as ctags for Rust is extremely hard because things keep breaking. I'm not really sure whether an API-stable libsyntax can ever be obtained as long as Rust is getting new features which extend the syntax of the language. So I'm not sure whether stable libsyntax works with the "stability without stagnation" plan. libsyntax that *compiles* on stable rust however seems like a doable thing and I do hope that eventually it will become a reality.
I wrote this a while ago for calling rust from c#: https://dev.to/living_syn/calling-rust-from-c-6hk
Well, if you consider async in rust as something for beginners, then sure. ;)
We were so slow with adopting LLVM 5.0 that [a direct jump to 6.0](https://github.com/rust-lang/rust/pull/47681) seems more likely. The major component that was holding back the 5.0 upgrade was emscripten. But in the future, it won't hold us back any further because we'll have a separate LLVM for emscripten, and a separate LLVM for the other targets.
Thanks, this seems to be much faster. I ended up accessing the data by pointer directly. Not quite as nice as I'd hoped but it's manageable. let buf = buf8.as_ptr() as *const u16; ... *buf.offset(x) ...
Ahh you're right. I was wrong. I just skipped through the TOC. It's actually not at all a comprehensive guide for total beginners. Unfortunately there's still only the official "book. :-(
&gt; CPUs of all vendors All CPUs that have speculation with side effects such as loading cache lines. Obviously there are some more primitive or low power processors that are not affected.
My understanding was that the retpoline mitigations were needed under this specific condition: You want your code to be able to exist in a shared memory space as untrusted JITed code that you want to sandbox away from reading other memory in the same process space. Doing this prevents speculative return-oriented programming by using your code as a gadget. But don't take my word for it; I might be mixing things up.
Fun fact: I believe the authors would love to rename it request, but nobody can get in touch with the author of [request](https://crates.io/crates/request) from 2015 :P
Also this would quite literally be the equivalent of Python's "requests" library for Rust, which is a fantastic tool.
Thanks!
See "Unresolved questions" section.
In python you can [send a value into a generator](https://docs.python.org/3/reference/expressions.html#generator.send), this is actually how async is implemented. Has there been talk of support for sending values into the generator?
It seems this implementation allows any number of consumers to receive results from a stream, while `futures::Stream` generally has a single output (and all combinators consume it, rather than taking `&amp;self`).
Arm is also affected.
I really should get this book it seems; you cover what I'm interested in. Unfortunately student budget ;(
I saw that, but it didn't seem adequately dealt with...a bit like it was being mentioned to head off a valid reason for not proceeding. Generator is still experimental and it feels premature to build in syntax sugar on top of it.
Yes, see tablair's link.
&gt; It seems like a mistake to specify this kind of desugaring when the underlying trait might change significantly. On the other hand it would be incredibly frustrating to stabilize a `Generator` trait that doesn't work with for loops. Just like `impl Trait` added more experimental features before stabilization, I think its important to expand the scope of the `Generator` experiment so that we can see how it interacts with the ultimately desired features, even if they get stabilized later.
&gt; Rust has a great RFC process for designing new features. Unfortunately, features get proposed faster than they are discussed. As a result, there are almost 80 open RFCs, some of which have not been discuss for half a year and some of which are a couple of years old now. I would like to see a systematic effort to either close or discuss RFCs at a steady rate, starting from the oldest RFCs. I think there's a tradeoff here. Reading though an RFC and its discussion thread takes a lot of time. If you're on the lang/libs team, there's a lot of pressure to really understand what's going on in every RFC so that you can make a good decision. For the full-time rust contributors, more RFC time == less implementation time. I think the core team would agree with the above, hence the Impl Period. The thing is, there are already enough accepted RFCs to take all of this year to implement, and probably more. I don't think it's necessarily a bad thing to create an RFC for something that won't be implemented right away. On the other hand, if some feature isn't going to be implemented for several years, why not wait on the design? Maybe a better idea will percolate up, maybe there's an interaction with some other new feature to consider. There's not much danger here, since it's easy to amend an RFC that hasn't been stabilized, but it does seem like a waste of time.
Dbus message passing (dbus-rs) is a nice alternative to straight up intergration for some applications. I've brought together Haskell code (XMonad), Python code (PySide, a qt library) and a Rust webserver + GraphQL (Rocket + Juniper) all together and it was a breeze to set up.
So [ReactiveX](http://reactivex.io/) for Rust? Neat! It does seem like a good way to manage all sorts of programs. I'd probably be using rx.NET in my day job if it had any sort of useful documentation.
Installing rust on a new system and rls-preview is broken today. Is there an easy way to find the most recent nightly with a working rls-preview?
Didn't this also happen to the folks behind iron? I feel like there should be some processes in place to fix this kind of thing.
I don't know, is it too much for new libraries to have new names? You can't just reuse names willy-nilly or you end up with the left-pad debacle.
In the current RFC for generators, what is the reason behind defining a new trait Generator instead of extending the usage of Iterator? In C# for example, they use the same interface (IEnumerable)), why not in Rust?
Because Generators can have different types for the Yield and Return cases. The motivation is for error handling and probably other stuff (unlike C# you can't use exceptions for this): // example from RFC struct CoroutineToFuture&lt;T&gt;(T); impl&lt;T: Coroutine&gt; Future for CoroutineToFuture { type Item = T::Item; type Error = T::Error; fn poll(&amp;mut self) -&gt; Poll&lt;T::Item, T::Error&gt; { match Coroutine::resume(&amp;mut self.0) { CoroutineStatus::Return(Ok(result)) =&gt; Ok(Async::Ready(result)), CoroutineStatus::Return(Err(e)) =&gt; Err(e), CoroutineStatus::Yield =&gt; Ok(Async::NotReady), } } } If `trait Generator : Iterator` then it would have to provide a default `next()` method which would have to convert errors to `None` or panic, neither of which is ideal. There should be methods to easily convert between Iterators and Generators, since they are similar, but they're not the same.
Hey all, I wrote this post to talk through some behavior I hadn't seen before implementing the FromStr trait. I'd love to be able to follow up this _how to deal with it_ post with some context about _why_ this is the case but at the moment I don't really know why. Thanks for any insight anyone is able to offer.
big :+1: to all of this from me
Thank you for the answer. I don't think that makes sense though, an Iterator can return (or yield) items from its next function that is wrapped in a Result if the iteration can fail, the generator could return a Result from its resume() function to signal error and stop yielding (or iterating) items too. Do you agree or am I missing something? You use Future in the example, I have not used the tokio library yet so the example does not tell me much but I can guess and it looks like the Future type might be the reason Iterator is not good enough?
To be clear on what this means, https://github.com/rust-lang/rfcs/blob/master/text/1946-intra-rustdoc-links.md Instead of writing blah blah [Bars](bars/struct.Bar.html) you can now write blah blah [Bars](bars::Bar) and it will work. This is not only more convenient, but fixes some long-standing bugs. For example, `HashMap` is defined in `std::collections::hash_map::HashMap`, but re-exported as `std::collections::HashMap`. Since the level of nesting changes, there's no way to manually write a link by hand that will resolve properly in both locations. This new notation can now properly handle this.
https://rust-lang-nursery.github.io/api-guidelines/
This code is a proof of concept and not a complete hack. It'll still work after the update. The windows update merely protects the OS from the hack by making it impossible/hard to address OS owned memory from userspace AFAIK.
Yes it is! It's up at https://github.com/ah-/anne-key. Runs on the Anne Pro (https://www.banggood.com/de/APP-Control-Anne-PRO-Blue-Red-Switch-RGB-Bluetooth-Mechanical-Gaming-Keyboard-p-1064055.html) which comes with two STM32s. Not pretty yet though, it's my first project using Rust and I'm still spending most time on figuring out all the hardware. Just figured out how to reliably send keystrokes over bluetooth yesterday :)
Yes, that's a decent start. It's a STM32L151, so it should have that mode, and I'm nowhere near actually needing it yet. If I don't get distracted with some other project I guess I'll end up wanting full shutdown at some point, as the keyboard doesn't even have a physical off switch but just goes into deep sleep. I think it goes into sleep after an wfi instruction, maybe that could just run as a really high priority task that then calls init again after returning from wfi?
This is a really big deal and I can't wait to start using it. Thanks to everyone who made this happen :)
If this gets implemented, I hope it does, how hard would it be to then recreate full coroutines? Could you do it by spawning a thread that just acts as a go-between a thread and a coroutine on a different thread?
You can just call `str::parse`, which will call `FromStr::from_str` for you, without you having to explicitly `use` any traits.
What I do is, instead of `Foo::from_str(string)`, I write `string.parse::&lt;Foo&gt;()`, which is a generic method of `&amp;str` that uses `FromStr`. Also the reason why you don't need to pull `Display` or `Iterator` into scope when you use them is because they are in the standard prelude of imports, also including `String`, `Vec`, etc... If you wanted to use any of the IO methods you'll find there that you have to pull `Read`/`Write` into scope. I'd say it's best just to go along with it, require people to pull `FromStr` into scope if they want to use it.
This is why Rust absolutely rules!
This is great, I wasn't aware of that approach but am really glad to be now. 
If we got default arguments, and they could be used for `Generator::resume`, would your opinion here change? I realize that default arguments are their own can of worms and here they'd be interacting with generic arguments as well but this is a question from a philosophical design point.
Glad to learn about this, exactly why I wrote this post! Thanks!
You can use include_bytes!() to compile with them as byte arrays
&gt; also name reuse didn't have much to do with the left-pad debacle afair The issue was that `left-pad`
Sweet! Is the "shortcut reference link" syntax from the RFC (e.g. just `[Bar]` by itself) implemented as well?
no problem! and yeah, to be clear, that won't be in rustdoc until tonight's build, so you can't do it literally right now.
It will work on docs.rs, and a stable compiler won't hate it, so.. exciting!
Not quite. A vector allocates a region of of memory once and only allocates again when it runs over capacity. Using boxes always allocs/deallocs per value.
If Rust async story will need resume with a value and future `Generator` RFC will include it I will not be against this feature. Hopefully users will not need to work with generators basic functionality directly that much (as today with iterators), so even if `resume(())` weirdness will stay it will not be seen that much.
This kind of annoyance (importing a commonly needed trait or type) is why I wrote the [std_prelude](https://crates.io/crates/std_prelude) crate. Just `use std_prelude::*` at the top of your modules and you won't have these kind of annoyances anymore!
You could probably have a stable API once [non-exhaustive enums](https://github.com/rust-lang/rust/issues/44109) become stable, no?
Reqwest is nice, but it lacks some flexibility. I had trouble trying to disable tls for my get requests
Wohoo this is so awesome!
Nope, I haven’t yet! What’s that? I’ll Google it!
https://github.com/frankmcsherry/timely-dataflow It's.. not clear for me either :). But both that and your crate remind me a bit of .NET's [TPL Dataflow](https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/walkthrough-creating-a-dataflow-pipeline).
In the case of a user-defined enum, yes, the compiler wouldn't allow you move the value and then reference its previous owner. At that point a beginner may try to derive `Copy` on the enum, and at that point, it is indeed more obvious that the enum is passed-by-value than in most languages. But for any imported/built-in type which implements `Copy`, I believe the problem would appear in Rust just the same as C#. Consider: class MyClass { public int IntVal; public static void Change(int value) { value = 5; } public static void Main() { var myClass = new MyClass { IntVal = 4 }; MyClass.Change(myClass.IntVal); } } vs: struct MyStruct { int_val: i32 } fn change(mut val: i32) { val = 5; } fn main() { let mut my_struct = MyStruct { int_val: 4 }; change(my_struct.int_val); } On the other hand, it is true that rustc will make more noise about unused variables in this case, which may clue the developer into the problem. But such warnings are hardly unique to Rust.
Awesome, awesome, awesome!
I meant, `Vec` also boxes.
Does it resolve `use`s and `extern crate`s?
 After using it more heavily, I've ended up not using it. I've just gone with make instead. I did really like your cargo make however. So I thought I'd leave some feedback on why. * It's slow. Like really slow. The time between hitting enter and it actually getting to the start of your task is reaaaaaallly long. Meanwhile regular make is instant. * It's slow to end. * It's quite verbose. I couldn't find a way of saying "give me my task info, but not everything else". * The `git config --list` stuff I didn't like. Meant I had 4 seconds of git errors every time it started (on top of the other slowness). This is when I haven't intended to have it integrate with git. * It's a bit over engineered tbh. In terms of providing so many workflows and integrations. I guess that's cool if you have one in mind, but if you just want a task runner and build up then it seems really bad. * There doesn't seem to be a way of saying *"this task is workspace"*. Instead you have to provide that on the command line when running the task. So to solve the run issue I had above it's *"cargo make run-fortress --no-workspace". I might as well just run it with `cargo run`. * I really liked the fact you can build a task, and have it automatically work on all workspaces. That's really cool. But it's just far too slow (this is partly cargo commands being slow though). I think the major issues were: * Too much by default. * Workspace specific tasks. * Too slow. I'd also love it if when I ran `cargo make` it would search for a `Makefile.toml` in the parent directories. That way I can run it from within the `src` folder.
[I believe they did get in contact.](https://github.com/ghmlee/rust-request/issues/7)
&gt; Thanks for your feedback! Hmm I agree, there are a lot of job platforms, I just had an idea to replace rustjobs.rs with something that's actually developed in a way that takes the community into account. Jobs were advertised though, just not on rustjobs.rs ;). What would that be? Job search is usually a very private _and_ very competitive thing. For everything else, there is Linkedin and such.
If you change the version no build should be broken though, no?
That works if you only have to add a variant but if you are extending an existing variant by parameters it doesn't work. And sometimes that is neccessary.
&gt; The issue was that the left-pad package was deleted which broke people's builds. Removing and replacing request would have similar effect. I'm not going to address the social side of this issue, but from a technical side... if anything, the replacement would simply be published with a higher version number. Anyone (which... there *is* no one) depending on the older version of "requests" would still be able to compile their code just fine.
[removed]
I think having an `0.x` libsyntax on crates.io which builds on stable will be a great improvement over the current situation. * It has to be `0.x` because the syntax itself is evolving. * However, you can totally use `0.x` crates from crates.io to build useful stuff, and it will work perfectly with all the code which does not actually use the new language features. * My understanding is that the big amount of breakage associated with syntex_syntax and similar solutions is not due to the fact that the syntax itself is changing very often, but just because libsyntax exposes a lot of compiler's internals in the API and it is those internals which are always in flux. 
I might be pedantic here, but no, only Box boxes. Boxing not being a sharply defined term, this is obviously something to bikeshed about. Boxing usually refers to moving _a single value_ out to the heap and returning a _wrapper_ that refers to the heap. The wrapper is intended to behave as closely to the original as possible. Also, what can be _boxed_ can be _unboxed_, returning the original. Additionally, in Rust, this means that every time you _box_, memory is allocated on the heap and the value moved to that location. This also means a box cannot exist without a value. All this doesn't work with a vector. You can move things in and out of a vector, but unwrapping the vector isn't terribly meaningful. It can also exist with no values. It is a collection, not a box. They both heap allocate (in very different patterns), but a vector does _not_ box.
&gt; Iterator can return (or yield) items from its next function that is wrapped in a Result if the iteration can fail, the generator could return a Result from its resume() function too. Do you agree or am I missing something? That would be cumbersome to use (double unwrap), and it doesn't actually have the same meaning since `Some(Err(_))` doesn't end the iterator. The return type is also useful for things other than error handling like a long-running operation: let compute = || { let mut results = vec![]; for x in 0..100 { results.push(do_something_expensive(x)); yield x; // can track progress } return results.sum(); } // Using for-loop integration from https://internals.rust-lang.org/t/pre-rfc-generator-integration-with-for-loops/6625 let result = for progress in compute { progressbar.update(progress); } println!("Got result: {}", result); Something like that could be shoehorned into the existing Iterator trait, but it would be much more cumbersome since the iterator trait is not designed for returning a final value. I think the key takeaway is that a generator is just an easy way to instruct the compiler to create a state machine. By allowing generators to have a specific return value, you can use them for more than just iterators: Rust | C# ---|--- GeneratorState&lt;T, ()&gt;| IEnumerable&lt;T&gt; GeneratorState&lt;(), T&gt;| async T function() GeneratorState&lt;T, U&gt; | Rx.NET Observable &gt; You use Future in the example ... It was the only relevant code example I found in the RFC. I brought it up just as an example of using `CoroutineStatus::Return` for error handling.
I think the interactions with for loops is one of the things that should be involved in the overall design of the generators, and not just an afterthought. This RFC formally includes it to the discussion, and I welcome it.
Perfect, thanks.
do Rust macros prove useful in rolling bindings? i imagine they would
That...doesn't look like the text you're replying to. ;)
Oups I forgot about kind of "conversion", the Trait conversions, you are right and the `Into` Trait doesn't seems to handle that.
P.S. unless you're going for 0 dependencies it's better to use the requests Python package then urllib