I had to scroll quite a distance to find this. There’s clearly a lot of inertia and expertise behind their established C systems, and it makes no sense (technical or financial) to suddenly start pushing Rust (or anything else). Not to mention the fact that coming to /r/rust and asking “hi guys, why is rust better than c ?” is basically saying “hi echochamber, please validate my pre-existing opinions, thanks”
I'm looking at the API for the `specs` library, and the way components are registered and retrieved confuses me. It seems almost equivalent to a dictionary where the type is they key. Am I getting this right, and how is that possible?
OK. What's the state of things when using a `.pyd` extension and the `extension-module` feature?
Oh, I always use `Result`, but I don't trust third-party package authors to accurately judge when a `panic!`-producing line is *truly* unreachable and I'd rather not NIH every non-`std` line of code in my projects.
I see, makes sense. Quick search yielded this: [https://github.com/libtom/libtomcrypt](https://github.com/libtom/libtomcrypt) You'd have to write (or generate?) bindings to this C library, but it looks like it's high quality and appropriate for your use case.
That's a **lovely** minimal example! Nice one and TY very much :D
C++ *can* do it, but Rust *always does* it and while you *can* shoot yourself in the foot, you have to really work at it.
\- Automatic documentation, with documentation for every package on [crates.io](https://crates.io) hosted on [docs.rs](https://docs.rs) \- Lifetimes mean that you can correctly share borrowed data with \`&amp;\`-references without worrying about the runtime overhead of \`shared\_ptr\` or the possibility of dangling pointers that you get with C++'s references \- Move semantics by default with explicit cloning means that you never need to worry about hidden runtime cost when passing values to functions \- Consistent use of types throughout the whole ecosystem avoids C++'s "50 different languages bolted together" problem, and combined with automatic documentation this means that diving into a new project is relatively painless \- A proper ad-hoc polymorphism system with explicit trait bounds means that it's usually obvious how to use a generic function and using it correctly is enforced at compile time. This can mean you can avoid runtime checks without worrying about possible unsafety, since the checks are expressed in the type system. \- Trait bounds plus excellent error messages means that when a compile-time error happens it's more often helpful than frustrating. \- No life-before-main makes the mental model of execution far simpler. &amp;#x200B; I think the best of Rust's benefits from the perspective of a C++ programmer come down to the fact that large and/or complex programs don't have to sacrifice speed - you can write maintainable code that is \_also\_ as fast as the equivalent hand-rolled C, instead of C++ where as a project's size increases you often have to sacrifice the fastest implementation in favour of an implementation that can be used correctly from another team without causing undefined or inconsistent behaviour. \`shared\_ptr\` vs \`&amp;\`/\`&amp;mut\` is a good example, but so is the trait system and so is the simpler move-vs-clone distinction. Writing fast, maintainable Rust code is the same as writing idiomatic Rust code.
you can also use `ncdu` if you only have access (or want use) the cli .
I tried this: ```rust #![feature(async_await)] use std::future::Future; async fn foo(n: usize) { if n &gt; 0 { let foo: Box&lt;dyn Future&lt;Output = ()&gt; + Unpin&gt; = Box::new(foo(n - 1)); foo.await; } } ``` But that still leads to a cycle, unfortunately, just a different one.
You may want to try r/playrust, or actually r/playrustservers to advertise new servers.
If you're a TUI kind of guy then ncdu is a nice tool.
Yes, that's how it works. One of the crates that implement such thing is [`anymap`](https://crates.io/crates/anymap) (although I'm not sure if specs actually use this under the hood). You can implement such data structure with safe code by using `TypeId`, `Box&lt;dyn Any&gt;`, and a simple `HashMap` ([here's a minimal example](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=448ca379c7988ef84e2e9a6a8cf26cf8)). `anymap` crate uses some unsafe code to improve performance and provide some extra features.
Everything works the same. [gist](https://gist.github.com/rokoatcoffee/b117d13d05f1118adb744f0d4b5d3813) I've changed the gist to add benchmarks and get the output of the python and rust functions. Install requirements to your venv and run build_win.sh my project tree now looks like this: . ├── build_win.sh ├── Cargo.toml ├── pi.py ├── requirements.txt ├── venv └── src └── lib.rs
&gt; But it isn't always possible, which leads to code suddenly not compiling anymore when you make a seemingly innocent change. For example by introducing a variable with a `Drop` implementation.
Thanks for posting this. Had to scroll down way too much to find this down-to-earth response.
&gt; "well-formed C++ can do the same things with smart-pointers, etc.". Well-formed assembly can do that too, but it's still a chore to manually ensure that it is actually well-formed.
You may be interested in https://gist.github.com/edmundsmith/855fcf0cb35dd467c29a9350481f0ecf which is a really fun dive in creating a Monad in Rust. The author defines two traits, `Plug` and `Unplug`, and a placeholder struct, `forall_t`, which are essentially, which I will adapt: struct ForAll; trait Unplug { type HigherKinded; type Parameter; } trait Plug&lt;A&gt; { type Result; } And instead of `ForAll`, I'll use `!` (the never type), for ease, although on stable you'd need `ForAll` with a bunch of traits implemented for it. Which you can implement like such: impl&lt;A&gt; Unplug for Vec&lt;A&gt; { type HigherKinded = Vec&lt;!&gt;; type Parameter = A; } impl&lt;A, B&gt; Plug&lt;A&gt; for Vec&lt;B&gt; { type Result = Vec&lt;A&gt;; } With those little bricks, you can now go from type to type constructor and back to type again. For example, `&lt;Vec&lt;String&gt; as Plug&lt;i32&gt;&gt;::Result` is `Vec&lt;i32&gt;`. I'll leave you to read the rest of the article; at the end the author defines `Functor`, `Application` and `Monad` based on the `Plug` and `Unplug` traits.
Thank you, that's really cool! A good concise example as well, and pointers to useful resources, just what I was looking for.
 async fn foo(n: usize) { if n &gt; 0 { let foo: Pin&lt;Box&lt;dyn Future&lt;Output=()&gt;&gt;&gt; = Box::pin(foo(n - 1)); foo.await; } } Should work - although it's not very convenient, TBH.
You could ask him to create a hello world package, which includes all static analysis tools which are required to come clos to what rust offers regarding safety. (+doxygen +(c)make/meson) When he is done ask him to apply it to any c++ library with 1k+ lines of code. &amp;#x200B; Valid C++ Code is everything starting from C89, of which you shouldn't use 99% of, but people do.
After skimming it, I... don't see that much reasoning in that pull request? The most I see is "it's a pain to type" in the linked internals discussion. It looks like most people were "why not, it's a better name". I'd argue that inclusion into the standard library should require a firm "why yes" argument instead. There are a LOT of things that could be included with a similar "why not" stance.
I'm not sure but the compiler might be a tad too pressimistic in rejecting your code. I worked around it by wrapping an async block into a normal function: #![feature(async_await)] use std::pin::Pin; use std::future::Future; fn foo(n: usize) -&gt; Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt;&gt;&gt; { Box::pin(async move { if n &gt; 0 { foo(n - 1).await } }) }
&gt; Hygienic macros There is some hygiene with C++ template macros. It's better to compare C++ template macros with Rust macros than with Rust generics, despite the more similar syntax. In Rust generics basically all checking happens at declaration time while in C++ generics it happens during monomorphization. In Rust macros, checking happens similarly at expansion time. In Rust macros, you have similarly rough control over macro parameters like you have in C++ templates: typename vs const in C++, expr vs ty in Rust. There is no duck typing in Rust generics, there is in C++ template macros. Then the entire "Rust doesn't have const generics unlike C++" becomes moot because Rust macros *do* support values :).
I would guess because you can activate different feature flags and make other modifications, such as overriding a dependency's dependencies.
You can do a quick audit by grepping for unwrap, expect, panic, unreachable, and see if any of those look reachable. Obv this isn't fully watertight but it does give you confidence. TBH I tend to look for and use either packages that are made by people I trust, are small enough to audit, or are heavily used.
There was a thread on r/cpp, not so long ago, where the author asked what the advantages of C++ were over Rust. [My answer](https://www.reddit.com/r/cpp/comments/c5bnme/what_are_the_advantages_of_c_over_rust/es48mn8) focused mostly on the language; not libraries, tooling, etc... and I must admit the list ended up shorter than I would have thought. It essentially boiled down to templates being more powerful than generics **for now**. As a summary: - Non Type Template Parameters (aka Const Generics): `template &lt;std::size_t M, std::size_t N&gt; class Matrix;` are not implemented yet in Rust, and the first implementation will be rather limited compared to what C++ already offers. - Template Template Parameters (close to Generic Associated Types): a new article featuring the `Unplug` and `Plug` traits to implement a `Monad` trait showed that there are work-arounds, still native support would be more ergonomic. - Specialization: C++ allows specializing both structs and their methods. There is a long partial implementation of specialization in Rust which is limited to methods (unclear if structs are needed, when we have traits) and known to have issues. - Variadics: Rust has built-in tuples, which means the lack of variadic templates is not as keenly felt. Beyond that, there are no plans. There have been a variety of *proposals*, none got approved, and I would personally recommend a wait and see approach with so much of the language still in flux with regard to generics. This is, all in all, a very short list. And while the first item (const generics) holds me back from attempting to introduce Rust at my work-place (because we use them extensively in C++), I have hope the minimum implementation will be available before the end of the year. --- By comparison, Rust offers: - Safety, therefore speed: no defensive copying any longer, go full throttle! - Clarity, by enforcing clean code: the flow of data tends to be simpler, no tangles of callbacks, bizarre observer pattern with side effects, and no mutating that list you're iterating over leading to weird results. - Productivity, thanks to tooling: cargo alone is a godsend, integrated unit-tests to avoid the horrendous compile-times of GTest (very useful otherwise but...), superb benchmarking abilities, the only missing point is IDE support, but let's be honest C++ is far from stellar there anyway as IDEs choke on templates and macros. Personally I'll wait for const generics to start pitching, as they are so useful for high-performance code, however if you don't really need them the cost/benefits analysis should be fairly clear.
Debugging ain't free!
&gt; I believe a bunch of expert C++ devs already do that I'll go on a limb and say NO. I am fairly proficient at C++, and I've noticed a pattern: the more proficient I have become, the harder the problems I have been asked to solve. Can I write a bug-free doubly-linked list implementation with not a single lifetime bug? With good probability yes, on the first try, and with valgrind and unit-tests, definitely. It's been a long while since I was asked to write such a trivial thing, though (Uni?). Nowadays, I write multi-threaded frameworks (mostly lock-free/wait-free) to power low-latency applications. There's a lot to hold in your head: packing memory tightly, avoiding contention, ensuring fairness/sequences, ensuring low algorithmic complexity, ensuring clarity ... and from time to time I'll slip up on a lifetime. Not enough brainpower, sorry :/
It is rare, and can be spotted. I do wish compilers were warning about it though; managed to lose an hour last week chasing down an empty string only to realize my refactoring had switch two data-members, and therefore the initializers of said data-members, leaving me with `std::move` being called for the first data-member initialization rather than the second (which thus was getting an empty string). :/
There have been quite a few proposals for variadics, but I think the focus for now is on: - Const Generics. - Generic Associated Types. Which are bigger roadblocks than variadics in general. (The fact that Rust has built-in support for `std::tuple`, `std::function` and `std::variant` drastically reduces the pressure of full-blown variadics)
There's very little that Rust cannot do with regard to template meta-programming; albeit with a lot of elbow grease. The key point is that Rust Generics are Turing complete, or close enough they might as well be. For example, const generics can be emulated by passing array types or by encoding constants as types and operating over them by traits. Similarly, a lot of variadic code can be emulated by passing tuples and them hacking away at them using custom traits. And of course, HKT can be emulated using the Plug/Unplug combination of traits. Not being first class means that support is clunky: poor ergonomics, poor error messages and long compile times. But then again, given how clunky C++ template metaprogramming is, you won't notice much of a difference ;)
I like GDMap for this on Linux.
Microsoft had a similar conclusion. Something like 70% of their security vulnerabilities were of the Memory Safety category :/
&gt; Of course, that means it'll be ten years before anyone gets to use it in production... Depends; my company started using C++17 in 2018, I think. If compiler support is good, we'll get C++20 in either 2020 or 2021 :) For now I'm more worried about the lack of support for modules in current toolchains; this is for me the single biggest feature of C++20, and I'd really like to take advantage of it as soon as possible, even in the absence of compile-time benefits (just for my own sanity).
Honestly, the "features" of Rust I lack the most when using C++ are Cargo and Modules. They may seem simple, but day-to-day the clunky build system and those headers are perhaps the biggest impediment to my productivity. I do curse about the lack of safety, or the other myriads C++ surprising semantics, every so often; but there are good days in this regard, whereas CMake and Headers are an everyday papercut.
Thank you very much for the wake-up call. I wish I didn't have to scroll so much to reach it. --- With that said, I am not so sure about *screwing your hiring pool*. I would expect a C++ developer to be able to adapt to Rust relatively easily; the concepts of ownership and borrowing are mostly known to C++ developers, if only because doing otherwise means crashing your software, and putting a name and formal semantics (rather than gut feelings) on them should be a relief. Of course, you'd need someone who knows both C++ *and* Rust relatively well to help guide the transition, someone who would field the questions of the type "in C++, I'd have done that, how should I do it in Rust?"...
&gt; For me Rust doesn't yet satisfy scrutiny for labor pool I am not *that* concerned about labor pool, especially not after having taught (real) C++ to junior developers. If anything, I would actually argue that Rust increases your hiring pool: attempts at hiring C++ developers are met with a concerning silence in many parts of the world, as a number of developers just don't want to bother, or fear they are not up to the task. On the contrary, any C or C++ developer can be quickly up to speed in Rust, and developers coming from other languages should find reassuring that they won't spend their time squinting at incomprehensible memory dumps. This is all predicated on having a core of people who do know Rust well within the company, though, whether intrinsically, or by bringing down a consultant or two to bootstrap the effort.
I'm using zola for my [little blog](https://cetra3.github.io/) and it's been great so far! I'd like to be able to use netlify cms but they're still not supporting the new [toml format](https://github.com/netlify/netlify-cms/issues/2144)
&gt; In my experience the biggest productivity killer in C++ is compile times. I'd be very reluctant to switch to a language that (at least currently) apparently has even worse compile times than C++. My experience has been that it's on par... which is hardly an argument *in favor* of Rust :/ &gt; While Rust is getting const generics soon, which will help, it's still a long way away from getting variadic templates, which are vital for compile-time-sized tensors of arbitrary dimensionality. How arbitrary? I would expect that the functionality could be recreated by implementing a handful of traits on tuples using macros, so long as the dimensionality is less than 6 or 12 for example. Which would be horrendous if you actually to write it yourself, of course, however so is writing Eigen, so as long as said nastiness is encapsulated in the library I would expect things to be fine, no. &gt; Rigid polymorphism. I... fail to see the problem, actually. The way I see it, you either have: - A template using `T::foo(int) -&gt; int`, with N of types having a `T::foo(int) -&gt; int` method. - A trait declaring `fn foo(&amp;self, i32) -&gt; i32`, with N implementations of said trait, one for each of the N types. In either case, the exact same number of implementations is written. Am I missing anything?
I commented on that issue, TOML 0.5 has been released for a year or so already
I appreciate the perspective, and the list of frameworks! I was looking for an example I could actually browse the source of, since I am not really sure how to design a real app using this framework.
Does anyone have an idea how to convert a webp file to a png in Rust?
So you need to assign the c string to a name too?
Ah i can work with that! We found a solution that we will try out first: we will precompute all the keys, compile them into the binary and use rusts ring package for de/encryption If that doesn’t work we will write some bindings for libTomCrypt Thanks !
Great, happy to help! Let us know how it goes!
I am having problems understanding why `Condvar`s don't work like I expect them to do. A slightly modified version of the example given in the std docs is [this](), I only added a blocking operation *after* the `cvar.notify_one()` call and dirty comments. I expected everything to work just like before, because the waiter has been notified, and no one should care about that thread anymore. If I wanted to wait until the thread is finished, I could just use `.join()`. But it turns out that the waiter never wakes up and the program is killed. So, why the hell does this situation occur?
But tokio still has not yet migrated to std::future: https://github.com/tokio-rs/tokio/issues/1201 . How this is possible, I thought that hyper works on the top of tokio?
Tokio is not released with std::future, but the project is in process of migration on the master branch. That is why hyper references it through git, instead of crates version [https://github.com/hyperium/hyper/blob/master/Cargo.toml#L41](https://github.com/hyperium/hyper/blob/master/Cargo.toml#L41)
&gt;ysjet You have a few invalidated assumptions here, like programming errors are cheap. A huge percentage of development budget goes to time, tools, and processes that try to achieve correctness. (I am routinely seeing 240eur/hr people trying to fix memory management errors for \*days\*.) Now you are offered a language that was formally proven to guarantee certain safeties, so you could get rid of most of that infrastructure, and you don't see the economic merit in that? A language with better abstractions (ie shorter development), and you don't see the economic merit in that? A language that is consistently the most loved, ie people are willing to work with it for less money (I know I am), and again, it's not economically feasible? Sorry for all this blatant evangelism, but don't you think Facebook considered business factors when they chose a language to implement their \*money\*?
A couple of weeks ago we at Fastmail released our new marketing website (and new branding, including the lowercase m in the name), and it’s generated with Zola. This replaced a custom arrangement with a bunch of Perl using Markdown.pl, Template::Toolkit and the likes. The help pages haven’t been migrated to Zola yet, but will be in the not-distant future; and that’s when I expect us to actively get a lot more practical value out of it than our previous arrangement, due to it managing the content architecture, which is decidedly ad-hoc at present. Even during the development of the website, Zola was praised among those controlling the content, because it being one binary readily downloaded and used made it easy to get going locally, and we were able to set up a CI job to deploy it to a common location whenever anyone pushed changes, so that changes could be made very quickly, and user testing prospered. End result, all who worked on the project love Zola and the arrangement we got going with it.
Your face detection posts are really cool! Did I miss them being posted on this subreddit?
&gt; that know Rust and modern C++ Been programming in Rust for 4 years, been programming in modern C++ (C++&gt;11, C++17 now) for 8 years. Rust is a better tool than C++ for all the tasks I've ever used C++ for. It is a time saver: * I spend almost no time debugging segfaults in Rust, and when I do, these are trivial to find (just follow `unsafe`). This is due to "memory safety", "data-race safety", "safe abstractions over unsafe code", proper backtraces, and many other things. * My Rust code has way less tests than my C++ code, while having less errors. No need to run ASan/TSan/MSan/Valgrind/... which saves a lot of testing time, the compiler automatically inserts bound checks, and other checks, that save you from writing `assert`s all over the place in C++ (e.g. `std::array&lt;T, N&gt;::operator[]` is not checked by default or in debug builds.., you need to go out of your way to change that). * Refactoring without introducing errors is trivial in Rust, and super hard in C++. In Rust you make the change, and follow the compiler's advice, and then your code compiles _and_ is correct. In C++, introducing subtle errors is super easy. Many Rust language features conspire and cooperate to achieve this, ADTs, pattern matching, destructuring, traits, auto traits, ... C++ doesn't have any of the features required for this. * Better meta-programming: meta-programming in Rust is just so much simpler, easier, intuitive and powerful than in C++. Writing code that parses Rust code and generates Rust code is a breeze, the tools are great, the error messages are great, etc. In C++, parsing C++ code is a nightmare, so you are left to template meta-programming, which is horrible, requires learning a lot of ad-hoc tricks, generates horrible compiler errors, etc.
Thanks! I posted them here and they ended up in the "This week in rust" threads as well. It was a few months ago now
Zola is pretty awesome. It's not as powerful or flexible as something like Gridsome, but I like being able to avoid Node for simpler websites. I'm currently building a website with Zola for a Rust project and I'm starting to get the hang of it. I really wish there were some sort of tutorial for building a Zola website. I've read the Zola and Tera documentation, plus the source code of a few Zola themes, and it still feels like I don't quite understand everything. A lot of the use very different ways of piecing everything together. It's hard to transfer the stuff I read in documentations into a working website with a good structure. I'll probably try to write a simple tutorial once I'm done, if I think I understand everything by then.
Have you tried the [examples folder on Github](https://github.com/David-OConnor/seed/tree/master/examples)?
🤦‍♂️ thanks.
\- Reflection! Won't be in cpp until 2023. at least, \- match statement, \- traits. Cpp will get compile time concepts, but runtime concepts will have to wait, \- cargo, which just works. When taking a cpp lib you never know what build system it uses underneath, \- tests inside source code. There are macro solutions for this in cpp, but these can go wrong in many ways over.
...and probably soon `todo` as a synonym for `unreachable`. As far as audits of that sort go, I consider that too slapdash to satisfy. I've been meaning to try [rustig](https://github.com/Technolution/rustig) to complement them.
One potential use for it I can see is as a thing to help out IDE development. Like, automatically integrating it with your workflow whenever you write todo!
I don't have a modern version of Windows set up right here, right now, so I may need a day or two to fit in pulling down one of the modern.ie [testing VMs](https://developer.microsoft.com/en-us/microsoft-edge/tools/vms/) and setting up Rust in it.
Calling `wait` on a thread is blocking until the waited thread is complete.
That doesn't really work in the general case. It is not reasonable to return a `Result` when the `Err` alternative is only possible when your routine has a bug, that is, an invariant failure. What would the consumer do about it? The program is now in an undefined state and continued execution is either unsafe or impossible.
Damn, well, I'm glad I've seen them now. I want to write a Rust + Tensorflow application to run on a drone for detecting ocean trash.
Such things can still be encoded to something that can key a cache, no?
They *can*, but I think the question is if it's worth it. Sure, for commonly re-used crates you lessen the used storage, hooray. But for most rare cases, the cache lives on forever because it's harder to manually clean stuff when you don't know where it was created.
As /u/K900_ says, but to elaborate slightly:There are four kinds of behaviors in C and C++: * Well-defined * Implementation-defined * Unspecified * Undefined Well defined is the most straightforward; this means behavior that the standard specifies. Here's some language for the others: &gt; Certain aspects and operations of the abstract machine are described in this International Standard as **implementation-defined** (for example, sizeof(int)). These constitute the parameters of the abstract machine. Each implementation shall include documentation describing its characteristics and behavior in these respects. &amp;#x200B; &gt;Certain other aspects and operations of the abstract machine are described in this International Standard as **unspecified** (for example, order of evaluation of arguments to a function). Where possible, this International Standard defines a set of allowable behaviors. These define the nondeterministic aspects of the abstract machine. &amp;#x200B; &gt;Certain other operations are described in this International Standard as **undefined** (for example, the effect of dereferencing the null pointer). \[ *Note*: **this International Standard imposes no requirements on the behavior of programs that contain undefined behavior.** —*end note* \] &amp;#x200B; In short, "implementation defined" means "hey, each implementation may have different behavior, and needs to document it." "Unspecified" means "implementations must do one of the things in this set of behaviors." "Undefined" means "this program is nonsense and so anything can happen." To claim Rust is "100% undefined behavior" is an attempt to say "there's no standard, so therefore, anything can happen, so everything is undefined." That's just not possible, though. To suggest that everything is UB would be to suggest that there's no possible way to know what's going to happen in a given situation. If you really want to fit Rust into this framework, it would be "everything is implementation defined"; that is, there is one implementation, and it defines the language itself. It has a ton of documented behavior. But really, I think all of these word games are a red herring entirely; even "implementation defined" behavior only makes sense in the context of a specification, after all, it's the term of art in one! So, the right way to describe Rust here is "does not have a specification." &amp;#x200B; I hope that helps.
this. rust causes far more harm to the developer community than any sort of half-baked "help" it provides
Specifically, it the call to \`lock\` on the \`Mutex\` will create a scoped guard that will release the lock only once it goes out of scope. In your case, the scope is the full closure inside the \`thread::spawn\`, and that means the thread will go to sleep with the lock still held. The solution is to create a smaller scope for the lock by using an anonymous block, for example. Like so: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=f0d1de1ea8e9234b8a8443550bbb0fb0
That's `&amp;str`, the type of just `"hello"`. Sometimes, you need something else, though. In this case, you don't need a `&amp;str`, you need a `CStr`, because Rust's representation of strings isn't the same as C's (they're not null terminated.)
(Commenting so I remember to check back later for answers to this, as I'm interested as well. Is there a way to follow a comment (thread) on Reddit?)
It still is missing some quickstart guide, please write a post in https://zola.discourse.group/ and we can try to improve it!
The two big ones are: 1) non-type parameters (integer values, booleans, and in C++, static addresses, member offset addresses, and enums (which are just discreet integers in C++) and 2) variadic templates, including parameter pack expansion, which allows templates to be defined against a variable list of types, and provides the tools for recursion, splitting, and (conditional) pattern matching on that list of types. There is a third feature which is both powerful and a huge can of worms: SFINAE. Essentially, specializations can be provided for a template that cannot be used with a specific instantiating type, and that is not a problem unless something that is attempted with that type cannot find any valid specialization. This is simplified with the standard library helper enable_if&lt;*boolean_statement*, ...&gt;.
&gt;Am I wrong for being so **excited** about Rust and wanting to phase C++ out of my development toolbox? The excitement hasn't stopped yet!! Woo!!
Tail call optimization would be able to help in this case
&gt;Can I write a bug-free doubly-linked list implementation with not a single lifetime bug? Imagine if existed a programming language based around bug-free linked lists!!
WARNING at: a subthread down below **PCJ hivemind caught in the local minima of the jerk attractor, cannot escape unjerk trap.** Boring unjerk will be deleted or locked for all to see.
I think there is some small difference in meaning between the (now 4) macros that technically do the same thing: * `todo!()` means the author *definitely* intends to fill in an implementation later. * `unimplemented!()` only means that it's unimplemented. *Maybe* the author intends to fill in an implementation later, maybe not. * `unreachable!()` means the author thinks that that bit of code should be impossible to reach. * `panic!()` usually means that the caller did something wrong. Basically, `unimplemented!()` is vague because it could have the meaning of `todo!()` or it could have the meaning of `panic!()` (that bit of code will never be implemented because the user did something wrong). I've never used it in the latter sense, but it doesn't seem unreasonable that other people might have. `todo!()` is less ambiguous in this regard.
The [image](https://docs.rs/image/0.21.2/image/) crate supports both WebP and PNG formats, so you can just read the image using [`open`](https://docs.rs/image/0.21.2/image/fn.open.html) (if it's a file with an appropriate extension) or [`load_from_memory_with_format`](https://docs.rs/image/0.21.2/image/fn.load_from_memory_with_format.html) if you have bytes, then save the result as a PNG using [`save`](https://docs.rs/image/0.21.2/image/enum.DynamicImage.html#method.save) (if writing to disk) or [`write_to`](https://docs.rs/image/0.21.2/image/enum.DynamicImage.html#method.write_to) (otherwise).
thx, I already took a look at it. The problem is that it just reads a webp in black and white. when I try to open it and save it to a png it's just black and white
&gt; "Rust doesn't offer anything C++ doesn't already have" &amp;#x200B; Whoever affirms this has not learn Rust or is in denial. &amp;#x200B; \`\`\` struct MonType { int mon\_champs = 0; }; std::unique\_ptr&lt;MonType&gt; pt = std::make\_unique&lt;int&gt;(); // bla bla bla ma\_super\_fonction(std::move(pt), pt-&gt;mon\_champs); \`\`\` This compile in C++ and crashed. It gave me a headache for 3 days tracking it down. I might not be using latest modern C++ feature there, but I do use smart pointer and move semantic.
Try r/playrust
If it's a git repo I frequently use `git clean -dffx`. Of course that's super destructive of anything you haven't checked in, so I usually check `git status` first.
This is something I find concerning, as the types inferred for async-await are complex. Is this a MVP issue, or a fundamental limitation of the approach? &amp;#x200B; It sounds like there would need to be some kind of case where the async state machine could go backwards instead of creating infinitely many steps. &amp;#x200B; i.e. step 4 method call step 5 if condition, go to step 4, otherwise go to step 6 &amp;#x200B; I have no idea of the complexity of implementing something like that, though.
You could make your blog responsive, to make it easier to read on phones! Good job btw!
Since we went there... Rust is more like a self-driving Tesla.
Note that RSA PKCS#1v1.5 encryption padding is not secure.
Shoot. I'm just here taking that for granted haha. When you stop and think of everything that just comes out of the box with Rust, it is rather amazing, actually.
Good approach!
Interesting, I have almost the same code in one of my projects. I solved it like this. Which would be more efficient? #![feature(async_await)] use std::future::Future; use futures::future::FutureExt; fn foo(n: usize) -&gt; impl Future&lt;Output = ()&gt; + Send { async move { if n &gt; 0 { foo(n-1).boxed().await } } } (I needed to add the \`Send\` bound because \`boxed()\` also has it in its signature).
It can and does. The target directory is smart enough not to use existing incompatible versions. So you can set the \`CARGO\_TARGET\_DIR\` env and have all projects share one cache. as /u/upsuper described. The main reason this is not the default is that \`cargo clean\` is the only existing way to clean it out. Witch just dells everything. So /u/jD91mZM2 is correct the default is not going to change until a better GC is crated and proved to work well. The closest we have is [cargo-sweep](https://github.com/holmgr/cargo-sweep) but it needs more work. Help is always appreciated!
Thanks a lot I will check this repo later. Hope it won’t be confusing for me
To add to that, normal recursive function calls work because each thread has a decent amount of space allocated in advance for it's callstack. (Running out of this space with too many recursive calls leads to a stack overflow crash.) However, this big allocation is one of the reasons that spawning new threads is expensive. One of the design goals of async IO is specifically to _avoid_ over-allocating (or dynamically allocating) a bunch of memory for each task, so that you can have thousands of tasks running efficiently at the same time.
Yeah I agree. I think I implied much the same. Especially with skill mix of my team, I'd rather start a rust project than a C++ one.
I'm driving down a dark road in the woods at night following every rule. Another car is driving the opposite direction following every rule. A deer jumps out from the trees into the road. I react immediately but my car can't stop in time. I hit the deer with the front-right corner of my car. The back-left corner of my car spins out into oncoming traffic and hits the other car.
I didn't look at the code, but you're missing Cargo.toml.
You are right, but it's not that important anyway, since my project doesn't have any dependencies at this point (Which will change (TLS))
It sounds like this is a [known issue](https://github.com/image-rs/image/issues/939). You might have some luck with [a crate wrapping libwepb](https://crates.io/crates/libwebp-sys), but now you're wandering into the realms of `unsafe` code.
The solution came to me overnight, using `macro_rules!`. I've posted it as an edit to the original text. The key is to put arbitrary extra arguments at the end of the `indices` macro, so that they can just be passed through unchanged using a `$($rest:tt)*` pattern. Then I can use a little bit of recursion to handle multiple sets of indices. Still I need a pattern for each different number of args, but that is only once in the code now, because I can reuse the same `indices` macro everywhere.
It's very important. Anyone looking at your project and wanting to play with it will just say "huh?" and move on.
I'm in the process of writing a procedural macro right now. In the case where there is an error and the procedural macro fails you're supposed to panic. Is there any information on how to customize the error that is reported to the user. I want to be able to highlight the areas that caused the panic but it's not immediately clear how to do that. I'm targeting stable so I'm hoping this wouldn't be a nightly only feature.
Hm. Never thought that way. You're right! Thanks
You don't need to tell us you're a lead programmer. We could already tell from the disgruntled sarcasm.
Right idk wtf is up with this post but i've legit spent more time typing this shit reply out than actually reading it. For starters the subreddit is not about the game and when posting to it you get a fucking huge text telling you that it is not about the game but i still for some reason find myself reading your post so the warning isnt even working like there is NO way you read and understood it.
Already found a library to read my webp but I am too stupid to get it as png in color. Already asked on the rust forum aswell and a dev with his own wrapping of libwepb answered but I am just stuck for now. https://users.rust-lang.org/t/convert-a-webp-to-png/30145/3
Most C / C++ developers have a high regard for *performance*. If your rust programs outperform their code, they will be all eyes and ears. So, may be talk about the ripgrep being faster than grep etc., in addition to the other great points like *safety*. The combination of performance and safety is the real killer.
Even better: your project should be backed by a VCS (if not, why??), so just delete your directory and have a cleaner filesystem :)
Thanks! This approach looks interesting, if a bit unwieldy. I also wonder how it affects optimization, but it's probably better to experiment with this myself.
Similar to linux mascot - ping Win
&gt; I also liked being completely free of exceptions in Rust. Even the best Clojure code is vulnerable to exceptions bubbling up from the underlying JVM. I usually use a macro wrapper when I call Java functions to convert exceptions into nil + log message, but sometimes I forget to do this at every place. I agree. And even though, as others have mentioned, there are panics in Rust, they are *not* encouraged for control flow the way exceptions are in many languages, including Java. That's been my biggest pain when using Clojure and Kotlin- I always have to call Java code, and Java likes exceptions. So if I don't trace 6 calls deep to see what exceptions might be thrown (and *why*), then my beautiful Kotlin/Clojure/Scala code is going to be brittle. &gt; so one does not get lost playing "type tetris" as people have accused Scala or Haskell of being prone to. Well, I definitely have had moments of type Tetris with Rust. Especially with respect to error handling/converting in long chains (especially of v0.1 Futures).
Oh, I forgot about `-&gt; impl` %-] Yours seems better in that you save one level of boxing. Which `boxed` are you referring to? I see no mention of `Send` in [futures API docs](https://rust-lang-nursery.github.io/futures-api-docs/0.3.0-alpha.9/futures/future/trait.FutureExt.html#method.boxed)
Nice. My very first bit of Rust was [gcstool](https://github.com/Freaky/gcstool). I threw together a [bloom filter](https://github.com/Freaky/blooming-rust) recently too.
This thing is literally 50x faster than WinDirStat! Link for the lazy: https://antibody-software.com/web/software/software/wiztree-finds-the-files-and-folders-using-the-most-disk-space-on-your-hard-drive/
Nice! I completely missed your crate when I was searching before writing my own :(
I've been using [sccache](https://github.com/mozilla/sccache) to locally cache build artifacts, and it's been working pretty well for me.
It's true that `shared_ptr`s have a small amount of overhead compared to *raw pointers* due to ref-counting and synchronization, of course, which is their raison d'etre. But be advised you'll encounter the same overhead using Rust's threadsafe refcounted smart pointer, `std::sync::Arc`. It *is* an advantage that Rust also provides a non-threadsafe refcounted smart pointer (`std::rc::Rc`) where i) you do not have to pay the synchronization overhead and ii) have the complier "remind" you (fail your build) if you forget and try to use your `Rc` in a threaded scenario. But it's not quite accurate to generalize and say that C++ smart pointers have overhead: (Default) `unique_ptr`s have no size or performance overhead over a raw pointer, assuming the normal use case: ie. manual raw pointer initialization and destruction. For more detail, see https://stackoverflow.com/a/22296124/1541330 Rust's [smart pointers](https://doc.rust-lang.org/book/ch15-00-smart-pointers.html) are the same in this respect as well.
Not surprising, I never published a crate. I also ported it [to Ruby](https://github.com/Freaky/ruby-gcs/), which likewise is not yet a gem. My main focus was making it all disk-backed, at least for querying, rather than your approach of two different in-memory representations. Loading a multi-GB filter is bit of a drag :)
I appreciate your answer! Perhaps I was downvoted because I was perceived as wasting your time. That was not the intention, and I wasn't trolling. If anything, I'm an evangelist. Rust is awesome. In my case, though, I'm a mostly self-taught rookie/novice who programs in my free time (tried Python, had much more success with Swift, and now loving Rust). I asked so I could learn your perspective. Again, many thanks for the lesson and your point of view on the matter!
Thank you for the distinction!
Using unimplemented!() to mean panic!() when the user does something wrong seems... wrong. That's what unreachable should be used for: the program should not end up in this state unless the user violated some invariant of the library/program.
Haaa yes, I was suspecting there was a much much simpler way of doing this! Thanks for the info, I just patched my code!
Very nice! Looks like a cool project! I ran into a couple problems when dealing with some of the grammar’s ambiguity, but Rust’s pattern matching capability is amazing for these use cases. Had some mutual recursion issues too that were hard to troubleshoot. At some point I’ll probably rebuild it with Nom, but an interesting exercise nonetheless.
Yes we will either hire somebody or switch the whole system to ed25519 until we find someone who can also audit the system.
There is a Cargo.toml! You are looking inside the /src/ folder. Go one folder higher and voilà..
So maybe I lack the context but at first glance https://github.com/teslaNova/np1th_irc/blob/master/src/mode/mod.rs#L11 The `type Target: Parseable` seems unnecessary? You can just return `Result&lt;Self,Box&lt;Error&gt;&gt;`. In 2 places your code does return `Result&lt;Self,Box&lt;Error&gt;&gt;`, but in 2 other places you define `type Target = Self`. So I'm not sure what `type Target: Parsable` accomplishes?
I have a simple example here that I stopped after compiling and flashing, but no interesting code. Not sure if it would be helpful or not. And as others have said, the nrf52-hal project got examples as well. https://github.com/trondhe/rust-embedded
I did not know about that tool! I just fixed my code using the useful warnings from the tool, thanks a bunch! Here's the related [git commit](https://github.com/Ryp/chip8-emu-rs/commit/12d31dcbe65896bf6905e0aa1d1d55b48c4245ea).
I applied your hints to the codebase, now my `use` statements are more readable, thanks! Here's the related [git commit](https://github.com/Ryp/chip8-emu-rs/commit/ab4f1ce27e593071bfe61d868ec1abe46899fe89).
You deserve 1000 upvotes just for the initiative. Fuck web development, you're doing the real work.
Thanks for the tip about the shorthand syntax for struct initialization. For implicit conversions I ended up doing as you said, favoring `usize` or more common types to begin with.
Not necessarily. Especially in parallel code, Rust will provide memory safety guarantees not found in languages like Java, Go, etc. Rust provides it's 'data race freedom' guarantee in addition to it's 'memory safe' guarantee. See: https://doc.rust-lang.org/nomicon/races.html
&gt; if a bit unwieldy It reminds me of my days of template meta-programming with Boost.MPL in C++03, when variadics were encoded as cons-lists ;)
I think a build system should be above a language. There is always one more language that needs compilation, build, packaging, ways to explain dependencies, etc. Look no further than bazel, buck, pants, please.build, even GN (through Google Ninja). Cargo maybe the best build system for Rust, and possibly few other langs (C/C++?), but can't go beyond that...
tokio can just depend on a version of hyper that hasn't moved to std::future
I don't disagree. There's no single C++ package + build systems that's as simple as Cargo, though, and the C++ community seems hell-bent in preventing any kind of standardization on that front because everyone refuses to refactor their codebase to move to some kind of standard files layout/packages.
&gt;and thread safety, but per the Rust definition freedom from data races is part of memory safety). That is a great benefit &gt;The primary benefit is memory safety But memory safety in the usual sense is irrelevant. Every GC language has memory safety. You could say the benefit is having better performance than Java/C#/Kotlin. But a JVM JIT compilation could outperform AOT compilation by identifying actual hotspots in the program better
Being turing complete says nothing about the developer and performance tradeoffs being made. Have you ever used Eigen? It takes advantage of lots of things that you can only do in C++. Essentially, by overriding almost every operator (including =), and taking advantage of SFINAE, Eigen is comparable to a compiler that takes linear algebra expressions to optimized SIMD code. I think Rust could keep the nice linear algebra expressions, or the optimized SIMD code, but I don't see how a Rust library could keep both. I did not mean to imply that you couldn't produce comprable output with Rust. My point was that C++ overs a unique toolset in this domain with different, not necessarily better, tradeoffs. It would a shame if that got lost in this discussion.
&gt;here, is that Rust strings aren't null-terminated Then you need to make a full copy everytime you call an external C function. That sounds annoying Delphi/Pascal has a great solution, they keep an \0 at the end of every string, but never use it themselves, since they also keep the length of the string. But all strings can be given in O(1) to C libraries
Why does it need so much though? What could possibly take up so much space?
If you're on windows, I've also found that enabling NTFS compression saves a not insignificant amount of space on target directories too, surprisingly.
I think it was added after that comment.
Unimplemented is too ambiguous for *almost all* use cases. Todo is what it should have been all along - sounds like a pretty straightforward "why yes" argument. Is it not obvious?
Oh dang my bad
UDP as a connectionless transport doesn't have a concept of error codes. This is something that you will need to include in your protocol, and I don't think that reusing HTTP codes is a bad idea if they match what your protocol is aiming for. That being said, you will want to keep in mind the MTU (Maximum Transmission Unit) while using UDP. This is the largest amount of data you can send in a single packet. If you want to send more than the MTU you will need to split the data across packets and deal with partial and out of order delivery. Because of this, JSON may not be the best choice if you are trying to send larger structures.
Something like that : https://awesomekling.github.io/Catching-use-after-move-bugs-with-Clang-consumed-annotations/
 pub type EventHandler = Box&lt;dyn FnMut()&gt;; pub struct State { event_handlers: DHashMap&lt;String, EventHandler&gt;, } impl State { pub fn on(&amp;mut self, event: &amp;str, event_callback: EventHandler) -&gt; Result&lt;(), String&gt; { ... } pub fn send_event(&amp;mut self, name: &amp;str) -&gt; Result&lt;(), String&gt; { ... } } #[test] fn test_send_method() { use std::sync::atomic::{AtomicUsize, Ordering}; use std::sync::Arc; let mut state = State::default(); let mut attack_count_arc = Arc::new(AtomicUsize::new(0)); let mut attack_count = Arc::clone(&amp;attack_count_arc); state.on("attack", box move || { attack_count.store(1, Ordering::SeqCst); }); state.send_event("attack"); assert_eq!(attack_count_arc.load(Ordering::SeqCst), 1); } I have a feeling that the Arc and Atomic is unnecessary. But how do I remove them? Any other input would be welcomed.
You can use the `concat2` combinator from `futures` to wait for the stream to complete and copy the chunks into a contiguous buffer. use futures::Stream; // futures 0.1 let body = req.into_body().concat2().wait().unwrap(); let body_str = String::from_utf8_lossy(&amp;body); for line in body_str.lines() { println!("Line: {}", line); }
You are probably looking for /r/playrust.
trusting a remote repo are we? :)
Thank you
Yes... except that annotating every single method of every single class is obviously way too much of a burden.
I mean a GIL also does that... it's way less efficient but a mutex always works
I really like the contains method for Option
Reading the entire stream into memory is exactly what I'm trying to avoid
&gt; Being turing complete says nothing about the developer and performance tradeoffs being made. Certainly; hence the use of *clunky: poor ergonomics, poor error messages and long compile times*. &gt; Have you ever used Eigen? No. &gt; It takes advantage of lots of things **that you can only do in C++**. However I am challenging this part. I've written a lot of C++ meta-template programming code, up-to-and-including Expression Templates, on which Eigen is based. And the truth is, this is less a matter of what the language can do, and more a matter of bending the language to your will. Rust does not have the exact same set of features as C++, but it doesn't matter: - Overriding operators: built-in. - Overriding assignment: impossible; there are From/Into traits though. - SFINAE: traits; SFINAE is nothing but a clunky way of directing overload resolution, traits do this naturally. In this sense, I am confident that *something like Eigen* could be produced in Rust with sufficient work; precisely because the trait system being Turing complete means there's a sufficiently large toolset available to make about anything.
Personally I count future standards as "not yet standardized" but it doesn't matter, thanks for the clarification.
It's the opposite my dude
I've done a lot of research on this, and edit distance is pretty consistently on top. I would (genuinely) love to know more about your findings. My data set has its own peculiarities. I am identifying OCR'ed, secretary typed scientific names.
haha yes? I trust that GitHub won't crash and erase all of my data. If that's the case, there are more serious issues than me losing my FizzBuzz implementation
Thanks for the clarification!
This. IMO Rust only exists because the community wasn't aware of Ada. I also don't think Rust will penetrate the safety-critical domain since most people there know about Ada, and are already using SPARK/Ada. Not only is Ada very proven, mature, AND standardized, Rust still needs to add formal verification before it can even consider competing in serious "critical software".
If you want to, you could be inspired by Hugo : [https://gohugo.io/](https://gohugo.io/) \- a static website generator written in Go (golang). &amp;#x200B; It could be nice if Zola could use Hugo themes: [https://themes.gohugo.io/](https://themes.gohugo.io/)
Do people leave their projects in a dirty state very often? I usually `cargo clean` or `make clean` after finishing a commit (or a set of), like when finishing a new feature or fixing a bug. Never would I leave a repo dirty unless I was actively working on it.
So I've had a look at the `nodrop` crate. It seems to override drop flags. It seems that the way they are being encoded has changed between versions. I have reconsidered support for 1.20.0 and dropped it in maybe_uninit 2.0 because supporting older rustcs is too hard at the moment. Rustc 1.20.0 was released almost two years ago, it should be okay for most crates. If someone really wants support for older rustcs (like idk serde wanting to use my crate), and asks me for support, I will reconsider it but it seems like a lot of work and many chances to do something wrongly.
I'm working my way through the rust book but I keep getting hung up on their use of enums. I'm on the "Reference Counted Smart Pointer" lesson. &amp;#x200B; `enum List {` `Cons(i32, Rc&lt;List&gt;),` `Nil,` `}` `use crate::List::{Cons, Nil};` `use std::rc::Rc;` `fn main() {` `let a = Rc::new(Cons(5, Rc::new(Cons(10, Rc::new(Nil)))));` `let b = Cons(3, Rc::clone(&amp;a));` `let c = Cons(4, Rc::clone(&amp;a));` `}` &amp;#x200B; How would I reference(or dereference) the value of a? I'm not familiar with cons or lisp but it seems like they have created a linked list here. How would you actually reference the data in each node?
If you look into a good book on TCP/IP, it'll contain information on how TCP does retries, etc. It's not that hard to implement the basic algorithms. That's where I'd start. A company for which I worked did that for its cluster setup when TCP connections became problematic. &amp;#x200B; I agree that HTTP response codes are fine to use if they fit your semantics.
Yeah it's pretty much the same reason you can't have a struct contain another instance of itself. *But* if you put it in a Box/Rc/some-other-indirection then you can get similar behavior.
&gt; Is it not obvious? I mean... not to me? Maybe I'm just used to `unimplemented`, but it works well enough in this role. `todo` is probably marginally clearer, but we're not discussing which one of the two to add; `unimplemented` already exists and works well enough. Seems to me like the alias should provide something extraordinary to warrant an alias. Duplication like this is not free - it adds confusion, affects learnability (now if I know about one but not the other, I have to look it up to understand that they are the same), and also sets an unfortunate precedent about adding aliases.
Well, firstly, it's just intuitively better. Consider queries like `Flanders Loves Homer` for the Simpsons episode titled, `Homer Love Flanders`. A straight-forward edit distance metric is going to consider the query very far from the target, where as an ngram metric isn't. Secondly, if you look at my other comments, you'll see that I did an evaluation for imdb-rename, and edit distance is included in that. The [evaluation section in the README](https://github.com/BurntSushi/imdb-rename#evaluation) explains how to run it, but if you just want the results, here they are: https://gist.github.com/946935b5b412cf73461a722bbb6f1358
if the attack count will be shared and mutated by multiple threads, then some form of synchronisation primitive will be necessary, with Arc and Atomics being examples of them. On the other hand, if events will only be executed sequentially in a single thread, then your example code will compile fine using a raw `usize` as the attack count and using `+=` to increment it.
Not the first, and won't be the last. It doesn't have to be particularly extraordinary to warrant something much clearer for the overwhelming majority of use-case.
Hope you don't work on security critical stuff I guess ᕕ( ᐛ )ᕗ
If this is significantly faster than cargo-search, then I'd use it. I often just go to the website since searching using the UI is faster than the `cargo search` command...
If I use a raw `usize` : I get: `error[E0597]: `attack_count` does not live long enough` So how do I make it live longer?
I doubt it is faster. I have moved to cargo search 😂
You could try passing a mutable reference to `attack_count` as an argument for the event handlers. This will change how your program is structured but may be better designed in comparison. For example, try changing the event handlers to have a parameter: pub type EventHandler = Box&lt;dyn FnMut(&amp;mut usize)&gt;; Then, the signature for the `send_event` method, such that the attack count is passed into the callback: pub fn send_event(&amp;mut self, name: &amp;str, attack_count: &amp;mut usize) -&gt; Result&lt;(), String&gt; Which should allow you to write code like this: let mut state = State::default(); let mut attack_count = 0; state.on( "attack", Box::new(move |attack_count| { *attack_count += 1; }), ); state.send_event("attack", &amp;mut attack_count); assert_eq!(attack_count, 1);
Ah, you linked to an older version of the docs. Current versions of `boxed()` require `Send`. See https://rust-lang-nursery.github.io/futures-api-docs/0.3.0-alpha.17/futures/future/trait.FutureExt.html#method.boxed I just noticed there's also a `boxed_local()` without the `Send` requirement. But I think it's pretty common for futures to be `Send`, the default tokio executor requires it, right?
You could have methods like: ``` impl List { fn head(&amp;self) -&gt; Option&lt;&amp;i32&gt; { match &amp;*self { Cons(x, _) =&gt; Some(x), Nil =&gt; None, } } fn tail(&amp;self) -&gt; Option&lt;&amp;Rc&lt;Self&gt;&gt; { match &amp;*self { Cons(_, l) =&gt; Some(l), Nil =&gt; None, } } } fn main() { let a = Rc::new(Cons(5, Rc::new(Cons(10, Rc::new(Nil))))); assert_eq!(Some(&amp;5), a.head()); assert_eq!(Some(&amp;10), a.tail().unwrap().head()); } ```
If you want to panic on errors you can just `.unwrap()`, no need to call `unwrap_or_else(|err| panic!(err))` as they are the same thing, AFAIK. Sorry I don't have more time to review ATM but that jumped out at me.
Happy to see this release. I'm using Tera in a website and am looking forward to the better error messages in the upcoming Tera 1. At the moment, any error in a template leads to bisecting the template to find the offending line. Perhaps we're doing it wrong.
Clean and clear, nice website
Okay. `Body` doesn't implement `AsyncRead`, so we can use the `rw_stream_sink` to convert, then use `tokio::io::lines` to create an async stream of lines. let sink = RwStreamSink::new(req .into_body() .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))); let async_lines = tokio::io::lines(std::io::BufReader::new(sink)); let lines = async_lines.wait();
Somewhat overkill for this task, you can also [implement `Iterator`](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=6f7acb63dd12798a45562bbfdaa3f898) for your `List`. I decided to have the iterator hold a reference to the list that you're iterating over, preventing it from being dropped, but you could create a version where it's holding an `Rc` instead, and can outlive the list it's iterating over.
Supporting Hugo themes is never going to happen: different template engines and different data models make that impossible.
Looking at `main.rs`: * You can potentially avoid turning `needle` into a `String` by replacing the lowercasing code with ``` let needle = if case_insensitive { Cow::Owned(needle.to_ascii_lowercase()) } else { needle }; ``` * the code `unwrap_or_else(|err| panic!(err))` is equivalent (modulo a slightly different error message) to `unwrap()`. * Since you have multiple unwraps in your main method, it might be easier to have it have a return type of `-&gt; Result&lt;(), std::num::ParseIntError&gt;`; then you can use `?` in place of the unwraps. * ``` let buf_size = m.value_of("buf_size") .unwrap_or("8192") .parse::&lt;usize&gt;() .unwrap_or_else(|err| { panic!(err); }); ``` introduces an unnecessary parse, since "8192" will always parse correctly; this can be written as ``` let buf_size = m .value_of("buf_size") .map(|s| s.parse::&lt;usize&gt;) .transpose()? // ? or .unwrap(); .unwrap_or(8192); ``` The same can be done for `pool_size`. * `max_depth` can be calculated as: ``` let max_depth = m .value_of("max_depth") .map(|s| s.parse::&lt;usize&gt;) .transpose()?; // ? or .unwrap(); ``` * Because all you're doing in the last bit of `main` is printing an error or the success, and since the error gets printed anyway on an unwrap, you can just do ``` println!("found {} times", count?); // ? or .unwrap(); ```
This part of my code is not a bottleneck for now, so perf-wise I'm not too interested in spending time there yet. However, you raised a very interesting point concerning the solution, I ended up trying to use `match` like you suggested and am really happy with the way it turned out! Here's the [git commit](https://github.com/Ryp/chip8-emu-rs/commit/99f052baa4b05a740ccc47f0e9dfe81ff45616a2) for reference.
You might find [structopt](https://docs.rs/structopt/0.2.18/structopt/) useful. It's a wrapper around `clap` and would reduce your arg parsing code to use std::path::PathBuf; #[derive(StructOpt)] pub struct Settings { // dir is a `String` in your version, but paths aren't always valid UTF-8 strings /// The directory to be searched in. #[structopt(parse(from_os_str))] dir: PathBuf /// The text you want to search for. needle: String // short without a value means to automatically generate a short name based on the first character // long without a value means to automatically generate a long name based on the attribute name /// Prints a text snippet containing the found search term. #[structopt(short, long)] snippets: bool /// Enables case INsensitive search. Be careful, this may be slower. #[structopt(name="case-insensitive", short, long)] case_insensitive: bool, /// Displays benchmarking data. #[structopt(short, long)] benchmark: bool, /// Used buffer size for reading from the buffered reader. #[structopt(short="d", long="max-depth")] max_depth: Option&lt;usize&gt;, /// Used buffer size for reading from the buffered reader. #[structopt(long="bufsize", default="8192")] bus_size: usize, /// The worker pool size, i. e. number of threads. #[structopt(long, default="8")] poolsize: usize } fn main() { let options = Settings::from_args(); // ... }
Running tests in my crate is very slow because the dependent crates are compiled in debug mode. Running the tests in --release mode is 30x as fast, but compilation is far slower. Is it possible to have best of both worlds? To compile my own code as debug and compile the dependent crates with optimizations, even in debug mode?
Rust is the future!
In `core.rs`: * At the end of the loop, you build a string and output it to stdout, but you don't really need the string; you can write the parts to stdout directly: ``` writeln!(stdout, "{}x in {}", val, f).unwrap_or_else(|err| { eprintln!("{}", err); }); ``` * The sum calculation in `stop` can be done like: ``` (0..self.opt.pool_size) .filter_map(|_| self.done_rx.recv().ok()) .sum() ```
I'm not totally a WASM expert, but you can [specify WASM imports](https://rustwasm.github.io/book/reference/js-ffi.html), which are just JS functions that you need to provide when constructing your WASM object in JS to run. So as long as the JS code is just functions, it shouldn't be too hard; just import them into your wrapper and add them to your WASM construction.
A try_new in Box would be a good start, and maybe try_reserve in a Vec. From there we can go further.
Ah, FFI was the term I was missing. Yeah, that looks pretty easy.
Any time! I’m not sure why you were downvoted either :/
&gt;But I'll give you my lone upvote because I think the quality of engineers in a language's community is a huge reason to join. Alan Perlis said something to the effect of "Don't learn a language unless it will teach you to think differently." I've found that Rust did this for me, and that at least right now, the caliber of developers in the community is the driving force behind it lets go build something wonderful together.
This is a small part of a bigger project, but I may as well share it, in case it is of interest to anyone. :)
To elaborate on this: SGX also keeps getting broken by security researchers every year or so. The "trust" it provides is really limited.
I think the term "entry point" is misleading since it implies that there's a function like "main" there. It's more like a root than an entry point.
Just adding my set-up, which works with nRF52840-DK. You should be able to use the example in the nrf52-hal. For the nRF52840-DK I use the [J-Link GDB Server](https://www.segger.com/products/debug-probes/j-link/tools/j-link-gdb-server/about-j-link-gdb-server). To run my code I have following in my `.cargo/config`, [target.thumbv7em-none-eabihf] runner = "arm-none-eabi-gdb -q -x jlink.gdb" rustflags = [ "-C", "link-arg=-Tlink.x", ] [build] target = "thumbv7em-none-eabihf" Where `jlink.gdb` contains, # print demangled symbols by default set print asm-demangle on # Connect to the JLink GDB server target remote :2331 # Enable semihosting monitor semihosting enable monitor semihosting IOClient 3 # Set a breakpoint at main # break main # reset to start monitor reset # Load the program load I have a shell script which invokes `JLinkGDBServer` JLinkGDBServer -select USB -device nRF52840_xxAA -endian little -if SWD -speed 4000 -noir -LocalhostOnly With the above set-up I just run my code with (first start `JLinkGDBServer`), $ cargo run --example example See [https://github.com/blueluna/nrf52840-dk-experiments/tree/master/nrf52840-dk](https://github.com/blueluna/nrf52840-dk-experiments/tree/master/nrf52840-dk) for inspiration.
I found it is some kind of equivalent to `opt == Some(value)`.
I would love to see a benchmark that confirms this claim about JITs. I've never seen a benchmark that AoT doesn't match or beat if given profile data. I _totally_ get the theoretical argument but what actually matters is the real world.
The same is true now of crate downloads though, right?
How about [this](https://www.reddit.com/r/rust/comments/8d21yh/graalvm_can_run_rust_via_llvm_bitcode/dxk888s/?context=1)?
Look cool. Very nice! My one opinion is that the locations should include the state, in case the city is ambiguous or not well known.
It's obviously Clojuror
If there's cake involved, then yes
Wow, that's pretty impressive. For the more noob-ish people like me: Why is this? I know Rust is usually somewhere in between C and C++ performance wise. But why is it so good at this type of task? Is there something inherent to Rust that could explain this? Is it because of the memory model? Is it because it is more optimized for this type of job? But then again what "exactly" (in layman's terms) does optimized mean here?
That's awesome. It seems like Actix is really fast. I wonder how similar the benchmarked version is to the normal Actix though. I know that "aspcore" is benchmarked with a very stripped down and optimized version of their framework.
You can try updating to the beta to see if it's better, there aren't many breaking changes. An error at compilation time should have the line but runtime is trickier as it's not keeping track of the line numbers.
Here you go. [Posted on the fine programmer quote connoisseurs subreddit.](https://www.reddit.com/r/programmingcirclejerk/comments/cbf4h5/rust_is_5_languages_stacked_on_top_of_each_other/?st=jxxtdoi8&amp;sh=a05f1195)
&gt;I know Rust is usually somewhere in between C and C++ I don't think that's really a fair statement. If I had to guess, I'd say that crate composability is a major factor in how well it performs. e.g instead of writing your own HashMap you can just pull in `hashbrown`, `ccl` etc which are extremely well optimised. C and C++ just make it way more difficult to use other people's code.
Rocket is also written in rust and ranked 209th
Rocket uses synchronous I/O so is going to be pretty bottlenecked by design. Not sure about Iron.
&gt; e.g instead of writing your own HashMap you can just pull in hashbrown, ccl etc which are extremely well optimised. C and C++ just make it way more difficult to use other people's code. Ah. Good point. (Pretty big disadvantage for C++ as a language though, if it makes it that hard to collaborate)
Yes but maybe that's on purpose? AFAIK the actix version used for the benchmark is not the original actix version, but a modified one (optimized for max performance) But then again, if there's a faster version of something, why not used this for the "normal" version as well?
Pretty sure it isn't using a modified version.
How do you handle the timing between SPI bytes, i.e. when the three SPI bits for an LED bit span across an SPI byte, are the timings stretched?
The source is there
https://github.com/TechEmpower/FrameworkBenchmarks/blob/master/frameworks/Rust/actix/Cargo.toml#L28
This is a really great explanation. I'm excited now to try Rust async.
I second this suggestion. Your intuition can lie to you. Measure all things.
I learned a lot by looking at Zola's creator's website. The source is [here](https://github.com/Keats/vincentprouillet) and the generated site is [here](https://www.vincentprouillet.com/).
&gt; And the more code that does that, I imagine it gets harder to actually decide it is UB. It does, but I also think people have a responsibility to others not to assume that they can do random things with `unsafe` that they can do in e.g. C which Rust may not provide a way for. ("I need to do my job" is not a good excuse; everyone does, but that's a tragedy of the commons waiting to happen.) As for a replacement API, ostensibly you could add (in a subtrait): ``` fn read_into_uninit(&amp;mut self, buf: &amp;mut [MaybeUninit&lt;u8&gt;]) -&gt; Result&lt;usize&gt;; ```
As pointed out [here](https://www.reddit.com/r/rust/comments/cbn1no/rust_is_leading_most_of_the_techempower_web/etguggf/), you can see that they are just using normal actix
it does not make hard to collaborate, but does not make sharing packages as easy as cargo and crates.io does. It was fine in early 2000, but by now the C++ committee should have created a central repo and/or expanded much more the standard library.
Iron just hasn't been updated and dead. Also sync I/O with very limited design.
Can you talk about the bigger project? Really interesting implementation btw.
When using nightly cargo you can use profile overrides cargo-features = ["profile-overrides"] [profile.dev.overrides."*"] opt-level = "z"
Ah, yes, that seems obvious now.
Ehhh, you're missing my point a bit. Sure, WE know programming errors are expensive... try getting your business office to understand that. Rust is not currently in a good place for this sort of thing- a cost/benefit analysis doesn't exist, and by the time you create one, Rust will have changed enough that it would be wrong, and that statement ALONE would cause it to get denied for being 'too unstable' (yeah yeah, I know.) Like I said, you're trying to consider things from a technical point of view, but at the end of the day, what non-programmers think brings the money is what you'll be doing, if I'm making sense.
I don't think synchronous I/O is the only issue. Rocket also loses to Roda which is synchronous **and** written in Ruby.
Hey po8, thanks for the great reply. It makes for a good, nuanced counterpoint to my more 'blustery' post. The bluster was mostly because, as you very truthfully point out, this kind of thing is hard. It's complicated, it takes a while, and there's a lot of things to consider. OP is doing none of that, and has no intention of doing any of that, which gets an immediate 'Nope.' from me, as it well should. As for stagnation, do remember that while new technologies and languages are good, some things are tried, tested, and true for a reason. Case in point: C.
Rocket is using a really old version of hyper, like 0.10.x and that's from like 2016/2017. It has not received many of the upgrades hyper has gotten since then. I'm pretty sure that's why it's losing to Ruby
Good question. So once the bytes have been handed off to the hardware SPI controller, I am not aware of any special timings between SPI bytes on the hardware controller side. It does have to stick pretty strictly to the clock signal, so I don't imagine that byte boundaries would be treated any differently from a timing perspective
Ruby’s IO is blocking, but asynchronous. Like Go.
Wrong sub bud. /r/rustgame
Glad to see rust getting some recognition! I'm preaching to the choir here but wanted to add that rust isn't just *faster* than the other options, it has: - Modern, flexible, and easy to use build/packaging/distribution systems (this makes sharing/reuse easy, feature gating is also awesome) - A fantastic toolchain that makes it easy to build statically (you can even go all the way* with musl) - An approaching-research-grade type system without the burden that is OOP - Completely novel (in a production-ready language, AFAIK) approach to data safety -- the rust code is almost certainly safer than the similar C/C++ code Rust isn't just better, it's *way* better. Actix is also build on *stable* rust -- this isn't even nightly performance. What the rust team and contributors have done in such a short time is simply mind-blowing.
It would generally be there to cover things that are partially there (maybe for an experimental feature) but are not promised. An example would be. Say that a class has has two modalities pub struct SomeConfigType { ... pack_tightly: bool, parallelize_aggresively: bool, ... } You initially implement a naive way, as people generally want one or the other (they care about memory, or they want to parallelize). The problem is that tightly packed data, when parallelized aggressively, result in a lot of contention and counterproductive solutions. You could build a solution that works in spite of this, but it would be a lot of effort and work; and as said before: there's no apparent need for this use case. You expose functions that force you to choose, so there should, in theory, be no way to handle this. But you realize that in the future someone may create a `SomeConfigType` that does allow for both, serialize it, and pass it on to your software. You do want to specify that the problem isn't as simple as the data being invalid or corrupt, but that the version of the software they are using cannot handle this. So your code looks like this: if config.pack_tightly &amp;&amp; config.parallelize_aggresively { unimplemented!("This version doesn't support simultaneously using pack_tightly and parallelize_aggresively."); } if config.pack_tightly { ... } if config.parallelize_aggresively { ... } So why not use `todo!()`? To me the difference is that `unimplemented` can go into production/release code, but `todo` shouldn't. While `unimplemented` means that we explicitly chose to not implement a condition that could be possible in the future (unlike `unreachable` that says *it never* will happen), `todo` means that I didn't implement it yet, but *it must* be implemented at some point for the code to be finished. The only way I could see it making it through is if it's a temporary situation (like a bug) but this would be more on removing a workaround, which I don't see why it should panic. Of course there might be a better way to do this (some comment that tells the linter that this `todo` is ok) but that's what it is.
Why would this be for the rust game sub
I saw trading and I assumed it was for the game. Sorry!
I'm using actix for the federated reddit alternative I'm working on, [Lemmy](https://github.com/dessalines/lemmy). Actix rules, and has websocket support too.
All good my fellow Rustacean 🖖🏻
I know Rust is used professionally in that sector (There's a few bits here an there in this reddit that you may find). For personal use? Maybe?
Web stuff like these benchmarks is almost always I/O bound. Rust has really good non-blocking I/O capabilities: mio for access to os level primitives in a platform-agnostic fashion, futures to provide a modern, reasonable programming model for writing non-blocking code, and all the platform pieces that go between. And the story only gets better with async/.await landing in the near future. Non-blocking I/O is faster than blocking I/O with big thread pools because it avoids a lot of context switch overhead. The overall flow of the program is clear to the compiler, so it can generate great code. Other high-performance frameworks like Vertx are similarly constructed. Actix itself is also a great, fast, thoughtfully designed low level framework. The language itself makes it embarrassingly easy to reason about async code, because it prevents broad classes of errors that commonly occur in other languages.
Do you have any links regarding its use in the institutional field? I was debating using python or Julia, but if I can use rust I’m gonna use rust. Best programming language out there
Yes, that is annoying overhead for calling C functions. (There is similar overhead for calling Windows functions, where Rust's UTF-8 strings need to be converted to UTF-16.) The big upside of `&amp;str` not being null-terminated, though, is that it can point into the interior of another string. That means an operation like string splitting doesn't have to allocate at all. Instead, it just gives you an iterator of string references, each of which points into the bytes of the input string. That can't work for null-terminated strings, at least not without modifying the input.
That is a dope ass game
One of the issues with rust is that all of the missing pieces you described above (with the exception of const) are generic over higher kinded types, which rust did not currently support. You can implement them individually for each type and they can have the same name, but writing code that is generic over all `Functors` for example is going to be difficult if not impossible.
I'd say it's not that people weren't aware of Ada, although I'll admit I knew of Rust before it. I think Ada's history of being something you had to pay quite a bit for hurt it. Thankfully GNAT is free to use and high quality.
In Haskell, all functions are essentially the equivalent of Fn, so you could just restrict all of your types to Fn and call it a day.
Wrong sub bud. /r/rustgame
That was my guess, too, after decades of seeing C and especially C++ beaten by things like Perl, Python, etc. because the low-level opportunities weren’t realized due to all of the time soaked up getting things to run at all (obviously not all the time but I’ve seen a fair number of cases where someone was surprised to spend a week under-performing what they expected to be easily beaten). Rust is a really interesting study in just how important those ergonomic factors are for making those possible optimizations actually happen.
I've been a rust lurker for a handful of months- and this is exactly the kind of thing I'd build with it. This thread would be of interest to you: [https://users.rust-lang.org/t/possible-java-to-rust-switch-for-a-securities-trading-platform/16895/32](https://users.rust-lang.org/t/possible-java-to-rust-switch-for-a-securities-trading-platform/16895/32)
What exactly do you mean by "reference the value of a"? Your "a" variable is a list. Are you trying to e.g. print 5? You can get at the contents of each node using a match statement or an if-let, perhaps that's what you were going for? (I haven't run this code, typing on my phone...) if let Cons(x) = &amp;*a { dbg!(x); }
`tokio `has migrated all the required components to `std::future::Future` that `hyper` needs. Currently `hyper` depends on the master branch of `tokio`.
I think that the causation is inverted. Python didn't target and cater scientists originally. Scientists sought out Python and build themselves using it because they liked it. A lot of the science tooling we now consider standard in python (NumPy/SciPy are the main ones I'm thinking of) likely originated from scientists building the tools they found necessary to accomplish their tasks. I think that for scientific computing to become a priority of the Rust community, scientists will have had to already invest themselves into the Rust programming language. And to do that, Rust needs have value to scientists over what they're already using. The value of Python vs other C like languages is pretty obvious: It's stupid easy to write code. I'll be honest, I don't know how likely it is for scientists to be really wooed by rust. 1. Rust isn't well known for being the most user friendly programming language. It requires a lot of up front effort to get things working in Rust, which simply is too big of a barrier when you're a new grad student with no programming experience who needs results yesterday. 2. The features that make Rust a good language are not the features that a lot of scientists really care about. Traits? Functional programming? Lifetimes? Safe Concurrency? So what? And before you say "Well we should communicate that these are important!" good luck. I'm watching as a thousand scientists walk right past 50 years of high performance scientific expertise, programming infrastructure, and (most importantly) performance gains they so desperately need because they don't like static typing. "It just works!" &gt;&gt; Literally anything else. Thats my cynical 2 cents.
Awesome explanation. I understood everything. :-) Thanks!
The topic of that article is not really comparable to the runtime in Java/C#/Kotlin because Dynamo operates on AoT-compiled binaries, and is compared to the HP toolchain from 2002 or earlier. All forms of optimizers have improved in the past 17 years, so this isn't a particularly relevant comparison. I'd also never heard of the HP C compiler before now which may or may not be a comment on its quality. I skimmed one of the Dynamo papers and the slide deck that the graph in that article is from. It's interesting that the Dynamo slides and Chris Lattner's thesis on LLVM are both dated 2002, and both adopt the same strategy of using a runtime to observe and re-optimize a program. LLVM no longer does this of course, as it isn't a VM. Do you have any other benchmarks? I don't mean to be patronizing or rude, I would very much like to learn about this topic.
How large can the packet be? And what’s the alternative for the JSON?
&gt;Python didn't target and cater scientists originally Actually Python was created specifically for scientists and non-programmers.
Thanks for sharing your experience. Do you have any reference about the TCP algorithm/structure so I can take that as a reference to design my own algorithm
Wrong sub. See r/playrust
From what I observe, most C++ programmers don't dare putting string\_view or any observing entities into a map or vector. So, what are you afraid of huh ? In rust I use Vec&lt;&amp;str&gt; when I need to, and sometimes I put &amp; \[String\] as a parameter and get back Vec&lt;&amp;str&gt; as the return value to avoid further memory allocation, but rarely do I see any C++ programmers do that. And also, people in the C++ world really don't like the observing entities that live for too long even without putting them in containers, so actually, C++ people already paid some performance tax for safety. Therefore, if any random coworker come to me and say "I can take care of the safety problem!", I'd reply: " OK, then, go screw up your own project and leave me alone with mine in rust.".
Oops thx
&gt;I think that the causation is inverted. Python didn't target and cater scientists originally. Scientists sought out Python and build themselves using it because they liked it. A lot of the science tooling we now consider standard in python (NumPy/SciPy are the main ones I'm thinking of) likely originated from scientists building the tools they found necessary to accomplish their tasks. I don't think I'm trying to argue that Rust should seek to compete with Python - in fact, I think any deep learning or ML framework front-end in Rust is very unlikely to succeed. You're not going to have the vast majority of scientists who currently write Python writing Rust. What I was trying to communicate was that Rust might be able to replace the C++ backends to many of these Python use cases. &gt;I think that for scientific computing to become a priority of the Rust community, scientists will have had to already invest themselves into the Rust programming language. I think that's likely true, but for many of these applications (e.g. large-scale numerical solvers for computer vision) there's just as much if not more going on in industry, so if a company were to sponsor a Rust rewrite it might gain some traction in the broader community. &gt;I'm watching as a thousand scientists walk right past 50 years of high performance scientific expertise, programming infrastructure, and (most importantly) performance gains they so desperately need because they don't like static typing. "It just works!" &gt;&gt; Literally anything else. I am very often one of those people :) But I think (in addition to the aforementioned industry groups) there is a subset of scientists who *do* have to occasionally write performant code (in C and/or C++) and then wrap it in Python for everyone to use. I wish we could replace C/C++ with Rust in this scenario, but I admit that it is a niche area.
I think it was created as a "simple" scripting language and the scientific computing libraries were relatively late arrivals. This is one of the motivations behind the development of Julia -- rather than having its numerical libraries "grafted on" like Python, it's built from the ground up for scientific computing.
No, Python was originally crated as a language to fit between C and shell scripts, as Guido van Rossum was working on a system at the time where those were the only options. &gt; I was working in the Amoeba distributed operating system group at CWI. We needed a better way to do system administration than by writing either C programs or Bourne shell scripts, since Amoeba had its own system call interface which wasn’t easily accessible from the Bourne shell. My experience with error handling in Amoeba made me acutely aware of the importance of exceptions as a programming language feature. &gt;It occurred to me that a scripting language with a syntax like ABC but with access to the Amoeba system calls would fill the need. I realized that it would be foolish to write an Amoeba-specific language, so I decided that I needed a language that was generally extensible.
Wrong reddit, I think it's r/play-rust
AreWeConfYet?
you're probably right, thank you
Rust is not a replacement for Python (or Julia). It is a possible replacement for C++ or Fortran. A lot of scientific software today is organised in layers. A typical way would be a fast core in C/C++/Fortran, then a front-end in Python. Use Python to create your models, wrangle IO and so on; and the core to do the computing itself. Rust may well find a role as another high-performance back-end language. But even in the core, the reality is that everybody(1) tends to call out to the same small set of BLAS/LAPACK compatible libraries where the mathematical heavy lifting is done; and OpenMP, MPI and related libraries for parallel computation. Rust would need performant bindings to these libraries. On large HPC systems there is literally no option other than those, as the systems provide specific versions of these libraries written and tuned for the particular system. If you can't link to and use their BLAS or MPI library, your code will run like a dog. &amp;#x200B; 1. OK, not literally everybody
Common mistake. People need to look at the About more often when first getting to a reddit.
r/playrust
&gt; I know that "aspcore" is benchmarked with a very stripped down and optimized version of their framework. Do they mention this somewhere? I'd be interested to read up more about it.
Relevant threads: [1] https://www.reddit.com/r/rust/comments/bhtuah/production_deployment_of_rust_in_hft_system_at/ [2] https://www.reddit.com/r/rust/comments/757up9/watching_this_carl_cook_cppcon_talk_on/
[Soon to be upgraded :)](https://github.com/SergioBenitez/Rocket/pull/1008)
Some scientists will need the speed and safety rust offers. Some won’t.
/r/playrust
If Rust had an engine for the FIX protocol, I'd definitely use Rust. I'm using C++ in the meantime.
It would be cool if your README included links to each package you're installing, so we can learn more about them
Get a repo going. I’m sure a decent amount of people would be really interested
&gt; actix I'm not a rust user, but actix looks a lot more complicated that Rocket as a non-rust developer. Since any web framework can scale horizontally quite easily, what's the use case for rust here over something like Go? Why would I chose rust (or C++) for web servers, when I can optimize for development time?
You're the same boooomba from r/samharris right? Weird seeing those posters out of that context and instead in programming subs.
Just because you can scale horizontally doesn't mean footprint doesn't matter.
I don’t think I was clear enough in my original post (I clarified in another reply). My lament is that right now Rust is nowhere near a replacement for C++ in that use case, and I’m wondering when I’ll be able to start wrapping my fast Rust routines in Python rather than C++.
Yes, but keep in mind that every call between the worlds has a lot of overhead, especially when complicated parameters like strings or arrays are involved.
I think safety isn’t a huge draw for most science applications, it’s more about a modern, ergonomic, non-kitchen-sink language to replace C++.
Yes, but you don't have to worry about it until you reach twitter scale, right?
Yes that would be me. I didn't know I'm reddit famous! ;-) (kidding) I will have to look out for you on the SH sub from now on!
I'm currently working on a crate that parses the FIX XML specifications\[1\]. Ideally this crate would be used for codegen, as the quickfix engine\[2\] does, and was suggested in fix-rs\[3\]. &amp;#x200B; I'm looking forward to cooperate on any crate that helps towards consolidating a decent FIX engine for Rust. &amp;#x200B; \[1\] [https://github.com/unterkontrolle/fix-spec-codegen](https://github.com/unterkontrolle/fix-spec-codegen) \[2\] [https://github.com/quickfix/quickfix/tree/master/spec](https://github.com/quickfix/quickfix/tree/master/spec) \[3\] [https://github.com/jbendig/fix-rs/issues/1#issuecomment-341530359](https://github.com/jbendig/fix-rs/issues/1#issuecomment-341530359)
&gt; The gains you get for traversing the learning curve are ridiculous -- C/C++ level speed with a near-Haskell type system, NodeJS level ease-of-reuse, Golang-level buildability (IIRC they're well known for making it so easy to static build for different targets), &gt; and &gt; a stack that you can take from embedded hardware all the way &gt; into the web browser &gt; (with WASM). I'll say it (again, but differently this time) -- Rust is bonkers. Boy I hope you're right, but that's a super exciting value proposition.
I agree. Rust is not a replacement for C/C++/Fortran in scientific computing in general, and in HPC in particular. And it doesn't look to me as if it will be anytime soon. The basic numerical and other libraries are missing, of course, but that's just the tip (bottom?) of the iceberg. Rust lacks hundreds of specialized libraries covering the gamut of computational research. Computer vision routines (OpenCV bindings?); file format libs for HDF5, Blast etc.; numerical solvers; visualization tools and so on and so on. Now, as you point out above, it took Python a decade to build up a solid body of modules for this, and we shouldn't expect Rust to do it any faster. It's early days yet. But unfortunately I also agree with you (I think) that many of Rusts strengths as a safe language is actually a hinder for adoption in the research community. Very few researchers have actual training in programming — they've effectively learnt it on the job by modifying other users' scripts and code — so things such as lifetimes and borrowing is utterly alien to them. I don't ever expect Rust to become a wholesale replacement, or even a mainstream alternative, to existing languages in research for that reason.
&gt;Which would be horrendous if you actually to write it yourself, of course, however so is writing Eigen, so as long as said nastiness is encapsulated in the library I would expect things to be fine, no. Even if it was possible to define the arbitrary-dimensionality tensors using macros, I'm skeptical it would be possible to also define the operator fusion that way, without the user having to use a macro for every operation. The thing about Eigen is it's not all encapsulated: to support fusion, an operation on two matrices/tensors won't produce another matrix, it will produce a lazily-evaluated thunk of sorts. But the lazy evaluation happens at compile time; these thunks are fused at compile time using expression templates, to create efficient runtime code. I'd be surprised if it's possible to do it in Rust using macros in a way that hides the nastiness from users, since I don't think Rust supports expression templates. (Of course, Rust could do it as a DSL that's processed by macros to produce efficient code, but that would arguably be harder to use/integrate with custom functions). More superficially, at least coming from C++/Haskell, using macros feels like something that should be avoided where possible; better to use the type system where possible. &gt;I... fail to see the problem, actually. Random practical example from some code I wrote recently. Imagine you've got a `fn&lt;T&gt;`, and somewhere in that function you call the constructor `T(arg1, arg2, arg3)`, where the args are read from a config file. Now, you create another different struct you want to use as `T`, but its constructor takes an extra `arg4`, and you don't want to change the constructors of all other structs that are currently used with that function. You can simply do `if constexpr (std::is_same&lt;MyNewT, T&gt;::value) { const auto arg4 = myConfig.mArg4; T(arg1, arg2, arg3, arg4) } else { T(arg1, arg2, arg3) }` With no need to define any traits or implementations. Adding a trait with N implementations doesn't work for external code (or a least you'd need to write newtype wrappers that delegate the trait to the external function). An example of something you can do in C++: define your own `to_string` functions, then when writing a function that operates on type `T`, add a `using namespace std` above where you call `to_string`, then if `T` is instantiated with your custom type, it will call the `to_string` defined for that `T`, while if it's instantiated with a standard library type then it will call `std::to_string`. In Rust (at least if there wasn't already an existing trait for what you wanted to do),
I think you wanted to post this in r/play_rust
This is my favourite "Rust game" post ever.
I agree and I think it’s a real shame — I don’t know what % of C++ these days is numerical solvers and scientific computing software, but C++ has that part of computing locked down and will for a long time. Same with embedded and C (another area I sometimes have to get into when I’m editing drivers for some robotics peripheral) - there are some efforts to build out an ecosystem for embedded in Rust but I think it’s doubtful they’ll overtake the massive inertia C has in this space and Rust will be relegated to hobbyist projects for the foreseeable future. C++ is making some inroads here but from what I can see it’s very C-like C++ that makes heavy use of backward compatibility. I guess I’d better spend more time updating my C++17 knowledge...
Especially these days
the time until you need n + 1 machines is further out the more efficient you are now.
Maybe part of the solution is realizing that “to replace” something it needs to add considerable value. For example, to overcome the activation energy required to learn a new api. I really like making python extensions in Rust. I think there is a lot of unrealized potential there. Think about the pain points coming from Pandas and np users and design apis that use Rust’s strengths and python’s. Right now the name of the game is shortening the distance between exploratory code and production code, I think Rust python extensions can be part of that story.
For embedded, I wouldn't count on it remaining "hobbyist" - this space is much less decentralized than scientific computing. If one big vendor makes a push for a Rust SDK (which is admittedly a stretch but we do see Rust being picked up by big names these days), it can change the game. Think iOS/Swift and Android/Kotlin. I don't see the same happening in scientific computing libraries, where most of the work is done by hundreds of small teams at research institutes, with all the resource constraints and conservatism that implies.
Especially these days
What is the best way to trash a value that I pop from a `VecDeque`? I have a cache that has an update function that has a function called `update` that basically pops the earliest entry from the cache. The code that uses this cache doesn't use this value, though, so I decided to drop it and not return it inside the function itself. I return a `Result` from my function, with `T` as `()` and `E` as the arbitrary `NoCacheItemError` struct (`Result&lt;(), NoCacheItemError&gt;`). Currently, my function looks like this ``` pub fn update(&amp;mut self) -&gt; Result&lt;(), NoCacheItemError&gt; { self.cache.pop_front() .map(|_| ()) // Drop the item .ok_or(NoCacheItemError) } ``` As you can see, the value is consumed by the intermediary closure but is dropped because the closure just returns `()` (and the `_` hints at the compiler that the value is not used, hopefully leading to better optimizations?) and then is turned into a `Result`. This feels clunky and unidiomatic. Rust, especially with the `Option` and `Result` types, usually has functions for simple things like this that make actions like this very smooth. TLDR: What would be the most "Rusty" way to drop the value from inside an `Option` before `.ok_or`ing it into a result.
You're a bit more optimistic than me for it coming soon 😅
One thing that always helps me when using python is a good IDE! If you haven't used PyCharm, I 100% recommend installing and trying it. I tried to use mypy at some point too, but gave up because it just couldn't represent every kind of higher-kinded type which is nice to use in Python code. Type-checking in an IDE like PyCharm can be much nicer, though, and usually works without having to be explicit. I like thinking of the best practices for Python as being a happy path, but with the caveat that those best practices don't value long-term maintainability as much as Rust's do. It's not that Python's objectively worst, it just values different things - and shifting to that value system is part of For instance, I tend to be running my Python applications a lot more often while developing them than Rust. With Rust, I can write a ton of code, just "check"ing it. If I have a design in mind, I can continuing writing for hours before running the program once. In Python this would be a bad idea because of two things: running Python applications and tests is _fast, and easy_, and Python doesn't have the compile-time checks rust has. When I try to think of the different design decisions and different workflow decisions as different (rather than completely superior or inferior), and evaluate why one might have made Python's choices, I have a much nicer time. Hope that helps?
/r/playrust
I would argue that Rust doesn't solve any different problems in the performance space than existing high performance solutions.
I bought this game yesterday on the last day of the summer sale, and I have been playing for the past two days with some Steam friends. I left our base on the last night before the reset, and wandered solo across the map looking for scrap to research blueprints. In pitch blackness, I swam across a frozen fjord, hopping icebergs, toward a lone cabin with a warm fire burning in the darkness. I crept along the shoreline right up to the lone wooden front door only to see a wooden door without a lock. Opening it, I rushed inside only armed with a machete to an open room where the occupant was standing by the fire. It was -22C and I was frozen. Screaming "MEAT, MEAT, MEAT!" I charged inside, and started slashing the startled Asian woman with my machete as she ran outside and tried to fight me off with a mace. But the cannibal bloodlust triumphed, and I was able to carve up a tasty meal, warm myself by her fire, and rob her house of its precious scrap and possessions. The flesh is good. &amp;#x200B; TL;DR - Noob kills other noob, giving in to the dark taste of cannibalism. Most hilarious experience in game so far.
More accurately, it's `&amp;'static str`, since a `&amp;'a str` where `'a` is anything other than `'static` is just string slice which may refer to (part of) a String which was populated with user input, although the lifetime checker is sufficiently powerful that it usually doesn't need explicit lifetimes.
There are a ton of people in this subreddit that are far more qualified to speak to this than I am but I'd bet on it. Rust took a drastic turn before 1.0 by removing a bunch of features in favor of having a runtime be opt-in -- because of that early sacrifice the language now supports *both* ends of the spectrum really well. Low level stuff: - https://docs.rust-embedded.org/book/ - https://github.com/rust-embedded/embedded-hal (maintained by https://github.com/rust-embedded/wg#the-hal-team) And all the way on the other end: - https://rustwasm.github.io/book/game-of-life/hello-world.html - https://www.youtube.com/watch?v=h7IndjPpNtM (this is a really good guide to wasm for rust) Now I personally don't feel the need to have rust on the frontend because I'm happy with Typescript (and I haven't even given Elm/Purescript) a shot, but the fact that you *can* use Rust on the frontend and it *isn't* the trainwreck that is ActiveX/Java Servlets but is actually a safe, general abstraction that other languages can use is amazing. BTW, as a newbie you are uniquely positioned to help the rust ecosystem -- if you see things that you don't like/understand or things that could be explained better or stumbling points, feel free to post about them/discuss them. People like me believing in the value proposition of rust is not worth much if no one ever ventures near the language due to misrepresentation of the benefits/learning curve (see: Haskell and Monads).
We use it in a hedge fund for risk and pricing of derivatives. I also use it for some glue code for pre trade applications. What's lacking for us is being able to target GPU with Rust right now, so our pricing simulations are written in cudaC. It's a shame tbh, hopefully one day it will target ptx.
r/playrust
how should NaN sort against numbers?
It sounds like your argument is that Rust should be used in addition to or in replacement of C/C++/Fortran in performance sections or performant libraries. I want to agree, but I simply have not progressed enough into Rust to go beyond writing horribly slow code. Unfortunately, I think Rust's safety features do make it difficult to manually write performance code (which is usually what high performance computing devs want to do); however, it seems like automatic optimization tooling should be able to synthesize performant alternatives, which I'm sure is an active area of research (but I don't see a lot of Rust papers these days).
I think the reason for this is that I used to use a custom macro called `error_panic!` in the closure, and I just replaced it with a `panic!` \- resulting in unnecessary code. Many thanks!
`structopt` seems extremely useful for me and your example demonstrates this well. I'm excitied to use it. Many thanks for that suggestion!
It really does depend on what you're doing, and in most cases it's not even down to technology, it's down to business costs/ what your team knows/is willing to learn. You're absolutely right that you can optimize for development time, but let me try and give a few points why rust would be a better choice over the other languages with everything else held equal (as in your company has enough money to train everyone on rust, people are willing to learn it, etc). Rust v Go: - Rust shares the toolchain benefits that Go brought to the table (in fact I consider it better because they sidestepped the modules fiasco) - Rust is managed in the open -- there's no begging Google devs for changes (whether that's good or bad, there are good points to be made on either side of that) - Rust's coroutine story is not as well fleshed out/integrated as with Go (though this is by design), but libraries like Actix (not actix-web, just regular actix which it's built on) show the quality implementations can bring even if they're not in the standard library. Go has also spent more time in production with it's rapid adoption for devops code. - Rust's type system blows Go's out of the water. `Result` &amp; `?` &gt; `if err != nil`, obviously generics existing is nice Rust v NodeJS: - NodeJS lets you very quickly write good code, but unfortunately it doesn't do anything to stop you from writing bad code unless you're using Typescript. Not declaring/inferring &amp; checking your types really is not the way to go IMO, everyone remembers how fast they were up and running (which is true), but forgets all the struggles they had with `undefined`s and weird unexpected behavior during local testing &amp; in production. - Up until very recently NodeJS was single threaded which meant you needed `pm2` or some other process spawn+daemon to work multiple cores efficiently. This is less important in a single-core web-worker scale-out situation, but the ability to scale up *or* out @ the same level of complexity is indeed a benefit. Also, node recently had [worker threads land](https://medium.com/lazy-engineering/node-worker-threads-b57a32d84845) so this point is less important now though of course the ecosystem has yet to embrace worker threads everywhere yet. - NodeJS is harder to deploy than rust, unless you're handing it to a service like Elastic Beanstalk/Heroku/something buildpack based All this said, Golang and NodeJS+Typescript are excellent choices, I personally use NodeJS+Typescript whenever I have to hand something off to a client, and Golang is what I would recommend to companies looking for something other than Java to use because Go is the antithesis of Java complexity (almost to it's detriment) and I like to see people experience what life could be like. Rocket does look less complicated than `actix-web` (note `actix` is a general actor framework that `actix-web` builds on), but that's very much part of it's value proposition -- it's aiming to be more Rails-y from what I can tell. I prefer the Sinatra/Flask/Express microframework group of tools -- And as such I actually prefer [`tower-web`](https://github.com/carllerche/tower-web). I use `actix-web` as well on a project too, because stable rust is very attractive to me and some other options required nightly.
The difference between Rust panics and C++ exceptions is that *you can't recover from a panic*. When your code panics, whatever thread called that macro is dead. When you join a thread, the Rust compiler will complain if you don't assign the Result of that call, and if you give the Result a name, the compiler will complain if you don't *use* that name, so since a thread that panics produces an `Err(...)` result, you have to explicitly ignore that error or do something about it, whereas the C++ compiler doesn't care if you check for errors in the joined thread.
I watched one of their Dev videos on YouTube a long time ago where they talked about their improvements in techempower. Iirc they even pointed out how close they were to "Actix-raw" or something, and that they weren't the only ones optimizing for good benchmark scores.
The closest parallel in style is probably [The Book](https://doc.rust-lang.org/stable/book/)
peoples should stop think Rust is a replacement for C++, you all wrong and so people listen to you and are disappointed.
The [docs for std::cmp::PartialOrd](https://doc.rust-lang.org/std/cmp/trait.PartialOrd.html) include an explanation for this: &gt; However it remains possible to implement the others separately for types which do not have a total order. For example, for floating point numbers, `NaN &lt; 0 == false` and `NaN &gt;= 0 == false` (cf. IEEE 754-2008 section 5.11).
Thanks, it looks similar to the kind of structure I'm aiming for, I'll check it out.
Quoting [https://www.floating-point-gui.de/errors/comparison/](https://www.floating-point-gui.de/errors/comparison/) &gt;Due to rounding errors, most [floating-point](https://www.floating-point-gui.de/formats/fp/) numbers end up being slightly imprecise. As long as this imprecision stays small, it can usually be ignored. However, it also means that numbers expected to be equal (e.g. when calculating the same result through different correct methods) often differ slightly, and a simple equality test fails.
Known-size at compile-time was a bit of an issue for me. Using `ndarray` I was unable to just paste in a 20x20 grid of integers. I'm sure there's a different way to accomplish what I wanted, but I looked at the docs for far too long and found nothing useful. :/
Only if money doesn't matter. Low footprint also helps scheduling granularity, which can be important if you're not on public cloud and can't just throw money at problems. Applications that start quickly and stay running have lower operational overhead too -- it's easier to monitor them, push updates, scale, and schedule them, which is great. I wouldn't write a normal CRUD web app in Rust. There are def more productive languages to write that it in. But there's a whole world of other HTTP connected things that value speed and stability. And, Rust is really nice to write. :) Actix is a beautiful lil library.
By panicking, imo. NaN only comes up when something has gone wrong and it's usually unrecoverable when you have to deal with it, just like dividing by zero or overflowing an integer.
If I switch hardware from physics to cloud, Rust loses the first place in most items. Anyone knows why?
&gt;and/or expanded much more the standard library. I guess this is why we have boost
I haven't posted there in years. Got sick of the racists ;)
As per the details of IEEE754:2008 section 5.10 which defines a total ordering of floating-point values.
High frequency trading systems are a different story, and these systems tend to be optimized to the point of memory access and assembly. This requires a lot of manual allocations and unsafe code. My personal opinion is that rust has potential but is not fully there yet. FIX, the protocol virtually every exchange is using, is a stateful protocol and requires an engine to work. Currently, there was a failed attempt of writing a fix engine. The maintainer stopped developing it by pointing issues that he could not optimize it [well enough as he would have liked](https://github.com/jbendig/fix-rs/issues/1). However for regular trading systems, that are not over optimized, rust has the benefit of great memory safety, expressiveness, good control over the execution of the program with no garbage collection. I would love to see an application where c++ is used for the main trading engine, and rust is used for writing strategies.
Thanks for the detailed response. &gt; feel free to post about them/discuss them. Will do :)
I would personally be against this, as the default value is rarely something I _want_ from a type, especially if I've forgotten to do an if/else. Even if that type is `Option&lt;T&gt;`, I would argue explicitly putting `None` in the else clause makes the code much more clear than an implicit default could. It's more typing, but for that cost you get much more clarity?
I came to the same question recently and found there's some [discussions](https://www.google.com/search?q=rust+float+partialord) about it.
There are crates that provide number types with exactly this behavior, FWIW.
Wow, thank you :) The more experienced Rustaceans seem to play around with `?` pretty often. However, doesn't the statement &gt; let needle = if case\_insensitive { Cow::Owned(needle.to\_ascii\_lowercase()) } else { needle }; return a `Cow` in the one arm and a `&amp;str` in the other one?
I wouldn't ever have the idea of using `0..self.opt.pool_size` as an iterator and receiving the values in `filter_map()`, but I really like it. Is this a more advanced use case or did I just miss something?
Which crates? My point is more that if you have a floating point operation that can result in a NaN without checking it before a comparison, you have a bug anyway and need to handle it.
There's a named function for `|_|()`: `std::mem::drop` :)
oh. wow. yeah now i realize how dumb that was. as soon as you said it i remembered the signature for drop is exactly that. sorry about that. thanks for the help
A macro is a great idea! I love how if I find something wanting in the language you can usually write a macro to fill the need... I think you are right: there's a lot of clarity from being explicit.
Really nice for some support to arrive, was going through rich &amp; knight and was trying to implement a bayesian network. Always appy as i think rust is a pretty good language for AI.
I always forget the areweXyet things exist, in fact I totally forgot about them till the comment. I think that's a good enough reason to not go with that naming. However if someone wants to have that redirect to this I would be fine with it.
Having `else { None }` everywhere is usually an indicator that you could be using `?` more frequently. Have you tried that?
The crate seems to be in maintenance mode - the author is [keeping up-to-date with PRs, and publishing new releases](https://github.com/PistonDevelopers/conrod/commits/master), but not implemented new features (or new docs). I wouldn't expect conrod to die anytime soon, but I wouldn't expect the guide to be completed any time soon either.
A nitpick: actix-web 1.0 is not actually built on actin the actor system.
very important thing do me is the documentation first and then the power of the crate. so apparently its not a good GUI to start with. But what GUI will you suggest that has a good docs and almost same as conrod (in terms of widgets - flexibility etc.)?
Hm - have you looked at gtk-rs? https://gtk-rs.org/ has pretty high quality docs and GTK definitely has a lot of widgets available. The one disadvantage is that it's not pure rust, but it has high quality bindings, good documentation for those bindings, and I don't think there are any pure-rust libraries coming closer to the maturity and completeness of gtk-rs than conrod.
oh yea, i've seen that at the first research but i prefer to use the GUI which is purely written in rust and not mixed web technologies such as css (coz its too ugly to me). But yea the GTK docs is very good. but the widgets are not as nice as conrod unfortunately.
I love Rust. It really does feel like it is bringing something new to the table. Learning another mainstream language like Java, Python or Go feels like just changing syntax for me (from C#). Rust feels like it's advancing the state of the art, and it's fun to be part of that.
I'm not returning from a function... but I refactor and put the whole `if` expression into a function I guess...
I’m not a Rust developer, but can’t you output a shared object that uses the C ABI in Rust and pull it in using cffi or similar in Python? This is how you do it in C++ as well.
&gt; the scientific computing libraries were relatively late arrivals That’s not really true, the scipy interests and communities (mailing lists, …) were very early, we’re talking mid to late 90s. Matrix-sig was created in ‘95. Now the core ecosystem took time to mature eg NumPy was created in 05, but it built on and unified older packages (numeric and numarray). And scientific interests fed back into the langage very early e.g. complex indexing and slicing were very much added to the langage for that reason / purpose.
Ah, fair enough. They’re not yet stable, but `try` blocks will come in handy here: [playground](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=eb4088d6200a7080eef8388721967e70)
Because you can cut operational costs by 10-100x and still serve 3-4x the number of users? Because you can do that without basically dropping down to C level, which previously would have been your only option and would have surely cost waaay more in developer time, developer cost and debugging+bug fixing?
&gt; What the rust team and contributors have done in such a short time is simply mind-blowing. Agreed. I've been using Rust for about a year now (hobbyist work only, unfortunately) and the improvement in that time feels huge. And I think async/await is going to take things to another level, I think it will drive a lot of interest in the language. And one of the most important things that can happen for Rust is to *grow the community*. With a bigger community, there are more crates, more blog posts, more people who can work on optimisation and improvements to the standard library and compiler... Another thing to think about is that the population of Rust users is a pyramid. Given that it's a young language, the number of experts is small compared to the total population of programmers. As the community grows and matures and people have more years of experience under their belt the number of experts will grow exponentially.
I guess, but there are a lot less variations: Just name and version. No infinite combinations of feature flags, no crate overrides. I don't know those, this is but a mere guess!
&gt; Unfortunately, I think Rust's safety features do make it difficult to &gt; manually write performance code (which is usually what high performance &gt; computing devs want to do) ... I don't think so. I have a decade of experience writing high performance C++ Code. There're several features in rust that make writing high performance code easier: - automatic move - explicit costly copies - borrow checker allows more aggressive sharing of data - multithread overhead only when needed (e.g. Rc/Arc vs. std::shared_ptr)
Errors at compile_templates!() are usually easy to fix. Most errors occurs when the `Context` instance is different from what the template expects. An error to indicate that a field does not exist in the context and on what line that field was accesses, would help with the most frequent errors.
Consider negative numbers. Floor will round down. Truncate will round up.
&gt; I think the open source linear algebra libraries contributed by small hobbyist teams are great, but without something like Eigen using Rust for serious research in vision and robotics (and probably many other areas) is a non-starter. I don't think this is true. In my experience doing serious research in robotics using Rust, [nalgebra] has been more than sufficient for my needs. If I am doing something that is more compute-intensive than it can handle, it's also probably more compute-intensive than I would want to do in Eigen and I will instead use TensorFlow (or similar). [nalgebra]: https://nalgebra.org
Fwiw 5.10 provides a total ordering predicate which includes nans. It’d have to be implemented in software though, i think. And unlike sql nulls nans don’t get grouped up at one end or the other: &gt; `−qNaN &lt; −sNaN &lt; numbers &lt; +sNaN &lt; +qNaN`, with ordering between two NaNs in the same class being based on the integer payload, multiplied by the sign bit, of those data.
Yes. But not able to understand why was not in the standard library? Is there any particular reason?
[removed]
Could also leverage the boolinator e.g. `(x == y).as_some_from(|| thinga).unwrap_or_default()`
That's awesome. Thanks mate.
For what it’s worth the goal of the [nalgebra](https://nalgebra.org) crate from the [Rustsim](https://rustsim. community (some of us use it for research on animation, physics simulation, and 3D streaming) is to get at least in par with Eigen featurewise and performancewise. Though the Rust language itself still lacks a few features (mamely const-generics and specialization which are both in the work) to achieve this. I agree there is still a long way to go and this wont come as quickly as it could without proper dedicated funding. Though the steady increase of popularity of Rust will hopefully help us get there.
The fact that Rust will detect integer over/underflow in debug mode might actually be quite useful for scientific code. I was surprised several times when such bugs were discovered in my Rust code. This can save quite a lot of debugging time, or even avoid getting incorrect results without realizing it.
Thank you very much for clarifying this -- I thought "actix" was the name of the actor framework in particular. After some digging I see [this line of code](https://github.com/actix/actix-net/blob/c1b183e1cea13772f23b148e37d18c16dcec2d0a/actix-server/src/builder.rs#L256) -- Doesn't it? `spawn` is from the `actix_rt` package, is that not the runtime for the actor runtime system in `actix`? Maybe I'm misundestanding what `actix` itself is
Is that correct or at least useful though? &amp;#x200B; It seems that floats are fucked because NaN shouldn't be in the set of possible values, it should be simply an error of certain computations. (Just like division by zero for integers.) And NaN shouldn't be accepted as input value for any FP operation. &amp;#x200B; Naturally there is probably a historical reason for why IEEE 754 is the way it is, but it seems like a footgun and now with ships with bullets included \[loaded\]!
Thanks. I found that [profile.dev] opt-level = "1" gives the shortest `cargo test` time when doing development. I'm not on Nightly.
That doesn't quite apply here. Accumulated errors does not change the ability to compare floating point numbers.
Thank you!
Correctness is surely important for scientific applications though?
You can still create a `Functor` trait. It’s still very ugly and not really “FP-idiomatic”, but you can still do it. There are several things I dislike about Rust’s trait system and lack of HKT. For instance, the fact that traits have an implicit type and “are applied on a type” is a bad visualization of what typeclasses are. In Haskell, a typeclass can apply on _several_ types (`-XMultiParamTypeClasses`). This is not possible in Rust and we have to hack around (and the `self` syntax gets in the way).
While I agree that panicking while sorting makes sense, it does come with a host of other issues that I find disagreeable. For example, sorting is implemented in terms of the `Ord` operator [[1]], which means that either there would have to be some specialization in regards to floating point numbers (which is not currently supported) or every single floating point comparison would have to check against NaN. That kind of overhead simply will not work for me. I also disagree with imposing upon the language the idea that having a NaN means that something went wrong and the program needs to panic. For example, I'm doing a lot of work with C++ libraries where NaN is used to indicate an absence of value which means they are common and expected. I also work with a Rust library that is vaguely transactional in the sense that a number of computations are done but it is possible to roll back to a previous state if NaN is detected in the final result. Basically, I think they should be treated just like overflowing an integer: only check on debug builds and provide me an explicit way to bypass that check because sometimes I did it intentionally. [1]: https://doc.rust-lang.org/src/alloc/slice.rs.html#196-200
Relm is a wrapper around gtk-rs to give it a nicer API.
In addition to what other people have suggested, mutability is not a sin. It would be perfectly valid to do: let mut thing = None; if foo() { if bar() { thing = Some(whatsit); } }
I haven't dug into the code, but my understanding of the shift was informed by this comment thread: [https://news.ycombinator.com/item?id=20104631](https://news.ycombinator.com/item?id=20104631) &gt;The architecture is no longer based on an actor paradigm but rather one of Services &amp;#x200B; &gt;Does this mean that actix-web does not use actix (the actor system library) anymore? &amp;#x200B; &gt;That is correct: the actor library is no longer used by default, although it can be imported and used in one's own server.
Thank you
With the `1.0` release, `actix-web` doesn't have anything to do with `actix` anymore. The `actix-rt` that you mention does not depend on `actix`, in fact in all of the transitive dependencies of `actix-web`, you'll never see `actux`. And the website has yet to be updated to reflect this change, as I understood it when the release came out. Maybe the `actix-rt` and other building blocks of `actix-web` are also building blocks of `actix`, that's something I haven't checked yet.
My 2 cents: the scientific computing application of Rust that everyone would love is the replacement of ParaView &amp; VTK libraries. Every user that I know holds some kind of grudge against those, for the most disparate reasons. Be it the unergonomic Reference Counting used by the VTK library, the random crashes or the lack of proper tutorials for advanced features. Rust could shine in creating standalone applications for post-processing and visualization of big datasets, but unfortunately the development of a framework to do such a thing requires a lot of work in different areas, especially GUI components.
It's really late for me, so I can't review the code thoroughly, but I can recommend a little tool that will help catch dumb mistake we can make. `clippy` is a wonderful linting tool that catches a lot of mistakes (I think over 300+ if I remember). This can be from small things, to general over complexity. I've been using it for a large project I've been working on for over 3+ months now. The amount of stuff it's caught me doing is embarrassing. It's also a great tool if you're learning Rust (saved me with unnecessary traits).
I have never written a 'normal' CRUD web app that would not benefit from being able to run on fewer smaller servers and serve the same number of users.
On my computer, there are still round 17 displayed. Maybe the website is not fully deployed with updates round 18. Hard refresh and check again, the results are outstanding
Well it's more the opposite honestly: the float NaN is a more convenient solution to what happens with integers. When you divide an integer by zero on a CPU you generate a CPU fault, the whole program is interrupted and the execution continues in the kernel interrupt handlers. This is a very slow process and makes it impossible to be handled at the application level forcing you to add divisor checks when you're unsure about its value. On the other hand NaN is great: it marks your computation as wrong and it propagates to other computations allowing you to only check the end result. People would go crazy if every float divide by zero caused an interrupt and crashed a program. Especially since it can happen when you have value that are different than zero but are rounded to zero because they underflow the precision. So you would have to check every divisor in your code and that would impact every high performance piece of code. The thing is the way integer encoding and cpu ALU traditionally work makes it impossible to add a NaN representation which function like the float one. So in that sense integers are actually inferior. Now to go into the nitty gritty details, floating point unit usually **have** an exception for division by zero, but this is never enabled by modern OS because of what I said above (e.g. for x86 [https://xem.github.io/minix86/manual/intel-x86-and-64-manual-vol3/o\_fe12b1e2a880e0ce-234.html](https://xem.github.io/minix86/manual/intel-x86-and-64-manual-vol3/o_fe12b1e2a880e0ce-234.html)). &amp;#x200B; The real solution is the strict ordering of float. Unfortunately it was only included in the 2008 revision of IEEE754 and nobody is going to manufacture a CPU which would behave completely differently compared to its predecessors regarding floating point comparison.
You're right, I totally mixed up `value_of` and `value_of_lossy`. The code should be: ``` let needle = if case_insensitive { Cow::Owned(needle.to_ascii_lowercase()) } else { Cow::Borrowed(needle) }; ``` or just ``` let needle: Cow&lt;str&gt; = if case_insensitive { needle.to_ascii_lowercase().into() } else { needle.into() }; ```
Yeah, this one's not really conventional, but the general principle is that it's often possible to replace code of the form ``` let mut x = ...; for a in y { // do something with x; } x ``` with ``` y.map(|a| ...).sum() // or collect(), or fold(), or some other thing ``` Of course, sometimes, like with the `filter_map` ignoring its argument, it's a little strange looking.
Rocket's techempower benchmarks are rather pointless if you look them a bit more carefully: over 90% of the requests fail. This is due to their old hyper dependency, it apparently breaks keep-alive.
The sub is in pretty bad shape at the moment. 50% of all posts are not even SH related and just people trying to push their race realism or SJW narrative. If you can ignore that, there are still some very good posts/topics every now and then though.
&gt; Why would I chose rust (or C++) for web servers, when I can optimize for development time? Mainly reliability. Rust as a language will allow you to prevent a lot more issues, so you will have less issues appearing in production. It is also sane and modern language, I prefer it to other ones you mentioned although ecosystem is obviously years behind them. Comparing to node it wins on being compiled, which provides performance and ability to perform cpu intensive tasks, where node would have to offload it to something else. Comparing to Go, it has generics, better error handling and sane dependency management. It also has C ABI compatibility if you ever need it. In my opinion when necessary libraries are there, Rust is as easy to use as anything else. Also it may not be as common for other people, but numerous times I had a situation where webservice preloads tons of data (language models, dictionaries, etc) and with multiple single-threaded processes I'd run out of memory very fast. Rust suits this usecase perfectly.
[const generics](https://github.com/rust-lang/rfcs/pull/2000) are on the way to solve this issue.
I'm sure you can create a `Functor` trait, but the one you provided is naive, and means that generic code over `Functor` looks like the following: // I have no idea on how to even format this type. fn do_something&lt;A: Functor&lt;u32, u32&gt;&gt;(input: A) -&gt; &lt;&lt;&lt;&lt;A as Functor&lt;u32, u32&gt;&gt;::Output as Functor&lt;u32, u32&gt;&gt;::Output as Functor&lt;u32, u32&gt;&gt;::Output as Functor&lt;u32, u32&gt;&gt;::Output where A::Output : Functor&lt;u32, u32&gt;, &lt;&lt;A as Functor&lt;u32, u32&gt;&gt;::Output as Functor&lt;u32, u32&gt;&gt;::Output: Functor&lt;u32, u32&gt;, &lt;&lt;&lt;A as Functor&lt;u32, u32&gt;&gt;::Output as Functor&lt;u32, u32&gt;&gt;::Output as Functor&lt;u32, u32&gt;&gt;::Output: Functor&lt;u32, u32&gt;, { input .fmap(|y| y + 3) .fmap(|y| y * 2) .fmap(|y| y - 10) .fmap(|y| y + 5) } Very clunky. In addition, trying to implement something like `liftA3` will require more than a single type for `Output`. Or inversely, when you implement `pure`, you will have an unnecessary unbound type. I thought about it for a bit and I think if you want true `Functors` you would have to have something like this: struct Map&lt;'a, A, ActA, F&gt; { act_a: ActA, func: F, _act_a_type: PhantomData&lt;&amp;'a A&gt;, } trait Functor&lt;A&gt; where Self: Sized, { fn map&lt;'a, B, F&gt;(self, func: F) -&gt; Map&lt;'a, A, Self, F&gt; where F: Fn(&amp;A) -&gt; B, Map&lt;'a, A, Self, F&gt;: Functor&lt;B&gt;, { Map { act_a: self, func: func, _act_a_type: PhantomData, } } } impl&lt;'a, A, B, ActA, F&gt; Functor&lt;B&gt; for Map&lt;'a, A, ActA, F&gt; where ActA: Functor&lt;A&gt;, F: Fn(&amp;A) -&gt; B, { } Which allows you to define `Functors` over *traits* rather than types: i.e a `impl Functor&lt;A&gt;` mapped will return an `impl Functor&lt;B&gt;`. The actual implementation is the deferred until we know exactly what `functor` we're using.
A bad implementation (in kernel handling of CPU faults) doesn't mean that including NaNs is great. &amp;#x200B; Obviously there should be an error/overflow/whatever bit. Like a nice atomic Result&lt;T,E&gt; :)
&gt; too big of a barrier when you're a new grad student with no programming experience who needs results yesterday. This reminded me of my first Rust project. I was an under grad. The project for the class was something about interprocess communication. I attribute my success that semester to the great documentation for the std library. While the borrow checker is a difficult concept, I think there is more than enough hand-holding from compiler errors to documentation to help determined grad students.
Our trading sim is written in rust (for speed and correctness), most of the actual strategies are then written in Python. I think this is a match made in heaven. Bits of a trading strategy that need to be fast can be also moved to Rust as required (instead of Cython which I find awful). We use PyO3 and so far it hasn't let us down. &amp;#x200B; Actually researching new strategies is going to be a massive pain in the neck in Rust, because what you need is a language that: 1. Doesn't get in your way and lets you quickly prototype ideas. 2. Has heaps of well tested time series and numerical libraries.
As a consequence one would expect that `min` and `max` would propagate NaNs, but [they don't](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=175bfae595e57890be27eb022aa371a0).
actix-web 1.0 changed this. actix is not a dependency of actix-web anymore, I believe it uses tokio now (yes the naming)
Mutability is not a sin. Using it solely to initialize an otherwise immutable variable is a sin.
The hardware ordering for floats is not a total order due to how NaNs are specified to behave. And this is not just a theoretical issue; accidentally introducing a NaN into an ordered set or map, or even trying to sort an array or vector with NaNs in it, leads to broken invariants and potential data corruption if the default hardware ordering is used. Now, as other commenters have said, there does exist a total order for IEEE floats, but it would have to be implemented in software due to lacking hardware support. Alternatively, there are several proposals for floating-point wrapper types that disallow NaNs, but the problem is that different use cases call for different semantics.
I think it will be really hard for Rust to displace C/C++/Fortran in simulations and other number crunching scientific applications. The biggest reason is an established ecosystem of libraries, layers and layers of them, people will be very reluctant to replace those. Another reason is compilers: Intel compiler gives a significant speed-up without any code changes if you target their hardware, and beating it with LLVM will be really hard and will require a lot of manual optimizations. An the third one, scientist are not programmers, usually they don't care about maintainability and safety, so it will be very hard to explain Rust advantages to them. But there is one scientific area which may be quite suitable for Rust: robotics. It often requires: efficiency, robustness and maintainability. Also often you have to do low-level embedded programming as well. And with ROS it's very easy to swap elements of your system, so it will be easier to experiment with Rust solutions without rewriting everything from scratch.
You can check the gitlab repo of orbtk and ping the developer, is a cool guy, he can give you an inside of the status of the project, last time I checked was a few months ago, the only downside at that time for me was the sdl requirement (in windows is kinda pain to setup), and also he was rewriting the entire API, my impression is that OrbTK and Azul are the best bet that we have in rust, maybe if you go to the rust discord (don’t have the link rn) and ask in the gui section you will get better and updated answers.
It is more complicated than Rocket. I personally think that having diversity is great because it means that I get to trade off performance for code that is easier to write
Could be an interesting project though, finding (or building) rust alternatives to the third-party libraries AtBS plugs.
Might wanna fix your formatting
On that topic, the impl clears up why: https://doc.rust-lang.org/src/core/num/f64.rs.html#387-397
How would you opti this at hand ? Magic ?
Sounds like you want an enum - something like enum Node { Add(left: Box&lt;Node&gt;, right: Box&lt;Node&gt;), String(&amp;str), Number(i64) }
I am rewriting parts of my system from Python to Rust, mostly for stability and speed. I still use Python for prototyping new strategies, but once I have them finilized I move them to Rust.
I guess if second box is null, it has to be A. Otherwise it's B.
Can I implement traits for an enum property? For example the trait fmt::Display for "Add"? And could I do multi-level inheritance like this (everything is a "Node", but only "Add" and "Sub" are subclasses of "Expression")?
Sure it does. It solves many problems inherent in C and C++ while being close to or faster than C and C++. Rust is faster/easier than C to write a tight loop for speed. That should be useful to geneticists at the minimum.
It doesn't seem to be optimized: https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=88291c8a7039c2ba1c056f0efa29bcd0 It looks like it could in theory but that might be a little difficult and ad-hoc.
You can't implement a trait for a subset of enum varians, you need to implement it for the whole enum. You can't have multi-level inheritance, but you can nest enums inside other enums, so if you have `enum Expression`, you can do `enum Node { Expression(expr: Expression), Statement(stmt: Statement) }` or something like that.
Thank you for answering! I'll give it a try!
I am no Rust fanboy and even refer people to C/C++ based on what they want to do but as far as I understand there is nothing right now that prevents you from using Rust for scientific computing from the language perspective. You can write your own struct if you want to change array addressing from row major to column major. That said, I think what you mean is Rust community and in that sense, it's unfortunate that the community uses Rust for web stuff where IMHO there are "better" alternatives. But that doesn't mean Rust has anything inherently in language whereby it prefers such workloads (in fact it's ill-suited for web kinda stuff).
... so, almost every Lisp dialect?
Sadly, not right now. But you could use struct with option instead. [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=6d5d8f87c0696b54f6f373f249380a44)
There’s definitely work being done. DataFusion is a project that’s working on making sure Rust can play well with the Arrow ecosystem. The language is still young though and numerical computing isn’t yet a focus for the larger community. On the other hand, the closer things like const generics and mature simd support get, the better positioned Rust becomes for something like Eigen to be written (but with much more straightforward implementation than fancy template meta programming).
There are many posts about writing performance Rust in this sub, and they tend to note Rust's general advantages there. If you are writing horribly slow code in Rust maybe you're fighting the compiler still?
As an aside I don't think a variant with two boxes is common or should be. As soon as your variants contain such values it's usually cleaner to use a specific struct, for example enum Test { A(A), B(B), }
exactly
I would generally use enums like /u/K900_ said, but if you want to you can use trait objects to do runtime polymorphism like in traditional OO languages. https://doc.rust-lang.org/book/ch17-02-trait-objects.html
AFAIK, NPO only applies to the case where one branch has no value and the other one has a NonZero value. Then the compiler can « pack » the valueless case as a zero of the valued one.
I just noticed this. &gt; Edit: &gt; &gt; Thanks to u/masklinn and u/ssokolow this is solved. Rename the *.dll file to *.pyd if on windows. I previously thought "everything works the same" meant "the symptoms on Windows haven't improved". Now, I'm going to assume you actually meant "Now, the Windows version works the same as the Linux version".
...though I think I remember hearing that it will drill down into `struct` members to find the `NonZero` so that the newtype pattern doesn't impede NPO. I don't have a citation for that, though, so someone more knowledgable will have to weigh in on whether I'm right about that.
I think that's an unnecessary level of zealotry. I would absolutely prioritize code readability over "initializing an otherwise immutable variable is a sin", particularly since I can just make it immutable after I am done initializing it. There really isn't a functional difference between this and hiding the mutability via a function call. I find: let mut thing = None; if foo() { // Some code if bar() { // Some more code if baz() { // Some more code thing = Some(whatsit); } } } let thing = thing; Way more readable than: let thing = if foo() { // Some code if bar() { // Some code if baz() { // Some more code Some(whatsit) } else { None } } else { None } } else { None }; Also, from a maintenance perspective, if the default value changes the mutable version only requires it is updated in a single place rather than `N` places. Granted, at some level it should be abstracted away into a function. But until that point, readability is more important than zealotry.
&gt; Granted, even if some time has been spent on optimizing the python code it could still be made faster. One the other hand I didn't spend much time in optimizing the rust part (is it not even multithreaded!). That case was also made early 2018 with a (Mozilla-sponsored?) rewrite of a source map parser: * js-&gt;rust (wasm) for a 5.9x gain * mraleph flexes their mastery of optimisation &amp; js (and algorithmic improvements) for a ~4x improvement on js-&gt;js * algorithmic improvements get folded back in the rust version for a final 10.9x js-&gt;rust and the noté that it provides &gt; *reliable* performance *without* the wizard-level shenanigans that are required to get the same performance in JavaScript. (Emphasis theirs)
Yes, as @hardicrust highlighted we are waiting for const generics to provide an ergonomic way to specify known shapes (or partial shapes) and check at compile time that matrix operations are well defined. The alternative is using TypeNum to "hack you way" to const generics, but the error messages you get are quite obscure...
This is expected in https://github.com/rust-lang/rust/issues/60958 .
Most SPI protocols don't strictly control the time between bytes (or words). Lots of simple SPI devices don't even really care about the clock being a consistent frequency, just that clocks come in to advance the internal state machines. On embedded systems, you'll see an appreciable gap of a few clocks between the clocks and data after every 8 bits as the microcontroller grabs the shifted in data and loads the next byte to go out. This is usually mitigated by using DMA transfers, though there still can be a gap. If you put a scope on it, I'd be curious to see if there's a stretched clock every 8 bits, though it appears to be within the DS2812s' timing requirements.
[You are right.](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=108f06cc215695f75c1b985a6ea29a5e)
My tower does actually go three deep...
Very minimal and clean, though I think the date format could use some work. I see in the code that the hours left only show up when the event is less than 24 hours away. Why not do it the other way? When there are `x days` until the event show `%D:%H:%M` and then once it is less then 24 hours do `%H:%M:%S`.
I don't really want to sell too much about something I don't really have anything to show about tbh. However I can tell that it's related to Bayesian Epistemology, and [this example](https://github.com/vberger/loopybayesnet/blob/master/examples/flat_earth.rs). :)
Not knowing anything else about your code, I would say that's the point where it should probably be turned into a function. You would get the clean code from the first example without playing with a mutable variable.
Ah I see what you mean. Yeah I suppose the fetching would have to be within tolerance for the panel to work at all as I'm not doing anything special to time between bytes. Scoping it there isn't a detectable difference I can make out at least. Would be interesting to dig into this a little deeper to fully understand
Interesting. It seems whenever I encounter an issue with Rust there's a fix right around the corner. NLL, now const generics. Cool stuff.
This is not supported currently. See this issue: https://github.com/rust-lang/rust/issues/46213
box can't be null
Thanks, you're right. I didn't work on modes very much and left it as it is for the time being. It's a relict, so to speak.
Bugs in scientific computing code are rarely very expensive, so I don't see a focus on safety happening anytime soon.
Used it to drive a KDB cluster and stream ticks / bars / curves to python, dot net and cpp. Now trying to interface with HFT middleware using shared memory. Will post if successful.
I thought most players moved to SBE?
Data analysis is data analysis whether it’s scientific or not. Could be super expensive could be not. Could be big-grant critical data could not. Rust eliminates many bugs that pop up in C, C++, and even python.
That’s the point. If the second word in the memory representation is zero, it must be the first variant. Just like `Option&lt;T&amp;&gt;` uses the zero value to represent `None`.
Rust code compiled is orders of magnitude smaller than a node modules directory... And way faster too. Is it ready for everything? No. There are places where massive productivity gains from existing tooling are huge wins and hardware is cheap.
Pretty sure code reviews are welcome! For this kind of utility I would recommend building on top of the crates **walkdir** and **clap**. However, rolling your own as you have done is good for exploring the language. &amp;#x200B; You can remove the double conversion to a string here: String::from(format!("failed to get file extension")) with either of these, which return a string String::from("failed to get file extension") format!("failed to get file extension") The format macro is mostly used to create a string that changes at runtime such as format!("failed to get file extension for file: {}", path) &amp;#x200B; If let can shorted matches where you only want one branch, so match path.extension() { Some(val) =&gt; { if file_extensions.contains(&amp;val) { let destination = origin.join(file.file_name()); fs::copy(file.path(), destination)?; } }, None =&gt; () }; becomes if let Some(val) = path.extension() { if file_extensions.contains(&amp;val) { let destination = origin.join(file.file_name()); fs::copy(file.path(), destination)?; } } &amp;#x200B; This type of block: let title = match tag.get_vorbis("title") { Some(t) =&gt; t[0].clone(), None =&gt; return Err(String::from(format!("failed to get song title"))), }; can be written functionally if you prefer it (really preference only) and then a ? to selectively return an Err swap\_remove can be used to avoid a clone/allocation let title = tag.get_vorbis("title") .map(|t| t.swap_remove(0)) .ok_or(format!("failed to get song title for file: {}", path))?; &amp;#x200B; Maybe change if let Err(e) = fs::rename(file.path(), destination) { return Err(format!("{}", e)); } to fs::rename(file.path(), destination).map_err(|e| format!("{}", e))?; &amp;#x200B; &amp;#x200B; Consider changing let (files, _folders) = match scan_path(origin) { Ok((fi, fo)) =&gt; (fi, fo), Err(e) =&gt; panic!("ERROR: {}", e) }; to let (files, _folders) = scan_path(origin).expect("ERROR"); as Result::expect() already prints a custom message and the Err value. &amp;#x200B; All in all that's some good rust code!
Thank you. This was extremely helpful. Particularly your advice on 'if let' and functional alternatives. I also didn't realise that expect prints the Err value too!
Thanks for your work on this, i'm eager to try out tantivy (once tantivy can score by fuzziness) :)
&gt;People would go crazy if every float divide by zero caused an interrupt and crashed a program. Especially since it can happen when you have value that are different than zero but are rounded to zero because they underflow the precision. So you would have to check every divisor in your code and that would impact every high performance piece of code. I enable floating point exceptions in my code so that e.g. dividing by zero creates a fault and a useful stack trace. It doesn't drive me crazy; on the contrary, it keeps me sane. An operation producing an infinity or a NaN is almost always a bug, so an immediate panic/crash is the appropriate and most useful response.
I'm unsure you can do that, box can't be null doesn't mean the inner pointer can't be zero. How do you expect fat pointer be handle ?
Interesting. You wouldn't happen to have some good resources I could look at about writing fast code in rust, would you?
If I have an FFI function that takes a [`FILE *`](https://docs.rs/libc/0.2.59/libc/enum.FILE.html), how do I pass stdout to it? For example, if [`puts`](https://docs.rs/libc/0.2.59/libc/fn.puts.html) did not exist, how would I achieve the same result using [`fputs`](https://docs.rs/libc/0.2.59/libc/fn.fputs.html)?
You might want to run [rustfmt](https://github.com/rust-lang/rustfmt) (it would like to change a few lines in your code) and the linter [clippy](https://github.com/rust-lang/rust-clippy). Notably clippy points out the `String::from(format!(` and the `match` shortened into a `if let`. It also isn't happy when you use `write()` and `read()` without handling the amount returned.
You definitely can, and it’s pretty easy in Rust, just as in C/C++. It’s just that people would also have to write the underlying libraries. And it seems like the interest there is relatively small in the Rust community at the moment.
Being null and being zero mean the same thing when talking about pointers. For fat pointers, this only applies to the "data" part, not the metadata (slice length or vtable pointer).
I run a KDB cluster, but haven’t considered using rust to manage it. My interest is more along the lines of using rust to optimize some low level stuff for text processing that kdb stinks at. Would you be able to tell me a bit more how your rust integration worked? If you can’t discuss it publicly, I’d be interested in going offline or something.
Do you know about [std::panic::catch_unwind](https://doc.rust-lang.org/std/panic/fn.catch_unwind.html)? Just checking; it sounds like you're presenting a simplified view of the situation.
One would think, but most scientific applications I've encountered are riddled with subtle bugs and people either don't notice or don't care. The kind of numerical programming that we do is very different from most other software; we're implementing approximations of the real world that are known to be somewhat incorrect already (sometimes scholastically) and sometimes the right answer isn't even known.
If you only need a checker for integer problems, ubsan is there for you. It can even check for over/underflow of unsigned integers (which is well-defined in C and C++). Of course it's not on by default but it's a lot easier to add a flag to your build than RIIR.
I think Rust is a good replacement for Python, because: * It has indexing. * It has type safety: Correct if wrong, const generics would make us able to check the correctness of dimensions of the input to a deep learning layer. * Python's autocompletion is worse that Rust's (Correct, if wrong). I think the only thing that lacks Rust is libraries.
The whole idea of the crate is to aid **code generation** for message serialization/deserialization. Could be used to generate code for the traditional text-based FIX, FIXML, SBE, etc. This is [what the QuickFix engine does](https://github.com/quickfix/quickfix/tree/master/spec).
Yep!
There is the [Rust machine learning working group](https://github.com/rust-lang/wg-governance/issues/11).
&gt; An operation producing an infinity or a NaN is almost always a bug, so an immediate panic/crash is the appropriate and most useful response. **almost** is the keyword here, there are a lot of commonly used mathematical function which have undefined point or asymptotic behaviors. NaN, +Inf, -Inf all have a meaning in those context and tell you something about the input to your function. Also do you really want to crash? Is that a sane behavior in the presence of inputs you might not control? If you want to check the computation you can always check the end result with [is_finite()](https://doc.rust-lang.org/std/primitive.f32.html#method.is_finite).
The parent's syntax is just slighty off, it needs to be \`Expression(Expression)\` or \`Expression { expr: Expression }\`. One is like a tuple, one is like a struct.
I don't think box has an 'inner pointer' and is, by itself, a standard pointer (maybe unless you are using unsized types or trait objects, I'm not sure how it works in that case). So the idea is the Enum is you can either have variant A with one nonzero pointer, it variant B with two nonzero pointers. The Enum type itself must be big enough to fit two pointers, even in the case of variant A, so the optimization would be to make the second pointer zero for variant A (since A only uses one pointer, the second does not need to be valid), and simply check that pointer to determine if you have variant A or B
Is it [this one](https://www.youtube.com/watch?v=1aDLYFBuWc8)? I haven't watched the video yet.
&gt; Obviously there should be an error/overflow/whatever bit. Like a nice atomic Result&lt;T,E&gt; :) Well good news! That bit does exist! And it’s not even in a architecture specific register but directly encoded inside the number itself so its cross platform! Yes I’m talking about NaN, +Inf and -Inf... Your problem seems mostly about the abstraction you have over float in Rust rather than the IEEE754 format. And, in any case, such abstraction can only be provided using expensive conditional checks that only makes sense outside of the standard library in separate crate as pointed out by other redditors.
 [https://crates.io/crates/noisy\_float](https://crates.io/crates/noisy_float) i sone of them
As the windows api only re-enters at well defined points (i.e. calls back into the windows api), on the same thread it's probabally fine. However it is not async-signal-safe. Personally I'm of the opinion "if you have to ask, why do it?" here though.
That could indeed work but this require so much work from the compiler side, detect this kind of case must be very complex.
You can construct a file pointer from it: let fileno = libc::STDOUT_FILENO; let mode = std::ffi::CStr::from_bytes_with_nul_unchecked(b"w\0").as_ptr(); let mut file: *mut libc::FILE = libc::fdopen(fileno, mode);
This is pretty interesting. Is there an explanation somewhere on why the switch away from actors?
I think the [Rust Cookbook](https://rust-lang-nursery.github.io/rust-cookbook/) is the closest thing, but it's not as coherent or entertaining as anything Al Sweigart writes. On a semi-related note, I have started working on a version of [The Flask Mega-tutorial](https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world), but written for `actix-web`. It is a long ways (maybe 2-3 weeks) from being done though.
There's no reason to use it over Python unless it's for extremely high-frequency trading (as in, where milliseconds matter). Additionally, most existing libraries for retail algo trading target Python.
Sorry, I forgot that code fences don't work on old/mobile reddit. Should be fixed.
1. Depends on your network configuration. &lt;500bytes should basically always work and typically ~1kb is fine 2. A binary serialization method or some custom binary packet format
You can use algebra to rearrange the layout of the types, although I'm not saying it would be easy to implement in rustc. `()` behaves like 1, `!` behaves like 0, enums behave like addition of types, and structs/tuples like multiplication (i.e. they form a Semiring). So if `x` is `Box&lt;String&gt;`, you'd write the type as `x + x*x`, then factor out an `x` to give `x(1 + x)`. `1 + x` is an `Option&lt;x&gt;` (1 is like `None`) so you end up with a struct of a `Box` and an `Option&lt;Box&gt;` like /u/Shadow0133 suggests.
Exactly, "almost," so the default should be to crash. In the other cases, you add a guard so the exceptional case is handled correctly. You should be validating inputs, not blindly processing them and generating NaNs.
You don't see rust as "C level"?
In some abstract sense, everything would benefit running on smaller servers and serve the same or more users, but there is diminishing returns vs just scaling horizontally. For most applications, hardware is cheap enough.
Thanks for this link -- I understand completely now
Thanks for the explanation -- I understand now, I definitely missed this development.
That's an ambitious project, good luck!
Your statement about compile times is interesting to me. How big are your Rust projects, and how long did your comparable C++ projects take to build? Also, are you employed somewhere that uses Rust, or doing it on your own time (for fun or profit)?
I meant dropping down to unsafe C syntax, not C's level. Sorry. Fixed the comment as well.
3 31st seems 2Ed exude school 2
Got you -- thanks for explaining this!
Currently tearing my hair out over [this code](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=a40894ffe5dad5a127aa49d8c86f148c)'s lifetime errors. Details are provided as code comments. Any help at all would be appreciated.
&gt; Sorry if this is becoming spam since I saw someone else also request a code review. If it is, I will remove this post immediately. Welcome to Rust! Requesting code reviews is great, but you should also be aware of /r/learnrust, which is sometimes a better venue for this kind of review: it is a good place in general.
The technical reasons for switching from c++ to Rust are compelling for a hobbyist but, at the end of the day, you have to demonstrate the switch to Rust makes business sense. The question you should ask is, will the savings realized due to the technical advantages of switching to Rust outweigh the costs of migrating off c++?
Great question! You might also want to check out /r/learnrust, which is another great place for this kind of thing.
Yes, but I can horizontally scale any framework basically infinitely. Money doesn't really matters because hardware is so cheap. In my day job I work on a Node.js websocket application that can only handle ~1000 concurrent users per host. But so what? We scale up to 40, 50, 80 c5.large instances without problem which is a drop in the bucket for the millions in revenue in helps bring.
it is a patch, not a fix; it does not fix dependency hell for you. yes yes, you could use X, Y, Z, W, etc.. but nothing is centralized, so if you will end up restricting what you use or mix together different build/dependency system with all the issue connected. One mediocre centralized tool would be better than hundred of good one (and you can still have the good one, that maybe repackage the mediocre ones, and get enough traction and get elected new standard..)
I see. I guess ultimately, when I look at Rust code, it seems to be the wrong level of abstraction for building APIs and webstuff. But people in this thread seem to think otherwise, and I'm trying hard to understand that perspective as mainly somebody who writes backend JavaScript/TypeScript where it's all about developer productivity.
Nice, my 1 word contribution there. I'd like to ideally in the future work on making the IndexMeta and SegmentReaders perhaps have a more public API
Rust has a wide range of levels. So while it can drop down to C level unsafe bit munging, it can also stay at a very high level, arguably a higher level then languages like Java or Go.
It's cheap because you have millions of revenue. The win here is Rust has some ergonomic language features yet is so competitive that you happen to save on compute which frees you up to pack servers. We run literally thousands of spring boot web servers and would probably spend 1/10 as much if it were written in rust (only considering server costs, I don't want to get into development costs)
As far as I know, the Rust compiler has never been capable of running on Windows XP. I can't remember whether it was Vista or 7 that was the minimum requirement though. I do know that it's not currently capable of it. (If you look at the [platform support matrix](https://forge.rust-lang.org/platform-support.html), you'll see under Tier 3 that `std` can be built for XP (meaning you can compile code to target XP) but `rustc` and `cargo` can't.
Oh I obviously agree, but there are times where raw productivity is the goal and having bugs isn't a big deal. I try not to work on those projects.
I mean late arrivals in the sense that the libraries that made Python synonymous with scientific computing, machine learning, etc. didn’t mature and weren’t popularized until Python was already pretty old as far as languages go.
To annotate calls, you need a heavy runtime which can interrupt and resume arbitrary functions. If you annotate functions, then the compiler can transform them into structs conceptually similar to Python generators behind the scenes, meaning no heavy runtime is needed.
The basics for high performance code are pretty much the same for every language: use the right algorithm, don't allocate a lot of small objects on the heap, keep the number of memory indirections low. The points I mentioned about Rust are the ones where the language supports you writing fast code.
Is there are roadmap for what features you want to go into tantivy and when we will get a 1.0 release ? Are you aiming for feature parity with Lucene with a few extras like wasm [https://github.com/tantivy-search/tantivy/issues/541](https://github.com/tantivy-search/tantivy/issues/541) ? Having a stable index format and up to date docs could be huge for adoption. I say this because I tried [https://fulmicoton.com/tantivy-examples/simple\_search.html](https://fulmicoton.com/tantivy-examples/simple_search.html) this article which is linked off the github page under "getting started" and it doesn't compile so required a bit of tweaking to get working.
I don't understand what you mean by "probably fine." Do you mean like mem::uninitialized, where there are no known crashes or CVE's assigned to it, or like MaybeUninitialized, where it's consistent with the safety guarantees of the language if used properly? In any case, I'm poking at this now partly because I see potential panics from nested `RefCell::borrow_mut` calls in my current code. One case where this could happen is if an event handler (holding a borrow) pops up a file dialog, then inside the file dialog's event loop is a WM_PAINT on one of the app's window. If the nested borrow is safe, then the way to fix it is to just materialize an `&amp;mut` reference and pass that to the handler. If it is not, then I need to change most of the `borrow_mut` to `try_borrow_mut` and do some other mitigations to reduce the likelihood and impact of that happening. There's some more discussion in a [Zulip thread](https://xi.zulipchat.com/#narrow/stream/147926-druid/topic/interior.20mutability.20in.20druid-shell.20interface) (xi Zulip login required).
&gt; since I don't think Rust supports expression templates I would expect it does, actually. Expression Templates are pretty basic as far as generic programming. Here is an example using specialization which reduces an Expression Template struct at compile-time: https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=b36d8599f7febd1fe347234f0bfaf258 . I think it would be possible to do something similar without specialization, using special Reduction traits for introspection. &gt; Random practical example from some code I wrote recently. [...] In Rust I would expect to use serialization, or equivalent, to build the struct from a file. Or, if you insist on manual parsing, this is simply a job for the `From` trait: T::from(my_config) Or a custom FromConfig trait will perfectly handle the fact that each `T` is built in a slightly different way than another.
I’d love to see Rust define a “MISRA Rust” and also build something like Ada’s SPARK for Rust, if something enterprising auto manufacturer built this it would push embedded Rust to the forefront in many new projects. The problem is that the many (the majority?) embedded developers come from non-CS backgrounds and are unlikely to advocate for anything non-C (the standard in EE programs).
[Playground with fix](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=4717230a3b7e74662fd72e83fd9a81c8). Explanation follows soon with an edit.
Aaah, I didn't think of that. Well. I'll stick to Javascript then and only start Rust when I'm back at my own rig.
That's very old news, and was already posted.
Why isn’t this macro just parameterized?
Thanks so much, but I'm afraid it doesn't fit the requirements :( As mentioned at the top of the first playground link, I need the closure to support arbitrary lifetimes for its arguments, since it might need to be stored elsewhere and called at some indefinite point in the future. See the error [here](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=dbc63257d7a556db3335096678095e3d).
But virtually the same technique that works with `async` annotated definitions should work with annotated calls: if the compiler cannot eliminate the possibility that a function will ever be called asynchronously, it is enough to compile that function's definition twice -- into an ordinary function and into a generator-like object, and then use the appropriate one depending on how that function is called. &amp;#x200B; What bothers me with annotating definitions is that if the same function may be called both synchronously and asynchronously, it needs to be defined twice: the same code once with `async` and once without.
&gt; High frequency trading systems are a different story, and these systems tend to be optimized to the point of memory access and assembly. This requires a lot of manual allocations and unsafe code. Not really. You can achieve single-digits microseconds reactions in software with a relatively small trusting base; and for anything faster you'll need FPGAs (or ASICs). &gt; FIX, the protocol virtually every exchange is using, is a stateful protocol and requires an engine to work. Having written my fair share of protocols and protocol handlers in the last year, including FIX ones, there's nothing that I see that Rust could not do. I'd personally wait on const generics for ease of use, but that's more to stave off objections than for actual performance reasons; large arrays are not used *that* often, and the few that exist can (and should) probably be handled as slices.
I'm not exactly an expert, but I'm currently writing a game with lua scripting support and have pretty much the same situation (lua calls rust functions that can call back into lua etc etc etc). I think it's not just "technically UB" because it can cause very real problems like reference invalidation. For example if you hold a reference into vector, call the reentrant procedure, and somewhere down the line push stuff into the above vector (which nothing is preventing you from doing). If you're already using interior mutability and it works fine, I would recomment to just keep it as is.
Very true. I attempt to be very balanced in my presentation of Rust's advantages. For example, it's debugging story is not as convenient as most other languages, and I am upfront with my team about this. Rust has so much going for it, but you have to be honest about it's rough edges.
I wish. At least in Europe, Eurex (the leading exchange) is using its own homemade protocol; essentially "structs" that are written as is on the wire. Euronext (second behind Eurex) is using SBE for its feed dissemination and half its orders (Cash), and the next half (Derivatives) should migrate toward the end of the year (Nov 25th).
I have already tested that design the problem with it is that without seconds the site becomes completely static. Seeing the seconds tick down gives nice live effect. Also I know it probably not your intention, however saying a design "could use some work" implies that didn't spend hours thinking and testing the design of the date formats. Just because it isn't in the final design, doesn't mean I didn't try it. :)
Here is my fix for your lifetime errors: https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=dc5e4c0e73da9d204b5b77f798ae2b03 Because the lifetimes of T and CreateFromI32Ref are not tied together in this line in your version: T: std::fmt::Debug + for&lt;'a&gt; CreateFromI32Ref&lt;'a&gt; it could cause problems for some implementations of make_closure and CreateFromI32Ref (perhaps with references not living long enough? I cannot generate an example).
ya, i really like the script and having a readme as suggested could be really helpful
It may also be worth mentioning that type inference is *specifically excluded* from the backward compatibility guarantees. As a result, it's expected that such papercuts may occur from time to time when upgrading.
Touche, wasn't my intention. Sorry about that.
I was having this same annoyances in GXI with GTK. Some calls to GTK would re-enter my main loop and my `Rc` pointers would panic because they were attempting to get a mutable reference twice. I had to remember which calls were reentrant and make sure nothing was borrowed during those calls. I felt like I was programming in a minefield. What's the concern with your unsafe &amp;mut reference? Is it that maybe optimizations will assume that the data never changes, since there's a &amp;mut reference out? I don't know the answer to this question. I'd be more interested in thinking through ways to avoid this problem entirely. It seems like what you need is to grab mutable references for only short periods where you need it, right? Is this a case where array indexes, or a data oriented design, would help get rid of the interior mutability?
I'm sorry, but that doesn't fit the requirements, because the closure can't accept arguments with arbitrary lifetimes :( Please see [this comment](https://www.reddit.com/r/rust/comments/cag8hc/hey_rustaceans_got_an_easy_question_ask_here/etj10uo/).
I don't have an answer, but I can say numerical works is pretty cumbersome in Rust. I write embedded Rust for a living just fine. But, when I first started with the langue I attempted writing some generic DSP/SDR code. It just turned into what I call 'trait constraint pollution'.
And there's the whole state thing to consider. Horizontally scaling a stateless service is easy for developers, though already harder on operations. Horizontally scaling a stateful service, ah! I've got so many war stories from distributed systems gone wrong; both on the developer and operator side. When I see people say "I'll just add a second server" casually, I cannot help but shudder. The second server is the hardest. Once you have 50, +1 is a cinch. But from 1 to 2? Oh boy, you're about to discover all the fun bugs you never thought about...
&gt; I just disagree with your assertion that no serious robotics research can be done in Rust, particularly since I am doing serious robotics research with Rust as my primary language. I think it depends on your priorities as a researcher as well as research area. Without the efforts I mentioned, Rust isn't "batteries included" in terms of computer vision and scientific computing in general, but people sufficiently motivated to use Rust will be able to use existing libraries like nalgebra, sure. For me the choice of language is secondary to making sure my code is as useful to the research community as possible when it's released, if there isn't enough reason for many people to use Rust then my code becomes much less useful in that regard. It's a bit of a chicken-and-egg problem but I do really think a comprehensive scientific computing environment is a prerequisite for any kind of serious uptake of Rust in research.
&gt; On the other hand, the closer things like const generics and mature simd support get, the better positioned Rust becomes for something like Eigen to be written (but *with much more straightforward implementation than fancy template meta programming*). I am very excited to see something like this come out in the next few years :)
&gt;I am no Rust fanboy and even refer people to C/C++ based on what they want to do but as far as I understand there is nothing right now that prevents you from using Rust for scientific computing from the language perspective. You can write your own struct if you want to change array addressing from row major to column major. It's more about the lack of libraries - I'd have to reimplement very large ecosystem (many hundreds of KLOC) to be able to get the same functionality that I have in C++ right now. Rust needs to be adopted by large (research) organizations before that happens.
If you're on Unix, you could just print a bunch of [ANSI escape codes](https://en.wikipedia.org/wiki/ANSI_escape_code).
I don't think anything will replace Python as a ML and deep learning frontend in the near future (5+ years). This is more about replacing that C++ backend.
If it calls out to asynchronous code, then it shouldn't be used synchronously to begin with. If the function doesn't contain any io, then there's no point in making it async. Either the function needs to wait for outside input, or it doesn't; there isn't much middle ground.
Is your DSP code usually written in C? I'd be really interested to hear more about stumbling blocks on writing the same kind of logic in Rust. If you try to make your implementations less generic (more C-like) is it a lot easier?
The main issue of C++ is that the C++ committee has always been focused on the language, and never really cared for the tooling: build systems, package managers, ... In fact, the very idea of a standard *build file* or *package manifesto* cause outcry in the C++ community! The result is the current landscape: - A variety of build systems, although CMake lead. - Overly complicated build systems, leading to a variety of styles even within a single build system ecosystem. - No widely used package manager; and no, distributions are not a cure, they're for end-users not developers. Getting a package usually means downloading a ZIP or TAR. It's actually pretty easy to check: go to a random github project, the README generally contains instructions on how to install... they're long-winded, vary per platform, and will fail half-way through more often than not. It's so ridiculous that in my experience the best way after downloading a dependency is to simply purge its build system and rewrite it yourself: this way you ensure it follows the standards you are used to, and integrates well with the rest of your code. Needless to say, this doesn't scale. Which results in two attitudes: - Header-only libraries: just copy/paste in the folder of your choice, you're good to go. Won't help your poor compile times, but you can't get everything, eh? - Not Invented Here syndrome: rather than deal with all that crap, it's often easier to just re-implement the bit of functionality yourself. It'll be quicker to fix the bugs than to try and integrate the next version of the library anyway. The only exceptions are libraries that are judged worth it. Typically Boost, or lately Abseil, where people actually make the effort because the benefits outweigh the costs by a large margin.
You can get by using ANSI escape codes directly, but I like to point people towards the [Termion](https://github.com/redox-os/termion) crate, which provides an abstraction over that, as well as many other terminal features.
Basically, print is writing to io::stdout using https://doc.rust-lang.org/std/fmt/index.html to format the strong you presented. Which supports K900_s answer.
Would love to read that. Please share it here when it's done
This answer deserved the stack overflow checkmark
My current code is "working fine," as there are panics when doing fancy things, and I've just reproduced one - from druid master, do `cargo run --example sample`, open file, then do a dynamic monitor change, then `thread 'main' panicked at 'already borrowed: BorrowMutError'`. And to be clear I think what *winit* is doing is only "technically UB", because it's not doing significant direct mutation to the struct, when deferring to user code it's always doing a RefCell borrow. I do think you can construct a scenario like reference invalidation. Again, I'd love an expert opinion because some people are saying it's fine, and I really want to understand where the line is.
I’ve written this same code in JavaScript using its async generators. Had to do some pretty weird stuff to optimize it. It’s great to see it’s coming to Rust with fewer pitfalls!
Do you actually need full-blown PKI with certs and stuff, or just public-private keypair authentication? For latter maybe [snow](https://github.com/mcginty/snow) could work?
Hmm, I don't know if this is type-able/well-typed. In some cases the lifetime of T matters. In `make_closure`, the lifetime of T is already fixed/decided by the caller. So if you call the function with the type argument `&amp;i32`, its lifetime does not seem to be late-bound by the call of the returned closure (lifetime 'a) but is already known/set/inferred: `for&lt;'k&gt; &amp;'k i32`. So, the LT of the closure param is 'a. 'k and 'a are uncorrelated and we cannot force them into a relation, at least [I could not](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=69fdd95005122922fd10f116f1cab226). The error rustc gives is completely valid (of course), I don't know how else you could model it though. I mean, you state that you accept any T (implicitly any T: 'k) which must be constructible from &amp;'a i32 for any 'a. Suddenly, you'd like to create a &amp;'a i32 from a &amp;'a i32 but there is no implementation for that as you require any &amp;'a i32 for all 'a to be convertible into a &amp;'k i32 for some 'k chosen earlier. You'd need to move the parameter T into the closure but those cannot be polymorphic yet — yes, I think HRTB are going to solve this. I don't exactly if this is correct but the return type should be `Box&lt;dyn for&lt;'a, T: 'a + Debug + CreateFromI32Ref&lt;'a&gt;&gt; Fn(&amp;'a i32)&gt;`. T seems unconstrained because it's only used inside of the body, not sure if this is gonna be problem. Would this be object-safe? Idk
I don’t think that’s true, especially for a domain where the original primary langage dates back to the origins of computing itself.
I like the yansi crate when all I need is colored output. It's one tiny library and pretty simple to use.
&gt; from a *const pointer to an &amp;self reference and then rely on interior mutability That might work, even if windows mutates the window state behind your back. As long as all mutations happen from a single thread. &gt; Someone on #winapi irc said that it would be valid to do this as mut, that the recursive call could be considered the same original borrow. At some point in the execution of your program, do two `&amp;mut` to the window object exist, that can be independently used to access the object ? If not, you are ok. Otherwise, you have UB.
If you don't get a good answer here, I'd ask ralfjung on the rust-lang zulip or open an issue on the unsafe code guildelines repo. I think this is one of the many edge cases which 1. Work in practice 2. Aren't allowed under the current proposed semantics (if I understand the state of the art w.r.t. stacked borrows etc.) 3. Could and possibly should work with a modification to the proposed semantics. So I think a discussion on the unsafe code guidelines would be productive.
&gt; How big are your Rust projects ~100 LOC. &gt; and how long did your comparable C++ projects take to build? Build from scratch, 3~4 minutes for C++. Similar project Rust project, build from scratch, ~1 minute. Small change after full build in C++, ~&gt;1 minute, sometimes over 2-3, depending on the change. Rust &lt; ~20 seconds, independently of the change.
As far as I can tell, termion doesn't support Windows, so I would not point people towards it, unless they explicitly are developing a Unix-only application. If you want a terse API, don't care about performance and don't care about Windows &lt;10 support, then [ansi_term](https://crates.io/crates/ansi_term) seems to be what folks use. Otherwise, use [termcolor](https://crates.io/crates/termcolor).
There are two methods in scope that this could resolve to, so the compiler doesn't know which one you want it to pick. You need to disambiguate, unambiguously spelling which method you want. If you want to avoid such errors in the future, disambiguate your method calls.
"Hardware conscious" software doesn't have to mean low-level. I think it got a bad rap because all anyone can compare it to is C, which is terrible at building abstractions or C++ which is quite difficult to use correctly and punishes you way worse when you get things wrong. If your operating costs are not your main expense and application complexity is not your main productivity bottleneck, then it's fine to go with something slower and more dynamic for the sake of developer ergonomics. If shaving a few % off of operating costs would pay for your entire department, then investing in more efficient implementations makes a lot of sense. This is why the majority of people that still use C++ for writing backends are doing so.
The closest I've come to a solution over the last hour is: trait CreateFromI32Ref { fn create_from_i32_ref&lt;'a&gt;(i32_ref: &amp;'a i32) where 'a: 'self; } This would solve the problem instantly (I'm pretty certain that the closure's body would typecheck?), but unfortunately the `'self` lifetime doesn't exist yet 🙃. In general, there doesn't seem to be any way to restrict a lifetime to outlive a type, rather than the other way around.
I have an application with Lua scripting. I ended up structuring it so that rust code never calls Lua. Instead Lua is running the main loop and calling into the rust core, which returns events rather than calling Lua callbacks. Works well for me now, but might not for other applications.
Your example with `'self` looks reasonable. Trying to implement it [failed though](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=9bf80a8ed9343f98771df7d3b88eb4b9). I am certain I modeled `'self` correctly with `'self_`.
In the domain of machine learning (and computer vision), the dominant research language was Matlab until ~2012. Matlab is only 6 years older than Python.
Not quite: The constraint I was trying to express was "`'a` must outlive all references stored in `Self`". The constraints you're expressing are "All references stored in `Self` must outlive `'_self`, and `'a` must outlive `'_self`". So in your case, it would be possible for some reference in `Self` to outlive `'a`.
Still better than fix tags :)
cc /u/burntsushi Thank you very much. The Ansi Escape Codes were everything I needed for now: println!("\x1B[36m{}\x1B[0m", al.to_string()); works as desired. Thank you verymuch.
Yeah, I considered doing this, but I have some cases where events won't suffice. For example, loading entities cached to file can execute lua code, but it can't be done by emitting an event because the data is required right now. I'm currently trying to write a monad-like thing that allows releasing borrows before calling lua and then getting them back, but it honestly feels like overengineering to me (fun overengineering but still). I'll probably end up using events, but it will limit what lua can do.
An ordinary function executes synchronously. What would calling this with `async` achieve? At best you would get a future that you can then execute later - but when you do, the original function executes synchronously anyway. There's also API compatibility issues to consider. Turning a "sync" function into `async` is a breaking change. Having that specified on the function level makes it clear when that change happens. If the change was based only on "whether the function contains an `async` somewhere within its 300-line body or any of the macros" makes that change really difficult to track. Admittedly I don't know much (anything?) about Go's implementation. Based on your comment it seems there's a lot more 'magic' going on behind the scenes with the program's runtime behavior changing based on a lot of small (and perhaps surprising) details in its codebase. Something Rust has been trying to avoid.
For me the worst part of FIX is not the tags, it's encoding numbers in ASCII. Especially when prices are encoded as decimals, and thus as two numbers :/
Actually in web context if you have already secure TLS connection, you could probably do just simple signature-based challenge-response authentication.
The only correct way to have one `&amp;mut T` in a caller and a second `&amp;mut T` in a(n indirect) callee is for the second to be a reborrow of the first. I suspect you could make this work by passing an actual reborrow into any and all APIs that reenter your window procedure, though I would double check with Ralf that rematerializing the `&amp;mut T` after crossing back into Rust doesn't break Stacked Borrows.
Not necessarily. Even if the outer `&amp;mut` cannot be used to access the object while the inner `&amp;mut` exists, the optimizer will assume that nothing can invalidate the outer `&amp;mut` during the API call that reenters the window procedure, leading to miscompilations.
No, that's from 2015. It was around the time this benchmark came out: https://www.ageofascent.com/2019/02/04/asp-net-core-saturating-10gbe-at-7-million-requests-per-second/ I remember them mentioning actix-raw, and that it was probably a very optimized version of actix, and that it's cool that they ranked so close to it. Here's one of the videos where they talk about creating smaller optimized platform tests to rank higher, but it's not the video I was initially referring to. https://www.youtube.com/watch?v=8GrXNE8ehLY&amp;feature=youtu.be&amp;t=2079
The implementation of `Future::map` you provide (`f(future.await)`) is eager instead of lazy, which to my mind significantly reduces its usefulness. I’m wondering, though, if there’s a reason I’m not seeing that a lazy `map` has to be so ugly. Maybe it has to do with `impl Trait` leaking auto traits?
How exciting! How exciting!
I'm in humanoid robotics, and I don't think that some core C++ computations can be replaced by anything. &amp;#x200B; But if we can show to the community that we can still call C++ libs when unlimited performances are needed, and be called by python to teach, script and prototype, there is a lot of room to replace C++ libraries that would greatly benefit from rust tooling and safety.
Have you tried IntelliJ Rust ? I’ve used vscode for rust since before the rls but I recently switched to IntelliJ and it’s been quite pleasant. The visible inferred types and trait method generation are pretty fun. Might want to install the vscode keymap plugin though. That was the biggest pain I had at first.
Will Rust move to consoles like the Xbox and PlayStation im curious because atm I dont have tge money to buy a gaming pc. I woupd love to play this game
So `Option&lt;bool&gt;` is not optimized?
Why do you think this implementation is eager? This is quite the same as [https://rust-lang-nursery.github.io/futures-api-docs/0.3.0-alpha.17/src/futures\_util/future/map.rs.html#30-46](https://rust-lang-nursery.github.io/futures-api-docs/0.3.0-alpha.17/src/futures_util/future/map.rs.html#30-46).
`Option&lt;bool&gt;` *is* optimized, but not by NPO: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=5b0fdbab3faa716102891851754e0439
My guess is that the average science and engineering person who just needs to crunch numbers isn't going to switch to Rust. Rust will become important if someone decides that a numerical algebra library or similar numerical nuts and bolts will be easier to maintain in Rust than in C/C++/Fortran.
Woah, this is neat. Are there any known algorithms for finding "desirable" transformations, kinda like SMTs?
&gt;Someone on #winapi irc said that it would be valid to do this as `mut`, that the recursive call could be considered the same original borrow. I'm very skeptical of this and would like an expert opinion. Your skepticism is well-placed. The act of materializing a `&amp;mut` from a raw pointer when another already exists is instant UB. No exceptions. Passing a `&amp;mut` down the call stack preserves the original borrow, since the compiler can see it happen. But this different, even if it's the same value that's being mutated. On the other hand, it will probably work fine in 99% of cases. What might happen in theory is that the compiler can elide loads and stores to the state, so that the outer call might not see mutations made by the re-entering call, or vice-versa. And it can reorder stores, so you might see newer data being mysteriously overwritten by older data. But unless you're mutating the data frequently and there are frequent re-entries, my gut feeling is that you're unlikely to see these bugs irl. Anyway, TL/DR: Your code seems sound to me. But the `winit` example isn't, if the crate ever does anything that causes re-entry. Also, if you're not familiar with `UnsafeCell`, you should probably look it up. It's the most flexible (and most dangerous) form of interior mutability Rust has. It behaves essentially identical to what you would do in C, which makes it good for interop. But if a plain old `Cell` works for your use case, then that is obviously easier to use.
I think your first link might be incorrect. It's going to a fork of dialoguer.
Not the same, as having the polling within `impl Future for Map` (type parameters elided due to laziness; I’m on mobile) means that polling the `Map` polls the internal future, which makes perfect sense. Having `fut.await` within the `map` function itself causes the future to be polled *when `map` is called*. The distinction is subtle, but important: if you’re making a library crate, you may want to return raw futures without relying on the presence of an executor, etc. That is, you want to return an object which implements `Future` (i.e. `poll`), without actually executing any async code. In the code you’ve provided, the future is consumed and then the transformation is applied; in the existing version, a future is provided that promises to eventually perform that transformation once it gets the input data (the results of the `map`ped future), with no implicit execution of async code.
100 LoC doesn't sound like it would be enough to draw any conclusions; do you mean kLoC?
Thanks ! I have changed the link :)
You're not correct. Map is an async function, it returns a future, and polling that future polls the future awaited inside of it. It is not eager.
I have a function that wants a range of strings: fn read_range&lt;'d, 'r&gt;(&amp;'d self, range: RB) -&gt; KeyReader&lt;'d, 'r, RB&gt; where RB: std::ops::RangeBounds&lt;&amp;'r str&gt; + Clone Of course, I can call this function as simply as `d.read_range("aardvark" .. "zzyzx")`. But if I how a `Cow&lt;'_, &amp;str&gt;` it all falls apart. The compiler refuses to turn that Cow into a `&amp;str`: let s = String::from_utf8_lossy(b"aaron aaronson"); // XXX d.read_range( s .. ); // ^^^^^^^^^^ the trait `std::ops::RangeBounds&lt;&amp;str&gt;` is not implemented for `std::ops::RangeFrom&lt;std::borrow::Cow&lt;'_, str&gt;&gt;` So I made the function accept a range with `AsRef&lt;str&gt;`: fn get_range&lt;'d, 'r, RB, RBR, S&gt;(&amp;'d self, range: RB) -&gt; KeyReader&lt;'d, 'r, RBR&gt; where RBR: std::ops::RangeBounds&lt;&amp;'r str&gt; + Clone, RB: std::ops::RangeBounds&lt;S&gt; + Clone, S: AsRef&lt;str&gt; + 'r, But now I don't know how to turn that `RangeBounds&lt;AsRef&lt;str&gt;&gt;` into a `RangeBounds&lt;&amp;str&gt;` as needed internally. How do I do that? (don't say make all my internals require `RangeBounds&lt;AsRef&lt;str&gt;&gt;`, as I would like to contain the complexity to one place.
Any ideas why actix-diesel is so much lower on the list? Does Diesel really add that much additional overhead?
&gt; Having fut.await within the map function itself causes the future to be polled when map is called. I have never heard of such behaviour. Where did you get it? I wrote a simple counter example: #![feature(async_await)] use futures_async_combinators::future::*; use futures::executor; async fn rand() -&gt; i32 { println!("here I am"); 42 } fn main() { let future = rand(); let future = map(future, |x| x + 1); println!("before"); executor::block_on(future); } And the output is: $ cargo run Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/futures-async-combinators` before here I am &gt; you may want to return raw futures without relying on the presence of an executor, etc Indeed my library does not rely on the presence of an executor at all. The only reason why I added futures-rs as a dependency is because there is no Stream defined in std. Also my tests are identical to the examples from futures-rs, see https://docs.rs/futures-preview/0.3.0-alpha.17/futures/future/trait.FutureExt.html#method.map vs https://github.com/kpp/futures-async-combinators/blob/master/src/future.rs#L165. The behaviour of my implementation is the same.
Thanks!
You’re on the wrong subreddit, try /r/rust
Will rust move to consoles??
I guess that if you provided more information about what problem do you try to solve, it'd be easier for us to help you.
Let me add my encouragement to this project. Is there a place to follow your actix-web mega-tutorial?
You can use this trick today (works with `Result` too): || -&gt; Option&lt;_&gt; { foo()?; bar() }()
What computations do you think must be done in C++, and why?
I have a function like `begin(bound: std::ops::Bound&lt;&amp;str&gt;)` I also have a function like `search&lt;RB&gt;(bound: RB) where RB: RangeBounds&lt;&amp;str&gt;` if I want `search` to call `begin(bound.start_bound())` I get a number of problems. For one thing, `start_bound()` returns a `Bound&lt;&amp;&amp;str&gt;` ??? Wtf! Secondly, if I want `search` to accept `AsRef&lt;str&gt;`, so that I could, for example `search` on `Cow` strings: let s = String::from_utf8_lossy(b"aardvark"); search( s .. ); Then it looks like the `search` function needs to decompose the RangeBounds and create a new `Bound` object. That's extremely tedious. Is there a simpler way? [homer simpson squeezing an orange with his head]
Ok, based on the very helpful responses, I now think I have a pretty good handle on this. It sounds like my current druid-shell code is safe can panic. The fix is to consistently use `try_mut_borrow` and not hold the borrow for very long-lived things like modal dialogs. I also believe winit is "technically UB", and makepad is a bit worse; neither should be used as a model of how to do this right. If I were to take a direct `&amp;mut` of user data, it would be highly unsafe, you'd be able to provoke classic iterator invalidation pretty easily. It seems technically possible to pass the full user-data mut reference down to the modal dialog call, and figure out how to reborrow that, but I don't think that's going to be a nice API. If any of this is wrong, feel free to correct me, but I'm now feeling more confident.
I am doing a lot of work in this space now. Feel free to email me: brian@briansmith.org.
&gt; One of the things I think we should put into our system is some kind of hard cap on the number of things you can do at any given time. I’d like this cap to be pretty small, like one or two. This will be frustrating. It will be tempting to say “sure I’m working on X, but I can make a little time for Y too”. It will also slow us down a bit. This seems like a good idea regardless of anything else! It is something I strive to do both personally and professionally. Learning how to say _no_ to something is one of the hardest things I've ever had to do, and I still occasionally fail at it. There's a deeply emotional component to it, and at least for me personally (others' coping mechanisms may differ), it requires detaching oneself a bit. Otherwise, it's too easy to wind up feeling guilty. Saying "no" doesn't necessarily mean being a curmudgeon about stuff either. Sometimes it's just a matter of working with the other person to find potential avenues for unblocking them. As a matter of course, the person in the position to say "no" often has context that the other person does not, and there's _sometimes_ a work-around that is perhaps not ideal but allows progress to happen. (I realize this isn't addressing the central pieces of this lovely blog post, but I figure a comment validating a small part of this post would be fine!)
See also https://github.com/rust-lang/rust/issues/62586 for a great explanation of how to use AsRef properly.
Oh. I'm sorry. The humor there went right over my head.
[magic completions](https://github.com/rust-analyzer/rust-analyzer/blob/master/docs/user/features.md#magic-completions) are interesting little unknown feature in rust analyzer, which I'm currently using in [neo]vim.
Thanks!
If your code looks like a funnel -&gt; refactor the inner level into a function (an anonymus function does the job too).
They definitely come from [postfix templates](https://www.jetbrains.com/help/idea/settings-postfix-completion.html) in IntelliJ.
Using an [if_chain!](https://crates.io/crates/if_chain) could be helpful in similar cases.
That's what I thought, but I couldn't find anything that didn't depend on syscalls unsupported by WASM, and I didn't want to fall into the rabbit hole of patching. I'll give Snow a look-see and get back to you, thanks!
I'm afraid I'm a bit too invested in various things to contribute, but I'm very glad to hear that this area isn't ignored! I'll be sure to check in on your projects later down the road!
/r/playrust
`start_bound` returns a `Bound&lt;&amp;T&gt;` simply because it can't move the `T` out of wherever it's actually stored. In this case `T` is `&amp;str` which is copyable, but in general that's not true.
Why not do: ``` let thing = { if foo() { // Some code if bar() { // Some more code Some(whatsit) } None }; ```
Hmm, thx for sharing the origin.
&gt; I think it depends on your priorities as a researcher as well as research area. Without the efforts I mentioned, Rust isn't "batteries included" in terms of computer vision and scientific computing in general, but people sufficiently motivated to use Rust will be able to use existing libraries like nalgebra, sure. I don't disagree with you. I was just disagreeing with the notion that no robotics research could happen in Rust in its present form. &gt; For me the choice of language is secondary to making sure my code is as useful to the research community as possible when it's released, if there isn't enough reason for many people to use Rust then my code becomes much less useful in that regard. I don't quite have the same philosophy as you. My first choice in language is based on how much I enjoy that language and how productive I think it will make me. The main contribution to the community should ideally be the idea/paper and but I am very excited if people find the library useful. &gt; It's a bit of a chicken-and-egg problem but I do really think a comprehensive scientific computing environment is a prerequisite for any kind of serious uptake of Rust in research. I agree. People will generally avoid Rust as a research language until that happens. But the language does work for my research and I am hoping that I can be a part of the push towards making that environment happen.* ------ * I have a few small contributions to some of the robot-centric crates, but I am kind of waiting for const generics to happen. Matrix/Tensor libraries are prime candidates for those and, while nalgebra/typenum does work right now, it does feel slightly hacky.
That’s precisely what I’m trying to convey here. More specifically, I’m trying to communicate why `map` *doesn’t* await a future, instead returning a new wrapper one. Perhaps I was unclear in my haste to respond. What I’m saying is that the OP’s version of `map`, `f(future.await)` *is eager*, as opposed to the “existing” version, which *is not eager*. In other words, exactly what you just told me. :)
Hi ! Disclaimer : I am a beginner with Rust too so don't take my comments too seriously ^^ I looked through your code rapidly and I think you could use clap as a way to parse the args of your program and to print the help part. I will read more thoroughly your code tomorrow though :)
That would just be `None`... but there is this in unstable: ```rust let thing = 'a: { if foo() { // Some code if bar() { // Some more code break 'a Some(whatsit); } } None }; ```
Thank you! Just had a look at clap and it looks excellent. Will definitely have a closer look at that tomorrow.
No it wouldn't? ``Some()`` returns early...
&gt; Do you have any other benchmarks? I don't mean to be patronizing or rude, I would very much like to learn about this topic. I only googled that up I do not know much about it I am trying to decide whether I should port my code to Rust or Kotlin. I am actually using Pascal at the moment, which used to be the safer than C, faster than Java language. But Pascal is not being maintained well. Kotlin native does not seem to be stable enough, yet. But if I port my code to Rust, and everyone switches to Graal VM, then Rust might end up being less maintained than Pascal, before I have even finished porting my code
Happy to see this project get more support from others, including new contributors. Distributed log indexing is in a sad state, I'm hoping to see stronger contenders based on primitives like Tantivy.
It wouldn't be ``None``. But apparently it's not valid in Rust anyway: ``note: \`if\` expressions without \`else\` evaluate to \`()\```
I think you can use [std::sync::Once](https://doc.rust-lang.org/std/sync/struct.Once.html). I modified your code to use it and it seems to work, [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=897ccbf7956407618d02273943af4c8b). I manually implemented `Send` when `T: Send` and `Sync` when `T: Send + Sync`, but I'll have to think a bit more about it tomorrow. When `Once::is_completed` gets stabilized, I think you could go from an `Option` to `mem::MaybeUninit`. This way you wouldn't have the tag and no need to unwrap every access but you'd have to implement `Drop`.
I am very interested in reading that Actix tutorial once it's done. Please let me know where to find it. :)
Yeah, I've been debugging a lot and it just sort grew 😊 I wouldn't make it a function because it would be a mistake to reuse it but an anonymous would do the trick! I hadn't thought about that, thanks.
`if_chain` looks awesome! Thanks for the link.
IDK, I find it much easier to write some web service stuff in Rust. Rust actually provides way better high level abstractions than other languages, in some areas. Working with JSON is fairly fundamental to "web", and I think Rust has, easily, the best JSON experience of any language I have used (Python/Java, primarily). And it's extremely fast on top of that.
What does Twitter scale mean, really? My side project is intended to handle 10's of thousands of events per second. Is that Twitter scale? Is it Twitter scale if no one actually uses it? It's pretty easy to run into interesting problems that require huge amounts of compute without being a large company. Another aspect to this is how serverless is changing pricing models. If my application executes in 100ms vs 200ms I just cut my costs in half for the runtime execution. Similarly, if my lambda requires 128MB of RAM vs 256MB of RAM, I have cut my costs in half, or I can use that extra 128MB for caching. I don't feel considerably less productive vs Python (my project is split between Python and Rust), and I have maybe 6 or 7 services I've built in both languages for this project. The main bottleneck for me with Rust is probably compile times at this point. My feedback loop with Python is faster mostly for this reason, and it's mostly just at the start of a service when everything is totally broken when it first gets pushed.
afaik deisel is synchronous
Serverless under load ends up being more expensive at scale. YMMV. Twitter scale just means that they got to a point where they were having problems scaling with Ruby. If you’re not having major scaling problems with Ruby then you’re not twitter scale. I am very curious about you feeling as productive in Python as Rust. That seems very surprising to me.
I totally did not realize that `Once` could be used non-globally. Thank you!
I dunno, working with JSON in JS is pretty great too. 😜
I know of only one financial firm that uses the JVM for trading logic. Virtually everyone else uses primarily C++. Obviously other native languages like rust are sometimes used, but not frequently.
The big difference you'll see is that `go do_something()` will do that something in the background even if you never interact with that goroutine again. In Rust, a future is just deferred computation (the same way a closure is!) until you `await` it. The equivalent of your description of "`async do_something()` would be `futures::ok_with(|| do_something())`, that calls `do_something` when you await it. (Note, this doesn't exist.) The fact is that supporting async has some cost to it, and Rust prides itself on the fact that you only pay for what you use. The explicit async/await approach gives users who really care about that the power to control it without weighing much down on those who don't (just make every fn async and await every async fn immediately, and it's effectively sync code). Your suggested solution of compiling everything twice, once for sync, and once for async, both would double Rust's already pretty long compile time and wouldn't even be able to compile out async machinery which is required for calling asynchronous OS primitives.
HFT firms rarely use FIX. Most exchanges have their own binary protocols.
Rust runs on Graal: https://www.graalvm.org/docs/reference-manual/languages/llvm/#running-rust
&gt; The act of materializing a &amp;mut from a raw pointer when another already exists is instant UB. It's probably good to be insistent on this point, but it's not _necessarily_ true. By the current Stacked Borrows proposal, it would just invalidate any reference derived after the pointer was created, such that using those borrows would be UB. (It is likely _unsound_, however, as it's likely safe code could cause UB in this case.) And it's possible to derive a new `&amp;mut` in an "explicit reborrow" that just unnecessarily goes through a raw pointer, which is definitely sound and not UB: let mut place = 5; let first_ref = &amp;mut place; let second_ref = &amp;mut *first_ref; let ptr = (&amp;mut *second_ref) as *mut _; let third_ref = &amp;mut *ptr; *third_ref = 6; drop(third_ref); drop(ptr); assert_eq!(*second_ref, 6); *second_ref = 7; drop(second_ref); assert_eq!(*first_ref, 7); But I'm just being a language lawyer for a spec that doesn't exist yet at that point.
Yea, it likely would be a complex thing for the compiler to figure out. That said, the compiler is already pretty good at a lot of complex things, so I don't think it is out of the question that this might be supported some day.
You might want to look at what WebCrypto provides, for example [`sign()` method](https://docs.rs/web-sys/0.3.25/web_sys/struct.SubtleCrypto.html#method.sign_with_object_and_u8_array) might be of use. Although with all the warnings it does seem bit scary.
&gt; Serverless under load ends up being more expensive at scale. It doesn't matter, that's only relative to non-serverless. I'm talking about serverless as a given. Comparing to non-serverless is too complex anyway, since there are tons of implicit costs involved in picking something like EC2. &gt; Twitter scale just means that they got to a point where they were having problems scaling with Ruby. If you’re not having major scaling problems with Ruby then you’re not twitter scale. Sure, my point is that there are tons of problems that wouldn't scale with Ruby. Like my side project. &gt; I am very curious about you feeling as productive in Python as Rust. That seems very surprising to me. The major things that I have run into that have caused me to lose time are: * Libraries not being there, so I roll them myself (this happened with dgraph, and now we have a dgraph crate) * Dependencies that update with breaking changes. It is still kind of nuts how much of Rust's ecosystem is pre-1.0. * Compile times slow down iteration cycles quite a lot, and my compile times are awful because I suck at Dockering and I recompile every dependency every time. That's on me. Otherwise, what would cause me to be slower in Rust? I have structures and functions and loops and all the things I care about.
lol I actually disagree! Ironically, I find JS quite annoying to work with in js. Null and Undefined propagation are some of the more annoying bugs I run into.
As someone trying to learn Rust, and has never done web dev, but might want to do a few simple webapps running on a pi this sounds awesome. I've been a bit lost trying to figure out where to start.
&gt; Consider specialization: On the one hand, this feature was first proposed in July of 2015. We had a lot of really important debate at the time about the importance of parametricity and so forth. We have an initial implementation. But there was one key issue that never got satisfactorily resolved, a technical soundness concern around lifetimes and traits. As such, the issue has sat around – it would get periodically discussed but we never came to a satisfactory conclusion. Then, in Feb of 2018, I had an idea which aturon then extended in April. It seems like these ideas have basically solved the problem, but we’ve been busy in the meantime and haven’t had time to follow up. I feel like this is actually somewhat dangerous, because while these features sit waiting for the right idea to come along, people are using them and putting nightly-only dependencies in their crates that can languish for years. I may be in the minority, but I feel that an abundance of nightly-only crates hurts the ecosystem.
&gt; I felt like I was programming in a minefield &gt; I'd be more interested in thinking through ways to avoid this problem entirely Why not use Rust compiler for that? You can wrap all re-entered functions with something like fn call_reentrant_func1(state: &amp;mut State) and compiler check that you nothing borrowed during the call?
&gt; My hunch is that this is technically UB but likely to work in practice But it is perfectly fine to pass reference to mutable state to function, and compiler check that you have no related references, like iterator for you some Vec inside your state. So if you wrap winapi calls that may callback your wndproc with something like this: fn call_winapi_that_may_be_recall_wndproc(_not_used_mystate: &amp;mut State, other_params) Then compiler should check that it valid to pass mutable reference to this function, it is still UB, but should be more safe.
How about using [`ed25519-dalek`](https://docs.rs/ed25519-dalek/)? It's a pure-Rust crate, so it should be quite easy to compile it to WASM (you may need some configuration, e.g. for `rand`).
God, rust is so lucky to have niko imo.
Another great option is structopt. It uses clap underneath, but lets you define a struct that it will parse all the options into. Here's a sample: #[derive(StructOpt)] struct Opt { /// The starting directory directory: PathBuf, /// Enter folders (traverse directory recursively) #[structopt(short = "r")] recursive: bool, /// Do not count symbolic links #[structopt(short = "d")] no_count_symlinks: bool, /// Do not count folders #[structopt(short = "s")] no_count_folders: bool, /// Do not count files #[structopt(short = "f")] no_count_files: bool, } That will automatically generate the following help message: fcount 0.1.0 eggmund &lt;joshuacolclough2@googlemail.com&gt; USAGE: fcount [FLAGS] &lt;directory&gt; FLAGS: -h, --help Prints help information -f Do not count files -s Do not count folders -d Do not count symbolic links -r Enter folders (traverse directory recursively) -V, --version Prints version information ARGS: &lt;directory&gt; The starting directory Structopt really shines when you have more complex commands, optional flags with values, defaults, etc.
I'm new to Rust and writing a subset-x86 VM. So far things have been great and I've got all the decoding infrastructure, and a few opcodes executing. Now I'm wanting to implement more complicated integration tests and benchmarks. As much as I love writing raw hex code in a `[u8]`, I'd love to somehow move to writing assembly code as a string, and then somehow get a `[u8]` out of it by calling an assembler like yasm. Trying to figure out the best course to take. Looks like creating a temporary file accessible by an external process is.. less simple than I would've thought.. and then it looks like with processes it can require multiple implementations depending on platform. Is there anything out there to look at as an example for demystifying this?
What do you mean by my network config?
Yes, keep us all posted.
Neat
&gt; The fix is to consistently use try_mut_borrow and not hold the borrow for very long-lived things like modal dialogs. Agreed! I prefer explicit drops of the borrows when there's any kind of reentrancy mixed with unsafe code. winit's [iOS](https://github.com/rust-windowing/winit/blob/master/src/platform_impl/ios/app_state.rs#L184) backend uses a `RefCell`, and explicit drops for similar reasons.
Looks like a cool project.
&gt; Why not use Rust compiler for that? You can wrap all re-entered functions with something like I'm not sure if we're misunderstanding each other. Here's an idea of what we're talking about: // my_state is type Rc&lt;RefCell&lt;State&gt;&gt; let my_state = my_state.borrow() let fcd = FileChooserDialog::new(...); fcd.run() I have to know that `FileChooserDialog::run` might re-run my main loop, which might hit ANY of my event handlers which might borrow my state again. At least this one is named `run` but some others are surprising. I'm not sure how I could use your wrapper to solve this problem.
Sometimes you end up needing to use those, like in C FFI integrations or purely embedded environments.
can you explain more about it in rust project example?
What's the exact error given at compile-time?
You're going to need to give more details.
I'm not sure if this would actualy be a good case, but suppose you're using a library with a function that takes a function pointer and not an Fn trait impl. If you have some global state you want to use in that function, you'd have to have it be static (afaik). If it's not const you might end up with an option too. Something like: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=371649f85ea923d43360e0aa2e1ee7fd
Any network appliances between the client and the server can set a maximum size. The smallest of these sizes is the maximum size you can send. There are many articles discussing how to discover this value and there is a minimum size requirement depending on if you are using IPv4 or IPv6.
Thinking more about this, you should! Even though I posted my own crate in the answer below, your solution does not rely on generators. Since they are not getting stable themselves any time soon, [async_stream](https://docs.rs/webdav-handler/0.1.1/webdav_handler/async_stream/) is our best shot at getting async streams into stable as early as possible.
Static variables are *not* unsafe, not even a little bit. *Borrowing them uniquely* is, for obvious reasons. The keyword "mut" is a total red herring.
https://github.com/sfackler/rust-openssl/issues/994
Yes.
This is now the entirety of my CI config in [`tracing-timing`](https://github.com/jonhoo/tracing-timing): ``` stages: - template: azure/stages.yml@templates parameters: minrust: 1.34.0 # integer atomics codecov_token: $(CODECOV_TOKEN_SECRET) resources: repositories: - repository: templates type: github name: jonhoo/rusty-pipes endpoint: jonhoo ```
If you were using openssl 1.0 previously instead of 1.1, try installing `openssl-1.0` (https://www.archlinux.org/packages/core/x86\_64/openssl-1.0/)
I think you're looking for rust the game, not rust the programming language.
If you want a total ordering predicate in core, please pick up [https://github.com/rust-lang/rust/pull/53938](https://github.com/rust-lang/rust/pull/53938)! (I don't have bandwidth to resolve the open design questions.)
I've been reading the book Modern Compiler Implementation in ML for some time now and I finally finished implementing the first 12 chapters, which gives me a compiler for the Tiger language that I implemented in Rust. I highly recommend you this book if you're into compilers. The code in the aforementioned repository is not perfect, but it should help you in case you need it: the repository is organized as one commit per chapter. If you want to execute this project, you need Linux 64-bits and you might need to adjust some paths [here](https://github.com/antoyo/tiger-rs/commit/20d4f384a1bdd788d710cdb38ede48e18ae5963b#diff-08595b72acf07245addcbff953a83e10R158), but they should be good on ArchLinux. This project generates Intel x86-64 assembly, features a register allocator with spilling and coalescing and a runtime which is also implemented in Rust. I'll continue reading this book and implement the projects from the next chapters in the coming months, so stay tuned!
I think \`Default\` is too general -- it can do too many things. I could possibly convinced to have a separate \`trait ImplicitDefault: Default {}\` that's only implemented for a narrower set of types -- particularly things that are ZSTs.
`unsafe` just means "stuff the compiler isn't smart enough to guarantee correct usage of, so trust the programmer's ability" and `std` couldn't be built without unsafe code. The important thing is to wrap abstractions about `unsafe` code that prevents it from being used incorrectly and disallowing `unsafe` constructs would just prevent 3rd-party crates from providing functionality as powerful as `std`. (Plus, any call into another language is inherently `unsafe` since the compiler only understands Rust and, in the case of C, the language itself doesn't give the compiler enough information about the programmer's intent to verify things.)
The compiler is not that resource heavy, you should be fine
Was looking at a few the mid range one seems to suit my needs thanks for answering my question
could help with compile times if it's got a good cpu
How'd you get rust-analyzer to work with coc.nvim? It loads extremely slowly for me (sometimes never) and the messages won't display when I hover over any errors. I've almost given up and moved to VS code...
I'm using emacs and the type overlays from lsp-ui are wonderful
Async code tends to call other async code, and Futures and other asynchronous things aren't self-executing in Rust (again, that would require doing "heavier runtime" things that would limit Rust's utility), which means that there has to be infrastructure to handle that. Making a synchronous version function properly and reliably would essentially mean having the compiler abritrarily provide and use something in like a Tokio executor behind your back, and It's not the Rust way to have the compiler silently making big decisions like that. What you're asking for is comparable to other things Rust explicitly decided against because they make codebases harder to maintain and unexpected API breakages more likely, such as global type inference, or features which don't fit Rust's "make costs explicit" philosophy. (Remember, this is the language where you have to explicitly specify when you want things cloned or reference-counted.) In fact, from what I remember, you get a warning if you circumvent that and launch two Tokio executors in the same process by doing something like using reqwest's default API in an async app.
On the other hand, if there are an abundance of crates that depend on nightly features, that can help to steer feature stabilization plans.
Congrats Paul.
/r/playrust
It can also help set priorities for what features to work on if there are limited resources
It's because you implement Copy (the Clone impl doesn't matter).
Fairly gross, but works ([playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=3f2fc3309ed637dc607df1550d6b0e00)): let thing = loop { if foo() { // Some code if bar() { // Some more code break Some(whatsit); } } break None; };
Thanks for the example code, it will take me some time to understand that sample code but i am working on it :)
Thank you. will search for it
so you mean, if i create a let mut my_list in main() and clone it via sync::Arc and pass it to a static variable as my_global_list = &amp;my_list and use this as reading only from other functions, are totally safe?
yea i got your point. but if you wanna share my_list which made in fn main() with your other modules that is not in the main() scope, then you need to use statics in order to force it to happen. but in the docs mentioned many times that this habit is not safe specially you go on threads... I'm not talking about binding other language in Rust, as i prefer to use everything purely in Rust.
Dereference is `&amp;T -&gt; T`^1 conversion. Since the input is a borrow, you cannot take the ownership via dereferencing. (Except the language-builtin `Box` type, which the compiler has special cases for. `*x` actually takes the ownership of `x: Box&lt;T&gt;`, if `T` is not `Copy`.) 1: More accurately, `&amp;T -&gt; &lt;T as Deref&gt;::Target`
more broadly, the fact that you can't move out of a borrow is sorta the whole point of rust. somebody else owns that data, you can't just steal it unless it implements clone / copy / some other way to move ownership (like vec.drain()).
&gt; yea i got your point. but if you wanna share my_list which made in fn main() with your other modules that is not in the main() scope, then you need to use statics in order to force it to happen. You can pass the list as a parameter to the functions that you're calling from `main`. A global variable isn't necessary.
Wrong subreddit. /r/playrust
&gt; There's a deeply emotional component to it, and at least for me personally (others' coping mechanisms may differ), it requires detaching oneself a bit. Otherwise, it's too easy to wind up feeling guilty. A trick I do both internally to myself and to others when I say "no" is to be clear about what that frees up time to do. "No" is the only way in the world to *create capacity*, so it is a very powerful tool. When I say "no", I try to think and say it terms of "because I want to focus on ___" instead.
There's nothing remotely unsafe about statics. What's totally unsafe (in that the compiler cannot guarantee safety) is having a mutable variable accessable, mutably, from everywhere in your program, no matter how many threads you spawn. Which is why *static mut* is unsafe: there's no way to drop the mut, so that the mutability is unique. Everywhere else in Rust, mutable access to memory is unique to one scope, at any point in time. So not only can you not write to a static mut, you can't even safely read from it, because it could be in a weird intermediate state (think about a struct with two related values, in the process of being updated: one value will be misleading at some point in time). Of course, this doesn't mean you can't use static mut. It just means you must use an unsafe block to do so, annotating parts of your code where problems are likely to occur. However, you'll only rarely have a legitimate need for mutable static data. Whatever problem you think you're solving with static variables is almost certainly better solved another way.
I'm not entirely sure I get what you're asking, but does this point you in the right direction? (Note I didn't test this) fn main() { let dir = tempdir::TempDir::new("foo").unwrap(); let asm = dir.path().join("sample.asm"); { let f = std::fs::File::create(asm); writeln!(f, "contents"); } std::process::Command("yasm").arg(asm).output().unwrap(); let compiled = std::fs::File::open(dir.path().join("sample.o")).unwrap(); }
I'm not using rust-analyzer for diagnostics b/c it was simply not as good as RLS at the time I starting trying rust-analyzer, and my configuration is still the same, just with recent builds of rust-analyzer. In my [neo]vim setup I use coc.nvim first, with ALE as fallback when the filetype isn't covered already by coc.nvim. But for Rust I do a bit different, I'm using rust-analyzer for completion which is working great, through coc.nvim, and disable coc.nvim diagnostics for it, and then enable RLS in ALE, so I'm using both, ALE is providing diagnostics, pretty fast and stable, coc.nvim is providing completion and other LSP features with rust-analyzer.
That's cool, for some reason I was thinking HKT (template template params) would be needed for that. &gt;Or a custom FromConfig trait will perfectly handle the fact that each T is built in a slightly different way than another. If initially all `T`s were built in the same way, and your `T` is the first one built differently, then you need to create the `FromConfig` trait and make all `T`s implement it. My point is not that C++'s template system allows you to do things Rust can't, it's that its flexibility allows you to hack things in with less effort (using `if constexpr` for a two line change vs defining a trait and a bunch of instances). Basically the dynamic typing vs static typing argument, except it's at compile time so an error interpreting your dynamically typed C++ template metaprogram won't lead to runtime bugs, it will just halt compilation.
140 could use `.any()` instead. At 117, you could use format to do your zero-padding by building your format string dynamically, and support arbitrarily long seasons. It's unnecessary, but it could be fun! Your error handling could be better. Panicking all over the place is fine in small toy programs, but you'll need to get used to error propagation, or at least supplying meaningful messages, if you write anything larger.
I don't think OP is asking *how* to do the move, I think OP is curious about *why* a move is not occurring in that example.
I was responding to "If statics are unsafe, why they even exists?" Beyond that, it's always possible to use them safeLY... Rust just doesn't force you to use one specific means for ensuring that.
Also, this (unstable): let thing = 'a: { if foo() { let x = 3; if bar() { let x = x + 1; break 'a Some(x); } } None }; [playground](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=ab22bdc9d25d7d0782a6c002c346823a)
[This page](https://github.com/rust-lang/rustfmt/blob/master/Configurations.md) lists out all of the config options and their default values.
I haven't followed it closely so there might be better explanations elsewhere, but the main author did say this: &gt; actix-web 0.7 doesnt use actors internally, it just have high level integration with actors. same integration will be available to 1.0 but as external dependency. &gt;as for reasons to replace actors in actix-web, actors are good for expressing high level components dependencies, but they are too high level for efficient code reuse. actors also imply overhead. actix-net's services on other hand are much lower level, they have very simple interface and provide efficient code re-use design. https://github.com/actix/actix-web/issues/722#issuecomment-473612082
To be more precise, Clone tells Rust how to copy the object, Copy tells it to copy rather than move, which is why the deref doesn’t move here.
Absolutely true- frank advice- stay with C++. But write your own libs in Rust and use with FFI.
You could try: 1. Use rustfmt's `--print-config` option to dump both the default and current configs, 2. Use something like the POSIX `sort` command or vim's built-in line-sorting support to ensure the settings are in the same order. (For vim, open the file and type `ggVG:sort` and press Enter, then save the file.) 3. Use `diff -u` or your preferred diffing tool to compare them.
When you have a poly-articulated body, with lots of joints &amp; actuators (let's say 30/40 for a full size humanoid), you need to compute forward / inverse kinematics / dynamics (eg. knowing the inertia, position and velocity of all joints, compute the torque needed to achieve some acceleration of all joints in order to move the position of all joints). A really good explanation of those algorithm is given by [Roy Featherstone in Rigid-Body Dynamics Algorithm](https://epdf.pub/rigid-body-dynamics-algorithms.html). This is pretty intensive, and you need to compute that at the highest possible frequency, just to control your robot (a 1kHz loop to read all sensors and compute the orders to all the actuators is an important goal to achieve). Moreover, you also need those algorithm for the higher level motion planner: you have to decide a few steps in advance, just to know where you want to go. And we do that in real time, so that if we say to the robot: "oh noes ! This tile is lava, don't walk on it !", it can just plan to put is foot somewhere else. For this to work, you also have to run those rigid body dynamics algorithms inside an optimal control solver, which need to launch them a lot of time. To do that, we use the [Pinocchio library](https://github.com/stack-of-tasks/pinocchio/) (full disclosure: I'm working on it a bit), which makes an extensive use of Eigen. And as OP says, you don't have anything like Eigen in Rust, or most other languages.
Rusty's abstractions are closer to C++ than anything else. Of course it's got its influences like ML and Haskel and Ocaml but that's a good thing. It's very close to the more functional "academial" languages but doesn't go to the extremes. That's why I like it so much. It's very different from most languages but it has some of the most useful abstractions around. You just have to let go of the OO mindset which can be hard at first.
According to your post that code is deprecated (and unstable). I suggest you should look for a crate. Or you can use directly the windows function LoadDllLibraryW. Also check the Winapi crate that should have some code to do that inside.
Thanks a lot ! I am going to try to implement what you said. I'll let you know if I have questions. Thanks again !
I gave up with rust in VS Code as the implementation seemed so crippled as to provide little more benefit than coloured syntax highlighting. It was quite odd as it seems to be a very popular plugin, but questions about it both here and on stackoverflow went unanswered so I've been left a little baffled and I can only conclude this is how it's supposed to be and most of the users are very happy. (although this was mid-May 2019 so maybe things have changed) I've since switched to IntelliJ IDEA and found it to be a MUCH more conducive environment for learning rust. As others have stated the visible inferred types are extremely helpful, code hints actually work, and it is possible to consistently build with a hotkey (None of which I was ultimately able to achieve in VS Code.)
And as a followup I have a [patch](https://github.com/xi-editor/druid/pull/77) that fixes the panics and I believe is safe. Overall I think this is a good direction for the code, less interior mutability (for clients of druid-shell) makes things simpler. There's more work to be done (especially not holding the borrow during file dialogs) but the basics are in place.
The compiler is correct in rejecting that. What `make_closure` wants is something that can convert `&amp;'a i32`, `&amp;'b i32`, … into `T` for all possible lifetimes `'a`, `'b`, … What you are providing in the function call is something that can be used to convert only one lifetime. Let’s say the lifetime of your `&amp;100i32` is `'x`, think of it as `&amp;'x 100i32`. You can convert `&amp;'x i32` to `&amp;'x i32`, but you cannot convert `&amp;'y i32` to `&amp;'x i32` where `'y` is not `'x`. That is, `&amp;'x i32` implements `CreateFromI32Ref&lt;'x&gt;` but does not implement `CreateFromI32Ref&lt;'y&gt;`, and so it cannot be passed to `make_closure`. And it makes sense if you think about it. The closure returned by `make_closure` has no lifetime, so it cannot be borrowing anything. If what you have works, you could do this. let i = Box::new(100i32); let closure = make_closure(&amp;i) // closure has no lifetime, so it cannot be borrowing i std::mem::drop(i); // use after free: closure();
Have a look at [https://github.com/rust-lang/rust-bindgen](https://github.com/rust-lang/rust-bindgen)
This works. I can return function pointers to closures as long as they don't enclose anything. This is super useful for type reflection. Eg: ``` pub fn define_clone_in_place&lt;C: Clone&gt;() -&gt; unsafe fn(C, *mut C) { |src, dest| unsafe { dest.write(src.clone()) } } ``` My question: Is there a trait that all functions that have pointer `fn()-&gt;R` have in common? You'd think `Fn()-&gt;R`, but actually these types have different pointers, namely `fn(&amp;self)-&gt;R` which is not the same. Is there a function I am looking for? Maybe there's a solution involving specialization?
There are a number of crates for that, mine is https://docs.rs/once_cell/0.2.2/once_cell/ :) In general, your logic is correct, but there are two problems: * call to f() should happen outside of unsafe block: calling user’s code within unsafe is dangerous. In this situation, the problem will arise if f tries to initialize the Cachee recursively. In the code as written that would lead to deadlock, which is ok, but, for example, adding a fast path which doesn’t lock mutex for definitely initialized cells will result in double initialization and UB * to be Sync, Cacher needs the T to be both Send and Sync: you can use Cacher to sneak a Sync value from one thread to another.
what if i needed that variable from some other functions that are not calling from the main() ? So i should keep passing the variable from the main all the way to the func that im going to use that variable?
I agree that you can achieve performance with small bases. And it's not that a rust system would lag that much from the c++/c systems. Based on the talk by Carl Cook, these systems are small and even use elegant (or dirty) tricks like indexing an array with a boolean to skip an if-branch. Almost all allocations are stack based. I wouldn't know how to do it in rust right now. I've seen some arena allocator implementations but I don't know how they perform and how they coexist with rusts type system. Rust and Tokyo probably got much better since this guy wrote the issue. I would like to see emplacement construction together with const generics :D
Didn't know about binary protocols. Guess that is something only HFT firms have access to...
is there any guide about software architecture is a safe/rust-y way to learn from? So far whatever language we learned, they never care about it and just introduce the global variables proudly and our programming mind adopt it so now is difficult to change this bad habit to a proper way (Rust's way). please share a link reference or guide about it. i mean a guide to bring the real world example not the Rust Docs.
Nice work. I like the book as well, particularly for getting into compilers in your own time. The compiler construction course we give at my uni was once loosely based on the Java version of this book. We still use MiniJava for the lab and Tiger in slides that need an example language. We did move away from the book because of its practical nature though. It's more of a cookbook for building this particular compiler. We're a bit more ambitious, and geared our lectures/lab towards that. We teach the concepts of compiler construction and let the students play with our own tooling for building languages. That gives them a good enough grasp on the general idea of building compilers to do so for a very different language later on (we see this with students who do the follow-up course where they pick an existing language and build part of a compiler for it). Of course I never tested my theory that the MCI book is too detailed and geared towards the toy language of the book. If you ever get to do another of these projects, I'd be very interested to know your experience in trying to build a compiler for a different toy language without the guidance of this book :)
&gt;i prefer to use the GUI which is purely written in rust Creator of [areweguiyet](https://areweguiyet.com/) here, if you stick to this requirements you wont get happy at the moment. There is no pure Rust GUI Framework out there that could compete with GTK or Qt. If you like conrod and it fulfills your technical requirements stick with it. So the decision is yours if you value documentation more than that it is written in rust.
(relevence: the linkerd2 proxy is written in rust)
Unfortunately, I learned not to use global variables at such a young age, and I've been cobbling together my own learning materials for so much of my life, that I can't think of anything like that to suggest. (Heck, I'm not sure I ever *did* pick up the habit of using globals. I don't remember ever really using the `global` keyword much in Python and I got into Python in high school.) I sort of have the opposite problem. I've been following good practice for modern, high-level languages for so long that I sometimes get stuck in a mental rut in my DOS retro-hobby programming. (eg. It took me too many minutes to realize that Free Pascal's APIs expect 1990s OOP-style subclassing for hooking up event handlers rather than the kind of `connect`/`bind`/`addEventListener` signal/slot architecture that's now ubiquitous.)
Yep, I meant kLOC.
A good, cross-platform helper for loading dynamic libraries is `libloading` : https://docs.rs/libloading
You can definietly do that. &amp;#x200B; I don't know if there is a generic, cross-platform library but I've recently had to do a bunch of Winapi stuff, including loading and calling methods from Dlls. &amp;#x200B; You can take a look at [LoadLibraryA](https://docs.rs/winapi/0.3.7/winapi/um/libloaderapi/fn.LoadLibraryA.html) from the winapi crate. Or as someone said below take a look at [rust-bindgen](https://github.com/rust-lang/rust-bindgen)
&gt; It’s really hard to tell what the current priorities are; it’s hard to tell when a given feature might actually appear. Some of this we can help resolve just by better labeling and documentation. Yes *please*. Knowing the priority of a thing would be useful, as would having some idea when a thing might be ready or what it is blocked by. (Yes, we've been waiting for specialisation and const-generics a *long* time — exciting to have both of these on the way!)
&gt; I guess my main questions is: Why doesn't dereferencing a reference pass ownership? This is a hard question to answer because it's so fundamental that I'm having trouble understanding what needs to be explained. If borrowing transferred ownership, it would defeat the whole point of borrowing because: 1. If Rust remained the same, but borrowing transferred ownership, then your code still wouldn't work. You'd just get the errors about trying to use values after they've been moved that you get when you don't apply `*` and `&amp;` as appropriate. (Borrowing is just an ownership transfer that undoes itself automatically at the end of the scope.) 2. The whole point of Rust's ownership system is to be able to allocate and free memory without runtime reference counting (like in garbage-collected languages) or region-based allocation (like in [Cyclone](https://en.wikipedia.org/wiki/Cyclone_(programming_language)#Dangling_pointers_and_region_analysis)). Multiple ownership requires one of those things and you have to opt into multiple ownership via runtime reference counting using the `Rc&lt;T&gt;` and `Arc&lt;T&gt;` types because they have a non-zero runtime overhead and trade the possibility of compile-time errors for the possibility of runtime panics. 3. If you don't have either of the above cases, then you're back to what C provides.
Name squatting has been explicitly allowed by the crates.io team, but it is still contentious in the community.
There's a [*long* thread on this topic](https://internals.rust-lang.org/t/crates-io-squatting/8031).
Yes. That's a good &amp; common practise in most if not all languages created after 1960s. If you need to access multiple variables, you can bundle them (or references to them) into a context/state `struct` and pass them all around at the same time.
Could you report the full output of `rustup update` please? Optionally as an issue on https://github.com/rust-lang/rustup.rs
info: syncing channel updates for 'stable-x86_64-pc-windows-msvc' info: checking for self-updates stable-x86_64-pc-windows-msvc unchanged - (rustc does not exist)
info: syncing channel updates for 'stable-x86_64-pc-windows-msvc' info: checking for self-updates stable-x86_64-pc-windows-msvc unchanged - (rustc does not exist)
&gt; the optimizer will assume that nothing can invalidate the outer &amp;mut during the API call that reenters the window procedure, leading to miscompilations. How could the outer &amp;mut be invalidated ? You only have a &amp;mut to the object, and this &amp;mut was derived from the outer &amp;mut. If you can use this &amp;mut to invalidate the outer mut, you have bigger problems.
Thanks for your comment. i prefer do use a crate which has a complete docs, coz without it is just wasting long time.
Oo nice! It's like what I am doing now but a lot simpler and easier to set up. Thank you
`static` is fine, `static mut` is actually [kinda contentious](https://github.com/rust-lang/rust/issues/53639).
Do you ever use the release task? [https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/utility/github-release?view=azure-devops](https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/utility/github-release?view=azure-devops)
I added both the components you suggested. They seem to be two extremely useful tools. I'm surprised I hadn't heard of them before. Thanks!
I wasn't aware of /r/learnrust it looks like just what I need. Thank you.
In the end I munged the `perf.data`: 1. Collect `perf.data` using `cargo flamegraph` 2. Use `perf script` to see the frames and identify my root and leaf frames of interest (ie regexes for `handle_request` and some lower level, in my case this was `(__GI___clone|unknown)`) 3. Munge `perf script` output. I tried `perf script | sed -n '1,/handle_route_request/p;/(__GI___clone|unknown)/,$p'` and a bunch of variants but could never get it to work. Eventually I just gave up and wrote a simple Python script and ran `perf script | python futures_strip.py | inferno-collapse-perf | inferno-flamegraph &gt; flamegraph.svg` `futures_strip.py` looks like: import re, sys start = "handle_request" end = "(__GI___clone|unknown)" if __name__ == "__main__": quiet = False for line in sys.stdin: if re.search(end, line) is not None: quiet = False if not quiet: print line, if re.search(start, line) is not None: quiet = True I'm vaguely interested in trying to more carefully match the additional stack frames by more smartly determining the additional futures frames instead of relying on a user defined "fence" but I'd have to see more `perf.data` examples before I'd trust such an impl.
What if the type didn't implement Copy? What would `*x` represent in that case? Would `*x` be a move (and therefore not allowed)?
I use [colored](https://crates.io/crates/colored) for this purpose which is very straightforward.
Just got the rust book and decided to convert a python script to rust. Hit a bit of wall, I have a timestamp and I want to add 48 hours to this date. Looking at the chrono library but nothing stands out on how to do this?
\&gt; Clone tells Rust how to copy the object, Copy tells it to copy rather than move &amp;#x200B; That's not quite right. Clone doesn't tell Rust how to copy, instead it gives you, the developer, a method to clone objects. This method can involve arbitrary operations, incl. new heap allocations etc. Copying as done by the compiler due to usage of the Copy trait on the other hand is always just a plain memcpy, it does not use clone().
Short answer: yes, this uses `Copy` - any type which implements `Copy` will always copy ownership in any situation you'd expect ownership to be transferred. `Clone` isn't relevant here; it only allows an explicit call to `x.clone()`. Long answer: this isn't anything specific to do with references or dereferencing. You can see the same behaviour with code like `let a = Rook; let b = a; a;`. This is valid only because `PieceKind` implements `Copy`. Here's how copy/move semantics work across C/C++/Rust: * In C, `T dest = src;` will do a bitwise copy of `src`. `src` will still be usable, and if it's something like a pointer that the owner is responsible for freeing then you'd better figure out which one is now responsible for freeing. * In C++, `T dest = src;` will call `T`'s copy constructor, which may run arbitrary code, and leave `src` still usable. Not all types are copyable. If you write `T dest = std::move(src);` then `src` will be left in a 'valid but unspecified' state. `src` is still alive until the end of its scope, and its destructor will be called. Not all types are movable. * In Rust, `let dest = src;` will do a bitwise copy of `src`, and `src` is no longer usable and is said to be 'moved from'. `src`'s destructor will not be called. Rust itself has no concept of immovable types, but the standard library provides features for this in `std::pin`. However, the `Copy` trait indicates that after bitwise copying `src`, it's safe for `src` to still live and be accessed. This isn't the case for anything that owns some resource, as then you'd have two owners. But it's the case for all primitive types, and generally the case for anything you wouldn't have to worry about in C. So `let dest = src;` always does a bitwise copy like C, but types get to decide whether that should be treated as a copy or a move, eliminating having to manually worry about ownership. The `Clone` trait is the equivalent of C++'s copy constructor - it allows you to run arbitrary code to create a new value that's equal to the old one, duplicating any resources it owns. In Rust this is always explicit; you have to say `x.clone()`. For types that implement `Copy` as well as `Clone`, this is just a bitwise copy again. So dereferencing a reference and binding that to a variable (or in this case a field) will always do a bitwise copy of the referenced object, and this will be treated as a transfer of ownership unless the type is `Copy`.
Absolutely! I do the same. That's definitely a super important piece, especially in a professional setting.
looks good. thank you.
You're welcome.
How does this compare to this? https://github.com/xoac/rust-azure-pipelines
Thanks for being a principled programmer. &gt;50% of people who responded to SO use Windows (and this doesn't account for the skew that Windows programmers are usually enterprise kind and less likely to respond to surveys). I'm very happy with where I am (Linux) but as an erstwhile Windows user, I hated being treated as a second class citizen in the OSS programmer community.
Hello, I have a very unusual problem in that my Rust program is too fast for the Hard Drive Disk to follow correctly. &amp;#x200B; The thing is I'm developing a program that sort a file based on a key I give it. The sort part is all good (really fast too, Hoare quicksort is really efficient btw), the read and write are very good too (BufReader and BufWriter with a buffer size of 64KB). The problem being that the program will execute alongside quite a few other processes that also write and read stuff to the HDD. &amp;#x200B; Since the Rust sort program read and write at least 250MB/s of data to the HDD, it seems that my program is stalled by the OS for saturating the HDD I/O limit and, although when running alone it's way faster than the old implementation, when running alongside other processes it is stalled such that it is 2 times slower than the old sort program. &amp;#x200B; I have tried allocating more RAM data in hope that the HDD has time to rest while I sort data but even 4GB of RAM is not enough since the sort part is too fast and the HDD is in constant read/write operations and I can't allocate much more RAM since it's also quite used by other processes. &amp;#x200B; Now, the easy solution here would be to buy more RAM and HDDs. But I was wondering if there is a possibility to prevent the OS from stalling my program from reading/writing on the HDD. &amp;#x200B; Does anyone know where I should look for this? I've tried googling it but I haven't yet found anyone complaining that Rust is too fast...
I tried this on a non Copy type and it did cause a move
This thread comes up once every few weeks. Needs to be addressed.
I've made a test just yesterday of Azure Pipelines that does tests &amp; binaries release: https://github.com/Keats/azure-pipelines-test
Do you have a particularly aggressive virus scanner installed?
I'm confused about this: I checked out linkerd2's GitHub page and it says it's almost all Go and I didn't see any Rust anywhere. What am I missing?
Ah that’s interesting. So why does Copy require Clone then? I’d assumed it was because Copy used clone() to do the copying.
Looks wrong: https://github.com/jonhoo/rusty-pipes/blob/master/azure/install-rust.yml is it really working? In my config I also have: curl https://sh.rustup.rs -sSf | sh -s -- -y --default-toolchain stable guess what gives rustc --version after that statement? 1.35.0 This is because of azure has pre-intalled rustc version.
No
I would rather say it's explicitly not disallowed, I don't think anyone thinks it's just acceptable to do. It's just very hard to police.
Well, [they are a lot faster than they used to be](https://hacks.mozilla.org/2018/10/calls-between-javascript-and-webassembly-are-finally-fast-%F0%9F%8E%89/). At least in Firefox.
The solution is something like this: fn call_file_chooser_dialog(_: &amp;mut Rc&lt;RefCell&lt;State&gt;&gt;) -&gt; i32 { unimplemented!(); } fn main_loop() { let mut my_state = Rc::new(RefCell::new(State)); let my_state2 = my_state.borrow(); call_file_chooser_dialog(&amp;mut my_state); } compiler emit error in case you have something borrowed
This is not possible because the exact size of the stack, and the position of everything in it, must be known at compile time. This is not unique to Rust, either. When your program is compiled into machine code, the compiler/assembler translates all variables into addresses (pointers) relative to the top of the stack (the stack pointer, SP). A variable with varying size, like a Vec’s data, cannot be located on the stack. The *reference* and metadata is.
To be even more precise, a move is also a plain memcpy. But the compiler assumes the source value is no longer valid. The Copy trait simply tells the compiler that the source value is still valid.
Why does supporting wasm require changes to a crypto library (apart from interfacing with a different system CSPRNG)?
https://www.reddit.com/r/rust/comments/8laxam/why_does_copy_require_clone/
I think anyone does, they just cost more.
The low-level proxy part of linkerd2 is in Rust, the higher level orchestration code is Go. [https://github.com/linkerd/linkerd2-proxy](https://github.com/linkerd/linkerd2-proxy)
The compiler doesn't seem to be able to infer the type of function pointers: trait Foo {} impl Foo for fn() {} fn bar&lt;T: Foo&gt;(_t: T) {} fn baz() {} fn main() { //bar(baz); //compilation fails bar(baz as fn()); //compilation succeeds bar::&lt;fn()&gt;(baz); //compilation succeeds //bar(|| {}); //compilation fails bar((|| {}) as fn()); //compilation succeeds bar::&lt;fn()&gt;(|| {}); //compilation succeeds } Does anybody know of a workaround which doesn't require type annotations at the callsite? The trait `Foo` specifically needs to be implemented for function pointer types, not closures in general, since one of its purposes is to cast `Self` to and from a `*const ()`.
Where's mine
&gt;How could the outer &amp;mut be invalidated ? Not the pointer itself, but the machine-level use- without knowing about the second `&amp;mut`, the compiler may not reload any values cached in registers, etc. It's the same problem as misusing a C `restrict` pointer.
Hmm, that's interesting.. I haven't actually check that it truly uses the very latest stable release. Did you have a different command in mind that night work?
Some of the files in there are based on those from that repo (see the README and LICENSE files in the azure/ directory), but they've been expanded a decent amount to also take into account features, code coverage, and some other bits. I've also revamped the setup to use stages and explicit dependencies to increase the parallelism and readability of the pipeline. Beyond that, I've taken great care to make it really easy to get a "give me everything" setup up and running. The complete CI file I'm now using in other projects is now like ten lines. I also tried to make the docs really explicit about precisely what you have to do to get Azure set up correctly, and how to not give it access to your entire GitHub account, because some of those processes are highly nontrivial! Hope that helps :)
I haven't been using them because I've never had the need for binary releases. And with docs.rs, it's now also rare I need to do any kind of documentation generation. What kind of Rust projects are you wanting a binary release step for?
&gt; Hmm, that's interesting.. I haven't actually checked that it truly uses the very &gt; latest stable release. Did you have a different command in mind that night work? Untill recently something like this works: export RUSTUP_HOME=$HOME/.rustup export CARGO_HOME=$HOME/.cargo echo ##vso[task.setvariable variable=RUSTUP_HOME]$HOME/.rustup echo ##vso[task.setvariable variable=CARGO_HOME]$HOME/.cargo by default CARGO_HOME and RUSTUP_HOME point to /usr/local/cargo and /usr/local/rustup, but for some reason at now it is broken. wchih rustc reports /home/vsts/.cargo/bin/rustc, but version is 1.35.0, so I have no idea what is goging on.
Since you're using the 2018 edition, imports have changed a bit. You don't need the `extern crate` statements; crates are imported by their name automatically. #[macro_use] is also no longer recommended; you can import macros by namespace, like any other item. So in your case: use clap::{App, Arg, crate_name, crate_version, crate_authors}; Where you have loops of the form for i in 0..foo.len() { // use i // use foo[i] } You may want to instead consider: for (i, f) in foo.enumerate() { // use i // use f } Where you have: match operation() { Err(_) =&gt; panic!("message"), _ =&gt; () } You can instead use: operation().expect("message"); Additionally, panicking (whether directly or via unwrap/expect etc.) should really be reserved for code paths that shouldn't be encountered (i.e. they suggest a bug). In a program this small, it doesn't make too much difference - but if you wanted to use this functionality as a library, you would want the caller to be able to choose what to do on an error. This is less painful than it may sound thanks to the `?` operator. Check out the [error chapter](https://doc.rust-lang.org/stable/book/ch09-00-error-handling.html) of the book.
Just some command line apps that I use at home and work (windows and mac) so I like to have the binaries ready to download. It might be too much to add into a default template then, if the use-case is a bit niche, and probably better to just add it to my local yml file?
It's the "I know better than anybody else when to use this crate name effectively" mindset, which inevitably leads to all of the best crate names becoming empty stubs.
TL;DR &gt; Judging by the lack of discovered relevant vulnerabilities and only a few miscellaneous issues, Cure53 has gained a rarely observed and very good impression of the examined Linkerd software complex and its surroundings. This June 2019 Cure53 project clearly demonstrates that the Linkerd product is fully capable of preventing major attacks and should be considered strong against the majority of malicious attempts at a compromise.
Yeah, it should be pretty easy to add as another step. Something like: ``` stages: - template: azure/stages.yml@templates - stage: binaries YOUR STUFF HERE resources: ... ``` Even in the `YOUR STUFF HERE` part, you could probably continue using some of the templates, such as `azure/install-rust.yml` :)
A classic! Consider at least tagging each chapter's commit. The downside to your repo structure is that you cannot fix a bug in a previous chapter without messing up the semantics of the commits.
I am trying to use [llvm-alt](https://crates.io/crates/llvm-alt): ``` use llvm; use llvm::{Compile}; pub struct CodeGenerator&lt;'a&gt; { builder: llvm::CSemiBox&lt;'a, llvm::Builder&gt;, module: llvm::CSemiBox&lt;'a, llvm::Module&gt;, vars: HashMap&lt;String, &amp;'a llvm::Value&gt;, ctx: &amp;'a llvm::CSemiBox&lt;'a, llvm::Context&gt; } impl&lt;'a&gt; CodeGenerator&lt;'a&gt; { pub fn new(ctx: &amp;'a llvm::CBox&lt;llvm::Context&gt;) -&gt; Self { let ctx = ctx.as_semi(); CodeGenerator { builder: llvm::Builder::new(&amp;ctx), module: llvm::Module::new("my-module", &amp;ctx), vars: HashMap::new(), ctx: ctx } } pub fn codegen(&amp;'a mut self, node: TAst) -&gt; Result&lt;&amp;'a llvm::Value, Error&gt; { match node { TAst::Int(i) =&gt; Ok(i.compile(self.ctx)), TAst::Bool(b) =&gt; Ok(b.compile(self.ctx)), TAst::Name(name, _) =&gt; Ok(self.vars.get(&amp;name).unwrap()), TAst::AddInts(lhs, rhs) =&gt; { let lhs = self.codegen(*lhs)?; let rhs = self.codegen(*rhs)?; Ok(self.builder.build_add(lhs, rhs)) }, _ =&gt; unimplemented!() } } } ``` This is the error i get: ``` error[E0499]: cannot borrow `*self` as mutable more than once at a time --&gt; src/codegen.rs:103:27 | 102 | let lhs = self.codegen(*lhs)?; | ---- first mutable borrow occurs here 103 | let rhs = self.codegen(*rhs)?; | ^^^^ second mutable borrow occurs here ... 108 | } | - first borrow ends here error[E0502]: cannot borrow `self.builder` as immutable because `*self` is also borrowed as mutable --&gt; src/codegen.rs:104:20 | 102 | let lhs = self.codegen(*lhs)?; | ---- mutable borrow occurs here 103 | let rhs = self.codegen(*rhs)?; 104 | Ok(self.builder.build_add(lhs, rhs)) | ^^^^^^^^^^^^ immutable borrow occurs here ... 108 | } | - mutable borrow ends here error: aborting due to 2 previous errors Some errors occurred: E0499, E0502. For more information about an error, try `rustc --explain E0499`. error: Could not compile `rhea`. To learn more, run the command again with --verbose. ``` I tried a lot of things but i can not find a way to fix this. I would be very thankfull for some help! I have a basic understanding of how the rust ownership system works, but i am having problems working with/around it in this case. I do not understand why my code does not work but this does: https://github.com/BookOwl/kaleidoscope-rs/blob/master/src/codegen.rs
Where's mine? Also, that's hella cute.
I had a look at Azure Pipelines, but at that time they don't support caching. Is caching supported now? If not, how much would that impact the time to build a project with lots of dependencies?
Looks like you were totally right, it wasn't using the chosen version _at all_! I fixed this in [this commit](https://github.com/jonhoo/rusty-pipes/commit/cd785e27cbec19263893377a08efe129151c45d4) by just adding ``` rustup default $RUSTUP_TOOLCHAIN rustup update $RUSTUP_TOOLCHAIN ``` to the Rust install step :)
Turns out I missed this line in the nomicon: " Note that we do not perform coercions when matching traits (except for receivers, see below). If there is an impl for some type U and T coerces to U, that does not constitute an implementation for T." This is a little annoying, but poking around GitHub, it looks like it's a [known issue](https://github.com/rust-lang/rust/issues/62530).
I am hoping someone can help with my intuition around global variables. So I understand that global variables are not really considered idiomatic in rust, since it's hard to make them play nice with the ownership model, but since I'm used to using them in other languages, I'm struggling a bit to figure out how to replace them in some cases. For instance, let's say I have a webserver which looks like this (all pseudocode so please ignore any syntax issues): // filesystem path to site data let const STATIC_ROOT = "/path/to/static/site/dir"; // stateless function fn on_request(req: HTTPRequest) -&gt; HTTPResponse { ... do something with STATIC_ROOT } main() { setup_http_server(&amp;on_request); } Now in this example, everything is fine, but what if I want to initialize the `STATIC_ROOT` based on a command line arg? If I were to write this in C, I would just remove the `const`, set the variable before setting up the server, and everything is fine. But it's not possible in Rust as far as I can tell. So what would be the idiomatic way to handle a situation like this?
That's super cool! My wife was teaching programming to children with the aid of Scratch, I'm pretty sure that she will think your project is cool!
Min rust source (10-20) lines + a couple weeks no commit = boot
Some possible rules: 1. After 3 months (or a year) if there's no source code, and no users of the crate, the name is revoked. 2. If a user has 3 crate names revoked, and doesn't have any sufficiently popular crates published, that user is banned from reserving crate names for a year. 3. Anyone who wants to reserve a top-level crate name needs to demonstrate some activity. 4. Allow username based crates (crates.io/user/myusername/cratename) where the user can make however many crates they want. 5. Have some kind of promotion process where a crate with a demonstrated userbase can move to the top-level namespace.
I've actually found that the much faster allocation of jobs on Pipelines makes up for the lack of caching. For very large projects, pulling in all the cached content (often many GB) is also frequently not even faster than a re-build (compare the speed of I/O to the speed of compute). That said, Pipelines now _does_ have caching as of very very recently. See [this GitHub comment](https://github.com/Microsoft/azure-pipelines-yaml/pull/113#issuecomment-508077422) and [the proposal](https://github.com/microsoft/azure-pipelines-yaml/blob/fd0dba2c61cbcd9e133e590015fda378055131b7/design/pipeline-caching.md). I haven't used it myself (yet), but it looks like you'd do the caching as its own task like this: ``` inputs: path: $(Pipeline.Workspace)/target key: Cargo.lock ```
The idiomatic way is to use the [lazy_static](https://docs.rs/lazy_static/1.3.0/lazy_static/) crate, which will initialize the value on first use. In your hypothetical case, you'd write something like // filesystem path to site data lazy_static::lazy_static! { pub static ref STATIC_ROOT: String = { // Assume that the first argument is the path to the root std::env::args().nth(1) }; } If you want to be able to modify `STATIC_ROOT` after its initial configuration, you'd wrap it in a `Mutex` (e.g. `pub static ref STATIC_ROOT: Mutex&lt;String&gt; = Mutex::new(...)`) or [`RwLock`](https://doc.rust-lang.org/std/sync/struct.RwLock.html).
Nothing different than any other language; you'd pass it in to \`on\_request\`, as an argument.
[Cargo.io](https://Cargo.io) need namespacing, badly.
Perhaps the [once_cell](https://docs.rs/once_cell/0.2.2/once_cell/) crate can help? One of its examples does something very similar to what you're describing.
&gt; Not the pointer itself, but the machine-level use- What does that mean? With _invalidated_ I meant the precise meaning of making a value _invalid_ per the Unsafe Code Guidelines. If the value is valid, no misoptimizations can occur. There is a restricted set of ways in which references can be invalidated. Creating a second &amp;mut T to the storage that's not derived from the first one, invalidates the first &amp;mut in stacked borrows, allowing such optimizations to happen, but then your program has UB, and the code at fault is the code that materialized this second &amp;mut T. &gt; It's not, that's the whole point. I don't understand how this can happen. Can you show an example ? &gt; It could be if we weren't crossing FFI, FFI isn't magic. For all practical purposes, FFI functions are _unknown_ _Rust_ functions. If you give an FFI function a `&amp;T`, and that function converts that into a `&amp;mut T`, it doesn't matter whether that function is written in C, assembly or Javascript. From Rust POV, that's UB.
Thanks a lot ! I'll try to edit my code according to your advice :)
That sounds like the right solution, tbh.
&gt;number of errors is getting very large with a lot of boilerplate you can fight boilerplate with macros. FromStr and Display can be derived in most cases.
Discussions about name squatting are as old as crates.io, the system we have now seems to be what we'll have in the future.
It's the Prisoner's Dilemma. If someone wants a crate name and doesn't squat it ASAP, they are vulnerable to losing it forever. So the impulse is to snag the name, which then makes the problem worse and everybody loses.
You have to use this old-style formatting in order for it to work on the old version of reddit as well: stages: - template: azure/stages.yml@templates parameters: minrust: 1.34.0 # integer atomics codecov_token: $(CODECOV_TOKEN_SECRET) resources: repositories: - repository: templates type: github name: jonhoo/rusty-pipes endpoint: jonhoo
To be exact, it is akin to `option.as_ref() == Some(value)`, which is quite a bit more verbose than `option.contains(value)`.
[https://github.com/linkerd/linkerd2/blob/master/SECURITY\_AUDIT.pdf](https://github.com/linkerd/linkerd2/blob/master/SECURITY_AUDIT.pdf) for those wanting to read the pdf online instead of downloading it immediately.
I can't actually tell what you did differently, but my guess would be four-space indent over fenced code blocks? Updated!
Wow
You got it! If you're using RES, you can click on the "source" link underneath posts to see the raw text =)
Got it, thanks! I also went back and updated a bunch of my old comments :p
In general I'd guess it's very similar to SAT solving (Boolean algebra forms a Semiring). I'm not sure I'd want Rust applying these transformations automatically beyond NPO though, but it's still a very useful mental model. If you're interested, you should check out what happens when you differentiate types! I couldn't find a rusty link, but try searching for "differentiating algebraic data types".
&gt; Edit: I just want to fix this so I can carry on. Can't you just re-install it?
`OnceCell` looks like exactly what I need, thanks!
Monitoring commits is just about the stupidest thing to do here.
I got the same error in IntelliJ. Don't remember exactly how I fixed it, but I reinstalled Visual C++ build tools, played around with toolchain, and reinstalled rustup and rustc at some point, and eventually it was fixed. Probably not that helpful, but good luck :)
NaN is a way of validating inputs; if you get a NaN result, you know the inputs are invalid. You can't effectively report that to your users if you're crashing from it.
The [dlopen](https://github.com/szymonwieloch/rust-dlopen#main-features) crate is also very handy. That link shows documentation comparing it with other popular dynamic loading crates.
I'm guessing you have a `chrono::DateTime`? That struct [implements](https://docs.rs/chrono/0.4.7/chrono/struct.DateTime.html#impl-Add%3CDuration%3E) the `Add` trait so you should be able to do this: let date = ...; //however you a getting your DateTime now date + Duration::from_secs(60 * 60 * 48) //60 seconds * 60 hours * 48 =&gt; 48 hours
[Ketos](https://github.com/murarth/ketos) is another Lisp implemented in Rust.
&gt;NaN is a way of validating inputs; if you get a NaN result, you know the inputs are invalid. You can't effectively report that to your users if you're crashing from it. You can't effectively report anything to users (besides "unknown error happened") if all you know is that your complicated algorithm returned a NaN. NaN is the floating point version of the [billion-dollar mistake](https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare/) (null references). Imagine a program that solves quadratic equations using the standard quadratic equation: (-b+-sqrt(b^(2)-4ac))/2a. If the only "input validation" that is done is looking at whether the result is NaN, and "no solution exists" is printed when a NaN is computed, then a bug is being masked. For the case where `a = 0`, solutions can actually exist, but the quadratic equation can't find them (because it evaluates to `0/0`); in other words, your program has a bug, because it prints "no solution exists" whereas a solution actually does exist. If you had instead implemented this program by crashing on NaNs and validating the input by, namely by determining whether a solution exists by checking whether `b^(2)-4ac &gt;= 0`, you would get better behavior: your program would only print "no solution" in the case where there is truly no solution, and your program would crash when `a=0`, which is what it should do, because your program has a bug (it can't handle the `a=0` case correctly). This isn't about speed; obviously skipping checks is faster. It's about correctness and handling errors sanely.
Not a big thing, but the `Display` implementation for `Counter` doesn't need to build multiple `Strings`: impl fmt::Display for FileCounter { fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result { let mut needs_newline = false; let new_line = |f: &amp;mut fmt::Formatter| { if needs_newline { write!(f, "\n") } else { needs_newline = true; Ok(()) } }; if !self.ops.no_count_files { new_line(f)?; if !self.ops.numbers_only { write!(f, "Files: ")?; } write!(f, "{}", self.file_count)?; } if !self.ops.no_count_folders { new_line(f)?; if !self.ops.numbers_only { write!(f, "Folders: ")?; } write!(f, "{}", self.folder_count)?; } if !self.ops.no_count_sym_links { new_line(f)?; if !self.ops.numbers_only { write!(f, "Symbolic Links: ")?; } write!(f, "{}", self.sym_link_count)?; } Ok(()) } } It can be shorter if you don't mind the extra newline at the end. You can also shorten it to a for loop: impl fmt::Display for FileCounter { fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result { let mut needs_newline = false; let new_line = |f: &amp;mut fmt::Formatter| { if needs_newline { write!(f, "\n") } else { needs_newline = true; Ok(()) } }; let entries = [ (!self.ops.no_count_files, "Files", self.file_count), (!self.ops.no_count_folders, "Folders", self.folder_count), (!self.ops.no_count_sym_links, "Symbolic Links", self.sym_link_count), ] .iter() .filter(|(cond, _, _)| *cond); for (_, name, val) in entries { new_line(f)?; if !self.ops.numbers_only { write!(f, "{}: ", name)?; } write!(f, "{}", val)?; } Ok(()) } }
&gt; This isn't about speed; obviously skipping checks is faster. It's about correctness and handling errors sanely. It is *entirely* about speed. Speed is the whole reason NaN's exist. It's faster to do a calculation and detect a NaN than it is to do pre-checks to avoid a NaN. Correctness is not even impacted; if a NaN is incorrect, then crash after you get one. Doing it before just slows everything down without increasing correctness at all. &gt;Imagine a program that solves quadratic equations using the standard quadratic equation: (-b+-sqrt(b2-4ac))/2a. Now imagine doing NaN checks after every intermediate computation.
Some folks in a [thread recently](https://www.reddit.com/r/rust/comments/bubtu8/which_error_crate_are_going_to_use_in_2019/) mentioned that https://github.com/shepmaster/snafu was useful for reducing boilerplate. Give that thread a read as well as [this one](https://www.reddit.com/r/rust/comments/bp47al/what_helper_crate_for_error_handling_and_why/) for more crates that you may find useful.
I think your main confusion here is between "asynchronous" code and "concurrent" code. Async functions are coroutines. They can yeild to their caller when unable to make progress and then be restarted later. Futures allow a single thread to make progress on multiple tasks (asynchronicity) and have nothing to do with dispatching tasks to multiple threads (concurrency). The `async` keyword does not spawn threads and the `await` keyword does not block them. Rust already has primatives for that purpose. Now, if you wanted, you could use an executer like tokio to spawn several threads and use them all to make progress on many futures. That would be equivalent to using goroutines. But an executer is not built into Rust itself because not everyone needs heavy-duty task scheduling. Some projects just want to use a single thread more efficiently.
&gt;Now imagine doing NaN checks after every intermediate computation. Uhh, if you [enable](https://linux.die.net/man/3/feenableexcept) the right flags on your processor, you get this [for free](https://www.gnu.org/software/libc/manual/html_node/FP-Exceptions.html). I'm now convinced you don't know what you're talking about, sorry.
I think "concurrency" *means* "asynchronous" code. It looks like what you call "concurrency" is more like parallelism. I am not confusing [concurrency with parallelism](https://blog.golang.org/concurrency-is-not-parallelism).
It's not free. Handling FP exceptions is slower than propagating NaNs.
Okay that's fascinating. That implies something has blocked rustc from existing, or deleted it from rustup's dir since you installed Rust. you could try finding the rustup toolchains directory, renaming the 'stable-x86_64-pc-windows-msvc' directory out of the way, and running `rustup toolchain install stable-x86_64-pc-windows-msvc` to see if it can successfully reinstall it.
So it looks like IntelliJ is the new cool kid on the block. The visible inferred types are nice, but is it possible to configure it so that they only appear if, for example, I press ctrl?
People rarely care about the cost of handling exceptional cases because they're just that; exceptional. If you're going to display an error on the screen, that takes a larger amount of time than handling a FP exception. Enabling FP exceptions doesn't hurt the common case.
I do not know if there is "middle ground," but IMO there is nothing wrong with executing a function that does IO synchronously, if one wishes so. It looks more reasonable to leave the choice to the caller, given that it would costs nothing the function's author. (It also looks like an intelligent compiler or linker could avoid keeping an unused version of the sync/async compiled function.)
This is exactly what i do!
People will then squat namespaces. Optional namespacing would be nice (being able to group all related crates from an org) but mandatory namespacing doesn't quite fix this.
A goroutine does not necessarily spawn a kernel-level thread but it does spaen a "green thread": a concurrent task, managed by the Go runtime itself, which might be executed simultaneously. Async functions and generators in Rust are functions who's state can be saved. The `await` keyword does nothing more than write the call stack to memory and return. The tokio/rayon/actix crates are different ways of dispatching tasks (whether async or not) across OS threads. They provide goroutines in the Rust language. Async/await does not.
Rust does not have a `with` like Kotlin? So you could replace write `with(a) { x = 1; y = 2; } ` rather than `a.x = 1; a.y= 2;` . Any chance that it will be added to the language?
&gt; pass it to a static variable This is word salad.
That's only true if your goal is to crash when a NaN is produced. If you want to handle it in any other way, it is definitely slow, either because you now have to recover from a trap, or because you have to do more detailed checking to avoid a trap. We can argue about what is more a common need, but I don't usually want my programs to crash on NaN, and I largely write numerical software, games, and interpretted languages. These are not uncommon things.
You said &gt; I do not understand why `async` should annotate function definitions and not function calls. [..] simply call an ordinary function with an `async`-annotated call to make it return a future. If `await` appeared in a function that is not called with an `async`-annotated call, it could behave like `block_on`, for example. Correct me if I am wrong but it seems like you picture the async keyword as a way of dispatching tasks. Like, I could type `async myFunction()` to execute `myFunction`elsewhere (although not necessarily on a different thread). But in Rust, calling an async function is a no-op! Literally no work is performed. It is really the `await` keyword that switches between tasks and performs work. If you are an async function that `await`s on a future, one of two things can happen. If the future can make progress, execution switches to the async function who's state is stored in that future. If no work can be performed, then your state is stored in a future and execution switches to whoever `awaited` on you.
`error: libssl.so.1.1: cannot open shared object file: No such file or directory`
Sorry, did you just edit your comment? I think a saw some interesting details i did not have time to think about, but now i do not find them...
in my case `libssl.so.1.1` lives under `/usr/lib/` so I set `OPENSSL_LIB_DIR` to `/usr` but nothing changes the so file is there but rust doesn't work with that. This issue come from `psl_codegen` library which is a dependency of `chttp` library people suggested to install `libssl-sys` but isnt this supposed to be handled by the library author ?
That will panic on recursive call, no?
I was suggesting a purely syntactic transformation from the actual Rust with `async`-annotated definitions to a hypothetical Rust variant with `async`-annotated calls, and i was expecting that with an appropriately defined semantics, such transformation would preserve the meaning of the "old" code transformed into the new form, but that the new form would allow greater flexibility. I am trying to understand the issues with such a hypothetical Rust variant. I was proposing `(async myFunction)()` call to return a future. Like what `myFunction()` currently does when `myFunction` is defined with `async fn myFunction()`.
And, buoyant (linkerd company) pays for much Rust OSS development (Tokio, Hyper, Tower)! All of this is in service of the linkerd proxy.
for your first question check the docs here https://www.nalgebra.org/vectors_and_matrices/ , under the section about slices it says: Assignment operators do not work on any kind of slice, i.e., one cannot write a *= b if a even if a is a mutable matrix slice. This is actually a limitation of the current design of nalgebra that will be fixed in the future. Use a.copy_from(&amp;(a * b)) as a workaround. So you can change it to: mat_3_ref.copy_from(&amp;Matrix3::identity());
It's squat or be squated.
For assignment, no, but for initialization, there's a special syntax where you can `let x = { a: 1, ..y }` to get all values from `y` except for `a`.
This is an unfortunate drawback of the conversion traits, that has been known for a long time (that they are fragile to changes like this, when used "non-generically").
&gt;If you are an async function that `await`s on a future, one of two things can happen. If the future can make progress, execution switches to the async function who's state is stored in that future. If no work can be performed, then your state is stored in a future and execution switches to whoever awaited on you. Is this exact? I thought that if future that is being `await`ed cannot progress, that the state is stared and the control is yielded to to the executor, not the async function that is `await`ing on the current one and thus is blocked too...
You can remove the `.ok_or(..)`s with suitable `From` implementations for your `ParseError`. There are `proc_macro` crates for deriving those.
A couple of random thoughts/suggestions: * Assuming this doesn't exist already, I think there should be a feature tree that clearly shows hard, soft, and co-dependencies. On that tree, you can decide branch priorities and go from there. * A permanent expansion on the *No RFC period* experiment might be warranted. Maybe new RFCs should only be excepted on odd months! Furthermore, maybe FCPs should be limited to every other even month! Three FCP periods every year ought to be enough, no? What warrants an exception should be clearly defined, with the abovementioned feature tree providing an ultimate reference. The exact details can be modified of course (e.g. to align with releases).
Another is [Arret](https://github.com/etaoins/arret).
Thanks
Okay, so you're not saying it's a fundamental language limitation, just an ecosystem shortcoming. I misunderstood; I thought you were saying replacing C++ would be *impossible* (even in the future). Have you taken a look at `nalgebra`, which another commenter said is aiming for feature-matching with `eigen`?
Pretty close, although I was simplifying to make a point. Remember, the executer is not a part of the language itself and is independent of async/await/futures. Technically, when you poll a promise, control is always transfered to that promise whether it can make progress or not. And when a promise cannot make progress, control is always given back to whoever polled it whether they awaited ot not. `await` is a syntactic sugar which just polls a promise and then yeilds itself if `poll` returns `Incomplete`. An executer is just a structure which holds a list of promises to continually `poll`.
Both rust-analyzer as RLS/racer are in the working-in-progress state. I think Rust analyzer will mature well to replace the current racer-based RLS and become quite fully featured, but at this moment it's not yet there, so, all official IDE tooling by the Rust project didn't yet show its strength to compete with IntelliJ, but I believe it'll eventually, I think this is true b/c Rust analyzer is being developed on top of core infrastructure of the Rust compiler.
&gt; Based on the talk by Carl Cook, these systems are small and even use elegant (or dirty) tricks like indexing an array with a boolean to skip an if-branch. Not necessarily that small ;) However the "unsafe" core is pretty small, mostly limited to the network interface when overlaying structs on slices of bytes, etc... actually, Rust is better here as it's not UB in Rust so long as the alignment is handled correctly. Indexing an array with a boolean is just indexing with `my_bool as u8` in Rust for example; it's covered. Branches can also be lifted to the type-level. Honestly, though, CPUs handle branches just fine, and you can get to 2.5 us with branches and virtual calls. Memory layout matters a lot more, and of course the few hot loops. &gt; Almost all allocations are stack based. I wouldn't know how to do it in rust right now. You can mostly use arrays: `FixedVector&lt;[T; 16]&gt;` is a bit more cumbersome than `FixedVector&lt;T; 16&gt;`, but is workable. There's no need for a generic allocator when you can write code that does not allocate, or when you can pre-allocate at start-up. It's a discipline, though.
Lol, "squat namespacing"? Really? Never seen this been done in any other community, wonder why this would be a problem for [Cargo.io](https://Cargo.io) and not for other communities.
To be more explicit, I would say that any other solution will not be considered, unless we have a proper benchmark showing absolutely no performance loss in a use case similar to ours. To be honest, I would love to escape from C++ and CRTP… I will try nalgebra a bit this WE :) But I still think that we can keep C++ for performance-critical libs, Python for scripts, prototypes &amp; tutorials, and move to a more modern langage like Rust for everything in between (and currently, in our case, that's a ton of C++ projects / SLOC). For this, all we need is a nice way to interract between each layer, not a state-of-the-art huge linear algebra lib.
I think the problem you are referring to is The Tragedy of the Commons.
Would love to collaborate on this. Over at crate-ci, we started [experimenting with templates](https://github.com/crate-ci/resources) . We slowed down a little after some talk with [spontoreau about turning his Azure Task into something more like our rustup template](https://github.com/crate-ci/resources/issues/2) since that would improve the usability of it. Since it seems he hasn't gotten to it yet, it'd be great if someone had the time to step in and contribute an update to his Task. I've been mixed about how much pre-packaged logic we should provide. For example, I see you have a `cargo check` template that can be great for a lot of people but once people need something beyond what you provide (for example, specific feature combinations), they have to instead roll their own.
Caching can sometimes hurt more than help. For example, there was a post in the last year about how much the `target` and other folders can explode, causing a lot of slow down due to deploying the cache to the build node. It had recommendations on what directories to clear out after every build to avoid them being cached, to keep the cache sizes small enough to actually be helpful.
Right, I'm absolutely not surprised to hear that C++ isn't replaceable *yet*, I just thought you were saying it never would be!
I deleted a previous comment that I didn't like. Here it is if you are still interested in reading it: &gt; A goroutine does not necessarily spawn a kernel-level thread but it does spaen a "green thread": a concurrent task, managed by the Go runtime itself, which might be executed simultaneously. &gt; Async functions and generators in Rust are functions who's state can be saved. The `await` keyword does nothing more than write the call stack to memory and return. &gt; The tokio/rayon/actix crates are different ways of dispatching tasks (whether async or not) across one or more OS threads. They provide goroutines in the Rust language. Async/await does not.
That sounds like a great idea! Yeah, so, rusty-pipes is pretty opinionated about its default deploy (i.e., `stages.yml`), but there's nothing stopping users from mixing and matching individual templates (even using `install-rust.yml` directly). I think that probably strikes a good balance. For example, if someone wanted cargo check with a particular feature combination, they could still use the template and write: - stage: feature-check jobs: - job: feature-check displayName: cargo check --features XYZ pool: vmImage: ubuntu-16.04 steps: - template: azure/install-rust.yml@templates - script: cargo check --features xyz displayName: Run cargo check w/ XYZ
One more thing: you don't need `.enumerate()` when you're not using the `i` component. The `iter()` call produces an iterator over the items in your vec: for f in foo.iter() { /*...*/ } The additional call to `.enumerate()` produces an iterator of items from the original source, paired with the count numbers. The [`Iterator`](https://doc.rust-lang.org/std/iter/index.html#for-loops-and-intoiterator) docs are worth a read to grasp when and how to use Iterators.
Yes. It isn't impossible to implement something like `let myfuture = (async myFunction)();`. But `myFunction` won't do any work until control is handed over to it by a call to `poll`, and then it will do all it's work and return normally. Since the async keyword doesn't dispatch `myFunction` to any kind of executer, all you've created is an extra complicated way to delay ordinary function calls! 😁
To summarize, after Chris Krycho announced that the New Rustacean podcast was winding down, there seemed to be a bit of interest from others in continuing on making Rust podcast content so I gathered a bunch of people together in a place and we made some noise for a while and this is what happened. :) Basically, none of us individually were up for taking on any more responsibility in the vein of spearheading a new podcast, but we realized that once the constant cost of setting up a new podcast was already paid (website, twitter, RSS feeds, hosting solution, podcast indexing), it would be relatively simple to push new content out to it as long as we could do so at our leisure. Thus our plan right now is to have just one regularly-recurring podcast under this umbrella, which will be the once-per-six-weeks Rust changelog discussion as featured here. All other episodes will be intermittent and on a variety of topics, and if any of **you** out there would like to toss an audio file at us for us to put up, get in touch with us on any of the venues listed in the show notes. :) TL;DR: it's a Rust audio 'zine, cut-and-pasted together and photocopied on the office printer. :P
An interesting effect of Rust's futures system is that futures are trivially cancelable until you hand them over to an executer crate. Just stop calling poll!
I don't have time to \*really\* answer your question, but you should check into "scoped threads" via scoped\_threadpool or crossbream.
&gt; With invalidated I meant the precise meaning of making a value invalid per the Unsafe Code Guidelines. If the value is valid, no misoptimizations can occur. There is a restricted set of ways in which references can be invalidated. Creating a second &amp;mut T to the storage that's not derived from the first one, invalidates the first &amp;mut in stacked borrows, allowing such optimizations to happen, but then your program has UB, and the code at fault is the code that materialized this second &amp;mut T. Then we agree. My initial comment was just trying to point out that this definition ("Creating a second &amp;mut T to the storage that's not derived from the first one, invalidates the first &amp;mut in stacked borrow") is a bit stronger than your initial definition ("do two &amp;mut to the window object exist, that can be independently used to access the object ? If not, you are ok."). That is, the first `&amp;mut` being "hidden" up in some caller stack frame is insufficient to prevent it from being invalidated. &gt; FFI isn't magic. Right, all I'm saying here is the Windows API doesn't pass around Rust references, so it's harder to convince rustc that the inner `&amp;mut` is derived from the outer `&amp;mut`. Doing so probably involves some weird tricks with wrapper Rust functions, if it's possible at all today.
As long as mixing and matching is supported, sounds great to me. If your interested, I can add you to the crate-ci so you can get your stuff merged in with outs and we can work on updating the docs.
`digest` is a Sha1, which [implements Copy](https://docs.rs/rust-crypto/0.2.36/src/crypto/sha1.rs.html#382). This means they can be moved into a closure while still being valid. `mac` is a `Vec&lt;u8&gt;`, which can't be `Copy`-ed and needs an explicit `.clone()` call.
Look at std::ptr, there are ptr::read/write_volatile: https://doc.rust-lang.org/std/ptr/index.html also look at recent discussion about its usage: https://internals.rust-lang.org/t/add-volatile-operations-to-core-x86-64/10480
Sounds like you want [ptr::read_volatile](https://doc.rust-lang.org/std/ptr/fn.read_volatile.html) and [ptr::write_volatile](https://doc.rust-lang.org/std/ptr/fn.write_volatile.html)
I built a Q IPC crate in Rust that allowed me to create some sort of KDB+ cluster data-portal API (HDB/RDB/TP), read protobuf-serialized object-graph defining a query, fan-out to the KDB+ shards (one per instrument type), generate K queries, aggregate snapshots and maintain live tick subscription, then send all this in a neat package to the caller. There was a C#/C/VBA package, but more interesting was a pyo3-backed python module that would take this query and produce pandas data frames (KDB types were swapped for numpy-friendly types when aggregating) for snapshots and live updates (based on a polling call from the client, didn't really have time to look into using python's async) I also built a bar builder in Rust called `barman` that would generate a request for (second/minute/hour) bar and send it to the RDB, then republish it to the TP. I did this in rust because... I despise Q's `\t` ;) The performance of the system blew my mind. Faster than the C# reference implementation, and much more stable than pyQ. If I have the time I might do a talk about this system to the London Rust group, loved this system to bits, and saved a ton of time for the quants (they didn't have to learn Q to feed their models). The only negative point was that I had to really investigate a pyo3 bug without being able to contribute code to pyo3 (thanks compliance dept!) - and TBH when someone asks me about using Rust in their fund, my answer is now: If your compliance dept allows you to publish bug fixes to OSS projects, by all means, use it!
As has been mentioned, Rust qualifies reads/writes (using `ptr::read_volatile` and `ptr::write_volatile`) rather than qualifying types. I am otherwise very confused by your description, as you are mixing: - `volatile`, used to communicate with hardware. - [`atomic_thread_fence`](https://en.cppreference.com/w/cpp/atomic/atomic_thread_fence), used to communicate across threads. In general, communicating with hardware requires different strategies than communicating across threads, and mixing strategies for either purpose only results in mystifying behavior. It would be very helpful if you could clarify your usecase: - Hardware communication: GPU, DMA, ... - Inter-process communication: shared memory, ... - Multi-threaded communication: atomics, fences, ...
What's the use case for this?
Awesome! I'd love subscribe with my podcast app. Where's the RSS feed?
The RSS feed is at https://rustacean-station.org/podcast.rss, though it _should_ also appear in most major apps [soon](https://twitter.com/rustaceanfm/status/1149738771484561408).
lsp-ui has been a little janky for me, although perhaps I have it configured improperly. I have it disabled since I'm fine just with the company lsp support.
What's the URL of the feed so that I can subscribe?
It's at https://rustacean-station.org/podcast.rss , and it should be possible for others to subscribe via other podcast venues (e.g. iTunes) as we slowly grind through the approval process for all of them.
I realized it may not an easy question and decided to post it on (StackOverflow)[https://stackoverflow.com/questions/57012729/how-to-limit-hard-drive-disk-i-o-when-reading-writing-a-file-on-disk]. I still welcome any feedback here though.
https://rustacean-station.org/podcast.rss :)
Interesting. Not the kind of thing that I would turn to Rust for necessarily, but I am definitely interested in the subject of welding something like GraphQL onto kdb backends. Did the object graph protocol you mentioned have specific support in your firm?
This thread is for the Rust Programming Language, not the game.
Maybe the middleware was originally written for MSVC. There, volatile (used to?) imlply release/aquire semantics.
oh shiiii
I have removed your post, which was likely meant for /r/playrust, to save you from further embarrassment. Please next time read the sidebar before posting.
Aw yeah, so looking forward to another Rust podcast. The "'zine" format actually really makes me want to consider throwing some audio files your way! :)
How about putting a link to that onto the page? Or better yet: Add a subscribe button. The podlove.org people made one that works with most podcast apps plus a bunch of other infrastructure to publish podcasts.
Mostly, making sure you're not including malicious code with your dependencies.
There was a mistake in the documentation were pointing to "Glossary" instead. The fix is released, but docs.rs did not build the documentation for 2 hours now, so in case you need it... the Getting Started Guide is available here as well: https://github.com/dpc/crev/blob/master/cargo-crev/src/doc/getting_started.md
Note that Azul is currently \[unmaintained\]([https://www.reddit.com/r/rust/comments/c24b57/azul\_the\_gui\_framework\_will\_be\_unmaintained\_from/](https://www.reddit.com/r/rust/comments/c24b57/azul_the_gui_framework_will_be_unmaintained_from/)). The link mentions that parts may be broken right now.
Hey new to rust and I am trying to parse a csv file to get familiar with it. The issue I am running into is that when I use the &lt; sign to feed a filename I get an out of bounds error. Example: main &lt; test.csv: thread 'main' panicked at 'index out of bounds: the len is 1 but the index is 1', /rustc/a53f9df32fbb0b5f4382caaad8f1a46f36ea887c/src/libcore/slice/mod.rs:2695:10 note: Run with `RUST_BACKTRACE=1` environment variable to display a backtrace. I'm having 0 luck with google.
You should!
Have you tried prefixing RUST_BACKTRACE=1 to your command?
Really awesome to see this idea crystalize. Thanks for putting in all of the ground work!
Yep, we added the link about half an hour ago after seeing the comments here. :) If anyone else would like to make improvements to the site, feel free to take a whack at it! Here's the repo: https://github.com/rustacean-station/rustacean-station.org
Sounds good!
Do it!
If your program is too fast, you could sleep it. You'd have to decide on a throughput. Then you check every x bytes how much time it took, if it's too fast, you sleep for the rest of the duration. That's a very simple solution (and not 100% accurate) but it will slow your program. I don't know much about io stuff but it seems weird that your Rust version is twice as slow when it's not alone. Even if the HDD is the bottleneck it should be as fast as your other implementation at worse, not twice as slow.
Yes, but nothing decipherable by me. &gt; stack backtrace: 0: std::sys::unix::backtrace::tracing::imp::unwind_backtrace at src/libstd/sys/unix/backtrace/tracing/gcc_s.rs:39 1: std::sys_common::backtrace::_print at src/libstd/sys_common/backtrace.rs:71 2: std::panicking::default_hook::{{closure}} at src/libstd/sys_common/backtrace.rs:59 at src/libstd/panicking.rs:197 3: std::panicking::default_hook at src/libstd/panicking.rs:211 4: std::panicking::rust_panic_with_hook at src/libstd/panicking.rs:474 5: std::panicking::continue_panic_fmt at src/libstd/panicking.rs:381 6: rust_begin_unwind at src/libstd/panicking.rs:308 7: core::panicking::panic_fmt at src/libcore/panicking.rs:85 8: core::panicking::panic_bounds_check at src/libcore/panicking.rs:61 9: &lt;usize as core::slice::SliceIndex&lt;[T]&gt;&gt;::index 10: core::slice::&lt;impl core::ops::index::Index&lt;I&gt; for [T]&gt;::index 11: &lt;alloc::vec::Vec&lt;T&gt; as core::ops::index::Index&lt;I&gt;&gt;::index 12: main::parse_csv 13: main::main 14: std::rt::lang_start::{{closure}} 15: std::panicking::try::do_call at src/libstd/rt.rs:49 at src/libstd/panicking.rs:293 16: __rust_maybe_catch_panic at src/libpanic_unwind/lib.rs:85 17: std::rt::lang_start_internal at src/libstd/panicking.rs:272 at src/libstd/panic.rs:394 at src/libstd/rt.rs:48 18: std::rt::lang_start 19: main 20: __libc_start_main 21: _start
Thank you, that makes much more sense!
Thanks! I will investigate about that
Wouldn't it just be Rustation?
And there's really no good reason not to have `Option` have as collection-like API as possible, after all, it *is* a collection (of up to one item).
The `unsafe` block is the innovation, the innovation is in the dichotomy. Python is a mostly-safe programming language with escape hatches (ctypes or numpy etc allow raw access to memory and the equivalent of dereferencing and read/writing through arbitrary pointers). What Rust contributes is the `unsafe` keyword and a structured way to keep the escape hatch system and parts that use it clearly marked.
podlove.org button added!
&gt; In a certain sense, this means that everything written in Python is memory unsafe. Eh? Is this a typo? Python is memory safe. The ffi plays the role of unsafe in Python.
&gt; 11: &lt;alloc::vec::Vec&lt;T&gt; as core::ops::index::Index&lt;I&gt;&gt;::index &gt; &gt; 12: main::parse_csv This means you have an index operation (`some_name[1]`) out-of-bounds in your `parse_csv()` function.
I tried snagging that as the twitter handle since "RustaceanStation" was too long by one letter, but it's already been taken. :P
What does your actual code look like?
FYI, parse_address support has landed in master, and is out on crates.io as 0.2.0. Cheers.
I really hope those with authority to enforce name allocation, would listen to the above recommendations and implement them.
ruststacean seems to be avail
They address this. Python, in theory, *purely* is memory safe. Pure Python does not exist in practice. If you use CPython, even without importing a single module, you will already be calling into C (just by constructing a List, for example). In practice it is in fact far, far worse than this. Python libraries, including std, are absolutely littered with unsafe bindings. To top it all off, Python really does very little of what a language like Rust does to hedge against this. Compiler mitigations are slow to be implemented, CVE practices are really weak, the runtime provides tons of good tools to leverage in an exploit (RWX memory, etc). Calling Python memory safe is true in that Python is merely a syntax, but there is no reality in which you can write memory safe Python.
It looks like some of the example code got out of date and was fixed [on master](https://github.com/maps4print/azul/pull/180) recently. Are you running an optimized build (`cargo run --release`)?
No, they post clearly states that they **might** start using it. `re2` is also considered.
Hey ! Thanks, have read the docs, it makes sense for me now !
Subbed! Can't wait to listen to the first episode.
Your best bet is rust-qt-bindings-generator, you write your models in rust, and then setup your widgets with qml(qt quick)/c++ (qt widgets) that use those models. I'd recommended gtk-rs instead
What exactly are you saying is `fn(&amp;self) -&gt; R`? All functions of type `fn() -&gt; R` do in fact implement `Fn() -&gt; R`. I'm not sure where the problem comes in.
Some more small suggestions: * You can `#[derive(Default)]` on a struct and it will implement `Default` by using the default for each of it's fields. * There isn't much point in checking whether you want to count something before incrementing it. I'd just go ahead and count everything, since it's hardly a difference in the amount of work, simpler, and avoids some branching. Then at the end, only display whatever the flags are configured for. * Consider returning `Result`s from some of your functions. Along with `?`, this can probably simplify your error handling. You could either return `Result&lt;Whatever, Box&lt;dyn std::error::Error&gt;&gt;` or create your own enum/struct and return `Result&lt;Whatever, MyError&gt;`. I see that your `main` currently returns a `Result` but doesn't actually have a way to return an `Err`. You could replace your `error_message`s with returning `Err`s. * Consider making the default value for the dir argument be the current directory (you can use structopt to do this).
Yes, I think mostly you would want to remove files from the project being built itself, but keep dependencies. I hope Cargo can provide a parameter to only build dependencies, so that there is a chance to cache just that.
Maybe this example will clear it up. I want to write this function. my goal is that \`foo\` acts as an adaptor. it takes as input a function and returns a new one. this does not compile because the closure encloses something, and so it does not match type \`fn(A)-&gt;B\`. this is reasonable since foo() can be invoked with the same types A and B but different values for \`f\`. obviously some dynamic dispatch is required, so the closure encloses the given pointer. \`\`\` pub fn foo&lt;A,B&gt;(f: fn(A)-&gt;B) -&gt; fn(A, \*mut B) { |src, dest| unsafe { dest.write(f(src.read())) } } \`\`\` Instead I want to make sure that for each combination of generics, exactly one input function is known statically, like my original Clone example. This works for Clone since \`&lt;C as Clone&gt;::clone\` is always the same static function for each instantiation of \`C\`. What I am asking is how can I take this clone idea and make the function applicable to ANYTHING that acts like a function. \`Fn()\` is a trait like clone, but it has a receiver, meaning that it encloses some state. this means it cannot be the same as fn().
follow up: here is something that ALMOST works. but I require the user implementing this silly helper trait. ``` pub trait Trait&lt;A,B&gt; { fn f(&amp;A) -&gt; B; } pub fn foo&lt;T: Trait&lt;A,B&gt;, A, B&gt;() -&gt; fn(*mut B, &amp;A) { |dest, src| unsafe { dest.write(T::f(src)) } } ```
I wonder if it would be a good idea to wrap volatile pointers in something similar to `NonNull`. Some `Volatile&lt;T&gt;` wrapper that provides `unsafe` `read`/`write` methods that use `read_volatile`/`write_volatile` internally.
&gt; Or is it unergonomic to use Qt with rust? I would also appreciate if anyone could point me to an open source app which uses both rust and Qt. It is pity, my application is closed source :( I use rust_swig to generate C++ binding to my Rust core. And then from C++ I used Qt for GUI.
There are some crates that do things like this. One example is [voladdress](https://docs.rs/voladdress/0.2.3/voladdress/)
That's if the function does not have any `await`s. I was thinking that being allowed to call a function with `await`s either synchronously or asynchronously would not hurt. But I've realised that calling an asynchronous function synchronously can be accomplished with `block_on`. However, what if a function `f` that does not contain any `await` calls (noramlly) another function `g` that has an `await` (but the first function `f` does not know about it)? The users of the function `f` should be free to decide whether to call it synchronously or make into a future.
Wrong subreddit. You're looking for /r/playrust.
Similar arguments can be leveled against rust as CPython. There's no way to directly execute Rust either, it compiles to binary, which is entirely unsafe. At the end of the day you're just hoping the compiler doesn't make you safe code access uninitialized memory, same as you're just hoping CPython doesn't do the memory morris dance or whatever else undefined behavior could show up. So the real difference is that python doesn't care that you're using the FFI much at all. Rust cares a little bit, but only because the keyword makes it so you can grep for `unsafe` and get a good idea of what to look at in case you care.
Neat! Glad I'm not the first to think of that.
Awesome. I've been missing a Rust podcast since New Rustacean shut down. Why is the first episode marked with the release date of March 26th though?
I see, thanks for letting me know.
Except when you do dependency upgrades, you'll want to flush it which is every build if you don't check in a lock file.
This sounds kinda like of what you want, although if I'm interpreting your last part right then it's not quite what you want. pub fn foo&lt;A, B&gt;(f: fn(A) -&gt; B) -&gt; impl Fn(A, *mut B) { move |src, dest| unsafe { dest.write(f(src)) } }
&gt; “But Nora,” I hear you asking, “if Rust provides an escape hatch from its guarantees, and the standard library is implemented using that escape hatch, isn’t everything written in Rust unsafe?” &gt; In a word, dear reader, yes - in exactly the same way that everything in Python is.
I think the problem is that if it's released *at all* people are going to pick it up and use it. I see the problem as more that there are very very useful things in nightly (ex: Specialization) and so crates choose to go nightly because the value proposition is just really big. So, maybe that means something along the lines you're suggesting, where the only things that actually go into nightly are things that the team has super high confidence will ship soon, or things that are relatively low value and so wouldn't entice so many devs?
Yes I tried some other example code that I found that was more up to date but it gives the same result, as does --release. Nevermind. Conrod seems to work very well and I've still got a couple of others to investigate - although they look a bit more intimidating, to a rust newb at least!
I literally wrote: &gt; fn main(){} and it failed with that error which is why this is so weird.
The lowest-level parts of the crypto are written in assembly language borrowed from OpenSSL/BoringSSL. We need non-assembly-language implementations for those functions to support WebAssembly. Also, we needed to interface with the CSPRNG.
I was checking gtk-rs and it seems it’s possible to use glade alongside. I’ll try it out. Thanks for the suggestion.
So you compile your rust as a cdylib and perform calls from the c++ side. Did you notice any downsides?
Perhaps you could ssh into your home computer, and have everything set up there.
Yeah, totally, I considered clarifying that no pure language really has an implementation, almost by definition. Still, the point is that when you write Python you're really nowhere even near pure, and, as I mentioned, to make things much worse, Python doesn't spend much time making up for that, whereas Rust does. The point is that when you write Python there's a bit of Python syntax and a ton of C code. With Rust the ratio is generally way different.
Currently using gtk-rs and relm on a project. I approve.
I'm sorry, I believe you mean "squat or be squate". :D
Bit of both, really.
&gt; For my own two cents: Generally, in Python, entire modules will be implemented in C, not tiny chunks of logic — and C actually does less to protect you from yourself than even unsafe Rust. Right. I agree that at a social/cultural level, Rust's model encourages better behavior. I just argue that the preceding paragraph built up Python's safety story (which is great in comparison to say C++). But then it backpedals and seemingly contradicts itself. I really did feel like it could have been a typo the way it's all phrased. But yes. I agree with this point you made. Although I will say that the reason people dip into the FFI is mostly due to Python's runtime being too slow and heavy, and people do it for performance they can't otherwise get. So, in this sense, I might argue that Rust's *speed*, just as much as its `unsafe` keyword, offers the safety that Python lacks.
Yep, cdylib or staticlib. The last one is easy for end user deployment, but harder for developer. With recent rust_swig master there are not many downsides, now I even can describe rule to convert FnOnce to QFuture. I use cmake to call cargo, so I can edit code in CLion like ordinary C++ project and open rust files within same IDE via rust plugin. But this is for desktop. I use widgets based Qt API. Have no idea about how convenient it to use QML. I also port my application to Android, but for some complicated reasons I reuse Rust core and use Java / Android SDK for GUI.
What advantage does relm add to gtk? I couldn’t tell from the github page, and for some reason the crates page doesn’t display correctly!
Omg I love this!
I've been using the [volatile](http://docs.rs/volatile) crate and its `Volatile&lt;T&gt;` type a bit for this, and it's basically this. Only differences I can see are that it's not a pointer type, so you'd use something like `&amp;Volatile&lt;T&gt;` or `*const Volatile&lt;T&gt;` instead, and that its `read` and `write` methods are safe.
That’s interesting. Especially the rule to convert rust futures to QFuture. I think QML wouldn’t be any different. Define and register a qmlcontext on the c++ side, and forward calls from the qml side to rust I imagine.
Have you recompiled your code? If your `main()` is empty then absolutely nothing should be getting executed, so something is out of sync here.
Yes I realize I could use some form of `wait()` between each read/write call to the HDD. But it's also the easiest solution. I'd like to find a solution that let me know of the current available I/O rate with the HDD and let me decide with some sort of of formula the rate at which I decide to read/write from a file on disk. And I also agree with you on your second point, I'm still looking for the reason why my program is twice as slow when other processes are also running. I'm far from being knowledgeable on this subject, that's why I'm only reporting on what I've observed so far, that is my program is twice as fast when alone, but also twice as slow when other programs are running.
Relm is basically a nicer way to write gtk stuff. That said, last time I checked their macro didn't cover many widgets/methods, it required nightly, and it was behind in keeping up to date with the latest gtk-rs release, which is itself behind in keeping up to date with gtk. I'd recommended to just use plain gtk-rs, if you have any issues feel free to let me know, and/or come join the #gui-and-graphics-dev channel on the rust community discord
&gt; What she's getting at, I think, is that ultimately everything is unsafe at a low enough level, but Rust's unsafe is a positive step for managing the unsafety. It's also bollocks, imo, that everything in Rust is unsafe. To say that is to say that 10,000 lines of Rust written on top of an unsafe foundation is not inherently more safe than 10,000 lines of C written on top of an unsafe foundation. It's madness. Every LOC you write introduces debt and risk. If a language was 100% safe it would mean each LOC you add *does not increase the overall risk*. The more unsafe each LOC you add *the more risk you add*. It's as simple as that, imo. I'm also speaking very loosely, too. A language you understand is likely more safe _(relatively speaking)_ than one you do not understand. As with everything the devil is in the details.
I apologize for not making this more clear, but what you're stating here is exactly the argument I'm advancing in the post. &gt; In Python, the burden of ensuring that raw memory manipulation is safe falls only on the interpreter maintainers and the users of the foreign function interface. In C, that burden is on every single programmer. &gt; In Rust, the burden falls on the user of the unsafe keyword. It’s clear, within the code, where variants need to be manually upheld, and it is common to strive for zero unsafe code anywhere in a library or application’s codebase. The unsafety is identified, segregated, and clearly marked, so if your Rust code segfaults, you have discovered either a bug in the compiler or a bug in your few lines of unsafe code.
Aha - you fell into my trap! Rhetorically speaking. Yes, of course we don't call Python an "unsafe language" - but if we don't call Python an unsafe language, it's unfair to conclude that Rust is unsafe, since Rust actually does a better (imo) job of segregating and controlling unsafety.
let lithp = String::from("Lisp").replace("s", "th");
&gt; Maybe the middleware was originally written for MSVC. There, volatile (used to?) imlply release/aquire semantics. It still does by default on non-ARM processors for backwards compatibility, but the interpretation is configurable and Microsoft "strongly recommends" that you set it to standard semantics.
Thanks
Thank you for the offer and for your helpful explanation. Really appreciate it.
Well you see, in the US we don't use metric, so in order to convert from European dates one first must subtract 32 and multiply by 5/9, leaving us with March 26.
No problem
Heya, I should have been more clear as well - I did not mean your post was bollocks _(I'll edit my post)_, I meant specifically that snippet I quoted was bollocks. I was primarily replying to that one concept, regardless of your post. Apologies for any confusion I caused. Have a great day :)
what do you mean?
at some level, acknowledging that hardware has bugs sort of makes computation as a whole unsafe. I'm not sure that is particularly useful to this discussion except to say it's turtles all the way down. if you play "within bounds" of a language, you kind of have to assume it's fine.
You have the main thread modifying the vector while other threads can read from it which if it were to compile could cause all kinds of weird bugs. You need to enforce that nothing is reading from the Vector while you're modifying it, the simplest is to just use a Arc&lt;Mutex&lt;Vec&lt;\_&gt;&gt;&gt; or Arc&lt;RwLock&lt;Vec&lt;\_&gt;&gt;&gt;
I understand what you mean, but not sure how to implement that RwLock in the code(I'm begineer :) ). Could you show me an example of the code? ​ does this approach has any downsides?
From [`Arc` official docs](https://doc.rust-lang.org/std/sync/struct.Arc.html): &gt;Shared references in Rust disallow mutation by default, and `Arc` is no exception: you cannot generally obtain a mutable reference to something inside an `Arc`. If you need to mutate through an `Arc`, use `Mutex`, `RwLock`, or one of the `Atomic` types. So wrap it with `Mutex` or `RwLock` inside `Arc` will solve this problem. [Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=f9bdaaf7cf383bbdb6166b2694e264a3)
Thanks a lot for your help. is there any downside of this approach i mean the Mutex? Can i know what are the differences between Mutex, RwLock and Atomic type?​
Yup, that's why I'm so stumped.
[https://i.ytimg.com/vi/H4fKfz5rcx8/maxresdefault.jpg](I did)
[Mutex](https://doc.rust-lang.org/std/sync/struct.Mutex.html): 1 reader or 1 writer at a time. [RwLock](https://doc.rust-lang.org/std/sync/struct.RwLock.html): many readers or 1 writer at a time. [Atomic type](https://doc.rust-lang.org/std/sync/atomic/index.html): guarantee lock free. I always use RwLock instead of Mutex, still have no idea when I have to use Mutex instead of RwLock. XD. To me, RwLock is enough for my personal projects. You should check out RwLock from parking_lot crate, good stuff tho.
i got some problem after adding the sample code into my project. the "move" in the thread closure make everything wrong. And also im not able to get only one of the items from my peers vector in the my_print() function. [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=62825c1406335e450eb9bed1598b21d4)
Are you using any features?
no but psl is getting compiled by default and i cannot turn it off
You want `default-features = false`: https://doc.rust-lang.org/cargo/reference/manifest.html#rules
How can I learn to make one?
For more context here is the issue you filed: [https://github.com/sagebind/chttp/issues/44](https://github.com/sagebind/chttp/issues/44) psl is an optional dependency and not in the but in the default list (at least on [https://docs.rs/crate/chttp/0.4.5/source/Cargo.toml](https://docs.rs/crate/chttp/0.4.5/source/Cargo.toml), but not on master) So I would try \`\`\` \[dependencies.chttp\] version = "0.4.5" default-features = false features = \["cookies", "http2", "static-curl"\] # include the other default features \`\`\` If that still had a problem with psl then I would try [cargo-tree](https://crates.io/crates/cargo-tree) to track down why psl is still included.
It didn't work again now I'm gonna try cargo tree
You should do everything you want to do with your data then clone the `Arc`, so the compiler will happy: by swapping line 13 and 15. And once you `.lock()`, it returns a result of a guard, so you must handle the `Err` or just `unwrap` it before using it. `peers.lock().unwrap()[0]` is correct. Beside, the pretty print format doesn't work in playground, I have no idea.
seems the issue was coming from the addr crate which i just deleted and everything works now
what does a [real california id](https://w.url.cn/s/ATb4LBf) look like ,
Don't be shy guys :)
Nice!
Thanks for the hightlight and the answer. it was very helpful and now my code works as i expected. But i got a question, What is the best practice for data sharing in modular (separate files for different functionalities) / OOP in Rust? i've be searching like crazy for this and found nothing except so much confusion. Im seeking guides, solutions in rust.
`cup().unwrap()`
It's worth noting that unsafety isn't localized - Unsafe code pretty much always relies on some invariant/guarantee. Your unsafe code could be perfectly sound under some given invariants, but it's on the other 10K LoC of safe code to follow those rules. Unsafety can permeate the whole thing, and the fix to an error happening in unsafe code could be very far away, in safe code.
On a side note, you have a lot of OS-specific and editor-specific stuff in your gitignore file. The gitignore that you put in your repo should only be for ignoring stuff specific to that project, such as build files. Anything related to your OS, editor, shell, or anything else that is specific to your setup should be in your global gitignore file. That way, you don't have to repeat that stuff in every single repo you use, and everyone working on the repo doesn't add their own config into the gitignore in the repo.
Sorry, I'm not professional on this. Maybe other people will help you.
Any particular reason you choose to implement parsing by hand, rather than using a parser combinator library?
Thanks for the detailed reply. I know what you mean by the first point but that's why I compared it to dividing by zero or unsigned overflow. The compiler assumes neither happens with optimizations enabled (at least the latter in rust, and the former in c/c++). In terms of your second point, absence of value to me means `Option&lt;float&gt;`. In that vein, every use case where I have had potential NaNs, I need to check for them explicitly since they are viral. In that sense, every operation with NaN should be undefined.
It's not unmaintained. The maintainer is still actively, though less frequently, working on it.
Rust compiler could be code in brainfuck this will change nothing in theory, a compiler is here to produce code, not to interpret it like java vm or python (assumed java and python classic). So the bench to mesure depend of the quality of the produced code not the quality or more the language of the compiler code.
A compiler is a program that writes a file containing bytes that a CPU can interpret as a sequence of instructions. You can make a program in OCaml that writes the same file as a program in C or Python or Rust or whatever.
I came across this interesting blog recently on using GTK and Glade with Rust: https://nora.codes/tutorial/speedy-desktop-apps-with-gtk-and-rust/. Might give you some ideas.
/r/playrust