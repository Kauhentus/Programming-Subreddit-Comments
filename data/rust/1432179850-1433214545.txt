Hrm, odd. A normal `cargo run` should add `-g`, and since you said it works on Linux... Mind filing a bug? This should work.
I've used the `num` crate that provides essentially the same `FromPrimitive` [trait](http://doc.rust-lang.org/num/num/traits/trait.FromPrimitive.html), and wrote a manual `impl` from there. ~~I can't remember the specifics right now, but I think the `#[derive(FromPrimitive]` didn't (still won't?) work as it is an external crate.~~ Edit: See below.
LLVM is optimizing the loop down to a constant. You can see it more easily in the optimized assembly of a stripped down version: http://is.gd/dMgoRD _ZN4main20h89577c7fd45002a6faaE: .cfi_startproc cmpq %fs:112, %rsp ja .LBB0_2 movabsq $72, %r10 movabsq $0, %r11 callq __morestack retq .LBB0_2: subq $72, %rsp .Ltmp0: .cfi_def_cfa_offset 80 movabsq $2400000000000000001, %rax movq %rax, 64(%rsp) movq _ZN3fmt3num16i64.fmt..Display3fmt20h162e88846e03e4aeKcIE@GOTPCREL(%rip), %rax movq %rax, 8(%rsp) leaq 64(%rsp), %rax movq %rax, (%rsp) movups _ZN4main15__STATIC_FMTSTR20h5534269f2b618895ZaaE(%rip), %xmm0 movaps %xmm0, 16(%rsp) xorps %xmm0, %xmm0 movaps %xmm0, 32(%rsp) leaq (%rsp), %rax movq %rax, 48(%rsp) movq $1, 56(%rsp) leaq 16(%rsp), %rdi callq _ZN2io5stdio6_print20ha1d8e66e312be5295TgE@PLT addq $72, %rsp retq It's just moving the constant value 2400000000000000001 into `%rax` and then printing that.
You’re *not willing* to license it?
Lol, I think exactly the opposite... Since my experience with Gradle in Android I use Gradle to build everything :D
Thanks. Looks like Firefox OS app isn't possible :( 
The `num` crate has a `#[derive(NumFromPrimitive)]` annotation that will do what the OP wants.
How to copy m bytes of &amp;[u8] to [u8;n] where m&lt;n? i.e. like C memcpy or java System.arraycopy
Yes, but I'd rather have some kind of on-going revenue stream, like a sponsorship deal. Maybe we could get it co-branded with Doritos or something. Serious answer, just in case: if you feel you *need* a license, I'm happy to give one.
One thing to keep in mind is that your example touches library *writing*, which has different cost-benefit requirements than library *usage*. You only have to write (and maintain) a library once to use it anywhere. Therefore higher cost for library creation doesn't hurt as much as higher cost for library use. Without further analysis, I'd guess usage of both `ErrorOr` and `Result` are about equally simple.
Alright, so essentially exactly what I said in the comment you replied to: &gt; Perhaps the key is to understand unsafe not as something that breaks the type system, but something that specifically breaks memory safety? 
For a straight C memcpy replacement, there is https://doc.rust-lang.org/std/ptr/fn.copy.html 
&gt; Copying arbitrary bytes via pointers. I just need copy contents of slice to array. Slice is safe, isnt it? So why no such method? Something like .copy_from( ) ? Java have System.arraycopy, wherein dont have pointers at all; 
There is `std::slice::bytes::copy_memory`, but it's unstable at the moment.
I think I found out what I was running into before as an issue. It looks like `num-macros` is also a required dependency to get a working `#[derive(NumFromPrimitive)]`. Example adopted from [num-macros/tests/test_macro.rs](https://github.com/rust-lang/num/blob/master/num-macros/tests/test_macro.rs): #![feature(custom_derive, plugin)] #![plugin(num_macros)] extern crate num; #[derive(Debug, NumFromPrimitive)] enum State { Zero, One, Two, Three } fn main() { let s: Option&lt;MyState&gt; = num::FromPrimitive::from_u8(2); println!("{:?}", s); // Some(Two) } I wasn't able to get this to work without all of the above, but I've since been able to change my manual `impl` to being `derive`'d using the same idea. Please correct me if this is incorrect/more trivial to do.
Oops forgot `num_macros`. yes that is correct. 
`Arena` could certainly be written that way, it just wasn't. Likewise it could absolutely present an unsafe API, it just doesn't. The joy of Rust is that it's powerful enough to implement all this stuff in libraries, so feel free to implement your own arena type that does whatever you like. :)
Goodness me, I completely missed that. Thanks.
&gt; you are drowning in questions and my non-urgent wonderings about the arcane details of the compiler can probably wait. Nope, do ask! If there is one thing about the Rust community that I love, it is that it is very, very, friendly toward questions. It may have asked thousands times, it may seem obvious to most, it may even have an answer straight in the manual: none of that matter. Ask and you shall receive :)
TCP connection timeouts have always been hard to do. [Special tricks in Perl](http://devpit.org/wiki/Connect%28%29_with_timeout_%28in_Perl%29) ([and another link](http://www.perlmonks.org/?node_id=581062)) are required to support this on Linux. Effectively it requires calling connect in non-blocking mode and using a select loop to detect when the connection completes (or times out after a user-specified period).
Are there any links to those benchmarks anywhere?
Ah, dammit, "not not"... Sorry and thanks))
The `foreach` as an alternative name for `inspect` did cross my mind, the latter sounds a bit too much like a debug method. And this itertool version also solves the consume problem. And I prefer the foreach approach to a separate for-loop since the intent is clearer, especially when other filter steps precede the final one.
Yeah, our messaging isn't always the clearest :/
`unsafe` should not actually break memory safety though, it just cannot be verified by the compiler to be safe. Humans are just fallible :)
Yes, we decided that it's a bugfix.
&gt; Java is all pointers. It's GCd so you don't have to worry. Reference is not a pointer. 
I'm sure I don't know what you're talking about...
Does `rustc` support or plan to support some kind of `-Og` that would pick some of the lowest hanging optimization fruit while preserving debuggability? If I'm writing a game then a 15x slowdown is completely unusable, but if I let llvm's optimizers go to town on the code then I'm going to be seeing a whole lot of `&lt;value optimized out&gt;`. :) (At least with C++.)
I started by mostly using it as a reference. With the std lib docs. Just searching for the solution to whatever I was stuck on. And then I went through the book in order, and that helped a lot. 
The person who has put so much time into the book is the wonderful /u/steveklabnik1 &lt;3 I believe he recently pulled the "projects" out into the "Learn Rust" section, but on [the first page of the "Learn Rust" section](http://doc.rust-lang.org/stable/book/learn-rust.html) it says: &gt; Welcome! This section has a few tutorials that teach you Rust through building projects. You’ll get a high-level overview, but we’ll skim over the details. &gt; &gt; If you’d prefer a more ‘from the ground up’-style experience, check out [Syntax and Semantics](http://doc.rust-lang.org/stable/book/syntax-and-semantics.html). So perhaps try starting with the [Syntax and Semantics](http://doc.rust-lang.org/stable/book/syntax-and-semantics.html) section? The idea is to provide material for both people who learn best through working on a little project, as well as people who are used to reading about concepts one by one.
When it was first, people wanted projects first. TOCs are hard :( I'm still open to changing this, but I have some secret stuff going on that I can't quite talk about yet.
Excellent, had to view that in context to see the whistle. You owe me a keyboard ;)
When reading linked hypermedia, does the order of the chapters matter? (philosoraptor)
Not very good to learn Rust... I just skipped through the warmup and there are already some "wrong" things: `()` is a type in Rust, yes. But its not something like `null` in other languages... This whole explanation was somehow not correct. So yeah, not very helpful for beginners ;)
Not that this is not a good thing for those who like gradle
You'll have to wait in line; I owe myself two already. I managed to kill both a G15 *and* a G18. As it stands, I'm using a crappy Logitech wireless media PC keyboard with a touchpad growing out of the side. It doesn't even have a numpad.
From the safety point of view? They're the same. Here the problem is that you could copy a pointer or whatever, and the original data could be destroyed by the owner. Arbitrary copies of non-`Copy` data doesn't work well. It's worth proposing a `Vec::from_slice` function which takes in `&amp;[T]`, where `T: Copy`
And, of course, the whole point of local-only inference is that it serves two goals: 1. Your functions form your API and you don't want that to change unpredictably. 2. By making function and generic signatures explicit, you allow the compiler to avoid the mess of pages-long error messages you tend to find in C++ by constraining the scope of the issue in a predictable manner.
`u32` has a size known at compile time, `IMouseCapabilities` (which has a very non-Rusty name) does not, as it's a trait object.
Agreed! And, seems like it does: https://msdn.microsoft.com/en-us/library/dd293608.aspx
Filed. 
It sounds like you don't want memory safety. That's totally fine. At present, Rust is not the language for you if you don't want that. I should add, however, that history has shown that C++ is not memory safe in practice or in theory. There is not a single large C++ codebase in existence that has been free of memory safety issues, and those readily translate into security vulnerabilities.
Awesome and glad it's useful. There's an [issue](https://github.com/rust-lang/rust-by-example/issues/497) for [rustbyexample](http://rustbyexample.com/) to add this type of thing to the intro because the std libs are really confusing (especially at first). I just haven't tried to add it because I haven't gotten around to trying to make it into an example. Having an explanation for this codified could really speed people on their way. steveklabnik may have similar plans for the [book](http://doc.rust-lang.org/book/) as well but I don't know. Rust does other things which used to make the docs more difficult to grok. An example (since been fixed) was that `vec` had methods available which weren't listed on the page because `vec` implemented `deref` which means that if you could `deref` to a different type, you get the the other types' methods for free. rustdoc now includes methods via `deref` on the page which is really nice eliminating this concern.
Instead of switching to a dynamically sized array (`Vec&lt;Vec3d&gt;`), you could also use a `Box&lt;[Vec3d; 1024]&gt;`. Box is a non-nullable unique pointer. Unfortunately not able to be pattern matched at this time, though it does deref into the type it points at, so you can use the methods on arrays (not that arrays of size &gt; 32 have methods since numeric generics aren't implemented).
Thanks! That's a great idea.
You might check out oxischeme's gc for inspiration if you haven't already http://fitzgeraldnick.com/weblog/60/
Thanks; will look at it tomorrow!
I have HTTPSeverywhere but same thing happens when it's switched off. I just opened it in another profile and in safe mode, and it works. I'll try to narrow it down.
Hm. That's weird. I disabled all add-ons and even plugins. It still fails the same way. Looks like something is messed up in the profile.
Weirdly, it aborts with stack overflow under debug mode, but works fine under release mode. http://is.gd/aGxdbf
about:support is helpful. It lists all modified settings. Custom security.tls.version.max looked really weird.
I doubt that's much of a difference from a `Vec::with_capacity(1024)`
My first Rust experience was very different from that of the author while trying to achieve very similar things: Let's write a Vec3D class! Oh wow traits are awesome! I love this! This is really awesome! Excitement! Now I need a Vec2D, I could copy paste Vec3D... but let's just write a Vec&lt;ND&gt; that solves this once and for all... Oh I can't do this with generics... It seems that I need to use a macro... all my code is under a macro now... crap I made a mistake... debugging macros is not that fun... anyhow finished it! This looks horrible! Crap I need some matrices too... macros and more macros... can't barely remember what Rust looked like... been inside macros for 2 hours... let's try to put most of the code in some generic traits and reduce the amount of code in macros... &lt;X&lt;T,U&gt; as Self&gt;:: everywhere... Damn I really miss C++... Luckily enough I decided to give it another try a month later and went the "everything is dynamic" way and all was fine. Having to make all my vectors and matrices heap allocated to achieve genericity feels really wrong coming from C++ but my mental health is worth more than performance. I've been thinking about giving it another try now that we have associated constants, trying to put everything into traits. We'll see how that goes.
&gt; Though I've to add that idiomatic C++11 code is less prone to memory related bugs. Compared to what? You won't have many leaks in C++11 if you write idiomatic code (The same is true for idiomatic C++98 code). But as soon as you "borrow" something (iterating over a container, storing raw pointers to things owned by other objects) you can get into trouble. To avoid "dangling borrows" in C++ you might be able to use `shared_ptr` and `weak_ptr` … but … I like the fact that in Rust I don't have to do this kind of thing. In Rust I can safely use borrowed pointers without any ref-counting overhead.
 [profile.debug] opt-level = 1 debug = true should be reasonable, I think
The problem is much more nuanced and can't really be thought of in the C++ sense because in C++ there's no parallel to the guarantees being invalidated. In C++ you can always leak by throwing something into thread local storage, or something. However, in Rust since you have borrowing guarantees, you can be sure that stuff containing borrowed data won't leak since if I have `foo(x)` and x is non `'static`, `foo()` cannot throw its argument into TLS or send it to another thread so that its destructor never runs, because `x` cannot outlive some scope. This *still* isn't possible, but the corollary -- "if x has a certain scope in which it is valid, the destructor runs in that scope" no longer works. Both C++ and Rust have always allowed forgetting of `'static` RAII handles via threads or TLS or Rc cycles. Everything in C++ is `'static`. Rust has the concept of non-`'static` data, and with these we have some additional guarantees. One of those is no longer true. The issue is about a whole new class of types with lots of restrictions on usage (and thus lots of guarantees) losing one guarantee. Can't be thought of in terms of a language where that class of types doesn't exist :) (`'static` means that the type contains no borrowed data other than borrowed statics)
I hear this project is looking for contribution: it listens to TCP right now, but they'd love to get some HTTP in there too.
You need `box` syntax (currently unstable; the [RFC](https://github.com/rust-lang/rfcs/pull/809) is accepted but implementation isn't done) to avoid the heap allocation entirely, without relying on the optimizer: http://is.gd/D1IUd0
Reddit tips: 1. Comments are threaded, so you can reply directly to the comment in question. 2. If you really want to get a user's attention out-of-thread, use /u/ instead of @, so /u/robobrain10 and /u/rovar. 3. Indent code by four spaces to get preformatted code. Like this: #![feature(duration)] use std::time::duration::Duration; let d = Duration::weeks(1); error: no associated item named `weeks` found for type `std::time::duration::Duration` in the current scope 
Great videos, i have learnt a lot, just watching the first 4 vids. Keep em coming :)
&gt; Now I need a Vec2D, I could copy paste Vec3D... but let's just write a Vec&lt;ND&gt; that solves this once and for all... Yeah, I need 2 cases, so why not write code for an INFINITY of cases! It won't be a waste of time! /s
EDIT: uhh a comment got deleted, but By default, it builds a `.rlib`, which is indeed different. You can [change a configuration](http://doc.crates.io/manifest.html#building-dynamic-or-static-libraries) to get a .`so` or `.dll`
Thank you for the detailed answer. What confuses me is that `T` is [supposed to be] behind a pointer (`*const T`). Why does size of `T` matter?
So you can't make any secure connections.
Well written, especially your "First steps" part was very informative.
I had this exact same issue a few weeks ago. I wonder if it has to do with a certain addon? Maybe Privacy Badger or HTTPS Everywhere
Hoverbear is compiling a repo of Rust examples for [Rosetta Code](http://rosettacode.org/wiki/Rosetta_Code). These are simple self contained programs showing common tasks. Writing examples for a few should get you familiar with the language and will be useful for future learners. https://github.com/Hoverbear/rust-rosetta
Should we be [registering](http://www.iana.org/form/media-types) a [media type](http://www.iana.org/assignments/media-types/)?
I've encountered this many times on a few of my profiles that I assume got corrupted somehow. It would be nice if the error reported by Firefox (or at least some of the Bugzilla pages I found when searching for the error) mentioned this `security.tls.version.max` possibilty...
I read through the README and even took a peak at the code, but for the life of me, I cannot figure out what this tool is supposed to be doing. It looks like it does something related to Ansible, which I'm not familiar with, so I'm probably missing some context.
Yeah, error reporting definitely could be more explicit.
Nice idea!
It means you'll be able to have `VecND&lt;2&gt;`, `VecND&lt;3&gt;` ... instead of `Vec2D`, `Vec3D`.
Either you have an exceptionally long commute, or you learn new languages really fast ;) Very well written, I really enjoyed it! I find it particularly interesting to read experience reports from people that are coming from a C++ background. Keep 'em coming :)
Just in case anybody else is still seeing this thread: As others here have said, I'm pretty sure this is all about inlining. When I separated my test case into a separate crate from the library itself, everything got really slow, even with optimization turned on for the compilation of both crates. Just to be sure, I reconstructed a single .rs file containing my lib and the text case (and fn main) and confirmed once again that without -O it is slow (around 10 seconds) and with -O it is fast (around 0.5 seconds). Then I double-checked to make sure the output file from the two runs is the same. It is. No funny tricks going on. The optimized version is doing the same work in ~5% of the time. Then I found this page: https://internals.rust-lang.org/t/when-should-i-use-inline/598 Which talks about how a function doesn't get inlined across crates unless you put the inline attribute on the function. But then it talks about this "lto" thing, which causes it to pretend like you put on inline attribute everywhere. So I rebuilt my two-crate approach with lto turned on. And now the executable crashes. Hard. A segmentation fault that rust didn't catch. I got a (cryptic to me) stack trace from lldb. I am willing to make sure this is reproducable and file a bug report somewhere if (1) somebody thinks that would be a good idea, and (2) somebody would point me in the right direction. Finally, I started sprinkling #[inline] throughout my library code. And that worked as expected. Basically, the more inline hints, the faster everything got. With an inline hint on every single function in my library (170 of them), I am once again getting roughly the fast performance I was getting when everything was in the same crate. If I take a few inline hints away, it gets a bit slower. I'm sure some of those inlines are more important than others, but I haven't done any specific measurements in that direction. Perhaps the most interesting thing here is that, in my particular situation, with the code in separate crates, and without inline hints, the optimizer doesn't help at all. I betcha I won't be the last person to trip over this. And AFAICT, the debate over "what the default opt-level should be" wouldn't affect this issue at all. 
If the size isn't known at compile time, you cannot have the data kept on the stack (Java puts everything on the heap so no problem here). `alloca()` and variable length arrays aside; in assembly you need to know the size of data on the stack at compile time since you need to hardcode the stack offsets. It's not exactly the size that's the problem (size is more of a problem with `[T]`), but `Trait` is also an unknown, or _erased_ type. So for dynamic dispatch to work you need to have at runtime information on what the trait object is. You can store this in two ways: - Either add a vtable pointer and the pointer to the actual thing behind the first `*const T`, so you dereference twice to get there. - Or make the pointer "fat" and make the representation of `*const T` to be a pointer and a vtable pointer. Both work, but both require differences in handling pointers. Since there are lots of types (eg `Vec`) that depend on pointer arithmetic (in general depend on regular C-style pointers for working the way they do in C) and would be broken by this, all type parameters have a default `Sized` bound. Types like `Trait` and `[T]` which need fat pointers are not `Sized`, and if you want to create a function that accepts these you put a `?Sized` bound on the type. So `Vec&lt;Trait&gt;` won't work, but `Vec&lt;Box&lt;Trait&gt;&gt;` (effectively what Java does, sans GC) will work fine, because `Vec&lt;T&gt;` needs regular pointers but `Box&lt;T&gt;` is written to work with unsized types.
`take` should be eager IMO.
Are your functions polymorphic or not? I don't know a lot about rustc but I tend to think polymorphic functions are specialized for each callsite (even across crates), and consequently more likely to be inlined.
Cool! Is there a practicam example where it's used for this pattern?
What about this? http://llvm.org/docs/LangRef.html#volatile-memory-accesses
I think this code is missing a `}`: if match result { None =&gt; true, Some(ref x) =&gt; dist &lt; x.dist) { result = Some(HitRecord { sphere: &amp;sphere, dist: dist }); } ...and I believe the match part can also be written as: if result.map_or(true, |x| dist &lt; x.dist) { 
I know you are joking but... the only thing I can say in my defense is that I was learning Rust! I basically knew I was going to need a Vec1D for point, and a Vec4D for quaternions, and a Vec5D and matrices later. In the same way that the post author decided to write something "trivial" (a 100LOC path tracer), I decided to write a "trivial" generic Vec&lt;ND&gt; class. I am very familiar with the internals of C++ Eigen myself, so for me this was something that I had already done and iterated upon multiple times before. I wasn't setting very high goals for it, I was just exploring the language and how it could allow me to abstract over data. Coming from C++ where this is trivial to do, and after being shocked by how nice Traits are, I somehow believed that this would be trivial on rust too. It was also a way to evaluate rust for my purposes. I need solid linear algebra libraries. If writing a Vec&lt;ND&gt; class was easy, I expected very high quality linear algebra libraries to pop up fast or I could easily write my own. If writing a Vec&lt;ND&gt; class was hard, this would take more time to happen. So this was also a way of evaluating how does Rust fit for the problems I want to solve. So I went for it, how hard could it be to write a Vec&lt;ND&gt; I thought? They have generics! I learned pretty fast that I couldn't easily do it. I learned how I could do it. And after all, I decided to stick with C++ for new projects for now. I also learned that Rust is a very nice language for a lot of things, and use it on some toy projects on my rasperry pi and am happy with it :) So I was learning and exploring, and the time I invested wasn't wasted time at all! I really like the language, and wish type level integers were a very high priority. I haven't played with associated constants at all tho, they might allow me to do some stuff that I wanted to do with type level integers. If I learned something from Rust is that it has a better way of doing anything I already know how to do in C++.
Wow, that's nifty! (I was expecting to see the rustc source code explorer, which would be nice to have too...)
&gt; The last thing after the semicolon is the return value of a function. You can use the `return` keyword to make it explicit and reduce the risk of accidental semi-colon addition?
That is very cool! Makes exploring assembler much less painful. Interestingly, I found that you have to use `opt-level=3` to get vectorization. IIRC `cargo --release` only uses `opt-level=2`. The code I tried was pub fn dot(a: [i32; 4], b: [i32; 4]) -&gt; [i32; 4] { [a[0]*b[0], a[1]*b[1], a[2]*b[2], a[3]*b[3]] }
IIRC, KDevelop recently began to switch from its own completion engine to clang for C++? So, I suppose it should go the same way for integrating racer for rust? (not saying it's easy ;)
How do you pass the `opt-level` argument? I get `error: Unrecognized option: 'opt-level'.`
Your Presburger solver idea sounds perfectly interesting to me, in my opinion just go ahead with that! :-)
My only problem with this software is that it's near impossible to get working with cargo crates. Would love to have an offline version that does directive removing and colorizing.
Very nice ! In particular the *Colourise* part !
`rustc -C opt-level=3`, which would just be putting `-C opt-level=3` in the compiler options on this site.
Thanks I was missing the -C :)
I really like the calendar example and the tutorial "Component programming with D". This solution using the STL2 is a really nice addition, there are traces of functional programming all over the place. I think that this example is interesting on its own, and that showing how to solve it in Rust would make for a really nice blog post. Maybe this even gets someone to write a similar blog post about "Component programming with Rust". The Rust Iterator functionality is certainly up to the task.
Most source code types are subtypes of *text* though (sensible imho - it's a specialization of *text/plain*, too), and Rust isn't really execute-with-shebang or anything (although the compiler recognizes shebangs, but ignores them). Cf. *text/x-(python|ruby|lua|dsrc)* and the like. Yes, there are counter-examples, but had to pick one :-). When I did some research to check for an earlier consensus, I found two types in use: *text/x-rust* (by rust-lang/(kate-config|gedit-config), which I ended up filing PRs against) and *text/x-rustsrc*, by the Pygments lexer. The latter isn't entirely without merit (shared-mime-info also has *text/x-csrc*, for example), but the vast majority of types were *x-foo*, and dropping the *x-* that left me with *foo*, in this case *rust*. It's also pretty simple.
Keep in mind Rust doesn't actually use clang, though. Rust uses llvm, but clang is the C/C++ frontend (Nim is an example of a lang using llvm via clang). kdev-cpp (which isn't the default at the time, the rpp engine still is) uses libclang; for Rust something else will need to be used.
I was a bit surprised that the basic square function (`pub fn square(n: i32) -&gt; i32 { n*n }`) generates a morestack prelude, even with optimizations. My local Rust 1.0 elides it, which is what I expected for functions that can be computed entirely in registers.
The loop-vectorisation passes kick in earlier (`opt-level=1`) than the straight-line vectorisation passes which are only active at `3` (one can see this by adding the `-Z print-llvm-passes` argument and searching for `vector`). Thus, loops get vectorised even at lower optimisation levels, the thinking/experience being that they're usually the hotspots and thus benefit the most. (I imagine if one calls `dot` in a loop and it is inlined, vectorisation may happen.)
Yes, of course. What I meant is that if work has already been done to interface libclang and KDevelop, I suppose it might be a basis to interface KDevelop and racer.
Notably, opting in to a later instruction set (the default for x86-64 is just SSE2) with an explicit `-C target-feature=+sse4.1` makes the ASM much nicer: the `pshufd`/`pmuludq` junk is replaced with a single `pmulld`.
Right, yeah, there's definitely some code around that can serve as a reference for how to integrate an external parser/toolkit into a language support plugin. The Python plugin also uses CPython to parse and get an AST, and takes it to the KDevelop DUChain from that repr. It'd definitely make sense to do as little work as possible on the KDevelop side.
I'll take a look, from the docs it looks like a mix of Boost.Fusion and Boost.Hana so I'm really interested although it might be a bit overkill. Thanks, i'll play with it later :)
Why does Rust have stack checking though? That surprised me. I thought it just reserved large stacks and relied on guard pages.
 fn encode(&amp;mut self,&amp;mut Write){ panic!("Sorry, not implemented yet"); } is this default implementation necessary?
I haven't read the code (yet) but indentation looks kinda weird here https://github.com/zorend/mongodb-rs/blob/master/src/msg.rs#L135
Is this a typo in v0.5.0? #[inline(always)] #[cfg(not(target_os = "linux"))] pub fn create(dir: &amp;Path) -&gt; io::Result&lt;File&gt; { create_unix(path) } It's causing this compile error: /Users/gabriel/.cargo/registry/src/github.com-1ecc6299db9ec823/tempfile-0.5.0/src/imp/unix.rs:45:17: 45:21 error: unresolved name `path`. Did you mean `dir`? /Users/gabriel/.cargo/registry/src/github.com-1ecc6299db9ec823/tempfile-0.5.0/src/imp/unix.rs:45 create_unix(path) ^~~~
Use [`unimplemented!()`](http://doc.rust-lang.org/std/macro.unimplemented!.html). It's literally a wrapper around that exact behaviour but is more greppable.
We haven't finished switching to guard pages + probes, [#16012](https://github.com/rust-lang/rust/issues/16012). It's an implementation detail and can/will be switched in future.
Tough answer but honestly what I was thinking too.
I nearly missed that! That's enormously helpful!
There are *three* problems. One small, one major, one *apocalyptic*. The small problem is that Rust macros have to expand to a complete syntax construct. This expansion does *not* include the parens (or braces) surrounding the contents of the expansion. In other words, if you were to write out your expansion by hand, you'd have: let t = 1u8, 1u8; which isn't valid code. The solution is to just wrap the expansion in parens: ($e, construct_tuple!($n-1,$e)) This leads to the second, major problem: this won't result in a tuple of `$n` elements, but a tuple of *two* elements, where the second is a tuple of `$n-1` elements. Usually, you get around this by using repetition expansions. That brings us to the third, *apocalyptic* problem: macros can't do math. Macros *do not interact with the language's semantics*, they are *entirely symbolic*. Given `$n` being `2`, `$n-1` is literally `2-1`, not `1`. This means that the termination rule *is never reached*. The only way I can think of doing this, without writing a syntax extension (which you can't use in a stable compiler *anyway*), is to provide *something* in the macro invocation that is literally `n` symbols in length. And at that point, there's not much to be gained over writing the tuple out in the first place. ----- That said, it *would* be rather nice if Rust had a simple `arithmetic!` macro for cases like this. But again, this isn't something you can really do yourself.
I thought it was necessary, but it will trigger only if you try to encode a OP_reply which is not the role of the client but rather the database. 
**Rust just hit 1.0, has lots of momentum behind it, 1,000 contributors, more crates every day and Mozilla is doing fine == a glourious future awaits Rust...** That being said, since Rust is an open-source project, already under its own organization on GitHub, the most obvious consequence would be that there will be no more paid, full-time developers working on Rust, resulting in some developers leaving and others having much, much less time to work on Rust == the pace of change would likely hit the floor compared to now. Aside from that, the Rust infrastructure would be under serious risk unless a willing sponsor is found to at least cover the hosting cost. Rust as a language however would almost certainly live on, we have 1,000 contributors and lots of skilled volunteers in other areas as well, so I think that would not happen. We can look at serveral programming languages that did not have a corporate backer and became big anyways, such as PHP, Perl and Ruby as an example of how it would likely go.
https://github.com/uutils/coreutils This project is a rewrite of GNU coreutils using Rust. A lot of small tools heavily used by Linux users, but this Rust version should work on Windows too.
Open source has nothing to do with company support. There's no apocalyptic "split" planned, though both Rust and Mozilla want to disperse the responsibilities and decision making power.
http://jsonapi.org/ We were supposed to 1.0 yesterday, but are giving it a week to review the text of the spec.
Oh I see :( that's very unfortunate as it's severely limiting the usefulness of the macro system for me in this particular case.. Thank you very much for the great explanation though, you helped me a lot wrapping my head around this!
pf has this built in! There's an option called `overload` that goes together with rate limiting, which puts the IP addresses into a table. [Here's an article about this](http://128bitstudios.com/2010/06/13/stopping-ssh-brute-force-attacks-with-pf-on-freebsd/). The only downside is that it doesn't clean up automatically. So I just use rate limiting without remembering the IPs. Because who cares anyway. I only allow public key auth. No one is going to brute force Ed25519 keys...
IIRC, there are more non-Moz contributors than Moz contributors, so it would be fine. Also, Mozilla really isn't going anywhere anytime soon.
How do you got Eclipse to work with Rust? RustDT wants a "Rust 'src' directory" that doesn't exist in the Windows installation?
Package not available
I think you wouldn't have been downvoted if you had made this a text post mentioning the relevance to Rust more clearly. 
Thanks for the answer. That's pretty much exactly what i was looking for.
Thanks!
Nice. I had the idea to do this for Haskell, but never really worked on it. I don't know if you're familiar with Haskell development, but there windows tends to be a second class citizen because the tools tend to assume a unix build environment. Having these tools in Rust (as long as it's easy for Haskell folks to install) would still solve the problem I wanted to solve with a Haskell rewrite. I might have to get involved at some point :)
I started working on it last night and already ran into a Yak that I'm trying not to shave. I quickly coded up an ADT for the presburger language, and now I'd rather parse the expressions than type them directly into my .rs file. Unfortunately, many of the parsing related crates require the unstable channel. The notable exceptions being `nom` and `parser-combinators`, but I'm having a really hard time understanding/reading the examples (which turns me off from using the parser combinator approach in rust). So, now I'm wondering, do I suck it up and make a simple parser by hand or should I go off on a tangent and fix (or write from scratch) a parser generator :) `peg` looks nice, but porting it to the 1.0 stable compiler might be hard for a rust beginner like myself. The issue tracker implies it would be easiest to support 1.0 by adopting the `syntex` library. Actually compiling it on 1.0 gives a bunch of errors about an unimplemented trait on String during macro expansion. I couldn't find the macro definition anywhere so I gave up.
I'm not sure if it's completely backwards-compatible; couldn't it theoretically make programs that create large uninitialized arrays on the stack memory unsafe where they currently are not (since if you make them large enough, the next stack frame can actually jump the stack guard and arrive on the heap, and the stack allocation won't trigger a page fault unless you actually access a value on the guard page)? That said, I sorta doubt anyone wrote a program that behaves like this since it would crash on stable Rust...
Hm... I don't really like the existence of unimplemented methods (in general, not just here). I would rather fix mio to be more flexible w.r.t. providing support for types that implement only `Read`.
Very intresting. I'm trying to understand the trick here, is it because Seal is borrowing itself in run() like this: self.lock.set( Some(&amp;self.inner) ); thus making itself immovable and immutable for the rest of its life? *EDIT: formatting*
I think that if you `box` the guard you'll still be able to leak it without moving it.
&gt;Live Streaming is not available in your country due to rights issues. Do you know of any other place I might be able to watch it?
I'd also love to be able to use MongoDB from Rust. Nice work so far! I was thinking about writing a wrapper for https://github.com/mongodb/mongo-c-driver. This avoids the problem of writing all the replica set failover logic and so on that's described in the driver metadata docs (http://docs.mongodb.org/meta-driver/latest/). Did you consider that approach?
This is major WTF. The livestreaming itself isn't available in Germany, this is no news. But the live event is over, so _a recording_ should be available just fine. I reported an issue to Google. If the issue won't be resolved within a couple of hours(e.g. sometimes it takes a while for a live stream recording to appear in your videos), I'll re-upload it(as a normal video).
The other question is, what content were they using that caused rights issues? So far it just looks like a skype call.
[You actually can tough](http://is.gd/Oq7JDX) The trick is just to put them into the vector *first* and *then* running them. You still can't leak them, because the moment you leak them, you lose all references, thus can't *run* them anymore. I think this is great, OP! :)
&gt; If `T` contains a reference, it's bound by `'a`. If T references are bounded by `'a`, why do I need to repeat the lifetime for T references like below: input: &amp;'a mut T, &gt; In this case, you also added two bounds to T, so this impl is just for Ts that implement Read + Seek. Do I need to repeat the `T: 'a` constraint here?
This is two different things coming together. When I say, "if `T` contains a reference," I mean "the type `T` might be something like `struct Foo&lt;'f&gt;{ x: &amp;'f i32 }`, which has a reference inside of it", not "a reference _to_ a `T`." `&amp;'a T`, on the other hand, doesn't care what `T` is. It's just a reference, with a given lifetime. That they all have the same name ties them together. You end up saying "This reference to a T has the lifetime `'a`, and any references `T` may contain also have the lifetime `"a`, which means that `T` will always contain references that are valid for the same time the reference to the `T` is valid. Does that make sense? 
it is not needed for the driver since you won't send a reply, and I wanted all the Operations of the wire protocol to implement the Message trait for consistency. 
The stack probes can poke each page that the function's stack will cover to ensure that the guard page is accessed.
Thanks for spotting the typo! The code on github was ok, but I missed it in pasting! Fixed now thanks. Thanks also for the map_or trick: it looks much nicer! I couldn't get it to compile however, as the borrow checker complains about it having been previously moved. I'll try and get it compiling, but if you have any ideas please let me know!
Yep, but the returned `Guard` is just to get the joined value. Leaking it doesn't cause any memory unsafety. The `Seal`'s destructor is what actually joins the scoped thread.
I don't think so, because `run()` causes `t` to self-borrow. It will stayed borrowed until `t` itself goes out of scope.
Sadly not here! This subreddit is about a programming language also called Rust. Try r/playrust
Yep! Since `self` has a reference to itself, it can't be moved without invalidating some of its data, making it immovable and immutable, like you said. I stole this trick from someone else, possibly /u/Quxxy?
I get `error: t does not live long enough`, but I might be doing it wrong. http://is.gd/5YuchL
Ah, I see. It's... weird that the Seal can be dropped after doing this (since it must outlive itself...?)
gdb has support for calling functions, just not Rust ones at the moment. There's an RFC for Rust support in gdb, including function call support: https://github.com/rust-lang/rfcs/issues/767
I believe you want something ([ToPrimitive](http://doc.rust-lang.org/num/num/traits/trait.ToPrimitive.html)?) in the [num crate](https://github.com/rust-lang/num).
I'm using nightly, but I'll look into the num crate, thanks.
&gt; Conceptually, this seems kinda like a bug, although I suspect there is a good reason for the current behavior. I do wonder if it can be changed without breaking compatibility. AFAIK, it's absolutely considered a bug and there is no good reason for the current behavior. It should be backwards compatible because Rust doesn't have ABI stability anyway. I think a lot of stuff like (backwards compatible, but nontrivial amount of work) got deprioritized in the rush to 1.0.
Doesn't making `run` to take `&amp;'a mut self` fix that issue? From what I've tested, it should prevent `Root::run()` from being callable from within `Rc` (even inside `RefCell`).
Store the data on the heap.
`-C target-cpu=native`.
What's with all the `R`s in this? pub struct Decoder&lt;R: Read&gt; { rd: R, } impl&lt;R: Read&gt; Decoder&lt;R&gt; { pub fn new(rd: R) -&gt; Decoder&lt;R&gt; { Decoder { rd: rd, } } } I recognize some of those as generics but I can't find a clear explanation on why you'd use generics when defining a struct, what the `&lt;R: Read&gt;` in `impl &lt;R: Read&gt; Decoder&lt;R&gt;`is actually doing, or what to even call this so I know how to look it up.
I tried that but got a lifetime error. Turns out rust was complaining about the borrow of x, not t.
I'm wondering why it's a macro..
I think I might be inching closer to understanding... Is it safe to say that this: pub struct Decoder&lt;R: Read&gt; { rd: R, } Could be rewritten as this? pub struct Decoder { rd: Read, } And, by extension, the `impl&lt;R: Read&gt;...` could be rewritten like this: impl Decoder&lt;Read&gt; { pub fn new(rd: Read) -&gt; Decoder&lt;Read&gt; { Decoder { rd: Read, } } } Or no? I've been approaching generics in Rust similar to Java, where an interface can also act as a type, but this makes me wonder if that's wrong?
My guess is to be absolutely sure it gets inlined.
&gt; &gt; &gt; The only way I can think of doing this, without writing a syntax extension (which you can't use in a stable compiler anyway), is to provide something in the macro invocation that is literally n symbols in length. Or using [syntex](https://github.com/erickt/rust-syntex), right?
Thanks, I got everything up and running now. But I have no autocompletion even after compiling Racer and setting the racer.exe path in Eclipse?
Yeah, in Rust, that means something different. With the bound, you're saying "a specific value of that implements the trait," which leads to static dispatch, but with the trait name itself, it's a 'trait object,' which is dynamic dispatch.
What does the log say?
The code is just for (i, j) in dst.iter_mut().zip(src).take(m) { *i = *j; } so it's not that bad to do in one line.
Mozilla is not at risk of collapsing.
AFAICT, the value isn't really important here except that you dispatch off of it. By the time you've dispatched, though, the actual value becomes unimportant.
Return from the `main` function. (?)
I agree with your original point as it happens, but your attitude is wayyyy too hostile to be appropriate in the Rust community, and I think it would be unfortunate if that form of discourse were legitimized. If you want to edit your comments to remove the hostility, you might get a better response.
I actually think it argues in _favor_ of the stability of the community that many of the most prolific contributors are gone. It means that enough people understood how the project and the codebase work that you can suffer multiple leading contributors quit, and the language will survive -- so if all the Mozilla employees stop working on it one day, chances are that things would figure themselves out. Imagine Python without Guido or Ruby without Matz. Rust losing Mozilla would be more like, oh, C++ losing ISO: there'd probably be some organizational confusion, but there's no reason to fear that the language itself was at existential risk.
&gt; Does that make sense? Yes, it makes sense. --- impl&lt;'a, T: Read + Seek + 'a&gt; Lexer&lt;'a, T&gt; { Do I need to repeat the `T: 'a` on the struct implementation?
[SSL v3 was disabled by default starting in Firefox 34 due to being insecure](https://blog.mozilla.org/security/2014/10/14/the-poodle-attack-and-the-end-of-ssl-3-0/).
To be fair, his question isn't "What if Mozilla went away?" it's "Mozilla keeps making bad decisions. What happens when it goes away?" which is a bit different, and was definitely inviting comments like the one you replied to.
Thanks it works now :)
I think the problem here is unconditionally printing to stdout or stderr, which is problematic on Windows. There should be a way to specify that the panic messages go somewhere else (this is different from catching panics at runtime). This may also be useful on other platforms too.
edit: Sorry, I should have read the linked article before responding. (The real issues here are that (1.) somehow this setting got changed, which I don't recall doing, and (2.) the error message from firefox makes it sound like the issue must be on the web site's end, providing no feedback about my own relevant settings that were changed from the default.) ---- But this setting, when I choose "Reset", goes back to 3. (This is on Firefox 38.0.1) (If I manually set it to 1, then `play.rust-lang.org` stops working.) So is there something else that is inspecting this setting that is unrelated to whether SSL v3 is enabled or disabled? Maybe I will just file a separate bugzilla ticket about this in particular.
If you did get it from me, it was only because I got it from someone else... maybe /u/Gankro?
But aren't macros just a builtin pre-processor as well? I mean, at least syntex is compatible with stable Rust. Anyway, I think this situation will improve.
I love how concise this API is. I don't mind the string based (i.e. error prone) API at all for option parsing, its a one time thing that's hard to get wrong. Consiceness is much more important in my opinion. Edit: If only it had an option to generate the help string :(
This is brilliantly simple. Thank you!
The code in the README doesn't compile because it uses `has_match`, when it should use `has_arg` instead. yohai@imac-5k ~/code/playground/pirate-test$ cargo build ✭master Updating registry `https://github.com/rust-lang/crates.io-index` Downloading pirate v0.2.0 Compiling pirate v0.2.0 Compiling pirate-test v0.1.0 (file:///Users/yohai/code/playground/pirate-test) src/main.rs:20:16: 20:30 error: no method named `has_match` found for type `pirate::matches::Matches` in the current scope src/main.rs:20 if matches.has_match("h") || matches.has_match("help") { ^~~~~~~~~~~~~~ src/main.rs:20:42: 20:59 error: no method named `has_match` found for type `pirate::matches::Matches` in the current scope src/main.rs:20 if matches.has_match("h") || matches.has_match("help") { ^~~~~~~~~~~~~~~~~ src/main.rs:35:16: 35:30 error: no method named `has_match` found for type `pirate::matches::Matches` in the current scope src/main.rs:35 if matches.has_match("b") || matches.has_match("boop") { ^~~~~~~~~~~~~~ src/main.rs:35:42: 35:59 error: no method named `has_match` found for type `pirate::matches::Matches` in the current scope src/main.rs:35 if matches.has_match("b") || matches.has_match("boop") { ^~~~~~~~~~~~~~~~~ error: aborting due to 4 previous errors Could not compile `pirate-test`. Submitted [a PR](https://github.com/zcdziura/pirate/pull/1).
Are compiler plugins planned to enter the stable branch at some point?
It could preserve file and line (as you can fit any Rust crate on one line). And it could handle syntex macro invocations inside non-syntax macro invocations. I've already commented on the latter in /u/erickt's serde post.
You mean *true* compiler plugins that operate on the data structures the compiler uses? *Oh my, no.* The problem is that exposes those types as stable would almost certainly prohibit any future changes to the language, at least with the way they're written now. For example, a lot of AST nodes are just enums, meaning that adding a new child node type will break all existing code that does exhaustive matching. My bet is on some kind of very low-level, low-fidelity link between the compiler and any "plugins" being stabilised (*i.e.* tokens encoded in JSON or something), with lots of heavy lifting being done in external libraries that the plugins link against (so, an out-of-tree copy of `libsyntax`, for example).
`self.beard.scratch()` *Column numbers.* But in all seriousness, I still say that having code generation be triggered from within the compiler is a cleaner solution than shadow files; that has a certain... "held together with gum and post-it notes" quality to it. Aside: is there any particular reason Rust couldn't grow support for something akin to `#line`?
How to do non-blocking IO in Rust? I've read the standard lib doc, and couldn't find anything about non-blocking IO. For a more specific question, I tried to establish a TCP connection using TcpStream, and then read some data before it sends data. But it's possible there are no data for it to read yet. In this case, I expected the read will just return with Ok(0). But it turned out that's not the behavior. The read just blocked the program forever. So the simplified code looks like: let mut conn = TcpSteam::connect(...).ok().expect("establish connection"); conn.read(&amp;mut buf).ok().expect("read some data"); // this never return unless data come, but I want to make it non-blocking. How? conn.write(...); P.S. I noticed people mentioned about calling some c code to do non-blocking. So here, I'm asking how to do it with the Rust standard library if possible. If not, is the a plan to support non-blocking IO? Thanks.
Context switching is hard, and you are running into other processes' stack... :) Personally I've found that "Rust will make you a better C++ programmer" adage largely applies to the architectural choices, and you'll have to be more careful about the actual programming in C++. The latter point heals itself when you get accustomed to programming in many different languages, but well, you still have to be careful.
&gt; That said, it's surprising to me (coming from a C background) that enabling debug info changes the code generation. I wouldn't be surprised if debuginfo only affected the morestack prelude, which (I imagine) LLVM doesn't get used with a lot; it's certainly not the default with clang, LLVM's biggest user.
Haha, OP, ignore this guy, he doesn't know what he's talking about! :D ... Dude, you can't just *tell* people it's the secret plan; then it won't be a secret any more! You keep this up, and you're going to get your Secret Rust Club card revoked! Then you won't be able to get on the awesome Secret Rust Zeppelin. Don't screw this up, man!
First and foremost: You *did* notice your mistake. Also you had enough knowledge and acumen to reason about the lifetimes and ownerships of your objects. On the other hand, this win was offset by your carelessness in the situation you described. Now you know not to trust C++ as you'd trust Rust. Does that make you a better or worse programmer? 
If history tells us anything it is that humanity is not very good at becoming smarter. 
Smart (adjective): Characterized by sharp quick thought; bright. See Synonyms at intelligent. --- ^(I am a bot. If there are any issues, please contact my [)[^master](http://np.reddit.com/message/compose/?to=Spedwards&amp;subject=/u/Define_It)^(].) ^(Want to learn how to use me? [)[^(Read this post)](http://np.reddit.com/r/Define_It/comments/31vrec/define_it_how_to/)^(].)
&gt;You might also phrase it as "Rust made me forget about being careful." Yes, but only once. OP will likely be more careful around C++ again.
But I want to be member of the Secret Rust Club, too :(
Some quick thoughts: Line 10: You only need `HashMap::new()`. Line 12: Because `words` is `&amp;Vec&lt;T&gt;`, just `words` should be sufficient, rather than needing an explicit `words.iter()`. Lines 23-26: `word` is already a `&amp;Vec&lt;u8&gt;`; you don't need to re-borrow it (*i.e.* just pass `word` instead of `&amp;word`). Line 65: I'm just doing a quick look, but be aware that `alph` may not fit in a `u8`. I believe there's an `Ascii` type floating around... *somewhere*, if the alphabet is really just ASCII. Might not be a problem; just FYI. Line 86: There's a [`swap`](http://doc.rust-lang.org/std/vec/struct.Vec.html#method.swap) you can use on Vec. Line 158: Rust tends to be *very* slow in the absence of optimisation. I also vaguely recall the current regex crate to be algorithmically sub-optimal.
Isn't that a good thing? That's more mental capacity for other things.
I never understood the appeal of minimal argument parsers like getopts or generating the strict schema from the human-audited docstring like docopt. When I moved in from Python, I ended up using [clap](https://github.com/kbknapp/clap-rs/) since it feels like an appropriately Rusty analogue to Python's [argparse](https://docs.python.org/dev/library/argparse.html) while going beyond [argparse for rust](https://github.com/tailhook/rust-argparse) in several ways.
I fully agree. I believe if a programmer starts writing "compiler-passing" Rust code consistently, that means that he/she will create memory-safe designs in other programming languages too. But of course semantics of languages differ, thus the actual program might not be so memory-safe.
The whole trouble with programming is that the techniques to manage software complexity are developed at a slower pace than the demand for more complex software. Going back to using less capable tools won't make programmers smarter, but just less equipped to perform their tasks. This demand is so high because we have more powerful hardware (meaning that more kinds of computation are feasible), and because previous systems, already overcomplicated, gave consumers a picture of what *ought* to be possible, and in turn they demand more. It's a vicious cycle.
The 1st rule of Secret Rust Club is: you don't talk about Secret Rust Club. The 2nd rule of Secret Rust Club is: error: `1st rule` does not live long enough. error: aborting due to previous error
Heh, definitely not the case for me. Every time I go back to C++ these days I'm ridiculously paranoid. Then again, it isn't language-specific, since the first thing I do when I look at a Rust repository is grep for `unsafe`.
Very nice! +1
&gt; In this case I wanted decimal precision, even if the input data were integer.
&gt;&gt; Whether we need smarter languages or we should become smarter. Why not both :) but, languages are more malleable than humans. IMO, Good technology complements how our minds already work.. compensates for our limitations &amp; weaknesses
collective knowledge has increased dramatically; I would bet individuals are no smarter . We are probably more efficient though, through specialisation
I think prefer `getopts` over `pirate` at the moment, pretty much solely because it generates a help string: life is too short for manually maintaining them. (I see that auto-generation is an intended feature for pirate... something to look forward too!)
LGPL3 is perfectly reasonable for a library. If you're releasing a closed-source program, you need to dynamically link because, AFAIK, there is no way to replace a statically linked library in rust (the LGPL requires that the library be replaceable) but if you're releasing an open-source program (regardless of the license), you don't need to do anything because the user can always just recompile your program.
Why can't you have an `enum` → `i8` mapping in a function? It seems the most straightforward way to do it.
Yes, meeting the LGPL requirements is [cumbersome](https://www.gnu.org/licenses/gpl-faq.html#LGPLStaticVsDynamic) when using static linking. This is mostly a concern for proprietary software, but there are also free software licenses incompatible with LGPLv3 (example, GPLv2). This creates a problem when statically linking *both* the LGPL library and the incompatible code. You may be forced to use dynamic linking in cases where you would rather not to - that is, a licensing concern dictated a matter that should be technical. For most users this isn't a problem though.
Why the name pirate? I gots to know!
Summoning /u/Manishearth to pontificate about Rust's laundry-eating capacity...
Define Define.
Define (verb-transitive): To state the precise meaning of (a word or sense of a word, for example). --- ^(I am a bot. If there are any issues, please contact my [)[^master](http://np.reddit.com/message/compose/?to=Spedwards&amp;subject=/u/Define_It)^(].) ^(Want to learn how to use me? [)[^(Read this post)](http://np.reddit.com/r/Define_It/comments/31vrec/define_it_how_to/)^(].)
Define Define_It.
This one took ages to work out how to break. [Short, hacky version.](http://is.gd/wUrXYA) [Longer, proper version.](http://is.gd/VtLRmR)
Looks good. Interesting idea! In `levenshtein.rs`, the loop could be simplified to: for (i, c1) in word1.chars().enumerate() { for (j, c2) in word2.chars().enumerate() { let cost = if c1 == c2 { 0 } else { 1 }; d[i+1][j+1] = cmp::min(cmp::min(d[i][j+1]+1, d[i+1][j]+1), d[i][j]+cost); } } Which avoids the `.chars().nth()` calls, which are O(n). Also, `Individual::new()` could take a `String` instead of a `&amp;str`. This lets the caller move in their `String if they don't need it anymore, which can avoid copying.
Please don't feed the bot. There are subreddits better suited to that.
Aren't you missing a `*`, to get `(n, &amp;*n)` ? Note that knowing that `&amp;i32` outlives `doesnt_work` is not enough, you would need syntax to tie its lifetime to that of `Box` so that the caller knows how long it will live.
No, I'm not missing anything. Look again. Everything is fine *whistles* Specifically, the lifetime of the `Box` storage that `n` is going to end up in once the function has returned, yes.
Please don't use a `static` like that, `const FIVE: &amp;'static u32 = &amp;5;` is better. Yeah, I can barely say that with a straight face. `&amp;5` *already* lives in static memory, no matter where it's used, but its type hasn't been "fixed" to `&amp;'static` because no RFC was written.
`(n, &amp;n)` also works, as far as type-checking is concerned (deref coercions &lt;3).
Is there any real difference? I mean, there has to be a memory location backing the `&amp;5`, right? And if it's being bound to a `const`, then it should be somewhere in the global data segment, which is where a `static` would live, right?
Because you can say "arg" (as in argument) as "arrrrrrrrrrrrrrrrg!" (like a pirate).
In general `&amp;Vec&lt;T&gt;` is not particularly rustaceany in function arguments. You should consider using `&amp;[T]` instead: it's more flexible and easily recognized by Rust programmers. If you have a `&amp;Vec&lt;T&gt;` or `Vec&lt;T&gt;`, I believe it will even coerce to `&amp;[T]` automatically through deref coercions. (This advice doesn't necessarily apply to `&amp;mut Vec&lt;T&gt;`, which lets you insert/delete elements unlike a `&amp;mut [T]`) 
Very cool! We are one step closer to PostGIS! (also I had no idea that rust had raw string literals via r#) :) 
Many of the comments here are just C++ bashing, which violates the /r/rust rule about zealotry.
Why doesn't this work? fn main() { let a = &amp;mut 4; match a { &amp;mut val =&gt; { val = 5; } } println!("{}", a); } Isn't don't you destruct val to a mutable reference so you can it? rustc tells me that val is immutable.
Yeah, I just learned about them too. [Relevant section in the reference](http://doc.rust-lang.org/stable/reference.html#raw-string-literals)
Yep, that looks clearly wrong. You can file a [bug report](https://github.com/rust-lang/rust/issues) which is probably the best way to ensure the Rust team looks at it.
I don't think docs are being backported meaning it will be fixed in 1.1 or 1.2, not in 1.0.
I did something similar for myself as well. Just wanted a container that I could tinker with nickel.rs some
Grumble. I thought I was in the nightly documentation. Oops. I think it just needs to change from "these operations" to "this operation"
Maybe the space in the "Hello World" directory is messing it up?
And yet, e.g. US politics today look remarkably similar to those in the roman senate 2000+ years ago, reading about the [Vasa](http://en.wikipedia.org/wiki/Vasa_%28ship%29) of the 17th century reminds one of modern software project management,... I would bet on the better language enforcing good practices over humans spontaneously getting smarter and substituting discipline for those enforced rules any day.
Well, you can, but then you're running a match statement instead of returning a constant.
&gt; Keep in mind that, as far as the cathedrals from the middle ages go, having them fall down was a common thing (my brother took a course in gothic architecture) and the ones that are left are the ones that passed that bit of "natural selection". &gt; heh ok, point taken. Still they're impressive, and we still do a lot of prototyping and stress testing today 
I'll be extremely surprised if this doesn't get optimized heavily (to a jump table or better, basically). Plus you're going to have to match off the enum type anyway, which means that the call could be optimized out completely in those cases. It doesn't seem like a particularly important cost.
I was thinking more of somebody passing this a f128, or a big num. Then casting to f64 won't do what you think it does. To me a generic mean function that compute the mean of some Ts should return a T. Casting to any other type should be done at call site, which can be wrapped in a mean_to_f64 function.
To me the appeal is that one has to write the help string anyways. I like to split some of the options in sections, and add some explanatory lines in between. If I do this following the unix convention, this is the only thing I have to write. Docopt generates everything from that automatically. With any other method i've tried I have to write the help string, plus explains the argument to the parser. Some parser can generate a help string for you. But these help strings are, in my experience, worse than the manually written ones. I value a good help string very highly, so until these methods get better, I prefer to write it myself. 
I prefer to write the help string manually. I really value a very good help string, and I have yet to see a parser with auto generated help strings that can match what one can do in a manually written one. 
Would: impl PartialEq for Shape { fn eq(&amp;self, other: &amp;Self) -&gt; bool { self.size() == other.size() } } Not be sufficient for you?
While I agree that getting that perfect help string is pretty difficult with auto-generation, I find that an autogenerated string is perfectly good enough for the things I do. :) (Rarely do the sort of tools I write have more than a handful of arguments.)
The `try!` macro will try to unwrap a `Result` or return it if it is `Err`. The documentation example is actually written inside of a function whose return type is a `Result`, although the documentation example doesn't show it (checkout the actual source of the example to see what actually gets compiled). If you want to run the example from a function like `main`, replace all uses of `try!(something())` to `something().unwrap()`.
Yes, I know I did repeat. But is it required to repeat it here? Sorry for not just testing it, but I've been used to years of C++ UB and I really need to understand and know to be confident. Working now isn't enough for someone who fought UB for years. And thank you for the help so far.
Ahh. Thanks.
I don't really see much bashing in this thread.
Yeah, this seems like a big limitation of what is a small nice library.
I agree that's true in some instances (most non-trivial instances at least ;) ), which is why I ended up adding an `.after_help()` method in `clap` for all those additional details that an auto-generated help string leaves out. When combined with the [from_usage()](https://github.com/thoughtram/clog/blob/ace4b4646b36d7484f2f93d3804f5fde9c70b0c7/src/main.rs#L41-49) style functions it feels like a good level of of auto-generation and additional details. And you still have access to all the fine grained control when required.
That makes a ton of sense actually. Well I guess it also sounds like something the riddler would come up with so props for that.
I haven't done too much digging, so I'm sure `pirate`s author could correct me if I'm wrong, but they appear to be targeted at slightly different use cases. Kind of like a `getopts` to `docopt` comparison. One focuses on a lightweight implementation which allows the consumer to customize exactly how it works while writing very concise code. The downside is you end up implementing a lot of the general features yourself which can be harder in the long run, but they're *exactly* how you want. There are also times where you may *not* want or need many features. Then the other end of the spectrum focuses additional feature sets, or ease of use. Sometimes this is at the expense of complexity at initial set up, or performance (this is **not** to say `docopt` or `clap` don't perform, both are very fast!). Neither method is better than the other, just used in different scenarios. As for `clap` specifically, I work pretty hard to make it fit somewhere in the middle of that spectrum. Very feature rich (things like error suggestions, intelligent usage strings on error, auto-generated help, argument relationship rules, groups, subcommands, and tons more.), while still keeping performance and usability in mind. `clap` can be *far* more verbose that something like `pirate` or `getopts` (even `docopt`), but there are times when that's a blessing in disguise (such as re-factoring [!!], or [dynamically generating CLIs](https://github.com/Byron/google-apis-rs)). To be fair, the addition of things like [from_usage()](https://github.com/thoughtram/clog/blob/ace4b4646b36d7484f2f93d3804f5fde9c70b0c7/src/main.rs#L41-49) have helped greatly with that ;) I think it's great that we have lots of libraries like this (`getopts`, `argparse`, `pirate`, `docopt`, `clap`, etc and I believe there are a few others as well) to choose from! There is very rarely a one-size-fits-all solution, and choices allow specialization and improvements! :) One little known thing is you can still get a very minimal implementation with `clap` to get things like `--help` or `--version` from simply adding 3 lines of code: extern crate clap; // &lt;-- one use clap::App; // &lt;-- two fn main() { App::new("mycli").version("1.0").get_matches(); // &lt;-- three :) } I usually add something like this whenever I make a cli even if I don't intend to use any type of arguments, just for when users out of habit try `mycli --help` or the like (*note*: `.version()` wasn't required, but without it `--version` only prints a name)
This is a weird tension with the examples: do we include the extra stuff around try!, which helps newcomers but obscures the point of examples? I'm still not sure :/
I didn't even know that was an option until I read this comment! Thanks.
A permanent button like [rust-lang](http://www.rust-lang.org/) has which says "Playpen" or something like it should probably be added. Then people will be more likely to see it. The current option is kinda subtle. Not sure though. Someone could make a PR with it and push a version to a server so people could see if it looks good. Then the option is still there to reject it if it looks really bad...
It would be nice to rewrite all code examples in to using `.ok().except(..)` instead of `try!`. I realize that `try!` is the proper way to do things, but it would be nice to have running examples. Alternatively one could postpone the decision and wait for rust to allow for a version of `try!` that unwraps in `main()` and returns in `Err()` outside `main()`. 
Rust does support conditional compilation. http://doc.rust-lang.org/stable/reference.html#conditional-compilation Is that not enough?
Possible solution without using copy/paste might be a macro: macro_rules! impl_partial_eq_for { ($t: ident) =&gt; ( impl PartialEq for $t { fn eq(&amp;self, other: &amp;Self) -&gt; bool { self.size() == other.size() } } ) } impl_partial_eq_for!(Square); impl_partial_eq_for!(Circle); 
Intra-species studies have not found evidence to support a link between brain size and intelligence. Which makes me rather doubtful about your guess regarding Cro-Magnon's intelligence. Of course, short of trying to clone one to measure, we cannot be sure.
There's self-borrowing and there's `impl&lt;'a&gt; Struct&lt;'a&gt; { fn foo(&amp;'a self) {...} }` to have `x.foo()` calls inform the compiler that the `'a` parameter of `x` is `x`'s lifetime itself. I don't recall the latter part being in any of /u/Kimundi's early drafts, so I'm surprised it made an appearance in that post. Please note that the *body* of the method doesn't matter, it could be empty and you would still end up locking `x` with only `foo`'s signature.
Note that `#[cfg()]` will not protect against parse errors.
How about this? trait See { fn see(&amp;self) { println!("seeing"); } } struct Human; impl See for Human {} fn main() { let joe = Human; joe.see(); //prints "seeing" } 
Thanks for the advice. It wasn't really clear for me at first but then I found this blog post: http://hermanradtke.com/2015/05/06/creating-a-rust-function-that-accepts-string-or-str.html
The problem of your Rust implementation is that you are not only trying to use composition but you’re also adding a second interface for everything that is an observer. So you’re using inheritance *and* composition at the same time. You should remove your Eye struct and provide an implementation for `see`: trait See { fn see(&amp;self) { println!("seeing") } } struct Human; impl See for Human {} fn main() { let joe = Human; joe.see(); //prints "seeing" } Otherwise it gets very complicated because you would need to an additional trait that provides an getter for eye like this: trait See { fn see(&amp;self); } trait Seeing { fn observer(&amp;self) -&gt; &amp;See; } struct Eye; struct Human { eye: Eye, } impl See for Eye { fn see(&amp;self) { println!("seeing with an eye") } } impl&lt;T&gt; See for T where T: Seeing { fn see(&amp;self) { self.observer().see() } } impl Seeing for Human { fn observer(&amp;self) -&gt; &amp;See { &amp;self.eye } } fn main() { let joe = Human {eye: Eye}; joe.see(); //prints "seeing" } Now you’re getting an automatic implementation of `See` for everything that implements `Seeing`. The python version of your Rust code actually also needs an individual implementation for every class: class See(object): def see(self): raise NotImplemented class Eye(See): def see(self): print "Seeing with an eye" class Human(See): def __init__(self): self.eye = Eye() def see(self): self.eye.see() 
Rather than thinking about it as a struct lots of things can have. Think about "has eyes" as a trait lots of things can havs
Most of the time it isn't problematic because in the few cases you need it the additional code is negligible. Especially in this example composition is more flexible because adding a second eye is simple but otherwise you have to rewrite a lot. The most beautiful solution is a syntax extension which uses the #[derive()] syntax but because it is not stable a (in this case ugly) macro would also work.
Now you just shifted the problem from implementing `See` to implementing `Seeing`.
This is what I was trying to tell you. You cannot get around individual implementations for every struct if you want to forward the `See` trait to everything that has something to see. This is inheritance + composition, this is as complicated as it sounds…
It was just an example. The real Eye may carry data.
You forgot to mention that C++ needs to *copy* your laundry to eat it, while Rust will happily eat it while *borrowing* it from you – then (in a way that I have yet to understand) return it. Edit: and I still want that higher-kinded T-shirt.
Well, more concretely, let's say I want a list of entities that can see. Some see with eyes, and some not. And for those that see with eyes, I want to use the code implemented for Eye.
"I bought a cat after owning a cow all my life, how do I milk it?" Ignoring how inheritance as displayed here is fundamentally flawed and one of the worst things to ever get popular in programming, why do you want it in Rust? If you learnt German would you be frustrated that every last bit of English slang didn't translate perfectly? Listen to what everyone else is saying: Use traits. Or more specifically, learn how traits work, and how to design code using them.
Well, if re-implementing of a trait from a field of a struct to the struct itself can be called inheritance, then Rust already has inheritance. It's just cumbersome to implement. I'm not unhappy, and I'm not actually writing anything right now, just exploring possibilities in the language...
That avoids a lot of the complications of inheritance because the behavior that you want to "inherit" is defined independently of any particular implementation, with a strongly typed call boundary that all implementations must share, regardless of their attendant data. But you're right, it would be cumbersome to re-implement the behavior of a struct's fields for the struct itself. That encumbrance is a sign that your project could benefit from a refactor.
&gt;But you're right, it would be cumbersome to re-implement the behavior of a struct's fields for the struct itself. That encumbrance is a sign that your project could benefit from a refactor. Quite possibly. Like I said, there is no project, this is just exploration. :-)
The following works, but it is also fairly elaborate. In most cases you can get away with a simpler design, but that depends on the data that you are modelling. Therefore it is probably easier to discuss a real life example. trait See { fn see(&amp;self); } struct Eye; impl See for Eye { fn see(&amp;self) {println!("I see")} } trait HasEye { fn get_eye(&amp;self) -&gt; &amp;Eye; } impl&lt;T&gt; See for T where T: HasEye{ fn see(&amp;self) {self.get_eye().see()} } struct Cyclope { eye: Eye } impl HasEye for Cyclope { fn get_eye(&amp;self) -&gt; &amp;Eye { &amp;self.eye} } fn main() { let bob = Cyclope { eye: Eye}; bob.see() } Here are some ideas on the table that may correspond to what you are looking for. I don't know what the current status is https://internals.rust-lang.org/t/summary-of-efficient-inheritance-rfcs/494 
What about macros ? It would be nice to have a generic delegator macro. Something in the veins of: !delegate(&lt;trait&gt;, &lt;parent struct&gt;, &lt;accessor&gt;)
Yeah, but it's beyond my powers currently. :-)
Like.... literally or in this context? Cause that seems pretty clear.
I'm actually glad that Rust doesn't support inheritance. I find that it's actually better to avoid inheritance as you usually end up with a lot better design that way; of course there are cases where you really **need** inheritance (e.g. a GUI toolkit), but they are pretty sparse.
It would probably be doable as a compiler plugin.
But do you want to keep the code for Eye/Radar/Magic inside `fn see`?
How do you know it works without tests? In `fn train` your `HashMap::&lt;Vec&lt;u8&gt;, i64&gt;::new()`: Do you need negatives? Why i64 and not u64? Also, consider making a `struct Model` such that `Model::train(...)` and `model.correct(&amp;args)` Instead of `print_bytevector` why not `print!("{:?}", vec)`? Everywhere you use `word.as_bytes().to_owned()` why not `word.to_string()` and store a `HashMap&lt;String, u64&gt;`? `let [mut] candidates = edits1(...` doesn't need to be `mut` you can redefine it with `let candidates = known_edits2(...` when you want to reassign it. 
If doing it this way, you'd probably want to implement it for &amp;Shape as in one of the comments below? And as it's already been mentioned, this doesn't implement PartialEq for the actual types, e.g. you can't do x == y and instead have to do (&amp;x as &amp;Shape) == (&amp;y as &amp;Shape).
`Button::Foo();` Edit: sorry I missed the first one
In the trait definition, you can call to the foo function with ```Self::foo()```. Outside of the trait definition you can call it with ```Window::foo()```. The reason you can't call ```foo``` on your button is because ```foo``` is not a method (note the lack of self in the definition). 
Combine this with a "nightly" feature in your Cargo.toml, and you can include unstable *APIs* (not language festures). Using them then requires a nightly compiler and passing '--features nightly' to cargo commands. 
Hmm... maybe it is me being stupid (I will go and hide in my cave) :-)
Strictly speaking, you don't call *default* `foo` here, you call `foo` as it implemented for `Button`, i.e. trait Window { fn foo() { println!("foo() called."); } fn create_window(&amp;self) { &lt;Self as Window&gt;::foo(); } } struct Button; impl Window for Button { fn foo() { println!("overrided foo() called."); } } fn main() { let b = Button; b.create_window(); Button::foo(); } prints overrided foo() called. overrided foo() called. 
I wonder if a middle ground would be an expanded error message in case of non-unit returns from `main`.
No need; `Deref` is already designed such that it works as delegation (even if that's not the "intended" purpose).
For individuals within a species, no, brain size doesn't correlate well with intelligence. But between species and over evolutionary time, yes, having a larger brain (particularly relative to body size) absolutely correlates with intelligence. Humans have unusually large brains, both for our body sizes and in absolute terms; that's not a complete coincidence, as you are implying. In any case, this is not a personal pet theory. http://discovermagazine.com/2010/sep/25-modern-humans-smart-why-brain-shrinking presents some of the various theories about why this is happening, and yes, one of them is that humans are indeed becoming less intelligent. There are, of course, other explanations, but your immediate dismissal of that possibility seems strange to me. I also want to call out the analogy with a CPU. Brains do not work like computers, and assuming that they do will often lead you astray.
We are getting a wee bit off topic here, so I'll try to be brief. Please note that a) correlating brain size with intelligence is a bit too simplistic and ignores many confounding factors, and b) this type of research has seen unhealthy interest by racists and xenophobes everywhere to explain their odd theories, which makes the topic quite loaded. PM me if you want to take the topic further.
Oh yup. Can't believe I couldn't find that. Thanks!
Thank you for this note. It makes sense, but I would have forgotten about it.
That is my personal theory, yes. This would help focus proposals to focus on the interesting part (thin pointers and cheap casting) which have more applicability than this sort of inheritance anyway.
PS1: both are decent choices. Reddit has more readers, I expect that to change over time. I'm on mobile, so I can't check out the code right now, but I'm glad to see this library exist! I share your reservations, but like you say, sometimes you have no choice...
Oh, that makes sense obviously. 
Inheritance is a means of architecturing programs, not a fundamental operation. All languages necessarily restrict their structuring constructs to a subset of all possible constructs. Other constructs that Rust doesn't have include: `goto`, exceptions, continuations, and counter-incremental for loops. Not saying there aren't good reasons for languages to include inheritance, but languages without inheritance get along just fine. Rust is not a Smalltalk-descended object-oriented language like Java, Python, and Ruby.
Put more concretely, what you want is `all_numbers.extend(more_numbers.iter().cloned());`, which is stable.
I come from a time *before* such syntax worked, a dark time where great beasts roamed the land and often was the sun blotted from the sky by the black clouds of misfortune. But mostly, I didn't think to try.
Doesn't that make the suggestions only work for that version of Rust? The documentation would work for a majority of the code, but some suggestions would not be correct. It would be nice if multirust included the source to work with racer.
Don't do this. Don't do this in Rust. Don't do this in Python. Don't do this in C++. Don't do this in Java. Don't do this in Javascript. Don't do this anywhere. Please. As someone who has to maintain your legacy code, I beg you not to. Let's say you now want to add a `roll()` method to your `Eye` class. Your `Human` suddenly gains a `roll()` method that doesn't actually appropriately implement rolling for `Human`s. Seriously seriously prefer: class Human: def __init__(self): self.eye_ = Eye() def see(): self.eye_.see() Yes, it doesn't look as pretty. But it's infinitely more maintainable. You can now make all the changes to the Eye class you want, and as long as it can still `see()`, your `Human` will behave correctly. If you want a set of things that can "see", have Human and Eye to conform to a common interface, `SeeingInterface` (in OO languages), or have them both implement the `Seeing` trait (in Rust). This accurately models what you're trying to do, and isn't nearly as brittle. It looks like you've got 400% overhead in doing this. You haven't, in anything but the most trivial of cases. If your biggest problem is verbosity, you're either in a very good place with your code, or you're working on something incredibly trivial.
Where does `Vec::iter()` come from? I have grepped through the source for the definition of this function, but can't find it (see [here](https://doc.rust-lang.org/src/collections/vec.rs.html#142-146) and try grepping for `fn iter`). . I know that I can call it: fn main() { let x = vec!["hello", "doctor", "name", "continue", "yesterday", "tomorrow"]; let y = x.iter(); // &lt;-- IT'S ALIVE!!!! println!("{}", y.count()) } but it gives me the willies that `.iter()` doesn't seem to have an implementation anywhere in the source code, and AFAIK you can't derive it... Is there some sort of trait magic involved? 
I'll just leave this here: [A Bridge to Nowhere](http://thecodelesscode.com/case/154)
&gt; I thought it's forbidden because then it provides a loophole through which you can implement remote traits for remote types via local traits (please correct me if I'm wrong)? There is nothing to correct, it’s just a different wording of the same thing. &gt; but then you're not really implementing it for the type itself still Yes because you can’t do that. You can only implement foreign traits for type you define in the current crate which includes trait objects.
Oh, excellent. I can use it with no issues, then. I'm curious how this is possible, though - the function is stable, but it returns an unstable type? Maybe I don't understand what stable and unstable mean.
Cool project! I think this might at some point be able replace the bigints from `num`, which are dreadfully slow compared to GMP. Speaking of which, how does this compare to GMP?
I'd love this. Especially for complicated traits it saves a lot of typing, when you really need delegation.
That header picture always gets me.
https://github.com/carllerche/mio, https://github.com/carllerche/eventual_io 
Oh, wow, I feel stupid now - how did I missed the Into&lt;T&gt; trait for so long? Just recently I needed to solve similar problem and ended up creating what is essentially my version of Into... Thanks for the enlightenment! :)
Do you know if there's any initiative to use evented IO with Iron? I'd love to replace Node/Io.js stack with Rust.
Just a little bit of magic, but no more! In the API doc, you can find the [`iter` method on the `std::vec::Vec`](http://doc.rust-lang.org/stable/std/vec/struct.Vec.html#method.iter) page. Now, if you scroll up a little, you will find that this method is in the section *Methods from Deref&lt;Target=[T]&gt;*. This title text contains two links : one to the `Deref` doc, and one to the `slice` doc. The `Deref` doc has a nice example of how this trait is supposed to be used, and how his `Target` parameter works. Actually, this trait is special because the compiler knows about it. It belongs to the same family of traits as `Add` (that is behind each use of the `+` operator) and `Index` (behind each use of the indexing operator `[]`). `Deref` is used when we explicitly dereference an expression using `*`, and it is also automatically inserted by the compiler when calling a method on an object. In our case, when calling a method on a `Vec`, the `Vec` object can be automatically dereferenced as a slice (`[T]`), a "lower level" version of our `Vec` that contains tons of useful methods. In the `Deref` page, you will find `impl&lt;T&gt; Deref for Vec&lt;T&gt;`. The impl can be found in vec.rs, with the signature `impl&lt;T&gt; ops::Deref for Vec&lt;T&gt;`.
Try to ask this guy https://github.com/reem about evented IO in Iron.
Or people can just pass `&amp;x`, which theyre conditioned to do anyway by types like `Vec` and `String` (I suppose this trick wouldn't work when passing by value).
Well for relatively small numbers, Ramp should fare well against GMP. It's the large numbers, where the improved algorithms GMP has take effect, that the difference becomes more obvious. I don't have any benchmarks yet though. 
Well the whole algorithm is basically just creating quadtree and using it to optimise checking of poisson-disk distributions invariant. Without the quadtree you would need to check distance between all nodes and the node you are adding to the distribution. The algorithm itself tries to add points to the distribution until the space is filled, but the you can run the algorithm so that the algorithm generates approximately points you want by calculating radius with formula in calc_radius.
There is an RFC to make `extend` just work in this case: https://github.com/rust-lang/rfcs/pull/839 In the meantime, use `array.iter().cloned()` as mentioned in other comments.
The Rust ABI is not stable. So, while you could create a FFI for Rust binaries, it probably needs to be updated for every new Rust version (for the time being). On the other hand, the C ABI has been stable for the past 30 years or so.
Close. You would need to do `for 1..(N/2)`, right? And if thats true I think a while loop would be less error prone.
I'm getting a error when I run this: note: this feature may not be used in the stable release channel error: aborting due to previous error Do I have to reinstall rust to use the nightly instead of the stable version? 
There is one problem. You can't combine .rev() and .step_by(). See https://github.com/rust-lang/rust/issues/23588.
Hmm, that explains it a bit. I wasn't aware that loops had changed so much.
Well, there's a reasonable view that this behavior is a bug, but at the same time, a relatively minor one. Something is stable if you can compile it either as-is or with trivial modification on Rust 1.x+1 for any x where it worked. See https://github.com/rust-lang/rfcs/pull/1105 for more details. So, consider the type signature of `cloned()`: https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.cloned fn cloned&lt;'a, T&gt;(self) -&gt; Cloned&lt;Self&gt; where T: 'a + Clone, Self: Iterator&lt;Item=&amp;'a T&gt; And `Cloned`: https://doc.rust-lang.org/std/iter/struct.Cloned.html pub struct Cloned&lt;I&gt; { // some fields omitted } All of `Cloned`'s fields are private. And since it represents an iterator, the only methods it's going to implement are the iterator ones. So, while we may not be 100% willing to stabilize `Cloned` as is, its use in this type signature is essentially stable. Furthermore, if you look at `Cloned`'s reason for being unstable, "Unstable : recent addition", and `git blame` it: 4a656062e src/libcore/iter.rs (Alexis Beingessner 2014-11-17 21:00:07 -0500 1376) pub struct Cloned&lt;I&gt; { We see that this was added back in November, and hasn't really been changed since. So this is really one of those things that just got lost in the shuffle for a while, for more important things: making it `stable` wouldn't really let you use it any better... but this is just a guess, I'm not 100% sure. I would argue that `Cloned` is ready to become stable. Maybe start an RFC? EDIT: oh look at this: https://github.com/rust-lang/rust/pull/25496
You could do `for i in (0..N/STEP).map(|i| i * STEP) {`. It's not so nice, but...
Sure. That's what the pokerlookup crate does :) It's a port of the 2+2 code, can generate the 124mb large lookup table and use it to evaluate 5, 6 or 7 card hands as fast as it gets. Everything else is basically a buildup to it, although the pokereval stuff works fine enough by itself (it's cactus kev's evaluation method).
If you like procedural style, you can also use `while` or even `loop` :)
Cool project! In the example within the `readme.md`: I *think* you forgot a `use ramp::Int` there! :)
Have you seen the itertools crate? It has an izip! macro which does the same thing. https://bluss.github.io/rust-itertools/doc/itertools/macro.izip!.html Universal function call syntax means you can also call ```Iterator::zip(a.iter(), b.iter());```
Since there's an implementation in std of impl&lt;T&gt; From&lt;T&gt; for T (i.e. whenever we have a function fn f(s: YourStruct) {...} we can replace that with fn&lt;T&gt;(s: T) where T: Into&lt;YourStruct&gt; { let newS: YourStruct = s.into(); ... ) without any issue), is there any reason not to use Into in general? In the case of using the function with a parameter of type YourStruct, would the s.into() line disappear after compilation? 
Thank you for digging in to this and for spending so much time providing the example code! Looking at the implementation of `next()` in the code that you pointed me to: impl&lt;'a, I: Iterator + ?Sized&gt; Iterator for &amp;'a mut I { type Item = I::Item; fn next(&amp;mut self) -&gt; Option&lt;I::Item&gt; { (**self).next() } fn size_hint(&amp;self) -&gt; (usize, Option&lt;usize&gt;) { (**self).size_hint() } } Two follow-up questions: 1. What's with the double-deref `**self`? I imagine that if `self` is of type `&amp;'a mut I` then `*self` is of type `I`, so what is the type of `**self`? 2. Why isn't `(**self).next()` an illegal move out of borrowed context? Since I imagine that `next` still insists on consuming `self`. It just seems to be kicking the can down the road. EDIT: DOH, right after hitting "save" I realized that `next` takes `&amp;mut self` and not `self`. Still wondering about the double-deref though. I'm guessing that answer to #2 is somehow related to #1 and has to do with the double-deref somehow, but I don't see it...
That is *not* a pleasant method of browsing Rust documentation.
The `self` value has type `&amp;mut (&amp;mut I)`, and since `&amp;mut I` is an iterator (i.e. has a `next` method), to call iterator methods on `I` itself, one has to dereference all the way to it (i.e. twice), to be specific.
&gt; It is after all aliasability and not mutability that's the biggest distinction. While both perspectives are certainly valid, and while I think overall I agree with you, post mutocalpyse we decided to use the mutability side of this coin with regards to terminology.
&gt; Still, their approach of compiler development - **do not fix bugs, fix bugclasses** - has produced a solid platform to write robust code. I've never heard this expression before. Is it something from the paper or something the Rust team has used to describe its approach? If the latter, what precisely does it mean?
Hi, author here. When I wrote this paper, I was nearly sure that I heard this from some Rust developer. But now it looks like I may have [cited myself](https://twitter.com/gcouprie/status/448010181361008640). Nevertheless, the approach is valid in the context of the compiler: whenever someone finds a memory corruption bug in her code, maybe the compiler would have prevented it. If you require the developer to write good code and be careful, you are in the additive bug fixing approach. If you update the compiler to take care of it, you remove whole bug classes, and multiply the fix by the whole available rust code base.
[**@gcouprie**](https://twitter.com/gcouprie/) &gt; [2014-03-24 08:15 UTC](https://twitter.com/gcouprie/status/448010181361008640) &gt; do not fix bugs. Fix bugclasses. ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://www.np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
The phrase has been around awhile: https://www.google.com/search?q=%22entire+classes%22+rust+safety
Rust equivalent of C++ pointers: Am I correct? C++ Rust ----------------------- --------------------------- int a = 10; let mut a = 10; int *a_ptr = &amp;a; let mut a_ptr = &amp;mut a; int * const a_ptr2 = &amp;a; let a_ptr2 = &amp;mut a; const int* a_ptr3 = &amp;a; let mut a_ptr3 = &amp;a; const int* const a_ptr4 = &amp;a; let a_ptr4 = &amp;a; const int b = 10; let b = 10; const int *b_ptr = &amp;b; let b_ptr = &amp;b; int *b_ptr2 = const_cast&lt;int*&gt;(&amp;b) &lt;not possible to do safely&gt; 
Because Kate is editor than can rather than Kant.
I dunno about /u/deadstone, but it *immediately* failed one of the most basic tests: it breaks scrolling with the arrow keys. Go directly to Web Dev Jail, do not pass Go, do not collect $200.
In your opinion, do you think this kind of library would benefit from do notation?
Wow, cool! I didn't know it existed.
I'm curious why there even is a need for the Cell type. Why can't the compiler simply allow the same semantics for normal references if the type is Copy? It must be a benefit to all users if the number of reference types are minimized.
Couldn't the same effect be achieved by allowing the `mut` modifier for fields with a `Copy` type? To me it seems the `Cell` type is just an unsafe wrapper for `Copy`-able values so why not change the language semantics to allow this safely, but maybe I'm missing something.
Is C ABI really stable for 30 years? It's different on every architecture, and changes even then. See Arm Old ABI vs Arm EABI vs ARM EABIHF etc. 
That phrase, or something similar has been around for a while, it basocally means instead of fixing an instance of the bug you make the bug impossible, thereby preventing it and any other bug like it (ie any bug in the same class of bugs). For example the borrow checker does this for use-after free (and some other classes too).
Having `mut` fields is pretty much what `Copy` provides. It's not too much overhead either, and the full-copy-on-write is explicit. Also, `Copy` is more general than `mut` fields. You can, for example, use it inside an `Rc` or something. Copies are generally implicit, but when there's shared mutability involved it's preferable (IMO) to have them being explicit; which is what `Cell` provides. [`Cell` isn't unsafe; it's safe.]
When you're using the Into Trait you're also most likely using it as a generic parameter for a function und therefore your code size might increase. Does Rust have some kind of whole program optimization, that a generic function is only instantiated once for the same generic parameters? So would the Rust developers really recommend Into&lt;String&gt; in this case? 
On this tangent: I've come the whole way round to Niko's point of view on the naming of things... Finishing implementing by-value closures was definitely the right way to resolve it at the time, but it's sad that we're now stuck with the old terminology.
I updated it and added a "Composition" section; comments?
When you write: use std::collections::hash_map::{self, HashMap}; It's like you've written two lines: use std::collections::hash_map; use std::collections::hash_map::HashMap; It means than `hash_map` and `HashMap` are both imported, so you can use them like this: let x = HashMap::&lt;i8, i8&gt;::new(); // thanks to std::collections::hash_map::HashMap; let y = hash_map::HashMap::&lt;i8, i8&gt;::new(); // thanks to std::collections::hash_map; // &lt;=&gt; std::collections::hash_map::self; 
In the case of that first line, what it's doing is effectively equivalent to: use std::collections::hash_map; use std::collections::hash_map::HashMap; The `self` is referring to the module itself; this lets you bring both a module *and* some items it contains into scope in one line instead of two.
BTW, since Java 7 (IIRC) substring method on strings in Java allocates a new string every time.
Thanks to both of you. It's always the simplest possible option imaginable...
Thanks to both of you. It's always the simplest possible option imaginable...
Based on your constraints, I tried a toy design of your game hierarchy. There is not a single pointer; only references. Everything is checked upon compilation, zero error guaranteed. // Every object of the game which gets triggered by the clock needs to be // provided some context in order to advance. // This is represented by the associated type `Context`. The context must // outlive the object being ticked. trait Tick { type Context; fn tick&lt;'s, 'c: 's&gt;(&amp;'s mut self, context: &amp;'c mut Self::Context); // ^~~~~~ 'c outlives 's } struct Player { hp: u8 // 0-100 } impl Tick for Player { type Context = (); // Could be some enemies, for example fn tick&lt;'s, 'c: 's&gt;(&amp;'s mut self, _context: &amp;'c mut ()) { unimplemented!() // say, it could lose hp if an enemy is too close } } struct PowerUp; impl Tick for PowerUp { type Context = Player; fn tick&lt;'s, 'c: 's&gt;(&amp;'s mut self, player: &amp;'c mut Player) { player.hp = 100; // revive! } } struct World { player: Player, powerup: Option&lt;PowerUp&gt;, } impl World { fn global_tick(&amp;mut self) { self.player.tick(&amp;mut ()); match (&amp;mut self.powerup, &amp;mut self.player) { (&amp;mut None, _) =&gt; {}, (&amp;mut Some(ref mut pwup), ref mut player) =&gt; pwup.tick(player), }; } } fn main() { let mut w = World { player: Player { hp: 100 }, powerup: None }; loop { w.global_tick() } } http://is.gd/hDDX6t
Why would you ever want to store a copy of the Player pointer inside every single PowerUp? While this is certainly possible in C++, it sounds like a bad idea: duplication of information, too many responsibilities for PowerUp, too tight coupling between PowerUp and Player. You may want to use one of those solutions: 1. Treat PowerUps as passive entities, and have a separate Collision system that is responsible applying effects to the Player when it collides with the PowerUp ([introduction to the Entity-Component-System pattern](http://jjcomer.github.io/blog/2011/11/06/entity-oriented-programming/)) 2. Make PowerUp a trait including a fn apply_effect(&amp;mut Player). Each PowerUp implementation can have a different effect by implementing this function differently. The World would be responsible for passing the correct Player argument to apply_effect.
The concept/ phrase certainly predates Rust. Mitigation techniques are centered around the idea of dealing with classes of bugs, not individual vulnerabilities.
That is what I wanted at first, but I was able to [work without](https://github.com/Geal/nom/blob/master/tests/mp4.rs#L247) 
Yes, I see that there would be a difference because with a `Cell` you would get a reference to the field in a temporary copy which would not be changed when modifying the `Cell` value. Thanks for clearing this up. I do see a problem with hidden unsafe code in libraries though: you don't know that the implementation is safe. But I guess that's a compromise you have to live with unless there is a way to automatically generate code using a theorem prover like Coq (or full dependent types are implemented in Rust).
Is there any place currently with 'change logs' or 'what's new' for Rust Nightly releases? Or are changes marked somehow in the Nightly Docs? (If they *are*, I haven't noticed them.)
You can scroll by using alt + arrow. Using arrows only navigates the sidebar. It should probably be the other way around?
It should scroll whichever region has focus, like just about every other webpage and program I've used in the last 15 or so years does. I'm afraid I have *zero tolerance* for websites that play silly-buggers by deliberately overriding normal functionality for no good reason.
Hm, I'm not sure what issues you have with implementing a dot product trait that you didn't have with the heaviside one. As far as I can see, it should work exactly the same way.
I've replied to the OP. You won't like it. :)
Using an `Iterator` trait object moves the tradeoff (from horrible types to dynamic dispatch), and also allows using closures.
Are you willing to fight for your precious *anonymized* return types?
&gt; I do see a problem with hidden unsafe code in libraries though: you don't know that the implementation is safe You have to trust it as much as you already trust the borrow checker to work. FWIW, the borrow checker has had more soundness bugs than the libraries in my experience; the libraries are based on a small set of principles; the borrow checker is more complex. Besides, in this case it's actually a "special" unsafe. It's not doing any pointer reads or stuff. It's just writing/reading from a special struct called `UnsafeCell`; which is endowed by the compiler to sidestep mutability restrictions. Because this can *cause* unsafe behavior to happen if done unrestricted, this is marked unsafe.
Screenshots?
Can you please explain why you emphasized the word "anonymized"? Is that what we are calling it now?
The C++ version is using -O3. -O3 often performs worse than -O2 because it's intended to be used for experimental and unstable optimizations. -O2 is the proper flag to use.
Maybe fix the order of entries? For example its 4.1 -&gt; 4.10 -&gt; 4.2 in the rust guide .
If you decide to use it with blocking, you should use a cron script that clears the table. If you only use rate limiting – it doesn't remember IP addresses for more than the interval (minute or whatever). &gt; by *someone* doing ... What do you mean "someone" – that someone doesn't have the same IP address as me (the owner of the server), right?
So on the basic helloworld tutorial. My terminal is not outputting the string? Everything looks fine and is installed according to the docs. OSX 10.10.3 Doing this over lunch in work.
This looks awesome! I love the design choice to keep everything in a single thread to avoid the need for mutexes/barriers. In your examples, the accept_loop waits on receiver.accept() for a single bound listener. If one wanted to handle multiple listener ports and potentially multiple protocols (e.g. http + websockets) in the same event loop, it would be a matter of making an array of ConnectionReceivers and "select" across them. Is there currently a way to select on multiple promises? I notice that there is a theme in Rust evented IO so far that resources and their containers move in a circle through the control flow. This is kind of a vague concept, but it seems to be one of the "curiously recurring" patterns in Rust. I wonder if there is a way to formalize this notion or at least standardize on some semantics or at least document the patterns. 
Just copy-paste the types from the error message. It will be longer than the code, but will work.
Also, are you concerned about the performance implications of "recursively" constructing FnOnce's to handle recurring events? I haven't actually benchmarked it. Have you considered using fn instead of FnOnce in places which don't require the capture of scope?
This looks good within the limitations of what Rust can do. I have to say though, that it is a shame that Rust forces us to write callback spaghetti code in scenarios like this, when it is otherwise so helpful when it comes to writing modern looking, clean code. I'm really hoping we get some kind of async/await-like lightweight coroutines at some point.
&gt; Is there currently a way to select on multiple promises? If I have two promises, `p1` and `p2`, I can form a promise that will be fulfilled when both are complete, like this: let p3 = gj::join_promises(vec![p1, p2]) or I can form a promise that will be fulfilled when one of them completes, like this: let p3 = p1.exclusive_join(p2); With `exclusive_join()`, the promise that does not complete first gets cancelled. Does that answer your question?
There has been quite a bit of discussion regarding this in [mio](https://github.com/carllerche/mio/issues/16) . What I would recommend is make a static atomic [boolean](https://doc.rust-lang.org/std/sync/atomic/struct.AtomicBool.html) variable called RUNNING. Make and register a sig handler using the signal API in nix rust (https://github.com/carllerche/nix-rust/blob/master/src/sys/signal.rs) Register a sigint callback fn that simply sets RUNNING to false. Have your loop run intil RUNNING is false, then put your clean-up code after the loop. 
exclusive_join() sounds like the ticket. I could just chain a series of promises CONS style to "select" on a list of promises. 
Well, just the namespace. It looks for extension methods on all static classes that are in scope, which means the current namespace, parent namespaces or namespace that have a using reference.
My understanding of async/await is that `async` means "spawn a new coroutine" and `await` means "yield". It looks like some people are indeed working on these things: https://github.com/rustcc/coroutine-rs An interesting question here is: should the closure argument to `spawn()` have a `Send` bound? Will we need two separate spawn functions, one that executes everything on the same thread and doesn't require `Send`, and another that can distribute work across threads?
&gt; Due to some stack limitations in Rust I haven't payed much attention over the last few months. What stack limitations are you referring to? Also, only difference I saw was the light source at the top of the rust image. It looks like there was some anti-aliasing differences happening, but I don't have a clue if thats significant.
I compared your benchmark between O2 with O3. O2 performs consistently but only slightly faster than O3, but not enough to justify it being the reason for why it's slower. The other consideration then is the number of threads. In the Rust version you are using 4 threads, in the C++ version it is unspecified but you state you have a quad-core processor. If you have hyper-threading enabled then the C++ version will be using 8 threads. If hyper threading is enabled, this can also explain the reason for the worse performance. Can you run the Rust benchmark to also use 8 threads and run the C++ benchmark to use O2 and then post the results on your machine? I do not have Rust on my benchmarking server otherwise I wouldn't mind doing it myself.
[This article](https://ruudvanasseldonk.com/2014/10/20/writing-a-path-tracer-in-rust-part-7-conclusion) has a similar conclusion.
My machine doesn't have hyper-threads, so in both cases 4 threads are being used. (I checked also in top -H)
Thank you, in that case the results do look promising.
I'm not quite sure what you mean about `Fn` vs. `FnOnce`. Your question about recursion is astute. :) I think at the moment that constructing promises recursively like this actually leaks memory. :/ I think this is fixable, but in any case for constructing infinite loops like these you can always work around this problem by pushing promises onto a `TaskSet` instead of returning them.
&gt; Yeah, but like I mentioned, I was trying to translate it as closely as possible. But I don't think that was what OP meant: &gt; So I challenge you to solve the calendar example in the nicest way possible using Rust! I don't know if looking at a 1:1 translation is really helpful... 
To add to the other replies here, I've seen this notion also in a 2013 CCC talk (Bug class genocide) about eliminating buffer overflows in C/C++
&gt; "rustic" to me means avoiding allocations where possible, and composing stream processing using iterators The range-v3 version solves the same problem "in this spirit", so I guess that this is the intended way to do it. Simplicity is also important: the range-v3 version takes some things farther than D (infinite ranges), and other aspects not as far. This is fine, these are different languages and libraries after all. The most important thing that this example demonstrates is how to write composable code in each language. Both, the D and C++ implementations are "tutorial like": they show how to build your own range type for each library and language. Performance is, in my opinion, secondary, but of course both D's std.range and C++'s range-v3 take pride on being very fast. About the number of allocations, the C++ version allocates one string per output line that is created by concatenating smaller strings. I do not know how complicated it would be to reuse the string storage.
Gustorn: Thanks a lot for that!
-ffast-math is about telling your compiler you don't care much if the floating point math is done strictly. Because of the nature of floating points, there are some precautions your compiler must take while optimizing code containing them. There are some kinds of optimizations that are prevented because of these precautions your compiler must take. I can't list them all here (because I don't know, and I'd imagine it isn't a small list). With -ffast-math, gcc will pay less attention to those things in favor of optimizing your floating point math code. This option is there because many people don't care about strict floating point math compliance. If I recall correctly, an example I saw showed how __x = x\*x\*x\*x;__ isn't the same as __x \*= x; x \*= x;__ because of how floating point works. With -ffast-math though, the compiler will assume you don't care about how the 2 pieces of code differ and it'll choose the faster one during some optimization phase. __[edit1]__ Floating point math is VASTLY weird. It's full of edge, icky, weird stuff. This blog https://randomascii.wordpress.com/ has a bunch of interesting posts on floating point. It's fascinating. Check the floating point category (https://randomascii.wordpress.com/category/floating-point/). __[edit2]__ I found the page in which I saw the example above: http://stackoverflow.com/questions/7420665/what-does-gccs-ffast-math-actually-do
I don't really understand why so many people are so keen on adding co-routines to Rust. It seems to me that the problem space where they're actually warranted is very small. If you need to do *anything*, *anywhere* that blocks they fall on their face. If you need to allocate a stack for them, you might as well not bother. If you build your own scheduler, you better have a good reason to think you can build one that's faster than the OS scheduler. Look at the crazy amount of code in golang which tries to make this stuff work, and yet it's not really clear if it provides any benefit at all. Threads are just better for most applications. I'm very happy that Rust has thrown out the green-thread implementation, and I really hope it doesn't come back.
Anyone know why the circle/light source is less rigid w/ the c++ verson and more rigid w/ the rust version?
Thanks, so marginally faster but no where close enough to justify the performance difference.
We usually write up changelogs before each release. This Week in Rust also summarizes changes on a weekly basis.
These are only rough equivlanets. For example, a `&amp;mut` pointer guarantees no aliasing, C++'s `&amp;` does not. And Rust's `&amp;` pointers check lifetimes for validity, C++ has no such built-in concept.
[Screenshot](http://i.imgur.com/hfuQiZX.gifv) I shrunk down the window size so it would fit in the browser.
Sorry, I posted that from my phone while out. I followed the Hello World tut. Created Hello_World.rs fn hw() { println!("Hello, world!"); } Ran rustc hello_world.rs And the terminal reported no errors, no output either 
A shameless plug if you would :) I've written a lookup-table-based 5-9 card evaluator a while ago (for MC simulation in Omaha), the repo is a bit messy but the main meat is here: https://github.com/aldanor/ray_eval/blob/master/src/raygen9.cpp I believe at the moment of writing it was the fastest Omaha evaluator to date if you don't mind a ~1GB lookup table (maybe it still is...) and it uses some neat tricks to pack the whole space tightly into a gigantic recursive table :) Edit: the per-hand scoring itself is cactus kev.
yes, I should have been more specific sorry.
May I steal this comment for the post?
I have never heard of -O3 being considered unstable/experimental either. One can see what GCC turns on at O3: https://gcc.gnu.org/viewcvs/gcc/trunk/gcc/opts.c?view=markup#l514 
&gt; sometimes slow code down by over-aggressive inlining ! Learning opportunity! This is a thing? Under what circumstances should I avoid using `#inline(always)`?
Well there are a couple of places to learn from. The first is of course the [Rust book](https://doc.rust-lang.org/book/). The explanations are really good, you'll learn a ton in it. Then you have [the `std` crate docs](http://doc.rust-lang.org/nightly/std/). Not useful in my example here, but you'll need it sooner or later. One of the most useful things here might be [the `Iterator` trait](http://doc.rust-lang.org/nightly/std/iter/trait.Iterator.html). This must be my personal most looked up page from the docs. Then finally, when there's something you believe is not in the docs, remember that Rust has not been stable for long. Ask google and occasionally you might find links to the RFCs. *Don't freak out* -- they're not too technical. Read some of them, they might actually help you. For example, I don't remember having seen the `'a: 'b` syntax in the docs. However, I discovered it [in an RFC](https://github.com/rust-lang/rfcs/blob/master/text/0192-bounds-on-object-and-generic-types.md).
I think that'd be a big win for doc browsing too. It keeps the type with the name when you have fn do_it(p: ~Path) rather than fn do_it&lt;P&gt;(p: P) where P: Into&lt;Path&gt;
FYI, the last line is undefined behavior in C++. You're not allowed to cast away constness. For example, the following program #include &lt;iostream&gt; int main() { const int x = 3; ++*const_cast&lt;int*&gt;(&amp;x); std::cout &lt;&lt; x &lt;&lt; std::endl; } prints "3" even without optimizations on my compiler (gcc 4.9.2). It's also undefined behavior in Rust, when you use unsafe functions like `transmute` to do it.
coroutines aren't really about scheduling. As robinet pointed out, they are all about avoiding inversion of control. The classic example is writing an iterator for a tree datastructure. Its easy to write an internal iterator with recursion (pseudocode example because I am a rust noob): function iterTree(tree, cb){ match tree { Leaf(x) =&gt; cb(x), Node(l, x, r) =&gt; { iterTree(l, cb); cb(x); iterTree(r, cb) } } } But its vastly more complicated to write an external iterator that can "pause" and resume with a `next()` method because you need to turn all that code inside out and maintain the "call stack" by hand. On the other hand, with a yield keyword you can just replace the `cb()` calls by `yield x` and you are done :) And this doesn't have to be as complicated as Go green threads, which have their own scheduler. You could theoretically do something a bit similar to C#'s async or the Regenerator tool for Javascript, where the compiler does continuation-passing-conversion for you so you can have async code without needing to write any callbacks yourself.
I come from a largely web background (Javascript, Ruby, PHP, Python), and thus largely an OOP background. Are there any readily available resources to transition from an OOP to imperative mindset? I'm used to having classes with methods, but Rust doesn't really have that. I don't necessarily understand the correlations between different things. For instance, in PHP or Ruby or Javascript, I might have a class with methods. In Rust, it looks like there are structs, enums, impls, and functions. Are there any obvious correlations between them? E.g., maybe a struct is roughly similar to a class, an impl roughly represents the methods of the class... or am I way off on this? I'm a pretty experienced programmer on the OOP side, and I've been messing with Rust since 0.4, but I've always had this block and haven't really wrapped my head around it yet.
&gt;&gt; To me, "container type" means Vec, HashMap, etc. &gt; I know, but there isn't really any better terminology here. Try "wrapper" or "smart pointer". He's right, "container" usually refers to a data structure that holds multiple elements, so using that for `Box` and `Rc` is confusing. 
Code size may negatively affect performance due to instruction cache pressure.
Did you have any improvements with `-C target-cpu`? I'd love to know if there is more to win there. You probably have a `corei7-avx` or `corei7-avx2` compat cpu?
They may not be anonym**ous** but they certainly are anonym**ized**: you cannot tell that `foo` returns `i32`, or any other type for that matter. This is also **not** the equivalent of C++'s "return type deduction", `auto` or whatever.
Works for me.
Of course. :) [See also](https://github.com/rust-lang/rfcs/issues/1106), [and](https://www.reddit.com/r/rust/comments/32ypxp/questions_about_mutability/cqgpale?context=3). I wrote in terms of `Cell` above because that's what exists, but I kinda think `CellRef` (or whatever we call it - `SharedShallowMutRef`) is the more primitive notion (alongside of `&amp;` and `&amp;mut`), and in a properly opinionated world the only thing you could directly do with a `Cell` would be to get a `CellRef` to it, and all other functionality would be in terms of that.
It can have a huge impact in some cases where it makes vectorization possible. Ignoring memory overhead, it is possible to achieve 4 times (with SSE) or 8 times (with AVX) the performance.
`async`/`await` is not spawn/yield, it's syntactic sugar for promises. `async` means "this function returns a `Task` rather than completing synchronously", where `Task` is just a future and doesn't require any particular implementation. `await someTask` then means "do the rest of this function when `someTask` completes, and return a new `Task` representing that". It works similarly to C#'s `yield`, by transforming the function at compile time into a state machine so it can pass each continuation as a callback to the `Task` being awaited.
Awesome; thanks!
Your version looks nice too :)
My rule of thumb for using `inline(always)` is: never use `inline(always)`. Overuse of it is brutal on LLVM's optimizers because it forces LLVM to inline every call it can and reoptimize the same code, which is expensive. In general it's better to trust LLVM's inlining heuristics and not override it. std used to have the attribute on many functions, the thinking being that these tiny abstractions should always be boiled away. Over time the compile time of std slowed to a crawl and we removed most of them. Now seeing `inline(always)` in a PR raises eyebrows. Don't tag functions with `inline(always)` unless profiling tells you it's necessary. `inline` is fine.
There's been a few Rust raytracers lately. Just for fun, here is the first Rust raytracer I saw, in 2011: https://mail.mozilla.org/pipermail/rust-dev/2011-December/001070.html The source code is in the mail attachments. I wonder if the author is hanging around here.
That's a great tip! It's included in the cargo bundled with current nightly at least.
&gt; […] to transition from an OOP to imperative mindset It's not really "imperative" what you are after, is it? C is imperative. Rust is too, but it's also functional and object-oriented. I think it's dangerous to try and compare Rust principles to 'classic' OOP stuff. Most of the time. But: &gt; E.g., maybe a struct is roughly similar to a class, an impl roughly represents the methods of the class... It's a bit like that. Unlike JS for example, Rust divides "data" and "methods on data". So, you define your data structure as `struct` or `enum` and then use `impl` on that structure to add methods. If you really like the formal definitions of OOP (which is more hard-core than the dynamic Ruby variant), you can think of this as a [class diagram in UML](http://en.wikipedia.org/wiki/Class_diagram): `struct`/`enum` represent the section with your instance variables, `impl`s are the section below that with the methods. Traits are a bit like interfaces. (I can't think of anything analogous to inheritance except maybe traits with default method implementations.)
Could you copy the full output of `cargo test --verbose` and `cargo build --verbose`? Maybe there is a Cargo bug where it needs to pass some more flags to `rustdoc --test`.
I think it is connected to this issue https://github.com/rust-lang/cargo/issues/1622 `cargo test`: https://gist.github.com/anonymous/edbe319fc1b7c2e3e64e
There's TCO but it actually needs to be a tail call (which means no destructors!). It's just not guaranteed right now, we leave it up to LLVM to do TCO (or, rather, the more general sibling-call optimization) for us.
I doubt there would be much of a perf win since doing a call through an FnOnce is just a pointer offset + virtual call - you'd save only the pointer offset by just storing an `fn` pointer.
Thanks for posting! I learned a lot from this paper.
What I've found helps is going back to basics. Start with your problem, then figure out a high-level solution, then try to apply the tools Rust gives you to that solution. By high-level, I mean really high-level. Think about the general aspects, what data do you need (in abstract terms, like "position" or "date")? How do you process it (again, in abstract terms like "people within some distance of a position")? Once you have clear picture of that in mind, you can start thinking about representation and algorithms. It's often all too easy to get caught up thinking about APIs and inheritance heirarchies and lose sight of the problem you're solving. If you find yourself struggling, take a step back and look at the problem again. 
Well, given that they wrote it on play, they can't use external crates...
It biases LLVM's heuristic towards inlining it without forcing it to.
Maybe this shouldn't be marked as 'for new users only' (as your title says), but just a general Ask Anything thread. 
Thanks for the answer. I still don't get it, is not up to the one implementing the trait to specify what implements the Iterator and not the caller? Either way, I'm lost. Tried to play with the concept and failed to produce a working code. [I filled a question in the other post to not pollute this one](https://www.reddit.com/r/rust/comments/37cryf/hey_new_rust_users_got_an_easy_question_ask_it/crlvqfb)
Would something like [this](https://github.com/TeXitoi/rust-mdo) be helpful?
&gt; I can't think of anything analogous to inheritance except maybe traits with default method implementations. Actually, I've found that implementing `Deref/DerefMut` is somewhat analogous to singular inheritance, especially how it appears in generated documentation now. Academically, it's probably a completely different concept, but in practice it's not a bad substitute. It's one of the core design elements of [KISS-UI's][kiss-ui] API, in that every widget type can be dereferenced to `BaseWidget`, which has all the common widget subroutines. [kiss-ui]: https://github.com/cybergeek94/kiss-ui/
I think that would count as "stable, but architecture-dependent." For the same chip, new and old compilers will get along.
&gt; You could specialize the given function on a type that is incompatible with Map What do you mean by this? The Map is only used in that implementation of the MyTrait. I was think that it would be possible to have several implementations each one having different Iterators. I continued playing with it, and [was able to reach a valid code](http://is.gd/fd6vM2). But it has the same problem as the original solution. The ideal would be to automatically infer the V type . Is this what /u/DroidLogician means by Abstract Data Types?
Trait objects are abstract data types. Maybe you meant *anonymized* return types?
The problem with your original code is that any type parameter on a function is an *input type*, even in the return type of the function signature. This behavior is easier to see with [`Iterator::collect()`][collect] (click for documentation and example). The bound on the type-parameter there is that the type `B` must implement `FromIterator`, but the type is inferred from the *calling context*. The *user* of that API is telling the function what type to use, `Vec` in this case, and the function's only requirement is that the type implements *FromIterator*. You're trying to do almost the opposite, you want to say, "I am returning a type that implements `Iterator`, but I can't say what it is exactly". This is because `Map` contains a closure, and closures don't have a user-exposed type (it's put together by the compiler). You managed to work around it in your new example because you used function pointers instead of closures, which are a single, unified type, like `i32` or `&amp;str`. They don't need to be parameterized. This sure works for your example, but as you might have noticed already, it's quite limiting, because it can only use vanilla functions. You can get around the closure type issue by using type erasure with `Box`, e.g. `fn do_something&lt;T&gt;(self) -&gt; Box&lt;Iterator&gt;` This makes the returned `Iterator` a *trait object*. Its exact size and type doesn't matter, because the return value contains all the information need to invoke the iterator's methods at runtime. This is called *dynamic dispatch*. The issue here is that you take a performance hit by doing this. You're discarding a lot of information about the type at compile time which could be used for optimization, *and* you're using a heap allocation, which is hard on the CPU cache and requires runtime management. This makes this somewhat of an anti-pattern in Rust. We prefer static dispatch and stack allocation where possible, because both are often *much* faster. Closures used to *only* work this way. Some of the more tenured Rustaceans still say "unboxed closures", because closures used to *all* be boxed, requiring heap allocations and dynamic dispatch. Then some very smart people came along and made them what they are today: stack-allocated and statically dispatched. But there's a catch: they only exist as anonymous types that implement certain traits. So trait objects are still necessary when you want to unify all closures with the same signature under one type. Abstract ~~data~~ return types would fix this. A previous RFC proposed a syntax like this: `fn do_something&lt;T&gt;(self) -&gt; impl Iterator` Here, the return type says, "I am returning a type that implements `Iterator`, and whose size and methods are computable at compile time, but I don't have its exact type name (maybe because it contains closures). Still, it's safe to allocate on the stack and can be statically dispatched." It'd be a *huge* ergonomics win for any API that makes heavy use of closures, like yours, since it doesn't necessitate using trait objects in return types. [collect]: http://doc.rust-lang.org/stable/std/iter/trait.Iterator.html#method.collect 
I've been really intrigued by Rust since I first heard about it. But I've heard a lot about it being "unstable" and changing a lot from version to version. How true is this now that it's at version 1? Side note - I think it's a shame Rust uses the `{ ; }` style. I wish more languages would embrace Haskell/Python style code blocks through indentation. 
[The RFC][rfc] uses "abstract return types", so that's probably what I meant. I swear, this friggin' community and their affection for confusingly similar phrases... [rfc]: https://github.com/rust-lang/rfcs/pull/105
&gt; To bad that it is worst. I mean, it's not *ideal*, but it's not *horrible*, either. You see it in the Rust compiler, occasionally, and it's also used by the threading API for moving closures to other contexts. It's just encouraged that you find a way around it if you can. But if using a trait object seems like the better approach to you, and you're willing to take the performance hit, no one will judge you for it. It's a *feature* of the language, not a concession.
[I also have an issue open for features to implement.](https://github.com/cybergeek94/kiss-ui/issues/15) IUP's API still has a lot of surface area that I haven't covered yet, and it's hard to figure out what to do next.
ARMHF and EABI are different ABI for the same architecture, so it's not that simple.
Is there anything you could tell me so I can try to fix it? :)
Very true, but you can call them more than once. :)
Very true. I was assuming non-blocking sockets for some reason, even though your code is set up for blocking sockets. I guess my question is, in what environment would this scheme be able to handle sigint correctly? We are working to handle exactly this issue in Mio, but that uses non-blocking sockets. 
I haven't looked at the C++ version; had to go to bed. :) As for `group_by`; I believe that was an artifact of me going through the crate source, deriving every trait I thought was applicable, then realising that `Clone` didn't make sense for that particular type. I don't think you can explicitly *forbid* a trait, though... I suppose it wouldn't be a bad idea to distinguish "this shouldn't be implemented" from "I totally forgot about this whoopslol".
We could have a *new* sticky thread where instead of answering questions, we merely tell people how hard they would be to answer, and where they should ask them.
There appears to be a link or footnote or something which isn't being processed correctly: &gt; only usable with a nightly compiler behind the `optin_builtin_traits` feature[\^opt-out].
Yeah, a lifetime bound `'a` on a type means that the type *can* live at least as long as `'a`, it doesn't meant that the values necessarily do. E.g. the `i32` type is `'static` because there's no restriction on how long you can hold it for.
&gt;Its basically just "enable the ability to inline this cross crate" Does this need both `-lto` *and* the `#[inline]` to work, or is it "and/or"?
Follow-up-follow-up: `v0.10.0` landed in `master` this evening and is now on crates.io. Let me know if you have any issues getting it to run on the stable channel.
[Issue](https://github.com/Manishearth/rust-clippy/issues/72) filed at [rust-clippy](https://github.com/Manishearth/rust-clippy).
No, `#[inline]` does not require LTO. LTO further enables LLVM to inline every function, including those not marked explicitly.
I have not had issues with the reconnect branch but I'm not stretching its legs yet, just reading off a queue on ActiveMQ. I'll switch over soon. Thank you! Makes me even more excited to use Rust! 
If you are really concerned about the runtime hash map insertion, there's always https://github.com/sfackler/rust-phf :) (although, depending on the number of language extensions I wouldn't be shocked to see linear scan or binary search do better in practice than either).
Oh, well that's slightly too strong a statement since it requires writing unsafe code to break the Send/Sync guarantees. Rather, it would be difficult to reason about creating safe boundaries for unsafe code if there were arbitrary unsafe default traits in the wild.
I am aware that there might be better c++ designs in the first place. But I specifically chose a "pointy" design for the purpose of learning Rust, this is not a production thing. With that said, your proposal is not always right and it depends on the game requirements. It would be indeed a duplication if there's only one player. But what if there are 20 players? Or what if we swap "PowerUp" with a "Homing Missile"? Surely each Missile/Powerup requires its own Player pointer in that case. Thanks for pointing this out, I'll edit my answer and explicitly state that I don't want a change in design because it's about learning rust, even though better designs might exist.
Interesting. That would work well if the PowerUp's target is a permanent player. How would you adapt that to a target-changing Object? Consider a Homing Missile, just like a powerup, it targets a specific player. But it may decide to change target at any given time. In c++ (Assuming players always outlive missiles), The missile would have a pointer to a player. If it decides to change the target player, it simply modifies that pointer. In your solution, a player "owns" the missile, and when the missile changes target, the player must pass the ownership of that missile to another player. This sounds like too much tight coupling between the player and the missile to me. I'm a rust newbie, so I may be way off course. Feel free to correct me.
&gt; pwup.tick(player) Why is it not "&amp;player"?
You can probably pass the flags to LLVM using `-C` when invoking `rustc`. Don't know whether `cargo` supports it though.
A fairly trivial matter, but: &gt; Like C, an binary exits once the main thread is finished, so I’ve inserted a sleep to (usually) ensure that the child thread is spawned and prints before the main thread dies. From https://doc.rust-lang.org/std/thread/ use std::thread; let child = thread::spawn(move || { // some work here }); // some work here let res = child.join(); "join" blocks the caller until the joined thread exits (and hence, in your example, lets the thread complete before exiting main). There are also "join guards" a little after that section, which implement an RAII like behavior to joining.
Oh, whoops! I forgot about `join`. I don't want to switch to it because it'll complicate the example at the end and the uniformity is nice, but I'll note it. Thanks! (Those RAII join guards have... [problems](https://github.com/rust-lang/rust/issues/24292), and are currently unstable.)
 match (..., &amp;mut self.player) { ... (..., ref mut player) =&gt; { pwup.tick(player) }, }; The binding `ref mut player` in the left hand side of the `match` takes a `&amp;mut` of the variable being matched. Hence, it binds the name `player` to a variable of type `&amp;mut &amp;mut Player`. You can check it out by making the compiler fail: (&amp;mut Some(ref mut pwup), ref mut player) =&gt; { let _: () = player; pwup.tick(player) }, This gives: &lt;anon&gt;:38:72: 38:78 error: mismatched types: expected `()`, found `&amp;mut &amp;mut Player` Finally, an [auto-deref](http://stackoverflow.com/questions/28519997/what-are-rusts-exact-auto-dereferencing-rules) takes place to call the method on `&amp;mut Player` instead of `&amp;mut &amp;mut Player`.
If you can't achieve what you want with borrows, or if it brings you to a special amount of pain, you could go for `Rc` which is Rust's equivalent for C++'s `std::shared_ptr`. However in #2 you say there's logically one owner, the World, hence I believe the reference/borrowing options should work as far as this constraint is satisified. In my opinion you should be able to go very far if every call comes up from the World and descends logically though the game hierarchy; it should be possible to achieve that with borrows only.
Also, please refrain from using raw pointers in complex situations like this. In Rust raw pointers are frowned upon *unless* you as a human can *guarantee* you're writing behaved code. If you use raw pointers just because you don't really know what you're doing anymore and you just want it to compile, you're going for hard times, because you break Rust's safety as a whole, not only in your `unsafe {}` blocks. An example of how raw pointers are intended to be used is [the implementation of `Vec`](http://doc.rust-lang.org/nightly/src/collections/vec.rs.html#156-160). It is a minimal unsafe behaviour well-wrapped into a correct interface, whose implementation holds expected invariants. TL;DR: keep unsafe code minimal and well-wrapped.
Oh, I didn't know about that. Good to know.
Some designs will simply not translate to Rust. It is true that C++ allows a richer family of designs; but Rust is partially opinionated---the designs it disallows are considered not as good as the ones it does. More than lifetimes, this is a consequence of the single writer mutability constraints. You simply cannot have a general graph of nodes where each one mutates every other without unsafe code or a cost in performance (RefCell). In my opinion that design is asking for trouble anyway, leading to horrible spaghetti code (and use after free segfaults). You may disagree and it is true that that particular design is not supported by Rust. PS: In my experience [many C++ engines](http://bitsquid.blogspot.co.uk/2011/01/managing-coupling.html) (see section 4) end up having large vectors of PODs, with tagged ID-s instead of pointers; partly for cache locality, partly to avoid precisely the problems that I mentioned above.
The RFC is confusing and I disagree with the name choice there.
&gt; What do you mean by "simple name"? Not fully qualified. Like `Chain` instead of `std::iter::Chain`. &gt; Also, a where statement only helps with generic parameters. Oh, right. Damn, my Rust is getting rusty :(
It could change the player health on contact.
Thanks!
LLVM inlining heuristics are, in my experience, pretty flawed (inlining is a really really hard problem!). There is a list comprehensions range-v3 C++ example that was 15x slower with clang than with gcc because LLVM inliner screwed up. Tweaking the inlining threshold of LLVM (`-mllvm -inline-threshold=50000`) was able to achieve "only" a 2x slowdown with respect to gcc. That is a 7x slowdown just from inlining. Checking the assembly to see if code is being inlined properly is one of the things I do when profiling. After 30 years of trying to solve the "inlining problem" for C++ code, it is pretty clear to me that I won't see a compiler with perfect inlining before I die. Link: http://www.reddit.com/r/cpp/comments/24663s/range_comprehensions/ch46dye
That isn't the intent. It should immediately go back into a loop waiting for new incoming connections from any of the ports which it is observing.
Whew, that's quite a bit of code. I see you are using the original Kev evaluation code and not the pefect-hash one. Any reason for that? When I tried to port the perfect-hash approach, I realized it relies heavily on arithmetical overflows and was trying to access arrays out-of-bounds every once in a while. Not sure if the issue was on my side. I'll give it a closer read when I get the time, thanks for the link! I love poker hand evaluation stuff for some reason.
Just making sure I got the idea: #4: Instead of storing a raw pointer in PowerUp, store a player ID. And borrow a player pointer each tick.
In my experience: - if you don't care about binary reproducibility of FP precision, enable them (it costs nothing) - if you do care about binary reproducibility of FP precision: - either do not enable them, or - enable them, and if you get a speedup that is worth it, figure out the reordering the compiler is doing, and transfer it back to your code, then you can disable them and get the speed up. FP arithmetic is not associative and the compiler respects the IEEE FP rules by default. It cannot reorder operations, eliminate no ops, ... Are these transformations important? Depends. From no impact at all to huge impact: for numerically intensive code, and due to enabling other optimizations (e.g. inlining, vectorization, ...). IMO rustc should have a -Ofast that enables these.
In this case the cost is negligible. Instead of a clamp per pixel it is 4 clamps per pixel. Comparing that to the cost of shading and traversing N paths with each X bounces, the total impact is probably impossible to measure
&gt; This needs a better image-generating function. Suggestions and/or PRs are very welcome. How about x xor y, it generates a pretty checker pattern like [this](http://i.imgur.com/ZN9SUqF.png).
Yes. You'll still need the right ownership semantics around borrowing the player 'store' (i.e. the big Vec with players in it), but it should be relatively easy. When I say tagged ids, I mean the trick described in the bitsquid post I linked allowing you to detect stale id-s. See [this series](http://bitsquid.blogspot.co.uk/2014/08/building-data-oriented-entity-system.html) for a really good explanation for how to build a system like this.
Thanks, it looks useful. Btw, this is still overkill when you're SURE the players will outlive things and there's no need for stale-checking.
I've now received and merged a patch request that should fix this.
I guess. If you think players don't die. In my view a homing missile (one of your other examples) should not keep tracking a dead player after respawning
600 levels sounds very high for a path tracer. You should look into "Russian Roulette" for deciding whether to go on or to abort. Russian Roulette makes such high recursion levels extremely improbable while still being an unbiased method. The basic principle is something like this: fn radiance(...) -&gt; Vec3d { if rng.gen::&lt;f64&gt;() &lt; 0.123 { return Vec3d::zero() } // abort early let r = { ...compute your radiance like before... }; r * (1.0f64 / (1.0f64 - 0.123)) // compensate for "early abortion" } You may want to adjust the probabilities. For example, select higher abortion probabilities if the expected radiance is low. This would be a form of importance sampling that should reduce time and/or the noise level. Anyhow, the image looks great! It's 4096 samples per pixel, right? If you're interested in further reducing the noise level, try to incorporate more importance sampling.
Though to be clear, I agree it's overkill in many cases!
What? That defeats the purpose of auto completion at all, this is NOT "auto"! Also, Racer doesn't give me options when I write "let a: " and hit CTRL+Space, only &gt; BUG, FIXME, forint, headerbar This plugin is crap.
Yeah. So, there is no "don't check because we're sure they're still there" design in Rust?
Why doesn't `Path` just implements the `Display` trait by itself?
Maybe there is a way to auto-enable it, but if there is, I haven't found it. Granted, racer does not do much at the time (or is it rustDT? I wouldn't know) but keep in mind both are young projects. From what I've tried (only in eclipse though), autocompletion seems to work ok with method/binding names, and that's about it.
Don't be a douche. You're probably doing something wrong because you are the first to complain about this(AFAIK). By being rude you're only decreasing your chances of receiving help.
This is not a problem with racer, this is just not implemented *yet* in rustDT. [Relevant issue](https://github.com/RustDT/RustDT/issues/23)
I thought this was a little weird: &gt;What's the downside? You can't do "föo"[1] and expect 'ö' to come back. But that's not a good idea anyways. Why wouldn't it be? Isn't that one of the most fundamental things that a string object should do for you? I mean, I really ought to be able to ask a string, "what's your second character?" and get the correct answer, no? 
Cool! Thanks! I was considering if maybe this was a good idea for a small project I'm making (actually in Python, not Rust) which converts language from a Japanese phonetic script into Latin characters, and I ended up custom coding a finite state machine. Basically you've got characters like アウエ and the output should be "AUE". Except that some characters modify the characters behind it, some modify the characters in front of it. I'm still not 100% sure if my particular use case is good for a LALR or GLR parser but my approach seems to be working and efficient so I'm happy anyway. :) If it's worth using a parser generator, I might work on one for this use case as an exercise.
Neat! Are you starting from scratch, or are you studying the (neo)vim sources and trying to do a port?
It does not seem to be implemented. There is no corresponding LLVM flag, see `rustc --help` and `rustc dummy.rs -C llvm-args=-help`.
Because converting a `Path` to a utf-8 string may fail. It is a safeguard, you have to call `display` explicitly.
When introducing OIBIT I don't understand the benefit of: enum Good { A, B } What are A and B? Assuming they both provide explicit implementations of Trait, I still don't get why this is good. I see it as: enum EnumImplementsTrait {A, B}; (Ok, it's good in that Good impls Trait - I just feel like I'm missing something when I read the word 'Good') also: why is "struct Excellent" excellent? I'm not seeing how 'Trait' is involved at all. Likely the rustc compiler in my brain needs improving...? Same line of thought about names: I think I'm missing something when you use 'Wonderful' so... struct StructImplementsTrait {x: u8, y: String}; Just my 2 cents... 
Good question! I had to look this up myself in the source code. `path::Display` implements `fmt::Display` via `thepath.to_string_lossy()`. I guess the idea is to avoid bad surprizes in case of some conversion loss. But the name `display` doesn't really convey this. Perhaps it should have been `display_lossy` instead. As for why offer `display` at all when there is `to_string_lossy`: I'm not sure. Perhaps there is some optimization potential. I think with `path::Display` it's possible to save the overhead of `to_string_lossy` possibly creating a temporary `String`.
Because I had no auto completion in Racer when it was advertised as an auto completion tool. Then Microbzz told me it doesn't work as an auto completer so I wondered why it was advertised a such. Then Microbzz specified the problem, linking to a bug tracker from RustDT which showed that RustDT doesn't have the feature to auto complete even if Racer would support it (the Racer site says you need to press keys to "auto" complete even in VIM and Emacs so I'm not sure if Racer supports auto completion at all). You would know that if you would have read the thread. But you didn't and that's the reason you asked this redundant question.
But there's no safeguard, `Path::display` just returns a `Display` which formats itself by using `Path::to_string_lossy`. There would be only some kind of safeguard if `Path::display` would return an `Option/Result`.
I think the use case for unsafe default traits outside of things that require `unsafe`code to break them is fairly limited, since the only way they make sense is if the properties they are attempting to preserve already exist in "transitively safe" Rust. So I don't think this will be a problem in practice. OTOH, I have already seen unsafe traits used in plenty of user libraries for very sensible reasons, and none of them are defaulted.
iirc `-ffast-math` has more impact on old school x87, where it allows intermediate results to stay in the x87's 80-bit internal representation. That can make things faster *and* more accurate. On modern x86 chips you usually use SSE for floating point (it's part of the x86-64 spec, iirc) and the effects of `-ffast-math` will depend on whether it enables optimizations like you described. 
First this is a UX problem. If autocomplete automatically completed stuff when it had a match, it would be a complete disaster. Such autocomplete happened to me in SublimeText by accident and they are infuriating. Assume I have methods called `string()`, `stringB()`, `stringBen()`, etc. and I want to type in `stringBen`. I start typing `string` and the autocomplete hijacks my control and finishes `string()` itself. Now I have to type i Second this is how Eclipse and most modern IDE implement autocomplete behavior. It's not the fault of Racer. You can raise the bug with them, but you'll be fighting against the grain. For UX problems listed above.
IMO, what could fix this is if ideas about `unsafe` fields (fields where accessing them, even from within the same module, can cause memory unsafety, hence require an `unsafe` block to access) are added to the language, and you could arrange it so that types with `unsafe` fields automatically opt out of `unsafe` traits. I believe this would capture *all* instances of opting out that aren't already caught, and it would be extensible to new `unsafe` traits. I think this is a good compromise and it is also (to my knowledge) the second thing that `unsafe` fields add over just having a private field (the first being to avoid the "`value` in `UnsafeCell`" situation, which is also resolvable in other ways). The only thing I can think of *at all* that would violate this is `unsafe` access to global / hardware data, which is resolvable as follows: have something like an `unsafe PhantomData` field for accessing globals in unsafe ways (indicating `unsafe` access to a value of that type). But realistically such access must always be highly conditional anyway in order to be safe and is unlikely to be wrappable in a safe interior in ways that could conceivably violate `unsafe trait` guarantees other than those that already exist (that is, I doubt there are a lot of remaining incredibly fundamental abstractions like thread safety).
&gt; If the thing you want is encodable by a finite-state machine then its not really a problem you solve with context free grammars, is it? Yeah, I wasn't entirely sure about the relative complexity of these solutions. It's hard for me to wrap my mind around this stuff, but it's starting to become more clear! A series of regexes was my initial idea, but it became clear pretty quickly that it wouldn't work. Or it would work but it'd be very inefficient.
Regular expressions can be very efficient if you implement them using finite state machines with no backtracking (so none of the fancy stuff you see in Perl regexes). They cover this kind of thing in university Automata courses. A more approachable explanation I like to recommend to people are these articles from the author of the re2 library that powered the Google code search. https://swtch.com/~rsc/regexp/regexp1.html https://swtch.com/~rsc/regexp/regexp2.html https://swtch.com/~rsc/regexp/regexp3.html
Very nice! I haven't looked very deeply at it, but it looks really good! There are some small bike-shedding things you could change like using `.to_owned()` instead of `.to_string()` in order to avoid having those strings being put through the formatting pipeline (small performance hit), or using `match` statements in a few places you have several a few `if-else`'s, or using an `enum` or perhaps `trait` for the `Language`. But like I said, that's all probably just bike-shedding. :) And of course I have to plug [clap](https://github.com/kbknapp/clap-rs) (or really any of the other argument parsers like [docopt](https://github.com/docopt/docopt.rs)) which can remove some of the boiler plate and make adding new argument/features a little easier down the road.
&gt; I mean, I really ought to be able to ask a string, "what's your second character?" and get the correct answer, no? That's not how text processing works. That would only work if you perform certain unicode normalization and only in certain languages. The better question is why you ask that question in the first place. Usually people do not get the second *character* in a string, they want to solve a specific problem. There is not really a problem that is “get the second character in a string”. If that is a problem, then it's badly defined because I could ask a dozen questions to narrow down what you actually want.
&gt; That said, if you try to autocomplete and it gives you a FIXME, that's broken for sure. Have you filed an issue? I don't have a Github account and the test in the cmd works just fine like shown on the Racer website. When I try this in Eclipse I get the list after &gt; std::io::B like it's supposed. It seems that Racer doesn't have full competion support and can only complete certain things, but not everything from Rust 1.0. &gt; std:: works &gt; let a: doesn't work. 
&gt;&gt; What's the downside? You can't do "föo"[1] and expect 'ö' to come back. But that's not a good idea anyways. &gt; Why wouldn't it be? Isn't that one of the most fundamental things that a string object should do for you? Because Unicode is hard. e.g. even in python you can get weirdness. &gt;&gt;&gt; print s1 föo &gt;&gt;&gt; print s2 föo &gt;&gt;&gt; print s1[1] ö &gt;&gt;&gt; print s2[1] o s1 and s2 look the same, but they aren't really. One has a o-umlaut as the 2nd char, the other just has a o. 
&gt;However this is for a good reason and that is that Rust has anonymous functions, closures and lots of chaining that Python cannot support well. These features are much easier to understand and write in a non indentation based language. That's a questionable assertion, considering ~~Standard ML,~~ Ocaml, F# and Haskell all have rich, indentation-based syntaxes.
&gt; That's a questionable assertion I don't think it is. All quoted languages do not have good syntax for the quoted features (one of them is not even indentation based in itself). However in Rust there are more reasons not do use pure indentation: you need the ability of starting and ending scopes at any point to work with the borrow checker. This requires delimiters.
Great! Feel free to contact me with feature requests or issues you encounter.
I meant "safeguard" in the sense that you have to call `display` consciously instead of just printing it. If you know about `display`, you know it is lossy. If you could just print it, you might assume it is not lossy (I know I would).
Not necessarily. It only does automatical auto-complete when you're in a type e.g. `StringBuffer.`. Outside, without CTRL+space it won't start finding names of variables and other parts. Any case, you're ire is misdirected, I think Racer works fine, but not necessarily the Eclipse IDE plugin which is calling Racer.
&gt; you could arrange it so that types with `unsafe` fields automatically opt out of `unsafe trait`s I'd actually prefer if this happened even for types with "merely" private fields, and for all defaulted traits not just `unsafe` ones, but that ship's sailed. If we also have some kind of rule that if your type does particular kinds of funny `unsafe` things behind the scenes then it *must* declare `unsafe` fields, then I guess this might work. (But we can't really require people using earlier versions of the language, where they didn't yet exist, to use `unsafe` fields...? If code written for older versions of the language without `unsafe` fields can't *safely* interoperate with code written for newer versions where we have stabilized defaulted `unsafe trait`s, isn't that essentially a backwards compatibility break?)
 for i in xrange(35): thread = Thread(target=thread_prog, args=(mutex, results, i)) | So what we do here is spawn 20 threads You must have changed the code while writing, or am I missing something obvious?
It's only a backwards compatibility break if this actually breaks anything in practice (the Linux approach). Remember that the case we are talking about is already a very, very tiny fraction of all usecases (opting out of an `unsafe` trait where the approach of opting out of types like `*const`, `*mut` and `UnsafeCell` isn't conservative enough). &gt; I'd actually prefer if this happened even for types with "merely" private fields, and for all defaulted traits not just unsafe ones, but that ship's sailed. This would be hugely unacceptable from a language ergonomics point of view and I doubt you really want this in the language unless you just don't want default traits (which is also, IMO, a pretty bad tradeoff, particularly for the standard library traits).
&gt; F# and Ocaml both have the pipeline operator |&gt; for chaining calls, which is an absolute breath of fresh air compared to OO method chaining. I guess there are different opinions on this. I find that syntax very frustrating. &gt; I'm curious which language you're saying isn't indentation-based. Haskell. It's a language with braces :)
It's all from scratch. When it's possible I simply look at how vim behaves then I set out to mimic that behaviour.
Sure, you can accommodate that in Python style syntax though: fn foo(): let x = 3 scope: let y = 4
Haskell's whitespace handling is a little *too* rich. When the parser encounters a parse error, it's sometimes required to reinterpret the whitespace and try again. This means you can't desugar whitespace into braces without parsing a full AST.
You can't put an `UnsafeCell` in `Arc` because of `impl&lt;T&gt; !Sync for UnsafeCell&lt;T&gt;`. `Arc` requires its contained type to be `Send + Sync`. You need to wrap the `UnsafeCell` first in a struct that manually implements `Sync`.
&gt; The question is ill formed from the codeless code i learned that this response is simply [“wú”/“mu”](http://en.wikipedia.org/wiki/Mu_%28negative%29#.22Unasking.22_the_question) in chinese/japanese …and from that wiki site i learned that the codeless code itself is a reference to [the gateless gate](http://en.wikipedia.org/wiki/The_Gateless_Gate) /edit: and that Mu is the [root of the type hierarchy in Perl 6](http://doc.perl6.org/type/Mu): &gt; what does “Any” inherit from? # &gt; The question is ill-formed.
Eh... Those are more extremely functional languages that don't have the more traditional "list of statements" model for functions.
Wouldn't a division of an utf-8 string to glyphs depend on a particular font being used?
You're right, my bad.
&gt;Wouldn't a division of an utf-8 string to glyphs depend on a particular font being used? No. A font is just a declaration of how your text is going to look. But a Unicode glyph (e.g. small letter a) is the same whether you display it or not.
&gt; A 1.0 stable release after nearly a decade of work Sometimes I forget these things.
Maybe x ^ y for red, (x+2) ^ (y+1) for green, and (x+4) ^ (y+2) for blue?
I'm using positive words for types that implement the trait, and negative ones for types that don't. &gt; What are A and B? They're just two variants, e.g. it's an enum with the same shape/same basic functionality as, say: enum Shape { Square, Triangle }
How about introducing a scope just by increasing the indentation level? e.g., let mutex = Mutex::new(...) let guard = mutex.lock().unwrap() println!("{}", *guard) // The scope goes out here This... sounds... both crazy and fun.
I've been using https://github.com/carllerche/pool which looks like it's the same thing.
You're welcome. :) Thank you for writing the post. (You may have forgotten after all the commits, but I'm still learning this stuff!)
I'm not sure calling `Box&lt;T&gt;` an "owned pointer" is helpful. Everything has an owner in Rust. I feel it is more an encapsulated non-stack memory resource. Kind of a `Vec&lt;T&gt;` only with a single value. Edit: I should note that you do allude to this fact later in the `Copy` section. I just feel it can confuse people with regard to the universality of unique ownership in Rust. Edit 2: The article itself is excellent, of course :)
I like that.
CoffeeScript has excellent support for all of these and is indentation based.
The channels in the standard library are multi-producer, single consumer, so it would seem that 'seen by everyone else' is fundamentally different here. I'm not familliar with `hassle`.
&gt; Everything has an owner in Rust. This is why we changed from 'owned pointer' to 'box' officially, for sure.
Well, crud. Dunno how I missed that. At least I got some educational value out of the process.
good job
Got it! You were right, I was taking a `&amp;mut` even though I was using `RefCell`. I've replaced `Rc` with `&amp;` in the `shared_ref` branch of the repo. This was a pretty nice speedup in the benchmarks! **Before:** test tests::bench01_standard_allocation_speed ... bench: 802110 ns/iter (+/- 25479) test tests::bench02_pooled_allocation_speed ... bench: 491332 ns/iter (+/- 15832) test tests::bench03_standard_initialized_allocation_speed ... bench: 1209248 ns/iter (+/- 30184) test tests::bench04_pooled_initialized_allocation_speed ... bench: 794782 ns/iter (+/- 29040) test tests::bench05_allocate_vec_vec_str ... bench: 650227 ns/iter (+/- 23282) test tests::bench06_pooled_vec_vec_str ... bench: 371798 ns/iter (+/- 14771) **After:** test tests::bench01_standard_allocation_speed ... bench: 851420 ns/iter (+/- 84011) test tests::bench02_pooled_allocation_speed ... bench: 363401 ns/iter (+/- 30065) test tests::bench03_standard_initialized_allocation_speed ... bench: 1205603 ns/iter (+/- 55400) test tests::bench04_pooled_initialized_allocation_speed ... bench: 643619 ns/iter (+/- 115773) test tests::bench05_allocate_vec_vec_str ... bench: 658596 ns/iter (+/- 24405) test tests::bench06_pooled_vec_vec_str ... bench: 331287 ns/iter (+/- 24732) Very interesting. I'm going to toy with this a bit more, but it's promising, thanks!
Unicode is really, *really* hard. Does Rust make it any easier? Can I iterate a string by graphemes? Does it provide decomposing normalisation?
It looks like she blogged about what DevOps means on her blog: http://edunham.net/2015/05/20/open_infrastructure.html
Awesome! Thanks for the tip!
[rusti](https://github.com/murarth/rusti) seems to be the current inofficial REPL for Rust. It has some rough edges, but could be a good starting point. Apart from that, the docs are really quite helpful. Oh, and Rust programs should be debuggable with gdb or lldb.
You're welcome. Thanks for sharing your experience.
Rust attempts to make costs explicit where possible. Closures and functions have different costs. Also, closures do type inference, whereas functions do not.
&gt;In my opinion, the most useful meaning of “DevOps” is to describe to the paradigm in which infrastructure is code. In this sense, the operations team are necessarily developers, since their main goal is to write code which describes the tasks that they would have had to do manually in the olden days. So basically deployment and configuration stuff? Is that not just scripting? edit: Looking at the downvotes I guess I struck a nerve, but thanks to the replies I sort of am beginning to see what dev ops is so thanks. Before this my main interaction with (and introduction to) dev ops was this site.... http://devopsreactions.tumblr.com/
Awesome, admittedly I was not thinking ecosystem but just rustc so that makes sense.
I wish we had a "type" we could put instead of `()` that would make rustc say: "Oh, the programmer is asking what type this expression is. I should just say that without complaining about mismatched types."
Ö is a single character.
You could just use `rusti` and use `.t my_object` instead.
[This one looks pretty damn cool!](http://i.imgur.com/aCF1Ej1.png) I think it's the best of these suggestions.
I do the DevOps stuff (among others) in my daily job, and DevOps *do* require programming---when the existing tool does not suffice the needs DevOps engineers are responsible for making or adjusting the tool. (Hint: This happens a lot. Also whole axes of trade-offs apply.)
Yeah, considering the eye-hurtiness it might have not been the best suggestion. Another possibility is to use ^ for red, &amp; for green and | for blue, which should give some sort of interesting gradient effect.
Awesome, that's a good start. Thanks! Some of these are kind of funny. Did `log` used to be some kind of built in? lol
rusti seems to be my best bet atm. but I had a little trouble getting it installed. Together with racer for auto-completion it requires the current nightly build. I got it all working now using this: https://gist.github.com/mbarkhau/236e9d08bc33e09fb7f3
Yes and no. You could reduce everything to: so it's just typing on a computer? Deployment and automated management requires a lot of domain specific knowledge. Even stuff like proper packaging and maintaining valid upgrade (and downgrade) paths through the architecture are surprisingly tricky. And the bigger the environment, the more issues cannot be fixed with just telling someone to do that one off thing. So yes, it's "just" scripting things. Things that have to do with what devops people are responsible for and things you don't want your product engineers to be distracted/annoyed with.
I wrote [many2many](https://crates.io/crates/many2many) to solve this problem for an IRC client that I was writing. It is built on top of regular boring channels, and it does this by having a background thread sit in the background and clone messages and send them out to the other receivers. This means that it is pretty heavyweight if you have a ton of separate many2many channels, but one thread for a thousand channels in the same "network" isn't that bad.
Even if it was "just" that sort of stuff, it is still a *really* important part of a software project. Having infrastructure that works smoothly makes everything so much better. Talking about it dismissively just means you miss out on the benefits. ;)
You wouldn't even need the "no semicolon to return" rule because it never type checks when you forget it anyway. There is no instance that I can think of where forgetting or putting an extra semi-colon type checks and doesn't do what you want it to.
Ah makes sense, just trying to learn. So you are a developer with a focus but that focus is helping build the tools for others, but not as an os person or language maker.
I must give credit to Handmade Hero in this case :)
Awesome good to know, anything that makes all our lives better is welcome in my book.
This allows normal devs to focus on the project then? Basically you are sort of like the dev version of IT then?
You could still have example A if you went with Haskell-style syntax. fn foo() { let guard1 = launch(task_a) } { let guard2 = launch(task_b) } //outer scope of the function here println!("{}", stuff) //function ends here
That's great! One thing I've noticed about a lot of the more successful open source projects out there is a lot of good dev infrastructure set up. Dolphin emulator comes to mind as a great example. I've seen a lot of great Rust ecosystem projects pop up, and I'm very glad to see going in to 1.0 that there's a team member dedicated to that stuff.
It's not semantics. Having the flexibility (and knowing about it) allows one to write generic data structures with sharing that are thread-safe when the contents are, while still being usable with thread-unsafe things (with some overhead vs. the optimal non-atomic version of course). (I tried to offer the correction as politely as possible! I'm sorry if you thought it was an attack. :) )
Ah, well, saying "just scripting" is a *very* good way to sound dismissive. I apologise.
*Nearly* pointless then. 
Not as a matter of viewing, but I've been trying to collect little stories of change over the history. It's mostly in my head, but someday, I want to write it down...
Yup, it was
&gt;Cell&lt;T&gt; is a type that provides zero-cost interior mutability, but only for Copy types. Since the compiler knows that all the data owned by the contained value is on the stack, there’s no worry of leaking any data behind references (or worse!) by simply replacing the data. I did not follow the logic here, I spose I need to learn more on cell types, is there a good source for that?
The easiest way to understand `Cell`, IMO is to try to use it. You'll quickly grow to discover what its advantages (numerous!) and limitations are that way. That being said, no, I'm unaware of any specific in-depth source on what `Cell` provides, unfortunately. **Edit:** Here's a link to some stuff I wrote about `Cell` earlier: https://www.reddit.com/r/rust/comments/33smjl/my_failed_attempt_to_build_a_digital_audio/cqopces
I think Cell&lt;T&gt; really warrants a blog post of its own, but I'm not the right person to write it.
iirc to use UnsafeCell you need a signed document from nmatsakis certifying that you are an expert, and that this should not, in fact, be tried at home. You pass it in with -Zi-got-this. Otherwise the compiler just prints out: {'. .' '. .'} { ~ '. _|= __|_ .' ~} { ~ ~ '-._ (___________) _.-'~ ~ } {~ ~ ~ ~.' '. ~ ~ } { ~ ~ ~ / /\ /\ \ ~ ~ } { ~ ~ / __ __ \ ~ ~ } { ~ /\/ -&lt;( o) ( o)&gt;- \/\ ~ ~} { ~ ;( \/ .-. \/ ); ~ } { ~ ~\_ () ^ ( ) ^ () _/ ~ } '-._~ \ (`-._'-'_.-') / ~_.-' '--\ `'._'"'_.'` /--' \ \`-'/ / `\ '-' /' jgs `\ /' '-...-'
Oh dear. I'd better not show anyone the source code for my concurrent hash map implementation, then :(
Concurrent cuckoo hashing, largely a port of the C++ libcuckoo library (in turn based on http://www.cs.princeton.edu/~mfreed/docs/cuckoo-eurosys14.pdf). It's not quite ready for prime time but the performance is pretty awesome (current implementation at https://github.com/pythonesque/libcuckoo.rs/ -- note that in order to read the assembly output better there is a lot of custom stuff to avoid panics [until such time as Rust provides a panic =&gt; abort option], so please be gentle; I'd also like to clean it up lots to replace the "everything is unsafe" nature of the library with some type system based safety assertions, despite your article). Also, `const fn`s just landed, which should enable quite a bit of cleanup :)
Rust explicitly chose not to infer too much because: 1. Functions are the point of API definition and it'd make it too difficult to ensure a stable API for your library. 2. With more type inference, you'd be in C++ "many screenfuls of generic type signature" error hell. 
I think this is the idea behind [typed holes in GHC](https://wiki.haskell.org/GHC/Typed_holes). I agree that it would be pretty great to have in Rust.
There is _one_ gotcha with regards to this: if you are using `collect()`, and you use `let guards: Vec&lt;_&gt; = ` with your call to `spawn`, and you use `;`, they'll operate in sequence, because it will infer to `Vec&lt;()&gt;` rather than `Vec&lt;JoinGuard&gt;`. 
&gt; both are very rare: This is generally a weakness of the docs; rarely used things don't have nearly as good of explanations of things that are common.
I keep thinking rustdoc should generate a page that just lists all trait impls in the crate, and maybe add those to the search index in some way that makes sense
`forget` is typically used in unsafe code to avoid "double free" errors or to avoid dropping non-initialized values. Outside of `unsafe` code, there is no need for `forget` – assuming you don't want to intentionally leak resources (why would you?). And that is why I think it should have kept the `unsafe` marker.
Did the web server go down?
Ugh, why is this even allowed? Sounds like that's an unwelcome source of bugs.
You know, we should start feeding the trespassers to Ferris; get some pincin' practice.
If the purpose of your code is to give a string to a Windows API, you can use the `std::os::windows::ffi::OsStrExt` trait like this: let text = OsStr::new(text).encode_wide().chain(Some(0).into_iter()).collect::&lt;Vec&lt;_&gt;&gt;(); If not, see the other answer. 
wow sorry, first time i try to post on playrust, i make a mistake. My own bad. Shall ive to erase this link?
A difference is that 'pool' has a static size, whereas lifeguard can grow or shrink. 
Just bought a paperback version. Look forward to receiving it.
I wanted to throw up a link to http://doc.rust-lang.org/1.0.0/reference.html#behavior-considered-undefined which was super useful for me when thinking about unsafe. Mostly that I should never use unsafe, because look at all these things that you probably can't get your head around. Whether unsafe proliferates or not, I think it would be great to cut in to this list whenever possible. Some of the items seem like they might be over-broad, or under-detailed ("reading undef can result in UB", presumably because LLVM does that for some undef (fp division by undef, for example), but the whole point (I think) of undef is that it doesn't always lead LLVM to UB).
&gt; you can write your own forget using std + safe code only I know I know. Still, nobody needs such a `forget` function *outside* of `unsafe` code. That's my point. I see no reason for making it *that* easy to leak stuff. The ability to call `forget` in safe code is useless.
Cool!
Nice writeup, you're adressing exactly the problem i struggled with for the last some weeks ;) I think this posting (or a text based on this) would be a nice addition to the book, as (as far as I know) the different pointer types are not covered there and they are spread accros the documentation. So this could be a starting point to motivate these types and their composition.
Why does `Rc` keep track of the number of weak references?
If all your Rcs go out of scope, but your Weaks don't, then you need to hold on to the internal RcBox allocation (which contains the refcounts and data). How else would the Weak realize that the Rc was deallocated? So when all Rcs go out of scope, the contained data is deallocated (I *think*), but the refcounts are not. Once all Weaks go out of scope as well, the whole RcBox is deallocated. To do this you need to keep track.
When I say "safe code" I mean code where `unsafe` isn't being used. Besides, using these has hidden problems. Appeasing the borrow checker isn't so simple; because there are assumptions made by the compiler based on the pointer types. So if I convert an `&amp;T` to a raw pointer (while holding on to a copy of it), and mutate it somehow, I might cause undefined behavior -- LLVM was told that the `&amp;T` won't change, but it did. Same goes for extracting raw pointers out of a `Box` and not using them properly. (IMO you should rarely have Rust pointers and raw pointers pointing to the same thing at the same time -- either use raw pointers only, or use rust pointers only, or convert from owned pointers to raw pointers and back, but never have both alive at once) In general using these to "appease the borrow checker" is bad; you probably want to use a cell type (if you're brave; `UnsafeCell`, but [be sure to get a certificate first](http://www.reddit.com/r/rust/comments/37itqj/unsafe_rust_an_intro_and_open_questions/crnakem)). What you should be using these for is in tiny isolated bits. For example, if you want to create your own linked list, or Vec, or Rc, or lock free concurrent ringbuf. In this case you'll have a couple of raw pointers floating around, and you'll have some invariants you'll maintain, along with runtime checks, that ensure safe access in the few `unsafe` blocks that you'll have.
Ah yes, that makes perfect sense. Thank you.
Thanks! :) A lot of people have mentioned the same -- probably should talk with Steve about where something of this sort could be fit.
OT: Why did you change from ```type dbaupp = huonw```?. I sometimes forget who you are!
I cant comment on this book, hopefully it's good, but in general I'd be very carefully when buying anything published by Pact, see e.g. http://www.reddit.com/r/haskell/comments/1rj2jq/book_haskell_financial_data_modeling_and/
Not if only the syntax was unified.
I don't think it's deceptive, because it's what I usually encounter in most codebases. Your po I in Java I never write for example `org.apache.commons.FileUtils.moveFilesToDir(new java.io.File("/dev/path"), new java.io.File("/dev/path2"))` when you can write `FileUtils.moveFilesToDir(File("dev/path"), File ("dev/path2"))`, even if you use the `FileUtils` and `File` once in all code. It's a token effort to make the thing readable.
Searching for "monotonic hashmap" on Google does not bring much: there seems to be something like "monotonic key" in Wikipedia, but I am unsure whether it works. Do you have some resources to point me toward?
Sorry, I don't. I understand how monotonicity can be exploited for creating efficient concurrent systems. I'm planning on cooking up a design for a hashmap that is monotonic, as a personal exercise. I haven't looked at (and may not) look at prior literature on the matter. Probably should ask Niko directly.
&gt; It shows how to give rid It should be "get rid" afaik :).
While I do get what is trying to be achieved with unsafe in Rust, sometimes I think it goes too far with regard to C# and Modula-3 unsafe, Modula-2 and Oberon SYSTEM, Ada unchecked and system. Basically, in the Rust code I have seen posted every now and then, unsafe seems to be everywhere, in comparison with the above languages.
&gt; I mean, do you know which module IntoIter comes from? If there are multiple ambiguous imports of `IntoIter`, I'd expect to use the qualified name (assuming it's not just some reexport). Otherwise I fully expect the one declared in the top of module with `use ...::IntoIter`. It's similar to the way `java.sql.Time` and `java.util.Time` is resolved in code (the commonly used one is imported, while the other one is fully qualified. Anyway I think our discussion here is moot, what do formatting guidelines for Rust say on this matter? &gt; It'd be like taking a giant pile of smelly garbage and spreading it out across the room on the basis of "well, now the pile is smaller". This analogy is defective, if it is true, why not do the same for `chrono::NaiveDate` , etc. And I still don't get your point? I'm not saying anonymized return types shouldn't happen, I'm just thinking this is going out of its way to make the code look as nasty as it can. `Chain&lt;Map &lt;Map&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;` looks just as nasty as the `std::iter::Chain&lt;std::map::Map...&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;`
&gt; Cell allows shared mutability but not interior references. I was a bit confused by this statement first, because code like this compiles just fine: let b = 5i32; let c = 6i32; let a = Cell::new(&amp;b); a.set(&amp;c); But then I realized that "interior reference" means "a reference to the interior", rather than "the interior is a reference". The latter is possible, the former is not.
Really? Granted, I've just started learning Rust a few weeks ago and I'm currently not working on anything low-level or high-performance, but apart from the examples in the docs or the obvious uses in std I've yet to see an unsafe block, let alone write one.
This response is especially helpful for me. Had been looking into how I would encode strings for UTF-16. Thanks for the tip.
I think this belongs in `std` and should be stabilized. In the meantime, I suggest you copy/paste it into your code: https://github.com/rust-lang/rust/blob/4f66d881a5/src/librustc_unicode/u_str.rs#L520-L561
Ah, I see, thanks
To my newbie ears, this sounds like a minor feature at best. Is a single level of pointer indirection that critical to performance, or what is the draw of this?
Yes, I need this for Windows. I have a follow up question. I believe I will need to get the raw pointer from the Vec&lt;u16&gt; to get the actual NULL terminated wide character string (LPCWSTR). That is: let text: Vec&lt;u16&gt; = OsStr::new(text).encode_wide(). chain(Some(0).into_iter()).collect(); let lp_wstr = text.as_ptr(); //The LPCWSTR Can this conversion from ``&amp;str`` to ``LPCWSTR`` be made implicitly somehow, perhaps by using ``std::convert::Into``? The ergonomics I am looking for is something like this: pub fn some_function(str : LPCWSTR) { } //Call the function some_function("Hello World"); 
The library doesn't support Visual Studio 2015 since it doesn't implement C++ 2003's "two-phase lookup" feature. Clang &gt;= 3.5 works on linux and mac, so you might want to try clang 3.6 window binaries (*). Mingw with gcc 5.1 _might_ work too. [*] http://llvm.org/releases/download.html
Critical for performance on many applications, due to cache effects. If many of the data needed for a computation can be loaded into the CPU cache simultaneously, then traversal of the data will be significantly faster. Bjarne Stroustrup gave an [interesting presentation related to this](https://www.youtube.com/watch?v=YQs6IC-vgmo) a couple years ago.
I mean by the examples that sometimes pop up in blog posts or code repositories. While I like Rust, among many other languages, I don't have a use for it on my daily work.
Here's how I would do it: use std::ffi::OsString; use std::os::windows::ffi::OsStrExt; #[link(name = "user32")] extern "stdcall" { fn MessageBoxW(hwnd: *mut (), message: *const u16, title: *const u16, kind: u32); } struct LPCWSTR { str: Vec&lt;u16&gt; } impl LPCWSTR { fn as_ptr(&amp;self) -&gt; *const u16 { self.str.as_ptr() } } impl&lt;T: Into&lt;OsString&gt;&gt; From&lt;T&gt; for LPCWSTR { fn from(source: T) -&gt; LPCWSTR { LPCWSTR { str: source.into().as_os_str().encode_wide().chain(Some(0).into_iter()).collect::&lt;Vec&lt;_&gt;&gt;() } } } fn message_box&lt;T: Into&lt;LPCWSTR&gt;&gt;(message: T, title: T) { unsafe { MessageBoxW(::std::ptr::null_mut(), message.into().as_ptr(), title.into().as_ptr(), 0) }; } fn main() { message_box("Hello, world!", "Greetings"); }
looks fishy
Why overload the "unsafe" keyword for two different things, i.e. debiting and crediting the status of safety of code? It seems like the second case discussed could be called something else to make the usage clear. "trust"? "ignore"? "turn-blind-eye"?
It's unoptimized yet. One thing to be improved would be to use the type invariant -- the value is always `Some` -- and use something like [debug_assert_unreachable](https://github.com/reem/rust-debug-unreachable) in the None branch of Deref, DerefMut.
Whoa, that's really cool. I wonder if we could auto-generate nice wrappers for many C functions using conversion traits.
Finally!! Does it also work for associated constants?
I don't mean litterall python or bash I just mean &gt; write code which describes the tasks that they would have had to do manually in the olden days. Sounded just like scripting to me, tis all. If I have to do something manually many times I wirte a script.
So its rather big and affects whether or not we will have a useable ecosystem later on, that is a big responsibility. I wish her luck as this is gonna be a huge undertaking with results that may not be apparent for years.
I always found the distinction between scripting and programming to be blurry and possibly nonexistant. Personally.
Active patterns are awesome :3
ah but there is, and it does allocate. Into mainly is used as a wrapper for the `From` trait by the way.
People who are interested in this problem may also be interested in the first set of slides in this PDF, where Derek Dreyer also talks about this problem: http://www.mpi-sws.org/~dreyer/talk.pdf
I've actually put a little bit of effort into this, using libclang. I may need to revisit this idea in the future.
Packt emailed me last year asking me to write a book about the Dart programming language even though I had only started using the language a month before. I really hope this isn't the case here!
Oh you're right about that. Sorry, that's my confusion.
I'll ask someone about cost, I don't remember off the top of my head. And yes, the site will update, and I'll be re-posting here :)
Well, the comment below is factually correct in that LLVM has finer-grained / lower-level semantics than many IRs we might want to generate (eg. you have to manually spell out the x64 ABI calling convention in somewhat excruciating detail, or you have to manually implement unions by some fakery, most of the type system in your frontend is erased during lowering, etc.) but that's not what I meant. What I meant was that LLVM is actually *higher level* than the level of control over codegen you have when you're emitting your own asm or pseudo-asm. In particular you have no control over what gets spilled to the stack, where on the stack it goes, or when (where the various safepoints are). This makes certain things obnoxiously difficult: swapping stacks or other coroutine-ish shenanigans, unwinding, tracing GC, tail calls ... you pretty much have to hand control to LLVM on all these topics. And if their implementation is unsatisfactory, you're SOL. The same is true of its generation of linkage machinery like PLTs and GOTs, more generally the object file symbol tables and, to some extent, DWARF / debuginfo. It has mechanisms you can control, but those have fixed interfaces with inherent limits. So for example, when we bootstrapped off rustboot to LLVM, we *immediately* lost the DWARF based linkage model, our support for tail calls, our (lightweight) unwinder, and our tracing GC. These were all rooted in records we were previously writing to very precise locations in the stack that LLVM simply didn't allow us to do anymore. And IIRC we were limited to a single task for quite a while until we could reconstruct the stack switcher machinery in the LLVM regime. These losses and limitations were survivable, but they were (at the time) a set of frustrating constraints to work within. If you were doing a GC-heavy language presently, you'd still find LLVM quite limiting. This is not to say that LLVM is bad. It's *amazing* and we souldn't have had a chance without it. I am continuously surprised by optimizations that it can accomplish, and thrilled by the rigour, patience and clarity of its design. But it's very much oriented towards optimizing the hell out of a C/C++-flavoured frontend, not the semantics of every exotic language out there.
One way of looking at the history of Rust is that as the type system got more expressive, the language lost lots of features. My go-to example for this is channels: there used to be a keyword to create them, and the compiler checked certain things with regards to their safety. Nowadays, they're just a library. That's true for basically all other safety things that the compiler used to do: they just became expressible in the type system + borrow checker.
&gt; Sounded just like scripting to me, tis all. ... and? (My point is that you're being _very_ condescending, even though you claim not to be.)
The conversion traits open up the API for calling the `message_box` function with `String`, `&amp;str`, and `OsString` which gives consumers of your API greater flexibility in the way they call your code. Also your `to_wchar` function has a few issues with it. The `Vec` stored in `v` is allocated on the stack and is thus dropped when `to_wchar` returns, making the pointer from `v.as_ptr()` now point to invalid memory. This is easily demonstrated with the following playground: https://play.rust-lang.org/?gist=281c85b643d3e11f747d&amp;version=stable **EDIT**: It appears that playground isn't loading the gist right now, which is here: https://gist.github.com/anonymous/281c85b643d3e11f747d
I tried to google that just now, but I can't find anything on it. Just how to "get rid" of hickeys fast, or how to give rid of fleas.
http://www.macmillandictionary.com/thesaurus-category/british/to-get-rid-of-something-or-someone
I [agree](http://www.reddit.com/r/rust/comments/2zoesz/just_out_of_curiosity_how_come_unsafe_isnt_called/cpkvnlt).
I don't think having to explicitly derive a couple of marker traits when you declare an abstract type would be ergonomic armageddon.
A cache miss is usually quite literally *tens* of times more expensive than normal instructions. Jumping around pointers is *the main reason* high level languages are slow. Plug: http://sebastiansylvan.com/2015/04/13/why-most-high-level-languages-are-slow/
Yeah thats valid, I generally see scripts as stringing together shell comands or making terminal things easier; but yeah fine line if any.
Website is up now (gweb.io problem). 
&gt; Honeslty I have no idea how I am being condescending? "'just' scripting" "This allows normal devs to focus on the project then" There's an undertone here that "normal devs" have better things to do and that scripting is "just" scripting. You may not be aware of it, but it really sounds like you find infra and scripting to be inferior.
No doubt there are others on this list that could have done a better job if they would have wanted to invest the time. But the book had 6 technical reviewers from the Rust community, among which Brian Anderson who read and commented on 6 out of 9 chapters. 
&gt; About the number of allocations, the C++ version allocates one string per output line that is created by concatenating smaller strings. I do not know how complicated it would be to reuse the string storage. The only reason I do any string manipulation at all (instead of producing non-allocating ranges of characters) is because I wanted to use Boost.Format, and it traffics in strings. If I wanted to do my own formatting, I could avoid that overhead. The other overhead comes from the vector of iterators in the interleave view's cursor. If we used a vector type with the small buffer optimization (users are unlikely to want more than 12 months side-by-side), then that overhead can be avoided too, and the whole thing can be done without a single dynamic allocation.
Interesting. Rust really suffers from the lack of auto return type deduction for the lazy kinds of things ranges are good for. It's where C++ was before 2011, at least in this one respect.
Also when you are using a resource that will be owned by someone outside of Rust. For example say that we have a resource that comes from the C++ world and if explicitly consumed within the Rust world we want to delete it in the C++ world. But if it isn't explicitly consumed we'd rather have the Rust world "forget" about it and let the C++ world code handle it.
wow sushi, dat x flag. I had previously toyed around with a syntax extension that would allow this in the general case for strings, but it was too tedious (not to mention it wouldn't work on stable). It's awesome to have support for this built-in :)
In OCaml, in vim, you can type "\t" while the cursor is over a variable or function name and its type will be displayed. Would be nice to have something like that for Rust.
Yes, that is painful to write and read. There was [a proposal](https://github.com/rust-lang/rfcs/pull/105/commits) for "constrained" return type deduction that might be coming back in the next Rust versions: &gt; The basic idea is to allow code like the following: &gt; &gt; pub fn produce_iter_static() -&gt; impl Iterator&lt;int&gt; { &gt; range(0, 10).rev().map(|x| x * 2).skip(2) &gt; } &gt; &gt;where `impl Iterator&lt;int&gt;` should be understood as "some type `T` such that `T: Iterator&lt;int&gt;`. Notice that the function author does not have to write down any concrete iterator type, nor does the function's signature reveal those details to its clients. But the type promises that _there exists_ some concrete type.
Wouldn't it be better to have the compiler enforce that this doesn't happen instead of relying on a comment? #[neverDerives(A, "error msg: doesn't make sense because...")] struct foo { ... }
Looks cool! The Adapter architecture is a little confusing to me. What does an adapter do? Is there some standard functionality that most of these chat services are going to have?
Over the code points would be less ambiguous.
This looks fairly awesome, actually. I've been interested in learning Rust, and I also have a need for a bot that includes audible I/O. This looks abstract enough to handle the job, however i haven't looked too deeply. Would this framework allow for async functions to occur between input-&gt;response? like input-&gt;function-&gt;callback-&gt;response?
That would make things clearer, and probably clear up the confusion of those who wonder why unsafe doesn't always propagate upward. It's likely the way it is because both unsafe functions and blocks enable the same things inside, even if their use cases are different. It's a bit late to change now, though.
Thanks, and Yes! Each handler gets an &amp;IncomingMessage passed to it which has a `reply` method. `reply` just wraps a Sender which can be cloned and used from other threads. Actually, IncomingMessage should be cloneable so you can just move that into another thread and `reply` at your leisure.
IIRC, Rust uses the #[cold] attribute as well as #[inline(never)] to the same effect.
I'm not familiar with Rust; what does the syntax `T: Iterator&lt;int&gt;` mean? Is it type-erasure (runtime polymorphism), or a static constraint? If it's the latter, is it possible to get the actual return type (with something like `decltype`)?
Virtual inheritance is a highly prioritized feature for upcoming releases, and Niko is working on a design as we speak. He's got a series of blog posts in the works discussing it, here's the first: http://smallcultfollowing.com/babysteps/blog/2015/05/05/where-rusts-enum-shines/
Per "thing"? Like, the worst case here is going from `Vec&lt;u8&gt;` to `Vec&lt;RefCell&lt;u8&gt;&gt;`, which will take 9x as much memory, and therefore (in the limit) 9x as much time to traverse the whole list. (Cache rules everything around me.) Even if we ignore that case as pathological, many user-defined structs are smaller than a word, and a great many are at most a few words large. In an interpreter for a high level language, you might write off dozens or even hundreds of bytes per allocation as "metadata overhead". But that's very much not acceptable in C++ or Rust. Growing a struct from 24 bytes to 32 is a huge deal when you have millions of them. If you only have one layer of `RefCell` and one copy of that object then sure, whatever. Structures that have "deep" interior mutability will use more memory, but will permit a greater variety of dynamic borrow patterns. That's a tradeoff you have to make.
Well, Haskell and Nim manage, albeit with a bit of syntactic special-casing in the later.
I won't tell you how to handle such invalidation idiomatically in Rust, because I don't think it's a trivial problem and your approach is good enough. &gt; do I need to replace Rc&lt;RefCell&lt;T&gt;&gt; with Arc&lt;Mutex&lt;T&gt;&gt; Yes. Basically multithreaded equivalent of `Rc` is `Arc` and `RefCell` – `RWLock` (you can use `Mutex` too, but `RWLock` allows multiple immutable borrows at the same time (with a little additional runtime cost)). &gt; and furthermore wrap the entire hashmap in another mutex Yes, you have to do that to be able to call `new` via `&amp;self` from multiple threads. Note that you don't need `Arc` here. &gt; Should the HashMap be then also wrapped in a RefCell/UnsafeCell so it could be accessed mutably via an immutable reference to the factory? You wrap it in `Mutex`, that already gives you "mutable acces via immutable reference". If you replace `Mutex` by `RefCell` here, it won't compile. If you create `Mutex&lt;RefCell&lt;HashMap&gt;&gt;`, that would be just redundant. &gt; Or is this just a bad approach in general? Don't be scared to try, if you don't use `unsafe`, the worst thing (aside from logic bugs) could be just slowness or compiler yelling at you. Oh, and you shouldn't use `RefCell` for basic types like `i32`. You can use just `Cell` for that (unless you want to check that some `borrow()` is not interrupted by `borrow_mut()` (which is closing a handle in your case)). Multithreaded equivalents of `Cell`s are [atomic](http://static.rust-lang.org/doc/master/std/sync/atomic/index.html) types. I was thinking about recommending `AtomicIsize` for your usecase, but now I think `RWLock` will be a better idea (assuming proper handling of handle borrowing).
Rust sometimes requires blocks in arbitrary bits of code in order to constrain the lifetime of a reference and satisfy the borrow checker. Neither Haskell nor Nim have this requirement.
Yeah, associated constants don't work for anything really interesting yet, unfortunately :(
I don't think that sort of stuff makes sense in the main Rust docs or standard library, but I could definitely imagine (and encourage) an external library that provides abstractions to help with all that. (In fact, googling a bit found [Pyrite](https://bitbucket.org/devin.jeanpierre/pyrite/overview), which is now very outdated but [demonstrates](https://bitbucket.org/devin.jeanpierre/pyrite/src/7777fcb55d259a9ca45ab7b9f6a856efd4005c42/examples/standalone/hello.rs?at=default) it's not too hard at all.)
Definitely!
Unfortunately, you'll have to ask in /r/playrust . This subreddit is for the programming language named Rust, not the game.
lol. Oh crap. i'm sorry. *blushes*
I might point out that these salt mines are also where former nominal technical leads of the project -- myself and brson -- have spent a large portion of our working hours. It's essential work for establishing and maintaining project momentum, contributor growth, product quality, platform ports, artifact availability. Without significant, sustained expenditure on infrastructure and automation, the project never would have got anywhere.
&gt; Per "thing"? Like, the worst case here is going from Vec&lt;u8&gt; to Vec&lt;RefCell&lt;u8&gt;&gt;, which will take 9x as much memory, ~~I'd say 12x or 16x - at least on ARM where unaligned access is disallowed (and I'd be very surprised if Rust packed all structs on other archs).~~ Edit: `RefCell` is a single `usize` in memory overhead. Add alignment to that and you'd get 8x on a 32-bit arch (usize is four bytes, the u8 is one, three bytes of padding) and 16x on a 64-bit arch (usize is 8 bytes, the u8 is one, seven bytes of padding). That said, `u8` is `Copy` which means that you would likely use `Vec&lt;Cell&lt;u8&gt;&gt;` instead, so I'd say that a sparse `Vec&lt;RefCell&lt;Option&lt;Box&lt;_&gt;&gt;&gt;&gt;` would be the smallest realistic one, with ~~4x~~ 2x memory overhead. Which is still a lot, of course.
&gt; Also having nested RefCells is often not what you want because you easily risk crashing your application by taking two references that leads to a panic. That's true, although I'd say that the safety argument is probably in `RefCell`s favour over my `UCell` container. Because if you use `unsafe` to mutate the `UCell` contents at the wrong place and time, then you might get UB, which is worse than a panic.
Hi there. I'm trying to write a function that returns an Iterator of the mutable values in a HashMap and I'm running afoul of the borrow checker. I'm still learning the ins and outs, but I don't understand what it's complaining about or how to fix it. struct Foo { h: HashMap&lt;String, String&gt; } impl Foo { fn all_values&lt;'a&gt;(&amp;'a mut self) -&gt; Box&lt;Iterator&lt;Item=&amp;'a mut String&gt;&gt; { Box::new(self.h.iter_mut().map(|i| i.1)) } } ([playpen link](http://is.gd/sdSnhF)) The borrow-checker is giving me all sorts of grief and I've tried just about every permutation I can think of: error: cannot infer an appropriate lifetime for autoref due to conflicting requirements Box::new(self.h.iter_mut().map(|i| i.1)) ^~~~~~~~~~ note: first, the lifetime cannot outlive the expression at 9:17... Box::new(self.h.iter_mut().map(|i| i.1)) ^~~~~~ note: ...so that auto-reference is valid at the time of borrow Box::new(self.h.iter_mut().map(|i| i.1)) ^~~~~~ note: but, the lifetime must be valid for the lifetime 'a as defined on the block at 8:74... fn all_values&lt;'a&gt;(&amp;'a mut self) -&gt; Box&lt;Iterator&lt;Item=&amp;'a mut String&gt;&gt; { Box::new(self.h.iter_mut().map(|i| i.1)) } This doesn't make sense to me because `iter_mut()` returns an `Iterator` whose `Item = (&amp;'a String, &amp;'a mut String)` where `'a` is the lifetime of the `HashMap`, so it should be able to live just as long as the HashMap, right?
Hi, I think you may be a bit confused. This is the subreddit for Rust, the programming language, not Rust, the video game.
Thanks for this explanation. You'll be interested to know that Concepts Lite is bringing much of this deduction to C++. For instance, you'll be able to do: ``` std::vector&lt;auto&gt; v = std::vector&lt;int&gt;{1,2,3,4}; ``` And even: ``` void accepts_vector_of_iterators(std::vector&lt;Iterator&gt; v) {/*...*/} ``` In the latter, `Iterator` is a concept and `accepts_vector_of_iterators` is implicitly a template.
People don't known which is lossy or not, if docs doesn't tell them. If docs do, they known `impl Display for Path` is lossy.
Precisely. The more static analysis my compiler can do for me the better. If I have to spend time, effort and money on an external tool and integrate that into my workflow, it's likely to have a low priority or not get done at all. Sad, but true.
Yes, I've been using the crate num_cpus to do this in a simple script. [Link to their github](https://github.com/seanmonstar/num_cpus) Edit: To give an example, it returns 8 on my quad-core i7, because it has 8 logical cores.
Over at [rust-clippy](https://github.com/Manishearth/rust-clippy), we have been integrating things from FindBugs, reddit discussions, and multiple other sources. We already have a good number of checks and get more by the day. Also there are [multiple](https://github.com/Manishearth/humpty_dumpty) [other](https://github.com/mitsuhiko/rust-excessive-bools-lint) [projects](https://github.com/Manishearth/rust-tenacious) supplying lints as plugin libraries that you can easily include in your build. Did I say easily? Well, that sort of was a lie, because you still need to add #[feature(plugin) #[plugin(clippy, tenacious, …)] to every file of your code. That gets tiresome quickly. Of course you can use a hacky cargo build script to set this up, but it would be so much easier if [this cargo issue](https://github.com/rust-lang/cargo/issues/1579#issuecomment-99139424) would be dealt with. That said, I think the approach of having a solid set of lints right in the compiler and allowing developers to add any number of plugins they might want is the best way forward. Edit: I also wanted to point out that this article gets reposted every now and then. And that's probably a good thing if it makes people realize that static analysis can be a worthwile tool to have on their belt.
See my other comment – it's not going to be in the compiler, but you can already add plugins to check for many interesting things. Edit: To expand on that a bit: Some people in the core team have expressed that they feel rustc already has too many Lint's – no one will use a compiler that takes ages to compile, even if it makes their code better. Also using plugins allows us to target the analysis better. That said, we want to make it as easy as possible to add lints to your build.
There's actually an easy hack to get around the cargo bug -- just add -Z extra-plugins=foo to your multirust shims ;P It's a hack and very fiddly though.
This is exactly what I meant. If `mem::forget` were `unsafe` to call, it could be argued that this is a non-issue as it involves calling a `unsafe` function. As `mem::forget` is safe, it is obvious that there is something unsound with `Rc`.
The_Masked_Lurker is (AFAIK) using "just" in the sense of suddenly understanding something previously opaque in terms of something already known, e.g.: "Hmm, what's an ordered multiset? Sounds confusing. (later) Oh, they're just lists! Now I get it." I trust nobody thinks lists are unimportant. ;-)
That also doesn't work if I want to build my code with clippy, as opposed to my code+all dependencies.
[Hinnant's stack allocator](https://howardhinnant.github.io/stack_alloc.html) lets you write such a vector with ease
Awesome. Could this also be run as a standalone application? Why is it a web service anyway?
baby steps I hope
I've been monitoring servo, and doing git pulls every other day and build the binary, but for the fast few day, I can't launch the servo browser anymore. I had error '[glutin] x error code=50 major=0 minor=0!' even if it clone the servo project again. I also tried other branches but still fails to start servo.
Are there any current tutorials/readings about this: ( http://featherweightmusings.blogspot.com/2014/03/subtyping-and-coercion-in-rust.html )? "sub-traits" and "sub-structs". *Disregard all that follows. Seems like I'm too sleepy to write at the moment...* ~~**[EDIT]** The error was totally unrelated. Now my new question is: What are the constraints of this? Like: "can't use 'super-trait' pointers to point to inheriting trait trait-objects" or stuff like that. What's in the new planned inheritance stuff that can't be modeled with smaller trait-building blocks? Thanks. **[/edit]**~~ ~~This : **[EDIT]**~~ impl tPoint for pP { fn mkPoint(&amp;self) -&gt; i32 { 3 } } fn main() { println!("NEW!"); let x = pP; //let x: pP; let y = pB; //let y: pB; println!("{}", x.mkPoint()); println!("{}", y.mkPoint()); y.mkMe(); } trait tPoint { fn mkPoint(&amp;self) -&gt; i32; } trait tBar : tPoint { fn mkMe(&amp;self); } struct pP; struct pB; impl tPoint for pB { fn mkPoint(&amp;self) -&gt; i32 { 90 } } impl tBar for pB { fn mkMe(&amp;self) { println!("hello!"); } } ~~works. As in, the errors don't sound too weird, and they aren't about the `&lt;trait&gt; : &lt;supertrait&gt;` syntax. So, my question is \^ above.~~
Yesterday I was searching for IRC bots and found an pre-beta repo and another one that was not soooo... , today this. *excited*
I'll cross-link to [r/programming](http://www.reddit.com/r/programming/comments/37p99p/problems_are_found_in_the_firmware_interface_for/) where viva64 is showing off a new analysis. The warnings they chose to show off this time were "scary" in that most of them were not type errors but copy/paste errors: &gt; Warning: V524 It is odd that the body of 'AllocateRuntimePages' function is fully equivalent to the body of 'AllocatePages' function. &gt; Warning: V535 The variable 'Index' is being used for this loop and for the outer loop. &gt; Warning: V547 Expression '...' is always false. &gt; Warning: V560 A part of conditional expression is always true... &gt; Warning: V649 There are two 'if' statements with identical conditional expressions. The first 'if' statement contains function return. It's unclear to me how many of those rustc will catch: Rust itself would not protect from any of those, I think, as those are business logic errors.
Will it work on stable rust at one point? I've been recommended on the irc to use the stable channel to learn Rust
If the worry about escaping is just for weird HTML edge cases you've missed? I think it's correct to just escape the 4 HTML special characters as you're doing. - Some software does ' -&gt; &amp;amp;apos; as well, in case fools use ' instead of " for attributes (browsers accept either). Use " to quote attributes as per the standard, and everything's fine. - It only gets complex when people want to allow "safe" html from user input. Particularly if you try to use blacklisting for security, instead of defining a sensible language/subset for user needs. - Programmers need to understand it's specifically for HTML, and not for the other languages that can be nested inside HTML. It doesn't make it right to insert into [JS string literals](https://github.com/ci-bonfire/Bonfire/commit/21e132c0aa08a66820ea0b5d80c9111c30eaaaff#diff-b297f7e871e48a15f07ea6089497b10cR454), random parts of URLs (e.g. without %-encoding), or whatever.
That would still remove the biggest hassle, which to me is including it into a (crossplatform) toolchain. So if more static analysis lints are made available and can be opted into on demand, then I'm a happy camper.
As you've discovered, the web ecosystem for Rust is currently pretty bleak. The essentials are indeed already there (e.g. Hyper for HTTP, Iron for request routing and response structure), but there are still pieces missing that most web applications require. If you're looking to experiment with a simple form application, you can use Iron with [router](https://github.com/iron/router) and [staticfile](https://github.com/iron/staticfile). The latter will let you serve an HTML file with a form. There are currently few readily available resources for further guidance. I recommend hopping on IRC @ `irc.mozilla.org`, channels `#rust-webdev` and `#iron`. If you're new to web programming concepts, don't let Rust's web immaturity stop you from learning!
Could you file an issue at https://github.com/servo/servo/issues/ with details of your system (operating system, versions, etc.) and the full output? Thanks!
So we've discussed stabilizing plugins. While syntax extensions can be pseudostabilized using stuff like syntex; it will take quite a bit of time before they are stabilized because they depend on compiler internals. Lints, longer. One idea is to use extensible enums and freeze the AST representation of existing nodes, but new node types can be added in the future. I guess syntax extensions would be stabilized first because they don't depend on all the side tables and `middle::ty` goodness. It's okay to use the nightly channel to use Rust too, there's no strict benefit. Don't turn on any `#![feature]`s and you should be good. Turn on features only if you're willing to accept that they may break :) 
That was what I was attempting originally but hadn't realised that it would work like that with `&amp;mut self`. Is this interpretation of the borrowing correct: The lifetime of the returned slice ends up as the lifetime of the borrow on self and so the latter is active until the former goes out of scope. The effect being you can't do anything with the object until the slice goes out of scope? This sounds safe, but under some circumstances, a bit of an over constraint. Returning this way makes the most sense, but is there any way to do prevent the recursive call with the closure method?
There's also [Nickel.rs](http://nickel.rs/) which has also had a few blog posts lately, but I can't seem to find them at them moment.
Once the syntax::ast classes have been stabilized...which is unlikely in the short term. Or we'd need a fork of libsyntax (which afaik is actually available), oh and also parts of typeck, etc. Our best bet atm is multirust - develop (and lint) on nightly, release on stable.
I currently feel like that (just a little bit) with haskell vs dependently typed languages. 
As far as the classical HTML tutorials go, the standard path of developing HTML forms is by writing an HTML page with the necessary form (and serving it via staticfile or another web server (?)) and handing over the data via argument or via an environment variable (if I get it right, something like the variable cars with the value volvo in this example: http://www.w3schools.com/html/tryit.asp?filename=tryhtml_elem_select). Do I get it right that in this case the Router is the glue between these variables and my actual programming logic in Rust? I recently did a RESTful API using Sinatra in Ruby, where the router basically was parsing the URL and answered with the corresponding JSON dataset after querying the database, but that's not really what I want to do here; in this case, the router would accept the form input of the user and would hand it over to my application? Furthermore, when the data (a dataset of a person's name, address, telephone for example) has arrived at my programming logic and I add the dataset to my array of saved datasets - what would be the best way to display it to the user who just submitted the dataset? (Think of a membership organisation page for a communinty, where there is a list of applied members and the manager just wants to add one more dataset to the bottom of the list.) Defining a template and "issuing a reload" after the submission of the form in order to make the last dataset visible, too? Thank you so much that you are willing to help a web development newbie! 
Any news about the specific proposals mentioned in the 'summary' link? Like, is Niko working on it alone for now? And if so, did he say which way he's leaning? (Couldn't figure it out from the Part 1 post, which mostly talks about the strengths of current Rust...)
It's kind of scary to admit this, but maybe the evidence shows that safety isn't that big of a deal.
Perhaps. Then again, I've seen C++ programmers wrangling with pointers all the time. Just an hour ago the guy next to me fell into a pointer-casting hellhole. Safety isn't that big of a deal because people donate time and effort looking for it. Of course it's entirely possible that I'm wrong and that safety is just something we worry too much about.
Hear hear. Btw. this is what I'm doing atm.
Resharper is impressive for that, making the c#tool chain awesome.
I'm not going to say that it is impossible, but considering that you don't have much experience in cross-compiling and that rustc currently does not have MIPS backend doing that would be quite a challenge. You might want to take a look of how people have added ARM support to rustc and follow their footsteps and add MIPS support. Generating an object file that you could link with C code probably would be a good place to start.
Does anyone have experience using a Rust web framework together with NodeJS? For instance triggering a GulpJS build script to be run along with a Cargo build that compiles and minifies assets (TypeScript, Sass, etc)? Personally I miss a solid HTML template engine the most. I dream of someday having a Razor like library for Rust, or perhaps something resembling the engine from Play Framework ([link](https://www.playframework.com/documentation/2.4.x/ScalaTemplates)).
What are these 'compiler directives' or 'pragmas' or whatever (neither term worked when I searched for it in relation to Rust) that enable stuff like assertions and unstable features called? (Form: `#[...]` and `#![...]`) Is there a list for all the currently available `#![feature(s)]`?
The difference between `take_trait_obj` and `take_bound_type` is that `take_trait_object` is called with a trait object, a pair of pointers to the data and a vtable, and `take_bound_type` takes an actual pointer to `T`. A distinct version of the function will be generated for each type it is called with. If it helps, `take_trait_obj` is doing dynamic dispatch, and `take_bound_type` is doing static dispatch. [The book does a better job explaining than I do.](https://doc.rust-lang.org/book/trait-objects.html)
I *think* that what is being discussed in your link is what led to [RFC 401](https://github.com/rust-lang/rfcs/pull/401), which would mean that all of that is [still being implemented](https://github.com/rust-lang/rust/issues/18469). There probably won't be any good tutorials or information until it's done. If you just want to know about subtraits, [you can read about those here](https://doc.rust-lang.org/book/traits.html#inheritance).
There is a [MIPS Linux target spec](https://github.com/rust-lang/rust/blob/master/src/librustc_back/target/mipsel_unknown_linux_gnu.rs) in the rustc source tree. And you can specify all that information through a [custom JSON file](https://github.com/rust-lang/rfcs/blob/master/text/0131-target-specification.md) anyway. In general, setting up rustc as a cross compiler to any LLVM target is the easy part. The hard(er) part is * building all the libraries you need -- at minimum, `libcore` * porting any OS- or architecture-specific code in those libraries. I definitely recommend using Rust nightly rather than the released 1.0.0 as you'll almost certainly need some experimental features.
&gt; to every file of your code Just to the top-level file of every crate.
Oh, I agree; I was listing those warnings because I believe they would be great additions to the lints in clippy (if not already existing). Those "extra" checks seem invaluable to me.
You're looking for /r/playrust.
 let v: Vec&lt;char&gt; = input.chars().collect(); for c in v { ... } You are needlessly allocating a Vec for the characters from the `.chars()` iterator, when you could use said iterator directly: for c in input.chars() { ... } http://is.gd/SumPYp
&gt; Re-allocating memory is really slow. Not only does Rust have to ask the kernel for new memory, it must also copy the contents of the vector from the old memory space to the new memory space. Eh, it's not nearly that bad, because: * Any decent malloc asks the OS for memory in big chunks and then doles it out in userspace. * Any decent multithreaded malloc also has per-thread caches so you don't have to synchronize all the time. * You can often grow an allocation in place, in which case there's no copy. You may have only reserved 100 bytes but the next 1,000 happen to be free and malloc will just give them to you. * Even when there is a copy, it's just a bytewise memcpy, with a totally predictable memory access pattern. So it's pretty much the most efficient possible memory &amp;rarr; memory operation. System libc usually includes a memcpy with optimizations for your particular microarchitecture. * You can also "move" big allocations by reconfiguring the MMU, meaning you only have to copy 1 page worth of data. However there is usually a large fixed cost to changing the page tables, so this would only make sense for really huge vectors. I'm not sure if Rust or jemalloc performs this optimization. Resizing a C++ `std::vector` can be much much slower because you have to call the move constructors individually, and they might `throw`.
No, I don't use GulpJS, but I use another kind of setup with grunt... Currently I run grunt "dev" and "prod" scripts manually and then do "cargo run" or "cargo run --release --features "prod"". I don't need to run "grunt dev" often because in dev all js files are loaded dynamically over requirejs. By the way, I am wondering if it is possible to conditionally compile for --release (instead of relying on fake feature "prod")... I need it so that the release mode can switch to different js paths.
Yes, but static analysis in general can be arbitrarily complex.
TIL. Thank you.
Thanks! &gt; Some software does ' -&gt; &amp;apos; as well, in case fools use ' instead of " for attributes (browsers accept either). Use " to quote attributes as per the standard, and everything's fine. I write the quotes for the user (and I use ") so I don't think this will be a problem. If you write raw HTML, you have to do your own escaping anyways. &gt;It only gets complex when people want to allow "safe" html from user input. Particularly if you try to use blacklisting for security, instead of defining a sensible language/subset for user needs. Users can implement the `Render*` traits so if they want their own escaping rules, they can create custom components (I'll just make this someone else's problem). &gt; Programmers need to understand it's specifically for HTML, and not for the other languages that can be nested inside HTML. It doesn't make it right to insert into JS string literals, random parts of URLs (e.g. without %-encoding), or whatever. Very good point. I've updated the docs.
OpenWRT is linux so the hardest part would be architecture-specific code and I think those can be grep'd (for "target_arch").
This looks like it's meant to work on ubuntu. Is there an equivalent to /dev/input that would make this work on a mac, or a -f parameter that would work?
The first one makes a single function that takes both a pointer to a `good_trait`-implementing struct and a pointer to its vtable. This means there's only one version of the function, but every member function call it does is indirect, so it's a little bit slower. The second one has the compiler generate a new function for every type you try to feed it. The function takes only the pointer to the struct, no vtable, and every method call is statically dispatched. This can make the final executable bigger, but is usually faster. You can always give the user a choice of what interface they want to use by making an `impl good_trait for &amp;T where T: good_trait`, and writing every function with the static dispatch version. That way they can call `take_bound_type(&amp;x as &amp;good_type)` to get dynamic dispatch.
It should work on any Linux distro (not just Ubuntu). What it's doing is reading from the device file into an `input_event` struct (described in section 5 [here](https://www.kernel.org/doc/Documentation/input/input.txt)). If there is an equivalent of that on a Mac, it should work. Edit: After doing a bit of research, I don't think there is a Mac equivalent. Someone correct me if I'm wrong.
Awesome, thanks!
This is my first real Rust project, and I'd really like to have some feedback on this! Do you think it's useful? Also, the macro invocation syntax is not yet set in stone, maybe it could be improved.
The whole thing can be simplified to just a filter + collect: input.chars().filter(|&amp;c| c != ' ').collect::&lt;String&gt;().into() or buf.extend(input.chars().filter(|&amp;c| c != ' ')); 
I agree with Hytosys. The web ecosystem for rust is currently pretty bleak. I was trying to do something pretty non-trivial, with a REST-like architecture. Here were the problems that I ran into. First, I tried to use nickel. I got it working, but it really was a struggle to get some non-trivial data to be shared between requests. I ended up making my own very ugly middleware. The apis would change. All of the documentation or examples would become outdated. It was a pain. I decided Iron had better APIs and more effort behind it. I really like it much better. But when it came to using it, I ran into a few roadblocks. * The staticfile module wouldn't even compile on stable rust because it depends on features from nightly rust (file modification times). * The staticfile module wouldn't even compile with nightly rust, since nightly rust changes all the time. This was easy to fix myself, and was fixed in the project only 4 days ago. * The router module doesn't let you handle a path that ends in a forward slash. This seems like a small oversight, and also easy enough to hack a fix myself. After that, I had a really fast rust web framework going. It seems like Iron is the best we have right now. I think it has a really nice modular framework, and really nice APIs. It's just a young project right now. It has problems that you would expect to see from a young project in a young language. Don't expect to be flawlessly up and running in a few minutes, and don't expect the APIs you're using to remain stable.
Agreed. I wanted to make it clear we are pushing characters onto the buffer so I made my contrived example more verbose. I really like your use of extend though!
This is the case. `unsafe` is not a panacea. `unsafe` will not let you do random things with pointers. You should strive to hold the Rust invariants within `unsafe` code too, even if it lets you break them. Rust assumes that `&amp;` pointers are immutable (and it tells LLVM the same). Similarly it assumes that `&amp;mut` pointers are uniquely mutating. Breaking these assumptions is undefined behavior. If you're temporarily hijacking a pointer for unsafe code, make sure it mutable if you're mutating it. If you're holding on to a raw pointer for a while, make sure there aren't any `&amp;mut` pointers lying around at the same time. A piece of data should generally be referred to by all Rust pointers or all raw pointers (*or* use `UnsafeCell` so that the Rust assumptions go away, but be careful). If there's a mixture, the assumptions will break.
Paging /u/Gankro, there may be real-world TURPL-worthy examples with the OP.
Ah, thanks. At least this gives an idea of where the offset comes from. Of course, why it would then be used as a pointer value is going to be... interesting?
I don't have control over anything git related, that's on github. Are you sure your key is configured properly? You're cloning over SSH.
Maybe it would be better to read from `/proc/bus/input/devices` directly instead of spawning 4 processes to get data from it?
&gt; Resizing a C++ std::vector can be much much slower because you have to call the move constructors individually, and they might throw. It's slow because C++ objects are immovable :(
4 processes? What are you talking about? Are you sure you didn't run the keylogger 4 times?
I loved the translation of identifiers! Now what does it take to make that translation reality in the rest of rustc?!
I didn't execute it, I just saw this: let mut command_str = "grep -E 'Handlers|EV' /proc/bus/input/devices".to_string(); command_str.push_str("| grep -B1 120013"); command_str.push_str("| grep -Eo event[0-9]+"); let res = Command::new("sh").arg("-c").arg(command_str).output().unwrap_or_else(|e| { panic!("{}", e); });
You might want to check out /r/rust_gamedev too, they might have good ideas :)
Synt**e**x. https://crates.io/crates/syntex &gt; Autocorrect, my fatal foe! Oh don't I feel this too :)
Or just because it's the same thing C# does. (AFAIK)
Part 2 just came out today: http://smallcultfollowing.com/babysteps/blog/2015/05/29/classes-strike-back/ Niko is likely working on his own proposal for now that takes all the previous proposals into account. I expect Part 3 will contrast his new proposal with each of the previous ones. After that he'll file an RFC, where people will be able to discuss and give feedback on the details of the proposal.
Cool cool. I don't currently write games in Rust, so that's all the advice I have to offer, but maybe someone else will have some good ideas :)
It does, via `impl&lt;T&gt; ToOwned for T where T: Clone`, since there's an `impl&lt;'a, B&gt; Clone for Cow&lt;'a, B&gt; where B: ToOwned + ?Sized` ([playpen](http://is.gd/t23c5g)): use std::borrow::{Cow, ToOwned}; fn main() { let x = "Hello"; let y = Cow::Borrowed(x); let z = y.to_owned(); println!("{}", z); } It looks like the docs may not be capable of chasing this level of indirection via blanket impls.
Why am I fishy? ffs This type of nonsense is the very reason I didn't register an account before now. 
See section 2.2 of [this](http://scialex.github.io/reenix.pdf), or how it works in [rustboot](https://github.com/charliesome/rustboot) (and the later [RustOS](https://github.com/ryanra/RustOS), though I can't make heads or tails of RustOS). TL;DR you're probably going to need some assembly to get it started.
Rust's major contribution is enforcing at compile time practices that are good habits in other languages. The borrow checker corresponds fairly closely with good practice if you want to write a program in C or C++ that safely manages memory without having to slather everything in reference counting and shared_ptrs. So if you want to use one of those languages eventually, Rust is a good start.
Whoa that's pretty neat. How are the type names for, e.g. m^2 generated?
For people who need something that works on stable, [Horrorshow](https://users.rust-lang.org/t/horrorshow-a-no-longer-poc-html-template-library/1603) implements a similar syntax.
https://github.com/dpc/titanos/blob/master/rt/aarch64/head.S Rust is not that hard to interact and include assembler code.
Original link works for me.
Here's a link to the actual project: https://github.com/lfairy/maud
There's also the [GitHub repository for reenix](https://github.com/scialex/reenix) if you want to take a look at the code.
If only Rust would have a proper [module system](https://ocaml.org/learn/tutorials/modules.html) ;-)
Looking for any project really. Actually suggestions outside of games would be greatly appreciated. Was more or less stating where my current work &amp; interests are outside of rust.
From [the reference](http://doc.rust-lang.org/reference.html#behavior-considered-undefined): &gt;The following is a list of behavior which is forbidden in all Rust code, including within unsafe blocks and unsafe functions. Type checking provides the guarantee that these issues are never caused by safe code. &gt; &gt; ... &gt; &gt; * Breaking the [pointer aliasing rules](http://llvm.org/docs/LangRef.html#pointer-aliasing-rules) with raw pointers (a subset of the rules used by C) &gt; * `&amp;mut` and `&amp;` follow LLVM’s scoped [noalias](http://llvm.org/docs/LangRef.html#noalias) model, except if the `&amp;T` contains an `UnsafeCell&lt;U&gt;`. Unsafe code must not violate these aliasing guarantees. &gt; * Mutating non-mutable data (that is, data reached through a shared reference or data owned by a `let` binding), unless that data is contained within an `UnsafeCell&lt;U&gt;`. It looks like you are trying to go from `&amp;` to a mutable pointer without using `UnsafeCell&lt;U&gt;` (or some other wrapper that uses `UnsafeCell&lt;U&gt;`), which seems to me to fall under the undefined behavior described above.
I know this doesn't answer your question, but you might be interested in [libpnet (https://github.com/libpnet/libpnet)](https://github.com/libpnet/libpnet), which has a lot of similar functionality to libpcap (written natively in Rust).
That makes sense. I could definitely see it confusing a newcomer.
[Here](http://jozefg.bitbucket.org/posts/2015-01-08-modules.html) is another introduction. Essentially, ML modules would subsume both Rust's `mod` and `trait`.
Yes, it is. At least when you want learn Rust to improve your coding and not just for your portfolio. Haskell is also a great choice because you learn a lot of theoretic background knowledge. Modern Java and Rust are very similar. Since Java is very old and has a huge collection of design flaws you tend to learn the outdated things because they have been used by other projects before. In old Java you often use inheritence and type erase, in new one generics or lambdas (yes, both are implemented with type erasure but still differenc concepts). For my current student project I have to write a simple game in java and I convinced my group to use Optional (Option in Rust), Stream (iterator) and a selfwritten Result class instead of null-references and exceptions. The Unit test discovered just a single out of bound exception, no null reference exception except one caused by a wrong Result implementation and I later found another caused by inheritance (turns out, there is no lint against overriding protected member in subclasses and leaving the parents' one uninitialized).
Can anybody clarify the bolded section of this line? &gt; Traits shouldn't be unsafe just because it enables some optimizations (**e.g. you can't currently "trust" implementors of Ord to have a total ordering; unsafe code must currently guard against this**) Isn't the point of `Ord` that types implementing it do have a total order? Or is this referring to the issue that the Ord implementation may have a bug.. and in that case, why does unsafe code need to guard against that more than safe code?
I sorta understand why we have them, but I honestly find `*mut` vs. `*const` confusing (even as a lint) because you have to cast between them.
Continually impressed at how much experimentation the Piston project is willing to embark upon. It's blazing a trail for so many things in the Rust ecosystem!
What does it mean for something to have the 'static lifetime? I have some conception of what it's supposed to mean-- that the data lasts for the life of the program. But what restrictions does it place on the instantiation or dereference of that data? Is it possible to create 'static data at any point during the execution of the program? Is it ever possible to drop() data that is 'static?
Ahh, the naming is kind of a problem. Otherwise I would totally use this. :\
Out of interest, what was it that made the pool slower than simply allocating? Were you using a pool from crates.io or a hand-rolled one?
I don't get it.
&gt; Interestingly, Rust can gain a lot of the benefits of the subclass approach—namely, common fields and refinement types—just by making enum variants into types. I think this is going to wreck havoc with type inference. Scala has this problem with its encoding of algebraic data types as classes and it's annoying as hell. Predictable type inference is an important point for ergonomy IMHO.
ML modules separate the _types of modules_, which ML calls _signatures_, from the corresponding implementations, which ML calls _structures_. This is great for separate compilation, as you can write a program in terms of a signature and compile it without having the concrete implementation on hand. ML modules are also trait-like: you can define a signature that contains an unspecified type and then implement signatures for concrete instantiations of that type. One difference is that, in Rust, each trait can only be implemented once per type (i.e. either there is no `Ord` instance for a type, or there is one) whereas in ML you can have as many as you (e.g., multiple `Ord` modules for strings, say, one case-sensitive and one case-insensitive.) This gives you more flexibility, but at the cost of convenience: when you use an ordering operation, you must specify which ordering you mean, whereas in Rust, there are no alternatives to choose from, so the compiler can choose implicitly. Finally, _functors_ are modules that are parameterized by another module: you can think of them as module-level functions, e.g. a `TreeMap` functor that is parameterized by some `Ord` module, or an `Invert` functor which takes an arbitrary `Ord` module and produces an `Ord` module that corresponds to the inverse ordering. Functor are a very expressive and powerful feature.
I did actually. I tried rustful before nickel in pre-1.0 times. I couldn't even get it to compile. I haven't looked at it lately.
There are several different projects for making a kernel (and eventually OS) in rust. Rustboot was one of the first, there's ryanna's RustOS, Tobba is making one (which afaik isn't public yet). I've also written both a small example of how to boot rust code (http://github.com/thepowersgang/rust-barebones-kernel/) and a in-progress kernel (http://github.com/thepowersgang/rust_os). Rust sits between C and C++ in terms of how hard it is to run on bare-metal (requiring a little more setup than C, but not as much support as C++)
Lol, now I get it. Although I had to look up what MLP stood for.
&gt;A *lot* of progress can be made with just non-complicated lints, e.g. the collapsible if statements one is just a bit of pattern matching. Yes, and there's good reason we're plucking those low-hanging fruit first. But sooner or later we will have lints that do flow analysis and some such. Another case: The len_zero lint almost grew a loop over all methods of the target (which could be many), only the nonavailability of typeck prevented this at the time.
This is great! Knowing nothing about C# myself, does the approach here only work with Unity or is this just using a general mechanism for calling native code from C#?
Such a loop is still only a constant percentage more: the rest of the compilation process will also scale (at least) linearly with the number of methods.
Agreed. I just took it as an example that additional *complexity* isn't holding us back; the nonavailability of APIs is.
Hey, I have something similar: http://paholg.com/dimensioned/ Always fun to see different approaches to the same problem!
Yeah, I've seen this (after I'd finished an initial version of my project). I think the basic approach is very similar, but being limited to SI dimensions might make it quite hard to use in practice (I like how in F# you can just define arbitrary units, and try to reach that flexibility in my library). If I understand correctly, you offer a python script to generate different units, but why not use macros if Rust has them? ;-) (It sure was a bit painful to write the macro and I'm surprised myself that it works that well!)
I have a similar library with a similar internal representation. You can name a type, say *m*^2 , not *too* cumbersomely by composing it of existing types, like so: type Meter2 = &lt;Meter as AddDim&lt;Meter&gt;&gt;::Output; If you want to name a type like *kg*^3 * *m*^4 / s^3 it's messier, but not too bad if you do it one step at a time.
Yes, but it was also made at a time that Rust was quite different from how it currently is. With traits now having associated [_] it may be a decision worth revisiting (given that, IIRC, when I asked a while back why we wouldn't want an ML-style module system in Rust the answer was at least partly that we didn't have the type system machinery for it in the first place). That being said, despite being a major fan of the idea of ML modules in Rust, I agree with /u/dbaupp that I'm not sure it really solves the thin pointer problem.
It's a general mechanism in C#.
Right, it's possible, just ugly. Also see https://github.com/Boddlnagg/units/issues/2
To add onto this, I believe you can skip renaming the extension from .dylib to .bundle since that's a Unity quirk. I haven't tested this, however.
Aren't bundles a common thing in XCode? Maybe a naïve question since I only have a passing exposure to Mac programming.
The reason we can do this kind of experimentation is because Rust works so we can do other things than fixing bugs, but also because many similar ideas have already been implemented, so we know approximately what we get if it succeeds. Piston-Meta is inspired by OMeta that had several years to prove itself. OMeta can parse anything, but it is not that good for error messages. I would like a tool that is more suited for data such as JSON, which is very common, and it has to be understandable how it works. Meta parsing is a coin with very trivial stuff on one side and very non-trivial stuff on the other side. The trivial thing is doing the parsing by rules and the non-trivial thing is how to bootstrap the data work flow into what the game is about. You also get pattern matching validation for free because that is how it reads data. This could be used to make debugging and changing easier, and without restarting, which is pretty exciting. For example, when doing a multiplayer online game engine you want it to never stop and just add content on the fly, or even let the players contribute while they are playing.
The python script was just meant as a temporary measure. I certainly plan to switch to macros or something. I think there was something that I wanted that macros wouldn't do. It's been a little while and I can't remember my exact reasoning. I've definitely always planned on having easily definable type systems and not trying to limit anyone to anything. It was recommended to me to use syntax extensions, but virtually no documentation existed. It seems there is some now, so it's time to do some research.
Builder *pattern*?
Mozilla's web inspector is a pile of crap compared to the one in Chrome, so maybe Google could do it better.
Is there a performance difference between `Box&lt;Option&lt;T&gt;&gt;` and `Option&lt;Box&lt;T&gt;&gt;`? (I'm asking because I saw one instance in the definition of NodeData [here](https://github.com/matthieu-m/rust-poly/blob/master/doc/0000-disjoint-polymorphism.md#implementing-the-dom-according-to-requirements))
Go back in time enough in the rust sources and you will find that instead of `std::option::Option` the type was `option::t` inside the `option` module.
To be honest, I prefer keeping metadata *with* the source as much as possible, and I'd love to see some sort of `rustc --extract-attrs` thing... but this is *way* more likely to be adopted, and a *hell* of a lot easier to implement. :D
Why not for bar in foo.iter_mut() { bar.baz() } ? I guess you could also do foo.iter_mut().map(|bar| bar.baz()).last() foo.iter_mut().map(|bar| bar.baz()).fold((), |_, _| ()) but... eww.
I'm not actually sure if there is a detailed exact definition of the name "variant" in the Rust docs, but what is meant is that a variant (which is not a type on its own) is the size of all its fields plus the size of a tag value big enough to differentiate between all variants. So in your code the minimum required memory layout would basically be `{u8, i32}`, which due to alignment padding results in `{u8, [u8; 3], i32}`, which is the same size as `{i32, i32}`. As an aside, what you probably meant is something like struct A { a: i32 } struct B { b: i32 } enum C { AVariant(A), BVariant(B) } That is, you can not use the name of an existing struct in a enum directly.
AFAIK, rust typically uses a one byte discriminator.
This is all hearsay, but: Static items are items stored in read-only memory, that live the duration of the program. They cannot be moved out from, so cannot be dropped. They can be dereferenced as usual. They must be initialized with constant values (basic constant-folding is performed). Mutations to them are unsafe.
&gt; Indeed there are some limitations given the fact that you can only access one item at a time, so e g, if you have an array of items you can never sort them. Yeh there certainly are limitations that will make it unsuitable for some situations. I can see it having a use though. &gt;I wonder if the clone implementation could enable a hole in the safety net though, as clone can call abritrary code which is not bound by ExcellSafe. I'm not completely sure how though, so it's very possible that I'm wrong, too. Do you have any sort of vague ideas that might do that that I could look into? I'm coming up completely blank here about where to even start. As another point of interest, I managed to get an `ExCell` to store itself, without ensuring that its `T: ExCellSafe` struct Alias { alias: RefCell&lt;Option&lt;Rc&lt;ExCell&lt;Rc&lt;Alias&gt;&gt;&gt;&gt;&gt; } let alias = Rc::new(Alias { alias: RefCell::new(None) }); let alias2 = Rc::new(ExCell::new(alias.clone())); *alias.alias.borrow_mut() = Some(alias2.clone()); let x = alias.alias.borrow(); x.as_ref().unwrap().borrow(|alias| { let addr = alias as *mut _ as usize; let y = alias.alias.borrow(); y.as_ref().unwrap().borrow(|aliased| { assert_eq!(addr, aliased as *mut _ as usize); }); }); Interestingly though, since the original `alias` is not `ExCellSafe` it can't be passed into the closure for the second `borrow`, so it seems safe. I keep trying things and I can't seem to break it, but I dunno, I feel like it *can* be broken. Like, just because `alias` can not be passed in direct, does not mean that `alias`es fields can't be (if you gave Alias extra fields of course)... but the only way I've found to get to this point in the first place is with `Rc` and `RefCell`, and `Rc` is immutable so you can't get mutable access to it's fields, and if you used `RefCell` as well it will have a runtime guarantee that you don't have 2 mutable references. So I don't know, maybe it *is* safe to get rid of the `T: ExCellSafe` on `ExCell`? (Also I'm really sorry for the pun in the name. I've only just realised that "Excel" is actually a word, and I really was just thinking "Exclusive Cell").
Thanks! I actually saw an sfml game posted on the rust-gamedev subreddit earlier. Was neat to see how that worked. Though I'm actually looking for non GD projects to try out. Realized I didn't make that clear in my original comment.
I'm not sure in how much detail you are interested, but the book has a (sub)chapter about the general idea: http://doc.rust-lang.org/nightly/book/ownership.html#move-semantics
You don't copy the objects (C++) or pass references around (Java, Python) but you move the content from one owner to another and invalidate the old owner. Unlike in C++ you have move by default and need to manually clone when you need it.
Yeah
You could clone the grid of mines, iterate over the clone, and mutate the original.
Well that seems inefficient, and besides that it simply creates the situation the borrow checker is there to stop: if the original changes the clone is no longer valid and you get bad data.
Most likely you can solve the iteration problem by splitting the algorithm into two phases: first, iterate and collect the required changes, and then apply the collected changes in the second iteration. Not enough info for me about GUI/Events so I won't comment about that. Note, that the primary memory management mechanism in Rust is Ownership, not Borrowing. Ownership is well suited for any kind of problem that can be described as transforming values into other kinds of values. For example, suggested double-iteration solution does exactly that: first, the cell data is transformed into the required changeset, and then, the changeset is applied to original cells. This kind of "pipeline building" can be used for wide variety of solutions. Most obvious are various kinds of parsers, compilers, streamers. However, the other kinds of solutions can also work in this model. For example, if the application configuration changes, you can simply think of it as "configuration stream" and recreate your application objects when that "stream" pushes a new value. The Borrowing system works hard to make sure that "the world" does not change under your feet. It is easy to forget that in Rust you are creating pointers to stack values in a way that would be very scary in C. Therefore, it is useful to think of a Borrow as a "temporary" thing. Because while something is borrowed, it can no longer be moved or changed, or mutably borrowed again. The following pattern might be helpful: use the ownership and move values into the place to "set the stage". Then, this "stage" can be used as an environment (which can be borrowed as needed) for some smaller work of moving other, more fine-grained values around. Likewise, these fine-grained values can also "set the stage" for some smaller work, and the pattern can be repeated.
Oh this is very cool. I am just learning Unity and working with Rust, so this is very interesting.
&gt; This raises the question of what value the fields of that this pointer have before the constructor finishes: in C++, the answer is just undefined behavior. Dismissing constructors out of use-before-initialization concerns strikes me as throwing the baby out with the bathwater. Consider the following C++ snippet: // at namespace scope, so we can declare first T f(T&amp; arg); T g(U&amp; arg); T h(V&amp; arg); T z(tuple&lt;T&amp;, U&amp;, V&amp;&gt; arg); extern T i; extern U j; extern V k; T i = f(i) + g(j) + h(k) + z(tie(i, j, k)); U j = …; V k = …; These are the horrors that C++ may or may not allow, depending on the details for `T`, `U`, `V`;`f`, `g`, `h`, `z`. It can get downright nasty but presumably that was not enough for Rust to avoid variable initialization altogether (can you imagine?). Now for each horror in our example before (non-comprehensive list: self-initialization, storage-before-lifetime-begins, zeroing-before-dynamic-init, order-of-initialization), pick out either the reason Rust avoids or supersedes it and apply it to the following: struct foo { T i; U j; V k; foo() : i(f(i) + g(j) + h(k) + z(*this)) , j(…) , k(…) {} }; And really that’s it for member-initialization (e.g. dynamic dispatch during construction being another story). The stuff inside the braces is a bonus where all the members (if not the whole `*this` super-object itself) are ready to go, no special conditions apply.
Sounds about right.
The `API restrictions, lifetimes, …` and `Verbose parts` parts are the direct consequence of Hyper/Iron using callbacks. In my opinion, callbacks are an anti-pattern in Rust, just like gotos and singletons in other languages for example. However with the lack of non-blocking I/O you have to open a thread for each client connection, and not using callbacks creates an overhead. For the record, I started writing [a small demo website](https://github.com/tomaka/example-tiny-http) using tiny-http to show people that the no-callbacks way is better (easier to write tests for, would instantly solve [the r2d2 issue](https://github.com/sfackler/r2d2/issues/11), more compile-time checks, etc.), but I really don't have time to work on webdev right now. 
The proper way would be to use a Cell if you want to do it all in one pass. It's not the only way (performing counting and mutation in two separate steps would also work). PS: here is a simple solution (without Cell): http://is.gd/B8TBe3
Nice article. I've been thinking of using Rust for my next hobby web project, too. &gt; Some things are just harder in Rust. Oh yeah. While I typically write JavaScript without having to think twice, writing Rust is quite the challenge. (I'm still not sure whether it's a challenge worth taking for small web stuff, but I'm sure I'll learn lot a lot doing it.) &gt; Another bad part is Rust’s JSON handling. It badly needs macros which make things easier. A crumb of comfort: The [_maplit_](http://bluss.github.io/maplit/doc/maplit/index.html) crate has a macro for creating BTreeMaps (among other collections). &gt; Weird interfaces I'm hoping to see some more abstract interfaces as well. Rust as a language should work well for making APIs without leaking too many implementation details. &gt; There’s no big ORM in Rust yet. I recently found [_Deuterium ORM_](https://github.com/deuterium-orm) (which also has a corresponding query builder), but I haven't tested it yet so I can't tell how useful/feature-complete this is. &gt; Then reading them back from results is only: &gt; &gt; rows.iter().map(|row| Event::from(&amp;row)).collect() I'm fairly certain this can be reduced to `rows.iter().map(Event::from).collect()`.
I'm not sure what you mean by no callbacks. Which part do you have in mind? In your example, it looks like the app holds the database itself and every route gets request + transaction + templates as parameters. While it solves the immediate issue, it doesn't look very extensible. I mean, what happens when I additionally need a queue, or 2 databases, or some external authN/Z? It looks like I'd have to change the signature of router itself. Please correct me if I'm missing something.
&gt;I'm fairly certain this can be reduced to &gt;`rows.iter().map(Event::from).collect()`. Does rust have currying or is that unique syntax for single argument functions and single parameter closures?
It's because `map` expects a function of one argument, and `Event::from` *is* a function of one argument. And the types line up. Everyone's happy!
I think you can use `as_ref()` or something after the `iter()` to get this behavior. But then I'm not sure it's not more verbose.
&gt; I recently found Deuterium ORM Added to the post, thank you!
Thank you. 
We've already got a lot of subtyping in the typechecker (for lifetimes) and it works quite well.
Thanks for pointing me in the right direction, I sweated a bit to clean up my code, but although the resulting code is more verbose it's also less unsafe... and no longer crashes!
Thanks for pointing me in the right direction, I sweated a bit to clean up my code, but although the resulting code is more verbose it's also less unsafe... and no longer crashes!
Yehuda has a really good Rust pitch that would fit. It goes something like this: the reason Node is so transformative is that it enabled a whole new group of people a new superpower: to write backend code. A lot of people who only did front end could easily do backend too. Rust is similar: due to its safety, it's going to enable a whole ton of people to do low-level programming who haven't even considered trying it, because C is terrifying. 
There's also the [json_macros](https://github.com/tomjakubowski/json_macros) crate, which I haven't tried but it came to mind immediately when I read that section.
Do you mean something like this: let t = ExCell::new(T); let x = ExCell::new(X); t.borrow(|mut_t| { x.borrow(|mut_x| { t.borrow(|mut_t2| /*boom*/) }) }); As far as I can see, that wouldn't be possible. `x.borrow`'s closure would contain an `&amp;ExCell&lt;T&gt;`, which is not `ExCellSafe&lt;T&gt;`, which would mean that `t.borrow`'s Closure would contain a closure which does not satisfy `ExCellSafe&lt;T&gt;`, so it wouldn't be allowed.
What is Derek Dryer working on in Rust?
No use after free without gc? Memory safety, speed
But then I'd have to *parse* the Rust source, glue adjacent comments together... *urgh*. This has the advantage of being really, stupidly simple to implement. :P Also, keep in mind that the whole *point* is to allow scripts that simply won't compile with rustc directly. If you don't need need a manifest, it should handle plain Rust source just fine. If you *do* need some dependencies... well, you're not likely to be compiling it with `rustc` alone, are you? :P But in all seriousness, if there's some consensus on a better way of going about this, I'll not be opposed.
Honestly I'm surprised that you don't get `-=` and `+=` for free when you implement Add and Sub.
[Working on a semantic model for unsafe Rust](http://www.reddit.com/r/rust/comments/37itqj/unsafe_rust_an_intro_and_open_questions/crnr5mi). I was surprised, too! (Actually, it seems like there is a cabal of researchers all over the world quietly working on extensions to Rust's type system).
Thanks!
Thanks, it's been corrected. The `SliceType` trait just hides away how something gets sliced. All I know is I give it a list and it returns a subset of that list. How it does it is completely hidden by the trait.
&gt; After a while I started to recognise which phase of compilation failed based on time-to-error (unknown names, wrong signatures, borrows, lifetimes, warnings) and that after 3 seconds or after any warning showed up, it’s only LLVM / linker / optimiser running and there will be no error anymore. I'm currently working on proposing a `cargo check` command which would forgo code generation altogether and just run the typechecker and friends, to better support workflows like this where you really just want the compiler to check your work, and don't care about actually building the crate. Given that LLVM codegen and linking are the vast majority of overall compilation time, this should have a profound effect on iteration speed.
[Features](http://doc.crates.io/manifest.html#the-[features]-section) as they work now should be additive. I.e. when activated not remove anything (if you need that, put the thing to remove under a feature, and have it as a default feature, then it can be removed by removing the feature). So they should keep things working and add features. Also bear in mind that if any crate in a build demands a feature, it will be enabled for all uses in that build. It sounds like it should be compatible with features, don't you think?
DLLs should work unless you're doing something strange. You'll need to make sure calling conventions and what not match up, but a C-API is a C-API, it's not like it's C++ or anything hairy like that.
For a very long time this was in the category of "should work but doesn't". Kids these days don't know how easy they have it! ;)
Maybe in this case I could talk about using Rust from other languages to speed up your code when you need it
Regarding PHP http://jaredonline.svbtle.com/creating-a-php-extension-in-rust
There are cases where `a += b` can be much cheaper than `a = a + b`. Think about adding a large matrix (element by element) to another large matrix in place, rather than allocating a new matrix for the sum and then destroying one of the arguments. In light of this problem and Rust's position as a low level performance sensitive language, it's important to allow overloading `+=` separately from `+`. But this is a can of worms, because there's no way to prove the definitions are compatible without something like dependent types. That might not be the end of the world, but it seems like a good enough reason not to stabilize the feature in Rust 1.0.0.
You can use [ffi](https://www.npmjs.com/package/ffi) to call into rust.
This should integrate with `cargo test` in some way, as you often want to run tests if the rest of the code compiles successfully.
I wrote a quick Vec2d struct that indexes into slices, so you can use v[x][y] but it's still a contiguous block of underlying storage.
I posted on the internals forum that I thought the toml should be in a doccomment in something like a \`\`\`Cargo ... \`\`\` block, and I really think that would be better than the current solution. Parsing markdown from doccomments with semantic code in blocks is a convention already established by rustdoc, introducing a new way seems very brittle. Even though you wouldn't compile this code with manual linking through `rustc`, it seems very important that you can. First, you wouldn't do it until the day that, for some weird reason, you have to. Second, if being incompatible with plain `rustc` is accepted from Day 1, on Day 1000 that incompatibility could be used as an excuse to have diverged fundamentally from standard Rust, which isn't the path this tool wants to go down I think.
Does RON handle Unicode?
And what makes this better than Elixir Term Syntax or Clojure's syntax? What fundamental difference is there in this that'll make people use it instead of JSON or YAML?
I'm actually working on an event library for rust right now. The idea is that the view and the model would live in separate threads and communicate by broadcasting (clonable) event objects. You write handlers that listen for events and update the view or model appropriately. In your case, the model would hold the board, and get events with the coordinate of the click. You can probably still use that approach even without any sort of event library. Finally, remember that most of the data structures in `std::sync` (e.g., `Mutex` and `RwLock`) only need *im*mutable references to access mutable copies of the data they hold. They're doing unsafe stuff under the covers, I'm sure, but they expose safe interfaces.
Is that `inspect`? &gt; Creates an iterator that calls a function with a reference to each element before yielding it. https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.inspect
Nope, `inspect` is really for debugging (it just executes a statement, like a `println!`, and then returns the element again, IIRC).
I mean, there's a difference between "Try avoiding foo and doing bar" and reading a bunch of code, thinking about it and comparing it to your code and then concluding that, "Oh, they didn't do foo, and instead did bar", eh? It's hard to se the higher level differences between two bits of code without looking at them carefully.
Wicked. I found [this](https://doc.rust-lang.org/book/traits.html#multiple-trait-bounds) in the rust book. Can this go out to any number of traits?
Networking is probably a good use case, yeah. ...but if you think its pretty slow, you really should look at some benchmarks. Its faster than the c++ UE4 engine by a significant margin. Especially now it uses the c# to c++ translater for builds. (ie. slow is relative. Its actually quite performant compared to other engines)
The format specification should be independent of the level of implementation. This is 2015, Unicode (and particularly native UTF-8) should be a *given*. 
No limit on number of trait bounds of generics, but you can [only have one non-builtin trait bound on a trait object](http://is.gd/R9evSA). I believe it is because otherwise you run into a multiple inheritance-like problem with the vtables in the trait object.
*Moooooom*, grandpa's telling one of his stories about how he had to walk to school both ways up hill in the summer while it snowed again. Can I go outside? (Wait a minute... that doesn't seem... contemporary...) *(The child ignores their wise elder, staring dead-eyed and listlessly at their phone. As their thumb flicks back and forth across the glass screen, their only hint of emotion is the infrequent, twitching motion that comes from typing "lol", their face a dead mask the whole time.)*
I agree, more or less. I just don't want to have to be the one to implement that. :P The less part is that being able to compile such scripts with `rustc` directly is important. I just cannot (at this time) convince myself that it is. This is a tool for things that literally *will not work* if you just feed them to `rustc`. That said, I did have a thought in bed last night that having `cargo script` function as a kind of archiver would be nifty; give it a Cargo package and it'll try to make a single file out of it. Give it a script, and you can ask it to "extract" it into a normal Cargo package (technically, it already does this, you just can't control *where* it does it). At that point, it's not about "this tool does magic things", it's just "this is an archive format specifically for Manifest+Rust that happens to be plain text". To me, at least, that seems perfectly reasonable.
&gt; This is a tool for things that literally will not work if you just feed them to rustc. I don't know what this could possibly be? `cargo build` doesn't do anything you couldn't do yourself with `rustc` and `curl`. It downloads dependencies from crates.io and then passes link flags to `rustc` so it can expand your `extern crate` declarations. It's always possible to pass rustc linking directives for projects managed by cargo rather than parsing the toml, and the same should be true for whatever format these scripts are saved in.
As far as I know, Python has basically no static type checking, whereas Rust's type system is somewhere north of C++. If they've ever had a function change type during development and then crash, they would understand. It's better to let the compiler catch those errors and save time.
Maybe I'm missing something critical ( or it's just late, and I'm a different topic :P), but what about using a specialized comment for `cargo script` meta data such as `//#` or `//@` which wouldn't hinder `rustc` at all. Of course this would require you specify all that data manually when using just `rustc`, but I don't see the issue with that.
I'm not saying that's a bad idea, merely that I don't see how it's at all necessary in practice. &gt; "Why not allow Rust to compile LOGO code?" &gt; &gt; Well, yes, OK, I can see that being useful in some limited circumstances... but how often are you *really* going to want to do that? No, I mean in actual *production* code. ... That's what I thought... 
I've been developing a web framework since rust 0.4. I use a `Shared` struct for thread-shared data, and a `Local` struct with an `Arc&lt;Shared&gt;` in it, and pass a mutable ref down to all the pages. I find it works well. Yes, I'm giving pages access to all the data, even if they don't need it, and maybe that's wrong. But the dispatch() function signature doesn't change: `pub fn dispatch&lt;'a&gt;(local: &amp;mut Local, path: String, response: Response&lt;'a,Fresh&gt;) -&gt; StatusCode` and I don't have lifetime or multi-borrow issues. 
`collect` *won't* allocate *anything* if the result of the `map` is `()`. `Vec&lt;()&gt;` is a vector of *zero-sized values*. *Because* they don't take any space, `Vec` never allocates any; it basically just turns into a counter.
But then what does it do here? It isn't impl'ed and the "slicing" is done by `Sliceable`'s impl.
&gt; Why not XXX? &gt; · if you know a better format, tell me! Why not S-expressions? 
As I've already expressed above, I think that being parseable by `rustc` is an important barrier to harmful feature creep ("rustc can't parse it anyway, what's wrong with adding this great feature that's good for scripts but incompatible with standard Rust"). While it may be easier to parse at the moment, what you've introduced is actually a preprocessor. Currently all you can do is define an inline Cargo.toml, but because your tool is philosophically a preprocessor, it can be extended to perform any transformation on the source code to turn it into valid Rust. That's a dangerous and powerful thing &amp; I wouldn't want to see it introduced when there are much less potent ways of inlining Cargo.toml data. It's also not that you *want* to use rustc, a purpose of cargo is to make calling rustc directly a very rare thing, but that sometimes you have no choice (e.g., cargo script has some corner case bug or won't let you pass some uncommon flag you need). The extra effort of writing a more complex parser will not, in the long run, outweigh the extra effort of everyone who has to modify their source file to run it directly with rustc "in production."
Is it the case that doccomments aren't parsed differently from other comments by rustc? Only rustdoc is aware of them? If so, then yeah, the most correct thing would be to introduce another specialized comment which, if they're at the head of a root file for a crate, would be read as cargo config data. I like `//#` myself.
Actually, I *believe* they *are* parsed differently: they're turned into `#[doc(...)]` annotations on the item, or somesuch. That's how they're persisted in the AST.
It does on my raspberry pi 2.
 let event_id = event_name .and_then({|name| Some(get_or_create_event(&amp;connection, &amp;name)) }) .and_then({|event| Some(event.event_id) }); Hm, this could be shorter, and those closure literals look a little bit too much like Ruby to me :) How about this? let event_id = event_name .map(|name| get_or_create_event(&amp;connection, &amp;name)) .map(|event| event.event_id); 
Sorry i know a few OS academics who have used VS , and think its the best IDE by a wide margin. The issue is windows is not a great platform for OS development as much of the tooling is better in Linux. re "Microsoft touched" seems very puerile .. all the great programmers I known are past that and use the right tools for the right job .
My bad, I was tired when I wrote that - thanks for correcting me.
I completely agree that adding additional preprocessing features would be a misfeature. My objection is a design objection that you open the door to the possibility of such features (including the ones you have already included!) by making the data your project uses incompatible with standard Rust. Making your files parseable by rustc would not require your project to parse them with libsyntax. Rust won't parse the inline toml anyway, all you need to do is change the condition that determines how much data to read as toml and then strip the comment marks from the front of each line.
That seems plausible. We already have a reflexive impl I think (from&lt;t&gt; for t), so it seems like it should be able to fit.
Could you link those benchmarks?
The community has already chosen a format to do configs in Cargo, and I don't see that changing anytime soon. I don't know what other projects use for configs, but TOML is probably a good bet anyway. Given what we have right now, it's not a bad idea for this RON format to not target configuration files. By excluding comments and focusing only to be a data interchange format, it simplifies its grammar and helps speed up parsing. Not everything has to do everything.
You can do let x: Box&lt;Error&gt; = Box::from("☺"); or let x: Box&lt;Error + Send + Sync&gt; = From::from("☺"); let y: Box&lt;Error&gt; = x; Is there any hope of ever being able to do let x: Box&lt;Error&gt; = From::from("☹"); ? It was quite confusing when I ran into it, and I'm wondering what the technical difficulties of supporting this kind of inference would be.
FWIW, you can do a `filter`/`count` instead of using a mutable `count` variable: http://is.gd/mPUwuh.
I have to agree on this point and it doesn't matter for me if there are only line comments (quite easy to skip while parsing). Being able to reference to data sources, in addition to the usual commenting, is a nice feature in a human readable data file and something I miss in JSON. Yes, you can put the sources in a separate file, but that's not as nice as keeping them close to the actual data. A separate file can, for example, get lost somewhere. That would be the only main feature I would miss here. It looks really good, otherwise, and being able to use types is what sold it to me.
You are my hero. I've been fighting for a couple weeks with trying to get a cross-compiler working targeting the Pi 2. I was following your guide (which is also fantastic), but kept getting hung up on my host running a different version of glibc than my Pi. Thanks for the 1.0.0 and nightly releases!
No, this is correct, it's just that the type parameters here default to Zero (https://github.com/Boddlnagg/units/blob/822ec0c9a1b3b0be7eb9934606c6d6774c8f32ee/src/lib.rs#L143). It probably could be done another way, but this worked, and it simplified another thing, namely the `type One = Unit;` alias, where all parameters are Zero. It's great that you are experimenting with macros now. :) Let's continue to inspire each other and find the best solutions, for the common good!
`'static` does not mean `static`. `'static` means that all contained lifetimes are `'static`, in other words, the type could potentially live forever. You can hold on to a `Vec&lt;T&gt;` or `Box&lt;T&gt;` as long as you want, moving it between functions and whatnot. You cannot do the same for `&amp;[T]` or `&amp;T` (also, `Vec&lt;&amp;T&gt;` and `Box&lt;&amp;T&gt;`, hence the comment about the inner type), because they are "borrowed" and have a limit past which they are not allowed to live, which is checked at compile time. I think I'd mentioned previously in the post that `'static` means no contained borrowed data. That's pretty much it here; `Vec&lt;T&gt;`/`Box&lt;T&gt;` don't contain any borrowed data unless `T` does; both types are owned. 
https://www.google.com/search?q=unity+vs+ue4+performance&amp;ie=utf-8&amp;oe=utf-8 It's not really a fair comparison though. The UE4 game engine is just, generally speaking, slow as balls. Kismet/Blueprints invoke a cost to execute every time you invoke one of the nodes, but even the C++ itself is crippled by their GC runtime and custom C++ reflection framework. Just download the engine and play with it, you'll see immediately what I mean. More seriously, http://www.codeproject.com/Articles/212856/Head-to-head-benchmark-Csharp-vs-NET is a fairly reasonable rundown. C++ is the master of fastness, but how they use the code in the engine makes a big difference.
excuse me, if this is a stupid question, but what will be the result? will rust eventually have *nominal subtyping* or *structural subtyping* or *row polymorphism*?
Beware that the `as` keyword allows overflows (checked at run-time, but still). It might be better to only `From`/`Into` for lossless conversions.
Yeah, this is one of the examples that made me wonder what was appropriate. What was the reason for this split into two crates (x11 and x11-dl), rather than a cargo feature? Does these two crates have a different API ?
Yeah, that's mostly what I think about all this. But... Just because I can't think about anything that could go wrong does not mean that nothing can go wrong... Better safe than sorry, hence my asking for confirmation. ^^"
You're trying to do something that is, at best, inconvenient in Rust. *Ideally*, `NbtTag` should be an enum. But, for reference, you *can* make this work, [as in this example](http://is.gd/dYeH4G). That said, there's no way to "restore the type information" like you seem to want. That would involve dynamic typing, which Rust does not, and likely *never will*, do.
"move semantics" is C++ terminology adopted by Rust. It means that by default, when a value is "used" (passed to a function for instance) it is neither shared (as in scheme) nor copied, it is moved (hence *move* semantics) into the operation, and the original owner can't use it anymore: http://is.gd/5gmNUz Of course this is only a default, it's possible to opt into different defaults: * references, which allow sharing (and use of a subset of all operations, namely those which don't need to own the value), also called *borrowing*: http://is.gd/iTSi3M (this is an immutable borrow, there are also mutable borrows which give access to a larger set of operations) * explicit copy via the `Clone` trait: http://is.gd/u205ca (the example uses automatic implementation, it could also be implemented by hand) * implicit copy via the `Copy` trait, opts the type itself into being copied by default instead of moved (note: `Copy` requires `Clone`): http://is.gd/IoNg97 that one is why you don't "lose" integers or references when you use them: they implement `Copy`. * more fancy forms of sharing like [Reference Counts](http://doc.rust-lang.org/std/rc/struct.Rc.html) and the like: http://is.gd/8tRgLV
x11 gives direct bindings to the functions in an extern block, but x11-dl defines a struct for each library (Xlib, Glx, etc.), which contains a pointer to each of the functions. Each library struct has an `open` function which returns a `Result`, so the user if the library can choose what to do at runtime if the library isn't found.
&gt; As far as I know, Python has basically no static type checking Interestingly, just this month it was announced that Python is going to [add optional type hints](https://mail.python.org/pipermail/python-dev/2015-May/140104.html).
There are single-line comments mentioned in README.
There are many: https://www.youtube.com/results?search_query=rust+programming+language &gt; About 1,650 results
Are there really people who prefer video to text for tutorials? If so, why? The things are common enough that I suppose there must be, but I've never understood it.
This is my number one pain point in json.
Eventually, yes.
Agreed. I mean, listening to someone talk is arguably as good as text to me. But reading code in a youtube video... Meh. On the other hand, there are videos from conferences about rust that can make a good introduction to the language. I find conferences videos in general to be an interesting watch, but I too miss the point of video tutorials. I don't know, I guess some people would simply rather listen than read.
If "NBTTag should be an enum", then it has problem: https://github.com/PistonDevelopers/hematite_server/blob/master/hem-nbt/lib.rs#L99 I am solving that so never has "HeterogeneousList" problem when rustc compiling. It should has a way to "restore" original type.
`List(Vec&lt;NbtValue&gt;)` was a mistake IMO, someone switched to that from my nice [List enum](https://github.com/PistonDevelopers/hematite/blob/master/src/minecraft/nbt.rs#L70-L84). I haven't been able to help out with the design and implementation, so I can't complain too much, but it makes me sad when the *right* design isn't chosen because of ergonomics, without exploring improvements for the latter. More to the point, you can still have that `List` enum *and* provide an iterator over `Nbt` values (or trait objects). Although most of the time you know the element type of the list you're working with, so expanding on [typed access methods](https://github.com/PistonDevelopers/hematite/blob/master/src/minecraft/nbt.rs#L129) would be beneficial.
Rust style would be `is_mine` and `is_clicked`, by the way.
http://doc.rust-lang.org/std/fs/index.html &lt;-
&gt; But this is a can of worms, because there's no way to prove the definitions are compatible without something like dependent types. There is no way to prove eq and ne are compatible, either. Or that `a + b` is the same as `a - -b`
That page doesn't contain any file IO stuff as far as I can tell:) It's more about handling files and directories. Did you just want to link to the official docs? Anyway, I think the closest thing to read() is the read() from the Read trait which is implemented for File. Links: [File](http://doc.rust-lang.org/std/fs/struct.File.html) [Read](http://doc.rust-lang.org/std/io/trait.Read.html#method.read)
Well, doing file IO starts with Files. Once have a [`File`](http://doc.rust-lang.org/std/fs/struct.File.html), the examples right there show basic IO. I agree there could be more, if you ask about something specific, we can work up an example. Ugh, the new subreddit style doesn't show that File is a link there. Here it is http://doc.rust-lang.org/std/fs/struct.File.html
It shows fine for me, what browser/client are you using?
Oops, totally forgot this isn't Haskell :p
This is my one "fear" about introducing down-casting in Rust: that suddenly people stop thinking and just copy nilly-willy all those OO examples they've seen in Java. On the one hand, I guess it is "efficient" in that one does not have to agonize over choices, but the perfectionist in me is always dissatisfied with such decisions.
Thanks for putting a name to functor modules for me. In JS, rather than AMD/CommonJS I've recently started just exporting plain functions parametrized by maps of what would normally have been require statements. Mocking dependencies without magic (see: [Jest](https://facebook.github.io/jest/)), transparent sync/async module loading, and dependency injection without polluting (actually non-existent) constructors became way simpler. Dead-simple but powerful concept.
Hey, I wrote a [how-to](https://github.com/japaric/rust-on-openwrt) on the topic. You may find it useful! Let me know if you encounter any difficulties. P.S. I started a new reddit thread on this topic [here](http://www.reddit.com/r/rust/comments/38052i/howto_rust_on_openwrt_cross_compiling_to)
Someone asked about this topic earlier this week, and since it was it my "itches to scratch" list. I decided to give it a go and post a how-to. Hope you find it useful, it has some general information about cross compiling with Rust. 
That's really awesome to see it working! I tried to get it running on OpenWRT about a year ago or so, and encountered some [weird, weird issues.](http://www.reddit.com/r/rust/comments/2c821g/getting_rust_running_on_mips_llvm_code_generation/)
Nice! Home routers usually have an admin interface written in C and bash. You can guess how secure that is, and how often they get patched in the real world. As a bonus, the attack surface is exposed to the entire Internet, because any Web site can make cross origin requests (even if they can't inspect the result). Rust has huge potential in this space. A single language that can do the low level system config *and* the web interface, with memory safety, static checks against XSS and the like, and a modern web app development experience. And this all compiles down to a lightweight self-contained executable with its own embedded HTTP server.
(Your first image link is the same as the second)
I've never heard of it before. :/
You might have a buggy version of Source Code Pro installed on your machine.
They look different to me with the latest chrome (chrome 43)
&gt; and encountered some weird, weird issues. That's odd. I tried an updated version of your [xchg snippet](https://gist.github.com/japaric/10848f9e76b751d27df5#file-xchg-rs) and it runs fine on my router. The output of objdump and emit=asm also agree. Perhaps it was some bug in LLVM's backend that has already been fixed?
Do you have a profiler?
Nice! If something along these lines gets mainlined into the standard library it would be a major selling point for Rust, IMHO. This is something really fundamental, and it would be really nice to have it "just work" across library boundaries.
`&amp;&amp;` is bold in syntax hilighting and `&amp;` is not.
Can't test my theory without my computer but I assume this is just following the C semantics in stdio. You need to specify an address so the system knows what interface to use, in the case you had multiple nic's and multiple networks. A "0.0.0.0" will bind to all nic's. All IP packets need a src port. A higher level library might pick a rare high level port and retry if busy.
Probably no, for used-defined types everything goes. As soon as you allow overloadable operators, they become just like regular functions.
I thought I merged it a week ago?
Even in C you typically need a bit of assembly to kickstart everything. I'm looking at trying to teach rustc to target the PE+ format that (U)EFI loads. Building libcore under that target should let us build something that runs directly after boot and save a whole load of tedious mucking about. I'm hoping I only need to create the right target.json, but no success so far. Hopefully I'm just using the wrong settings in it. If anyone has any insight please comment! :-)
nalgebra's `Vec2` takes a parameter for the inner type. Imports import the symbol `Vec2`, so you need not touch those; but in the function definition you want to use `Vec2&lt;f64&gt;`.
BTW, it is better to use pointer conversions instead of `transmute`s: let base = self as *const _ as *const u8; ... base.offset(...) as *mut _ as *mut (); This way it is harder to accidentally make a mistake and transmute unrelated types.
You should be able to work around this currently if you're willing to spawn a new thread. You can block in the separate thread and use channels to simulate your proposed `status` or `check` methods. (I'm not saying we shouldn't have a `status`/`check` method though!)
Is there a way to forbid somebody from implementing a trait for my type? Say I have a type that can be Clone, but for which Clone doesn't make sense. I can write a comment saying: "even tho you could derive Clone for this type, please don't do that". Is there a way to avoid that comment and enforce it at compile time? #[neverDerives(Clone)] struct A { ... } 
clang has `-fsyntax-only`, does rustc have an equivalent option?
Perhaps someone should throw together a wiki page for unofficial builds, there's quite a few popping up for different platforms.
&gt; If such a user sees a compiler error "use of undeclared type name int", they'll naturally be lead to the guide Confusingly I was lead here 
In this instance, there is no higher level library to pick a "rare high level port". By default (and in the C example above), the OS itself picks an unused port (a so-called [Ephemeral Port](http://en.wikipedia.org/wiki/Ephemeral_port)) to use. Later one can query the socket's bound address with `getsockname`.
In case of eq/ne, what you could do instead is create an opt-in mechanism that limits the trait to **exactly one** custom implementation. Either define eq and have automatic ne, or vice versa.
Why not [hocon](https://github.com/typesafehub/config)?
Well, in the case of Eq, that would be possible. In the case of PartialEq, there may well be elements for which `x == y` *and* `x != y` should return `false` (in lieu of a don't-know value). Update: submitted issue to rust-clippy.
Any tool that works for C or C++ should work for Rust as well. You should be able to use perf, cachegrind, instruments, etc. There's also the `bench` attribute for benchmarking your code.
So if I have trait A in module a, and type B in module b, i can implement A for B in a different module c only if module b does not import module a (i.e. if trait A is not visible in module b)?
Erm, PartialEq returns `Option&lt;bool&gt;`, I think. So in case of *don't-know* it should return `None`, for both eq and ne.
For historical purposes, just adding a comment here to say that I never filed a bug on the segfault with lto turned on because shortly afterward, I updated to another nightly and the problem had been fixed.
It is safer because of baked memory safety - to my knowledge, unless your code is in an unsafe block, it is very very hard (impossible) to segfault the program. The language itself is also designed to reduce ambiguity as much as possible, from the naming scheme to the forced curly braces for one liners on if-expressions. It is generally much faster than python or java (notwithstanding some edge cases) because it compiles natively - it's compiled by llvm, the same backend that powers clang. Thread safety is a fortunate consequence of the ownership and borrowing functionality that drives memory safety. There is no shared mutable state. There is a lot of other cool stuff, too. I've fallen in love with the algebraic data types and match expressions, especially that they completely eliminate the need for exceptions. I'm not into the language enough yet to give a short and sweet description of the personality this language has, but it feels like it is trying as hard as it possibly can to make sure I don't shoot myself in the foot, and while it takes some getting used to, the cruelty of the compiler starts to seem helpful instead of scornful. 
&gt; There is no shared mutable state. Well, there's no _unsafe_ shared mutable state. Like, a `Arc&lt;Mutex&lt;T&gt;&gt;` is still shared mutable state in a sense, just access is a bit more controlled.
I'm working on code that needs one more level down - the ability to deal with children in a way that handles things like wait_all, NOASYNC, and signal handling. I'm happy to write a patch, but the question is what shape should it take - to make it in to core, does it need to be cross-platform? Is the right place to innovate here in a crate?
I would actually be happy if I could just extract the PID from a process that has been spawned, so I can drop down to the lower level abstraction. 
Kind of off topic, what would you say is your favorite resource for reading about concurrency in general? It is probably my weakest programming skill, and while I really would like to try it in Rust, I feel as though I should have a decent understanding first. 
&gt; safer This means several things. It's safer than directly competing languages like C++ because working without a garbage collector is normally very dangerous. Rust is saying it gives you *memory safety* without a GC. Java and Python use GCs so are already "safe" in this regard. The cost is that you have to use a GC, the benefit is that it's easier. The other reason is Rust's much stronger type system - this is a real advantage (and disadvantage) over Java and Python. For example, option types instead of exceptions or `null` makes it easy to deal with all errors (but, sadly, hard to ignore them!). Rust also makes you deal with things like string strangeness upfront - Python and Java both largely ignore the intricacies you get with different platforms. There are many more examples, I'm sure. &gt; faster Java's raw throughput is rather good, but it's greatly limited by its inability to let you control memory layout and the really fine-grained details that low-level programmers like. There's a reason games are written in C++. &gt; better multi-threading support Basically, Rust prevents **memory** races in safe code. This is a particularly gnarly problem in multi-threading. This static guarantee means that it's easier to do more dangerous stuff without getting fatally wounded. --- Rust is **not** a great alternative to Python for stuff Python is good at. It **is** a great alternative for when you need all three of * memory safety * speed * determinism C++ gives you speed and determinism. Java gives you decent speed and memory safety. Even when you're OK dropping safety, it's often the case that Rust is simply nicer to write than the alternatives.
Just using `match`: data.into_iter().fold(None, |m, x| { match m { Some(m) if m &lt; x =&gt; Some(m), _ =&gt; Some(x) } })
`fold` makes my brain hurt. :-) Can you explain why it returns `None` if the iterator is empty?
But it prevents most of the one-shot shellcode options that exploit memory safety. Which, as a side node, covers nearly every single "Critical" security bulletin from Microsoft. Though there's probably some routers out there that'll take a URL to an arbitrary binary and just download and run it.
The first parameter of fold is the initial value of the accumulator, and it is the value returned when the iterator is empty. The closure combines the accumulator with the "next" value of the iterator, giving a new value to the accumulator. A fold just consumes the whole iterator and returns the last value of the accumulator.
Yeah, yeah, I'm not denying all that. Just that being overly optimistic that all rust code you write is unexploitable can be dangerously naive.
Compiles natively does make program start up time much faster. Instead of needing to initialize a JIT or interpreter, you just run the already compiled code. This gives Rust an advantage for writing things like terminal commands which need to execute immediately. 
Yeah, binding to port 0 assigns one automatically, the same as sendto without a bind.
/u/pcwalton tells me that the CPU profiler from gperftools (https://code.google.com/p/gperftools/) works just fine with Rust on Linux.
Oops, I just checked and the comparison should be `m &lt; Some(&amp;x)`. The reason the `None` branch isn't `Some(x)` is because it would move `x`. Addressing both of those issues, here's a third version: data.into_iter().fold(None, |m, x| { if m &lt; Some(&amp;x) { m.or(Some(x)) } else { Some(x) } }) I... I don't like it very much. A `filter` method on `Option` could help, I guess.
No, according to the [docs](http://doc.rust-lang.org/std/cmp/trait.PartialEq.html): &gt; `ne` must respect the rule that `eq` is a strict inverse of `ne`; that is, `!(a == b)` if and only if `a != b`.
&gt; Does that mean that if you have Some(x) inside one branch of an if, you have to have it in the other branch as well, so that the move is unconditional? No, the borrow checker will just treat the value as moved after the conditional expression even if it isn't moved in all branches. Even if the branch its moved in is `if false`, because the borrow checker doesn't do any evaluation.
This is an article covering a bunch of the work zmike has been doing with our CEF / embedding support. It also has some quick videos of parts of the demos we'll be showing at LinuxCon Japan and the Mozilla JP office for the Rust Samurai this week in Tokyo!
I've never seen a font bug like that!! You win the found-a-new-and-interesting-way-computers-are-horrible award of the day.
`std::process::Child` has an `id() -&gt; u32` method that's only unstable because it's new.
`vector_elements[i]` if you know the element is there, because it will panic if it's not. Details: `Vec` impls `Index&lt;usize&gt;`, which means you can provide a `i: usize` using the `[i]` syntax. `vector_elements.get(i)` if you aren't sure the element is there, because it will return an `Option&lt;&amp;f64&gt;`. This is in [Vec's docs](http://doc.rust-lang.org/std/vec/struct.Vec.html).
The right hand side of the `A + B` (that is, `B`) must be an &amp;str, so you can either do `A + &amp;B` or just do `A + "B"` if your right hand side is known at compile time. The semantics here help make it explicit that you're not handing B (which is a String in your example) by value (aka moving) to the addition operation.
When String implements the Add trait it declares the type of the item to be added as &amp;str. impl&lt;'a&gt; Add&lt;&amp;'a str&gt; for String So, basically you do: let s1 = "Hello".to_string(); let s2 = " World"; let s = s1 + s2; //s is a String 
`push_str()` is also available: let mut a : String = "A".into(); let b : String = "B".into(); a.push_str(&amp;b); Still requires the borrow (`&amp;`) either way though.
&gt; Do you agree that the standard library should aggressively deprecate APIs for consistency? Yes &gt;Do you think the ability of supporting older Rust versions is important? Yes The standard lib should be improved if possible, deprecating seems like the way to go - improvements and still backwards compatible in Rust 1.x.
Oh nice, he works on my favorite desktop environment
I might be misunderstanding what you are looking for, but do you want [`as_ref`](http://is.gd/PCSQ5e)?
I'd prefer instead: * Take more time for design and testing before sabilizing an interface. Do not hastily rush design like before the Rust 1.0 release. * Do not deprecate for cosmetic reasons. We're not in a beauty contest, we're an engineering project that has to be long-time dependable.
I'm still wondering what's the value proposition of Servo? It's obviously cool, but Mozilla wouldn't be pouring in the big bucks if they didn't expect something to come out of it.
I wouldn't say callbacks are an anti pattern. However, I'd be interested to see what you mean that an iterator provides more compiler time checks. 