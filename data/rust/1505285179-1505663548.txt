I feel like i should really look into the generics and traits system of rust to get further then just a beginner level of understanding rust.
All 7 crates.
There are two sides of the lifetime coin: - borrow analysis - type annotation The first is a variation on liveness analysis. It pays attention to control flow and attaches restrictions on paths. So what the heck is a path? Anything you can build by starting with a local variable name and adding either fields or derefs to. `*(local.field1).field2` is a particularly hairy example. If you borrow it uniquely that will also put a shared borrow on the ancestors: `*(local.field1)` `local.field1` `local` A path describes step by step how to calculate the address of a location. Start with the current stack frame pointer, add an offset to `local`, offset to `field1`, load the pointer you find there, offset to `field2`. (Notes: A- the "load address" operation may be overloaded, but the borrow checker doesn't need to know this detail. B- the compiler has a pretty good idea when this operation is required so you would actually write `local.field1.field2` - unless using raw pointers.) The other side of the coin is type checking. This ensures that a reference value can't escape to a longer lifetime. What makes lifetimes as types opaque is that the only times you can use lifetime annotations are when composing types and creating function or trait signatures. It's not even optional: you can't name a scope and use that name as a type annotation. (So good riddance to scoped lifetimes.) Another term I would like to see is "unborrowed" -- the language calls this `'static`. Since "unborrowed" is a subtype of data in general "borrowed" is clearer in contrast to it. A struct with one or more lifetime parameter is "borrowed by nature" or "ephemeral." However, a concrete type derived from it may be unborrowed if the lifetime is `'static` so perhaps that's not the best nomenclature. The lifetime bounds in a function signature place restrictions on the caller. This is the same role as any other type information, but it helps to repeat this point. I say a method "locks" an argument if it places an "argument must outlive result" constraint on its callers. I prefer to think "unique" in many/most places where Rust uses `mut`. In particular `&amp;mut` is the unique borrow operator. "Shared mutability" is better than "inner mutability". Any type or interface that allows shared mutability is a "cell", which also means the order of execution may impact the result. Even `Mutex` - it imposes before-after ordering, but threads still "race" to lock it.
This library is not on crates.io. It is built with CMake currenlty, so it cannot be on crates.io until a Cargo.toml file is created. This approach is not related to rust-qt. This is approach the other way around. rust-qt aims to let you call qt from rust. These bindings will let you call rust code from Qt. Indeed, I meant build.rs. Sorry for the disturbing filename.
Having this whole process in cargo would be wonderful. However I do not feel like supporting cross-platform building of these bindings. That is why I leave it to the user so tie it to a build system. I can imagine crates that build on this tool to make it easier to use.
Very cool - Seems like they agree with you, too! &gt; We hope to see future language support for the great languages out there including Rust, Go, Python, etc.
This is suspiciously similar to [this post](https://www.reddit.com/r/unix/comments/6gxduc/how_is_gnu_yes_so_fast/?st=j3v3iw3c&amp;sh=5651ea3c) :P
I think more info is on https://docs.rs/crate/sapper/0.1.0 :)
Awesome! In the meantime, I figured out that I can look at clippy's [Travis CI page](https://travis-ci.org/rust-lang-nursery/rust-clippy) and, for example, check [the Linux build job](https://travis-ci.org/rust-lang-nursery/rust-clippy/jobs/274822068) to see which nightly I have to roll back to.
It is not 100% clear to me, but the ATC RFC says: &gt; this RFC proposes adding ATCs of types as well: &gt; &gt; trait Foo { &gt; type Bar&lt;T&gt;; &gt; } and shows: &gt; trait PointerFamily { &gt; type Pointer&lt;T&gt;: Deref&lt;Target = T&gt;; &gt; fn new&lt;T&gt;(value: T) -&gt; Self::Pointer&lt;T&gt;; &gt; } which is very similar to `Functor`. Invoking /u/desiringmachines
This post shows a huge issue with the current state of `std::Iterator` on stable Rust: the only way to eagerly consume an iterator, e.g., for its side-effects, on stable Rust is to call `.collect` or `.count` (`.for_each` is nightly only). Most beginners don't associate `.count` with this, so they use `.collect`, which is horrible. The author says: &gt;The Bencher crate will test everything in the function so we want to make sure we're not loading or creating data in the function or our test results will be off: but then proceeds to call `.collect()` in the `iter_closure` method "creating data". Does the author belives that `.collect()` eagerly evaluates an iterator for its side-effects? `.collect()` does this, but it also allocates a new vector on the heap, copying the results from the old vector into the new one, which the benchmarks show is 2x slower for all sizes!(*) This slowdown has nothing to do with "closures", and all to do with the call to `.collect`. I really don't know how many Rust users are using `.collect()` incorrectly introducing 2x slowdowns into their programs, but... if there are many people doing this, there are many things that we could do: - make `.collect`'s result `#[must_use]`. If you are throwing `.collect`'s result away, you are doing it wrong, and should not have used `.collect` in the first place. A loop or `.for_each` would do. - make `.count` result `#[must_use]`: while `.count` is "efficent" (when compared to `.collect`) it doesn't convey what the code is actually doing - add an `.eval() == .for_each(|_|)`: because `.for_each(|_|)` is also ugly, maybe stabilize `.for_each` as well. - address this in the book: `.collect` means copy the results of the iterator into a collection, not "eagerly evaluate", or similar - add warnings in rustc/clippy for throwing `.collect`'s / `.count`'s result away in case we cannot break backwards compatibility over this, but we should do so in the next epoch, in particular new users should not be allowed to learn bad idioms. (*) /u/stjepang explanation works here perfectly, the `.collect` call introdes a 2x slowdown because it doubles the memory of the problem. Since the benchmark is bandwidth limited, it slows down by a 2x factor. 
Yes!! Thank you!
&gt; '_ We need some C++ flavor: `'auto`.
&gt; Shouldn't the parallel version be around 4 times faster It doesn't work that way. 2.5..3 is the best.
To me the question is do we really need these other options? The example with no elision at all is much more clear to me and not so verbose.
To lazy to google: How can I have both nightly and stable installed at the same time (Mac) - and easily switch between them. Is there any need to "make clean" when I switch versions of Rust?
The compiler claims that x outlives y. But if I call the function like this: ``` let y = 42u; { let mut v = vec![]; foo(&amp;mut v, &amp;y); } ``` then this is a lie. The problem isn't that x actually outlives y, it's that the compiler cannot prove that it doesn't. Thus the wording is confusing.
I'd suggest using [this](https://github.com/Darksonn/backblaze-b2-rs), our code is very specialized, and only implements the calls we need.
To understand how Rust is performing for such tasks we need to take his solution and rewrite it Rust. And then answer three questions: 1) Is the performance still the same or better/worse? 2) Is the code safe, or is it requires unsafe blocks in every function? 3) Was it easier to write? Did you have to write less code/more code? I'm afraid the current Rust will fail on this questions, that's why people would still prefer C++/Go for such contests.
Yep, assuming you installed Rust via [rustup](https://www.rustup.rs/). To install both stable and nightly toolchains: rustup install stable nightly And to switch between them: rustup default stable rustup default nightly To specify a toolchain without changing the default: cargo +nightly run
Might be better to compare `vec_closure(&amp;small_vec)` to `vec_iter(&amp;mut small_vec.clone())`.
Atom w/ rust linter is already pretty good. Can't wait to see Atom as a Rust IDE!
It doesn't work that way at all when CPU time is negligible compared to RAM time. Read the post you replied to again.
Great. Sorry for the limited interest; I've happily been using [pass](https://www.passwordstore.org/) for a while now.
I'd be sure only when I see actual code. 1. Lowlevel async IO can be achieved with https://crates.io/crates/mio. 2. Parsing of request and generation of response shouldn't differ that much. 3. For unsynchronized data storage, it'll definitely require some unsafe things. As for your concerns, I've tried to write polite counter-arguments, but got only zealous flame on my side. So maybe later.
&gt; references &amp;T, which signify *a temporarily borrowed value of type T* I'm sure I've read that before and it's really darn misleading. `&amp;T` is a sized address of a borrowed *location* of type T. You cannot borrow a value, only a location. If you write something like `&amp;(a + b)` it will compile, but it means that the temporary location is borrowed. This most often happens with chained method calls. --- &gt; [meaningful lifetime parameters] I'm experimenting with a style guideline that lifetimes are named using participles such as `'locked` or `'iterating`. Please not `'vec` - that doesn't mean anything! Passive participles like "locked" should be read as progressive passive "being locked". This is a limitation of English. This parallels another rule that fields and getters are nouns and other methods or functions are verbs or prepositions. So I don't put `TBuilder::new()` in an API but `T::build()`. It seems to work well so far, but exact rules for when to be explicit and when to abbreviate just to satisfy the compiler. `impl` in particular is a good candidate for abbreviation and elision. To give a more concrete example, the `entry` protocol would have signatures like these: Map::at_entry&lt;&amp;mut self, key: K&gt; -&gt; AtEntry&lt;'selected, K, V&gt; Selects an entry for in-place modification. AtEntry::Occupied::get_mut(&amp;mut self) -&gt; &amp;'editing mut V where 'editing: 'selected Uniquely borrow the value at an occupied entry. AtEntry::Vacant::insert_get_mut(self, value: V) -&gt; &amp;'selected mut V Insert a value at a vacant entry and borrow it uniquely. I like what this RFC does in general. `'_` may look ugly, but it's nice to have an antonym for `'static` 
Can't try it out now, but just from looking at the source: when I clone bimap, do insertion and removal operations still work? Because Rcs should just have their reference counts increased, and then unwrapping them shouldn't work, right? 
The results as posted are fairly uninteresting apart from the parallel results: the map version allocates a new vector then throws it away, of course it is slower. I'm more intrigued by the conclusion the author drew that are not evident from the data: &gt; Turns out the answer is it depends! Normally I'm dealing with bytes (so u8) and doing fairly easy math over a vector and .iter() is slightly faster; however anything more complex a closure is the Rust way and faster. At which point should we move from for-loops to using iterators? why is this faster?
Video is at https://vimeo.com/105852957 and site at https://github.com/lihaoyi/workbench look at live reloading section. It obviously has limitations but still fun to mess with.
Found that the [evmap](https://crates.io/crates/evmap) crate seems to do exactly this.
To me `'_` looks like a "wildcard" that could be anything (so an unbound lifetime like `fn blah&lt;'a&gt;(&amp;self) -&gt; Struct&lt;'a&gt;`), not "what elision would do".
It's literally just Atom with a very slightly different UI (provided by an extension) plus another extension or two. I really don't understand what the big deal is? To me, it doesn't seem like this announcement has any real substance.
This is my first attempt at FFI in rust and first time publishing a library too :) Oh, and by the way, feel free to review the code: [github](https://github.com/ndesh26/evdev-rs) 
By not using the full name as salt you make it possible to launch offline attacks against all users at the same time. It will be possible to build rainbow tables, making it less secure than traditional password managers. Users with the same master password will have identical passwords for all sites. You could fix this by adding a randomly generated secret to the config and using the secret as salt.
People naming their lifetimes `'a` and `'b` grind my gears too, but the mixing of separate namespaces was not worth it, and in the long run would make lifetimes less clear.
A logging utility like [cyclog](https://jdebp.eu/Softwares/nosh/guide/cyclog.html) but a bit less weird. Use UTC timestamps and ISO time formats, don't make log files executable (WTF), don't put @ in filenames. This is something i've been meaning to get round to writing for ages, because i could make use of it myself (instead of doing logging by redirecting standard output to a file, like a caveman). If someone else writes it before i do, even better!
I mean, I think you're describing [a rental](https://crates.io/crates/rental), or possibly something a little more intense. I just don't see the advantage of having a bunch of aliasing pointers. If you're using transmute, you're almost certainly going to shoot yourself in the foot. it's not a good solution here. Honestly, you could just store the data in owned Vecs for each section. Unless you have hundreds of sections, which would be unwieldy to manipulate with handwritten code anyways, you could literally use `Vec::split_off` to work through the data and create a `Vec` for each section. Copying bytes around isn't that expensive in most applications, especially when you're doing it as few times as you're likely to here. I mean, how many sections can you have if you're planning to manually create a field in the struct for each one? Fortunately, in Rust, you don't even need to do something as slightly wasteful as that, since you could use a small stack cache to hold bytes from the file as you read them, determine which section they go into, and then push them into the corresponding Vec. Depending on how much information the Header gives you, you could even pre-allocate those Vecs to the right capacity after the Header. When you're reading data from disk, it gets copied _somewhere_, it might as well be copied into distinct, owned Vecs rather than a bunch of potentially aliased pointers with transmuted lifetimes that could be way wrong, leading to dangling pointers and other wonderful things.. I would prioritize safety over performance until you determine that you _must_ have better performance than what you're measuring. The Rust compiler (thanks to LLVM) does a fantastic job of making code fast, in my opinion. But, plenty of people have written libraries to manipulate a given file format in Rust. Have you looked at their work?
On the contrary, i've seen benchmarks showing that blocking IO is *faster* below some critical number of threads (10 - 100). If you are building a system with a small number of clients where latency matters (a single-instance game server, an audioconferencing server, an algorithmic trading system), blocking IO might well be faster. "Async IO is faster" is 2017's "schemaless is easier". 
You didn't, but you replied defensively to a critique of a blog post which did: &gt; But if we want to support a high performance service, such as a database, Sync is not enough.
&gt; I just don't see the advantage of having a bunch of aliasing pointers. I'm taking alternative solutions but when working with complex data there are very few alternatives. In particular right now I work with `gimli` and `goblin` and both libraries have an obsession with borrowing data. Unless I want to parse this data over and over there are not many alternatives.
I've been wondering how the convention of using single character names for lifetimes came to be. It's seems to be about as useful for understanding their purpose as single character generic parameters... or single character function arguments. Would it be worthwhile to lint against these, so as to encourage better naming?
Just generating the salt with the hash and storing it alongside it is pretty traditional. Every user should have a unique salt. What you're describing seems more like a pepper where it's global and stored separately.
There is no big deal but since atom-ide supports the LS protocol theoretically there should be less work required to port the RLS to it than to target another IDE.
You're welcome :)
I get a lot of requests, but they all look like this: IP &lt;B2IP&gt;.rdns.backblaze.com.https &gt; &lt;ME&gt;.&lt;PORT&gt;: Flags [P.], seq 3969226027:3969227520, ack 915833261, win 1452, options [nop,nop,TS val 38355559 ecr 3871642719], length 1493 IP &lt;ME&gt;.&lt;PORT&gt; &gt; &lt;B2IP&gt;.rdns.backblaze.com.https: Flags [.], ack 1493, win 1438, options [nop,nop,TS val 3871643099 ecr 38355559], length 0 IP &lt;ME&gt;.&lt;PORT&gt; &gt; &lt;B2IP&gt;.rdns.backblaze.com.https: Flags [P.], seq 1:294, ack 1493, win 1444, options [nop,nop,TS val 3871643129 ecr 38355559], length 293 IP &lt;B2IP&gt;.rdns.backblaze.com.https &gt; &lt;ME&gt;.&lt;PORT&gt;: Flags [.], ack 294, win 1451, options [nop,nop,TS val 38355650 ecr 3871643129], length 0 IP &lt;B2IP&gt;.rdns.backblaze.com.https &gt; &lt;ME&gt;.&lt;PORT&gt;: Flags [P.], seq 1493:2986, ack 294, win 1452, options [nop,nop,TS val 38355711 ecr 3871643129], length 1493 IP &lt;ME&gt;.&lt;PORT&gt; &gt; &lt;B2IP&gt;.rdns.backblaze.com.https: Flags [.], ack 2986, win 1438, options [nop,nop,TS val 3871643251 ecr 38355711], length 0 IP &lt;ME&gt;.&lt;PORT&gt; &gt; &lt;B2IP&gt;.rdns.backblaze.com.https: Flags [P.], seq 294:587, ack 2986, win 1444, options [nop,nop,TS val 3871643258 ecr 38355711], length 293 IP &lt;B2IP&gt;.rdns.backblaze.com.https &gt; &lt;ME&gt;.&lt;PORT&gt;: Flags [.], ack 587, win 1451, options [nop,nop,TS val 38355780 ecr 3871643258], length 0 IP &lt;B2IP&gt;.rdns.backblaze.com.https &gt; &lt;ME&gt;.&lt;PORT&gt;: Flags [P.], seq 2986:4479, ack 587, win 1452, options [nop,nop,TS val 38356163 ecr 3871643258], length 1493 IP &lt;ME&gt;.&lt;PORT&gt; &gt; &lt;B2IP&gt;.rdns.backblaze.com.https: Flags [.], ack 4479, win 1438, options [nop,nop,TS val 3871643704 ecr 38356163], length 0 IP &lt;ME&gt;.&lt;PORT&gt; &gt; &lt;B2IP&gt;.rdns.backblaze.com.https: Flags [P.], seq 587:880, ack 4479, win 1444, options [nop,nop,TS val 3871643709 ecr 38356163], length 293 IP &lt;B2IP&gt;.rdns.backblaze.com.https &gt; &lt;ME&gt;.&lt;PORT&gt;: Flags [.], ack 880, win 1451, options [nop,nop,TS val 38356229 ecr 3871643709], length 0 IP &lt;B2IP&gt;.rdns.backblaze.com.https &gt; &lt;ME&gt;.&lt;PORT&gt;: Flags [P.], seq 4479:5972, ack 880, win 1452, options [nop,nop,TS val 38356370 ecr 3871643709], length 1493 IP &lt;ME&gt;.&lt;PORT&gt; &gt; &lt;B2IP&gt;.rdns.backblaze.com.https: Flags [.], ack 5972, win 1438, options [nop,nop,TS val 3871643910 ecr 38356370], length 0 IP &lt;ME&gt;.&lt;PORT&gt; &gt; &lt;B2IP&gt;.rdns.backblaze.com.https: Flags [P.], seq 880:1173, ack 5972, win 1444, options [nop,nop,TS val 3871643917 ecr 38356370], length 293 IP &lt;B2IP&gt;.rdns.backblaze.com.https &gt; &lt;ME&gt;.&lt;PORT&gt;: Flags [.], ack 1173, win 1451, options [nop,nop,TS val 38356437 ecr 3871643917], length 0 IP &lt;B2IP&gt;.rdns.backblaze.com.https &gt; &lt;ME&gt;.&lt;PORT&gt;: Flags [P.], seq 5972:7465, ack 1173, win 1452, options [nop,nop,TS val 38356699 ecr 3871643917], length 1493 IP &lt;ME&gt;.&lt;PORT&gt; &gt; &lt;B2IP&gt;.rdns.backblaze.com.https: Flags [.], ack 7465, win 1438, options [nop,nop,TS val 3871644239 ecr 38356699], length 0 IP &lt;ME&gt;.&lt;PORT&gt; &gt; &lt;B2IP&gt;.rdns.backblaze.com.https: Flags [P.], seq 1173:1466, ack 7465, win 1444, options [nop,nop,TS val 3871644246 ecr 38356699], length 293 IP &lt;ME&gt;.&lt;PORT&gt; &gt; &lt;B2IP&gt;.rdns.backblaze.com.https: Flags [P.], seq 1173:1466, ack 7465, win 1444, options [nop,nop,TS val 3871644361 ecr 38356699], length 293 IP &lt;B2IP&gt;.rdns.backblaze.com.https &gt; &lt;ME&gt;.&lt;PORT&gt;: Flags [.], ack 1466, win 1451, options [nop,nop,TS val 38356880 ecr 3871644361], length 0 IP &lt;B2IP&gt;.rdns.backblaze.com.https &gt; &lt;ME&gt;.&lt;PORT&gt;: Flags [P.], seq 7465:8958, ack 1466, win 1452, options [nop,nop,TS val 38357103 ecr 3871644361], length 1493 IP &lt;ME&gt;.&lt;PORT&gt; &gt; &lt;B2IP&gt;.rdns.backblaze.com.https: Flags [.], ack 8958, win 1438, options [nop,nop,TS val 3871644643 ecr 38357103], length 0 IP &lt;ME&gt;.&lt;PORT&gt; &gt; &lt;B2IP&gt;.rdns.backblaze.com.https: Flags [P.], seq 1466:1759, ack 8958, win 1444, options [nop,nop,TS val 3871644649 ecr 38357103], length 293 IP &lt;B2IP&gt;.rdns.backblaze.com.https &gt; &lt;ME&gt;.&lt;PORT&gt;: Flags [.], ack 1759, win 1451, options [nop,nop,TS val 38357171 ecr 3871644649], length 0 IP &lt;B2IP&gt;.rdns.backblaze.com.https &gt; &lt;ME&gt;.&lt;PORT&gt;: Flags [P.], seq 8958:10451, ack 1759, win 1452, options [nop,nop,TS val 38357314 ecr 3871644649], length 1493 In my understanding, the empty "ack" requests are keep-alive flags, but they don't appear to share an id. Any idea of what's happening? There shouldn't be any concurrent connections in this example.
I'm not familiar with goblin or gimli, so I can't be much help there, but I was just describing a different way to accomplish arguably the same thing you're already attempting to do, just with fewer lifetimes. You can still coerce those Vecs into pointers or references, and then they become indistinguishable from just storing references in the first place, basically. Maybe someone else who is more familiar with those libraries can provide more help than I can.
&gt; But I am asking if your team were to build something with Elixir and Phoenix, would you suggest Rust instead? No. Rust is really fast with little memory overhead. But elixir is built on erlang. This means it has a lot more libraries , tutorials and examples on how to scale. Most importantly is that its defaults are battle tested for providing uniform delays. AKA. * 100 connections on rust could have all their request handled in 20ms * 100 connections on elixir could have all their requests handled in 40ms * 10000 connections on rust would leave the last 1000 to have a delay of 10 seconds * 10000 connections on elixir would handle all requests in 100ms. These are completely made up numbers. And it is of course possible to achieve the same with rust. The problem is that you would be among the first to try/build the tech. Additionally elixir will guide/force you to build the application in such a way that scale is possible. 
How does 7 crates translate to easy use? There's no introductory documentation, no source link (so I can't easily dig into examples unless maybe I figure out how to pick the crate apart), no way to file issues. How is it different/better than pencil, iron, nickel, rocket, rouille, edge, gotham, susano, pemmican, ship, boron, mould or bare?
what I would suggest is another inbuilt lifetime, ```'temp``` or something like that to explicitely mean 'the shortest possible lifetime' (non-escaping) .. like the opposite of ```'static``` . between 'temp, 'static, 'self , and a decent default assumption, one shouldn't have to deal with explicit names often IMO. the other way to do it might be to define the lifetimes related to the variables... e.g. instead of saying foo, bar,baz have lifetimes 'a, 'a, 'b, you just say "foo and bar share a lifetime" or "all share a lifetime except baz" I'm also ok with single letter generic parameters - because they tend to get clarified by named bounds. e.g. ```&lt;T:Num&gt;``` versus ```&lt;SomeNumericType:Num&gt; .. etc
Couple of notes: * You use &amp;str in a few places, but &amp;[u8] may be sufficient and you won't pay the cost of UTF8 validation, plus you get O(1) indexing. Characters aren't going to matter if you're just hashing - and if you're treating passwords as strings you might do something not-great like print to the screen. Using a newtype might be nice here - you could have a 'debug' impl that panics if built with --release? Plus you won't accidentally pass it into a function that doesn't work the way you expect it to with your secret. * I would move your tests below the code - when I see tests I think "k, the file is basically over". Moving tests to their own module is pretty standard. * &gt; // format to 20 characters because it's all we need for password // validation. This also gives the attacker LESS information. // // To get the true master password, and attacker will have to know // AT LEAST two passwords. I'm confused by this - it would be nice to have your methodology around how you're hashing documented at a higher level. * At a glance I can't really tell how you're comparing passwords, but you'll want to use a constant time function. * You'll want a new salt *for every password*. You can generate it with that password, and then store it alongside the password. You'll want this to be a completely random 'n' bits of data. You have some "what is this?" comments in your code: https://github.com/P-H-C/phc-winner-argon2 I suggest reading that. &gt; The secret parameter, which is used for keyed hashing. This allows a secret key to be input at hashing time (from some external location) and be folded into the value of the hash. This means that even if your salts and hashes are compromized, an attacker cannot brute-force to find the password without the key. &gt; The ad parameter, which is used to fold any additional data into the hash value. Functionally, this behaves almost exactly like the secret or salt parameters; the ad parameter is folding into the value of the hash. However, this parameter is used for different data. The salt should be a random string stored alongside your password. The secret should be a random key only usable at hashing time. The ad is for any other data. Hope that addresses your questions - basically, you could roll a 'pepper'-like mechanism on top of your argon2 hashing.
It compiles but whenever I press on a menu entry it exits with: "error: process didn't exit successfully: `target\debug\window.exe` (exit code: 101)". Still, thanks for the comment.
oh ya, that makes sense. If this application got 30,000 users than someone could launch a rainbow table attack. If people followed the direction of `username@sitename.com` then it would not be a problem... but not everyone is going to do that. I think this is why it is a good idea to use your full name...
This is using synchronous `hyper 0.10`, right?
I'm trying to read a file into a `String`. When I open the file normally I get the error: StringError("stream did not contain valid UTF-8") }) }', src\libcore\result.rs:860 That indicates to me that the file is not encoded in UTF-8. I tried opening the same file in Python and got the following: Python 3.6.1 (v3.6.1:69c0db5, Mar 21 2017, 17:54:52) [MSC v.1900 32 bit (Intel)] on win32 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; f = open('Cyrano de Bergerac (1950).srt') &gt;&gt;&gt; f &lt;_io.TextIOWrapper name='Cyrano de Bergerac (1950).srt' mode='r' encoding='cp1252'&gt; Somehow `open()` was able to automatically guess the encoding and do the conversion to UTF-8. Is there any way I can replicate this "magic" in Rust?
&gt; I've been wondering how the convention of using single character names for lifetimes came to be. Type parameters are often (but not always) one letter, so same with lifetime parameters.
I have to parse some values coming from XML. I've been able to get most of the way using serde-xml-rs but one of the tags has an attribute that's a 30 char representation of a binary value ie: "001110100111100001010100111101" how do I convert that into the corresponding u32 which I can then manipulate to pull out data?
oh the scala side? Yeah, it's super cool! I wondered if Rust could have it too...
&gt;I understand Rust, being systems language, can be adapted to be very fast. But I am asking if your team were to build something with Elixir and Phoenix, would you suggest Rust instead? If so, which framework? Rocket? 
I found this snippet on a [Github issue](https://github.com/serde-rs/json/issues/317) that might be useful: use std::fmt::Display; use std::str::FromStr; use serde::de::{self, Deserialize, Deserializer}; #[derive(Deserialize, Eq, PartialEq, Debug)] struct Test { #[serde(deserialize_with = "from_str")] test: u16 } fn from_str&lt;'de, T, D&gt;(deserializer: D) -&gt; Result&lt;T, D::Error&gt; where T: FromStr, T::Err: Display, D: Deserializer&lt;'de&gt; { let s = String::deserialize(deserializer)?; T::from_str(&amp;s).map_err(de::Error::custom) }
The problem with using the full name is that it still allows offline attacks targeting one user, unlike traditional password managers. It's more secure to use a random secret instead. If you don't store the secret on the server, it's even more secure than traditional password managers. 
&gt; You use &amp;str in a few places The password is gotten from the user and it is a string. It is hashed as `&amp;str.as_ref()` and converted to a string using base64url. It *has* to be a string when it is finally outputted -- as many sites only accept basic ascii characters. I do use newtypes extensively to prevent serialization. &gt; I would move your tests below the code Good idea. All the tests in `secure.rs` have to stay there since the methods are private on purpose. &gt; At a glance I can't really tell how you're comparing passwords The user inputs a master password and it is hashed with `__validation__` as the "user name" and stored in the `novault.toml` file. When the user goes to get a password for say `vitiral@reddit.com`, first NoVault hashes the password with `__validation__` and compares it to the one stored in `novault.toml`. If they match, it hashes it with `vitiral@reddit.com` and that is your password for reddit. Thanks for the clarification on those parameters. I added [this comment](https://github.com/bryant/argon2rs/issues/14#issuecomment-329199786) to include that in the argon2rs documentation. Along with the [comment](https://www.reddit.com/r/rust/comments/6zr036/i_wrote_a_password_manager_over_the_weekend/dmy0fck/) of /u/vks_ it looks like maybe I should require a "username / Full Name" to use as the salt and use the site-name + revision as the "ad". I'm a little bit wary of these extra parameters. I would much rather just do salt = username + site-name + revision since I KNOW what the salt is doing (or at least... I think I do).
Dang that’s interesting! Never thought about the bottle neck there. 
Does [OwningRef](https://kimundi.github.io/owning-ref-rs/owning_ref/struct.OwningRef.html) help you at all? It has that vibe of "multiple references to a common owned thing", only works for types with a fixed memory location, etc. It may mean that you need to wrap your original owned bytes as a `Rc&lt;Vec&lt;u8&gt;&gt;` or so, rather than actually owning it, but perhaps you can get them back out when you drop all the other references and the strong owner count hits zero.
Hey everyone article author here! Thanks for the kind words and super constructive criticism (&lt;3 Rust community) I am aware of the unfair bias to ‘.iter()’ I’m giving in the results, I wasn’t intending to judge the results, the test case you’re seeing was a crop job of a specific piece of code I was looking at, and not supposed to be encompassing of the many options this language gives us. Since people are interested (and I totally need practice writing) I will try to give must justice to closures and proper use. Thanks for teaching me so much even here in the comments! :) 
Yes! This, sorry I missed it ill edit the blog post to reflect that. I think during the process of setting this up i had the old crate ‘test::Bencher’ guide and that _was_ a long time ago nightly only. 
&gt; Good idea. All the tests in secure.rs have to stay there since the methods are private on purpose. Sure, it's just about organizing them. &gt; The user inputs a master password and it is hashed with __validation__ as the "user name" and stored in the novault.toml file. When the user goes to get a password for say vitiral@reddit.com, first NoVault hashes the password with __validation__ and compares it to the one stored in novault.toml. If they match, it hashes it with vitiral@reddit.com and that is your password for reddit. I can't tell what this provides, since you're not hashing with secrets. &gt; Along with the comment of /u/vks_ it looks like maybe I should require a "username / Full Name" to use as the salt and use the site-name + revision as the "ad". A salt should just be randomly generated. Why have a salt be predictable, based on something non-secret like a username? Keep it simple, use random noise where possible. If you want to roll a pepper into the mix too, maybe a username would work - I would personally not want passwords tied directly to the username. It's not a secret and it seems like it will make future changes more complex. 
I tried and mostly this fails because what I work with does not abstract around references. 
Well, that's the issue, isn't it? For a large number of Rust's users, these are *not* completely different things. They're just slightly different ways of writing the exact same thing, and so a lot of us end up going back and forth several times over the course of designing and implementing something. Sure, the compiler sees them as very different things, but users often disagree.
Well, if you don't copy then you need to prove that the hashset won't access an already freed value - so you need borrow checking, and you're going to use references. If you don't want to do the borrow checking you need to clone. Not really 'needless' if that's your goal. You could wrap it in an Rc I guess, and then your Clone is cheaper?
&gt; e.g. instead of saying foo, bar,baz have lifetimes 'a, 'a, 'b, you just say "foo and bar share a lifetime" or "all share a lifetime except baz" I would prefer something like this in general, but I don't see any non-ugly way to fit it into the syntax of Rust in particular.
Okay, I opened and fixed [this issue](https://github.com/vitiral/novault/issues/2), tell me what you think! `0.3` will be released in the next few days (breaking change). I don't see the value of keeping the salt/unique-name secret -- only the *password* should be secret. If they crack the password won't they have cracked the salt as well (along with any other "secret" parameters) anyway? I thought salts are only useful to prevent rainbow-table attacks. Another thing: adding *another* secret thing adds complexity to the application, and I don't see the benefit. If I were storing these passwords on a server and could have a "single hashing computer" that I could lock down with a "secret key" on it, THEN I see the value. Theoretically I could ask the user to store their "full user name" in `~/.local/novault.secret` or something. That would be *moderately* secret, but really it's not much benefit for more complexity.
&gt; I can't tell what this provides, since you're not hashing with secrets. The master password is secret. I only compare to prevent you from mis-typing your password. &gt; A salt should just be randomly generated. It can't be randomly generated. One of the benefits of this application is that *even if you loose your novault.toml file* you can still recover your passwords if you know their username@site information (and your own global name and master password, obviously). The point of the salt is that it creates a unique password per site but the master password is still kept secure.
thanks for the wellwishes. *pass* requires you to store your vault somewhere, and if you loose it there is no way to recover. That is one of the design decisions of NoVault.
It's still nightly-only IIRC, because it uses some compiler magic for `black_box`. The `bencher` crate uses a volatile store instead.
/r/playrust
/r/playrust
&gt; especially knowing that it doesn't even need to hold onto the references. It does need to hold on to the references, to resolve potential hash collisions
I mean, the announcement wasn't supposed to be an announcement of a "new IDE", just an extension that lets you make atom into an IDE. It's a coherent announcement of a set of extensions using the LSP for IDE capabilities in Atom.
I use atom for all my rust work and when I went to install atom-ide-ui it says atom-ide-ui will be deactivated in favor of Nuclide. Atom IDE UI is bundled with Nuclide. My suggestion is to use Nuclide (they are both developed by Facebook).
You can also give the HashSet ownership of the thing. let mut set = HashSet::new(); let data = String::from("Hello, World!"); set.insert(data); Is perfectly valid.
Is there any way for people to help make that happen faster? I haven't been able to find any tracking issues for this change.
Created an issue for this. https://github.com/rust-lang/rust/issues/44546 Also &gt; add warnings in rustc/clippy for throwing .collect's / .count's result away in case we cannot break backwards compatibility over this `#[must_use]` makes a warning, not an error. It should be backward compatible to add, no?
Please include extra metadata in your Cargo.toml http://doc.crates.io/manifest.html including: readme, documentation, categories, repository, keywords, category. This will help us navigate and understand the crate.
Welcome to Reddit. Before posting to a subreddit/forum/community, you should check to see what that subreddit is for. This includes reading the sidebar and the rules. You should also pay attention to warnings that you're posting to the wrong subreddit. Check /r/playrust. 
That means the process panicked. You can see `unimplemented!()` in /u/Lisoph's code example which is where you should fill in code to do something other than panic.
See [this recent Github issue](https://github.com/rust-lang/rust/issues/44266) discussing the same question.
I would definitely do the lifetime one, because I don't feel that lifetimes are "extremely annoying". Whenever the compiler gives me hell with a lifetime error, I just think about all the times I've had to debug use-after-free in C programs, and realize that me getting a compiler error is way, *way* less annoying than a customer getting UB. If you can't guarantee that the items will exist for as long as the set, you can try to store a `Weak` reference instead. But these cannot be stored directly in a hash set, since their values can vanish at any time. You'll need to find some other value to use as key, and store the `Weak` reference as the value. This may or may not work depending on your use case. 
It's hard to say since this doesn't show the initial syn/ack, but it looks like this is all part of a single file request using a multipart download that is happening serially. The client is requesting a chunk (likely max segment size of 1493) and then backblaze responds with another chunk. So this log, to me, doesn't indicate one way or the other. 
Thanks but I don't think that turns the bits represented in the string into one byte.
For people who don't want to dig through the RFC thread for why they were removed (full disclosure- I was one of those who opposed backreferences): * Backreferences are not expressive enough for all cases, so we need both syntaxes anyway. This alone was not a reason they were removed, but it has some downsides that played a role: * This leads to a situation where it's harder to tell what a lifetime applies to, because there's not always a `'` to point it out. * This also introduces a cliff in the learning curve, because the backreference syntax is so different from the general syntax. * Backreferences pick one particular use as the definition, which isn't how they actually work. The closest actual behavior is that some lifetimes are classified as "input" and some as "output," but even then there's not always a single input, and the output constrains the input just as much as the other way around. * Lifetimes don't actually apply to the arguments themselves, but to what they point to. This means that the apparently-simple correspondence in `x: &amp;T` is actually misleading- `x` itself goes away after the function returns, but the `T`, and thus `'x`, don't. * This is also where backreference syntax breaks down and you need the general syntax. If an argument has multiple lifetimes, e.g. `&amp;'_ T&lt;'_&gt;`, `(&amp;'_ i32, &amp;'_ i32)`, `T&lt;'_, '_&gt;`, then which one should the argument name apply to? * This is particularly apparent when you try to apply the same logic to local variables, which normally behave like they're part of the same scope as arguments.
I'm just going to drop my [talk from RustConf](https://www.youtube.com/watch?v=JpkjOkiu-fA) here which was about shipping a solid crate. Documentation, cargo metadata, and more were all covered in it.
I would assume collecting the zero-sized type `()` (resulting from `*i += 1`) would almost be a no-op for `Vec`.
You're right, didn't think about zero-sized... 
If `#[must_use]` is added to those, then a new method should be created to force the iteration (returning `()`).
The salt (and pepper) are typically stored alongside the hashed passwords: being secret is not necessary for their role, but there's no need to advertise them.
Another user linked to this very page: https://www.reddit.com/r/rust/comments/6zsxqk/atomide_seems_like_particularly_lowhanging_fruit/ (And yes, it was posted 4 hours later, but there are comments there and not here... life is unfair)
This doesn't help you right now, but the [immovable types RFC](https://github.com/rust-lang/rfcs/pull/1858) should solve this problem in the future. It's primarily there as a way to let generators hold references to local variables across suspension points, but it should help in cases like this as well, where you want both self-reference and mutability.
Although it is up to the server to respect it or not, so you should be prepared to handle a full download again.
The files should all be a 1000 bytes.
Instead of `T::from_str`, I think [u32::from_str_radix](https://doc.rust-lang.org/std/primitive.u32.html#method.from_str_radix) might be what you need if you give it a radix of 2
Why use this over the [`evdev`](https://crates.io/crates/evdev) crate, which doesn't even depend on an external library?
My take on name generics has always been naming them, much like naming parameters to a function. There are relationships and constraints for lifetimes and generic parameters, but it's asking a lot to keep all of them straight. (I'm of the same opinion for algorithm descriptions as well.)
The evdev crate is a relatively simple crate and it will miss out on any complex handling that libevdev provides. However, the ultimate goal is to have a libevdev implementation in rust instead of using the bindings to libevdev.
A better comparison for D would be to use LDC, which also uses LLVM for its compiler backend: https://wiki.dlang.org/LDC
You have more than two options. You can for example use Rc to share ownership, you and the HashSet both.
Today I'm starting in on making a GitHub webhook verifier/payload saver, to replicate a part of the stack powering an internal app at work. I don't think we'd really gain anything from using Rust specifically (we're a .NET shop, and the app right now is a very simple Azure deployment &amp; has no real perf issues), but I'm finding having a domain I know inside-out is really helping me along - this is my fourth try to really dive into Rust in three years, but I think this time's going to stick. I am sporadically documenting my experience over at [my blog](https://varnerin.info/getting-rusty-day-1), but to summarize: - got a full dev setup working, including LLDB-based debugging in vscode, racer, and the RLS-based vscode plugin - got through the struct chapter of the new rust book - started planning out what my project will actually do I'm not sure what I'm going to use for the http listener - I really only need a single static endpoint, so having a super complex router is unnecessary. My needs are: - single static endpoint - easy request/response capability (more high-level like `add_header()` and `.get_body()` preferred) - stable Rust I'm looking at [iron](https://github.com/iron/iron) and [hyper](https://github.com/hyperium/hyper), but if anyone has experience with those/an alternative you think would be a better fit, it would be much appreciated! I'm hoping to extract a simple verifier crate as the real end goal.
Am on mobile right now, but Oliver Schneider recently made clippy a submodule.
Ahhhh I remember realizing cloning would be a problem but I forgot to leave myself a TODO to change it. You're 100% right, good catch! Fixed &amp; added a test for good measure, now it clones the underlying values as intended instead of the Rcs.
&gt; You could wrap it in an Rc I guess, and then your Clone is cheaper? At the cost of a prior memory allocation though.
The crates ecosystem gives you the tools to implement this, but you gotta plug a couple things together. The two crates that come together to make this work are `uchardet` and `encoding`. The former is what performs the detection of the character set using some arcane set of heuristics. It's actually a wrapper around a C library, but the author has done a really cool thing and set it up to build the C library automatically so you don't have to find a binary distribution. And the latter is a massive library handling a good chunk of known character encodings, including Windows-1252 which is what Python is reporting as the character set of your file (typical for files created on Windows machines). A really nice feature of this library is that it has a function for taking the string name of a charset and returning a codec for it. So after adding `uchardet` and `encoding` to your `Cargo.toml` (the versions aren't critical as they aren't directly coupled), you can implement this charset detection and reading like this: extern crate encoding; extern crate uchardet; use encoding::label::encoding_from_whatwg_label; use encoding::types::DecoderTrap; use uchardet::detect_encoding_name; use std::fs::File; use std::io::{self, Read}; use std::path::Path; fn read_to_string(path: &amp;Path) -&gt; io::Result&lt;String&gt; { // for simplicity I'm reading the whole file all into memory; for big files you'll want to do incremental decoding let mut data = Vec::new(); File::open(path)?.read_to_end(&amp;mut data)?; let charset = detect_encoding_name(buf).map_err(|e| other_io_err(format!("unable to detect encoding for file: {}, reason: {}", path.display(), e)) )?; println!("Detected charset: {}", charset); let encoding = encoding_from_whatwg_label(&amp;charset).ok_or(|| other_io_err(format!("unsupported charset for file: {}, charset: {}", path.display(), charset)))?; // `DecoderTrap::Strict` returns an error if an invalid sequence was found encoding.decode(&amp;data, DecoderTrap::Strict).map_err(|e| other_io_err(format!("failed decoding file: {} with charset: {}, reason: {}", path.display(), charset, e))) } // helper function fn other_io_err(msg: String) -&gt; io::Error { io::Error:new(io::ErrorKind::Other, msg) }
You're a hero. I had found the `encoding` crate but the not the `uchardet`. Thank you.
fn main() { let t = 10; let t_t = &amp;t; println!("{}", t + t_t); } I just started on rust. Why is it that i can add an integer and a reference to an integer together. (I thought that its supposed to fail as both are of different types).
In this case the answer lies in what types implement the `std::ops::Add` trait.
Ah. Well in that case, it appears to be doing the right thing. 
Super excited about cargo getting split into 3 packages.
We could also introduce relative pointers. Then you could still move your struct around.
It doesn't error because you are not modifying score in your example? Maybe you are confused about what the `match` keyword does?
`Some(i) =&gt; Some(2000)` This doesn't replace the value in the hashmap with 2000, this just creates a new `Some(2000)` which becomes the result of the `match` statement.
You probably meant this: match score { Some(mut i) =&gt; { *i = 2000; } None =&gt; (), }; In which case, a borrowing error will indeed occur.
I'm not sure what you mean by 'abstracting around references', but this problem is exactly what [OwningRef](https://crates.io/crates/owning_ref) and [Rental](https://crates.io/crates/rental) were designed to solve. They have the 'FixedLocation' trait just as you suggest, factored into a common crate called [StableDeref](https://crates.io/crates/stable_deref_trait). This would need language support to work 100%, but it's a good 80% solution. 
It depends on what the rest of your code is doing, but if cloning a `Thing` is expensive/incorrect, you might want to have a single `HashMap&lt;usize, Thing&gt;` as the canonical store for all the things that you have. Then when you want other maps or sets to refer to the shared things, they can store the `usize` ID instead of a reference. This might be more convenient than an `Rc` if you need to modify the things a lot, or if you want to avoid having too many separate heap allocations.
https://play.rust-lang.org/?gist=b5cb0eb25e60389ddba0e47fbb710b3b&amp;version=stable the trait bound `Trait: Trait` is not satisfied What? Why can't I get `#[derive(Copy, Clone)]` to work? Is manually implementing these traits the appropriate way to go? Send help. use std::marker::PhantomData; trait Trait: Copy {} // Doesn't work. #[derive(Clone, Copy)] struct Struct&lt;T: Trait + ?Sized&gt; { t: PhantomData&lt;*const T&gt;, v: i32, } // Works when Trait is no longer a sub-trait of Copy. // note that no Clone or Copy bound is placed on T. //impl&lt;T: Trait + ?Sized&gt; Clone for Struct&lt;T&gt; { fn clone(&amp;self) -&gt; Self { *self } } //impl&lt;T: Trait + ?Sized&gt; Copy for Struct&lt;T&gt; {} fn main() { let s1 = Struct::&lt;Trait&gt; { t: PhantomData, v: 1234, }; let s2 = s1; let s3 = s1; } 
As other have stated you aren't modifying anything. If you want to mutate the score you are storing in the hash map you have a couple options... but in essence if let Some(score) = scores.get_mut(&amp;team_name) { *score = 2000; } does I think what you are actually wanting to do. The docs give a similar example https://doc.rust-lang.org/std/collections/struct.HashMap.html#examples-20 There's also the entry api for hash maps which are convenient if you want to insert or modify depending on if the hash map has the key or not.
I managed to make it work with `OwningHandle` and since that needs a bit of unsafe code I am building some fancy wrappers around that now. Thanks for the hint.
Isn't that essentially an other way to clone()?
There are 12 rfcs in their final comment period with a merge disposition, surely that is way too much? It looks like rfcs are being accepted much more rapidly than they can reasonably be implemented (or read by those who might like to follow the process). And if 12 out of 13 rfcs get a "disposition:merge", it doesn't sound like the core team is being very discriminating when it comes to language additions. 
I agree that 12 FCPs seems like too much to me. However, just because an RFC has been accepted, that doesn't mean that it will be implemented within a given timeframe. If you look [here](https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3AB-RFC-approved), you'll see that there are many accepted RFCs that have yet to be implemented. Additionally, these are just the RFCs that are being discussed this week. If you look back through previous TWIRs, you'll see many RFCs have been declined and many have been postponed. 
Do you have a link talking about this? There doesn't seem to be any mention here or in the linked post above.
Thanks that seems to work
I believe this is in preparation for the [impl period](https://internals.rust-lang.org/t/announcing-the-impl-period-sep-18-dec-17/5676).
"impl period" starts next week, which naturally means there is a bit of a push to get RFCs accepted before that. https://internals.rust-lang.org/t/announcing-the-impl-period-sep-18-dec-17/5676
Just to clarify, Python is not doing heuristics to determine the encoding. It uses the same encoding based on the platform. On Windows, Python uses [GetLocaleInfo](https://msdn.microsoft.com/en-us/library/windows/desktop/dd318101). Unfortunately, I don't know of any particular locale crates for Rust. However, using a character detection library is probably better.
I suspect this is an actual limitation in rustc that has yet to be fixed: https://github.com/rust-lang/rust/issues/26925 In short, deriving places corresponding trait bounds on all the type parameters, even when they are not necessary. Since the fix is not coming any time soon, I think a manual implementation is the right way to go here. 
It's actually a move, so there's no unnecessary cloning involved. Like he said, you could just *give* the ownership of the thing. Obviously if you can neither give ownership nor use references, you can try your luck with a `Rc&lt;Thing&gt;`
I found an acceptable workaround for me through an abstraction based on OwningRef: My base `MyFile` type looks like this now: pub struct FatObject&lt;'a&gt; { handle: ByteViewHandle&lt;'a, FatObjectKind&lt;'a&gt;&gt;, } And used like this: impl&lt;'a&gt; FatObject&lt;'a&gt; { pub fn parse(byteview: ByteView&lt;'a&gt;) -&gt; Result&lt;FatObject&lt;'a&gt;&gt; { let handle = ByteViewHandle::from_byteview(byteview, |bytes| -&gt; Result&lt;_&gt; { /* parse file here */ FatObjectKind::Placeholder(bytes) })?; Ok(FatObject { handle: handle }) } pub fn as_bytes(&amp;self) -&gt; &amp;'a [u8] { ByteViewHandle::get_bytes(&amp;self.handle) } pub fn objects(&amp;'a self) -&gt; Result&lt;Vec&lt;Object&lt;'a&gt;&gt;&gt; { let mut rv = vec![]; match *self.handle { FatObjectKind::Placeholder(..) =&gt; { /* do stuff here */ } } } } 
If a site password gets compromised, it is possible to perform offline attacks against the master password if you know the salt. By having a secret salt, you can prevent offline attacks.
A note of caution that `OwningHandle` is unsound in the general case (see [this issue](https://github.com/Kimundi/owning-ref-rs/issues/27) for details). Rental was designed to serve the same use cases (and more) as `OwningHandle`, but is sound and does not require unsafe code to use. The tradeoff is a bit more boilerplate and less than ideal ergonomics.
Is it better to use /u/Lisoph's approach or using a match guard like in the issue you linked?
Is there a way to set `RUST_FLAGS` in the cargo file so that you dont have to remember to set it every time a new shell is opened?
I *think* my wrapper around it is safe. I could not get rental working which I assume is because i'm just not intelligent enough to understand it, and it seems largely unused :(
I hope I can express this clearly because I suspect we both agree that Rust should have a good learning curve and the current one isn't quite good enough. On the other hand, the concepts that make Rust different and special are move/borrow and INHTPAMA ("imagine never hearing the phrase 'aliasable, mutable' again" - or how I'd phrase it: shared, mutable, pokayoke, pick two.). Rust as a language community should be moving towards universal understanding of those concepts. So if most people programming in Rust don't have a good feel for whether or not a structure should be borrowed I think that's an opportunity for further education. We should be asking "what will make people grasp this concept more easily?" not "how can we avoid this concept because it is hard?" If a software designer doesn't want to deal with ownership, there are many other excellent languages. Rust shouldn't try to be a better Go than Go. It would be lovely to have the learning curve of Go, though.
I use `*const Thing`, but I'm careful with it.. ie, the pointers only point to stuff owned by the struct.
Glad to see that bicyclomatic complexity comment make quote of the week 😂
When you start using match guards the compiler no longer checks whether you exhausted all the cases, so I recommend avoiding them when possible.
I'm with you. I feel like there's a ton of fanciness thrown around that I don't really follow, but which looks really powerful. I think it's more accessible to people who've studied programming language theory, which I haven't.
Personally I think this is very cool. I often write little code-overviews for myself when I work on projects, so I can jump into them after a break with little hesitation. If I must level some criticism, I would have you go into further detail about the types you talk about (like `ItemId`). I would also include links to relevant parts of the source. All in all, very nice!
Lots of things have been accepted. Some take forever to get to or just might never be stabilized it seems (box syntax when)
No, but you have a few options: * You can set `rustflags` in your [`~/.cargo/config` ](http://doc.crates.io/config.html) * You can add it as a global environment variable * You can create a buildscript for your project that sets it before calling cargo edit: You can also have a `.cargo/config` in your project folder. 
I mean, I store the master password hashed with `salt="username__checkhash__0"` in the [`novault.toml`](https://github.com/vitiral/dotfiles/blob/master/config/novault.toml) file (key=`checkhash`), which I recommend storing pretty much anywhere (including on github). Unless I'm misunderstanding something: yes, you could have a secret salt -- or you could just have a more secure password. Both should give you the same level of security, should they not? Difference is that it is easier to remember a long ~~salt~~ password. The salt is mostly to avoid them being able to crack *multiple users passwords simultaneously* (if the user's happened to choose the same password). Again, I'm not an expert -- but I don't see how my understanding is wrong. You could absolutely have a secret salt -- and that *would* increase your security. But it would also increase the difficulty of remembering *both* a salt and a password! I would prefer users just use a more secure password instead.
I mean, they are only as advertised as the user's file is. They can store their file semi-secretly via email, dropbox or a private server. Or they can store it publically on github. It's totally up to them.
I am addressing some issues on cargo-testify: https://github.com/greyblake/cargo-testify (tests auto-runner that shows friendly desktop notifications)
Nested groups in imports is a nice little quality of life thing. I totally missed that RFC.
Hmm, the only one of those which sticks with the repo across systems (build script) seems the least beginner friendly unfortunately. Still, like 2x faster is pretty great. Strange its not set by default.
Only the last of those is useful for a single project which needs special case flags, and even the simplest build script is something which must be actively employed; you have to overcome the inertia of typing `cargo whatever`. That said, I think the simplest possible build script for this case is called `fargo` and lives in the project root with the executable bit set: #!/bin/sh RUST_FLAGS="XXX" cargo $1 $2 $3 $4 $5 $6 $7 $8 $9
I think the only bad thing about this, which has been brought up many times before, is that it makes it hard for people whose full time job is not Rust to participate in RFC discussions they otherwise would've. For example, if the average Rust developer has an hour a week they can spend on reading, digesting, and commenting on an RFC, then the more RFCs that are active simultaneously, the more that person will have to miss. To some extent this isn't a solvable problem, and there can't exactly be an expectation that such a person _should_ be as involved as someone working full time on Rust. It's still something to consider.
Any examples (besides the question the OP asked) of things you'd want to know that aren't in the relevant chapters of [the book](https://doc.rust-lang.org/stable/book/)?
I missed that you can have a "per-project" config file too - So the first point is actually viable for repos.
Oh, well i will look in to that
On a match where you only need to use part of the pattern you can do this: match unit { &amp;Money::Penny { in_circulation, .. } =&gt; in_circulation, &amp;Money::One { in_circulation, .. } =&gt; in_circulation } In fact you can reduce it even further: match unit { &amp;Money::Penny { in_circulation, .. } | &amp;Money::One { in_circulation, .. } =&gt; in_circulation } 
That works! Perfect! I had stumbled onto the { .. } syntax for eliding all members, but I didn't know that 1) you can reorder the members, and 2) you can use it as the last list item to elide all omitted members.
To be clear, after creating `~/.cargo/config`, with the content: [build] rustflags = ["-Ctarget-cpu=native"] I get CPU-native builds? **Edit**: thx @JohnMcPineapple for the correction
&gt; (box syntax when) Isn't box syntax being replaced by *placement in* syntax? I'd like to know myself, the info on this is all over the place.
You can also use a tool like direnv and commit the envrc. 
&gt; And if 12 out of 13 rfcs get a "disposition:merge", it doesn't sound like the core team is being very discriminating when it comes to language additions. All that means is that most RFCs that make it to FCP get accepted. I'm not sure I'd want it any other way. Having a large number of RFCs that make it to FCP get rejected would mean that lots of issues are getting discovered only very late in the process, which would itself be a problem.
Almost, the file is just `config` (without the dot) and the flag is a single string without spaces: rustflags = ["-Ctarget-cpu=native"] The space inbetween seems to only work in the RUST_FLAGS env variable, it needs to be concatenated here or rustc complains.
ah, that make sense, thanks I knew I was missing something.
yeah, I got confused on match, since I didn't realize that match does not actually change the variable itself unless you explicitly tell it to do so.
make sense, thanks for the explanation.
yeah, I was confused.
&gt; It looks like rfcs are being accepted much more rapidly than they can reasonably be implemented Funny, since it was all due to the.. implementation period.
¯\\\_(ツ)_/¯
What "complex handling" do you believe it's missing? The only complexity I'm aware of in libevdev is resynchronization, which the evdev crate does indeed reimplement...
For what it's worth, a better shell script way to use "all arguments" is with the special variables $* or "$@". I'd recommend: #!/bin/sh RUST_FLAGS="XXX" cargo "$@" 
Spending some time on a friction-reducing tool for the day job: [release-party](https://github.com/matthewkmayer/release-party-BR). This CLI tool uses the Github API to get a list of all repositories in an organization, checks if the `release` branch is behind `master` and makes a pull request if so. For our workflow, it lets us release to production via the `release` branch faster and easier. At the end of an execution it prints out all the release PRs for easy copy/paste into Slack for team members to review. Recently I made a change to reduce friction by only asking for the Github organization from the CLI instead of the entire Github API URL for the org, added paging for the Github API so we can handle more than 100 repos and cleaned up the code with `rustfmt`. In progress: ensure we don't bump into Github API throttling limits. Hasn't been a problem since a Github token is required to look at private repos and there's a *lot* of API calls you can make when authenticated like that. Still, I want to be a good user of the API so I want to keep well inside the limits.
&gt;* Instead of an explicit `yield` form, Kotlin coroutines automatically suspend whenever another coroutine is called. That's pretty nice. Is this possible in Rust? Maybe using the `?` operator, with some dark magic using the `From` trait.
People have suggested using the `?` operator because it tends to be used along with `await!` in the async/await prototype, but personally I think that's a terrible idea. It mixes two entirely unrelated control flow constructs together in a pretty misleading way. Worse, it doesn't *actually* make suspension automatic and doesn't work for things like generators that, unlike `futures-rs`, *don't* need error handling around suspension points. IMO, if we were to follow Kotlin's lead here and suspend on calls to async functions, we should just do it directly. There's still plenty of time for that- generators are only in nightly because of an eRFC so the syntax intentionally hasn't even really been discussed much.
You're right, that's a better way.
Push should mean getting a decision, not necessarily an "accepted" one. Whether a RFC gets accepted should depend on solely on merits, not push.
Has anyone mastered rust at this point? http://norvig.com/21-days.html ---- I haven't read it. I think the book at rust-lang is good. If you combine that with lots of practical experience, asking questions of more experienced users, getting code reviews, and that sort of thing then it's probably all the more book you need.
`rustflags = ["-C", "target-cpu=native"]` works fine.
The author of the comment originally missed a method: &gt; edit: You can also have a .cargo/config in your project folder.
Thanks for the reply! Don't get me wrong, the book at rust-lang is good, but I personally want something that goes a little deeper into the topics rather than "This is what it is, here's a little taste of why."
I wonder how far you could get if there was a `unique ('this lifetime is unshared') , and in the absence of that it must assume the lifetimes are similar. (with a division between inputs &amp; outputs, i think the 'self output assumption works very well) conversely, if if gets pi-types (the ability to refer to values?) could one say ```foo:&amp;Foo, bar:ref&lt;T,foo&gt;``` where ref&lt;T,VAR_NAME&gt; means ' a reference sharing lifetime with 'VAR_NAME' I guess the actual tags get more useful when you have to declare elements in structs that collaborate with functions, but generally creating fewer names is better IMO.
I want to load Rust libraries dynamically from Rust code, for implementing plugins that can be compiled separately from the main application. Currently I have a plugin architecture based on piping data between processes, but I want to test the performance difference between that and sharing memory between a plugin within the same process. So, I need to build and load dynamic libraries. Is there any guide for that? From https://github.com/rust-lang/rfcs/blob/master/text/1510-cdylib.md I get that there are two kinds of dynamic libs, rdylibs and cdylibs. Which one is better for my use case?
&gt; Functions can be defined not only with the usual fun f() { ... } syntax, but also with a fun f() = ... syntax. Functions whose final parameter is a function can be invoked as f() { ... } (Rust used to use do for this!). Combined, this means you can write something like fun main() = runBlocking&lt;Unit&gt; { ... }, which is a very clear but also very lightweight way to annotate functions and reduce nesting. I'm a big fan of both these pieces of syntax sugar (see thread [https://users.rust-lang.org/t/could-rust-do-this-kotlin-single-expression-function-with-inferred-return-type/12580?u=dobkeratops]); the single-expression functions inferring the return type are a great idea .. rust's standard behaviour is usually good, but that doesn't mean there's other cases where an alternative isn't better. Combining both options would be superior. The ```foo()=...``` syntax is very intuitive IMO; I independently guessed it and implemented it in my pet language without knowing about kotlin. it's just haskell inspired, and I've seen similar in an old BASIC. (bbc.. FNs vs PROCs were different admitedly but FNs were just expressions). [Julia also has similar](https://docs.julialang.org/en/stable/manual/functions/). trailing ```=``` could work especially well for simple [constructors](https://aturon.github.io/ownership/constructors.html) too , e.g. imagine ```fn make_foo(args..)= Foo{ .... }``` (it's very clear that the return type is a ```Foo```) (again something else I did in my pet-language was to copy haskells idea of where, allowing trailing definition of intermediate variables.. but you still see the key behaviour on one line. I gather there was also appetite for a shortcut for '[a function which matches on it's arg](https://github.com/rust-lang/rfcs/issues/1577)' e.g. ```fn foo(x..) match{....}``` , perhaps ```fn foo(x..)=match x{....}``` would be close enough. I was very dissapointed when Rust lost **do notation**; my interest was data-parallel and having the ability for high-order-functions for iteration but looking as natural as inbuilt 'loop' constructs (i.e. no extra nesting) was a **huge** draw. for-loops and iterations are mentally quite similar (especially for..in). The extra nesting levels seem to bug me a lot, I think it must be some sort of 'muscle-memory' issue (stepping outside of what you pick up through intuitive speed-reading, into manual reasoning).. they stick out like a sore thumb. Stepping in and out of bracket levels costs more than you might think, which is why [LISP](https://en.wikipedia.org/w/index.php?title=LISP) isn't more popular (despite it's extreme conceptual elegance). Tangentially I find this problem with a lot of macro uses aswell, and hope there's eventually ways to streamline that .. method macros?). I'm guessing 'do' clashed with haskeller's expectation, but perhaps a 'trailing/infix' form of it could work e.g. ```foo(...) do |x|{ ... }```. people suggested macros, but they can't achieve nesting-reduction, which is the real point. Quite a few other languages have something similar, e.g. [swift](https://developer.apple.com/library/content/documentation/Swift/Conceptual/Swift_Programming_Language/Closures.html#//apple_ref/doc/uid/TP40014097-CH11-ID102), I remember they said 'the feature wasn't pulling it's weight' but they were making assumptions based on the compiler use-cases; what about the future ability to write snippets of GPU compute kernels (similar to [C++AMP](https://msdn.microsoft.com/en-us/library/hh265137.aspx?f=255&amp;MSPPError=-2147217396)) , as well as the worker-thread data-parallel use cases.. (I also remember seeing it used for concurrency, i.e 'run this little block of code deferred..')
&gt; Instead of an explicit `yield` form, Kotlin coroutines automatically suspend whenever another coroutine is called. I think languages that do this are making a terrible mistake. One of the huge, *huge* advantages you can get with coroutines is the context switching points being explicit. This makes it possible to tell where assumptions might be violated. For example, I once wrote a GUI program on top of a coroutine-based UI framework in Python. One class of bugs that popped up when I started was where suspending a coroutine (while waiting for other information) would invalidate something I'd already computed prior to the suspension. I learned pretty quick that I *had* to re-check important things *after* a suspend point, and move environment-dependent calculations to just before I used them, or Bad Things would happen. What really baffles me about this design choice is that we already have something similar which *should* have taught these people just what a bad idea it is: *threads*. You can't see the suspend points in threads, either. Functions that use threads are wonderful and *composable*. They don't add any syntactic noise to using them. And it's *terrible*. One of the two fundamental problems of threads (the other being shared, mutable memory) is not being able to tell where or when you're going to lose control. That turned into more of a rant than I'd expected, but this idea that removing syntactic signals like `yield` is a *benefit* just... really grinds my gears. It's just introducing a new way to shoot yourself in the face, and I really wish people would stop shooting themselves in the face, and then trying to convince me that *I* should should myself in the face, too. All the cool kids are doing it!
Adding addresses is meaningless in safe Rust, so the core library is free to define `i32 + &amp;i32` to add values. Generally speaking, Rust won't convert between different concrete types of data (to my endless mild annoyance - no, having to type `const B2: f32 = A3 * 3.0;` did not prevent a bug today), but it's quite eager to convert references. The reference type constructors are *really* good at inventing types internally. (There's a new type defined at *every* `&amp;mut` and most method calls!) So without implicit casting of reference types, Rust would be impossible to use.
Makes me wonder if we could leverage Rust's `Send`/`Sync` system to combat the downsides of implicit yielding. Explicit suspension points are nice but I'm not convinced they're worth it.
I take the current large number of issues in FCP to imply that bringing RFCs to a decision has been relatively low-priority for a while. If the impending impl period means that a lot of the RFCs that have been left in limbo finally get to make progress, then that's a good thing. And obviously it is possible that people could be trying to slip in RFCs sneakily, but the idea of the final comment period is to prevent that from happening (I've seen several RFCs that get pushed out of FCP and into a discussion state due to a large number of comments once FCP starts). And if you feel like any RFC is getting accepted despite a large number of unaddressed comments during FCP (IOW indicating that teams may be rushing to accept things), then don't hesitate to call them out with a post to the subreddit here. Finally, also remember that an RFC getting accepted does not necessarily mean that feature gets into Rust; it still has to survive at least an entire six-week cycle while the RFC's implementation is considered for stabilization, during which feedback is again requested.
I like to think I'm personally responsible for (friendly) pushing the core team to merge variable-length arrays, mainly because I offered to set up a PoC implementation we can iterate on. Now it's likely going to be merged and I'll have to make good on my offer. Cool.
Does anyone know what color scheme is used in the screenshot? I like the appearance.
so i've been using tokamak recently... isn't that pretty much already atom turned into a rust IDE?
&gt; And it's terrible. One of the two fundamental problems of threads (the other being shared, mutable memory) is not being able to tell where or when you're going to lose control. I'm having a hard time seeing the problem. Unless you're using shared mutable memory (or mutexes, locks, etc. which are basically the same thing), what's the problem? Overhead? If things you've computed in-thread are getting invalidated while suspended then we're *again* talking (effectively) shared mutable memory.
Putting aside cases like pure, independent computation (where this genuinely doesn't matter, but also isn't a problem with any concurrency mechanism), you only reach for coroutines *because* you have some kind of shared state that you want to operate on. Like waiting for a read/write to complete, or some long external calculation to finish. Otherwise, you wouldn't bother. Coroutines (depending on the implementation) have two advantages. The first is higher performance due to less context switches (since they only happen when you actually *need* to suspend), and the second is explicit context switches (so you can see where and when you have to re-evaluate cached information). To put it another way: with threads, you have to be paranoid everywhere, all the time. With coroutines, you have to be paranoid around `yield`s. It's like how with memory safety and C++ versus Rust (everywhere versus around `unsafe`).
This actually works today using packages like language-rust, ide-rust, and the new atom IDE package. May need a little polish but I was using it earlier today.
&gt; you only reach for coroutines because you have some kind of shared state that you want to operate on. Huh? That's not really true, IME. You may just want concurrency because it may make the program flow much clearer. To me coroutines seem like a simple way to introduce concurrency with the ability to communicate via rendezvous queues. I.e. the "guaranteed safe" way (again, modulo mutable state) to do concurrent programming with queues. (Of course the coroutine/suspension *itself* represents a form of shared mutable state, but with the right abstractions that's not really observable.) If you'd said they're "dangerous because mutable state", then I'd probably agree, but you said they were 'dangerous' for other reasons, and I'm curious about what those reasons were. Everything you've talked about so *is* shared mutable state in one form or another. (And we already *know* that's dangerous, explicit yield or no.)
I feel like we're talking across purposes. If coroutines are communicating in *any way* that couldn't be done without coroutines, that's "shared mutable state". Maybe not in the "it's locked behind a mutex" sense, but definitely in terms of the broad properties and pitfalls. The behaviour and state of a coroutine depend on the behaviour and state of either other coroutines, or other parts of the system. That's what I was describing with the GUI code I wrote: there was no "traditional" shared mutable state (heck, half the application was isolated in a whole other process), but I *still* saw the same kinds of problems you'd get with threads and "real" shared mutable data. I mean, I'm playing around with a fixed point compiler at the moment to try out Rust's generators. There is (currently) no "real" shared mutable state involved... but between suspension points, answers to questions like "does symbol `X` exist?" can change. As far as I'm concerned, that's morally the same thing. It's still something I have to take into account. Now, you say I said they're 'dangerous'... but I didn't, so I'm not sure how to respond to that. I'm also not sure what the subject of that last paragraph is. Maybe I can rephrase: shared mutable state is bad because you don't know when someone else is going to come along and stomp on what you think you know to be true. Now, if you can eliminate shared mutable state entirely, that's one way of solving it. Another is to use locks to ensure the stomping can't happen. A third is to use explicit context switches so you know *when* the stomping can happen. Threads are dangerous because they don't provide *any* of the above. Limited abstractions (like fork/join concurrency) give you the first. Mutexes and other kinds of locks give you the second. Coroutines give you the third... unless you remove the explicit yields, in which case you've basically just got threads again.
You're cloning the literal str is what I mean. I assume OP is not a complete dummy and they clone their data because they want to keep using the structure from outside the hashset. 
Couldn't 6 of the crates be feature-gated inside the 7th? :o
I'm really interested in this argument because I see it as a major boon - if you call a function, you don't worry about how it's implemented. It might initially be implemented as a synchronous function, but changed in the future to be asynchronous and you don't need to modify every call-site. To me, whether soothing is async or not is an implementation detail, the program should operate the same way in any case. Do you mind explaining exactly what assumptions you made before invoking an async function, which broke those assumptions?
Is there a macro for getting a time stamp (as a string)? I'd like to embed the build time to the binary, and setting up an env var and reading it from there is troublesome and creates a need for build scripts...
Aren't native cpu builds by default? 
So, if i understand correctly. impl&lt;'a&gt; Add&lt;&amp;'a f32&gt; for f32 allows rust to be that way ?
Did you try [Learning Rust With Entirely Too Many Linked Lists](http://cglab.ca/~abeinges/blah/too-many-lists/book/) It's an excellent complement to the rust book IMHO.
Love this blog series! I'm new in Rust, so may not get the whole picture, but have a question about BoxedMemoryManager: What is the point of defining it as a Generic trait and create a zero-sized type for each boxed type. Can we define it as just "pure" trait like?: pub trait BoxedMemoryManager { unsafe fn copy(ptr: *const Self) -&gt; *mut Self; unsafe fn free(ptr: *mut Self); } with implementation impl BoxedMemoryManager for $ffi_name { #[inline] unsafe fn copy($copy_arg: *const $ffi_name) -&gt; *mut $ffi_name { $copy_expr } #[inline] unsafe fn free($free_arg: *mut $ffi_name) { $free_expr } } Probably I just missed something but would like to see the explanation
It also means that any use of the ID has to be guarded by the unwrapping of an Option. If you attempt a 'use after free', doing a lookup with the ID after the entry has been removed from the map, you'll get a None. Perhaps annoying, but safer than doing it in C++! 
http://vfoley.xyz/rust-compilation-tip
In the specific examples I'm thinking of, it was a few things: that a given UI element existed, that a UI element had a particular value, that there were a particular number of elements in a set. Depending on what else was going on at the time, it was possible for a request to suspend a coroutine long enough that something changed in the interim.
For what reason was the coroutine suspended? Network IO? UI event loop? And what function call lead to the suspension? Would it have made any difference if it was explicit?
The idea is to store the secret salt on your computer to avoid having to remember it. You don't store your password. I don't see how your scheme is not vulnerable to the attack mentioned above. If I know a site password from some breach, I can use brute force to attack your master password. This would not work with a traditional password manager, because access to the vault is required. For more details, see this [criticism of deterministic password managers](https://tonyarcieri.com/4-fatal-flaws-in-deterministic-password-managers). 
I assume you are referring to * [Gimli: A lazy, zero-copy parser for the DWARF debugging format](https://github.com/gimli-rs/gimli) * [Goblin: An impish, cross-platform binary parsing crate, written in Rust ](https://github.com/m4b/goblin) When you find a solution can you make a text post? 
I don't know who you are /u/0b_0101_001_1010 but I like you. Keep it up!
Could one do something like [petgraph](https://github.com/bluss/petgraph) and have a Vec of offsets?
It's not much feedback, but I was rather confused by the name.
It was usually waiting on the database backend (in the other process) to respond. And it *was* explicit. The bugs initially happened because I wasn't thinking about what could happen due to the suspensions, but I managed to resolve the bugs by just looking for every `yield` and making sure I didn't re-use values from before the yield that might have been invalidated. Once I knew to do that, the bugs stopped happening. Basically, just like `unsafe` in Rust is a big "you need to pay attention to memory safety" flag, every `yield` was a big "you need to pay attention to state invalidation" flag.
By the way just a note to tell you I'm using it and it works quite well, thanks a lot !
Honestly, I would have expected a simple answer withing a range of ["yes", "no"]. And, if "no", then I would ask "why not?". 
This isn't actually a problem when writing Kotlin. IntelliJ IDEA (pretty much everybody uses it when doing Kotlin development) clearly shows all the suspension points in the gutter, and, AFAIK, you can even set things up so that suspending functions are highlighted differently. And if you really don't want to use an IDE, it's not that hard to spot the suspension point. 90% of the time you would actually just use one or two standard suspending functions in your code. It's pretty easy to spot: fun foo() = async { val a = 42 val b = someFutureComputation(a).await() b } And what's great, you can implement new suspension primitives (http://community.schemewiki.org/?amb is especially fun) without the need to use macros. I feel like most of the asynchronous code written in Rust won't ever directly use the `yield` keyword, but some macros like `await!()` and `#[async]`, so the suspension point will also be "hidden". I personally prefer using normal functions instead of macros.
&gt; Cargo also extends this ability to a hierarchical strategy. If, for example, Cargo were invoked in /home/foo/bar/baz, then the following configuration files would be probed for and unified in this order: &gt; &gt; /home/foo/bar/baz/.cargo/config &gt; &gt; /home/foo/bar/.cargo/config &gt; &gt; /home/foo/.cargo/config &gt; &gt; /home/.cargo/config &gt; &gt; /.cargo/config Okay, so what if cargo is invoked in /tmp/bar/baz? Does it recurse up to the root from there? Which means it never looks in ~/.cargo/config? So there isn't really a user-specific .cargo directory, there's one in the user home directory which happens to get searched under the hierarchical rule? Also, a global cross-user default file goes in /.cargo? Not in /etc/default/cargo where you (and your backup tools etc) would expect on a unix system? I remember a while ago there was a discussion about where certain user-specific cargo files should live. On a modern Linux system, they should really be under ~/.local or something. However, that doesn't exist on non-Linux systems, and whoever is Duke of Cargo felt that it was more important to be identical across platforms than do the right thing for each platform. Perhaps this is also a consequence of that ethos. 
There's now a 13th that went into FCP the day after this TWIR was published - [Add generic_assert](https://github.com/rust-lang/rfcs/pull/2011). Also, several of these now have comments stating "the final comment period is now complete", despite still being tagged. I'm not sure what the true status of those is. The RFCs currently tagged as being in FCP are: * #1826 [Change the default URL of doc.rust-lang.org](https://github.com/rust-lang/rfcs/pull/1826) * Freshening up the documentation site, seems benign * #1977 [RFC for Public/Private Dependencies](https://github.com/rust-lang/rfcs/pull/1977) * You can, and should, explicitly declare which of your dependencies are part of your API (Return an [ArrayString](https://docs.rs/arrayvec/0.4.0/arrayvec/struct.ArrayString.html)? Better declare it, buddy.). Core idea is good, details seem sound. Introduces a little bit more coupling between crate machinery and rustc. Catches conflicts earlier and more usefully. Change from highest to lowest version resolution is interesting: should prevent certain problems, but means you won't automatically pick up bugfixes; values discipline over comfort. Should be easy to change later if it turns out to be a mistake. * #1990 [Add external doc attribute to rustc](https://github.com/rust-lang/rfcs/pull/1990) * You can import an external file into an item's doc comment. Seems really useful. Might not have settled in its optimal form, but will definitely make life better. Should be easy to tweak or augment later if it turns out to be a mistake. * #2000 [Const generics](https://github.com/rust-lang/rfcs/pull/2000) * The big one! It's a commendably brief RFC, and will be a big change, so i encourage everyone to read it. The goal is undeniably useful, and the plan seems sensible. It'll be hard to back down from later, but it's deliberately a minimal change, with refinements left for later. I have a few bikesheddy comments, just to annoy the core team; the FCP has ended, so everyone is free to ignore them. * #2011 [Add generic_assert](https://github.com/rust-lang/rfcs/pull/2011) * `assert!`has been bitten by a radioactive [Groovy](http://grails.asia/groovy-assert-examples) and gains the proportional strength of a Groovy. The RFC is short, and mostly examples, so read it and get hyped. There are some surprisingly tricky implementation issues, but the squad seems to be on top of them. Easily tweaked or reversed later. * #2021 [Allow comparisons between integers of different types](https://github.com/rust-lang/rfcs/pull/2021) * Disposed to postpone; dr * #2045 [RFC: target_feature](https://github.com/rust-lang/rfcs/pull/2045) * Compile-time and run-time tools for detecting specific CPU features and running code written specifically for them. Those of us lucky enough to be deploying on our own hardware can already make assumptions about features, but people writing software for filthy users, eg game devs, should find this useful. The implementation seems straightforward and sensible. There's some pretty strict process stuff around adding new features, which should help us get this right. Tricky to change later, but pretty niche, so the cost of getting it wrong is small. * #2052 [RFC: Evolving Rust through Epochs](https://github.com/rust-lang/rfcs/pull/2052) * This is big enough that everyone should read it. Personally, i'm profoundly unconvinced that we need this. Other languages have got on fine without it. It probably doesn't help that the motivating example is around `catch`, which i think is a bad feature we should not adopt! Still, it has enough momentum now that it's going to happen whether you finally comment on it or not. * #2071 [Add impl Trait type alias and variable declarations](https://github.com/rust-lang/rfcs/pull/2071) * This is a logical extension of `impl Trait` from return types to other places. It opens a number of cans of worms. I have never used `impl Trait`, and don't feel qualified to evaluate the arguments, so i just have to trust the people who are getting stuck into it. I doubt it will be possible to substantially change this later, so fingers crossed. * #2103 [Attributes for tools, 2.0](https://github.com/rust-lang/rfcs/pull/2103) * We namespace attributes aimed at specific tools in the Rust suite. `#[rustfmt::skip]` is the standard example. The idea is to pave the way to an extensible mechanism to support external tools. Seems useful, sensible, and minimal. At this stage, it should be fairly easy to change, as the tools in question are all owned by the Rust project. * #2111 [Autoreferencing `Copy` Types](https://github.com/rust-lang/rfcs/pull/2111) * If T is Copy, you can pass a T to a function that wants a &amp;T and it will work, somehow. It notionally gets copied, but presumably in practice the compiler will elide that. The motivating example is `HashMap.get(&amp;1)` being silly. This is a small feature that would be really useful. It's also a gateway to some kind of philosophical hyperspace of hyperbolic complexity, apparently. The conversation in the comments is rich and interesting. It's clear that we haven't thought this through sufficiently, and it absolutely has to be postponed. _At this point i had to stop reading RFCs and so some actual work, hence the delay._ * #2113 [`dyn Trait` Syntax for Trait Objects: Take 2](https://github.com/rust-lang/rfcs/pull/2113) * The type you today call `MyTrait`, you will instead call `dyn MyTrait`. This is irritating, but there are good reasons to make it explicit that this is "some object of unknown type which implements Trait, and you are going to have to go through a vtable to get to it", especially now that we can say `impl Trait` to mean "some object of a type that i know, and the compiler knows, but we won't tell you, but we'll let you make statically dispatched calls to". `dyn` is an inexcusably bad keyword, but i guess nobody has been able to come up with anything better. The comments on this are pretty good, and worth a read. This is ultimately a superficial syntactic change (right?), so it's not very dangerous. * #2116 [fallible collection allocation 1.0](https://github.com/rust-lang/rfcs/pull/2116) * At the moment, if some code tries to allocate memory, and fails, it aborts the entire process. Two alternative options will be added to let programmers detect and handle allocation failures. Firstly, a build-time option to panic instead of aborting; that would let programs catch the panic and do normal panic-handling style stuff (tear down the thread and spawn a new one, shut down gracefully, etc). Secondly, new methods on the collections to reserve more space, which can report failure. Actually exceeding the safely reserved space can still blow up, but this is the foundation for safe methods for that too. I guess the latter doesn't help with failure to allocate a Box etc, though? This change doesn't affect the 'standard' case of never caring about allocation failure, so it doesn't seem dangerous, but it should be helpful for people who need to care. * #2126 [RFC: Clarify and streamline paths and visibility](https://github.com/rust-lang/rfcs/pull/2126) * This is the whittled-down core of the modules proposal that we have been discussing for the past _ten thousand years_. it gets rid of `extern crate` (yay!), introduces `crate` as a module root and visibility modifer (boo!) and allows submodule.rs and submodule/subsubmodule.rs to coexist (ok). That's it for now. The module system will still be an overcomplicated mess, but it will be a slightly better overcomplicated mess. We'll probably tackle it again some time in the future when we've recovered from the current round of discussions. As an aside, [this comment](https://github.com/rust-lang/rfcs/pull/2113#issuecomment-325129475) by /u/glaebhoerl had be nodding vigorously: &gt; I think it's highly plausible that the demographics of people who participate in discussions on rust-lang/rfcs diverge from that of Rust users in general. I would conjecture that hobbyists and "language enthusiasts" (that is, people like me) are likely to be overrepresented: people who care about Rust to some extent for its own sake, find questions about its design exciting, and basically just want it to be the best language it possibly can be. And that people who use Rust for "real-world purposes" are likely to be underrepresented: people who are interested in Rust merely as a tool to accomplish the things that they actually care about, and whose day probably consists of coming in to work, writing code (which may happen to be in Rust) and doing other work things, and then going home, and where spending time reading and debating Rust RFCs is probably not part of the job description. &gt; &gt; And I think the first group is likely to be the most in favor of breaking changes to improve the language, and the second group, having the most to lose, is likely to be the least in favor. But since the purpose of Rust is first and foremost to be a useful tool for accomplishing real-world tasks, we should care more about the opinions of the latter group with respect to this question than the former! The group of people closely involved with Rust development, inside the team and around it, are hugely impressive in their knowledge, intelligence, reasonableness, and kindness. But they are also kind of nuts. 
For example, under Windows Cargo looks up filesystem hierarchy in current volume (e.g. `f:/foo/bar/baz/project/.cargo/config`) AND in user profile (which can be in different volume/drive).
Here is how it's used: https://github.com/getsentry/symbolic/blob/24ed40b2356b53d372a8c320f0271ba9b4662b1e/debuginfo/src/object.rs#L135 Here is where the type is defined: https://github.com/getsentry/symbolic/blob/24ed40b2356b53d372a8c320f0271ba9b4662b1e/common/src/byteview.rs#L83-L164
The idea was to put the modules into the proper "form". I'm not adverse to changing it.
Yeah I figured. No worries :-).
&gt; pencil, iron, nickel, rocket, rouille, edge, gotham, susano, pemmican, ship, boron, mould or bare ...Wow. I knew we had a _few_ web frameworks in Rust but this is just astounding. I wonder how long it will take for the ecosystem to leave only 2-3 major ones standing (like Django &amp; Flask in Python) which is obviously a better situation in terms of focusing community efforts.
Obviously "no"t, otherwise this whole thread wouldn't exist. If you compile for the native cpu by default, you're going to have problems when you distribute binaries.
Can't you easily implement `BitBlt` in terms of pixel iteration? Or does it do something extra?
There's also an official Rust image: https://hub.docker.com/_/rust/
&gt; All the cool kids are doing it! Nah, all the cool kids these days are preaching the virtues of async and shunning explicit threads. Thing is, in real world async code for something like web/API server that talks to a database, you often end up with so many `yield` points that they lose their significance. When every line, or every other line, can be potentially preempted by another coroutine, it becomes indistinguishable from threads (which are suspended predominantly at syscalls).
I can get behind this syntax. 
I don't really like the examples in the RFC text (multi line) but I miss this feature often, like `use std::sync::{Arc, mpsc, atomic::{self, Ordering}}`
Just look at how gtk-rs makes its testing?
Nice! Silly question though, what does it mean exactly when a RFC is merged? Does it mean like "this is validated, feature will definitely will be in a future version after some testing" or more "this is for consideration but it will still have to been validated a bit more"?
These reasons all seem pretty bogus to me. Still, no big deal - we can always revisit this question in the future, and the future is a long time.
aturon addressed this same issue last week here: https://www.reddit.com/r/rust/comments/6yg1gj/this_week_in_rust_198/dmo4onv/?context=10000
I recommend [Programming Rust](http://shop.oreilly.com/product/0636920040385.do). It seems to cover a broad swath of all the things one needs to know as a beginner, and includes low-level details to understand how things work. The print version should be available in October.
https://www.reddit.com/r/rust/comments/6ynm53/a_simple_tip_to_improve_rust_program_speed/dmp1505/?context=1
&gt; Being "active" is not a rubber stamp, and in particular still does not mean the feature will ultimately be merged; it does mean that in principle all the major stakeholders have agreed to the feature and are amenable to merging it. &gt; Furthermore, the fact that a given RFC has been accepted and is "active" implies nothing about what priority is assigned to its implementation, nor does it imply anything about whether a Rust developer has been assigned the task of implementing the feature. While it is not necessary that the author of the RFC also write the implementation, it is by far the most effective way to see an RFC through to completion: authors should not expect that other project developers will take on responsibility for implementing their accepted feature. So a merged RFC means that in stakeholders are fine with the idea in the form presented in the RFC, implementation *should not but may* lead to ultimate rejection, and there's no guarantee anyone will ever step up to implement it.
Well you never read control with threads so mutating shared state was always bad. The trickiness is threads are multiproc style computation with shared state. So you can't rely on global being consistent. Rust at least prevents you from footgunning yourself.
Sounds like you spawned your coroutines before you ensured everything was ready to go. Don't spawn the one that depends on UI till after the ui is ready etc etc.
But that's exactly my point: if you don't know which calls can suspend, how can you properly order them? If suspendable calls require a `yield` in front of them, it becomes really easy. If *any* call could secretly suspend due to a transitive dependency three layers deep? *Good luck with that.*
 use { syntax::ast::*; rustc::mir::*; }; The semicolons here are a typo, right? (They're not allowed by the syntax definition below, so I assume so.) If not, what's the difference between comma-separated and semi-separated elements?
I ended up [doing something similar without generics](https://play.rust-lang.org/?gist=5f88ae628d2321dfb89a964b9469edf4&amp;version=stable) but when I try to use them with crossbeam I get the trait bound `std::ops::Fn() -&gt; std::boxed::Box&lt;BackendOp + 'static&gt; + 'static: std::marker::Send` is not satisfied which seems weird to me since I use scoped threads. std::ops::Fn() -&gt; std::boxed::Box&lt;mailbox::backends::BackendOp + 'static&gt; + 'static`cannot be sent between threads safely EDIT: *Might* have solved this using Arc. I hope I don't stumble upon anything else. Thanks a lot everyone! EDIT 2: The monstrosity for prosperity: pub struct BackendOpGenerator(Box&lt;Fn() -&gt; Box&lt;BackendOp&gt;&gt;); impl BackendOpGenerator { pub fn new(b: Box&lt;Fn() -&gt; Box&lt;BackendOp&gt;&gt;) -&gt; Self { BackendOpGenerator(b) } pub fn generate(&amp;self) -&gt; Box&lt;BackendOp&gt; { self.0() } } unsafe impl Send for BackendOpGenerator {} unsafe impl Sync for BackendOpGenerator {} struct Obj { op: Option&lt;Arc&lt;Box&lt;BackendOpGenerator&gt;&gt;&gt; } 
An advantage of the env var situation is that it gives you reproducible builds; even if you find some other way, you should provide that option as an override.
`cdylibs` are for non-Rust consumers, `rlibs` are for Rust consumers. See also https://crates.io/crates/libloading
Yes.
Sounds like a good project to start with. I would recommend using hyper directly, iron is not very actively maintained unfortunately. And if you only have one endpoint, iron doesn't give you much more. Use the 0.10 version of hyper if you don't want to deal with async IO just yet.
Yeah, the example was a last minute addition and this is a typo.
Working on fancy-regex to add support for regexes like `(?&lt;=a|bb)`, see [pull request](https://github.com/google/fancy-regex/pull/25). The long-term goal is to be able to [migrate the syntect library](https://github.com/trishume/syntect/pull/34) to a pure Rust regex engine and hopefully get deterministic performance. It currently uses the [Oniguruma](https://github.com/kkos/oniguruma) library which is written in C.
Seems like we're down to painting the shed a new color. I guess this is nice? To me it seems like yet another rule I'll have to grok now that I didn't before. Rust already has a lot of rules.
this is going to have a big impact when the new absolute path for `crate` gets introduced. Instead of having to add `crate::` in front of all your imports, you can just do use crate::{ foo, bar, baz::{Foo, Bar}, };
What about box patterns or deref patterns?
Furthermore, if you have implicit yield / automatic await, wouldn't you need a keyword to opt out of that when necessary? E.g., if you are doing something like in non-implicit yield: let x = getStockQuoteFromGoogle() let y = getStockQuoteFromYahoo() let result = await Futures.race(x, y) If you had a language that automatically awaited both of the "let x" and "let y" fns, then you'd unnecessarily slow down your program. let x = noawait getStockQuoteFromGoogle() let y = noawait getStockQuoteFromYahoo() let result = Futures.race(x, y)
&gt; you have some kind of shared state that you want to operate on. Like waiting for a read/write to complete, or some long external calculation to finish. Those... don't sound like shared state at all to me! Two of the biggest applications of async/await are GUIs and web servers/clients, with a lot of overlap between the two in individual programs. In both cases it's far more about not blocking the event loop than about a `yield` intentionally being able to modify any shared state out from under you. Tasks/futures/coroutines are generally isolated into different purposes and communicate via arguments/return values (or maybe queues if you're feeling fancy). Explicit suspension points are just gravy on top of that, IMO, and we can get the same benefit from the systems Rust has to make threads better.
Pretty sure we're not talking about the same thing. Either that or I don't grok your jargon. Particularly, you say "whether or not a struct should be borrowed." This isn't what we are talking about--or not what I was talking about. I'm talking about an owned struct that may or may not borrow someone else's data. If you decide that one of the fields on the struct should be borrowed from elsewhere, you have to add a lifetime to the struct. If it doesn't borrow anything, you remove it again. The struct performs exactly the same function in either case, at least as far as the programmer is concerned, but changing from one form to the other is labor-intensive. I didn't say it was hard to understand--I just said it was a pain in the ass.
It's not *any* call- it's only calls to async functions, which are still documented as such and easily pointed out by something like RLS. A synchronous function can't magically become async just by changing a transitive dependency. **edit**: and by the same rules you still only have to search blocks that are explicitly marked as async. Much like Rust only marks *blocks* and *functions* as `unsafe` (and not individual operations), implicit suspension still requires you to mark *blocks* and *functions* as async.
IMO, parsers should work against buffers of data, and not directly against fds/sockets. So it shouldn't matter whether they're using tokio or blocking sockets. As far as idiomatic types that represent a protocol.. you can't do better than https://github.com/hyperium/http For the most clear, concise and secure parsers (perhaps at the expense of some speed), I'd recommend a parser combinator library like nom. Tons of examples here : https://github.com/Geal/nom/issues/14 
Rust's old `do` didn't actually reduce indentation levels, and still wouldn't today. You can always write this: x.f(a, b, c, || { // single level of indentation }) The thing that would reduce the number of levels is the `fn f() = ...` syntax, transforming this: fn f() -&gt; impl Generator&lt;...&gt; { FutureFromGenerator(move || { // two levels of indentation }) } Into this: fn f() -&gt; impl Generator&lt;...&gt; = FutureFromGenerator(move || { // single level of indentation }) Of course you can still do that without the extra syntax, it's just a little weirder because you wind up with `}) }` on the final line. And by the same argument the `do` syntax does improve things somewhat by removing that final `)`: fn f() -&gt; impl Generator&lt;...&gt; = do FutureFromGenerator() move || { // single level of indentation } The current prototype has yet another solution to the double-nesting, which is the `#[async]` macro. That's a bit more opaque, but at the same time it does also rewrite the return type for you.
I see now. The argument of "what if you copy+paste your masterpass into facebook" is what really won me over. I've opened **[this issue](https://github.com/vitiral/artifact/issues/177)**. Does that design look reasonable to you? I think I could probably reduce the size of the secret to 512 bytes... something that is copy/pastable if you wanted to. 512 bytes is already an incredible amount of entropy.
Rust already supports use foo::{bar, baz}; In some senses, this RFC makes things more consistent; you can now do this for any level of a `use` line, not just the terminal part.
Sounds like a bug to me.
Very happy to see stack traces with line numbers on OS X landing. That was a real pain point the last time I was working regularly with Rust (It's a testament to Rust's compile time guarantees that this wasn't a show-stopper).
&gt; You can always write this: every time I've done that, it backfires, e.g. what if those other parameters want line breaks. There's no two ways about it. It's an extra nesting level (and it's really the bracket nesting that the brain is reading). The trailing-lambda idea combats it, which is why Julia, Swift, Nim all have something similar. conversely, why don't you advocate 'for loop' bodies or whiles etc inside a nesting level? that would be silly, wouldn't it. My desire is for a language where high-order functions can be used for custom (e.g. parallel) iteration and it looks as natural as the languages 'inbuilt' means of looping. Thats what rust showed me in it's original form.
&gt; The struct performs exactly the same function in either case, at least as far as the programmer is concerned, I think this is the key disconnect; a struct that owns and a struct that borrows are very different, and this is a key aspect of Rust.
This also makes preludes a bit more useful. Currently it is shorter to write `use module::{a, b, c, d};` than `use module::prelude::*; use module::{c, d};`.
I recognize that you are technically correct, but consider these things from a higher level: "This struct lets me pass a user's name and age to this function." struct Foo { name: String, age: u8 } vs. "This struct lets me pass a user's name and age to this function." struct Bar&lt;'a&gt; { name: &amp;'a str, age: u8 } Again, I get that one of them is storing the name and the other is referencing the name, but as far as the guy writing the code is concerned, the difference is that there are a lot of angle brackets and an apostrophe thrown into the latter, and it takes a long time to go from one form to the other. Edit: it takes a long time because changing from one form to the other requires you to hop around all through every implementation and add or remove forward declarations of the lifetime, etc. And this is significant for the kind of people you're talking about--the ones who only dimly recognize there is any difference between the two--because *they are the ones who are apt to wind up doing it the most.* At least, in my case, when I was still figuring this stuff out, I spent hours adding and removing lifetimes from crap because I kept quibbling over whether or not to borrow some bit of data to avoid copying it (and, more to the point, *how* I could borrow it--which was, to me, nontrivial at the time).
Yup! Piston developers have a great library called image that lets you edit channels in images of various types. https://github.com/PistonDevelopers/image
This outcome doesn't seem to be anything to celebrate.
Yeah, I mean, I guess what I'm saying is that this view isn't really the right one, as it's missing something very important. I *do* agree that doing the refactoring is a pain. It's an important pain though.
I feel like this is an argument about implicit side effects in general. Threads, blocking IO, allocation, panic handling, etc. all have the same problem. Given that implicit side effects are already prevelant in Rust, I'm not so sure there's a major impact. While I don't have a complete view of the problem, Rust's move semantics, borrowing and auto traits seem sufficient to protect us against the worst problems of implicit yield points. I'd prefer if we had some way to control effects more generally like an [effect handling system](https://internals.rust-lang.org/t/async-and-effect-handlers/5801) rather than throwing syntactic salt at the programmer and telling them "its obvious now, go figure it out".
&gt; My desire is for a language where high-order functions can be used for custom (e.g. parallel) iteration and it looks as natural as the languages 'inbuilt' means of looping. Thats what rust showed me in it's original form. But Rust violates Tennent's Correspondence Principle (TCP) you can't `break` out of it or early `return` out of closure regardless of the syntax sugar for passing closures. So despite how it looks, its never as natural as syntax constructs. I believe Ruby, Nim, and Julia are TCP following languages and do allow you do treat blocks more natively. In my experience the lack of TCP in rust is a much larger ergonomics issue than writing an extra paren.
Note too that the target_feature RFC is seen as the path toward stable SIMD.
Thanks!
Early Rust *also* tried to let `break`/`continue`/`return` work from closures used to implement control structures. `for` used to be entirely based on this! What we learned was that even with all the extra complexity to make that work, it was *still* not as good as what we have today. Reifying iterators is far more powerful for far less language complexity. And on top of that, if we use the extra complexity budget we got back from ditching TCP to implement coroutines, we get the best of both worlds! Custom control structures that are based on scoped continuations rather than higher order functions are a much better fit for an imperative language like Rust.
Links are a great idea. &gt; I would have you go into further detail about the types you talk about (like ItemId) Yeah its difficult to strike a balance between necessary details and avoiding information overload. I leaned towards the latter because this is meant as an overview/introduction, and once someone knows the general role a type plays, hopefully the source can serve as the canonical authority for further questions. Thanks for the feedback!
This is deliberate: https://github.com/rust-lang/rust/issues/44232
For the Travis build, looks like you are missing some of the dev packages needed. For instance, your most recent build is erroring out finding `cairo.pc`. Looking on a recent Debian system, looks like that's found in `libcairo2-dev`, it's probably the same on whichever Ubuntu distro Travis is using. I found the package needed by using `apt-file search cairo.pc` (which gives a number of packages since there are files with that as a substring in several, but it's pretty easy to pick out the right one). You can install `apt-file` on any Debian or Ubuntu based system, run `apt-file update` to pull down lists of package contents, and then use `apt-file` to find what package you'll need to install to get whatever missing file it's complaining about. I'm less familiar with MinGW, but I notice in the errors that you seem to have a stray space character in front of the targets listed: bash -lc "pacman -S --noconfirm \ mingw-w64-i686-gtk3 \ mingw-w64-x86_64-gtk3 \ mingw-w64-i686-cairo \ mingw-w64-x86_64-cairo \ mingw-w64-i686-toolchain \ mingw-w64-x86_64-toolchain \ mingw-w64-i686-openssl \ mingw-w64-x86_64-openssl \ mingw-w64-i686-pkg-config \ mingw-w64-x86_64-pkg-config \ mingw-w64-i686-gobject-introspection \ mingw-w64-x86-64-gobject-introspection" error: target not found: mingw-w64-i686-gtk3 error: target not found: mingw-w64-x86_64-gtk3 error: target not found: mingw-w64-i686-cairo error: target not found: mingw-w64-x86_64-cairo error: target not found: mingw-w64-i686-toolchain error: target not found: mingw-w64-x86_64-toolchain error: target not found: mingw-w64-i686-openssl error: target not found: mingw-w64-x86_64-openssl error: target not found: mingw-w64-i686-pkg-config error: target not found: mingw-w64-x86_64-pkg-config error: target not found: mingw-w64-i686-gobject-introspection error: target not found: mingw-w64-x86-64-gobject-introspection Which likely comes from [this part of the appveyor.yml](https://github.com/f5xs-0000a/akameneko/blob/ci_fixup/appveyor.yml#L52), though I don't know exactly how the YAML and batch command quoting are interacting to produce this result: # install GTK here # TODO: separate these so that only designated archs get designated packages - bash -lc "pacman -S --noconfirm \ mingw-w64-i686-gtk3 \ mingw-w64-x86_64-gtk3 \ mingw-w64-i686-cairo \ mingw-w64-x86_64-cairo \ mingw-w64-i686-toolchain \ mingw-w64-x86_64-toolchain \ mingw-w64-i686-openssl \ mingw-w64-x86_64-openssl \ mingw-w64-i686-pkg-config \ mingw-w64-x86_64-pkg-config \ mingw-w64-i686-gobject-introspection \ mingw-w64-x86-64-gobject-introspection"
Yes, but it doesn't have to be a keyword- it can just be a library function. I described how Kotlin does this: &gt; Getting a reified Future-like object is done not by leaving off the yield keyword, but by calling a library function on the coroutine itself (or usually a coroutine lambda that calls it). Your example in Kotlin looks like this: val x = async() { getStockQuoteFromGoogle() } val y = async() { getStockQuoteFromYahoo() } val result = race(x, y) As an additional interesting point on top: Because `async` is just a library function here, it's how you control where the coroutine runs- you can run it on the same thread, you can farm it out to a thread pool, etc. If you get your future just by calling a function without `await`ing its result, by default you end up relying on whatever that function decides. It's an interesting tradeoff.
maybe it would have been possible to 'overload' break, return .. or at least warn about their use (of course for the data-parallel use case that interests me, you simply want to disallow the idea of returning from the enclosing function) making 'return' do something different to plain 'trailing expression return' might have been ok
I made an algorithm to check whether a given String is a palindrome. I can use this to solve a project euler problem.
`someFutureComputation(a)` isn't a `suspend` function call, so it's obvious that you're suspending by using `await()` on it. You can't tell what functions are _suspendable_ and what aren't by looking at the call site. I think that's the main complaint here, and IMO it is a completely fair complaint especially considering the suspending gutter icon is only visible if you happen to be using IntelliJ.
See my sibling. Its unfortunately not easy or cheap to make closures preserve break, continue, return behavior through closures. You end up needing to implement it as more or less exceptions with unwinding which is a non-starter for many rust domains. You could make blocks and closures different syntactic constructs like Ruby does, but explaining the difference between a block and a lambda in ruby is a frequent source of confusion even for advanced users. That also violates some of the benefit of the cleaner syntax. A warning might be a good idea however, I do frequently use early return in closures. 
For anyone who wants to use this code snippet, counting menus/menu items starts from 0. match wparam { 0 =&gt; Some(FileEntries::New), ... } and under WM_COMMAND it needs to be an option Some(FileEntries) =&gt; unimplemented!(), except for that everything works perfectly!
Which is actually exactly how tokio does framed protocols ;)
Can I fill an array or a vector by defining the range . Something like . let a = Vector::new(); a = [1..100] I know this doesn't work but I wounder if there is something like that. 
`let v: Vec&lt;i32&gt; = (0..10).into_iter().collect();`
An RFC can be (and often is) merged without an implementation; that's the case here. If you look at the RFC https://github.com/rust-lang/rfcs/blob/master/text/1598-generic_associated_types.md It links to this tracking issue: https://github.com/rust-lang/rust/issues/44265 Which shows that it's not implemented at all.
&gt; IntelliJ IDEA (pretty much everybody uses it when doing Kotlin development) clearly shows all the suspension points in the gutter, and, AFAIK, you can even set things up so that suspending functions are highlighted differently. I'll be clear, for me **requiring an IDE is a non-starter**. First of all, it requires using one of the IDEs that has implemented this particular piece of functionality; that Kotlin comes with Jetbrains is rather expected, but Rust is not, and I argue should not, be tied to any specific IDE. Secondly, syntax highlighting, little icons, etc... are NOT a panacea. Blind or visually impaired users, for example, are very unlikely to benefit from it as I seriously doubt that their screen readers are sophisticated enough to reproduce those nuances, even if they can use the IDE (which is not a given). This is why for me a specific syntax is **necessary**; anything else is implicitly casting off some users.
Okay, thank you.
One simple addition i would make is to wrap your `establish_connection` with a ["connection guard"](https://rocket.rs/guide/state/#connection-guard) and let rocket manage it. 
&gt; **Sorry, because of its privacy settings, this video cannot be played here** Okay... great... a TL;DR?
Thanks.
Some stats, for fun: Searching through all the past (i.e., not currently open) RFC pull requests, out of 468 PRs that were assigned to a sub-team, 288 (62%) made it to final-comment-period, and 182 (39%) were merged.
While I agree that doing things Kotlin-way may not work for Rust (in my comment I was specifically talking about Kotlin), having explicit syntax for this in Rust doesn't really help, because you have macros in Rust which can hide that syntax, just as `suspend fun`s can hide the more standard suspending functions in Kotlin. I guess the advantage is that macros are rarer and more suspicious-looking.
With the Public/Private Deps RFC AFAIK the lowest version resolution change is only for when publishing to verify that your version bounds are valid and that you are not relying on features added in a later minor version than your lowest bound. Edit: Just wanted to clarify this as you this means that you will still get bug fixes for free at compile time, but if you rely on that bugfix you will need to update your dependencies, as you should anyway.
It's still possible to participate... but you have to choose your battles. Most RFCs I skip, but some high-profile ones (const generics, module revamp) I followed avidly because I thought they were important enough to warrant my attention. If you limited the number of RFCs to what a casual user could review, you would not be getting anywhere.
I think more interesting than the point about IDE support is the point (made elsewhere in this thread) about the density of `unsafe` annotations: `await` exists on every suspension point. `unsafe` only marks whole blocks/functions, while simultaneously being much more crucial than `await`. In async-heavy code, `await` leads to an awful lot of noise. Implicit suspension, importantly, still marks closures/functions as async, but without so much noise. Further, implicit suspension *does* make it explicit when you defer suspension, which is the weirder case. So in the end it's not a question of "do we want an explicit syntax or not." It's a question of *how* explicit and *which* operations should be explicit. I think that needs to be considered rather than taking a hard-line approach.
Valid point, `suspend fun`s are the other 10% of the time. At least in my experience, YMMV.
I think macros are fine because: - they are explicit, so indeed more suspicious-looking, - you probably use few enough in your code to know which induce a `yield` (and on what argument).
Also, range implements `Iterator` directly, therefore you don't need `into_iter()` call - simply `(1..10).collect()` also works.
Ah crap, really? TL;DR: It's important for any widely-used technology to be very explicit about its values so that the criteria for what constitutes an acceptable change/addition/etc to the language/ecosystem/etc are clear. The example given was about the conflict between Joyent (the steward of Node for a number of years), who generally value reliability, operability, and stability above all else, and the community of Node users, who generally value approachability and ease of use above all else. The speaker talked about how this made it fundamentally impossible to come to resolution about certain issues, and ultimately led to the split of the community and to Joyent giving up control of the project.
My code for wrapping a Postgres connection pool in a Request Guard [&gt;&gt;here&lt;&lt;](https://github.com/ghotiphud/rust-web-starter/blob/aa47487fe050a322a77bacd62b830fd20adc7f57/api_server/src/pg_pool.rs)
I just occasionally try to raise concerns that are apt to be more apparent to people with that jitted/garbage collected background. :p
I think you want /r/playrust.
Ye Ik i messed up
wrong sub friendo
I like this approach to learning. :-) Not much to add here... If you want to simplify your getting started documentation steps, I find that Docker/Docker-Compose are good tools. [Hopefully useful blatant self-promotion](https://github.com/ghotiphud/rust-web-starter)
What are your vim-rust plugins?
I don't see how this is clearer (for reading) than: use crate::{foo, bar}; use crate::baz::{Foo, Bar}; I keep waiting to be impressed by some example where this syntax looks cleaner and/or more readable.. I just haven't seen it yet.
I suppose in this specific example, yes you are cloning the `str`. But that sort of disregards the whole point of the post - strings are just one of the easiest non-copy types to create and we're trying to avoid `clone`ing to insert (the creating of the object is out of the scope of the question).
New reply because I just realized something new about this (ping /u/matthieum, /u/Quxxy): Because you can only call `suspend` functions from other `suspend` functions or closures (much like `unsafe`), you can't accidentally fire off an async operation and ignore its result. This may very well be a bigger deal than always knowing precisely where the suspension points are. This is somewhat mitigated in the explicit case by a static type system- if you try to use the result you'll get a type error. Further, we could make the result `#[must_use]`. But requiring an explicit `runBlocking` or `run` call like Kotlin does might be even better, since the `let _ =` idiom for dropping a `#[must_use]` value doesn't say anything about concurrency. **edit:** Plus, an explicit call gives you a convenient way to tell not only *that* an async operation is starting, but also *where* it's being run.
I think I'd rather see this as: use std::sync::{Arc, mpsc, atomic, atomic::Ordering} Once you start nesting braces, I personally find it more readable to just break it out into a separate use statement. But I keep telling myself that maybe if I see the nested syntax enough, I'll start to get used to it.
Yes, I can and it's very easy with `bmp` crate, but the task is to compare 2 methods: BitBlt and pixelwise.
Would you mind telling why you find it troublesome? It's only a single line in build.rs println!("cargo:rustc-env=BUILD_TIMESTAMP={}", &amp;chrono::Utc::now().timestamp().to_string()); and then it's simply accessible via `env!("BUILD_TIMESTAMP");` in your source.
Note that implementing it requires integrating Chalk into Rust. AFAIK it isn't done yet and I guess it'll take some time.
PSA: When checking your tire pressure, kicking them is not sufficient. Who can we thank for this migration?
Yeah, I intuitively tried to do what this RFC proposes and got compile error. This will remove one more rule to remember for me.
Yeah, I think this will be the most useful example: use crate::{foo, bar, baz::Foo};
&gt; Who can we thank for this migration? I did the actual port (https://github.com/rust-lang/rust-by-example/pull/897) but what really enabled it was projektir's great work on mdbook: https://github.com/azerupi/mdBook/pull/338 and budziq and azerupi fixing bugs as I found them: https://github.com/azerupi/mdBook/pull/440 and https://github.com/azerupi/mdBook/pull/439
yep. that example is more interesting to me, but I sorta feel we could get that without supporting the nested braces portion of the RFC.
`Image` is very nice crate, but as a new it's quite challenging to understand how to set needed channel, wish they had more examples in the docs.
Thanks, it's nice having this now hosted on a rust project. Also typo on "2.1 **Litearls** and operators"
And stable inline assembly?
/r/playrust
thanks lol
I'm curious what their rust code looks like, because I feel with Rust being move by default it should be able to close the gap or beat C++ on it's memory footprint. It's curious seeing Go sweep in above Rust in the memory footprint department.
That's indeed better, mine is just merging what was previously a 2 liner into a 1 liner :)
Thanks! I merged a PR fixing this, should be live soon.
This looks like the benchmarks game to me.
&gt; mdBook . &gt; https://github.com/azerupi/mdBook . &gt; implemented in Rust Hmmm. Yes, I approve of this :D
That's cool. It'd be nice if conversions from literals could be done at compile time with macros.
&gt; and there's no guarantee anyone will ever step up to implement it That makes me wonder... What's the maximum time it has taken for a feature from RFC-merge to an initial implementation in nightly? Is that timespan longer than the difference between now and the oldest merge of an RFC that hasn't been implemented yet?
I thought about jumping into Docker but didn't. I feel like, while being chill on the actual setup side, using docker for a new programmer would be a little more of an undertaking. For an experienced programmer, getting up and running with Docker would be much faster if they hadn't used it before.
Using a connection pool and guard are definitely on the list of changes to be made.
Here's a snippet to get you started let img = image::open(&amp;Path::new(&amp;"mypicture.bmp")).unwrap(); let out = ImageBuffer::new(img.width, img.height); for (x, y, pixel) in img.pixels() { let mut tmp_pixel = pixel; tmp_pixel.data[1] = 0x00_u8; //data[1] is the b channel out.put_pixel(x, y, tmp_pixel); } That exact code might not compile but it's very close. You can look at my repo (which uses the image library heavily) for some more [examples](https://github.com/teovoinea/steganography). Also, here are the docs for the crate https://docs.rs/image/0.15.0/image/
I put off learning Docker for a long time until I had to work with some older projects recently... One was a PHP app that hadn't been worked on in a while and getting everything setup to run locally was a pain until I remembered Docker. Turned hours of setting up my laptop with old versions of things into a quick couple Dockerfiles. Convinced me to wrap my new projects from the start.
&gt; We consider ten different programming problems that are expressed in each of the languages, following exactly the same algorithm, as defined in the Computer Language Benchmark Game (CLBG) [11]. We compile/execute such programs using the state-of-the-art compilers, virtual machines, interpreters, and libraries for each of the 27 languages
There a reason the README and CONTRIBUTING are [gone](https://github.com/rust-lang/rust-by-example/commit/6845594d3344ca88797ba786a66e907c49ddfb96)? I don't see them merged into the core of the documentation. What I found useful - Build instructions. If I hadn't seen this reddit post, I probably wouldn't have recognized that I need to lookup how to use mdBook to build this. - Mechanism for discussing proposed content. 
If you're doing a plugin architecture, you should have your plugins be compiled as cdylibs and declare `#[no_mangle] extern "C"` functions so they have a stable ABI. Then you can import them with `libloading` as /u/steveklabnik1 mentions.
&gt; cdylibs are for non-Rust consumers, rlibs are for Rust consumers. Rlibs are specifically for Rust consumers being compiled with the same compilers or at least compilers using compatible ABIs. To my limited knowledge, they're not considered stable for a plugin architecture.
I'm currently re-doing them entirely; they'll be back shortly. Thanks for making sure I don't forget! EDIT: They're back! Tomorrow I'm going to be doing issue labels, and will update CONTRIBUTING with those then.
Yes, the same compiler is a requirement.
If you only look at the results page, this is something to keep in mind: &gt; In some cases, the programming language name will be followed with a ↑x /↓y and/or ⇑x /⇓y symbol. The first set of arrows indicates that the language would go up by x positions (↑x ) or down by y positions (↓y ) if ordered by execution time. For example in Table 3, for the fasta benchmark, Fortran is the second most energy efficient language, but falls off 6 positions down if ordered by execution time. The second set of arrows states that the language would go up by x positions (⇑x ) or down by y positions (⇓y ) if ordered according to their peak memory usage. Looking at the same example benchmark, Rust, while the most energy efficient, would drop 9 positions if ordered by peak memory usage. You'll see Rust and others with these arrows. The paper is short and easily consumable - I recommend it.
Agreed. I don't doubt the usefulness of docker at all. For this project specifically, I'm thinking more about the experience for new programmers coming to it and wanting to spin it up to try. I know for me at the beginning, having to learn another piece of tech on top of what I'm already learning, whether it's complex or not, still ads to "pile" that quickly becomes overwhelming if it isn't already. All that being said, Docker is definitely something I'll integrate with future projects.
Thanks for the example! For pixelwise part i ended up with the following code: fn remove_blue_pixels(mut img: bmp::Image) -&gt; bmp::Image { for (x, y) in img.coordinates() { let mut pix = img.get_pixel(x, y); pix.b = 0; img.set_pixel(x, y, pix); } img } Do you have any ideas how to apply such effect to whole image at once?
&gt; Neovim is for sure better than Vim for when you need certain extensions to run asychronously (linters like Ale and Neomake can do that). I don't want to start a fight, just wondering: How is neovim better in this, than Vim 8?
&gt; How much of my .emacs (here it is for anyone who cares) and how many of my packages can I still use? My understanding is that remax intends to be 100% compatible with emacs, so it should all work.
This isn't quite accurate; its more like we're going to refactor the compiler based on things learned from chalk. chalk's end state is as a tool to verify that the compiler is correct and to experiment with extensions to the language in a simpler (but slower) implementation.
In my experience it's mostly a case of the async plugins that came to neovim first, and some don't plan on supporting Vim 8.
Take a read of the FAQ section on the [homepage](https://neovim.io/#) and the [vision](https://neovim.io/charter/) gives a little insight as well. EDIT: People on the #neovim IRC channel might be able to give you more details than I can.
Holy hell, really? That's a tall order for any Emacs fork to fill, and if it does allow me to use all my packages; that's fucking sweet.
[This section of *Structure and Interpretation of Computer Programs* is never not relevant:](https://mitpress.mit.edu/sicp/full-text/book/book-Z-H-24.html#%_sec_3.5.5) &gt; On the other hand, if we look closely, we can see time-related problems creeping into functional models as well. One particularly troublesome area arises when we wish to design interactive systems, especially ones that model interactions between independent entities... &gt; ...This is precisely the same constraint that we had to deal with in section 3.4.1, where we found the need to introduce explicit synchronization to ensure a "correct'' order of events in concurrent processing of objects with state. Thus, in an attempt to support the functional style, the need to merge inputs from different agents reintroduces the same problems that the functional style was meant to eliminate. &gt; We began this chapter with the goal of building computational models whose structure matches our perception of the real world we are trying to model. We can model the world as a collection of separate, time-bound, interacting objects with state, or we can model the world as a single, timeless, stateless unity. Each view has powerful advantages, but neither view alone is completely satisfactory. A grand unification has yet to emerge.
Thanks for your reply! I have not read that book but it looks like such a good resource I'm looking through it right now!
I've always wondered why AWS and Google Cloud didn't push Java, Ruby and friends more, because the cost model is based pretty directly around RAM. &lt;tongue in cheek&gt; They should be attempting to stifle the efforts of Rust, C++, etc. &lt;/&gt;
Thanks for the suggestions! Nom is definitively great for parsing binary data! However, I was looking more for issues specific to protocols, like how to handle multiplexing, framing, dealing with timeouts, initial handshaking/connection setup, etc. Do you happen to have some good suggestions there as well? :)
Thanks for replying! That is actually one of the ones I have on order from Amazon for when it comes out in a physical, edited version. Do you have any experience with that book?
It's not a re-implementation, it's a gradual port. And it's not re-doing any elisp code, only the base C stuff.
I couldn't find a direct function for it, but could you do something like let no_blue = img.pixels_mut().map(|p| p.data[1] = 0).collect(); ?
so, I hit something unexpected: the secret key can only be 32 bytes!!! I don't like this. The password can be 2^32 bytes, but the key can only be 32 bytes. I'm considering swapping them: the string the user enters is used for the "key" and is capped at 32 bytes in length. The randomly generated "secret" will be used for the "password". The salt will stay the same. What do you think? I could also just append to the password and ignore the "key" -- I really don't see the point of it.
&gt; For example, if you use the auto-package-update package to update packages automatically at startup... I wouldn't do that: a bad update would mean an unusable Emacs just when I need it. Or at least, backup the elpa folder before proceeding.
I couldn't find this functionality on crates.io, so I whipped it up.
Yes, that would be nice. I intend to look at using procedural macros to auto-derive conversions to and from other enums, maybe that would allow compile-time range checks for literals, too.
Nice! I guess I'll play with it. When reading your post I thought this crate might analyze functions for certain properties and generate doc comments for it: for example, if a function is `fn f(a: i32, b: u64) -&gt; Result&lt;Option&lt;SomeType&gt;&gt;;`, it would generate a doc header with: // Main description placeholder // // Details placeholder // // # Returns // // * `Ok(Some(SomeType))` when... // * `Ok(None)` when... // * `Err(e)` when... // And so on. Also with a section for parameters, unsafe code explanation (if any) and panics description (if any). Have you something like this in mind? Would be awesome to have something like that! (I'm on mobile, hope formatting is not broken too much) 
Oh yea I commented that section of my `.emacs` out.
Ah...yea that makes more sense.
Ok, this may be true. But some support Vim 8, e.g. the mentioned Ale. I've yet to run into an async plugin I want to use that does not support vim.
Neat. A friend was wanting this sort of thing for Haskell recently but he also programs in Rust so I forwarded it along to him.
If you know the lengths are the same, you can `mem::transmute` the slices. This isn't safe, but it's fast. You could iterate the values and convert them. This isn't fast, but it's safe. Decide how much you trust your input, and select accordingly.
Using `grep` to find what files use a particular import is broken more and we have to rely on IDE.
Ah yes, I forgot about transmute actually, thanks a lot.
They're pushing Javascript, no? In AWS at least it's one of the main supported languages.
Rust provides an abstraction for C Strings called [`std::ffi::CString`](https://doc.rust-lang.org/std/ffi/struct.CString.html). It's comparable to `Vec&lt;u8&gt;`, except it will automatically handle null bytes for you. Additionally `as_ptr` method of `CString` returns `*const std::os::raw::c_char`, which is probably what you want for interacting with C API that wants `char *` parameter (on some operating systems, `char` is signed (`i8`), on some it's unsigned (`u8`), `c_char` uses one your operating system uses).
Please note that transmuting `Vec` and slices is [explicitly undefined behaviour](https://doc.rust-lang.org/nomicon/transmutes.html). It's a good idea to use `slice::from_raw_parts` and `Vec::from_raw_parts` instead of `transmute`.
RFC 16 (attributes on blocks and expressions) was the contender for a long while... I think it is finally fully implemented but parts are still unstable.
yeah I am using CStrings already, but my problem is that the c library takes fixed size buffers, fills these in with some bytes and hands them back to me, so I get buffers that have not only one nul byte at the end but most of the time many more. And with this I am unable to create CStrings out of those buffers, since this will create a NulByteError or what they are called 
To me it just seems less surprising to allow full use of braces, given that it exists at all.
In that case, what you can do is this. 1. Make an array or `Vec`. 2. Take a pointer to it with `as_mut_ptr`. 3. Pass it to C function. 4. Use `CStr::from_ptr` API on pointer from step 2. Note that if you use `Vec`, the C API won't be able to extend that vector by itself, as `Vec` is a Rust concept. You will need to use `Vec` if you want dynamic array length however.
But...why? Just because mdBook is written in Rust?
I think you got downvotes because this was already posted here a few hours ago, that's all. :)
Yup. Transmute is like using dental floss for a guard rail and should be handled really carefully.
I guess I'm not very energy efficient :(
&gt; I feel with Rust being move by default it should be able to close the gap or beat C++ on it's memory footprint only if they forget to use 'move' where needed in C++. 
Do you have a bitcoin wallet/paypal I can donate to? This has abstracted away one of the largest chunks of boilerplate I dread writing. 
I appreciate the kind gesture, but I'll politely decline :)
Lol it happens :)
If your emacs startup time bothers you, I recommend running it in server/client mode. https://www.emacswiki.org/emacs/EmacsAsDaemon
Yes and no. GitBook is a fine project, but to be able to use it, we had to make a custom build system, and some custom plugins. With mdBook, it just works. Beyond that, it is *also* much easier for people to get involved with an mdBook based project because it *is* in Rust, for multiple reasons. First, because we already know people have Rust installed, but have no idea if they have node installed. Second, because every other long-form doc project uses mdBook; nothing else in the Rust ecosystem uses GitBook. This also opens the path to things like "Rust by Example can be distributed with the rest of the docs", all kinds of other things. Basically, not *because* it's written in Rust, but because of all that that implies.
It seems like the table-of-contents search is gone. Any chance of this coming back?
Is it really explicit undefined behavior if you transmute a Vec&lt;i8&gt; to a Vec&lt;u8&gt; though? I mean I get the risks for most transmutes, but I cant really see the problem in doing this. Mind explaining me what might go wrong there if you wouldnt mind?
I wrote an alternative to `ls`, which lists directories and files in two columns. It isn't aiming to be a full replacement to `ls`. Just a pretty version for 99% of day to day use. [This is what it looks like.](https://i.imgur.com/jDnp5vg.png) I had a bash script doing it but it was too slow (as much as 500ms in some folders when it should really be instant), and too buggy. The code is kinda bad. I just turn all my directories and files into a giant string, and then iterate over them together to multiplex them into one output. The printing especially is awful. `print!` which I believe is non-buffered, and so pretty inefficient. But it was pretty trivial to all get done. It also does run instantly (well around 60ms at worst). I have a few other bash functions which I use. Shorter and slightly more intelligent versions of a fuzzy find, grep, sed, and 'fuzzy find and then open in an editor'. I may move these into Rust CLIs too.
Neat! Looks similar to [enum-methods](https://github.com/alekratz/enum-methods). Maybe the two crates can learn things from eachother?
https://doc.rust-lang.org/std/mem/fn.transmute.html The documentation outright says that `std::mem::transmute::&lt;Vec&lt;&amp;i32&gt;, Vec&lt;Option&lt;&amp;i32&gt;&gt;&gt;` is [undefined behaviour](https://en.wikipedia.org/wiki/Undefined_behavior), and conversion from `Vec&lt;u8&gt;` to `Vec&lt;i8&gt;` is very similar in what it does. What happens when you do it anyway? It may work. It may not work. It may cause mysterious crashes that would be pain to debug later on. It may stop working in later version of Rust. I don't know about you, but I don't like to put bugs in my programs myself. Especially when there is an alternative - `Vec::from_raw_parts` which doesn't have undefined behaviour.
It's wanted in mdBook generally; something to be added in the future for sure. Until then a workaround is control-f on the print page.
Ah alright I read through the docs there, but I thought that `std::mem::transmute::&lt;Vec&lt;&amp;i32&gt;, Vec&lt;Option&lt;&amp;i32&gt;&gt;&gt;` was a bit different from `std::mem::transmute::&lt;Vec&lt;u8&gt;, Vec&lt;i8&gt;&gt;`, cause in the latter the only difference is a primitive of the same size. But yeah, from_raw_parts obviously is the better choice for such a thing
Javascript seems do have done really well in these results. Notice how it trounces all the other interpreted languages (apart from Dart/Typescript which share the same engine). Say what you will about the language itself, but the engineering work on the part of browser manufacturers to make Javascript perform is really impressive.
I am gonna try that out tomorrow and see if that works for me, thanks
`&amp;i32` and `Option&lt;&amp;i32&gt;` both have the same size, just saying. It's just that `Option&lt;&amp;i32&gt;` uses 0 to mean `NULL`, while 0 value in `&amp;i32` is invalid (causes undefined behaviour).
Feedback is always kindly accepted. I hope this can be of use to someone other than myself!
r/rust_gamedev --------------------------------------------- [^(Why is this bot needed?)](https://np.reddit.com/r/botwatch/comments/6xrrvh/clickablelinkbot_info/) ^| ^(Downvote to remove) ^| ^(PM for sub to be ignored)
&gt; I'm curious what their rust code looks like I think the code is there: https://github.com/greensoftwarelab/Energy-Languages/tree/master/Rust 
Yes, I've read the pre-release editions. It is generally geared towards those that have done some systems programming with C or C++, but I think it's fine for a motivated person who is comfortable in a higher-level language. It has diagrams [like this](https://i.imgur.com/wOXbiAv.png) to help you visualize how objects are laid out on the heap and stack, which I think is nice. I'd say a prerequisite is that you need to be comfortable with things like pointers, stacks, and heaps since it assumes you know what those are. The concurrency sections assume you know what threads and processes are, and explains Rust's take on that, etc. 
It's significantly better than JRuby, Erlang and Dart but it seems to be pretty much on par with Java in terms of RAM usage in most graphs, and worse than PHP, Python, and Ruby according to the normalized global results table ([section B](https://sites.google.com/view/energy-efficiency-languages/results?authuser=0)). Or am I somehow reading the results wrong? I quite like the language actually, but it isn't the most memory saving one. I had to experience that aspect myself recently too when deploying on AWS.
That would be a fun template Haskell project! Of course, lens already does it with prisms... 
Is this similar to the bitflags crate? Or does it provide functionality that bitflags doesn't.
Neovim was the result of vim being incredibly difficult to work on, with many features like async stuff not being merged for silly reasons. Neovim includes significant code base improvements along with the async stuff. My neovim plugin uses features that still aren't supported by vim 8, I believe. 
I do this, Emacs starts as a systemd user service, then I use emacsclient to connect to it. I can close my Emacs windows without closing the buffers.
It might use a bit more memory, but the cost calculation for AWS is usage multiplied by time, so you'd have to multiply the time and memory results together to get an idea of the approximate cost. With Javascript roughly 4x-9x faster than the other scripting languages, using a little more memory isn't going to affect the cost nearly as much as using less memory for a much longer period of time.
better idea: develop a processor that executes javascript natively. u mad
The repository is now on GitHub, [link here](https://github.com/jsonnull/valor). I plan to add a lot more details to the repo over the next few days, it's still very new.
Bluntly, that's not going to happen, because it's a terrible idea. 
In [Chapter 11](https://rustbyexample.com/attribute.html), it looks like the HTML comment in the source is interfering with that first unordered list. GitHub's Markdown renderer doesn't seem to care, but apparently mdBook's does.
［］ is a slice so u need to convert it
Can you explain why in a sentence?
That's correct. Values in the high and low surrogate ranges can never be legal Unicode code points ("characters" in the sense of this post). High and low surrogate values are legal Unicode code *units* in UTF-16, but are not legal Unicode code *points*.
Awesome concept, definitely going to give this a read.
Most plugins will work fine on both. Naming 2 that I've used that have poor Vim 8 support: [deoplete](https://github.com/Shougo/deoplete.nvim) and [nvim-complete-manager](https://github.com/roxma/nvim-completion-manager). For me it was about the timing, neovim supported it first, so I migrated and never went back to vim.
JavaScript is a relatively high-level / abstract language. The mapping to machine hardware is non-trivial. Just look at how certain parts of the language, such as changing a "prototype" field, would work for a "native" JS CPU. You could certainly interpret a JS interpreter in silicon, but it would be hideously inefficient. Modern JS engines are "fast" because they do a shit-ton of program analysis -- they look at your program at a scope of many, many instructions in order to discover constraints (such as "this value could only ever be an integer"), and then they compile your code using the most efficient machine instructions for those constraints. If you built a "JS CPU", then you would not be doing any of that analysis, and your CPU would do a huge amount of work for every JS instruction. Just think about the work needed to implement "x + y". What would your processor do? x and y could be one of several different types: undefined, String, Number, Object, Array, etc. So your CPU first has to determine what to do, then do it. "Adding" two strings is nothing like "adding" two numbers. If you want anything like efficient JS, then you take the approach that all modern JS engines have already taken -- you build a JIT compiler, whose output is native CPU instructions that implement the JS code semantics. Once you have that, there is no *need* for a JS-specific CPU. It wouldn't have any benefit. People tried building "Java CPUs" waaay back in the 90s, and that was a terrible idea for essentially the same reasons. Compared to JS, Java is a better fit for this (admittedly terrible) goal -- it has a well-defined bytecode instruction format, which the CPU was intended to directly execute. But translating the bytecode to native CPU instructions was always better, so that effort thankfully died. 
This coincides with the benchmarksgame results, some of which are hurt by having no stable SIMD, some are hurt by not using Rust's perfect `noalias` information because of a LLVM bug (that will presumably be fixed by 6.0), and some are hurt by LLVM not optimizing as good as GCC. That said, the gap is impressively small, considering Rust is in it's infancy, whereas GCC is at a ripe age. Shoulders of Giants, I tell you. 
Well, they tried that with Lisp :)
As someone pretty new to Rust, I was looking for a project to work on to try and get better with the language and stumbled on the idea of making a CHIP8 emulator in Rust, so I've been trying: https://github.com/smt923/chip8 It's been pretty cool so far, and it's given me a new interest in emulators and lower level stuff too, the code is pretty ugly right now and I'm sure there's a ton of issues, luckily there's a lot of blogs and other code which has helped a ton. I also have my first contribution to any language, and to Rust, albeit a small documentation change: https://github.com/rust-lang/rust/pull/44472 Hopefully I can contribute some more, but for someone like me almost all issues and stuff seem pretty difficult, but hopefully I'll keep learning
Don't forget Rust moves and C++ move so are different, so even if they did, it may still not be the same exact thing.
Excellent, thanks for the specific version! I really like the idea of the async/await (I use the equivalent daily in .NET/TS) but I'm avoiding nightly/nightly features this time around - last time I went down a very deep rabbit hole trying out new features I wasn't quite ready for yet, and getting all the crates working together on nightly.
I suppose tagged memory might be possible, (see [lisp machines](https://en.wikipedia.org/wiki/Lisp_machine) ) r.e. dynamic types and GC (not really 'executing JS natively', but hardware more aware of it's underlying model) they are suggesting that post "moore's law" we might see more special purpose devices, following on from the CPU-GPU split. The most immediate is dedicated neural-net processors. Whilst my initial reaction to this post is "that's silly..", I did think again, taking this into account; might there be a market for a specialised tagged-memory machine, if security is so important?
**Lisp machine** Lisp machines are general-purpose computers designed to efficiently run Lisp as their main software and programming language, usually via hardware support. They are an example of a high-level language computer architecture, and in a sense, they were the first commercial single-user workstations. Despite being modest in number (perhaps 7,000 units total as of 1988), Lisp machines commercially pioneered many now-commonplace technologies – including effective garbage collection, laser printing, windowing systems, computer mice, high-resolution bit-mapped raster graphics, computer graphic rendering, and networking innovations like Chaosnet. Several firms built and sold Lisp machines in the 1980s: Symbolics (3600, 3640, XL1200, MacIvory, and other models), Lisp Machines Incorporated (LMI Lambda), Texas Instruments (Explorer and MicroExplorer), and Xerox (Interlisp-D workstations). *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
3rd* Behind C, and C++ like always.
ok Rust really does consume the variable, whereas std::move is supposed to leave the source in a valid state, but I wonder if C++ compilers can elide any details .. e.g. if a value is cleared, and the destructor checks if it's not cleared, (then does something), that check could be elided; ... it does sound complicated, but there would be strong demand for this, and there's already eliding machinery for RVO which was a prelude to some move-semantics use cases. I think static analysers would want to do the same tracking, so code to do this might appear for other reasons
Thanks for the response. It sounds like generic associated types are still a ways off then. I am really looking forward to this feature as I'd like to use a type family pattern. I guess I'll have to settle on a less elegant work around for now.
Do you know why this is? The nomicon has a list of possible causes and the only ones that may apply as far as I see are 1. transmuting between non-repr C types and 2. creating an unbounded lifetime Nr. 2 would just require explicitly given lifetimes in transmute as far as I see and nr. 1 I guess is because the memory layout of Option&lt;&amp;T&gt; is not guaranteed?
A mix of hardware and software support could probable provide wins over the current state of the art. This is pretty close to the way that Lisp Machines actually worked. There was still a compiler on a symbolics box, it just produced asm code that had a very simple s-expression syntax and had `cons` as a primitive instruction. One really obvious way to speed up any dynamic language with special hardware is to make the arithmetic instructions do the type checking in parallel with the actual arithmetic.
Cool! I didn't find that when searching crates.io; looks like there's a lot of overlap.
The idea of consuming the variable (binding) is a compile time abstraction. At runtime it should just be the case that a references is passed (no copy) and is then freed following the end of it's last useful scope.
I can't wait for SIMD and strict aliasing Rust to take off. I'll be pushing for HPC Rust for years to come. Watch out Fortran.
Since the field names are the same, it also looks really straightforward to use a pipe to combine the patterns on the left-hand side and just return the common field between them.
Hope you enjoy!
Yeah, I don't buy it. If performance is your goal, then JS (or most Lisps) are the wrong tool. And these days, power consumption is a huge limiting factor for logic design and performance. Even doing the tag check and dealing with the possible exception is expensive, compared to a simple "add" op that needs no type checking.
You're also forgetting move constructors, and hence exception safety, etc.
This should be top comment / tl;dr.
as I understand C++ acheives move semantics *through* move constructors (std::move doesn't actually move, it just recasts the object as an r-value reference to *invoke* the move constructor); r.e. exception safety, I've always used the subset of C++ with exceptions disabled, so I'm hazy on those details
concurrency is coming in emacs26 (python GIL style). remacs is not planning on changing anything (at least until they've port 100% of the C base to rust). They're working on making the code more amenable to future work by (as far as i know): - move to github - reuse 3rd part code (for instance for sha256 etc.), instead of having everything recoded in - cut exotic platform support - move to a modern language (better types, better macros, nowadays emacs does nothing that requires C).
I liked my HTTP status code enum with five hundred variants (representing codes 100–599).
That's weird. I've read several times that Chalk will become part of the compiler. Maybe I misunderstood it or it was poorly written.
Nice!
Thanks, that was a lot more straightforward than I thought!
Thanks, I set build.rs so that it sets the env var only if it isn't already set!
The other guy posted a paragraph, so here's my sentence: "There are no integers in JavaScript, just 64 bit doubles, so you can't have pointers."
Lie to C, not to Rust. Keep the Rust data u8, and cast the raw pointers as needed. You *might* want to check that the data you're passing is valid ASCII.
If you want a less intimidating foray into Rust compiler internals, [clippy](https://github.com/rust-lang-nursery/rust-clippy) always welcomes contributors &amp; we have mentored issues.
I really like the [Derive Error](https://crates.io/crates/derive-error) crate, but the documentation is really lacking and I've had trouble using it. Is there anywhere I can find a better documentation for this crate, or a crate that offers similar functionality that isn't error-chain?
&gt; especially knowing that it doesn't even *need* to hold onto the references. Technically there is no such thing as a collision-free hash function, but if you were to use a sufficiently large hash and strong hash function, you could pretend this is true. If that's what you want to do, keep a set of strong hashes. For example, if you're computing 512 bit hashes, a HashSet&lt;[u32, 16]&gt; might do the trick. Denial of service prevention (if you need it) may still require a randomized hash function, so don't feel too weird about hashing hashes. 
Lisp, in comparison, is a simple language.
Hey this is great! Wish more projects had this. 
2nd in 'normalized global result'. But this is just another benchmark. The point is less about the exact position than the ballpark, which is as expected the same as c/c++
I'm guessing the story would be similar to Java in proposing wasm for this scenario?
Is it? From reading the paper I had the impression it's very close behind C but with some margin, comparable to C, in front of C++. 
what about jazelle
I used the word "complex handling" because I don't know this handling very well myself :P. I started this project at the suggestion of Peter (the maintainer of libevdev) and this is what he said regarding this: evdev synchronization is **not** just sending a SYN_DROPPED, it's a bit more involved than that. which is why handling evdev directly is painful when you have more than one entity because everyone has to re-do all the handling and replicate all the bugs. anyway, a few things that libevdev does transparently, not sure which ones of those the evdev crate does: * handling of fake multitouch devices * synching of slots and per-slot state * transparent generation of missing tracking ids after SYN_DROPPED * various boundary checks with defined error codes if you request invalid data (e.g. event codes that don't exist on the device) * fd swapping on the same context * disabling/enabling events on a per-context basis, so you can disable/enable ABS_FOO and then not care about quirks in the client-side code. in the uinput code which we haven't done in the rust crate yet: * transparent handling of the UI_GET_SYSNAME ioctl * transparent handling of the UI_DEV_SETUP ioctl * automatic fd management of the uinput device if required (LIBEVDEV_UINPUT_OPEN_MANAGED) All of the above didn't happen because it seemed like a nice idea, it was because we needed it in the X drivers, libinput, etc. IOW, this is the minimum subset you need to be useful :) The hardest thing to explain is: it's very easy to make an evdev wrapper because the API is so simple. But the **behavior** of the API is complicated, unpredictable and often badly documented/understood. and that is what libevdev wraps so you don't need to know the details. Some bits from me: evdev-rs closely follows libevdev API and hence results in a one to one mapping between a c program using libevdev and a rust program using evdev-rs. This will allow people already using libevdev to shift to evdev-rs easily, whether it is a strong reason to go write a new wrapper might be debatable. 
whoa, so spacemacs should work with it ?
As far as I can tell lenses contains everything.
It happens to be third, behind C and C++, in the very first benchmark results table. There are, of course, many other benchmarks, including a few where Rust beats C and C++ (one or both). The "normalized global result (Energy)" table seems like the right one to look at if you just want to consider a single ranking, and as you say it ranks just a hair behind C there, at 103% of C's energy usage.
&gt; because of a LLVM bug (that will presumably be fixed by 6.0) Do you have a source for this, or are you just getting my hopes up for no reason? :)
But not by much.
One weird thing in the results: JavaScript scores 6.5x in time, TypeScript 46.2x. That means they are comparing totally different implementations. The tests look remarkably likes those of http://benchmarksgame.alioth.debian.org/, where you can see that e.g. the Mandelbrot implementation for JavaScript forks off multiple processes, while the TypeScript implementation doesn't. So, as always: take the results with a grain of salt.
One of the things I like about the Rust documentation toolchain is that it doesn't make any structured demands on comments - three slashes and a descriptive paragraph. (The 'panics' section is important because this is information not reflected in the public API). Compare with Javadoc etc! 'Examples are Tests' is pure genius, but it requires code to be written in comments using special rules. This used to drive me crazy, hence `cargo docgen`
&gt; in the very first benchmark results table I still have trouble to find said table. I had the impression that figure "B. Normalized Global Results"(Complete Set of Results website / Paper Table 4.) is the one of interest because it accumulates the findings of the various test scenarios. Is it in the Paper or the Website (Complete Set of Results)? EDIT: Sry, do you (or better bumblebritches57) mean the very first benchmark binary-trees? That's very cherry picking to concentrate on a single test – not to say that the benchmark game is any more valid and should be interpreted with a grain of salt.
&gt; In Rust a technique called type coercion is used to deduce the types Actually, you meant [type inference](https://en.wikipedia.org/wiki/Type_inference). [Type coercion](https://en.wikipedia.org/wiki/Type_coercion) is another name for implicit type conversion, such as how C lets you pass a `float` into any function which expects a `double`. That said, you did use it correctly when talking about Deref coercion... it's just not the same thing as type inference. (Type inference deals how data is *stored* while type coercion deals with how it's *converted*.) &gt; Fearless concurrency While elaborating, you missed a piece of low-hanging fruit. Rust's ownership system is used to guarantee that you can't forget to acquire or release locks. &gt; For instance, if the file_lenexample earlier had extra ; in the Ok(File::open(“test.txt”)?.metadata()?.len()); line, the compiler error is: Your markup here is a bit messy. For example, note the missing space after `file_len`. &gt; Object-oriented or not? One thing you might not have realized about traits: They let you safely add new methods to other people's types. For example, I have a project where I amend `str` with a method to get a wordwise iterator which identifies word boundaries using CamelCase. (Compare that to runtime monkey-patching in languages like Ruby and JavaScript.)
Thanks for the comments, very good points indeed. This is exactly the kind of feedback I was hoping for. I'll certainly add the lock release guarantee and type inference. I tried to balance how much to write about each topic to keep the post concise but still try to mention as many Rust features (especially the unique ones) as possible. I might continue the object-oriented chapter a bit to add the point you mentioned. 
And java AFAIK.
Or you can use the `from_iter` named constructor let v = Vec::from_iter(1..100); I'm a big fan of code reading like English, so this is my favourite. "Let v be a vec[tor] made from iter[ating] 1 to 100." 
Nice writeup! A nit: &gt; object-oriented features like encapsulation Rust does provide encapsulation: it allows specifying privacy on module basis, and everything is private by default. It also allows you to bundle data and behaviour, implementing methods on structs.
I tried to say exactly that. That Rust does have encapsulation even though it does not have inheritance. I'll try to modify that sentence a bit so that it is clearer. Thanks for the comment!
That is my favorite also. 
What does it mean a character to be bigger than an another character? fn largest_char(list: &amp;[char]) -&gt; char { let mut largest = list[0]; for &amp;item in list.iter() { if item &gt; largest { largest = item; } } largest }
My comment was inspired by [the "Special Sections"-section from the documentation on how to comment source code](https://doc.rust-lang.org/book/first-edition/documentation.html#special-sections), though. If you do not want to force your users to follow a certain predefined way on how to do this you can make it opt-in/opt-out and use something like `handlebars` for letting the user provide her own templates for the comment format! :-) I'd love that, actually. Would make documenting my 20-30kloc project a breeze!
Hmm, any idea /u/allengeorge?
My guess would be a comparison between unicode code points, which are just u32
Oops, sorry, I guess I can't read, lol.
&gt; so that effort thankfully died. It did not took the world like jvm Java did, but it didn't die either. You probably have more than one native Java CPU in you pocket : AFAIK most SIM cards and credit cards chips are using Java.
&gt; There are no integers in JavaScript, just 64 bit doubles By default yes, but you can use a work-around with bitwise operators : If `i` is a Number `i|0` is an i32. That's how asm.js worked.
GCC is gud man.
It is certainly. However, the benchmark is far from any realistic workload neither typical programs to process them.
Gotcha: &gt; NewGVN was recently merged into LLVM (still experimental), it's a rewrite of the global value numbering algorithm. The last remaining bug on our list is bug in the old gvn implementation. I compiled the example codes in the bug report with the new gvn algorithm, and they work fine, so hopefully LLVM 5.0 will stabilize NewGVN and we can turn this optimization back on. And this: &gt; I talked with Davide Italiano from LLVM and the goal is for NewGVN to be turned on in LLVM 6.0. https://github.com/rust-lang/rust/issues/31681#issuecomment-272825268
They might be issues too, but wasm is lower level, so it should be better suited than Java Bytecode. 
Not going to happen with JavaScript, buy I could see it with WebAssembly.
In my experience, the hard thing is coming up with pithy short natural language descriptions and illustrative examples. Users are happy then. But I agree, marvellous opportunity to go forth and complicate! Might just be yak shaving, or putting off the tedious business of documentation :-) 
I think rust does worse than c++ in part due to usage of jemalloc. I bet with a different malloc implementation it would do a lot better
Unfortunately, all the energy savings have to be spent on Rust compilation. _hides_
It's also worth noting that in many cases these concerns, and more, can be addressed without *any* methods. enum Pet { Dog, Cat, } let pet = Pet::Dog; if let Pet::Dog = pet { println!("woof"); } And of course `match` is available for more complex conditional logic. See also `assert_matches` crate or similar for assertions. This is more readable at least in the sense that any rust dev can look at it and tell exactly what it does, without clicking through to a method definition or worse finding a derive declaration which means having to read some docs.
Although, now I get you: `cargo docgen` is the wrong name - it would imply filling in the sections, doing the skeleton. Naming things is hard. Unfortunately, _renaming_ things is also hard, so let me think about it.
Isn't "transmuting between non-repr C types" enough of a reason? If the documentation says it's undefined, well, it's undefined.
This is not the situation where you want an `is_*` function. There are situations where `if let` is really annoying to write, e.g. let my_pets: Vec&lt;Pet&gt; = ...; my_pets.filter(|pet| if let Pet::Dog = pet { false } else { true }) is much harder to read than let my_pets: Vec&lt;Pet&gt; = ...; my_pets.filter(|pet| !pet.is_dog())
Well, Armv8.3-A added an instruction for the sake of JS VMs, notably an instruction to convert a 64-bit double to a 32-bit signed int, setting the Z flag to 0 if it's not an integer or out of range. That said, a whole JS implementation in hardware seems unlikely.
Well no, not if that's not the reason for the warning
Yes I agree in that we should have a *std* way of mapping a pattern match to a boolean with less syntactic weight. However, there is a `matches` crate. #[macro_use] extern crate matches; let pets: Vec&lt;Pet&gt; = ... pets.into_iter().filter(|p| !matches!(*p, Pet::Dog)) I think something like this will come to the core library when the macro import system turns up.
Very slick site (something that is too often overlooked). I am currently using vscode for rust but I am going to give this a spin as it seems like it integrates cargo and rustup more fully.
The work we did on the [lapin AMQP client](https://github.com/sozu-proxy/lapin) should be interesting for you. There are two crates, "lapin-async" which implements the protocol, parsing and decoding, and provides an asynchronous interface you could use in a mio loop. "lapin-futures" wraps the first crate in a futures based API that you can use with tokio. About the design: - separate the protocol's state machine from the parsing (except to decide which parser to use): the state machine changes its state when it receives a parsed structure, not just a slice of bytes (this makes tests easier to write) - the protocol implementation does not own the socket, or even the buffer. The IO is typically something owned by the calling code. With this, it means the calling code can easily change the transport (like, use whatever TLS implementation they want, which is often a big issue), handle reconnection, etc. - use queues of messages internally in the state machine. There's the queue of stuff we parsed, and the queue of stuff to send. The IO part of the calling code interacts with it - there's a query interface for the state machine. "Are we at that state yet? Did I receive that message?" This mixes well with polling APIs like futures.
/fun /hide too
&gt; but I wonder if C++ compilers can elide any details .. e.g. if a value is cleared, and the destructor checks if it's not cleared, (then does something), that check could be elided; C++ compilers can't do any of this but their optimization backend might remove unnecessary operations. Having said this, many operations cannot be reasoned about as unnecessary because the optimizer does not have all the information.
why?
This is probably just benchmarking LLVM vs the GNU Compiler Collection. To make this a more apples to apples comparison one could just use clang instead of GCC to compile the C and C++ binaries.
Though, the site is crap on mobile.
[removed]
On the other hand, if you want to find out how energy efficient some code is, you would choose the compiler that emits the most efficient instructions. Sure, that makes it harder to compare straight up which language encourages the most efficient code at a theoretical level, but using the "best" possible compiler for each language seems like the only thing to do if you're interested in data that reflects the practical reality.
When: unclear - and I've no idea :/ There's been a burst of activity recently, so I'm hopeful "soonish"? Lemme see if I can find out. Version: It'll be 0.11. The Thrift developers don't see the point releases as an issue. Thrift has been stable for a while, so from their perspective the version is just a number.
Also, FWIW, if you'd like to try out the Rust support you can build the compiler fairly easily. There's a docker container in-tree that allows you to build Linux binaries, and I was able to build OSX binaries after fiddling a bit with OpenSSL include paths. The `thrift` crate works with the Rust compiler in-tree. I know it's not ideal, but you can experiment with it, and with tools like `pants` (pantsbuild.org) you can have it download your custom toolchain. Ping me if you've any questions on the above.
It does
jemalloc allocates in different arenas based on size, and initializes the arenas up front, so you start with a larger spike in memory usage and you might end up with more space overallocated. IIRC jemalloc is optimized for (multithreaded) speed, not memory usage
If you look at the most important optimizations in JS runtimes, most of them come from collecting runtime information about data and control flow in order to jit-compile specialized code that runs a ton faster *because it doesn't have to do most of the type checking*. The logic to collect this information is so high level and complicated that it would be foolish to try to wire it in a CPU.
I'm using rust linter, I'll give this one a shot.
&gt; Finally, also remember that an RFC getting accepted does not necessarily mean that feature gets into Rust; it still has to survive at least an entire six-week cycle while the RFC's implementation is considered for stabilization, during which feedback is again requested. Also, many RFCs are updated during the implementation work, and most of them don't make it from RFC into stable in less than half a year anyways, if ever. 
thinking about it a bit more (posting questions in C++) .. it seems it would have to be done at the end of the toolchain, link time optimisation , when all the information is available. The work to handle this scenarios ('eliding calls in trivial cases') should be universally applicable - that lends me to suspect it might already be done. I do want a 'really destroy' directive there now , though. one thing to bear in mind is we do have RVO for some scenarios, so maybe they figured it wasn't so important
As I understand it, the bitflags crate is oriented around giving easy boolean-like access to individual bits within a value. This crate provides a convenient container for groups of bits (bit fields), particularly if they have been extracted from a larger value. Sub-word-sized integers are common in hardware register APIs and network protocol wire formats.
Across all *processes*? Not unless `State` contains something in shared memory or something similar. I think you're asking "between different request threads", in which case, yes. You would have to lock access with a mutex. For example: type LockedServer = Mutex&lt;Server&gt;; /// Create a new game. #[cfg_attr(feature = "cargo-clippy", allow(needless_pass_by_value))] #[post("/new")] fn new_game(server_state: State&lt;LockedServer&gt;) -&gt; Result&lt;Json&lt;GameCreated&gt;&gt; { let mut server = server_state.lock().expect("lock server state"); let created = server.new_game()?; Ok(Json(created)) }
It's a bit more tricky than that. For example, allocating/deallocating memory calls an opaque function (sooner or later, the OS kernel). One cannot remove these calls even at link time because, e.g., they could abort the process. So removing them could change the semantics of the program. These "extern" opaque calls are very common in destructors, so... relying on the backend to remove unnecessary destructors for you is a big leap of faith. Rust approach of destructive moves eliminates this problem, introducing others. 
&gt; `-&gt; impl Generator&lt;...&gt; = do FutureFromGenerator() move || {` (I know this is just hypothetical syntax and brainstorming but as a person-unfamiliar-with-Rust I would be completely baffled by how to interpret this sequence of tokens.) 
&gt; One cannot remove these calls even at link time (EDIT: not sure, let me check.. is the destructor called separately) sometimes operator delete is overloaded to something *inside* the program. it can be overloaded per type (e.g. you can tell it to always use custom pooling or whatever you want for certain types .. making alloc/free extremely lightweight). it might be part of the definition that delete must do nothing if null, in wchih case the compiler should be able to tell. of course it might be overloaded for instrumentation aswell. &gt; Rust approach of destructive moves eliminates this problem, introducing others. IMO we need both. I do want C++ to have the destructive option.
After writing this I started thinking about what that *std* way could be and ended up putting it down at [rfcs/issues/2153](https://github.com/rust-lang/rfcs/issues/2153). I've probably missed something obvious with my idea, but I'm sure we can make a better way than macros, derives or `{ false } else { true }`.
&gt; At the cost of a prior memory allocation though. The OP doesn't say anywhere that it needs to keep the elements around; it is mostly worried about the cost of the `.clone()`. However, one can often have its cake and eat it too. It is more of a question of whether doing so is worth the trouble. `Rc`ing everything gets the job done and allows one to finish the application. If profiling reveals `Rc` is not acceptable, that can be worked around with arenas or similar. For example, one could allocate all the values in a `Vec&lt;T&gt;` for maximum memory locality. For the part of the application that needs the `HashSet`, one could move the `Vec` into a `WeakVec` that has a single reference count but offers `Weak&lt;T&gt;`s to the `Vec` elements, and build the `HashSet` on top of that. One could support `push` while holding the `HashSet` by switching to a `VecDeque`, and one could support deletions as well by having the `WeakVecDeque` track holes. This is not a 5 minute fix though. And given that `Rc` "just works", I'll start there.
hi, good news, someone else has inspected the output for me , and it turns out the compiler *does* infact elide the delete already. 
&gt; I assume OP is not a complete dummy and they clone their data because they want to keep using the structure from outside the hashset. The OP doesn't say this anywhere. It looks to only be concerned about the cost of the `.clone()`.
&gt; The OP doesn't say this anywhere. Which would be why I called it *an assumption*.
&gt; The OP doesn't say anywhere that it needs to keep the elements around No but you can assume good faith and basic intelligence, and thus that the clone is there for a reason, especially when the alternative option they list is using a reference which requires keeping a handle on the value you refer to.
Yeah, I am not saying that you are wrong. The first thing I thought was "just `Rc` it", but after seeing this answer i'm like... duh, only do this is you need to keep the other around which now that I re-read the question am no longer sure if its the case.
Why can't the OP move the element into the set and access it through the set? Maybe the OP just hasn't thought about this possibility because, well in the set you cannot change its value. But you can move it out, change it, and re insert it. Things like that. I am not saying the OP is acting in bad faith, and not calling the OP dumb.When one is deep into a problem it is easy to forget the simplest answers. Happens to me all the time.
The initial design of lambdas in Java followed TCP. The current design doesn't. It turned out that following TCP made the design worse. It's an intuitively appealing principle, but it is not, in fact, a useful guide in designing programming languages - [nor was it intended to be](https://softwareengineering.stackexchange.com/a/120409/854).
Rust does, it compiles pub fn foo() -&gt; u32 { let mut v: Vec&lt;u32&gt; = Vec::with_capacity(3); v.push(314); v[0] } to foo: push rbp mov rbp, rsp mov eax, 314 pop rbp ret fully eliding the memory allocation (see [here](https://godbolt.org/g/dq5f4t)). GCC trunk and Clang trunk compile "equivalen looking" code: #include &lt;vector&gt; unsigned foo() { std::vector&lt;unsigned&gt; a; a.push_back(314); return a[0]; } to foo(): # @foo() push rax mov edi, 4 call operator new(unsigned long) mov rdi, rax call operator delete(void*) mov eax, 314 pop rcx ret pay attention to the calls to `operator new` and `operator delete` (see it live [here](https://godbolt.org/g/PTUUEU)). The assembly I posted is from clang but the link shows similar GCC assembly. The fact that clang does not do this optimization while Rust does perform it even though both share the same optimization and code generation backends is worth noticing. This does not mean that this optimization is impossible in C++, but that at least the trunk versions of two of the 3 most widely used C++ compilers do not perform it. This is a mini benchmark that is not representative of real world applications, so one should not use it to extrapolate to larger programs either.
Same here - I have high hopes for Rust number crunching but good SIMD is essential.
*Achievement unlocked: Necromancer.* --- Awesome! So, how exactly does v0.4+ compare to [IDE-Rust](https://atom.io/packages/ide-rust) now? cc /u/mehcode
I have to agree with the other posters. I'm just not seeing the benefits.
indeed it seems i spoke too soon, i did find cases where C++ doesn't do it (someone else made a more trivial example where it *did*, so clearly someone has thought of it.) I was more looking at cases where you consume a value by moving it as an argument of another call. the other case where someone found it sucessfuly eliding was where it was moved *between locals*. The only thing that would truly satisfy me here is an addition to the standard for a real destructive move, but I am sure the information is there for a compiler to figure it out.. it's just hard work to get every compiler to handle every possible optimization. we can't make std::move destructive because there's other valid use cases where it's used in a deliberate way to re-use memory etc. 
Why would changes on `rand` require an RFC? Isn't code put outside the stdlib exactly to let it evolve freely, decoupled from the language?
icc should have been used then. fortran with icc would have likely wiped the floor with the other languages.
Sometimes you want a language which is both expressive and performant. I might as well say, "If performance is your goal I don't see why you ever let the kernel schedule your processes." Sometimes performance matters enough that you want to isolate all the cores that you are using, but usually it just does not matter that much. That does not mean that all cases where you can afford to be scheduled are also cases where ruby is an appropriate language choice. There exists a range of different performance targets.
What if you never had to pay for the cost of any typechecking ever? Doesn't that seem better to you? Modern JITs can elide lots of it, but not all.
Regardless of it being rust, you can just download a prebuilt binary. I was looking at contributing and the old instructions for building were ... daunting.
Undefined behaviour doesn't need a reason for being "undefined". If it's UB by the language semantics, it is. (Of course there's real reasons why the designers of the language semantics might want to leave something as UB, but the existence of those reasons doesn't make it less UB.)
`rand` isn't just another third-party lib; it split off from `stdlib` (which needs randomisation of the hash function in `HashMap`). It's still maintained by the core Rust team.
Thanks!
I would make it, but my task (it's homework) is to compare pixel-wise operations with applying bitmap to whole image at once. 
I personally really love the built in terminal (it could be that vim 8 has added that since I made the switch). I don't think the neovim language server client has been ported to vim yet either (I believe that it is underway though).
I'm surprised -- I was certain this project was dead.
Let me see if I understand this correctly. The stdlib depends on `rand` and every Rust program already links it implicitly, but if I want to use `rand` on my project I need to depend on them via `Cargo.toml`, which will download and build another copy? Can it at least detect that the `rand` version on `Cargo.toml` is the same of the stdlib, and avoid duplicating code?
I'm wondering -- will this integrate with the overall [Atom IDE](https://atom.io/packages/atom-ide-ui) endeavour? Right now [ide-rust](https://atom.io/packages/ide-rust) wins in the naming scheme of things... though also not (yet) integrated with Atom IDE
https://github.com/rust-lang/rust-by-example/pull/904
It uses basic code ide-rust uses on top of that other providers enabled from atom-ide package. Status bar added for RLS health check. Will work on custom messages of RLS tonight.
I don't disagree that the site doesn't render very well on my Note 5, but in the interest of keeping community guidelines and making this comment constructive, *what specifically can improve*?
Rust is going to make you a better C programmer. It forces you to think about data ownership and lifetimes, even if you write in other languages. It's also a great language in its own right.
I created a `common` crate, but as you said it gets a bit messy with macros. I am not aware of a good solution either. 
Contributions are welcome. Thanks for feedback also.
You're pretty early to be looking at rust, and it isn't a super easy language to learn - in particular because it's young, so there are fewer resources. That said, Rust also has a community that's pretty good at responding to beginner level questions, so if you do decide to learn rust I highly recommend taking advantage of the #rust-beginners IRC channel. In a CS50 class, with C, you'll probably be introduced to concepts like the stack, heap, and pointers. Rust makes these things pretty explicit so it'll pair well with C. This early in your CS career I'd say focus on C, focus on fundamentals, and experiment with a lot of different things - so check rust out for a while, check Python out, check everything out that you can.
Yeah, it certainly is a mouthful. Kotlin gets away inferring the return type, and even if they didn't they'd use dynamic dispatch and drop the `impl`, and it's garbage collected so they drop the `move`, and their closure argument lists are optional and inside the braces. In our case we could probably ditch the `do`- we don't have overloading so it should still be unambiguous even if slightly magical? We could alternatively just drop the closures-outside idea. We could also rename the constructor? That leaves this: -&gt; impl Generator&lt;...&gt; = async(move || { Perhaps slightly less mysterious?
It is already integrated with Atom IDE: https://github.com/vertexclique/tokamak/blob/db3307cc8188df9a4abe78a5db83cdc7ee14cae8/package.json#L95
I guess Firefox's battery consumption will drop considerably with each new oxidation it gets. Fun times are comming! Fun times! :D
&gt; it could be that vim 8 has added that since I made the switch Yeah, terminal window support is still a WIP in rust. &gt; I don't think the neovim language server client has been ported to vim yet either (I believe that it is underway though). There is [prabirshrestha/vim-lsp](https://github.com/prabirshrestha/vim-lsp) which I use for the RLS.
That would be great wouldn't it? But that's unfortunately not possible. The CPU on your computer already does a pretty good job at detecting dependencies between instructions and reordering/pipelining/parallelizing them as much as possible (modern CPUs are jit compilers of their own). Hard-coding special silicon to look at dynamic object types wouldn't get much better than that, because the types that are being checked depend on prior instructions and what comes next depends on the result of your type checks. You make it sound like it is a parallel problem, but it isn't at all. At the lower levels, it's not even a very different problem from what CPUs struggle with in any language (predicting control flow).
Last time this came up I totally forgot to ask: is there a limit of crates you can publish per user per time frame? (That'd be one of the easiest restrictions I'd implement.)
Correct. Probably not.
Really? It's just awesome you like it. :D
Everyone is going to recommend error-chain, so it'd be helpful to give some more of your criteria.
The GTK project is basically abandoning Vala for Rust, so that's at least one reason...
Firefox is in C++, so I wouldn't expect a ton just by moving to rust. Better utilization of multicore systems + GPU will have a bigger difference.
https://github.com/Wilfred/remacs/issues/305
So, /u/innovator12 isn't *wrong*, but missing some subtlety. [RFC 1242](https://github.com/rust-lang/rfcs/blob/master/text/1242-rust-lang-crates.md) defines how crates in the nursery, like `rand`, work. This text is long, so emphasis mine: &gt; **New cratess start their life in a 0.X series that lives in the rust-lang-nursery**. Crates in this state do not represent a major commitment from the Rust maintainers; rather, they signal a trial period. A crate enters the nursery when (1) there is already a working body of code and (2) the library subteam approves a petition for inclusion. The petition is informal (not an RFC), and can take the form of a discuss post laying out the motivation and perhaps some high-level design principles, and linking to the working code. &gt; &gt; If the library team accepts a crate into the nursery, they are indicating an interest in ultimately advertising the crate as "a core part of Rust", and in maintaining the crate permanently. During the 0.X series in the nursery, the original crate author maintains control of the crate, approving PRs and so on, but the library subteam and broader community is expected to participate. As we'll see below, nursery crates will be advertised (though not in the same way as full rust-lang crates), increasing the chances that the crate is scrutinized before being promoted to the next stage. &gt; &gt; **Eventually, a nursery crate will either fail (and move to rust-lang-deprecated) or reach a point where a 1.0 release would be appropriate.** The failure case will be determined by means of an RFC. &gt; If, on the other hand,** a library reaches the 1.0 point, it is ready to be promoted into rust-lang proper. To do so, an RFC must be written** outlining the motivation for the crate, the reasons that community ownership are important, and delving into the API design and its rationale design. These RFCs are intended to follow similar lines to the pre-1.0 stabilization RFCs for the standard library (such as collections or Duration) -- which have been very successful in improving API design prior to stabilization. **Once a "1.0 RFC" is approved by the libs team, the crate moves into the rust-lang organization**, and is henceforth governed by the whole Rust community. That means in particular that **significant changes (certainly those that would require a major version bump, but other substantial PRs as well) are reviewed by the library subteam and may require an RFC.** On the other hand, the community has broadly agreed to maintain the library in perpetuity (unless it is later deprecated). And again, as we'll see below, the promoted crate is very visibly advertised as part of the "core Rust" package. &gt; &gt; Promotion to 1.0 requires first-class support on all first-tier platforms, except for platform-specific libraries. &gt; &gt; **Crates in rust-lang may issue new major versions, just like any other crates, though such changes should go through the RFC process**. While the library subteam is responsible for major decisions about the library after 1.0, its original author(s) will of course wield a great deal of influence, and their objections will be given due weight in the consensus process. These RFCs are about moving `rand` to 1.0.
Almost, but not quite. One aspect of the `rustc_private` crates is that sometimes, their internal version diverged from the crates.io version. I believe `rand` is one of those. https://github.com/rust-lang/rust/tree/master/src/librand still exists inside the compiler; nobody has done the work to move to the crates.io version yet. The plan is to eventually move all of them to the crates.io versions, but that takes work.
Typosquatting a crate does not immediately become an attack vector. The attack needs time for users to initialize new crates and make a typo in a dependency name. Instead of restricting this it might be better to silently flag the users for review so that they can be banned. It might also be interesting to flag any crate at a Levenshtein distance of e.g. &lt; 2 from widely used crates (for some useful definition of "widely used") so that an admin can at least manually review these. If manpower is an issue, it might be useful to show these crates in some dashboard page so that the internet police can review these, with maybe the ability to whitelist crates from the list. One could also rank users on crates.io by the number of crates they have with names that are "close" to those of popular crates. That way if a single user tries to typosquat many popular crates that user would immediately become a suspect. For example: let threshold = 3; //&lt; Max Levenshtein dist let user_points = crates_io.popular().iter_names() // if a popular crate name is too short, its their own fault .filter(|cio| cio.len() &gt; threshold) .map(|cio| user_crate.iter_names() .map(|u| 10.powf(threshold - cio.levensthein(u)) .clamp(0., f32::MAX)) .sum()) .sum(); 
I've heard really bad things about the C++ code i Firefox :D Guess all the new Rust code is more modern and fancy. Just looking on how they want to pull NSS out of Firefox and have various dependencies shows how much things are tightly coupled. Now they want to use Hyper and Tokyo for networking stuff. Pretty cool! :D I can't believe people still use Chrome :)))
I'm a fan of this idea. This problem is a perfect candidate for the "use computers to weed out the obvious cases and then ask humans to look at what's left over" approach.
That's correct.
Cargo includes the compiler version in the metadata for compiled artifacts, so it will notice when you switch versions. (You don't need to explicitly `cargo clean`.)
But the problem still exists with targeted attacks where typosquatting is not the problem, but the typo is.
Sure, this would only make the information of "dangerously named" crates, and "users with many dangerously named crates" available. Humans would still need to review this information.
To expand on this a bit, you could increase the automation a bit by seeing if the crates provide an identical API. Might be computationally quite expensive though if that requires building each crate.
I'd have to agree. I'm learning rust by implenting an old game called Hunt the Wumpus, and I've learned a ton. Hoping to get done this weekend and start contributing to some open source project.
That sounds like a great idea. One would only need to do this for "suspiciously named crates". Maybe one wouldn't even need to build the crate, but just parse the crate and see if most of the public items are named similarly.
&gt; The coding style of the added code snipplet (see Appendix A) makes it incompatible with Python 3.x. Troubles installing the packages on Python 3.x were reported on the Internet multiple times, but to our knowledge, never identified as a security incident. I find it really funny that the Python 2/3 breakage is what detected (and prevented some of) these typosquatting attacks. /u/aturon this advantage of enabling new epochs by default is not mentioned in the RFCs :D
Yeah that looks a bit nicer - especially being rid of the `do FOO move || {` sequence which seems highly prone to mis-parsing.
This happens fairly often. There are ways to try to mitigate this, someone brought up string distance checks and I think that's likely the best method.
Ah, I'd just gotten settled in vscode after switching away from atom... Though vscode with just RLS feels very raw so I will give tokamak a try! The biggest feature I miss is having doc snippets show inline when doing completions, it's cumbersome to tab out to the docs all the time.
I'm giving it a try, even though I'm likely to go right back to vim. For some reason `apm install tokamak` installed 0.3.2 until I forced it with `apm install tokamak@0.4.0`. The new version still flashes an error whenever I open a project saying that cargo timed out, and I get about a thousand errors about racer configuration whenever I press a key. That said, it does attempt to compile errors very nicely once the storm of error popups clears away. But then sometimes trying to mouse over them is a bit too much for atom-ide-ui, which `cannot read property 'row' of undefined`. So far, shiny but not very usable.
As someone getting into programming / computer science you should be picking up lots of languages over the next few years - but doing a deep focus on just one or two (I'd suggest making C one of those since you need it for your course). The idea being that learning different languages makes you better at every other language (including the ones you already know). A mixture of depth *and* breadth is the key. I would also urge variety, Rust and C are both procedural systems languages (although they take different approaches within that paradigm), trying out higher level procedural languages like Java, Go, Python, Javascript will expose you to a whole different set of tradeoffs without being too exotic. Conversely functional languages like Haskell, Lisp, Erlang will force you to approach problems from a very different angle. With regards to Rust in particular? Your choice. Rust is a very modern language and so there's lots of potential for learning state of the art in languages (particularly in comparison to C which is fundamentally a very similar language to how it was 30 years ago). It's also a complex language for a beginner which might make it a suitable challenge. I would suggest try it (in particular, try to understand what is different about Rust compared to C and why that might be better/worse) and if you enjoy Rust then try it some more.
For dns typo attacks, companies will pay the modest cost of owning similar domain names. Not sure if that helps us.
[svgcleaner](https://github.com/RazrFalcon/svgcleaner) :)
I've written two: - [artifact](https://github.com/vitiral/artifact) -- design documentation tool for developers, hit 1.0 last week (after over a year of development) - [novault](https://github.com/vitiral/novault) -- command line password manager, still in early beta
This is really great, I'm actually going to install fd, exa, and tokei when I get home. I've been using ripgrep. but that's about it. I guess you're probably not referring to cargo subcommands, but I find cargo-info and cargo-script to be pretty useful.
&gt; you could increase the automation a bit by seeing if the crates provide an identical API I would also consider crates with a `build.rs`. `build.rs` can include any Rust code *and* is executed during the compilation *prior* to actually trying to build your crate. By the time the compilation error would occur due to an API mishap, your system is already compromised.
I might totally use this in Citybound once I add 3D terrain!
Does Cargo do anything to prevent one person having multiple accounts? If not, then per user bans don't seem very effective at stopping this kind of attack. 
Rust is the future of system programming. You can quote me on this. RemindMe! 5 years "Did Rust took over the world yet?"
I will be messaging you on [**2022-09-15 18:15:19 UTC**](http://www.wolframalpha.com/input/?i=2022-09-15 18:15:19 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/rust/comments/70ajv1/im_getting_into_compsci_now_should_i_be_looking/dn1wvjb) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/rust/comments/70ajv1/im_getting_into_compsci_now_should_i_be_looking/dn1wvjb]%0A%0ARemindMe! 5 years ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! dn1wvzo) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
Spent my summer learning Coq so I could understand this. It's really cool!
(all mine, sorry): * [text-minimap](https://github.com/dpc/text-minimap) * [dotr](https://github.com/dpc/dotr) 
Since packages cannot be unregistered after they've been registered, I don't think we want to be encouraging people to register packages that they don't intend to use.
People might also be typosquatting on packages to prevent these kinds of attacks. I honestly wouldn't know what the best course of action is, but Rust has close ties with a lot of the people from NPM so I'm sure we could learn from them, considering it also happened to them.
It might nice as a cargo command, as well as a configuration setting that could be flipped on during development so one might enable an explicit check pause before download if it triggers the specified deps. Something that would stop you and ask: *xxx dep specified in the manifest has y1,y2,y... similarly named crates, are you sure?* As much as I prefer to avoid stop-and-ask processes like that, feels like it would be a nice security step before creating or updating a Cargo.lock during development. Edit: also maybe a nice check for "cargo install ..."
I'm guessing it requires Atom Beta?
Rust has more up-front learning cost – it's harder to get something working than with other languages. This is at least partially offset by the awesome community, where it's very easy to find a great mentor, and people are generally friendly, helpful, not to forget the helpful compiler messages, which get better with every release (or by the day, if you use nightly). So decide for yourself whether it's worth your while.
My favorite is [just](https://github.com/casey/just). It's great being able to simplify long commands that I frequently type and save them in my repos.
If I had to typosquat a crate I would use a different account for every squat, typosquating the real author name too.
&lt;quote&gt;It can be thought of as, well, switch-case on steroids.&lt;/quote&gt; I find this phrase to be one of the most over-used and useless things to say. What does it mean? Does it add any useful information? Does it tell you anything useful? I'd argue not. For some reason it is a throw-away phrase that gets used A LOT for no discernible reason. I'd recommend removing it or saying something else.
Yeah, we're in agreement I think. I believe /u/bumblebritches57 was looking at the first table, perhaps (wrongly) believing that it was a table which summarized the results of all their benchmarks. But it is, in fact, just a single benchmark, and in the summary results Rust is *quite* competitive with C (ranking 2nd, at 103% of C's energy usage), and pretty far ahead of C++, on energy usage.
This is a problem in ~~mode~~ *node* package manager as well
&gt; It might also be interesting to flag any crate at a Levenshtein distance of e.g. &lt; 2 from widely used crates (for some useful definition of "widely used") so that an admin can at least manually review these. If manpower is an issue, it might be useful to show these crates in some dashboard page so that the internet police can review these, with maybe the ability to whitelist crates from the list. I built such a script, the results are at https://internals.rust-lang.org/t/cargo-package-aliases/5870/6?u=eh2406 I'd love to find a use for that work!
For me rls in vs code is insanely slow (because compiling is slow I guess?) . Does anyone know if the atom plugin is faster? 
Xsv!
The rust compiler has very good informative error messages most of the time, as well as being far less tolerant of bad programming practices than C and C++ are. Particularly its ability to identify issues at compile time rather than runtime is invaluable. That said Rust itself isn't super marketable as a skill right now (yet! we shall soon conquer this feeble world!), and like other low level languages; sometimes you want the whole low level aspect to go away for a bit so you can really get stuck into the concepts. Also for the purpose of academia you might not be able to use Rust for any OOP exercises, even though Rust has an awesome implementation of OOP-like concepts that work perfectly well in the real world, it doesn't map exactly to the traditional OOP models you study.
Nope
Having more than one namespace, eg. GroupId like Maven and others, seems like it would prevent this from being an issue.
This is a good idea and inspired one of my own: What if a first time crate publish to crates.io checks the Levenshtein distance for the crate name (in the server backend) and denies the publish if it's too close, providing a helpful error message on how to contact someone from crates.io to manually validate that they are not typosquatting and that their repo looks legit. If they pass, they get some sort of one time token (which only works for the same repository and crate name) that allows the crate to do the first time publish (token not required on subsequent publishes) I suppose someone could replace their legit looking repo on a subsequent publish or even after receiving the token, but I think the initial hassle might be enough to ward off most, especially automation
Just my opinion, but I'm not a big fan of employers that look for Github activity as a requirement for the job. A strong open source presence can (and probably should) be looked at as a plus, but statements like: &gt; In order to join us, you need to: [...] have a GitHub account with a significant body of public source code. make it difficult for engineers who work primarily on closed source or other behind the scenes kind of projects to get through the door to some jobs that they may otherwise be extremely qualified for.
Thanks for the info! After 0.11 is out I think I have a chance to try it in real environments.
Are blocks rust equivalent of Anonymous functions? Can you pass an argument to a block?
Have you read the Rustnomicon? It's not a physical book, but it's for advanced Rust. https://doc.rust-lang.org/nomicon/
It may be a proxy for "is well versed in OSS development" to weed out people who might not handle remote work. I had the same issue. The solution is to start now.
Alright I just tried this out and it works fine until the scope of `buf` ends, after that I get an access violation. I suppose it tries to deallocate the buffer, but it's contents are already partially deallocated due to the CString deallocating it's resources? I dont know that much about how this all works, so I am probably wrong with some stuff here, maybe. But afaik a CString just wraps the data so if I were to `mem::forget` the CString it should solve everything without creating a memory leak, is that correct? //scoped part of my function let mut buf = vec![0;100]; let ptr = buf.as_mut_ptr(); let result = file_manager.get_directory_name(100, ptr); unsafe { println!("FILE -&gt; {:?}", CString::from_raw(ptr)); } Ok(result)//access violation when scope of buf ends This here fixes the violation, but I am not sure if this could result in a memory leak because I am not sure if I understood CString correctly let mut buf = vec![0;100]; let ptr = buf.as_mut_ptr(); let result = file_manager.get_directory_name(100, ptr); unsafe { let string = CString::from_raw(ptr); println!("FILE -&gt; {:?}", string); ::std::mem::forget(string); } Ok(result) 
I wouldn't expect it until next year at the earliest
I too will say anything to get namespaces. But seriously, namespaces *would* mitigate a lot of this. Also, having names and a hash or checksum? 
Is `just` "just" a subset of `make`?
HIring is very hard, and no wonder employers are looking for any significant and reasonably practical to evaluate signs of your skills and experience. Especially in cryptofin space, trust is very important and Open Source work shows good motives. On top of it participating in Open Source is a skill one get to build on experiences, which might be important part of the job itself. People spending their time benefiting the Open Source community get to build a reputation and have something to show for their skills. It's very valuable. They typically don't get paid for it, if they did it in free time. If you work on proprietary, closed source software exclusively, then it's a drawback of your work: the fruits of your labor and skill belongs purely to your employer, and are unusable to you as soon as you leave. You need to take it into consideration when deciding where you're going to working. 
Awesome. I had no idea this existed. I've been thinking about writing an odfcleaner / odf normalizer. There's some code in java already, but I'd much prefer to generate rust code from the Relax NG... libsvgdom and libsvgparser look interesting! 
I use xsv frequently at work. It's an excellent, simple toolkit for how I do processing on CSV files.
Hope I'm not getting annoying here. I'm having a question about the Rust book. I'm reading the following chapter: https://doc.rust-lang.org/book/second-edition/ch04-01-what-is-ownership.html#the-stack-and-the-heap Specifically, this part &gt;We’ve already seen string literals, where a string value is hardcoded into our program. String literals are convenient, but they aren’t always suitable for every situation in which you want to use text. One reason is that they’re immutable. And &gt; So, what’s the difference here? Why can String be mutated but literals cannot? The difference is how these two types deal with memory. Except that the following code is working fine let mut text = "Text"; text = "New Text"; println!( "{}", text ); So what am I missing here?
It's similar to (and inspired by) make, but it's really designed to be a command runner, not a build tool. It makes it easy to list/show available commands, pass through command line arguments, run commands in a different directory, run with a different interpreter and provides better error messages. It doesn't have things like the notion up-to-date files or phony targets. I don't want to disparage make since it's been a key part of many development workflows for decades, but I think just aims to strip away parts of make that aren't relevant to a simple command runner and creates a better user experience for people who don't need those features. I should probably also say that I love when a repo I checkout has a justfile. The first thing I do is `just --list` to see what canned commands are available. If I want to run one, I'll `just --show command` to see what would be run. It's almost a way to document common how-to instructions for new users in addition to being a time saver for people familiar with the project.
Meh. I work exclusively on closed-source and behind-the-scenes projects, but my employers and recruiters often cite my github account as a reason for their interest in me.
I disagree with /u/staticassert's caveats regarding Rust. I'm not saying Rust is easy to learn, but it's not *more* difficult than what I started with, and a relative lack of resources is not a problem because those resources which do exist are easily accessible and comprehensive. One problem I ran into when self-teaching C# was that the interwebs were full of resources that were either outdated or just plain bad. I have not found that to be the case with Rust--with the caution that it's a good idea to search doc.rust-lang.org/std/ or one of the books instead of just googling the whole world, because then you risk pulling up stuff about legacy code, including sigils, etc... Since picking up Rust, I have started to learn several other languages, but I found most of them much harder to learn and lost interest. That said, it's possible my patience for learning languages is wearing thin in my old age. :)
You are rebinding `text` to a separate immutable literal, not mutating the string itself.
&gt; But seriously, namespaces would mitigate a lot of this. Couldn't one just typosquat the namespace instead then? It's just shifting the problem along a bit.
Nothing to keep someone from typosquatting the namespace. The attack vector goes from mistyping `serde` as `sedre` to mistyping `burntsushi/regex` as `burtsushi/regex`.
&gt; We are in a rush to deliver cutting-edge blockchain software so you should be able to hit the ground running and start contributing. No on-the-job training is provided! *Every* job has on-the-job training requirements. You have to get used to their code base, their preferred workflow, all kinds of job-specific things. Seeing this kind of statement makes me wonder how many people they might hire, only to turn around and fire them.
The attack vector is users mistyping a name in their dependencies file, which isn't going to be solved with a hash unless one wants to force everyone to look up the hash every time they add a dep and paste it into their Cargo.toml (and if you're willing to go to that length, you can already just copypaste the `"foo" = 0.1.2` string conveniently displayed at the top of every crates.io page).
You brilliant SOB, you've typosquatted `node` as `mode` in the Debian package repos, haven't you?
The lack of namespaces is baffling to me. I normally agree with nearly 100% of the decisions of the Rust / Cargo community, but in this case, they totally made the wrong call.
Even NPM realized how bad their lack of namespaces is, which is why they added scoped packages ex: @types
Good point, I didn't think of how that kind of work typically translates to experience with remote communication and collaboration, which would definitely be a desired quality for remote jobs.
And I would have gotten away with it, if it weren't for you meddling devs!
I was imagining a little more ceremony around claiming a namespace, but you're right it's not that great of an answer.
Rust has Closures as anonymous functions. See [here for examples](https://rustbyexample.com/fn/closures.html) and [here for detailed infos](https://doc.rust-lang.org/book/second-edition/ch13-01-closures.html). Blocks are just like blocks in many other languages, only with the addition that they are also an expression in itself (i.e. they evaluate to a value).
I am pretty sure that _at the moment_ `transmute&lt;Vec&lt;i8&gt;, Vec&lt;u8&gt;&gt;` does exactly what you'd expect and goes fine unless someone knows something I don't just as `forall 'a, T: transmute&lt;Vec&lt;&amp;'a T&gt;, Vec&lt;Option&lt;&amp;'a T&gt;&gt;&gt;` But I don't think anyone wants to commit to this internal representation at the moment. The internal representation might change in the future at which point horrible things might happen. There was a where enums of a non-nullable pointer type and another tag without a payload were not yet compressedly represented with the other tag being compressed into the null pointer and there might be a time where they find further optmizations that would run the equivalence.
Yes, it's not to say that the need to register a Github account wouldn't slow down typosquatters some (all you need is an email, and Github allows multiple accounts with the same email AFAIR). But at the same time, an attacker typosquatting many packages from a single user account (which is the concern in the current state of affairs) is easier to detect and remove due to all the malicious packages being linked to that user. Not a pure win either way.
Cargo-edit
Sounds awesome. Probably could replace my much of the "scripts" directory I inevitably end up creating.
https://github.com/uutils/coreutils
These are the results I got, in release mode: 79002700000 Branch sorted: Duration { secs: 0, nanos: 856457046 } 78540000000 Branch unsorted: Duration { secs: 4, nanos: 441991897 } 78079350000 Cond assign sorted: Duration { secs: 0, nanos: 967570572 } 79191450000 Cond assign unsorted: Duration { secs: 0, nanos: 968036235 } Interesting what a huge difference the conditional assignment makes.
CStr, not CString. In this case, it's not owned, but rather borrowed from a vector which manages lifetime. Also, why is `file_manager.get_directory_name` exactly safe, I wonder... It accepts a pointer, so it should be marked as unsafe API, I think.
It's more often a proxy for "is willing to work on nights and weekends without compensation"
I wrote a Linux process querier in Rust at one point that comes with an expression grammar. https://pastebin.com/fe5CCEru So you can do like pmatch 'sid == {%sid, 1} &amp;&amp; !kthread' --format '%pid (%name)\n To get pids and names of all proceses in the current session and sid 1 that aren't kernel threads. It assumes a Linux-like `/proc`filesystem and really I only tested it on Linux but bonus points for outperforming `pgrep` in the range they overlap at least on my system. (Both were compiled with `-march=native`). Really, I just wrote it to use it as part of my shutdown scripts because `pkill -s1,0 --inverse` did not exclude kthreads and I needed that so I felt like dumping an entire expression grammar into it.
&gt; to weed out people who might not handle remote work. Except it also weeds out folks who work remotely at a closed source job. And people who don't have the time to contribute to open source. "start now" works if you have time on your hands, which is not always the case for folks working multiple jobs and/or who have children. (or just, folks who don't feel like programming an extra ten hours a week.) --- A prolific GitHub account is a good indicator of a decent candidate since it lets you easily see that they know their stuff. The lack of one should not be an indicator of a _bad_ candidate, it just means that you should use other means to decide how good they are.
I'm partial to quick-error, though I have no idea whether it would meet your use case.
The book should probably call them `str` literals. `str` is the type of the data itself, but you can't have a local variable or temporary value with that type. Why? Because `str` is an unsized type. There's no (practical) limit to how large a `str` value can get, so it's not possible to keep it on the stack. This problem is solved for literals by - giving the `str` a location in the read only data segment - substituting a reference for the literal, type `&amp;'static str` - `'static` means no lifetime restriction. So your variable "text" holds an address-length pair.
Oh okay that makes sense, I'll change that. And `file_manager.get_directory_name`is part of a dll wrapper I've written myself and currently I only wrapped the raw functions with an unsafe block, I still have to change the functions to be/look more safe. 
I'm really interested in that, any sources? GTK moving to Rust pretty much means I'll learn rust, really into GTK dev...
Linux package repositories typically have more strict requirements on who can upload software. This prevents spam and malicious software, as, in Debian at least, one must be approved by community members before being able to upload packages. I know this imposes a large burden, but it may prevent these attacks.
The first time I heard about Aeternity was with the following link : https://github.com/zack-bitcoin/amoveo/blob/master/docs/why_I_left.md Don't know what to think.
Or "is willing to work on and patch upstream libraries that the company uses." Most of my OSS these days is patches and improvements to the libraries we use at work.
- [tv-renamer](https://github.com/mmstick/tv-renamer): Also includes GTK3 UI &amp; grabs episode titles from TheTVDB. - [ion shell](https://github.com/redox-os/ion) - [mdBook](https://github.com/azerupi/mdBook)
If you take a look [at the assembly](https://play.rust-lang.org/?gist=8358a24d15898af5a5c09f85fdb9d47f&amp;version=stable&amp;mode=release) you'll see that the "cond assign" is compiled to a `cmovaq` instruction where the "branch" version has a jump (`jb`). Apparently intel CPUs handle an unpredictable `cmovaq` better than they handle an unpredictable `jb`!
Still digesting this but it seems your "walled garden" separation between allocator types is stricter than necessary. In addition to the proposed `Copy` and `Move` forms of interaction, it's possible, in at least some cases, to allow borrowing by one allocator of values owned by another allocator (with `Borrow`/`Return` functions polymorphic on the types of the borrowing allocator and the lending allocator): - Anyone can borrow from RC simply by incrementing the reference count (and decrementing it when done). - Anyone can borrow from GC by telling the GC to treat the address in which we store our borrow as a root + pinning what it refers to (which is trivial in non-compacting GC's, and possible in compacting ones). - Lex can borrow from anyone, since you already have baked it into the language as the `borrowed` allocator (it can reason about the liveness of the value it is borrowing, and so can return the object before the other allocator has a chance to do anything).
True. But from the employer point of view, having access to a portfolio is a great way to assess whether you are a good candidate or not... whether or not it makes sense to require a good github account then becomes a matter of how much time they can spend on recruiting, what is their aversion to false positives, and whether they care about false positives.
Rust isn't any more difficult to learn than C. There is a difference in how this difficulty is experienced. If you get your pointer manipulation approximately right, C will likely compile to an approximately correct program with nasty bugs that you're unlikely to stumble across. The same level of "approximately correct" in Rust won't compile. However, Rust is often *too* conservative: you can write something that's correct but won't compile without `unsafe`. Unsafe Rust is very similar to C, except that you're working within a framework of pointer best practices. (And a misstep is more likely to cause bizarre bugs. Rust is aggressively optimized in release mode, often more aggressively than C.) So Rust is simultaneously a *terrible* language in which to do your Data Structures assignments and a brilliant language for learning data structures. Outside of data structures, if you're actually writing software that Does Stuff, Rust is a better C than C. And it's compatible with C-api libraries. - I'll also echo that you shouldn't worry much about which language you learn. Different "languages" are often more like dialects. If you know Rust or C, you can pick up the basics of Go, Ruby, JavaScript, Python, Swift, C++, etc. etc. in an afternoon. A new programming paradigm like you'd find in Elixir, Scala, or Clojure will take longer. Actually mastering any one will take longer. But again that knowledge is typically very transferrable.
Except for the dreaded Pentium 4
I would strongly suggest checking Rust out. It's very cool, and it provides a different way of thinking about programming languages -- a lot of the stupid `SEGFAULT` errors you see in C and C++ are prevented by Rust's type system. I would also suggest checking out Smalltalk. It is a fantastic approach to object oriented programming, and will change how you think about programming and programming langauges. You'd also benefit from a functional programming langauge, like Haskell or OCaml. Just like Smalltalk and Rust, they'll change how you think about programming, and give you entire new vocabularies to think with. At this point, your brain is young enough that everything is hard and new and novel. This is the best time to pick up new paradigms! If you only learn one thing, and stick with it for a long time, then your brain will have a very hard time picking up new concepts and ways of thinking. If you're always challenging yourself, then you won't have this problem to the same degree.
I would at least like some statement supporting alternate public development repo like GitLab or the various mailing lists used for sending patches.
The epochs wouldn't really affect this, since rustc will be able to compile older epochs just fine.
Awesome! Btw, I really wish you the best of luck with Citybound -- I've been watching from afar, and so far it seems super cool!
Better handling of unpredictable `cmovaq` should not be a surprise, since there is no _branch miss_ - whether the condition is `true` or `false` the CPU will always follow with the same instructions. That's the reason they added conditional move instructions.
&gt; For example, allocating/deallocating memory calls an opaque function (sooner or later, the OS kernel). This is hogwash. GCC already tracks `malloc` as a "special" function. There really is no particular reason it could not be elided.
Yeah ngl i skimmed the table and only looked at the first 5 or so entries.
&gt; Apparently intel CPUs handle an unpredictable cmovaq better than they handle an unpredictable jb! It's more subtle than this (at least it was recently). The CPU won't have to speculate with conditional moves, which is great for compute-dense code, but it generally also wont prefetch through computed addresses, meaning you'd rather have the jump and speculation if you expect memory latency to be an issue.
A lack of a positive that others have will be a negative for you. Not sure there's any other way to square that.
Maybe, hard to say. Not at my job at least.
Also check out Prolog, Haskell, Erlang, Forth, and some weird operating systems like Minix, Haiku, and NixOS. Read about them even if you don't actually work with them (I've only tried half the things in that list). Get some variety in your thinking while it's still fun!
What would be a better way to define it? I only looked a little bit into C before learning Rust, so I know what a switch-case is, but I don't see much of a difference between match and switch.
I became very excited the first time I read your suggestion. This approach had not occurred to me. It would indeed be nice if the garden walls had more doors! In this reply, let me call your mechanism "co-own" for the sake of not confusing it with the "borrowed alias" I mention in my paper. They are different mechanisms, as I will come back to. After thinking through your idea, several concerns came to mind: * **metadata**. Each allocator has its own unique metadata (e.g., reference count or tracing colors) it maintains for every allocated object, which is often located "with" the object contents. So, an object created by a tracing GC would not have a field for reference count information. One could perhaps solve this by "unifying" the metadata, so that all allocators use the same structure holding all possible information and correctly initialized by all allocators. * **lexical**. Unfortunately, lexical cannot be "co-owned" by a runtime GC. The compiler's static mechanism depends on the alias reference having only *one* owner for it to work. The compiler has no access to run-time allocator metadata when determining when to request a free. I should point out that what I call "borrowed aliases" are *not* lexical aliases (though they may have borrowed from a lexical owner). 'Borrowed' aliases are just content references whose owner allocator is unknown. * **Type**. What would be the allocator type for an alias co-owned by two different allocator types? Obviously, It cannot be just one or the other. What I think you did was to invent sum types for allocators! So: {rc | tgc}. The language would need to offer pattern matching, coercion, and other mechanisms to allocators to handle downstream aliasing and other needs. Doable, perhaps, but that adds programming complexity when handling aliases that hold dual citizenship for runtime allocators. There would have to be compensatory benefits to having aliases be co-owned by multiple runtime allocators, enough to offset the added cost of metadata unification, the added runtime bookkeeping cost of using two runtime allocators for the same aliases, and the programmer complexity of allocator sum types. Right now, I am not clear what those benefits might be. Importantly, I do not yet know how limiting the walled garden restrictions I describe will actually be on programs. The borrowed references I talk about in the paper go a long way towards providing some measure of temporary lexical windows between gardens, as borrowed references do not care where they came from. But they too have some necessary deterministic lifetime usage restrictions. Once I build a language that implements these ideas, and then build complex programs using it, we will finally be able to assess how rigid or flexible these walls are. Thank you very much for sharing this intriguing idea. If I missed the mark in responding to it, feel free to help me get past these concerns.
It seems Database comes from `use juniper::tests::model::Database;` So, looking in the juniper repo src/test/model.rs I see it [here](https://github.com/graphql-rust/juniper/blob/f9d6f2c83f9814cf41bf8c32a45d4b36aec567fb/juniper/src/tests/model.rs#L101). Definitely not obvious at first glance...
I like Go's model of using DNS to namespace packages.
💖💖💖 So glad you like it!
That sounds like a problem for *Automation Man*! I haven't created a github account for quite some time, but it should be pretty easy to automate this: 1. Automate creating email addresses 1. Automate signing up for a github account 1. Automate checking your email for each account 1. Automate publishing fake rust packages (e.g. mirrors) 1. Manually add malware to your most popular crates and bump the version I could probably get this done in a weekend and set it up to run periodically and email me the most popular crates each week. It's really not *that* hard.
Why?
I really don't like how Go completely ignores package versions. I've been using a hack (gopkg.in/pkgname.branch), but that's not very powerful and is just a workaround. I hear they're working on a versioning system, but it hasn't landed yet AFAIK.
Actually, part of the reason I wrote `sn` was that the Rust `du` was pretty slow. I'm not sure about the other tools of course since I didn't benchmark.
And the time savings are spent commenting on RFCs :)
This is an excellent replacement to piles of bash files :) Thanks!!
Since when is citybound using gfx-rs for rendering?
I thought that was what bitflags is doing. I use it to parse MQTT flags from the wire. But I can see that you've considered a use case of smaller fields inside other values.
I don't think there's the resources to do this since this involves continuous manual work. That and it increases the barrier of entry to publishing a crate. The core team is not a large team.
You should have no trouble getting through the door if you are extremely qualified. 
We want not only the best and the brightest but also the intrepid. Yes, I want to see that you know your stuff and no, passing a whiteboard puzzle interview is not the best way to show it. I want to see your code but I also want to see you raise the bar on yourself and then pull up to it. In other words, do something if you want the job. Make time, take a few evenings or weekends to put some code out there. If you only complain and shrug your shoulders then you don't want it bad enough! I'm talking from personal experience, 25 years of working mostly closed-source jobs. 
Yes, there's always some of that. 
I want the folks who can dig into our code base on their own. There will be readme files and design docs but no lectures on how things are done. You are confusing on-the-job learning with training. 
No. 
I did this thing https://github.com/Marwes/schemafy while back to generate types for visual studio code's debug server. It lacks some stuff such as external refs which proved a bit difficult to fix due to the crate's heavy use of `&amp;` references. I unfortunately forgot about that issue last time before I had managed to come up with a refactoring I were happy with. I will put it on the to do list though as it is a fairly interesting project to work on (just not THE most interesting project I work on :) ).. For instance, it bootstraps itself using the Jason schema which defines main schema! 
I wrote [rockman](https://github.com/mehcode/rockman) if you happen to use Arch Linux. It works well for my use case and it's fun to tinker with. 
Definitely low hanging fruit. Check out https://github.com/mehcode/atom-ide-rust and see just how small the code is. It integrates cleanly into Atom IDE as well.
great! please post a link when its ready!
Learning C makes it easier to learn Rust, because when you fight with the borrower checker, you understand the terrible bugs it's trying to protect you from. I'd recommend learning C for systems programming, Haskell, ML or F# for typed functional programming, then Rust to see their beautiful combination. But there might be an advantage to learning typed programming separately from manual memory management.
It is coming. I wish I could link an article, but there is a go lock file and things coming.
A whole lot easier to detect. And many libs will be pulled in via the same namespace so it only has to declared once.
The "you need to ..." requirements suggest otherwise. 
It also weeds out the incompetent and the lazy. 
I'd prefer reactive review, to avoid throwing up unnecessary barriers for legitimate users. Typosquatting isn't a particularly time sensitive attack, since you still have to wait for people to make the typo and download your crate.
Rust's match is much more powerful than traditional switch statements, because it can pattern match, rather than just matching specific top level values. For example, you can match on enum tags nested within the structure being matched, all in a single match statement. 
Rust is just a tool, Comp science is not a tool, it is perhaps mostly Math and Algorithms. Use the tool your instructor/prof asks you to use or rather ask them. My suggestion would be ask your Prof, if he is language agnostic and you have time to learn go for it. Else, stick to what he suggests. Comp science though easy eats up time in School. It would be wiser to spend time on understanding fundamentals rather than the tool, in that case. 
I am sorry, but concurrency doesn't buy anything here, emacs already has a way to do concurrency, you launch separate process and let the os takes care of it.
A worthy effort, but there's more value in rethinking classic POSIX tools. Especially with the flag-ridden GNU versions, it gets easier to hit Stackoverlow for answers rather than parse the man page. So ergonomics is important. I think it would be _most_ useful if the new breed of Rust utilities had dump-to-JSON capabilities, specified perhaps with Serde-compatible structs for easy consumption. Doesn't have to be JSON, but there are a fair number of existing tools like `jq` that can process it already.
I feel that rust could really do with a blessed subset of packages that have received significant attention with regards to quality and stability. Something in between a free for all and the standards required for the standard library. If the method of acessing blessed packages were slightly different, this would also go some way towards mitigating typo squatting Most packages in use by more than a few percent of the community would wind up in there, so the effort/success ratio of an attack on the remaining packages would be less.
&gt; If you only complain and shrug your shoulders then you don't want it bad enough! I think that's the point - why doesn't someone have to desperately want a specific job in order to be just another applicant?
The variable `text` is basically a pointer. In the beginning it points to `"Text"` (somewhere in the executable's data section). Then, you change it to point to `"New Text"` (also in the data section). So you're mutating the pointer, but not the text of the literal.
- Simple hex editor: https://github.com/osa1/rhex - IRC client: https://github.com/osa1/tiny
A lot of companies have employment contracts that try to claim copyright over software written by employees on their own time. Legally they may not be able to put some code out there that they've written on their own time, because their employer owns the copyright (though some countries/states limit how far those kinds of contracts can go).
[`cargo-script` does it using `CARGO_TARGET_DIR`](https://github.com/DanielKeep/cargo-script/blob/master/tests/util/mod.rs#L17-L19) and assuming the build profile is `debug` (which *should* always be true for tests). Also, keep in mind there can be any number of executables, so the definite article is not always appropriate.
false. C++ is still in the running (recent additions keep it relevant), and there will be the alternative of JAI for gamedev, and Swift is going to get move semantics. In 5 years, Rust will be one of several viable options in the same space.
That indeed sounds like a very clean implementation, thank you for the suggestion and for taking the time to summarize the design here!
It would be nice if there was a consistent interface to get flag/option completion data and not something that has to be maintained externally.
I ... clarified that in my post! : &gt; it just means that you should use other means to decide how good they are. Some candidates have easy indicators of their skill. (The mere existence of a FOSS profile is not an indicator, but you can do a reasonably scoped amount of research on it to determine this). Others don't. Spend more time in the interview. Ask other kinds of questions. 
No more than GitHub does, or I would assume exactly as much as GitHub does - seeing as cargo requires github as the unique identifier and login.
&gt; Yes, I want to see that you know your stuff and no, passing a whiteboard puzzle interview is not the best way to show it. There are other ways to do this. This is a false dichotomy. ------ &gt; Make time, take a few evenings or weekends to put some code out there. Not everyone is in a position to "make time". Different people have different constraints in life. There are single parents. There are people with crushing student loan debt working multiple jobs. People with family members with medical problems to support. Sometimes these are the same people. &gt; Make time, take a few evenings or weekends to put some code out there. Honestly, if you want folks to put in extra work like this for your interview process, _pay them for it_. You're going to have M candidates and hire N&lt;&lt;M. For the rest, this becomes wasted effort. Sure, this may result in open source contributions. Sure, this may make them better programmers. But you're forcing them into it if they want the job. It's not unheard of for companies as a part of their interview process to pay candidates to do nontrivial tasks (generally ones that take ~half a day). You can do something similar here, if you wish. (I enjoy [this blog post](https://sockpuppet.org/blog/2015/03/06/the-hiring-post/) about a similar interview process at Matasano) ----- I say this as someone who works at a ~50% remote^1, nearly 100% open source company which does _not_ require an open source profile in any hiring posts (in fact, I don't even think we mention this at all, forget requiring this, but I could be wrong on that point). We've hired plenty of folks who have had zero open source contributions (creating github accounts on day 1), and the ones I'm aware of all turned out great! ^1 i.e. around 50% of our employees are nowhere near an office, though those who do go to an office work from home reasonably often / at whim.
I'm already using a lock file (glock), what I want is proper version numbers. We'll see what they come up with though. This is something that I really like about Rust, and if Rust can work reasonably well as a server (e.g. if Rocket stabilizes and gets websocket support, that may be enough), I don't have much reason to use Go. Until then, Go will be my main server language.
(I am not a lawyer) Just for general awareness, such provisions are unenforceable in the state of California (in the case of work done in your own time on your own equipment/resources) However, IIRC they're not _illegal_ (you can still write a contract like that, just that that provision won't be valid), so it's still not uncommon, and as a result you have a lot of folks who _think_ they're not allowed to do this legally even though they aren't. https://leginfo.legislature.ca.gov/faces/codes_displaySection.xhtml?lawCode=LAB&amp;sectionNum=2870
I've written [gisht](https://github.com/Xion/gisht), which in theory can replace all the others mentioned here ;-)
The idea seems to have came up first around October 2016: https://siliconislandblog.wordpress.com/2016/10/31/thoughts-on-dx-gnome-and-rust/ After some talk between the two projects, a first hackfest was held in March to get better integration between Rust and GObject (which is the object-oriented framework all the libraries around gtk use): https://wiki.gnome.org/Hackfests/Rust2017 At the end of that wiki article you can find some blog posts if you want to know more about what happened there. There's another Hackfest planned to continue this work: https://wiki.gnome.org/Hackfests/Rust2017-2
How does the output compare to Inkscape's export as optimised SVG?
If it helps, in Python, I have my integration tests redefine `sys.argv` and then call the `main()` function I use as my entry point. It shouldn't be too difficult to accomplish something similar in Rust by doing some minor refactoring of your `main()` so it's split into two parts: 1. A `_main()`which takes its command-line arguments as a function parameter. 2. A trivial `main()` which just calls `std::env::args_os()` and feeds the result to `_main()`.
Thanks for the link to the blog post!
One could create a VLIW processor that ran invariant detection code side by side with program logic. I think there are *many* ways that CPUs could be augmented to support dynamic languages. 
&gt; unfortunately not possible One is often wrong when they say this phrase.
Would that require external shell support?
Still, for people unfamiliar with "proper" pattern matching, it's a reasonable analogy if you recognize that switch/case is a very primitive pattern-matching construct. (It's an especially appropriate analogy for anyone who's programmed in Bourne shell script, where `case` has power and versatility half-way between C and Rust... limited in no small part by the minimal support for structured data in the language itself.)
Thanks for the answer (and the great work, both of you!). Sounds like Rust has a great future with Atom!
Yes it would. Shell are in dire need of modernization. I mean, it would be nice to dump a completion structure (once, static, not so good) using `your-binary --dump-completion-json` so that the shell could get completion data directly rather than maintaining completions in a shell specific format.
what are they coding then? why? i don't follow emacs dev (hell, i have not updated my conf for a few years now) so i don't know much, any good link would help a lot :).
It isn’t, but I’m planning to transition at some point
There's ongoing work on [swagger generators for Rust](https://github.com/swagger-api/swagger-codegen/pull/6105), which must include generating types.
I'd try to convert your indexed access to iterating over slices, but I'm on mobile right now.
I've been searching for a solution to this problem with a bunch of C++ programs for AGES. This one seems worth a shot.
Thank you :)
I think you might be misinterpreting your experiences with Emacs. Emacs has been great at running asynchronous extensions for decades; stuff like flymake and M-x compile works fine and you can keep editing freely while the linting/compiling/whatever happens concurrently. In the two examples you mention, it sounds like you're waiting for network communication with the the update server, and for the JVM to spin up, neither of which are things that Emacs (or Neovim) could do much about.
Yes, a hundred times yes. The audience is lower; malware is potentially "only" distributed to all of that crates's users, instead of all users of software created by that crate, but that's still a very worthwhile attack for the more popular crates. Particularly if they can gain access to the networks of large organisations this way - especially when you remember that dev machines often have all sorts of useful credentials and extra privileges to steal and abuse.
Except it isn't true for cargo test. You can always use `cargo test --release` to run tests in release mode. That's a good point that there can be any number of executables. Probably just providing the directory would be enough. Or maybe something like `CARGO_BIN_&lt;name&gt;`?
Depends on image, but usually much better.
This is a good idea. When you find a possible problem crate, you should then look at what other crates depend on it, and show that list. That way people can go through that list and file issues on that crate saying things like "you depend on X which is probably wrong", and then people will fix the dependency. This way the typo squatted name will not be used. Which is what you want. 
A bit of background since I hit the character limit (Exactly) on that post. I've been programming for a few years and I have experience in Python, PHP and Go. Decided I wanted to see what Rust was like so I read through the book. As I haven't actually written anything in Rust yet this isn't supposed to be a critique of the language, more first impressions. I'd love to hear comments!
This is doable, but you would still need a separate `lib.rs` and duplicate code (e.g. `mod`s, `extern crate`s) there, just for exposing things to tests. Also, a crate which isn't supposed to be used as library still exposes some public API, which could potentially be confusing itself.
And this could happen automatically - the shell detects a new executable, goes "Hello! What can you do?" and invoke `--dump-completion-json` or whatever the standard would be. I agree that it's time for shells to move on, as much as I'm _used_ to bash. I find that POSIX-compatibility between shells is more of an irritation than a feature, once you start requiring reliable cross-platform behaviour. 
Nobody mentioned the fact that this issue is much bigger in the Python world. Python actually executes code that is provided by the package on installation time with the current users privileges. 
Remember to check if your link has already been posted. This was posted yesterday as well :)
tangentially, I wondered if you should have a minimum character limit on crate names, so that the convenient names don't get taken up early (migrate to short names as packages get more established)
at the very least, how about the system telling you if a crate is 100% safe code [https://users.rust-lang.org/t/crates-io-search-by-traits-safety/12226] the 'blessed packages' idea would give you more confidence in their unsafe blocks, i.e. you should be more mindful of less well tested packages with unsafe blocks.
`build.rs` scripts are executed on build time though.
This works against unintentional security flaws, not so much against actively malicious crates. Sending your environment variables, aws credentials etc to some well known IP address while still providing the functionality of the typosquatted package doesn't need any `unsafe`.
Not going to answer everything, but here's what jumped out to me: &gt; Three different loops is pointless, the compiler should be able to handle the three cases without three keywords You mean `for`/`while`/`loop`? They're all syntax sugar that gets desugared to what's basically just `loop` inside. &gt; Rand isn't in the standard library? It's not. The standard library is intentionally minimal. Also, the `rand` crate everyone uses is more or less "official" now. &gt; Dropping a reference when calling a function seems like a weird default (Surely &amp;String is more common than String) Explicit is better than implicit. &gt; Why does String::from exist, it seems like .to_string can do that and more? Likewise with push and push_str `String::from` is part of the general `Into`/`From` conversion traits. It's equivalent to `to_string`, but the infrastructure built around `Into` is generally more flexible. `push` and `push_str` mutate the existing string, and only work with characters and string slices. &gt; The fact that the format! macro doesn't consume variables even if you type s instead of &amp;s seems confusing to me. Isn't it clearer if something is only taken by reference if I explicitly specify it? It's kind of magical, being a compiler built-in. &gt; String handling makes sense, not providing a function for grapheme clusters in the stdlib is a cop-out however https://crates.io/crates/unicode-segmentation &gt; Again with missing stdlib functions, no constructor for hash maps? How long would that take to write, really. `HashMap::new()`? &gt; .or_insert returns a mutable reference even if you assign with let rather than let mut? The return type has nothing to do with the assignment. &gt; Why is indexing a vector implemented with a trait? (core::ops::Index) Why not? &gt; What does derive do exactly? It autogenerates implementations for traits.
Thanks for taking the time to write this!
&gt; // if a popular crate name is too short, its their own fault Won't somebody think of 'log' ?!!
&gt; Just for general awareness, such provisions are unenforceable in the state of California (in the case of work done in your own time on your own equipment/resources) To be clear, the link is about intellectual property, and says that they do *not* protect any inventions that "Relate at the time of conception or reduction to practice of the invention to the employer’s business, or actual or demonstrably anticipated research or development of the employer; or result from any work performed by the employee for the employer." So, be careful working on things your employer could reasonably claim would be useful to their business.
I'm sure Steve will *love* this list. To cover a few things others don't appear to have: &gt; Capitalisation to differentiate types is sort of ugly (string vs String) It's a convention, not a requirement. The only exceptions are language-level built-in types which, love it or hate it, is how things is. &gt; The fact that the format! macro doesn't consume variables even if you type s instead of &amp;s seems confusing to me. Isn't it clearer if something is only taken by reference if I explicitly specify it? Yes, but I suspect this is a case of something being done so frequently, and there being almost no reason to ever do anything else, that the macro auto-refs as a convenience. Rust walks a razor's edge of "overly explicit and annoying" and "overly terse and confusion". How well it succeeds at that is subjective. &gt; String handling makes sense, not providing a function for grapheme clusters in the stdlib is a cop-out however I believe the motivation was (at least in part) the size of the Unicode tables; in general, Rust tries to push what it can *out* of the standard library. &gt; Again with missing stdlib functions, no constructor for hash maps? How long would that take to write, really. [Not that long, actually.](https://crates.io/crates/collect-mac) Likely another case of "we don't **need** it." &gt; 'Note that it is not possible to call the default implementation from an overriding implementation' What's the reasoning behind this? Because it doesn't really exist, so it can't be called. Rust doesn't *have* inheritance in the conventional sense. The default implementation is just copy+pasted into `impl`s that don't override it. &gt; Do any other languages have a pub use equivalent? I can't say I've felt the need for it before Sure. I know D has similar mechanics for re-exporting symbols. It's really, *really* useful to distinguish between how code is internally structured, and how it's publicly exported. If you squint a little, it's really no different to using accessor methods: separating implementation and interface. &gt; No GitLab for crates.io? I'm not sure what you're asking here. If you're asking why there's no mirror of the index on a host other than GitHub... I'd assume because no one's ever bothered to make one. That said, the last time I tried, Cargo was... *deeply uncooperative* when it came to alternate index sources. I gave up in the end. &gt; "Functions have the type fn, with a lowercase 'f' not to be confused with the Fn closure trait." Case to differentiate identifiers is ugly Well, this is more distinguishing a keyword and a trait... but yeah. Rather unfortunate. Personally, I wish the `Fn*` family had been called `Call*` or `Apply*` or something. &gt; Is there any reason that Rust can't/won't transparently add Box&lt;Fn&gt; around a function return type? Explicit is better than implicit. *Especially* if it involves nasty, nasty allocation and virtual calls! *Doubly especially* when `Box` isn't even the only option available. &gt; Main information missing from second edition: I haven't checked in a while, but I'll be amused if the book *still* doesn't explain what the hell `for` means in where clauses. That's been this black hole in the docs for a while now. :P &gt; Why can you use most operators as macro separators? The only use I can think of is for assert! also having the behavior of assert_eq! et cetera. You mean in repetitions? You can use any single token that *isn't* `*`* or `+`, I believe. Not because someone went through and specifically allowed them, but just because that's how the macro system *works*. It wants a token for a separator, you give it a token for a separator, it doesn't care what it is. &gt; How does the type system interact with the cfg attribute? It doesn't. `cfg` is resolved as part of macro expansion, meaning it happens *before* any semantic analysis (like name or type resolution) is done. As far as the type system is concerned, what's a `cfg`? &gt; Ahhhh, why doesn't rust escape html in docs? Because it's Markdown and Markdown sucks. I advise learning to live with it; the alternative is to go mad. &gt; Why is indexing a vector implemented with a trait? Almost *every* generally applicable operation is implemented with a trait. All the arithmetic operators, indexing, calling, cloning, marking `Copy` types, marking thread safety... It would be *weirder* if it wasn't. &gt; What does derive do exactly? It takes the abstract syntax tree (*i.e.* no name or type information; just parsed source text) of the thing it's attached to, and spits out an implementation of a trait based on what it sees. They're basically just macros with weird invocation syntax. &gt; 4.13 Says you can create your own traits to derive but 3.19 (iirc) says you can't? I'm too lazy to look up exactly what's being said, so I'll just generalise: you can define your own traits, and you can define a mechanism to derive said trait for a type. You could always do this with compiler plugins, but those are nightly-only. You could always do this with `macro_rules!`, but basically no one ever bothered. You can *now* do it with procedural macros, but this is a recent addition and the docs might not have been entirely updated to take this into account.
You could call `cargo run -- --you-apps--args` with [process::Command](https://doc.rust-lang.org/std/process/struct.Command.html). This requires Cargo, however likely your tests already depend on it. This allows your tests to run in separation from one another, rather then modifying the arguments and environment variables, which forces the tests to run in serial.
In so many other fields, you are expected to have a portfolio of work. If you are an architect, you have a portfolio of work. If you are a scientist, you have a portfolio of work. You are welcome to take higher salaries from jobs that don't let you share your work (and lots of industrial researchers do this), but it can end up biting you if you eventually want a job (like "professor") that requires a public body of work. If you write computer programs professionally, you should either have a portfolio of work or risk only having access to entry level work.
I don't quite see why you think semantically overloading a single loop operator is a good idea? I liked the distinct keyword for distinct control-follow concepts and use-cases when I learnt Rust.
&gt; Rust walks a razor's edge of "overly explicit and annoying" and "overly terse and confusion". How well it succeeds at that is subjective. Yeah, it's obviously quite hard. I remember having a hard time understanding that `println!` and co didn't move variables as functions calls, particularly since Rust is usually more explicit. On the other hand, not sure I'd want it to change now (not even talking about compatibility issues obviously), because yeah you use it so often the quirk is probably worth it. Anyway, thanks to the OP for summing up their impressions!
Sure, there is a barrier for legitimate users, but it would only occur for crate names that are suspiciously similar to existing names and would not be a common occurrence. (*) If, for example, someone tries to create a crate `foubar`, that's suspiciously similar to my crate `foobar` and should be reviewed first. But if they create a crate `foobar_plugin` then that's totally legit and shouldn't be caught by the Levenshtein distance (if I understand it correctly). 
I'd like to tie onto that request and ask for code generators that take Relax NG or XML Schema as input. I've not seen them yet, but the type system in Rust should make generated structs and enums from these schema languages fairly pleasant to work with.
First of, thanks for trying out Rust :). I will try to answer your concerns to best of my ability. There is a good reason for most of those. I was writing this on a train, so I wasn't been able to search particularly much for answers as internet access is very slow where I'm - and due to that I didn't answer all questions, but hopefully that will be helpful. &gt; Three different loops is pointless, the compiler should be able to handle the three cases without three keywords I assume you mean like `for` keyword in Go (I assume you know Go considering you mentioned it twice in your post). I would like to point out those forms are inherently quite different however, which is why they use different keywords in Rust, and `for in` form used in Rust uses an unique keyword in Go called `range` which is not used anywhere else - so it's not that Rust avoids introducing needless keywords this way. Go | Rust --------------------------------|-------------------------------------------------- `for {}` | `loop {}` `for _, item := range slice {}` | `for item in vec {}` `for condition {}` | `while condition {}` `for init; cond; after {}` | `init; while cond { after; }` (or `cfor!` macro) The iterator form (`for item in vec {}`) is by far the most common loop syntax used in Rust, so it deserves to be shorter. `loop` and `while` are quite rarely seen, especially with existence of iterators in Rust which further reduce how common they are compared to Go - for instance, instead of `for i := 0; i &lt; 10; i++ {}` in Go, you can type `for i in 0..10 {}`. &gt; Capitalisation to differentiate types is sort of ugly (string vs String) If that helps, it's a distinction unique to `str` and `String` (and I suppose `fn` and `Fn`), no other type has such a distinction. This is due to an unique rather feature of Rust, as in concept of ownership needed due to lack of GC - it needs to be clear where the object is deallocated, and if the object is owned, when it goes out of scope it is deallocated. But there is more to it, if it was just about ownership, it would be easy to just have `Box&lt;str&gt;` type, and in fact that's what was done in very old versions of Rust. `String` also stores its capacity which is number of bytes that were allocated - if a string needs to be extended, and there is enough space allocated, an allocation is reused. In fact, `String` is comparable to `bytes.Buffer` type in Go rather than `string`. Go | Rust ---------------|---------- `string` | `str` `bytes.Buffer` | `String` &gt; Rand isn't in the standard library? &gt; String handling makes sense, not providing a function for grapheme clusters in the stdlib is a cop-out however Rust standard library is intentionally minimal, and random number generators and Unicode are complex so it makes sense to have them maintained outside of Rust standard library. Additionally Unicode has versions and definition of grapheme clusters can change in new Unicode versions, so it makes sense to maintain it outside of standard library to allow using a new Unicode standard before new version of Rust is released, or to use old Unicode standard with new version of Rust to preserve compatibility. &gt; Organising modules seems sort of convoluted, Go's always-absolute imports are nicer IMO This will likely improve soon with module ergonomics RFC. &gt; Dropping a reference when calling a function seems like a weird default (Surely &amp;String is more common than String) If a string is borrowed, it needs to have a lifetime (even if one is likely to implied in many cases due to lifetime elision rules). The only alternative to this syntax would be `str&lt;'a&gt;` really. However, doing so would require additional indirection when a function wants a generic reference (`&amp;T`) leading to ugly types like `&amp;'a str&lt;'a&gt;`, when `&amp;str` is already a reference to string contents (`str` type). &gt; Why does `String::from` exist, it seems like `.to_string` can do that and more? Likewise with `push` and `push_str` `String::from` is actually [`From::from`](https://doc.rust-lang.org/std/convert/trait.From.html). This allows for writing generic functions which can take argument that can be casted to `String`. It has rather strict requirements about its parameters, for instance you can write `String::from("Hello")` or `String::from(String::from("Hello"))` but you cannot write `String::from(42)`. This helps reduce errors, as it requires an argument to be a string. On the other hand `to_string` comes from [`ToString::to_string`](https://doc.rust-lang.org/std/string/trait.ToString.html). This trait is implemented by any type with user-readable (non-debug) string representation. It is implemented for types like numbers and errors, and allows to write code like `42.to_string()` which converts an integer into a string representation of it (which is `String::from("42")`). As for `push` and `push_str`, it's convenient to think of `String` as a vector of characters. `push` append a single character of `char` type while `push_str` pushes multiple characters. This is comparable to `WriteRune` (`push`) and `WriteString` (`push_str`) methods of `bytes.Buffer` in Go. &gt; The fact that the `format!` macro doesn't consume variables even if you type `s` instead of `&amp;s` seems confusing to me. Isn't it clearer if something is only taken by reference if I explicitly specify it? This is a design mistake, kept for backward compatibility. &gt; Again with missing stdlib functions, no constructor for hash maps? How long would that take to write, really. &lt;https://www.rust-lang.org/en-US/faq.html#why-no-literal-syntax-for-dictionaries&gt; &gt; `.or_insert` returns a mutable reference even if you assign with `let` rather than `let mut`? It's possible to change mutable reference into immutable reference by doing `&amp;*` if needed. Mutability of references is distinct from a mutability of variable containing it, in fact, in Rust it's possible to make variable mutable by simply rebinding it with `let mut variable = variable`. &gt; 'Note that it is not possible to call the default implementation from an overriding implementation' What's the reasoning behind this? I don't understand the question, could you clarify what you mean. &gt; Do any other languages have a pub use equivalent? I can't say I've felt the need for it before Go added it 1.9 as type alias. This feature allows for making flatter namespaces where more commonly used features have shorter paths, while having namespace separation. For instance, Serde provides two modules, `ser` (serialization) and `de` (deserialization). For instance, one of most important features of Serde is `serde::ser::Serialize` trait, which for convenience purposes is also available as `serde::Serialize` using `pub use serde::ser::Serialize`. &gt; The book should really talk about static variables outside of 'Advanced Rust' in 19.1. They're not a complex topic but it would be a bad thing to skip over. `static mut` is an advanced feature, and I honestly feel like it shouldn't even be even mentioned in a book - it's very dangerous to use, as it pretty much ignores the entire thread safety thing. Rustonomicon sounds like a better place for it. &gt; "Functions have the type `fn`, with a lowercase 'f' not to be confused with the `Fn` closure trait." Case to differentiate identifiers is ugly Is there an alternative for that? `Fn` is a trait implemented by closure types and what is usually used for function - most Rust programs will be using that one. `fn` on the other hand is a pointer to a function which cannot store any extra information (somewhat like function pointers in C), and it's very rarely used in Rust programs - which is why it's mentioned in advanced features to begin with. &gt; Is there any reason that Rust can't/won't transparently add `Box&lt;Fn&gt;` around a function return type? If anything, what you want is `impl Fn()` instead of `Box&lt;Fn()&gt;` as return type, but unfortunately this feature is not stable - `impl` return feature allows saying that a type implements a particular trait without saying what type it is exactly, which is needed as closures don't have nameable types. Every closure in Rust is its unique type which implements function call trait, this allows for various optimizations. However, explicitly boxing causes Rust to lose type information, as instead of a function, a vtable and allocated function storage is returned - this has a cost of heap allocation and having to do a so called virtual call when calling a function (so it couldn't be, say, inlined). &gt; Ahhhh, why doesn't rust escape html in docs? Because it's Markdown. Markdown allows HTML. &gt; Why is indexing a vector implemented with a trait? (`core::ops::Index`) Simply because traits work really well for operator overloading. Traits in `std::ops` generally involve operator overloading, for instance `std::ops::Add::add` is used when `+` operator is used.
For the same reason Rust has modules and C++ has namespaces. Also, it helps prevent typosquatting as well as regular squatting. Another reason, for example we have a crate called regex. Let's say it becomes abandoned and no one is granted ownership of the repo. With namespaces, I can easily fork it and still use the name regex, which is perfectly descriptive. Otherwise I have to use an inferior name, just because someone got there first. 
Sometimes "You should look at your website on a phone" is constructive feedback... it has been useful for me.
Use `assert_cli` and if someone feels there is a better way to handle finding the executable, they'll create a PR and we'll all benefit.
Keep in mind, lack of namespaces is what caused the entire leftpad incident there, since two organizations wanted the same package name.
&gt; feels like Haskell &gt; I have experience in Python, PHP and Go. Do you read a lot of language books without programming much in those languages?
Anecdotal, but I had the opposite experience. After immersing in rust for a while, whenever a C++ program compiled successfully, I was left wondering what bugs have I left on the table. 
That's exactly my point. Rust makes you think about the memory model way more. I'm going to guess that the you-before-Rust would have never even thought those errors might be there.
I agree -- your rendition has a different tone from "Your website on mobile is crap." though. :)
Yeah will do!
[Your code works](https://play.rust-lang.org/?gist=6ecd3e84024c774a320e35f79014b6f6&amp;version=stable).
By the way, that's a nice trick to use `?` in a function that doesn't return an error: fn function() { let result = (|x| { let a = func1(x)?; let b = func2(a)?; lec c = func3(b)?; func4(c) })(10); }
Awesome, thanks for the links!
I think there may be a proposal to extend auto-borrow to function arguments. It's already the default for method calls. If I were designing from the ground up, the `move` keyword would be required to move out of non-copy locations; they'd be borrow by default. But I'm not. So... oh well. 
Looks like they're doing it all in Java. I was hoping for something in Rust. :)
That makes sense. What I was trying to say was, the compiler telling me things guarantees me stuff in Rust, but with C++ I feel helpless, that beyond my skillset with C++, I am unable to find certain bugs. The rust compiler spits it out for me upfront. Your point still stands and I agree with it, working with Rust has taught me a lot.
Well, co-operative concurrency means no benefits to performance. https://github.com/emacs-mirror/emacs/blob/master/doc/lispref/threads.texi Also note that the synchronization exposed is locks and cond-vars which nobody really wants to use for concurrency. The only possible benefit could be some library providing abstraction over threads like futures to encourage people to write concurrent code conveniently. But there are some libraries(async) that facilitate future style code with current async-process approach. Here is a post explaining it in some detail too: https://www.lunaryorn.com/posts/a-blast-from-the-past-the-tale-of-concurrency-in-emacs I am not sure about the long-term goal with this, since implementing parallelism would be very hard because of excessive global variable use in emacs.
I'm pretty sure 'move' was used like that in one stage of Rust's development.
That is a great idea! The same but different ness between BSD and GNU utilities feels like a wedge. From what I read about VMS, it had a design decision to limit the number of options to a program because it hurt portability.
&gt; Rand isn't in the standard library? It was part of std before Rust 1.0, but [it was decided](https://github.com/rust-lang/rfcs/pull/722#issuecomment-71779521) to [move](https://github.com/rust-lang/rust/pull/21892) it to a separate crate. The API still has not stabilized, and is under [very active refactoring](https://github.com/rust-lang/rfcs/pull/2106) as a result of the recent [libz blitz](https://internals.rust-lang.org/t/crate-evaluation-for-2017-07-25-rand/5505). Random numbers are a tricky topic, with a lot of different use cases and concerns, and you don't want to cement a premature design.
Hello! I see your point and agree with you just with a few notes: * Yes, the simplicity and productivity of the API is the main aim now, but it's not true that we want to sacrifice performance for this goal. At least, I always trying to find the ways to improve performance and keep API simple (where it's possible). * Froggy isn't ECS, it's different ideology that is completely hidden from the user. You can't do the same with ECS, unfortunately. * Your last concern is serious. Fortunately, the bus factor of `gfx` is 2 already and we're working on increasing that for most libraries :D Thank you for your feedback, I hope kvark will find some time to answer. UPD: my nickname is different here, you can find me as 'vitvakatu' on the github.
I think 'have experience' is something a lot different than 'understands the general concepts' I wouldn't say I had any experience in Python, but I could still write a basic script, just like I wouldn't put 'has experience in haskell' on my CV because I know what the `Maybe` type is
How about something like: A match expression under Rust has some similarities to a switch-case in C-like languages; however, it is much more powerful. One of the incredibly powerful and useful aspects of 'match' expressions is that they require that you match all possibilities for the values of an enum variant. This ensures that you address all of the possible branches in your code as enforced by the compiler. It is impossible to not deal with all variants of an enum in a match expression. Another powerful feature of match expressions as opposed to switch-case statements is the fact that they are "expresssion" and not just statements. The value of the overall expression is the value produced by the branch that executes. -- Something along those lines. Just saying they are, "like switch-case on steroids", I don't believe provides any useful information. ASIDE: Please don't take this as any sort of criticism of your writing or me thinking I know better than you. Just a suggestion.
Oddly enough, I can't get this to build locally. I wanted to see how performance would change by switching the target from `core2` to `native` (seems like a better optimization goal). However, the Makefiles specifically target Rust 1.16 in a particular directory as well as using a very specific Rust library version and they rely on `typed_arena`, which no longer seems to be present in Rust (either stable or nightly). Has `typed_arena` been removed from the language?
Do you ever use factories? 
I don't really agree with that sentiment. I didn't see the post yesterday. It being here today meant that I saw it. This isn't a forum, it's a crowd-sourced news site. Reposting just makes stories stick around longer, meaning more people can see it. 
No thanks.
&gt; named for a waterproof cloth used to cover cargo on a ship You solved one of the [two hardest problems](https://martinfowler.com/bliki/TwoHardThings.html) in Computer Science, congratulations.
The main motivation to use this expression was to have a lighter tone in the post. So that it would feel like a blog post and not like e.g. technical documentation. I agree that it does not convey much information. Overall the idea in the post is to highlight unique features in Rust and hopefully get someone interested in it (after which they can read the details from e.g. the Rust Book). That said, I might add a bit more details about the match expression. Thanks for the comments!
Earlier discussion at https://www.reddit.com/r/rust/comments/704c27/rust_is_one_of_the_most_energy_efficient_languages/
Not to debate one way or another, but that post is still on the front page of /r/rust (#13) with 153 upvotes and 81 comments. 
&gt; If you are an architect, you have a portfolio of work. If you are a scientist, you have a portfolio of work. These are both jobs where the default status of your work is open. You can't hide a building, and most science is published.
The story with [imag](https://github.com/matthiasbeyer/imag) is as follows: We replace our filesystem-abstraction backend with an in-memory filesystem and we replace the `clap` argument parsing input with test-defined arguments, ... and then we check the virtual filesystem after each "commandline call" whether the results are correct. Fairly, the test setup is rather complex... but IMO it is worth it.
This came clear to me a while back when I did [shmake](https://github.com/stevedonovan/shmake) where the 'shmakefiles' were just shell. It felt like a good idea, and very expressive - but once I started writing shmakefiles that needed to work across platforms, things started falling apart. In fact, exactly the kind of trouble we always had with `make`. (I have an unhealthy obsession with creating build tools, and I'm trying to resist doing a Rust one) 
&gt;Should someone in my position be looking into Rust? Why is that? Depends what you want to do. Rust is a systems language with many of the advantages of C, and some of the shortcomings as well. &gt;I'm doing CS50, which starts with C Rust is pretty close to "a better C" and it's pretty much required if you want to write secure code.
&gt; but with C++ I feel helpless, that beyond my skillset with C++, I am unable to find certain bugs. I think a lot of C++ programmers feel the same helplessness (to a degree).
&gt; You're pretty early to be looking at rust, and it isn't a super easy language to learn - in particular because it's young, so there are fewer resources. As someone who picked up Rust by experimentation, I think it's easier to learn Rust with the resources available now than it is to learn C. &gt;In a CS50 class, with C, you'll probably be introduced to concepts like the stack, heap, and pointers. Rust makes these things pretty explicit so it'll pair well with C. I think part of what I like about Rust is that I've only really had to worry about pointers. I'm sure my code could be more performant, but "performant data structures" is quite a rabbit hole.
&gt;Rust has more up-front learning cost – it's harder to get something working than with other languages. I think part of Rust's aim is to make the invisible bugs disappear alongside the visible ones. Once you start working on large projects, static guarantees make "getting something working" in fact *easier*. 
&gt; However, Rust is often too conservative: you can write something that's correct but won't compile without unsafe. That's going to be unavoidable to an extent. Unfortunately, compilers can't be infinitely smart :) I think Rust achieves a good balance, but then I could also see it improving in the near future. So I am hopeful.
&gt; Rust walks a razor's edge of "overly explicit and annoying" and "overly terse and confusion". How well it succeeds at that is subjective. Will quote this. You've been warned! 
How do you like that language client implementation? I'm curious because the one I'm using doesn't seem to play nice with the javascript-typescript language server and I wonder if a different client would do better. Also, on a more general note, how come you prefer vim over neovim? 
I've been meaning to write a post on CLI integration testing. It's probably going to end up describing what I've done [here in waltz_cli](https://github.com/killercup/waltz/tree/ef79bf0fc3cfc8dd225cce864e21a91192121afe/waltz_cli/tests), which takes inspiration from my earlier attempts in cargo-edit, as well as cargo (proper) and diesel_cli.
I for one am really happy about this change if only for the fact that my keyboard scrolling actually works now! For some reason I can't scroll with arrow keys or vimperator bindings when I'm on gitbook. Great work!
I have a bunch of custom CLI tools written in Rust that I frequently use/run as cron jobs, from simple converters up to stuff like [bitrust](http://killercup.github.io/bitrust/). [You should write lots of custom CLI tools in Rust too, it's sooo easy](https://deterministic.space/rust-cli-tips.html) :)
&gt; it helps prevent typosquatting as well as regular squatting. How? Doesn't it just move the problem to namespace (typo-)squatting?
There is the `rust-lang-nursery`: https://crates.io/teams/github:rust-lang-nursery:libs
That's not because of memory allocation. It's indirection from `std::vector::push_back` that's preventing both Clang and GCC to optimize that vector out. edit: At least for Clang though. It seems GCC is conservative either way. This: #include &lt;vector&gt; unsigned foo() { std::vector&lt;unsigned&gt; a{314}; return a[0]; } Compiles to this: foo(): # @foo() mov eax, 314 ret 
Hello there! &gt; I don't know why all current engines choose to have it baked-in at the lowest possible level Because ECS can't be a component of the engine, it's got to be that vertical basis for other stuff to hook up to. &gt; you'd never use it for a complex 3d game, because it's optimized for ergonomics and productivity with a runtime penalty I wouldn't jump to conclusions based on intuition here. Three-rs is not three.js, and this is not JavaScript. Rust proved that we don't need to choose between productivity and performance. Three-rs will do it's best to pursue a similar trade-off. Sometimes, a more restrictive and higher level API (like the one we expose) provides greater optimization opportunities, like [automatic instancing](https://github.com/three-rs/three/issues/37) for example. I don't expect AAA grand titles ever coming, like big open world games, but small-to-medium sized ones should be completely fine to make with Three-rs. And if you *do* need big worlds, you pretty much have to throw out the scene graph and adopt an ECS anyway. &gt; Implements an ECS. It does not. It just happens to use Froggy CGS. &gt; users should be able to pair the ECS of their choice with their rendering tech. The beauty of Froggy CGS is that it doesn't have to be everywhere. A few components here and there are self-sufficient and abstracted away from the user (it's not in any public API). They are perfectly compatible with whatever ECS/CGS/whatever the user wants to use. &gt; Author wrote gfx, three-rs, froggy ... I don't want to rely on him for every single layer of my game stack gfx-rs has been a community effort from the very beginning, and remains such. I'm the project lead, but I don't expect it to stop if I'm thrown under the bus. three-rs is very young, and I started it alone. But now something truly wonderful is happening - a community is raising. There are 2 strong contributors (one of them is /u/fumlead) who are basically doing everything today, I'm just giving an advice and guiding a little, my role is no longer crucial. froggy is also no longer a one man show. It's a small gear in the mechanism though, so, again, not a crucial piece for three-rs. For instance, [kiss3d](https://github.com/sebcrozet/kiss3d) has a scene graph without Froggy.
The thing is, I don't browse /r/rust directly. It's in my programming language multi, which means I typically don't see things that are a day old. I don't know if my use case is particularly common, but reposts like this help with my use case. 
I fully agree, however the initial complexity cost is still borne by all learning the language. There is a lot of activity to lessen that cost, but i'm still quite certain Rust will never be as easy to learn as, say, Python.
If you mean the *factory pattern*, I've never seen it used in Rust. Perhaps this is because we have free functions and even `self`-less methods. On the other hand, builders are quite common.
Ah, but `println!` *is not a function*. It makes a lot of sense to me that it doesn't consume values passed to it because of how I imagine the macro expanding to simply use `Display`/`Debug` to get a String value.
Did you name it rockman as a video game character joke? (Original is pacman, right? And in Japan megaman is called rockman).
Yeah. The name seemed to fit.
Have you seen [cargo script](https://github.com/DanielKeep/cargo-script/blob/master/README.md)? It has some really cool dependency management for scripts. It has a "help wanted" issue to add gist support. Perhaps there might be a collaboration opportunity there.
FWIW, Rust would be an excellent platform for making a build tool. It would be cool if someone did a Rust version of [redo](https://cr.yp.to/redo.html).
&gt; it helps prevent typosquatting You can just typosquat the namespace, so it's arguably worse. You have a point about abandoned projects, but that can be fixed without namespaces, such as petitioning the package manager maintainers to transfer ownership to you.
"Broken underneath me" You should be using a specific version via cargo.toml and cargo.lock. Unless you are using bleeding edge features or there's a security issue you shouldn't have to upgrade if it breaks things for you.
Open api/swagger itself is in Java, but all the code generators are written in mustache. Mustache is a templating language that works similarly to Python's ability to format a string given a dictionary with the right fields. It also has support for looping. You don't really need to do Java dev to make a new codegen for swagger, but the system they use is heavily tied to openapi.
Nice notes! I think there are some good insights and criticisms here, plus a few good questions. Various other people have addressed some of these. Also, a few of them are matters of taste, and established convention so just the way things are, so I won't bother going over those. But I can respond to a few of them. &gt; Rand isn't in the standard library? Random number generations is trickier than you may think. One of the goals of Rust's API design is to help avoid easy mistakes to make that can lead to serious bugs or security vulnerabilities. Another is stability; once an API is added to the standard library, it is very difficult to remove or modify without breaking a lot of code, so you want to make sure the API is something you are willing to commit to for the long term. Many aspects of security involve random numbers that are hard to predict. This is fairly obvious in generation of secret keys and the like, but there are a lot of other places where it's necessary like generation of nonces, and also places where it can substantially increase the difficulty of attacks like using unpredictable identifiers so that attackers can't easily predict allocation of identifiers and take advantage of that for various kinds of collision attacks, and the like. There are plenty of cases in which people have used something like C's `rand()`, which made certain attacks possible because it was easy to predict the sequence of random values produced. In order to avoid this, you want the easiest default way of generating random numbers to use system-collected entropy and a cryptographically secure pseudo random number generator (CSPRNG). But that then adds some more complications. Fetching entropy from the operating system can block; most operating systems will not return data from such calls until they have collected enough entropy to be considered secure. But on some embedded systems, there are insufficient sources of entropy, so enough may never be generated. Then the question arises whether you always make generation of random numbers fallible, so it could return an error if there is insufficient entropy, or you just let it block, or you provide some way to allow generations of random numbers with insufficient entropy. Then there's the fact that CSPRNGs are not as fast as other methods of generating random numbers, and for some applications, you don't need the security. For instance, if you're doing modelling or simulation, there are much faster random number generators that satisfy all of the requirements that you need for those purposes, but could be predicted by an attacker if they were able to get enough information about some of the earlier outputs. So, you may need a way to opt-out of the secure default; but that brings up the question of whether you just provide some kind of generic "secure" and "fast" random number generators, or you provide specific algorithms, or the like. There's also the question of how rich a random number interface you provide. For security purposes, it's usually best to provide as simple of an interface as possible; fewer knobs means less code to audit, fewer ways for a user to shoot themselves in the foot, and so on. Some people advocate just having a very small core that allows you to fetch a buffer or random bytes, with no knobs to turn. On the other hand, for things like modelling purposes, or use of random numbers for fuzz testing, it can be helpful to have a library of richer random operations, like the ability to generate random integers of different types, random floating point numbers, random numbers in different ranges, and so on. You may think "can't I just do `rand() % n`for a random number in the range 0 to *n*", but that actually provides a small bias towards lower values as an even distribution of values from 0 to `RAND_MAX` doesn't necessarily divide evenly by *n*, providing a slight bias. Likewise, you can's just coerce a random byte string to floating point and get a valid floating point number, or an even distribution, so it can really help to provide a good set of tools for generating random numbers in different ranges, random floating point numbers, and the like. But then there are tricky questions like "what if I'm using it to fuzz-test an API, then I do want to have the potential of generating invalid floating point bit patterns." All of these mean that designing a good standard library random interface is tricky, as there are questions about it's scope, what core interface to provide and allow tools to build on, and so on. Before Rust 1.0 was released, which was the time that the developers wanted to be able to guarantee stability of the API, there was `rand` in the standard library, but some of these questions were still unresolved, so it was decided that it would be better to fork that out of the standard library into a separate package, where the interface could be iterated on more easily without breaking people's code. That work is [still ongoing](https://github.com/rust-lang/rfcs/pull/2106) (also note the [rand-core RFC](https://github.com/rust-lang/rfcs/pull/2152), which is related but only linked deep in the comments). It's possible that once a good API is decided upon, and there is sufficient evidence from the field that it will work well and be maintainable, that `rand` could eventually make it back into the standard library. An example of when that's happened before is with Unix socket support; that didn't land in `std` in 1.0, but instead was developed in an external crate, and then once the API was deemed solid enough was merged into `std` and released in Rust 1.10. &gt; String handling makes sense, not providing a function for grapheme clusters in the stdlib is a cop-out however Unicode is very big and continues to change. It also isn't always 100% backwards compatible; later Unicode releases can change some details of segmentation algorithms and data tables. The table required for doing this kind of stuff in Unicode are very big, and the standard library gets statically linked to every program. That means that unless it can be eliminated at link time, it would bloat the size of executables. Also, grapheme cluster segmentation is only sometimes what you want; it really depends on what you are trying to do with text. An API for dealing with all of the kinds of segmentation that you might want to do is going to be big and complex, and not necessarily easy to design right on the first try. I think that grapheme cluster segmentation and other higher-level text processing tasks are definitely a good thing for third-party crates, which can be updated independently of the standard library, multiple versions maintained for compatibility, and for not including them in executables that don't need them. &gt; Again with missing stdlib functions, no constructor for hash maps? How long would that take to write, really. Yeah, there are pretty simple third party crates for this, and something like this probably should be in the standard library. I think that coming to a consensus on exactly what the syntax should be, and how it interacts with type inference, are probably the biggest hurdles. &gt; Do any other languages have a `pub use` equivalent? I can't say I've felt the need for it before I've definitely been frustrated by the lack of it in Python. The fact that by default, if I import something in a module it's also exported, means that it's easy for someone to accidentally rely on something imported into another module, and then have that break once the import is removed because the module doesn't need it any more. Making it explicit when you mean to re-export something to create a facade, vs. just importing it so you can use it locally, is quite handy. There is some concern, however, that the module system is [a bit too confusing](https://withoutboats.github.io/blog/rust/2017/01/04/the-rust-module-system-is-too-confusing.html), and there have been [some recent proposals](https://github.com/rust-lang/rfcs/pull/2108) for [redesigns](https://github.com/rust-lang/rfcs/pull/2121), though that discussion is [still ongoing](https://github.com/rust-lang/rfcs/pull/2106). &gt; Why is indexing a vector implemented with a trait? (`core::ops::Index`) So that you can index into things other than vectors, like hash maps or trees or your own favorite type of associative arrays. &gt; What does `derive` do exactly? It automatically generates boilerplate code for you for the "obvious" implementation of some trait. Many traits have some kind of "obvious" implementation based on their implementation on the various components of their type. For instance, `PartialEq` or `Eq`, the obvious implementation would be to compare every member of the type, and if they are all equal then the whole thing is. There are some types for which these obvious implementations aren't correct; where you may want to implement `Eq` differently, perhaps ignoring some members of your struct because they are irrelevant for equality comparison. So you can't just have the compiler automatically apply those obvious, mechanical implementations to each type. But what `derive` does is just applies that mechanical, obvious implementation to a type, so that you don't have to write it out manually when it is the correct implementation. &gt; 4.13 Says you can create your own traits to derive but 3.19 (iirc) says you can't? 4.13 is correct, it looks like 3.19 is out of date. This is a relatively recent feature, and I believe that the most effort has been going into the new book, but it might be good to fix that oversight. If you want, you can [submit a pull request to update 3.19 to fix that issue and add a reference to 4.13](https://github.com/rust-lang/book/blob/master/first-edition/src/traits.md).
Making the programmer write more boilerplate doesn't having skewed state, but it does make heavily async code more painful.
&gt; I wouldn't jump to conclusions based on intuition here. Three-rs is not three.js, and this is not JavaScript. Rust proved that we don't need to choose between productivity and performance. Three-rs will do it's best to pursue a similar trade-off. I would be careful with your naming here. You're setting up a comparison between three.js and three-rs explicitly, but in reality you're trying to cut away some of the real trade-offs three.js makes. Bear in mind your README makes assertions about ergonomics, usability for prototyping etc, but nothing about performance, so to some extent you really are asking readers to jump to [some] conclusion based on intuition here, just maybe not the same conclusions you would. :) &gt; It just happens to use Froggy CGS. I think I mistook this for an ECS taking a different approach. When I looked at Froggy, an earlier version of the README read like this: &gt; Component Graph System is an alternative approach to ECS. It shares a lot in common with ECS and was derived from it. CGS design expands on the original ECS concept and simplifies it to the bare minimum. It also didn't have code examples in the README, so I'm certain I mistook it for something closer to ECS than intended perhaps. Thanks a bunch for taking some time to share your thoughts on my post! :)
Hi, thanks for taking some time to reply! kvark was nice enough to drop by and expand on some of your points and some other ideas. Thanks again for taking some time to reach out, I'm sure we'll be in touch more here or on GitHub! :)
/u/mfb81719_posdz, did my suggestions help out at all? I see that you deleted your CI test branch, but don't seem to have pushed anything to master.
&gt; Yes, but I suspect this is a case of something being done so frequently, and there being almost no reason to ever do anything else, that the macro auto-refs as a convenience. Fair enough. &gt; I believe the motivation was (at least in part) the size of the Unicode tables; in general, Rust tries to push what it can out of the standard library. I can see the motivation for keeping the standard library minimal. Do you think that as Rust matures there might be less of a maintenance burden on including more in it? &gt; Because it doesn't really exist, so it can't be called. Rust doesn't have inheritance in the conventional sense. The default implementation is just copy+pasted into impls that don't override it. That's pretty interesting. &gt; Well, this is more distinguishing a keyword and a trait... but yeah. Rather unfortunate. Personally, I wish the Fn* family had been called Call* or Apply* or something. Yeah I don't agree with the current name but it's easy to see how it came about. &gt; Explicit is better than implicit. Especially if it involves nasty, nasty allocation and virtual calls! Doubly especially when Box isn't even the only option available. I can understand that, I didn't quite think through the implications of that when I wrote it. &gt; It takes the abstract syntax tree (i.e. no name or type information; just parsed source text) of the thing it's attached to, and spits out an implementation of a trait based on what it sees. They're basically just macros with weird invocation syntax. Thanks, definitely something I'd like to see explained in the traits section. &gt; I'm too lazy to look up exactly what's being said, so I'll just generalise: you can define your own traits, and you can define a mechanism to derive said trait for a type. You could always do this with compiler plugins, but those are nightly-only. You could always do this with macro_rules!, but basically no one ever bothered. You can now do it with procedural macros, but this is a recent addition and the docs might not have been entirely updated to take this into account. Ok, doesn't seem like something you'd do often so pretty minor.
why is it that, an assignment like `let test = String::from("test_").as_str();` is not possible.
That definitely makes sense, I just wasn't sure if it was that or if they actually just enjoyed reading programming books.
Yeah I can understand for the different keywords for loops, especially since you can return values from `loop`. &gt; Rust standard library is intentionally minimal, and random number generators and Unicode are complex so it makes sense to have them maintained outside of Rust standard library. Additionally Unicode has versions and definition of grapheme clusters can change in new Unicode versions, so it makes sense to maintain it outside of standard library to allow using a new Unicode standard before new version of Rust is released, or to use old Unicode standard with new version of Rust to preserve compatibility. That definitely makes sense. &gt; This will likely improve soon with module ergonomics RFC. Exciting! &gt; static mut is an advanced feature, and I honestly feel like it shouldn't even be even mentioned in a book - it's very dangerous to use, as it pretty much ignores the entire thread safety thing. Rustonomicon sounds like a better place for it. I wasn't talking about `static mut` just plain old `static`, I might be wrong but I don't remember the `const` keyword being discussed either.
Yup, by saying experience I meant that I had used the language at work or in significant side projects. I've done some messing around with Haskell but not enough to justify implying that I had any real knowledge.
I'm confused, why do they use the same layout as most rust documentation for a website? This makes my brain hurt...
**EDIT**: Looking back, either I posted this in reply to the wrong comment while more tired than I thought or spinicist edited it. Not necessarily. There's nothing preventing you from using Rust's unit test facility for integration tests. While it's not using the full "override `argv`" technique I used in Python, here's a fragment of a regression suite I wrote in a `--bin` crate: #[cfg(test)] mod tests { use std::borrow::Cow; use super::{AppConfig, make_clap_parser}; #[test] /// Can override DEFAULT_INPATH when specifying -i before the subcommand fn test_can_override_inpath_before() { let defaults = AppConfig::default(); let matches = make_clap_parser(&amp;defaults).get_matches_from(&amp;["rip_media", "-i/", "cd"]); let inpath = matches.value_of("inpath").unwrap(); assert!(inpath == "/", "\"-i/ cd\" should have produced \"/\" but actually produced \"{}\"", inpath) } } If you structure your code well, then the integration portion can be pretty compact, since you're *just* testing the integration with all the heavy stuff being tested closer to its definition and aspects of the type system like enums, `Option`, and `Result` ruling out other common sources of integration bugs that tend to crop up in dynamic languages. (Not to mention that I generally argue in favour of making every command-line utility a bin/lib combo crate, so I don't have to serialize/deserialize through shell script (being weakly-typed and with little support for structured data) when I want to call a Rust utility from a Rust frontend. That also greatly reduces the portion of your code which is technically integration-tested but only visible to the unit facility.)
&gt;&gt; "switch-case on steroids" &gt;&gt; I find this phrase to be one of the most over-used and useless things to say. it grabs attention. It *does* convey the emotive response that a programmer will have moving from C++ to rust and actually seeing what match can do. Although it's a nontechnical statement, it basically highlights the fact that it's important . the phrases 'pattern matching' , 'match', etc don't mean anything to a C++ person. the actual description of what it *does* do isn't catchy. think of this phrase as informal marketing, PR.
...and I follow /r/rust/ via RSS, which means that I see every post, including the stuff meant for /r/playrust/ which gets quickly squashed. Reposts like this are annoying enough that, if they were more common, I'd follow the lead of the people who were working on a bot to automatically detect and report /r/playrust/ content. Don't game the design of Reddit's web interface to the detriment of others. Change how you use Reddit.
&gt; Organising modules seems sort of convoluted, Go's always-absolute imports are nicer IMO Imports (`use`) currently *are* absolute, where the root is the current crate's root module. Dependencies are added there via `extern crate`, so that the first segment of a `use` path always refers to a top-level item of the current crate, where this can be either a dependency, a submodule, or a function/type/etc. The ongoing module RFCs mentioned in a few other comments propose changing this so that the first segment of a `use` path instead always refers to a *crate*, whether that's a dependency or the current crate. (However, because it is idiomatic to have both a library and binary crate with the same name, the current crate is referred to as `crate` rather than its name.)
&gt; That work is still ongoing (also note the rand-core RFC, which is related but only linked deep in the comments). It's possible that once a good API is decided upon, and there is sufficient evidence from the field that it will work well and be maintainable, that rand could eventually make it back into the standard library. An example of when that's happened before is with Unix socket support; that didn't land in std in 1.0, but instead was developed in an external crate, and then once the API was deemed solid enough was merged into std and released in Rust 1.10. This was my guess, do you think that more crates will be integrated into the stdlib as Rust matures? &gt; Unicode is very big and continues to change. It also isn't always 100% backwards compatible; later Unicode releases can change some details of segmentation algorithms and data tables. I didn't know that, exclusion from the standard library seems like the best choice. &gt; There is some concern, however, that the module system is a bit too confusing, and there have been some recent proposals for redesigns, though that discussion is still ongoing. I'm glad to see there's some discussion around it. The latest proposal looks promising. &gt; It automatically generates boilerplate code for you for the "obvious" implementation of some trait. Right, I do think this should be explained in the traits section of the book. It's used a few times in the examples and while *what* it does is mostly explained details of *how* aren't.
Definitely. One of the big advantages given by posts about Servo is that mobile CPUs often only have a single clock-speed control for all cores, so limited parallelism winds up wasting power on idle cores.
Dedicated neural-net processors would definitely be a likely candidate, given how crippling the I/O-boundedness of simulating them on a traditional CPU is. (Something like giving each neuron an associated register to store its internal state.) That's actually why there was so much hype about memristors.
If you see `cratename::item` in rust source you can't tell anything about where the crate or the item are defined. It could be in an external crate, a module in the same file, a module in a different file or a module in a different directory. In go all imports are just directory paths so all you need to do is look at the top of the file and open the import path. It seems like there is some discussion on making the module system simpler though (https://github.com/rust-lang/rfcs/pull/2126).
Well I wouldn't say I hate it... An actual explanation [here](https://www.reddit.com/r/rust/comments/70g0i2/a_complete_list_of_notes_on_the_rust_book_from_a/dn3leaj/).
&gt; You mean for/while/loop? They're all syntax sugar that gets desugared to what's basically just loop inside. Yeah I'm in two minds about this. A different keyword for `loop` makes sense since it can return values. I guess `for` and `while` are different enough to justify separate keywords. &gt; String::from is part of the general Into/From conversion traits. It's equivalent to to_string, but the infrastructure built around Into is generally more flexible. push and push_str mutate the existing string, and only work with characters and string slices. Best explanation for that is [here](https://www.reddit.com/r/rust/comments/70g0i2/a_complete_list_of_notes_on_the_rust_book_from_a/dn2zoj5/) &gt; HashMap::new()? I was thinking of `vec!`. &gt; The return type has nothing to do with the assignment. So if you write assign the result of `or_insert` with `let` will it be a mutable reference? It won't right?
Because it is actually Rust documentation; there's a crate for the podcast, with a module per episode. Many of them contain examples of the things discussed in that episode, and the episode notes are in the module level documentation. It provides an easy way to provide episode notes that contain code samples that can easily be compiled and tested all in one repository.
...yes, that's literally what I just described, and the RFC I was referring to.
Ah my bad, I didn't quite understand.
The concurrency-friendly nature is irrelevant to me honestly because it's going to take a lot for me to ever make multi-threaded processes on Unix. It's a dead end in my opinion; once you make that part of your architecture you just sacrifice too much sanity so I just stick to multi-processing and abstract over IPC instead for what I need. Usually you only need to send a specific object across process boundaries so I just serialize that and use a socket or pipe. I really wish Unix multithreading was better than it was but it isn't and the thing with modern multi-threading design in languages with channels and similar stuff is that they basically modelled it after IPC in multi-processing to begin with where you don't mutate global stare and make sure you get the mutexes right but share state by communicating rathe than communicating by sharing state which is pretty much what using good old fashioned sockets is. Edit: This is especially true for Rust because it's not entirely clear what Rust functions actually are async-safe and which aren't so if you fork in a multi-threaded process it's even more of a hell-hole to know what exactly you can and cannot do and it's bad enough in C.
No transcript?
I would say rulinalg if you don't need anything larger than a matrix (e.g. MLP), I haven't used it but have heard good things. For general tensors there is [ndarray](https://github.com/bluss/rust-ndarray), more complex but handles nearly everything.
Yes. Used to be, highly parallel code was scary and tiring: the mental effort of double checking every assumption was really slowing things down and debugging weird race conditions was no fun. Rust made it very easy to work with parallel code. I am very happy with [`rdedup` performance now](https://dpc.pw/blog/2017/04/rusts-fearless-concurrency-in-rdedup/). I am working on it in my spare time, mostly evenings, when I'm already tired and often distracted. Despite that I don't have to spend time debugging silly human errors and race conditions and can focus on more productive things.
I don't understand what are you trying to say. Doing multi-processing has it's own benefits (mostly security and fault tolerance, by having separate address spaces and PID), but message passing within the same process is much more powerful and efficient: you can send messages that you don't have to copy and/or serialize, and they are typed. You can combine state sharing, atomics and message passing within same code, to get best qualities of each where they matter. &gt; it's not entirely clear what Rust functions actually are async-safe and which aren't so if you fork in a multi-threaded process it's even more of a hell-hole to know what exactly Seems to me like this is just incorrect. Why would just just `fork`? By using `std::thread::spawn` you get much nicer abstraction to work with, and Rust explicitily tracks `Send` and `Sync`, which is one of the main selling points. You know exactly what is thread-safe. If you think about "async" as like `mio`, then you'd just use them like an event loop itself, or abstractions like futures (`tokio`) or coroutines (`mioco`). I fail to see your concern here. The ecosystem is young and so on, but there are no fundamental issues here.
C++ dev (and Rust convert) here. I work with a heavily multithreaded code base. Rust doesn't make my code faster, because it would be just as fast if I wrote it in C++. But Rust makes **me** much faster, because I don't have to spend endless minutes carefully checking my code for race conditions, and endless hours (or days) tracking down the ones that slipped past me. 
Also, if you're on Windows, as I am 95% of the time, processes have more overhead than on Linux.
A generic type allows FromIterator to be implemented over multiple iterator item types. For example, String can be constructed from either an Iterator&lt;Item=char&gt;, or an Iterator&lt;Item=&amp;'a str&gt;. Both of these behaviors are useful and it wouldn't be possible if FromIterator didn't use a generic parameter ;)
That is what I meant.
&gt; Doing multi-processing has it's own benefits (mostly security and fault tolerance, by having separate address spaces and PID), but message passing within the same process is much more powerful and efficient: you can send messages that you don't have to copy and/or serialize, and they are typed. You can combine state sharing, atomics and message passing within same code, to get best qualities of each where they matter. The biggest problem is that as soon as a process becomes multi-threaded you can essentially kiss fork goodbye as it really becomes too complex to keep track of how to properly fork any more especially with languages that abstract over the libc. The basic problem is that when you fork in a multi-threaded program only the thread that called fork survives in the daughter process which is single-threaded again but any mutex held by another thread will be perpetually held at that point and never released. So if you fork while another thread is using malloc which is permitted to use mutexes by the standard and surely will then that mutex will be held and never be released so if that happens your new daughter process essentially cannot use malloc ever again which is used under the hood all the time in Rust obviously. There are a tonne of other library functions in Rust which internally use such mutexes (not being async safe) and Rust does not say which functions are and which aren't async-safe. POSIX requires that certain functions in the libc _must_ be async safe which means you can use them in a fork from a multi-threaded program without any fear of a deadlock but if your program uses a function anywhere in another thread that is not async safe and you use a non async safe function after a fork in a multi-threaded program that function may very well block and never return as it's waiting on a mutex which is an implementation detail that will never be released ever. &gt; Seems to me like this is just incorrect. Why would just just fork? By using std::thread::spawn you get much nicer abstraction to work with, and Rust explicitily tracks Send and Sync, which is one of the main selling points. You know exactly what is thread-safe. Because `thread::spawn` makes a new thread and not a new process and if I `exec` in a thread the _entire_ process gets replaced, not just the thread? I mean a basic use case which happens to be my current use case is to write a service manager which alters the security and resource context of a service it starts. The process is: 1. Fork off a daughter process 2. Alter the security and resource context of this daughter 3. Exec into the actual process you want to supervise If you attempt to do this from a multi-threaded process you can pretty much expect that due to race conditions the program will lock up at step 2 or perhaps even step 3 because for al I know execing in Rust involves malloc in some way or another to form the string to pass to the raw `execve` system cal underneath which expects a null terminated string so for all I know it needs to malloc to copy the string into a new space to add the terminating null byte; it doesn't dcument this or makes any guarantees about this behaviour. &gt; If you think about "async" as like mio, then you'd just use them like an event loop itself, or abstractions like futures (tokio) or coroutines (mioco). I fail to see your concern here. The ecosystem is young and so on, but there are no fundamental issues here. No, as I said async-safe is a POSIX guarantee that essentially comes down to "it is safe to use this function from inside of a signal handler handler or from a fork off a multi-threaded program"; both of which are known to be troublesome and it essentially under the hood comes down to "this function is free of using any mutexes".
It allows a collection to implement `FromIterator` for multiple item types. For example, `String` implements `FromIterator` for both `char` and `&amp;char` item types, among others. If the item was an associated type, it would only be possible to implement the trait once per collection type.
"Linux can spawn processes faster than Windows can spawn threads" is the claim I've heard.
For me, Rust's parallelism features are mostly nice-to-haves. I know Rust was designed to deal with multicore in complex applications, and honestly, a systems language that doesn't do that these days is deserving of criticism. But mere concurrency has been easy for almost 20 years now. Every time I've received the news that my code was too slow, it's been IO bound, so I'd start using coroutines and async IO, get a 1000x speed improvement in an afternoon, and marvel at how easy it was. But I don't actually compute that much so I can't speak for everyone. What I like about Rust is the type system. In an age where web development is what people think programming means, it's astounding to see a new language that has an uncompromising (or uncompromised) type system. The traditional tools of this trade are dynamically typed, and most systems languages in common use when the web took off did little for you in terms of types. But you know, with Rust there are two basic improvements for concurrent code. The first is boring: now you can put that on another thread and it will be fine. The second is the real boon: you don't need to worry about scheduling. The majority of my time spent on concurrency in an application is getting the coroutine ratios right, and tweaking their scheduling. (Shoutout to Perl's Coro, which lets you choose how involved you want to be.)
The factory pattern actually does appear in at least one popular crate's API, namely [Hyper's `NewService` trait](https://docs.rs/hyper/0.11.2/hyper/server/trait.NewService.html) (which is implemented for closures of the right signature). You could also consider the implementation of `IntoIterator` for slices to be a spoof on this pattern (because it doesn't consume the implementing value). (Edit: removed comparison of factories and builders because I realized you meant you knew the difference and it just ended up sounding condescending)
That's... pretty awesome, and clever.
Maybe a better example would be artists/designers. They have a portfolio and it is not necessarily open or public.
Not yet, but that's mostly because, as someone whose overwhelming majority of work is in Python, PHP, JavaScript, and shell script, I have 15+ years of learning to not even bother thinking of CPU-bound tasks. (I mainly use Rust because it gives me more compile-time correctness guarantees for my I/O-bound creations.)
Worst of it, it can be used as an attack vector for a "trust in trust" attack style: you can use to replace the installation of rustc on the dev machine or change the source of the existing crates (you have all the privileges of the current user after all). This can in turn be leveraged to actually insert malicious code in the binaries created, which is real nice if they are further distributed...
There really isn't much difference between a separate process and a separate thread on Unix. Threads were hacked on top of separate process who can just read in each other's address space. When multithreading was first introduced people were like "ohhhh, fancy, we can now have two processes who read into each other's address space; that's cool." then people eventually realized how messy it was and modern concurrency models use conduits which look eerily similar to IPC so we're close to back where we started. Really I wouldn't mind a trait like `Serialize` which determines that a datum can be written down to a binary representation and then read back from it from which a sort of channel between processes can be abstracted before they fork or whatever or even after when supplying a socket path.
Somewhat related note: binary search is terrible (caching wise). For mostly read load of unpredictable keys, instead of sorting the vector, you can instead overlay a tree inside it: `v[0]` is the root, for a node `v[i]` the children are at `v[2i]` and `v[2i+1]`. There are two nice things about this layout: - the most frequently accessed elements (root and first few levels) are all packed tightly together (at the beginning), so are likely to stay in cache yet do not pollute it, - when comparing to the key at `v[i]`, whether the result is true or false, you are likely to end up on the same cache line (because both children are next to each other); you can therefore use a *prefetch hint*. *Note: another way to think about it, a sorted vector is a depth-first arrangement of a binary tree whereas the above is a breadth-first arrangement of the same tree.*
&gt; I believe the motivation was (at least in part) the size of the Unicode tables; in general, Rust tries to push what it can out of the standard library. There's also an issue of versioning. Each new revision of Unicode may update some classification, alter collation algorithms, ... This means that the behavior of a program can change depending on the version of Unicode it uses; and worst, it means that a program which filled up a database with a version of Unicode, could have issues finding its records/... with a newer/older versions. As a result, it seems better to let the user decide which version of Unicode they wish to use; and not tie that to the version of rustc/std.
Good points from both of you; that line can be really hard to figure out, especially if you're working at a large company (ex: Google) that has their hands in everything.
&gt; I can see the motivation for keeping the standard library minimal. Do you think that as Rust matures there might be less of a maintenance burden on including more in it? I think the idea was that instead of extending std, the useful libraries could be "adopted" by the rust-lang organization: - this makes finding such libraries easy: browse what's available from rust-lang, - it highlights those libraries: they are mature, maintained, etc... - yet it allows competing libraries to emerge, be adopted, and eventually displace the others (which is important, as new language features/better maturity can bring in much better approaches). There is a dread that including things in the standard library, and subjecting them to the extremely stringent backward compatibility requirements, would be condemning them to obsolescence.
&gt;Should someone in my position be looking into Rust? Why is that? The most important thing is that you follow through and fully master the language you choose. I read a great anecdote today about this, http://jxyzabc.blogspot.com/2017/09/the-genius-fallacy.html There is no "best" language. All of them have their faults. Rust included. First think, what is my mission in life? Once you have that, choose the language most suitable for completing the mission. Then learn to be your very best in it.
This! It's a really thorough report; this is gold for improving the documentation!
In this arrangement, the `String` (from `String::from()`) doesn't last longer than this statement; because it's not assigned to anything, the compiler wants to drop it immediately. This is, of course, an issue because you're wanting to bind a borrow to this `String` (with `.as_str()`) to the full scope (the function or block that `test` appears in). It's a little clearer if you expand the intermediate value to a temporary in a nested block: let test = { let temp1 = String::from("test_"); temp1.as_str() // temp1 is freed at the end of this block but // you're trying to use a borrow to it outside }; The quick fix is to bind the `String` to a variable in the same scope, so the compiler can determine that they have the same lifetime: let string = String::from("test_"); let borrowed = string.as_str();
I have not yet done the work to embed the transcript on the episode pages, no. However, you can always find them in the source on GitHub. Here are [all of them](https://github.com/chriskrycho/newrustacean.com/tree/master/docs). And [here is this episode](https://github.com/chriskrycho/newrustacean.com/blob/master/docs/cysk-rayon.md).
As others have noted, it's real Rust docs so that I can have Rust *source* in tutorial episodes. I discussed why (and noted that it's a little crazy!) in some detail in [e001: Document all the things!](http://www.newrustacean.com/show_notes/e001/index.html).
https://transform.now.sh/json-to-rust-serde https://www.reddit.com/r/rust/comments/6yf899/an_online_repl_for_converting_json_to_rust_serde/ It's only for serde, but very useful for generating structs from JSON responses. 
Given the way they're acting in this thread I wouldn't touch this company with a ten foot poll. Not the kind of people I would ever want to work for.
Using something with a fixed version in `Cargo.toml` doesn't mean that package, and _all_ of its dependencies are.
That makes sense, thanks! Still trying to grok everything about Rust's type system.
&gt; for all I know There's an open bug in nix-rust discussing this with links to how standard library does and documents fork-exec. The long and short of it is "do all allocation before forking". Also, the standard library has a mechanism for doing what you want: `std::process::command` and `std::os::unix::process::CommandExt`. `CStr::from_bytes_with_nul(b"Hello, World!\n\0")` doesn't require run time allocation. 
I think the risk of obsolescence only really exists in some specific areas. For example Go's http implementation is used by a large number of people and parts of it are used for most popular libraries. This obviously doesn't come without a cost but as the language stabilises I thought it might become more practical.
&gt; Will be a perceived negative in the eyes of a myopic ingrate. Fixed that for you.
I assume you're talking about `before_exec`, from its documentation: &gt; normal operations like malloc or acquiring a mutex are not guaranteed to work (due to other threads perhaps still running when the fork was run). So you still run into the problem that from a multi-threaded process `before_exec` is essentially useless and underdocumented and no one essentially knows what it does and what the guarantees are in a multi-threaded environment. And what if I don't want to `exec` at all from the fork? The rust stdlib as far as I know can only `fork/exec` it cannot just fork and then exit for which you need to dive into `nix` or `libc` in particular my code right now contains a rather ingenious "hack" for a super simple main-loop design that sleeps consuming zero CPU until something is delivered on a socket. So how does it handle signals? The signal handler itself forks and then the fork sends a message to its own socket to wake it up in order to respond to the signal. It forks first in order to be able to use non async-safe functions which is permitted and it never execs. Really, I scarcely touch multi-threading in a language like C which has strong guarantees about what you can and cannot do and I most certainly do not touch in Rust where the guarantees come down to utter vagueness like "normal operations are not guaranteed to work in a multi-threaded environment" where no documentation exists of what is a 'normal operation'.
Lisp Machines that did this were built. I'll break it down for your explicitly: Machine words on lisp machines were all 40 bits long. Four bytes were for the regular machine word, and one byte was for the descriptor. Now consider integer addition. You can only add two integers together with integer addition, so in a normal lisp implementation you have to first check that the descriptors match, then do the actual addition. In a lisp machine both happen at once, and if the descriptors don't match an exception is raised. I make it sound like a parallel problem because it is one.
This is my experience. I wrote a program that transforms some data files into several other formats (okay, that describes most programs ever written, doesn't it...) and it used 100% of one CPU core to do the translation. Then I put it in parallel so it could process N files at once. Could I have done that in C++? Yes. Would I have gotten it wrong the first 73 times and had crashing bugs / overwritten data / deadlocks? Also yes. Fearless concurrency says I!
That seems like using a hammer on a screw. It's a great tool being used for the wrong task. Maybe the right tool doesn't exist yet? I'd think something like a Jupyter notebook would be a better tool for this job. They are explicitly designed to mix text, media, and code, and Github will render the notebook on site.
sure; there's already devices in use and the latest apple SOC has something they call a 'neural engine' (no idea exactly what it is). the google TPU is just a giant low-precision matrix multiplier, i think you upload a big array of coefficients into it then stream data through, and it does indeed keep other data inlace ('giving each neuron an associated register= = a big array of accumulators for the matrix-multiplications') i'm sure we will see many ideas implemented
Do you have Vulkan driver? If so, check and/or open an issue on the issue tracker.
This is what I call missing the point. ;-) *Obviously* Rustdoc is not an "optimal" selection for this—not even close! It was and is, however, a *fun* selection for it, and one I think gets the job done in an interesting way.
If you assign a mutable reference to an immutable variable, you can still mutate whatever the reference is pointing to. What you can't do is make it point to a different thing. 
I find that pretty confusing. Wouldn't it better if everything assigned with just `let` wasn't mutable? Mutable function returns would get coerced into immutable references.
Got it resolved. There is apparently a bug with the Vulkan ISD loader and discrete/integrated graphics setups. You have to disable the integrated graphics device in the BIOS, then it works.
Does this mean the problem is vulkano-specific or is the problem somewhere else? Edit: Fix my grammar to be more clear.
not sure if I understand your question 100%, but if you're asking if the problem is in the vulkano library, the answer is no. The problem rests with the ISD loader provided with the Vulkan SDK from LunarG.
What exactly are they doing that makes you not touch this company with a ten foot poll?
[removed]
Allowing anything like this is unsound; Haskell had to go through a major breakage not too long ago because a similar problem wasn’t discovered until too late.
are you more interested in gpu or general purpose cpu code; when I hear *linear algebra library* it makes me think of slightly different use cases to *tensor library* (focussed on leveraging a GPU for AI/ML). it seems ML (which you mention) has slightly different requirements, e.g convolutions. just curious where your exact interest lies.
You can test cli programs using tools like [cram](https://bitheap.org/cram/) or [bats](https://github.com/sstephenson/bats). I like cram, but bats is probably more popular. [This](https://thomaslevine.com/!/computing/shell-testing/) article has lots of suggestions.
Excellent work folks. This comment's score clearly demonstrates to companies how mature and well-balanced rust's community is (I suppose it's to be expected given the disproportionate emphasis on social issues and the type of people such emphasis attracts, but I digress). If you're an employer looking to hire professionals with solid experience in rust, I strongly recommend against looking for candidates in r/rust. If you must, thoroughly vet them to avoid problems down the road. I personally would look for competent C++ developers if the relatively small amount of downtime they'll need to pick up rust is not an issue.
&gt;You [should] also have a GitHub account with a significant body of public source code. They're looking to hire developer. I'm sure what they want to know is if you have a solid grep on rust. They're not going to throw out your application if you link to gitlab or a patch. You're making a mountain out of a molehill. 
I think you and /u/Uncaffeinated are over thinking this a bit. Alerting the attacker that their crate is under review leaks information. And a reactive review will only be doing damage control PR. Everything submitted should be put into a pending state until it is reviewed by the community during its initial age. If someone has a enough reputation (usage graph, age, etc) they will have lower update latency. Edit distance checks should apply to everyone.
Not to brag, but 99% of the time the crashes that people report with vulkano are caused by the Vulkan implementation.
A specialization (this type isn't specializable, but that's neither here nor there) could specialize only the assoc type without overriding the function. Then there would be a type error. There are solutions to this - like some way to indicate that all these items need to be specialized together (or the compiler figuring it out for you). But this is the conservative solution for now.
No one said core had to review crates. If I was Rust czar, I'd require tests, some amount of coverage and a public repo for all crates and all releases would be signed. The crates themselves would have to be built and tested before being listed.
The existence of an attack vector doesn't make it the same as the original attack, nor does it mean that it shouldn't be implemented. Security is a spectrum. Typosquatting a namespace is less valid than typosquatting a crate. Namespaces would also allow for cleaner forking of crates w/o some releasing `serde2` 
Is there a Rust implementation of Cucumber? I tend to just throw the Ruby Cucumber shell plugin over all my CLI tools, using that to automate basic input vs. output checks.
Doesn't it need a `build.rs` or a procedural macro to execute code during a build? Using different sets of Rust features gets one different levels of assurances in how safe it is for the developer and the end user.
You understood it. Thanks. That's a helpful answer.
I think it would be great if not only short names but also dictionary-ish words were taken, they are akin to Community Property. 
Does it not *require* a build.rs for code to be executed at build time?Together you and /u/ma-int make a valid point that crates containing `build.rs` could attack build infrastructure.
Hmm to clarify, why is the type not specializable? How would I indicate that all the items are specialized together? Is the simplest way to do this to change the associated types to type parameters? EDIT: This works: https://play.rust-lang.org/?gist=763c47a29b83076d7dc08dce82c93356&amp;version=nightly
Yes, just dropped in rayon to replace a for loop and got 8x speedup. Required almost no thinking other than having to use a closure where there was none before.
Yes. I came from Ruby, and was very used to programming with blocks and iterator-style patterns. [Rayon](https://github.com/nikomatsakis/rayon) made it almost trivially easy to translate my existing code to something that used all 4 processors and completed the work in nearly 1/4 the time. The major advantage of Rust in this context was ensuring that things were `Send` and `Sync`, rather than relying on other languages' solution of a global interpreter lock (e.g., Ruby).
Have you looked at [Idris](https://www.idris-lang.org/)? It could be thought of as Haskell with eager evaluation and dependent types.
Right. The point is, before knowing Rust, you probably wouldn't even thought of those bugs too much until you encountered them. Feeling helpless is probably the right, healthy emotion to feel while writing C++.
Also, "Git repositories on fuchsia" on fuchsia.googlesource.com lists several Rust related projects. https://fuchsia.googlesource.com/?format=HTML 
&amp;: [Reference](https://doc.rust-lang.org/book/first-edition/references-and-borrowing.html). *: [Raw pointer](https://doc.rust-lang.org/book/first-edition/raw-pointers.html). I **do not** recommend trying to write an FFI binding by trying to copy what you find in other projects. If you don't understand what's going on, go and read [The Book](https://doc.rust-lang.org/book/) and the [Rustonomicon](https://doc.rust-lang.org/nomicon/) until you do. It is way, *way* too easy to blow both your legs off without even realising it.
Where does the unsoundness lie, exactly? Is it because in an impl I override the function, but it might be possible that I didn't override the associated type simultaneously, thus leading to a type error?
Basically, but it’s always possible with a setup like this to convolute things enough to *not* cause a type error (but then have things blow up at runtime—or possibly not blow up, which is even scarier). The underlying issue is that this would require the compiler to insert implicit instances of `mem::transmute` (effectively). To learn more about Haskell’s struggle with this kind of issue, [read this page](https://ghc.haskell.org/trac/ghc/wiki/Roles#Theproblemwewishtosolve).
Great point. A most insidious attack vector, to be sure.
Thanks a lot! The key to understanding this was the "raw pointer" part. I read the second edition of The book and I guess I missed that part which stands out more in the first edition. If I'm understanding this correctly I should try to minimize the use of raw pointers as they are unsafe but might be needed for the ffi with the dll and then expose a safe interface (using references) to the users of my rust module.
This is just a zero-value-added rehash of the [actual survey result report](https://blog.rust-lang.org/2017/09/05/Rust-2017-Survey-Results.html).
The article references static analysis tools for C/C++, but fails to mention [we have them, too](https://github.com/rust flange nursery/rust-clippy) (at least on nightly, for now).
I think you misunderstood me - I want to take `_main()` and trivial `main()` approach you outlined, and apply it to my suite of C++ programs. Then I can use something like CTest to start doing decent tests instead of my cobbled together `bash` scripts like the `fd` example above. My programs (image processing utilities) take a *lot* of arguments. The most important bit of the testing is checking I got the damned arguments set up correctly! What can be put in a library already is, but its the actual end-to-end program I want to test.
I'd say no, not really. It would complicate reasoning about lifetimes a lot if you start silently coercing immutable references to mutable ones. 
&gt; Hmm to clarify, why is the type not specializable? Because there is nothing 'more special' than `Thing&lt;usize&gt;`. &gt; How would I indicate that all the items are specialized together? You can't right now.
Ahh. Doing it in a non-Rust language would definitely require some tweaks to the approach. I'm not personally familiar with C and C++ frameworks like CTest but, depending on how your build system is set up, it may still not be too difficult to take the approach I outlined by doing as follows: 1. Put `main()` and `_main()` in separate files 2. Set up the build so that the test suite includes all of the usual files except the one containing `main()`. That way, the test suite gets behaviour similar to making `_main()` a public library function without having to go that far. If the test framework requires a library be built, maybe architect the generation of a library only during test builds which is the binary's contents, minus the usual `main()` entry point.
My impression of Rust is that it's probably the best balance point for me between imperative and functional elements. I just don't feel comfortable with the distance functional languages place between the machine model and the language's abstract model. (The CPU's branch prediction and cache hierarchy are unnerving enough to me as it is.) If Rust can eventually support dependent types, that'll be great, but, at this point, I find Idris simply not worth the effort for what it brings to the table over and above Rust. ...not to mention that one of my big reasons for using Python is its library ecosystem and one of my big reasons for using Rust is the combination of the [rust-cpython](https://github.com/dgrunwald/rust-cpython) crate and the rate at which its ecosystem is growing. (For example, one of my projects is a PyQt application where I'm incrementally migrating stuff to Rust for maintainability as time permits. The goal being for Python to become a "QML for the QWidget API" until a project like [rust-qt](https://github.com/rust-qt) matures.)
Yeah, there is some disconnect here. It's like dereferencing a mutable reference `&amp;mut T` is implemented using a hypothetical DerefUniq trait ("unique borrow"): fn deref_uniq(&amp;uniq self) -&gt; &amp;mut T It does not require the binding to be mutable (the binding itself is not changed!) but it requires the borrowing to be unique because otherwise you'd be able to create many aliasing mutable references. I actually like this! The only problem I have with this is that you can't emulate this with a custom type such as `std::cell::RefMut` because `&amp;uniq` isn't a thing but just some internal compiler magic. The only unique borrow available that we can express in a method is `&amp;mut`, see `DerefMut` trait: fn deref_mut(&amp;mut self) -&gt; &amp;mut T Of course, mutably borrowing a `RefMut` requires the binding to be mutable as well even though we don't need to mutate anything about the `RefMut` struct.
Totally cool. I think Rust strikes that sweet spot right now. People have been doing some amazingly functional-ish stuff on the platform. Excited for more. In the future I'd like to see really high level abstractions and equally advanced JITs that can cross the whole stack. I love Python, but I really try to distance myself from the CPython interpreter. I'd love something analogous to rust-cpython but targeted more generically at dynamic languages, including PyPy (cffi, and thus CPython). 
You put your externs in lib.rs and have main.rs call the entry point you expose from there. There should be no duplication this way.
It's now called zircon. I don't know why they don't just call Fuchsia's kernel "fuchsia kernel"
My interest would be in a library which not necessarily (at the moment as I am just prototyping) leverage something like a GPU. I would be content with a linear algebra library that works on the CPU but that makes use of good practices to make it run fast on a CPU, e.g. SIMD operations.
I certainly agree. The more versatile my bindings, the better... as long as it doesn't impose unusual ecosystem constraints, as would be the case for using GObject Introspection in a project that already provides its own equivalent components (eg. event loop), such as a PyQt application. (Better to have some kind of generator which allows the generation of bare Python bindings, GI bindings, etc. with minimal duplication of definitions.) At the very least, I'd like to see something like rust-cpython that also works with PyPy (ie. without throwing out the high-level aspect the way Snaek does). As-is, I generally try to aim for pure Rust or pure Python with rust-cpython being used in situations where I need something like Qt or Django on the frontend, I can produce a reusable backend, and I have future plans for other bindings beyond Python. For example, the PyQt app is a game launcher I'm using as a development platform for experimenting with heuristics and UI tweaks I haven't seen anyone else doing. I eventually hope to offer the heuristics as a Rust library with various bindings that projects like GNOME Games could use and the UI tweaks in a document detailing the rationale and how to implement them. (One example UI tweak would be the default mode I've written for the filter field on the games list, which uses a substring match bound to a word boundary on the left end, so a search like "pir" will match "Pirate" or "Pirates" anywhere in the title, but not "Spirits" or "Vampire". In my experimentation, that best aligns with human intuition.)
Hmm but I'm not quite trying to specialize `Thing&lt;usize&gt;`, but rather `Thing&lt;T&gt; where T: Clone`. I provide an impl for such T, and then specifically another one for `usize`. EDIT: Oh I see now, I'd marked the impls for `Thing&lt;usize&gt;` as default as well. That wasn't my intention, only for `Thing&lt;T&gt;` to have the `default` marker.
Link 404.
I got the impression that Fuchsia is comparable to Android, and Zircon is comparable to Linux.
Hi all, I have a question too! So I have a struct, which has a u16 type array. pub struct Renderer { ... pub abc : [u16; 26], ... } I also have a function, which calls another function in its body. pub fn render_registers(&amp;mut self, reg : Vec&lt;String&gt;) { self.render_char(100, 100, self.abc[0]); } In this state, the compiler gives me an error: &gt; error[E0503]: cannot use `self.caps_abc[..]` because it was mutably borrowed If I change the self.render_char(100, 100, self.abc[0]); to self.render_char(100, 100, &amp;self.abc[0]); and also change the render_char function parameter to &amp;u16, then the error is: &gt; error[E0502]: cannot borrow `self.caps_abc[..]` as immutable because `*self` is also borrowed as mutable I would like to learn from this mistake as I'm a beginner. Please help guys! Thanks in advance.
But it's all part of one project. The windows kernel also does not have a name as far as I know.
Check out this talk: https://youtu.be/3CwJ0MH-4MA It may be a little out of date now but it should still be useful. 
Calm down, folks. Please. /u/koheant: Reddit scores have very limited predictive power over tech job performance. Even in the most favorable interpretation I can find, you come off as trolling. So stop that, please. /u/ae-cto: your comments don't seem to add anything constructive to the discussion. Perhaps you can give us more actionable information?
That's not just the Python and Rust code that's shown, I need additional files, right?
I haven't tried it myself, but [this blog post](https://bheisler.github.io/post/calling-rust-in-python/) seemed very informative.
All these questions seem to be asked many a time and gathering all the answers is kind of nasty. It would be nice to see this post as a structured blog article like "Summed up some answerd questions from reddit". Anyone?
In the first case, this is actually something the compiler could do better and a solution is on the way that will make the compiler accept that as-is: https://github.com/rust-lang/rfcs/pull/2025 The basic problem is that you can't call a `&amp;mut self` method on a value and also use that value (call a method, access a field, etc) in the arguments to that method call because the compiler can't reconcile the borrows. The simplest fix is to lift the problematic access to a variable, which works for your first example but not the second because it's copying out the `u16` instead of taking a reference to it: let char = self.abc[0]; self.render_char(100, 100, char); This form still isn't allowed because it borrows `self`: let char_ref = &amp;self.abc[0]; self.render_char(100, 100, char); However, if you come up against this again and the previous solution doesn't work, you can instead change the method that wants a mutable borrow into a standalone function that takes the individual fields instead of the whole struct: // `canvas` standing in for whatever fields you need mutable access to fn render_char(canvas: &amp;mut Canvas, x_pos: u32, y_pos: u32, char: &amp;u16) { ... } // in your `render_registers` render_char(&amp;mut self.canvas, 100, 100, &amp;self.abc[0]);
It is the NT Kernel. Edit: MS naming is a mess, that is nowhere near definitive, but at least everyone calls it the NT kernel.
Strangely enough, that code doesn't work for me (Win10) as it throws an error: cffi.error.CDefError: cannot parse "int double(int);" https://pastebin.com/JumxVz2T
Thank you! I think I got the hang of it. I thought about the first solution too, but I wanted to know is there any other possible solution to this. Thank you again :) 
I'd outright ban creating crate with too small Levenshtein distance from anything else. (I guess Levenshtein distance is something similar to Hamming distance but designed for text.)
(it's a link to clippy)
As someone in a similar situation (though preferring Rust for its stronger type system in some code that can be easy to mess up), here's my recommendation: [rust-cpython](https://github.com/dgrunwald/rust-cpython) paired with [setuptools-rust](https://pypi.python.org/pypi/setuptools-rust). (See the second example in the rust-cpython README as the first one is about embedding a Python interpreter in a Rust program.) This is what I used for my in-progress efforts to rewrite the backend of a PyQt application in Rust and I can vouch for its simplicity. (Basically, you use the types and macros from rust-cpython and it builds a library that can be `import`ed. It includes a bunch of conversions between common Python and Rust types and you can write your own by implementing the `ToPyObject` and `FromPyObject` traits.) (After I've slept, I'll think about whether I'm willing to push the branch in question to GitHub so you can study how I'm using it. It's in a bit of an in-between state right now.) Technically, the PyO3 fork of rust-cpython is superior, but it currently requires nightly Rust, so I can't recommend it.
This sounds interesting and would like to hear more about what the loop was doing, if you don't mind sharing.
https://github.com/PyO3/pyo3
I guess I should check out Rayon after all. I work with Ruby and your comment makes me curious about Rayon.
Maybe installing rust under non-privileged user isn't that good idea after all...
There indeed is! There is the older `replace` mechanism and the newer `patch` mechanism. The newer is easier to use and more powerful. Check out these docs: http://doc.crates.io/specifying-dependencies.html#overriding-dependencies
There indeed is! There is the older `replace` mechanism and the newer `patch` mechanism. The newer is easier to use and more powerful. Check out these docs: http://doc.crates.io/specifying-dependencies.html#overriding-dependencies
Yep, literally just found that! Feel like a right old plum! Should be noted that patch doesn't seem to work currently, I found that it's 'going to be made available in rust 1.20' according to http://doc.crates.io/manifest.html. Use `[replace]` for now.
I can't seem to build the example code there: https://pastebin.com/XYQ5Y324 I have nightly installed... how do I activate it for cargo?
It doesn't alert them that they're under review, though. It just notifies them that, to use that specific crate name, they must apply for a review.
Sending arrays to Rust is fairly straightforward. [Here's a setup that uses ctypes to send nested arrays to Rust](https://github.com/urschrei/polylabel-rs/blob/master/ffi.py), and [here's the FFI code on the Rust side](https://github.com/urschrei/polylabel-rs/blob/master/src/ffi.rs) The project itself is fairly simply structured, but it assumes you know Rust. Note that if your Rust function is only going to _transform the values_ of your array (that is, if you give it an array of length `n` and type `T`, it will return the same) or only borrow it in order to compute single values , you can (generally) just work with slices, and not worry about Rust taking ownership of the array. [The FFI omnibus is an excellent read](http://jakegoulding.com/rust-ffi-omnibus/). [Here's a good Cookiecutter template for Python](https://github.com/mckaymatt/cookiecutter-pypackage-rust-cross-platform-publish), and an [example project using it](https://github.com/mckaymatt/rust_pypi_example)
I started with a new lib (cargo new pppp), pasted the file contents, created the setup.py file and it gives me this error: PS C:\Users\harkonnen\Documents\pppp&gt; python .\setup.py develop running develop running egg_info creating hello_rust.egg-info writing hello_rust.egg-info\PKG-INFO writing dependency_links to hello_rust.egg-info\dependency_links.txt writing top-level names to hello_rust.egg-info\top_level.txt writing manifest file 'hello_rust.egg-info\SOURCES.txt' error: package directory 'hello_rust' does not exist That's my folder structure: Verzeichnis: C:\Users\harkonnen\Documents\pppp Mode LastWriteTime Length Name ---- ------------- ------ ---- d----- 17.09.2017 14:34 .vscode d----- 17.09.2017 14:45 hello_rust.egg-info d----- 17.09.2017 14:35 src d----- 17.09.2017 14:30 target -a---- 17.09.2017 14:29 31 .gitignore -a---- 17.09.2017 14:30 5335 Cargo.lock -a---- 17.09.2017 14:42 222 Cargo.toml -a---- 17.09.2017 14:45 394 setup.py Any idea how to get this to run? 
Check out the stainless steel org--they have Blas and lapack bindings for rust and various compressed matrix formats. Just beware the apis are actually unsafe even though they're unmarked. 
It should go even further and weak specialization support seem to be the cause. Really all you need is `From`. In an ideal world you could just impl&lt;A, B&gt; From&lt;A&gt; for Vec&lt;B&gt; where A: IntoIterator&lt;Item=B&gt; But sadly even the current specialization proposal isn't powerful enough to do things so the `FromIterator` trait exists as a hack to solve this.
I'm hours overdue for bed, but I'll get you an answer after I've slept.
Thanks. Goodnight!
Ehhh, to be completely honest you probably shouldn't be writing bindings if you don't undertand the difference between references and raw pointers yet because it is almost sure to go wrong and lead to undefined behaviour if you don't understand this difference. Raw pointers in Rust take way more care to use than pointers in C since the compiler is free to make a lot of assumptions that it can't in C which can lead to undefined behaviour easily.
"Using the features available on the site" isn't "gaming" anything. Reddit makes money off of people using their site; without people using it, Reddit dies. If reposts are so annoying, maybe reconsider how you access the site. They're not against any rules of the site itself, and they don't actually break anything. Your use case is no more or less valid from a user's point of view, but mine directly supports the service I'm getting, however small that support is. 
"Using the features available on the site" isn't "gaming" anything. Reddit makes money off of people using their site; without people using it, Reddit dies. If reposts are so annoying, maybe reconsider how you access the site. They're not against any rules of the site itself, and they don't actually break anything. Your use case is no more or less valid from a user's point of view, but mine directly supports the service I'm getting, however small that support is. 
&gt; The existence of an attack vector doesn't make it the same as the original attack, nor does it mean that it shouldn't be implemented. Security is a spectrum. Agreed. &gt; Typosquatting a namespace is less valid than typosquatting a crate. I don't see how. &gt; Namespaces would also allow for cleaner forking of crates w/o some releasing serde2 I don't consider that a desirable feature, and has no bearing on the typosquatting argument. For the record, there are plenty of advantages to namespaces, and I think crates.io will get them someday, but I tire of claims that namespaces will solve every problem under the sun.
&gt; If I use *mut, it seems I don't have to specify the lifetime which I believe is not helpful for compile-time checks. Thing is, these compile-time checks are not possible - because you are calling a foreign function. That function does not have Rust's lifetime info in its signature, and is not guaranteed to respect Rust's safety rules. You may send a borrowed pointer to it, and it may store it somewhere else and escape it's lifetime. It may return a non-unique mutable pointer. It may return null pointers, and so on.
 rustup override set nightly 
I wrote an [implementation of a neural network](https://github.com/cdbfoster/zero_sum/tree/master/src/impls/tak/state/ann) for use in the analysis of zero-sum games; you're welcome to take a look at how I did things. The only thing that isn't general-use in there is the feature representation, which is specific to a zero-sum game called [tak](https://www.reddit.com/r/Tak/). Everything else should be applicable anywhere. The network uses [blas](https://crates.io/crates/blas) to do the heavy lifting, on the CPU, using vectorized instructions. I'd be happy to answer any questions about how I did things!
This is a feature I've wanted in Rust within my own personal projects, so I decided to make a crate for it! One of the main reasons I made this is that you can convert C-like `enum`s _to_ integers via an `as` cast but not _from_ integers. Deriving `FromUnchecked` for such types allows for this. `From` can then be implemented via `FromUnchecked`, using masking or other operations to ensure a valid value. In my opinion, using `from_unchecked` or `into_unchecked` is much more expressive than `mem::transmute`. Usage examples are provided [here](https://docs.rs/uncon/1.0.0/uncon/#examples) and [here](https://docs.rs/uncon_derive/1.0.3/uncon_derive/#examples).
It was, and it was *terrible*.
This sounds sweet. I didn't want to say Swig, but I wanted to say Swing, but it gives me PTSD, so I didn't say it. A high level machine readable representation of how Rust code should interop with HLL languages *should* enable the automatic construction of bindings. COM/Swig/etc targeting GObject, Lua, Python (Jython, PyPy, CPython, etc). A Rust aware `DLOpen` could enable Rust to be directly loaded by dynamic languages. We are in agreement on wanting to stay high level and the less boilerplate means that code is actually *easier* to migrate to something else in the future. Cython is actually keeping a great number of folks on CPython instead of PyPy which I think is unfortunate.
I think this would leak too much information and the attacker would tweak their algorithm until the alerts went away.
No, my Rust code has the same performance as my C code and it took longer time to write. But I am still very happy with Rust since I am more confident in the correctness of this code.
hmm sounds like a familiar situation
JAI dunno about that prediction
I think a little bit of custom CSS would go a long way.
I didn't read /u/koheant as trolling, I read him as concerned that the aggressive downvoting of comments made by /u/ae-cto is unbecoming of the community. Which I agree, it is.
It's all open source anyway so it's not like they can't figure out the method either way. It's basically public info no matter how it's implemented But the point is that, even if they tweak their algorithm, it would still keep them from typosquatting a name that is very close to the original name. It doesn't prevent all typosquatting, but prevents the ones that might easily be mistaken for the original crate
JAI is purpose built for gamedev. It will be superior to Rust, C++, or Swift. there's big overlap between gamedev and the needs of 'systems-programming' (it's no accident gamedev uses C++). I doubt they'll push JAI outside , but it's not inconceivable that it could be used in other fields. As gamedev is such an important niche for C++ , it seems worth bringing it up here. I like to mention gamedev because manny people think Rust is good for gamedev (and are experimenting) but when you compare to JAI and look at the philosophy behind it, you'll see Rust isn't necaserily ideal there. I present my thoughts in more detail in this thread: https://www.reddit.com/r/GraphicsProgramming/comments/6wfrsa/graphics_programming_in_d_or_rust/
Such a channel already exists and I believe it does just use `Serialize`: https://github.com/servo/ipc-channel
It's been a while since I used C, but that's probably because you're trying to declare a function `double` -- `double` is a builtin type in C. 