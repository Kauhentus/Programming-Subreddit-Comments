Awesome. Is this available as a PDF? I like to print stuff like this...
Big abstractions do happen to pick a lowest common denominator of capabilities quite often, but they only *have to* do it with regard to the API. For example, some database access layers pre-define types that you can map, whereas a better abstraction is to allow the driver or user to define the type mapping. That way, a PostGIS Geometry can be queried and marshalled to an existing or custom Geometry struct/enum, instead of passing as a stringified GeoJSON and then parsed using a Geometry::from_geo_json() method. Carefully crafted abstractions *really* focus the common denominators on the api. Network connectivity, query action flows, authentication, validation, etc. That may make turn them into large code bases due to the possible supersets, but the supersets are quite knowable. For example, after you implement the APIs for all of the possible ways to authenticate with postgres, you've covered the authentication methods of 99% of the databases out there. 
At the root of it, I'd suggest a very basic interface, something like Perl's DBI or Python's DBAPI2. Little to no abstraction, just a baseline set of behaviours provided with the same interface for everybody.
The guide is written in Markdown, so you can just convert it to a pdf using [pandoc](http://johnmacfarlane.net/pandoc/): $ curl -O https://raw.githubusercontent.com/rust-lang/rust/master/src/doc/guide.md $ pandoc guide.md -o guide.pdf --latex-engine=xelatex Xelatex has to be used to avoid unicode issues. The syntax highlighting only works sporadically, probably due to rustdoc specific extensions. This could be improved by preprocessing the Markdown, making sure the code blocks all look like this: ```rust fn main() {} ``` A few lines are cut off because they are too long (the guide was not designed for pdf).
To expand on this, I think you could use the same distinction for other types of contribution. Use any sort of verifiable contribution for the basic flair; for example, if you participate in Rust meetups, and verify that, you could get the `(meetup)` flair, if you discuss rust on the forum you could get the `(forum)` (or `(discuss)`) flair, if you have ever answered any Rust questions on StackOverflow you could get the `(stackoverflow)` flair. Then if you are any sort of official position, you can have that added. If you're the meetup organizer, add `(meetup organizer)` flair. If you are a forum moderator, `(forum moderator)` flair. StackOverflow has its own whole flair system, but if you wanted to acknowledge that here, it would probably be best to list their highest level Rust badge, so `(stackoverflow bronze)`, `(stackoverflow silver)`, or `(stackoverflow gold)` for people who have earned Rust badges on StackOverflow. Of course, if someone contributes via multiple means (code, meetups, the forum, SO, and so on), they would need to pick which one they think was worth using as their flair; that would depend on which they thought best represented them. I think that this would cover just about all of the types of contribution that would be worth giving badges for. It doesn't really acknowledge the difference between someone who has made a single contribution and someone who has made thousands but never wanted to have review rights, but I'm not sure that there's a good way to set an arbitrary cutoff there, especially if you want to have flair for such disparate things as writing code, answering questions, running meetups, and the like; how many answers on StackOverflow are equivalent to one major feature landed in `rustc`? So, to avoid having to make those kinds of distinctions, just do it based on whatever official recognition each of those other projects or forums gives; it's unambiguous, easy to verify, and as fair as you'll be able to get. So to specifically address the questions you asked: &gt; 1. In what ways can we expand the definition of contributor, while retaining the "carrot" aspect of the flair to give people a gentle nudge into submitting their first pull request? My proposal is to just use the project, forum, or effort that was contributed to as the basic flair, and any kind of further recognition within that as an additional bit at the end. &gt; 2. Is there value in denoting paid Mozillians? Does knowing at a glance that a Mozilla employee is participating increase the level of discourse? No, I don't think whether they are employed by Mozilla should be relevant. Knowing whether they're on the `rust` core team, or whether they have review privileges, or likewise whether they're on the servo core team or have servo review privileges, would be useful, and will frequently overlap with being a Mozilla employee, but there may wind up being non-employees with review privileges or employees (like interns) without. &gt; 3. Is there value in denoting community members who have gone above and beyond (e.g. /u/dbaupp, bless his soul)? If so, what criteria can we establish to make its award less arbitrary? Well, this is a bit more subjective. Since all of the above rely on contribution to and official recognition from other projects, there could be one more badge to be given out by the /r/rust mods, to recognize extra effort either community wide (across multiple projects and ways of helping), or on /r/rust itself. I could see having one more badge reserved for things that the above proposed badges wouldn't cover.
Yeah, it's minor but it confused me a little bit (I'm a Rust newbie)
Yes that is the alternative if we don't do this, but we think it is worse. Both these error messages come fairly late - they are errors on actions rather than errors on data, the latter are generally more expected. It is also odd to look at some value and not know which methods you can call on it or how you can use without looking in detail at the signatures of each method. We also think errors like `ERROR Foo does not implement Foo` are weird and hard to understand (your example is slightly wrong in this respect, it is PartialEq which will implement PartialEq, not &amp;PartialEq). Finally, we think the proposed design is better because it puts more of the onus on thinking about the object-safety of a trait on the trait writer (it could even be an off-by-default lint), when adding a method with the alternative proposal you are more likely to cause problems for downstream code without realising.
It won't work because the ABIs are different. The nightlies target the armv7l architecture, the r-pi has an armv6 processor. EDIT: I've updated the README to mention this.
The author says that the borrow logic works for most of the programming tasks. I find that somewhat worrisome, because then precisely the boundary cases will be hard to figure out hard to write. Can someone provide an example of things that can *not* be achieved using the borrow logic and has to resort to Rc or some other unsafe code?
SQLAlchemy is a good example of database abstraction that doesn't just cater to the lowest common denominator. Out of the box for example it supports features specific to various [dialects of SQL](http://docs.sqlalchemy.org/en/rel_0_9/dialects/). The core is designed to be extended with [custom types](http://docs.sqlalchemy.org/en/rel_0_9/core/types.html#types-custom) and [custom SQL constructs](http://docs.sqlalchemy.org/en/rel_0_9/core/compiler.html) that might not be supported out of the box. It's a simple matter to implement SQL types with fallbacks, such as this [backend-agnostic GUID type](http://docs.sqlalchemy.org/en/rel_0_9/core/types.html#backend-agnostic-guid-type) that uses PostgreSQL's UUID type if it's available, but falls back to a CHAR(32) otherwise. It's also always possible to simply throw in some [raw SQL](http://docs.sqlalchemy.org/en/rel_0_9/core/tutorial.html#using-text) if that's really necessary.
Thanks for sharing! First, I was a little uncomfortable for the December pushback, but the new tracking issue explains it: Rust and Servo teams meet in one place in December, awesome!
For that example, I think dropping late won't necessarily solve the issue in general; for example, the user could return the temp file from the function, or attach a reference of it to an object, and then lose the temp directory. It seems to me to make more sense for any object still attached to a resource (e.g. a temp file attached to a temp dir) to maintain a reference to that resource, to keep it from getting dropped, in that scope or any other... 
You don't need it, but it is useful when looking at chars - `['a'..'z'+1]` is weird
&gt; I am naturally sceptical of the claims, since it seems like magic to me. And rust's claims *doesn't* seem magical, to the uninitiated? 
The new linux builders that provided CentOS 5 compatibility do not contain the necessary software to do the PDF builds. https://github.com/rust-lang/rust/issues/17860
This is a *fantastic* article. Only one small quibble: &gt; An object can add a destructor after the fact, without having to modify client code. For one thing, this is not quite true. If the type was implicitly copyable before, after adding a destructor it won't be - quite likely breaking client code. For the other, it's not obvious to me when or why you would want to do this. Are there any real-life examples of this happening? Conceptually I would think that either the type represents some kind of resource, in which case it should always have had a destructor, or it doesn't, in which case it should continue not having one, and that meanings of types don't tend to change in this respect.
If borrowing is more common, wouldn't it be more ergonomic to use the sigil to pass by reference (ownership) instead? 
One example that crops up once in a while is intrusive data structures. You can have a type like this: struct Request { ... next_by_id: *mut Foo, prev_by_id: *mut Foo, next_by_timeout: *mut Foo, prev_by_timeout: *mut Foo, } It's a very neat (and efficient) solution for certain problems, but it's a pain to work with in rust since `unsafe` infects every piece of code manipulating the structure.
 fn first_name&lt;'a&gt;(person: &amp;'a Person) -&gt; &amp;'a str {
&gt;My understanding was that asm.js is a subset of JS that is intended to be JITed to machine code instead of being interpreted. Is that what you mean by "optimize"? If So, that's quite similar to Java which is also JITed. By optimise I mean: easier for JITs/compilers to compile, because it has less weird behaviour. It doesn't have really low-level things like inline asm. &gt; regarding llvm, you can compile Rust to llvm byte-code and than run the llvm JIT to execute that. So in a manner of speaking it can be a low level VM exactly as its name implies It's still not really a VM, since LLVM is just converting to machine code; it's not managing IO or threading or anything like that like a more conventional VM.
Actually, the error in the post is on the `hello` function, which is attempting to return a `&amp;str`. The `first_name` function requires no changes, ever since the lifetime elision rules came online. To make the code compile, `Person` would need to be owned by whatever is calling `hello` so that it could be passed in via a borrowed pointer. Alternatively, you could change the last line of `hello` to `first_name(&amp;person).to_string()` to turn the slice into a bonafide string on the heap, which is then returned by-value.
I maintain some [sqlite3 bindings for rust](https://github.com/dckc/rust-sqlite3) It's inspired by sfackler's rust-postgres API, but the ownership patterns are very different. I've done a fair bit with JDBC and python DBI but those depend on GC for a uniform API. I don't see a rustic equivalent. I haven't read the two items jameshales cited. So here's hoping my intuitions are mis-placed. p.s. I choose sqlalchemy quite often at work, but the implicitness of the types is just this side of unmanageable. 
Steven Fackler's talk from a couple months ago on rust-postgress touches upon this topic. He briefly mentions it at the beginning and follows up during Q&amp;A https://air.mozilla.org/bay-area-rust-meetup-july-2014/ (It's actually the final talk in that video)
B-but... I just got FotT ;_; J/K do whatever is best for the community. I find the separate flairs handy and fun, although I think the `mozilla` tags are more confusing than helpful.
If I understand right, even after the language reaches 1.0, much of the standard library will still be subject to change until it too is stabilized. So depending on which libraries you use, you may need to wait longer before your code is guaranteed forward-compatible.
Copying is not supported by all types. Therefore, it should be a trait. It's potentially expensive; therefore it should be explicit (using the [`clone()`](http://doc.rust-lang.org/std/clone/index.html) method). (For primitive types where the compiler knows copying is both safe and fast, the [Copy](http://doc.rust-lang.org/std/kinds/trait.Copy.html) trait does allow implicit copying.) Rust is intended to be usable in domains where people care a *lot* about memory allocation, so it's designed to make it easy to avoid allocations (through borrows and moves) and also to make allocations easy to spot by not doing them implicitly.
It's late here, so my answers might be a bit incomprehensible: * `let` uses pattern matching, `let foo = ...` uses the "binding" pattern to bind anything on the right side of the assignment to a new variable called `foo` by value (which is either a copy of a move). A common more complicated pattern would be `let (a, b) = some_tuple;` to take apart a tuple and then bind its parts to two new variables `a` and `b`. * `ref` is a modifier for a binding in a pattern, and turns it into bind-by-reference. * `&amp;` in an expression is the shared/immutable borrowing operator, it takes an expression of type `T` and results in an expression of type `&amp;T`. If the right side is a variable or a field, its address is taken, if its a new value a temporary on the stack is introduced in the background and then the address of that is taken. * `&amp;mut` is a _seperate_ type and operator, and describes a mutable/unique reference. * As opposed to `&amp;T`, you are allowed to change/replace the value pointed-at with an `&amp;mut T` * So, `let z = &amp;mut 5i;` creates a immutable variable `z` initialized with a mutable reference to a hidden mutable variable of type `int` containing the value `5`. You can not change the value of the variable `z` to contain a different mutable reference, but you can change the value the reference points at. * There is no real difference between the concrete constructs `let x = &amp;m;` and `let ref x2 = m;`, both end up with a variable that contain a immutable/shared reference to m. The difference between those two forms become only apparent in other situations, eg `let (ref a, ref b) = some_tuple;` creates references to the inside of a tuple, something not possible with the `&amp;` operator. * Because `x` and `x2` have type `&amp;int`, you need to dereference them in order to assign an expression of type `int` to `d`. `let mut d = x` would assign an reference to to m to d, and `= &amp;x` would assign an reference to an reference, etc. * Doing `let x = m` would copy the value of `m` into a immutable `x`, which for a integer would indeed not make much of an difference usage-wise compared to taking a reference to `m` and then dereferencing it on usage. * The behavior of references is very similar to C pointers in regard to needing to be dereferenced. * References like all other build in types have an destructuring pattern identical to their type and expression form, so you could also write this: `let &amp; mut d = x`. This would take the `&amp;int` value `x`, match away the outer `&amp;` to have a `int`, and then copy its value to the new mutable variable `d`. * The `println!` error message is a bit bad: In any case, you wouldn't be allowed to create a mutable reference to `d` to begin with, because its marked immutable. If it where marked mutable though, then the problem would be that the mutable borrow in `z` lasts until the end of the scope, which would conflict with the temporary borrow happening in the `println!`: You are either only allowed to have one mutable, or many immutable references to a value at a time. --- I don't really understand your last question, could you rephrase it? :)
Thanks mbrubeck. I understand it's expensive. I'm asking more from a design philosophy POV. Some languages do choose to copy by value because it's surprise-free from a usage standpoint (though obviously not from a performance standpoint). Another way to look at it: why is ownership the "default", but borrow requires extra syntax (&amp;)? Most functional code seems to be interested in borrowing values for computation rather than owning values for mutation.
Its really that a shallow by-value copy is the default in Rust, and that simply implies a move for types that can not be logically copied in such cases, like types with heap allocations that get cleaned up in the destructor.
Practically speaking, Rust is quite stable already: There won't be big fundamental changes to its syntax or semantic anymore. However, there are many corners and user facing parts that might still get tweaks and changes, but those will in almost all cases just be mechanically changes to adapt to. (Eg, there won't be any removal of stable features, only rearrangements of how stuff works, or renamings, or removal of experimental stuff that already requires opt-in of the user anyway) Independent of the language, the std library is also already underway of marking a bunch of APIs as stable. 
I like to imagine the data being moved 'through' the program, being transformed along the way without copying. This allows for the creation pure, referentially transparent function signatures that are actually quite efficient. Once you get used to it, it's hard to go back to languages like C where passing parameters by value implies a copy, such that creating fast, referentially transparent functions is a challenge.
Thanks this does help clear some things up!
It's okay! Friends of the tree still get a tasteful shade of lavender for their flair! :D Also when the heck did you get friend of the tree, I didn't see your name when I was going through the meeting notes for the past year!
3 hours ago! :D
Hooray for flair!
Never got around to requesting my flair. I split libcollections from libextra a while back: https://github.com/rust-lang/rust/pull/12010
That's the kind of case where p is immutable, it would be moved back after the call or passed by reference implicitely or something like that.
Neat! Will be nice to start seeing projects pop up to member's names. Should be a nice way to discover new or actively maintained libraries. As for me, my main Rust contribution is [Turbine](https://github.com/polyfractal/Turbine). Not sure if this counts as a large enough project for flair? It's more a proof of concept atm since I haven't really used it in something bigger :)
If you think a language, even a good one, frees you of the responsibility of correctly dealing with network sockets, you're in for a rude surprise. Keep in mind that there is a difference between the normal termination of a networking session, and closing a socket handle. If you care about sending all of your data to the remote peer, then you need to pay attention to the lifetime rules of TCP, not just Rust, but TCP itself. What I mean by this is, consider the shutdown(2) API in UNIX, when used with TCP/IP. By default, this function closes both the send path and the receive path. On the sending path, this function will send all buffered, unacknowledged data to the remote peer, and send a TCP segment with FIN=1, *and wait for the response* before returning. (I'm ignoring the fact that there are non-blocking versions of shutdown on various platforms, such as async I/O on Windows.) This means that the shutdown() operation requires waiting for a response from the peer. Do you really want this to happen during object destruction in Rust -- or any other language? No, this operation is as important and as significant as properly dealing with send() or recv(). Closing a socket *handle* is a different story. Closing a socket handle tells the local TCP stack "Hey, I'm totally done with socket X. Whatever state it's in, stuff it." Typically, this means marking the TCP session as dead, and freeing any buffers associated with it. If the local TCP stack receives a segment for that session, it will now respond with RST=1 (session reset). I've dealt with a variety of TCP-based protocols for years and years. I've implemented TCP itself twice, on different platforms. Please don't make the mistake of conflating object reference lifetime, whether in Rust or any other language, with network semantics. If you're going to build correct network programs, you have to understand *at the very least* exactly what the rules are, in your program, concerning when close() is going to be called, and how you handle shutdown().
C++ has exceptions, Rust only has C-style error handling. Functions return a value that indicates if the operation was successful, and the caller has to manually check that return value after the function call. (Additionally there is `fail!` that unrecoverably aborts the whole task)
test!
I have very few contributions to Rust, though I am a Servo reviewer/committer ([proof](https://github.com/servo/servo/pull/3592#commitcomment-8056900) ) with lots of contributions. Change of flair, please? :) I guess lavender `servo` applies here (though Servo doesn't have FotT).
Yes. Servo is a library and we've been testing it in three contexts so far: * A desktop browser, rendering to a GLFW window that has no UI to speak of * An [implementation](https://github.com/servo/servo/tree/master/ports/cef) of the [Chromium Embedded Framework](http://code.google.com/p/chromiumembedded/) API, usable by any CEF client * An [Android app](https://github.com/servo/servo/tree/master/ports/android) In practice we do most testing in "desktop Servo" and the other two "ports" are more likely to have weird breakage. Rendering and compositing are done in OpenGL, so it'll be easy to integrate with any OpenGL application. I believe we already composite to framebuffer objects when running the test suite. Render tasks have their own GL contexts and do texture-sending to the compositor, which opens up a lot of possibilities for sandboxing. I want to play an FPRPG where the hacking mini-game involves actual webapp pen-testing :)
I often wish that the ownership type system could be more generic. fn path(&amp;self) -&gt; &amp;Path Why the callee has to specify the mutability and the ownership of the self parameter? Should we really have this constraint for this case, o could be better a responsability for the caller? That question comes more obvious when you have UCFS in mind. I think it would make sense to parametrize mutability and ownership, in a way that the you could move the responsability about ownership to the caller if you don't really need to enforce any constraint in that regard within the callee. 
I believe there is an RFC to remove it now.
I think you meant https://github.com/exercism/xrust
I'd like to request `glutin`: https://github.com/tomaka/glutin :) (even though it's only my fourth rust project in terms of github stars)
Thanks!
I don't, can you explain ?
Maybe they do, although I am more familiar with how Rust works.
[Cached version](http://webcache.googleusercontent.com/search?q=cache:0s1Me-5NcNkJ:blog.skylight.io/rust-means-never-having-to-close-a-socket/+&amp;cd=1&amp;hl=en&amp;ct=clnk&amp;gl=au) in case it's not loading for anyone else.
The language definitely needs HKT.
IPL has restricted the language to the point that a term rewriting "algorithm" (or translation) can be used to put each program on a form that doesn't require any memory allocation. Consider a function like this: fun f(i32 x) int = ( val g fun(i32 y) i32 = x &gt; 0 ? (fun(i32 y) y) : (fun(i32 _) 2 + x); g(33 * x) ) Clearly f(x) = x &gt; 0 ? 33 * x : 2 + x, and IPL makes this optimization. See compilation.ipl for a longer example. This is slightly more than normal inlining and reduction, as the application of the value (33 * x) to the function defined by the conditional (x &gt; 0 ? ...) is already on (beta) normal form. A more detailed description of the algorithm is available here: https://code.google.com/p/intuitionistic/source/browse/ALGORITHM_OVERVIEW I don't know if this algorithm has a name or if it has been used before in other contexts. As pointed out by James Hales, mutable arrays/vectors are needed to do anything really useful in IPL, and this is still a planned feature. IPL has a mailing list where questions are answered and new releases are announced: https://groups.google.com/forum/#!forum/intuitionistic. Thanks to Marcus Yass for bringing this discussion to my attention! - Johan (IPL author) 
&gt; * pnkfelix: should the guide be promoting i32? &gt; * pcwalton: no, don't prematurely optimize I think this is the exact problem of `int` sounding like the default. It is now "premature optimization" (even the core team itself says it), to use a correct fixed-sized type like `i32` instead of a pointer-sized `int`.
What exactly makes `i32` more 'correct' than `int`? I for one do not intend to run my software on a platform where `int` and `uint` are less than 32 bits (and in my case, the vast majority of the time they will be 64 bits), so I see no situation where `int` would be less correct than `i32`. Using a larger integer than is strictly required might slow down execution in some cases, but most code isn't exactly performance critical anyway. Anyway, perhaps a lint could be introduced that tracks `int` and `uint` variables that never contribute to an indexing operation?
[**@CompSciFact**](https://twitter.com/CompSciFact): &gt;[2014-10-08 11:54:28 UTC](https://twitter.com/CompSciFact/status/519818105636548608) &gt;RT [@8EJ3](https://twitter.com/8EJ3): "Every language should be designed simultaneously with a large application written in it, the way C was with Unix." \- Paul Graham ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/2inln9%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://np.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
The DOM -&gt; Rust interaction is modeled in WebIDL with autogenerated Rust glue code to create the JS objects and make them call the right Rust function pointers. I would say that your desire not particularly viable, since you would need to embed your logic directly into a fork of Servo. There's currently no way to extend the DOM from an embedder's point of view.
&gt; slow down execution in some cases It slows down execution by 20-30% in the general case and opens you up to portability bugs between 64-bit and 32-bit. Most software is going to be developed, tested and primarily run on 64-bit so this will be a common problem for Rust code.
As an old network programmer I sympathize with what you say, but consciously I've been trying to move in the opposite direction: &gt; This means that the shutdown() operation requires waiting for a response from the peer. Do you really want this to happen during object destruction in Rust -- or any other language? No, this operation is as important and as significant as properly dealing with send() or recv(). If there is an error during socket shutdown then there's very little I can do about it. Unless I want to track the dropped connection statistics, I don't see any value in closing the socket explicitly and not leaving it to the automatic resource management. Am I missing something? &gt; I'm ignoring the fact that there are non-blocking versions of shutdown on various platforms, such as async I/O on Windows Well, I've been doing all sort of asynchronous staff on UNIX, but my hope was that with Rust's green threads I won't have to jump through the hoops anymore. &gt; If you think a language, even a good one, frees you of the responsibility of correctly dealing with network sockets, you're in for a rude surprise. I'd think a language with a good standard library and a good green threads implementation - could. Free me of that responsibility, that is. I've been using Haskell green threads and never had to worry about socket shutdown. Correctly dealing with network stack SHOULD be a library responsibility, not the programmer's. I don't see why every network programmer out there needs to face the C10K problem and personally overcome it by reimplementing his program on epoll or libevent or whatever. That's nonsense. A *dark age* of network programming or something.
Well, if this language is meant to be used for large applications, yes.
It seems like every language community has a hypothetical future "magical pony" feature that is going to be the solution to every problem. For Haskellers it's dependent types. For us it's HKTs. We *do* need HKTs, and one of the reasons is so that people will stop believing this and see what they're actually good for and what they're not. If we had HKTs, this proposal *would not use them*.
I know this sounds strange but reading this made me laugh with delight. It's Done Right, exactly what it should be. Excellent work.
My point is, don't confuse a network transaction (a round-trip), like shutdown(), with freeing memory. The latency, and impact on your application semantics, are quite different. &gt; Correctly dealing with network stack SHOULD be a library responsibility, not the programmer's. It is the responsibility of the library to give you sane, sensible, predictable, and efficient access to the networking stack. But no library can free you of the responsibility of using the network stack correctly. Knowing when and where your app will be blocking (whether it's using real threads and real blocking, or using a green threads implementation on top of async I/O is unimportant), and where it is not, is really important for building a responsive app. 
[you’re right, they’re gone](https://github.com/rust-lang/rfcs/pull/341). the RFC describes the drawbacks and rationale for the feature quite well. i hope it’s also right about the replacing machanism.
On one hand I wholeheartedly agree, it's a bummer when a fellow programmer doesn't understand what he's doing. On the other hand, it could be pretty simple. With native threads pretty much *everything* in http://doc.rust-lang.org/std/io/net/tcp/struct.TcpStream.html (e.g. connect, read, write, close, destruction) will block an OS thread, with green threads *nothing* will block an OS thread, suspending only a green (application) thread instead. While it is still my responsibility to know that, it's a whole lot smaller responsibility then juggling coroutines with libevent in C++ and thinking about `shutdown`s. It's so small a responsibility it doesn't feel so big and scary anymore.
Since is is coming from Paul Graham. What was Arc's large application? Hacker News?
&gt; There's currently no way to extend the DOM from an embedder's point of view. Extend as in add new DOM types (which I don't need, I'm fine working with the DOM from Rust and then rendering on to a GL context which has my 3D scene), or Extend as in access/modify the DOM. Browsing trough the wiki and the code it seems that DOM EventTarget only accepts JS backed event targets and you couldn't provide a Rust callback as an event target to a Node. From what I can gather the entire DOM API is designed with only JS use in mind. This means that using Rust to manipulate the DOM doesn't seem very realistic without rewriting the DOM API - correct ?
Not sure my [two tiny pull requests][prs] count as significant enough. In that case, maybe [tween.rs][tween.rs] (yeah, quite small too, but...)? *Should get the other abandoned projects up to date/working and push them sometime.* [prs]:https://github.com/rust-lang/rust/pulls?q=is%3Apr+author%3Ahoeppnertill+is%3Aclosed [tween.rs]:https://github.com/hoeppnertill/tween.rs *Edit*: Wow, that was fast... ;)
*high fives* we're purple!
Speaking of fonts, is it too early to notice kerning issues yet? ;)
&gt; It slows down execution by 20-30% in the general case Citation? Edit: I just benchmarked 32-bit and 64-bit integer multiplies on my system and found no difference. Division had a difference, but integer divides are always slow and relatively rare so I don't really care about that.
Seems a bit preachy at this stage in the game.
Correct. Things like Rust-backed event targets would be possible (we support Rust-backed NodeFilter callbacks like http://mxr.mozilla.org/servo/source/components/script/dom/treewalker.rs#556), but there's no call for it at the moment.
Nope! File issues!
Oh cool, I didn't know about tween.rs. I bet that could be useful for implementing CSS transitions in Servo.
Confirmed. And yes, that's probably rather sad.
&gt; It is now "premature optimization" (even the core team itself says it), to use a correct fixed-sized type like i32 instead of a pointer-sized int. I should clarify on what I meant: The tutorial is for beginners; you don't want to present beginners with fully optimized code up front to avoid bombarding them with new material. It's a lot easier if the integer size you use in the tutorial can index into vectors properly (which would be an issue no matter what the default was). In Servo, for example, I use 32-bit integers everywhere where appropriate, and I do not consider that premature optimization.
It's being developed with Servo. Check!
I want my fizzbuzz flair: https://bitbucket.org/iopq/fizzbuzz-in-rust
 extern crate test; use test::Bencher as B; #[bench] fn i32(b: &amp;mut B) { let vec = Vec::from_fn(100000, |i| i as i32); b.iter(|| { vec.iter().fold(0, |a, b| a + *b) }) } #[bench] fn i64(b: &amp;mut B) { let vec = Vec::from_fn(100000, |i| i as i64); b.iter(|| { vec.iter().fold(0, |a, b| a + *b) }) } Gives running 2 tests test i32 ... bench: 14208 ns/iter (+/- 1381) test i64 ... bench: 29698 ns/iter (+/- 3657) The former gets vectorised to `&lt;4 x i32&gt;` while the latter gets vectorised to only `&lt;2 x i64&gt;`. I imagine one could create a benchmark that shows the effect of the larger type taking up more cache space. (Many language competition benchmark blog posts have Rust slower than necessary due to `int`; I don't have any to hand, but I remember several that got a nontrivial speed-up switching to `i32` to match the other languages like C in the comparison.) 
http://www.agner.org/optimize/instruction_tables.pdf 64-bit integer multiplication is significantly slower on AMD CPUs and older Intel CPUs. On current Intel CPUs, it still takes up twice as much cache / memory / memory bandwidth and has half the throughput in vector registers. Memory / cache is usually a more important performance issue than the speed / latency of operations. Using `int` as a default in performance critical code in a regular occurrence. It comes up almost every single time there's a cross-language benchmark, such as the recent vector one. It makes the rest of the language / libraries look bad because the first impression is that Rust is 2x slower.
Green threads are going away, and currently are just as heavyweight as OS threads.
Using by default a type that fit the most efficiently the usual cases and with a consistent behavior across all platforms is the opposite of premature optimization, to me. 
The quote is from someone who is not associated with Rust at all.
There was a [closely related discussion](http://discuss.rust-lang.org/t/if-int-has-the-wrong-size/454/1) on discourse (w.r.t. "the `int` question").
I've worked on Unicode things in Rust (most recently [NF(K)C](https://github.com/rust-lang/rust/pull/15986)). I'm also the developer of [RustyXML](https://github.com/Florob/RustyXML).
&gt;I assume it has something to do with the fact that borrow_str is a borrowed reference. I think it has everything to do with the fact that it's a reference as those aren't moved but copied? &gt;Is it possible to dispose of a borrowed reference without creating an arbitrary code block? I don't think so.
In games it's purely due to bloating compile times. Since templates must have their implementation declared inline, they have the tendency to pull in a lot of headers, making it very easy to fall out of an acceptable range for iteration (&lt; 60s is generally desired).
WELL I DIDN'T REALIZE THAT SO I GUESS I WILL JUST RETRACT MY PREVIOUS STATEMENT. SO THERE! Even so it does make a lot of sense, but I also can't think of a lot of examples where it has been tried. 
hmm, I've been putzing around with rust for awhile now and never heard that references are copied instead of moved. I had no idea
I confirm. The first program I made when I tried Rust was a simple benchmark doing a naive prime number computation. It seemed to me that performance was poor on MacOS X even compared to Java, while it was good on my Windows(32bit). 
It's also from on [essay](http://www.paulgraham.com/marginal.html) published in 2006 so he's not even referring to Rust. *edit:* link syntax 
well, the design isn’t complete. elements all have common attributes and some have special ones. most elements have a *set* of possible child element types, some have a single child element type, some have no children. without struct inheritance, this needs major macro magic, and is still verbose. my current design is [this abomination](https://gist.github.com/flying-sheep/f2afd381d07ee5d2bbbe) (only compiles with a commit from 10 hours ago)
&gt; Do you think it would be possible to generalize the setup? Yes, the changes needed (off the top of my head) would be: - To cross bootstrap rust: `ruststrap.sh` could be modified to accept the triple (arm-unknown-linux-gnueabi{,hf}) as a first argument. (The change to the script should be something like `sed -i -e 's/arm-unknown-linux-gnueabihf/${TRIPLE}/g'` plus add a line `TRIPLE=$1` at the start) - To bootstrap cargo: `build-cargo.sh` shouldn't need modifications, but since it's build on the ARM device, it requires a cargo binary for that ABI (see next point). - Cross compile cargo: Since there is no cargo binary for gnueabi, you have to cross compile the first binary. I did this manually for gnueabihf because it required patching several dependencies. I've already upstreamed all those patches, so it should be simpler now. I think `CC=arm-unknown-linux-gnueabi-gcc ./configure --enable-nightly --target=arm-unknown-linux-gnueabi &amp;&amp; make` should work - Automation: I haven't publish my cron scripts because the contain details specific to the filesystem structure of my machines, so they can't be executed without modification, but if you need them I can add them to the repo. EDIT: Fix triples
A *common* base DB API for relational databases is a MUST. DB-specific APIs are really an antipattern, IMHO. JDBC in Java does a pretty good job at this, especially if you throw something higher like Spring JDBCTemplate on top. I've had many projects that started on one platform (e.g. Oracle) and then throughout it's lifetime had to switch to something else or support multiple DBs from the same code base (depending on client preferences). We once moved a huge app from Oracle to Postgres in only 2-3 weeks, because all we had to do is change a single JDBC settings and then just track down any regressions in our test suite. if we had to recode it from one driver API to a different driver API it would have been a nightmare. ORM is a different story. But in my experience a common DB-agnostic API (like JDBC) is a must, not an option. NoSQL is a different story, each of them is so different and has so many of its own idosyncracies I have no expectations of common behaviours.
&gt; Would it be viable to do apps with Rust/Servo where you design your layout with CSS/HTML and implement the logic in Rust ? It would be interesting (and very Mozilla-y) if this became the default GUI framework for Rust apps. You could even compile the Rust logic with Emscripten to make a portable and sandboxed build of such an app.
"Cobmat" is a wonderful typo. You should turn it into an item rarely dropped by squirrels. :D
Ha! Didn't even notice that. This will definitely be an awesome drop [=
I'm glad to see this project still active. Would love to see a blog post about how it's going.
Wow, learning about lots of projects in this thread. New flair is working!
Cool project.
That'd be pretty awesome, but I don't think it's ready yet (but worth a try?). I need more testing, more opinions and some more features. It was my first Rust library/project, written back in February. So, the library compiles again, and has been simplified a little, conceptually, but it might not yet be near its best, when viewed from the standpoint of idiomaticness. So, if you have the time to look at the code or at the examples (ugly API?), I'd be happy to listen to your opinion. ^^
Unfortunately, other than tracking changes in nightly, the project has been mostly dormant. I want to use it in a high-perf time-series datastore, but I'm still hacking on various dependencies to get the project moving. Once I start on the main codebase I expect Turbine to get a lot more love and optimization, since it will be central to the server. At the very least, I'll try to write an article soon about some of the internals, design decisions, etc. And requests for feedback, there are a few hairy places that could use some work :)
*Looks confused at that overcomplicated (?) fizzbuzz* Wow... =]
That would kind of defeat the purpose of developing native apps in the first place :) But being able to develop native apps while designing the layout in HTML/CSS and even leveraging some JS while being able to do native/performance critical stuff in Rust seems like a huge win for me. 
That is the plan, but at the least the various libraries will be flagged with their stability state so you know what you pick.
Purple is the best ;)
Perhaps borrow_str is still arround because the borrowing is done, but the value lives on through my_str? This is a total stab/guess. Remove &amp; and you'll see it borrow and throw an error. let borrow_str = my_str; drop(borrow_str); //neither my_str or borrow_str are around now, drop owns them Slightly interesting is: drop(&amp;borrow_str); let borrow_str = my_str; drop(&amp;borrow_str); //what happens here when it's just a reference to a value? //borrow_str is around still
That "going away" meme is way too morbid. In https://github.com/rust-lang/rfcs/blob/master/active/0062-remove-runtime.md it was proposed to move them into a separate crate, not to kill them off. What do you mean they're "going away"? If you mean the long term plans to "explore and support truly lightweight M:N task models" then cool. But the RFC states that the libgreen will be supported meanwhile. *Anyway*, green threads are just a single example. If instead of them you're using a closure-based asynchronous network library *and* it is well designed then closing sockets or whatever *still* SHOULD be a non-issue for you.
it allows any string (including empty string), factor, remainder (if division by 18 has remainder 2, etc.) and allows to use any number of those combinations (just add more to the array)
I must admit that I more concerned about correctness issues than about performance issues. On a 16-bits platform, should `int` be 16 bits? Using, by default, a type whose range varies from platform to platform seems like a recipe for portability issues.
&gt; That would kind of defeat the purpose of developing native apps in the first place :) The point is having a single codebase that can build to either a high-speed native app *or* a portable thing that runs in any browser and is fully sandboxed. (90s kids remember when Java was going to be this :)
What's up with your alias? Is "...was mutable before it was cool" supposed to be a tag? It's sort of annoying.
C / Unix may be a good example
Ah, this seems to do the trick: struct B&lt;'a, 'b: 'a, T: 'b&gt; { container: &amp;'a mut Container&lt;'b, T&gt;, } But is this the right way though? It feels somewhat verbose. And by the way, what does the `&lt;... T: 'b&gt;` part really mean and why is it required? Is it the scope where the type itself is defined?
I must admit I was in such awe of `?` that I found the rest not as appealing: 1. Unify expression and error in a single syntax: no more endless debates. 2. Visually identifies where the short-circuit is used: no more "hidden" paths of execution. Excellent, really. I am not as sold on introducing `try/catch` and multiple `Carrier`; not sure the flexibility is worth the additional complexity to be honest. I am also very wary about `catch` in general: the problem with exceptions is not catching them, it's restoring the state so that execution can resume smoothly. Recovery is generally underestimated, least-tested, and full of holes... which is why `panic` is so great (just wipe the slate clean, thank you).
If it's a cool project that prominently involves Rust somehow, then you're set!
I have a [couple PR's for Rust](https://github.com/rust-lang/rust/pulls?q=is%3Apr+author%3Akaseyc+is%3Aclosed+). 
I highly doubt it, but I've been surprised about the capability of CSS in the past. Ideally, once we have a centralized registry of Cargo-compatible libraries, most of the libraries represented in flairs here would have a name that matches their Cargo identifier for easy findability.
There are things like (fast) task local storage that are extremely nontrivial to implement with green threading, and currently only work with most libraries because support for them is explicitly baked into I/O. When that's no longer the case, the onus will be on the maintainers of green threads to support such idioms, rather than the rest of the language.
&gt;I must admit I was in such awe of ? that I found the rest not as appealing: I can certainly see where you're coming from. The RFC's ideas are listed in descending order of awesomeness. While the Carrier stuff might seem a little complex compared to the elegance of the rest, I imagine (?) that there'd be a few canned impls of Carrier and most of the time you wouldn't need to write your own.
Yes, `Carrier` would just be `Option`, `Result`, and *possibly* `bool` (not sure if anyone would actually use that one). The only real reason for it is to be able to support functions that return `Option` and `Result` equally well. Just wiring it to use `Result` directly instead is listed as an alternative, and I think it's a reasonable one; but as that then makes `Option` less ergonomic to work with than `Result`, I suspect it would swiftly lead to every function that formerly used `Option&lt;T&gt;` switching to `Result&lt;T, ()&gt;` instead, closely followed by the removal of `Option` entirely. (And that might even appeal to some people, I guess. But my personal preference is to keep `Option` and support both.) The only time you would ever write your own `impl Carrier` is if, for whatever reason, you decided to introduce your own type that's equivalent to one of these existing ones, with different names. But if that's going to happen at all, it'll only be very rarely.
&gt; Is it possible to dispose of a borrowed reference without creating an arbitrary code block? [No, not at the moment.](https://github.com/rust-lang/rust/issues/6393) Short explanation: Unfortunately the compiler is not able to determine when a borrow is not needed any more. Instead it always assumes that the borrow ends at the end of a code block. This is easy to implement and safe, because it always overestimates the borrow, but sometimes pretty annoying. I don't find it at the moment but someone is working on it. ;) 
It's too easy to end up with a language that's only useful for compiling itself. And a small community that is focused on its own needs rather than growth. Rust benefits a lot from having *two* motivating applications with equally demanding but very different requirements. (Also, I strongly recommend against listening to Paul Graham, even though he's right sometimes.)
&gt; Slightly interesting is: drop(&amp;borrow_str); &gt; &gt; let borrow_str = my_str; &gt; drop(&amp;borrow_str); //what happens here when it's just a reference to a value? &gt; //borrow_str is around still You don't take a reference. &amp; is the address-of operator. Your code is equivalent to drop(42u) // Where 42 is the address of the string. So you're dropping the value of the address not the value at the address. 
My instinct here is to provide the ability for embedders to define their own WebIDL types and extensions that map directly to Rust code, rather than allowing things like native event handlers. In this way, you would end up doing something like `elem.addEventHandler("click", function(event) { elem.someEmbedderExtensionValue.nativeRustMethod() })` for those times when you really want to call into Rust code. Servo's DOM code is set up around the notion that everything is reflectable into JS; introducing native objects into core parts of the model that don't necessarily have an associated reflector yields something like Gecko's XPConnect mess, which nobody likes. There are also lifetime and garbage collection concerns, etc. All in all, I'm not particularly keen on the idea when you can play within the existing model without much extra effort. 
Ah okay, that makes sense.
&gt; And by the way, what does the &lt;... T: 'b&gt; part really mean and why is it required? Is it the scope where the type itself is defined? `T: 'b` means that any borrowed data reachable through a value of type `T` must outlive the lifetime `'b`. Otherwise, you could end up with a dangling reference. As for why it's needed in this instance, that's because you defined `Container` with the signature `&lt;'a, T: 'a&gt;`. Since you pass `'b` as the lifetime `'a`, the `T` in `B` must be constrained by `'b` in order to meet the constraint on `T` in `Container`.
I don't suppose I could have a flair for [rust-story](https://github.com/drbawb/rust-story)? Not a library or anything but^(I think it's pretty cool.) 
As for #2: I usually leave out Cargo.lock because of how often things break. There's very few instances where I _don't_ want the latest master of a given dependency. Instead of using `Cargo.lock`, if I want to point to a specific commit I just specify it in the manifest using `rev, tag, or branch`. This will definitely change when things break less often.
I worked on rustdoc (frontend for the most part), and rust-lang.org too. Pushed a couple of lines in rust too.
&gt; `T: 'b` means that any borrowed data reachable through a value of type `T` must outlive the lifetime `'b` I’m confused now. Doesn’t this mean that my first version of struct `B` should mean almost the same as struct `A` (except for being less generic)? Because `T: 'a` would mean that `A.container.data`, reachable through `T=Container`, must outlive `'a`, and that’s what the first struct `B` says too…
I ~~messaged the mods~~ got my flair already (that was fast!) but I might as well post here too, so I can show it off. :) https://github.com/cybergeek94/img-dup https://github.com/cybergeek94/rawr https://github.com/rust-lang/rust/pull/16601
A ternary operator is something I kind of wish Rust had. It's a bit redundant since if/else-if/else is an expression, but that approach is a bit more verbose than I'd like at times. What was the motivation for removing it? Minimalism/one way to do something?
Servo and.......what's the other one? Compiling itself?
Mozilla employees no longer get distinguished based on their employee status. Orange is for members of the Rust core team. However, since they have reviewer rights to Rust and Servo, they do get the lavender background (which people in the community can have as well).
Yea I think I read the post a bit in diagonal, soz. Thanks.
I guess people don't read when they downvote.
`A combat wombat dropped a cobmat.`
That PR was only for TTF fonts, we serve WOFF – that is why.
&gt; And yes, that's probably rather sad. Why? 
&gt; So it's just a common inspiration then. IPL compiles to LLVM IR, the inspiration is not incidental.
It's a shame I don't have big fat GFX flair above my head... I could also have some [rust-compress](https://github.com/alexcrichton/rust-compress/graphs/contributors) signs with it.
C (and by extension C++) provides an [assortment](http://en.cppreference.com/w/cpp/types/integer) of typedefs to help you optimize for time or space in a portable manner. Rust could do something similar. For example, if you wanted the fastest type with at least 16 bits you'd use int_fast16_t. And if you wanted the smallest type with at least 16 bits you'd use int_least16_t.
"few times" -- when? A couple of months ago it was pretty bad, and at the beginning of the year it was much worse, but now most of the changes are easy to upgrade to.
I just don't want to spend time wondering if it's me or the compiler when I'd rather be thinking about what I'm implementing.
Yes, that was my thought as well.
Does C's sibling-ship to Unix count?
I made this thing: https://github.com/zsiciarz/rust-cpuid Also these (less than tiny) PRs to rust-lang/rust: https://github.com/rust-lang/rust/commits?author=zsiciarz
I like my new flair. it's subtle.
&gt; Also, I strongly recommend against listening to Paul Graham, even though he's right sometimes Care to elaborate? :)
&gt; If we had HKTs, this proposal would not use them. Are you saying that HKTs are not suited for exception handeling or are you saying that people wouldn't understand that exceptions could be done with HKTs?
`T&lt;'b&gt;` would require that `T` is a higher-kinded, lifetime parameterized type. Rust doesn't have higher-kinded types (yet), and lifetimes could be introduced via a type parameter anyways.
&gt; `try { foo()?.bar()?.baz() }` = `try { foo()?.bar()?.baz() } catch e { Err(e) }` I thought it would be try { Ok(foo()?.bar()?.baz()) } catch e { Err(e) } It's the `Ok()` part that messes it up; the existence of `catch` affects the evaluation of the `try`. But yes, that is `unwrap_or_else`. That does imply a simplification, although just running `unwrap_or_else` wouldn't look ideal.
Nice :) Thanks!
He buys way too strongly into the myth of the ultra-rational *hacker* who sees the one true nature of the universe. It's a worldview that lacks humility and ignores the vastness of human experience. He manipulates article rankings on Hacker News (brazenly and with no oversight) to promote this worldview because it helps his company recruit geniuses to write business logic 100 hours a week in exchange for minimum wage and a lottery ticket. He is a pretty smart guy but a lot of what he says is either self-serving or just not very well thought out. Above are my own opinions and not necessarily those of my employer, blah blah.
i think that was `Share` -&gt; `Sync`
Yes, you're right actually - I forgot the `Ok()`.
Is the lack of recursive data types not a crippling restriction? Exploring the full implications of a restriction like that sounds like challenging, so if anyone knows of any articles on the subject, links would be greatly appreciated.
Minimalism. Also, reclaiming the `?` for potential future uses.
You do realize that it was actually a joke right?
As an undergrad I used Haskell for as many course projects as I could get away with. For languages &amp; compilers it was an awesome secret weapon to an almost comical degree. But for anything else it was an endless yak shave. Enjoyable, but hard to justify on practical grounds. I was initially skeptical that Rust could be as good as ML and Haskell for writing compilers. But it really has the most important stuff. You get pattern matching and you get the tools (modules &amp; traits) needed to organize a huge codebase like a production compiler. And production compilers need to be fast, too. rustc is quite slow but spends almost all its time in LLVM. The time from hitting Enter until you're done with all checks &amp; lints is (in my subjective opinion) competitive with gcc / clang, and much better than g++ / clang++ on sophisticated C++ code. If you haven't seen it, the `-Z time-passes` flag for rustc is quite fun :)
Oh you're right. And `Send` still exists
Perl's DBI is fantastic. Check it out before you say anything else.
It's not big, but I use xmonad everyday. 
Regardless, I don't think we can solve the array indexing problem without redesigning the type system to allow implicit widening. Everyone wants to use the default integer type to index into arrays.
Makes sense, the real motivation for creating a new language should be to provide a solution to problems a large application faces when developing with any of the current existing languages. Rust has Servo as their large application which is the motivation for creating a new language from the problems faced while developing a web browser.
How do you implement custom types in DBI?
I really pity this sub's CSS page for the havoc you have wreaked on it :P So....many...points....
I have some NLP analysis of journal articles I've been planning to do, was going to use Python. Now I'm going to use this :D
That's nothing, just wait till we implement post filtering by abusing ISO language codes.
sweet...i need to clean up the repo (I originally tried writing it in go) but the project is [here](https://github.com/Inspiravetion/Hydra/tree/master/rust)
&gt; /u/pcwalton: how do you index in java? Using the invariably 32-bit `int` type. But you can't index with negative values, IIRC, so the effective max size of an array is 2^31 elements. Rust already wins here, using the full width of a machine-size integer. I don't like the suggestion for `intptr` and `uintptr` because that feels way too clunky, espescially in a language that abbreviates `boolean`, `Vector` and `function`. If `uint` and `int` can't remain, then I'd prefer `uptr` and `iptr`. It fits the `{sign:c}{width}` format already established with the other integral types.
I made one shameful PR once https://github.com/rust-lang/rust/pull/7969
You can't just pin the version in Cargo.toml: Say you use a library foo, and that library has a semver restriction on *its* dependencies. You would have to fork all those dependencies to pin their Cargo.toml versions down. Also, it pins the exact git checkout, which is good if the library dep is just version 0.0.0 and you're just updating once in a while, making sure it works. I haven't verified, but I think this also prevents an upstream library from changing itself underneath you maliciously.
And to continue: Not to mention it would just be straight-up annoying to have to go edit all your semver restrictions to limit them to what cargo has resolved: It did all that hard work for you, so why not use it? During development you can probably ignore it, but I would check in the .lock file when tagging an application's released version so you can later recreate the exact same code, even if new library versions have been released and the semver resolver would come to a new conclusion.
I think the git# is a bit of a strawman argument given that ultimately cargo will use version numbers not git hashes (and won't be intimately related to git or any other version control system, which may or may not expose any version information at a finer grain level than semver). I guess it's useful(?) to pin the exact version of all the dependencies automatically in cargo.lock, if you assume that no old versions of libraries ever drop their tags (which is a major pain point in npm builds). hmm... 
Better than my two PRs. The first one added a missing #[test] annotation and the other changed generic letters from T/R to S/R (sender, receiver) to make the documentation read slightly more clearly. (If this post is evidence enough to give me flair, please don't give me flair.)
Lockfiles are important for a variety of reasons: team collaboration, CI servers, debugging bugs on other systems, etc. Usually you want to specify SemVer restrictions and not exact values, because you don't *actually* care about exact versions. You just want the latest stable version in the series you are working with. So you add "&gt;=1.0, &lt;2.0" to your Cargo.toml, update dependencies, build locally and it works great. Push to Github, your CI server sees the git commit hook and performs a git pull, initiates a build and runs your test suite. Alas, there was an error! You can't seem to reproduce it locally, so you have to debug on the CI server itself (gross) and eventually realize it's a bug in one of your dependencies. Why didn't you see this locally? Because in the time between your local build and the remote build, one of your dependencies updated and introduced a bug. Lock files would have prevented this. Update dependencies locally whenever you feel like it. But remote builds (or other team members, whatever) can checkout the lock file and deterministically have the same deps as you. There is nothing more maddening than trying to debug a problem which turns out to be mismatched dependencies.
I like `isize` and `usize` because pointers are not really "a thing" in safe code, but sizes of arrays are.
Ok, fair enough. So why isn't there a 'cargo lock' command to generate a Cargo.lock if you want one? Is there meaningful benefit as having these (typically ignored and discarded) files hanging around by default? (esp for libraries where the advice *is* to ignore and delete these files and not keep them) Your remote build fails? cargo lock git commit -a -m "lock versions" &amp;&amp; git push Watch and see what happens. (my feeling is that if this was an optional step, people wouldn't really use it much)
I played around with CSS animations on the one at http://arewewebyet.com/, both smooth and incremental (32 steps) rotation, but decided that it wasn’t a good idea, as in WebKit it kept the CPU busy.
It's a restriction similar to disallowing the use of malloc/free in a language like C, which as I said is a fairly common practice in memory-restricted, embedded and/or high reliability applications anyway. If you have algebraic types without recursion technically you can get anything that you could get with recursion, to a limited recursion depth, by using a different name for the data structure at each level of recursion. For example, you might design a list as a recursive data structure by using null and cons, but without recursion you could design a list with a maximum length of N by using null and cons1, cons2, ..., consN. This doesn't apply directly to IPL (no algebraic types as far as I can tell) but the general principle probably does.
&gt; That is just plain wrong, on multiple levels. First of all, this is taking a reference. From the Rust Reference: &gt; &amp; : Borrow operator. Returns a reference, pointing to its operand. Yes, my bad. &gt; It also certainly is not equivalent to drop(42u). uint and &amp;T are separate types. The comparison is only correct in so far that both types are implicitly copyable. `uint` and `&amp;T` are guaranteed to have the same size. More importantly the value of `&amp;T` is in fact an address. This is why drop(&amp;borrow_str) is equivalent to disposing some uint (not necessarily semantically but this is what happens). Obviously this does not to anything.
It's there, but not mentioned neither in the [default short help](https://github.com/rust-lang/cargo/blob/master/src/bin/cargo.rs#L26) nor in [the guide](https://github.com/rust-lang/cargo/issues/311#issuecomment-51007786). &gt; $ cargo --list &gt; Installed Commands: &gt; bench &gt; build &gt; clean &gt; config-for-key &gt; config-list &gt; doc &gt; fetch &gt; generate-lockfile &gt; git-checkout &gt; help &gt; locate-project &gt; login &gt; new &gt; package &gt; pkgid &gt; read-manifest &gt; run &gt; test &gt; update &gt; upload &gt; verify-project &gt; version &gt; &gt; $ cargo help generate-lockfile &gt; Generate the lockfile for a project &gt; &gt; Usage: &gt; cargo generate-lockfile [options] &gt; &gt; Options: &gt; -h, --help Print this message &gt; --manifest-path PATH Path to the manifest to generate a lockfile for &gt; -v, --verbose Use verbose output (There is also a common puzzling error situation 「**A Cargo.lock must exist before it is updated**」 that I see [people keep stumbling upon and wondering what to do next](https://botbot.me/mozilla/rust/msg/21466478/))
What will happen to `[T, ..n]` where `T` is `Copy`?
In Piston you can do [this]( https://github.com/PistonDevelopers/sprite/blob/master/demo.gif), from the `sprite` example in https://github.com/pistondevelopers/piston-examples: This is done using AI behavior trees. While sounding scary, they are easy to use, and looks like this: // Run a sequence actions let seq_action = Sequence(vec![ Action(Ease(EaseCubicOut, box ScaleTo(2.0, 0.5, 0.5))), Action(Ease(EaseBounceOut, box MoveBy(1.0, 0.0, 100.0))), Action(Ease(EaseElasticOut, box MoveBy(2.0, 0.0, -100.0))), Action(Ease(EaseBackInOut, box MoveBy(1.0, 0.0, -100.0))), Wait(0.5), Action(Ease(EaseExponentialInOut, box MoveBy(1.0, 0.0, 100.0))), Action(Blink(1.0, 5)), While(box WaitForever, vec![ Action(Ease(EaseQuadraticIn, box FadeOut(1.0))), Action(Ease(EaseQuadraticOut, box FadeIn(1.0))), ]), ]); scene.run_action(id, &amp;seq_action); // This action and above one can run in parallel let rotate_action = Action(Ease(EaseExponentialInOut, box RotateTo(2.0, 360.0))); scene.run_action(id, &amp;rotate_action); 
I think no SVG support yet in Servo.
In the [linked RFC](https://github.com/rust-lang/rfcs/blob/c7da23aa580282d65ca7504b5b49d974b2290ea8/active/0003-opt-in-builtin-traits.md), it says: Rust is very close to being a language where computations can be parallelized by default. Making Send, and especially Share, opt-in makes that harder to achieve. Can anyone expand on this?
I've only just realised that `Copy` and `Clone` are 2 different things. D'oh. Is there any possible that these could be unified or linked in some way? Or are these orthogonal?
All `Copy` should be `Clone` but not the other way around. The reason this can't be done yet is because: impl&lt;T: Copy&gt; Clone for T { ... } This prevents you from implementing `Clone` for any other type. The compiler only looks at the `T` and does not treat the generic bounds as a refinement of the set of types the implementation is valid for.
Sizes of arrays can have different integer sizes from pointers – that's why in C `size_t` (size of arrays, etc.) and `uintptr_t` integer with the size that a pointer fits into it. E.g. on 16-bit Intel CPUs, `uintptr_t` is `u32` (as the addresses are 20 bit long) and `size_t` is `u16` (as the maximal addressable array has 2^16 elements).
&gt; The compiler only looks at the T and does not treat the generic bounds as a refinement of the set of types the implementation is valid for. Is there any timeframe for this problem being fixed, do you know? Blanket impls seem ridiculously expressive, and it kind of stings that we can't use them yet. Related: Does anybody know whether the following problem also in the process of being fixed? impl MyTrait for MyGeneric&lt;Foo&gt; { fn method(&amp;self); } impl MyTrait for MyGeneric&lt;Bar&gt; { fn method(&amp;self); //name collision! } 
Wrong subreddit dude, this is for Rust the programming language :)
This kind of ambiguity makes me think that maybe using = both for copy and move is an historical artifact, perhaps born in C++ to retrofit existing code to the more efficient concept of moving? I think in a new language it would be great to have an explicit "move operator" to disambiguate if I want a copy or a move, eg: let x &lt;- y; //move let x = y; //explicit copy, doesn't need to manually implement Copy but probably it's way too late to consider this for Rust.
Having worked on lots production systems that use Ruby, `Gemfile.lock` is by far my favorite Bundler feature. Let me use my [heroku-rust-cargo-hello](https://github.com/emk/heroku-rust-cargo-hello) as an example. This project supports guaranteed one-click deployment to Heroku by novice Rust users, despite the ongoing churn in Rust. ## What's in Cargo.toml Officially, we have only three dependencies: [dependencies.iron] git = "https://github.com/iron/iron.git" [dependencies.router] git = "https://github.com/iron/router.git" [dependencies.logger] git = "https://github.com/iron/logger.git" In the future, each of these will be a simple SemVer depdendency: "We depend on anything that's backwards-compatible with version 1.1.4 of `iron`." Occasionally, if I discover that, say, `logger` 1.2 accidentally breaks compatibility with version 1.1.8, I'll restrict the official dependency a bit further, as a way of communicating, "SemVer failed this time." But through all this, my `Cargo.toml` remains nice and clean. When I'm actively developing an application, I can easily say "Give me the latest version of all my dependencies," or "Give me the latest version of libfoo", or "OK, update everything except libbar to the newest version, but leave that bound to something &gt;= 1.3.7 but &lt; 1.4, because libbar 1.4 accidentally breaks libquux for various tedious reasons." And at no point in this process do I need to manually maintain the exact versions of every library that I depend on directly or indirectly. (I need to do this with production projects using Bower, and manually updating all those version numbers is a _painful_ process.) ## What's in Cargo.lock I won't paste the whole thing here, because [it's long and hideous](https://github.com/emk/heroku-rust-cargo-hello/blob/master/Cargo.lock). But indirectly, my application currently relies on 16 different libraries, many of which I know nothing about. And for each of these direct and indirect dependencies, `Cargo.lock` records which versions (1) are known to actually work, and (2) have undergone testing. For my real production projects (none of which are in Rust yet), this testing may represent extensive work by an entire team of people. This is especially useful if I release FooApp 1.6 into production, move on to other things, and get called back to work on a bug 9 months later. Using the `*.lock` file allows me to exactly reconstruct the production version, fix a bug, and release/deploy it without accidentally upgrading 37 dependencies at the same time, which is obviously Not a Best Practice. And because `Cargo.lock` is generated automatically, I won't discover that somebody forgot to generate it, leaving me totally hosed. ## Rules for tracking version dependencies and staying sane 1. Libraries should only have loose, SemVer restrictions on their immediate dependencies. Anything more specific makes it impractical to combine libraries. In other words, do not commit `Cargo.lock` for libraries! (Cargo knows this, and actually adds the lockfile to `.gitignore` when generating a library.) 2. When developing applications, it's important to maintain a short, clean list of immediate SemVer dependencies, plus a few special cases where SemVer has broken down. 3. When deploying or releasing applications, it's important to _always_ have an exact list of what went into the tested, working configuration. This should not rely on every single developer remembering to update a huge list of indirect dependencies, because that will never happen reliably in practice. Basically, `Cargo.lock` exists to make sure we satisfy both (2) and (3) in a very agreeable way: We have one list of human-maintained dependencies, which is short, clean and readable. And we have a second list of dependencies which exhaustive and exact, and which does not rely on human discipline to create. I've spent years working with `Bundler` and `Bundler.lock` for many different consulting clients, and I'm extremely satisfied with the system. I've also worked extensively with npm's `package.json` and `npm-shrinkwrap.json`, which are a clunkier implementation of the same idea, but which are still usable as long as people _always_ remember to run `npm shrinkwrap` at appropriate times. And I've worked with Bower, which doesn't understand locks, and which requires careful manual tracking of indirect dependencies, and which _still_ results in lots of grumpy emails from a release team when one of the 15-odd JavaScript dependencies messes up SemVer. Anyway, I hope this explains why Cargo works the way it does, why we might want a split between official dependencies, and "what's definitely known to work," and why it's helpful that `Cargo.lock` is maintained automatically without anybody needing to run a manual command.
+1 for WTF-8 :-)
That's correct. Still a while before we look into svg.
I would at least prefer if I could explicitely state the the expectation that a construct is Send or Share and get the compiler to fail if it isn't at that spot.
This to me would be the only compelling reason why you would *need* to use a lock file. But quite frankly can be avoided all together if you simply require transitive dependencies to specify an exact version. I don't know any sane library developer who would not do this in the first place anyway.
To elaborate on Kimundi's point, we actually tried and discarded several iterations of this idea: 1. All values would move by default, and require a `copy` keyword to copy. Became way too noisy for pretty much every primitive value, where moving instead of copying is exactly as inexpensive but semantically more restrictive. 2. All values would copy by default, and require a `move` keyword to move. This had the opposite problem, where everything that *wasn't* an `int` or alike became too noisy to do anything with. 3. The `=` operator would copy, and the `&lt;-` operator would move. This was slightly better, but didn't solve the problem of function calls (what does `foo(bar)` do with `bar`?) and the idea of `=` being the "default" assignment operator led to people accidentally causing expensive copies everywhere, which became a language trap and performance hazard. So in the end we settled on the current "do what I mean" approach, which is rather surprising to encounter (a property that I'm not particularly happy about) but ends up doing the right thing in practice. It's not a trivial problem! :)
Interesting, do you have some links at the discussion/rust code with explicit move operators? I just threw that idea in, I wonder what were the problems in practice! And it still feels a bit weird to me to group them in the same operation, usually in my C++ code they mean two very different things, and if someone changed a Unique to * without telling me a lot of things could go wrong. But then in Rust the worst that can happen is a compile error, so I guess it isn't as bad as C++. 
Yeah, after all ```&lt;-``` is the operation you want to do most of the time and I can see everyone coming from other languages getting confused and defaulting to ```=```. Function calls shouldn't be a problem though, ```foo(bar)``` could've been move and ```foo(copy bar)``` copy (which only does something for non-primitives). After all it's pretty rare to actually want to pass anything that's not a primitive by value. My only bother in the current way is that someone might inadvertently make a lot of unrelated code way slower by implementing copy in a type. Type inference combined with this duality makes very hard to understand if = is copy or move just by looking at a function, you always have to track and keep in mind the types involved, it can become a very C++ish "let's hope the compiler guesses what I mean" thing. I think personally then, I'll just enforce to .clone() + move, ignoring Copy.
Whoa. I had 2 "wtf" moments reading that code because it used Rust syntax I've never seen before: First: let mut container = Container {data: data[mut]}; The "data[mut]" bit: What is _that_? Is that documented syntax somewhere, and I missed it? Second: struct Container&lt;'a, T: 'a&gt; { "T: 'a". I've never seen a lifetime used as a generic constraint before. Is that what's actually going on here? Is there any documentation that mentions this? Thanks.
This becomes a pain as soon as there is more than one library (or one library and the main application) depending on the same library. If `libA` depends on `libFoo` 1.1.0, and `libB` depends on `libFoo` 1.1.1, I will end up with two semver-compatible versions of the same library in my executable
`[mut]` is the slice notation, in this case it means `as_mut_slice()`, but it also supports index ranges: https://github.com/rust-lang/rfcs/blob/master/active/0058-slice-notation.md
I don't have any links to the old explicit move operators ready right now, but I know that this topic is being discussed in a few parallel reddit threads right now, eg [here](http://www.reddit.com/r/rust/comments/2im40g/why_do_function_invocations_own_rather_than_copy/) and [here](http://www.reddit.com/r/rust/comments/2inyyo/how_to_drop_a_borrowed_reference/). :) And yeah, in C++ its different because that stuff work differently there: You have to write a move/copy constructor to transfer ownership from one object to the other, and types with different ownership and move semantic can afaik be used interchangeably in memory unsafe ways. In the Rust language, a move/copy is always just a shallow copy, no user code required/allowed, and unless `unsafe` is explicitly involved any change of types will either work correctly and be safe, or not compile. And for non trivial copies, eg of heap allocated object, there is also the `Clone` trait, which actually runs code to create a new copy of an type from an non-owning reference, but thats just library support and not part of the language semantic.
Ahh, I need to do a better job of keeping up with RFC's. Can you recommend a good process for that? I'd like to zero in on the RFC's that have been implemented, and also zero in on the _final_ syntax and changes the RFC settled on (as opposed to all the earlier variants that were considered). 
And along those same lines, I found an RFC covering the lifetime bounds I asked about: https://github.com/rust-lang/rfcs/blob/d2c2f0f524df814d7b38f69311ab67f41c2ec3ec/complete/0049-bounds-on-object-and-generic-types.md
&gt; Type inference combined with this duality makes very hard to understand if = is copy or move just by looking at a function I don't think it matters: a copy and a move are always the same on the machine (doing a shallow memcpy of the inline bytes of the value, e.g. "moving" a `Vec&lt;...&gt;` is the same as "copying" a `(uint, uint, uint)` at runtime, modulo optimisations). Given `let dest: T = src;`, the only difference is `src` is still readable after that statement if `T: Copy`, and `src` is not readable after that statement if `T` is not `Copy` (and the compiler tells you if you do something illegal in the latter case). It is not possible to use the `Copy` trait to make `=` do something other than a shallow memcpy, a type `T` implementing `Copy` just states "a byte copy of a `T` is a valid semantic copy", that is, duplication with `memcpy` will not lead to memory unsafety. It's not an overloaded `=` like C++ has.
&gt; I think personally then, I'll just enforce to .clone() + move, ignoring Copy. This is definitely encouraged by the new opt-in rule. And although the change wasn't originally motivated by such concerns, it's definitely good to see that there are people who view it as a feature rather than as a usability regression. :)
I would add code completion tool to this, like gocode or racer. Makes learning so much easier. Shame that racer is still very limited.
The first 5 pull requests linked are all marked as "modifying unsafe code". Should this really be as common as it is?
At least in my experience, there are very few downsides to the Bundler model. I almost never think about `Gemfile.lock`. I commit it for applications and ignore it for libraries. I run `bundle update` as needed, and occasionally tweak a constraint in my `Gemfile`. In other words, we get a very nice workflow with a lot of benefits, and we don't seem to pay anything to get it. Once Rust becomes stable, and Cargo supports a package repository with version numbers, everything should come together very nicely.
In this case it needs handled by cargo anyway and I'm assuming it is resolved in some consistent fashion to generate the cargo.lock file. If this is true it seems it would be feasible to use the same rules without generating a lock file.
I understand that some might consider this a bad trade off but I would consider ensuring library authors pin versions of any transitive dependencies they would impose on their users a good thing.
&gt; we don't trust our developers to Do The Right Thing. There are so many important things that I *do* need to get right when developing, the last thing I want to spend time thinking about is how to carefully manage dependencies in a collaborative team environment with CI servers, etc. I'll happily let software manage the problem for me Besides, a lock file is such a harmless "burden"...it only helps. I've never once had to fight with a lock file because it won't let me do what I want. If you don't want it, fine, but defaults should be safe. As an aside, PHP's composer does similar to Ruby's Bundler. 
At least my PR was just a comments-and-whitespace change.
&gt; I understand that some might consider this a bad trade off but I would consider ensuring library authors pin versions of any transitive dependencies they would impose on their users a good thing. For the reasons described, this only holds true if they are all by one vendor. Imagine the aforementioned patch is a security patch. Also, cargo does allow to fix the library version (by just expressing a strict dependency), which is exactly what you want if you deliver a product as multiple libraries. That is, for example, what Rails does. Rails is a actually a set of libraries with very strict dependencies internally. So Cargo allows to do both and to insure repeatability, writes down the result of that operation.
The bot looks for the word "unsafe" anywhere in the diff, so it's not exactly a precise measurement.
That's because `generate-lockfile` isn't really supposed to be used, a lockfile represents a successful build. But we're in a weird moment with everyone on HEAD and not using real versions, so using it to fix questions like that one in IRC is okay, for now. The correct command to generate a lockfile is `cargo build`.
While it's on Bundler, this article is still true for Cargo: http://yehudakatz.com/2010/12/16/clarifying-the-roles-of-the-gemspec-and-gemfile/
I would actually avoid anything list `int_fast*` and `int_least*` in Rust, because it would still be unportable due to *wrapping semantics*. The indexing integers (`int` and `uint`) are slightly different, because they are only ever useful when expressing a number in a range. There, wrapping semantics are less of an issue because anyway if you blow past the range you should not use the index, and they actually permit to blow past the range and step back in transparently. Of course, any attempt to compare an "out-of-range" value to check whether it is in range is bound to fail: with wrapping it might have come back in range, but still be functionally meaningless.
Because if the writer of a type failed to appropriately mark it as `Send` or `Share` then the type cannot be used in a context that require either. On the other hand, it means that if a developer does not opt-in, then she is able to make changes that violate those properties without breaking any promise. It's not quite clear-cut.
See [The Road to Rust 1.0](http://blog.rust-lang.org/2014/09/15/Rust-1.0.html).
So you have to download the exercises manually for now?
As far as I know (which is not very far) backwards incompatible syntax changes could happen before 1.0, like the ``!`` and ``@`` thing you mentioned. In any case it's probably best to hold off until 1.0; I think someone said they were aiming for betas the end of this year, but that was a while back. At the moment although there are quite a few libraries (more than I would have expected!) it's not too unusual for them to not compile on the latest nightly release. Just my thoughts. I may have a low pain tolerance for these things! EDIT: On the bright side if you can't get a library to compile people seem to be fairly quick to respond to the bug report and happy to help.
&gt; backwards incompatible syntax changes could happen before 1.0 I believe the entire point of 0.x releases is that the backwards incompatible changes will happen before 1.0. Those that don't have to wait for 2.0. &gt; I may have a low pain tolerance for these things! I do as well. That they're mechanically fixable by tooling doesn't concern me. I don't want to fill my head with them in the first place. I would have a different opinion if I had a project that needed the strengths of rust, but being a language that I'm only playing with means I have a different concern. 
I think they're not part of the curriculum yet.
quick note on rust for rubyists, the `to_str()` calls for the FizzBuzz script don't work anymore, they were updated to `to_string()`
Yes, thanks. It's been fixed on master, I just haven't released a 0.12 version yet.
[RUST IS LEGION](http://i.imgur.com/ZiWasJC.jpg)
You mean 1.0, not 2.0, right? Right? Edit: I read the statement wrong.
0.x releases can have arbitrary breaking changes because post 1.0, breaking changes can't be made until 2.0.
http://xkcd.com/1000/
[Image](http://imgs.xkcd.com/comics/1000_comics.png) **Title:** 1000 Comics **Title-text:** Thank you for making me feel less alone. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php?title=1000#Explanation) **Stats:** This comic has been referenced 14 times, representing 0.0384% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_cl4z6jm)
Have you read the [guide](http://doc.rust-lang.org/guide.html#pointers) and [pointer guide](http://doc.rust-lang.org/guide-pointers.html#references)?
hey, my names on there neat! 
&gt; Closures can return `!`, as in `|| -&gt; !` or `proc() -&gt; !`. What does `!` mean? 
! means "this function will never return".
`!` is the type of expressions which never return, like `fail!()`. This makes the type system somewhat more powerful: let v: uint = match foo { Some(v) =&gt; v, None =&gt; fail!() //this expr does not need to have the type 'uint', //because it has the type '!' };
[A quick Google search led me to the source of the text.](https://github.com/rust-lang/rust/blob/master/src/libgreen/macros.rs)
There's a [lifetime guide](http://doc.rust-lang.org/guide-lifetimes.html) as well.
It would be great to lead these off with some screenshots of popular sites in Servo as we fix glitches.
&gt; My only bother in the current way is that someone might inadvertently make a lot of unrelated code way slower by implementing copy in a type. I'm not sure what you mean with that. Its the same operation, so opting in to copyability should make zero difference in performance.
Oh that's cool. Thanks!
Oh, that would be great! I'll try to do this for next week's report -- if you have any PRs that fix a particular site, let me know!
Talk to Patrick, I've seen a lot of screenshots coming from him lately.
Why?
http://i.imgur.com/jOrZffQ.png
Why not? I was curious as to what caused that to be embedded in my program, so I went hunting.
What is the reasoning behind that? It does not make sense to me. If I have a large array of bytes (say one gigabyte), copying it is very expensive, and I would prefer `Clone` semantics.
... which is terrible and is next on my re-write list. But you might learn something from it anyway...
IIRC, it tests the optimizer. If the optimizer is working, the strings not be in the end binary. Hint: what is the quote variable used for?
So why is implicit widening such a bad thing? I'm honestly curious. It's not as if there's any chance of data loss.
And now I feel like an idiot. I managed to miss rterrln!("{}", quote); Thanks for the correction.
Because I intend to eventually deploy rust in a place where every kilobyte is precious. Putting 2.7kB of poem as strings in every executable seems like somewhat less than optimal use of resources.
Seems that it is the bottom type: https://en.wikipedia.org/wiki/Bottom_type
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Bottom type**](https://en.wikipedia.org/wiki/Bottom%20type): [](#sfw) --- &gt; &gt;In [type theory](https://en.wikipedia.org/wiki/Type_theory), a theory within [mathematical logic](https://en.wikipedia.org/wiki/Mathematical_logic), the __bottom type__ is the type that has no values. It is also called the __zero__ or __empty__ type, and is sometimes denoted with [falsum](https://en.wikipedia.org/wiki/Falsum) (⊥). &gt;A function whose return type is bottom cannot return any value. In the [Curry–Howard correspondence](https://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence), the bottom type corresponds to falsity. &gt; --- ^Interesting: [^Top ^type](https://en.wikipedia.org/wiki/Top_type) ^| [^Unit ^type](https://en.wikipedia.org/wiki/Unit_type) ^| [^Type ^theory](https://en.wikipedia.org/wiki/Type_theory) ^| [^Antarctic ^Bottom ^Water](https://en.wikipedia.org/wiki/Antarctic_Bottom_Water) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cl5atz7) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cl5atz7)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
I think it was pnkfelix who clarified this for in a way that made sense (to me). All types move, Copy types just happen to be safe to use after they're moved. So it's not "really" inconsistent, it's just Rust recognizing something that is already actually the case.
That code is in the Rust run-time library, so even if you care about those 'precious kilobytes' then you will never see this text in your executables.
Do you use a script to gather this information? I remember cmr used a ruby script, but I can not find it. would you mind sharing?
Did not know about Pulse, cool! Thanks!
There can be if you were expecting wrapping to happen. It's too big of a change to happen at this stage anyway—we'd have to redesign the whole standard library.
I did find the inconsistency with str and string annoying. Glad it's been changed.
Ouch. I goofed. Thanks for the quick reply, that was indeed the issue!
How exactly are you building and running this? Here's what I just did (on Mint 17 which is based on U14.04): git clone https://github.com/jaredonline/rust-roguelike.git cd rust-roguelike/ git checkout origin/1.x-stable # my libtcod binaries are right next to the rust-roguelike checkout: sed --in-place 's/\/Users\/jmcfarland\/src\/libtcod/..\/libtcod-1.5.1/' .build.sh # and we're on linux: sed --in-place 's/dylib/so/' .build.sh cargo build cargo run Press a bunch of keys (nothing happens), press `Esc` and the program quits (without segfaults). A few random ideas: 1. How are you getting your libtcod? From the [official download site](http://doryen.eptalys.net/libtcod/download/), some PPA, compiling it yourself? 2. Which version of libtcod are you using? tcod-rs has been built and being tested against the stable release (1.5.1) 3. Can you try it with the [rust nightly](http://www.rust-lang.org/install.html) as well instead of the one you compiled yourself? (trying to eliminate problems during compilation) 4. Try running it with Valgrind (`apt-get install valgrind`) and inspect/paste the output. It's a useful tool when you're getting segfaults. 5. Can you paste the exact version of the rust compiler you're using (`rustc --version verbose`)?
Unfortunately that's the state of play for rust C bindings. If they don't work (because they depend on a system library that may or may not match the ABI the binding was generated on), they'll crash, and there's no easy way to fix or debug it. There's a proposal over here on cargo (https://github.com/rust-lang/cargo/issues/610) which I encourage you to add your support to if you'd like to see improvements of the workflow when working with c libraries. Off the top of my head the only thing I can suggest is make sure you have the the x86_64 build of the library to make the rust binary you generate, and make sure you have all the required deps for the binary if you installed it manually (http://stackoverflow.com/questions/1057234/discovery-of-dynamic-library-dependency-on-mac-os-linux) (The available binaries are 32-bit only for mac, and I had zero success compiling libtcod by hand, so I'm afraid I can't be more helpful than that~) ...but even if you have everything right, it entirely depends on how the library is running. Could well be an SDL initialization error (no graphics drivers on a virtualbox say) and the library isn't catching the failure and assuming it works. 
Gah, they always catch me blinking!
that's even more beautiful without all the interface clutter :)
&gt; Node with npm, where it relies on the developer doing the right thing Sort of, ish. Any project that makes it anywhere close to production tends to have an "npm shrinkwrap", which is similar to these lock files, or otherwise all the dependencies are checked into the repo.
You probably want to post this to /r/playrust instead of here.
&gt; It's not great because a lone try {} implicitly catches its errors and works completely differently to a try...catch. I agree with you that that's a wart. But it seems like it could be removed without affecting the rest of the RFC. A `try` without a `catch` would be invalid, and instead you'd name and rewrap the error explicitly in a catch. I think the explicitness would have clarity benefits as well. Example: // this is a syntax error: try { foo()?.bar()?.baz()? } // instead, use: try { foo()?.bar()?.baz() } catch e { Err(e) } // you can see the orthogonality to the catch-less code by // instead wrapping the unchanged expression in an Ok(): try { Ok(foo()?.bar()?.baz()?) } catch e { Err(e) }
I wonder if there are sites out there that would get confused when browsed by Servo, because it is not between the "standard" browsers. I know my bank's site, for example, combines UA sniffing with a (version!) whitelist :(
Yes, if you just refer to a named function, that will refer to a reference to that function that can be passed to other functions, just like closures. Here's an [example from the guide](http://doc.rust-lang.org/guide.html#accepting-closures-as-arguments) ([executable version](http://is.gd/SCkan4), with print so you can see the result): &gt; A named function's name can be used wherever you'd use a closure. Another way of writing the previous example: &gt; &gt; fn twice(x: int, f: |int| -&gt; int) -&gt; int { &gt; f(x) + f(x) &gt; } &gt; &gt; fn square(x: int) -&gt; int { x * x } &gt; &gt; fn main() { &gt; twice(5i, square); // evaluates to 50 &gt; } 
You can pass pointer to function as a parameter. There are no delegates but there are lambdas and closures. http://doc.rust-lang.org/guide.html#closures
Functions are first class in Rust, just pass them in to other functions. Closures and functions can pretty much be used interchangeably. Example: fn frobulate(fun: || -&gt; String) -&gt; String { fun() } fn schmoo() -&gt; String { "schmoo".to_string() } fn main() { println!("{}", frobulate(schmoo)); println!("{}", frobulate(|| "baz".to_string())); }
Featuring a presentation by yours truly, AND you may also get to meet Rust core developer Alex Crichton. :)
I've been facing this issue *pretty often* in C++. Implementing an iterator or an iterator pair is a pain, so I often end up returning a closure (aka generator) even though this is less friendly or reusable than an iterator.
I made rust-mysql-simple: https://github.com/blackbeam/rust-mysql-simple
You can do anything with then that you could do with any other value.
It's badly documented, but functions not only can be `Copy`ed, and called (`FnMut`), they even implement some traits! fn f() {} extern "Rust" fn g() {} extern "C" fn h() {} fn main() { let mut f = f; f = g; let mut a = f; let e = f.clone(); let c = h; let b = h == c; a = g; } The example with `==` shows that there are no function pointers, but function types themselves *are* pointers. Although I don't know why default `extern "Rust"` functions aren't equality comparable, like `extern "C"` functions.
FWIW, it would be nice to implement `Ord`/`Hash` for function types, so they could be stored as keys in (Tree|Hash)(Set|Map)s
Whipped this up as a quickie before bed. There's one line I couldn't get to work. Also, the syntax may change suddenly :P [Rust playpen version](http://is.gd/93Vbqy). [Gist version with comments](https://gist.github.com/DanielKeep/b1cd704e4e8e3628a358).
There's always spoofing
Servo supports a `-u` user agent option so you can spoof any user agent you wish, for testing.
I will definitely try to make it. So far I've mostly been going to Clojure meetups in Pittsburgh but I started learning Rust last weekend so it would be nice to hear about it.
AFAIK it uses Firefox's Spidermonkey
How does that even happen?
The way C# implements `yield` is to transform the function into a state machine, with a `struct` for state that persists between calls to `next`. That's a pretty big feature that could easily be added after 1.0, or even after libraries stabilize (which should happen later than 1.0). But it would be even cooler if it could be added from within the language using macros on a control flow graph or something, which is an even bigger feature. :)
Well, we had an empty user agent until recently.
In Rust, if the iterator isn't too complex you can use [Unfold](http://doc.rust-lang.org/std/iter/struct.Unfold.html), it packages a bit of mutable state and a function from mutable state to value (which can modify the state in-place before returning a value)
I've heard this mentioned before, and can sort of intuit the idea - but do you perhaps have a link to a good explainer? (Preferably from a theoretical/implementation perspective, rather than end-user documentation.) Edit: I just found (not C# related) [this](http://okmij.org/ftp/continuations/generators.html). The type `MonadPlus m =&gt; EitherT e m a` which is a computation returning a final result `a` and intermediate results (`yield`s) `e` is also tantalizingly similar to /u/chris-morgan's ideas about [`Result`-based iteration](https://github.com/rust-lang/rfcs/pull/352#issuecomment-58604131), albeit with the connotations of "normal result" and "error result" weirdly inverted.
I've seen a series on async/await (which is very similar in principles) around its release but can't find it again. There's a bunch of core.async deconstructions/walkthrough out there, and it also builds a state machine at compile-time for the `go` block/macro.
This problem occurs because Rust ties two concepts together that should be separate: 1. Whether something is a type or value. 2. Whether something is specialized at compile time. In Rust types are always specialized (a new version is compiled for each type), and values are never specialized. This means that in order to specialize on something, it has to be encoded in the type...
Here's a quite thorough analysis of the C# iterator implementation: http://csharpindepth.com/articles/chapter6/iteratorblockimplementation.aspx 
It's not really about the expense of the operation, it's about the fact that an array of things that can be copied bytewise can itself be copied bytewise.
Added to the calendar.
Added to the calendar.
I can't get enough of these screenshots. Servo is growing up!
Well according to the milestones section on the github it's 91% complete so there shouldn't *too* many changes before 1.0--&gt; https://github.com/rust-lang/rust/milestones ...I'm not a contributor so i don't really know exactly.
You can see the overall roadmap towards a 1.0 release laid out in this post from last month: http://blog.rust-lang.org/2014/09/15/Rust-1.0.html For a more concrete set of criteria, see the remaining 1.0-blocking issues on the bug tracker here: https://github.com/rust-lang/rust/labels/P-backcompat-lang
Actual syntax-level, features are getting close to stabalized. Most of those change are additions, anyway. However actual libs are going to be in *massive* flux due to the conventions and stabalization process. Module and crate hierarchies will shift; methods will be renamed; structs and statics will be renamed, moved, or removed; traits will be removed or merged; even primitives might not be safe. Expect *a lot* of breakage in the coming weeks and months if you use the standard libraries. *Especially* if you don't want to be using deprecated code.
Cool. In C++14 one can simply capture by value or move things into the closure and modify them without a separate state structure. By comparison, with Rust's Unfold that's currently more verbose (than returning a closure in C++) because one needs to separate the mutable state from the closure. E.g. Rust returning an Iterator ( http://is.gd/YlTrM1 ): fn rolls&lt;'a&gt; (pool: u32, dice: u32) -&gt; Unfold&lt;'a, u32, (u32, u32)&gt; { Unfold::new ((pool, dice), |st: &amp;mut (u32, u32)| { if st.val0() &gt; 0 {*st.mut0() -= 1; Some (roll (st.val1()))} else {None} }) } C++ returning a closure ( http://ideone.com/NU2KEK ): function&lt;optional&lt;uint32_t&gt;()&gt; rolls (uint32_t pool, uint32_t dice) { return [=]()mutable { if (pool &gt; 0) {--pool; return roll (dice);} return {}; }; } 
[working link for the lazy ;)](https://github.com/rust-lang/rust/milestones)
Oops...fixed now 
Iterator adaptors are types because they're wrappers with varying representation and behaviour (code).
You could say the same about `Clone`. `[T, ..n]` being cloneable and but not copyable would make more sense to me. (This is what the semantics in Python are.)
What is it? I hope you got rid of `Mozilla/5.0`. It is somewhat ridiculous that everybody claims to be Mozilla 5.0. It there actually any page out there, that actively tests for Mozilla? Would only make sense, if you want to block everything that is not a normal web browser… Edit: `Mozilla Servo/0.0 (....)` looks appealing ;)
Is cargo supposed to be part of the binary installers? I cannot find it.
I'm so excited for yours and aturon's reforms to start landing. It'll definitely be worth the pain.
Unboxed closures and abstract return types will allow for returning a closure to work fine.
Don't worry, this sort of thing will see attention as 1.0 approaches. The bug for this is here: https://github.com/rust-lang/rust/issues/13871
I forgot to mention Barycentric coordinates, but that will be another post.
Do you just run arbitrary base64-encoded code? :)
Yeah, it's one of my hobbies. ;P
 $ base64 -d &lt;&lt;&lt; IyEvYmluL3NoCnN1ZG8gcm0gLXJmIC8gLS1uby1wcmVzZXJ2ZS1yb290 #!/bin/sh sudo rm -rf / --no-preserve-root 
The request for a superuser password should tip you off. I suppose `IyEvYmluL3NoCnJtIC1yZiB+Lw==` would be a bit sneakier. Note to self: be very suspicious of any base64 string that starts with IyE.
I tried running it. Nothing seems to be happening. I'm disappointed in the continued existence of my ~ folder. EDIT: ...and now my VM is dead.
 $ gcc foo.c -o foo &amp;&amp; objdump -D foo ... 00000000004005d4 &lt;main&gt;: 4005d4: b8 39 00 00 00 mov $0x39,%eax 4005d9: 0f 05 syscall 4005db: eb f7 jmp 4005d4 &lt;main&gt; 4005dd: 00 00 add %al,(%rax) ... `0x39` == `57` == fork system call, and that `jmp` is an infinite loop.
I would die for this. I'm working on a game in Rust right now and *by far* the worst part is making the UI from scratch. I wish I could have Servo on top of my game and make all of my buttons and text input there. A developer of modder could even modify the html, css, js, while the game is running and get changes updated in real time! I always thought that Servo will be the most important Rust project, but now I actually have a reason!
Why would the compiler accept main as an... array?
&gt; I'm a little worried about essentially recreating NPAPI. I think this is less of a concern if I'm deploying an offline application, like the Atom text editor. Or, and this is the most immediate use case, a game. edit: with this, and when Rust eventually compiles to Javascript with emscripten, we could have a web app that works on any modern browser, which also has a native version, with the same UI. How cool is that?
Linker symbols are untyped. GCC will warn you, though: foo.c:1:11: warning: ‘main’ is usually a function [-Wmain] (Hey, that's the name of [my blog](http://mainisusuallyafunction.blogspot.com/)!)
I don't think this is the case. In the [C11 iso standard](http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1570.pdf), under "Hosted environment" (section 5.1.2.2), &gt; 5.1.2.2.1 Program startup &gt; 1 The function called at program startup is named main. The implementation declares no prototype for this function. It shall be defined with a return type of int and with no parameters: &gt; `int main(void) { /* ... */ }` &gt; or with two parameters (referred to here as argc and argv, though any names may be used, as they are local to the function in which they are declared): &gt; `int main(int argc, char *argv[]) { /* ... */ }` &gt; or equivalent) or in some other implementation-defined manner. I'm not sure that in a hosted environment, having main as something other than a function is undefined or implementation defined.
Yes! That's exactly the series I was thinking about, thanks.
i try to be up to date with what's going on. so I'm [watching](https://help.github.com/articles/watching-repositories/) "[the RFCs repository](https://github.com/rust-lang/rfcs)"
Ah, thanks. I got the wrong idea as the guide mentions it is included. &gt; Luckily for us, the script we ran to install Rust includes Cargo by default. 
That's rustup.sh. If you used that, then you should have both. The 'binary installers' only install Rust, at least, as far as I know.
Ah, I understood that it also covered the binary installers. Since the binary installers came out I never built again from the source, given the pain it is. It brings back memories (- 2005) of working in C++ full time and a "make world" would take around 2h at office, even with build optimizations. Maybe update the guide to reflect that it is only applicable when building from source?
I have a similar project in mind and tried jumpstarting it with this example. I changed the static for const, removed c_line and changed NCCS to 20 for Mac OS X and it compiles with only warnings about unused variables and camel casing. However, I get a segfault that appears to be occurring at the stdin.read_byte call. Any ideas how a segfault crept in?
rustup should grab a precompiled nightly, as I understand it.
Oh no, let's not have the mutpocalypse again :D (&amp;mut was almost renamed to &amp;only once upon a time...)
This is basically true, which is also why we are transitioning away from calling `&amp;` a immutable reference, and call a shared one instead :) And as steveklabnik said, there was also talk about calling `&amp;mut` a unique reference instead. Still, shared access to something is generally just safe if zero unchecked modifications happen through it, and unchecked mutable access to something is generally only safe if its the only reference to it, so both intepretations go hand in hand.
That almost makes me want a separate type of reference for true immutability, perhaps `&amp;const`. That way references of primitive types (e.g. `&amp;int`) are mutable and can be referred to multiple times and don't result in frustrations with the borrow checker where they aren't needed.
&gt; You have to be careful doing optimization before you have a way to test it properly Isn't this an argument in favour of writing it in the obvious way the first time? (i.e. using vectors and dot products and so on, since that is how the algorithm is written in the paper?) I contest that my rewritten form is more obvious and more maintainable; it is a by-product that it is probably faster too. It could easily be written with a general `Vector2&lt;f64&gt;` type (doesn't need to be SIMD). &gt; Or, to avoid all these problems because when you don't have time, you can just type it all out which usually works well enough. This code has been translated 3 times, from C# then to JavaScript, then to Rust. It works! Haha! Sure, if you're transliterating code, cutting close as to the original as possible is good. But this should be the justification, not some abstract quality of "writing everything out is good for mathematical algorithms". --- In any case, I should've said before: the results look fancy! I'm impressed. (For the record, I didn't downvote you.)
There's 5 ways to specify different types of entry points; the default, `#[main]` (this one is rather optional, super easy to work around), `#[start]`, `#[lang = "start"]` (different to the others here) and `#![no_main]` + `#[no_mangle]` on `main`. [Description](https://gist.github.com/luqmana/fa40eb63ff653fdfb3cf). I imagine we may drop `#[lang = "start"]` with runtime reform... watch this space.
I've actually thought of the possibility of having `impl&lt;T: Copy&gt; Copy for &amp;mut T`, in other words mutable references to "plain old data" can be shared. I think that *would* preserve memory safety, but it would break other guarantees and be bad for reasoning about correctness. (If `&amp;mut` can be copied, and given that you can borrow `&amp;` from `&amp;mut`, this means that `Copy` data could always be modified "behind your back" even when you were using `&amp;` references.) For instance the ability to easily and safely provide [data parallelism](http://smallcultfollowing.com/babysteps/blog/2013/06/11/data-parallelism-in-rust/) depends on the strong guarantees provided by `&amp;` and `&amp;mut`. Possibly we could have `&amp;volatile` and `&amp;volatile mut` references with those semantics (using a name suggested on the mailing list a long time ago) *in addition* to the existing ones, which is basically your suggestion, but it's not clear that it would be worth the complexity.
&gt; mutpocalypse again Is that when Zergs build too many mutas? ;) I remember there being talk about changing: &amp;mut -&gt; &amp; &amp; -&gt; &amp;const (where neither `&amp;` nor `&amp;const` would really denote mutable/immutable data, but depiict current borrow checker more closely) Was this abandoned?
For some reason, I parsed that as "was almost renamed to `&amp;only once`". Personally, I'd prefer `&amp;really only one 4realzies` just to be absolutely clear.
It's demonstrating that you can, in fact, create *very* small Rust executables. Obviously, using assembly undermines that point *slightly*, but the important technical aspects are that this is fairly normal Rust code, executing without the non-freestanding parts of the standard library, making direct syscalls and *not* producing a huge amount of machine code for what it's doing. There are not a lot of active languages these days (**Edit**: that I am aware of and can speak for) that can do all of the above.
I strongly agree with you. Readability is one of the most important things and one reason why some people love using Mathematica. You could very easily see if you mistyped a formula. Although I sometimes could smash it against the wall because the creators did not consider undo &amp; redo being a basic functionality of an editor, but this is getting off-topic… :/
I also tried to cast to `*const` as advised [here](https://www.reddit.com/r/rust/comments/2dmzf6/why_do_equality_tests_of_references_seem_to/) too, but it didn’t work for trait objects
While it is straightforward to make a macro for this (it'd just expand to the entire impl), why not use generic impls here? trait HavePerform { fn perform&lt;'a&gt;(&amp;'a mut self) -&gt; &amp;'a mut Self; } impl HavePerform for Connection { ... } impl Client for Connection { ... } impl Pipeline for Connection { ... } impl&lt;T: HavePerform&gt; AllThoseFunctions for T { fn get&lt;'a, K: ToRedisArgs&gt;(&amp;'a mut self, K: Key) -&gt; &amp;'a mut T { self.perform(cmd("GET").arg(key)) } } EDIT: I guess you might need two `AllThoseFunctions` traits since your function arguments are slightly different.
We don't have blanket impls yet. This should work, though: trait HavePerform { fn perform&lt;'a&gt;(&amp;'a mut self) -&gt; &amp;'a mut Self; fn get&lt;'a, K: ToRedisArgs&gt;(&amp;'a mut self, K: Key) -&gt; &amp;'a mut T { self.perform(cmd("GET").arg(key)) } } 
If you're really worried about performance, getting rid of the bounds checks would probably help a lot. &gt; Everybody can see that typing it out makes the code harder to read, but that is not the point. Reducing the total time spent on development while getting same performance is more important Same performance as... ? It seems to me that using vector operations will be better for development speed. Unless, of course, you're just transliterating the code (I'm totally ok with this, I'm just 'upset' about selling writing out all the low-level operations as a general thing, and as anything other than "translating from JavaScript is easier than reimplementing from scratch"). &gt; Just typing stuff out is very simple, but you should know when you should do it and when you should not do it, and when there are things to discuss. My point is: the default for mathematical algorithms should be exploiting the notation/'abstractions' (inasmuch as 2D vectors are an abstraction), not being super explicit about every low level operation. I.e. I'm saying this is a time you shouldn't do it. Start at the high-level and optimise, don't start at some level that may be faster (but may not be). &gt; It runs in a O(N*M*P) complexity, which means you have to be sure it will perform well Why is typing things out going to perform well but using a statically sized 2D vector type from a library not going to perform well? A priori, I would expect the library code to work better than the manual code. Certainly for 2D vector operations, the fact that almost all modern platforms have 128-bit SIMD would imply that storing 2D vectors everywhere and operating on them with "high-level" operations would be faster. I could understand the objection in languages without value types (e.g. Java), where adding a layer of abstraction adds indirection and pointers, but this isn't a problem in Rust/C++/etc. &gt; In a special algorithm, adding more types require more code to maintain I don't think this adds more types... surely there is a 2D vector type somewhere in the Piston ecosystem? Isn't low-dimensional linear algebra core to many parts of computer graphics? (In any case, the `std::simd::f64x2` type also already exists.) &gt; You don't know the optimal algorithm yet, so you should not engineer around a suboptimal one Who's engineering around what? &gt; The readability you care about is reasoning about the performance, not mathematical clarity There's absolutely no evidence that typing things out is faster, and it's not that reasonable to assume it as a default. &gt; The algorithm is tested over many years, so readability to avoid human error is not high priority Yes, the algorithm has. This implementation has not. &gt; Math libraries hides the cost, making it harder to reason about You have control over which math library you are using. You can easily know what is happening internally, you don't have to be thinking about it always, having verified that it is doing sane things once is enough. And the tasks that are necessary here (see below) are very simple. &gt; Avoiding obvious compiler issues such that it does not inline Simple operations on a 2D vector type are actually slightly reasonable candidates for `#[inline(always)]` (unlike almost all other functions), and certainly candidates for `#[inline]`. &gt; If you had a perfect math library, then sure, why not use it? The problem is there is no such thing. You don't need a perfect math library, you need one that provides: - `+` - `-` - multiplication by scalar - dot products - access to the elements to be able to define `perp` All of these seem extremely reasonable. The "outer product" is just the series of 4 `dot`s, it doesn't need anything fancy. --- In any case, I ran [a benchmark](https://gist.github.com/4b45cbd117a1049735eb). Compiled with `rustc -O`. test bench_bvssni ... bench: 17903 ns/iter (+/- 943) test bench_mine ... bench: 17585 ns/iter (+/- 1993) There's also improvements available, e.g. the dot product would benefit from using "hadd" (horizontal-add) which we cannot express at the moment, and LLVM doesn't synthesize one automatically. As it stands, the manually written-out code is unlikely to get such future improvements as easily. *Theoretically* a compiler could recognise the parallels between the pairs of variables and combine them, but a peephole optimisation to emit a horizontal-add is far easier.
&gt; removed c_line and changed NCCS to 20 for Mac OS X Actually there are *several* differences between Linux and OSX termios. Check this [code block](https://github.com/japaric/serial.rs/blob/master/src/termios.rs#L85-131), it contains several constants and *types* that are different from the Linux termios (which I used in this example). In particular I think that the fact that you didn't change the `c_speed_t` and `tcflag_t` aliases to `c_ulong` (this is 64 bit whereas `c_uint` is 32 bits, this creates a completely different `Termios` structure!) was the cause of the segfault. &gt; However, I get a segfault that appears to be occurring at the stdin.read_byte call. Any ideas how a segfault crept in? I find hard to believe that the segfault occurred in that function since it's safe. I think that it's more likely that the problem occurred in one of the unsafe blocks. Doing a backtrace or adding "debug" prints should help you to pinpoint the source of the problem. --- If you need termios bindings for your project, you can drop me an issue at [serial.rs](https://github.com/japaric/serial.rs/issues). I think it may make sense to split the current serial.rs into termios.rs (with only termios bindings) + a new serial.rs that's built on top of termios.rs, that way you could use termios.rs as a cargo dependency in your project.
`const` was used in place of `static` a year (or more ago); that was changed but the keyword was left reserved.
Generally, having `unsafe` code should be avoided where possible. For the equality check, I think what you can do is have the `A` struct implement the `PartialEq` and `Eq` traits, for example like so: #[deriving(PartialEq, Eq)] struct A; Then, you could check if `A == A`. If you want to pass `A` struct to a function and check for equality there, you could try something like (assuming that the object you pass to this function implements the `Thing` trait): fn check&lt;T: Thing + PartialEq&gt;(one: T, two: T) -&gt; bool { one == two } Does that help? I'm not sure since you were talking about pointers, and this would not check for same pointers. For pointers, this seems like an interesting piece of documentation, specifically the first subsection about coercion: http://doc.rust-lang.org/std/ptr/index.html
You are correct. Thank you!
I'm sure I understand what you mean by "trait reference". Do you mean you don't know if two objects have a specific trait and you want to figure that out at runtime? What's the use case, if I may ask? What are you trying to do, that would need what you want? Maybe there is another safe (as in not using `unsafe`) to achieve the same thing.
Ok, well in that case, what I gave you above should do the trick, no? This is assuming that the two objects are of the same type, not only the same trait (which seems to be what you want from the examples you posted, but please correct me if I misunderstood something here). Here's a full example of what I meant: struct A; trait Thing {} impl Thing for A {} fn main () { fn same&lt;T: Thing + PartialEq&gt;(one: *const T, two: *const T) -&gt; bool { one == two } let a = A; let a: *const A = &amp;a; let b = A; let b: *const A = &amp;b; println!("{}", same(a, b)); println!("{}", same(a, a)); } 
But what if I add another `struct B` that implements `Thing`, make a trait object `let b = &amp;b_val as &amp;Thing` and want to compare the pointers inside `a` and `b`? Here you are using concrete `*const A` pointer, not a polymorphic trait object. Edit: I’ve updated the post to represent this case.
Yep, I've put back the generic that implements `Thing` and `PartialEq`. Sorry about that. Ok, so you want to compare equality of two pointers of different types? What is it that you're trying to do? I want to help you (and if possible learn in the process), but I don't understand why you need to check the equality of two differently typed pointers.
True immutability is hard to define though. Eg, a `Rc&lt;T&gt;` is pretty much immutable for its content, but it employs internal mutability for the ref counts.
That has recently [been changed](https://github.com/rust-lang/rust/commit/90d03d792669fed99b659d1efbe835d4b9b8873c). All global constants are now `const`, whereas `static` now always refer to some global memory location.
Yes, we've come in a circle and now have `const`s again (as well as `static`s this time).
The thing is, they are not of entirely different types, they are both `Thing`s. What I’m trying to do is some extensible game-like world model with different things in it, and things can relate to other things in some ways. For example, I can add a field like `parent: &amp;Thing` to some struct implementing `Thing` and then I want to be able to tell if some other `&amp;Thing` is exactly the same one that `parent` points to.
Alright, I think this may suit your needs, and is "safe" (as in not `unsafe`): trait Thing {} struct A; impl Thing for A {} struct B; impl Thing for B {} fn main () { fn same&lt;T1: Thing, T2: Thing&gt;(one: *const T1, two: *const T2) -&gt; bool { one == two as *const T1 } let a = A; let a: *const A = &amp;a; let b = B; let b: *const B = &amp;b; println!("{}", same(a, b)); println!("{}", same(a, a)); println!("{} / {}", a, b); }
I think this would be of limited value if you didn't have access to the DOM API from Rust, and ATM from what I've gathered - you don't have a nice way to interface with the DOM from Rust - for eg. you can't even register a event handler that's a Rust function, Servo implementation hardcodes the callback as a JS engine function pointer. So, IMO what's really needed for Servo to be Rust GUI library is refactoring/rewriting the DOM API so that it allows you to access it trough both JS and Rust. This would also allow you to write UI code in JavaScript and interop between the two, essentially making JS a scripting language for your app.
The productivity gain from being able to prototype/design stuff with standard HTML/CSS tools is huge, and being able to write UI logic in JS (or some compiled -&gt; JS language) seems nice.
Glad I can help ! Your question is very interesting ! I'm learning stuff too :-) To the best of my knowledge, you can only convert to a type, not a trait. What you can do is something like this: trait Thing {} struct B; impl Thing for B {} struct HelloWorld&lt;'a, T: 'a + Thing&gt; { some_field: &amp;'a T } fn main () { let hello = HelloWorld { some_field: &amp;B }; } Is that what you're looking for?
For many changes, `make check-stage1` is enough to make sure it bootstraps. You can also make the makefile process multiple crates in parallel, like `make check-stage1 -j4`, but this will not help much for the biggest crate, rustc itself.
&gt; you can only convert to a type, not a trait I’m not sure what you mean by this. You can convert to a trait object (e.g. `&amp;Thing`), something like this: http://is.gd/jKcli3.
&gt; Is that what you're looking for? Sadly, no, because it lacks runtime polymorphism. For example, I can’t have one vector of `HelloWorld`s pointing to different types of `Thing`s this way.
If you want runtime polymorphism, you could make use of `Any` and `TypeId`. Here's an example of something I did recently, for fun: https://gist.github.com/conradkleinespel/1919ab0b707491c0ee15 This is a super flexible data structure in which you can put anything. But when you want to access an item inside it, it returns an `Option` to avoid possible dangerous usage (like a bad type conversion, which could lead to segfaults and all kinds of weird behavior). This has an impact on syntax and most likely performance (even though I have not benchmarked it).
That’s interesting, thanks, although I can’t see a way of using this to solve my problem.
Thanks for the benchmark! Your feedback is very appreciated, and I opened up 3 issues: https://github.com/PistonDevelopers/graphics/issues/631 https://github.com/PistonDevelopers/graphics/issues/632 https://github.com/PistonDevelopers/graphics/issues/633 In the Piston libraries we do not have an official 2D vector type, but we have a `vecmath` library that we use for internal usage. This library is just very basic and does not provide everything you need, so it is intended to be reexported under other `vecmath` modules in specific libraries. For example, piston-graphics has its own vecmath module, adding other useful math functions related to 2D graphics. There are 2 other libraries in the Rust gamedev ecosystem, cgmath and nalgebra, which both are too complicated to reason about without familiarity with the code base. As a game engine Piston is extremely modular, where we try to assume as little as possible about application structure and take low dependency very seriously.
Wasn't the mutapocalypse mostly because there was talk about removing default-local mutability? I actually remember the `&amp;only` or `&amp;uniq` suggestion being the only one that people liked.
Yeah, I could have a data structure with `&amp;Any`, but I can do this with `&amp;Thing` too. The original problem remains: how can I have both polymorphism and the ability to compare references? How can I tell if one `&amp;Any` points to the same memory as another `&amp;Any` without converting them to one particular type? No, all the code I have on this particular problem is in this post.
It works the same way with `mut` in variables. It only means inherited mutability.
Agreed that we need DOM access from embedders to make this useful. Event handlers could be an issue. In general, though, the DOM implementation within Servo has an API that's already [pretty close](https://github.com/servo/servo/blob/9dfd5e7fcd2011a411b219e8c45aadc0ecb270bd/components/script/dom/document.rs#L393-L895) to what an embedder might want. (Indeed, we sometimes call it from other parts of Servo.) They'll have to learn about the [wonderful world of `JS&lt;T&gt;`](https://blog.mozilla.org/research/2014/08/26/javascript-servos-only-garbage-collector/) but it's not *that* complicated and it means their DOM access will be just as fast as Servo's internals. The biggest limitation is that native code which touches the DOM will need to run in the same thread as JavaScript and all of Servo's built-in DOM stuff. This is a pretty core restriction of the Web platform — [Web Workers](https://developer.mozilla.org/en-US/docs/Web/Guide/Performance/Using_web_workers) can't touch the DOM either. I think for v1 of this idea it's simply up to the embedder how to handle communication between the UI thread and worker threads. OpenGL rendering can be done on any thread (or even a separate process) using OS-level support for sending textures between GL contexts, which is something Servo already uses for compositing. (There's some progress on allowing [WebGL from Web Workers](https://blog.mozilla.org/research/2014/07/22/webgl-in-web-workers-today-and-faster-than-expected/) as well.) I should also mention that the Rust↔JS bindings are auto-generated from interface description files. If embedders need additional wrapper code, we can probably auto-generate a lot of that too. This project would be an *awesome* way for Rust gamedev people to contribute to Servo. It's all graphics and system-level hackery; the amount of work on the layout / JS side should be quite small.
Mostly to show off our ongoing work on forms :) (Not yet merged, [this branch](https://github.com/Manishearth/servo/compare/rebased-input) is what I ran above). We're pretty close to being able to log in to Reddit Mobile (and possibly desktop) too, from what I see, the only thing blocking us is that Reddit uses `&lt;button type=submit&gt;` which I haven't gotten around to adding submit functionality to.
It's the way many new games are going, planetary annihilation's whole UI is HTML, CSS and JS. Also storage and RAM are basically free, the productivity gain is huge
Unless the thing inside has interior mutability, in which the Arc thinks it's immutable but it actually isn't...
Right, it only includes the parts of the std lib that you actually call. In this case at runtime there's nothing at all left. Operationally, things like `mem::transmute` and `intrinsics::unreachable` are more like directives to rustc / LLVM rather than actual code. We don't even have anything from libc / crt / compiler-rt. Our `main` is more like what's traditionally called `_start`; it's the very first thing executed once the kernel creates our process. Here's the full disassembly of the binary: 0000000000400078 &lt;main&gt;: 400078: b8 01 00 00 00 mov $0x1,%eax 40007d: bf 01 00 00 00 mov $0x1,%edi 400082: be 08 00 40 00 mov $0x400008,%esi 400087: ba 07 00 00 00 mov $0x7,%edx 40008c: 0f 05 syscall 40008e: b8 3c 00 00 00 mov $0x3c,%eax 400093: 31 ff xor %edi,%edi 400095: 0f 05 syscall All of this machine code came out of [inline asm blocks in syscall.rs](https://github.com/kmcallister/syscall.rs/blob/e7bb50e93c2ad0b23785e71bb9f6fde8b2722fc9/src/platform/linux-x86_64/mod.rs). In one sense it's not written in Rust at all ;) But I used a bunch of Rust features that compiled away entirely — slices, lifetime checking, crate linking, macros, generics (`raw::Slice&lt;u8&gt;`), etc. This is what we mean by "zero-cost abstraction" :)
This `fn` has basically nothing to do with any standard entry point in C or Rust. It could be named anything. The program builds as a static library and I use `nm` to find the address of `main` to store it in the `e_entry` field of the custom ELF header.
Don't forget --enable-ccache in your configure script.
Long long ago, the Shoes toolkit for Ruby did this, with Gecko. Eventually it moved to native widgets, but there is some precedence. Or think of things like the Steam Browser.
Also it's much easier to hire people who can do amazing things with HTML / CSS / JS, compared to something homegrown or niche.
I wonder why this option isn't the default if `ccache` is installed... I'm sure many people don't poke at `./configure --help`, and end up not even knowing this option is there
I had an issue after the last llvm upgrade where I had to stop using it. Even blowing away ~/.ccache didn't fix it. :/
I'm sorry but I don't have a simple answer to that. The problem is that I do not understand what problem you're trying to solve in the first place. You say you want to compare pointers. I gave you a solution for comparing pointers of two structs that implement `Thing` but are of different types. But it seems like the problem is more complex. What's the big picture? Why do you need to compare pointers? What I'm saying is that Rust is not Python. Rust is not C either. Maybe there is a way that completely differs from the C / Python way. If I knew what you're trying to do, I could help more. Right now, I've reached my limit :-/
I’m basically trying to do something like this: extern crate debug; trait Thing {} struct A; impl Thing for A {} struct B; impl Thing for B {} // This is your function fn same&lt;T1: Thing, T2: Thing&gt;(one: *const T1, two: *const T2) -&gt; bool { one == two as *const T1 } fn main() { let a1 = A; let a2 = A; let b = B; println!("{:p}", &amp;a1); println!("{:p}", &amp;a2); let things: Vec&lt;&amp;Thing&gt; = vec![&amp;a1 as &amp;Thing, &amp;a2 as &amp;Thing, &amp;b as &amp;Thing]; things.push(&amp;a1 as &amp;Thing); // error: mismatched types: expected `*const &lt;generic #222&gt;`, found `&amp;Thing` (expected *-ptr, found *-ptr) same(things[0], things[1]); // error: mismatched types: expected `*const A`, found `&amp;Thing` (expected struct A, found trait Thing) same(things[0] as *const A, things[1] as *const A); // error: internal compiler error: expected object type same(things[0] as *const Thing, things[1] as *const Thing); // Here's what I want to achieve: things[0] == things[1]; // false things[0] == things[3]; // true } The reason I want this is because there may be many references to `Thing`s of unknown concrete type laying around, and sometimes I want to know if some `Thing` from this `things: Vec&lt;&amp;Thing&gt;` is actually a parent (`parent: &amp;Thing`) of current `Thing` in a `for` loop, for example. It can’t be done with what you proposed, because it requires that the concrete type is known at compile time.
Idiomatic rust would probably use the [standard library](http://doc.rust-lang.org/std/str/trait.StrSlice.html#tymethod.subslice_offset). Rust strings aren't great with direct indexed access, since they're designed to work with unicode (which will break horrifically in your Go example). If you assume that the strings are all ASCII, you can use the [slice](http://doc.rust-lang.org/std/str/trait.StrSlice.html#tymethod.slice) method to get successive slices of the longer string and compare them to the smaller one.
I can do this by adding an `id()` method to the `Thing` trait returning some kind of unique identifier for this `Thing`, it might as well be its address in memory casted to `uint`, so I can implement `is()` as simple as `self.id() == other.id()`, but it seems like an unnecessary workaround to me — I feel like a language should have builtin support for something as simple as this. Or I can use `unsafe` code: fn same&lt;Sized? T&gt;(a: &amp;T, b: &amp;T) -&gt; bool { unsafe { mem::transmute::&lt;_, TraitObject&gt;(a).data == mem::transmute::&lt;_, TraitObject&gt;(b).data } } println!("{}", same::&lt;Thing&gt;(a, a)); 
im partial to ```&amp;there can be only one```
I have bug fixes for most of the problems in my PRs!
What about cookies? Do you and jdm have any plans for them? Probably we should think about how they interact with embedding, since the embedder should probably be responsible for managing the cookie jar…
I'll one up you! f0VMRgEAAAAAAAAAAAABAAIAAwAgAAEAIAABAAQAAAAxwLACzYDr+DQAIAAB
Should a subreddit for Servo pics be started?
&gt; Agreed that we need DOM access from embedders to make this useful. Arguing with myself here: Given the threading issue, and exposure to `JS&lt;T&gt;` internals, does it really make sense to let embedders manipulate the DOM directly? The alternative is more like a web worker: native code can draw to `&lt;canvas&gt;` and it can `postMessage` to JS code running in DOM context. This would require writing your app's UI logic in JS, but I think a lot of people will want to do that anyway. It's very high-level, it's designed for DOM manipulation, you can use JS libraries, you can hire web developers, etc. Building a native app UI in Ember.js actually sounds really awesome :)
 It would be dead, only a couple people posting. Plus its not like this sub is filled with content anyways.
Your `get_ptr()` solution is pretty good, thanks. &gt; How would you implement something that's of type T2 to be also of type T1 in Rust? No, I’m not trying to do that. Some are `T1` and some are `T2`, but both are referenced via `&amp;Thing`. 
Note that this won't work correctly if the type is zero sized (there doesn't seem to be a way to tell if a type is zero sized at compile time), due to zero sized types being able to have the same address . For example: struct A; struct B(int); let x = A; let y = A; assert!((&amp;x as *const A) != (&amp;y as *const A)); // this will fail let x = B(1); let y = B(1); assert!((&amp;x as *const B) != (&amp;y as *const B)); // this will succeed
It's actually standard for any GUI toolkit to require scene graph modification only on UI thread so it's not that different from anything else as long as you expose the JS DOM thread event loop (unless green threads complicate things here - don't know how Rust/Servo do it). I agree that the most pragmatic approach would be to do the UI part in JS and then communicate with native code trough JS &lt;-&gt; Rust bridge. The only issue I see with this is that you're forced to use JS to write UI code (which IMO is preferable to writing Rust because it's higher level but still it's a limitation) ~~and you need to have a JS engine that can talk to Servo (which could be a pain on iOS/consoles)~~ (nvm I didn't see that there were projects already distributed with spidermonkey for iOS in interpreter mode).
ouch :/ Did you try a `make clean` first? Sounds like debris from a previous compilation
&gt; you need to have a JS engine that can talk to Servo Wouldn't Servo bring in Spidermonkey with it?
Idiomatic Rust would not reimplement an inferior version of something that’s already in the standard library as [`.contains(needle)`](http://doc.rust-lang.org/std/str/trait.StrSlice.html#tymethod.contains), which optimises the algorithm it uses based on the input lengths.
How about fn addr_eq&lt;Sized? T&gt;(a: &amp;T, b: &amp;T) -&gt; bool { unsafe { let tobj1: std::raw::TraitObject = std::mem::transmute(a); let tobj2: std::raw::TraitObject = std::mem::transmute(b); tobj1.data == tobj2.data } } For some reason this will require type annotations when used.
Yep, I had this solution in my post from the beginning (question #2) :) I just could’t do this with a method.
Ah. Missed that.
The Go example would actually work fine for utf-8 data despite it being bytewise. Not guaranteed to work for other encodings though. And definitely, the Rust standard library version will be fast.
&gt; This library is just very basic and does not provide everything you need Yes, it does: [`+`](https://github.com/PistonDevelopers/vecmath/blob/fb14c586842e7e6e93cd02bb23e3dd4bf958e594/src/lib.rs#L836), [`-`](https://github.com/PistonDevelopers/vecmath/blob/fb14c586842e7e6e93cd02bb23e3dd4bf958e594/src/lib.rs#L745), [scaling](https://github.com/PistonDevelopers/vecmath/blob/fb14c586842e7e6e93cd02bb23e3dd4bf958e594/src/lib.rs#L836) and [dot products](https://github.com/PistonDevelopers/vecmath/blob/fb14c586842e7e6e93cd02bb23e3dd4bf958e594/src/lib.rs#L927).
For more: http://doc.rust-lang.org/guide-strings.html#indexing-strings
Since your question seems more general than "How do I match sub-strings", some remarks: I suspect you were having trouble converting the inner for loop, because it contains `found` in the conditional expression. In this case this is easily solved by a `break` after `found = false`, making it easy to use a range based loop. In cases wit a even more complicated/general condition rewriting to a `while` loop usually works, failing that a `loop`, with conditional `break`s an `continue`s. A somewhat idiomatic port of your Go code is this: use std::io; fn is_sub_string(ss1: &amp;str, ss2: &amp;str) -&gt; bool { let (s1, s2) = if ss1.len() &gt; ss2.len() { (ss1, ss2) } else { (ss2, ss1) }; let (s1, s2) = (s1.as_bytes(), s2.as_bytes()); let s2_len = s2.len(); for i in range(0, s1.len() - s2_len + 1) { if s1.slice(i, i + s2_len) == s2 { return true } } false } fn main() { let mut reader = io::stdin(); println!("Enter the first string: "); let str1 = reader.read_line().ok().expect("Failed to read string"); println!("Enter the second string: "); let str2 = reader.read_line().ok().expect("Failed to read string"); println!("{}", is_sub_string(str1[].trim(), str2[].trim())); }
To clarify on what I was saying the other night, I think you could write a macro that looked like this in use: mitsumono! { thingy Connection fn&lt;T: FromRedisValue&gt;(&amp;self) -&gt; RedisResult&lt;T&gt;; thingy Client fn&lt;T: FromRedisValue&gt;(&amp;self) -&gt; RedisResult&lt;T&gt;; thingy Pipeline fn&lt;'a&gt;(&amp;'a mut self) -&gt; &amp;'a mut Pipeline; cmd get&lt;K: ToRedisArgs&gt;(key: K) "GET"; cmd set&lt;K: ToRedisArgs, V: ToRedisArgs&gt;(key: K, value: V) "SET"; cmd something() { some_command_generating_function() } } (`thingy` because I don't know what you would call them as a category.) There shouldn't be anything hard about parsing this, since it's largely just re-using existing language constructs (for example, the lifetime &amp; type parameters just be parsed with `Parser::parse_generics`; see also the [docs for the compiler's parser interface](http://doc.rust-lang.org/syntax/parse/parser/struct.Parser.html)). You can then expand into the product of the two sets, concatenating the type and argument lists together for each combination. If the "body" of a command is a string literal, you can auto-generate the `cmd("XXX")` business. If you want an example of how you'd parse all this, you can look at [my scan* macro library](https://github.com/DanielKeep/rust-scan/blob/master/src/lib.rs), starting at the `plugin_registrar` function.
Right, I guess if you slice off part of a character and get an invalid string, then the second string will definitely not match it. So you could use some `unsafe` stuff to do bytewise comparisons.
&amp;mut... you ask for mutable reference; to be a *safe* mutable reference, it has to be unique - so compiler error messages assert that for you. I'm happy with that. &amp;mut is what you write because its' what *you* want, and the compiler deals with the rest.
How is "`4realzies`" not sufficient to indicate that I'm joking?!
Very cool! ... not the most constructive of feedback, but there you go. :P
Thanks! Let me know if you run into any trouble building/running it, I've only tested it on my one linux box.
Well, I can't compile it at the moment because every time I try to put SDL.dll in the target directory, Cargo deletes it and then complains that it can't find it. No, of course you can't find it, dumbass... *sigh*
I like how you think :) You got me really excited with your post. I wish I had the low-level chops to work on projects like that (that's part of why I got interested in Rust). Maybe someday I will :)
Cargo.toml should have *some kind* of reference to the external (non-rust) dependencies.. at least for documentation. Example, Cargo.toml for rust-sdl2 doesn't refer to what it actually depends.
I'm just confused why it's `&amp;mut` and not `mut&amp;` since you can make a `&amp; &amp;mut` variable that's confusingly not mutable. Wouldn't it make more sense to make it `&amp; mut&amp;` so you can at least see that the part that comes first applies?
You can always just make a pub write a wrapper struct for R for exposing to other modules. I agree it's not ideal, but I'm pretty sure it will work, and in practice lots of modules (e.g. in the Rust stdlib) define internal types like that.
\o/ Awesome!
Uh, forgot about them ;P I don't have any plans, though Josh might. I was thinking about embedding the other day, and questions like that made me think that we should to at least have some way of delegating work to the embedder, even if the API isn't decided. 
You mean like a "blanket" `impl` of a trait for all trait objects? Not that I know of. There's currently no way to differentiate trait objects from other type of references I think? 
This is against zero-overhead approach.
You can just use Cell, which is zero-overhead and lets you mutate shared references through Copy types. let foo = std::cell::Cell::new(3i32); let bar = &amp;foo; println!("{}", foo.get()); bar.set(10); println!("{}", foo.get());
See the linked mailing list thread, it contains a summary as well as a detailed description (including a fairly formal specification).
I was making a pun on "double UTF-8"
r/rustporn, in the spirit of r/unixporn?
Yeah, how exactly do we get deterministic builds (a goal of Cargo) otherwise? Or perhaps it's not realistic for external dependancies.. That would be a shame.
I felt that way too in question #2 (`&amp;T`?). Maybe I should’ve asked that in a separate post…
**Update #2:** I ended up using an inheritance solution [like this one](https://www.reddit.com/r/rust/comments/27sbgr/oop_in_rust/ci466rd) with this *safe* `is()` method: trait ThingTrait { fn is(&amp;self, other: &amp;ThingTrait) -&gt; bool { self.get_thing() as *const Thing == other.get_thing() as *const Thing } // ... fn get_thing(&amp;self) -&gt; &amp;Thing; fn get_thing_mut(&amp;mut self) -&gt; &amp;mut Thing; } 
Because client/connection are generic for T and pipline is not. They have different signatures and behavior.
Thanks for the great response, this is exactly what I was looking for. The Rust for loop is actually way nicer than the standard C-style loop, I just need to get used to it :-) EDIT: Also, I was curious, since you just use `&amp;str` instead of `&amp;'static str` is that lifetime elision at work here?
One way to actually achieve deterministic builds would be to have Cargo.toml refer to a nixpkgs package (well, or other package database; but nix was designed to be deterministic, and is well supported in distros that use other package managers, by installing all packages in your home). Or, perhaps, have Cargo.toml refer to specific github commits in the repository of a native library and also give it some build instructions; that way Cargo can disregard already installed dependencies and build a deterministic binary from scratch. This isn't possible for all libraries. For example, you're not supposed to build your own libGL, because it's provided by the vendor. And most of time you want to use the system libraries (that is, build a Debian package that links against Debian libraries; an Arch package that links against Arch libraries, etc). Of course the traditional packaging route throws away determinism: if I tested in Arch, not necessarily it will works identically in Debian, perhaps because version mismatches or distribution patches.
can you comment on the experience implementing this, do you have some experience with other languages say D or C++, how does it compare, any downsides? How is Rust learning curve? Thanks for posting this!
I think it should use the same reasoning regarding Maybe vs Either of Haskell. Option should be the default return type for partial functions, and Result is for cases where Option would be inadequate (that is, you need to explain the failure - perhaps because it could have failed in one of many ways). One reason is that it's easier to compose two operations that return Option (with `and_then`). It may be awkward to compose Results that have different types for their error condition.
I would've used the standard library, but I don't actually need to match substrings :-), I wanted to understand the for loop in Rust better and this is the first thing that came to mind. Useful info nonetheless, thanks!
But please don’t understand this critique wrong. It's great work and a nice article. I’m just nutpicking und unfortunately can only up-vote once. ;)
This only works when there's only one type of `Thing` right?
This seems more viable, if deterministic builds aren't really a goal..
I got round that in one of my projects by adding a build command to Cargo.toml that symlinks (or in this case, copies) the required libraries to the target directory. That way they're added after the directory is wiped.
You mean only one type implementing `ThingTrait`? No, there can be many, they just have to implement `get_thing()` method, but I need it for inheritance anyway: struct Thing { // Common fields // ... } trait ThingTrait { // Common methods using get_thing() // ... fn is(&amp;self, other: &amp;ThingTrait) -&gt; bool { self.get_thing() as *const Thing == other.get_thing() as *const Thing } fn get_thing(&amp;self) -&gt; &amp;Thing; fn get_thing_mut(&amp;mut self) -&gt; &amp;mut Thing; } struct Car { thing: Thing, // Car fields // ... } impl ThingTrait for Car { // Car methods // ... #[inline] fn get_thing(&amp;self) -&gt; &amp;Thing { &amp;self.thing } #[inline] fn get_thing_mut(&amp;mut self) -&gt; &amp;mut Thing { &amp;mut self.thing } } struct House { thing: Thing, // House fields // ... } impl ThingTrait for House { // House methods // ... #[inline] fn get_thing(&amp;self) -&gt; &amp;Thing { &amp;self.thing } #[inline] fn get_thing_mut(&amp;mut self) -&gt; &amp;mut Thing { &amp;mut self.thing } } 
Well, /r/rustporn already exists...
Note: if you wish to still use the computer in parallel, then `-j6` should leave you some room on an `i7`. Of course having access to a beefy server and tossing `-j24` or `-j48` can really speed things up...
http://crates.io/native-build.html
Gah, that's frustrating. As far as I can tell, cargo on Windows is still pretty flaky, I don't really know how to get around this problem nor do I have a Windows computer. I'll see if I can do something about it...
That sounds useful! Do you have gist or a repo I could take a look at for your solution? It'd be awesome to get it running on Windows.
It's really just a problem with Cargo. I could probably get around it by installing the linker libs... wherever it is GCC looks for them. The way I handled this when I was playing with some GL stuff was to add a Python script that grabbed the dependencies, cached them, and extracted the necessary files. But having every project do that is a bit insane. Ideally, packages (like the sdl package) could export binary dependencies in some way to consuming packages. Actually, *ideally*, there'd be a meta-package repository that mapped abstract package names to system-specific managers, source repositories and precompiled binaries. Then you could just depend on "sdl2" without having to worry about the target platform.
The solution I use at the moment is using a makefile and `ln -s` commands, so it's not immediately usable on Windows (I do plan to make it cross-platform at some point though), but the same technique should work. All you need to do is create a command (e.g. a batch file) that copies the required files into the target directory (use the `OUT_DIR` environment variable provided by Cargo) and refer to it from your Cargo.toml as the external build step. The Cargo website has a tutorial for adding native build steps.
I come from a C++ background and I'm sure that helped when I was learning Rust. Haskell is probably another useful language to know. D is a pretty cool language, but is a sense very close to C++, just without all the garbage. That said, Rust is a very simple language, simpler than D and definitely simpler than C++. I'm hardly an expert on Rust, but I managed to get to up to speed pretty quickly by reading the Guide and then working on this project: in about a week I was feeling pretty confident. The API docs help a lot while actually writing code, they're really good. Comparison-wise: it's no secret that C++ is broken. It has good ideas at its core, particularly since C++11, but it gathered a lot of cruft and it is very resistant to change (vector&lt;bool&gt; should have been deprecated a year after being introduced). What Rust does crucially better (an incomplete list): * Ownership &amp; lifetime management - Modern C++ encourages you to think about things owning things in a structure as close to a tree as possible (shared_ptr-s allow multiple parents on the rare occasion that's necessary). Rust uses the same model (in lieu of a GC for instance), but the compiler ensures you can't get dangling or null pointer as long as you stick to this (think a moved unique_ptr&lt;&gt; in C++). * Concurrency - strict rules about data sharing, encouraging message passing). * Module &amp; dependency management - C++'s idea of this is concatenating files. Rust has a modern, fully-fledged module system which, surprisingly, still manages to work with the compile &amp; link model. * Haskell-like type inference - Rust's type inference is very smart (and yet relatively easy to grasp) and is much more extensive than the one in C++. * Algebraic data types + pattern matching - These things are just stupidly useful, it's crazy more languages don't have them. Again reminiscent of Haskell. * Type constraints - In many ways C++'s generics are more powerful and, indeed, often more useful than Rust's (integer parametrised types, for instance). However the lack of traits (or concepts as they're called in the C++ world) means debugging generics is hell.
 src/writer/emitter.rs:113:9: 113:14 error: no rules expected the token `const` src/writer/emitter.rs:113 const WROTE_NOTHING = 0, ^~~~~ Build failed, waiting for other jobs to finish... src/sdl2/joystick.rs:50:9: 50:14 error: no rules expected the token `const` src/sdl2/joystick.rs:50 const CENTEREDHATSTATE = 0, ^~~~~ Could not compile `rust-xml`. Hmmmm... My Rust is only a few days old. I think this was changed recently? shouldn't these be `static`?
Ideally yes. But it'd be very difficult for Cargo to know where to grab the DLL-s from for the meta-package; in Windows there's no standard place to put 3rd party DLLs. The [solution that ZRM2 came up with](http://www.reddit.com/r/rust/comments/2izm2a/doom_iii_opengl_3_renderer_written_in_rust/cl79g88) sounds like a pretty good workaround, but I couldn't really test it w/o a Windows computer. It'd require you to place all the DLLs in a folder from which they'd get copied on every build.
No, `const` is the new kid on the block.
Cool thanks, I must be out of date then. I've been on planes, it's not my fault! :)
Yeah, thats elision. :) In general, if your function only needs to use a reference for the duration of its body, but not return or store one, then you'll usually take a reference without lifetime parameters.
I assume you're referring to this: http://www.wabbo.org/blog/2014/22aug_on_bananas.html
Looks like I'm not the only one trying to figure out what would be a good way to approach this. Along the idea to use a wrapper struct wrongerontheinternet mentioned, two alternatives have come to my mind. 1) Doesn't seem to fit this specific use case, but I'll mention it anyway for completeness' sake: Only expose a trait to the users of the library. The trait only includes those parts of R's functionality you're willing to show to the world. Use the struct R directly within the crate, it can have more methods or public fields visible to mod3 than what exists in the trait. This one would be more feasible if mod3::f were a member function of a struct, and the "RTrait" had a method that took in instances (or references) to the said struct. 2) A more practical idea: Have a free function in mod2 that's only visible within the crate, that allows you to access internals of R. Something like `pub fn access_a(r: &amp;mut R) -&gt; &amp;mut int` along the struct R but not in its impl, and not re-exported in mod1 for the world to see. The downside of this approach is that the accessor is less convenient to call than a real member function of R.
Nice.
That's not quite true, since `Result`, unlike `Option`, comes with an 'unused result' warning. I.e. you have to explicitly ignore a `Result`, while an `Option` can be implicitly ignored. In my code, I use `Option` only when `None` does not signify an error condition (yes, it requires some thought as to when it is an error condition, but not too much thought).
Ah, that's brilliant and so simple! Thank you!
Depending on your needs you can do this is two ways You can use enums wrapped in enums #[deriving(Show)] // &lt;- Just to make it printable pub enum AdtDetails { A04, A08 } #[deriving(Show)] // &lt;- Just to make it printable pub enum SiuDetails { S12, S13, S14 } #[allow(dead_code)] pub enum Message { ADT(AdtDetails), SIU(SiuDetails) } fn render_message(message: &amp;Message) { match *message { ADT(details) =&gt; print!("ADT {} ", details), SIU(details) =&gt; print!("SIU {} ", details) } } fn main() { let message = ADT(A04); render_message(&amp;message); } http://play.rust-lang.org/ You can use traits and structs #[deriving(Show)] // &lt;- Just to make it printable pub enum AdtDetails { A04, A08 } #[deriving(Show)] // &lt;- Just to make it printable pub enum SiuDetails { S12, S13, S14 } // A trait more or less corresponds to a java interface trait Renderable { fn render(&amp;self); } pub struct ADT { details: AdtDetails } impl Renderable for ADT { fn render(&amp;self) { print!("ADT {} ", self.details); } } pub struct SIU { details: AdtDetails } impl Renderable for SIU { fn render(&amp;self) { print!("SIU {} ", self.details); } } fn main() { let message = &amp;ADT{ details: A04}; message.render(); } http://is.gd/g0ahJM
Note: This also works match message { ADT(A04) =&gt; {...} ADT(A08) =&gt; {...} SIU(S12) =&gt; {...} SIU(S13) =&gt; {...} }
The activity list also contains some bookkeeping works on RFC.
Yeah, there are CEF functions relating to a cookie manager that are stubbed out right now. khodzha's been plugging away at a cookie implementation for a while, so I'm going to try to merge that soon so we can keep iterating.
That sounds like a pretty neat way to handle the issue, actually. It hadn't occurred to me to use traits for crate-internal calls that way. Of course there's the double typing of all the method signatures, but at least it's nicer to use than the free functions way, when only one item has to be imported into a module.
Awesome! I just checked and the readme does say it's for 1.5.1. Any ideas how to make it more prominent? I.e. what would have made you go for 1.5.1 instead of 1.6.0 when you first tried it? I think the libtcod download site is partly to blame since it lists two nightlies before the stable version, but still.
It looks like you're implementing HL7 messaging in Rust. Nice. I run a startup that makes healthcare software and we're also very interested in tech like Rust. I'd be curious to hear more about your experience if you want to chat.
The bot (the account?) was used to "transfer" all issues tagged as RFC from the regular rust repos to the rfcs repos.
Not sure why the bot has its own repositories, but I guess it's for testing. The bot's code is at https://github.com/nick29581/highfive and as you can see there it's a fork of a servo equivalent
Note that instead of having `extern crate gl`, you can write: #[phase(plugin)] extern crate gl_generator; mod gl { generate_gl_bindings!("gl", "core", "3.3", "global") } This will only generate the functions available in OpenGL 3.3 instead of the latest version (4.5). This way you are sure that you don't use anything that appeared in OpenGL4. I'd even recommend using the `struct` generator instead of `global` (see the docs), but that would require you to make changes to all your code that uses GL. 
D defines transitive immutability, it's useful for shared data across threads.
Waiting for the first screenshot posted using Servo! :)
Wow all, thanks a ton! So much faster, close to an order of magnitude actually. To give everyone some reference numbers: I build from a clean master with: ./configure --enable-ccache and make -j8 in like 25 min. I was able to run make check-stage1 -j8 in around 12 min. 
Neat, can you point me at documentation for using `#phase` to metaprogram? I was thinking about this problem last night and it'd be nice to see how Rust handles it.
There's not much, but you can check this: http://doc.rust-lang.org/guide-plugin.html
Ask yourself: "would it make any sense to have an API that just returns T and aborts otherwise?". If the answer is yes, you should probably use a Result. If the answer is no, you should probably either return an Option or an ad-hoc enum. 
I should have known.
This is still the very beginnings. You can't get it off of Rubygems yet. It only works on Linux. The setup is very hacky. But it works :) 
There are plans to have integration with `pkg-config`...
Thank you Steve :)
So it's the opposite of the Haskell convention. &gt; Result&lt;T, ()&gt; I was going to say that `Option&lt;T&gt;` is isomorphic to `Result&lt;T, ()&gt;`, but such use of `Result` type would be pointless... well, the other branch is called `Err` so it's clearer it's actually an error. But anyway, a "partial function" is a function where for some inputs it has no return value. The lack of value might be treated as an error in some situations and not on others; it might be ambiguous. I think that if you pass around a `None` value, store it on a data structure, etc. without caring much about it then it probably is a good match for `Option`. If you would only store the value inside (doing something else if it's not found), then probably not having the value is more like an "error". Or if you're doing a search and either return a value or a "not found". If it's on a data structure like a binary tree, then an `Option` is more adequate. But if it's on a remote host, then a `Result` is adequate, because there's "not found" but also "network error", and perhaps "access denied", etc.
I've played around with doing something similar for Perl 5. I'm also not very familiar with Ruby and it's build system, so this question might seem a bit naive: Do I understand the flow correctly that you're using Cargo during build to generate the Rust library, and then use some C code to hook that up in the Ruby "runtime"? I assume you use that instead of some form of in-Ruby FFI bindings for performance reasons? I was considering an in-Perl DSL or a JSON file for configuring bindings between Perl-space and Rust-space, with a JSON file having the advantage of possibly being host-language agnostic. Are you planning anything in that regard?
Considering RubyGems can also invoke a Rakefile, could you not swap out the C code with Rust as well? However, this _would_ require users to have Rust installed when installing the Gem, but would remove the need of writing any C (other than the C -&gt; Rust interface).
I was so excited. Was fighting the linker until wycats helped me out. (Also, I prefer the ones with :cry: in them. Been doing C for two thirds of my life, off and on, and I still forget that `printf` doesn't give you a newline.
Yes, this is possible. However, if it was a 'real' extension, you'd start running into some issues that make this approach make sense. Basically, Ruby provides a number of C macros that marshall C types to Ruby types. I think that it's easier to have a thin C layer between Rust and Ruby that uses these macros to do the marshalling, rather than re-implement said macros in Rust.
Thanks for the tip, I'll merge the generated bindings with the check_gl module for the next release. I like the idea of using a GL object, rather than a namespace, but that might require too many changes right now. Much of the rendering code is in dire need of refactoring though, so when I get around to that, I'll probably switch to the struct generator.
I think it would just have to say 1.5.1 *only*. Otherwise, yeah, the libtcod website is pretty terrible, especially with installation instructions.
Good reasons, thanks for the information :) I can also see the reasoning behind keeping it simple for now. I'm more looking into what can be built to make it easier for people to do that. My end-goal would be to have some way to go directly from Perl (or any other dynamic host) to Rust. I believe Rust will work well with dynamic languages for a variety of reasons, so my full end goal would be some form of definition file (I like JSON not because of it's format, but because it's usually easy accessible to the wider toolchain here) that can be used to generate both the dynamic host side (either FFI or tighter integration) and the Rust (extern "C") side of the bindings. A bit like GIR but more specialized, and making use of Rust's ownership system for certain guarantees. So your content and examples are very appreciated since they're saving me tons of research :)
rust-highfive is my pet bot. Its main job is welcoming new contributors and assigning reviewers (try putting r? @foo in your PR's commit message and it will set the assignee field. In the future, if you don't specify the reviewer it will try and choose one for you). I also use the account for a few scripts for moving issues amongst repos and for testing, in both cases where it is clearer to use an 'anonymous' account rather than my personal one. The repos rust-highfive has are just for testing, it doesn't really use them.
Oh, and as someone pointed out, it is a fork of the highfive bot from Servo, which was written by jdm.
That's why i was asking if it was possible with macros. I know that compiler plugin would work, but you would also end up writing more code than just copy pasting an implementation.
When people think of programming, they don't think about fighting a linker for days. Good job man, you're fighting the fights so the rest of us don't have to :D
This is pretty much how I feel any time I get something to compile and run as intended. There is always extra cackling if the only bugs are compile errors / syntax issues / etc.
 pub struct MyError { cause: Option&lt;Box&lt;Error + Send&gt;&gt; } should work
Option implies that a returned value could be a Some or it could be a None, and that they are both equally valid, expected results. I like the string search example someone else used. Result implies that if it's not an Ok, then something is wrong and you're running into a problem of some sort.
Good idea, but I think of using Rust itself instead of JavaScript. Would it be possible to create something like jQuery selector library in rust, so you don't have to dabble in JS at all? Instead of events we can have infinite loop going on in one thread that checks if mouse or key was pressed and in what element.
The issue is that you're moving, not copying the `World`/`Box` out of the `WordIter` struct. You can't leave a partially moved struct behind, and the compiler is not smart enough to realize you're filling the moved part of the struct again. This is usually solved with `mem::replace()`: fn next(&amp;mut self) -&gt; Option&lt;World&gt; { let new_world = self.world.next(); let old_world = std::mem::replace(&amp;mut self.world, new_world); Some(old_world) }
This is such a good idea. I love how Rust is using the Github bots so nicely. Thanks for making it.
I'm unfamiliar with the build systems for Ruby, but would the user of the ruby-gem need to have cargo + rustc installed?
You're right about that you will have to create a copy of the `World` in the iterator method. There is no way around it. You will need implement `Clone` trait on `World` and `Cell`: #[deriving(Clone)] struct World { ... } #[deriving(Clone)] enum Cell { ... } and then you will need to invoke `self.world.clone()` in `WorldIter`'s `next()` method: impl Iterator&lt;World&gt; for WorldIter { fn next(&amp;mut self) -&gt; Option&lt;World&gt; { let old_world = self.world.clone(); self.world = self.world.next(); Some(old_world) } } You don't need boxes here, they don't add anything useful. `Box`ed value have *value* semantics, i.e. `Box&lt;T&gt;` behaves exactly like plain `T`, except that it has pointer size and a destructor. `Box`es are only really needed when you have recursive structures or when you work with *really* large chunks of data. You can read more on them [here](http://doc.rust-lang.org/guide-pointers.html). **Edit** /u/Florob0x2a's approach is much nicer, you should use it because it does not need `Clone` and does not perform extra allocations.
Yeah, I'd like to support that option as well. Servo has a CSS selector matching engine, and we could maybe extract it as a library. This would be a great way to navigate html5ever's static parse trees as well. If you look at frameworks like Ember and Angular, they basically provide a way to declare your UI in HTML and CSS, and keep it in sync with some JS objects. I wonder if we could do the same with Rust objects instead. That would be a really nice way to define a UI without writing any JS code. You could add custom JS if you want, say, custom UI elements or animations. These would be nicely separated from the application logic.
Unlike many folks here I actually like Javascript and find Node.js to be valuable effort. But I also believe in keeping things simple, and adding one more language to the mix is contrary to that. So I would prefer to just have servo graphic capabilities and keep all code to rust. We can maybe have two versions, with and without JS.
Thank you so much, the likelihood of me finding `std::mem:replace` on my own any time soon is very slim! (mainly because the existence of a function to do that didn't even cross my mind) I'll definitely give `std::mem` a much more thorough look. It turns out that the [example in the documentation](http://doc.rust-lang.org/std/mem/fn.replace.html) is almost exactly what I was trying to do (return something that was previously in a struct, replace it with a new value). PS: The `mem::replace` page has in its first paragraph "without deinitialising or copying either one". But looking at the source for [`mem::replace`](http://doc.rust-lang.org/src/core/home/rustbuild/src/rust-buildbot/slave/nightly-linux/build/src/libcore/mem.rs.html#322-325) shows that it uses [`ptr::swap`](http://doc.rust-lang.org/src/core/home/rustbuild/src/rust-buildbot/slave/nightly-linux/build/src/libcore/ptr.rs.html#146-159) which as far as I can tell does actually copy the memory. Are the docs in error here?
I'm not sure how I feel about the wording "without […] copying either one". It is technically correct within Rust's semantics. What happens here semantically is a *move* from `dest` to the return value, followed by a *move* from `src` to `dest`. A copy would temporarily create a duplicate (potentially requiring the type to implement `Clone`) and then destroy the old one (calling the destructor in the process, which does not happen here). However, from a memory point of view, the data obviously has to be copied.
I feel like the wording should probably be changed a bit there. It does make sense in terms of Rust semantics, but for someone who hasn't been working with Rust for a while the immediate assumption is that "copy" refers to a memory copy. Perhaps adding "Note that memory copies will occur."?
&gt; But even C♯, Java and Go each have just one type of string. Java has `StringBuilder`, which is the equivalent of Rust's `String`. It's just not used as much because the standard `String`s allow concatenation. In fact, Java's `String` is very similar to `&amp;str` too, but once again the support for concatenation makes it usable in more situations. Not sure about C#/Go as I haven't used them.
In the next section I mention .NET’s StringBuilder and Java’s StringBuffer (which I have now replaced with StringBuilder as it’s the one people are more likely to want). That they each have just one type of string is more just a matter of public perception in the case of .NET and Java.
I was planning on doing that first but I wasn't able to (forgot about cookies, and Reddit uses button submit) :P Once these existing PRs merge I might have a go at tinkering with khodzha's cookie support branch to get very basic cookies working, and add button submit capabilities (which is easy). If that doesn't work, add wget-esque `--load-cookies=cookies.txt`. Still time though.
You probably want http://www.reddit.com/r/playrust
I did think about returning `result&lt;option&lt;T&gt;, Error&gt;`, but it does mean that code which consume this function will need to do 2 levels of unwrapping to access the value. I'm not 100% convinced the trade-off is worth it. 
And I also added the fastest single-threaded C++ version (#2)
There's also the [fastest C version](http://benchmarksgame.alioth.debian.org/u64q/program.php?test=revcomp&amp;lang=gcc&amp;id=2), which people may find to be a simpler implementation to compare against.
You've got that backwards. StringBuffer has been around since Java 1 and is synchronized. StringBuilder was added in Java 5 and is unsynchronized. EDIT: I totally misread that parenthetical.
… and unsynchronised is what people will normally want.
I see StringBuilder about 10x as much as I see StringBuffer. YMMV but I think Chris is correct here about which one is used more.
Yeah, I'm just bad at reading.
DList has a lot of warts, for sure. I wouldn't use it as a good design example. It's on my ever growing list of "someone should do something about that", but it's low priority. I agree that RawLink is weird (and in fact, it doesn't even work the way it's supposed to, since it's Copy under the current rules). The reason the backlinks need to be different is because of Rust's multiple aliasing rules: there can only exist one (accessible) mutable reference to any given value. But with a forward and back link to every node, each node would have *two*. Using Rust's unsafe raw pointers enables us to tell the compiler "I've got this, I know exactly what I'm doing" and bypass this restriction. Basically, as far as Rust is concerned, a doubly-linked list is 100% unsafe (and it's not wrong, there's a reason we use it to teach undergrads *how* to use pointers). Here's a minimal example of a reasonably idiomatic Singly Linked List Stack: struct Node&lt;T&gt; { data: T, next: Option&lt;Box&lt;Node&lt;T&gt;&gt;&gt;, } struct List&lt;T&gt; { head: Option&lt;Box&lt;Node&lt;T&gt;&gt;&gt;, } impl&lt;T&gt; List&lt;T&gt; { fn new() -&gt; List&lt;T&gt; { List { head: None } } fn push(&amp;mut self, elem: T) { self.head = Some(box Node { data: elem, next: self.head.take(), }); } fn pop(&amp;mut self) -&gt; Option&lt;T&gt; { match self.head.take() { None =&gt; None, Some(mut head) =&gt; { self.head = head.next.take(); Some(head.data) } } } } [you can play with it on playpen here](http://is.gd/uBFbkJ) Note that this implementation has a subtle flaw: the destructor of the List will recursively call the destructors of each node, making it easy to blow the stack if you make a big list. A correct destructor (Drop) implementation would essentially call `pop` until None is yielded. Edit: You can of course also implement pop like this: fn pop(&amp;mut self) -&gt; Option&lt;T&gt; { self.head.take().map(|mut head| { self.head = head.next.take(); head.data }) } Whether this is more or less idiomatic is a matter of taste. I *think* most would prefer this form, but the other form is perhaps more "newbie" friendly. I have conflicting feelings myself. Closurey conveniences can be nice, but can make refactoring and maintenance bit harder (for instance, if you wanted to do something special in the None branch). They're *probably* more readable to intermediates and beyond, because they remove a lot of boiler-plate? *shrug*
&gt; PS: The mem::replace page has in its first paragraph "without deinitialising or copying either one". But looking at the source for mem::replace[2] shows that it uses ptr::swap[3] which as far as I can tell does actually copy the memory. Are the docs in error here? It does a shallow byte copy, not a semantic copy. The former is just duplicating the bytes, e.g. via `memcpy`, while the latter may need arbitrary computations to ensure sfaety, e.g. a semantic copy of a `Vec&lt;T&gt;` needs to allocate a new chunk of memory for a new vector and the (semantic) copy each element from the old into the new (sharing the memory of the old one would result in two owning pointers to the same memory, both of which think they have sole responsibility for freeing it; this leads to bad memory safety violations). For some types, a shallow byte copy is a perfectly safe semantic copy; e.g. `int` can by safely duplicated by copying the bytes. The `Copy` built-in trait captures this information: a type is `Copy` if and only if the compiler can see that a shallow byte copy is a safe semantic copy. ([See also](http://stackoverflow.com/a/24253573/1256624).)
*nods*. Data structures are always going to be the home of `unsafe`. They're effectively language primitives. Although we're getting better at figuring out how to minimize the actual unsafe surface area. That said, you can actually implement basically any node-based data structure safely using `Rc`, and `RefCell`, but that basically shifts all the burden of safety checks to the runtime, making the resulting data structures... sucky? You can also get pretty far with a `Vec&lt;Option&lt;T&gt;&gt;` for array-based structures, but that also has similar (but much lesser) problems to the `Rc`/`RefCell` solution. It also glosses over the fact that someone has to implement Vec! :P
BTW: if you're interested in trying to clean up DList or any of the other standard collections, I'd be more than happy to provide any guidance! It can be rough getting started. Collections want to do a lot of things that Rust really doesn't want to do, and the standard libraries are the *ultimate* legacy Rust codebase (well, rustc and servo are probably worse), meaning the code you find in there can be pretty gnarly or just outright wrong. Thankfully these are *usually* just maintenance issues, and not user-facing. Usually. Still, it's a great way to learn Rust fast! HashMap, BTreeMap, and Vec are probably the most modernized collections. All three have some really cool ideas in them, although HashMap and BTreeMap probably have more generally applicable techniques (HashMap's still my favourite).
Is it more idiomatic in Rust to use two structs as you did over an enum? Say something like enum Node&lt;T&gt; { Nil, Node(T, Box&lt;Node&lt;T&gt;&gt;) } I ask because in Haskell it wouldn't be idiomatic to use Maybe in the same way.
No. You've got to define a struct.
The `deriving` automatically generates an `impl` for you, so it's not necessary. You only would need an `impl` if you wanted to write the code yourself :) (say, because you know how to apply some optimization to the cloning process for your particular type)
I'd definitely say the Option is more idiomatic. Though I don't go through much code in the Cargoverse. Still, `Option&lt;SomethingReferenceLike&gt;` is our go-to way of expressing "nullable pointer", which is the idea we want to express here. From an actual technical perspective, the Option form can benefit from some specific enum optimizations, at very least. `Option&lt;Box&lt;Foo&gt;&gt;` is optimized to a nullable pointer. Also Options are often needed for their ability to be `take`n. Otherwise you run into a lot of "use of partially moved value" errors.
I'm working on the TrieMap Entry API implementation as we discussed on Github :)
Alright, cool, thanks.
Any plans on a bi-directional map? Most languages don't seem to have it in their standard libraries, but it can be very useful. Rather than a mapping between a key and a value, it's more of a mapping between a key and a key. Basically, it's a `Map&lt;A, B&gt;` that can also be a `Map&lt;B, A&gt;`.
I think it's worth it. I honestly don't feel that two levels of unwrapping is that bad. If you care about differentiating not found and network errors, it's between: match val { Ok(x) =&gt; // Success Err(e) =&gt; match e { SearchFailed =&gt; // Nothing found _ =&gt; // Network error } } or match val { Ok() =&gt; match v { Some(x) =&gt; // Success None =&gt; // Nothing found } Err(e) =&gt; // Network error } And these can both be condensed down into 5 lines by merging the two match statements. If you don't care about differentiating network errors: match val { Ok(x) =&gt; // Success _ =&gt; // Nothing/fail } or match val { Ok(Some(x)) =&gt; // Success _ =&gt; // Nothing/fail } Besides the type signature, there isn't really any extra verbosity.
Okay, another question. I'm getting double keypresses (as in keypress on key_down, keypress on key_up) with con.wait_for_keypress(true); and also con.wait_for_keypress(false); which is a bug noted with Python and an earlier version of libtcod, and I don't know what is up. Do you have any idea why that would be? I downloaded libtcod 1.5.1 from the website, I've tried it with both the .so included, and compiling it myself.
In go, strings are constants represented as immutable array slices stuffed with [byte values that can be converted into] 32-bit integers (unicode code points/"runes"). Rather, I guess, strings are mutable until they become bona fide strings. var s = []byte{102,110,111} // byte slice fmt.Println(string(s)) // "pno" s[0] = "f"[0] s[1]++ fmt.Println(string(s)) // "foo" but... var s string s = "fno" s[1]="o"[0] // cannot assign to s[1] They can be concatenated pretty easily, though. Depending on the approach taken, there might be a lot of overhead. `str += "foo"+"bar"` or `str = strings.Join([]string{str, "foo", "bar"}, "")` ... and a lot of other ways to do it. edit - correction
Definitely, I'll continue my adventure with algorithms and data structures in rust, and hope to help with something soon!
I needed this earlier today. Would be *great* to have.
I agree that this wording should probably change. Moves are still copies. Feel free to open an issue about this.
When you say: &gt; Rust can do better. Do you mean, a better Rust implementation, or better Rust compiler?
*ahem* compl**e**ment.
Tuple Struct?
I went through a very similar thought process and program evolution when implementing FizzBuzz, though I never made it to the last step. I really like the idea of using an Enum here. Thanks for this!
Any plan to support boost-like instrusive containers? 
&gt; In go, strings are constants represented as immutable array slices stuffed with 32-bit integers (unicode code points/"runes"). Minor point, they're actually UTF-8 (by convention), i.e. arrays of bytes that encode code points/runes. (Unlike Rust, it's perfectly legal to store invalid UTF-8 in a string in Go.)
Tuple structs don't have named fields either. Sometimes I do wish Rust had anonymous structs or allow defining types in structs (using structs like mods).
My bad - thanks for the correction. A rune is an alias for int32 but a string is indeed a slice/array of bytes, which is of course an alias for uint8. So, `str[i]` gives a byte value, where the conversion `[]rune(str)` would let you range over the runes.
I almost feel like this warrants a public trello board or something - reddit isn't exactly the best way to track progress on a lot of tasks.
You can also solve the problem by defining a temporary boxed string outside the scope. Note that temp_string is immutable, so this approach is fairly safe (but it can still be fairly messy for large functions.) fn fizz_buzz(imax: uint) { for i in range(1, imax) { let temp_string; let result = if i % 15 == 0 { "FizzBuzz" } else if i % 5 == 0 { "Buzz" } else if i % 3 == 0 { "Fizz" } else { temp_string= box i.to_string(); temp_string.as_slice() }; println!("{}" , result); } } fn main() { fizz_buzz(10) } Random question. Is it possible to solve the problem by letting result be a reference to a trait object? I tried to do something like the following, but it didn't work for me let result: &amp;std::fmt::Show = .... EDIT: Is it possible to define some sort of box with the lifetime of a parent scope? AFAICS that would allow me to define temp_string in the innermost scope.
If most of libcollections is bad, why not rip it all out to Cargo packages? (Then again, that's what I'd say to most things...)
See Boost.Bimap for a very general implementation of this in C++.
`HashSet` should have a `find_equiv` method. Right now just in order to get around that I have a `HashMap&lt;&amp;Foo, &amp;Foo&gt;` where the key and the value are the exact same object. It feels like a bit of a waste. 
`find_equiv` is on the way out in general.
How does it define it? Also, in Rust, the shared data between threads use case is already safely handled with the `Share` trait, which expresses that a type is threadsafely accessible through a `&amp;` reference. (Which implies that the type has either none or threadsafe inner mutability)
There are redundant checks in author's solutions, and the code is not composable/extensible. Consider the *FizzBuzzHissHowl* problem, where *Hiss* and *Howl* are printed for multiples of 7 and 11 respectively. You end up with a very long list of enum entities, and adding one more becomes a pain. [That (pdf)](http://themonadreader.files.wordpress.com/2014/04/fizzbuzz.pdf) is the solution in Haskell. Can you please explain how to get the same in Rust? Functions are first-class citizens, so there should be a way.
The main alternative is Scaleform, which many more game devs will have experience with. Game devs in general tend to be unfamiliar with web tech.
Interesting. I've only ever used the realtime check for keypress (which lets you filter the actions). This is usually what you want if you ever want to do things like animations, fade out, etc. Anyway, I've reproduced the behaviour you're seeing locally and based on the [libtcod changelog](http://doryen.eptalys.net/files/libtcod-CHANGELOG.txt) it's been fixed in 1.5.2. I've tried that out and it does fix the problem. I can't do any more extensive testing of 1.5.2 right now, but it seems to work and based on the changelog they didn't change the API so if you're feeling adventurous, you can try it out :-). Otherwise, I'd recommend using `check_for_keypress`. It might make your game loop a bit more complicated, but you'll have more flexibility later. Alternatively, you could ignore the "key released" events.
The `box` is not necessary, `temp_string = i.to_string();`compiles and runs perfectly ok. For sized, affine (non-`Copy`) types like `String`, `Box&lt;T&gt;` and `T` are essentially semantically identical, with little benefit gained out of `Box`ing unless `T` is very huge, or if `T` is a recursive data type. (Also, this solution is actually mentioned with caption "Taking a reference while storing the owned string in the outer scope: this works. ")
I think the trie code could be removed, and even though it just got a nice overhaul, you could make the case that a btree isn't needed in a standard library. Everything else seems pretty fundamental, though.
I'm not opposed to leaving important things in, but if I was Rust Dictator, I'd _almost_ consider moving EVERYTHING that isn't libcore. But I might just be scarred from 20 year old Ruby code that went to the stdlib to die...
All blocks introduce a new scope level. It would be inconsistent for an `if` block not to.
Not extensible? How tragic! But seriously, when you end up with something that’s a dozen lines long, you don’t worry about designing for extensibility—it’s simply a waste of time. If you want to add more, *then* you can worry about making it extensible, either by extending the inextensible or by rewriting the whole thing. Redundant integer comparisons? Terrible! But in practice, that can be *executed* very quickly, and it’s avoided string concatenation altogether which is by comparison very slow. In FizzBuzz we get 2² = 4 branches, and with FizzBuzzHissHowl we get 2⁴ = 16 branches. And you know which will be faster, the string concatenation or 12 “superfluous” checks? Yep, the one that doesn’t need to touch heap memory. But if we want to go with the one that takes less code, that can be done easily enough too. (I’m not intending to actually translate that Haskell thing into Rust, though someone else is welcome to.)
No, unsafe code is not required to implement the vast majority of data structures. It's possible to implement a hash table, trees without parent pointers, ring buffers, singly-linked lists and plenty of other data structures without reference counting or unsafe code. Using `Rc` / `RefCell` allows expressing trees with parent pointers, doubly-linked lists and so on without `unsafe` code. A highly optimized implementation will usually require some unsafe code to avoid unnecessary overhead but that doesn't mean it can't be done without it.
Yeah, it occurred to me as I was polishing the article for publication (with `enum { Word(&amp;'static str), Number(int) }`, and I liked it so much better than I went back and replaced that part!
&gt; Basically, as far as Rust is concerned, a doubly-linked list is 100% unsafe (and it's not wrong, there's a reason we use it to teach undergrads how to use pointers). Rust allows building a doubly-linked list or tree with parent pointers in safe code with `Rc` and `RefCell`. The need to use unsafe code for an optimized implementation *does not* mean that it cannot be expressed without unsafe code.
Improvements to the Rust compiler are only necessary when it comes to adding more SIMD functionality. There's no compiler problem blocking code with performance on par with C and C++ beyond that.
The `mem::swap` implementation hasn't been touched in over a year. Did you mean something end like the `swap` method on slices?
Having a trie implementation that only supports int keys seems _really_ non-core to me. btrees are pretty useful for achieving compactness, though, as are tries that support string keys (bit or char) - as well as having some other nice properties.
*FizzBuzz* is a toy problem that reveals real software engineering problems. You say the lack of extensibility is not problematic, then why wouldn't you be satisfied with repeating println multiple times? Because in the real world it can be not a single println, but a whole block of complicated code. You say multiple checks aren't a problem, but in the real world it might be not two integer operations, but traversing a giant data structure. And I talk not only about execution speed, but about code duplication too. When you're solving *FizzBuzz*, you are actually solving a very complex control flow problem. And your answer is basically "screw control flow, it's just FizzBuzz, who cares?".
Is the dependency on OpenSSL a design decision or a temporary solution until *something better* is available for Rust?
Tries and btrees are definitely useful, but I don't think that means they have to ship in a standard library. If you get to the point where you need a trie or a btree, there's a good chance you want a particular variation for a specific use case.
Will do! I haven't contributed to any OSS before (or really used github), so it might take me a bit to get up to scratch with the process. This seems like a pretty simple fix, so I might have a crack at it if I can figure out the process :) Is it good form to open an issue if I'm working on fixing it and it's this simple, and if so should I mention that I'm working on it when I create the issue?
For small things like this, making an issue first before a pull request is overkill. If it was something bigger, where maybe you wanted to get feedback before you invest the time, opening an issue first can be good.
Sure, fair enough. I generally just consider Rc+RefCell a nonstarter for collections (because what's the point of a slow collection?).
*Touché*! In reality it’s all a balancing act.
perhaps, although not having basic variants in a standard library most likely results in the utilisation of inferior algorithmic options for use cases in which they'd be applicable, since they are more readily available, and more trusted.
Haha, a bit of hyperbole there, I'll admit. Most of libcollections is *okay*. It's not great, for sure. I think there's value in covering the *standard* gamut of collections. In contrast to you, I'm scarred by the Javascript ecosystem where they give you an associative arraystack and something that's mostly a hashmap and tell you to have fun. *shudder* That said, popping out DList, LruCache, TrieMap, and EnumSet have all been variously suggested because they're a bit half-baked or random. TreeMap is mostly a functional carbon-copy of BTreeMap which scales worse, and SmallIntMap is also kind of weird (it's just a Vec of Options!). I got a vague pushback when I suggested actual cullings of collections. If you want to champion the lean-and-mean philosophy there, be my guest.
I would wager that if a standard rust TLS library becomes available it would replace openssl, until then...
If one had to go, I'd make the argument for keep BTree, kill TreeMap myself. But I'm a bit biased. :P
I was thinking about Mozilla's NSS, perhaps servo uses (or should use?) it. There's some bindings on github but they are outdated. I actually don't know why OpenSSL is favored over NSS. [This discussion](https://github.com/servo/servo/wiki/Meeting-2013-10-28#rust-http-ssl-support) was about it, but it was from last year..
Awesome, thanks! I'll get on to it.
Maybe create a meta-issue on GitHub?
&gt; TreeMap is mostly a functional carbon-copy of BTreeMap I see you're into rewriting history. :P
Naturally. It's the pastime of champions! :D (The *spirit* of the statement holds-- they're the same data structure, just with slightly different performance characteristics)
A lot of these are just "cool avenues to explore", and not necessarily appropriate for an issue. I dunno, though. Maybe someone on the core team can give some insight there.
I think an issue would be useful. We have the 'metabug' issue for a reason. You can use the checklist syntax to make a nice todo list in the issue: - [ ] blah - [x] bleh - [ ] blurgh It would be good to coordinate so folks don't step on each others toes.
If this post seems devoid of purpose to you, it might be because you don't know that ELI5 is supposed to mean "explain like i'm 5". This comment was brought to you by Stupid Internet Slang FTW Inc.
I'm not particular either way, the concern was that most applications that specifically need a btree (as opposed to needing a sorted map and not really caring about the implementation) are also somewhat likely to need some additional specialization as well.
Servo uses OpenSSL because rust-http added support for it. We're pragmatic.
Rust used to have structural records, but they were removed. So no.
The thing is that BTreeMap is faster than TreeMap a lot of the time already (and as my list notes, it's not even really optimized). The ability to choose B also represents a light-weight way to optimize for your usecase in a way that TreeMap can't provide. What does TreeMap provide over BTreeMap? Better worst-case guarantees and less variance?
You've missed the joke, which is that brson was suggesting that our performance in that benchmark was a reverse compliment... an insult. :)
Here's a Rust implementation of FizzBuzz inspired by Haskell: https://bitbucket.org/iopq/fizzbuzz-in-rust . Perhaps this answers your question?
Regarding augmentations to collections iterators, there was a point where I wanted a pop iterator, but I couldn’t find one, so I [wrote it manually](https://github.com/ruud-v-a/robigo-luculenta/blob/master/src/pop_iter.rs). Behaviour is similar to `into_iter`, except you don’t lose the remainder of the collection if you stop iterating early. Would such a thing be useful in libcollections? Something completely unrelated: I recently saw [Rich Hickey’s Transducers talk](https://www.youtube.com/watch?v=6mTbuzafcII). I haven’t thought about it in detail, but it might actually be possible to work out the types in Rust. If it is possible, that would be a nice generalisation of iterators. Has anyone looked into this?
I didn't say TreeMap provided anything over BTreeMap; I haven't looked closely enough to know either way. Given that you just put so much work into btree I wouldn't be surprised at all that it was in better shape right now. The point was that users shouldn't be too concerned about the specific data structure chosen for their standard-library-supplied general purpose in-memory sorted map (any option comes w/ tradeoffs). On the other hand, someone specifically deciding they need a btree probably has a good reason (usually related to how the nodes are stored) which is likely to require a specialized implementation anyways. So basically this is an argument that if BTreeMap is fundamentally superior to the current implementation of TreeMap, it should just become the new TreeMap, instead of being advertised as a btree when nobody will be able to use it for real-world btree-specific use cases anyways.
I think there's an advantage to *not* allowing custom comparators in sorted collections. It's nice to be able to reasonably assume that two instances of `TreeMap&lt;T&gt;` will have the same ordering. If new zero-cost wrapper types can be created quickly and easily (thereby allowing you to simply create a new type with the desired `Ord` implementation), then there's no need for custom comparators.
There is an extremely elegant solution in the hacker news comments on this story, if anyone hasn't taken a look at it: for i in range(1i, 101) { match (i % 3, i % 5) { (0, 0) =&gt; println!("Fizzbuzz"), (0, _) =&gt; println!("Fizz"), (_, 0) =&gt; println!("Buzz"), _ =&gt; println!("{}", i), } } Credit: https://news.ycombinator.com/item?id=8447267 
The simplest way is just to remove almost all the lifetimes and `Box`es, and turn all the `&amp;str`s into `String`s like this: http://is.gd/SYiUlP Then I went back and replaced some of the `String`s with `&amp;str`s again where the string didn't need to be owned: http://is.gd/pzWjlT I'm not sure what your current mental model is, but I'll explain the changes I made there: * Lifetimes are only for things you *don't* own. `PluginHook`'s `name`/`desc` fields, for example, don't need to be pointing into any other string, they *are* the string, so I used `String` instead of `&amp;'h str` * `String` is kind of like `Box` for `str`s, so there's not much point having a `&amp;String`- if you own it use a `String`, if you just want to borrow it use a `&amp;str`. * `Box` means heap allocating something. You probably don't need to box all your `PluginHook`s, as using something by value already transfers ownership. * `let mut x` means the variable `x` itself is mutable, while `&amp;mut T` means the T is mutable. So I removed some unnecessary `let mut`s that rustc warned on. There's probably more cleanup possible, but that solves the ownership/lifetime issues.
I'd rather go full-in on OrderedMap and UnorderedMap at that point. Our collection naming conventions are just all over the place right now. For BTreeMap at least, being able to configure B only makes sense for such an impl, so it would be weird to just call it TreeMap.
Only problem here is the duplicated prints which is what the article spent the majority of the time trying to optimize out. 
Some interesting points. Here's the argument for comparators: * They can be part of the type (similar to hasher on HashMap), so two TreeMap's of the same type still have the same ordering. Default parameters should be able to completely hide the comparator stuff to someone who doesn't care. * Making wrapper types and implementing Ord is cumbersome at best. * If you want to accept or return a TreeMap. You either have to make the user go through hoops to get at the desired value, or are completely out of luck if they expect a concrete K/V but you want to reverse the order or whatever. * In the case of PriorityQueue, getting a reverse ordering is especially non-trivial, as you can't just iterate in reverse.
you would do so with a closure: let database = database::new() let req_handler = |incoming: Incoming| { handle(incoming, database) } let server = Server::http(Ipv4Addr(127, 0, 0, 1), 1337); server.listen(req_handler).unwrap(); not saying this is better or worse, just that it is possible :-)
Do you expect people to spend a lot of productive time tuning B for an in-memory map? Even if there were large performance gains available they're going to derive from cache size, and B could probably be tuned up front for a set of common architectures and then nobody has to touch it ever again.
According to [your docs](http://hyperium.github.io/hyper/hyper/server/trait.Handler.html) `Handler` must implement `Send`, which means that closures can't implement this trait. EDIT: it should be feasible with a `proc` and an `Arc` 
not my docs (this isn't my lib :-)) and the latest version suggest the signature has changed.
I genuinely have *no idea* how people optimize their programs. I think it's certainly a reasonable thing to offer, though. You're getting exactly at the heart of this bullet-point, though: &gt; Investigate a richer default B-selection algorithm for BTreeMap's default constructor than "6" Note that cache-size isn't the be-all-end-all. For instance, some keys take more or less time to compare. If a key is slow to compare, it may make sense to crank down B to optimize for fewer comparisons and worse cache.
Okay, yeah, using 1.5.2 worked. Thank you for all of your help, sir!
Interesting! This might have to do with the fact that we pass it by-value a fair amount. I'm not sure how rust/llvm optimizes it. Can you post the patch? I'd be interested to see your impl. BTreeMap is already in a pretty good place anyway since we track the depth (which is uniform across all leaves). I expect better gains on TreeMap, which is surely resizing a fair amount on taller trees. Maybe just making its search stack `with_capacity(10)` would be enough, though.
As the person who wrote the previous version of this particular benchmark, I'm happy to see it improved! I was happy to have a functional solution, since none existed, but I knew there were improvements to be made (aka, it kinda sucked).
[Here](https://github.com/gereeter/rust/commit/10d4442586ce87e9108e0cb4f736019f530f9ad6) is the patch. I'm currently checking to see if removing the bounds checks on the array helps, but I don't expect to get anything positive.
Okay yeah, you did the sort of thing I was thinking of. That's too bad :/ Have you experimented with uint::BITS/2 or /4? This would be sound for sufficiently large B. I'm curious if it's just size that's the issue. If B ever becomes part of the type, this might be usable... ah whatever, it's probably a deadend.
My use case is this: I have a struct that owns one of its fields to struct Foo { owns: Bar, &lt;- Only thing that is hashed and checked for Eq metadata_1: ..., metadata_2: ... ... metadata_n: ... } Now I have a hashmap `HashMap&lt;Foo, somethingelse&gt;` and a `&amp;Bar` reference. I *need* to be able to look for a value in the hashmap without being forced to 1. Own the Bar object. I only have a reference to a Bar so I can't wrap it in Foo even if I wanted to. 2. Reconstruct all the metadata.
I can't think of any situation where I'd want to accept a Tree of a concrete type where I would not also be implicitly relying on its ordering. If the specific ordering isn't important you'd just accept a `Map`. Allowing custom hashers/comparators complicates any operation that operates on multiple maps/sets, e.g. making it impossible to correctly define (Haskell-ish pseudocode): union :: Set a, Set b =&gt; a t -&gt; b t -&gt; SetView t because a and b may have different equivalence relations. Adding the hasher/comparator as a type parameter partially solves this if you're willing to only operate on Sets of the same type (no unions of HashSets with any set that does not have a Hasher type parameter). Of course if creating new wrapper types is too cumbersome then this is all moot. I thought it might be easy, but I'm very much an outsider, not very familiar with the language yet, this is just my 2 cents.
Rust's safety rules make all collections trivially concurrency-safe already. The only way to create a scenario where you need an explicitly ConcurrentHashMap would be to bypass that with UnsafeCell, I think. That makes them fairly niche. Not something we'd need in std right now.
Collections Reform will introduce a Borrow trait for abstracting over equiv-like things.
The biggest practical problem with flat enums seems to be importing and re-exporting them. I just moved several enums to lib crate root, because the match statements in submodules take care of exhaustiveness whereas re-exports don't. I wonder if anyone has suggested changing the use syntax to handle the issue, something like `use enum`? Of course that can easily be seen as a wart to cover a wart.
My pleasure, good luck with your game and Rust endeavors! The bindings are far from finished so if there's something you need feel free to open an issue (or send a pull request :-)).
Honestly PriorityQueue is the primary motivator. Simplifies the min/max-heap situation. Introducing a wrapper is just a lot of tedious boiler-plate. It's not the end of the world, just something I'd rather not force people to do to make a max-heap or whatever.
Oh hey, thanks for posting this. I'm going to be splitting it up into quite a few parts. Here's the third: http://tmblr.co/ZYXl-x1T3Vako
+1000000 to this. This is the intuitive way of handling things, as well as consistent and convenient. A pure win for Rust.
You can rip my HTTP 1.1 from my cold, dead fingers!
I've been digging in to the TrieMap code recently and very much agree. I needed a trie with non-integer keys a while ago and ended up writing my own: https://github.com/michaelsproul/rust-generic-trie My implementation differs from the TrieMap in that it treats the keys as explicit lists (I need this for the two places I'm using this code; in Iron's mounter and my file-copying tool). There's a note in the TrieMap code about using a trait to make it generic, and I think with this addition it might warrant inclusion in the stdlib. That said, I think a Cargo package would definitely be safer, as I don't think this code has seen a lot of use.
What's a good way to read the body of a response? This is kind of what I've settled on. Are there other better ways? let mut response = match stream.send() { Ok(response) =&gt; response, Err(err) =&gt; fail!("Failed to read response {}", err) }; let mut body = MemWriter::new(); copy(&amp;mut response, &amp;mut body); let output = String::from_utf8(body.unwrap()).unwrap(); 
https://github.com/rust-lang/rfcs/pull/235
Removing the bounds checks and eliminating some drop glue checks reduces the number of branches but has no measurable effect on runtime. Seems like the benchmark needs to be parallelized, though even on 1 core the OpenMP C++ versions beat the Rust: http://benchmarksgame.alioth.debian.org/u32/benchmark.php?test=revcomp&amp;lang=all&amp;data=u32
how would you create an in-memory cache (e.g. of common master data) that needs to be *simultaneously* accessed by X threads responding to HTTP requests?
Coming from Java, that's how I expected it to work. I was subsequently both disappointed and confused. Some variants like `Some(), None, Ok(), Err()` work well in the global namespace but stuff like the `serialize::json::Json ` variants would work better like this. I would gladly lend my help refactoring the libs so we can have this feature complete by 1.0.
Why were they removed (and tuples were not)?
AFAIK Windows XP is not supported. Whether that means it's possible to get it to run or not, I don't know.
I actually prefer this use of "tuple match", it seems like a direct translation of the problem, without meta-reasoning that 3x5 is 15 and need to be tested *first*. However, I feel I have to point out that this would make it much more different than Python, and then muddies up the purpose of the article which is less about FizzBuzz and more about `String` and `&amp;str`.
Yessir! Will do. (Actually already opened an issue, for the update to 0.13 :P)
Me? Wrap it in one of our cool [Mutex types](http://doc.rust-lang.org/sync/struct.Mutex.html), I guess. Someone who actually knows what they're doing could probably answer better, though. Edit: [RWLock](http://doc.rust-lang.org/sync/struct.RWLock.html) is probably a more appropriate choice here.
Aka: Boost.MultiIndex :) Might be overreaching though?
Oh, for sure, the article is making great points about ownership and the difference between String and &amp;str. 
Rust emphasis *not sharing* memory, so most people should not find themselves in a position of actually needing this, and a low-performance alternative is wrapping in a `Mutex`. That being said, I would value multi-thread-safe implementations of common collections (just because high-performance implementations are so hard to get safe), but it would probably be best in a *dedicated* crate even if it ends up being standard.
Thank you for this proposal. I really want this.
Personally I first stumbled on the problem when attempting to write a simple and functional cons-list: enum List { None, Next(Box&lt;List&gt;) } Seemed perfectly reasonable (or something like that...). Except that because `Option` also uses `None` I was left with a mess of error message everywhere which surprised the hell out of me. The risk of collisions has thus stuck with me as the most annoying thing. And coming from C++ where C++11 introduced `enum class` to get scoped enums because the default of unscoped ones (inherited from C) was perceived as a wart did nothing to change my mind :/
Yes, but this is a global lock. I am talking about striped locks with multiple segments within a concurrent hash map...that's what makes a Java ConcurrentHashMap so performant. Simple Mutex or RWLock does not cut it when you are doing 10,000 requests per second and there is a background thread occasionally updating the cache with new values from the DB.
fiddle would require you to install the library yourself and in a certain path. See also my other comments about Ruby &lt;-&gt; C marshaling too... I forget if Fiddle makes that nice.
Not currently. We have the ability to do it, I think... But since we don't do overloaded functions, it would have to have a different name, not map.
Meaning a comparator which maintains some state internally? I suppose you'd have to have a (semi-?)global variable to emulate that. I confess I hadn't thought of that, don't think I've ever seen a comparator which wasn't a pure function. Is there a use case for such a thing?
I found that the first name collision that I had was on `None`. But then I thought to myself, if `None` is a valid option, you should probably just use `Option&lt;EnumType&gt;` instead. Is this a valid observation or is it perfectly legit to have your own `None` variant?
Here was the issue: https://github.com/rust-lang/rust/issues/3089 And the commit: https://github.com/rust-lang/rust/pull/5249 Trait coherence was the issue, I think... I still find is a little asymmetrical, but eh.
Wow, Rust, I had no idea that this is how it *didn't* work. Look, Java and C# got this right, to begin with. (C# does it better than Java, imho.) C++ *fiiiiiiiiinally* got this right with "enum class". PLEASE DON'T FUCK UP AND REPEAT THE C++ DISASTER.
Oh yeah, sorry I didn't even look at refactoring the lifetime names. Normally we just go with 'a, 'b, 'c, etc. in increasing order because "proper" names would usually be meaningless and noisy. Looks like they just went for 'h for "hook" and 's for "string" or "system". The `: 'h` syntax is similar to applying a trait bound on a type. Like `T: Show + Ord`, but instead of requiring it to implement a trait, it's requiring it to live at least as long as the lifetime `'h`. For closures in particular, this means that it can't close over any values/references that might expire before before `'h`, which of course is necessary for safety.
Why can't it be vetted and standardized outside of the core rust language?
The commenter specifically says "putting the String issue aside..."
Haskell made this same mistake, and I've always found it annoying to have to manually do name mangling on its ADTs. +1 to fixing this issue entirely before 1.0.
The standard library and the core language are separate things, and will be versioned separately. If we want to break backcompat in the stdlib without breaking backcompat in the language, we can do that. If you're asking why we don't wait until after 1.0 and see what libraries evolve organically, well, that's exactly what we've been doing for the past three years. Why wait any longer?
I was thinking about this recently myself, and iterators seem pretty damn close to transducers already! They do exactly what transducers do: transform reducing functions (eg `map`), combining them together. You get that by just chaining iterators together. Reducing functions in iterators have already had the `append` step factored out, as it is with the clojure implementation. Eg. see the definition of map: http://doc.rust-lang.org/src/core/home/rustbuild/src/rust-buildbot/slave/nightly-linux/build/src/libcore/iter.rs.html#1240-1248 It doesn't even have the `step` that Clojure's mapping transducer has. Instead, the for loop steps through any iterator, and Rust also has the `FromIterator` (the fn is `collect`) to construct any collection that implements it: http://doc.rust-lang.org/std/iter/trait.FromIterator.html Furthermore, iterator reusability is on-par with transducers, afaict. I'm having trouble finding a real difference, besides the fact that Clojure's version is lazy (I'm probably not thinking hard/deep enough). And you get huge efficiency wins too, by avoiding intermediate allocations, and the fact that llvm will optimize everything into a tight loop. Iterators are truly a marvelous creation...
So I probably don't understand the rustverse well enough. What is the difference between moving something into Cargo vs shipping it in the standard library? Why isn't the standard library a Cargo package in the first place? I was under the impression that the standard library was part of the language definition like many other languages.
It's [not pretty](https://github.com/tikue/fizzbuzz/blob/master/src/main.rs), but it's doable.
I think it's perfectly valid to have your own `None` variant. You may want to make a type that always enforces the fact that it could be `None`. `Option&lt;EnumType&gt;` enforces this, but then your basic `EnumType` doesn't enforce it, which may not be what logically makes sense for the type.
I've played over the idea of using, like, Key and Value instead of K and V before. Generic expressions can already get *very* long and complicated. Consider for instance the snippet from BTreeMap: impl&lt;K, V, E, T: Traverse&lt;E&gt; + DoubleEndedIterator&lt;TraversalItem&lt;K, V, E&gt;&gt;&gt; DoubleEndedIterator&lt;(K, V)&gt; for AbsEntries&lt;T&gt; { Which would (I guess) expand to: impl&lt;Key, Value, Edge, Traversal: Traverse&lt;Edge&gt; + DoubleEndedIterator&lt;TraversalItem&lt;Key, Value, Edge&gt;&gt;&gt; DoubleEndedIterator&lt;(Key, Value)&gt; for AbsEntries&lt;Traversal&gt; { To me, it's now *a lot* harder to pick out what the generic tokens are, and what the actual concrete types/traits are. The line has also grown *subtantially*. On the other hand, while K and V were fairly obvious by convention, E and T have been substantially clarified by the more verbose code. E is some kind of Edge type, and T is a traversal of the Edge type (so I guess Edges are actually a kind of Node). When browsing code, the short form makes it *much* easier to pick up the *kind* of type something is. Is it concrete or generic? If I want to look this thing up, should I be looking at the impl/fn signature, or looking for struct/imports definitions? For a full examination of the situation, let's also consider the new Where clause syntax, which may replace the old syntax. impl&lt;K, V, E, T&gt; DoubleEndedIterator&lt;(K, V)&gt; for AbsEntries&lt;T&gt; where T: Traverse&lt;E&gt; + DoubleEndedIterator&lt;TraversalItem&lt;K, V, E&gt;&gt;&gt; { Which would (I guess) expand to: impl&lt;Key, Value, Edge, Traversal&gt; DoubleEndedIterator&lt;(Key, Value)&gt; for AbsEntries&lt;Traversal&gt; where Traversal: Traverse&lt;Edge&gt; + DoubleEndedIterator&lt;TraversalItem&lt;Key, Value, Edge&gt;&gt;&gt; { The short form seems even *more* parseable now. I think there might be an arugment to be made for favouring T/K/V style when it's really just like, *anything*, and the more verbose style when there's something specific in mind. Alternatively, or additionally, we can consider favouring the short-form when the type is truly *pervasive*. In our favourite example, this would produce something like: impl&lt;K, V, Edge, Traversal&gt; DoubleEndedIterator&lt;(K, V)&gt; for AbsEntries&lt;Traversal&gt; where Traversal: Traverse&lt;Edge&gt; + DoubleEndedIterator&lt;TraversalItem&lt;K, V, Edge&gt;&gt;&gt; { Because K and V are basically "anything", and E and T are really just genericizing over a handful of concrete types. For instance E will only ever be `Node&lt;K, V&gt;` `&amp;Node&lt;K, V&gt;` or `&amp;mut Node&lt;K, V&gt;`. Further, K and V are basically everywhere in BTreeMap, but E and T are just some custom magic specific to getting Iterators working. But I usually just go with the short form because "that's what you do", and it of course means less typing.
&gt; Some variants... this is because those ones are in the Prelude, there's nothing else special about them.
Saddly yes, they are dropped XP :( https://github.com/rust-lang/rust/issues/12842 But I cant buy windows7. i want to run it in my laptop too (Atom).
It's actually possible that we could remove the Send requirement for Handler, but it comes at an ergonomic cost, namely, we would have to make `.listen` a blocking operation.
The lack of this and sibling module visibility have been my number one irritations about Rust. I'm glad that at least one of them might get fixed. Having said that, most of the rest of Rust is brilliant.
Thank you so much for your helpful advice. I didn't mention it, but I did actually have a simpler version of this code working yesterday, before I put in all the references, lifetimes, and boxes. It seems that I was more correct with that than my later attempts. Thanks for pointing out the Entry API, that certainly looks like a more correct way of doing that.
Transducers also require Rank2Types to model correctly, and Rust does not yet have that extension, though it is gaining the necessary groundwork with Higher Ranked Lifetimes.
This is awesome! I'm always interested in hearing what users of Iron and Hyper have to say, so please reach out or comment on anything you find sub-optimal. This is just the kind of thing we need to make web development in Rust a little more approachable.
Yes, please. 
Why not just steal it from swift, all enums have to be referenced by namespace, except in comparisons where the type inference will determine the name space and you can use .enum, eg select optional { case .Some(x): ... case .None: ... } That way you get the terse syntax and namespacing. And you don't need any special cases. 
Easily fixed, though: use std::str::{SendStr, Slice, Owned}; fn fizzbuzz(n: int) -&gt; SendStr { match (n % 3, n % 5) { (0, 0) =&gt; Slice("FizzBuzz"), (0, _) =&gt; Slice("Fizz"), (_, 0) =&gt; Slice("Buzz"), _ =&gt; Owned(n.to_string()) } } fn main() { for i in range(1, 16) { println!("{}", fizzbuzz(i)); } } Of course, one might argue that the Slice/Owned is just as redundant as the `println!`s...
No, that's because they're monadic. I think that monadic enums and datatype-style enums (i.e. where they contain data) are better in a flat namespace, which is why ML, Haskell, and Scala all do it the same way Rust does.
No, Rust is different because C++ enums can't contain data. I don't believe that Rust would be any better with `Option::None` and `Option::Some`, and it would be slightly worse. (Note that these are in the prelude, but this applies to any user-defined monadic type.)
I prefer the current behavior for the reasons stated in the RFC, but I would not be opposed to adding the ability to namespace variants if desired.
I understand how Rust enums are different with regard to semantics. However, if Rust is going to use this mechanism for the same purposes (and possibly more) than C/C++/C# does with enum, then Rust is going to have all of the same problems that C++ code does (with respect to enums). The namespace pollution is a real problem in C++. In the code base I work in, before "enum class" was available, it was mandatory that enum values defined in Foo be named Foo_*Bar*, to prevent any possibility of confusion. 
Why not just have a use for the few things like `Option::None` that would drag it out in the outer namespace and re-export?`
Pretty much this. I'd love to use a rust TLS library. OpenSSL is the best choice I have, for now.
You could do that, but it adds some boilerplate. That's what I mean by "it doesn't gain us anything, and it makes things slightly worse" for the monadic case.
I am not sure that would work with macro hygiene.
IMO... there's no need, because of rusts' heavy default namespacing. Files are already namespaces, every symbol is already namespaced.. so this would be overkill. a criticism of how C++ does something isn't necaserily a criticism here, because of that fundamental difference 
Man, I way overcomplicated things :-/
This is using the [support for CSS `@media` queries](https://github.com/servo/servo/pull/3610), currently being reviewed.
You could just make it return Option&lt;&amp;str&gt;, and branch on Some/None to print the number or the string. fn fizzbuzz(n: int) -&gt; Option&lt;&amp;'static str&gt; { Some(match (n % 3, n % 5) { (0, 0) =&gt; "FizzBuzz", (0, _) =&gt; "Fizz", (_, 0) =&gt; "Buzz", _ =&gt; return None, }) }
Use linux, Luke
Scala does this not because they are "better", but because ADTs are modeled with traits and classes quite nicely and Scala developers didn't want to introduce something even more different from Java. Moreover, with singleton objects it is possible to make scoped ADTs, like this: sealed trait Option[+A] object Option { case class Some[+A](value: A) extends Option[A] case object None extends Option[Nothing] } I and my colleagues follow this pattern quite often. And because of very powerful import system it is possible to import `Some` and `None` to use them without prefixes, so such approach is strictly more powerful than flat namespace. Scala also has [`Enumerations`](http://www.scala-lang.org/api/current/index.html#scala.Enumeration) which *has* to be scoped due to the way they are defined.
Could be. I don't know about you, but factoring out indices to be used in sets, maps etc. seems like a good idea to me, if only for code reuse. And if you have them, it makes sense to make them (semi-)public, just in fact someone finds them useful. I don't know how hard it would be in Rust though.
i say overkill because sometimes we find rust has an additional 'level' eg std::option::Option, std::vec::Vec to have to locate `std::option::Option::Some` definitely looks like overkill to me. I think its' either-or. if it was `std::Option, std::Option::Some` ... that would seem ok. I wouldn't say one or the other is "right" or "wrong" ... its just with a different starting point, other choices are better or worse. 
https://github.com/TeXitoi/rust/commit/b8786a5cbac0c0868e28000f8936ae91fd2ef926 before: real 0m0.396s user 0m0.280s sys 0m0.112s after: real 0m0.293s user 0m0.216s sys 0m0.076s best C version: real 0m0.135s user 0m0.132s sys 0m0.060s Still not perfect, but better! Waiting for review and comments :)
I think in practice we will use the re-exported `Option`/`Some`/`None` in the prelude so this is not a problem. We can always "pull up" the variants if necessary, but cannot "push them down", so I think the default should be "nested", not "flattened". 
I think the difference is that you explicitly have to iterate an iterator, which limits it to things that can be iterated over. Things that are push-based (like Rx) will not work this way. And I think there could be more re-use. For example, `Option` can use the iterator’s `map`, by doing `into_iter().map(f).collect()` (edit: no wait, that does **not** work), but instead, it has its own implementation. (True, it is straightforward, but still.)
Do you know where I can find more information about that?
I'm guessing that it's also because some designs do actually fit quite well into an inheritance model. And sometimes, an understandable design is more important than speed. It just makes some things less painful, such as direct structural reuse (otherwise you need to explicitly delegate to something to achieve the same effect, it just takes away the boilerplate of doing that).
https://github.com/rust-lang/rfcs/issues/349
As outlined in the RFC, Rust's current behaviour means that enums are very inconvenient when actually used as enums. Where you want to use them as monadic types this RFC just adds a very, very minor inconvenience: having to add a `use` statement. It improves things *immensely* for all other cases.
Thank you! I know I shouldn't use unsafe, I was looking for an equivalent of iter_swap in C++, but couldn't find anything. &gt; But you can try with matching with slices, that should enable you to do it without manually indexing and passing these indices to swap. Could you please elaborate on this? I'm not sure what you mean. &gt; About speed, did you test with -O? Without optimizations any speed measurements don't make any sense for compiled language. Yes, the iterator-version is still slower when I test them with a huge array of integers.
Thanks! Using those unsafe functions was faster. But I don't really care about speed, I just want to know how to use iterators properly :)
&gt; And sometimes, an understandable design is more important than speed. Speed is actually the motivation for adding something like inheritance. 
This is not the case.
Part of the key here is that some of the subtleties of the situation got lost in translation. The original problem: "Servo can not model the DOM in an efficient way." This telephone gamed into "The DOM is based on inheritance" -&gt; "Servo needs inheritance." -&gt; "There are some things that need inheritance" -&gt; "Rust needs inheritance" But that misses the original point. The original point was performance. We are missing an important zero-cost abstraction. The link to RFC Issue 349 lays out the actual requirements in detail: * cheap field access from internal methods; * cheap dynamic dispatch of methods; * cheap downcasting; * thin pointers; * sharing of fields and methods between definitions; * safe, i.e., doesn't require a bunch of transmutes or other unsafe code to be usable; * syntactically lightweight or implicit upcasting; * calling functions through smartpointers, e.g. fn foo(JSRef&lt;T&gt;, ...); * static dispatch of methods. It happens to be that inheritance is one pattern to make the syntax that fits these requirements palatable. But it's not strictly true. Any feature which improves upon the situation relating to these requirements is what's needed. (I'm on team "composition over inheritance", personally)
Without inheritance, Servo has to do hacks like [this](http://doc.servo.org/src/script/dom/bindings/codegen/InheritTypes.rs.html#1990-2021) to get it. We store the parent class object as the first field of the struct, and transmute back and forth (using an auto-generated trait with a manual impl to check that casting. This is *really* hacky. Some of this can be achieved with variants, but I don't think all of it can be without any similar hacks.
The rest of the thread has good stuff already :)
All I'm saying is that the requirement isn't "inheritance", but it looks like inheritance might be the easiest way to satisfy the requirements.
As far as I know, there isn't a thing to do that because you don't know that each quad really has four entries (what if `chunks(4)` is called on a vector with three elements?), and yet the patterns in a for-loop need to be irrefutable. I guess you could write an iterator adaptor transforming slices into fixed-size arrays, though. Edit: Looks like there's [some ICE around irrefutable array patterns](https://github.com/rust-lang/rust/issues/15381) or I'm just using them wrong. This seems to work though: http://is.gd/kX3Io2
Hmm... I'm using 0.12.0, so I'll update and check if this works. urgh... still getting used to snake_case :P
Oh yes, please do. Please, please please!
I'm on my phone, and don't often use tuples, so I couldnt check.
&gt; It happens to be that inheritance is one pattern to make the syntax that fits these requirements palatable. What are the alternatives? You mention composition over inheritance, how does that deal with all of the above? 
I like this mainly because glob imports would be nice to have for `enum` variants. Seriously, using enumerations for state results in a fricking import explosion.
this is why I ended up using sublime temporarily because I haven't spent time working out emacs for rust, thanks for posting this! perhaps I can switch back now :)
I'm working on a project that at least needs field inheritance of structs to represent vtables. I've essentially landed on the same solution as servo at this point (first field is the inherited type) along with unsafe transmutes. I haven't gone as far as auto-generated traits, just yet. Inheritance has its uses in some scenarios. I think it'd just be another good tool for the rust developer to leverage when it makes sense to do so.
Many of the proposals are outlined and discussed(heh) [here](http://discuss.rust-lang.org/t/summary-of-efficient-inheritance-rfcs/494)
Ok, performance is a good point - Rust, the "zero cost abstraction" language lacking an abstraction that would actually *reduce* cost is not an easy sell. One downside is that inheritance can easily be misused. Case in point: I used to teach CS introductory courses and once created an assignment consisting of 3 java classes (C extends B extends A) with a few methods basically calling each other (about 5 methods; it all fit neatly on half a page) and one method printing something and the question what this construction will print. Only one of over 600 students managed to correctly solve that one (which was kinda the point of the assignment: Even single inheritance can make it extremely hard to reason about code). So if there would be a way to perform zero-cost composition (e.g. some syntactic sugar for simlpifying the pattern /u/Manishearth lays out) it could give us an easy way to allow for single-parent composition, which would bring us at least a good chunk of the benefits that inheritance has.
&gt; Variants are not extensible; (sub-)classes are. To elaborate: it’s easy to add a subclass; it’s easy to add a new operation on enums. It’s inconvenient to add a virtual method to a base (it ripples through to existing subclasses); it’s inconvenient to add a variant to an enum (it ripples through to existing operations). Cue the [expression problem](http://en.wikipedia.org/wiki/Expression_problem).
We have a lot of codegen to bind with SpiderMonkey, so it's relatively easy to add more. Macros probably can do the job just as easily.
It's possible to write a trait or a function that safely split and transmute a slice into a slice of fix-sized arrays. Something like turning a `&amp;[T]` into `&amp;[[T,..4]]` while discarding any remaining entries that don't fit (or alternatively return the remaining entries in a separate `&amp;[T]` slice, like `fn slice_chunks_4&lt;T&gt;(slice:&amp;[T]) -&gt; (&amp;[[T,..4]],&amp;[T])`). From there, it's easy to just use existing iterators and adaptors on the slices. I tried to create a generic trait for this (that allow any length for the fix-sized array), but couldn't figure out a way to do it without it being an `unsafe` function due to having no arity in Rust generics (there doesn't seem to be a way to specify the length of the fixed size array using generics without also allow specifying types that might be considered "unsafe"). Also, this doesn't work sensibly with zero sized types, and there's no way to avoid zero sized types at compile time (one can only do `assert!(size_of::&lt;T&gt;() != 0)` at runtime). I suppose a syntax extension *might* work, but I'm too lazy to work out all the details needed to write a syntax extension :p. `macro_rules!` might work as well, but wouldn't give good error messages (and wouldn't be able to detect zero sized types...).
`chunks` returns a slice, not a tuple... it would require more type system than we have to turn the function parameter `4` (which could easily be a runtime variable) into the appropriately sized tuple. (If/when we get integer generics, we could probably have `.const_sized_chunks::&lt;n&gt;()` that yields `&amp;[T, .. n]`, which achieves the same thing as a tuple and would be usable in a `for` pattern.)
Ahhhh. I haven't actually used `chunks`. 
&gt; You mention composition over inheritance, how does that deal with all of the above? I mean solely as a modelling question, nothing to do with the performance aspects. I just mean to say that I'm on team "inheritance sucks" but realize that there's good reason to maybe add it (or something else) to Rust.
&gt; forgive me if this is well known/documented, It's all good, the modules guide is in progress. We don't have great docs here.
I am Delphi programmer, i cant switch to linux every time i need to work on rust-lang, I am thinking to use a virtual machine, but that make rust-lang have a weak point beside other languages.
That doesn't answer my question. I asked what are alternatives to inheritance, those seem to be inheritance proposals. I meant more as how would *X* deal with Inheritance, where *X* is a hypothetical language, that would match Rust's current syntax nicely. For example *X* could be C or Haskell or DoesNOTEXist language.
Linux's perf works. Maybe callgrind also works. You have to compile with "-g -opt-level 3"
Many of those proposals don't implement classic inheritance, eddyb and kimundi's one for example implements a few orthogonal features that solve the problem rather than just implementing inheritance. If you read through all the proposals you can see the different ways people are trying to solve the problem in Rust, they're not all just different ways to implement C++ style inheritance.
Oh, nice work! I was afraid we weren't going to make progress. Out of curiosity, how did you profile for this? For me, running perf and seeing one giant assembly `main` doesn't give many clues. It's a shame that `TwoSidedIterator` seems like such a special case - not sure I want that in std. Perhaps it makes sense as a default method of `DoubleEndedIterator`. I'm happy to put unsafe code into the shootout though.
Are you trying to import modules using `mod`? For imports there is `use`, while `mod` actually defines your project structure. So if you see mod foo; it means mod foo { // contents of foo.rs } My layouts usually look like this (simplified of course): // src/main.rs pub mod foo; // src/foo/mod.rs pub mod bar; pub mod baz; // src/foo/bar.rs pub static BAR_VAL: u8 = 23; // src/foo/baz.rs pub static BAZ_VAL: u8 = 42; Which basically gives you a multi-file equivalent of the following: pub mod foo { pub mod bar { pub static BAR_VAL: u8 = 23; } pub mod baz { pub static BAZ_VAL: u8 = 42; } } If you want to import from another place in the crate you can now use `use`: // import the item BAR_VAL use foo::bar::BAR_VAL; println!("bar {}", BAR_VAL); // import the baz namespace use foo::baz; println!("baz {}", baz::BAZ_VAL); If your crate is a library and you want to use it from another crate (or if you want to import from another crate) you have to prefix the used namespace: // import the item BAR_VAL use cratename::foo::bar::BAR_VAL; println!("bar {}", BAR_VAL); Note that the above makes everything public for simplicity. For complicated projects and libraries in general you probably want to be more conservative. In those cases it is also often desirable to reexport symbols (by using `pub use`) to provide a more flat API that doesn't depend on your crate's layout. I hope that clears things up a bit. Edit: For `use` there are also the `self` and `super` "pseudo-namespace" (unsure what they are really called) that are basically for importing namespaces without referring to them with an absolute path from the crate root, but I haven't used them much yet.
Ok, that worked. Thank you. 
The best C version is parallelized right? What about single thread performance?
I just have a Makefile in every project that has rules like run, build, debug etc. I bind the function keys to the different make rules and get F5 to save, compile and run *anything*. Doesn't matter what language the project is in, and doesn't matter if it's code at all (I use it for reports written in LaTeX too). This is vim though, but it should be easily applicable to any editor. As a plus, I can have arbitrary complex build steps and I can build and run anything from the terminal too.
http://discuss.rust-lang.org/t/summary-of-efficient-inheritance-rfcs/494
DSTs are not fully ready yet. You can't store them directly within your own structs or cast structs that reference them other than `Box&lt;T&gt;`, but you can parametrize over them, store references to them and store `Box`es of them. So you can still implement your `FooPtr` as you want. Change its signature to (with any additional parameters and traits you need): struct FooPtr&lt;Sized? T&gt; { ... } And make sure to specify `Sized?` on any `impl`s that require it. Then make sure that you do not directly store values of type `T` in the struct. Instead use `Box&lt;T&gt;`. You can cast `Box&lt;T&gt;` to `Box&lt;SomeTrait&gt;` by writing ` as Box&lt;SomeTrait&gt;`. The one thing you will still be missing is `as` syntax up and down casting your pointer type between traits and structs. You will have to write an auxillary function for that. **Edit:** And if you want your `Foo` trait to support `Sized?` types you need to write `for Sized?` in its definition, like so: trait Foo for Sized? { ... } **Edit 2:** Of course, if your values are not owned by `FooPtr` you don't need to store `Box`es of them in it - use a reference. The current rule is that structs that are not `Box` can store references to T and parametrized types that take `Sized? T` in them for dynamically sized `T`, but not actual values. In the future you will be able to store one dynamically sized value at the end of the struct. 
You mention storing types in `Box` to make this work. Which raises the question of ownership. My understanding, which I'm not sure is correct, is that `Box` owns the pointer and will free the pointer when dropped. If this is the case, I don't know if storing in a `Box` is what I want. The pointers I'm trying to manage are coming from an external source and have their own reference counting. I'm trying to implement my own pointer type to manage making the appropriate increment and decrement calls of the external API for the pointers it hands back. In the end, I'll be fine having pointers to the actual structs, instead of pointers to traits. I'm probably obsessing over encapsulation too much.
Sorry, very new to rust here. There's no vector type in the rust library? Is it just for nobody having done it yet, or is there a philosophical reason why they would be omitted?
I don't see how to emulate state with a global variable (or several) in Rust (due to the lack of "move constructor"/"move assignment operator"). As for a usecase, I seem to remember I had a realistic use of it at some point (maybe for an indirect sort, where all you have is an index into another data structure)... and of course there is the debugging case: it's useful to be able to pass an *instrumented* version of the comparator which logs/counts the comparisons to debug the `TreeMap` implementation or even test its complexity guarantees.
If I recall correctly, the architecture of Boost.MultiIndex is basically a gigantic node containing both the value and one specific "sub-node" per index. It thus uses intrinsic containers heavily (although hidden to the user), and has way to move from a sub-node to its containing node. I am afraid that today this would require unsafe code in Rust. Apart from that, there is of course the issue of variadic templates... because the number of indexes varies.
What do you mean a "vector type"? That means a lot of different things to different people.
I' ve skimmed through them. And they don't really present an alternative to inheritance as much as alternative *implementation* of inheritance. To put it bluntly - "What would Haskell do?".
Looks like you are running into https://github.com/rust-lang/rfcs/pull/105/files. TL;DR: it's not possible to return types containing bare traits, you have to return concrete types or trait objects.
You should definitely request the `servo` flair :)
The Servo usecase doesn't require extensibility from subclasses, like at all.
You can store DST values in a struct, but it can only be in the last field, and that in turn makes the whole struct a DST. That and the rest of the restrictions you point out are in fact the final state for DST, we don't intend to change any of this behaviour. Still to come with DSTs is being able to coerce to a smart pointer to a DST and better support in type inference. Also, you don't need the `as` for the coercions which go from sized to unsized, Rust will implicitly coerce.
Haskell wouldn't do anything like this, because Haskell is not in the business of providing guaranteed zero cost abstractions and structural inheritance does not really provide abstractive power.
&gt; cheap field access from internal methods; This actually: cheap access *through interface/base class*. For example, we know that a `Node` (base structure) has a `hidden` field, how should this be represented? For example if you have a `Node` interface which has a `getHidden` method (because a pure interface does not have a state itself), however that's not cheap access! Many languages "cheat" with a base class concept, which is both *extensible* and *has state*, however that is not possible in Rust (yet): - you can have traits, but those are pure interface (no state), and thus require a virtual call to get/set a boolean - you can *contain* a `Node` struct in your main struct, however it makes casting from `Node` to the "main" struct more difficult Thus, while it can be done in Rust (with struct), in the current state doing so requires some gymnastic/inefficiencies in other areas. A satisfying proposal should solve *all* requirements at once.
That looks very much like what I'm running into. Thanks for the info. Suppose I'll just resolve to using concrete types for now.
Hi all! This is my first piece of Rust code. I found myself writing a blog post on how to call REST APIs from Rust and wanted a more concise way to do it. Hope someone finds it useful. I'd love to hear your feedback about making it even more useful, more idiomatic, etc.
Well, I didn't profile the code. As I wrote the current version, I know how it works well. And comparing with better implementation in other languages, I realise that this loop that I have tried to optimize without unsafe code last time should in fact do a lot of check (one for next(), one for next_back(), and then 2 tests on Option/None in the match). So I just tried to limit these checks and it worked :) `TwoSidedIterator` is in fact the basic building block of `MutableSlice::reverse`. Maybe it makes sense to have such a method in `DoubleEndedIterator`, but a default implementation will not be effective in this case. You really are happy to put unsafe code into the shootout? I was thinking that unsafe is bad into the shootout. On the other side, in this case, the unsafe code is well isolated and quite easy to audit. Should I propose a PR to rust and propose this implementation to the shootout, or anyone have any comment, better idea, whatever?
Inheritance would be lower cost than what needs to be done today.
Completely agree, because servo is not using ZCA's for its current solution. It can not, as it requires a form of subtyping, currently through a hack using the first field of a struct and transmutes. It is a lower cost then the current solution, but not zero.
That sounds like a nice approach. The consistency across all projects sounds good. However, I also like being able to do this sort of thing on single, non-project files.
Hmm. I don't know enough about the language yet to know why you would need unsafe blocks with Vec. If it was C++, I would use a unique_ptr to the data and get basically the same ownership behavior that Rust seems to have.
IMO.. basically there is a spectrum.. situations with closed/open set of types; closed/open set of methods; single/multi dispatch. Different language features handle each of these situations optimally. Adding more language features helps represent each combination more elegantly. Of course if you have a low level-capable language (which rust is) - you can emulate the binary layout for anything (roll your own vtables, whatever), but maybe sacrificing safety. I think single-inheritance is a nice feature, because it's something very simple to represent at low level .. just the same data at particular struct offsets; I think its orthogonal to the variant stuff Rust has different to C++. 
You can’t `collect()` into an `Option`, because `FromIterator` is already implemented for `Option`, but for the case where you would collect an iterator of options into an option of a collected value, so you _can_ do `option.into_iter().map(f)`, but then you end up with an iterator, not an option.
Yes, you could build a Vec on top of a Box&lt;[Option&lt;T&gt;]&gt; (unique_ptr to an known-length array of safely "nullable" T's), but I don't think there's any safe way to *allocate* a block of memory of dynamically determined size. Or rather, our safe code for that *is* Vec. I suppose we could write/expose one. That function would of course just use unsafe code to call the allocator directly, though. It all bottoms out at unsafe code somewhere.
Sweet, I might use this in my Reddit API Wrapper for Rust. I'm using rust-http but I was going to migrate to hyper anyways. Though, I need to be able to specify a custom `X-Modhash` header. The API doc says it can be a POST parameter, but that the header is better for some reason. It might add too much indirection, but I might suggest to consider possibly integrating JSON serialization like [Retrofit for Java][1] does. You could even leverage compiler plugins to achieve the same brevity as it does with annotating interfaces, but with even better performance because it's doing the reflection and generating the glue code at compile time. Now that I think about it, it might even be possible to do it with regular macros! Damn, I might have to take that idea and run with it. Do you mind? [1]: http://square.github.io/retrofit/
Good point on specifying custom headers. I haven't gotten to that yet in this layer, but it's definitely going to be needed. I wonder if a fluent interface would start to make more sense so my request parameters don't multiply... Optional keyword args sure would be nice sometimes. That's how Ruby's rest-client supports custom headers, anyway. Also, integrated JSON serialization would make this even better! Go ahead and run with it. I might take a stab at it too, and we can compare notes.
Personally, I'm fine putting unsafe code into the shootout, though I'd prefer not to when we can. Benchmarks do lots of non-idiomatic things, so we should feel free to use whatever tools Rust provides (I think we have one now that just calls GMP, like the C benchmarks, which to me is more distasteful than using unsafe). I think you should make a PR.
Is this change backwards compatible?
I am confused about concurrency in Rust. I have read both that async io ops are not supported and async is explicitly used in the runtime with a scheduler but io is synchronous by default.... so I have to ask after seeing the concurrent server examples in the repo is concurrent http clients (socket requests) possible with hyper?
Why not something like: /// Implements the FizzBuzz algorithm. /// If n is: /// * divisible by 3, returns "fizz" /// * divisible by 5, returns "buzz" /// * divisible by 3 and 5, returns "fizzbuzz" /// * anything else, returns n as a String fn fizzbuzz(n: int) -&gt; String { let test = |d, s: &amp;str, prev: String| if n % d == 0 { s.to_string() + prev } else { prev }; let x = test(5, "buzz", "".to_string()); let x2 = test(3, "fizz", x); let x3 = test(8, "lulz", x2); if x3 == "".to_string() { n.to_string() } else { x3 } } fn main() { assert!(fizzbuzz(3).as_slice() == "fizz"); assert!(fizzbuzz(5).as_slice() == "buzz"); assert!(fizzbuzz(15).as_slice() == "fizzbuzz"); assert!(fizzbuzz(7).as_slice() == "7"); assert!(fizzbuzz(8).as_slice() == "lulz"); } ? I'm new to both rust and haskell so I honestly don't know, but it seems to have the same conceptual idea. Meaning it allows you to extend fizzbuzz will minimal(ish) changes.
I feel your pain. The first non-trivial program I finished writing in Rust is an implementation of 'pstree'. Naturally, I wanted to use a tree structure -- I ended up getting it to work but only after learning that there were a few things (parent pointers) that were not worth including. For this particular application, the parent pointers would not have added much anyhow. Code for anyone interested (review *very* welcome): https://github.com/posborne/rust-pstree/blob/master/pstree.rs Building the tree is quadratic with n being the number of processes, which could be optimized, but it served its purpose of helping me learn the language. Here's my original implementation in C for a comparison: https://github.com/posborne/linux-programming-interface-exercises/blob/6b1ae2357d7c73378a56e2d7b499b4ab49c4452f/12-system-and-process-information/pstree.c The process was frustrating, but as others have noted, most of the times I got "stuck", the compiler was warning me of real memory problems. That and some just learning the language and standard library (e.g. calling iter_mut() instead of just iter()).
Thanks for the example. I had glanced over Option's take() before, but now I see where it can be really useful for transferring ownership as is done here.
Yeah take is kinda a weird double-edged sword. It's *super* useful for making safe code work, and being able to reason about it, but it's a bit of a perf-pig since has to overwrite the Option that is `take`n from. Especially sucks when it's in a hot code-path (e.g. Tree Rotation). *shrug*
It didn't take me long at all once I got off work to throw together a proof of concept! https://github.com/cybergeek94/ferrite/blob/master/src/lib.rs It compiles and runs, but the test endpoint I chose is having hosting issues. I was thinking of testing against the Reddit API but I wanted something simpler. Maybe a test page hosted by GitHub? Edit: It passes with a GitHub test page!!!
And now merged!
To clarify, this is only part of UFCS, it doesn't include the harder stuff about specifying the concrete type of self when calling a method (the `&lt;Foo as Bar&gt;::baz()` syntax).
At least theoretically. There could always be compiler bugs that break your app, but Tilde is a company that is successfully using Rust in production.
Neat proof of concept! Got me excited to learn more about Rust macros and figure out something fun to do with them. 
 There *are* companies using Rust in production. Tilde's skylight.io is the most prominent example. In that sense, if your code works and passes your tests, you can use it today! But that's not really how software development works. You don't write a piece of code and then never touch it again. You'll find bugs, and some of them will be in code from Rust, or in 3rd party libraries, or in the compiler itself. And you'll need to be up to date to move on. So there's a fair amount of work just keeping up with the Rust community, keeping track of what's going on with language changes and how things are going. And you've got to be willing to pay that cost if you want to use Rust in prod.
Since I started I've already got URL Interpolation implemented and tested grabbing vectors. This is getting really cool.
FYI, we get an ICE with this short piece of code: fn main() { let x: &amp;Str = &amp;"a"; } http://is.gd/n7We0x I'd say Rust is still in the early stage of development. I hope to use it at my day job when it reaches v3.1.
The accepted RFCs were moved to have more stable URLs. https://github.com/rust-lang/rfcs/blob/master/text/0132-ufcs.md (It's unfortunate that github has such a pathetic 404 page; they could do something like heuristically guess a "did you mean" search query based on the filename. E.g. replacing nonalphabetic characters with a space.)
Yes, pidigits use handmade ffi bindings to GMP, but with a safe interface. At lease it shows how C bindings works: http://benchmarksgame.alioth.debian.org/u64q/program.php?test=pidigits&amp;lang=rust&amp;id=2 PR: https://github.com/rust-lang/rust/pull/18056
Hello! If you do not know, using arrow keys is the worst way to browse through these slides, spacebar goes to the correct next slide :) I would love feedback on the topics of the slides, and the ways in which they are presented. I do a lot more talking than slide-reading, but I think the idea comes off well. Also note that the example links sometimes give different code then the code on the slide. I am going to finish up my toy language then post that here hopefully in a few days.
I think I heard somewhere that Rust is aiming for 1.0 by the end of the year. Is that still correct? Also: alexKoch - the current minor version of Rust is 0.12.
While this is an unfortunate bug, it doesn't impact the production readyness of the resulting binary: there is none. I think the OP was more speaking about the (runtime) stability of the runtime and given that there is almost no runtime to speak of, I am pretty positive there.
I think the goal is to have a release candidate end of this year, so i can imagine that the final 1.0 will be early next year. 
It's all good! There was only one or two more comments at the time you made that one :)
its a talk at a local meetup, on the rust language. I'm sorry if it was hard to figure out, I will make sure to be more descriptive next time. Usually I leave the description in the main comment, sorry I didn't this time. Also, please do not delete your name from the comment automatically, it only discredits you. I say a lot of controversial things ( I guess, I do not consider them controversial), but I stick to my guns, and take criticism like any person should. Also, the belief that we are all 'trying to waste your time' is just a terrible outlook on life. I make no money from posting this, There are no ads. Please be more positive. Edit: for anyone who wants to know what the wholly deleted comment says: something like "fuck you for an innacurate post title! You're wasting everyone's time!" Except in 2 paragraphs. The poster had a point :)
I hope that should be v1.3 and not v3.1 :)
For the smallest definition of 'companies': two that we know about.
A release candidate around the end of the year, yes.
I'm not sure it qualifies, but we (@asquera) rewrote `terminal.c` from asciinema in Rust and are using that for internal purposes. https://github.com/skade/rust-terminal https://github.com/asciinema/asciinema.org/blob/master/src/terminal.c
The idea is to be 1.0 around february ;)
Woo! Glad to hear it. I would argue that most people think 'customer facing' when they think of 'production,' but still, it's nice to see. Though still a bit brave at this point!
For UFCS to shine, the [Component Programming](http://www.drdobbs.com/architecture-and-design/component-programming-in-d/240008321) style provides good examples. It leads to something similar as bash-pipes. Here is a [bigger example](http://wiki.dlang.org/Component_programming_with_ranges). 
Is something like D's "auto-delegation" feature (https://news.ycombinator.com/item?id=8212028) relevant here? This kind of feature would be AWESOME for "composition over inheritance."
I think it's to prevent ambiguity because traits can have the same function names. Like: struct Foo; trait Bar { fn do_thing(); } trait Baz { fn do_thing(); } impl Bar for Foo { fn do_thing() { println!("bar"); } } impl Baz for Foo { fn do_thing() { println!("baz"); } } fn main() { let f = Foo; &lt;Foo as Bar&gt;::do_thing(); //prints bar &lt;Foo as Baz&gt;::do_thing(); //prints baz }
That's a bit too much magic for my taste, but I'd really like annotating struct members to delegate methods, e.g. (arbitrary syntax'd, don't know if it would be feasible): struct MyType { parent: ParentType::(add, remove) // delegate add and remove to ParentType … }
&gt; I tested it and it does work with CLion, but it is only useful for lexing, code highlighting and code completion right now. Typo of yours or is the plugin description not accurate anymore? Because there it says that the plugin can't do code completion.
Sorry, my mistake. It does not do code completion. Though given its lexing and highlighting capabilities, it should be easy for the developer to make it do keyword based completion (so I assumed it had that when I wrote this).
Nobody has mentioned a specific month. "Around" is as close as it gets.
Then how about this? This is about `std::num::ToPrimitive` for floats. fn main() { println!("{}", (256_i32).to_u8()); println!("{}", (255_i32).to_u8()); println!("{}", (256_f64).to_u8()); // 256.0 doesn't fit into u8 } None Some(255) Some(255) // Who told them to do saturated conversion? What is Option&lt;&gt; for? - http://is.gd/u17egk (See [Issue #10481](https://github.com/rust-lang/rust/issues/10481) and [the list of `A-libs I-wrong` issues](https://github.com/rust-lang/rust/issues?q=is%3Aopen+label%3AA-libs+label%3AI-wrong) in general. Indeed it isn't too long.)
Dynamic - static dispatch is a spectrum. Suppose you have an inheritance hierarchy Root, Foo inherits from Root, Bar inherits from Root, A inherits from Foo, B inherits from Foo. If the type of an object is A, then you can do static dispatch. If the type of an object if Root, then you have to do fully dynamic dispatch. If you know the type of an object is Foo then you may be able to do partially static dispatch because you know statically that it can never dispatch to Bar or any of the subtypes of Bar.
Dependent types can simulate inheritance with all the above requirements. You represent an object as a dependent pair (tag, payload(tag)) where the type of payload depends on the tag. Tag is an enum of all your concrete classes in the inheritance hierarchy, and payload is the type of the data associated with objects with that tag. At any point of the program you can have partial static knowledge about what the tag is, and that allows you to access particular fields in the payload, and call particular methods that are only defined on a subtree of the inheritance tree. If you arrange your payload data such that data from supertypes comes before data from subtypes, then accessing a field of a particular type in the hierarchy can be a direct memory access without knowing the exact concrete type of the object.
Yes, in D mutable thread-safe data uses a `shared` qualifier. immutable: http://dlang.org/const3.html
It's too late to abandon the &lt;&gt; syntax, right?
Interesting, will any of this allow: let mut x = 0u; let y = &amp;mut x; if x == 1 {...} // read x without mutating *y += 1; 
Why not just use the ([opensourced, free](https://github.com/JetBrains/intellij-community)) Intellij IDEA community edition? I believe PhpStorm, CLion, IDEA are all the same codebase with a different set of plugins.
That's a valid problem, yes. It also doesn't affect runtime stability, though. API oddities are present in almost any language.
Rust's UFCS is (unfortunately) the opposite of D's UFCS. It allows object.method(args...) to be called as trait::method(object, args...) and doesn't allow function(arg, rest) to be called as arg.function(rest) AFAIK.
I most certainly don't mean to be demeaning!!! :)
Thanks :)
The plugins generally lag behind the specialised IDEs, and usually don't provide all features (e.g. special library and tooling integration) when the plugin is available at all (not the case for the objc IDE AFAIK). Plugins may also not be available for CE (though not sure whether it's a technical or licensing issue, haven't used the main IJ in a long time)
It is brief, which is nice :). I love papy as an example, as it demonstrates the ML roots of rust. Depending on which meetup you're attending, explaining something as 'affine types' will probably just create more confusion than clarity. Other than that, great stuff. 
Not understood like that, just wanted to clarify 'internal' ;).
I don't think so. I'm not sure we would even *want* to ever allow that.
It feels to me like D's UFCS is more about making all D functions similar to Rust's trait methods, except with less boilerplate (something like an anonymous trait?). Though convenient, I wonder if it's really needed for Rust.
Wrong subreddit mate
/u/AztecPlayss this subreddit is for the Rust programming language, not the game. http://rust-lang.org if you want to learn more :)
I wondered because I'd like to write a `scope_exit` macro, i.e. the example code is part of a macro expansion.
I have a question. Your last example looks like this: fn foo&lt;T: Array&lt;int, (1 &gt;&gt; 2)&gt;&gt;() But... that type parameter of (1 &gt;&gt; 2) needs to be determined at compile time, correct? Couldn't one just ban expressions there altogether, since you can't have arbitrary expressions anyway? Or am I also missing something?
What is DST? I've seen it around but this community really gets friendly with their initialisms.
No, that will probably never be supported. Rust used to have features that could handle things like this for types like `uint`, but they were removed because they complicated the language. The right way to write this today would be to replace `x` with a `Cell&lt;uint&gt;`. A `Cell` allows for mutation via an `&amp;` pointer for `Copy` types.
See Niko's article [Road to Rust 1.0](http://blog.rust-lang.org/2014/09/15/Rust-1.0.html).
Oh god, not that discussion again.
In a type context, an easy way to parse Rust is to treat `&lt;` and `&gt;` as delimeters of a token tree, i.e. you match up all your angle brackets (with a trivial rule that `&gt;&gt;` counts as 2 `&gt;`'s). However, the angle brackets that occur in an expression context embedded in a type context will not be matched, so you need to switch modes and start ignoring the angle brackets. Here's an even worse example: fn foo&lt;T: Trait&lt;(1 &lt; 2)&gt;&gt;() Without tracking when an expression begins it'd go like this (this algorithm is perfectly fine in today's Rust... I use it for the symbol browser generator for Geany): * Found `&lt;`, angle bracket nest level = 1 * Found `&lt;`, angle bracket nest level = 2 * Found `(`, parenthesis nest level = 1 * Found `&lt;`, angle bracket nest level = 3 * Found `)`, parenthesis nest level = 0 * Found `&gt;&gt;`, angle bracket nest level = 1 And now we have an unpaired angle bracket and the parser never stops parsing this function definition.
You could but it'd be inconsistent with the rest of the language. E.g. today, this is legal: enum A { V = 1 &lt;&lt; 2, } const B: uint = 1 &lt;&lt; 2; Rust has something called a 'constant language' that is a subset of Rust that can be evaluated at compile time. Future extensions to the language may make it as general as C++'s `constexpr`.
Well, if it continues to present niggling difficulties in a variety of contexts, maybe it's okay to keep bringing it up.
Ah, I see; I didn't now about the 'constant language'. That's pretty neat, actually!
There are other ways to solve syntax problems than going from a familiar syntax that's easy on the eyes to an alternative that comes with it's own set of unknown problems.
Dynamically Sized Type.
&gt;Why not just use the (opensourced, free[1] ) Intellij IDEA community edition? I am using that one now, after my 30 trial of Ultimate had ended. I only used the trial period of Ultimate to check out the additional features. &gt;I believe PhpStorm, CLion, IDEA are all the same codebase with a different set of plugins. This is true to an extent, but there are limitations (as /u/masklinn has mentioned) for example the extremely advanced and very useful PHP plugin is only available on PHPStorm (and of course installed by default on that) and similarly the python plugin is only available on PyCharm, ObjC only on AppCode etc.
And then you posted to the wrong subreddit. :(
You want /r/playrust. :-)
lol im so dumb thanks for the tip. you are a kind soul
The concurrent server uses tasks (threads). It spawns a thread for every request. 
&gt;the commonly requested future feature of using values in generics (e.g. integers) Is there an RFC for this? I'm interested in it myself.
I wrote a small telco call detail record parser and report tool in rust, which is actually used for monthly reports
POST requests now available!
Dynamically sized types. This - http://smallcultfollowing.com/babysteps/blog/2014/01/05/dst-take-5/ - is probably the best description. It is basically the ability to treat types like `[Foo]` (which is dynamically sized) pretty much like regular types.
Includes a suggestion for custom coercions which allows for proper support for smart pointers to DSTs.
I love it. It's my go-to for REST stuff in Java. I figured Rust needed something like it.
Familiarity to C++ programmers, and `[]` doesn't solve the ambiguity requiring `::` because of array indexing.
Wouldn't it make sense to instead rename the bit shifting operators to bsl/bsr? I've always found "&gt;&gt;" and "&lt;&lt;" to be weird names for those operators outside of languages where you can't abstract properly.
&gt; P.S. can you give me another idea of implementing link_lists in rust ? Don't do it. There is literally no reason to implement a linked list and in languages like C/C++/Rust you will actually quickly notice how slow they actually are. To answer your question though: the swap function might help you resolve the swapping part.
This may also be a candidate for using the `if let` syntax. I've never used it though. And it may or may not be clearer. I think `if let` is applicable in any case that a match has 2 arms(?), and the last is `_ =&gt; ()`. And I guess you can use an `else` with the `if let` if the equivalent match isn't a `unit` type, i.e., if the last arm is `_ =&gt; 300` or something.
Intrusive linked lists are still very useful, but I see no way of implementing them in rust.
Regardless, it is an exercise in data structure and algorithm. It's a nice step up from FizzBuzz and HelloWorld. A lot of people get stuck after reading the tutorial, and they don't know what to do next.
Advertising a GUI without any screenshots? Madness! :P (*e:* [Here's one I took](http://i.imgur.com/yLsIqT2.png).)
I think you need to force reload the page, here I have: pidigits Rust 1.73 1.73 5,308 1297 1% 100% 0% 0% C++ g++ 2.29 2.30 1,656 682 1% 0% 0% 100%
The problem with that is that data structures themselves are really hard to write in Rust and as such not the best goal to do after doing a tutorial :)
 fn press_btn(&amp;mut self, button: Button) { if let (Keyboard(keyboard::Space), During) = (button, self.status) { self.worm_dir = Up; } } Though if there are more button events to handle, a `match` would be better.
&gt; their own problems getting them going in Rust. Then surely it is good to explore these problems, as a learning exercise? Unsafe code is not something that should be feared.
&gt; Unsafe code is not something that should be feared. Yes, it is; it's fairly difficult to get `unsafe` code correct. I've seen quite a lot of `unsafe` code that has subtle bugs. (Rust has `unsafe` for a reason, and there are good reasons to use it, but it is dangerous and should be regarded as a last resort.)
If I ever do end up needing to use unsafe someday, I'd rather do it after having learned how to use it properly, i.e. by solving simpler problems like this one. 
The problem here is `link = &amp;mut ...` isn't doing what you want: `link` is a pointer into some memory location inside `self`, and you wish to assign to that memory location to update that part of the linked list. Writing `link = &amp;mut ...` is assigning a new value to the `link` local variable, that is, it's trying to make the variable hold a new reference, not change the value at which the reference points (which is what is required here). The way to fix this is: *link = box NodeEntry { value: element, link: *link }; That is, dereference `link` to assign to the memory location to which it points. However, this also does not compile: &lt;anon&gt;:38:67: 38:72 error: cannot move out of dereference of `&amp;mut`-pointer &lt;anon&gt;:38 *link = box NodeEntry { value: element, link: *link }; ^~~~~ The problem is `link: *link` is (trying to) steal ownership of the contents of the `&amp;mut` reference. Taking ownership must invalidate the source, but `&amp;mut`s must always point to valid data, hence the compiler cannot allow directly moving out of an `&amp;mut`. A good fix for these sort of ownership juggling is [`std::mem::replace`](http://doc.rust-lang.org/nightly/std/mem/fn.replace.html) (and `std::mem::swap`, but `replace` is often what is desired). In this case, one would flip how the insertion works slightly, to update the `Box` in `link` directly, and re`box` the next element instead (rather than boxing the new value placed into `link`). That is: let old = mem::replace(&amp;mut **link, Nil); // update the internals of the Box **link = NodeEntry { value: element, link: box old }; (I guess you could also do `let old = mem::replace(link, box Nil); **link = NodeEntry { value: element, link: old }`.) [playpen][pp] [pp]: http://play.rust-lang.org/?run=1&amp;code=%23!%5Bfeature%28struct_variant%29%5D%0A%0Ause%20std%3A%3Amem%3B%0A%0A%23%5Bderiving%28Show%29%5D%0Aenum%20Node%20{%0A%20%20%20%20NodeEntry%20{%0A%20%20%20%20%20%20%20%20value%3A%20uint%2C%0A%20%20%20%20%20%20%20%20link%3A%20%20Box%3CNode%3E%0A%20%20%20%20}%2C%0A%20%20%20%20Nil%0A}%0A%0Aimpl%20Node%20{%0A%20%20%20%20fn%20new%28%29%20-%3E%20Node%20{%0A%20%20%20%20%20%20%20%20Nil%0A%20%20%20%20}%0A%0A%20%20%20%20fn%20append%28%26mut%20self%2C%20element%3A%20uint%29%20{%0A%20%20%20%20%20%20%20%20match%20*self%20{%0A%20%20%20%20%20%20%20%20%20%20%20%20NodeEntry%20{%20value%3A%20_%2C%20link%3A%20ref%20mut%20link%20}%20%3D%3E%20link.append%28element%29%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20Nil%20%3D%3E%20*self%20%3D%20NodeEntry%20{%20value%3A%20element%2C%20link%3A%20box%20Nil%20}%0A%20%20%20%20%20%20%20%20}%0A%20%20%20%20}%0A%0A%20%20%20%20fn%20length%28%26self%29%20-%3E%20uint%20{%0A%20%20%20%20%20%20%20%20match%20*self%20{%0A%20%20%20%20%20%20%20%20%20%20%20%20NodeEntry%20{%20value%3A%20_%2C%20link%3A%20ref%20link%20}%20%3D%3E%201%20%2B%20link.length%28%29%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20Nil%20%3D%3E%200%2C%0A%20%20%20%20%20%20%20%20}%0A%20%20%20%20}%0A%0A%20%20%20%20%2F%2F%20newNode.next%20%3A%3D%20node.next%0A%20%20%20%20%2F%2F%20node.next%20%20%20%20%3A%3D%20newNode%0A%20%20%20%20fn%20insert_after%28%26mut%20self%2C%20element%3A%20uint%2C%20after%3A%20uint%29%20{%0A%20%20%20%20%20%20%20%20match%20*self%20{%0A%20%20%20%20%20%20%20%20%20%20%20%20NodeEntry%20{%20value%3A%20value%2C%20link%3A%20ref%20mut%20link%20}%20%3D%3E%20{%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20value%20%3D%3D%20after%20{%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20let%20old%20%3D%20mem%3A%3Areplace%28%26mut%20**link%2C%20Nil%29%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%2F%2F%20update%20the%20internals%20of%20the%20Box%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20**link%20%3D%20NodeEntry%20{%20value%3A%20element%2C%20link%3A%20box%20old%20}%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20}%20else%20{%20link.insert_after%28element%2C%20after%29%20}%0A%20%20%20%20%20%20%20%20%20%20%20%20}%0A%20%20%20%20%20%20%20%20%20%20%20%20Nil%20%3D%3E%20fail!%28%22There%20is%20no%20element%20{}%22%2C%20after%29%2C%0A%20%20%20%20%20%20%20%20}%0A%20%20%20%20}%0A}%0A%0Afn%20main%28%29%20{%0A%20%20%20%20let%20mut%20x%20%3D%20Node%3A%3Anew%28%29%3B%0A%20%20%20%20x.append%281%29%3B%0A%20%20%20%20x.append%282%29%3B%0A%20%20%20%20println!%28%22{}%20%28{}%29%22%2C%20x%2C%20x.length%28%29%29%3B%0A%20%20%20%20x.insert_after%28456%2C%201%29%3B%0A%20%20%20%20println!%28%22{}%20%28{}%29%22%2C%20x%2C%20x.length%28%29%29%3B%0A}
Perhaps I phrased that badly. You should sure as hell be *wary* of it, and be *very* sure of yourself before you use it. But should you be *afraid*? No. You should no how to use it properly, and you can't do that without practice.
Well, I *fear* `unsafe`. I don't think wary is strong enough: as soon as you start doing non-FFI `unsafe` (especially data structures with mutability) you need to be paranoid. It's very easy to get problems with unwinding &amp; destructors (especially this), moving out of something you shouldn't and aliasing `&amp;mut`s if you're not super careful. I think it's reasonable to assume that `unsafe` that has not been reviewed by a reasonably savvy Rust programmer is incorrect. (That's not to say that `unsafe` code is automatically broken, but I don't really trust `unsafe` code that hasn't had at least two pairs of eyes on it; even my own code.) Of course, none of this is an argument against knowing how to use it properly/practicing.
The only way I can think of to deal with this case is to use unsafe code (though I prefer to avoid this). The way I would implement something similar, would be something like this (though I don't like the recursions): struct Node { value: uint, link: Option&lt;Box&lt;Node&gt;&gt;, } impl Node { fn new(value: uint) -&gt; Node { Node { value: value, link: None, } } fn append(&amp;mut self, value: uint) { match self.link { Some(ref mut node) =&gt; node.append(value), None =&gt; self.link = Some(box Node::new(value)), } } fn length(&amp;self) -&gt; uint { match self.link { Some(ref node) =&gt; node.length() + 1, None =&gt; 1, } } fn insert_after(&amp;mut self, value: uint, after: uint) -&gt; bool { if self.value == after { self.link = Some(box Node { value: value, link: self.link.take() }); true } else { match self.link { Some(ref mut node) =&gt; node.insert_after(value, after), None =&gt; false, } } } } 
I forgot about `std::mem::replace`. Yeah, that would work.
Reminds me of tuples and structs. Ideally structs and anonymous structs with unnamed fields (tuples) should have a very similar syntax. Same for this and enums. That is one thing in rust I find unnecessary complex. I don't have a real proposal but i am imaging something like this: // struct type MyStruct: ( a: int, b: int, ); // tuple (int, int) // tuple struct type MyTupleS: (int, int); // maybe one could also have these (a: int, b: int) // and the same for enums with '|' type MyEnum: ( A | B: int | ) // and the anonymous enums (A | B: int) Initialization could be done with = instead of : That was just a quick idea but I would really like to see something general and consistent. One could also include defaults in the syntax and nesting. If one could mix named, unnamed fields and defaults in structs we would also have keyword arguments. But i guess this is not similar enough to C++ and too close to 1.0
I think I agree with you on all of your points, I'm just using different words :) When I think "afraid", I mean "never touch it, ever." I guess I just feel like you need to have used `unsafe` a fair bit before you can call yourself a "reasonably savvy Rust programmer" (at least enough to vet `unsafe` code), so discouraging `unsafe` for learning purposes is setting up a paradox.
Have a look at my implementation of a Haskell like linked list https://github.com/pzol/fnrust/blob/master/src/list.rs I don't think it will be ever fast, but it works mostly.
1. Existentially quantified types do not imply virtual method calls. They exist purely for type-checking, i.e. they are "zero cost abstractions". The fact that Rust has slow "trait objects" instead should not be used as an excuse. 2. Rust would be better off if people get this whole "virtual method calls" mantra out of their heads because it leads to wrong solutions and your attempts to optimise them only makes matters worse. 3. Regarding memory usage I am most interested to see actual benchmarks which show a real impact. I concede that the variant constructor needs to be represented at runtime but I have doubts if this is as much of a problem as claimed. 4. I stand by my comment regarding misleading requirements which preclude other options. If all you can think of is virtual method calls and dynamic dispatch you will end up with inheritance and think this is the only solution. The way existentially quantified types are implemented is a case in point.
If it's anything like the previous bay area meet-ups, [yes](https://air.mozilla.org/?tag=rust).
Is [this Torque](http://torque-bhp.com/) the right torque?
&gt; Existentially quantified types do not imply virtual method calls. They exist purely for type-checking, i.e. they are "zero cost abstractions". The fact that Rust has slow "trait objects" instead should not be used as an excuse. How on earth do you have an existentially typed without some form of dynamic function call (i.e. calling a function pointer)? The whole point of using an existential is the concrete type is not known at compile time, and so the call cannot be statically dispatched. I would be very interested in hearing alternatives (especially alternatives that don't already exist in Rust, since the Servo team, full of Rust experts, don't consider the current abstractions enough). &gt; I stand by my comment regarding misleading requirements which preclude other options. If all you can think of is virtual method calls and dynamic dispatch you will end up with inheritance and think this is the only solution. The way existentially quantified types are implemented is a case in point. We can definitely think of other things; look at the way the rest of Rust works, e.g. tagged unions (`enum`) and statically dispatched calls of (trait) methods by default. (Either way, it doesn't make sense to call the requirements misleading. [This](https://gist.github.com/jdm/9900569) needs to be coded efficiently. I encourage you to try to translate that into whatever scheme you visualise (pseudocode is fine), without throwing away performance or safety.)
Is there anything the indexing syntax provides that isn't mere sugar? Personally, I'd be fine with normal traits that just provide methods. I also use parameterization much more often that indexing, but I might be biased because I started out before indexing syntax was available.
So cool!
&gt; Be that as it may, it's surely a valuable exercise. It's an exercise, the value of which is questionable. &gt; I also feel like this is a bad culture to develop - discouraging people from trying to do things I think this is where we disagree. I think it's a terrible idea to support people going down wrong paths but to support them for their efforts. We should not award them for their efforts but for their end results and no matter how do do it, a linked list will never be a good end result in Rust :)
Why is this a wrong path? A linked list like this seems like a fairly reasonable way to get a handle on borrowing and ownership.
It does seem that we are in violent agreement.
within the context of unsafe, sure. But you're not supposed to reach for unsafe first, or even second.
I strictly seperate learning code from production code. For example, I've been learning Ruby for the past 10 years (yes, I still learn stuff after that long) and have a lot of code that does horrible, horrible things. My favourite is JRuby embedded in JRuby, passing objects around that don't inherit from the same `Object` class. The whole point of the excercise is to see how the systems works and how strict it is. It yielded a lot of insight, with no practical value. My production code tends to be rather conservative, though, because it plays by different rules.
If this RFC is accepted, then it will inevitable grow in to a full scale solution to all rusts inheritance problems. I think that this could work very well. Is it be possible to handle coercercion and some kind of "struct inheritance" within this scheme? If A coerces to Parent and B coerces to Parent then A | B should automatically coerce to Parent. The syntax is bike-sheddable. I would probably prefer to spend a line to declare the join and giving it a name, but that is a detail. /// Perhaps something like this join AorB {A, B}; /// Or something like this (assuming that macros work here) type AorB = join!(A, B); If rust could start all over again, then I would love to replace all rusts enums with joins of simple structs, but that is probably a little too late to do now.
While I think Rust has succeeded in not being horrible for writing high level code with the borrow checker it's a very different experience when you write containers. But I do believe that is entirely okay. I do think though that writing a linked list in general should be avoided even as an example because it teaches the completely wrong thinking about how computers work :)
Well, for a list in the safe subset it's not that hard, actually. See my top-level answer. :) As long as it's just a little finger exercise ...
It's definitely important to separate production and learning code. My issue is that it seems like the default mode is production on this sub, even if the question is likely for learning.
That depends on what you're doing and what's already available. I would phrase it differently: It's generally a good idea to stay clear of `unsafe` unless you have a good reason not to.
Why does it teach wrong thinking about how computers work? Sure they may not be the most performant data structure, but if we restricted ourselves to only using/learning the most performant algorithms/structures I'd graduate uni two years faster.
I found this approach to be less useful. Try implementing a merge sort for this list in a way that only swaps the pointers and does not require reboxing stuff.
Of course! But if this were a doubly-linked list, rather than a single... you can't do it without unsafe.
Regarding the discussion on github about `T | T`, surely that should just be *exactly the same type* as `T`? So all union types should be simplified as much as possible, thus their representation only consists of unique types.
&gt; How on earth do you have an existentially typed without some form of dynamic function call (i.e. calling a function pointer)? The whole point of using an existential is the concrete type is not known at compile time, and so the call cannot be statically dispatched. I would suggest you read Chapter 24 of "Types and Programming Languages" by Benjamin C. Pierce, in particular sections "Objects vs. ADTs" and "Encoding Existentials". In addition Oleg Kiselyov's notes about [eliminating existentials](http://okmij.org/ftp/Computation/Existentials.html) may be illuminating. &gt; I encourage you to try to translate that into whatever scheme you visualise (pseudocode is fine), without throwing away performance or safety. I will look into this.
&gt; [...] isn't the best path Depends on your background. Don't forget the well-experienced programmers with strong systems programming backgrounds that are interested in the plumbing. They might consider reimplementing `Vec` as an exercise a fun activity. I think we actually agree on the use of `unsafe`. I just don't like your generalizations. ;)
True. But the OP is more interested in singly linked lists it seems.
I think the 'fun' vs 'production' distinction below is important. As long as I'm never going to depend on your code, I don't care what you do. But as a guideline for writing 'real' Rust code, I do like my generalizations ;)
I think that it would be good to shoot for proper sum types. A \| A **is** just A.
What? :D
It could be nice to be able to group the variants type Number = int | uint | float; type Other = bool | String; type NumberOrOther = Number| Other; fn(x: NumberOrOther) { match x { v@ Number =&gt; { // Do stuff that requires certain traits}, v@ Other =&gt; { // Do stuff that requires certain traits}, } } Perhaps the traits implemented by Number and Other should be specified in a way that is less ad hoc. 
Yes we will live stream it on air mozilla. 
Read the sidebar before posting
Sorry im not sure what your talking about 
This subreddit is for the programming language Rust. Not CS.
I was thinking of something like the following struct Employee { worker_id: uint} struct Accountant : Employee { desk_id: uint} struct Driver : Employee { car_id: uint} let workers Vec&lt;Accountant| Driver&gt; = ...// Code goes here; for workers in workers { match *worker { v @ Driver =&gt;{//.....} v @ Accountant =&gt;{//.....} } } for worker in workers { println!("Worker id: {}", worker.worker_id); } Right now you can use Vec&lt;Box&lt;SomeTrait&gt;&gt; to create a vector of disimilar objects, but it is cumbersome to perform matches. 
Yeah, wrong subreddit, man.
Yep, that's the one.
Couldn't it be worth it to just get rid of &lt;&lt; and &gt;&gt; as lsh and rsh? They always confuse me anyway, because I tend to see them as arrows and can never remember on which side the number of bits to shift should go.
It seems intuitive, however it has to be checked whether this could potentially bring issues. I am specifically wary of *generic* code, in `R | S` you expect two types, but what of the instantiation where `R = S = T` ?
Well, you enter `Rc&lt;RefCell&lt;Node&lt;T&gt;&gt;&gt;` hell.
That’s a union type, not a sum type. If you treat types as sets of possible values, then sum corresponds to *disjoint* union. A Rust `enum` is a sum (indexed by the enum tag) of products (the fields for each tag). Dual to unions, there is also a notion of intersection types. Unions and intersections become more useful, or at least more interesting, when subtyping is at play. If I have two interfaces, then their union is the greatest lower bound in the inheritance hierarchy, and their intersection is the least upper bound: IX / \ IA IB / \ / \ C1 C2 C3 `IA /\ IB` is `IX` (the interface common to `IA` and `IB`) and `IA \/ IB` is `C2` (classes implementing both `IA` and `IB`). This is flipped from the usual interpretation of union (join) and intersection (meet) in set theory, because we computer scientists draw our trees upside-down. :) 
Idiomatic unsafe Rust is an active area of research. For instance right now we treat safe/unsafe as a rather binary matter. You can either have safe references with lifteimes, no aliasing, no nulls, no dangling, no casting to ints, no offsetting; or you can have raw ptrs with no lifetimes, aliasing, nulls, dangling, casting, and offsetting. No middle-ground. I'm not sure if this is the right approach, but at very least a sufficiently motivated programmer can take the totally unsafe bits and build their own partially-safe abstractions. Still, there aren't any official or even community guidelines on how to use unsafe code "right".
Interesting. Inspired by Rust i would like some sugar in C++ for doing a ladder of these: // x=some vtable object that could be a class A, class B, ... if (auto p=dynamic_cast&lt;A*&gt;(x)) { .. do stuff with A* p.. } else if (auto p=dynamic_cast&lt;B*&gt;(x)) {... .. do stuff with B* p } maybe `virtual switch(p:x) { case A: ....break; case B: ... break;...}`// like a switch statement on the vtable-ptr of x, yielding A* p, B* p, ... Is that closer to the scenario you have in mind... being able to do an equivalent of C++'s dynamic cast, on a trait-object. Does Rust already have something similar? It does seem like something that would fit in match.. The benefit of C++ vtables/Rust trait-objects , you can have an open set of types vs a closed set of methods, but with dynamic_cast you can use the same binary layout to add open methods to a known set of types aswell. 
I'm going to make HTML slides for my talk and display them live, in Servo.
&gt;For instance right now we treat safe/unsafe as a rather binary matter. You can either have safe references with lifteimes, no aliasing, no nulls, no dangling, no casting to ints, no offsetting; or you can have raw ptrs with no lifetimes, aliasing, nulls, dangling, casting, and offsetting. No middle-ground. Do you propose to create a sort of opt-in `unsafe`, where you specify what you want use and what not?
Will this allow forced unit tests when using Rust as build script? I can also see this become useful to do some tricky platform detection. I am overall impressed by the RFC and the thought put into it!
I really like the idea of the build "script" being a Rust file itself which is compiled separately for the host platform and run. That just makes so much more sense than the C solutions, which have resulted in the complete fiasco of trying to recreate the entire Unix ecosystem inside of Windows. Fingers crossed for ending up with a cross-platform solution that feels more like "npm install" "node app.js" than "step 1 install cmake and make sure you have python 2.7 (because we don't support 3.x yet) and set the boost environment variables (you can download boost from www.boost.org), but don't try to build boost with the latest VC-C++-14-enabled CTP because boost doesn't recognize that compiler yet (though it's open source so you can add support for it yourself with just a couple hours of hacking the bootstrapper... *etc etc*" I long for the day when my grandchildren will look into my eyes and say "Papa, tell us another story about how Rust saved us from GNU autoconf!" and I'll just nod my gray head and smile, knowing the pain they will never endure....
so I take it just named unions are out the question enum Either&lt;A,B&gt;{ Left(A), Right(B) } the above works just fine in haskell 
That would certainly be an interesting project, but I was just thinking of more transitionary types between the two extremes. Or methods to do things safely on the unsafe type and unsafely on the safe type. We have this a bit, but not much. raw ptrs already have a method that returns and `Option&lt;&amp;T&gt;` for null-vs-not.
Can concur, I spent an extra year getting my degree due to waiting for my bogosort to complete. :(
I feel that this approach could be taken even further (even though that might not be such a great idea). What if instead of building an executable and passing the configuration data as serialized text via stdout, you would build a shared object/dylib with some specified entry point function that would return the configuration data directly as some sort of rust object. In addition to general cleverness, this approach would avoid the general pitfalls that follow from using text, maybe most importantly the handling of whitespace or non-printable characters.
Replacing a big C library with idiomatic, memory-safe Rust code feels pretty good :) Check out the [html5ever README](https://github.com/servo/html5ever/blob/master/README.md) for an overview of what it does and how it works.
This is super-cool! I'm interested in using html5ever for HTML parsing - in my case, scraping data from a web page. Do you know if it's possible to use Servo's CSS selector library and html5ever to do something like, e.g. python's BeautifulSoup, or lxml?
I'm not sure if Servo's CSS selector matching can be turned into a library, although I opened [a ticket about it](https://github.com/servo/servo/issues/3669). Either way, I'd love to see a scraping library that incorporates html5ever and provides a way to navigate the parse tree. It's really a complementary project, since html5ever works with any parse tree representation. A [simple reference-counted tree](http://www.rust-ci.org/servo/html5ever/doc/html5ever/sink/rcdom/index.html) is included with the library, but a production-grade scraping library would likely implement its own.
&gt; fn load_document() -&gt; Result&lt;Document, DatabaseError&gt; { let db = match open_database() { Some(x) =&gt; x, Err(err) =&gt; { return Err(err); } }; match db.load("document_1") { Some(x) =&gt; x, Err(err) =&gt; { return Err(err); } } } These `Some`s should be `Ok`s. &gt; The Python interpreter for instance has a thread local variable that contains the "interpreter state" which holds a reference to the last actual error that happened. Individual calls return NULL pointers or other indicator values. When you fail in a function you return NULL after creating an error object and storing in the interpreter state. If you call into another function and you can see that a failure indicator (NULL pointer) comes back you just propagate the failure upwards. Once something that can handle the error sees a NULL it can go back to the interpreter state to figure out what exactly happened. Should this `NULL` be `None`? (*edit* Oh, I guess /u/mitsuhiko is talking about the internal C implementation of the CPython interpreter.)
This is a nice write up. I generally agree. Moreover, I think the RFC linked is a very nice step forward. As an experiment, one approach I've taken to this "how do I handle multiple types of errors" is to extend the `try!` macro slightly: macro_rules! try( (csv| $e:expr) =&gt; (try!($e.map_err(::types::CliError::from_csv))); (io| $e:expr) =&gt; (try!($e.map_err(::types::CliError::from_io))); (str| $e:expr) =&gt; (try!($e.map_err(::types::CliError::from_str))); ($e:expr) =&gt; ( match $e { Ok(e) =&gt; e, Err(e) =&gt; return Err(e) } ); ) Where `CliError` is defined as: pub enum CliError { ErrCsv(csv::Error), ErrIo(io::IoError), ErrOther(String), } It's a pretty hacky solution the problem, but I'm not altogether displeased with it either. It sucks in that you need an extra case to handle each type of error in your macro *and* you have to indicate the type of error you're expecting when you use `try!`: let mut rdr = csv::Reader::from_reader(try!(io| File::open("wat"))); let headers = try!(csv| rdr.headers()); But the function that this is in has a return type of `Result&lt;(), CliError&gt;`, so it does by you some convenience. (Just presenting another perspective here. Again, the `Error` trait in the RFC is a much better path.)
Sounds interesting. I've not seen an error handling mechanism that I really liked, this looks at least like it may be a little nicer than most. Though, I'm not entirely sure what this buys you over java's multicatch and re-wrap (other than the fact that this looks more terse).
I am very happy about this, this sounds like it will eliminate so many match statements, and I like how a backtrace can essentially become a nested structure going back to the original cause. I very much like the idea of an operator for try!() as well.
`Either&lt;A, Either&lt;B, Either&lt;C, D&gt;&gt;&gt;` vs. `A | B | C | D` Not to mention the matching for that leads to a textual triangle that gets bigger and more unreadable the more types you add. ``` match value { Left(A) -&gt; ... Right(Left(B)) -&gt; ... Right(Right(Left(C))) -&gt; ... Right(Right(Right(D))) -&gt; ... } ```
change the return type of ```load_document``` and ```load``` to Result&lt;Option&lt;Document&gt;, DatabaseError&gt; 
What was servo using before? And besides the garuntees provided by writing a library in Rust, are there any other gains?
Ahhh you are right. Tuple indexing is now a thing so that might help a little.
I've used reveal.js for most of my talks, and the code samples are always too small :/
We were using [Rust bindings](https://github.com/servo/rust-hubbub) to [Hubbub](http://www.netsurf-browser.org/projects/hubbub/). The interface to the parser becomes not just safer, but also a lot nicer. We implement a trait rather than filling a struct with C function pointers. The new parser participates in [garbage collection of DOM objects by SpiderMonkey](https://blog.mozilla.org/research/2014/08/26/javascript-servos-only-garbage-collector/), which means we can safely hold on to a parser even while arbitrary JavaScript is running. This is essential for implementing `document.write` and other bits of the web platform. Likewise we can add whatever hooks we need to support off-thread parsing, speculative fetching of resources, etc. Also, HTML is a "living standard", and html5ever will make it much easier to incorporate those ongoing changes. Check out [html5ever's tokenizer rules](https://github.com/servo/html5ever/blob/66b9a7f7df3b93f0f2e210c3bc6c3f8fd891e451/src/tokenizer/mod.rs#L640) vs. the way it's written [in Hubbub](http://source.netsurf-browser.org/libhubbub.git/tree/src/tokeniser/tokeniser.c#n659) We can also push performance much further with our own parser. html5ever integrates with [Servo's string interning](https://github.com/servo/string-cache), which minimizes string copying. I have a branch which uses [SSE 4.2 string instructions](https://github.com/servo/html5ever/blob/e6c9cc1c457bade010226e510ca7806fa061215e/src/util/smallcharset/x86_64.rs) for parsing. I also want to experiment with [speculative parallel tokenization](https://github.com/servo/html5ever/issues/25) along the lines of [*Safe Programmable Speculative Parallelism*](http://research.microsoft.com/apps/pubs/default.aspx?id=118795) (Prakash Prabhu, G Ramalingam, and Kapil Vaswani, PLDI '10).
`?`-propagation *will* be used on random stuff, not just meaningful operations (in any meaningful sense). Say, `Map` lookups, those return `Option`. Out-of bounds accesses to `Vec` do `fail!`. One could probably argue that either one should use the other method. But, in any case: Would you really be keen on not having debug information available for that kind of stuff?
Are there benchmarks of html5ever vs other parsers?
Ideally, better library behaviour would fall out of them *knowing* stack traces are unavailable. Of course, layers of abstraction could squash this. On balance, I'd be more interested in seeing how community conventions play out without traces for now. I'm not fundamentally opposed to having them provided in the future. 
You could use [pandoc](http://johnmacfarlane.net/pandoc/) to write your slides using markdown. It supports various html backends, the "fanciest" probably being [reveal.js](http://lab.hakim.se/reveal-js/). You would need to create your graphics using an external tool. Syntax highlighting should be excellent, but I've had some problems with slightly advanced LaTeX math.
Alternative look at this -&gt; https://github.com/sfackler/rust-phf
Being able to do things safely on unsafe types might be useful. I'm also wondering if having lifetimes optionally work on raw pointers could be useful for making it less likely to make mistakes for the case of going from `&amp;'a T` to `*const T` to `&amp;'a [T]` or something similar.
I didn't even think of doing this, +1 to Rust! My favorite line is [L223](https://github.com/alexchandel/rust-gravity-worm-ii/blob/master/src/main.rs#L223), where the game object is overwritten inside its own method. It almost reminds me of C++'s placement new.
It seems SDL2 also [wants to specify](https://wiki.libsdl.org/SDL_GLattr#OpenGL) its OpenGL version. Are there examples of Gfx, Glutin, and Piston used together anywhere?
Yeah, I've seen many presenters falter with reveal.js due to the small font size, and the inability to change it with the browser's zoom level... :( Dunno if they have fixed it yet...
[And here's how!](http://www.reddit.com/r/rust/comments/2jhnya/write_slides_in_rustdoc_and_view_them_in_servo_or/)
Today I created [sliderust](https://github.com/kmcallister/sliderust), which uses `rustdoc` to convert Markdown to HTML slides. This means your code highlighting and general visual style will match the official docs, which is cool. sliderust is super barebones and mostly exists so that I can use Servo to present slides about Servo next month. That said, I'm happy to take small improvements that are Servo-compatible!
Replace NoScript with a minimal pure Rust JS interpreter :).
To add to the incredible odd list of suggestions: I use `ConTeXt` my slides. The advandage of ConTeXt is that it is layout-based, so quickly definining a slide style was pretty easy. It has a very nice `vim` package, which highlights code using vim syntax files (vim needs to be installed). I have this horrible piece of code for compiling Markdown to ConTeXt slides. The horribleness stems from the fact that most of the code was written hours before a conference talk ;). https://github.com/skade/SHSC/blob/master/context_slides.rb (SHSC stands for Skades Horrible Slide Compiler) (Usage: just pipe pandocs JSON output to the script)
I meant something like [this](http://play.rust-lang.org/?code=%23![feature%28if_let%29]%0A%0Afn%20shift%3CT%3E%28items%3A%20%26mut%20%26mut[T]%29%20{%0A%09%2F%2F%20mut_shift_ref%28%29%20is%20deprecated%0A%09%2F%2F%20replace%20is%20workaround%20for%20*items%20%3D%20items.tail_mut%28%29%3B%0A%09*items%20%3D%20std%3A%3Amem%3A%3Areplace%28items%2C%20%26mut[]%29.tail_mut%28%29%3B%0A}%0A%0Afn%20pop%3CT%3E%28items%3A%20%26mut%20%26mut[T]%29%20{%0A%09*items%20%3D%20std%3A%3Amem%3A%3Areplace%28items%2C%20%26mut[]%29.init_mut%28%29%3B%0A}%0A%0Afn%20bubsort%3CT%3A%20Ord%3E%28mut%20items%3A%20%26mut[T]%29%20{%0A%09loop%20{%0A%09%09let%20mut%20has_changed%20%3D%20false%3B%0A%09%09{%0A%09%09%09let%20mut%20items%20%3D%20%26mut%20*items%3B%0A%09%09%09loop%20{%0A%09%09%09%09if%20let%20[ref%20mut%20a%2C%20ref%20mut%20b%2C%20..]%20%3D%20%26mut%20*items%20{%0A%09%09%09%09%09if%20*a%20%3E%20*b%20{%0A%09%09%09%09%09%09std%3A%3Amem%3A%3Aswap%28a%2C%20b%29%3B%0A%09%09%09%09%09%09has_changed%20%3D%20true%3B%0A%09%09%09%09%09}%0A%09%09%09%09}%20else%20{%20break%20}%0A%09%09%09%09shift%28%26mut%20items%29%3B%0A%09%09%09}%0A%09%09}%0A%09%09if%20!has_changed%20{%20break%20}%0A%09%09pop%28%26mut%20items%29%3B%0A%09}%0A}%0A%0Afn%20main%28%29%20{%0A%09let%20mut%20arr%20%3D%20[4%2C1%2C3%2C0i]%3B%0A%09bubsort%28%26mut%20arr%29%3B%0A%09println!%28%22{}%22%2C%20arr.as_slice%28%29%29%3B%0A}), although it's not as concise as I thought it would be. It's primarily because the fact that `&amp;mut` references have move semantics and you can't use them as freely as you may want.
They haven't :(
Wonderful. Wish I would have had his last week ;) No worries, I have another talk this upcoming week! Time to re-do my slides! :)
Yeah, you did amazing work :) That DSL is to quote an acquaintance "Most excellent". Anyway I'm interested if there are more in-depth guides to html5ever? Like how to extend it further? Also the nitty-gritty of parser making. I'm interested in that since I'd like to collaborate on XML5 tokenizer. I'm wondering if I can participate even if I'm not a student, but equally newbish when it comes to parser making. 
The OpenGL version is set in the SDL2 back-end. Glutin does not have a Piston back-end yet.
FWIW, my day job is working on a several MLOC java codebase. Having exceptions print out a stack trace when there's any kind of significant error is *stunningly* useful. Say my query times out - instead of a message saying 'hey, this query timed out', I can easily find out what code path generated the query that timed out as well. I can't possibly know all of the code well enough to reliably divine where the problem came from, and the stack trace gives me great clues on where to start looking. It's particularly important when I don't have access to the system with the issue. Now, maybe that timeout should be a fail rather than an error - but that means that (assuming I avoid failure in libraries), the point at which I start to get line numbers is before any library code. In general, I'd be happy enough with a solution that allowed me to programatically generate a backtrace for logging purposes as and when I saw fit. At least then I can say 'you know what, this error is more of a big deal than average. Provide an option to log where it came from'.
&gt; Hmm. I don't see any talk about line numbers anywhere, which is one of the few gripes I have with Haskell: There's a library solution based on a custom monad and there's even a language solution for ordinary exceptions... but you need to enable profiling, as Haskell is lazy and the call stack doesn't look like anything you'd expect because it transcends lexical scope, and the cost centre annotations needed for profiling are needed to reconstruct a lexical one. I strongly agree with this. For a long time that did not seem very likely to happen because errors had neither a specific interface to follow nor was there a generic way to generate them. Now that this is changing th door might open up a bit for this. I personally would find it insanely useful :)
Probably. But the `from_stuff` is hiding a [dirty little secret](https://github.com/BurntSushi/xsv/blob/master/src/types.rs#L27-L32). Of course, I could just push that unwrapping to the time at which the error is actually handled.
This is the result of one of the first code that I wrote when I discovered Rust in april/may of this year. Around two months ago I started using it for my small indie game prototype. Even though the library has no tests yet, I know that some "advanced" things like geometry shaders and render to texture work, because I've been using them. Recently I have started adding other components to this library: drawing sprites, drawing text, loading textures from a file (thanks to piston/image), etc. but I have now realized that it was better to split these components in their own crate: https://github.com/tomaka/glium-utils (which is not yet up-to-date with the latest changes in glium) and let glium be its own library. 
I haven't tried it, but it might be as simple as building with the `x86-linux-androideabi` target-triple, following the rest of the Building Rust for Android instructions and the x86 build instructions that come with the NDK. I'd be surprised if it actually is that simple.
Yeah, this has been an issue with my rawslices proposal, if you say "raw is how you dodge checks", you basically force the programmer to discard all lifetime information. Maybe a smart pointer type wrapping a raw ptr to maintain the info?
So is this pronounced *glee-um* or *gee-el-ee-um*?
How does this affect other (non-linker) flags that go to rustc? For example, you need special flags to build native Windows binaries that do not run in a console.
I'm much in favor of the first one: it reminds me of glia cells (whose name comes from “glue”) It glues rusts syntax to the OpenGL API.
cool :). I don't really have use for rust day to day, but i do want to check it out for graphics &amp; game related stuff.
this is awesome, and clean, and understandable. thanks just a few thoughts: * what's target.finish? let mut target = display.draw(); target.clear_color(0.0, 0.0, 0.0, 0.0); // filling the output with the black color target.draw(glium::BasicDraw(&amp;vertex_buffer, &amp;index_buffer, &amp;program, &amp;uniforms, &amp;std::default::Default::default())); target.finish(); * glium::Program::new might be better served by passing it a struct instead of 3 string args, least it seems that way to me. * why does the glium::VertexBuffer::new require &amp;display? is this because of rust's borrowing, in general I don't know if that would be a necessary concept. I don't know if this is common, but what if the buffer was useful for more than one display buffer? like a multi-window cad program?
&gt; what's target.finish? For the moment it's [an empty function](https://github.com/tomaka/glium/blob/master/src/lib.rs#L592). Considering that the destructor of `Target` swaps the buffers (ie. shows the result to the user), I think that it's better if you have a way to explicitly do it. Also this function may take some parameters in the future. &gt; glium::Program::new might be better served by passing it a struct instead of 3 string args, least it seems that way to me. [I agree](https://github.com/tomaka/glium/blob/master/src/program.rs#L67). I have not yet decided what to put here, but it's definitely going to change. I'm planning to have [compile-time verification of the shaders' source code](https://github.com/tomaka/glium/pull/12), and this compile-time check may contain additional infos than just the source code (for example the locations of the uniforms). &gt; why does the glium::VertexBuffer::new require &amp;display? That's how OpenGL works. The `Display` object contains a handle to an OpenGL context, plus the list of loaded functions, plus the current state of the context. Note that the `VertexBuffer` doesn't borrow the display, it just uses it when you create it in order to specify which display to load the buffer to. Theoretically you can create multiple OpenGL contexts (ie. multiple windows) that share the same objects. This is not yet possible with glium/glutin, but it should be pretty simple to add. 
I faced a similar problem due to having multiple static "entry points" into an application ie. `main` and the Windows event loop - `WndProc`. I had to initialize a Window instance (at runtime, this could fail), but then access it from the WndProc function. What I did was make the static variable an `Option&lt;T&gt; = None`, and then at runtime do the following: unsafe { s_app = Some(my_initalized_var); } This is obviously unsafe, but I make sure that it is only used when it is safe to do so. However I then ran into the issue that my struct somehow ended up having a destructor, in which case it cannot be static. So I went the whole hog and ended up with a static `Option&lt;*const T&gt;`, allocating the object on the stack and storing a static pointer to it (!!!). This gave me grey hairs. So I'd love to know how to do this as well. I don't like living dangerously :'( Code explaining what I mean: [http://pastebin.mozilla.org/6802976](http://pastebin.mozilla.org/6802976)
I think first-class thread local variables (which I think are coming) will make this much more sane. It is generally unsafe to have a static global variable, even if it's just initialized once, without some sort of synchronization. The only reason it is safe in Java, for example, is because the JVM takes a global lock on a class when it is first loaded, during which time it runs static initializers (this can be abused using subclasses to produce fast, unsynchronized, safe lazy initialization--part of your reward for using the JVM). But that is not the case for thread locals.
You could also do `drop(target);`.
A "not so smart" pointer with lifetime that implement the traits `std::ptr::RawPtr` and `std::ptr::RawMutPtr`(along with other methods and traits that would make it easier to get things right) might work I guess (`LifetimeRawPtr&lt;'a, T&gt;` and `LifetimeRawMutPtr&lt;'a, T&gt;`?), but the syntax feels clumsy. I'd think that providing a way to optionally allow raw pointers to have lifetime associated with them would be nicer, but this might work without having to add more language features I guess.
As "gallium" is already taken by mesa, but is a nice element starting with g and there's also lithium, which is also a nice element and starts with l, *and* GaLi compounds are used in electronics, what about "galithium"? Or, if you like it more punny, Ga[lanthanum](http://en.wikipedia.org/wiki/Lanthanum). And if you ever do an XML library, it could be Xenon-Molyb­denum-Lithium, Xemolithium. Doesn't work for SQL, there's no element starting with q, but then one can't have everything. Of course, sound libraries all should end in "Lutetium".
As a dedicated user of [Sphinx](http://sphinx-doc.org) I've used [Hieroglyph](http://docs.hieroglyph.io/en/latest/) a few times and have been reasonably happy with it. Since Sphinx delegates code blocks to [Pygments](http://pygments.org) and Pygments has a rust lexer, it'll just work. Alternatively, if you really want to keep LibreOffice you can use the `pygmentize` CLI tool, I'm sure it has at least one output format which can be imported/pasted in LO.
A fine question! I'm not sure but I'll take patches if they're small and don't break Servo. My fallback as far as making sure the content is widely accessible is that the Markdown source for the slides looks okay as rendered on GitHub or with plain `rustdoc`.
I'm giving [a talk next month](http://www.reddit.com/r/rust/comments/2je2mt/116_announcing_sf_meetup_all_about_servo/) about this very topic! There will be slides/notes and probably video. Other than that, there's a little info on [the project wiki](https://github.com/servo/html5ever/wiki/Design), and a page about [the source tree layout](https://github.com/servo/html5ever/blob/master/STRUCTURE.md). I'm also happy to answer questions any time; I'm `kmc` on Mozilla irc.
I actually used the html5ever to do some screen scraping as one of my first learning project with Rust. This example https://github.com/servo/html5ever/blob/master/examples/print-rcdom.rs was my starting point and it didn't take too much to turn it into a screen scraper.
Well, what I can tell you is that in that method, `drop(self)` does nothing, as `self` is a `&amp;mut` pointer, where nothing happens if you drop it. The actual drop happens because you reassign `self.link` with a new value, this necessarily has to destroy the element that was there before.
I just discovered that Intel has an ARM to x86 translator called Houdini and the Play store automatically adds it when the app only has ARM binaries. So Rust not supporting Android/x86 yet is not a showstopper for those devices. The performance loss is likely significant though. One blog post mentions that the native version of the Epic Citadel demo runs 40% faster than the translated one.
I think you underestimate the time needed to write a backend such as LLVM.
this is actually perfect for what I want to do...thanks
I honestly am not. I realize this would be a huge effort requiring almost as much effort as the language itself. I just do see some benefits to it and was simply wondering if it was at least an idea in the community or completely abandoned.
&gt; I realize this would be a huge effort requiring almost as much effort as the language itself. You're still underestimating by an order of magnitude or two :)
&gt; and it's now a core focus of effort for what is literally the world's largest corporation. ExxonMobil is spearheading the LLVM development effort?
I am afraid there is a balance issue here: - on the one hand a file location and stack trace are incredibly useful to locate the root-cause of the issue - on the other hand, capturing and storing information consumes resources Let's not forget that `Result` is supposed to be the de-facto interface for things that may fail; if the performance is not good enough a number of users will simply shy away from it introducing divergences in API design and this will not help anyone.
Wow alright... Maybe I do need to frame this a bit more realistically in my mind. Thanks for bring me down to earth :)
They have to do something now that Tesla is around.
At the moment `AAPL` is ahead by about $200 billion :) (Market cap, that is.)
Someone should perhaps tell Forbes that they got it all wrong then ;) http://www.forbes.com/global2000/list/ (my Exxon quip was a guess) Edit: just saw your edit about market cap. Disregard!
I am not talking about replacing LLVM. I am talking about replacing LLVM in the rust compilation chain. I would think this would be a far smaller effort than replacing all of LLVM. However, please correct me if I'm wrong.
Keep in mind stack traces and 'Either/Result' types are not mutually exclusive. In Scala (well, Java), the stack trace is captured in the constructor of the Exception class, and occurs whether you use normal throw/catch logic or not. This means you can write something like the following def readFile:Either[IOException, String] = Left(new IOException("File not found")) And you'll get a nice fancy Either you can treat as a Monad, which also happens to include a stack trace if you inspect the left element. I can't speak for Rust, but I see no reason why the same thing couldn't occur in it. tl;dr (new RuntimeException().printStackTrace() will give you a meaningful stack trace even if you don't throw it).
If you are familiar with C++ "smart pointers", `Box&lt;T&gt;` in Rust is almost identical to `unique_ptr&lt;T&gt;` in C++. When it gets replaced, the previous thing it is pointing to will be dropped automatically. The guide and pointer guild each has a section on `Box&lt;T&gt;`. Though I'm not sure if it helps: - http://doc.rust-lang.org/guide.html#boxes - http://doc.rust-lang.org/guide-pointers.html#boxes `self.link.as_mut().unwrap()` will fail when there's no link. You need to make sure that `self.link` is not `None`. As an example, `insert_before()` can be implemented this way (`remove_node()` should also be similar): fn insert_before(&amp;mut self, element: uint, before: uint) -&gt; bool { match self.link { Some(ref mut node) =&gt; { if node.value != before { // does not match `before` // recursion. Explicitly return. return node.insert_before(element, before) } // found `before`, continued below after the match block... }, // no more links. `before` not found. Explicitly return `false` None =&gt; return false, } // this has to be outside of the match block, since `self.link` cannot be modified while being borrowed within the match block. self.link = Some (box List { value: element, link: self.link.take() }); true } 
The thing is LLVM doesn't just provide code generation. It also provides most of the optimization passes AFAIK. Replacing those pieces means forgetting about competing with C/C++ in terms of speed.
As for non-recursive functions, the only way I can think of is to make it iterative instead. However, I'm not quite sure how to that without using `unsafe` blocks and raw pointers.
This is probably a bit strong. It really depends upon what you want. Look at GHC's [native code generator](https://github.com/ghc/ghc/tree/master/compiler/nativeGen), for instance. It takes C-- (which is about the same level of abstraction as LLVM's intermediate language) and spits out an object file. If you just look at the core code generator and the X86 backend it's only a few thousand lines of Haskell. Admittedly it leaves many optimizations on the table, but it produces solid code and has been a perfectly fine default for GHC for years. It's also a bit of an apples and oranges comparison as GHC does a great deal of optimization in earlier compilation stages, but it's also coming from a much higher level source language.
Oh, cool! Do you have the source code for what you did lying around anywhere / can you share it?
It is to expected that Isaac64 is much slower, because the Mersenne Twister is no cryptographically secure (by observing a few random numbers you can predict the next ones). Did you try Rust's XorShift RNG? It is supposed to be much faster than Isaac64. (The period is only up to 2^160 &amp;cong; 10^48, but I would think it is still enough for your application.)
This kind of seems cool, but I don't know: it seems like a hard-coded, special case of something that could be generalized into monadic composition.
Did you consider implementing the RNG traits? (That is: `Rng`, `SeedableRng`, `Rand`)
&gt; Next, my struct doesn't include a single reference. Doesn't that mean that it owns its fields? Yes. &gt; Moreover, why Vec is content without having a lifetime but Option is not? Both are content without lifetimes, and I don't get why you're giving Element a lifetime, what is Element? Defining Element as a unit struct (with a trivial `new`) and removing all lifetime annotations, things work as expected.
If anonymous enums are to have the same expressive power as regular `enum`s, they need to be able to represent `T | T`. Consider : enum Foo { Bar(int), Baz(int), } How do you represent this as an anonymous enum?
Even just replacing LLVM for unoptimised code generation for Rust alone would be a big effort, e.g. it would have to support at least 3 architectures.
Here's how Element looks. struct Element&lt;'e&gt; { e_type: ElementType, value: &amp;'e str, attr: HashMap&lt;&amp;'e str, &amp;'e str&gt;, children: Vec&lt;Element&lt;'e&gt;&gt; } `ElementType` is an enum. `value` and `attr` is supposed to reference slices of `Parser.source`. If I don't have lifetimes I start getting a lot of this: error: wrong number of lifetime parameters: expected 1, found 0 [E0107] root: Option&lt;Element&gt;, ^~~~~~~ 
What's the purpose of the `'p` in `Elements`? &gt; Object instance = struct instance + impl. I'm not sure why I have to explicitly match lifetimes on these two. Is it even possible in Rust for implementation to "live" shorter/longer than a corresponding struct? I don't know what you mean by this. I guess you are confused about the meaning of lifetime parameters in `impl`s. `impl&lt;'p,T&gt; Foo...` simply means "for all lifetimes p and types T implement Foo...". This is generic programming / parametric polymorphism. If you have a type with a lifetime parameter in it (like `Elements&lt;'p&gt;`) it means that a value/instance of this type is restricted not to outlive `'p` (typically because it stores a borrowed reference to something that is alive for at least `'p`). If you have an instance of type T where the type T does not mention any lifetimes directly or indirectly it is not lifetime-restricted. Example: `Vec&lt;int&gt;`. Internally, a vector "refers" to its elements but the elements are considered "owned" by the vector, which in this case means that the only one getting rid of the elements is the vector. So, as long as you have such a non-empty Vec&lt;int&gt;, the elements are still there. No need to restrict the lifetime of such a vector. The lifetime thing is something that typically pops up if there is "borrowing" involved. That means, one thing refers to another but *does not own* it. if X refers to Y but does not own it ("if X borrowed Y"), X does not keep Y alive by merely existing. That's why X is not allowed to exist for too long.