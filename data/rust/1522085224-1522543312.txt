My advice would be to try writing something small but practical and struggle through it. I find passively reading information only gets me so far.
Funny that – I did something similar recently with my last [mutagen PR](https://github.com/llogiq/mutagen/pull/68/files) (see plugin/SRC/lib.rs, line 801) using `mem::replace`.
If into Rust you want to enter join a project and find you a mentor who will help you for free so you can easily become a great Rust implementor!
[removed]
[removed]
I’d remove iron from list. It is deprecated
+1 for mentor/implementor rhyme. 2nd line scans better without the 'you'. 2nd last line definitely needs more syllables. But it's not everyday we get poetry!
I usually rhyme on my twitter account.
I love you
Kind of, but part of the intent is also to enable reuse - eg, you may have many different JSON schemas to parse that include the pagination fields inline, and you can now define a single Pagination struct for all of them. Moreover, the [flattened HashMap syntax](https://serde.rs/attr-flatten.html#capture-additional-fields) makes it much easier to reason about unknown fields.
Cool! I'm taking a break from programming at home and have another few weeks left, but I'll hopefully have some time to integrate mutagen into one of my projects soon after.
Thanks again. 
https://rustjobs.rs/ is the canonical resource here. I'm on mobile otherwise I'd check if it's in the sidebar. If it's not, I'd suggest adding this there at least in the meantime.
Well, it's pretty clear they mean "the question mark operator is generally how you'd achieve that sort of short-circuiting behavior."
[removed]
You are not mistaken.
Uhm but their memes are on point .. why get rid of them?
&gt; This approach is flawed because it treats sem-ver as an absolute truth rather than an approximation For those of us that aren't too familiar with the details of the proposal, can you unpack this?
For this use case, release/acquire is enough. With SeqCst you effectively force all the sending thread's modifications to be visible to all completely unrelated threads doing a SeqCst operations on a completely unrelated atomic, and it is bidirectional (eg. the threads synchronize both ways). With acquire/release, the relation is only between the two threads that „meet“ on the common single atomic variable, and is unidirectional (data flow from the release one to the acquire one).
maidsafe.net code in rust and have been recruiting.. not sure what they're looking for atm
&gt; Your program most definitely contains non-atomic writes, and those are still undefined if they race anything else in any possible interleaving. (factorial blowup) I don't think they can race, under my framing ("on all shared memory locations"): they can't be writes to *shared* data. Additionally, if we're talking about guaranteeing safety, `unsafe` is inherently off the cards: it breaks guarantees even without concurrency. (It's true that Rust doesn't let you do much safely with just the `Atomic*` types, but I'm not sure that is the key point: I think everything would be okay even with an `AtomicPtr` that took `Box&lt;T&gt;` where `T: Send`. Rust's ownership plus `Sync` means there's no way to get bad shared data.) &gt; Java is concurrent and raw but not safe. Data races are UB. Hm, I'm also unsure about what you're getting at here, could you expand? The language model essentially forces implementations to have "non-atomic" writes be sufficiently atomic so that concurrent, non-atomic mutation isn't undefined behaviour in the C/C++/Rust sense. For instance, [LLVM gained the `unordered` memory ordering value](http://llvm.org/docs/LangRef.html#ordering), for this Java-style "non-atomic" write. &gt; If you pick the latter, you must provide the ordering guarantees of Mutex or RwLock - and those can be implemented without SeqCst. They *can* be, but that's not my point: validating that Release/Acquire is correct is significantly harder than SeqCst, because the interleaving model doesn't necessarily hold. (Although specifically Mutex and RwLock are the easiest cases.) &gt; As far as I understand, the power of SeqCst over Acquire is negative reasoning. If I don't see a particular signal value, it hasn't happened before the barrier (but some other thread may make it happen before I do). I think a lot of the memory orders are negative reasoning in this sense: they're strengthening the requirements over non-atomic accesses and thus saying that certain executions can't occur/certain values can't be observed.
"There are no open rust jobs anywhere in the world." which is not something i'm inclined to believe.
Maybe you should search for the experiences of others bringing Rust to their team, I think I've read a few interesting blog posts on this here already.
&gt; Relying on import compatibility can instead let Go use a trivial, linear-time algorithm to find the single best configuration, which always exists. This algorithm, which I call minimal version selection, in turn eliminates the need for separate lock and manifest files. It replaces them with a single, short configuration file, edited directly by both developers and tools, that still supports reproducible builds. Basically, they just always pick the latest *mentioned* minor version for each major version of a dependency.
Right, but with the caveat: &gt; Exclusions only apply to builds of the current module. If the current module were required by a larger build, the exclusions would not apply.= For example, an exclusion in rsc.io/quote's go.mod will not apply to our “hello, world” build. This policy balances giving the authors of the current module almost arbitrary control over their own build, without also subjecting them to almost arbitrary control exerted by the modules they depend on. So that means you have no way of telling your downstream users that your package doesn't work with a specific version of your dependencies: they have to figure that out for themselves.
Memes are intrinsically a `Cow`
I have been working on the resolver in cargo. ( Announcement to come when the last PR hits nightly, in a day or two.) And was fully prepared to write a rant of the form "You can't decide you're not an SAT solver because you say so." but [this](https://research.swtch.com/vgo-mvs) was very clear and informative. So my takeaway is I wish them luck. I hope we can learn from them as it rolls out in practise. The designers of cargo should see this hole discussion as a ***BIG*** compliment. All of the research work refers to cargo as if it was the only serious pryer art. As if no one else had a package manager worth learning anything from. The article discusses that ["Cargo developers have proposed that cargo publish try a build with the minimum versions of all dependencies"](https://github.com/rust-lang/cargo/issues/4100) that issue was just closed thanks to @klausi implementation of [`-Z minimal-versions`](https://github.com/rust-lang/cargo/pull/5200) wich will hit nightly in a day or two!
I wouldn't necessarily be looking only for "Rust jobs". Don't rely exclusively on the keyword "Rust", in other words. You could look for systems programming jobs in general, and ask if they have any interest in transitioning to Rust. Or you could (like me) join a C++ shop, and start ~~evangelizing~~ gently nudging them towards Rust.
I'm OK with it, though. I don't mind a little bit of self-promotion if the article has genuine value, and this article definitely did.
I would. Rust isn't really gaining a lot of adoption from what I've seen. I thought it would take off more in certain areas where performance was important and with Java trying to make it more difficult to abuse internals for that purpose, but I think the pace at which rust is adding complexity it scaring people away.
Oh nonono I don't mean the article itself, I mean't /u/ebvalaim's comment, with the way it ended listing the main selling points of Rust, in a comment in rust's own subreddit. I'm not sure why it read that way to me, then I remembered this is a link post so putting a comment to explain the link is what's usually done. I didn't notice ebvalaim was the one that posted the link, I read too much into it
Haha, yeah, now that I read it, it does sound a bit like an ad :D But I don't really have any idea how to phrase it better, as Rust's selling points _are_ what makes it really shine when considering such cases.
[removed]
One thing that I really hope to see one day in cargo is the ability to import multiple versions of a package in a single crate, not just across create boundaries. I think that the "get rid of `extern crate`" work is getting us closer, because it means that cargo is getting first class support for renames, so we may be able to do: [dependencies] lib = { version: ”1”} lib = { version: ”2”, rename: "lib2" } I've never actually needed this, but the thing that concerns me and makes me think it will eventually be helpful is the idea of two dependencies, each depending on "lib", but each depending on different versions of it. Without the ability to include both versions in the same create life will get... painful.
As a non native speaker I have to say that it helped me to understand the sentences with typos. Maybe "hole/whole" was quite easy, but pryer wasn't clear for me. So in the end it added something to the conversation.
Ninth - yes, unless you use `unsafe`, but then of course you aren't protected. Seventh - as far as I know, no, but then again, nobody is saying that Rust is a silver bullet and a cure for _all_ problems ;)
One place it could be useful is crates pulling in their own previous version(s) in order to implement compatibility shims... or possibly the other way around (*i.e.* implementing v1.x on top of v2.x as a translation layer).
&gt; Some breakage is unavoidable This is *especially* frustrating when you and your dependencies disagree on what constitutes "breaking".
Thanks for the correction. My complete inability to spell held me back from contributing for a long time. Eventually, I decided to help ware I could even though it leaves spelling mistakes for others to clean up. So thank you. One note on wording. Some people find jokes about "Nazism" triggering. I am generally not one of them despite having grandparents with numbers on their arms and cousins so thoroughly obliterated that we don't even know there names.
Why? Rust is still a very young language, one that I'm sure companies aren't very willing to take bets on yet that include hiring people with that expertise. There are some companies interested, but most would likely want to retrain internal talent that is already valuable rather than possibly hire someone with a skillset they won't care about in a year or so depending on the project's success.
Can't you already do that? This sounds similar to the [semver-trick](https://github.com/dtolnay/semver-trick), which I even used in num-traits to release 0.2. 
&gt; start evangelizing gently nudging them towards Rust. Relevant: https://medium.com/@caspervonb/a-brief-totally-accurate-history-of-programming-languages-cd93ec806124#e3be ;P
Original author here. A "write-only" language refers to the relative difficulty of reading a program vs writing the program. Languages with C-like syntax often attempt to deliberately make it easier for programmer to write code, and this usually comes at the expense of being harder to read that same code. It's important to also understand that Ada was designed to be legible even to people who are not very familiar with the language. I'm sorry to say that I'm just not willing to spend a lot of time in this debate, as no matter what I try, it devolves into technicalities. Ada's strengths by far lie in very high-level conceptual areas related to formal specification, engineering of very large systems, and very practical experience. Ada works extremely well. It has proven itself over three decades, and it has been continually improved. If Ada had any fatal flaw, it would be noticed by now. The only real "flaws" in Ada are very academic ones, where Ada is intended for practical application. I don't see the relevancy of even comparing these two languages. Rust does some fun things, surly, but it doesn't provide any serious contention for Ada. Rust has everything Ada has, plus a bunch of things that 1) no one asked for, or 2) are already being included in Ada 2020 and SPARK. As someone who makes a living developing very large, critical software systems, I can state, unequivocally: Rust does not have higher-level organization and general legibility features that I require when implementing massive distributed systems that are built by large teams, and need to be maintained for decades. This is especially the case when formal methods are involved. To be totally honest, from an industry perspective, I see not one single reason why anyone would use Rust instead of Ada, except that they don't know about Ada. If you really look at the history and progression of Ada, you will find the most meticulously engineered language in human history - bar none. It's an achievement worth celebration, not a failure needing replacement. It's pretty naive, in my humble opinion, to think that Rust is punching at that weight. In the end, I will continue to put my money where my mouth is, as I hope everyone will. 
Looks interesting! &gt; The constraints of Cargo and Dep make version selection equivalent to solving Boolean satisfiability, meaning it can be very expensive to determine whether a valid version configuration even exists. I haven't studied the SAT instances produced by package managers in detail. Are they really that expensive in terms of clock milliseconds to solve? I have worked on and with SAT solvers: modern SAT solvers are *scary* fast.
Er, is sixth place really a bug? It looks like it's finding the end of a list and then sticking a new value in. Having that as a loop body interferes directly with the loop condition. I'd call it bad formatting, certainly.
it's the 2018 goal, something about making Rust boring.
I came from Python and JavaScript. 
&gt; Rust community is really awesome Indeed. 
Noted. Thanks!
There was some relevant discussion in the CLI-WG gitter today about performance of CLIs. Although it may not be super relevant for `rjoin`, the TL:DR; is a common mistake is to read `stdin` line by line, which does a heap allocation for each line and is quite slow. The best thing to do without getting too crazy is to use a `BufReader::read_line`. Another one is to use `println!` when doing lots of output, because `println!` (credit goes to /u/BurntSushi who was actually helping the visitor) 
Thank you!
Thank you!
Will do, thanks!
Sure, I will ask more later on. 
Depends on the number of dependencies I guess. Here's the dependency list for Kubernetes, for example: https://github.com/kubernetes/kubernetes/blob/master/Godeps/Godeps.json . I presume you've already seen Russ's post on Version-SAT ? https://research.swtch.com/version-sat
I was not aware that worked. Thanks.
No need to debate, thanks for the reply. Here are some of my thoughts though. Your point on the continual evolution of Ada in Ada2020 and SPARK is apt, languages to improve. Look no further to C++11/14/17 or Java9. A decade ago it was obvious why people bemoaned those languages, now many issues are mere paper cuts. There flaws of old are not reasons to abandon ship. Of course Rust started before C++11 was a thing and the dangers of C will never stop being a point of horror to even the experienced, who are familiar with the extent of their own ignorance. Even when Rust benefits by disallowing old poor approaches by default or out-right in entirety, C++ can be compiled with flags (if not they could technically be added) that turn the compiler into a friend that hints towards current standards instead of allowing the user to smuggle in the past's errs. Enforce those in your project and you're living with similar standards. So one might ask, while Rust demonstrated vision and justification, why use it when other languages have kept up? For Rust it's easy to site things external to the language like its package and build tools, how it's macro system is leagues better than C's, maybe even it's all setup to lead you right towards agreed upon correct ways to do things where C++ still might not convey that outright. Ignoring those though could the language be an equally go option to other things? Sure. One of your main complements paid to Ada relates to one's need for creating as you say "higher-level organization and general legibility." Outside of semantic correctness, the expressive needs and legibility are highly subjective qualities. Rust and C++ are perfectly capable of modeling the same thing, but I'll vastly prefer Rust since I just wouldn't perform the same without it, even while C++ people may see no reason to switch now they have constexpr and other improvements. They might say they have Boost while I say I have crates. I have no doubt Ada is suited to get certain things done with little friction, but I don't see any flaws in Rust other than immaturity that would prevent it from targeting the same domain. Of course I think Rust is suited to bring formal specification (obviously not in the first-class formal proof sense of Coq/Agda,) to the domains that it more readily targets at the moment. Let's just say for the time being I only see claims being made that Ada suits you better personally, than I'm seeing in specific criticisms that Rust is unsuitable in the general sense. I know Ada is incredibly suited for it's purpose as is MISRA C. I don't necessarily think c-syntax always makes writing easier and reading harder, I do know that I find Rust's semantics very easy for me to parse, so the points on a write-only language mean nothing to me beyond subjective testimony. As far as implementation details I find Rust highly self-documenting. I know I personally I struggle to intuit implementation details that Haskell might convey to it's expert users, but I still recognize it's perfectly suitable for those people. It's strange to me that Rust isn't being credited for it's legible merit and design faculties with regards to it's accustomed user-base. Ada and Rust are both niche, and the fact that Rust is taking some of the best achievements of Ada and punching them into domains where Ada is not to be found is the farthest thing from naive I can imagine. It is logically and correct to capitalize on those foundations, and that is what is worthy of celebrating. Further to not see "one single reason why anyone would would use Rust instead of Ada, except that they don't know about Ada" just seems like the entirely wrong mentality, and truly naive to boot. It's hard to see your case for Ada over Rust when it's all being given from that perspective. Specific capabilities that only Ada can achieve that don't relative to subjective usability is what I'd have to see a case made for. As far as I can see Ada mostly benefits from being entrenched in it's domain, and with years of momentum, quite like C. Rust is young and I see no reason why it shouldn't build momentum and establish itself amongst the other great languages that don't seem to go away.
&gt; "Cargo developers have proposed that cargo publish try a build with the minimum versions of all dependencies" As someone who has had to do this manually by hand in the past *ohmygodyesitsaboutdamntime*.
Still working on my zen garden sandbox https://github.com/etrombly/sandbox . I've got Linear movements done, and the basic code for arc movements. Just need to finish up arc moves and I can build the frame for it. Should work as a basic framework if someone wanted to make a 3D printer firmware. No path planning though, and I'm not sure if the arc movement is implemented efficiently.
I have not heard about this when I hired for one or two rust positions last year.
A `while` loop would be much clearer style: pmd0 = m_pMeshUpdate; while (pmd0-&gt;next) { pmd0 = pmd0-&gt;next; } pmd0-&gt;next = pmd;
Ideally, we'll end up with that easier / safe harfbuzz crate in here: https://github.com/servo/rust-harfbuzz :)
This is where static analysis to look for these changes at publish time would be great. elm does that, you cannot publish breaking changes while ignoring semver, which is super nice and spares you from having to worry too much about it.
One thing that this would allow you to do that is more useful than the semver-trick would be to create a couple of *conversion* functions. The semver trick only allows to to expose exactly the types from your crate, whereas this would allow you to build any sort of shim you wanted.
I don't know. I've noticed a trend where the longer you've been writing code the less you use while loops for anything. It's just so much easier to lose track of the program flow. I would keep the code as-is except replace the semicolon with an empty body with a comment in it says something like `// Find end of list`.
Maybe your company is different from mine, but I wouldn't expect to get any traction at all in getting your company to pay for this. Your first step needs to be getting some Rust code running at your company (I'm still working on this point myself). *Then* you have a valid reason to start asking your company to send you to Rust conferences.
Links would be nice.
So first off, I'm going to change some names of things and slightly rewrite your `SubImgIterator` impl to make things a little easier to explain: impl&lt;'parent, G&gt; Iterator for SubImgIterator&lt;'parent, G&gt; where G: 'static + GenericImage, G::Pixel: 'static, &lt;G::Pixel as Pixel&gt;::Subpixel: 'static, { type Item = SubImage&lt;'parent, G&gt;; fn next&lt;'b&gt;(&amp;'b mut self) -&gt; Option&lt;Self::Item&gt; { let im: &amp;'parent mut G = (*self).img; let a = im.sub_image(); Some(a) } } The trouble here is that the compiler is being very conservative about what it assumes with respect to lifetimes of things in the implementation of `next`. We can see that by trying to compile this code and receiving the error: error[E0312]: lifetime of reference outlives lifetime of borrowed content... --&gt; src/main.rs:136:38 | 136 | let im: &amp;'parent mut G = (*self).img; | ^^^^^^^^^^^ | note: ...the reference is valid for the lifetime 'parent as defined on the impl at 128:5... --&gt; src/main.rs:128:5 | 128 | / impl&lt;'parent, G&gt; Iterator for SubImgIterator&lt;'parent, G&gt; 129 | | where 130 | | G: 'static + GenericImage, 131 | | G::Pixel: 'static, ... | 142 | | } 143 | | } | |_____^ note: ...but the borrowed content is only valid for the lifetime 'b as defined on the method body at 135:9 --&gt; src/main.rs:135:9 | 135 | fn next&lt;'b&gt;(&amp;'b mut self) -&gt; Option&lt;Self::Item&gt; { | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ And this is a good thing. Think about the kind of thing you're trying to create: it's a very thin wrapper around a mutable reference. To make this safe, you would have to move that reference out of the iterator, and then back in again before the next call to `next` since only one mutable reference to any object can exist at a time. The `Iterator` API fundamentally doesn't support this pattern unfortunately, so I don't think it's possible to do exactly what you want to do given the design of the `GenericImage`/`SubImage` API in the `image` crate. They may be able to implement something like the iterator you want internally, and it might be worth trying to get that working upstream. Sorry =(
&gt; We also got Servo running under the hood of Firefox Focus on Android as a proof of concept. Yes!!! 
Probably, but what about the users who blindly install using `pip install &lt;package&gt;`? I work in security so I'm being extremely nit-picky here even though I know the likelihood of this happening is hopefully small.
I'm glad it helped! My position is that spelling is just about the least interesting part of someone's ideas, and I found your actual comment to be great. Non-native speakers shouldn't be intimidated to contribute, and I think that the best way to demonstrate that is to engage with ideas, rather than just criticizing parts that don't matter. If the post I initially responded to had said something substantive and had _also_ pointed out some spelling things in order to be helpful then I wouldn't have said anything. 
You are implying that the threads know about which atomic got modified. Is that true? Cause I feel like if that's true then Rust's atomics are actually unsound.
Your bugfix is someone else's breaking change.
I'm an unpaid volunteer for this particular Russian botnet.
&gt; To me, it seems a bit like the author is trying to solve problems in another language and then translating that into Rust code, rather than thinking in Rust terms from the beginning. The author is just saying that he spends too much time writing non-business logic. Despite the fact that many languages will indeed let you write a business logic faster (with different tradeoffs), the act of trying to write business logic is not "solving problems in another language." 
If you're in Austin I will hire you. 
Yeah, but if we can automate most of it, by looking for API changes, why the hell not? It's still far better than nothing.
I don't think you need to worry about the next epoch wiping out your generics.
alright thank you. I'll start farming crafting parts for this shitty game lol
"Details" isn't the word I'd use for it. This thing is *very* different from Cargo, to the point where the only real similarity is that it's trying to solve the same problem. There's no registry, no lock file, and their version selection algo is supposed to be far simpler (Cargo's is a SAT solver, while VGo is a linear-time graph traversal).
It was the word used in the post.
It's taking off in more quiet ways. I know of a ton of places that are using Rust in production, but not talking about it just yet, or not hiring explicitly for Rust jobs. &gt; I think the pace at which rust is adding complexity it scaring people away. I haven't heard this; most people complain about difficulty or productivity.
This is god's work for everyone that doesn't want to run a browser engine for a decent looking vector graphics UI. 
Glad you asked! [This week in Rust](https://this-week-in-rust.org) has a weekly updated list, and many projects, including but not limited to [rust](https://github.com/rust-lang-nursery/rust), [clippy](https://github.com/rust-lang-nursery/rust-clippy) and my own [mutagen](https://github.com/llogiq/mutagen), have mentored issues, that is you will get a mentor when you agree to work on the issue.
I guess that’s where we differ; if anything, it’s getting easier, not harder. IMO.
That's bigger than I though, but still doesn't look too scary: something like 1000 direct dependencies. For this kind of structured problem, that would normally be a cakewalk for a good SAT engine. But maybe there's something special that's hard. My favorite ref from Russ's paper is &lt;http://web.archive.org/web/20160326062818/http://algebraicthunk.net/~dburrows/blog/entry/package-management-sudoku/&gt;. Big fun.
As an example of this, here's someone apparently at Twitter mentioning that this job is for a team using Rust, and that they've secretly been using Rust in production for a year: https://twitter.com/stuhood/status/978410393944047617 This isn't even one of the ones I know about! (Oh, and /u/ohmeeyes you might want to check that out)
I don't know about the threads, but this is what the C++ standard says about acquire (and Rust ordering is modelled after that): &gt; A load operation with this memory order performs the acquire operation on the affected memory location: no reads or writes in the current thread can be reordered before this load. All writes in other threads that release *the same atomic variable* are visible in the current thread (see Release-Acquire ordering below) I guess the compiler could use that to an advantage. A hardware that tracks that could. No idea if it actually does, though.
Is that including WebRender? I heard drivers on Android were really bad which is why it's disabled in Firefox Nightly on Android. 
You are partially right. Because we try to push back on unfinished stuff on the compiler, and introduce more focus, we are cutting all memes from the 2018 edition, with the possibility to reintroduce them in a proper push in 2019. This includes `--error-format nelson`, the already outdated `lolcat32-wellknown-wellknown` target and burning your code in a trashfire if the compiler detects too many lifetime errors.
wish to use rust within c++ source. i am new to rust, learning rust now. i like it.
I haven't used this library, so no concrete advice. Here's the book chapter on ffi: https://doc.rust-lang.org/book/first-edition/ffi.html And here's bindgen, a tool to autogenerate bindings https://doc.rust-lang.org/book/first-edition/ffi.html
Yes, it's hyperbolic and unnecessary. I propose that the new term is "Grammar Fascist"
Note that Cargo doesn't even use a SAT solver. From the source: *"Actually solving a constraint graph is an NP-hard problem. This algorithm is basically a nice heuristic to make sure we get roughly the best answer most of the time."* https://github.com/rust-lang/cargo/blob/master/src/cargo/core/resolver/mod.rs
I've mentioned this elsewhere in this post, but Cargo does not use a SAT solver.
Is it possible to somehow reset the module regardless of the state? You could expose reset fn only in that case.
That's the idea. The output file will look corretly everywhere (except QtSvg).
[removed]
As a non-native speaker, I like it when people correct my grammar mistakes. That's how you make progress, anyway.
Once, in school, a classmate snuck a `#define while if` in my code and it took me the longest time to figure it out.
I second this. Rust is actually very easy to integrate into existing products, and certainly our company has not advertised anything. The results have been phenomenal, though, and it is by far the least problematic part of our stack, even considering track changes in the language or important libraries every so often.
The decision problem regarding dependencies is indeed very easy in practice. Yes, people are scared as hell when they see "NP-complete", yet they solve sudokus every day ;) But it gets interesting when you try to add optimization constraints to your problem, making it more MAXSAT than SAT. Like, you both want to have the newest version as possible, but you also want to minimize the number of new packages downloaded and installed (sometimes a minor upgrade on a dependency makes you download another dependency, and so on, and you don't want to do that if you don't actually need the newest version). Now it gets harder. But the interesting part about optimization problems is that, although they are NP-hard, they can be interrupted at anytime, leaving you with a usable, although sub-optimal solution. So that part can be run in a limited amount of time. 
You can't cure all problems, but probably those two issues could be added to Clippy (is something like memset_s already in Rust std?)
If the library has a C interface, then it's pretty straightforward and explained in the ffi section of the book. If the library has a C++ interface, then you take a C++ compiler and write a library that binds to that C++ interface and exposes a C interface for you first.
&gt; what you are calling easy (more functions, more features) and more complexity. I do think we have a terminology difference. I'd defer to Rich Hickey's split between "simple" and "easy." It seem that you want something simple, and call that "easy". Sometimes, more complex things can be easier. For example, Brainfuck is turing complete. Rust is turing complete. Brainfuck is significantly simpler than Rust. That doesn't mean that "hello world" is easier in Brainfuck than Rust.
Have you seen [smoltcp](https://crates.io/crates/smoltcp)? It has a great many types that you might find convenient even if you don't want the network stack.
Remember that "coroutines" means many different things; we're specifically going with stackless ones. For example, the Rust version is *significantly* different and allocates much less than the C++ Coroutines TS, for example. &gt; Not every user case needs to be solved in the next year. Absolutely agreed. That's why the 2018 roadmap had *focus* as a goal. We picked four areas where we think we can *meaningfully* ship a good story, and are focusing on those.
&gt; mio still an alpha level mess Really why? I've never had issues with it. &gt; I work almost entirely in high performs systems where bugs cost money, but so does slow development time You work in what language now? 
My take would be in the hypothetical scenario where "text data" is using some encoding where `'\n' != 0x0a`. With UTF-16, splitting on `\n` could land you on a code point boundary depending on byte order. The fact that low code points in UTF-8 are ASCII-compatible is brilliant and make me feel like I'm living on the best timeline. This all depends on what you throw at your application. We can create data which use whatever encoding we want on Windows and pipe it to the application. Grep-like applications don't want to choke, because they want to find the given pattern independent of what it is being fed. But as a general strategy I think choking is good. If an application is designed to eat UTF-8, feeding it non-UTF-8 should yield an error.
I really enjoy reading about CLI tools implemented in Rust, and feel they are one of the best showcases for the language's abilities. It's also promising to see that your biggest pain points - Lexical Lifetimes and weak SIMD - are being fixed right as we speak. Thanks for the post.
Agreed. I was thinking more of handling non-utf8 code pages on Windows tho 
Also take a look at [aravis](https://github.com/AravisProject/aravis), which is used in tiscamera. It's mostly a C library, so it could be easier to wrap.
The important thing about memory ordering is that it's about prohibiting reordering of memory accesses along certain rules. By default, both the compiler and the CPU are completely free to reorder memory accesses or even elide them, as long as a single thread of the program cannot observe that this has happened. Thus, you may write: fn bar() { let a = 1; let b = 2; let sum = a + b; let c = 3; let product = a * b; external_foo(sum, product); } But the compiler and CPU are free to rearrange this to: fn bar() { let a = 1; let b = 2; let product = a * b; let sum = a + b; external_foo(sum, product); } This loses the write to `c` completely (it can't be observed by the single thread), and moves the write to `product` before the write to `sum` (`external_foo` is the first observation point, and it can't tell the difference). While this is awesome for making programs fast (the less work you do, the better, and you can rearrange so that a slow multiplication is executed at the same time as a fast addition on a modern [superscalar](https://en.wikipedia.org/wiki/Superscalar_processor) or [OoOE](https://en.wikipedia.org/wiki/Out-of-order_execution) CPU, it's not so good for reliable data sharing between multithreaded programs. Atomics impose an additional two conditions on the CPU and the compiler: 1. Atomic writes must be visible to all threads. 2. Atomic operations are indivisible. Point 2 needs a little bit of clarification; if I executed `let a = b; if a == 0 { b = 1; }` in multiple threads, the compiler and CPU are permitted to interleave the two threads so that they both do `let a = b;`, then both do the `if` block. On the other hand, if `b` is an atomic, and I do `let a = b.compare_and_swap(0, 1, Ordering::Relaxed)`, this cannot be interleaved with another thread - the entire `compare_and_swap` either happens, or it does not even start. This helps with synchronization, but still leaves a problem - if I don't want to do all my communication between threads via atomics, I need some way to stop the reordering that we discussed above. In the code: fn bar(go: &amp;mut AtomicUsize) { let a = 1; let b = 2; let sum = a + b; let c = 3; let product = a * b; if go.compare_and_swap(0, 1, Ordering::Relaxed) == 0 { external_foo(sum, product); } } The compiler and CPU are still allowed to reorder freely. It can, for example, execute as-if you wrote: fn bar(go: AtomicUsize) { let a = 1; let b = 2; if go.compare_and_swap(0, 1, Ordering::Relaxed) == 0 { let sum = a + b; let product = a * b; external_foo(sum, product); } } as this meets all the ordering requirements you've got. Memory orderings are about preventing the compiler and CPU from doing this. They set rules on what can move past an atomic operation: * `Relaxed` says that reordering is allowed as long as it would be allowed in the absence of atomics. * `Acquire` says that you cannot move earlier atomic reads (except for `Relaxed` ordering reads) after this read. You can, however move non-atomic reads or any write (atomic and non-atomic) after this operation. * `Release` says that you cannot move *any* earlier write operation after this write, whether it's an atomic write or not. You can, however, move any reads, or non-atomic writes after this operation. * `AcqRel` is only effective for operations like `compare_and_swap` above that do both a read and a write to the same location. It says that you cannot move earlier atomic reads (except for `Relaxed` ordering reads) after this operation, nor can you move any earlier writes to after this operation. You can, however move non-atomic reads after this operation. * `SeqCst` is the big hammer. You cannot move *any* earlier read *or* write operation after this operation, regardless of whether it was atomic or not. Note that these rules apply to both the compiler and to the CPU's execution hardware, which means that they cost performance - a rearrangement by the CPU to start a multiplication a cycle earlier is also barred, even if it would reduce the time your program takes to run.
Can't you use macro_rules to do that?
I hear you, but it's tough: I think it depends on where you come from. Many people I talk to say they don't want to use Rust because our type system is too simple; if you come from a dynamically typed language, it can totally appear too complex. Better explanations are certainly something we need!
I read the comment in the code that you linked. It seems that the solver does uses heuristics so that the first solution found during solution is a reasonable one. However, in the worst case it may take exponential time. Form the comments: &gt; Beyond that, what's implemented below is just a naive backtracking version &gt; which should in theory try all possible combinations of dependencies and &gt; versions to see if one works. 
I wouldn't recommend them personally. I left and they've had a high developer turn-over and been in "start-up" status for over 10 years.
This doesn‘t address the unsoundness though. Voth the C and C++ standard imply that a thread only sees stores of a thread that has previously stored to the SAME atomic object via Release and is now being loaded from via Acquire. However if hardware actually follows this properly and actually has some registry of which atomic objects have been written to, then Rust‘s atomics are unsound as Rust doesn‘t follow that model. Rust freely memcpys atomics around without any synchronisation and thus from a hardware POV the acquire happens on a different atomic object (because it has been memcpyd to a different location) and thus no synchronization needs to occur, and thus your code is unsound.
The hardware doesn't have that model - instead, the hardware has the reordering rules I've already described. The key is that `Acquire` loads cannot be reordered against any other `Release` stores, or against any other `Acquire` loads, regardless of address. There is no registry - it's all about reordering, not about objects, in the underlying hardware, although the C++ standard permits a weaker model so that the compiler can do more reordering if it so wishes.
I don't know what you're saying.
I don't think I understand your question. I suspect I don't know of any cut-off point, other than to say that if your problem domain permits, and you really care about every ounce of performance, then you'll want to avoid doing line-by-line. Pretty much for exactly the reasons mentioned in OP.
If you write a CLI tool for Windows and intend for other people to use it, then at one point or another, you'll run into UTF-16. This is a different problem than on Unix systems, where probably everything you hit will be ASCII compatible (UTF-16, of course, is not), and *most* things will probably be valid UTF-8. Handling UTF-16 is more complex. If you can read the entire file into memory, then it's easy: just use `String::from_utf16`. If you want to stream the file or use memory maps, then you probably need an explicit streaming transcoding step.
Nice! I have messed with Rust a bit but macros always seemed a bit daunting. This post cleared them up a bit for me.
Messing around with implementing an Icecast-style WebM live-streaming server. Probably picked the wrong time to come back to this project given the current churn with Futures and thus Hyper, but on the other hand I'm groking lifetimes better now, so I've been able to simplify my streaming EBML parsing code.
regarding the rolling buffer thing: check out [buf_redux](https://crates.io/crates/buf_redux) which has a [make_room](https://github.com/abonander/buf_redux/blob/67483b7961fb324f2c1365c0a15ddc371d29f79d/src/lib.rs#L801) method. I've used that in my network/file buffering needs and been happy with it.
This release *finally* brings a lot of the changes we've been working hard on. Please test it and give your feedback! The actual 0.5 release will be in a week or two assuming no major issues come up. Release tracker: https://github.com/rust-lang-nursery/rand/issues/232 Upgrade guide: https://github.com/rust-lang-nursery/rand/blob/master/UPDATING.md Full changelog: https://github.com/rust-lang-nursery/rand/blob/master/CHANGELOG.md#050---unreleased
It's a shame we can't rename `rand_core` to `rand-core`, but otherwise it's a promising release!
v0.1.2 with more translations is underway.
I read that as, "If you know the source is valid UTF-8 there's a shortcut method to validate the rest by ensuring you didn't slice in the middle of a code point at the end, in order to use something like `String::from_utf8_unchecked` and save from checking the entire buffer. Also with the added assumption you didn't start the slice in the middle of a code point." Although, I'm not sure how that would help when you don't know if (or there is the possibility of) the source containing invalid UTF-8, as in your comments above. It also relies on quite a few assumptions, which may or may not be valid depending on the problem domain.
Is adding a "fake" version (that takes two `chrono::DateTime`s, but converts them into Duration) to the API now (before the proper implementation is done) is a good idea.
"Grammar Snob" is a nice one that seems unlikely to upset anyone.
Hmmm, [minimal version selection](https://research.swtch.com/vgo-mvs) seems like a simple and elegant solution to guaranteeing consistent builds. This should really be the default in all build systems with an option to explicitly upgrade to the latest (or some later) compatible versions.
Nice post, and such a readable blog layout/theme!
You'll have to ask someone from the Italian, Spanish, ... communities weather those Mass murderers are funnier.
Correct, it uses a custom fairly nieve SAT solver, mostly so the error messages talk about the domain, packages and versions and things. But there are lots of bug reports about cargo hanging indefinitely, most of which have been closed in the past month. ( Announcement to come when the last PR hits nightly, in a day or two.) And there is now an issue to update that comment.
Read the comments on [C++ reddit about this article](https://www.reddit.com/r/cpp/comments/879gk3/top_10_bugs_in_the_c_projects_of_2017/). Pretty much to the point
Looking at the Github page, am I missing something obvious or does Rand actually have 30,000 commits?
Wait, what? You can get paid for shilling Rust on PCJ? Man, /u/cmov must be swimming in money...
I particularly wanted your opinion because you do care about portability. I use an editor which is great for code, but not for logs which get scrambled- because it tries to interpret the whole file as valid utf-8. Line by Line, can skip dodgy lines of course. But it can be better to grab \n delimited lines of [u8] sometimes. C of course doesn't care :)
there are so many free c++ static analysis tools available.
woow, exactly what I was looking for. It's a pity I didn't find it before.
Thanks for your work on improving the resolver! :D
Thank you.
What's the benefit of Boxed Errors? eg: ``` type Result&lt;T&gt; = std::result::Result&lt;T, Box&lt;std::error::Error&gt;&gt;; ``` I'm using a crate in a project now that does this and it makes error handling kind of annoying.
Yeah. It assumes the entire stream is valid utf8. Just avoids chopping at the ends accidentaly.
But given that it bails out early if it can find any solution, that would imply that the problem it's solving isn't NP-complete, yes? Been a while since CS. :P To use traveling salesman as an analogy, we're not trying to find the optimal path, we're just trying to determine whether the cities are connected in the first place (with some simple guiding heuristics to attempt to make sure that the first connecting graph that we find isn't total garbage). Even if it can take worst case in exponential time, that shouldn't really matter: *lots* of algorithms have an exponential worst-case, but--unless I'm radically misremembering my CS--truly NP-complete problems have exponential *best-case* time. :)
Glad it works for you!
Is it possible to call `ripgrep` without utf-8 support ?
Have you considered procedural macros? Then you should be able to do #[derive(SVGProperty)] enum { Miter, Round, Bevel, Inherit, } and get the same functionality.
Yes, Servo relies entirely on WebRender.
I think the best solution would be to have an official (as in http://careers.rust-lang.org/) board for companies to post jobs. That way it would become the is "the place" to look for rust jobs, containing every current open position that involves rust.
I have made an edit for the "Nazism" thing. I appreciate the advice -- how's it look? So, did you also want some "FTFY" in comments? Because `s/ware/where` and `s/there/their`. :) I genuinely hope to be helpful, and not be irritating or otherwise off-putting -- this community deserves better than that. I can simply stop if it ever gets to that point.
&gt; or to tell it "assume this input is valid utf-8 and don't do any checks" This is how it works by default. I contend that it can't really work any other way by default. I think examples are best here: First, create a file that is not completely valid UTF-8. $ echo -e 'a\xFFz' &gt; wat Try to find three consecutive characters. Since ripgrep has Unicode enabled by default, the *fundamental atom of a match* is a Unicode codepoint (technically, a scalar value). Therefore, nothing matches: $ rg '.{3}' wat Unicode support can be disabled, which switches the fundamental atom of a match to a *single byte*. We get a match, and our terminal helpfully displays the replacement codepoint: $ rg '(?-u:.){3}' wat 1:a�z Now try the previous query, but insist on valid UTF-8 (this isn't an intended feature per se, but just kind of comes with supporting all encodings provided by `encoding_rs`): $ rg '(?-u:.){3}' wat -E utf-8 1:a���z In this case, the UTF-8 transcoder inserts a [Unicode replacement character](https://en.wikipedia.org/wiki/Specials_(Unicode_block)#Replacement_character) in lieu of the invalid `\xFF` byte. It is odd that we see three `�` characters, though. Is the byte representation actually correct? $ rg '(?-u:.){3}' wat -E utf-8 &gt; output $ xxd output 00000000: 61ef bfbd 7a0a a...z. Looks good to me. The replacement char is encoded as `\xEF\xBF\xBD`, which is right. (I don't actually know whether rendering three `�` glyphs is correct or not, but the actual file contents are what I'd expect them to be.)
This is the key to `?` in main right? Should that be hitting nightly in a week or so now?
Yes, I think that would be a good idea. Deprecate the other function or heavily discourage it in the future, if possible.
For anyone unfamiliar, this enables `let v = try!(a_u64 as u32)`
You *may* be able to do some kind of internal iteration instead. *E.g.*, you could have a custom function fun try_fold_subimages&lt;R, E, I, F&gt;(im: I, f: F, init: R) -&gt; Result&lt;R, E&gt; where F: Fn(R, &amp;SubImage&lt;I&gt;) -&gt; Result&lt;R, E&gt;, I: GenericImage; and then implement everything in terms of that.
Using macros to replace boilerplate impls is probably the single most legit use case for macros, IMO. Good post!
How?
The spelling thing was meant to be tongue in cheek, I should have used something like :-P , but no, I'm pretty sure grammar is about how you put words together according to rules, it's not just "every rule pertaining to written communication."
A few days ago, the author wrote a short post that generated a lot of attention [here and on the Orange Website](https://www.reddit.com/r/rust/comments/86mtn0/100_days_with_rust_a_series_of_brick_walls/). This article is the followup.
Yeah `cargo add try_from` always felt a little odd, because the types I needed are *literally right there in Rust `std` docs*... :(
I paid my way to RustConf both times I went. I wouldn't expect my company to send me to a conference that has to relevance to my work. When I was a speaker my boss offerred but I didn't really follow up on that, and I probably would have had to have put my company's name on the slides or something silly like that. If I were to make the argument that the company should send me I would probably try to argue that: a) Learning about Rust will make me better at &lt;some relevant thing to my job&gt; b) We can recruit people who will be good at &lt;some open position&gt; c) One of the talks is about &lt;some relevant thing&gt; But all of these are really tough sells, even if you can argue all 3, and companies usually expect you to come back and actually perform some sort of knowledge transfer - so you can't just bullshit your boss on this. If you're in a financial situation where a ticket is out of your price range I'd suggest contacting the organizers.
I haven't decided on my personal error handling philosophy for Rust so I can't say if these are Good Things to have in general, but some potential benefits are - It allows the crate to put multiple unrelated kinds of errors into the box rather than having to explicitly wrap them all together into a custom struct/enum type and return that. - If some of the errors are large it can also keep stack usage lower than if it were an enum, which necessarily reserves enough space for its largest variant event if that's not the one in use. A box will use constant stack space and only the necessary amount of heap space. - The crate can also change which errors get put into it without breaking compilation for downstream users, and because you have to check the result of your downcasts any such change is likely to fall into a blanket error handling case rather than specific one, and that can be considered backwards compatible.
Thanks for the pointer! That's an interesting approach. I'd need to study it in a lot more detail to really understand it.
The linked tweet was tweeted by [@rustlang](https://twitter.com/rustlang) on Mar 27, 2018 15:57:58 UTC ------------------------------------------------- The libs team has also announced that they hope to stabilize SIMD in Rust 1.27! \#RustAllHands ------------------------------------------------- ^• Beep boop I'm a bot • Find out more about me at /r/tweettranscriberbot/ •
 &gt; 27! 27! = 1.0888869450418352e+28 
There's always those who don't fit the mold.. don't be sour about it. If you understand anything of what they are about, you should wish them well instead.
Good bot
https://github.com/rust-lang-nursery/rand/pull/344
Probably worth doing the git filter-branch thing and pushing the non-fast-forward commit. Pain in the neck for everybody, I know, but it would be nice to have the clean history going forward.
Any chance we could get a Permuted Congruential Generator crate like [this one](https://docs.rs/pcg_rand/0.7.1/pcg_rand/) integrated and used as the default SmallRng instead of XorShift? Should be simultaneously faster and better.
I did something very [similar](https://github.com/maps4print/azul/blob/master/src/css_parser.rs#L30-L43), although I like to leave the enums outside of the macro, for easier readability, using it [like this](https://github.com/maps4print/azul/blob/master/src/css_parser.rs#L540-L550). I am, however much more proud of the [calling code](https://github.com/maps4print/azul/blob/master/src/display_list.rs#L576-L580), mainly due to how complicated the function delaration looks. I also don't have one "AttributeError", I have a various error types depending on the thing to parse - a "ColorParseError", a "BoundingBoxParseError", etc. Though, the [usage](https://github.com/maps4print/azul/blob/master/src/display_list.rs#L599-L607) is quite simple. I didn't know you could delimit idents with `=&gt;`, though, I'll definitely add that to my parser.
I'm actually not sour about it, but don't think they have much chance of success, and it's true, they have had a *lot* of devs come and go.
All things worthwhile are hard.. and there's always people looking for a lazy quick win. Finding quality takes time too. What they are trying is worth the effort.
What people are you talking to? I have a feeling you are talking to people that want rust to be more research-language like and more Haskellish? Most systems developers I know think the type system is way too complex already.
No that's a separate feature, though it's also in its final comment period so should be stabilized soon.
Too many macros is rarely a good idea.
Upvoted because I find -8 a bit over the top.
Heh I down voted myself. Should have copied directly from the rfc 
Yeah sorry I should have pasted / not skimmed
Nice article! &gt; Slow, but only relative to "very, VERY fast" This is really Rust's performance story in a nutshell, and I love it.
&gt; [...] they hope to stabilize SIMD in Rust 1.27! &gt; they hope Good luck.
 &gt; 27! 27! = 1.0888869450418352e+28 
Will OsRng be optional, such as on WASM without stdweb?
Good bot
I wrote [entmut](https://github.com/dstu/entmut) to demo/play with a common zipper trait for navigating and editing several different tree implementations. You need HKTs/ATCs to be able to do a full-blown tree editing interface generically, but the navigational traits night be useful. I'd like to try making a common crate that defines this sort of interface and implements it for various popular crates, but I haven't needed to yet on the personal projects I've had time for.
Really detailed article. Thanks for linking it. Needs the strikeout removed from the link CSS. :-) 
Off the top of my head, t the point where you are writing the message len, you can: ``` let len_pos = buf.len(); // Write a bogus length buf.write_u16(0); // encode the body // 2 is the size of the length field let len = buf.len() - (len_pos + 2); // Write the length field Cursor::new(&amp;mut buf[len_pos..len_pos+2]).write_u16(len); ``` The last bit requiring `std::io::Cursor` is annoying and will be fixed in the next breaking release. You can also use `ByteOrder` directly to write the len at the specified position. I did not verify that any of the code is correct, so double check it :)
No problem, it happens. I wish people weren't so downvote crazy, like, we get it, someone said something somewhat incorrect. *-9 is excessive*.
I have some specific libraries in mind, but I'm not of a mind to shame them. :P I'll just say, don't use macros as a replacement for functions. You know who you are!
Glad to see this stabilized after so long :) In two related PRs ([one](https://github.com/rust-lang/rust/pull/49305), [two](https://github.com/rust-lang/rust/issues/49415)) there's some discussion about the portability of `impl From&lt;u32&gt; for usize` definitions. It just reminds me how annoying dealing with `u32` indices are. I kind of long for a `#![exclusive_target(x86_64)]` crate attribute, denoting that I specifically only care to target x84_64. Then it'd be nice if `u8/u16/u32/u64` coerced to `usize`. The other way would still require an `as` conversion to denote truncation. Perhaps this is best accomplished by adding some more impls to [`std::slice::SliceIndex`](https://doc.rust-lang.org/nightly/std/slice/trait.SliceIndex.html). I don't see any other issues in the rfc repo mentioning this trait, so maybe I should bring it up there. I'm writing a graph processing library, where memory usage is a potential constraint, so saving 50% space on indices is huge, but it just makes code annoying in a lot of places sprinkling `as usize` or `as u32` everywhere. I guess this is somewhat similar to the [nonportable RFC](https://github.com/rust-lang/rust/issues/41619) but that was only concerned with OS features. 
To give some context, in most cases NP-complete problems are defined as decision problems. For example, for TSP the question is in most cases defined as "Is there a tour of cost at most K", and for SAT problems the question is simply "Is the formula satisfiable". Optimization variants can be achieved by iterating the base question several times. Also important to remember, we do not yet know if there are algorithms that are always fast for NP-complete problems, and most researchers believe that there never will be. We suspect that NP-complete problems will require exponential worst-case complexity (big-O complexity), but it is not known. For many NP-complete problems many instances are easy to solve, while only some require lots of time to solve. This has been well studied for SAT problems in particular, where only a small set of problems close to the switch between satisfiable and unsatisfiable are actually hard to solve for a modern SAT solver. Now, back to the problem that cargo solves. It is known that solving the dependency graph resolution (lets call it DGR) problem can encode any SAT problem, and therefore it is NP-hard. It is also easy to see that DGR is in NP (given a proposed solution, it is easy to check if the solution is valid). Thus the problem is NP-complete (in NP and can encode another NP-complete problem). This means that there is no known algorithm for solving a DGR problem that does not have exponential worst-case time. Note also In practice, most instances of DGR that occur naturally are probably very simple to solve for most algorithms. If you take a really large instance, and iteratively add additional requirements that remove found solutions as far down the search tree as possible, it is probably easy to construct a case where there is no known solution and the algorithm will take a very long time. Side note: Why is the proposed vgo version of dependency resolution not NP-complete? It is because the expressiveness of the dependency specifications is limited so that only 2-SAT can be encoded, which is a problem that has an effective algorithm that runs in polynomial time. This comes with a cost: some dependency requirements that can be expressed with cargo can not be expressed in vgo.
I tried, but the closest I got is this. It needs you to repeat the identifier, but at least it works on stable. macro_rules! bind { ($(let $ident: ident: $pat: pat = $expr: expr;)*) =&gt; { $( let $ident = match $expr { $pat =&gt; $ident, _ =&gt; unreachable!(), }; )* }; } fn main() { enum A { Foo(i32), Bar }; let x = A::Foo(10); bind! { let y: A::Foo(y) = x; } assert_eq!(y, 10); }
Crater downloads the latest version of every crate, and their dependencies. That’s one bot we know about, there may be others.
Kind of makes me wish we could parameterize `Vec` with a type for the indices...I wonder if that would be a useful crate?
Interesting, thanks. I don't remember seeing TSP phrased as a decision problem before, or the optimization variant being phrased as an iterated decision problem. But that does mean that the only way to actually solve the optimization problem is still to brute force all the possibilities, yes? (Or is it too presumptuous of me to presume P!=NP?) And when we talk about using a SAT solver to resolve dependencies (like, IIRC, in apt-get), presumably we're usually talking about the optimization variant rather than the decision variant? And Cargo's early-bail behavior means that it deliberately sidesteps the need to brute-force an answer to the optimization problem, in exchange for being content with suboptimal results, and will usually exhibit worst-case behavior only when a solution doesn't exist? I'm not trying to argue here that Cargo's algorithm is at all akin to vgo's, because it's obvious that vgo's is more restricted; all I'm trying to say is that Cargo's algorithm isn't isomorphic to a SAT solver because Cargo usually doesn't give you the same answers that a SAT solver would, in exchange for more favorable best-case time complexity. Am I incorrect somewhere? Am I being too imprecise with terminology? I was a solid C student. :P
I imagined the same - could have a 'default = "Miter"', in a way somewhat similar to `structopt`
Below are some notes and remarks as I look through [the documentation](https://docs.rs/rand/0.5.0-pre.0/rand/). In the "Cryptographic security" section of the main page: &gt; Potential threat: are algorithmic generators predictable? Certainly some are; algorithmic generators fall broadly into two categories: those using a small amount of state (e.g. one to four 32- or 64-bit words) designed for non-security applications and those designed to be secure, typically with much larger state space and complex initialisation. Whatever the intent of the passage, this reads to me like it *equates* state size and security, which is wrong—a simple counterexample is that the Mersenne Twister has a large state (624 bytes, IIRC) but is completely insecure. Additionally, four 64-bit words are 256 bits, which doesn't strike me as a necessarily insecure state size (e.g., I think an AES-based CTR_DRBG would have about that much state). The passage continues: &gt; The former should not be trusted to be secure, the latter may or may not have known weaknesses or may even have been proven secure under a specified adversarial model. We provide some notes on the security of the cryptographic algorithmic generators provided by this crate, `Hc128Rng` and `ChaChaRng`. Note that previously `IsaacRng` and `Isaac64Rng` were used as "reasonably strong generators"; these have no known weaknesses but also have no proofs of security, thus are not recommended for cryptographic uses. I would very much avoid the term "proof" here, since it's notoriously easy to misunderstand. For example, a "provably secure" algorithm, by definition, can actually be insecure (if its security proof reduces it to a problem that turns out to not actually be computationally hard). I'm also concerned that the term "proof" is being misapplied here—I think that what this passage is trying to convey is not that HC128 or ChaCha are provably secure (or differ from Isaac in provable security), but rather that they have been more stringently cryptanalyzed than Isaac. Or even simpler, that cryptographers do not consensually trust it to be secure. One potential pitfall that recurs through this is that it seems to me like the documentation is sometimes unclear who the audience is for which passage, and thus often gives what's either too much or too little information—a reader that doesn't know a lot beforehand is told a bunch of stuff they can't understand, while one who knows more isn't told enough to understand. In [Struct `rand::prng::chacha::ChaChaRng`](https://docs.rs/rand/0.5.0-pre.0/rand/prng/chacha/struct.ChaChaRng.html): &gt; We deviate slightly from the ChaCha specification regarding the nonce, which is used to extend the counter to 128 bits. This is provably as strong as the original cipher, though, since any distinguishing attack on our variant also works against ChaCha with a chosen-nonce. See the XSalsa20 [3] security proof for a more involved example of this. I'm confused by this passage. I know what the XSalsa20 nonce extension is, but the passage leaves me wondering how it's relevant to this use of ChaCha as an RNG, since this is an application where clients don't actually supply nonces. The passage says that the motivation is to extend the counter to 128 bits, but the "modified word layout" diagram below already shows that the state has 128 bits for the counter *before* nonce extension is applied. There's some equivocation going on here between the terms *nonce* and *counter*, I think. The methods `new_unseeded` and `set_rounds` on the `ChaChaRng` type are a bit scary, IMHO. I'm heartened that the former is deprecated, but maybe the warning ought to be strengthened (e.g., "This method makes it too easy to create a random number generator in an insecure state.") `set_rounds` sounds like something that should only be allowed when the object is being created. More generally, I just noticed that there's no "raw" method for creating a `ChaChaRng` from a key and nonce/counter—I think there ought to be one. `set_counter` is also a bit scary but something like it is most likely necessary to support non-cryptographic applications (e.g., producing multiple random streams from the same seed by advancing far into the generator's sequence). In the page for [Struct `rand::prng::IsaacRng`](https://docs.rs/rand/0.5.0-pre.0/rand/prng/struct.IsaacRng.html): &gt; Although ISAAC is designed to be cryptographically secure, its design is *not founded in cryptographic theory*. Therefore it is not recommended for cryptographic purposes. It is however one of the strongest non-cryptograpic RNGs, and that while still being reasonably fast. This is another of those cases where I think neither a newcomer nor a seasoned reader can figure out what this means. I would consider just saying that Isaac: 1. In spite of being designed with cryptographic security in mind, hasn't been stringently cryptanalyzed and thus cryptographers do not not consensually trust it to be secure; 2. Is notably fast and produces excellent quality random numbers for non-cryptographic applications. &gt; Where fast random numbers are needed which should still be secure, but where speed is more important than absolute (cryptographic) security (e.g. to initialise hashes in the std library), a generator like ISAAC may be a good choice. This is another statement that I just don't understand. The reader is giving no criterion for deciding which applications are such that "speed is more important than absolute (cryptographic) security." I fear people will be encouraged to get cocky and take undue risks. In [Module `rand::distributions`](https://docs.rs/rand/0.5.0-pre.0/rand/distributions/index.html): &gt; A distribution may have internal state describing the distribution of generated values; for example `Range` needs to know its upper and lower bounds. But looking at the docs for `Range` it seems to be immutable, so the passage above seems to misapply the term *state*. And now I'm confused whether distributions are actually allowed to be stateful objects and the `Range` example just failed to illustrate it, or whether they're not and it's just the common OOP mistake of referring to any internal values as "state."
What a wall of text! It would be more useful if you would open an issue on GH.
Typically one would not solve an optimization problem as an iterated decision problem, no. However, the NP class is actually defined as a decision problem class so iterated decisions for optimization is an easy out for showing equivalence between decision variants and optimization variants. The reasoning used to show that dependency graph resolving and SAT are equivalent is about the problem definitions, without regards to any possible algorithm to solve them. Similarly, vgo solves a problem that is easier (assuming P!=NP, which we I for one always assume, anything else would be too crazy), and this is also without regards to the actual algorithm used. It is possible to solve the problem vgo solves with an inefficient algorithm, but that would not make the problem itself harder. Adding optimization criteria to the problem only changes the definitions around some, but it does nto make it inherently different. My example for how one could construct a hard problem was only intended to show how one could go about doing that, not that it was the only way. It is still the case that since SAT and the dependency grapg resolution problem are equivalent, _any_ algorithm that solves the problem will have exponential worst-case behavior. I agree that cargo giving the first possible result and using heuristics to guide it to a "good" solution is a great way to solve complex combinatorial problems reasonably, especially when it is an optimization problem. It is important to remember that it is just a hack that will sometimes work, and perhaps work well for a large class of the problems of interest to solve. However, it will not work for all instances, and not even for all normal instances probably. It might be the case that one could show that all "reasonable" instances are easy enough, but that is very hard thing to show if it is true and not something that I would not assume is true. 
For now OsRng will simply panic in that scenario; later we plan to allow custom OsRng. There is still the option of not using it; unfortunately both `thread_rng` and `NewRng` require OsRng (or JitterRng) to function.
I think I had the same problem as you with the enum conversion. I wrote a little crate to derive From for enum's. It's on crates.io as from_repr_enum_derive.
Would it? I never look back that far, and I'm not really sure what "clean" means anyway (even best-case there are going to be a hundred or so merges).
The context defines which k8s cluster you're talking to. If you only ever talk to one cluster you wouldn't have to specify it. We could probably make click just default to that one if you only have one in your config file. However, since Click remembers your last context, you can just set it once and forget about it forever. (maybe a hide-context option would be useful though, to de-clutter your prompt)
I recently saw and passed over the classic unsigned int bug in loops (c code though). `while( u32 i &lt;= 0 )` - should be a lint if it isn't already.
Looking forward to seeing what you've changed in the resolver. Dependency resolution is a a really fun and interesting problem that lots of people re-discover the need to solve, and solve in some pragmatically efficient manner. My background is in constraint programming, and the system I was a part of building (Gecode) suddenly got a huge spike in downloads when [Chef started using it as a backend for solving for their dependecy graph resolutions](https://github.com/chef/dep-selector).
Thanks for your expertise, it's only people like you that keep me from accidentally spouting lies on the internet. :)
I don't see the relation? Any compiler should warn on that because the loop condition is always true. But even in the context of this discussion, coercing between signed / unsigned is very bad and should not be allowed. Again, I just want indexing to be easier. Expanding `SliceIndex` would be great.
Redox doesn't seem to be an RTOS
Thanks. It's fun to answer when I just happen to know the answer well. Please don't hesitate to ask more if anything is unclear, and I'll come back to it tomorrow.
This is going to get heavily confused with [click](http://click.pocoo.org/5/), the Python CLI library.
I'm happy to see custom allocators, Alloc, and placement-new on the agenda. It's been *a long time* coming but the lack of these things is a gaping hole in Rust imo.
I was saying that form my own past mistakes. Long macros can bloat the final binary at an impressive rate. Some macros are also nearly unreadable too. Powerful feature to be used sparingly.
From the code snippet, the analysis of 7th looks wrong. It appears that the `memset` is supposed to just clear the struct before being used as an out parameter, but then there's a typo and the wrong pointer is actually passed - look at this *very* suspicious argument pair at the end: `&amp;out, sizeof(dout)`.
You raise an interesting point. Even if a problem seems to be NP-complete, it is not always. I mean, even if P != NP, there are many problems that are reduced to SAT instances that can be solved in polynomial time. The reason why SAT solvers are so efficient in practice is probably that there are much more than we think.
Nope.
As a rust newbie, what exactly does that mean? Can I basically change all calls of `into` to `try_into`? 
While the warning is on by default for rustc, gcc requires a `-Wtype-limits` flag to warn about comparing an `unsigned` to `0`. The flag is not included with `-Wall`, but is included with `-Wextra`. Usually, using both `-Wall` and `-Wextra` is a good idea.
Well that is a stark reminder that life is a do-ocracy. I did not do anything cutting edge, nor profound. My background is ... not relevant to this work. I am sure you, or anyone with the background, could have done more, better, and faster. But I had the spare cycles and did the work.
&gt; What good is it? Honestly, I haven’t found a use case that couldn’t be solved by something weaker yet. I’ll be glad if you can provide one. Dekker's algorithm requires SeqCst ordering on its internal variables. It's one of the earliest mutual exclusion algorithms.
Was I correct in thinking that apt-get (or other distro package managers) use honest-to-god SAT solvers? If not, are there any other practical examples of their use in the wild that I might be able to appreciate?
Actually I did some big effort on that, but just filter-branch is not enough. Something went wrong during the earliest commits extracting rand out of the rust repro, and the history has two roots. Don't know if it is wordt the trouble to bring the cleaned-up history over...
Algorithm that cargo currently uses, despite the comments claiming a DFS, is a backtracking search with [`value ordering`](http://intelligence.worldofcomputing.net/ai-search/intelligent-backtracking.html). [Sorece](https://github.com/rust-lang/cargo/blob/master/src/cargo/core/resolver/mod.rs#L977)
The issue you're running in to is generally called "coherence". The problem is that if the compiler accepted your implementation there would no longer be a unique way to resolve this situation: let x: GenericStruct&lt;T&gt; = ...; let y: GenericStruct&lt;T&gt; = GenericStruct::&lt;T&gt;::from(x); Either it could use the `impl` you're trying to write (`impl&lt;F, T&gt; From&lt;GenericStruct&lt;F&gt;&gt; for GenericStruct&lt;T&gt;`) or the one in core (`impl&lt;T&gt; From&lt;T&gt; for T`). I think you're correct that specialization should allow this, but at this time it probably won't work. [This `impl` in core would need to be marked default first](https://github.com/rust-lang/rust/blob/9c9424de51da41fd3d1077ac7810276f8dc746fa/src/libcore/convert.rs#L404-L408) assuming I'm reading [the specialization RFC](https://github.com/rust-lang/rfcs/blob/master/text/1210-impl-specialization.md) correctly. This doesn't mean you can't provide a `From` method of the form you desire for your type though, it just means it won't apply when `From` bounds are expected; which may or may not be good enough for your usecase. It would look something like this impl&lt;T, F&gt; GenericStruct&lt;T&gt; where T: From&lt;F&gt; { fn from(o: F) -&gt; Self { // do conversion from `o` to an instance of GenericStruct&lt;T&gt; using From&lt;F&gt; for T } }
I work a lot on compilers, and it happens every now and then that you have a syntax tree (represented as a enum), and you know that an instance of that syntax tree is a particular branch (e.g. because of typechecking) and you just want to extract the fields of the particular arm. I don't think it's that common, which is why it's not covered by the standard library!
This works too for a few cases! It doesn't generalize to multiple variables (e.g. A::Multi(x, y)), although you could work around that by having `$($ident),*` maybe.
I just published my first crate: [linked_array](https://crates.io/crates/linked_array). This is an idea I've had floating around for a while now and I figured I could try publishing it. The gist is instead of having an enum with 2 variants, you'd have a trait with 2 implementers. Instead of linking nodes with pointers, one would physically contain the tail as a whole value. This necessitates different types because otherwise it would have a recursive type. The main benefit is that it has a fixed size and can be passed around as a single value, and in general should have the same in-memory representation as a flat array. The 2 main reasons why I came up with this was to get passed Rust's lack of integer generics, and to potentially use in a pure functional language designed for low-level programming where the heap doesn't exist and arrays are hard. A major problem for me is I'm not entirely certain how to properly document and test it, so I could use some assistance in that department.
It means that you'll be adding `try_into` into your data conversion toolbox for anything that's fallible and may return a `Result`. You'll probably want to keep plain `into` calls where you can because it's simpler code. :)
We are a legion. We don't forgive, we don't forget. Memes are immortal. Always Rust.
I refined it a bit more to take a token tree instead of an identifier, so that it can accept both an identifier, and a tuple. macro_rules! bind { ($(let $lhs: tt: $pat: pat = $rhs: expr;)*) =&gt; { $( let $lhs = match $rhs { $pat =&gt; $lhs, _ =&gt; unreachable!(), }; )* }; } fn main() { #[derive(PartialEq, Debug)] enum A { Foo(i32, u32), _Bar }; let mut x = A::Foo(10, 20); { bind! { let (y1, y2): A::Foo(y1, ref mut y2) = x; } assert_eq!(y1, 10); *y2 += 2; } assert_eq!(x, A::Foo(10, 22)); }
Your solution (though solid for my use-case, thanks) wouldn't work since `F` isn't constrained by "the impl trait, self type, or predicates" :/
I feel Rust really needs to get out of its academic and Haskell-oriented echo chamber and try to pull in more people that actually do a lot of system programming in C/C++/Java and let them have a voice in terms of what is important.
I've never used the feature, but [this page](https://doc.rust-lang.org/cargo/guide/project-layout.html) says in a `benches/` subdirectory in the project root.
But the features seem to be heavily driven by the Haskell/Scala crowd.
Async stuff and ergonomics around async (which is what drives async await) is one of the largest things that production users ask us for, directly. If other industry users want things, we are super receptive to it. We’re following what we hear, and can’t act on what we don’t hear.
Good point. I think the ergonomic benefits of compile-time verified commands are big enough to warrant slightly trickier handling of things if something goes wrong.
I'm trying to use ```diesel print-schema``` to auto-generate my table schema for a web project. However, I'm running into issues regarding foreign keys--specifically, the auto-generation fails with the file being generated and its contents only reading "Diesel only supports tables with primary keys." How do I use this with foreign keys, as from everything I've seen in the documentation, Diesel /does/ support foreign keys.
Probably they tested on a known working device for this proof of concept...
Or even `#[default]` on one of the variants. 
I thought the same. There's a somewhat higher overhead to put it together: more code and needs its own crate. But potentially more powerful. Probably where they want to end up, but starting with a regular macro is not a bad idea to get up and running faster.
&gt; Really detailed article. Thanks for linking it. Yep! brandur has some great articles, particularly around postgres and API design. &gt; Needs the strikeout removed from the link CSS. :-) I _think_ you might be referring to the underline. Your browser might not be rendering that correctly!
I have refactored a lot of code in the [Monero node](https://github.com/xmr-rs/xmr) I'm creating in Rust. The levin server (networking protocol that Monero uses) has been separated from the p2p code and it's a bit cleaner and more multi-threading friendly. However these days development has stopped because writing the synchronization code is giving me a lot of problems (and headcaches) because of the mess that Monero source code internals are, most of the time is spent in reverse-enginerring the Monero internals and testing if i'm doing things correctly. I think I need to go afk some days to think more clearly and come with goods solutions again.
It'd make cloning the repo *much* smaller.
Hey would someone mind sharing a before and after example of what this release solves?
Oh crap, sorry. I wrote that last snippet right before running out and missed it. You need to write it like this: impl&lt;T&gt; GenericStruct&lt;T&gt; { fn from&lt;F&gt;(o: GenericStruct&lt;F&gt;) -&gt; Self where T: From&lt;F&gt; { GenericStruct { t: T::from(o.t) } } } Basically the parameter `F` has to be consumed somewhere, in the `impl` line (something of the form `F: ...`, `TypeImpledFor&lt;F, ...&gt;`, or `TraitImplFor&lt;F, ...`). I thought that the `From&lt;F&gt;` bound would count but apparently not, that's what I get for not testing snippets I write =/. Moving the parameter to the function works because it's used directly in that type declaration.
I think it's mostly a matter of convenience, and as long as you don't have * imports for *every* library you use there's no harm done. In the case of diesel and some other libraries these use statements usually provide access to a bunch of trait methods. If they're frequently used, you can end up in loops like this: 1. alter a query in some method in your program 2. ERROR: method "get_foo" is not available, it's in "FooTrait" 3. you import FooTrait 4. you get a bunch of warnings about unused imports for the method calls you just replaced with "get_foo" 5. repeat I guess you do pollute your namespaces somewhat, but what's the harm? It's only the namespace of that specific module you just used that * import in. Personally, I don't use them often, but they're just extra convenience sometimes at no real cost. Worst case, you run into a method naming conflict and change that specific import. The compiler error messages about that are pretty clear, so there's no big search for bugs or anything involved.
The benefit is that it's shorter and less noisy. You don't have to do it if you don't want to. Some people like it because, in the context they are working, it wouldn't be all that useful to list every import. Especially if you've got hundreds of them. That's just a big mess of text that you aren't going to read anyway.
It is my impression that if my web application is primarily issuing database calls then I won't benefit by actix. Am I correct?
Not quite. It's _very_ unlikely that Actix will be your bottleneck. Any benefits you'd get from Actix would be orthogonal to its speed or related to the Actix' API and design. I believe the author is active on this subreddit, perhaps they can give a better answer than me.
I don't think this properly discusses the tradeoff of using macros like this. Sure, there's some minor code savings, but it is no longer clear to the reader of the macro what actually is going on. They have to learn the language of your macro in addition to that of Rust. It also harms the ability to find where logic is defined. For example, if I want to find where a type comes from, I will often grep for `(struct|enum) Name`, which will no longer return this type (in fact there's no easy way to find where the type is defined) I'm not saying it's a bad idea to use this macro, but there are major tradeoffs that are completely ignored here
I'm pretty sure it's considered a bad practice in most cases. In case of `diesel`, it just reduces noise. It's pretty easy to guess where type came from in that case. In case of `chrono` prelude (notice how it's neatly grouped together in one module) it just helps you to start using it without thinking what traits you need to import. Now, I'd rather use `use diesel::sql_types as types` and explicitly use them. I mean you have std's predule imported and it doesn't seem to bother you... 
Thanks for the write-up. I'm glad neon is working well for you. FYI the "this article" link just points to this week in Rust. I want to see that article :)
Glob imports are better during growth, listed out imports are better for reading later. Ideally we'll get a "cargo bake" command which can do things like replace star imports with the fixed list of whatever you're currently using in that module.
Thanks for the FYI! Fixed it and [here](https://keminglabs.com/blog/building-a-fast-electron-app-with-rust/) is the link :) Looking forward to see how can I contribute back to the project!
At quick glance this looks super cool! I'll dig in a bit more later, but wanted to quickly point out [kubeclient](https://github.com/anowell/kubeclient-rs) which might be of interest here (the crates.io crate is outdated compared to the repo, and the now much of the client is generated from the OpenAPI spec), but I'm definitely open to collaborating on a k8s client library here. I'm also working on a separate ncurses UI around it - a `top` like interface for interacting with the kubernetes API. It's not yet on Github, but I'll try and get it (unpolished as it is) pushed to a repo in the next couple days.
I know exactly who you mean.
It is better to write it explicitly in most cases, but sometimes you want to use 50 structs/functions and you prefer spending time on other stuff than writing all the imports.
Neat! I've just been defining my own try_into trait that matches the api of the real one. Now I can just delete that trait and everything will still work :D
Wow.
Why is this perplexing you? A similar thing is possible in Python.
It's awesome to see someone pushing `rand` forward! However, there's quite a few unconventional/unexpected changes here that don't seem to have the *why* explained: &gt; Floating point types (f32 and f64): Uniformly distributed in the open range (0, 1). This... breaks with every other programming language I know. It seems worth giving some motivation for the decision in the docs. &gt; `Rng` and `RngCore` Rust has generally moved away from having extension traits for utility methods. Could you say some more about why these are separate? None of the methods seem like they need `std`, so it's presumably not for `#![no_std]` purposes. Also, I believe adding `where Self: Sized` to generic methods resolves object-safety problems, like `Iterator`. &gt; `NewRng::new` These seem like they could have a better name: with such an innocuous and common-initialization name (i.e. a lot of things have a `new` that just fills in some fields/does some simple preparation), it's not obvious that it'll be hitting the OS/hogging CPU time. Maybe `from_entropy()` or something. &gt; `BlockRng` All the fields are public? --- Other observations: &gt; `iter::repeat(()).map(|()| ...)` I find that this pattern doesn't express the intent at all, and "generate a sequence of random numbers" has to be reverse-engineered. :( &gt; `Uniform` This trait seems to not have an expressible rule about what values it generates, and even if there is a rule, it's not uniform: it doesn't give all possible values of the type (see the floating point types), and it's not even a uniform distribution across some subset of the values of the type (`Option`). Lining up with statistics, like the rest of the distributions, it'd probably make more sense to rename `Range` to `Uniform` (I think I was the one who chose the name `Range`, and I now don't think it was a good choice) and call what's currently `Uniform` something else. Also, something cute: `Rng`s can implement `Uniform`. This would mean that `NewRng` isn't entirely necessary: `EntropyRng::new().sample::&lt;StdRng&gt;(Uniform)`. In `Range`: &gt; Ignore the RangeInt&lt;i32&gt; parameterisation; these non-member functions are available to all range types. (Rust requires a type, and won't accept T: RangeImpl. Consider this a minor language issue.) Why is this parameterized by `&lt;X as SampleRange&gt;::T`? Couldn't it be parameterized by `X` itself, and store `&lt;X as SampleRange&gt;::T` internally? struct Range&lt;X: SampleRange&gt; { x: X::T } impl&lt;X: SampleRange&gt; Range&lt;X&gt; { fn new(low: X, high: X) -&gt; Range&lt;X&gt; { Range { x: X::T::new(low, high) } } } This has the bonus of making the `Range` type itself nicer: `Range&lt;i32&gt;` instead of `Range&lt;RangeInt&lt;i32&gt;&gt;`. (Also, why's that associated type called "`T`"?! And `RangeImpl::X`? Unlike `&lt;&gt;` generic parameters, associated types are part of the public API like type names and function names, in that users of the library will write them in their code. These particular ones will also be rarely written or read, so there's little value in making them short/unexplained.) Lastly, having `Range&lt;char&gt;` would be neat. (Also, when I was looking at this, I thought that `rng.sample(0..10)` would be neat, and, in particular `rng.sample_iter(0..10)` would be good, and it'd be nice for it to be fast: some sort of `IntoDistribution` trait or something, but getting the generics to work nicely was hard.) &gt; Add Rng::gen_bool. (#308) This implementation is biased: `gen_bool(0.0)` has a non-zero chance of returning `true` because of the `&lt;=`. &gt; // we use the lorentzian distribution as the comparison distribution &gt; // f(x) ~ 1/(1+x/^2) Since both `Poisson` and `Binomial` use this, it seems worth pulling out into a separate `Cauchy` distribution (for the name: there's approximately 5x as many google results for "cauchy distribution" vs. "lorentz distribution" etc.). This would also allow it to be independently optimized and, in particular, it seems worth using a Ziggurat-like algorithm, given, by my basic benchmarking just now, `tan` is ~half the speed of `ln`, and the simple Exp(1) was faster with Ziggurat than `-f64::ln(rng.gen())`. Although, it's fair to say that all the other `sqrt`s and `log_gamma`s will mean these optimizations aren't that much of a percentage improvement for those two discrete distributions. Also, I suspect that rejection sampling with `&gt;= 0.0` isn't necessary: the bias from using `rng.sample(Cauchy).abs()` will likely be less than the bias from floating point error. (This applies to both Poisson and Binomial.) --- On that note, how much testing of distributions has been done? When I first implemented Normal and Exp there was an off-by-one error that resulted in a very small bias (the mean of `Exp1` was 0.4% too low): https://github.com/rust-lang/rust/issues/10084 The testing I see [for `Poisson`](https://docs.rs/rand/0.5.0-pre.0/src/rand/distributions/poisson.rs.html#119) and [for `Binomial`](https://docs.rs/rand/0.5.0-pre.0/src/rand/distributions/binomial.rs.html#133) don't seem like they'd catch a little error like this: for Poisson, `avg` ends up being N(λ, λ/1000), and it's quite unlikely (0.001) that this falls outside [λ - 0.5, λ + 0.5] which is good for a test... except the interval is so wide that it's also very unlikely that N(λ + ε, (λ + δ)/1000) would fall outside it, which is the distribution to which `avg` would converge if there was a small bias/bug. The probability of this occurring with a 0.4% bias in the mean is about 0.004, i.e. only 4&amp;times; more often than the correct one, and both of these are so rare that I don't think I'd be able to tell "this test is failing more often than it should". I ended up doing some relatively aggressive tests using moments and Kolmogorov-Smirnov that (retrospectively) caught the off-by-one issue easily: https://github.com/huonw/random-tests (the code itself is waaaay out of date now, but the idea is still valid, I think). Also, stepping back a bit: is there a reason for `rand` to include all the distributions itself? It seems like, other than the fundamental `Uniform` and `Range`, they'd fit better in a separate crate. --- To finish on a positive note: `Distribution` is nicer than `Sample`/`IndependentSample`, and `Poisson` and `Binomial` are nice additions to that set of things!
You typically won't see things like `std::path::*` or `serde_json::*. Or at least you shouldn't. You're right in not wanting to pollute your name space. Diesel queries use A LOT of elements that would need to be imported. I already use 2-3 diesel use statements in my code even with gobbing. Without it you'd need a half dozen for a simple select query. 
Is from/to really that widely used? I never hear people talk about them.
I considered it and they could definitively be used! The reason why I didn't was simply because to where I was going to deploy (AWS EC2 t2.nano) has only one thread. I actually checked if maybe their one vCPU was multi threaded but no :-( 
I didn't mean that there is a rewrite. I'm just talking about bindings!
This is not an uncommon complaint and various solutions have been attempted. The `failure` and `error_chain` crates are especially worth looking at.
If you want me to take a shot I'm happy to. Or we can leave it alone, as you prefer. Might be fine to just truncate the history to the point where it left the main Rust repo, assuming they preserved it over there?
It's definitely a judgement call. It's going to mean more disk space and network traffic this way, but not an intolerable amount. Folks trying to research the early history of the project may get confused. I don't know.
Thank you!
When's the last time you read a book which listed every vocabulary word used in the text? Probably not since elementary school. As a more proficient reader in middle school, you probably just needed a glossary of less-frequent terms, and adult-level texts only define the most technical items of their vocabulary. Imports are really just building the lexicon you'll need to express yourself. That kind of globbed import communicates "I'm going to speak Diesel jargon in this module, you might want to have [its docs handy](https://docs.diesel.rs/diesel/index.html)." If you need a big vocabulary, globs can be *much* more clear than listing every vocabulary item in a giant wall of text. A very clear coding smell is "don't look at that, the IDE hides it away anyway" - and that's standard practice with import blocks in Java. Ideally (if you take literate programming as a kind of ideal) `use` lines in Rust should communicate something. They're a kind of bibliography and should give you a sense of how tightly the module at hand is bound to other crates and modules. Too much globbing can be bad, then, if it obscures the answer to the question "what do I need to understand to be able to read this module?" Like, you maybe shouldn't import `std::sync::* if you only use `Arc` `Mutex` `Once` but not `Barrier` (which feels like potential namespace pollution). 
Thanks for the kind words. Your project looks very interesting. I'd be happy to off-load actually talking to cluster to a solid library. I had a quick look and I see you're using reqwest, which is also what I've been thinking of moving to (it didn't exist when I started Click). But last time I tried it out it couldn't load simple .pem files to do authentication, and it seemed like it was gonna take a lot of hacking for me to build a pkcs12 myself. Have you solved that? I'll have a closer look in the near future, and thanks again!
I think it would be "is", as the sum is singular.
I pondered that for the longest time! English being a second language didn't help either :)
I prefer it over `as`.
I worked on [this PR to reqwest](https://github.com/seanmonstar/reqwest/pull/176) to land support upstream. It's usage in kubeclient [looks like this](https://github.com/anowell/kubeclient-rs/blob/b7b04c9addb3aecff82f1a2af7b0e5ac8e9a45c4/src/clients/low_level.rs#L51-L55) (which could be cleaned up for sure) Anyhow, I think kubeclient has work to go before calling it a "solid library". It is generally working well with k8s 1.9 for interacting with the resource types listed [in this directory](https://github.com/anowell/kubeclient-rs/tree/master/src/resources) - which is just the set needed by my original use case. Part of why I'm building a ncurses-based controller is to push on the features in needs to support. Where it's lacking: - Lots of missing features. Simple things like `logs` are on my shortlist. But then there is also the more complicated process of upgrading connections to support tailing logs. - Auth is basically the minimal work I needed to support our kubeconfig files. I have no idea how well it will work for others yet, though it sounds like a couple people have had luck with it as is. - It still needs a story around how it will version alongside k8s API. - It's real-world usage is pretty minimal Still, I'm happy to discuss PRs, issues, and even design changes.
Just published a simple crate for fun: [Stellar (Cryptocurrency) Vanity Wallet Generator](https://crates.io/crates/stellar_vanity). Also made my first rust open source contribution to [Stellar SDK](https://crates.io/crates/stellar_vanity). 
&gt; Rust implementation of the cryptocurrency Nano This is super interesting! I'm pretty active in the blockchain space in SF and seeing people implement clients in rust is awesome.
Wholeheartedly agree with this. It's bad practice in Python because name conflicts so easily creep in and remain undetected. Not so much in Rust (especially with Cargo locking dependencies)
I was pleasantly surprised by Rusts use of `enum` (which is a "Tagged Union", not a simple enumeration of values) and how Traits based programming makes my brain hurt and delightfully tingle at the same time. (It's not really the same as an "interface", but I can't really point out why) Above all, I like being bitchslapped relentlessly by the compiler, to the point of relative confidence that when it finally compiles - it most likely works. And not just 98% of the time. I suppose Rust is showing me my previously unknown Masochistic side.
(If you haven't gotten comfortable with at least one other language first, I'll always recommend doing that first. What makes Rust great also makes it kind of difficult to get started with.) Things that other languages have: - Static Typing - Means that you know what kind of data you have and what you can do with it (and the compiler helpfully points out when you do something illegal) - Powerful Generics - Allows abstraction over multiple concrete types with one code path - (Hygenic) Macros - Code generation based on patterns to reduce repetitive boilerplate, such as serialization or debug output formatting Things More Rust Specific: - Cargo - A wonderful works-by-default build system - A large amount of maturing high quality libraries available to easily add as dependencies - Ownership - The "poster child" - The cause of the famously picky compiler - Data is owned by one location, and can loan out the data to other places or give ownership away - If a mutable loan is out, no other loans can be given - If an immutable loan is out, only immutable access is available - This means that there are a lot more guarantees about your code's behavior - Easily safe concurrency - Clear resource ownership, meaning memory allocations _and other resources_ get freed after use - Resources cannot be used after they are freed Check out the Rust Book if you're interested; it covers what makes Rust unique in a manner directly tailored for readers with some experience with programmatic thinking, but not necessarily any experience with the world of "systems programming". (Which just basically means not GCd at this point (so long as you're willing to call forced but exclusively Reference Counting a minimal GC).)
First off, welcome! Rust is a very special language to me. I've never considered myself a programmer, likely because it's too easy to make mistakes. In languages like C you can get just about any code to work, but there are very likely edge cases or hidden gotchas you don't know about that can cause big problems. From crashing your program all the way to allowing anyone with a bit of knowledge to hack your computer. So despite how much I enjoyed working in C, I usually worked in Python. Python is an amazing language for a beginner in my opinion, but also has downsides. It promotes some bad practices that can quickly bite you in the butt if you're trying to make a bigger piece of software. It's very easy to get lost in 'it didn't work so I did a thing and it worked and now I depend on it working that way'. It's very easy to introduce subtle bugs. Rust does away with a great deal of that. If your code compiles, it's very likely it will work in the way you intended it to. It may not be the easiest to maintain and grow a codebase, but the compiler will stop you from making many kinds of subtle mistakes. All that said, go learn something else first. I am a Rust fanboy, but unless you have at least a year of programming Rust will likely be harder to understand. Personally, I'd start with something like python if you've never touched programming logic before. Once you have the basics though, explore a bit. Go build a gui calculator in C#, play with Java a bit (then back away quickly), maybe dabble in some functional programming. Then sit down and build something in C. Personally I think it's important to at least have used C in order to better understand how all languages work under the hood. After that, come back to Rust. Or just do it now. I'm not your dad.
I’ve been coding for about a year and from what I’m seeing so far in the comments I predict I’m going to be frustrated but will be able to manage. From what I’m gathering Rust is much less abstract than languages like Java (probably my strongest language). I’ve played with Rust a little and it seems like a much more tedious version of Python. Probably a gross generalization considering I’ve just hit the tip of the iceberg but I’m excited to go deeper 
The [API guidelines](https://rust-lang-nursery.github.io/api-guidelines/macros.html#input-syntax-is-evocative-of-the-output-c-evocative) do actually encourage designing the input syntax for that sort of greppability. 
Not to cool your thunder, but one decent suggestion is to learn a bit of C or C++ first if you haven't worked with them already. A lot of the additional work the rust compiler forces you to do is hard to understand why it's needed unless you've had to work in a language that doesn't have a garbage collector and your manually managing memory. C and C++ are currently the most popular languages still in widespread use which require this. If you've done a toy project or worked a little with either language enough to see the pain points I'd say go ahead on to rust. 
The people. Not being trite. Part of the reason all the technical reasons given in this thread are true is because of the community and culture built around Rust, and how intentional that has been. Improvements are made thoughtfully, with care for human and technical factors. One lovely example is that RFCs should have a "How do we teach this?" section. 😊
Not at a computer atm but can type up some code later. `into()` cannot fail; if you `impl Into` for some type, the `into()` has to either work or panic, since it can't return an error. This is good in theory until you get to stuff that would be nicer to handle with an error rather than a panic. An example I can think of might be turning `u64` into `u32` with no (transparent) loss of information, if the number is outside the bounds of `u32`. Currently there's a few ways to handle this (and I have no idea which is done by default): - panic, because it's an overflow - silently lop off the first 4 bytes to fit it to size - silently wrap and return only the overflow - return the max for a `u32` - don't even compile None of these are particularly favourable (to me). With `try_into()`, you could allow for the possibility that it might be out of bounds by returning an error if it would be. There's other examples that others could provide with custom structs, but it's just one that came to mind. The other pro is that currently people might (including me) have something that's effectively `try_into` already (like `into_mytype -&gt; Result&lt;MyType, Error&gt;` that can be unified into a standard library trait. Results in (IMO) cleaner and more navigable code. 
can you not use `kubectl config current-context` ? I feel that would make it more integrated into the k8s ecosystem seen as changing k8s context changes it for all sessions of the user.
Sounds like you'll appreciate rust then! Cheers! 
Yeah, someone actually already filed an [issue](https://github.com/databricks/click/issues/22) for doing this, and I'll implement it soon. I don't think I'll handle hot switching (i.e. if you change it while click is running it won't pick that up), but it'll pick `current-context` when starting up.
TL;DR: Speed of C, safety of Java, difficulty of Ada Rust is the first advance in programming language theory (PLT) since Java. C had raw speed, at the expense of disorganization. C++ introduced OOP, but kept manual memory management and thus use-after-free errors and buffer overflows. Java fixed these issues with the expense of a garbage collector. C# was just a (much) better Java. Rust is the next step: all the speed and memory efficiency of C, but with the safety of Java and the terseness of C#. It does this by statically checking memory allocations, which requires allocating memory in trees instead of graphs. If you really need to manage graph structures, then that is an important point to watch for.
Thank you, but it is a solved problem :-). I have a repo, we would have to rebase/graft the more recent history on top of it. https://github.com/pitdicker/rand_clean_history
I don't see the similarity to Java. In Java all none-primitive types are references objects defined by a closed class. In Rust you define a value type, which is extensible through impls where your reference types then wrap the value as need based on the use-case. Rust strongly favors static dispatch, has no reflection. Rust does away with Java's exceptions and nulls. I really can't think of a stronger deviation between two relatively prolific curly braces than Java and Rust.
Yes, I can see how learning C first will be helpful to make you understand how pointers, heap and stack works on a low level. However, I can't really recommend learning C++ first, it's just too big and complicated, and most of the things you'll learn will work differently in Rust (no inheritance, no templates, no const, move/copy works differently, borrow checker, traits, generics). You're better off just learning the Rust way of doing things instead of trying to wrap your head around the ugly beast called C++. That said, some things in Rust might be easier to understand if you already know C++ (like RAII, smart pointers etc.).
Published.
As is alluded to be /u/dbaup Java has a pure example of acquire/release not being enough. Before I think it was 1.4, possibly 1.3, double checked locking was a big no-no in java. Then the volatile keyword was promoted to have seqcst semantics, this allowed for much greater concurrency guarantees and double checked locking is now safe. I’m personally on the fence, and it entirely depends on your use case. The surrounding memory accesses need to be considered for anything less than seqcst. 
It really depends on how the person reads it. If they read it as a fancy way to say "Rust and Node.js", then it's plural. If thet read it as a fancy way to say "Rust with Node.js", then it's singular. "Rust plus Node.js" is definitely singular, but writing "Rust + Node.js" can sometimes be parsed as "Rust &amp; Node.js" depending on the reader's preconceptions and current mind state.
&gt; Rust prefers "correct later" over "maybe correct now". In my experience, when a project compiles in Rust, it's a good sign that the code will work as expected and I'm thinking that my tests should all pass. I don't really get that in other languages. If my C++ project compiles, I'm probably thinking that I just entered the first stage of debugging.
Thanks for the long comment, and your previous work on rand! This deserves a longer reply, and some of your points certainly deserve making some changes in rand. I don't have time at the moment, but will reply later.
I really like this explanation! Well done!
Thank you! Worth polishing the documentation a bit more.
Yep, and not just SAT solvers. Dependency graph resolution/version selection is its own problem, with various variants in different systems. Reducing to/from SAT is useful both for theoretical arguments (it is a good target for reductions since it SAT is so simple), and also in some cases for actually solving since many SAT solvers are very good. Russ Cox wrote a [nice overview](https://research.swtch.com/version-sat) in 2016 on version selection, with links to many different systems and short comments on what techniques and systems they use.
I've never been good at contributing to open source projects, and I'm not an experienced Rust developer (yet), so I would definitely have been a worse candidate for writing a better resolver :-) My guess is that good heuristics are good enough for most practical cases, and then it is more about implementing the heuristics in an efficient manner within the system, not in finding some groundbreaking new algorithm.
Graph isomorphism is actually not known to be NP-complete! It is known to be in NP, but apart from that we don't know yet. It may be in P (remember, all problems in P are in NP), it may be NP-complete, or it may lie between P and NP. Zero knowledge proofs are really fun, and can be defined for NP-complete problems. Two nice examples are [graph coloring](http://web.mit.edu/~ezyang/Public/graph/svg.html) and [average salary computation](https://everything2.com/title/Zero+knowledge+computation+of+the+average+salary). Finding adversarial examples and and/or showing that the subset of examples used in some protocol is not efficiently solvable are also quite fun problems.
While Rust is great and has a bunch of properties that make it "special", I'm not sure it's a great pick if you're new to programming. Rust has a steep learning curve and while it has excellent documentation, it is not as widely used out in the wild as many other languages, meaning that it would be harder to find help or answers for some problems or questions you might run in to.
&gt; Rust is the only language I've ever encountered which places a higher priority on correctness than convenience. You make it sound like it's the only language which takes a correctness-first approach. Perhaps for a language created in industry, sure, but it's hardly the first. The tone of this post (maybe all the italics?) is overly fan-boyish. It's great that you're excited about the language, but it's kind of annoying to see every other language being oversold. 
I think instead of “fairly new” I should’ve said “relatively new”. I’ve been coding for a year now and I’ve gotten a decent bit of experience with programming. I feel like I’ll be able to manage the debugging (can’t be worse than the shit I’ve had to do in MIPS asm, probably the worst language to find answers to problems for). Overall I predict the little nuances and the pickiness of the compiler is gonna bite me in the ass hard. But then again, I plan on using it for assignments in my OS course, not making any huge app. Just needed to shake things up 
You went out of your way to chop out my qualifying statement, and then complained about what I didn't say.
I'm most proficient in Java, but dabbled around with C++ for a year or so. I'd say you're good to go with Rust without diving into C++ first. You don't need that much pointer stuff in Rust, and you learn to do things the right way when you just go with Rust.
Why the down-vote? Okay, first I should say a big thank you to sacundim for the detailed feedback! &gt; One potential pitfall that recurs through this is that it seems to me like the documentation is sometimes unclear who the audience is for which passage, and thus often gives what's either too much or too little information Very true. This documentation was aimed mostly at those less familiar with cryptography, and I agree it is out of place and a poor half-way house. &gt; set_rounds on the ChaChaRng type are a bit scary Yes, this allows anyone with `&amp;mut` access to the algorithm to adjust the security (but so does any constructor: `foo(rng: &amp;mut ChaChaRng){ *rng = ChaChaRng::weak_constructor() }`). Pushing `set_rounds` into a constructor would be better, unfortunately `SeedableRng` doesn't allow it; possibly exposing this via a type parameter would be better? It's a trade-off; maybe we should just expose ChaCha20, ChaCha12 and ChaCha8. &gt; More generally, I just noticed that there's no "raw" method for creating a ChaChaRng from a key and nonce/counter—I think there ought to be one. Personally I agree, although it has also been argued that we're trying to implement a standards-compliant ChaCha encryption engine here. I don't think extra constructors would hurt however. &gt; or whether they're not and it's just the common OOP mistake of referring to any internal values as "state." Correct. We ended up removing stateful distributions in favour of a simpler `Distribution` type [after some discussion](https://www.reddit.com/r/rust/comments/7wmfo0/deprecate_randrand_in_favour_of_a_distribution/).
"rustc is like peer programming for introverts". Was a big step when I no longer got personally offended by all that red ink
Yes, learning C++ (mostly) means learning how to program in C++. C is where you learn the fundamentals without the annoying magic of C++ (and I was a _big_ C++ fanboy)
Fair enough. I'll be honest: Rust has been one of the hardest languages to pick up for me, and I've heard from others that they find the learning curve pretty steep as well. It's a complicated language, and it has a bunch of concepts or language mechanics that are not straightforward to most people because they are not part of any existing mainstream language. That said, now that I mostly understand how Rust works, it's mostly a pleasure to work in. I came to Rust because I wanted a language which checked as much as possible at compile time, and on that part it delivers in spades. On top of that, I really enjoy the trait system, the excellent compiler error messages and a growing ecosystem of libraries. People in the #rust and #rust-beginners IRC channels can help you out when something has got you stumped. There are still times when I get frustrated at the compiler not agreeing with my work, but they are getting less frequent as time passes on. ^(PS: MIPS is the most beautiful of all the assemblies I have seen.)
There's very little we see in the mainstream today that wasn't exhaustively worked out twenty or thirty years ago. The borrow checker is fairly novel, though.
If MIPS is beautiful I’m terrified to see other assembly languages. My system programming languages course has been a nightmare. But thanks for the input! I’m excited to get my hands dirty and challenge myself 
As someone who is fairly new to programming too and learned Rust as his second language, I would say go for it. The Rust Book(Second Edition) is awesome. But another mistake I used to do and now I am trying to correct myself, don't say you know a language if you just know the syntax of it, work with it in a few non-trivial projects. Learning the syntax is the easiest part, effectively using it really takes some time. So my advice would be after completing the rust book, work on something that you find interesting to actually understand what the language has to offer. 
Somewhat offtopic, but does someone know how images like [these](https://brandur.org/assets/rust-web/concurrency-model.svg) have been generated? Looks like it might have been rendered from some ascii template. I like the clean and oldschool look of it. 
Well, I know for sure I’ll be using it for an assignment on process synchronization for my OS class lol
You could parse the + as "and", but then it would read as if rust is awesome and js is awesome, without them being combined. Pretty sure that isn't what the OP meant.
Quick google search. Yeah. This’ll help a lot. Also I saw something about std::semaphore in Rust. If that’s seriously a thing this project will be a breeze lol 
Backtracking search and "value ordering" are compatible with the exploration order being DFS. Some context (at least, these are the definitions I'm used to): * A backtracking search is a search procedure that searches in (explores/discovers/constructs) an implicit search tree, and upon failure decides to return to a previous node in the search tree, and continue from there. * "Value ordering" is simply using a heuristic to order the next nodes in the search tree based on the "best" value to try next. Heuristics can also be used to choose the next variable to make a choice for ("variable ordering"), or some other combination of choices. The assumption is typically that child-nodes to the left are better according to the heuristic than child-nodes to the right. * Given a heuristic, the search tree is implicitly defined (it is induced, to use a fancy-sounding term from mathematics). The exploration order in the search tree is defined by an algorithm such as DFS (depth first search), BFS (breadth first search, high memory cost), LDS (limited discrepancy search, finding final nodes in the order of least number of right steps), "Best-first" search (essentially A*, high memory cost like BFS), Random order, and any combination of the previous with parallelization, along with lots of other interesting variants. * Search can be done to find the first solution, all solutions, the best solution, or be limited in some other way (at most 10 seconds, at most 1 million nodes, …). Best solution search is typically done by finding a solution, and then adding a new requirement that the next solution found is better than any previous solution. * Sometimes search algorithms use heuristics or exploration order that is based on learning or information that is discovered during search. SAT solvers in particular uses a variable and variable ordering based on previous search activity ([VSIDS](https://en.wikipedia.org/wiki/Boolean_satisfiability_algorithm_heuristics#Branching_heuristics_in_conflict-driven_algorithms_[2] for example) and which is very efficent combined with cutting of large parts of the search space using [clause learning.](https://en.wikipedia.org/wiki/Conflict-Driven_Clause_Learning#CDCL_\(conflict-driven_clause_learning\)) * With randomized and learning heuristics, restarts for the search can be very efficient. From the code in cargo I thought I saw a DFS exploration order, but I may of course be mistaken.
I don't think Rust has semaphore, but most probably you can use CondVar and Mutex to get what you want. Also, I think, Rust, like Go, stresses synchronizing state via communication between processes rather than sharing state. But, as I said I am fairly new to programming and most of my knowledge is self-taught, so maybe someone more experienced and knowledgeable can help you with this and correct where I am wrong.
[Found this](https://doc.rust-lang.org/1.1.0/std/sync/struct.Semaphore.html)
I wasn't trying to imply that Rust is *all* roadblocks, merely that it has a lot of them relative to *contemporary* languages. In that context, error handling absolutely *is* a roadblock, because with exceptions, you just throw them and job's a good-un. That together with your parenthetical comment about exceptions is basically the point I was trying to make: Rust has more roadblocks, but they're roadblocks for a good reason that you're choosing to put in your way to help yourself get things right. And I've argued in the past that Rust is riding a very carefully drawn line between too much magic and not enough magic, but I have to stop typing at *some point*...
Ah, it's an unstable feature. I had no idea the nightly had a Semaphore.
Oh sorry. Essentially, one the core guarantees of Rust today is the stable features that std already has will continue to work as they do for Rust's entire lifetime. So, actually, the unstable features are those that are still going through changes and aren't guaranteed to not have any breaking changes to their API (at least that's my understanding). And nightly is the version of the rust compiler that gives you access to these unstable features.
Oh, it's certainly *wrong* to parse "+" as "and", but two of the things I focus on are that readers/listeners/viewers/users are fallible we generally don't realize how much we expect who/what we interact with to silently make up for our errors. (Half of Human-Computer Interaction is about addressing that sort of thing.) In fact, I was tired enough that I experienced a complex mix of such failures and I didn't notice until I saw the comments. I read it as "Rust and Node.js are awesome", interpreted the intent as "Rust and Node.js are awesome when used together", and didn't realize I'd weaselled my way out of recognizing a "[singluar] are awesome" error until I went back to look at it again.
Many things: - It is super fast like C (due to being native language and having lot of zero cost abstractions) - It is very hard to shoot yourself in foot (if you do not use unsafe) - It is productive as many modern languages (like Scala) - Code is readable a easy to reason about (compared to things like Scala implicits and 4873 ways of inheritance, initialization order, ...) - Cargo is awesome (compared to shit like SBT) - Progress between versions is brutal and yet it does not add bad stuff
Show him rustup and cargo. Compiling and using rust is a bridge with cargo, and rustup makes it a bridge to install rust on most machines.
&gt; This [using an open (0,1) range by default] breaks with every other programming language I know. It does. It's one of the things I was less sure about. [See here](https://github.com/dhardy/rand/issues/85#issuecomment-367445299). &gt; Could you say some more about why these [Rng and RngCore] are separate? Ultimately [it's about crate separation](https://github.com/rust-lang-nursery/rand/issues/264); the other reason is to allow use of `Rng` methods on dynamic trait objects (without the double-referencing work-around). &gt; ... it's not obvious that it'll be hitting the OS/hogging CPU time. Maybe from_entropy() or something. With respect, *any* PRNG initialisation should use significant CPU time (relative to the size); even the old `new_unseeded` methods did. `from_entropy` isn't a bad name; ultimately we just wanted to make correctly seeding PRNGs as simple as possible. &gt; Also, what's the value in this being a trait? When would someone bound a generic by NewRng? It's a *hack* to get an extra method on `SeedableRng` impls from a different crate. &gt; [BlockRng] All the fields are public? Yes; this is a helper for implementing PRNGs so we didn't see it as a big issue; I guess we could abstract over the needed operations however. &gt; I find that this pattern doesn't express the intent at all, and "generate a sequence of random numbers" has to be reverse-engineered. :( For what it's worth, we considered [adding an intuitive iterator interface](https://github.com/rust-lang-nursery/rand/pull/275). &gt; [Uniform] This trait seems to not have an expressible rule about what values it generates Did the old `Rand`? I would be happy enough to lose the `Option` impl myself; maybe we should. &gt; it'd probably make more sense to rename Range to Uniform and call what's currently Uniform something else. This might make sense (overhead for 0..MAX fixed ranges can probably be optimised out). I think this can wait until a future release though; we've worked hard to get 0.5 ready! &gt; Also, something cute: Rngs can implement Uniform. Too cute. The decision not to generate PRNGs via `Rand` was very deliberate. The PR was #233 but discussion goes way back; can't find it. &gt; This has the bonus of making the Range type itself nicer: Range&lt;i32&gt; instead of Range&lt;RangeInt&lt;i32&gt;&gt;. Good idea. We've also been considering [leveraging the extra parametrisation](https://github.com/rust-lang-nursery/rand/pull/320#issuecomment-376235714) however; still no decision on that. &gt; Also, why's that associated type called "T"? Because a single-letter type name screams *this is a template parameter* which a long name doesn't? &gt; Lastly, having Range&lt;char&gt; would be neat. Yes it would! Although often char-sampling involves multiple small ranges, so a different approach might work better (reverse regex-patterns?). &gt; I thought that rng.sample(0..10) would be neat It's possible but reduces expressiveness; e.g. we could support this but it would be less obvious that creating a dedicated `Range` would be faster for multiple samples. `sample_iter` would probably need specialisation to work optimally for all types. Ambitious. &gt; This implementation is biased: gen_bool(0.0) has a non-zero chance of returning true because of the &lt;=. https://github.com/rust-lang-nursery/rand/pull/347 &gt; Since both Poisson and Binomial use this, it seems worth pulling out into a separate Cauchy distribution ... Wish I could ask you to impl that! &gt; On that note, how much testing of distributions has been done? Very little; it's an area we need help with. Also see: https://github.com/rust-lang-nursery/rand/issues/290 &gt; To finish on a positive note Thank you also for all the prior work! It would have been good to get more feedback on the work we've been doing but I already guessed there are reasons that's difficult for you.
I’ll see if he wants me to show him, granted I think I’m the first and last student to randomly ask his permission to teach myself/use a non-mainstream language for a class. Everyone else just seems to go through the motions. I don’t see him getting much use out of downloading everything. Especially considering he’s a hardware guy
Yeah, I think this sense of correct "*later*" is a unique part of Rust design, or I can just say Rust found its sweet spot. Say, when it comes to correctness, there are many other extreme(?) options, like Haskell. Haskell is obviously way stricter than Rust, but its type system wants "correct right now", so satisfying the compiler often is an overburden. But, the memory-safe(?) type system of Rust is much less frequently triggered, giving more breathing room to users, while providing the promised memory safety. In very unprofessional rough terms, compared to Haskell, Rust sacrificed(?) correctness to protect the flexibility of imperative language, but is 100% memory safe.
Thanks for clarification ! 
Oh hey, a brson.
There's a difference though: Into/From are conversion traits, while `as` is a simple cast.
There are big semantic differences which make star-imports a bigger issue in Python than in Rust: 1. In Rust, nothing is exported by default, , `*` will only get what was explicitly exported. In Python, everything is exported by default and unless the module has a `__all__`, star-imports will import literally everything module-global. 2. Critically, that includes the imported module's own imports (which could be aliased to something very inconvenient e.g. `from collections import OrderedDict as dict`) or various utility declarations e.g. the module you're star-importing has defined a `list = [1, 2, 3]` for some weird reason? You've broken `list` in your own module's namespace. This could theoretically be an issue in Rust but is less likely to be, because the source module would need to specifically re-export these. 3. IME Rust modules seem to have tighter APIs and sub-modules are especially tight, in Python it's pretty common to provide access to everything from the root module directly but in Rust a sub-module would export solely the useful stuff pertaining to it. 4. In fact large Rust libraries will often provide prelude-type modules whose exports lists are *specifically crafted for that use*, I don't remember ever seeing that in Python. 5. And the odd [2] is less troublesome in Rust as it's statically typed and the odd name collision would generally lead to non-matching types down the line, in Python that's a runtime concern which may go un-noticed for some time. 
&gt; It does. It's one of the things I was less sure about. See here. Thanks for the reference, but my point was the reasoning for the decision should probably be in the docs somewhere, since others will have the same "weird?" reaction. &gt; Ultimately it's about crate separation; the other reason is to allow use of Rng methods on dynamic trait objects (without the double-referencing work-around). I see. Why couldn't the crates be separated but have all of `Rng`s methods on `RngCore`? People who only want to use `rand-core` don't need to be forced to reimplement those convenience methods. In any case, even if that wasn't the case, it seems like a possible better naming would be `Rng` and `RngExt`, reflecting the extension-trait-ness of the latter. &gt; With respect, any PRNG initialisation should use significant CPU time (relative to the size); even the old new_unseeded methods did. from_entropy isn't a bad name; ultimately we just wanted to make correctly seeding PRNGs as simple as possible. I don't think that's true, e.g. ChaCha just copies the seed into its internal buffer. The argument about making it easy/obvious to get a correctly*-for-crypto* seeded RNG is fair, but there's always a bit of tension between optimizing for the "true" randomness of cryptography and the reproducible/fast randomness of simulations... but I'm sure you've encountered this distinction heavily. (That said, even crypto applications can want reproducible RNGs: that's the background for ChaCha, as a stream cypher.) &gt; It's a hack to get an extra method on SeedableRng impls from a different crate. Ah, I see. Maybe that should be explained in the docs? Also, a name related to `SeedableRng` (like `SeedableRngExt`) would be a possible better way to express the relationship. In fact, controversially, it almost seems pointless to have a whole trait just for the `::new` method: the trait has to be imported anyway, so a free standing function would work alright too (`rand::new_rng::&lt;MyRng&gt;()`). This consequence of Rust's name-lookup rules + conventions is a bit unfortunate, in my mind. :( &gt; Did the old Rand? I would be happy enough to lose the Option impl myself; maybe we should. Not really, no, but it also didn't have a name that's a specific piece of statistical jargon referring to a particular distribution. I don't think losing `Option` is enough to fix it, quite: because `f32` and `f64` still aren't uniform (a whole pile of values have probability 0). &gt; Good idea. We've also been considering leveraging the extra parametrisation however; still no decision on that. Is it worth having the most common cases be `Range&lt;RangeInt&lt;i32&gt;&gt;`, etc. instead of having the rare `Range&lt;HighPrecision&lt;f32&gt;&gt;` have some extra `.0`s at the use-sites? (There's an argument for `Distribution` to have adaptors like `map` and even `filter` and so on, similar to `Iterator`, to ensure one can still use a `Range&lt;HighPrecision&lt;f32&gt;&gt;` as a `Distribution&lt;f32&gt;` via `Range::new(...).map(|x| x.0)`.) &gt; Because a single-letter type name screams this is a template parameter which a long name doesn't? But... it's not a template parameter, it's an associated type? Sure, it's mostly used passed to a type parameter, but I'm not thinking about that when I'm looking at the trait's docs, and maybe not even when implementing it. &gt; sample_iter would probably need specialisation to work optimally for all types I don't think so: having the ability to convert from `0..10` to `Range::new(0, 10)` (e.g. via a trait `IntoDistribution`, that's used as the generic bound instead of `Distribution`) would mean `sample` and `sample_iter` do the conversion and then behave as they currently (hypothetically, for the latter) do... but it's a lot of infrastructure for just making the syntax slightly nicer: making `rng.sample_iter(1..=6).take(10).sum()` a neat way to roll 10 dice. &gt; Wish I could ask you to impl that! Me too. &gt; Also see: https://github.com/rust-lang-nursery/rand/issues/290 Ah, cool. &gt; Thank you also for all the prior work! It would have been good to get more feedback on the work we've been doing but I already guessed there are reasons that's difficult for you. You've done much more work that I ever did!
So what's the point of using nodejs at all, like a wrapper to boot up a http server? If so why didn't you write a micro-service that would do only the job you needed with no extra layers.
&gt; why it is not considered as bad practice It is. Just not as strongly.
async/await is far from an academic thing : it was first introduced in the .Net environment (is there something more corporate than .Net ?) and have recently been introduced in JavaScript (which is probably the less academic language ever). It's marvelous when you have to deal with asynchronous stuff, it makes everything much more intuitive : the code is easier to write and way easier to read. The fact that it got massively adopted by the JavaScript crowd shows that this isn't at all an « academically-minded» thing.
&gt; It's not really the same as an "interface", but I can't really point out why Because you can decide to implement new traits for any type you would want. This makes objects extensible without owning their implementation, meaning that you don't have to encapsulate classes into new ones just to make them compatible with your own APIs.
&gt; Why the down-vote? I believe it is because wall of text has a negative connotation, so it seemed like you were dismissing their criticism entirely.
I don't have experience with iOS-style layouts and I'm used to older systems, but a constraint solver seems a bit heavy-handed for layout. Am I missing something?
If I understand the release notes correctly, OsRng's byte filling function is considered fallible (why is this..). In the event of a byte-fill failure, would a reasonable countermeasure be to simply retry a byte-fill?
&gt; I see. Why couldn't the crates be separated but have all of Rngs methods on RngCore? People who only want to use rand-core don't need to be forced to reimplement those convenience methods. What convenience methods? `gen_bool` is the only one not requiring any extra code from the main `rand` crate; `fill` and `try_fill` could easily be moved over but the main reason they were added is so that users do not have to import `RngCore` as well as `Rng`. &gt; Rng and RngExt That was originally the idea; the primary reason for the current names is so that existing code needs less tweaking — many users will not need to use `RngCore` directly at all. &gt; reproducible/fast randomness of simulations Reproducible obviously requires a different approach but `NewRng` is otherwise a good option for simulations/games *unless* many separate generators are needed. That said, the original point of `NewRng` was to provide a place to house fall-back logic in case `OsRng` fails, but we now have `EntropyRng` for that. &gt; I don't think losing Option is enough to fix it, quite: because f32 and f64 still aren't uniform (a whole pile of values have probability 0). The way I see it FP is an approximation over the Real numbers; hence almost anything using them should be assumed to be an approximation IMO. I'm not sure which values you're referring to; obviously we have to clamp the range, and regarding the values close to 0 we have a [higher precision variant](https://github.com/rust-lang-nursery/rand/pull/320) which does allow sampling them all I think (with the exception of 1.0). &gt; I don't think so ... In case you missed it, [we have two implementations of ranged sampling](https://docs.rs/rand/0.5.0-pre.0/rand/distributions/range/struct.Range.html#method.sample_single); ideally `sample` should use the single-use variant and `sample_iter` the multiple use one. This at least needs different coercion traits. Actually we've already had suggestions to add `sample_iter` which at least allows `rng.sample_iter(Range::new(1, 7)).take(10).sum()`.
Since you're new to programming, you have different immediate challenges and goals than someone who is looking for a new tool-set for a well-used tool box. You probably should work with a language that has a robust ecosystem and community who can help you with the basics. There are far more resources to learn other languages, and learn how to use them well, than there are for Rust just yet. I'd recommend you learn Python but that advises is strongly biased.
"This library, bui-backend, enables an application to serve a Browser User Interface (BUI). The browser becomes your GUI." This feels like I'm reading Computerworld from 1991.
This has been a super productive week. It’s crazy how fast things are moving. 
I am actually using error_chain in this project and I love it. The issue is just with boxed errors, which it doesn't handle well. There's an open PR on the project to add the functionality, though, so hopefully it won't be a pain for long. 
Not meant as tongue-in-cheek, though I understand the reading. Given the target audience, and the experiences I've had introducing Rust to, say, electrical engineers, it's an entirely earnest sentiment :)
&gt; The pedant in me doesn’t like that embedded system also means embedded Linux computer. The author of the post agrees ;) Unfortunately the term "embedded" has become diluted, and I'm not sure there's a really good replacement. I often just wind up saying "microcontroller" to differentiate.
Wonderful writeup! I'm incredibly grateful to Diggory, Paul, and the broader community for taking this on, and can't wait to see 0.5!
Yes, the borrow checker is a novelty at least in a mainstream programming language (the Swift team is considering adding a similar feature). Although it comes with a fairly steep learning curve for beginners and sometimes add unnecessary burden on the programmer it doesn't seem to negatively impact the popularity of the language much. The other features of Rust, like traits (type classes), pattern matching, enums (ADT's), structs (records), associated types (type members), are old and proven, and available as more competent versions in languages like Haskell, Idris and Scala. Hopefully Rust will continue to "steal" more of the good parts of these languages. 
Well, a constraint solver is the only really "scalable" and efficient system. I do not want to roll my own constraint system - this would be a buggy mess. I'd rather use a tried-and-tested library / algorithm. cassowary isn't "heavy-handed" - it can solve thousands of constraints in less than a millisecond (if you cache it correctly). Yes, it's a difficult to understand library, but that's because layout is difficult. And you, as a user, would never interact with cassowary directly, you'd just write CSS (regular CSS, like on the web). It won't have an Auto-Layout API, that's hidden behind the CSS / DOM model. If you mean by "older systems" an API like `button.position(50, 50); button.add_to(main_window);` - no, I'm not doing that, I still have nightmares from those days. Updating views, reusing styles and resizable layouts are an absolute pain in frameworks like these. In most of these frameworks, the layout is more or less forced on you, the library user, instead of being solved by the framework. Plus the code cannot be hot-reloaded while CSS can be. Which, given the current rustc compile time, can be horrible. So yeah, that's why I use cassowary. It's a well-known algorithm, tried and tested for UIs, it works, it's efficient and it already has a library implementation in Rust. I wouldn't know of any better way to do it. 
&gt; What convenience methods? gen_bool is the only one not requiring any extra code from the main rand crate; fill and try_fill could easily be moved over but the main reason they were added is so that users do not have to import RngCore as well as Rng. The things just using `Distribution` only need the trait definition, the implementations can stay in `rand`. But yes, I hadn't understood the design properly. I wonder if the double-import problem could be solved by redefining the methods from `RngCore` on `Rng` with default implementations in terms of the parent ones. In any case, now that I understand the relationship, it makes a bit more sense. &gt; Reproducible obviously requires a different approach but NewRng is otherwise a good option for simulations/games unless many separate generators are needed. I disagree about the implication that simulation and games usually don't need reproducibility. For instance, reproducibility is *critical* for scientific simulation (the goal is/should be for someone else to download the code and run it and get the same results). IIRC, there were even complaints that `thread_rng` couldn't be seeded, because there was concern that someone could inadvertently get non-deterministic behaviour by using it accidentally. Even for games there's numerous places where having deterministic behaviour is good (e.g. a map generator seed), plus plain old debuggability. &gt; That said, the original point of NewRng was to provide a place to house fall-back logic in case OsRng fails, but we now have EntropyRng for that. However, I think it's important to have a easy way to create a good-randomly-seeded RNG, but I find the set-up a little clunky, with "new" everywhere and extra imports and so on (it is, to some degree, a failing of Rust's name resolution + conventions, as I said before, so it's hard to see what to do here other than adding inherent `new`s to each `Rng`). It does seem like something needs to happen here as having the approach be using `EntropyRng` directly with `from_rng` seems... prone to mistakes: `MyRng::from_rng(JitterRng::new())`, `MyRng::from_rng(thread_rng())`, `MyRng::from_rng(some_other_rng_lying_around)`. But that's partly pointing to a deeper problem I think: having this huge proliferation of RNG types directly at the top level of `rand` seems like it'd make it harder for someone to choose the right thing, especially without good ways of distinguishing the hierarchy other than the big paragraph of text someone (you?) has helpfully written out. Someone looking at `rand` for the first time isn't going to be able to internalize the guidelines and may just end up overwhelmed. (For a specific exampe, is it worth keeping `Isaac*Rng` around? If it's only historical reasons, it's a relatively rare algorithm that isn't *great* along any particularly dimension (speed, security, size, etc.), and so could easily be relegated to an external crate.) &gt; The way I see it FP is an approximation over the Real numbers; hence almost anything using them should be assumed to be an approximation IMO. I'm not sure which values you're referring to; obviously we have to clamp the range, and regarding the values close to 0 we have a higher precision variant which does allow sampling them all I think (with the exception of 1.0). This isn't a floating-point approximation problem: it's a terminology one. The values with probability zero are all the values outside (0, 1), i.e. the fact that the range is clamped. As you know, that means this distribution is U(0, 1), but that's *a* uniform distribution of `f32`/`f64`, not *the* uniform distribution. (This concern applies a little to integers too. At least, when thinking of them as an approximation to Z, the unbounded integers, which is, to be fair, much less sensible than thinking so for floats.) Basically, I find it weird to have `Normal` and `Exp` and all of those be the true statistical distributions (parameterized appropriately and everything), but then have the Uniform distribution be called `Range` and the thing with the name `Uniform` be a vague approximation/special-case of it. &gt; In case you missed it, we have two implementations of ranged sampling; ideally sample should use the single-use variant and sample_iter the multiple use one. This at least needs different coercion traits. I don't think so: maybe a `sample_single` method on the coercion trait would cover it, that could even be default-implemented in terms of the coercion. However, this is all hypothetical. &gt; Actually we've already had suggestions to add sample_iter which at least allows rng.sample_iter(Range::new(1, 7)).take(10).sum(). Indeed, I saw those suggestions. Hm, I wonder if one way to bridge the gap here would be to have a constructor of `Range`/`Uniform` that takes `..`/`..=` (e.g. `Uniform::new(1..=6)` in this case), with more explicit `Uniform::new_exclusive(0, 10)` and `Uniform::new_inclusive(0, 10)` if desired.
The emscripten target, while it has its uses, is much harder to get going with than the "unknown" target. Give https://www.hellorust.com/setup/wasm-target/ a try instead, IMO.
&gt; you'd just write CSS (regular CSS, like on the web) I'm even more confused now. The way I see it, there's a hierarchy of sorts when it comes to the expressiveness of defining layouts, e.g. fixed coordinates &lt; Swing `GridBagLayout` / WPF `Grid` / Windows Forms `DockStyle` and their friends &lt; CSS &lt; Cassowary. I assume `servo` and Gecko don't need a constraint solver for the layout, and can do with a simpler algorithm. Since you're restricting `azul` to CSS, Cassowary seems to bring a lot of generality that's not needed otherwise.
Those docs are for Rust 1.1; semaphore has been long gone.
These docs are for Rust 1.1, and has since been removed. That was only possible given that it was unstable in the first place. That said: https://crates.io/search?q=semaphore
There are several ways to categorize programming languages, but one of the most widely used ones is [static vs dynamic typing](https://www.sitepoint.com/typing-versus-dynamic-typing/). As a general rule, statically typed languages require more ceremony in declaring the types and annotating the types of things, and requires some weird constructs to do things that are natural in dynamically typed languages. In return, statically typed languages can detect many problems at compilation and allow the compiler various optimizations that make them considerably faster than dynamically typed languages. (nowadays there are static checkers for some dynamically typed languages, and modern statically typed languages add some sugar to reduce the verbosity of static typing, but these are still the general characteristics of static and dynamic typing) Rust's most distinctive feature is the concept of ownership. It annotates not just the types of things, but their lifetime and ownership too. This makes Rust more statically typed than any other statically typed language - enough that, I daresay, one could think of it as a third category of typing. Rust's ownership system requires more even ceremony and makes you do workaround for things that would have been trivial in regular statically typed languages, but in return it detects even more potential problems at compile time and allows farther optimizations.
The Rust performance and low overhead guarantees are basically requirements for things like embedded and system level programming. I hope soon I will never again have to write one more line of C++ code :) However Scala is improving in these areas as well. There is work on whole program optimization, automatic specialization and native compilation so potentially it could reach similar speeds as Rust and C++. And the JVM is getting value types, so GC issues might be alleviated in a not so distant future. If latency is important there are new GC alternatives on the JVM (Shenandoah and ZGC).
I guess what I tried to convey is that both are great and together are awesome! But yeah, no matter what is written humans interpret throw their own glasses
Looks a bit like [Monodraw](https://monodraw.helftone.com/) to me.
The compile straight-up tells you what the problem is: error[E0277]: the trait bound `std::ops::Fn(): std::marker::Sync` is not satisfied in `[closure@src/main.rs:12:14: 12:28 callback:&amp;&amp;std::ops::Fn()]` --&gt; src/main.rs:12:10 | 12 | .map(|_| callback()) | ^^^ `std::ops::Fn()` cannot be shared between threads safely You gave it a callable, but didn't do anything to ensure the callable was thread-safe. So you need to do that: fn compile_error(callback: &amp;(Fn() + Sync)) { // no more compile error (0..10) .into_par_iter() .map(|_| callback()) .collect::&lt;Vec&lt;_&gt;&gt;(); } This isn't a problem for the other function because the type of `hello` isn't being hidden behind a `Fn` trait object.
I agree C is probably the easier language to learn. C++ is a bitch to learn. Editing to reflect that. 
If you would ask for a two word answer to the question of "Why Rust?" the answer will probably be "ownership model". A lot of Rust's strengths can be traced back to the ownership model. It's the second use of [poster child](https://en.wikipedia.org/wiki/Poster_child), the embodiment or Rust if you will.
I don't know what makes you think that, but that's pretty much the opposite of the consensus.
Aah OK I get it now. I was reading this on my phone ("Slide" app), where there's no indentation between for all bullets. I've just fired firefox and it's all clear now. Sorry for the noise.
ah thank you so much!
No, this isn't based on servo, this is based on webrender. I still have to do the layout in some way. servo is way too bloated to be usable for the desktop. Servo takes up 70MB disk space (stripped) and 300MB RAM, while a webrender / azul app takes 10MB disk space and 30MB RAM. &gt; I assume servo and Gecko don't need a constraint solver for the layout Yes, but they have a huge, highly customized layout engine in the back. I don't have that. I don't have the manpower to create a full browser layout engine - that's an engineering feat achieved by tens and hundreds of engineers. *Browser layout engines are nowhere near "simple".* And you can't rip servos layout engine out of Firefox and put it somewhere else (I tried). So I had to look for a solution that doesn't have an awful API and has flexibility that comes close to a browser layout engine. Expressiveness of cassowary constraints is a difficult topic. [This](https://github.com/maps4print/azul/blob/bd9b03fc0a0e681d53ff767eeba730a7f1a9d673/src/constraints.rs#L70-L110) is how "expressive" cassowary can be. As you can see, there is little "generality" involved - cassowary was specifically made for UI constraint solving, not general constraint solving. What cassowary is very good at is updating an existing constraint model - it doesn't need to redo the whole layout just to update one variable. But in order to do that, it need a model of dependencies. Which is very weird to work with - [limn](https://github.com/christolliday/limn) does that and it's awful. I know it because I tried to use limn previously - ex. [this](https://github.com/christolliday/limn/issues/22#issuecomment-348290043) is how you specify paddings (versus just `padding: 10px 20px 5px 4px;` in CSS). Which is why I started azul, in order to "fix" what limn did wrong in Cassowary also doesn't specify how you do text layout, fonts, colors, images, shadows, etc. So if I had exposed cassowary directly to the library user, I'd have to now confuse people with two APIs, one for layout, one for styling, mixed in some way. It's simpler to just have everything in one language. And since webrenders internals map closely to CSS, that was my next best pick. I mean I could've re-invented QML or a similar, non-standard syntax, like the [stylish](https://github.com/Thinkofname/stylish) system. But people are more familiar with CSS than with cassowary-internal layout constraints, which is also a huge factor. I don't have to explain to people what the CSS syntax is, they already know it. I would have to do this if I would use cassowary - people would need to learn new syntax and new mental models for very little gain. I would say that CSS &lt; Cassowary. They can't really have any comparison, because CSS is just a language, not a layout system. And CSS layout engines are crazy complex, I don't have the resources to create my own and existing ones are not modular. I'm sorry for this wall of text, but I hope that clears things up on why I chose cassowary and CSS.
"ownership"
Async/await started in haskell (shocking) then went to f# then c#. Javascript was last. Look at the disaster tokio is to see how bad that model gets. I've been writing very low latency high performance network code since college, so about 20 years now myself in finance and trading. I even started with futures and promises in lisp dialects. The only thing async/await/futures has going for it is composability. I can write higher performance code with select /poll that is a lot simple. Rust isn't going to be a C or C++ replacement. It is going to be a haskell replacement. This thing about needing to copy every Haskell feature is pushing me away from the language. Haskell and ML are not productive languages for high performance systems.
Got it. So it's not that you _need_ or _want_ to use Cassowary, but it's a pragmatic solution to your problem and doesn't have too many downsides. And if someone extracts the layout engine from `servo` to a separate crate, you might be still able to switch to that. &gt; I'm sorry for this wall of text, but I hope that clears things up on why I chose cassowary and CSS. On the contrary, thank you for the write-up!
How to use `self` in futures? Here is a small example I'd like to compile: https://play.rust-lang.org/?gist=67f68bb37a376ce1f5408258e9df1e38&amp;version=nightly gist: https://gist.github.com/67f68bb37a376ce1f5408258e9df1e38
Uh that's cool. And a nice fit with [kairos](https://github.com/matthiasbeyer/kairos), actually!
The other big difference is that it's invalid to call a generator after it's returned Return, and doing so will cause it to panic. Is general, the traits are similar, but provide a very different set of guarantees on valid usage.
I'd do something like this: https://play.rust-lang.org/?gist=df05fe8aa8a2473fd4a879d09d4c7d23&amp;version=stable
I'm convinced that as much crap as Rust gets for being unproductive, it's actually exactly the opposite in the long run. As people become more familiar with the language and start recognizing common patterns, I believe we become more productive when continuing to extend and work on the same codebase. We're hitting a point (I would include myself in this) where a lot of people came into the language at 1.0 and have now been working with it for 3 years. This means there's a large swath of people who can start being considered experienced devs in Rust, besides the original Rustaceans who brought us this beautiful language. Rust is being taken ever more seriously broadly, and more people will be attempting to learn it and bring it into new spaces. I expect we'll start seeing even more acceleration due to this and productive weeks won't be unusual. (I know this probably wasn't exactly the intent of your post, also I'm an optimist ;)
The issue is that the default parameters are not hidden. If you didn't cared about them while writing the code, then you probably don't care about them when compiling. Probably a flag should enable explicit showing them to retain current behavior. 
I believe it's common practice (at least as far as I've seen) in Rust to import structs and traits directly, but to use functions scoped by their module: use my::module::MyStruct; use my::module; module::do_thing(MyStruct {}); Given that, I often glob-import a module if I know that it only contains types and not functions. I also tend to write modules that only contain data types to allow me to do this. As for why this is more broadly accepted in Rust, I would suggest it's because Rust code tends to be better documented and more searchable, so it is less hard to find which module something comes from. All (almost) crates pushed to crates.io have a docs page on docs.rs with at least the module structure and declarations of all functions and types, and you can easily search for them. Plus, if you aren't sure which module declares a function/struct, you can always grep for `fn &lt;thing&gt;` or `struct &lt;thing&gt;`, which may not be the case in other languages.
Number one reason is the borrow checker. It enforces correctness over who owns data at any given point of time. It's what allows it to be memory safe, without a garbage collector. More so than that. It catches a lot of other ownership issues which are not related to memory management. Day to day I work in TypeScript, and I've noticed over the last 2 weeks 3 occasions where an issue in my code base would have been caught by the borrow checker. 2 were straight up bugs. There is a lot of other stuff people will talk about. Cargo, the type system, it's enums, match, etc. These are features of Rust for sure, but they aren't unique. Lots of mainstream languages have something similar. Many worse. Still there though. The borrow checker is the big thing for me that makes Rust interesting compared to other mainstream languages.
No do you have to "Manage memory like in C"....not in any meaningful sense of "like".
Also it's a little common to request feedback be on github, but when the thread was originally posted on reddit, and that's where the discussion happens, it is best to address most of the concerns and then request them to post to github. Otherwise it seems like, as you said, dismissing the criticism
Cross link [users](https://users.rust-lang.org/t/cargo-got-some-new-tricks-but-is-it-still-correct/16485) and [internals](https://internals.rust-lang.org/t/cargo-got-some-new-tricks-but-is-it-still-correct/7167)
&gt; And we're working on verification tools that could recover some of the correctness properties, like static bounds checking. And that is doubly interesting. I think that a combination of attributes `#[spark(range(i, 1, 10))]` and plugins (coupled with separate annotations support for 3rd-party libraries) could really improve static checking as SPARK does for Ada.
Does that make CLion the primary choice for a Rust IDE, then?
What's PGO exactly?
Well there ya go. :-) I should buy you lunch sometime soon and we should catch up.
Are you pretty much decided on using a PCG as the weak RNG? If not I should probably make a case for it. It's about [2 bits worse than true randomness](https://www.reddit.com/r/programming/comments/7amkpv/16384dimensional_party_trick_a_random_generator/dpc3q85/) under PractRand, there are good reasons to think it's resistant to prediction, it has a bunch of useful features and it's fast enough that it seems absurd to think it would ever have nontrivial cost in a wider program.
Yes, PCG will replace Xorshift. It didn't make the cut for 0.5, but for me it is high on the list. The code is written, only needs a little cleanup. But we plan to move all the PRNGs to a companion crate, combined with better documentation. That seemed like a bit too much work to finish for 0.5.
There are a few good issues to work on there, tagged with "E-Easy" or "E-help-wanted", maybe others. One thing that is a bit difficult, is that for some things we had a lot of discussion, and an idea of the direction to take, but don't yet have an issue yet to explain so. Most of the 'design' discussion took place in https://github.com/dhardy/rand/issues. But if you want to help out, feel free to comment on an issue or open one. I am sure we can get things organized.
[Portable SIMD RFC](https://github.com/rust-lang/rfcs/pull/2366): I invite you to browse the RFC just to see the sheer amount of work the author poured into it. It's a novel!
Is luminance a game engine? [ /me ducks ]
I’m wondering the same thing. Though I heard that you can’t create a CLion project without CMakeLists.txt
Yes, depending on the error type we retry https://github.com/rust-lang-nursery/rand/blob/master/src/os.rs#L81
I wasn't asking you, and that doesn't even explain why it wouldn't be in Rust.
Generally speaking `Iterator&lt;Item=T&gt;` is functionally equivalent to `Generator&lt;Yield=T, Return=()&gt;`. The main difference is that iterator closely integrated with for loops, but I hope one day they'll support generators as well. See this [proposal](https://internals.rust-lang.org/t/pre-rfc-generator-integration-with-for-loops/6625) for more details.
Yes thanks, see my previous comment, the problem was with my reddit app which [doesn't render this comment properly](https://github.com/ccrama/Slide/issues/2697). Once again sorry for the noise.
Sorry, but this subreddit isn't for the Rust game. You should go to /r/playrust
In the big data era, working with numbers has become an incredibly complicated task. Inspired by this highly and critically acclaimed [post](https://www.reddit.com/r/programming/comments/87pav8/isthirteen_npm_package_to_check_if_a_number_is/?ref=share&amp;ref_source=link) in /r/programming, I've decided to build in Rust this useful library. Check it out! (jk, I'm just learning Rust and this was fun. Suggestions are welcome!)
Fantastic summary with a lot of great links. Thanks for posting!
I'm curious, do you know of some good resources about doing text layout with cassowary ? I have some difficulties with arranging and splitting spans of texts.
I would recommend `libpnet`, it sounds perfectly suited for your use case. 
You could improve the following code by using the format macro: ``` let response_string: String = [ relp_response.transaction_number.to_string(), " ".to_string(), "rsp".to_string(), " ".to_string(), relp_response.status.to_string(), relp_response.message.map(|m| " ".to_string()+ &amp;m ) .unwrap_or("".to_string()) ] .concat(); ``` would become ``` let response_string = format!( "{} rsp {} {}", relp_response.transaction_number, relp_response.status.to_string(), relp_response.message.unwrap_or("".to_string()) ); } ``` and clippy had some suggestions that you could take a look at.
I haven't tried debugging recently, but editing Rust with IntelliJ Ultimate with the Rust plugin is great. 
Sorry to correct you op, but clion already supported debugging via gdb. The support for cargo is new...
5 years? Why have I never heard of this language?
I agree that the documentation's pretty sad in this case. There's a lot of work to be done there -- somebody's just gotta do it! :) `lo-pdf` is intended to be a very low-level crate for PDF access -- I found it MUCH easier to understand after becoming more familiar with the structure of a PDF document as defined [in the PDF spec](https://www.adobe.com/content/dam/acom/en/devnet/pdf/pdfs/PDF32000_2008.pdf). My bet, however, is that you're not necessarily looking to invest that much into writing your own PDF extraction. If you look at the issues in `lo-pdf`, you'll notice that somebody is already asking about how to do simple PDF extraction -- the [`pdf-extract`](https://crates.io/crates/pdf-extract) crate is a direct response to the discussion in that issue. If you look at the [`extract`](https://github.com/jrmuizel/pdf-extract/blob/master/examples/extract.rs) example, I think you'll find it's closer the API you had in mind. I don't know if `pdf-extract` gives you facilities for examining pages like you mention in the OP, but I bet that it's a much easier starting point that `lo-pdf`!
How does CLion Rust stack up against IntelliJ Rust?
Few years ago (huh, it has been so long..) I was hacking some ARP code and found nom to work pretty easily for parsing Ethernet frames and ARP messages. Sure, it was pretty simple use-case too, but it allowed me to handle stuff like optional vlan tag and big-endian integers quite nicely.
Believe it’s better now that it works correctly without CMake. Also has debugging where I believe IntelliJ does not. Someone correct me if I’m wrong here.
Thanks for this. I'd just note that while Glium isn't "maintained" actively, /u/tomaka17 is taking pull requests, and there is one even in the last month. I think Glium is also somewhat battle tested as it's used by Servo? I don't know if this implies ongoing commitment by the Servo team however.
One approach to drivers I have used is to write all state registers on start to guarantee a know state. If reading that state is slow you can an some cases read the proxy state from memory instead, but not perhaps in this case. On err, reset full state again. An optional developer-supplied closure on err could also be a pattern for this emerging ecosystem. 
They have a preview build that’s free.
Yes, it's possible, but every tutorial I saw on the topic of imports and modules says: DON'T DO THAT. So, I'm used to files where everything that is used is listed on the top don't matter how much space it going to take. And after some time reading and writing Python, with everything explicitly stated, I found it strange that Rust allows and does not discourage this practice.
As far as I can tell it’s a long, complicated, mostly-untold story, but you can start [here!](http://joeduffyblog.com/2015/11/03/blogging-about-midori/)
Ah I thought it was only idea that did. My bad. 
Hmm, what about VSCode? I write and debug my code there. 
"Should immutable package managers be curated, and if so how?" 
I wrote a type for this, based loosely on the new file:///Users/benjaminfry/.rustup/toolchains/nightly-x86_64-apple-darwin/share/doc/rust/html/std/vec/struct.Vec.html#method.place_back and Place feature: https://github.com/bluejekyll/trust-dns/blob/master/proto/src/serialize/binary/encoder.rs#L372-L414
For context, I just watched [Rich Hickey's "Spec-ulation" Keynote](https://www.youtube.com/watch?v=oyLBGkS5ICk) and I read through [a](https://blog.golang.org/versioning-proposal) [bunch](https://research.swtch.com/vgo-import) [of](https://research.swtch.com/vgo-tour) articles from Russ Cox about vgo and semantic import versioning, which made me curious about Rust - what the heck are editions / epics? And/or where can I go to find out more about them? A lazy, basic googling of the term didn't really get me anywhere.
Servo uses gleam, not glium.
This is what "trait objects" are for, but there's no inheritance. https://doc.rust-lang.org/book/second-edition/ch17-02-trait-objects.html shows this off, putting several `Draw` types in one `Vec&lt;T&gt;`.
It's time-locked, and will stop working in a month or so. For CLion you really need a license.
The (epoch RFC)[https://github.com/rust-lang/rfcs/blob/master/text/2052-epochs.md] explains what they are
I'm hoping for VSCode and the RLS to be best of class. At the moment RLS still has some issues though where I find I have to restart the editor to resolve them. I still prefer its experience to that of IntelliJ, but only because I've grown to like VSCode. I'd really like an extension to LLDB to be able to just click on tests and run/debug them. At least, I haven't see that ability anywhere yet.
But isn't there a new one each month? (I'm still a noob, so I maybe messed it up, I thought that was true though.)
You can download new EAP build after a month
I had a few *well duh, obviously!*-moments with implementing a 2,3-tree, so things are moving ahead nicely. I'm currently working on separating the tree into pages: a single page contains a subtree, pages higher up in the tree will have "pointers" to next pages at their bottom level. Hopefully I'll have that working by the end of the week and can start tinkering with storing to and (partially) loading from disk.
I guess that means I'm buying a license or convincing work to get the business package.
Is this support in conflict with the "IntelliJ Rust" plugin or is it "just" the plugin preinstalled to clion?
That's fair. As I said, still a noob, so I'm not using particularly advanced stuff, and I've been using it to supplement VS: Code rather than replace it fully. I like what I've seen so far!
For sure!
Wow! This is asking for demonstration video :) Great to see the progress, i follow the development of this every now and than due to the involvement of jeremy@Redox – greetings to him, you, the pop_os team and the hole System76 crew!
Rouille, postgres (through diesel), nginx, Debian. After [doing some research](https://wiki.alopex.li/AnOpinionatedGuideToRustWebServers) Rouille did what I wanted. I sort of want to re-tread the ground covered by that article and see what's changed, sometime. It sort of surprised me how many things not directly related to my application that I ended up using anyway.... base64, dotenv, failure, jsonwebtoken, num, ring, serde, slog, tokio... all of those have a fairly critical role in making it go from "toy web app" to "actual robust API".
Thank you!
That only applies when an EAP cycle is active. There are gaps when a new build won't be available.
I'd say they are pretty similar and the biggest difference is actually convention. You could implement interfaces the same way as traits if you wanted (at least in .NET). For example I can make a class in c# and implenent an IClone interface that forces the class to define a function that clones itself. You could do this for every class and use interfaces everywhere. It's not convention but it would work the same.
Well, we do have this - https://www.youtube.com/watch?v=xF17TCWpqR8 :-) But you can check out screenshots on numerous blog posts on https://blog.system76.com/
Yes, but can you define a new interface and apply it to a class without modifying its definition? Genuinely asking, I know almost nothing about C#.
It's the same ish. CLion just has debugging support on top of that. 
Maybe check out https://github.com/m-labs/smoltcp, it seems similar to what you want to build (and if not, its test / example tools should help you).
&gt; even using the right APIs on Windows, which later had to re-invented.. I am curious, what does this mean?
Currently I write services that work in one of two ways: * They listen to SQS Messages, which are published to SQS from SNS, and to SNS from S3 Events This was pretty simple code to write. Not really robust though. I'll probably rewrite it to handle things like timeouts etc - a full rewrite of my 'sqs-service-helper' is really due, as that was a fun POC but really is quite garbage. It's built on rusoto. * Capnproto RPC The other services I have use Capnproto RPC. I'm going to be moving away from this to grpc, for a few reasons. I'd love to use Actix eventually but I'm just writing synchronous, simple code at this point. I don't use any databases yet. At some point I'll use redis, that's about it. Basically, the vast majority of my services should be communicating asynchronously - but I want persistence of messages. So S3 -&gt; SNS -&gt; SQS gives me: * Persistent messages (S3) * Multiconsumer (SNS) * Simple queue logic, retries, dead letters, etc (SQS) However there are a few services that need to be synchronous primarily for simplicity - I want consumers of these services to have a really, really easy time writing code that uses them. As such, I went with capnproto because I think it's awesome. Unfortunately, the documentation is not too great for rust, and I find intellij does a poor job of autocompleting the generated code. I'm moving to grpc because: * I think it's likely to be extremely well supported by other languages and services like ngnx * grpc has better documentation and general shared knowledge * to some degree, language support matters, but capnproto actually covers the only 3 I care about (C++, Rust, Python) 
I actually have an article on this. oO https://jmarcher.io/internal-vs-external-iteration/ The short version is that one use for generators is as a way to *implement* iteration in complex cases. The article provides some examples, albeit examples written in C#, not Rust.
[removed]
Been using IntelliJ to develop and Visual Studio to debug. This could convince me to get a license.
The blogpost said &gt; Rust comes with Cargo build system support Is this from the additional "Rust Plugin" i have to install or is this build into CLion? 
That's a good point; I was wrong. Interfaces only contain method signatures so you have to define the function for each class that implenents it. You would have to use inheritance/abstract classes to get that kind of functionality.
I’m getting big red security warnings on android. The security certificate you’re using is for *.tumblr.com. You may wish to fix that up.
It’s properly spelled “forty,” by the way.
Rocket, SQLite (through diesel and r2d2), nginx, NixOS. [It's a small API](https://github.com/flosse/openfairdb) used for [a map of sustainable POIs](https://kartevonmorgen.org/).
Oh yeah I was working with a vendor'd copy of the author's crate. There was a chain of breaking TLS related changes around November of last year and freezing it proved easier to maintain. 
Couldn't agree more about Cargo &gt; SBT. SBT was so arcane that I couldn't figure out how to get custom functionality, even after reading docs profusely. Maybe I'm just stupid for not being a high-level build tool expert (which I do not argue) but I much prefer Cargo and its simplicity. It gets out of your way, provides you the tools to do complicated stuff in a way that makes sense to you (build scripts etc), and is configured through a simple textual format which is painless to read.
I have a very simple app (for now) that is based on actix-web and just persists data with YAML files on disk with serde. The reason I chose actix-web is because: 1. it's asynchronous (based on tokio), which is important to me because my app involves long-polling, which is bad if you have to use threads. 2. it works on stable 3. and it has really good ergonomics for a framework that works on stable.
Ah, thanks!
Before 1.0, do we want to correct the spelling of "forty"? I know that's a breaking change. I guess it depends on whether you're ok with breaking thousands of users...
Yes, thanks! I appreciate that.
You have to install Rust plugin into CLion and then you'll get Cargo and Rust debugger, and all full Rust support
Same plugin, but debug is available now.
Libraries shouldn't check in their `Cargo.lock`.
&gt; The other services I have use Capnproto RPC. I'm going to be moving away from this to grpc, for a few reasons. Could you expand on those reasons? I'm about to start a new project that needs some form of RPC and I was leaning towards Capnproto.
Does it automatically start the browser, or does the user have to start it and enter the localhost link manually?
To be fair, I do not know how to create and export a library. Is `cargo new --lib name` enough?
Cool, thanks.
To add to this: Google uses this to make real systems go 10–15% faster via [AutoFDO](https://research.google.com/pubs/pub45290.html): a feedback loop that automatically gathers profiles in production and applies them to the next build. It turns out you don't need to instrument the exact same code to get a performance increase; even a six-month-old profile on an actively-developed codebase is enough to see some benefit. Alternatively, you could have your build process run some hot code paths (maybe the same things you've marked `#[bench]` on) and generate profiles from those, then compile it again using them. That seems a lot more practical for e.g. desktop software where you don't have a loop back from real users. As I understand it, the commit referenced here is just basic rustc support. You'd also want support in cargo and the like to actually do these things easily, but it's a step in the right direction.
Great! Thanks for the direct reply.
I have been using the webbrowser crate to open the link automatically (but haven’t put that in the demo).
One thing to consider when deciding if you need an async webserver is if you'll be directly exposing your webserver to the Internet, or if instead you'll have a reverse proxy server (such as nginx) in front of it. If you're directly exposing it to the Internet, you'll likely have a whole bunch of HTTP connections in keepalive state. Do you have the RAM to keep threads running for all of them? If not, you want an async server (actix or hyper 0.11.x), even if your actual request handling logic is synchronous. If you have a reverse proxy in front, the number of keepalive connections your webserver sees will be relatively small, so this probably isn't a concern.
That's [apparently](https://doc.rust-lang.org/cargo/guide/cargo-toml-vs-cargo-lock.html) Cargo's party line, but I disagree. It's useful to library developers to record the exact working configuration at each commit, even if binaries using the libraries don't pay attention to it. yarn's party line is to [commit the lockfile](https://yarnpkg.com/blog/2016/11/24/lockfiles-for-all/) for all projects, binaries and libraries. Their arguments apply equally well to `Cargo.lock`.
I am working on my first semi-useful crate: [enum-vec](https://github.com/Badel2/enum-vec), which "efficiently stores a vector of enum variants". It's basically a bitvec, but expanded to work with more than one bit at a time. I needed this crate for another project where I frequently use `Vec&lt;Bit&gt;` and `Bit` is defined as `enum Bit { L, H, X }`, so now I will try to refactor it to `EnumVec&lt;Bit&gt;` and benchmark the change. I don't expect much, so I will probably also create a `SmallEnumVec` which stores a few elements inline just like a `SmallVec`. And depending on my free time I may also write a blog post about that and all the things I explored while working on it: cargo doc, how to write a proc macro, travis integration, how to publish crates, how `A { 0: bool, }` is valid syntax with `struct A(bool)` even though 0 is not a valid identifier... well, it was a long journey.
I guess I could also add `gleam` then?
You could. There's really no good reason to recommend `gleam` over `glium`; you get almost no safety benefits and it's basically a transparent wrapper over the GL APIs.
I think what he/she is trying to say is that you don't need to track Cargo.lock with version control when writing a library. They are intended for binary projects for the most part.
I was looking at the [rayon source](https://github.com/rayon-rs/rayon) and saw that they didn't have a `main.rs` file in their `src` directory - I was wondering how this is possible, since I thought a `main.rs` file was necessary for compilation? I'm super new to rust (and compiled languages in general) so any help would be great!
Hmm rusts system of result type errors actually reminds me strongly of Java Java tried to have mostly checked exceptions with Runtime unchecked exceptions for a rare escape hatch like panics. But since they added so much complexity people started using runtime exceptions instead Result types are basically checked exceptions integrated into the type system. And rusts auto conversion and syntax sugar seek to make it easy to avoid java's problems
So the reasons were about the RPC and not the serialization?
That's actually a Cargo convention. `src/main.rs` is the implicit entry point for binary crates, expected to produce an executable. `src/lib.rs` is the implicit entry point for library crates, expected to be imported by others. Rayon is a library so it uses the latter. See this page/section for more information: https://doc.rust-lang.org/stable/cargo/reference/manifest.html#the-project-layout
Haskell has purity and an incredibly powerful type system which is used by tons of awesome libraries to enforce invariants, so it certainly gives the "if it compiles, it works" feeling. But there's still [exception stuff](https://www.fpcomplete.com/blog/2016/11/exceptions-best-practices-haskell) to worry about! Agda is more of a proof assistant than a practical programming language. ([Idris](https://www.idris-lang.org/) is an attempt at making a fully dependently typed language practical, but it's still [quite far from being a production language](http://docs.idris-lang.org/en/latest/faq/faq.html#is-idris-production-ready).) Scala and OCaml are… not that different from {insert generic language with garbage collection, mutable state and exceptions}, if you forget about their preference for functional style and think about what they actually *allow* :) But sure, some Scala libraries do use the type system like in Haskell. [Zig](https://www.recurse.com/events/localhost-andrew-kelley) is actually a language very much going for full correctness. The author cares a lot about memory allocation failure and such. You *have* to handle malloc failing. And by the way Zig has import of C headers built in without any need to make bindgen wrapper crates… and the compiler is really damn fast… why are we using Rust again?? … oh. Zig has fully manual memory management, no RAII, no traits.
&gt; Haskell is obviously way stricter than Rust Haskell is infinitely less strict than Rust, since everything is lazy by default! (sorry, had to make the joke :D) Back to the usual meaning of the word "strict"… well, Haskell requires you to explicitly sequence actions that mutate state / interact with the real world, sure. (Until you cheat and type the forbidden word `unsafePerformIO`.) But Haskell also is garbage collected, while Rust forces you to care about memory, with lifetimes and borrows and all that stuff.
Thank you for taking the time to share this. I was planning on using nginx.
None of the reasons are really technical. They're all about momentum behind the projects, and documentation. It isn't about the RPC or the serialization, it's about the fact that everyone is using gRPC and I'd rather not tie myself to a project that doesn't have a ton of support - I already am writing rust.
Awesome! Out of curiosity, which package manager does Pop!_OS use?
Vim using ALE has had asynchronous Linting for Rust for a while now /shrug
Have you compared the output of `generate-lockfile` on all of the manifests in crates.io?
Thanks for the explanation!
Node in the front end?
&gt; I could easily create a Vector&lt;T&gt; that stored instances of all those type, since they all inherit from T. That's only possible itself in the case where all of the stored types have the same size as T. Otherwise you fall into the [object slicing](https://en.wikipedia.org/wiki/Object_slicing) trap.
Any idea as to why it's so much faster than other installers? other than "because rust"
You totally missed out on the valid chance to call it "Kuic" - Kubenetes user intuitive controller. Which I'd pronounce the same as Quick
you should add the playlist to the README file :) Also some screenshots.
Not yet. @aidanhs did it for the original work, and it took ~4 hours using before and after that commit. Thanks to the `-Z no-index-update`. @aidanhs has not responded to requests to do it again. Nore have I had time to make an equivalent setup.
And other than "because almost every S76 machine has SSDs".
Haven't looked at the API, but start by using `&amp;mut data.vertex_buffer` if you are going to use `iter_mut()` I think?
redis rust implement
No Rust debugging in IntelliJ, you need CLion.
Rust plugin works great on community edition and ultimate but does not do debugging.
&gt; MIPS is the most beautiful of all the assemblies I have seen. With the baked-in branch delay slot? Meh. I'd personally have to go with m68k assembly, but that was 20 years ago.
I can't list every language I haven't used seriously or at all.
Text layout is not done via cassowary, that would be too performance-heavy. Only the rectangle for the layouted text is calculated, the rest of the text is layouted "regularly" (split into lines, determine spacing for alignment, correct line endings based on Knuth-Plass, handle text overflow scenarios). Take a look at how [limn-text-layout](https://github.com/christolliday/limn/tree/master/text_layout/src) handles this.
Text layout is not done via cassowary, that would be too performance-heavy. Only the rectangle for the layouted text is calculated, the rest of the text is layouted "regularly" (split into lines, determine spacing for alignment, correct line endings based on Knuth-Plass, handle text overflow scenarios). Take a look at how [limn-text-layout](https://github.com/christolliday/limn/tree/master/text_layout/src) handles this.
Text layout is not done via cassowary, that would be too performance-heavy. Only the rectangle for the layouted text is calculated, the rest of the text is layouted "regularly" (split into lines, determine spacing for alignment, correct line endings based on Knuth-Plass, handle text overflow scenarios). Take a look at how [limn-text-layout](https://github.com/christolliday/limn/tree/master/text_layout/src) handles this.
That would be wonderful! The last time this was done was https://github.com/rust-lang/cargo/pull/4834#issuecomment-363296892 witch has detailed notes on how @aidanhs quick script worked. If you could do a new run comparing after that merged (you'll want the `-Z no-index-update`) with nightly that would be amazing. Extra Credit if you felt like setting it up so we could easily run it again or setting it up to try pairs of dependencies.
What is system 76 or the pop! team? It reminds me of plants vs zombies, but I don't think they're making games with this. 
I don't need five bucks and it'd be better if you donated it somewhere! To install rust you can check out https://www.rustup.rs or head over to the rust site to get the latest stable build too. As far as learning goes, you can check out the book at https://doc.rust-lang.org/book/second-edition/ Again the rust website has lots of resources if you get stuck such as IRC or the user forum. Have fun!
Are you sure you can’t help me. I’m having other trouble than installing 
I see Aidan today and will make him aware. They are probably just very busy because of the all-hands.
Based on the video posted in another comment, the installation was done in a NVMe disk, which can be much faster than SSD. Still pretty impressive. 
System76 is an OEM that manufactures laptops, desktops, and servers. Everything ships with Linux (pop!OS specifically) and they are focused on making things as free (libre) as possible. [Check out this interview](https://youtu.be/MujjuTWpQJk) with the founder and the guy behind redox (a rust operating system)
I feel that the monetary reward would have the same impact it has on blood donors : reducing the amount of help instead of increasing it because it changes the perception of helping someone into «working» and working is way less rewarding than helping (and $5 isn't enough to overcome that feeling, especially in a community where everybody is making tens of thousands a year).
Well it’s a simple thing I’m asking you that should only take 2 minutes do approximately. 
This is very cool. How long does Ubuntu take to install on your machine? What is the relation between Pop! and Elementary? (It looks like you're also rewriting the installer for Elementary to use distinst.)
This is a community that will gladly help if you're having trouble installing and can clearly explain why the instructions on https://www.rustup.rs/ are not working for you. The $5 offer is a bit unusual... let's just drop it.
Ok nevermind getting help but thanks for the offer 
What about running it in a VM, disable NTP and change the date to one month earlier when your month is over ? Or you could just download a new one like everyone else said, but that not fun :p.
Thanks for diving in the details. The mention of XSalsa20 (which I just copied from some place in the original code) probably should go. It complicates things, becausae we don't use the extension scheme. The thing is we *don't have* a nonce. What would be a nonce+counter of together 128 bits, is now used as an 128-bit counter.
&gt; In Module rand::distributions: &gt; &gt; A distribution may have internal state describing the distribution of generated values; for example Range needs to know its upper and lower bounds. &gt; &gt; But looking at the docs for Range it seems to be immutable, so the passage above seems to misapply the term state. And now I'm confused whether distributions are actually allowed to be stateful objects and the Range example just failed to illustrate it, or whether they're not and it's just the common OOP mistake of referring to any internal values as "state." The art of wording things well :-). And actually I have difficulty improving upon it. What we try to convey is that there may be a one-time setup cost to prepare variables, but for now the distributions are only immutable. But we have mutable distributions in the back of our head, that just hasn't been a clear use for them yet. Any suggestion how to improve the doc?
Step 2: Find out that crates.io rolls certificates recently and you validation errors that the certificate is from the future. (I had that recently with a VM that didn't properly update it's time for $reasons)
make it 50 and I ll take your money
That’s a bit too much 
Please note that struct layout in Rust is undefined (to allow the compiler to optimise), _unless_ you use the `repr` tags to force a layout.
&gt; One potential pitfall that recurs through this is that it seems to me like the documentation is sometimes unclear who the audience is for which passage, and thus often gives what's either too much or too little information—a reader that doesn't know a lot beforehand is told a bunch of stuff they can't understand, while one who knows more isn't told enough to understand. Yes, I can recognize that. We, but especially /u/innovator12, have been putting some effort into improving the documentation for 0.5. There is the trick of collecting what is important to say, and turning it into something nice and user-focused. So I/we are going to work on the points you said. But if you want to help out a bit more in the repro by opening an issue/pr that would be great!
Nevermind got the help figured it out 
That parallel processing with in-order output pattern comes up pretty often. Is there a crate that helps with it?
https://github.com/rust-lang-nursery/rand/pull/353
You shouldn't be accessing verticies inside the buffer and changing their positions CPU-side to move an object. Instead you should be sending over a uniform (in gfx terms, a "constant") matrix that you apply to each of the verticies in the vertex shader in order to move them. This is because 1. The CPU is bad at changing many values at once 2. Sending data between the CPU and GPU is slow So, you calculate just a few values and send them to the GPU and then you let the GPU calculate the transformation on every vertex that it's displaying. That said, if you do want to use write_mapping to write to the vertex buffer, that method [returns a result](https://docs.rs/gfx/0.17.1/gfx/trait.Factory.html#tymethod.write_mapping) so you'll need to use that somehow before calling iter_mut() on it. For example, using the `?` operator: factory.write_mapping(&amp;data.vertex_buffer)?.iter_mut() Finally, looking at the type that write_mapping returns, [Writer](https://docs.rs/gfx/0.17.1/gfx/mapping/struct.Writer.html), it says: &gt; Mapping writer. Currently is not possible to make write-only slice so while it is technically possible to read from Writer, it will lead to an undefined behavior. Please do not read from it. So, I think you shouldn't be using `iter_mut` on it since you'll be implicitly reading from it to do so. Instead modify it directly like let vb_write = factory.write_mapping(&amp;data.vertex_buffer)?; vb_write[0] = my_vert_data; or whatever
This would make sense for most things, but in gfx, the OP actually has this part right. The argument to `write_mapping` is merely taking a handle to a buffer that's being managed by whatever the underlying graphics API that's being used is (opengl/vulkan/dx). Therefore it just takes a reference to a gfx Buffer object which is this handle.
Thanks for great explanation but I have few questions: * What if I want to remove some vertices? I assume I have to copy vertices from my vertex buffer, remove unwanted vertices and create new but how? I'm aware that it would be painful to do so in a game but I think it will be necessary in my level editor, which I'm also going to create * What if I want to change their data like texture position (I use it to "cut" sprites out of the main texture)? Do I have to use a unifofm for every attribute I want to change? * Do I have to have a list of *n* uniforms for *n* vertices and pass it all at once? (I keep all of the vertices in one buffer and draw them with one call)
Note that I specifically said _functional idioms_ (in particular, iterator chains) rather than FP, to avoid implying a direct comparison with state-of-art FP
I'm about to head to bed; I'll try to put together a response at some point tomorrow :)
Ok, thank you
No, it's supposed to say "the same size as `*mut T`". We actually just changed it to "the same size as `T`" and are fixing it now.
&gt; You can now have | at the start of a match arm Why was that necessary?
Hold on to your pants then. I believe the next release will have stablised impl Trait, among some other really cool features. As always, grats to the Rust Team(s) for creating an awesome Language!
Can any of your string formatting [trick](https://github.com/gimli-rs/gimli/commit/f138c5beb88cba7c1cbfac09b2dc91ab69fd53a3) be ported to std (somehow)?
It wasn't *necessary*, but it's also an extremely small tweak to the grammar that can make certain cases more regular, which can help when you're doing things like generating code. We have some precedent for this; you can declare empty structs with `struct Foo;` or `struct Foo { }`, for example
&gt; This has a number of effects, a major one being a step closer to AVR support. I'm a bit confused. As [this issue](https://github.com/avr-rust/rust/issues/90) is not closed yet, it seems that the rust avr backend seems be on an older LLVM right now... why is updating to LLVM 6.0 beneficial then?
I'm not sure how I haven't seen/thought of this before, but I'm definitely adding this as my default for long Python list comprehensions :)
Ok, then adding it to the list will be quick. Thanks!
From the issue: &gt; The AVR backend as of LLVM 6.0 has all of the patches included in the avr-rust/llvm fork (but we should double check this). This means that we should have no extra cherry-picked commits for avr-rust, so we will be using the exact same LLVM fork as upstream Rust. 
why !
I see. Thanks. 
Does that `cargo new` change also affect `cargo init`? Also, it's the first time I even hear about `cargo new`, what are the differences compared to `cargo init`?
I don't think so, but am not sure; I never use `cargo init`. `cargo new` creates a new subdirectory, `cargo init` initializes in the current directory. that is: $ cargo new foo --bin or $ mkdir foo $ cd foo $ cargo init
killercup is at the Rust All-Hands happening in Berlin, where the release took place "live", an event usually reserved for members of the release team. :P 
Thanks!
&gt; Many users love cargo doc, a way to generate local documentation for their Cargo projects. It’s getting a huge **speed bump** in this release I'm not a native English speaker, but is “speed bump” the right phrase ? Aren't “speed bump” speed reducing devices ? Shouldn't it be “speed boost” instead ? If I'm misunderstanding, please correct me so I can learn something new about English :).
I'm worried that things like nested import statements just makes the language less approachable. And for what? Do we really need multiple ways to write/structure imports so we can save a few characters at the start of each line?
I personally agree with https://www.reddit.com/r/programming/comments/87zdsc/announcing_rust_125/dwgpw9v/ I think it's pretty clear what the nested stuff is doing, I don't feel that it will make it particularly less approachable. I personally find it *clearer*, it's not really about saving characters.
Done! 
Thanks for the solid answer, and the good work 😁
A'ight, mate; she'll be right.
*chuckle* This was a good change. :-)
NVMe disks mostly are SSDs.
I've been looking forward to this for cases where you're mapping lots of `enum` variants to a smaller set of values. Think of mapping file type to whether that file is text or not: match file_type { Svg | Txt | Xml =&gt; true, Mpq | Png | Zip =&gt; false, } This format is less than great, because if you have a lot of variants, it can cause diff churn. It also hides the result all the way over on the right, which can make it harder to quickly parse the structure of the code. So you can put one variant on a line: match file_type { Svg | Txt | Xml =&gt; true, Mpq | Png | Zip =&gt; false, } At which point, you can probably guess why some people want to be able to write a leading `|`. :)
I misread this as "prison" and it took me a while to work out why you added the sad face :P
Iterator chains is not an FP idiom. It's just typical mutable programming.
Parent probably meant SSD+SATA.
We still can't have #[repr(align(n), packed)] though. :(
Am Norwegian, I reply "Ja, nei" to some yes/no questions, and it's direct translation is "yes, no" so.. Speech is kinda required to get the intonation though. 
There's so many socialists in the Rust team, we should have guessed it will end like this ! :p 
&gt; Furthermore, when getting stated Started, may be?
Can NonNull be used in FFI?
Yup! Spellcheck can't catch when you mis-spell as another valid word, heh. Want to send in a PR?
English, it's such a weird language filled with nonsensical things like that. 
This is awesome! Thanks for putting this together. :-)
I've been looking for an answer for 2 hours. How do I turn a 32 byte vector V into an immutable array?
It doesn't seem to have `repr(transparent)`, which isn't stabilized yet I think. It definitely should have it.
Especially if that code is generated by a macro. Not having to special-case the first variant is a boon.
Awesome! Can't wait for the next one...
Hey, I did see your ping on github but haven't had a chance to get round to running the full test, I don't have the powerful machine I ran it on available at the moment. It's reasonably easy to set up so I figured leaving [the instructions](https://github.com/rust-lang/cargo/pull/4834#issuecomment-363296892) around would be enough if someone were interested :)
that needs an RFC
You can't do it "in place" without going through unsafe (Probably using `transmute`). One thing to consider is that arrays usually go on the stack in rust, while the vector will be on the heap, meaning that you at most can do `Vec&lt;T&gt;` to `&amp;[T; N]` (i.e. a reference to an array). You can create an array and then use `copy_from_slice` to move data from the vec into the array. Of course, the array has to be mutable for this to work. You can make it immutable by by reassigning the variable as follows: ``` let mut array = [0u8; 32]; array.copy_from_slice(&amp;array); let array = array; // Not its immutable ```
Tokio has a [tutorial](https://tokio.rs/docs/getting-started/hello-world/) which introduces tokio and futures. There is a [guide](https://aturon.github.io/apr/async-in-rust/chapter.html) started by Aaron Turon, but it hadn't been updated for a while. For more deep introduction to network programming I'd reccomend Steven's book on [Unix network programming](https://www.amazon.com/Unix-Network-Programming-Sockets-Networking/dp/0131411551/ref=la_B000AP9GV4_1_1?s=books&amp;ie=UTF8&amp;qid=1522324533&amp;sr=1-1), but it is not Rust, but C.
&gt; This has a number of effects, a major one being a step closer to AVR support. What is AVR? 
That worked, thanks.
A family of microcontrollers from Atmel. Wikipedia: https://en.wikipedia.org/wiki/Atmel_AVR
AVR is an architecture used in some Atmel microcontrollers. Some of the more popular Arduino models use AVR-based microcontrollers.
Very minor benefit: as a vim user, I prefer it when a language allows all lines to be interchangable (e.g. trailing `,`) because of how quick it is to insert, delete, or move lines in contrast to making a change and adjusting the special case.
Thanks for the links! Does not need to be rust in particularity if it describes network programming in detail It is also fine. Just want to have some good knowledge of network programming. 
Next release certainly not, since development of it is done. The one after, we'll see what happens in the next six weeks! I haven't kept up with the details though... so I'm not sure.
&gt;Next release certainly not, since development of it __isn't__ done. Fixed a typo, I think. In any case, exciting! Development has been going really fast.
Ah yes thanks.
No, that’s not true. It works the same as pretty much every european language, where “a and b” is plural.
&gt; In Rust, a method that takes an immutable `&amp;self` reference guarantees it can be called safely on the same object from multiple threads While this is true for most types, there are a few types which are not `Sync` and `&amp;T` is not `Send`.
&gt; 'oo'roo Becky?
Heeey English speakers do that too! It’s usually phrased as “Yeah, no.” With a really sarcastic sounding ‘yeah’ 
I might be mistaken, but I believe this new version broke the `app_dirs` crate. I found [this error](https://travis-ci.org/mullvad/mullvadvpn-app/jobs/359835987#L179) in a Travis build. It was working yesterday, but I can't be sure about the cause because I don't have MacOS here to test it :/
https://en.wikipedia.org/wiki/Atmel_AVR
Hopefully `NonNull` will be stable in 1.26, it's what I look forward to, to optimize all my `Option&lt;usize&gt;`. I have an urge to post this on /r/playrust on April 1, just to get their confused reactions and get some revenge for all the video posts here. Not sure if I should do this, though.
Do you mean a different `NonNull`? It was stabilized in this release.
Sorry, I meant `NonZero`. Not yet stable: https://github.com/rust-lang/rust/issues/49137 So that `Option&lt;usize&gt;` is 8 bits (instad of 16) where the `usize` part can never be 0. 
Ahh, I forgot that the next version goes on to beta at each release.
I believe gzip at the moment. You're free to try your crate out on distinst that will perform a complete install to a specified disk. There's a install script in the tests directory. You just need to provide the key files from the casper directory in the Linux ISO.
I saw the ggez 0.4.2 announcement mention switching to app_dirs2 to fix macos build on 1.25 stable. That led to https://github.com/AndyBarron/app-dirs-rs/issues/28 which led to https://github.com/rust-lang/rust/issues/48716. tl;Dr: use app_dirs2
How to annotate that a function returns a fixed size str? fn hex(&amp;self) -&gt; str { let mut strs = String::new(); for b in self.bytes.iter() { strs.push_str(&amp;*format!("{:02X}", b)) } strs[0..64] } `self.bytes` is a 32 byte array. I am getting 42 | fn hex(&amp;self) -&gt; str { | ^^^ `str` does not have a constant size known at compile-time | 
I get all kinds of conflicting information about the "max" number of threads allowed for a rust program to spawn - sometimes arbitrary numbers like "32", sometimes people using some multiple of the number of cores. Is there a convention for this, or an idiomatic way of determining the maximum suitable number of threads for a task?
&gt; [..] the "max" number of threads **allowed** for a rust program to spawn A Rust program is allowed to spawn as many threads as the OS will let it. &gt; Is there a convention for this, or an idiomatic way of determining the maximum suitable number of threads for a task? If there is, you'd probably be able to publish a paper on it. The number of threads a given task can efficiently use depends entirely on what the task is doing, and what kind of hardware it's running on. You'll need to profile to find out what works best. Generally, "number of hardware threads" is about as good a choice as anything, given no further information. That's what crates like `rayon` default to.
No... If you want to encode a set of integer using this crate you would have to sort them and then encode them using this method. This crate does not include any way to rapidly compute the union or the intersection of two such sets. (Tantivy includes efficient way to do that.) In general, I don't think any beats a bitset if your bitset is dense. If your bitset is sparse, you might want to encode it using bitpacking, and implement unions and intersection on your own. What is the ratio of ones over zeros in your bitset today?
i use roaring-rs to handling this ( https://github.com/Nemo157/roaring-rs )
Would love to hear more about the game itself mate!
It makes it easy to format things when I make vim macros and don't have to worry about one line doing something weird and non uniform
(From the same author by the way)
Why dont you read books (orilley, Rust in Action) and develop some prototypes :) ?
Removing because of the loginwall and unclear relevance.
We're a bit late with it because of Reasons, should be soonish. Probably Mondayish.
Im a newbie as well. One thing I found that has helped me so far is to find a project to contribute to along side reading books. There are many great projects put there with people just waiting to help newbie contributors :)
I’m in a project with people who do Python Haskell and web development 
AFAIK, you can't independently deallocate two different parts of the same `Vec`. The underlying allocator (quite reasonably) won't stand for it. So even if you weren't coding in Rust, but in C, you'd need to figure out how to synchronize deallocation. I mean, if both parts have full ownership, that would also imply that both could simultaneously mutate the same region of memory. I would instead suggest something like this: https://doc.rust-lang.org/std/primitive.slice.html#method.split_at_mut --- It's not clear whether it fits your requirements or not though.
"yeah, nah" meaning, "yeah, that won't work"? vs. "Nah, yeah" meaning "Nah, that's right"?
It should be speed boost. But as a native English speaker, it's clear to me what they meant.
As someone pretty new to rust, can you explain what is meant by sticking your imports in a stack? A code example would be great!
The style of use foo::bar; use foo::bar::baz; use foo::bar::baz::quxx; feels like you're stacking them up. It's not really a term everyone uses, just invented for that post.
We did a test install of Ubuntu using Ubquity, and it took over 2 minutes. But we use some pieces of elementary like the app store, and they've been helping with the installer. Our UX architect also works on elementary.
It uses debian packaging since it is based on Ubuntu.
One use case I'm imagining is reading in a large buffer from a data source, inspecting and partitioning it based on some protocol, then distributing those buffers to different handlers (maybe different threads, different structs, etc). I realize the underlying malloc wouldn't like two disjoint frees, even if the theory is sound. Maybe this would be ideal: - the Reader allocates a big buf (let's say 32kB) and reads data into it - the Reader decides it wants to break the buffer directly in two and hand out two 16 kB buffers - the underlying buffer has a ref count that is set to two - each consumer gets a "buffer" which to them is a regular mutable slice of bytes, but is actually part of the larger buffer - the big buffer only gets deallocated when when the last consumer drops it. This would be easy to do with an explicit lifetime but that would restrict e.g. passing the buffer to a different thread. It could also be done with an Arc and Mutex around one buffer, but the consumers, having completely disjoint memory regions, really shouldn't need to lock the entire thing and block eachother. The ref count is the only thing that needs to be synchronized and can probably be done pretty easily with Atomics. 
that's the way I understand it. "yea, no" and "no, yea" have made their way into american english too, over the last couple years.
Have you tried `split_at_mut`? Once you have two `&amp;mut [T]`s, you can then send them off to two different threads independently. You can do this with a scoped threadpool, which even includes an example that is basically exactly what we're talking about: https://docs.rs/scoped_threadpool/0.1.9/scoped_threadpool/ I believe crossbeam also has support for scoped threadpools. No need for reference counts of mutexes. :)
Okay so I'll try to answer these naively and then explain why you are probably coming at some of these from the wrong perspective. * In gfx, the [draw](https://docs.rs/gfx/0.17.1/gfx/struct.Encoder.html#method.draw) method on an encoder takes something gfx calls a [Slice](https://docs.rs/gfx/0.17.1/gfx/struct.Slice.html). This will allow you to modify which vertices in a buffer get drawn. If you want to remove a vertex at the end of the buffer, you can simply use this to draw one less vertex. Now, if you want to remove a vertex or vertices from the middle of the buffer, you'll need to splice those out in your local representation of the vertex buffer (what I was calling `vertices` above), then do the `encoder.update_buffer(..)` as above, and then also change the `Slice` you give to `draw` to draw however many less vertices. * If you want to change a texture position (or another "vertex attribute" (one of these is the vertex "itself" aka position)) individually then you should change it in your local buffer as I described above and then again `update_buffer` as described above. Uniforms are for values that are the same for every (or a set of) vertices within one draw call. This should hopefully make more sense with the next answer... * No, you generally want a single uniform that represents a certain transformation. Uniforms (aka constants, I'll call them that from now on since that's what gfx calls them) maintain a constant value *throughout an entire draw call*. Therefore the idea is that you'll have one constant, often called an MVP or *model-view-projection* matrix, which is the sum of all transformations that need to be applied to a single object. Then you pass this constant into your draw call for a specific object, and those transformations get applied to all of the vertices in that object at once. So, you have one uniform for all the vertices that you want to apply the same transformation to. The key here is that these transformation are moving/transforming the object as a whole. If you want to modify the actual geometry of the object (the form of the object itself) and not where the object is or its rotation/scale/etc (rigid body transformations) then you'll want to modify the vertices in the vertex buffer themselves. But--remember, these are relative only to the object itself, and then you take this changed mesh and apply the above transformations to it to move it just like before. Ultimately, I think you need to learn about how modern graphics pipelines work. The best documentation for this revolves around opengl, which, the API of course won't translate directly to GFX, but almost all the concepts will (as far as how the pipeline works, how shaders work, how you should be doing transformations, etc.). Check out [learnopengl](https://learnopengl.com/Getting-started/OpenGL) and go through the whole "getting started" tab on the left and make sure you understand it all thoroughly, these are all super important concepts for graphics programming in general. If you don't get something or want some more help/explanation then feel free to send me a message or something and I'd be happy to help. 
In C, to "view" a packet, you first need to `memcpy` it on to the struct you use for viewing. And then hope the compiler removes the copy. Or just use `-fno-strict-aliasing`.
Vlan tags are indeed annoying :p You can still reinterpret memory piecemeal, though, which works well, although it requires a first lightweight parsing step to skip the vlan tags. Did you compare the performance of using `nom` versus just "viewing" the memory?
Ha, I'm not used to this confusion going the other direction.
No lie!
The compute_delta function could use alignr (ssse3 instruction). The compiler seems to figure that out with the sse3 version when it's compiled with ssse3 instructions enabled. But since the avx vpalignr is too weird the compiler can't use it automatically here. But by hand it should look like fn compute_delta(curr: DataType, prev: DataType) -&gt; DataType { unsafe { let shifted = _mm256_alignr_epi8(curr, _mm256_permute2x128_i256(prev, curr, 0x21), 12); _mm256_sub_epi32(curr, shifted) } }
You can use vec::into_boxed which returns a Box&lt;[T]&gt; and doesn't require any copying.
thanks for the info! the ratios vary quite a bit as I am keeping indexes for ~10 attributes of an object that is split in columnar format. Not sparse, though, I don't think. Maybe 5% ones is the minimum case, 50% maximum case. 
That is not a worry, this is a worry.
AVX2's alignr is so frustrating: https://github.com/rust-lang/regex/blob/2b1fc2772dc4d99ad732a43751fb5627f327abc8/src/vector/avx2.rs#L149-L163 (make sure to see jneem's link from the comments for a much better explanation)
I feel that the output printing tuning is a recurring theme in these sorts of stories. That makes me think that maybe we should/could provide better patterns/libraries for doing that so that projects wouldn't get slowed down by default by printing so much. Another thing is that we are paying occasionally somewhat high price for Rusts thread safety, which is overhead in single-threaded contexts. This goes sort of bit against the promise of zero-cost abstractions and paying only for what you use. It would be neat if we could somehow avoid that. I fully acknowledge that both of these points are very difficult problems, so I'm not laying any blame for Rust not doing better here. But there is always room for improvements.
Are globs imports supported in nested imports yet? I thought they were under a separate feature toggle.
This is the first time I'm hearing about event sourcing, but it sounds interesting. Lots of questions: * So do you store each event as a record in a database? Do you not end up storing a massive amount of data that way? Maybe that's a feature not a bug :) * How far back in time do you go? Would you store the entire history of a product from releasing it to discontinuing it? * If I'm imagining a large corporation with several stores, I can imagine that each store would have its own event stream for keeping track of inventory or revenue. How would that look at the corporate level? Would each store fire off corporate-level events (say at the end of each business day) that are collected by corporate HQ, or would HQ just listen in on every store-level event produced at each store?
You're welcome :) One more tip, for gfx specifically, I've found that often the best documentation is looking at projects that use it. For example, [`three-rs`](https://github.com/three-rs/three) is written by the same people who are writing gfx, and the code is (relatively) fairly easy to understand one you start getting the basics down. Also, if you hop into irc on `irc.mozilla.org` and join the `#rust-gamedev` channel, `kvark`, who is one of the main authors of gfx, is often hanging around there and is usually happy to answer questions (or at least provide some guidance on where to look).
Yes, glob imports inside of groups are supported in stable Rust 1.25.
&gt; Maybe a good hello world tutorial you guys can point me to? You might like https://doc.rust-lang.org/book/second-edition/ which starts at hello world and goes from there, or https://rustbyexample.com/ which is mostly code, less prose.
&gt; The embedded WG has proposed an alternative proposal: expose some assembly operations that need to be inlined as “Rust intrinsics” – in a similar fashion to how SIMD is being implemented; these intrinsics would be in the `core::asm::$ARCH` module and they could either be implemented by lowering to a LLVM intrinsics or using inline assembly. It's not immediately clear to me how such instructions would specify the clobbering, for example, but I think I'd like the syntax of calling functions instead of writing a string with assembly inside; and I hope the compiler would produce better error messages!
Woot!
There are a million variations and if you’re new to ES I’d suggest taking in a few videos from conferences on the subject. In general, there’s an “event store” that provides a persistent read only list of events. Sometimes there are snapshots (persistent aggregates) in there as well but that’s also an architecture choice that usually spurs a good bit of debate. Your snapshots and your compliance records usually determine how far back you go. It is not uncommon to see people storing multiples years worth in systems like Kafka. If you’re taking about divisions of a company expressing interest in events managed elsewhere, with their own unique event stores, then we’re looking at concepts like event streaming. There’s no silver bullet and a lot of this stuff ends up being domain specific. Some constants are the immutable nature of events, and the use of aggregates to expose computed state based on some subset of an event stream.
Thanks (again), that's really helpful
Perhaps he means as a rendering engine?
Take a look at rustfmt and cargo clippy. Nice job and welcome!
:O thank you I wasn't aware of this. Is it as panic happy as the other prometheus crate?
Try the csv crate first: https://crates.io/crates/csv
Assuming the file is in cache, the CSV crate should be able to munch through a 2GB file in a matter of a few seconds. There is a [full blown tutorial here](https://docs.rs/csv/1.0.0-beta.5/csv/tutorial/index.html) and a [cookbook here](https://docs.rs/csv/1.0.0-beta.5/csv/cookbook/index.html). To get every drop of performance see the [corresponding section in the tutorial](https://docs.rs/csv/1.0.0-beta.5/csv/tutorial/index.html#performance). I don't have time to rewrite your program but: * What proportion of records are you creating and writing a file? If it's "most," then that's a lot of syscalls. :-) * Reduce or eliminate allocations. `BufRead::lines` creates a new allocation for each line. `format!` creates another allocation. `chars().skip().take().collect()` creates another one. If your file isn't in cache and you don't have an SSD and/or Windows is running some kind of anti malware stuff slowing down file read throughput, then all bets are off. (Spinning rust alone shouldn't account for the 4 minute clock time, but Windows might.)
Why do you want a color scheme only for rust?
Okay I'm learning Rust myself. Rightnow with the orilley book. I can offer you that both of us do kind of a challenge and develop the same thing After that we compare the solutions :)
Out of curiosity, what would the following be worth to you?: * 13 week course (7 days/week) * On-Line Live (or recorded) Lectures (1 per day / 2 hours) * Exercises to work (4 hours/day) * Graded Feedback Code Reviews * Starts from "Hello World!" and download/install Rust Toolchain * by 1/2 way point creating a full Console CRUD application * by End, creating a full Web-Stack application using Rust for back-end and possibly even Rust for a lot of the front-end with WebAssembly - use of JS etc. as well * would include DB integration with PostgreSQL etc. * smallish/simple game creation (think "Battleship", "Tic-Tac-Toe", etc) Course would assume no specific prior programming experience. You would just need to be motivated, intelligent, and hard-working and at the end of the 13-week course you would have done all of the above (not just followed a recipe). What would that be worth to you?
Ok 
I’d have to think about it 
If you don't need to re-allocate the underlying buffer you can transform the `Vec&lt;u8&gt;` into a `Box&lt;[u8]&gt;` (owned fixed slice) then into an `Arc&lt;[u8]&gt;` which you can slice and partition while respecting the `Arc&lt;T&gt;` contract. As the underlying `[u8]` is read only you don't have to worry about synchronization.
I probably don't know shit, but I would still say that all the enum variants that lead to true are part of only one *match arm*. Is that just my misunderstanding / bad wording in the announcement or is there something else going on?
Yep! I was running with the debug version, now with release is 1m20s. I'm going to try to improve allocations and not use the iterator as you propose.
Thanks! I had already ran rustfmt and clippy, but it looks like there was a couple of small issue for them to fix after all.
I also find myself saying "no, yeah" sometimes, like if someone asks "Would it be a huge problem if we did XYZ?" "No, yeah, go ahead and do that."
Do you hire remote developers?
I only ever use init and i usually build a lib and i usually have -rust in the folder bt not crate name. I’m a sad camper :(
Sorry :(
Hacking on a library for doing background jobs like the kinds that web apps always use. Think sidekiq for Rust. https://github.com/davidpdrsn/robin
Great. I'd be curious to know what the other changes do to your runtime, too--you know, if you implement that stuff and happen to be bored afterward. :)
You already have a BufReader; there's also BufWriter to avoid a `write` syscall for every line. The `l = format!(...)` call for each line is unnecessary, you can write the line and the line-ends to the output separately or using `write!(out, "{}\r\n", line)`. As others have said, `symbol` need not be a String immediately, you only need an owned string to insert in the hashmap, but not for lookup
It benefits git diffs quite a bit as well. 
Yeah, looks like Rust catches about 8 too.
Will be other languages than English be supported?
It might will require copying if vectors size is not equal to capacity - you can't make a slice that uses bigger allocation than its length, as dropping it would give wrong length and probably corrupt the heap.
That could be correct if "+" was short for "and", but I don't think it is in this case. I think it's more like a combination (like addition) of Rust and Node.js. A "the sum is grater then the parts" type thing.
oh sweet... The original library did not have delta integration for AVX2 (at least I did not find it) so I kind of went freestyle but the latency of the instructions I used is much higher than what you used.
Thanks for filling the issue. It is well appreciated. I'll need a bit of time to reply,
bitvec are probably not a bad solution then.
"A Snakes Tale" was done in Rust: https://michaelfairley.com/blog/i-made-a-game-in-rust/ 
&gt; I feel that the output printing tuning is a recurring theme in these sorts of stories. It would generally be great if the thread local output stream was exposed, was switchable and could be replaced with a faster one. In particular I would love to tell threads to temporary print to memory only (in tests), the delay flushing etc.
/r/playrust
&gt; There is a standard way of improving data processing performance: parallelization. Nope. Not. Ever. Parallelization is the **last** step of improving performance, it introduces a whole host of issues of its own, as well as performance pitfalls. The standard way of improving data processing is to: - process close to the data, - reduce the number of syscalls, - and optimize CPU usage, not down to the last cycles, but avoiding allocations and playing nice with the cache are huge performance leaps. Then, and only then, if serial performance is still insufficient, you can try and open Pandora's box. 2GB is peanuts; Rust should crunch through that much in **seconds**.
Micro optimization: avoid double look-ups! if !map.contains_key(&amp;symbol) { // insert here } else if let Some(x) = map.get_mut(&amp;key) { ... } Means that whenever the element is in the map you first look-up to see if it's there (it is) and then look-up a second time to get it. A slightly better way is to reverse the clauses: if let Some(x) = map.get_mut(&amp;key) { ... } else { // insert here } As returning `None` is the same information (logically) as `!contains_key`. This still incurs a double look-up in the "miss" case, however since you're creating a file it won't matter. For sake of completeness though, I feel compelled to indicate the **optimal** way: using the `Entry` API. let x = map.entry(&amp;key).or_insert_with(|| { let out_path = format!("{}{}{}", "C:\\outRust\\", symbol,".txt"); OpenOptions::new().write(true).append(true).create(true).open(out_path).unwrap() }); This does a single look-up, whether the item is already there or not!
why not use trailing ```|```? 
Not quite. The point was that internal iteration is a lot easier to do when you're dealing with some kinds of complex data structures. In that case, a generator becomes a way of--basically--exposing internal iteration as an external iterator. So, for that use case, a generator makes *internal* iteration *external.* 
I just read in the hackernews thread that rust 1.26 will have impl trait. I'm really excited! But a shame that I will be on vacation from may 13th on for one year... So, I will not have the opportunity to port the imag codebase to use impl trait, unfortunately. :'-(
Adding to /u/Menawir's answer, the [arrayref](https://github.com/droundy/arrayref) crate helps you make that pointer conversion safely. And because a `[u8; 32]` is `Copy`, you can just use `*` to turn those references into values. The result tends to be a one liner, which is nice.
Is the file ASCII? If so you don't need to treat it as UTF8, just a Vec&lt;u8&gt;. The two calls to `l.contains("RH") || l.contains("RT")` stand out to me. You don't say where you expect these tags...if they are in a fixed position you can just sub-slice. Much faster. The fact it is CSV seems to be red-herring, as you aren't trying to parse it as CSV at all. How long does it take Windows to copy the file? That is probably the best time you can match since you seem to be writing the same amount of data as you are reading.
That makes me think of something like: struct Buffer&lt;T&gt; { buf: Arc&lt;[T]&gt;, range: (usize, usize), // Probably should use dedicated range type } fn split_vec&lt;T&gt;(v: Vec&lt;T&gt;, idx: usize) -&gt; (Buffer&lt;T&gt;, Buffer&lt;T&gt;) { let a = Arc::from(v); let b = a.clone(); let len = a.len(); (Buffer{buf: a, range: (0, idx)}, Buffer{buf: b, range: (idx, len)}) } impl &lt;T&gt; Buffer&lt;T&gt; { fn get(&amp;self, idx: usize) -&gt; Option&lt;&amp;T&gt; { let offset = idx + self.range.0; if offset &gt;= self.range.1 { None } else { self.buf.get(offset) } } } Feel free to use it if it does what you want, though I'd recommend testing it as I just typed it straight into Reddit.
Oh no! &lt;3 Something to look forward to when you're back?
Thanks!
If you wish, It's also possible to implement the Index and IndexMut traits for operator overloading. You can also implement the split function as a method on Buffer itself to further subdivide it. Naturally you wouldn't need to generate a new Arcfor it, just clone the existing one. Maybe I should package this as a crate with a few more features.
`rayon` is a library for others to use, not a binary (executable) target for standalone use; as such, it uses the *library* layout style, which means that its default main file is `lib.rs` (which [does exist](https://github.com/rayon-rs/rayon/blob/master/src/lib.rs)) instead of `main.rs` (which you noted does not exist).
/r/playrustlfg to be specific; /r/playrust doesn't want "LFG" posts either.
How are you benchmarking the cargo resolver? I'm playing with it a little bit and I would like to measure the before/after performance.
From what I can tell, this is something that my code can do that `bytes` can't: `Buffer&lt;Option&lt;Box&lt;i32&gt;&gt;&gt;`
I'm a fan of base16-twilight
This was the same [conclusion I arrived at](https://stackoverflow.com/q/49392712/155423).
We do want to support other languages, and we'll look into having translations after the 18.04 release.
&gt; Tier 2 support for AVR next release I'll say **no** :-). We aren't even fully compiling libcore yet. :-)
No, I can't agree. You are talking about micro optimizations and as you mentioned yourself - **serial** data processing. Though the things you mentioned are very important for serial data processing, in any non-trivial data pipeline they are not enough nor standard: * in 99% cases you have a network cable between your "data-processor" and your data and you need a data pre-fetching, * as soon as you have more than one more or less heavy data processing stages - you want them to have their own buffers and work in parallel (sequentially in data-time but parallel in real time, if you understand what I mean). But if your algorithm is parallelizable - that's the way to go: use all 32+ cores or go further and scale on many servers. **Horizontal** scaling is the only reliable and working approach to process data really fast - it's not even comparable. Micro optimizations come next - when you see too big bills from AWS and you decide to cut some costs. I could understand you point 10 years ago, even maybe 5. But it is 2018, it's not "Pandora's box" anymore. We have data processing frameworks and libraries which make things smooth, easy and safe. Not sure about the state of it in Rust, though, but I hope it's getting there. But that's just about data in general. Going back to the topic starter's problem. I agree that he has a simple problem and 2GB of data is not a lot and that the processing logic is almost non-existing. But the author wanted ideas how to process data faster - so let him know all the possibilities. In the end he can make better decision based on all unknown to us variables (like what are the actual business requirements and development vision, etc.).
Reminds me of http://asciiflow.com/
Currently there are still 2 bugs open which crash llvm when compiling rust-core. These might be resolved really soon™. After that I think we have to evaluate what is still missing.
How can one parallel iterate over a serde JSON data structure using rayon. For example like here: https://gitlab.com/tobias47n9e/wikibase_rs/blob/master/src/from_json.rs#L296 Do I need to collect the data into a vector first or is it possible to implement these par_iter traits for serdejson?
I'd also think that rather than `get` and so on, you'd `impl&lt;T&gt; Deref for Buffer&lt;T&gt; { type Target = [T]; }` just like `Vec` and get all of the access methods for free from that.
What do you mean by "panic happy"?
I'm with matthieum on this one. If your single threaded version is taking minutes when it should be taking seconds, then start there. When you're done, you might not even need to do anything more because you might have hit your target. In other words, the OP's got bigger fish to fry. :-)
Absolutely. I was trying to keep things simple for a Reddit post.
https://github.com/altercation/vim-colors-solarized
(10) is referring to `(lParam &gt;&gt; 16) &amp;&amp; 0xff?` If so, it will compile error because &amp;&amp; expects booleans rather than ints.
You forgot blockchain. 
i thought old vim color scheme doesn't understand rust well. so those schemes are half-hearted. am i wrong?
If you want to re-interpret the bytes of your fields as another type, (e.g. casting a `[u8; 4]` as an `i32`) then you will need unsafe (have a look at [`std::mem::transmute`](https://doc.rust-lang.org/std/mem/fn.transmute.html) ). You will also need unsafe if your "fields" overlap. If you just want mutable access to non-overlapping sub-ranges of your initial buffer, then no unsafe required! Just wrap the `&amp;mut [u8]` in some type that uses `split_at_mut()` to break out the individual fields that you want to access. See https://play.rust-lang.org/?gist=6aaf707f7a6773effb9a609f5bd4b5ce&amp;version=stable for an example 
I agree, Mpq | Png | Zip more looks like a tree-structure of read (not "parsed in your head")
Go compiler already inserts preemption points (think "yield") at each non-inlined function call. Now they want to have them nearly everywhere. I find this really interesting, compared to the fully manual (and not yet finalized) Rust way.
Good to known I'm not the only one that's working on with undomented codebases :) &gt; Protocol is only documented by its (sometimes messy) code. Monero is one of the worst codebases I've seen so that's why I'm rewriting it, actually while reading it's source code I've found things like [this][patch]. I think doing it benefit both projects :). ***** If you want we can do coworking on your project or mine's. [patch]: https://github.com/monero-project/monero/pull/3261
I'm an idiot. &gt; which means that `Option&lt;NonNull&lt;T&gt;&gt;` has the same size as `*mut T` Why is this not `NonNull&lt;Option&lt;T&gt;&gt;` instead? I think I'm misunderstanding something here. (Glad cargo defaults to binaries now.)
And here's an example of how you might use unsafe and `mem::transmute` to re-interpret the memory: https://play.rust-lang.org/?gist=d5a4304dddd7fb102d652672f5c26c3e&amp;version=stable
I wonder how this would compare to how Erlang does preemption with reduction counts
How do you avoid the `BufRead::lines` allocation? (assuming you want lines and utf8)
Well, Option&lt;T&gt; normally takes up an extra byte to store the state of the option. `Option&lt;NonNull&lt;T&gt;&gt;` had been taking up an extra byte until this release. The optimization relies upon the observation that if we won't ever allow a `null` value stored in an `NonNull&lt;T&gt;`, then there's never a case where that value should have all 0 bits (since that's `null`)--therefore that value that could be repurposed to represent `Option&lt;NonNull&lt;T&gt;&gt;` as `None`.
I guess my basic assumptions were wrong. I'll take a look in the Rust book. Thanks!
Quick [search for `getter` on `crates.io`](https://crates.io/search?q=getter) shows at least three. As an aside, accessors aren't as much a thing in Rust as in other languages. The major reason is probably how they interfere with borrow checking in ways that direct field access doesn't. With an accessor, you have to borrow the *entire* base value. With field access, you only borrow that specific field.
The inner array is just a regular `Vec`, so `par_iter` should work fine for that. The outer loop is over a custom `Map` type, so you'd probably have to dump it to an array first. That said, I'm not sure if parallelisation will help here. Even if you could avoid the up-front allocation for the outer loop, you'd have to reallocate to merge the results together at the end. Plus, this code doesn't seem to do much actual *processing*, so you're probably bound by memory speed, not processing speed. (He says as someone who recently did something very similar just to make sure he could.)
Hey! I took the liberty of reformatting your code blocks. Reddit uses 4 spaces at the start of each line rather than triple quotes/backticks for codeblocks. Here it is with all of the context: &gt; I'm having difficulty binding to an SDK. The SDK is provided as a set of C++ headers with precompiled static libraries. My build script looks like this: &gt; &gt; extern crate bindgen; &gt; &gt; use std::env; &gt; use std::path::Path; &gt; use bindgen::builder; &gt; &gt; fn main() { &gt; &gt; // output message &gt; println!("launching build script."); &gt; &gt; // create the output file location &gt; let out_dir = env::var("OUT_DIR").unwrap(); &gt; let dest_path = Path::new(&amp;out_dir).join("pleora.rs"); &gt; &gt; // make the bindings &gt; let bindings = builder() &gt; .enable_cxx_namespaces() &gt; .raw_line("pub use self::root::*;") &gt; .header(r"src/pleora-sdk/PvVersion.h") &gt; .header(r"src/pleora-sdk/PvTypes.h") &gt; .header(r"src/pleora-sdk/PvString.h") &gt; .header(r"src/pleora-sdk/PvDevice.h") &gt; .header(r"src/pleora-sdk/PvStreamGEV.h") &gt; .header(r"src/pleora-sdk/PvResult.h") &gt; .whitelist_type(r"PvString") &gt; .whitelist_type(r"PvResult") &gt; .whitelist_type(r"PvDevice") &gt; .whitelist_type(r"PvStreamGEV") &gt; .whitelist_var(r"PRODUCT_NAME") &gt; .trust_clang_mangling(false) &gt; .derive_copy(false) &gt; .layout_tests(false) &gt; .clang_arg(r"-xc++") &gt; .clang_arg(r"-std=c++14") &gt; .clang_arg(r"-Isrc/pleora-sdk") &gt; .clang_arg(r"-L/Library/Frameworks/eBUS.framework/Versions/A/eBUS") &gt; .clang_arg(r"-lPvBase") &gt; .clang_arg(r"-lPvDevice") &gt; .clang_arg(r"-lPvBuffer") &gt; .clang_arg(r"-lPvGUIUtils") &gt; .clang_arg(r"-lPvGUI") &gt; .clang_arg(r"-lPvPersistence") &gt; .clang_arg(r"-lPvGenICam") &gt; .clang_arg(r"-lPvStream") &gt; .clang_arg(r"-lPvTransmitter") &gt; .clang_arg(r"-lPvVirtualDevice") &gt; .generate() &gt; .expect("Failed to generate Pleora bindings!"); &gt; &gt; // write the output &gt; println!("write bindings to: {:?}", &amp;dest_path); &gt; bindings.write_to_file(&amp;dest_path).expect(&amp;format!("Coudn't write bindings to {:?}", &amp;dest_path)); &gt; &gt; &gt; // output message &gt; println!("build script complete."); &gt; &gt; } &gt; &gt; &gt; but it outputs: &gt; &gt; Compiling pleora-bindgen v0.1.0 (file:///Users/me/Developer/pleora-bindgen) &gt; error: linking with `cc` failed: exit code: 1 &gt; | &gt; = note: "cc" "-m64" "-L" "/Users/me/.rustup/toolchains/nightly-x86_64-apple-darwin/lib/rustlib/x86_64-apple-darwin/lib" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e.1240bgp2jxhfxlb4.rcgu.o" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e.16u6js6g0l3k1ic6.rcgu.o" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e.1im38lueib99jsk0.rcgu.o" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e.1q2kt05ir4tvpm2v.rcgu.o" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e.1t29deoczvd0tzz7.rcgu.o" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e.1y16o1qfye96o7m0.rcgu.o" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e.3ayaeypdcro9d6yk.rcgu.o" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e.3cx7oljifvb206q7.rcgu.o" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e.3rngp6bm2u2q5z0y.rcgu.o" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e.44bsbddupzfao2om.rcgu.o" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e.45nf4z58qqykpcpi.rcgu.o" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e.48pm6mf8t7zlf4b1.rcgu.o" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e.49a7n47po4ttqjl7.rcgu.o" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e.49lx1q7cxvpykyv0.rcgu.o" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e.4ezmh1vbs95c5ack.rcgu.o" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e.4jdnq7xfjeka1bt.rcgu.o" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e.4xq48u46a1pwiqn7.rcgu.o" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e.4yh8x2b62dcih00t.rcgu.o" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e.5gf6du7k58s78kob.rcgu.o" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e.8xzrsc1ux72v29j.rcgu.o" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e.9elsx31vb4it187.rcgu.o" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e.fyyrldo6ugu80s.rcgu.o" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e.kt25z0521ngsjub.rcgu.o" "-o" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e" "/Users/me/Developer/pleora-bindgen/target/debug/deps/pleora_bindgen-adc9c9bd4fdd514e.crate.allocator.rcgu.o" "-Wl,-dead_strip" "-nodefaultlibs" "-L" "/Users/me/Developer/pleora-bindgen/target/debug/deps" "-L" "/Users/me/.rustup/toolchains/nightly-x86_64-apple-darwin/lib/rustlib/x86_64-apple-darwin/lib" "/Users/me/.rustup/toolchains/nightly-x86_64-apple-darwin/lib/rustlib/x86_64-apple-darwin/lib/libstd-186ebb02bb898b2e.rlib" "/Users/me/.rustup/toolchains/nightly-x86_64-apple-darwin/lib/rustlib/x86_64-apple-darwin/lib/libpanic_unwind-8f3ff946899e1ced.rlib" "/Users/me/.rustup/toolchains/nightly-x86_64-apple-darwin/lib/rustlib/x86_64-apple-darwin/lib/liballoc_jemalloc-b8d81a19584fbd63.rlib" "/Users/me/.rustup/toolchains/nightly-x86_64-apple-darwin/lib/rustlib/x86_64-apple-darwin/lib/libunwind-59b780b13cfd3c10.rlib" "/Users/me/.rustup/toolchains/nightly-x86_64-apple-darwin/lib/rustlib/x86_64-apple-darwin/lib/liballoc_system-17c73a48aced397c.rlib" "/Users/me/.rustup/toolchains/nightly-x86_64-apple-darwin/lib/rustlib/x86_64-apple-darwin/lib/liblibc-e0e80d4f6cc88586.rlib" "/Users/me/.rustup/toolchains/nightly-x86_64-apple-darwin/lib/rustlib/x86_64-apple-darwin/lib/liballoc-3dfe44468cc2e464.rlib" "/Users/me/.rustup/toolchains/nightly-x86_64-apple-darwin/lib/rustlib/x86_64-apple-darwin/lib/libstd_unicode-ef92149c7f7e05a7.rlib" "/Users/me/.rustup/toolchains/nightly-x86_64-apple-darwin/lib/rustlib/x86_64-apple-darwin/lib/libcore-9bd1f167f57b6988.rlib" "/Users/me/.rustup/toolchains/nightly-x86_64-apple-darwin/lib/rustlib/x86_64-apple-darwin/lib/libcompiler_builtins-5a76b37283373ff2.rlib" "-l" "System" "-l" "resolv" "-l" "pthread" "-l" "c" "-l" "m" &gt; = note: Undefined symbols for architecture x86_64: &gt; "PvString", referenced from: &gt; pleora_bindgen::root::PvString::new2::h9ad47772b38d0a30 in pleora_bindgen-adc9c9bd4fdd514e.fyyrldo6ugu80s.rcgu.o &gt; (maybe you meant: __ZN14pleora_bindgen4root8PvString4new217h9ad47772b38d0a30E, __ZN67_$LT$pleora_bindgen..root..PvString$u20$as$u20$core..fmt..Debug$GT$3fmt17hec8729cf5e1779eaE ) &gt; ld: symbol(s) not found for architecture x86_64 &gt; clang: error: linker command failed with exit code 1 (use -v to see invocation) &gt; &gt; &gt; error: aborting due to previous error &gt; &gt; error: Could not compile `pleora-bindgen`. &gt; &gt; To learn more, run the command again with --verbose. &gt; &gt; &gt; How do I link to the static library correctly? I've never done this before. Any help would be great! 
Use [`BufRead::read_line`](https://doc.rust-lang.org/std/io/trait.BufRead.html#method.read_line). Use [`BufRead::read_until`](https://doc.rust-lang.org/std/io/trait.BufRead.html#method.read_until) to avoid UTF-8 validation.
The first transmute isn't needed at all. The second transmute looks like UB to me, since you aren't checking alignment. Transmute is dangerous. Be careful.
&gt; If you want to re-interpret the bytes of your fields as another type, (e.g. casting a [u8; 4] as an i32) then you will need unsafe (have a look at std::mem::transmute ). You will also need unsafe if your "fields" overlap. `byteorder` does this for you, safely: https://docs.rs/byteorder/1.2.1/byteorder/trait.ByteOrder.html#method.read_i32
It might help to include some of the code you've tried for this. Another thing to look at might be the Cap'n Proto implementation for Rust, since IIRC, this is exactly the sort of the thing it's supposed to do. (I'm not necessarily suggesting using Cap'n Proto, but rather, learning from it.)
So if I understand correctly, this will read 4 bytes from the `&amp;[u8]` and _create a new i32 from them_. If I modify the value returned by read_i32, it won't affect the `[u8]` the `i32` was created from. Ideally I'd like to be able to return an `&amp;mut i32` from something like this.
Aside from the issues burntsushi raised, my main concern with something like this is that there's no obvious way to get at the underlying `[u8]` (for instance if I was going to send this off on the wire somewhere after modifying it). Can I just store the `&amp;mut [u8]` in a field of the struct? I guess that won't trigger the self-borrowing struct problem, will it, since the buffer exists outside the struct somewhere... 
That's a great idea, I'll check out capnproto-rust. For some reason I had the impression it was just wrapping the C library but it seems I was wrong.
I see. The only way to do that safely is to make sure your data is aligned. I'm pretty sure Cap'n Proto is, for example, designed for exactly that kind of thing. But yeah, this will undoubtedly require `unsafe` if you need a mutable pointer of `i32` to a backing `&amp;[u8]` buffer. I'd recommend thinking carefully about it, and seeing if you can define a safe abstraction for it. (e.g., Something that does alignment checks in a way that doesn't impact performance or similar such things. How well that works and how useful it is depends on your use case!)
Thanks! This insight is super helpful. I'll work on it and see how it works.
Ah, I see you're a man of culture as well.
Minor detail: the optimization itself is very old, a stable `NonNull` type is the addition here, there was no way on stable to take a raw pointer and opt into the same optimization we've always done for same references etc.
Might not cover all of your use cases, but I was bored and wanted a little challenge: Cargo.toml: [package] name = "pleora" version = "0.1.0" authors = ["Josh Chase &lt;josh@prevoty.com&gt;"] [dependencies] [build-dependencies] bindgen = "*" build.rs: extern crate bindgen; use bindgen::builder; use std::env; use std::path::Path; static PLEORA_INCLUDE: &amp;'static str = "../include"; static PLEORA_LIB: &amp;'static str = "../lib"; fn main() { // output message println!("launching build script."); // create the output file location let out_dir = env::var("OUT_DIR").unwrap(); let dest_path = Path::new(&amp;out_dir).join("pleora.rs"); // make the bindings let mut bindings = builder() .rustfmt_bindings(true) // .enable_cxx_namespaces() .whitelist_type(r"PvString") .whitelist_type(r"PvResult") .whitelist_type(r"PvDevice") .whitelist_type(r"PvStreamGEV") .whitelist_var(r"PRODUCT_NAME") .clang_arg(r"-xc++") .clang_arg(r"-std=c++14") .clang_arg(format!("-I{}", PLEORA_INCLUDE)) // .trust_clang_mangling(false) .derive_copy(false) .layout_tests(false); for header in &amp;[ "PvVersion.h", "PvTypes.h", "PvString.h", "PvDevice.h", "PvStreamGEV.h", "PvResult.h", ] { bindings = bindings.header(format!("{}/{}", PLEORA_INCLUDE, header)); } let bindings = bindings .generate() .expect("Failed to generate Pleora bindings!"); bindings .write_to_file(&amp;dest_path) .expect(&amp;format!("Coudn't write bindings to {:?}", &amp;dest_path)); println!("cargo:rustc-link-search=native={}", PLEORA_LIB); for lib in &amp;[ "EbTransportLayerLib", "EbUtilsLib", "PtConvertersLib", "PtUtilsLib", "PvAppUtils", "PvBase", "PvBuffer", "PvCameraBridge", "PvDevice", "PvGenICam", "PvGUI", "PvPersistence", "PvSerial", "PvStream", "PvSystem", "PvTransmitter", "PvVirtualDevice", "SimpleImagingLib", ] { println!("cargo:rustc-link-lib=dylib={}", lib); } } lib.rs: mod raw { #![allow(dead_code)] #![allow(non_camel_case_types)] #![allow(non_snake_case)] #![allow(non_upper_case_globals)] include!(concat!(env!("OUT_DIR"), "/pleora.rs")); } pub use raw::*; #[cfg(test)] mod tests { use super::PvString; use std::ffi::{CStr, CString}; #[test] fn it_works() { let c_string = CString::new("Hello, world!").unwrap(); let orig_str = unsafe { let pv_string = PvString::new2(c_string.as_ptr()); let c_str = CStr::from_ptr(pv_string.GetAscii()); c_str.to_string_lossy() }; println!("{}", orig_str); } } 
To enable this style match x { | 0 =&gt; 3, | 1 =&gt; 5, | x if x%2 == 0 =&gt; x/2, | x =&gt; x, } /bait
The Australian "yeah, nah" has a casual tone to it, as in "yeah, I acknowledge what you said, but I disagree because .. ".
This is really helpful. I appreciate it a ton. I had been working in macos. I'm downloading a centos iso at the moment to try it out in virtualbox. I downloaded a few of the ebus distributions for different platforms and noticed that they ship differently. I hadn't realized this before your comment earlier.
Sound like what you want is a syntax plugin, not a color scheme.
So does that mean I can put a bool in an Option and it will still only use 1 byte since they can be packed together?
1 + 2 is 3 1 &amp; 2 are numbers Fair enough, I think I interpreted it as “and”. I guess both are equally correct 
Interesting. Maybe one should discuss this for Cargo as well?
I'm trying to make a lexer/parser as a learning project, and am having trouble getting a sub slice from an iterator. I found this link https://users.rust-lang.org/t/takewhile-iterator-over-chars-to-string-slice/11014/2 But the solution: match ch { '0'...'9' =&gt; { let str = self.it.as_str(); while self.it.clone().next().map_or(false, |ch| ch.is_numeric()) { self.it.next(); } Some(Token::Number(&amp;str[..str.len() - self.it.as_str().len()])) } } Seems so incredibly ugly I feel dirty writing that. Is there a better way to do this? Some way to just get the current index of an iterator or collect a range into a str? 
A few things: * Generally you want to be `unwrap`ing as little as possible. For example here: https://github.com/aleyan/langtonsant/blob/master/src/canvas.rs#L19 you could instead return a `Result&lt;Self&gt; and then use the `?` to automatically forward potential error results to the caller. (Same thing for the various draw methods, that way you can propagate errors up https://github.com/aleyan/langtonsant/blob/master/src/canvas.rs#L104) * Generally people like naming things a bit more verbose, though this is of course partially personal preference (for example here, `real` and `imaginary` https://github.com/aleyan/langtonsant/blob/master/src/canvas.rs#L131) * In these kinds of situations https://github.com/aleyan/langtonsant/blob/master/src/canvas.rs#L20 you should be able to use `x as T` instead of `T::from(x)` (specifically with numbers). Also you could destructure like let (cols, rows) = (size.0 as i32, size.1 as i32 - 1); Overall nice job! Most of these are nits, the error handling part should definitely be the biggest takeaway. 
Base16-tomorrow-night-80s is my vice.
Hello! I'm happy to report it now can do about 1 million lines per second (while streaming live updates to the terminal). Curious to hear if that's fast enough for your use case. 
I wouldn't say its the right thing to do in every case, but its a useful trick especially when its easy with rayon and you have lots of cores. Earlier this week I was writing code to parse about 100GB of data which was line delimited so used unix "split" to partition the file then read/processed each partitioned file in parallel with rayon (parallelize the names of the files and then read/parse data in a map function). It resulted in a nice speed since boost I was on a 12 core system. That being said, 2GB isn't all that much data... While on the topic, I would appreciate any comments on how to improve speed since I am still relatively new to rust coming from python/scala/spark/sql land. https://github.com/EntilZha/wikidata-rust/blob/master/src/main.rs
I've got a 1000 line F# `match` at work which this helps with a lot. Rarely are any of the arms complicated at all but the sheer number of them makes this style really appealing because it keeps it clean and organized. I would find it annoying to do the same thing in rust without the leading vert and it would be messier.
In this specific example you'd just return `&amp;'a X` though, the compiler is able to stretch and squeeze lifetimes anyway so it's usually good to return the longest. The `'a: 'b` becomes important when you either have invariant types, or are dealing with storing a reference to a struct that already has a lifetime.
Wow, did you write an entire tutorial inside module comments? It's amazing yet scary.
Just use a pre-made tool :) https://github.com/BurntSushi/xsv
yes you put a full stop at the end of your sentence,
yup https://play.rust-lang.org/?gist=7b1558ec812cc2b41e6a34c1465039a7&amp;version=stable
Using the word for "yes" (or a descendant of it) in a pure adverbial sense to mean something like obviously, of course, as you know, etc. (the meaning can be quite nuanced in the languages that use it that way, so an exact translation to English is a bit difficult) is actually very common in Norwegian (jo), Danish (jo), Swedish (ju), and German (ja). There are probably some others I missed as well. I'm not a native speaker of any, however I have been learning Norwegian for some years and this way of using the word can be quite difficult and strange to wrap your head around :p
People deserve a choice. I'm a tabs user and Rust still allows tabs even though most others use spaces.
5.5s on a Core i7-3740QM extern crate itertools; #[macro_use] extern crate quicli; use itertools::Itertools; use std::collections::HashMap; use std::fs::{File, OpenOptions}; use std::io::{BufRead, BufReader, BufWriter, Write}; use std::path::PathBuf; use quicli::prelude::*; // Add cool slogan for your app here, e.g.: /// Get first n lines of a file #[derive(Debug, StructOpt)] struct Cli { #[structopt(parse(from_os_str))] filepath: PathBuf, #[structopt(long = "verbose", short = "v", parse(from_occurrences))] verbosity: u8, } main!(|args: Cli, log_level: verbosity| { let mut output_path = r#"C:\outRust\xxxx.txt"#.to_string(); let lines = BufReader::new(File::open(args.filepath)?) .lines() .skip(1); let mut streams = HashMap::new(); for line in lines { let l = line?; if l.is_empty() || l.chars().tuple_windows().any(|(a,b)| a == 'R' &amp;&amp; (b == 'H' || b == 'T')) { continue; } let symbol = &amp;l[11..15]; let symbol_bytes = unsafe { *std::mem::transmute::&lt;*const u8, *const [u8; 4]&gt;(l.as_bytes().as_ptr())}; unsafe { (&amp;mut output_path)[11..15].as_bytes_mut() } .copy_from_slice(symbol.as_bytes()); writeln!(streams.entry(symbol_bytes).or_insert_with(||OpenOptions::new() .write(true) .append(true) .create(true) .open(&amp;output_path).map(BufWriter::new).unwrap()), "{}", &amp;l)?; } }); $ RUSTFLAGS="-C target-cpu=native" cargo build --release $ /usr/bin/time -v target/release/quick ../maker/sample.txt Command being timed: "target/release/quick ../maker/sample.txt" User time (seconds): 5.46 System time (seconds): 1.70 Percent of CPU this job got: 98% Elapsed (wall clock) time (h:mm:ss or m:ss): 0:07.25 Average shared text size (kbytes): 0 Average unshared data size (kbytes): 0 Average stack size (kbytes): 0 Average total size (kbytes): 0 Maximum resident set size (kbytes): 2780 Average resident set size (kbytes): 0 Major (requiring I/O) page faults: 0 Minor (reclaiming a frame) page faults: 149 Voluntary context switches: 27 Involuntary context switches: 140 Swaps: 0 File system inputs: 0 File system outputs: 3927256 Socket messages sent: 0 Socket messages received: 0 Signals delivered: 0 Page size (bytes): 4096 Input generated with: use std::io::Write; const LINES: &amp;[&amp;str] = &amp;[ "2018-03-26;DI1V18 ;1;000007651829344;000000000104395;001;08:56:09.077000;0000258912; 000000000006.225000;000000000000000300;000000000000000000;2018-03-26;2018-03-26 08:56:09;0;0;00000074", "2018-03-26;DI1V18 ;1;000007651829344;000000000125979;004;09:03:53.055000;0000258912; 000000000006.225000;000000000000000300;000000000000000300;2018-03-26;2018-03-26 09:03:53;2;2;00000074", ]; fn main() { let desired_line_count = 2000000000usize / LINES.iter().map(|l|l.len()).sum::&lt;usize&gt;(); let mut f = std::io::BufWriter::new(std::fs::File::create("sample.txt").unwrap()); for _ in 0..desired_line_count { for line in LINES { writeln!(f, "{}", line).unwrap(); } } } 
Wouldn't the compiler itself understand the clobbering of each intrinsic?
Wouldn't the compiler itself understand the clobbering of each intrinsic?
Wouldn't the compiler itself understand the clobbering of each intrinsic? 
Wouldn't the compiler itself understand the clobbering of each intrinsic? 
Wouldn't the compiler itself understand the clobbering of each intrinsic? 
You should post this on internals.
You are partially right but most of your post is arrogance - at least as much as in this article. First of all, I have no idea why you say '99%' referring to network usage. I do lots of data processing at work that is not using networking. Typically when I need some network communication, I try to send only finite and small number of requests at the beginning or use file cache. Big data systems overhead - this is obviously true, your program using any big data system or cloud or whatever gets always more complicated comparing to plain serial processing. But well, I must agree that "lot of" is unfortunate. Running same computation on your laptop - again, the keyword "in many cases" is a major problem here (same as yours '99%'). For me it is true, because my processing is highly dependent upon disk speed and disks in clouds are either slow or very expensive. Nice cloud setup costs much, much, much more than a set of PCs with same processing power. However, cloud has its own benefits that may or may not be more important, it depends on the use case. 
That will be written as `#[repr(packed(n))]` once bitshifter's PR gets merged. It is "finished" but tests are failing in one 32-bit system.
Shaved it down to 6 seconds by assuming ASCII in the filtering: if l.is_empty() || l.as_bytes().iter().tuple_windows().any(|(a,b)| *a == b'R' &amp;&amp; (*b == b'H' || *b == b'T')) {
Good point; I was thinking of range errors but it's a type one here.
&gt; You are talking about micro optimizations and as you mentioned yourself No, I am not. Micro-optimizations are about shaving off 1% or so, and I explicitly said *"not down to the last cycles"*. I am talking about order of magnitude gains. Any optimization that gives you an easy 2-fold performance improvement or better should not be shrugged off. If you find yourself reaching for assembly or increasing code size by x10, then pause and ponder whether it's worth it.
Presumably, you're using `.chars()` on the string to get an iterator. You can use `.char_indices()` instead, which gives you the byte offset of each `char`.
When I read about Go cooperative preemption mechanism, the fact that loops were not instrumented was a huge red flag. I understand the *difficulties* in retaining performance (and I am not sure what's the best way to do it), but as the article points out, without instrumenting loops you can completely starve an executor and get into live-lock situations.
Thank you for letting us know. I think it will be useful.
I nowhere said that I'm against an easy optimization especially if it can give you x2. I disagreed that parallel data processing is "Nope. Not. Ever." because that is simple not true. When you optimized everything you could you hit a brick wall. You simply cannot process it faster at some point. What do you do next? 
Pretty much, yup! I think I [wrote it as a blog post first](https://blog.burntsushi.net/csv/), but I had always intended to have it also be in the API docs too, since I think that makes it more discoverable. There's not much difference from my perspective between writing it as a doc comment and as a blog post. The latter does provide a chance at syntax highlighting, but every Markdown syntax highlighter I've tried (in vim) breaks in very annoying ways anyway.
Mhm, I’m not sure with your third point. I wouldn’t encourage the use of `as`. I personally use `x.into()` for infallible and `x.try_into().unwrap()` for potentially fallible casts that are expected to never fail. But that’s a part of the Rust language that still needs some work IMHO. I’d like the language to panicking by default on overflows and truncating casts, even in release mode. 
What do you typically use for event sourcing?
&gt; I disagreed that parallel data processing is "Nope. Not. Ever." because that is simple not true. I'm pretty sure /u/matthieum objected to your suggestion that parallelization is the standard _first step_; and that /u/matthieum did not argue that parallelization is never an option _at all_. I agree with that statement. To explain my reasoning I'll start from a comment you made in another subthread here: You claim that it's a "bs statement" to say that big data systems scale well, but have a large inherent overhead. This does not agree with my experience. When have e.g., three machines on which Spark/Zookeeper/Kafka/ZeroMQ/... were deployed ever been more than twice as fast as one of those machines running the same pipeline hard-coded in a single program (i.e., when has distributing ever had an overhead of less than +50%) for a realistic application? Out-of-process communication — especially multi-node — always has an overhead. That is acceptable for Big Data, but only because the single-machine-based solution _cannot_ work then. This also answers your straw-man attack that "So basically in your mind everyone who uses Spark, Flink, Map-reduce, including big companies - are idiots". No, they are not idiots, if (and only if) the load they have to handle is (or is soon expected to be) too large for a single machine. Hiring another sysadmin forever costs more than having your programmers look at the code another hour. The startup-cost of training your programmers to build distributed solutions isn't negligible either, even if the frameworks are easy to use once set up. As a side note, note that when you accused Frank of displaying "so much arrogance to[...] even [remain] funny", you seem to have missed that the text was written from the perspective of the creators of [the distributed data processing system Naiad, by Microsoft Research](https://www.microsoft.com/en-us/research/project/naiad/), and that Frank, Michael, and Derek are not just vacuously attacking the concept of distributed Big Data processing, but are instead pointing out the limitations of the existing work (including their own). ^(This remark is not meant as argument-by-authority, but merely to point out that you may have misjudged what you saw. They're not some-random-idiot-saying-something-that-disagrees-with-your-experience, which would probably have been wrong about it, but they are instead very well informed on the topic, and may very well be referring to things beyond what you have experienced.)
Sadly Rust isn't Erlang, and thus the end of a Rust sentence is spelled }.
4.9s on a Core i7-3740QM. Requires 2GB+ of free memory. extern crate itertools; #[macro_use] extern crate quicli; use itertools::Itertools; use std::collections::HashMap; use std::fs::{File, OpenOptions}; use std::io::{BufRead, BufReader, BufWriter, Read, Write}; use std::path::PathBuf; use quicli::prelude::*; const NEWLINE: &amp;[u8] = b"\r\n"; const SYMBOL_SIZE_BYTES: usize = 4; const OUTPUT_PATH_SYMBOL_BEGIN: usize = 11; const OUTPUT_PATH_SYMBOL_END: usize = OUTPUT_PATH_SYMBOL_BEGIN + SYMBOL_SIZE_BYTES; const LINE_SYMBOL_BEGIN: usize = 11; const LINE_SYMBOL_END: usize = LINE_SYMBOL_BEGIN + SYMBOL_SIZE_BYTES; // Add cool slogan for your app here, e.g.: /// Get first n lines of a file #[derive(Debug, StructOpt)] struct Cli { #[structopt(parse(from_os_str))] filepath: PathBuf, #[structopt(long = "verbose", short = "v", parse(from_occurrences))] verbosity: u8, } main!(|args: Cli, log_level: verbosity| { let mut contents = String::with_capacity(args.filepath.metadata()?.len() as usize); BufReader::new(File::open(args.filepath)?).read_to_string(&amp;mut contents)?; let lines = contents .lines() .skip(1) .collect::&lt;Vec&lt;&amp;str&gt;&gt;() .into_par_iter() .filter_map(|l|{ if l.is_empty() || l.as_bytes().iter().tuple_windows().any(|(a,b)| *a == b'R' &amp;&amp; (*b == b'H' || *b == b'T')) { None } else { Some((&amp;l.as_bytes()[LINE_SYMBOL_BEGIN..LINE_SYMBOL_END], l)) } }) .collect::&lt;Vec&lt;_&gt;&gt;(); let mut output_path = r#"C:\outRust\xxxx.txt"#.to_string(); let mut streams = HashMap::new(); for (symbol_bytes, l) in lines { unsafe { output_path[OUTPUT_PATH_SYMBOL_BEGIN..OUTPUT_PATH_SYMBOL_END].as_bytes_mut() } .copy_from_slice(&amp;symbol_bytes); let f = streams.entry(symbol_bytes).or_insert_with(||BufWriter::new(OpenOptions::new() .write(true) .append(true) .create(true) .open(&amp;output_path).unwrap())); f.write_all(l.as_bytes())?; f.write_all(NEWLINE)?; } }); Timing stats: Command being timed: "target/release/quick ../maker/sample.txt" User time (seconds): 5.33 System time (seconds): 2.90 Percent of CPU this job got: 167% Elapsed (wall clock) time (h:mm:ss or m:ss): 0:04.93 Average shared text size (kbytes): 0 Average unshared data size (kbytes): 0 Average stack size (kbytes): 0 Average total size (kbytes): 0 Maximum resident set size (kbytes): 4063536 Average resident set size (kbytes): 0 Major (requiring I/O) page faults: 0 Minor (reclaiming a frame) page faults: 1279677 Voluntary context switches: 1522 Involuntary context switches: 345 Swaps: 0 File system inputs: 0 File system outputs: 3948256 Socket messages sent: 0 Socket messages received: 0 Signals delivered: 0 Page size (bytes): 4096 Exit status: 0 
&gt; `'x: 'y` notation doesn't imply that `'x` will outlive `'y`, just that it lives at least as long. Indeed, that's what I meant but I often forget that English doesn't works the same way French does : in French, especially in Maths, «more» means «equal of more» and we use «strictly more» when we want an exclusive superiority. With this mindset, when using «outlive» I meant «live equally or longer» which is not what it means in English. And your example is wrong, because here you can use only one lifetime [just fine](https://play.rust-lang.org/?gist=918316c1d553787286e88bf7a7d29922&amp;version=stable). That's a good illustration of my question though ;).
&gt; you either have invariant types Can you tell me more about that ?
&gt; You claim that it's a "bs statement" to say that big data systems scale well, but have a large inherent overhead Big-data systems have overhead, that's obvious. But if you go back to Frank's quote: "Big data systems may scale well, but this can often be just because they introduce a lot of overhead." - it has different meaning, essentially he's saying that just because my system has big overhead it may scale well, lol. I understand that he most likely didn't mean that. But I will peak on wording if it is a public article. 
I have a borrow checker problem, anyone want to take a look? https://play.rust-lang.org/?gist=189c94cda706951638b7717392692ffb&amp;version=stable
Glad to hear it! :D
In c++ you would use vector&lt;shared_ptr&lt;BaseClass&gt;&gt;, which is similar to Vec&lt;Rc&lt;Trait&gt;&gt; or Vec&lt;Box&lt;Trait&gt;&gt;. In rust interfaces (or abstract base classes) can be done using trait objects, and have no hierarchies. The second edition of rust book has an excellent chapter on OO that teaches this.
Another good article on a similar topic here: https://hoverbear.org/2016/10/12/rust-state-machine-pattern/. Personally I've become wary of enums because of massive, unwieldy match statements that tend to crop up. 
Why does `BufRead::lines` need to allocate in the first place? Doesn't it just provide string slices referencing the underlying buffer?
S T R E A M I N G I T E R A T O R S
So `BufRead::read_line` still needs to copy the whole line, it just doesn't have to allocate memory for it? Maybe I'm misunderstanding something, but that seems like unnecessary work when you just want to look at each line once, then proceed to the next line etc.
Parallelization is pretty much never useful in a case like this because the bottleneck (his disk) is inherently "single threaded." That is, assuming he's not got anything pathological in his code, this program is going to work at the speed of his disk no matter what.
Other preemption points (in addition to function calls) are channel operations, I/O, and memory allocation. Pure CPU-bound loops could starve and cause issues with the collection, but luckily those tended to be edge cases rather than the norm. And of course that's exactly more or less what we're trying to solve here. David Chase did try instrumenting back loops (I believe the bug is listed in the proposal) but wasn't happy with the results. Fascinating reading though.
I'm confused about this, too. As per the [Stackoverflow answer](https://stackoverflow.com/a/35820003/416626), `lines()`is the best way to get a `Vec&lt;String&gt;` from a `BufReader`. Does using `read_line` lead to fewer allocations, and if so, could you provide a minimal example?
Maybe you could query uniform locations at shader compile time instead of when they are accessed? I know that glium does something similar. Here is a stack overflow link that should point you in the right direction: [https://stackoverflow.com/questions/440144/in-opengl-is-there-a-way-to-get-a-list-of-all-uniforms-attribs-used-by-a-shade](https://stackoverflow.com/questions/440144/in-opengl-is-there-a-way-to-get-a-list-of-all-uniforms-attribs-used-by-a-shade). That could also let you remove that nasty RefCell. set_uniform() should return something like Result&lt;(), UniformNotFound&gt; instead of just quietly ignoring everything. Other than that, the code looks really good!
&gt; So BufRead::read_line still needs to copy the whole line, it just doesn't have to allocate memory for it? Yes. &gt; Maybe I'm misunderstanding something, but that seems like unnecessary work when you just want to look at each line once, then proceed to the next line etc. Consider the lifetimes involved, what would you return from such a read_line given any call may require the buffered reader to overwrite its internal buffer and invalidate all previous lines?
&gt; Does using read_line lead to fewer allocations Yes. &gt; and if so, could you provide a minimal example? let mut buf = String::new(); loop { match b.read_line(&amp;mut buf) { Err(_) | Ok(0) =&gt; break, Ok(_) =&gt; { print!("{}", buf); buf.clear(); } } }
I spend way too much time on this. 
woah, that is BRIGHT! Personally any scheme that underlines things is out for me, also if the line highlight color is too stark of a contrast. But glad I checked this one out, to see it at least. 
I guess it would be easy enough with an internal iterator, but I'm not quite sure how you'd do it with an internal iterator.
`lines` is the most *convenient* way to get all of the lines out of a `BufReader`. It is most certainly not the fastest. Calling it the "best" I think is, respectfully, a bit of unwarranted editorialism on your part. The only way something can be the "best" is if you define your requirements. If your requirement doesn't include performance, or is a case where a few seconds on small-GBs of data doesn't matter, then sure, `lines()` is indeed perhaps *the best* way to iterate over lines. It's simple, easy and basically impossible to mess up. If your requirements change, then "the best" may no longer be true. For example, if your CLI tool is taking 5 seconds, and that's slightly annoying, then maybe shaving off a few seconds is worth it. Your next "best" bet there might indeed to be to use `read_line` or perhaps even `read_until`. Is this the fastest possible thing you can do? Nope. As /u/Sapiogram mentioned, it is indeed doing an extra copy. But there's already a few copies going on, assuming you're using the standard `read` syscall (which `io::BufReader(File::open(...).unwrap())` will use on Unix): * Some low number of copies in kernel space. I dunno how many. * In user space, `read` is copying the bytes into your provided buffer. In `io::BufReader`'s case, it's some internal buffer probably on the order of multiple KBs in size, which amortizes calls to `read` directly. (Because syscalls are their own expense.) * When you call `read_line` with a mutable string, then the buffer needs to copy contents from its internal buffer into the string provided. We call this *amortizing allocation* because most calls probably won't cause an allocation, since it will reuse space allocated during previous calls. This rests on some assumptions, for example, that lines are all generally around the same length, or at least, that long outlier lines are rare. The end result of this is that for each line you read, on average, you pay 0 syscalls and 0 allocations. That's nice. You do still indeed need to pay for the copy, which means this isn't the fastest possible way to read lines. Getting rid of that copy requires a commensurate jump in code complexity if you're still using `read` calls, because you need to handle the case where the end of your buffer contains an incomplete line. There exists some crates for this, and it's not crazy hard to do or anything, but certainly much more overhead than `BufReader`'s `read_line` method. With all that said, you could cheat and not use `read` and simply use a memory map instead. For huge files, I've found that this is indeed worth it. But you will need to deal with `&amp;[u8]` directly instead of a `&amp;str`, which has its own challenges depending on what you're doing. :-)
My feeling is that if you really want preemption you should probably just be using 1:1 threads. The kernel is better equipped to do this than userspace. One of the things I really like about Rust is that it gives you the choice between 1:1 and M:N to fit your needs (the latter being the async I/O story).
Hah. Weird though, I don't see any underlines for me. I wouldn't like underlines either. :-) I appear to have a local copy of `summerfruit256.vim`, and it is very possible that I have tweaked it.
&gt; See https://docs.rs/fst/0.3.0/fst/trait.Streamer.html and https://docs.rs/streaming-iterator/0.1.3/streaming_iterator/trait.StreamingIterator.html I see. I'm still crap at *leveraging* lifetimes for constraints, that's a smart approach.
Thanks, did as instructed: https://internals.rust-lang.org/t/regarding-type-inference-of-numeric-types-with-closures/7185
Just for future ppl encountering same issues or this post: /u/aidanhs PR is likely to be merged in the near future and he did a very good summary why the current placement feature needs to be removed and what design goals would be benefitial for placement to implement (to be a competitor to C++s placement-new at least) PR can be found at: https://github.com/rust-lang/rust/pull/48333
When looking for an error to serve as an example I just remembered the last one I had with a project I was working on recently, retraced my steps, made the error happen again and took the screenshot. I haven't put much thought into it really, given as it's just supposed to show how the compiler errors look like. So in this particular case, the hint was right - adding the reference did solve the problem :) I'll look into it later though and maybe find an error that people who had no contact with Rust will be more familiar with.
https://www.youtube.com/watch?v=MtaUHMWQpiI
Kernel threads don't scale. Even if Linux is better at that than other OS there's still a penalty to pay wrt userspace task switching.
Here's a podcast that was just published today about event sourcing for anyone else interested in learning about the basics: * [Full Stack Radio Ep. 85 - Frank de Jonge - Event Sourcing for Beginners](http://www.fullstackradio.com/85)
Thanks for sharing, interesting stuff. Where can I learn more about stack and register maps? In the proposed scheme, how does the Go runtime (GC or some other module?) interrupt a running Go OS thread? Via some kind of OS signal? and then I guess the interrupted thread runs a signal handler which synchronizes with the interrupting thread? I'm not familiar with Go's RTS so sorry if I'm talking nonsense.
Erlang's system is similar to the "put preemption points in loops" proposal.
I concede that "best" was not the…best choice here. Thanks for the thorough explanation!
You're looking for /r/playrust
https://reddit.com/r/playrust
Did you read the article (and the paper)? They literally show that some of these "scalable" algorithm *never* beat a single threaded implementation, and for most of them they need dozens or hundreds of cores to be competitive. You dismiss this as bullshit and arrogance, but it's actual benchmarks and data (the paper has even more). Do you have any reasoning of your own, or just assertions and dogma? &gt; So basically in your mind everyone who uses Spark, Flink, Map-reduce, including big companies - are idiots No. I work at google. We do have genuinely Big Data here. It makes sense for *us* to use some of these big algorithms. But 99.99% of people do *not* have the kinds of scale that we do, and taking on a 10-100x scale and performance hit up front in order to use complicated frameworks when a simple single-threaded implementation would be faster is a bad idea. If you intend to throw 1000 cores at it, then yeah you'll still go faster despite the up front overhead, but again *most* people don't do that. For *most* people running it on a single machine (and even a single thread) with sensible performance choices is faster, easier to develop and maintain, and needs fewer dependencies (=risk).
Hmm I guess I'm a little confused why you're trying to write your own allocation system for this purpose... what's the need here? Why not just use Rust-native ways to allocate safely?
Thank you
Thank
Thanks
In Dutch ja isn't really used like that. That's the problem with using it in Dutch. In Gronings ja often means "after all". " after all I haven't done that" would be the translation.
The main problem is this: `parts` (and subsequently `dep` and `dep_feat_opt`) don't have lifetime `'a`, but only the lifetime of a current function. That happens because `Deref` can only give you an `str` reference with lifetime of that `Cow` variable itself, not `'a`. It's not even possible to make a string of lifetime `'a` - if `Cow` is an owned string, there's no guarantee that it will live for lifetime `'a`. So, there's how to fix stuff: 1. Remove `'a` from `Fn(&amp;'a str) -&gt; bool` - I'm pretty sure that `is_feature` does not care about how long the given string will live for. With lifetime elision rules for trait bounds, this will result in `for&lt;'b&gt; Fn(&amp;'b str) -&gt; bool`, which is much easier to work with. 2. Replace match feature { Cow::Owned(_) =&gt; FeatureValue::CrateFeature( Cow::Owned(dep.into()), Cow::Owned(dep_feat.into()), ), Cow::Borrowed(_) =&gt; FeatureValue::CrateFeature( Cow::Borrowed(dep), Cow::Borrowed(dep_feat), ), } with FeatureValue::CrateFeature( Cow::Owned(dep.into()), Cow::Owned(dep_feat.into()), ) As I said, `dep` and `dep_feat` don't have lifetime `'a`, so you can't get away with only borrowing them in the second `match` branch. 3. Resolve all the lexical lifetime issues - `parts` borrows `feature`, and subsequently you want to move `feature` into `FeatureValue` to construct the function result. If you are using nightly, you can try to get away with `#![feature(nll)]`, if not - you can hack around the lexical borrows with [something like this](https://play.rust-lang.org/?gist=fb1bf50814b6c0fa30773346b5912ed9&amp;version=stable).
Is this publicly available?
Hey, game engines often have the purpose to control the areas objects are allocated in in a more granular way than just calling malloc. For example stack allocator for ensuring objects are deallocates in a LIFO fashion or to wrap allocations with additional functionality as tracking them. Another purpose would be to provide the memory area an allocator works upon - for example allocating buffers/objects in GPU memory or on the stack (via something just as alloca in C++)
If you want to manage a slice of bytes yourself, check out [`std::slice::split_at_mut()`](https://doc.rust-lang.org/std/primitive.slice.html#method.split_at_mut) which is the primitive for slicing a block of memory into smaller chunks. Note that you will need to be careful with alignment if you try to cast these byte slices directly to other structures. If you're open to looking at existing examples, I recommend the [typed_arena crate](https://crates.io/crates/typed-arena) which is a slab-based allocator similar to what you've described above. Finally, note that rust has some support already for this use case via [custom allocators](https://doc.rust-lang.org/1.16.0/book/custom-allocators.html) which allows you to replace the system's heap allocator.
thanks a lot, I'll definitely check that out because i disliked the RefCell as well but i didnt want the function to take self as mutable either 
Maybe [packed_struct](https://crates.io/crates/packed_struct) does what you want? Otherwise, [smoltcp](https://github.com/m-labs/smoltcp/) manipulated buffers safely using accessors. See the [ipv4 module](https://github.com/m-labs/smoltcp/blob/master/src/wire/ipv4.rs#L227-L541) for instance. To hand out mutable chunks, they just provide a `XXX_mut()` method that returns a mutable slice (see the [payload_mut() method](https://github.com/m-labs/smoltcp/blob/master/src/wire/ipv4.rs#L530)). The author also [blogged about the design](https://lab.whitequark.org/notes/2016-12-13/abstracting-over-mutability-in-rust/). 
&gt; Other preemption points (in addition to function calls) are channel operations, I/O, and memory allocation. Pure CPU-bound loops could starve and cause issues with the collection, but luckily those tended to be edge cases rather than the norm Agreed, though of course like all 0.001% events in software, it will show up :) &gt; David Chase did try instrumenting back loops (I believe the bug is listed in the proposal) but wasn't happy with the results. Fascinating reading though. Definitely fascinating! I've been thinking about cooperative preemption in coroutines/fibers, so I'm definitely interested in how Go manages to tackle the challenge.
&gt; I'm pretty sure /u/matthieum objected to your suggestion that parallelization is the standard *first step* Indeed, that is exactly what I was objecting to. I'm perfectly fine parallelizing workloads, and indeed I've been doing that for most of my professional life. However it's usually cheaper, both in resources, development costs and operational costs, to first optimize serial performance from my experience. At some point, when there's no obvious way to optimize serial performance, then parallel processing becomes cheaper; but this only happens for some workloads. 
It's a thesis project. He has to do it himself for that piece of paper. 
Yeah its a bug I haven't been able to work out yet. I think its due to the orthographic rendering and the AO method I'm using was designed for a perspective view but i'm not sure, this isn't my strong point.
I like Erlang system, as it's elegant and covers *every* operation. However I have some doubt with regards to its efficiency. Go is attempting to avoid slow-down in hot loops, and any kind of check is going to imply some degree of slow-down (register pressure, instructions, branch, etc...). I am looking forward to what solution they come up with.
Neat! I particular like the fact that it is possible to include into `Monster` *another* intrusive node for an intrusive collection coming from a completely different crate. In case, you know, I want an ordered list of them :)
Nitpick: why `wkly` and `mthly` when `weekly` and `monthly` are just two more characters? I'd understand using `w`, `m` and `y` for shortcuts, as it'd save typing, but those near-full words seem awkward.
I feel like we need more trippy non-euclidean 3-D (4-D?) games. Ones that play with your sense of proportion, distance, that renders your mental map inadequate.
Thank you for sharing my project! This is the first project of this kind I made, my goal is to ultimately build a real-time GPU renderer that I can build a puzzle game with, sort of inspired by the excellent anti-chamber. Writing this naive CPU ray tracer provided me with some experience, but is far from what I'm trying to achieve. In my free time, I've done some research and found out focusing my efforts toward learning geometric algebra is going to be essential. So my next goal in this regard is making a geometric algebra library and then find a way to port it to the GPU.
Thank you! 1) I got rid of all but one unwraps (it is on the last line of `main()`). A few methods that used to not return anything now return `Ok(())`. Is this common/acceptable? 2) Agree, I prefer full words as well. However in this case I went with the identifiers that `num-complex` crate uses inside of `Complex`. 3) Clippy recommended `T::from(x)` because of additional run-time safety checks. 4) `let (cols, rows) = (size.0 as i32, size.1 as i32 - 1);` Done! Thank you so much.
Very much agreed, I recommend checking out [noeuclid](https://github.com/cnlohr/noeuclid) and [Anti-Chamber](http://www.antichamber-game.com/). I am also waiting for the release of [Manifold Garden](http://manifold.garden/). There's also [this](https://www.youtube.com/watch?v=ztsi0CLxmjw) great proof of concept of rendering H³ and H²×E spaces, really impressive.
You don't "just learn rust." That is a silly title.
We share the same interests (geometric algebra on the GPU). Hit me up on email, it's &lt;my-user-name&gt;@gmail.com. 
A main function is only necessary if you are writing an application, because that's where your program starts when you execute it. rayon is a library, you don't execute it, so it doesn't need one. 
It has to do with how and when things are inferred. In your first example we deduce the type of the closure when the closure is generated. The closure's output is not bound by the `as` part, but by the `Box::new` function that doesn't put any limits on it. Since it doesn't define what the output can be, the compiler chooses a reasonable default. The `as` happens later as a cast, I wish it wasn't used the way it is because I feel it's confusing. It should stop being an explicit cast and instead be a constraint upon the output type (so for example `1_i32 as u32` wouldn't work, which sets expectations that align with the above example). In your second example you explicitly set the output type in the function parameters, you don't cast between them, but instead simply enforce the type from the beginning. This means that the type infer-er knows that `requires_u32` **must** take a `Box&lt;Fn() -&gt; u32&gt;` so that's what `box_fn` **must** output, so `R` in `box_fn` **must** (and *can*) be `u32`, so `|| 1` **must** return a `u32` so `1` **must** (and *can*) be a u32. There is no, guess the type and *then*, after guessing, try to convert it to this other type. Notice that you can fix it like this: Box::new(|| 1_u32) as Box&lt;Fn() -&gt; u32&gt; The expression `1_u32` explicitly defines the return type. But maybe not here. You can also define the type before-hand: let b: Box&lt;Fn()-&gt;u32&gt; = Box::new(|| 1); And it also can work (basically this is what your second example does at one point or another).
I've taken a different approach in my library https://github.com/oussama/glee-rs/blob/master/src/core/uniform.rs used generics and trait to achieve function overloading. so it results in static dispatch without the state machine overhead.
I think maybe "just began learning rust" is more appropriate. There's a lot to learn, and it's changing, and you can even learn enough to help improve it.
Or alternatively "just learned how to use rust" might be sufficiently succinct to not annoy your parent poster here. :)
this is also a nice way of doing achieving the desired result, I didn't think of implementing the function calls in the trait directly. Thanks for sharing!
&gt; Is this common or acceptable Yes, I would say Result&lt;(), Err&gt; is a common pattern
I haven't looked if those are subcommands or not, but the OP could use [`clap::AppSettings::InferSubcommands`](https://docs.rs/clap/2.31.2/clap/enum.AppSettings.html#variant.InferSubcommands) to implement the shorcuts with a single line of code ;)
Oh great. This really beats async await, cause who needs that?
Cool, this solves literally the only use case I have for async. The API looks great.
neat project~ ...but I'm not sure rendering higher dimensional objects is what 'non euclidian' means. Non eculidian geometry is like the surface of a sphere, where for example, 3 90 degree turns (rather than 4 in euclidian geometry; ie a flat plan) return you to your origin point. I'm puzzling as to if the idea of a non eculidian renderer would actually be meaningful. I suppose you'd have to distort the rays of the raycaster to follow the geometry? It'd be super weird.
Ah, sorry. I should have specified. Each "slot" can hold an arbitrary number of timeouts. The slot represents a time period. It is a head pointer in a linked list of timeouts for that time period.
Ah thanks, that makes more sense. Is the timer basically just a thread that keeps popping the closest timeouts and sleeps when there's no incoming timeout?
What's your use case?
The timer doesn't require a dedicated thread anymore. It is integrated into the threadpool worker threads. But yes, the logic is basically what you described.
\&gt; ...but I'm not sure rendering higher dimensional objects is what 'non euclidian' means. Good thing the readme has both examples of non euclidian space and higher dimensional rendering then!
mm... ok. well um... Its not about the number of dimensions, but maybe I've misunderstood what this engine does. http://tume-maailm.pri.ee/ylikool/ComputerGraphicsSeminar/2016/fall/other/Non-Euclidean%2520Geometry%2520Rendering%2520-%2520Diana%2520Algma.pdf Has some great examples. It's about whether the space is *curved* or not. ie. whether the rays are cast in straight lines or curves? ...I mean, I could be completely wrong here, but I'm pretty sure what you're talking about and eclidian geometry aren't the same thing.
Hey, thanks for the suggestion but the allocator body is mutating the internal parts of the allocator such as bumping pointers used for book keeping and similar cases - to taking a mutable reference is mandatory
Hey, thanks for the suggestions and references. The typed arena crate is something I already looked and and also got some inspiration for another allocator policy, the pool allocator where each allocation/chunk is the same size. For rusts custom allocators I have to say that the limitation of having only one per artifact (that replaceds the default system allocator or jemalloc) is disqualifying it for the use case I got - but it's nice for wrapping dynamic allocs with book-keeping infos or using a different application wide allocator :)
'make network request or time out' 'perform network request periodically' In particular, for SQS I need a background task that periodically updates the visibility timeout for the message. I've been using OS threads for this, but it shouldn't be necessary.
Link 404's for me but in rendering "non\-Euclidean" means it simply does not follow Euclidean rules rather than it's another of the "traditional" metric geometries \(hyperbolic/spherical\).
&gt; ... It had a granularity of 100 milliseconds, so any timeout set with a resolution of less than 100 milliseconds would get rounded up... The timer has been rewritten... Slots in the lowest level represent one millisecond. Great timing, just got an input device server running and this would have been a hard bump in progress. I haven't dived into Mio/Tokio
In this case, there is no other option than to use internal mutability: mutating a data structure through an immutable reference.
I actually hadn't looked for any other personal finance tools; I figured the intersection of {set of people who manage their finances} and {set of people who would do it via a CLI} would basically just be me :P. The in-memory storage is a `HashMap`, which is stored on disk as JSON; will add this to the README.
If each thread gets its own timer, does that mean that the future that is scheduled to resume at that timer can only be executed on the thread which holds that particular timer?
[removed]
&gt; all timer operations (creating a timeout, canceling a timeout, firing a timeout) are constant If I understand correctly (and this threw me first time so I wouldn't bet on it), firing a timer might require moving an arbitrary number of timeouts from one level to the next. It's amortized constant, but not strictly constant.
Nice experience report! What was your resolution to sort ordering?
https://github.com/rcoh/angle-grinder/blob/master/src/data.rs#L129-L148 I needed to be able to sort a list of records by a set of their columns so I ended up writing runtime-generated comparator: ``` pub fn ordering&lt;'a&gt;(columns: Vec&lt;String&gt;) -&gt; Box&lt;Fn(&amp;VMap, &amp;VMap) -&gt; Ordering + 'a&gt; { Box::new(move |rec_l: &amp;VMap, rec_r: &amp;VMap| { for col in &amp;columns { let l_val = rec_l.get(col); let r_val = rec_r.get(col); if l_val != r_val { if l_val == None { return Ordering::Less; } if r_val == None { return Ordering::Greater; } let l_val = l_val.unwrap(); let r_val = r_val.unwrap(); return l_val.partial_cmp(r_val).unwrap_or(Ordering::Less); } } Ordering::Equal }) } ```
My point is that if you have a spacial distortion, like a black hole, or a portal, you're *still visualizing Euclidean space*. Here is a details academic paper on what some real visualizations would look like: http://elevr.com/portfolio/hyperbolic-vr/ (Notice that they're super weird looking! Nothing at all like antichamber) &gt; for me but in rendering "non-Euclidean" means... Well. *shrug* &gt; “The good thing about science is that it's true whether or not you believe in it.” ― Neil deGrasse Tyson 
If you have a spare hour this cppcon talk gives a good explanation of why this is important https://www.youtube.com/watch?v=nZNd5FjSquk
I like Hacker news monthly job posting. It is not rust specific but it should be pretty easy to search.
heads up, the `*.tumblr.com` cert seems to be what I'm seeing still.
Each operation on a timeout does, in fact, have a strictly constant complexity. Inserting, removing, and firing a single timeout has constant complexity. Informally, Amortized constant complexity would be if any of those single operations have a worst case to do a single operation happens to be rare, but much worse than constant. A timer tick may result in a lot of timeouts to cascade to the lower level, but the work for each timeout goes directly to the firing operation for that timeout. The complexity for the entire timer is linear on the number of timeouts, but that is to be expected. * Fine, technically not as it is a factor of the timeout duration, but the worst case is 6, so let's just call it constant.
No, it can move. It will just result in a synchronization (lock free) work. But, because the scheduler uses a work-stealing approach, tasks should* stay on the same thread with which the timeout is registered * If the runtime internals are correctly tuned, which they probably aren't quite yet because the whole thing is still new.
If the raw file handle can integrate with epoll (or whatever the equivalent is for the operating system in question), then it shouldn't be too hard. You would use `Evented` in Mio and `PollEvented` in Tokio. You can see how the TCP types are implemented in Tokio to get a sense.
Learn Rust by porting webbench :-) Not very exciting but good for learning. https://github.com/ksqsf/webbench-rs
you think the paywall hell and scientific publishing bullshit is *only* that nasty? Oh, you sweet summer child. Authors have to *pay* to get their scientific papers published, and doing so they lose the rights to their own paper in most cases. yeah...seriously.
I mean if you want to call a portal Euclidean geometry even though it breaks the axioms of Euclidean geometry feel free, I'm just trying to explain a term in one study does not always refer to the meaning of the same term in a different study. Taking "non Euclidean" to mean curved geometries in this case is the equivalent of an artist commenting `servo` doesn't paint on a canvas.
&gt; You Can’t Sort Floats I think the most surprising thing is how many programming languages consider "not a number" to be a number. I feel the same way about NaN as I do about void, None, null, etc. They're basically errors encapsulated into a value that silently propagate that failure throughout you program until it crashes. In this case, NaN is a failure that has infected the language design itself so that it refuses to so much as sort a list of numbers in case that list of numbers has been infected with the number which is not a number.
I've actually had to use scihub to get access to papers on which I was an author because I couldn't find the original copy. Nuts.
My understanding is that Nan is specified in the floating point standard. I suppose rust could have an option that wraps float like Option&lt;int&gt; without any extra space that forces NaN check for every change
Thank you! I tried to get the match-on-tuple syntax to work but couldn't for some reason.
https://doc.rust-lang.org/stable/nomicon/subtyping.html `&amp;mut T` or `Cell&lt;&amp;T&gt;` for example cannot have its lifetime stretched or squeezed the same way it may happen for `&amp;T`
Maybe you're visualizing a different scenario, but it doesn't seem particularly different to the compiler knowing that `add` touches the flags register?
god damn you’ve got me beat. I made a regular old euclidean [ray-caster](https://www.github.com/poly04/rust-raycaster) with a brick pattern on every wall. It runs slower on my modern machine than doom runs on a 386.
&gt; Needless to say, I was pleasantly surprised to find that Rust has all the functional programming paradigms I enjoyed in Scala (map, flat_map, fold, etc.). They’re slightly less ergonomic to use I'm sure it's been discussed before but a collect_vec() would be a nice ergonomics improvement here by letting us elide the type and still being less characters.
To port code I first create a modified version in the original language that looks as much as possible as how the code should look in the target language (running unittests often to avoid breaking the original code), and later I try to translate that modified version. This strategy seem to require more time, but for me it introduces less bugs and it's simpler. I'd like to invent a cool name for this strategy.
Thanks for all input, FYI, for now, i am using dracula theme: https://draculatheme.com/vim/
Ditto in Afrikaans, "Ja-Nee" :)
Hm, I rather would have a more intelligent code completion that would suggest not only collect but also things like collect::&lt;Vec&gt; (more or less like IntelliJs postfix completion). 
The static dispatch certainly seems nice. My only changes would be to make a macro since every call is the same structure and remove the default trait implementation. pub trait SetUniform&lt;T&gt; { fn set_uniform(&amp;self, _: WebGLUniformLocation, _: T); }
Is it possible to use Tokio for async file I/O?
Small correction under the Ownership Hell header: &gt;This is the core of Rust. It guarantees at compile time that ~~you cannot lose pointers to allocated memory,~~ you cannot double-free, you cannot have dangling pointers. [`std::mem::forget`](https://doc.rust-lang.org/std/mem/fn.forget.html) is safe to use, and you can also leak allocated memory by having cyclic refrence counted pointers.
Most of my GUI needs at the moment are small utility applications, but with the requirement of supporting Mac OS, Linux and (most of the time) Windows. I've found libui and it's rust bindings a good compromise for this. The reason I forked libui-rs (masche842-branch mentioned above) was missing support of pixmap-drawing, which it supports now for Linux and Mac OS. When I updated things a few weeks ago I figured it was hard to get an overview of all the other forks, usually concentrating on one or two things (Windows, cmake-support, pixmap, whatsoever). So I'm totally in favour of merging things together again. @LeoLambda I've taken a quick look at your iui approach and it looks promising. I haven't switched over though, because porting things would have taken too long given the project's deadline. Maybe that has been a problem for others as well. So, if we can find a few more people that are using libui-rs right now and are willing to migrate to iui, that would be a good start. 
Yeah, that's about what I figured as well. You explained the way rust interprets the code and the assumptions it makes way better than I did, though. Tagging literal types gets a bit noisy when populating a lot of (in my case maybe 50) closures of type `Fn(x: SomeEnumType) -&gt; Option&lt;u32&gt;` though, where most enum variants are converted to numerical values. I have a handful of functions that, based on an enum value, among other things, return closures that translate other enum values into Option&lt;u32&gt;. Compile-time enum-&gt;u32 maps, so to speak. I think having explicit casts and trait object conversions expressed using the same keyword is the confusing point here. Trait object conversions could be used to set constraints, while casts can be a little more ambiguous. Having them under one `as` keyword makes them feel like doing the same thing, when in reality they are not.
[IEEE 754](https://en.m.wikipedia.org/wiki/IEEE_754)
**IEEE 754** The IEEE Standard for Floating-Point Arithmetic (IEEE 754) is a technical standard for floating-point computation established in 1985 by the Institute of Electrical and Electronics Engineers (IEEE). The standard addressed many problems found in the diverse floating point implementations that made them difficult to use reliably and portably. Many hardware floating point units now use the IEEE 754 standard. The standard defines: arithmetic formats: sets of binary and decimal floating-point data, which consist of finite numbers (including signed zeros and subnormal numbers), infinities, and special "not a number" values (NaNs) interchange formats: encodings (bit strings) that may be used to exchange floating-point data in an efficient and compact form rounding rules: properties to be satisfied when rounding numbers during arithmetic and conversions operations: arithmetic and other operations (such as trigonometric functions) on arithmetic formats exception handling: indications of exceptional conditions (such as division by zero, overflow, etc.) The current version, IEEE 754-2008 published in August 2008, includes nearly all of the original IEEE 754-1985 standard and the IEEE Standard for Radix-Independent Floating-Point Arithmetic (IEEE 854-1987). *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Non-Mobile link: https://en.wikipedia.org/wiki/IEEE_754 *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^166112
or improving interference so that we can have stable [default type parameters](https://github.com/rust-lang/rfcs/blob/master/text/0213-defaulted-type-params.md) in functions (right now structs can have defaulted type parameters - it’s how HashMap works - but you can’t do that for functions, which makes working with them clunkier then they should be)
So the original goal was to a) implement the stretching; b) add something akin to black holes to distort light rays around; c) implement ray tracing in the surface of a 4D hypersphere. The first part is pretty much implemented and working as intended, you can define how the direction of a ray changes when passing through a threshold, see [the hallways scene file](https://github.com/Limeth/euclider/blob/master/scenes/3d_hallways.json#L28-L56). After doing some research about how I could implement black holes, I found out that I'd have to use approximation techniques, which I did not want to employ, so I threw that idea away. Finally, I entertained the idea of making a true non–euclidean curved space, either spherical or hyperbolic. I believe that both of these could be implemented in euclider, but when I started implementing it, I ran into the issue of having to express everything in euclidean coordinates. That seemed unnecessary and I began looking for an alternative. So I asked around and finally was pointed towards Geometric Algebra, so that's what I've been learning.
AGRPCWRIAL? ("A good Rust programmer can write Rust in any language")
&gt; Instead of just using a single hashed timer wheel implementation, it uses a hierarchical approach (also described in the paper linked above). The timer uses six separate levels. Each level is a hashed wheel containing 64 slots. Slots in the lowest level represent one millisecond. The next level up represents 64 milliseconds (1 x 64 slots) and so on. What is the advantage of timer wheels compared to keeping the timeouts in a [heap](https://en.wikipedia.org/wiki/Heap_(data_structure)), like Python's [asyncio does](https://github.com/python/cpython/blob/233de021d915364bd3daee921d1d96d50d46d7fe/Lib/asyncio/base_events.py#L656)? One possible advantage is that heap push/pop are O(log n), whereas the described implementation seems to achieve constant-time adding and firing timeouts. Possible advantage of the heap approach is simplicity of implementation, given [a heap](https://doc.rust-lang.org/beta/std/collections/struct.BinaryHeap.html). Also, a heap or tree based implementation doesn't assume any particular granularity of the timers seem to round all timers to 1ms (if my understanding is correct - I didn't understand from the text exactly how the slots in the lowest level are ordered).
You could make signed integers slightly more elegant by doing the same thing, i.e. give them a NaN/Inf as the 0x80....00 value. That way divide by zero and overflow can be handled without signals, and the problem of negating the most negative value producing a negative value goes away. That would force everyone to think about how to make it more elegant in the language too, and as you say, treating it as a None-like value makes a lot of sense. How the code would look, I have no idea. (Pony cheats and says "let a/0 be 0".) (But all this would need hardware support, so will probably never happen; although if someone's in a position to make it happen, please make a%16==a&amp;15 and a/16==a&gt;&gt;4, for negative values too.)
This is rather cute! 
If I had a dime for each time I've seen someone report that they needed to parse, went with `nom` as the 'default option', and ended up complaining about macros, I'd have, uh, a dollar maybe. I wonder if there's anything we can or should do as a community about this situation? This is nothing against `nom` which is likely the best fit for many use cases, but the perception of it as "*the* Rust solution to parsing" is maybe not optimal. /u/arcoain, have you looked into `combine`, `lalrpop`, or `pest` maybe? (N.B. I haven't tried either; these are just the other options which came immediately to mind) 
Thank you for the analysis! I ended up with this: https://play.rust-lang.org/?gist=3314404e746cf90c833169a931d4d320&amp;version=stable Your hint about adjusting the lifetime of the closure was causing some weird errors at first even though the suggestion made sense to me -- turned out to be because the closure I was passing in did have the lifetime attached. In the end I did manage to find a neat solution that allows me to not have to reallocate the string even for the splitting case (at the expense of some repetition in the code), by doing the split in a different way and directly reusing the nested data. I also found a slightly less complicated way to hack around the lexical borrows.
Bikeshedding warning: C# LINQ they have `Enumerable&lt;T&gt;.ToList`, `Enumerable&lt;T&gt;.ToDictionary` and `Enumerable&lt;T&gt;.ToArray`. The equivalent for Rust would be `Iterator::to_vec` and `Iterator::to_hash_map` (array distinction isn't relevant for Rust).
Interesting, thanks. Not sure, whether the @-syntax works here, so pinging /u/LeoLambda
I have a really hard time understanding the wrapper tipes in Rust. I would like to use one in a shared muttable Vector but not sure which one would be best. The types that I have a hard time understanding are: Box, Cell, RefCell, Ref, RefMut, Arc and Rc. What are these good and bad for? For example Rc and Box seem really similar, why would I use one and not the other?
Indeed: https://github.com/grame-cncm/faust/tree/7da22e299e5a7f7fe7146feb886e107026b5ebcb/compiler/generator/rust
It's about knowing what you need, and picking the least restrictive type(s) that give you that. A brief summary would be something like: For the pointer types: | Type | Sharing/Mutation | Thread-portable | |------|------------------|-----------------| | Box | Mutation | Yes | | Rc | Sharing | No | | Arc | Sharing | Yes | - "Thread-portable" means it can be `Send` to another thread. For the cell types: | Type | T: Copy | Thread-safe | Ref Access | |---------|---------|-------------|--------------------| | Cell | Yes | No | N/A | | RefCell | No | No | 1 at a time | | Mutex | No | Yes | 1 at a time | | RwLock | No | Yes | Many read, 1 write | - "T: Copy" means "does this require the value stored within be a simple, `Copy` value? Note that `Ref` and `RefMut` aren't wrappers; they're just guards so `RefCell` knows when you're finished using your borrow to the value it holds.
Regarding the granularity: it would be possible to reduce the granularity quite easily, however since tokio is not intended for realtime work there are diminishing returns. The very clock that many OS provide has its granularity, and `usleep` itself is in micro-seconds, so one cannot go down that much. Regarding the heap, this is what the existing timer implementations I have seen use. As you mention, it means O(log N) scheduling/firing/cancelling. Worse, while O(log N) comparisons is not too bad, it may also means O(log N) cache misses worst-case! By comparison, the hierarchical hash wheels offer O(1) cache misses by design... not sure how it ensures O(1) cancelling though, to be honest.
Question: how do you get O(1) cancelling? I get that finding the wheel and its slot are O(1), but if all you have is a linked-list of timers in there, surely finding the one to cancel requires a linear search through the list?
From a quick glance over `rust_code_container.cpp`, it seems like that might be ... broken? At the end of the file there's `extern "C" void computeThreadExternal(&amp;mut self, num_thread: i32)`, which might need `void`-&gt;`fn`, and that function seems to have a single statement: `computeThread((...*)dsp, num_thread);`, which might need to be `computeThread(dsp as *mut ..., num_thread);`? Am I missing something?
&gt; Rust obviously has huge potential. But still not quite there to replace C/C++ completely. To be clear, could sum up exactly which missing features you think that Rust is missing? For me, const generics and SIMD are the last barrier, with SIMD scheduled to be released in the second next release if I'm not mistaken.
CLI apps seem to be a very good way to bring more programs written in Rust to users. I have replaced my usage of grep and silversurfer (ag) with ripgrep (rg), not because I like Rust, but because ripgrep is faster, and because I have not once found it lacking a feature, and its speed constantly impresses me—I can can `rg pattern` in my home directory and it's done in a few seconds. Similarly, for simple usage, I now use fd-find (fd) rather than GNU find: fd-find is faster, it ignores files that I don't want in my output, and it's easier to use.
Few things from the top of my head (in decreasing order of priority) that "I" definitely want: 1. Custom Allocators and thus support for raw memory allocation in stable release. 2. More production ready libraries for DSL. Like Boost.Spirit. 3. Stop the need for Boxing to return a lambda. 4. Specialization of Generic structs and Traits. 5. GI bindings (I work on that). I have not seen much on it in Rust. 6. Lots of libraries coming out are probably not time tested or production ready. I just can't use them blindly if it is that I need to use for my work. There are more...but these are few important ones. 
I generally recommend combine to newcomers after some hairy experiences with nom (with some produce thanks from people who had also been have bad experiences with nom). I didn't particularly care about performance so never measured it and can't comment, but it feels like a simpler model, with better error messages and less chance of pain when going off the beaten track - sometimes you have a silly underspecified format and you just want to run a bit of code on your input sequence to figure out what to do next. As it happens, I do still use nom, but it parses the tokens combine emits (https://github.com/aidanhs/frametool/blob/master/src/lex.rs). I can't comment on any other solutions.
Unix: https://docs.rs/tokio-file-unix/0.4.2/tokio_file_unix
Thanks, totally forgot about that while searching for &lt;&gt; on my smartphone. That syntax sure is ugly - HKTs to the rescue? 
&gt; Stop the need for Boxing to return a lambda. What cases were you hoping to handle? If you need to capture a closure's environment, then `impl Trait` (IIUC) will alleviate most of the problems. If you're just using the equivalent of free functions, you can always use `Fn*` references instead.
One more question: what is the difference between pointer types and cell types?
&gt; Custom Allocators and thus support for raw memory allocation in stable release. Should be in nightly at least. I think this feature is actually in pretty high demand, are there ongoing plans for stabilization?
Thanks god for Russian hackers...
It's a doubly-linked list, the caller has a reference to the item in question, and there are a bunch of `unsafe` blocks. I found the code [here](https://github.com/tokio-rs/tokio/blob/master/tokio-timer/src/timer/entry.rs). See the `remove` method, and the `next_stack`/`prev_stack` linked list pointers.
So: - Custom allocators are being worked on AFAIK, - DSL: I think relies very much on macros for this, for better or worse, that being said the last time I used Boost.Spirit the compile times were excruciating, - Boxing lambdas: `impl Trait` which is coming in 6 weeks (in 1.26) should allow return lambdas without boxing; if you wish to store multiple different lambdas in a `Vec` you may still need boxing, though. There is no way yet, AFAIK, to have `SmallBox&lt;N&gt;` which would be off-heap for N bytes. - Specialization of Traits is coming, I haven't heard of Specialization of struct. All in all, not too bad, ... although it leaves out the elephant in the room: mature libraries. That being said, I must admit than in C++ I've usually avoided most libraries (except for Boost/Google code) given (1) licensing and (2) build integration issues; so I am not feeling that much.
Pointers are just that, like in any other language. Cells give you interior mutability: some mechanism for mutating values via shared access (*i.e.* `Rc`, `Arc`, or globals).
I think `deallocate` should be unsafe: ``` fn deallocate(ptr: *mut T, len: usize, cap: usize) { unsafe { mem::drop(Vec::from_raw_parts(ptr, len, cap)); } } ```
That's the design I chose for now, adding another layer of abstraction called a *Allocator storage* leaving the exposed Allocator immutable while mutating only the storage that is used by it 
Thank you! I never understood interior mutability untill this discussion. Thank you for spending the time to clear things up.
Hmm..Shouldnt the compiler atleast warn you about it then ? I did not get any warnings.
Ahh...nice. Thanks for the update!
I am guessing `FnOnce` should also work w/o boxing. It is useful for creating combinators.
&gt; Does someone already have a comparable experience when writing a REST API in rust or go? I personally prefer rust overall, especially for CLI focused applications. But Go is designed for web development and still holds the best support in this regard so currently all my web applications are written in Go bar some more experimental things. &gt; When should one consider using go over rust in this domain? It is getting closer - a few of the blockers in this area (most around the async area) are actively being worked on an some of the major ones look like they will be resolved or at least dramatically improved in the upcoming releases. I am not sure I will switch the bulk of my workload over until futures/hyper (or a competitor) reaches a stable 1.0 version but I will continue to increase my experimentation in the area as they approach this. There is a lot of active development in this area at the moment and things are rapidly moving forward but I don't expect things to reach this point for another year or two. --- Is there any reason why you would not learn and use both? And then use the one most suited to the part you are currently building. I have to concede that go is one of the simplest languages you can learn so makes a good stop gap while rust matures in this space - but I do find it more limiting and less expressive then rust.
[I wrote an API in Rust](https://github.com/unicornheartclub/roll-api). I thoroughly enjoyed writing it but I would say the web ecosystem is still not quite there yet in terms of maturity compared to Go or Node.js. In particular, I have yet to find a good, reliable framework to get rolling with quickly (though I last dabbled about a month or two ago, so take with a grain of salt!) I tried [Iron](https://github.com/iron/iron) and [Rocket](https://github.com/SergioBenitez/Rocket). I liked Iron better but I think it has been abandoned. Rocket is nice but required some heavy fiddling with package dependencies on nightly for some time. I'm unsure if that has been resolved. I just discovered [Actix](https://github.com/actix/actix-web) which looks really nice but have no experience with it. Rocket's middleware support is good but I stumbled when writing a middleware to collect stats for Prometheus as all requests are done async. My lack of knowledge is not a knock on the framework but rather that there will be some learning curve. Overall, writing and maintaining the small API has been a joy but getting up and started was somewhat cumbersome in comparison to starting an API from scratch in Go or Node.js. I absolutely think it was worth writing in Rust. Just do the research on a good, reliable framework that you enjoy writing in.
Just to note from that crate: &gt; This crate is primarily intended for pipes and other files that support nonblocking I/O. Regular files do not support nonblocking I/O, so this crate has no effect on them. AFAIK, your best bet at the moment is doing reads in a cpu pool.
Another word us old farts have to look up!
Yes, if a future's poll method where a `loop`, and doesn't return, then the `Deadline` which wrapped cannot continue and check its `Delay`.
Nitpick: after a recent RFC, you can put non-Copy types in a Cell, you just can't get() them. But the other methods (set, swap, get_mut) are available. I'm still not quite sure why this is useful. 
The unsafe in the body tells the compiler not to complain.
I would like to second the recommendation for Anti-Chamber. It's a very fun game to play and learn the rules and mechanics. For anyone who has played it through, I suggest looking up speed runs. They are mind bending.
Yes, right. Now that I recheck my code, I have put it inside `unsafe`. @jkleo1 - It is inside unsafe already.
Here's the loquacious version of what /u/torkleyy said: You used `unsafe` which basically told the compiler "it's cool I got this". But then you didn't actually "got this". The general idea is that after using `unsafe`, you should either 1) expose only an API that is "known" to be safe on top of that (for instance like std::cell::RefCell). By "safe" I mean that you guarantee that a user doing random stuff with your APIs, for instance calling your `deallocate()` twice in a row, still won't be able to crash the system, perhaps due to extra sanity checking you added to `deallocate()`. Or, 2) You can manually mark your function as `unsafe`, so anybody calling it knows they have to be careful too. Obviously 1) is preferable since with the latter you're going to get 'unsafe' propagating itself everywhere. But sometimes it's infeasible to do 1). The key point is that the compiler can't tell whether you actually did it right or not, so it has to trust you. If distrust was the default, the compiler would have to throw a warning for anybody who used 'safe' functions that internally used unsafe abstractions, or any function that used *those* functions, etc. Given that things like std::vec are built on top of unsafe code, that's not really an option. If you get a flat-out crash (SIGSEGV) in your code, that's when you start auditing all uses of `unsafe` in that area, since theoretically that's where the issue must lie (excepting extreme corner cases like a stack overflow or compiler bug). Hope it helps.
Aha..Got it! Thanks.
The 1ms granularity of the timer is not really that important given that the underlying syscalls used to sleep have ms level granularity. In other words, even if you used a heap, you would have timeouts rounded to the closest ms. If a high precision timer is needed, a completely different api / implementation strategy is going to have to be employed. Because once a timeout fires there is no guarentee as to when the task will be scheduled. It might be more than a ms. 
While it's maybe a little outdated now, I still think [An Opinionated Guide to Rust Web Servers](https://wiki.alopex.li/AnOpinionatedGuideToRustWebServers) (by /u/icefoxen) is one of the best resources for comparing the different Rust server libraries. There's also [this one on GitHub](https://github.com/flosse/rust-web-framework-comparison), which I'm less familar with but seems well researched.
&gt; GI bindings (I work on that). I have not seen much on it in Rust. So you've not stumbled across [gleam](https://github.com/servo/gleam), [glium](https://github.com/glium/glium), [glutin](https://crates.io/crates/glutin) or [gl-generator](https://crates.io/crates/gl_generator)? Rust has very strong OpenGL support, not only because servo is using OpenGL. And these libraries are pretty stable. I mean, what does C++ have ... SDL and that's it. 
It's GObeject Introspection that I am talking about.
The way you wrote it guarantees that `deallocate` will never do anything unsafe, such as deallocating an invalid `Vec` pointer, or one with an invalid length or capacity. There is no way to guarantee that, so the function is wrong, but that `unsafe` block says you're taking responsibility for doing things correctly. If you wrote the function like this: unsafe fn deallocate(ptr: *mut T, len: usize, cap: usize) { mem::drop(Vec::from_raw_parts(ptr, len, cap)); } then you push the unsafety onto the caller, so they must use an `unsafe { }` block to call `deallocate`, where they accept responsibility for only providing a valid pointer, with the correct length and capacity. As it is with your current function, any piece of safe, normal Rust could call `deallocate` on an invalid pointer and cause bad/undefined behavior, which safe code shouldn't be able to do.
&gt; Should be in nightly at least. I think this feature is actually in pretty high demand, are there ongoing plans for stabilization? It was a hot topic at the all-hands.
The gtk-rs project is very active and has [gir](https://github.com/gtk-rs/gir), are you working on something similar?
Yes, I have seen that. It had quite a few features missing that we would have liked to have. Also, there is no much community support on it (I am not sure about it though.)
I recall discussing this back in mid 2017, and saw some generated code that (while looking like idiomatic C, and had only mutable variables) had no unsafe code at all. This kind of translation work is super helpful for the DSP community -- otherwise we're just rewriting the same algorithms by hand over and over again! I think there's potentially a lot of room to contribute to this Faust backend by profiling the generated code against "idiomatic" Rust code. FIR (Faust Intermediate Representation) makes substantial decisions about the structure of the code, so the class / member model is more or less set, but I bet there's some wiggle room somewhere.
Is this related? https://github.com/gtk-rs/gir/ GTK overall seems to be pretty enthusiastic about Rust, so it would surprise me if there was much that wasn't already at least roadmapped...
There is no proper non-blocking File IO for most systems, so the cross platform way is to do FS operations in a separate thread. There is [futures-fs](https://crates.io/crates/futures-fs) to do that in a thread pool and integrate with futures!
&gt; If a high precision timer is needed, a completely different api / implementation strategy is going to have to be employed. So would it be possible to implement a timer that uses e.g. [nanosleep](http://man7.org/linux/man-pages/man2/nanosleep.2.html)?
&gt; Custom Allocators and thus support for raw memory allocation in stable release. I made a [crate](https://crates.io/crates/loca) for exactly this reason. 
&gt; The way you wrote it guarantees that deallocate will never do anything unsafe Incorrect rather than unsafe ;) The entire point of unsafe blocks is to do unsafe things, but you pinkie-swear to uphold Rust's invariants no matter what the (valid) input is.
When I was choosing, I think I just went with the library with the most stars or downloads or something. Probably also the one with the clearest _looking_ docs. FWIW when I picked nom, I hadn't figured out that you need to search crates.io for things
`next = prev = se-&gt;posSL = it = sl.insert(se).first;` yikes
When you mention the async issues, is Go better right now because of its built in channels and goroutines, or is there a library that handles some async stuff in Go you like better? I do find that doing stuff with channels and goroutines is pretty painless, haven't quite experienced that in Rust yet but to be fair I haven't dug much into that side of the language yet. 
Yea, it shows a clear example on how to do this that I get, what I do not get is how to do this when you do not provide a static number of entities for the collection. In this example, the `Screen` collection `component` are always initialized with all the types in compile time using the `vec!` macro. When I try to do this in runtime, I get the complication error `mismatched types, expected struct X, found struct Y` even if both implements the base trait that is specified in the class with a `where` argument. Like this: pub trait Test : Sized{ fn new(Test_name: &amp;str) -&gt; Self; fn process(&amp;self, message: &amp;str); } pub struct TestSystem&lt;T: Test&gt; { pub tests: HashMap&lt;String,Box&lt;T&gt;&gt;, } impl&lt;T&gt; TestSystem&lt;T&gt; where T: Test{} 
Yeah. So I briefly had an openssl dependency and it wreaked havoc on the builds for anyone on OSX. For some it wouldn't build, for some it would segfault, for some it wouldn't start. So I ripped that out and am pretty wary of putting it back in. Plus it just seems like a gross way to do it, the rust libs should support pems which are by far the most common form for keys/certs. 
I'm very new to learnig Rust (currently going through the second edition of the "The Rust Programming Language") and have a question about mutable references. In order to get used to Rust's syntax and simple concepts I tried to implement a simple bubble sort algorithm on an array of integers. One of the things I decided to do is to extract the actual swapping of the values into a separate function called "swap". The signatures of the functions look like this: fn swap(array: &amp;mut [i32], i: usize, j: usize) {} fn bubble_sort(array: &amp;mut [i32]) {} So in main I initiate an array containing integers (i32), call bubble_sort and pass over a mutable reference of the array to it. bubble_sort() then calls swap() at some point, again passing a mutable reference of the array to it. Now, this shouldn't be and isn't possible as it is not allowed to have two mutable references at the same time. My question is: what's the "best" way to go about this? Of course I could just move the body of swap() into the body of bubble_sort() and get rid of swap() but in the case of larger projects this is not always feasible. Should I move the array (regarding ownership) to one of the functions instead of passing a mutable reference? Which one, bubble_sort() or swap()? So tl;dr: What's the standard way of dealing with a situation where I want to manipulate a variable and I have to pass it through nested function calls?
Go has async built into the language with goroutines, no need for a third party library like with rust but this also limits competing implementations (for better and worst). There are a few competing implementations of async code in rust, [tokio](https://tokio.rs/) being the most popular in the web domain at the moment and is based on the [futures](https://github.com/rust-lang-nursery/futures-rs) library. The async libraries in rust are usable now - but they are less than ergonomic in their usage partly due to some missing features in the language. [Rocket](https://rocket.rs/) is a good example of a high level async (based on [hyper]()) web server library that shows what can be possible in the language - [but currently requires nightly to run](https://github.com/SergioBenitez/Rocket/issues/19).
&gt; HKTs to the rescue? HKT here would mean that `collect` takes a type parameter of kind `* -&gt; *` (using Haskell syntax, sorry I'm not familiar enough with the current state of HKT in Rust). In other words, it would require collections to be parameterized by their item type, and so it would not work with eg `impl FromIterator&lt;char&gt; for String`.
Teeniest correction: I don't believe Rocket is currently using async (non blocking) sockets.
Looking at the linked code, combine looks much closer to the parser combinator library in Scala. Will have to give that a try next time
&gt;The biggest story in libraries this release is std::ptr::NonNull&lt;T&gt;. This type is similar to *mut T, but is non-null and covariant. This blog post isn’t the right place to explain variance... I would love to see an explanation of that somewhere, and examples of data structures that should not be invariant 
You mean just about every operation on `f64` could result in NaN: - -inf + inf - inf - inf - 0 / 0 - inf * 0
Thanks for the confirmation! Intrusive containers are really neat in that regard!
Perhaps you could give a little more context about what you're doing? Often it is possible restructure stuff to work around this. For instance, in this example it seems `v` is not assigned inside your loop, perhaps you could lift that line out of the loop? Or does calling `Dfa::to_set` borrow `partition`?
Thank you. Bookmarked the part about embedded 
It is possible to implement a timer that uses nonosleep, however the API would need to be rethought in context of the use cases. The Tokio timer API does not provide any high precision guarantees. This is an API design decision of the timer and to some extend Rust's futures. I have personally not ever encountered a use case for sub ms timers, so I cannot comment on that. I would assume that if one needs sub ms resolution, then precision is very important. As such, I would ask how does the application respond to load? In other words, if the timer fires but the application is already processing a backlog of work, what happens?
I miss `switch` for this kind of generator/coroutine pattern auto work(state&amp; s) -&gt; result { switch (s.loc) { case 0; for (s.idx = 0; s.idx != s.max; ++s.idx) { if (done(s.idx)) continue; push_to_work_queue(s.idx); s.loc = 1; return result::suspend; case 1: } return result::finished; case default: return result::bad_loc; } } You can also use C's unprincipled token-paste macros to turn it into #define BEGIN switch(s.loc) { \ default: return result::bad_loc; \ case 0: #define SUSPEND(n) s.loc = n; \ return result::suspend; \ case n: #define END } \ return result::finished; auto work(state&amp; s) -&gt; result { BEGIN for (s.idx = 0; s.idx != s.max; ++s.idx) { if (done(s.idx)) continue; push_to_work_queue(s.idx); SUSPEND(1) } END } Note that you can serialize `s.loc` and since its values are explicit (`SUSPEND(**1**)`) you can modify the code in a way that is backwards compatible with serialized values.
Yes, that is correct. If one wanted to interrupt a CPU intensive logic, it would require checking some "interrupt" flag every so often and aborting if it is set.
this is a bit more code: while spin_again { spin_again = false; for set in partition.iter_mut() { for transition in &amp;self.transitions { let start_vertex = &amp;(set.set[0]); for state in set.set[1..].iter() { if let Some(op_delta) = Dfa::delta(state, transition) { if let Some(delta) = Dfa::delta(start_vertex, transition) { let same = Dfa::to_set(delta, &amp;partition) != Dfa::to_set(op_delta, &amp;partition); { //split set.set.remove_item(state); spin_again = true } } else { // split spin_again = true } } else { if let Some(_) = Dfa::delta(start_vertex, transition) { //split spin_again = true } } } } } } It's part of hop croft's algorithm to minimize a Dfa. Yes to_set() needs to borrow partition.
Yes, you are correct on that point. There are ways of dealing with this case if one is willing to accept a loss of precision as the duration of the timeout elapses. For example, if a higher level has a huge amount of timeouts, instead of cascading it down immediately, that work could be spread out across the duration of the lower level's first slot. This would add a worst case imprecision of that duration, but it would also spread out the work. So, if you set a timeout for exactly 262,144ms (just over 4 minutes), that would fall in level 3 with an offset of 0ms, so the timer should fire off exactly at the beginning of level three. But, if you spread out the work to cascade the timeouts down a level, that timeout *might* fire at 262,144ms + 4,096ms, i.e. roughly 4 seconds late (worst case). It might be acceptable to say that if you set a timeout for 4 minutes in the future, the precision is +/- 4 seconds. So, if you set 1MM timeouts for 17h30, you might end up spreading out the actual timeouts firing over some period (seconds, minutes). I know that the linux kernel uses a hierarchical hashed timer wheel and this is also a problem in the kernel itself. I hesitate to read the actual code as it is GPL.
Why doesn't this code compile? struct A&lt;T&gt; { inner: T, } fn foo&lt;T&gt;(a: A&lt;T&gt;) -&gt; T { unsafe { std::mem::transmute(a) } } It says: error[E0512]: transmute called with types of different sizes --&gt; src/main.rs:8:14 | 8 | unsafe { std::mem::transmute(a) } | ^^^^^^^^^^^^^^^^^^^ | = note: source type: A&lt;T&gt; (size can vary because of T) = note: target type: T (this type's size can vary) How can `A&lt;T&gt;` be of different size than `T`?
Async file I/O doesn't exist on anything except FreeBSD, where it's implemented as creating sync kernel threads anyway. Basically, you might as well create your own threadpool to handle it.
Glad to hear that. The research was done by my friend and I dont know when. I will take a look at it again when I understand Rust well enough. We use it extensively (The C one) to generate code for creating python and Lua bindings.
Uh... would you rather not have proper support for generators? I mean, that's one of the goals for 2018; and /u/desiringmachines has been putting a lot of work into prepping the language and libraries to support them efficiently. See their serie on [Async/Await](https://boats.gitlab.io/blog/post/2018-03-20-async-vi/).
[removed]
You can do struct specialization on top of trait specialization but in general specialization of generic structs is a nasty topic since it interacts with variance in potentially unexpected ways.
Can they do what I said in my last paragraph?
Sorry, but I take issue with a couple things in this post. All the material under "Things Move" isn't really illustrating any fundamental differences between C++ and Rust. It's just showing that the implicit `this` parameter in C++ is a pointer, I guess. You can do things in C++ the same way as your Rust example if you want: ``` struct Point { int x; int y; }; Point new_point(int x, int y) { Point p; p.x = x; p.y = y; return p; } ``` I also think this statement &gt; In C++ ... there is generally nothing stopping you from taking an address of a value and then using it. ... In Rust this is just generally not possible. is misleading. Sure, due to the borrow checker there are some restrictions on what you can do with a reference, but to say it's "generally not possible" to use them is very odd. And of course you can take pointers and use them for whatever you want in unsafe code.
&gt; isn't really illustrating any fundamental differences between C++ and Rust. It's just showing that the implicit this parameter in C++ is a pointer How is this not a fundamental difference? Move-by-default is a huge fundamental difference between the languages. It also extends beyond 'this' to all non-reference parameters. &gt; In Rust this is just generally not possible. I agree that this is poorly worded. It's more like 'use is significantly restricted'.
[Theoretically](https://github.com/hmwill/tokio-linux-aio).
High demand? When would you need one?
No, you didn't show anything I mentioned in my last paragraph at all. &gt; Note that you can serialize `s.loc` and since its values are explicit (`SUSPEND(**1**)`) you can modify the code in a way that is backwards compatible with serialized values. Suppose I stop the C++ program after calling the generator a few times and serialize the `state` variable to disk (it's just some, say, `u32`s: `idx`, `max` and `loc`). Then I edit the source code to auto work(state&amp; s) -&gt; result { BEGIN for (s.idx = 0; s.idx != s.max; ++s.idx) { if (done(s.idx)) continue; check_if_excluded(s.idx); SUSPEND(2) if (is_excluded(s.idx)) continue; push_to_work_queue(s.idx); SUSPEND(1) } END } and recompile, load the serialized state into the new generator and keep running. The generator will pick up at the point it left off. Since the programmer manually handles the values `n` in `SUSPEND(n)` they have control over where the generator resumes from (note that it would break if you switched `SUSPEND(1)` and `SUSPEND(2)` so those numbers can't be handled implicitly). That's what I mean about being able to edit in a way that's backwards compatible. Nothing like this is exposed for an `ops::Generator`. And even if it were, there will always be some other small perturbation of constraints which make it inapplicable. So yes, if you need a `Generator`, then `Generator` is much nicer to have than a `switch`! If you need something a little different, `Generator` might be completely useless while `switch` is _still_ useful. This is always the problem with taking some general construct, making a finite list of things it might be used for and saying "well we have better versions of these so you don't need this" and getting rid of it.
* By struct specialization, I meant more like C++ template specialization on class/struct. * By custom allocators I mean the ability to provide non-default allocators to containers/collections. Accessing `libc` for allocation requirements is not a good idea at all! I was thing more on the lines of something like `new` in C++ but better. * I just checked out `nom`. Didnt understand it at all! I haven't read up on Macros yet. But I think I will miss Spirit.X3 like PEG grammar parsing code :)
IIRC, you can specialize structs via associated types.
&gt; DSL: I think relies very much on macros for this, for better or worse, that being said the last time I used Boost.Spirit the compile times were excruciating, Seriously, that. I just last summer rewrite a "small" boost.spirit-based DSL with a hand-written recursive-descent parser. Compile times are better despite the increased amount of code. Runtime is also _vastly_ better. I (and other mere mortal human beings) can also further optimize and tweak the code; just did that last week to replace the uses of strings with a purely-stack-allocated fixed_strings for another ~10% runtime perf *ahem* boost.
I'm glad you found it promising! Unfortunately it's kind of on hold because I don't have a ton of time between school and work, but I try to add things when I can.
[removed]
yes `Dfa::to_set()` needs to borrow all of partition. fn to_set(v: &amp;Vertex, p: &amp;Vec&lt;VertexSet&gt;) -&gt; u32 { let ret: Vec&lt;Vertex&gt; = p.iter().filter(|&amp;x| x.contains(v)).map(|x| x.id).collect(); ret[0] } 
The whole file for clarity [code](https://pastebin.com/xPYU4tuZ)
&gt; Is there any reason why you would not learn and use both? And then use the one most suited to the part you are currently building. I have to concede that go is one of the simplest languages you can learn so makes a good stop gap while rust matures in this space - but I do find it more limiting and less expressive then rust. You do have a good point. I guess being lazy since I thought I could kill two birds with one stone. I will reconsider go for this task since I do not have any prior rust experience and should start smaller by writing a cli client as an introductory exercise first. 
Well, technically, rust does not guarantee anything about struct layouts - you can't just assume that a struct will have the same representation as its only field. Also, rustc is seems to be pretty conservative regarding type parameters - it won't assume anything about type parameter sizes, and a struct that directly contains it will not be transmutable to anything (not even itself). Even `#[repr(transparent)]` doesn't help here.
MPI I/O also offers async File I/O on every platform :)
&gt; Suppose I stop the C++ program after calling the generator a few times and serialize the state variable to disk. [...] Then I edit the source code [...] and recompile, load the serialized state into the new generator and keep running. That sounds like an incredibly niche use case. When would this be useful? Games programming?
For that kind of specialization what the GP suggests is probably the cleanest choice. Why doesn’t it fit your needs ? Non default allocators for collections are in the distant future, in Rust one can’t really configure the global allocator yet. Yeah, nom and combine are more like Haskell’s parser combinators. Spirit is also inspired by these but in C++ it has to be implemented in a widely different way. 
&gt; How is this not a fundamental difference? Move-by-default is a huge fundamental difference between the languages. How does this example illustrate that difference? It seems to me the difference is that where C++ would copy, Rust moves. But in the C++ example here, nothing is copied anyway! (well, except the integers) Surely the way to illustrate this would be to show a function accepting a `Point` as an argument, and showing that in C++ you can use the `Point` afterwards but in Rust you cannot.
Wait, why do you collect into a vector and then only access the first element and throw the rest of it away?
&gt; What Does Not Work? AIO read and write on files opened without O_DIRECT (i.e. normal buffered filesystem AIO). This isn't actually useful for the vast majority of applications, as you're losing out on caching and buffering in the kernel. If O_DIRECT wasn't something you were thinking of using in the first place, Linux AIO is definitely not what you're looking for.
After I read what you wrote I think it would be great to have such warnings. Eg. When you use unsafe, your function is automatically unsafe until you explicitly mark it as _safe_
Sure, to serialize actor states for a save game. Even without the requirement of surviving recompilation, you could use it to resume any kind of long-running process between runs of a binary, or to move a long-running process from one machine to another. Besides serializing, you can clone the generator, debug-print it, move it between threads, etc. Unlike a normal generator, the flow of data can easily be bi-directional (from the caller into the generator as well the reverse). You can write a non-deterministic computation with CHOOSE(n) { foo } else { bar } where `CHOOSE(n)` expands to s.loc = n; return result::decision_point; case n: if (s.which) and drive the direction the computation goes from the caller by setting `s.which`, exploring the forest of possible computations. You can have a reversible computation by cloning the state before you call into the generator and restoring it if you want to go back. This is certainly niche, but niche use cases still exist.
I gave up on writing a toy compiler in rust because of `nom`. If I had known about `lalrpop` at the time I think I might not have had to fall back to Haskell.
[removed]
just curious why array/vec distinction isn't relevant (rust noob)
I think the last example can be more easily done by Arc::make_mut().