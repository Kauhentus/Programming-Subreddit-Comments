You can use any function that returns `Stuff` too.
I'am working on fork of tcpconsole in rust. So far implemented only remote sysrq-trigger. 
:D Every time this happens to me, I cringe at how much worse this could have been in C++. Then again, in C++ I would probably have avoided using references entirely and used `shared_ptr` or whatever long before reaching this point. Rust lets you try to toe the line without crossing it here, which is pretty amazing.
I'm going to keep working on [Uni.rs](https://github.com/uni-rs/uni.rs). The network driver for Xen is fairly advanced (RX side is 100% working though not committed yet). Therefore it's time to start seriously working on a network stack.
It is possible to write code whose safety depends on messages received over a network, so that it safety can't be proven using the code itself. In fact, automatic updates pretty much require this. Unsafe code basically introduces new obligations for the safety proof. It is the coder's responsibility to ensure that these are satisfied. The module system is useful for guaranteeing these obligations in the presence of unknown code.
Just added support for MySQL to https://github.com/Keats/dbmigrate and I'll read up on how attributes work to make a struct validation crate
you're*
History agrees, we have had collections traits, but they just didn't work well. A more powerful type system might be able to express useful collections traits, but not the one Rust currently has. 
Interesting, although you should probably not name your project Etherpad: http://etherpad.org/
It sounds like you're coming at this more from an "`unsafe` is a lint" aspect rather than "non-`unsafe` has absolute guarantees" aspect? The latter aspect implies that that all of this discussion has to be more than just convention: they're rules that Rust code must follow or the optimiser/type checker (or standard library, or whatever) may misbehave arbitrarily severely. Under that second aspect, your two conventions aren't different: if fields are `pub`, then they cannot be relied on for `unsafe` blocks and hence any invariants that must hold for them in an `unsafe` block must be checked (in other words, they become as unknown as a parameter that's a plain `i32` or `&amp;str`). In any case, making assumptions about the validity of inputs is pretty important, e.g. methods on `Vec` couldn't expose a safe API *at all* if they had to assume all parameters (i.e. including the `Vec`) could be mangled. For example, a invalid `Vec` may have a null internal pointer which is `unsafe` to derefence and hence exposing such an operation through a non-`unsafe` function such as `v[0]` would be incorrect.
I did read it :) . I'm looking forward to seeing your model! Right now, by semantics is built on a variant of the CompCert memory model as described in &lt;https://hal.inria.fr/hal-00703441/document&gt;. I simplified it by removing all the types and letting all base types have the same size. &gt; Rust doesn't care about allocation and deallocation of memory. Rust cares which memory is allocated and which is not. This is needed to define whether a using a pointer obtained via pointer arithmetic, or accessing an array index without checking, is defined or not. I don't think it's possible to realistically model Rust without primitives for memory (de)allocation. Even for languages that do not have an unsafe part, where all pointer accesses will always be valid (e.g., SML), an important part of proving type safety is to show that all memory accesses *are* indeed valid. Again, this requires a distinction between those locations that are currently allocated, and those that are not.
To get familiar with rust, I'm trying my hand at implementing a "Tree-Bitmap" for storing IP prefixes in a compact datastructure with fast lookups, based on [this paper](http://cseweb.ucsd.edu/~varghese/PAPERS/ccr2004.pdf). I have some projects in mind where that would be handy. So far I have written a bucket allocator (built with RawVecs) for storing the trie nodes/values and trie bit matching logic using fast lookup tables. Now to implement the frontend struct that ties it all together..
[Seems fine to me](https://play.rust-lang.org/?gist=de21b647510dbacfee25&amp;version=stable)
Developer docs aren't currently deployed, they hopefully will be soon. Until then, Manish has a mirror: http://manishearth.github.io/rust-internals-docs/
With `#[repr(C)]` structs, this is not undefined (i.e. go hog-wild, or at least exactly as hog-wild as you would with C) - although it does require `unsafe` code. Non-`#[repr(C)]` structs have no defined layout (although I believe the lang team is working on it) so transmuting between them will always be undefined. EDIT: [macros are great](https://play.rust-lang.org/?gist=486a786f17434f40c168&amp;version=stable) EDIT2: I don't know if there is a standard way to define "unsafe `From` impl" (ideally this would be a stdlib `UnsafeFrom` trait but a man can dream) but that would be the ideal way to initialise that struct.
As /u/dbaupp already mentioned, this isn't about convention at all. The question "which code has to be manually proven correct" is a formal one, with a mathematically rigorous answer. The way Rust works right now, the correct answer is "at least everything in the same module". Of course we could change Rust such that unsafety is a module property, which would make this point more clear. However, I don't think we'd want Rust to treat the entire body of such a module as being inside an `unsafe` block; there's still value to the Rust compiler making sure we don't accidentally dereference a raw pointer where we did not mean to. Finally, your comment about privacy is correct. I should stress that point more in the post, and will edit it accordingly.
All the examples in and after the "Other Stuff" heading are just single words. Either `x` or `foo` and that's it.
Came here to mention the examples being `x` (perhaps they were truncated or are a placeholder), but anyway, another comment: &gt; (If you're interested, the type rules and semantics for existential types are standard and can be found online or in a textbook, I recommend TaPL by Pierce). Thanks!
Atomics are for lock-free multithreading stuff. volatile is for memory-mapped peripheral hardware (like GPIOs). At least that's how it works in C11/C++11. So The use case is different.
why would someone downvote this?
There's some people on Reddit that just don't like me. It happens.
Working on [a big PR](https://github.com/tomaka/glium/pull/1371) in glium to rework buffers. There are four types of buffer right now: regular (good ol' buffers), dynamic (good ol' buffers but stored in RAM instead of video memory), immutable (content inaccessible from CPU), and persistent (the buffer content is always accessible and the programmer must manually enforce memory safety). For the moment all four types of buffers use the same API, and everything is dispatched at runtime. This leads to weird implementations, for example writing to an immutable buffer is done by creating a temporary buffer, writing to it, then asking the GPU to copy the content to the real buffer. The PR would split everything in three different types of buffers (regular + dynamic grouped in one), so that the API is more correct. This also solves another problem right now, which is that you can't choose the locking strategy of persistent mapped buffers. For example the Rust stdlib provides two different strategies: Mutex and RwLock. I'd like to use a similar design in glium in order to allow the user to choose which one suits best. 
As a noob to Rust and systems languages in general - I have been rewriting gnu coreutils as a practice exercise. I have completed `wc` and am now working on `cat`. Depending on how adventurous I'm feeling I may attempt `watch` next
As mentioned somewhere in the post, while the return type would be `impl Clone`, the function/method would only be allowed to return **one** concrete type. That is, `foo` can return `String`, but it can't have a branch that returns `i32` instead, because the caller needs to know the exact size and type of the return value. Basically, what the `impl` notation allows, is more encapsulation/less typing out of explicit types. For example when returning an Iterator from a function/method, the type can get quite long, which this syntax would shorten dramatically. Was that your question?
Hm, all right. Just for the record, [here's what the C++ implementation does](https://github.com/jubatus/jubatus-msgpack-rpc/blob/master/cpp/test/echo_server.h#L17). I'm guessing that without any runtime reflection that's what I'm stuck with.
&gt; In particular, it already doesn't apply to generic functions with trait bounds (if that trait provides a method). I've never understood this reasoning... instead of a trait bound, I could've written the function to take a `struct` as an explicit argument, containing the same functions/methods (i.e., manual dictionary-passing style). Would you say parametricity / abstraction safety doesn't apply to functions which have arguments? &gt; Notice that there is a third abstraction mechanism, and it, too, remains safe with specialization: Hiding mutable state in the environment of a closure. Hmm, why would mutable state have anything to do with it? But closures (trait objects) are also existentials, so yes indeed. &gt; Concerning the abstract return types, the way I understand the proposal is that the existential return type is only ever going to be instantiated with a newtype that nobody can name. Thus specialization cannot distinguish such types. My understanding... is the opposite.
haha yeah that tends to be confusing ;)
Yeah, I disagree, because these things aren't confusing except for people who are absolutely new to programming--and even then it's something you learn by rote in two minutes. I'm not saying Rust is a great introductory language because "hey, you learn abbreviations quickly," but let's be realistic about the relative costs, here.
I should hope that `impl A+B` would work, though that starts to get a little ugly. Once you're getting too specific, it's nicer to just return your specific concrete type.
I feel like it'd be a lot of fun to talk to you in real time. If you're ever on the IRCs, give me a shout at `ubsan`. You seem like a cool person :P
Wrong subreddit? Maybe you wanted: https://www.reddit.com/r/playrust/
`println!("{}", mem::align_of::&lt;[u8; 4]&gt;());` prints 1. There are proposed RFCS to add attributes to provide control over the alignment and packing of types, but at the moment you just have to have a field with the desired alignment. People often abuse `[T; 0]` for this since it has the alignment of T but a size of 0.
I think you only need `volatile_store` here, since you're writing to the pointer: `volatile_store((GPIO_BASE + LED_GPSET) as *mut usize, 1 &lt;&lt; LED_GPIO_BIT);` 
Nope, you can add inherent impls to any type defined in your crate: use foo::Bar; mod foo { pub struct Bar { pub x: i32, y: i32 // don't want any other module accessing this } impl Bar { pub fn new() -&gt; Bar { Bar { x: 0, y: 0 } } } } impl Bar { fn qux(&amp;self) { println!("{}", self.x); // this works // println!("{}", self.y); // error: field `y` of struct `foo::Bar` is private } } fn main() { let z = Bar::new(); z.qux(); }
&gt; A more powerful type system might be able to express useful collections traits, but not the one Rust currently has. Are we talking HKT(Higher Kinded Type)/HKP(Higher Kinded Polymorphism) or just a way to abstract over pointers?
What will you be talking about?
I'll know it when I find the time to actually prepare.
&gt; You get the interoperability between libraries while still encouraging competition on the implementation. And then there's this one new library which has the same problem domain but whose interface is much more efficient if expressed in a completely different way. The issue is that by consecrating *one* interface, you are kicking out competition on interface improvement.
Speak for yourself. For me, the key factor for the YCM support is allowing a consistent behaviour and configuration across multiple languages so muscle memory can be built effectively. It isn't always easy (or even feasible) to get everything behaving consistently if you're reinventing YCM from bits and pieces.
&gt; It is not OK for foo to return `A` in one branch and `B` in another, the programmer must choose one data type and return a value of that type in all branches. &gt; [...] &gt; If `foo` could return different types depending on the branch taken at runtime, the compiler can't know the size of `x`. An upper-bound of the size of `x` is sufficient, so the size argument does not hold. It might be worth focusing on the more important point of knowing whether to call methods from `A` or `B` without a virtual look-up. 
Ah that makes sense, learning a new workflow for every lang is a pain. That was one reason go's curly brace rule screwed me up so much!
This has always felt like a bummer to me, too. Especially since `flat_map` is used on iterators, so it even has precedence. They could have at least renamed `Option::map` to `Option::then` :P
&gt; **Notable changes** &gt; - Feature gate defaulted type parameters appearing outside of types. &gt; - Make ".".parse::&lt;f32&gt;() and ".".parse::&lt;f64&gt;() return Err. &gt; - Add std::panic::propagate. &gt; - Cross item dependencies, take 2. Adds dependency graph for incremental compilation. &gt; - libstd: unix process spawning: fix bug with setting stdio. &gt; - Add OpAssign to Wrapping&lt;T&gt;, etc. in core::num::wrapping. &gt; - [MIR] Refine representation and translation of calls. &gt; - Refactor and improve: Arena, TypedArena. A regular week in Rust-land...
The problem for me with something as simple as &lt;C-x&gt;&lt;C-o&gt; is that thinking about it, even for a moment, can interrupt *flow*. It's also a nice check for "am I doing what I think I'm doing?". If you're expecting completions and none show up, there's probably something wrong. In the &lt;C-x&gt;&lt;C-o&gt; paradigm, you can obviously still get that, but the feedback is not automatic in this case.
When I've presented on Rust at JavaScript conferences I usually throw in a joke about this, everyone laughs.
Like you said, I would read the book and go through RustByExample at the same time. There is some good source code out there as well, like the Mozilla servo project: https://github.com/servo/servo/tree/master/components/servo A simple web server is always fun to make by just figuring out what you need as you go. For most languages, I would say the best way to learn is by making things. Books and tutorials are good for reference, but IMO, the best way is just doing it. 
Yeah, last week was a bit slow.
Nothing would prevent alternative interfaces outside of the standard library.
Build something with the books as references. From personal experience, try to avoid FFI at first. I did a small project that used FFI as a learner project and found that I spent most of my time wrestling with Rust's build tools. It was instructive, but I don't feel like I learned a lot about Rust doing it.
should work fine, the examples only have a single bound (until the OIBIT one, which was missing), but the design accounts for multiple bounds.
I agree on the formal question part, but that formal question is based on some assumptions which are not (aiui) constrained by the model. I'm not questioning the maths bit, only the assumptions bit, which are absolutely about convention. You could assume that all code which affects unsafe code occurs in an unsafe block, instead you want to assume that only private fields can affect unsafe code. Both are enforced by convention only, neither is enforced by the compiler. Now you could argue that Rust programmers tend to program with the second convention, not the first and that seems reasonable. Thus its reasonable to claim that it is a better assumption. But I don't think there is anything intrinsically better about it from a formal perspective.
Also perhaps worth noting that even if fields are private, that is not enough since clients can still change your fields via transmute. So you either have to further assume that nobody accesses your private fields, or do some kind of whole-program analysis to ensure that doesn't happen.
&gt; Of course. This would be a horrible security problem, because you should always check untrusted input, and you should never trust network input :D Automatic updates do work in this fashion (they also verify a signature at some point, but the reason that the signature is worth anything is because the private key's owner is careful). Hypothetically, Rust's safety proof is supposed to be extended to a "whole system" proof of safety, which may even include other (trusted) computers. However, creating such a proof naïvely runs into the problem that one must ensure that every part of the program does not create problems for every other part. The way this is typically dealt with is modularity - invariants, each of which is only supposed to be relevant for a small amount of code, and which together are sufficient to prove the program's safety, are introduced. This part can even be done in a language like C. On the other hand, one has to be sure that every line of that small amount of relevant code is known. The privacy system allows to automatically prove that all freshly-added Rust code is not relevant. However, unsafe code can trust everything it wants to - various functions (e.g. `sort`) working correctly, messages signed by a particular key being valid, etc. - as long as one remembers that this becomes an obligation for the safety proof.
&gt; Hmm, why would mutable state have anything to do with it? But closures (trait objects) are also existentials, so yes indeed. I was quite sure that closures are implicit compiler-generated "private" structs and not existentials, Certainly you can write every function that is written with closures equivalently without them (up to the zero-sized lifetime truncation thing, but that is just nitpicking).
&gt; The way Rust works right now, the correct answer is "at least everything in the same module". No. The correct answer is "anything that is trusted by the unsafe code". If the unsafe code trusts some standard library function to operates correctly, then that has to be proven. If the unsafe code trusts some field to hold an invariant, then every function that touches that field has to be proven. In the latter case, we may know that all these functions are in the same module as the *struct* (note: the trusting unsafe code may be in some entirely-different module).
So with this declared, would I be able to do this? let mut sample_union: UnionType = UnionType{y: "a"};
/r/playrust perhaps? This sub is for Rust the programming language.
This is a subreddit for a programming language. You want /r/rustgame.
Congrats!
I doubt `concat_idents!` will ever be made usable. I believe that is something they intend to fix with the new macro system that is coming eventually in the distant future.
Thank you!
Hahaha, not in the slightest. You'd have to do `UnionType { _union_data_: 0 }` and then invoke `y_mut` to get a mutable pointer and assign the value you want to that. Furthermore `"a"` is a string which is not a `char` so if you want a `char` you'd have to do `'a'`.
 trait Nothing {} impl&lt;T&gt; Nothing for T {} trait Lambda { fn apply&lt;T&gt;() -&gt; impl Nothing; } struct BoxL; impl Lambda for BoxL { fn apply&lt;T&gt; -&gt; Box&lt;T&gt; { unreachable!() } } fn foo&lt;L: Lambda&gt;() { let _: &lt;typeof(L::apply::&lt;i32&gt;)&gt;::Output; } // functionally equivalent to fn foo&lt;L&lt;type&gt;&gt;() { let _: L&lt;i32&gt;; } Note that even without `typeof`, you can still create values of that type and manipulate them.
Yeah I didn't think it would be that simple. On GitHub there were proposals to add unions to rust for a while now. Is there any development on that?
Thanks! Ooh, I like this idea but I do wonder whether I would just end up reinventing SWIG. 
ideally they would allow macro nodes in every position that idents, types, etc. are allowed. I think at the moment it's only in item (i.e. trait, function) and expression position. This is completely anecdotal, however, I'd love to hear a member of the language team chime in
Associated types normalize at every opportunity, while true existentials only normalize when you open them. I think nrc proposed that we type-check with the existential types skolemized, and add the necessary `open`s around the "MIR".
ok interesting!
You'll only learn by doing it. First thing I wrote was the simple board game [Reversi](https://en.wikipedia.org/wiki/Reversi) in the console.
https://github.com/hackndev/zinc/tree/master/volatile_cell Zinc-rs is overally a great project to investigate low-level Rust handling. Another is Redox and other Rust oses.
That is my bad, I suspect. It's been on my mind every now and then lately. Having said that, I once tried to have clang optimize some atomic statements and it didn't, so I'm not sure now aggressive llvm is in that regard.
Rust by example was already mentioned, so yep. Go read that. :-) What helped me the most was to rebuild a small project with Rust. Just pick some piece of code you're familiar with and rewrite it in Rust. Write some tests and from there on see how you can refactor your code to be more Rustafarian. :-)
Yeah, you can't get a list of field names in macro. But you can probably do that with [compiler plugin](https://doc.rust-lang.org/nightly/book/compiler-plugins.html). I also think that you don't need all that stuff, but I'm not sure what you're trying to achieve. I can imagine some case if type of `x` in both `Foo` and `Bar` structs is the same, but it isn't, so I'm wondering... Could you provide some real world problem and example how you're solving that right now?
Sure, every trait can be used as a type, but `X: Foo` doesn't mean that I can cast any `X` to a `Foo` without other coercions. Specifically here, closures can't be cast to those `Fn` trait types!
Working on adding DBus API and monitoring support to [Froyo](https://github.com/agrover/froyo)
For accessing different fields you still use `match`, right? And for creating a struct that contains `&amp;mut`s from enum you'll still have to use `match` (in your example you're creating this struct from another struct. how do you combine that with enum?). Anyway, for your case I would prefer methods. What about doing something like [this](http://is.gd/PM2Fkq)? 
For me it parses all the way through, but the weird thing about the file is that it seems to be only part of the file based on the numbers of samples it is reporting in the stream info. What I want to know is what OS you are using and if you are using the `--release` flags.
The database is compatible with other existing software? I would like to carry a copy of the database of passwords in my phone for accessing my account on websites from it. (I know a mobile application will come in the future, but I want to know if a workaround is possible in the mean time)
Rust at the moment is compatible with LLVM 3.5, 3.6, and 3.7. Note that some tests fail with 3.5 and 3.6 because there are tests specifically testing for LLVM bugs in those versions.
Oh that's a nice Cargo.toml. I'll have time later this week to investigate. Thanks for sharing your research. I am surprised that it's not working for the crates.io dependencies, though...
I recommend solving simple problems using http://play.rust-lang.org/ along with https://github.com/carols10cents/rustlings
How would that upper bound is going to be calculated? Wouldn't it require whole program analysis to find all types that implement the given Trait? 
One of them definitely isn't undefined behavior though. It's just not something we want to allow.
First read the [rust book](https://doc.rust-lang.org/book/), eventually take a look at the [rustonomicon](https://doc.rust-lang.org/stable/nomicon/), finally [rust-learning](https://github.com/ctjhoa/rust-learning) if you have further questions or need more resources
&gt; The rule is simple: if unsafe is used in a module, the module is unsafe and you need to Pay Attention. `unsafe` is not inherently related to module, only privacy is. You still have to carefully make enough things private so that the unsafety doesn’t "leak" outside the module.
Regarding this: https://github.com/rust-lang/rfcs/pull/1449 is it useful to pattern match on the bitfields?
If I understand it correctly, as you add more arguments, that approach starts suffering from a bad case of combinatorial explosion, though (you need _n!_ macro rules where _n_ = number of defined kwargs) 
Note that kwargs and default arguments are also independent.
would be awesome to auto generate ruby or python wrappers... just sayin...
Ideally, you would have all the common fields in a struct like so: struct FooContainer { first_common: i32, second_common: i32, variant: Foobar, } enum Foobar { Foo { uncommon: i32 }, Bar { also_uncommon: i32 }, } I believe the Rust team is planning on a method of enum variant inheritance that would fix this exact problem. EDIT: I really wish Rust allowed macros in any position (and parsed them as early as possible), so I could do stuff like [this](https://play.rust-lang.org/?gist=498de8bc42be72f873b0&amp;version=stable). No dice though, unfortunately. 
I have finally released a first version of Palette, which is meant to make linear color calculations and conversions between color spaces easy and accessible. Its features includes conversion to and from gamma corrected and sRGB pixel representations, operations such as lighten and desaturate, and linear gradients. It may be useful in areas like 3D rendering, photo manipulation, and some games. This is a first release, so there are still many areas that can be improved, but doing so will be easier with some user feedback. It would be great to hear what you think about the way things are structured, as a whole, the way colors are converted between color spaces, the generic `Color` type, etc., as well as anything else you thinks about it. What's good? What could be better? How could it be better? I hope you will find it useful and I'm happy to answer any questions.
If you get a nightly, that's currently build with an LLVM version very close to 3.7.1. Maybe we miss a commit or two, and there's only a small number of our own patches applied to it. Not sure if the latest LLVM upgrade is already in beta/stable, but these two should at least have 3.7.0 + some fixes that went into 3.7.1.
I'm looking into using rust to consume an http service with hyper. Serde_json is kind of picky compared to json.net... But there seems to be a change that will stop it from throwing errors on unknown fields. Crossing my fingers for that PR to come through. Finally figured out how to mock the hyper client, so at least I can test things now without needing to hit the network every time.
And we could reserve them all and never run out of keywords! (Until we reach zzz).
That's not a bad idea. sRGB is sort of both a pixel format and a color space (it has fewer colors than Adobe RGB, for example), which makes the RGB situation a bit strange. Having a separate sRGB type may be useful in any case, since it makes it possible to make use of the type system, as you said, and it may also be the best way to deal with the constructor explosion. I'll add your suggestion to the issue list. Thanks :) Edit: [see issue #7](https://github.com/Ogeon/palette/issues/7)
In other words: You have to pay attention when implementing the module.
Where do I send beer or cookies for your hard work? :D
The point of hygienic macros is that they correct some of the problems with textual substitution. One of those is that they prevent you from writing macros that depend on certain local variables being in scope and manipulating them in potentially unexpected ways. This can also be problematic if the macro assumes it's referring to something from global scope, but something local usurps the name. Essentially, hygiene encourages you to make your macros represent a proper abstraction with clear boundaries, which means making any dependencies on the calling code explicit.
3.8 hasn't been released yet, it's basically whatever's on the master branch. The release notes for 3.8 [say as much](http://llvm.org/docs/ReleaseNotes.html).
Yes it makes sense, I only have to redesign the program a bit. Luckily there is regexp ;-)
I think you mean /SUBSYSTEM:WINDOWS, because CONSOLE is what rust is giving you by default, but yes, replace `link-args=-Wl,--subsystem,windows` with `link-args=/SUBSYSTEM:WINDOWS` for msvc.
Yes, sorry, my bad. CONSOLE,5.01 was for the Windows XP support.
f64 support could be achieved by making the types generic over the component type. An other alternative would be to use a cargo feature to toggle it, but that could cause "fun" compatibility issues. White point awareness sounds like an interesting can of worms. I didn't want to touch that topic until I could get things up and running, but it's worth investigating. You are very welcome to join forces, as I mentioned in my answer to you on GitHub. The current restrictions are not permanent, so those could very well be future feature if they can be implemented in a good way. It has to be balanced against usability, as well.
This is why type classes that follow mathematical laws are preferred in Haskell. A formal basis for an interface usually has more staying power.
No, but you would lose interoperability.
Yeah, this is completely true, but it's as good as I could do without writing a compiler plugin (which I don't really know how to do and, anyways, wouldn't really solve much). EDIT: It's actually even worse! Suppose you have a function with `n + m` kwargs, `n` of them optional the other `m` mandatory. Then in fact the number of cases would be the sum from `k = 0` to `m` of `(n + k)! C(k, m)`. So yeah, pretty bad. 
&gt; #What It Isn't &gt; This library is only meant for color manipulation and conversion. It's not... &gt; * ...an image manipulation library. It will only handle colors, and not whole images. &gt; * ...an optimal pixel format. The colors are represented by linear 32-bit floats with a mandatory alpha component. It's not a compact format. You will have to look elsewhere for those features. Could an efficient image crate depend on `pallete`? Besides the fact that it is not a compact format, another issue is that image crates may want to process many pixels at a time, using SIMD or other technique. Or, would it be possible to run SIMD operations on a small array of colors provided by the `pallete` crate?
I'm not sure about SIMD, since I haven't used it that much, but possibly maybe. I'm not really sure about the best way to vectorize things, but it sounds like a desirable goal (without knowing too much). I have, however, had single pixel operations in mind when making it and there's [a helper trait](https://ogeon.github.io/docs/palette/master/palette/trait.RgbPixel.html) for component extraction that can be implemented for various pixel representations.
It is a promise. Perhaps one we cannot fulfill upon provably just yet, and we may screw up, but we still have that promise. It's part of the basis of safe Rust.
You might want to try [Exercism.io](http://exercism.io/). (Rust link [here](http://exercism.io/languages/rust)). You get to write programs that must past a test suite for each exercise and are then critiqued by other users. There are currently 27 exercises that range in difficulty.
First, I should note that the core of GJ is `gj::Promise&lt;T,E&gt;` and `gj::EventLoop`. The event loop's job is to execute a queue of event callbacks and then to call a `wait()` function once the queue is empty; nothing about this depends on any particular I/O library. I think GJ's I/O module `gj::io` can and should be broken off into a separate crate (perhaps named gj_io?). We could achieve that by defining an `EventPort` trait which `gj_io::MioEventPort` would implement. The `EventPort` trait would include the `wait()` function, which is "how to ask for more events". GJ's current dependency on mio is a private implementation detail of `gj::io`. Nothing from mio is exposed to the user. However, it would be straightfoward to add a way to, for example, construct a new `gj::io::tcp::Stream` from a `mio::tcp::TcpStream`, and also the other way around. 
The proof is about safe code calling this module, .e.g. "No safe code can call Vec in a way that causes a crash." Hence we can assume that the environment does not `transmute`. If they do, they have to prove themselves that this doesn't break anything.
*If* I have a freestanding module (not depending on any other module), and *if* all fields carrying extra invariants are private, then there are no conventions or anything involved. Code outside of the module cannot break these invariants, this follows from the privacy property of the type system. Of course, in particular the first assumption is a strong one. If your module calls other modules, you have to check whether you rely on more than just the question whether your dependencies are safe. if you do, there's more proof work here. Maybe the second assumption is what you call a "convention". I'd argue it is more than that. Having an invariant on a public field (of a public type) is just a bug, you are not going to reach your goal of encapsulating the unsafety if you do this. So, the only actual assumption I am making here is that the programmer actually has some interest in providing a safe abstraction. If they do not, well, sure - have fun ;-) Or maybe I misunderstood where you see a convention here?
I wish you used glium instead of sdl. Still, this is really cool and thanks for this tutorial!
To more directly answer your question: things are unlikely to "just work". mio has very a low-level interface. Libraries that use it directly are unlikely to be able to play very well with each other. That's why I think it's important that we develop higher level, composable abstractions. `Promise&lt;T,E&gt;` is my take on what one such abstraction might look like. 
You made an off-by-one error. `Stage0` is an actual stage (which usually starts with downloading a snapshot) so the whole thing ends at `stage2`. `Stage3` is normally used for building a `snapshot` (like the one used in stage0) and so it's fully optional.
Yeah, the second assumption is exactly what I mean by convention. I think perhaps we just don't agree on the definition of convention. I mean that this assumption is not checked. You are requiring the programmer to adhere to this restriction without checking it. We agree that you need such an assumption to do the verification work. However, I am arguing that you could rely on other assumptions instead. I don't think that from the perspective of the formal verification one assumption is better than the other. I.e., which assumption you should choose is not a fundamental property of the PL or the verification technique. However, one could argue that the privacy assumption is more practical to program against than a stricter assumption around unsafety.
I won't post this as an answer because I'm not sure if it's correct, but isn't it because it doesn't make sense to build an executable for a `none` platform? There's no operating system at that level to load the executable into memory and jump to its entry point.
Thanks! Do you know if there's a way to give different linker flags based on whether I'm compiling an executable or a library?
What about something like this? let nums: Vec&lt;usize&gt; = text.split(" ").filter_map(|x| x.parse().ok()).collect(); thingy(nums[0], nums[1], nums[2], nums[3]);
Wrong subreddit, you clearly meant to post this on /r/playrust
[The definition of `rustc_back::target::TargetOptions` might be of interest.](https://github.com/rust-lang/rust/blob/cf8b1ce250348c4b28dc922d49b0b2465329192e/src/librustc_back/target/mod.rs#L94) There seem to be `pre_link_objects_exe` and `pre_link_objects_dll` but I don't know how useful these are for you.
Huh. I thought that would pass in options. Oops.
Sorry, I forgot to remove that. I'll upload a new version tomorrow.
Couldn't you use mem::swap and remove the unsafe ? EDIT: I suppose you cannot swap 2 elements of the same slice ...
So your suggestion is to have the compiler create what is more or less an anonymous `enum` which implements the trait bound by deferring to its variants? I worry that the property of the return type always having the size of the largest variant would have unfortunate consequences when the caller of the abstract-returning function _does_ decide to box. If you have a function which returns a `Tiny` 99% of the time, and a `Huge` the remaining 1%, a caller who decides to `box` the result pays the space cost on the heap for a `Huge` every single time. 
It makes sense particularly when you think of the bound `A+B` as a bound on a new `trait _: A + B {}`.
My [awk clone](http://github.com/Xion/ap) is shaping up pretty nicely. Solved many parsing issues with integer &amp; float constants, had to some fun defining macro rules to shorten the code for binary operators, and finally added some tests. Right now I want to shift from "weak typing" that's basically redundant reinterpreting of various literals to type-tagging the AST at the parse stage. 
A CESK machine to interpret an obscure functional language.
Do you mean glutin? edit: oh, it seems that he is drawing with SDL instead of just setting up the window.
Also [Rust by Example](http://rustbyexample.com/)!
It's already included in rust-learning
Great to see GJ coming along! Is there a reason why `std::io::Error` doesn't implement `Clone`?
Well, yes, stuff needs to be manually checked - that's what unsafe is all about. Privacy of the fields is only a tiny little part of what you have to check. &gt; I don't think that from the perspective of the formal verification one assumption is better than the other. I.e., which assumption you should choose is not a fundamental property of the PL or the verification technique. Sure, there is some freedom you have in defining the theorem you want to prove, in particular, its assumptions. &gt; However, one could argue that the privacy assumption is more practical to program against than a stricter assumption around unsafety. By "stricter assumption", do you mean one where only literally the code within the unsafe modules has to be checked? There is some unsafe code that could still be proven sound - all unsafe code where the unsafety is "local" to the unsafe block. But most of the time, this will *at least* depend on some details of the safe part of the same function (like, bounds checks). Whether you have many small or one big unsafe block within a function is a matter of style (and, as far as I am concerned, semantically entirely equivalent). So, an alternative theorem one may want to prove is that every single function (that contains unsafe) is actually safe to use by anybody. This theorem would be useful. I think this is the practical statement that most closely matches the convention of "only deal with unsafe blocks", though I weakened this to "only deal with functions that contain unsafe blocks". However, it just doesn't hold for to many, many cases - e.g., Vec and RefCell. The way these data structures work, you need extra invariants on fields of these types, which immediately implies that safe code within the module can violate these invariants. The best you can hope for now is a weaker theorem: That Vec et. al. are safe to use from outside the module. This is the theorem we are aiming for with RustBelt[1], and you won't get this theorem if a public field of a public type has extra invariants on it. [1] &lt;https://www.reddit.com/r/rust/comments/401vy0/rustbelt_logical_foundations_for_the_future_of/&gt;
It is? Care to elaborate?
Ah, ok! I thought stage0 just downloaded the snapshot, I didn't realise it compiled anything. Thanks for clarifying. So, just to make sure I update it right, do I just need to shift all the bits of information back one stage? ie: information I give in stage1 is actually part of stage0, information I give for stage2 is actuall stage1?
Thank you! I'll update the article with the link to those docs, and the extra make target!
The problem is that the Rust compiler still relies on unstable features, so a stable compiler would not work. But I agree that the compiler should aim to be able to be compiled from stable and get rid of downloaded snapshot at some point in the future.
Fair enough. At least the binary is verified using a hash (SHA1 though, which is not recommended for any use, but anyway...), so it should be fairly safe.
From memory it caches the snapshot, so you don't need to download it every time you build it. And it's not downloading source code, it's downloading a binary of an older compiler. If you wanted to rebuild it 'from scratch', you'd have to go all the way back to the ocaml source, and spend weeks waiting for it to compile its way through the entire history of changes. But then how do you compile ocaml? _If you want to make an apple pie from scratch, you must first invent the universe_
Done! Thanks.
The reason I need the unsafe is because of the pivots dereference. If you check the source code, today I have pushed an improvement that uses insertion sort for smaller slices that uses swap but does not require the unsafe block. 
I struggled trying to benchmark the code with cargo bench (my first rust project!). I did run some regular tests and timed them with "time". I got the same timings overall. The biggest difference with stdlib's sort as far I can tell is that the latter uses merge sort thus it requires extra space for allocating the sorted sub slices. 
As the stdlib currently needs quite a bit of nightly features to build, this is probably a while away. Snapshots are rather rare, though, so a certain stability is there.
It depends on what you're working on. A game console emulator is something where the results can be immediately obvious to a bystander, even one without programming skills. ^^\*cough\* ^^game ^^server ^^emulator ^^too ^^shameless ^^self ^^insert
SHA1 is not not recommended for any use. It is only discouraged to use it whenever collision attack is possible, which mean checking arbitrary data like downloaded file from untrusted source (so you are right that this is dangerous). Git use SHA1 and there is no security issue with that. Firstly, becouse SHA1 wasn't used as security guarantee, and secondly, because Git hashes relies on second preimage attack resistance which SHA1 is still providing. 
It's likely because you are using an old version of nix, or something that depends on nix. Try running `cargo update`.
I realize this is just starting, but on the inside I'm all &gt;Please work on Linux, Please have netplay! Mupen 64++ on debian is such a pain. Have to download the gui seperatley and even then I can't remap the pad!
Maybe you can use [this](http://panicbit.github.io/monster/monster/incubation/fmt/fn.format.html). I'm willing to add more functionality if you need it. Just poke me here or on IRC.
According to an issue of nix reported at https://github.com/carllerche/nix-rust/issues/218 , c_char change on ARM in 1.6 causes this problem. How can I solve this problem when nix crate is not upgraded to libc v0.2? Through some Cargo.lock magic? 
Thanks for the heads up. 
Maybe you could create a local repo, fix it and then [override it in Cargo.toml](http://doc.crates.io/guide.html#overriding-dependencies) (if you do, it would be a good idea to share how you fix it, so upstream can be fixed!). Don't know whether this works for dependencies that in turn depend on nix, though.
No problem. It's a relatively high priority thing, like, Debian (and other distros) really needs this.
How is Servo now? Like if I downloaded it and went to https://www.reddit.com/r/rust/comments/40qqfg/this_week_in_servo_47_steady_improvements/ what would happen? Also was there an official alpha released? I remember that being a proposed goal on the previous road map. In any case Servo seems to be improving a lot, well done team :-)
Well, even if SHA-1 is still considered secure for specific applications (such as HMAC-SHA1 and similar), it's still not **recommended** over SHA-2 for new applications; nobody recommends MD5 either, even though that is also secure in some scenarios. SHA-1 has been considered "broken" since long before Rust development started, so I don't really see a valid reason for the Rust build system to pick it over SHA-2 (or SHA-3 for that matter). Recent developments indicate that SHA-1 is even more insecure than previously thought: https://www.schneier.com/blog/archives/2015/10/sha-1_freestart.html. We should move away from it ASAP.
we have different definitions of interesting then
Are these going to be archived on Youtube for people who can't watch live?
Reddit is one of the more usable sites in Servo, since it doesn't use any particular new and flashy JS features.
I am not suggesting anything, I am just remarking that computing the size is a non-issue. There are plenty of arguments in favor of keeping things simple and restricting to a single type, but computing the return size is not one of them.
Maybe my information is out of date, but I was under the impression SHA-3 could still use some more time to bake academically before adopting it whole-hog. 
Huh, interesting idea, thanks! I hadn't thought of using an iterator.
Yeah, I can only handle little-endian elf files. I couldn't think of a way to handle big-endian ones without copying
You could at least also run `wrk2` which is almost exactly like wrk but force-feeds the server a given request rate. For example, Hyper seems to perform well under wrk, but wrk2 exposes the fact that Hyper can't actually handle much concurrency (it completely chokes on more than ~100 req/s)
It's going to be an `rlib` once it's feature-complete (e.g. supports the `std` crate), but right now it's an executable.
I don't think B=Belongs is right, is it? The two B- tags are B-unstable and B-RFC-Approved, neither of which seem to indicate a misplaced issue.
But `cargo test` runs on your host system, not on your target system. How should it test your OS if it's not running?
Wow, the timing of this could not better! I'm trying to teach myself Rust by writing a library for opening and reading TDMS files and your library has a bunch of examples of approaches I can learn from. Thank you!
This will be interesting to watch as someone who's new to Rust. Especially since the N64 hardware is pretty complicated compared to, say, the Gameboy or NES. 
I forget, to be honest. `B-` was one of the labels that was least used, so I don't remember. Both Belongs and Blocker sound reasonable.
I like the idea but, in my experience, RetroArch is "equally horrendous UI for all emulators". If I can ever make time to get my idea for a unified game launcher up to 1.0, maybe I'll also write a libretro backend for it.
I started doing exactly the same thing today! So I'll avoid looking at your code, as tempting as it is, so I can see what I can do by myself.
I just managed to successfully flash this onto my Photon :) I now get some rustful LED blinking.
Have you tested this on a big-endian system? It seems to me that you would run into issues in the places that you cast to `u16`, as the byte order would be swapped. Also, I'm a little bit worried about alignment assumptions that you might be breaking. A `&amp;u16` pointer is guaranteed to have the bottom bit cleared, while it looks like you might violate this with your code. Those caveats aside, this looks like an excellent library!
That's a good question. When building against a target platform different from the one `cargo` is running on, `cargo test` doesn't have an easy way of running the tests. However, it could produce a binary that, when executed on the target machine, prints the results of the test run.
Huh. I guess I'll start by cross-compiling the `test` crate and going from there. E: crap, it wants a bunch of crates, including `libc`.
I think it's totally critical to get interoperability for mio-based libraries, so that I can use one that do websockets and another that do capnproto RPC or something like this. But I actually wished something more complex, like: have two mio-based libraries, A and B, in such a way that A can spawn B jobs and vice-versa, and schedule them (as "green threads") among N pre-defined threads. For example, a library that does web scrapping, takes some data that will be fed to another service, that will return data to do more scrapping.. the "library that does scraping" and the "library that talks with service X" should be independent of each other. It would also be nice if, despite combining A and B this way, the shape of the event loop remained fully accessible to the application that is using those libraries (unlike, say, libuv). So I could schedule A's jobs and B's jobs in dedicated threads or something like this. Anyway, I found [rotor](https://github.com/tailhook/rotor) - "The mio-based framework for rust for doing I/O in simple and composable way". What do you think?
Not sure if this is an improvement, but when parsing an &amp;str from a byte array you could do something like this: use std::slice; use std::str; fn main() { let bytes: &amp;[u8] = b"what\x00ever"; let pointer: *const u8 = bytes.as_ptr(); let mut len: isize = 0; loop { let peek: u8 = unsafe { *(pointer.offset(len)) }; if peek == 0u8 { break; } len += 1; } let slice: &amp;[u8] = unsafe { slice::from_raw_parts(pointer, len as usize) }; let sub_str: &amp;str = str::from_utf8(slice).expect("Failed to parse str"); println!("{}", sub_str); } the difference being using `slice::from_raw_parts` instead of a raw Slice and `str::from_utf8` instead of transmuting the raw slice into an &amp;str
Yeah it's awesome, but I wish he would also write articles. He proposes the project for learning game programming, but it's very hard for most people to watch all videos. There is [this guide](https://hero.handmadedev.org/jace/guide/) that helps navigating the content, also stuff like [this](https://hero.handmadedev.org/jace/iker/handmade_hero_week_010.png), but few people will be able to watch everything. Fortunately he can work out some written material at some time in future.
Yeah, I think avoiding transmutes is probably a good thing - and the two functions you suggest offer some beneficial abstraction. I'll change to use `from_raw_parts`, I'm in two minds about `from_utf8` - I'm not sure if the utf8 validation is worthwhile - I don't defend against a badly-formed ELF file anywhere atm, so I'm not sure if it is worth doing so here.
Hmm... For what it's worth, today I was linked to [this fascinating example](https://github.com/youngspe/rust-http-async), which is making me reconsider my opinions about mio interoperability.
The biggest challenge you'll face is probably porting `std`. It requires a lot of stuff that Xen probably doesn't handle, like threading and I/O. It might be better to code your own test runner that builds the binary, load it into your VM and boots it. I think most VM suites are scriptable to some extent.
You can avoid the `unsafe` search by using iterators, either a `for` loop or the preexisting adaptors: let len = bytes.iter().position(|x| **x == 0).unwrap(); (With the `unwrap` substituted for the appropriate handling code for when there's no `b'0'` in `bytes`.)
I think I ended up with `usize` because `take()` uses it.
This devices are really interesting. In a price similar to Teensy Board, they pack WIFi and more flash and RAM. Are there any drawbacks over Teensy? Can this be used for anything?
For development purposes, you can probably get away with having most everything else stubbed out as long as you have support for memory allocation. It's a common pattern to turn panics into aborts for platforms that don't support unwinding yet. I don't know what support Xen has for exception handling, you probably know a lot more about that than I do. That'll cover a large number of crates that don't touch threading, the filesystem, or networking. Your primary goal after that should probably be (IMO) threading and synchronization primitives (mutexes, read-write locks, and condition variables). It looks like Xen has some kind of capacity for both of those items. That should be enough to get `libtest` up and running which appears to be your primary goal, judging from your previous posts. After that, it's up to you. Probably some sort of rudimentary filesystem and networking.
Sorry, I phrased that badly. What I meant is that `u16` has 2-byte alignment, so any pointer to a `u16` must have a value that is a multiple of 2 bytes. Since you are creating these pointers from an arbitrary buffer of bytes, there is no reason for the alignment guarantees to be satisfied. This won't show up in normal execution, I think, since x86 doesn't mind unaligned loads and stores and since when you allocate a `Vec`, its backing buffer is aligned. However, I would not be surprised if this library crashed on ARM if the file is stored in a `Vec` with one padding byte at the front to misalign everything.
Great stuff! I am new to Rust as of last week so I am looking forward to listening! (just subscribed - will be listening on my commute)
Someone needs to propose some interesting twist on traditional network stacks to force y'all to get that into shape!
Management-by-nerd-sniping That's a new one.
Replace the body of the function with `unimplemented!()`, except for `rust_panic` which should probably scream at you somehow.
Oh, so you're saying I should patch the actual crate source code? o_O I'd assumed Rust had a more principled approach to porting `libstd` somehow.
Yeah, I'm unsure where to draw the line in assuming the input is good. Right now I just assume it is. But I feel like some basic verification would be nice. OTOH, I don't want to go to the other extreme and do a full verification of the whole file, although I guess there might be a place for that.
This is true. I assume that reading in the file won't introduce that kind of misalignment and the data in a Vec would be aligned to at least 4 bytes - I'm not actually sure if that assumption is fair. Perhaps `open_file` should allocate a Vec&lt;u64&gt; to ensure proper alignment.
Try emulationstation, which is a much nicer frontend for retroarch (and the core of retropie if you're into that sorta thing)
Trouble is, in the presence of a badly formed enough ELF file, I think just about every function can cause memory unsafety. I hope this is easy enough to fix with bounds checks before we call the parse_* functions, but until we have those checking for utf8-ness seems secondary
SSL on the GPU
Excellent. So, this is an interesting thing I'm wrestling with, and the idea of a "solver" comes into play--I'd like it to have the possibility of working with zero allocations, because I'm finding complex roots in a realtime audio synthesis program (finding the resonances of a linear filter). But is a "Solver" or a "Workspace" (in the GSL sense) the more Rust-like way to do things? I've seen it both ways in various crates.
http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7280966 (Caution: random idle speculation after this point) You know, if we continue with this everything-on-the-GPU stuff, we're going to hit the roadblock of GPU safety at some point. I wonder how games deal with this. Reminds me of how folks used CPU parallelization for years before the fundamentals for safety were figured out, and we only recently got Rust as a way of dealing with it well. Though there of course have been other solutions out there. Maybe 10 years from now GPUs will be used so much that someone comes up with a better/safer/more logical shader language. Or something. _hypes for Vulkan in the meantime_ 
The standard library necessarily relies on operating system calls to do stuff (e.g. read a file, open a network connection, allocate memory, create a thread...). Introducing a new target implies adding support for that target. I'm not sure what a more principled approach would entail in this case. 
Thanks, this project seems cool! :-) I will try to look at this this week-end!
That's a strong coincidence! At the start, a friend needed a packet sniffer for his student project. I offer to him to write a simple piece of code to do that in Rust :-) Happy codding ;-) 
`heap::allocate()` specifies alignment. Looks like `jemalloc` tends not to go below 4, for compatibility with C optimizations.[1] I think you could port Rust to use a more compact allocator, without breaking explicit guarantees, and without hurting interop with the average C library. [1] Search "--with-lg-quantum" in https://github.com/jemalloc/jemalloc/blob/dev/INSTALL (Now I'm wondering if Rust's type system effectively provides more alignment information, and how much that buys you... I guess functions prefer e.g. &amp;str to the aligned String type, so they'd have to be inlined or otherwise specialized). A production elf library would just use `mmap()`, and then everything is aligned to a whole page :P.
I know, I know, but they're finally starting to care about the user experience now that they're using the lakka frontend. I use retroarch for everything (Wii, Phone, Linux), when it works it's wonderful, I attach my xbox360 controller and play (no configuration required). I use Ubuntu, I had the worst experience with Arch because the package has no sane configuration.
Love this podcast, thanks for making it, chriskrycho! I really like this information dense, short, one person format. 
Here is the link to the discussion: https://internals.rust-lang.org/t/libsystem-or-the-great-libstd-refactor/2765
Yeah I think I played with that bit, my interest sort of died with the lack of netplay however. (Unless I missed that)
I think there is a toolkit called conrod, I haven't played with it, but I'd bet there is a tutorial somewhere.
There is the [gtk](https://github.com/gtk-rs/gtk) binding.
I compiled it and ran the demos, but they were fairly buggy. Most of the controls would lock up after only a few clicks.
maybe do it like elm? where the controls don't know about each other, but can only modify a state object and return lists of tasks, the results of which can be routed to other controls. 
Much better syntax, I really haven't been following it. I just wanted to show how things are slightly different.
In my experience, returning a list of tasks is leading to a horribly complex code. Imagine a widget is interacting with 2 other widgets. There may be millions of combinations of actions that it may want to do. Returning all these in a Vec and then handling in parent widget is IMO an awful solution. Another problem is that sometimes a widget needs to check some states in some other widgets. Returning actions doesn't solve this problem. I don't know anything about Elm, but "modify a state object" &lt;- this part sounded like it'd have exactly the same problem: Widgets would have to share a mutable reference. That would potentially solve the "cyclic reference" problem though.
Well in a way, `libstd` is similar because you 'only' need to implement a few system calls. I imagine if you provide `libc` for your target you're most of the way there.
Rust can run on bare metal, sure, but I never thought a single boson would be sufficient!
That's the current "testing" branch. Freeze should happen in December 2016, and the "stable" release somewhere next year. Jessie still is the current stable release.
No problem ;-)
It's not exactly a full GUI system yet, but I'm working on a safe abstraction for using Direct2D to draw UIs on Windows, so hopefully some day it could be used as a backend for a more complete GUI toolkit written in pure rust https://github.com/connorcpu/direct2d-rs
While some of those may be more intuitive than RetroArch, all three have the same fundamental problem: I don't want an XBMC-style interface. When you're using a mouse, they're frustratingly slow and inefficient UIs. What I really want is something more like Snes9x-GTK's UI. * https://doc.ubuntu-fr.org/_media/ss1.png * http://www.linuxnanet.com/wp-content/uploads/Snes9x-config.png That's why I was thinking I might start work on turning [this](https://github.com/ssokolow/game_launcher) into a RetroArch frontend once the GUI is more than just a tester for the heuristic backend routines. (Perhaps I'll try to hook into [Antimicro](https://github.com/Ryochan7/antimicro), take the output of its GUI for defining SDL2 Gamepad API mappings, and use it for non-Antimicro things)
&gt;I imagine if you provide `libc` for your target I'd actually rather avoid that :P
Did you see https://crates.io/crates/chan/ ?
I did, but I thought that it wouldn't help me, because its README states that: &gt; chan's synchronous channels have comparable throughput with `std::sync::mpsc`. Anyway, since you've mentioned it, I decided to give it a try. The result is about the same as with `mpsc::sync_channel`, confirming what the README says.
What's the difference between this and [elmesque](https://github.com/mitchmindtree/elmesque)? More backends?
Platform is linux, specifically ubuntu linux. 14.04 rustc 1.7.0-nightly (1447ce78f 2016-01-13) I didn't use strace yet because I don't have it. I have to generate the images that I'm running the rust code on with buildroot, and my buildroot configuration is currently under development. But I'm working on it. Yes, I am using --target as you've mentioned. I've configured my rust toolchain to have the musl compiled standard libraries to link in when it is building.
Option 2 is brilliant! I tried the `sync_channel` with a fairly large bound (~44M), but this alone didn't help at all. Only after I started sending a buffer a particles, I got the same performance as with `channel`! I already [updated the code](https://github.com/evoL/reactor/blob/1956a9740f4a55bdfa3dca9adb65c8cac77f6094/src/reactor.rs). Huge thanks for the help!
Ah, sorry, I missed that.
cc /u/danburkert
/u/gchp A guide to compiler internals is one of the pieces sorely missing from the [contributing](https://www.rust-lang.org/contribute-compiler.html) page. If there were some documentation of this sort either in-tree or on the hypothetical wiki I would link it from the website.
Okay, I tried to reproduce your problem with this simplified version: extern crate libc; use libc::{mmap,MAP_SHARED,MAP_FILE,PROT_READ,PROT_WRITE}; use std::fs::*; use std::ptr::null_mut; use std::os::unix::io::AsRawFd; fn main() { let file = OpenOptions::new() .write(true) .read(true) .open("/dev/zero") .ok() .expect("failed to open mmap file as read/write"); let p = unsafe { mmap(null_mut(), 1024, PROT_READ | PROT_WRITE, MAP_FILE | MAP_SHARED, file.as_raw_fd(), 0) }; println!("{:p}", p); } I'm using rustc 1.7.0-nightly (49c382779 2016-01-12), libc 0.2.4 and build on Ubuntu 12.04.5 with the same target. strace reports correct values (mmap(NULL, 1024, PROT_READ|PROT_WRITE, MAP_SHARED, 3, 0) = 0x7ff59d054000). Can you try this with your setup?
I like the new docs page. The old section was kinda disappointing because if only fit 3-4 sections or whatever it was. Pushing to a new comprehensive landing page really seems smarter than showcasing 3 items and hiding everything else behind a link. Nice.
I found the FAQ surprisingly helpful and summarised.
Not directly, but there's a trick: let i_wanna_know_the_type: () = ... Whatever you put on the right there will be a type error, and the compiler will tell you about it.
This moves: let x = y; (Assuming y isn't `Copy`) This does a borrow: let x = &amp;y; Same syntax for functions. It's even more obvious when you annotate the type: let x: SomeStruct: = y; let x: &amp;SomeStruct = &amp;y; fn takes_ownership(x: SomeStruct); fn does_a_borrow(x: &amp;SomeStruct); Swapping them for function calls would be more confusing, imho. I guess we could use `move` instead? fn takes_ownership(x: move SomeStruct); fn does_a_borrow(x: SomeStruct); But now it's opposite from everywhere else that you annotate a type. 
`rustc -Z unstable-options --unpretty=hir,typed` or even `cargo rustc -- -Z unstable-options --unpretty=hir,typed` (although I don't know where the output goes for the latter). **EDIT**: update for compiler changes in last few months.
I thought that it went away! I guess it just changed from `pretty` to `emit`.
&gt; Top level navigation is simplified. I had become attached to the dropdown menu before the change. :(
One of the reasons would be that other languages like C/C++ do it like this too. It may seem strange when you come from a managed language but it's basicly the default in languages where you can choose between move/copy or referencing something.
I'm glad! We took a lot of care to make the questions approachable for people with minimal background knowledge. A few of the answers in particular (mostly the Unicode-related answers and higher-kinded types answer) went through a half-dozen revisions before landing on the answers you see in the final document.
Sure it would be confusing, but move and many other things that differ from C are confusing too.
Yes. However, I think that wouldn't be a great way to do it. Silently putting things behind a pointer, and then verbosely just giving you the thing feels backwards to me.
Move doesn't differ from C because C doesn't have anything like affine types: all C types are `Copy` and C has no implicit borrowing, just explicit address-of.
Will this keep up with the pace of Rust releases? I think it's _amazing_ that the Rust team is pushing for a fast release cycle the same way browsers have, and it'd be a real shame if distro packaging slowed the cycle.
After a few days spend getting it to compile (mostly my fault), I found rgtk to be good. Their documentation is currently outdated, but the library acts (almost) identically to the C version, so you can just use that documentation plus the source. Since it's a wrapper, the code won't be very idiomatic though. Oh, and I'm using the version that's currently on github, not the one on crates.io.
I like conrod for its implementation of the actual handling of the ui programming, but I think it's lacking widgets at the moment, and the look of it isn't native. Though personally I have a soft-spot for programs with non-native GUIs - they look interesting if done well.
Good c++ is move by default these days even if the language can't inforce it as a default
Hehe, I'm glad I'm not the only one that does this :) Issues like this are why I'm most excited for a real Rust IDE. The biggest thing I struggle with regarding crate documentation are the examples: they all assume you know the types/enums being used. So the examples are all minimal with no type annotations. Sometimes I can reason out the major types, but sometimes I just have to c/p the code and manually break things to see what the compiler says. Hopefully an IDE will just tell me in the future. 
&gt;That works, and that's great. What do you mean by that? Have you verified that mmap() syscall is being called with correct parameters using strace/gdb/whatever? &gt;But for me, the mmap callback that I've implemented in our custom driver You're moving too fast here. Rust (or libc) doesn't know about your custom mmap callback. It just calls the regular mmap() syscall, which goes through (skipping arch-specific magic) regular [do_mmap](http://lxr.free-electrons.com/source/mm/mmap.c#L1263) into [mmap_region](http://lxr.free-electrons.com/source/mm/mmap.c#L1537) and then calls your [callback](http://lxr.free-electrons.com/source/mm/mmap.c#L1625). Why is your callback not seeing what you're supposedly passing? Probably [this](http://lxr.free-electrons.com/source/mm/mmap.c#L1312). 0xff = VM_READ | VM_WRITE | VM_EXEC | VM_SHARED | VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC | VM_MAYSHARE // i can't figure out where VM_EXEC comes from, that's strange
&gt; Personally I liked the old navigation more, the links in the new one seem so huge in comparison. :) I'm also not in love with it, but it was simple to do and it looks basically fine. The bigness is a bit weird. I'd be happy to see iteration on this basic concept, but I'm personally not going to be tackling it in the near term. /u/AndrewBrinker has some other mockups [on the issue thread](https://github.com/rust-lang/rust-www/issues/175) that look nice, but I do basically want less information in the navigation bar, not more. &gt; I would however put a link to the FAQ from the homepage. Good idea. Every change to the home page is tough. Stuffing new information in needs to be done carefully to preserve its qualities. &gt; The only thing I can think of for improvement is to use syntax highlighting for examples. Yes. [Issue](https://github.com/rust-lang/rust-www/issues/246). I spent like half an hour trying and decided to punt. Help wanted. &gt; it would be awesome if it could be fleshed out with an intro to the code base explaining the main areas I want this guide to the codebase, as an external resource, maybe in-tree or on the hypothetical wiki. /u/gchp said they were poking at it. &gt; how to compile, make changes, submit a patch and go through the reviewing process This information exists and (I think) is linked from the contributing pages, but isn't laid out in a single place like [this guide](http://gregchapple.com/contributing-to-the-rust-compiler/) that /u/gchp wrote. I definitely agree it needs to be presented better. We could link to gchp's blog post directly. gchp maybe you could think about how to integrate your concise guide with our website and the information already available on these topics? 
If you think you might be able to reproduce these issues you should try and report them as bugs. I know of a bug with the underlying input framework they use on OSX that makes it feel bad, but there could be more bugs like that that you can help nail down.
Looks much cleaner! Thanks for all the effort.
Yes, I know that mmap is being called with what we expect it to because I have a modified version of the rust-mmap sitting locally with a println statement right above the libc::mmap call as I described in the original post body. If you just change the file being opened, it will call the respective function that corresponds to the file_operations specification that has be registered for the corresponding char device. So in my case, in my kernel module init, I create and register a suite of class, device, and char device items. This places the "my_device_file" in /dev, and ensures that when a userland app opens the file, the functions in my module are executed as per respective operation. So, read calls my read, write to my write excetera. When I originally wrote my response to your test, I was contrasting the events between my program working on my device versus /dev/zero. Ahhh. Ok. So now I gotta figure out why it strikes that segment of kernel code for my device file in /dev and not for /dev/zero!
I think that multirust is still more convenient if you sometimes use unstable stuff. (and unfortunately, some interfaces will be unstable for a long time) But it would be *amazing* if I could install distro packages `rust1.5`, `rust1.6`, `rust-beta`, `rust-nightly`, etc. And have them all side by side, and then install a special version of multirust that simply switch between distro packages (and don't install or upgrade packages by itself)
And thanks to brson for taking such an active role in stewarding the website. :)
I've only just started with Rust and I found myself wondering a version of this too, just phrased slightly differently: why was the syntactical decision made that borrowing is explicit (with `&amp;` and `&amp;mut`) but ownership transfer is implicit (with no annotation on a declaration, parameter, or argument)? You could make an argument that it makes for some familiarity coming from other languages (like `&amp;` in C gets you a pointer). While I can appreciate the benefit that familiarity has for adoption, I think it costs more by decreasing the signal to noise ratio when reading code and making it less ergonomic to write. I personally want the most common case to have the least amount of syntax and I find that what one _usually_ wants is an immutable reference. More often than not if you own something you only want to lend it, and if you don't own something you only want to borrow it. The two places I find unannotated ownership to be the common case are in declarations/initializations and return values. So I find my code to be littered with `&amp;` symbols that wouldn't need to be there if an unannotated type meant having an immutable reference. So I was thinking about what that might look like and what implications it would have in a hypothetical redesign with a "reference-first" mentality. I kind of like what I have so far but I definitely haven't worked out all the hitches. I also wanted it to be minimally different, almost deterministically, such that one could run `cargo migrate` and it would take you from unannotated ownership transfer to unannotated references. Here's a sample of what I'm thinking (all off the top of my head, please forgive syntax errors). let a = "some text"; // a: str - still borrowed reference, because it's default now let b = "some text".to_string(); // b: $String - $ is the ownership symbol (arbitrarily, but only because it's not used outside macros so far as I know) fn my_to_string&lt;T&gt;(param: T) -&gt; $String { param.to_string() } // param is a reference to whatever is passed let c = my_to_string(a); // nice and clean let d = my_to_string(b); // also nice and clean, no &amp; because immutable borrowing/lending is implicit fn get_member(s: SomeStruct) -&gt; SomeOtherStruct { s.some_other_struct } // totally fine because parameter is borrowed and outlives the function fn get_member_illegal(s: $SomeStruct) -&gt; SomeOtherStruct { s.some_other_struct } // illegal because s' lifetime ends fn set_member(s: mut SomeStruct) -&gt; () { s.integral += 1; } // s is a mutable reference fn give(s: $SomeStruct) -&gt; () { set_member(s); } // s is owned and can be mutably lent let e = SomeStruct { /* ... */ }; // e: $SomeStruct, because to create an object is to own it set_member(mut e); // explicit mutable lending match e { // or: match mut e SomeStruct(integral, ..) =&gt; () // reference by default SomeStruct(mut other_field, ..) =&gt; () // e is owned and can lend mutably in matches _ =&gt; () } give(move e); // explicit ownership transfer The point is that you are explicit at the places where its most meaningful: requiring/allowing mutability or requiring/transfering ownership. I think such a system would result less syntactic noise and improved reading and writing overall. No doubt there are lots of difficult things I'm forgetting or just don't know about being new to Rust in general. I'd be interested in more history on how the current syntax came about and informed opinions on difficulties if my approache were put into practice. Tangentially related to syntax, is there a way I can create a closure/lambda without naming parameters? For instance, Scala allows `collection.map(_.toString)` as a short way to write `collection.map(e =&gt; e.toString)`. I'd prefer that to the somewhat noisy `collection.map(|e| e.toString())` that's in Rust now.
[removed]
you can even shorten that to let () =
Tried `cargo check --lib -- -Z unstable-options --unpretty=hir,typed` and it kind of works...(terminal flooded by messy output) Would there be something like `println!("type of {:?}: {}", val, typeof!(val))`?
We should really update this to use type ascription instead of comments. It would also be great if we could do this preserving the original source formatting, rather than using 'pretty' printing. If anyone wants to give it a go, it would be a great project and I'd be happy to mentor and help out.
https://github.com/rust-lang/rust/issues/30924 
After a substantial [rewrite to the core parser](https://github.com/shepmaster/sxd-document/commit/e2f3559693149d90788398455d64b4b48528cec4), I've released version 0.2.0. For a quick comparison, when reading, building a DOM, and then writing the DOM back out: |xmllint|SXD 0.1.2|SXD 0.2.0 ---|---|---|--- 16MiB|0.3098s| 0.8289s|0.5223s 111MiB|2.7244s|7.8759s|4.9285s
"More examples" on the front page of rust-lang.org
How much of that is file io? Can you time just the parsing?
Nitpicking: there's a "Nan" (note lower case N) at least in one place in the FAQ. Can someone please edit it? My connection is too slow :(
Something noticed on mobile on the FAQ, since its not meant to read linearly, a "return to top" link would be helpful to get back to the table of contents. It looks great on mobile though. 
Quick question, will the doc style change ? When I look at [that](http://i.imgur.com/qJzYFmV.png) I always have trouve to find the next function signature, they just don't stand out IMO. I always find the sub section titles ("Examples", here) first. Edit: great work on the new website. Clean, to the point.
Review after 3 episodes: I am glad I subscribed. I haven't checked out the code samples yet but the content of the podcast itself is great. You have helped enforce my own understandings as I have learnt some of the basics. I particularly liked it when you said "we will cover the move keyword in a future episode when, frankly, I understand it better myself". This is great and I feel like I will be learning along with you (as is the goal I guess... so kudos!).
I understand that (im)mutable references are their own first-class types. I guess I didn't think of `&amp;` and `&amp;mut` as operators - that's an interesting way to look at it. &gt; If arguments declared `arg: T` are actually of the type `&amp;T` I wasn't exactly suggesting the syntax results in that type. I was suggesting that in this hypothetical what is declared at `T` would have the same semantics as what is currently `&amp;T`. The idea being that the current `&amp;T` is what is usually called for and desirable and so should have the least intrusive syntax. So something declared as `T` would be of type `T` but would behave as `&amp;T` does currently. Then it wouldn't be far fetched to have what is currently `&amp;&amp;T` be `&amp;T` in the hypothetical system. In a sense the `current -&gt; hypothetical` mapping would be `T -&gt; $T`, `&amp;T -&gt; T`, and so forth, with the purpose being to reduce the amount of syntax that must be present in the usual case. &gt; Does this syntax apply to other type locations as well? I don't immediately see why not. But I am very new to Rust, so maybe? :) &gt; How does it account for explicit lifetime parameters? That I do not know for sure. I haven't truly internalized Rust's explicit lifetimes and how they're different from the C++ lifetimes I do understand. So far I've been treating them roughly as "this exists for at least as long as whichever lifetime I specify later". However I do expect that lifetime analysis would be largely same as it is currently. &gt; There are many more questions that will fall out from this. I believe that's true. I'm very much interested in those questions and answers. &gt; The most common syntax is `collection.map(Foo::to_string)` I think that's the syntax I was looking for, thanks. It's not quite what I was hoping existed, since if `collection` was, say, a `Vec&lt;T&gt;` I would want `collection.map(_.to_string())` to infer that `_` was an instance of or otherwise scoped to `T` rather than having to specify the type explicitly. &gt; these aren't either lambdas or closures (I don't know about Scala) I appreciate and understand the distinction. In Scala the expression would result in a truly anonymous function. So `collection map (_.toString)` would create a variation `def anon(t: T): String = t.toString` and then call `collection map anon`. That's very similar to `fn to_string(&amp;self) -&gt; String` as a member of `T` and calling `collection.map(T::to_string)` in Rust, except that in Scala the `T` would not have to be explicit. In Rust I'd even be okay with `collection.map(_::to_string)`. I don't wish to undermine the consistency behind the current rules. It might be nice to have less to read, write, and remember for the usual case. That's all.
I don't think its true in fact `&amp;T` is actually the most common case. It's quite common in arguments, but it is very rare in my experience to declare variables with `let` binding as references. Obviously, these are inferred and arguments are not, but even still I often do not pass by reference - it doesn't usually make sense to pass `Copy` values by reference, for instance. And not infrequently I do actually want to consume the argument. There's also the fact that Rust uses deref coercions in some instances. In brief, what you're describing has a huge number of edge cases and quirks that the current syntax does not. A set of rules whereby a pointer is `T` but a pointer to pointer is `&amp;T` and `$T` is "anything but a pointer" seems like hell to learn and think about (so is `$&amp;T` a pointer again?). A lot of simplicity flows from having a "zero" form and a "succ" form only. &gt; That I do not know for sure. I haven't truly internalized Rust's explicit lifetimes and how they're different from the C++ lifetimes I do understand. So far I've been treating them roughly as "this exists for at least as long as whichever lifetime I specify later". However I do expect that lifetime analysis would be largely same as it is currently. The issue is that the type `&amp;T` is actually an ellided form of the type `&amp;'a T`; every reference has a lifetime, the compiler just inserts it for you in most cases. You'd need another syntactic form for when lifetimes are explicit. &gt; I would want collection.map(_.to_string()) to infer that _ was an instance of or otherwise scoped to T rather than having to specify the type explicitly. I'd never tried it out, but it turns out this works fine: http://is.gd/4uJeIX
Are there any tracking issues in our bug tracker for improving packageability?
So what's happening is you're trying to move a value of type `ThunkParser`. But the instantiated send method looks like this: ``` fn send(mut ThunkParser, parser: &amp;mut Parser, node: Ast) ``` Which contains a bare unsized type. (Which isn't allowed, rust can't tell how big the object is). (Boxed traits are unsized, their size is stored in either the Box, or the VTable... I can't remember which) I can't think of way to fix this sorry. Edit: I think the above is actually wrong. But it's very close to what I think is happening. Anyway, boxed traits (like `ThunkParser`), `str` and `[T]` are all unsized and can only be kept in: `Box&lt;_&gt;`, `&amp; _`, `&amp;mut _`, `*const _`, `*mut _`. And inside structs that have them as their last member. (Then the containing struct itself becomes unsized)
Out of curiousity, that's without the [UTF-8 validation PR](https://github.com/rust-lang/rust/pull/30740), right? Edit: Gah, I messed up the math in my head and calculated with a 10% speedup instead of 1%... So with/without won't make that much of a difference.
Have you tried to get to the documentation from the homepage? I have like 5 bookmarks for various entrypoints to crates.io because the navigation leaves something to be desired.
&gt;There's a new FAQ. It is pretty damn comprehensive! Give it a read and see if your questions are answered. It would be nice if code in the FAQ was highlighted.
/u/brson as mentioned on the other thread, I'd be happy to contribute the guide I put together to the website. Just let me know what you feel the best way forward there is. Aside from that, I'm working on some in-depth docs for different pieces of the compiler. Right now I'm just getting started on a high-level overview of the general process, covering things like the driver, the different phases in compilation, that kind of thing. After that I'll start going through each phase in more detail, probably starting with the parser/lexer initially because I'm most familiar with those areas right now. Eventually I want to have all the major pieces of the compiler well documented so that when a brand new contributor comes along there is a single place where they can get information on whatever part of the compiler interests them. And also for those without the desire to contribute, who just want to know about how it works, how it is structured, etc. If there are any other areas you think would be worth touching on, just let me know. I hope to have the high-level overview in good shape over the next few days so it can get reviewed by some folks. Do you think an `internals` folder inside `src/doc` would be an appropriate place for this type of documentation?
I don't like that the specification for an argument is in two places. Some aspects are in "add_opt" but others are in "get". Can those be combined? let mut height = 0; let mut names: Vec&lt;String&gt; = vec![]; { let mut parser = ... parser.add_opt("height", "h", int_parser, &amp;mut height, "..."); parser.add_opt("names", "n", list_parser(str_parser), &amp;mut names, "..."); parser.parse(); } println!("height: {:?}, names: {:}", height, names) This still sort of sucks because part of the specification (the types) is still specified separately from the rest of the specification. Maybe macros can help? Re: zero-copy. Argument parsing usually doesn't need to be efficient. I think programmer-friendliness should be the highest priority. I'd be sad if making it zero-copy caused the API to be even 1% less programmer-friendly. But if your zero-copy changes don't affect the API, that's obviously great. And even if they do affect the API, have fun and do whatever you want :-) BTW, I'm new to Rust, so don't take any of this too seriously.
If you manage to pull that off, I might drop Elm and use that for the next project. Rust on the backend and the frontend would be nice, and if we can have native/web apps with the same code base, it would help the community quite a bit.
I'll just chime in and say that you don't always need to reach for async IO. *Depending on your performance requirements*, it would be perfectly acceptable to spin up a new thread for each type of I/O you're doing (tcp, file, another channel, etc.), and then synchronize on those using `select!`. If you want to use stable Rust, then you can use the [`chan`](https://crates.io/crates/chan/) crate, which provides mpmc channels and a `chan_select!` macro that works not only on Rust stable, but also synchronizes across both sends and receives.
Also having to go to the home page before you can then click on "getting started".
This looks great, the FAQ page especially looks awesome. One discrepancy I see: on the [Community page](https://www.rust-lang.org/community.html), /r/rust is referred to as "the unofficial subreddit", and in the [How Do I Get Help question in the FAQ](https://www.rust-lang.org/faq.html#how-do-i-get-help-with-rust-issues), it's referred to as "the official Rust subreddit".
...you head over to /r/playrust! (This is the subreddit for Rust, the programming language)
We're merging the biggest refactoring the rgtk lib ever had since our beginning, we'll post something about it very soon. The documentation will follow shortly.
Awesome work! I _really_ like how simple the homepage is, and the small number of links in the top bar. The documentation page could do with some smarter design in terms of typography though, to help break things up and be easier to read/scan.
[This video shows how its done.](https://www.youtube.com/watch?v=7SiOGC0Zm24)
Agreed. I was incrdibly impressed with the smart, reasonable answers in the ['other languages'](https://www.rust-lang.org/faq.html#other-languages) section in particular.
&gt; This comes up regularly. A large part (&gt;300k I think) is that jemalloc is linked in by default. You can switch to the system allocator if you want. Awesome, this reduced my binary size more than 50%! &gt; The last one at least is unnecessary (derive Clone and Copy). As for the lifetime variables, are you aware of lifetime elision? It should make many lifetime annotations unnecessary. Indeed, this also helped. I think I just removed about 100 `clone()` calls. I'll see what lifetime elision is. Thanks!
I'm working on [imag - a personal information management suite for the terminal](https://github.com/matthiasbeyer/imag). I actually removed the whole codebase to start over (I'm learning rust since about 2 months maybe) and re-implement everything seperated into several libraries and frontends for them(, like git is developed). The goal of the project is to provide a terminal-PIM-suite with the ability to _link_ content together. So your notes can be linked to your bookmarks, wiki articles, emails, contacts, calendar entries, shopping lists, RSS feeds/entries, music, videos, etc etc etc (and vice-versa of course). The program is for the commandline, but as developed as library + binary, you can use the functionality later to build curses/gui/web interfaces for it. I removed the codebase because I did not split the project into libraries+binaries initially, but developed everything as one big binary. Two modules (bookmarks, notes) were working before the re-init... At the moment, I'm writing up my goals and discuss with two others on how things should be done, how the library-interfaces should look like and so on, then the implementation phase will start and we will (re-)implement the functionality. Feel free to ask me questions and of course feel also free to add thoughts on the project, the ideas I/we propose and so on (also in the github issue tracker if you want to).
How would the device handle that? 
&gt; I don't think its true in fact `&amp;T` is actually the most common case. It's quite common in arguments, but it is very rare in my experience to declare variables with let binding as references That's one of the two cases I originally mentioned where owning is more common than referencing and was included in my examples. The inference mostly resolves it, as you suggest, and there would be an explicit way to express it as well; in my example that was with `$T`. &gt; it doesn't usually make sense to pass Copy values by reference, for instance Hmm.. good point. That's one of those things I hadn't considered. My history with C++ suggests implicit copying by default is not usually what you want as it can become a hidden performance loss. My immediate solution here is to require explicit copying in addition to explicit ownership transfer. Perhaps a `copy` keyword, similar to `move`, but with obviously different semantics. Although perhaps it would work out pretty much the same in the end. My understanding is the fact that it's `Copy` only comes into play when it would otherwise be moved, so right now passing to a `&amp;T` parameter would still not copy even if `T: Copy`. So passing a `Copy` to a `T` would be like passing to a `&amp;T` today, and passing to a `$T` (or `let` expression, which would also own/move by default - basically assignment with `=` is a request to move) would be just like moving today, which results in a copy. I also suggest that quickly determining when copying and ownership transfer occur is more important and useful than quickly determining when referencing happens. Referencing by default and being explicit otherwise helps that too. &gt; And not infrequently I do actually want to consume the argument And there would be an explicit syntax for that similar to how there's explicit syntax for borrowing today. I posit that consuming/copying arguments is less common than borrowing them, which is why I would be okay with trading explicit borrowing for explicit consumption/copying to reduce overall syntax. It would be interesting to me to do a larger study across the Rust ecosystem and see if that holds up. &gt; what you're describing has a huge number of edge cases and quirks that the current syntax does not. . .A lot of simplicity flows from having a "zero" form and a "succ" form only. No doubt that's true about edge cases. I'm interested if you'd like to lay them out for me since I don't see them immediately. I have only been musing on the problem sporadically for maybe a week and came up with the syntax on the fly. And I agree there's a lot of simplicity in the current system. But even if my sample syntax isn't quite right I don't think that makes my goal infeasible. I definitely wouldn't want some incoherent and inconsistent language in the end. I haven't thought of or even attempted to lay out every change that would need to be made for my proposal to work in a consistent way. But I am not sure Rust "got it just right" with its current syntax and I'm not sure I agree with your prior implication that an alternative syntax and rule set for expressing equivalent semantics would result in a "tangle of special cases". &gt; A set of rules whereby a pointer is `T` but a pointer to pointer is `&amp;T` and `$T` is "anything but a pointer" seems like hell to learn That doesn't sound quite what I was suggesting either. Perhaps saying `T` would have the semantics of `&amp;T` was either taking it too far or not being explicit enough. Or maybe what you say is the natural implementation of the behavior I'm after. Or maybe I just quite grasp the fine details yet. Hmm.. I was after an alternate way to express ownership and lifetimes and, by extension, argument passing semantics. So `$T` would mean "I own this `T`" and `T` would mean "I don't own this `T`". Similar to how `T` means "I own this `T` and `&amp;T` always means "I don't own this `T`" today. I was not trying to say anything about representation or implementation. I wonder if changing the use of `&amp;` in my hypothetical system is warranted. My immediate thought is that if you had `t: T` then `&amp;t` would obtain an explicit pointer to `t` and probably have a different type like `*T`. That's not too far from how the unary `&amp;` behaves on a `const T&amp;` in C++. It seems like that would be pretty rare in idiomatic use. How often is `&amp;&amp;` used today to get pointers to pointers? I haven't seen it once so far. I'm not convinced my current suggestion is particularly difficult to learn but it's possible a more complicated set of language rules is the cost I'd have to pay for less syntactic noise. I'd be okay with paying that cost up front to have an easier time day-to-day for as long as I use Rust (which is shaping up to be for a long time). &gt; The issue is that the type &amp;T is actually an ellided form of the type &amp;'a T; every reference has a lifetime, the compiler just inserts it for you in most cases. You'd need another syntactic form for when lifetimes are explicit. It seems natural here to drop the `&amp;` such that in my proposed system `T` would be an elided form of `'a T`. Explicit lifetimes are one of the areas I haven't dealt with much yet so I anticipate some more issues and edge cases would come of that. &gt; it turns out this works fine: http://is.gd/4uJeIX Neat! Thanks for that. It does somewhat illustrate what got me thinking about this alternate representation and "reference behavior by default" (or maybe "borrow by default"?) in the first place. I find `&lt;_&gt;::to_string` is *noisy*. The important `to_string` part is prefixed by a fair number of symbols which convey little useful information. Explicit generics are noisy in general - that `collect` call is evidence. Reminds me of trying to explicitly use container iterator types in C++ before `auto` was useful. 
Arguably, a couple of ways. On Android, if you click a link to one of the sections, clicking the back button will take you back to the table of contents. On iOS, clicking the status bar at the top will always take you to the very top. I'm not opposed to having return to top links.
Why are there only numbers for the first 7 FAQ items in the table of contents? the rest are unnumbered, at least from my phone.
You can add a version number (or `stable`, `beta`, or `nightly`) after doc.rust-lang.org, for example http://doc.rust-lang.org/1.4.0/ But yes, this should be exposed somehow so you don’t have to mess with URLs to reach it.
&gt; Do you think an internals folder inside src/doc would be an appropriate place for this type of documentation? I would love such a thing.
I'm sure you meant to post to /r/playrust. This is about the Rust programming language!
Hm... this seems to be about the survival game Rust (/r/playrust/)and not the programming language.
IO is in general fairly small. Reading the entire file in takes about 1.25% of the runtime, writing everything out (to `/dev/null`, but doing the important formatting) takes about 5.75%. So IO is about 7% of the total time. This is with the awesome work by /u/neutralinostar and /u/doener to [reduce overhead of validating UTF-8](https://github.com/rust-lang/rust/pull/30740). It may be worth some time to investigate the writing side of things, as shaving a few percentage points a few times adds up nicely.
If you're using up all your resources, have you tried profiling to narrow down the parts of the code that are resource-intensive? ;)
And /u/doener, it's a collab. Do you know approximately what the rest of the difference is?
&gt; Do you know approximately what the rest of the difference is? I don't understand what you mean. The difference between what A and what B? :-)
FTFY; There're already many argparse libraries. And there is no law against making a new one.
Linked from [here](https://internals.rust-lang.org/t/perfecting-rust-packaging-the-plan/2767).
I never said there wasn't. You mentioned "useful" in the title. I read this as implying that existing argparse libraries aren't useful. Now if you wanted to write this for your own learning, that's cool. But I wanted to know if I, as a user of the existing (argparse)[https://github.com/tailhook/rust-argparse] library, would have anything to gain from switching to this library. My question in my post should have been read as "is there anything that distinguishes this library from existing argparse libraries that make it worth using over them for existing users?". I think that's a reasonable question.
Not really, because I still can't call `self.match_entity_signature` inside that loop.
I agree, and I spent several minutes trying to word it better but failed. Do you have a suggestion?
Good catch. I'll change the faq.
As a piece of official documentation, I am worried that it is duplicating existing content. My inclination right now is that [CONTRIBUTING.md](https://github.com/rust-lang/rust/blob/master/CONTRIBUTING.md) should be augmented with important information from your blog post. They seem to cover a lot of the same territory and CONTRIBUTING.md is linked prominently from contributing.html.
[Done](https://github.com/rust-lang/rust-www/pull/264). Thanks.
There aren't specific plans to address that, but rustdoc's style is always being tweaked. If you have a concrete idea to improve it please submit a PR.
Huh, that's a good point. [Issue](https://github.com/rust-lang/rust-www/issues/265).
600KB doesn't seem that much to me! Is there a code editor that is lighter?
Yes. [Here's an issue](https://github.com/rust-lang/rust-www/issues/246). I couldn't figure out how to do it.
If you can move `match_entity_signature` away from being called through `self`, by making it a freestanding function, or a method on one of your types, you should be able to access multiple parts of your struct mutably like this: pub fn apply(&amp;mut self, entity: Entity) { let World { ref mut entities, ref mut systems, .. } = *self; // entities and systems are &amp;mut Vec&lt;_&gt; } But I might be missing something about your use-case. Addendum: This is how I would write the above pattern, if I understood everything completely. Let me know if I made an error somewhere, since I'm having a case of the fridays. Note that for a game I think batching things to add/remove afterwards can pay of performance wise, since it would seem more cache-efficient. Especially if you can reuse the buffers holding the indices. type EntityId = i32; type EntityKey = i32; type Entity = i32; struct System; impl System { fn match_entity_signature(&amp;self, entity: Entity) -&gt; bool { true } fn contains_entity(&amp;self, entity: Entity) -&gt; bool { true } fn on_entity_added(&amp;mut self, entity: Entity) { } fn on_entity_removed(&amp;mut self, entity: Entity) { } } struct World { free_entity_ids: Vec&lt;EntityId&gt;, entities: Vec&lt;EntityKey&gt;, systems: Vec&lt;Box&lt;System&gt;&gt;, components: (), } impl World { fn apply(&amp;mut self, entity: Entity) { let World { ref mut entities, ref mut systems, .. } = *self; for system in systems.iter_mut() { if system.match_entity_signature(entity) { if !system.contains_entity(entity) { system.on_entity_added(entity); } } else { if system.contains_entity(entity) { system.on_entity_removed(entity); } } } } } 
If `match_entity_signature` does not need to access the `systems` field, you can split the struct. For example, if `match_entity_signature` needs access to `entities` and `free_entity_ids`, you could create an own struct for it: ``` struct Entities { free_entity_ids: Vec&lt;EntityId&gt;, entities: Vec&lt;EntityKey&gt;, } impl Entities { fn match_entity_signature(&amp;self, ...) {...} } pub struct World { entities: Entities, systems: Vec&lt;Box&lt;System&gt;&gt;, components: Vec&lt;HashMap&lt;TypeId, Vec&lt;Box&lt;Component&gt;&gt;&gt;&gt; } ``` Then `match_entity_signature` does not need to borrow the whole `World` and everything should work fine.
Agree. [Here's an issue](https://github.com/rust-lang/rust-www/issues/266). I don't have time to dig up the links right now but might circle back later today.
[screenshot](http://imgur.com/4JOGStq) there are 21 items, and only the first 7 are numbered.
One place where you will see alot of FPGAs in the automotive industry is power electronics for hybrid/electric vehicle systems. Because they haven't standardized on controls enough to put them into ASICs, alot of them use FPGAs to achieve the fast switching and ultra-fast reaction times for safety-critical functions that would eat up microcontroller resources.
I'd be careful actually putting that in a FAQ page, though. It's the kind of thing that C++ enthusiasts will call out as inaccurate. Since nobody actually has any data on how often C++ programmers use shared_ptr when they didn't need to, it'll be an "our word against theirs" sort of situation, which isn't going to sway anyone.
I've put together a simple implementation of the Discworld-inspired board game Thud, using gtk-rs. It's far from clean and mature, but in the spirit of sharing [here it is](https://github.com/dstu/thud). The experience was generally a good one. All the basic APIs I needed were there when I looked for them, and documentation for GTK is plentiful. I actually found snippets of PyGTK to be of help at times, since it is a more widely used GTK binding that can be used to figure out how to glue GTK together without worrying about the C-specific bits. There were two times when I ran into walls. The first, for which I filed an issue, is that functions for rendering GTK widgets to images aren't exposed, so I can't write my game board renderings to disk when debugging remotely. The second problem was that I couldn't register new events on a widget because the gtk-rs Widget trait doesn't provide the necessary method. Fortunately, the underlying GTK function is exposed by gtk-rs, so I could access this functionality by pretending I was writing in C and passing the naked pointer exposed by gtk-rs struct types. A third issue complicates things but isn't insurmountable. If you want to use closures to respond to GTK events, they need to have static lifetimes. That means you either have to move your application state structures into them, keep your state in shared memory, or use a bunch of global state. Upon reflection, this limitation is reasonable. There is no guarantee that GTK won't call your event handlers after your local structures have had their memory reclaimed. I handled this issue by storing all state that event handlers had to access or mutate in `Arc&lt;Mutex&lt;T&gt;&gt;&gt;` wrappers. This rankles a bit, and it seems like some sort of channel-based communication system, with logic for the event handler separated from actual state changes, would be cleaner. But that's a design problem for another day.
What browser are you using, and what version of that browser?
Fair point. I'll see what I can do!
Or a search bar/keyword thing. On Chrome I just type "rstd &lt;search term&gt;" and it takes me to the search results page in the stdlib API docs.
I believe /u/glaebhoerl had some ideas on how we could handle `TypeId` in the presence of lifetimes and even get `Any` to play nice with it, but I don't remember the specifics (I'm hoping he sees this and answers himself).
I think it's fine if we leave out the jab at C++. We can say that references are usually enough, and sometimes reference counting smart pointers are needed.
My idea was basically to *avoid* solving the problem of lifetimes vs. type-id, and instead parameterize `Any` itself over the lifetime of the given data, so that `Any&lt;'static&gt;` would be equivalent to the current `Any`, but you could also have `&amp;'a Any&lt;'a&gt;` and such. (I'm not sure if this would satisfy /u/Marwes's use case?)
Yes, the `rlibs` must come from a rustc built in exactly the same way or you'll get this error: https://github.com/rust-lang/rust/issues/30363#issuecomment-164596319
I recall reading the history of the turbofish once upon a time (but not by that name, lol). It seems like a reasonable decision to make when you're trying to get something done. I happen to think prioritizing the ease of parsing over ease of use is a little bit backward in the long term, until it gets ridiculous impractical like an order of magnitude slower. Maybe I'm ignorant of technical limitations here and definitely ignorant of history (my searches couldn't find the justification or discussion), but I can conceive syntax like `collect&lt;Vec&gt;` or `collect!(Vec)` that doesn't seem like it would be terribly bad to support. Do you know where I can find the original discussions? Or maybe you can enlighten me as to what I'm missing?
It does the same on Chrome on my Ubuntu laptop, although Firefox works correctly.
Just the perf difference between your sxd and libxml
It worked! I didn't know about `let World { ref mut entities, ref mut systems, .. } = *self;`. Is this pattern matching? Can I use it to borrow single parts of an object without borrowing everything else? Let's see if I can apply this to other cases.
If your keys are at most a couple dozen bytes, you should also look at the performance from storing a statically sized array, e.g. (usize, [u8; 32])
Yes, `let` can destructure and bind any irrefutable pattern. So, since the right side will always be a `World` and you're allowed to access its insides directly, you can take mutable references to inner parts of it. Same as with `let (ref mut x, ref mut y) = ...`, except instead of taking references to the insides of a tuple, the referenced values are inside a struct. I should note, in your example above you should get away with just `let systems = &amp;mut self.systems` and using that, but I assumed multiple parts could be involved in the other parts of the code.
Right -- but how can I bench getting/inserting keys in a hashmap without allocations when the key has to be some kind of non-Copy type?
Thanks!
Ah! Not really, as I've been trying to treat libxml as a black box. I'll pipe exemplars into `xmllint` to see how it treats a given input if the spec is unclear, or I'll time it on the command line to compare like-for-like, but I'm trying to avoid looking at the code directly. This is to maintain a psuedo clean-room environment, but also as an attempt to allow the Rust code to be designed as Rust code, as opposed to C-ported-to-Rust. 
You are right, `match_entity_signature` didn't have to be a member of World, that and learning how to borrow single parts of an object solved my issue.
Yes, the docs created by cargo doc already fit together with rust-Lang.org
If you're into gamedev, you should try out a tutorial of mine: [ArcadeRS](http://jadpole.github.io/arcaders/arcaders-1-0/). It's still a work in progress, but I'm midway through the 12th/16 article, so it should be enough to get you started.
That is more or less how I do it right now thought with the added annoyance of needing to manually (using the macro) implement `AnyRef`.
[Not propertiary](https://github.com/mattermost/platform), but yes - invite only. But there is #redox channel @ irc.mozilla.org that is linked with a room at the Mattermost. So you can still chat with us without being part of the core.
First of all: It's not proprietary. The source code is freely available under MIT license. The reason for being invite only is to avoid spam and other caveats entailed by an 'open' system. However, we hand out invites to whoever wants them (as long as you're not a spam network ;) ). Drop me a PM if you want an invite. I have also made an IRC bridge to the #redox channel at mozilla's IRC.
Probably there will also be XMPP server added ASAP there probably will be one enabled for Redox chat also.
This looks perfect
Yes, will you submit a PR? Thanks!
[Here's a PR to change the word](https://github.com/rust-lang/rust-www/pull/276). Thanks. You're right that it should provide an alternative.
That did the trick! Thank you!
Unfortunately the name turbofish postdates the discussions about it, so its hard to search. I'm not informed enough to speak intelligently about the parsing issues that led to turbofish, but I _think_ it has to do with the amount of analysis that would be needed to distinguish `collect&lt;Vec&gt;` from `collect &lt; Vec`. Rust intentionally has a grammar which can be parsed with a LALR(1) parser (iirc). This restriction has advantages other than performance - it also makes the parser implementation easier to modify and makes it easier to write tools which interact with and manipulate and Rust source code (like rustfmt or live syntax checking). I am totally uninformed about Scala, but my impression of the language is that it has a lot of special cases and complex rules which make common cases more elegant (maybe this impression is wrong or unfair). Rust's design definitely has focused on limiting the special cases and simplifying the language where possible, in part because of the significant inherent complexity of systems like the borrow-checker. This has had some cost syntactically, but I think its worth it.
Do you know how long it'll be yet? I was working on something quite similar but if you're going to be finished first then I might as well save myself the duplication of effort.
Ah you're the author of that library! It looks really cool, I'm sorry for pushing redundant functionality :\ still do you have any comments on my stuff, just as a sort of exercise?
Looks really cool! After reading all the stuff in the description, like ECS, lua integration etc., I was kind of disappointed that not everything is there already :P But especially the state-based stuff looks really nice, usually the same approach I take. Really good!
Thanks for the response! I'm disappointed that those features are not there yet myself ;) I'm in the process of hashing out a redesign of the renderer backends' resources and state objects ([issue #7](https://github.com/ebkalderon/amethyst/issues/7)). Once this is fleshed out, it will be trivial to build an OpenGL backend, for starters. If you have any design suggestions of any kind to share, I'm all ears. Please be sure you first read from the ["Design Inspiration"](https://github.com/ebkalderon/amethyst/blob/master/CONTRIBUTING.md#useful-resources) part of the Contribution Guidelines to get a clearer idea of what kind of architecture I'm trying to shoot for.
There are also my personal favorite [clap](https://github.com/kbknapp/clap-rs), and [docopt](https://github.com/docopt/docopt.rs) which takes a different approach of parsing options from documentation. Perhaps you could take a look at those as well for inspiration. There's never any harm in adding more options to the community (unfortunately in the PHP and Javascript communities which I frequent as a web developer, there are a lot of people who strongly discourage "reinventing the wheel"--I personally think it's fine to do so and find that sort of discouragement to be harmful to a community).
Sometimes I wish Rust's safety was a thing in Rust!
&gt; Another option is to use a graph crate. petgraph is popular This is how we solve the problem in conrod. petgraph is an expressive and performant graph library and has become my go-to for graph-like structures. Specifically, we use the [daggy](http://mitchmindtree.github.io/daggy/daggy/) wrapper, which refines the petgraph interface to a more concise DAG type which more closely matches our needs. We've not yet required cycles and I can't foresee any need from this point - they only ever seem to cause more trouble and complexity. Our [`Walker`](http://mitchmindtree.github.io/daggy/daggy/walker/trait.Walker.html) trait makes it a breeze to traverse the graph in different ways with an API that feels like `Iterator`, but doesn't require borrowing the graph for the lifetime of the iterator type. I think for a lot of people `Rc` tends to feel like the intuitive, simple, approachable solution when first realising they require a parent-child link, and I imagine this might be the case for very small groups of nodes. However in my experience, as the graph/tree begins to grow larger and more complex, moving to an actual `Graph` or `Tree` type can vastly reduce ambiguity, help to keep clear track of ownership, greatly simplify whole-graph operations (traversal/mapping/cloning/serialisation) and improve performance via temporal locality.
We'd definitely appreciate bug reports if you come across them :) Though as /u/cptroot mentioned, there are some known bugs with the current user input handling that might have caused you issues, though these are currently [being worked on](https://github.com/PistonDevelopers/conrod/issues/670).
I was *just* about to embark on an SDL-fuelled game dev journey. I'll take a look!
&gt; Design and documentation review is appreciated just as much as code review, so please be honest. Well, there's not much to see for the moment. Some general remarks for what I've seen: - Projects split in multiple repositories are usually a huge pain to maintain. I don't really understand why people do this instead of a single repo and subdirectories. - You seem to have lost a lot of time on the `amethyst_cli`, which is probably a useless tool for now. - Your `renderer` module is public, which leads me to think that you want to give people access to it. This means that if you want your engine to be cross-API you will need to design a high-level shading language that is compiled to either GLSL, SPIR-V or HLSL for example. This can be extremely painful to do. - You said you're designing your engine for Vulkan, but what I see in the `renderer` has already slightly gone the wrong way. You should wait for the specs before designing this, or be ready to revamp the module. - I strongly dislike entity-component systems because it's too hard to cache important data and too easy to get an invalidate state. It's probably good for small games because they are simple and don't need a lot of CPU, but meh. But I'm not an expert here so it's not a strong opinion. 
Sure thing, here you go: https://github.com/rust-lang/rust-www/pull/281 :)
What do you prefer in lieu of entity-component systems?
Let's walk through your code: 1 fn main() { 2 let m = 23; This declares a variable called `m`, which is an integer, and has a lifetime which is valid until line 7. 3 let z: &amp;i32; This declares a variable called `z`, which is a reference to an integer, which has a lifetime which must remain valid from line 3 to line 7. 4 let arun = m; This declares a variable called `arun`, also an integer, which is initialised to the value of `m` (23). Since `m` is an integer, and is copyable, it is copied into `arun`. `arun` has a lifetime which is valid from line 4 to line 7. 5 z = &amp;arun; This assigns a reference to `arun` (which is valid from line 4 to line 7) to z (which must be valid from line 3 to line 7) - when the Rust compiler sees this, it gives an error message "error: `arun` does not live long enough" - the reference that `z` refers to needs to be valid for longer than `arun` is valid. If you read the error message carefully, you'll see that this is exactly what it tells you - it takes a little while to be able to understand the messages. In order to fix this, `arun` must outlive `z`, so if you switch the order of lines 3 and 4 your code will compile. 6 println!("{} {}",z,m); 7 } I hope this make sense!
I had a previous comment here but I realized that I got it wrong entirely, so I deleted it. The real reason you can't assign `&amp;arun` to `z` is that variables are destroyed in reverse order of declaration when they go out of scope. `z` is declared before `arun`, so it outlives `arun`, which is illegal.
I think your design sounds interesting. I myself have been switching between ECS and a more OOP approach in my (simple) games. Could you elaborate a bit more or point to something that talks about what you mean?
X-Post referenced from /r/handmadequake by /u/klo8 [Handmade Quake in Rust](https://www.reddit.com/r/HandmadeQuake/comments/417y8g/handmade_quake_in_rust/) ***** ^^I ^^am ^^a ^^bot ^^made ^^for ^^your ^^convenience ^^\(Especially ^^for ^^mobile ^^users). ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
Ah, thanks. I fixed it, I always forget the Markdown link syntax.
Looks like an interesting plan! Hopefully it all goes well. Why roll your own command line parsing, rather than use an existing crate (not judging. It's a totally reasonable choice. I'm just curious)? Just a desire to do it yourself?
I tried argparse (I've used it before, it's pretty nice) and it didn't let me do long commandline flags with a single dash (like "-windowed" instead of "--windowed"). Also, I wanted to recreate the way Quake parses its arguments list (gets the values on demand, basically).
This should be very awesome to follow. Thanks for linking to Handmade Quake, I'll be following that one as well. It'll be interesting to see the Rust version of the Quake source. Now all we need is for someone to get Rust to compile for MS-DOS. :)
I'm interested to see where this goes with regards to gameplay code, especially the ECS framework and pushdown automota-based gameplay. While technical stuff like rendering is cool and fun to show off, the hard part (at least in my experience so far) is making a framework for gameplay code that is easy to use, safe, and performant. I too have tried to follow the ECS design used by Bitsquid but I've found that it's not super easy to use for gameplay code. I'm interested to see what you'll come up with to make your engine easy to use :)
I'm working on merging that serde_json patch right now :)
I do think you need the `PhantomData` marker. Personally I would throw in a little more generics by accepting any iterator that returns items that can be `AsRef`'ed to a `str`, like so: struct FromStrIter&lt;T, U&gt; where T: Iterator, &lt;T as Iterator&gt;::Item: AsRef&lt;str&gt;, U: FromStr { iter: T, pd: PhantomData&lt;U&gt; } impl&lt;T, U&gt; Iterator for FromStrIter&lt;T, U&gt; where T: Iterator, &lt;T as Iterator&gt;::Item: AsRef&lt;str&gt;, U: FromStr { type Item = U; fn next(&amp;mut self) -&gt; Option&lt;U&gt; { self.iter.next().as_ref() .map(AsRef::as_ref) .map(FromStr::from_str) .and_then(Result::ok) } } impl&lt;T, U&gt; FromStrIter&lt;T, U&gt; where T: Iterator, &lt;T as Iterator&gt;::Item: AsRef&lt;str&gt;, U: FromStr { fn new&lt;V&gt;(into_iter: V) -&gt; FromStrIter&lt;T, U&gt; where V: IntoIterator&lt;IntoIter=T, Item=&lt;T as Iterator&gt;::Item&gt; { FromStrIter { iter: into_iter.into_iter(), pd: PhantomData } } } Note that I prefer to use the methods on `Option` and `Result` instead of doing pattern matching.
Well, before the time of programming with emojis there were programming languages with actual words in them. E.g Pascal has the full spelled out "Implementation" as keyword. Would you believe that Pascal programmers actual knew how to spell? :P But, again this is unrelated to my comment. This is exactly like my dad telling me stories about his army service in Siberia and how he saw his family only once a year. Well, sure, but cellphones didn't exist back than so the comparison doesn't hold.
Not relevant to Rust but I have implemented a very tiny and unfinished ECS in c++. I have written about it here: https://maikklein.github.io/2016/01/14/Entity-Component-System/ I am currently implementing in it D and I would also like to implement it in Rust but I don't think that Rust as sufficient metaprogramming capabilities. 
Ok, as it turns out, once I finally got strace into my buildroot and the configuration saved and all (other things came up), I was able to find the following when it comes to mmap'ing my device file: mmap(NULL, 8192, PROT_READ | PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) That's what got received. That's not what was printed out as the parameters: addr 0 (correct), len 8192 (correct), prot 3 (correct; 1 | 2), fd 3 (incorrect, 3!=-1), offset 0 (correct) So I guess it's the file descriptor that's changing somehow? Then I ran strace on the example you gave me, and I saw that the flags passed to mmap differed quite a bit. Among the differences, there is MAP_FILE in the flags (not present in my binary), and the actual correct file descriptor got passed in. I then thought to just change the file being opened in the example you gave to my device file, load it up in qemu buildroot, and try and see if I could just mmap in my file. I got the same issue with vm_flags being set to 0xff! In addition, I could see that the correct file descriptor got passed in, and that strace did in fact see the correct parameters (correct everything :) ). But by the time it gets to my device callback, the flags have been changed for me.
Thanks for this! Am I safe to assume you think it's best to return None if the value cannot be parsed FromStr? I was thinking perhaps it's best to have the iterator return: `Option&lt;Result&lt;T,SomeErr&gt;&gt;` ? This way the user can check if the value was parsed during iteration and deal with it themselves? Thanks again!
&gt; The `unsafe { asm!("") }` part was the way I found to avoid the compiler to strip this part of the code out during the optimization phase, as it doesn't seem to do anything. Would it be a bad idea to turn compiler optimizations off? 
`F: Send+Sync` and maybe `thread::spawn(move || {` (so you capture the `Arc` instead of a reference to it).
Returning `Option&lt;Result&lt;T, &lt;U as FromStr&gt;::Err&gt;&gt;` is definitely the way to go. If you want to, you don't even need to define your own struct, you can just use what `std::iter` already provides: use std::str::FromStr; fn from_str_iter&lt;I, U&gt;(iter: I) -&gt; std::iter::Map&lt;I, fn(&lt;I as Iterator&gt;::Item) -&gt; Result&lt;U, &lt;U as FromStr&gt;::Err&gt;&gt; where I: Iterator, &lt;I as Iterator&gt;::Item: AsRef&lt;str&gt;, U: FromStr { fn from_str_fn&lt;T, U&gt;(item: T) -&gt; Result&lt;U, &lt;U as FromStr&gt;::Err&gt; where T: AsRef&lt;str&gt;, U: FromStr { FromStr::from_str(item.as_ref()) } iter.map(from_str_fn) }
This should work, with the addition of `F: 'static` too. To the original poster: The closure bounds are derived from the signature of [`thread::spawn`](https://doc.rust-lang.org/std/thread/fn.spawn.html) which requires `F: Send + 'static` for its closure too. The bounds on spawn's closure are to be understood as the bounds on the values captured by the closure.
move doesn't make any difference. Where do I put the send+sync?
Also, I noticed that the trail you went down was for the latest kernel, but I'm using kernel 3.14.56
Why not recommend "heavy tags"? `git tag -a v0.1.2`. Or you can even sign them with -s.
That seems like the sort of question that should be added to the FAQ. I'll open an issue for it! EDIT: We actually have a question covering this already, but it's easy to miss because the question itself doesn't mention feature gates. I'll see if we can improve things.
I didn't recommend annotated tags, but that's not to be confused with recommending *against* using them either. \^_\^ **I** don't use them because I'm too lazy to fully investigate the benefits and downsides of doing so. The same with signing — I'm too lazy to know the better course of action and to get my initial key created. For the purposes of publicizing when something was released, I believe that an annotated or signed tag will work just as well. If an author's experience or requirements lead to that, I think that's just swell!
Yeah, that's probably the right place for it. I'll open an issue.
It's a real pain to do this manually every time. RubyGems has `bundle release`, [OPAM](http://opam.ocaml.org) has `opam publish`, how about implementing a tool to simplify the process and *then* asking other people to go out of their way? :) I'd probably write one myself but I don't release crates all that often...
I used to tag one of my crate's releases. The other crates I didn't bother. It's another thing to remember for releasing and I prefer to release many small versions often.. If it could somehow be integrated in the workflow, I'd be ok with it.
Not really. I just tend to remember it better because I'm already doing "git stuff". I'm pretty sure you *would* want to commit before publishing though. I also delay pushing the tag and changes just in the off chance that `cargo publish` fails for some reason. This may be a bit silly, but it's what I do.
I use the Github interface.It allows to have a draft for the next version, so you can keep a change log that you can fill in as you push new commits. When you are ready just publish it and your code will be tagged with a complete change log without too much effort. :)
I'll try these two options, thanks!
&gt; a draft change log that I keep updated That sounds like you are already doing far beyond what I'm looking for. Having a Github "release" is even nicer than just scattered tags.
It doesn't really matter. LLVM will not attempt to optimize `asm!()` blocks, because you probably put those there for a reason.
[removed]
Most of the automation that is needed is simply to create a git (or whatever vcs is used) tag during publishing (so that the published version == tagged version). The script should pull the tag name from the version (v prefix is a bad idea IMO).
I knew there must be a variant of `iter` to do that, but I failed to find it in the API docs.
That's probably a good first start. Although I'd vote to flip it around and have it tag by default (if a VCS is found) and have a `--no-tag` to disable. I guess `cargo publish` doesn't push to your remote anyway, so why should this...
&gt; mmap(NULL, 8192, PROT_READ | PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) Make sure you're looking at right mmap(). There would be many of them in strace output, as memory allocation (malloc) uses mmap() too. &gt;But by the time it gets to my device callback, the flags have been changed for me. You shouldn't check with vm_flags == VM_WRITE|VM_READ as kernel may add whatever additional flags it wants. Just use if (vma-&gt;vm_flags &amp; VM_WRITE) { ... // write access requested } if (vma-&gt;vm_flags &amp; VM_READ) { ... // read access requested } 
Cargo should do it. I'm sorry, but I'm not being paid to do my Open Source projects, I do it in my own erratic personal time, sometimes in haste etc. I'm sure a lot of people are in similar position. Unless the tools enforce it, it won't happen.
Hi there! This is one of my first non-trivial crate, a server (and basic CLI client) for the card game Coinche (a variante of the french belote). The goal is to eventually have an HTML UI instead (or in addition to) the CLI one. Though I'm beginning to see why people like Node.js: in the current situation, I may have to port a part of rust code to javascript. Maybe emscripten would help? I'd very much like to hear comments or suggestions about it. Thanks!
into_iter() does indeed do the trick, thanks
Thanks! To avoid using unstable and per the suggestion below I used into_iter() instead. The final code which compiles and works is below. Everybody says the thing that trips everyone up is ownership &amp; borrowing and so it is for me too. use std::thread; use std::sync::Arc; fn integrate&lt;F&gt;(from: f64, to: f64, intervals: i32, threads: i32, func: F) -&gt; Option&lt;f64&gt; where F : Fn(f64) -&gt; f64 + Send + Sync + 'static { if intervals % threads == 0 { let delta_x = (to - from) / (intervals as f64); let chunk_intervals = intervals / threads; let chunk_width = delta_x * (chunk_intervals as f64); let function = Arc::new(func); let handles: Vec&lt;_&gt; = (0..threads).map(|chunk_number| { let function = function.clone(); thread::spawn(move || { let offset_from = chunk_width * (chunk_number as f64) + delta_x / 2.0; delta_x * (0..chunk_intervals).fold(0.0, |sum, i| { sum + function(offset_from + delta_x * (i as f64)) }) }) }).collect(); Some(handles.into_iter().map(|h| { match h.join() { Ok(v) =&gt; v, Err(_) =&gt; 0.0, } }).fold(0.0, |sum, i| sum+i)) } else { None } } fn main () { let result = 4.0 * integrate(0.0, 1.0, 1000000000, 2, |x| 1.0 / (1.0 + x*x)).unwrap(); println!("{:.16}, error: {:.16e}", result, result - 3.141592653589793238462643383279502884197169399375105820); } 
Fixed!
&gt; if every crate author could take the time to publish docs, even just bare bones API docs generated by Rustdoc [travis-cargo](https://github.com/huonw/travis-cargo) is _incredibly_ useful for this.
True it exists, but learning by doing will probably be much more helpful I think.
&gt; The idea of the video series is to go through the Quake 1 source code and re-implement that in C Isn't the original source mostly in C? What's the point of re-implementing it in the same language?
It might be simpler to use [`Vec::retain`](https://doc.rust-lang.org/std/vec/struct.Vec.html#method.retain) for some of the `filter_map`s, like [the one](https://github.com/jadpole/jadpole.github.io/blob/master/code/arcaders-1-12/src/views/game.rs) that checks for asteroid collisions. Unfortunately, you couldn't use it for the one that calls on `update` on them, since it takes an `&amp;T` rather than an `&amp;mut T`.
I guess, although I quite like the idea of a single, unified technique used again and again throughout the article. I might add a note about it, though.
Remember that IRC stands for Idle Relay Chat, so people aren't always around to notice your question and respond. If you do have a Windows related question though, feel free to ping WindowsBunny on IRC with your questions and he'll always be there and respond (although sometimes delayed by a few hours).
&gt; Remember that IRC stands for ~~Idle~~ **Internet** Relay Chat 
I believe that /u/retep998 was making a joke. :-) If there weren't a rule about memes, I'd insert something relevant here. I think the point is that sometimes you have to ask a question on IRC and wait a while (minutes, hours, days) before getting a response. Or summed up as "don't lose hope".
The example covers gcc. I wasn't sure if there differences between the Windows/POSIX interfaces 
Most of the steps can be automated and I'm working on bringing that to Rust.
There should be a bot going through repositories of crates and notifying maintainers of untagged releases. Example: https://github.com/jgallagher/rusqlite/issues/118
Rust will make mistakes. What matters is how we work to evolve the language over time.
Learning perhaps?
Hopefully major versions will be willing to break backwards compatibility more than C++'s have. AFAIK C++11 didn't break anything except programs that used new keywords as names, but I think we can get away with a deprecation path for a while.
I expect that mistakes will be deprecated but keep working in the 1.x branch, and eventually removed in a possible Rust 2.0.
Note that Rust's implementation of hashing does have one known flaw: it lacks a fast-path for "one-shot" hashing. For instance, hashing a single integer, or an array of bytes (strings!). This is because it's built to handle composing multiple hashable fields. You hash by mixing in the bytes, and then asking the hasher to produce a final result when you're done. /u/neutralinostar has probably looked into this the most. All I remember off the top of my head is that this horribly penalizes cityhash, which is basically an amalgamation of "optimized algorithm for this kind of one-shot data". There's possible paths forward with default methods on the relevant traits but they're *ultra-brittle*. As in, when I tried it once the compiler completely exploded because I evidently made a mistake (and as everyone knows, the Rust compiler is secretly just a big hashmap stress test). Particularly pernicious is the matter of "extra" mixins necessary to distinguish collections-of-collections. For instance `("c", "at")` reliably hashing to the same thing as `("ca", "t")` would be disastrous for collisions. In order to avoid this, strings also hash in a junk byte, so the hasher basically sees "c0at0" and "ca0t0" when hashing these two pairs. We *don't* want to include these bonus values when doing a one-shot hashing of a string, though. This however means that one-shot and multi-shot hashing diverge, and all previously unoptimized one-shot hashes will change (if for instance you stored them).
If there's a stable ABI by the time that transition happens, then maybe we could have the vN.X compiler be able to compile and link with v(N-1).Y crates. That would smooth out the transition quite a bit, since you wouldn't need to wait for external libraries to upgrade.
That's inaccurate to say the least. I don't have to declare separately each individual function in a header file, only those I want to export publicly. I can also define short functions inline in the header file. And finally, header file are a separate deficiency - lack of a proper module system. That has nothing to do with function declaration syntax. Btw, there is a prototype design of a module system that is going to be added in c++17. 
Deprecations -- even just "renamed to X, use that" can create havok as well. We've seen this several times in the community as well, as the compiler is screaming at you to upgrade, but doing that makes your library incompatible with older version of Rust. You need a robust version straddling strategy even for trivial cases. For hard cases like Python... well, I *still* interact with people arguing over 2 vs 3.
We defined `contains`/`overlaps` at the very end of [ArcadeRS 1.6](http://jadpole.github.io/arcaders/arcaders-1-6/).
I intended to watch this live, but I was far too tired and went to bed at midnight. * You do know Rust allows trailing commas in structs and enums? Makes for less messy diffs. :) * Might you be able to get away with deriving Default for some parts of the power-on reset, given how much state is left undefined?
I prefer the inner scope style for creating immutable variables that need to be modified initially. For example, your file_buf could be written like this: let file_buf = { let mut file_buf = Vec::new(); // Do whatever you want to construct file_buf here file_buf };
Another nice suggestion! Thanks!
You could pick a command that is missing and join the project.
I'm not entirely sure if convincing would be the right way to go. Either you are intrinsically interested in learning Rust or you are not. And it entirely depends on what you are aiming to do with either C or Rust. I could also go forth and try to convince you to learn Haskell. It completely depends on what you are looking for.
1. While C and Rust serve the same systems programming niche, C is over 40 years old while Rust 1.0 was less than a year ago. C today is horrendously crippled by the need to remain compatible with the language it used to be while Rust incorporates four decades of experience in what makes a programming language comfortable without sacrificing performance. 2. The only commonly-learned language that's easier to make a mistake in than C is assembly language. By comparison, Rust is explicitly designed to catch as many mistakes at compile time as it can without driving people away. 3. I know how to use C, C++, Python, PHP, JavaScript, CoffeeScript, Bourne shell script, and possibly others that I don't use often enough to just leap to mind. I never code anything non-trivial in C and, even then, never if I can avoid it. By contrast, I'm planning to switch all of my non-browser efforts to Rust as soon as I can make room for the necessary dip in productivity. (Limited, of course, by the availability of suitable libraries. I don't have the time and the drive to be the guy who writes a competitor for Django.) 4. C has no native string type (a naked character array doesn't count) and that's a major pain. Rust's standard library has native string support which includes the usual rogue's gallery of functions we've grown used to having over the last few decades. (And, in my opinion, Rust's approach to being Unicode-ready is the smartest of any of the languages I've examined.) 5. Rust's type system makes it easy to replace at least 50% of what I unit test in dynamically-typed languages with compile-time checks. (eg. The [hyper](https://github.com/hyperium/hyper/) library uses the ownership system in combination with "parameterized traits" to enforce, at compile time, that you can't try to modify an HTTP request's headers after you've already sent them.) 6. C makes it easy to ignore errors and hard to ensure you've caught all of them. Rust requires you to explicitly either handle or ignore every possible error but provides syntax that makes it easy and comfortable. (eg. functions like `Result.and_then()` which you can chain) 7. By design, Rust is good at calling into C libraries and producing libraries to be called from C. The community continues to work to make it even easier. (eg. There's a package named rusty-cheddar which can automate generating C header files for code you've asked to be compiled with a C-callable ABI) 8. C has no package manager and it's generally a hassle to set up build environments unless you're building using only packages available in your platform's package manager (your platform does have one of those, right?). Rust has "cargo", which is similar to "npm" for Node.JS. It's an easy-to-use package manager and build/install automation tool in one. Enough for you?
&gt;1. Goal I currently have no set goal (still in education), but I do plan on entering the industry. &gt;2. Languages you know now C++ and some Java &gt;3. Program-space you want to work in (web apis, guis, ???) Desktop applications, and to some small extent games &gt;In addition, if you go through the FAQ and learning links on the side, you can get a better feel for specific questions you might have, which are much easier to work with than this sort of vague question. Thanks for telling me of the FAQ and other links, I'll go take a look at them. 
That's actually a great reason to use trailing commas...I had always assumed it was just for uniformity and less accidental errors when adding/deleting elements.
I am interested in Rust, but I am hesitant to do so because I don't know whether or not learning Rust will be of benefit should I chose the find work in the industry.
&gt; I currently have no set goal (still in education), but I do plan on entering the industry. Rust will give you a step up on other people because it will make you think more about lifetimes, ownership, and memory. This translates well once you go back to C or even Java, Ruby, etc, because it makes explicit things that are implicit in all of those languages. It is also a good talking point when meeting other engineers or in interviews.
Any language that has interesting semantics will teach you something new that is applicable back to the rest of your programming work. I do Ruby, JS, and Java in my day job, and I constantly find that my Rust knowledge gives me a deeper understanding of the choices I am making when I program. I would say the same with Haskell.
You are not allowed to use Rust.^* ^* Research^** shows that something being forbidden makes it more desirable ^** Of the arbitrary kind
You need to update your nightly (1.7 is vague, the specific version might be too old). This has nothing to do with windows.
I think that C is not a good language to build reliable, large scale software. And I'm also not convinced that C is a good language to learn programming per se. But it's a great language to learn the C computer model, which is quite relevant. For example, if you want to learn Rust. ;) When your goal is learning, than the downsides of C doesn't matter that much. Dependency management? You won't have big dependencies. Weird edge cases and undefined behavior? Won't matter for small learning projects. Missing functionality that is considered must-have in newer languages? There is much to learn implementing that oneself. And the educational value of your program crash and burn is much greater than your compiler telling you that the borrow checker is unhappy.
Just a heads up, the latest MIPS instruction set reference and programmer's manual can be found [here](https://imgtec.com/mips/architectures/mips32/) and [here](https://imgtec.com/mips/architectures/mips64/). I'm not sure how useful they are going to be though, since they may contain stuff that didn't apply to MIPS in 1996.
Hell, there have been like four of those arguments on /r/Python in the last week.
I'll let stack overflow explain http://stackoverflow.com/questions/11514075/ It's just a bit of git sadness that it allows both and has us bother with the details.
Just my 2c, but I feel quite queasy about the idea of Cargo touching my git repository, and even more queasy about Cargo doing git push. Of course it is easy to me to say when I don't maintain any public crates.
No pushing please.
Or at least warn when the current version isn't tagged.
I've mostly only seen discussion of "what will 2.0 be, what would we need to have set up to handle whatever that is". Nothing necessitates 2.0 right now.
See https://github.com/rust-lang/crates.io/issues/75
If they're absolutely required, you can write C-style Rust by making everything `Copy` and not `Drop` and then writing all of the manipulations yourself.
When is the next episode?
Cool, thanks!
Oh nice, didn't know about that sub!
I'm not entirely sure yet. I'll announce it on my twitter at least: https://twitter.com/ferristweetsnow
And maintain a changelog, please
&gt; I think that C is not a good language to build reliable, large scale software. Mr. Linus Torvalds might have a different opinion...
I might livestream some of it. If I do, I'll probably make another post here. 
&gt; When you use some library from github you can have at least some confidence that there is no malicious code. If that repository is popular and some one will try to commit something bad this will probably be noticed. I don't believe this to be the best position to take. [This was posted to /r/programming yesterday](https://github.com/alerj78/lucky7coin/issues/1). In short, someone inserted a backdoor that allowed theft of various cryptocurrencies. This backdoor was reported on Github "about a year after the theft took place". The code was there (albeit in a hidden manner), but not obviously flagged. You can also point at the various OpenSSL issues that were available to be found if you looked... but no one looked soon enough. &gt; where owners of projects with thousands contributors can just add backdoors to their crates and upload them to crates.io and no one will probably notice How does that differ from any other repo on Github with thousands of contributors that *doesn't* upload to crates.io? &gt; Every time you execute cargo build or cargo run you are executing code from many different crates Don't forget you are also executing `cargo` and `rustc` and `bash` and ... For what it's worth, you can see the source of the crate that you downloaded and compiled in `$HOME/.cargo/registry/src/*/$crate-$version/`. ~~AFAICT, this is after the fact though~~. `cargo fetch` will allow you to download the code from crates.io and inspect it before you compile it.
0.1.* would mean if you verified 0.1.1 it wouldn't matter as if 0.1.2 was released with malicious changes it would be downloaded. It also means builds aren't reproducible if you use wildcards. When you tag with git make sure you've got rid of wildcards. When doing general development I suppose it's alright!
Isn't ferris also the name of the rust crab?
Cargo does not have to force it. I shouldn't have used "enforce" word, that's not what I've ment. It can just warn, or ask to do it and/or have option to disable it. It can detect presence of `.git` etc. This idea is just such a no-brainer...
But at that point it can be implemented externally easily (Cargo allows for arbitrary subcommands). That way Cargo devs don't need to decide which one they want to favour over another.
I'm also looking forward to the next one. Very interesting first episode.
Wrong rust.
thank you!!
That was a fun watch. Have you considered using Preview.app or something like that for the PDF datasheet? I've found enabling "Table of Contents" view to be invaluable when viewing datasheets like that (only if they are built with an embedded table of contents). If not, you can set up bookmarks for quick access (you seem to be jumping between register definitions, the main index and some other distinct blocks a lot, with a lot of time spent hunting for them each time). [Here's what I mean](https://www.dropbox.com/s/wdvfzwmxrqt4a4h/Screenshot%202016-01-18%2008.02.08.png?dl=1) Hope to tune in again soon!
Good call, I pretty much just found that datasheet and ran with it live, so I didn't think of viewing it outside the browser. Thanks for the tip!
https://www.dropbox.com/s/vv3biui28tgjg35/Screenshot%202016-01-18%2008.06.50.png?dl=0 That datasheet you had has inbuilt annotations! Just open it in Preview and hit command-option-3. Enjoy!
Yay! I too had this idea, but haven't had the time to get around to it. I'm glad someone is, as I love writing rust on my Pi for some oddball reason. ^^No ^^really, ^^anyone ^^know ^^why?
So rad, thanks again :D
One simply does not learn C++. It is a journey, not a destination. As others have said before, by learning Rust, it will teach you how to handle memory safely. Something that can only be learned from C and C++ by `Segmentation fault: 11` and that is only when you are lucky enough to have your program crash.
This is actually quite useful! Might come in handy for some hacks I have in mind..
Ah, I see. Yes, that makes sense. The only things that would be nice to have a bit more confidence in it would be to have the author sign it, to have authenticated communication with the hosting server, and to have public feedback as mentioned... But even with all three your point does remain relevant. &gt; I am more than happy to download some code from crates.io or Github or Homebrew or the ever-exciting `curl awesomesite.cx | bash`. Go wash out your mouth with soap. ;) At that point you might as well use `sudo` too.
&gt; author sign it [...] authenticated communication [...] public feedback Yeah, all of those would be good to have, and it looks like there is some general consensus along those lines, it "just" needs the time and effort put towards an implementation. &gt; At that point you might as well use `sudo` too. I don't know what you mean... I just log in as "root", why would I need to run `sudo`? \^_\^ &lt;/sarcasm&gt;
I've been waiting to see a good example of someone putting in a backdoor in an OS project and just linking people to it on something like Reddit. It's really one of the easiest vectors. Make a half interesting project and add a backdoor. People will sudo make install without a second thought. People are really silly these days about installing any damn program they find on github. I at least try to skim the code if its not a massive popular project like apache. And if I don't need it, I don't install it. Installing third party code willingly is one of the biggest security threats these days IMO. People are trusting and curious, and too lazy to read the source. I'm trying to avoid that habit. Reading source is fun, either way.
Updating Rust fixed the problem for me. Thanks!
Have you tried wrapping it in an `Arc&lt;Mutex&lt;T&gt;&gt;`?
First time watching live coding: It's neat but I kind of wish there was a quick good way to get an accurate transcript. 3 hours is just a tad long and text has better random access!
&gt; At a certain point every programmer should learn C. It gives you the full control over your memory but also forces you to control everything. I really hate that meme. Machine models can be learned without learning C.
Would you mind giving a one-paragraph explanation what such a library gives us or cases where it might be used? I've never needed to use WiringPi before \^_\^
[removed]
Mainly, the GPIO pins on the RaspberryPi is used for a lot of different things, but mainly to control other hardware components that would be connected to the GPIO pins. For example I'm working on a small project that blinks and LED (controlled by the GPIO pins) on a raspberry pi from an iPhone app as a PoC of RGB Angel lights of a car (https://github.com/Vikaton/MagicLEDPi). There are countless of other uses and lots of pretty cool projects from adafruit: an LED audio spectrum thingy: https://learn.adafruit.com/raspberry-pi-spectrum-analyzer-display-on-rgb-led-strip/led-strip-and-rgb-led-software a simple Robot: https://learn.adafruit.com/simple-raspberry-pi-robot/assembly and so much more at https://learn.adafruit.com/category/raspberry-pi So this library helps you use the GPIO pins programmatically :)
 use std::io; fn main() { let mut input = String::new(); io::stdin().read_line(&amp;mut input) .ok() .expect("Couldn't read line"); println!("hello {}", input); } ^^ That right there should get you going, but have you seen the book yet? It's fantastic! [This section of the book](https://doc.rust-lang.org/book/guessing-game.html) walks you through a simple guessing game, user input and all, and the rest of the book explains so much more...it's totally worth the time to read through it. Happy learning!
Finishing up a pull request to improve the do-like notation provided by macros in Chomp: https://github.com/m4rw3r/chomp/pull/31
I think unwrap or unwrap_or_else may be a bit cleaner than the match.
Is the current syntax `0..10` and `0...9` being the same thing? Because that seems like a big big mistake to me. On the other hand I do quite like `0=..&lt;8`, it may be verbose but it's just so logical.
you say you know C++ but don't know C? C++ is a superset of C.
It would be nice to have some way of doing it automatically though, even if it's opt-in. Something like `cargo publish --tag`, maybe.
very cool. thanks.
I think there will be a Rust 2.0, but I don't think it'll be named "Rust", for this reason.
When you want to use the FFI, you should know how pointers work. The c interfaces are often the most low level that you get, but the only one that can be used by the ffi or compilers by most languages. Lua and python for example can call C functions. When you mix rust and C++ you need to go through a wrapper written in C.
I'll continue to work on the network stack for [Uni.rs](https://github.com/uni-rs/uni.rs). Xen network driver is now 100% working (both RX and TX). The stack is able to process and respond to ARP requests. I still have some code cleanup to do before everything lands on the repo. Next step: ICMP. Hopefully, we will be able to ping an application using Uni.rs soon !
&gt; When you want to use the FFI, you should know how pointers work. The c interfaces are often the most low level that you get, but the only one that can be used by the ffi or compilers by most languages. For that, I only need to know a very very small subset of C. Knowledge about memory locations and pointers does help, but this can also be tought using, for example, Rust.
[Here's a failed attempt at backdooring the Linux kernel in 2003.](https://lwn.net/Articles/57135/) Not exactly what you're looking for, but it should be close enough.
Use git flow. It handles tagging. It also provides a robust way to have active development with simultaneous potentially breaking feature development, hotfix releases, and normal development. http://nvie.com/posts/a-successful-git-branching-model/ I guess having crate tag whatever branch you publish from is an OK fallback, but I would always disable this and use git flow.
Here's the problem with TUF: It's a typical security project. * There is an implementation in python * It claims to "integrate well" * It's hard to find actual integrations * All security consultants claim that you should "just" use it * While not undocumented, safe usage examples are rare * The spec admits that certain usages of the framework are insecure. Now, that doesn't make TUF bad, it just means that "just use it" is just not possible. Would anyone take up the work to implement TUF for Rust, especially the client side?
Follow the (likely) implementation path the whole product has taken. Basically a learning experience.
[removed]
Not a clippy developer so I can't say for certain but my guess would be no. Compiler plugins like clippy only see a stream of tokens (as far as I know) so they aren't able to differentiate even between macro-generated code and regular code, let alone which crate the macro came from. Your best bet is to make a pull request to the library the macro comes from that fixes the generated code to not have the warnings. If that isn't an option you could always disable the specific lint that's causing trouble. 
AFAIK, the `v` was dropped with SemVer 2.0.0, which is my main justification for not using it.
[removed]
You can ignore some lints if you want. Or fix them. :p
I do like that proposal. But I think it's been too long that we've argued over the syntax with nothing implemented. Once things land unstable we can play with them and argue from experience instead of theory.
Signing provides some level of assurance even without a web of trust; for example you can verify that the new version 2.0 was indeed signed by the same person who signed 1.0 and 1.5.
I can't check right now, but I think many of clippy's lints do ignore code produced by macros. If there are false positives caused by macros, it's probably a good idea to file a ticket with the specifics on the clippy repo.
thanks!
You're more than welcome! I expect /u/nick29581 would have more info on it if you need.
Implement the `MethodCommand` trait for all the functions that match `execute`'s signature. impl MethodCommand for FnMut(Optionn&lt;Params&gt;) -&gt; Result&lt;Value, Error&gt; { ... }
Yeah, we're in the process of adding macro checks to most lints. Feel free to file an issue for your particular case.
Are you suggesting that the actual Rust language change to use `begin` / `end` for blocks? Or do you just want to make your own fork of Rust that has that? Also, do you want to *replace* existing `{`, `}` with `begin`, `end`, or support both at the same time? It sounds like you want both... Aside: you can use backticks (\`) around a word to make it in a monospace font: \`OpenDelim\` -&gt; `OpenDelim `. You also have a typo in "string" and a few other grammatical issues. Cleaning those up *may* make people able to understand quicker and more likely to respond.
Also worth noting that in the next() function this bit is broken: self.iter.next().map(|i| DataHandleMut { item: i, data: &amp;mut self.data }) There's a reference to self.data being taken, where self.data is already an &amp;mut. It should be data: self.data.
I wonder if we could just add both syntaxes, while everything is unstable (intention being to only retain one of them). They don't seem to conflict. The question is what kind of struct `a&gt;..&lt;b` lowers to.
I suppose `a&gt;..&lt;b` could just be sugar for `(a+1)=..=(b-1)`. Also I feel like I should make some sort of joke about how that looks like a face, but I can't think of one.
whoa, crazy
Are you posting here under two accounts...?
True. Maybe to begin with you could just allow it on the right (`0..=9` or `0..&lt;9`), since that's the common case anyway.
As an ex-molecular neurobiologist, I've always been fascinated with biologically-inspired machine learning and emergent systems. So in my free time, I've been working on a neural cellular automata system loosely based on the [CoDi-1bit paper](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.2.17&amp;rep=rep1&amp;type=pdf). It's a fun mix of high- and low-level. Growth and processing is done in parallel by using Rayon's `into_par_iter()`, which has been super clean and high-level approach so far. The grid is accessed via enums and a wrapper struct, but under the covers it does a lot of bit manipulation on u16's to encode the state, roaring-bitmaps to track active cells, etc. It's tentatively named CAjal, after Santiago Ramón y Cajal the "father of neuroscience", and because the "CA" stands for Cellular Automata. :)
you want /r/playrust
Thanks for the bindgen idea, I came across this, is this more convenient? https://github.com/manuels/cxx2rs
:3
I've never tried that one personally, so I couldn't say.
Seconding the bindgen recommendation - it makes it crazy easy to generate correct rust bindings for just about any any C library you have a header for. The only thing that I wish it has is macro support. A lot of times, C headers will include a lot of constants via `#define`'s, and bindgen currently (or when I last used it at least) doesn't include them.
Yep, that's adorable. I would buy a t-shirt with Morris to complement the one I have of Ferris. Edit: Or a sticker! Someone make it happen! :3
d'awwwwwww! I &lt;3 it! :)
Right, but you could, in theory, translate something simple like #define FIVE 5 to macros_rules! FIVE { () =&gt; { 5 } } and it would keep all of the same don't-care-about-types semantics since they're both just macros. Although then you'd run into the problem of polluting the macro namespace. 
Where do I buy a rust tshirt?????
I absolutely need a shirt with Morris and Tux on it.
`find` needs to use the `Self::Item` again, since it returns `Option&lt;Self::Item&gt;`, and hence it cannot pass away ownership. On the other hand, `any` just returns a `bool` and does not need to use elements again, and so it can give users maximally flexibility by handing ownership to the closure. The implementations are informative: [`find`](https://github.com/rust-lang/rust/blob/7a7307e5cf08ad25de62d4f9e13ddd58c59881c8/src/libcore/iter.rs#L1724-L1732), [`any`](https://github.com/rust-lang/rust/blob/7a7307e5cf08ad25de62d4f9e13ddd58c59881c8/src/libcore/iter.rs#L1671-L1681).
I tried to run your code and the part you have a problem with works fine for me, but I get errors elsewhere. Tested using rustc 1.7.0 nightly, and the latest versions of the crates your using. Maybe try a `cargo update` or delete `Cargo.lock`?
&gt; and so it can give users maximally flexibility by handing ownership to the closure. Wouldn't borrowing, instead of taking ownership, be more flexible?
It would be more flexible for `any`'s internals, but less flexible for the callers of `any`. By having that signature `any` is basically saying "my internals don't need to borrow" (and implicitly "and they won't be changed to need to borrow in future"). Adding (trait) bounds to a function means the function can do more internally because they have more info about the types, but means the user can do less because fewer types will satisfy those bounds. This is a similar situation: `Fn(Self::Item)` is a looser bound than `Fn(&amp;Self::Item)`, since every thing that implements the latter can be trivially adapted to implement the latter too, `|x: Self::Item| f(&amp;x)`.
You can always just call ```iterator.by_ref().any(...)``` to solve this. Update: You can't.
Is it because a function type is contravariant in its argument, so the subtyping relationship is reversed? That is: it's more flexible for the caller to call a function that borrows its parameter (as in `fn f_borrow(x: &amp;X)`) instead of taking ownership (as in `fn f_own(x: X)`) because if I have a `x: X` I can just call with `f_borrow(&amp;x)`. Or, as the following table: With | I have x: X | I have x: &amp;X ---|---|--- | f_borrow | f_borrow(&amp;x) | f_borrow(x) |f_own | f_own(x) | Not possible to call But it appears that when taking a closure this is reversed: `fn g_own&lt;T: Fn(X)&gt;(c: T)` is more general than `fn g_borrow&lt;T: Fn(&amp;X)&gt;(c: T)`, because as you said one can call `g_own(|x: X| f_borrow(&amp;x))`. That is: With | I have f_own: T: F(X) | I have f_borrow: T: F(&amp;X) ---|---|--- | g_borrow | Not possible to call | g_borrow(f_borrow) | g_own | g_own(f_own) | g_own(&amp;#124;x: X&amp;#124; f_borrow(&amp;x)) I'm not sure I fully grasp this (variance is a subject that always confused me). But, my take is: if `g_borrow` wanted to receive a borrowing closure, it's because it must not actually be willing to handle over ownership to the closure; so a closure that takes ownership is of no use to it. But if `g_own` is okay with handling ownership to a closure, passing it a closure that doesn't actually need ownership also works. I think the book should have a chapter on this (if it doesn't already have). --- &gt; `Fn(Self::Item)` is a looser bound than `Fn(&amp;Self::Item)`, since every thing that implements the latter can be trivially adapted to implement the latter too, `|x: Self::Item| f(&amp;x)`. I think you mean "everything that implements the latter can be trivially adapted to implement the former".
Surely, that would be something interesting for both projects and others that want to get the network working on there OS. I am not very familiar with redox code (so correct me if I am wrong) but it appears that the network code is somewhat glued in other OS related mechanisms. I am trying to create an "independent" network stack. I want it to be a black box (similar to Lwip) in the sense that it has a driver end (TX/RX packet) and an user end (TCP/UDP sockets). The only necessary code to port it to a new OS would be the network driver and some OS primitives (locks, threads, ...). This is something that I am trying to achieve by having the network stack only depend on some of Uni.rs's primitives, so that one day it can be used as a crate similar to what Lwip does.
I don't know, but I thought they had plans for user-space networking (as mentioned in [this week in Redox 2](http://www.redox-os.org/news/this-week-in-redox-2/)), so it looks they wanted their networking code to be decoupled from the Redox kernel. Now, I'm not sure in which ways their userpace interface restrict how this networking code would be written. Perhaps one could abstract between the Uni.rs and Redox concrete types using traits (a bit like [piston_graphics](https://github.com/pistondevelopers/graphics) abstracts between glium, gfx and raw OpenGL using a trait)
How would the regex `(a|b){4,100}` be written using Verex? (or even `(a|b)*`)
When you call `.compile`, it returns [`Result&lt;Regex, Error&gt;`](https://verbalexpressions.github.io/RustVerbalExpressions/verex/struct.Verex.html#method.compile). But you could have a type like this: enum Parser { Regex(Regex), LLGrammar(OtherType), } And return `Result&lt;Parser, Error&gt;`, compiling to a regex when you can (that is, when the user doesn't call any method that makes it impossible to compile into a regex), and compiling to something else if not possible. But not sure if in practice this would be useful. Anyway: your library has an interface similar to [combine](https://github.com/Marwes/combine), that implements a LL(k) grammar. Similar in the sense that combine's `many(letter())` is the same as the regex `[[:alpha:]]*`.
You are right. The closure still expects an owned value. Interestingly enough by_ref() makes it so that the closure gets access to the owned value without actually moving the ownership into the closure. That seems pretty odd to me. Is there any good explanation for that? This is the first time I'm seeing a function taking an owned parameter without it actually getting ownership over the value and there being no clone involved. Update: nvm, by_ref() and then 2 calls to any() results in the first any consuming all elements of the iterator and the second any() then iterating over an empty iterator. So yeah, that explains everything and yeah, by_ref doesn't do anything then.
Thank you for this, I started learning Rust recently and it explains many things that wasn't clear in my mind yet.
Why is the `handle_mut()` function allowed when the iterator's `next()` isn't? They're both returning structures containing a mutable reference [re-]borrowed from an internal field.
Thnak you! I mislead myself thinking there is some difference between take_while and filter but it was indeed the two different operators. It all makes sense now. Now my question is, which is preferred? 
Yes it is, for their current semantics. Current semantics allow: let first = iter.next(); let second = iter.next(); assert!(first == second); That is: you can have several (all in fact) iterator elements alive at the same time.
Your answer is like the prototype for how this should be handled.
No, there's absolutely no difference in the performance. Everything gets inlined anyway, so the compiler won't introduce any unnecessary indirections and the compiled Assembly is the exact same.
This is great i've been looking for something like this, thank your very much!
I don't know much about it, but [PDCurses](http://pdcurses.sourceforge.net/) may work for you.
I generally do what you do; politely direct them to the appropriate sub. If you're feeling ambitious, you could also give a one-sentence explanation for what Rust the language is, but that's not really necessary. There's not really much more the mods could do, other than just deleting the thread, while politely directing them to the appropriate sub is helpful and provides them quicker feedback.
Doesn't look like it, it just wraps termbox which uses nix* functions and doesn't appear to have a windows port.
Thanks, it is the first time I post on Reddit
Here i was thinking crab! was some sort of new macro :). Love the art work, looks very nice.
Thanks very much, I edit my code， which cannot use downcast from Box. ` let bar = Box::new(Bar) as Box&lt;Foo&gt;;`
Sorry, my answer was actually incorrect. A `Box` is an *owned* pointer. You can't have two `Box`s owning the same object.
Aww! Love Morris!
In Rust? yeah its unsafe. Your converting a read-only pointer to a read-write pointer. This can lead to use-after-frees, and all the fun stuff that Rust Pointer Aliasing Rules attempt to prevent.k In C? yeah your fine. &gt;Isn't Rust just C with a fancier compiler/type system? *cough*
Maybe there could be a lint for redundant borrows? Or, maybe stylistically it's better to show that no ownership transfer is happening... This is firmly in the "ship already sailed" department, but one thing I wonder about is if there's any way Rust could've been designed so that you always had to put `&amp;` or `&amp;mut` in front of an argument in order to pass a borrow, rather than being able to directly pass in values that are already references. Rust basically started out with passing modes, then transitioned to first-class reference values, and then designed them halfway back to being passing modes again (deref coercions encourage seeing `&amp;` as a borrowing operator rather than a referencing operator), leaving the language in an odd position where references are first-class values that behave somewhat like a passing mode. It makes me wonder if Rust had evolved freely for a bit longer whether it would've gone full circle and readopted passing modes using the lessons learned along the way.
Yeah! Maybe something like: http://imgur.com/Nyy4bpe
Yes, your code is unsound, because you create a new box from a reference. You don't notice the error because `Bar` is a zero-sized-type, but if you by analogy consider the case where you pretend a `&amp;[T]` is the memory of a `Vec&lt;T&gt;`, you have something that breaks the laws of type safety, ownership, and causes double frees.
I've personally had a very enjoyable time learning `xcb` with Rust for a game I'm writing :D ([Handmade Hero][handmade_hero] in Rust on Linux) [handmade_hero]: https://handmade_hero.org
Ambiguous terminology 😉. I'm assuming that you mean that always writing `&amp;mut` could result in double indirection, especially if you're passing to a function accepting `T` or `&amp;mut T`, where `T` is a type parameter. It's only in cases where `T` is a concrete type where `&amp;mut` can be a no-op. In that case, you're right, a style where you always write it wouldn't really work in a lot of cases. A lint for redundant borrows might still be useful, though. The reason I say "ambiguous" is because "reborrowing" has a specific meaning in Rust which is basically the opposite of what I think you meant. Essentially, if you have `x: &amp;mut T` and you pass it to a function by writing `f(x)`, that's equivalent to writing `f(&amp;mut*x)`, which is referred to as "reborrowing". Rather than getting moved or copied like any other type of value in Rust, a new borrow is created with its own lifetime.
I had a course of C++ with both people with C background and no C background mixed. It was just the basics and some GUI'ing was taught with Qt. In the end people would be able to create GUI apps with some OO happening, file I/O, basic networking, etc. Now, people with no C background still had no idea how to program in C, they knew that C++ was "an improvement" of C, but would not know how to program outside the taught model. So, it's perfectly reasonable to claim you know (to some extent) C++ but not C.
Very nice, thanks for saving a lot of work.
Ahh, yes. Well put.
There are international competitions for SAT solvers. I think that it would be pretty hard to match their performance.
Thanks for the tip!
Thanks for posting this :)
I know, right??
you're*
What happens when you do this before the `for` loop: ``` fprintf(stderr, "%p\n", &amp;M); ```
Well, variance isn't really involved here, since the compiler isn't actually reshaping any types. "everything that implements the latter can be trivially adapted to implement the former" is correct here, the API is such that on the user's side you may adapt it easily. However, variance runs on the same principle, really, the direction in which you can go depends on whether you are a caller or callee. But we only have it for lifetimes (it's also limited and only goes in one way though it used to go both ways). There is no variance in the compiler for automatically borrowing arguments or converting moves to borrows. This is just conceptually similar to variance where the user has the ability to make a type fit the API.
&gt; But we only have it for lifetimes I see, saying it's contravariant wasn't the proper terminology. &gt; This is just conceptually similar to variance where the user has the ability to make a type fit the API. I think this concept, of the "variance"-like aspects of borrowing and function types, should be featured in the book. Well. Perhaps not the book. But it's related to API design: you should know this stuff to design good APIs, that doesn't introduce unnecessary burden to the callers. And while it's "obvious" for seasoned Rust developers, I think it's within the scope of the Book to pass this lore. 
&gt; I see, saying it's contravariant wasn't the proper terminology. It is the right term for the concept, just the "subtyping" relationship is more broad than the subtyping Rust has built-in. (I.e. we're considering `&amp;T` a subtype of `T`, because any `x: T` can be "coerced" to the former with `&amp;x`.)
I believe you also need to set `RUST_MIN_STACK` (it's a number of bytes).
Doesn't that only apply to threads created from within the already running Rust program? Edit: Going through the source really quickly indicates that `RUST_MIN_STACK` applies when calling `Thread::spawn` and it's applied in `min_stack()`, if the stack size was not explicitly set using a `Builder`, and then those threads will default to 2MB in the event neither was set explicitly. So far I haven't found that the main/initial Rust thread goes through a `spawn` call (or otherwise calls `min_stack()`) so I can't say for sure whether it respects the environment variable or not. I can check when I get home.
yes
I think that it should be a verex method that either accepts another verex as parameter, or a string (you can do this by accepting a parameter `T: IntoVerex`, such as `String`, `&amp;str` and `Verex` implements it). Something like this: `Verex::new().many(Verex::new().find("a").or_find("b")).many1("c")` would compile into the `(a|b)*c+` regex. For this same reason, `.maybe` should optionally accept a verex too, etc. (you can have `(a|b)?` instead of just `a?`) Also, you probably need something to reduce the `Verex::new` noise. Perhaps `verex![find("a"), maybe("b")]` should expand into `Verex::new().find("a").maybe("b")`. Actually. Not sure if this is a good idea. Well, you already have an `or!` macro, which is nice.
Anyway, screw that - you are probably better off having Verex be "only" a convenient regex library.
It would be more like `T: IntoString` because that is the basis of the Verex struct, so I'd just go with something like `Verex::new().many(find("a").source())`. I do need a story for adding `*`, `+` and ranges of recurrences for things other than `.` I also have all the functions as constructors so you can do `find("a").or_find("b")` easily.
Yeah I think I'm gonna go with that, also because I want to be sort of similar to the other Verex projects.
we're still pretty far from that part, but it's super fun already nonetheless!
The actual error message is ``` error: the trait `core::convert::AsRef&lt;std::path::Path&gt;` is not implemented for the type `(&amp;str, collections::string::String, collections::string::String) ``` It tells you that `AsRef&lt;Path&gt;` is not implemented for the given tuple that you're passing. It does not automatically know that you want to format the arguments based on the string you gave, you have to explicitely call the `format!` macro and then it works: ``` let file = std::fs::OpenOptions::new().create(true).open(format!("{}/{}.extension", args[3], args[5])); ```
Just wanted to say thank you on behalf of everyone new to Rust for taking the time to provide such a thorough response. 
There are tens of thousands of constants in `winapi` and it already takes a minute just to compile. I'm pretty sure if I switched to providing macros for all of them I would trigger some `O(n^2)` algorithm in rustc and the compile times would go through the roof.
And the compiler spawns a thread [here](https://github.com/rust-lang/rust/blob/7561466948727be1ce20a7e349b53b6d0f86dbe9/src/librustc_driver/lib.rs#L867) in order to catch ICEs (I wonder why they don't just use `panic::recover`).
This is still on the to-do list to incorporate into my project!
NES or GB. Always where I recommend starting. The architectures are documented *amazingly* well: [Gameboy](http://bgb.bircd.org/pandocs.htm), [NES](http://wiki.nesdev.com/w/index.php/NES_reference_guide); they're dead simple MMIO-based designs and the CPU's have fairly basic [opcode tables](http://www.pastraiser.com/cpu/gameboy/gameboy_opcodes.html) + timing. Whereas a *good* SNES emu would take a beginner months to get to a decent level, they could be running diagnostic + basic ROMs on one of those in a few weeks to a month.
Question about that repository. Can Rust also handle platform support with separate package files, such as syscalls_linux, syscalls_openbsd and syscalls_windows?
Legacy, that code is waaaaaaay older than even the notion of recover() being safe. :)
that was it. Thank you so much for the swift reply!
It basically addresses the original vulnerability, and is somewhat helpful with the points listed in the linked article (which are really mitigations for the fundamental problem, but definitely good as part of a defence-in-depth strategy). In particular, the risk of private key exposure is because one could read uninitialised data out of an allocated buffer, and the lack of initialisation means this may contain data that was previously `free`d. Rust doesn't allow this to happen; data is either not accessible, or is initialised. For the points in the article: - [`File`](http://doc.rust-lang.org/std/fs/struct.File.html) is unbuffered (although not explicitly documented as such), but it is fairly common to either use it inside [`BufReader`](http://doc.rust-lang.org/std/io/struct.BufReader.html), or to use something like [`read_to_end`](http://doc.rust-lang.org/std/io/trait.Read.html#method.read_to_end) which uses `Vec`, an automatically reallocating buffer type, which brings us onto the next point. - The most common data structure is `Vec` (specifically `Vec&lt;u8&gt;` for this) which is a convenient buffer management utility, including calling realloc automatically. However, one can either wrap this in a type that's more careful about the operations it exposes and reallocations, or, use `Box&lt;[u8]&gt;`, which is fixed-length. - The last point is completely language agnostic. Also, Rust does provide significantly more powerful abstractions than C, e.g. one can create buffer types that automatically zero their memory when dropped (or reallocated). (When I say "Rust disallows *X*" I mean safe Rust, `unsafe` Rust can do anything... and, unfortunately, even if you don't write any `unsafe` yourself, there may be a bug in `unsafe` code that causes problems. That said, the surface there will be much smaller than the whole program as it is in C: the explicit `unsafe` makes it easy to focus more testing/analysis/etc. on the code that is likely to be the most risky.)
~~How can a 4-byte IPv4 address have a 12-byte prefix?~~ Do you think pre-processing the IPv4 addresses into 5 bytes (adress + prefix length) could speed up the process? I'm also considering doing something with "big data" just for fun, most likely using d3 and AJAX to get a live display of the results on my website. :)
While we're at it, it's a bad idea to use `String` for command-line arguments which might be filenames, because there's no guarantee that these can actually be interpreted as UTF8. `env::args_os` will return them as `OsString`s, which will avoid panics when users have non-UTF8 filesystem encodings.
I see. Check out `Option::as_ref()` then, e.g. `foo.a.as_ref().and_then(...)`.
The biggest issue to distributing Rust libraries that are proprietary is that our ABI is not stable. This means that you'd have to provide a version for each version of the compiler you want to support. &gt; is there a way to distribute a crate via Cargo without distributing the source code? No, Cargo is source-only.
Yep, it can! The first example that comes to mind is [glutin](https://github.com/tomaka/glutin), a cross-platform window creation library in Rust. It's pretty standard to see platform-dependent parts split into their own modules, as seen [in the source](https://github.com/tomaka/glutin/tree/master/src/os).
&gt; I understand that MIR is supposed to relax the borrow checker; To be clear, MIR will make it easier to implement proposals that change the borrow checker. There's no current RFC that actually proposes non-lexical borrows. That work will come after MIR is done.
That worked perfectly, now I need to try and wrap my head around why...
Good info. OP might have different ideas, but if I were to sell closed source library then I would take the general stance that locks are to keep honest people out; in other words I wouldn't worry overly much about reverse engineering/decompilation. 
I see. Yes it's possible but... AFAIK it isn't "build in". It's still an interesting approach.
in this simple case (where they are small and "copyable") you can also make your structs derive Copy: http://is.gd/L4vHNJ
&gt;Whereas a good SNES emu would take a beginner months to get to a decent level, they could be running diagnostic + basic ROMs on one of those in a few weeks to a month. Out of curiosity how would you handle snes starfox (superfx)?
There are two questions here: - is it possible to create a proprietary library in Rust? - is it possible to distribute a crate via Cargo without distributing the source code? The answer to the first question is: **Yes**, the Rust license is liberal enough that you can use Rust and link with Rust's Standard Libraries in a proprietary product. The answer to the second question is: **No**, Cargo is source-only, and as said by Steve in the absence of a stable ABI you would have to provide compiled binaries for each version of the compiler and each platform you plan to support... for each version of YOUR library. Of course, this can be automated, but it's still a lot of binaries. Note that proprietary does NOT imply closed-source. You can, and I encourage you to, have people buy your software (or pay for licenses to use it) AND expose the source code. In my personal experience, the only libraries I used which are closed-source (and obsfuscated...) are Oracle's and that's only because I was forced to; I don't mind paying for software, but the inability to debug efficiently is a HUGE downside.
Cool! :) I've currently got my hands full, but I'll bookmark this for when I decide to try it out.
That is quite a bit simpler. The actual structs that I'm using are much larger though. Just a reduced sample, but definitely something to keep in mind for later. Thank you!
I should also mention that we are very interested in supporting commerical users of Rust generally, so this is a problem we will want to have solutions for. But we also don't want to rush into something as serious as ABI stability just yet.
&gt; Note that proprietary does NOT imply closed-source. Those terms are very similar, actually. You probably meant that commercial and proprietary are not always linked: some gratis software is proprietary, and some libre (and open source) software is commercial.
&gt; This (especially #2) can allow recovering a large amount of original source code. Note that this is no worse than the situation in Java or C# (although both of them have obfuscators to mitigate this).
Someone really ought to write a nice terminal UI library in Rust, I even have a nice middle level wrapper around the Windows console stuff in `wio`. I mean, look at how simple it is to work with the Windows console API through that wrapper https://github.com/retep998/wio-rs/blob/master/examples/console.rs If anyone wants to work on a terminal UI library in Rust that supports the Windows console, please get in touch with WindowsBunny on IRC.
This isn't just a DNS propagation issue. The domain isn't known neither the root DNS servers nor any of the DNS servers listed in the whois.
I read some drafts of this, it's really good!
Well wouldn't what's awkward depend on what resources you have available?
Glad you like it!
new to rust but maybe this struct Foo { a: Option&lt;Bar&gt;, } struct Bar { b: Option&lt;i32&gt;, } fn main() { let bar = Bar {b: Some(123)}; let foo_vec = vec![Foo {a: Some(bar)}]; let _ : Vec&lt;Bar&gt; = foo_vec.iter() .map(|f| Bar {b: f.a.as_ref().and_then(|x| x.b)}) .collect(); }
Neat! Some more candidates: - [CoIO](https://github.com/zonyitoo/coio-rs) (and [SimpleSched](https://github.com/zonyitoo/simplesched)): mio-based coroutines like Mioco, just different api. - [Context-rs](https://github.com/zonyitoo/context-rs): the context switching library used by both CoIO and Mioco - [Chan](https://github.com/BurntSushi/chan): a more ergonomic MPMC channel (but lower performance compared to std's mpmc) - [Bounded-SPSC-Queue](https://github.com/polyfractal/bounded-spsc-queue): higher perf than std's sync_chan if you need bounded SPSC semantics. Shameless plug, this is mine :) - [SPMC](https://github.com/seanmonstar/spmc): Unsure if this works... - [Threadpool](https://github.com/frewsxcv/rust-threadpool): simple pool of threads - [Syncbox](https://github.com/carllerche/syncbox): "A collection of concurrency utilities for Rust" - [Latest](https://github.com/mitchmindtree/latest): "a channel that acts exactly as std::sync::mpsc::channel does, but rather than storing messages in an underlying queue, it only stores the latest message." Edit: Just a quibble actually: maybe rephrase "Rust itself" to something like "Rust standard library" or similar? I believe all of that is provided by std not the language itself (other than atomics via llvm intrinsics) 
In this case I believe that parent was referring that you can distribute proprietary software in source form to your customers without giving them rights to redistribute the source.
My first attempt at a Rust module. Code reviews / feedback welcome prior to pushing it up to Cargo. Thanks!
Same repo: https://github.com/Gankro/thesis/ (project structure jacked from my labmate Sander Verdonschot)
I wasn't sure how to capitalize the title for the submission, given that it's all in all caps in the rendered version. I suppose I should have thought to [check the source](https://github.com/Gankro/thesis/blob/1cbe3c70510549216107f1ca58b4654dad95044e/classicthesis-config.tex#L49), or just apply title case. Oh well.
Well, the "awkward zone" is very relative. I don't think there are that many laptops around with over 1TB SSD. But anyway, it's just a pretext to try and see how efficient you can make it instead of taking the easy way and scaling the hell out of it. 
Worked for me about 10 minutes ago.
[removed]
Yeah, I guess I should have linked to https://cdn.rawgit.com/Gankro/thesis/d2f0b64fe93c23923f3a43a7038427083edad4c5/thesis.pdf instead which includes the appropriate `Content-Type` header so it can be displayed inline in the browser.
Thank you for the thorough explanation. I guess I missed the part where you can own an outer object that contains an inner reference. Rust is definitely changing the way I look at things.
[removed]
Pony language is not discussed there...
&gt; impl InternedString { &gt; pub fn get(&amp;self) -&gt; String; &gt; } This seems unnecessarily inefficient. Are there any issues with: impl InternedString { pub fn with&lt;F: FnOnce(&amp;str) -&gt; T, T&gt;(&amp;self, f: F) -&gt; T; }
Looks nice! Just please, please, please, make sure that if you're not willing to update it, you set it up in a way that lets others take it over in the future.
Typo in chapter "2.1 basic syntax" let x: i32 = 0; // x is an i32 let y: &amp;i32 = &amp;x; // y is a reference to an i32 let z: i32 = *x; // z is an i32 (copied from x) struct Foo { data: i32 } let x: Foo = Foo { data: 0 }; let y: &amp;Foo = &amp;x; let x: i32 = y.data; // automatic dereferencing with ‘.‘ it should be: let x: i32 = 0; // x is an i32 let y: &amp;i32 = &amp;x; // y is a reference to an i32 let z: i32 = *y; // z is an i32 (copied from x) &lt;--- struct Foo { data: i32 } let x: Foo = Foo { data: 0 }; let y: &amp;Foo = &amp;x; let z: i32 = y.data; // automatic dereferencing with ‘.‘ &lt;---
That's true, but it's more relevant to things like performance than it is than using them for safety, which is the topic here.
I've also done chip-8, and it was a good stepping stone. I would still recommend it as a _first_ emulator, but I also recommend not making it your last :)
Submit a PR if ya want it fixed... otherwise, *shrug*, I got my degree. :P
It seems to be based on the [classicthesis style](https://bitbucket.org/amiede/classicthesis/wiki/Home) (which mimics the style of the book "The Elements of Typographic Style" by Robert Bringhurst).
I think that's what I said, yeah. 
Based on the inclusion of rayon, I guess that [pure parallelism](http://composition.al/blog/2014/11/24/yet-another-blog-post-about-how-parallelism-is-not-concurrency/) is of interest too. If so, there's quite a few extra crates, e.g.: - https://crates.io/crates/timely/ - https://crates.io/crates/simple_parallel/ - https://crates.io/crates/arrayfire/ - https://crates.io/crates/collenchyma/ (I don't know much about anything except for `simple_parallel`, which probably fits best into "Functional, though still prone to change".)
Another option not mentioned is to distribute an executable and communicate with it over a well defined protocol like protocol buffers, thrift, capn proto and etc. You could open source the client side and protocol, while keeping your source private. 
Which part ? The why-it-is-faster part or the which part of the lucene code messed up?
Your about link 404s, it should probably go to http://blog.carlosgaldino.com/about.html instead of http://carlosgaldino.com/about.html.
When do InternedStrings get deallocated and what happens if you still have their `&amp;str` pointers?
An `InternedString` lives for as long as the thread it was created in lives for, I don't think it's even possible to have a `&amp;str` live longer than that.
Rust is all the pony I want.
Looks like it requires unsafe? Seems easier to just use crossbeam.
To be fair, catching me outside of my home, particularly lately, has been a difficult feat. Do you go to Carleton? I gave a few presentations on Rust there over the past ~year.
The example I think is outdated. There was a bug making it unsafe to call which was patched in Rust 1.4 (then nightly), but any version after that has it without safe to call. Now that 1.5 is our current stable, it can probably be updated (in fact, there's even a PR for it which has been open for a month: https://github.com/Kimundi/scoped-threadpool-rs/pull/9)
Sure, I messed up with that one. Thank you!
&gt; If you don't want to install Rust, multirust is also available on Eniac Well named student server. I chuckled a little. It looks like the slides and homework are all going to be up on the web? I will point this out to some of my colleagues who have been thinking of looking at Rust but prefer more structured learning.
Yep, we will release all of the slides and assignments publicly.
Nice catch; thanks! We'll fix it.
Also, travis-ci participates in github education pack and provides private builds if you're interested https://education.github.com/pack 
&gt; I suppose that most security bugs in Rust programs that end up in disaster will be bugs in unsafe code. Yes, that's exactly why I mentioned the defense-in-depth philosophy, one that is held by many in the Rust community (e.g. the Servo team): don't just rely on the language guarantees, but include other measures that will mitigate bugs in the compiler/the language/`unsafe` code/external libraries etc. (It is also why I wrote the last paragraph of the parent comment.) &gt; I think Rust is expecting expertise from programmers that may not necessarily be experts. Eh, `unsafe` code is pretty clearly marketed as a "you better know what you're doing" tool. If people wish to shoot themselves in the foot, they're free to, but Rust is definitely not *forcing* them to. This fact is true of essentially all languages (e.g. Haskell is generally regarded as super-safe, but still has things like `unsafePerformIO`). As you say, Rust can't prevent programmers from doing their own thing.
It is possible to have long-lived `&amp;str`s, e.g. a literal `"foo"` is a `&amp;'static str`, which lives for the whole length of the program, and with, for instance, [scoped threads](http://aturon.github.io/crossbeam-doc/crossbeam/struct.Scope.html#method.spawn) one can even have dynamic strings that are guaranteed to outlive a specific thread.
These error messages are not very helpful, but at the moment to box closures you need to use the unstable [`FnBox`](https://doc.rust-lang.org/alloc/boxed/trait.FnBox.html). https://play.rust-lang.org/?gist=7258327ee7dff70e8a2d&amp;version=nightly
I always thought that the "big data" is a buzzword for "data that wouldn't fit in the reasonable amount of RAM".
`FnBox` is for a slightly different task: `Box&lt;FnOnce(...)&gt;`. The reason it is needed is `FnOnce`'s `call_once` method takes `self`, which currently makes it impossible to call on a trait object. `FnBox` acts as a proxy with a `Box&lt;Self&gt;` method, which *can* be called on a (`Box`) trait object.
The problem here is a `Box&lt;Fn(...) -&gt; ...` trait object doesn't actually implement the closure traits: it is callable because it dereferences to a `Fn(...) -&gt; ...` object (i.e. the `.call`/`.call_mut` methods are callable via autodereferencing). However this means that it can't be used directly in places that require generics that implement those traits, you'll have to ~~wrap it like `{ let f = do_some_fp(); move |t| f(t) }` (pretty lame, I know :( )~~, coerce to a borrowed trait object with `&amp;*do_some_fp()` as /u/-nmk- demonstrates. I believe [#19032](https://github.com/rust-lang/rust/issues/19032) is the relevant issue, although you can see it spelled out more explicitly in some comments on a different issue: [1](https://github.com/rust-lang/rust/issues/28796#issuecomment-161726177), [2](https://github.com/rust-lang/rust/issues/28796#issuecomment-171252018).
(Small point: `&amp;*` is coercing to a `&amp;Fn()` trait object, it's not possible to call a `&amp;FnMut()` one.)
Added to https://wiki.mozilla.org/Areweyet
A professor at UT Austin was seriously considering using Rust in his honors OS class. I'm not entirely sure if he ended up doing it, though.
Also probably Rusty.
lol at the first two slides. XD
I don't think so. But since you are dealing with a wrapper here (Box&lt;T&gt;) that doesn't implement the trait explicitly, you need to unwrap your inner Fn to get it to recognize the trait. * simply dereferences the Box into a Fn (through the Deref Trait impl of Box), but since Fn is neither sized, nor can you move it out of the box, you need to get a reference to that through &amp;, which makes it &amp;* overall. You could just do ```do_some_fp().as_ref()``` instead though, which is a lot more readable.
Not necessarily, the loop is allowed to take ownership of each element of `xs`. The desired behavior is not specified.
I seriously thought there was some connection to COBOL for a second. I was like huh..this is new.
I finished HW00 =p not even due until the 25th...awesome! 
[More or less](https://github.com/teepee/arewewebyet/commits/master)
nice! maybe you could do a PR? i already added GJ.
A bibtex file for this thesis would be great.
As someone learning Rust those slides seem better than trying to learn from the docs and *Rust by Example*. But I have been trying for a while now and so its likely because I know the stuff covered in the slides so far. At times I found the examples given in the documentation/book wouldn't actually compile. This is understandable though, the language moves fast so its hard to keep track of it all I imagine. Currently I'm finding it hardest to find the idiomatic way to do things in Rust. (Seemingly) simple things such as copy a section of a vector into a new one, I had to use unsafe for this which I'd rather not do. Should I try to copy from an array instead and use a slice to construct the vector? Back to the original topic, using github to deliver the course and submit homework is pretty cool. Would have liekd if even one class at my uni did that just for the git practise. Although I'm from the UK so seeing so much homework at uni is still strange to me. Getting marks just for attending is strange but I can see some benefits of it (encourage people to show up mostly), but now I'm getting off-topic.
This looks like issue 6393 aka https://github.com/rust-lang/rfcs/issues/811 - a known issue that we are planning to fix. The problem is that currently we restrict borrow lifetimes to be full scopes, and the only possible full scope here is too big.
slide 34: "v3 and ~~v3~~ v4 are equal"
I've just read the first group of slides (http://cis198-2016s.github.io/slides/00/#1 ). They are well done, but in my opinion for a university student the "why" is as much important as the "how", and sometimes it's even more important: those slides quickly explain *how* to program with Rust, but they don't explain the design decisions behind most Rust features and parts, that is *why* Rust is the way it is. In my opinion it's better to go slower, and let students understand why the various parts of this language are the way they are now. This way they will remember better the Rust language and its design, the will learn faster the idiomatic way to write Rust, they will get a hint at how a real language is designed and what the trade-offs are, they will learn something about designing modern languages too, they will find better ways to work around the current limitations of Rust and they will learn why those limitations are currently present, and if they want they will start to learn how to contribute to the future development of Rust and its standard library.
Probably, but I was expecting a bit more than 30 GB from the title. I have no idea why anyone would fire 5 servers to process 30 GB :/
What about making the source available under the GPL? You can then still use it in your propretary projects and sell it, if someone wants to use your library in a non-gpl project.
There is [one](https://github.com/Gankro/thesis/blob/master/thesis.bib) in the repo linked above.
The course is targeted at people who already are familiar with programming in general ([see "Prerequisites"](http://cis198-2016s.github.io/)), so it seems pretty reasonable for the first class to give a high-level overview and then blast through the basic syntactic stuff like local variables/`if`s etc. and the hum-drum stuff about various common types. Presumably they'll come back and revisit the interesting parts in more detail. (I guess one could discuss the pros/cons of Rust's specific choices for this basic stuff, but that seems like it would be missing the forest for the trees in terms of what's most interesting about Rust.)
Oh, as in you want the bibtex citation for the thesis itself, not the bibtex file the thesis uses. Makes sense, sorry for the confusion.
I think it ends up being 30GB per node, so 150GB across 5 servers. More generally though, getting too excited about whether the data appears small for your use case may be premature. This particular experiment can tell you whether or not you might expect to keep up with a logging infrastructure that drops off 30GB each minute. Maybe you need 5 machines for that rate. 
I'm really enjoying watching you coding and working on that emulator. I hope you're planning to do more projects live! Keep it up!
&gt; Learn Rust the Hard Way. Does this actually exist? I own the domain name, I'd like to donate it if there's the project. And yes, if examples in the docs don't work, please file bugs!
`*` as a de-reference operator and `&amp;` as a reference operator are both mentioned, but I'm not sure that there's anything explicitly about using them together.
By its author: yes. He mentioned on twitter that he wanted to hand it over to the rest of us, and we said yes, but then never responded again :(
Sure, if that happens I will make sure to hand it to someone else.
This isn't really the case in Rust, since Rust isn't GCd, and you'll only capture stuff you mention directly inside. Most Rust code doesn't keep large variables on the stack (instead putting the large variable on the heap with a non-`Copy` pointer on the stack), so you don't have to worry about that copy either.
That's less "explicit control" and more "unnecessary annotations", similar to non-`auto` decl type annotations in C++. There's only one correct answer for the capture clause, but the compiler won't figure it out for you. The box/deref stuff ... meh, that should be fixed soon when we get abstract return types. 
that's a huge problem for any language that wants to get into the functional paradigm, even partially. Closures are used everywhere on functional programming styles, so they need to be simple and cheap. Rust's closures are already cheap (with some planning), but they do seem a bit unergonomic still. Seems fixable though, I have faith!
https://en.wikipedia.org/wiki/Open_core
By the way, doesn't that mark today as 1.6 release day?
Well, the domain registration ends in May. Assuming that the author is abandoning it, the community should be able to get it back after then.
That is correct! Usually it's released... three or four hours from now
Way late to the party; just found this thread. Any updates on this?
Not yet, no. https://github.com/rust-lang/rfcs/issues/271 is the tracking issue.
I wasn't under the impression there was enough for a serious meetup. Barely enough for one in Toronto. Still, could certainly just hang out every now and then.
Dang, I didn't know there was a difference in behavior there vs. Vec
hi steve how are you thanks for sharing this info i love rust a lot - sincerely, by a haiku enthusiast
So, so, so much. Like, all the code will not work. 
Thanks! Fixed.
im wondering if the class is continuing vs say the Udacity OS class. I suppose the concepts will be the same, but if the code is now just 'wrong' then it will hinder my ability to do/learn from the exercises :/
I have not taken it, so I can't say. But yeah, this class as well before 1.0; lots of syntax has changed, as well as more drastic things like "The runtime was removed".
From just the function signature though, isn't the lifetime of &amp;T directly linked to the &amp;[u8]?
&gt; and may decide to reuse the memory of input for other stuff Shouldn't the lifetimes prevent that, as the lifetime of the result is the same as the lifetime of the input? I'd also say `convert2` is nicer — any time you can avoid `transmute` is a good thing in my book as it's a very big hammer. I'd question how this works in different endian systems, but I don't have access to easily test though.
For some context - The CIS-19X courses at UPenn are a series of language (or area) specific courses, generally taught by graduate (and sometimes undergraduate students). They tend to be very practically oriented, and help fill in some of the reality of software engineering, on top of the standard curriculum of theory. They started up a few years ago (while I was there) and have been pretty awesome.
May I humbly suggest showing the students how to use [clippy](https://github.com/Manishearth/rust-clippy) – it will help them write rustic code and avoid beginner mistakes.
I haven't tried it yet, but I've seen rusty-cheddar mentioned here a few times: https://crates.io/crates/rusty-cheddar
That's exactly the plan - our hope is that a syntax overview will get people started on doing homework (and exploring on their own), until we start going deeper into concepts next week (starting with ownership).
I would argue against making this a function at all, it's just 1 line of code and really unsafe. If u do, at least mark it as unsafe.
Yup, we're all submatriculated students (in the combined BSE/MSE program) in our 5th and 4th years at Penn. The 19x program is awesome - I had the opportunity to co-teach another a few years ago (191, Linux/Unix Skills), and it was a lot of fun. Since then it's been formalized a bit and gained a lot of recognition. The EE department recently made their own mini-course ESE 190, Silicon Garage, on hardware hacking.
Sorry to hear about your car troubles! I'm not too familiar with Servo innards, but perhaps /u/pcwalton could help? If he's not around, try asking on #servo on irc.mozilla.org.
`*` dereferences the `Box&lt;T&gt;` (box is still a pointer) into `T` and then `&amp;` borrows it ending up with `&amp;T`
Excited both about the libcore stabilization and the banning of wildcard dependencies on crates.io. These are two great steps toward a better Rust ecosystem.
&gt; I think it will be very helpful for students. I sure hope so. Contact me or anyone from the clippy team if you need any help.
This is a good release – both for the ecosystem and the language. It'll be interesting to see how 1.6 fares in certain benchmarks (as opposed to 1.5).
This is the best tl;dr I could make, [original](http://devpost.com/software/trumpscript) reduced by 79%. (I'm a bot) ***** &gt; As the undeniably best presidential candidate in the 2016 language, we found that the current field of programming languages does not include any that Trump&amp;#039;s glorious golden combover would approve of. &gt; All programs must end with &amp;quot;America is great.&amp;quot; Our language will automatically correct Forbes&amp;#039; $4.5B to $10B In it&amp;#039;s raw form, TrumpScript is not compatible with Windows, because Trump isn&amp;#039;t the type of guy to believe in PC The language is completely case insensitive Grammar. &gt; E.g. &amp;#039;Make America great&amp;#039; assigns the value of the variable &amp;#039;great&amp;#039; to &amp;#039;America&amp;#039; Printing to stdout can be done via &amp;#039;tell&amp;#039; or &amp;#039;say&amp;#039; While loops are denoted via &amp;#039;as long as&amp;#039;. ***** [**Extended Summary**](http://np.reddit.com/r/autotldr/comments/422dov/trumpscript_make_python_great_again/) | [FAQ](http://np.reddit.com/r/autotldr/comments/31b9fm/faq_autotldr_bot/ "Version 1.6, ~29070 tl;drs so far.") | [Theory](http://np.reddit.com/r/autotldr/comments/31bfht/theory_autotldr_concept/) | [Feedback](http://np.reddit.com/message/compose?to=%23autotldr "PMs and comment replies are read by the bot admin, constructive feedback is welcome.") | *Top* *keywords*: **Trump**^#1 **great**^#2 **language**^#3 **programs**^#4 **used**^#5 
While your second bullet is generally correct, I think (though I may be wrong, I'm not sure what the guarantees here are) that this is safe if `T` is `#[repr(C)]` or `#[repr(pack)]` **and** `T` only contains primitive typed fields (no `&amp;`/`Vec`/`Box`). Maybe you could add an `unsafe` trait that declares that shape and then restrict your cast functions. This is a pretty common pattern in C for parsing binary protocols (e.g. IP headers), just lay a packed struct over the `char` array and read the values. It's specifically required by the C spec that this works (the exception specifically covers `char` arrays, otherwise this counts as aliasing and is UB).
Thanks!
I believe they also give granular access to by-val/by-ref, which is indeed a non-trivial thing that Rust can't infer for you. Getting the same expressivity requires minor hacks in Rust like "capturing a reference by-value".
What does it mean that "This will allow for a library ecosystem to develop around libcore, but applications are not fully supported yet."?
Looks like it's failing to build on windows. Is that just because of the download failure in the automated build client, or due to an actual error in the library?
[Wow - just 1384 to go until a big round-number milestone!](http://xkcd.com/1000/)
Certainly something to be careful of. I’ve used a pattern of a no_std cargo feature, which lets you get no_std at the cost of potentially removing some things.
Ah, I figured the issue it was something like that.
I'm learning rust by doing the challenges at cryptopals.com! Already I am appreciating the distinction between str and String. Oh my yes.
/r/playrust
cargo features are additive, so I think it should be using a default "std" feature instead, to work correctly when multiple crates in the same build depend on your crate.
The only solution is to treat the rust library as a black-box external C library. Rust does not offer any higher level primitives you can use to do this 'better' somehow.^ Google 'calling C++ from C" and "calling C from C++". Some typical solutions: - Expose your app's C++ api as a C api and call it from the rust crate - Pass function pointers to the rust code (and back) as a 'simple' api to the C++ and back (look at the openssh bindings for some examples). - Treat your rust crate as a 'black box' with a C api that cannot call out to the existing C++ code. - Unsafely hack C++ objects in invoke their function pointers (http://stackoverflow.com/questions/14815274/how-to-call-a-c-method-from-c). Good luck~ ^ (Well, rust offers a lot of nice things like Drop support, so it is better, but in terms of exposing an API or calling an external C++ API there's nothing special to find out about). 
The string comparison `memcmp` speedup seems decent I guess.
I am only on week 2 of my Rust journey, so I am implementing the Shunting Yard algorithm and calculator. Its going very well and I am enjoying Rust along the way. I will post it in this subreddit for feedback when done :)
You could obfuscate an AST by converting it to some bytecode, using your usual obfuscation techniques and converting back to AST. The only thing that changes is that if you distribute the bytecode, your reverse engineers will need to decompile it into an AST themselves.
For a very simple and probably not very good example, check out a [class I wrote for SuperCollider](https://github.com/andrewcsmith/VoxRes) which calls [a rust library](https://github.com/andrewcsmith/vox_box.rs). It works pretty well, but I did indeed have to implement the class itself in C++. I could potentially foresee implementing more of it in Rust, but because it's a realtime audio synthesis language I had to use their realtime-safe allocation functions instead of Rust's, so most of the work was making sure that proper workspace memory was available at initialization. [Here's a blog post](http://andrewchristophersmith.com/blog/implementing_a_supercollider_external_in_rust/) I wrote about it all.
The lang item doc brson linked to has an invalid link to the eh_personality implementation.
&gt; Will MIR help? I think it's safe to answer this with "No". `t` is a borrow of `e`, hence you cannot move `e` to another location. The compiler/type system does not distinguish between "`t` reters to `e`" and "`t` refers to something that `e` indirectly owns but is located somewhere outside of `e` and does not move if `e` moves". So, it has to prohibit any attempt of moving `e` if `e` is borrowed. MIR is certainly not going to change any of that. To make something like this work (to allow `e` to be moved in some situations even though `e` is borrowed) we would need a way to distinguish between the two cases mentioned above in the type system because moving `e` even though it is borrowed is only safe if the borrow does not actually refer to e but to something that `e` owns indirectly and lives somewhere else. This would make the type system more complicated. I'm not sure whether it's worth the hassle in this case. I don't even know exactly what the type system that supports this would look like. The signature of `send` would have to become more complicated too. It has to codify the link between the `Env` and the borrow somehow so that the compiler knows inside `send` that `term` is still a borrow of `env`. Right now, there is no connection between `env` and `term` inside `send` (as far as the types are concerned).
[Clippy issue](https://github.com/Manishearth/rust-clippy/issues/572)
Oh, abstract return types don't work that way. The idea is that you can specify that the return type implements a certain trait (so, `-&gt; impl Fn()`), and the only information that callers can use about the return type of the function is that it implements that trait (so, if I return a `Vec&lt;T&gt;` and say `-&gt; impl Clone`, the callers cannot use the information that this implements `Hash` as well, only `Clone`) The type is known, just anonymous. There is no runtime type information stuff going on here like Ruby.
No, Steve asked about *Learning* Rust the hard way, not insanity wolf mode.
I think we should separate out the "casting NaN to an integer" from the ignoring of overflow. The former is just a bug and Rust is never OK with arbitrary undefined behavior. But the latter is by design. I really don't want overflow checks in my casts for release builds. So I don't see a blunder here.
I don't want overflow checks either. What I want is more explicitness. For example `51u8 as u32` would be fine, but `51u32 as u8` would need to be written as `51u32.truncating_cast::&lt;u8&gt;()` for example. 
Thanks /u/nick29581! Opened a ticket for you with a question [on GitHub](https://github.com/nrc/stupid-stats/issues/3).
Taking a look at the feature gates in [`src/main.rs`](https://github.com/dpc/rhex/blob/d4e52cc615b89e7ccea99325874e75b4f197b293/src/main.rs): #![feature(libc)] I think this could be replaced with https://crates.io/crates/libc/, instead of using the built-in one that is just there as a private feature for the standard library to use. #![feature(core_str_ext)] I don't think that this is necessary; the stability marker for this feature says "stable interface provided by `impl str` in later crates". Would be worth a try just removing this and removing the `use core::str::StrExt;` that it allows, and see if that works. #![feature(hashmap_hasher)] This is still unstable. I think this just allows changing the hash function, by passing in `DefaultState&lt;FnvHasher&gt;` as a type parameter for `HashMap`, `HashSet`, etc ([for example](https://github.com/dpc/rhex/blob/b36861bdb0e7b0f62170e97093d7c5281ee29aaa/src/game/mod.rs#L39)). I think that the only reason to prefer `FnvHasher` over the default is that it's faster; but it would be worth trying removing that and see if performance is still good enough, possibly still allowing `FnvHasher` to be used behind a cargo feature (which would then require the feature gate and thus nightly). Or another possibility would be to use a different data structure entirely than a hash table, it looks like most uses are to map from a coordinate to things that are on that hex, but it may be possible to just use something like a `Vec` with a mapping function from coordinates to indices rather than a hash map Looks like it wouldn't be too much work, might be worth a try; I'm not the original author, however so I can't speak for him. Also, it's possible that some of the dependencies also depend on feature-gated features, so you may need to check those as well.
Still work to do!
Not that it's a competition or anything, but it's definitely a competition.
Docker image updated: https://hub.docker.com/r/jimmycuadra/rust/ `docker pull jimmycuadra/rust` or `docker pull jimmycuadra/rust:1.6.0`
/me deletes everything written in rust and installs swift !
Wrong! var a = 10; var b = function() { debugger; } b(); a =&gt; 10 And more proof: (function(){ var a=10; var b=function(z) { console.log(eval(z)) }; b('a'); })() =&gt; 10 Mind taking back your downvote? You can even do math on it. Do you think JS is actually looking at the string that I might eventually be passing in order to do this? (function(){ var a=10; var b=function(z) { console.log(eval(z)) }; b('a/2'); })() =&gt; 5 Now I'm getting *really* creative, and you are still wrong! ((function(){ var a=10; return function(z) { console.log(eval(z)) }; })())('a/2') =&gt; 5
Yes, closures can take typed arguments (All closures are typed, just that inference means that you don't need to make the types explicit). Depending on the way they interact with ownership and borrowing, closures may or may not be able to be called more than once, however the types of the arguments must be the same each time. Closures which can be called more than once implement `FnMut` or `Fn`. Closures are really just sugar for objects with a `Fn*` trait impl.
Will `extend_from_slice` be deprecated once we have specialization?
I should have guessed/remembered :)
&gt; (we should probably evaluate whether we want to start doing that) There's a thread somewhere about this.... the general sentiment about TBAA is very negative.
Your right about borrowing. I hadn't thought of that, and it makes me want to return objects even more, where I can call methods more than once. I know "state is bad" - so, I won't put any state in them (for now), problem solved. This whole closure thing seems like a downgrade.
Could there be a tool like Crater but for benching? It would obviously depend a lot on crate themselves changing but if you only run it on a small subset of crates (let's say 100 top crates that have benches) daily, you could see changes and compare them with new versions to see if it's due to Rust version or a new version of the crate
Thanks. I am now starting to see the difference between my example and the other non-lexical borrow examples. I need to harpoon a red herring here: `t` can't refer to the underlying allocation in `e` because these are all wrappers for opaque C data structures. If I understand the C internals correctly, `t` is an integer index into an array that `e` holds. `t` has no destructor (its just an index), so it can still live after `e` has been destroyed but it just can't ever be used. EDIT: mixed up e and t 
Doesn't compile. I was very morbidly curious for a second there...
I have no proof, but I'm pretty sure that all JS engines perform this optimization, it's easy to implement and lowers memory usage a ton, so there's no reason not to. I really wasn't being an ass. Re-read my original comment. I simply contradicted what you said, that's not being an ass. You were the one to respond with personal attacks.
I didn't downvote you. You calling me an ass is definitely a personal attack, regardless.
Please don't judge me. :D https://github.com/dpc/hex2d-dpcext-rs/blob/master/src/algo.rs#L217
Would you recommend me switching to mio because of the non-blocking sockets it offers? Or is std good enough?
No need unless you plan on having one process connect to hundreds of servers.
From a quick look, it looks like your bot only deals with a single connection, so I don't think there is any advantage to using mio.
Here's [my end result](https://github.com/andrey-gvrd/basic-forth-interpreter/pull/1). Your code was easy to read and understand. I was **very happy** to see tests. Many people ask for code review without tests and then it's always flying blind to know if I broke anything. My suggestions: 1. Make types `Copy` when possible. Especially simple enums and "small" structs of `Copy` types. 1. Use `for &amp;collection` instead of `for collection.iter()`. 1. Use `for collection` instead of `for collection.into_iter()`. 1. Use `if let` when you have a `match` with only one interesting arm. 1. Use `collection.extend(iter)` instead of `for i in iter { collection.push(i) }` 1. Use `Option::ok_or` to convert an `Option` into a `Result` instead of a `match`. 1. Use `Iterator::collect` instead of a `for` loop when building a `String` from characters. 1. Use `try!` more pervasively. This tends to cut down on rightward drift and refocuses the programmer on the success case (without neglecting the failure cases). 1. There's no need to use a `VecDeque` here, a simple `Vec` will work. 1. There's no benefit to using `lazy_static` here. You always re-clone the entire `HashMap` anyway, not saving much work. 1. Use `Option::None` to denote the absence of a value, instead of an empty `String`. 1. Use a formatting wrapper instead of returning a `String`. This is more flexible and doesn't *require* allocation. It can be directly output to stdout, or into a `String`. 1. There were many cases of overzealous allocation. Unneeded conversion to `String`, duplicate conversion of `String` to `String`, excess cloning, etc. 
Overall the code looks clean to me. Nice work! There are a few places where it can be improved though :). [Implement Error](https://github.com/andrey-gvrd/basic-forth-interpreter/blob/1be66214029106d3e618a17b600851160f50691c/src/lib.rs#L55-L60) It is a good idea to implement [Error](http://doc.rust-lang.org/std/error/trait.Error.html) for any error type you define. It is perfectly fine to avoid it in this case but it is very nice for usability as it will allow the error to be converted into a `Box&lt;::std::error::Error&gt;` which allows users to avoid defining their own error type. [Enum variant names](https://github.com/andrey-gvrd/basic-forth-interpreter/blob/1be66214029106d3e618a17b600851160f50691c/src/lib.rs#L20-L30) I am guessing that you add the '_' suffix to the enum variants to prevent name collisions with other types which are named the same. Rust does not declare variants in the same scope as the enum but they are instead only accessible through the enum itself so you could remove the suffix. [WORD_MAP](https://github.com/andrey-gvrd/basic-forth-interpreter/blob/1be66214029106d3e618a17b600851160f50691c/src/lib.rs#L32-L47) As you only use WORD_MAP to clone it in the constructor I would argue for just creating it in the constructor which would let you avoid needing the lazy_static crate. [Unnecessary String copies](https://github.com/andrey-gvrd/basic-forth-interpreter/blob/1be66214029106d3e618a17b600851160f50691c/src/lib.rs#L79) ([and](https://github.com/andrey-gvrd/basic-forth-interpreter/blob/1be66214029106d3e618a17b600851160f50691c/src/lib.rs#L261-L262)) Calling to_string on a `&amp;str` will allocate it to the heap. For temporary values this is rather inefficient so just call `push_str` directly on the `&amp;str` or use `push` if you have a `char`. [Calling Clone on &amp;str](https://github.com/andrey-gvrd/basic-forth-interpreter/blob/1be66214029106d3e618a17b600851160f50691c/src/lib.rs#L130) Calling Clone on a `&amp;str` does nothing so those calls can just be removed. [Passing String where &amp;str is enough](https://github.com/andrey-gvrd/basic-forth-interpreter/blob/1be66214029106d3e618a17b600851160f50691c/src/lib.rs#L194-L204) Both `parse` and `to_uppercase` only requires `&amp;str` so there is no need to take a `String`. This will also let you remove some `to_owned` calls as well. Lastly I noticed that you use `VecDeque` in a few places but you only ever use `push_back` and `pop_back`. Is there any reason you are not using a `Vec` instead?
Not just Vulkan, DX12 and Metal rendering is based on PSOs as well. Theoretically, I could name 3 big things that the next-gen APIs feature and have in common: 1. Split command buffer construction from execution. This allows rendering from multiple threads effectively. We got this model in GFX too quite a [while ago](https://www.reddit.com/r/rust_gamedev/comments/2dc47d/gfxrs_is_metamorphosing/). 2. Split render data processing and declaration from the contents. This is what PSO is - it defines what we are gonna do with the data, and what data exactly is supposed to be processed. GFX just got this model with strongly-typed PSOs in the subject PR. 3. Resources memory pools and aliasing. We don't have anything for this yet. A LOT of old "artificial" concepts are now gone in favor of a single "close to the metal" PSO. GFX itself distanced away from GL and became more API-agnostic. If only we had volunteers/resources to start DX11/DX12/Metal/whateverelse backend, it would be much easier now.
Sub-question to the other OS developers: Newlib is extremely pluggable, and only expects 17 symbols to be defined (all of which can easily be stubbed). First class Rust support for Newlib would be a boon to OS developers, as they could get `std` up on their OSes in a matter of weeks. What would be the best way to implement Newlib support in a generic, pluggable way?
How many are there? Aren't like half of them in hidden courses?
Why isn't `error::Error` in the core crate? It only depends on the traits `fmt::Debug`, `fmt::Display`, and `marker::Reflect`, all of which are in core, and its methods both return `&amp;str` and `Option&lt;&amp;Error&gt;`, which are all possible without an allocator.
I apologize if my tone was a bit crude, I was enjoying the thread and I reacted with exclamation points under the assumption that the other user had down voted my post despite it being a relevant and interesting discussion. I presume this is where the accusation towards my tone was based on. I would have rather the reply been inquisitive instead of defensive and dismissive. Also, I feel that feelings have been resolved. Thank you.
We do not have libstd in Redox, but we have something extremely similar: libredox. Libredox is an almost one-to-one replica of libstd. It essentially reexport all of libcore, and then provides the extra platform dependent features (like libstd). So we got things like, io, thread, sync, float methods, prelude, collections (Vec, Box, HashMap, etc.), env, net etc. Obviously, libredox is still incomplete, but it provides many of the common platform dependent from libstd. I believe this is a good solution, though it is only temporary until we can port libc.
&gt; Is it possible (or desirable) to share code with Redox? I think that at least things like a networking stack could be moved to a separate crate that both Uni.rs and Redox depends on. Well, we have a very permissive license (MIT), so I guess that's okay. Depending on the writer of the particular part, you want to use, you should probably inform them before using it (though it is not a requirement). You can ping us at the #redox channel at the Mozilla IRC.
This was [cross-posted to Stack Overflow](http://stackoverflow.com/q/34914572/155423).
What is the difference between gfx, and sld2? 
I would like to see better documentation and a tutorial for gfx. Learning from the examples is too difficult for me. 
I consider the number of contributors the most relevant ,readily-available, metric. The fact that it's cheat-resistant is an added bonus.
I will! There's quite a bit more work to be done before it'll be complete enough to show / write about, but I will eventually. And gather some feedback, particularly around how to improve performance and cache coherence (since it's essentially just flipping bits around)
We're (Dropbox) currently using libpnet + netmap to implement some userspace networking stuff in our Rust project. We're using libutp ( https://github.com/bittorrent/libutp ) to handle retransmission and congestion control. The goal is to be able to hit the 40Gbps line rate on the fleet of machines that we've custom-designed for this Rust daemon. Anyway, libpnet is an awesome tool to roll your own high-performance network stack. Very zero-copy friendly so you can create packets directly on the NIC's TX queues. Thanks, Robert!
SDL creates the window with OS-specific calls and capture input from keyboard/mouse/gamepad, and can do other things like play audio. SDL can either draw simple 2D graphics by itself (using the CPU), or set up an OpenGL context so that gfx-rs (or glium) can draw 3D graphics. A pure-Rust alternative to SDL is [glutin](https://github.com/tomaka/glutin) (but Glutin does only the window/input part; you also need stuff from [RustAudio](https://github.com/RustAudio), etc). Something interesting about SDL is that, whether you compile it statically or dynamically, the user can [override the SDL version at runtime](https://www.reddit.com/r/linux_gaming/comments/1upn39/sdl2_adds_dynamic_api_magic_to_allow_updating_it/)by setting an environment variable (kind like LD_PRELOAD, but works for statically linked SDL too). This enables Linux games (such as games published on Steam) to benefit from SDL updates even if the game itself isn't updated.
PSO is the shader set plus all the peripheral links to the data, except the data itself. The peripheral includes the formats and layouts of all vertex buffers, output targes, and all the state associated with them (blend func, depth/stencil test, color mask, etc). See [dx12 documentation](https://msdn.microsoft.com/en-us/library/windows/desktop/dn899196%28v=vs.85%29.aspx) for more info. Rust does indeed shine when it comes to PSO. Thanks to our type system, GFX is able to enforce the data formats at compile time. I'm not aware of any other attempts to make PSO type-safe (enlighten me, if you do!). There are rough edges, of course, and we'll continue working on it, hopefully with some user feedback.
It's a pretty strange criticism to talk about how things look strange to developers "lower on the totem poll" and then assume the common C++ developer isn't aware of the problems discussed in the example. I feel the Blub Paradox simply gets it wrong. It's not that a C++ developer can't see the benefits of a borrow checker, in fact C++ developers are interested in making tools to incorporate it. The problem is that languages change and a new language might get some things right and several things wrong. The old languages can pull in the good and leave out that bad, there is no point wasting time in learning the new (inevitable) quirks of the new language. This, in regard to the Blub Paradox, is a reduction in the complexity of the problem. To claim "they simply can't see," is to undermine the reality.
Only if you're not going to mutate me, as I'm clearly also being borrowed by Rust itself :p
Thanks! Will shaders still be written in GLSL?
&gt; where I can call methods more than once You can do this with closures too, as long as the closure doesn't move anything. This is no different from the situation with objects, where if you want to call a method multiple times the method must take `&amp;self` and cannot move out of the object. I think you're taking a rather narrow view of closures. They're really great as function parameters since they usually optimize away to fast code (for example, a chain of iterator adapters using closures will optimize down to a single `for` loop, however the code will be neater to read and easier to write). As far as returning closures, it's not done much, but returning specialized objects for future computation/state is something I've never seen done in Rust. It's pretty easy to return closures (sure, you need to `Box` them, but that's very little typing and still easy to read), and the costs of the closure are rather clear.
&gt; How would libc help? Wouldn't it be better to implement libstd on top of Rust code instead of libc? Libc allows us to 1) run non-Redox applications without any form of "compatibility layer", since libc is _the_ core dependency for a lot of programs, libraries, and programming languages. 2) not have to maintain a secondary libstd. Any update in upstream will either work out-of-the-box or be trivial to get it to work. If we only want to port libstd, we can add a `redox` module to the `sys` module, adding all the platform-dependent API (see `unix` directory for reference). But even this is a pain to do and maintain. The best long-term solution is to port libc, since that'll give you super-powers.
I would say it is easier to port newlib in C, since newlib does not fit very good with Rust, because it's designed for and to C API. https://github.com/redox-os/redox/tree/master/libc/newlib-redox for reference Also, note that while newlib provides a lot of features, it is not a replacement for libc, since it is not compatible with libc.
Since 2.0, SDL no longer does 2D rendering on the CPU.
Look forward to it!
we'll try to be safe ;)
I think is cool, does that mean you could build complex stuff like OSes with this? Pretty new to Rust.
Our shader story is [incomplete](https://github.com/gfx-rs/gfx/issues/71) and needs a hero. There is an epic idea of Rust-based shading that would translate into GLSL or whatever, but it seems too difficult for us/now. We'll probably end up with [SPIR-V](https://www.khronos.org/spir) and some offline translators.
To be clear, I think it's more of an issue with the "blub" concept in general than your post specifically. I totally agree that different people learn differently and that languages shape how you think, and that impacts how you learn different languages.
Super exciting! &gt; Yeah as this is for the `boostrap` binary itself Ah, I'm glad [this fun typo](https://twitter.com/boostrapghost) will be making it's way into Rust for a while. 
I agree with others that the 'Blub paradox' is a concept with little use in general because of the value judgment it puts on different languages. The language Paul Graham was talking about was mostly Java, and of course Java has features that Rust does not have (inheritance being a very obvious one). A programmer exposed only to Rust and not Java would think inheritance was weird and useless - a lot of people exposed to both would agree with them sure, but Rust is adding features to get the benefits that inheritance has without some of its costs, ideas we wouldn't have as likely have been able to conceive of without exposure to languages with inheritance. But I also agree that the "leg day" criticism is off base. Rust's memory management system is not a distraction I waste time on to save CPU cycles, _it helps me write my programs_. Memory errors are fundamentally state errors, and Rust's move semantics, borrowing, and aliasing XOR mutating help enormously for me to reason about how my program changes state as it executes, to avoid accidental shared state and side effects at a distance. Rust more than any other language I know enables me to do _compiler driven design._ And internalizing its rules has helped me design better systems, even in other languages.
Yep. This is a common misconception, and the fact that borrowck is still active is actually a pretty useful way of minimizing the zone of unsafety.
I don't like the first C++/Rust code comparison because the code does very different things when they could be much more similar. Why not use trait objects instead if you are going to do such comparison? I suppose its the phrase " And really, that's how polymorphism starts in Rust. *It's all with generics*." that I disagree most with.
I think Andrei's quote was fundamentally referring to untyped templates vs. typed generics (traits). He's come out strongly in favor of the former, with "design by introspection" being essentially an argument in favor of untyped templates against concepts. The way I interpret "Rust skipped leg day" is that untyped templates (and related features, such as compile time function evaluation and static if) are more powerful than Rust's typed generics (which are also, to be fair, lacking some features such as integer type parameters) are. In particular, most statements along the lines of "look at how easy it is to do X with C++/D/Nim, and you can't do it at all in Rust!" are actually just arguments for untyped templates in disguise. It's a fair criticism, but in my view there's an equally strong counterargument that typed generics are easier to get right (better error messages, more straightforward to write, simpler semantics, potentially faster compilation speed). To me it just comes down to the perpetual dynamic vs. static typing debate, except at the metaprogramming level as opposed to the programming level. It's always easier to do powerful things in dynamically-typed systems like D. But it's easier to understand and debug code in statically-typed systems like Rust.
&gt; I feel the Blub Paradox simply gets it wrong. It's not that a C++ developer can't see the benefits of a borrow checker, in fact C++ developers are interested in making tools to incorporate it. The problem is that languages change and a new language might get some things right and several things wrong. Graham puts Lisp at the top, and Java at the bottom, but in reality Blub lives in the middle of a multi-dimensional field. If we simplify the idea to a spectrum, we can reason about it more easily and bring out a useful meaning. It's an analogy, not an entire thesis statement, and the idea is going to leak. The point of the blub paradox isn't that people literally can't understand concepts from a language that is (arguably) more powerful along some language feature spectrum. It's that, by and large, most practitioners are going to avoid them because they perceive their current language to be sufficient. And they ultimately miss out because of it. /u/jntrnr uses the blub paradox in exactly the right way. Everyone probably would agree that the type system and borrow checker, etc., in Rust are powerful language tools that do something that C++ doesn't do for you. So along that particular spectral line, it's valid thinking, and useful for trying to entice someone to check it out. Paul Graham is opinionated, and doesn't hold anything back. I enjoy reading him even when I disagree, and I don't feel like he's condescending in those cases. Maybe if I was a Java fanboi, I might be slightly offended. Maybe.
The server was down when I saw this a little while ago, but I found someone giving a talk about this. Excellent, hilarious, and terrifying. EDIT: Oh, ACM is back up now.
I've had similar experiences myself and have heard similar things from other newcomers to the language. However, we do emphasize borrowck a lot whilst evangelizing Rust, so this is an easy and understandable criticism to make. As someone who has been using Rust for a while now it's really "just another compiler pass" to me like Jonathan's blog post says. But it has enforced a really nice programming style on me which I miss in other languages.
&gt;The point of the blub paradox isn't that people literally can't understand concepts from a language that is (arguably) more powerful along some language feature spectrum. The idea I was putting forth was that a developer can disagree with what you claim to be better *and be quite justified in doing so.* To say something like this: &gt;It's that, by and large, most practitioners are going to avoid them because they perceive their current language to be sufficient. And they ultimately miss out because of it. Isn't necessarily what I would call condescending, but it is opinionated to a fault. I like Rust quite a bit (why else would I bother posting here), and I would say I wish C++ looked a bit more like Rust, or that Rust was old enough to interface better with the existing ecosystem. The fact of the matter though, is that when someone claims C is just better than C++ and Rust, and they list their reasons, not being able to win them over doesn't mean they're missing out. One should not assume that Rust is objectively the best tool for the job in certain scenarios. Even with a good case for this (a case that should be voiced, for sure) it is not the dissenter that is automatically wrong, a difference in opinion can coexist without either being incorrect, even a contradictory one. I am reminded of another man who shares Graham's name. Graham Priest would have words about paraconsistent logic and approaching things with a more diplomatic tone, but I digress.
Did you figure out which libc you wanted to port?
&gt; Libc allows us to &gt; 1) run non-Redox applications without any form of "compatibility layer", since libc is the core dependency for a lot of programs, libraries, and programming languages. Yes, that makes sense. &gt; 2) not have to maintain a secondary libstd. Any update in upstream will either work out-of-the-box or be trivial to get it to work. &gt; If we only want to port libstd, we can add a redox module to the sys module, adding all the platform-dependent API (see unix directory for reference). But even this is a pain to do and maintain. I'm not convinced about this. IMO, it is better to have a "native" syscall interface independent of POSIX/libc and then do a POSIX/libc wrapper on top of it. Then native applications get the full benefits of your OS while legacy applications work in an emulated mode. I also would guess it wouldn't be much work to maintain a native Rust implementation of libstd once it is written. In fact, it could become the reference implementation and then the Linux/POSIX/Win32 implementations would be the ones that would be extra work.
Static type systems are a form of static analysis. That includes the borrow checking portion of Rust’s type system.
Copying has no different runtime cost than moves. Both at a lower level are memcpys as I understand it, but they do differ in semantics.
Yup, the only difference is the invalidation of the original.
Rust allows you take a sub-range of a string, as in python, so how about this: let s = "(1, 2, 3, 4)"; let numbers: Vec&lt;i32&gt; = s[1..s.len()-1].split(", ").map(|s| i32::from_str(s).unwrap()).collect(); 
Sorry I can't help; I was hoping for an answer to this. FWIW, I spent a couple of hours trying to solve essentially the same problem, and couldn't find a way. I ended up just using unsafe setsockopt(), same as you did.
Slice them out with [`str::trim_matches`](http://doc.rust-lang.org/std/primitive.str.html#method.trim_matches). // Never a bad idea to trim off whitespace too let s = "(1, 2, 3, 4)".trim_matches(&amp;['(', ')', ' ']); assert_eq!(s, "1, 2, 3, 4"); And then to parse it's probably better to split on just the comma, and trim the whitespace (so there can be variable amounts of it on both sides of the comma, including none at all): let numbers: Vec&lt;i32&gt; = s.split(',').map(|s| s.trim().parse::&lt;i32&gt;().unwrap()).collect(); Parsing that's sensitive to whitespace and different amounts of it tends to break pretty easily.
I've updated the code, it works now. I'd be glad to hear what improvements I can make to my code, like how to make it more idiomatic.
This is something I've been hacking on while waiting for Gfx to merge PSO...
In D, templates can run arbitrary code to decide what they want to expand into. For example, in D you could have a template that precomputes a table of sines and cosines, while that'd be extremely unergonomic at best to try to do with Rust's generics system. (Rust code would use a syntax extension for this particular example, which has its own upsides and downsides.) The downside of D's approach is that the compiler can't possibly check to make sure your templates always expand into code that compiles, because a single D template can literally, in the limit, expand into anything given the right input. Rust, on the other hand, can (and does) verify that your generics will always expand into valid code. So it's a tradeoff. In fact, it's exactly the tradeoff of dynamic vs. static typing, with "type errors caught at runtime" vs. "type errors caught at compile time" replaced by "type errors caught at template expansion time" vs. "type errors caught at template writing time".
Might I suggest [`scan-rules`](https://crates.io/crates/scan-rules/)? /*! To run, create a new Cargo project and add the following, or just run this with `cargo script` (which you'll have to install if you don't already have it). ```cargo [dependencies] scan-rules = "0.0.4" ``` */ #[macro_use] extern crate scan_rules; fn main() { let s1 = "(1 2 3)"; scan!(s1; ("(", [ let ns1: i32 ]*, ")") =&gt; { println!("ns1: {:?}", ns1); }).unwrap(); let s2 = "(-0.7 0.8 1.8)"; scan!(s2; ("(", [ let ns2: f64 ]*, ")") =&gt; { println!("ns2: {:?}", ns2); }).unwrap(); // I'm feeling lazy; let's ignore error handling entirely. let s3 = " values : &lt; 1, 2, 3 , 4&gt; "; let_scan!(s3; ("values: &lt;", [let ns3: u8],*, "&gt;")); for (i, n3) in ns3.into_iter().enumerate() { println!("ns3[{}]: {:?}", i, n3); } } Output: ns1: [1, 2, 3] ns2: [-0.7, 0.8, 1.8] ns3[0]: 1 ns3[1]: 2 ns3[2]: 3 ns3[3]: 4
I've played with your code for a bit and decided to take out all early returns and `try!` macros, for fun. The result can be found [here](https://github.com/Thiez/basic-forth-interpreter/blob/0108026a1b122182706cccfe61c4d81e907b3630/src/lib.rs). Note that I'm not claiming this is very ideomatic Rust (many people seem to use `try!` at every opportunity), I merely present it to illustrate the difference in style.
Procedural macros are on a path to stability, and there are early proposals for const value parameters; between those two features you could precompute values and parameterize types by them. Barring missing but implementable features, is the issue just that it would be more verbose to write metaprograms like this in Rust (a very common argument for dynamic types)?
You really missed a chance here to call it the "Bay Area Rust Friends (BARF) Meetup"
Dynamo?:) The name is same with Autodesk's Dynamo which is design script before: https://github.com/DynamoDS/Dynamo
I can’t find an actual bug filed right now, sorry, but I know that Servo has been upgrading Rust but is stuck on an old Cargo (nightly 2015-09-30, specifically) because of linking-related issues in newer Cargo versions. So, maybe try downgrading Cargo?
I began working on a solution, I'll probably implement it in the [net2 crate](https://doc.rust-lang.org/net2-rs/net2/index.html).
libmacro's design is pretty similar to D in ergonomics and power, really. There's a smooth transition between macros, token-matching macros with light use of procedural components, and full blown procedural macros. There aren't any templates, but the procedural contents of the template will be similar.
I don't think it's dishonest. I think it reflects the attitude a lot of people who were involved in the C++ standards work, where concepts were a huge debacle that eventually ended in failure and needed substantial reworking into Concepts Lite (which still haven't shipped in a standard), had. Because strongly-typed generics like those of Rust didn't work in C++, it's easy to conclude that they can't possibly work anywhere. Couple that with the fact that D's templates actually are more expressive (like all dynamically typed systems are), especially combined with static if and CTFE, and it's not surprising that many people (like Andrei) see strongly-typed generics systems as far too limiting.
When I read the original Quora post, it sounded like the big "muscle" was lifetimes et al. and the "legs" were the rest of the language: &gt; Safe, deterministic memory reclamation is a hard problem, but is not the only problem or even the most important problem in a program. Therefore Rust ends up expending a disproportionately large language design real estate on this one matter. I find this dishonest because Rust didn't "trade" lifetimes for other features. It is a general purpose language with many great features, and many people, myself and yourself included, find it downright pleasant to use. I default to Rust for tasks befitting Python.
&gt; The new build system has a Python script entry point which manages downloading both a Rust and Cargo nightly. Having worked with python extensively, I might just point out that having python as any part of your 'cross platform' build system is project doomed to struggle and failure. Ever uses scons? Haha~ ' Because SCons is written in Python, you must obviously have Python installed on your system to use SCons. ' mm... yes. About that.
I wager Niko is wearing a Noro scarf, as in http://brooklyntweed.blogspot.com/2007/04/noro-scarf.html They are really cool, and pretty easy to knit, too. Also wtf "quick sort is probably everyone's favorite sort"? :) Top down radix sort for the win!
Why is any build system using Python doomed to failure?
&gt; Anything in particular that you think might make a difference in benchmarks? I believe bluss (/u/neutralinostar) sped up utf-8 validation recently, but not sure if it made 1.6.
&gt; I think the Blub paradox blog post is rather condescending. It was written by Paul Graham, after all. He is a bright guy, certainly, but...
I think c style loops is a mistake, it usually generates more byte code and you end up having two looping syntaxes. Something along the lines of rust/nim 0..9 or python range is nicer. 
I sent you a PM, feel free to follow through with it if you want to learn more about iterators. Anyway, you are trying to get mutable access to an inner value on an iterator, this means you want `.iter_mut()` fn main(){ // Simple struct named Structure struct Structure { elem: u32 } // modify function for Structure impl Structure { fn modify(&amp;mut self){ self.elem +=1 ; } } // Default implementation for Structure impl Default for Structure { fn default() -&gt; Structure { Structure{elem:0} } } // Array of "Structures" let mut struct_tuple = [Structure::default(), Structure::default()]; // Loop trough struct_tuple for loop_struct in struct_tuple.iter_mut() { loop_struct.modify(); } } For context, I came from python3, so I feel your pain getting to grips with the borrow checker. But when you're used to it is a beautiful thing.
Alternatively he can use the into_iter() of a mutable reference: for loop_struct in &amp;mut struct_tuple { loop_struct.modify(); } http://is.gd/ZbJws2 Another alternative is using the "ref" keyword: // Array of "Structures" let ref mut struct_tuple = [Structure::default(), Structure::default()]; // Loop trough struct_tuple for loop_struct in struct_tuple { loop_struct.modify(); } http://is.gd/7eTQdj
Now this brings another questions in my head : &gt; Where does iter_mut() come from ? Is it like Python's _ _ function_name _ _ notation ( _ _ unicode _ _ , _ _ str _ _ , etc)? I know i didn't implemet iter_mut() so it must be a default construct. How can i find all of these default constructs ? I presume there's more that just iter_mut(). Thank you for your help , i higly appreciate it. 
Your two element array automatically turns into a slice (coerces), and slices implement it https://doc.rust-lang.org/std/primitive.slice.html
Do you know a good irc client for linux ? I am on manjaro so i can probably find it in AUR. Thx for your help. 
Yeah, I thought about including that, but I felt I should keep it simple
The `#rust-beginners` IRC channel is made specifically for this. `#rust` is fine too, but people are only in `#rust-beginners` if they want to be bothered, so ask as many questions as you want. :) But this subreddit is fine too. Anyway, take a look at the [Iterating section of the Vectors chapter in the book](https://doc.rust-lang.org/book/vectors.html#iterating). If you iterate on a slice, vector, etc. with `for i in &amp;v`, you get immutable (`&amp;T`) references to the elements. If you iterate with `for i in &amp;mut v`, you get mutable (`&amp;mut T`) references. If you iterate with `for i in v`, you transfer ownership of the vector to the loop, and therefore each run of the loop gets ownership (`T`) of the items inside. The reason it works this way is the `IntoIterator` trait, which is used to implement the `for x in y` syntax. If you search the [vector documentation](https://doc.rust-lang.org/std/vec/struct.Vec.html) for `IntoIterator`, you'll see three implementations, one for `Vec&lt;T&gt;` with `Item = T`, one for `&amp;'a Vec&lt;T&gt;` with `Item = &amp;'a T`, and one for `&amp;'a mut Vec&lt;T&gt;` with `Item = &amp;'a mut T`. Similarly, if you search the [slice documentation](https://doc.rust-lang.org/std/primitive.slice.html) for `IntoIterator`, you'll see two implementations, one for immutable slices and one for mutable ones.
&gt; LLVM requires Python already. Yeah, talking about that, another long term goal should be (and I believe already is) to get rid of this additional source dependency. Rust should not need to maintain its own fork of LLVM nor should it build it as part of its bootstrapping process. Just use the system one or download a binary package. 
lol wrong subreddit. this subreddit is for rust the programming language, not the game.
 Help working [on mine](https://github.com/matthiasbezer/imag)! ;-)
The reason I am using a C style loop is because there are some alternatives that might be more powerful in a small scripting language, and I think this Rust/Nim like sugar would be perfect. Something of an idea I have, since the most common case is to walk over some array, is to use arrays of slices in reverse order '[end2, start2, end1, start1, end0, start0]'. It is efficient to iterate by incrementing the start until the end then pop both and continue on the next. You can also do unions, intersection and set subtraction before the loop and pass it around as arguments. It is a little more expensive but gives some advantages when debugging, and it easy to use for higher level programming.
I can tell you for sure they won't be in the next release, because master is two releases out.
Both? My understanding was that they did some code generation to pre-computer some set of things to make compilation at runtime faster. I just don't understand that part. I also don't understand what Lucene messed up. Actually, in general, I know very little about what Lucene is doing here. For the most part, I followed Jules Jacobs' formulation. AIUI, Lucene read that ridiculously long paper and implemented that instead.
Rust already can use the system one, it's just even better to use edge.
irc.mozilla.org:6697 (SSL) - see https://wiki.mozilla.org/IRC
I use weechat. Just type /server add mozilla irc.mozilla.org /connect mozilla /join #rust-beginners and you'll be good to go! 
Thx i am there ... I will keep quiet for now since my question got answered here. Thank you for your help, and have a nice day. 
You are absolutely right. It needs to pass around the lifetime information somehow. Have not thought that much about the syntax yet, but I am sure there is a solution around that problem.
Now you have a statically typed language though ;). Still, it would be very interesting if you manage to find a nice middle ground between dynamic and full blown static typing.
We haven't shot that idea down, and in fact we've had such threads in the past. It's just another thing that we mods have to remember to do, and nobody has stepped up to take responsibility for doing it every week (e.g. like /u/llogiq has stepped up to handle the recurring "What are you doing this week" thread).
Do you remember how long it took you to find it pleasant? I still do not. I've been off and on but call it three months experience. I can get things done but I don't like it. I remember with Haskell it took me about six months before I was no longer getting desperately frustrated with the compiler on occasion. However, in every case that happened I came out of it with something quite elegant and with a deeper understanding. This gave me hope that eventually I'd learn all of these lessons and Haskell would be easy and fun - which did turn out to be the case eventually. The same is not true so far in my experience with the Rust borrow checker. When I get frustrated with it, I often end up with a solution that is not elegant - that is harder to understand for my program's intent because it is so consumed with memory management chores. I am skeptical if it will ever become fun to program Rust.
awesome, I was trying to do the same, but you did it so thanks. I am not in favor of inheritance because it can leads to confusing code. But encapsulate things that way is clear and I like it.
I'd raise my hand to volunteer, but I don't feel I'm either experienced enough with rust or the community. Perhaps I am mistaken. 
Broken link?
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rust_networking] [Low level networking using libpnet now possible on Rust stable](https://np.reddit.com/r/rust_networking/comments/42bnxx/low_level_networking_using_libpnet_now_possible/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
Thanks for reporting this. I've filed [a bug on the issue tracker](https://github.com/rust-lang/rust/issues/31150). By the line '"-L" "/usr/local/lib/rustlib/i686-unknown-linux-gnu/lib"' you can see that rustc is trying to compile a 32-bit (i686) library, and is failing to find the C dependencies. Is your CPU 32-bit or 64-bit? What's the output of `uname -a`? Also, have you built successfully on 1.5 on *this* computer? It looks like you are running an i686 userspace without parts of the i686 C toolchain installed, but *with* the x86_64 toolchain. Which is strange.
Thanks for the report. [I filed it here](https://github.com/rust-lang/rust/issues/31151).
Hexchat has been pretty nice for me recently, but I'm not a power user.
I think it largely depends on the type of programs you write. I don't remember how long it took me, but I'd estimate it was after about a month of working on servo 40 hours a week. In contrast, a friend of mine played with Rust on and off for a year in his free time -- often becoming frustrated and going back to c++ -- before getting to that sweet spot. But I'm not an expert Rust user by any means. I use it in my side projects, when I have any, but mostly just follow /r/rust these days. I rely on irc #rust a lot when I get blocked.
It looks like the problem is that you've created some Zero-Sized types to represent handle values, when in reality those types are typedef'd as `*mut c_void`. I think if you changed those structs to type aliases for `*mut c_void`, it should work. You'll also need to mark your enum as `#[repr(C)]`. Edit: JsThreadServiceCallback is also a function pointer, so you'll need to change that to `Option&lt;unsafe extern "system" fn(callback: JsBackgroundWorkItemCallback, callbackData: *mut c_void)&gt;`
Damn. German Keyboard vs. English keyboard layout. github.com/matthiasbeyer/imag
with nom, it could look like this: named!(split&lt; &amp;str, Vec&lt; &amp;str &gt; &gt;, separated_list!(char!(' '), digit) ); If you need to handle the parens, there's a combinator for this too: named!(split&lt; &amp;str, Vec&lt; &amp;str &gt; &gt;, delimited!( char!('('), separated_list!(char!(' '), digit), char!(')') ) ); 
Even better, [use empty `enum`s to represent an opaque struct](http://doc.rust-lang.org/stable/book/ffi.html#representing-opaque-structs). Then you get type safety (as opposed to a type alias).
http://tgceec.tumblr.com/ (also: https://news.ycombinator.com/item?id=10959520 )
Thanks, that worked. :)
You probably mean shoggoth-rs, which I managed to get to compile around rust 1.4 – anyhow [typenum](https://github.com/paholg/typenum) implements the core of it in current Rust. Based on /u/paholg 's and my experience implementing it, I am pretty sure that Rust's type system actually is turing-complete. However, one has to be careful to avoid triggering a bug that leads to exponential type expansion, which precludes larger operations.
What does `cargo install --verbose` say?
In general, big regressions like this are not expected, no. I don't know what caused this. Maybe someone else does...
Ymmm... I think that's wrong cargo install --verbose Updating registry `https://github.com/rust-lang/crates.io-index` must specify a crate to install from crates.io, or use --path or --git to specify alternate source 
This is the same as just `*` for the constraint, by the way.
Ugh, I got caught up in the error, and not the bigger picture. Nicely done.
I am a big fan of large recursive macros. Great work. You may already know this, but Rust _does_ have a form of this functionality in terms of the `Deref` trait: essentially you can overload the `*` operator, and if a method call doesn't resolve Rust will try adding `*` (and `&amp;`) until it does. The necessary impls are [a bit shorter](https://gist.github.com/durka/eaf4e7cc8168dfa03096) than the macro! Also, if you haven't read it, [The Little Book of Rust Macros](http://danielkeep.github.io/tlborm/) is a treasure trove.
If somebody will make a text version, please share. (I'm personally too lazy to allow executing JS on a page that should show some text (sorry).)
The stackoverflow community is very particular about the kind of questions they accept. There are a lot of perfectly reasonable questions that will be closed before you can get an answer. I think a Q&amp;A thread would be really nice for those.
Down again, it seems.
Have you actually added a "nightly" feature option to your `Cargo.toml`? It's not automatic.
[removed]
You'll need to conditionally compile anything in regard to the recover. So you'll need to add #[cfg(feature = "nightly")] to the import and all functions using the recover api. 
This is not a great thing to say, I wish you wouldn't. There are plenty of reasons to dislike the design of many languages, but questioning the competence of their designers is rude and pointless. Notwithstanding, John McCarthy and Simon Peyton Jones are both people I would describe as famous language designers, and I suspect you don't think either of them incompetent, even if you (clearly wrongly) think that Dennis Ritchie and Bjarne Stroustrup are incompetent. Pretty much by definition, a famous language designer is competent because they've made a language a lot of people wanted to use.
I hadn't thought of the Deref trait; it might be better for the actual use case I had, a simple wrapper for a standard library type. And I haven't looked at the *Little Book*, although I have heard of it. I just recently started fooling with macros seriously.
&gt; cognitive load of learning C++ That's overly diplomatic, IMO. I'd say that C++ is hard almost entirely because C++ is the worst designed language I have ever seen. They're just starting to fix some of it now. The grammar itself is just a nightmare (e.g. `&gt;&gt;`). 
So a common case is I have my program already running, so `cargo build --release` can't succeed. But it just says unknown error. I can diagnose the issue only when I run `--verbose`. Hopefully it gets fixed soon!
Usually the blub paradox people seem to be the fp crowd, so if anything I feel like rust would have been on the receiving end of the condescension what with not having the haskell feature du jour, relatively awkward macros, lack of dynamic something or other, no gc, ...
[removed]
&gt; no gc I don't think no GC falls under Blub because people are genuinely familiar with the idea. However, I am keen to see if/when the no GC thing is worthwhile. 
[Guy Steele](https://en.wikipedia.org/wiki/Guy_L._Steele,_Jr.)
Well, the thing about templates is that they run much later in the pipeline and have access to typechecking information. That gives them a lot more power.
Because (a) users will see that error in terms of the specific code you wrote in your template, leading to confusing messages that leak implementation details of your template; (b) it's harder to test your templates to make sure they won't accidentally produce type errors with certain types.
&gt; A lot of programmers I know, including myself on a good day, use an understanding of the bias as a way to train ourselves to take time with each feature and work through the knee-jerk "oh this is crap!" reaction. Hear, hear, everyone commenting on [RFC 243](https://github.com/rust-lang/rfcs/pull/243).
Well, yes, but one could _circumvent_ (though not _turn it off_) the borrow checker with `mem:transmute`.
YouTube is uploading; will be available in a few hours.
Would you mind pasting the results of the `--verbose`?
I filed an issue: https://github.com/rust-lang/rust/issues/31157
You can ask in Stack Overflow, it's a good place to ask questions programming, large and small. If the SO mods close your question for being too silly (they really shouldn't), or if you want more visibility, you could cross-post to [the Rust users forum](http://users.rust-lang.org) (in the category ["help"](https://users.rust-lang.org/c/help)) or this subreddit. A great point about the forum is that it typically has less noise than Reddit, so you might prefer the environment there. IRC is great too (also to see the questions of other people and just to chat)
I've made [another PR](https://github.com/rust-lang/rust/pull/31158) to try to make that code more robust. When it does land and a nightly comes out, could you test it to make sure it fixes the issue for you?
Sure, will do. Thanks.
This is a double-post of [this one](https://www.reddit.com/r/rust/comments/42efnk/how_feasible_would_be_to_provide_a_spirv_target/).
In a way, reddit is that semi-realtime chat with some historical permanence. It would be helpful if reddit was somewhat more structured with a taxonomy of questions and the ability to refine a question and an answer after the fact. It is often the highly specific that gives people an insight into the way systems actually work. 
YouTube is ready: https://www.youtube.com/watch?v=UOp3lYC2Dvw (though probably not HD yet)
That *is* the correct value. You are dividing integers, and `2.5` is not an integer. If you want to divide floating point numbers, divide floating point numbers: `let b = (a as f64) / 2.0;`
Rust does not coerce to floating point by default (which is a very good thing, or it would be very hard to be precise), and that is the [typical "definition" of modulo](https://en.wikipedia.org/wiki/Modulo_operation). If you would like to have floating point operations, write e.g. `5.0 / 2.0`. edit: see /u/DarkNeutron 's post
As /u/just_a_null said, the first statement uses integer division. The result of an integer divided by an integer is also an integer, dropping the fractional part if it exists. For the second part, Rust uses `%` as a remainder operator, [not modulus](https://github.com/rust-lang/rust/issues/13909). This is largely because the remainder operation maps directly to hardware support (assembly instructions).
Ok, then a follow up: how do I make it so that someone compiling with the nightly build automatically has the "nightly" feature enabled without putting "--features=nightly" every time they invoke Cargo?
Amazing timing on this question. I just started trying to do this, literally hours before this post. I haven't yet made any notable progress, but I'm trying to make it a side project for my last semester of school. I'd really like to work with others on this project if anyone is willing, please get in touch! All I have done so far is set up llvm-spirv (took a few tries to compile) and build rust from source. Now I need to figure out how to massage the llvm output of rustc to work with llvm-spirv.
Given that this is one of those cases where neither design decision is obviously right for all use cases, it's good practice as a programmer to avoid needing to be right about how the modulo/remainder operator behaves with negative operand(s), regardless of the particular language we're working in at the time. For example, if you're making a snake game where the head of the snake moves one unit at a time left, right, up, or down, and the game board "wraps" (going off the left brings you back on the right of the board), then then instead of doing your calculation as... ``` new_x = (old_x + delta_x) % board_width ``` ...you can avoid the potential error entirely by habitually ensuring you're working with positive numbers any time you use the modulo/remainder operator: ``` new_x = (old_x + delta_x + board_width) % board_width ```
While I don't know of a way to make cargo automatically compile with a specific feature, it is possible to specify arbitrary rustc cfg's using build scripts, see [the build script documentation](http://doc.crates.io/build-script.html#outputs-of-the-build-script) and the [scoped-threadpool crate](https://github.com/Kimundi/scoped-threadpool-rs) for how it can be used (the build script uses the [rustc_version crate](http://kimundi.github.io/rustc-version-rs/rustc_version/index.html) to detect which version of rust is used). Also, if your crate is primarily used on nightly rust, you could make nightly a [default feature](http://doc.crates.io/manifest.html#the-features-section).
Thx you are indeed right ... I comes preinstalled in manjaro so i probably use that. Thank you for the info. 
I think, it is more the question, when rust gets GPU support and not if. Now that C++ has AMP, that allows to write GPU code directly in the language, rust would need something like that too. It would require some additions to the core language. C++ got the extra annotation `restricted(amp)`, so that the compiler can verify, that the function can be used on the GPU.
Thanks so much! Really glad you like them!
Interesting writeup, thanks for posting. C++ really cleaned up in the run times part even with all the fiddling with Java's GC settings. I was also surprised to see Scala finishing in front of Java there too - in my experience it was difficult to predict Scala's performance when I was using it. For many years with Scala even the simplest integer range for loop suffered greatly in performance compared to Java, until Paul Phillips implemented a hack to specialize it IIRC. I guess they've made progress. 
Of course if you only have exactly one problem, there will be one language that is superior to all others in solving it. But that's the false question to ask, because while you are solving your one problem, it may already have changed (at least this matches the experience of the majority of software engineers). Otherwise we'd all be programming HQ9+. But as soon as you expand the domain of your language and move from a DSL to a general programming language, you have to make some engineering tradeoffs that make your language more suitable to some problems while making it less suitable to others. So are some languages better than others? Sure, but which are which depends much on the problem you're trying to solve. Good thing we have so many languages.
I don’t see a clear regression [here](http://www.ncameron.org/perf-rustc/mem.html). Perhaps the benchmark should be added to avoid regressing in the future?
I don't mean to be a pedant, but perhaps considering why you need a zeroed buffer but help you to avoid having to do it at all. Unless you're passing the buffer into `unsafe` code, I'm unsure why it's worth the cycles. 
When starting out, it's likely easier to default to owning all fields, and cloning data into them. Once you start to understand when a struct will live for less, or otherwise doesn't need to own, you change the struct to have a reference. Another way to think of it is: get it working first, then worry about performance. 
I think the key word here is *safely*. We allow uninitialized memory to be safely worked with within a single function, but any abstraction (read: function) breaks such an analysis (because the consumer gets to assume mem is init, and the giver has to assume the consumer won't init the mem). I believe this is what the hypothetical `&amp;out` is supposed to handle. Type level "this is uninitialized, and someone needs to initialize it". This can be hacked down to runtime checks with destructor bombs and internal interfaces, I think. Basically: Foo::get_uninit() -&gt; UninitBuff write(buff: UninitBuff, I: IntoIter&lt;Item=u8&gt;) -&gt; Result&lt;UninitBuff, InitBuff&gt; Where UninitBuff can't be read (or perhaps, only exposes the read parts), and dropping an UninitBuff kills the program. Extend is just a weaker version of this. The issue with Read is trusting its claim that it wrote `x` bytes (which might be done by the kernel, and not any observable Rust code). Of course, this is only a problem because of the insistence on *genericity*. It is of course reasonable to trust e.g. a specific Reader like Vec/File to give an accurate result.
Trait objects? Yes, you can start with a Box, and later recognize you only borrow for a short time, and stop cloning it. 
Thanks for the feedback! Nice integration with Rust has been one of things I had in mind.
I want to do Fast Fourier Transform to get the frequency spectrum of an audio clip. Which libraries are in an usable state and preferably fast?
For library crates, it is the main entry point (and namespace) of your crate. All `extern crate` definitions and everything you don't want in submodules lives here.
Oh my, this post trolled me, since "guid" means something in programming. This is /r/rust, the community for the Rust programming language (and yes, we had this name before the game). You want /r/playrust - though given the content of your post, you're likely to be downvoted there. Work on your grammar and try to be polite about things.
Okay, so I have a type `Type` that I use within the directory. Can I place that in lib.rs and than in each file just say `use lib::Type`? This results in an error.
No, that'd be `Type` or perhaps in a subcrate `super::Type`.
If you really need access to private data, i don't see a way around either cloning/editing the original crate. Otherwise you can absolutely implement your own trait for their struct.
I'm confused. What do you mean? Doesn't `Box`ing a value simply allocate it on the heap and return a type of pointer (which is Sized)? Where does cloning come into play?
No need for the `lib`, only `use Type`. A crate is a tree of modules. Your `lib.rs` is the root of the tree. Therefore, it's not in some kind of namespace, it's at the 'top level'. `use`, by default, always starts at the top.
When compiling and running this code https://gist.github.com/anonymous/567d65f4b084041abfe8 I get the error: src/main.rs:4:5: 4:45 warning: the trait `core::marker::Sized` is not implemented for the type `Self` [E0277] src/main.rs:4 fn mconcat(&amp;self, b: Vec&lt;Self&gt;) -&gt; Self; ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ src/main.rs:4:5: 4:45 help: run `rustc --explain E0277` to see a detailed explanation src/main.rs:4:5: 4:45 note: `Self` does not have a constant size known at compile-time src/main.rs:4:5: 4:45 note: this warning results from recent bug fixes and clarifications; it will become a HARD ERROR in the next release. See RFC 1214 for details. src/main.rs:4 fn mconcat(&amp;self, b: Vec&lt;Self&gt;) -&gt; Self; ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ src/main.rs:4:5: 4:45 note: required by `collections::vec::Vec` Running `target/debug/monoid` How do I resolve that?
Two questions: How do I handle errors better? I feel like all my functions return Result&lt;(), String&gt;, and I have a lot of match arms like this: 0x20 =&gt; { let value = try!(self.function_that_can_fail()); slef.function_that_can_not_fail(value)); Ok(()) // Can I get rid of this? } Secondly, how can I get a build that has optimizations on (--release), but without stripping the debugging symbols?
Add a `Sized` bound. Either `trait Monoid: Sized` or `fn mconcat(&amp;self, b: Vec&lt;Self&gt;) -&gt; Self where Self: Sized;` Probably bounding the whole trait is what makes the most sense here.
Ah, I kept trying `?Sized` based on what I found on Github. This fixed it, thanks!
That was it, thank you!
&gt; I have a lot of match arms like this If many arms return the same thing, then you can move that to the end, after the `match`: match expr { 1 =&gt; try!(thing1()), 2 =&gt; try!(thing2()), 3 =&gt; try!(thing3()), }; Ok(())
Maybe the easiest way is just to submit a PR to the rand crate with a method that adds a `get_lambda()` method to `rand::distributions::Exp`? 
I'm happy to put this PR in but I think I'll just clone the necessary parts within my crate as /u/yammajr suggested. As I add more distributions etc. I think it will be easier to maintain if I have this stuff locally. Thanks for the advice though!
Usually, unit tests go with the source, and integration tests go in the tests directory. But: https://doc.rust-lang.org/book/testing.html#the-tests-module By putting them in a module, you could easily extract it to another file, like any module. This can help with larger modules.
Thanks for the tip. Sounds interesting to compare using petgraph, too.
[rgsl](http://rust-ci.org/GuillaumeGomez/rust-GSL/doc/rgsl/index.html) is a wrapper around [GNU's Scientific Library](http://www.gnu.org/software/gsl/) and includes some tried and true [FFT functionality](http://rust-ci.org/GuillaumeGomez/rust-GSL/doc/rgsl/fft/index.html).
Does this mean you don't need me to change the license of [this](https://github.com/sellibitze/secretshare/) anymore? Looks like you've reimplemented everything...
`?Sized` means that you specify that the type may or may not be sized, for cases when `Sized` is the default. If you have a function like: fn print_it&lt;'a, T&gt;(val: &amp;'a T) where &amp;'a T: std::fmt::Debug { println!("{:?}", val); } fn main() { print_it("asdf"); } gives the error &lt;anon&gt;:6:5: 6:13 error: the trait `core::marker::Sized` is not implemented for the type `str` [E0277] &lt;anon&gt;:6 print_it("asdf"); ^~~~~~~~ since the function's template parameters implicitly have a `T: Sized` bound. You can relax it by adding the `?Sized` bound: fn print_it&lt;'a, T: ?Sized&gt;(val: &amp;'a T) where &amp;'a T: std::fmt::Debug { println!("{:?}", val); } fn main() { print_it("asdf"); } In your case, you can only use values that are `Sized`, since you're moving around raw values.
Yeah, I rebuilt it from scratch :) Coding during a blizzard is fun!
You want to post on /r/playrust.
Do you happen to know the intent of the rewrite? I've been going through the book and have been impressed.
What an interesting algorithm. What are the use cases for something like that?
It's called truncation towards zero. You perform the division on the real numbers and throw away the fractional part. The remainder is defined as the integer that satisfies `b * (a div b) + a mod b = a`. Thus `5 div -2 = -2`, because `5 / -2 = -2.5` on the real numbers and -2.5 without the fractional part is -2. And `5 mod -2 = 1`, because `(-2) * (-2) + 1 = 5`.
The README says: let secret_data = SecretData::with_secret(&amp;"Hello World!"[..], 3); ...but [the source](https://github.com/Nebulosus/shamir/blob/76a69feef2a9e8ab157989e15f8c00b0ac9a5a6b/src/lib.rs#L86) says: pub fn with_secret(secret: &amp;str, threshold: u8) -&gt; SecretData If `secret` needs to be `&amp;str`, can't you just pass `"Hello World!"`? Why do you need to reference and slice it?
&gt; Interesting writeup, thanks for posting. Unfortunately Hundt's benchmark methodology is not great. &gt; C++ really cleaned up in the run times part even with all the fiddling with Java's GC settings. I was particularly interested in [F# cleaning up in the run times](https://fwaris.wordpress.com/2011/07/11/googles-multi-language-benchmark-in-f/) beating everything including the original generic C++. There is a C++ version specialised for this particular test that is much faster but that is only possible because the methodology is dodgy. So I'm wondering if idiomatic Rust can beat idiomatic F#. I'm also interested in bigger benchmarks than the usual suspects. Rust seems to be mostly benchmarked against C++ and the poor productivity of C++ limits the complexity of the tests themselves. 
There are multiple reasons I think. First of all the book is going to be published in paper format by "No Starch", so I guess they need a more cohesive and continuous flow through the whole book. Secondly the structure of the book dates back pre-1.0 when Rust would change frequently an a lot of time went into updating the book giving Steve less time to work on the general structure and flow. Now that Rust has hit the 1.0 milestone and all the crazy fuss has settled down a little, Steve can finally take the time to really write it the way he planned it to be. /u/steveklabnik1 should be able to give more details or correct me if I said something wrong :) I think the rewrite will go more in depth in certain concepts like ownership and borrowing and other parts were newcomers generally struggle a little at first. 
You always build a prototype and then throw it away :) That is basically it, yes. I did a lot of work, but it was more important to have _some_ kind of documentation on everything, rather than making it perfect. And then I missed some things, and so stuff was brought up, and so I fit them in... but it was never really in the shape that I truly wanted it to be, it was just the best that I could have done at the time. Now that there's gonna be a printed version, and that we've had some experience with post-1.0 Rust, I can actually do it right. I don't plan on doing another major re-work of it until if and when there is a 2.0, though I will modify it to add stuff for new features as they arrive. But they should be able to fit into the existing framework.
Is there an RFC for &amp;out? I've never heard of it until now.
Thank you!
To answer your first question: There's simply no other option. You either move the content (transferring ownership) when you dereference or you copy the content (by deriving `Copy` or `Clone` as you discovered). Dereferencing is the opposite of referencing. You borrow when you reference, you transfer ownership when you dereference. To answer your second question: `#[derive]` generates an appropriate `impl` for the associated Trait. Only `Eq`, `PartialEq`, `Ord`, `PartialOrd`, `Clone`, `Copy`, `Hash`, `Default`, `Zero`, and `Debug` can be derived. The [reference](https://doc.rust-lang.org/reference.html#derive) section about `derive` could probably be improved, but you have an example of a generated `impl` there. Edited to include `Copy`.
I'm not really an expert on this, but I think [mio](https://github.com/carllerche/mio) might be useful.
&gt; rediculously fast compared to c++ It's also quite concise compared to Java, clear compared to Perl, and fast-running compared to Python. The compile times are a bit of a pain point at the moment, but there's work in progress that is expected to speed things up quite a bit. First a better internal representation (MIR) that enables some optimizations in the front end that reduce the work that LLVM needs to do in the back, and then incremental compilation so it doesn't need to rebuild the entire crate every time anything changes. And yeah, the auto-generated documentation is beautiful. It's part of what makes external libraries so much easier to use than in C++. I can just open up the `target/doc` and, even if the library author put in no effort whatsoever, get a full listing of every data structure and function provided by the crate.
&gt; This is also part of a multi-language benchmark found here. Yeah, I saw that too. &gt; About two weeks ago I had a version with reference counting, but it was slow, around 30 seconds (you can see some results on the benchmark's page, my laptop produces almost the same execution times). Interesting. &gt; It took me about a week to understand the syntax and the compiler messages, but it finally compiled. I didn't have much time to polish it, I'm not entirely sure that it does the same thing as the other implementations, because it's a bit hackish, but it runs just under 11 seconds (if you compile it with a nightly that contains the BTreeMap rewrite). You can find it here. I'll take a look, thanks. 
If anyone has any issues specifically with rust on windows, you can reply to me and I'll try to tell you what I know. I've had my fair share of windows related annoyances and would love to pass on the knowledge I've gathered! 
Yeah I have noticed it... It's just I don't know how to feel about it. (They also automatically posted that same thing to my other projects). I don't myself know what problems only having MIT has compared to dual licensing and I am unsure about it.
Well thats odd... There doesn't seem to be trait in num for it.
Thanks for the observation! It;s a holdover from pre first commit :) Fixed in the tests and the readme :)
Where do I find the plan for the next versions of rust? I always read that someone "had to use nightly" but never know when the feature is planned to be stable.
&gt; The lot of languages you can offhandedly think of either weren't available at all or for the platform. Not to disagree with your main point, but the first language I thought of was Forth, and that's twenty years older than BF. 
`Copy` can be derived too, which OP probably wants in addition to `Clone`. The the code can be changed to `1 &amp; (*foo as usize)`
I asked a while ago but I'm curious if the situation has changed. Has anyone created a software projection rendering engine in Rust? I'd like a good, simple base to work with for experiments.
Is there a list of unstable features anywhere? Can a function be generic over borrow types? (return &amp; if passed &amp;self or &amp;mut if passed &amp;mut self)
It's called "shadowing", what you're actually doing is creating a new variable with the same name (and this new variable is what `x` refers to thereafter). It's a useful trick, and great for keeping your variables from becoming like `x_inner_2` or whatever, but you should avoid overusing shadowing elsewhere.
&gt; There isn't really much of a plan for what features go in what version, though, they kind of just throw them in as they finish. To elaborate a little, when new versions come out every six weeks, there's a lot less pressure to get a particular change into any given version. That doesn't mean that it's entirely ad-hoc, it just means that the plan for specific releases isn't as big of a deal as it is in a project which releases something like once a year.
There seems to be a lot of words missing e.g. "Using &amp;str we borrowing whole array to the given variable binding." Also seems to be missing a lot of pronouns, "Allow to" instead of "Allow you to" and similar things. Otherwise a really nice intro.
Thanks, I'll fix it :) 
No, it's just things like how to use certain crates. Like with SDL and multirust, it was not made clear where to put the sdl libraries, but I made a PR for it. Another one that caused some headaches were using anything with freetype to start. We finally got that figured out in irc though
I have a good idea what most of the features on the homepage refer to, but what exactly is "move semantics"? I'm a new (hobbyist) Rust programmer coming from web development. I haven't been this excited to learn a new language in a long time!
It means that Rust, unlike C++ prefers to create flat copies of objects by default. C++ implicitly creates deep copies by default whenever you pass an object by value, which creates a lot of unnecessary cost. In Rust flat copies are the default, but you are not allowed to use the original object once you "moved" the object. You are not allowed to use the original object anymore, because both copies might share the same data (due to it being a flat copy). In case of a vector, they refer to the same internal array for example. But if you add an element to one of them, only the one that is directly modified gets the new length. So they get out of sync eventually and everything breaks, which is why you shouldn't (and therefore can't) access the old object. If you want to do that, you need to explicitly create a deep copy (via .clone()). C++ 11 added move semantics too, but those only work on rvalue references (temporary values) or explicitly via std::move (instead of the compiler not letting you access the old object, C++ simply says it's undefined behaviour). So basically Rust switched to a better default in this regard.
Move semantics have to do with rust's borrow system. For any type that doesn't implement the Copy trait, the ownership of an object is moved upon reassignment. E.g. let x = vec![1,2,3,4]; // Vector is owned by x let y = x; // Vector ownership has moved to y x.push(5); // Error! x no longer owns Vector
Hmm. Best I could find with a short search is [this Quora question](https://www.quora.com/Whats-the-different-between-Apache-v2-0-and-MIT-license).
 $ uname -a Linux laptop 4.2.0-25-generic #30-Ubuntu SMP Mon Jan 18 12:31:50 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux I built my code and it compiled with Rust 1.5, then I immediately (literally) upgraded to Rust 1.6 on the same computer, tried to build again, and the problems began. Upgraded to nightly and it failed again.
Sorry, PHP is dying and C is being adapted for web development? What on earth are you talking about? The PHP ecosystem has never been healthier, and I don't know many developers looking closely at C/C++ for application development. Saying nothing about Rust itself, this article is front-loaded with a bunch of nonsense. 
Many thanks for your YouTube uploads. I really like your series. It's especially interesting to not watch someone building an emulator, who knows every single tiny step required by heart. All that research-on-the-fly and refactoring makes these streams way more interesting to watch.
Even today's Microforths come at a Kb or more. And remember you have to type in the machine code for the interpreter by hand.
This is an awesome and ridiculously easy trick. Thanks!
For shorter-term, but more detailed, lists of changes, https://this-week-in-rust.org/ is helpful. It lists the new and accepted RFCs for each week together with those placed in "final comment period" (i.e., those that soon should be decided upon).
`cargo update --precise _version_ _name_` updates the dependency version in your `Cargo.lock` file to what you specify IIRC. To add a dependency with a specific version (or just the latest), use `cargo add` which comes with cargo-edit.
I don't quite understand what this [this GitHub comment](https://github.com/rust-lang/rust/issues/21784#issuecomment-158279842) means, saying that `#[test]` is stable but that the test crate is not. (I'm trying to build unit tests for the [imageproc](https://github.com/PistonDevelopers/imageproc) library, but get a warning saying that `#![cfg_attr(test, feature(test))]` may not be used on the stable release channel.)
I've found this gem from [the proggit discussion on Herbie](https://www.reddit.com/r/programming/comments/42g7p7/new_tool_herbie_automatically_rewrites_arithmetic/cza4ndc). It seems that it hadn't received much highlight so far, and I was not aware of other similar projects available.
Since I [haven't found](http://stackoverflow.com/questions/34865593/find-out-the-current-version-of-a-crate-from-a-lint) a reliable way to find the current versions of dependencies, my dependency lint is stalled, so I picked up writing a lint to suggest the use of `extend_from_slice(_)` where applicable. Also perhaps I'll still find the time to write my level generator. Edit: I'll also blog about clippy again now we reached the absolutely arbitrary milestone of **100** lints!
Still working on the MSVC detection stuff. There's a lot of weird edge cases in how MSVC is installed. https://github.com/rust-lang/rust/pull/31158
Ok, let me know once you have something online :)
Yes. You encrypt data with normal symmetric algorithm and then split the key using SSS. Then each party receive portion of the key. 
You can use #[test] attributes on stable, but the imageproc unit tests use the Bencher class, which depends on the unstable "test" crate (#[test] attributes don't use that crate). At the moment you can build imageproc on stable but can only build the tests on nightly. Switching between the two is really easy if you use multirust, so if you're not using that yet it's worth taking a look.
I am in the process of rewriting [mdBook](https://github.com/azerupi/mdBook) to have a cleaner, more modular and testable code base. I will probably [switch from JSON to TOML](https://github.com/azerupi/mdBook/issues/96) for the configuration file and [add multilingual support](https://github.com/azerupi/mdBook/issues/5) in the next few weeks! 
Awesome to hear! I was particularly worried that that wouldn't be the case before I started doing this, so it's awesome to hear it was the right idea. I find it super fun myself!
A question about generics, closures and lifetimes: How to make this work? I thought I could do it, but now I'm baffled. make_doubler is supposed to create a closure that has a reference to another closure, and the lifetimes are supposed to make it work safely, but I can't convince the borrow checker. http://is.gd/pNYZam
I think you should document the fact you can expose modules as public with the use statement, which means you can have a different name scheme internally as to the one you expose.
The main reason, why I think that especially this is interesting is,... well... Basically, if you know what to do, building a compiler, a kernel, or an emulator is actually rather trivial. Just writing down the code based on your knowledge and it's done. However, barely anyone knows everything about the target system by heart, so the actual work will always be a "search-research-impl-test"-loop. And your series greatly shows how to do this right. Including getting help where needed. So, in a way, this series is a great HowTo for any kind of project people may come up with. And this way it will feel more fulfilling when the emulator finally works. Just FYI. Keep the vids coming! ;3
http://is.gd/DywO8k ?
The problem is that `FnOnce` can only be called once, and then it's destroyed. A reference to an `FnOnce` is therefore unusable, since its value can't be moved and destroyed. It looks more like you want to use `Fn`, since you are using the first closure in two places. Here are the general rules: * `Fn = fn(&amp;self)`: Share and reuse, but not change or destroy. * `FnMut = fn(&amp;mut self)`: Reuse and change, but not destroy. * `FnOnce = fn(self)`: Change and destroy, but not reuse.
touché, that'll probably be the next change :)
Yep, PHP is not dying; and the whole *"betting on HTML5 was a mistake, lets go native"* looks somewhat strange when the blog then suddenly suggests using *systems languages* as back-end languages for the web (i.e. the mistake part).
That link compares C++ on an unknown CPU to F# on the author's machine, it's not meaningful.
Already there! https://doc.rust-lang.org/book/crates-and-modules.html#re-exporting-with-pub-use
I'm honestly not sure you can do that in the `where` clauses. Your second example is correct, as far as I know.
The link also contains comparisons done on the same machine that are meaningful. Ignore the meaningless ones and focus on the meaningful ones. Or just run the benchmark yourself.
This is magnificent and potentially super useful to me (solving ODE systems in rust)! Not only does Rust save me from a ton of programming mistakes, it now also yells at me to avoid issues with my numerics. Just fantastic!
Would you like to explain what you mean with "software projection rendering engine"? Do you mean rendering on the CPU? I have seen multiple path/ray tracers of the slower but more accurate kind, but I can't remember seeing any realtime engines.
Thanks! Okay, the final challenge. (I actually started playing with this example because I was interested in this particular case) http://is.gd/wkT5Jr Is the type V that is being handled by the closures, possible to be made generic? Currently I'm stuck with trying to get the the where clause the specify that V should implement Mul with Right Hand Side specifically being i32...
I can understand why they did it, although I think in another form this could be quite effective as well as beneficial. Maybe some sort of permission to receive notifications/improvements of Rust-wide resolutions?
Thanks. I think I understand - I think I need to try and familiarise myself with C style pointers, so I can fully understand where this is coming from :) I hadn't spotted the reference section about `#derive` - thank you for pointing that out :) I might try and understand this further by reading some code and fleshing that documentation out :) For context, I was working on an exercism problem which I've managed to get working thanks to your help - my first pass solution is here: http://exercism.io/submissions/29d9de2180ed429c9222be32f6dc8868
The definition of `Mul` has one type parameter (the right hand side) and one associated type (`Output`). You want the right hand side to be `i32` and `Output` to be `V`, so the syntax for that is `V: std::ops::Mul&lt;i32, Output=V&gt;`.