Could you return `Vec&lt;[u8;2{&gt;` with wasm-bind gen? I would be curious if there would be a performance benefit?
Hi all! I've been thinking a lot about some of the efforts folks have been making in the last few years to help grow our ecosystem's maturity. This post is another effort from the \[Ecosystem Working Group\]\([https://github.com/rust\-lang\-nursery/ecosystem\-wg](https://github.com/rust-lang-nursery/ecosystem-wg)\) to talk about how we can organize our projects to cope with inevitable change, and apply it to some of the long\-term residents of our own Rust nursery. I'd love to hear what other maintainers in the community think on this broad topic! :\) Speaking of long\-term residents of the nursery, we're looking at setting up an organization around the \`bitflags\` crate. If you'd like to get involved check out the post and reach out \[here\]\([https://github.com/rust\-lang\-nursery/ecosystem\-wg/issues/2](https://github.com/rust-lang-nursery/ecosystem-wg/issues/2)\).
Would glob work? https://crates.io/crates/glob I think ripgrep uses this... but don't quote me on that.
ripgrep uses [`globset`](https://docs.rs/globset). To address /u/SirVer... I don't think there is any out-of-the-box library API, but you could probably roll your own where the effort required would be proportional to the sophistication you want. e.g., Something simple might be to use the [`strsim`](https://docs.rs/strsim) crate to compute string similarities between your query and your entire corpus. Something more sophisticated might be to use [`tantivy`](https://github.com/tantivy-search/tantivy) or just [roll your own mini-index structure](https://github.com/BurntSushi/imdb-rename/blob/master/imdb-index/src/index/names.rs). (The latter two choices require building an index, which could require quite a bit of work to maintain depending on the problem you're trying to solve. e.g., If your corpus changes frequently.) Globs and/or regexes would be convenient if you could make that work. :-)
[rustfix](https://github.com/rust-lang-nursery/rustfix) We as developers don't even have to solve bugs anymore. 
Really nifty! And my son was enthralled!
A similar pattern is also used in the `http` crate's [extensions API](https://docs.rs/http/0.1.5/http/struct.Extensions.html).
Sounds good; thanks!
&gt; First we seed the random number generator (RNG). hash_sum takes the u8 value of each character in hash and adds them all together. I found that this resulted in greater changes between two similar hashes, when compared to having a fixed seed. I'm glad that you made this decision. I noticed that with Levein's implementation a change to the last digit of the hash produces only a subtle change to the snowflake. In the Rust version the change to the snowflake is more pronounced.
I mean if you look at the code, it does is `unsafe`. This is unsafe in exactly the same way `mem::transmute` is unsafe
I noticed that Specs came up in previous conversations about this, but I can't recall any mention of [Froggy](https://github.com/kvark/froggy). Froggy is an experimental library by one of the Specs authors, exploring a different way to deal with this idea of a "graph of components". I haven't put any thought into whether it would be applicable/useful to what you're doing, but it seems like it would be worth including in a "solutions considered" section of your talk, if only to explain why it's _not_ suitable.
What's the benefit of the struct wrapping the enum?
Honestly Froggy is probably closer to what Raph is doing, since it completely gives up on the idea of an ECS and just goes with a graph instead.
It's nice as a way of providing a point to encapsulate errors or add higher level operations on errora, which provides some flexibility while maintaining compatibility. In simpler cases or where compatibility isn't a huge concern, then just a straight enum is probably fine.
&gt; `Unknown` might be a touch more ambiguous, since it might refer to an "unknown" error of sorts. I agree. Coming up with a descriptive yet succinct name is difficult. My reasoning for that formulation was that it reads how it is. "Unknown error kinds aren't implemented." The RFC takes a different approach. It forces downstream crates to use non-exhaustive matches (there's no way to opt-in to an exhaustive match), and prevents them from constructing the type completely.
You mean like this? https://crates.io/crates/sublime_fuzzy I use that for fuzzy string search, it works well.
If someone asks me straight up "Code FizzBuzz" in an interview and expects this, I can tell you right now I'm not getting the job.
I'll offer some perspective, because I've been writing on the issue a lot lately. I'm not an expert on GUIs or anything (I am currently writing my first,) but basically there are some core facts that we have to deal with. A Graphical User Interface (GUI) is fundamentally a communication platform. Its purpose is to provide a channel by which an application can communicate with the application's user. The GUI is an interactive simulation which uses some sort of communication protocol for synchronizing user intent with application state. Thus the most important aspect of a GUI is *how the communication happens*. There are things that need to be communicated and there are ways to enable the communication. Before I get to that, I'd like to give a rough summary of the design for the library I'm working on in terms of the *communication* required: --- My UI's communication model is broken up into several different components, with varying degrees of coupling, roughly categorized as 1. Core (Events) - The 'core' component is responsible for collecting inputs from control devices and translating them into messages (called `Event`s) for other components, as well as dispatching those messages to the appropriate places. It is the top-level "manager" for the UI. 2. Sync - The 'sync' component is responsible for synchronizing the state of the UI with the state of the application. This is mostly done through Rust's memory synchronization primitives (e.g., `Arc`, `Mutex`.) 3. Script - The 'script' component is responsible for synchronizing the UI elements with each other, and for allowing the application to control the behavior of the UI directly. This is done through a combination of `Event`s, sync primitives, function overrides, and closures. 4. Flow - The 'flow' component is responsible for communicating the shape and size of UI elements to the core component (for dispatching spatial events to the correct element,) to the draw component (for drawing elements in the correct place), and to each other (for responsive containers.) Flow communication typically happens through internal function calls, though events can be used in some cases. UI elements will typically maintain their flow state 5. Style - The 'style' component is responsible for providing styles and behaviors to the core, flow, and draw components. Style communication happens through a `Style` object which is made available to the style-sensitive parts of the system, though elements may maintain some style information internally if they need to override defaults or use an element-specific style or behavior. 6. Draw - The 'draw' component is responsible for rendering the current state of the UI to the user. Drawing information is communicated through overridden function calls, and UI elements will typically maintain their draw state internally. 7. Engine - The 'engine' component is an optional, and is responsible for running the whole system in the case that the application is purely UI driven. (I.e., the application simply idles without user input.) It is not needed for applications that want to drive the UI themselves. --- Now if you read that over, there's one impression I'd like to leave: Rust is *not* bad at GUIs, because Rust as *good* at modeling communication channels. It's just not going to do it in the way everyone is accustomed to, and it may take us a while to find the optimal form. 
I will tell you my story as a beginner maybe it will help you about your situation. i was taking rust as my primary language. for sure it was hard for me to absorb the concepts. but right now I feel 'aha moment' i have built cli application for my little daughter to train her at math. also developed web application with rocket for my personal use . my journey began from 1.0 of rust yes... it was a long journey but one thing is very important for me. most languages like go , python and others became more easier to me. and I developed an application to analyze data in one day with go-lang. PS. I am still beginner in rust :-) 
That seems more true for binaries than for libraries. In a library it should be expected to be in an environment where a panic should never happen, like embedded, so it would be unwinded, and memory would leak. Not exactly ok.
I have no problem with this. Make the act of opting in very deliberate. A simple flag might be accidentally set by complicated and nested build system. `cargo install cargo-telemetry` removes this possibility. If rust is adding telemetry, then I strongly support going with this method. 
I'm interested! I'm up in Davis county, so Utah valley isn't too far.
What are the paths to entering this type of role? I am in kind of position in life, where I am seeking low\-level programming \(kernel drivers, working with audio, fintech\) type of role. I have 2 years commercial experience, mostly self\-taught. But have bad luck applying to those roles. Web\-dev seems like an easier route to get into, but that is not really my passion. Any advice?
Is there private data stored in the struct? Otherwise I'm not sure how it makes a difference. The enum could just as well have the methods like `is_io_error` on them, and if the enum is public, you're still have to worry about breaking changes to variants/matching. It'd make more sense to have an opaque struct if there *wasn't* an enum the user can access.
Yes, although undocumented, consensus is that Rust has no strict aliasing and type punning is fully defined and not UB (although unsafe).
_sigh_ SF has all the best meetups :)
See since you sound kind of involved... Is the one where the variable name of what I can only imagine is in intermediate compilation level leaks been reported? I've had a `.map(|_| ...` that had other things wrong with it. The error message pointed at the _ and told me "'b' is not defined". I think I get dotenv to point at an derive with the error `"f" is not defined` too. That one I can probably reproduce if this doesn't sound familiar.
In C (or at least some version of it), type punning is undefined behaviour, i.e. shouldn't ever happen, which is different to what `unsafe` means.
If you can reproduce it, file it. I couldn't find anything similar after a cursory look at the [A-Diagnostics issues](https://github.com/rust-lang/rust/issues?utf8=%E2%9C%93&amp;q=is%3Aissue+is%3Aopen+label%3AA-diagnostics), although there are apparently 623 of them currently open.
I couldn't get registered it time - some meetup.com glitch, but I'm coming anyway. Try stop stop m.
Thank you! Here's a version that's closer to my original but uses a couple of the ideas from your version: http://play.rust-lang.org/?gist=62722ac7d257d4d36c543e3908cc95f8&amp;version=stable&amp;mode=debug In short: - Using `match self` instead of `match *self` is necessary. - Using `v.pop()` twice instead of indexing into `v` is necessary. - Using `swap` instead of `replace` isn't necessary.
But there is no GUI in Rust...
I think you're right. It might not matter if you do it once, but in a loop the last thing you want to do is to take a memory access just to load up zeroes in a register. /u/jackmott2: `_mm_set1_ps(0.0)` and `_mm_setzero_ps()` both compile to a `xorps`. `_mm_set1_epi32(1)` ends up as a memory load anyway (I'm a bit surprised), and `_mm_set1_epi32(0xff)` is nifty. You can check the ASM here: https://play.rust-lang.org/?gist=c5bfcab3cbe2deda3cac4d445a91e9e2&amp;version=beta&amp;mode=release. So in three of the four cases you're worse off using a constant, and in the last one you get the same thing. With more complex values it might be worth storing them into a register (`__m128` variable and hoping they really stay there), but for these you should just use them where you need. There's a small caveat which you might have noticed on my playground link: vectors are returned on stack, not in a register.
If it’s automatically solvable, it’s not really a bug.
[Chalk is a PROLOG-ish interpreter written in Rust, intended eventually for use in the compiler](https://github.com/rust-lang-nursery/chalk)
this is why I personally use a: // Kludge: Comment tag in my code. When I get a chance I search and review and see if I can fix things.
I'd say it isn't a bug unless it ends up in your post-compilation code. Until then it's just a thing you tried.
I am not sure if loops are the main problem, in modern C++ iterator loops are also very common (though not as much for integer ranges) and compile times are not as bad by just using them. An optimization for them would be tempting, but it might tie the compiler and the stdlib too much and I'm not sure this is desired? Unless your code gets highly generic, which is a lot of Rust code and less C++ code. (But if you use a lot of Boost or friends, you will end up with worse compile times again, I'm currently working on 4-5k C++ project with two (bigger) header only libraries and it takes 40-50s to compile which I think is rather slow.) 
This sounds quite interesting as a model. I'll be curious to see how it works out with `bitflags`. I assume that we would be better off discussing at [the GitHub issue](https://github.com/rust-lang-nursery/ecosystem-wg/issues/2) than here in Reddit, though?
Looks interesting, good luck with that!
Alternatively to a one organisation per crate model, I really like the crossover and exchange of ideas of having domain organisations like we have for game developers (piston) and AI (autumn). Having an excellent crate is half the battle, the other half is ensuring it fits in easily as part of a larger story. I am really excited by these domain specific communities, getting like minds together and realising they are tackling common problems has to be a good thing. How we structure things organisationally has a big impact on how the resultant code / ecosystems are structured.
Logic based thingy to implement rusts trait and type system, by Niko Matsakis Here's the introduction: http://smallcultfollowing.com/babysteps/blog/2017/01/26/lowering-rust-traits-to-logic/ More on Chalk: http://smallcultfollowing.com/babysteps/blog/2017/05/25/query-structure-in-chalk/ Latest: 
I would love to put in a PR that fixes this, but for now this is [perfectly fine behaviour](https://doc.rust-lang.org/nomicon/leaking.html). I agree that memory leaks suck, and I would like to write a PR that addresses this, but the current behaviour is fine for now.
I would never call using `failure` or `error-chain` an overkill. Both are very small libs and adds a lot of value to your project. I currently use `failure` in all my cli projects (I have lots of them at work), because its `Error` type is great, but not perfect anyway. I still have to use `.map(Into::into)` and some other conversions sometimes. However, I've found `failure` pretty hard to use in libraries. When I've read documentation, it looked very easy, but when it comes to actual implementation, I failed. The thing I miss most are some more detailed examples
I maintain the `url` crate, which has a number of open issues and pull requests that I have little time of motivation to go through. My interests have moved one since I made this thing 5 years ago, but despite giving a few people access after [a specific call for help](https://users.rust-lang.org/t/help-wanted-maintaining-rust-url/10707), PRs tend to still be neglected until *I* get around to dealing with them. &gt; Do you have a library you think needs more support growing its maintainership? Reach out [here](https://github.com/rust-lang-nursery/ecosystem-wg/issues/11) if you’ve got any thoughts. This sounds great! Except that the link goes to something about the libs blitz. We’ve done that with `url` (last year?), and unfortunately it only resulted in more open issues and PRs for me to neglect. This post says a lot of interesting things, but it starts with the premise that a number of people are available and interested in doing the work. In my experience, getting an open source project to the point where there are multiple such people is the hard part. &gt; We take: […] A shepherd. […] A team of more than one person that […]
Like anyone would haha
This is a good point! I think Rust's current domain working groups are achieving this exchange of ideas even without collecting libraries under a single domain specific organization, but piston and servo are great counter examples for broad organizations that maintain a collection of loosely related libraries. I think there are more implications around coarsely fragmented ecosystems that you might expect from organizing around a few key domains or frameworks (I see it a bit in .NET), but I haven't dug too far into them yet. So I think independent organizations are a good starting point, but we should always work to realise that exchange of ideas.
I understood that part. I mean -- what's the context for this project? Do you have connections to any of the other projects mentioned in your README (Gnome/KDE/whatever) that you are using (want to use) resvg for?
Yeah I think I marked them with a TODO.
&gt; because it usually means you have to handle errors more explicitly than just using the `?` operator everywhere You can fix that by implementing `From` for the respective error types. Which has the added bonus that you express relationships between error types, making sure that a lower-level error wraps correctly into a higher level one. The easiest case, of course, is to simply have a wrapping enum variant, but sometimes you’ll end up with duplicate nested variants. I actually started out with one large error type in the domain crate but in the rewrite I changed this to separate error types matching that actual error. `failure` is a godsend for that, since it makes writing the `Display` impls a breeze. 
Good points, though I don't see a reason to make the `Unknown` variant undocumented/hidden.
I've tweaked it a little and cleaned up some bits. Also took care of some cases in truncate that were not being handled. https://play.rust-lang.org/?gist=efb244666d705fd17deeb170bc2907d9&amp;version=stable&amp;mode=debug 
Your hat project could use a small summary to explain what is going on because I don’t understand at a glance what a snapshot backup is and I’m very curious.
BTW #rust-fuzz on irc.mozilla.org is a nice place for all things related to rust fuzzing
A snapshot backup in this context is a full copy of your local file\-system, as it looked at one point in time \(the snapshot time\). Or at least, that is what the snapshotting backup system is trying to give you. In Hat, this works by first adding all the files that should be included \(a bit like "git add" if you know git\) and then comitting them \(like "git commit"\) to create the final snapshot. In the end, all snapshots look like a complete file\-system, as opposed to incremental backups where some snapshots only contains the parts that were different. Does that make sense? :\-\) The fuzz test in the blog\-post creates a completely new Hat system in every test, then adds a single file to the index and commits it. This creates a new snapshot, which is then used to recover the file, so the fuzz chosen metadata can be verified. Let me know if I am helping or making it worse :\-\)
Thanks for the pointer, I will go and hangout in there! :\-\)
Thank you, that’s what I suspected from reading the code but it helps to get it from the horse’s mouth. I’ve saved this for future reference and I’ll be interested to see how this develops. Fuzz testing is something that I’m aware of, but until I use it for my own project I won’t fully appreciate. Btw why are the copyright licenses from 2014? Is that from when the license was last revised?
One way to simulate it would be using closures: struct BasicLetterHandler&lt;C: FnMut(ch: char), V: FnMut(ch: char)&gt; { pub consonant: C, pub vowel: V, } impl&lt;C: FnMut(ch: char), V: FnMut(ch: char)&gt; LetterHandler for BasicLetterHandler&lt;C, V&gt; { fn consonant(&amp;mut self, ch: char) { (self.consonant)(ch); } fn vowel(&amp;mut self, ch: char) { (self.vowel)(ch); } } Then you can do this: scan("hello world", &amp;mut BasicLetterHandler { consonant: |ch| handle.write(format!("consonant {}\n", ch).as_bytes()).unwrap(), vowel: handle.write(format!("vowel {}\n", ch).as_bytes()).unwrap(), }); Note that you'll have to handle sharing the handle somehow.
Thanks! I am happy to help and to talk about fuzzing. I hope you will enjoy the next few posts too :\-\) For the copyright licenses, I am not updating the year, so it is just from when the file was originally created.
You can use closures and a generic implementor for your trait. struct FnLetterHandler&lt;FC: FnMut(char) -&gt; (), FV: FnMut(char) -&gt; ()&gt; { fn_c: FC, fn_v: FV, } impl&lt;FC: FnMut(char) -&gt; (), FV: FnMut(char) -&gt; ()&gt; FnLetterHandler&lt;FC, FV&gt; { fn new(fn_c: FC, fn_v: FV) -&gt; Self { FnLetterHandler { fn_c, fn_v } } } impl&lt;FC: FnMut(char) -&gt; (), FV: FnMut(char) -&gt; ()&gt; LetterHandler for FnLetterHandler&lt;FC, FV&gt; { fn consonant(&amp;mut self, ch: char) { (self.fn_c)(ch) } fn vowel(&amp;mut self, ch: char) { (self.fn_v)(ch) } } [Link to the playground](https://play.rust-lang.org/?gist=8d701a37fa5d81583949b663aa9b48e6&amp;version=stable&amp;mode=debug)
Unfortunately, that "somehow" is what this problem is fundamentally about!
oh so rust is only for the smart ppl no??? 
It is in the book under Advanced Traits: https://doc.rust-lang.org/book/second-edition/ch19-03-advanced-traits.html#using-supertraits-to-require-one-traits-functionality-within-another-trait
After reading everything carefully and trying to implement it myself I still can't understand what `Error::description` should return. Someone duplicate the Display output. Someone return a single line. In `csv` you are reexporting an underling descriptions. If all my errors are belong to one type, lets say XML parsing, no io error and stuff - can I simply return "an XML error" as a description? I don't really understand what is the difference between `Display` and `Error::description`.
`description` isn't worth fretting about, because AFAIK, nobody uses it. The original intent of `description` was to cheaply return a short message describing the error, and it therefore returns a `&amp;str`. Because of that, you can't use `format!` to dynamically construct a new string, so your options are limited. On nightly, [the `description` method is soft-deprecated](https://doc.rust-lang.org/nightly/std/error/trait.Error.html#method.description).
I feel like an organization model for a number of crates could work better. I think one of the issues is that the effort to put together a group of people for each of these fairly small and stable crates could wind up being a lot of overhead for a relatively little amount of actual work. It also makes evaluating trust in the group a bit harder, since you have to re-evaluate for each crate, while if there's an over-arching group, you can get more familiar with how that group works and their policies. But, I do think it can be worth trying out both models.
https://en.wikipedia.org/wiki/Entity%E2%80%93component%E2%80%93system Looks like that is a way to use composition over inheritance, that is a pattern that match with Rust
**Entity–component–system** Entity–component–system (ECS) is an architectural pattern that is mostly used in game development. An ECS follows the Composition over inheritance principle that allows greater flexibility in defining entities where every object in a game's scene is an entity (e.g. enemies, bullets, vehicles, etc.). Every Entity consists of one or more components which add additional behavior or functionality. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Also, you can simplify your `Clone` into simply returning `*self`.
You can just use closures, share that buffer and use `RefCell` to get mutable reference.
use PyO3 https://github.com/PyO3/pyo3
Silly me! There it is in plain sight. Thanks very much!
If sharing is the problem, why not pass the buffer as explicit argument to the closures? https://play.rust-lang.org/?gist=6889beb4e14fb265b03297f54b158567&amp;version=stable&amp;mode=debug
are the cortex M4's specialised with NEON SIMD or something, does rust support that, does LLVM (and rust) support the C66x DSPs?
You can use `vec![0; size]`. Also, you shouldn't need to turn the `Vec` into a boxed slice.
I'd hope the loop would be optimised out, but for tidier code, you can do this: let tmp_vec = vec![0; size]; You might find some tricks for uninitialised memory in, say, the RawVec code.
Thank you, that's far more attractive than what I was doing!
Some of the tools are needed by the test suite. Many of them are very handy when debugging what the compiler does.
I don't know how the loop would be optimized away, given that `size` is a variable in the grand scheme of things. At the moment where I'm using this, size is only a few dozen bytes so it's not a problem, but I can see some cases in the future where it would be much larger. Maybe preallocating a buffer is the best bet for perfomance? 
I find this work extremely enticing and makes me want to try it myself sooner than later! Even though I am absolutely new to embedded/tiny systems, I know that thanks to Rust even I can do it! Which board would you recommend for use with bobbin, and for use with Rust in general?
Unless someone \(or multiple people\) volunteer as co\-maintainer\(s\) and actually spend time dealing with open PRs and issues I don’t know if opening an issue with the WG is gonna achieve much.
Use the code above for now. Easy to change later IFF it is identified as a performance bottleneck. Don’t do premature optimisation. 
I'll take you up on the offer when I'm more prepared to do so, haha. Ah that's what I expected. Quite a long spanning project. What made you choose to undertake this in the first place? Usually it's some existing solution that fell short for some reason.
`Vec::with_capacity(size).as_mut_ptr()`?
I don't see any comments in the linked code file. Have you pushed your latest changes?
updated, forgot the push! 
The closest thing to a "standard board" in the Rust embedded community is the [STM32F3 Discovery](http://www.st.com/en/evaluation-tools/stm32f3discovery.html). It's not the most modern device, but well supported and a good starting point.
I believe as long as the union is marked with `#[repr(C)]`, and all values the first type could have are valid instances of the second type, it's sound. I... think this is unsound if we don't have `#[repr(C)]`, since the layout is then undefined? Getting most of my information from https://github.com/rust-lang/rfcs/blob/master/text/1444-union.md#unions-and-undefined-behavior. --- [`mem::transmute`](https://doc.rust-lang.org/std/mem/fn.transmute.html) would be preferable if we could use it in a constant expression, since it definitely allows transmuting types like this. When we have constant functions, I guess this will be the right solution?
Note that `stdsimd` `u32x4::new` and `u32x4::splat` which are both `const fn`
&gt; This is particularly an issue for driver authors. There is no way for a driver author to write a crate that directly targets a peripheral which is common across many MCUs sold by a vendor. Instead, the author must either publish a driver crate for each individual MCU crate (potentially dozens) or publish a single crate that uses Cargo features to import the correct MCU crate at compile time. In either case, the author must re-test any time any of the MCU crates change because there is no way to know whether the change affects the specific peripheral being used. I thought that the plan of the Embedded WG, and the direction pioneered by /u/japaric, was to use traits. That is, while each specific device gets a special-purpose crate, this crates exposes its functionality via traits so that most of the code can be developed against the traits.
Fuzzing is great. Curious - can you set up sanitizers with cargo-fuzz?
Don't forget to put the vec in a temp variable first. Otherwise you may trigger undefined behavior!
Great to see 2 things: 1. You do not avoid the discussions 2. You point the right thing directly. Unfortunately, I am not sure that the whole community could trust the leads developer the same way in a small and big community. All big github projects are, at least partially, maintained by a strong team belonging to a private-company/foundation with clear goal. I hope Mozilla will help you focusing on the main goal even if part of the community distrust your work and either fork your rust source with a counter productive effect. The positive effect is that, IMHO, the community is now big enough, diverse enough, that communication takes time to go from center to bordures, letting time to critics aside from the core devs chats. It is no more a small united family; it is a society. This looks like the price of success.
Ah yes, my bad. https://play.rust-lang.org/?gist=926c9de53137bdeb837c3b77bb86de41&amp;version=stable&amp;mode=debug
Looks like unrolling those two loops to just declare the arrays inline saves ~90 assembly intrusctions https://play.rust-lang.org/?gist=146e7e450b71a6e3f84deafd9989c64e&amp;version=beta&amp;mode=release
"Isn't helpful" is relative. Usually the errors that have me scratching my head are lifetime issues and sometimes the sheer quantity of data is overwhelming ("You said this here, but look at this and this and *that*. So, from this we can conclude this other thing. Finally, you are a penguin"). They are no worse than plenty of C++ error messages I've seen (pro-tip: you didn't make the iterator const. That's probably what it is), which I admit isn't the highest bar.
If the type is `Clone` `Vec::resize` is less unsafe
Correct - the traits are the contract between the driver implementer and the driver user. Those are great. The issue I'm bringing up is the task faced by the driver implementer. A vendor may have dozens of MCU variants, which may be implemented by dozens of MCU crates. Right now, someone that wants to implement a driver for a peripheral that is common among most or all of those variants (the watchdog peripheral, for instance) must implement that driver for every single one of those MCU crates. Alternatively they create their own register definitions for the peripheral and include that in their crate, but there is no compile-time way to know if that driver is actually compatible with the MCU they are targeting. With the approach that I'm using, shared peripherals are broken out into a separate crates which are then re-exported by the MCU crate. The driver author writes a driver (i.e. newtype wrapper) against the peripheral type from the shared crate, and the driver user passes the peripheral type from the MCU crate they are using to the driver constructor. Since Rust uses nominal typing, it checks that the peripheral type being passed by the user is actually the same as the one that the driver expects. The MCU crate author is the one that is responsible for identifying that the peripheral is compatible. 
Thanks! It's an interesting bug.
I'm looking to create a way for Rust users to better document their libraries and applications using external sites \(AKA, not generated docs but a website like [hyper.rs](https://hyper.rs) or [rocket.rs](https://rocket.rs)\). If you could fill out this survey \(should take no more than 5 minutes\) it would help me gauge what viewers and maintainers see as important features. \[[https://goo.gl/forms/WILT2vM82rcxHHsi2](https://goo.gl/forms/WILT2vM82rcxHHsi2)\]\([https://goo.gl/forms/WILT2vM82rcxHHsi2](https://goo.gl/forms/WILT2vM82rcxHHsi2)\) I will post a followup on the data I receive sometime later :slight\_smile: If you have any concerns about the survey or want to express ideas not covered in the survey, please respond below or on the \[Rust users forum\]\([https://users.rust\-lang.org/t/help\-fill\-in\-this\-survey\-to\-hopefully\-make\-external\-rust\-documentation\-websites\-better/17693](https://users.rust-lang.org/t/help-fill-in-this-survey-to-hopefully-make-external-rust-documentation-websites-better/17693)\)!
Hmm... I like this blog post, but I feel like the issue over `impl trait` in argument position is less about lack of trust, and more about a feeling that people who thought they were keeping track of discussions turned out not be because two features (impl trait in return position and impl trait in arg position) were stablised as part of one RFC (even though there was previous discussion about seperating out impl trait into separate RFCs). I think this is a communication issue, not a trust one. For me the biggest takeaway would be that it should be easy to see at a glance which features have been approved, and are due to be included in the next stable release. There used to be an internals post maintained by brson that tracked features upcoming in realeases. Something like https://www.chromestatus.com would be ideal (note that it includes features in development and their status)
I definitely think that's an aspect (and the simple answer is: this is what tracking issues are for -- subscribing to one should keep you fully updated). However, it's not the whole story. The threads surrounding the RFC dipped into conspiracy theory, talking about "shadowy" moves and suggesting that the feature was "slipped in" purposefully. So there's definitely a vein of mistrust at play too.
This is why we need those sweet, sweet MIR optimization passes :) 
Good to see `rust` community leaders are listening and taking actions !!
I haven't been following the recent discussions, so I don't really have opinions on that, but I do know what I think about the Rust process and the people that run it. It is rare to see people trying so hard to be open, judicious and fair. I have overwhelmingly seen great judgement, and, though things don't always go right the first time, you have an uncanny ability to get there in the end. I cannot be the only one who thinks a bit of trust is deserved at this point.
It could be optimized to a simple `calloc` (i.e. in rust `rust_alloc_zeroed`). In fact that's exactly what's happening with the macro. The implementation of `vec![N; size]` is specialized for `N` being of type `{integer}` and having the value `0`, then it boils down to a call of `Alloc::alloc_zeroed`.
You can declare a struct inside the scope of the method, like so: pub fn scan_to_buffer() { struct Internal { buffer: String, } impl LetterHandler for Internal { fn consonant(&amp;mut self, ch: char) { self.buffer.push_str(&amp;format!("consonant {}\n", ch)); } fn vowel(&amp;mut self, ch: char) { self.buffer.push_str(&amp;format!("vowel {}\n", ch)); } } let mut internal = Internal(String::new()); scan("hello world", &amp;mut internal); println!("{}", internal.0); }
It's the same as `self.0` but using a destructure rather than an ugly tuple access operator
What's controversial about emoji? 
I usually watch RFCs and their tracking issues I'm interested in. The problem is that some of them can get very noisy. And sometimes I don't have the time to read them, other times I'm not willing to read through hundreds of comments just to catch up. Thus when an RFC / stabilization issue goes into FCP should be more visible. That is the point where everyone that has interest in the feature but may not have had the time to keep up should come back! There should be a summary of what exactly was decided on (because that can change quite a lot during discussion) and which concerns have already been discussed to end (with which result). Pinning TWIR for 3 days is definitely a right step into that direction. But I think that FCP should still become better, because that is the point everything boils down to.
IIRC the usual downsides of them is that they aren't often useful feedback, and can also cause dogpiling of negative reactions.
This calls `as_mut_ptr()` on a 0-length slice – is this safe? The address is fine, obviously, but is there not at least technically a problem here with the fact that it's handing out uninitialized memory?
I’ve been using and watching the project closely (without participating much) since roughly version 0.6. I think one of the things the project/community struggles with is integrating new high-volume contributors - people who just show up one day and suddenly seem to be everywhere, but haven’t necessarily earned their stripes with the community yet. The problem tends to solve itself over time - they either ultimately earn the trust to be in as many conversations as they want, flame out and disappear, or work into their niche - but there’s often a somewhat painful transition period where Official Rust People are (in my opinion, of course) too accommodating of the sheer volume of ‘contribution’ before it’s clear it’s actually contributing, while conversely parts of the Rust community are too hostile and engage in the typical stupid hierarchy pissing matches that plague a lot of projects. Not to put too fine a point on it, but I think that’s at least part of what’s going on with a couple of these issues.
&gt; It is rare to see people trying so hard to be open, judicious and fair Especially aturon excels at this. Kudos to him. He devoted a lot of time to listen to my feedback on the modules RFC back in 2017, and believe me I had a ton of feedback.
I am in Salt Lake County, and YES! We need a Rust meetup here!
I think so too! I think Aaron communicates very articulate, open and precise. The RFC process is not only highly visible in the repository but also in the newsletter. Therefore I am honestly puzzled about any rising mistrust. Decisions have to be made and it is clear that not anybody can be satisfied. But the last thing that comes to my mind is that these decisions are made in a form of misuse of power... It makes me sad, really...
&gt; were stablised as part of one RFC For the record, there *were* two RFCs. This one which talks about impl trait in argument position: https://github.com/rust-lang/rfcs/pull/1951 Conservative impl trait is this RFC: https://github.com/rust-lang/rfcs/pull/1522 Now, I'm not saying there wasn't a communication issue, and that some higher level tracker wouldn't be useful, but it doesn't seem like it was some sort of issue with a given proposal not being clear.
This isn't constructive or even funny.
Didn't have time to make it funny because I don't have as much time to devote to the Rust community as the pros who execute this strategy, sorry. As for constructive: maybe not, but the first step to real change is for people to see the problem. Right now a lot of community leaders are in denial about the related application of this strategy in recent months, so the community was the next stop. If it's upsetting, good; people **should** be upset that a few individuals are subverting community prices like this for their own benefit.
If the process has led to results that violate our expectations as users or developers of Rust, we should adjust the process instead of blaming each other. We've made mistakes before and adjusted the process to make them less likely. All your post is doing is blaming and projecting bad faith onto others' intentions. I don't know why you think that would be helpful.
I understand your frustration, but please be civil. You do raise valid points, yet you chose a style of writing which will ultimately lead to it being written off as trolling/butthurt, hurting the broader discussion around these issues as well.
And it sounds like you're gating community participation on effective, elite writing styles. Should I not be allowed to have an opinion or try to help the community because I'm not the best writer or the most effective consensus builder? Do I need an English degree from a top 10 school to be okay in your book or will top 30 do?
To achieve the level of sarcasm and hyperbole in this post requires a level of writing competency much higher than is required to be polite. The criticism is definitely not related to incompetence, but intentional malice.
In C you'd use `isatty`. See also this: https://www.reddit.com/r/rust/comments/2pfkp0/isatty_in_rust_how_to_find_a_command_line_program/
Hi, I wrote the book "Beginning Rust" and I think it is the easiest available introduction to Rust programming. Though, I don't recommend it to you, for two reasons. First, Rust is best used as a systems programming language, i.e. a language to build software for other programmers, not for end users. If you want to build a production-ready AI library, then use Rust, but it would be a huge task. Instead, if you just want to explore AI algorithms, or to build application software based on AI libraries, probably Rust is not the best language for those cases. Second, even my book assumes a prior knowledge of a systems programming language, like C or C++.
You'd typically use isatty() as implemented by the isatty crate: https://crates.io/crates/isatty 
Its about decency and being able to reach consent and acknowledge own shortcomings. Which discussion would you think will be more fruitful? a) "I merged thing X" "&lt;Arguments why that was bad&gt;" "Hmm, ... maybe merging x wasn't good, we shouldn't do it that way" b) (Hyperbole) "I merged x" "Hey you ignorant dumb fuck, i hate you for merging X" "..." The thing is that you elevate this onto personal attacks instead of staying on topic. This is extremly hostile and has potential to burn out everyone involved. Maybe take a step back, try to articulate the precise point that makes you angry. Identify the weakpoints in the process which allowed that, talk about it. This will not only help you deal with the frustration, but also allow others to join the conversation and improve it together. The only thing you did is show that you're not capable of controlling your emotions.
You can imitate `self` by giving it an explicit field in the struct: struct BasicLetterHandler&lt;T, C: FnMut(T, ch: char), V: FnMut(T, ch: char)&gt; { pub this: T, pub consonant: C, pub vowel: V, } impl&lt;C: FnMut(ch: char), V: FnMut(ch: char)&gt; LetterHandler for BasicLetterHandler&lt;C, V&gt; { fn consonant(&amp;mut self, ch: char) { (self.consonant)(this, ch); } fn vowel(&amp;mut self, ch: char) { (self.vowel)(this, ch); } } Then you can do something like: scan("hello world", &amp;mut BasicLetterHandler { this: handle, consonant: |this,ch| this.write(format!("consonant {}\n", ch).as_bytes()).unwrap(), vowel: |this,ch| this.write(format!("vowel {}\n", ch).as_bytes()).unwrap(), });
Maybe that strategy is the one that people *you* identify with would have used, but telling me I need to "acknowledge my own shortcomings" that I don't act/look exactly like you and yours is pretty toxic. People from different cultures and backgrounds express themselves differently and it's not a bad thing if someone doesn't do things the way you do. It sounds like *you* have some pretty serious unconscious bias issues you need to work through. If, however, you're just pointing out that this community is overwhelmingly from a certain background and they don't respond well to differences - then the point is well taken, I can see that now.
That seems nice, and closest to what I am searching for. Is there also a way I can pass my corpus to a function in rff, it shows the matching ui and returns the selected item from my corpus again? I'd like to decouple the object from the string that is presented to the user as a selection option.
 being able to reach consent and acknowledge own shortcomings This wasn't meant to target you specifically, more in general. Don't get me wrong, its good to express your emotions in discussions because its really easy to offend people without intention. But you shouldn't let them overwhelm you/ allow you to get off-topic.
Pretty sure bstrie isn't a new contributor...
It might not be -- but it might be, because /u/nnethercote has recently been doing a bunch of optimization work in rustc. So I was just curious if/how this was question was related to that.
Perhaps what people actually mean is that both features were \[stabilized at the same time\]\([https://github.com/rust\-lang/rust/pull/49255/commits](https://github.com/rust-lang/rust/pull/49255/commits)\) by the same rust\-lang/rust PR.
Agreed. Rust is lucky to have such leadership. Rapidly growing the organization, the community, and the language at the same time is tough.
Rust is one of the best maintained and managed open source projects I have ever seen (and closed source for that matter). I'm not sure I could give any higher praise to a development team, given the unique difficulties faced by open source. I really hope those who work to maintain Rust aren't fooled into thinking otherwise by the recent "outrage" described in the article.
As for the “shadowy” part, I won’t talk in place of others, but I really think it means that people didn’t see / weren’t able to follow correctly. This is not negative, just factual. I used the word “shadowy” on reddit and I just wanted you to know that I – and I say I, I don’t speak for others – used it as a picture for “something running almost invisible while I wanted to see”. When I read the comment of yours I’m repyling too, I immediately looked up for “shadowy” on wordreference, like “Wait, did I just misuse that word?!”. :) As for the conspiracy “slipped in”, I’m strongly against this kind of idea and I really don’t support them. As others said, I think the whole thing here to work on, as a big community / team / family, is to communicate more effectively. No trust was harmed.
You're right, it won't do anything on its own. But it could be helpful to look at why previous efforts haven't stuck if you'd really like to see more maintenance for `url`. At the end of the day we have to accept it as-is, where its maintainer doesn't have a lot of time for it. Maybe communicating that on the repo would give some context for people looking to open new issues and pull requests.
Subscribing to RFC and/or tracking issue will keep one updated on that issue, but there does not seem to be widely known simple way of getting a list of them and their states. For RFCs it is relatively easy—once you think of it—as they have their own repository. But for the implementations the number of labels is overwhelming and from quick look I couldn't find a combination of labels or milestones that would actually give me the features cooking on beta.
Why do you want to do this? Everywhere I've seen, it's considered bad practice in the C and C++ communities unless you have overwhelming evidence that one branch is going to be taken like 99.9% of the time. To answer your question, it isn't possible on stable Rust. Rust will never stabilize LLVM intrinsics unless the core team changes their philosophy *significantly.*
I found your blog soon after [writing a test program](https://github.com/ciofeca/wayback) using the Client Toolkit. Nice, but requires quite a lot of boilerplate. I tried to cross\-compile it to SailfishOS 2.1.4 but got a bunch of link errors about missing *wl\_proxy\_wrapper\_destroy, wl\_proxy\_marshal\_array\_constructor\_versioned* and* wl\_proxy\_get\_version*; does this mean its libwayland versions are too old? \(client 0.3, egl 1.0, cursor 0.0\).
I might be wrong, but I thought it implements it’s own HAL and device/mcu crate topology?
I mean, I only looked [here](https://github.com/bobbin-rs/bobbin-sdk/blob/master/board/frdm-k64f/Cargo.toml) really. But it is Japaric's HAL. I'd be very happy if this project just leverages LISP to generate as much code as possible given generic definitions of hardware and some constraints. That would _really_ jumpstart a lot of projects.
Ah, I apologise, I am completely wrong. In that case I’m very excited about this project :)
Just playing devil's advocate here -- you should try to answer this to get more people involved: Who are you, what are you actually doing (more precise than "project websites"), and why should I spend my time on this survey?
The detail of your opinion was interesting to hear, but ultimately this post seems intended to antagonize members of the community you perceive to apply this process. That's definitely not constructive. I think that analyses of collaborative styles, especially where friction is involved, are important because they help us to more intelligently collaborate; they're **not** helpful when they don't actually build bridges between members of the community. I actually think that caricatures of the situations like the communication breakdowns the community had in certain RFCs can actually be healthy ways to discuss them. In my mind, one thing that would need to be fixed here, for example, is that the sarcasm in the OP is directed at a **single** set of individuals with a single specific collaborative style -- perhaps a *collection* of sarcastic caricatures could help us all laugh at ourselves? :) Once it's no longer too soon to write comedic observations, that is...
IME it's better just to integrate PGO into your build process so you get the equivalent everywhere automatically. That's much more likely to be stabilized, if it's not already possible.
Could you please guide me on the costs of running py-functions from rust? How does it work on multi-threaded setup when rust uses multiple threads? 
FWIW - and that's not much, I realize, if people walk away with the wrong message to begin with - I have no individual in mind. Note that exactly zero people are named here. =) Seriously, I'm confused as to how people correctly identify this post as not actually being what it purports to be - a guide to attack the community - but still take the "it's intentional" part of that seriously. Ah, well; occasional miscommunication is all part of a diverse community.
A simple example where you do know that is around error handling. Some errors are either extremely unlikely, and it is very common to not care about latency at all for erroring paths. There are exceptions^lol, but there is also a large number of cases that aren't.
I'd expect 60-40 is a pretty poor fit for `likely`/`unlikely`, since it can encourage more branchy behaviour than otherwise.
...but, if you decide to, be aware that PyO3 requires nightly Rust. [rust-cpython](https://github.com/dgrunwald/rust-cpython) is the project it forked from which supports stable Rust.
Good reason.
I cannot tell if you are trolling or not...
&gt; Plus a lot of people disagree with the general anti-optimization sentiment that seems to be pretty common. It's not anti-optimization sentiment. It's anti-blindly-messing-with-things sentiment. Compilers are really effective at optimization these days. Too many people feel like they're doing good things to their code by providing branch likeliness hints without realizing that they're actually hurting the performance of their code. If they actually are measuring things and they've found that this branch hint has a material effect, I would usually expect to see that mentioned.
Every once in a while I find myself wanting some sort of "nested enum" kind of deal, where I want a type that can be any of a list of variants, but some variants naturally group another list of variants. Usually none of the variants has any extra data, just separate names for separate values. In essence, I want to do something like enum BigEnum { VariantA, VariantB, VariantsC { VariantCSubA, VariantCSubB, VariantCSubC } } The only thing that really comes to mind is to make `VariantsC` a tuple variant \(is that the correct term?\) wrapping around a value of a separate type, which I'm guessing might make sense to call `VariantsC` \(I'm not entirely sure if this is a naming conflict or if it's fine since one is a type and the other a variant name\), which in turn is an enum enum BigEnum { VariantA, VariantB, VariantsC(VariantsC), } enum VariantsC { VariantCSubA, VariantCSubB, VariantCSubC, } but it feels somewhat off, and I can't place my finger on it to have to separately define a new enum type when its only purpose is to be wrapped in an identically named variant of another enum. This isn't really a problem, since it's easily solvable by "working around it", for example with the "separate type for further variants" solution I wrote, it's just that this in particular is nagging at me and I kind of want to ask if anyone has stumbled upon this and found out a nice way to go around it. \(Or if it is really a non\-issue and I'm just being too particular about how I write my code\)
I only got time to look at this now. I'm (still - judging by the comments here) getting a GoDaddy domain parking page.
It was related to rustc. Allocations are reasonably expensive and avoiding them can help. As a rule of thumb, I have found that reducing the number of allocations done by rustc by 10% might speed it up by 1--2%. (Though the effect is shrinking as the number of allocations is going down.) The particular case was in the `ena` crate where there was a function that was frequently allocating `Vec`s. In the common case it would push and then pop a single element and nothing more. So this type would avoid the allocation in that common case. Preliminary measurements weren't very encouraging, though, so I stopped working on it for now.
I don't want this to turn into a prolonged argument, so I'll keep it brief. I think the skill of compilers is hugely overstated and most of the concerns I hear are from people who aren't actually informed about what compilers are and aren't good at. A lot of this comes from my own experience, and how I used to say these same things until I actually got engaged and interested in the subject. Yes, it is possible to be wrong and hurt yourself, but the solution is to learn how things work, not throw the tools out.
&gt; The problem is that some of them can get very noisy. The noise is usually either: * Off-topic, and thus should be moved somewhere else (e.g. arguing about decisions that have already been made). Unfortunately, we don't see mods doing this often. * Discussions and bike-shedding about unresolved questions or design details. That's considered on-topic ATM. But maybe that should change. Maybe tracking issues should only be used for **tracking** progress in implementations **and decisions**.
Pear 0.0.17 was released a week or two ago for this reason
That list is [on rfcbot's little-known website](http://rusty-dash.com/). 
The whole goal is to get uninitialized memory though, which isn't what `Vec::resize` does.
Part of the goal is to get *uninitialized* memory though, which isn't what `Vec::resize` does.
/u/Holy_City I wanted to make sure you saw this (parent comment), since you only replied to an answer that incorrectly states it is impossible.
No, you can't specify non-elided lifetimes (actually you simply cannot specify any lifetimes at call site).
You know, I realized while reading this, that it's not really clear what you're supposed to do during the final comment period. Are you supposed to only comment if you disagree with the proposed action?
Perhaps the rfcbot could post a short notice on the corresponding RFC whenever a tracking issue entered the final period. Would that be too much spam?
[lol](https://www.dropbox.com/s/jy9jzo1k6btne54/Screen%20Shot%202018-05-25%20at%2022.45.40.png?dl=0). What a way to treat your community.
I think that this is a passive aggressive post. I don't necessarily disagree with the technical aspect, but these people weren't acting out of malice and they dont deserve to be mocked. Our community should continue to be one of excellence and technical conversation, not one of passive aggressive or mocking posts. We can debate things without our feelings getting involved. That is my two cents. You post is out of place on here and will give people the wrong idea. Please try to keep these discussions to a reflective and technical perspective so we can appreciate it.
The goal of final comment period is go give people a chance to raise new arguments or concerns that might not have been considered prior to the decision to enter FCP. If no new arguments emerge, the team's decision to merge the RFC stands. If there are new arguments (ones the team didn't consider as part of their original decision to enter FCP), then the FCP is cancelled and must be reconsidered in light of new information.
https://github.com/SergioBenitez/Pear/issues/7 Github is typically a better place to get information than reddit.
Sure, apologies for not providing this up front. I'm primarily a \[UI/UX designer\]\([https://alexloz.com](https://alexloz.com)\) active in the Rust community. I'm about to create a project website for the crate \[vst\]\([https://github.com/rust\-dsp/rust\-vst](https://github.com/rust-dsp/rust-vst)\) and I wanted some feedback before starting work. Additionally, I am thinking of creating a generic theme for \[gutenberg\]\([https://github.com/Keats/gutenberg](https://github.com/Keats/gutenberg)\) \(a static site generator\) that anyone can use \(MIT licensed and open\-source\) easily to build their own external documentation website. I wanted to find the pros and cons of current solutions so I could make something better. As far as personal info, location is useful when dealing with internationalization. My hypothesis is that European countries would have a greater need for internationalization, and I wanted to test that hypothesis. I also wanted to take gender into account to make sure I could compensate for a majority male audience. However, I made sure to keep both of those options optional to respect privacy. If you have any additional questions I'd be happy to answer them. As far as disclaimers go, this is a side project I'm doing for fun, I plan to release any project as free and open source, and I am not backed by any company.
What's the problem here? Your screenshot and the word "lol" don't really explain anything. I'm probably not familiar with the thread in question (again, I can't tell from the screenshot), but in general if I'm trying to read through comments on a long GitHub issue to catch up with the conversation, I actually appreciate off-topic comments being collapsed by default. If I want to read all the side discussions, _then_ I can very easily click to expand. 
Neither std::intrinsics nor specifically `likely` are truly LLVM intrinsics: they'd be better described as Rust intrinsics some of which `rustc` implements as LLVM intrinsics but they mostly should be independent of it, and these do get stabilised... just not in that module (E.g. `std::mem::transmute` is a re-export of an intrinsic). Of course, you're correct that this isn't currently possible in stable, but the reason for why isn't.
Do you know of documentation or a blog article that expands on this?
That second RFC added it in argument position while also settling other unresolved questions and putting both return position and argument position on a path to stabilization. So it wasn't really orthogonal. 
People leave a reaction and assume they've expressed their opinion, but others don't interpret them that way because there's no explanation of the reasoning behind the reaction, RFCs aren't popularity contests, etc. Also, you don't see when the reactions were added, so they can continue accumulating after a decision has been made. 
The single-threaded format just isn't a good venue for RFC discussion. A bikeshed can drown out everything else. 
You're looking for /r/playrust
For what it's worth, I think there would be value in determining how many people there are that actually contribute to these "incidents". I worry there are a few squeaky wheels who are receiving too much grease in these discussions.
The Python runtime still has its GIL (Global Interpreter Lock) and the handle for it is part of the callable object it gives you. If one Rust thread is running Python code, any other Rust thread that tries to run Python code will block until the first one returns.
A list of all unstable features, usually with tracking issue links, can be found in the unstable book: [https://doc.rust\-lang.org/unstable\-book/](https://doc.rust-lang.org/unstable-book/)
Having a strcat deja vu here.
One thing that _is_ stable is `#[cold]`. Any branch that would lead to a cold function is [considered unlikely](http://llvm.org/docs/LangRef.html#function-attributes), so you could consider splitting the unusual path into a separate function.
I've been unable to make this work. If any passersby have, please let me know!
Sorry for the late announcement, we didn't know if the venue could provide enough bandwidth.
I find it nice to automatically have bindgen make the c-&gt;rust bindings and then make an Idiomatic rust layer from the generated bindings by hand
links for external players \[webm sd\]\([https://cdn.c3voc.de/s3\_native\_sd.webm](https://cdn.c3voc.de/s3_native_sd.webm)\) \[webm hd\]\([https://cdn.c3voc.de/s3\_native\_hd.webm](https://cdn.c3voc.de/s3_native_hd.webm)\) \[hls sd\]\([https://cdn.c3voc.de/hls/s3\_native\_sd.m3u8](https://cdn.c3voc.de/hls/s3_native_sd.m3u8)\) \[hls hd\]\([https://cdn.c3voc.de/hls/s3\_native\_hd.m3u8](https://cdn.c3voc.de/hls/s3_native_hd.m3u8)\)
This is an interesting project you have here! I myself have been thinking about this sort of approach \(asking for next action to do every time\), but for a totally different goal: scriptable wayland clients/servers for automated testing \(of smithay crates, but others also, why not\). Though I never got around to actually do it... Regarding boilerplate, it is indeed still pretty early. My approach to this toolkit is to avoid as much as possible to be too opinionated in the wrong directions. Thus, for now I've mostly written low\-level, minimalist, abstractions, but it is absolutely in my scope to add high\-level ones afterwards, built on top of the low\-level ones. I strive toward a kind of lego\-like approach, where the simple way would be what most people need/want, but not hide the low\-level stuff for users that want to access them. On this note, if you have any feedback, suggestion, or want to contribute to the Client Toolkit, please don't hesitate to open issues on the repository to discuss about it! :\) Regarding your link errors, yes, the client toolkit is built on top of wayland\-client, which requires version \&gt;= 1.12 of the wayland system libs. This version was released in september 2016, so I was hoping this would not be too old, and I really need these symbols to make the safe wrapper that wayland\-client is. The soname is still `libwayland-client.so.0.3` though, so I can't tell just from this which version of the libs you have. I don't know much about sailfishos, but if it is possible for you to update the libs, it would be I believe the best solution.
It takes a pretty impressive lack of self-awareness to complain about toxic behavior in a thread like this. This thread is a passive-aggressive, unsubstantiated, cheap shot. It's not always a bad thing if people don't do the things the way we want them to, but in the specific case of this thread, it very definitely is a bad thing.
The book is something like 520 pages; it's totally reasonable to miss something!
I was very excited to learn about Autumn organization focused on Rust in AI. Unfortunately, it seems it's been pretty much abandoned. Here is a link to an article from one of the founders of that organization: [https://medium.com/@mjhirn/tensorflow\-wins\-89b78b29aafb](https://medium.com/@mjhirn/tensorflow-wins-89b78b29aafb)
I was recently pondering if something like this (and by extention strings) could speed up lookup within an Vec&lt;(UVec, Value)&gt; where UVec is a key. 
I've read that using unions of simd types can prevent the compiler from fully optimising, but I've not experimented with that so I've no first hand experience. Also I noticed you are using blend which is only available in sse4.1 not sse2.
Yeah, sorry, this is pretty much a passive\-aggressive troll\-y post. There's some constructive criticism to be made in this area, and we'd welcome that, but this is not the form to do it. Thanks.
I agree completely with this. While I am not concerned that this will happen given the great leadership of Rust, any response should be careful not to overcorrect for a few very vocal individuals while many don’t perceive a problem. I think Aaron in the article mentioned something along the lines of needing to make sure people coming into the community are aware of the mutual respect that we all expect of one another, along with civil discourse. I recently had a term explained to me that might be on point here: “disagree and commit”. This is a concept of lodging the disagreement with something, but recognizing that you happen to be in the minority and are trusting the broader team is making a good and fair decision. By trusting in this, you can then commit to helping move forward.
The RFC issues are currently a kinda wastelandy place with lots of random feature requests and also some tracking by the team. If we move things there we should probably also clean it up and restrict what issues get posted. \(I'd filed an RFC for making the RFC issues exclusively for team scratch space use, e.g. for tracking multi\-step RFC chains, or for tracking general features that there's clear consensus on us wanting. But we decided against that and instead just updated the readme to discourage filing feature requests as issues\)
If there are more than ten (I think), it only shows some names, the rest are hidden.
There’s pros and cons. Conceptually, they belong on the compiler repo, as the RFC aspect of the feature is complete.
«No trust was harmed.» This might be what you think but I believe the core team had suffered from a pretty rough week \- as highlighted in this blog post \-, maybe because of the extent of the rust community \(price of success, as other suggested ?\). It is hard for everyone to stay civic as the size of the group involves grows. So congrats to the core team for staying civic despite the consequences, and keep up the good work ! However, for the "shadowy part", I should say the github isn't very ergonomic in the regard of following \(without being spammed of messages, that is without starring PRs\) RFCs progress. Maybe a website highlighting all RFCs and their progress would alleviate thoses issues \- as was suggesting somewhere on/r/rust \- ?
One thing to consider is if it is time to consciously slow down a bit. From the sidelines it still feels like we are moving quite fast and carrying some of the momentum from the rush to 1.0 (which I'd point out was controversial in itself). Realize that Rust right now is pretty damn good language already and focus on polishing rather than new features. Not saying that we should drop feature development forever, but right now I feel like the community needs to work out more what we can do with the toys we already have, establish patterns and libraries, and recognize then the pain points that arise from those. That would also mean more time to understand what Rust is about and what is actually "rustic". just my 2¢ from the peanut gallery. 
This year’s focus is about slowing down, generally. The majority of features shipping this year are the “last mile”, that is, for example, the impl Trait stuff has been in the works for years. The roadmap for this year is “finish things we’ve started.” They all have motivations coming from pain points.
Woo! I can use the RLS again without it crashing constantly!
It already does on the tracking issue. Unfortunately we don’t have great formal metadata to associate tracking issues to RFCs. Maybe it’s worth doing? But really, IMO if you’re subscribed to a RFC PR thread, when it’s merged and a link to the tracking issue is posted you should subscribe to that as well.
Aaron, I enjoy reading your blog posts, but I can’t for the life of me understand why you, as the leader of the Rust project, post about official Rust business on your personal blog and not the official Rust blog. I’m not saying everything you post on your personal blog should be posted on the official Rust blog but, this post and the series to follow would possibly better target the larger audience if it were posted in the official “zone”. I haven’t had time to follow the impl trait furore, but I’m willing to bet that a lot of people follow the main blog only, which is why there is shock when they only hear about released features as they occur with no word in between. The know there is TWiR, but that’s a lot like the release notes: just links to long conversations that don’t get to the crux of the matter fast enough for most. I think making better use of the existing official communication channels would be a good start. “Rust’s leadership needs to do a better job broadcasting about the people and process side of the project.”
Thanks for the livestream. I have a frivolous question. What's is the font type in the rust code slides now? It is beautiful.
Really impressed with the quality/stability of the stream! Wish I was there in person, but this is the next best thing :\)
If you mean these (https://hsivonen.fi/rustfest2018/), it's "Fira Sans", a font Mozilla had created by Eden Spiekermann for Firefox OS. https://github.com/mozilla/Fira It's a really nice font, coming in all kinds. I use the mono version for coding.
[1.26.1 release notes](https://github.com/rust-lang/rust/blob/stable/RELEASES.md)
More than that, open, judicious and fair rust core team is good and all, but there are not a lot of people who are vocal on any matter, and ones who are, well, what is their motivation? You can't have open processes like that, without involving all interested people. It always gets one sided. And then ones who are disagreeing in any way will be ignored. Not like it never happened before, ay?
Thanks for posting! I had a ticket but wasn't able to make the trip, so it's nice to be able to listen in from home.
Ehh... the paper that added language support for this to C++ actually shows hard data about when these are profitable and they are even if a branch is not taken 99.99% of the time.
&gt; Everywhere I've seen, it's considered bad practice in the C and C++ communities unless you have overwhelming evidence that one branch is going to be taken like 99.9% of the time. I don't like the name `__builtin_expect` nor do I like `likely`/`unlikely`, precisely because they seem to hint that this is about likeliness, when this is but ONE motivation. `__builtin_expect` is not about priming the branch predictor, it's about optimizing for a specific case. The goal is for the optimizer: - to be more aggressive with inlining/optimization on some paths, while being less aggressive on others: a bloat/speed trade-off. - to be more attentive to keeping one execution path's code blocks close together, while pushing other code blocks out of the way. If used based on **likelihood** it can indeed increase **throughput**. However, another usage is to identify **latency-sensitive paths**, and optimize for those. A prime example is busy-waiting on queue with infrequent events: most polling attempts return that there's no event, but you want to optimize for the case when there IS an event.
Yes this it it! Thanks!
PGO can help with throughput *if* you have representative training sets, but is much more harder to use to improve latency. It would optimize a busy-waiting loop for the "no-event" case as it's the more frequent, even though what you really want is optimizing for the "event-present" case.
&gt;I've read that using unions of simd types can prevent the compiler from fully optimising, but I've not experimented with that so I've no first hand experience Any idea where you read it so I can investigate? &gt;Also I noticed you are using blend which is only available in sse4.1 not sse2. Yeah I could figure out what string to use for target feature, found it last night. floor is only in 4.1 as well. 
&gt; I've read that using unions of simd types can prevent the compiler from fully optimising Where did you read this?
Allocate a vector. vec![0; size] But hey, won't this waste time assigning `0` to each value of a vector? Yes. But first of all, `memset` should be really fast, and second it's better than having issues like Heartbleed if somehow C library wouldn't fill in the vector correctly.
The Rust blog speaks for the team, and is generally focused outward, that is, for users of Rust, more than for developers of Rust. So, Aaron can post anything he likes to his personal blog, and doesn’t need to get a sign off from the rest of us, whereas the official blog is different. Also, while Aaron is obviously an important part of Rust, I think characterizing him as “the leader of the Rust project” is inaccurate. We don’t have singular leaders like that. That being said, a development blog of some kind is a great idea, IMHO.
It feels like threaded discussion would really help, I'm not sure there's a way to do that unfortunately. 
No reason why someone couldn't whip up a quick react app to track feature progress, maybe hand the reigns over to the rust team?
You posted to stack overflow AFTER the question was answered here?
As I read this, I can't help but feel a parallel to the political world. I have to grapple with this issue on a monthly basis as an elected member of my Registered Neighborhood Organization with Denver. Residents have differing opinions about how things should be voted on, but in the end, I get to vote. I can't choose a yes &amp; a no and make the entire community happy. I have to choose one. I have to do that by weighing the discussion and points brought up leading up to the vote. As a board, we have been struggling hard with trying to make the board's process feel transparent and not corrupt and self-interested. We haven't figured out a good way to do it. There are entire classes of people in our neighborhood that refuse to participate because of the board's skin color or other demographic identities. As a decision maker, you feel you let down some subset of constituents. And as a constituent of a failing idea, you feel unheard. It really sucks and can feel polarizing. And frankly, at times can be completely and utterly demoralizing. But, ideological discussion is a very messy process. And if you want good things, you have to participate in the messy &amp; contentious arena.
I was going to write something whiny about how I'm having difficulty getting what I specifically want to display from `csv::Error` and `failure` didn't really help but then I saw this https://github.com/rust-lang-nursery/failure/issues/189 and actually I saw Armin here at RustFest so I might just beg him to explain. In the meantime, I'll just say I've been back and forth over a bunch of ugly implementations where all I really want is `error DOING_X in FILENAME:LINENO - CAUSE_STR` Right now I find dealing with diverse errors coming from lots of places and getting the specific formatting I want to be super unintuitive so if there's something obvious that can be done with `csv::Error` it would be awesome to have in the docs :)
If you actually want to go the heterogeneous list route, I recommend [hlist](https://crates.io/crates/hlist) which covers a lot of the boilerplate. Otherwise, either an enum or boxed trait objects are the preferred solution. The enum approach is best if the set of implementors is closed (you control the trait and all types implementing it), or provide a variant containing `Box&lt;Trait&gt;` as a catch-all. `[Box&lt;Trait&gt;; n]` is probably easier to work with (and wouldn't require much boilerplate) but you're leaving performance on the table if you call trait object methods in hot loops due to the dynamic dispatch overhead.
CSV errors should already include line numbers in them. If you want precise control, you'll probably want to write your own error type that reformats csv's `Error` type to your liking.
Uninitialized memory is dangerous, proceed with caution.
You still can't do this. Destructuring of type that implements `Drop` is prohibited.
Sorry I assumed he was the leader. A development blog would be a great idea, given how many working groups you have now. Especially if people like yourself, Aaron, Niko, &amp; Nick don’t need sign off to communicate with the “internals” community. My concern was/is that the correct audience isn’t being addressed through an official channel. A development blog would help. :-) 
Sure, if you’re diligent enough, you CAN find it out, but that’s not exactly the point. The cost benefit ratio is really out of control here.
Sorry to be blunt, but the claim that reactions are anonymous, and PCJ hordes could be influencing them, is flat-out wrong. That's a fact. And there is no need to dance around it.
I didn’t say they were anonymous. PCJ or anyone else can still use them though. 
I'm running Rust on an AM5728. If you _really_ want to use Rust on the M4s, you're best bet is to duplicate the v-ring and RPMSG structures in Rust. That said, I personally would go down this road, even though I have experience with porting Rust to Cortex-Ms. I'd just resign myself to c. Between VirtIO/remoteproc/rpmsg, there's just too many un[der]documented pieces.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rust_gamedev] [Yet another minesweeper in Rust • r\/rust](https://www.reddit.com/r/rust_gamedev/comments/8mar78/yet_another_minesweeper_in_rust_rrust/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Read the parent of this sub-thread.
In general, the original post in the tracking issue is updated, though of course that depends on people involved remembering to do so. Another thing to look for, which happens automatically so doesn't require someone to remember to do so, is any pull requests or other issues referencing the tracking issue. In this case, it's only a couple of weeks ago that this tracking issue was filed, and it doesn't look like much has happened other than some bikeshedding on the exact `await` syntax. One thing to recall is that while some people are paid to work on this full time, others are just volunteers working in their free time, so you can't necessarily expect results immediately. In general, the teams try to keep all of the significant discussion in the issues. They do post [notes for their meetings online](https://paper.dropbox.com/doc/Lang-Team-Agenda-bbhfd7hrR26fDoz8Hsb2v), but generally try to just make decisions on things already discussed in the ticket, or if there's something new to discuss, they try to take it back to the ticket. There is definitely room for better collection of a summary of the status of various features, but that's another thing that would take some time and effort to curate.
Yes, the OP made a *technically* incorrect statement based on the difference between the API and the interface. Most people don’t use the API to read issues.
Thanks for the reply, I appreciate that many people are volunteering in the Rust community and didn't mean to come across as demanding progress!
I guess \`.collect\(\)\` is not a good option for just waiting for a stream to end since we will create a vector of values. I could do \`.fold\(0, |acc, \_| future::ok\(acc\)\)\`, is there something more eloquent? I want something like \`.last\(\)\` that would give a future with the last value once the stream ends.
I have worked with remoteproc, rpmsg and OpenAMP. Why do you want to reverse engineer the VirtIO v\-ring structures? The remoteproc subsystem does the job of loading ELF binary and rpmsg subsystem is suppose to expose it with an interface like tty or socket to user space. Do you want to run something with Rust on A15 cores or M4? I did not understand your end requirement.
Cool, I'm able to get the latest nightly this way, but its not clear to me if or how you can pin it to a specific version. Could you give an example?
Very cool! This is the first GUI application in rust I've tried and it looks nice! I filed a few minor issues on GitHub.
I know you're probably not willing to use Rust nightly, but with `#![feature(nll)]` the `v.len() == 2` case is *very* clean. Here's the code as it would be on Rust nightly + NLL: http://play.rust-lang.org/?gist=8f8eca4a0f19a04491b20dd4b95106d9&amp;version=nightly&amp;mode=release
&gt; My Qt is installed in my /home/me/Qt5.7.0 This is a non-standard path, maybe qmlrs allows setting an environment variable to point it to the right place? If possible, you can also try installing Qt5 using apt-get. By the way, do you know what the difference is between the forked repo you linked (https://github.com/flanfly/qmlrs/) and the original repo (https://github.com/cyndis/qmlrs)? They seem to have diverged quite a bit.
Maybe I'm nitpicking here, but couldn't the sending of values also be done by spawning a future, instead of spinning up a new thread? That would probably make it more idiomatic overall, because I feel like thread usage within a future defeats the purpose of using futures.
Actually never mind! I got a shell.nix working with a little trial and error: let moz_overlay = import (builtins.fetchTarball https://github.com/mozilla/nixpkgs-mozilla/archive/master.tar.gz); nixpkgs = import &lt;nixpkgs&gt; { overlays = [ moz_overlay ]; }; in with nixpkgs; stdenv.mkDerivation { name = "practica-env"; buildInputs = [ # nixpkgs.latest.rustChannels.nightly.rust (nixpkgs.rustChannelOf { date = "2018-04-11"; channel = "nightly"; }).rust pkgconfig openssl.dev nix ]; OPENSSL_DEV= openssl.dev; }
You simply need to override `date` using `rustChannelOf`: nightly = rustChannelOf { date = "2018-05-21"; channel = "nightly"; }; You can see a full example in [this comment](https://www.reddit.com/r/rust/comments/8l0luc/migrating_to_actix_web_from_rocket_for_stability/dzdsano/).
You're right! But the external c library I'm integrating against have internal threads. So in my actual code I wouldn't be spawning the thread myself, just get a callback in one. 
You're right! But the external c library I'm integrating against have internal threads. So in my actual code I wouldn't be spawning the thread myself, just get a callback in one.
Yes, scottmcm made an incorrect statement. But it wasn't based on the difference between the API and the interface. That was Steve's.
Yes maybe, I don't know how qmlrs is looking for qt place, I will try the apt\-get way. I have no idea, I was looking the both repo, wanted to link the original but I made a mistake !
This also fixes installing 1.26 on ARM for me.
I think the `v.len() == 2` bit in `pop` is counter-productive. Once the allocation has been made, it makes no sense to lose it and then possibly have to reallocate if the length needs to go back up. Once you're in `Many`, you should just stay there.
What's PCJ?
Rust's `Result` and `Option` types have some really nice combinators. The book has pa pretty good section](https://doc.rust-lang.org/book/first-edition/error-handling.html#composing-option-and-result) on this. For the above, I'd probably do something like `args.get(1).ok_or(MyErrorType::NoPath).and_then(|path| read_file(path)).and_then(|s| serde_json::from_str::&lt;Data&gt;(&amp;s)).and_then(|data| data.generate_random())`.
so, this doesn't require the types of the `Err` to be the same?
The nice thing is you'll end up with a `Result` regardless of what happens, and it'll either be `Ok(town)` or `Err(e)`, where `e` comes from one of the called functions (closures). You can then do something like `map` or `try!` (via `?`) or even `match` on the resulting value to do something with the error message. Using my earlier example, this would be something like the following. let res = args .get(1) .ok_or(MyErrorType::NoPath) // Converts from Option&lt;T&gt; to Result&lt;T, MyErrorType&gt; .and_then(|path| read_file(path)) // Runs if above is Ok(path: T) .and_then(|s| serde_json::from_str::&lt;Data&gt;(&amp;s)) // Runs if above is Ok(s: U) .and_then(|data| data.generate_random()) // Runs if above is Ok(data: V); Followed by one of the following. res.map(|town| do_something_with(town)).map_err(|err| eprintln!("{}", err); You could even add this to the end of the chain from above: let res = args .get(1) .ok_or(MyErrorType::NoPath) // Converts from Option&lt;T&gt; to Result&lt;T, MyErrorType&gt; .and_then(|path| read_file(path)) // Runs if above is Ok(path: T) .and_then(|s| serde_json::from_str::&lt;Data&gt;(&amp;s)) // Runs if above is Ok(s: U) .and_then(|data| data.generate_random()) .map(|town| do_something_with(town)) .map_err(|err| eprintln!("{}", err));
Check out the [failure crate](https://boats.gitlab.io/failure/). Combined with a separate `run` function you could change it to something like the following (untested): fn main() { if let Err(ref e) = run() { eprintln!("{}", err); ::std::process::exit(1); } } fn run() -&gt; Result&lt;(), failure::Error&gt; { let args: Vec&lt;String&gt; = env::args().collect(); if let Some(path) = args.get(1) { let result = read_file(path)?; let data = serde_json::from_str::&lt;Data&gt;(&amp;result)?; let town = data.generate_random()?; println!("{}", town); } else { println!("Error: Please supply a file path to a .json file"); } } 
Don't worry, I'm familiar with combinators from Haskell, yet for some reason they seem much more confusing to use in Rust, I'm not sure why... The fact that `and_then` can handle different kinds of error seems strange to me though, seeing as it all needs a common return type at the end
Yeah, you may need to toss in another `map_err` or return `impl Error` or something.
assigning the `and_then` chain to a result and matching on it, does indeed result in an error like I expected it would. I guess the suggestion of implementing `From` or using `Failure` would make things simpler
Note: Target was not killed, he was wearing roadsign.
I think you wanted to post this on /r/playrust? This subreddit isn't about the game Rust.
Strange, I still get: $ RUSTUP_DIST_SERVER=https://dev-static.rust-lang.org rustup update stable info: syncing channel updates for 'stable-arm-unknown-linux-gnueabihf' info: latest update on 2018-05-25, rust version 1.26.1 (827013a31 2018-05-25) error: component 'rust-docs' for 'arm-unknown-linux-gnueabihf' is unavailable for download
Of note here is that there's no longer any need to have a separate `run` function in most cases: [`main` can return a `Result` as of 1.26](https://blog.rust-lang.org/2018/05/10/Rust-1.26.html#main-can-return-a-result) (with some more cool stuff coming in that area soon).
Do you have the latest rustup version? `rustup self update`.
The error actually occurred on the serde side of things. I find it ironic that my hack job so far has been the simplest solution
Oh, that's weird. I did: ``` ✓ jbp@localhost ⎇ master= ~$ rm -rf ~/.rustup/ ✓ jbp@localhost ⎇ master= ~$ curl https://sh.rustup.rs -sSf | sh info: downloading installer Welcome to Rust! (etc.) info: syncing channel updates for 'stable-armv7-unknown-linux-gnueabihf' info: latest update on 2018-05-10, rust version 1.26.0 (a77568041 2018-05-07) error: component 'rust-docs' for 'armv7-unknown-linux-gnueabihf' is unavailable for download ✗ jbp@localhost ⎇ master= ~$ RUSTUP_DIST_SERVER=https://dev-static.rust-lang.org rustup update stable info: syncing channel updates for 'stable-armv7-unknown-linux-gnueabihf' info: latest update on 2018-05-25, rust version 1.26.1 (827013a31 2018-05-25) info: downloading component 'rustc' info: downloading component 'rust-std' info: downloading component 'cargo' info: installing component 'rustc' info: installing component 'rust-std' info: installing component 'cargo' stable-armv7-unknown-linux-gnueabihf installed - rustc 1.26.1 (827013a31 2018-05-25) ✓ jbp@localhost ⎇ master= ~$ rustup default stable info: using existing install for 'stable-armv7-unknown-linux-gnueabihf' info: default toolchain set to 'stable-armv7-unknown-linux-gnueabihf' stable-armv7-unknown-linux-gnueabihf unchanged - rustc 1.26.1 (827013a31 2018-05-25) ✓ jbp@localhost ⎇ master= ~$ rustc --version rustc 1.26.1 (827013a31 2018-05-25) ✓ jbp@localhost ⎇ master= ~$ cargo version cargo 1.26.0 (0e7c5a931 2018-04-06) ✓ jbp@localhost ⎇ master= ~$ rustup --version rustup 1.11.0 (e751ff9f8 2018-02-13) ```
Yes, at least I think so. $ rustup self update info: checking for self-updates $ rustup --version rustup 1.11.0 (e751ff9f8 2018-02-13) It's old-ish, but the newest I can find, even on github.
Please open an issue on GitHub then :)
It was mentioned in http://www.codersnotes.com/notes/maths-lib-2016/
There already is [this issue for rustup](https://github.com/rust-lang-nursery/rustup.rs/issues/1410) or would this be more appropriate for rust-lang itself to block the release of 1.26.1?
Happy to be of help, hope to see you at the next one!
FWIW, not sure if you're a native speaker, but to me, "shadowy", when used to refer to a group of people (or actions taken by a group of people), has a strongly negative connotation, implying that the people have something to hide. For example, here are two random news headlines using the word: "Wagner: The shadowy Russian mercenary firm behind an attack on U.S. troops in Syria"; "Russian Art Collector Tied to Shadowy Payments to Trump’s Lawyer". Somewhat linked to the word "shady".
Hi, This is a subreddit for Rust the programming language. You may be looking for r/playrust for the videogame.
[Workshops](https://paris.rustfest.eu/workshops/) are tomorrow, so no material can be downloaded yet.
As the code stands, I agree. However, if additional functions are added to `UVec` then things change. If there are two possible representations for a UVec of length 0 or 1 then I would have to be careful with the implementation of some other operations. For example, I would have to implement `PartialEq` and `Hash` myself, rather than using `derive`.
Maybe it's specific to using it as a vector3 which is going to be used in scalar code a lot. Might be compiler specific too.
I’m French, then I might have misused the word. I saw others using it but I didn’t ever imply “hiding things on purpose”. More like “hard to see” (as factual). However I’d use shady, yeah.
hmm yeah that might make sense. I only use the unions to fill in stuff when a SIMD instruction doesn't exist - like floor in sse2
Sure, that'll work fine. It's the easiest way too if you have a simple environment. You can also make separate crates, and have multiple crates in the same project root. /MyProject /shared /Cargo.toml /src/ /bin/ /Cargo.toml /src/ main.rs svx2.rs sse41.rs Now you can `use shared::function`. I like doing this when there is a bunch of dependencies I only need for `shared` and I just need black box functions around them. For example, I typically make an `auth` crate that handles all my password hashing and other crypto functions. Also useful for client/server/shared project structures.
Yes, you might wanna declare your own enum for all errors you can have and combine everything with map, and\_then and map\_err. Also check out Railway\-Oriented Programming talk \(assume Either == Result and and\_then == bind\)
Yes, you might wanna declare your own enum for all errors you can have and combine everything with map, and\_then and map\_err. Also check out Railway\-Oriented Programming talk \(assume Either == Result and and\_then == bind\)
I did do that actually, and the code wouldn't compile, saying that they weren't of the same type, even though I had implemented `From` for all the different types. Using `?` though, did work without a hitch
What you are doing is fine. I would personally just do `use shared::*;` if these are all at top level (under `lib.rs` and not `some_other_module.rs`. Only use another crate like /u/usernamedottxt suggests if shared is actually something that makes sense to have as another crate (i.e. stands on it's own as a library). Even then it's not necessary just a possibility.
tbf, Centril is shaping up to become Rust's own Xah Lee or Jon Harrop.
Devils advocate but I would generally prefer it if the generated documentation was more comprehensive so that an extra website wasn’t needed. The generated docs are already distributed with the library, they are tested with the library so you know the example code on there is up to date, and most importantly thanks to `cargo doc` they can be accessed offline. 
The post had the best timing. I lovey your response. :D
Amazing! I can’t wait for the first high powered wasm physics engine in Rust.
I wanted to solve it in my Ogg and lewton crates. In both crates, I have a low level API that assumes neither blocking or async IO. On top of that I build not one but two high level APIs, one for blocking, once for async IO. This is incredibly complex and annoying and I don't think I'd do it again somewhere else but it pays off: I can expose `futures` and `tokio-io` dependencies as optional so if you don't need async, there is no need for additional deps. 
I have all the files in one directory, but when I do `use shared::*;` I get unresolved import errors. 
Despite claims to the contrary, I am not omnipresent. If you see irrelevant brigading originating from PCJ, report the post and I'll look. Though I make no guarantees about what I will or won't do.
You can just call `wait` on a Future just to block the current thread and wait for it to complete, essentially transforming async piece of code into sync.
FWIW this is kind of news to me (not sure where/how I got the opposite impression; possibly 'just' from the fact that Aaron also submitted the roadmap RFC(s), wrote many important blog posts, etc.); thanks for the clarification.
In [this RFC thread](https://github.com/rust-lang/rfcs/pull/2441#issuecomment-391476522), there was something of an argument over whether it's appropriate to stabilize a feature that has a lot of downvotes attached to it.
You might be interested in Niko's [old proposal](http://smallcultfollowing.com/babysteps/blog/2015/08/20/virtual-structs-part-3-bringing-enums-and-structs-together/) (NB: link goes to the end of a series) for doing this by promoting enum variants to be types in their own right. 
My implementation of similar idea for [slab](https://crates.io/crates/slab): [slab_typesafe](https://crates.io/crates/slab_typesafe). Helps you avoid confusion with those `usize`s while allowing easy opt out with `.into()` and `From::from`.
The OP shows code that prints the Display impl of an error. Using `?-in-main` will print the Debug by default. To satisfy the OP's desire, you need to add another type that provides the Display message in its Debug impl. IMO, just ignore `?-in-main` for CLI applications until that use case is made easier.
Yes! There's even [the start of an RFC](https://github.com/canndrew/rfcs/blob/effects/text/0000-effects.md). It's super-exciting stuff, but I wouldn't hold your breath; implementing this in Rust would be a _huge_ undertaking, so if it ever does happen, it won't be soon. For shorter-term practical applications, better to go with something like [what /u/tux_mark_5 suggested](https://www.reddit.com/r/rust/comments/8mdj5s/abstracting_over_asynchronicity/dzmsp7u/).
They seem to both be dead projects? The original repo has a issue from another qml rust crate author chiming in stating that: https://github.com/cyndis/qmlrs/issues/52 Though their repo seems to not be having much development/activity now either. I think the KDE maintained project for Qt/QML is what should be used for such projects these days? Although initial setup might be a bit more work?(I haven't got around to trying it yet) https://github.com/KDE/rust-qt-binding-generator u/taspai
Have you thought of using ChaCha20? It is a production — quality stream cipher, and SIMD implementations can reach 0.4 cycles per byte on x86.
Also, some people may need to compile with `oom=panic` because they need to survive OOM situations.
You could use a `#[repr(C)]` struct set up so that you could use unsafe pointer arithmetic. Not sure if that is well-defined though.
In the long term I think RFCs should move away from GitHub to some tool (custom built or not) that has facilities for each of your bullet points. 
Does `futures::ok(val).wait()` compile into a no-op?
Nphysic already support wasm. 
I guess the simplest way would be to keep track of everything that you’ve written onto the screen in an array, as well as the cursor position and then read from there.
My mother also crochets and I would love a pattern for this!
The problem with rust-qt-binding-generator is that it's designed on the assumption that you're comfortable with having pieces of your project in C++ and CMake. It's very much a solution written by and for people who are already developing Qt applications in C++. (So, since I have no faith in my ability to write memory-safe code in C++, I instead decided to press Python into being a "QML for the QWidget API" via rust-cpython and Qt's Python bindings.)
Of course. That requires reactor (at leas as a dependency) and I specifically wrote that it should allow polling without reactor. The goal would be if you for some reason don't want to use `tokio` or something similar, you can avoid it provided your return types support it. The advantage would be having a single interface, which needs to be implemented only once.
I did want to use `?`/`try!`, I just didn't want to do any unnecessary extra work for a small throwaway application, which is why my initial solution was to just create a macro that simply printed the error to `stderr`, which lead to this fairly simple looking solution: fn main() { let args: Vec&lt;String&gt; = env::args().collect(); if let Some(path) = args.get(1) { let result = try_print!{read_file(path)}; let data: Data = try_print!{serde_json::from_str(&amp;result)}; let town = data.generate_random().unwrap(); println!("{}", town); } else { println!("Error: Please supply a file path to a .json file"); } } Then I tried using combinators as suggested, but kept running into errors due to the fact that (you guessed it) the error types weren't the same across the board. I then looked into the combinators section in the Rust book, and made this: let args: Vec&lt;String&gt; = env::args().collect(); let _ = args.get(1).ok_or("Please supply an argument") .and_then(|path| read_file(path).map_err(|err| err.to_string()) .and_then(|file| serde_json::from_str::&lt;Data&gt;(&amp;file).map_err(|err| err.to_string()) .and_then(|data| data.generate_random().map_err(|err| err.to_string())) .map(|town| println!("{}", town)) .map_err(|err| eprintln!("{}", err)); But I wasn't happy being forced to `map_err` on every line, and especially not to a string, so I did the thing I didn't want to do initially: made a common error type that encompassed all the three types of errors the program would encounter. This however, still did not work with a bare `and_then` chain without being forced to do a `map_err`, but then I remembered that there is an error conversion in the definition of `try!`, which lead to my current implementation: fn run() -&gt; std::result::Result&lt;String, Errors&gt; { let args: Vec&lt;String&gt; = env::args().collect(); let path = args.get(1).ok_or(ParsingError::NoArguments)?; let file = read_file(path)?; let data = serde_json::from_str::&lt;Data&gt;(&amp;file)?; let result = data.generate_random()?; Ok(result) } It's simple and to the point, but now my code is 34 lines longer because I had to implement all the boilerplate to make this work. Though I guess, exercising good code practice even in throwaway code is better than just being sloppy, so I guess it was worth it?
Yeh, I don't think we should rule anything out. A single organization might work better for some small collection of niche or domain-specific cohesive libraries, like the [RustCrypto](https://github.com/RustCrypto) organization that u/newpavlov raised on the Working Group GitHub. The main thing I'm trying to avoid with a single organization is a process that totally depends on the existence of that one organization, because moving into an existing org might not always be viable. That's a valid point about effort. Right now it is a lot of work to set up an organization, CI, Gitter and various bots. From a people perspective, I don't actually think it's more work to set up a new organization than it is to move a library into a larger existing one. Having an existing team doesn't necessarily mean that ownership over a library is actually going to result in maintenance, so I think there's still effort either way in building up the kind of ownership that does.
I haven't read the article, but ring switches on x86 are expensive. They've gotten less expensive with x86_64. It introduced a "fast" syscall. Linux, for example, goes to the length of mapping a read-only copy of the raw clock value into each process. Then with some coordination between glibc and the kernel `gettimeofday` is able to avoid a ring transition. If I recall correctly, this is a huge win for programs like `make` that frequently need to know what time it is.
No, it usually spins up a single-threaded threaded executor in the background and puts the future on.
`wait` doesn't require `tokio` or any other dependency. It's part of the [Future trait itself](https://docs.rs/futures/0.1/futures/future/trait.Future.html#method.wait).
Ah, I see. It's hard to tell what you were trying to achieve in the original question; was this for quick throwaway code where you didn't want to think about the errors too much, or code where you wanted to be able to robustly handle errors. For quick throwaway code, there is of course the `.unrwap()` or `.expect("message")` quick way out. That's not terribly satisfying, as it shows up more like a crash than a proper error message, so if you're using it for something quick but that you expect someone else to use, it's not the nicest. If you want something quick and easy that will collect errors into a single type that can be printed out, you can use [`failure`](https://github.com/rust-lang-nursery/failure). This can be used either with or without your own custom error types. This will be a lot less boilerplate than what you'd have to implement to collect things into an enum and implement `From` yourself. For example, here's a quick sketch of your problem using `failure`; it doesn't add any boilerplate over importing failure and calling `err_msg` to produce an error from a string. extern crate failure; use std::env; use std::convert::AsRef; use std::fs::File; use std::path::Path; use std::io::{ self, Read, }; use failure::{ Error, err_msg, }; fn read_file&lt;P: AsRef&lt;Path&gt;&gt;(path: P) -&gt; Result&lt;String, io::Error&gt; { let mut string = String::new(); File::open(path)?.read_to_string(&amp;mut string)?; Ok(string) } fn run() -&gt; Result&lt;(), Error&gt; { let path = env::args() .nth(1) .ok_or_else(|| err_msg("Please supply a file path to a .json file"))?; let _contents = read_file(path); // ...etc... Ok(()) } fn main() { match run() { Err(x) =&gt; eprintln!("{}", x), _ =&gt; (), } }
The shortest possible answer is “system calls become function calls, so you lose all of that overhead.”
This is great, thanks for the hard work! 
Yeah I guess that makes sense. I'll check out `Failure` when I have the chance, thanks!
This is my suggested solution too, but you don't need `failure` for this - you can just have `run` return a `Result&lt;(), Box&lt;std::error::Error&gt;&gt;`.
Try [`ggez`](https://crates.io/crates/ggez/), which has a `SpriteBatch` that allows batching of render calls. Text rendering is still slow but next version will include `gfx_glyph`.
Hey! I was working on a simple cacher using an underlying vec, it's for quite a small amount of data, and could include floats as keys, so I chose not to go with a HashMap, and linear look up times does not seem to be a problem. All was going well until I got to get_or_insert, where I get some ownership issues, [the playground can be found here](http://play.rust-lang.org/?gist=84c22bfa82a046e8606c0bc83e17ecc4&amp;version=stable&amp;mode=debug). I would think that the immutable reference to self on line 15 to be gone by the time it determined the value was `None`. I also tried this with nll, still no luck! Could anyone let me know why this is a violation, or maybe hint towards a solution?
&gt; the birth and death of JavaScript i can not find that.
https://www.destroyallsoftware.com/talks/the-birth-and-death-of-javascript
?
I think I'd probably use `failure` at this point for CLI applications, but you can just use `Box&lt;Error&gt;` instead from the standard library if this is just a quick one-off. This is how I'd write it: use std::error::Error; use std::process; fn main() { if let Err(err) = try_main() { eprintln!("{}", err); process::exit(1); } } fn try_main() -&gt; Result&lt;(), Box&lt;Error&gt;&gt; { let args: Vec&lt;String&gt; = env::args().collect(); let path = match env::args().nth(1) { None =&gt; return Err("error: please give file path to json file".into()), Some(path) =&gt; path, }; let rawdata = read_file(path)?; let data = serde_json::from_str::&lt;Data&gt;(&amp;rawdata)?; let town = data.generate_random()?; println!("{}", town); } 
I don't like how people seem to be bashing Rust in the YouTube comments. We need to play the prophet, and tell them about what an enormous improvement it is regarding systems programming. 
I am working with the Rocket and diesel to build a web app. I noticed that I tend to need 3 or 4 structs of the same data for different purposes. I need one struct for inserting into the database, one slightly different one for querying, another to take form input, and yet another that converts text fields to a corresponding enum. For a "Users" table, here is what I mean: #[derive(Queryable)] struct QueryUser { id: i32, email: String, password_hash: String, role: String } #[derive(Insertable)] struct InsertUser&lt;'a&gt; { email: &amp;'a str, password_hash: &amp;'a str, role: &amp;'a str } #[derive(Serialize)] struct FormUser { email: String, password: String, role: String } struct User { id: i32, email: String, password_hash: String, role: Role //An enum } Any way I can reduce the number of similar structs here?
Out of curiosity, how does this compare to [nebulet](https://github.com/nebulet/nebulet)? As I understand it, the motivations for both these projects are similar.
Off topic, I've decided this guy must be a troll. Only a troll would make a video like [this benchmarking disaster](https://www.youtube.com/watch?v=wBYc_0Z56eM)
I clicked not knowing what to expect. I was *not* expecting that. Wow that is bad.
Thanks, that was a fun thing to watch!
Seems to be more or less the same idea, just that this is built on top of Linux, while nebulet has a microkernel.
Anyone can explain this function signature to me? Particularly the FnOnce word pub fn map&lt;U, F: FnOnce(T) -&gt; U&gt;(self, f: F) -&gt; Option&lt;U&gt; { match self { Some(x) =&gt; Some(f(x)), None =&gt; None, } }
Nebulet has significantly better performance and reinvents the ecosystem, instead of being built on top of a inherently flawed os.
So `FnOnce(T) -&gt; U` is the trait for all functions which can be called once with a `T` returning a `U`. It's also the super trait for `FnMut` and transitively `Fn`. So in that case, the use of `FnOnce` is just saying any function can be used there.
so for example if it was FnOnce(&amp;mut T) -&gt; U does that mean that x has to becoe a &amp;mut?
- `pub`: visible to code outside the current module, - `fn`: a function, - `map`: called `map`, - `&lt;` .. `&gt;`: defined - `U`: for all types `U`, and - `F:`: for all types `F` such that: - `FnOnce(T) -&gt; U`: `F` implements [this] trait. - `(` .. `)`: takes arguments: - `self`: the invocant (*a.k.a.* subject, instance), passed by value, and - `f: F`: a value of type `F`, passed by value, - `-&gt;`: returning - `Option&lt;U&gt;`: an optional `U`. `FnOnce` is one of the "callable" traits (also including `Fn` and `FnMut`): types implementing these traits can be called like functions. This includes functions and closures. `Fn*(A, B, C, ..) -&gt; Z` means a callable taking arguments `A, B, C, ..` and returning `Z`. `Fn`, `FnMut`, and `FnOnce` roughly correspond to the following signatures: - `fn call(&amp;self, ..) -&gt; ..` - `fn call_mut(&amp;mut self, ..) -&gt; ..` - `fn call_once(self, ..) -&gt; ..` So a `Fn` cannot mutate any captured state, a `FnMut` *can* mutate captured state, and a `FnOnce` can move captured values in exchange for only being called at most once. So it's a function that takes the invocant by value, along with a function or closure that it can (at most) call once.
&gt;Tuples are left out because they doesn’t seem to have a fixed memory layout (as in `#[repr(C)]`). Does that mean you're converting with `mem::transmute` behind the scenes?
I'm doing pointer casting, but it's essentially the same kind of trick. There are assertions in place to check that the numbers adds up, so it doesn't cause buffer overflow.
You mean, it's useless?
Cervus is a "subsystem" for Linux that runs WebAssembly, loaded into the kernel as an LKM. In this way we can benefit from the existing, amazing Linux kernel ecosystem, including a huge number of device &amp; filesystem drivers and highly optimized kernel constructs like schedulers. Initially, cervus will focus on user mode, since drivers introduce too much complexity related to low-level things like interrupts. Nebulet is built from bottom up with rust + wasm, and tries to make everything possible WebAssembly (if I understand correctly), from user mode programs to drivers. Therefore, It's possible to try many more new ideas and designs on nebulet, which weren't possible on traditional OSes and even Cervus. Going to write a blog post about the details in two weeks :)
Yes. Regular functions' `self` is effectively `()`. It contains no information, so functions implement all three. A closures' `self` is a bundle of the values that were captured from it's definition point. You can think of it as an anonymous struct. The kind of capture used for each value is guessed by the compiler; it uses ` &amp;_` if it can, `&amp;mut _` if that doesn't work, `_` (*i.e.* moved) if *that* doesn't work. You can override this by putting `move` before the `|..|`s, which causes all captures to be moved into the closure. That said, `Fn`/`FnMut`/`FnOnce` is *independent* of these capture choices; they only determine what the closure can *do* with these captures. So you can capture a value by move, and then only read it from a `Fn`, or capture a an immutable borrow and read it from a `FnOnce`.
Actually cervus is a "microkernel on top of linux"
Yeah, so the type T has to be the same in the `Option` and the `FnOnce`.
This is very very cool!
Hm. I'm not sure that copying 3 or 4 floats is really something you need to worry about.
&gt; instead of being built on top of a inherently flawed os. Careful here; this is treading in non-constructive comment territory. Criticism is welcome when formed thoughtfully; careless off-hand comments are "not constructive".
In C, if you only know the size at runtime, you would more likely use: ``` int *arr = malloc(sizeof(int) * size); ``` What you need here is `Vec::new` or the `vec!` macro for things like `vec![0; size]. Keep in mind that a `Vec` is *not* the direct representation of a memory region represented by a pointer. It adds two other concepts: its *size* and its *capacity*. Up to you to state whether you care or not about the two extra `usize`. If you do, there’s `unsafe` functions to allocate memory like you would do in C, but if you can avoid it, just avoid it. :D
It might make more sense to call Linux "potentially insecure". Even so, at some level you will have some native code points of attack in nebulet. Nebulet is also inherently flawed in the sense that it doesn't have drivers. Security is not the only kind of flaw.
I'm talking about larger scales like whole images, so it may be at the level of millions of bytes. Pointer casting will most likely be optimized to only check the size, while a copy loop is harder to avoid. It's good if you can cast the buffer from a whole photo, do changes in place and just output it to file again without copying to change the type.
I think I’ve seen this answered before, but have you considered collaborating with Redox on at least the microkernel? Might be nice to have a why not &lt;other os here&gt; section in your post. It’s all very exciting!
How could the reference be gone? You're explicitly holding onto it through `key`. 
It's still alive because you are returning the value. Consider this rephrasing of the function: let ret; match self.get(&amp;key) { Some(value) =&gt; { ret = value; } None =&gt; { ret = self.insert(key, f()); } } ret As far as I know the only way to fix it with safe code is by doing the lookup twice: if self.get(&amp;key).is_some() { self.get(&amp;key).unwrap() } else { self.insert(key, f()) } 
I generally agree with what he's saying, but his perspectives on Java and Python, taken together, suggest that he has a very Windows-centric view of programming. Sure, Java is run on Linux in the Enterprise, but his list seems to completely ignore how Unixy OSes see the three languages he listed. Rust's ecosystem is too immature, Java feels very ill-fitting and has a disproportionately small presence in *nix land outside of writing JEE web apps, NPM is about as ready as Crates.io for writing Linux things other than web apps or build automation, and we all know how annoying Electron and NW.js applications are to have in an otherwise native desktop. While he claims that Python only has the "one thing" of machine learning, on Linux and BSD, it has essentially become Perl 5's de facto successor and, to a lesser extent, a replacement for shell scripting, it has bindings for everything under the sun or even pure Python implementations (eg. Universal Feed Parser, Mutagen meta-tag reader/writer, etc.), and is the only language other than C++ with official support for writing the bits of a Qt application than QML can't yet.
There's just not much shared code between nebulet and redox. Nebulet's microkernel is so domain\-specific that sharing the kernel would be more work than just writing a new one.
Is wasm a requirement for that? Wouldn't rust with no unsafe code achieve the same thing? Purely functional languages should also work without flawlessly in ring 0, no? I have watched the talk and one thing that surprised me was that the VM eats 20&amp;#37; of performance by doing what ring 0 would do otherwise. If I understood it right, the ring 0 is basically read write protection. Well, if that is the case, we can easily create a type system, which won't compile, if you do some suspicious memory hackery. **And, if that's the case, you won't lose any performance at all!**
Many people have tried to do this many ways, for sure. Wasm isn’t required, it’s just an option.
How close does this bring us to being able to run [GIMP inside Chrome inside Firefox](https://www.destroyallsoftware.com/talks/the-birth-and-death-of-javascript)?
That is always a sort of dream of safety oriented languages: to be able to run untrusted code with no runtime memory checks, from the hardware or the software. Unfortunately, rustc is not (yet) an adequate sandbox for this, because it has known bugs that a malicious code author could exploit to achieve memory unsafety, even in safe code.
Great write-up! I am excited to see more in the future! This is nice because you often post interesting snips of Nebulet's implementation on the `blog_os` gitter but I don't want to waste your time asking a billion questions haha.
Ask away :\)
So, is cervus an exec format handler (in the binfmt-misc sense)?
I was thinking about posing this same question to the Rust community after seeing that article. I saw mention elsewhere that data which is meant to be an invariant will have to be checked or confirmed in some manner when deserializing. So some data might need some sort of digital signature and checksums to confirm that the things that shouldn't change, have not changed. You can imagine some invariant that get's set differently with respect to it's surrounding data.
No, the real risk with Java is that objects could be created arbitrarily with serialization and deserialization. This means if you can inject a crafted serialized object into the program's input, you could create any object and anything in that object's constructor or destructor or whatever would run. It just wasn't safe, it was a bad idea to have or use publicly such a flexible method to serialize and deserialize objects. With Rust and Serde, you have a much more strict, defined deserialization process. If you have a struct with a few fields and you want to deserialize that from JSON, that's all that's going to be deserialized. Arbitrary objects cannot be created in the same way. It's not vulnerable to the class of vulnerabilities discussed in the article above.
First, i'm not really all that knowledgeable in that topic, but i'm a java programmer myself. As far as I can tell (and as [this blogpost](https://www.darkreading.com/informationweek-home/why-the-java-deserialization-bug-is-a-big-deal/d/d-id/1323237) for example tells), the problems arise when accepting foreign input, in this case serialized classes. The problem is here, as far as I can understand, that an attacker could inject malign code that may be executed since the whole class, including methods, may be serialized. Foreign code execution is bad for obvious reasons, and one should never accept code from untrusted input. The problem here is that methods are serialized and deserialized by default, even when only wanting to transfer for example data within the objects. This is more akin to an sql injection attack, where an attacker adds code to an input that is not expected to be code. If used correctly, this can be a powerful tool, but by default that poses great security risks and most of the use cases would only call for a way simpler attribute serialization. In rust I have not heard of a library that is able to serialize objects including functions, and if so, this would have to be done explicitly instead of implicitly. Even the java team seems to want to include a serialization/deserialization functionality that is more akin to the way serde does things; by writing the state of the Object to json or xml instead of serializing using a byte stream.
Java serialization was bad because there was a lot of ways to cause code execution. I gave some of the exploits a cursory look, but it looks like they are using functions in the object to rebuild the correct object. Python Pickling had the same issue, where you can pretty much re-write an object be accessing its underlying dictionary that made it a python object. Python and Java looked at something that was sent to it as an object with the attitude "Can I put this input into this memory? Okay, it's there". Rust only moves *data* since the object is defined at compilation time. Serde looks at something off the wire and says "Is this an integer? No? Error."
What are some use-cases for needing such a complex color library?
I prefer this answer. It requires you manually declare what is being captured by your "closure" but there will be few surprises with borrowing and in the simplest case you can use a zero sized struct making, giving you the ability to group callback functions.
Apparently he is falling in love with Rust: [https://www.youtube.com/watch?v=fkv\-CzIcu1E](https://www.youtube.com/watch?v=fkv-CzIcu1E)
DoS isn't a security risk, and since Serde is derived on structs, I'm not sure how someone could do a recursive DoS attack against Serde, but I'm happy to learn more about that.
I think Cacao is the biggest step we still need
someone remind me, what is able to target webassembly? Obviously JS \(because that's the original point, correct?\) But how do I get C/Rust/Python/etc to target wasm? My guess would be LLVM can target wasm \(for C/Rust/...\) and therefore the cpython interpreter can be built to wasm, so therefore python is runnable? But then how do you get syscalls?
Actually JS *doesn't* compile to wasm. The goal is to allow languages like C/C++/Rust to compile into it and run in wasm VMs. You can have syscalls perfectly well if you provide functions for that into the VM on construction.
Different parts may be useful for different uses. There's of course the color science use case, but other than that it could for example be useful for image manipulation, GUI color themes, computer vision, 3D rendering or just covering from one format to another. I'm sure there are things I haven't even heard about. The idea is to make it flexible but approachable enough to be used in both simple and advanced applications. The thing is that colors become pretty advanced as soon as you start looking deeper than just sRGB. First there is the common unawareness if linear vs. non-linear RGB, then there are the multiple kinds of RGB (some people prefer AdobeRGB for photo manipulation, for example), and then we have the CIE colors that are a bit special, but really useful because they are closer to how colors actually look. Add things like blending, transparency, different storage formats (8bit, 16bit, float, etc.) and it will end up being quite complex just by adding pretty common features. I guess the use of the type system makes it seem even more complex, but it's either that or a pantheon of arbirary RGB types. Now it's possible to make one's own type if something is missing in the library, and put it behind a type alias. Complexity is basically the price for flexibility.
`wait` is gone in futures 0.2 though. You have to use `executors::block_on(future)` and `executors::block_on_stream(stream)` which IMO isn't quite as convenient. Not sure what the motivation for that change was.
O(*n*) allocations based on input isn't really much of an extra DoS risk, though, since you would have had to read in O(*n*) amount of data in most serializaiton formats to achieve that, and you would have already had to do that O(*n*) work to allocate and read into the buffer. In general, there's a DoS risk to worry about if the attacker can use *n* input to trigger substantially greater than O(*n*) amount of work; for instance, using hash collisions to turn what should be O(*n*) to insert *n* items into a hash table into something that is O(*n*^2).
&gt;There is a Copy trait that tells you whether a type can be passed by reference or not. That's not what it does though. It tells you if a type has copy semantics instead of move semantics.
Probably should have mentioned I'm not the author. Found it via dev.to.
Amazon loses about $1000/second that it is offline. Obviously an extreme example, but extortion via DoS is a real thing. 
Because Java is a dynamic language the "end goal" for deserialization attacks is often to get a byte array of the attacker's choice loaded by a ClassLoader, since it's the most powerful result (cross platform arbitrary code execution). There's no obvious analogue in a compiled language like Rust. But if you look at the attacks themselves, there is a lot more to say about this. Java serialization is designed in such a way that it is could not be better designed as a fun puzzle for hackers. You try to craft an object graph that gives you a new tool to work with (say, invoking toString on an arbitrary object) and then look for toString methods that do something interesting and so on. Let's look at why this is so, and compare it to Rust. * In Java, a serialized stream can contain instances of *any* class that implements the Serializable or Externalizable interface. In Rust there is no general way to find a type with a certain name at runtime. * You can't control deserialization (originally, fixing this is in fact how they tried to patch it), you just have to see if the object tree you get out of it seems legitimate. With Serde, you specify what you are deserializing. * There are *tons* of classes that implement Serializable or Externalizable, especially if you use some notorious "enterprisey" libraries that have dynamic code generation or expression trees. In Rust, merely using extra libraries does not expand the types available to deserialization. * Deserialization can immediately cause code to run, either directly via readObject or readExternal methods on classes, or indirectly via code that is run in destructors or code called indirectly via one of these means. I think in Serde you can sort of do this, but the separation between the serialization format and the type definitions strongly discourages this. * Because internally Java performs type erasure on Generics, it's often possible to stuff wildly different objects inside containers than the application was expecting. With Serde you have to be a lot more explicit about types. * Because serialization restores private object state, it's possible to put objects into a state that violates internal invariants. In principle this could happen in Rust, but there is less focus on object orientation and serialization tends to be done on "pure data" types without special invariants. * Because the serialization format allows aliasing, it's possible to create object graphs where two things unexpectedly point to the same object. I don't think Serde currently supports aliasing, and in any case most serialization formats don't 
Very interesting read, thanks.
&gt; Wouldn't rust with no unsafe code achieve the same thing? Tock OS has chosen this approach for their [capsules](https://www.tockos.org/documentation/design/), but they also have proper processes.
That doesn't really matter, the inconvenience is that without const generics you can't automatically map `[u32; 5]` to `[u32; 6]`. Also, for `[u32; 0]` you want `SmallVec` to be zero-sized, but specialization is hard to use in a way that allows this.
Are you looking for something like this? That is, only tracking the time that it takes to poll a future? ``` struct DurationWrapper&lt;F&gt; { duration: Duration, future: F, } impl&lt;F&gt; DurationWrapper&lt;F&gt; where F: Future, { pub fn new(future: F) -&gt; Self { DurationWrapper { duration: Duration::from_secs(0), future, } } } impl&lt;F&gt; Future for DurationWrapper&lt;F&gt; where F: Future, { type Item = F::Item; type Error = F::Error; fn poll(&amp;mut self) -&gt; Poll&lt;Self::Item, Self::Error&gt; { let now = Instant::now(); let poll_result = self.future.poll(); self.duration += now.elapsed(); poll_result } } ```
Under "security risk" I understand that the attacker can get my personal data, credit card number, etc. While in everything you mention the only thing the attacker can do is bring the service down. Sure, that's annoying, but it is not a security risk.
Security is traditionally defined to include "availability". Without it, any system can be trivially made "secure" by turning it off. Further, consider availability in the context of, say, industrial control systems. Crashing a controller for a dam could literally kill people.
&gt; The point of wasm and the VM is to enforce that you can't do memory unsafety at runtime, not compile time. Well, isn't it the same? If you forbid dll injections.
Denial of service attacks are absolutely security issues. https://en.wikipedia.org/wiki/Denial-of-service_attack The ramifications include 1. Loss of revenue due to non functioning service 2. Financial liability from failing to meet a contractual SLA 3. Extortion 4. Significant time and money spent to block or otherwise remediate the DOS Security issues cannot be constrained to just the undesirable egress of private information.
We should have a continuous fuzzer for serde-json considering that's the most likely library to be under attack.
LOL, I thought that Java is a badly designed language but at least secure. Turns out it's not secure either. :D
Sorry first time
It's not just serde-json you want to fuzz alone, though that would be good too. But any project which uses it should also have a fuzzer running to find any bugs in how it handles the deserialized data, and any constructor functions it might call during deserialization. One of the nice things about serde is that for many uses, you can just deserialize straight into structs, or fairly well tested types like `Vec`, without calling into arbitrary constructors, which does help reduce the attack surface. However, you can map field to particular constructors, or you might do some complex processing of the deserialized data, so it is always good to get coverage of your specific use of serde-json in addition to general purpose fuzzing of serde-json itself.
/r/playrust
One caveat is you don't want to `#[derive(Deserialize)]` on a type that maintains invariants in its fields so that it can use `unsafe` in its methods. If you do so you might lose memory safety
If each struct has similar data but very different methods defined for them, then trying to make one or two unified structs will make all of those methods more complicated. I can't think of any way to improve on that except macros can cut down on very similar code in your codebase.
&gt; I need to know the difference between int, long, uin8_t, size_t even if all I want is a goddamn integer. Is knowing and having full control over what you want and how much resource you are going to take and what the limit of your integer is supposed to be a bad thing? Do you not know what exactly you want? &gt; I have to duplicate the signatures of the methods and functions in the header and the source files Technically you don't. However editing header files will force them to re-compile. C++'s compile speed is bad as it is. Also, C++ requires forward declarations. These are genuine complaints against C++. &gt;I never know if a compiler warning or error indicates a bug or not Same for many other languages. Compiler warnings are a general pre-cursor to bugs. &gt;There’s still a lot of bugs the compiler does not catch (race conditions, dangling pointers ….) Use a static analyser &gt;Refactoring is hard: when you change a function signature, you have to fix the code everywhere before you can even run some tests. Good point. I hope C++20 modules TS will help. &gt;Plus, gtest sucks. Good point &gt;Python Rocks No it doesn't. Also, Comparing Python with C++ is comparing apples with oranges. &gt;I don’t have to think about types if I don’t want to. If I really need it, I can write an abstract base class, but most of the time duck-typing “just works”. Not giving proper types deprives you from state of the art performance tuning and runtime type safety. &gt;If I misspell a variable or function name, or if I forgot to import a module, I’ll get a test failure immediately. How is C++ different? Sure, it doesn't have built in testing but if a testing framework fails you, should you blame this on C++ itself? &gt; Rust &gt; Specifying types is easy: all you need to annotate are function parameters and return values, and everything else is inferred by the compiler. Nice but how is C++ different? C++11 even offers implicit return types! &gt;Error messages and warnings almost always indicate a bug or an inefficient way of doing things. I find Rust's errors to be restrictive at times. The borrow checker is too strict in many cases unless you want to wrap everything inside an `unsafe` block. Rust prevents things that are perfectly okay and considered safe in other languages, for example, C++. Hence you will find hard time in implementing (for the sake of argument) basic, normal and completely safe data structures like doubly linked lists without performance overhead. I do agree that Rust makes playing with types easier with its trait based generics. It's better than C++s `std::enable_if` and tag-dispatching any time of the day. I also think it's more elegant than the concept TS. It's also the reason why Rust has better error messages in comparison to the cascading stream of endless garbage clang or GCC provides (especially with STL errors). 
A lot of things you've responded to are things the author calls out as opinions they now consider to be incorrect.
Hyper is good if you want to control many aspects of your http client/server and write a lot of potential boilerplate to do reasonably simple things. It's also good if you want to write a higher level library on top of something already implementing async HTTP operations. Rocket, Gotham, etc. seem to be better if you're writing a more typical web server application and want to get to writing the actual server code rather than handling things at the lower level.
If I really wanted to understand what is happening at a lower level would Hyper work?
CIA - Confidentiality, Integrity, *Availability*
This sort of small-size optimization basically trades allocations for branchiness. You save the allocation but your code is more branchy, possibly making mispredictions more common. This might be why the results are not as convincing, but I'm only guessing. Good thing you're measuring this!
&gt;If I misspell a variable or function name, or if I forgot to import a module, I’ll get a test failure immediately. How is this a reason why "python rocks" and "C++ sucks"? If the exact same thing happened in C++, you would get a compilation error, not a runtime error.
I'm noticing that the age of a language, and its purpose, dictates what a lot of people see as "good" and "bad". I've seen similar criticisms of Erlang lately (usually by Elixir users), and it's starting to border on insanity. (This isn't to say that when I was younger I didn't have similar views, I just tended not to air them publicly, and my private negative assertions about certain languages were often curbed by someone explaining it.) Typically people from a C or C++ background can appreciate certain things that interpreted language users (e.g. Ruby, PHP, Python, JavaScript, and Lua, users) can't (more often than not due to lack of exposure), but the reverse is true too; features, directions, and interpretations are exactly what they sound like (they are a subjectively adopted, commonly agreed upon (in their community), abstraction over the interface(s) to the machine(s)). Just because people like various feature sets, or their presence (or lack thereof) speeds up an environment's development time doesn't make them objectively anything; subjectively (which is to say "within the development scope") it makes them good or bad for the task, or, perhaps more correctly, helpful or unhelpful. The same is true of the functional/imperative divide, and OOP and non-OOP models. (And I suppose "event loop" and non-event loop models, though that's not a clear binary line for me, for so many reasons.) Horses for courses. Java is good at what it does, and is a good language for people to learn if they want to understand various design features in languages (or get into reversing byte code, I guess, but I'd honestly recommend Lua for that). It isn't my cup of tea, and I very rarely have nice things to say about it -- but it doesn't mean it's inherently badly designed or that the language isn't secure (or even that I'll say bad things about it). I just really don't enjoy writing it, reading it, or otherwise dealing with it. I feel that way about most virtual machines, and yet I hate constantly (re)writing platform abstraction code in most languages (and yes, I recognise the irony). That's just how I look at things, and that's a preference. That said, I'll hack together Go applications as stopgaps *because* of its portability, which in turn comes from what feels like a virtual machine (but isn't); Rust appeals to me for reasons similar to why I use Go and C++, though it's not even in the same ballpark for developing a lot of applications due to the increased depth of Go's stdlib, or the ecosystem in which I write C++ (I also consider most of the Go code I write to be more transparent than the others, but that's due to a far lower learning curve, which is yet another situational choice). Nonetheless, I enjoy writing Rust, as much as it frustrates me (fairly constantly, because sometimes the expressive syntax makes it feel inefficient, and other times because certain things aren't yet possible -- but most of them are RFCs). But if I have to work on certain tasks, for certain people, they have to be in certain languages (usually C++, Python, Go, or Java). Rust is great, Erlang is great, and others are great, but unless the deployment environment is expecting it, or they've transitioned to a microservice style configuration, there's a good chance people aren't going to love things that don't conform. Again, this is really just horses for courses. Python's `pickle` is a massive security risk, but it's an amazing feature. I can't count the number of times I've seen people use it for network serialisation within an organisation and then be surprised when a dist-upgrade (or similar) breaks everything. Just like Java's serialisation, or even some Rust `derive`-based approaches, the key is how you use it (only with trusted data, in environments you can trust). Java and Python both look vulnerable because they give you a feature that you can ab/use to effectively page or swap certain data in/out without feeling like it's high cost (realistically it probably still is); people misusing it isn't on the language (particularly since the documentation issues warnings). Anyone who has been doing this for a while, or uses languages that don't have automatic support for it, will usually lean on writing their own de/serialisation methods (which goes doubly so for people who need bit level packing for storage). That doesn't say that the mistakes of the aforementioned languages aren't replicated, or that constructors are appropriately handled (with sanitisation). I still see serialisation issues on a daily basis, but people seem to hesitate when solutions are presented (a lot of people are strangely allergic to checksums). The general purpose workaround is to implement one yourself, or take a leaf out of the generative playbooks and build something that safely, and sanely, generates code to process it. Protocol Buffers is an example of a generative model that works well for data, and is *mostly* secure. Replicating it isn't super pleasant, so most people don't. ----- As an aside, I'd usually leave this alone, but I keep seeing this sort of knee-jerk reaction to another language and I've hit capacity with it. There are very few languages that are bad. There are even fewer that deserve to be called out. (I dislike Prolog immensely, don't find it fit for task, but I won't deny it was important, and still is to some people. I know people who feel the same about LISP.) Anything that has lasted this long in either research or enterprise systems clearly has value, even if nobody in a given community likes it, wants it, or feels that the RAM usage it presently chews up on a given server is in the realms of reasonable. Further, anything can be insecure. A bad password turns the most secure password system into a joke. Throwing multi-factor authentication at it (even if you have multiple parallel OTPs) improves it (even over a bad password), but a combination of (frequently low effort) social engineering, or outright theft, defeats even that. Technology can't solve social issues, and as much as many may resist the notion, programmers are social entities.
Depends on how low you want to go! If you're interested in what's happening at the machine level, using `mio` might be a better idea. It's a fairly simple async IO framework which really does expose what's happening at a much lower level. Hyper is more just slightly lower level than the frameworks. It will still do the majority of the work for you, but it won't do things like keep track of cookies or sending the correct headers, or handling redirects automatically in the client like reqwest does. I mean hyper will show you something at a lower level, but it's not very much lower. It's still fairly high level, just without a lot of the "magic" that you get with Rocket or other frameworks.
&gt; No it doesn't. Also, Comparing Python with C++ is comparing apples with oranges. If using Python to solve the problem the author has instead of C++, then no, it's not incorrect to compare the two. &gt; Nice but how is C++ different? C++11 even offers implicit return types! Don't you still need to write `auto`for the type? Also, this was written as the way opinions change over time. People are still transition to C++11 to this day. The given opinion could have even been before C++11 was released. &gt; The borrow checker is too strict in many cases unless you want to wrap everything inside an unsafe block. &gt; Hence you will find hard time in implementing (for the sake of argument) basic, normal and completely safe data structures like doubly linked lists without performance overhead. Just wrapping in unsafe doesn't turn off borrowck, gotta actually use raw pointers or something. And yes, those basic data structures have to use techniques that Rust cannot reason about safely. They use knowledge about their layout to guarantee these properties, and then tell us they do so by using `unsafe` where needed. There is nothing wrong about using `unsafe` in this way. Other languages either using GC to avoid having to care or are always unsafe. C++ doesn't say it's safe, as it doesn't say anything is safe. Furthermore, as has been shown in practice, the levels above the basic building blocks generally doesn't require these techniques and don't need to use `unsafe`.
Awesome thanks! I will check it out!
&gt; Is serialization by nature a security risk? No, just like a car isn't dangerous by nature. It's how it's used that determines if it can do harm (so if you leave it parked and never turn the engine over it's harmless -- without external force). If you deserialise blindly in an untrusted environment you don't know what will happen unless you lace it with checks/sanitisers. In the case of Java (and lesser so Python), if you use the built-in methods it can be (and in fact really is if you're serialising something that's used without tests). If you instead serialise out the values and then push it through constructors it's no more risky than taking user input for those given objects. (But that's a whole different story of tears and rage.) &gt; and if so how might this impact on use of libraries like Serde as the rust ecosystem grows? Off the top of my head I'm not aware of any public de/serialisation crate that blindly de/serialises. I didn't think Serde did. I've written a few (internal) data portability crates that are basically bad ports of some of my old C/C++ code, and they do things that I wouldn't be comfortable making public (because they're bad code and the word `unsafe` appears more than I'm comfortable admitting). As I refactor them (in both languages), I'm slowly dropping some of the riskier behaviours as the models shift to flyweight (so ID based references instead of using pointer portability code). There are costs involved in both models, so it's a cost/benefit analysis. There are reasons to make risky portability plays (mostly performance), but it becomes a question of trust. If you know you'll always trust the environment in which an application runs (it lives in its own scope, only writes out, etc., etc.) it doesn't matter what you do. If your system could be compromised (and yes, they all could be ...), and it matters, then obviously assume less (or no) trust. (Insert rant about paranoia and how I have a bad case of it some days.) If you're worried about Serde and others (which I can't think of a reason you should be), do the rational/reasonable thing and serialise into JSON, XML, or a similar exchange format that has to be processed back in (i.e. treat it as though you're going to change language between nodes and use a portable exchange format). You pay a performance cost, but if you want peace of mind (and the de/serialisers for it are decent) it's not a bad way to go if you don't want to hand code the store/restore functionality. If you want a binary exchange format look at Protocol Buffers or Cap'n Proto. I'm not exactly taken with either for most of my own purposes (I still hand write most of my serialisation with the help of inline things like `u32.serial_get(&amp;mut source)` and `u32.serial_put(&amp;mut source)`).
I'm working on wrapping a C library with Rust, and wanted to make sure that I'm on the right track with how I'm implementing a self\-referential structure being passed through FFI. The C library allows you to register callbacks which will fire when parsing replies from a server. Replies can nest meaning that when the callback fires, the C library can indicate that the object has a "parent" so we should both attach the new reply to the parent and return the new object itself. I'm using this struct for representing replies in Rust: #[derive(Debug)] enum CustomReply { Integer(i32), Array(Vec&lt;Rc&lt;RefCell&lt;CustomReply&gt;&gt;&gt;), } My callbacks to create either integer or array objects look like this: extern "C" fn create_array(task: *const readTask, len: usize) -&gt; *mut c_void { let obj = CustomReply::array(len); attach_reply(task, obj) } extern "C" fn create_integer(task: *const readTask, v: c_int) -&gt; *mut c_void { let obj = CustomReply::integer(v as i32); attach_reply(task, obj) } Specifically, I'd like input as to whether I am correct with how I construct the self\-referential bit, in `attach_reply`: fn attach_reply(task: *const readTask, reply: CustomReply) -&gt; *mut c_void { let rc = Rc::new(RefCell::new(reply)); if unsafe { (*task).parent.is_null() != true } { let parent = unsafe { Rc::from_raw((*task).parent as *mut RefCell&lt;CustomReply&gt;) }; { match *parent.borrow_mut() { CustomReply::Array(ref mut v) =&gt; v.push(rc.clone()), _ =&gt; panic!("Parent not an array type!"), } } std::mem::forget(parent); } Rc::into_raw(rc) as *mut _ } This appears to work, and valgrind is happy but I'm still quite a rust n00b. :\) Here is a link to the [GitHub repo](https://github.com/michael-grunder/selfref) with all of the code.
&gt; Don't you still need to write autofor the type? That's not for the type, FYI. It's required for C++11's trailing return type. `auto greet(const std::string_view&amp; name) -&gt; void` becomes `auto greet(const std::string_view&amp; name)`. C++ has had this feature(!) since 7 years!
where's the thrill and adventure in that?
Serde ist just the framework for actual serializers, so in the end it depends on those.
Hyper is a pretty low level library one can use to build frameworks or small services. However it is both lowlevel in some aspects and very high level in others. In the end I don't think it is necessarily the best abstraction. Rocket currently uses hyper I think and so you can fall down to a lower level there if you want. I would recommend looking into actix which I think generally has a more straightforward API and does not depend on unstable rust and stays about as low level as hyper if you need.
The author mentions that this is what they _used_ to think - I kind of interpreted that line as "[I don't need compile-time checks because] if I misspell a variable ..."
Recursion limits need to be implemented on the serializer itself, not directly in serde. For example, serde_json has a depth limit of [128](https://github.com/serde-rs/json/pull/163) that we could make customizable, but so far no one has asked us to so we haven’t implemented it.
Well, there's this: https://www.youtube.com/watch?v=LKnqECcg6Gw
I place a lot of weight on whether a developer tries multiple languages over time and this is why. Someone can spend 10 years doing python and never know the wonders and increased safety of a more expressive type system. It doesn't make python a bad language, it doesn't make the other language a better language -- that all depends on what you're doing with the language (as there is usually a better tool in context)... But you have to try different things to experience different things and grow as a developer. I personally appreciate languages that aren't statically type checked for their speed and simplicity, but after discovering and taking some time to get used to Haskell I don't think I've ever looked back. **What drew me to rust was that it had an expressive type system and systems-level speed natively, with ezpz cross platform static compilation**. I'm not actually sure that all of those things have actually come together in a language before -- you could probably argue they've been possible in a lisp like SBCL but the community is too sparse for me (despite the fact that I love lisp). BTW JS + Typescript is amazing.
No, it isn't. Cervus loads WASM to kernel using ioctl on device file, which Cervus kernel module implements.
The whole point is to get rid of syscalls and replace them with normal foreign function calls.
&gt; I started re-writing a Python project in Rust, and suddenly all this stuff about “if it compiles, it works”, and “types system make unit tests unnecessary” finally started to make sense. That's not very compelling at all. I don't actually believe that a rust rewrite of well tested python code would be any more correct than a rust implementation; faster, certainly... but its hard to preserve existing behavior with a rewrite, especially when the rewrite is presumably doing complicated (concurrent) stuff the original wasn't. The author would probably have been far better served by profiling the service and rewriting the hotspots as rust powered python packages and preserving the existing test suite. Rust has a great type system, but correctness at compile time and bug rates don't correlate as strongly as people imagine.
Back from RustFest, it was totally great (despite my son throwing up on Sunday morning, which meant I missed the workshops). I'm going to do TWiR, [mutagen](https://github.com/llogiq/mutagen) (gotta get a new release out) and perhaps some other things.
Not all statements at the beginning are wrong. pytest is still awesome! :)
This weekend I've ported my [Zemeroth](https://github.com/ozkriff/zemeroth) game to [ggez](https://github.com/ggez/ggez) engine: [#247](https://github.com/ozkriff/zemeroth/pull/247) RIP [Häte2d](https://docs.rs/hate), you were a fun experiment, but using ggez is much more practical. The most serious downside of the engine switch, [though temporary](https://github.com/ggez/ggez/issues/70), is that there's no Android version of the game now.
Not to forget Haskell which can do a lot of type inferrence.
Trailing return type is C++11 feature. But... Isn't inferred return type is C++14 feature?
That video was pretty eye-opening.
Plus even though Haskell can do full type inference, it's still recommended in pretty much every style guide to specify the type signature, for documentation purposes and because it can help get better type errors when modifying the body of the function.
True! Part of why I chose the word "let" in that description is because I was aiming for "things the compiler allows" over "things the compiler can do". I probably should have been more precise, though I wasn't even thinking about closures at the time so thanks for the clarification!
It is often said that the type system makes a certain subset of unit tests in dynamically typed languages unnecessary. I don't see many people arguing that strongly typed languages need no unit tests, thats a little silly.
Interesting, thanks for sharing.
I remember not writing types for Haskell at all and then adding them later cause I couldn't debug it.
Nice!!
Rust type inference is quite good but there's some cases where it's frustratingly stupid. Here's a minimal example: https://play.rust-lang.org/?gist=2167d0b053f496729421a77e43764d07&amp;version=stable&amp;mode=debug It must know the type already when finding the first occasion of type-based dispatch – it it would do "full" backwards inference, it would realise that the type is `Vec` here from the function return value.
The most difficult part of Hyper is less its low\-levelness than the fact it uses futures ... It takes time to understand how it works \(errors are generally not really helpful\). On the other hand it is pretty useful to know/understand it at some point. Rocket is just plain easy to write. My main complaint is that it is nightly so it breaks, sometimes \(it is probably rare but it happened\). Nowadays I do hyper mainly because it is very simple and I have this feeling of control. Both code run just as fast in practice \(i am rarely bounded on http side and I have only few concurrent connections\).
They also take some ambiguity out of documentation work, because the code itself documents what types parameters and return values belong to. In a dynamically typed language like JS (which is my favourite language, I might add), I may have a function called "getUser" ... But what exactly does getUser return? A "User" object presumably - but what does this "User" object comprise of? Is it an instance of a prototype/ES6 class? If so, where is that prototype/class defined? And if it isn't an instance of a prototype/class ... The expressiveness/flexibility of dynamically typed languages is powerful (what I can do elegantly in an hour or two in JS would probably take half a day of toil in Golang), but it comes at a cost.
Yeah, I would do the same if I had a very long function in Rust so that I had to scroll to the top to know the type of some argument. Of course good Rusticans never write functions that long... still, documenting stuff is good.
Not sure about Java but Python's pickle is actually a dedicated executable bytecode, executing that creates the relevant objects. It's way worse than just loading an existing object payload in memory, just loading a pickle is an arbitrary code execution. 
`.collect()` has this problem a lot to be fair. ``` /// Because `collect()` is so general, it can cause problems with type /// inference. As such, `collect()` is one of the few times you'll see /// the syntax affectionately known as the 'turbofish': `::&lt;&gt;`. This /// helps the inference algorithm understand specifically which collection /// you're trying to collect into. ``` 
I started a small command-line utility this weekend, called [checkpwn](https://crates.io/crates/checkpwn). It's used to check a single, or a list of emails, against breaches with the [Have I Been Pwned](https://haveibeenpwned.com/) API. You can of course also check a password. Just added password range search and expecting to add input validation, and perhaps automatic recognition of lists passed to the binary as argument, within the three days.
This is a very good point and should be noted prominently somewhere in the `serde` docs.
I had a look at [Not Yet Awesome Rust](https://github.com/not-yet-awesome-rust/not-yet-awesome-rust) for inspiration and decided to have a go at the QR Decoder. Very ambitiously I named it [bardecoder](https://github.com/piderman314/bardecoder) in the hopes of having it support other codes as well in the future. After a few weekends of coding it is finally starting to come together. I can now decode all versions given the data and detection is reasonable. Things TODO: - Improve detection of QR Codes, especially given a skewed perspective - Rethink code organisation, I'm not 100% happy with the modules. - Add documentation (ha!) - Maybe some parallellism? Especially the detection part lends itself very well. Maybe some SIMD? All the discrete mathematics seems to lend itself.
Yeah, for better or worse it only goes as far as the first usage and bails if the type cannot be determined at or before that usage site. I have a feeling Rust _could_ do full inference considering the entire body of the function; it just doesn't at the moment.
Haskell can not do full type inference in all circumstances, this is especially true for certain language extensions, but even without them it can be true. E.g. `read` which parses a string and converts it to the type that's needed, but that only works if that type can be inferred. This won't be the case if (for example) you immediately print it out to a file and never use the value again, because to print it you only need the type to implement a typeclass and there is no bound to how many possible types are valid (and therefore different implementations of the parse and print functions).
This is of course not only a problem with `collect` but any function that has a generic return type; some highly generic libraries such as Diesel suffer from this too. I'd like to see some relatively simple extension to type inference some day: It would check if it can infer the type at the end of the lifetime of the variable, when it's passed to some function or when it's returned from the current function. I think that would account like 75% of the cases it fails at the moment. (Accounting also the case of taking a reference and then passing that to a function would bring that even higher, but that's a bit less local, even if it's still inside the current function body.)
Come on, it was just a joke... I really thought Java is more secure than that, so it seemed funny to me.
&gt; The project's readme seems to indicate performance, but I am unsure how this decision improves performance. If user applications are run on ring 3 and the kernel on ring 0, a syscall requires a context switch. A context switch adds a constant overhead that can be very large compared to that of a function call - this depends on many things like the types of registers that the application could be using. Running user applications on ring 0 allows performing syscalls without doing a context switch. If your application does many short-lived syscalls, then the cost of context switches might be relevant. 
Thanks for all that! With your experience with this approach, can you deploy the app as an .exe for users, not requiring them to have python runtime or Qt installed? I briefly tried using the Python API for QML/Qt last year and remember it not being a fun time especially for Windows, 5.6 was available as a python/pip wheel, there were plans to release a 5.9 wheel on conda forge(I think this might not have happened yet). With the Qt for Python support being official with Qt 5.11, hopefully this will be less of a problem. On Linux I don't mind linking to the system Python/Qt packages, but for Windows users that might not go well?
Just saying, Java deserialization code is written in Java itself, so unless Java has memory safety bugs, memory safety isn't a concern.
I will propably finish the rust book this week (Really excited about the webserver example). After that I would like to look further into webassembly and maybe even remake an old project of mine. 
If I recall correctly, the short version is that Rust and Go used to be 'closer' to each other language wise, back when Rust had green threads and such. During this time Go was also (correctly or not) marketed as a 'systems' programming language, which put Rust and Go into the same category of new systems programming languages. I could be wrong though. 
There's a lot of hate (and mistrust) to/from a lot of language groups, and you'll find anyone who has lived through some of the less pleasant periods (or even just observed them in retrospect), really doesn't want to go back there.
On top of this, both languages are procedural-paradigm languages, both in a time when procedural languages have fallen out of fashion to object-oriented programming. 
Thanks! I'll rephrase the part about the Copy trait
I concur :) I'll rephrase, thanks.
At a quick glance, the two languages are somewhat similar: Both Rust and Go promise a new, better, safer, C-like language. However, that's about where the similarities end. The ways of how each language achieves this improvements (ergonomics, safety, concurrency, builds, etc.) are completely different. 
But if you are a dev looking for the next compiled language, then you may be in a dilemma on what to choose
will rust or go take the stage which is c stand for in the future?
if choosing 'something to learn , to find new problems to work on' , then it would be a dliemma; However, if you are focussed on a particular problem or area of interest already, then the choice would be clearer.
&gt; With your experience with this approach, can you deploy the app as an .exe for users, not requiring them to have python runtime or Qt installed? Last time I checked, PyQt and the old PyGTK bindings got along just fine with tools like [py2exe](http://py2exe.org/), [cx_Freeze](https://anthony-tuininga.github.io/cx_Freeze/), and [PyInstaller](http://www.pyinstaller.org/)... with the caveat that you'll may have to add some manual hints for the dependency-finder. (eg. If you've got some kind of fancy dynamic import which confuses it or if it picks up Qt libraries too aggressively and you wind up with a full 100+ MiB set of them when you're not using things like QtSQL.) I'm not sure how Qt for Python (being PySide rather than PyQt) will change that equation, but, generally speaking, it shouldn't require anything more than a manual addition to the overrides. Worst case scenario, you have some files that, for some reason, can't be loaded from the bundle automatically and you could either distribute a Zip file or use [InnoSetup](http://www.jrsoftware.org/isinfo.php) to build an installer. (I highly recommend InnoSetup over [NSIS](http://nsis.sourceforge.net/Main%5FPage) or [WiX](http://wixtoolset.org/) if you don't have complex/specialty installation needs that make the hassle of the others worth it.) I'd also suggest incorporating advzip.exe from [AdvanceCOMP](http://www.advancemame.it/comp-readme.html) into your build script to compact the `.zip` before it gets concatenated onto the Python runtime. (But then I recommend that for any "bundle up a non-machine-code language" operation.) Here's an [example of said advzip integration](https://github.com/ssokolow/fanfic2ebook/blob/development/setup.py) from the `setup.py` for one of my older projects that I really need to get back to working on. As for the rust-cpython component, while I haven't tried to deploy it for Windows yet, I don't foresee any problems. When building an extension, the resulting file is self-contained aside from the usual "Rust dynamically links to libc"... but then tools like `py2exe` do that too rather than bundling libc to satisfy the dependency Python itself has on it. (For legal reasons. The "everyone has permission to redistribute" applies to Microsoft's VC++ Runtime redistributable installers. You need to obtain extra permission to redistribute unpacked pieces of them rather than just having an installer which runs them as part of what it does.) Thankfully, Visual C++ runtimes get bundled into Windows as time goes on. (eg. Python 2.7 depends on a version that comes with Vista and above. I can't remember what Python 3.x releases or Rust's MSVC target need.)
Really helpful, thank you so much :) So with InnoSetup and py2exe, the user shouldn't need to have Python or Qt installed prior? If I get Qt via a python wheel or conda that doesn't make much of a difference does it? This also ensures that the intended versions of python and Qt are bundled into the .exe? Thanks for the example link. I'll try get something basic going :)
I'm writing a recipe website using acticx-web and typescript/react for the fronted because I'm trendy like that. Futures are not very fun. 
Probably exactly that: To make it less convenient.
I wanted to learn more about LAPACK and SIMD, so I started writing some code to do computations involving matrices last weekend. So far, things are going pretty well and I'm feeling happy with the results. 
&gt; Really helpful, thank you so much :) Not a problem. :) &gt; So with InnoSetup and py2exe, the user shouldn't need to have Python or Qt installed prior? Yeah. The goal of tools like py2exe is to get as close as legally possible to having *everything* inside a `.exe` file you can double-click. The only things you'll need InnoSetup or a Zip file for are: 1. Files you're not legally allowed to bundle into the EXE (eg. The aforementioned MSVC redistributable DLLs which must be installed onto older Windows versions using the Microsoft-provided installers if you haven't paid for the right kind of developer license.) 2. Resources that your program only knows how to load from unpacked files on the hard drive. (If your code can be written to accept any object which provides the right methods (eg. `read()`) or to load from a bytestring, there are ways to bundle non-code files into the EXE too.) 3. Things which, by their very definition, require an installer, such as adding a Start Menu entry or file type association. &gt; If I get Qt via a python wheel or conda that doesn't make much of a difference does it? This also ensures that the intended versions of python and Qt are bundled into the .exe? Not a problem. Tools like py2exe try to replicate the lookup behaviour you get when you actually run the program as closely as possible when figuring out what to bundle and, once it's all bundled up, the bits outside the bundle only matter if the bundler missed something. (In which case, you manually mention whatever was missed in the bundler's config.)
I had this problem too.
Goroutine needs some runtime support, and I don't think anyone's working on GCless Go. So, that's a no for Go. For Rust, maybe? Rust aims to be a close-to-metal language like C/C++, and I think it does that quite well. So it could replace C/C++ in the future, but we'll have to see how things go.
As someone who's been somewhat of a fanboy of all the languages in question, C, C++, Go and Rust, I would like to recommend learning and experimenting with at least Go and Rust to build some feeling for the difference. And by all means try them all, if you have the time :) Others in this thread have pointed out that Go and Rust are quite different and I do very much agree on that. &gt; will rust or go take the stage which is c/cpp stands for in the future? I sure do *hope* that Rust will keep replacing both C and C++ at an ever increasing pace! In my opinion, Rust is the first true successor to C++, and by that some might consider it the first true successor to C.
Interesting. What were the reasons for choosing Tetris? Is your work related to similar games?
From the youtube comments: &gt; See, even benchmarks have to be webscale these days 
systemaids say that the best tech is python for everything about devops, so i think a junior should learn about it instead of golang.
In my book, both Rust and Go are OOP languages because they both have method call syntax.
That is an incredibly shallow way to define OOP. 
I am currently working on [azul](https://github.com/maps4print/azul), my GUI framework. Last week I did horizontal centering for text, this week I'll do vertical alignment / scrolling (webrender has a special API for scrollable items, esp. text). That should be enough to implement the `align-items` and `overflow-{x, y}` property (so that elements auto-scroll on overflow, etc.). There are a lot of changes I did last week, like implementing dynamic CSS properties (avoids re-parsing the CSS), implementing deamons (sync) and tasks (async) - all of them should work correctly now. But the documentation isn't great right now, I'll need to redo that. Lots of typos and code mistakes. And lastly of course, implementing svg drawing using lyon / OpenGL. I did prepare a compositing system, but integrating that with webrender can be a bit tricky. And I can now start implementing `:hover` / `:focus`, etc. properties because I finished the dynamic CSS properties, so yeah, that's nice.
To be appealing to newcomers, I wanted an example that has some visual output plus interactivity, and Tetris was a game simple and familiar enough for it. My work is in other areas now. However the graphics inkling still remained from the 90's back when I learned how to program. Past Tetris clones I wrote were in Basic, Pascal, and C++.
is like saying that Haskell is an OOP language because it has infix notation
It would have been awesome if you had videoed the live coding.
Not sure about this particular one, but perhaps future ones now that I have more live-coding experience :)
&gt; &gt; Python Rocks &gt; No it doesn't. Also, Comparing Python with C++ is comparing apples with oranges. Having programmed in both Python and Rust, I can say this confidently - Python syntax is a joy to read and I'm still envious at the sheer outrageous flexibility Python tools like [SQLAlchemy](www.sqlalchemy.org) give to Python users. I don't think one needs to be zealot about his programming choices. Right tool for the right job. If someone told me, write a game engine today, it would make more sense to write it in C++ or Python, than in Rust, simply because available tooling and resources for those two languages are top notch (Python being more beginner oriented and C++ more experienced dev oriented).
It would be tremendously helpful if rustc could at least guess what I'm trying to do (in these basic situations) and give a 'did you mean...?'. Right now I have to 'guess' the complete type manually. Normally this is probably the best thing to do, but when prototyping it can be very helpful to get a perhaps overly broad type to work with.
There seems to be a prevailing opinion (which I'm not attributing to anyone in particular) that Go and Rust are "not competitors". But, well, they clearly are. * New (current decade) general-purpose languages attempting to fix problems with C/C++ * Statically compiled and 'fast' * Backed by major tech companies (that are themselves in competition) There are many application domains where one could choose one or the other. Parsers, servers, CLIs. General programming. Even if one has better features for a given domain (e.g. Go is arguably better for async web services), good libraries can overcome most deficiencies. Python-the-language does not seem particularly suited for web servers, but it does have Django, Flask and SqlAlchemy. But more fundamentally, they are in competition like any two languages are in competition. It takes a very significant investment of time and energy to become proficient in a language, and not everyone (indeed not many people) aim to become language polyglots. It is absolutely possible to survive (and be well paid!) in this industry knowing nothing but Java or Python, for example. I think the claim they are not competitors has to be seen as a defensive/political maneuver, because if one wins that seems to imply that the other one will lose (and it would be foolish to pick a fight with Google). Of course, this is not a zero-sum game. The number of developers in the world is steadily increasing, and Go and Rust could both benefit at the expense of other languages rather than each other (and indeed that seems to be happening). Personally, I think Rust is simply better than Go, in practically every way. the only aspect of Go I prefer is fast compile times. And if someone told me they were thinking of learning Go, I would not hesitate to recommend they learn Rust instead.
A slightly deeper rephrasing would be "type-directed function lookup", i.e. `x.foo()` can call two different `foo`s depending on what `x` is.
Interesting idea! Had you coded a Tetris clone in Rust before? If not, did you get stuck, or make mistakes, or stumble at all, during the presentation?
I'm converting my OpenCL mandelbulb render (gtk-rs+ocl) to Vulkan (gtk-rs + vulkano); Neither Vulkan or Vulkano are easy going!
might've been a tiny bit cleaner with a macro :-)
I'd add in a shift towards Strong Static typing, and AOT compilation. Plus a focus on concurrency schemes and use of pointer types. Things that generally fall more in the realm of systems work.
Strange definition as OOP language do not require method call syntax nor method call syntax do not indicate OOP. What makes environment OO is existence of traits/interfaces. By that definition Unix filesystem is also OO which I like presenting as a great example of true OO in my opinion. Alternative (original) definition is that objects are independent units that communicate with other units by passing messages. That makes Erlang more OOP in original sense than in comparison Java.
I've only used typescript -- I never gave flow a chance (and basically decided not to after reading a [random blog post](https://blog.mariusschulz.com/2017/01/13/typescript-vs-flow)), could you expand on the advantages Flow offers over Typescript? After a few more seconds of googling I found [a presentation that does a much better job of comparing the two](https://djcordhose.github.io/flow-vs-typescript/flow-typescript-2.html) -- is this what you meant? **I'm ashamed that I didn't look into flow more closely :(** it does indeed have the better type system -- The one thing I'd consider a big benefit of typescript is the large amount of libraries that have `@types` repositories already, but I usually go with what I think is the best solution rather than what is more popular, and I thought they were just about equivalent, type system wise.
Go's statically typed in theory but in practice many people cast values to the top type `interface {}` often and it's idiomatic to do so.
It was the second time. The first time took about two\-three hours from scratch, once I figured how to draw squares in Piston. I've prepared a printed copy of the first try's code to assist me during the session. My original intention was to start with an empty program, then extend the game feature by feature: first draw an empty board with no action, then add a piece, then add gravity to the piece, then add keyboard controls to move the piece, then add rotation, complete line elimination, etc. In practice due to time, I needed to shortcut by copying whole functions from the finished code's digital copy. Only managed to reach the state where I had falling pieces without rotation and without completed line elimination. In retrospect, perhaps if I had prepared a Git history that shows through the progression of changes, then 90 minutes would have been enough. I've had to stop occasionally to answer questions about the language. One stumble was due to breakage in my RLS\+VIM setup that caused Cargo to recompile all dependencies each time, so I had to disable it mid\-session.
The 2 languages definitely are competitors in the web development backend and network application space, but outside of that small category of problems where pretty much every language is a competitor I don't think there's a lot of overlap. I'm from an embedded and scientific computing background, Go isn't even vaguely on the radar, not any more than the Javas, JavaScripts or Rubys or the world anyway. Go just isn't an appropriate or potential choice in that space. As another anecdotal example, I know some people in game dev excited about Rust, none even vaguely interested in Go, it's just not perceived as having tje basic language features required to grow into the space, even via libraries.
 Close, but not precisely. I'd much rather have something like: ``` trait SearchItem { fn display_text(&amp;self) -&gt; &amp;str; // or maybe Cow&lt;str&gt; } fuzzy_find&lt;T: SearchItem&gt;(haystack: Vec&lt;&amp;SearchItem&gt;) -&gt; Result&lt;&amp;SearcItem, rff::Error&gt; ``` or instead returning the index of the element I am interested in, so that I can keep an outside vector with more structured data in the same order. ``` fuzzy_find&lt;T: SearchItem&gt;(haystack: Vec&lt;&amp;SearchItem&gt;) -&gt; Result&lt;usize, rff::Error&gt; ``` 
I quite like the way it is tbh, sometimes macros can needlessly obfuscate stuff
I believe your hunch is absolutely correct. Many books / courses these days focus on command line, stdin/out and features of the language. If you are learning your 5th language -- that is ok -- that is what you expect and interested in. But for a person who learns the very fist one this visual component to the process is extremely helpful. I wish beginner tutorials did more of that. Another good resource is https://turtle.rs/. 
One of the absolute best uses of youtube is watching conferences. Make sure to subscribe to (or periodically check if you don't want to make a youtube account) the [rust channel](https://www.youtube.com/channel/UCaYhcUwRBNscFNUKTjgPFiA) if you haven't already!
`typedef int(*FunctionPtr)(void *Arg);` `typedef struct _Interface` `{` `FunctionPtr Func;` `} Interface;` `int Func1(void *Arg)` `{` `free(Arg);` `return 0;` `}` `int Func2(void *Arg)` `{` `return Arg != NULL;` `}` `Interface Impl1 = { .Func = Func1, };` `Interface Impl2 = { .Func = Func2, };` So is C OOP?
One thing I think is missing from modern day programming is making a gui easily. I learned with turbo c++ where it has GUI and graphics stuff built in. I ran it and could start drawing stuff. But now it necessitates getting some library or opengl and learning a whole other framework on top of the language.
I think you missed a chance to introduce tuple structs. You have both untyped tuples and arrays which could just as easily have been defined as a Point, Size, Rect and Color struct. Would have barely add code but made it nicer and showed of another very useful feature.
GObject smth smth...
It does have non\-independent tuple structs embedded as some of the enum options, which bears to mind that named structs as enum options are missing from the example, among other things \- Traits, and Trait Objects, Rc, RefCell, and lots of other useful stuff the Rustaceans use often. On a wider perspective, it could be a challenge to cram a lot of Rust features into the smallest space as possible. Maybe it's possible to take all the examples from the 'Rust By Example' book have one nice project to demo them all of them together? Some of the people I know trying to read 'Rust By Example' have given it up in the middle due to lack of interest. A single project to code\-read can be more engaging perhaps.
hi, i'm not really an simd expert but i'm a little curious about it. do you know this library [https://github.com/AdamNiederer/faster](https://github.com/AdamNiederer/faster) ? do you think it could work in your case ?
Also available at https://media.ccc.de/c/rustfest18
Tests are done manually using the [vdiff](https://github.com/RazrFalcon/resvg-test-suite/tree/master/tools/vdiff) tool.
I haven't messed around with terminion or anything, but wouldn't you just need to add: if event == Quit { break; } after line 106? Right now you aren't ever exiting the loop that's polling for keys.
In the era that Rust was pre-1.0 and still evolving, when it hadn't quite yet grabbed my attention, Go's marketing at the time was exactly what I had been wanting in a language in the years prior to it's debut. So this definitely rings true to me. Today Go feels like C 1.5, being if C underwent syntax redesigns, given a standardized ecosystem and revitalized standard library, then a GC tossed in. Certainly much closer to Nim than Rust. 
To me, the GC puts it in a 100% different category than C. I'm not bashing GCs at all, and I think they're excellent tools. But it's just a different category of language.
how would you specify a shared reference in JSON or XML? exactly. you can't. There's no way for the (de)serializer to understand the relationship between shared references anyways, so each reference would be saved as a complete, separate copy and deserialized the same way. So, no, it isn't possible to do that as far as I know.
I'm just alluding to the overlap in paradigm philosophy between the two languages. Small core feature set, static, compiled, pointers, nulls. While you might not be managing memory, your approach to problem domains will be familiar. It's like a half-step away from C, ala the 1.5 version analogy. Hope that clarifies.
For a deserializer it would be tricky, but for a serializer, it's pretty easy, for example like this: http://play.rust-lang.org/?gist=fad124ce2fca65f83dd1ef3c17b50e71&amp;version=stable&amp;mode=debug. If someone's allowed a type with interior mutability and references in it to be serialized, then it's up to them to make sure that a user can't generate cycles, or else you'll get a DDOS (though in this case it looks like it just stack overflows).
My personal reasons for using Flow over Typescript: \- I'm not sure about the theoretical type\-theory basis, but Flows' type system just felt better to me, and that might very well be because it's closer to Rust \- I like Babel and I use quite a few features from it, so ditching it for Typescript would have been painful \- Since the default Flow typechecker is stateful and works in an incremental way, so it's blazingly fast \- Great React support \- Can't support this with hard evidence, but I felt that Flow was less "demanding"/infectous regarding type annotations. So if there was one conflict that was detected, I had to add 2\-3 type annotations to resolve it, while it was 5\+ with Typescript.
I'm writing a CLI app to convert Intel hex files to STM DFU files, which are super useful in embedded systems. All that exists right now is a windows only GUI app, and a an abandoned C version of it with no distribution (brew, apt-get, etc.). So I was hoping I could get it in a few package managers so it could become part of people's build systems.
can someone explain to me why someone would want to run "web assembly" in a non\-web environment? what's the benefits?
You might want to consider using the k-anonymity range endpoint discussed on Troy Hunt's blog.
Out would look superficially cleaner, but be much harder to understand. Only with it if it is something you are doing a *lot*, not 5 times.
Yes, most standard collections should be superlinear-proof (or well, `BTreeMap` is O(N log N) but that's close enough...), so there's not much risk in Rust. Well, unless someone writes their own hasher...
I would imagine that WASM will start to become a popular target for all manner of applications, becoming a kind of cross platform target like JVM, which means that the ability to run WASM apps in Linux will mean that you can use those programs too. I could see it becoming especially useful if there is a nice graphical library that means near-native cross platform GUI is easier for those of us with web experience.
Still trying to port rust, feeling a lil lost every step 
A lot of people in this thread are talking about competition between C, C++, and Rust. While that may be the case I think it gives the wrong idea for the future. Both Rust and Go are attracting a lot of users who don't traditionally use systems-style languages. I don't expect considerable C or C++ codebases to be rewritten in Rust (and certainly not Go), but I do expect to see both Rust woven into a lot of web backend work. I think there's a possible future where more Rust is in the wild than C++, but no C++ codebase gets rewritten and no C++ team switches to Rust.
+1 on the live coding possibility.. would love to see more Rust live code
I am sure there are tons of options to do that. The simpler and least efficient that comes onto my mind is using IR + JIT compiler, that is provided by the OS. That would actually mean that we are just using VM with typed bytecode. But it would still be much faster than than the VM with WASM, which checks the ring0 every time the code is run, as opposed to checking it only once. 
We^^^ * Item * Item /u/ * Item /u/ * Itemi * toItem * s * Item[caption](http://imgur.com/5NRPqap.jpg) * Item
What do you mean by “removed out of the box”? What things?
/u/ /r/
I don't really agree that it's restricted. 'Backend' seems pretty broad and massive. As an example, you could build a REST app in Go/ Rust. You could also build complex instrumentation, such as auditd[0], which is a whole other domain. Or you could build runtime environments like Docker (Go)/ Habitat (Rust). Or CLI apps. All sorts of things. And Go and Rust both compete in this area - and yeah, I'd say it's probably the largest by market as well. Rust is definitely more flexible in that it can move into other areas, but where they overlap is very significant. https://github.com/slackhq/go-audit
My reply was a joke. 
Yesssss. Watch the talks. Read the limericks! And admire Bodil's performing the best transition I've ever seen in a talk here: https://youtu.be/Gfe-JKn7G0I?t=13m30s
You are bad at reading
Y
Not for a very, very long time. There is too much existing code written in C, and too many cases where Rust and Go need a lot of work to be usable. For example, Rust won't work in a lot of embedded systems because they have their own non\-standard architecture. The manufacturer will provide their own C compiler, but that's not much use if you're writing Rust code. The manufacturer would have to either provide an LLVM\-compatible backend to compile to their architecture \(hah!\), or provide their own version of `rustc` \(hah!\), neither of which seems terribly likely. Rust and Go are also probably not an option for, say, NASA, given their incredibly restrive policies on what sort of code is allowed, like their [10 rules for developing safety\-critical code](https://en.wikipedia.org/wiki/The_Power_of_10:_Rules_for_Developing_Safety-Critical_Code). I mean, none of these are *impossible* to meet in Go or Rust \(apart from maybe Rule 3 in Go \- can you *completely* disable dynamic allocation?\), but equally, I think you lose a lot of their power if you do. Plus, there aren't, AFAIK, any static code analysers for either language. You might start seeing less new code being written in C or C++ in a few years. But they won't stop being mainstream for a very, very long time.
How do I look at the generated assembly (LLVM IR I think) for a function?
Update: I can't seem to link the library quite right, because it's missing compiler builtins ... maybe this is the only way? 
awesome comment, thank you sir 
I think OSX uses 'seatbelt' - a quick search gave me https://github.com/s7ephen/OSX-Sandbox--Seatbelt--Profiles
Ohhhhhh I'm the big dumb srry 
The readme mentions `sandbox_init`, which is deprecated according to apples documentation.
Oh :\
How about adding a poll type to the event enum? If you don't receive a key press you can send a poll event, that is normally ignored on the rx side. If the rx end is dropped you should get an error, then you would know to exit the tx end. Not sure how bad the performance impact would be, you'd have to test it.
You're probably after the `emit` options in `rustc`. $ rustc Usage: rustc [OPTIONS] INPUT Options: ... --emit [asm|llvm-bc|llvm-ir|obj|metadata|link|dep-info|mir] Comma separated list of types of output for the compiler to emit
Thanks
The problem is that it's waiting on the tx end. The wait is coming from a read on stdin, which can't be interrupted.
Because people are ignorant? 
Wow, that is both beautiful and ugly. But a very creative way to use variable names!
That video is pretty much on point, although a bit simplified, with part of what this library is meant to help with. Thanks for posting it! :) That problem is why the non-linear RGB types doesn't implement any of the fun functionality. You would be surprised by how many gets it wrong and it's fascinating that not even Photoshop seem to do it right as a default.
The only other thing that comes to mind is having a second channel to send the quit signal back on. Just give the sender the rx end of that one.
The [gaol](https://github.com/servo/gaol) crate may be what you're looking for.
Right, but how would I make it stop blocking on stdin when it receives the quit signal?
Remember that a crate is generally used to write applications. Think about what features you would want if you were somebody else using the crate to write a PPTX application. Some people may want low level features and some may want more beginner friendly features. I would write the low level features first, then build some more beginner friendly ones out of the low level ones, so users of your crate have the choice.
`multiset`/`multimap`!
Sounds cool! Feel free to check out my [alsa](https://crates.io/crates/alsa) crate if you want Linux support.
I feel like there is some information source I am missing out on. I got it to generate .ll files but I don't know how to find the actual function. Also, when I add `-C opt-level=3`, it will put the .ll files under the `debug` folder, but it should be putting it under the `release` folder?
Stack
sorry, didn't notice keys() was blocking. You need asyn_stdin https://github.com/redox-os/termion/blob/master/examples/async.rs
OrderedMap and OrderedSet (by insertion order)
What exactly are you trying to port? If I may ask, of course.
In a general term? All of rust More specifically, there's a new platform that I managed to get a POC working (ie a no_std program), but now I'm playing around with getting all of std working on the new target (no promises though)
What would the difference be between an ordered set and a `Vec` using `push` and `pop`?
Uniqueness
From a theoretical perspective, they're both "bad" type systems because neither fit any reasonable definition of type safety or [the gradual guarantee](http://homes.soic.indiana.edu/mvitouse/papers/snapl15.pdf). Some might choose to instead call them "optional type systems" (as opposed to "gradual type systems") for this reason.
Graphs (both directed and undirected), self-balancing trees, any heap that isn't binary, persistent data structures. You might want to check out [this Wikipedia page](https://en.wikipedia.org/wiki/List_of_data_structures).
&gt; You might want to consider using the k-anonymity range endpoint discussed on Troy Hunt's blog. You're right, I was still missing that. Good that I got that into the update just now :)
Also follow me on [twitter](https://twitter.com/llogiq) for even more limericks (and some other stuff, most of which Rust-related)!
there was a very good talk in rustfest 2018 by Bodil Stokke about immutable data structures: https://www.youtube.com/watch?v=Gfe-JKn7G0I also her crate https://crates.io/crates/im
Sorry, but we're not having this kind of 'joke' here. If you want to dump on other programming languages you can do that elsewhere. Here we stand for constructive critique and discussion, not for lame 'jokes'. Please respect the rules.
Looks like it doesn't have [ropes](https://en.wikipedia.org/wiki/Rope_(data_structure)).
And efficient lookup, set operations, etc. 
Looks like it doesn't have [ropes](https://en.wikipedia.org/wiki/Rope_(data_structure\))
I obviously can't speak for the whole Rust community, but I would like to say that personally there are no question that the Rust team had anything but the best intentions :)
An implementation exists for thread\_rng's functionality: [https://github.com/alexcrichton/wbg\-rand](https://github.com/alexcrichton/wbg-rand)
Bidirectional map is one.
I'd suggest reaching out to the LibreOffice devs and seeing what they think. They might be interested in replacing their import or export filter for .pptx docs with one in Rust. I suggest this because I echo u/arewemartiansyet point that libraries need an application to really prove their value.
[Bloom](https://github.com/jedisct1/rust-bloom-filter) / [cuckoo](https://github.com/seiflotfy/rust-cuckoofilter) filters aren't in there, although those are somewhat niche. Bitmaps are also missing. [`hibitset`](https://github.com/slide-rs/hibitset) is a very cool crate for fast-iteration bitsets, although I'm not sure how stable it is. There aren't any parallel data structures beyond basic multithreading tools; you can just put an `RwLock` around your structure, but there are structures with higher performance on crates.io like [`rust-evmap`](https://github.com/jonhoo/rust-evmap) and the various `crossbeam` sub-crates. There aren't any spatial hashes ([k-d trees](https://github.com/mrhooray/kdtree-rs) / [r-trees](https://github.com/Stoeoef/spade)), although those are again kinda niche. (I haven't found any maintained octree crates.)
&gt; The manufacturer would have to either provide an LLVM-compatible backend to compile to their architecture (hah!) Why wouldn't they do that? Is it easier to repackage gcc than to write an llvm backend? Wasn't that the whole promise of llvm, that it will turn what is now a (Language*Backend) problems into (Language+Backend)?
Maybe he works in parcel logistics?
If every function is just a few lines, then you only need integration tests. If every function does exactly one thing and it's obviously correct, it's a waste to unit test it. It irks me when people write tests that are longer than the function just to test the obvious.
/r/playrust
I think godbolt does a great job here, with the demangling. Perhaps you could use [their code](https://github.com/mattgodbolt/compiler-explorer/blob/master/rust/src/main.rs) on the .ll files?
Because out of the latest generation of programming languages, they are the only ones who got really popular. (Swift doesn't count - the latest Apple product will always be popular with the Apple market)
core graphics problems when I try to compile: Compiling core-graphics v0.4.2 Compiling core-graphics v0.3.2 error: type `color_space::__CGColorSpace` is private --&gt; /Users/gradyplayer/.cargo/registry/src/github.com-1ecc6299db9ec823/core-graphics-0.3.2/src/context.rs:86:26 
A quick glance at the source code shows that it is also using `sandbox_init`.
This might be something neat to do four 30-minute screencast videos on and post to YouTube. I'm sure that the community would get a lot out of it.
* `matrix` today normally uses the `ndarray` crate. I think that the Rust language should have better support for n-dimensional arrays, probably by doing the Haskell thing and allowing arrays to be indexed via an `Index` trait. * I wrote some super-sketch slow barely-tested support for a sparse vector [here](ssh://git@github.com/BartMassey/sivec.git). * I wrote some barely tested code for a union-find struct [here](ssh://git@github.com/BartMassey/union-find.git). You may want to look at this [detailed critique](http://ticki.github.io/blog/horrible/) of Rust's collection classes. I don't agree with everything there, but a lot of it is valid.
There aren't any concurrent data structures. A concurrent hash map in particular would be very useful. 
&gt; Also, when I add -C opt-level=3, it will put the .ll files under the debug folder, but it should be putting it under the release folder? Optimisation level is independent of profile. If you want a release build, you have to ask for a release build, not a debug build with higher optimisation. Asking for a full English breakfast will get you sausages (among other things), but asking for sausages will not also get you a full English breakfast.
I would argue tests that the compiler can catch aren't usually meaningful. Rust is unique is that it *does* catch some meaningful concurrency related stuff at compile time... bit thats not because of the type system, it's because of the borrow checker.
Super cool!
See that's my point. I am primarily a web dev and know the front end technologies, and I've played with opengl. But compared to the old days where I could just import draw and write circle(x,y,z) it's significantly more complicated.
I'm currently trying to write a parser using the new\(ish\) Impl Trait features, but I'm having issues. I'd like to do one of the following: 1\) Have my lexer Impl Iterator where Item = Result\&lt;Impl Token, E\&gt; 2\) Have my lexer return Vec\&lt;Impl Token\&gt; Am I missing something or is this currently impossible? If the later, is there another approach to my problem that someone could recommend?
2D canvas is pretty much that: var ctx = canvas.getContext('2d'); ctx.arc(x, y, radius, 0, 2*Math.PI, false); ctx.stroke();
That's a good idea, I'll do that for the next post.
Is there actually any significantly better way to do a sparse array/vector than with a `BTreeMap`?
I can do it too, only the ide window should be activated when running.
&gt;Can I and how do I specify what allocator to use for std containers (Vec, Box, etc)? This is not in nightly yet, [though perhaps soon](https://github.com/rust-lang/rust/pull/50882). The allocator would be a default type parameter on the containers like `Box&lt;T, A: Alloc = Global&gt;`. I assume there would also be a different constructor which would allow passing in an allocator instance. &gt; How can Rust maintain memory safety for stuff like frame allocators (memory is freed at the end of each frame) or ring buffers (memory is never explicitly freed)? Would I have to just resort to unsafe or can the borrow checker be reasoned with? Frame/arena allocators will generally own the values and return `&amp;mut` references, then the borrow checker handles the rest. This strategy won't work directly with the standard collections as the [Alloc API](https://github.com/rust-lang/rust/issues/32838) semantically returns ownership with a `*mut` pointer. You could probably do something like have the allocator return a `&amp;mut` reference to the collection so that its lifetime is tied to the allocator. Allocators with more complex ownership/lifetime semantics could maybe use a smart pointer? Not sure. &gt; Can I control the default allocation mechanism? E.g. replace it with a custom allocator or prohibit it altogether, in case I'm using some crates which I'm entirely sure about. Yes, this is [RFC 1974](https://github.com/rust-lang/rfcs/blob/master/text/1974-global-allocators.md), which will probably be the first thing stabilized as I think it's mostly in nightly already. 
There are some good active meetups in Boston, if you happen to be near that area of the world.
This is very interesting indeed, thanks!!
I want to implement it, but I don't know how to make wasm\-bindgen work for browsers and nodejs at same time.
Getting closer to a 0.3 version of my `retro-pixel` library. I have indexed color images and bitmap images. I just need to eliminate a few more redundancies.
Is there any more details on this?
Because system type things are being done in the two languages. So K8s and Docker done in Go. Think big difference, imo, is that Rust can also handle OS level and Go can not and need a bit higher level. Personally enjoy both languages a lot.
They definitely are competing. But Rust can handle a lower level than Go. But there are many system type applications like K8S for example can be done in Go well. Long tail on stop the world with the Go GC is actually pretty manageable for most applications.
I found this blog post about the same topic also useful: http://huonw.github.io/blog/2015/01/peeking-inside-trait-objects/ 
Good link, didn't know it existed (but could have assumed). I should point out that it is using Math.random for seeding, which is not secure. What Rand wants to use, and already uses with the `stdweb` feature, are `Crypto.getRandomValues` in browsers and `crypto.randomBytes` in Node.js.
To add to other answers in this thread, as Mozilla and Google both develop web browsers there is a mental connection between the languages that they have both incubated and grown.
Yesterday I have finally got my first Rust Pull Request merged into [ndarray](https://github.com/bluss/ndarray) - variance computation for matrices with float values. This week I am going to work on implementing a `map_mut` method to iterate over array elements as mutable reference. This will support a `map_axis_mut` method, to apply reducer functions on 1-dimensional slices of the array borrowed as mutable. Both methods have already been implemented immutably as `map` and `map_axis`, so it's merely an exercise in Rust proficiency (and it's proving a little complicated, still a long way to go here...)
wasm\-bindgen does not support dynamic feature\-detects, I think wbg\-rand still uses Math.rand for the same reason.
&gt; Plus, there aren't, AFAIK, any static code analysers for either language. I'm not sure this point apply to Rust since the compiler provide much more strong static guaranties than C static analyzers. You can consider the static analyser is included. 
I'd love to see more array-backed data structures like `ArrayVec`, *not* falling back to memory allocation like `SmallVec`. Well, I expect them to really come buy after const generics are a thing. Also, I'd be very happy to see a well-optimised augmented interval tree in `alloc`, but well, very special case, so more of a nice to have than a real every-day need.
Really? I would think quite a few C++ projects would get replaced with a Rust implementation eventually, just to ease maintenance (for things continually developed). But partly this is just semantics. Is ripgrep a *replacement* for grep? Effectively for some of us, yes, but of course not officially.
**Quine (computing)** A quine is a non-empty computer program which takes no input and produces a copy of its own source code as its only output. The standard terms for these programs in the computability theory and computer science literature are "self-replicating programs", "self-reproducing programs", and "self-copying programs". A quine is a fixed point of an execution environment, when the execution environment is viewed as a function transforming programs into their outputs. Quines are possible in any Turing complete programming language, as a direct consequence of Kleene's recursion theorem. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Well, i had to look at the LibreOffice code for a few times and i don't think it's that easy to replace it. It would probably affect it's whole oox import module. I will try it, when my app/lib actually does something, but i think it will be hard to sell the benefits of Rust to them.
You can have the same with traits in Rust; that's just return type polymorphism. Haskell has the syntactic equivalent to `.` of Rust in the form of the `&amp;` operator: `4 &amp; print :: IO ()`. The reason `.` can't be reused for this is since it stands for function composition in Haskell. Of course, I could go and redefine `(.) = (&amp;)` and then type `4.print :: IO ()` and the compiler is happy, but don't do this in real code :)
More generally, a [MultiIndexContainer](https://www.boost.org/doc/libs/1_67_0/libs/multi_index/doc/index.html).
From what you are saying, I'm guessing you have many different `structs` that `impl Token` and you want to return a collection/iterator that don't contain just a single type of these structs. That won't work for `impl Trait` since it must resolve to a single type. What you probably want instead is dynamic dispatch, which you can do drug `Box&lt;Trait&gt;`. Alternatively you can just create an enum that contains all your token types, which would be my preferred solution.
Sounds similar to Go's nil interface issues: Go's interface are fat pointers of `(*Type, Object)`. If you cast `nil` to an interface since it has no type you get `(nil, nil)`, a nil `int*` cast to an interface would be `(*int, nil)` and a nil `float*` cast to an interface will be `(*float, nil)`. So despite all of these being the same concrete value (nil) they're not the same "interface value" and [will compare unequal](https://play.golang.org/p/sKHul_DnLGB): var v0 *int = nil var v1 *float64 = nil var p1, p2, p3 interface{} = nil, v0, v1 fmt.Printf("p1: %#v, p2: %#v, p3: %#v\n", p1, p2, p3) // =&gt; p1: &lt;nil&gt;, p2: (*int)(nil), p3: (*float64)(nil) fmt.Println(p1 == p2, p1 == p3, p2 == p3) // =&gt; false false false
This only measures poll() time, not "from completion to creation" like op asked. I believe the following is what OP asked for. struct DurationFuture&lt;F&gt; { inner: F, start: Instant, } impl&lt;F&gt; DurationFuture&lt;F&gt; where F: Future { pub fn new(inner: F) -&gt; Self { DurationFuture { inner, start: Instant::now(), } } } impl&lt;F&gt; Future for DurationFuture&lt;F&gt; where F: Future { type Item = (F::Item, Duration); type Error = F::Error; fn poll(&amp;mut self) -&gt; Poll&lt;Self::Item, Self::Error&gt; { self.inner.poll().and_then(|v| match v { Async::Ready(v) =&gt; Async::Ready((v, self.start.elapsed())), Async::NotReady =&gt; Async::NotReady }) } } 
I've also started something along those lines using k-anonimity but haven't found time to finish it. The goal is to be able to give it CSV exports of keepass / lastpass / 1password databases and have it check all passwords. You can look at the code at https://gitlab.com/samueltardieu/hibp-check/. Right now it only checks the 4th field of a CSV with a header line. If you create `t.txt` wich ,,, ,,,foobar ,,,djflsdjf ,,,xyzzy and run `cargo run --release - &lt; t.txt` you would get: foobar in 11063 instances xyzzy in 3419 instances I had prepared a `cli.yml` with various command line options but my immediate need was to check a keepass export file so I stopped there.
Diversity requires accessible learning materials. What a great point. So this talk has nothing specific to Rust, but is a great introduction to learning (and Feynman!), so highly recommended.
Very interesting to see how one can decompose trait-object-pointers, but not inherently useful I think. I have wanted to construct these fat pointers from their components (objects + vtable) in the past, but of course it's not easy to design a *safe* way to do that.
Not counting how simple and easy it is to write portions of your C software in Rust and vice-versa, but how calling C/Go interoperability leaves a lot to be desired.
I have been playing around a bit with the OpenDocument spreadsheet, and my very early code is at [rheets](https://gitlab.com/silwol/rheets) for general spreadsheet representation and [rheets\_opendocument](https://gitlab.com/silwol/rheets_opendocument/) for OpenDocument specific functionality, namely the export to ods files \(these should probably be in \*one\* repository once I find the time to migrate it\). It does not do a lot by now except for creating a demo document, but I think you get the idea when looking at the [OpenDocument example](https://gitlab.com/silwol/rheets_opendocument/blob/master/examples/demo.rs). You can take a look at the XML serialization there. The structure of the crate is far from perfect and would require a lot of refactoring, as it's a learning project for me. I think some common parts could be refactored and extracted into separate crates which could be shared among projects of this kind, e.g. the zip packaging, as the different OpenDocument types share the same structure.
Incidentally, these are available [in the indexmap crate](https://docs.rs/indexmap/1.0.1/indexmap/) (formerly ordermap).
I think the `slab` crate is a useful collection type that is not in `std`.
what is your book?
&gt; I encountered an issue with fat pointers: two fat pointers pointing to the same address may have a different vtable. is that if they're different types (different interfaces) - wouldn't the same trait for the same peice of memory have the same vtable pointer - or am I missing something (are you talking about unsafe code aswell)
This code would work in dynamic languages, but not in rust: let mapping = { let mut mapping = HashMap::new(); mapping.insert("String", "String"); loop { if condition { break }; change(&amp;mut mapping); // basically I want the `mapping` from line 2 to be updated by `change`, then feed the updated `mapping` to `change` to get yet another updated `mapping`, and again and again. }; } This should output mapping as iteratively changed by "change". 
One of my most successful packages in Ruby world was created to fix a bug I had in another package of mine. The bugfix involved a structure that would be useful for others, so I published it, tweeted about it, and went to bed. The next day, one of my friends went "omg steve, my job today was to fix a similar bug. I used your package and was done in fifteen minutes." Turns out some other people found it useful too. 22 million downloads later, it's possibly the most popular thing I'd ever done.
This could have awesome positive security implications, so go for it! It'd be best if you wrote some simple viewer as well, so people could view untrusted documents with much less fear of being exploited.
&gt; This code would work in dynamic languages, but not in rust: I can't think of any dynamic language that would return a random variable out of a block. &gt; This should output mapping as iteratively changed by "change". Well, there's no reason that construct *wouldn't* work in Rust, but you haven't told us what problem (if any) that you're having. There's also no context for what `change` is doing.
I modified the code a bit to make it more clear. The change() function simply changes the content of the hashmap to something else. In practical terms: I begin with {"a": "b"}, change() it to {"a": "b1"}, change() the latter to {"a": "b11"}, change the latter to {"a": "b111"}, and so on.
First of all, you say you want `HashMap&lt;String, String&gt;`, but you're not using `String`s. That third line should be `mapping.insert(String::from("String"), String::from("String"));` or something equivalent. Secondly, you say the result of `change` isn't written back, *but you haven't shown us what `change` looks like*. Use [the playpen](http://play.rust-lang.org/) to paste a complete example that shows your code, and that when compiled shows the error or errors you don't know how to deal with. Pasting minimal snippets of code without all the needed context just makes it that much harder to help you.
Nice, the only disadvantage I see here is storing passwords clear-text on disk. I know this is not very different from my approach, since these just end up in bash_history. There are also [plugins](https://github.com/topics/keepass-plugin) for KeePass that do this, and I think Bitwarden has it built-in.
Sorry, it's because it's a dummy example, not real code. Did you see the python equivalent (I added it later as an edit)?
 def change(mapp): new = {} for k, v in mapp.items(): new[k] = v + '1' return new
My issue is simply: how do achieve in rust the same behaviour that in python I get by making a variable `global`?
The Python and Rust code are doing wildly different things. &gt; In rust it doesn't work because the result of "change" is not written back to the initial "mapping" variable. That's what `&amp;mut` is for. What you're describing doesn't make sense, which is why I'm asking for the code that doesn't do what you expect it to. If you don't *have* code, how do you know what you're written doesn't work? Besides which, you can absolutely do what you're written in Python in Rust in exactly the same fashion (except for the use of `global` which *looks* redundant, but again, you're not showing the broader context).
I meant your *Rust* code. Like I said, the code you posted was already correct (aside from the strings). [You'd translate the above Python to something like this.](http://play.rust-lang.org/?gist=8d4e23e578c0279784850e83283727e0&amp;version=stable&amp;mode=debug). I still have no idea why you had a global variable, or what `condition` was.
I've been working for several weeks on a GPU-accelerated path tracer as a follow-up to my series of posts on writing a raytracer in Rust. I've run into a bunch of problems with the PTX backend that make me wonder if anyone has ever used it in anger before. It doesn't appear that anyone is actively working on it either. I sort of wish that we had a working group for the PTX backend, or even just a place where I could go to ask questions. Despite that though, I have gotten my path tracer working and I've written most of the first two posts in this series, so I'm getting there.
I haven't had a lot of free time recently, but did get a PR from /u/Aehmlo with 8 new quantities merged into [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis) and am looking at a `rustfmt` PR now.
&gt; I'm accessing two independent slots of t, namely t[0] and t[1], which have nothing in common, so why is that an issue at all? Because the compiler can't prove that. It can't "see through" indexing operations because they're implemented as function calls, and the compiler can't "see through" function calls. The simplest way around this is to swap `t[1]` out of `t` into temporary storage, then swap it back when you're done. That way the two borrows are *provably* disjoint.
Yeah and I tried on nightly and stable... I looked it up on the google, and I am not sure why it wants both versions of core graphics... but 0.3.2 has issues.
&gt; I'm accessing two independent slots of t, namely t[0] and t[1], which have nothing in common, so why is that an issue at all? In short, the compiler doesn't *know* that they have nothing in common. `Vec&lt;T&gt;` supports indexing by implementing the `Index` trait, so, as far as the compiler knows, manipulating a `&amp;mut t[1]` could invalidate the `&amp;t[0]` in some way, similar to how iterator invalidation works.) Try one of the `split_*_mut` methods.
If you check the second snippet, the source is a `Vec&lt;Vec&lt;i32&gt;&gt;`
&gt; is that if they're different types No, the problem occurred with the same interface: https://github.com/Genymobile/gnirehtet/commit/c36fa4d1a1086aa03e56aabae12669f8b1a1a1c4 AFAIU, the compiler generated two instances of the vtable for the same Trait. This is more difficult to trigger on a PoC, but here is one: https://github.com/rust-lang/rust/issues/48795#issuecomment-381834548
So OP basically wants this? fn f2(old: &amp;Vec&lt;i32&gt;, new: &amp;mut Vec&lt;i32&gt;) { new.push(old.len() as i32); } fn f(t: &amp;mut Vec&lt;Vec&lt;i32&gt;&gt;) { let (fst, snd) = t.split_at_mut(1); f2(&amp;fst[0], &amp;mut snd[0]); } fn main() { let mut v = vec![vec![1,2,3], vec![10]]; f(&amp;mut v); println!("{:?}", v); }
Another way is to use a slice's [`split_at_mut` method](rust slice split_at_mut), which will allow you to get two disjoint mutable slices and borrow from each independently. This is one way to "prove" to Rust that you are operating on disjoint elements.
Quines don't take any input, so no.
This really frustrates me about Go to the point where I wish they'd special case `nil`, either by disallowing it as a type (would be gross) or by checking `nil` against the value only (less surprising). Both would be a backwards incompatible change AFAIK, so hopefully it'll get addressed in Go 2. I was hopeful that Rust would be immune to this type of lunacy, but I guess not. I can't think of how OP's situation could happen, so I guess it's a bit less likely than in Go (which I ran into a lot with runtime reflection).
That would be my understanding, and matches /u/ssokolow's recommendation.
I'm not much into algorithms or data structures, but it does fascinate me how much we can improve even fundamental things like hashmaps. But.... How Rust related?
&gt; I was hopeful that Rust would be immune to this type of lunacy, but I guess not. Generally speaking it is because equality will defer to PartialEq/Eq which should be implemented with value semantics, you need to specifically check for pointer equality on fat pointers (slices or trait *objects*) for this to be an issue. I'm not even sure you could impl/specialise PartialEq such that this would work correctly. Though it's also a bit odd that you can convert fat-pointer references to raw pointers and you apparently get a 128b pointer?
Interesting ! I have some concerns about efficiency, though : those `split_` methods seem to create temporary objects, am I right? It's a problem, because that part of my code is a very tight loop.
That's neat; I wasn't aware of that struct. The tracking issue for it is interesting: https://github.com/rust-lang/rust/issues/27751 The comments there address both the use cases people have found for it, and the reasons not to stabilize it (i.e. reasons the representation of this may change with the introduction of new features).
If you haven't profiled something it isn't slow :p
You could just do this with unsafe if you're concerned, as the split_at_mut function does. I don't think split_at_mut should have any more cost than a single assert statement.
Hmm, I'd prefer avoiding unsafe code if possible, but maybe I'll give it a try if the split methods don't satisfy me...
I suppose this might be interesting for implementing in Rust too? That's at least what I thought of when reading the article originally on HN.
It just seems odd, though perhaps there are performance/simplicity arguments for it. But yes, my guess is that PartialEq/Eq should avoid that problem entirely, so it's only if you're doing direct memory compares as in the OP with \`ptr::eq\` you'd actually run into it. I expect I won't run into it, but it seems like it shouldn't even be a concern.
This sounds natural to me. And, if you are not digging too kuch, they are quite similar. Then you see the differences between them and you see what you was looking for. A mental representation of where you push them in your head. 
Ah, didn't think that anybody would know `hibitset` :) I don't work on it very often, so docs and co aren't very good, but the crate itself works. You should note that `hibitset` is not just a usual bitset, but a multi-layer bitset for a sparse data structures. Currently, we're using 4 layers and that's also the unstable bit of the crate; we want to make the number of layers generic, then I'll stabilize that crate.
Isn't possible to change the unwrap_or syntax to something like result.unwrap().or( "other result" ); The or function will take None and return the passed argument. Isn't that more straightforward?
Migrating actix from tokio-core to tokio
Chances are good that the compiler will optimize away the new slices (which after all are only two stack allocated pointers and two lengths), depending on your surrounding code. E.g. a tight loop for consuming a slice in chunks of size N via the `split` methods compiles down to assembly that is as efficient as doing the same thing via the unsafe functions. See [here](https://coaxion.net/blog/2018/01/speeding-up-rgb-to-grayscale-conversion-in-rust-by-a-factor-of-2-2-and-various-other-multimedia-related-processing-loops/#split-at) for an example with corresponding assembly.
Oh, that's good news.
It's reasonable to want to avoid unsafe, just an option.
I wonder if one of these "high-quality hash tables" could replace the hash table implementation that is currently in Rust's standard library. Could a Rust core dev or someone else involved with the standard library comment on this? I am not familiar with the implementation details.
Submissions must be relevant to /r/rust. If the submission mentions neither Rust nor a Rust-related project, then please leave a comment as to why this is relevant to our readers.
And if you are looking for time from first poll to completion, just initialize the instant on the first poll instead of in the constructor. 
I've implemented "to\_str" \(std::fmt::Display\) and "from\_str" \(std::str::FromStr\) for my type. How to I get serde \(specifically serde\_json\) to use to\_str and from\_str to serialize / deserialize?
I definitely think watching this space is interesting to improve on current hash tables, however I was saddened that the blog post was so short: it's basically a teaser for the talk, there's no explanation of *why* the hash table would perform so well. I hope that when the Cpp Now talk goes online, it'll contain more details. And of course, I'd like to see the implementation of Google's fast hash table that Matt Kulundis said was "in the final stages of tweaking" in his CppCon 2017 talk.
As a sibling says, that's something that Rust also has and shares with many languages, but is different to this "method call syntax" thing.
u/Manishearth discussed [a similar idea](https://twitter.com/ManishEarth/status/989291585526419456) on Twitter recently.
I know that this isn't what you're wanting to hear, but that's somewhat expected, e.g. struct X {} impl SomeTrait for X { ... } struct Y { x: X } impl SomeTrait for Y { ... } let y = Y { x: X {} } let a = &amp;y as &amp;SomeTrait; let b = &amp;y.x as &amp;SomeTrait; It's highly likely that `a` and `b` will have the same underlying data pointer (the `x` field of `Y` is likely to have the same address as the whole `Y` object, there won't be any padding/other data before that field in memory) but it is also expected for them to different vtable pointers since the values are of different types. That is to say, data pointers being equal doesn't imply that the trait objects should be equal, and vtable pointers being different doesn't imply that the trait objects are truly different.
And sometimes you can use an assertion to just use one comparison. For example consider this code: pub fn f(t: &amp;mut Vec&lt;Vec&lt;i32&gt;&gt;, f2: fn(&amp;Vec&lt;i32&gt;, &amp;mut Vec&lt;i32&gt;)) { assert!(t.len() &gt; 1); let (fst, snd) = t.split_at_mut(1); f2(&amp;fst[0], &amp;mut snd[0]); } pub fn g(t: &amp;mut Vec&lt;Vec&lt;i32&gt;&gt;, g2: fn(&amp;Vec&lt;i32&gt;, &amp;Vec&lt;i32&gt;)) { g2(&amp;t[0], &amp;t[1]); } Here `g` does not even need to split as `g2` takes immutable references, but it has two conditional branches, the first to make sure `t` has at least one element, and the second to make sure `t` has at least two elements. The function `f` has only one conditional branch because the assertion makes sure `t` has at least two elements right at the start. The rest of the assembly is the same for `f` and `g`; the compiler fully optimizes the `split_at_mut` in this case.
It's included at compile time.
Thanks for posting this. This is the first rust project I've cloned and compiled because it looks simple and self contained. 
That's really nice! I never knew it was possible to retrieve the source code from the packaged file. Very cool :)
First, well done to everyone for getting this out, there are quite a few non-trivial fixes. However there have been quite a few point-one releases the last 18 months, more than previously. Are there any plans, to improve test coverage to fix these things? It’s be fairly disastrous for the Rust2018 project if, two weeks after the big announcement, a bug fix release had to be issued to fix compiler &amp; toolchain bugs. It would unsettle any new users that thought to take a look. 
The most direct improvement would be to get more folks trying the beta regularly, if not nightly as well. A lot of projects do have beta and nightly in their CI config, but this doesn't help issues in developer tools.
Would it be disastrous? Bug-fix point-releases are pretty common among all compilers, especially after major releases. If these breakages were related to long-standing features, then I'd be worried, but all of these issues are either completely unforeseen consequences of brand new features (tests are not really going to help here) or bugs with tier-2 or below platforms where no automated testing is done at all. 
OP might also like this solution: https://crates.io/crates/alias Which may be coming to the std at some point: https://github.com/rust-lang/rust/issues/43038
I'm having an issue with the error: `the parameter type T may not live long enough` I just cannot wrap my head around why adding a `'static` lifetime bound to the generic parameter `T` in ` fn with&lt;T: Component&gt;` below makes it compile. I've read stack overflow answers on the subject but just don't get it. Here's the code use std::collections::HashMap; trait Component { fn type_name() -&gt; String where Self: Sized; } struct Entity { components: HashMap&lt;String, Box&lt;Component&gt;&gt; } impl Entity { fn with&lt;T: Component&gt;(&amp;mut self, comp: T) -&gt; &amp;mut Self { self.components.insert(T::type_name(), Box::new(comp)); self } } fn main() {} P.S. I suck at lifetimes if it's not already obvious. 
It's been every other release for the past 6 releases. That's significantly higher than normal (for rust). In post 1.0, there's been only 5 ".1" releases -- the three from the past 6 and 12.1 and 15.1. Of course, the sample is still smaller enough that it's probably happenstance (randomness does yield natural clusters) -- I haven't bothered to run the stats on it though.
You’re right, it’s three in the last year. It’s also three out of the last five releases. More constructively: Is anyone looking at the list of Rust open source projects that bors compiled for integration testing? Do they still have a representative list of features like impl-traits, ?-in-main etc. Is there a plan to cut a Rust2018 Developer Preview, with a Reddit announcement. Is there a working group to take select Rust projects and have them build with Rust2018 Developer Preview? I realise the difference between “developer preview” and nightly is mostly marketing, but with so many new features, including async, and with a plan for a larger than average marketing push, is the plan to use the standard testing, unchanged? 
Well Rust2018 seems to me to be targeting a larger than average marketing push. A big part of Rust’s story is that it’s safe and stable. A point release two weeks later would undercut that message, and thereby undo a large part of the marketing push. Swift rarely releases a point release two weeks after a major release, same for Go. These are the main competitors for mindshare. If you want someone to learn a whole new language, I feel you need to aim for excellence. 
Suggestion: Change "Rustfmt stopped badly formatting text in some cases" to "Rustfmt text formatting error fixed" 
for my area of interest there is one serious choice: C or C++ *, and Rust is the only thing you could consider as an alternative, because of it's lack of GC. (yes I think of C as a subset of C++, or C++ as a code-generator for C)
Isn’t the original type Vec&lt;Vec&lt;T&gt;&gt; so you could mutate the Vec inside the Cell?
I'm going to release a new version of [bioyino](https://github.com/avito-tech/bioyino) after some production testing. If I have more spare time, going to improve [raft-tokio](https://github.com/Albibek/raft-tokio) - a tokio-based generic Raft implementation.
Go has a release cycle of six months, compared to Rust's six weeks. A point release after two weeks is quite reasonable. The stability message is about not breaking your code, not that you won't see regular compiler updates.
This is because of how lifetime elision works for trait objects. If you expand elided lifetimes on `Entity`, you get this: struct Entity { components: HashMap&lt;String, Box&lt;Component + 'static&gt;&gt; } That is - if you don't specify a lifetime, a trait object has to be `'static` by default. Therefore the compiler asks `T` to be `'static` too, so that `Box&lt;T&gt;` could be converted to `Box&lt;Component + 'static&gt;`. You can fix this by explicitly making `Entity` work with any lifetime: [playground](https://play.rust-lang.org/?gist=f18bd49928283d6b0291646c38dc1a21&amp;version=stable&amp;mode=debug).
&gt; Swift rarely releases a point release two weeks after a major release, same for Go. It's not an easy comparison because Go does twice-yearly minor releases, and Swift does annual major increases (with notoriously more regular breakage than either Go or Rust). Looking at https://golang.org/doc/devel/release.html, measuring for the past year (since Go 1.8), Go has had 18 releases (3 minor versions, 15 patch versions); in the same timeframe (since Rust 1.15), Rust has had 16 releases (12 minor versions, 4 patch versions).
That's awesome! I work on a Rust game engine called [Amethyst](https://www.amethyst.rs), and I was curious if you could review it and let me know how you feel about it. I'm mostly wondering how you think it compares to Piston. 
That's being discussed in https://github.com/nrc/dev-tools-team/issues/38 too.
The crate `core-grapgics` seems to be a deprecated dependency in MacOS. I think you can use [cargo\-tree](https://github.com/sfackler/cargo-tree) to see how these dependencies are pulled in and urge the authors to upgrade to later minor versions or migrate to [core\-foundation](https://github.com/servo/core-foundation-rs).
Your sample shows that the vtables are different for different trait implementations. As you say, this is expected. In the issue I encountered, vtables were differents for the very same object (pointers retrieved from several _related_ `Rc&lt;RefCell&lt;T&gt;&gt;`). However, your sample is very interesting in that it shows that changing the semantic of `ptr::eq()` (or `==`) for fat pointers would be unsound.
Gotcha. Can really only think of kernels and embeded real time systems that would be true?
Thanks! I really appreciate this, but I have to warn you this is not meant to be the cleanest rust code. Beware of what you read :\)
If the failure mode is that they do nothing, then probably just expose it as is. If there's an actual race condition, eg. deadlocking, memory unsafety, etc. then you definitely want to prevent that.
I'm not sure of the best way to work around this problem in particular, but there is a general convention in Rust FFI crates that you can follow here. First you create a `foo-sys` crate that just wraps the C API with unsafe `extern` declarations. Then you create the `foo` crate with a dependency on `foo-sys`, which further wraps those APIs in a safe way. Usually the `foo` crate has to make some assumptions (like depending on the standard library) that won't work for every possible caller, but then the callers with special needs can use `foo-sys` and read the docs very carefully.
I haven’t found anything like that yet, calls either get ignored or are reorder leaving the LED device in the wrong state.
&gt; If you want someone to learn a whole new language, I feel you need to aim for excellence. Perfect is the enemy of good
Aphorisms don’t absolve the search for continuous improvement. 
I have a sys crate with the raw c functions, but since the SDK only supports Windows and dynamic linking and the DLL is not installed to Path, I look up where the DLL is installed in the registry and then load it manually with `LoadLibrary()` from the sys crate.
game engines: including the construction of command lists for the GPU, and setup of GPU assets. but the scenarios I've seen, the performance critical parts (requiring careful control over memory layout hence when and where things are allocated) because surprisingly widespread
&gt; why do you want to compare trait objects for equality In fact, I just want to remove from a vector the Rc&lt;RefCell&lt;…&gt;&gt; associated to the pointer I have. The actual code is here: https://github.com/Genymobile/gnirehtet/blob/v2.2.1/relay-rust/src/relay/router.rs#L148-L162
before you can do that you need an html file with a canvas, that references you js file, a web browser, and so on. pretend you are 8 years old. its more complicated than typing "Circle" then tap f5 
are there return values that you can use to determine when a call has finished?
One way to clean up the nastiness is this: - Model what a robust SDK would do, synchronize all accesses through a `ReadWriteLock`, last write always wins). It doesn't actuall talk to the SDK yet, just tracks the state internally. - When the internal state changes, do the following: -- If the last write was long-enough ago, send the new state. Record when that call happened. -- Otherwise register a callback (many different ways to do that, but a timer-thread running sleep_until or something is a good way to achieve it), which will try sending the state again once enough time has happened.
The problem is that std depends on system calls. Which on a unknown target, won't work 
I think you're making assumptions here that other people don't share, and so things that seem like improvements to you might seem like "tradeoffs that we don't want to make" to others. In particular, I think most people are generally ok with bugfix releases happening at the current rate, or at least they don't see it as disastrous. Rust 2018 is expected to be a version of the language that people should feel comfortable targeting for a long time. But it's not expected to be a particular compiler binary that people use without updates.
No, it seems like the calls return before the actual commands are received by the LED device and that commands get reordered somewhere.
I have a few questions about benchmarks provided by the `test` crate. When I put nothing but `vec![1u64,2,3,4,5,6,7,8]` into the Bencher, the benchmark says that it take tens of nanoseconds per iteration. Is this measuring the time it takes to allocate the vector? I have a Vec of random `ApInt`s from the `apint` library and am trying to measure the time it takes to perform a binary operation on them, but not including the allocation time or anything other than the operation. Where should I put the the Vec, operation, and the Bencher in relation to each other?
What are you compiling for? What's your target? 
I found the secret to P=NP guys! Write a SAT solver, but then don't ever run the code!
For that level, [A-Frame](https://aframe.io/) might be appropriate.
Nice!
``` fn main() { Foo.bar::&lt;u32&gt;(0); } ``` Is this allowed syntax? Shouldn’t be `Foo::bar::&lt;u32&gt;(…)`? Also, `Foo::bar` takes two arguments.
I'm working on [org-mode](https://orgmode.org/) library for rust. I want to parse *.org documents, have API to add, delete and modify existing nodes (for example, sections, TODOS, dates etc). Then - after the `liborg` part - I want to create progressive Web Application (codename `pOrg`) with rust backend (using my library). I know it's a lot. I have some experience in making parsers and compilers and I think i know what I'm doing, however: * OrgMode is very like Markdown format - I think it is context free (not sure), but definitely ambiguous. And parser cannot fail! If user forget to close brackets I must parse whole thing as text, not broken link for example. This is one of the reasons why Markdown does not have PEG. * Thats why I decided to use parser combinators, however I'm not satisfied with Nom or Combine (altough the latter is very good IMO and very close to ideal) - so I decided to use my own based on `impl Trait`... * ... and right now I think I found some strange bug in rustc linked to `impl Trait`. Cause some unit tests should be deterministic but sometimes fail (pure random). My first impression is sometimes rustc generates invalid code, but I need to investigate it more.
This looks cool. I will be sure to look at it more deeply if i eventually get to write a converter of some sorts.
Afaik having a 6 week release schedule is working out well, and haven't heard anything about changing that. Personally I'm quite happy with the current release cycle. Between "stable", "beta" and "nightly" there's little to wish for in terms of releases. Probably a thing I (and others) could be better at is testing the beta releases. If we all did a better job, we could help reduce the number of regressions even further :D
Damn, that would have been too easy, eh? Can you query the state of the command?
For anyone wanting to know, printed books ship the last week of June.
So your build error refers to the `compiler_builtins_shim` crate, which the Rust build system uses instead of depending on `compiler_builtins` directly. Interestingly enough, the [build script](https://github.com/rust-lang/rust/blob/master/src/rustc/compiler_builtins_shim/build.rs) for the shim crate is blank, and apparently intentionally so. Not sure why that's causing a problem for you though since apparently it's not a problem during a normal rust bootstrap.
No, the calls/commands change the state of the LED device, but I have no way to know the if a command was received or to get the state of the device except physically looking at the device to see if the LEDs change.
Woh that turbofish + 1-inhabited value got me confused for a few secs! :D
Yes, it could, and IIRC in early days I switch several times between the two (I don't remember the reasons). Of course, not using a trait would _avoid_ the fat pointers comparison issue, but not _solve_ it ;-)
If nobody else does, I am going to make an n-spatial tree crate for R trees and barnes hut trees once const generics come out. Until const generics come out it would be absolutely painful to make something like that. I need it to run distributed spatial simulations for my emergent phenomena library collection (https://github.com/evomata). I am eagerly awaiting the release of const generics because my next project is going to be such a simulation.
If you are returning the vector to the `Bencher`, then yes - compiler won't optimize it out and therefore it measures how long it takes to create the vector. If you want to measure just the operation time, you can create initial values outside the closure you pass to bencher: #![feature(test)] extern crate test; extern crate apint; use test::Bencher; use test::black_box; use apint::ApInt; #[bench] fn bench(bencher: &amp;mut Bencher) { let a = black_box(ApInt::from(123u64)); let b = black_box(ApInt::from(456u64)); bencher.iter(|| &amp;a + &amp;b); } You should pass initial values through `black_box` so that the compiler wouldn't optimize the computation to a constant, and return the result value to the bencher so that the compiler wouldn't remove the computation completely. 
I suspect the reason we've had point releases more has had more to do with infrastructural changes making it easier to do point releases (for example, actually having a release team) than with having more bugs. I can't be sure though.
I linked an r-tree crate in my post, I don't know if you saw that
&gt; but I think I need to make sure I close the TcpStream when my struct which holds the stream goes out of scope as TcpStream itself does not implement the Drop trait. [From the docs](https://doc.rust-lang.org/std/net/struct.TcpStream.html): &gt; The connection will be closed when the value is dropped. So I think you don't need to do anything special?
Yay!
There will be a preview of 2018. The announcement will probably make it to reddit, given that most announcements do. We’ll have multiple releases after the preview purely for polish.
How embarrassing. You are correct. I should have just read the text rather than looking if it implements the drop trait.
Is there any reason rust can't look at what structs might be used for that type and do the enum trick in the compiler?
Am playing around with porting to a vxworks simulator - this isn't exactly something professional 
If you can't know how long to wait, you're simply out of luck and there's no way to use the library correctly, much less write bindings that allow using it correctly from Rust. So I'll assume you do know how long to wait after each given operation (or at least a lower bound). The right way to expose this in Rust is by writing a Future-based library API where operations return futures which only resolve to complete after the delay time appropriate for an event. You can either have a queue under the hood to allow API consumers to construct actions without throttling, or you could have a RefCell-style dynamically-checked interface to prevent concurrent existence of multiple borrows on the LED resource, and move ownership of that resource between futures with chaining. Honestly, I would advocate reverse-engineering what it sounds like is a disaster of a library that you're trying to bind.
Please note that there is also a rather bad soundness bug that this release does *not* fix, with the new match ergonomics: https://github.com/rust-lang/rust/issues/51117
that confused me as well
This doesn't appear to be a new bug. It's just a slightly more painful manifestation of an old bug. MIR borrowcheck will fix this. You can audit your code for this pretty easily by enabling `nll` feature. This does look like it's even easier to trip over now than it used to be.
How did such a library ever become production-ready?
When is `::std::borrow::Cow&lt;'a str&gt;` less favourable than `String` and `&lt;'a str&gt;`?
Bursty api calls would cause crazy allocations unless the queue is bounded. Could achieve the same effect by creating a wrapper object and storing some timestamps, then only sleeping when your calls start to get too close together. No reason to burn memory just to do nothing. 
How does it choose which field lines to draw?
How is it not a new bug? It was not possible to write the bad match before because the pattern needed &amp;/&amp;mut.
I just updated and noticed nightly and beta are still versioned as `1.28.0` and `1.27.0`. Is the `1.26.1` patch version also ported to nightly/beta?
Are you expecting them to be 1.28.1 and 1.27.1? The .1 is an increment over the first .0 release, it isn't a marker for what changes a branch includes, and those branches are really pre-releases for those versions, not actual releases. I see the nightly versioned as `1.28.0-nightly` which is, AIUI, a semver-approved way to indicate a pre-release.
Since when do hardware companies worry about software being production ready? 
&gt; takes a generic T and checks if it's "None" `None` is not `null`. The only type that can be `None` is `Option`, *nothing else*. Even if that weren't the case, `unwrap` *panics if `result` is None*, so it wouldn't make it to the `or` call anyway. &gt; Is there actually an "or" function in rust? [One or two](https://doc.rust-lang.org/std/index.html?search=or). The relevant one is [`Option::or`](https://doc.rust-lang.org/std/option/enum.Option.html#method.or).
I wasn't really sure how the numbering would work. Since beta/nightly aren't actual releases that makes sense that the patch wouldn't affect their own versioning. Are there expectations for when the 1.26.1 changes are merged into nightly/beta? I'm just curious how the process works.
Hardware is only as reliable as its software. They should be very concerned about quality.
Very neat trick! See also the [if_chain](https://crates.io/crates/if_chain) macro. 
Another use case for this (and one that caught me out personally) is using fat pointers as keys in a BTreeMap. The intuitive expectation would be that comparing two fat pointers which point to the same instance of a trait should return true, but that's not the case. At the very least we should find a way to be very explicit about this behaviour in all the documentation as it seems to surprise everyone unfamiliar with the compiler internals.
&gt; Any other neat (ab)uses of Rust syntactic sugar? There's the "move expression" syntax `{expr}`, which forces a move of `expr` rather than any implicit re-borrowing. Very handy for moving mutable slices around when you're re-borrowing the tail in a loop. I also frequently use `'block: loop { stmts; break 'block expr; }` to get named blocks (at least until 2046 arrives).
The thing that annoyed me the most was not being able to use Rust 1.26 on FreeBSD. This is something I could've helped since it's not a Tier 1 platform and has relatively few users, but I don't know enough about the issue to know if it was present in the beta builds. I'm going to commit to using the beta builds in development and the release for production builds. I'm not interested in using nightly for production stuff because I don't want try rely on features that won't make it to release anytime soon (or ever), but I can definitely test the beta packages.
Is there talk of resetting the minor number at each edition? Not that it matters too much, but I find it more difficult to keep track of changes between versions when the numbers get big. I'm not sure what it is, but smaller numbers seem to be nicer to deal with than larger ones.
I'm like 90% sure I saw your issue on github, and was trying to figure out what you did do you have any advice/commentary? I'm a bit out of my element. Did you successfully get your cross-compile working? Also, for some reason, previous libraries compiled fine, idk why this is an issue for me now
The vrings are not gonna be exported in /sys or /proc. Generally, a kernel driver will expose an interface for RPMsg communication after remoteproc loads the ELF binary on remote core/processor. I have worked with NXP's Vybrid and iMX7 processors and NXP had small custom drivers exposing them as tty ports. If you are interested in implementation, see [here](http://git.freescale.com/git/cgit.cgi/imx/linux-2.6-imx.git/tree/drivers/rpmsg/imx_rpmsg_tty.c?h=imx_4.1.15_1.0.0_ga). TI has documentation on it's wiki and it seems the interface they expose it through /dev. See the documentation [here](http://processors.wiki.ti.com/index.php/PRU-ICSS_Remoteproc_and_RPMsg) and [here](http://processors.wiki.ti.com/index.php/RPMsg_Quick_Start_Guide). At the moment I can't trace which is the driver implementing this /dev interface for TI's processors. 
You wouldn't really have a solid way to name the variants of the enums if it did it implicitly. But in addition rust favors not doing implicit conversions like that, so it leaves the creation of the enum to you.
&gt; In particular, I think most people are generally ok with bugfix releases happening at the current rate, or at least they don't see it as disastrous. People who post here are generally ok with it, because we're involved and bought into Rust. This is not true of all users and especially not true of prospective users. 1.25 in particular had a bug that was a pain point for a few popular public crates including, full disclosure, one maintained by a personal friend of mine. The amount of time and effort she spent trying to communicate back and forth with the dev team and the amount of stress involved with trying to get it fixed was much higher than she would have liked. I'm not suggesting that things should necessarily grind to a complete halt while every crate is double checked or whatever. I'm simply pointing out that glibly suggesting that no one really cares about this stuff is both wrong and wrongheaded.
To be fair, Logitech doesn't worry that much about their *hardware* being production ready, either. I don't think I've ever had a high-end Logitech mouse that didn't have some sort of semi-common, crippling flaw in it. I write this as my *current* high-end Logitech mouse is totally unusable due to a stuck button disabling the motion sensor. (To forestall the obvious question: because no one *else* makes comparable mice that are, even with the absurd problems, that good.)
You can also have a look at calamine crate for a sheet oriented implementation (only readers). Covers both XML and binary versions.
I could try that. Last time I looked ndarray wasn't in use in any such libraries. Currently I am making extensive use of those in nalgebra. Thanks for pointing that out! However, I would really like versions of these using const generics instead because ndarray is quite limiting. I would also like to create abstractions myself and I don't want to keep having to use ndarray. Currently with nalgebra I haven't been able to separate out my LSTM implementation from my simulation because templating with multiple dimensions for matrix multiplications resulted in some really peculiar recursive type errors. I don't think reasonable abstraction will be possible yet without const generics. However, that library can probably let me get started on my next project before I separate the simulation bits out into their own crate.
This would also work: ``` fn f(a: A){ if let Some(B { c: Some(C { d: Some(D { field: Some(f), ..}), ..}) , ..}) = a.b { println!("{}", f) } else { // log the missing field } } ```
I've been working through the rust book, I have a question regarding using FnBox to wrap a FnOnce so that you can pass the closure to threads and have the call it, as seen near the end of this page. https://doc.rust-lang.org/book/second-edition/ch20-02-multithreaded.html I think I'm clear on why we can't invoke the closure directly in the thread (because the definition of FnOnce requires the closure to be moved on invocation, and we don't know the size of the closure at compile time). I'm confused as to why that is not allowed, but it is ok to move the closure inside the FnBox, as you see with fn call_box(self: Box&lt;Self&gt;) { (*self)() } Perhaps something to do with the fact that the compiler knows that the Box will know how big the data it holds is and so is able to defer some details of the move until runtime?
[removed]
For the 1.26.1 release, there has been a [post on reddit](https://www.reddit.com/r/rust/comments/8m8yaq/rust_1261_prerelease_testing/) asking for feedback. I've heard that this reaching out was quite useful. I can't recall similar posts for Rust beta. Maybe make a post on reddit, asking for feedback like 2 weeks after every stable release? Then attention on it won't conflict with attention on the stable release, which naturally is larger.
wait... ? is implemented for options??????? ... 
&gt; There's the "move expression" syntax {expr}, which forces a move of expr rather than any implicit re-borrowing. Very handy for moving mutable slices around when you're re-borrowing the tail in a loop. Do you have an example of this? It sounds like something I've wanted.
Yeah\- `?` is versatile, which is the main difference between it and the old `try!()` macro. The trait isn't stable to implement yourself yet, but you can see the existing implementations for `Option` and `Result` [here](https://doc.rust-lang.org/std/ops/trait.Try.html).
As of [1.22](https://blog.rust-lang.org/2017/11/22/Rust-1.22.html)!
Well of the rust compiler doesn't support it. Then you won't have stdlib
Oh, so I can't try!() options, but I can use ? with them?
[Here's a contrived example](http://play.rust-lang.org/?gist=10ff1d71893cf890bcdc8be3e4505caf&amp;version=stable&amp;mode=debug). To see the effect, try replacing `{s}` with `s`.
This [blog post](https://bluss.github.io/rust/fun/2015/10/11/stuff-the-identity-function-does/). 
In fact, deferring the details until runtime is what must be avoided! The compiler knows the sizes of things at compile time, but once the closure is stuffed into a `Box&lt;FnOnce()&gt;`, the size is erased until runtime, so it can't be moved out. Now with `FnBox`, the `call_box` definition is within a `impl&lt;F: FnOnce()&gt; FnBox for F`, and we see here that `F` always has a defined size (else it would say `F: ?Sized + FnOnce()`, so the move can always be compiled correctly. 
*Five* borrowck errors, that's impressive. 
I/\*t\*/ w/\*ould\*/ a/\*nnoy\*/ m/\*e\*/, b/\*ecause\*/ i/\*nterspersing\*/ s/\*ymbols\*/ w/\*ith\*/ w/\*ords\*/ i/\*s\*/ j/\*ust\*// a m/\*ess\*/.
Wonder why you want to write like this? I didn't see any advantages
Yeah! That's the only real difference between the operations besides syntax. `try!` expands to a Result-specific match statement while `?` calls the Try::into_result method, matches on that, then uses Try::from_error or just passes the Ok value through.
\*h/\*ot\*/ m/\*ess\*/
The *primary* problem I see \(and I see several, including that it isn't very readable as code\) is that those comments wouldn't make it into the [rendered docs](https://docs.rs/regex)
That’s not how editions work; that’s the compiler version, distinct from editions. Rust 1.40 or whatever, just picking a random version, will compile both Rust 2015 and Rust 2018.
If you really want to use one-letter names inside the function body for conciseness, I think a more readable version would look something like... ```rust fn error_wrong_type(type_recieved: &amp;str, expected_type: &amp;str, problematic_key: &amp;str) { let t = type_received; let e = expected_type; let k = problematic_key; eprintln!("JSON error: Key {} is {}, not {} as expected", k, t, e); std::process::exit(2); } ``` That way the names are actually comprehensible from the outside (e.g. in docs) and you can also easily read what each single-letter name means inside the function body.
Thanks, I made that! What did you use it for?
That helps, but wouldn't F also inherit the ?Sized trait bound from FnOnce()? Given the implementation here: impl&lt;'a,A,F:?Sized&gt; FnOnce&lt;A&gt; for &amp;'a F
You're using an OLD version of serde. You should be using serde 1.0, not 0.9, and that's what's causing the problem. The CSV crate is expecting a type that implements serde 1.0's Serialize trait, which your type doesn't.
I just checked and no version of the csv crate supports serde 0.9. You need to use serde 1.0 if you want to use csv.
currently, i don't think serde_derive offers an easy way to do this via attributes, but its not that hard to write your own serialize and deserialize impls that hand off to `to_string()` and `from_str()`respectively [playground link](https://play.rust-lang.org/?gist=1c7e0d4550d8d5e3790dcfe5ae658c99&amp;version=stable&amp;mode=debug)
&gt; So, in general, how do I port the system calls? You probably would port libc.
can you talk about how you went about implementing this? I can do all sorts of programming, but I've never been able to get into computer vision.
&gt; There will be a preview of 2018. The announcement will probably make it to reddit, given that most announcements do. Cool, that's great to hear.
Is this stuff in the book now? When i was learning, try! was introduced first, so I've always just used that instead of ?, this is the kind of feature i've wanted for ages! Glad to see it got added.
xacrimon, I feel like you are missing that mywaterlooaccount is trying to *add support* for a new target, and is asking for instructions on how to do that for Rust.
Trying to figure out how to test my concurrent union-find.
Ooooh
My kingdom for proper monads!
I don't think the book covers the exact semantic differences between `try!` and `?`, but it does show the operator in use in the "error handling" section ([chapter 9.2](https://doc.rust-lang.org/book/second-edition/ch09-02-recoverable-errors-with-result.html#a-shortcut-for-propagating-errors-the--operator)). I'm guessing it doesn't compare them since it's more of a teaching resource than a technical reference for all std features. For new code, the `?` operator is always preferred to `try!` since it has upsides like working on options and readability, and almost no downside. (it can be a bit cryptic looking, but if you know what it does it gets out of the way nicely). I think this is why the second edition book completely replaced all mentions of `try!` with `?`. The detailed design and future plans for the operator are covered in [RFC 1859](https://github.com/rust-lang/rfcs/blob/master/text/1859-try-trait.md), though, if you're interested.
I think this is fine if you do it with `match`: match a { A { b: Some(B { c: Some(C { d: Some(D { field: Some(f) })})})} =&gt; { println!("g matched the pattern to {}", f) }, _ =&gt; panic!("field must not be None"), } (note that rustfmt's defaults aren't too happy leaving the pattern on a single line, but it's not nearly as deep a right-ward pyramid than what you shared above) playground: http://play.integer32.com/?gist=56f4a71f9e7cb6731d9489d98eec9e5c&amp;version=stable&amp;mode=debug
The inconvenient is that this only works if you only need `i` and not the intermediary values in the body.
I am still kind of sad that Rust didn’t pick the second form instead of using third one.
Solving Advent of Code 2018 day 12 part 1. It is pretty much the definition of the union-find problem.
The compiler should probably make an effort here to give a more explicit error message. I've had the same kind of error in the past, and they're really non-obvious to figure out. OTOH, the compiler should be able to detect that there *is* an implementation of a similarly named trait in another version of the same crate in the pile of crates used directly or indirectly.
Perfect is the enemy of average.
maybe it would be better to move this huge heap of conditions to a separate function and call this function from the first condition? Steve McConnel in "code complete" advises to do like that
Often some of those are really function calls, and this doesn't work in that case.
I could swear there is a bug for that, but I can't find it.
I'm not sure I would go so far as to call it 'computer vision' ;) QR Codes were specifically designed to detect them quickly; it's nothing like face recognition or something like that. They (are supposed to\*) have nice black/white blocks, a white border around it etc. The big squares in the corners have a black/white pixel ratio of 1:1:3:1:1 in any direction (even diagonally!) so they can be found just by doing line scanning. Fortunately there are [some tutorials](http://aishack.in/tutorials/scanning-qr-codes-1/) that can help you get started and the [official ISO spec](https://www.iso.org/standard/62021.html) also has a nice section on how to do it. There are also [scientific articles](https://www.researchgate.net/publication/221337868_Fast_QR_Code_Detection_in_Arbitrarily_Acquired_Images) using fancy methods that are supposedly even faster but I haven't gotten into those yet. The hardest part is probably the error correction that involves Reed-Solomon codes using Galois Fields. The documentation is very [rest of the fucking owl](http://knowyourmeme.com/memes/how-to-draw-an-owl) about it unfortunately. Some googling, example code from [other libraries](https://github.com/josephholsten/libdecodeqr) and lots of trial and error helped there ;) \* [Artsy fartsy QR Codes](https://cdn.dribbble.com/users/1398774/screenshots/3184110/__.gif) are the worst and any scanner would have a lot of trouble deciphering that!
Explain like I'm 5 please, what's the difference between `String` and `str`. For instance, as though you're going to explain it to somebody who's only ever done Javascript programming, has no knowledge of the stack and heap and so forth. I've got almost 20 years experience but no particularly low-level experience but regardless can understand at a high level what the difference is from my reading online. Problem is, I now want to explain it to those with much less experience, and am at a loss. Thanks in advance. 
It's a much harder problem (of the exhaustive search kind) than the "type conflict between two types with the same path" (which we've solved already). It'd probably help to cache a set of duplicated crate names to begin with, and maybe even put the version number in the error message.
I've not tested it, but this should also work: if letSome(f) = a.b.and_then(|b| b.c).and_then(|c| c.d).and_then(|c| c.d).and_then(|d| d.field) { ... } Not very pretty though.
Is it possible to set cargo to always run `cargo clippy` as `cargo +nightly clippy`? A workaround is to set an alias in bash. I'm wondering if there is a cargo solution though.
I think it's a little easier to explain for arrays first. `[u8]` is "some bytes" (in general, `[T]` is "some `T`s"). If you have "some bytes" stored in memory, whether that's in an array literal, a fixed-length array, a dynamic array, whatever, you can point at those bytes and say "here are *some bytes*". It doesn't care how or where those bytes are stored, only that they are, in fact, bytes. The consequence of this is that you can't directly own a `[u8]` value, because it doesn't describe how "some bytes" is being stored. You always have to refer to a `[u8]` behind some kind of indirection. That indirection is what encodes how those bytes are stored, what are the ownership semantics (shared, unique), how are they cleaned up, *etc.*. So `&amp;[u8]` is an immutable borrow of "some bytes". `Box&lt;[u8]&gt;` is "some bytes" that are uniquely owned. `Rc&lt;[u8]&gt;` is "some bytes" that have shared ownership. The most general way of creating "some bytes" is to use `Vec&lt;u8&gt;`. That's a dynamically resizable array of bytes. You can add bytes, remove bytes, mutate bytes, *etc.*. However, deep down, it's just another kind of wrapper around `[u8]`. You can even turn a `Vec&lt;u8&gt;` directly into a `Box&lt;[u8]&gt;`, or borrow the insides of a `Vec&lt;u8&gt;` as `&amp;[u8]` or `&amp;mut [u8]`. So, another way you can look at it: `[u8]` is a common, binary layout that can be shared between any kind of storage for arrays of bytes. `Vec&lt;u8&gt;` is a general way of creating and owning an array of bytes. All of the above more or less directly applies to `str` and `String`, which are effectively just `[u8]` and `Vec&lt;u8&gt;` with one added requirement: their contents must be valid UTF-8.
New challenge: maximize the ratio of borrowck errors on the number of character changed
For fun I have tried to implement the logic naively on my side too. The rendering is just printing. 260 lines of code. [https://gist.github.com/rust\-play/20d555a19f5d93301ce2ba32b8aebfaf](https://gist.github.com/rust-play/20d555a19f5d93301ce2ba32b8aebfaf)
Coming from Go, I'd expect something like "if not let ... { return }" could possibly flatten the pyramid. I've found [an RFC for something like this](https://github.com/rust-lang/rfcs/pull/1303), closed as postponed in Feb 2016. However, based on [one comment with an example workaround](https://github.com/rust-lang/rfcs/pull/1303#issuecomment-303396592), I started to wonder — would it be possible to write a macro for such an "if not let" expression? Or does one maybe exist already? I'm a total Rust greenhorn as of now, but still a fan and interested in it, so I totally don't have an idea if such a macro would be possible or how to try writing it. That's why I'm asking! Is this doable? Specifically, I mean I understand it is (?) currently possible to write something like: let b = if let Ok(b) = a.b { b } else { return } let c = if let Ok(c) = b.c { c } else { return } Instead, would it be possible to have a macro, say `unless_let!` usable like this: unless_let! Ok(b) = a.b { return } unless_let! Ok(c) = b.c { return } ?
Putting version numbers of the crates/traits when there is a conflict would be amazing
I'd use typedefs instead: type TypeReceived&lt;'a&gt; = &amp;'a str; type ExpectedType&lt;'a&gt; = &amp;'a str; type ProblematicKey&lt;'a&gt; = &amp;'a str; fn error_wrong_type(t: TypeReceived, e: ExpectedType, k: ProblematicKey) { eprintln!("JSON error: Key {} is {}, not {} as expected", k, t, e); std::process::exit(2); } Note that these provide no type-safety, they're type aliases not newtypes: fn main() { error_wrong_type("foo", "bar", "baz"); }
Fair enough; I completely ignored what the function was actually doing, or what the names were supposed to mean. 😅
It's not the monads OP is looking for, it's the do block.
Well, this kind of things is being discussed here: [https://github.com/rust\-lang/rfcs/issues/2414](https://github.com/rust-lang/rfcs/issues/2414)
I'm prettty sure I have access to an ISO compliant libc (that is, Dinkumware). However, VxWorks doesn't have a native compile, but I'd imagine if I poked around I could retrieve libc from the target would I just put it in /rustc/libc_shim? Also, that still doesn't fix the error where for whatever reason xargo doesn't like compiling the empty compiler_builtins crate
That's actually the first thing I thought when I saw this pyramid too, "if this was go it would be flat".
That's a good point. I was thinking more about bug fixes like accidental stabilization.
Sorry for not getting back earlier, I was at [RustFest.eu](https://RustFest.eu) :\) I think it was two\-sided. I like the mix of advanced data\-organization techniques that make a backup system a fun playground, along with the strict requirement that it actually works \(I like property based testing, so that is a fun challenge too\). On top of that, I wanted a system that was flexible enough that I can pick my own cloud backend \(like AWS or Google\), while still protecting my privacy. And of course, it should do so fairly efficiently. I have not looked in a while, but when surveying the options years back, they were either not very flexible, inefficient \(uploaded huge files synchronously, or did not manage to reuse data after a restart\), or they didn't support deleting data \-\- they were all missing something. So I decided I would use the proprietary tarsnap \(though I believe Hat will be faster\), while slowly working on my own thing as a fun side\-project, which is now almost usable.
yeah \`s.as\_bytes\(\)\` works equally well. But the point is basically that the \`impl From\&lt;&amp;String\&gt; for &amp;str\` seems to disappears when importing env\_logger...
 fn people(w/*ho*/: &amp;str, d/*o*/: i32, t/*his*/: usize) { if w.is_empty() { println!("also do") ;}{ else { println!("this") ;}}
[@llogiq's latest tweet](https://i.imgur.com/sroTka7.jpg) [@llogiq on Twitter](https://twitter.com/llogiq) - ^I ^am ^a ^bot ^| ^[feedback](https://www.reddit.com/message/compose/?to=twinkiac)
Correction: I saw [this post](https://github.com/japaric/xargo/issues/216) and thought you in specific would have some great insights - mind if I pm you?
This is great! I've actually already been working on a fat32 lib \[fat\-rs\]\([https://gitlab.com/susurrus/fat\-rs](https://gitlab.com/susurrus/fat-rs)\) which is read\-only right now. I was planning to come back to it, but it looks like another library \[fatfs\]\([https://crates.io/crates/fatfs](https://crates.io/crates/fatfs)\) now exists on [crates.io](https://crates.io). Is the plan to integrate that library with Redox or what's the plan for the underlying FAT implementation?
Why are bigger numbers better than smaller ones? If anything, over time, it *really* demonstrates our commitment, IMHO.
There is: https://doc.rust-lang.org/std/option/enum.Option.html#method.or And in fact, the function you're describing exists too: https://doc.rust-lang.org/std/option/enum.Option.html#method.unwrap_or_default
We are currently evaluating the various libraries available. There is also a very slight possibility of having Redox's own FAT32 library. Will post another update on this soon :)
Field lines are drawn starting from the border of charged tiles, using a moore neighborhood.
[Porting tokio to redox - week 1](https://www.redox-os.org/news/rsoc-porting-tokio-1/) – the TWiR link is dead by the way – is not exactly a GSoC Project ... its a RSoC project
Ah, I see it now. The lines originate at the centres of the squares immediately surrounding red charges.
Hey guys, I just released this crate which is a procedural macro for translating rust structs into other languages for helping write FFI libraries. This is the MVP, and I've got plans to expand it. You can read about it more here: https://github.com/LivingInSyn/Translator
I would probably expose multiple levels: 1. the \-sys crate, no abstractions at all 2. A public API that gives safe wrappers around those \-sys functions 3. A high\-level API that does the thread&amp;queue thing with enforced delays between calls to the backend.
maybe one of the core devs can correct me, but this seems like the kind of thing you should open an issue for at https://github.com/rust-lang/rust/issues
Did you figured it out or did you fill in a bug in xargo upstream?
&gt; Write an imperfect foundational library, and watch everything built on top of it crumble down at some point. &gt; Perfection has its uses. &gt; &amp;mdash;https://news.ycombinator.com/item?id=15170219
Another workaround is to add the nightly libs to your path. For example, on Mac it would be something like: `LD_LIBRARY_PATH=~/.rustup/toolchains/nightly-x86_64-apple-darwin/lib cargo clippy` For Windows it would be the `bin` dir (for dlls) to PATH. 
Idk, it's just easier to keep track of smaller numbers IMO. There's a reason Linux went from 2.36 -&gt; 3.0, and it wasn't because there was some backwards incompatible change. To quote (emphasis mine): &gt; It will get released close enough to the 20-year mark, which is excuse enough for me, although honestly, **the real reason is just that I can no longe rcomfortably count as high as 40** As editions roll out, I'll likely be referring to Rust releases by their Edition name (e.g. Rust 2018), but individual releases still matter, and it's a bit confusing to remember if Rust 1.40 is part of Rust 2018 or Rust 2019. Having the minor number reset will help me remember, "oh, it was 4 releases since the Rust 2018 edition, so it has feature X". I don't particularly care if that means that Rust 2018 is "2.0" or "2018.0", it *is* helpful to know the delta since an edition release. If an edition is released roughly once a year, then there are 8-9 Rust releases until the next edition. I don't know why, but my brain works a lot better with comparisons between small numbers than large ones. 1.26 is already getting quite large, and the only reason I remember it is because a few significant things landed (and my FreeBSD build broke, so I had to wait until 1.26.1 to use those new features). This is also somewhat annoying with Firefox. IMO, Firefox should've reset the minor number with Firefox 57 to mark that it's a "new browser" with the stylo uplift and the end of support for legacy extensions. That's not *particularly* relevant here since Rust is a separate project, but it *does* mark a point at which a natural minor version reset would've been helpful (e.g. if the rapid release cycle for Firefox was X.Y.Z, instead of Y.0.Z). Version numbers in Chrome and Firefox are unhelpful, and while I appreciate that they're intended to be meaningless (since they're intended to be continuously updated), it ends up being significant in my particular line of work. I deal with ultra-conservative IT departments (military, infrastructure, etc) where we need approval to update the browser on locked-down devices. It's a bit easier to just figure out what polyfills I need to use for whatever old version they have, but I have to look it up every time because I can't easily make mental checkpoints with version numbers as large as they are. I don't know if others feel the same way, but I feel that smaller version numbers are generally more helpful than larger ones. And Rust (the language) technically *is* breaking backwards compatibility by using a different edition, but the compiler will continue to support older editions of Rust. It's really just marketing at this point. As you mentioned in your talk, Java does something similar by supporting older versions of Java in their newer compilers, and takes 2-3 "editions" do remove deprecated items. However, Java *also* uses version numbers for newer releases (e.g. Java 8 vs Java 7) to signify that there are new features and potentially removed deprecated features. So why should Rust do something different?
I'm emailing one person who might be able to help (other than fenrirwolf and his magical appearance in various places, and japaric because he's freakin next level) to see if I'm missing something trivial, and then I might fill in a bug. I'm (both relatively and absolutely) quite new to the rust scene, but I'm delighted to see how kind and helpful the community is, but I'm hesitant to file a bug if I'm not entirely sure there is one. At the moment, I did some basic shenanigans and ended up apparently slightly further than before (deleted, reloaded the appropriate file, which went from a wall of error, to a simple "can't find specification". 
Interesting, thanks :)
Sorry if it came off a bit ranty. I can potentially throw together an RFC if that's the proper thing to do.
Not at all! The length is great, it really helps me understand how you think about it. I would think that with so much stuff in flight we wouldn’t consider something like this until after the edition ships; it still might be worth an internals post just to see how others feel.
\&gt; More constructively: Is anyone looking at the list of Rust open source projects that bors compiled for integration testing? Do they still have a representative list of features like impl\-traits, ?\-in\-main etc. Literally every crate on [crates.io](https://crates.io) is tested every release. The problem is that some workflow things get missed \(e.g. running RLS and then cargo\). \&gt; Is there a plan to cut a Rust2018 Developer Preview, with a Reddit announcement. Yes. But I'm unclear how the edition is relevant to this at all; none of these breakages have anything to do with the edition.
None of this has to do with Rust2018, however.
Exactly. You explained it better than I did :\)
Almost this entire article can apply to a JVM agent too (i.e. using JVMTI). They are pretty easy to write.
I don’t see what this is trying to achieve, because Cargo does find clippy on stable. It’s just clippy falls over.
That sounds like a good idea. I understand that there's a ton of work leading up to the first edition, but I think it's important to at least reach an informal consensus before cutting it, though it doesn't need to happen before the preview release.
got past this error, now onto updating libc 
Ah, cool! It’s nice to hear when random code I wrote for fun is getting used.
I've filled an [issue](https://github.com/rust-lang/rust/issues/51223) upstream.
I don't think it ever has `From&lt;&amp;String&gt;`, just the identity `impl From&lt;T&gt; for T`, i.e. `From&lt;&amp;str&gt;`. Normally, your `&amp;String` will auto\-deref to `&amp;str`. But if` env_logge`r or its dependencies add a new` From&lt;Something&gt; for &amp;st`r, then we have multiple possibilities of` Fro`m and auto\-deref isn't applied. I suspect it's [this one](https://docs.rs/env_logger/0.5.10/env_logger/struct.Env.html#impl-From%3CT%3E). You can also write `&lt;&amp;str&gt;::from(&amp;*string)` to do the same thing auto\-deref would.
Ah ok. Thanks. I'll try it then.
I think all the patterns suggested here prevent you from using intermediary values, except the pyramid.
For instance: https://gist.github.com/LivingInSyn/ee19783b5eb848317440e1dd50860a94 Works perfectly
Here are my initial impressions, please note that I'm not an expert. - You can refactor the code into multiple files instead of a single 400 file. - I think you should use match instead of if : https://github.com/brycx/checkpwn/blob/master/src/main.rs#L53
I suppose should be `struct SomeStructTag { int32_t foo;`
The only activity I'm aware of is in [https://internals.rust\-lang.org/t/removal\-of\-all\-unstable\-placement\-features/7223](https://internals.rust-lang.org/t/removal-of-all-unstable-placement-features/7223) \(which had some interesting thoughts\), but I've not seen anything that immediately strikes me as a solution. I'd see step 1 as defining precisely what placement behaviour the proposal intends to guarantee \(a task that has some subtleties\) \- this then allows reviewers to a\) decide if they agree with the goals and b\) decide if the goals can be met by the design.
Unless you're talking about C, **and not C++**, then the struct name won't matter indeed.
I've heard that it's important for the growth of the language to have these Rust-in-production success stories out there. Always nice to read them!
I mean, that's fair, but the claim was that this won't work over FFI. It very clearly does
Fixed. Thanks for the PR!
Author here - can you expand what you're saying? The position of the Rust code in this project is as a standalone binary that sits outside of our customer's Python app (Ruby and Elixir the same), and the specific-to-those-languages agents are inside the app, and push data outward. I'm not very familiar with the Java ecosystem, can you expand on where you see the JVMTI code fitting in?
The proposed [try-expressions](https://www.reddit.com/r/rust/comments/8a32wj/rfc_reserving_try_for_try_expressions/) look quite similar to your trick.
Luckily non lexical lifetimes remove the need for using move expressions in most cases, including the example you posted below.
There is no guaranteed way to get placement new semantics, from what I understand. https://crates.io/crates/boxext You can use that crate and the 'with' methods that take closures to fake it - this relies on optimizations and is not guaranteed though.
This is a valid point - safety is high on agenda for Rust. But be careful with cherry picking examples that align with your world view. It becomes very hard to see differently
Can you easily write Ruby and Python modules with JVMTI?
Hmm, what do you mean? It supports an `else` clause but I think it just copies the code N times. 
Yes, it's still true you can't create a binding in a higher scope. But a macro can expand to statements without introducing a new scope, avoiding the issue. My [RFC 1303 macro](https://github.com/durka/guard) recursively parses the pattern in order to do this. 
What is this "placement new" about?
&gt; PCJ What does this acronym stand for?
Placement `new` is a C++ language feature. In C++, the `new` keyword can be used to both allocate memory (via the `operator new`) and call the constructor of the object: `new MyType(4)`. It is less known that `new` can also be invoked with parameters *for the `new` operator*: `new (&lt;parameters&gt;) MyType(4)`. These parameters can be used to pass any argument to `operator new` (as long as a suitable overload of the operator is provided), such arguments may include a pool to allocate from, a particular alignment/region, etc... Placement `new` is the only `operator new` with parameters provided by the standard library: it takes a `void*` as parameter, and returns this address instead of allocating memory. This lets the user construct an object *in-place* at an arbitrary (suitably aligned) place in memory. ---- There have been attempts to bring such functionality to Rust, which are regularly referred to as "placement new" since it's a similar concept in a language many in the community are somewhat familiar with and thus a short way of describing the functionality. As noted, those attempts are for now aborted (back to the drawing board).
Someone more knowledgable should confirm this, but I think it goes like this: Right now you allocate a value on the heap with `Box::new`. let b = Box::new(123) This looks okay at first, but notice that since the value is passed as an argument to a function it is first constructed as a local value (on the stack) which is then moved into the allocated area. For a small values this doesn't matter, but for larger structs this causes (1) larger stack usage and (2) unnecessary copies. Placement new was one proposal to fix this by having a custom syntax for saying "construct this value directly inside the allocated area".
Yeah, I agree completely. The other option that I thought of was to have a file for each struct, and a file that I edit incrementally that re-exports all of the individual struct files
I'm sure there are more nuances than just that example, but surely that would be trivial to optimize away? I tried to show that it *is* optimized away in Godbolt, but I realized it places `123` in a register before moving it to the allocated memory, but I also don't know enough assembly to know whether there's a better way to do this (and I don't think there is). I guess my point is, I'm not sure that example explains to me the benefits in terms of how it gets compiled.
Actually there [was a post](https://www.reddit.com/r/rust/comments/8i1063/psa_help_us_test_the_upcoming_rust_126_all_it/) three weeks ago. u/kibwen has [done this before](https://www.reddit.com/r/rust/comments/600mwc/psa_hey_rust_users_especially_library_authors/) as well. 
Just spent some time wrestling with this issue, and yes, it would absolutely help to have a version number in the error message.
I read through all the relevant RFC's and issues in ~April. There's no solid plans, and no one appears to be dedicated to the mission. The work-around I've settled on for large structs is to use `unsafe fn init(&amp;mut self)` methods instead of `fn new() -&gt; Self` methods, and to use `ptr::write` and/or cascaded `init`s for initialization. It's not as pretty, but it works, and it's no less safe than the corresponding C code.
RiscV would be so, so cool. 
So, to be clear, you'd be happier with this: ``` typedef struct SomeStructTag { int32_t foo; Baz bar; Baz* baz_pntr; uint8_t foobar[5]; char* test_c_char; } SomeStruct; ``` If that's the case, there's a compromise to be made in the default mapping because there's a handy override (because of the std::os::raw library).
I'm continuing work on my distributed web scraper. This week I want to get the "tester" portion done, where it reads a tests json file and ensures the webpages for a certain site are scrapeable and marks sites ready or not before the actual scraping.
That's a bit like saying the purpose of a car is to drive people to work, sure it's true, but it kind of misses the breadth of other things people do with cars.
'monadic', but not 'proper monad'. Which I take to mean 'can express monads'. The fact that and\_then is monadic doesn't take away from the fact that we can't actually express the concept of monad in the language yet. That's sort of synonymous with the do\-block, it works on any Monad. We're nitpicking here obviously
This isn't a great example. Sure, this will definitely affect debug mode, but in release mode the compiler will optimize this away. Similar to `Box::new(MyLargeStruct { ... })` vs `box MyLargeStruct { ... }`
This isn't a great example. Sure, this will definitely affect debug mode, but in release mode the compiler will optimize this away.
The fact that it gets optimized away is certainly nice, but the true problem is that there's no way to intentionally and unconditionally place something directly on the heap.
The point is that you don’t have to rely on the optimizer; you’re guaranteed that it happens. Furthermore, it can work on more places than just boxes.
i agree. I will say, I recently chose go over rust for a project and find myself dealing with the same problem: if err != nil after every db call and most functions can be pretty frustrating to deal with and looks pretty gross. I'd think error handling would be more thought out given that go is so particular about things like function names and formatting and version imports. That said, I recognize that it and rust are both great languages in different ways. 
All I can see is `Page not found` :(
Why don't impls for serde’s `Serializable` and `Deserializable` traits show in the generated documentation?
Ah, cool, so there is already an implementation! \^v^/ Though as to details, I must say I don't really understand the subtlety of the solution to the binding problem: *"[We] can't create a binding in a higher scope[, so we] construct a top-level `let` statement [...]"*; uh-oh; isn't a `let` statement in fact creating a binding and introducing a new scope? o_O
`let` doesn't introduce a scope. Curly braces do that. 
X: Is there a list of traits from the std somewhere? Y: wlroots-rs is rapidly approaching 1.0 status and I want to ensure I have everything implemented that can be implemented. I know about Eq, PartialEq, Hash, Debug, Display, Clone, and Copy. Is there anything else that's reasonable to implement?
&gt; But if it's trivial to optimize away, I would imagine it does actually get optimized away... As mentioned, the optimization is not only very hard to do, but it is easy to come up with cases in which it is impossible to perform (cross-crate function calls without LTO), single crate function call using `#[inline(never)]`, `#[target_feature]`, etc. Basically anything that prevents inlining prevents this optimization.
Can you explain that to me please? Why would inlining make it so you can't optimize this? 
The docs seem to list the traits on a per-module basis, e.g. [`std::borrow`](https://doc.rust-lang.org/std/borrow/index.html#traits). Not familiar with wlroots-rs but off hand I'd say you might want any generic impls for the various conversion/coercion traits (`FromStr`/`From`/`TryFrom`/`Into`/`TryInto`/`Borrow`/`AsRef`) and possibly any operators that make sense `Add`/`Sub`/etc. Maybe `Default`.
Rewritten with [`is` sugar](https://github.com/rust-lang/rfcs/issues/929#issuecomment-285602496): fn f(a: A){ if a.b is Some(b) &amp;&amp; b.c is Some(c) &amp;&amp; c.d is Some(d) { if d.field is Some(f) { println!("{}", f) } else { // log the missing field } } } 
https://github.com/rust-lang/rust/issues/22750
Note that if your goal is to help ffi, then your rust code *needs* to use #[repr(C)] on the structs, otherwise the layout will likely not match.
How you get the midi interface will depend on your operating system. There's a few crates here that may be useful: https://github.com/RustAudio I've personally done this with Jack on Linux, but jack is probably overkill unless you are already running it for something. Web browers can also read from midi devices, I wonder if there's a cool WebAssembly way to do something fun?
Consider: // crate A: #[inline(never)] fn foo(x: [u64; 1000000]) -&gt; Box&lt;[u64]&gt; { Box::new(x) } // crate B: A::foo([0; 1000000]); When compiling crate A, assembly code for `foo` is generated, and the function API is exported, but other crates don't know what `foo` does, its internals are private. When compiling crate B, the compiler only knows the signature and the address of `A::foo` and just call it. It has no clue what `foo` does (it does not know and cannot know that `Box::new` is called in it because that is private), so it puts the array on the stack, and calls the function using the calling convention of the current target. At run-time, the array overflows the stack. 
I see. That makes sense to me, though I would like to point out perhaps ego-defensively that that's not the original example. Could you also please explain how this proposal would solve the problem?
&gt; though I would like to point out perhaps ego-defensively that that's not the original example. `Box` is in a crate different that the code written in the original example (unless you are writing code in libcore).
&gt; Could you also please explain how this proposal would solve the problem? There is no proposal, this problem is really hard to solve. C++ "solves" it by requiring everything involved to be `#[inline]`. That solution sucks.
&gt; Also re-borrows behave oddly. Re-borrowing locks out the original borrow; it's less about not having more than one reference to something, and more about not having more than one *active* reference. The first example compiles because you're not *allowed* to use `some_object` until `mut_ref`'s borrow ends. In the second, you're trying to create two distinct `&amp;mut _`s that will both be live at the same time.
&gt; There is no proposal Then what is placement new?
I'm working on a crate that needs to extrapolate to &gt;2 dimensions in some use cases, but I want to allow the user to opt into this. I would like to make the default number of dimensions 2 while enabling the user to change this (without forking, etc.) to an arbitrary value specified at compile time. The crate is all set up with a `const DIMENSIONS: usize` binding, but I don't know of an easy way to let this be an arbitrary value without editing my crate's source. Is there such a trick?
Thanks for your help!
A language feature of a different programming language.
[Are you in the same thread as me?](https://github.com/rust-lang/rust/issues/27779)
fire up qbasic or turbo c++ in a dos box sometime and maybe you will understand the simplicity and the value of that. 
amazing!!!!!!!!!!
&gt; fire up qbasic or turbo c++ in a dos box Would require me to download one of those and own a DOS box. Opening notepad (or equivalent) and a browser is by far more accessible nowadays.
own a dos box? how old are you son! *yells at cloud* 
Can someone recommend me a book for systems programming? I want to learn Rust, but the book I bought, "Programming Rust" by Blandy and Orendorff, teaches the language but doesn't teach systems programming.
Can't wait to hear the Bike Shed on this one.
I work for a HFT in fintech and NYC and we use C/C++. The reason is mostly because that is what the HFT experienced guys on the street know. It's harder to build and team and recruit experienced people using something non-standard. We are always looking for good low-latency C/C++ techies with a lot of experience or coming from top colleges, so if this is something you would be interested (fulltime on-site in NYC) feel free to PM me for more info.
First, this is a challenging task. Second, if you would like to follow along with something with a little bit of structure, check out Stanfords CS140e. [https://web.stanford.edu/class/cs140e/](https://web.stanford.edu/class/cs140e/) Good luck on your quest!
That's exactly why I want to attempt it. Thank you!
[Redox](https://github.com/redox-os/redox) Is an OS written in Rust. There is also [this blog series](https://os.phil-opp.com/) , which walks you through building one.
Definitely run into the motivating case before. Would love to see this extension to the rules. Would also love to see a way to truly define orphan impls. I've found that handy in Scala, and it's only possible due to the way Scala searches the implicit scope, effectively allowing for prioritized implementations. In my mind it's not too far removed from specialization. Just spit-balling here: maybe Rust could have a more principled variant where a crate must declare it provides orphan impls for a set of traits/types in order to define those impls, but you cannot depend on two such crates whose sets overlap if you use any of those traits. Such a thing might be more tedious than Scala but it would also be less brittle at least it's not impossible. Thanks for writing up the RFC /u/rabidferret - I always know I'm in for a treat when I see your name attached.
The secret to systems programming is...there is no secret. It's just programming.
Interesting. I'll give it a look, thanks!
I think reqwest would generally be advised for a high level library for simple use cases. If you want to do anything complicated, use hyper, which reqwest uses internally. Although I'm interested to see if anyone has any less obvious suggestions.
Special thanks to Debian for packaging 1.26.1 and adding it to Debian/Sid. You people are doing great work. [link](https://packages.debian.org/sid/rust/rustc)
Is Rust a good language for developing an OS? Arguably it's now the best language for the job; C/C++ are old and have there warts, while most modern languages are not suitable for developing a kernel. Of course, not everyone would agree that Rust is best, but if you want a different opinion, this particular subreddit may not be the best place :-). Is developing an OS a realistic project? I haven't gotten around to building an OS from scratch yet, though I am a contributor to Redox. But it's not necessarily as hard as it sounds. Philipp Oppermann's blog should be a good source, and osdev.org should have some helpful information. One of the issues with OS development is that there sometimes isn't much information available. You can find a lot of resources on developing web apps. But if you want to implement [the ISO 9660 filesystem](https://github.com/ids1024/iso9660-rs) (a project I need to get back to), you might have to look into places like comments in the Linux kernel source code to learn about quirks you should deal with. Of course, for central aspects of a kernel, you can find books like the one you mentioned. As far as Rust-specific concerns, to develop a kernel you will have to work with with nostd code, some of which will be unsafe, and you'll probably have to compile with nightly to use some unstable features. So if you aren't familiar with any of those things, you should start reading about them.
There is `rendersvg`, which is a CLI application that you can run anywhere. 
That did not solve problem, so it was removed and no longer exists in rust. Nothing has replaced it yet, so there is no proposal that would solve the problem.
No, just a gaming graphics card and bad wiring. ;-P
Check out [intermezzOS](https://intermezzos.github.io/book/) as well
I use the [mdo crate](https://github.com/TeXitoi/rust-mdo) for this. It provides do-notation for Option, Result and Iterator. So your example would become: fn f(a: A){ if let Some(f) = mdo! { b =&lt;&lt; a.b; c =&lt;&lt; b.c; d =&lt;&lt; c.d; ret d.field } { println!("{}", f) } else { // log the missing field } }
Btw, with the [`mdo` crate](https://www.reddit.com/r/rust/comments/8n4o5q/avoiding_the_pyramid_of_doom/dzv9k7s/) you can use intermediate values later in the chain.
Why doesn't [this](http://play.rust-lang.org/?gist=63a52d85c719c85dd1c6349120e493b1&amp;version=nightly&amp;mode=debug) work? Why does `s.len()` even borrow `s` immutably in `while s.len() &gt; 0 {`? `.len()` is not returning a ref into `s`.
And in debug you will get stack overflow. Happy bugfixing program that works only with optimizations enabled.
Because it *has* to borrow `s` to look at the length.
If you weren’t happy with sharing data between threads using a mutex, I’d suggest sending messages with a `mpsc` ( multi producer single consumer channels). As a side effect you won’t need to worry about thread deadlocks as you can just fire and forget.
But only for the duration of the `s.len()` call! Why is `s` still borrowed in the while-body?
It's not. It's the *mutable* borrow that's blocking the immutable borrow. The loop is re-borrowing `s`, then looping back to the top. Because there are two ways into the top of the loop (`s` contains the original borrow *vs.* `s` contains a reborrow of itself), I think the compiler is working under the conservative assumption that *either* could be live at that point.
What I teach in the book today is, "use `&lt;T: &gt;` when the bounds are simple, move to `where` when the bounds are complex." As far as I know, that's still our recommendation. Basically, the same as /u/Quxxy.
&gt; Maybe if we just allowed crates to have incompatible impls, and set a standard of "don't write orphan impls unless that's the entire point of your crate", it wouldn't actually be that bad. What about a special kind of `impl` that has to be `use`d to apply? Like: #[no_orphan_rules_pls = "descriptive_name"] impl&lt;T&gt; ForeignTrait for T { ... } And to actually use that impl, you'd have to `use that_crate::descriptive_name`. So whenever the compiler has to decide whether or not a trait is implemented for a type, it would have to consider all normal impls (as today) *and* all special impls that are in scope. And if the imported impl would overlap with some normal impls, the compiler would show an error ala "no you can't import that impl, because it's overlapping with this other impl". That would shift the problem of "no overlapping impls in the whole world" to "no overlapping impls in scope". Which is actually exactly what we do with names: same names are allowed to co-exist in the world as long as they are not in scope at the same time. --- I really haven't thought this through yet, but it's true that orphan rules are very annoying for a few things. Somehow explicitly "allowing" them for the few cases where they are really important would be a great step, I think. 
Wait, we agree on something in regards to code formatting? I wasn't aware we were due for a planetary alignment... :P
&gt; Is Rust a good language for developing an OS? Arguably it's now the best language for the job This is a very bold and unsubstantiated claim...
 Whats wrong with HashMap&lt;Key,HashSet&lt;V&gt;&gt; ? or or HashMap&lt;Key,Vec&lt;V&gt;&gt;. or a HashMap&lt;Key,LinkedList&lt;V&gt;&gt; or an other collection as value ( and the other container versions of those ) I never understood the usefullness adding it to std as a structure, since then the choice was already made w.r.t outer and inner container and it might not fit your usecase. Perhaps as a trait over all options which could provide some wrappers for easy access. 
No idea. AFAIK, `nll` was about allowing borrows to end sooner than their lexical scope, but in this case, you've got a borrow that's *supposed* to live into the next loop iteration. Unless `nll` can *also* figure out when to not re-borrow, I wouldn't be surprised to see it still fail to handle this.
It's been tagged as "fixed by NLL" on Github. TBH I don't have the knowledge required to confirm or deny this claim right now, have you?
Ha!
Can this actually be bike-shedded? It's about having more permissive coherence rules, and does not introduce any new names or syntax to bike shed.
I think the explanation of why it is worth addressing and why this solution is helpful, even if less than perfect, could be sufficiently interesting. The issue thread on the RFC is interestingly already.
That's rather nice! And it extends to 'capturing' multiple mutable variables pretty well using a tuple: https://play.rust-lang.org/?gist=310e4e3bbee47f673efc67e5c791735a&amp;version=stable&amp;mode=debug Although if you 'capture' a Foo, what you end up with in the method is a &amp;mut &amp;mut Foo, which auto-deref means is fine most of the time, but sometimes needs contortions, like calling add_assign directly rather than being able to use +=.
Yes, that's what my example code does.
&gt;What language would you build an OS with? C or C++ until Redox experiments ends with the developers concluding that Rust was a good language and it didn't get in their way. They may have already reached this conclusion as I didn't follow them much though.
For those who want to see this for themselves: simply select the nightly channel, and add this to the top of the file:`#![feature(nll)]`
Thank you.
This is one of various [soundness bugs](https://github.com/rust-lang/rust/labels/I-unsound%20%F0%9F%92%A5), some of which are some years old. Of course it would be nice if all soundness bugs in the compiler are fixed, but I don't think they make the Rust language not safe.
I believe they mean http://bikeshed.fm/
Ah, that makes much more sense! Thanks.
[removed]
This is horrible! :-C~ Who would do such a thing?!
As always, everything needs to be prioritized. Soundness holes are some of the most severe bugs, but you always have to consider how many people they affect, how hard they are to fix, who is available to work on things, etc. Take this bug, for example. It's going to be fixed by NLL. Is it worth dropping everything to fix now, when it's going to just be fixed in a few months, taking away from the time to fix other bugs? It's also not clear anyone has run into this in real code, but instead was found by someone messing around. What's most important, though, is that soundness bugs *are bugs*. Software has bugs. It happens. They'll be fixed.
According to [this blog post](http://smallcultfollowing.com/babysteps/blog/2018/04/27/an-alias-based-formulation-of-the-borrow-checker/) the new borrow checker engine will handle examples like [this](https://github.com/rust-lang/rust/issues/47680#issuecomment-363131420). So wouldn't it handle your example, too?
I don't think it is an objective for the standard library to include every data structure under the sun but rather just the ones that are used most often like \`Vec\` and \`HashMap\`. An exception would be \`LinkedList\` \(actually a doubly linked list\) which, although not used often, might exist in the standard library since it can't be written in safe Rust.
[removed]
I don't know. In theory, practice and theory are the same; in practice, they aren't. Besides which, I don't work on NLL.
i'm surprised you're allowed to do that raw pointer manipulation outside unsafe
It works for me right now
Manipulating raw pointers is safe. Only the deference is unsafe. If you modify a pointer but don’t dereference, nothing terrible can happen.
Yes we do. We do require an on-site interview though so you would have to come to NYC for a day.
While I don't fundamentally disagree with what you say, there's more to it than that, I think. On the front page of rust-lang.org, we say that Rust features **guaranteed memory safety**. What is the guarantee really worth, if we are aware that rustc has several bugs that cause unsound code to be emitted, many of them being open for several years? Easy for me to complain about while others do the work? So I thought a while ago, so I spent quite some time actually fixing one of these bugs, and it ended up being [reintroduced on purpose](https://blog.rust-lang.org/2018/03/01/Rust-1.24.1.html) by the Rust core team. :-( That says something about priority too.
Rust the language guarantees memory safety. The implementation, like any implementation has bugs. "Modulo bugs" is *always* implicit when talking about this, even when people say things like "x was proven to be true", they mean "x was proven to be true, modulo bugs that may be in the implementation of the solver", etc. &gt; many of them being open for several years? This is the whole thing about prioritization. Many of these bugs are *much* harder to fix than the value gained from fixing them *right now*. &gt; it ended up being reintroduced on purpose by the Rust core team Yes, but as it says &gt; While we still plan to introduce this behavior eventually, we will be rolling it out more slowly and with a new implementation strategy. We severely broke a production user with this change, while the fix was fixing a hole that wasn't affecting anyone. You're right that it speaks to priorities, but the priority is stability and taking care of people over being able to just close a bug. You know?
I have a gut feeling we'd really want something like an "unitialized" keyword for this. Then one would be able to support something similar using: struct A { foo: i32; }; impl A { fn new_at(&amp;mut unitialized self) -&gt; Result&lt;&amp;mut Self, Error&gt; { self.foo = 12; Ok(self) } } Effectively this would mean that the compiler knows that the "self" parameter is unitialized, but the result would be that unique reference without the "unitialized" keyword, so only the fully initialized mutable reference can be returned \(otherwise it would be a compile error\). So when this function returns, the mutable reference is either fully initialized or not initialized at all. The compiler check if all fields are initialized or none are initialized \(any assigned fields' values have to be dropped\). The caller will \(barring panics, but those introduce their own kind of safety\) that the structure has been initialized or not and can adjust it's knowledge about the memory underlying the unitialized parameter depending on the result.
reqwest can be async too: https://github.com/seanmonstar/reqwest/blob/bffebfc4709ad86ced3ba524515f234ad4cbc661/examples/async.rs
Locking should maybe add a couple miliseconds (or maybe nanoseconds?) To your time per request... If it's addint 2 seconds then you are probably missing something else. Also as suggested in another comment, check out RwLock
I was expecting this post to talk a little bit on the technical differences between Gotham and actix-web and Rocket and whether all 3 make sense to have in the same ecosystem. I'd expect that to be part of the conversation in recruiting new maintainers, but it wasn't mentioned.
Thanks for pointing this out. Are the lectures for CS140e available on the website and I missed it, or must you log in with a Stanford ID?
From the [glib docs](http://gtk-rs.org/docs/glib/#objects): &gt; Each class and interface has a corresponding smart pointer struct representing an instance of that type (e.g. `Object` for `GObject`, `gtk::Widget` for `GtkWidget`). They are reference counted and feature interior mutability similarly to Rust's `Rc&lt;RefCell&lt;T&gt;&gt;` idiom. Consequently, cloning objects is cheap and their methods never require mutable borrows. Two smart pointers are equal iff they point to the same object. So yes, they are reference counted. When you pass the label in to `button.add`, it will clone the object, incrementing the reference count and so retaining shared ownership of the object. When `label` goes out of scope, its `Drop` implementation is run which decrements the reference count, but since the button still has a reference to it and is being returned, the underlying object is not deallocated; its ownership is then passed into `window`, which lives until the end of `main`.
While I usually disagree with people evangelizing a particular code formatting. I feel that three way of declaring statically dispatched parameters is too much. I would agree to recommend `impl` because it's the simplest and `where` because it can cover any case.
&gt; but you cannot depend on two such crates whose sets overlap if you use any of those traits. This rule isn't far fetched, it already exists in a form in a couple places in Rust. First libraries with C dependencies can only be linked once (and that's understood by cargo). Secondly, `#[fundamental]` traits in `stdlib` allow their definitions to be defined in the other `std` crates. Third, some `#[lang]` items like the global allocator cause single linkage. I think this property would be really useful to have for glue crates like say diesel compatibility layers for different drivers, crates like `rayon-core`, global allocators, etc!
simple, use https://doc.rust-lang.org/std/sync/atomic/struct.AtomicPtr.html#method.compare_exchange and just refresh it every 1 minutes (not 2) at that point both "old" and "new" are valid so whatever thread reads will work, and CAS ( compare_exchange ) does not require any locking or slowing down either readers or writters 
Thanks!
I'm not affiliated with any of the projects, but Rocket still requires nightly, is synchronous and will move to `hyper` or maybe something else in the future. Gotham is using `hyper`, while `actix-web` uses a completely different implementation of the protocol. I hope there will be a high-level (Rocket-like) framework based on `hyper`. That could be Gotham, but I'm not sure I like its API.
uhh sorry i thought it needs to be refreshed every 2 minutes, its actualy every 60 minutes, in that case do "refresh" CAS operation every 30 minutes
also refresh can be done in separate thread that sleeps 30 minutes between refreshes that way you dont need to do checks if token is valid on main thread, its always valid (except when Microsoft service is down)
&gt; First, this is a challenging task. Yes and no. IMO the hardest part in the beginning is bootstrapping. But you can review and understand some examples, these are often written in your target CPU's assembly. But a "super-loop" could be considered to be an "OS" in the most limited sense. And from there you add features until you're satisfied. These days with `qemu` and other similarly fantastic stuff, building an OS is nowhere near as hard as it used to be.
Assuming the OP is indeed primarily self taught and has the equivalent of Data Structures and Algorithms, this is a challenging task. The course listed here would typically be the 4th or 5th computer science course in a systems track undergrad sequence at Stanford. While some people may not consider that content challenging, I think many would and they should take pride in accomplishing it. QEMU is a pretty fantastic tool and I agree that modern tools can help you get a bare-metal OS up and running. 
I have only come across the slides on the syllabus page and then the assignments have some good content in them as well. If you combine it with the blog post mentioned by usernamedottxt I think you have some solid resources. I have not seen video lectures for OS implementation in Rust.
It's just harder to read and less idiomatic if your audience is C++ programmers. Also not sure which name you will see in the debugger using that approach. You are right that it's not especially harmful though.
&gt; developers concluding that Rust was a good language and it didn't get in their way. It's already been decided that Rust has been instrumental to the success of Redox OS, and as a result it's also being used at System76 for Pop!_OS.
While we're listing OSs, [Tock](https://www.tockos.org/) definitely deserves a mention.
It seems like you're asking for "const generics" which are vaguely planned but haven't been implemented yet. You can get part of the way there with the `typenum` crate (but you'll need a strong stomach for `where` clauses). 
This is a [known bug](https://github.com/rust-lang/rust/issues/36922) that doesn't seem to have received much investigation yet. 
There aren't profile-specific features, but you can use `#[cfg(test)]` and other things to similar effect depending on what you want. This seems like an X-Y question? 
Even with the web ecosystem being fairly "unstable" in the sense of API changes and new language features, projects like this one still come out with good quality. I'm sure we'll see an explosion of web tool crates when the ecosystem gets mature.
If I have a struct with fields that must have certain properties (IE some 'length' field takes an integer that must be less than 999), is it proper to have the associated my_struct::new() method contain logic that checks for that and have the whole thing return a Result type, or is there a more idiomatic way of doing it? I usually see this done for other types in a way that the limited type only accepts as arguments user defined types that already meet certain requirements, but for something like a bounded integer that seems overly verbose. Thank you!
Does it really use something like RefCell or just cast &amp;self to *mut Self.
 &gt; Many of these bugs are much harder to fix than the value gained from fixing them right now. I disagree. I believe that, for Rust to be appropriate in security sensitive contexts - everything from web servers to self-driving cars - there must be an implementation that is reasonably bug free, as in whenever a bug is discovered it is dealt with swiftly. But even if we do disagree about that, I cannot even put my own time into fixing soundness bugs, because they might end up getting disabled. &gt; We severely broke a production user with this change Well, the production user was told how to the code should have been written instead, tried it, found it working, and then [stated](https://github.com/rust-lang/rust/issues/48251#issuecomment-369343769) that the revert was not necessary. &gt; while the fix was fixing a hole that wasn't affecting anyone I believe it closes a whole class of possible security vulnerabilities; but you're right in that no such bugs have been discovered (at least not to my knowledge). &gt; the priority is stability and taking care of people Which people? It speaks to me that taking care of a "production user" (that does not even need the fix) is more important than taking care of unpaid volunteers that contribute code to the compiler on their spare time. Was that intended? 